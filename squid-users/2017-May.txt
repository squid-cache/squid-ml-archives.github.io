From squid3 at treenet.co.nz  Mon May  1 02:44:15 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 1 May 2017 14:44:15 +1200
Subject: [squid-users] Squid proxy without name resolution for internet
 adresses behind parent proxy
In-Reply-To: <00e201d2c17e$16067e10$42137a30$@ngtech.co.il>
References: <1493370033619-4682225.post@n4.nabble.com>
 <f6d4410e-32af-de08-b875-c4c34efd8f4a@gmail.com>
 <1493376531696-4682229.post@n4.nabble.com>
 <f4bcea5d-8681-dbb4-3cd3-ffacf5adbfc6@treenet.co.nz>
 <1493496450559-4682235.post@n4.nabble.com>
 <00e201d2c17e$16067e10$42137a30$@ngtech.co.il>
Message-ID: <90f3e28b-99eb-b6d9-7382-d168f549bce6@treenet.co.nz>

On 30/04/17 18:50, Eliezer Croitoru wrote:
> Can you try to add the next to your squid.conf:
> dns_v4_first on
>
> and see if it helps?
>
> Eliezer
>
> * http://www.squid-cache.org/Doc/config/dns_v4_first/

Just to clarify: if that solves your problem then you need to fix IPV6 
handling in your network. Squid-2 is IPv4-only, and a Squid-3 trying to 
connect to it on a properly working IPv6-enabled network should failover 
very fast to the parents IPv4 address(es). Any delay caused by IPv6 in 
that process indicated ICMP/ICMPv6 failures - usually in the path-MTU 
discovery or tunnel MSS settings.


Additional to that test - make sure the child proxy has:

  nonhierarchical_direct off

that will ensure that CONNECT/PUT/POST etc traffic is sent through the 
parent proxy and never tries to resolve.

You can also check that host_verify_strict is *not* in your child 
squid.conf. If that is set to "on" it will force Squid to resolve to do 
the verify checks. Likewise Squid-3 will need to resolve public names if 
it ever receives intercepted traffic, but thankfully your setup seems to 
avoiding that.


Assuming your local servers are using .local as the internal domain. If 
not make this whatever your internal TLD is:

  acl local dstdomain .local
  never_diirect allow !local


The cache_peer name to the parent can be hostname instead of an internal 
IP, but does need to be the internal name in this network. That will 
simplify management and also make the Squid-3 ready to cope with IPv6 
parents when your network migrates for that.

Not having dns_nameservers configured means Squid is using the machines 
system-wide DNS settings. Those do need to be set somehow, since at the 
very least Squid needs to resolve names for the parent proxies and any 
internal traffic that happens to get to it. I would make sure that has 
the internal DNS server details there to handle those lookups traffic.


If the problem remains after all that, tracking down what exactly the 
timeout value is would be helpful. The various things that can hang have 
different timeouts. And worst case a debug log with ALL,6 might be 
needed to find the exact cause of delay, but be aware that could be a 
huge log.


HTH
Amos



From thesnable at gmail.com  Mon May  1 09:10:13 2017
From: thesnable at gmail.com (marco)
Date: Mon, 1 May 2017 09:10:13 +0000
Subject: [squid-users] squid 4.0.19 error with certificates
In-Reply-To: <c28c97e5-d2b7-fbb4-a42e-91c1eb21c72d@gmail.com>
References: <c28c97e5-d2b7-fbb4-a42e-91c1eb21c72d@gmail.com>
Message-ID: <c-6120-j25wmijf-fi5evnsf00v1cphklm2c7511xxdkpr8+18p8r8x@2.bolt.im>

solution:
all monitoredsites, m1 m2 are bumped correctly
all others are spliced
squid4

this works great. just contact me for questions.

acl monitoredSites ssl::server_name_regex -i (phncdn|ypncdn|heise|rncdn|youporn)

acl m1 ssl::server_name_regex -i \.youporn\.com

acl m2 ssl::server_name_regex -i \.rncdn7\.com

ssl_bump stare m1
ssl_bump stare m2
ssl_bump stare monitoredSites
ssl_bump peek !m1 !m2 !monitoredSites
#ssl_bump splice step3 !m1 !m2
ssl_bump bump m1
ssl_bump bump m2
ssl_bump bump monitoredSites
ssl_bump splice !m1 !m2 !monitoredSites

[marco - Contact Using Hop](http://GetHop.com/?_hmid=1493629813)

On April 30, 2017 at 13:35 GMT, Yuri Voinov <yvoinov at gmail.com> wrote:

Check this. It seems this is the issue:

http://bugs.squid-cache.org/show_bug.cgi?id=4711

30.04.2017 12:02, snable snable ?????:

hello

i am using squid on a external box.
i forward all traffic from my openwrt router to it
htto works fine
https with youtube app doesnt work
i get:

Error negotiating SSL connection on FD 73: error:14094416
:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

errors

other sites work well so far

i heard that squid4 auto downloads intermediate certificates.. maybe thats the issue?

i workarounded this with a white list of sites that work. but i wanna rollout this for all sites. (also see my other question)

thanks!

_______________________________________________ squid-users mailing list squid-users at lists.squid-cache.org http://lists.squid-cache.org/listinfo/squid-users
--
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170501/e1f49eec/attachment.htm>

From yvoinov at gmail.com  Mon May  1 09:13:52 2017
From: yvoinov at gmail.com (Yuri)
Date: Mon, 1 May 2017 15:13:52 +0600
Subject: [squid-users] squid 4.0.19 error with certificates
In-Reply-To: <c-6120-j25wmijf-fi5evnsf00v1cphklm2c7511xxdkpr8+18p8r8x@2.bolt.im>
References: <c28c97e5-d2b7-fbb4-a42e-91c1eb21c72d@gmail.com>
 <c-6120-j25wmijf-fi5evnsf00v1cphklm2c7511xxdkpr8+18p8r8x@2.bolt.im>
Message-ID: <8988b672-94d1-3366-e5f6-96dbfed98ae7@gmail.com>

Sorry, this is not solution. All https spliced means for me catastrophyc 
drop byte hit. I knew about this wrkarnd from the beginning. But this is 
unacceptable.

At maximum this is temporary workaround.


01.05.2017 15:10, marco ?????:
> solution:
> all monitoredsites, m1 m2 are bumped correctly
> all others are spliced
> squid4
>
> this works great. just contact me for questions.
>
>
> acl monitoredSites ssl::server_name_regex -i 
> (phncdn|ypncdn|heise|rncdn|youporn)
>
> acl m1 ssl::server_name_regex -i \.youporn\.com
>
> acl m2 ssl::server_name_regex -i \.rncdn7\.com
>
> ssl_bump stare m1
> ssl_bump stare m2
> ssl_bump stare monitoredSites
> ssl_bump peek !m1 !m2 !monitoredSites
> #ssl_bump splice step3 !m1 !m2
> ssl_bump bump m1
> ssl_bump bump m2
> ssl_bump bump monitoredSites
> ssl_bump splice !m1 !m2 !monitoredSites
>
> marco- Contact Using Hop <http://GetHop.com/?_hmid=1493629813>
>
>
> On April 30, 2017 at 13:35 GMT, Yuri Voinov <yvoinov at gmail.com 
> <mailto:yvoinov at gmail.com>> wrote:
>
>
>     Check this. It seems this is the issue:
>
>     http://bugs.squid-cache.org/show_bug.cgi?id=4711
>
>
>     30.04.2017 12:02, snable snable ?????:
>>     hello
>>
>>     i am using squid on a external box.
>>     i forward all traffic from my openwrt router to it
>>     htto works fine
>>     https with youtube app doesnt work
>>     i get:
>>
>>      Error negotiating SSL connection on FD 73: error:14094416
>>     :SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
>>
>>     errors
>>
>>     other sites work well so far
>>
>>     i heard that squid4 auto downloads intermediate certificates..
>>     maybe thats the issue?
>>
>>     i workarounded this with a white list of sites that work. but i
>>     wanna rollout this for all sites. (also see my other question)
>>
>>     thanks!
>>
>>
>>
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org
>>     http://lists.squid-cache.org/listinfo/squid-users
>
>     -- 
>     Bugs to the Future
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170501/cf85977b/attachment.htm>

From thesnable at gmail.com  Mon May  1 09:16:10 2017
From: thesnable at gmail.com (marco)
Date: Mon, 1 May 2017 09:16:10 +0000
Subject: [squid-users] squid 4.0.19 error with certificates
In-Reply-To: <8988b672-94d1-3366-e5f6-96dbfed98ae7@gmail.com>
References: <8988b672-94d1-3366-e5f6-96dbfed98ae7@gmail.com>
Message-ID: <c-6120-j25wu54r-gzcm5rqzk83xjmzq7g6w64szd9x6fuc+11g4knb@2.bolt.im>

Thanks. What means drop byte hit? I just wanna bump a few sites, and pass the rest. Why isnt that a good solution? Is it bad form
performance?

[marco - Contact Using Hop](http://GetHop.com/?_hmid=1493630170)

On May 1, 2017 at 9:13 GMT, Yuri <yvoinov at gmail.com> wrote:

Sorry, this is not solution. All https spliced means for me catastrophyc drop byte hit. I knew about this wrkarnd from the beginning. But this is unacceptable.

At maximum this is temporary workaround.

01.05.2017 15:10, marco ?????:

solution:
all monitoredsites, m1 m2 are bumped correctly
all others are spliced
squid4

this works great. just contact me for questions.

acl monitoredSites ssl::server_name_regex -i (phncdn|ypncdn|heise|rncdn|youporn)

acl m1 ssl::server_name_regex -i \.youporn\.com

acl m2 ssl::server_name_regex -i \.rncdn7\.com

ssl_bump stare m1
ssl_bump stare m2
ssl_bump stare monitoredSites
ssl_bump peek !m1 !m2 !monitoredSites
#ssl_bump splice step3 !m1 !m2
ssl_bump bump m1
ssl_bump bump m2
ssl_bump bump monitoredSites
ssl_bump splice !m1 !m2 !monitoredSites

[marco - Contact Using Hop](http://GetHop.com/?_hmid=1493629813)

On April 30, 2017 at 13:35 GMT, Yuri Voinov <yvoinov at gmail.com> wrote:

Check this. It seems this is the issue:

http://bugs.squid-cache.org/show_bug.cgi?id=4711

30.04.2017 12:02, snable snable ?????:

hello

i am using squid on a external box.
i forward all traffic from my openwrt router to it
htto works fine
https with youtube app doesnt work
i get:

Error negotiating SSL connection on FD 73: error:14094416
:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

errors

other sites work well so far

i heard that squid4 auto downloads intermediate certificates.. maybe thats the issue?

i workarounded this with a white list of sites that work. but i wanna rollout this for all sites. (also see my other question)

thanks!

_______________________________________________ squid-users mailing list squid-users at lists.squid-cache.org http://lists.squid-cache.org/listinfo/squid-users
--
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170501/399a6e8d/attachment.htm>

From squid3 at treenet.co.nz  Mon May  1 10:50:58 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 1 May 2017 22:50:58 +1200
Subject: [squid-users] squid 4.0.19 error with certificates
In-Reply-To: <c-6120-j25wu54r-gzcm5rqzk83xjmzq7g6w64szd9x6fuc+11g4knb@2.bolt.im>
References: <8988b672-94d1-3366-e5f6-96dbfed98ae7@gmail.com>
 <c-6120-j25wu54r-gzcm5rqzk83xjmzq7g6w64szd9x6fuc+11g4knb@2.bolt.im>
Message-ID: <a409ac7a-e7a8-4379-31c0-1eb0255df6ca@treenet.co.nz>

On 01/05/17 21:16, marco wrote:
> Thanks. What means drop byte hit? I just wanna bump a few sites, and 
> pass the rest. Why isnt that a good solution? Is it bad form
> performance?
>

Yuri prizes caching over everything, including correctly behaving 
HTTP(S) and user experience.

If the solution works for you that is good, and it is generally best not 
to intercept HTTPS traffic unless you have a reason to do so.

Amos



From yvoinov at gmail.com  Mon May  1 11:38:29 2017
From: yvoinov at gmail.com (Yuri)
Date: Mon, 1 May 2017 17:38:29 +0600
Subject: [squid-users] squid 4.0.19 error with certificates
In-Reply-To: <c-6120-j25wu54r-gzcm5rqzk83xjmzq7g6w64szd9x6fuc+11g4knb@2.bolt.im>
References: <8988b672-94d1-3366-e5f6-96dbfed98ae7@gmail.com>
 <c-6120-j25wu54r-gzcm5rqzk83xjmzq7g6w64szd9x6fuc+11g4knb@2.bolt.im>
Message-ID: <ed85b7b0-f63c-6210-6d91-930b81e8f279@gmail.com>

Byte hit is caching related. This is most important functionality for me.


01.05.2017 15:16, marco ?????:
> Thanks. What means drop byte hit? I just wanna bump a few sites, and 
> pass the rest. Why isnt that a good solution? Is it bad form
> performance?
It disables HTTPS caching completely.
>
> marco- Contact Using Hop <http://GetHop.com/?_hmid=1493630170>
>
>
> On May 1, 2017 at 9:13 GMT, Yuri <yvoinov at gmail.com 
> <mailto:yvoinov at gmail.com>> wrote:
>
>
>     Sorry, this is not solution. All https spliced means for me
>     catastrophyc drop byte hit. I knew about this wrkarnd from the
>     beginning. But this is unacceptable.
>
>     At maximum this is temporary workaround.
>
>
>     01.05.2017 15:10, marco ?????:
>>     solution:
>>     all monitoredsites, m1 m2 are bumped correctly
>>     all others are spliced
>>     squid4
>>
>>     this works great. just contact me for questions.
>>
>>
>>     acl monitoredSites ssl::server_name_regex -i
>>     (phncdn|ypncdn|heise|rncdn|youporn)
>>
>>     acl m1 ssl::server_name_regex -i \.youporn\.com
>>
>>     acl m2 ssl::server_name_regex -i \.rncdn7\.com
>>
>>     ssl_bump stare m1
>>     ssl_bump stare m2
>>     ssl_bump stare monitoredSites
>>     ssl_bump peek !m1 !m2 !monitoredSites
>>     #ssl_bump splice step3 !m1 !m2
>>     ssl_bump bump m1
>>     ssl_bump bump m2
>>     ssl_bump bump monitoredSites
>>     ssl_bump splice !m1 !m2 !monitoredSites
>>
>>     marco- Contact Using Hop <http://GetHop.com/?_hmid=1493629813>
>>
>>
>>     On April 30, 2017 at 13:35 GMT, Yuri Voinov <yvoinov at gmail.com
>>     <mailto:yvoinov at gmail.com>> wrote:
>>
>>
>>         Check this. It seems this is the issue:
>>
>>         http://bugs.squid-cache.org/show_bug.cgi?id=4711
>>
>>
>>         30.04.2017 12:02, snable snable ?????:
>>>         hello
>>>
>>>         i am using squid on a external box.
>>>         i forward all traffic from my openwrt router to it
>>>         htto works fine
>>>         https with youtube app doesnt work
>>>         i get:
>>>
>>>          Error negotiating SSL connection on FD 73: error:14094416
>>>         :SSL routines:SSL3_READ_BYTES:sslv3 alert certificate
>>>         unknown (1/0)
>>>
>>>         errors
>>>
>>>         other sites work well so far
>>>
>>>         i heard that squid4 auto downloads intermediate
>>>         certificates.. maybe thats the issue?
>>>
>>>         i workarounded this with a white list of sites that work.
>>>         but i wanna rollout this for all sites. (also see my other
>>>         question)
>>>
>>>         thanks!
>>>
>>>
>>>
>>>         _______________________________________________
>>>         squid-users mailing list
>>>         squid-users at lists.squid-cache.org
>>>         http://lists.squid-cache.org/listinfo/squid-users
>>
>>         -- 
>>         Bugs to the Future
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170501/583f1701/attachment.htm>

From acctforjunk at yahoo.com  Mon May  1 13:18:26 2017
From: acctforjunk at yahoo.com (j m)
Date: Mon, 1 May 2017 13:18:26 +0000 (UTC)
Subject: [squid-users] Tutorial for better authentication than basic
References: <456739995.1458100.1493644706831.ref@mail.yahoo.com>
Message-ID: <456739995.1458100.1493644706831@mail.yahoo.com>

I'm using Ubuntu 16.04 Server in the home and would like to set up a proxy server for use from over the Internet. ?The main purpose for this is to easily access a few web-devices on my LAN without using VPN, and at times to route web traffic from a remote location through my home ISP. ?I do not need nor want any caching or filtering.
I previously used Tinyproxy and that did the job, but it had no authentication whatsoever. ?I have basic authentication working on squid 3.5, where it asks for the username and password, but I believe this login is sent in clear text. ?I've did some research and found squid supports various better methods, such as kerberos, ntlm, smb, etc. ?However, while I'm able to install Linux and set up various things, I'm struggling with this authentication aspect. ?I have a suspicion some of these methods will not work well because they rely on other services (such as SMB) and may require opening more ports on my router, something I'm not crazy about.
Amos previously suggested client cert auth, but I'm not sure how to set this up. ?Are there any other secure auth methods that would work well over the Internet and are fairly simple to configure?
In any case, can anyone point me to an online tutorial somewhere (for a authentication newbie) that outlines how this is done?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170501/72dbf1e1/attachment.htm>

From eliezer at ngtech.co.il  Mon May  1 15:52:01 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Mon, 1 May 2017 18:52:01 +0300
Subject: [squid-users] Tutorial for better authentication than basic
In-Reply-To: <456739995.1458100.1493644706831@mail.yahoo.com>
References: <456739995.1458100.1493644706831.ref@mail.yahoo.com>
 <456739995.1458100.1493644706831@mail.yahoo.com>
Message-ID: <02b801d2c292$df68d950$9e3a8bf0$@ngtech.co.il>

And what about digest authentication?

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of j m
Sent: Monday, May 1, 2017 4:18 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Tutorial for better authentication than basic

I'm using Ubuntu 16.04 Server in the home and would like to set up a proxy server for use from over the Internet.  The main purpose for this is to easily access a few web-devices on my LAN without using VPN, and at times to route web traffic from a remote location through my home ISP.  I do not need nor want any caching or filtering.

I previously used Tinyproxy and that did the job, but it had no authentication whatsoever.  I have basic authentication working on squid 3.5, where it asks for the username and password, but I believe this login is sent in clear text.  I've did some research and found squid supports various better methods, such as kerberos, ntlm, smb, etc.  However, while I'm able to install Linux and set up various things, I'm struggling with this authentication aspect.  I have a suspicion some of these methods will not work well because they rely on other services (such as SMB) and may require opening more ports on my router, something I'm not crazy about.

Amos previously suggested client cert auth, but I'm not sure how to set this up.  Are there any other secure auth methods that would work well over the Internet and are fairly simple to configure?

In any case, can anyone point me to an online tutorial somewhere (for a authentication newbie) that outlines how this is done?



From acctforjunk at yahoo.com  Mon May  1 21:04:55 2017
From: acctforjunk at yahoo.com (j m)
Date: Mon, 1 May 2017 21:04:55 +0000 (UTC)
Subject: [squid-users] Tutorial for better authentication than basic
In-Reply-To: <02b801d2c292$df68d950$9e3a8bf0$@ngtech.co.il>
References: <456739995.1458100.1493644706831.ref@mail.yahoo.com>
 <456739995.1458100.1493644706831@mail.yahoo.com>
 <02b801d2c292$df68d950$9e3a8bf0$@ngtech.co.il>
Message-ID: <742538244.50351.1493672695826@mail.yahoo.com>

Wow, I didn't find that one. ?Not super secure, but better than clear text and I'm not too worried about someone sniffing my packets.

      From: Eliezer Croitoru <eliezer at ngtech.co.il>
 To: 'j m' <acctforjunk at yahoo.com>; squid-users at lists.squid-cache.org 
 Sent: Monday, May 1, 2017 3:30 PM
 Subject: RE: [squid-users] Tutorial for better authentication than basic
   
And what about digest authentication?

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of j m
Sent: Monday, May 1, 2017 4:18 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Tutorial for better authentication than basic

I'm using Ubuntu 16.04 Server in the home and would like to set up a proxy server for use from over the Internet.? The main purpose for this is to easily access a few web-devices on my LAN without using VPN, and at times to route web traffic from a remote location through my home ISP.? I do not need nor want any caching or filtering.

I previously used Tinyproxy and that did the job, but it had no authentication whatsoever.? I have basic authentication working on squid 3.5, where it asks for the username and password, but I believe this login is sent in clear text.? I've did some research and found squid supports various better methods, such as kerberos, ntlm, smb, etc.? However, while I'm able to install Linux and set up various things, I'm struggling with this authentication aspect.? I have a suspicion some of these methods will not work well because they rely on other services (such as SMB) and may require opening more ports on my router, something I'm not crazy about.

Amos previously suggested client cert auth, but I'm not sure how to set this up.? Are there any other secure auth methods that would work well over the Internet and are fairly simple to configure?

In any case, can anyone point me to an online tutorial somewhere (for a authentication newbie) that outlines how this is done?


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170501/28865f0b/attachment.htm>

From mlifshin at phantomdesign.com  Mon May  1 22:12:05 2017
From: mlifshin at phantomdesign.com (Masha Lifshin)
Date: Mon, 1 May 2017 15:12:05 -0700
Subject: [squid-users] Squid cannot parse Content-Length header value and
 closes connection before sending body?
Message-ID: <CA+8Eki0pWGHPxVUca+nfLgVRKrSnFv39KYvAZk0Ka0nuRyQ3Kg@mail.gmail.com>

Dear squid-users mailing list,

Thank you for reading this message and for all your hard work on this great
project.

I have inherited a Squid 3.5.2 install, with ecap, icap, and custom respmod
and reqmod icap services.  I am upgrading to Squid 4, adding ssl-bump, and
upgrading c-icap to 0.5.2.

When I run squid without icap (by editing it out of squid.conf), things
work fine and my custom client can load http and https pages.  However, for
http, when I turn on icap, squid shuts down the connection early, without
returning the body of the response.  It seems it cannot read the content
length header and that messes up both squid and icap.  Or is there some
disconnect about the 206 code from icap?

Does anyone know what I can do to further debug or fix this issue?
Debugging info below, (sanitized so you'll see dummy names like
'custom-info').  Let me know if there is anything else I can add.

Thank you again,
-Masha

------------------------------
------------------------------
squid.conf
------------------------------
------------------------------

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7   # RFC 4193 local private network range
acl localnet src fe80::/10  # RFC 4291 link-local (directly plugged)
machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 81          # http
acl Safe_ports port 800         # http
acl Safe_ports port 8000        # http
acl Safe_ports port 8080        # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl SSL method CONNECT
acl CONNECT method CONNECT

http_access allow manager to_localhost
http_access deny manager

http_access deny !Safe_ports

http_access deny to_localhost

icp_access deny all
htcp_access deny all

http_port 172.30.0.67:80 <http://172.30.0.67/> ssl-bump
cert=/some/path/etc/ca.pem generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB
http_port 172.30.0.67:443 ssl-bump cert=/some/path/etc/ca.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all

sslproxy_cert_error allow all

logformat custom %>a %[ui %{custom-info}>h [%tl] "%rm %ru HTTP/%rv" %>Hs
%<st

access_log stdio:/some/path/var/log/access.log custom
cache_store_log stdio:/some/path/var/log/store.log custom
log_mime_hdrs on

pid_filename /some/path/var/run/custom-squid.pid

coredump_dir /some/path/var/cache

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

request_header_access Proxy-Authenticate deny all
request_header_access Proxy-Authentication-Info deny all
request_header_access Proxy-Authorization deny all
request_header_access Proxy-Connection deny all
request_header_access Proxy-support deny all
request_header_access custom-client-version deny all
request_header_access custom-watermark deny all
request_header_access custom-info deny all
request_header_access more-custom-info deny all
request_header_access Via deny all
request_header_access X-Cache deny all
request_header_access X-Cache-Lookup deny all
request_header_access X-Forwarded-For deny all
reply_header_access X-XSS-Protection deny all
request_header_access Other allow all

cache_mgr cache_mgr at somewhere.com
mail_from custom-squid at somewhere.com
icap_enable on
icap_preview_enable on
icap_preview_size 1024
icap_default_options_ttl 60
icap_persistent_connections on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_header X-Client-Username
icap_client_username_encode off

ecap_enable on
loadable_modules /some/path/modules/libcustom_ecap.so
ecap_service custom_validate_req reqmod_precache ecap://
somewhere.com/ecap/services/validate routing=on bypass=off
ecap_service custom_validate_resp respmod_precache ecap://
somewhere.com/ecap/services/validate routing=on bypass=off

icap_service custom_req reqmod_precache routing=on icap://
127.0.0.1:1344/custom_req
icap_service custom_resp respmod_precache routing=on icap://
127.0.0.1:1344/custom_resp
forwarded_for delete

adaptation_service_set custom_req_set custom_validate_req custom_req
adaptation_service_set custom_resp_set custom_validate_resp custom_resp

adaptation_access custom_req_set allow all
adaptation_access custom_resp_set allow all

icap_service_failure_limit -1

debug_options ALL,3 44,0 23,0 40,0 73,0 93,3

------------------------------
------------------------------
Abridged cache.log
------------------------------
------------------------------

2017/04/28 08:11:46.958 kid1| 11,2| client_side.cc(1330) parseHttpRequest:
HTTP Client local=172.30.0.67:80 <http://172.30.0.67/> remote=
75.147.129.242:55706 FD 11 flags=1
2017/04/28 08:11:46.958 kid1| 11,2| client_side.cc(1334) parseHttpRequest:
HTTP Client REQUEST:
---------
GET http://example.com/ HTTP/1.1
Host: example.com
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Proxy-Connection: keep-alive
Accept-Language: en-us
custom-info: <snip>
Accept-Encoding: gzip, deflate
another-custom-info: true
more-custom-info: example.com
custom-client-version: iOS-1.0
User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 10_3 like Mac OS X)
AppleWebKit/603.1.30 (KHTML, like Gecko) Mobile/14E269 (140606214001632)
Upgrade-Insecure-Requests: 1
Connection: keep-alive


----------
2017/04/28 08:11:46.958 kid1| 33,3| client_side.cc(1366) parseHttpRequest:
complete request received. prefix_sz = 546, request-line-size=34,
mime-header-size=512, mime header block:
Host: example.com
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Proxy-Connection: keep-alive
Accept-Language: en-us
custom-info: <snip>
Accept-Encoding: gzip, deflate
another-custom-info: true
more-custom-info: example.com
custom-client-version: iOS-1.0
User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 10_3 like Mac OS X)
AppleWebKit/603.1.30 (KHTML, like Gecko) Mobile/14E269 (140606214001632)
Upgrade-Insecure-Requests: 1
Connection: keep-alive


----------
2017/04/28 08:11:46.958 kid1| 87,3| clientStream.cc(140)
clientStreamInsertHead: clientStreamInsertHead: Inserted node 0x230b5f8
with data 0x2309e58 after head
2017/04/28 08:11:46.958 kid1| 5,3| comm.cc(559) commSetConnTimeout: local=
172.30.0.67:80 <http://172.30.0.67/> remote=75.147.129.242:55706 FD 11
flags=1 timeout 86400
2017/04/28 08:11:46.958 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x23032c0
add request 1 0x2308df0*4
2017/04/28 08:11:46.958 kid1| 14,3| Address.cc(389) lookupHostIP: Given
Non-IP 'example.com': Name or service not known
2017/04/28 08:11:46.958 kid1| 33,3| client_side.cc(646)
clientSetKeepaliveFlag: http_ver = HTTP/1.1
2017/04/28 08:11:46.958 kid1| 33,3| client_side.cc(647)
clientSetKeepaliveFlag: method = GET
2017/04/28 08:11:46.958 kid1| 85,3| client_side_request.cc(142)
ClientRequestContext: ClientRequestContext constructed, this=0x1e94968
2017/04/28 08:11:46.958 kid1| 83,3| client_side_request.cc(1693)
doCallouts: Doing calloutContext->hostHeaderVerify()
2017/04/28 08:11:46.958 kid1| 85,3| client_side_request.cc(654)
hostHeaderVerify: validate host=example.com, port=0, portStr=NULL
2017/04/28 08:11:46.958 kid1| 85,3| client_side_request.cc(668)
hostHeaderVerify: validate skipped.
2017/04/28 08:11:46.958 kid1| 83,3| client_side_request.cc(1700)
doCallouts: Doing calloutContext->clientAccessCheck()
2017/04/28 08:11:46.958 kid1| 28,3| Checklist.cc(70) preCheck: 0x2310918
checking slow rules

<snip>

2017/04/28 08:11:47.294 kid1| 50,3| comm.cc(350) comm_openex: comm_openex:
Attempt open socket for: 0.0.0.0
2017/04/28 08:11:47.294 kid1| 50,3| comm.cc(393) comm_openex: comm_openex:
Opened socket local=0.0.0.0 remote=[::] FD 15 flags=1 : family=2, type=1,
protocol=6
2017/04/28 08:11:47.294 kid1| 51,3| fd.cc(199) fd_open: fd_open() FD 15
example.com
2017/04/28 08:11:47.294 kid1| 5,3| ConnOpener.cc(289) createFd:
local=0.0.0.0 remote=93.184.216.34:80 <http://93.184.216.34/> flags=1 will
timeout in 60
2017/04/28 08:11:47.295 kid1| 17,3| AsyncCall.cc(93) ScheduleCall:
ConnOpener.cc(137) will call fwdConnectDoneWrapper(local=172.30.0.67:18160
 remote=93.184.216.34:80 <http://93.184.216.34/> FD 15 flags=1,
data=0x231bfb8) [call127]
2017/04/28 08:11:47.295 kid1| 17,3| AsyncCallQueue.cc(55) fireNext:
entering fwdConnectDoneWrapper(local=172.30.0.67:18160 remote=
93.184.216.34:80 <http://93.184.216.34/> FD 15 flags=1, data=0x231bfb8)
2017/04/28 08:11:47.295 kid1| 17,3| AsyncCall.cc(38) make: make call
fwdConnectDoneWrapper [call127]
2017/04/28 08:11:47.295 kid1| 17,3| FwdState.cc(681) connectDone: local=
172.30.0.67:18160 remote=93.184.216.34:80 <http://93.184.216.34/> FD 15
flags=1: 'http://example.com/'
2017/04/28 08:11:47.295 kid1| 17,3| FwdState.cc(929) dispatch: local=
172.30.0.67:80 <http://172.30.0.67/> remote=75.147.129.242:55706 FD 11
flags=1: Fetching GET http://example.com/
2017/04/28 08:11:47.295 kid1| 11,3| http.cc(2330) httpStart: GET
http://example.com/
2017/04/28 08:11:47.295 kid1| 20,3| store.cc(457) lock: Client locked key
3400000000000000132A000001000000 e:=p2DIWV/0x231f010*3
2017/04/28 08:11:47.295 kid1| 17,3| AsyncCallQueue.cc(57) fireNext: leaving
fwdConnectDoneWrapper(local=172.30.0.67:18160 remote=93.184.216.34:80
<http://93.184.216.34/> FD 15 flags=1, data=0x231bfb8)
2017/04/28 08:11:47.295 kid1| 5,3| comm.cc(559) commSetConnTimeout: local=
172.30.0.67:18160 remote=93.184.216.34:80 <http://93.184.216.34/> FD 15
flags=1 timeout 86400
2017/04/28 08:11:47.295 kid1| 22,3| refresh.cc(646) getMaxAge: getMaxAge: '
http://example.com/'
2017/04/28 08:11:47.295 kid1| 28,3| Checklist.cc(70) preCheck:
0x7ffdcaef6840 checking fast rules
2017/04/28 08:11:47.295 kid1| 28,3| Ip.cc(540) match: aclIpMatchIp: '
75.147.129.242:55706' found
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked: all = 1
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked:
http_header_access custom-info#1 = 1
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked:
http_header_access custom-info = 1
2017/04/28 08:11:47.295 kid1| 28,3| Checklist.cc(63) markFinished:
0x7ffdcaef6840 answer DENIED for match
2017/04/28 08:11:47.295 kid1| 28,3| Checklist.cc(70) preCheck:
0x7ffdcaef6840 checking fast rules
2017/04/28 08:11:47.295 kid1| 28,3| Ip.cc(540) match: aclIpMatchIp: '
75.147.129.242:55706' found
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked: all = 1
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked:
http_header_access Other#1 = 1
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked:
http_header_access Other = 1
2017/04/28 08:11:47.295 kid1| 28,3| Checklist.cc(63) markFinished:
0x7ffdcaef6840 answer ALLOWED for match
2017/04/28 08:11:47.295 kid1| 28,3| Checklist.cc(70) preCheck:
0x7ffdcaef6840 checking fast rules
2017/04/28 08:11:47.295 kid1| 28,3| Ip.cc(540) match: aclIpMatchIp: '
75.147.129.242:55706' found
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked: all = 1
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked:
http_header_access more-custom-info#1 = 1
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked:
http_header_access more-custom-info = 1
2017/04/28 08:11:47.295 kid1| 28,3| Checklist.cc(63) markFinished:
0x7ffdcaef6840 answer DENIED for match
2017/04/28 08:11:47.295 kid1| 28,3| Checklist.cc(70) preCheck:
0x7ffdcaef6840 checking fast rules
2017/04/28 08:11:47.295 kid1| 28,3| Ip.cc(540) match: aclIpMatchIp: '
75.147.129.242:55706' found
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked: all = 1
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked:
http_header_access custom-client-version#1 = 1
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked:
http_header_access custom-client-version = 1
2017/04/28 08:11:47.295 kid1| 28,3| Checklist.cc(63) markFinished:
0x7ffdcaef6840 answer DENIED for match
2017/04/28 08:11:47.295 kid1| 28,3| Checklist.cc(70) preCheck:
0x7ffdcaef6840 checking fast rules
2017/04/28 08:11:47.295 kid1| 28,3| Ip.cc(540) match: aclIpMatchIp: '
75.147.129.242:55706' found
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked: all = 1
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked:
http_header_access Other#1 = 1
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked:
http_header_access Other = 1
2017/04/28 08:11:47.295 kid1| 28,3| Checklist.cc(63) markFinished:
0x7ffdcaef6840 answer ALLOWED for match
2017/04/28 08:11:47.295 kid1| 28,3| Checklist.cc(70) preCheck:
0x7ffdcaef6840 checking fast rules
2017/04/28 08:11:47.295 kid1| 28,3| Ip.cc(540) match: aclIpMatchIp: '
75.147.129.242:55706' found
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked: all = 1
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked:
http_header_access Via#1 = 1
2017/04/28 08:11:47.295 kid1| 28,3| Acl.cc(290) matches: checked:
http_header_access Via = 1
2017/04/28 08:11:47.295 kid1| 28,3| Checklist.cc(63) markFinished:
0x7ffdcaef6840 answer DENIED for match
2017/04/28 08:11:47.295 kid1| 11,2| http.cc(2286) sendRequest: HTTP Server
local=172.30.0.67:18160 remote=93.184.216.34:80 <http://93.184.216.34/> FD
15 flags=1
2017/04/28 08:11:47.295 kid1| 11,2| http.cc(2287) sendRequest: HTTP Server
REQUEST:
---------
GET / HTTP/1.1
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-us
Accept-Encoding: gzip, deflate
another-custom-info: true
User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 10_3 like Mac OS X)
AppleWebKit/603.1.30 (KHTML, like Gecko) Mobile/14E269 (140606214001632)
Upgrade-Insecure-Requests: 1
Host: example.com
Cache-Control: max-age=259200
Connection: keep-alive


----------
2017/04/28 08:11:47.295 kid1| 5,3| IoCallback.cc(116) finish: called for
local=172.30.0.67:18160 remote=93.184.216.34:80 <http://93.184.216.34/> FD
15 flags=1 (0, 0)
2017/04/28 08:11:47.295 kid1| 5,3| comm.cc(559) commSetConnTimeout: local=
172.30.0.67:18160 remote=93.184.216.34:80 <http://93.184.216.34/> FD 15
flags=1 timeout 900
2017/04/28 08:11:47.297 kid1| 5,3| IoCallback.cc(116) finish: called for
local=172.30.0.67:18160 remote=93.184.216.34:80 <http://93.184.216.34/> FD
15 flags=1 (0, 0)
2017/04/28 08:11:47.297 kid1| 5,3| Read.cc(92) ReadNow: local=
172.30.0.67:18160 remote=93.184.216.34:80 <http://93.184.216.34/> FD 15
flags=1, size 65536, retval 956, errno 0
2017/04/28 08:11:47.297 kid1| ctx: enter level  0: 'http://example.com/'
2017/04/28 08:11:47.297 kid1| 11,3| http.cc(692) processReplyHeader:
processReplyHeader: key '3400000000000000132A000001000000'
2017/04/28 08:11:47.297 kid1| 11,2| http.cc(743) processReplyHeader: HTTP
Server local=172.30.0.67:18160 remote=93.184.216.34:80
<http://93.184.216.34/> FD 15 flags=1
2017/04/28 08:11:47.297 kid1| 11,2| http.cc(747) processReplyHeader: HTTP
Server RESPONSE:
---------
HTTP/1.1 200 OK
Content-Encoding: gzip
Accept-Ranges: bytes
Cache-Control: max-age=604800
Content-Type: text/html
Date: Fri, 28 Apr 2017 08:09:01 GMT
Etag: "359670651+gzip"
Expires: Fri, 05 May 2017 08:09:01 GMT
Last-Modified: Fri, 09 Aug 2013 23:54:35 GMT
Server: ECS (iad/182A)
Vary: Accept-Encoding
X-Cache: HIT
Content-Length: 606

----------
2017/04/28 08:11:47.297 kid1| 55,2| HttpHeader.cc(1483)
httpHeaderNoteParsedEntry: cannot parse hdr field: 'Content-Length: 606'
2017/04/28 08:11:47.297 kid1| 55,2| HttpHeader.cc(1483)
httpHeaderNoteParsedEntry: cannot parse hdr field: 'Content-Length: 606'
2017/04/28 08:11:47.297 kid1| ctx: exit level  0
2017/04/28 08:11:47.297 kid1| 28,3| Checklist.cc(70) preCheck: 0x2310918
checking slow rules
2017/04/28 08:11:47.297 kid1| 28,3| Ip.cc(540) match: aclIpMatchIp: '
75.147.129.242:55706' found
2017/04/28 08:11:47.297 kid1| 28,3| Acl.cc(290) matches: checked: all = 1
2017/04/28 08:11:47.297 kid1| 28,3| Acl.cc(290) matches: checked:
adaptation_access#1 = 1
2017/04/28 08:11:47.297 kid1| 28,3| Acl.cc(290) matches: checked:
adaptation_access = 1
2017/04/28 08:11:47.298 kid1| 28,3| Checklist.cc(63) markFinished:
0x2310918 answer ALLOWED for match
2017/04/28 08:11:47.298 kid1| 28,3| Checklist.cc(163) checkCallback:
ACLChecklist::checkCallback: 0x2310918 answer=ALLOWED
2017/04/28 08:11:47.298 kid1| 93,3| AccessCheck.cc(196) callBack:
0x1e515e0*2
2017/04/28 08:11:47.298 kid1| 11,3| http.cc(1090) persistentConnStatus:
local=172.30.0.67:18160 remote=93.184.216.34:80 <http://93.184.216.34/> FD
15 flags=1 eof=0
2017/04/28 08:11:47.298 kid1| 5,3| comm.cc(585) commUnsetConnTimeout:
Remove timeout for local=172.30.0.67:18160 remote=93.184.216.34:80
<http://93.184.216.34/> FD 15 flags=1
2017/04/28 08:11:47.298 kid1| 5,3| comm.cc(559) commSetConnTimeout: local=
172.30.0.67:18160 remote=93.184.216.34:80 <http://93.184.216.34/> FD 15
flags=1 timeout -1
2017/04/28 08:11:47.298 kid1| 17,3| FwdState.cc(455) unregister:
http://example.com/
2017/04/28 08:11:47.298 kid1| 48,3| pconn.cc(425) push: new IdleConnList
for {93.184.216.34:80/example.com <http://93.184.216.34/example.com>}
2017/04/28 08:11:47.298 kid1| 5,3| comm.cc(559) commSetConnTimeout: local=
172.30.0.67:18160 remote=93.184.216.34:80 <http://93.184.216.34/> FD 15
flags=1 timeout 60
2017/04/28 08:11:47.298 kid1| 48,3| pconn.cc(437) push: pushed local=
172.30.0.67:18160 remote=93.184.216.34:80 <http://93.184.216.34/> FD 15
flags=1 for 93.184.216.34:80/example.com <http://93.184.216.34/example.com>
2017/04/28 08:11:47.298 kid1| 93,3| Iterator.cc(193) handleAdaptationError:
trying a replacement service
2017/04/28 08:11:47.298 kid1| 93,3| Xaction.cc(101) Xaction:
Adaptation::Icap::ModXact constructed, this=0x231b938 [icapxjob22]
2017/04/28 08:11:47.298 kid1| 93,3| Xaction.cc(101) Xaction:
Adaptation::Icap::OptXact constructed, this=0x231cf78 [icapxjob24]
2017/04/28 08:11:47.298 kid1| 93,3| ServiceRep.cc(140) getConnection: got
connection:
2017/04/28 08:11:47.298 kid1| 93,3| Xaction.cc(188) openConnection:
Adaptation::Icap::OptXact opens connection to 127.0.0.1:1344
2017/04/28 08:11:47.298 kid1| 93,3| AsyncCall.cc(26) AsyncCall: The
AsyncCall Adaptation::Icap::Xaction::noteCommConnected constructed,
this=0x232bd60 [call156]
2017/04/28 08:11:47.298 kid1| 50,3| comm.cc(350) comm_openex: comm_openex:
Attempt open socket for: 0.0.0.0

<snip>

2017/04/28 08:11:47.576 kid1| 93,3| AsyncCall.cc(93) ScheduleCall:
IoCallback.cc(135) will call Adaptation::Icap::Xaction::noteCommRead(local=
127.0.0.1:16810 remote=127.0.0.1:1344 FD 17 flags=1, data=0x231b938)
[call196]
2017/04/28 08:11:47.576 kid1| 93,3| AsyncCallQueue.cc(55) fireNext:
entering Adaptation::Icap::Xaction::noteCommRead(local=127.0.0.1:16810
 remote=127.0.0.1:1344 FD 17 flags=1, data=0x231b938)
2017/04/28 08:11:47.576 kid1| 93,3| AsyncCall.cc(38) make: make call
Adaptation::Icap::Xaction::noteCommRead [call196]
2017/04/28 08:11:47.576 kid1| 93,3| AsyncJob.cc(123) callStart:
Adaptation::Icap::ModXact status in: [FD 17r;RrBG/wP(ieof) job26]
2017/04/28 08:11:47.576 kid1| 5,3| Read.cc(92) ReadNow: local=
127.0.0.1:16810 remote=127.0.0.1:1344 FD 17 flags=1, size 65535, retval
615, errno 0
2017/04/28 08:11:47.576 kid1| 5,3| comm.cc(585) commUnsetConnTimeout:
Remove timeout for local=127.0.0.1:16810 remote=127.0.0.1:1344 FD 17 flags=1
2017/04/28 08:11:47.576 kid1| 5,3| comm.cc(559) commSetConnTimeout: local=
127.0.0.1:16810 remote=127.0.0.1:1344 FD 17 flags=1 timeout -1
2017/04/28 08:11:47.576 kid1| 93,3| Xaction.cc(486) noteCommRead: read 615
bytes
2017/04/28 08:11:47.576 kid1| 55,2| HttpHeader.cc(1483)
httpHeaderNoteParsedEntry: cannot parse hdr field: 'Content-Length: 606'
2017/04/28 08:11:47.576 kid1| 55,2| HttpHeader.cc(1483)
httpHeaderNoteParsedEntry: cannot parse hdr field: 'Content-Length: 606'
2017/04/28 08:11:47.576 kid1| 91,2| BodyPipe.cc(489) ~BodyPipeCheckout:
Warning: cannot undo BodyPipeCheckout
2017/04/28 08:11:47.576 kid1| 93,3| ../../../src/base/AsyncJobCalls.h(177)
dial: Adaptation::Icap::Xaction::noteCommRead threw exception: garbage
instead of CRLF line terminator
2017/04/28 08:11:47.576 kid1| 93,3| Xaction.cc(591) setOutcome: Warning:
reseting outcome: from ICAP_MOD to ICAP_ERR_OTHER
2017/04/28 08:11:47.576 kid1| 93,2| AsyncJob.cc(129) callException: garbage
instead of CRLF line terminator
2017/04/28 08:11:47.576 kid1| 93,3| ServiceRep.cc(155) putConnection:
RST-closing  [FD 17;rp(2)6/RwP(ieof)S job26]
2017/04/28 08:11:47.576 kid1| 5,3| comm.cc(865) _comm_close: comm_close:
start closing FD 17
2017/04/28 08:11:47.576 kid1| 5,3| comm.cc(546) commUnsetFdTimeout: Remove
timeout for FD 17
2017/04/28 08:11:47.576 kid1| 93,3| Xaction.cc(112) ~Xaction:
Adaptation::Icap::ModXact destructed, this=0x231b938 [icapxjob26]
2017/04/28 08:11:47.576 kid1| 93,3| AsyncCallQueue.cc(57) fireNext: leaving
Adaptation::Icap::Xaction::noteCommRead(local=127.0.0.1:16810 remote=
127.0.0.1:1344 flags=1, data=0x231b938)
2017/04/28 08:11:47.576 kid1| 51,3| fd.cc(94) fd_close: fd_close FD 17
127.0.0.1
2017/04/28 08:11:47.576 kid1| 20,3| store.cc(1853) replaceHttpReply:
StoreEntry::replaceHttpReply: http://example.com/
2017/04/28 08:11:47.576 kid1| ctx: enter level  0: 'http://example.com/'
2017/04/28 08:11:47.576 kid1| 11,3| http.cc(934) haveParsedReplyHeaders:
HTTP CODE: 200
2017/04/28 08:11:47.576 kid1| 20,3| Controller.cc(306) find:
5C9109034C1D089FB6D92F7258B2F5C3

<snip>

2017/04/28 08:11:47.576 kid1| 20,3| store_key_md5.cc(133)
storeKeyPublicByRequestMethod: updating public key by vary headers:
accept-encoding="gzip,%20deflate" for: http://example.com/
2017/04/28 08:11:47.577 kid1| 20,3| store.cc(421) hashInsert:
StoreEntry::hashInsert: Inserting Entry e:=p2DV/0x231f010*3 key
'6E5F80FC98AEE5F58F47899D580B6430'
2017/04/28 08:11:47.577 kid1| ctx: exit level  0
2017/04/28 08:11:47.577 kid1| 90,3| store_client.cc(729) invokeHandlers:
InvokeHandlers: 6E5F80FC98AEE5F58F47899D580B6430
2017/04/28 08:11:47.577 kid1| 90,3| store_client.cc(735) invokeHandlers:
StoreEntry::InvokeHandlers: checking client #0
2017/04/28 08:11:47.577 kid1| 90,3| store_client.cc(295) storeClientCopy2:
storeClientCopy2: 6E5F80FC98AEE5F58F47899D580B6430
2017/04/28 08:11:47.577 kid1| 90,3| store_client.cc(429) scheduleMemRead:
store_client::doCopy: Copying normal from memory
2017/04/28 08:11:47.577 kid1| 55,2| HttpHeader.cc(1483)
httpHeaderNoteParsedEntry: cannot parse hdr field: 'Content-Length: 606'
2017/04/28 08:11:47.577 kid1| 55,2| HttpHeader.cc(1483)
httpHeaderNoteParsedEntry: cannot parse hdr field: 'Content-Length: 606'
2017/04/28 08:11:47.577 kid1| 88,2| client_side_reply.cc(2084)
processReplyAccessResult: The reply for GET http://example.com/ is ALLOWED,
because it matched all
2017/04/28 08:11:47.577 kid1| 20,3| store.cc(457) lock:
ClientHttpRequest::loggingEntry locked key 6E5F80FC98AEE5F58F47899D580B6430
e:=p2DV/0x231f010*4
2017/04/28 08:11:47.577 kid1| 88,3| client_side_reply.cc(2122)
processReplyAccessResult: clientReplyContext::sendMoreData: Appending 0
bytes after 440 bytes of headers
2017/04/28 08:11:47.577 kid1| 87,3| clientStream.cc(158)
clientStreamCallback: clientStreamCallback: Calling 1 with cbdata 0x2309e58
from node 0x2307b28
2017/04/28 08:11:47.577 kid1| 33,3| Pipeline.cc(35) front: Pipeline
0x23032c0 front 0x2308df0*3
2017/04/28 08:11:47.577 kid1| 33,3| Pipeline.cc(35) front: Pipeline
0x23032c0 front 0x2308df0*3
2017/04/28 08:11:47.577 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP
Client local=172.30.0.67:80 <http://172.30.0.67/> remote=
75.147.129.242:55706 FD 11 flags=1
2017/04/28 08:11:47.577 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP
Client REPLY:
---------
HTTP/1.1 200 OK
Content-Encoding: gzip
Accept-Ranges: bytes
Cache-Control: max-age=604800
Content-Type: text/html
Date: Fri, 28 Apr 2017 08:09:01 GMT
ETag: "359670651+gzip"
Expires: Fri, 05 May 2017 08:09:01 GMT
Last-Modified: Fri, 09 Aug 2013 23:54:35 GMT
Server: ECS (iad/182A)
Vary: Accept-Encoding
X-Cache: HIT
Content-Length: 606
still-more-custom-info: ignore-value
X-Cache: MISS from ip-172-30-0-67.ec2.internal
X-Cache-Lookup: MISS from ip-172-30-0-67.ec2.internal:80
Via: ICAP/1.0 localhost (C-ICAP/0.5.2 Custom Response Module ), 1.1
ip-172-30-0-67.ec2.internal (squid/4.0.17)
Connection: keep-alive


----------
2017/04/28 08:11:47.577 kid1| 20,3| store.cc(1081) lengthWentBad: because
body adaptation aborted: e:=p2DV/0x231f010*4
2017/04/28 08:11:47.577 kid1| 20,3| store.cc(472) setReleaseFlag:
StoreEntry::setReleaseFlag: '6E5F80FC98AEE5F58F47899D580B6430'
2017/04/28 08:11:47.577 kid1| 20,3| store.cc(421) hashInsert:
StoreEntry::hashInsert: Inserting Entry e:=p2XDIVL/0x231f010*4 key
'3600000000000000132A000001000000'
2017/04/28 08:11:47.577 kid1| 17,3| FwdState.cc(481) complete:
http://example.com/
status 200
2017/04/28 08:11:47.577 kid1| 17,3| FwdState.cc(1067) reforward:
http://example.com/?
2017/04/28 08:11:47.577 kid1| 17,3| FwdState.cc(1070) reforward: No,
ENTRY_FWD_HDR_WAIT isn't set
2017/04/28 08:11:47.577 kid1| 17,3| FwdState.cc(505) complete: server (FD
closed) not re-forwarding status 200
2017/04/28 08:11:47.577 kid1| 20,3| store.cc(1089) complete: storeComplete:
'3600000000000000132A000001000000'
2017/04/28 08:11:47.577 kid1| 20,2| store.cc(990) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2017/04/28 08:11:47.577 kid1| 90,3| store_client.cc(729) invokeHandlers:
InvokeHandlers: 3600000000000000132A000001000000
2017/04/28 08:11:47.577 kid1| 90,3| store_client.cc(735) invokeHandlers:
StoreEntry::InvokeHandlers: checking client #0
2017/04/28 08:11:47.577 kid1| 90,3| store_client.cc(755)
storePendingNClients: storePendingNClients: returning 1
2017/04/28 08:11:47.577 kid1| 20,3| store.cc(494) unlock: Client unlocking
key 3600000000000000132A000001000000 e:=sp2XDIVL/0x231f010*4
2017/04/28 08:11:47.577 kid1| 17,3| FwdState.cc(274) ~FwdState: FwdState
destructor start
2017/04/28 08:11:47.577 kid1| 20,3| store.cc(494) unlock: FwdState
unlocking key 3600000000000000132A000001000000 e:=sp2XDIVL/0x231f010*3
2017/04/28 08:11:47.577 kid1| 17,3| AsyncCall.cc(56) cancel: will not call
fwdConnectDoneWrapper [call127] because FwdState destructed
2017/04/28 08:11:47.577 kid1| 17,3| FwdState.cc(301) ~FwdState: FwdState
destructed, this=0x231bfb8
2017/04/28 08:11:47.577 kid1| 5,3| IoCallback.cc(116) finish: called for
local=172.30.0.67:80 <http://172.30.0.67/> remote=75.147.129.242:55706 FD
11 flags=1 (0, 0)
2017/04/28 08:11:47.577 kid1| 33,3| Pipeline.cc(35) front: Pipeline
0x23032c0 front 0x2308df0*2
2017/04/28 08:11:47.577 kid1| 88,3| client_side_reply.cc(1172)
storeOKTransferDone: storeOKTransferDone  out.offset=0 objectLen()=440
headers_sz=440
2017/04/28 08:11:47.577 kid1| 5,3| comm.cc(865) _comm_close: comm_close:
start closing FD 11
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170501/8fe5a98f/attachment.htm>

From rousskov at measurement-factory.com  Mon May  1 23:37:46 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 1 May 2017 17:37:46 -0600
Subject: [squid-users] Squid cannot parse Content-Length header value
 and closes connection before sending body?
In-Reply-To: <CA+8Eki0pWGHPxVUca+nfLgVRKrSnFv39KYvAZk0Ka0nuRyQ3Kg@mail.gmail.com>
References: <CA+8Eki0pWGHPxVUca+nfLgVRKrSnFv39KYvAZk0Ka0nuRyQ3Kg@mail.gmail.com>
Message-ID: <d3a1bf7c-2dea-5f2a-507f-9c458079887a@measurement-factory.com>

On 05/01/2017 04:12 PM, Masha Lifshin wrote:

> when I turn on icap, squid shuts down the connection early,
> without returning the body of the response.  It seems it cannot read the
> content length header and that messes up both squid and icap.

> 2017/04/28 08:11:47.297 kid1| 55,2| HttpHeader.cc(1483)
> httpHeaderNoteParsedEntry: cannot parse hdr field: 'Content-Length: 606'


These "cannot parse hdr field" lines is a sign of a minor accounting bug
(fixed in the latest Squid; v5 r15019). Do not worry about it -- it does
not affect Squid behavior beyond header statistics reporting.


> 2017/04/28 08:11:47.576 kid1| 93,3|
> Adaptation::Icap::Xaction::noteCommRead threw exception: garbage
> instead of CRLF line terminator

This exception can explain your symptoms: Squid failed to parse some
portion of the ICAP response from your ICAP server. This is either a
Squid bug or an ICAP server bug.

Please make sure your Squid v4 contains a fix for bug #4551:

    http://bugs.squid-cache.org/show_bug.cgi?id=4551

Squid v4.0.13 and newer should have that fix. If your Squid is v4.0.17
then bug #4551 should be fixed, but perhaps there is another bug OR the
ICAP server itself is misbehaving.


>  Or is there some disconnect about the 206 code from icap?  

The posted logs do not show enough info for me to pinpoint the problem.
Try replacing "93,3" with "93,9 74,9" in your debug_options. Is that
enough to get the ICAP server response logged? (I do not remember the
minimum set of debug_options necessary to accomplish that.) If you post
a new log, please attach (or post a link to) it instead of quoting it in
the email because email formatting often screws up important details.

Alternatively, post a pcap-format capture of TCP packets between Squid
and ICAP server (but be careful with what you share on the list).


Cheers,

Alex.



From squid3 at treenet.co.nz  Tue May  2 00:06:28 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 2 May 2017 12:06:28 +1200
Subject: [squid-users] Tutorial for better authentication than basic
In-Reply-To: <742538244.50351.1493672695826@mail.yahoo.com>
References: <456739995.1458100.1493644706831.ref@mail.yahoo.com>
 <456739995.1458100.1493644706831@mail.yahoo.com>
 <02b801d2c292$df68d950$9e3a8bf0$@ngtech.co.il>
 <742538244.50351.1493672695826@mail.yahoo.com>
Message-ID: <c0440ac0-a9a7-8eec-0359-73ffc4fe5af7@treenet.co.nz>

On 02/05/17 09:04, j m wrote:
> Wow, I didn't find that one.  Not super secure, but better than clear 
> text and I'm not too worried about someone sniffing my packets.
>

The security level with Digest depends on the nonce lifetime and reuse 
counter, both of which you can tune to your liking. The shorter those 
are the more secure, up to the point where it is a purely one-time 
token. That said, some clients (most often browsers) have big trouble 
managing nonces in correct order and with dozens of connections open to 
the proxy - and then there are Squid bugs. So tuning those is not as 
easy as it should be.

NTLM does not work over the Internet. Kerberos might, but not very well. 
They are connection-oriented authentication schemes designed for use in 
LAN environments. So for your described situation they are not useful 
even if you were willing to open the ports.

Amos



From eliezer at ngtech.co.il  Tue May  2 11:17:47 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Tue, 2 May 2017 14:17:47 +0300
Subject: [squid-users] Tutorial for better authentication than basic
In-Reply-To: <742538244.50351.1493672695826@mail.yahoo.com>
References: <456739995.1458100.1493644706831.ref@mail.yahoo.com>
 <456739995.1458100.1493644706831@mail.yahoo.com>
 <02b801d2c292$df68d950$9e3a8bf0$@ngtech.co.il>
 <742538244.50351.1493672695826@mail.yahoo.com>
Message-ID: <032b01d2c335$ba5e4930$2f1adb90$@ngtech.co.il>

There is another option if you don't have any issue to allow a certain public IP address access to your network you can use some kind of portal which will allow based on a SSL(even with self signed certificate) the "session" access to the service.

If it sounds fine let me know and I will prepare and example.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of j m
Sent: Tuesday, May 2, 2017 12:05 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Tutorial for better authentication than basic

Wow, I didn't find that one.  Not super secure, but better than clear text and I'm not too worried about someone sniffing my packets.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
To: 'j m' <mailto:acctforjunk at yahoo.com>; mailto:squid-users at lists.squid-cache.org 
Sent: Monday, May 1, 2017 3:30 PM
Subject: RE: [squid-users] Tutorial for better authentication than basic

And what about digest authentication?

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il

From: squid-users [mailto:mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of j m
Sent: Monday, May 1, 2017 4:18 PM
To: mailto:squid-users at lists.squid-cache.org
Subject: [squid-users] Tutorial for better authentication than basic

I'm using Ubuntu 16.04 Server in the home and would like to set up a proxy server for use from over the Internet.  The main purpose for this is to easily access a few web-devices on my LAN without using VPN, and at times to route web traffic from a remote location through my home ISP.  I do not need nor want any caching or filtering.

I previously used Tinyproxy and that did the job, but it had no authentication whatsoever.  I have basic authentication working on squid 3.5, where it asks for the username and password, but I believe this login is sent in clear text.  I've did some research and found squid supports various better methods, such as kerberos, ntlm, smb, etc.  However, while I'm able to install Linux and set up various things, I'm struggling with this authentication aspect.  I have a suspicion some of these methods will not work well because they rely on other services (such as SMB) and may require opening more ports on my router, something I'm not crazy about.

Amos previously suggested client cert auth, but I'm not sure how to set this up.  Are there any other secure auth methods that would work well over the Internet and are fairly simple to configure?

In any case, can anyone point me to an online tutorial somewhere (for a authentication newbie) that outlines how this is done?




From acctforjunk at yahoo.com  Tue May  2 11:20:52 2017
From: acctforjunk at yahoo.com (j m)
Date: Tue, 2 May 2017 11:20:52 +0000 (UTC)
Subject: [squid-users] Tutorial for better authentication than basic
In-Reply-To: <c0440ac0-a9a7-8eec-0359-73ffc4fe5af7@treenet.co.nz>
References: <456739995.1458100.1493644706831.ref@mail.yahoo.com>
 <456739995.1458100.1493644706831@mail.yahoo.com>
 <02b801d2c292$df68d950$9e3a8bf0$@ngtech.co.il>
 <742538244.50351.1493672695826@mail.yahoo.com>
 <c0440ac0-a9a7-8eec-0359-73ffc4fe5af7@treenet.co.nz>
Message-ID: <1971334974.487527.1493724052864@mail.yahoo.com>

Also good information to know. ?I'll check into this. ?
I'm still finding my way through this and the next step is getting SSH to work over it....no luck with that yet.

      From: Amos Jeffries <squid3 at treenet.co.nz>
 To: squid-users at lists.squid-cache.org 
 Sent: Monday, May 1, 2017 7:06 PM
 Subject: Re: [squid-users] Tutorial for better authentication than basic
   
On 02/05/17 09:04, j m wrote:
> Wow, I didn't find that one.? Not super secure, but better than clear 
> text and I'm not too worried about someone sniffing my packets.
>

The security level with Digest depends on the nonce lifetime and reuse 
counter, both of which you can tune to your liking. The shorter those 
are the more secure, up to the point where it is a purely one-time 
token. That said, some clients (most often browsers) have big trouble 
managing nonces in correct order and with dozens of connections open to 
the proxy - and then there are Squid bugs. So tuning those is not as 
easy as it should be.

NTLM does not work over the Internet. Kerberos might, but not very well. 
They are connection-oriented authentication schemes designed for use in 
LAN environments. So for your described situation they are not useful 
even if you were willing to open the ports.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170502/6cda908c/attachment.htm>

From Ralf.Hildebrandt at charite.de  Tue May  2 11:59:38 2017
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 2 May 2017 13:59:38 +0200
Subject: [squid-users] URL sometimes reurns empty response
Message-ID: <20170502115938.gvqtqxshocmy6epy@charite.de>

In some cases, our proxies (got 4 of them) return a empty result when
querying "http://www.msftconnecttest.com/ncsi.txt" (whcih is used by
Microsoft Brwosers to check if they're online).

I'm using this incantation to check the URL:

watch -d curl --silent -v -x "http://proxy-cvk-1.charite.de:8080" http://www.msftconnecttest.com/ncsi.txt

Usually, the URL should just return "Microsoft NCSI".
In some cases I get an empyt response, but curl reports:

< Age: 5
< X-Cache: HIT from proxy-cvk-1
< Via: 1.1 proxy-cvk-1 (squid/5.0.0-20170421-r15126)
< Connection: keep-alive
<
* Excess found in a non pipelined read: excess = 14 url = /ncsi.txt (zero-length body)
* Curl_http_done: called premature == 0
* Connection #0 to host (nil) left intact

As you can see, something is producing an excess of 14 Bytes (which
coincides with the 14 bytes length of "Microsoft NCSI").

< Cache-Control: max-age=30,must-revalidate

Immediatly after revalidating, the problem occurs.

I tried this with 5.0.0-20170421-r15126 as well as 4.0.19 - same result.

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
https://www.charite.de             Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From yvoinov at gmail.com  Tue May  2 12:05:31 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 2 May 2017 18:05:31 +0600
Subject: [squid-users] URL sometimes reurns empty response
In-Reply-To: <20170502115938.gvqtqxshocmy6epy@charite.de>
References: <20170502115938.gvqtqxshocmy6epy@charite.de>
Message-ID: <241b3eef-50aa-52c3-e498-5724d60a9e8a@gmail.com>

If you add this URL to cache deny rule - problem still exists?


02.05.2017 17:59, Ralf Hildebrandt ?????:
> In some cases, our proxies (got 4 of them) return a empty result when
> querying "http://www.msftconnecttest.com/ncsi.txt" (whcih is used by
> Microsoft Brwosers to check if they're online).
>
> I'm using this incantation to check the URL:
>
> watch -d curl --silent -v -x "http://proxy-cvk-1.charite.de:8080" http://www.msftconnecttest.com/ncsi.txt
>
> Usually, the URL should just return "Microsoft NCSI".
> In some cases I get an empyt response, but curl reports:
>
> < Age: 5
> < X-Cache: HIT from proxy-cvk-1
> < Via: 1.1 proxy-cvk-1 (squid/5.0.0-20170421-r15126)
> < Connection: keep-alive
> <
> * Excess found in a non pipelined read: excess = 14 url = /ncsi.txt (zero-length body)
> * Curl_http_done: called premature == 0
> * Connection #0 to host (nil) left intact
>
> As you can see, something is producing an excess of 14 Bytes (which
> coincides with the 14 bytes length of "Microsoft NCSI").
>
> < Cache-Control: max-age=30,must-revalidate
>
> Immediatly after revalidating, the problem occurs.
>
> I tried this with 5.0.0-20170421-r15126 as well as 4.0.19 - same result.
>

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170502/f582c03a/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170502/f582c03a/attachment.sig>

From acctforjunk at yahoo.com  Tue May  2 12:40:36 2017
From: acctforjunk at yahoo.com (j m)
Date: Tue, 2 May 2017 12:40:36 +0000 (UTC)
Subject: [squid-users] Tutorial for better authentication than basic
In-Reply-To: <c0440ac0-a9a7-8eec-0359-73ffc4fe5af7@treenet.co.nz>
References: <456739995.1458100.1493644706831.ref@mail.yahoo.com>
 <456739995.1458100.1493644706831@mail.yahoo.com>
 <02b801d2c292$df68d950$9e3a8bf0$@ngtech.co.il>
 <742538244.50351.1493672695826@mail.yahoo.com>
 <c0440ac0-a9a7-8eec-0359-73ffc4fe5af7@treenet.co.nz>
Message-ID: <595899296.566110.1493728836278@mail.yahoo.com>

Here's a question: ?if I use SSL or TLS encryption between squid and browser, would even the basic auth login be encrypted? ?
I'm thinking that instead of trying to use the proxy to SSH through, I could use something like shellinabox over the proxy if the link is encrypted. ?This would be much easier and serve the purpose.
According to this link, it seems pretty straightforward to get Firefox or Chrome to do it: ?wiki.squid-cache.org/Features/HTTPS#Chrome
Would the default config located at?wiki.squid-cache.org/SquidFaq/ConfiguringSquid#Squid-3.5_default_config? allow this?

      From: Amos Jeffries <squid3 at treenet.co.nz>
 To: squid-users at lists.squid-cache.org 
 Sent: Monday, May 1, 2017 7:06 PM
 Subject: Re: [squid-users] Tutorial for better authentication than basic
   
On 02/05/17 09:04, j m wrote:
> Wow, I didn't find that one.? Not super secure, but better than clear 
> text and I'm not too worried about someone sniffing my packets.
>

The security level with Digest depends on the nonce lifetime and reuse 
counter, both of which you can tune to your liking. The shorter those 
are the more secure, up to the point where it is a purely one-time 
token. That said, some clients (most often browsers) have big trouble 
managing nonces in correct order and with dozens of connections open to 
the proxy - and then there are Squid bugs. So tuning those is not as 
easy as it should be.

NTLM does not work over the Internet. Kerberos might, but not very well. 
They are connection-oriented authentication schemes designed for use in 
LAN environments. So for your described situation they are not useful 
even if you were willing to open the ports.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170502/1591e284/attachment.htm>

From Ralf.Hildebrandt at charite.de  Tue May  2 12:59:07 2017
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 2 May 2017 14:59:07 +0200
Subject: [squid-users] URL sometimes reurns empty response
In-Reply-To: <241b3eef-50aa-52c3-e498-5724d60a9e8a@gmail.com>
References: <20170502115938.gvqtqxshocmy6epy@charite.de>
 <241b3eef-50aa-52c3-e498-5724d60a9e8a@gmail.com>
Message-ID: <20170502125906.zd2gqn7xxw5gwtl2@charite.de>

* Yuri Voinov <yvoinov at gmail.com>:

> If you add this URL to cache deny rule - problem still exists?

Using this:

# START
acl nocaching url_regex "^http://www\.(msftconnecttest|msftncsi)\.com"
cache deny nocaching
# ENDE

And yes, problem still exists...

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
https://www.charite.de             Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From marcus.kool at urlfilterdb.com  Tue May  2 13:02:38 2017
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 2 May 2017 10:02:38 -0300
Subject: [squid-users] URL sometimes reurns empty response
In-Reply-To: <20170502115938.gvqtqxshocmy6epy@charite.de>
References: <20170502115938.gvqtqxshocmy6epy@charite.de>
Message-ID: <74d64749-0ab2-7b75-5637-b18c07ef1f77@urlfilterdb.com>

Looks like MS uses multiple servers for msftconnecttest.com and that they send different content.

On 02/05/17 08:59, Ralf Hildebrandt wrote:
> In some cases, our proxies (got 4 of them) return a empty result when
> querying "http://www.msftconnecttest.com/ncsi.txt" (whcih is used by
> Microsoft Brwosers to check if they're online).
>
> I'm using this incantation to check the URL:
>
> watch -d curl --silent -v -x "http://proxy-cvk-1.charite.de:8080" http://www.msftconnecttest.com/ncsi.txt
>
> Usually, the URL should just return "Microsoft NCSI".
> In some cases I get an empyt response, but curl reports:
>
> < Age: 5
> < X-Cache: HIT from proxy-cvk-1
> < Via: 1.1 proxy-cvk-1 (squid/5.0.0-20170421-r15126)
> < Connection: keep-alive
> <
> * Excess found in a non pipelined read: excess = 14 url = /ncsi.txt (zero-length body)
> * Curl_http_done: called premature == 0
> * Connection #0 to host (nil) left intact
>
> As you can see, something is producing an excess of 14 Bytes (which
> coincides with the 14 bytes length of "Microsoft NCSI").
>
> < Cache-Control: max-age=30,must-revalidate
>
> Immediatly after revalidating, the problem occurs.
>
> I tried this with 5.0.0-20170421-r15126 as well as 4.0.19 - same result.
>


From Ralf.Hildebrandt at charite.de  Tue May  2 13:08:43 2017
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 2 May 2017 15:08:43 +0200
Subject: [squid-users] URL sometimes reurns empty response
In-Reply-To: <74d64749-0ab2-7b75-5637-b18c07ef1f77@urlfilterdb.com>
References: <20170502115938.gvqtqxshocmy6epy@charite.de>
 <74d64749-0ab2-7b75-5637-b18c07ef1f77@urlfilterdb.com>
Message-ID: <20170502130843.2c444jsiyvohu5ou@charite.de>

* Marcus Kool <marcus.kool at urlfilterdb.com>:

> Looks like MS uses multiple servers for msftconnecttest.com and that they send different content.

Nope. I verified the server's responses on the proxy machines itself
using direct connections. It's always correct.

Note this:

> > * Excess found in a non pipelined read: excess = 14 url = /ncsi.txt (zero-length body)

It seems that squid is returning an incorrect Content-Lenght: header 
while the revalidation is still fresh/ongoing.

I haven't yet tried tcpdumping the response to check if the 14 bytes
do indeed contain the correct string.

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
https://www.charite.de             Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From Ralf.Hildebrandt at charite.de  Tue May  2 13:15:26 2017
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 2 May 2017 15:15:26 +0200
Subject: [squid-users] URL sometimes reurns empty response
In-Reply-To: <20170502130843.2c444jsiyvohu5ou@charite.de>
References: <20170502115938.gvqtqxshocmy6epy@charite.de>
 <74d64749-0ab2-7b75-5637-b18c07ef1f77@urlfilterdb.com>
 <20170502130843.2c444jsiyvohu5ou@charite.de>
Message-ID: <20170502131526.2hu2dyt4fgzck6vp@charite.de>

* Ralf Hildebrandt <Ralf.Hildebrandt at charite.de>:

> It seems that squid is returning an incorrect Content-Lenght: header 
> while the revalidation is still fresh/ongoing.
> 
> I haven't yet tried tcpdumping the response to check if the 14 bytes
> do indeed contain the correct string.

And voila - here we go (Content-Length: 0 but squid sends 14 bytes of excess data: "Microsoft NCSI")

15:10:31.741436 IP proxy-cvk-1.charite.de.http-alt > vsw-it-nw-10.54228: Flags [P.], seq 1:952, ack 156, win 235, options [nop,nop,TS val 126939588 ecr 1696144349], length 951: HTTP: HTTP/1.1 200 OK
E...cR at .?....*...*......V?.....5....U......
....e...HTTP/1.1 200 OK
Cache-Control: max-age=30,must-revalidate
Content-Length: 0
Content-Type: text/plain
Last-Modified: Fri, 04 Mar 2016 06:55:23 GMT
ETag: "0x8D343F9F578A7F9"
Server: Microsoft-IIS/7.5
x-ms-request-id: 6508a999-0001-0016-4fbc-c0483a000000
x-ms-version: 2009-09-19
x-ms-meta-CbModifiedTime: Tue, 01 Mar 2016 21:41:22 GMT
x-ms-lease-status: unlocked
x-ms-blob-type: BlockBlob
X-ECN-P: RD0003FF838204
Access-Control-Expose-Headers: X-MSEdge-Ref
Access-Control-Allow-Origin: *
Timing-Allow-Origin: *
X-CID: 7
X-CCC: US
X-MSEdge-Ref: Ref A: 2C6BD6F103A24795AE6784C3DC22E5F5 Ref B: BER30EDGE0115 Ref C: Tue May  2 06:10:31 2017 PST
X-MSEdge-Ref-OriginShield: Ref A: 5A9FC4FE82DC4E2DB26E51E59C50B50A Ref B: AMS04EDGE0506 Ref C: Sat Apr 29 05:30:12 2017 PST
Date: Tue, 02 May 2017 13:10:31 GMT
Age: 0
X-Cache: HIT from proxy-cvk-1
Via: 1.1 proxy-cvk-1 (squid/5.0.0-20170429-r15127)
Connection: keep-alive

Microsoft NCSI
15:10:31.741454 IP vsw-it-nw-10.54228 > proxy-cvk-1.charite.de.http-alt: Flags [.], ack 952, win 243, options [nop,nop,TS val 1696144352 ecr 126939588], length 0
E..4._ at .@..=.*...*.........5V?.G.....O.....
e.......

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
https://www.charite.de             Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From yvoinov at gmail.com  Tue May  2 13:19:16 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 2 May 2017 19:19:16 +0600
Subject: [squid-users] URL sometimes reurns empty response
In-Reply-To: <20170502131526.2hu2dyt4fgzck6vp@charite.de>
References: <20170502115938.gvqtqxshocmy6epy@charite.de>
 <74d64749-0ab2-7b75-5637-b18c07ef1f77@urlfilterdb.com>
 <20170502130843.2c444jsiyvohu5ou@charite.de>
 <20170502131526.2hu2dyt4fgzck6vp@charite.de>
Message-ID: <9a46cb5d-2a37-8835-30b2-391d03d5b24b@gmail.com>

Hmmmmm. See no issue from my side:

root @ khorne /patch # wget -S http://www.msftconnecttest.com/ncsi.txt
--2017-05-02 19:16:11--  http://www.msftconnecttest.com/ncsi.txt
Connecting to 127.0.0.1:3128... connected.
Proxy request sent, awaiting response...
  HTTP/1.1 200 OK
  Cache-Control: max-age=30,must-revalidate
  Content-Length: 14
  Content-Type: text/plain
  Last-Modified: Fri, 04 Mar 2016 06:55:23 GMT
  ETag: "0x8D343F9F578A7F9"
  Server: Microsoft-IIS/7.5
  x-ms-request-id: 45e06e80-0001-000b-6f15-be91d0000000
  x-ms-version: 2009-09-19
  x-ms-meta-CbModifiedTime: Tue, 01 Mar 2016 21:41:22 GMT
  x-ms-lease-status: unlocked
  x-ms-blob-type: BlockBlob
  X-ECN-P: RD0003FF838204
  Access-Control-Expose-Headers: X-MSEdge-Ref
  Access-Control-Allow-Origin: *
  Timing-Allow-Origin: *
  X-CID: 7
  X-CCC: SE
  X-MSEdge-Ref: Ref A: FFF0B969CF5F48DA856B48165D32542E Ref B:
STOEDGE0510 Ref C: Tue May  2 06:16:14 2017 PST
  X-MSEdge-Ref-OriginShield: Ref A: 9D033F6C12734D3A839C09F1BAFF798E Ref
B: AMS04EDGE0220 Ref C: Thu Apr 27 07:42:11 2017 PST
  Date: Tue, 02 May 2017 13:16:13 GMT
  X-Cache: MISS from khorne
  X-Cache-Lookup: MISS from khorne:3128
  Connection: keep-alive
Length: 14 [text/plain]
Saving to: 'ncsi.txt'

ncsi.txt            100%[===================>]      14  --.-KB/s    in
0s     

2017-05-02 19:16:14 (2.07 MB/s) - 'ncsi.txt' saved [14/14]

root @ khorne /patch # wget -S http://www.msftconnecttest.com/ncsi.txt
--2017-05-02 19:16:32--  http://www.msftconnecttest.com/ncsi.txt
Connecting to 127.0.0.1:3128... connected.
Proxy request sent, awaiting response...
  HTTP/1.1 200 OK
  Cache-Control: max-age=30,must-revalidate
  Content-Length: 14
  Content-Type: text/plain
  Last-Modified: Fri, 04 Mar 2016 06:55:23 GMT
  ETag: "0x8D343F9F578A7F9"
  Server: Microsoft-IIS/7.5
  x-ms-request-id: 45e06e80-0001-000b-6f15-be91d0000000
  x-ms-version: 2009-09-19
  x-ms-meta-CbModifiedTime: Tue, 01 Mar 2016 21:41:22 GMT
  x-ms-lease-status: unlocked
  x-ms-blob-type: BlockBlob
  X-ECN-P: RD0003FF838204
  Access-Control-Expose-Headers: X-MSEdge-Ref
  Access-Control-Allow-Origin: *
  Timing-Allow-Origin: *
  X-CID: 7
  X-CCC: SE
  X-MSEdge-Ref: Ref A: FFF0B969CF5F48DA856B48165D32542E Ref B:
STOEDGE0510 Ref C: Tue May  2 06:16:14 2017 PST
  X-MSEdge-Ref-OriginShield: Ref A: 9D033F6C12734D3A839C09F1BAFF798E Ref
B: AMS04EDGE0220 Ref C: Thu Apr 27 07:42:11 2017 PST
  X-Origin-Date: Tue, 02 May 2017 13:16:13 GMT
  Date: Tue, 02 May 2017 13:16:32 GMT
  X-Cache-Age: 19
  X-Cache: HIT from khorne
  X-Cache-Lookup: HIT from khorne:3128
  Connection: keep-alive
Length: 14 [text/plain]
Saving to: 'ncsi.txt.1'

ncsi.txt.1          100%[===================>]      14  --.-KB/s    in
0s     

2017-05-02 19:16:32 (1.90 MB/s) - 'ncsi.txt.1' saved [14/14]

root @ khorne /patch # wget -S http://www.msftconnecttest.com/ncsi.txt
--2017-05-02 19:18:06--  http://www.msftconnecttest.com/ncsi.txt
Connecting to 127.0.0.1:3128... connected.
Proxy request sent, awaiting response...
  HTTP/1.1 200 OK
  Content-Length: 14
  ETag: "0x8D343F9F578A7F9"
  Cache-Control: max-age=30,must-revalidate
  Content-Type: text/plain
  Last-Modified: Fri, 04 Mar 2016 06:55:23 GMT
  Server: Microsoft-IIS/7.5
  x-ms-request-id: 45e06e80-0001-000b-6f15-be91d0000000
  x-ms-version: 2009-09-19
  x-ms-meta-CbModifiedTime: Tue, 01 Mar 2016 21:41:22 GMT
  x-ms-lease-status: unlocked
  x-ms-blob-type: BlockBlob
  X-ECN-P: RD0003FF838204
  Access-Control-Expose-Headers: X-MSEdge-Ref
  Access-Control-Allow-Origin: *
  Timing-Allow-Origin: *
  X-CID: 7
  X-CCC: SE
  X-MSEdge-Ref: Ref A: 1F682D6F87124BF28456EB937B49B208 Ref B:
STOSCHEDGE0116 Ref C: Tue May  2 06:18:06 2017 PST
  X-MSEdge-Ref-OriginShield: Ref A: 9D033F6C12734D3A839C09F1BAFF798E Ref
B: AMS04EDGE0220 Ref C: Thu Apr 27 07:42:11 2017 PST
  Vary: Accept-Encoding
  X-Origin-Date: Tue, 02 May 2017 13:18:05 GMT
  Date: Tue, 02 May 2017 13:18:06 GMT
  X-Cache-Age: 1
  X-Cache: HIT from khorne
  X-Cache-Lookup: HIT from khorne:3128
  Connection: keep-alive
Length: 14 [text/plain]
Saving to: 'ncsi.txt.2'

ncsi.txt.2          100%[===================>]      14  --.-KB/s    in
0s     

2017-05-02 19:18:06 (2.03 MB/s) - 'ncsi.txt.2' saved [14/14]

Seems correct. Will dig more.


02.05.2017 19:15, Ralf Hildebrandt ?????:
> * Ralf Hildebrandt <Ralf.Hildebrandt at charite.de>:
>
>> It seems that squid is returning an incorrect Content-Lenght: header 
>> while the revalidation is still fresh/ongoing.
>>
>> I haven't yet tried tcpdumping the response to check if the 14 bytes
>> do indeed contain the correct string.
> And voila - here we go (Content-Length: 0 but squid sends 14 bytes of excess data: "Microsoft NCSI")
>
> 15:10:31.741436 IP proxy-cvk-1.charite.de.http-alt > vsw-it-nw-10.54228: Flags [P.], seq 1:952, ack 156, win 235, options [nop,nop,TS val 126939588 ecr 1696144349], length 951: HTTP: HTTP/1.1 200 OK
> E...cR at .?....*...*......V?.....5....U......
> ....e...HTTP/1.1 200 OK
> Cache-Control: max-age=30,must-revalidate
> Content-Length: 0
> Content-Type: text/plain
> Last-Modified: Fri, 04 Mar 2016 06:55:23 GMT
> ETag: "0x8D343F9F578A7F9"
> Server: Microsoft-IIS/7.5
> x-ms-request-id: 6508a999-0001-0016-4fbc-c0483a000000
> x-ms-version: 2009-09-19
> x-ms-meta-CbModifiedTime: Tue, 01 Mar 2016 21:41:22 GMT
> x-ms-lease-status: unlocked
> x-ms-blob-type: BlockBlob
> X-ECN-P: RD0003FF838204
> Access-Control-Expose-Headers: X-MSEdge-Ref
> Access-Control-Allow-Origin: *
> Timing-Allow-Origin: *
> X-CID: 7
> X-CCC: US
> X-MSEdge-Ref: Ref A: 2C6BD6F103A24795AE6784C3DC22E5F5 Ref B: BER30EDGE0115 Ref C: Tue May  2 06:10:31 2017 PST
> X-MSEdge-Ref-OriginShield: Ref A: 5A9FC4FE82DC4E2DB26E51E59C50B50A Ref B: AMS04EDGE0506 Ref C: Sat Apr 29 05:30:12 2017 PST
> Date: Tue, 02 May 2017 13:10:31 GMT
> Age: 0
> X-Cache: HIT from proxy-cvk-1
> Via: 1.1 proxy-cvk-1 (squid/5.0.0-20170429-r15127)
> Connection: keep-alive
>
> Microsoft NCSI
> 15:10:31.741454 IP vsw-it-nw-10.54228 > proxy-cvk-1.charite.de.http-alt: Flags [.], ack 952, win 243, options [nop,nop,TS val 1696144352 ecr 126939588], length 0
> E..4._ at .@..=.*...*.........5V?.G.....O.....
> e.......
>

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170502/d450fe7a/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170502/d450fe7a/attachment.sig>

From Ralf.Hildebrandt at charite.de  Tue May  2 13:29:32 2017
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 2 May 2017 15:29:32 +0200
Subject: [squid-users] URL sometimes reurns empty response
In-Reply-To: <9a46cb5d-2a37-8835-30b2-391d03d5b24b@gmail.com>
References: <20170502115938.gvqtqxshocmy6epy@charite.de>
 <74d64749-0ab2-7b75-5637-b18c07ef1f77@urlfilterdb.com>
 <20170502130843.2c444jsiyvohu5ou@charite.de>
 <20170502131526.2hu2dyt4fgzck6vp@charite.de>
 <9a46cb5d-2a37-8835-30b2-391d03d5b24b@gmail.com>
Message-ID: <20170502132932.4rlqqamakucdksse@charite.de>

* Yuri Voinov <yvoinov at gmail.com>:
> Hmmmmm. See no issue from my side:

"Content-Length: 0", happens when Age ist either 0 or 1

$ wget -S http://www.msftconnecttest.com/ncsi.txt
--2017-05-02 15:27:28--  http://www.msftconnecttest.com/ncsi.txt
Aufl?sen des Hostnamens ?proxy.charite.de (proxy.charite.de)? ?
141.42.1.215
Verbindungsaufbau zu proxy.charite.de
(proxy.charite.de)|141.42.1.215|:8080 ? verbunden.
Proxy-Anforderung gesendet, auf Antwort wird gewartet ? 
  HTTP/1.1 200 OK
  Cache-Control: max-age=30,must-revalidate
  Content-Length: 0
  Content-Type: text/plain
  Last-Modified: Fri, 04 Mar 2016 06:55:23 GMT
  ETag: "0x8D343F9F578A7F9"
  Server: Microsoft-IIS/7.5
  x-ms-request-id: 6508a999-0001-0016-4fbc-c0483a000000
  x-ms-version: 2009-09-19
  x-ms-meta-CbModifiedTime: Tue, 01 Mar 2016 21:41:22 GMT
  x-ms-lease-status: unlocked
  x-ms-blob-type: BlockBlob
  X-ECN-P: RD0003FF838204
  Access-Control-Expose-Headers: X-MSEdge-Ref
  Access-Control-Allow-Origin: *
  Timing-Allow-Origin: *
  X-CID: 7
  X-CCC: US
  X-MSEdge-Ref: Ref A: AB76E69442AC44F496DBBD15A2132A90 Ref B: BER30EDGE0206 Ref C: Tue May 2 06:27:28 2017 PST
  X-MSEdge-Ref-OriginShield: Ref A: 5A9FC4FE82DC4E2DB26E51E59C50B50A Ref B: AMS04EDGE0506 Ref C: Sat Apr 29 05:30:12 2017 PST
  Date: Tue, 02 May 2017 13:27:27 GMT
  Age: 1
  X-Cache: HIT from proxy-cbf-1
  Via: 1.1 proxy-cbf-1 (squid/5.0.0-20170429-r15127)
  Connection: keep-alive
L?nge: 0 [text/plain]


-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
https://www.charite.de             Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From acctforjunk at yahoo.com  Wed May  3 00:10:32 2017
From: acctforjunk at yahoo.com (j m)
Date: Wed, 3 May 2017 00:10:32 +0000 (UTC)
Subject: [squid-users] Tutorial for better authentication than basic
In-Reply-To: <02b801d2c292$df68d950$9e3a8bf0$@ngtech.co.il>
References: <456739995.1458100.1493644706831.ref@mail.yahoo.com>
 <456739995.1458100.1493644706831@mail.yahoo.com>
 <02b801d2c292$df68d950$9e3a8bf0$@ngtech.co.il>
Message-ID: <1207337074.1242098.1493770232643@mail.yahoo.com>

This is in response to:
"There is another option if you don't have any issue to allow a certain public IP address access to your network you can use some kind of portal which will allow based on a SSL(even with self signed certificate) the "session" access to the service."
I didn't receive the email so couldn't reply directly. ?
I'm pretty happy with digest auth as I think that is likely secure enough. ?The proxy is working, mostly ?However I'm having trouble with two things:
1. I'm not able to figure out what goes into squid.conf to allow SSH through proxy. ?My SSH server is on a non-standard port above 1024, and as I understand, squid.conf has to account for this. ?I have references to (ssh_port) and have the CONNECT method enabled (I believe) but I'm not sure if this is correct. ?I'm certainly not able to SSH thru it:

auth_param digest program /usr/lib/squid/digest_file_auth -c /etc/squid/passwdauth_param digest realm the_zone
auth_param digest children 2
acl auth_users proxy_auth REQUIRED
acl SSL_ports port (ssh_port)
acl Safe_ports port (ssh_port)
acl SSL_ports port 443
acl Safe_ports port 80 ? ? ? ?# httpacl Safe_ports port 21 ? ? ? ?# ftpacl Safe_ports port 443 ? ? ? ?# httpsacl Safe_ports port 70 ? ? ? ?# gopheracl Safe_ports port 210 ? ? ? ?# waisacl Safe_ports port 1025-65535 ? ?# unregistered portsacl Safe_ports port 280 ? ? ? ?# http-mgmtacl Safe_ports port 488 ? ? ? ?# gss-httpacl Safe_ports port 591 ? ? ? ?# filemakeracl Safe_ports port 777 ? ? ? ?# multiling httpacl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_portshttp_access allow auth_users
http_access allow all
http_port (proxy_port)
cache deny all
access_log none



2. I am no longer able to start squid in Ubuntu by using "service squid start". ?This used to work, but it gives no error; it appears to immediately execute, but it's not running as a process. ? ?However, if I run "squid -N -d 1 -D", it runs with no complaints.



      From: Eliezer Croitoru <eliezer at ngtech.co.il>
 To: 'j m' <acctforjunk at yahoo.com>; squid-users at lists.squid-cache.org 
 Sent: Monday, May 1, 2017 3:30 PM
 Subject: RE: [squid-users] Tutorial for better authentication than basic
   
And what about digest authentication?

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of j m
Sent: Monday, May 1, 2017 4:18 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Tutorial for better authentication than basic

I'm using Ubuntu 16.04 Server in the home and would like to set up a proxy server for use from over the Internet.? The main purpose for this is to easily access a few web-devices on my LAN without using VPN, and at times to route web traffic from a remote location through my home ISP.? I do not need nor want any caching or filtering.

I previously used Tinyproxy and that did the job, but it had no authentication whatsoever.? I have basic authentication working on squid 3.5, where it asks for the username and password, but I believe this login is sent in clear text.? I've did some research and found squid supports various better methods, such as kerberos, ntlm, smb, etc.? However, while I'm able to install Linux and set up various things, I'm struggling with this authentication aspect.? I have a suspicion some of these methods will not work well because they rely on other services (such as SMB) and may require opening more ports on my router, something I'm not crazy about.

Amos previously suggested client cert auth, but I'm not sure how to set this up.? Are there any other secure auth methods that would work well over the Internet and are fairly simple to configure?

In any case, can anyone point me to an online tutorial somewhere (for a authentication newbie) that outlines how this is done?


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/0390f9f3/attachment.htm>

From blaxxton at yahoo.com  Wed May  3 00:40:04 2017
From: blaxxton at yahoo.com (Blaxton)
Date: Wed, 3 May 2017 00:40:04 +0000 (UTC)
Subject: [squid-users] limit access with acl only based on source and
	destination domain
References: <982145555.1000130.1493772004922.ref@mail.yahoo.com>
Message-ID: <982145555.1000130.1493772004922@mail.yahoo.com>

Hi
I am trying to limit the out bound connection based on list of domain names definedin srcdomain and dstdomain.?
Here is acl :
acl From_Source_Domains srcdomain domain1 domain2 domain3acl To_Destination_Domains dstdomain domain4 domain5 domain6
Now some web site says below considered OR and it is working for me:http_access allow From_Source_Domainshttp_access allow To_Destination_Domains
And some web sites saying below considered AND but it is not working for me:http_access allow From_Source_Domains To_Destination_Domains
I am assuming since I have not allowed any port, then port should be disabledbut it is not, on OR of the src and dst domains.
If add?acl http_port 80 ?http_access allow http_port
Then it allow traffic from any source to any destination if port is 80.
Kind of confusing and need a bit of help.
Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/cc40d04b/attachment.htm>

From rafael.akchurin at diladele.com  Wed May  3 08:47:40 2017
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Wed, 3 May 2017 08:47:40 +0000
Subject: [squid-users] ssl bump and chrome 58
In-Reply-To: <a6ee678d1e41241f678c71380c05862a@data-core.org>
References: <20170421142934.241ce2cf@efreet-freebsd.kappastar.com>
 <f822ef50-731e-ec12-3b1f-144ce1f48347@gmail.com>
 <e12127951db2c3923f57ba0b4af8de78@data-core.org>
 <3e7c47a85eca33d1f2cd3331ab782857@data-core.org>
 <a6ee678d1e41241f678c71380c05862a@data-core.org>
Message-ID: <DB6PR0401MB2680322D60ED3DFFC11197FE8F160@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Hello all,

The following steps give in Chrome 58 the "Your connection is not private" error with "NET::ERR_CERT_COMMON_NAME_INVALID" and "missing_subjectAltName" error:

(peek-an-splice bumping squid 3.5.23_1 as in https://docs.diladele.com/howtos/build_squid_ubuntu16/index.html)

1. Open Chrome 58+
2. Type some non existing domain name like "https://www.asdlajsdfl.com" (note the httpS:// schema)
3. See the missing_subjectAltName error.

Correct behavior would be Squid generating faked certificate for the domain name "www.asdlajsdfl.com" *with* subjectAltName extension set to "www.asdlajsdfl.com".

So question is - does anyone know if this is already existing bug or shall I file one?
May be it is a feature?

Best regards,
Rafael


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Flashdown
Sent: Thursday, April 27, 2017 6:42 PM
To: Yuri Voinov <yvoinov at gmail.com>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] ssl bump and chrome 58

I've tested the registry setting and it worked out. You can copy the below lines in a .reg file and execute it.

Windows Registry Editor Version 5.00

[HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Google\Chrome]
"EnableCommonNameFallbackForLocalAnchors"=dword:00000001


Best regards,
Flashdown

Am 2017-04-27 18:34, schrieb Flashdown:
> Hello together,
> 
> here is a workaround that you could use in the meanwhile.
> 
> https://www.chromium.org/administrators/policy-list-3#EnableCommonName
> FallbackForLocalAnchors
> 
> Source:
> https://www.chromium.org/administrators/policy-list-3#EnableCommonName
> FallbackForLocalAnchors
>>>>>> BEGIN
> EnableCommonNameFallbackForLocalAnchors
> Whether to allow certificates issued by local trust anchors that are 
> missing the subjectAlternativeName extension
> 
> Data type:
>     Boolean [Windows:REG_DWORD]
> Windows registry location:
>     
> Software\Policies\Google\Chrome\EnableCommonNameFallbackForLocalAnchor
> s
> Mac/Linux preference name:
>     EnableCommonNameFallbackForLocalAnchors
> Android restriction name:
>     EnableCommonNameFallbackForLocalAnchors
> Supported on:
> 
>         Google Chrome (Linux, Mac, Windows) since version 58 until 
> version 65
>         Google Chrome OS (Google Chrome OS) since version 58 until 
> version 65
>         Google Chrome (Android) since version 58 until version 65
> 
> Supported features:
>     Dynamic Policy Refresh: Yes, Per Profile: No
> Description:
> 
>     When this setting is enabled, Google Chrome will use the 
> commonName of a server certificate to match a hostname if the 
> certificate is missing a subjectAlternativeName extension, as long as 
> it successfully validates and chains to a locally-installed CA 
> certificates.
> 
>     Note that this is not recommended, as this may allow bypassing the 
> nameConstraints extension that restricts the hostnames that a given 
> certificate can be authorized for.
> 
>     If this policy is not set, or is set to false, server certificates 
> that lack a subjectAlternativeName extension containing either a DNS 
> name or IP address will not be trusted.
> Example value:
>     0x00000000 (Windows), false (Linux), false (Android), <false />
> (Mac)
> <<<<<<<<<<<< END
> 
> 
> 
> Am 2017-04-27 18:16, schrieb Flashdown:
>> Hello together,
>> 
>> Suddenly I am facing the same issue when users Chrome has been 
>> updated to V58. I am running Squid 3.5.23.
>> 
>> This is the reason:
>> https://www.thesslstore.com/blog/security-changes-in-chrome-58/
>> Short: Common Name Support Removed in Chrome 58 and Squid does not 
>> create certs with DNS-Alternatives names in it. Because of that it 
>> fails.
>> 
>> Chrome says:
>> 1. Subject Alternative Name Missing - The certificate for this site 
>> does not contain a Subject Alternative Name extension containing a 
>> domain name or IP address.
>> 2. Certificate Error - There are issues with the site's certificate 
>> chain (net::ERR_CERT_COMMON_NAME_INVALID).
>> 
>> Can we get Squid to add the DNS-Alternative Name to the generated 
>> certs? Since this is what I believe is now required in Chrome 58+
>> 
>> Best regards,
>> Enrico
>> 
>> 
>> Am 2017-04-21 15:35, schrieb Yuri Voinov:
>>> I see no problem with it on all five SSL Bump-aware servers with new 
>>> Chrome. So fare so good.
>>> 
>>> 
>>> 21.04.2017 18:29, Marko Cupa? ?????:
>>>> Hi,
>>>> 
>>>> I have squid setup with ssl bump which worked fine, but since I 
>>>> updated chrome to 58 it won't display any https sites, throwing 
>>>> NTT:ERR_CERT_COMMON_NAME_INVALID. https sites still work in 
>>>> previous chrome version, as well as in IE.
>>>> 
>>>> Anything I can do in squid config to get ssl-bumped sites in chrome 
>>>> again?
>>>> 
>>>> Thank you in advance,
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From rafael.akchurin at diladele.com  Wed May  3 09:05:44 2017
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Wed, 3 May 2017 09:05:44 +0000
Subject: [squid-users] ssl bump and chrome 58
In-Reply-To: <DB6PR0401MB2680322D60ED3DFFC11197FE8F160@DB6PR0401MB2680.eurprd04.prod.outlook.com>
References: <20170421142934.241ce2cf@efreet-freebsd.kappastar.com>
 <f822ef50-731e-ec12-3b1f-144ce1f48347@gmail.com>
 <e12127951db2c3923f57ba0b4af8de78@data-core.org>
 <3e7c47a85eca33d1f2cd3331ab782857@data-core.org>
 <a6ee678d1e41241f678c71380c05862a@data-core.org>
 <DB6PR0401MB2680322D60ED3DFFC11197FE8F160@DB6PR0401MB2680.eurprd04.prod.outlook.com>
Message-ID: <DB6PR0401MB26806D92D0A27750DFEE883E8F160@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Sorry disregard - should practice my  google fu better - see http://bugs.squid-cache.org/show_bug.cgi?id=4711

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Rafael Akchurin
Sent: Wednesday, May 3, 2017 10:48 AM
To: Flashdown <flashdown at data-core.org>; Yuri Voinov <yvoinov at gmail.com>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] ssl bump and chrome 58

[This sender failed our fraud detection checks and may not be who they appear to be. Learn about spoofing at http://aka.ms/LearnAboutSpoofing]

Hello all,

The following steps give in Chrome 58 the "Your connection is not private" error with "NET::ERR_CERT_COMMON_NAME_INVALID" and "missing_subjectAltName" error:

(peek-an-splice bumping squid 3.5.23_1 as in https://docs.diladele.com/howtos/build_squid_ubuntu16/index.html)

1. Open Chrome 58+
2. Type some non existing domain name like "https://www.asdlajsdfl.com" (note the httpS:// schema) 3. See the missing_subjectAltName error.

Correct behavior would be Squid generating faked certificate for the domain name "www.asdlajsdfl.com" *with* subjectAltName extension set to "www.asdlajsdfl.com".

So question is - does anyone know if this is already existing bug or shall I file one?
May be it is a feature?

Best regards,
Rafael


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Flashdown
Sent: Thursday, April 27, 2017 6:42 PM
To: Yuri Voinov <yvoinov at gmail.com>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] ssl bump and chrome 58

I've tested the registry setting and it worked out. You can copy the below lines in a .reg file and execute it.

Windows Registry Editor Version 5.00

[HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Google\Chrome]
"EnableCommonNameFallbackForLocalAnchors"=dword:00000001


Best regards,
Flashdown

Am 2017-04-27 18:34, schrieb Flashdown:
> Hello together,
>
> here is a workaround that you could use in the meanwhile.
>
> https://www.chromium.org/administrators/policy-list-3#EnableCommonName
> FallbackForLocalAnchors
>
> Source:
> https://www.chromium.org/administrators/policy-list-3#EnableCommonName
> FallbackForLocalAnchors
>>>>>> BEGIN
> EnableCommonNameFallbackForLocalAnchors
> Whether to allow certificates issued by local trust anchors that are 
> missing the subjectAlternativeName extension
>
> Data type:
>     Boolean [Windows:REG_DWORD]
> Windows registry location:
>
> Software\Policies\Google\Chrome\EnableCommonNameFallbackForLocalAnchor
> s
> Mac/Linux preference name:
>     EnableCommonNameFallbackForLocalAnchors
> Android restriction name:
>     EnableCommonNameFallbackForLocalAnchors
> Supported on:
>
>         Google Chrome (Linux, Mac, Windows) since version 58 until 
> version 65
>         Google Chrome OS (Google Chrome OS) since version 58 until 
> version 65
>         Google Chrome (Android) since version 58 until version 65
>
> Supported features:
>     Dynamic Policy Refresh: Yes, Per Profile: No
> Description:
>
>     When this setting is enabled, Google Chrome will use the 
> commonName of a server certificate to match a hostname if the 
> certificate is missing a subjectAlternativeName extension, as long as 
> it successfully validates and chains to a locally-installed CA 
> certificates.
>
>     Note that this is not recommended, as this may allow bypassing the 
> nameConstraints extension that restricts the hostnames that a given 
> certificate can be authorized for.
>
>     If this policy is not set, or is set to false, server certificates 
> that lack a subjectAlternativeName extension containing either a DNS 
> name or IP address will not be trusted.
> Example value:
>     0x00000000 (Windows), false (Linux), false (Android), <false />
> (Mac)
> <<<<<<<<<<<< END
>
>
>
> Am 2017-04-27 18:16, schrieb Flashdown:
>> Hello together,
>>
>> Suddenly I am facing the same issue when users Chrome has been 
>> updated to V58. I am running Squid 3.5.23.
>>
>> This is the reason:
>> https://www.thesslstore.com/blog/security-changes-in-chrome-58/
>> Short: Common Name Support Removed in Chrome 58 and Squid does not 
>> create certs with DNS-Alternatives names in it. Because of that it 
>> fails.
>>
>> Chrome says:
>> 1. Subject Alternative Name Missing - The certificate for this site 
>> does not contain a Subject Alternative Name extension containing a 
>> domain name or IP address.
>> 2. Certificate Error - There are issues with the site's certificate 
>> chain (net::ERR_CERT_COMMON_NAME_INVALID).
>>
>> Can we get Squid to add the DNS-Alternative Name to the generated 
>> certs? Since this is what I believe is now required in Chrome 58+
>>
>> Best regards,
>> Enrico
>>
>>
>> Am 2017-04-21 15:35, schrieb Yuri Voinov:
>>> I see no problem with it on all five SSL Bump-aware servers with new 
>>> Chrome. So fare so good.
>>>
>>>
>>> 21.04.2017 18:29, Marko Cupa? ?????:
>>>> Hi,
>>>>
>>>> I have squid setup with ssl bump which worked fine, but since I 
>>>> updated chrome to 58 it won't display any https sites, throwing 
>>>> NTT:ERR_CERT_COMMON_NAME_INVALID. https sites still work in 
>>>> previous chrome version, as well as in IE.
>>>>
>>>> Anything I can do in squid config to get ssl-bumped sites in chrome 
>>>> again?
>>>>
>>>> Thank you in advance,
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From yvoinov at gmail.com  Wed May  3 10:30:24 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 3 May 2017 16:30:24 +0600
Subject: [squid-users] ssl bump and chrome 58
In-Reply-To: <DB6PR0401MB26806D92D0A27750DFEE883E8F160@DB6PR0401MB2680.eurprd04.prod.outlook.com>
References: <20170421142934.241ce2cf@efreet-freebsd.kappastar.com>
 <f822ef50-731e-ec12-3b1f-144ce1f48347@gmail.com>
 <e12127951db2c3923f57ba0b4af8de78@data-core.org>
 <3e7c47a85eca33d1f2cd3331ab782857@data-core.org>
 <a6ee678d1e41241f678c71380c05862a@data-core.org>
 <DB6PR0401MB2680322D60ED3DFFC11197FE8F160@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <DB6PR0401MB26806D92D0A27750DFEE883E8F160@DB6PR0401MB2680.eurprd04.prod.outlook.com>
Message-ID: <cba4a78b-2189-6753-0835-3921b5c71ec4@gmail.com>

Mountain brake, Raf :-)

Fixed yesterday, already running on productions (on my side) ;-)


03.05.2017 15:05, Rafael Akchurin ?????:
> Sorry disregard - should practice my  google fu better - see http://bugs.squid-cache.org/show_bug.cgi?id=4711
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Rafael Akchurin
> Sent: Wednesday, May 3, 2017 10:48 AM
> To: Flashdown <flashdown at data-core.org>; Yuri Voinov <yvoinov at gmail.com>
> Cc: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] ssl bump and chrome 58
>
> [This sender failed our fraud detection checks and may not be who they appear to be. Learn about spoofing at http://aka.ms/LearnAboutSpoofing]
>
> Hello all,
>
> The following steps give in Chrome 58 the "Your connection is not private" error with "NET::ERR_CERT_COMMON_NAME_INVALID" and "missing_subjectAltName" error:
>
> (peek-an-splice bumping squid 3.5.23_1 as in https://docs.diladele.com/howtos/build_squid_ubuntu16/index.html)
>
> 1. Open Chrome 58+
> 2. Type some non existing domain name like "https://www.asdlajsdfl.com" (note the httpS:// schema) 3. See the missing_subjectAltName error.
>
> Correct behavior would be Squid generating faked certificate for the domain name "www.asdlajsdfl.com" *with* subjectAltName extension set to "www.asdlajsdfl.com".
>
> So question is - does anyone know if this is already existing bug or shall I file one?
> May be it is a feature?
>
> Best regards,
> Rafael
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Flashdown
> Sent: Thursday, April 27, 2017 6:42 PM
> To: Yuri Voinov <yvoinov at gmail.com>
> Cc: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] ssl bump and chrome 58
>
> I've tested the registry setting and it worked out. You can copy the below lines in a .reg file and execute it.
>
> Windows Registry Editor Version 5.00
>
> [HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Google\Chrome]
> "EnableCommonNameFallbackForLocalAnchors"=dword:00000001
>
>
> Best regards,
> Flashdown
>
> Am 2017-04-27 18:34, schrieb Flashdown:
>> Hello together,
>>
>> here is a workaround that you could use in the meanwhile.
>>
>> https://www.chromium.org/administrators/policy-list-3#EnableCommonName
>> FallbackForLocalAnchors
>>
>> Source:
>> https://www.chromium.org/administrators/policy-list-3#EnableCommonName
>> FallbackForLocalAnchors
>>>>>>> BEGIN
>> EnableCommonNameFallbackForLocalAnchors
>> Whether to allow certificates issued by local trust anchors that are
>> missing the subjectAlternativeName extension
>>
>> Data type:
>>      Boolean [Windows:REG_DWORD]
>> Windows registry location:
>>
>> Software\Policies\Google\Chrome\EnableCommonNameFallbackForLocalAnchor
>> s
>> Mac/Linux preference name:
>>      EnableCommonNameFallbackForLocalAnchors
>> Android restriction name:
>>      EnableCommonNameFallbackForLocalAnchors
>> Supported on:
>>
>>          Google Chrome (Linux, Mac, Windows) since version 58 until
>> version 65
>>          Google Chrome OS (Google Chrome OS) since version 58 until
>> version 65
>>          Google Chrome (Android) since version 58 until version 65
>>
>> Supported features:
>>      Dynamic Policy Refresh: Yes, Per Profile: No
>> Description:
>>
>>      When this setting is enabled, Google Chrome will use the
>> commonName of a server certificate to match a hostname if the
>> certificate is missing a subjectAlternativeName extension, as long as
>> it successfully validates and chains to a locally-installed CA
>> certificates.
>>
>>      Note that this is not recommended, as this may allow bypassing the
>> nameConstraints extension that restricts the hostnames that a given
>> certificate can be authorized for.
>>
>>      If this policy is not set, or is set to false, server certificates
>> that lack a subjectAlternativeName extension containing either a DNS
>> name or IP address will not be trusted.
>> Example value:
>>      0x00000000 (Windows), false (Linux), false (Android), <false />
>> (Mac)
>> <<<<<<<<<<<< END
>>
>>
>>
>> Am 2017-04-27 18:16, schrieb Flashdown:
>>> Hello together,
>>>
>>> Suddenly I am facing the same issue when users Chrome has been
>>> updated to V58. I am running Squid 3.5.23.
>>>
>>> This is the reason:
>>> https://www.thesslstore.com/blog/security-changes-in-chrome-58/
>>> Short: Common Name Support Removed in Chrome 58 and Squid does not
>>> create certs with DNS-Alternatives names in it. Because of that it
>>> fails.
>>>
>>> Chrome says:
>>> 1. Subject Alternative Name Missing - The certificate for this site
>>> does not contain a Subject Alternative Name extension containing a
>>> domain name or IP address.
>>> 2. Certificate Error - There are issues with the site's certificate
>>> chain (net::ERR_CERT_COMMON_NAME_INVALID).
>>>
>>> Can we get Squid to add the DNS-Alternative Name to the generated
>>> certs? Since this is what I believe is now required in Chrome 58+
>>>
>>> Best regards,
>>> Enrico
>>>
>>>
>>> Am 2017-04-21 15:35, schrieb Yuri Voinov:
>>>> I see no problem with it on all five SSL Bump-aware servers with new
>>>> Chrome. So fare so good.
>>>>
>>>>
>>>> 21.04.2017 18:29, Marko Cupa? ?????:
>>>>> Hi,
>>>>>
>>>>> I have squid setup with ssl bump which worked fine, but since I
>>>>> updated chrome to 58 it won't display any https sites, throwing
>>>>> NTT:ERR_CERT_COMMON_NAME_INVALID. https sites still work in
>>>>> previous chrome version, as well as in IE.
>>>>>
>>>>> Anything I can do in squid config to get ssl-bumped sites in chrome
>>>>> again?
>>>>>
>>>>> Thank you in advance,
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From rafael.akchurin at diladele.com  Wed May  3 10:32:19 2017
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Wed, 3 May 2017 10:32:19 +0000
Subject: [squid-users] ssl bump and chrome 58
In-Reply-To: <cba4a78b-2189-6753-0835-3921b5c71ec4@gmail.com>
References: <20170421142934.241ce2cf@efreet-freebsd.kappastar.com>
 <f822ef50-731e-ec12-3b1f-144ce1f48347@gmail.com>
 <e12127951db2c3923f57ba0b4af8de78@data-core.org>
 <3e7c47a85eca33d1f2cd3331ab782857@data-core.org>
 <a6ee678d1e41241f678c71380c05862a@data-core.org>
 <DB6PR0401MB2680322D60ED3DFFC11197FE8F160@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <DB6PR0401MB26806D92D0A27750DFEE883E8F160@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <cba4a78b-2189-6753-0835-3921b5c71ec4@gmail.com>
Message-ID: <DB6PR0401MB2680D31C829B015620D814798F160@DB6PR0401MB2680.eurprd04.prod.outlook.com>

And on 3.5 too?

-----Original Message-----
From: Yuri [mailto:yvoinov at gmail.com] 
Sent: Wednesday, May 3, 2017 12:30 PM
To: Rafael Akchurin <rafael.akchurin at diladele.com>; Flashdown <flashdown at data-core.org>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] ssl bump and chrome 58

Mountain brake, Raf :-)

Fixed yesterday, already running on productions (on my side) ;-)


03.05.2017 15:05, Rafael Akchurin ?????:
> Sorry disregard - should practice my  google fu better - see 
> http://bugs.squid-cache.org/show_bug.cgi?id=4711
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
> On Behalf Of Rafael Akchurin
> Sent: Wednesday, May 3, 2017 10:48 AM
> To: Flashdown <flashdown at data-core.org>; Yuri Voinov 
> <yvoinov at gmail.com>
> Cc: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] ssl bump and chrome 58
>
> [This sender failed our fraud detection checks and may not be who they 
> appear to be. Learn about spoofing at 
> http://aka.ms/LearnAboutSpoofing]
>
> Hello all,
>
> The following steps give in Chrome 58 the "Your connection is not private" error with "NET::ERR_CERT_COMMON_NAME_INVALID" and "missing_subjectAltName" error:
>
> (peek-an-splice bumping squid 3.5.23_1 as in 
> https://docs.diladele.com/howtos/build_squid_ubuntu16/index.html)
>
> 1. Open Chrome 58+
> 2. Type some non existing domain name like "https://www.asdlajsdfl.com" (note the httpS:// schema) 3. See the missing_subjectAltName error.
>
> Correct behavior would be Squid generating faked certificate for the domain name "www.asdlajsdfl.com" *with* subjectAltName extension set to "www.asdlajsdfl.com".
>
> So question is - does anyone know if this is already existing bug or shall I file one?
> May be it is a feature?
>
> Best regards,
> Rafael
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
> On Behalf Of Flashdown
> Sent: Thursday, April 27, 2017 6:42 PM
> To: Yuri Voinov <yvoinov at gmail.com>
> Cc: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] ssl bump and chrome 58
>
> I've tested the registry setting and it worked out. You can copy the below lines in a .reg file and execute it.
>
> Windows Registry Editor Version 5.00
>
> [HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Google\Chrome]
> "EnableCommonNameFallbackForLocalAnchors"=dword:00000001
>
>
> Best regards,
> Flashdown
>
> Am 2017-04-27 18:34, schrieb Flashdown:
>> Hello together,
>>
>> here is a workaround that you could use in the meanwhile.
>>
>> https://www.chromium.org/administrators/policy-list-3#EnableCommonNam
>> e
>> FallbackForLocalAnchors
>>
>> Source:
>> https://www.chromium.org/administrators/policy-list-3#EnableCommonNam
>> e
>> FallbackForLocalAnchors
>>>>>>> BEGIN
>> EnableCommonNameFallbackForLocalAnchors
>> Whether to allow certificates issued by local trust anchors that are 
>> missing the subjectAlternativeName extension
>>
>> Data type:
>>      Boolean [Windows:REG_DWORD]
>> Windows registry location:
>>
>> Software\Policies\Google\Chrome\EnableCommonNameFallbackForLocalAncho
>> r
>> s
>> Mac/Linux preference name:
>>      EnableCommonNameFallbackForLocalAnchors
>> Android restriction name:
>>      EnableCommonNameFallbackForLocalAnchors
>> Supported on:
>>
>>          Google Chrome (Linux, Mac, Windows) since version 58 until 
>> version 65
>>          Google Chrome OS (Google Chrome OS) since version 58 until 
>> version 65
>>          Google Chrome (Android) since version 58 until version 65
>>
>> Supported features:
>>      Dynamic Policy Refresh: Yes, Per Profile: No
>> Description:
>>
>>      When this setting is enabled, Google Chrome will use the 
>> commonName of a server certificate to match a hostname if the 
>> certificate is missing a subjectAlternativeName extension, as long as 
>> it successfully validates and chains to a locally-installed CA 
>> certificates.
>>
>>      Note that this is not recommended, as this may allow bypassing 
>> the nameConstraints extension that restricts the hostnames that a 
>> given certificate can be authorized for.
>>
>>      If this policy is not set, or is set to false, server 
>> certificates that lack a subjectAlternativeName extension containing 
>> either a DNS name or IP address will not be trusted.
>> Example value:
>>      0x00000000 (Windows), false (Linux), false (Android), <false />
>> (Mac)
>> <<<<<<<<<<<< END
>>
>>
>>
>> Am 2017-04-27 18:16, schrieb Flashdown:
>>> Hello together,
>>>
>>> Suddenly I am facing the same issue when users Chrome has been 
>>> updated to V58. I am running Squid 3.5.23.
>>>
>>> This is the reason:
>>> https://www.thesslstore.com/blog/security-changes-in-chrome-58/
>>> Short: Common Name Support Removed in Chrome 58 and Squid does not 
>>> create certs with DNS-Alternatives names in it. Because of that it 
>>> fails.
>>>
>>> Chrome says:
>>> 1. Subject Alternative Name Missing - The certificate for this site 
>>> does not contain a Subject Alternative Name extension containing a 
>>> domain name or IP address.
>>> 2. Certificate Error - There are issues with the site's certificate 
>>> chain (net::ERR_CERT_COMMON_NAME_INVALID).
>>>
>>> Can we get Squid to add the DNS-Alternative Name to the generated 
>>> certs? Since this is what I believe is now required in Chrome 58+
>>>
>>> Best regards,
>>> Enrico
>>>
>>>
>>> Am 2017-04-21 15:35, schrieb Yuri Voinov:
>>>> I see no problem with it on all five SSL Bump-aware servers with 
>>>> new Chrome. So fare so good.
>>>>
>>>>
>>>> 21.04.2017 18:29, Marko Cupa? ?????:
>>>>> Hi,
>>>>>
>>>>> I have squid setup with ssl bump which worked fine, but since I 
>>>>> updated chrome to 58 it won't display any https sites, throwing 
>>>>> NTT:ERR_CERT_COMMON_NAME_INVALID. https sites still work in 
>>>>> previous chrome version, as well as in IE.
>>>>>
>>>>> Anything I can do in squid config to get ssl-bumped sites in 
>>>>> chrome again?
>>>>>
>>>>> Thank you in advance,
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From yvoinov at gmail.com  Wed May  3 10:33:01 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 3 May 2017 16:33:01 +0600
Subject: [squid-users] ssl bump and chrome 58
In-Reply-To: <DB6PR0401MB2680D31C829B015620D814798F160@DB6PR0401MB2680.eurprd04.prod.outlook.com>
References: <20170421142934.241ce2cf@efreet-freebsd.kappastar.com>
 <f822ef50-731e-ec12-3b1f-144ce1f48347@gmail.com>
 <e12127951db2c3923f57ba0b4af8de78@data-core.org>
 <3e7c47a85eca33d1f2cd3331ab782857@data-core.org>
 <a6ee678d1e41241f678c71380c05862a@data-core.org>
 <DB6PR0401MB2680322D60ED3DFFC11197FE8F160@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <DB6PR0401MB26806D92D0A27750DFEE883E8F160@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <cba4a78b-2189-6753-0835-3921b5c71ec4@gmail.com>
 <DB6PR0401MB2680D31C829B015620D814798F160@DB6PR0401MB2680.eurprd04.prod.outlook.com>
Message-ID: <1ad88514-4006-9f05-796e-2fcf5745ad34@gmail.com>

Exactly.


03.05.2017 16:32, Rafael Akchurin ?????:
> And on 3.5 too?
>
> -----Original Message-----
> From: Yuri [mailto:yvoinov at gmail.com]
> Sent: Wednesday, May 3, 2017 12:30 PM
> To: Rafael Akchurin <rafael.akchurin at diladele.com>; Flashdown <flashdown at data-core.org>
> Cc: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] ssl bump and chrome 58
>
> Mountain brake, Raf :-)
>
> Fixed yesterday, already running on productions (on my side) ;-)
>
>
> 03.05.2017 15:05, Rafael Akchurin ?????:
>> Sorry disregard - should practice my  google fu better - see
>> http://bugs.squid-cache.org/show_bug.cgi?id=4711
>>
>> -----Original Message-----
>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
>> On Behalf Of Rafael Akchurin
>> Sent: Wednesday, May 3, 2017 10:48 AM
>> To: Flashdown <flashdown at data-core.org>; Yuri Voinov
>> <yvoinov at gmail.com>
>> Cc: squid-users at lists.squid-cache.org
>> Subject: Re: [squid-users] ssl bump and chrome 58
>>
>> [This sender failed our fraud detection checks and may not be who they
>> appear to be. Learn about spoofing at
>> http://aka.ms/LearnAboutSpoofing]
>>
>> Hello all,
>>
>> The following steps give in Chrome 58 the "Your connection is not private" error with "NET::ERR_CERT_COMMON_NAME_INVALID" and "missing_subjectAltName" error:
>>
>> (peek-an-splice bumping squid 3.5.23_1 as in
>> https://docs.diladele.com/howtos/build_squid_ubuntu16/index.html)
>>
>> 1. Open Chrome 58+
>> 2. Type some non existing domain name like "https://www.asdlajsdfl.com" (note the httpS:// schema) 3. See the missing_subjectAltName error.
>>
>> Correct behavior would be Squid generating faked certificate for the domain name "www.asdlajsdfl.com" *with* subjectAltName extension set to "www.asdlajsdfl.com".
>>
>> So question is - does anyone know if this is already existing bug or shall I file one?
>> May be it is a feature?
>>
>> Best regards,
>> Rafael
>>
>>
>> -----Original Message-----
>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
>> On Behalf Of Flashdown
>> Sent: Thursday, April 27, 2017 6:42 PM
>> To: Yuri Voinov <yvoinov at gmail.com>
>> Cc: squid-users at lists.squid-cache.org
>> Subject: Re: [squid-users] ssl bump and chrome 58
>>
>> I've tested the registry setting and it worked out. You can copy the below lines in a .reg file and execute it.
>>
>> Windows Registry Editor Version 5.00
>>
>> [HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Google\Chrome]
>> "EnableCommonNameFallbackForLocalAnchors"=dword:00000001
>>
>>
>> Best regards,
>> Flashdown
>>
>> Am 2017-04-27 18:34, schrieb Flashdown:
>>> Hello together,
>>>
>>> here is a workaround that you could use in the meanwhile.
>>>
>>> https://www.chromium.org/administrators/policy-list-3#EnableCommonNam
>>> e
>>> FallbackForLocalAnchors
>>>
>>> Source:
>>> https://www.chromium.org/administrators/policy-list-3#EnableCommonNam
>>> e
>>> FallbackForLocalAnchors
>>>>>>>> BEGIN
>>> EnableCommonNameFallbackForLocalAnchors
>>> Whether to allow certificates issued by local trust anchors that are
>>> missing the subjectAlternativeName extension
>>>
>>> Data type:
>>>       Boolean [Windows:REG_DWORD]
>>> Windows registry location:
>>>
>>> Software\Policies\Google\Chrome\EnableCommonNameFallbackForLocalAncho
>>> r
>>> s
>>> Mac/Linux preference name:
>>>       EnableCommonNameFallbackForLocalAnchors
>>> Android restriction name:
>>>       EnableCommonNameFallbackForLocalAnchors
>>> Supported on:
>>>
>>>           Google Chrome (Linux, Mac, Windows) since version 58 until
>>> version 65
>>>           Google Chrome OS (Google Chrome OS) since version 58 until
>>> version 65
>>>           Google Chrome (Android) since version 58 until version 65
>>>
>>> Supported features:
>>>       Dynamic Policy Refresh: Yes, Per Profile: No
>>> Description:
>>>
>>>       When this setting is enabled, Google Chrome will use the
>>> commonName of a server certificate to match a hostname if the
>>> certificate is missing a subjectAlternativeName extension, as long as
>>> it successfully validates and chains to a locally-installed CA
>>> certificates.
>>>
>>>       Note that this is not recommended, as this may allow bypassing
>>> the nameConstraints extension that restricts the hostnames that a
>>> given certificate can be authorized for.
>>>
>>>       If this policy is not set, or is set to false, server
>>> certificates that lack a subjectAlternativeName extension containing
>>> either a DNS name or IP address will not be trusted.
>>> Example value:
>>>       0x00000000 (Windows), false (Linux), false (Android), <false />
>>> (Mac)
>>> <<<<<<<<<<<< END
>>>
>>>
>>>
>>> Am 2017-04-27 18:16, schrieb Flashdown:
>>>> Hello together,
>>>>
>>>> Suddenly I am facing the same issue when users Chrome has been
>>>> updated to V58. I am running Squid 3.5.23.
>>>>
>>>> This is the reason:
>>>> https://www.thesslstore.com/blog/security-changes-in-chrome-58/
>>>> Short: Common Name Support Removed in Chrome 58 and Squid does not
>>>> create certs with DNS-Alternatives names in it. Because of that it
>>>> fails.
>>>>
>>>> Chrome says:
>>>> 1. Subject Alternative Name Missing - The certificate for this site
>>>> does not contain a Subject Alternative Name extension containing a
>>>> domain name or IP address.
>>>> 2. Certificate Error - There are issues with the site's certificate
>>>> chain (net::ERR_CERT_COMMON_NAME_INVALID).
>>>>
>>>> Can we get Squid to add the DNS-Alternative Name to the generated
>>>> certs? Since this is what I believe is now required in Chrome 58+
>>>>
>>>> Best regards,
>>>> Enrico
>>>>
>>>>
>>>> Am 2017-04-21 15:35, schrieb Yuri Voinov:
>>>>> I see no problem with it on all five SSL Bump-aware servers with
>>>>> new Chrome. So fare so good.
>>>>>
>>>>>
>>>>> 21.04.2017 18:29, Marko Cupa? ?????:
>>>>>> Hi,
>>>>>>
>>>>>> I have squid setup with ssl bump which worked fine, but since I
>>>>>> updated chrome to 58 it won't display any https sites, throwing
>>>>>> NTT:ERR_CERT_COMMON_NAME_INVALID. https sites still work in
>>>>>> previous chrome version, as well as in IE.
>>>>>>
>>>>>> Anything I can do in squid config to get ssl-bumped sites in
>>>>>> chrome again?
>>>>>>
>>>>>> Thank you in advance,
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users



From sam.egerton at ntlworld.com  Wed May  3 10:47:51 2017
From: sam.egerton at ntlworld.com (BurningSky)
Date: Wed, 3 May 2017 03:47:51 -0700 (PDT)
Subject: [squid-users] Passing Windows username to parent proxy
Message-ID: <1493808471375-4682272.post@n4.nabble.com>

Hi,

I have been searching around the web for a while now to try and find a
solution but having not had much luck I was wondering if someone on here
could help.

I have set up a Windows 2008 R2 server running the Diladele pre-complied
Squid 3.5 proxy and am looking to make use of our firewall for URL
filtering. Our firewall allows/denies access to certain web sites by using
the AD group memberships of the Windows end user.

I have managed to get a basic config up and running and am using the line
below to forward the traffic via the proxy setup on our firewall. If I point
the end user machine directly at the firewall then the filtering works but
the firewall doesn't have caching, thus wanting to use Squid.
cache_peer whl-utm1.e2v.com parent 3128 0 no-query default login=PASSTHRU

As I am new to Squid I thought, perhaps naively, that the end user domain
username would automatically be forwarded on with the requests to the parent
but in the parents log file I just seem to see the username of the account
that I have RDPed to the server on, not of the end user machine that the
request is coming from.

Do I need to enable some form of dummy authentication on the Squid proxy and
is this possible when running the Windows based version of the Squid proxy?

Any thoughts would be greatly appreciated!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Passing-Windows-username-to-parent-proxy-tp4682272.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From nil_fergi at hotmail.com  Wed May  3 11:54:18 2017
From: nil_fergi at hotmail.com (Nil Nik)
Date: Wed, 3 May 2017 11:54:18 +0000
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <35f15acb-9b86-edc7-1152-a53dfaabfc22@measurement-factory.com>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
 <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
 <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
 <215c7b2a-f034-5913-f0fe-00c2f4511b72@gmail.com>
 <123f43b6-4d76-9493-32c7-a0b05a794618@treenet.co.nz>
 <73c06bc6-87b6-d8c9-0d93-eeb6645cb1ac@gmail.com>,
 <35f15acb-9b86-edc7-1152-a53dfaabfc22@measurement-factory.com>
Message-ID: <BY1PR10MB03577C3C006CEF30984D393584160@BY1PR10MB0357.namprd10.prod.outlook.com>

Hi,


NO_DEFAULT_CA doesn't help. Still goes in GB. Can anyone tell me area so that i can work on?


Regards,

Nil


________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Alex Rousskov <rousskov at measurement-factory.com>
Sent: Wednesday, April 26, 2017 7:37 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Huge memory required for squid 3.5

On 04/26/2017 09:35 AM, Yuri Voinov wrote:

> This is openssl issue or squid's?

AFAIK, the underlying issue (i.e., bug #4005) is mostly a Squid problem:
Squid is caching SSL contexts (instead of certificates) and does a poor
job maintaining that cache.

Earlier OpenSSL versions (that had to be used when the original code was
written) complicated solving this problem. OpenSSL v1.0.1+ added APIs
that simplify some aspects of the anticipated fix. Certain OpenSSL
aspects will continue to hurt Squid, even with OpenSSL v1.0.1, but if
you want to blame a single project (instead of both), blame Squid.


> Why sessions can't share CA's data cached in memory? shared_ptr invented
> already.

OpenSSL knew how to share things well before std::shared_ptr became
available. However, it is the responsibility of the application to tell
OpenSSL what to create from scratch and what to share. A part of the
problem is that Squid tells OpenSSL to create many large things from
scratch and then caches those large things while underestimating their
size by several(?) orders of magnitude (and probably also missing many
cache hits).

More details, including the difference between problems associated with
from-client and to-server connections, are documented in the "Memory
Usage" section of http://wiki.squid-cache.org/Features/SslBump
Features/SslBump - Squid Web Proxy Wiki<http://wiki.squid-cache.org/Features/SslBump>
wiki.squid-cache.org
Squid-in-the-middle decryption and encryption of straight CONNECT and transparently redirected SSL traffic, using configurable CA certificates.



FWIW, we have spent a lot of resources on triaging this problem and
drafting possible solutions (in various overlapping areas), but there is
currently no sponsor to finalize and implement any of the fixes. AFAIK,
bug #4005 is stuck.

I am glad that NO_DEFAULT_CA helps mitigate some of the problems in some
environments.


HTH,

Alex.


> 26.04.2017 9:08, Amos Jeffries ?????:
>> On 26/04/17 10:53, Yuri Voinov wrote:
>>> Ok, but how NO_DEFAULT_CA should help with this?
>>
>> It prevents OpenSSL copying that 1MB into each incoming client
>> connections memory. The CAs are only useful there when you have some
>> of the global CAs as root for client certificates - in which case you
>> still only want to trust the roots you paid for service and not all of
>> them.
>>
>> Just something to try if there are huge memory issues with TLS/SSL
>> proxying. The default behaviour is fixed for Squid-4 with the config
>> options changes. But due to being a major surprise for anyone already
>> relying on global roots for client certs it remains a problem in 3.5.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users


>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users


>

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/146effbe/attachment.htm>

From yvoinov at gmail.com  Wed May  3 11:55:29 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 3 May 2017 17:55:29 +0600
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <BY1PR10MB03577C3C006CEF30984D393584160@BY1PR10MB0357.namprd10.prod.outlook.com>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
 <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
 <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
 <215c7b2a-f034-5913-f0fe-00c2f4511b72@gmail.com>
 <123f43b6-4d76-9493-32c7-a0b05a794618@treenet.co.nz>
 <73c06bc6-87b6-d8c9-0d93-eeb6645cb1ac@gmail.com>
 <35f15acb-9b86-edc7-1152-a53dfaabfc22@measurement-factory.com>
 <BY1PR10MB03577C3C006CEF30984D393584160@BY1PR10MB0357.namprd10.prod.outlook.com>
Message-ID: <5fb34039-8c41-819a-e57f-d75d426a59ee@gmail.com>

How big disk cache(s) and how it full?


03.05.2017 17:54, Nil Nik ?????:
> Hi,
>
>
> NO_DEFAULT_CA doesn't help. Still goes in GB. Can anyone tell me area 
> so that i can work on?
>
>
> Regards,
>
> Nil
>
>
> ------------------------------------------------------------------------
> *From:* squid-users <squid-users-bounces at lists.squid-cache.org> on 
> behalf of Alex Rousskov <rousskov at measurement-factory.com>
> *Sent:* Wednesday, April 26, 2017 7:37 PM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Huge memory required for squid 3.5
> On 04/26/2017 09:35 AM, Yuri Voinov wrote:
>
> > This is openssl issue or squid's?
>
> AFAIK, the underlying issue (i.e., bug #4005) is mostly a Squid problem:
> Squid is caching SSL contexts (instead of certificates) and does a poor
> job maintaining that cache.
>
> Earlier OpenSSL versions (that had to be used when the original code was
> written) complicated solving this problem. OpenSSL v1.0.1+ added APIs
> that simplify some aspects of the anticipated fix. Certain OpenSSL
> aspects will continue to hurt Squid, even with OpenSSL v1.0.1, but if
> you want to blame a single project (instead of both), blame Squid.
>
>
> > Why sessions can't share CA's data cached in memory? shared_ptr invented
> > already.
>
> OpenSSL knew how to share things well before std::shared_ptr became
> available. However, it is the responsibility of the application to tell
> OpenSSL what to create from scratch and what to share. A part of the
> problem is that Squid tells OpenSSL to create many large things from
> scratch and then caches those large things while underestimating their
> size by several(?) orders of magnitude (and probably also missing many
> cache hits).
>
> More details, including the difference between problems associated with
> from-client and to-server connections, are documented in the "Memory
> Usage" section of http://wiki.squid-cache.org/Features/SslBump 
> <http://wiki.squid-cache.org/Features/SslBump>
> Features/SslBump - Squid Web Proxy Wiki 
> <http://wiki.squid-cache.org/Features/SslBump>
> wiki.squid-cache.org
> Squid-in-the-middle decryption and encryption of straight CONNECT and 
> transparently redirected SSL traffic, using configurable CA certificates.
>
>
>
> FWIW, we have spent a lot of resources on triaging this problem and
> drafting possible solutions (in various overlapping areas), but there is
> currently no sponsor to finalize and implement any of the fixes. AFAIK,
> bug #4005 is stuck.
>
> I am glad that NO_DEFAULT_CA helps mitigate some of the problems in some
> environments.
>
>
> HTH,
>
> Alex.
>
>
> > 26.04.2017 9:08, Amos Jeffries ?????:
> >> On 26/04/17 10:53, Yuri Voinov wrote:
> >>> Ok, but how NO_DEFAULT_CA should help with this?
> >>
> >> It prevents OpenSSL copying that 1MB into each incoming client
> >> connections memory. The CAs are only useful there when you have some
> >> of the global CAs as root for client certificates - in which case you
> >> still only want to trust the roots you paid for service and not all of
> >> them.
> >>
> >> Just something to try if there are huge memory issues with TLS/SSL
> >> proxying. The default behaviour is fixed for Squid-4 with the config
> >> options changes. But due to being a major surprise for anyone already
> >> relying on global roots for client certs it remains a problem in 3.5.
> >>
> >> Amos
> >>
> >> _______________________________________________
> >> squid-users mailing list
> >> squid-users at lists.squid-cache.org
> >> http://lists.squid-cache.org/listinfo/squid-users 
> <http://lists.squid-cache.org/listinfo/squid-users>
> squid-users Info Page <http://lists.squid-cache.org/listinfo/squid-users>
> lists.squid-cache.org
> squid-users -- General discussion relating to Squid. The membership of 
> this list is thousands of Squid users from around the world About 
> squid-users
>
>
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users 
> <http://lists.squid-cache.org/listinfo/squid-users>
> squid-users Info Page <http://lists.squid-cache.org/listinfo/squid-users>
> lists.squid-cache.org
> squid-users -- General discussion relating to Squid. The membership of 
> this list is thousands of Squid users from around the world About 
> squid-users
>
>
> >
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> squid-users Info Page <http://lists.squid-cache.org/listinfo/squid-users>
> lists.squid-cache.org
> squid-users -- General discussion relating to Squid. The membership of 
> this list is thousands of Squid users from around the world About 
> squid-users
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/2b2c8eee/attachment.htm>

From squid3 at treenet.co.nz  Wed May  3 13:18:45 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 4 May 2017 01:18:45 +1200
Subject: [squid-users] limit access with acl only based on source and
 destination domain
In-Reply-To: <982145555.1000130.1493772004922@mail.yahoo.com>
References: <982145555.1000130.1493772004922.ref@mail.yahoo.com>
 <982145555.1000130.1493772004922@mail.yahoo.com>
Message-ID: <a49a4f3e-73a4-f84f-f356-097743f14d0d@treenet.co.nz>

On 03/05/17 12:40, Blaxton wrote:
> Hi
>
> I am trying to limit the out bound connection based on list of domain 
> names defined
> in srcdomain and dstdomain.
>
> Here is acl :
>
> acl From_Source_Domains srcdomain domain1 domain2 domain3
> acl To_Destination_Domains dstdomain domain4 domain5 domain6
>
> Now some web site says below considered OR and it is working for me:
> http_access allow From_Source_Domains
> http_access allow To_Destination_Domains
>
> And some web sites saying below considered AND but it is not working 
> for me:
> http_access allow From_Source_Domains To_Destination_Domains
>
> I am assuming since I have not allowed any port, then port should be 
> disabled
> but it is not, on OR of the src and dst domains.

No, ports are not part of that lines rule. There is no enable/disable - 
they are simply irrelevant when processing that line.

Traffic which gets filtered by that line coming from any client whose IP 
address rDNS matches one of the "From_Source_Domains" AND URL contains 
one of the "To_Destination_Domains" gets allowed into Squid.

>
> If add
> acl http_port 80
> http_access allow http_port
>
> Then it allow traffic from any source to any destination if port is 80.
>
> Kind of confusing and need a bit of help.

The "how" is simple:

   http_access lines are processed from top to bottom, left to right. 
First fully matching line wins and its action (allow or deny) happens.

<wiki.squid-cache.org/SquidFaq/OrderIsImportant>
<http://wiki.squid-cache.org/SquidFaq/SquidAcl#The_Basics:_How_the_parts_fit_together>
<http://wiki.squid-cache.org/SquidFaq/SquidAcl#Common_Mistakes>

Amos


From squid3 at treenet.co.nz  Wed May  3 13:26:56 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 4 May 2017 01:26:56 +1200
Subject: [squid-users] Tutorial for better authentication than basic
In-Reply-To: <595899296.566110.1493728836278@mail.yahoo.com>
References: <456739995.1458100.1493644706831.ref@mail.yahoo.com>
 <456739995.1458100.1493644706831@mail.yahoo.com>
 <02b801d2c292$df68d950$9e3a8bf0$@ngtech.co.il>
 <742538244.50351.1493672695826@mail.yahoo.com>
 <c0440ac0-a9a7-8eec-0359-73ffc4fe5af7@treenet.co.nz>
 <595899296.566110.1493728836278@mail.yahoo.com>
Message-ID: <c5ac10a9-da7e-a365-24b0-7ddb7e9a3549@treenet.co.nz>

On 03/05/17 00:40, j m wrote:
> Here's a question:  if I use SSL or TLS encryption between squid and 
> browser, would even the basic auth login be encrypted?
>

All of the HTTP going to the proxy would be encrypted.


> I'm thinking that instead of trying to use the proxy to SSH through, I 
> could use something like shellinabox over the proxy if the link is 
> encrypted.  This would be much easier and serve the purpose.
>
> According to this link, it seems pretty straightforward to get Firefox 
> or Chrome to do it: wiki.squid-cache.org/Features/HTTPS#Chrome 
> <http://wiki.squid-cache.org/Features/HTTPS#Chrome>
>
> Would the default config located at 
> wiki.squid-cache.org/SquidFaq/ConfiguringSquid#Squid-3.5_default_config 
> <http://wiki.squid-cache.org/SquidFaq/ConfiguringSquid#Squid-3.5_default_config> 
> allow this?
>

The answer there depends on what the traffic is and what it needs from 
the proxy. Default config for Squid allows HTTP clients to use the 
proxy, that is all.

Amos



From squid3 at treenet.co.nz  Wed May  3 13:54:52 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 4 May 2017 01:54:52 +1200
Subject: [squid-users] Passing Windows username to parent proxy
In-Reply-To: <1493808471375-4682272.post@n4.nabble.com>
References: <1493808471375-4682272.post@n4.nabble.com>
Message-ID: <d5cc395d-65cc-e2c3-5811-4b61e33771b6@treenet.co.nz>

On 03/05/17 22:47, BurningSky wrote:
> Hi,
>
> I have been searching around the web for a while now to try and find a
> solution but having not had much luck I was wondering if someone on here
> could help.
>
> I have set up a Windows 2008 R2 server running the Diladele pre-complied
> Squid 3.5 proxy and am looking to make use of our firewall for URL
> filtering. Our firewall allows/denies access to certain web sites by using
> the AD group memberships of the Windows end user.
>
> I have managed to get a basic config up and running and am using the line
> below to forward the traffic via the proxy setup on our firewall. If I point
> the end user machine directly at the firewall then the filtering works but
> the firewall doesn't have caching, thus wanting to use Squid.
> cache_peer whl-utm1.e2v.com parent 3128 0 no-query default login=PASSTHRU
>
> As I am new to Squid I thought, perhaps naively, that the end user domain
> username would automatically be forwarded on with the requests to the parent
> but in the parents log file I just seem to see the username of the account
> that I have RDPed to the server on, not of the end user machine that the
> request is coming from.

Not sure exactly what you mean by "RPDd", but you can only authenticate 
one user at a time with connection based authentication.

The login=PASSTHRU is correct for passing whatever the clients sends 
through to the parent proxy and vice versa for the parents response auth 
headers. Squid must not itself perform any type of authentication with 
either client, or the parents cache_peer TCP connections.

Amos



From sam.egerton at ntlworld.com  Wed May  3 14:19:39 2017
From: sam.egerton at ntlworld.com (BurningSky)
Date: Wed, 3 May 2017 07:19:39 -0700 (PDT)
Subject: [squid-users] Passing Windows username to parent proxy
In-Reply-To: <d5cc395d-65cc-e2c3-5811-4b61e33771b6@treenet.co.nz>
References: <1493808471375-4682272.post@n4.nabble.com>
 <d5cc395d-65cc-e2c3-5811-4b61e33771b6@treenet.co.nz>
Message-ID: <F665DADF-0840-4194-A238-9B77804EDAE1@ntlworld.com>

Hi Amos,

Thanks for the reply. Sorry, what I meant by that was that I was logged into the Squid Windows server using remote desktop so that I could edit the configuration so that is separate from the machine trying to use Squid a a proxy.

So it would seem like the issue is with the firewall from what you're saying? Using the most basic Squid config pointing it at the firewall as a parent should be all I need to do for the Windows username to be passed through to the firewall?

Thanks,
Sam 

> On 3 May 2017, at 14:43, Amos Jeffries [via Squid Web Proxy Cache] <ml+s1019090n4682277h30 at n4.nabble.com> wrote:
> 
> On 03/05/17 22:47, BurningSky wrote:
> 
> > Hi, 
> > 
> > I have been searching around the web for a while now to try and find a 
> > solution but having not had much luck I was wondering if someone on here 
> > could help. 
> > 
> > I have set up a Windows 2008 R2 server running the Diladele pre-complied 
> > Squid 3.5 proxy and am looking to make use of our firewall for URL 
> > filtering. Our firewall allows/denies access to certain web sites by using 
> > the AD group memberships of the Windows end user. 
> > 
> > I have managed to get a basic config up and running and am using the line 
> > below to forward the traffic via the proxy setup on our firewall. If I point 
> > the end user machine directly at the firewall then the filtering works but 
> > the firewall doesn't have caching, thus wanting to use Squid. 
> > cache_peer whl-utm1.e2v.com parent 3128 0 no-query default login=PASSTHRU 
> > 
> > As I am new to Squid I thought, perhaps naively, that the end user domain 
> > username would automatically be forwarded on with the requests to the parent 
> > but in the parents log file I just seem to see the username of the account 
> > that I have RDPed to the server on, not of the end user machine that the 
> > request is coming from.
> 
> Not sure exactly what you mean by "RPDd", but you can only authenticate 
> one user at a time with connection based authentication. 
> 
> The login=PASSTHRU is correct for passing whatever the clients sends 
> through to the parent proxy and vice versa for the parents response auth 
> headers. Squid must not itself perform any type of authentication with 
> either client, or the parents cache_peer TCP connections. 
> 
> Amos 
> 
> _______________________________________________ 
> squid-users mailing list 
> [hidden email] 
> http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> If you reply to this email, your message will be added to the discussion below:
> http://squid-web-proxy-cache.1019090.n4.nabble.com/Passing-Windows-username-to-parent-proxy-tp4682272p4682277.html
> To unsubscribe from Passing Windows username to parent proxy, click here.
> NAML




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Passing-Windows-username-to-parent-proxy-tp4682272p4682278.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From nil_fergi at hotmail.com  Wed May  3 15:44:45 2017
From: nil_fergi at hotmail.com (Nil Nik)
Date: Wed, 3 May 2017 15:44:45 +0000
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <5fb34039-8c41-819a-e57f-d75d426a59ee@gmail.com>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
 <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
 <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
 <215c7b2a-f034-5913-f0fe-00c2f4511b72@gmail.com>
 <123f43b6-4d76-9493-32c7-a0b05a794618@treenet.co.nz>
 <73c06bc6-87b6-d8c9-0d93-eeb6645cb1ac@gmail.com>
 <35f15acb-9b86-edc7-1152-a53dfaabfc22@measurement-factory.com>
 <BY1PR10MB03577C3C006CEF30984D393584160@BY1PR10MB0357.namprd10.prod.outlook.com>,
 <5fb34039-8c41-819a-e57f-d75d426a59ee@gmail.com>
Message-ID: <BY1PR10MB0357ECF69FE367088AF5601D84160@BY1PR10MB0357.namprd10.prod.outlook.com>

Hi,


Its not disk cache, its due to in memory SSL context.


Nil

From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Yuri <yvoinov at gmail.com>
Sent: Wednesday, May 3, 2017 11:55 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Huge memory required for squid 3.5


How big disk cache(s) and how it full?

03.05.2017 17:54, Nil Nik ?????:
Hi,


NO_DEFAULT_CA doesn't help. Still goes in GB. Can anyone tell me area so that i can work on?


Regards,

Nil


________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org><mailto:squid-users-bounces at lists.squid-cache.org> on behalf of Alex Rousskov <rousskov at measurement-factory.com><mailto:rousskov at measurement-factory.com>
Sent: Wednesday, April 26, 2017 7:37 PM
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Huge memory required for squid 3.5

On 04/26/2017 09:35 AM, Yuri Voinov wrote:

> This is openssl issue or squid's?

AFAIK, the underlying issue (i.e., bug #4005) is mostly a Squid problem:
Squid is caching SSL contexts (instead of certificates) and does a poor
job maintaining that cache.

Earlier OpenSSL versions (that had to be used when the original code was
written) complicated solving this problem. OpenSSL v1.0.1+ added APIs
that simplify some aspects of the anticipated fix. Certain OpenSSL
aspects will continue to hurt Squid, even with OpenSSL v1.0.1, but if
you want to blame a single project (instead of both), blame Squid.


> Why sessions can't share CA's data cached in memory? shared_ptr invented
> already.

OpenSSL knew how to share things well before std::shared_ptr became
available. However, it is the responsibility of the application to tell
OpenSSL what to create from scratch and what to share. A part of the
problem is that Squid tells OpenSSL to create many large things from
scratch and then caches those large things while underestimating their
size by several(?) orders of magnitude (and probably also missing many
cache hits).

More details, including the difference between problems associated with
from-client and to-server connections, are documented in the "Memory
Usage" section of http://wiki.squid-cache.org/Features/SslBump
Features/SslBump - Squid Web Proxy Wiki<http://wiki.squid-cache.org/Features/SslBump>
wiki.squid-cache.org
Squid-in-the-middle decryption and encryption of straight CONNECT and transparently redirected SSL traffic, using configurable CA certificates.



FWIW, we have spent a lot of resources on triaging this problem and
drafting possible solutions (in various overlapping areas), but there is
currently no sponsor to finalize and implement any of the fixes. AFAIK,
bug #4005 is stuck.

I am glad that NO_DEFAULT_CA helps mitigate some of the problems in some
environments.


HTH,

Alex.


> 26.04.2017 9:08, Amos Jeffries ?????:
>> On 26/04/17 10:53, Yuri Voinov wrote:
>>> Ok, but how NO_DEFAULT_CA should help with this?
>>
>> It prevents OpenSSL copying that 1MB into each incoming client
>> connections memory. The CAs are only useful there when you have some
>> of the global CAs as root for client certificates - in which case you
>> still only want to trust the roots you paid for service and not all of
>> them.
>>
>> Just something to try if there are huge memory issues with TLS/SSL
>> proxying. The default behaviour is fixed for Squid-4 with the config
>> options changes. But due to being a major surprise for anyone already
>> relying on global roots for client certs it remains a problem in 3.5.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
>> http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users


>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
> http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users


>

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users





_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/a2bd95a4/attachment.htm>

From yvoinov at gmail.com  Wed May  3 15:47:08 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 3 May 2017 21:47:08 +0600
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <BY1PR10MB0357ECF69FE367088AF5601D84160@BY1PR10MB0357.namprd10.prod.outlook.com>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
 <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
 <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
 <215c7b2a-f034-5913-f0fe-00c2f4511b72@gmail.com>
 <123f43b6-4d76-9493-32c7-a0b05a794618@treenet.co.nz>
 <73c06bc6-87b6-d8c9-0d93-eeb6645cb1ac@gmail.com>
 <35f15acb-9b86-edc7-1152-a53dfaabfc22@measurement-factory.com>
 <BY1PR10MB03577C3C006CEF30984D393584160@BY1PR10MB0357.namprd10.prod.outlook.com>
 <5fb34039-8c41-819a-e57f-d75d426a59ee@gmail.com>
 <BY1PR10MB0357ECF69FE367088AF5601D84160@BY1PR10MB0357.namprd10.prod.outlook.com>
Message-ID: <4d23dfe0-6015-c622-745b-0ec1394a6150@gmail.com>

You sure?


http://wiki.squid-cache.org/SquidFaq/SquidMemory


03.05.2017 21:44, Nil Nik ?????:
>
> Hi,
>
>
> Its not disk cache, its due to in memory SSL context.
>
>
> Nil
>
>
> *From:* squid-users <squid-users-bounces at lists.squid-cache.org> on
> behalf of Yuri <yvoinov at gmail.com>
> *Sent:* Wednesday, May 3, 2017 11:55 AM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Huge memory required for squid 3.5
>  
>
> How big disk cache(s) and how it full?
>
>
> 03.05.2017 17:54, Nil Nik ?????:
>> Hi,
>>
>>
>> NO_DEFAULT_CA doesn't help. Still goes in GB. Can anyone tell me area
>> so that i can work on?
>>
>>
>> Regards,
>>
>> Nil
>>
>>
>> ------------------------------------------------------------------------
>> *From:* squid-users <squid-users-bounces at lists.squid-cache.org> on
>> behalf of Alex Rousskov <rousskov at measurement-factory.com>
>> *Sent:* Wednesday, April 26, 2017 7:37 PM
>> *To:* squid-users at lists.squid-cache.org
>> *Subject:* Re: [squid-users] Huge memory required for squid 3.5
>>  
>> On 04/26/2017 09:35 AM, Yuri Voinov wrote:
>>
>> > This is openssl issue or squid's?
>>
>> AFAIK, the underlying issue (i.e., bug #4005) is mostly a Squid problem:
>> Squid is caching SSL contexts (instead of certificates) and does a poor
>> job maintaining that cache.
>>
>> Earlier OpenSSL versions (that had to be used when the original code was
>> written) complicated solving this problem. OpenSSL v1.0.1+ added APIs
>> that simplify some aspects of the anticipated fix. Certain OpenSSL
>> aspects will continue to hurt Squid, even with OpenSSL v1.0.1, but if
>> you want to blame a single project (instead of both), blame Squid.
>>
>>
>> > Why sessions can't share CA's data cached in memory? shared_ptr
>> invented
>> > already.
>>
>> OpenSSL knew how to share things well before std::shared_ptr became
>> available. However, it is the responsibility of the application to tell
>> OpenSSL what to create from scratch and what to share. A part of the
>> problem is that Squid tells OpenSSL to create many large things from
>> scratch and then caches those large things while underestimating their
>> size by several(?) orders of magnitude (and probably also missing many
>> cache hits).
>>
>> More details, including the difference between problems associated with
>> from-client and to-server connections, are documented in the "Memory
>> Usage" section of http://wiki.squid-cache.org/Features/SslBump
>> <http://wiki.squid-cache.org/Features/SslBump>
>> Features/SslBump - Squid Web Proxy Wiki
>> <http://wiki.squid-cache.org/Features/SslBump>
>> wiki.squid-cache.org
>> Squid-in-the-middle decryption and encryption of straight CONNECT and
>> transparently redirected SSL traffic, using configurable CA certificates.
>>
>>
>>
>> FWIW, we have spent a lot of resources on triaging this problem and
>> drafting possible solutions (in various overlapping areas), but there is
>> currently no sponsor to finalize and implement any of the fixes. AFAIK,
>> bug #4005 is stuck.
>>
>> I am glad that NO_DEFAULT_CA helps mitigate some of the problems in some
>> environments.
>>
>>
>> HTH,
>>
>> Alex.
>>
>>
>> > 26.04.2017 9:08, Amos Jeffries ?????:
>> >> On 26/04/17 10:53, Yuri Voinov wrote:
>> >>> Ok, but how NO_DEFAULT_CA should help with this?
>> >>
>> >> It prevents OpenSSL copying that 1MB into each incoming client
>> >> connections memory. The CAs are only useful there when you have some
>> >> of the global CAs as root for client certificates - in which case you
>> >> still only want to trust the roots you paid for service and not all of
>> >> them.
>> >>
>> >> Just something to try if there are huge memory issues with TLS/SSL
>> >> proxying. The default behaviour is fixed for Squid-4 with the config
>> >> options changes. But due to being a major surprise for anyone already
>> >> relying on global roots for client certs it remains a problem in 3.5.
>> >>
>> >> Amos
>> >>
>> >> _______________________________________________
>> >> squid-users mailing list
>> >> squid-users at lists.squid-cache.org
>> >> http://lists.squid-cache.org/listinfo/squid-users
>> squid-users Info Page <http://lists.squid-cache.org/listinfo/squid-users>
>> lists.squid-cache.org
>> squid-users -- General discussion relating to Squid. The membership
>> of this list is thousands of Squid users from around the world About
>> squid-users
>>
>>
>> >
>> >
>> >
>> > _______________________________________________
>> > squid-users mailing list
>> > squid-users at lists.squid-cache.org
>> > http://lists.squid-cache.org/listinfo/squid-users
>> squid-users Info Page <http://lists.squid-cache.org/listinfo/squid-users>
>> lists.squid-cache.org
>> squid-users -- General discussion relating to Squid. The membership
>> of this list is thousands of Squid users from around the world About
>> squid-users
>>
>>
>> >
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>> squid-users Info Page <http://lists.squid-cache.org/listinfo/squid-users>
>> lists.squid-cache.org
>> squid-users -- General discussion relating to Squid. The membership
>> of this list is thousands of Squid users from around the world About
>> squid-users
>>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>

-- 
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/3c65110d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/3c65110d/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/3c65110d/attachment.sig>

From acctforjunk at yahoo.com  Wed May  3 16:57:09 2017
From: acctforjunk at yahoo.com (j m)
Date: Wed, 3 May 2017 16:57:09 +0000 (UTC)
Subject: [squid-users] HTTPS support
References: <1251311337.1946637.1493830629405.ref@mail.yahoo.com>
Message-ID: <1251311337.1946637.1493830629405@mail.yahoo.com>

I wanted to set up a proxy on my home server for use from remote locations to use as a web proxy (of course) and also to run SSH over. ?This means that basic auth is undesirable due to the login being sent in clear text. ?So, someone suggested digest auth, and I was happy. ?But, now I'm finding that PuTTY and WinSCP do not support digest auth. ?And consequently, I haven't found any other SSH clients that support digest. (sigh)
So, I'm back to plan b, and that is to have a secure proxy connection so all browser-to-server communication is encrypted. ?Since SSH over proxy might not be feasible because I don't want to use basic auth, I could use shellinabox if the proxy link is secure. ?So the question is, does anyone know if squid 3.5 on Ubuntu 16.04 supports secure connections? ?From what I've found it does not, although nothing has definitively said one way or another. ?Is there a way to tell? ?I've tried configuring for it and it didn't work, but I have little confidence in my config file for this.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/876bf4a9/attachment.htm>

From rousskov at measurement-factory.com  Wed May  3 17:22:42 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 3 May 2017 11:22:42 -0600
Subject: [squid-users] HTTPS support
In-Reply-To: <1251311337.1946637.1493830629405@mail.yahoo.com>
References: <1251311337.1946637.1493830629405.ref@mail.yahoo.com>
 <1251311337.1946637.1493830629405@mail.yahoo.com>
Message-ID: <9541b1fa-cdf5-1777-0478-eabb36b06379@measurement-factory.com>

On 05/03/2017 10:57 AM, j m wrote:
> I wanted to set up a proxy on my home server for use from remote
> locations to use as a web proxy (of course) and also to run SSH over.

The "ssh" part is unrelated to Squid. Secure ssh separately from Squid.


> This means that basic auth is undesirable due to the login being sent
> in clear text.  So, someone suggested digest auth, and I was happy.
>  But, now I'm finding that PuTTY and WinSCP do not support digest auth.
>  And consequently, I haven't found any other SSH clients that support
> digest. (sigh)

These problems will go away if you stop mixing Squid and ssh. Squid is
HTTP while PuTTY/WinSCP is SSH. You gain very little by trying to use
the same authentication mechanism for both protocols in your use case.


> So, I'm back to plan b, and that is to have a secure proxy connection so
> all browser-to-server communication is encrypted.

That is a good idea if all of your browsers support it. Popular browsers
support HTTPS-to-proxy on desktop, but I am not sure about their mobile
versions. You may have to jump through some hoops.


> So the question is, does
> anyone know if squid 3.5 on Ubuntu 16.04 supports secure connections?

Squid v3.5 supports secure connections to the proxy. See "TLS / SSL
Options" for the http_port directive (not the https_port directive!).

You can install Squid v3.5 on Ubuntu. I do not know whether the official
Ubuntu Squid package is built with the required support.


HTH,

Alex.



From acctforjunk at yahoo.com  Wed May  3 17:37:36 2017
From: acctforjunk at yahoo.com (j m)
Date: Wed, 3 May 2017 17:37:36 +0000 (UTC)
Subject: [squid-users] HTTPS support
In-Reply-To: <9541b1fa-cdf5-1777-0478-eabb36b06379@measurement-factory.com>
References: <1251311337.1946637.1493830629405.ref@mail.yahoo.com>
 <1251311337.1946637.1493830629405@mail.yahoo.com>
 <9541b1fa-cdf5-1777-0478-eabb36b06379@measurement-factory.com>
Message-ID: <754215205.1965655.1493833056577@mail.yahoo.com>

I should clarify things a bit. ?I do realize SSH and squid are separate, but the problem I'm having is I cannot SSH into my home server from an organization that is apparently blocking SSH connections, for whatever reason, intentional or not. ?I am, however, able to use a squid proxy that I run from my home server. ?So the plan was to use SSH through the proxy. ?VPNs are out of the question as this does not work.
I would only need to use my proxy from the desktop, so mobile is not required. ?

>Squid v3.5 supports secure connections to the proxy. See "TLS / SSL
>Options" for the http_port directive (not the https_port directive!).

This is helpful since I was trying to use https_port.
      From: Alex Rousskov <rousskov at measurement-factory.com>
 To: "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
Cc: j m <acctforjunk at yahoo.com>
 Sent: Wednesday, May 3, 2017 12:22 PM
 Subject: Re: [squid-users] HTTPS support
   
On 05/03/2017 10:57 AM, j m wrote:
> I wanted to set up a proxy on my home server for use from remote
> locations to use as a web proxy (of course) and also to run SSH over.

The "ssh" part is unrelated to Squid. Secure ssh separately from Squid.


> This means that basic auth is undesirable due to the login being sent
> in clear text.? So, someone suggested digest auth, and I was happy.
>? But, now I'm finding that PuTTY and WinSCP do not support digest auth.
>? And consequently, I haven't found any other SSH clients that support
> digest. (sigh)

These problems will go away if you stop mixing Squid and ssh. Squid is
HTTP while PuTTY/WinSCP is SSH. You gain very little by trying to use
the same authentication mechanism for both protocols in your use case.


> So, I'm back to plan b, and that is to have a secure proxy connection so
> all browser-to-server communication is encrypted.

That is a good idea if all of your browsers support it. Popular browsers
support HTTPS-to-proxy on desktop, but I am not sure about their mobile
versions. You may have to jump through some hoops.


> So the question is, does
> anyone know if squid 3.5 on Ubuntu 16.04 supports secure connections?

Squid v3.5 supports secure connections to the proxy. See "TLS / SSL
Options" for the http_port directive (not the https_port directive!).

You can install Squid v3.5 on Ubuntu. I do not know whether the official
Ubuntu Squid package is built with the required support.


HTH,

Alex.



   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/11fd0074/attachment.htm>

From Antony.Stone at squid.open.source.it  Wed May  3 17:47:41 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 3 May 2017 18:47:41 +0100
Subject: [squid-users] HTTPS support
In-Reply-To: <754215205.1965655.1493833056577@mail.yahoo.com>
References: <1251311337.1946637.1493830629405.ref@mail.yahoo.com>
 <9541b1fa-cdf5-1777-0478-eabb36b06379@measurement-factory.com>
 <754215205.1965655.1493833056577@mail.yahoo.com>
Message-ID: <201705031847.41944.Antony.Stone@squid.open.source.it>

On Wednesday 03 May 2017 at 18:37:36, j m wrote:

> I cannot SSH into my home server from an organization that is apparently
> blocking SSH connections, for whatever reason, intentional or not.  I am,
> however, able to use a squid proxy that I run from my home server.

So, redirect *external* connections to port 3128 to localhost 22, and then SSH 
to your home server on port 3128?

> So the plan was to use SSH through the proxy.

Squid is an HTTP (and partly FTP) proxy, not a general-purpose TCP proxy.


Antony.

-- 
"In fact I wanted to be John Cleese and it took me some time to realise that 
the job was already taken."

 - Douglas Adams

                                                   Please reply to the list;
                                                         please *don't* CC me.


From rousskov at measurement-factory.com  Wed May  3 18:19:26 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 3 May 2017 12:19:26 -0600
Subject: [squid-users] HTTPS support
In-Reply-To: <754215205.1965655.1493833056577@mail.yahoo.com>
References: <1251311337.1946637.1493830629405.ref@mail.yahoo.com>
 <1251311337.1946637.1493830629405@mail.yahoo.com>
 <9541b1fa-cdf5-1777-0478-eabb36b06379@measurement-factory.com>
 <754215205.1965655.1493833056577@mail.yahoo.com>
Message-ID: <51549da6-b09e-dbfe-d65f-89453bf38c8b@measurement-factory.com>

On 05/03/2017 11:37 AM, j m wrote:
> the plan was to use SSH through the proxy.

If your SSH clients support SSH through an HTTP proxy, then do not
authenticate them in Squid. Just do not let them go anywhere but the SSH
server. It would be like running an exposed-to-the-world SSH server, no
worse. Squid will still know nothing about SSH. Squid will just tunnel
opaque bytes from your SSH clients to your SSH server. You will use an
HTTP (not HTTPS) Squid port for this traffic because your SSH clients
are unlikely to support HTTPS to the proxy.

Your browsers will still use HTTPS to the proxy (and get authenticated).
Thus, you will have two different http_ports, one for HTTP
(unauthenticated SSH clients) and one for HTTPS (authenticated browsers).

If SSH blocking is not based on _protocol_ but on port, then follow
Antony Stone advice and change the SSH server port instead of
HTTP-proxying SSH connections.

Alex.



> ------------------------------------------------------------------------
> *From:* Alex Rousskov <rousskov at measurement-factory.com>
> *To:* "squid-users at lists.squid-cache.org"
> <squid-users at lists.squid-cache.org>
> *Cc:* j m <acctforjunk at yahoo.com>
> *Sent:* Wednesday, May 3, 2017 12:22 PM
> *Subject:* Re: [squid-users] HTTPS support
> 
> On 05/03/2017 10:57 AM, j m wrote:
>> I wanted to set up a proxy on my home server for use from remote
>> locations to use as a web proxy (of course) and also to run SSH over.
> 
> The "ssh" part is unrelated to Squid. Secure ssh separately from Squid.
> 
> 
>> This means that basic auth is undesirable due to the login being sent
>> in clear text.  So, someone suggested digest auth, and I was happy.
>>  But, now I'm finding that PuTTY and WinSCP do not support digest auth.
>>  And consequently, I haven't found any other SSH clients that support
>> digest. (sigh)
> 
> These problems will go away if you stop mixing Squid and ssh. Squid is
> HTTP while PuTTY/WinSCP is SSH. You gain very little by trying to use
> the same authentication mechanism for both protocols in your use case.
> 
> 
>> So, I'm back to plan b, and that is to have a secure proxy connection so
>> all browser-to-server communication is encrypted.
> 
> That is a good idea if all of your browsers support it. Popular browsers
> support HTTPS-to-proxy on desktop, but I am not sure about their mobile
> versions. You may have to jump through some hoops.
> 
> 
> 
>> So the question is, does
>> anyone know if squid 3.5 on Ubuntu 16.04 supports secure connections?
> 
> 
> Squid v3.5 supports secure connections to the proxy. See "TLS / SSL
> Options" for the http_port directive (not the https_port directive!).
> 
> You can install Squid v3.5 on Ubuntu. I do not know whether the official
> Ubuntu Squid package is built with the required support.
> 
> 
> HTH,
> 
> Alex.
> 
> 
> 
> 



From acctforjunk at yahoo.com  Wed May  3 18:26:36 2017
From: acctforjunk at yahoo.com (j m)
Date: Wed, 3 May 2017 18:26:36 +0000 (UTC)
Subject: [squid-users] HTTPS support
In-Reply-To: <201705031847.41944.Antony.Stone@squid.open.source.it>
References: <1251311337.1946637.1493830629405.ref@mail.yahoo.com>
 <9541b1fa-cdf5-1777-0478-eabb36b06379@measurement-factory.com>
 <754215205.1965655.1493833056577@mail.yahoo.com>
 <201705031847.41944.Antony.Stone@squid.open.source.it>
Message-ID: <1434790977.2051106.1493835996512@mail.yahoo.com>

>So, redirect *external* connections to port 3128 to localhost 22, and then SSH?
>to your home server on port 3128?

I think what you're saying is it's a port number issue, that certain ports are problematic. ?But that doesn't seem to be the case. ?I already run SSH on a non-standard port, and have tried moving SSH to squid's port after moving moving squid elsewhere; it still doesn't work. ?In addition, I'm able to connect to an entirely different service I run on the same server. ?So it seems SSH is being filtered
>Squid is an HTTP (and partly FTP) proxy, not a general-purpose TCP proxy.
This is the first I've been told this. ?I personally don't know since I'm very proxy-illiterate.?

      From: Antony Stone <Antony.Stone at squid.open.source.it>
 To: squid-users at lists.squid-cache.org 
 Sent: Wednesday, May 3, 2017 12:48 PM
 Subject: Re: [squid-users] HTTPS support
   
On Wednesday 03 May 2017 at 18:37:36, j m wrote:

> I cannot SSH into my home server from an organization that is apparently
> blocking SSH connections, for whatever reason, intentional or not.? I am,
> however, able to use a squid proxy that I run from my home server.

So, redirect *external* connections to port 3128 to localhost 22, and then SSH 
to your home server on port 3128?

> So the plan was to use SSH through the proxy.

Squid is an HTTP (and partly FTP) proxy, not a general-purpose TCP proxy.


Antony.

-- 
"In fact I wanted to be John Cleese and it took me some time to realise that 
the job was already taken."

 - Douglas Adams

? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Please reply to the list;
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/66976188/attachment.htm>

From acctforjunk at yahoo.com  Wed May  3 18:44:15 2017
From: acctforjunk at yahoo.com (j m)
Date: Wed, 3 May 2017 18:44:15 +0000 (UTC)
Subject: [squid-users] HTTPS support
In-Reply-To: <51549da6-b09e-dbfe-d65f-89453bf38c8b@measurement-factory.com>
References: <1251311337.1946637.1493830629405.ref@mail.yahoo.com>
 <1251311337.1946637.1493830629405@mail.yahoo.com>
 <9541b1fa-cdf5-1777-0478-eabb36b06379@measurement-factory.com>
 <754215205.1965655.1493833056577@mail.yahoo.com>
 <51549da6-b09e-dbfe-d65f-89453bf38c8b@measurement-factory.com>
Message-ID: <342639953.2054602.1493837055869@mail.yahoo.com>

In any case, I'm finding SSH through proxy is undesirable or not possible. ?I'm thinking shellinabox, which is insecure but run over a secure proxy link, is my best bet.

      From: Alex Rousskov <rousskov at measurement-factory.com>
 To: j m <acctforjunk at yahoo.com>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Wednesday, May 3, 2017 1:19 PM
 Subject: Re: [squid-users] HTTPS support
   
On 05/03/2017 11:37 AM, j m wrote:
> the plan was to use SSH through the proxy.

If your SSH clients support SSH through an HTTP proxy, then do not
authenticate them in Squid. Just do not let them go anywhere but the SSH
server. It would be like running an exposed-to-the-world SSH server, no
worse. Squid will still know nothing about SSH. Squid will just tunnel
opaque bytes from your SSH clients to your SSH server. You will use an
HTTP (not HTTPS) Squid port for this traffic because your SSH clients
are unlikely to support HTTPS to the proxy.

Your browsers will still use HTTPS to the proxy (and get authenticated).
Thus, you will have two different http_ports, one for HTTP
(unauthenticated SSH clients) and one for HTTPS (authenticated browsers).

If SSH blocking is not based on _protocol_ but on port, then follow
Antony Stone advice and change the SSH server port instead of
HTTP-proxying SSH connections.

Alex.



> ------------------------------------------------------------------------
> *From:* Alex Rousskov <rousskov at measurement-factory.com>
> *To:* "squid-users at lists.squid-cache.org"
> <squid-users at lists.squid-cache.org>
> *Cc:* j m <acctforjunk at yahoo.com>
> *Sent:* Wednesday, May 3, 2017 12:22 PM
> *Subject:* Re: [squid-users] HTTPS support
> 
> On 05/03/2017 10:57 AM, j m wrote:
>> I wanted to set up a proxy on my home server for use from remote
>> locations to use as a web proxy (of course) and also to run SSH over.
> 
> The "ssh" part is unrelated to Squid. Secure ssh separately from Squid.
> 
> 
>> This means that basic auth is undesirable due to the login being sent
>> in clear text.? So, someone suggested digest auth, and I was happy.
>>? But, now I'm finding that PuTTY and WinSCP do not support digest auth.
>>? And consequently, I haven't found any other SSH clients that support
>> digest. (sigh)
> 
> These problems will go away if you stop mixing Squid and ssh. Squid is
> HTTP while PuTTY/WinSCP is SSH. You gain very little by trying to use
> the same authentication mechanism for both protocols in your use case.
> 
> 
>> So, I'm back to plan b, and that is to have a secure proxy connection so
>> all browser-to-server communication is encrypted.
> 
> That is a good idea if all of your browsers support it. Popular browsers
> support HTTPS-to-proxy on desktop, but I am not sure about their mobile
> versions. You may have to jump through some hoops.
> 
> 
> 
>> So the question is, does
>> anyone know if squid 3.5 on Ubuntu 16.04 supports secure connections?
> 
> 
> Squid v3.5 supports secure connections to the proxy. See "TLS / SSL
> Options" for the http_port directive (not the https_port directive!).
> 
> You can install Squid v3.5 on Ubuntu. I do not know whether the official
> Ubuntu Squid package is built with the required support.
> 
> 
> HTH,
> 
> Alex.
> 
> 
> 
> 



   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/acd76705/attachment.htm>

From skyvolt at gmail.com  Wed May  3 18:54:14 2017
From: skyvolt at gmail.com (Skyvolt Zoltar)
Date: Wed, 3 May 2017 15:54:14 -0300
Subject: [squid-users] Squid as Proxy/Web Filer only
Message-ID: <CAOM=vzxBqO7JZbfOZJ1sKWgHMxzDN6bbzv8r3VaVSAyaTagRVA@mail.gmail.com>

Hi, I am completely new to Squid.

I would like to know if it is possible to configure squid within my network
as a web filter only.

The scenario would be like this.

User's browser has proxy configuration > forwards all the browsers request
to Squid > squid does an analysis > squid forward to the default gateway of
my network.

But all that within the same IP address range. I have a router already
doing the routing from my internal to external network.

Or I cannot? Will Squid only work between two different network, with
different IP address (one IP for an internal interface and other for
external interface)?

Thank you.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/b4de5b6f/attachment.htm>

From marcel at baltruschat.net  Wed May  3 18:45:20 2017
From: marcel at baltruschat.net (mbaltruschat)
Date: Wed, 3 May 2017 11:45:20 -0700 (PDT)
Subject: [squid-users] Squid proxy without name resolution for internet
 adresses behind parent proxy
In-Reply-To: <90f3e28b-99eb-b6d9-7382-d168f549bce6@treenet.co.nz>
References: <1493370033619-4682225.post@n4.nabble.com>
 <f6d4410e-32af-de08-b875-c4c34efd8f4a@gmail.com>
 <1493376531696-4682229.post@n4.nabble.com>
 <f4bcea5d-8681-dbb4-3cd3-ffacf5adbfc6@treenet.co.nz>
 <1493496450559-4682235.post@n4.nabble.com>
 <00e201d2c17e$16067e10$42137a30$@ngtech.co.il>
 <90f3e28b-99eb-b6d9-7382-d168f549bce6@treenet.co.nz>
Message-ID: <1493837120705-4682289.post@n4.nabble.com>

Hello Amos,

many thanks, i think i got it, it was a Problem with my "never_direct"
rules, i already got them in the conf, but the dont worked, so after your
tips,  i wrote the conf from scratch in Notepad++ and now it works - i guess
it was a Problem with charset while saving.

again, many thanks, can i donate something for squid development? Paypal?

Regards
Marcel



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-proxy-without-name-resolution-for-internet-adresses-behind-parent-proxy-tp4682225p4682289.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Tommy.Craddock at bicgraphic.com  Wed May  3 19:03:38 2017
From: Tommy.Craddock at bicgraphic.com (Craddock, Tommy)
Date: Wed, 3 May 2017 19:03:38 +0000
Subject: [squid-users] HTTPS support
In-Reply-To: <342639953.2054602.1493837055869@mail.yahoo.com>
References: <1251311337.1946637.1493830629405.ref@mail.yahoo.com>
 <1251311337.1946637.1493830629405@mail.yahoo.com>
 <9541b1fa-cdf5-1777-0478-eabb36b06379@measurement-factory.com>
 <754215205.1965655.1493833056577@mail.yahoo.com>
 <51549da6-b09e-dbfe-d65f-89453bf38c8b@measurement-factory.com>
 <342639953.2054602.1493837055869@mail.yahoo.com>
Message-ID: <CA86A9283AA07E478F6B0629521FFEE74D39C8@CLWSEXCMBX02.na.bicworld.com>

Hello,

Is this more in line with what your trying to do:

http://loredo.me/post/116633549315/geeking-out-with-haproxy-on-pfsense-the-ultimate

Tommy

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of j m
Sent: Wednesday, May 03, 2017 2:44 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] HTTPS support

In any case, I'm finding SSH through proxy is undesirable or not possible.  I'm thinking shellinabox, which is insecure but run over a secure proxy link, is my best bet.

________________________________
From: Alex Rousskov <rousskov at measurement-factory.com<mailto:rousskov at measurement-factory.com>>
To: j m <acctforjunk at yahoo.com<mailto:acctforjunk at yahoo.com>>; "squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>" <squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>>
Sent: Wednesday, May 3, 2017 1:19 PM
Subject: Re: [squid-users] HTTPS support

On 05/03/2017 11:37 AM, j m wrote:
> the plan was to use SSH through the proxy.

If your SSH clients support SSH through an HTTP proxy, then do not
authenticate them in Squid. Just do not let them go anywhere but the SSH
server. It would be like running an exposed-to-the-world SSH server, no
worse. Squid will still know nothing about SSH. Squid will just tunnel
opaque bytes from your SSH clients to your SSH server. You will use an
HTTP (not HTTPS) Squid port for this traffic because your SSH clients
are unlikely to support HTTPS to the proxy.

Your browsers will still use HTTPS to the proxy (and get authenticated).
Thus, you will have two different http_ports, one for HTTP
(unauthenticated SSH clients) and one for HTTPS (authenticated browsers).

If SSH blocking is not based on _protocol_ but on port, then follow
Antony Stone advice and change the SSH server port instead of
HTTP-proxying SSH connections.

Alex.




> ------------------------------------------------------------------------
> *From:* Alex Rousskov <rousskov at measurement-factory.com<mailto:rousskov at measurement-factory.com>>
> *To:* "squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>"
> <squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>>
> *Cc:* j m <acctforjunk at yahoo.com<mailto:acctforjunk at yahoo.com>>
> *Sent:* Wednesday, May 3, 2017 12:22 PM
> *Subject:* Re: [squid-users] HTTPS support
>
> On 05/03/2017 10:57 AM, j m wrote:
>> I wanted to set up a proxy on my home server for use from remote
>> locations to use as a web proxy (of course) and also to run SSH over.
>
> The "ssh" part is unrelated to Squid. Secure ssh separately from Squid.
>
>
>> This means that basic auth is undesirable due to the login being sent
>> in clear text.  So, someone suggested digest auth, and I was happy.
>>  But, now I'm finding that PuTTY and WinSCP do not support digest auth.
>>  And consequently, I haven't found any other SSH clients that support
>> digest. (sigh)
>
> These problems will go away if you stop mixing Squid and ssh. Squid is
> HTTP while PuTTY/WinSCP is SSH. You gain very little by trying to use
> the same authentication mechanism for both protocols in your use case.
>
>
>> So, I'm back to plan b, and that is to have a secure proxy connection so
>> all browser-to-server communication is encrypted.
>
> That is a good idea if all of your browsers support it. Popular browsers
> support HTTPS-to-proxy on desktop, but I am not sure about their mobile
> versions. You may have to jump through some hoops.
>
>
>
>> So the question is, does
>> anyone know if squid 3.5 on Ubuntu 16.04 supports secure connections?
>
>
> Squid v3.5 supports secure connections to the proxy. See "TLS / SSL
> Options" for the http_port directive (not the https_port directive!).
>
> You can install Squid v3.5 on Ubuntu. I do not know whether the official
> Ubuntu Squid package is built with the required support.
>
>
> HTH,
>
> Alex.
>
>
>
>


______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________

______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/da6879bb/attachment.htm>

From rousskov at measurement-factory.com  Wed May  3 19:15:21 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 3 May 2017 13:15:21 -0600
Subject: [squid-users] Squid proxy without name resolution for internet
 adresses behind parent proxy
In-Reply-To: <1493837120705-4682289.post@n4.nabble.com>
References: <1493370033619-4682225.post@n4.nabble.com>
 <f6d4410e-32af-de08-b875-c4c34efd8f4a@gmail.com>
 <1493376531696-4682229.post@n4.nabble.com>
 <f4bcea5d-8681-dbb4-3cd3-ffacf5adbfc6@treenet.co.nz>
 <1493496450559-4682235.post@n4.nabble.com>
 <00e201d2c17e$16067e10$42137a30$@ngtech.co.il>
 <90f3e28b-99eb-b6d9-7382-d168f549bce6@treenet.co.nz>
 <1493837120705-4682289.post@n4.nabble.com>
Message-ID: <2c2e4365-0eaa-46da-67e1-dd933f54f8e2@measurement-factory.com>

On 05/03/2017 12:45 PM, mbaltruschat wrote:

> can i donate something for squid development? Paypal?

If you would like to donate to the Squid Project, please see the URL
below but note that Amos, personally, will not receive your donation
because Squid Foundation directors are unpaid volunteers. If you want to
reward Amos, please contact him (off-list) for details. Either way, you
will be helping the Squid Project, and we thank you!

    http://www.squid-cache.org/Foundation/donate.html

Cheers,

Alex.



From acctforjunk at yahoo.com  Wed May  3 19:14:27 2017
From: acctforjunk at yahoo.com (j m)
Date: Wed, 3 May 2017 19:14:27 +0000 (UTC)
Subject: [squid-users] HTTPS support
In-Reply-To: <CA86A9283AA07E478F6B0629521FFEE74D39C8@CLWSEXCMBX02.na.bicworld.com>
References: <1251311337.1946637.1493830629405.ref@mail.yahoo.com>
 <1251311337.1946637.1493830629405@mail.yahoo.com>
 <9541b1fa-cdf5-1777-0478-eabb36b06379@measurement-factory.com>
 <754215205.1965655.1493833056577@mail.yahoo.com>
 <51549da6-b09e-dbfe-d65f-89453bf38c8b@measurement-factory.com>
 <342639953.2054602.1493837055869@mail.yahoo.com>
 <CA86A9283AA07E478F6B0629521FFEE74D39C8@CLWSEXCMBX02.na.bicworld.com>
Message-ID: <1970063095.2069926.1493838867209@mail.yahoo.com>

Looks interesting, but it looks complex and sounds like I'd need more of a router than I have to do it.

      From: "Craddock, Tommy" <Tommy.Craddock at bicgraphic.com>
 To: "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Wednesday, May 3, 2017 2:04 PM
 Subject: Re: [squid-users] HTTPS support
   
#yiv0837668946 #yiv0837668946 -- _filtered #yiv0837668946 {font-family:Helvetica;panose-1:2 11 6 4 2 2 2 2 2 4;} _filtered #yiv0837668946 {panose-1:2 4 5 3 5 4 6 3 2 4;} _filtered #yiv0837668946 {font-family:Calibri;panose-1:2 15 5 2 2 2 4 3 2 4;}#yiv0837668946 #yiv0837668946 p.yiv0837668946MsoNormal, #yiv0837668946 li.yiv0837668946MsoNormal, #yiv0837668946 div.yiv0837668946MsoNormal {margin:0in;margin-bottom:.0001pt;font-size:12.0pt;}#yiv0837668946 a:link, #yiv0837668946 span.yiv0837668946MsoHyperlink {color:blue;text-decoration:underline;}#yiv0837668946 a:visited, #yiv0837668946 span.yiv0837668946MsoHyperlinkFollowed {color:purple;text-decoration:underline;}#yiv0837668946 span.yiv0837668946EmailStyle17 {color:#1F497D;}#yiv0837668946 .yiv0837668946MsoChpDefault {font-size:10.0pt;} _filtered #yiv0837668946 {margin:1.0in 1.0in 1.0in 1.0in;}#yiv0837668946 div.yiv0837668946WordSection1 {}#yiv0837668946 Hello,  ? Is this more in line with what your trying to do:  ? http://loredo.me/post/116633549315/geeking-out-with-haproxy-on-pfsense-the-ultimate  ? Tommy  ? From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]On Behalf Of j m
Sent: Wednesday, May 03, 2017 2:44 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] HTTPS support  ? In any case, I'm finding SSH through proxy is undesirable or not possible. ?I'm thinking shellinabox, which is insecure but run over a secure proxy link, is my best bet.  ? From: Alex Rousskov <rousskov at measurement-factory.com>
To: j m <acctforjunk at yahoo.com>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org>
Sent: Wednesday, May 3, 2017 1:19 PM
Subject: Re: [squid-users] HTTPS support  ? On 05/03/2017 11:37 AM, j m wrote:
> the plan was to use SSH through the proxy.

If your SSH clients support SSH through an HTTP proxy, then do not
authenticate them in Squid. Just do not let them go anywhere but the SSH
server. It would be like running an exposed-to-the-world SSH server, no
worse. Squid will still know nothing about SSH. Squid will just tunnel
opaque bytes from your SSH clients to your SSH server. You will use an
HTTP (not HTTPS) Squid port for this traffic because your SSH clients
are unlikely to support HTTPS to the proxy.

Your browsers will still use HTTPS to the proxy (and get authenticated).
Thus, you will have two different http_ports, one for HTTP
(unauthenticated SSH clients) and one for HTTPS (authenticated browsers).

If SSH blocking is not based on _protocol_ but on port, then follow
Antony Stone advice and change the SSH server port instead of
HTTP-proxying SSH connections.

Alex. 



> ------------------------------------------------------------------------
> *From:* Alex Rousskov <rousskov at measurement-factory.com>
> *To:* "squid-users at lists.squid-cache.org"
> <squid-users at lists.squid-cache.org>
> *Cc:* j m <acctforjunk at yahoo.com>
> *Sent:* Wednesday, May 3, 2017 12:22 PM
> *Subject:* Re: [squid-users] HTTPS support
> 
> On 05/03/2017 10:57 AM, j m wrote:
>> I wanted to set up a proxy on my home server for use from remote
>> locations to use as a web proxy (of course) and also to run SSH over.
> 
> The "ssh" part is unrelated to Squid. Secure ssh separately from Squid.
> 
> 
>> This means that basic auth is undesirable due to the login being sent
>> in clear text.? So, someone suggested digest auth, and I was happy.
>>? But, now I'm finding that PuTTY and WinSCP do not support digest auth.
>>? And consequently, I haven't found any other SSH clients that support
>> digest. (sigh)
> 
> These problems will go away if you stop mixing Squid and ssh. Squid is
> HTTP while PuTTY/WinSCP is SSH. You gain very little by trying to use
> the same authentication mechanism for both protocols in your use case.
> 
> 
>> So, I'm back to plan b, and that is to have a secure proxy connection so
>> all browser-to-server communication is encrypted.
> 
> That is a good idea if all of your browsers support it. Popular browsers
> support HTTPS-to-proxy on desktop, but I am not sure about their mobile
> versions. You may have to jump through some hoops.
> 
> 
> 
>> So the question is, does
>> anyone know if squid 3.5 on Ubuntu 16.04 supports secure connections?
> 
> 
> Squid v3.5 supports secure connections to the proxy. See "TLS / SSL
> Options" for the http_port directive (not the https_port directive!).
> 
> You can install Squid v3.5 on Ubuntu. I do not know whether the official
> Ubuntu Squid package is built with the required support.
> 
> 
> HTH,
> 
> Alex.
> 
> 
> 
>   ? 
______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________ 
______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/ab9b3a8c/attachment.htm>

From Tommy.Craddock at bicgraphic.com  Wed May  3 19:35:53 2017
From: Tommy.Craddock at bicgraphic.com (Craddock, Tommy)
Date: Wed, 3 May 2017 19:35:53 +0000
Subject: [squid-users] HTTPS support
In-Reply-To: <1970063095.2069926.1493838867209@mail.yahoo.com>
References: <1251311337.1946637.1493830629405.ref@mail.yahoo.com>
 <1251311337.1946637.1493830629405@mail.yahoo.com>
 <9541b1fa-cdf5-1777-0478-eabb36b06379@measurement-factory.com>
 <754215205.1965655.1493833056577@mail.yahoo.com>
 <51549da6-b09e-dbfe-d65f-89453bf38c8b@measurement-factory.com>
 <342639953.2054602.1493837055869@mail.yahoo.com>
 <CA86A9283AA07E478F6B0629521FFEE74D39C8@CLWSEXCMBX02.na.bicworld.com>
 <1970063095.2069926.1493838867209@mail.yahoo.com>
Message-ID: <CA86A9283AA07E478F6B0629521FFEE74D3A88@CLWSEXCMBX02.na.bicworld.com>

Hello,

Yeah, that guide is for PFsense in particular, but you could run HAProxy by itself (say in a VM) and get the same result.  Just fwd those ports from your router to the HAProxy box.

Thanks!


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of j m
Sent: Wednesday, May 03, 2017 3:14 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] HTTPS support

Looks interesting, but it looks complex and sounds like I'd need more of a router than I have to do it.
________________________________
From: "Craddock, Tommy" <Tommy.Craddock at bicgraphic.com<mailto:Tommy.Craddock at bicgraphic.com>>
To: "squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>" <squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>>
Sent: Wednesday, May 3, 2017 2:04 PM
Subject: Re: [squid-users] HTTPS support

Hello,

Is this more in line with what your trying to do:

http://loredo.me/post/116633549315/geeking-out-with-haproxy-on-pfsense-the-ultimate

Tommy

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of j m
Sent: Wednesday, May 03, 2017 2:44 PM
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] HTTPS support

In any case, I'm finding SSH through proxy is undesirable or not possible.  I'm thinking shellinabox, which is insecure but run over a secure proxy link, is my best bet.

________________________________
From: Alex Rousskov <rousskov at measurement-factory.com<mailto:rousskov at measurement-factory.com>>
To: j m <acctforjunk at yahoo.com<mailto:acctforjunk at yahoo.com>>; "squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>" <squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>>
Sent: Wednesday, May 3, 2017 1:19 PM
Subject: Re: [squid-users] HTTPS support

On 05/03/2017 11:37 AM, j m wrote:
> the plan was to use SSH through the proxy.

If your SSH clients support SSH through an HTTP proxy, then do not
authenticate them in Squid. Just do not let them go anywhere but the SSH
server. It would be like running an exposed-to-the-world SSH server, no
worse. Squid will still know nothing about SSH. Squid will just tunnel
opaque bytes from your SSH clients to your SSH server. You will use an
HTTP (not HTTPS) Squid port for this traffic because your SSH clients
are unlikely to support HTTPS to the proxy.

Your browsers will still use HTTPS to the proxy (and get authenticated).
Thus, you will have two different http_ports, one for HTTP
(unauthenticated SSH clients) and one for HTTPS (authenticated browsers).

If SSH blocking is not based on _protocol_ but on port, then follow
Antony Stone advice and change the SSH server port instead of
HTTP-proxying SSH connections.

Alex.




> ------------------------------------------------------------------------
> *From:* Alex Rousskov <rousskov at measurement-factory.com<mailto:rousskov at measurement-factory.com>>
> *To:* "squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>"
> <squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>>
> *Cc:* j m <acctforjunk at yahoo.com<mailto:acctforjunk at yahoo.com>>
> *Sent:* Wednesday, May 3, 2017 12:22 PM
> *Subject:* Re: [squid-users] HTTPS support
>
> On 05/03/2017 10:57 AM, j m wrote:
>> I wanted to set up a proxy on my home server for use from remote
>> locations to use as a web proxy (of course) and also to run SSH over.
>
> The "ssh" part is unrelated to Squid. Secure ssh separately from Squid.
>
>
>> This means that basic auth is undesirable due to the login being sent
>> in clear text.  So, someone suggested digest auth, and I was happy.
>>  But, now I'm finding that PuTTY and WinSCP do not support digest auth.
>>  And consequently, I haven't found any other SSH clients that support
>> digest. (sigh)
>
> These problems will go away if you stop mixing Squid and ssh. Squid is
> HTTP while PuTTY/WinSCP is SSH. You gain very little by trying to use
> the same authentication mechanism for both protocols in your use case.
>
>
>> So, I'm back to plan b, and that is to have a secure proxy connection so
>> all browser-to-server communication is encrypted.
>
> That is a good idea if all of your browsers support it. Popular browsers
> support HTTPS-to-proxy on desktop, but I am not sure about their mobile
> versions. You may have to jump through some hoops.
>
>
>
>> So the question is, does
>> anyone know if squid 3.5 on Ubuntu 16.04 supports secure connections?
>
>
> Squid v3.5 supports secure connections to the proxy. See "TLS / SSL
> Options" for the http_port directive (not the https_port directive!).
>
> You can install Squid v3.5 on Ubuntu. I do not know whether the official
> Ubuntu Squid package is built with the required support.
>
>
> HTH,
>
> Alex.
>
>
>
>


______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com<http://www.symanteccloud.com/>
______________________________________________________________________

______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users


______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________

______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/c5a37c0a/attachment.htm>

From dig at digcorp.net  Wed May  3 20:22:27 2017
From: dig at digcorp.net (Daniel Greenwald)
Date: Wed, 3 May 2017 16:22:27 -0400
Subject: [squid-users] HTTPS support
In-Reply-To: <CA86A9283AA07E478F6B0629521FFEE74D3A88@CLWSEXCMBX02.na.bicworld.com>
References: <1251311337.1946637.1493830629405.ref@mail.yahoo.com>
 <1251311337.1946637.1493830629405@mail.yahoo.com>
 <9541b1fa-cdf5-1777-0478-eabb36b06379@measurement-factory.com>
 <754215205.1965655.1493833056577@mail.yahoo.com>
 <51549da6-b09e-dbfe-d65f-89453bf38c8b@measurement-factory.com>
 <342639953.2054602.1493837055869@mail.yahoo.com>
 <CA86A9283AA07E478F6B0629521FFEE74D39C8@CLWSEXCMBX02.na.bicworld.com>
 <1970063095.2069926.1493838867209@mail.yahoo.com>
 <CA86A9283AA07E478F6B0629521FFEE74D3A88@CLWSEXCMBX02.na.bicworld.com>
Message-ID: <CAOsHgtvv7=GfqRCTq2aovEfkJfc+0q_7VCE_UEobeo_7b391fg@mail.gmail.com>

Seems to me you are overthinking this. What you're up against is blocked
outbound ports. Simply run openvpn at your home over one of the allowed
outbound ports eg 80 443 or possibly 3128/8080 according to your
environment and call it a day. You won't need proxy authentication or
haproxy etc..

On Wed, May 3, 2017 at 3:35 PM, Craddock, Tommy <
Tommy.Craddock at bicgraphic.com> wrote:

> Hello,
>
>
>
> Yeah, that guide is for PFsense in particular, but you could run HAProxy
> by itself (say in a VM) and get the same result.  Just fwd those ports from
> your router to the HAProxy box.
>
>
> Thanks!
>
>
>
>
>
> *From:* squid-users [mailto:squid-users-bounces at lists.squid-cache.org] *On
> Behalf Of *j m
> *Sent:* Wednesday, May 03, 2017 3:14 PM
>
> *To:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] HTTPS support
>
>
>
> Looks interesting, but it looks complex and sounds like I'd need more of a
> router than I have to do it.
> ------------------------------
>
> *From:* "Craddock, Tommy" <Tommy.Craddock at bicgraphic.com>
> *To:* "squid-users at lists.squid-cache.org" <squid-users at lists.squid-
> cache.org>
> *Sent:* Wednesday, May 3, 2017 2:04 PM
> *Subject:* Re: [squid-users] HTTPS support
>
>
>
> Hello,
>
>
>
> Is this more in line with what your trying to do:
>
>
>
> http://loredo.me/post/116633549315/geeking-out-with-
> haproxy-on-pfsense-the-ultimate
>
>
>
> Tommy
>
>
>
> *From:* squid-users [mailto:squid-users-bounces at lists.squid-cache.org
> <squid-users-bounces at lists.squid-cache.org>] *On Behalf Of *j m
> *Sent:* Wednesday, May 03, 2017 2:44 PM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] HTTPS support
>
>
>
> In any case, I'm finding SSH through proxy is undesirable or not
> possible.  I'm thinking shellinabox, which is insecure but run over a
> secure proxy link, is my best bet.
>
>
> ------------------------------
>
> *From:* Alex Rousskov <rousskov at measurement-factory.com>
> *To:* j m <acctforjunk at yahoo.com>; "squid-users at lists.squid-cache.org" <
> squid-users at lists.squid-cache.org>
> *Sent:* Wednesday, May 3, 2017 1:19 PM
> *Subject:* Re: [squid-users] HTTPS support
>
>
>
> On 05/03/2017 11:37 AM, j m wrote:
> > the plan was to use SSH through the proxy.
>
> If your SSH clients support SSH through an HTTP proxy, then do not
> authenticate them in Squid. Just do not let them go anywhere but the SSH
> server. It would be like running an exposed-to-the-world SSH server, no
> worse. Squid will still know nothing about SSH. Squid will just tunnel
> opaque bytes from your SSH clients to your SSH server. You will use an
> HTTP (not HTTPS) Squid port for this traffic because your SSH clients
> are unlikely to support HTTPS to the proxy.
>
> Your browsers will still use HTTPS to the proxy (and get authenticated).
> Thus, you will have two different http_ports, one for HTTP
> (unauthenticated SSH clients) and one for HTTPS (authenticated browsers).
>
> If SSH blocking is not based on _protocol_ but on port, then follow
> Antony Stone advice and change the SSH server port instead of
> HTTP-proxying SSH connections.
>
> Alex.
>
>
>
>
>
> > ------------------------------------------------------------------------
> > *From:* Alex Rousskov <rousskov at measurement-factory.com>
> > *To:* "squid-users at lists.squid-cache.org"
> > <squid-users at lists.squid-cache.org>
> > *Cc:* j m <acctforjunk at yahoo.com>
> > *Sent:* Wednesday, May 3, 2017 12:22 PM
> > *Subject:* Re: [squid-users] HTTPS support
> >
> > On 05/03/2017 10:57 AM, j m wrote:
> >> I wanted to set up a proxy on my home server for use from remote
> >> locations to use as a web proxy (of course) and also to run SSH over.
> >
> > The "ssh" part is unrelated to Squid. Secure ssh separately from Squid.
> >
> >
> >> This means that basic auth is undesirable due to the login being sent
> >> in clear text.  So, someone suggested digest auth, and I was happy.
> >>  But, now I'm finding that PuTTY and WinSCP do not support digest auth.
> >>  And consequently, I haven't found any other SSH clients that support
> >> digest. (sigh)
> >
> > These problems will go away if you stop mixing Squid and ssh. Squid is
> > HTTP while PuTTY/WinSCP is SSH. You gain very little by trying to use
> > the same authentication mechanism for both protocols in your use case.
> >
> >
> >> So, I'm back to plan b, and that is to have a secure proxy connection so
> >> all browser-to-server communication is encrypted.
> >
> > That is a good idea if all of your browsers support it. Popular browsers
> > support HTTPS-to-proxy on desktop, but I am not sure about their mobile
> > versions. You may have to jump through some hoops.
> >
> >
> >
> >> So the question is, does
> >> anyone know if squid 3.5 on Ubuntu 16.04 supports secure connections?
> >
> >
> > Squid v3.5 supports secure connections to the proxy. See "TLS / SSL
> > Options" for the http_port directive (not the https_port directive!).
> >
> > You can install Squid v3.5 on Ubuntu. I do not know whether the official
> > Ubuntu Squid package is built with the required support.
> >
> >
> > HTH,
> >
> > Alex.
> >
> >
> >
> >
>
>
>
>
> ______________________________________________________________________
> This email has been scanned by the Symantec Email Security.cloud service.
> For more information please visit http://www.symanteccloud.com
> ______________________________________________________________________
>
>
> ______________________________________________________________________
> This email has been scanned by the Symantec Email Security.cloud service.
> For more information please visit http://www.symanteccloud.com
> ______________________________________________________________________
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> ______________________________________________________________________
> This email has been scanned by the Symantec Email Security.cloud service.
> For more information please visit http://www.symanteccloud.com
> ______________________________________________________________________
>
> ______________________________________________________________________
> This email has been scanned by the Symantec Email Security.cloud service.
> For more information please visit http://www.symanteccloud.com
> ______________________________________________________________________
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/a02cbeea/attachment.htm>

From acctforjunk at yahoo.com  Wed May  3 21:30:16 2017
From: acctforjunk at yahoo.com (j m)
Date: Wed, 3 May 2017 21:30:16 +0000 (UTC)
Subject: [squid-users] HTTPS support
In-Reply-To: <CAOsHgtvv7=GfqRCTq2aovEfkJfc+0q_7VCE_UEobeo_7b391fg@mail.gmail.com>
References: <1251311337.1946637.1493830629405.ref@mail.yahoo.com>
 <1251311337.1946637.1493830629405@mail.yahoo.com>
 <9541b1fa-cdf5-1777-0478-eabb36b06379@measurement-factory.com>
 <754215205.1965655.1493833056577@mail.yahoo.com>
 <51549da6-b09e-dbfe-d65f-89453bf38c8b@measurement-factory.com>
 <342639953.2054602.1493837055869@mail.yahoo.com>
 <CA86A9283AA07E478F6B0629521FFEE74D39C8@CLWSEXCMBX02.na.bicworld.com>
 <1970063095.2069926.1493838867209@mail.yahoo.com>
 <CA86A9283AA07E478F6B0629521FFEE74D3A88@CLWSEXCMBX02.na.bicworld.com>
 <CAOsHgtvv7=GfqRCTq2aovEfkJfc+0q_7VCE_UEobeo_7b391fg@mail.gmail.com>
Message-ID: <1037259491.2210996.1493847016057@mail.yahoo.com>

I don't believe blocked outbound ports is the problem. ?I can for example connect to several ports in the 8090 - 8100 range using services other than SSH. ?I've also tried moving the SSH server to 443 and one of these aforementioned ports, but no go.

      From: Daniel Greenwald <dig at digcorp.net>
 To: "Craddock, Tommy" <Tommy.Craddock at bicgraphic.com> 
Cc: "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org>
 Sent: Wednesday, May 3, 2017 3:23 PM
 Subject: Re: [squid-users] HTTPS support
   
Seems to me you are overthinking this. What you're up against is blocked outbound ports. Simply run openvpn at your home over one of the allowed outbound ports eg 80 443 or possibly 3128/8080 according to your environment and call it a day. You won't need proxy authentication or haproxy etc..

On Wed, May 3, 2017 at 3:35 PM, Craddock, Tommy <Tommy.Craddock at bicgraphic.com> wrote:

Hello,?Yeah, that guide is for PFsense in particular, but you could run HAProxy by itself (say in a VM) and get the same result.? Just fwd those ports from your router to the HAProxy box. 
Thanks!??From: squid-users [mailto:squid-users-bounces@ lists.squid-cache.org]On Behalf Of j m
Sent: Wednesday, May 03, 2017 3:14 PM
To: squid-users at lists.squid-cache. org
Subject: Re: [squid-users] HTTPS support?Looks interesting, but it looks complex and sounds like I'd need more of a router than I have to do it.From: "Craddock, Tommy" <Tommy.Craddock at bicgraphic.com >
To: "squid-users at lists.squid- cache.org" <squid-users at lists.squid- cache.org>
Sent: Wednesday, May 3, 2017 2:04 PM
Subject: Re: [squid-users] HTTPS support?Hello,?Is this more in line with what your trying to do:?http://loredo.me/post/ 116633549315/geeking-out-with- haproxy-on-pfsense-the- ultimate?Tommy?From: squid-users [mailto:squid-users-bounces@ lists.squid-cache.org]On Behalf Of j m
Sent: Wednesday, May 03, 2017 2:44 PM
To: squid-users at lists.squid-cache. org
Subject: Re: [squid-users] HTTPS support?In any case, I'm finding SSH through proxy is undesirable or not possible.? I'm thinking shellinabox, which is insecure but run over a secure proxy link, is my best bet.?From: Alex Rousskov <rousskov at measurement-factory. com>
To: j m <acctforjunk at yahoo.com>; "squid-users at lists.squid- cache.org" <squid-users at lists.squid- cache.org>
Sent: Wednesday, May 3, 2017 1:19 PM
Subject: Re: [squid-users] HTTPS support?On 05/03/2017 11:37 AM, j m wrote:
> the plan was to use SSH through the proxy.

If your SSH clients support SSH through an HTTP proxy, then do not
authenticate them in Squid. Just do not let them go anywhere but the SSH
server. It would be like running an exposed-to-the-world SSH server, no
worse. Squid will still know nothing about SSH. Squid will just tunnel
opaque bytes from your SSH clients to your SSH server. You will use an
HTTP (not HTTPS) Squid port for this traffic because your SSH clients
are unlikely to support HTTPS to the proxy.

Your browsers will still use HTTPS to the proxy (and get authenticated).
Thus, you will have two different http_ports, one for HTTP
(unauthenticated SSH clients) and one for HTTPS (authenticated browsers).

If SSH blocking is not based on _protocol_ but on port, then follow
Antony Stone advice and change the SSH server port instead of
HTTP-proxying SSH connections.

Alex.



> ------------------------------ ------------------------------ ------------
> *From:* Alex Rousskov <rousskov at measurement-factory. com>
> *To:* "squid-users at lists.squid- cache.org"
> <squid-users at lists.squid- cache.org>
> *Cc:* j m <acctforjunk at yahoo.com>
> *Sent:* Wednesday, May 3, 2017 12:22 PM
> *Subject:* Re: [squid-users] HTTPS support
> 
> On 05/03/2017 10:57 AM, j m wrote:
>> I wanted to set up a proxy on my home server for use from remote
>> locations to use as a web proxy (of course) and also to run SSH over.
> 
> The "ssh" part is unrelated to Squid. Secure ssh separately from Squid.
> 
> 
>> This means that basic auth is undesirable due to the login being sent
>> in clear text.? So, someone suggested digest auth, and I was happy.
>>? But, now I'm finding that PuTTY and WinSCP do not support digest auth.
>>? And consequently, I haven't found any other SSH clients that support
>> digest. (sigh)
> 
> These problems will go away if you stop mixing Squid and ssh. Squid is
> HTTP while PuTTY/WinSCP is SSH. You gain very little by trying to use
> the same authentication mechanism for both protocols in your use case.
> 
> 
>> So, I'm back to plan b, and that is to have a secure proxy connection so
>> all browser-to-server communication is encrypted.
> 
> That is a good idea if all of your browsers support it. Popular browsers
> support HTTPS-to-proxy on desktop, but I am not sure about their mobile
> versions. You may have to jump through some hoops.
> 
> 
> 
>> So the question is, does
>> anyone know if squid 3.5 on Ubuntu 16.04 supports secure connections?
> 
> 
> Squid v3.5 supports secure connections to the proxy. See "TLS / SSL
> Options" for the http_port directive (not the https_port directive!).
> 
> You can install Squid v3.5 on Ubuntu. I do not know whether the official
> Ubuntu Squid package is built with the required support.
> 
> 
> HTH,
> 
> Alex.
> 
> 
> 
> ?
______________________________ ______________________________ __________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________ ______________________________ __________
______________________________ ______________________________ __________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________ ______________________________ ________________________________________ _________________
squid-users mailing list
squid-users at lists.squid-cache. org
http://lists.squid-cache.org/ listinfo/squid-users?
______________________________ ______________________________ __________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________ ______________________________ __________
______________________________ ______________________________ __________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________ ______________________________ __________

______________________________ _________________
squid-users mailing list
squid-users at lists.squid-cache. org
http://lists.squid-cache.org/ listinfo/squid-users



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/0c4929ee/attachment.htm>

From acctforjunk at yahoo.com  Wed May  3 22:04:51 2017
From: acctforjunk at yahoo.com (j m)
Date: Wed, 3 May 2017 22:04:51 +0000 (UTC)
Subject: [squid-users] HTTPS support
In-Reply-To: <CAOsHgtvv7=GfqRCTq2aovEfkJfc+0q_7VCE_UEobeo_7b391fg@mail.gmail.com>
References: <1251311337.1946637.1493830629405.ref@mail.yahoo.com>
 <1251311337.1946637.1493830629405@mail.yahoo.com>
 <9541b1fa-cdf5-1777-0478-eabb36b06379@measurement-factory.com>
 <754215205.1965655.1493833056577@mail.yahoo.com>
 <51549da6-b09e-dbfe-d65f-89453bf38c8b@measurement-factory.com>
 <342639953.2054602.1493837055869@mail.yahoo.com>
 <CA86A9283AA07E478F6B0629521FFEE74D39C8@CLWSEXCMBX02.na.bicworld.com>
 <1970063095.2069926.1493838867209@mail.yahoo.com>
 <CA86A9283AA07E478F6B0629521FFEE74D3A88@CLWSEXCMBX02.na.bicworld.com>
 <CAOsHgtvv7=GfqRCTq2aovEfkJfc+0q_7VCE_UEobeo_7b391fg@mail.gmail.com>
Message-ID: <1568223823.2225203.1493849091663@mail.yahoo.com>

I forgot: I know VPN doesn't work from there, but it's on the standard port, so I could investigate that. ?However the issue is then everything else running will want to run over the VPN, e.g. email, IM, various IT services I don't know about.

      From: Daniel Greenwald <dig at digcorp.net>
 To: "Craddock, Tommy" <Tommy.Craddock at bicgraphic.com> 
Cc: "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org>
 Sent: Wednesday, May 3, 2017 3:23 PM
 Subject: Re: [squid-users] HTTPS support
   
Seems to me you are overthinking this. What you're up against is blocked outbound ports. Simply run openvpn at your home over one of the allowed outbound ports eg 80 443 or possibly 3128/8080 according to your environment and call it a day. You won't need proxy authentication or haproxy etc..

On Wed, May 3, 2017 at 3:35 PM, Craddock, Tommy <Tommy.Craddock at bicgraphic.com> wrote:

Hello,?Yeah, that guide is for PFsense in particular, but you could run HAProxy by itself (say in a VM) and get the same result.? Just fwd those ports from your router to the HAProxy box. 
Thanks!??From: squid-users [mailto:squid-users-bounces@ lists.squid-cache.org]On Behalf Of j m
Sent: Wednesday, May 03, 2017 3:14 PM
To: squid-users at lists.squid-cache. org
Subject: Re: [squid-users] HTTPS support?Looks interesting, but it looks complex and sounds like I'd need more of a router than I have to do it.From: "Craddock, Tommy" <Tommy.Craddock at bicgraphic.com >
To: "squid-users at lists.squid- cache.org" <squid-users at lists.squid- cache.org>
Sent: Wednesday, May 3, 2017 2:04 PM
Subject: Re: [squid-users] HTTPS support?Hello,?Is this more in line with what your trying to do:?http://loredo.me/post/ 116633549315/geeking-out-with- haproxy-on-pfsense-the- ultimate?Tommy?From: squid-users [mailto:squid-users-bounces@ lists.squid-cache.org]On Behalf Of j m
Sent: Wednesday, May 03, 2017 2:44 PM
To: squid-users at lists.squid-cache. org
Subject: Re: [squid-users] HTTPS support?In any case, I'm finding SSH through proxy is undesirable or not possible.? I'm thinking shellinabox, which is insecure but run over a secure proxy link, is my best bet.?From: Alex Rousskov <rousskov at measurement-factory. com>
To: j m <acctforjunk at yahoo.com>; "squid-users at lists.squid- cache.org" <squid-users at lists.squid- cache.org>
Sent: Wednesday, May 3, 2017 1:19 PM
Subject: Re: [squid-users] HTTPS support?On 05/03/2017 11:37 AM, j m wrote:
> the plan was to use SSH through the proxy.

If your SSH clients support SSH through an HTTP proxy, then do not
authenticate them in Squid. Just do not let them go anywhere but the SSH
server. It would be like running an exposed-to-the-world SSH server, no
worse. Squid will still know nothing about SSH. Squid will just tunnel
opaque bytes from your SSH clients to your SSH server. You will use an
HTTP (not HTTPS) Squid port for this traffic because your SSH clients
are unlikely to support HTTPS to the proxy.

Your browsers will still use HTTPS to the proxy (and get authenticated).
Thus, you will have two different http_ports, one for HTTP
(unauthenticated SSH clients) and one for HTTPS (authenticated browsers).

If SSH blocking is not based on _protocol_ but on port, then follow
Antony Stone advice and change the SSH server port instead of
HTTP-proxying SSH connections.

Alex.



> ------------------------------ ------------------------------ ------------
> *From:* Alex Rousskov <rousskov at measurement-factory. com>
> *To:* "squid-users at lists.squid- cache.org"
> <squid-users at lists.squid- cache.org>
> *Cc:* j m <acctforjunk at yahoo.com>
> *Sent:* Wednesday, May 3, 2017 12:22 PM
> *Subject:* Re: [squid-users] HTTPS support
> 
> On 05/03/2017 10:57 AM, j m wrote:
>> I wanted to set up a proxy on my home server for use from remote
>> locations to use as a web proxy (of course) and also to run SSH over.
> 
> The "ssh" part is unrelated to Squid. Secure ssh separately from Squid.
> 
> 
>> This means that basic auth is undesirable due to the login being sent
>> in clear text.? So, someone suggested digest auth, and I was happy.
>>? But, now I'm finding that PuTTY and WinSCP do not support digest auth.
>>? And consequently, I haven't found any other SSH clients that support
>> digest. (sigh)
> 
> These problems will go away if you stop mixing Squid and ssh. Squid is
> HTTP while PuTTY/WinSCP is SSH. You gain very little by trying to use
> the same authentication mechanism for both protocols in your use case.
> 
> 
>> So, I'm back to plan b, and that is to have a secure proxy connection so
>> all browser-to-server communication is encrypted.
> 
> That is a good idea if all of your browsers support it. Popular browsers
> support HTTPS-to-proxy on desktop, but I am not sure about their mobile
> versions. You may have to jump through some hoops.
> 
> 
> 
>> So the question is, does
>> anyone know if squid 3.5 on Ubuntu 16.04 supports secure connections?
> 
> 
> Squid v3.5 supports secure connections to the proxy. See "TLS / SSL
> Options" for the http_port directive (not the https_port directive!).
> 
> You can install Squid v3.5 on Ubuntu. I do not know whether the official
> Ubuntu Squid package is built with the required support.
> 
> 
> HTH,
> 
> Alex.
> 
> 
> 
> ?
______________________________ ______________________________ __________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________ ______________________________ __________
______________________________ ______________________________ __________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________ ______________________________ ________________________________________ _________________
squid-users mailing list
squid-users at lists.squid-cache. org
http://lists.squid-cache.org/ listinfo/squid-users?
______________________________ ______________________________ __________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________ ______________________________ __________
______________________________ ______________________________ __________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________ ______________________________ __________

______________________________ _________________
squid-users mailing list
squid-users at lists.squid-cache. org
http://lists.squid-cache.org/ listinfo/squid-users



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170503/d4960c59/attachment.htm>

From squid3 at treenet.co.nz  Thu May  4 02:32:37 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 4 May 2017 14:32:37 +1200
Subject: [squid-users] Passing Windows username to parent proxy
In-Reply-To: <F665DADF-0840-4194-A238-9B77804EDAE1@ntlworld.com>
References: <1493808471375-4682272.post@n4.nabble.com>
 <d5cc395d-65cc-e2c3-5811-4b61e33771b6@treenet.co.nz>
 <F665DADF-0840-4194-A238-9B77804EDAE1@ntlworld.com>
Message-ID: <3aeaaf0d-f8f1-12fb-d7c6-535f4a4fb373@treenet.co.nz>

On 04/05/17 02:19, BurningSky wrote:
> Hi Amos,
>
> Thanks for the reply. Sorry, what I meant by that was that I was logged into the Squid Windows server using remote desktop so that I could edit the configuration so that is separate from the machine trying to use Squid a a proxy.
>
> So it would seem like the issue is with the firewall from what you're saying? Using the most basic Squid config pointing it at the firewall as a parent should be all I need to do for the Windows username to be passed through to the firewall?

If I'm remembering it correctly yes.

Amos



From squid3 at treenet.co.nz  Thu May  4 02:38:16 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 4 May 2017 14:38:16 +1200
Subject: [squid-users] Squid as Proxy/Web Filer only
In-Reply-To: <CAOM=vzxBqO7JZbfOZJ1sKWgHMxzDN6bbzv8r3VaVSAyaTagRVA@mail.gmail.com>
References: <CAOM=vzxBqO7JZbfOZJ1sKWgHMxzDN6bbzv8r3VaVSAyaTagRVA@mail.gmail.com>
Message-ID: <20fbd9ac-ab83-a55b-c4de-17c8bf8b7c62@treenet.co.nz>

On 04/05/17 06:54, Skyvolt Zoltar wrote:
> Hi, I am completely new to Squid.
>
> I would like to know if it is possible to configure squid within my 
> network as a web filter only.
>
> The scenario would be like this.
>
> User's browser has proxy configuration > forwards all the browsers 
> request to Squid > squid does an analysis > squid forward to the 
> default gateway of my network.
>
> But all that within the same IP address range. I have a router already 
> doing the routing from my internal to external network.
>
> Or I cannot? Will Squid only work between two different network, with 
> different IP address (one IP for an internal interface and other for 
> external interface)?

Sure can. Squid works between any HTTP client(s) and server(s).

Amos



From squid3 at treenet.co.nz  Thu May  4 02:40:57 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 4 May 2017 14:40:57 +1200
Subject: [squid-users] Squid proxy without name resolution for internet
 adresses behind parent proxy
In-Reply-To: <1493837120705-4682289.post@n4.nabble.com>
References: <1493370033619-4682225.post@n4.nabble.com>
 <f6d4410e-32af-de08-b875-c4c34efd8f4a@gmail.com>
 <1493376531696-4682229.post@n4.nabble.com>
 <f4bcea5d-8681-dbb4-3cd3-ffacf5adbfc6@treenet.co.nz>
 <1493496450559-4682235.post@n4.nabble.com>
 <00e201d2c17e$16067e10$42137a30$@ngtech.co.il>
 <90f3e28b-99eb-b6d9-7382-d168f549bce6@treenet.co.nz>
 <1493837120705-4682289.post@n4.nabble.com>
Message-ID: <1f6825dd-774d-d1be-c99c-cea0f6eedcaa@treenet.co.nz>

On 04/05/17 06:45, mbaltruschat wrote:
> Hello Amos,
>
> many thanks, i think i got it, it was a Problem with my "never_direct"
> rules, i already got them in the conf, but the dont worked, so after your
> tips,  i wrote the conf from scratch in Notepad++ and now it works - i guess
> it was a Problem with charset while saving.
>
> again, many thanks, can i donate something for squid development? Paypal?

Donations to Squid project:
  <http://www.squid-cache.org/Foundation/donate.html>

or, Donations to me for time doing Squid related stuff:
  <http://treenet.co.nz/projects/squid/>

Amos



From nil_fergi at hotmail.com  Thu May  4 04:05:30 2017
From: nil_fergi at hotmail.com (Nil Nik)
Date: Thu, 4 May 2017 04:05:30 +0000
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <BY1PR10MB03577C3C006CEF30984D393584160@BY1PR10MB0357.namprd10.prod.outlook.com>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
 <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
 <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
 <215c7b2a-f034-5913-f0fe-00c2f4511b72@gmail.com>
 <123f43b6-4d76-9493-32c7-a0b05a794618@treenet.co.nz>
 <73c06bc6-87b6-d8c9-0d93-eeb6645cb1ac@gmail.com>,
 <35f15acb-9b86-edc7-1152-a53dfaabfc22@measurement-factory.com>,
 <BY1PR10MB03577C3C006CEF30984D393584160@BY1PR10MB0357.namprd10.prod.outlook.com>
Message-ID: <BY1PR10MB03573D77B16052D873CF27DE84EA0@BY1PR10MB0357.namprd10.prod.outlook.com>

Hi,


Can we cleanup 'Cache' using -

SSL_flush_sessions(ctx, time(NULL));  or
SSL_flush_sessions(ctx,0);

Periodically or on reconfigure?

Nil

________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Nil Nik <nil_fergi at hotmail.com>
Sent: Wednesday, May 3, 2017 11:54 AM
To: Alex Rousskov; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Huge memory required for squid 3.5

Hi,


NO_DEFAULT_CA doesn't help. Still goes in GB. Can anyone tell me area so that i can work on?


Regards,

Nil


________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Alex Rousskov <rousskov at measurement-factory.com>
Sent: Wednesday, April 26, 2017 7:37 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Huge memory required for squid 3.5

On 04/26/2017 09:35 AM, Yuri Voinov wrote:

> This is openssl issue or squid's?

AFAIK, the underlying issue (i.e., bug #4005) is mostly a Squid problem:
Squid is caching SSL contexts (instead of certificates) and does a poor
job maintaining that cache.

Earlier OpenSSL versions (that had to be used when the original code was
written) complicated solving this problem. OpenSSL v1.0.1+ added APIs
that simplify some aspects of the anticipated fix. Certain OpenSSL
aspects will continue to hurt Squid, even with OpenSSL v1.0.1, but if
you want to blame a single project (instead of both), blame Squid.


> Why sessions can't share CA's data cached in memory? shared_ptr invented
> already.

OpenSSL knew how to share things well before std::shared_ptr became
available. However, it is the responsibility of the application to tell
OpenSSL what to create from scratch and what to share. A part of the
problem is that Squid tells OpenSSL to create many large things from
scratch and then caches those large things while underestimating their
size by several(?) orders of magnitude (and probably also missing many
cache hits).

More details, including the difference between problems associated with
from-client and to-server connections, are documented in the "Memory
Usage" section of http://wiki.squid-cache.org/Features/SslBump
Features/SslBump - Squid Web Proxy Wiki<http://wiki.squid-cache.org/Features/SslBump>
wiki.squid-cache.org
Squid-in-the-middle decryption and encryption of straight CONNECT and transparently redirected SSL traffic, using configurable CA certificates.



FWIW, we have spent a lot of resources on triaging this problem and
drafting possible solutions (in various overlapping areas), but there is
currently no sponsor to finalize and implement any of the fixes. AFAIK,
bug #4005 is stuck.

I am glad that NO_DEFAULT_CA helps mitigate some of the problems in some
environments.


HTH,

Alex.


> 26.04.2017 9:08, Amos Jeffries ?????:
>> On 26/04/17 10:53, Yuri Voinov wrote:
>>> Ok, but how NO_DEFAULT_CA should help with this?
>>
>> It prevents OpenSSL copying that 1MB into each incoming client
>> connections memory. The CAs are only useful there when you have some
>> of the global CAs as root for client certificates - in which case you
>> still only want to trust the roots you paid for service and not all of
>> them.
>>
>> Just something to try if there are huge memory issues with TLS/SSL
>> proxying. The default behaviour is fixed for Squid-4 with the config
>> options changes. But due to being a major surprise for anyone already
>> relying on global roots for client certs it remains a problem in 3.5.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users


>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users


>

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170504/d9d71e34/attachment.htm>

From nil_fergi at hotmail.com  Thu May  4 04:21:05 2017
From: nil_fergi at hotmail.com (Nil Nik)
Date: Thu, 4 May 2017 04:21:05 +0000
Subject: [squid-users] Squid dead error with 3.5.23
Message-ID: <BY1PR10MB03573793452EB94AA58D981584EA0@BY1PR10MB0357.namprd10.prod.outlook.com>

Hi,


Using Squid 3.5.23, After some time found squid dead with below errors. Even i restart it doesn't start for some time (5-10 minutes).


Apr 28 16:16:18 mysystem (squid-1): Ipc::Mem::Segment::open failed to shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
Apr 28 16:16:18 mysystem squid[30477]: Squid Parent: (squid-1) process 30490 exited with status 1
Apr 28 16:16:21 mysystem squid[30477]: Squid Parent: (squid-1) process 30495 started
Apr 28 16:16:21 mysystem (squid-1): Ipc::Mem::Segment::open failed to shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
Apr 28 16:16:21 mysystem squid[30477]: Squid Parent: (squid-1) process 30495 exited with status 1
Apr 28 16:16:24 mysystem squid[30477]: Squid Parent: (squid-1) process 30500 started
Apr 28 16:16:24 mysystem (squid-1): Ipc::Mem::Segment::open failed to shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
Apr 28 16:16:24 mysystem squid[30477]: Squid Parent: (squid-1) process 30500 exited with status 1
Apr 28 16:16:24 mysystem squid[30477]: Squid Parent: (squid-1) process 30500 will not be restarted due to repeated, frequent failures
Apr 28 16:16:24 mysystem squid[30477]: Exiting due to repeated, frequent failures

I was using squid 3.3.9 never observed such kind of issue.
Please help.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170504/f1e71dd9/attachment.htm>

From sblachmann at gmail.com  Thu May  4 04:55:01 2017
From: sblachmann at gmail.com (Stefan Blachmann)
Date: Thu, 4 May 2017 06:55:01 +0200
Subject: [squid-users] Can I use squid to reverse proxy https (without
	making it a man-in-the-middle)?
Message-ID: <CACc-My2BPEHDLSpT9EL+zZxK407BiaLP9E5rKWP3vvBWzCB5sA@mail.gmail.com>

I am using squid 3.5.23 for no-caching reverse proxying http to
backend web servers.
I want to do the same with https.

If I try to make cache_peer, acl, http_access and cache_peer_access
for port 443 in addition to port 80, the connection attempt fails with
browser complaining about error code: SSL_ERROR_RX_RECORD_TOO_LONG. In
squid access log then there is a complaint about "invalid request".

Is there a way to configure squid to just pass through https traffic
to https backends? Just like it does with http?
That is, _without_ needing to give squid access to the certificates and keys?

(I ask because all instructions I found in the web are
privacy-breaking decrypting Mitm interception instructions. And I do
_not_ want to do it this way!)


From sam.egerton at ntlworld.com  Thu May  4 07:29:18 2017
From: sam.egerton at ntlworld.com (BurningSky)
Date: Thu, 4 May 2017 00:29:18 -0700 (PDT)
Subject: [squid-users] Passing Windows username to parent proxy
In-Reply-To: <3aeaaf0d-f8f1-12fb-d7c6-535f4a4fb373@treenet.co.nz>
References: <1493808471375-4682272.post@n4.nabble.com>
 <d5cc395d-65cc-e2c3-5811-4b61e33771b6@treenet.co.nz>
 <F665DADF-0840-4194-A238-9B77804EDAE1@ntlworld.com>
 <3aeaaf0d-f8f1-12fb-d7c6-535f4a4fb373@treenet.co.nz>
Message-ID: <1493882958266-4682303.post@n4.nabble.com>

Is there a way to view what Squid is forwarding so that I can inspect the
packets to prove that Squid is sending user information as I have a call
open with the firewall vendor and I want to be able to tell them with
certainty that it is an issue at the firewall end rather than the Squid end.

Thanks,
Sam



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Passing-Windows-username-to-parent-proxy-tp4682272p4682303.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From listes at e-gaulue.com  Thu May  4 09:03:21 2017
From: listes at e-gaulue.com (=?UTF-8?Q?Edouard_Gaulu=c3=a9?=)
Date: Thu, 4 May 2017 11:03:21 +0200
Subject: [squid-users] ssl bump and url_rewrite_program (like squidguard)
In-Reply-To: <563939D3.20804@e-gaulue.com>
References: <563939D3.20804@e-gaulue.com>
Message-ID: <b0d1d249-f52a-4179-378b-f4345ea381ce@e-gaulue.com>

Hi community,

Any news about this?

I've tried 3.5.25 but still observe this behaviour.

I understand it well since I read: 
https://serverfault.com/questions/727262/how-to-redirect-https-connect-request-with-squid-explicit-proxy

But how to let the CONNECT request succeed and later block/redirect next 
HTTP request coming through this established connection tunnel?

Best Regards,

Le 03/11/2015 ? 23:48, Edouard Gaulu? a ?crit :
> Hi community,
>
> I've followed
> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit  to
> set my server. It looks really interesting and it's said to be the more
> common configuration.
>
> I often observe (example here withwww.youtube.com) :
> ***************************
> The following error was encountered while trying to retrieve the URL:
> https://http/*
>
>     *Unable to determine IP address from host name "http"*
>
> The DNS server returned:
>
>     Name Error: The domain name does not exist.
> ****************************
>
> This happens while the navigator (Mozilla) is trying to get a frame at
> https://ad.doubleclick.net/N4061/adi/com.ythome/_default;sz=970x250;tile=1;ssl=1;dc_yt=1;kbsg=HPFR151103;kga=-1;kgg=-1;klg=fr;kmyd=ad_creative_1;ytexp=9406852,9408210,9408502,9417689,9419444,9419802,9420440,9420473,9421645,9421711,9422141,9422865,9423510,9423563,9423789;ord=968558538238386? 
>
>
> That's ads so I'm not so fond of it...
>
> But this leads me to the fact I get this behavior each time the site is
> banned by squidguard.
>
> Is there something to do to avoid this behavior? I mean, squidguard
> should send :
>
> *********************************
>   Access denied
>
> Supplementary info     :
> Client address     =     192.168.XXX.XXX
> Client name     =     192.168.XXX.XXX
> User ident     =
> Client group     =     XXXXXXX
> URL     =     https://ad.doubleclick.net/
> Target class     =     ads
>
> If this is wrong, contact your administrator
> **********************************
>
> squidguard is an url_rewrite_program that looks to respect squid
> requirements. Redirect looks like this :
> http://proxyweb.myserver.mydomain/cgi-bin/squidGuard-simple.cgi?clientaddr=... 
>
>
> I've played arround trying to change the redirect URL and it leads me to
> the idea ssl_bump tries to analyse the part until the ":". Is there a way
> to avoid this? Is this just a configuration matter?
>
> Could putting a ssl_bump rule saying "every server that name match 
> "http" or
> "https" should splice" solve the problem?
>
> Regards, EG
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users




From sam.egerton at ntlworld.com  Thu May  4 09:13:45 2017
From: sam.egerton at ntlworld.com (BurningSky)
Date: Thu, 4 May 2017 02:13:45 -0700 (PDT)
Subject: [squid-users] Passing Windows username to parent proxy
In-Reply-To: <1493882958266-4682303.post@n4.nabble.com>
References: <1493808471375-4682272.post@n4.nabble.com>
 <d5cc395d-65cc-e2c3-5811-4b61e33771b6@treenet.co.nz>
 <F665DADF-0840-4194-A238-9B77804EDAE1@ntlworld.com>
 <3aeaaf0d-f8f1-12fb-d7c6-535f4a4fb373@treenet.co.nz>
 <1493882958266-4682303.post@n4.nabble.com>
Message-ID: <1493889225013-4682305.post@n4.nabble.com>

I just read http://wiki.squid-cache.org/Features/LogFormat. The 8th column is
showing - rather than a user name, could this be the issue? What causes a -
to be shown rather than a users name and how can I get round this?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Passing-Windows-username-to-parent-proxy-tp4682272p4682305.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From acctforjunk at yahoo.com  Thu May  4 11:14:18 2017
From: acctforjunk at yahoo.com (j m)
Date: Thu, 4 May 2017 11:14:18 +0000 (UTC)
Subject: [squid-users] Tutorial for better authentication than basic
In-Reply-To: <032b01d2c335$ba5e4930$2f1adb90$@ngtech.co.il>
References: <456739995.1458100.1493644706831.ref@mail.yahoo.com>
 <456739995.1458100.1493644706831@mail.yahoo.com>
 <02b801d2c292$df68d950$9e3a8bf0$@ngtech.co.il>
 <742538244.50351.1493672695826@mail.yahoo.com>
 <032b01d2c335$ba5e4930$2f1adb90$@ngtech.co.il>
Message-ID: <1112968001.2630137.1493896458609@mail.yahoo.com>

Wow, this only showed up in my email yesterday. ?I blame Yahoo.
I did respond earlier basically saying I would need to connect from different IPs.

      From: Eliezer Croitoru <eliezer at ngtech.co.il>
 To: 'j m' <acctforjunk at yahoo.com>; squid-users at lists.squid-cache.org 
 Sent: Wednesday, May 3, 2017 6:37 PM
 Subject: RE: [squid-users] Tutorial for better authentication than basic
   
There is another option if you don't have any issue to allow a certain public IP address access to your network you can use some kind of portal which will allow based on a SSL(even with self signed certificate) the "session" access to the service.

If it sounds fine let me know and I will prepare and example.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of j m
Sent: Tuesday, May 2, 2017 12:05 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Tutorial for better authentication than basic

Wow, I didn't find that one.? Not super secure, but better than clear text and I'm not too worried about someone sniffing my packets.
________________________________________
From: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
To: 'j m' <mailto:acctforjunk at yahoo.com>; mailto:squid-users at lists.squid-cache.org 
Sent: Monday, May 1, 2017 3:30 PM
Subject: RE: [squid-users] Tutorial for better authentication than basic

And what about digest authentication?

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il

From: squid-users [mailto:mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of j m
Sent: Monday, May 1, 2017 4:18 PM
To: mailto:squid-users at lists.squid-cache.org
Subject: [squid-users] Tutorial for better authentication than basic

I'm using Ubuntu 16.04 Server in the home and would like to set up a proxy server for use from over the Internet.? The main purpose for this is to easily access a few web-devices on my LAN without using VPN, and at times to route web traffic from a remote location through my home ISP.? I do not need nor want any caching or filtering.

I previously used Tinyproxy and that did the job, but it had no authentication whatsoever.? I have basic authentication working on squid 3.5, where it asks for the username and password, but I believe this login is sent in clear text.? I've did some research and found squid supports various better methods, such as kerberos, ntlm, smb, etc.? However, while I'm able to install Linux and set up various things, I'm struggling with this authentication aspect.? I have a suspicion some of these methods will not work well because they rely on other services (such as SMB) and may require opening more ports on my router, something I'm not crazy about.

Amos previously suggested client cert auth, but I'm not sure how to set this up.? Are there any other secure auth methods that would work well over the Internet and are fairly simple to configure?

In any case, can anyone point me to an online tutorial somewhere (for a authentication newbie) that outlines how this is done?



   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170504/f199b272/attachment.htm>

From marcus.kool at urlfilterdb.com  Thu May  4 11:43:47 2017
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Thu, 4 May 2017 08:43:47 -0300
Subject: [squid-users] ssl bump and url_rewrite_program (like squidguard)
In-Reply-To: <b0d1d249-f52a-4179-378b-f4345ea381ce@e-gaulue.com>
References: <563939D3.20804@e-gaulue.com>
 <b0d1d249-f52a-4179-378b-f4345ea381ce@e-gaulue.com>
Message-ID: <5c3f219d-da61-b2f1-b056-dfcd92104c40@urlfilterdb.com>

Hi Edouard,

To block GET https://www.example.com/foo.html and to pass CONNECT www,example.com you need
a) squid with ssl-bump in peek+bump mode
b) ufdbGuard

ufdbGuard can skip the CONNECT and waits for the GET request
which can be blocked without browser errors.

Since ssl-bump is not easy it is recommended to do this in two steps:
a) make sure that Squid with ssl-bump works fine,
b) then add ufdbGuard.

Marcus


On 04/05/17 06:03, Edouard Gaulu? wrote:
> Hi community,
>
> Any news about this?
>
> I've tried 3.5.25 but still observe this behaviour.
>
> I understand it well since I read: https://serverfault.com/questions/727262/how-to-redirect-https-connect-request-with-squid-explicit-proxy
>
> But how to let the CONNECT request succeed and later block/redirect next HTTP request coming through this established connection tunnel?
>
> Best Regards,
>
> Le 03/11/2015 ? 23:48, Edouard Gaulu? a ?crit :
>> Hi community,
>>
>> I've followed
>> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit  to
>> set my server. It looks really interesting and it's said to be the more
>> common configuration.
>>
>> I often observe (example here withwww.youtube.com) :
>> ***************************
>> The following error was encountered while trying to retrieve the URL:
>> https://http/*
>>
>>     *Unable to determine IP address from host name "http"*
>>
>> The DNS server returned:
>>
>>     Name Error: The domain name does not exist.
>> ****************************
>>
>> This happens while the navigator (Mozilla) is trying to get a frame at
>> https://ad.doubleclick.net/N4061/adi/com.ythome/_default;sz=970x250;tile=1;ssl=1;dc_yt=1;kbsg=HPFR151103;kga=-1;kgg=-1;klg=fr;kmyd=ad_creative_1;ytexp=9406852,9408210,9408502,9417689,9419444,9419802,9420440,9420473,9421645,9421711,9422141,9422865,9423510,9423563,9423789;ord=968558538238386?
>>
>>
>> That's ads so I'm not so fond of it...
>>
>> But this leads me to the fact I get this behavior each time the site is
>> banned by squidguard.
>>
>> Is there something to do to avoid this behavior? I mean, squidguard
>> should send :
>>
>> *********************************
>>   Access denied
>>
>> Supplementary info     :
>> Client address     =     192.168.XXX.XXX
>> Client name     =     192.168.XXX.XXX
>> User ident     =
>> Client group     =     XXXXXXX
>> URL     =     https://ad.doubleclick.net/
>> Target class     =     ads
>>
>> If this is wrong, contact your administrator
>> **********************************
>>
>> squidguard is an url_rewrite_program that looks to respect squid
>> requirements. Redirect looks like this :
>> http://proxyweb.myserver.mydomain/cgi-bin/squidGuard-simple.cgi?clientaddr=...
>>
>> I've played arround trying to change the redirect URL and it leads me to
>> the idea ssl_bump tries to analyse the part until the ":". Is there a way
>> to avoid this? Is this just a configuration matter?
>>
>> Could putting a ssl_bump rule saying "every server that name match "http" or
>> "https" should splice" solve the problem?
>>
>> Regards, EG
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From skyvolt at gmail.com  Thu May  4 14:19:28 2017
From: skyvolt at gmail.com (Skyvolt Zoltar)
Date: Thu, 4 May 2017 11:19:28 -0300
Subject: [squid-users] Squid as Proxy/Web Filer only
In-Reply-To: <20fbd9ac-ab83-a55b-c4de-17c8bf8b7c62@treenet.co.nz>
References: <CAOM=vzxBqO7JZbfOZJ1sKWgHMxzDN6bbzv8r3VaVSAyaTagRVA@mail.gmail.com>
 <20fbd9ac-ab83-a55b-c4de-17c8bf8b7c62@treenet.co.nz>
Message-ID: <CAOM=vzwVXGaLOgmHdT6MeaWY7WWY_tqy1KoLCPHbvyGFOfNaEw@mail.gmail.com>

Thank you for your answers. I will look the blacklist thing. I do not need
too much control at this time.



On Wed, May 3, 2017 at 11:38 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 04/05/17 06:54, Skyvolt Zoltar wrote:
>
>> Hi, I am completely new to Squid.
>>
>> I would like to know if it is possible to configure squid within my
>> network as a web filter only.
>>
>> The scenario would be like this.
>>
>> User's browser has proxy configuration > forwards all the browsers
>> request to Squid > squid does an analysis > squid forward to the default
>> gateway of my network.
>>
>> But all that within the same IP address range. I have a router already
>> doing the routing from my internal to external network.
>>
>> Or I cannot? Will Squid only work between two different network, with
>> different IP address (one IP for an internal interface and other for
>> external interface)?
>>
>
> Sure can. Squid works between any HTTP client(s) and server(s).
>
> Amos
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170504/29ba63af/attachment.htm>

From rousskov at measurement-factory.com  Thu May  4 14:44:51 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 4 May 2017 08:44:51 -0600
Subject: [squid-users] Squid dead error with 3.5.23
In-Reply-To: <BY1PR10MB03573793452EB94AA58D981584EA0@BY1PR10MB0357.namprd10.prod.outlook.com>
References: <BY1PR10MB03573793452EB94AA58D981584EA0@BY1PR10MB0357.namprd10.prod.outlook.com>
Message-ID: <5ac04d4b-52a3-c7b7-3a68-8f499869beb0@measurement-factory.com>

On 05/03/2017 10:21 PM, Nil Nik wrote:

> Using Squid 3.5.23, After some time found squid dead with below errors.
> Even i restart it doesn't start for some time (5-10 minutes).

If your Squid started OK at some time and then, after working OK for a
while, failed and could not be restarted after that a failure, then your
restarting procedure is broken. There are Squid bugs that affect you,
but if you fix the restarting procedure, you should be able to restart
Squid despite those Squid bugs.

Specifically, make sure that there are no Squid processes running when
you start a new Squid process. Do not rely exclusively on PID file
absence until that becomes safe (we are working on making it safe).

Also, search the mailing list archive for ssl_session_cache.shm. You may
find threads with other relevant advice.


> Apr 28 16:16:18 mysystem (squid-1): Ipc::Mem::Segment::open failed to
> shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory

This is a sign of OS misconfiguration (if Squid never works OK) or
broken Squid [re]starting procedure (if Squid works OK but cannot be
restarted after a failure).

There are also Squid bugs that may affect you, including:

* Race conditions related to shared memory segments maintenance.
* Using a shared SSL session cache when none is needed.

FWIW, Factory is actively working on fixing the former.


> I was using squid 3.3.9 never observed such kind of issue.

Older Squids did not use shared SSL session caches (or shared memory
segments at all) and tolerated broken restart scripts better. We are
working on restoring that robustness (to the extent possible).

Alex.



From blaxxton at yahoo.com  Fri May  5 03:47:47 2017
From: blaxxton at yahoo.com (Blaxton)
Date: Fri, 5 May 2017 03:47:47 +0000 (UTC)
Subject: [squid-users] limit access with acl only based on source and
 destination domain
In-Reply-To: <a49a4f3e-73a4-f84f-f356-097743f14d0d@treenet.co.nz>
References: <982145555.1000130.1493772004922.ref@mail.yahoo.com>
 <982145555.1000130.1493772004922@mail.yahoo.com>
 <a49a4f3e-73a4-f84f-f356-097743f14d0d@treenet.co.nz>
Message-ID: <1061329603.2784761.1493956067490@mail.yahoo.com>

What is the difference between :
http_access allow From_Source_Domains
http_access allow To_Destination_Domains

And

http_access allow From_Source_Domains To_Destination_Domains

?


      From: Amos Jeffries <squid3 at treenet.co.nz>
 To: squid-users at lists.squid-cache.org 
 Sent: Wednesday, May 3, 2017 8:19 AM
 Subject: Re: [squid-users] limit access with acl only based on source and destination domain
   
On 03/05/17 12:40, Blaxton wrote:
> Hi
>
> I am trying to limit the out bound connection based on list of domain 
> names defined
> in srcdomain and dstdomain.
>
> Here is acl :
>
> acl From_Source_Domains srcdomain domain1 domain2 domain3
> acl To_Destination_Domains dstdomain domain4 domain5 domain6
>
> Now some web site says below considered OR and it is working for me:
> http_access allow From_Source_Domains
> http_access allow To_Destination_Domains
>
> And some web sites saying below considered AND but it is not working 
> for me:
> http_access allow From_Source_Domains To_Destination_Domains
>
> I am assuming since I have not allowed any port, then port should be 
> disabled
> but it is not, on OR of the src and dst domains.

No, ports are not part of that lines rule. There is no enable/disable - 
they are simply irrelevant when processing that line.

Traffic which gets filtered by that line coming from any client whose IP 
address rDNS matches one of the "From_Source_Domains" AND URL contains 
one of the "To_Destination_Domains" gets allowed into Squid.

>
> If add
> acl http_port 80
> http_access allow http_port
>
> Then it allow traffic from any source to any destination if port is 80.
>
> Kind of confusing and need a bit of help.

The "how" is simple:

? http_access lines are processed from top to bottom, left to right. 
First fully matching line wins and its action (allow or deny) happens.

<wiki.squid-cache.org/SquidFaq/OrderIsImportant>
<http://wiki.squid-cache.org/SquidFaq/SquidAcl#The_Basics:_How_the_parts_fit_together>
<http://wiki.squid-cache.org/SquidFaq/SquidAcl#Common_Mistakes>

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170505/8009cb0a/attachment.htm>

From squid3 at treenet.co.nz  Fri May  5 04:12:30 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 5 May 2017 16:12:30 +1200
Subject: [squid-users] limit access with acl only based on source and
 destination domain
In-Reply-To: <1061329603.2784761.1493956067490@mail.yahoo.com>
References: <982145555.1000130.1493772004922.ref@mail.yahoo.com>
 <982145555.1000130.1493772004922@mail.yahoo.com>
 <a49a4f3e-73a4-f84f-f356-097743f14d0d@treenet.co.nz>
 <1061329603.2784761.1493956067490@mail.yahoo.com>
Message-ID: <57367ed3-3a9d-c2ed-527b-e3de5621e8d9@treenet.co.nz>

On 05/05/17 15:47, Blaxton wrote:
> What is the difference between :

That is documented in 
<http://wiki.squid-cache.org/SquidFaq/SquidAcl#Common_Mistakes>


if:
> http_access allow From_Source_Domains
or, if:
> http_access allow To_Destination_Domains
or, deny all


versus ...

if:
> http_access allow From_Source_Domains To_Destination_Domains
or, deny all.



Amos


From blaxxton at yahoo.com  Fri May  5 04:23:52 2017
From: blaxxton at yahoo.com (Blaxton)
Date: Fri, 5 May 2017 04:23:52 +0000 (UTC)
Subject: [squid-users] limit access with acl only based on source and
 destination domain
In-Reply-To: <57367ed3-3a9d-c2ed-527b-e3de5621e8d9@treenet.co.nz>
References: <982145555.1000130.1493772004922.ref@mail.yahoo.com>
 <982145555.1000130.1493772004922@mail.yahoo.com>
 <a49a4f3e-73a4-f84f-f356-097743f14d0d@treenet.co.nz>
 <1061329603.2784761.1493956067490@mail.yahoo.com>
 <57367ed3-3a9d-c2ed-527b-e3de5621e8d9@treenet.co.nz>
Message-ID: <922809777.2808027.1493958232864@mail.yahoo.com>

> acl From_Source_Domains srcdomain domain1 domain2 domain3
> acl To_Destination_Domains dstdomain domain4 domain5 domain6
if:
> http_access allow From_Source_Domains
or, if:
> http_access allow To_Destination_Domains
or, deny all

According to your answer, if these are ORed, first http_access should allow connection to everywhere from ?domain1,domain2,domain3Second http_access allow connections to from everywhere.

Is above statement correct ?


      From: Amos Jeffries <squid3 at treenet.co.nz>
 To: "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Thursday, May 4, 2017 11:12 PM
 Subject: Re: [squid-users] limit access with acl only based on source and destination domain
   
On 05/05/17 15:47, Blaxton wrote:
> What is the difference between :

That is documented in 
<http://wiki.squid-cache.org/SquidFaq/SquidAcl#Common_Mistakes>


if:
> http_access allow From_Source_Domains
or, if:
> http_access allow To_Destination_Domains
or, deny all


versus ...

if:
> http_access allow From_Source_Domains To_Destination_Domains
or, deny all.



Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170505/300c301c/attachment.htm>

From squid3 at treenet.co.nz  Fri May  5 10:57:58 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 5 May 2017 22:57:58 +1200
Subject: [squid-users] limit access with acl only based on source and
 destination domain
In-Reply-To: <922809777.2808027.1493958232864@mail.yahoo.com>
References: <982145555.1000130.1493772004922.ref@mail.yahoo.com>
 <982145555.1000130.1493772004922@mail.yahoo.com>
 <a49a4f3e-73a4-f84f-f356-097743f14d0d@treenet.co.nz>
 <1061329603.2784761.1493956067490@mail.yahoo.com>
 <57367ed3-3a9d-c2ed-527b-e3de5621e8d9@treenet.co.nz>
 <922809777.2808027.1493958232864@mail.yahoo.com>
Message-ID: <e6c1c26a-69db-f44d-4f1e-6ac0e3ff7af7@treenet.co.nz>

On 05/05/17 16:23, Blaxton wrote:
> > acl From_Source_Domains srcdomain domain1 domain2 domain3
> > acl To_Destination_Domains dstdomain domain4 domain5 domain6
>
> if:
> > http_access allow From_Source_Domains
> or, if:
> > http_access allow To_Destination_Domains
> or, deny all
>
> According to your answer, if these are ORed, first http_access should 
> allow connection to everywhere from domain1,domain2,domain3
> Second http_access allow connections to from everywhere.
>
>
> Is above statement correct ?

What I mean is Squid performs these in this exact order:

The first line is checked.
   If From_Source_Domains matches the traffic is allowed.
Otherwise the second line gets checked.
  If To_Destination_Domains matches, the traffic is allowed.
Otherwise the traffic is denied.

Amos



From bosscb.chrisbren at gmail.com  Fri May  5 15:18:33 2017
From: bosscb.chrisbren at gmail.com (christian brendan)
Date: Fri, 5 May 2017 16:18:33 +0100
Subject: [squid-users] Squid Cache to Users at Full Bandwidth
Message-ID: <CAHptoxrgO2CbtapCTnzf=uWcM3MsH7Gzh2AcxCBqeZn_tsUO+w@mail.gmail.com>

Squid Version 3.5.20
Cento 7
Mikrotik RouterBoard v 6.39.1
Users IP: 192.168.1.0/24
Squid ip: 192.168.2.1

Traffic to squid is routed

i would like users to have full LAN bandwidth access to squid server, i
have tried simple queue on mikrotik but it seems not to be working.

Any guide will be appreciated.

Best Regards
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170505/f49ed72e/attachment.htm>

From yvoinov at gmail.com  Fri May  5 17:46:29 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 5 May 2017 23:46:29 +0600
Subject: [squid-users] Squid Cache to Users at Full Bandwidth
In-Reply-To: <CAHptoxrgO2CbtapCTnzf=uWcM3MsH7Gzh2AcxCBqeZn_tsUO+w@mail.gmail.com>
References: <CAHptoxrgO2CbtapCTnzf=uWcM3MsH7Gzh2AcxCBqeZn_tsUO+w@mail.gmail.com>
Message-ID: <a63ba7ad-61d2-f16d-5623-235b108d24d7@gmail.com>

http://wiki.squid-cache.org/


05.05.2017 21:18, christian brendan ?????:
> Squid Version 3.5.20
> Cento 7
> Mikrotik RouterBoard v 6.39.1
> Users IP: 192.168.1.0/24 <http://192.168.1.0/24>
> Squid ip: 192.168.2.1
>
> Traffic to squid is routed
>
> i would like users to have full LAN bandwidth access to squid server,
> i have tried simple queue on mikrotik but it seems not to be working.
>
> Any guide will be appreciated.
>
> Best Regards
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170505/b26dda8f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170505/b26dda8f/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170505/b26dda8f/attachment.sig>

From Antony.Stone at squid.open.source.it  Fri May  5 18:04:39 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 5 May 2017 19:04:39 +0100
Subject: [squid-users] Squid Cache to Users at Full Bandwidth
In-Reply-To: <CAHptoxrgO2CbtapCTnzf=uWcM3MsH7Gzh2AcxCBqeZn_tsUO+w@mail.gmail.com>
References: <CAHptoxrgO2CbtapCTnzf=uWcM3MsH7Gzh2AcxCBqeZn_tsUO+w@mail.gmail.com>
Message-ID: <201705051904.39473.Antony.Stone@squid.open.source.it>

On Friday 05 May 2017 at 16:18:33, christian brendan wrote:

> Squid Version 3.5.20
> Cento 7
> Mikrotik RouterBoard v 6.39.1
> Users IP: 192.168.1.0/24
> Squid ip: 192.168.2.1
> 
> Traffic to squid is routed
> 
> i would like users to have full LAN bandwidth access to squid server, i
> have tried simple queue on mikrotik but it seems not to be working.

How does it "not seem to be working"?

A "queue" on the Mikrotik would normally be used to restrict bandwidth, not 
increase it.  Please give details of how you have implemented this queue.

A few further questions:

1. Is Squid running on the Routerboard, or on a rather more capable machine?

2. If the client machines access the Internet directly (ie: not via Squid), do 
they also go via the Routerboard?

3. How are you measuring bandwidth for the clients?


Antony.

-- 
I thought I had type A blood, but it turned out to be a typo.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From bosscb.chrisbren at gmail.com  Sat May  6 17:21:23 2017
From: bosscb.chrisbren at gmail.com (christian brendan)
Date: Sat, 6 May 2017 18:21:23 +0100
Subject: [squid-users] Squid Cache to Users at Full Bandwidth
Message-ID: <CAHptoxqvzSir5sTjASLrRD66P6fQxJaL+sDurDPd-17M7ofFiw@mail.gmail.com>

On Sat, May 6, 2017 at 1:00 PM, <squid-users-request at lists.squid-cache.org>
wrote:

> Send squid-users mailing list submissions to
>         squid-users at lists.squid-cache.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         http://lists.squid-cache.org/listinfo/squid-users
> or, via email, send a message with subject or body 'help' to
>         squid-users-request at lists.squid-cache.org
>
> You can reach the person managing the list at
>         squid-users-owner at lists.squid-cache.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
>
>
> Today's Topics:
>
>    1. Squid Cache to Users at Full Bandwidth (christian brendan)
>    2. Re: Squid Cache to Users at Full Bandwidth (Yuri Voinov)
>    3. Re: Squid Cache to Users at Full Bandwidth (Antony Stone)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Fri, 5 May 2017 16:18:33 +0100
> From: christian brendan <bosscb.chrisbren at gmail.com>
> To: squid-users at lists.squid-cache.org,
>         squid-users-owner at lists.squid-cache.org
> Subject: [squid-users] Squid Cache to Users at Full Bandwidth
> Message-ID:
>         <CAHptoxrgO2CbtapCTnzf=uWcM3MsH7Gzh2AcxCBqeZn_tsUO+w at mail.
> gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Squid Version 3.5.20
> Cento 7
> Mikrotik RouterBoard v 6.39.1
> Users IP: 192.168.1.0/24
> Squid ip: 192.168.2.1
>
> Traffic to squid is routed
>
> i would like users to have full LAN bandwidth access to squid server, i
> have tried simple queue on mikrotik but it seems not to be working.
>
> Any guide will be appreciated.
>
> Best Regards
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <http://lists.squid-cache.org/pipermail/squid-users/
> attachments/20170505/f49ed72e/attachment-0001.html>
>
> ------------------------------
>
> Message: 2
> Date: Fri, 5 May 2017 23:46:29 +0600
> From: Yuri Voinov <yvoinov at gmail.com>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid Cache to Users at Full Bandwidth
> Message-ID: <a63ba7ad-61d2-f16d-5623-235b108d24d7 at gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> http://wiki.squid-cache.org/
>
>
> 05.05.2017 21:18, christian brendan ?????:
> > Squid Version 3.5.20
> > Cento 7
> > Mikrotik RouterBoard v 6.39.1
> > Users IP: 192.168.1.0/24 <http://192.168.1.0/24>
> > Squid ip: 192.168.2.1
> >
> > Traffic to squid is routed
> >
> > i would like users to have full LAN bandwidth access to squid server,
> > i have tried simple queue on mikrotik but it seems not to be working.
> >
> > Any guide will be appreciated.
> >
> > Best Regards
> >
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> --
> Bugs to the Future
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <http://lists.squid-cache.org/pipermail/squid-users/
> attachments/20170505/b26dda8f/attachment-0001.html>
> -------------- next part --------------
> A non-text attachment was scrubbed...
> Name: 0x613DEC46.asc
> Type: application/pgp-keys
> Size: 2437 bytes
> Desc: not available
> URL: <http://lists.squid-cache.org/pipermail/squid-users/
> attachments/20170505/b26dda8f/attachment-0001.key>
> -------------- next part --------------
> A non-text attachment was scrubbed...
> Name: signature.asc
> Type: application/pgp-signature
> Size: 473 bytes
> Desc: OpenPGP digital signature
> URL: <http://lists.squid-cache.org/pipermail/squid-users/
> attachments/20170505/b26dda8f/attachment-0001.sig>
>
> ------------------------------
>
> Message: 3
> Date: Fri, 5 May 2017 19:04:39 +0100
> From: Antony Stone <Antony.Stone at squid.open.source.it>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid Cache to Users at Full Bandwidth
> Message-ID: <201705051904.39473.Antony.Stone at squid.open.source.it>
> Content-Type: Text/Plain;  charset="iso-8859-15"
>
> On Friday 05 May 2017 at 16:18:33, christian brendan wrote:
>
> > Squid Version 3.5.20
> > Cento 7
> > Mikrotik RouterBoard v 6.39.1
> > Users IP: 192.168.1.0/24
> > Squid ip: 192.168.2.1
> >
> > Traffic to squid is routed
> >
> > i would like users to have full LAN bandwidth access to squid server, i
> > have tried simple queue on mikrotik but it seems not to be working.
>
> How does it "not seem to be working"?
>
> A "queue" on the Mikrotik would normally be used to restrict bandwidth, not
> increase it.  Please give details of how you have implemented this queue.
>
> A few further questions:
>
> 1. Is Squid running on the Routerboard, or on a rather more capable
> machine?
>
> 2. If the client machines access the Internet directly (ie: not via
> Squid), do
> they also go via the Routerboard?
>
> 3. How are you measuring bandwidth for the clients?
>
>
> Antony.
>
> --
> I thought I had type A blood, but it turned out to be a typo.
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
>
> End of squid-users Digest, Vol 33, Issue 24
> *******************************************
>

*?1. How does it "not seem to be working"?*

Simple Queue on Mikrotik?
name="pppoe" target=192.168.1.0/24 dst=192.168.2.1/32 parent=none
packet-marks="" priority=1/1
      queue=default/default limit-at=0/0 max-limit=0/0 burst-limit=0/0
burst-threshold=0/0 burst-time=0s/0s
      bucket-size=0.1/0.1 total-queue=default

With this queue in place users still connect to the squid server with their
predefined bandwidth limit, Eg: 1mbps to and from the squid server.

* 2. Is Squid running on the Routerboard, or on a rather more capable
machine?*

Squid is running on CentOS 7, Routerboard is doing the routing to squid.



*2. If the client machines access the Internet directly (ie: not via
Squid), dothey also go via the Routerboard?*

Yes
All traffics goes through Routerboad (traffic to squid and to internet goes
through Routerboard)

*3. How are you measuring bandwidth for the clients?*

By re-downloading a file that has been cached, Which i believe the first
download should be on 1mbps predefined bandwidth and sub-sequence  download
of the same file should be on 100mbps or even 50mbps at a full bandwidth to
the client.

Best Regards.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170506/20040ec5/attachment.htm>

From chip_pop at hotmail.com  Sat May  6 18:59:08 2017
From: chip_pop at hotmail.com (joseph)
Date: Sat, 6 May 2017 11:59:08 -0700 (PDT)
Subject: [squid-users] Squid Cache to Users at Full Bandwidth
In-Reply-To: <CAHptoxqvzSir5sTjASLrRD66P6fQxJaL+sDurDPd-17M7ofFiw@mail.gmail.com>
References: <CAHptoxrgO2CbtapCTnzf=uWcM3MsH7Gzh2AcxCBqeZn_tsUO+w@mail.gmail.com>
 <CAHptoxqvzSir5sTjASLrRD66P6fQxJaL+sDurDPd-17M7ofFiw@mail.gmail.com>
Message-ID: <1494097148239-4682320.post@n4.nabble.com>

you have to mark packet on mangle the DSCP(tos) = 12  first did you
and in squid  add       qos_flows tos local-hit=0x30 miss=0xFF

and in queues pic the marked packet name so  it will serve the cached HIT to
your clients
if you can not do it  i help u out



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Cache-to-Users-at-Full-Bandwidth-tp4682314p4682320.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From tobiastromm at msn.com  Sat May  6 21:08:18 2017
From: tobiastromm at msn.com (Tobias Tromm)
Date: Sat, 6 May 2017 21:08:18 +0000
Subject: [squid-users] 'Intercept' option on Windows
Message-ID: <BY2PR20MB021336F70A1DFC709A3196CCAEE80@BY2PR20MB0213.namprd20.prod.outlook.com>

Hi Guys,


I am using squid on Windows (http://squid.diladele.com/), but, they don't compile it with support to 'intercept' option.


Is that possible to enable it for Windows on current version?


I am using a very old version 2.7STABLE 8 with support 'transparent' option on Windows, available here: http://squid.acmeconsulting.it/download/dl-squid.html (maybe someone who understand how it works, can port these option from the old system to the new system, I don't know exactly...).


Based on Squid documentation there is these options, but they dont apply to Windows:


- http://wiki.squid-cache.org/SquidFaq/InterceptionProxy#Concepts_of_Interception_Caching :

  *   For Linux configure Squid with the --enable-linux-netfilter option.

  *   For *BSD-based systems with IP filter configure Squid with the --enable-ipf-transparent option.

  *   If you're using OpenBSD's PF configure Squid with --enable-pf-transparent

Here is how diladele compile it:


https://docs.diladele.com/tutorials/build_squid_windows/index.html


If someone can help, thanks!


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170506/f261bc11/attachment.htm>

From yvoinov at gmail.com  Sat May  6 21:52:28 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 7 May 2017 03:52:28 +0600
Subject: [squid-users] 'Intercept' option on Windows
In-Reply-To: <BY2PR20MB021336F70A1DFC709A3196CCAEE80@BY2PR20MB0213.namprd20.prod.outlook.com>
References: <BY2PR20MB021336F70A1DFC709A3196CCAEE80@BY2PR20MB0213.namprd20.prod.outlook.com>
Message-ID: <34380d46-f82f-aad2-e026-a2f4d450532d@gmail.com>

If this has not been done yet, it is impossible or not necessary.

PS. You always can setup VirtualBox (www.virtualbox.org) on your Windows
box, set up Linux/*BSD/Solaris inside and make all you want in guest OS.

07.05.2017 3:08, Tobias Tromm ?????:
>
> Hi Guys,
>
>
> I am using squid on Windows (http://squid.diladele.com/), but, they
> don't compile it with support to 'intercept' option.
>
>
> Is that possible to enable it for Windows on current version?
>
>
> I am using a very old version 2.7STABLE 8 with support 'transparent'
> option on Windows, available here:
> http://squid.acmeconsulting.it/download/dl-squid.html
> <http://squid.acmeconsulting.it/download/dl-squid.html> (maybe someone
> who understand how it works, can port these option from the old system
> to the new system, I don't know exactly...).
>
>
> Based on Squid documentation there is these options, but they dont
> apply to Windows:
>
>
> -
> http://wiki.squid-cache.org/SquidFaq/InterceptionProxy#Concepts_of_Interception_Caching
> :
>
>  *
>
>     For Linux configure Squid with the --enable-linux-netfilter option.
>
>  *
>
>     For *BSD-based systems with IP filter configure Squid with the
>     --enable-ipf-transparent option.
>
>  *
>
>     If you're using OpenBSD's PF configure Squid with
>     --enable-pf-transparent
>
> Here is how diladele compile it:
>
>
> https://docs.diladele.com/tutorials/build_squid_windows/index.html
>
>
> If someone can help, thanks!
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170507/257dde20/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170507/257dde20/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170507/257dde20/attachment.sig>

From squid3 at treenet.co.nz  Sun May  7 08:35:02 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 7 May 2017 20:35:02 +1200
Subject: [squid-users] 'Intercept' option on Windows
In-Reply-To: <BY2PR20MB021336F70A1DFC709A3196CCAEE80@BY2PR20MB0213.namprd20.prod.outlook.com>
References: <BY2PR20MB021336F70A1DFC709A3196CCAEE80@BY2PR20MB0213.namprd20.prod.outlook.com>
Message-ID: <c1d2e494-6a8d-c8da-e9c0-ef0f3d1fad79@treenet.co.nz>

On 07/05/17 09:08, Tobias Tromm wrote:

> Hi Guys,
>
>
> I am using squid on Windows (http://squid.diladele.com/), but, they 
> don't compile it with support to 'intercept' option.
>
>
> Is that possible to enable it for Windows on current version?
>
>
> I am using a very old version 2.7STABLE 8 with support 'transparent' 
> option on Windows, available here: 
> http://squid.acmeconsulting.it/download/dl-squid.html 
> <http://squid.acmeconsulting.it/download/dl-squid.html> (maybe someone 
> who understand how it works, can port these option from the old system 
> to the new system, I don't know exactly...).
>

Windows does not provide any API to access its NAT system. Squid-2 only 
appeared to work because it has the CV-2009-0801 problems.

Amos



From tobiastromm at msn.com  Sun May  7 16:05:17 2017
From: tobiastromm at msn.com (Tobias Tromm)
Date: Sun, 7 May 2017 16:05:17 +0000
Subject: [squid-users] 'Intercept' option on Windows
In-Reply-To: <c1d2e494-6a8d-c8da-e9c0-ef0f3d1fad79@treenet.co.nz>
References: <BY2PR20MB021336F70A1DFC709A3196CCAEE80@BY2PR20MB0213.namprd20.prod.outlook.com>,
 <c1d2e494-6a8d-c8da-e9c0-ef0f3d1fad79@treenet.co.nz>
Message-ID: <BY2PR20MB0213E3B673F6C6E5D751E48AAEE90@BY2PR20MB0213.namprd20.prod.outlook.com>

I don't know what exactly you need to make it work.


I found these APIs (https://msdn.microsoft.com/pt-br/library/windows/desktop/aa366278.aspx , https://msdn.microsoft.com/pt-br/library/windows/desktop/aa366187(v=vs.85).aspx), can they help?


If not, can you explain to me what kind of access is necessary? Maybe I can find someone on the internet that can do something about, maybe create one, I don't know...


Thanks.

________________________________
De: squid-users <squid-users-bounces at lists.squid-cache.org> em nome de Amos Jeffries <squid3 at treenet.co.nz>
Enviado: domingo, 7 de maio de 2017 08:35:02
Para: squid-users at lists.squid-cache.org
Assunto: Re: [squid-users] 'Intercept' option on Windows

On 07/05/17 09:08, Tobias Tromm wrote:

> Hi Guys,
>
>
> I am using squid on Windows (http://squid.diladele.com/), but, they
> don't compile it with support to 'intercept' option.
>
>
> Is that possible to enable it for Windows on current version?
>
>
> I am using a very old version 2.7STABLE 8 with support 'transparent'
> option on Windows, available here:
> http://squid.acmeconsulting.it/download/dl-squid.html
> <http://squid.acmeconsulting.it/download/dl-squid.html> (maybe someone
> who understand how it works, can port these option from the old system
> to the new system, I don't know exactly...).
>

Windows does not provide any API to access its NAT system. Squid-2 only
appeared to work because it has the CV-2009-0801 problems.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170507/7e117b5e/attachment.htm>

From yvoinov at gmail.com  Sun May  7 16:37:08 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 7 May 2017 22:37:08 +0600
Subject: [squid-users] 'Intercept' option on Windows
In-Reply-To: <BY2PR20MB0213E3B673F6C6E5D751E48AAEE90@BY2PR20MB0213.namprd20.prod.outlook.com>
References: <BY2PR20MB021336F70A1DFC709A3196CCAEE80@BY2PR20MB0213.namprd20.prod.outlook.com>
 <c1d2e494-6a8d-c8da-e9c0-ef0f3d1fad79@treenet.co.nz>
 <BY2PR20MB0213E3B673F6C6E5D751E48AAEE90@BY2PR20MB0213.namprd20.prod.outlook.com>
Message-ID: <7ff098b1-e069-a13f-07f6-52ddca37d093@gmail.com>

He is talking about NAT *.h files on Windows. This is exactly required.


07.05.2017 22:05, Tobias Tromm ?????:
>
> I don't know what exactly you need to make it work.
>
>
> I found these APIs
> (https://msdn.microsoft.com/pt-br/library/windows/desktop/aa366278.aspx
> ,
> https://msdn.microsoft.com/pt-br/library/windows/desktop/aa366187(v=vs.85).aspx
> <https://msdn.microsoft.com/pt-br/library/windows/desktop/aa366187%28v=vs.85%29.aspx>),
> can they help?
>
>
> If not, can you explain to me what kind of access is necessary? Maybe
> I can find someone on the internet that can do something about, maybe
> create one, I don't know...
>
>
> Thanks.
>
> ------------------------------------------------------------------------
> *De:* squid-users <squid-users-bounces at lists.squid-cache.org> em nome
> de Amos Jeffries <squid3 at treenet.co.nz>
> *Enviado:* domingo, 7 de maio de 2017 08:35:02
> *Para:* squid-users at lists.squid-cache.org
> *Assunto:* Re: [squid-users] 'Intercept' option on Windows
>  
> On 07/05/17 09:08, Tobias Tromm wrote:
>
> > Hi Guys,
> >
> >
> > I am using squid on Windows (http://squid.diladele.com/), but, they
> > don't compile it with support to 'intercept' option.
> >
> >
> > Is that possible to enable it for Windows on current version?
> >
> >
> > I am using a very old version 2.7STABLE 8 with support 'transparent'
> > option on Windows, available here:
> > http://squid.acmeconsulting.it/download/dl-squid.html
> > <http://squid.acmeconsulting.it/download/dl-squid.html> (maybe someone
> > who understand how it works, can port these option from the old system
> > to the new system, I don't know exactly...).
> >
>
> Windows does not provide any API to access its NAT system. Squid-2 only
> appeared to work because it has the CV-2009-0801 problems.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170507/ed27dc1a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170507/ed27dc1a/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170507/ed27dc1a/attachment.sig>

From squid3 at treenet.co.nz  Sun May  7 19:07:08 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 8 May 2017 07:07:08 +1200
Subject: [squid-users] 'Intercept' option on Windows
In-Reply-To: <BY2PR20MB0213E3B673F6C6E5D751E48AAEE90@BY2PR20MB0213.namprd20.prod.outlook.com>
References: <BY2PR20MB021336F70A1DFC709A3196CCAEE80@BY2PR20MB0213.namprd20.prod.outlook.com>
 <c1d2e494-6a8d-c8da-e9c0-ef0f3d1fad79@treenet.co.nz>
 <BY2PR20MB0213E3B673F6C6E5D751E48AAEE90@BY2PR20MB0213.namprd20.prod.outlook.com>
Message-ID: <7f720a85-e755-7396-27dc-e2006a5bd08c@treenet.co.nz>

On 08/05/17 04:05, Tobias Tromm wrote:
>
> I don't know what exactly you need to make it work.
>
>
> I found these APIs 
> (https://msdn.microsoft.com/pt-br/library/windows/desktop/aa366278.aspx 
> , 
> https://msdn.microsoft.com/pt-br/library/windows/desktop/aa366187(v=vs.85).aspx 
> <https://msdn.microsoft.com/pt-br/library/windows/desktop/aa366187%28v=vs.85%29.aspx>), 
> can they help?
>
>
> If not, can you explain to me what kind of access is necessary? Maybe 
> I can find someone on the internet that can do something about, maybe 
> create one, I don't know...
>

Those are API for setting up NAT rules.

What Squid needs is a way to fetch the dest-IP which was in the TCP 
packet before NAT altered it.

Amos



From squid3 at treenet.co.nz  Sun May  7 19:22:23 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 8 May 2017 07:22:23 +1200
Subject: [squid-users] Passing Windows username to parent proxy
In-Reply-To: <1493889225013-4682305.post@n4.nabble.com>
References: <1493808471375-4682272.post@n4.nabble.com>
 <d5cc395d-65cc-e2c3-5811-4b61e33771b6@treenet.co.nz>
 <F665DADF-0840-4194-A238-9B77804EDAE1@ntlworld.com>
 <3aeaaf0d-f8f1-12fb-d7c6-535f4a4fb373@treenet.co.nz>
 <1493882958266-4682303.post@n4.nabble.com>
 <1493889225013-4682305.post@n4.nabble.com>
Message-ID: <d1ca711a-882b-04bf-8e5d-e3926b9ba40c@treenet.co.nz>

On 04/05/17 21:13, BurningSky wrote:
> I just read http://wiki.squid-cache.org/Features/LogFormat. The 8th column is
> showing - rather than a user name, could this be the issue? What causes a -
> to be shown rather than a users name and how can I get round this?

It indicates that no username is known to Squid. Since your requirement 
is for credentials to be passed to the parent that is correct.

The "Windows" authentication methods (NTLM and Negotiate) are designed 
for end-to-end uses so a proxy in the middle like your Squid cannot 
participate when the auth details are needing to be sent further upstream.

Amos



From squid3 at treenet.co.nz  Sun May  7 19:24:57 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 8 May 2017 07:24:57 +1200
Subject: [squid-users] Passing Windows username to parent proxy
In-Reply-To: <1493882958266-4682303.post@n4.nabble.com>
References: <1493808471375-4682272.post@n4.nabble.com>
 <d5cc395d-65cc-e2c3-5811-4b61e33771b6@treenet.co.nz>
 <F665DADF-0840-4194-A238-9B77804EDAE1@ntlworld.com>
 <3aeaaf0d-f8f1-12fb-d7c6-535f4a4fb373@treenet.co.nz>
 <1493882958266-4682303.post@n4.nabble.com>
Message-ID: <ce164df4-ba89-71f7-aee2-7077b7b1eea5@treenet.co.nz>

On 04/05/17 19:29, BurningSky wrote:
> Is there a way to view what Squid is forwarding so that I can inspect the
> packets to prove that Squid is sending user information as I have a call
> open with the firewall vendor and I want to be able to tell them with
> certainty that it is an issue at the firewall end rather than the Squid end.

Add this to your squid.conf:
   debug_options 11,2

That will log the HTTP headers going through. You should see Proxy-Auth* 
headers arriving and the exact same value(s) being sent onward, for both 
request and response messages.

Amos



From ahmed.zaeem at netstream.ps  Sun May  7 21:35:19 2017
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Mon, 8 May 2017 00:35:19 +0300
Subject: [squid-users] show name instead of ip in access logs
Message-ID: <6A8BABEF-DB7B-4ECF-AF0F-E43BD3A8D8AF@netstream.ps>

hey folks .

i just want to ask how can i show names instead of ips on access logs 


if i put the ip:port in my browser , then i can see the names that i access ?.but if i use squid as transparent ?. i don?t see the names


any idea how can i fix it ?


have a look down :


transparent logs :

1494192594.244  10104 192.168.1.140 TCP_TUNNEL/200 234 CONNECT 172.217.6.68:443 - HIER_DIRECT/172.217.6.68 -
1494192595.818  10088 192.168.1.140 TCP_TUNNEL/200 0 CONNECT 172.217.6.34:443 - HIER_DIRECT/172.217.6.34 -

1494192604.244  14125 192.168.1.140 TCP_TUNNEL/200 234 CONNECT 172.217.6.70:443 - HIER_DIRECT/172.217.6.70 -
1494192604.247  18597 192.168.1.140 TCP_TUNNEL/200 234 CONNECT 172.217.6.34:443 - HIER_DIRECT/172.217.6.34 -
1494192624.409  65110 192.168.1.140 TCP_TUNNEL/200 1654 CONNECT 31.13.77.36:443 - HIER_DIRECT/31.13.77.36 -





ip:port logs :

1494192683.096    223 192.168.1.208 TCP_MISS/200 2715 GET http://facebbok.com/ - HIER_DIRECT/199.59.243.120 text/html
1494192683.429    160 192.168.1.208 TCP_MISS/200 5661 GET http://facebbok.com/glp? - HIER_DIRECT/199.59.243.120 text/javascript
1494192684.002    152 192.168.1.208 TCP_MISS/404 1527 GET http://facebbok.com/favicon.ico - HIER_DIRECT/199.59.243.120 text/html
1494192684.739   1195 192.168.1.208 TCP_MISS/200 874 POST http://facebbok.com/gzb - HIER_DIRECT/199.59.243.120 text/javascript
1494192684.942    162 192.168.1.208 TCP_MISS/200 454 POST http://facebbok.com/z - HIER_DIRECT/199.59.243.120 text/javascript
1494192685.239    107 192.168.1.208 TCP_MISS/307 970 GET http://bridge.sfo1.admarketplace.net/ct? - HIER_DIRECT/104.218.74.13 text/html
1494192685.399     23 192.168.1.208 TCP_MISS/200 5821 GET http://bridge.sfo1.admarketplace.net/co? - HIER_DIRECT/104.218.74.13 text/html
1494192690.127  10114 192.168.1.208 TCP_TUNNEL/200 211 CONNECT www.facebook.com:443 - HIER_DIRECT/31.13.77.36 -
1494192700.127  19160 192.168.1.208 TCP_TUNNEL/200 4162 CONNECT fonts.gstatic.com:443 - HIER_DIRECT/216.58.195.227 -
1494192700.127  20056 192.168.1.208 TCP_TUNNEL/200 234 CONNECT www.google.com:443 - HIER_DIRECT/172.217.6.68 -


1494192726.868     85 192.168.1.208 TCP_MISS/301 359 GET http://youtube.com/ - HIER_DIRECT/172.217.6.78 text/html
1494192728.913    235 192.168.1.208 TCP_TUNNEL/200 5049 CONNECT i.ytimg.com:443 - HIER_DIRECT/216.58.192.14 -
1494192728.913    236 192.168.1.208 TCP_TUNNEL/200 5049 CONNECT i.ytimg.com:443 - HIER_DIRECT/216.58.192.14 -
1494192734.778  10125 192.168.1.208 TCP_TUNNEL/200 4162 CONNECT fonts.gstatic.com:443 - HIER_DIRECT/216.58.195.227 -
1494192744.778  16051 192.168.1.208 TCP_TUNNEL/200 5049 CONNECT i.ytimg.com:443 - HIER_DIRECT/216.58.192.14 -
1494192744.778  16005 192.168.1.208 TCP_TUNNEL/200 234 CONNECT i.ytimg.com:443 - HIER_DIRECT/216.58.192.14 -
1494192744.778  17826 192.168.1.208 TCP_TUNNEL/200 151 CONNECT r11---sn-n4v7knee.googlevideo.com:443 - HIER_DIRECT/74.125.157.240 -
1494192744.778  17827 192.168.1.208 TCP_TUNNEL/200 151 CONNECT r11---sn-n4v7knee.googlevideo.com:443 - HIER_DIRECT/74.125.157.240 -
1494192744.779  17829 192.168.1.208 TCP_TUNNEL/200 151 CONNECT r11---sn-n4v7knee.googlevideo.com:443 - HIER_DIRECT/74.125.157.240 -
1494192744.779  17827 192.168.1.208 TCP_TUNNEL/200 151 CONNECT r11---sn-n4v7knee.googlevideo.com:443 - HIER_DIRECT/74.125.157.240 -
1494192744.779  17827 192.168.1.208 TCP_TUNNEL/200 151 CONNECT r11---sn-n4v7knee.googlevideo.com:443 - HIER_DIRECT/74.125.157.240 -
1494192744.779  17827 192.168.1.208 TCP_TUNNEL/200 151 CONNECT r4---sn-n4v7sne7.googlevideo.com:443 - HIER_DIRECT/173.194.166.106 -
1494192744.779  17827 192.168.1.208 TCP_TUNNEL/200 151 CONNECT r4---sn-n4v7sne7.googlevideo.com:443 - HIER_DIRECT/173.194.166.106 -
1494192744.779  17827 192.168.1.208 TCP_TUNNEL/200 151 CONNECT r4---sn-n4v7sne7.googlevideo.com:443 - HIER_DIRECT/173.194.166.106 -
1494192744.779  17827 192.168.1.208 TCP_TUNNEL/200 234 CONNECT s.youtube.com:443 - HIER_DIRECT/172.217.6.78 -
1494192744.779  14741 192.168.1.208 TCP_TUNNEL/200 234 CONNECT tpc.googlesyndication.com:443 - HIER_DIRECT/172.217.6.65 -








###############


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170508/f5c1d34a/attachment.htm>

From tobiastromm at msn.com  Sun May  7 22:12:43 2017
From: tobiastromm at msn.com (Tobias Tromm)
Date: Sun, 7 May 2017 22:12:43 +0000
Subject: [squid-users] Passing Windows username to parent proxy
In-Reply-To: <ce164df4-ba89-71f7-aee2-7077b7b1eea5@treenet.co.nz>
References: <1493808471375-4682272.post@n4.nabble.com>
 <d5cc395d-65cc-e2c3-5811-4b61e33771b6@treenet.co.nz>
 <F665DADF-0840-4194-A238-9B77804EDAE1@ntlworld.com>
 <3aeaaf0d-f8f1-12fb-d7c6-535f4a4fb373@treenet.co.nz>
 <1493882958266-4682303.post@n4.nabble.com>,
 <ce164df4-ba89-71f7-aee2-7077b7b1eea5@treenet.co.nz>
Message-ID: <BY2PR20MB0213088620A24459268190CBAEE90@BY2PR20MB0213.namprd20.prod.outlook.com>

I found a windows ipfw version here http://wipfw.sourceforge.net/ and here https://github.com/luigirizzo/dummynet


So, if I install it on Windows, and do that http://wiki.squid-cache.org/ConfigExamples/Intercept/Ipfw should it work?


Just to be clear, I don't want Windows doing the job of redirecting packets from 80 to 3129. I use iptables on dd-wrt for that (wifi guest only).


The problem is that when I configure squid as "http_port 3129 intercept" instead of "http_port 3129" it show me these errors:


2017/05/06 17:43:08 kid1| ERROR: NAT/TPROXY lookup failed to locate original IPs on local=10.0.0.1:3129 remote=192.168.11.236:57141 FD 9 flags=1
2017/05/06 17:43:08 kid1| WARNING: transparent proxying not supported

________________________________
De: squid-users <squid-users-bounces at lists.squid-cache.org> em nome de Amos Jeffries <squid3 at treenet.co.nz>
Enviado: domingo, 7 de maio de 2017 19:24:57
Para: squid-users at lists.squid-cache.org
Assunto: Re: [squid-users] Passing Windows username to parent proxy

On 04/05/17 19:29, BurningSky wrote:
> Is there a way to view what Squid is forwarding so that I can inspect the
> packets to prove that Squid is sending user information as I have a call
> open with the firewall vendor and I want to be able to tell them with
> certainty that it is an issue at the firewall end rather than the Squid end.

Add this to your squid.conf:
   debug_options 11,2

That will log the HTTP headers going through. You should see Proxy-Auth*
headers arriving and the exact same value(s) being sent onward, for both
request and response messages.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170507/4d6208a7/attachment.htm>

From tobiastromm at msn.com  Sun May  7 22:14:41 2017
From: tobiastromm at msn.com (Tobias Tromm)
Date: Sun, 7 May 2017 22:14:41 +0000
Subject: [squid-users] 'Intercept' option on Windows
In-Reply-To: <7f720a85-e755-7396-27dc-e2006a5bd08c@treenet.co.nz>
References: <BY2PR20MB021336F70A1DFC709A3196CCAEE80@BY2PR20MB0213.namprd20.prod.outlook.com>
 <c1d2e494-6a8d-c8da-e9c0-ef0f3d1fad79@treenet.co.nz>
 <BY2PR20MB0213E3B673F6C6E5D751E48AAEE90@BY2PR20MB0213.namprd20.prod.outlook.com>,
 <7f720a85-e755-7396-27dc-e2006a5bd08c@treenet.co.nz>
Message-ID: <BY2PR20MB0213EA259EEA6E2128A108D0AEE90@BY2PR20MB0213.namprd20.prod.outlook.com>

[Replying on correct topic (sorry)]


I found a windows ipfw version here http://wipfw.sourceforge.net/ and here https://github.com/luigirizzo/dummynet

So, if I install it on Windows, and do that http://wiki.squid-cache.org/ConfigExamples/Intercept/Ipfw should it work?

Just to be clear, I don't want Windows doing the job of redirecting packets from 80 to 3129. I use iptables on dd-wrt for that (wifi guest only).

The problem is that when I configure squid as "http_port 3129 intercept" instead of "http_port 3129" it show me these errors:


2017/05/06 17:43:08 kid1| ERROR: NAT/TPROXY lookup failed to locate original IPs on local=10.0.0.1:3129 remote=192.168.11.236:57141 FD 9 flags=1
2017/05/06 17:43:08 kid1| WARNING: transparent proxying not supported


________________________________
De: squid-users <squid-users-bounces at lists.squid-cache.org> em nome de Amos Jeffries <squid3 at treenet.co.nz>
Enviado: domingo, 7 de maio de 2017 19:07:08
Para: squid-users at lists.squid-cache.org
Assunto: Re: [squid-users] 'Intercept' option on Windows

On 08/05/17 04:05, Tobias Tromm wrote:
>
> I don't know what exactly you need to make it work.
>
>
> I found these APIs
> (https://msdn.microsoft.com/pt-br/library/windows/desktop/aa366278.aspx
> ,
> https://msdn.microsoft.com/pt-br/library/windows/desktop/aa366187(v=vs.85).aspx
> <https://msdn.microsoft.com/pt-br/library/windows/desktop/aa366187%28v=vs.85%29.aspx>),
> can they help?
>
>
> If not, can you explain to me what kind of access is necessary? Maybe
> I can find someone on the internet that can do something about, maybe
> create one, I don't know...
>

Those are API for setting up NAT rules.

What Squid needs is a way to fetch the dest-IP which was in the TCP
packet before NAT altered it.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170507/5362d0a0/attachment.htm>

From sblachmann at gmail.com  Mon May  8 04:19:33 2017
From: sblachmann at gmail.com (Stefan Blachmann)
Date: Mon, 8 May 2017 06:19:33 +0200
Subject: [squid-users] Can I use squid to reverse proxy https (without
	making it a man-in-the-middle)?
In-Reply-To: <CACc-My2BPEHDLSpT9EL+zZxK407BiaLP9E5rKWP3vvBWzCB5sA@mail.gmail.com>
References: <CACc-My2BPEHDLSpT9EL+zZxK407BiaLP9E5rKWP3vvBWzCB5sA@mail.gmail.com>
Message-ID: <CACc-My3U5MJO=UcbTzmCQs=wFJKPEYrV0CUzrLRV5-3R2YWqkg@mail.gmail.com>

With squid, it apparently seems impossible to just pass through SSL
traffic to the HTTPS servers without breaking privacy. The same seems
to be valid for some other "proxies" like nginx when being used as
reverse proxy.

So my solution to the problem was to discard squid and switch to haproxy.

Maybe I am not the only one who wants a proxy which can _actually_ do
SNI, i.e. use the clear-text domain name to just pass through to the
appropriate server, _without_ having to intercept and encrypt the
data.
I think my very simple haproxy.conf is quite self-explanatory, so I
attach it in the following to possibly help others who have similar
needs:

global
  maxconn 2000
  user haproxy
  group haproxy

defaults
  timeout client 30s
  timeout server 30s
  timeout connect 10s

frontend ft_http
  bind 10.0.0.10:80
  mode http
  acl http_sitewithssl_de hdr(host) -i sitewithssl.de
  acl http_sitewithssl_de_www hdr(host) -i www.sitewithssl.de
  acl http_anothersitewithoutssl_de hdr(host) -i anothersitewithoutssl.de
  acl http_anothersitewithoutssl_de_www hdr(host) -i
www.anothersitewithoutssl.de
  use_backend backend_sitewithssl_de_http if http_sitewithssl_de
  use_backend backend_sitewithssl_de_http if http_sitewithssl_de_www
  use_backend backend_anothersitewithoutssl_de_http if
http_anothersitewithoutssl_de
  use_backend backend_anothersitewithoutssl_de_http if
http_anothersitewithoutssl_de_www

frontend ft_https
  bind 10.0.0.10:443
  mode tcp
  acl https_sitewithssl_de req_ssl_sni -i sitewithssl.de
  acl https_sitewithssl_de_www req_ssl_sni -i www.sitewithssl.de
  use_backend backend_sitewithssl_de_https if https_sitewithssl_de
  use_backend backend_sitewithssl_de_https if https_sitewithssl_de_www

backend backend_anothersitewithoutssl_de_http
  mode http
  server server_anothersitewithoutssl_de_http 10.0.0.8:80

backend backend_sitewithssl_de_http
  mode http
  server server_sitewithssl_de_http 10.0.0.9:80

backend backend_sitewithssl_de_https
  mode tcp
  server server_sitewithssl_de_https 10.0.0.9:443



On 5/4/17, Stefan Blachmann <sblachmann at gmail.com> wrote:
> I am using squid 3.5.23 for no-caching reverse proxying http to
> backend web servers.
> I want to do the same with https.
>
> If I try to make cache_peer, acl, http_access and cache_peer_access
> for port 443 in addition to port 80, the connection attempt fails with
> browser complaining about error code: SSL_ERROR_RX_RECORD_TOO_LONG. In
> squid access log then there is a complaint about "invalid request".
>
> Is there a way to configure squid to just pass through https traffic
> to https backends? Just like it does with http?
> That is, _without_ needing to give squid access to the certificates and
> keys?
>
> (I ask because all instructions I found in the web are
> privacy-breaking decrypting Mitm interception instructions. And I do
> _not_ want to do it this way!)
>


From squid3 at treenet.co.nz  Mon May  8 06:35:42 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 8 May 2017 18:35:42 +1200
Subject: [squid-users] 'Intercept' option on Windows
In-Reply-To: <BY2PR20MB0213EA259EEA6E2128A108D0AEE90@BY2PR20MB0213.namprd20.prod.outlook.com>
References: <BY2PR20MB021336F70A1DFC709A3196CCAEE80@BY2PR20MB0213.namprd20.prod.outlook.com>
 <c1d2e494-6a8d-c8da-e9c0-ef0f3d1fad79@treenet.co.nz>
 <BY2PR20MB0213E3B673F6C6E5D751E48AAEE90@BY2PR20MB0213.namprd20.prod.outlook.com>
 <7f720a85-e755-7396-27dc-e2006a5bd08c@treenet.co.nz>
 <BY2PR20MB0213EA259EEA6E2128A108D0AEE90@BY2PR20MB0213.namprd20.prod.outlook.com>
Message-ID: <7ce3b1ab-9272-920e-3e11-3ac97843fb83@treenet.co.nz>

On 08/05/17 10:14, Tobias Tromm wrote:
>
> [Replying on correct topic (sorry)]
>
>
> I found a windows ipfw version here http://wipfw.sourceforge.net/ and 
> here https://github.com/luigirizzo/dummynet
>
> So, if I install it on Windows, and do that 
> http://wiki.squid-cache.org/ConfigExamples/Intercept/Ipfw should it work?
>
> Just to be clear, I don't want Windows doing the job of redirecting 
> packets from 80 to 3129. I use iptables on dd-wrt for that (wifi guest 
> only).

This is not possible without opening your entire network to invisible 
attack through CVE-2009-0801 
(<http://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery>).

NAT destroys the destination IP on the TCP packets. It has to be done on 
the Squid machine.

Amos



From hazri at ymail.com  Mon May  8 08:09:27 2017
From: hazri at ymail.com (hoje)
Date: Mon, 8 May 2017 01:09:27 -0700 (PDT)
Subject: [squid-users] Squid error : ERR_CONNECT_FAIL,
	TAG_NONE/503 & TCP_MISS/503
Message-ID: <1494230967229-4682334.post@n4.nabble.com>

Hi,

I have installed squid 3.5.24 and have enable option '--enable-ssl'
'--enable-ssl-crtd' and '--with-openssl?. Im using debian 8.7. Im want to
use this squid to filter http & https traffic. I have no problem filtering
http/https when using it with <10 users. If i connect it to 200+ users, i
will get lots of ERR_CONNECT_FAIL, TAG_NONE/503 & TCP_MISS/503 in less than
10 minutes. Need some advice. Thank you.


My squid.conf
??????

max_filedesc 65535
dns_v4_first on
request_timeout 5 minutes 


acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
#acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
#acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines
#acl SSL_ports port 443
acl SSL_ports port 443 563 1863 5190 5222 5050 6667
acl Safe_ports port 80		# http
acl Safe_ports port 21		# ftp
acl Safe_ports port 443		# https
acl Safe_ports port 70		# gopher
acl Safe_ports port 210		# wais
acl Safe_ports port 1025-65535	# unregistered ports
acl Safe_ports port 280		# http-mgmt
acl Safe_ports port 488		# gss-http
acl Safe_ports port 591		# filemaker
acl Safe_ports port 777		# multiling http
acl CONNECT method CONNECT

http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
#http_access deny CONNECT !SSL_ports 


http_access allow localhost manager
http_access allow localnet manager
http_access deny manager

#http_access deny to_localhost

http_access allow localnet
http_access allow localhost

http_access deny all

http_port 0.0.0.0:3128 intercept
http_port 0.0.0.0:3130
https_port 0.0.0.0:3129 intercept ssl-bump connection-auth=off
cert=/etc/squid/squidCA.pem


cache_mem 512 MB
always_direct allow all
#sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER
acl blocked ssl::server_name  "/etc/squid/tah.txt" 
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump terminate blocked 
ssl_bump splice all
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB


cache_dir ufs /var/spool/squid 15360 16 256
cache_swap_low 87
cache_swap_high 90

coredump_dir /var/spool/squid


refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320

??????????
My cachemgr:info
- - - - - -  - - - - - - - -  
Squid Object Cache: Version 3.5.24
Build Info: 
Service Name: squid
Start Time:	Thu, 27 Apr 2017 09:25:20 GMT
Current Time:	Thu, 27 Apr 2017 09:43:30 GMT
Connection information for squid:
	Number of clients accessing cache:	228
	Number of HTTP requests received:	15757
	Number of ICP messages received:	0
	Number of ICP messages sent:	0
	Number of queued ICP replies:	0
	Number of HTCP messages received:	0
	Number of HTCP messages sent:	0
	Request failure ratio:	 0.00
	Average HTTP requests per minute since start:	866.7
	Average ICP messages per minute since start:	0.0
	Select loop called: 292181 times, 3.733 ms avg
Cache information for squid:
	Hits as % of all requests:	5min: 0.1%, 60min: 0.1%
	Hits as % of bytes sent:	5min: 100.0%, 60min: 99.8%
	Memory hits as % of hit requests:	5min: 52.9%, 60min: 55.6%
	Disk hits as % of hit requests:	5min: 47.1%, 60min: 44.4%
	Storage Swap size:	13683904 KB
	Storage Swap capacity:	87.0% used, 13.0% free
	Storage Mem size:	2104 KB
	Storage Mem capacity:	 1.6% used, 98.4% free
	Mean Object Size:	15.44 KB
	Requests given to unlinkd:	0
Median Service Times (seconds)  5 min    60 min:
	HTTP Requests (All):  57.44813 57.44813
	Cache Misses:         28.47649 10.20961
	Cache Hits:            0.00000  0.00102
	Near Hits:             0.00000  0.00000
	Not-Modified Replies:  0.00000  0.00000
	DNS Lookups:           0.00860  0.00860
	ICP Queries:           0.00000  0.00000
Resource usage for squid:
	UP Time:	1090.832 seconds
	CPU Time:	128.728 seconds
	CPU Usage:	11.80%
	CPU Usage, 5 minute avg:	26.31%
	CPU Usage, 60 minute avg:	11.76%
	Maximum Resident Size: 3929760 KB
	Page faults with physical i/o: 85
Memory accounted for:
	Total accounted:       183695 KB
	memPoolAlloc calls:   3003099
	memPoolFree calls:    3027675
File descriptor usage for squid:
	Maximum number of file descriptors:   65535
	Largest file desc currently in use:   2691
	Number of file desc currently in use: 2405
	Files queued for open:                   0
	Available number of file descriptors: 63130
	Reserved number of file descriptors:   100
	Store Disk files open:                   0
Internal Data Structures:
	887622 StoreEntries
	  1623 StoreEntries with MemObjects
	    55 Hot Object Cache Items
	886002 on-disk objects



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-error-ERR-CONNECT-FAIL-TAG-NONE-503-TCP-MISS-503-tp4682334.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From marc.werner at cc-itzehoe.de  Mon May  8 10:55:30 2017
From: marc.werner at cc-itzehoe.de (Marc Werner)
Date: Mon, 8 May 2017 12:55:30 +0200
Subject: [squid-users] Automatic redirect to https
Message-ID: <dc3a8186-0368-0e0d-d529-026bddfde427@cc-itzehoe.de>

Hi folks,

I've set up an reverse proxy ("accel mode") using Squid Cache: Version 
3.5.20 which works fine. It listens on port 443 speaking https to the 
client and https with a self signed certificate to the server. I'm happy 
with that.

Now I want to redirect every client which asks the proxy at port 80 
using http to port 443 using https.

Using url_rewrite_program doesn't work for me, so I tried ACLs:

http_port 80 accel vhost
acl redir localport 80
http_access deny redir
deny_info 301:https://myfqdn.com/sub/ redir

After restarting squid, the proxy doesn't deny the request at port 80 
but I had access to my webserver via http! Can someone please tell me 
what's wrong with my ACL? I don't get it. Thank you very much!

King regards
Marc Werner



From tobiastromm at msn.com  Mon May  8 12:13:44 2017
From: tobiastromm at msn.com (Tobias Tromm)
Date: Mon, 8 May 2017 12:13:44 +0000
Subject: [squid-users] Help to Compile Squid for Windows
Message-ID: <BY2PR20MB0213DAF20EB51B7A4762CADBAEEE0@BY2PR20MB0213.namprd20.prod.outlook.com>

Hi.


So I am trying now to compile the last version  squid-3.5.25-20170504-r14155<http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.25-20170504-r14155-RELEASENOTES.html> 05 May 2017 for Windows with Cygwin and I am having the erros on attached file (please see the ones I paint with red).


[doc version attached or pdf version here due to list attached size limit https://www.papinho.com/squid.pdf ]


What is wrong?


Thanks.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170508/11f8761b/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.docx
Type: application/vnd.openxmlformats-officedocument.wordprocessingml.document
Size: 40958 bytes
Desc: squid.docx
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170508/11f8761b/attachment.docx>

From squid3 at treenet.co.nz  Mon May  8 13:44:18 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 9 May 2017 01:44:18 +1200
Subject: [squid-users] Automatic redirect to https
In-Reply-To: <dc3a8186-0368-0e0d-d529-026bddfde427@cc-itzehoe.de>
References: <dc3a8186-0368-0e0d-d529-026bddfde427@cc-itzehoe.de>
Message-ID: <44d8c970-e88d-88a2-5ebc-205ac8f19771@treenet.co.nz>

On 08/05/17 22:55, Marc Werner wrote:
> Hi folks,
>
> I've set up an reverse proxy ("accel mode") using Squid Cache: Version 
> 3.5.20 which works fine. It listens on port 443 speaking https to the 
> client and https with a self signed certificate to the server. I'm 
> happy with that.
>
> Now I want to redirect every client which asks the proxy at port 80 
> using http to port 443 using https.
>
> Using url_rewrite_program doesn't work for me, so I tried ACLs:
>
> http_port 80 accel vhost
> acl redir localport 80
> http_access deny redir
> deny_info 301:https://myfqdn.com/sub/ redir

Try with these instead:

  acl redir proto HTTP
  deny_info 301:https://%H%R redir
  http_access deny redir


Amos



From tobiastromm at msn.com  Mon May  8 14:29:28 2017
From: tobiastromm at msn.com (Tobias Tromm)
Date: Mon, 8 May 2017 14:29:28 +0000
Subject: [squid-users] Help to Compile Squid for Windows
In-Reply-To: <BY2PR20MB0213DAF20EB51B7A4762CADBAEEE0@BY2PR20MB0213.namprd20.prod.outlook.com>
References: <BY2PR20MB0213DAF20EB51B7A4762CADBAEEE0@BY2PR20MB0213.namprd20.prod.outlook.com>
Message-ID: <BY2PR20MB021315DB4D8FD5421C2A0D68AEEE0@BY2PR20MB0213.namprd20.prod.outlook.com>

For testing purpose I enable "--disable-external-acl-helpers" and now I receive the following error, with i fix by changing


the line mentioned to " const void *i = memchr(buf(), (int)c, (size_type)endPos); "


someone probably has to change the fsource file with have the typo...



c -I../include    -I../src   -I/usr/include/libxml2  -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -pipe -D_REENTRANT -g -O2 -march=native -MT SBuf.o -MD -MP -MF $depbase.Tpo -c -o SBuf.o SBuf.cc &&\
mv -f $depbase.Tpo $depbase.Po
SBuf.cc: In member function ?SBuf::size_type SBuf::rfind(char, SBuf::size_type) const?:
SBuf.cc:760:61: error: ?memrchr? was not declared in this scope
     const void *i = memrchr(buf(), (int)c, (size_type)endPos);
                                                             ^
make[3]: *** [Makefile:7173: SBuf.o] Error 1
make[3]: Leaving directory '/usr/src/squid-3.5.25/src'
make[2]: *** [Makefile:7296: all-recursive] Error 1
make[2]: Leaving directory '/usr/src/squid-3.5.25/src'
make[1]: *** [Makefile:6157: all] Error 2
make[1]: Leaving directory '/usr/src/squid-3.5.25/src'
make: *** [Makefile:581: all-recursive] Error 1


________________________________
De: squid-users <squid-users-bounces at lists.squid-cache.org> em nome de Tobias Tromm <tobiastromm at msn.com>
Enviado: segunda-feira, 8 de maio de 2017 12:13:44
Para: squid-users at lists.squid-cache.org
Assunto: [squid-users] Help to Compile Squid for Windows


Hi.


So I am trying now to compile the last version  squid-3.5.25-20170504-r14155<http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.25-20170504-r14155-RELEASENOTES.html> 05 May 2017 for Windows with Cygwin and I am having the erros on attached file (please see the ones I paint with red).


[doc version attached or pdf version here due to list attached size limit https://www.papinho.com/squid.pdf ]


What is wrong?


Thanks.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170508/7caad55a/attachment.htm>

From squid3 at treenet.co.nz  Mon May  8 14:41:01 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 9 May 2017 02:41:01 +1200
Subject: [squid-users] Help to Compile Squid for Windows
In-Reply-To: <BY2PR20MB0213DAF20EB51B7A4762CADBAEEE0@BY2PR20MB0213.namprd20.prod.outlook.com>
References: <BY2PR20MB0213DAF20EB51B7A4762CADBAEEE0@BY2PR20MB0213.namprd20.prod.outlook.com>
Message-ID: <5fd8b8f1-4552-a6e0-3e83-50e24c544328@treenet.co.nz>

On 09/05/17 00:13, Tobias Tromm wrote:
>
> Hi.
>
>
> So I am trying now to compile the last version 
> squid-3.5.25-20170504-r14155 
> <http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.25-20170504-r14155-RELEASENOTES.html>|05 
> May 2017| for Windows with Cygwin and I am having the erros on 
> attached file (please see the ones I paint with red).
>
>
> [doc version attached or pdf version here due to list attached size 
> limit https://www.papinho.com/squid.pdf 
> <https://www.papinho.com/squid.pdf> ]
>
>
> What is wrong?
>
>

This list is really for sysadmin and other user discussions about Squid 
features and uses. For code problems please contact the squid-dev 
mailing list. The size limit there is quite a bit larger exactly so 
traces can be posted, though if as you say it is a compile error I 
expect your trace can be pruned down to just the first (or first few) 
actual error messages.

Your system seems to be missing headers for the ancient LanManager 
protocols (superceded by NTLM back in the 1980's). You can work around 
that by not building the ACL helpers (--disable-external-acl-helpers) or 
listing just the ones you want in --enable-external-acl-helpers="..."

To avoid hitting more of this type of thing later check out the build 
options Diladele use for their builds of Squid for Windows with Cygwin.

Amos



From squid3 at treenet.co.nz  Mon May  8 14:41:26 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 9 May 2017 02:41:26 +1200
Subject: [squid-users] Squid error : ERR_CONNECT_FAIL,
 TAG_NONE/503 & TCP_MISS/503
In-Reply-To: <1494230967229-4682334.post@n4.nabble.com>
References: <1494230967229-4682334.post@n4.nabble.com>
Message-ID: <304ce559-ca9a-cecf-d5bb-308b61dac753@treenet.co.nz>

On 08/05/17 20:09, hoje wrote:
> Hi,
>
> I have installed squid 3.5.24 and have enable option '--enable-ssl'
> '--enable-ssl-crtd' and '--with-openssl?. Im using debian 8.7. Im want to
> use this squid to filter http & https traffic. I have no problem filtering
> http/https when using it with <10 users. If i connect it to 200+ users, i
> will get lots of ERR_CONNECT_FAIL, TAG_NONE/503 & TCP_MISS/503 in less than
> 10 minutes. Need some advice. Thank you.

I suspect that the problem is just one or a few of the users having 
broken TLS/SSL or doing something weird with it.

First thing to do is ensure that the problem remains with the very 
latest code. A whole bunch of bug fixes around the topic of error 
handling during SSL-Bump processing steps have just landed in Squid-4. 
The set started with some changes that made it into the 3.5.25 release.

So I suggest rebuilding with the 3.5.25 released code, or if the problem 
remains the snapshot of Squid-4 which should be labeled r15031 or later.

Amos



From tobiastromm at msn.com  Mon May  8 14:53:10 2017
From: tobiastromm at msn.com (Tobias Tromm)
Date: Mon, 8 May 2017 14:53:10 +0000
Subject: [squid-users] Help to Compile Squid for Windows
In-Reply-To: <5fd8b8f1-4552-a6e0-3e83-50e24c544328@treenet.co.nz>
References: <BY2PR20MB0213DAF20EB51B7A4762CADBAEEE0@BY2PR20MB0213.namprd20.prod.outlook.com>,
 <5fd8b8f1-4552-a6e0-3e83-50e24c544328@treenet.co.nz>
Message-ID: <BY2PR20MB021300E9375A534365FC0BDEAEEE0@BY2PR20MB0213.namprd20.prod.outlook.com>

I see, another list fo dev compile errors, ok : -)


Will find it.


Thanks!

________________________________
De: squid-users <squid-users-bounces at lists.squid-cache.org> em nome de Amos Jeffries <squid3 at treenet.co.nz>
Enviado: segunda-feira, 8 de maio de 2017 14:41:01
Para: squid-users at lists.squid-cache.org
Assunto: Re: [squid-users] Help to Compile Squid for Windows

On 09/05/17 00:13, Tobias Tromm wrote:
>
> Hi.
>
>
> So I am trying now to compile the last version
> squid-3.5.25-20170504-r14155
> <http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.25-20170504-r14155-RELEASENOTES.html>|05
> May 2017| for Windows with Cygwin and I am having the erros on
> attached file (please see the ones I paint with red).
>
>
> [doc version attached or pdf version here due to list attached size
> limit https://www.papinho.com/squid.pdf
> <https://www.papinho.com/squid.pdf> ]
>
>
> What is wrong?
>
>

This list is really for sysadmin and other user discussions about Squid
features and uses. For code problems please contact the squid-dev
mailing list. The size limit there is quite a bit larger exactly so
traces can be posted, though if as you say it is a compile error I
expect your trace can be pruned down to just the first (or first few)
actual error messages.

Your system seems to be missing headers for the ancient LanManager
protocols (superceded by NTLM back in the 1980's). You can work around
that by not building the ACL helpers (--disable-external-acl-helpers) or
listing just the ones you want in --enable-external-acl-helpers="..."

To avoid hitting more of this type of thing later check out the build
options Diladele use for their builds of Squid for Windows with Cygwin.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170508/56e39f23/attachment.htm>

From rousskov at measurement-factory.com  Mon May  8 15:50:36 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 8 May 2017 09:50:36 -0600
Subject: [squid-users] Help to Compile Squid for Windows
In-Reply-To: <BY2PR20MB021315DB4D8FD5421C2A0D68AEEE0@BY2PR20MB0213.namprd20.prod.outlook.com>
References: <BY2PR20MB0213DAF20EB51B7A4762CADBAEEE0@BY2PR20MB0213.namprd20.prod.outlook.com>
 <BY2PR20MB021315DB4D8FD5421C2A0D68AEEE0@BY2PR20MB0213.namprd20.prod.outlook.com>
Message-ID: <21663892-5f8d-a362-c896-738ae8ab0f79@measurement-factory.com>

On 05/08/2017 08:29 AM, Tobias Tromm wrote:
> I receive the following error, with i fix by changing 
> the line mentioned to " const void *i = memchr(buf(), (int)c,
> (size_type)endPos); " 
> 
> someone probably has to change the fsource file with have the typo...

This is not a typo: There is a huge difference between memchr() and
memrchr() functions. If there is no memrchr() in your Windows
environment, Squid would have to provide a replacement.

If you want to work on fixing these problems, move to squid-dev like
Amos advised. If you want to report these problems and then wait for the
fix, then file a bug report (and wait). Please note that, AFAICT, the
Squid Project currently lacks active Windows developers so it may take a
while to address any Windows-specific bugs.


Cheers,

Alex.

> SBuf.cc:760:61: error: ?memrchr? was not declared in this scope
>      const void *i = memrchr(buf(), (int)c, (size_type)endPos);



From blaxxton at yahoo.com  Tue May  9 04:03:55 2017
From: blaxxton at yahoo.com (Blaxton)
Date: Tue, 9 May 2017 04:03:55 +0000 (UTC)
Subject: [squid-users] limit access with acl only based on source and
 destination domain
In-Reply-To: <57367ed3-3a9d-c2ed-527b-e3de5621e8d9@treenet.co.nz>
References: <982145555.1000130.1493772004922.ref@mail.yahoo.com>
 <982145555.1000130.1493772004922@mail.yahoo.com>
 <a49a4f3e-73a4-f84f-f356-097743f14d0d@treenet.co.nz>
 <1061329603.2784761.1493956067490@mail.yahoo.com>
 <57367ed3-3a9d-c2ed-527b-e3de5621e8d9@treenet.co.nz>
Message-ID: <1056993437.5263468.1494302635808@mail.yahoo.com>

apparently srcdomain only works with FQDN of host and that was the reason below directive not working for us:
http_access allow From_Source_Domains To_Destination_Domains

Is there a document that mention we can't have host name in srcdomain acl ?

      From: Amos Jeffries <squid3 at treenet.co.nz>
 To: "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Thursday, May 4, 2017 11:12 PM
 Subject: Re: [squid-users] limit access with acl only based on source and destination domain
   
On 05/05/17 15:47, Blaxton wrote:
> What is the difference between :

That is documented in 
<http://wiki.squid-cache.org/SquidFaq/SquidAcl#Common_Mistakes>


if:
> http_access allow From_Source_Domains
or, if:
> http_access allow To_Destination_Domains
or, deny all


versus ...

if:
> http_access allow From_Source_Domains To_Destination_Domains
or, deny all.



Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170509/8c9115c8/attachment.htm>

From mohammedjk89 at gmail.com  Tue May  9 06:41:33 2017
From: mohammedjk89 at gmail.com (Mohammed al-jakry)
Date: Tue, 9 May 2017 09:41:33 +0300
Subject: [squid-users] No valid signing SSL certificate configured for
 HTTPS_port [::]:3128 (SSL Bump)
Message-ID: <CADHjJ6KqTAw437TjFeF25MVeW0br5bbYHa_g1JZLGo+HnFoB+g@mail.gmail.com>

Hi,

I am facing an issue with Squid 3.5 with SSL Bump configuration, i already
configure it without SSL bump and it works fine. but after configuring
intercept process it shows the below error:

*No valid signing SSL certificate configured for HTTPS_port [::]:3128*

below snippet from the Squid configuration file:

*https_port 3128 intercept ssl-bump \*
*  generate-host-certificates=on \*
*  dynamic_cert_mem_cache_size=4MB \*
*  cert=/etc/squid/ssl_cert/myCA.pem*

*# For squid 3.5.x*
*sslcrtd_program /usr/lib64/squid/ssl_crtd  -s /var/lib/ssl_db -M 4MB*


*acl step1 at_step SslBump1*
*ssl_bump peek step1*
*ssl_bump bump all*

i used the below link as guid in creating the certificate:
http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

moreover, below are the result for squid -k command:

2017/05/09 09:38:26| Startup: Initializing Authentication Schemes ...
2017/05/09 09:38:26| Startup: Initialized Authentication Scheme 'basic'
2017/05/09 09:38:26| Startup: Initialized Authentication Scheme 'digest'
2017/05/09 09:38:26| Startup: Initialized Authentication Scheme 'negotiate'
2017/05/09 09:38:26| Startup: Initialized Authentication Scheme 'ntlm'
2017/05/09 09:38:26| Startup: Initialized Authentication.
2017/05/09 09:38:26| Processing Configuration File: /etc/squid/squid.conf
(depth 0)
2017/05/09 09:38:26| Processing: acl localnet src 172.16.10.0/24        #
RFC1918 possible internal network
2017/05/09 09:38:26| Processing: acl localnet src 192.168.0.0/16        #
RFC1918 possible internal network
2017/05/09 09:38:26| Processing: acl localnet src fc00::/7       # RFC 4193
local private network range
2017/05/09 09:38:26| Processing: acl localnet src fe80::/10      # RFC 4291
link-local (directly plugged) machines
2017/05/09 09:38:26| Processing: acl SSL_ports port 443
2017/05/09 09:38:26| Processing: acl Safe_ports port 80         # http
2017/05/09 09:38:26| Processing: acl Safe_ports port 21         # ftp
2017/05/09 09:38:26| Processing: acl Safe_ports port 443                #
https
2017/05/09 09:38:26| Processing: acl Safe_ports port 70         # gopher
2017/05/09 09:38:26| Processing: acl Safe_ports port 210                #
wais
2017/05/09 09:38:26| Processing: acl Safe_ports port 1025-65535 #
unregistered ports
2017/05/09 09:38:26| Processing: acl Safe_ports port 280                #
http-mgmt
2017/05/09 09:38:26| Processing: acl Safe_ports port 488                #
gss-http
2017/05/09 09:38:26| Processing: acl Safe_ports port 591                #
filemaker
2017/05/09 09:38:26| Processing: acl Safe_ports port 777                #
multiling http
2017/05/09 09:38:26| Processing: acl CONNECT method CONNECT
2017/05/09 09:38:26| Processing: http_access deny !Safe_ports
2017/05/09 09:38:26| Processing: http_access deny CONNECT !SSL_ports
2017/05/09 09:38:26| Processing: http_access allow localhost manager
2017/05/09 09:38:26| Processing: http_access deny manager
2017/05/09 09:38:26| Processing: http_access allow localnet
2017/05/09 09:38:26| Processing: http_access allow localhost
2017/05/09 09:38:26| Processing: http_access deny all
2017/05/09 09:38:26| Processing: https_port 3128 intercept ssl-bump
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
cert=/etc/squid/ssl_cert/myCA.pem
2017/05/09 09:38:26| Starting Authentication on port [::]:3128
2017/05/09 09:38:26| Disabling Authentication on port [::]:3128
(interception enabled)
2017/05/09 09:38:26| Processing: sslcrtd_program /usr/lib64/squid/ssl_crtd
 -s /var/lib/ssl_db -M 4MB
2017/05/09 09:38:26| Processing: acl step1 at_step SslBump1
2017/05/09 09:38:26| Processing: ssl_bump peek step1
2017/05/09 09:38:26| Processing: ssl_bump bump all
2017/05/09 09:38:26| Processing: cache_dir ufs /var/spool/squid 100 16 256
2017/05/09 09:38:26| Processing: coredump_dir /var/spool/squid
2017/05/09 09:38:26| Processing: refresh_pattern ^ftp:          1440    20%
    10080
2017/05/09 09:38:26| Processing: refresh_pattern ^gopher:       1440    0%
     1440
2017/05/09 09:38:26| Processing: refresh_pattern -i (/cgi-bin/|\?) 0    0%
     0
2017/05/09 09:38:26| Processing: refresh_pattern .              0       20%
    4320
2017/05/09 09:38:26| Initializing https proxy context
2017/05/09 09:38:26| Initializing https_port [::]:3128 SSL context
2017/05/09 09:38:26| Using certificate in /etc/squid/ssl_cert/myCA.pem
FATAL: No valid signing SSL certificate configured for HTTPS_port [::]:3128
Squid Cache (Version 3.5.20): Terminated abnormally.
CPU Usage: 0.027 seconds = 0.013 user + 0.014 sys
Maximum Resident Size: 37264 KB
Page faults with physical i/o: 0

I already do googling for this issue, and i found similar issue and it was
solved by setting SELinux to permissive and reboot. i already did the same
but its still not working. pleas advice

Thanks and Regards,

Mohammed AL-Jakri
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170509/596ecefb/attachment.htm>

From kevinmuehlparzer at hotmail.de  Tue May  9 07:16:52 2017
From: kevinmuehlparzer at hotmail.de (Kevin M?hlparzer)
Date: Tue, 9 May 2017 07:16:52 +0000
Subject: [squid-users] Squid - using NTLM for SSO
Message-ID: <VI1PR0501MB1967EDD767E33EE779D8C877A7EE0@VI1PR0501MB1967.eurprd05.prod.outlook.com>

Hello list,


I need your help with a Squid-Proxy (3.5) NTLM Auth, the aim is to use SSO for my windows clients.

My Windows-Clients are using Active-Directory running on a Samba4-PDC.

I set up ldap basic auth in a developer environment, now I want to achieve SSO. (using NTLM?)

The Documentation on http://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm doesn't really help me enough (on my knowledge about squid and forms of authentication/samba).


Tests:

-> testing Kerberos

I'm able to obtain (kinit) tickets and list them (klist)


root at xxx-testproxy01:~# kinit Administrator
Password for Administrator at X-XXX.LOCAL:
root at xxx-testproxy01:~# klist
Ticket cache: FILE:/tmp/krb5cc_0
Default principal: Administrator at X-XXX.LOCAL

Valid starting       Expires              Service principal
2017-05-09 08:43:25  2017-05-09 18:43:25  krbtgt/X-XXX.LOCAL at X-XXX.LOCAL
    renew until 2017-05-10 08:43:21

-> testing Samba:
I joined my domain X-XXX.
Test support for ntlm:
root at xxx-testproxy01:~# wbinfo -a testuser%xxxxxxxxxxx
plaintext password authentication succeeded
challenge/response password authentication succeeded

root at xxx-testproxy01:~# wbinfo -a testuser%xxxxxxxxxxx
plaintext password authentication succeeded
challenge/response password authentication succeeded
root at xxx-testproxy01:~# wbinfo -t
checking the trust secret for domain X-XXX via RPC calls succeeded
root at xxx-testproxy01:~# wbinfo -g
X-XXX\cert publishers
...
X-XXX\webusers

-> Testing NTLM-helper:
Now here's my problem.

root at xxx-testproxy01:~# /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --username=testuser --password=xxxxxxxxxxx
x-xxx\testuser xxxxxxxxxxx
SPNEGO request [testuser xxxxxxxxxxx] invalid prefix
BH SPNEGO request invalid prefix

root at xxx-testproxy01:~# /usr/bin/ntlm_auth --helper-protocol=squid-2.5-basic --username=testuser --password=xxxxxxxxxxx
x-xxx\testuser xxxxxxxxxxx
OK

What is ntlmssp? I read both helpers on tutorials. If I need both, why do I need both?
My squid is starting how it should, logs are looking normal, PopUp for authentication appears aswell, but I can't log in. I shoudn't need to authenticate in the first place because it should use SSO.
What is missing/faulty?
The rest of squid is basic stuff:
auth_param ntlm program /usr/bin/ntlm_auth ?helper-protocol=squid-2.5-ntlmssp --username=testuser --password=Passme123
auth_param ntlm children 10
auth_param basic program /usr/bin/ntlm_auth ?helper-protocol=squid-2.5-basic --username=testuser --password=Passme123
auth_param basic children 5
auth_param basic realm Proxy Server
auth_param basic credentialsttl 2 hours
auth_param basic casesensitive off
authenticate_cache_garbage_interval 10 seconds
...
acl auth proxy_auth REQUIRED
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
...
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localnet
http_access allow localhost manager
http_access deny !auth
http_access allow auth
http_access deny all
...
url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
url_rewrite_children 5

Does anyone know further? Thanks in advance.
- Kevin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170509/8f1caea0/attachment.htm>

From eliezer at ngtech.co.il  Tue May  9 13:57:50 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Tue, 9 May 2017 16:57:50 +0300
Subject: [squid-users] Automatic redirect to https
In-Reply-To: <44d8c970-e88d-88a2-5ebc-205ac8f19771@treenet.co.nz>
References: <dc3a8186-0368-0e0d-d529-026bddfde427@cc-itzehoe.de>
 <44d8c970-e88d-88a2-5ebc-205ac8f19771@treenet.co.nz>
Message-ID: <00c701d2c8cc$3f2e7ae0$bd8b70a0$@ngtech.co.il>

Wouldn't it in any way smarter or faster if we do the redirect using the port 80 name acl compared to the protocol acl?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Monday, May 8, 2017 4:44 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Automatic redirect to https

On 08/05/17 22:55, Marc Werner wrote:
> Hi folks,
>
> I've set up an reverse proxy ("accel mode") using Squid Cache: Version 
> 3.5.20 which works fine. It listens on port 443 speaking https to the 
> client and https with a self signed certificate to the server. I'm 
> happy with that.
>
> Now I want to redirect every client which asks the proxy at port 80 
> using http to port 443 using https.
>
> Using url_rewrite_program doesn't work for me, so I tried ACLs:
>
> http_port 80 accel vhost
> acl redir localport 80
> http_access deny redir
> deny_info 301:https://myfqdn.com/sub/ redir

Try with these instead:

  acl redir proto HTTP
  deny_info 301:https://%H%R redir
  http_access deny redir


Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From uhlar at fantomas.sk  Tue May  9 14:16:59 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 9 May 2017 16:16:59 +0200
Subject: [squid-users] Automatic redirect to https
In-Reply-To: <00c701d2c8cc$3f2e7ae0$bd8b70a0$@ngtech.co.il>
References: <dc3a8186-0368-0e0d-d529-026bddfde427@cc-itzehoe.de>
 <44d8c970-e88d-88a2-5ebc-205ac8f19771@treenet.co.nz>
 <00c701d2c8cc$3f2e7ae0$bd8b70a0$@ngtech.co.il>
Message-ID: <20170509141659.GA12474@fantomas.sk>

On 09.05.17 16:57, Eliezer  Croitoru wrote:
>Wouldn't it in any way smarter or faster if we do the redirect using the port 80 name acl compared to the protocol acl?

depends... "proto HTTP" applies on different ports while "port 80" not.

>-----Original Message-----
>From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
>Sent: Monday, May 8, 2017 4:44 PM
>To: squid-users at lists.squid-cache.org
>Subject: Re: [squid-users] Automatic redirect to https
>
>On 08/05/17 22:55, Marc Werner wrote:
>> Hi folks,
>>
>> I've set up an reverse proxy ("accel mode") using Squid Cache: Version
>> 3.5.20 which works fine. It listens on port 443 speaking https to the
>> client and https with a self signed certificate to the server. I'm
>> happy with that.
>>
>> Now I want to redirect every client which asks the proxy at port 80
>> using http to port 443 using https.
>>
>> Using url_rewrite_program doesn't work for me, so I tried ACLs:
>>
>> http_port 80 accel vhost
>> acl redir localport 80
>> http_access deny redir
>> deny_info 301:https://myfqdn.com/sub/ redir
>
>Try with these instead:
>
>  acl redir proto HTTP
>  deny_info 301:https://%H%R redir
>  http_access deny redir

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Christian Science Programming: "Let God Debug It!".


From dijxie at gmail.com  Wed May 10 00:16:08 2017
From: dijxie at gmail.com (Dijxie)
Date: Wed, 10 May 2017 02:16:08 +0200
Subject: [squid-users] Squid - using NTLM for SSO
In-Reply-To: <VI1PR0501MB1967EDD767E33EE779D8C877A7EE0@VI1PR0501MB1967.eurprd05.prod.outlook.com>
References: <VI1PR0501MB1967EDD767E33EE779D8C877A7EE0@VI1PR0501MB1967.eurprd05.prod.outlook.com>
Message-ID: <b6c339d1-4fcd-72f2-40b8-7a70e649fba6@gmail.com>


> Hello list,
>
>
> I need your help with a Squid-Proxy (3.5) NTLM Auth, the aim is to use 
> SSO for my windows clients.
>
> My Windows-Clients are using Active-Directory running on a Samba4-PDC.
>
> I set up ldap basic auth in a developer environment, now I want to 
> achieve SSO. (using NTLM?)
>
> The Documentation on 
> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm 
> <http://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm> doesn't 
> really help me enough (on my knowledge about squid and forms of 
> authentication/samba).
>
>
> Tests:
>
> -> testing Kerberos
>
> I'm able to obtain (kinit) tickets and list them (klist)
>
>
> root at xxx-testproxy01:~# kinit Administrator
> Password for Administrator at X-XXX.LOCAL:
> root at xxx-testproxy01:~# klist
> Ticket cache: FILE:/tmp/krb5cc_0
> Default principal: Administrator at X-XXX.LOCAL
>
> Valid starting       Expires              Service principal
> 2017-05-09 08:43:25  2017-05-09 18:43:25 krbtgt/X-XXX.LOCAL at X-XXX.LOCAL
>     renew until 2017-05-10 08:43:21
>
> -> testing Samba:
> I joined my domain X-XXX.
> Test support for ntlm:
> root at xxx-testproxy01:~# wbinfo -a testuser%xxxxxxxxxxx
> plaintext password authentication succeeded
> challenge/response password authentication succeeded
>
> root at xxx-testproxy01:~# wbinfo -a testuser%xxxxxxxxxxx
> plaintext password authentication succeeded
> challenge/response password authentication succeeded
> root at xxx-testproxy01:~# wbinfo -t
> checking the trust secret for domain X-XXX via RPC calls succeeded
> root at xxx-testproxy01:~# wbinfo -g
> X-XXX\cert publishers
> ...negotiate_wrapper
> X-XXX\webusers
>
> -> Testing NTLM-helper:
> Now here's my problem.
>
> root at xxx-testproxy01:~# /usr/bin/ntlm_auth 
> --helper-protocol=squid-2.5-ntlmssp --username=testuser 
> --password=xxxxxxxxxxx
> x-xxx\testuserxxxxxxxxxxx
> SPNEGO request [testuser xxxxxxxxxxx] invalid prefix
> BH SPNEGO request invalid prefix
>
> root at xxx-testproxy01:~# /usr/bin/ntlm_auth 
> --helper-protocol=squid-2.5-basic --username=testuser 
> --password=xxxxxxxxxxx
> x-xxx\testuser xxxxxxxxxxx
> OK
>
> What is ntlmssp? I read both helpers on tutorials. If I need both, why 
> do I need both?
> My squid is starting how it should, logs are looking normal, PopUp for 
> authentication appears aswell, but I can't log in. I shoudn't need to 
> authenticate in the first place because it should use SSO.
> What is missing/faulty?
> The rest of squid is basic stuff:mail/u/0/
> auth_param ntlm program /usr/bin/ntlm_auth 
> ?helper-protocol=squid-2.5-ntlmssp --username=testuser 
> --password=Passme123
> auth_param ntlm children 10
> auth_param basic program /usr/bin/ntlm_auth 
> ?helper-protocol=squid-2.5-basic --username=testuser --password=Passme123
> auth_param basic children 5
> auth_param basic realm Proxy Server
> auth_param basic credentialsttl 2 hours
> auth_param basic casesensitive off
> authenticate_cache_garbage_interval 10 seconds
> ...
> acl auth proxy_auth REQUIRED
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> ...
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
>
> # Only allow cachemgr access from localhost
> http_access allow localnet
> http_access allow localhost manager
> http_access deny !auth
> http_access allow auth
> http_access deny all
> ...
> url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
> url_rewrite_children 5
>
> Does anyone know further? Thanks in advance.
> - Kevin
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Hi,


1. There is no point in testing kerberos (kinit) when you're going to 
use ntlm_auth helper; squid has it's spnego helper, 'negotiate_wrapper 
', which is capable doing negotiation between kerberos and NTLM.  Just 
look for squid-helpers package for your OS; if it's not in OS repo, 
check http://ngtech.co.il/repo/ - Eliezer is doing really good job here.

If kerberos is working in your environment, I would use 
negotiate_wrapper or negotiate_kerberos_auth.  Good thing about 
negotiate_wrapper is -d switch, which is giving you a good portion of 
debug info in cache.log

Really, NTLM is bitchy and it is not primary protocol even in MS systems 
since 2003/XP. If you can fulfill kerberos' requirements in your 
environment,  I would go into kerberos, not NTLM.


2. My guess is that you have problem with access to windbind_priviledged 
pipe; can you perform usr/bin/ntlm_auth 
--helper-protocol=squid-2.5-ntlmssp --username=testuser --password=...et 
cetera witch ptrace? There is still a mess with winbind's pipe location; 
/var/run/samba vs /var/lib/samba, perharps you need some symlinking, 
ptrace can give you a clue.


3. Sometimes - just sometimes - passing --domain=DOMAIN_NAME to 
/usr/bin/ntlm_auth resolves cosmic issues. Sometimes it's 
DOMAIN\username vs just username in --username.


Last thing is error message: "BH SPNEGO request invalid prefix". It is 
strange, at least for me. SPNEGO reply is rather kerberos or negotiate 
reply; not ntlm_auth. What distro are you using?

-- 
Dijx

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170510/c103aa9a/attachment.htm>

From squid3 at treenet.co.nz  Wed May 10 06:23:19 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 10 May 2017 18:23:19 +1200
Subject: [squid-users] Squid - using NTLM for SSO
In-Reply-To: <b6c339d1-4fcd-72f2-40b8-7a70e649fba6@gmail.com>
References: <VI1PR0501MB1967EDD767E33EE779D8C877A7EE0@VI1PR0501MB1967.eurprd05.prod.outlook.com>
 <b6c339d1-4fcd-72f2-40b8-7a70e649fba6@gmail.com>
Message-ID: <5a2a2508-b8f4-dd98-2246-b31874de1c8b@treenet.co.nz>

On 10/05/17 12:16, Dijxie wrote:
>
>> Hello list,
>>
>>
>> I need your help with a Squid-Proxy (3.5) NTLM Auth, the aim is to 
>> use SSO for my windows clients.
>>
>> My Windows-Clients are using Active-Directory running on a Samba4-PDC.
>>
>> I set up ldap basic auth in a developer environment, now I want to 
>> achieve SSO. (using NTLM?)
>>
>> The Documentation on 
>> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm doesn't 
>> really help me enough (on my knowledge about squid and forms of 
>> authentication/samba).
>>
>>
>> Tests:
>>
>> -> testing Kerberos
>>
>> I'm able to obtain (kinit) tickets and list them (klist)
>>
>>
>> root at xxx-testproxy01:~# kinit Administrator
>> Password for Administrator at X-XXX.LOCAL:
>> root at xxx-testproxy01:~# klist
>> Ticket cache: FILE:/tmp/krb5cc_0
>> Default principal: Administrator at X-XXX.LOCAL
>>
>> Valid starting       Expires              Service principal
>> 2017-05-09 08:43:25  2017-05-09 18:43:25 krbtgt/X-XXX.LOCAL at X-XXX.LOCAL
>>     renew until 2017-05-10 08:43:21
>>
>> -> testing Samba:
>> I joined my domain X-XXX.
>> Test support for ntlm:
>> root at xxx-testproxy01:~# wbinfo -a testuser%xxxxxxxxxxx
>> plaintext password authentication succeeded
>> challenge/response password authentication succeeded
>>
>> root at xxx-testproxy01:~# wbinfo -a testuser%xxxxxxxxxxx
>> plaintext password authentication succeeded
>> challenge/response password authentication succeeded
>> root at xxx-testproxy01:~# wbinfo -t
>> checking the trust secret for domain X-XXX via RPC calls succeeded
>> root at xxx-testproxy01:~# wbinfo -g
>> X-XXX\cert publishers
>> ...negotiate_wrapper
>> X-XXX\webusers
>>
>> -> Testing NTLM-helper:
>> Now here's my problem.
>>
>> root at xxx-testproxy01:~# /usr/bin/ntlm_auth 
>> --helper-protocol=squid-2.5-ntlmssp --username=testuser 
>> --password=xxxxxxxxxxx
>> x-xxx\testuserxxxxxxxxxxx
>> SPNEGO request [testuser xxxxxxxxxxx] invalid prefix
>> BH SPNEGO request invalid prefix
>>
>> root at xxx-testproxy01:~# /usr/bin/ntlm_auth 
>> --helper-protocol=squid-2.5-basic --username=testuser 
>> --password=xxxxxxxxxxx
>> x-xxx\testuser xxxxxxxxxxx
>> OK
>>
>> What is ntlmssp? I read both helpers on tutorials. If I need both, 
>> why do I need both?
>> My squid is starting how it should, logs are looking normal, PopUp 
>> for authentication appears aswell, but I can't log in. I shoudn't 
>> need to authenticate in the first place because it should use SSO.
>> What is missing/faulty?
>> The rest of squid is basic stuff:mail/u/0/
>> auth_param ntlm program /usr/bin/ntlm_auth 
>> ?helper-protocol=squid-2.5-ntlmssp --username=testuser 
>> --password=Passme123
>> auth_param ntlm children 10
>> auth_param basic program /usr/bin/ntlm_auth 
>> ?helper-protocol=squid-2.5-basic --username=testuser --password=Passme123
>> auth_param basic children 5
>> auth_param basic realm Proxy Server
>> auth_param basic credentialsttl 2 hours
>> auth_param basic casesensitive off
>> authenticate_cache_garbage_interval 10 seconds
>> ...
>> acl auth proxy_auth REQUIRED
>> acl SSL_ports port 443
>> acl Safe_ports port 80          # http
>> acl Safe_ports port 21          # ftp
>> acl Safe_ports port 443         # https
>> acl Safe_ports port 70          # gopher
>> acl Safe_ports port 210         # wais
>> acl Safe_ports port 1025-65535  # unregistered ports
>> acl Safe_ports port 280         # http-mgmt
>> acl Safe_ports port 488         # gss-http
>> acl Safe_ports port 591         # filemaker
>> acl Safe_ports port 777         # multiling http
>> acl CONNECT method CONNECT
>> ...
>> http_access deny !Safe_ports
>>
>> # Deny CONNECT to other than secure SSL ports
>> http_access deny CONNECT !SSL_ports
>>
>> # Only allow cachemgr access from localhost
>> http_access allow localnet
>> http_access allow localhost manager
>> http_access deny !auth
>> http_access allow auth
>> http_access deny all
>> ...
>> url_rewrite_program /usr/bin/squidGuard -c 
>> /etc/squidguard/squidGuard.conf
>> url_rewrite_children 5
>>
>> Does anyone know further? Thanks in advance.
>> - Kevin
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> Hi,
>
>
> 1. There is no point in testing kerberos (kinit) when you're going to 
> use ntlm_auth helper; squid has it's spnego helper, 'negotiate_wrapper 
> ', which is capable doing negotiation between kerberos and NTLM.  Just 
> look for squid-helpers package for your OS; if it's not in OS repo, 
> check http://ngtech.co.il/repo/ - Eliezer is doing really good job here.
>
> If kerberos is working in your environment, I would use 
> negotiate_wrapper or negotiate_kerberos_auth.  Good thing about 
> negotiate_wrapper is -d switch, which is giving you a good portion of 
> debug info in cache.log
>
> Really, NTLM is bitchy and it is not primary protocol even in MS 
> systems since 2003/XP. If you can fulfill kerberos' requirements in 
> your environment,  I would go into kerberos, not NTLM.
>
>
> 2. My guess is that you have problem with access to 
> windbind_priviledged pipe; can you perform usr/bin/ntlm_auth 
> --helper-protocol=squid-2.5-ntlmssp --username=testuser 
> --password=...et cetera witch ptrace? There is still a mess with 
> winbind's pipe location; /var/run/samba vs /var/lib/samba, perharps 
> you need some symlinking, ptrace can give you a clue.
>

The *full* setup related to Squid and winbind permissions is detailed at 
<http://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm#winbind_privileged_pipe_permissions> 
- pay particular attention to the three notes. Do ONLY what is 
specifically mentioned there, any other permissions fiddling done will 
only screw things up.


>
> 3. Sometimes - just sometimes - passing --domain=DOMAIN_NAME to 
> /usr/bin/ntlm_auth resolves cosmic issues. Sometimes it's 
> DOMAIN\username vs just username in --username.
>
>
> Last thing is error message: "BH SPNEGO request invalid prefix".  It 
> is strange, at least for me. SPNEGO reply is rather kerberos or 
> negotiate reply; not ntlm_auth. What distro are you using?
>

That output happened because Kevin passed the clear text (Basic auth) 
username/password to the helper when it was running in NTLM mode.  As 
you may notice the exact same input works fine when the helper is run in 
Basic mode.

When the helper is run with --helper-protocol=squid-2.5-ntlmssp the 
input it is expecting is the base64 encoded NTLMSSP object as found in 
the HTTP request headers. Squid does *not* decode the received header 
before sending it to the helper. The helper will respond with the crypto 
hunk to be sent to the client.

Amos


From omidkosari at yahoo.com  Wed May 10 10:32:45 2017
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 10 May 2017 03:32:45 -0700 (PDT)
Subject: [squid-users] Windows Updates a Caching Stub zone,
	A windows updates store.
In-Reply-To: <018f01d2b87c$59a02a50$0ce07ef0$@ngtech.co.il>
References: <004a01d1daf3$e6c4a490$b44dedb0$@ngtech.co.il>
 <1491489566256-4682002.post@n4.nabble.com>
 <05ce01d2aef3$1cb537d0$561fa770$@ngtech.co.il>
 <1492257145655-4682113.post@n4.nabble.com>
 <018f01d2b87c$59a02a50$0ce07ef0$@ngtech.co.il>
Message-ID: <1494412365812-4682351.post@n4.nabble.com>

Hello,

The old problem appears again because i am running 6 instances at same time.

TCP: out of memory -- consider tuning tcp_mem

Here is commands you mentioned .



root at squidbox:~#  free -m
              total        used        free      shared  buff/cache  
available
Mem:          16037       13503         147         171        2386       
1652
Swap:          8179         576        7603
root at squidbox:~# cat /proc/sys/net/ipv4/tcp_mem
381630  508844  763260
root at squidbox:~# top -n1 -b
top - 15:07:11 up 2 days, 10:04,  1 user,  load average: 3.50, 3.24, 3.13
Tasks: 190 total,   2 running, 188 sleeping,   0 stopped,   0 zombie
%Cpu(s): 19.1 us,  6.2 sy,  0.5 ni, 67.5 id,  1.9 wa,  0.0 hi,  4.8 si,  0.0
st
KiB Mem : 16422248 total,   166088 free, 13829624 used,  2426536 buff/cache
KiB Swap:  8376316 total,  7786056 free,   590260 used.  1690840 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 1620 proxy     20   0 3977368 3.606g   4708 S  46.7 23.0   1272:29 squid
 4451 root      20   0  632240 592500    584 S  26.7  3.6 404:11.34
ms-updates-fetc
 2573 root      20   0  636068 594116    612 S  20.0  3.6 403:12.45
ms-updates-fetc
 3661 root      20   0  646392 607532    500 S  20.0  3.7 427:31.70
ms-updates-fetc
 4171 root      20   0  656876 619500    604 S  20.0  3.8 460:54.17
ms-updates-fetc
 3934 root      20   0  642160 604896    492 S  13.3  3.7 411:05.97
ms-updates-fetc
 4555 root      20   0  656732 619700   1548 R  13.3  3.8 478:16.31
ms-updates-fetc
14746 root      20   0   40552   3464   2892 R   6.7  0.0   0:00.01 top
    1 root      20   0  185784   4972   3112 S   0.0  0.0   0:12.01 systemd
    2 root      20   0       0      0      0 S   0.0  0.0   0:00.69 kthreadd
    3 root      20   0       0      0      0 S   0.0  0.0   0:16.70
ksoftirqd/0
    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
kworker/0:0H
    7 root      20   0       0      0      0 S   0.0  0.0   7:11.28
rcu_sched
    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh
    9 root      rt   0       0      0      0 S   0.0  0.0   0:00.23
migration/0
   10 root      rt   0       0      0      0 S   0.0  0.0   0:00.54
watchdog/0
   11 root      rt   0       0      0      0 S   0.0  0.0   0:00.50
watchdog/1
   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.22
migration/1
   13 root      20   0       0      0      0 S   0.0  0.0   0:52.29
ksoftirqd/1
   15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
kworker/1:0H
   16 root      rt   0       0      0      0 S   0.0  0.0   0:00.48
watchdog/2
   17 root      rt   0       0      0      0 S   0.0  0.0   0:00.40
migration/2
   18 root      20   0       0      0      0 S   0.0  0.0  10:22.44
ksoftirqd/2
   20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
kworker/2:0H
   21 root      rt   0       0      0      0 S   0.0  0.0   0:00.49
watchdog/3
   22 root      rt   0       0      0      0 S   0.0  0.0   0:00.24
migration/3
   23 root      20   0       0      0      0 S   0.0  0.0   0:16.35
ksoftirqd/3
   25 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
kworker/3:0H
   26 root      20   0       0      0      0 S   0.0  0.0   0:00.00
kdevtmpfs
   27 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 netns
   28 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 perf
   29 root      20   0       0      0      0 S   0.0  0.0   0:00.13
khungtaskd
   30 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
writeback
   31 root      25   5       0      0      0 S   0.0  0.0   0:00.00 ksmd
   32 root      39  19       0      0      0 S   0.0  0.0   0:35.21
khugepaged
   33 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 crypto
   34 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
kintegrityd
   35 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
   36 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kblockd
   37 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 ata_sff
   38 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 md
   39 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
devfreq_wq
   43 root      20   0       0      0      0 S   0.0  0.0  81:22.18 kswapd0
   44 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 vmstat
   45 root      20   0       0      0      0 S   0.0  0.0   0:00.17
fsnotify_mark
   46 root      20   0       0      0      0 S   0.0  0.0   0:00.00
ecryptfs-kthrea
   62 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kthrotld
   63 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
acpi_thermal_pm
   64 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
   65 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
   66 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
   67 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
   68 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
   69 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
   70 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
   71 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
   72 root      20   0       0      0      0 S   0.0  0.0   0:00.02
scsi_eh_0
   73 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
scsi_tmf_0
   74 root      20   0       0      0      0 S   0.0  0.0   0:00.01
scsi_eh_1
   75 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
scsi_tmf_1
   77 root      20   0       0      0      0 S   0.0  0.0   0:00.04
scsi_eh_2
   78 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
scsi_tmf_2
   79 root      20   0       0      0      0 S   0.0  0.0   0:00.01
scsi_eh_3
   80 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
scsi_tmf_3
   88 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
ipv6_addrconf
  102 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 deferwq
  103 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
charger_manager
  108 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
  110 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
  111 root       0 -20       0      0      0 S   0.0  0.0   0:08.58
kworker/0:1H
  112 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
  113 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
  115 root       0 -20       0      0      0 S   0.0  0.0   0:01.65
kworker/2:1H
  116 root       0 -20       0      0      0 S   0.0  0.0   0:06.23
kworker/1:1H
  117 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
  163 root      20   0       0      0      0 S   0.0  0.0   0:00.00
scsi_eh_4
  164 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
scsi_tmf_4
  170 root       0 -20       0      0      0 S   0.0  0.0   0:19.22
kworker/3:1H
  171 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
kpsmoused
  237 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 ttm_swap
  432 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
  433 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
  434 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
  435 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
  700 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kdmflush
  703 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
  729 root      20   0       0      0      0 S   0.0  0.0   0:17.71
jbd2/dm-0-8
  730 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
ext4-rsv-conver
  776 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kauditd
  779 root      20   0   43924   5732   3444 S   0.0  0.0   7:32.43
systemd-journal
  800 root      20   0  102976    516    516 S   0.0  0.0   0:00.00 lvmetad
  806 root      20   0   45616   2432   2000 S   0.0  0.0   0:12.24
systemd-udevd
  983 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
kvm-irqfd-clean
 1003 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
reiserfs/sdd1
 1004 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
reiserfs/sdc1
 1005 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
reiserfs/sdf1
 1012 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
reiserfs/sdg1
 1016 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
reiserfs/sdi1
 1022 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
reiserfs/sdh1
 1024 root      20   0       0      0      0 S   0.0  0.0   0:10.50
jbd2/sde1-8
 1025 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
ext4-rsv-conver
 1032 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
reiserfs/sdb1
 1039 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kdmflush
 1040 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 bioset
 1048 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
ext4-rsv-conver
 1138 systemd+  20   0  100324   1592   1548 S   0.0  0.0   0:00.20
systemd-timesyn
 1253 root      20   0   28644   2328   2128 S   0.0  0.0   0:02.90
systemd-logind
 1255 syslog    20   0  256396   2276   1148 S   0.0  0.0   2:15.29 rsyslogd
 1263 root      20   0    4400   1012   1012 S   0.0  0.0   0:00.00 acpid
 1267 root      20   0   27324    948    620 S   0.0  0.0   0:00.88 smartd
 1271 message+  20   0   43028   1228    892 S   0.0  0.0   0:10.03
dbus-daemon
 1320 root      20   0  274588    592    168 S   0.0  0.0   1:05.66
accounts-daemon
 1329 root      20   0   27736   1764   1656 S   0.0  0.0   0:04.45 cron
 1334 whoopsie  20   0  345040    972    432 S   0.0  0.0   0:00.09 whoopsie
 1338 root      20   0   29888    212    212 S   0.0  0.0   0:00.00
cgmanager
 1350 daemon    20   0   26052   1112   1084 S   0.0  0.0   0:00.00 atd
 1352 root      20   0  472528  47288   3292 S   0.0  0.3  42:29.62
ms-updates-logg
 1473 root      20   0   19480   1548   1440 S   0.0  0.0   0:06.55
irqbalance
 1478 proxy     20   0    7464    284      0 S   0.0  0.0   0:00.25 polipo
 1488 root      20   0   18852      0      0 S   0.0  0.0   0:00.00 daemon
 1489 root      20   0    4508   1576   1484 S   0.0  0.0   0:00.27
megaraidsas-sta
 1492 root      20   0   18852      0      0 S   0.0  0.0   0:00.00 daemon
 1493 root      20   0    4508   1576   1496 S   0.0  0.0   0:00.23
megaclisas-stat
 1544 dnsmasq   20   0   51596   1544   1432 S   0.0  0.0   0:32.33 dnsmasq
 1618 root      20   0  129492    112    112 S   0.0  0.0   0:00.00 squid
 1624 root      20   0  277096   1036    732 S   0.0  0.0   0:00.02 polkitd
 1781 proxy     20   0   30224     36     36 S   0.0  0.0   1:29.41
log_file_daemon
 1932 vnstat    20   0    7536   1860   1788 S   0.0  0.0   0:06.87 vnstatd
 1935 root      20   0   65528   1680   1568 S   0.0  0.0   0:00.57 sshd
 1995 debian-+  20   0   97576  40352   4080 S   0.0  0.2   3:08.26 tor
 2008 root      20   0   14660   1036   1036 S   0.0  0.0   0:00.00 agetty
 2025 snmp      20   0   58552   5260   2724 S   0.0  0.0   2:23.73 snmpd
 2060 root      20   0  441600  11468   3444 S   0.0  0.1   3:00.98
fail2ban-server
 2065 root      20   0   92552   4496   2564 S   0.0  0.0   0:04.84
miniserv.pl
 2555 root      20   0   67456   1516   1476 S   0.0  0.0   0:00.00 cron
 2556 root      20   0    4508    348    348 S   0.0  0.0   0:00.00 sh
 2562 root      20   0   11236   1348   1348 S   0.0  0.0   0:00.00 bash
 2577 snmp      20   0   18804   2972   2508 S   0.0  0.0   0:11.78 perl
 3635 root      20   0   67456   1528   1488 S   0.0  0.0   0:00.00 cron
 3638 root      20   0    4508    376    376 S   0.0  0.0   0:00.00 sh
 3641 root      20   0   11236   1380   1380 S   0.0  0.0   0:00.00 bash
 3916 root      20   0   67456   1528   1488 S   0.0  0.0   0:00.00 cron
 3919 root      20   0    4508    244    244 S   0.0  0.0   0:00.00 sh
 3922 root      20   0   11236   1312   1312 S   0.0  0.0   0:00.00 bash
 4145 root      20   0   67456   1528   1488 S   0.0  0.0   0:00.00 cron
 4154 root      20   0    4508    400    400 S   0.0  0.0   0:00.00 sh
 4158 root      20   0   11236   1356   1356 S   0.0  0.0   0:00.00 bash
 4433 root      20   0   67456   1528   1488 S   0.0  0.0   0:00.00 cron
 4441 root      20   0    4508    332    332 S   0.0  0.0   0:00.00 sh
 4445 root      20   0   11236   1372   1372 S   0.0  0.0   0:00.00 bash
 4529 root      20   0   67456   1528   1488 S   0.0  0.0   0:00.00 cron
 4533 root      20   0    4508    324    324 S   0.0  0.0   0:00.00 sh
 4538 root      20   0   11236   1380   1380 S   0.0  0.0   0:00.00 bash
 9791 root      20   0 2100128   3268   3084 S   0.0  0.0   0:00.08
console-kit-dae
12173 root      20   0       0      0      0 S   0.0  0.0   0:00.93
kworker/u32:0
12997 root      20   0       0      0      0 S   0.0  0.0   0:00.00
kworker/3:0
13232 root      20   0       0      0      0 S   0.0  0.0   0:01.73
kworker/2:0
13458 root      20   0       0      0      0 S   0.0  0.0   0:01.48
kworker/0:1
13475 root      20   0       0      0      0 S   0.0  0.0   0:01.45
kworker/3:1
13558 root      20   0       0      0      0 S   0.0  0.0   0:00.34
kworker/u32:1
13656 root      20   0       0      0      0 S   0.0  0.0   0:01.12
kworker/1:1
13658 root      20   0       0      0      0 S   0.0  0.0   0:00.40
kworker/2:2
13809 root      20   0       0      0      0 S   0.0  0.0   0:00.16
kworker/u32:3
13896 root      20   0       0      0      0 S   0.0  0.0   0:00.00
kworker/1:2
13898 root      20   0       0      0      0 S   0.0  0.0   0:00.00
kworker/0:0
14055 root      20   0       0      0      0 S   0.0  0.0   0:00.00
kworker/2:1
14103 root      20   0       0      0      0 S   0.0  0.0   0:00.26
kworker/u32:4
14411 root      20   0  105996   6804   5800 S   0.0  0.0   0:00.03 sshd
14413 root      20   0       0      0      0 S   0.0  0.0   0:00.00
kworker/3:2
14414 omid      20   0   45256   4452   3760 S   0.0  0.0   0:00.08 systemd
14417 omid      20   0  225564   2144      0 S   0.0  0.0   0:00.00 (sd-pam)
14521 omid      20   0  105996   3424   2424 S   0.0  0.0   0:00.00 sshd
14522 omid      20   0   21288   5116   3252 S   0.0  0.0   0:00.08 bash
14537 root      20   0   70080   4036   3344 S   0.0  0.0   0:00.01 sudo
14538 root      20   0   21476   5248   3192 S   0.0  0.0   0:00.05 bash
14554 root      20   0       0      0      0 S   0.0  0.0   0:00.00
kworker/2:3
14639 root      20   0       0      0      0 S   0.0  0.0   0:00.00
kworker/1:0
14647 root      20   0       0      0      0 S   0.0  0.0   0:00.00
kworker/0:2
14703 root      20   0    6012    660    588 S   0.0  0.0   0:00.00 sleep
14740 root      20   0    6012    764    692 S   0.0  0.0   0:00.00 sleep
14742 root      20   0   67456   3436   2944 S   0.0  0.0   0:00.00 cron
14743 root      20   0    4508    760    680 S   0.0  0.0   0:00.00 sh
14744 root      20   0    6036    672    600 S   0.0  0.0   0:00.00 iostat
14745 root      20   0   15032   1108   1000 S   0.0  0.0   0:00.00 sed
22792 proxy     20   0   26420   6352   1392 S   0.0  0.0   0:33.16
storeid_file_re
22793 proxy     20   0   26420   6360   1400 S   0.0  0.0   0:00.68
storeid_file_re
22794 proxy     20   0   26420   6372   1408 S   0.0  0.0   0:00.20
storeid_file_re
22795 proxy     20   0   26420   6420   1456 S   0.0  0.0   0:00.15
storeid_file_re
22796 proxy     20   0   26420   6236   1396 S   0.0  0.0   0:00.14
storeid_file_re
32745 root       0 -20   18228   5852   3548 S   0.0  0.0   0:02.26 atop
root at squidbox:~# cat /proc/net/sockstat
sockets: used 15109
TCP: inuse 2337 orphan 879 tw 2073 alloc 15789 mem 767999
UDP: inuse 5 mem 5
UDPLITE: inuse 0
RAW: inuse 0
FRAG: inuse 0 memory 0
root at squidbox:~# cat /proc/sys/net/ipv4/tcp_max_orphans
65536






--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Windows-Updates-a-Caching-Stub-zone-A-windows-updates-store-tp4678454p4682351.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From omidkosari at yahoo.com  Wed May 10 12:17:36 2017
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 10 May 2017 05:17:36 -0700 (PDT)
Subject: [squid-users] Windows Updates a Caching Stub zone,
	A windows updates store.
In-Reply-To: <1494412365812-4682351.post@n4.nabble.com>
References: <004a01d1daf3$e6c4a490$b44dedb0$@ngtech.co.il>
 <1491489566256-4682002.post@n4.nabble.com>
 <05ce01d2aef3$1cb537d0$561fa770$@ngtech.co.il>
 <1492257145655-4682113.post@n4.nabble.com>
 <018f01d2b87c$59a02a50$0ce07ef0$@ngtech.co.il>
 <1494412365812-4682351.post@n4.nabble.com>
Message-ID: <1494418656416-4682352.post@n4.nabble.com>

I have deleted and recreate the request directory and see huge decrease in
memory usage of the fetcher process .

Did i do the right thing ? Is there anything that should i do after a while
?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Windows-Updates-a-Caching-Stub-zone-A-windows-updates-store-tp4678454p4682352.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yuriang at ltu.sld.cu  Wed May 10 14:27:33 2017
From: yuriang at ltu.sld.cu (yuriang)
Date: Wed, 10 May 2017 10:27:33 -0400
Subject: [squid-users] How to terminate (close) the active CONNECT
	connection when matching ACL.
Message-ID: <201705101027339230492@ltu.sld.cu>

How to terminate (close) the active CONNECT connection when matching ACL.

I have worked on version 3.5.23 on Debian 9.0, I use user authentication in addition to ACL to filter IP, MAC, all this works correctly. I have an ACL of type proxy_auth (quota_end) that contains a list of users that have exceeded a certain quota, which I deny to prohibit the user to continue the connection after having consumed its quota, that is to say when it is added to the aforementioned list . This works correctly for HTTP connections but not for HTTPS connections, these links remain active until the user performs an update to the page (press F5). Not so new HTTPS links if they are denied.
My question: Is there a way to terminate (close) the user's active HTTPS connection after matching the proxy_auth ACL (quota_end).

For more information here is my configuration, I manage several subnets, but I will only put one as an example:

# - TO AUTHENTICATE 
Acl authentication proxy_auth REQUIRED

# - (quota_end) Contains the users who consumed the assigned quota, it is used to deny the
# - browsing these users and displaying the quota page exceeded.
Acl quota_end proxy_auth "/ etc / squid / users / quota_end"

# ---- NETWORKS
Acl ip_ucm src "/etc/squid/redes_permitidas/ip_ucm.txt"
Acl mac_ucm arp "/ etc / squid / allowed_networks / mac_ucm.txt"

# ---- CONNECTION PORTS PERMITTED
Acl SSL_ports port 443 # https |
Acl SSL_ports port 563 # snews |
Acl SSL_ports port 873 # rsync |
Acl SSL_ports port 2187 # Iluminate |
Acl Safe_ports port 80 # http |
Acl Safe_ports port 21 # ftp |
Acl Safe_ports port 443 # https |
Acl Safe_ports port 70 # gopher |
Acl Safe_ports port 210 # wais |
Acl Safe_ports port 1025-65535 # unregistered ports
Acl Safe_ports port 280 # http-mgmt |
Acl Safe_ports port 488 # gss-http |
Acl Safe_ports port 591 # filemaker |
Acl Safe_ports port 777 # multilingual http
Acl Safe_ports port 631 # cups |
Acl Safe_ports port 873 # rsync |
Acl Safe_ports port 901 # SWAT |
Acl Safe_ports port 8888 # IRC |
Acl Safe_ports port 2187 # Iluminate |
Acl Safe_ports port 25 # smtp |
Acl Safe_ports port 110 # pop3 |

Acl CONNECT method CONNECT

# Deny requests to certain unsafe ports
Http_access deny! Safe_ports

# Deny CONNECT to other than secure SSL ports
Http_access deny CONNECT! SSL_ports

# Only allow cachemgr access from localhost
Http_access allow localhost manager
Http_access deny manager

# ----- DENY USERS EXHEDED YOUR QUOTA
Http_access deny quota_end

# - ALLOW USERS
Http_access allow ip_ucm mac_ucm authentication! Quota_end

# And finally deny all other access to this proxy
Http_access deny all


--
Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas

Infomed: http://www.sld.cu/



From denizlist at denizeren.net  Wed May 10 14:32:58 2017
From: denizlist at denizeren.net (Deniz Eren)
Date: Wed, 10 May 2017 17:32:58 +0300
Subject: [squid-users] Squid 4.0.19 SSLBump Crashes
Message-ID: <CAHQdsZ_6N9RMdMjbGoPkB+J85GQqsXADFdt2qxtni-4=D8stuQ@mail.gmail.com>

Hi,

I'm testing squid squid-4.0.19-20170508-r15031 when I enable ssl-bump
in intercept mode, after couple of SSL requests squid crashes in
"Parser::BinaryTokenizer::want(unsigned long long, char const*) const
()" function.

OS: CentOS 5
OpenSSL: 1.0.1e-51
g++: 4.8.2-15

I have attached part of debug log,core stack trace and squid.conf.(I
have migrated from 3.5, so there might be non-correct parts in my
squid.conf)

Does something wrong with my compilation or squid.conf; how can I
debug this issue.

Regards,
-------------- next part --------------
(gdb) bt
#0  0xf6f9fc80 in __kernel_vsyscall ()
#1  0xf6992b10 in raise () from /lib/libc.so.6
#2  0xf6994421 in abort () from /lib/libc.so.6
#3  0xf6bb2ab0 in __gnu_cxx::__verbose_terminate_handler() () from /usr/lib/libstdc++.so.6
#4  0xf6bb0515 in __gxx_personality_v0 () from /usr/lib/libstdc++.so.6
#5  0xf6bb0552 in __gxx_personality_v0 () from /usr/lib/libstdc++.so.6
#6  0xf6bb068a in __cxa_rethrow () from /usr/lib/libstdc++.so.6
#7  0xf7443830 in Parser::BinaryTokenizer::want(unsigned long long, char const*) const ()
#8  0xf744571d in Parser::BinaryTokenizer::area(unsigned long long, char const*) ()
#9  0xf7445915 in Parser::BinaryTokenizer::pstring16(char const*) ()
#10 0xf73c8238 in Security::TLSPlaintext::TLSPlaintext(Parser::BinaryTokenizer&) ()
#11 0xf73c9fa9 in Security::HandshakeParser::parseModernRecord() ()
#12 0xf73ca70d in Security::HandshakeParser::parseRecord() ()
#13 0xf73ca780 in Security::HandshakeParser::parseHello(SBuf const&) ()
#14 0xf73e158c in Ssl::ServerBio::readAndParse(char*, int, bio_st*) ()
#15 0xf73e195a in Ssl::ServerBio::read(char*, int, bio_st*) ()
#16 0xf73de898 in ?? ()
#17 0xf6dd7271 in BIO_read () from /lib/libcrypto.so.10
#18 0xf6f0b98b in ssl23_read_bytes () from /lib/libssl.so.10
#19 0xf6f0a902 in ssl23_connect () from /lib/libssl.so.10
#20 0xf6f1e09a in SSL_connect () from /lib/libssl.so.10
#21 0xf73d1f4d in Security::PeerConnector::negotiate() ()
#22 0xf73d4735 in NullaryMemFunT<Security::PeerConnector>::doDial() ()
#23 0xf73d510f in JobDialer<Security::PeerConnector>::dial(AsyncCall&) ()
#24 0xf73d52d2 in AsyncCallT<NullaryMemFunT<Security::PeerConnector> >::fire() ()
#25 0xf73615fb in AsyncCall::make() ()
#26 0xf736616c in AsyncCallQueue::fireNext() ()
#27 0xf7366568 in AsyncCallQueue::fire() ()
#28 0xf7185114 in EventLoop::runOnce() ()
#29 0xf7185228 in EventLoop::run() ()
#30 0xf71fc9f9 in SquidMain(int, char**) ()
#31 0xf70ce209 in main ()
-------------- next part --------------
2017/05/10 16:07:57.917 kid1| 5,8| ModEpoll.cc(266) DoSelect: got FD 23 events=4 monitoring=1c F->read_handler=0 F->write_handler=1
2017/05/10 16:07:57.917 kid1| 5,8| ModEpoll.cc(288) DoSelect: Calling write handler on FD 23
2017/05/10 16:07:57.917 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf959c078
2017/05/10 16:07:57.917 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf959c078=6
2017/05/10 16:07:57.917 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf959c078
2017/05/10 16:07:57.917 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf959c078=7
2017/05/10 16:07:57.917 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall Comm::ConnOpener::doConnect constructed, this=0xf9791d88 [call1160]
2017/05/10 16:07:57.917 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf959c078
2017/05/10 16:07:57.917 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf959c078=8
2017/05/10 16:07:57.917 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf959c078=7
2017/05/10 16:07:57.917 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf959c078=6
2017/05/10 16:07:57.917 kid1| 5,4| AsyncCall.cc(93) ScheduleCall: ConnOpener.cc(463) will call Comm::ConnOpener::doConnect() [call1160]
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf959c078=5
2017/05/10 16:07:57.918 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering Comm::ConnOpener::doConnect()
2017/05/10 16:07:57.918 kid1| 5,4| AsyncCall.cc(38) make: make call Comm::ConnOpener::doConnect [call1160]
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf959c078
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf959c078
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf959c078
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf959c078
2017/05/10 16:07:57.918 kid1| 5,4| AsyncJob.cc(123) callStart: Comm::ConnOpener status in: [ job139]
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf959c078
2017/05/10 16:07:57.918 kid1| 5,9| comm.cc(608) comm_connect_addr: connecting socket FD 23 to 192.229.233.50:443 (want family: 2)
2017/05/10 16:07:57.918 kid1| 5,9| comm.cc(714) comm_connect_addr: comm_connect_addr: FD 23 connected to 192.229.233.50:443
2017/05/10 16:07:57.918 kid1| 5,5| ConnOpener.cc(350) doConnect: local=0.0.0.0 remote=192.229.233.50:443 flags=1: Comm::OK - connected
2017/05/10 16:07:57.918 kid1| 5,4| ConnOpener.cc(155) cleanFd: local=0.0.0.0 remote=192.229.233.50:443 flags=1 closing temp FD 23
2017/05/10 16:07:57.918 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 23, type=2, handler=0, client_data=0, timeout=0
2017/05/10 16:07:57.918 kid1| 5,4| AsyncCall.cc(56) cancel: will not call Comm::ConnOpener::timeout [call1125] because Comm::ConnOpener::cleanFd
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf959c078=4
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf959c078=3
2017/05/10 16:07:57.918 kid1| 5,5| comm.cc(1030) comm_remove_close_handler: comm_remove_close_handler: FD 23, AsyncCall=0xf960bad0*2
2017/05/10 16:07:57.918 kid1| 5,4| AsyncCall.cc(56) cancel: will not call Comm::ConnOpener::earlyAbort [call1124] because comm_remove_close_handler
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf959c078=2
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf959c078=1
2017/05/10 16:07:57.918 kid1| 5,6| ConnOpener.cc(423) lookupLocalAddress: local=88.230.201.84:55332 remote=192.229.233.50:443 FD 23 flags=1
2017/05/10 16:07:57.918 kid1| 17,3| AsyncCall.cc(93) ScheduleCall: ConnOpener.cc(139) will call fwdConnectDoneWrapper(local=88.230.201.84:55332 remote=192.229.233.50:443 FD 23 flags=1, data=0xf94d5020) [call1119]
2017/05/10 16:07:57.918 kid1| 93,5| AsyncJob.cc(84) mustStop: Comm::ConnOpener will stop, reason: Comm::ConnOpener::connected
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf959c078
2017/05/10 16:07:57.918 kid1| 93,5| AsyncJob.cc(139) callEnd: Comm::ConnOpener::doConnect() ends job [Stopped, reason:Comm::ConnOpener::connected job139]
2017/05/10 16:07:57.918 kid1| 93,5| AsyncJob.cc(40) ~AsyncJob: AsyncJob destructed, this=0xf959c078 type=Comm::ConnOpener [job139]
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(309) cbdataInternalFree: 0xf959c078
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(321) cbdataInternalFree: 0xf959c078 has 1 locks, not freeing
2017/05/10 16:07:57.918 kid1| 93,6| AsyncJob.cc(149) callEnd: Comm::ConnOpener::doConnect() ended 0xf959c078
2017/05/10 16:07:57.918 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving Comm::ConnOpener::doConnect()
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf959c078=0
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(276) cbdataRealFree: Freeing 0xf959c078
2017/05/10 16:07:57.918 kid1| 17,3| AsyncCallQueue.cc(55) fireNext: entering fwdConnectDoneWrapper(local=88.230.201.84:55332 remote=192.229.233.50:443 FD 23 flags=1, data=0xf94d5020)
2017/05/10 16:07:57.918 kid1| 17,3| AsyncCall.cc(38) make: make call fwdConnectDoneWrapper [call1119]
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf94d5020
2017/05/10 16:07:57.918 kid1| 17,3| FwdState.cc(704) connectDone: local=88.230.201.84:55332 remote=192.229.233.50:443 FD 23 flags=1: '192.229.233.50:443'
2017/05/10 16:07:57.918 kid1| 5,5| comm.cc(974) comm_add_close_handler: comm_add_close_handler: FD 23, handler=1, data=0xf94d5020
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf94d5020=3
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf94d5020=4
2017/05/10 16:07:57.918 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall SomeCloseHandler constructed, this=0xf95402c8 [call1161]
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf94d5020=5
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf94d5020=4
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf94d5020=3
2017/05/10 16:07:57.918 kid1| 5,5| comm.cc(985) comm_add_close_handler: comm_add_close_handler: FD 23, AsyncCall=0xf95402c8*1
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf94d5020=4
2017/05/10 16:07:57.918 kid1| 17,4| AsyncCall.cc(26) AsyncCall: The AsyncCall FwdState::ConnectedToPeer constructed, this=0xf95dc780 [call1162]
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf94d5020
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf94d5020=5
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf94d5020=4
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(256) cbdataInternalAlloc: Allocating 0xf963ed50
2017/05/10 16:07:57.918 kid1| 93,5| AsyncJob.cc(34) AsyncJob: AsyncJob constructed, this=0xf963edac type=Ssl::PeekingPeerConnector [job148]
2017/05/10 16:07:57.918 kid1| 83,5| PeerConnector.cc(41) PeerConnector: Security::PeerConnector constructed, this=0xf963ed50
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf963ed50=1
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf963ed50
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf963ed50=2
2017/05/10 16:07:57.918 kid1| 93,5| AsyncCall.cc(26) AsyncCall: The AsyncCall AsyncJob::start constructed, this=0xf9791d88 [call1163]
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf963ed50
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf963ed50=3
2017/05/10 16:07:57.918 kid1| 93,5| AsyncCall.cc(93) ScheduleCall: AsyncJob.cc(26) will call AsyncJob::start() [call1163]
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf963ed50=2
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf963ed50=1
2017/05/10 16:07:57.918 kid1| 17,3| AsyncCallQueue.cc(57) fireNext: leaving fwdConnectDoneWrapper(local=88.230.201.84:55332 remote=192.229.233.50:443 FD 23 flags=1, data=0xf94d5020)
2017/05/10 16:07:57.918 kid1| 93,5| AsyncCallQueue.cc(55) fireNext: entering AsyncJob::start()
2017/05/10 16:07:57.918 kid1| 93,5| AsyncCall.cc(38) make: make call AsyncJob::start [call1163]
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf963ed50
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf963ed50
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf963ed50
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf963ed50
2017/05/10 16:07:57.918 kid1| 93,5| AsyncJob.cc(123) callStart: Ssl::PeekingPeerConnector status in: [ FD 23 job148]
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf963ed50
2017/05/10 16:07:57.918 kid1| 83,5| PeerConnector.cc(61) start: this=0xf963ed50
2017/05/10 16:07:57.918 kid1| 83,5| PeerConnector.cc(88) prepareSocket: local=88.230.201.84:55332 remote=192.229.233.50:443 FD 23 flags=1, this=0xf963ed50
2017/05/10 16:07:57.918 kid1| 83,5| PeerConnector.cc(94) prepareSocket: local=88.230.201.84:55332 remote=192.229.233.50:443 FD 23 flags=1
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf963ed50=2
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf963ed50
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf963ed50=3
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf963ed50
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf963ed50=4
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf963ed50=5
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf963ed50=4
2017/05/10 16:07:57.918 kid1| 9,5| AsyncCall.cc(26) AsyncCall: The AsyncCall Security::PeerConnector::commCloseHandler constructed, this=0xf960bad0 [call1164]
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf963ed50
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf963ed50=5
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf963ed50=6
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf963ed50=5
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf963ed50=4
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf963ed50=3
2017/05/10 16:07:57.918 kid1| 5,5| comm.cc(985) comm_add_close_handler: comm_add_close_handler: FD 23, AsyncCall=0xf960bad0*1
2017/05/10 16:07:57.918 kid1| 83,5| PeerConnector.cc(107) initialize: local=88.230.201.84:55332 remote=192.229.233.50:443 FD 23 flags=1, ctx=0xf8fbef98
2017/05/10 16:07:57.918 kid1| 83,5| Session.cc(98) NewSessionObject: SSL_new session=0xf96c9e60
2017/05/10 16:07:57.918 kid1| 83,5| bio.cc(616) squid_bio_ctrl: 0xf9789ec0 104(6001, 0xff91f760)
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9711 created
2017/05/10 16:07:57.918 kid1| 83,7| bio.cc(100) Bio: Bio constructed, this=0xf9760508 FD 23
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9712 created
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9713 created
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9714 created
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9715 created
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9716 created
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9717 created
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9718 created
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9719 created
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(49) SBuf: SBuf9720 created from id SBuf9719
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9719 destructed
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9721 created
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(49) SBuf: SBuf9722 created from id SBuf9721
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9721 destructed
2017/05/10 16:07:57.918 kid1| 83,5| Session.cc(157) CreateSession: link FD 23 to TLS session=0xf96c9e60
2017/05/10 16:07:57.918 kid1| 83,5| PeerConnector.cc(123) initialize: local=88.230.201.84:55332 remote=192.229.233.50:443 FD 23 flags=1, session=0xf96c9e60
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(256) cbdataInternalAlloc: Allocating 0xf96bbb48
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9723 created
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf8faabb0=4
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf9512480
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf9512480
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf9512480=7
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf9512480
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(49) SBuf: SBuf9724 created from id SBuf9295
2017/05/10 16:07:57.918 kid1| 24,7| SBuf.cc(150) rawSpace: reserving 1 for SBuf9724
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(908) cow: SBuf9724 new size:14
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(878) reAlloc: SBuf9724 new size: 14
2017/05/10 16:07:57.918 kid1| 24,9| MemBlob.cc(56) MemBlob: constructed, this=0xf960ba80 id=blob2074 reserveSize=14
2017/05/10 16:07:57.918 kid1| 24,8| MemBlob.cc(101) memAlloc: blob2074 memAlloc: requested=14, received=14
2017/05/10 16:07:57.918 kid1| 24,7| SBuf.cc(887) reAlloc: SBuf9724 new store capacity: 14
2017/05/10 16:07:57.918 kid1| 83,5| PeerConnector.cc(187) negotiate: SSL_connect session=0xf96c9e60
2017/05/10 16:07:57.918 kid1| 83,7| bio.cc(168) stateChanged: FD 23 now: 0x10 UNKWN  (before/connect initialization)
2017/05/10 16:07:57.918 kid1| 83,7| bio.cc(168) stateChanged: FD 23 now: 0x1001 UNKWN  (before/connect initialization)
2017/05/10 16:07:57.918 kid1| 83,5| bio.cc(117) write: FD 23 wrote 234 <= 234
2017/05/10 16:07:57.918 kid1| 83,7| bio.cc(168) stateChanged: FD 23 now: 0x1001 23WCHA (SSLv2/v3 write client hello A)
2017/05/10 16:07:57.918 kid1| 24,7| SBuf.cc(150) rawSpace: reserving 65535 for SBuf9711
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(908) cow: SBuf9711 new size:65535
2017/05/10 16:07:57.918 kid1| 24,8| SBuf.cc(878) reAlloc: SBuf9711 new size: 65535
2017/05/10 16:07:57.918 kid1| 24,9| MemBlob.cc(56) MemBlob: constructed, this=0xf9540350 id=blob2075 reserveSize=65535
2017/05/10 16:07:57.918 kid1| 24,8| MemBlob.cc(101) memAlloc: blob2075 memAlloc: requested=65535, received=65535
2017/05/10 16:07:57.918 kid1| 24,7| SBuf.cc(887) reAlloc: SBuf9711 new store capacity: 65535
2017/05/10 16:07:57.918 kid1| 83,5| bio.cc(140) read: FD 23 read -1 <= 65535
2017/05/10 16:07:57.918 kid1| 83,5| bio.cc(145) read: error: 11 ignored: 1
2017/05/10 16:07:57.918 kid1| 83,7| bio.cc(168) stateChanged: FD 23 now: 0x1002 23RSHA (SSLv2/v3 read server hello A)
2017/05/10 16:07:57.918 kid1| 83,5| PeerConnector.cc(451) noteWantRead: local=88.230.201.84:55332 remote=192.229.233.50:443 FD 23 flags=1
2017/05/10 16:07:57.918 kid1| 5,3| comm.cc(559) commSetConnTimeout: local=88.230.201.84:55332 remote=192.229.233.50:443 FD 23 flags=1 timeout 60
2017/05/10 16:07:57.918 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 23, type=1, handler=1, client_data=0xf963ed50, timeout=0
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf963ed50
2017/05/10 16:07:57.918 kid1| 93,5| AsyncJob.cc(154) callEnd: Ssl::PeekingPeerConnector status out: [ FD 23 job148]
2017/05/10 16:07:57.918 kid1| 93,5| AsyncCallQueue.cc(57) fireNext: leaving AsyncJob::start()
2017/05/10 16:07:57.918 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf963ed50=2
2017/05/10 16:07:57.918 kid1| 1,9| EventLoop.cc(42) checkEngine: Engine 0xff91fb48 is idle.
2017/05/10 16:07:57.918 kid1| 1,9| EventLoop.cc(42) checkEngine: Engine 0xff91fb4c is idle.
2017/05/10 16:07:57.921 kid1| 5,8| ModEpoll.cc(266) DoSelect: got FD 19 events=1 monitoring=19 F->read_handler=1 F->write_handler=0
2017/05/10 16:07:57.921 kid1| 5,8| ModEpoll.cc(272) DoSelect: Calling read handler on FD 19
2017/05/10 16:07:57.921 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf967cd78=3
2017/05/10 16:07:57.921 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf967cd78
2017/05/10 16:07:57.921 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf967cd78=4
2017/05/10 16:07:57.921 kid1| 83,7| AsyncCall.cc(26) AsyncCall: The AsyncCall Security::PeerConnector::negotiate constructed, this=0xf9791d88 [call1165]
2017/05/10 16:07:57.921 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf967cd78
2017/05/10 16:07:57.921 kid1| 45,9| cbdata.cc(351) cbdataInternalLock: 0xf967cd78=5
2017/05/10 16:07:57.921 kid1| 83,7| AsyncCall.cc(93) ScheduleCall: PeerConnector.cc(380) will call Security::PeerConnector::negotiate() [call1165]
2017/05/10 16:07:57.921 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf967cd78=4
2017/05/10 16:07:57.921 kid1| 45,9| cbdata.cc(383) cbdataInternalUnlock: 0xf967cd78=3
2017/05/10 16:07:57.921 kid1| 83,7| AsyncCallQueue.cc(55) fireNext: entering Security::PeerConnector::negotiate()
2017/05/10 16:07:57.921 kid1| 83,7| AsyncCall.cc(38) make: make call Security::PeerConnector::negotiate [call1165]
2017/05/10 16:07:57.921 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf967cd78
2017/05/10 16:07:57.921 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf967cd78
2017/05/10 16:07:57.921 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf967cd78
2017/05/10 16:07:57.921 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf967cd78
2017/05/10 16:07:57.921 kid1| 83,7| AsyncJob.cc(123) callStart: Ssl::PeekingPeerConnector status in: [ FD 19 job147]
2017/05/10 16:07:57.921 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0xf967cd78
2017/05/10 16:07:57.921 kid1| 83,5| PeerConnector.cc(187) negotiate: SSL_connect session=0xf96df048
2017/05/10 16:07:57.921 kid1| 24,7| SBuf.cc(150) rawSpace: reserving 65535 for SBuf9697
2017/05/10 16:07:57.921 kid1| 24,7| SBuf.cc(157) rawSpace: SBuf9697 not growing
2017/05/10 16:07:57.921 kid1| 83,5| bio.cc(140) read: FD 19 read 2800 <= 65535
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(526) forceSize: SBuf9697 force grow to length=2800
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(49) SBuf: SBuf9725 created from id SBuf9697
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: ?v2Hello.msg_head=5635 occupying 2 bytes @0 in 0xff91f708;
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: ?v2Hello.msg_type=3 occupying 1 bytes @2 in 0xff91f708;
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9725 destructed
2017/05/10 16:07:57.921 kid1| 24,7| SBuf.cc(96) assign: assigning SBuf9706 from SBuf9697
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9726 created
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: TLSPlaintext.type=22 occupying 1 bytes @0 in 0xf95aace4;
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: TLSPlaintext.version.major=3 occupying 1 bytes @1 in 0xf95aace4;
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: TLSPlaintext.version.minor=3 occupying 1 bytes @2 in 0xf95aace4;
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: TLSPlaintext.fragment.length=96 occupying 2 bytes @3 in 0xf95aace4;
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(49) SBuf: SBuf9727 created from id SBuf9706
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(74) got: TLSPlaintext.fragment.octets= 0200005c0303fc0e81458ed8b121fefbcfd3703a2f681f069eeea7af7af9cd2843c3a830394300c02f00003400000000ff01000100000b0004030001020023000000050000000f0001013374001208687474702f312e3108687474702f312e30 occupying 96 bytes @5 in 0xf95aace4;
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9727 destructed
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(57) got: TLSPlaintext occupying 101 bytes @0 in 0xf95aace4;
2017/05/10 16:07:57.921 kid1| 24,7| SBuf.cc(96) assign: assigning SBuf9704 from SBuf9726
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(49) SBuf: SBuf9728 created from id SBuf9704
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9728 destructed
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9729 created
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: Handshake.msg_type=2 occupying 1 bytes @0 in 0xf95aad0c;
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: Handshake.msg_body.length=92 occupying 3 bytes @1 in 0xf95aad0c;
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(49) SBuf: SBuf9730 created from id SBuf9708
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(74) got: Handshake.msg_body.octets= 0303fc0e81458ed8b121fefbcfd3703a2f681f069eeea7af7af9cd2843c3a830394300c02f00003400000000ff01000100000b0004030001020023000000050000000f0001013374001208687474702f312e3108687474702f312e30 occupying 92 bytes @4 in 0xf95aad0c;
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9730 destructed
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(57) got: Handshake occupying 96 bytes @0 in 0xf95aad0c;
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(49) SBuf: SBuf9731 created from id SBuf9729
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: ServerHello.version.major=3 occupying 1 bytes @0 in 0xff91f5e8.
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: ServerHello.version.minor=3 occupying 1 bytes @1 in 0xff91f5e8.
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(82) skipped: ServerHello.random occupying 32 bytes @2 in 0xff91f5e8.
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: ServerHello.session_id.length=0 occupying 1 bytes @34 in 0xff91f5e8.
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9732 created
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9732 destructed
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: ServerHello.cipher_suite=49199 occupying 2 bytes @35 in 0xff91f5e8.
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: ServerHello.compression_method=0 occupying 1 bytes @37 in 0xff91f5e8.
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: ServerHello.extensions.length=52 occupying 2 bytes @38 in 0xff91f5e8.
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(49) SBuf: SBuf9733 created from id SBuf9731
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(74) got: ServerHello.extensions.octets= 00000000ff01000100000b0004030001020023000000050000000f0001013374001208687474702f312e3108687474702f312e30 occupying 52 bytes @40 in 0xff91f5e8.
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(49) SBuf: SBuf9734 created from id SBuf9733
2017/05/10 16:07:57.921 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9735 created
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: Extension.type=0 occupying 2 bytes @0 in 0xff91f500.
2017/05/10 16:07:57.921 kid1| 24,7| BinaryTokenizer.cc(65) got: Extension.data.length=0 occupying 2 bytes @2 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9736 created
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9736 destructed
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(57) got: Extension occupying 4 bytes @0 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9737 created
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9737 destructed
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9735 destructed
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9738 created
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: Extension.type=65281 occupying 2 bytes @4 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: Extension.data.length=1 occupying 2 bytes @6 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(49) SBuf: SBuf9739 created from id SBuf9734
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(74) got: Extension.data.octets= 00 occupying 1 bytes @8 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9739 destructed
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(57) got: Extension occupying 5 bytes @4 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9738 destructed
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9740 created
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: Extension.type=11 occupying 2 bytes @9 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: Extension.data.length=4 occupying 2 bytes @11 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(49) SBuf: SBuf9741 created from id SBuf9734
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(74) got: Extension.data.octets= 03000102 occupying 4 bytes @13 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9741 destructed
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(57) got: Extension occupying 8 bytes @9 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9740 destructed
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9742 created
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: Extension.type=35 occupying 2 bytes @17 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: Extension.data.length=0 occupying 2 bytes @19 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9743 created
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9743 destructed
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(57) got: Extension occupying 4 bytes @17 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9742 destructed
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9744 created
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: Extension.type=5 occupying 2 bytes @21 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: Extension.data.length=0 occupying 2 bytes @23 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9745 created
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9745 destructed
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(57) got: Extension occupying 4 bytes @21 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9744 destructed
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9746 created
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: Extension.type=15 occupying 2 bytes @25 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: Extension.data.length=1 occupying 2 bytes @27 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(49) SBuf: SBuf9747 created from id SBuf9734
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(74) got: Extension.data.octets= 01 occupying 1 bytes @29 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9747 destructed
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(57) got: Extension occupying 5 bytes @25 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9746 destructed
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9748 created
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: Extension.type=13172 occupying 2 bytes @30 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: Extension.data.length=18 occupying 2 bytes @32 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(49) SBuf: SBuf9749 created from id SBuf9734
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(74) got: Extension.data.octets= 08687474702f312e3108687474702f312e30 occupying 18 bytes @34 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9749 destructed
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(57) got: Extension occupying 22 bytes @30 in 0xff91f500.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9748 destructed
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9734 destructed
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9733 destructed
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(57) got: ServerHello occupying 92 bytes @0 in 0xff91f5e8.
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9731 destructed
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9729 destructed
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(81) ~SBuf: SBuf9726 destructed
2017/05/10 16:07:57.922 kid1| 24,8| SBuf.cc(41) SBuf: SBuf9750 created
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: TLSPlaintext.type=22 occupying 1 bytes @101 in 0xf95aace4;
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: TLSPlaintext.version.major=3 occupying 1 bytes @102 in 0xf95aace4;
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: TLSPlaintext.version.minor=3 occupying 1 bytes @103 in 0xf95aace4;
2017/05/10 16:07:57.922 kid1| 24,7| BinaryTokenizer.cc(65) got: TLSPlaintext.fragment.length=4575 occupying 2 bytes @104 in 0xf95aace4;
2017/05/10 16:07:57.922 kid1| 24,5| BinaryTokenizer.cc(47) want: 1881 more bytes for TLSPlaintext.fragment.octets occupying 4575 bytes @106 in 0xf95aace4;
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf
Type: application/octet-stream
Size: 5062 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170510/e68c77b0/attachment.obj>

From eliezer at ngtech.co.il  Wed May 10 14:38:53 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Wed, 10 May 2017 17:38:53 +0300
Subject: [squid-users] Windows Updates a Caching Stub zone,
	A windows updates store.
In-Reply-To: <1494418656416-4682352.post@n4.nabble.com>
References: <004a01d1daf3$e6c4a490$b44dedb0$@ngtech.co.il>
 <1491489566256-4682002.post@n4.nabble.com>
 <05ce01d2aef3$1cb537d0$561fa770$@ngtech.co.il>
 <1492257145655-4682113.post@n4.nabble.com>
 <018f01d2b87c$59a02a50$0ce07ef0$@ngtech.co.il>
 <1494412365812-4682351.post@n4.nabble.com>
 <1494418656416-4682352.post@n4.nabble.com>
Message-ID: <02ce01d2c99b$25a59c50$70f0d4f0$@ngtech.co.il>

Technically it depends on the GoLang Garbage collection.
I will try to upgrade the software to GoLang V 1.8.1 in the next days but no promises on a specific date.
The next article might help you:
https://www.howtogeek.com/howto/ubuntu/delete-files-older-than-x-days-on-linux/

You can try to use the atime and not the mtime.
In any case if you are running out of memory please dump the top -n1 into a file and then use some paste or attach the file so I would be able to read it since the lines are in a way not in a form it would be easy for me to read.
It is possible that some fetchers will consume lots of memory and some of the requests are indeed un-needed but... don?t delete them.
Try to archive them and only then remove from them some by their age or something similar.
Once you have the request you have the option to fetch files and since it's such a small thing(max 64k per request) it's better to save and archive first and later wonder if some file request is missing.

All The Bests,
Eliezer

* if you want me to test or analyze your archived requests archive them inside a xz and send them over to me.

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Omid Kosari
Sent: Wednesday, May 10, 2017 3:18 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Windows Updates a Caching Stub zone, A windows updates store.

I have deleted and recreate the request directory and see huge decrease in memory usage of the fetcher process .

Did i do the right thing ? Is there anything that should i do after a while ?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Windows-Updates-a-Caching-Stub-zone-A-windows-updates-store-tp4678454p4682352.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Wed May 10 17:07:21 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 10 May 2017 11:07:21 -0600
Subject: [squid-users] How to terminate (close) the active CONNECT
 connection when matching ACL.
In-Reply-To: <201705101027339230492@ltu.sld.cu>
References: <201705101027339230492@ltu.sld.cu>
Message-ID: <36a7f12b-cffb-1a43-13fa-ad5f3ae5a0d1@measurement-factory.com>

On 05/10/2017 08:27 AM, yuriang wrote:
> How to terminate (close) the active CONNECT connection when matching ACL.

> I deny to prohibit the user to continue the connection after having
> consumed its quota

This is not quite what is happening. You are denying a user _request_,
not closing the user _connection_. In general, the user is free to send
more requests on the same connection (and they will be denied as well).
The difference between "request" and "connection" is usually minor in
this context, but it becomes important in case of any long-lived HTTP
transactions, including CONNECT tunnels.

The entire CONNECT tunnel is a single HTTP transaction from a
(non-bumping) Squid point of view. Your http_access rules allowed it.


> My question: Is there a way to terminate (close) the user's active
> HTTPS connection after matching the proxy_auth ACL (quota_end).

The question is somewhat wrong because Squid does not evaluate any ACLs
after it starts servicing a CONNECT tunnel. You may interpret that as a
"no" answer, but that would be somewhat misleading.

Your options include:

1. Use delay pools instead of access controls to enforce quota.
   Delay pools should be consulted throughout transaction lifetime.
2. Abruptly terminate long-lived CONNECT tunnels (time quota).
   This will hurt innocent users while preventing gross abuse.
3. Enforce quota outside of Squid (possibly, with Squid's help).
   A Squid helper can associate connections with users so that an
   external program can terminate connections as needed.

Some of the above options may require experimentation and/or Squid
enhancements.


HTH,

Alex.
P.S. Please note that copy-pasting corrupted your configuration.


> # - TO AUTHENTICATE 
> Acl authentication proxy_auth REQUIRED
> 
> # - (quota_end) Contains the users who consumed the assigned quota, it is used to deny the
> # - browsing these users and displaying the quota page exceeded.
> Acl quota_end proxy_auth "/ etc / squid / users / quota_end"
> 
> # ---- NETWORKS
> Acl ip_ucm src "/etc/squid/redes_permitidas/ip_ucm.txt"
> Acl mac_ucm arp "/ etc / squid / allowed_networks / mac_ucm.txt"
> 
> # ---- CONNECTION PORTS PERMITTED
> Acl SSL_ports port 443 # https |
> Acl SSL_ports port 563 # snews |
> Acl SSL_ports port 873 # rsync |
> Acl SSL_ports port 2187 # Iluminate |
> Acl Safe_ports port 80 # http |
> Acl Safe_ports port 21 # ftp |
> Acl Safe_ports port 443 # https |
> Acl Safe_ports port 70 # gopher |
> Acl Safe_ports port 210 # wais |
> Acl Safe_ports port 1025-65535 # unregistered ports
> Acl Safe_ports port 280 # http-mgmt |
> Acl Safe_ports port 488 # gss-http |
> Acl Safe_ports port 591 # filemaker |
> Acl Safe_ports port 777 # multilingual http
> Acl Safe_ports port 631 # cups |
> Acl Safe_ports port 873 # rsync |
> Acl Safe_ports port 901 # SWAT |
> Acl Safe_ports port 8888 # IRC |
> Acl Safe_ports port 2187 # Iluminate |
> Acl Safe_ports port 25 # smtp |
> Acl Safe_ports port 110 # pop3 |
> 
> Acl CONNECT method CONNECT
> 
> # Deny requests to certain unsafe ports
> Http_access deny! Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> Http_access deny CONNECT! SSL_ports
> 
> # Only allow cachemgr access from localhost
> Http_access allow localhost manager
> Http_access deny manager
> 
> # ----- DENY USERS EXHEDED YOUR QUOTA
> Http_access deny quota_end
> 
> # - ALLOW USERS
> Http_access allow ip_ucm mac_ucm authentication! Quota_end
> 
> # And finally deny all other access to this proxy
> Http_access deny all



From rousskov at measurement-factory.com  Wed May 10 17:18:18 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 10 May 2017 11:18:18 -0600
Subject: [squid-users] Squid 4.0.19 SSLBump Crashes
In-Reply-To: <CAHQdsZ_6N9RMdMjbGoPkB+J85GQqsXADFdt2qxtni-4=D8stuQ@mail.gmail.com>
References: <CAHQdsZ_6N9RMdMjbGoPkB+J85GQqsXADFdt2qxtni-4=D8stuQ@mail.gmail.com>
Message-ID: <673d0878-e413-59af-4a14-50864d20a807@measurement-factory.com>

On 05/10/2017 08:32 AM, Deniz Eren wrote:

> I'm testing squid squid-4.0.19-20170508-r15031 when I enable ssl-bump
> in intercept mode, after couple of SSL requests squid crashes


You have discovered one or two Squid bugs:

* Squid should handle exceptions when parsing SSL (without crashing);
* Squid must parse valid SSL (without throwing an exception).

To improve your chances of getting the bugs fixed, I recommend filing a
bug report in Bugzilla and attaching compressed whole-packet
to-and-from-Squid capture, captured while reproducing the problem (as
well as all the other artifacts you have provided, but updated to match
the packet capture).

If you can also test v5, please do so.


Thank you,

Alex.



From mlifshin at phantomdesign.com  Wed May 10 19:39:35 2017
From: mlifshin at phantomdesign.com (Masha Lifshin)
Date: Wed, 10 May 2017 12:39:35 -0700
Subject: [squid-users] Squid cannot parse Content-Length header value
 and closes connection before sending body?
Message-ID: <CA+8Eki3ezhXwhzVwGiqQzdGbDj77rKqxNkDd3tRO1iLBfrFrTQ@mail.gmail.com>

Thank you very much for your reply and subsequent work on this issue.  For
those who run into similar issues, the cause is the following bug:

http://bugs.squid-cache.org/show_bug.cgi?id=4492
<http://www.google.com/url?q=http%3A%2F%2Fbugs.squid-cache.org%2Fshow_bug.cgi%3Fid%3D4492&sa=D&sntz=1&usg=AFQjCNHxLMMy7H9BCp8Cu4-yItJLHWQ1zg>


Alex has created a patch that fixes the issue.

Thank you,
-Masha

On Mon, May 1, 2017 at 4:37 PM, Alex Rousskov <rousskov at measurement-factory.
com> wrote:

> On 05/01/2017 04:12 PM, Masha Lifshin wrote:
>
> > when I turn on icap, squid shuts down the connection early,
> > without returning the body of the response.  It seems it cannot read the
> > content length header and that messes up both squid and icap.
>
> > 2017/04/28 08:11:47.297 kid1| 55,2| HttpHeader.cc(1483)
> > httpHeaderNoteParsedEntry: cannot parse hdr field: 'Content-Length: 606'
>
>
> These "cannot parse hdr field" lines is a sign of a minor accounting bug
> (fixed in the latest Squid; v5 r15019). Do not worry about it -- it does
> not affect Squid behavior beyond header statistics reporting.
>
>
> > 2017/04/28 08:11:47.576 kid1| 93,3|
> > Adaptation::Icap::Xaction::noteCommRead threw exception: garbage
> > instead of CRLF line terminator
>
> This exception can explain your symptoms: Squid failed to parse some
> portion of the ICAP response from your ICAP server. This is either a
> Squid bug or an ICAP server bug.
>
> Please make sure your Squid v4 contains a fix for bug #4551:
>
>     http://bugs.squid-cache.org/show_bug.cgi?id=4551
>
> Squid v4.0.13 and newer should have that fix. If your Squid is v4.0.17
> then bug #4551 should be fixed, but perhaps there is another bug OR the
> ICAP server itself is misbehaving.
>
>
> >  Or is there some disconnect about the 206 code from icap?
>
> The posted logs do not show enough info for me to pinpoint the problem.
> Try replacing "93,3" with "93,9 74,9" in your debug_options. Is that
> enough to get the ICAP server response logged? (I do not remember the
> minimum set of debug_options necessary to accomplish that.) If you post
> a new log, please attach (or post a link to) it instead of quoting it in
> the email because email formatting often screws up important details.
>
> Alternatively, post a pcap-format capture of TCP packets between Squid
> and ICAP server (but be careful with what you share on the list).
>
>
> Cheers,
>
> Alex.
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170510/2aed7f00/attachment.htm>

From squid-user at tlinx.org  Thu May 11 05:15:04 2017
From: squid-user at tlinx.org (L A Walsh)
Date: Wed, 10 May 2017 22:15:04 -0700
Subject: [squid-users] How to make sslbump'ing more robust? (option to
	continue?)
Message-ID: <5913F358.9080005@tlinx.org>

I tried accessing a site that had an expired certificate today
(https://www.tcl.tk/doc/scripting.html).

In going through squid, I got:

-----
The following error was encountered while trying to retrieve the URL: 
https://www.tcl.tk/doc/scripting.html

    *Failed to establish a secure connection to 38.88.76.19*

The system returned:

    (71) Protocol error (TLS code: X509_V_ERR_CERT_HAS_EXPIRED)

    SSL Certificate expired on: May 10 23:59:59 2017 GMT

This proxy and the remote host failed to negotiate a mutually acceptable 
security settings for handling your request. It is possible that the 
remote host does not support secure connections, or the proxy is not 
satisfied with the host security credentials.

----------------


But trying the same page through IE (not going through squid), I got:

-------

There is a problem with this website's security certificate.

The security certificate presented by this website has expired or is not 
yet valid.

Security certificate problems may indicate an attempt to fool you or 
intercept any data you send to the server.

We recommend that you close this webpage and do not continue to this 
website.

Click here to close this webpage. <javascript:closePage()>

Continue to this website (not recommended).


------

Is there any way to put up some similar page to describe the problem,
and most importantly, allow the connection to continue at user
discretion?


Thanks!
-linda



From omidkosari at yahoo.com  Thu May 11 06:41:07 2017
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 10 May 2017 23:41:07 -0700 (PDT)
Subject: [squid-users] Windows Updates a Caching Stub zone,
	A windows updates store.
In-Reply-To: <02ce01d2c99b$25a59c50$70f0d4f0$@ngtech.co.il>
References: <004a01d1daf3$e6c4a490$b44dedb0$@ngtech.co.il>
 <1491489566256-4682002.post@n4.nabble.com>
 <05ce01d2aef3$1cb537d0$561fa770$@ngtech.co.il>
 <1492257145655-4682113.post@n4.nabble.com>
 <018f01d2b87c$59a02a50$0ce07ef0$@ngtech.co.il>
 <1494412365812-4682351.post@n4.nabble.com>
 <1494418656416-4682352.post@n4.nabble.com>
 <02ce01d2c99b$25a59c50$70f0d4f0$@ngtech.co.il>
Message-ID: <1494484867742-4682360.post@n4.nabble.com>

Eliezer Croitoru wrote
> You can try to use the atime and not the mtime.

Each time the fetcher script runs , all of request files will access and
then atime will refreshed .
I think for "request" directory it should be "mtime" and for "body"
directory it should be "atime" .


Eliezer Croitoru wrote
> It is possible that some fetchers will consume lots of memory and some of
> the requests are indeed un-needed but... don?t delete them.
> Try to archive them and only then remove from them some by their age or
> something similar.
> Once you have the request you have the option to fetch files and since
> it's such a small thing(max 64k per request) it's better to save and
> archive first and later wonder if some file request is missing.

But currently there is more than 230000 files in old request directory .
Maybe the garbage collector of GoLang will not release the memory after
processing each file .



Eliezer Croitoru wrote
> * if you want me to test or analyze your archived requests archive them
> inside a xz and send them over to me.

I have sent you the request directory in previous private email .

Thanks




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Windows-Updates-a-Caching-Stub-zone-A-windows-updates-store-tp4678454p4682360.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From glazov.vladimir.a at gmail.com  Thu May 11 08:31:46 2017
From: glazov.vladimir.a at gmail.com (=?UTF-8?B?0JLQu9Cw0LTQuNC80LjRgCDQk9C70LDQt9C+0LI=?=)
Date: Thu, 11 May 2017 11:31:46 +0300
Subject: [squid-users] Squid for windows,
	ldaps authentication with tls support.
Message-ID: <CAAfifq9FLcjUGYo7JH0NfdP7VtqpBi8B4VeiqyPhUL_MUAFKbQ@mail.gmail.com>

Hello!

I ran in to a problem with Diladele B.V. squid for windows, then i try
authenticate user with basic_ldap_auth against ldaps server using TLS it's
ending with error "Could not Activate TLS connection". From traffic dump i
can see, what problem is in "Unknown CA" but i don't see any way how to add
trusted root ca in this setup.

Is there any option in my situation?

Squid version 3.5.15.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170511/a6e881d4/attachment.htm>

From erdosain9 at gmail.com  Thu May 11 15:27:54 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 11 May 2017 08:27:54 -0700 (PDT)
Subject: [squid-users] WARNING: All 20/20 negotiateauthenticator processes
	are busy.
Message-ID: <1494516474107-4682362.post@n4.nabble.com>

Hi.
Im having this problem.

may 11 11:26:23 squid.xxxx.lan squid[32138]: WARNING: All 30/30
negotiateauthenticator processes are busy.
may 11 11:26:23 squid.xxxx.lan squid[32138]: WARNING: 30 pending requests
queued
may 11 11:26:23 squid.xxxx.lan squid[32138]: WARNING: Consider increasing
the number of negotiateauthenticator processes in your config file.


This is my config file

###Kerberos Auth with ActiveDirectory###
auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -s
HTTP/squid.empddh.lan at EMPDDH.LAN
auth_param negotiate children 30
auth_param negotiate keep_alive on


Can somebody explain this for me?
Of course, i can "increasing the number of negotiateauthenticator", but i
want to understand (maybe its a better way)

I see some examples like this
	auth_param digest children 20 startup=0 idle=1

What about that? startup? idle? that was a better way? or this not having
nothing to do?

Thanks to all!
(i dont speak english)



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/WARNING-All-20-20-negotiateauthenticator-processes-are-busy-tp4682362.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Thu May 11 16:19:39 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 11 May 2017 10:19:39 -0600
Subject: [squid-users] How to make sslbump'ing more robust? (option to
 continue?)
In-Reply-To: <5913F358.9080005@tlinx.org>
References: <5913F358.9080005@tlinx.org>
Message-ID: <4f256c33-438b-96b4-7984-bc4e3a884ad4@measurement-factory.com>

On 05/10/2017 11:15 PM, L A Walsh wrote:
> I tried accessing a site that had an expired certificate today

> In going through squid, I got [a Squid error page]

> But trying the same page through IE, I got [IE error page with]
> Continue to this website (not recommended).

> Is there any way to put up some similar page to describe the problem,
> and most importantly, allow the connection to continue at user
> discretion?

Yes, there is a way. Your options include:

1. Tell Squid to ignore expired certificates errors. Squid will then
mimic the expired certificate while allowing the client traffic. The
client should then detect the expired (fake) certificate and may offer
the user to bypass the problem. However, if the client is not smart
enough, it may silently allow the connection to an attacker. In general,
not all clients are smart browsers (and not all users are smart enough
not to bypass warnings that should not be bypassed). It is your decision
who to delegate certificate freshness checks to. By default, Squid does
them (and smart browsers do them as well). This is not so much about
robustness but mostly about security.

2.1 Customize Squid error page(s). You can make them look almost exactly
like the browser error pages if you want.

2.2. Add user-driven error bypass to #2.1. Write Squid helper scripts
(at least!) that convert user clicking a link in a Squid-generated error
page to Squid ignoring the expired certificate error and generating a
fresh fake certificate (instead of the expired one). Implementing this
well is difficult, but, AFAICT, possible.

For more details and starting points, please see error_directory,
sslproxy_cert_error, sslproxy_cert_adapt, and external_acl_type in
squid.conf.documented.


HTH,

Alex.



From erdosain9 at gmail.com  Thu May 11 17:37:49 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 11 May 2017 10:37:49 -0700 (PDT)
Subject: [squid-users] How to make sslbump'ing more robust? (option to
	continue?)
In-Reply-To: <4f256c33-438b-96b4-7984-bc4e3a884ad4@measurement-factory.com>
References: <5913F358.9080005@tlinx.org>
 <4f256c33-438b-96b4-7984-bc4e3a884ad4@measurement-factory.com>
Message-ID: <1494524269254-4682364.post@n4.nabble.com>

how you do the option 1???
Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-to-make-sslbump-ing-more-robust-option-to-continue-tp4682359p4682364.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Thu May 11 17:54:29 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 11 May 2017 18:54:29 +0100
Subject: [squid-users] How to make sslbump'ing more robust? (option to
	continue?)
In-Reply-To: <1494524269254-4682364.post@n4.nabble.com>
References: <5913F358.9080005@tlinx.org>
 <4f256c33-438b-96b4-7984-bc4e3a884ad4@measurement-factory.com>
 <1494524269254-4682364.post@n4.nabble.com>
Message-ID: <201705111854.29743.Antony.Stone@squid.open.source.it>

On Thursday 11 May 2017 at 18:37:49, erdosain9 wrote:

> how you do the option 1???

As Alex already said:

"For more details and starting points, please see error_directory,
sslproxy_cert_error, sslproxy_cert_adapt, and external_acl_type in
squid.conf.documented."


Antony.

-- 
Salad is what food eats.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From dijxie at gmail.com  Thu May 11 20:00:44 2017
From: dijxie at gmail.com (Dijxie)
Date: Thu, 11 May 2017 22:00:44 +0200
Subject: [squid-users] WARNING: All 20/20 negotiateauthenticator
 processes are busy.
In-Reply-To: <1494516474107-4682362.post@n4.nabble.com>
References: <1494516474107-4682362.post@n4.nabble.com>
Message-ID: <89df3bbf-300e-dcdd-21b2-079ea847662d@gmail.com>

W dniu 11.05.2017 o 17:27, erdosain9 pisze:
> Hi.
> Im having this problem.
>
> may 11 11:26:23 squid.xxxx.lan squid[32138]: WARNING: All 30/30
> negotiateauthenticator processes are busy.
> may 11 11:26:23 squid.xxxx.lan squid[32138]: WARNING: 30 pending requests
> queued
> may 11 11:26:23 squid.xxxx.lan squid[32138]: WARNING: Consider increasing
> the number of negotiateauthenticator processes in your config file.
>
>
> This is my config file
>
> ###Kerberos Auth with ActiveDirectory###
> auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -s
> HTTP/squid.empddh.lan at EMPDDH.LAN
> auth_param negotiate children 30
> auth_param negotiate keep_alive on
>
>
> Can somebody explain this for me?
> Of course, i can "increasing the number of negotiateauthenticator", but i
> want to understand (maybe its a better way)
>
> I see some examples like this
> 	auth_param digest children 20 startup=0 idle=1
>
> What about that? startup? idle? that was a better way? or this not having
> nothing to do?
>
> Thanks to all!
> (i dont speak english)
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/WARNING-All-20-20-negotiateauthenticator-processes-are-busy-tp4682362.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> Also, you may try set keep_alive to off - this option sometimes tends to hang negotiate helper.

Hi.
Here is documentation: http://www.squid-cache.org/Doc/config/auth_param/
Startup is the number auth helpers launched when squid is starting. Idle 
is the nuber of processes that squid will keep alive even if there is no 
cache users. You may increase children calculating available RAM, but 
leave startup and idle values low. Squid will launch helpers when 
needed, and next will gracefully close them if not used until "idle" 
value reached; that 'recycle' process is good for helpers.  Just make 
sure that your available RAM is enough for all negotiate helpers squid 
may launch (children number), that considers system daemons, memory 
cache etc.

Kerberos and negotiate authenticators are not capable of doing 
concurrent authentications, as well as ntlm authenticator (at least in 
squid-2.5-ntlmssp mode); one worker can serve one request at the time. 
So, that warning is saing that your cache server has more users - or 
rather users are making more concurrent connections at the same time 
than auth helpers can handle. Or, there is something wrong with one or 
more helpers; use cachemgr.cgi or squid-client to verify.
http://wiki.squid-cache.org/Features/CacheManager
http://wiki.squid-cache.org/SquidClientTool - squidclient mgr:menu will 
give you available comands, grep output by "auth", AFAIR it's 
mgr:negotiate_authenticator
If the number of connections awaiting authentication is greater than 
children number, the queue begins. The queue is something unwanted; 
makes users wait for page to load. Also, at the end, squid will restart 
if queue situation trurns to be chronic.
Also, you may try set keep_alive to off - this option sometimes tends to 
hang negotiate helper.

Could you satisfy my curiousity by telling me how many users are there 
in your environment?



-- 
Greetings, Dijx



From jramirez.uy at gmail.com  Fri May 12 00:49:34 2017
From: jramirez.uy at gmail.com (=?UTF-8?Q?Juan_Ram=C3=ADrez?=)
Date: Thu, 11 May 2017 21:49:34 -0300
Subject: [squid-users] ICAP Persistent Connections vs Retries (with code
	review)
Message-ID: <CAEK0aNvmxU1h_Tj-Qu46NO2fSvZhRcKtpPmSkar+4-vG3BjmbQ@mail.gmail.com>

Hi,

Mi name is Juan, I am a Software Engineer from Uruguay. I think this
message is more suited to the squid-dev mailing list due to the
developer-oriented nature of the message but, given that the development
list is for people who actually contributes code to Squid, I chose to post
here.

I started using Squid a few days ago in order to test its
content-adaptation capabilities. The plan was to test the ICAP
implementation first and then maybe try the eCAP API as well.

In order to test ICAP, I based my code in the open source PYICAP project, I
also ran some tests using the C-ICAP server.

It came to my attention that, even when persistent connections is enabled,
Squid closes the ICAP connection everytime a new request arrives, like this:

1. A new request arrives
2. Squid creates a connection to the ICAP server
3. Content is adapted and returned to the client
4. Squid returns the connection to the connection pool
5. A new requests arrives
6. Squid closes the active connection
7. Squid opens a new connection to the ICAP server

Note: I am using only the RESPMOD method.

This tests was performed using Squid 3.5.x. I downloaded the last available
tarball (squid-4.0.19), and run the same test, which gave the same results.

So I started digging into the source code and found something interesting:

File:
    /src/adaptation/icap/ServiceRep.cc
Function:
    Adaptation::Icap::ServiceRep::getConnection(bool retriableXact, bool
&reused)

Code:
    if (retriableXact)
        connection = theIdleConns->pop();
    else {
        theIdleConns->closeN(1);
    }

The connection is taken from the set of idle connections  ONLY if
retriableXact is set to true.

File:
    /src/adaptation/icap/Xaction.cc
Function:
    Adaptation::Icap::Xaction::openConnection()

Xaction uses the member variable 'isRetriable' as parameter for
ServiceRep::getConnection.

The function Xaction::disableRetries() is called from a lot of places, but
in my test case was called only two times (per request):

   1. In the function Adaptation::Icap::Xaction::noteCommRead, when
Comm::ReadNow returns Comm::OK.

   2. In the function Adaptation::Icap::Xaction::closeConnection,
because reuseConnection is set to true.

I am not sure if Xaction objects are reusable, it seems that they are
because setting isRetriable to false is affecting the way connections are
reused.

Anyway, I think the concept of retriability shuld not be confused with the
concept of reusability, but I haven't gone deep enough in order to ensure
that.

I appreciate your comments on this. Don't hesitate to contact me should any
additional information be needed.


-- 
Juan
:wq
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170511/7cfcdb0c/attachment.htm>

From squid3 at treenet.co.nz  Fri May 12 00:59:06 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 May 2017 12:59:06 +1200
Subject: [squid-users] Squid for windows,
 ldaps authentication with tls support.
In-Reply-To: <CAAfifq9FLcjUGYo7JH0NfdP7VtqpBi8B4VeiqyPhUL_MUAFKbQ@mail.gmail.com>
References: <CAAfifq9FLcjUGYo7JH0NfdP7VtqpBi8B4VeiqyPhUL_MUAFKbQ@mail.gmail.com>
Message-ID: <83f100e3-4643-dac0-c8f4-cd1b2dbf1ae7@treenet.co.nz>

On 11/05/17 20:31, ???????? ?????? wrote:
> Hello!
>
> I ran in to a problem with Diladele B.V. squid for windows, then i try 
> authenticate user with basic_ldap_auth against ldaps server using TLS 
> it's ending with error "Could not Activate TLS connection". From 
> traffic dump i can see, what problem is in "Unknown CA" but i don't 
> see any way how to add trusted root ca in this setup.
>
> Is there any option in my situation?

Are you using SSL-Bump features of this Squid or using it as a normal proxy?

>
> Squid version 3.5.15.

Please update to latest version before debugging TLS related problems. 
The TLS related code in Squid is quite volatile still, and problem you 
have may already be fixed.

Amos



From squid3 at treenet.co.nz  Fri May 12 01:30:39 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 May 2017 13:30:39 +1200
Subject: [squid-users] ICAP Persistent Connections vs Retries (with code
 review)
In-Reply-To: <CAEK0aNvmxU1h_Tj-Qu46NO2fSvZhRcKtpPmSkar+4-vG3BjmbQ@mail.gmail.com>
References: <CAEK0aNvmxU1h_Tj-Qu46NO2fSvZhRcKtpPmSkar+4-vG3BjmbQ@mail.gmail.com>
Message-ID: <e2c054b0-36af-1b1a-fd1f-48729e975ddd@treenet.co.nz>

On 12/05/17 12:49, Juan Ram?rez wrote:
> Hi,
>
> Mi name is Juan, I am a Software Engineer from Uruguay. I think this 
> message is more suited to the squid-dev mailing list due to the 
> developer-oriented nature of the message but, given that the 
> development list is for people who actually contributes code to Squid, 
> I chose to post here.

Membership is for those people, the list itself acts as a focal point 
for anyone such as yourself with this query to contact them without 
having to know particular peoples contacts.


As to your issue;

Requests which are not retriable are not able to be re-sent if it turns 
out they got even partially delivered on a pre-opened persistent 
connection which happened to be in the process of closing by the other 
endpoint unknown to Squid. For example if the timing of the write to 
deliver the ICAP RESPMOD headers overlapped with the TCP FIN/RST packets 
coming from a router along the network path, or the ICAP service itself.

As such those requests need a new TCP connection to be opened to 
guarantee the absence of immediate closure. When they complete with 
their transaction it gets added to the pool for other traffic to use if 
they can.

The behaviour which you describe was designed to prevent the ICAP pool 
from absorbing all available TCP resources through these constant brand 
new TCP connections being needed then added to the pool. Which would 
leave the proxy unable to receive HTTP traffic as there would be no TCP 
sockets/ports available for non-ICAP connections.

If your service only (or mostly) has non-retriable transactions occuring 
it can be more efficient to disable persistence o speed up the turn 
around on TCP socket closures. Persistence is useful for when you have 
many retriable transactions occuring which can use pooled connections 
and be re-tried if something barfs at the TCP level.


As far as I know RESPMOD transactions should all be retriable unless the 
body payload length is unknown at the HTTP level (lack of Content-Length 
header).

They can also become non-retriable when the response from the ICAP 
server has been received by Squid and already started delivery to the 
HTTP client. That is the noteCommRead call - to prevent the connection 
being pooled if the connection suddenly closes before it completes. This 
should not have any effect on whether a pooled connection was used to 
start with, but will affect whether a pooled connection gets used on the 
retry attempt to prevent the same issue/delay repeating indefinitely to 
the same client.

(PS. Alex knows a lot more about the details of this design than me, so 
if he says anything contradicting the above go with his).

Amos



From squid-user at tlinx.org  Fri May 12 03:45:01 2017
From: squid-user at tlinx.org (L A Walsh)
Date: Thu, 11 May 2017 20:45:01 -0700
Subject: [squid-users] How to make sslbump'ing more robust? (option to
	continue?)
In-Reply-To: <4f256c33-438b-96b4-7984-bc4e3a884ad4@measurement-factory.com>
References: <5913F358.9080005@tlinx.org>
 <4f256c33-438b-96b4-7984-bc4e3a884ad4@measurement-factory.com>
Message-ID: <59152FBD.90802@tlinx.org>

Alex Rousskov wrote:
> Yes, there is a way. Your options include:
> 
> 1. Tell Squid to ignore expired certificates errors. Squid will then
> mimic the expired certificate while allowing the client traffic. The
> client should then detect the expired (fake) certificate and may offer
> the user to bypass the problem. 
...
----

Since my SSL-bump is on a private server with most clients
being my clients, this is probably the most ideal.  I wasn't sure
if the type of SSL-problem would be correctly duplicated to the
client, as I didn't want to just continue the connection without
telling the browser operator (most often, me) that there was
some problem.

Thanks!
-linda




From Anton.Kornexl at Uni-Passau.De  Fri May 12 08:51:50 2017
From: Anton.Kornexl at Uni-Passau.De (Anton Kornexl)
Date: Fri, 12 May 2017 10:51:50 +0200
Subject: [squid-users] cachemgr
Message-ID: <591593C6020000940008E1FE@smtp1.gw.uni-passau.de>

Hello,

i am using the cachemgr.cgi (cachemgr.cgi/3.3.14 from openSUSE Leap 42.1 (x86_64))

The cache Manager menu shows many entries multiple times:
See following list

Cache Manager menu for localhost:
 
	    Cache Manager Interface
	    Cache Manager Menu
	    Toggle offline_mode setting (requires authentication).
	    Shut Down the Squid Process (requires authentication).
	    Reconfigure Squid (hidden).
	    Rotate Squid Logs (hidden).
	    Persistent Connection Utilization Histograms
	    Statistic of cached generated ssl certificates
	    Memory Utilization
	    DISKD Stats
	    Async IO Function Counters
	    Current Squid Configuration (requires authentication).
	    comm_incoming() stats
	    IP Cache Stats and Contents
	    FQDN Cache Stats and Contents
	    Internal DNS Statistics
	    URL Redirector Stats
	    Basic User Authenticator Stats
	    External ACL stats
	    HTTP Header Statistics
	    Via Request Headers
	    X-Forwarded-For Request Headers
	    General Runtime Information
	    Service Times (Percentiles)
	    Process Filedescriptor Allocation
	    All Cache Objects
	    In-Memory and In-Transit Objects
	    Server-side network read() size histograms
	    Traffic and Resource Counters
	    Peer Selection Algorithms
	    Cache Digest and ICP blob
	    5 Minute Average of Counters
	    60 Minute Average of Counters
	    Cache Utilization
	    Full Histogram Counts
	    Client-side Active Requests
	    Active Cached Usernames
	    Objects with Swapout files open
	    Store Digest
	    Histogram of store.log tags
	    Store Directory Stats
	    Store IO Interface Stats
	    storeCheckCachable() Stats
	    Refresh Algorithm Statistics
	    Delay Pool Levels
	    Request Forwarding Statistics
	    Callback Data Registry Contents
	    Event Queue
	    Cache Client List
	    Network Measurement Database
	    AS Number Database
	    CARP information
	    peer userhash information
	    peer sourcehash information
	    Peer Cache Statistics
	    List of Unknown sites sending ICP messages
	    Current Squid Configuration (requires authentication).
	    Via Request Headers
	    X-Forwarded-For Request Headers
	    Histogram of store.log tags
	    Internal DNS Statistics
	    URL Redirector Stats
	    Basic User Authenticator Stats
	    External ACL stats
	    Cache Client List
	    Network Measurement Database
	    AS Number Database
	    CARP information
	    peer userhash information
	    peer sourcehash information
	    Peer Cache Statistics
	    List of Unknown sites sending ICP messages 




Kind regards
Anton Kornexl
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170512/d28560df/attachment.htm>

From chiasa.men at web.de  Fri May 12 10:31:21 2017
From: chiasa.men at web.de (chiasa.men)
Date: Fri, 12 May 2017 12:31:21 +0200
Subject: [squid-users] (no subject)
In-Reply-To: <42de2bce-9528-439b-e2a3-2e7957213bc6@treenet.co.nz>
References: <trinity-3602572c-8333-41eb-a8ca-303df9eff1f7-1492946751598@3capp-webde-bap06>
 <42de2bce-9528-439b-e2a3-2e7957213bc6@treenet.co.nz>
Message-ID: <2182775.AmgSP9YVQ3@march>

Am Sonntag, 23. April 2017, 17:57:52 CEST schrieb Amos Jeffries:
> On 23/04/17 23:25, chiasa.men at web.de wrote:
> > Hello
> > 
> > my squid.conf looks like that:
> > 
> > https_port 3128 accel cert=/cert.pem key=/cert.key
> > 
> > defaultsite=ww1.example.com vhost
> > 
> > acl server20_domains dstdomain ww1.example.com ww2.example.com
> > 
> > http_access allow server20_domains
> > 
> > cache_peer server20 parent 443 0 no-query originserver name=server20
> > 
> > login=PASSTHRU ssl sslversion=6
> > 
> > cache_peer_access server20 allow server20_domains
> > 
> > cache_peer_access server20 deny all
> > 
> > The idea was to send ww1 and ww2 to server20 which is hosting an apache
> > 
> > webservice for both sites.
> 
> That looks fine.
> 
> > You can see that approximately after 5s the timeout happens. Is it a
> > message
> > 
> > to worry about? (it is just "info" labled) Why does it occur?
> 
> Unknown. This is an Apache problem. The Squid portion of things appears
> to be working if I'm reading that weird  access.log correctly.
> 
> Amos

Acutally it's not. The problem seemed to be the 
server_persistent_connections setting in squid.conf.
By default set to on it tries to keep the cache_peer connection. Apache on the 
other site hit the KeepAliveTimeout which was set to 5 seconds by default.
server_persistent_connections off in squid.conf

It set server_persistent_connections to off and the problem disappeared.
Is there any downside of this setting?

  __
|"""\-=
(____)
  __
|"""\-=
(____)
(tanks)

Chia


From squid3 at treenet.co.nz  Fri May 12 12:16:45 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 May 2017 00:16:45 +1200
Subject: [squid-users] (no subject)
In-Reply-To: <2182775.AmgSP9YVQ3@march>
References: <trinity-3602572c-8333-41eb-a8ca-303df9eff1f7-1492946751598@3capp-webde-bap06>
 <42de2bce-9528-439b-e2a3-2e7957213bc6@treenet.co.nz>
 <2182775.AmgSP9YVQ3@march>
Message-ID: <6e91c07f-6511-2cd3-9cb9-9e425b7a90e5@treenet.co.nz>

On 12/05/17 22:31, chiasa.men wrote:
> Am Sonntag, 23. April 2017, 17:57:52 CEST schrieb Amos Jeffries:
>> On 23/04/17 23:25, chiasa.men at web.de wrote:
>>> Hello
>>>
>>> my squid.conf looks like that:
>>>
>>> https_port 3128 accel cert=/cert.pem key=/cert.key
>>>
>>> defaultsite=ww1.example.com vhost
>>>
>>> acl server20_domains dstdomain ww1.example.com ww2.example.com
>>>
>>> http_access allow server20_domains
>>>
>>> cache_peer server20 parent 443 0 no-query originserver name=server20
>>>
>>> login=PASSTHRU ssl sslversion=6
>>>
>>> cache_peer_access server20 allow server20_domains
>>>
>>> cache_peer_access server20 deny all
>>>
>>> The idea was to send ww1 and ww2 to server20 which is hosting an apache
>>>
>>> webservice for both sites.
>> That looks fine.
>>
>>> You can see that approximately after 5s the timeout happens. Is it a
>>> message
>>>
>>> to worry about? (it is just "info" labled) Why does it occur?
>> Unknown. This is an Apache problem. The Squid portion of things appears
>> to be working if I'm reading that weird  access.log correctly.
>>
>> Amos
> Acutally it's not. The problem seemed to be the
> server_persistent_connections setting in squid.conf.
> By default set to on it tries to keep the cache_peer connection. Apache on the
> other site hit the KeepAliveTimeout which was set to 5 seconds by default.
> server_persistent_connections off in squid.conf

So Squid is told (by Apache) that the connection is to be kept open / 
persistent and then Apache closes it very quickly afterward. That is an 
explicit configured problem, but still Apache endpoint is the cause of 
the issues you are having here.

It is not a bug or error for either software, since that is one of the 
behaviours explicitly allowed by HTTP. But for you its being a problem.


> It set server_persistent_connections to off and the problem disappeared.
> Is there any downside of this setting?

1) Every single HTTP request sent to any upstream server has to go 
through a full TCP connection handshake process, then a TCP shutdown 
process afterwards.

2) TCP socket cannot be used for a second connection until the kernel 
has confirmed both endpoints are not going to send anything on it. Which 
may be up to 15min.

Between them these can cause a 50ms extra latency on every request, with 
a limit of just over 70 requests per second through the proxy to any 
given server - compared to the several tens of thousands Squid can 
normally handle and under 1ms latency that is quite bad.


The efficient solution is to have long persistence on the connections 
between your CDN frontend (Squid) and the backend origins (Apache). You 
can make the timeout much shorter on the Squid client connections.

Amos



From squid3 at treenet.co.nz  Fri May 12 12:21:37 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 May 2017 00:21:37 +1200
Subject: [squid-users] How to make sslbump'ing more robust? (option to
 continue?)
In-Reply-To: <59152FBD.90802@tlinx.org>
References: <5913F358.9080005@tlinx.org>
 <4f256c33-438b-96b4-7984-bc4e3a884ad4@measurement-factory.com>
 <59152FBD.90802@tlinx.org>
Message-ID: <a1af1f6f-f7ab-0e86-5421-86ca43ba8670@treenet.co.nz>



On 12/05/17 15:45, L A Walsh wrote:
> Alex Rousskov wrote:
>> Yes, there is a way. Your options include:
>>
>> 1. Tell Squid to ignore expired certificates errors. Squid will then
>> mimic the expired certificate while allowing the client traffic. The
>> client should then detect the expired (fake) certificate and may offer
>> the user to bypass the problem. 
> ...
> ----
>
> Since my SSL-bump is on a private server with most clients
> being my clients, this is probably the most ideal.  I wasn't sure
> if the type of SSL-problem would be correctly duplicated to the
> client, as I didn't want to just continue the connection without
> telling the browser operator (most often, me) that there was
> some problem.

The detail of what gets mimic'd are documented at 
<http://wiki.squid-cache.org/Features/MimicSslServerCert>.

Under validity Dates:
  "True dates by default. If a true validity date is missing or if 
sslproxy_cert_adapt setValidAfter and setValidBefore is active, then the 
signing certificate validity date is used."

Amos



From rousskov at measurement-factory.com  Fri May 12 13:49:27 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 12 May 2017 07:49:27 -0600
Subject: [squid-users] cachemgr
In-Reply-To: <591593C6020000940008E1FE@smtp1.gw.uni-passau.de>
References: <591593C6020000940008E1FE@smtp1.gw.uni-passau.de>
Message-ID: <6393f7b4-4b39-8b84-da65-58353d83f050@measurement-factory.com>

On 05/12/2017 02:51 AM, Anton Kornexl wrote:

> i am using the cachemgr.cgi (cachemgr.cgi/3.3.14 from openSUSE Leap 42.1

> The cache Manager menu shows many entries multiple times

Could be bug 3188 fixed four years ago:
http://bugs.squid-cache.org/show_bug.cgi?id=3188

Alex.



From rousskov at measurement-factory.com  Fri May 12 14:08:51 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 12 May 2017 08:08:51 -0600
Subject: [squid-users] ICAP Persistent Connections vs Retries (with code
 review)
In-Reply-To: <e2c054b0-36af-1b1a-fd1f-48729e975ddd@treenet.co.nz>
References: <CAEK0aNvmxU1h_Tj-Qu46NO2fSvZhRcKtpPmSkar+4-vG3BjmbQ@mail.gmail.com>
 <e2c054b0-36af-1b1a-fd1f-48729e975ddd@treenet.co.nz>
Message-ID: <cfe8696e-e243-2f5c-4646-f830bbafe4ad@measurement-factory.com>

On 05/11/2017 07:30 PM, Amos Jeffries wrote:

> Requests which are not retriable are not able to be re-sent [...] 
> As such those requests need a new TCP connection to be opened to
> guarantee the absence of immediate closure. When they complete with
> their transaction it gets added to the pool for other traffic to use if
> they can.

The above is accurate, including the snipped parts documenting the
rationale. BTW, since HTTP and ICAP share the same basic connection
persistency model, you may find more information reading about these
general problems in HTTP-related documents.


> As far as I know RESPMOD transactions should all be retriable unless the
> body payload length is unknown at the HTTP level (lack of Content-Length
> header).

This is inaccurate. A REQMOD or RESPMOD transaction is deemed retriable
at the time when a connection is chosen/open if:

* Squid can send a preview or
* Squid can buffer the entire HTTP message body.

The "known length" aspect affects the second bullet, but that bullet
covers more cases than just messages with Content-Length. And there may
be more conditions in the code than the bullets cover -- I have not checked.


> They can also become non-retriable when the response from the ICAP
> server has been received by Squid and already started delivery to the
> HTTP client.

This is accurate (including the snipped part about the irrelevance to
the connection choice).


HTH,

Alex.



From chiasa.men at web.de  Fri May 12 14:50:36 2017
From: chiasa.men at web.de (chiasa.men)
Date: Fri, 12 May 2017 16:50:36 +0200
Subject: [squid-users] (no subject)
In-Reply-To: <6e91c07f-6511-2cd3-9cb9-9e425b7a90e5@treenet.co.nz>
References: <trinity-3602572c-8333-41eb-a8ca-303df9eff1f7-1492946751598@3capp-webde-bap06>
 <2182775.AmgSP9YVQ3@march>
 <6e91c07f-6511-2cd3-9cb9-9e425b7a90e5@treenet.co.nz>
Message-ID: <5016333.HCJO9l77OU@march>

Am Freitag, 12. Mai 2017, 14:16:45 CEST schrieb Amos Jeffries:
> On 12/05/17 22:31, chiasa.men wrote:
> > Am Sonntag, 23. April 2017, 17:57:52 CEST schrieb Amos Jeffries:
> >> On 23/04/17 23:25, chiasa.men at web.de wrote:
> >>> Hello
> >>> 
> >>> my squid.conf looks like that:
> >>> 
> >>> https_port 3128 accel cert=/cert.pem key=/cert.key
> >>> 
> >>> defaultsite=ww1.example.com vhost
> >>> 
> >>> acl server20_domains dstdomain ww1.example.com ww2.example.com
> >>> 
> >>> http_access allow server20_domains
> >>> 
> >>> cache_peer server20 parent 443 0 no-query originserver name=server20
> >>> 
> >>> login=PASSTHRU ssl sslversion=6
> >>> 
> >>> cache_peer_access server20 allow server20_domains
> >>> 
> >>> cache_peer_access server20 deny all
> >>> 
> >>> The idea was to send ww1 and ww2 to server20 which is hosting an apache
> >>> 
> >>> webservice for both sites.
> >> 
> >> That looks fine.
> >> 
> >>> You can see that approximately after 5s the timeout happens. Is it a
> >>> message
> >>> 
> >>> to worry about? (it is just "info" labled) Why does it occur?
> >> 
> >> Unknown. This is an Apache problem. The Squid portion of things appears
> >> to be working if I'm reading that weird  access.log correctly.
> >> 
> >> Amos
> > 
> > Acutally it's not. The problem seemed to be the
> > server_persistent_connections setting in squid.conf.
> > By default set to on it tries to keep the cache_peer connection. Apache on
> > the other site hit the KeepAliveTimeout which was set to 5 seconds by
> > default. server_persistent_connections off in squid.conf
> 
> So Squid is told (by Apache) that the connection is to be kept open /
> persistent and then Apache closes it very quickly afterward. That is an
> explicit configured problem, but still Apache endpoint is the cause of
> the issues you are having here.
> 
> It is not a bug or error for either software, since that is one of the
> behaviours explicitly allowed by HTTP. But for you its being a problem.
You are absolutely right.
> 
> > It set server_persistent_connections to off and the problem disappeared.
> > Is there any downside of this setting?
> 
> 1) Every single HTTP request sent to any upstream server has to go
> through a full TCP connection handshake process, then a TCP shutdown
> process afterwards.
> 
> 2) TCP socket cannot be used for a second connection until the kernel
> has confirmed both endpoints are not going to send anything on it. Which
> may be up to 15min.
> 
> Between them these can cause a 50ms extra latency on every request, with
> a limit of just over 70 requests per second through the proxy to any
> given server - compared to the several tens of thousands Squid can
> normally handle and under 1ms latency that is quite bad.
> 
> 
> The efficient solution is to have long persistence on the connections
> between your CDN frontend (Squid) and the backend origins (Apache). You
> can make the timeout much shorter on the Squid client connections.
I see. So I'll tell apache to set the KeepAliveTimeout to squids default 
persistent_request_timeout of 2 minutes :)
That sounds reasonable.
Thank you for the explanation.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users




From rousskov at measurement-factory.com  Fri May 12 15:20:50 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 12 May 2017 09:20:50 -0600
Subject: [squid-users] (no subject)
In-Reply-To: <5016333.HCJO9l77OU@march>
References: <trinity-3602572c-8333-41eb-a8ca-303df9eff1f7-1492946751598@3capp-webde-bap06>
 <2182775.AmgSP9YVQ3@march>
 <6e91c07f-6511-2cd3-9cb9-9e425b7a90e5@treenet.co.nz>
 <5016333.HCJO9l77OU@march>
Message-ID: <62eeccf3-d7cd-496e-c9cc-8bfcdcbeb5b6@measurement-factory.com>

On 05/12/2017 08:50 AM, chiasa.men wrote:
> Am Freitag, 12. Mai 2017, 14:16:45 CEST schrieb Amos Jeffries:
>> The efficient solution is to have long persistence on the connections
>> between your CDN frontend (Squid) and the backend origins (Apache). You
>> can make the timeout much shorter on the Squid client connections.

> I see. So I'll tell apache to set the KeepAliveTimeout to squids default 
> persistent_request_timeout of 2 minutes :)

To avoid race conditions, the Apache timeout should be _larger_ than
Squid timeout. If Apache only talks to Squid, then it does not hurt to
set the Apache timeout to twice the value of Squid timeout. It is the
_smaller_ timeout that will effectively determine the number of idle
persistent connections between the two points in this case.

Alex.



From erdosain9 at gmail.com  Fri May 12 15:30:34 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Fri, 12 May 2017 08:30:34 -0700 (PDT)
Subject: [squid-users] WARNING: All 20/20 negotiateauthenticator
	processes are busy.
In-Reply-To: <89df3bbf-300e-dcdd-21b2-079ea847662d@gmail.com>
References: <1494516474107-4682362.post@n4.nabble.com>
 <89df3bbf-300e-dcdd-21b2-079ea847662d@gmail.com>
Message-ID: <1494603034421-4682379.post@n4.nabble.com>

Hi.
Thanks!

We have 100 users........... What would you think is a good "auth_param
negotiate children"??

I cant run squidclient

[root at squid ~]# squidclient mgr:negotiate_authenticator 
ERROR: Cannot connect to [::1]:3128
[root at squid ~]# squidclient -vv mgr:negotiate_authenticator 
verbosity level set to 2
Request:
GET cache_object://localhost/negotiate_authenticator HTTP/1.0
Host: localhost
User-Agent: squidclient/3.5.20
Accept: */*
Connection: close


.
Transport detected: IPv4-mapped  and IPv6
Resolving localhost ...
Connecting... localhost ([::1]:3128)
ERROR: Cannot connect to [::1]:3128


CONFIG
# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager


So??
Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/WARNING-All-20-20-negotiateauthenticator-processes-are-busy-tp4682362p4682379.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yanier at eleccav.une.cu  Fri May 12 19:58:15 2017
From: yanier at eleccav.une.cu (yanier)
Date: Fri, 12 May 2017 14:58:15 -0500
Subject: [squid-users] squid sslbump
Message-ID: <011b01d2cb5a$18294a20$487bde60$@eleccav.une.cu>

Hi all:

 

I have a question and I would like to clarify this.
I have the following internet connection scheme

Proxy (administrator by me) - Router / FW - Proxy Parent - -Router -
Internet

I would like to know if I could implement sslbump or similar to be able to
filter traffic https (I think squid uses sslbump and slice) with this scheme
without having to make changes in the parent proxy (I do not have access to
do anything in the parent proxy).

If possible what configuration do you recommend?

If not, what other option do I have to filter https traffic in squid?


Greetings Yanier

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170512/119a200d/attachment.htm>

From jramirez.uy at gmail.com  Fri May 12 19:17:57 2017
From: jramirez.uy at gmail.com (=?UTF-8?Q?Juan_Ram=C3=ADrez?=)
Date: Fri, 12 May 2017 16:17:57 -0300
Subject: [squid-users] ICAP Persistent Connections vs Retries (with code
	review)
In-Reply-To: <cfe8696e-e243-2f5c-4646-f830bbafe4ad@measurement-factory.com>
References: <CAEK0aNvmxU1h_Tj-Qu46NO2fSvZhRcKtpPmSkar+4-vG3BjmbQ@mail.gmail.com>
 <e2c054b0-36af-1b1a-fd1f-48729e975ddd@treenet.co.nz>
 <cfe8696e-e243-2f5c-4646-f830bbafe4ad@measurement-factory.com>
Message-ID: <CAEK0aNvx7oRuP7yqaS-ar2aFRThvTs7TahBfV0Ef8eF-VLs3QA@mail.gmail.com>

Hi,

Thank you all for such detailed responses.

I still don't understand whether it is possible to reuse ICAP connections
for cases other than retries.

As far as I know, Squid is able to save connections in a pool called
`theIdleConns`.
Can these connection be reused for other transactions in the future?

The flow I am trying to accomplish is the following:

1. Client performs a requests and a response arrives
2. Squid catches the response and invokes the ICAP adaptation routine
3. A new connection the the ICAP server is created
4. The RESPMOD transaction is issued successfully
5. The connection is returned to the pool
6. The response is then sent to the client

... Moments later:

7. Another client performs a request a a response arrives
8. Squid catches the response and invokes the ICAP adaptation routine
9. Squid reuses the connection which was created previously
10. The RESPMOD transaction is issued successfully
11. The connection is returned to the pool
12. The response is then sent to the client

That behavior does not happen, going back to this code:

    if (retriableXact)
        connection = theIdleConns->pop();
    else
        theIdleConns->closeN(1);

The line `theIdleConns->closeN(1);` is the one that gets executed all the
time with no exception. Well, it is actually an exception to the case, and
I'll explain it later. Have in mind that I modified the code in order to
prove that:

    if (retriableXact) {
        debugs(93, 1, HERE << "Calling theIdleConns->pop()");
        connection = theIdleConns->pop();
    } else {
        debugs(93, 1, HERE << "Calling theIdleConns->closeN(1)");
        theIdleConns->closeN(1);
    }


Based on that log, I could confirm that connections are reused properly
only for small response sizes.
Digging a little bit into the source code I finally understood what Alex
mean with "Squid can buffer the entire HTTP message body.":
  Retries are disabled if the message body is to big, this is a protective
measure which prevents from using to much RAM, it is clearly documented and
I understand it.

For those curious enough, the file in question is `ModXact.cc` (functions `
decideOnRetries()` and `canBackupEverything()`).

Wrapping up:

* Why does disabling retries in a connection dooms the connection?
* Why does the size of the payload affect the way connections are reused
* Does Squid need a finer control on this matter in order to ensure
connection reusability is not affected by the size of the payload?

In the first response, Amos wrote the following:

>> Requests which are not retriable are not able to be re-sent if it turns
out
>> they got even partially delivered on a pre-opened persistent connection
>> which happened to be in the process of closing by the other endpoint
>> unknown to Squid. For example if the timing of the write to deliver the
>> ICAP RESPMOD headers overlapped with the TCP FIN/RST packets
>> coming from a router along the network path, or the ICAP service itself.

>> As such those requests need a new TCP connection to be opened to
>> guarantee the absence of immediate closure. When they complete with
>> their transaction it gets added to the pool for other traffic to use if
they can.


This allows me to possibly answer the questions above and create new ones
(a clever reader may notice I understand much more now than when I started
writing this message).

+ Squid uses a self-defense mechanisms which allows to do two things:
  1. Use a fresh connection for non-retriable transactions, minimizing the
possibility of using a connection which may be in the process of being
closed.
  2. Control the number of open connections so it doesn't go out of bounds.
This is a little redundant because `ServiceRep::putConnection()` is already
taken care of that.
+ I am working with payloads that have more than 64K in size, which makes
me fall in the conditions stated above.
+ I am not sure if it needs finer control, but the fact that is closing
connections in advance seems dangerous.
+ It also seems dangerous to me this protection mechanism given the fact
that opening/closing TCP connections everytime can become a bottleneck.

So, and this is the final question, I promise:

I disabled the call to `theIdleConns->closeN(1);` and it seems to work
well.
The pool doesn't go out of bounds because the connection is closed inside
`ServiceRep::putConnection()` whenever `ServiceRep::excessConnections()`
returns true.

Do you think there would be any issues with this change?


Thanks in advance

Juan



On Fri, May 12, 2017 at 11:08 AM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 05/11/2017 07:30 PM, Amos Jeffries wrote:
>
> > Requests which are not retriable are not able to be re-sent [...]
> > As such those requests need a new TCP connection to be opened to
> > guarantee the absence of immediate closure. When they complete with
> > their transaction it gets added to the pool for other traffic to use if
> > they can.
>
> The above is accurate, including the snipped parts documenting the
> rationale. BTW, since HTTP and ICAP share the same basic connection
> persistency model, you may find more information reading about these
> general problems in HTTP-related documents.
>
>
> > As far as I know RESPMOD transactions should all be retriable unless the
> > body payload length is unknown at the HTTP level (lack of Content-Length
> > header).
>
> This is inaccurate. A REQMOD or RESPMOD transaction is deemed retriable
> at the time when a connection is chosen/open if:
>
> * Squid can send a preview or
> * Squid can buffer the entire HTTP message body.
>
> The "known length" aspect affects the second bullet, but that bullet
> covers more cases than just messages with Content-Length. And there may
> be more conditions in the code than the bullets cover -- I have not
> checked.
>
>
> > They can also become non-retriable when the response from the ICAP
> > server has been received by Squid and already started delivery to the
> > HTTP client.
>
> This is accurate (including the snipped part about the irrelevance to
> the connection choice).
>
>
> HTH,
>
> Alex.
>
>


-- 
Juan
:wq
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170512/56b48745/attachment.htm>

From rousskov at measurement-factory.com  Fri May 12 21:29:46 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 12 May 2017 15:29:46 -0600
Subject: [squid-users] ICAP Persistent Connections vs Retries (with code
 review)
In-Reply-To: <CAEK0aNvx7oRuP7yqaS-ar2aFRThvTs7TahBfV0Ef8eF-VLs3QA@mail.gmail.com>
References: <CAEK0aNvmxU1h_Tj-Qu46NO2fSvZhRcKtpPmSkar+4-vG3BjmbQ@mail.gmail.com>
 <e2c054b0-36af-1b1a-fd1f-48729e975ddd@treenet.co.nz>
 <cfe8696e-e243-2f5c-4646-f830bbafe4ad@measurement-factory.com>
 <CAEK0aNvx7oRuP7yqaS-ar2aFRThvTs7TahBfV0Ef8eF-VLs3QA@mail.gmail.com>
Message-ID: <b7c09a72-efa9-e8e9-c3d1-c7bc2252b8d7@measurement-factory.com>

On 05/12/2017 01:17 PM, Juan Ram?rez wrote:

> I still don't understand whether it is possible to reuse ICAP
> connections for cases other than retries.

You are implying that idle persistent connections are used for retries.
They are not (or, at least, should not be). Idle persistent connections
are used for new requests that can be retried.

I am deleting most of my carefully written answers and skipping most of
your email until the place where you discovered problems without your
earlier statements/questions :-(.


> * Why does the size of the payload affect the way connections are reused

Because to resend the request, Squid has to have the payload to send.
Thus, to resend a 10GB request, Squid has to buffer a 10GB request.
Squid does not want to do that for, hopefully, obvious reasons.


> * Does Squid need a finer control on this matter in order to ensure
> connection reusability is not affected by the size of the payload?

No. Connection reusability is affected by the size of the payload. It is
the unavoidable consequence of combining finite memory with potentially
infinite response sizes.


> I understand much more now than when I started writing this message.

FWIW, you would save some of us a lot of time if you do not send
portions that you later (but in the same email!) discovered to be
incorrect or irrelevant. This mailing list is not a blog; somebody may
actually be reading and responding to what you write.


> + I am not sure if it needs finer control, but the fact that is closing
> connections in advance seems dangerous.

There is no danger in a client closing an idle connection.


> + It also seems dangerous to me this protection mechanism given the fact
> that opening/closing TCP connections everytime can become a bottleneck.

There is some performance overhead, but not danger. High quality
optimizations are welcomed.


> I disabled the call to `theIdleConns->closeN(1);` 
> Do you think there would be any issues with this change?

Yes, I do:

* In some environments, your patched Squid is likely to open too many
connections, violating various OS limits and/or admin expectations.

* In some environments, your patched Squid is likely to stop servicing
requests after hitting one of the open connection limits, unable to open
a new connection for an (unretriable) transaction, with a connection
pool full of idle connections.

The code you do not like was added because Squid was experiencing such
problems in some real-world environments (both HTTP and ICAP). It _can_
be improved, and quality patches are welcomed, but it should not be
disabled (in the official version).


HTH,

Alex.



From rousskov at measurement-factory.com  Fri May 12 21:39:37 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 12 May 2017 15:39:37 -0600
Subject: [squid-users] squid sslbump
In-Reply-To: <011b01d2cb5a$18294a20$487bde60$@eleccav.une.cu>
References: <011b01d2cb5a$18294a20$487bde60$@eleccav.une.cu>
Message-ID: <e58314ff-a74b-2752-965d-5fff13709a7d@measurement-factory.com>

On 05/12/2017 01:58 PM, yanier wrote:
> I have the following internet connection scheme

> Proxy (administrator by me) - Proxy Parent - Internet

> I would like to know if I could filter https without having to make
> changes in the parent proxy

A general-purpose parent proxy has no affect on bumping SSL traffic by
the child proxy -- you may ignore such parent proxy existence as far as
modern SslBump is concerned.

It is possible to write a specialized proxy that would detect and resist
some forms of SSL bumping by child proxies, but I speculate that you are
unlikely to deal with such a situation.

Alex.



From dijxie at gmail.com  Fri May 12 21:48:09 2017
From: dijxie at gmail.com (Dijxie)
Date: Fri, 12 May 2017 23:48:09 +0200
Subject: [squid-users] WARNING: All 20/20 negotiateauthenticator
 processes are busy.
In-Reply-To: <1494603034421-4682379.post@n4.nabble.com>
References: <1494516474107-4682362.post@n4.nabble.com>
 <89df3bbf-300e-dcdd-21b2-079ea847662d@gmail.com>
 <1494603034421-4682379.post@n4.nabble.com>
Message-ID: <99bc82bf-324f-0be9-3b55-94842c07f31b@gmail.com>

W dniu 12.05.2017 o 17:30, erdosain9 pisze:
> Hi.
> Thanks!
>
> We have 100 users........... What would you think is a good "auth_param
> negotiate children"??

The one that does not gives you a warning. One of my squids has 12 users 
who can kill 18 helpers and  generate 1.2GB log within one day; it all 
depends on many, many things.

> I cant run squidclient
>
> [root at squid ~]# squidclient mgr:negotiate_authenticator
> ERROR: Cannot connect to [::1]:3128
> [root at squid ~]# squidclient -vv mgr:negotiate_authenticator
> verbosity level set to 2
> Request:
> GET cache_object://localhost/negotiate_authenticator HTTP/1.0
> Host: localhost
> User-Agent: squidclient/3.5.20
> Accept: */*
> Connection: close
>
>
> .
> Transport detected: IPv4-mapped  and IPv6
> Resolving localhost ...
> Connecting... localhost ([::1]:3128)
> ERROR: Cannot connect to [::1]:3128
>
>
> CONFIG
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
>
>
> So??
> Thanks!

My guess is that your config file was only a sample, so:
- Is your squid listening on 3128 TCP? If not, pass -p <port> to squidclient.
- Is there a possibility that cachemgr access is disallowed by some other acl, placed above "http_access allow localhost manager" in config file?


-- 
Greets, Dijx



From mlifshin at phantomdesign.com  Sat May 13 02:33:52 2017
From: mlifshin at phantomdesign.com (Masha Lifshin)
Date: Fri, 12 May 2017 19:33:52 -0700
Subject: [squid-users] Best practices for beefing up security for squid with
	ssl-bump
Message-ID: <CA+8Eki3xf6U8ARnRnC6vewSQoQz2cH4YTegKLsRY7mHjDxwXEQ@mail.gmail.com>

Dear Squid Users list,

I have a Squid 4 configured as explicit proxy with ssl-bump interception.
I am working on making it as secure as possible, given the vulnerability
risks with doing ssl inspection (
https://insights.sei.cmu.edu/cert/2015/03/the-risks-of-ssl-inspection.html).

I am implementing the hardening suggestions at
http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

One other feature I have found is the SSL Server Certificate Validator.  As
far as I understand one can write a helper that performs additional
certificate validation checks that squid doesn't perform out of the box?
Does anyone know of any widely agreed upon open source helpers, or is this
something where people are rolling their own?

Are there other configuration options that can help?  I am curious what
else others in the community are doing along these lines, and if there are
recommended best practices in the squid community?  I appreciate your
insights.

Thank you very much,
-Masha
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170512/72aa786b/attachment.htm>

From squid3 at treenet.co.nz  Sat May 13 12:36:08 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 14 May 2017 00:36:08 +1200
Subject: [squid-users] Best practices for beefing up security for squid
 with ssl-bump
In-Reply-To: <CA+8Eki3xf6U8ARnRnC6vewSQoQz2cH4YTegKLsRY7mHjDxwXEQ@mail.gmail.com>
References: <CA+8Eki3xf6U8ARnRnC6vewSQoQz2cH4YTegKLsRY7mHjDxwXEQ@mail.gmail.com>
Message-ID: <8cb6b527-9348-d7c9-ecab-e2e47072a20c@treenet.co.nz>

On 13/05/17 14:33, Masha Lifshin wrote:
> Dear Squid Users list,
>
> I have a Squid 4 configured as explicit proxy with ssl-bump 
> interception.  I am working on making it as secure as possible, given 
> the vulnerability risks with doing ssl inspection 
> (https://insights.sei.cmu.edu/cert/2015/03/the-risks-of-ssl-inspection.html).
>
> I am implementing the hardening suggestions at 
> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>
> One other feature I have found is the SSL Server Certificate 
> Validator.  As far as I understand one can write a helper that 
> performs additional certificate validation checks that squid doesn't 
> perform out of the box?

Yes. However, do not expect to use it as an alternative to what Squid 
already validates. Disabling validation (eg the DONT_VERIFY_* flags) 
includes disabling use of the helper as well.

>   Does anyone know of any widely agreed upon open source helpers, or 
> is this something where people are rolling their own?

AFAIK this is something a very few people are implementing on their own. 
Squid validates the whole cert chain using the normal OpenSSL library 
mechanisms regardless of this helper, so it is most useful for unusual 
types of checks (eg DANE).

>
> Are there other configuration options that can help?  I am curious 
> what else others in the community are doing along these lines, and if 
> there are recommended best practices in the squid community?  I 
> appreciate your insights.

The features are still under constant development, so best practices are 
almost as volatile as the code. The basics I'm recommending for now are:

0) don't bump. treat it as a last resort.

1) use cert mimic to pass problems on to the client.

2) avoid client-first and equivalent (step1) bumping.

3) follow TLS best practices to harden.


Amos



From rightkicktech at gmail.com  Sat May 13 13:59:54 2017
From: rightkicktech at gmail.com (Abi Askushi)
Date: Sat, 13 May 2017 16:59:54 +0300
Subject: [squid-users] Squid tproxy net unreachable
In-Reply-To: <CABMULtKCcnJvptPLiEQ5crc_4B+FJ3PqZO+-u5WFZqAVC0QdHg@mail.gmail.com>
References: <CABMULtKfn3Efs8=uiSiyzPQYCm2kgwwNp__j8wXV+FeBSONw1g@mail.gmail.com>
 <CABMULt+4P3sO0yv6=tStN1h=_Q6VQ+A6V1Rwy3oLG8nWXvRoQw@mail.gmail.com>
 <CABMULt+C0zW3dXo84D6ZdZFtkVbK-Pp+mVfBfrnQ+-U7QkqJWQ@mail.gmail.com>
 <CABMULtLA3M=oG437EY6AunSP1f8+Yxmw2qvhrxc1u7tLF_Oskg@mail.gmail.com>
 <CABMULt+AULqbiNBpxDmAnmY+YgugRbN6SOu9wXXUWUtuD9rmaw@mail.gmail.com>
 <CABMULtJ79qswod_49NTFJ8PnoDRyVS9F2Sy9p9so+8chHnDbiA@mail.gmail.com>
 <CABMULt+dij9PJRP4mPJEPa6OkajibL1X=qv06gSp7GKLwCbZyg@mail.gmail.com>
 <CABMULtJtmKqO+S5pUF51YKVTB9zCNaPLySvvwVG-Jimf2gXt5g@mail.gmail.com>
 <CABMULt+sK2WjTxpk35EWQPu1-nmcT85aZqtJn8x6qs_A1Kfniw@mail.gmail.com>
 <CABMULtKdH1W5EN_8_s9m_KfZSNyBFYq5WsYw7Qyz32PCmkmmcw@mail.gmail.com>
 <CABMULtLfMLDQ7HMwsu=V06gLJ9e_Rx2oofBO_a2TxxoZSZihaw@mail.gmail.com>
 <CABMULt+_NLz7-8scstCOan-zHTvyzE1n4TQEViGzfba_2FPVrw@mail.gmail.com>
 <CABMULtKBXRgi5OesjvmpT=9UtNND_BdwbdCR58t9BAUuDu0oGg@mail.gmail.com>
 <CABMULtLsWMGKu8+ZnEbrXDsnoQukwfs52eZvLS2A8=0w3Z5ChA@mail.gmail.com>
 <CABMULtKCcnJvptPLiEQ5crc_4B+FJ3PqZO+-u5WFZqAVC0QdHg@mail.gmail.com>
Message-ID: <CABMULtLTqK-gtafw_xuFLMWLosUUhaxG5KR9W97Y+0hA8f7Gyg@mail.gmail.com>

Hi,

I have setup squid (v 3.1.20) with tproxy and relevant iptables and policy
routes. It is functioning ok except one thing, squid is not able to
redirect to deny page (located on same device) and it gives error "101
network unreachable". I have squidguard in the setup as a helper program
and squidguard is doing the redirection to a page on localhost. With squid
in intercept mode this redirection to deny page is ok. I have also disabled
rpfilter in kernel. I may provide more details on configs if needed.

Did anyone encounter this? Any ideas?

Thanx,
Alex
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170513/7f48710b/attachment.htm>

From farrukh_smile05 at yahoo.com  Sun May 14 11:26:03 2017
From: farrukh_smile05 at yahoo.com (farrukh saleem)
Date: Sun, 14 May 2017 11:26:03 +0000 (UTC)
Subject: [squid-users] Linux squid proxy server blocking outlook in my
	network.
References: <929129483.855934.1494761163121.ref@mail.yahoo.com>
Message-ID: <929129483.855934.1494761163121@mail.yahoo.com>

Dear All,
Hello, am using squid proxy server it is working fine with http filtering, but it stop outlook connection when i configure my gmail account, i have tried add outlook ports in acl_safe ports please help us how can i configure outlook using squid proxy server. Thankyou.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170514/a3856daa/attachment.htm>

From squid3 at treenet.co.nz  Sun May 14 12:16:23 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 15 May 2017 00:16:23 +1200
Subject: [squid-users] Squid tproxy net unreachable
In-Reply-To: <CABMULtLTqK-gtafw_xuFLMWLosUUhaxG5KR9W97Y+0hA8f7Gyg@mail.gmail.com>
References: <CABMULtKfn3Efs8=uiSiyzPQYCm2kgwwNp__j8wXV+FeBSONw1g@mail.gmail.com>
 <CABMULtLA3M=oG437EY6AunSP1f8+Yxmw2qvhrxc1u7tLF_Oskg@mail.gmail.com>
 <CABMULt+AULqbiNBpxDmAnmY+YgugRbN6SOu9wXXUWUtuD9rmaw@mail.gmail.com>
 <CABMULtJ79qswod_49NTFJ8PnoDRyVS9F2Sy9p9so+8chHnDbiA@mail.gmail.com>
 <CABMULt+dij9PJRP4mPJEPa6OkajibL1X=qv06gSp7GKLwCbZyg@mail.gmail.com>
 <CABMULtJtmKqO+S5pUF51YKVTB9zCNaPLySvvwVG-Jimf2gXt5g@mail.gmail.com>
 <CABMULt+sK2WjTxpk35EWQPu1-nmcT85aZqtJn8x6qs_A1Kfniw@mail.gmail.com>
 <CABMULtKdH1W5EN_8_s9m_KfZSNyBFYq5WsYw7Qyz32PCmkmmcw@mail.gmail.com>
 <CABMULtLfMLDQ7HMwsu=V06gLJ9e_Rx2oofBO_a2TxxoZSZihaw@mail.gmail.com>
 <CABMULt+_NLz7-8scstCOan-zHTvyzE1n4TQEViGzfba_2FPVrw@mail.gmail.com>
 <CABMULtKBXRgi5OesjvmpT=9UtNND_BdwbdCR58t9BAUuDu0oGg@mail.gmail.com>
 <CABMULtLsWMGKu8+ZnEbrXDsnoQukwfs52eZvLS2A8=0w3Z5ChA@mail.gmail.com>
 <CABMULtKCcnJvptPLiEQ5crc_4B+FJ3PqZO+-u5WFZqAVC0QdHg@mail.gmail.com>
 <CABMULtLTqK-gtafw_xuFLMWLosUUhaxG5KR9W97Y+0hA8f7Gyg@mail.gmail.com>
Message-ID: <e196c3b6-cc54-ab9b-4506-071e07765c84@treenet.co.nz>

On 14/05/17 01:59, Abi Askushi wrote:
> Hi,
>
> I have setup squid (v 3.1.20) with tproxy and relevant iptables and 
> policy routes. It is functioning ok except one thing, squid is not 
> able to redirect to deny page (located on same device) and it gives 
> error "101 network unreachable". I have squidguard in the setup as a 
> helper program and squidguard is doing the redirection to a page on 
> localhost. With squid in intercept mode this redirection to deny page 
> is ok. I have also disabled rpfilter in kernel. I may provide more 
> details on configs if needed.
>
> Did anyone encounter this? Any ideas?
>

It is not possible to use a global IP address (eg the spoofed client IP) 
to connect to any machines lo (localhost) interface.

So Squid is not able to perform TPROXY spoofing to fetch the page your 
SG is *re-writing* (not redirecting) the URL to. If you actually are 
redirecting then the client cannot connect to the web server running in 
*its* localhost interface.


PS. please upgrade, no up to date OS releases I'm aware of still ship 
Squid-3.1.

Amos



From squid3 at treenet.co.nz  Sun May 14 12:18:52 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 15 May 2017 00:18:52 +1200
Subject: [squid-users] Linux squid proxy server blocking outlook in my
 network.
In-Reply-To: <929129483.855934.1494761163121@mail.yahoo.com>
References: <929129483.855934.1494761163121.ref@mail.yahoo.com>
 <929129483.855934.1494761163121@mail.yahoo.com>
Message-ID: <6da73270-36b5-2f7b-1578-2495282de4ea@treenet.co.nz>

On 14/05/17 23:26, farrukh saleem wrote:
> Dear All,
> Hello, am using squid proxy server it is working fine with http 
> filtering, but it stop outlook connection when i configure my gmail 
> account, i have tried add outlook ports in acl_safe ports please help 
> us how can i configure outlook using squid proxy server. Thankyou.

Squid is an HTTP proxy, not an IMAP/POP3/SMTP proxy.

If your outlook is using CONNECT tunnels you also need to adjust the 
SSL_Ports ACL. Any other way of using Squid is dangerous with email and 
can result in serious security issues or broken traffic.

Amos



From eliezer at ngtech.co.il  Sun May 14 19:07:44 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Sun, 14 May 2017 22:07:44 +0300
Subject: [squid-users] ICAP Persistent Connections vs Retries (with code
	review)
Message-ID: <003b01d2cce5$5e33dd00$1a9b9700$@ngtech.co.il>

Hey Juan,

Without delving into ICAP and HTTP semantics you should notice\remember one thing:
Proxies which are performing as an ICAP client should not care about a scenario which a single TCP connection is being used for a single query.
If indeed you find that this scenario, which many connections are being opened and closed towards the ICAP service, affects your service I believe you should rethink things over.
The directions you should think are:
 - Software(OS or Squid or ICAP service)
 - Hardware (CPU, RAM)
 - Network (Network interfaces, Cables Switches)

I can testify that for HTTP content filtering and adaptation there are much more efficient pieces of software out there(which includes internal content adaptation).

With the above in mind you should not really care too much about new TCP connections per request.
If you see some performance degradation in your environment I would recommend your to create a "check list" which will help you to decide what direction you should choose.

All The Bests,
Eliezer

* Let me know if you need some help with the check list or software which you can test.

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Juan Ram?rez
Sent: Friday, May 12, 2017 3:50 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] ICAP Persistent Connections vs Retries (with code review)

Hi,

Mi name is Juan, I am a Software Engineer from Uruguay. I think this message is more suited to the squid-dev mailing list due to the developer-oriented nature of the message but, given that the development list is for people who actually contributes code to Squid, I chose to post here.

I started using Squid a few days ago in order to test its content-adaptation capabilities. The plan was to test the ICAP implementation first and then maybe try the eCAP API as well.

In order to test ICAP, I based my code in the open source PYICAP project, I also ran some tests using the C-ICAP server.

It came to my attention that, even when persistent connections is enabled, Squid closes the ICAP connection everytime a new request arrives, like this:

1. A new request arrives
2. Squid creates a connection to the ICAP server
3. Content is adapted and returned to the client
4. Squid returns the connection to the connection pool
5. A new requests arrives
6. Squid closes the active connection
7. Squid opens a new connection to the ICAP server

Note: I am using only the RESPMOD method.
<<SNIP>>

-- 
Juan
:wq




From harariboy at gmail.com  Sun May 14 21:49:28 2017
From: harariboy at gmail.com (avi_h)
Date: Sun, 14 May 2017 14:49:28 -0700 (PDT)
Subject: [squid-users] Squid to listen to HTTPS
Message-ID: <1494798568853-4682393.post@n4.nabble.com>

Hi,

I'm trying to get squid to listen to HTTPS in order to encrypt the traffic
between the proxy and the user.
I'm running squid 3.5.19 and squid is compiled with the --with-openssl
option which is required for https_port directive.
In order to accomplish that I used the following configuration:

https_port 3129 cert=/etc/squid/certificate.pem
key=/etc/squid/privatekey.pem

However, when I try to connect from the browser using port 3129 I get a
connection refused.
When runnig squid in debug mode I got the following in cache.log:

2017/05/14 21:10:19.854 kid1| 83,2| client_side.cc(3743) Squid_SSL_accept:
Error negotiating SSL connection on FD 7: error:00000005:lib(0):func(0):DH
lib

Please help me understand the reason.
Thanks.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-to-listen-to-HTTPS-tp4682393.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From jkarthur at gmail.com  Sun May 14 22:26:34 2017
From: jkarthur at gmail.com (J Arthur)
Date: Sun, 14 May 2017 18:26:34 -0400
Subject: [squid-users] Use with Gateway to Gateway VPN
Message-ID: <CAJw4dKU9GR9Bvb=6cAmen92eMXSzEnpyMa-nirRTYQtLUJL02g@mail.gmail.com>

Greetings to all,

Here's my situation, I have three locations A, B and C connected by
gateway to gateway vpn using cisco rv320's, A has a network of
192.168.0.0/24, B is 192.168.1.0/24 and C is 192.168.2.0/24

I set up squid on network A and it works for anything that is on
network A,  but from network B or C I can ping the server or browse
network shares other programs that access network resources work but
when I configure the browser with the proxy settings it acts like it
cant reach the squid proxy.

I have acl that allow the three networks so I am wondering if squid
cant work across networks,  or can someone point me in the right
direction.

Thank you


From Antony.Stone at squid.open.source.it  Sun May 14 22:40:25 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sun, 14 May 2017 23:40:25 +0100
Subject: [squid-users] Use with Gateway to Gateway VPN
In-Reply-To: <CAJw4dKU9GR9Bvb=6cAmen92eMXSzEnpyMa-nirRTYQtLUJL02g@mail.gmail.com>
References: <CAJw4dKU9GR9Bvb=6cAmen92eMXSzEnpyMa-nirRTYQtLUJL02g@mail.gmail.com>
Message-ID: <201705142340.25445.Antony.Stone@squid.open.source.it>

On Sunday 14 May 2017 at 23:26:34, J Arthur wrote:

> Greetings to all,
> 
> Here's my situation, I have three locations A, B and C connected by
> gateway to gateway vpn using cisco rv320's, A has a network of
> 192.168.0.0/24, B is 192.168.1.0/24 and C is 192.168.2.0/24
> 
> I set up squid on network A and it works for anything that is on
> network A,  but from network B or C I can ping the server or browse
> network shares other programs that access network resources work but
> when I configure the browser with the proxy settings it acts like it
> cant reach the squid proxy.

"Acts like..."?  What's the exact error message you get in the browser?

Is there any indication of this request coming in on the Squid machine's 
access.log?

Have you used something like wireshark to see whether the requests are 
reaching Squid, and whether it is trying to reply?

Does the Squid server have an appropriate route for getting back to the 
clients on networks B and C?

> I have acl that allow the three networks

Show us how you've written this?

> so I am wondering if squid cant work across networks,  or can someone point
> me in the right direction.

Squid can certainly "work across networks".  This sounds like a routing probem 
to me, not a Squid problem.


Regards,


Antony.

-- 
#define SIX 1+5
#define NINE 8+1

int main() {
    printf("%d\n", SIX * NINE);
}
	- thanks to ECB for bringing this to my attention

                                                   Please reply to the list;
                                                         please *don't* CC me.


From rentorbuy at yahoo.com  Mon May 15 15:53:50 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Mon, 15 May 2017 15:53:50 +0000 (UTC)
Subject: [squid-users] Cannot access https site
References: <1736144500.1917549.1494863630143.ref@mail.yahoo.com>
Message-ID: <1736144500.1917549.1494863630143@mail.yahoo.com>

Hi,



My goal is to set up Squid so it can act as a transparent proxy for local clients browsing the web. It should "deny all" except traffic to the destination domains included in an ACL file.

This is my squid config:

http_port 3129 tproxy
https_port 3130 tproxy ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cert=/etc/ssl/squid/proxyserver.pem

acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range

acl intercepted myportname 3129
acl interceptedssl myportname 3130

acl allowed_domains dstdomain "/usr/local/share/proxy-settings/allowed.domains"

http_access deny intercepted !localnet
http_access deny interceptedssl !localnet
http_access deny !allowed_domains
http_access allow localnet

sslcrtd_program /usr/libexec/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 16MB
sslcrtd_children 10
ssl_bump stare all
ssl_bump bump all
sslproxy_cert_error allow all
always_direct allow all

The ACL file allowed.domains contains:
.squid-cache.org
.stackexchange.com

When a client in localnet tries to access http://www.squid-cache.org, everything works fine, as expected.

However, when the same client tries to access https://stackexchange.com, the first SQUID error page says that access is denied to https://151.101.1.69/* (that's one of stackexchange's IP addresses).
How can I avoid this?

If I add 151.101.1.69 to allowed.domains I get a SQUID SSL handshake error page with https://*.stackexchange.com/* (bad write retry).

What am I doing wrong?

Also, would I have performance issues if the "allowed.domains" ACL file becomes very big over time?

Thanks,

Vieri


From rousskov at measurement-factory.com  Mon May 15 17:25:12 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 15 May 2017 11:25:12 -0600
Subject: [squid-users] Cannot access https site
In-Reply-To: <1736144500.1917549.1494863630143@mail.yahoo.com>
References: <1736144500.1917549.1494863630143.ref@mail.yahoo.com>
 <1736144500.1917549.1494863630143@mail.yahoo.com>
Message-ID: <b4b0357a-9a52-03b0-9332-5969ade0edf8@measurement-factory.com>

On 05/15/2017 09:53 AM, Vieri wrote:

> My goal is to set up Squid so it can act as a transparent proxy for
> local clients browsing the web. It should "deny all" except traffic
> to the destination domains included in an ACL file.

> http_access deny intercepted !localnet
> http_access deny interceptedssl !localnet
> http_access deny !allowed_domains
> http_access allow localnet
...
> ssl_bump stare all
> ssl_bump bump all


> What am I doing wrong?

You are denying fake CONNECT requests during SslBump step1. During that
step, intercepted SSL connections are represented by fake CONNECT
requests with IP addresses (not domain names). Such requests will often
match your "http_access deny !allowed_domains" rule. See "Step 1"
description at http://wiki.squid-cache.org/Features/SslPeekAndSplice

What you probably want is to allow all reasonable fake CONNECT requests
during that step. There are several ways to do that, and I hope others
on the list can help you with that if you cannot figure it out. Please
do not forget to post your Squid version if you need further help (and
use the latest v3.5 or later if you are doing SslBump, regardless of
what your OS packages for you).

Some other configuration aspects are (or may be considered by some)
wrong as well, but it is best to fix one SslBump problem at a time IMHO.


> Also, would I have performance issues if the "allowed.domains" ACL
> file becomes very big over time?

Naturally, the more domains you have, the slower ACL checks become. 1000
domains is not a problem, but 1000 million domains usually is. Define
"very big" and "performance issues".


HTH,

Alex.



From rousskov at measurement-factory.com  Mon May 15 17:33:59 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 15 May 2017 11:33:59 -0600
Subject: [squid-users] Squid to listen to HTTPS
In-Reply-To: <1494798568853-4682393.post@n4.nabble.com>
References: <1494798568853-4682393.post@n4.nabble.com>
Message-ID: <037c2ff9-3985-a7db-36e5-11c1b285a97e@measurement-factory.com>

On 05/14/2017 03:49 PM, avi_h wrote:

> I'm trying to get squid to listen to HTTPS in order to encrypt the traffic
> between the proxy and the user.

> https_port 3129 cert=/etc/squid/certificate.pem key=/etc/squid/privatekey.pem


> However, when I try to connect from the browser using port 3129 I get a
> connection refused.
> When runnig squid in debug mode I got the following in cache.log:
> 
> 2017/05/14 21:10:19.854 kid1| 83,2| client_side.cc(3743) Squid_SSL_accept:
> Error negotiating SSL connection on FD 7: error:00000005:lib(0):func(0):DH
> lib


FYI: The "connection refused" browser error does not seem to match
"Error negotiating SSL connection" Squid error, but perhaps it is just
your browser being a little misleading.


> Please help me understand the reason.

You have configured Squid to be an HTTPS proxy.

Did you configure your browser to use an HTTP proxy instead of an HTTPS
proxy? Some browsers support HTTPS proxies, but it is tricky to enable
that support so I have to ask. HTTP proxies expect plain HTTP requests.
HTTPS proxies expect encrypted HTTP requests.

If you are still having trouble, it may be useful to attach
browser-Squid packet capture when reproducing the problem with
http://www.example.com/ or a similar "trivial" site.

Alex.



From erdosain9 at gmail.com  Mon May 15 18:52:49 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 15 May 2017 11:52:49 -0700 (PDT)
Subject: [squid-users] =?utf-8?b?U2xvdyBzZXJ2ZXIgwr8/?=
Message-ID: <1494874369830-4682400.post@n4.nabble.com>

Hi.
Can somebody tell why the squid server it's going slow???

top - 15:05:21 up  3:52,  1 user,  load average: 0,93, 2,15, 10,85
Tasks: 186 total,   1 running, 185 sleeping,   0 stopped,   0 zombie
%Cpu(s):  1,7 us,  0,5 sy,  0,0 ni, 97,2 id,  0,7 wa,  0,0 hi,  0,0 si,  0,0
st
KiB Mem :  3882708 total,   110044 free,  1934236 used,  1838428 buff/cache
KiB Swap:  2097148 total,  2087324 free,     9824 used.  1646000 avail Mem 

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     
 2142 squid     20   0 1127580 0,977g   9244 S   3,7 26,4  65:15.76 squid       
 2171 squid     20   0   52788   3404   2292 S   0,7  0,1  10:54.76
negotiate_+ 
  939 clamscan  20   0 1437976 553640   9036 S   0,3 14,3   2:03.58 clamd       
    1 root      20   0   41148   3156   2368 S   0,0  0,1   0:01.56 systemd     
    2 root      20   0       0      0      0 S   0,0  0,0   0:00.00 kthreadd    
    3 root      20   0       0      0      0 S   0,0  0,0   0:00.23
ksoftirqd/0 
    7 root      rt   0       0      0      0 S   0,0  0,0   0:00.32
migration/0 
    8 root      20   0       0      0      0 S   0,0  0,0   0:00.00 rcu_bh      
    9 root      20   0       0      0      0 S   0,0  0,0   0:00.00 rcuob/0     
   10 root      20   0       0      0      0 S   0,0  0,0   0:00.00 rcuob/1     
   11 root      20   0       0      0      0 S   0,0  0,0   0:26.01
rcu_sched   
   12 root      20   0       0      0      0 S   0,0  0,0   0:12.05 rcuos/0     
   13 root      20   0       0      0      0 S   0,0  0,0   0:25.08 rcuos/1     
   14 root      rt   0       0      0      0 S   0,0  0,0   0:00.05
watchdog/0  
   15 root      rt   0       0      0      0 S   0,0  0,0   0:00.05
watchdog/1  
   16 root      rt   0       0      0      0 S   0,0  0,0   0:00.00
migration/1 
   17 root      20   0       0      0      0 S   0,0  0,0   0:04.11
ksoftirqd/1 

Config file
*-----------------------------------------------------------------------------------------**


####GRUPOS DE IP
acl sin_autenticacion src "/etc/squid/listas/sin_autenticacion.lst"
acl red6 src 192.168.6.0/24

###Kerberos Auth with ActiveDirectory###
auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -s
HTTP/squid.xxxxxxx.lan at xxxxxxx.LAN
auth_param negotiate children 35 startup=0 idle=1
auth_param negotiate keep_alive off


external_acl_type i-full %LOGIN /usr/lib64/squid/ext_kerberos_ldap_group_acl
-g i-full at xxxxxxx.LAN
external_acl_type i-limitado %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-limitado at xxxxxxx.LAN
external_acl_type i-sinlimite %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-sinlimite at xxxxxxx.LAN


#GRUPOS
acl i-full external i-full
acl i-limitado external i-limitado
acl i-sinlimite external i-sinlimite

####Bloquea Publicidad ( http://pgl.yoyo.org/adservers/ )
acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
http_access deny ads


####Streaming
acl youtube url_regex -i \.flv$
acl youtube url_regex -i \.mp4$
acl youtube url_regex -i watch?
acl youtube url_regex -i youtube
acl facebook url_regex -i facebook
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.jpg)\? 
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.jpg)\?

##Dominios denegados
acl dominios_denegados dstdomain "/etc/squid/listas/dominios_denegados.lst"

##Extensiones bloqueadas
acl multimedia urlpath_regex "/etc/squid/listas/multimedia.lst"

##Extensiones peligrosas
acl peligrosos urlpath_regex "/etc/squid/listas/peligrosos.lst"


#Puertos
acl SSL_ports port 443
acl SSL_ports port 8443
acl SSL_ports port 8080
acl SSL_ports port 20000
acl SSL_ports port 10000
acl SSL_ports port 2083

acl Safe_ports port 631         # httpCUPS
acl Safe_ports port 85
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 8443        # httpsalt
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 8080        # edesur y otros
acl Safe_ports port 2199	# radio
acl CONNECT method CONNECT


#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localhost
http_access allow i-sinlimite
http_access allow sin_autenticacion
http_access allow i-limitado #!dominios_denegados
http_access allow i-full #!dominios_denegados

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.1.215:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=5MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pem 

acl step1 at_step SslBump1 

acl excludeSSL ssl::server_name_regex "/etc/squid/listas/excluidosSSL.lst"

ssl_bump peek step1 
ssl_bump splice excludeSSL 
ssl_bump bump all 


# Uncomment and adjust the following to add a disk cache directory.
cache_dir diskd /var/spool/squid 15000 16 256
cache_mem 256 MB

cache_swap_low 90
cache_swap_high 95

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid


#Your refresh_pattern
refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
ignore-private

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320

###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
via off
forwarded_for delete
###

#Pools para ancho de banda
delay_pools 5

#Ancho de Youtube
delay_class 1 2 
delay_parameters 1 1000000/1000000 50000/512000
delay_access 1 allow i-limitado youtube !facebook
delay_access 1 deny all

#Ancho de Facebook
delay_class 2 2 
delay_parameters 2 1000000/1000000 50000/512000
delay_access 2 allow i-limitado facebook !youtube
delay_access 2 deny all

#Ancho de banda YOUTUBE FULL
delay_class 3 1
delay_parameters 3 1000000/1000000
delay_access 3 allow i-full youtube !facebook
delay_access 3 deny all

#Ancho de banda LIMITADO
delay_class 4 3 
delay_parameters 4 3000000/3000000 1000000/1000000 256000/512000
delay_access 4 allow i-limitado !youtube !facebook
delay_access 4 deny all

#Ancho de banda FULL
delay_class 5 3
delay_parameters 5 1500000/1500000 750000/750000 256000/512000
delay_access 5 allow i-full !youtube !facebook
delay_access 5 deny all

dns_nameservers 192.168.1.200 8.8.8.8
#dns_nameservers 8.8.8.8 8.8.4.4
visible_hostname squid.xxxxxxx.lan

# try connecting to first 25 ips of a domain name
forward_max_tries 25

# fix some ipv6 errors (recommended to comment out) 
dns_v4_first on

# c-icap integration
# -------------------------------------
# Adaptation parameters
# -------------------------------------
icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024
icap_service service_avi_req reqmod_precache
icap://127.0.0.1:1344/squidclamav bypass=on
adaptation_access service_avi_req allow all
icap_service service_avi_resp respmod_precache
icap://127.0.0.1:1344/squidclamav bypass=off
adaptation_access service_avi_resp allow all
# end integration





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Slow-server-tp4682400.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Mon May 15 18:53:09 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 15 May 2017 11:53:09 -0700 (PDT)
Subject: [squid-users] WARNING: All 20/20 negotiateauthenticator
	processes are busy.
In-Reply-To: <99bc82bf-324f-0be9-3b55-94842c07f31b@gmail.com>
References: <1494516474107-4682362.post@n4.nabble.com>
 <89df3bbf-300e-dcdd-21b2-079ea847662d@gmail.com>
 <1494603034421-4682379.post@n4.nabble.com>
 <99bc82bf-324f-0be9-3b55-94842c07f31b@gmail.com>
Message-ID: <1494874389106-4682401.post@n4.nabble.com>

Hi.
this is my config file 


####GRUPOS DE IP
acl sin_autenticacion src "/etc/squid/listas/sin_autenticacion.lst"
acl red6 src 192.168.6.0/24

###Kerberos Auth with ActiveDirectory###
auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -s
HTTP/squid.xxxxxxx.lan at xxxxxxx.LAN
auth_param negotiate children 35 startup=0 idle=1
auth_param negotiate keep_alive off


external_acl_type i-full %LOGIN /usr/lib64/squid/ext_kerberos_ldap_group_acl
-g i-full at xxxxxxx.LAN
external_acl_type i-limitado %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-limitado at xxxxxxx.LAN
external_acl_type i-sinlimite %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-sinlimite at xxxxxxx.LAN


#GRUPOS
acl i-full external i-full
acl i-limitado external i-limitado
acl i-sinlimite external i-sinlimite

####Bloquea Publicidad ( http://pgl.yoyo.org/adservers/ )
acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
http_access deny ads


####Streaming
acl youtube url_regex -i \.flv$
acl youtube url_regex -i \.mp4$
acl youtube url_regex -i watch?
acl youtube url_regex -i youtube
acl facebook url_regex -i facebook
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.jpg)\? 
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.jpg)\?

##Dominios denegados
acl dominios_denegados dstdomain "/etc/squid/listas/dominios_denegados.lst"

##Extensiones bloqueadas
acl multimedia urlpath_regex "/etc/squid/listas/multimedia.lst"

##Extensiones peligrosas
acl peligrosos urlpath_regex "/etc/squid/listas/peligrosos.lst"


#Puertos
acl SSL_ports port 443
acl SSL_ports port 8443
acl SSL_ports port 8080
acl SSL_ports port 20000
acl SSL_ports port 10000
acl SSL_ports port 2083

acl Safe_ports port 631         # httpCUPS
acl Safe_ports port 85
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 8443        # httpsalt
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 8080        # edesur y otros
acl Safe_ports port 2199	# radio
acl CONNECT method CONNECT


#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localhost
http_access allow i-sinlimite
http_access allow sin_autenticacion
http_access allow i-limitado #!dominios_denegados
http_access allow i-full #!dominios_denegados

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.1.215:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=5MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pem 

acl step1 at_step SslBump1 

acl excludeSSL ssl::server_name_regex "/etc/squid/listas/excluidosSSL.lst"

ssl_bump peek step1 
ssl_bump splice excludeSSL 
ssl_bump bump all 


# Uncomment and adjust the following to add a disk cache directory.
cache_dir diskd /var/spool/squid 15000 16 256
cache_mem 256 MB

cache_swap_low 90
cache_swap_high 95

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid


#Your refresh_pattern
refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
ignore-private

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320

###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
via off
forwarded_for delete
###

#Pools para ancho de banda
delay_pools 5

#Ancho de Youtube
delay_class 1 2 
delay_parameters 1 1000000/1000000 50000/512000
delay_access 1 allow i-limitado youtube !facebook
delay_access 1 deny all

#Ancho de Facebook
delay_class 2 2 
delay_parameters 2 1000000/1000000 50000/512000
delay_access 2 allow i-limitado facebook !youtube
delay_access 2 deny all

#Ancho de banda YOUTUBE FULL
delay_class 3 1
delay_parameters 3 1000000/1000000
delay_access 3 allow i-full youtube !facebook
delay_access 3 deny all

#Ancho de banda LIMITADO
delay_class 4 3 
delay_parameters 4 3000000/3000000 1000000/1000000 256000/512000
delay_access 4 allow i-limitado !youtube !facebook
delay_access 4 deny all

#Ancho de banda FULL
delay_class 5 3
delay_parameters 5 1500000/1500000 750000/750000 256000/512000
delay_access 5 allow i-full !youtube !facebook
delay_access 5 deny all

dns_nameservers 192.168.1.200 8.8.8.8
#dns_nameservers 8.8.8.8 8.8.4.4
visible_hostname squid.xxxxxxx.lan

# try connecting to first 25 ips of a domain name
forward_max_tries 25

# fix some ipv6 errors (recommended to comment out) 
dns_v4_first on

# c-icap integration
# -------------------------------------
# Adaptation parameters
# -------------------------------------
icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024
icap_service service_avi_req reqmod_precache
icap://127.0.0.1:1344/squidclamav bypass=on
adaptation_access service_avi_req allow all
icap_service service_avi_resp respmod_precache
icap://127.0.0.1:1344/squidclamav bypass=off
adaptation_access service_avi_resp allow all
# end integration



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/WARNING-All-20-20-negotiateauthenticator-processes-are-busy-tp4682362p4682401.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From harariboy at gmail.com  Mon May 15 19:56:12 2017
From: harariboy at gmail.com (avi_h)
Date: Mon, 15 May 2017 12:56:12 -0700 (PDT)
Subject: [squid-users] Squid to listen to HTTPS
In-Reply-To: <037c2ff9-3985-a7db-36e5-11c1b285a97e@measurement-factory.com>
References: <1494798568853-4682393.post@n4.nabble.com>
 <037c2ff9-3985-a7db-36e5-11c1b285a97e@measurement-factory.com>
Message-ID: <1494878172214-4682402.post@n4.nabble.com>

Hi Alex,

I figured out the issue was with the browser after consulting with a
colleague.
I couldn't find any browser add-on that works in order to test this so I had
a tester built just for that.
With the tester I was able to use the HTTPS proxy with no issues.
Thanks for your reply.

Regards,
Avi




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-to-listen-to-HTTPS-tp4682393p4682402.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Mon May 15 23:59:58 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 15 May 2017 17:59:58 -0600
Subject: [squid-users] Squid to listen to HTTPS
In-Reply-To: <1494878172214-4682402.post@n4.nabble.com>
References: <1494798568853-4682393.post@n4.nabble.com>
 <037c2ff9-3985-a7db-36e5-11c1b285a97e@measurement-factory.com>
 <1494878172214-4682402.post@n4.nabble.com>
Message-ID: <26967745-5e1d-84f0-7cce-4e163f86fdd7@measurement-factory.com>

On 05/15/2017 01:56 PM, avi_h wrote:

> I couldn't find any browser add-on that works in order to test this so I had
> a tester built just for that.

FYI: Modern Curl releases support HTTPS proxies. Some popular browsers
support them too (without any add-ons!), but you need PAC files or other
tricks to configure that browser feature properly.

Alex.



From eliezer at ngtech.co.il  Tue May 16 00:11:38 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Tue, 16 May 2017 03:11:38 +0300
Subject: [squid-users] destination ip to splice
Message-ID: <02a401d2cdd8$fcafb7d0$f60f2770$@ngtech.co.il>

I have a scenario which I want to disable ssl-bump for specific hosts ip
network masks.
In this scenario I want to allow all localnet(10.0.0.0/8, 192.168.0.0/16...)
https traffic to be spliced.
I tried to understand from the acl docs if there is such acl out there but
couldn't understand if it exists.
I am using squid in this scenario as a simple forward proxy and not in
intercept mode.
>From the next:
***** ACL TYPES AVAILABLE *****

	acl aclname src ip-address/mask ...	# clients IP address [fast]
	acl aclname src addr1-addr2/mask ...	# range of addresses [fast]
	acl aclname dst [-n] ip-address/mask ...	# URL host's IP
address [slow]
	acl aclname localip ip-address/mask ... # IP address the client
connected to [fast]

Is there a specific one that can help me with that or I should use
ssl::server_name_regex :
(^127\.0\.0\.1)|(^192\.168)|(^10\.)|(^172\.1[6-9])|(^172\.2[0-9])|(^172\.3[0
-1])

??

In intercept mode I can just use iptables to bypass the interception but in
a forward proxy mode I do not see another option.
This might not be the place but, would ever maybe such an option to bypass
squid parsing for specific destinations ie "splice" for special http
requests?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il






From rousskov at measurement-factory.com  Tue May 16 00:31:10 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 15 May 2017 18:31:10 -0600
Subject: [squid-users] destination ip to splice
In-Reply-To: <02a401d2cdd8$fcafb7d0$f60f2770$@ngtech.co.il>
References: <02a401d2cdd8$fcafb7d0$f60f2770$@ngtech.co.il>
Message-ID: <0d99b3ea-3c58-419b-f09f-2836955a3254@measurement-factory.com>

On 05/15/2017 06:11 PM, Eliezer  Croitoru wrote:
> I want to [match] all localnet(10.0.0.0/8, 192.168.0.0/16...)

How about something like this, adapted from the existing localnet ACL
definition in squid.conf.documented?

>   acl to_localnet dst 0.0.0.1-0.255.255.255  # RFC 1122 "this" network (LAN)
>   acl to_localnet dst 10.0.0.0/8         # RFC 1918 local private network (LAN)
>   acl to_localnet dst 100.64.0.0/10      # RFC 6598 shared address space (CGN)
>   acl to_localnet dst 169.254.0.0/16     # RFC 3927 link-local (directly plugged)
>   acl to_localnet dst 172.16.0.0/12      # RFC 1918 local private network (LAN)
>   acl to_localnet dst 192.168.0.0/16     # RFC 1918 local private network (LAN)
>   acl to_localnet dst fc00::/7           # RFC 4193 local private network range
>   acl to_localnet dst fe80::/10          # RFC 4291 link-local (directly plugged) 

Alex.



From eliezer at ngtech.co.il  Tue May 16 00:40:01 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Tue, 16 May 2017 03:40:01 +0300
Subject: [squid-users] destination ip to splice
In-Reply-To: <0d99b3ea-3c58-419b-f09f-2836955a3254@measurement-factory.com>
References: <02a401d2cdd8$fcafb7d0$f60f2770$@ngtech.co.il>
 <0d99b3ea-3c58-419b-f09f-2836955a3254@measurement-factory.com>
Message-ID: <02a601d2cddc$f3d334d0$db799e70$@ngtech.co.il>

I tried this with splice but it just doesn't work the requests are still being bumped.
>From the docs I understand that it should work on the URL destination hostname and not the ip of the destination hostname.
So my assumption is that it's not in the tcp socket level but the http hostname url-hostname level.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: Alex Rousskov [mailto:rousskov at measurement-factory.com] 
Sent: Tuesday, May 16, 2017 3:31 AM
To: Eliezer Croitoru <eliezer at ngtech.co.il>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] destination ip to splice

On 05/15/2017 06:11 PM, Eliezer  Croitoru wrote:
> I want to [match] all localnet(10.0.0.0/8, 192.168.0.0/16...)

How about something like this, adapted from the existing localnet ACL
definition in squid.conf.documented?

>   acl to_localnet dst 0.0.0.1-0.255.255.255  # RFC 1122 "this" network (LAN)
>   acl to_localnet dst 10.0.0.0/8         # RFC 1918 local private network (LAN)
>   acl to_localnet dst 100.64.0.0/10      # RFC 6598 shared address space (CGN)
>   acl to_localnet dst 169.254.0.0/16     # RFC 3927 link-local (directly plugged)
>   acl to_localnet dst 172.16.0.0/12      # RFC 1918 local private network (LAN)
>   acl to_localnet dst 192.168.0.0/16     # RFC 1918 local private network (LAN)
>   acl to_localnet dst fc00::/7           # RFC 4193 local private network range
>   acl to_localnet dst fe80::/10          # RFC 4291 link-local (directly plugged) 

Alex.




From dijxie at gmail.com  Tue May 16 00:54:11 2017
From: dijxie at gmail.com (Dijxie)
Date: Tue, 16 May 2017 02:54:11 +0200
Subject: [squid-users] WARNING: All 20/20 negotiateauthenticator
 processes are busy.
In-Reply-To: <1494874389106-4682401.post@n4.nabble.com>
References: <1494516474107-4682362.post@n4.nabble.com>
 <89df3bbf-300e-dcdd-21b2-079ea847662d@gmail.com>
 <1494603034421-4682379.post@n4.nabble.com>
 <99bc82bf-324f-0be9-3b55-94842c07f31b@gmail.com>
 <1494874389106-4682401.post@n4.nabble.com>
Message-ID: <ae663996-50b8-f68b-ad8e-9557fa8a95f7@gmail.com>

On 2017-05-15 20:53, erdosain9 wrote:
> http_port 192.168.1.215:3128

Hi,

My guess is since you've declared it this way (I never did), you should 
try consequently:
squidclient -h 192.168.1.215 -p 3128 mgr:negotiateauthenticator
-h stands for host; running squidclient without this parameter makes it 
use loopback (127.0.0.1) I think. Since you've declared "http_port 
192.168.1.215:3128", you've bound squid to this IP address only and my 
guess is that you're not allowed to use loopback
http://www.squid-cache.org/Doc/config/http_port/

But there is a directive then in your conf:
http_access allow localhost manager
http_access deny manager
you may not be able to connect to manager using 192.168.1.215 either, 
since it is not localhost - but I'm not sure.  If so, my way is:

acl MGR-ALLOWED src "/etc/squid/mgr-allowed.hosts"
http_access allow MGR-ALLOWED manager
and put 192.168.1.215 or/and any other host allowed to use cachemgr to 
/etc/squid/mgr-allowed.hosts file

Good luck this time.

-- 
Greets, Dijx


From eliezer at ngtech.co.il  Tue May 16 01:04:26 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Tue, 16 May 2017 04:04:26 +0300
Subject: [squid-users] Experimental YouTube Caching helper\tool and SQUID
	3.5.25 + 4.0.19 RPM's RELEASED
Message-ID: <02aa01d2cde0$5cf2cc70$16d86550$@ngtech.co.il>

Hey List,

I have been working a while ago on a tool(ICAP service) that will do the
next:
- Snatch YouTube main video pages(watch?...) on the fly
- Fetch them
- Parse them
- Find the key to predict the ID of the X.googlevideo.com/Y which will match
the YouTube video
- Store the key with the correlated video ID in a redis DB for an hour
- Then a StoreID helper will analyze X.googlevideo.com/Y urls and will try
to see if it finds the matching a YouTube video by the ID on the redis DB

The concept is kind of "divide and conquer" while later if I will have time
there will be an option to combine these two things into one ICAP service
that will help to cache YouTube videos and probably also Windows Updates
using squid.

Currently the ICAP service code will not be published but the binaries and
the resources which I have used to create the tool will be published.
(Something like the ingredients without the recipe due to this task being
considered a caching master level and not just any novice)
However my email is wide open for questions requests and tips for anyone
that wishes to get answers, directions and guidance.

@Alex, What will encourage you to help with an improved patch to add ICAP
X-StoreID (or else) response header capability that will help me to write a
complete StoreID solution based on ICAP alone?

@Others, if you are interested in this solution publication please respond
to this thread and CC to me.

Thanks,
Eliezer

* I have released Squid-Cache 3.5.25 and 4.0.19 RPMS but Life takes more of
my time and as I get busy I didn't have enough time to publish the article
like in the past.
The article topic is "ENCRYPTION, HOW FAR WILL YOU GO?" at
[http://www1.ngtech.co.il/wpe/?p=430]

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



From eliezer at ngtech.co.il  Tue May 16 01:29:25 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Tue, 16 May 2017 04:29:25 +0300
Subject: [squid-users] WARNING: All 20/20
	negotiateauthenticator	processes are busy.
In-Reply-To: <1494874389106-4682401.post@n4.nabble.com>
References: <1494516474107-4682362.post@n4.nabble.com>
 <89df3bbf-300e-dcdd-21b2-079ea847662d@gmail.com>
 <1494603034421-4682379.post@n4.nabble.com>
 <99bc82bf-324f-0be9-3b55-94842c07f31b@gmail.com>
 <1494874389106-4682401.post@n4.nabble.com>
Message-ID: <02ad01d2cde3$daec1160$90c43420$@ngtech.co.il>

To allow access to the squid manager info pages just add:
http_port 127.0.0.1:3128

And then you can use squidclient to get some info and statistics on your squid using the manager interface.
I can recommend you to use the next instead of squidclient:
curl http://127.0.0.1:3128/ squid-internal-mgr/menu
curl http://127.0.0.1:3128/ squid-internal-mgr/info

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Monday, May 15, 2017 9:53 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] WARNING: All 20/20 negotiateauthenticator processes are busy.

Hi.
this is my config file 


####GRUPOS DE IP
acl sin_autenticacion src "/etc/squid/listas/sin_autenticacion.lst"
acl red6 src 192.168.6.0/24

###Kerberos Auth with ActiveDirectory###
auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -s
HTTP/squid.xxxxxxx.lan at xxxxxxx.LAN
auth_param negotiate children 35 startup=0 idle=1
auth_param negotiate keep_alive off


external_acl_type i-full %LOGIN /usr/lib64/squid/ext_kerberos_ldap_group_acl
-g i-full at xxxxxxx.LAN
external_acl_type i-limitado %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-limitado at xxxxxxx.LAN
external_acl_type i-sinlimite %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-sinlimite at xxxxxxx.LAN


#GRUPOS
acl i-full external i-full
acl i-limitado external i-limitado
acl i-sinlimite external i-sinlimite

####Bloquea Publicidad ( http://pgl.yoyo.org/adservers/ )
acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
http_access deny ads


####Streaming
acl youtube url_regex -i \.flv$
acl youtube url_regex -i \.mp4$
acl youtube url_regex -i watch?
acl youtube url_regex -i youtube
acl facebook url_regex -i facebook
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.jpg)\? 
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.jpg)\?

##Dominios denegados
acl dominios_denegados dstdomain "/etc/squid/listas/dominios_denegados.lst"

##Extensiones bloqueadas
acl multimedia urlpath_regex "/etc/squid/listas/multimedia.lst"

##Extensiones peligrosas
acl peligrosos urlpath_regex "/etc/squid/listas/peligrosos.lst"


#Puertos
acl SSL_ports port 443
acl SSL_ports port 8443
acl SSL_ports port 8080
acl SSL_ports port 20000
acl SSL_ports port 10000
acl SSL_ports port 2083

acl Safe_ports port 631         # httpCUPS
acl Safe_ports port 85
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 8443        # httpsalt
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 8080        # edesur y otros
acl Safe_ports port 2199	# radio
acl CONNECT method CONNECT


#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localhost
http_access allow i-sinlimite
http_access allow sin_autenticacion
http_access allow i-limitado #!dominios_denegados
http_access allow i-full #!dominios_denegados

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.1.215:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=5MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pem 

acl step1 at_step SslBump1 

acl excludeSSL ssl::server_name_regex "/etc/squid/listas/excluidosSSL.lst"

ssl_bump peek step1 
ssl_bump splice excludeSSL 
ssl_bump bump all 


# Uncomment and adjust the following to add a disk cache directory.
cache_dir diskd /var/spool/squid 15000 16 256
cache_mem 256 MB

cache_swap_low 90
cache_swap_high 95

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid


#Your refresh_pattern
refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
ignore-private

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320

###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
via off
forwarded_for delete
###

#Pools para ancho de banda
delay_pools 5

#Ancho de Youtube
delay_class 1 2 
delay_parameters 1 1000000/1000000 50000/512000
delay_access 1 allow i-limitado youtube !facebook
delay_access 1 deny all

#Ancho de Facebook
delay_class 2 2 
delay_parameters 2 1000000/1000000 50000/512000
delay_access 2 allow i-limitado facebook !youtube
delay_access 2 deny all

#Ancho de banda YOUTUBE FULL
delay_class 3 1
delay_parameters 3 1000000/1000000
delay_access 3 allow i-full youtube !facebook
delay_access 3 deny all

#Ancho de banda LIMITADO
delay_class 4 3 
delay_parameters 4 3000000/3000000 1000000/1000000 256000/512000
delay_access 4 allow i-limitado !youtube !facebook
delay_access 4 deny all

#Ancho de banda FULL
delay_class 5 3
delay_parameters 5 1500000/1500000 750000/750000 256000/512000
delay_access 5 allow i-full !youtube !facebook
delay_access 5 deny all

dns_nameservers 192.168.1.200 8.8.8.8
#dns_nameservers 8.8.8.8 8.8.4.4
visible_hostname squid.xxxxxxx.lan

# try connecting to first 25 ips of a domain name
forward_max_tries 25

# fix some ipv6 errors (recommended to comment out) 
dns_v4_first on

# c-icap integration
# -------------------------------------
# Adaptation parameters
# -------------------------------------
icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024
icap_service service_avi_req reqmod_precache
icap://127.0.0.1:1344/squidclamav bypass=on
adaptation_access service_avi_req allow all
icap_service service_avi_resp respmod_precache
icap://127.0.0.1:1344/squidclamav bypass=off
adaptation_access service_avi_resp allow all
# end integration



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/WARNING-All-20-20-negotiateauthenticator-processes-are-busy-tp4682362p4682401.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Tue May 16 01:51:50 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 15 May 2017 19:51:50 -0600
Subject: [squid-users] destination ip to splice
In-Reply-To: <02a601d2cddc$f3d334d0$db799e70$@ngtech.co.il>
References: <02a401d2cdd8$fcafb7d0$f60f2770$@ngtech.co.il>
 <0d99b3ea-3c58-419b-f09f-2836955a3254@measurement-factory.com>
 <02a601d2cddc$f3d334d0$db799e70$@ngtech.co.il>
Message-ID: <8143c269-aa76-ab62-fa89-b148f027a8a6@measurement-factory.com>

On 05/15/2017 06:40 PM, Eliezer  Croitoru wrote:
> I tried this with splice but it just doesn't work the requests are still being bumped.

Do you know exactly why they are being bumped? Check the debugging logs
if you do not.


> From the docs I understand that it should work on the URL destination hostname
> and not the ip of the destination hostname.

The dst ACL works on IPs (including, when necessary and allowed, on IPs
obtained from resolved domain names). In a forward-proxy configuration,
those IPs or domains are extracted from the URL. In an ssl_bump context,
that URL comes from the CONNECT request target.


> So my assumption is that it's not in the tcp socket level but the
> http hostname url-hostname level.

What is the exact CONNECT request URL when your dst ACL is being
evaluated in your ssl_bump test case? Does the ACL match? Attach the
corresponding debugging log snippet.

Alex.


> -----Original Message-----
> From: Alex Rousskov [mailto:rousskov at measurement-factory.com] 
> Sent: Tuesday, May 16, 2017 3:31 AM
> To: Eliezer Croitoru <eliezer at ngtech.co.il>; squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] destination ip to splice
> 
> On 05/15/2017 06:11 PM, Eliezer  Croitoru wrote:
>> I want to [match] all localnet(10.0.0.0/8, 192.168.0.0/16...)
> 
> How about something like this, adapted from the existing localnet ACL
> definition in squid.conf.documented?
> 
>>   acl to_localnet dst 0.0.0.1-0.255.255.255  # RFC 1122 "this" network (LAN)
>>   acl to_localnet dst 10.0.0.0/8         # RFC 1918 local private network (LAN)
>>   acl to_localnet dst 100.64.0.0/10      # RFC 6598 shared address space (CGN)
>>   acl to_localnet dst 169.254.0.0/16     # RFC 3927 link-local (directly plugged)
>>   acl to_localnet dst 172.16.0.0/12      # RFC 1918 local private network (LAN)
>>   acl to_localnet dst 192.168.0.0/16     # RFC 1918 local private network (LAN)
>>   acl to_localnet dst fc00::/7           # RFC 4193 local private network range
>>   acl to_localnet dst fe80::/10          # RFC 4291 link-local (directly plugged) 
> 
> Alex.
> 



From rousskov at measurement-factory.com  Tue May 16 01:58:01 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 15 May 2017 19:58:01 -0600
Subject: [squid-users] Experimental YouTube Caching helper\tool and
 SQUID 3.5.25 + 4.0.19 RPM's RELEASED
In-Reply-To: <02aa01d2cde0$5cf2cc70$16d86550$@ngtech.co.il>
References: <02aa01d2cde0$5cf2cc70$16d86550$@ngtech.co.il>
Message-ID: <e4516be6-006d-ae64-d4d7-efd78f80b541@measurement-factory.com>

On 05/15/2017 07:04 PM, Eliezer  Croitoru wrote:

> @Alex, What will encourage you to help with an improved patch to add ICAP
> X-StoreID (or else) response header capability

A submission of a high-quality patch would encourage me to review it.
Unfortunately, I do not have the free cycles necessary for actually
writing code together if that is what you meant.

Alex.



From squid3 at treenet.co.nz  Tue May 16 06:00:32 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 16 May 2017 18:00:32 +1200
Subject: [squid-users] =?utf-8?b?U2xvdyBzZXJ2ZXIgwr8/?=
In-Reply-To: <1494874369830-4682400.post@n4.nabble.com>
References: <1494874369830-4682400.post@n4.nabble.com>
Message-ID: <03a6452f-8480-eeda-0c9a-0de7e78c43f6@treenet.co.nz>

On 16/05/17 06:52, erdosain9 wrote:
> Hi.
> Can somebody tell why the squid server it's going slow???

Please define "slow".

Amos



From squid3 at treenet.co.nz  Tue May 16 06:08:33 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 16 May 2017 18:08:33 +1200
Subject: [squid-users] WARNING: All 20/20 negotiateauthenticator
 processes are busy.
In-Reply-To: <ae663996-50b8-f68b-ad8e-9557fa8a95f7@gmail.com>
References: <1494516474107-4682362.post@n4.nabble.com>
 <89df3bbf-300e-dcdd-21b2-079ea847662d@gmail.com>
 <1494603034421-4682379.post@n4.nabble.com>
 <99bc82bf-324f-0be9-3b55-94842c07f31b@gmail.com>
 <1494874389106-4682401.post@n4.nabble.com>
 <ae663996-50b8-f68b-ad8e-9557fa8a95f7@gmail.com>
Message-ID: <efd8d8a0-b676-ed13-f220-27bda75c39c1@treenet.co.nz>

On 16/05/17 12:54, Dijxie wrote:
> On 2017-05-15 20:53, erdosain9 wrote:
>> http_port 192.168.1.215:3128
>
> Hi,
>
> My guess is since you've declared it this way (I never did), you 
> should try consequently:
> squidclient -h 192.168.1.215 -p 3128 mgr:negotiateauthenticator
> -h stands for host; running squidclient without this parameter makes 
> it use loopback (127.0.0.1) I think. Since you've declared "http_port 
> 192.168.1.215:3128", you've bound squid to this IP address only and my 
> guess is that you're not allowed to use loopback
> http://www.squid-cache.org/Doc/config/http_port/
>
> But there is a directive then in your conf:
> http_access allow localhost manager
> http_access deny manager
> you may not be able to connect to manager using 192.168.1.215 either, 
> since it is not localhost - but I'm not sure.


For the record the above is completely correct on all points.

Thanks Dijxie :-)

Amos


From rentorbuy at yahoo.com  Tue May 16 07:54:07 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Tue, 16 May 2017 07:54:07 +0000 (UTC)
Subject: [squid-users] Cannot access https site
In-Reply-To: <b4b0357a-9a52-03b0-9332-5969ade0edf8@measurement-factory.com>
References: <1736144500.1917549.1494863630143.ref@mail.yahoo.com>
 <1736144500.1917549.1494863630143@mail.yahoo.com>
 <b4b0357a-9a52-03b0-9332-5969ade0edf8@measurement-factory.com>
Message-ID: <737683166.333060.1494921247721@mail.yahoo.com>


________________________________
> From: Alex Rousskov <rousskov at measurement-factory.com>
>> My goal is to set up Squid so it can act as a transparent proxy for
>> local clients browsing the web. It should "deny all" except traffic
>> to the destination domains included in an ACL file.
>>
>> http_access deny intercepted !localnet
>> http_access deny interceptedssl !localnet
>> http_access deny !allowed_domains
>> http_access allow localnet
> ...
>> ssl_bump stare all
>> ssl_bump bump all
>
> You are denying fake CONNECT requests during SslBump step1. During that

> step, intercepted SSL connections are represented by fake CONNECT> requests with IP addresses (not domain names). Such requests will often

> match your "http_access deny !allowed_domains" rule. See "Step 1"> description at http://wiki.squid-cache.org/Features/SslPeekAndSplice
> 
> What you probably want is to allow all reasonable fake CONNECT requests

> during that step. There are several ways to do that

Hi,

Thanks for the explanation. I'm posting the whole squid.conf below as I wrongly left out some information in my first post. Sorry.
I didn't think I would have issues with CONNECT to 443 ports because I already had the default "http_access deny CONNECT !SSL_ports".
However, the ACL parsing doesn't stop there and goes on until it reaches "http_access deny !allowed_domains".
So I added the following explicit "allow" right before "deny":
http_access allow CONNECT SSL_ports
http_access deny !allowed_domains

So here's the full config:

# grep -v "^#" squid.conf | grep -v "^$"
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 901         # SWAT
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
include /etc/squid/squid.custom.rules
http_access allow localhost
http_access deny all
coredump_dir /var/cache/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

# grep -v "^#" squid.custom.rules | grep -v "^$"
http_port 3128
http_port 3129 tproxy
https_port 3130 tproxy ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cert=/etc/ssl/squid/proxyserver.pem
external_acl_type nt_group ttl=0 children-max=10 %LOGIN /usr/libexec/squid/ext_wbinfo_group_acl -K
auth_param negotiate program /usr/libexec/squid/negotiate_kerberos_auth -s HTTP/proxy.mydomain.org at MYDOMAIN.ORG
auth_param negotiate children 60
auth_param negotiate keep_alive on
auth_param basic realm ORG proxy
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl ORG_all proxy_auth REQUIRED
acl explicit myportname 3128
acl intercepted myportname 3129
acl interceptedssl myportname 3130
acl interceptednormal myportname 3131
acl interceptedsslnormal myportname 3132
acl allowed_ips src "/usr/local/share/proxy-settings/allowed.ips"
acl allowed_groups external nt_group "/usr/local/share/proxy-settings/allowed.groups"
acl denied_domains dstdomain "/usr/local/share/proxy-settings/denied.domains"
acl allowed_domains dstdomain "/usr/local/share/proxy-settings/allowed.domains"
acl denied_ads url_regex "/usr/local/share/proxy-settings/denied.ads"
acl denied_filetypes urlpath_regex -i "/usr/local/share/proxy-settings/denied.filetypes"
acl restricted_ips src "/usr/local/share/proxy-settings/restricted.ips"
acl restricted_groups external nt_group "/usr/local/share/proxy-settings/restricted.groups"
acl restricted_domains dstdomain "/usr/local/share/proxy-settings/restricted.domains"
http_access deny restricted_ips !restricted_domains
http_access deny restricted_groups !restricted_domains
http_access deny denied_domains !allowed_groups !allowed_ips
http_access deny CONNECT denied_domains !allowed_groups !allowed_ips
http_access deny denied_ads !allowed_groups !allowed_ips
http_access deny denied_filetypes !allowed_groups !allowed_ips
http_access deny explicit !ORG_all
http_access deny intercepted !localnet
http_access deny interceptedssl !localnet
http_access deny interceptedsslnormal !localnet
http_access deny interceptednormal !localnet
http_access allow CONNECT SSL_ports
http_access deny !allowed_domains
cache_mgr it at mydomain.org
email_err_data on
error_directory /usr/share/squid/errors/ORG
append_domain .mydomain.org
http_access allow localnet
sslcrtd_program /usr/libexec/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 16MB
sslcrtd_children 10
ssl_bump stare all
ssl_bump bump all
sslproxy_cert_error allow all
always_direct allow all
icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_encode off
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024
icap_service squidclamav respmod_precache bypass=0 icap://127.0.0.1:1344/clamav
adaptation_access squidclamav allow all
include /etc/squid/squid.custom.common
include /etc/squid/squid.custom.hide
cache_dir diskd /var/cache/squid 100 16 256

# grep -v "^#" squid.custom.hide | grep -v "^$"
httpd_suppress_version_string on
dns_v4_first on
via off
forwarded_for off
request_header_access Allow allow all
request_header_access Authorization allow all
request_header_access WWW-Authenticate allow all
request_header_access Proxy-Authorization allow all
request_header_access Proxy-Authenticate allow all
request_header_access Cache-Control allow all
request_header_access Content-Encoding allow all
request_header_access Content-Length allow all
request_header_access Content-Type allow all
request_header_access Date allow all
request_header_access Expires allow all
request_header_access Host allow all
request_header_access If-Modified-Since allow all
request_header_access Last-Modified allow all
request_header_access Location allow all
request_header_access Pragma allow all
request_header_access Accept allow all
request_header_access Accept-Charset allow all
request_header_access Accept-Encoding allow all
request_header_access Accept-Language allow all
request_header_access Content-Language allow all
request_header_access Mime-Version allow all
request_header_access Retry-After allow all
request_header_access Title allow all
request_header_access Connection allow all
request_header_access Proxy-Connection allow all
request_header_access User-Agent allow all
request_header_access Cookie allow all
request_header_access All deny all

So this setup is a mixed explicit/transparent proxy. Right now, I'm just trying to focus on the transparent part only.
The goal is to allow http/https traffic to allowed_domains only and to force content analysis via ICAP (clamav) of both http and https content.

The above config now seems to work and I can access sites listed in allowed_domains only. I just hope I got it all cleared out.

BTW I've seen the example at http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit where it suggests to use:

acl step1 at_step SslBump1
ssl_bump peek step1

Should I be using that instead of "ssl_bump stare all"?

Which "other configuration aspects are wrong", as you say?

Are you referring to "sslproxy_cert_error allow all" or are there more?

# squid -version
Squid Cache: Version 3.5.14
Service Name: squid
configure options:  '--prefix=/usr' '--build=i686-pc-linux-gnu' '--host=i686-pc-linux-gnu' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--datadir=/usr/share' '--sysconfdir=/etc' '--localstatedir=/var/lib' '--disable-dependency-tracking' '--disable-silent-rules' '--libdir=/usr/lib' '--sysconfdir=/etc/squid' '--libexecdir=/usr/libexec/squid' '--localstatedir=/var' '--with-pidfile=/run/squid.pid' '--datadir=/usr/share/squid' '--with-logdir=/var/log/squid' '--with-default-user=squid' '--enable-removal-policies=lru,heap' '--enable-storeio=aufs,diskd,rock,ufs' '--enable-disk-io' '--enable-auth-basic=MSNT-multi-domain,NCSA,POP3,getpwnam,SMB,LDAP,PAM,RADIUS' '--enable-auth-digest=file,LDAP,eDirectory' '--enable-auth-ntlm=smb_lm' '--enable-auth-negotiate=kerberos,wrapper' '--enable-external-acl-helpers=file_userip,session,unix_group,wbinfo_group,LDAP_group,eDirectory_userip,kerberos_ldap_group' '--enable-log-daemon-helpers' '--enable-url-rewrite-helpers' '--enable-cache-digests' '--enable-delay-pools' '--enable-eui' '--enable-icmp' '--enable-follow-x-forwarded-for' '--with-large-files' '--disable-strict-error-checking' '--disable-arch-native' '--with-ltdl-includedir=/usr/include' '--with-ltdl-libdir=/usr/lib' '--with-libcap' '--enable-ipv6' '--disable-snmp' '--with-openssl' '--with-nettle' '--with-gnutls' '--enable-ssl-crtd' '--disable-ecap' '--disable-esi' '--enable-htcp' '--enable-wccp' '--enable-wccpv2' '--enable-linux-netfilter' '--with-mit-krb5' '--without-heimdal-krb5' 'build_alias=i686-pc-linux-gnu' 'host_alias=i686-pc-linux-gnu' 'CC=i686-pc-linux-gnu-gcc' 'CFLAGS=-O2 -march=i686 -pipe' 'LDFLAGS=-Wl,-O1 -Wl,--as-needed' 'CXXFLAGS=-O2 -march=i686 -pipe' 'PKG_CONFIG_PATH=/usr/lib/pkgconfig'

Thanks,

Vieri


From squid3 at treenet.co.nz  Tue May 16 13:14:45 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 17 May 2017 01:14:45 +1200
Subject: [squid-users] Cannot access https site
In-Reply-To: <737683166.333060.1494921247721@mail.yahoo.com>
References: <1736144500.1917549.1494863630143.ref@mail.yahoo.com>
 <1736144500.1917549.1494863630143@mail.yahoo.com>
 <b4b0357a-9a52-03b0-9332-5969ade0edf8@measurement-factory.com>
 <737683166.333060.1494921247721@mail.yahoo.com>
Message-ID: <b4b54e8a-6bd8-8d00-38e5-c76d4cb00208@treenet.co.nz>

On 16/05/17 19:54, Vieri wrote:
>
> Which "other configuration aspects are wrong", as you say? Are you 
> referring to "sslproxy_cert_error allow all" or are there more?

The "always_direct allow all" is wrong, you do not have cache_peer, and 
if you did why would you prohibit using any of them for *all* traffic ?

That "sslproxy_cert_error allow all" is the default, so useless to 
configure - but not exactly wrong, just a waste of CPU and memory 
setting up ACLs only to do nothing.

In a similar topic many of the request_header_access rules are checking 
for non-request headers. (eg. Title, WWW-Authenticate) or headers which 
are not relayed (eg. all the Proxy-* ones).

> # squid -version Squid Cache: Version 3.5.14


On 16/05/17 05:25, Alex Rousskov wrote:
>
> (and use the latest v3.5 or later if you are doing SslBump, regardless 
> of what your OS packages for you).

The current release is 3.5.25 or 4.0.19. A lot has changed in the last 
year in terms of both TLS practices and how SSL-Bump works to fit with 
those.


Amos



From eliezer at ngtech.co.il  Tue May 16 13:34:20 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Tue, 16 May 2017 16:34:20 +0300
Subject: [squid-users] Experimental YouTube Caching helper\tool and
	SQUID 3.5.25 + 4.0.19 RPM's RELEASED
In-Reply-To: <e4516be6-006d-ae64-d4d7-efd78f80b541@measurement-factory.com>
References: <02aa01d2cde0$5cf2cc70$16d86550$@ngtech.co.il>
 <e4516be6-006d-ae64-d4d7-efd78f80b541@measurement-factory.com>
Message-ID: <03b401d2ce49$1fedd360$5fc97a20$@ngtech.co.il>

What I meant was that the patch that exists in the Bugzilla(http://bugs.squid-cache.org/show_bug.cgi?id=4332) can be polished to be tested on 3.5.25
(I didn?t managed to patch my sources with it due to some lack of knowledge, experience and time)

If you do not have enough free time then the current solution will be required to have:
- ICAP server
- StoreID helper
- Redis DB

Or I can write a dedicated proxy like the one I wrote for Windows Updates but since SSL is involved I believe that the right choice would be to use ICAP and StoreID.

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: Alex Rousskov [mailto:rousskov at measurement-factory.com] 
Sent: Tuesday, May 16, 2017 4:58 AM
To: Eliezer Croitoru <eliezer at ngtech.co.il>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Experimental YouTube Caching helper\tool and SQUID 3.5.25 + 4.0.19 RPM's RELEASED

On 05/15/2017 07:04 PM, Eliezer  Croitoru wrote:

> @Alex, What will encourage you to help with an improved patch to add ICAP
> X-StoreID (or else) response header capability

A submission of a high-quality patch would encourage me to review it.
Unfortunately, I do not have the free cycles necessary for actually
writing code together if that is what you meant.

Alex.




From rightkicktech at gmail.com  Tue May 16 13:53:05 2017
From: rightkicktech at gmail.com (Abi Askushi)
Date: Tue, 16 May 2017 16:53:05 +0300
Subject: [squid-users] Squid tproxy net unreachable
In-Reply-To: <e196c3b6-cc54-ab9b-4506-071e07765c84@treenet.co.nz>
References: <CABMULtKfn3Efs8=uiSiyzPQYCm2kgwwNp__j8wXV+FeBSONw1g@mail.gmail.com>
 <CABMULtLA3M=oG437EY6AunSP1f8+Yxmw2qvhrxc1u7tLF_Oskg@mail.gmail.com>
 <CABMULt+AULqbiNBpxDmAnmY+YgugRbN6SOu9wXXUWUtuD9rmaw@mail.gmail.com>
 <CABMULtJ79qswod_49NTFJ8PnoDRyVS9F2Sy9p9so+8chHnDbiA@mail.gmail.com>
 <CABMULt+dij9PJRP4mPJEPa6OkajibL1X=qv06gSp7GKLwCbZyg@mail.gmail.com>
 <CABMULtJtmKqO+S5pUF51YKVTB9zCNaPLySvvwVG-Jimf2gXt5g@mail.gmail.com>
 <CABMULt+sK2WjTxpk35EWQPu1-nmcT85aZqtJn8x6qs_A1Kfniw@mail.gmail.com>
 <CABMULtKdH1W5EN_8_s9m_KfZSNyBFYq5WsYw7Qyz32PCmkmmcw@mail.gmail.com>
 <CABMULtLfMLDQ7HMwsu=V06gLJ9e_Rx2oofBO_a2TxxoZSZihaw@mail.gmail.com>
 <CABMULt+_NLz7-8scstCOan-zHTvyzE1n4TQEViGzfba_2FPVrw@mail.gmail.com>
 <CABMULtKBXRgi5OesjvmpT=9UtNND_BdwbdCR58t9BAUuDu0oGg@mail.gmail.com>
 <CABMULtLsWMGKu8+ZnEbrXDsnoQukwfs52eZvLS2A8=0w3Z5ChA@mail.gmail.com>
 <CABMULtKCcnJvptPLiEQ5crc_4B+FJ3PqZO+-u5WFZqAVC0QdHg@mail.gmail.com>
 <CABMULtLTqK-gtafw_xuFLMWLosUUhaxG5KR9W97Y+0hA8f7Gyg@mail.gmail.com>
 <e196c3b6-cc54-ab9b-4506-071e07765c84@treenet.co.nz>
Message-ID: <CABMULtKfJAS=OswJqx-Y+X6px8FGbcPc9aN0iysNn--0AkDVUg@mail.gmail.com>

Thank you Amos.

I have the following at squidguard:

    default {
        pass     !porn !adv !drugs !custom any
        redirect http://localhost:10080/error.php
    }

Which when squid in intercept mode the user is "redirected" to error page.
I'm not sure if squidguard is rewriting or redirecting.
With squid in tproxy mode the user gets the squid error page "The Requested
URL cannot be retrieved: network unreachable 101 ... "

I did replace this squid error page with my custom and it can be displayed
to user, though this means that I will not be able to discern connections
errors from deny errors.
I would prefer not to do this dirty trick and have a more clean approach.
Attempts to resolve it through routing table hacks were not successful
also.






On Sun, May 14, 2017 at 3:16 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 14/05/17 01:59, Abi Askushi wrote:
>
>> Hi,
>>
>> I have setup squid (v 3.1.20) with tproxy and relevant iptables and
>> policy routes. It is functioning ok except one thing, squid is not able to
>> redirect to deny page (located on same device) and it gives error "101
>> network unreachable". I have squidguard in the setup as a helper program
>> and squidguard is doing the redirection to a page on localhost. With squid
>> in intercept mode this redirection to deny page is ok. I have also disabled
>> rpfilter in kernel. I may provide more details on configs if needed.
>>
>> Did anyone encounter this? Any ideas?
>>
>>
> It is not possible to use a global IP address (eg the spoofed client IP)
> to connect to any machines lo (localhost) interface.
>
> So Squid is not able to perform TPROXY spoofing to fetch the page your SG
> is *re-writing* (not redirecting) the URL to. If you actually are
> redirecting then the client cannot connect to the web server running in
> *its* localhost interface.
>
>
> PS. please upgrade, no up to date OS releases I'm aware of still ship
> Squid-3.1.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170516/0b627a9b/attachment.htm>

From rousskov at measurement-factory.com  Tue May 16 15:41:41 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 16 May 2017 09:41:41 -0600
Subject: [squid-users] Experimental YouTube Caching helper\tool and
 SQUID 3.5.25 + 4.0.19 RPM's RELEASED
In-Reply-To: <03b401d2ce49$1fedd360$5fc97a20$@ngtech.co.il>
References: <02aa01d2cde0$5cf2cc70$16d86550$@ngtech.co.il>
 <e4516be6-006d-ae64-d4d7-efd78f80b541@measurement-factory.com>
 <03b401d2ce49$1fedd360$5fc97a20$@ngtech.co.il>
Message-ID: <56735d21-eb8d-c26a-ef0b-98d1ddc9a888@measurement-factory.com>

On 05/16/2017 07:34 AM, Eliezer  Croitoru wrote:

> What I meant was that the patch that exists in the
> Bugzilla(http://bugs.squid-cache.org/show_bug.cgi?id=4332) can be
> polished to be tested on 3.5.25

Ah, that is my patch so it does not need my review or original code
writing. It needs updating and up-porting to Squid v5 (at least). I do
not have free cycles for that work so the usual options apply:

http://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F

Alex.


> -----Original Message-----
> From: Alex Rousskov [mailto:rousskov at measurement-factory.com] 
> Sent: Tuesday, May 16, 2017 4:58 AM
> To: Eliezer Croitoru <eliezer at ngtech.co.il>; squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Experimental YouTube Caching helper\tool and SQUID 3.5.25 + 4.0.19 RPM's RELEASED
> 
> On 05/15/2017 07:04 PM, Eliezer  Croitoru wrote:
> 
>> @Alex, What will encourage you to help with an improved patch to add ICAP
>> X-StoreID (or else) response header capability
> 
> A submission of a high-quality patch would encourage me to review it.
> Unfortunately, I do not have the free cycles necessary for actually
> writing code together if that is what you meant.
> 
> Alex.
> 



From mlifshin at phantomdesign.com  Tue May 16 17:12:05 2017
From: mlifshin at phantomdesign.com (Masha Lifshin)
Date: Tue, 16 May 2017 10:12:05 -0700
Subject: [squid-users] Best practices for beefing up security for squid
 with ssl-bump
In-Reply-To: <8cb6b527-9348-d7c9-ecab-e2e47072a20c@treenet.co.nz>
References: <CA+8Eki3xf6U8ARnRnC6vewSQoQz2cH4YTegKLsRY7mHjDxwXEQ@mail.gmail.com>
 <8cb6b527-9348-d7c9-ecab-e2e47072a20c@treenet.co.nz>
Message-ID: <CA+8Eki2KD83AtrLLPJ+PV1Z=KRw2xadUmWxAq_xeo-ZJoOLf6g@mail.gmail.com>

Dear Amos,

Thank you for these insights.  I appreciate the clarification on Ssl Sever
Cert Validator, and am putting in place your list of basics.

-Masha

On Sat, May 13, 2017 at 5:36 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 13/05/17 14:33, Masha Lifshin wrote:
>
>> Dear Squid Users list,
>>
>> I have a Squid 4 configured as explicit proxy with ssl-bump
>> interception.  I am working on making it as secure as possible, given the
>> vulnerability risks with doing ssl inspection (
>> https://insights.sei.cmu.edu/cert/2015/03/the-risks-of-ssl-
>> inspection.html).
>>
>> I am implementing the hardening suggestions at
>> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>>
>> One other feature I have found is the SSL Server Certificate Validator.
>> As far as I understand one can write a helper that performs additional
>> certificate validation checks that squid doesn't perform out of the box?
>>
>
> Yes. However, do not expect to use it as an alternative to what Squid
> already validates. Disabling validation (eg the DONT_VERIFY_* flags)
> includes disabling use of the helper as well.
>
>   Does anyone know of any widely agreed upon open source helpers, or is
>> this something where people are rolling their own?
>>
>
> AFAIK this is something a very few people are implementing on their own.
> Squid validates the whole cert chain using the normal OpenSSL library
> mechanisms regardless of this helper, so it is most useful for unusual
> types of checks (eg DANE).
>
>
>> Are there other configuration options that can help?  I am curious what
>> else others in the community are doing along these lines, and if there are
>> recommended best practices in the squid community?  I appreciate your
>> insights.
>>
>
> The features are still under constant development, so best practices are
> almost as volatile as the code. The basics I'm recommending for now are:
>
> 0) don't bump. treat it as a last resort.
>
> 1) use cert mimic to pass problems on to the client.
>
> 2) avoid client-first and equivalent (step1) bumping.
>
> 3) follow TLS best practices to harden.
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170516/b331c3c7/attachment.htm>

From jared at iaps.pro  Tue May 16 19:21:23 2017
From: jared at iaps.pro (IAPS Security Services, Ltd.)
Date: Tue, 16 May 2017 14:21:23 -0500
Subject: [squid-users] Squid + IPv6
Message-ID: <119093bb-bd72-b489-c10e-bde7b4e1b64c@iaps.pro>

Greetings All,

First time poster to the list, long time squid user.

I have an issue I've come across and I'm greatful if the community can
suggest ideas here. I've recently deployed squid for Windows from
Diladele (http://squid.diladele.com/) and they said to bring my issue to
the mail list.

Here goes:

Squid requires each individual ip to be put on the network card instead
of being permitted to use a cidr annotation for dedicated ip's. There is
a 128 ip limit for squid by default. This limit can be removed for linux
machines by re-compiling and adjusting the limits. In the ipv6
deployment that I'm trying to create, I need much more than 128 ip's.

There are no instructions, at least none that I could find in a basic
google search, on how to increase this limit on a windows deployment.
With ipv6 ip's I'm setting up individual ipv6's per squid acl's so that
users have access to specific ipv6 proxies. Only issue I have is the 128
ip limit imposed by default. Now when you have access to an ipv6 /29
range 128 usable ip's is a drop in the bucket and I'd need the ability
to have squid to use thousands of ipv6 ip addresses on demand. The first
128 work fine, but when adding the 129th, the entirety of squid
immediately stops working. The acl that I'm using looks like this:

acl ip1 myip 2axx:xxxx:285::1
tcp_outgoing_address 2axx:xxxx:285::1 ip1

acl ip2 myip 2axx:xxxx:285::2
tcp_outgoing_address 2axxxx:xxxx:285::2 ip2

How can I compile squid for windows to get around the 128 ip limit imposed?

-- 
Best Regards,

Jared Twyler


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170516/78bb0ce9/attachment.sig>

From Walter.H at mathemainzel.info  Tue May 16 19:55:51 2017
From: Walter.H at mathemainzel.info (Walter H.)
Date: Tue, 16 May 2017 21:55:51 +0200
Subject: [squid-users] Squid + IPv6
In-Reply-To: <119093bb-bd72-b489-c10e-bde7b4e1b64c@iaps.pro>
References: <119093bb-bd72-b489-c10e-bde7b4e1b64c@iaps.pro>
Message-ID: <591B5947.2010203@mathemainzel.info>

On 16.05.2017 21:21, IAPS Security Services, Ltd. wrote:
> How can I compile squid for windows to get around the 128 ip limit imposed?
>
have you ever tried to give each network interface more than 128 IP 
addresses at a time?


-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170516/e3b23eb9/attachment.bin>

From eliezer at ngtech.co.il  Tue May 16 21:14:28 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Wed, 17 May 2017 00:14:28 +0300
Subject: [squid-users] Squid + IPv6
In-Reply-To: <119093bb-bd72-b489-c10e-bde7b4e1b64c@iaps.pro>
References: <119093bb-bd72-b489-c10e-bde7b4e1b64c@iaps.pro>
Message-ID: <04c301d2ce89$6748a060$35d9e120$@ngtech.co.il>

Hey,
(not sure what?s your first name)

What do you actually need from squid, in words.
Do you need it as a caching proxy?
What functionality is the main business of squid in your scenario?
To give specific users ip addresses the option to use a specific outgoing address?
Do you need\want squid to enforce some policy else then the issue you are having?
If you only need to "load balance'" or decide which outgoing ip will be used for a specific user source IP then there are much more efficient ways to do that these days.
Also when you are talking about "big" number of users with big numbers of connections you need to be more specific about your upper limit.
If you want it to be more then 128 but less the 1024 I would say go with squid and compile it but... when you are talking about 1k+ I would recommend you to rethink your strategy.
If you don't care about SSL-BUMP for example then there are really simple ways to write a simple proxy which will do what you need, you just need the right programmer.

All The Bests,
Eliezer

* I am really not looking for a job to write a proxy.. but just think it's a kind suggestion to redirect into some other directions.

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of IAPS Security Services, Ltd.
Sent: Tuesday, May 16, 2017 10:21 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid + IPv6

Greetings All,

First time poster to the list, long time squid user.

I have an issue I've come across and I'm greatful if the community can
suggest ideas here. I've recently deployed squid for Windows from
Diladele (http://squid.diladele.com/) and they said to bring my issue to
the mail list.

Here goes:

Squid requires each individual ip to be put on the network card instead
of being permitted to use a cidr annotation for dedicated ip's. There is
a 128 ip limit for squid by default. This limit can be removed for linux
machines by re-compiling and adjusting the limits. In the ipv6
deployment that I'm trying to create, I need much more than 128 ip's.

There are no instructions, at least none that I could find in a basic
google search, on how to increase this limit on a windows deployment.
With ipv6 ip's I'm setting up individual ipv6's per squid acl's so that
users have access to specific ipv6 proxies. Only issue I have is the 128
ip limit imposed by default. Now when you have access to an ipv6 /29
range 128 usable ip's is a drop in the bucket and I'd need the ability
to have squid to use thousands of ipv6 ip addresses on demand. The first
128 work fine, but when adding the 129th, the entirety of squid
immediately stops working. The acl that I'm using looks like this:

acl ip1 myip 2axx:xxxx:285::1
tcp_outgoing_address 2axx:xxxx:285::1 ip1

acl ip2 myip 2axx:xxxx:285::2
tcp_outgoing_address 2axxxx:xxxx:285::2 ip2

How can I compile squid for windows to get around the 128 ip limit imposed?

-- 
Best Regards,

Jared Twyler





From jared at iaps.pro  Tue May 16 21:19:47 2017
From: jared at iaps.pro (IAPS Security Services, Ltd.)
Date: Tue, 16 May 2017 16:19:47 -0500
Subject: [squid-users] Squid + IPv6
In-Reply-To: <04c301d2ce89$6748a060$35d9e120$@ngtech.co.il>
References: <119093bb-bd72-b489-c10e-bde7b4e1b64c@iaps.pro>
 <04c301d2ce89$6748a060$35d9e120$@ngtech.co.il>
Message-ID: <42b652f1-3bd6-a3c8-8a3f-821d14c0d0da@iaps.pro>

What I need from squid is the ability to use thousands of ipv6 ip
addresses in normal http mode. I am not concerned about https at this
point. But the original question was how to increase the ip limit of
squid past the 128 ip maximum on a Windows platform. The main purpose is
to assign a specific set of ipv6 proxies to specific users.

Best Regards,

Jared Twyler
On 5/16/2017 4:14 PM, Eliezer  Croitoru wrote:
> Hey,
> (not sure what?s your first name)
> 
> What do you actually need from squid, in words.
> Do you need it as a caching proxy?
> What functionality is the main business of squid in your scenario?
> To give specific users ip addresses the option to use a specific outgoing address?
> Do you need\want squid to enforce some policy else then the issue you are having?
> If you only need to "load balance'" or decide which outgoing ip will be used for a specific user source IP then there are much more efficient ways to do that these days.
> Also when you are talking about "big" number of users with big numbers of connections you need to be more specific about your upper limit.
> If you want it to be more then 128 but less the 1024 I would say go with squid and compile it but... when you are talking about 1k+ I would recommend you to rethink your strategy.
> If you don't care about SSL-BUMP for example then there are really simple ways to write a simple proxy which will do what you need, you just need the right programmer.
> 
> All The Bests,
> Eliezer
> 
> * I am really not looking for a job to write a proxy.. but just think it's a kind suggestion to redirect into some other directions.
> 
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
> 
> 
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of IAPS Security Services, Ltd.
> Sent: Tuesday, May 16, 2017 10:21 PM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Squid + IPv6
> 
> Greetings All,
> 
> First time poster to the list, long time squid user.
> 
> I have an issue I've come across and I'm greatful if the community can
> suggest ideas here. I've recently deployed squid for Windows from
> Diladele (http://squid.diladele.com/) and they said to bring my issue to
> the mail list.
> 
> Here goes:
> 
> Squid requires each individual ip to be put on the network card instead
> of being permitted to use a cidr annotation for dedicated ip's. There is
> a 128 ip limit for squid by default. This limit can be removed for linux
> machines by re-compiling and adjusting the limits. In the ipv6
> deployment that I'm trying to create, I need much more than 128 ip's.
> 
> There are no instructions, at least none that I could find in a basic
> google search, on how to increase this limit on a windows deployment.
> With ipv6 ip's I'm setting up individual ipv6's per squid acl's so that
> users have access to specific ipv6 proxies. Only issue I have is the 128
> ip limit imposed by default. Now when you have access to an ipv6 /29
> range 128 usable ip's is a drop in the bucket and I'd need the ability
> to have squid to use thousands of ipv6 ip addresses on demand. The first
> 128 work fine, but when adding the 129th, the entirety of squid
> immediately stops working. The acl that I'm using looks like this:
> 
> acl ip1 myip 2axx:xxxx:285::1
> tcp_outgoing_address 2axx:xxxx:285::1 ip1
> 
> acl ip2 myip 2axx:xxxx:285::2
> tcp_outgoing_address 2axxxx:xxxx:285::2 ip2
> 
> How can I compile squid for windows to get around the 128 ip limit imposed?
> 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170516/908a3795/attachment.sig>

From eliezer at ngtech.co.il  Tue May 16 22:45:32 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Wed, 17 May 2017 01:45:32 +0300
Subject: [squid-users] Squid + IPv6
In-Reply-To: <42b652f1-3bd6-a3c8-8a3f-821d14c0d0da@iaps.pro>
References: <119093bb-bd72-b489-c10e-bde7b4e1b64c@iaps.pro>
 <04c301d2ce89$6748a060$35d9e120$@ngtech.co.il>
 <42b652f1-3bd6-a3c8-8a3f-821d14c0d0da@iaps.pro>
Message-ID: <04d401d2ce96$1fe84e20$5fb8ea60$@ngtech.co.il>

It's doable but I really recommend to try and run squid on Linux instead of
Windows.
It's very important that you understand that the windows version cannot be
fully supported for your specific need.
Even if you will run a Linux virtual machine ontop of a windows box you will
probably have better results then trying to find a "fix" for the windows
version from this mailing list.

Specifically for the thousands of  IPv6 I believe that you will need a
custom solution either by patching squid for Linux or write the right
software for your needs.

Hope It Helps,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: IAPS Security Services, Ltd. [mailto:jared at iaps.pro] 
Sent: Wednesday, May 17, 2017 12:20 AM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid + IPv6

This is an OpenPGP/MIME signed message (RFC 4880 and 3156)
--E9SVe58D61BPqLwwes7HgAq2DqWH0WJJV
Content-Type: multipart/mixed; boundary="9uXrNjm44vJFPKovTw2oihDfwSCwtM6rd";
 protected-headers="v1"
From: "IAPS Security Services, Ltd." <jared at iaps.pro>
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Message-ID: <42b652f1-3bd6-a3c8-8a3f-821d14c0d0da at iaps.pro>
Subject: Re: [squid-users] Squid + IPv6
References: <119093bb-bd72-b489-c10e-bde7b4e1b64c at iaps.pro>
 <04c301d2ce89$6748a060$35d9e120$@ngtech.co.il>
In-Reply-To: <04c301d2ce89$6748a060$35d9e120$@ngtech.co.il>

--9uXrNjm44vJFPKovTw2oihDfwSCwtM6rd
Content-Type: text/plain; charset=utf-8
Content-Transfer-Encoding: quoted-printable

What I need from squid is the ability to use thousands of ipv6 ip addresses
in normal http mode. I am not concerned about https at this point. But the
original question was how to increase the ip limit of squid past the 128 ip
maximum on a Windows platform. The main purpose is to assign a specific set
of ipv6 proxies to specific users.

Best Regards,

Jared Twyler
On 5/16/2017 4:14 PM, Eliezer  Croitoru wrote:
> Hey,
> (not sure what=E2=80=99s your first name)
>=20
> What do you actually need from squid, in words.
> Do you need it as a caching proxy?
> What functionality is the main business of squid in your scenario?
> To give specific users ip addresses the option to use a specific 
>outgoi=
ng address?
> Do you need\want squid to enforce some policy else then the issue you 
> a=
re having?
> If you only need to "load balance'" or decide which outgoing ip will 
> be=
 used for a specific user source IP then there are much more efficient wa=
ys to do that these days.
> Also when you are talking about "big" number of users with big numbers 
> =
of connections you need to be more specific about your upper limit.
> If you want it to be more then 128 but less the 1024 I would say go 
> wit=
h squid and compile it but... when you are talking about 1k+ I would reco=
mmend you to rethink your strategy.
> If you don't care about SSL-BUMP for example then there are really 
> simp=
le ways to write a simple proxy which will do what you need, you just nee= d
the right programmer.
>=20
> All The Bests,
> Eliezer
>=20
> * I am really not looking for a job to write a proxy.. but just think 
>i=
t's a kind suggestion to redirect into some other directions.
>=20
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>=20
>=20
>=20
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
>On=
 Behalf Of IAPS Security Services, Ltd.
> Sent: Tuesday, May 16, 2017 10:21 PM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Squid + IPv6
>=20
> Greetings All,
>=20
> First time poster to the list, long time squid user.
>=20
> I have an issue I've come across and I'm greatful if the community can  
>suggest ideas here. I've recently deployed squid for Windows from  
>Diladele (http://squid.diladele.com/) and they said to bring my issue 
>t=
o
> the mail list.
>=20
> Here goes:
>=20
> Squid requires each individual ip to be put on the network card 
>instead=

> of being permitted to use a cidr annotation for dedicated ip's. There 
> i=
s
> a 128 ip limit for squid by default. This limit can be removed for 
> linu=
x
> machines by re-compiling and adjusting the limits. In the ipv6  
>deployment that I'm trying to create, I need much more than 128 ip's.
>=20
> There are no instructions, at least none that I could find in a basic  
>google search, on how to increase this limit on a windows deployment.
> With ipv6 ip's I'm setting up individual ipv6's per squid acl's so 
>that=

> users have access to specific ipv6 proxies. Only issue I have is the 
> 12=
8
> ip limit imposed by default. Now when you have access to an ipv6 /29 
> range 128 usable ip's is a drop in the bucket and I'd need the ability 
> to have squid to use thousands of ipv6 ip addresses on demand. The 
> firs=
t
> 128 work fine, but when adding the 129th, the entirety of squid  
>immediately stops working. The acl that I'm using looks like this:
>=20
> acl ip1 myip 2axx:xxxx:285::1
> tcp_outgoing_address 2axx:xxxx:285::1 ip1
>=20
> acl ip2 myip 2axx:xxxx:285::2
> tcp_outgoing_address 2axxxx:xxxx:285::2 ip2
>=20
> How can I compile squid for windows to get around the 128 ip limit 
>impo=
sed?
>=20


--9uXrNjm44vJFPKovTw2oihDfwSCwtM6rd--

--E9SVe58D61BPqLwwes7HgAq2DqWH0WJJV
Content-Type: application/pgp-signature; name="signature.asc"
Content-Description: OpenPGP digital signature
Content-Disposition: attachment; filename="signature.asc"

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQIcBAEBCAAGBQJZG2z0AAoJEHJVw0pF7EnlQK4QAKy+I3fflCY1Z9XXoRoygpg2
d2DBcJ688fXY9xqbonGQ6h46FqNZCSBmViiPhTPt0ebj5sXOdGcjA4o0SK03JW15
8vmlfCd2hDfRFtkkVkqa6muTF3SLvVSPhb48/5AvAI6rDzwRrZWx8UeGH0X9nei1
nUd/wQdCY4V8CTA/ZeJmqF855ZrNzKw0+rb/s/m4Ub+Q8KxyJ/z+ygu9IRyi10Bc
/94IjY+w0vL+fZzZN0FZIloVYNGFyHfu4fHe028jSZ00stwH1zS5M2g6D1A4JI1P
oSbJ/5wkxwX51h7+B70t8pHQIQ/XD9BZ71EvE+jz5ImtnJwOLq5EuTLHZtlzFr6e
lHdWw+Pp6mqIB+IXTuE8iXsTT1J5rullUdpCEtg7+nh9Sp3Z0Q7YdLQrRNF902v8
7qDptx1tIHQ9J9cBchGtsX1wgOKNIG8FH28XSSzfT45x69Z14r7mTSxLeszblcvN
LDzXr+DXLj0N6esOFQGzHM/YCn0A5bAWQinoLO/pmdflxGnbPPTXI4muxkz1E/Mp
Kz60FW3TYPHtYHJ66NKKu8iL7W0Ax+aEkaEuAX5c9e8LL15U1FCOlT7KfeE0WU9+
oPsOCW/eoTrtdWfGzSTShg3A3Plfip5jUpjz4lJl7VDD4v3Ldwcx4oCt4QGwoowC
2zRnoiMu+j+mFwNpGhkQ
=t2dJ
-----END PGP SIGNATURE-----

--E9SVe58D61BPqLwwes7HgAq2DqWH0WJJV--



From squid3 at treenet.co.nz  Wed May 17 01:32:53 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 17 May 2017 13:32:53 +1200
Subject: [squid-users] Squid + IPv6
In-Reply-To: <04d401d2ce96$1fe84e20$5fb8ea60$@ngtech.co.il>
References: <119093bb-bd72-b489-c10e-bde7b4e1b64c@iaps.pro>
 <04c301d2ce89$6748a060$35d9e120$@ngtech.co.il>
 <42b652f1-3bd6-a3c8-8a3f-821d14c0d0da@iaps.pro>
 <04d401d2ce96$1fe84e20$5fb8ea60$@ngtech.co.il>
Message-ID: <7ea22b39-45c6-bd59-ac5c-04de077c8b5b@treenet.co.nz>

Holdup guys. There is no limit on tcp_outgoing_address in Squid.

So Jared;

* what did you mean by "the entirety of squid immediately stops working" 
in your original mail?
   crash? errors? something else?

* what is your Windows system per-process handle limit?


Amos



From style9595 at gmail.com  Wed May 17 02:29:31 2017
From: style9595 at gmail.com (Dominic Kim)
Date: Wed, 17 May 2017 11:29:31 +0900
Subject: [squid-users] I want to get intact response
Message-ID: <CAFEpjOqs3J2SU5FNqvkSj017jmbVtsg6bfS=53F=QtOU+9ER=A@mail.gmail.com>

I am quite a newbie to Squid proxy.

I am using it with default configuration by running this:

docker run --name squid -d --publish 3128:3128 sameersbn/squid:3.3.8-23


When I connect to backend server via squid, if backend server is not ready
yet, squid get connection refused error or other connection error.
But squid always returns 503 service unavailable only.

Is there any option to get intact response(connection refused or failed)
from the backend server via squid?

Thanks in advance.
Dominic
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170517/5b507dab/attachment.htm>

From eliezer at ngtech.co.il  Wed May 17 02:50:53 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Wed, 17 May 2017 05:50:53 +0300
Subject: [squid-users] Experimental YouTube Caching helper\tool and
	SQUID	3.5.25 + 4.0.19 RPM's RELEASED
In-Reply-To: <02aa01d2cde0$5cf2cc70$16d86550$@ngtech.co.il>
References: <02aa01d2cde0$5cf2cc70$16d86550$@ngtech.co.il>
Message-ID: <04f701d2ceb8$66b0e8e0$3412baa0$@ngtech.co.il>

Now I am encountering an issue:
I worked on the ICAP service and it works fine to find and extract the unique identifier for the googlevideo id prediction.
Now I have a working ICAP+StoreID helpers but from an unknown reason it seems that squid find's a match in the cache but still serves the content from the origin server.
What might be causing it?
I tried to run a basic debug but I need some help in the lookup, what to look for?
What might be causing it?
I am attaching "debug_options ALL,1 11,3" output of a request(I am removing the Accept-Enconding from the request, which doesn't seems to affect anything)
Also I am attaching store.log output which shows a release of the object just before it's being swaped out.
What debug_options might help in this scenario? I am kind of clueless since I have not touched the subject for a very long time.

## cache.log
2017/05/17 05:00:23.861 kid1| 11,3| http.cc(1061) persistentConnStatus: local=192.168.89.12:36708 remote=194.90.196.53:443 FD 37 flags=1 eof=0
2017/05/17 05:00:24.351 kid1| 11,2| client_side.cc(2364) parseHttpRequest: HTTP Client local=192.168.89.12:13128 remote=192.168.89.58:61588 FD 89 flags=1
2017/05/17 05:00:24.351 kid1| 11,2| client_side.cc(2365) parseHttpRequest: HTTP Client REQUEST:
---------
GET /videoplayback?sparams=clen%2Cdur%2Cei%2Cgir%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Ckeepalive%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cpl%2Crequiressl%2Csource%2Cupn%2Cexpire&expire=1495008016&ipbits=0&requiressl=yes&keepalive=yes&mt=1494986305&upn=gDVDWK1Q9qM&mime=video%2Fmp4&initcwndbps=892500&pl=20&ei=sK4bWZ6AHMGsW7bJgcgP&clen=68830605&itag=135&gir=yes&mm=31&mn=sn-aigllndd&dur=3835.833&id=o-AOxPmibb2YStmY_Tqj-VR0X40QeAgJtRsH3sB1Ma2WO1&key=yt6&ip=84.95.212.160&lmt=1428485111698865&source=youtube&mv=m&ms=au&alr=yes&ratebypass=yes&signature=C6DF66F0AC390B367375FF487E7FC11CA01BC834.9392D0F984CBCAE83A1FB380BE826C93E8739747&cpn=NowGUcZPl2y4ArWs&c=WEB&cver=1.20170511&range=1029733-2546112&rn=9&rbuf=34495 HTTP/1.1
Host: r15---sn-aigllndd.googlevideo.com
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:53.0) Gecko/20100101 Firefox/53.0
Accept: */*
Accept-Language: en-US,he;q=0.7,en;q=0.3
Accept-Encoding: gzip, deflate, br
Referer: https://www.youtube.com/
Origin: https://www.youtube.com
Connection: keep-alive


----------
2017/05/17 05:00:24.358 kid1| 11,3| http.cc(2274) httpStart: GET http://ytgv.squid.internal/id=X727AYHiNLM&itag=135&range=1029733-2546112
2017/05/17 05:00:24.358 kid1| 11,2| http.cc(2230) sendRequest: HTTP Server local=192.168.89.12:54702 remote=209.85.230.84:443 FD 90 flags=1
2017/05/17 05:00:24.358 kid1| 11,2| http.cc(2231) sendRequest: HTTP Server REQUEST:
---------
GET /videoplayback?sparams=clen%2Cdur%2Cei%2Cgir%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Ckeepalive%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cpl%2Crequiressl%2Csource%2Cupn%2Cexpire&expire=1495008016&ipbits=0&requiressl=yes&keepalive=yes&mt=1494986305&upn=gDVDWK1Q9qM&mime=video%2Fmp4&initcwndbps=892500&pl=20&ei=sK4bWZ6AHMGsW7bJgcgP&clen=68830605&itag=135&gir=yes&mm=31&mn=sn-aigllndd&dur=3835.833&id=o-AOxPmibb2YStmY_Tqj-VR0X40QeAgJtRsH3sB1Ma2WO1&key=yt6&ip=84.95.212.160&lmt=1428485111698865&source=youtube&mv=m&ms=au&alr=yes&ratebypass=yes&signature=C6DF66F0AC390B367375FF487E7FC11CA01BC834.9392D0F984CBCAE83A1FB380BE826C93E8739747&cpn=NowGUcZPl2y4ArWs&c=WEB&cver=1.20170511&range=1029733-2546112&rn=9&rbuf=34495 HTTP/1.1
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:53.0) Gecko/20100101 Firefox/53.0
Accept: */*
Accept-Language: en-US,he;q=0.7,en;q=0.3
Referer: https://www.youtube.com/
Origin: https://www.youtube.com
Host: r15---sn-aigllndd.googlevideo.com
Cache-Control: max-age=4794000
Connection: keep-alive


----------
2017/05/17 05:00:24.436 kid1| ctx: enter level  0: 'http://ytgv.squid.internal/id=X727AYHiNLM&itag=135&range=1029733-2546112'
2017/05/17 05:00:24.436 kid1| 11,3| http.cc(694) processReplyHeader: processReplyHeader: key 'C40AE216D4CE802B5FAE71A34B75A843'
2017/05/17 05:00:24.436 kid1| 11,2| http.cc(735) processReplyHeader: HTTP Server local=192.168.89.12:54702 remote=209.85.230.84:443 FD 90 flags=1
2017/05/17 05:00:24.436 kid1| 11,2| http.cc(736) processReplyHeader: HTTP Server REPLY:
---------
HTTP/1.1 200 OK
Last-Modified: Wed, 08 Apr 2015 09:25:11 GMT
Content-Type: video/mp4
Date: Wed, 17 May 2017 02:00:24 GMT
Expires: Wed, 17 May 2017 02:00:24 GMT
Cache-Control: private, max-age=21292
Accept-Ranges: bytes
Content-Length: 1516380
Connection: keep-alive
Alt-Svc: quic=":443"; ma=2592000
Access-Control-Allow-Origin: https://www.youtube.com
Access-Control-Allow-Credentials: true
Timing-Allow-Origin: https://www.youtube.com
Access-Control-Expose-Headers: Client-Protocol, Content-Length, Content-Type, X-Bandwidth-Est, X-Bandwidth-Est2, X-Bandwidth-App-Limited, X-Bandwidth-Est-App-Limited, X-Bandwidth-Est-Comp, X-Bandwidth-Avg, X-Head-Time-Sec, X-Head-Seqnum, X-Sequence-Num, X-Segment-Lmt, X-Walltime-Ms
X-Content-Type-Options: nosniff
Server: gvs 1.0


----------
2017/05/17 05:00:24.436 kid1| ctx: exit level  0
2017/05/17 05:00:24.436 kid1| 11,3| Client.cc(936) noteAdaptationAclCheckDone: no adapation needed
2017/05/17 05:00:24.436 kid1| ctx: enter level  0: 'http://ytgv.squid.internal/id=X727AYHiNLM&itag=135&range=1029733-2546112'
2017/05/17 05:00:24.436 kid1| 11,3| http.cc(905) haveParsedReplyHeaders: HTTP CODE: 200
2017/05/17 05:00:24.437 kid1| ctx: exit level  0
2017/05/17 05:00:24.437 kid1| 11,2| client_side.cc(1408) sendStartOfMessage: HTTP Client local=192.168.89.12:13128 remote=192.168.89.58:61588 FD 89 flags=1
2017/05/17 05:00:24.437 kid1| 11,2| client_side.cc(1409) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 200 OK
Last-Modified: Wed, 08 Apr 2015 09:25:11 GMT
Content-Type: video/mp4
Date: Wed, 17 May 2017 02:00:24 GMT
Expires: Wed, 17 May 2017 02:00:24 GMT
Cache-Control: private, max-age=21292
Accept-Ranges: bytes
Content-Length: 1516380
Alt-Svc: quic=":443"; ma=2592000
Access-Control-Allow-Origin: https://www.youtube.com
Access-Control-Allow-Credentials: true
Timing-Allow-Origin: https://www.youtube.com
Access-Control-Expose-Headers: Client-Protocol, Content-Length, Content-Type, X-Bandwidth-Est, X-Bandwidth-Est2, X-Bandwidth-App-Limited, X-Bandwidth-Est-App-Limited, X-Bandwidth-Est-Comp, X-Bandwidth-Avg, X-Head-Time-Sec, X-Head-Seqnum, X-Sequence-Num, X-Segment-Lmt, X-Walltime-Ms
X-Content-Type-Options: nosniff
Server: gvs 1.0
X-Cache: MISS from filter
X-Cache-Lookup: HIT from filter:3128
Connection: keep-alive


----------
## End of cache.log

## store.log
1494988764.096 RELEASE 00 000000FC 9F3457302C3C18CC9420F78989501F21   ?         ?         ?         ? ?/? ?/? ? ?
1494988764.180 SWAPOUT 00 000001C8 9F3457302C3C18CC9420F78989501F21  200 1494988764 1425925658 1495009739 audio/webm 414553/414553 GET https://r15---sn-aigllndd.googlevideo.com/videoplayback?clen=76689610&source=youtube&sparams=clen%2Cdur%2Cei%2Cgir%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Ckeepalive%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cpl%2Crequiressl%2Csource%2Cupn%2Cexpire&expire=1495010039&dur=3836.501&ei=l7YbWfjyEdPacseFsOgB&initcwndbps=847500&mt=1494988343&requiressl=yes&ip=84.95.212.160&ms=au&gir=yes&mv=m&pl=20&mime=audio%2Fwebm&id=o-AAyoF-88PGHEqhkC-hBvKEPjiIeUoDi6DohmCQ0WoGs8&mn=sn-aigllndd&mm=31&ipbits=0&itag=251&keepalive=yes&lmt=1425925658208642&key=yt6&upn=JGXkLnd5jwI&alr=yes&ratebypass=yes&signature=7A20E093615AC902AAE33D726AD3F9BE3934DFDD.BDCC662814E40739201EA9EE69D1058F7C74C7A1&cpn=ZWjhgUtxrr_va9Vr&c=WEB&cver=1.20170511&range=8837089-9251641&rn=32&rbuf=352381

1494988783.284 RELEASE 00 000000FD 0436BF4E1A398F3365103BE514907CD5   ?         ?         ?         ? ?/? ?/? ? ?
1494988783.366 SWAPOUT 00 000001C9 0436BF4E1A398F3365103BE514907CD5  200 1494988783 1425925658 1495009739 audio/webm 413087/413087 GET https://r15---sn-aigllndd.googlevideo.com/videoplayback?clen=76689610&source=youtube&sparams=clen%2Cdur%2Cei%2Cgir%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Ckeepalive%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cpl%2Crequiressl%2Csource%2Cupn%2Cexpire&expire=1495010039&dur=3836.501&ei=l7YbWfjyEdPacseFsOgB&initcwndbps=847500&mt=1494988343&requiressl=yes&ip=84.95.212.160&ms=au&gir=yes&mv=m&pl=20&mime=audio%2Fwebm&id=o-AAyoF-88PGHEqhkC-hBvKEPjiIeUoDi6DohmCQ0WoGs8&mn=sn-aigllndd&mm=31&ipbits=0&itag=251&keepalive=yes&lmt=1425925658208642&key=yt6&upn=JGXkLnd5jwI&alr=yes&ratebypass=yes&signature=7A20E093615AC902AAE33D726AD3F9BE3934DFDD.BDCC662814E40739201EA9EE69D1058F7C74C7A1&cpn=ZWjhgUtxrr_va9Vr&c=WEB&cver=1.20170511&range=9251642-9664728&rn=33&rbuf=372381

1494988939.087 RELEASE 00 000001EB 2257A59BCD5457AC526432A31D8C1DAE   ?         ?         ?         ? ?/? ?/? ? ?
1494988939.176 SWAPOUT 00 00000215 2257A59BCD5457AC526432A31D8C1DAE  200 1494988939 1425925658 1495010229 audio/webm 290838/290838 GET https://r15---sn-aigllndd.googlevideo.com/videoplayback?clen=76689610&upn=Ar8EsOEX6u8&source=youtube&expire=1495010529&lmt=1425925658208642&mime=audio%2Fwebm&gir=yes&requiressl=yes&keepalive=yes&id=o-AH3RVksarviuBTrz7-iVa695QDmwgtd25mI2pwtDvNDe&sparams=clen%2Cdur%2Cei%2Cgir%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Ckeepalive%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cpl%2Crequiressl%2Csource%2Cupn%2Cexpire&initcwndbps=822500&ms=au&itag=251&mt=1494988830&dur=3836.501&mv=m&pl=20&mm=31&ipbits=0&mn=sn-aigllndd&key=yt6&ei=gbgbWdf_FtW9cseknvgM&ip=84.95.212.160&alr=yes&ratebypass=yes&signature=7C1C7F0389FF6102FAAFB4F4978E8A2BEAE64D40.596DE1F2DEAD3091CD0B49354E49A42BEE812362&cpn=Xy6NBwdfsknjfruc&c=WEB&cver=1.20170511&range=327790-618627&rn=8&rbuf=16213

1494988940.164 RELEASE 00 00000207 E306D0FF544DCD9B997C189364B9173D   ?         ?         ?         ? ?/? ?/? ? ?
1494988940.493 SWAPOUT 00 0000021B E306D0FF544DCD9B997C189364B9173D  200 1494988940 1428485111 1495010229 video/mp4 1516380/1516380 GET https://r15---sn-aigllndd.googlevideo.com/videoplayback?clen=68830605&upn=Ar8EsOEX6u8&source=youtube&expire=1495010529&lmt=1428485111698865&mime=video%2Fmp4&gir=yes&requiressl=yes&keepalive=yes&id=o-AH3RVksarviuBTrz7-iVa695QDmwgtd25mI2pwtDvNDe&sparams=clen%2Cdur%2Cei%2Cgir%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Ckeepalive%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cpl%2Crequiressl%2Csource%2Cupn%2Cexpire&initcwndbps=822500&ms=au&itag=135&mt=1494988830&dur=3835.833&mv=m&pl=20&mm=31&ipbits=0&mn=sn-aigllndd&key=yt6&ei=gbgbWdf_FtW9cseknvgM&ip=84.95.212.160&alr=yes&ratebypass=yes&signature=B38EC7D16A460518D56AB4AEC2686F8417E4F66D.5C0A937164F499F9951C0AC2ED4E3C1655718B98&cpn=Xy6NBwdfsknjfruc&c=WEB&cver=1.20170511&range=1029733-2546112&rn=10&rbuf=38883
## End of store.log

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eliezer Croitoru
Sent: Tuesday, May 16, 2017 4:04 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Experimental YouTube Caching helper\tool and SQUID 3.5.25 + 4.0.19 RPM's RELEASED

Hey List,

I have been working a while ago on a tool(ICAP service) that will do the
next:
- Snatch YouTube main video pages(watch?...) on the fly
- Fetch them
- Parse them
- Find the key to predict the ID of the X.googlevideo.com/Y which will match the YouTube video
- Store the key with the correlated video ID in a redis DB for an hour
- Then a StoreID helper will analyze X.googlevideo.com/Y urls and will try to see if it finds the matching a YouTube video by the ID on the redis DB

The concept is kind of "divide and conquer" while later if I will have time there will be an option to combine these two things into one ICAP service that will help to cache YouTube videos and probably also Windows Updates using squid.

Currently the ICAP service code will not be published but the binaries and the resources which I have used to create the tool will be published.
(Something like the ingredients without the recipe due to this task being considered a caching master level and not just any novice) However my email is wide open for questions requests and tips for anyone that wishes to get answers, directions and guidance.

@Alex, What will encourage you to help with an improved patch to add ICAP X-StoreID (or else) response header capability that will help me to write a complete StoreID solution based on ICAP alone?

@Others, if you are interested in this solution publication please respond to this thread and CC to me.

Thanks,
Eliezer

* I have released Squid-Cache 3.5.25 and 4.0.19 RPMS but Life takes more of my time and as I get busy I didn't have enough time to publish the article like in the past.
The article topic is "ENCRYPTION, HOW FAR WILL YOU GO?" at [http://www1.ngtech.co.il/wpe/?p=430]

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Wed May 17 03:52:03 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 17 May 2017 15:52:03 +1200
Subject: [squid-users] I want to get intact response
In-Reply-To: <CAFEpjOqs3J2SU5FNqvkSj017jmbVtsg6bfS=53F=QtOU+9ER=A@mail.gmail.com>
References: <CAFEpjOqs3J2SU5FNqvkSj017jmbVtsg6bfS=53F=QtOU+9ER=A@mail.gmail.com>
Message-ID: <cbf43f2c-34e7-461b-a439-429f302078e1@treenet.co.nz>

On 17/05/17 14:29, Dominic Kim wrote:
> I am quite a newbie to Squid proxy.
>
> I am using it with default configuration by running this:
>
> |docker run --name squid -d --publish 3128:3128 sameersbn/squid:3.3.8-23|
>
> When I connect to backend server via squid, if backend server is not 
> ready yet, squid get connection refused error or other connection error.
> But squid always returns 503 service unavailable only.
>
> Is there any option to get intact response(connection refused or 
> failed) from the backend server via squid?

If the backend is producing an HTTP response Squid delivers it. The 
exception being certain HTTP responses that indicate Squid should retry, 
in which case Squid does that retry and whatever happens on that gets 
delivered.

Connection Refused/Failed are control messages from the network 
infrastructure to Squid indicating that TCP SYN failed. There is no 
backend HTTP response when that happens, so Squid itself generates the 
503 to tell the client what happened. But if there are alternative 
servers the request can go to they will be attempted first.


PS. Squid-3.3 is very outdated, please look into upgrading to a 
currently supported release. As of this writing those are 3.5.x or 4.x 
series.

Amos



From squid3 at treenet.co.nz  Wed May 17 04:29:12 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 17 May 2017 16:29:12 +1200
Subject: [squid-users] Experimental YouTube Caching helper\tool and
 SQUID 3.5.25 + 4.0.19 RPM's RELEASED
In-Reply-To: <04f701d2ceb8$66b0e8e0$3412baa0$@ngtech.co.il>
References: <02aa01d2cde0$5cf2cc70$16d86550$@ngtech.co.il>
 <04f701d2ceb8$66b0e8e0$3412baa0$@ngtech.co.il>
Message-ID: <6a5567a8-57be-1f27-a245-4cde7173dc7f@treenet.co.nz>

On 17/05/17 14:50, Eliezer Croitoru wrote:
> Now I am encountering an issue:
> I worked on the ICAP service and it works fine to find and extract the unique identifier for the googlevideo id prediction.
> Now I have a working ICAP+StoreID helpers but from an unknown reason it seems that squid find's a match in the cache but still serves the content from the origin server.
> What might be causing it?

There are three possible reasons visible in the server response:

1) private response
  Cache-Control: private

2) stale response
  Last-Modified: Wed, 08 Apr 2015 09:25:11 GMT
  Cache-Control: max-age=21292

3) stale response
   Date: Wed, 17 May 2017 02:00:24 GMT
   Expires: Wed, 17 May 2017 02:00:24 GM


and another in the Squid backend request:
   Cache-Control: max-age=4794000

That means that either;
  a) the refresh_pattern has been configured to force objects to be 
under 55.4 days to avoid revalidation
OR
  b) the object in cache is 55.4 days old and Squid is seeking an update.

Except there are no If-* headers to indicate revalidation, so probably (a).

In either case the server is responding with an object which is both a 
full-size 200 status, and already over 2 years old:
   Last-Modified: Wed, 08 Apr 2015 09:25:11 GMT
so the new object already cannot meet the freshness requirements before 
it is even delivered to Squid.

Currently Squid caches such responses and uses them in favour of older 
cached content, especially when Store-ID is obscuring the exact URL 
origin of the older content.

Amos



From style9595 at gmail.com  Wed May 17 07:30:42 2017
From: style9595 at gmail.com (Dominic Kim)
Date: Wed, 17 May 2017 16:30:42 +0900
Subject: [squid-users] Retry on connection refused.
Message-ID: <CAFEpjOrpjOpXYdO3bgW7OikunGdosFGThehy7KGNX-VZr52oDg@mail.gmail.com>

Is there any way to make squid retry on connection refused instead of
returning 503 service unavailable immediately?

Thanks in advance.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170517/da4365c8/attachment.htm>

From style9595 at gmail.com  Wed May 17 08:46:08 2017
From: style9595 at gmail.com (Dominic Kim)
Date: Wed, 17 May 2017 17:46:08 +0900
Subject: [squid-users] Retry on connection refused.
In-Reply-To: <CAFEpjOrpjOpXYdO3bgW7OikunGdosFGThehy7KGNX-VZr52oDg@mail.gmail.com>
References: <CAFEpjOrpjOpXYdO3bgW7OikunGdosFGThehy7KGNX-VZr52oDg@mail.gmail.com>
Message-ID: <CAFEpjOqWnx24_z7Vj1hUx3Q=2=xXt_M-LdR-y0jtiR3-fffJ-A@mail.gmail.com>

Precisely, when I send request to backend server, if server does not expose
a target port yet, squid returns with 503 service unavailable.
So I want to make squid retry until port is ready.

With ''connect_retries" option, it is working in case of "No route to host".
But if server exists but port is not ready yet, it does not work.

Thanks regards
Dominic


2017-05-17 16:30 GMT+09:00 Dominic Kim <style9595 at gmail.com>:

> Is there any way to make squid retry on connection refused instead of
> returning 503 service unavailable immediately?
>
> Thanks in advance.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170517/90e81a86/attachment.htm>

From chicago_computers at hotmail.com  Wed May 17 11:32:06 2017
From: chicago_computers at hotmail.com (chcs)
Date: Wed, 17 May 2017 04:32:06 -0700 (PDT)
Subject: [squid-users] Squid custom error page
Message-ID: <1495020726548-4682433.post@n4.nabble.com>

Firefox 53.0.2 , Chrome 58.3029 y Opera 44 display "Proxy Server Refused
Connection" page, instead of Squid custom error page, when connect to HTTPS
site which blocked by proxy server.
For example we try to connect to https://www.something.com via Squid proxy
server which denied with 403 error this connect and send custom error page
with description of problem in older versions it's worked.
I'm using pfSense 2.4 (actual version squid 3.5.24).

Reproducible: Always

Steps to Reproduce:
1. Configure Firefox to use proxy server (SSL Proxy).
2. HTTPS/SSL Interception , Enable SSL filtering, splice all, CA: Let's
Encript autority
3. Try to connect to HTTPS site, which will be blocked by proxy server

Actual Results:  
Firefox will display "Page Load Error" with description "Proxy Server
Refused Connection. Firefox is configured to use a proxy server that is
refusing connections."
If we connect to HTTPS site which not blocked by proxy server OR using CA
self-signed issuer , all works fine.

Expected Results:  
Display proxy server error page with deny info. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-custom-error-page-tp4682433.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed May 17 14:04:28 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 May 2017 02:04:28 +1200
Subject: [squid-users] Squid custom error page
In-Reply-To: <1495020726548-4682433.post@n4.nabble.com>
References: <1495020726548-4682433.post@n4.nabble.com>
Message-ID: <c1c6f8fe-f7ee-92f3-41c6-fbe2ab53ba88@treenet.co.nz>

On 17/05/17 23:32, chcs wrote:
> Firefox 53.0.2 , Chrome 58.3029 y Opera 44 display "Proxy Server Refused
> Connection" page, instead of Squid custom error page, when connect to HTTPS
> site which blocked by proxy server.
> For example we try to connect to https://www.something.com via Squid proxy
> server which denied with 403 error this connect and send custom error page
> with description of problem in older versions it's worked.
> I'm using pfSense 2.4 (actual version squid 3.5.24).
>
> Reproducible: Always
>
> Steps to Reproduce:
> 1. Configure Firefox to use proxy server (SSL Proxy).
> 2. HTTPS/SSL Interception , Enable SSL filtering, splice all, CA: Let's
> Encript autority
> 3. Try to connect to HTTPS site, which will be blocked by proxy server
>
> Actual Results:
> Firefox will display "Page Load Error" with description "Proxy Server
> Refused Connection. Firefox is configured to use a proxy server that is
> refusing connections."
> If we connect to HTTPS site which not blocked by proxy server OR using CA
> self-signed issuer , all works fine.
>
> Expected Results:
> Display proxy server error page with deny info.

This is a well-known problem with Browsers, they all refuse to display 
any response to a CONNECT tunnel message.
<On 17/05/17 23:32, chcs wrote:
> Firefox 53.0.2 , Chrome 58.3029 y Opera 44 display "Proxy Server Refused
> Connection" page, instead of Squid custom error page, when connect to HTTPS
> site which blocked by proxy server.
> For example we try to connect to https://www.something.com via Squid proxy
> server which denied with 403 error this connect and send custom error page
> with description of problem in older versions it's worked.
> I'm using pfSense 2.4 (actual version squid 3.5.24).
>
> Reproducible: Always
>
> Steps to Reproduce:
> 1. Configure Firefox to use proxy server (SSL Proxy).
> 2. HTTPS/SSL Interception , Enable SSL filtering, splice all, CA: Let's
> Encript autority
> 3. Try to connect to HTTPS site, which will be blocked by proxy server
>
> Actual Results:
> Firefox will display "Page Load Error" with description "Proxy Server
> Refused Connection. Firefox is configured to use a proxy server that is
> refusing connections."
> If we connect to HTTPS site which not blocked by proxy server OR using CA
> self-signed issuer , all works fine.
>
> Expected Results:
> Display proxy server error page with deny info.

This is a well-known problem with Browsers, they all refuse to display 
any response to a CONNECT tunnel message.
<http://wiki.squid-cache.org/Features/CustomErrors#Custom_error_pages_not_displayed_for_HTTPS>

Use of TLS to secure the connection to the proxy does not affect this 
browser behaviour on HTTPS traffic. The best you can hope for is to make 
Squid use a 511 status code with deny_info and hope that it chooses to 
display something halfway useful.

Amos



From dijxie at gmail.com  Wed May 17 14:25:03 2017
From: dijxie at gmail.com (Dijxie)
Date: Wed, 17 May 2017 16:25:03 +0200
Subject: [squid-users] Squid custom error page
In-Reply-To: <1495020726548-4682433.post@n4.nabble.com>
References: <1495020726548-4682433.post@n4.nabble.com>
Message-ID: <70010ca1-fa12-f781-d645-5004069a11ca@gmail.com>

W dniu 17.05.2017 o 13:32, chcs pisze:
> Firefox 53.0.2 , Chrome 58.3029 y Opera 44 display "Proxy Server Refused
> Connection" page, instead of Squid custom error page, when connect to HTTPS
> site which blocked by proxy server.
> For example we try to connect to https://www.something.com via Squid proxy
> server which denied with 403 error this connect and send custom error page
> with description of problem in older versions it's worked.
> I'm using pfSense 2.4 (actual version squid 3.5.24).
>
> Reproducible: Always
>
> Steps to Reproduce:
> 1. Configure Firefox to use proxy server (SSL Proxy).
> 2. HTTPS/SSL Interception , Enable SSL filtering, splice all, CA: Let's
> Encript autority
> 3. Try to connect to HTTPS site, which will be blocked by proxy server
>
> Actual Results:
> Firefox will display "Page Load Error" with description "Proxy Server
> Refused Connection. Firefox is configured to use a proxy server that is
> refusing connections."
> If we connect to HTTPS site which not blocked by proxy server OR using CA
> self-signed issuer , all works fine.
>
> Expected Results:
> Display proxy server error page with deny info.
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-custom-error-page-tp4682433.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

This is intentional Firefox behavior since long time ago:
https://bugzilla.mozilla.org/show_bug.cgi?id=493699

Even if this bug is outdated,  it is browser thing how to render error 
pages, not squid's fault.
You may try to redirect (instead of blocking) your blocked page to your 
custom page that looks exactly  like sqid's internal error page, but 
then You will see browser's SSL security warning, since page you have 
requested was SSL, and your error page is not - the same goes for 
internal error pages.
Proxies error pages are nowadays usually replaced by browsers due to 
security reasons in case of SSL pages.

If your custom-pretending-to-be-squid's-internal page would be SSL with 
valid cert, my guess is your problem is solved.

-- 
Greets, Dijx

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170517/6ed82198/attachment.htm>

From Walter.H at mathemainzel.info  Wed May 17 14:42:13 2017
From: Walter.H at mathemainzel.info (Walter H.)
Date: Wed, 17 May 2017 16:42:13 +0200
Subject: [squid-users] Squid custom error page
In-Reply-To: <c1c6f8fe-f7ee-92f3-41c6-fbe2ab53ba88@treenet.co.nz>
References: <1495020726548-4682433.post@n4.nabble.com>
 <c1c6f8fe-f7ee-92f3-41c6-fbe2ab53ba88@treenet.co.nz>
Message-ID: <591C6145.1070605@mathemainzel.info>

On 17.05.2017 16:04, Amos Jeffries wrote:
> On 17/05/17 23:32, chcs wrote:
>> Expected Results:
>> Display proxy server error page with deny info.
>
> This is a well-known problem with Browsers, they all refuse to display 
> any response to a CONNECT tunnel message.
> <http://wiki.squid-cache.org/Features/CustomErrors#Custom_error_pages_not_displayed_for_HTTPS> 
>
>
> Use of TLS to secure the connection to the proxy does not affect this 
> browser behaviour on HTTPS traffic. The best you can hope for is to 
> make Squid use a 511 status code with deny_info and hope that it 
> chooses to display something halfway useful.
there seems to be another problem ...

at my setup any browser shows the proxy messages;

with deny_info the special page
e.g. ERR_DOMAIN_BLOCKED,
without just the ERR_ACCESS_DENIED as default ...

my squid 3.5,25 (CentOS 6.9) - thanks to
Eliezer Croitoru for doing this good job;

the custom error pages are only shown, when the proxy does
SSL interception and the browser has installed the squid CA certificate ...

why is this:

without SSL interception, the browser sends a CONNECT
and expects a SSL/TLS handshake, instead he gets an
HTTP reply with the custom error page, which the browser
doesn't know to handle at this moment ...
only the information of HTTP header is processed;

in case someone has configured https_port this is just the same,
because the SSL/TLS connection to the webserver is tunneled inside
the SSL/TLS connection between client and browser ...

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170517/4c0dc3c3/attachment.bin>

From rafael.akchurin at diladele.com  Wed May 17 14:50:06 2017
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Wed, 17 May 2017 14:50:06 +0000
Subject: [squid-users] Squid custom error page
In-Reply-To: <c1c6f8fe-f7ee-92f3-41c6-fbe2ab53ba88@treenet.co.nz>
References: <1495020726548-4682433.post@n4.nabble.com>,
 <c1c6f8fe-f7ee-92f3-41c6-fbe2ab53ba88@treenet.co.nz>
Message-ID: <F9272F31-A3B4-46B7-A793-376F1A5DF562@diladele.com>

Please note if you first let the connect tunnel to succeed (forcing bump) and then block the next coming request through that tunnel - you will get the blocked message displayed.

We do it in ICAP (https://docs.diladele.com/faq/squid/cannot_connect_to_site_using_https.html) - other community members may know better if it is possible to do that in Squid directly.

Beware of those using your tunnels to pump non http traffic though. Blocking the connect as it is done now in Squid keeps you on safe side.

Best regards,
Rafael Akchurin

Op 17 mei 2017 om 4:04 PM heeft Amos Jeffries <squid3 at treenet.co.nz<mailto:squid3 at treenet.co.nz>> het volgende geschreven:

On 17/05/17 23:32, chcs wrote:
Firefox 53.0.2 , Chrome 58.3029 y Opera 44 display "Proxy Server Refused
Connection" page, instead of Squid custom error page, when connect to HTTPS
site which blocked by proxy server.
For example we try to connect to https://www.something.com via Squid proxy
server which denied with 403 error this connect and send custom error page
with description of problem in older versions it's worked.
I'm using pfSense 2.4 (actual version squid 3.5.24).

Reproducible: Always

Steps to Reproduce:
1. Configure Firefox to use proxy server (SSL Proxy).
2. HTTPS/SSL Interception , Enable SSL filtering, splice all, CA: Let's
Encript autority
3. Try to connect to HTTPS site, which will be blocked by proxy server

Actual Results:
Firefox will display "Page Load Error" with description "Proxy Server
Refused Connection. Firefox is configured to use a proxy server that is
refusing connections."
If we connect to HTTPS site which not blocked by proxy server OR using CA
self-signed issuer , all works fine.

Expected Results:
Display proxy server error page with deny info.

This is a well-known problem with Browsers, they all refuse to display any response to a CONNECT tunnel message.
<On 17/05/17 23:32, chcs wrote:
Firefox 53.0.2 , Chrome 58.3029 y Opera 44 display "Proxy Server Refused
Connection" page, instead of Squid custom error page, when connect to HTTPS
site which blocked by proxy server.
For example we try to connect to https://www.something.com via Squid proxy
server which denied with 403 error this connect and send custom error page
with description of problem in older versions it's worked.
I'm using pfSense 2.4 (actual version squid 3.5.24).

Reproducible: Always

Steps to Reproduce:
1. Configure Firefox to use proxy server (SSL Proxy).
2. HTTPS/SSL Interception , Enable SSL filtering, splice all, CA: Let's
Encript autority
3. Try to connect to HTTPS site, which will be blocked by proxy server

Actual Results:
Firefox will display "Page Load Error" with description "Proxy Server
Refused Connection. Firefox is configured to use a proxy server that is
refusing connections."
If we connect to HTTPS site which not blocked by proxy server OR using CA
self-signed issuer , all works fine.

Expected Results:
Display proxy server error page with deny info.

This is a well-known problem with Browsers, they all refuse to display any response to a CONNECT tunnel message.
<http://wiki.squid-cache.org/Features/CustomErrors#Custom_error_pages_not_displayed_for_HTTPS>

Use of TLS to secure the connection to the proxy does not affect this browser behaviour on HTTPS traffic. The best you can hope for is to make Squid use a 511 status code with deny_info and hope that it chooses to display something halfway useful.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170517/2b2f2b70/attachment.htm>

From Walter.H at mathemainzel.info  Wed May 17 15:13:29 2017
From: Walter.H at mathemainzel.info (Walter H.)
Date: Wed, 17 May 2017 17:13:29 +0200
Subject: [squid-users] list generates error messages ...
Message-ID: <591C6899.2050005@mathemainzel.info>

whenever I send a mail to the list, I get
such an error message back from
MAILER-DAEMON at squid-cache.org

This is the mail system at host lists.squid-cache.org.

I'm sorry to have to inform you that your message could not
be delivered to one or more recipients. It's attached below.

For further assistance, please send mail to postmaster.

If you do so, please include this problem report. You can
delete your own text from the attached returned message.

                    The mail system

<squid-users at squid-cache.org>  (expanded from
     <squid-users at lists.squid-cache.org>): mail forwarding loop for
     squid-users at squid-cache.org



Reporting-MTA: dns; lists.squid-cache.org
X-Postfix-Queue-ID: 7EF5FE0F2B
X-Postfix-Sender: rfc822;Walter.H at mathemainzel.info
Arrival-Date: Wed, 17 May 2017 14:49:16 +0000 (UTC)

Final-Recipient: rfc822;squid-users at squid-cache.org
Original-Recipient:rfc822;squid-users at lists.squid-cache.org
Action: failed
Status: 5.4.6
Diagnostic-Code: X-Postfix; mail forwarding loop for
     squid-users at squid-cache.org


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170517/c1684c82/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170517/c1684c82/attachment.bin>

From harariboy at gmail.com  Wed May 17 15:35:45 2017
From: harariboy at gmail.com (avi_h)
Date: Wed, 17 May 2017 08:35:45 -0700 (PDT)
Subject: [squid-users] Squid to listen to HTTPS
In-Reply-To: <26967745-5e1d-84f0-7cce-4e163f86fdd7@measurement-factory.com>
References: <1494798568853-4682393.post@n4.nabble.com>
 <037c2ff9-3985-a7db-36e5-11c1b285a97e@measurement-factory.com>
 <1494878172214-4682402.post@n4.nabble.com>
 <26967745-5e1d-84f0-7cce-4e163f86fdd7@measurement-factory.com>
Message-ID: <1495035345054-4682439.post@n4.nabble.com>

Hi Alex,

Thanks for the info.
I updated Curl to a newer version that supports HTTPS and managed to access
the SSL proxy.
Much appreciated.

Regards,
Avi



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-to-listen-to-HTTPS-tp4682393p4682439.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Wed May 17 17:43:24 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 17 May 2017 10:43:24 -0700 (PDT)
Subject: [squid-users] =?utf-8?b?U2xvdyBzZXJ2ZXIgwr8/?=
In-Reply-To: <03a6452f-8480-eeda-0c9a-0de7e78c43f6@treenet.co.nz>
References: <1494874369830-4682400.post@n4.nabble.com>
 <03a6452f-8480-eeda-0c9a-0de7e78c43f6@treenet.co.nz>
Message-ID: <1495043004338-4682440.post@n4.nabble.com>


Hi.
The server is serving web pages very slow.
Not related to bandwith of delay pools.......
Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Slow-server-tp4682400p4682440.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From uhlar at fantomas.sk  Wed May 17 18:22:11 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 17 May 2017 20:22:11 +0200
Subject: [squid-users] list generates error messages ...
In-Reply-To: <591C6899.2050005@mathemainzel.info>
References: <591C6899.2050005@mathemainzel.info>
Message-ID: <20170517182211.GA21904@fantomas.sk>

On 17.05.17 17:13, Walter H. wrote:
>whenever I send a mail to the list, I get
>such an error message back from
>MAILER-DAEMON at squid-cache.org
>
>This is the mail system at host lists.squid-cache.org.
>
>I'm sorry to have to inform you that your message could not
>be delivered to one or more recipients. It's attached below.
>
>For further assistance, please send mail to postmaster.
>
>If you do so, please include this problem report. You can
>delete your own text from the attached returned message.
>
>                   The mail system
>
><squid-users at squid-cache.org>  (expanded from
>    <squid-users at lists.squid-cache.org>): mail forwarding loop for
>    squid-users at squid-cache.org

it's possible that a broken mail server re-sends mail from the list back to
the list.
hard to detect who did it...
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
WinError #98652: Operation completed successfully.


From erdosain9 at gmail.com  Wed May 17 19:17:54 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 17 May 2017 12:17:54 -0700 (PDT)
Subject: [squid-users] WARNING: All 20/20 negotiateauthenticator
	processes are busy.
In-Reply-To: <efd8d8a0-b676-ed13-f220-27bda75c39c1@treenet.co.nz>
References: <1494516474107-4682362.post@n4.nabble.com>
 <89df3bbf-300e-dcdd-21b2-079ea847662d@gmail.com>
 <1494603034421-4682379.post@n4.nabble.com>
 <99bc82bf-324f-0be9-3b55-94842c07f31b@gmail.com>
 <1494874389106-4682401.post@n4.nabble.com>
 <ae663996-50b8-f68b-ad8e-9557fa8a95f7@gmail.com>
 <efd8d8a0-b676-ed13-f220-27bda75c39c1@treenet.co.nz>
Message-ID: <1495048674590-4682442.post@n4.nabble.com>

Thanks, now i have "access denied".......why???

[root at squid ~]# squidclient -vv -h 192.168.1.215 mgr:info
verbosity level set to 2
Request:
GET cache_object://192.168.1.215/info HTTP/1.0
Host: 192.168.1.215
User-Agent: squidclient/3.5.20
Accept: */*
Connection: close


.
Transport detected: IPv4-mapped  and IPv6
Resolving 192.168.1.215 ...
Connecting... 192.168.1.215 (192.168.1.215:3128)
Connected to: 192.168.1.215 (192.168.1.215:3128)
Sending HTTP request ... 
done.
HTTP/1.1 403 Forbidden
Server: squid/3.5.20
Mime-Version: 1.0
Date: Wed, 17 May 2017 19:14:41 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3567
X-Squid-Error: ERR_ACCESS_DENIED 0
Vary: Accept-Language
Content-Language: en
X-Cache: MISS from squid.xxxxxxx.lan
X-Cache-Lookup: NONE from squid.xxxxxxx.lan:3128
Connection: close

<!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01//EN&quot;
&quot;http://www.w3.org/TR/html4/strict.dtd&quot;>
<html><head>
<meta type="copyright" content="Copyright (C) 1996-2016 The Squid Software
Foundation and contributors">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>ERROR: The requested URL could not be retrieved</title>

</head><body id=ERR_ACCESS_DENIED>
<div id="titles">
ERROR

The requested URL could not be retrieved

</div>
<hr>

<div id="content">
<p>The following error was encountered while trying to retrieve the URL: 
cache_object://192.168.1.215/info <cache_object://192.168.1.215/info>  </p>

<blockquote id="error">
<p>*Access Denied.*</p>
</blockquote>

<p>Access control configuration prevents your request from being allowed at
this time. Please contact your service provider if you feel this is
incorrect.</p>

<p>Your cache administrator is  webmaster
<mailto:webmaster?subject=CacheErrorInfo%20-%20ERR_ACCESS_DENIED&amp;body=CacheHost%3A%20squid.xxxxxxx.lan%0D%0AErrPage%3A%20ERR_ACCESS_DENIED%0D%0AErr%3A%20%5Bnone%5D%0D%0ATimeStamp%3A%20Wed,%2017%20May%202017%2019%3A14%3A41%20GMT%0D%0A%0D%0AClientIP%3A%20192.168.1.215%0D%0A%0D%0AHTTP%20Request%3A%0D%0AGET%20%2Finfo%20HTTP%2F1.0%0AUser-Agent%3A%20squidclient%2F3.5.20%0D%0AAccept%3A%20*%2F*%0D%0AConnection%3A%20close%0D%0AHost%3A%20192.168.1.215%0D%0A%0D%0A%0D%0A> 
.</p>
<br>
</div>

<hr>
<div id="footer">
<p>Generated Wed, 17 May 2017 19:14:41 GMT by squid.xxxxxxx.lan
(squid/3.5.20)</p>

</div>
</body></html>





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/WARNING-All-20-20-negotiateauthenticator-processes-are-busy-tp4682362p4682442.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Wed May 17 19:41:06 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 17 May 2017 12:41:06 -0700 (PDT)
Subject: [squid-users] WARNING: All 20/20 negotiateauthenticator
	processes are busy.
In-Reply-To: <1495048674590-4682442.post@n4.nabble.com>
References: <1494516474107-4682362.post@n4.nabble.com>
 <89df3bbf-300e-dcdd-21b2-079ea847662d@gmail.com>
 <1494603034421-4682379.post@n4.nabble.com>
 <99bc82bf-324f-0be9-3b55-94842c07f31b@gmail.com>
 <1494874389106-4682401.post@n4.nabble.com>
 <ae663996-50b8-f68b-ad8e-9557fa8a95f7@gmail.com>
 <efd8d8a0-b676-ed13-f220-27bda75c39c1@treenet.co.nz>
 <1495048674590-4682442.post@n4.nabble.com>
Message-ID: <1495050066524-4682443.post@n4.nabble.com>

And if i do this 

http_port 127.0.0.1:3128

The i get this

[root at squid ~]# squidclient -vv mgr:menu
verbosity level set to 2
Request:
GET cache_object://localhost/menu HTTP/1.0
Host: localhost
User-Agent: squidclient/3.5.20
Accept: */*
Connection: close


.
Transport detected: IPv4-mapped  and IPv6
Resolving localhost ...
Connecting... localhost ([::1]:3128)
ERROR: Cannot connect to [::1]:3128




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/WARNING-All-20-20-negotiateauthenticator-processes-are-busy-tp4682362p4682443.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Wed May 17 19:59:34 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 17 May 2017 12:59:34 -0700 (PDT)
Subject: [squid-users] WARNING: All 20/20 negotiateauthenticator
	processes are busy.
In-Reply-To: <1495050066524-4682443.post@n4.nabble.com>
References: <1494516474107-4682362.post@n4.nabble.com>
 <89df3bbf-300e-dcdd-21b2-079ea847662d@gmail.com>
 <1494603034421-4682379.post@n4.nabble.com>
 <99bc82bf-324f-0be9-3b55-94842c07f31b@gmail.com>
 <1494874389106-4682401.post@n4.nabble.com>
 <ae663996-50b8-f68b-ad8e-9557fa8a95f7@gmail.com>
 <efd8d8a0-b676-ed13-f220-27bda75c39c1@treenet.co.nz>
 <1495048674590-4682442.post@n4.nabble.com>
 <1495050066524-4682443.post@n4.nabble.com>
Message-ID: <1495051174862-4682444.post@n4.nabble.com>

Sorry now squidclient it's working! was the ipv6.
Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/WARNING-All-20-20-negotiateauthenticator-processes-are-busy-tp4682362p4682444.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Wed May 17 20:17:36 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 17 May 2017 21:17:36 +0100
Subject: [squid-users] WARNING: All 20/20 negotiateauthenticator
	processes are busy.
In-Reply-To: <1495050066524-4682443.post@n4.nabble.com>
References: <1494516474107-4682362.post@n4.nabble.com>
 <1495048674590-4682442.post@n4.nabble.com>
 <1495050066524-4682443.post@n4.nabble.com>
Message-ID: <201705172117.36875.Antony.Stone@squid.open.source.it>

On Wednesday 17 May 2017 at 20:41:06, erdosain9 wrote:

> And if i do this
> 
> http_port 127.0.0.1:3128
> 
> The i get this
> 
> [root at squid ~]# squidclient -vv mgr:menu
> verbosity level set to 2
> Request:
> GET cache_object://localhost/menu HTTP/1.0
> Host: localhost
> User-Agent: squidclient/3.5.20
> Accept: */*
> Connection: close
> .
> Transport detected: IPv4-mapped  and IPv6
> Resolving localhost ...
> Connecting... localhost ([::1]:3128)
> ERROR: Cannot connect to [::1]:3128

Okay, so what happens if you do a consistent test instead:

	http_port 127.0.0.1:3128
and
	GET cache_object://127.0.0.1/menu HTTP/1.0


The fact that your machine is resolving "localhost" to the IPv6 address in 
favour of the IPv4 address you specified in the Squid configuration means that 
you're not testing what you configured - not helpful...


Antony.

-- 
I conclude that there are two ways of constructing a software design: One way 
is to make it so simple that there are _obviously_ no deficiencies, and the 
other way is to make it so complicated that there are no _obvious_ 
deficiencies.

 - C A R Hoare

                                                   Please reply to the list;
                                                         please *don't* CC me.


From dijxie at gmail.com  Wed May 17 23:58:15 2017
From: dijxie at gmail.com (Dijxie)
Date: Thu, 18 May 2017 01:58:15 +0200
Subject: [squid-users] =?utf-8?b?U2xvdyBzZXJ2ZXIgwr8/?=
In-Reply-To: <1495043004338-4682440.post@n4.nabble.com>
References: <1494874369830-4682400.post@n4.nabble.com>
 <03a6452f-8480-eeda-0c9a-0de7e78c43f6@treenet.co.nz>
 <1495043004338-4682440.post@n4.nabble.com>
Message-ID: <1b16a948-9ae2-2452-a18c-4330da49f7bf@gmail.com>

On 2017-05-17 19:43, erdosain9 wrote:
> Hi.
> The server is serving web pages very slow.
> Not related to bandwith of delay pools.......
> Thanks
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Slow-server-tp4682400p4682440.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Just check every mgr item listed in mgr:menu with squidclient or do some 
basic setup for cachemgr.cgi - it's not so hard after all.
At this point, it can be literally everything. Negotiate helpers or slow 
KDC reply can be an issue, as well as slow dns response. Disk cache 
problem. Even rsyslog, if used. Just anything.

-- 
Greets, Dijx.



From eliezer at ngtech.co.il  Thu May 18 09:05:38 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Thu, 18 May 2017 12:05:38 +0300
Subject: [squid-users] Chrome 58+: only the subjectAlternativeName extension,
	not commonName,
	is used to match the domain name and site certificate
Message-ID: <06ce01d2cfb5$eac75d50$c05617f0$@ngtech.co.il>

Hey List,

Since one of the subjects is SSL and specifically SSL-BUMP I noticed a
change today and found out that:
For Chrome 58 and later, only the subjectAlternativeName extension, not
commonName, is used to match the domain name and site certificate.
?If the certificate doesn?t have the correct subjectAlternativeName
extension, users get a NET::ERR_CERT_COMMON_NAME_INVALID error letting them
know that the connection isn?t private.?

Google source:
https://support.google.com/chrome/a/answer/7391219?hl=en

So if someone will see something weird... it might not even be related
directly to squid!

Regards,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il






From eliezer at ngtech.co.il  Thu May 18 09:08:51 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Thu, 18 May 2017 12:08:51 +0300
Subject: [squid-users] Squid + IPv6
In-Reply-To: <7ea22b39-45c6-bd59-ac5c-04de077c8b5b@treenet.co.nz>
References: <119093bb-bd72-b489-c10e-bde7b4e1b64c@iaps.pro>
 <04c301d2ce89$6748a060$35d9e120$@ngtech.co.il>
 <42b652f1-3bd6-a3c8-8a3f-821d14c0d0da@iaps.pro>
 <04d401d2ce96$1fe84e20$5fb8ea60$@ngtech.co.il>
 <7ea22b39-45c6-bd59-ac5c-04de077c8b5b@treenet.co.nz>
Message-ID: <06d001d2cfb6$5e331810$1a994830$@ngtech.co.il>

I think that the answers on how to re-compile squid for windows with special options might be the diladale part of the issue.
They compile squid with mostly default and they have enough experience and knowledge on how to recompile squid to match the requirement of the thread.

I still think that it's better to run Squid ontop of a linux and even in a VM ontop of windows compared to squid native binary(but it's my preference).

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Wednesday, May 17, 2017 4:33 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid + IPv6

Holdup guys. There is no limit on tcp_outgoing_address in Squid.

So Jared;

* what did you mean by "the entirety of squid immediately stops working" 
in your original mail?
   crash? errors? something else?

* what is your Windows system per-process handle limit?


Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid at bloms.de  Thu May 18 09:17:50 2017
From: squid at bloms.de (Dieter Bloms)
Date: Thu, 18 May 2017 11:17:50 +0200
Subject: [squid-users] custom error pages with stylesheets doesn't work for
	me
Message-ID: <20170518091750.GA246@bloms.de>

Hello,

I use squid 3.5.25 compiled with following options:

Squid Cache: Version 3.5.25
Service Name: squid
configure options:  '--prefix=/usr' '--sysconfdir=/etc/squid' '--bindir=/usr/sbin' '--sbindir=/usr/sbin' '--localstatedir=/var' '--libexecdir=/usr/sbin' '--datadir=/usr/share/squid' '--mandir=/usr/share/man' '--with-default-user=squid' '--with-filedescriptors=24576' '--disable-auto-locale' '--disable-auth-negotiate' '--disable-auth-ntlm' '--disable-eui' '--disable-carp' '--disable-htcp' '--disable-ident-lookups' '--disable-loadable-modules' '--disable-translation' '--disable-wccp' '--disable-wccpv2' '--enable-async-io=128' '--enable-auth' '--enable-auth-basic=LDAP NCSA' '--enable-auth-digest=LDAP file' '--enable-epoll' '--enable-log-daemon-helpers=file' '--enable-icap-client' '--enable-snmp' '--enable-disk-io=AIO,DiskThreads,IpcIo,Blocking' '--enable-storeio=aufs,rock' '--enable-referer-log' '--enable-useragent-log' '--enable-large-cache-files' '--enable-removal-policies=lru,heap' '--enable-external-acl-helpers=session' '--enable-follow-x-forwarded-for' '--enable-ssl-crtd' '--disable-strict-error-checking' '--with-openssl=/opt/dv-openssl1' 'CFLAGS= -O2 -fPIE -fPIC -DSQUID_USE_SSLGETCERTIFICATE_HACK=1' 'LDFLAGS= -fPIC -pie' 'CPPFLAGS= -O2 -fPIE -fPIC -DSQUID_USE_SSLGETCERTIFICATE_HACK=1'

I wrote some custom error pages and activated style sheets in the header of the error pages like:

<style type="text/css">
%l
</style>

In the squid.conf file I set err_page_stylesheet to my stylesheet file and I restarted squid.
My expectation was, that the content of this style sheet file will be included in the error page at the %l position.
But the place between <style type="text/css"> and </style> is empty.

Does anybody know how can I insert the content of the style sheet file to the error pages ?


-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
From field.


From flashdown at data-core.org  Thu May 18 09:41:38 2017
From: flashdown at data-core.org (Flashdown)
Date: Thu, 18 May 2017 11:41:38 +0200
Subject: [squid-users] Chrome 58+: only the subjectAlternativeName
 extension, not commonName,
 is used to match the domain name and site certificate
In-Reply-To: <06ce01d2cfb5$eac75d50$c05617f0$@ngtech.co.il>
References: <06ce01d2cfb5$eac75d50$c05617f0$@ngtech.co.il>
Message-ID: <3f99c784a86b07d4f958470ee1e08493@data-core.org>

Dear Eliezer,

Please have look into http://bugs.squid-cache.org/show_bug.cgi?id=4711
the patches for this issue are already done. Many thx to Christos 
Tsantilas!


@Amos: I hope you consider adding the patch to Squid 3.5 as well, since 
for now it just has been added to Squid 4, maybe the reason is a testing 
period or something similar. Would be nice to get an update like will be 
added into upcoming release 3.5.xx :)

Am 2017-05-18 11:05, schrieb Eliezer  Croitoru:
> Hey List,
> 
> Since one of the subjects is SSL and specifically SSL-BUMP I noticed a
> change today and found out that:
> For Chrome 58 and later, only the subjectAlternativeName extension, not
> commonName, is used to match the domain name and site certificate.
> ?If the certificate doesn?t have the correct subjectAlternativeName
> extension, users get a NET::ERR_CERT_COMMON_NAME_INVALID error letting 
> them
> know that the connection isn?t private.?
> 
> Google source:
> https://support.google.com/chrome/a/answer/7391219?hl=en
> 
> So if someone will see something weird... it might not even be related
> directly to squid!
> 
> Regards,
> Eliezer
> 
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From innovature.arun.xavier at gmail.com  Thu May 18 10:26:22 2017
From: innovature.arun.xavier at gmail.com (arun.xavier)
Date: Thu, 18 May 2017 03:26:22 -0700 (PDT)
Subject: [squid-users] Squid works with ssl bump in intercept mode and root
 certificate in browser, but apps does not work
Message-ID: <1495103182661-4682451.post@n4.nabble.com>

I have configured squid with ssl-bump (intercept mode) and it works as
expected while accessing secure sites from browsers.

What I have done so far.

 - Configured squid.
 - created a root& intermediate certificate for dynamic cert generation in
squid.
     installed the same root certificate in mobile device(iphone 6 -iOS-10).
 - Every website works on chrome/safari.

But apps like facebook,twitter are not working(showing network error).

When checking cache log of squid, I found the below log.

/Error negotiating SSL connection on FD 12: error:14094418:SSL
routines:ssl3_read_bytes:tlsv1 alert unknown ca (1/0)
/
It looks like initial CONNECT/Handshake is not working.

what I have changed in squid.conf
-----------------------------------------------------------------
acl localnet src 172.16.0.0/12
acl localnet src fe80::/10
acl allow localnet
ssl_bump bump all
always_direct allow all
http_port localhost:3128
http_port localhost:3129 intercept
https_port localhost:3130 intercept ssl-bump generate-host-certificates=on
cert=/etc/squid/cert/cert.pem 
key=/etc/squid/cert/key.pem
strip_query_terms off
----------------------------------------------------------------

Any idea how to fix this? or where to check? What might be my mistake ?
PS:
I use squid to get logs of all internet traffic from mobile devices.
Overview of my intented system is like this:
SmartPhone---->VPN--->Squid--->Internet



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-works-with-ssl-bump-in-intercept-mode-and-root-certificate-in-browser-but-apps-does-not-work-tp4682451.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From marcus.kool at urlfilterdb.com  Thu May 18 10:59:16 2017
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Thu, 18 May 2017 07:59:16 -0300
Subject: [squid-users] Squid works with ssl bump in intercept mode and
 root certificate in browser, but apps does not work
In-Reply-To: <1495103182661-4682451.post@n4.nabble.com>
References: <1495103182661-4682451.post@n4.nabble.com>
Message-ID: <277d6606-89db-da7b-9d18-cd40fa8b11f5@urlfilterdb.com>

You have not stated which version of Squid you are using but my guess is that it is 3.5.x.

facebook app and other apps use port 443 but do not use HTTPS and therefore Squid does not how to bump it and consequently the app does not work.

What you need is the not yet stable Squid 4.0 and use the option
    on_unsupported_protocol tunnel all
so that the non-HTTPS protocols get through without being bumped.

Marcus


On 18/05/17 07:26, arun.xavier wrote:
> I have configured squid with ssl-bump (intercept mode) and it works as
> expected while accessing secure sites from browsers.
>
> What I have done so far.
>
>  - Configured squid.
>  - created a root& intermediate certificate for dynamic cert generation in
> squid.
>      installed the same root certificate in mobile device(iphone 6 -iOS-10).
>  - Every website works on chrome/safari.
>
> But apps like facebook,twitter are not working(showing network error).
>
> When checking cache log of squid, I found the below log.
>
> /Error negotiating SSL connection on FD 12: error:14094418:SSL
> routines:ssl3_read_bytes:tlsv1 alert unknown ca (1/0)
> /
> It looks like initial CONNECT/Handshake is not working.
>
> what I have changed in squid.conf
> -----------------------------------------------------------------
> acl localnet src 172.16.0.0/12
> acl localnet src fe80::/10
> acl allow localnet
> ssl_bump bump all
> always_direct allow all
> http_port localhost:3128
> http_port localhost:3129 intercept
> https_port localhost:3130 intercept ssl-bump generate-host-certificates=on
> cert=/etc/squid/cert/cert.pem
> key=/etc/squid/cert/key.pem
> strip_query_terms off
> ----------------------------------------------------------------
>
> Any idea how to fix this? or where to check? What might be my mistake ?
> PS:
> I use squid to get logs of all internet traffic from mobile devices.
> Overview of my intented system is like this:
> SmartPhone---->VPN--->Squid--->Internet
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-works-with-ssl-bump-in-intercept-mode-and-root-certificate-in-browser-but-apps-does-not-work-tp4682451.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From squid3 at treenet.co.nz  Thu May 18 11:10:34 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 May 2017 23:10:34 +1200
Subject: [squid-users] Chrome 58+: only the subjectAlternativeName
 extension, not commonName,
 is used to match the domain name and site certificate
In-Reply-To: <3f99c784a86b07d4f958470ee1e08493@data-core.org>
References: <06ce01d2cfb5$eac75d50$c05617f0$@ngtech.co.il>
 <3f99c784a86b07d4f958470ee1e08493@data-core.org>
Message-ID: <9518ad9c-a694-fab1-84ff-bbd8a9225acc@treenet.co.nz>

On 18/05/17 21:41, Flashdown wrote:
> Dear Eliezer,
>
> Please have look into http://bugs.squid-cache.org/show_bug.cgi?id=4711
> the patches for this issue are already done. Many thx to Christos 
> Tsantilas!
>
>
> @Amos: I hope you consider adding the patch to Squid 3.5 as well, 
> since for now it just has been added to Squid 4, maybe the reason is a 
> testing period or something similar. Would be nice to get an update 
> like will be added into upcoming release 3.5.xx :)
>

Aye, its on the list just waiting for me to get time for backporting. 
Since Christos has provided patches already that has good chances of 
happening next week.

Amos



From squid3 at treenet.co.nz  Thu May 18 11:18:00 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 18 May 2017 23:18:00 +1200
Subject: [squid-users] Squid works with ssl bump in intercept mode and
 root certificate in browser, but apps does not work
In-Reply-To: <277d6606-89db-da7b-9d18-cd40fa8b11f5@urlfilterdb.com>
References: <1495103182661-4682451.post@n4.nabble.com>
 <277d6606-89db-da7b-9d18-cd40fa8b11f5@urlfilterdb.com>
Message-ID: <afc6dbd4-8bf0-817d-1baa-578a34b95436@treenet.co.nz>

On 18/05/17 22:59, Marcus Kool wrote:
> You have not stated which version of Squid you are using but my guess 
> is that it is 3.5.x.
>
> facebook app and other apps use port 443 but do not use HTTPS and 
> therefore Squid does not how to bump it and consequently the app does 
> not work.
>
> What you need is the not yet stable Squid 4.0 and use the option
>    on_unsupported_protocol tunnel all
> so that the non-HTTPS protocols get through without being bumped.

Also apps are more likely to have certificate pinning in operation since 
the domains they need to contact is much smaller than a general-use 
browser. If that is done the traffic cannot be bump'ed (only peek, 
stare, splice or terminate work).

Amos



From innovature.arun.xavier at gmail.com  Thu May 18 11:08:49 2017
From: innovature.arun.xavier at gmail.com (arun.xavier)
Date: Thu, 18 May 2017 04:08:49 -0700 (PDT)
Subject: [squid-users] Squid works with ssl bump in intercept mode and
 root certificate in browser, but apps does not work
In-Reply-To: <277d6606-89db-da7b-9d18-cd40fa8b11f5@urlfilterdb.com>
References: <1495103182661-4682451.post@n4.nabble.com>
 <277d6606-89db-da7b-9d18-cd40fa8b11f5@urlfilterdb.com>
Message-ID: <1495105729755-4682455.post@n4.nabble.com>

Thanks for the quick response, I have tried different versions of squid &
luckily now I have already configured squid-4.0.19, so I will try
/on_unsupported_protocol/ directive.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-works-with-ssl-bump-in-intercept-mode-and-root-certificate-in-browser-but-apps-does-not-work-tp4682451p4682455.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From innovature.arun.xavier at gmail.com  Thu May 18 12:46:56 2017
From: innovature.arun.xavier at gmail.com (arun.xavier)
Date: Thu, 18 May 2017 05:46:56 -0700 (PDT)
Subject: [squid-users] Squid works with ssl bump in intercept mode and
 root certificate in browser, but apps does not work
In-Reply-To: <afc6dbd4-8bf0-817d-1baa-578a34b95436@treenet.co.nz>
References: <1495103182661-4682451.post@n4.nabble.com>
 <277d6606-89db-da7b-9d18-cd40fa8b11f5@urlfilterdb.com>
 <afc6dbd4-8bf0-817d-1baa-578a34b95436@treenet.co.nz>
Message-ID: <1495111616447-4682456.post@n4.nabble.com>

Hello Amos,

The issue seems to be certificate pinning, is it possible to configure squid
to peek/splice pinned requests and to bump all other requests? 



-----
- Arun Xavier
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-works-with-ssl-bump-in-intercept-mode-and-root-certificate-in-browser-but-apps-does-not-work-tp4682451p4682456.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Thu May 18 12:48:13 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 18 May 2017 05:48:13 -0700 (PDT)
Subject: [squid-users] Documentation for squidclient?
Message-ID: <1495111693229-4682457.post@n4.nabble.com>

Hi.
Where i can find documentation for the opcion on squidclient, many of them
are self-explanatory but for example this:

[root at squid ~]# squidclient mgr:external_acl
HTTP/1.1 200 OK
Server: squid/3.5.20
Mime-Version: 1.0
Date: Thu, 18 May 2017 12:40:54 GMT
Content-Type: text/plain;charset=utf-8
Expires: Thu, 18 May 2017 12:40:54 GMT
Last-Modified: Thu, 18 May 2017 12:40:54 GMT
X-Cache: MISS from squid.xxxxxxx.lan
X-Cache-Lookup: MISS from squid.xxxxxxx.lan:3128
Connection: close

External ACL Statistics: i-full
Cache size: 13
program: /usr/lib64/squid/ext_kerberos_ldap_group_acl
number active: 5 of 5 (0 shutting down)
requests sent: 48
replies received: 48
queue length: 0
avg service time: 11 msec

   ID #	     FD	    PID	 # Requests	  # Replies	Flags	   Time	 Offset
Request
      6	     23	   2134	         48	         48	    	  0.011	      0	(none)
      7	     25	   2135	          0	          0	    	  0.000	      0	(none)
      8	     27	   2136	          0	          0	    	  0.000	      0	(none)
      9	     29	   2137	          0	          0	    	  0.000	      0	(none)
     10	     31	   2138	          0	          0	    	  0.000	      0	(none)

Flags key:

   B = BUSY
   W = WRITING
   C = CLOSING
   S = SHUTDOWN PENDING

External ACL Statistics: i-limitado
Cache size: 29
program: /usr/lib64/squid/ext_kerberos_ldap_group_acl
number active: 5 of 5 (0 shutting down)
requests sent: 110
replies received: 110
queue length: 0
avg service time: 101 msec

   ID #	     FD	    PID	 # Requests	  # Replies	Flags	   Time	 Offset
Request
     11	     33	   2139	        110	        110	    	  0.014	      0	(none)
     12	     35	   2140	          0	          0	    	  0.000	      0	(none)
     13	     37	   2141	          0	          0	    	  0.000	      0	(none)
     14	     39	   2142	          0	          0	    	  0.000	      0	(none)
     15	     41	   2143	          0	          0	    	  0.000	      0	(none)

Flags key:

   B = BUSY
   W = WRITING
   C = CLOSING
   S = SHUTDOWN PENDING

External ACL Statistics: i-sinlimite
Cache size: 51
program: /usr/lib64/squid/ext_kerberos_ldap_group_acl
number active: 5 of 5 (0 shutting down)
requests sent: 195
replies received: 195
queue length: 0
avg service time: -1441 msec

   ID #	     FD	    PID	 # Requests	  # Replies	Flags	   Time	 Offset
Request
     16	     43	   2144	        191	        191	    	  0.050	      0	(none)
     17	     45	   2145	          1	          1	    	  0.175	      0	(none)
     18	     47	   2146	          1	          1	    	  0.185	      0	(none)
     19	     49	   2147	          1	          1	    	  0.130	      0	(none)
     20	     51	   2148	          1	          1	    	  0.229	      0	(none)

Flags key:

   B = BUSY
   W = WRITING
   C = CLOSING
   S = SHUTDOWN PENDING

I know that i dont have any user in External ACL Statistics: i-sinlimite...
then why those statistics (with request and replies and 5 of 5).

Thanks to all




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Documentation-for-squidclient-tp4682457.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Thu May 18 13:07:02 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 18 May 2017 06:07:02 -0700 (PDT)
Subject: [squid-users] Documentation for squidclient?
In-Reply-To: <1495111693229-4682457.post@n4.nabble.com>
References: <1495111693229-4682457.post@n4.nabble.com>
Message-ID: <1495112822444-4682458.post@n4.nabble.com>

And for example, if i have this

Negotiate Authenticator Statistics:
program: /lib64/squid/negotiate_kerberos_auth
number active: 20 of 20 (0 shutting down)
requests sent: 23980
replies received: 23980
queue length: 0
avg service time: 8 msec

   ID #	     FD	    PID	 # Requests	  # Replies	 Flags	   Time	 Offset
Request
     21	     18	   2159	      15266	      15266	     	  0.034	      0	(none)
     22	     20	   2160	       4016	       4016	     	  0.167	      0	(none)
     23	     26	   2161	       1827	       1827	     	  0.225	      0	(none)
     24	     34	   2162	       1063	       1063	     	  0.142	      0	(none)
     25	     36	   2167	        674	        674	     	  0.113	      0	(none)
     26	     40	   2169	        427	        427	     	  0.134	      0	(none)
     27	     44	   2170	        251	        251	     	  0.134	      0	(none)
     28	     48	   2172	        171	        171	     	  0.073	      0	(none)
     29	     55	   2174	        106	        106	     	  0.299	      0	(none)
     30	    213	   3167	         64	         64	     	  0.298	      0	(none)
     31	    216	   3168	         41	         41	     	  0.297	      0	(none)
     32	    218	   3169	         26	         26	     	  0.250	      0	(none)
     33	    217	   3170	         15	         15	     	  0.297	      0	(none)
     37	     99	   6631	         10	         10	     	  0.243	      0	(none)
     38	    106	   6632	          7	          7	     	  0.171	      0	(none)
     39	    124	   7630	          4	          4	     	  0.112	      0	(none)
     40	    129	   7631	          4	          4	     	  0.306	      0	(none)
     41	    263	  18079	          3	          3	     	  0.306	      0	(none)
     42	    266	  18080	          3	          3	     	  0.404	      0	(none)
     43	    108	  18081	          2	          2	     	  0.401	      0	(none)

Flags key:

   B = BUSY
   C = CLOSING
   R = RESERVED
   S = SHUTDOWN PENDING
   P = PLACEHOLDER

20 of 20 authenticators are in use but, there is no busy... so... i have to
increase the number of authenticators or not?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Documentation-for-squidclient-tp4682457p4682458.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Thu May 18 13:20:04 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 18 May 2017 06:20:04 -0700 (PDT)
Subject: [squid-users] Documentation for squidclient?
In-Reply-To: <1495111693229-4682457.post@n4.nabble.com>
References: <1495111693229-4682457.post@n4.nabble.com>
Message-ID: <1495113604772-4682459.post@n4.nabble.com>

And... for last....

How i read this??

Delay pools configured: 5

Pool: 1
	Class: 2

	Aggregate:
		Max: 1000000
		Restore: 1000000
		Current: 1000000

	Individual:
		Max: 512000
		Restore: 50000
		Current: 124:512000 67:512000 120:512000 127:512000 9:512000 26:214810
64:512000 169:512000 156:512000

Pool: 2
	Class: 2

	Aggregate:
		Max: 1000000
		Restore: 1000000
		Current: 1000000

	Individual:
		Max: 512000
		Restore: 50000
		Current: 238:512000 124:512000 67:512000 120:512000 127:512000 26:512000
64:512000 156:512000 149:512000

Pool: 3
	Class: 1

	Aggregate:
		Max: 1000000
		Restore: 1000000
		Current: 1000000

Pool: 4
	Class: 3

	Aggregate:
		Max: 3000000
		Restore: 3000000
		Current: 3000000

	Network:
		Max: 1000000
		Restore: 1000000
		Current: 1:1000000 2:1000000

	Individual:
		Max: 512000
		Restore: 256000
		Current [Network 1]: 238:512000 127:512000 124:512000 17:512000 63:512000
149:512000 120:512000 155:512000 156:512000 26:512000 9:512000
		Current [Network 2]: 68:512000 61:512000 67:512000 64:512000 169:512000
66:512000 12:512000


Pool: 5
	Class: 3

	Aggregate:
		Max: 1500000
		Restore: 1500000
		Current: 1500000

	Network:
		Max: 750000
		Restore: 750000
		Current: 1:750000

	Individual:
		Max: 512000
		Restore: 256000
		Current [Network 1]: 48:512000 75:512000 121:512000 151:512000




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Documentation-for-squidclient-tp4682457p4682459.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From dijxie at gmail.com  Thu May 18 13:51:16 2017
From: dijxie at gmail.com (Dijxie)
Date: Thu, 18 May 2017 15:51:16 +0200
Subject: [squid-users] Documentation for squidclient?
In-Reply-To: <1495111693229-4682457.post@n4.nabble.com>
References: <1495111693229-4682457.post@n4.nabble.com>
Message-ID: <6ebe6c62-adfd-41f1-4183-6e81bbd1f58e@gmail.com>

W dniu 18.05.2017 o 14:48, erdosain9 pisze:
> Hi.
> Where i can find documentation for the opcion on squidclient, many of them
> are self-explanatory but for example this:
>
> [root at squid ~]# squidclient mgr:external_acl
> HTTP/1.1 200 OK
> Server: squid/3.5.20
> Mime-Version: 1.0
> Date: Thu, 18 May 2017 12:40:54 GMT
> Content-Type: text/plain;charset=utf-8
> Expires: Thu, 18 May 2017 12:40:54 GMT
> Last-Modified: Thu, 18 May 2017 12:40:54 GMT
> X-Cache: MISS from squid.xxxxxxx.lan
> X-Cache-Lookup: MISS from squid.xxxxxxx.lan:3128
> Connection: close
>
> External ACL Statistics: i-full
> Cache size: 13
> program: /usr/lib64/squid/ext_kerberos_ldap_group_acl
> number active: 5 of 5 (0 shutting down)
> requests sent: 48
> replies received: 48
> queue length: 0
> avg service time: 11 msec
>
>     ID #	     FD	    PID	 # Requests	  # Replies	Flags	   Time	 Offset
> Request
>        6	     23	   2134	         48	         48	    	  0.011	      0	(none)
>        7	     25	   2135	          0	          0	    	  0.000	      0	(none)
>        8	     27	   2136	          0	          0	    	  0.000	      0	(none)
>        9	     29	   2137	          0	          0	    	  0.000	      0	(none)
>       10	     31	   2138	          0	          0	    	  0.000	      0	(none)
>
> Flags key:
>
>     B = BUSY
>     W = WRITING
>     C = CLOSING
>     S = SHUTDOWN PENDING
>
> External ACL Statistics: i-limitado
> Cache size: 29
> program: /usr/lib64/squid/ext_kerberos_ldap_group_acl
> number active: 5 of 5 (0 shutting down)
> requests sent: 110
> replies received: 110
> queue length: 0
> avg service time: 101 msec
>
>     ID #	     FD	    PID	 # Requests	  # Replies	Flags	   Time	 Offset
> Request
>       11	     33	   2139	        110	        110	    	  0.014	      0	(none)
>       12	     35	   2140	          0	          0	    	  0.000	      0	(none)
>       13	     37	   2141	          0	          0	    	  0.000	      0	(none)
>       14	     39	   2142	          0	          0	    	  0.000	      0	(none)
>       15	     41	   2143	          0	          0	    	  0.000	      0	(none)
>
> Flags key:
>
>     B = BUSY
>     W = WRITING
>     C = CLOSING
>     S = SHUTDOWN PENDING
>
> External ACL Statistics: i-sinlimite
> Cache size: 51
> program: /usr/lib64/squid/ext_kerberos_ldap_group_acl
> number active: 5 of 5 (0 shutting down)
> requests sent: 195
> replies received: 195
> queue length: 0
> avg service time: -1441 msec
>
>     ID #	     FD	    PID	 # Requests	  # Replies	Flags	   Time	 Offset
> Request
>       16	     43	   2144	        191	        191	    	  0.050	      0	(none)
>       17	     45	   2145	          1	          1	    	  0.175	      0	(none)
>       18	     47	   2146	          1	          1	    	  0.185	      0	(none)
>       19	     49	   2147	          1	          1	    	  0.130	      0	(none)
>       20	     51	   2148	          1	          1	    	  0.229	      0	(none)
>
> Flags key:
>
>     B = BUSY
>     W = WRITING
>     C = CLOSING
>     S = SHUTDOWN PENDING
>
> I know that i dont have any user in External ACL Statistics: i-sinlimite...
> then why those statistics (with request and replies and 5 of 5).
>
> Thanks to all
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Documentation-for-squidclient-tp4682457.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

As far as I remember, you have some ldap group-based ACLs in your 
config. If any user is trying to access site listed in that kind of ACL, 
this helper is checking is user is in AD group that allows or disallows 
this action.

You may not have any user in i-sinlimite, but you DO HAVE this ACL, so 
squid will always  check that group and find out that the result is 
negative. If you have no users in this group and not going to have in 
near future, analyze your ACL logic and remove this rule from 
configuration - this will make squid faster for sure.

Your config is:

===begin conf sample===

http_access allow localhost
http_access allow i-sinlimite
http_access allow sin_autenticacion
http_access allow i-limitado #!dominios_denegados
http_access allow i-full #!dominios_denegados

# And finally deny all other access to this proxy
http_access deny all

===end===
You have no user in this group, yet since it is the first rule, EVERY user has to be checked is he/she ini-sinlimite at xxxxxxx.LAN  group. What for, if group is not used? And it is not used in delay_class either.
When squid knows that user is not allowed by i-sinlimite, next rule (sin_autenticacion) is launched, but this is different, list-based ACL, don't now what is on the list - my guess is that's the list of sites that does not require an authentication. If so, it makes no sense - that kind of rule should be above any ACL that requires authentication.
So, most users will access most sites by rule i-limitado, but before, any user has to be checked by i-sinlimite. Makes no sense, really.
Second thing is that most of these ACLs are doing nothing, since your allow everything (!negation is disabled by # sign). Save some RAM consumed by helpers and reorganize your config.

Stats for i-sinlimite look good, although avg service time: -1441 msec is wrong (don't know why). Since that rule affects every user, delay caused by this hepler is added to every user's connection. As long as requests sent = recieved, there is no disaster anyway - users can browse The internet. Once more, remove that ACL and disable hepler.

IMHO you should build a test squid and do some practical learning how things work.

PS. Post your squid.conf every time; I rememer it from different thread, someone else may not.

-- 
Greets, Dijx

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170518/1a6c9084/attachment.htm>

From yvoinov at gmail.com  Thu May 18 13:55:13 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 18 May 2017 19:55:13 +0600
Subject: [squid-users] Squid works with ssl bump in intercept mode and
 root certificate in browser, but apps does not work
In-Reply-To: <1495103182661-4682451.post@n4.nabble.com>
References: <1495103182661-4682451.post@n4.nabble.com>
Message-ID: <6e97dcc7-254a-7cae-679d-2bb66dfb55a7@gmail.com>

The issue is crystal:

tlsv1 alert unknown ca

Check you configured CA bundle available for squid.

Either FB, Twitter works via browser.

Apps (usually uses from mobiles) also required to install proxy CA into devices. If they pinned, just write splice acl to pass it without bump.


18.05.2017 16:26, arun.xavier ?????:
> tlsv1 alert unknown ca


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170518/d1b3fac9/attachment.sig>

From dijxie at gmail.com  Thu May 18 14:04:43 2017
From: dijxie at gmail.com (Dijxie)
Date: Thu, 18 May 2017 16:04:43 +0200
Subject: [squid-users] Documentation for squidclient?
In-Reply-To: <1495112822444-4682458.post@n4.nabble.com>
References: <1495111693229-4682457.post@n4.nabble.com>
 <1495112822444-4682458.post@n4.nabble.com>
Message-ID: <65d362a3-0b6d-f9a2-c028-b039a039f09d@gmail.com>

W dniu 18.05.2017 o 15:07, erdosain9 pisze:
> And for example, if i have this
>
> Negotiate Authenticator Statistics:
> program: /lib64/squid/negotiate_kerberos_auth
> number active: 20 of 20 (0 shutting down)
> requests sent: 23980
> replies received: 23980
> queue length: 0
> avg service time: 8 msec
>
>     ID #	     FD	    PID	 # Requests	  # Replies	 Flags	   Time	 Offset
> Request
>       21	     18	   2159	      15266	      15266	     	  0.034	      0	(none)
>       22	     20	   2160	       4016	       4016	     	  0.167	      0	(none)
>       23	     26	   2161	       1827	       1827	     	  0.225	      0	(none)
>       24	     34	   2162	       1063	       1063	     	  0.142	      0	(none)
>       25	     36	   2167	        674	        674	     	  0.113	      0	(none)
>       26	     40	   2169	        427	        427	     	  0.134	      0	(none)
>       27	     44	   2170	        251	        251	     	  0.134	      0	(none)
>       28	     48	   2172	        171	        171	     	  0.073	      0	(none)
>       29	     55	   2174	        106	        106	     	  0.299	      0	(none)
>       30	    213	   3167	         64	         64	     	  0.298	      0	(none)
>       31	    216	   3168	         41	         41	     	  0.297	      0	(none)
>       32	    218	   3169	         26	         26	     	  0.250	      0	(none)
>       33	    217	   3170	         15	         15	     	  0.297	      0	(none)
>       37	     99	   6631	         10	         10	     	  0.243	      0	(none)
>       38	    106	   6632	          7	          7	     	  0.171	      0	(none)
>       39	    124	   7630	          4	          4	     	  0.112	      0	(none)
>       40	    129	   7631	          4	          4	     	  0.306	      0	(none)
>       41	    263	  18079	          3	          3	     	  0.306	      0	(none)
>       42	    266	  18080	          3	          3	     	  0.404	      0	(none)
>       43	    108	  18081	          2	          2	     	  0.401	      0	(none)
>
> Flags key:
>
>     B = BUSY
>     C = CLOSING
>     R = RESERVED
>     S = SHUTDOWN PENDING
>     P = PLACEHOLDER
>
> 20 of 20 authenticators are in use but, there is no busy... so... i have to
> increase the number of authenticators or not?
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Documentation-for-squidclient-tp4682457p4682458.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

No need to. Although, in corporate reality there is always sooner or 
later situation when someone sends an e-mail to all users "Go to 
www.some.domain and do something instantly. These are the cases that may 
make life hard. Above shows that 20 is overkill , but only in the period 
of time when stats were collected.

-- 
Greets, Dijx.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170518/78c80405/attachment.htm>

From rousskov at measurement-factory.com  Thu May 18 14:26:55 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 18 May 2017 08:26:55 -0600
Subject: [squid-users] Documentation for Cache Manager?
In-Reply-To: <1495111693229-4682457.post@n4.nabble.com>
References: <1495111693229-4682457.post@n4.nabble.com>
Message-ID: <d98c69d0-af87-85aa-394d-a93f43fc3174@measurement-factory.com>

On 05/18/2017 06:48 AM, erdosain9 wrote:

> Where i can find documentation for the opcion on squidclient, many of them
> are self-explanatory but for example this:

You are not looking for squidclient documentation! You are looking for
Cache Manager reports (a.k.a. pages) documentation. The "mgr:X" URN that
you use with squidclient is just a convenient shorthand for a Cache
Manager page X URL.

    http://wiki.squid-cache.org/Features/CacheManager

Some Cache Manager reports are documented at the above URL. When you
figure out what an undocumented report means, please consider adding a
wiki page to document what you have found.

IIRC, Squid Books have documentation for some of the cache manager pages
that are not documented on Squid wiki.


HTH,

Alex.



From erdosain9 at gmail.com  Thu May 18 15:55:40 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 18 May 2017 08:55:40 -0700 (PDT)
Subject: [squid-users] Documentation for squidclient?
In-Reply-To: <65d362a3-0b6d-f9a2-c028-b039a039f09d@gmail.com>
References: <1495111693229-4682457.post@n4.nabble.com>
 <1495112822444-4682458.post@n4.nabble.com>
 <65d362a3-0b6d-f9a2-c028-b039a039f09d@gmail.com>
Message-ID: <1495122940560-4682464.post@n4.nabble.com>

Thanks you all!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Documentation-for-squidclient-tp4682457p4682464.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Thu May 18 16:15:59 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 18 May 2017 10:15:59 -0600
Subject: [squid-users] Squid works with ssl bump in intercept mode and
 root certificate in browser, but apps does not work
In-Reply-To: <1495111616447-4682456.post@n4.nabble.com>
References: <1495103182661-4682451.post@n4.nabble.com>
 <277d6606-89db-da7b-9d18-cd40fa8b11f5@urlfilterdb.com>
 <afc6dbd4-8bf0-817d-1baa-578a34b95436@treenet.co.nz>
 <1495111616447-4682456.post@n4.nabble.com>
Message-ID: <9cab7b63-72dc-53f9-3f8f-81c6dabb0f9c@measurement-factory.com>

On 05/18/2017 06:46 AM, arun.xavier wrote:

> is it possible to configure squid to peek/splice pinned requests? 

It is impossible. The TLS client decides which certificates are pinned
to which servers. Squid cannot know that because the client commitment
to pin is not expressed in the TLS protocol.

Said that, please do pay attention to Yuri's response quoted below. Yuri
has identified your immediate problem, which is _not_ pinning.

Alex.

> On 05/18/2017 07:55 AM, Yuri wrote:
>> The issue is crystal:
>> 
>> tlsv1 alert unknown ca
>> 
>> Check you configured CA bundle available for squid.



From rousskov at measurement-factory.com  Thu May 18 16:35:35 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 18 May 2017 10:35:35 -0600
Subject: [squid-users] custom error pages with stylesheets doesn't work
 for me
In-Reply-To: <20170518091750.GA246@bloms.de>
References: <20170518091750.GA246@bloms.de>
Message-ID: <22878de5-65fc-8727-4ab3-fbde91369b95@measurement-factory.com>

On 05/18/2017 03:17 AM, Dieter Bloms wrote:

> I wrote some custom error pages and activated style sheets in the header of the error pages like:
> 
> <style type="text/css">
> %l
> </style>
> 
> In the squid.conf file I set err_page_stylesheet to my stylesheet file and I restarted squid.
> My expectation was, that the content of this style sheet file will be included in the error page at the %l position.

Your expectation was correct.


> But the place between <style type="text/css"> and </style> is empty.
> Does anybody know how can I insert the content of the style sheet file to the error pages?

The steps you described above appear correct to me. Did you check for
errors in cache.log when starting Squid? Squid should complain if it
cannot load err_page_stylesheet but, unfortunately, Squid thinks that
you do not really care much about style and keeps running despite any
loading failures.

Temporary renaming the stylesheet file (so that Squid cannot load it)
will help you test whether you are looking for errors in the right place.


HTH,

Alex.



From erdosain9 at gmail.com  Thu May 18 16:27:41 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 18 May 2017 09:27:41 -0700 (PDT)
Subject: [squid-users] Documentation for squidclient?
In-Reply-To: <65d362a3-0b6d-f9a2-c028-b039a039f09d@gmail.com>
References: <1495111693229-4682457.post@n4.nabble.com>
 <1495112822444-4682458.post@n4.nabble.com>
 <65d362a3-0b6d-f9a2-c028-b039a039f09d@gmail.com>
Message-ID: <1495124861774-4682467.post@n4.nabble.com>

Look this

Negotiate Authenticator Statistics:
program: /lib64/squid/negotiate_kerberos_auth
number active: 25 of 25 (0 shutting down)
requests sent: 27331
replies received: 27306
queue length: 11
avg service time: 389 msec

I change to 25... and in this moment i have queue length 11....... there is
a way to know who is taken this? Because its strange, before this is not
happening... can be a virus? there is some way to know from what pc came
this?

(really sorry for my english....... i know this is not to readable).



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Documentation-for-squidclient-tp4682457p4682467.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Thu May 18 16:31:19 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 18 May 2017 09:31:19 -0700 (PDT)
Subject: [squid-users] Documentation for squidclient?
In-Reply-To: <1495124861774-4682467.post@n4.nabble.com>
References: <1495111693229-4682457.post@n4.nabble.com>
 <1495112822444-4682458.post@n4.nabble.com>
 <65d362a3-0b6d-f9a2-c028-b039a039f09d@gmail.com>
 <1495124861774-4682467.post@n4.nabble.com>
Message-ID: <1495125079578-4682468.post@n4.nabble.com>

and 35, someone it's eating...and by the way the first "error" (a lot of
numbers and letters its happening)

Negotiate Authenticator Statistics:
program: /lib64/squid/negotiate_kerberos_auth
number active: 35 of 35 (0 shutting down)
requests sent: 35222
replies received: 35221
queue length: 0
avg service time: 105 msec

   ID #	     FD	    PID	 # Requests	  # Replies	 Flags	   Time	 Offset
Request
    209	    113	   7534	        557	        556	B R  	  0.000	      0	YR
YIIGXQYGKwYBBQUCoIIGUTCCBk2gMDAuBgkqhkiC9xIBAgIGCSqGSIb3EgECAgYKKwYBBAGCNwICHgYKKwYBBAGCNwICCqKCBhcEggYTYIIGDwYJKoZIhvcSAQICAQBuggX+MIIF+qADAgEFoQMCAQ6iBwMFACAAAACjggSQYYIEjDCCBIigAwIBBaEMGwpFTVBEREguTEFOoiMwIaADAgECoRo
wGBsESFRUUBsQc3F1aWQuZW1wZGRoLmxhbqOCBEwwggRIoAMCARKhAwIBAqKCBDoEggQ2jpSodyZYVva7UV1lpeFDneeTonYRIuPbWQrRHapGngHJsxJ0Sb/saB97FH3aC3DuJgDF5eJIgrDqh38gksmi+zd7WhOWF7r9iRudcgHSnYmSYS9hxrMNEaoyBd0kKlO2it11WDBYb0tdd8OZKlFzYF+T4r714kl52a2fvHrJl5M3RB0QcHlrqngBoANinyZkvCZLpWkLtGJ5PC0jutoRvCX0KT6Znth2GwotJjOUftR4rQR0SfgQuxGkqcOsku2/xhJ88pMMo+7R6F3Crx0d391NS0F/4DWSk/JYsPOfEoemFKQPRWGQyQvLJ4Y78obg48PnMv9xhtsbUGB+LdYMWIAjKGFUDK4RGFPJtEnmhsOt6LIHi+Yqo3Ravna0mq61+xSFtzGJRuHTptpACxy/F+3tsSIIWsTdyVMHIBY4TH/5IXgFG2xc06kt8XmQaWvvByxZhBWn97W8ynrgR0y9Eg3YwqDi1YZtDGKc1XqbExMAw2bWlRNI3Oo6F8czcekK/H0Yrzm9sgXmmHHqFGGoJBBeqNZXQ+j8FhJ7LuXLg3B1Vki8XWaIP21LQcR/kLj2QvmMdZzLo2lglJIaUVlPnTFBEA3/ACAT2NHm0j4rZhEirf5+k45w/gz6fAlkbYWfISAqw20prIDbjMuzV+Z9XcxU9mZH0QuSIhV4wYNfZMh1VakBw00B9/5il/xqoXf15ra/vvopOib8WHztAsUwi+NLWsLichIh7fmrW2+U1D0XfSj8G2HhNus71ZsffYN0HZHsxz4ESlhAoxOLj/7eZLyNXL/zchrQspw+1URE1aizx6ui4oOZ0u/2QjPF0as/1+XjvS9VzSSCypx6gLMCXUAVPnVQayG0HF1OumIXvdHEhn5lyzng6qk5KYqbJcFGi+yHsQGLzaBjvv704ldsSucKnrXtmjxyZIapt10frNXVHa42yp+DAfaCGJBTQdsbD/6Y1OIvgpOzr0VEkzUFaYoGCMMqT7yRdWxdXewvpb8hLNYwTNJwepIYO15Y6n2a+R5HLCh5l1arnAgn1iIdiB86NoL0gMNhgQ8sg6ow3oNRnjzylQN/wqNFgouymk8fpp/Z1/vr3zq3wn8GEpoEKFgkYlM8S9b700lai85apEO5RF/92Fu150+kk6j/zBgkASdCHF7NHu4ljVcaUQ2Pn/vjNKopQ2AfAw/eLvbEoi47tRbvq+cQo71VJxrbqu+d6N+9Me1K6RIjrauPhnxmqtv8jmzUEd7eMSlFS1Nhcm/zbiXffS1z1+sattSADqr/r9vz/stT1UIPUvTGECSGscwzO9eBx2KqNd64Y8ijgo8r7oZfGPy5BEYc6Kme8iehWdXMjIW4CDoKJd5rbJ+mn2l0ZKsm4141ZOjr/N64PZZRMFTax3ejDyefXs101kKJpfkCJjPugzFCu6MGvk5ZcvrtSjefCqSCAU8wggFLoAMCARKiggFCBIIBPnk2DODYIW0g4hXFKmoKlnIHRezRwxL/E22eI7mjihUd/z7PQ2V6IQdx/ScsgKyMHcsaG5naiQliCf7/Sl7QQbpxypdbT0/7THdMBd67fMLNZ3/7I78+dS90BD+XODtWJyC/+vQdfHGBOSFfAnetzaFJGsfbni4qMrF1V8onHnmwq800CrN1WoQt6ADBwBwFbMIHqSLUbaBmye3AQiZ16L646xGw7GqCwPKeFUkrXeG17iD0NRQKUr3nPD0UZtOf36YK5J+/HQ68+ou6d2as4Rjx7FHQVR9RLKeCj6ZnBZKeAp5P/SmLaj1+0k5F5Ra71KZslWyzLDFw7/unGUksNkpP71Gl9B3XMavdhPqfOSrczGnW5Rr4nJ7oLikj06IdsCSmhub+TUN1qxn3/XNfHu08wA0lJv9mEZpCpaKSdA==\n
    210	    131	   7535	        490	        490	     	  0.332	      0	(none)
    211	    144	   7536	        435	        435	     	  0.550	      0	(none)
    212	    189	   7537	        398	        398	     	  0.825	      0	(none)
    213	     27	   7538	        364	        364	     	  0.566	      0	(none)
    214	    214	   7539	        331	        331	     	  0.783	      0	(none)
    215	    225	   7540	        307	        307	     	  0.500	      0	(none)
    216	    238	   7541	        284	        284	     	  0.838	      0	(none)
    217	     96	   7542	        288	        288	     	  0.587	      0	(none)
    218	     76	   7543	        272	        272	     	  0.626	      0	(none)
    219	    227	   7544	        245	        245	     	  0.796	      0	(none)
    220	    275	   7545	        241	        241	     	  0.427	      0	(none)
    221	    299	   7546	        236	        236	     	  0.694	      0	(none)
    222	    308	   7547	        228	        228	     	  0.784	      0	(none)
    223	    241	   7548	        215	        215	     	  0.919	      0	(none)
    224	    265	   7549	        210	        210	     	  0.842	      0	(none)
    225	    318	   7550	        198	        198	     	  0.728	      0	(none)
    226	    321	   7551	        190	        190	     	  0.770	      0	(none)
    227	    233	   7552	        183	        183	     	  0.527	      0	(none)
    228	    242	   7553	        171	        171	     	  0.819	      0	(none)
    229	    190	   7554	        169	        169	     	  0.690	      0	(none)
    230	    272	   7555	        155	        155	     	  0.636	      0	(none)
    231	    353	   7588	        147	        147	     	  0.683	      0	(none)
    232	    357	   7589	        138	        138	     	  0.623	      0	(none)
    233	    340	   7590	        122	        122	     	  0.750	      0	(none)
    234	    362	   7591	         98	         98	     	  0.529	      0	(none)
    235	    365	   7592	         87	         87	     	  0.655	      0	(none)
    236	    207	   7593	         80	         80	     	  0.654	      0	(none)
    237	     40	   7594	         66	         66	     	  0.526	      0	(none)
    238	    382	   7595	         58	         58	     	  0.653	      0	(none)
    239	     74	   7596	         44	         44	     	  0.525	      0	(none)
    240	     50	   7597	         37	         37	     	  0.645	      0	(none)
    241	    156	   7598	         29	         29	     	  0.645	      0	(none)
    242	    206	   7599	         24	         24	     	  0.965	      0	(none)
    243	    414	   7600	         23	         23	     	  0.940	      0	(none)

Flags key:

   B = BUSY
   C = CLOSING
   R = RESERVED
   S = SHUTDOWN PENDING
   P = PLACEHOLDER




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Documentation-for-squidclient-tp4682457p4682468.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Thu May 18 16:33:53 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 18 May 2017 09:33:53 -0700 (PDT)
Subject: [squid-users] Documentation for squidclient?
In-Reply-To: <1495125079578-4682468.post@n4.nabble.com>
References: <1495111693229-4682457.post@n4.nabble.com>
 <1495112822444-4682458.post@n4.nabble.com>
 <65d362a3-0b6d-f9a2-c028-b039a039f09d@gmail.com>
 <1495124861774-4682467.post@n4.nabble.com>
 <1495125079578-4682468.post@n4.nabble.com>
Message-ID: <1495125233911-4682469.post@n4.nabble.com>

Negotiate Authenticator Statistics:
program: /lib64/squid/negotiate_kerberos_auth
number active: 35 of 35 (0 shutting down)
requests sent: 39928
replies received: 39893
queue length: 40
avg service time: 854 msec

   ID #	     FD	    PID	 # Requests	  # Replies	 Flags	   Time	 Offset
Request
    209	    113	   7534	        856	        855	B R  	  2.022	      0	YR
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\n
    210	    131	   7535	        764	        763	B R  	  0.104	      0	YR
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\n
    211	    144	   7536	        690	        689	B R  	  0.104	      0	YR
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\n
    212	    189	   7537	        639	        638	B R  	  0.628	      0	YR
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\n
    213	     27	   7538	        579	        578	B R  	  2.473	      0	YR
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\n
    214	    214	   7539	        538	        537	B R  	  1.526	      0	YR
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\n
    215	    225	   7540	        502	        501	B R  	  1.815	      0	YR
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\n
    216	    238	   7541	        472	        471	B R  	  2.006	      0	YR
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\n
    217	     96	   7542	        458	        457	B R  	  1.743	      0	YR
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\n
    218	     76	   7543	        428	        427	B R  	  1.983	      0	YR
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\n
    219	    227	   7544	        399	        398	B R  	  0.000	      0	YR
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\n
    220	
erdosain9 wrote
> ETC
> and 35, someone it's eating...and by the way the first "error" (a lot of
> numbers and letters its happening)
> 
> Negotiate Authenticator Statistics:
> program: /lib64/squid/negotiate_kerberos_auth
> number active: 35 of 35 (0 shutting down)
> requests sent: 35222
> replies received: 35221
> queue length: 0
> avg service time: 105 msec
> 
>    ID #	     FD	    PID	 # Requests	  # Replies	 Flags	   Time	 Offset
> Request
>     209	    113	   7534	        557	        556	B R  	  0.000	      0	YR
> YIIGXQYGKwYBBQUCoIIGUTCCBk2gMDAuBgkqhkiC9xIBAgIGCSqGSIb3EgECAgYKKwYBBAGCNwICHgYKKwYBBAGCNwICCqKCBhcEggYTYIIGDwYJKoZIhvcSAQICAQBuggX+MIIF+qADAgEFoQMCAQ6iBwMFACAAAACjggSQYYIEjDCCBIigAwIBBaEMGwpFTVBEREguTEFOoiMwIaADAgECoRo
> wGBsESFRUUBsQc3F1aWQuZW1wZGRoLmxhbqOCBEwwggRIoAMCARKhAwIBAqKCBDoEggQ2jpSodyZYVva7UV1lpeFDneeTonYRIuPbWQrRHapGngHJsxJ0Sb/saB97FH3aC3DuJgDF5eJIgrDqh38gksmi+zd7WhOWF7r9iRudcgHSnYmSYS9hxrMNEaoyBd0kKlO2it11WDBYb0tdd8OZKlFzYF+T4r714kl52a2fvHrJl5M3RB0QcHlrqngBoANinyZkvCZLpWkLtGJ5PC0jutoRvCX0KT6Znth2GwotJjOUftR4rQR0SfgQuxGkqcOsku2/xhJ88pMMo+7R6F3Crx0d391NS0F/4DWSk/JYsPOfEoemFKQPRWGQyQvLJ4Y78obg48PnMv9xhtsbUGB+LdYMWIAjKGFUDK4RGFPJtEnmhsOt6LIHi+Yqo3Ravna0mq61+xSFtzGJRuHTptpACxy/F+3tsSIIWsTdyVMHIBY4TH/5IXgFG2xc06kt8XmQaWvvByxZhBWn97W8ynrgR0y9Eg3YwqDi1YZtDGKc1XqbExMAw2bWlRNI3Oo6F8czcekK/H0Yrzm9sgXmmHHqFGGoJBBeqNZXQ+j8FhJ7LuXLg3B1Vki8XWaIP21LQcR/kLj2QvmMdZzLo2lglJIaUVlPnTFBEA3/ACAT2NHm0j4rZhEirf5+k45w/gz6fAlkbYWfISAqw20prIDbjMuzV+Z9XcxU9mZH0QuSIhV4wYNfZMh1VakBw00B9/5il/xqoXf15ra/vvopOib8WHztAsUwi+NLWsLichIh7fmrW2+U1D0XfSj8G2HhNus71ZsffYN0HZHsxz4ESlhAoxOLj/7eZLyNXL/zchrQspw+1URE1aizx6ui4oOZ0u/2QjPF0as/1+XjvS9VzSSCypx6gLMCXUAVPnVQayG0HF1OumIXvdHEhn5lyzng6qk5KYqbJcFGi+yHsQGLzaBjvv704ldsSucKnrXtmjxyZIapt10frNXVHa42yp+DAfaCGJBTQdsbD/6Y1OIvgpOzr0VEkzUFaYoGCMMqT7yRdWxdXewvpb8hLNYwTNJwepIYO15Y6n2a+R5HLCh5l1arnAgn1iIdiB86NoL0gMNhgQ8sg6ow3oNRnjzylQN/wqNFgouymk8fpp/Z1/vr3zq3wn8GEpoEKFgkYlM8S9b700lai85apEO5RF/92Fu150+kk6j/zBgkASdCHF7NHu4ljVcaUQ2Pn/vjNKopQ2AfAw/eLvbEoi47tRbvq+cQo71VJxrbqu+d6N+9Me1K6RIjrauPhnxmqtv8jmzUEd7eMSlFS1Nhcm/zbiXffS1z1+sattSADqr/r9vz/stT1UIPUvTGECSGscwzO9eBx2KqNd64Y8ijgo8r7oZfGPy5BEYc6Kme8iehWdXMjIW4CDoKJd5rbJ+mn2l0ZKsm4141ZOjr/N64PZZRMFTax3ejDyefXs101kKJpfkCJjPugzFCu6MGvk5ZcvrtSjefCqSCAU8wggFLoAMCARKiggFCBIIBPnk2DODYIW0g4hXFKmoKlnIHRezRwxL/E22eI7mjihUd/z7PQ2V6IQdx/ScsgKyMHcsaG5naiQliCf7/Sl7QQbpxypdbT0/7THdMBd67fMLNZ3/7I78+dS90BD+XODtWJyC/+vQdfHGBOSFfAnetzaFJGsfbni4qMrF1V8onHnmwq800CrN1WoQt6ADBwBwFbMIHqSLUbaBmye3AQiZ16L646xGw7GqCwPKeFUkrXeG17iD0NRQKUr3nPD0UZtOf36YK5J+/HQ68+ou6d2as4Rjx7FHQVR9RLKeCj6ZnBZKeAp5P/SmLaj1+0k5F5Ra71KZslWyzLDFw7/unGUksNkpP71Gl9B3XMavdhPqfOSrczGnW5Rr4nJ7oLikj06IdsCSmhub+TUN1qxn3/XNfHu08wA0lJv9mEZpCpaKSdA==\n
>     210	    131	   7535	        490	        490	     	  0.332	      0
> (none)
>     211	    144	   7536	        435	        435	     	  0.550	      0
> (none)
>     212	    189	   7537	        398	        398	     	  0.825	      0
> (none)
>     213	     27	   7538	        364	        364	     	  0.566	      0
> (none)
>     214	    214	   7539	        331	        331	     	  0.783	      0
> (none)
>     215	    225	   7540	        307	        307	     	  0.500	      0
> (none)
>     216	    238	   7541	        284	        284	     	  0.838	      0
> (none)
>     217	     96	   7542	        288	        288	     	  0.587	      0
> (none)
>     218	     76	   7543	        272	        272	     	  0.626	      0
> (none)
>     219	    227	   7544	        245	        245	     	  0.796	      0
> (none)
>     220	    275	   7545	        241	        241	     	  0.427	      0
> (none)
>     221	    299	   7546	        236	        236	     	  0.694	      0
> (none)
>     222	    308	   7547	        228	        228	     	  0.784	      0
> (none)
>     223	    241	   7548	        215	        215	     	  0.919	      0
> (none)
>     224	    265	   7549	        210	        210	     	  0.842	      0
> (none)
>     225	    318	   7550	        198	        198	     	  0.728	      0
> (none)
>     226	    321	   7551	        190	        190	     	  0.770	      0
> (none)
>     227	    233	   7552	        183	        183	     	  0.527	      0
> (none)
>     228	    242	   7553	        171	        171	     	  0.819	      0
> (none)
>     229	    190	   7554	        169	        169	     	  0.690	      0
> (none)
>     230	    272	   7555	        155	        155	     	  0.636	      0
> (none)
>     231	    353	   7588	        147	        147	     	  0.683	      0
> (none)
>     232	    357	   7589	        138	        138	     	  0.623	      0
> (none)
>     233	    340	   7590	        122	        122	     	  0.750	      0
> (none)
>     234	    362	   7591	         98	         98	     	  0.529	      0
> (none)
>     235	    365	   7592	         87	         87	     	  0.655	      0
> (none)
>     236	    207	   7593	         80	         80	     	  0.654	      0
> (none)
>     237	     40	   7594	         66	         66	     	  0.526	      0
> (none)
>     238	    382	   7595	         58	         58	     	  0.653	      0
> (none)
>     239	     74	   7596	         44	         44	     	  0.525	      0
> (none)
>     240	     50	   7597	         37	         37	     	  0.645	      0
> (none)
>     241	    156	   7598	         29	         29	     	  0.645	      0
> (none)
>     242	    206	   7599	         24	         24	     	  0.965	      0
> (none)
>     243	    414	   7600	         23	         23	     	  0.940	      0
> (none)
> 
> Flags key:
> 
>    B = BUSY
>    C = CLOSING
>    R = RESERVED
>    S = SHUTDOWN PENDING
>    P = PLACEHOLDER





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Documentation-for-squidclient-tp4682457p4682469.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chicago_computers at hotmail.com  Thu May 18 17:40:40 2017
From: chicago_computers at hotmail.com (chcs)
Date: Thu, 18 May 2017 10:40:40 -0700 (PDT)
Subject: [squid-users] Squid custom error page
In-Reply-To: <1495020726548-4682433.post@n4.nabble.com>
References: <1495020726548-4682433.post@n4.nabble.com>
Message-ID: <1495129240192-4682470.post@n4.nabble.com>

One more cuestion:
With 2 CA differents certificates to block twitter.com >> differents results 

Issuer: self-signed    0 10.0.0.100 TAG_NONE/403 4709 GET
https://www.twitter.com/ - HIER_NONE/- text/html
Result: no problem, it's show me squid custom error page
 
Issuer: Let's encript  0 10.0.0.100 TCP_DENIED/403 4714 CONNECT
www.twitter.com:443 - HIER_NONE/- text/html
Result: It doesnt show me squid custom error page

Why?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-custom-error-page-tp4682433p4682470.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Walter.H at mathemainzel.info  Thu May 18 18:12:46 2017
From: Walter.H at mathemainzel.info (Walter H.)
Date: Thu, 18 May 2017 20:12:46 +0200
Subject: [squid-users] Squid custom error page
In-Reply-To: <1495129240192-4682470.post@n4.nabble.com>
References: <1495020726548-4682433.post@n4.nabble.com>
 <1495129240192-4682470.post@n4.nabble.com>
Message-ID: <591DE41E.6050403@mathemainzel.info>

On 18.05.2017 19:40, chcs wrote:
> One more cuestion:
> With 2 CA differents certificates to block twitter.com>>  differents results
>
> Issuer: self-signed    0 10.0.0.100 TAG_NONE/403 4709 GET
> https://www.twitter.com/ - HIER_NONE/- text/html
> Result: no problem, it's show me squid custom error page
>
> Issuer: Let's encript  0 10.0.0.100 TCP_DENIED/403 4714 CONNECT
> www.twitter.com:443 - HIER_NONE/- text/html
> Result: It doesnt show me squid custom error page
>
> Why?
and what is the end entity certificate where the issuer is Let's encrypt?
(this might be the reason)

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170518/666227fc/attachment.bin>

From rousskov at measurement-factory.com  Thu May 18 18:42:15 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 18 May 2017 12:42:15 -0600
Subject: [squid-users] Squid custom error page
In-Reply-To: <1495129240192-4682470.post@n4.nabble.com>
References: <1495020726548-4682433.post@n4.nabble.com>
 <1495129240192-4682470.post@n4.nabble.com>
Message-ID: <56f0e164-d081-9ce8-8cdc-634949c1c017@measurement-factory.com>

On 05/18/2017 11:40 AM, chcs wrote:

> HTTPS/SSL Interception , Enable SSL filtering, splice all, CA: Let's Encript autority

> One more cuestion:
> With 2 CA differents certificates to block twitter.com >> differents results 
> 
> Issuer: self-signed    0 10.0.0.100 TAG_NONE/403 4709 GET
> https://www.twitter.com/ - HIER_NONE/- text/html
> Result: no problem, it's show me squid custom error page
>  
> Issuer: Let's encript  0 10.0.0.100 TCP_DENIED/403 4714 CONNECT
> www.twitter.com:443 - HIER_NONE/- text/html
> Result: It doesnt show me squid custom error page

Let's Encrypt does not issue CA certificates. You need a CA certificate
for an SslBump setup to work for more than one site. Let's Encrypt also
does not issue leaf certificates for www.twitter.com unless you control
www.twitter.com.

When you generated a self-signed certificate, you probably generated a
CA certificate. If you did not, then you will encounter problems if you
try to import that certificate in browsers/clients that require CA
certificates. See the OpenSSL command below for one way to check what
you have generated.

CA certificates have an x509 "Basic Constraints" extension with a
CA:TRUE constraint. For example:

> $ openssl x509 -in CA-priv+pub.pem -text -noout | fgrep -A 1 'Basic'
>             X509v3 Basic Constraints: 
>                 CA:TRUE

HTH,

Alex.



From squid3 at treenet.co.nz  Thu May 18 21:08:03 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 19 May 2017 09:08:03 +1200
Subject: [squid-users] Documentation for squidclient?
In-Reply-To: <1495125233911-4682469.post@n4.nabble.com>
References: <1495111693229-4682457.post@n4.nabble.com>
 <1495112822444-4682458.post@n4.nabble.com>
 <65d362a3-0b6d-f9a2-c028-b039a039f09d@gmail.com>
 <1495124861774-4682467.post@n4.nabble.com>
 <1495125079578-4682468.post@n4.nabble.com>
 <1495125233911-4682469.post@n4.nabble.com>
Message-ID: <40108344-b1da-93d2-ea40-a627ec29ed77@treenet.co.nz>

On 19/05/17 04:33, erdosain9 wrote:
> Negotiate Authenticator Statistics:
> program: /lib64/squid/negotiate_kerberos_auth
> number active: 35 of 35 (0 shutting down)
> requests sent: 39928
> replies received: 39893
> queue length: 40
> avg service time: 854 msec

Two things to take note of with these reports.

First is the queue length vs how many helpers are running. Each helper 
running has one row in the table. Your initial report with 20 helpers 
had no queue, and showed that all 20 helpers had been needed at one 
point, but the top-5 only needed a few times.
  IMO that is not overkill, but close to what you actually need. In a 
perfect world there should be some helpers not needed at all, but peak 
traffic does happen.

Second thing to notice is the "avg service time". In that same initial 
report it showed avg was 9ms - that is good (might be better if you tune 
the auth backend for speed, but a few ms is okay). These later reports 
when you were experimenting it fluctuates between 300ms and 850ms. That 
can be kind of bad - if it remains high with just normal traffic that is 
something to fix. That said it may have been an artifact from the delay 
caused by reconfiguring and restarting all the helpers, which is 
supported by the low number of requests processed by the heaviest used 
helper (~500).


Amos



From squid3 at treenet.co.nz  Thu May 18 21:12:33 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 19 May 2017 09:12:33 +1200
Subject: [squid-users] Documentation for squidclient?
In-Reply-To: <1495113604772-4682459.post@n4.nabble.com>
References: <1495111693229-4682457.post@n4.nabble.com>
 <1495113604772-4682459.post@n4.nabble.com>
Message-ID: <42682172-6f00-9c3f-0f83-b8f29f3efbd9@treenet.co.nz>

On 19/05/17 01:20, erdosain9 wrote:
> And... for last....
>
> How i read this??
>
> Delay pools configured: 5
>
> Pool: 1
> 	Class: 2
>
> 	Aggregate:
> 		Max: 1000000
> 		Restore: 1000000
> 		Current: 1000000
>
> 	Individual:
> 		Max: 512000
> 		Restore: 50000
> 		Current: 124:512000 67:512000 120:512000 127:512000 9:512000 26:214810
> 64:512000 169:512000 156:512000

For each delay pool in your squid.conf it describes the details you have 
configured.

The "Current:" section lists the number of active connections which are 
using that pool, and how much bandwidth each has available.
eg, clients #124, 67, 120, 127, 9, 64, 169, 156 are connected by not 
used any bandwidth this second. Whereas client #26 has used about half 
their allocation.


Amos



From dan at getbusi.com  Fri May 19 03:47:00 2017
From: dan at getbusi.com (Dan Charlesworth)
Date: Fri, 19 May 2017 13:47:00 +1000
Subject: [squid-users] Rock store size not decreasing
Message-ID: <CAN8nrKBTE-HpHMDx9mdaO9kjv1VW2B1GORxGN7ZN4uMacjQ0Ag@mail.gmail.com>

Hey all

I'm fairly new to rock caching. With aufs, if you reduce the cache size in
the config it'll start slowly reducing it down the new size.

I've done that with a ~137GB rock store (reduced it to 10240MB) but it
'aint changing after reloading the config.

cache_dir rock /var/spool/squid/rock 10240

# du --max-depth=1 /var/spool/squid/ -h

137G /var/spool/squid/rock

What am I missing?

Best,
Dan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170519/2788cdee/attachment.htm>

From squid at bloms.de  Fri May 19 08:10:15 2017
From: squid at bloms.de (Dieter Bloms)
Date: Fri, 19 May 2017 10:10:15 +0200
Subject: [squid-users] custom error pages with stylesheets doesn't work
 for me
In-Reply-To: <22878de5-65fc-8727-4ab3-fbde91369b95@measurement-factory.com>
References: <20170518091750.GA246@bloms.de>
 <22878de5-65fc-8727-4ab3-fbde91369b95@measurement-factory.com>
Message-ID: <20170519081015.GA329@bloms.de>

Hello Alex,

On Thu, May 18, Alex Rousskov wrote:

> On 05/18/2017 03:17 AM, Dieter Bloms wrote:
> 
> > I wrote some custom error pages and activated style sheets in the header of the error pages like:
> > 
> > <style type="text/css">
> > %l
> > </style>
> > 
> > In the squid.conf file I set err_page_stylesheet to my stylesheet file and I restarted squid.
> > My expectation was, that the content of this style sheet file will be included in the error page at the %l position.
> 
> Your expectation was correct.
> 
> 
> > But the place between <style type="text/css"> and </style> is empty.
> > Does anybody know how can I insert the content of the style sheet file to the error pages?
> 
> The steps you described above appear correct to me. Did you check for
> errors in cache.log when starting Squid? Squid should complain if it
> cannot load err_page_stylesheet but, unfortunately, Squid thinks that
> you do not really care much about style and keeps running despite any
> loading failures.
> 
> Temporary renaming the stylesheet file (so that Squid cannot load it)
> will help you test whether you are looking for errors in the right place.

thank you for the hint.
Squid had no read permission to this file. After right permissions
it worked.
But there was _no_ error message in the cache log file.
I found the wrong permission with the help of strace command.
It would be nice, when squid drop a note, that it can't read the file.


-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
>From field.


From webmaster at squidblacklist.org  Fri May 19 09:03:17 2017
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Fri, 19 May 2017 04:03:17 -0500
Subject: [squid-users] custom error pages with stylesheets doesn't work
 for me
In-Reply-To: <20170519081015.GA329@bloms.de>
References: <20170518091750.GA246@bloms.de>
 <22878de5-65fc-8727-4ab3-fbde91369b95@measurement-factory.com>
 <20170519081015.GA329@bloms.de>
Message-ID: <43018788-2cb6-4dc4-b8ac-de333efa2ca7@squidblacklist.org>

You might actually be in the wrong directory, I wouldnt be surprised if 
this was the case, particularly if you are using a debian or ubuntu box.

Heres a hint.  You need to be editing the following default document 
instead...

/usr/share/squid-langpack/templates/ERR_ACCESS_DENIED

And make sure your css is within your style tag.

<style>.someclass{background:#000;}</style>

And make sure you place this css inside the tag <head></head>


On 5/19/2017 3:10 AM, Dieter Bloms wrote:
> Hello Alex,
>
> On Thu, May 18, Alex Rousskov wrote:
>
>> On 05/18/2017 03:17 AM, Dieter Bloms wrote:
>>
>>> I wrote some custom error pages and activated style sheets in the header of the error pages like:
>>>
>>> <style type="text/css">
>>> %l
>>> </style>
>>>
>>> In the squid.conf file I set err_page_stylesheet to my stylesheet file and I restarted squid.
>>> My expectation was, that the content of this style sheet file will be included in the error page at the %l position.
>> Your expectation was correct.
>>
>>
>>> But the place between <style type="text/css"> and </style> is empty.
>>> Does anybody know how can I insert the content of the style sheet file to the error pages?
>> The steps you described above appear correct to me. Did you check for
>> errors in cache.log when starting Squid? Squid should complain if it
>> cannot load err_page_stylesheet but, unfortunately, Squid thinks that
>> you do not really care much about style and keeps running despite any
>> loading failures.
>>
>> Temporary renaming the stylesheet file (so that Squid cannot load it)
>> will help you test whether you are looking for errors in the right place.
> thank you for the hint.
> Squid had no read permission to this file. After right permissions
> it worked.
> But there was _no_ error message in the cache log file.
> I found the wrong permission with the help of strace command.
> It would be nice, when squid drop a note, that it can't read the file.
>
>

-- 
--

Signed,

Benjamin E. Nichols
http://www.squidblacklist.org

1-405-397-1360 - Call Anytime.



From dijxie at gmail.com  Fri May 19 12:44:44 2017
From: dijxie at gmail.com (Dijxie)
Date: Fri, 19 May 2017 14:44:44 +0200
Subject: [squid-users] How to redirect all squid's error pages to one?
Message-ID: <f4ba5710-0557-8310-8bdf-1cb620b7abf8@gmail.com>

Hi list,

1. I'd like to redirect **all** squid error pages to one, universal, 
preferably internal squid error page. For sure I can symlink every error 
page to one, but is there a clener way?
I'm not sure if I get it: http://www.squid-cache.org/Doc/config/deny_info/

2. And then, using %e code and presumably external js nested in this 
page, display more detailed info for some error numbers.

Can it be done? Can squid internal web server handle easy js?

-- 
Greets, Dijx

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170519/b2accbfe/attachment.htm>

From uhlar at fantomas.sk  Fri May 19 12:54:22 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 19 May 2017 14:54:22 +0200
Subject: [squid-users] How to redirect all squid's error pages to one?
In-Reply-To: <f4ba5710-0557-8310-8bdf-1cb620b7abf8@gmail.com>
References: <f4ba5710-0557-8310-8bdf-1cb620b7abf8@gmail.com>
Message-ID: <20170519125422.GE4267@fantomas.sk>

On 19.05.17 14:44, Dijxie wrote:
>1. I'd like to redirect **all** squid error pages to one, universal, 
>preferably internal squid error page. For sure I can symlink every 
>error page to one, but is there a clener way?
>I'm not sure if I get it: http://www.squid-cache.org/Doc/config/deny_info/
>
>2. And then, using %e code and presumably external js nested in this 
>page, display more detailed info for some error numbers.
>
>Can it be done? Can squid internal web server handle easy js?

no, unless using icap/ecap. 

But what's the point to direct all error messages (with language
autodection) into one, when you also want to make them different by
javascript?
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
It's now safe to throw off your computer.


From squid3 at treenet.co.nz  Fri May 19 13:13:32 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 May 2017 01:13:32 +1200
Subject: [squid-users] How to redirect all squid's error pages to one?
In-Reply-To: <f4ba5710-0557-8310-8bdf-1cb620b7abf8@gmail.com>
References: <f4ba5710-0557-8310-8bdf-1cb620b7abf8@gmail.com>
Message-ID: <1d9af110-0fb8-0d12-e340-d9f5503785b5@treenet.co.nz>

On 20/05/17 00:44, Dijxie wrote:
>
> Hi list,
>
> 1. I'd like to redirect **all** squid error pages to one, universal, 
> preferably internal squid error page. For sure I can symlink every 
> error page to one, but is there a clener way?
> I'm not sure if I get it: http://www.squid-cache.org/Doc/config/deny_info/
>

deny_info is to provide some non-default response payload (aka. "page") 
instead of the 403 when an ACL performs administrative denial of access.

As to your purpose; What is this universal message that conveys all 
possible environmental conditions to the reader in one simple text?

Keep in mind that the reader may not be human; some errors are 
explanations of indirect problems and only visible when the accompanying 
machine instructions reach a failure (eg 30x, 401, 407 messages); and 
some are not errors at all but instructions for a user on what they need 
to do to continue with communication (eg 511 login pages).

> 2. And then, using %e code and presumably external js nested in this 
> page, display more detailed info for some error numbers.
>
> Can it be done? Can squid internal web server handle easy js?
>

Squid is not a web server. On "error" it produces message payloads which 
happen to contain HTML by default. Modern HTML can contain embedded 
scripts, but they are not interpreted by Squid as anything beyond opaque 
characters.


If you redirect all errors to one URL any information the client might 
have had about the error is destroyed.

The symlinking you though of is the "best" way to do what you are asking 
for. However, think carefully about what the purpose of displaying an 
error message is, see above.

Amos



From squid3 at treenet.co.nz  Fri May 19 13:29:20 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 May 2017 01:29:20 +1200
Subject: [squid-users] Rock store size not decreasing
In-Reply-To: <CAN8nrKBTE-HpHMDx9mdaO9kjv1VW2B1GORxGN7ZN4uMacjQ0Ag@mail.gmail.com>
References: <CAN8nrKBTE-HpHMDx9mdaO9kjv1VW2B1GORxGN7ZN4uMacjQ0Ag@mail.gmail.com>
Message-ID: <310d5774-dede-169b-e039-7d3f9532f5ec@treenet.co.nz>

On 19/05/17 15:47, Dan Charlesworth wrote:
> Hey all
>
> I'm fairly new to rock caching. With aufs, if you reduce the cache 
> size in the config it'll start slowly reducing it down the new size.
>
> I've done that with a ~137GB rock store (reduced it to 10240MB) but it 
> 'aint changing after reloading the config.

With UFS/AUFSdiskd the cache is stored in a directory tree with 
individual files per item. Reducing the size results in files being 
deleted from disk an the total size shrinks naturally without any 
special action by Squid.

Rock on the other hand has all content stored inside one file. That file 
gets initialized with the space configured and maybe grown if needed. 
But there is nothing I'm aware of to reinitialize it on smaller sizes 
being configured. Reducing the size does reduce the size of stuff using 
space *inside* the database file, but AFAIK not the file itself.

Amos



From squid3 at treenet.co.nz  Fri May 19 13:40:11 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 May 2017 01:40:11 +1200
Subject: [squid-users] custom error pages with stylesheets doesn't work
 for me
In-Reply-To: <20170519081015.GA329@bloms.de>
References: <20170518091750.GA246@bloms.de>
 <22878de5-65fc-8727-4ab3-fbde91369b95@measurement-factory.com>
 <20170519081015.GA329@bloms.de>
Message-ID: <6099f5cf-f117-09e1-b4fd-4e115c004cca@treenet.co.nz>

On 19/05/17 20:10, Dieter Bloms wrote:
> Hello Alex,
>
> On Thu, May 18, Alex Rousskov wrote:
>
>> On 05/18/2017 03:17 AM, Dieter Bloms wrote:
>>
>>> I wrote some custom error pages and activated style sheets in the header of the error pages like:
>>>
>>> <style type="text/css">
>>> %l
>>> </style>
>>>
>>> In the squid.conf file I set err_page_stylesheet to my stylesheet file and I restarted squid.
>>> My expectation was, that the content of this style sheet file will be included in the error page at the %l position.
>> Your expectation was correct.
>>
>>
>>> But the place between <style type="text/css"> and </style> is empty.
>>> Does anybody know how can I insert the content of the style sheet file to the error pages?
>> The steps you described above appear correct to me. Did you check for
>> errors in cache.log when starting Squid? Squid should complain if it
>> cannot load err_page_stylesheet but, unfortunately, Squid thinks that
>> you do not really care much about style and keeps running despite any
>> loading failures.
>>
>> Temporary renaming the stylesheet file (so that Squid cannot load it)
>> will help you test whether you are looking for errors in the right place.
> thank you for the hint.
> Squid had no read permission to this file. After right permissions
> it worked.
> But there was _no_ error message in the cache log file.
> I found the wrong permission with the help of strace command.
> It would be nice, when squid drop a note, that it can't read the file.

I just checked the code and do see a log entry being made at critical 
level. It does not say "ERROR" like most of those things should though, 
just the filename and the system error message (fixed that right now).

It may be that you missed it amongst the other informational startup 
messages, or that it is in the part of "cache.log" messages that are 
output before cache.log is opened - those lines currently go to stderr 
and/or your system messages log (where/what that is depends on your OS).

Amos



From squid at bloms.de  Fri May 19 13:56:38 2017
From: squid at bloms.de (Dieter Bloms)
Date: Fri, 19 May 2017 15:56:38 +0200
Subject: [squid-users] custom error pages with stylesheets doesn't work
 for me
In-Reply-To: <6099f5cf-f117-09e1-b4fd-4e115c004cca@treenet.co.nz>
References: <20170518091750.GA246@bloms.de>
 <22878de5-65fc-8727-4ab3-fbde91369b95@measurement-factory.com>
 <20170519081015.GA329@bloms.de>
 <6099f5cf-f117-09e1-b4fd-4e115c004cca@treenet.co.nz>
Message-ID: <20170519135638.GB329@bloms.de>

Hello Amos,

On Sat, May 20, Amos Jeffries wrote:

> On 19/05/17 20:10, Dieter Bloms wrote:
> >Hello Alex,
> >
> >On Thu, May 18, Alex Rousskov wrote:
> >
> >>On 05/18/2017 03:17 AM, Dieter Bloms wrote:
> >>
> >>>I wrote some custom error pages and activated style sheets in the header of the error pages like:
> >>>
> >>><style type="text/css">
> >>>%l
> >>></style>
> >>>
> >>>In the squid.conf file I set err_page_stylesheet to my stylesheet file and I restarted squid.
> >>>My expectation was, that the content of this style sheet file will be included in the error page at the %l position.
> >>Your expectation was correct.
> >>
> >>
> >>>But the place between <style type="text/css"> and </style> is empty.
> >>>Does anybody know how can I insert the content of the style sheet file to the error pages?
> >>The steps you described above appear correct to me. Did you check for
> >>errors in cache.log when starting Squid? Squid should complain if it
> >>cannot load err_page_stylesheet but, unfortunately, Squid thinks that
> >>you do not really care much about style and keeps running despite any
> >>loading failures.
> >>
> >>Temporary renaming the stylesheet file (so that Squid cannot load it)
> >>will help you test whether you are looking for errors in the right place.
> >thank you for the hint.
> >Squid had no read permission to this file. After right permissions
> >it worked.
> >But there was _no_ error message in the cache log file.
> >I found the wrong permission with the help of strace command.
> >It would be nice, when squid drop a note, that it can't read the file.
> 
> I just checked the code and do see a log entry being made at critical level.
> It does not say "ERROR" like most of those things should though, just the
> filename and the system error message (fixed that right now).

thank you very much, so I will see the message next time ;)


-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
From field.


From dijxie at gmail.com  Fri May 19 14:55:11 2017
From: dijxie at gmail.com (Dijxie)
Date: Fri, 19 May 2017 16:55:11 +0200
Subject: [squid-users] How to redirect all squid's error pages to one?
In-Reply-To: <1d9af110-0fb8-0d12-e340-d9f5503785b5@treenet.co.nz>
References: <f4ba5710-0557-8310-8bdf-1cb620b7abf8@gmail.com>
 <1d9af110-0fb8-0d12-e340-d9f5503785b5@treenet.co.nz>
Message-ID: <00381e8c-9d9c-50a8-f4d3-72c2a2e1f665@gmail.com>

W dniu 19.05.2017 o 15:13, Amos Jeffries pisze:
> On 20/05/17 00:44, Dijxie wrote:
>>
>> Hi list,
>>
>> 1. I'd like to redirect **all** squid error pages to one, universal, 
>> preferably internal squid error page. For sure I can symlink every 
>> error page to one, but is there a clener way?
>> I'm not sure if I get it: 
>> http://www.squid-cache.org/Doc/config/deny_info/
>>
>
> deny_info is to provide some non-default response payload (aka. 
> "page") instead of the 403 when an ACL performs administrative denial 
> of access.
>
> As to your purpose; What is this universal message that conveys all 
> possible environmental conditions to the reader in one simple text?
>
> Keep in mind that the reader may not be human; some errors are 
> explanations of indirect problems and only visible when the 
> accompanying machine instructions reach a failure (eg 30x, 401, 407 
> messages); and some are not errors at all but instructions for a user 
> on what they need to do to continue with communication (eg 511 login 
> pages).
>
>> 2. And then, using %e code and presumably external js nested in this 
>> page, display more detailed info for some error numbers.
>>
>> Can it be done? Can squid internal web server handle easy js?
>>
>
> Squid is not a web server. On "error" it produces message payloads 
> which happen to contain HTML by default. Modern HTML can contain 
> embedded scripts, but they are not interpreted by Squid as anything 
> beyond opaque characters.
>
>
> If you redirect all errors to one URL any information the client might 
> have had about the error is destroyed.
>
> The symlinking you though of is the "best" way to do what you are 
> asking for. However, think carefully about what the purpose of 
> displaying an error message is, see above.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

The purpose is to provide unified, debug info for 1st line of support. 
End users in my corpo are not best IT trained people in the world and 
they tend to open tickets for any reason, usually pasting printscreen 
into ticket.
Simple debug info like: IP, user name, client name, cache name in short 
list would help service desk to divide "moronic" tickets from important 
ones, and as for default squid info pages... user do not read them 
anyway. I do not want to remove error codes, I just want to remove 
content of most error pages and replace it with unified message that 
also contains raw error code (%e, %E) and add some more information if 
%e will be nxdomain or access denied for example.
Unfortunately, I'm far from VPN right now, so I cannot show you the 
sample "unified" error page I've commited till now.

But indeed, you have striked the home; cache users are both human and 
machine$ AD accounts, I must reconsider that. Perhaps parsing all error 
pages with sed ie and adding few lines will be easer and more 
convenient, anyway.
I know that squid is not web serwer, but error page is html; I assume it 
can contains iframe served from external web server and this will be 
rendered by client's browser, not squid? My idea was:
- js nested in squid error page looks for error code
- then redirects nested iframe to specific URL hosted on external httpd 
depending on error code. If error code is unimportant for human (user 
can do nothing with that anyway), iframe stays blank.
- human client has has his explenation like "this is your error, do not 
open ticket please, check your URL again" for nxdomain.

We are talking about ~2K users and 3-4 cache servers. I must take 
comfort of first line support into concideration, they are quite 
heavy-loaded already.
I'm not feeling comfortable with this idea, but I also have a feeling 
that it might be necessity.

Thank You.

-- 
Greets, Dijx.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170519/5958ef87/attachment.htm>

From squid3 at treenet.co.nz  Fri May 19 15:16:15 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 May 2017 03:16:15 +1200
Subject: [squid-users] How to redirect all squid's error pages to one?
In-Reply-To: <00381e8c-9d9c-50a8-f4d3-72c2a2e1f665@gmail.com>
References: <f4ba5710-0557-8310-8bdf-1cb620b7abf8@gmail.com>
 <1d9af110-0fb8-0d12-e340-d9f5503785b5@treenet.co.nz>
 <00381e8c-9d9c-50a8-f4d3-72c2a2e1f665@gmail.com>
Message-ID: <15bde1d1-275f-9ec4-493f-06dd0db6aeae@treenet.co.nz>

On 20/05/17 02:55, Dijxie wrote:
> W dniu 19.05.2017 o 15:13, Amos Jeffries pisze:
>> On 20/05/17 00:44, Dijxie wrote:
>>>
>>> Hi list,
>>>
>>> 1. I'd like to redirect **all** squid error pages to one, universal, 
>>> preferably internal squid error page. For sure I can symlink every 
>>> error page to one, but is there a clener way?
>>> I'm not sure if I get it: 
>>> http://www.squid-cache.org/Doc/config/deny_info/
>>>
>>
>> deny_info is to provide some non-default response payload (aka. 
>> "page") instead of the 403 when an ACL performs administrative denial 
>> of access.
>>
>> As to your purpose; What is this universal message that conveys all 
>> possible environmental conditions to the reader in one simple text?
>>
>> Keep in mind that the reader may not be human; some errors are 
>> explanations of indirect problems and only visible when the 
>> accompanying machine instructions reach a failure (eg 30x, 401, 407 
>> messages); and some are not errors at all but instructions for a user 
>> on what they need to do to continue with communication (eg 511 login 
>> pages).
>>
>>> 2. And then, using %e code and presumably external js nested in this 
>>> page, display more detailed info for some error numbers.
>>>
>>> Can it be done? Can squid internal web server handle easy js?
>>>
>>
>> Squid is not a web server. On "error" it produces message payloads 
>> which happen to contain HTML by default. Modern HTML can contain 
>> embedded scripts, but they are not interpreted by Squid as anything 
>> beyond opaque characters.
>>
>>
>> If you redirect all errors to one URL any information the client 
>> might have had about the error is destroyed.
>>
>> The symlinking you though of is the "best" way to do what you are 
>> asking for. However, think carefully about what the purpose of 
>> displaying an error message is, see above.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> The purpose is to provide unified, debug info for 1st line of support. 
> End users in my corpo are not best IT trained people in the world and 
> they tend to open tickets for any reason, usually pasting printscreen 
> into ticket.
> Simple debug info like: IP, user name, client name, cache name in 
> short list would help service desk to divide "moronic" tickets from 
> important ones, and as for default squid info pages... user do not 
> read them anyway. I do not want to remove error codes, I just want to 
> remove content of most error pages and replace it with unified message 
> that also contains raw error code (%e, %E) and add some more 
> information if %e will be nxdomain or access denied for example.
> Unfortunately, I'm far from VPN right now, so I cannot show you the 
> sample "unified" error page I've commited till now.
>
> But indeed, you have striked the home; cache users are both human and 
> machine$ AD accounts, I must reconsider that. Perhaps parsing all 
> error pages with sed ie and adding few lines will be easer and more 
> convenient, anyway.
> I know that squid is not web serwer, but error page is html; I assume 
> it can contains iframe served from external web server and this will 
> be rendered by client's browser, not squid? My idea was:
> - js nested in squid error page looks for error code
> - then redirects nested iframe to specific URL hosted on external 
> httpd depending on error code. If error code is unimportant for human 
> (user can do nothing with that anyway), iframe stays blank.
> - human client has has his explenation like "this is your error, do 
> not open ticket please, check your URL again" for nxdomain.
>
> We are talking about ~2K users and 3-4 cache servers. I must take 
> comfort of first line support into concideration, they are quite 
> heavy-loaded already.
> I'm not feeling comfortable with this idea, but I also have a feeling 
> that it might be necessity.
>

I think a better approach may be a link they can click on that 
automatically reports the details for them. Some of our errors already 
include a mailto web link to contact the administrator that embeds the 
error details in subject etc as an example. But you can go a bit further 
with a jQuery script that pulls IP etc and POSTs them to a support 
database API.

You can also reduce a bit of the work editing files by pointing 
error_directory in squid.conf to a directory with your altered 
templates. That will save your changes from being overwritten when the 
OS packaged ones update.

Amos



From rousskov at measurement-factory.com  Fri May 19 16:08:21 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 19 May 2017 10:08:21 -0600
Subject: [squid-users] custom error pages with stylesheets doesn't work
 for me
In-Reply-To: <20170519081015.GA329@bloms.de>
References: <20170518091750.GA246@bloms.de>
 <22878de5-65fc-8727-4ab3-fbde91369b95@measurement-factory.com>
 <20170519081015.GA329@bloms.de>
Message-ID: <d7ef71b5-6e79-244a-b823-39cf62fb3a64@measurement-factory.com>

On 05/19/2017 02:10 AM, Dieter Bloms wrote:
> But there was _no_ error message in the cache log file.

You are right. The lack of an error message is a Squid bug.


On 05/19/2017 07:40 AM, Amos Jeffries wrote:

> I just checked the code and do see a log entry being made

The code you are looking at is not executed. Look two lines higher at
the if statement that guards it... Code duplication strikes again.

Alex.



From dijxie at gmail.com  Fri May 19 16:22:15 2017
From: dijxie at gmail.com (Dijxie)
Date: Fri, 19 May 2017 18:22:15 +0200
Subject: [squid-users] How to redirect all squid's error pages to one?
In-Reply-To: <15bde1d1-275f-9ec4-493f-06dd0db6aeae@treenet.co.nz>
References: <f4ba5710-0557-8310-8bdf-1cb620b7abf8@gmail.com>
 <1d9af110-0fb8-0d12-e340-d9f5503785b5@treenet.co.nz>
 <00381e8c-9d9c-50a8-f4d3-72c2a2e1f665@gmail.com>
 <15bde1d1-275f-9ec4-493f-06dd0db6aeae@treenet.co.nz>
Message-ID: <62a3569c-f589-d4cb-d30d-0d089aeea351@gmail.com>

W dniu 19.05.2017 o 17:16, Amos Jeffries pisze:
> On 20/05/17 02:55, Dijxie wrote:
>> W dniu 19.05.2017 o 15:13, Amos Jeffries pisze:
>>> On 20/05/17 00:44, Dijxie wrote:
>>>>
>>>> Hi list,
>>>>
>>>> 1. I'd like to redirect **all** squid error pages to one, 
>>>> universal, preferably internal squid error page. For sure I can 
>>>> symlink every error page to one, but is there a clener way?
>>>> I'm not sure if I get it: 
>>>> http://www.squid-cache.org/Doc/config/deny_info/
>>>>
>>>
>>> deny_info is to provide some non-default response payload (aka. 
>>> "page") instead of the 403 when an ACL performs administrative 
>>> denial of access.
>>>
>>> As to your purpose; What is this universal message that conveys all 
>>> possible environmental conditions to the reader in one simple text?
>>>
>>> Keep in mind that the reader may not be human; some errors are 
>>> explanations of indirect problems and only visible when the 
>>> accompanying machine instructions reach a failure (eg 30x, 401, 407 
>>> messages); and some are not errors at all but instructions for a 
>>> user on what they need to do to continue with communication (eg 511 
>>> login pages).
>>>
>>>> 2. And then, using %e code and presumably external js nested in 
>>>> this page, display more detailed info for some error numbers.
>>>>
>>>> Can it be done? Can squid internal web server handle easy js?
>>>>
>>>
>>> Squid is not a web server. On "error" it produces message payloads 
>>> which happen to contain HTML by default. Modern HTML can contain 
>>> embedded scripts, but they are not interpreted by Squid as anything 
>>> beyond opaque characters.
>>>
>>>
>>> If you redirect all errors to one URL any information the client 
>>> might have had about the error is destroyed.
>>>
>>> The symlinking you though of is the "best" way to do what you are 
>>> asking for. However, think carefully about what the purpose of 
>>> displaying an error message is, see above.
>>>
>>> Amos
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> The purpose is to provide unified, debug info for 1st line of 
>> support. End users in my corpo are not best IT trained people in the 
>> world and they tend to open tickets for any reason, usually pasting 
>> printscreen into ticket.
>> Simple debug info like: IP, user name, client name, cache name in 
>> short list would help service desk to divide "moronic" tickets from 
>> important ones, and as for default squid info pages... user do not 
>> read them anyway. I do not want to remove error codes, I just want to 
>> remove content of most error pages and replace it with unified 
>> message that also contains raw error code (%e, %E) and add some more 
>> information if %e will be nxdomain or access denied for example.
>> Unfortunately, I'm far from VPN right now, so I cannot show you the 
>> sample "unified" error page I've commited till now.
>>
>> But indeed, you have striked the home; cache users are both human and 
>> machine$ AD accounts, I must reconsider that. Perhaps parsing all 
>> error pages with sed ie and adding few lines will be easer and more 
>> convenient, anyway.
>> I know that squid is not web serwer, but error page is html; I assume 
>> it can contains iframe served from external web server and this will 
>> be rendered by client's browser, not squid? My idea was:
>> - js nested in squid error page looks for error code
>> - then redirects nested iframe to specific URL hosted on external 
>> httpd depending on error code. If error code is unimportant for human 
>> (user can do nothing with that anyway), iframe stays blank.
>> - human client has has his explenation like "this is your error, do 
>> not open ticket please, check your URL again" for nxdomain.
>>
>> We are talking about ~2K users and 3-4 cache servers. I must take 
>> comfort of first line support into concideration, they are quite 
>> heavy-loaded already.
>> I'm not feeling comfortable with this idea, but I also have a feeling 
>> that it might be necessity.
>>
>
> I think a better approach may be a link they can click on that 
> automatically reports the details for them. Some of our errors already 
> include a mailto web link to contact the administrator that embeds the 
> error details in subject etc as an example. But you can go a bit 
> further with a jQuery script that pulls IP etc and POSTs them to a 
> support database API.
>
> You can also reduce a bit of the work editing files by pointing 
> error_directory in squid.conf to a directory with your altered 
> templates. That will save your changes from being overwritten when the 
> OS packaged ones update.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

It would be yet another explanatory link they don't ever click, 
unfortunately. But yes, I know it would be a better approach. This is an 
organizational and 'political' issue and me myself can do nothing about it.
malto: is alredy removed - they cannot open tickets this way and we do 
not want to be flooded by emails like that.

That was my pimal idea: simle database/array that contains some criteria 
like:
if %e is bad gateway and %I=10.10.10.69 and %i=10.22.0.0/16 then iframe 
says: "we alredy told you 10000 times that you shall not try to access 
%H server from %i network". Then I could give user info database's 
managment to the people in service desk so they can change info 
depending on the buisiness circumstances - without reconfiguration of 
all squids (that should be identical because of LB and FO) and harrasing 
my department of course :)

If they (end users) open a ticket in circumstances they were precisely 
instructed not to do so, they (their company) are extra charged. If they 
open a ticket because they do not know what to do, service desk folks 
have to do unnecessary work for nothing. And common practice is 
everybody forgets to inform users and service desk about changes or 3rd 
party supporting companies change something on their machines causing 
huge mess and 2300 identical tickets within an hour; I'm just trying to 
provide  kind of dynamic, easy managed and functional error page that 
can provide basic explenation for end users if needed.

So: js/jq + external iframe in error page(s) is something that does not 
violate standards? Let's not talk about common sense here ;)

Greets, Dijx

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170519/9c37fa0a/attachment.htm>

From vze2k3sa at verizon.net  Fri May 19 17:13:45 2017
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Fri, 19 May 2017 13:13:45 -0400
Subject: [squid-users] Change are not taking
Message-ID: <000601d2d0c3$463d7a80$d2b86f80$@verizon.net>

Hi,

 

I am making changes to my squid.conf, yet they don't seem to take. Is there
something I'm missing? Any help appreciated

 

# Squid Proxy Configuration

 

# Network(s) where proxy traffic is originating

# acl localnet src 10.0.0.0/8          # RFC1918 possible internal network

# acl localnet src 172.16.0.0/12   # RFC1918 possible internal network

# acl localnet src 192.168.0.0/16 # RFC1918 possible internal network

acl localnet src all

 

# acl and http_access ("rmsc.txt")

acl whitelist dstdomain  "c:/squid/etc/squid/rmsc.txt"

http_access        allow     whitelist

 

acl http      proto      http

acl https     proto      https

acl SSL_ports port 443

acl Safe_ports port 80                    # http

acl Safe_ports port 443                  # https

acl CONNECT method CONNECT

 

# rules allowing proxy access

http_access allow http  Safe_ports whitelist localnet

http_access allow https SSL_ports whitelist localnet

 

# Deny requests to certain unsafe ports

http_access deny !Safe_ports

 

# Deny CONNECT to other than secure SSL ports

http_access deny CONNECT !SSL_ports

 

# Lastly deny all other access to this proxy

http_access deny all

 

# Listens to port 3128

http_port 3128

 

# DNS servers (Change dns_nameservers to client dns servers for consistency
and better performance)

dns_nameservers 8.8.8.8 8.8.4.4

 

# Roll log file daily and keep 30 days

logfile_rotate 30

 

# Access log format

logformat squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt

 

# Debug (Only used by Rave Service Personnel)

# debug_options             ALL,2

 

# Use IPv4 based DNS first

dns_v4_first on

 

# Log definitions

access_log stdio:c:/Squid/var/log/squid/access.log

cache_store_log stdio:c:/Squid/var/log/squid/store.log

buffered_logs on

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170519/25caea8a/attachment.htm>

From dijxie at gmail.com  Fri May 19 17:38:48 2017
From: dijxie at gmail.com (Dijxie)
Date: Fri, 19 May 2017 19:38:48 +0200
Subject: [squid-users] Change are not taking
In-Reply-To: <000601d2d0c3$463d7a80$d2b86f80$@verizon.net>
References: <000601d2d0c3$463d7a80$d2b86f80$@verizon.net>
Message-ID: <49d895c8-1bbb-08a8-4788-2e868a5f82e2@gmail.com>

W dniu 19.05.2017 o 19:13, Patrick Flaherty pisze:
>
> Hi,
>
> I am making changes to my squid.conf, yet they don?t seem to take. Is 
> there something I?m missing? Any help appreciated
>
> # Squid Proxy Configuration
>
> # Network(s) where proxy traffic is originating
>
> # acl localnet src 10.0.0.0/8          # RFC1918 possible internal network
>
> # acl localnet src 172.16.0.0/12   # RFC1918 possible internal network
>
> # acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
>
> acl localnet src all
>
> # acl and http_access ("rmsc.txt")
>
> acl whitelist dstdomain "c:/squid/etc/squid/rmsc.txt"
>
> http_access        allow     whitelist
>
> acl http      proto      http
>
> acl https     proto      https
>
> acl SSL_ports port 443
>
> acl Safe_ports port 80                    # http
>
> acl Safe_ports port 443                  # https
>
> acl CONNECT method CONNECT
>
> # rules allowing proxy access
>
> http_access allow http  Safe_ports whitelist localnet
>
> http_access allow https SSL_ports whitelist localnet
>
> # Deny requests to certain unsafe ports
>
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports
>
> http_access deny CONNECT !SSL_ports
>
> # Lastly deny all other access to this proxy
>
> http_access deny all
>
> # Listens to port 3128
>
> http_port 3128
>
> # DNS servers (Change dns_nameservers to client dns servers for 
> consistency and better performance)
>
> dns_nameservers 8.8.8.8 8.8.4.4
>
> # Roll log file daily and keep 30 days
>
> logfile_rotate 30
>
> # Access log format
>
> logformat squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
>
> # Debug (Only used by Rave Service Personnel)
>
> # debug_options             ALL,2
>
> # Use IPv4 based DNS first
>
> dns_v4_first on
>
> # Log definitions
>
> access_log stdio:c:/Squid/var/log/squid/access.log
>
> cache_store_log stdio:c:/Squid/var/log/squid/store.log
>
> buffered_logs on
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

But what changes are you making?
Are you aware that you must reapply squid.conf after changing it by 
restarting or reloading? At linux, it's squid -k reconfigure; dunno how 
to do that on Windows, the same way i guess...

-- 
Greets, Dijx

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170519/275e189b/attachment.htm>

From erdosain9 at gmail.com  Fri May 19 18:46:32 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Fri, 19 May 2017 11:46:32 -0700 (PDT)
Subject: [squid-users] Documentation for squidclient?
In-Reply-To: <40108344-b1da-93d2-ea40-a627ec29ed77@treenet.co.nz>
References: <1495111693229-4682457.post@n4.nabble.com>
 <1495112822444-4682458.post@n4.nabble.com>
 <65d362a3-0b6d-f9a2-c028-b039a039f09d@gmail.com>
 <1495124861774-4682467.post@n4.nabble.com>
 <1495125079578-4682468.post@n4.nabble.com>
 <1495125233911-4682469.post@n4.nabble.com>
 <40108344-b1da-93d2-ea40-a627ec29ed77@treenet.co.nz>
Message-ID: <1495219592156-4682491.post@n4.nabble.com>

Hi again.

Just boot up
11:43
number active: 14 of 25 (0 shutting down)
requests sent: 166348
replies received: 166348
queue length: 0
avg service time: 34 msec

   ID #	     FD	    PID	 # Requests	  # Replies	 Flags	   Time	 Offset
Request
    366	     97	  13237	        510	        510	     	  0.040	      0	(none)
    367	    107	  13238	        225	        225	     	  0.243	      0	(none)
    368	    135	  13239	        119	        119	     	  0.069	      0	(none)
    369	     94	  13240	         77	         77	     	  0.072	      0	(none)
    370	    109	  13242	         51	         51	     	  0.228	      0	(none)
    371	    131	  13243	         41	         41	     	  0.228	      0	(none)
    372	    301	  13244	         28	         28	     	  0.276	      0	(none)
    373	    212	  13245	         23	         23	     	  0.276	      0	(none)
    374	    261	  13246	         15	         15	     	  0.276	      0	(none)
    375	    427	  13249	          9	          9	     	  0.276	      0	(none)
    376	    429	  13250	          6	          6	     	  0.276	      0	(none)
    377	    431	  13251	          5	          5	     	  0.276	      0	(none)
    381	    332	  13293	          2	          2	     	  0.276	      0	(none)
    382	    496	  13359	          1	          1	     	  0.276	      0	(none)


12:00
---------------------------------------------------------------------------------------------
number active: 25 of 25 (0 shutting down)
requests sent: 173579
replies received: 173579
queue length: 0
avg service time: 42 msec

   ID #	     FD	    PID	 # Requests	  # Replies	 Flags	   Time	 Offset
Request
    366	     97	  13237	       3561	       3561	     	  0.130	      0	(none)
    367	    107	  13238	       1622	       1622	     	  0.059	      0	(none)
    368	    135	  13239	        910	        910	     	  0.128	      0	(none)
    369	     94	  13240	        599	        599	     	  0.142	      0	(none)
    370	    109	  13242	        411	        411	     	  0.153	      0	(none)
    371	    131	  13243	        308	        308	     	  0.215	      0	(none)
    372	    301	  13244	        230	        230	     	  0.167	      0	(none)
    373	    212	  13245	        172	        172	     	  0.136	      0	(none)
    374	    261	  13246	        120	        120	     	  0.167	      0	(none)
    375	    427	  13249	         98	         98	     	  0.173	      0	(none)
    376	    429	  13250	         71	         71	     	  0.120	      0	(none)
    377	    431	  13251	         50	         50	     	  0.180	      0	(none)
    381	    332	  13293	         41	         41	     	  0.294	      0	(none)
    382	    496	  13359	         32	         32	     	  0.312	      0	(none)
    383	    374	  13361	         25	         25	     	  0.192	      0	(none)
    384	    377	  13362	         21	         21	     	  0.309	      0	(none)
    385	    373	  13430	         16	         16	     	  0.198	      0	(none)
    386	    392	  13431	         13	         13	     	  1.044	      0	(none)
    387	    399	  13432	         10	         10	     	  0.960	      0	(none)
    388	    403	  13433	          8	          8	     	  1.006	      0	(none)
    389	    448	  13434	          6	          6	     	  0.930	      0	(none)
    390	    450	  13435	          7	          7	     	  0.994	      0	(none)
    391	    452	  13436	          5	          5	     	  0.927	      0	(none)
    392	    455	  13437	          4	          4	     	  0.829	      0	(none)
    393	    457	  13438	          3	          3	     	  0.253	      0	(none)


12:30
--------------------------------------------------------------------------------------------
number active: 25 of 25 (0 shutting down)
requests sent: 182608
replies received: 182608
queue length: 0
avg service time: 36 msec

   ID #	     FD	    PID	 # Requests	  # Replies	 Flags	   Time	 Offset
Request
    366	     97	  13237	       7458	       7458	     	  0.085	      0	(none)
    367	    107	  13238	       3401	       3401	     	  0.128	      0	(none)
    368	    135	  13239	       1862	       1862	     	  0.108	      0	(none)
    369	     94	  13240	       1235	       1235	     	  0.534	      0	(none)
    370	    109	  13242	        862	        862	     	  0.115	      0	(none)
    371	    131	  13243	        641	        641	     	  0.118	      0	(none)
    372	    301	  13244	        466	        466	     	  0.118	      0	(none)
    373	    212	  13245	        335	        335	     	  0.568	      0	(none)
    374	    261	  13246	        249	        249	     	  0.568	      0	(none)
    375	    427	  13249	        202	        202	     	  0.605	      0	(none)
    376	    429	  13250	        156	        156	     	  0.451	      0	(none)
    377	    431	  13251	        109	        109	     	  0.605	      0	(none)
    381	    332	  13293	         88	         88	     	  0.509	      0	(none)
    382	    496	  13359	         69	         69	     	  0.568	      0	(none)
    383	    374	  13361	         54	         54	     	  0.803	      0	(none)
    384	    377	  13362	         46	         46	     	  0.689	      0	(none)
    385	    373	  13430	         32	         32	     	  0.743	      0	(none)
    386	    392	  13431	         26	         26	     	  0.778	      0	(none)
    387	    399	  13432	         20	         20	     	  0.772	      0	(none)
    388	    403	  13433	         16	         16	     	  0.976	      0	(none)
    389	    448	  13434	         12	         12	     	  0.599	      0	(none)
    390	    450	  13435	         11	         11	     	  0.598	      0	(none)
    391	    452	  13436	         10	         10	     	  0.519	      0	(none)
    392	    455	  13437	          7	          7	     	  0.519	      0	(none)
    393	    457	  13438	          5	          5	     	  0.451	      0	(none)

12:46
-------------------------------------------------------------------------------------------
number active: 25 of 25 (0 shutting down)
requests sent: 189038
replies received: 189038
queue length: 0
avg service time: 37 msec

   ID #	     FD	    PID	 # Requests	  # Replies	 Flags	   Time	 Offset
Request
    366	     97	  13237	      10231	      10231	     	  0.050	      0	(none)
    367	    107	  13238	       4662	       4662	     	  0.052	      0	(none)
    368	    135	  13239	       2537	       2537	     	  0.103	      0	(none)
    369	     94	  13240	       1693	       1693	     	  0.104	      0	(none)
    370	    109	  13242	       1194	       1194	     	  0.104	      0	(none)
    371	    131	  13243	        875	        875	     	  0.074	      0	(none)
    372	    301	  13244	        637	        637	     	  0.619	      0	(none)
    373	    212	  13245	        462	        462	     	  0.648	      0	(none)
    374	    261	  13246	        346	        346	     	  0.648	      0	(none)
    375	    427	  13249	        277	        277	     	  0.663	      0	(none)
    376	    429	  13250	        207	        207	     	  0.078	      0	(none)
    377	    431	  13251	        150	        150	     	  0.503	      0	(none)
    381	    332	  13293	        121	        121	     	  0.501	      0	(none)
    382	    496	  13359	         96	         96	     	  0.401	      0	(none)
    383	    374	  13361	         73	         73	     	  0.354	      0	(none)
    384	    377	  13362	         61	         61	     	  0.288	      0	(none)
    385	    373	  13430	         43	         43	     	  0.200	      0	(none)
    386	    392	  13431	         34	         34	     	  0.360	      0	(none)
    387	    399	  13432	         27	         27	     	  0.390	      0	(none)
    388	    403	  13433	         23	         23	     	  0.390	      0	(none)
    389	    448	  13434	         16	         16	     	  0.363	      0	(none)
    390	    450	  13435	         12	         12	     	  1.525	      0	(none)
    391	    452	  13436	         11	         11	     	  1.619	      0	(none)
    392	    455	  13437	          8	          8	     	  1.578	      0	(none)
    393	    457	  13438	          6	          6	     	  1.611	      0	(none)

TIME FOR LUNCH
----------------------------------------------------------------------------------------
number active: 25 of 25 (0 shutting down)
requests sent: 199622
replies received: 199622
queue length: 0
avg service time: 27 msec

   ID #	     FD	    PID	 # Requests	  # Replies	 Flags	   Time	 Offset
Request
    366	     97	  13237	      15368	      15368	     	  0.051	      0	(none)
    367	    107	  13238	       6711	       6711	     	  0.047	      0	(none)
    368	    135	  13239	       3571	       3571	     	  0.089	      0	(none)
    369	     94	  13240	       2342	       2342	     	  0.066	      0	(none)
    370	    109	  13242	       1650	       1650	     	  0.068	      0	(none)
    371	    131	  13243	       1185	       1185	     	  0.186	      0	(none)
    372	    301	  13244	        866	        866	     	  0.103	      0	(none)
    373	    212	  13245	        638	        638	     	  0.153	      0	(none)
    374	    261	  13246	        482	        482	     	  0.092	      0	(none)
    375	    427	  13249	        378	        378	     	  0.402	      0	(none)
    376	    429	  13250	        273	        273	     	  0.495	      0	(none)
    377	    431	  13251	        201	        201	     	  0.234	      0	(none)
    381	    332	  13293	        162	        162	     	  0.428	      0	(none)
    382	    496	  13359	        127	        127	     	  0.447	      0	(none)
    383	    374	  13361	         99	         99	     	  0.492	      0	(none)
    384	    377	  13362	         82	         82	     	  0.392	      0	(none)
    385	    373	  13430	         62	         62	     	  0.471	      0	(none)
    386	    392	  13431	         49	         49	     	  0.434	      0	(none)
    387	    399	  13432	         39	         39	     	  0.346	      0	(none)
    388	    403	  13433	         31	         31	     	  0.287	      0	(none)
    389	    448	  13434	         20	         20	     	  0.292	      0	(none)
    390	    450	  13435	         16	         16	     	  0.451	      0	(none)
    391	    452	  13436	         15	         15	     	  0.322	      0	(none)
    392	    455	  13437	         11	         11	     	  0.466	      0	(none)
    393	    457	  13438	          8	          8	     	  0.505	      0	(none)

14:53
--------------------------------------------------------------------------------------
number active: 25 of 25 (0 shutting down)
requests sent: 226841
replies received: 226841
queue length: 0
avg service time: 26 msec

   ID #	     FD	    PID	 # Requests	  # Replies	 Flags	   Time	 Offset
Request
    366	     97	  13237	      27933	      27933	     	  0.178	      0	(none)
    367	    107	  13238	      11866	      11866	     	  0.450	      0	(none)
    368	    135	  13239	       6397	       6397	     	  0.447	      0	(none)
    369	     94	  13240	       4165	       4165	     	  0.456	      0	(none)
    370	    109	  13242	       2946	       2946	     	  0.374	      0	(none)
    371	    131	  13243	       2146	       2146	     	  0.389	      0	(none)
    372	    301	  13244	       1541	       1541	     	  0.387	      0	(none)
    373	    212	  13245	       1121	       1121	     	  0.366	      0	(none)
    374	    261	  13246	        835	        835	     	  0.376	      0	(none)
    375	    427	  13249	        651	        651	     	  0.376	      0	(none)
    376	    429	  13250	        471	        471	     	  0.376	      0	(none)
    377	    431	  13251	        341	        341	     	  0.376	      0	(none)
    381	    332	  13293	        263	        263	     	  0.199	      0	(none)
    382	    496	  13359	        200	        200	     	  0.273	      0	(none)
    383	    374	  13361	        160	        160	     	  0.135	      0	(none)
    384	    377	  13362	        131	        131	     	  0.216	      0	(none)
    385	    373	  13430	        101	        101	     	  0.608	      0	(none)
    386	    392	  13431	         81	         81	     	  0.541	      0	(none)
    387	    399	  13432	         67	         67	     	  0.269	      0	(none)
    388	    403	  13433	         54	         54	     	  0.249	      0	(none)
    389	    448	  13434	         37	         37	     	  0.137	      0	(none)
    390	    450	  13435	         30	         30	     	  0.153	      0	(none)
    391	    452	  13436	         28	         28	     	  0.996	      0	(none)
    392	    455	  13437	         23	         23	     	  0.996	      0	(none)
    393	    457	  13438	         17	         17	     	  0.867	      0	(none)

15:52
--------------------------------------------------------------------------------------
number active: 25 of 25 (0 shutting down)
requests sent: 239806
replies received: 239806
queue length: 0
avg service time: 26 msec

   ID #	     FD	    PID	 # Requests	  # Replies	 Flags	   Time	 Offset
Request
    366	     97	  13237	      34695	      34695	     	  0.045	      0	(none)
    367	    107	  13238	      14219	      14219	     	  0.102	      0	(none)
    368	    135	  13239	       7622	       7622	     	  0.091	      0	(none)
    369	     94	  13240	       4912	       4912	     	  0.091	      0	(none)
    370	    109	  13242	       3440	       3440	     	  0.065	      0	(none)
    371	    131	  13243	       2499	       2499	     	  0.096	      0	(none)
    372	    301	  13244	       1775	       1775	     	  0.134	      0	(none)
    373	    212	  13245	       1305	       1305	     	  0.062	      0	(none)
    374	    261	  13246	        974	        974	     	  0.190	      0	(none)
    375	    427	  13249	        760	        760	     	  0.551	      0	(none)
    376	    429	  13250	        545	        545	     	  0.659	      0	(none)
    377	    431	  13251	        393	        393	     	  0.531	      0	(none)
    381	    332	  13293	        303	        303	     	  0.515	      0	(none)
    382	    496	  13359	        235	        235	     	  0.500	      0	(none)
    383	    374	  13361	        188	        188	     	  0.529	      0	(none)
    384	    377	  13362	        156	        156	     	  0.498	      0	(none)
    385	    373	  13430	        122	        122	     	  0.606	      0	(none)
    386	    392	  13431	         99	         99	     	  0.498	      0	(none)
    387	    399	  13432	         81	         81	     	  0.467	      0	(none)
    388	    403	  13433	         68	         68	     	  0.482	      0	(none)
    389	    448	  13434	         48	         48	     	  0.467	      0	(none)
    390	    450	  13435	         38	         38	     	  0.573	      0	(none)
    391	    452	  13436	         37	         37	     	  0.470	      0	(none)
    392	    455	  13437	         32	         32	     	  0.485	      0	(none)
    393	    457	  13438	         24	         24	     	  0.449	      0	(none)

This values are fine?? probably yes, but how can i tune for better??

###Kerberos Auth with ActiveDirectory###
auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -s
HTTP/squid.xxxxxxx.lan at xxxxxxx.LAN
auth_param negotiate children 25 startup=0 idle=1
auth_param negotiate keep_alive on


external_acl_type i-full %LOGIN /usr/lib64/squid/ext_kerberos_ldap_group_acl
-g i-full at xxxxxxx.LAN
external_acl_type i-limitado %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-limitado at xxxxxxx.LAN

#GRUPOS
acl i-full external i-full
acl i-limitado external i-limitado

####Bloquea Publicidad ( http://pgl.yoyo.org/adservers/ )
acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
http_access deny ads
#deny_info TCP_RESET ads

####Streaming
acl youtube url_regex -i \.flv$
acl youtube url_regex -i \.mp4$
acl youtube url_regex -i watch?
acl youtube url_regex -i youtube
acl facebook url_regex -i facebook
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.jpg)\? 
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.jpg)\?

##Dominios denegados
acl dominios_denegados dstdomain "/etc/squid/listas/dominios_denegados.lst"

#Puertos
acl SSL_ports port 443
acl SSL_ports port 8443
acl SSL_ports port 8080
acl SSL_ports port 20000
acl SSL_ports port 10000
acl SSL_ports port 2083

acl Safe_ports port 631         # httpCUPS
acl Safe_ports port 85
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 8443        # httpsalt
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 8080        # edesur y otros
acl Safe_ports port 2199	# radio
acl CONNECT method CONNECT


#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager


#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow i-limitado !dominios_denegados 
http_access allow i-full !dominios_denegados 
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 127.0.0.1:3128
http_port 192.168.1.215:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pem 

acl step1 at_step SslBump1 

acl excludeSSL ssl::server_name_regex "/etc/squid/listas/excluidosSSL.lst"

ssl_bump peek step1 
ssl_bump splice excludeSSL 
ssl_bump bump all 


# Uncomment and adjust the following to add a disk cache directory.
cache_dir diskd /var/spool/squid 15000 16 256
cache_mem 758 MB

cache_swap_low 90
cache_swap_high 95

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid


#Your refresh_pattern
refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
ignore-private

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320

###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
via off
forwarded_for delete
###

#Pools para ancho de banda
delay_pools 5

#Ancho de Youtube
delay_class 1 2 
delay_parameters 1 1000000/1000000 50000/256000
delay_access 1 allow i-limitado youtube !facebook
delay_access 1 deny all

#Ancho de Facebook
delay_class 2 2 
delay_parameters 2 1000000/1000000 50000/256000
delay_access 2 allow i-limitado facebook !youtube
delay_access 2 deny all

#Ancho de banda YOUTUBE FULL
delay_class 3 1
delay_parameters 3 1000000/1000000
delay_access 3 allow i-full youtube !facebook
delay_access 3 deny all

#Ancho de banda LIMITADO
delay_class 4 3 
delay_parameters 4 3000000/3000000 1000000/1000000 256000/512000
delay_access 4 allow i-limitado !youtube !facebook
delay_access 4 deny all

#Ancho de banda FULL
delay_class 5 3
delay_parameters 5 1500000/1500000 750000/750000 256000/512000
delay_access 5 allow i-full !youtube !facebook
delay_access 5 deny all

dns_nameservers 192.168.1.222 8.8.8.8
#dns_nameservers 8.8.8.8 8.8.4.4
visible_hostname squid.xxxxxxx.lan

# try connecting to first 25 ips of a domain name
forward_max_tries 25

# fix some ipv6 errors (recommended to comment out) 
dns_v4_first on

# c-icap integration
# -------------------------------------
# Adaptation parameters
# -------------------------------------
icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024
icap_service service_avi_req reqmod_precache
icap://127.0.0.1:1344/squidclamav bypass=on
adaptation_access service_avi_req allow all
icap_service service_avi_resp respmod_precache
icap://127.0.0.1:1344/squidclamav bypass=off
adaptation_access service_avi_resp allow all
# end integration

THANKSSSSSSSSSSSSSSSS!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Documentation-for-squidclient-tp4682457p4682491.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From dan at getbusi.com  Sat May 20 05:13:16 2017
From: dan at getbusi.com (Dan Charlesworth)
Date: Sat, 20 May 2017 15:13:16 +1000
Subject: [squid-users] Rock store size not decreasing
In-Reply-To: <310d5774-dede-169b-e039-7d3f9532f5ec@treenet.co.nz>
References: <CAN8nrKBTE-HpHMDx9mdaO9kjv1VW2B1GORxGN7ZN4uMacjQ0Ag@mail.gmail.com>
 <310d5774-dede-169b-e039-7d3f9532f5ec@treenet.co.nz>
Message-ID: <CAN8nrKByQcSxCnyYpSROzyS7r=SMSJg0Bh-NAy2hB1f-DjKnFg@mail.gmail.com>

Okay, cool ? thanks for clarifying.

Guess I'll nuke it myself and reinitialise a blank one.

Best,
Dan


On 19 May 2017 at 23:29, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 19/05/17 15:47, Dan Charlesworth wrote:
>
>> Hey all
>>
>> I'm fairly new to rock caching. With aufs, if you reduce the cache size
>> in the config it'll start slowly reducing it down the new size.
>>
>> I've done that with a ~137GB rock store (reduced it to 10240MB) but it
>> 'aint changing after reloading the config.
>>
>
> With UFS/AUFSdiskd the cache is stored in a directory tree with individual
> files per item. Reducing the size results in files being deleted from disk
> an the total size shrinks naturally without any special action by Squid.
>
> Rock on the other hand has all content stored inside one file. That file
> gets initialized with the space configured and maybe grown if needed. But
> there is nothing I'm aware of to reinitialize it on smaller sizes being
> configured. Reducing the size does reduce the size of stuff using space
> *inside* the database file, but AFAIK not the file itself.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
Getbusi
p +61 3 6165 1555
e dan at getbusi.com
w getbusi.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170520/220b692f/attachment.htm>

From squid3 at treenet.co.nz  Sat May 20 11:10:19 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 May 2017 23:10:19 +1200
Subject: [squid-users] How to redirect all squid's error pages to one?
In-Reply-To: <62a3569c-f589-d4cb-d30d-0d089aeea351@gmail.com>
References: <f4ba5710-0557-8310-8bdf-1cb620b7abf8@gmail.com>
 <1d9af110-0fb8-0d12-e340-d9f5503785b5@treenet.co.nz>
 <00381e8c-9d9c-50a8-f4d3-72c2a2e1f665@gmail.com>
 <15bde1d1-275f-9ec4-493f-06dd0db6aeae@treenet.co.nz>
 <62a3569c-f589-d4cb-d30d-0d089aeea351@gmail.com>
Message-ID: <130379b2-dcd9-a610-330c-138a0f0e97ff@treenet.co.nz>

On 20/05/17 04:22, Dijxie wrote:
> W dniu 19.05.2017 o 17:16, Amos Jeffries pisze:
>> On 20/05/17 02:55, Dijxie wrote:
>>> W dniu 19.05.2017 o 15:13, Amos Jeffries pisze:
>>>> On 20/05/17 00:44, Dijxie wrote:
>>>>>
>>>>> Hi list,
>>>>>
>>>>> 1. I'd like to redirect **all** squid error pages to one, 
>>>>> universal, preferably internal squid error page. For sure I can 
>>>>> symlink every error page to one, but is there a clener way?
>>>>> I'm not sure if I get it: 
>>>>> http://www.squid-cache.org/Doc/config/deny_info/
>>>>>
>>>>
>>>> deny_info is to provide some non-default response payload (aka. 
>>>> "page") instead of the 403 when an ACL performs administrative 
>>>> denial of access.
>>>>
>>>> As to your purpose; What is this universal message that conveys all 
>>>> possible environmental conditions to the reader in one simple text?
>>>>
>>>> Keep in mind that the reader may not be human; some errors are 
>>>> explanations of indirect problems and only visible when the 
>>>> accompanying machine instructions reach a failure (eg 30x, 401, 407 
>>>> messages); and some are not errors at all but instructions for a 
>>>> user on what they need to do to continue with communication (eg 511 
>>>> login pages).
>>>>
>>>>> 2. And then, using %e code and presumably external js nested in 
>>>>> this page, display more detailed info for some error numbers.
>>>>>
>>>>> Can it be done? Can squid internal web server handle easy js?
>>>>>
>>>>
>>>> Squid is not a web server. On "error" it produces message payloads 
>>>> which happen to contain HTML by default. Modern HTML can contain 
>>>> embedded scripts, but they are not interpreted by Squid as anything 
>>>> beyond opaque characters.
>>>>
>>>>
>>>> If you redirect all errors to one URL any information the client 
>>>> might have had about the error is destroyed.
>>>>
>>>> The symlinking you though of is the "best" way to do what you are 
>>>> asking for. However, think carefully about what the purpose of 
>>>> displaying an error message is, see above.
>>>>
>>>> Amos
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>> The purpose is to provide unified, debug info for 1st line of 
>>> support. End users in my corpo are not best IT trained people in the 
>>> world and they tend to open tickets for any reason, usually pasting 
>>> printscreen into ticket.
>>> Simple debug info like: IP, user name, client name, cache name in 
>>> short list would help service desk to divide "moronic" tickets from 
>>> important ones, and as for default squid info pages... user do not 
>>> read them anyway. I do not want to remove error codes, I just want 
>>> to remove content of most error pages and replace it with unified 
>>> message that also contains raw error code (%e, %E) and add some more 
>>> information if %e will be nxdomain or access denied for example.
>>> Unfortunately, I'm far from VPN right now, so I cannot show you the 
>>> sample "unified" error page I've commited till now.
>>>
>>> But indeed, you have striked the home; cache users are both human 
>>> and machine$ AD accounts, I must reconsider that. Perhaps parsing 
>>> all error pages with sed ie and adding few lines will be easer and 
>>> more convenient, anyway.
>>> I know that squid is not web serwer, but error page is html; I 
>>> assume it can contains iframe served from external web server and 
>>> this will be rendered by client's browser, not squid? My idea was:
>>> - js nested in squid error page looks for error code
>>> - then redirects nested iframe to specific URL hosted on external 
>>> httpd depending on error code. If error code is unimportant for 
>>> human (user can do nothing with that anyway), iframe stays blank.
>>> - human client has has his explenation like "this is your error, do 
>>> not open ticket please, check your URL again" for nxdomain.
>>>
>>> We are talking about ~2K users and 3-4 cache servers. I must take 
>>> comfort of first line support into concideration, they are quite 
>>> heavy-loaded already.
>>> I'm not feeling comfortable with this idea, but I also have a 
>>> feeling that it might be necessity.
>>>
>>
>> I think a better approach may be a link they can click on that 
>> automatically reports the details for them. Some of our errors 
>> already include a mailto web link to contact the administrator that 
>> embeds the error details in subject etc as an example. But you can go 
>> a bit further with a jQuery script that pulls IP etc and POSTs them 
>> to a support database API.
>>
>> You can also reduce a bit of the work editing files by pointing 
>> error_directory in squid.conf to a directory with your altered 
>> templates. That will save your changes from being overwritten when 
>> the OS packaged ones update.
>>
> It would be yet another explanatory link they don't ever click, 
> unfortunately. But yes, I know it would be a better approach. This is 
> an organizational and 'political' issue and me myself can do nothing 
> about it.
>

For some maybe, if it is a major problem then make it an auto-fetch 
jQuery instead so they dont need to click at all, the report "just 
happens". That will also filter a lot of the machine-specific occurances 
out.

> malto: is alredy removed - they cannot open tickets this way and we do 
> not want to be flooded by emails like that.
>
> That was my pimal idea: simle database/array that contains some 
> criteria like:
> if %e is bad gateway and %I=10.10.10.69 and %i=10.22.0.0/16 then 
> iframe says: "we alredy told you 10000 times that you shall not try to 
> access %H server from %i network". Then I could give user info 
> database's managment to the people in service desk so they can change 
> info depending on the buisiness circumstances - without 
> reconfiguration of all squids (that should be identical because of LB 
> and FO) and harrasing my department of course :)
>
> If they (end users) open a ticket in circumstances they were precisely 
> instructed not to do so, they (their company) are extra charged. If 
> they open a ticket because they do not know what to do, service desk 
> folks have to do unnecessary work for nothing. And common practice is 
> everybody forgets to inform users and service desk about changes or 
> 3rd party supporting companies change something on their machines 
> causing huge mess and 2300 identical tickets within an hour; I'm just 
> trying to provide  kind of dynamic, easy managed and functional error 
> page that can provide basic explenation for end users if needed.
>
> So: js/jq + external iframe in error page(s) is something that does 
> not violate standards? Let's not talk about common sense here ;)
>

Anything that is accepted by browsers in an HTML document for 
client-side interpretation can be used. That includes references to 
sub-resources.

Amos



From squid3 at treenet.co.nz  Sat May 20 11:22:26 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 May 2017 23:22:26 +1200
Subject: [squid-users] Change are not taking
In-Reply-To: <000601d2d0c3$463d7a80$d2b86f80$@verizon.net>
References: <000601d2d0c3$463d7a80$d2b86f80$@verizon.net>
Message-ID: <f50726c5-07fd-8b01-4eae-05cde2444b37@treenet.co.nz>

On 20/05/17 05:13, Patrick Flaherty wrote:
>
> Hi,
>
> I am making changes to my squid.conf, yet they don?t seem to take. Is 
> there something I?m missing? Any help appreciated
>

 From the changes below it looks like you are attempting to configure a 
reverse-proxy. Relevant changes below:

> # Squid Proxy Configuration
>
> # Network(s) where proxy traffic is originating
>
> # acl localnet src 10.0.0.0/8          # RFC1918 possible internal network
>
> # acl localnet src 172.16.0.0/12   # RFC1918 possible internal network
>
> # acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
>
> acl localnet src all
>

Remove the above change.

> # acl and http_access ("rmsc.txt")
>
> acl whitelist dstdomain "c:/squid/etc/squid/rmsc.txt"
>
> http_access        allow     whitelist
>
Move this section down to the place marked below.

> acl http      proto      http
>
> acl https     proto      https
>
> acl SSL_ports port 443
>
> acl Safe_ports port 80                    # http
>
> acl Safe_ports port 443                  # https
>
> acl CONNECT method CONNECT
>
> # rules allowing proxy access
>
> http_access allow http  Safe_ports whitelist localnet
>
> http_access allow https SSL_ports whitelist localnet
>

Remove the above http_access lines.

> # Deny requests to certain unsafe ports
>
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports
>
> http_access deny CONNECT !SSL_ports
>

This is where the whiltelist lines should be placed.

> # Lastly deny all other access to this proxy
>
> http_access deny all
>
> # Listens to port 3128
>
> http_port 3128
>

Add this line:
  http_port 80 accel

> # DNS servers (Change dns_nameservers to client dns servers for 
> consistency and better performance)
>
> dns_nameservers 8.8.8.8 8.8.4.4
>

NP: Google DNS server farm design causes DNS results to churn on every 
single request. This breaks HTTP/1.x connection persistence, pipeline 
and multiplexing performance features. If you want these performance 
enhancing features to work properly you should run your own local DNS 
resolver and have Squid and the LAN use that.

> # Roll log file daily and keep 30 days
>
> logfile_rotate 30
>
> # Access log format
>
> logformat squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
>
>

Do not re-define the "squid" default logformat the result will not be 
what you want.
If you need something that is not provided by one of the default formats 
use a format name of your own choosing name.

> # Debug (Only used by Rave Service Personnel)
>
> # debug_options             ALL,2
>
> # Use IPv4 based DNS first
>
> dns_v4_first on
>
> # Log definitions
>
> access_log stdio:c:/Squid/var/log/squid/access.log
>
> cache_store_log stdio:c:/Squid/var/log/squid/store.log
>
> buffered_logs on
>
>

.. and finally as Dijixie mentioned dont forget to reload Squid.

PS: If you are using Squid-3 on one of the latest Linux with systemd 
that may need to be a full stop/start cycle to make sure it works due to 
problems systemd has with services like Squid-3.

Amos



From squid3 at treenet.co.nz  Sat May 20 11:27:10 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 May 2017 23:27:10 +1200
Subject: [squid-users] Documentation for squidclient?
In-Reply-To: <1495219592156-4682491.post@n4.nabble.com>
References: <1495111693229-4682457.post@n4.nabble.com>
 <1495112822444-4682458.post@n4.nabble.com>
 <65d362a3-0b6d-f9a2-c028-b039a039f09d@gmail.com>
 <1495124861774-4682467.post@n4.nabble.com>
 <1495125079578-4682468.post@n4.nabble.com>
 <1495125233911-4682469.post@n4.nabble.com>
 <40108344-b1da-93d2-ea40-a627ec29ed77@treenet.co.nz>
 <1495219592156-4682491.post@n4.nabble.com>
Message-ID: <461ba1fa-f1ac-254c-4e84-5d662b49ff12@treenet.co.nz>

On 20/05/17 06:46, erdosain9 wrote:
> This values are fine?? probably yes, but how can i tune for better??

They look reasonably okay to me.

The service time is probably the only worry, Squid config cannot fix 
that - it is up to your AD or equivalent system to be tuned for faster 
response times. I don't use AD etc myself so cannot help with that setup 
sorry.


Amos



From squid3 at treenet.co.nz  Sat May 20 11:30:46 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 May 2017 23:30:46 +1200
Subject: [squid-users] Change are not taking
In-Reply-To: <f50726c5-07fd-8b01-4eae-05cde2444b37@treenet.co.nz>
References: <000601d2d0c3$463d7a80$d2b86f80$@verizon.net>
 <f50726c5-07fd-8b01-4eae-05cde2444b37@treenet.co.nz>
Message-ID: <9e4f815f-c5fd-5769-431f-09ccb568ca06@treenet.co.nz>

Sorry I missed one part...


On 20/05/17 23:22, Amos Jeffries wrote:
> On 20/05/17 05:13, Patrick Flaherty wrote:
>>
>> Hi,
>>
>> I am making changes to my squid.conf, yet they don?t seem to take. Is 
>> there something I?m missing? Any help appreciated
>>
>
> From the changes below it looks like you are attempting to configure a 
> reverse-proxy. Relevant changes below:
>
>> # Squid Proxy Configuration
>>
>> # Network(s) where proxy traffic is originating
>>
>> # acl localnet src 10.0.0.0/8          # RFC1918 possible internal 
>> network
>>
>> # acl localnet src 172.16.0.0/12   # RFC1918 possible internal network
>>
>> # acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
>>
>> acl localnet src all
>>
>
> Remove the above change.
>
>> # acl and http_access ("rmsc.txt")
>>
>> acl whitelist dstdomain "c:/squid/etc/squid/rmsc.txt"
>>
>> http_access        allow     whitelist
>>
> Move this section down to the place marked below.
>
>> acl http      proto      http
>>
>> acl https     proto      https
>>
>> acl SSL_ports port 443
>>
>> acl Safe_ports port 80                    # http
>>
>> acl Safe_ports port 443                  # https
>>
>> acl CONNECT method CONNECT
>>
>> # rules allowing proxy access
>>
>> http_access allow http  Safe_ports whitelist localnet
>>
>> http_access allow https SSL_ports whitelist localnet
>>
>
> Remove the above http_access lines.
>
>> # Deny requests to certain unsafe ports
>>
>> http_access deny !Safe_ports
>>
>> # Deny CONNECT to other than secure SSL ports
>>
>> http_access deny CONNECT !SSL_ports
>>
>
> This is where the whiltelist lines should be placed.

Also, add cache_peer and cache_peer_access entries for each of your servers.

>
>> # Lastly deny all other access to this proxy
>>
>> http_access deny all
>>
>> # Listens to port 3128
>>
>> http_port 3128
>>
>
> Add this line:
>  http_port 80 accel
>
>> # DNS servers (Change dns_nameservers to client dns servers for 
>> consistency and better performance)
>>
>> dns_nameservers 8.8.8.8 8.8.4.4
>>
>
> NP: Google DNS server farm design causes DNS results to churn on every 
> single request. This breaks HTTP/1.x connection persistence, pipeline 
> and multiplexing performance features. If you want these performance 
> enhancing features to work properly you should run your own local DNS 
> resolver and have Squid and the LAN use that.
>
>> # Roll log file daily and keep 30 days
>>
>> logfile_rotate 30
>>
>> # Access log format
>>
>> logformat squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
>>
>>
>
> Do not re-define the "squid" default logformat the result will not be 
> what you want.
> If you need something that is not provided by one of the default 
> formats use a format name of your own choosing name.
>
>> # Debug (Only used by Rave Service Personnel)
>>
>> # debug_options             ALL,2
>>
>> # Use IPv4 based DNS first
>>
>> dns_v4_first on
>>
>> # Log definitions
>>
>> access_log stdio:c:/Squid/var/log/squid/access.log
>>
>> cache_store_log stdio:c:/Squid/var/log/squid/store.log
>>
>> buffered_logs on
>>
>>
>
> .. and finally as Dijixie mentioned dont forget to reload Squid.
>
> PS: If you are using Squid-3 on one of the latest Linux with systemd 
> that may need to be a full stop/start cycle to make sure it works due 
> to problems systemd has with services like Squid-3.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From Ralf.Hildebrandt at charite.de  Sat May 20 16:07:09 2017
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Sat, 20 May 2017 18:07:09 +0200
Subject: [squid-users] Tagged ACLs?
Message-ID: <20170520160709.tdz2yyazxntqeasz@charite.de>

Currently we're using a few blacklists (from abuse.ch) as ACLs on our
squid installation.

This is working well, but we want to create statistics on how many
clients were "caught" trying to access blocked sites.

Currently, we're grepping the log for TCP_DENIED in conjunction with the
patterns from the ACLs. This is working somewhat OK, but if access was
blocked using a pettern that was in use when the client tried to
access and was subsequently removed (prior to the time of the log
analysis process), it won't be found...

Is there any way around this? Like "tagging" rejects or logging the
ACL that caused the rejection? (Using squid-5 HEAD here)

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
https://www.charite.de             Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From rousskov at measurement-factory.com  Sat May 20 18:53:22 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 20 May 2017 12:53:22 -0600
Subject: [squid-users] Tagged ACLs?
In-Reply-To: <20170520160709.tdz2yyazxntqeasz@charite.de>
References: <20170520160709.tdz2yyazxntqeasz@charite.de>
Message-ID: <0fa8d307-cad9-00e0-e3ae-9d39cc3f3991@measurement-factory.com>

On 05/20/2017 10:07 AM, Ralf Hildebrandt wrote:

> we want to create statistics on how many
> clients were "caught" trying to access blocked sites.
> 
> Currently, we're grepping the log for TCP_DENIED in conjunction with the
> patterns from the ACLs. [...]  
> Is there any way around this? Like "tagging" rejects or logging the
> ACL that caused the rejection?

Yes, append an annotate_transaction ACL with a distinct annotation value
to each distinct http_access rule. If you have many such rules, this
should be automated, of course.

Log the added annotation using %note logformat code.

FWIW, the idea of logging "the [name of the] ACL that caused the
rejection" (a la deny_info) does not work well in general because the
same ACL name may appear in many rules (in general). And the idea of
logging the matched http_access rule "number" makes logged values very
fragile -- a single change in http_access lines may change the meaning
of half of the logged values.


HTH,

Alex.



From yuriang at ltu.sld.cu  Sat May 20 19:02:25 2017
From: yuriang at ltu.sld.cu (yuriang)
Date: Sat, 20 May 2017 15:02:25 -0400
Subject: [squid-users] It is possible to use SSL_bump on my squid server
	3.5.23, if my parent cache (cache_peer) does not use ssl_bump (not
	configured).
Message-ID: <201705201502253242538@ltu.sld.cu>

It is possible to use SSL_bump on my squid server 3.5.23, if my parent cache (cache_peer) does not use ssl_bump (not configured).

# When I try to access an https: //
# With this setting:

http_port 127.0.0.1:3129 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myCA.pem
sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
ssl_bump none localhost
ssl_bump server-first all
sslproxy_flags DONT_VERIFY_PEER
sslproxy_cert_error allow all

# Cache.log reports this error:
assertion failed: PeerConnector.cc:116: "peer->use_ssl"

# With this setting:
http_port 127.0.0.1:3129 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myCA.pem
sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
ssl_bump none localhost
ssl_bump bump all
sslproxy_flags DONT_VERIFY_PEER
sslproxy_cert_error allow all

# The browser designates that the connection is not private, NET::ERR_CERT_AUTHORITY_INVALID

Is it necessary for the cache_peer to be compiled with --enable-ssl-crtd and --with-openssl and configured with ssl_bump to be able to use ssl_bump on my squid child server? Or there is a way to configure ssl_bump on the child only, even if the parent does not.

Please help.


--
Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas

Infomed: http://www.sld.cu/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170520/8515ce01/attachment.htm>

From dijxie at gmail.com  Sat May 20 19:37:53 2017
From: dijxie at gmail.com (Dijxie)
Date: Sat, 20 May 2017 21:37:53 +0200
Subject: [squid-users] Tagged ACLs?
In-Reply-To: <20170520160709.tdz2yyazxntqeasz@charite.de>
References: <20170520160709.tdz2yyazxntqeasz@charite.de>
Message-ID: <a24d996b-2523-d641-8369-8e2631f60f17@gmail.com>

W dniu 20.05.2017 o 18:07, Ralf Hildebrandt pisze:
> Currently we're using a few blacklists (from abuse.ch) as ACLs on our
> squid installation.
>
> This is working well, but we want to create statistics on how many
> clients were "caught" trying to access blocked sites.
>
> Currently, we're grepping the log for TCP_DENIED in conjunction with the
> patterns from the ACLs. This is working somewhat OK, but if access was
> blocked using a pettern that was in use when the client tried to
> access and was subsequently removed (prior to the time of the log
> analysis process), it won't be found...
>
> Is there any way around this? Like "tagging" rejects or logging the
> ACL that caused the rejection? (Using squid-5 HEAD here)
>
Hi,

Try that:
http://www.squid-cache.org/Doc/config/logformat/
"Access Control related format codes" => "et" can be the thing you are 
looking for.

-- 
Pozdrawiam, Remik

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170520/15c139a3/attachment.htm>

From vze2k3sa at verizon.net  Sat May 20 22:20:27 2017
From: vze2k3sa at verizon.net (vze2k3sa at verizon.net)
Date: Sat, 20 May 2017 18:20:27 -0400
Subject: [squid-users] FW: squid-users Digest, Vol 33, Issue 64
Message-ID: <009601d2d1b7$49118130$db348390$@verizon.net>

----------------------------------------------------------------------------
---

 

Thanks so much Amos, I eliminated a lot of lines per your suggestion and I
see now how line precedence matters!

 

Also the directive ' http_port 80 accel' seems to have seemingly sped up the
server dramatically. It co-exists with my default listening ports which is a
bit confusing.

 

http_port 3128

http_port 80 accel

 

Do both of these (speed and co-existance) makes sense?

 

Thanks again,

Patrick

 

----------------------------------------------------------------------------
---

 

Message: 3

Date: Sat, 20 May 2017 23:22:26 +1200

From: Amos Jeffries <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz> >

To: squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org> 

Subject: Re: [squid-users] Change are not taking

Message-ID: <f50726c5-07fd-8b01-4eae-05cde2444b37 at treenet.co.nz
<mailto:f50726c5-07fd-8b01-4eae-05cde2444b37 at treenet.co.nz> >

Content-Type: text/plain; charset=utf-8; format=flowed

 

On 20/05/17 05:13, Patrick Flaherty wrote:

> 

> Hi,

> 

> I am making changes to my squid.conf, yet they don't seem to take. Is 

> there something I'm missing? Any help appreciated

> 

 

>From the changes below it looks like you are attempting to configure a
reverse-proxy. Relevant changes below:

 

> # Squid Proxy Configuration

> 

> # Network(s) where proxy traffic is originating

> 

> # acl localnet src 10.0.0.0/8          # RFC1918 possible internal network

> 

> # acl localnet src 172.16.0.0/12   # RFC1918 possible internal network

> 

> # acl localnet src 192.168.0.0/16 # RFC1918 possible internal network

> 

> acl localnet src all

> 

 

Remove the above change.

 

> # acl and http_access ("rmsc.txt")

> 

> acl whitelist dstdomain "c:/squid/etc/squid/rmsc.txt"

> 

> http_access        allow     whitelist

> 

Move this section down to the place marked below.

 

> acl http      proto      http

> 

> acl https     proto      https

> 

> acl SSL_ports port 443

> 

> acl Safe_ports port 80                    # http

> 

> acl Safe_ports port 443                  # https

> 

> acl CONNECT method CONNECT

> 

> # rules allowing proxy access

> 

> http_access allow http  Safe_ports whitelist localnet

> 

> http_access allow https SSL_ports whitelist localnet

> 

 

Remove the above http_access lines.

 

> # Deny requests to certain unsafe ports

> 

> http_access deny !Safe_ports

> 

> # Deny CONNECT to other than secure SSL ports

> 

> http_access deny CONNECT !SSL_ports

> 

 

This is where the whiltelist lines should be placed.

 

> # Lastly deny all other access to this proxy

> 

> http_access deny all

> 

> # Listens to port 3128

> 

> http_port 3128

> 

 

Add this line:

  http_port 80 accel

 

> # DNS servers (Change dns_nameservers to client dns servers for 

> consistency and better performance)

> 

> dns_nameservers 8.8.8.8 8.8.4.4

> 

 

NP: Google DNS server farm design causes DNS results to churn on every
single request. This breaks HTTP/1.x connection persistence, pipeline and
multiplexing performance features. If you want these performance enhancing
features to work properly you should run your own local DNS resolver and
have Squid and the LAN use that.

 

> # Roll log file daily and keep 30 days

> 

> logfile_rotate 30

> 

> # Access log format

> 

> logformat squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt

> 

> 

 

Do not re-define the "squid" default logformat the result will not be what
you want.

If you need something that is not provided by one of the default formats use
a format name of your own choosing name.

 

> # Debug (Only used by Rave Service Personnel)

> 

> # debug_options             ALL,2

> 

> # Use IPv4 based DNS first

> 

> dns_v4_first on

> 

> # Log definitions

> 

> access_log stdio:c:/Squid/var/log/squid/access.log

> 

> cache_store_log stdio:c:/Squid/var/log/squid/store.log

> 

> buffered_logs on

> 

> 

 

.. and finally as Dijixie mentioned dont forget to reload Squid.

 

PS: If you are using Squid-3 on one of the latest Linux with systemd that
may need to be a full stop/start cycle to make sure it works due to problems
systemd has with services like Squid-3.

 

Amos

 

 

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170520/a6911034/attachment.htm>

From nldo.tut.alberto at gmail.com  Sun May 21 14:51:54 2017
From: nldo.tut.alberto at gmail.com (Ikari C)
Date: Sun, 21 May 2017 09:51:54 -0500
Subject: [squid-users] clientside_mark
Message-ID: <CACmb8S=KG28hK7piF==hPdJnGYPBhhbbdEkkoHsDhVn8iwnxHQ@mail.gmail.com>

Hi, i'm new in maillist and in Squid configuration, I use Squid 3.5 version
and i read about clientside_mark configuration, but i have a doubt, wich
type of  ACL is compatible with this option. I want to create a MARK by
dstdomain ACL, and use TC configuration to set QOS, it is posible? or only
works with SRC ALC type.


i want to do this in squid.conf:

acl aclname1 dstdomain url1
acl aclname2 dstdomain url2
clientside_mark 0x3 aclname1
clientside_mark 0x4 aclname2

the configuration on squid.conf is the default.



Thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170521/17a6358d/attachment.htm>

From style9595 at gmail.com  Mon May 22 09:01:36 2017
From: style9595 at gmail.com (Dominic Kim)
Date: Mon, 22 May 2017 18:01:36 +0900
Subject: [squid-users] 503 service unavailable on connection refused
Message-ID: <CAFEpjOqc+aNX=B8pKXvPLXDj7Af+4cBtSnXC=ditUhfE0AV0yw@mail.gmail.com>

When I connect to a target server via squid, if server does not exist, I
get "No route to host" error.
And if server exist, but port is not opened yet, I get "Connection refused"
error.

As per the definition of "connect_retries" option, it should retry when
connection attempt failed.
(reference: http://www.squid-cache.org/Doc/config/connect_retries/)

IMHO, in both the cases, connection attempts failed and it is supposed to
retry.
However, if I enable this feature, it only retries on "No route to host"
error.
In case of "Connection refused", I am getting 503 service unavailable error
immediately.

Are there anyway to fix this behavior?
Kindly help me.

Thanks
Regards
Dongkyoung
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170522/816d5c6e/attachment.htm>

From style9595 at gmail.com  Mon May 22 09:02:32 2017
From: style9595 at gmail.com (Dominic Kim)
Date: Mon, 22 May 2017 18:02:32 +0900
Subject: [squid-users] 503 service unavailable on connection refused
In-Reply-To: <CAFEpjOqc+aNX=B8pKXvPLXDj7Af+4cBtSnXC=ditUhfE0AV0yw@mail.gmail.com>
References: <CAFEpjOqc+aNX=B8pKXvPLXDj7Af+4cBtSnXC=ditUhfE0AV0yw@mail.gmail.com>
Message-ID: <CAFEpjOotnQC0n_3wETRqQ8QUP8Gt9D_ANvij2vH=+W26K7hxoQ@mail.gmail.com>

I have tested with squid 3.3, 3.5, 4.
And the behavior were same.

Thanks
Regards
Dongkyoung

2017-05-22 18:01 GMT+09:00 Dominic Kim <style9595 at gmail.com>:

> When I connect to a target server via squid, if server does not exist, I
> get "No route to host" error.
> And if server exist, but port is not opened yet, I get "Connection
> refused" error.
>
> As per the definition of "connect_retries" option, it should retry when
> connection attempt failed.
> (reference: http://www.squid-cache.org/Doc/config/connect_retries/)
>
> IMHO, in both the cases, connection attempts failed and it is supposed to
> retry.
> However, if I enable this feature, it only retries on "No route to host"
> error.
> In case of "Connection refused", I am getting 503 service unavailable
> error immediately.
>
> Are there anyway to fix this behavior?
> Kindly help me.
>
> Thanks
> Regards
> Dongkyoung
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170522/607210f9/attachment.htm>

From yuriang at ltu.sld.cu  Mon May 22 14:14:07 2017
From: yuriang at ltu.sld.cu (yuriang)
Date: Mon, 22 May 2017 10:14:07 -0400
Subject: [squid-users] It is possible to use SSL_bump on my squid server
	3.5.23, if my parent cache (cache_peer) does not use ssl_bump (not
	configured).
Message-ID: <201705221014073007673@ltu.sld.cu>


It is possible to use SSL_bump on my squid server 3.5.23, if my parent cache (cache_peer) does not use ssl_bump (not configured).

# When I try to access an https: //
# With this setting:

http_port 127.0.0.1:3129 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myCA.pem
sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
ssl_bump none localhost
ssl_bump server-first all
sslproxy_flags DONT_VERIFY_PEER
sslproxy_cert_error allow all

# Cache.log reports this error:
assertion failed: PeerConnector.cc:116: "peer->use_ssl"

# With this setting:
http_port 127.0.0.1:3129 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myCA.pem
sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
ssl_bump none localhost
ssl_bump bump all
sslproxy_flags DONT_VERIFY_PEER
sslproxy_cert_error allow all

# The browser designates that the connection is not private, NET::ERR_CERT_AUTHORITY_INVALID

Is it necessary for the cache_peer to be compiled with --enable-ssl-crtd and --with-openssl and configured with ssl_bump to be able to use ssl_bump on my squid child server? Or there is a way to configure ssl_bump on the child only, even if the parent does not.

Please help.


--
Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas

Infomed: http://www.sld.cu/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170522/5c7aaf8a/attachment.htm>

From marciobacci at gmail.com  Mon May 22 14:15:07 2017
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Mon, 22 May 2017 11:15:07 -0300
Subject: [squid-users] Problem with Squid3 Authentication
Message-ID: <CA+0TdyqWG9Y96fBK+0+19vYUW9_9e6mMekkY47sUnY4Bw0douw@mail.gmail.com>

I have migrated of Samba 4.2.1 to Samba 4.6.3 as DC, but now my Squid
authentication doesn't work.

In samba 4.2.1 is working properly.

This is my authentication block:


auth_param basic program /usr/lib/squid3/basic_ldap_auth -R -b
DC=empresa,DC=com,DC=br -D CN=proxy,CN=Users,DC=empresa,DC=com,DC=br -w
password -h 192.168.10.4 -p 389 -s sub -v 3 -f "sAMAccountName=%s"
auth_param basic children 50
auth_param basic realm Access Monitored
auth_param basic credentialsttl 8 hours
auth_param basic casesensitive off

I'm using Squid 3.4.8

Can anybody help me ?

Regards,

M?rcio Bacci
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170522/1b8d4535/attachment.htm>

From rousskov at measurement-factory.com  Mon May 22 14:48:44 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 22 May 2017 08:48:44 -0600
Subject: [squid-users] Tagged ACLs?
In-Reply-To: <20170522115633.bbmbfbfgbdfsxovb@charite.de>
References: <20170520160709.tdz2yyazxntqeasz@charite.de>
 <0fa8d307-cad9-00e0-e3ae-9d39cc3f3991@measurement-factory.com>
 <20170522115633.bbmbfbfgbdfsxovb@charite.de>
Message-ID: <67aba1d0-e704-a5ac-ab3f-58f3e351e9f5@measurement-factory.com>

On 05/22/2017 05:56 AM, Ralf Hildebrandt wrote:
> * Alex Rousskov <rousskov at measurement-factory.com>:
>> On 05/20/2017 10:07 AM, Ralf Hildebrandt wrote:
>>> we want to create statistics on how many
>>> clients were "caught" trying to access blocked sites.
>>>
>>> Currently, we're grepping the log for TCP_DENIED in conjunction with the
>>> patterns from the ACLs. [...]  
>>> Is there any way around this? Like "tagging" rejects or logging the
>>> ACL that caused the rejection?

>> Yes, append an annotate_transaction ACL with a distinct annotation value
>> to each distinct http_access rule. If you have many such rules, this
>> should be automated, of course.
>>
>> Log the added annotation using %note logformat code.

> How would I add this to this exemplary ACL?

> acl zeustrackerdomain dstdomain "/etc/squid3/generated-zeus-domainblocklist.acl"
> http_access deny zeustrackerdomain

You do not add this to an ACL. You add this to an http_access rule:

   acl markZeustrackerdomain annotate_transaction
accessRule=zeustrackerdomain
   acl markFoobar annotate_transaction accessRule=foobar
   ...

   http_access deny zeustrackerdomain markZeustrackerdomain
   http_access allow foo bar markFoobar
   ...

   logformat ... accessRule=%{accessRule}note ...


> deny_info   http://proxy.charite.de/zeusdomain/ zeustrackerdomain

The above deny_info would have to be adjusted to stay in sync:

  deny_info http://proxy.charite.de/zeusdomain/ markZeustrackerdomain


HTH,

Alex.



From rousskov at measurement-factory.com  Mon May 22 16:13:47 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 22 May 2017 10:13:47 -0600
Subject: [squid-users] 503 service unavailable on connection refused
In-Reply-To: <CAFEpjOotnQC0n_3wETRqQ8QUP8Gt9D_ANvij2vH=+W26K7hxoQ@mail.gmail.com>
References: <CAFEpjOqc+aNX=B8pKXvPLXDj7Af+4cBtSnXC=ditUhfE0AV0yw@mail.gmail.com>
 <CAFEpjOotnQC0n_3wETRqQ8QUP8Gt9D_ANvij2vH=+W26K7hxoQ@mail.gmail.com>
Message-ID: <12341987-c2ab-d01a-922c-c64f756edaa9@measurement-factory.com>

On 05/22/2017 03:02 AM, Dominic Kim wrote:
> I have tested with squid 3.3, 3.5, 4.
> And the behavior were same.

When using Squid v3.5 or v4, please reproduce the problem using a single
HTTP transaction while collecting level-7 or higher debugging and then
post the corresponding (compressed) cache.log.

http://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction

Alex.


> 2017-05-22 18:01 GMT+09:00 Dominic Kim:
> 
>     When I connect to a target server via squid, if server does not
>     exist, I get "No route to host" error.
>     And if server exist, but port is not opened yet, I get "Connection
>     refused" error.
> 
>     As per the definition of "connect_retries" option, it should retry
>     when connection attempt failed.
>     (reference: http://www.squid-cache.org/Doc/config/connect_retries/
>     <http://www.squid-cache.org/Doc/config/connect_retries/>)
> 
>     IMHO, in both the cases, connection attempts failed and it is
>     supposed to retry.
>     However, if I enable this feature, it only retries on "No route to
>     host" error.
>     In case of "Connection refused", I am getting 503 service
>     unavailable error immediately.
> 
>     Are there anyway to fix this behavior?
>     Kindly help me.
> 
>     Thanks
>     Regards
>     Dongkyoung
> 
> 
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From erdosain9 at gmail.com  Mon May 22 19:11:01 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 22 May 2017 12:11:01 -0700 (PDT)
Subject: [squid-users] Documentation for squidclient?
In-Reply-To: <461ba1fa-f1ac-254c-4e84-5d662b49ff12@treenet.co.nz>
References: <1495111693229-4682457.post@n4.nabble.com>
 <1495112822444-4682458.post@n4.nabble.com>
 <65d362a3-0b6d-f9a2-c028-b039a039f09d@gmail.com>
 <1495124861774-4682467.post@n4.nabble.com>
 <1495125079578-4682468.post@n4.nabble.com>
 <1495125233911-4682469.post@n4.nabble.com>
 <40108344-b1da-93d2-ea40-a627ec29ed77@treenet.co.nz>
 <1495219592156-4682491.post@n4.nabble.com>
 <461ba1fa-f1ac-254c-4e84-5d662b49ff12@treenet.co.nz>
Message-ID: <1495480261434-4682512.post@n4.nabble.com>

Ok, 
Thanks.
We are using a windows server 2012...

Can you explain to me how the negotiate authenticator works??
how works? when a user want browser to a page, the squid, use the
authenticator for know if can browse?? every time? for every single web
pages?
Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Documentation-for-squidclient-tp4682457p4682512.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Mon May 22 19:53:53 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 23 May 2017 07:53:53 +1200
Subject: [squid-users] Documentation for squidclient?
In-Reply-To: <1495480261434-4682512.post@n4.nabble.com>
References: <1495111693229-4682457.post@n4.nabble.com>
 <1495112822444-4682458.post@n4.nabble.com>
 <65d362a3-0b6d-f9a2-c028-b039a039f09d@gmail.com>
 <1495124861774-4682467.post@n4.nabble.com>
 <1495125079578-4682468.post@n4.nabble.com>
 <1495125233911-4682469.post@n4.nabble.com>
 <40108344-b1da-93d2-ea40-a627ec29ed77@treenet.co.nz>
 <1495219592156-4682491.post@n4.nabble.com>
 <461ba1fa-f1ac-254c-4e84-5d662b49ff12@treenet.co.nz>
 <1495480261434-4682512.post@n4.nabble.com>
Message-ID: <c5dad687-2c52-ff73-07a7-1e5dbcc2b3c0@treenet.co.nz>

On 23/05/17 07:11, erdosain9 wrote:
> Ok,
> Thanks.
> We are using a windows server 2012...
>
> Can you explain to me how the negotiate authenticator works??

<http://wiki.squid-cache.org/Features/Authentication#How_does_Proxy_Authentication_work_in_Squid.3F>

> how works? when a user want browser to a page, the squid, use the
> authenticator for know if can browse??

If your ACLs configuration requires credentials for that request, yes.

>   every time? for every single web
> pages?

HTTP is stateless. Each request is required to contain all the necessary 
details to server it. So every single time a request is sent to the 
proxy credentials are needed in that message.

Note that "page" is a UI concept, one "page" may be a few or hundreds of 
objects - one request is sent to the proxy for each object that needs 
fetching or updating by the Browser.

Squid does not use the helper for every request though. The Negotiate 
and NTLM schemes authenticates a TCP connection (not a user), so once a 
request has been authenticated those credentials are "cached" as peer of 
the connection state and the credentials on further requests are simply 
compared against the previous ones until their TTL expires.

Amos



From rousskov at measurement-factory.com  Mon May 22 20:06:20 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 22 May 2017 14:06:20 -0600
Subject: [squid-users] It is possible to use SSL_bump on my squid server
 3.5.23,
 if my parent cache (cache_peer) does not use ssl_bump (not configured).
In-Reply-To: <201705221014073007673@ltu.sld.cu>
References: <201705221014073007673@ltu.sld.cu>
Message-ID: <ee8e1c3a-85d1-c5a6-de2f-249d8ab9e4fd@measurement-factory.com>

On 05/22/2017 08:14 AM, yuriang wrote:

> It is possible to use SSL_bump on my squid server 3.5.23, if my parent
> cache (cache_peer) does not use ssl_bump (not configured).

I do not think it is possible to use SslBump steps 2+ with cache_peers
that expect plain HTTP requests. AFAICT, for SslBump to work with a
cache peer beyond the first step, the cache_peer line in the child
squid.conf has to configure that peer as an TLS origin server. Here are
some potentially relevant emails about this missing feature:

http://lists.squid-cache.org/pipermail/squid-users/2017-January/014283.html

http://lists.squid-cache.org/pipermail/squid-users/2017-January/014287.html

http://lists.squid-cache.org/pipermail/squid-users/2017-January/014290.html

Please note that this is not about "my parent does not use ssl_bump"
specifically but about "I use a cache_peer" in general.

Alex.



From squid3 at treenet.co.nz  Mon May 22 20:46:29 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 23 May 2017 08:46:29 +1200
Subject: [squid-users] Problem with Squid3 Authentication
In-Reply-To: <CA+0TdyqWG9Y96fBK+0+19vYUW9_9e6mMekkY47sUnY4Bw0douw@mail.gmail.com>
References: <CA+0TdyqWG9Y96fBK+0+19vYUW9_9e6mMekkY47sUnY4Bw0douw@mail.gmail.com>
Message-ID: <7e19132d-9430-c473-2dfe-8885f2844f9c@treenet.co.nz>

On 23/05/17 02:15, Marcio Demetrio Bacci wrote:
> I have migrated of Samba 4.2.1 to Samba 4.6.3 as DC, but now my Squid 
> authentication doesn't work.
>
> In samba 4.2.1 is working properly.
>
> This is my authentication block:
>
>
> auth_param basic program /usr/lib/squid3/basic_ldap_auth -R -b 
> DC=empresa,DC=com,DC=br -D CN=proxy,CN=Users,DC=empresa,DC=com,DC=br 
> -w password -h 192.168.10.4 -p 389 -s sub -v 3 -f "sAMAccountName=%s"
> auth_param basic children 50
> auth_param basic realm Access Monitored
> auth_param basic credentialsttl 8 hours
> auth_param basic casesensitive off
>
> I'm using Squid 3.4.8
>
> Can anybody help me ?

If the only thing that changed was Samba its clearly an issue with that 
end of the system.

I suggest you compare those LDAP parameters with what the new Samba 
version needs, and if there is no issue there please contact your vendor 
or the Samba help channels.

Amos



From squid3 at treenet.co.nz  Mon May 22 21:03:05 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 23 May 2017 09:03:05 +1200
Subject: [squid-users] clientside_mark
In-Reply-To: <CACmb8S=KG28hK7piF==hPdJnGYPBhhbbdEkkoHsDhVn8iwnxHQ@mail.gmail.com>
References: <CACmb8S=KG28hK7piF==hPdJnGYPBhhbbdEkkoHsDhVn8iwnxHQ@mail.gmail.com>
Message-ID: <f9facfaf-1940-6e6b-8237-5495e617884c@treenet.co.nz>

On 22/05/17 02:51, Ikari C wrote:
> Hi, i'm new in maillist and in Squid configuration, I use Squid 3.5 
> version and i read about clientside_mark configuration, but i have a 
> doubt, wich type of  ACL is compatible with this option. I want to 
> create a MARK by dstdomain ACL, and use TC configuration to set QOS, 
> it is posible? or only works with SRC ALC type.
>
>
> i want to do this in squid.conf:
>
> acl aclname1 dstdomain url1
> acl aclname2 dstdomain url2
> clientside_mark 0x3 aclname1
> clientside_mark 0x4 aclname2
>
> the configuration on squid.conf is the default.
>

Any of the ACLs which work in http_access should work there too.

However, because HTTP contains message pipelines the arrival time of any 
given request may be significantly different from the response delivery 
time. i.e. there may be earlier requested responses using the connection 
between now (when the MARK gets set by the newly arrived request) and 
the response you were intending to mark. So it is best to only rely on 
TCP level things if you can.

Amos



From sobredinero1 at gmail.com  Mon May 22 23:39:50 2017
From: sobredinero1 at gmail.com (George Diaz)
Date: Mon, 22 May 2017 19:39:50 -0400
Subject: [squid-users] a bit off topic. New user question
Message-ID: <CAEO0YGAUdewLw0EqEZoPfmFS0PUcZUyYQJKV74z_1+t5eDs-SA@mail.gmail.com>

Hi

sorry this off-topic question ...

I want pre-cache some object from some interest host with wget.

My question is : I want: the wget download the object to the /dev/null but
I'm not found this switches....
(GNU Wget 1.5.3)

I'm probe this :
export http_proxy=http://mycache.com:8080/
wget -r http://sobredinero.com -P /dev/null -nH -nd -Y on -b -l5 -t1 -o
/dev/null

but this is create a /dev/null directory :) and download the files into
this.

any suggestions ?

Thanks in advance.

George
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170522/23ec63f7/attachment.htm>

From nldo.tut.alberto at gmail.com  Tue May 23 00:03:05 2017
From: nldo.tut.alberto at gmail.com (Ikari C)
Date: Mon, 22 May 2017 19:03:05 -0500
Subject: [squid-users] clientside_mark
Message-ID: <CACmb8SnHa9fA0hrCmLJ0yGMrQxywgC7ECL8hp473ABb37MYo-Q@mail.gmail.com>

On 22/05/17 02:51, Ikari C wrote:

> Hi, i'm new in maillist and in Squid configuration, I use Squid 3.5
> version and i read about clientside_mark configuration, but i have a doubt,
> wich type of  ACL is compatible with this option. I want to create a MARK
> by dstdomain ACL, and use TC configuration to set QOS, it is posible? or
> only works with SRC ALC type.
>
>
> i want to do this in squid.conf:
>
> acl aclname1 dstdomain url1
> acl aclname2 dstdomain url2
> clientside_mark 0x3 aclname1
> clientside_mark 0x4 aclname2
>
> the configuration on squid.conf is the default.
>
>
Any of the ACLs which work in http_access should work there too.

However, because HTTP contains message pipelines the arrival time of any
given request may be significantly different from the response delivery
time. i.e. there may be earlier requested responses using the connection
between now (when the MARK gets set by the newly arrived request) and the
response you were intending to mark. So it is best to only rely on TCP
level things if you can.

Amos


Thanks. i will keep it in mind

I tested this configuration and squid effectively mark this packages (I saw
with iptables --m mark --mark X -j log) but mark also other domain that i
have visited inmediately after and they aren't in the acl, for example, if
i put "acl ac1 dstdomain .yahoo.com", squid mark this package, but if i go
to google.com squid also mark the google package, but if i go to google
first than yahoo.com squid doesn't mark the package to google, and then i
go to yahoo, squid mark the yahoo package, and if i go to visit again
google, "squid" mark the package google too. I wanted to create a QOS based
by domain whith TC configuration.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170522/e4ed54b3/attachment.htm>

From harariboy at gmail.com  Tue May 23 01:25:28 2017
From: harariboy at gmail.com (avi_h)
Date: Mon, 22 May 2017 18:25:28 -0700 (PDT)
Subject: [squid-users] External ACL
Message-ID: <1495502728560-4682519.post@n4.nabble.com>

Hi,

I'm currently using the DB authentication (squid_db_auth).
This works flawlessly, however I have a need to enable authentication by a
list of IPs.
I tried using a simple ACL, but it's not dynamic so that doesn't answer my
need.
So I'm trying to create an external ACL.
For some reason the external ACL isn't working.
In order to check this, I commented out all the configs of squid_db_auth.
Please see the configurations below:

external_acl_type ip_checker children-max=20 %SRC
/usr/lib64/squid/ip_checker.sh
acl allowed_ips external ip_checker

http_access allow allowed_ips

cat /usr/lib64/squid/ip_checker.sh

#!/bin/bash

while read ip
do
  if ! grep -w "$ip" /etc/squid/allowed_ips.txt ; then
    echo "ERR"
  else echo "OK"
  fi
done

cat /etc/squid/allowed_ips.txt
192.168.1.1

The error message I'm getting:

2017/05/23 01:33:09.160 kid1| 82,2| external_acl.cc(786) aclMatchExternal:
ip_checker("192.168.1.1") = lookup needed
2017/05/23 01:33:09.160 kid1| WARNING: external ACL 'ip_checker' queue
overload. Request rejected '192.168.1.1'.

Thanks in advance,
Avi



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/External-ACL-tp4682519.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Tue May 23 04:45:57 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 23 May 2017 16:45:57 +1200
Subject: [squid-users] clientside_mark
In-Reply-To: <CACmb8SnHa9fA0hrCmLJ0yGMrQxywgC7ECL8hp473ABb37MYo-Q@mail.gmail.com>
References: <CACmb8SnHa9fA0hrCmLJ0yGMrQxywgC7ECL8hp473ABb37MYo-Q@mail.gmail.com>
Message-ID: <e1c8980a-3ab8-4234-bca0-190b9c1457f5@treenet.co.nz>



On 23/05/17 12:03, Ikari C wrote:
> On 22/05/17 02:51, Ikari C wrote:
>
>     Hi, i'm new in maillist and in Squid configuration, I use Squid
>     3.5 version and i read about clientside_mark configuration, but i
>     have a doubt, wich type of  ACL is compatible with this option. I
>     want to create a MARK by dstdomain ACL, and use TC configuration
>     to set QOS, it is posible? or only works with SRC ALC type.
>
>
>     i want to do this in squid.conf:
>
>     acl aclname1 dstdomain url1
>     acl aclname2 dstdomain url2
>     clientside_mark 0x3 aclname1
>     clientside_mark 0x4 aclname2
>
>     the configuration on squid.conf is the default.
>
>
> Any of the ACLs which work in http_access should work there too.
>
> However, because HTTP contains message pipelines the arrival time of 
> any given request may be significantly different from the response 
> delivery time. i.e. there may be earlier requested responses using the 
> connection between now (when the MARK gets set by the newly arrived 
> request) and the response you were intending to mark. So it is best to 
> only rely on TCP level things if you can.
>
> Amos
>
>
> Thanks. i will keep it in mind
>
> I tested this configuration and squid effectively mark this packages 
> (I saw with iptables --m mark --mark X -j log) but mark also other 
> domain that i have visited inmediately after and they aren't in the 
> acl, for example, if i put "acl ac1 dstdomain .yahoo.com 
> <http://yahoo.com/>", squid mark this package, but if i go to 
> google.com <http://google.com/> squid also mark the google package, 
> but if i go to google first than yahoo.com <http://yahoo.com/> squid 
> doesn't mark the package to google, and then i go to yahoo, squid mark 
> the yahoo package, and if i go to visit again google, "squid" mark the 
> package google too. I wanted to create a QOS based by domain whith TC 
> configuration.

I think you have missed the fact that this is marking the *connection*, 
not the message. So the mark remains set on the connection until you 
unset it, change it, or the connection closes.

Amos



From squid3 at treenet.co.nz  Tue May 23 05:00:16 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 23 May 2017 17:00:16 +1200
Subject: [squid-users] External ACL
In-Reply-To: <1495502728560-4682519.post@n4.nabble.com>
References: <1495502728560-4682519.post@n4.nabble.com>
Message-ID: <046c5862-9f83-911e-0e0f-aa3d52db6a34@treenet.co.nz>

On 23/05/17 13:25, avi_h wrote:
> Hi,
>
> I'm currently using the DB authentication (squid_db_auth).
> This works flawlessly, however I have a need to enable authentication by a
> list of IPs.

What do you mean by that exactly?

> I tried using a simple ACL, but it's not dynamic so that doesn't answer my
> need.
> So I'm trying to create an external ACL.
> For some reason the external ACL isn't working.
> In order to check this, I commented out all the configs of squid_db_auth.
> Please see the configurations below:
>
> external_acl_type ip_checker children-max=20 %SRC
> /usr/lib64/squid/ip_checker.sh
> acl allowed_ips external ip_checker
>
> http_access allow allowed_ips
>
> cat /usr/lib64/squid/ip_checker.sh
>
> #!/bin/bash
>
> while read ip
> do
>    if ! grep -w "$ip" /etc/squid/allowed_ips.txt ; then
>      echo "ERR"
>    else echo "OK"
>    fi
> done
>
> cat /etc/squid/allowed_ips.txt
> 192.168.1.1
>
> The error message I'm getting:
>
> 2017/05/23 01:33:09.160 kid1| 82,2| external_acl.cc(786) aclMatchExternal:
> ip_checker("192.168.1.1") = lookup needed
> 2017/05/23 01:33:09.160 kid1| WARNING: external ACL 'ip_checker' queue
> overload. Request rejected '192.168.1.1'.

For some reason your helper is not coping with the amount of traffic 
going through your Squid, even with 20 processes running.

I don't see anything particularly wrong with the script logic, maybe 
just the inefficiency of using bash and grep?
  or perhapse how you are designing the http_access sequence? order 
matters a lot.


Amos



From squid3 at treenet.co.nz  Tue May 23 05:29:30 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 23 May 2017 17:29:30 +1200
Subject: [squid-users] a bit off topic. New user question
In-Reply-To: <CAEO0YGAUdewLw0EqEZoPfmFS0PUcZUyYQJKV74z_1+t5eDs-SA@mail.gmail.com>
References: <CAEO0YGAUdewLw0EqEZoPfmFS0PUcZUyYQJKV74z_1+t5eDs-SA@mail.gmail.com>
Message-ID: <6bc164b0-ea28-ba6f-bbbd-988ac699864c@treenet.co.nz>

On 23/05/17 11:39, George Diaz wrote:
>
> Hi
>
> sorry this off-topic question ...
>
> I want pre-cache some object from some interest host with wget.
>
> My question is : I want: the wget download the object to the /dev/null 
> but
> I'm not found this switches....
> (GNU Wget 1.5.3)
>
> I'm probe this :
> export http_proxy=http://mycache.com:8080/
> wget -r http://sobredinero.com -P /dev/null -nH -nd -Y on -b -l5 -t1 
> -o /dev/null
>
> but this is create a /dev/null directory :) and download the files 
> into this.
>
> any suggestions ?
>

Some advice before you get too far into this project;

  Pre-caching was an good idea back in the days of HTTP/1.0 and static 
websites where the URL was all that mattered. In todays HTTP/1.1 and 
HTTP/2 world dynamic content and variants are much more common things, 
and both make pre-caching pretty much useless.

Before you attempt it for any domain I recommend passing a few of its 
URLs through the tool at <https://redbot.org>. If that tool indicates 
the site uses content negotiation or conditional HTTP features then 
pre-caching is just going to be causing problems.

For example; that sobredinero domain above produces these details:


      Content Negotiation

  * The response body is different when content negotiation happens.


      Caching

  * Vary: User-Agent can cause cache inefficiency.


This means that anything you pre-cache with wget will be ignored and 
probably replaced when any non-wget agent (ie a browser) is used to 
fetch through the proxy. So you just waste all the bandwidth, time, and 
storage space used pre-caching it.


Vary:User-Agent is particularly bad since any single character 
difference in the User-Agent header will cause a different object to be 
referred to in the cache storage. If you wish to pre-cache these objects 
in any useful way you have to know and mimic the *exact* User-Agent 
header values that will be used to fetch it. For example; two different 
version of Chrome -> different User-Agent header. Internet Explorer with 
different Windows Updates applied -> different User-Agent header. As you 
can imagine that is a very hard thing to predict.


Note: if you have come to this idea after seeing objects from that 
domain getting a lot of MISS records, the problem is very much that Vary 
header causing so many different objects to be needed that objects being 
stored are often not the right one(s) for any later client request. 
pre-caching will not solve this but make it worse as wget is just 
another different User-Agent.


Amos




From belle at bazuin.nl  Tue May 23 07:09:46 2017
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Tue, 23 May 2017 09:09:46 +0200
Subject: [squid-users] Problem with Squid3 Authentication ( after
	sambaupgrades )
In-Reply-To: <7e19132d-9430-c473-2dfe-8885f2844f9c@treenet.co.nz>
References: <CA+0TdyqWG9Y96fBK+0+19vYUW9_9e6mMekkY47sUnY4Bw0douw@mail.gmail.com>
Message-ID: <vmime.5923e03a.7d2d.3a08459675107ada@ms249-lin-003.rotterdam.bazuin.nl>

Hi Amos and others. 

Its not a "samba" thing or a squid thing.   
Maybe in the end yes, but this is a configuration thing. 

For you guys to know, samba AD DC setup this parameter as default : 
 ldap server require strong auth = yes 
Which obligates the use of TLS. 

Next, users dont configure /etc/ldap/ldap.conf when they use TLS. 
Squid and samba may need the CA root if you use TLS. 
Which should to in ldap.conf 
TLS_CACERT      /etc/ssl/certs/ca-certificates.crt
TLS_REQCERT allow

Samba sets these days: 
ntlm auth = no
Laman auth = no

Which disables NTLMv1 and last, users dont know kerberos and the need of A/PTR records. 

For others, i've posted a example auth setup and smb.conf setup for squid on Debian Jessie.
Tested as of squid 3.4.8 upto 3.5.24. ( with and without ssl bumping ) 
Google for : Problems with Samba 4.6.3 Authentication  
Post date 23-may 2017

When upgrading samba/winbind as of 4.2 upto 4.5 or 4.6. 
You MUST read the change logs at least for every samba 4.X.0 version. \
At least 4.2.0 4.3.0 4.4.0 4.5.0 and 4.6.0 

https://www.samba.org/samba/history/ 
Look a the smb.conf changes. 
Like this one for 4.5 : 
smb.conf changes
================

  Parameter Name                Description             Default
  --------------                -----------             -------
  kccsrv:samba_kcc              Changed default         yes
  ntlm auth                     Changed default         no
  only user                     Removed
  password hash gpg key ids     New
  shadow:snapprefix             New
  shadow:delimiter              New                     _GMT
  smb2 leases                   Changed default         yes
  username                      Removed



Greetz, 

Louis



 

> -----Oorspronkelijk bericht-----
> Van: squid-users 
> [mailto:squid-users-bounces at lists.squid-cache.org] Namens 
> Amos Jeffries
> Verzonden: maandag 22 mei 2017 22:46
> Aan: squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] Problem with Squid3 Authentication
> 
> On 23/05/17 02:15, Marcio Demetrio Bacci wrote:
> > I have migrated of Samba 4.2.1 to Samba 4.6.3 as DC, but 
> now my Squid 
> > authentication doesn't work.
> >
> > In samba 4.2.1 is working properly.
> >
> > This is my authentication block:
> >
> >
> > auth_param basic program /usr/lib/squid3/basic_ldap_auth -R -b 
> > DC=empresa,DC=com,DC=br -D CN=proxy,CN=Users,DC=empresa,DC=com,DC=br
> > -w password -h 192.168.10.4 -p 389 -s sub -v 3 -f 
> "sAMAccountName=%s"
> > auth_param basic children 50
> > auth_param basic realm Access Monitored auth_param basic 
> > credentialsttl 8 hours auth_param basic casesensitive off
> >
> > I'm using Squid 3.4.8
> >
> > Can anybody help me ?
> 
> If the only thing that changed was Samba its clearly an issue 
> with that end of the system.
> 
> I suggest you compare those LDAP parameters with what the new 
> Samba version needs, and if there is no issue there please 
> contact your vendor or the Samba help channels.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From rentorbuy at yahoo.com  Tue May 23 11:00:59 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Tue, 23 May 2017 11:00:59 +0000 (UTC)
Subject: [squid-users] squid and c-icap ERR_ICAP_FAILURE
References: <856649153.230175.1495537259096.ref@mail.yahoo.com>
Message-ID: <856649153.230175.1495537259096@mail.yahoo.com>

Hi,

I know I have an "old" version of Squid (3.5.14), but I'd like to know if the issue I'm seeing has been fixed in newer versions before I upgrade.

I can't easily reproduce the failure. The Squid process uses a c-icap module to scan content (squidclamav).
It's all fine, in general, but at times clients get the ERR_ICAP_FAILURE Squid error page.
When this happens (usually when there's a lot of traffic), users can't browse the web and a c-icap restart on the Squid server (c-icap server and Squid on same proxy server) does not solve the issue.
I need to run at least "squid -k reconfigure" to make everything work again (restart not necessary).

Any idea why?

I'm not posting the squid log files because I couldn't find anything relevant (debug not enabled).

Maybe I shouldn't waste anyone's time if this is a known issue and update to the latest version first, right?

Thanks,

Vieri


From yvoinov at gmail.com  Tue May 23 11:23:39 2017
From: yvoinov at gmail.com (Yuri)
Date: Tue, 23 May 2017 17:23:39 +0600
Subject: [squid-users] a bit off topic. New user question
In-Reply-To: <CAEO0YGAUdewLw0EqEZoPfmFS0PUcZUyYQJKV74z_1+t5eDs-SA@mail.gmail.com>
References: <CAEO0YGAUdewLw0EqEZoPfmFS0PUcZUyYQJKV74z_1+t5eDs-SA@mail.gmail.com>
Message-ID: <ea9e5ee0-6144-e362-22b1-f9b3be82a42e@gmail.com>

        --delete-after              delete files locally after 
downloading them

I know this by simple execution wget --help :-D

Feel free to do RTFM :-D


23.05.2017 5:39, George Diaz ?????:
>
> Hi
>
> sorry this off-topic question ...
>
> I want pre-cache some object from some interest host with wget.
>
> My question is : I want: the wget download the object to the /dev/null 
> but
> I'm not found this switches....
> (GNU Wget 1.5.3)
>
> I'm probe this :
> export http_proxy=http://mycache.com:8080/
> wget -r http://sobredinero.com -P /dev/null -nH -nd -Y on -b -l5 -t1 
> -o /dev/null
>
> but this is create a /dev/null directory :) and download the files 
> into this.
>
> any suggestions ?
>
> Thanks in advance.
>
> George
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170523/c5d5929c/attachment.htm>

From harariboy at gmail.com  Tue May 23 13:02:09 2017
From: harariboy at gmail.com (avi_h)
Date: Tue, 23 May 2017 06:02:09 -0700 (PDT)
Subject: [squid-users] External ACL
In-Reply-To: <046c5862-9f83-911e-0e0f-aa3d52db6a34@treenet.co.nz>
References: <1495502728560-4682519.post@n4.nabble.com>
 <046c5862-9f83-911e-0e0f-aa3d52db6a34@treenet.co.nz>
Message-ID: <1495544529394-4682527.post@n4.nabble.com>

Hi Amos,

Thanks for your reply.

What I mean is that so far I only used squid_db_auth and it works great but
now I have a need to allow certain IPs on top of allowing users.
Since the IPs are not constant, I need a way to handle the allowed IPs
dynamically.


As for the amount of traffic, there is no traffic on this server at the
moment, I'm only using it for testing.
As for the http_access, I have the following:

http_access allow localnet
http_access allow localhost
http_access allow allowed_ips

I even commented out localnet for the test and it didn't work.

Any other ideas other than the fact its in bash?
Thanks.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/External-ACL-tp4682519p4682527.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Tue May 23 17:19:13 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 23 May 2017 10:19:13 -0700 (PDT)
Subject: [squid-users] Two squid server - Would it be useful?
Message-ID: <1495559953171-4682529.post@n4.nabble.com>

Hi.
I have working a squid server. we have 110 pc. 
I have two virtualized squids.
One of them is working, and the other i use for testing purpose. but, i want
to know if i could take that of "testing purpose" and put to work with
"cache peers or neighbors"??
It would be better?? it give some benefits??
thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Two-squid-server-Would-it-be-useful-tp4682529.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Tue May 23 17:47:40 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 23 May 2017 19:47:40 +0200
Subject: [squid-users] Two squid server - Would it be useful?
In-Reply-To: <1495559953171-4682529.post@n4.nabble.com>
References: <1495559953171-4682529.post@n4.nabble.com>
Message-ID: <201705231947.41218.Antony.Stone@squid.open.source.it>

On Tuesday 23 May 2017 at 19:19:13, erdosain9 wrote:

> Hi.
> I have working a squid server. we have 110 pc.
> I have two virtualized squids.
> One of them is working, and the other i use for testing purpose.

So, do you have two Squid instances, or three, in total?

> i want to know if i could take that of "testing purpose" and put to work
> with "cache peers or neighbors"??

Yes, you could, provided it has an appropriate configuration.

> It would be better?? it give some benefits??

Why not just try it and see (by whatever measurement you use to judge 
"better")?

After all, adding a neighbour peer is only a configuration change on the Squid 
server - clients don't even know about it, so it's simple to do (and undo).


Antony.

-- 
I conclude that there are two ways of constructing a software design: One way 
is to make it so simple that there are _obviously_ no deficiencies, and the 
other way is to make it so complicated that there are no _obvious_ 
deficiencies.

 - C A R Hoare

                                                   Please reply to the list;
                                                         please *don't* CC me.


From Joseph.Garbacik at netapp.com  Tue May 23 18:34:00 2017
From: Joseph.Garbacik at netapp.com (Garbacik, Joe)
Date: Tue, 23 May 2017 18:34:00 +0000
Subject: [squid-users] Logging
Message-ID: <D4C4C3F5-0D67-4ECB-B7B0-A8FCBF775A73@netapp.com>

I am trying to separate logs so that in the log entries define why it was blocked. For example, I have created the following log formats:

logformat MyAllowSuccessLog  local_time="[%tl]" action=ALLOW status=SUCCESS ** orig_src_ip=%{X-Forwarded-For}>h proxy_src_ip=%>a proxy_src_port=%>p dst_ip=%<a dst_host=%<A dst_port=%<p ident_username=%[ui username=%[un request_method=%rm request="%rm %ru HTTP/%rv" status_code=%>Hs referer="%{Referer}>h" user_agent="%{User-Agent}>h" protocol_version=%rv squid_status=%Ss squid_hierarchy_status=%Sh ** dns_response_time=%dt response_time=%tr mime_type=%mt **  total_request_size=%>st total_reply_size=%<st **

logformat MyAllowFailureLog  local_time="[%tl]" action=ALLOW status=FAILURE ** orig_src_ip=%{X-Forwarded-For}>h proxy_src_ip=%>a proxy_src_port
=%>p dst_ip=%<a dst_host=%<A dst_port=%<p ident_username=%[ui username=%[un request_method=%rm request="%rm %ru HTTP/%rv" status_code=%>Hs referer="%{Referer}>h" user_agent="%{User-Agent}>h" protocol_version=%rv squid_status=%Ss squid_hierarchy_status=%Sh ** dns_response_time=%dt response_time=%tr mime_type=%mt **  total_request_size=%>st total_reply_size=%<st **

logformat MyDenyPortLog  local_time="[%tl]" action=DENY status=DENIED reason=PORT ** orig_src_ip=%{X-Forwarded-For}>h proxy_src_ip=%>a proxy_src_port=%>p dst_ip=%<a dst_host=%<A dst_port=%<p ident_username=%[ui username=%[un request_method=%rm request="%rm %ru HTTP/%rv" status_code=%>Hs referer="%{Referer}>h" user_agent="%{User-Agent}>h" protocol_version=%rv squid_status=%Ss squid_hierarchy_status=%Sh ** dns_response_time=%dt response_time=%tr mime_type=%mt **  total_request_size=%>st total_reply_size=%<st **

logformat MyDenyProtocolLog  local_time="[%tl]" action=DENY status=DENIED reason=PROTOCOL ** orig_src_ip=%{X-Forwarded-For}>h proxy_src_ip=%>a proxy_src_port=%>p dst_ip=%<a dst_host=%<A dst_port=%<p ident_username=%[ui username=%[un request_method=%rm request="%rm %ru HTTP/%rv" status_code=%>Hs referer="%{Referer}>h" user_agent="%{User-Agent}>h" protocol_version=%rv squid_status=%Ss squid_hierarchy_status=%Sh ** dns_response_time=%dt response_time=%tr mime_type=%mt **  total_request_size=%>st total_reply_size=%<st **

acl success_codes http_status 100-199 # informational
acl success_codes http_status 200-299 # successful transactions
acl success_codes http_status 300-399 # redirection

Then in my access rules, I am doing the following:
# - Block to Unsafe Ports
http_access deny !Safe_ports
deny_info ERR_BLOCKED_PORT.html !Safe_ports
access_log /var/log/squid/access_denied.log MyDenyPortLog !Safe_ports

http_access allow 
http_access allow ApprovedDestinations
access_log /var/log/squid/access_haproxy.log MyAllowSuccessLog  success  ApprovedDestinations
access_log /var/log/squid/access_haproxy.log MyAllowFailureLog !success ApprovedDestinations

If there a better way to accomplish this? Can I add a string like an acl when it matches so I can log on which http_access rule was matched?




From erdosain9 at gmail.com  Tue May 23 19:05:38 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 23 May 2017 12:05:38 -0700 (PDT)
Subject: [squid-users] Two squid server - Would it be useful?
In-Reply-To: <201705231947.41218.Antony.Stone@squid.open.source.it>
References: <1495559953171-4682529.post@n4.nabble.com>
 <201705231947.41218.Antony.Stone@squid.open.source.it>
Message-ID: <1495566338034-4682532.post@n4.nabble.com>

thanks and sorry, i have just two.
In one of them (the more "important") i have SSO, and in the other i have
access per ip.
So, i need to have the two squid servers equally or not?

In the other hand I do not mind the use of bandwidth but serve as fast as
possible.
how i would config this??

thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Two-squid-server-Would-it-be-useful-tp4682529p4682532.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Tue May 23 19:28:51 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 23 May 2017 13:28:51 -0600
Subject: [squid-users] Logging
In-Reply-To: <D4C4C3F5-0D67-4ECB-B7B0-A8FCBF775A73@netapp.com>
References: <D4C4C3F5-0D67-4ECB-B7B0-A8FCBF775A73@netapp.com>
Message-ID: <be3c6ca9-87c9-6880-e1df-04ea0bf88496@measurement-factory.com>

On 05/23/2017 12:34 PM, Garbacik, Joe wrote:

> I am trying to separate logs so that in the log entries define why it
> was blocked. For example, I have created [one custom log format for each
> blocking rule]. If there a better way to accomplish this?

Yes, please see this very recent discussion:
http://lists.squid-cache.org/pipermail/squid-users/2017-May/015355.html

Also, the "action" you are hard-coding in your logformats is already
expressed (with better precision) in the %Ss logformat code.


HTH,

Alex.
P.S. The example Squid configuration you posted contains several errors,
but it could be just a side effect of a careless copy-paste.



From Antony.Stone at squid.open.source.it  Tue May 23 22:06:05 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 24 May 2017 00:06:05 +0200
Subject: [squid-users] Two squid server - Would it be useful?
In-Reply-To: <1495566338034-4682532.post@n4.nabble.com>
References: <1495559953171-4682529.post@n4.nabble.com>
 <201705231947.41218.Antony.Stone@squid.open.source.it>
 <1495566338034-4682532.post@n4.nabble.com>
Message-ID: <201705240006.05811.Antony.Stone@squid.open.source.it>

On Tuesday 23 May 2017 at 21:05:38, erdosain9 wrote:

> thanks and sorry, i have just two.
> In one of them (the more "important") i have SSO, and in the other i have
> access per ip.
> So, i need to have the two squid servers equally or not?

You configure the one the clients point to for SSO (I'm assuming that is your 
"working / production" server), and you simply configure the other to accept 
peer requests from the first - it will never get client requests directly.

> In the other hand I do not mind the use of bandwidth but serve as fast as
> possible.
> how i would config this??

1. Don't use Squid - just let your clients access the Internet directly.

2. If you do use Squid, use as simple a configuration as possible, and make 
sure that Squid runs as efficiently as possible on the hardware you have (ie: 
don't use VMs; don't run multiple instances on one machine; don't run other 
CPU or disk -intensive processes on the same machine).

3. For only 110 clients, unless your hardware is remarkably old and low-
performance, just use a single proxy server.


Antony.

-- 
Schr?dinger's rule of data integrity: the condition of any backup is unknown 
until a restore is attempted.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From eliezer at ngtech.co.il  Wed May 24 01:26:29 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Wed, 24 May 2017 04:26:29 +0300
Subject: [squid-users] YouTube caching helper ICAP service RPM
Message-ID: <031701d2d42c$c4ce4e30$4e6aea90$@ngtech.co.il>

I packaged the helper\service for CentOS 7 at:
http://ngtech.co.il/repo/centos/7/x86_64/ytgv-predictor-icap-0.0.1-5.el7.centos.x86_64.rpm

And the StoreID helper at:
http://wiki.squid-cache.org/Features/StoreID/PredictionAssitenedHelper

with some squid.conf example.

Now, if you don't understand something but want me to help you just write to me!(here or privately)

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: Alex Rousskov [mailto:rousskov at measurement-factory.com] 
Sent: Tuesday, May 16, 2017 4:58 AM
To: Eliezer Croitoru <eliezer at ngtech.co.il>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Experimental YouTube Caching helper\tool and SQUID 3.5.25 + 4.0.19 RPM's RELEASED

On 05/15/2017 07:04 PM, Eliezer  Croitoru wrote:

> @Alex, What will encourage you to help with an improved patch to add 
> ICAP X-StoreID (or else) response header capability

A submission of a high-quality patch would encourage me to review it.
Unfortunately, I do not have the free cycles necessary for actually writing code together if that is what you meant.

Alex.




From acctforjunk at yahoo.com  Wed May 24 01:44:19 2017
From: acctforjunk at yahoo.com (j m)
Date: Wed, 24 May 2017 01:44:19 +0000 (UTC)
Subject: [squid-users] SSL bump, SSL intercept, explicit, secure proxy,
	what is it called?
References: <1140034948.954341.1495590259601.ref@mail.yahoo.com>
Message-ID: <1140034948.954341.1495590259601@mail.yahoo.com>

I'd like to set up a proxy on a home server so I can use it remotely for web browsing; no filtering, nothing fancy, just a pass-through of sorts to get around web filters. ?That part I've got working. ?The part I haven't had luck with is encrypting the browser-to-proxy connection. ?I've found some tutorials online but part of the problem is I don't know what this feature is called when searching for solutions to problems.
I have squid 3.5.23 on Ubuntu compiled with?
'--with-openssl' '--enable-ssl' '--enable-ssl-crtd'
so I believe I'm set there. ?However, upon finally getting a squid.conf that doesn't cause immediate errors when squid is started, I find that the squid process is gone after several seconds and find lots of these in syslog:
(squid-1): The ssl_crtd helpers are crashing too rapidly, need help!

I found a suggestion to fix this problem, but it didn't help:
rc-service squid stoprm -rf /var/lib/ssl_db/usr/lib/squid3/ssl_crtd -c -s /var/lib/ssl_db?rc-service squid start

So firstly, what is the actual name for what I want (encrypting proxy to browser)?
And secondly, any advice on the error? ?Or even better, a good tutorial on setting this up? ?I thought if I follow a configuration exactly, I'd be off and running with little problem.


??
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170524/24aefee8/attachment.htm>

From WarkentinJens at AviationPower.de  Wed May 24 08:07:06 2017
From: WarkentinJens at AviationPower.de (Warkentin, Jens)
Date: Wed, 24 May 2017 08:07:06 +0000
Subject: [squid-users] Squid Service crash >>> assertion failed:
 store_swapout.cc:289: "mem->swapout.sio == self"
Message-ID: <6d9047e4bbf943b3bfe2a25518ef9cc5@AviationPower.de>

Hi,

we?re using SQUID 3.5.25 on Centos 7.3.1611 (Core).

Looks like we have a permission or swap-file problem, when SQUID is running as a service.

When we enable and start the service (systemctl enable squid, systemctl start squid) then does the service crash each time a user tries to connect to our Outlook WebAccess (reproducible).

cache.log
>>  2017/05/24 09:14:15.504 kid1| ctx: enter level  0: 'https://<public host name>/owa/manifests/appCacheManifestHandler.ashx?owamanifest=1'
>>  2017/05/24 09:14:15.504 kid1| assertion failed: store_swapout.cc:289: "mem->swapout.sio == self"
We have to restart the service afterwards.


If we do remove the service (systemctl stop squid, systemctl disable squid) and do launch the ?squid? as a process (root user) everything is working very well.
Then the squid process is running very stable (also with Outlook WebAccess).

How can we fix the ?swapout issue?, when SQUID is running as a system service?

Thank you
Jens
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170524/99ffaa36/attachment.htm>

From squid3 at treenet.co.nz  Wed May 24 12:35:37 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 May 2017 00:35:37 +1200
Subject: [squid-users] Squid Service crash >>> assertion failed:
 store_swapout.cc:289: "mem->swapout.sio == self"
In-Reply-To: <6d9047e4bbf943b3bfe2a25518ef9cc5@AviationPower.de>
References: <6d9047e4bbf943b3bfe2a25518ef9cc5@AviationPower.de>
Message-ID: <b8970235-ef00-3236-6803-f15833d78dbd@treenet.co.nz>

On 24/05/17 20:07, Warkentin, Jens wrote:
>
> Hi,
>
> we?re using SQUID 3.5.25 on Centos 7.3.1611 (Core).
>
> Looks like we have a permission or swap-file problem, when SQUID is 
> running as a service.
>
> When we enable and start the service (systemctl enable squid, 
> systemctl start squid) then does the service crash each time a user 
> tries to connect to our Outlook WebAccess (reproducible).
>
> cache.log
>
> >>  2017/05/24 09:14:15.504 kid1| ctx: enter level  0: 'https://<public host 
> name>/owa/manifests/appCacheManifestHandler.ashx?owamanifest=1'
>
> >>  2017/05/24 09:14:15.504 kid1| assertion failed: store_swapout.cc:289: 
> "mem->swapout.sio == self"
>
> We have to restart the service afterwards.
>
> If we do remove the service (systemctl stop squid, systemctl disable 
> squid) and do launch the ?squid? as a process (root user) everything 
> is working very well.
>
> Then the squid process is running very stable (also with Outlook 
> WebAccess).
>
> How can we fix the ?swapout issue?, when SQUID is running as a system 
> service?
>

This is bug 3852 <http://bugs.squid-cache.org/show_bug.cgi?id=3852>

Amos



From squid3 at treenet.co.nz  Wed May 24 12:56:55 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 May 2017 00:56:55 +1200
Subject: [squid-users] SSL bump, SSL intercept, explicit, secure proxy,
 what is it called?
In-Reply-To: <1140034948.954341.1495590259601@mail.yahoo.com>
References: <1140034948.954341.1495590259601.ref@mail.yahoo.com>
 <1140034948.954341.1495590259601@mail.yahoo.com>
Message-ID: <41b65b4b-5603-ef56-5c5a-7bf68d8b0cd0@treenet.co.nz>

On 24/05/17 13:44, j m wrote:
> I'd like to set up a proxy on a home server so I can use it remotely 
> for web browsing; no filtering, nothing fancy, just a pass-through of 
> sorts to get around web filters.  That part I've got working.  The 
> part I haven't had luck with is encrypting the browser-to-proxy 
> connection.  I've found some tutorials online but part of the problem 
> is I don't know what this feature is called when searching for 
> solutions to problems.
>
> I have squid 3.5.23 on Ubuntu compiled with
>
> '--with-openssl' '--enable-ssl' '--enable-ssl-crtd'
>
> so I believe I'm set there.  However, upon finally getting a 
> squid.conf that doesn't cause immediate errors when squid is started, 
> I find that the squid process is gone after several seconds and find 
> lots of these in syslog:
>
> (squid-1): The ssl_crtd helpers are crashing too rapidly, need help!
>
> I found a suggestion to fix this problem, but it didn't help:
>
> rc-service squid stop
> rm -rf /var/lib/ssl_db
> /usr/lib/squid3/ssl_crtd -c -s /var/lib/ssl_db
> rc-service squid start
>
>
> So firstly, what is the actual name for what I want (encrypting proxy 
> to browser)?
>


Some people seem to be calling it "HTTPS", but that is not correct and 
thankfully makes it difficult to find the bad info. (that said our own 
wiki documents it on the HTTPS page referenced below :-P ).

The current IETF term for it is "TLS explicit proxy". Previously it did 
not have a formal term and often got described in words like "TLS proxy" 
or sometimes "TLS to the proxy" and variants switching "SSL" for "TLS". 
It also has some relation to early forms of "HTTP opportunistic 
security" - though that now means an HTTP version of emails STARTTLS 
that is quite unrelated to anything Squid supports at present.



> And secondly, any advice on the error?  Or even better, a good 
> tutorial on setting this up?  I thought if I follow a configuration 
> exactly, I'd be off and running with little problem.
>
>

The ssl_crtd helper in not related to TLS explicit proxy. It is a part 
of SSL-Bump features for intercepting HTTPS traffic, specifically it is 
the part that forges certificates.

You could avoid it entirely by removing the --enable-ssl-crtd build 
option if you don't need SSL-Bump features later. Otherwise check the 
directory creation and ownership permissions are correct and that Squid 
http_port is *not* setup to use ssl-bump features (yet).


The TLS explicit proxy is simply a Squid that uses https_port to receive 
proxy traffic, as opposed to http_port. You will need a server 
certificate for that, but nothing else special on Squid's side of 
things. eg:
   https_port 3128 cert=blah_public.pem key=blah_private.key

The tricky part is getting a browser to talk TLS to anything other than 
origin servers.  The details we know of are all at 
<http://wiki.squid-cache.org/Features/HTTPS#Encrypted_browser-Squid_connection>.

Amos



From squid3 at treenet.co.nz  Wed May 24 13:11:12 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 May 2017 01:11:12 +1200
Subject: [squid-users] External ACL
In-Reply-To: <1495544529394-4682527.post@n4.nabble.com>
References: <1495502728560-4682519.post@n4.nabble.com>
 <046c5862-9f83-911e-0e0f-aa3d52db6a34@treenet.co.nz>
 <1495544529394-4682527.post@n4.nabble.com>
Message-ID: <bb991bc6-d898-7fd6-f525-084affa93716@treenet.co.nz>

On 24/05/17 01:02, avi_h wrote:
> Hi Amos,
>
> Thanks for your reply.
>
> What I mean is that so far I only used squid_db_auth and it works great but
> now I have a need to allow certain IPs on top of allowing users.
> Since the IPs are not constant, I need a way to handle the allowed IPs
> dynamically.

Ah, okay.

So, I'm a little hesitant to advise this since it is not clear why the 
shell script is operating so bad - the same problem might still occur if 
it wasn't the script itself...

Anyway, I recommend trying the ext_sql_session_acl helper. Your use-case 
is almost exactly the one  wrote it for. It uses arbitrary database 
table of "keys" (eg the %SRC IP addresses in this case) so you can 
manage the list of IPs in DB the same as you do for the auth user accounts.

> As for the amount of traffic, there is no traffic on this server at the
> moment, I'm only using it for testing.
> As for the http_access, I have the following:
>
> http_access allow localnet
> http_access allow localhost
> http_access allow allowed_ips
>
> I even commented out localnet for the test and it didn't work.
>
> Any other ideas other than the fact its in bash?

Not really. Bash should normally work fine, the SMB auth helpers are 
pretty much the same to what you wrote - just calling other applications 
than grep. So I'm very puzzled about what is going wrong there myself.

Amos



From acctforjunk at yahoo.com  Wed May 24 14:15:28 2017
From: acctforjunk at yahoo.com (j m)
Date: Wed, 24 May 2017 14:15:28 +0000 (UTC)
Subject: [squid-users] SSL bump, SSL intercept, explicit, secure proxy,
 what is it called?
In-Reply-To: <41b65b4b-5603-ef56-5c5a-7bf68d8b0cd0@treenet.co.nz>
References: <1140034948.954341.1495590259601.ref@mail.yahoo.com>
 <1140034948.954341.1495590259601@mail.yahoo.com>
 <41b65b4b-5603-ef56-5c5a-7bf68d8b0cd0@treenet.co.nz>
Message-ID: <1678189547.1377557.1495635328136@mail.yahoo.com>

Thanks for the clarification.
I went back to the squid.conf I was using successfully (without encryption) and changed http_port to https_port and added the cert and key you mentioned. ?Since I'm not all that knowledgeable about SSL certs, I had some trouble with squid not liking the keys I provided. ?So I eventually found this command to generate what I need:
openssl req -newkey rsa:4096 -x509 -keyout /etc/squid/squid.pem -out /etc/squid/squid.pem -days 365 -nodes

which puts them into the same file, which squid seemed to be ok with.
Then I tried starting another instance of Chrome using:
chrome --proxy-server=https://my-domain-name:8092

but it didn't work. ?No errors, nothing unusual. ?Chrome simply behaved like there was no proxy configured. ?I found documentation on chromium.org that showed the format as:
chrome --proxy-server="https://my-domain-name:8092"

so I tried adding the quotes, but no change.
I then removed the private key from squid.pem and saved it as another file on the Windows computer running Chrome, and added it as a cert. ?No problem there, but no change.
My squid.conf is below. ?I'm at a loss as far as what to try next.

auth_param digest program /usr/lib/squid/digest_file_auth -c /etc/squid/passwdauth_param digest realm myrealmauth_param digest children 2acl auth_users proxy_auth REQUIREDacl SSL_ports port 443
acl Safe_ports port 80 ? ? ? ?# httpacl Safe_ports port 21 ? ? ? ?# ftpacl Safe_ports port 443 ? ? ? ?# httpsacl Safe_ports port 70 ? ? ? ?# gopheracl Safe_ports port 210 ? ? ? ?# waisacl Safe_ports port 1025-65535 ? ?# unregistered portsacl Safe_ports port 280 ? ? ? ?# http-mgmtacl Safe_ports port 488 ? ? ? ?# gss-httpacl Safe_ports port 591 ? ? ? ?# filemakeracl Safe_ports port 777 ? ? ? ?# multiling httpacl CONNECT method CONNECThttp_access deny !Safe_portshttp_access deny CONNECT !SSL_portshttp_access allow auth_usershttp_access allow all#http_port 8092https_port 8092 cert=/etc/squid/squid.pem key=/etc/squid/squid.pemcache deny allaccess_log nonenetdb_filename none


      From: Amos Jeffries <squid3 at treenet.co.nz>
 To: squid-users at lists.squid-cache.org 
 Sent: Wednesday, May 24, 2017 7:57 AM
 Subject: Re: [squid-users] SSL bump, SSL intercept, explicit, secure proxy, what is it called?
   
On 24/05/17 13:44, j m wrote:
> I'd like to set up a proxy on a home server so I can use it remotely 
> for web browsing; no filtering, nothing fancy, just a pass-through of 
> sorts to get around web filters.? That part I've got working.? The 
> part I haven't had luck with is encrypting the browser-to-proxy 
> connection.? I've found some tutorials online but part of the problem 
> is I don't know what this feature is called when searching for 
> solutions to problems.
>
> I have squid 3.5.23 on Ubuntu compiled with
>
> '--with-openssl' '--enable-ssl' '--enable-ssl-crtd'
>
> so I believe I'm set there.? However, upon finally getting a 
> squid.conf that doesn't cause immediate errors when squid is started, 
> I find that the squid process is gone after several seconds and find 
> lots of these in syslog:
>
> (squid-1): The ssl_crtd helpers are crashing too rapidly, need help!
>
> I found a suggestion to fix this problem, but it didn't help:
>
> rc-service squid stop
> rm -rf /var/lib/ssl_db
> /usr/lib/squid3/ssl_crtd -c -s /var/lib/ssl_db
> rc-service squid start
>
>
> So firstly, what is the actual name for what I want (encrypting proxy 
> to browser)?
>


Some people seem to be calling it "HTTPS", but that is not correct and 
thankfully makes it difficult to find the bad info. (that said our own 
wiki documents it on the HTTPS page referenced below :-P ).

The current IETF term for it is "TLS explicit proxy". Previously it did 
not have a formal term and often got described in words like "TLS proxy" 
or sometimes "TLS to the proxy" and variants switching "SSL" for "TLS". 
It also has some relation to early forms of "HTTP opportunistic 
security" - though that now means an HTTP version of emails STARTTLS 
that is quite unrelated to anything Squid supports at present.



> And secondly, any advice on the error?? Or even better, a good 
> tutorial on setting this up?? I thought if I follow a configuration 
> exactly, I'd be off and running with little problem.
>
>

The ssl_crtd helper in not related to TLS explicit proxy. It is a part 
of SSL-Bump features for intercepting HTTPS traffic, specifically it is 
the part that forges certificates.

You could avoid it entirely by removing the --enable-ssl-crtd build 
option if you don't need SSL-Bump features later. Otherwise check the 
directory creation and ownership permissions are correct and that Squid 
http_port is *not* setup to use ssl-bump features (yet).


The TLS explicit proxy is simply a Squid that uses https_port to receive 
proxy traffic, as opposed to http_port. You will need a server 
certificate for that, but nothing else special on Squid's side of 
things. eg:
? https_port 3128 cert=blah_public.pem key=blah_private.key

The tricky part is getting a browser to talk TLS to anything other than 
origin servers.? The details we know of are all at 
<http://wiki.squid-cache.org/Features/HTTPS#Encrypted_browser-Squid_connection>.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170524/907ad0c0/attachment.htm>

From rousskov at measurement-factory.com  Wed May 24 14:17:53 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 24 May 2017 08:17:53 -0600
Subject: [squid-users] SSL bump, SSL intercept, explicit, secure proxy,
 what is it called?
In-Reply-To: <41b65b4b-5603-ef56-5c5a-7bf68d8b0cd0@treenet.co.nz>
References: <1140034948.954341.1495590259601.ref@mail.yahoo.com>
 <1140034948.954341.1495590259601@mail.yahoo.com>
 <41b65b4b-5603-ef56-5c5a-7bf68d8b0cd0@treenet.co.nz>
Message-ID: <e5e5371f-74ce-0e6d-23ca-b29ddff49254@measurement-factory.com>

On 05/24/2017 06:56 AM, Amos Jeffries wrote:
> On 24/05/17 13:44, j m wrote:
>> So firstly, what is the actual name for what I want (encrypting proxy
>> to browser)?

> Some people seem to be calling it "HTTPS", but that is not correct and
> thankfully makes it difficult to find the bad info.

What makes you think that "HTTPS proxy" is an incorrect term? That is
the term I have seen used the most, and that is the term I would use.
That is also the term that allows to locate relevant documents by googling.


> The current IETF term for it is "TLS explicit proxy". 

Any supporting references? Neither Google nor I remember that term, and
the term itself seems inferior to "HTTPS proxy" -- the proxy in question
expects HTTP traffic underneath TLS so "HTTPS proxy" fits better IMHO.

Alex.



From erdosain9 at gmail.com  Wed May 24 14:43:51 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 24 May 2017 07:43:51 -0700 (PDT)
Subject: [squid-users] AD Windows server 2012 - Squid Authenticator slow
Message-ID: <1495637031541-4682543.post@n4.nabble.com>

Hi to all.
Im having too much "avg service time" in the negotiate kerberos helper. Amos
tell me that it's a configuration related to the AD. Can somebody give me a
hand to tune that? or tell me where find information about?
Thanks


Negotiate Authenticator Statistics:
program: /lib64/squid/negotiate_kerberos_auth
number active: 20 of 20 (0 shutting down)
requests sent: 1063
replies received: 1043
queue length: 2
avg service time: 414 msec




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/AD-Windows-server-2012-Squid-Authenticator-slow-tp4682543.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From harariboy at gmail.com  Wed May 24 16:00:49 2017
From: harariboy at gmail.com (avi_h)
Date: Wed, 24 May 2017 09:00:49 -0700 (PDT)
Subject: [squid-users] External ACL
In-Reply-To: <bb991bc6-d898-7fd6-f525-084affa93716@treenet.co.nz>
References: <1495502728560-4682519.post@n4.nabble.com>
 <046c5862-9f83-911e-0e0f-aa3d52db6a34@treenet.co.nz>
 <1495544529394-4682527.post@n4.nabble.com>
 <bb991bc6-d898-7fd6-f525-084affa93716@treenet.co.nz>
Message-ID: <1495641649465-4682544.post@n4.nabble.com>

Hi Amos,

I can tell you I created a helper in python but had the same issue.
Do you have some more details about the ext_sql_session_acl ?
How should the SQL table be like and if every entry must have both an IP and
a username associated with it?

Thanks,
Avi




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/External-ACL-tp4682519p4682544.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Wed May 24 18:49:25 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 24 May 2017 11:49:25 -0700 (PDT)
Subject: [squid-users] Wrong timestamp??
Message-ID: <1495651765128-4682545.post@n4.nabble.com>

Hi to all.
This is strange...
if a put "date" i get the actual time. I mean the time it's correct.
More or less in this moment it is

[root at squid ~]# date
mi? may 24 15:59:59 ART 2017

in the same moment (more or less) access.log
24/May/2017:19:00:21     

same moment (more or less)
[root at squid ~]# squidclient mgr:negotiateauthenticator
HTTP/1.1 200 OK
Server: squid/3.5.20
Mime-Version: 1.0
Date: Wed, 24 May 2017 19:01:37 GMT
Content-Type: text/plain;charset=utf-8
Expires: Wed, 24 May 2017 19:01:37 GMT
Last-Modified: Wed, 24 May 2017 19:01:37 GMT

So... why squid have wrong time if the "date" command says another thing.
>From where squid take the time?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Wrong-timestamp-tp4682545.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Wed May 24 19:06:18 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 25 May 2017 01:06:18 +0600
Subject: [squid-users] Wrong timestamp??
In-Reply-To: <1495651765128-4682545.post@n4.nabble.com>
References: <1495651765128-4682545.post@n4.nabble.com>
Message-ID: <1597dcfd-cdc7-f5de-2aa1-981266010444@gmail.com>

You ask us, how do you have time zones on the your server configured? :)


25.05.2017 0:49, erdosain9 ?????:
> Hi to all.
> This is strange...
> if a put "date" i get the actual time. I mean the time it's correct.
> More or less in this moment it is
>
> [root at squid ~]# date
> mi? may 24 15:59:59 ART 2017
>
> in the same moment (more or less) access.log
> 24/May/2017:19:00:21     
>
> same moment (more or less)
> [root at squid ~]# squidclient mgr:negotiateauthenticator
> HTTP/1.1 200 OK
> Server: squid/3.5.20
> Mime-Version: 1.0
> Date: Wed, 24 May 2017 19:01:37 GMT
> Content-Type: text/plain;charset=utf-8
> Expires: Wed, 24 May 2017 19:01:37 GMT
> Last-Modified: Wed, 24 May 2017 19:01:37 GMT
>
> So... why squid have wrong time if the "date" command says another thing.
> From where squid take the time?
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Wrong-timestamp-tp4682545.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/0eaa36a4/attachment.sig>

From yvoinov at gmail.com  Wed May 24 19:13:14 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 25 May 2017 01:13:14 +0600
Subject: [squid-users] Wrong timestamp??
In-Reply-To: <1495651765128-4682545.post@n4.nabble.com>
References: <1495651765128-4682545.post@n4.nabble.com>
Message-ID: <8bfe82a5-518a-5239-c6c1-5aabdbef20f0@gmail.com>

I've take a look on one of my servers:

root @ khorne / # date
Thu May 25 01:09:38 ALMT 2017
root @ khorne / # su - squid
squid @ khorne $ date
Thu May 25 01:10:01 ALMT 2017

Is is ok. Either from root, or from non-privileged user.

Well, let's run squidclient:

 # su - squid
squid @ khorne $ cd /usr/local/squid/bin
squid @ khorne $ squidclient mgr:negotiateauthenticator
HTTP/1.1 404 Not Found
Server: squid
Mime-Version: 1.0
Date: Wed, 24 May 2017 19:11:01 GMT

(I have no authenticators, but date is correct.)

Seems you have misconfigured server.

25.05.2017 0:49, erdosain9 ?????:
> Hi to all.
> This is strange...
> if a put "date" i get the actual time. I mean the time it's correct.
> More or less in this moment it is
>
> [root at squid ~]# date
> mi? may 24 15:59:59 ART 2017
>
> in the same moment (more or less) access.log
> 24/May/2017:19:00:21     
>
> same moment (more or less)
> [root at squid ~]# squidclient mgr:negotiateauthenticator
> HTTP/1.1 200 OK
> Server: squid/3.5.20
> Mime-Version: 1.0
> Date: Wed, 24 May 2017 19:01:37 GMT
> Content-Type: text/plain;charset=utf-8
> Expires: Wed, 24 May 2017 19:01:37 GMT
> Last-Modified: Wed, 24 May 2017 19:01:37 GMT
>
> So... why squid have wrong time if the "date" command says another thing.
> From where squid take the time?
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Wrong-timestamp-tp4682545.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/a4c282f3/attachment.sig>

From yvoinov at gmail.com  Wed May 24 19:19:09 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 25 May 2017 01:19:09 +0600
Subject: [squid-users] Wrong timestamp??
In-Reply-To: <8bfe82a5-518a-5239-c6c1-5aabdbef20f0@gmail.com>
References: <1495651765128-4682545.post@n4.nabble.com>
 <8bfe82a5-518a-5239-c6c1-5aabdbef20f0@gmail.com>
Message-ID: <3d9bfbe8-f772-1068-e621-df6c8a2d5a29@gmail.com>

Just in case, I explain - Squid takes the system time in the client by
UTC. Since the client profile does not explicitly specify a local time
zone (which in, in my case, is GMT+6). So, you can easy calculate
difference.

This is OS-specific behaviour. Unrelated to squid. AFAIK.


25.05.2017 1:13, Yuri ?????:
> I've take a look on one of my servers:
>
> root @ khorne / # date
> Thu May 25 01:09:38 ALMT 2017
> root @ khorne / # su - squid
> squid @ khorne $ date
> Thu May 25 01:10:01 ALMT 2017
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Local TZ
>
> Is is ok. Either from root, or from non-privileged user.
>
> Well, let's run squidclient:
>
>  # su - squid
> squid @ khorne $ cd /usr/local/squid/bin
> squid @ khorne $ squidclient mgr:negotiateauthenticator
> HTTP/1.1 404 Not Found
> Server: squid
> Mime-Version: 1.0
> Date: Wed, 24 May 2017 19:11:01 GMT
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ GMT
>
> (I have no authenticators, but date is correct.)
>
> Seems you have misconfigured server.
>
> 25.05.2017 0:49, erdosain9 ?????:
>> Hi to all.
>> This is strange...
>> if a put "date" i get the actual time. I mean the time it's correct.
>> More or less in this moment it is
>>
>> [root at squid ~]# date
>> mi? may 24 15:59:59 ART 2017
>>
>> in the same moment (more or less) access.log
>> 24/May/2017:19:00:21     
>>
>> same moment (more or less)
>> [root at squid ~]# squidclient mgr:negotiateauthenticator
>> HTTP/1.1 200 OK
>> Server: squid/3.5.20
>> Mime-Version: 1.0
>> Date: Wed, 24 May 2017 19:01:37 GMT
>> Content-Type: text/plain;charset=utf-8
>> Expires: Wed, 24 May 2017 19:01:37 GMT
>> Last-Modified: Wed, 24 May 2017 19:01:37 GMT
>>
>> So... why squid have wrong time if the "date" command says another thing.
>> From where squid take the time?
>>
>>
>>
>> --
>> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Wrong-timestamp-tp4682545.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/c86581b9/attachment.sig>

From squid3 at treenet.co.nz  Wed May 24 19:45:37 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 May 2017 07:45:37 +1200
Subject: [squid-users] SSL bump, SSL intercept, explicit, secure proxy,
 what is it called?
In-Reply-To: <e5e5371f-74ce-0e6d-23ca-b29ddff49254@measurement-factory.com>
References: <1140034948.954341.1495590259601.ref@mail.yahoo.com>
 <1140034948.954341.1495590259601@mail.yahoo.com>
 <41b65b4b-5603-ef56-5c5a-7bf68d8b0cd0@treenet.co.nz>
 <e5e5371f-74ce-0e6d-23ca-b29ddff49254@measurement-factory.com>
Message-ID: <e1e7a176-91bb-da65-a8b7-207ef8f9d1f1@treenet.co.nz>

On 25/05/17 02:17, Alex Rousskov wrote:
> On 05/24/2017 06:56 AM, Amos Jeffries wrote:
>> On 24/05/17 13:44, j m wrote:
>>> So firstly, what is the actual name for what I want (encrypting proxy
>>> to browser)?
>> Some people seem to be calling it "HTTPS", but that is not correct and
>> thankfully makes it difficult to find the bad info.
> What makes you think that "HTTPS proxy" is an incorrect term? That is
> the term I have seen used the most, and that is the term I would use.
> That is also the term that allows to locate relevant documents by googling.

Two reasons;

1) "HTTPS" has a definition (HTTP messages over TLS transport) and a 
scheme (https://) which explicitly precludes it being used to contact 
forward proxies. TLS to a proxy does not have a scheme of its own and 
can carry any protocol the proxy supports, not just HTTP.

2) protocol nesting for HTTPS-over-HTTPS is a very different series of 
layers and message sequence(s) than HTTPS-over-TLS [to a proxy]. In 
particular it is 4 layers deep (one for each "HTTPS").

Both HTTPS and TLS can be used independently to connect to a proxy. The 
differences are discussed at some length in the drafts below [a][b], its 
technically a fine line but the privacy and security implications are 
huge. People talking about one protocol stack while using the terms from 
the other have led to a lot of deadlocked arguments already.



>
>> The current IETF term for it is "TLS explicit proxy".
> Any supporting references? Neither Google nor I remember that term, and
> the term itself seems inferior to "HTTPS proxy" -- the proxy in question
> expects HTTP traffic underneath TLS so "HTTPS proxy" fits better IMHO.his

No direct reference sorry - it is not formal and may change, thus 
"current". It is what the sub-group of the WG have been using to discuss 
the case of "TLS (explicit)" connections made to an explicit proxy (see 
that 4-word -> 3-word redux?) since the long discussions instigated by 
the loreto draft[a] has effectively burned the term "trusted proxy" and 
"HTTPS proxy" into being HTTPS protocol stack to a proxy, and the rpeon 
draft[b] has formalized the term "explicit proxy" as what used to be the 
defacto standard "forward-proxy" with again "trusted proxy" being full 
decryption at the proxy.

[a] <https://datatracker.ietf.org/doc/draft-loreto-httpbis-trusted-proxy20/>
[b] <https://datatracker.ietf.org/doc/html/draft-rpeon-httpbis-exproxy-01>


Amos



From rogerio.coelho at gruporbs.com.br  Wed May 24 19:53:42 2017
From: rogerio.coelho at gruporbs.com.br (Rogerio Coelho)
Date: Wed, 24 May 2017 19:53:42 +0000
Subject: [squid-users] New Member - Just testing mail list
Message-ID: <SC1PR80MB194955C64F5CD37836A0883FD0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>

Hi Squid Users !

Just testing mail list.

Rog?rio Ceni Coelho
Engenheiro de Infraestrutura - Infrastructure Engineer
Diretoria de TI e Telecom - Grupo RBS
Fone: +55 (51) 3218-6983
Celular: +55 (51) 8186-2933 Claro
Celular: +55 (51) 8050-4225 Vivo
rogerio.coelho at gruporbs.com.br
http://www.gruporbs.com.br



Esta mensagem e quaisquer anexos s?o exclusivamente para o uso da parte endere?ada e poder?o conter dados privilegiados e confidenciais. Caso o leitor da mensagem n?o seja a parte a quem ela foi endere?ada, nem um representante autorizado da mesma, ficar? notificado, por meio desta, que qualquer divulga??o desta comunica??o ? estritamente proibida. Se esta comunica??o for recebida erroneamente, por favor, notifique-nos disto imediatamente por e-mail e delete a mensagem  e quaisquer anexos a ela de seu sistema.


O Grupo RBS pauta sua atua??o por seu C?digo de ?tica e Conduta, em conformidade com a Legisla??o Brasileira. Qualquer situa??o irregular deve ser informada via Canal de ?tica pelo site https://www.contatoseguro.com.br/gruporbs ou 0800 602 1831. Este e-mail e seus anexos podem conter informa??es confidenciais. Se voc? recebeu esta mensagem por engano, por favor apague-a e notifique o remetente imediatamente.


From squid3 at treenet.co.nz  Wed May 24 19:56:50 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 May 2017 07:56:50 +1200
Subject: [squid-users] Wrong timestamp??
In-Reply-To: <3d9bfbe8-f772-1068-e621-df6c8a2d5a29@gmail.com>
References: <1495651765128-4682545.post@n4.nabble.com>
 <8bfe82a5-518a-5239-c6c1-5aabdbef20f0@gmail.com>
 <3d9bfbe8-f772-1068-e621-df6c8a2d5a29@gmail.com>
Message-ID: <5d60cbb8-f238-e58f-f57d-a586e73837b4@treenet.co.nz>

Or a more accurate comparison:

   date ; date --utc ; squidclient mgr:info | grep Date

Thu May 25 07:54:05 NZST 2017
Wed May 24 19:54:05 UTC 2017
Date: Wed, 24 May 2017 19:54:05 GMT

Amos




From rogerio.coelho at gruporbs.com.br  Wed May 24 20:02:37 2017
From: rogerio.coelho at gruporbs.com.br (Rogerio Coelho)
Date: Wed, 24 May 2017 20:02:37 +0000
Subject: [squid-users] New Squid Server 3.5.20 on Centos 7 - Trying to
 redirect local web access to Port 80 on Linux Servers with iptables to
 Squid Server with http_port intercept
Message-ID: <SC1PR80MB194973E5AE33EB788BFB08C5D0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>

Hi Squid Jedi?s,

I am just a little stuck tryng to replace an old Squid 3.1.23 Server on Centos 6 that i use to redirect local web access to port 80 on linux servers to Squid Server.

On my Squid 3.1.23 Server on Centos 6 i use http_port 3128 transparent mode and on my Linux servers clients i use iptables to redirect Web traffic as below ( this config works ):

Squid Server 3.1.23 :

[root at leli squid]# cat squid.conf | egrep -v "^#|^$"
acl default_ip req_header x-forward -i "/ipt/SQUID/default/ip"
acl default_url dstdom_regex -i "/ipt/SQUID/default/url"
acl default_ip2 srcdom_regex -i "/ipt/SQUID/default/ip"
http_access allow default_ip default_url
acl endereco  req_header x-forward -i "/ipt/SQUID/libera/ip"
http_access allow endereco
acl all_ip req_header x-forward -i "/ipt/SQUID/all/ip"
acl all_url dstdom_regex -i "/ipt/SQUID/all/url"
acl all_ip2 srcdom_regex -i "/ipt/SQUID/all/ip"
http_access allow all_url
acl all src all
acl manager proto cache_object
acl from_localhost src 127.0.0.1/255.255.255.255
acl to_localhost dst 127.0.0.0/8
acl SSL_ports port 443
acl GIT_PORT port 9418         # git
acl CONNECT method CONNECT
acl Safe_ports port 80
acl Safe_ports port 443
acl Safe_ports port 21 # ftp
acl GIT_PORT2 port 9418 # git
http_access allow manager from_localhost
http_access deny manager
http_access allow GIT_PORT2
http_access deny !Safe_ports
http_access allow CONNECT GIT_PORT
http_access deny CONNECT !SSL_ports
http_access deny to_localhost
http_access allow from_localhost
http_access deny all
http_port 3128 transparent
https_port 3129 transparent intercept cert=/ipt/SQUID/https/squid.crt key=/ipt/SQUID/https/squid.key
hierarchy_stoplist cgi-bin ?
emulate_httpd_log on
logformat squid %tg %6tr %>a %{x-forward}>h %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
access_log /var/log/squid/access.log squid
access_log syslog:local0.info  squid
cache_log /var/log/squid/cache.log
cache_store_log /var/log/squid/store.log
mime_table /etc/squid/mime.conf
pid_filename /var/run/squid.pid
acl QUERY urlpath_regex .*
cache deny QUERY
acl apache rep_header Server ^Apache
acl FS_TESTE srcdom_regex -i "/ipt/SQUID/puppet/ip2"
cache_mgr tecnologiaseguranca at gruporbs.com.br
cache_effective_user squid
cache_effective_group squid
coredump_dir /var/spool/squid
maximum_object_size 0 KB
minimum_object_size 0 KB
no_cache deny all
deny_info 172.20.63.73 webapp_ip

[root at leli ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 46M packets, 3068M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 4581K packets, 276M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 4581K packets, 276M bytes)
 pkts bytes target     prot opt in     out     source               destination
[root at leli ~]#

Linux Server Clients ( Centos 5, 6 e 7 ) :

[root at montana rules]# cat proxy2.sh
#!/bin/bash

IPTBIN=$(which iptables)

$IPTBIN -t nat -F
$IPTBIN -t nat -X

#SQUID
$IPTBIN -A OUTPUT -s 10.240.68.68 -p tcp --sport 3128 -j ACCEPT

#PROXY
$IPTBIN -t nat -N PROXYSQUID
$IPTBIN -t nat -A OUTPUT -p tcp --dport 80 -j PROXYSQUID
$IPTBIN -t nat -A OUTPUT -p tcp --dport 443 -j PROXYSQUID
$IPTBIN -t nat -A PROXYSQUID -d 192.168.0.0/16 -j RETURN
$IPTBIN -t nat -A PROXYSQUID -d 189.76.144.0/20 -j RETURN
$IPTBIN -t nat -A PROXYSQUID -d 189.76.156.190 -j RETURN
$IPTBIN -t nat -A PROXYSQUID -d 172.16.0.0/12 -j RETURN
$IPTBIN -t nat -A PROXYSQUID -d 10.0.0.0/8 -j RETURN
$IPTBIN -t nat -A PROXYSQUID -p tcp -j DNAT --to-destination=10.240.68.68:3128


[root at montana rules]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 58M packets, 4835M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 2487K packets, 184M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 2487K packets, 184M bytes)
 pkts bytes target     prot opt in     out     source               destination
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           tcp dpt:80
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           tcp dpt:443

Chain PROXYSQUID (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
    0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
    0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           to:10.240.68.68:3128
[root at montana rules]# curl -v www.google.com
* About to connect() to www.google.com port 80
*   Trying 216.58.222.68... * connected
* Connected to www.google.com (216.58.222.68) port 80
> GET / HTTP/1.1
User-Agent: curl/7.12.1 (i686-redhat-linux-gnu) libcurl/7.12.1 OpenSSL/0.9.7a zlib/1.2.1.2 libidn/0.5.6
Host: www.google.com
Pragma: no-cache
Accept: */*

< HTTP/1.0 302 Moved Temporarily
< Location: http://www.google.com.br/?gws_rd=cr&ei=FtwdWdaDMYm0wQSWwZ24Ag
< Cache-Control: private
< Content-Type: text/html; charset=UTF-8
< P3P: CP="This is not a P3P policy! See https://www.google.com/support/accounts/answer/151657?hl=en for more info."
< Date: Thu, 18 May 2017 17:38:30 GMT
< Server: gws
< Content-Length: 262
< X-XSS-Protection: 1; mode=block
< X-Frame-Options: SAMEORIGIN
< Set-Cookie: NID=103=Vdks002SayhLjRhSWr_ETgZR2-0Hngh7ci-McE8fBhw6vDhAENt6JxWkTKtPKWen7HL-KYjiSNg9lwXnjSCejhv1va4yIUhPpMDYZ-mK4uDb9FQldR1zp3Y1RiOwx4jX; expires=Fri, 17-Nov-2017 17:38:30 GMT; path=/; domain=.google.com; HttpOnly
< X-Cache: MISS from leli.rbs.com.br
< X-Cache-Lookup: MISS from leli.rbs.com.br:3128
< Via: 1.0 leli.rbs.com.br (squid/3.1.23)
* HTTP/1.0 connection set to keep alive!
< Connection: keep-alive
<HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
<TITLE>302 Moved</TITLE></HEAD><BODY>
<H1>302 Moved</H1>
The document has moved
<A HREF="http://www.google.com.br/?gws_rd=cr&amp;ei=FtwdWdaDMYm0wQSWwZ24Ag">here</A>.
</BODY></HTML>
* Connection #0 to host www.google.com left intact
* Closing connection #0
[root at montana rules]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 58M packets, 4835M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 2487K packets, 184M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 2487K packets, 184M bytes)
 pkts bytes target     prot opt in     out     source               destination
    1    60 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           tcp dpt:80
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           tcp dpt:443

Chain PROXYSQUID (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
    0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
    0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
    1    60 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           to:10.240.68.68:3128
[root at montana rules]#

On my new Squid Server running 3.5.20 on Centos 7 a try to use in many different ways but have no success.

I will send my steps on a new reply email in few minutes because the email size.

Sorry about all this log of information.



Rog?rio Ceni Coelho
Engenheiro de Infraestrutura - Infrastructure Engineer
Diretoria de TI e Telecom - Grupo RBS
Fone: +55 (51) 3218-6983
Celular: +55 (51) 8186-2933 Claro
Celular: +55 (51) 8050-4225 Vivo
rogerio.coelho at gruporbs.com.br
http://www.gruporbs.com.br



Esta mensagem e quaisquer anexos s?o exclusivamente para o uso da parte endere?ada e poder?o conter dados privilegiados e confidenciais. Caso o leitor da mensagem n?o seja a parte a quem ela foi endere?ada, nem um representante autorizado da mesma, ficar? notificado, por meio desta, que qualquer divulga??o desta comunica??o ? estritamente proibida. Se esta comunica??o for recebida erroneamente, por favor, notifique-nos disto imediatamente por e-mail e delete a mensagem  e quaisquer anexos a ela de seu sistema.



O Grupo RBS pauta sua atua??o por seu C?digo de ?tica e Conduta, em conformidade com a Legisla??o Brasileira. Qualquer situa??o irregular deve ser informada via Canal de ?tica pelo site https://www.contatoseguro.com.br/gruporbs ou 0800 602 1831. Este e-mail e seus anexos podem conter informa??es confidenciais. Se voc? recebeu esta mensagem por engano, por favor apague-a e notifique o remetente imediatamente.


From rogerio.coelho at gruporbs.com.br  Wed May 24 20:12:15 2017
From: rogerio.coelho at gruporbs.com.br (Rogerio Coelho)
Date: Wed, 24 May 2017 20:12:15 +0000
Subject: [squid-users] RES: New Squid Server 3.5.20 on Centos 7 - Trying to
 redirect local web access to Port 80 on Linux Servers with iptables to
 Squid Server with http_port intercept
Message-ID: <SC1PR80MB194956E6A7A30F4ECFD508A6D0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>

On my new Squid Server running 3.5.20 on Centos 7 a try to use in many different ways.

When i use wget or firefox using http_proxy conf web access go ok. But when i try to access web using iptables redirect from Linux Server i got bad request / Invalid URL.

When i use http_port 3329 intercept mode i got forbbiden.

[root at prd-rbs-squid01-poa ~]# yum install squid -y
Loaded plugins: fastestmirror
base                                                                                                                                                      | 3.6 kB  00:00:00
epel/x86_64/metalink                                                                                                                                      |  38 kB  00:00:00
epel                                                                                                                                                      | 4.3 kB  00:00:00
extras                                                                                                                                                    | 3.4 kB  00:00:00
updates                                                                                                                                                   | 3.4 kB  00:00:00
zabbix                                                                                                                                                    |  951 B  00:00:00
zabbix-non-supported                                                                                                                                      |  951 B  00:00:00
(1/2): epel/x86_64/updateinfo                                                                                                                             | 798 kB  00:00:05
(2/2): epel/x86_64/primary_db                                                                                                                             | 4.7 MB  00:00:25
Loading mirror speeds from cached hostfile
 * base: centos.brnet.net.br
 * epel: mirror.globo.com
 * extras: centos.brnet.net.br
 * updates: centos.xpg.com.br
Resolving Dependencies
--> Running transaction check
---> Package squid.x86_64 7:3.5.20-2.el7_3.3 will be installed
--> Finished Dependency Resolution

Dependencies Resolved

=================================================================================================================================================================================
 Package                               Arch                                   Version                                              Repository                               Size
=================================================================================================================================================================================
Installing:
 squid                                 x86_64                                 7:3.5.20-2.el7_3.3                                   updates                                 3.1 M

Transaction Summary
=================================================================================================================================================================================
Install  1 Package

Total download size: 3.1 M
Installed size: 10 M
Downloading packages:
squid-3.5.20-2.el7_3.3.x86_64.rpm                                                                                                                         | 3.1 MB  00:00:02
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : 7:squid-3.5.20-2.el7_3.3.x86_64                                                                                                                               1/1
  Verifying  : 7:squid-3.5.20-2.el7_3.3.x86_64                                                                                                                               1/1

Installed:
  squid.x86_64 7:3.5.20-2.el7_3.3

Complete!
[root at prd-rbs-squid01-poa ~]# systemctl enable squid
Created symlink from /etc/systemd/system/multi-user.target.wants/squid.service to /usr/lib/systemd/system/squid.service.
[root at prd-rbs-squid01-poa ~]# systemctl start squid
[root at prd-rbs-squid01-poa ~]# cat /var/log/squid/cache.log
2017/05/18 14:59:57 kid1| Set Current Directory to /var/spool/squid
2017/05/18 14:59:57 kid1| Starting Squid Cache version 3.5.20 for x86_64-redhat-linux-gnu...
2017/05/18 14:59:57 kid1| Service Name: squid
2017/05/18 14:59:57 kid1| Process ID 3051
2017/05/18 14:59:57 kid1| Process Roles: worker
2017/05/18 14:59:57 kid1| With 16384 file descriptors available
2017/05/18 14:59:57 kid1| Initializing IP Cache...
2017/05/18 14:59:57 kid1| DNS Socket created at [::], FD 6
2017/05/18 14:59:57 kid1| DNS Socket created at 0.0.0.0, FD 8
2017/05/18 14:59:57 kid1| Adding domain RBS.NET from /etc/resolv.conf
2017/05/18 14:59:57 kid1| Adding domain rbs.com.br from /etc/resolv.conf
2017/05/18 14:59:57 kid1| Adding nameserver 10.236.68.62 from /etc/resolv.conf
2017/05/18 14:59:57 kid1| Adding nameserver 10.1.1.40 from /etc/resolv.conf
2017/05/18 14:59:57 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2017/05/18 14:59:57 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2017/05/18 14:59:57 kid1| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2017/05/18 14:59:57 kid1| Store logging disabled
2017/05/18 14:59:57 kid1| Swap maxSize 0 + 262144 KB, estimated 20164 objects
2017/05/18 14:59:57 kid1| Target number of buckets: 1008
2017/05/18 14:59:57 kid1| Using 8192 Store buckets
2017/05/18 14:59:57 kid1| Max Mem  size: 262144 KB
2017/05/18 14:59:57 kid1| Max Swap size: 0 KB
2017/05/18 14:59:57 kid1| Using Least Load store dir selection
2017/05/18 14:59:57 kid1| Set Current Directory to /var/spool/squid
2017/05/18 14:59:57 kid1| Finished loading MIME types and icons.
2017/05/18 14:59:57 kid1| HTCP Disabled.
2017/05/18 14:59:57 kid1| Squid plugin modules loaded: 0
2017/05/18 14:59:57 kid1| Adaptation support is off.
2017/05/18 14:59:57 kid1| Accepting HTTP Socket connections at local=[::]:3128 remote=[::] FD 11 flags=9
2017/05/18 14:59:58 kid1| storeLateRelease: released 0 objects

Linux Server Client ( Centos 7 ) ( Same Network of Squid Server ) :

[root at prd-rbs-squid02-poa ~]# /mnt/bin/Linux/proxy3520.sh
[root at prd-rbs-squid02-poa ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 32 packets, 2146 bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain INPUT (policy ACCEPT 7 packets, 528 bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:443

Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain PROXYSQUID (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
    0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
    0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            to:10.240.64.11:3128

[root at prd-rbs-squid02-poa ~]# wget http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm -e use_proxy=yes -e http_proxy=10.240.64.11:3128
--2017-05-18 15:03:18--  http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
Connecting to 10.240.64.11:3128... connected.
Proxy request sent, awaiting response... 200 OK
Length: 11416 (11K) [application/x-redhat-package-manager]
Saving to: ???zabbix-release-3.0-1.el7.noarch.rpm???

100%[=======================================================================================================================================>] 11,416      --.-K/s   in 0s

2017-05-18 15:03:18 (297 MB/s) - ???zabbix-release-3.0-1.el7.noarch.rpm??? saved [11416/11416]

[root at prd-rbs-squid02-poa ~]# wget http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
--2017-05-18 15:03:27--  http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
Resolving repo.zabbix.com (repo.zabbix.com)... 162.243.159.138
Connecting to repo.zabbix.com (repo.zabbix.com)|162.243.159.138|:80... connected.
HTTP request sent, awaiting response... 400 Bad Request
2017-05-18 15:03:27 ERROR 400: Bad Request.

[root at prd-rbs-squid02-poa ~]# curl -v http://www.google.com
* About to connect() to www.google.com port 80 (#0)
*   Trying 216.58.222.68...
* Connected to www.google.com (216.58.222.68) port 80 (#0)
> GET / HTTP/1.1
> User-Agent: curl/7.29.0
> Host: www.google.com
> Accept: */*
>
< HTTP/1.1 400 Bad Request
< Server: squid/3.5.20
< Mime-Version: 1.0
< Date: Thu, 18 May 2017 18:03:37 GMT
< Content-Type: text/html;charset=utf-8
< Content-Length: 3556
< X-Squid-Error: ERR_INVALID_URL 0
< Vary: Accept-Language
< Content-Language: en
< X-Cache: MISS from prd-rbs-squid01-poa.rbs.com.br
< X-Cache-Lookup: NONE from prd-rbs-squid01-poa.rbs.com.br:3128
< Via: 1.1 prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20)
< Connection: close
<
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
<meta type="copyright" content="Copyright (C) 1996-2016 The Squid Software Foundation and contributors">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>ERROR: The requested URL could not be retrieved</title>
<style type="text/css"><!--
 /*
 * Copyright (C) 1996-2016 The Squid Software Foundation and contributors
 *
 * Squid software is distributed under GPLv2+ license and includes
 * contributions from numerous individuals and organizations.
 * Please see the COPYING and CONTRIBUTORS files for details.
 */

/*
 Stylesheet for Squid Error pages
 Adapted from design by Free CSS Templates
 http://www.freecsstemplates.org
 Released for free under a Creative Commons Attribution 2.5 License
*/

/* Page basics */
* {
        font-family: verdana, sans-serif;
}

html body {
        margin: 0;
        padding: 0;
        background: #efefef;
        font-size: 12px;
        color: #1e1e1e;
}

/* Page displayed title area */
#titles {
        margin-left: 15px;
        padding: 10px;
        padding-left: 100px;
        background: url('/squid-internal-static/icons/SN.png') no-repeat left;
}

/* initial title */
#titles h1 {
        color: #000000;
}
#titles h2 {
        color: #000000;
}

/* special event: FTP success page titles */
#titles ftpsuccess {
        background-color:#00ff00;
        width:100%;
}

/* Page displayed body content area */
#content {
        padding: 10px;
        background: #ffffff;
}

/* General text */
p {
}

/* error brief description */
#error p {
}

/* some data which may have caused the problem */
#data {
}

/* the error message received from the system or other software */
#sysmsg {
}

pre {
    font-family:sans-serif;
}

/* special event: FTP / Gopher directory listing */
#dirmsg {
    font-family: courier;
    color: black;
    font-size: 10pt;
}
#dirlisting {
    margin-left: 2%;
    margin-right: 2%;
}
#dirlisting tr.entry td.icon,td.filename,td.size,td.date {
    border-bottom: groove;
}
#dirlisting td.size {
    width: 50px;
    text-align: right;
    padding-right: 5px;
}

/* horizontal lines */
hr {
        margin: 0;
}

/* page displayed footer area */
#footer {
        font-size: 9px;
        padding-left: 10px;
}


body
:lang(fa) { direction: rtl; font-size: 100%; font-family: Tahoma, Roya, sans-serif; float: right; }
:lang(he) { direction: rtl; }
 --></style>
</head><body id=ERR_INVALID_URL>
<div id="titles">
<h1>ERROR</h1>
<h2>The requested URL could not be retrieved</h2>
</div>
<hr>

<div id="content">
<p>The following error was encountered while trying to retrieve the URL: <a href="/">/</a></p>

<blockquote id="error">
<p><b>Invalid URL</b></p>
</blockquote>

<p>Some aspect of the requested URL is incorrect.</p>

<p>Some possible problems are:</p>
<ul>
<li><p>Missing or incorrect access protocol (should be <q>http://</q> or similar)</p></li>
<li><p>Missing hostname</p></li>
<li><p>Illegal double-escape in the URL-Path</p></li>
<li><p>Illegal character in hostname; underscores are not allowed.</p></li>
</ul>

<p>Your cache administrator is <a href="mailto:root?subject=CacheErrorInfo%20-%20ERR_INVALID_URL&amp;body=CacheHost%3A%20prd-rbs-squid01-poa.rbs.com.br%0D%0AErrPage%3A%20ERR_INVALID_URL%0D%0AErr%3A%20%5Bnone%5D%0D%0ATimeStamp%3A%20Thu,%2018%20May%202017%2018%3A03%3A37%20GMT%0D%0A%0D%0AClientIP%3A%2010.240.64.12%0D%0A%0D%0AHTTP%20Request%3A%0D%0A%0D%0A%0D%0A">root</a>.</p>
<br>
</div>

<hr>
<div id="footer">
<p>Generated Thu, 18 May 2017 18:03:37 GMT by prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20)</p>
<!-- ERR_INVALID_URL -->
</div>
</body></html>
* Closing connection 0
[root at prd-rbs-squid02-poa ~]#

[root at prd-rbs-squid01-poa ~]# tail -f /var/log/squid/access.log



1495130446.581    439 10.240.64.12 TCP_MISS/200 11869 GET http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - HIER_DIRECT/162.243.159.138 application/x-redhat-package-manager
1495130598.008      0 10.240.64.12 TCP_MEM_HIT/200 11877 GET http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - HIER_NONE/- application/x-redhat-package-manager
1495130607.437      0 10.240.64.12 TAG_NONE/400 4111 GET /zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - HIER_NONE/- text/html
1495130617.581      0 10.240.64.12 TAG_NONE/400 3991 GET / - HIER_NONE/- text/html

I will send more on reply to this email because of the size of this email.

Rog?rio Ceni Coelho
Engenheiro de Infraestrutura ? Infrastructure Engineer
Diretoria de TI e Telecom - Grupo RBS
Fone: +55 (51) 3218-6983
Celular: +55 (51) 8186-2933 Claro
Celular: +55 (51) 8050-4225 Vivo
rogerio.coelho at gruporbs.com.br
http://www.gruporbs.com.br



Esta mensagem e quaisquer anexos s?o exclusivamente para o uso da parte endere?ada e poder?o conter dados privilegiados e confidenciais. Caso o leitor da mensagem n?o seja a parte a quem ela foi endere?ada, nem um representante autorizado da mesma, ficar? notificado, por meio desta, que qualquer divulga??o desta comunica??o ? estritamente proibida. Se esta comunica??o for recebida erroneamente, por favor, notifique-nos disto imediatamente por e-mail e delete a mensagem  e quaisquer anexos a ela de seu sistema.



-----Mensagem original-----
De: Rogerio Coelho
Enviada em: quarta-feira, 24 de maio de 2017 17:03
Para: squid-users at lists.squid-cache.org
Assunto: New Squid Server 3.5.20 on Centos 7 - Trying to redirect local web access to Port 80 on Linux Servers with iptables to Squid Server with http_port intercept

Hi Squid Jedi?s,

I am just a little stuck tryng to replace an old Squid 3.1.23 Server on Centos 6 that i use to redirect local web access to port 80 on linux servers to Squid Server.

On my Squid 3.1.23 Server on Centos 6 i use http_port 3128 transparent mode and on my Linux servers clients i use iptables to redirect Web traffic as below ( this config works ):

Squid Server 3.1.23 :

[root at leli squid]# cat squid.conf | egrep -v "^#|^$"
acl default_ip req_header x-forward -i "/ipt/SQUID/default/ip"
acl default_url dstdom_regex -i "/ipt/SQUID/default/url"
acl default_ip2 srcdom_regex -i "/ipt/SQUID/default/ip"
http_access allow default_ip default_url acl endereco  req_header x-forward -i "/ipt/SQUID/libera/ip"
http_access allow endereco
acl all_ip req_header x-forward -i "/ipt/SQUID/all/ip"
acl all_url dstdom_regex -i "/ipt/SQUID/all/url"
acl all_ip2 srcdom_regex -i "/ipt/SQUID/all/ip"
http_access allow all_url
acl all src all
acl manager proto cache_object
acl from_localhost src 127.0.0.1/255.255.255.255 acl to_localhost dst 127.0.0.0/8 acl SSL_ports port 443
acl GIT_PORT port 9418         # git
acl CONNECT method CONNECT
acl Safe_ports port 80
acl Safe_ports port 443
acl Safe_ports port 21 # ftp
acl GIT_PORT2 port 9418 # git
http_access allow manager from_localhost http_access deny manager http_access allow GIT_PORT2 http_access deny !Safe_ports http_access allow CONNECT GIT_PORT http_access deny CONNECT !SSL_ports http_access deny to_localhost http_access allow from_localhost http_access deny all http_port 3128 transparent https_port 3129 transparent intercept cert=/ipt/SQUID/https/squid.crt key=/ipt/SQUID/https/squid.key hierarchy_stoplist cgi-bin ?
emulate_httpd_log on
logformat squid %tg %6tr %>a %{x-forward}>h %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt access_log /var/log/squid/access.log squid access_log syslog:local0.info  squid cache_log /var/log/squid/cache.log cache_store_log /var/log/squid/store.log mime_table /etc/squid/mime.conf pid_filename /var/run/squid.pid acl QUERY urlpath_regex .* cache deny QUERY acl apache rep_header Server ^Apache acl FS_TESTE srcdom_regex -i "/ipt/SQUID/puppet/ip2"
cache_mgr tecnologiaseguranca at gruporbs.com.br
cache_effective_user squid
cache_effective_group squid
coredump_dir /var/spool/squid
maximum_object_size 0 KB
minimum_object_size 0 KB
no_cache deny all
deny_info 172.20.63.73 webapp_ip

[root at leli ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 46M packets, 3068M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 4581K packets, 276M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 4581K packets, 276M bytes)
 pkts bytes target     prot opt in     out     source               destination
[root at leli ~]#

Linux Server Clients ( Centos 5, 6 e 7 ) :

[root at montana rules]# cat proxy2.sh
#!/bin/bash

IPTBIN=$(which iptables)

$IPTBIN -t nat -F
$IPTBIN -t nat -X

#SQUID
$IPTBIN -A OUTPUT -s 10.240.68.68 -p tcp --sport 3128 -j ACCEPT

#PROXY
$IPTBIN -t nat -N PROXYSQUID
$IPTBIN -t nat -A OUTPUT -p tcp --dport 80 -j PROXYSQUID $IPTBIN -t nat -A OUTPUT -p tcp --dport 443 -j PROXYSQUID $IPTBIN -t nat -A PROXYSQUID -d 192.168.0.0/16 -j RETURN $IPTBIN -t nat -A PROXYSQUID -d 189.76.144.0/20 -j RETURN $IPTBIN -t nat -A PROXYSQUID -d 189.76.156.190 -j RETURN $IPTBIN -t nat -A PROXYSQUID -d 172.16.0.0/12 -j RETURN $IPTBIN -t nat -A PROXYSQUID -d 10.0.0.0/8 -j RETURN $IPTBIN -t nat -A PROXYSQUID -p tcp -j DNAT --to-destination=10.240.68.68:3128


[root at montana rules]# iptables -L -n -v -t nat Chain PREROUTING (policy ACCEPT 58M packets, 4835M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 2487K packets, 184M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 2487K packets, 184M bytes)
 pkts bytes target     prot opt in     out     source               destination
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           tcp dpt:80
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           tcp dpt:443

Chain PROXYSQUID (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
    0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
    0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           to:10.240.68.68:3128
[root at montana rules]# curl -v www.google.com
* About to connect() to www.google.com port 80
*   Trying 216.58.222.68... * connected
* Connected to www.google.com (216.58.222.68) port 80
> GET / HTTP/1.1
User-Agent: curl/7.12.1 (i686-redhat-linux-gnu) libcurl/7.12.1 OpenSSL/0.9.7a zlib/1.2.1.2 libidn/0.5.6
Host: www.google.com
Pragma: no-cache
Accept: */*

< HTTP/1.0 302 Moved Temporarily
< Location: http://www.google.com.br/?gws_rd=cr&ei=FtwdWdaDMYm0wQSWwZ24Ag
< Cache-Control: private
< Content-Type: text/html; charset=UTF-8 < P3P: CP="This is not a P3P policy! See https://www.google.com/support/accounts/answer/151657?hl=en for more info."
< Date: Thu, 18 May 2017 17:38:30 GMT
< Server: gws
< Content-Length: 262
< X-XSS-Protection: 1; mode=block
< X-Frame-Options: SAMEORIGIN
< Set-Cookie: NID=103=Vdks002SayhLjRhSWr_ETgZR2-0Hngh7ci-McE8fBhw6vDhAENt6JxWkTKtPKWen7HL-KYjiSNg9lwXnjSCejhv1va4yIUhPpMDYZ-mK4uDb9FQldR1zp3Y1RiOwx4jX; expires=Fri, 17-Nov-2017 17:38:30 GMT; path=/; domain=.google.com; HttpOnly < X-Cache: MISS from leli.rbs.com.br < X-Cache-Lookup: MISS from leli.rbs.com.br:3128 < Via: 1.0 leli.rbs.com.br (squid/3.1.23)
* HTTP/1.0 connection set to keep alive!
< Connection: keep-alive
<HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
<TITLE>302 Moved</TITLE></HEAD><BODY>
<H1>302 Moved</H1>
The document has moved
<A HREF="http://www.google.com.br/?gws_rd=cr&amp;ei=FtwdWdaDMYm0wQSWwZ24Ag">here</A>.
</BODY></HTML>
* Connection #0 to host www.google.com left intact
* Closing connection #0
[root at montana rules]# iptables -L -n -v -t nat Chain PREROUTING (policy ACCEPT 58M packets, 4835M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 2487K packets, 184M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 2487K packets, 184M bytes)
 pkts bytes target     prot opt in     out     source               destination
    1    60 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           tcp dpt:80
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           tcp dpt:443

Chain PROXYSQUID (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
    0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
    0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
    1    60 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           to:10.240.68.68:3128
[root at montana rules]#

On my new Squid Server running 3.5.20 on Centos 7 a try to use in many different ways but have no success.

I will send my steps on a new reply email in few minutes because the email size.

Sorry about all this log of information.



Rog?rio Ceni Coelho
Engenheiro de Infraestrutura ? Infrastructure Engineer Diretoria de TI e Telecom - Grupo RBS
Fone: +55 (51) 3218-6983
Celular: +55 (51) 8186-2933 Claro
Celular: +55 (51) 8050-4225 Vivo
rogerio.coelho at gruporbs.com.br
http://www.gruporbs.com.br



Esta mensagem e quaisquer anexos s?o exclusivamente para o uso da parte endere?ada e poder?o conter dados privilegiados e confidenciais. Caso o leitor da mensagem n?o seja a parte a quem ela foi endere?ada, nem um representante autorizado da mesma, ficar? notificado, por meio desta, que qualquer divulga??o desta comunica??o ? estritamente proibida. Se esta comunica??o for recebida erroneamente, por favor, notifique-nos disto imediatamente por e-mail e delete a mensagem  e quaisquer anexos a ela de seu sistema.



O Grupo RBS pauta sua atua??o por seu C?digo de ?tica e Conduta, em conformidade com a Legisla??o Brasileira. Qualquer situa??o irregular deve ser informada via Canal de ?tica pelo site https://www.contatoseguro.com.br/gruporbs ou 0800 602 1831. Este e-mail e seus anexos podem conter informa??es confidenciais. Se voc? recebeu esta mensagem por engano, por favor apague-a e notifique o remetente imediatamente.

From rogerio.coelho at gruporbs.com.br  Wed May 24 20:16:59 2017
From: rogerio.coelho at gruporbs.com.br (Rogerio Coelho)
Date: Wed, 24 May 2017 20:16:59 +0000
Subject: [squid-users] RES: New Squid Server 3.5.20 on Centos 7 - Trying to
 redirect local web access to Port 80 on Linux Servers with iptables to
 Squid Server with http_port intercept
Message-ID: <SC1PR80MB19499C09E5D9F768548EED20D0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>

Using intercept mode with 3129 port :

[root at prd-rbs-squid01-poa squid]# cat /etc/squid/squid.conf | egrep -v "^#|^$"
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
acl SSL_ports port 443
acl Safe_ports port 80          # http
?
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localnet
http_access allow localhost
http_port 3128
http_port 3129 intercept
cache_dir ufs /var/spool/squid 100 16 256
coredump_dir /var/spool/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
[root at prd-rbs-squid01-poa squid]#

[root at prd-rbs-squid01-poa ~]# systemctl restart squid
[root at prd-rbs-squid01-poa squid]# systemctl start squid
[root at prd-rbs-squid01-poa squid]# cat cache.log
2017/05/18 15:22:29 kid1| Set Current Directory to /var/spool/squid
2017/05/18 15:22:29 kid1| Starting Squid Cache version 3.5.20 for x86_64-redhat-linux-gnu...
2017/05/18 15:22:29 kid1| Service Name: squid
2017/05/18 15:22:29 kid1| Process ID 6592
2017/05/18 15:22:29 kid1| Process Roles: worker
2017/05/18 15:22:29 kid1| With 16384 file descriptors available
2017/05/18 15:22:29 kid1| Initializing IP Cache...
2017/05/18 15:22:29 kid1| DNS Socket created at [::], FD 6
2017/05/18 15:22:29 kid1| DNS Socket created at 0.0.0.0, FD 8
2017/05/18 15:22:29 kid1| Adding domain RBS.NET from /etc/resolv.conf
2017/05/18 15:22:29 kid1| Adding domain rbs.com.br from /etc/resolv.conf
2017/05/18 15:22:29 kid1| Adding nameserver 10.236.68.62 from /etc/resolv.conf
2017/05/18 15:22:29 kid1| Adding nameserver 10.1.1.40 from /etc/resolv.conf
2017/05/18 15:22:29 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2017/05/18 15:22:29 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2017/05/18 15:22:29 kid1| Unlinkd pipe opened on FD 14
2017/05/18 15:22:29 kid1| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2017/05/18 15:22:29 kid1| Store logging disabled
2017/05/18 15:22:29 kid1| Swap maxSize 102400 + 262144 KB, estimated 28041 objects
2017/05/18 15:22:29 kid1| Target number of buckets: 1402
2017/05/18 15:22:29 kid1| Using 8192 Store buckets
2017/05/18 15:22:29 kid1| Max Mem  size: 262144 KB
2017/05/18 15:22:29 kid1| Max Swap size: 102400 KB
2017/05/18 15:22:29 kid1| Rebuilding storage in /var/spool/squid (dirty log)
2017/05/18 15:22:29 kid1| Using Least Load store dir selection
2017/05/18 15:22:29 kid1| Set Current Directory to /var/spool/squid
2017/05/18 15:22:29 kid1| Finished loading MIME types and icons.
2017/05/18 15:22:29 kid1| HTCP Disabled.
2017/05/18 15:22:29 kid1| Squid plugin modules loaded: 0
2017/05/18 15:22:29 kid1| Adaptation support is off.
2017/05/18 15:22:29 kid1| Accepting HTTP Socket connections at local=[::]:3128 remote=[::] FD 17 flags=9
2017/05/18 15:22:29 kid1| Accepting NAT intercepted HTTP Socket connections at local=[::]:3129 remote=[::] FD 18 flags=41
2017/05/18 15:22:29 kid1| Done reading /var/spool/squid swaplog (3 entries)
2017/05/18 15:22:29 kid1| Finished rebuilding storage from disk.
2017/05/18 15:22:29 kid1|         2 Entries scanned
2017/05/18 15:22:29 kid1|         0 Invalid entries.
2017/05/18 15:22:29 kid1|         0 With invalid flags.
2017/05/18 15:22:29 kid1|         1 Objects loaded.
2017/05/18 15:22:29 kid1|         0 Objects expired.
2017/05/18 15:22:29 kid1|         0 Objects cancelled.
2017/05/18 15:22:29 kid1|         0 Duplicate URLs purged.
2017/05/18 15:22:29 kid1|         1 Swapfile clashes avoided.
2017/05/18 15:22:29 kid1|   Took 0.01 seconds ( 91.36 objects/sec).
2017/05/18 15:22:29 kid1| Beginning Validation Procedure
2017/05/18 15:22:29 kid1|   Completed Validation Procedure
2017/05/18 15:22:29 kid1|   Validated 1 Entries
2017/05/18 15:22:29 kid1|   store_swap_size = 12.00 KB
2017/05/18 15:22:30 kid1| storeLateRelease: released 0 objects

[root at prd-rbs-squid01-poa squid]# netstat -nap | grep -i squid
tcp6       0      0 :::3128                 :::*                    LISTEN      6592/(squid-1)
tcp6       0      0 :::3129                 :::*                    LISTEN      6592/(squid-1)
udp        0      0 0.0.0.0:50868           0.0.0.0:*                           6592/(squid-1)
udp6       0      0 :::55754                :::*                                6592/(squid-1)
unix  3      [ ]         STREAM     CONNECTED     73819    6592/(squid-1)
unix  2      [ ]         DGRAM                    72824    6590/squid
[root at prd-rbs-squid01-poa squid]#

[root at prd-rbs-squid02-poa ~]# /mnt/bin/Linux/proxy3520_3129.sh
?
[root at prd-rbs-squid02-poa ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 27 packets, 1754 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain INPUT (policy ACCEPT 4 packets, 240 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 1 packets, 76 bytes)
?
 pkts bytes target     prot opt in     out     source               destination
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:443

Chain POSTROUTING (policy ACCEPT 1 packets, 76 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain PROXYSQUID (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
    0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
    0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            to:10.240.64.11:3129
[root at prd-rbs-squid02-poa ~]# rm zabbix-release-3.0-1.el7.noarch.rpm*
rm: remove regular file ???zabbix-release-3.0-1.el7.noarch.rpm???? y
rm: remove regular file ???zabbix-release-3.0-1.el7.noarch.rpm.1???? y
rm: remove regular file ???zabbix-release-3.0-1.el7.noarch.rpm.2???? y
rm: remove regular file ???zabbix-release-3.0-1.el7.noarch.rpm.3???? y
?
[root at prd-rbs-squid02-poa ~]# wget http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm -e use_proxy=yes -e http_proxy=10.240.64.11:3128
--2017-05-18 15:23:57--  http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
?
Connecting to 10.240.64.11:3128... connected.
Proxy request sent, awaiting response... 200 OK
Length: 11416 (11K) [application/x-redhat-package-manager]
Saving to: ???zabbix-release-3.0-1.el7.noarch.rpm???

100%[=======================================================================================================================================>] 11,416      --.-K/s   in 0s

2017-05-18 15:23:58 (194 MB/s) - ???zabbix-release-3.0-1.el7.noarch.rpm??? saved [11416/11416]
?

[root at prd-rbs-squid02-poa ~]# wget http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
--2017-05-18 15:24:16--  http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
?
Resolving repo.zabbix.com (repo.zabbix.com)... 162.243.159.138
Connecting to repo.zabbix.com (repo.zabbix.com)|162.243.159.138|:80... connected.
HTTP request sent, awaiting response... 403 Forbidden
2017-05-18 15:24:16 ERROR 403: Forbidden.
?

[root at prd-rbs-squid02-poa ~]# curl -v http://www.google.com
* About to connect() to www.google.com port 80 (#0)
*   Trying 216.58.222.68...
* Connected to www.google.com (216.58.222.68) port 80 (#0)
> GET / HTTP/1.1
> User-Agent: curl/7.29.0
> Host: www.google.com
> Accept: */*
>
< HTTP/1.1 403 Forbidden
< Server: squid/3.5.20
< Mime-Version: 1.0
< Date: Thu, 18 May 2017 18:24:23 GMT
< Content-Type: text/html;charset=utf-8
< Content-Length: 3707
< X-Squid-Error: ERR_ACCESS_DENIED 0
?
< Vary: Accept-Language
< Content-Language: en
< X-Cache: MISS from prd-rbs-squid01-poa.rbs.com.br
< X-Cache-Lookup: MISS from prd-rbs-squid01-poa.rbs.com.br:3128
< X-Cache: MISS from prd-rbs-squid01-poa.rbs.com.br
< X-Cache-Lookup: MISS from prd-rbs-squid01-poa.rbs.com.br:3128
< Via: 1.1 prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20), 1.1 prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20)
< Connection: keep-alive
?
</head><body id=ERR_ACCESS_DENIED>
?
<div id="titles">
<h1>ERROR</h1>
<h2>The requested URL could not be retrieved</h2>
</div>
<hr>

<div id="content">
<p>The following error was encountered while trying to retrieve the URL: <a href="http://www.google.com/">http://www.google.com/</a></p>

<blockquote id="error">
<p><b>Access Denied.</b></p>
</blockquote>

<p>Access control configuration prevents your request from being allowed at this time. Please contact your service provider if you feel this is incorrect.</p>

<p>Your cache administrator is <a href="mailto:root?subject=CacheErrorInfo%20-%20ERR_ACCESS_DENIED&amp;body=CacheHost%3A%20prd-rbs-squid01-poa.rbs.com.br%0D%0AErrPage%3A%20ERR_ACCESS_DENIED%0D%0AErr%3A%20%5Bnone%5D%0D%0ATimeStamp%3A%20Thu,%2018%20May%202017%2018%3A24%3A23%20GMT%0D%0A%0D%0AClientIP%3A%2010.240.64.11%0D%0A%0D%0AHTTP%20Request%3A%0D%0AGET%20%2F%20HTTP%2F1.1%0AUser-Agent%3A%20curl%2F7.29.0%0D%0AAccept%3A%20*%2F*%0D%0AVia%3A%201.1%20prd-rbs-squid01-poa.rbs.com.br%20(squid%2F3.5.20)%0D%0AX-Forwarded-For%3A%2010.240.64.12%0D%0ACache-Control%3A%20max-age%3D259200%0D%0AConnection%3A%20keep-alive%0D%0AHost%3A%20www.google.com%0D%0A%0D%0A%0D%0A">root</a>.</p>
?
<br>
</div>

<hr>
<div id="footer">
<p>Generated Thu, 18 May 2017 18:24:23 GMT by prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20)</p>
<!-- ERR_ACCESS_DENIED -->
</div>
</body></html>
?
* Connection #0 to host www.google.com left intact
[root at prd-rbs-squid02-poa ~]#
?
[root at prd-rbs-squid02-poa ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 238 packets, 21830 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain INPUT (policy ACCEPT 48 packets, 4956 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 4 packets, 257 bytes)
?
 pkts bytes target     prot opt in     out     source               destination
    2   120 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80
?
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:443

Chain POSTROUTING (policy ACCEPT 6 packets, 377 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain PROXYSQUID (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
    0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
    0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
    2   120 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            to:10.240.64.11:3129
[root at prd-rbs-squid02-poa ~]#

[root at prd-rbs-squid01-poa squid]# tail -f /var/log/squid/access.log
1495131838.333    470 10.240.64.12 TCP_SWAPFAIL_MISS/200 11868 GET http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - HIER_DIRECT/162.243.159.138 application/x-redhat-package-manager

1495131856.340      0 10.240.64.11 TCP_MISS/403 4352 GET http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - HIER_NONE/- text/html
1495131856.340      0 10.240.64.12 TCP_MISS/403 4517 GET http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - ORIGINAL_DST/10.240.64.11 text/html
1495131863.177      0 10.240.64.11 TCP_MISS/403 4147 GET http://www.google.com/ - HIER_NONE/- text/html
1495131863.177      3 10.240.64.12 TCP_MISS/403 4312 GET http://www.google.com/ - ORIGINAL_DST/10.240.64.11 text/html





When i add iptables nat rules on Squid Server i get Service Unavailable / ERR_CONNECT_FAIL 111 .

[root at prd-rbs-squid01-poa ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 11682 packets, 1002K bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain INPUT (policy ACCEPT 2631 packets, 243K bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 150 packets, 11353 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 150 packets, 11353 bytes)
?
 pkts bytes target     prot opt in     out     source               destination
[root at prd-rbs-squid01-poa ~]# cat /root/squid.sh
#!/bin/bash

echo "1" > /proc/sys/net/ipv4/ip_forward
echo "0" > /proc/sys/net/ipv4/conf/default/rp_filter
echo "0" > /proc/sys/net/ipv4/conf/default/accept_source_route

iptables -F -t nat
iptables -X -t nat

# your proxy IP
SQUIDIP=10.240.64.11

# your proxy listening port
SQUIDPORT=3129

iptables -t nat -A PREROUTING -s $SQUIDIP -p tcp --dport 80 -j ACCEPT
iptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to-destination $SQUIDIP:$SQUIDPORT
iptables -t nat -A POSTROUTING -j MASQUERADE
iptables -t mangle -A PREROUTING -p tcp --dport $SQUIDPORT -j DROP
[root at prd-rbs-squid01-poa ~]# /root/squid.sh
[root at prd-rbs-squid01-poa ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 13 packets, 1777 bytes)
?
 pkts bytes target     prot opt in     out     source               destination
    0     0 ACCEPT     tcp  --  *      *       10.240.64.11         0.0.0.0/0            tcp dpt:80
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80 to:10.240.64.11:3129

Chain INPUT (policy ACCEPT 6 packets, 885 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination
    0     0 MASQUERADE  all  --  *      *       0.0.0.0/0            0.0.0.0/0

[root at prd-rbs-squid01-poa ~]# netstat -nap | grep -i squid
tcp6       0      0 :::3128                 :::*                    LISTEN      6592/(squid-1)
tcp6       0      0 :::3129                 :::*                    LISTEN      6592/(squid-1)
udp        0      0 0.0.0.0:50868           0.0.0.0:*                           6592/(squid-1)
udp6       0      0 :::55754                :::*                                6592/(squid-1)
unix  3      [ ]         STREAM     CONNECTED     73819    6592/(squid-1)
unix  2      [ ]         DGRAM                    72824    6590/squid
[root at prd-rbs-squid01-poa ~]# systemctl stop squid
[root at prd-rbs-squid01-poa ~]# rm /var/log/squid/* -f
?
[root at prd-rbs-squid01-poa ~]# systemctl start squid
[root at prd-rbs-squid01-poa ~]# cat /var/log/squid/cache.log
2017/05/18 15:34:48 kid1| Set Current Directory to /var/spool/squid
2017/05/18 15:34:48 kid1| Starting Squid Cache version 3.5.20 for x86_64-redhat-linux-gnu...
2017/05/18 15:34:48 kid1| Service Name: squid
2017/05/18 15:34:48 kid1| Process ID 8435
2017/05/18 15:34:48 kid1| Process Roles: worker
2017/05/18 15:34:48 kid1| With 16384 file descriptors available
2017/05/18 15:34:48 kid1| Initializing IP Cache...
2017/05/18 15:34:48 kid1| DNS Socket created at [::], FD 6
2017/05/18 15:34:48 kid1| DNS Socket created at 0.0.0.0, FD 8
2017/05/18 15:34:48 kid1| Adding domain RBS.NET from /etc/resolv.conf
2017/05/18 15:34:48 kid1| Adding domain rbs.com.br from /etc/resolv.conf
2017/05/18 15:34:48 kid1| Adding nameserver 10.236.68.62 from /etc/resolv.conf
2017/05/18 15:34:48 kid1| Adding nameserver 10.1.1.40 from /etc/resolv.conf
2017/05/18 15:34:48 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2017/05/18 15:34:48 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2017/05/18 15:34:48 kid1| Unlinkd pipe opened on FD 14
2017/05/18 15:34:48 kid1| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2017/05/18 15:34:48 kid1| Store logging disabled
2017/05/18 15:34:48 kid1| Swap maxSize 102400 + 262144 KB, estimated 28041 objects
2017/05/18 15:34:48 kid1| Target number of buckets: 1402
2017/05/18 15:34:48 kid1| Using 8192 Store buckets
2017/05/18 15:34:48 kid1| Max Mem  size: 262144 KB
2017/05/18 15:34:48 kid1| Max Swap size: 102400 KB
2017/05/18 15:34:48 kid1| Rebuilding storage in /var/spool/squid (dirty log)
2017/05/18 15:34:48 kid1| Using Least Load store dir selection
2017/05/18 15:34:48 kid1| Set Current Directory to /var/spool/squid
2017/05/18 15:34:48 kid1| Finished loading MIME types and icons.
2017/05/18 15:34:48 kid1| HTCP Disabled.
2017/05/18 15:34:48 kid1| Squid plugin modules loaded: 0
2017/05/18 15:34:48 kid1| Adaptation support is off.
2017/05/18 15:34:48 kid1| Accepting HTTP Socket connections at local=[::]:3128 remote=[::] FD 17 flags=9
2017/05/18 15:34:48 kid1| Accepting NAT intercepted HTTP Socket connections at local=[::]:3129 remote=[::] FD 18 flags=41
2017/05/18 15:34:48 kid1| Done reading /var/spool/squid swaplog (4 entries)
2017/05/18 15:34:48 kid1| Finished rebuilding storage from disk.
2017/05/18 15:34:48 kid1|         2 Entries scanned
2017/05/18 15:34:48 kid1|         0 Invalid entries.
2017/05/18 15:34:48 kid1|         0 With invalid flags.
2017/05/18 15:34:48 kid1|         1 Objects loaded.
2017/05/18 15:34:48 kid1|         0 Objects expired.
2017/05/18 15:34:48 kid1|         0 Objects cancelled.
2017/05/18 15:34:48 kid1|         0 Duplicate URLs purged.
2017/05/18 15:34:48 kid1|         1 Swapfile clashes avoided.
2017/05/18 15:34:48 kid1|   Took 0.01 seconds ( 91.74 objects/sec).
2017/05/18 15:34:48 kid1| Beginning Validation Procedure
2017/05/18 15:34:48 kid1|   Completed Validation Procedure
2017/05/18 15:34:48 kid1|   Validated 1 Entries
2017/05/18 15:34:48 kid1|   store_swap_size = 12.00 KB
2017/05/18 15:34:49 kid1| storeLateRelease: released 0 objects


[root at prd-rbs-squid02-poa ~]# /mnt/bin/Linux/proxy3520_80.sh
?
[root at prd-rbs-squid02-poa ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 8 packets, 594 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain INPUT (policy ACCEPT 0 packets, 0 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 1 packets, 76 bytes)
?
 pkts bytes target     prot opt in     out     source               destination
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:443

Chain POSTROUTING (policy ACCEPT 1 packets, 76 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain PROXYSQUID (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
    0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
    0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            to:10.240.64.11:80
?

[root at prd-rbs-squid02-poa ~]# wget http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm -e use_proxy=yes -e http_proxy=10.240.64.11:3128
--2017-05-18 15:35:16--  http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
?
Connecting to 10.240.64.11:3128... connected.
Proxy request sent, awaiting response... 200 OK
Length: 11416 (11K) [application/x-redhat-package-manager]
Saving to: ???zabbix-release-3.0-1.el7.noarch.rpm.1???
?

100%[=======================================================================================================================================>] 11,416      --.-K/s   in 0s

2017-05-18 15:35:16 (193 MB/s) - ???zabbix-release-3.0-1.el7.noarch.rpm.1??? saved [11416/11416]
?

[root at prd-rbs-squid02-poa ~]# wget http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
--2017-05-18 15:35:25--  http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
?
Resolving repo.zabbix.com (repo.zabbix.com)... 162.243.159.138
Connecting to repo.zabbix.com (repo.zabbix.com)|162.243.159.138|:80... connected.
HTTP request sent, awaiting response... 503 Service Unavailable
2017-05-18 15:35:25 ERROR 503: Service Unavailable.
?

[root at prd-rbs-squid02-poa ~]# curl -v http://www.google.com
* About to connect() to www.google.com port 80 (#0)
*   Trying 216.58.222.68...
* Connected to www.google.com (216.58.222.68) port 80 (#0)
> GET / HTTP/1.1
> User-Agent: curl/7.29.0
> Host: www.google.com
> Accept: */*
>
< HTTP/1.1 503 Service Unavailable
< Server: squid/3.5.20
< Mime-Version: 1.0
< Date: Thu, 18 May 2017 18:35:42 GMT
< Content-Type: text/html;charset=utf-8
< Content-Length: 3586
< X-Squid-Error: ERR_CONNECT_FAIL 111
?
< Vary: Accept-Language
< Content-Language: en
< X-Cache: MISS from prd-rbs-squid01-poa.rbs.com.br
< X-Cache-Lookup: MISS from prd-rbs-squid01-poa.rbs.com.br:3128
< Via: 1.1 prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20)
< Connection: keep-alive
?
<
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
<meta type="copyright" content="Copyright (C) 1996-2016 The Squid Software Foundation and contributors">
<meta http-equiv="Content-Type" CONTENT="text/html; charset=utf-8">
?
</head><body id=ERR_CONNECT_FAIL>
?
<div id="titles">
<h1>ERROR</h1>
<h2>The requested URL could not be retrieved</h2>
</div>
<hr>

<div id="content">
<p>The following error was encountered while trying to retrieve the URL: <a href="http://www.google.com/">http://www.google.com/</a></p>

<blockquote id="error">
<p><b>Connection to 10.240.64.11 failed.</b></p>
</blockquote>

<p id="sysmsg">The system returned: <i>(111) Connection refused</i></p>

<p>The remote host or network may be down. Please try the request again.</p>

<p>Your cache administrator is <a href="mailto:root?subject=CacheErrorInfo%20-%20ERR_CONNECT_FAIL&amp;body=CacheHost%3A%20prd-rbs-squid01-poa.rbs.com.br%0D%0AErrPage%3A%20ERR_CONNECT_FAIL%0D%0AErr%3A%20(111)%20Connection%20refused%0D%0ATimeStamp%3A%20Thu,%2018%20May%202017%2018%3A35%3A42%20GMT%0D%0A%0D%0AClientIP%3A%2010.240.64.12%0D%0AServerIP%3A%20www.google.com%0D%0A%0D%0AHTTP%20Request%3A%0D%0AGET%20%2F%20HTTP%2F1.1%0AUser-Agent%3A%20curl%2F7.29.0%0D%0AAccept%3A%20*%2F*%0D%0AHost%3A%20www.google.com%0D%0A%0D%0A%0D%0A">root</a>.</p>
?

<br>
</div>

<hr>
<div id="footer">
<p>Generated Thu, 18 May 2017 18:35:42 GMT by prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20)</p>
<!-- ERR_CONNECT_FAIL -->
</div>
</body></html>
?
* Connection #0 to host www.google.com left intact
[root at prd-rbs-squid02-poa ~]# telnet 10.240.64.11 80
Trying 10.240.64.11...
Connected to 10.240.64.11.
Escape character is '^]'.
www.google.com.br
?
HTTP/1.1 400 Bad Request
Server: squid/3.5.20
Mime-Version: 1.0
Date: Thu, 18 May 2017 18:36:12 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 4083
X-Squid-Error: ERR_INVALID_REQ 0
?
</head><body id=ERR_INVALID_REQ>
?
<div id="titles">
<h1>ERROR</h1>
<h2>The requested URL could not be retrieved</h2>
</div>
<hr>

<div id="content">
<p><b>Invalid Request</b> error was encountered while trying to process the request:</p>

<blockquote id="data">
<pre>www.google.com.br
</pre>
</blockquote>
?

<p>Some possible problems are:</p>
<ul>
<li id="missing-method"><p>Missing or unknown request method.</p></li>
<li id="missing-url"><p>Missing URL.</p></li>
<li id="missing-protocol"><p>Missing HTTP Identifier (HTTP/1.0).</p></li>
<li><p>Request is too large.</p></li>
<li><p>Content-Length missing for POST or PUT requests.</p></li>
?
<li><p>Illegal character in hostname; underscores are not allowed.</p></li>
<li><p>HTTP/1.1 <q>Expect:</q> feature is being asked from an HTTP/1.0 software.</p></li>
</ul>

<p>Your cache administrator is <a href="mailto:root?subject=CacheErrorInfo%20-%20ERR_INVALID_REQ&amp;body=CacheHost%3A%20prd-rbs-squid01-poa.rbs.com.br%0D%0AErrPage%3A%20ERR_INVALID_REQ%0D%0AErr%3A%20%5Bnone%5D%0D%0ATimeStamp%3A%20Thu,%2018%20May%202017%2018%3A36%3A12%20GMT%0D%0A%0D%0AClientIP%3A%2010.240.64.12%0D%0A%0D%0AHTTP%20Request%3A%0D%0A%0D%0A%0D%0A">root</a>.</p>
<br>
</div>

<script language="javascript">
if ('[unknown method]' != '[unknown method]') document.getElementById('missing-method').style.display = 'none';
if ('error:invalid-request' != '[no URL]') document.getElementById('missing-url').style.display = 'none';
if ('[unknown protocol]' != '[unknown protocol]') document.getElementById('missing-protocol').style.display = 'none';
</script>

<hr>
<div id="footer">
<p>Generated Thu, 18 May 2017 18:36:12 GMT by prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20)</p>
<!-- ERR_INVALID_REQ -->
</div>
</body></html>
Connection closed by foreign host.
?
[root at prd-rbs-squid02-poa ~]#


[root at prd-rbs-squid01-poa ~]# tail -f /var/log/squid/access.log



1495132516.589    414 10.240.64.12 TCP_SWAPFAIL_MISS/200 11868 GET http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - HIER_DIRECT/162.243.159.138 application/x-redhat-package-manager
1495132525.592      1 10.240.64.12 TCP_MISS/503 4275 GET http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - ORIGINAL_DST/10.240.64.11 text/html
1495132542.412      4 10.240.64.12 TCP_MISS/503 4037 GET http://www.google.com/ - ORIGINAL_DST/10.240.64.11 text/html
1495132572.097      0 10.240.64.12 TAG_NONE/400 4518 NONE error:invalid-request - HIER_NONE/- text/html
^[[A^[[A^C
[root at prd-rbs-squid01-poa ~]#
[root at prd-rbs-squid01-poa ~]#
[root at prd-rbs-squid01-poa ~]#
[root at prd-rbs-squid01-poa ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 1302 packets, 114K bytes)
?
 pkts bytes target     prot opt in     out     source               destination
    0     0 ACCEPT     tcp  --  *      *       10.240.64.11         0.0.0.0/0            tcp dpt:80
    3   180 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80 to:10.240.64.11:3129

Chain INPUT (policy ACCEPT 300 packets, 26683 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 14 packets, 983 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes)
?
 pkts bytes target     prot opt in     out     source               destination
   14   983 MASQUERADE  all  --  *      *       0.0.0.0/0            0.0.0.0/0
[root at prd-rbs-squid01-poa ~]#

[root at prd-rbs-squid01-poa ~]# curl -v http://www.google.com
?
* About to connect() to www.google.com port 80 (#0)
*   Trying 172.217.30.4...
* Connected to www.google.com (172.217.30.4) port 80 (#0)
?
> GET / HTTP/1.1
> User-Agent: curl/7.29.0
> Host: www.google.com
> Accept: */*
>
< HTTP/1.1 302 Found
< Location: http://www.google.com.br/?gws_rd=cr&ei=wuodWZinJcmZwgTciKb4Bg
?
< Cache-Control: private
< Content-Type: text/html; charset=UTF-8
< P3P: CP="This is not a P3P policy! See https://www.google.com/support/accounts/answer/151657?hl=en for more info."
< Date: Thu, 18 May 2017 18:41:06 GMT
?
< Server: gws
< Content-Length: 262
< X-XSS-Protection: 1; mode=block
< X-Frame-Options: SAMEORIGIN
< Set-Cookie: NID=103=WzsmeICIbXNm_Pvj9tvsdijmqA-NgEXXDYt9Oiso971cJhOyXiM3GEjVwZNUxKs4QorVs9P_07jwWkPk6LhbODbhNPdchdTiTpMXh_ZIFpRKDPERbxD3w46bOVl_CngR; expires=Fri, 17-Nov-2017 18:41:06 GMT; path=/; domain=.google.com; HttpOnly
?
<
<HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
<TITLE>302 Moved</TITLE></HEAD><BODY>
<H1>302 Moved</H1>
The document has moved
<A HREF="http://www.google.com.br/?gws_rd=cr&amp;ei=wuodWZinJcmZwgTciKb4Bg">here</A>.
?


I am missing something on this ... Please help !!!

Thanks.



Rog?rio Ceni Coelho
Engenheiro de Infraestrutura ? Infrastructure Engineer
Diretoria de TI e Telecom - Grupo RBS
Fone: +55 (51) 3218-6983
Celular: +55 (51) 8186-2933 Claro
Celular: +55 (51) 8050-4225 Vivo
rogerio.coelho at gruporbs.com.br
http://www.gruporbs.com.br



Esta mensagem e quaisquer anexos s?o exclusivamente para o uso da parte endere?ada e poder?o conter dados privilegiados e confidenciais. Caso o leitor da mensagem n?o seja a parte a quem ela foi endere?ada, nem um representante autorizado da mesma, ficar? notificado, por meio desta, que qualquer divulga??o desta comunica??o ? estritamente proibida. Se esta comunica??o for recebida erroneamente, por favor, notifique-nos disto imediatamente por e-mail e delete a mensagem  e quaisquer anexos a ela de seu sistema.



-----Mensagem original-----
De: Rogerio Coelho
Enviada em: quarta-feira, 24 de maio de 2017 17:11
Para: 'squid-users at lists.squid-cache.org' <squid-users at lists.squid-cache.org>
Assunto: RES: New Squid Server 3.5.20 on Centos 7 - Trying to redirect local web access to Port 80 on Linux Servers with iptables to Squid Server with http_port intercept

On my new Squid Server running 3.5.20 on Centos 7 a try to use in many different ways.

When i use wget or firefox using http_proxy conf web access go ok. But when i try to access web using iptables redirect from Linux Server i got bad request / Invalid URL.

When i use http_port 3329 intercept mode i got forbbiden.

[root at prd-rbs-squid01-poa ~]# yum install squid -y Loaded plugins: fastestmirror
base                                                                                                                                                      | 3.6 kB  00:00:00
epel/x86_64/metalink                                                                                                                                      |  38 kB  00:00:00
epel                                                                                                                                                      | 4.3 kB  00:00:00
extras                                                                                                                                                    | 3.4 kB  00:00:00
updates                                                                                                                                                   | 3.4 kB  00:00:00
zabbix                                                                                                                                                    |  951 B  00:00:00
zabbix-non-supported                                                                                                                                      |  951 B  00:00:00
(1/2): epel/x86_64/updateinfo                                                                                                                             | 798 kB  00:00:05
(2/2): epel/x86_64/primary_db                                                                                                                             | 4.7 MB  00:00:25
Loading mirror speeds from cached hostfile
 * base: centos.brnet.net.br
 * epel: mirror.globo.com
 * extras: centos.brnet.net.br
 * updates: centos.xpg.com.br
Resolving Dependencies
--> Running transaction check
---> Package squid.x86_64 7:3.5.20-2.el7_3.3 will be installed
--> Finished Dependency Resolution

Dependencies Resolved

=================================================================================================================================================================================
 Package                               Arch                                   Version                                              Repository                               Size
=================================================================================================================================================================================
Installing:
 squid                                 x86_64                                 7:3.5.20-2.el7_3.3                                   updates                                 3.1 M

Transaction Summary
=================================================================================================================================================================================
Install  1 Package

Total download size: 3.1 M
Installed size: 10 M
Downloading packages:
squid-3.5.20-2.el7_3.3.x86_64.rpm                                                                                                                         | 3.1 MB  00:00:02
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : 7:squid-3.5.20-2.el7_3.3.x86_64                                                                                                                               1/1
  Verifying  : 7:squid-3.5.20-2.el7_3.3.x86_64                                                                                                                               1/1

Installed:
  squid.x86_64 7:3.5.20-2.el7_3.3

Complete!
[root at prd-rbs-squid01-poa ~]# systemctl enable squid Created symlink from /etc/systemd/system/multi-user.target.wants/squid.service to /usr/lib/systemd/system/squid.service.
[root at prd-rbs-squid01-poa ~]# systemctl start squid [root at prd-rbs-squid01-poa ~]# cat /var/log/squid/cache.log
2017/05/18 14:59:57 kid1| Set Current Directory to /var/spool/squid
2017/05/18 14:59:57 kid1| Starting Squid Cache version 3.5.20 for x86_64-redhat-linux-gnu...
2017/05/18 14:59:57 kid1| Service Name: squid
2017/05/18 14:59:57 kid1| Process ID 3051
2017/05/18 14:59:57 kid1| Process Roles: worker
2017/05/18 14:59:57 kid1| With 16384 file descriptors available
2017/05/18 14:59:57 kid1| Initializing IP Cache...
2017/05/18 14:59:57 kid1| DNS Socket created at [::], FD 6
2017/05/18 14:59:57 kid1| DNS Socket created at 0.0.0.0, FD 8
2017/05/18 14:59:57 kid1| Adding domain RBS.NET from /etc/resolv.conf
2017/05/18 14:59:57 kid1| Adding domain rbs.com.br from /etc/resolv.conf
2017/05/18 14:59:57 kid1| Adding nameserver 10.236.68.62 from /etc/resolv.conf
2017/05/18 14:59:57 kid1| Adding nameserver 10.1.1.40 from /etc/resolv.conf
2017/05/18 14:59:57 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2017/05/18 14:59:57 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2017/05/18 14:59:57 kid1| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2017/05/18 14:59:57 kid1| Store logging disabled
2017/05/18 14:59:57 kid1| Swap maxSize 0 + 262144 KB, estimated 20164 objects
2017/05/18 14:59:57 kid1| Target number of buckets: 1008
2017/05/18 14:59:57 kid1| Using 8192 Store buckets
2017/05/18 14:59:57 kid1| Max Mem  size: 262144 KB
2017/05/18 14:59:57 kid1| Max Swap size: 0 KB
2017/05/18 14:59:57 kid1| Using Least Load store dir selection
2017/05/18 14:59:57 kid1| Set Current Directory to /var/spool/squid
2017/05/18 14:59:57 kid1| Finished loading MIME types and icons.
2017/05/18 14:59:57 kid1| HTCP Disabled.
2017/05/18 14:59:57 kid1| Squid plugin modules loaded: 0
2017/05/18 14:59:57 kid1| Adaptation support is off.
2017/05/18 14:59:57 kid1| Accepting HTTP Socket connections at local=[::]:3128 remote=[::] FD 11 flags=9
2017/05/18 14:59:58 kid1| storeLateRelease: released 0 objects

Linux Server Client ( Centos 7 ) ( Same Network of Squid Server ) :

[root at prd-rbs-squid02-poa ~]# /mnt/bin/Linux/proxy3520.sh [root at prd-rbs-squid02-poa ~]# iptables -L -n -v -t nat Chain PREROUTING (policy ACCEPT 32 packets, 2146 bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain INPUT (policy ACCEPT 7 packets, 528 bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:443

Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain PROXYSQUID (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
    0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
    0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            to:10.240.64.11:3128

[root at prd-rbs-squid02-poa ~]# wget http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm -e use_proxy=yes -e http_proxy=10.240.64.11:3128
--2017-05-18 15:03:18--  http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
Connecting to 10.240.64.11:3128... connected.
Proxy request sent, awaiting response... 200 OK
Length: 11416 (11K) [application/x-redhat-package-manager]
Saving to: ???zabbix-release-3.0-1.el7.noarch.rpm???

100%[=======================================================================================================================================>] 11,416      --.-K/s   in 0s

2017-05-18 15:03:18 (297 MB/s) - ???zabbix-release-3.0-1.el7.noarch.rpm??? saved [11416/11416]

[root at prd-rbs-squid02-poa ~]# wget http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
--2017-05-18 15:03:27--  http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
Resolving repo.zabbix.com (repo.zabbix.com)... 162.243.159.138 Connecting to repo.zabbix.com (repo.zabbix.com)|162.243.159.138|:80... connected.
HTTP request sent, awaiting response... 400 Bad Request
2017-05-18 15:03:27 ERROR 400: Bad Request.

[root at prd-rbs-squid02-poa ~]# curl -v http://www.google.com
* About to connect() to www.google.com port 80 (#0)
*   Trying 216.58.222.68...
* Connected to www.google.com (216.58.222.68) port 80 (#0)
> GET / HTTP/1.1
> User-Agent: curl/7.29.0
> Host: www.google.com
> Accept: */*
>
< HTTP/1.1 400 Bad Request
< Server: squid/3.5.20
< Mime-Version: 1.0
< Date: Thu, 18 May 2017 18:03:37 GMT
< Content-Type: text/html;charset=utf-8
< Content-Length: 3556
< X-Squid-Error: ERR_INVALID_URL 0
< Vary: Accept-Language
< Content-Language: en
< X-Cache: MISS from prd-rbs-squid01-poa.rbs.com.br < X-Cache-Lookup: NONE from prd-rbs-squid01-poa.rbs.com.br:3128
< Via: 1.1 prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20) < Connection: close < <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
<meta type="copyright" content="Copyright (C) 1996-2016 The Squid Software Foundation and contributors"> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>ERROR: The requested URL could not be retrieved</title> <style type="text/css"><!--
 /*
 * Copyright (C) 1996-2016 The Squid Software Foundation and contributors
 *
 * Squid software is distributed under GPLv2+ license and includes
 * contributions from numerous individuals and organizations.
 * Please see the COPYING and CONTRIBUTORS files for details.
 */

/*
 Stylesheet for Squid Error pages
 Adapted from design by Free CSS Templates  http://www.freecsstemplates.org  Released for free under a Creative Commons Attribution 2.5 License */

/* Page basics */
* {
        font-family: verdana, sans-serif; }

html body {
        margin: 0;
        padding: 0;
        background: #efefef;
        font-size: 12px;
        color: #1e1e1e;
}

/* Page displayed title area */
#titles {
        margin-left: 15px;
        padding: 10px;
        padding-left: 100px;
        background: url('/squid-internal-static/icons/SN.png') no-repeat left; }

/* initial title */
#titles h1 {
        color: #000000;
}
#titles h2 {
        color: #000000;
}

/* special event: FTP success page titles */ #titles ftpsuccess {
        background-color:#00ff00;
        width:100%;
}

/* Page displayed body content area */
#content {
        padding: 10px;
        background: #ffffff;
}

/* General text */
p {
}

/* error brief description */
#error p {
}

/* some data which may have caused the problem */ #data { }

/* the error message received from the system or other software */ #sysmsg { }

pre {
    font-family:sans-serif;
}

/* special event: FTP / Gopher directory listing */ #dirmsg {
    font-family: courier;
    color: black;
    font-size: 10pt;
}
#dirlisting {
    margin-left: 2%;
    margin-right: 2%;
}
#dirlisting tr.entry td.icon,td.filename,td.size,td.date {
    border-bottom: groove;
}
#dirlisting td.size {
    width: 50px;
    text-align: right;
    padding-right: 5px;
}

/* horizontal lines */
hr {
        margin: 0;
}

/* page displayed footer area */
#footer {
        font-size: 9px;
        padding-left: 10px;
}


body
:lang(fa) { direction: rtl; font-size: 100%; font-family: Tahoma, Roya, sans-serif; float: right; }
:lang(he) { direction: rtl; }
 --></style>
</head><body id=ERR_INVALID_URL>
<div id="titles">
<h1>ERROR</h1>
<h2>The requested URL could not be retrieved</h2> </div> <hr>

<div id="content">
<p>The following error was encountered while trying to retrieve the URL: <a href="/">/</a></p>

<blockquote id="error">
<p><b>Invalid URL</b></p>
</blockquote>

<p>Some aspect of the requested URL is incorrect.</p>

<p>Some possible problems are:</p>
<ul>
<li><p>Missing or incorrect access protocol (should be <q>http://</q> or similar)</p></li> <li><p>Missing hostname</p></li> <li><p>Illegal double-escape in the URL-Path</p></li> <li><p>Illegal character in hostname; underscores are not allowed.</p></li> </ul>

<p>Your cache administrator is <a href="mailto:root?subject=CacheErrorInfo%20-%20ERR_INVALID_URL&amp;body=CacheHost%3A%20prd-rbs-squid01-poa.rbs.com.br%0D%0AErrPage%3A%20ERR_INVALID_URL%0D%0AErr%3A%20%5Bnone%5D%0D%0ATimeStamp%3A%20Thu,%2018%20May%202017%2018%3A03%3A37%20GMT%0D%0A%0D%0AClientIP%3A%2010.240.64.12%0D%0A%0D%0AHTTP%20Request%3A%0D%0A%0D%0A%0D%0A">root</a>.</p>
<br>
</div>

<hr>
<div id="footer">
<p>Generated Thu, 18 May 2017 18:03:37 GMT by prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20)</p>
<!-- ERR_INVALID_URL -->
</div>
</body></html>
* Closing connection 0
[root at prd-rbs-squid02-poa ~]#

[root at prd-rbs-squid01-poa ~]# tail -f /var/log/squid/access.log



1495130446.581    439 10.240.64.12 TCP_MISS/200 11869 GET http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - HIER_DIRECT/162.243.159.138 application/x-redhat-package-manager
1495130598.008      0 10.240.64.12 TCP_MEM_HIT/200 11877 GET http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - HIER_NONE/- application/x-redhat-package-manager
1495130607.437      0 10.240.64.12 TAG_NONE/400 4111 GET /zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - HIER_NONE/- text/html
1495130617.581      0 10.240.64.12 TAG_NONE/400 3991 GET / - HIER_NONE/- text/html

I will send more on reply to this email because of the size of this email.

Rog?rio Ceni Coelho
Engenheiro de Infraestrutura ? Infrastructure Engineer Diretoria de TI e Telecom - Grupo RBS
Fone: +55 (51) 3218-6983
Celular: +55 (51) 8186-2933 Claro
Celular: +55 (51) 8050-4225 Vivo
rogerio.coelho at gruporbs.com.br
http://www.gruporbs.com.br



Esta mensagem e quaisquer anexos s?o exclusivamente para o uso da parte endere?ada e poder?o conter dados privilegiados e confidenciais. Caso o leitor da mensagem n?o seja a parte a quem ela foi endere?ada, nem um representante autorizado da mesma, ficar? notificado, por meio desta, que qualquer divulga??o desta comunica??o ? estritamente proibida. Se esta comunica??o for recebida erroneamente, por favor, notifique-nos disto imediatamente por e-mail e delete a mensagem  e quaisquer anexos a ela de seu sistema.



-----Mensagem original-----
De: Rogerio Coelho
Enviada em: quarta-feira, 24 de maio de 2017 17:03
Para: squid-users at lists.squid-cache.org
Assunto: New Squid Server 3.5.20 on Centos 7 - Trying to redirect local web access to Port 80 on Linux Servers with iptables to Squid Server with http_port intercept

Hi Squid Jedi?s,

I am just a little stuck tryng to replace an old Squid 3.1.23 Server on Centos 6 that i use to redirect local web access to port 80 on linux servers to Squid Server.

On my Squid 3.1.23 Server on Centos 6 i use http_port 3128 transparent mode and on my Linux servers clients i use iptables to redirect Web traffic as below ( this config works ):

Squid Server 3.1.23 :

[root at leli squid]# cat squid.conf | egrep -v "^#|^$"
acl default_ip req_header x-forward -i "/ipt/SQUID/default/ip"
acl default_url dstdom_regex -i "/ipt/SQUID/default/url"
acl default_ip2 srcdom_regex -i "/ipt/SQUID/default/ip"
http_access allow default_ip default_url acl endereco  req_header x-forward -i "/ipt/SQUID/libera/ip"
http_access allow endereco
acl all_ip req_header x-forward -i "/ipt/SQUID/all/ip"
acl all_url dstdom_regex -i "/ipt/SQUID/all/url"
acl all_ip2 srcdom_regex -i "/ipt/SQUID/all/ip"
http_access allow all_url
acl all src all
acl manager proto cache_object
acl from_localhost src 127.0.0.1/255.255.255.255 acl to_localhost dst 127.0.0.0/8 acl SSL_ports port 443
acl GIT_PORT port 9418         # git
acl CONNECT method CONNECT
acl Safe_ports port 80
acl Safe_ports port 443
acl Safe_ports port 21 # ftp
acl GIT_PORT2 port 9418 # git
http_access allow manager from_localhost http_access deny manager http_access allow GIT_PORT2 http_access deny !Safe_ports http_access allow CONNECT GIT_PORT http_access deny CONNECT !SSL_ports http_access deny to_localhost http_access allow from_localhost http_access deny all http_port 3128 transparent https_port 3129 transparent intercept cert=/ipt/SQUID/https/squid.crt key=/ipt/SQUID/https/squid.key hierarchy_stoplist cgi-bin ?
emulate_httpd_log on
logformat squid %tg %6tr %>a %{x-forward}>h %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt access_log /var/log/squid/access.log squid access_log syslog:local0.info  squid cache_log /var/log/squid/cache.log cache_store_log /var/log/squid/store.log mime_table /etc/squid/mime.conf pid_filename /var/run/squid.pid acl QUERY urlpath_regex .* cache deny QUERY acl apache rep_header Server ^Apache acl FS_TESTE srcdom_regex -i "/ipt/SQUID/puppet/ip2"
cache_mgr tecnologiaseguranca at gruporbs.com.br
cache_effective_user squid
cache_effective_group squid
coredump_dir /var/spool/squid
maximum_object_size 0 KB
minimum_object_size 0 KB
no_cache deny all
deny_info 172.20.63.73 webapp_ip

[root at leli ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 46M packets, 3068M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 4581K packets, 276M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 4581K packets, 276M bytes)
 pkts bytes target     prot opt in     out     source               destination
[root at leli ~]#

Linux Server Clients ( Centos 5, 6 e 7 ) :

[root at montana rules]# cat proxy2.sh
#!/bin/bash

IPTBIN=$(which iptables)

$IPTBIN -t nat -F
$IPTBIN -t nat -X

#SQUID
$IPTBIN -A OUTPUT -s 10.240.68.68 -p tcp --sport 3128 -j ACCEPT

#PROXY
$IPTBIN -t nat -N PROXYSQUID
$IPTBIN -t nat -A OUTPUT -p tcp --dport 80 -j PROXYSQUID $IPTBIN -t nat -A OUTPUT -p tcp --dport 443 -j PROXYSQUID $IPTBIN -t nat -A PROXYSQUID -d 192.168.0.0/16 -j RETURN $IPTBIN -t nat -A PROXYSQUID -d 189.76.144.0/20 -j RETURN $IPTBIN -t nat -A PROXYSQUID -d 189.76.156.190 -j RETURN $IPTBIN -t nat -A PROXYSQUID -d 172.16.0.0/12 -j RETURN $IPTBIN -t nat -A PROXYSQUID -d 10.0.0.0/8 -j RETURN $IPTBIN -t nat -A PROXYSQUID -p tcp -j DNAT --to-destination=10.240.68.68:3128


[root at montana rules]# iptables -L -n -v -t nat Chain PREROUTING (policy ACCEPT 58M packets, 4835M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 2487K packets, 184M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 2487K packets, 184M bytes)
 pkts bytes target     prot opt in     out     source               destination
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           tcp dpt:80
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           tcp dpt:443

Chain PROXYSQUID (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
    0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
    0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           to:10.240.68.68:3128
[root at montana rules]# curl -v www.google.com
* About to connect() to www.google.com port 80
*   Trying 216.58.222.68... * connected
* Connected to www.google.com (216.58.222.68) port 80
> GET / HTTP/1.1
User-Agent: curl/7.12.1 (i686-redhat-linux-gnu) libcurl/7.12.1 OpenSSL/0.9.7a zlib/1.2.1.2 libidn/0.5.6
Host: www.google.com
Pragma: no-cache
Accept: */*

< HTTP/1.0 302 Moved Temporarily
< Location: http://www.google.com.br/?gws_rd=cr&ei=FtwdWdaDMYm0wQSWwZ24Ag
< Cache-Control: private
< Content-Type: text/html; charset=UTF-8 < P3P: CP="This is not a P3P policy! See https://www.google.com/support/accounts/answer/151657?hl=en for more info."
< Date: Thu, 18 May 2017 17:38:30 GMT
< Server: gws
< Content-Length: 262
< X-XSS-Protection: 1; mode=block
< X-Frame-Options: SAMEORIGIN
< Set-Cookie: NID=103=Vdks002SayhLjRhSWr_ETgZR2-0Hngh7ci-McE8fBhw6vDhAENt6JxWkTKtPKWen7HL-KYjiSNg9lwXnjSCejhv1va4yIUhPpMDYZ-mK4uDb9FQldR1zp3Y1RiOwx4jX; expires=Fri, 17-Nov-2017 17:38:30 GMT; path=/; domain=.google.com; HttpOnly < X-Cache: MISS from leli.rbs.com.br < X-Cache-Lookup: MISS from leli.rbs.com.br:3128 < Via: 1.0 leli.rbs.com.br (squid/3.1.23)
* HTTP/1.0 connection set to keep alive!
< Connection: keep-alive
<HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
<TITLE>302 Moved</TITLE></HEAD><BODY>
<H1>302 Moved</H1>
The document has moved
<A HREF="http://www.google.com.br/?gws_rd=cr&amp;ei=FtwdWdaDMYm0wQSWwZ24Ag">here</A>.
</BODY></HTML>
* Connection #0 to host www.google.com left intact
* Closing connection #0
[root at montana rules]# iptables -L -n -v -t nat Chain PREROUTING (policy ACCEPT 58M packets, 4835M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 2487K packets, 184M bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 2487K packets, 184M bytes)
 pkts bytes target     prot opt in     out     source               destination
    1    60 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           tcp dpt:80
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           tcp dpt:443

Chain PROXYSQUID (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
    0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
    0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
    1    60 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0           to:10.240.68.68:3128
[root at montana rules]#

On my new Squid Server running 3.5.20 on Centos 7 a try to use in many different ways but have no success.

I will send my steps on a new reply email in few minutes because the email size.

Sorry about all this log of information.



Rog?rio Ceni Coelho
Engenheiro de Infraestrutura ? Infrastructure Engineer Diretoria de TI e Telecom - Grupo RBS
Fone: +55 (51) 3218-6983
Celular: +55 (51) 8186-2933 Claro
Celular: +55 (51) 8050-4225 Vivo
rogerio.coelho at gruporbs.com.br
http://www.gruporbs.com.br



Esta mensagem e quaisquer anexos s?o exclusivamente para o uso da parte endere?ada e poder?o conter dados privilegiados e confidenciais. Caso o leitor da mensagem n?o seja a parte a quem ela foi endere?ada, nem um representante autorizado da mesma, ficar? notificado, por meio desta, que qualquer divulga??o desta comunica??o ? estritamente proibida. Se esta comunica??o for recebida erroneamente, por favor, notifique-nos disto imediatamente por e-mail e delete a mensagem  e quaisquer anexos a ela de seu sistema.



O Grupo RBS pauta sua atua??o por seu C?digo de ?tica e Conduta, em conformidade com a Legisla??o Brasileira. Qualquer situa??o irregular deve ser informada via Canal de ?tica pelo site https://www.contatoseguro.com.br/gruporbs ou 0800 602 1831. Este e-mail e seus anexos podem conter informa??es confidenciais. Se voc? recebeu esta mensagem por engano, por favor apague-a e notifique o remetente imediatamente.

From harariboy at gmail.com  Wed May 24 20:16:39 2017
From: harariboy at gmail.com (avi_h)
Date: Wed, 24 May 2017 13:16:39 -0700 (PDT)
Subject: [squid-users] External ACL
In-Reply-To: <1495641649465-4682544.post@n4.nabble.com>
References: <1495502728560-4682519.post@n4.nabble.com>
 <046c5862-9f83-911e-0e0f-aa3d52db6a34@treenet.co.nz>
 <1495544529394-4682527.post@n4.nabble.com>
 <bb991bc6-d898-7fd6-f525-084affa93716@treenet.co.nz>
 <1495641649465-4682544.post@n4.nabble.com>
Message-ID: <1495656999263-4682555.post@n4.nabble.com>

So I managed to create the SQL table after reviewing the script.
When testing the script outside of squid I get an OK reply.
When I tested with squid I got the same error message as before (queue
overload).
After some more investigating I managed to resolve that.
What solved it was adding ipv4 to the external_acl_type line.
I was then able to run my own scripts as well.
But now I'm getting the following error:

2017/05/24 20:28:57.084 kid1| 82,2| external_acl.cc(786) aclMatchExternal:
ip_checker("192.168.1.1") = lookup needed
2017/05/24 20:28:57.084 kid1| 82,2| external_acl.cc(789) aclMatchExternal:
"192.168.1.1": queueing a call.
2017/05/24 20:28:57.084 kid1| 28,2| Checklist.cc(129) goAsync: 0x2af3658 a
slow ACL resumes by going async again! (loop #0)
2017/05/24 20:28:57.084 kid1| 82,2| external_acl.cc(1416) Start: fg lookup
in 'ip_checker' for '192.168.1.1'
2017/05/24 20:28:57.084 kid1| 82,2| external_acl.cc(792) aclMatchExternal:
"192.168.1.1": return -1.

Any ideas?

Thanks,
Avi




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/External-ACL-tp4682519p4682555.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed May 24 20:53:06 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 May 2017 08:53:06 +1200
Subject: [squid-users] External ACL
In-Reply-To: <1495656999263-4682555.post@n4.nabble.com>
References: <1495502728560-4682519.post@n4.nabble.com>
 <046c5862-9f83-911e-0e0f-aa3d52db6a34@treenet.co.nz>
 <1495544529394-4682527.post@n4.nabble.com>
 <bb991bc6-d898-7fd6-f525-084affa93716@treenet.co.nz>
 <1495641649465-4682544.post@n4.nabble.com>
 <1495656999263-4682555.post@n4.nabble.com>
Message-ID: <f6666fd7-a855-9304-d5c8-1c68c6d2329f@treenet.co.nz>

On 25/05/17 08:16, avi_h wrote:
> So I managed to create the SQL table after reviewing the script.
> When testing the script outside of squid I get an OK reply.
> When I tested with squid I got the same error message as before (queue
> overload).
> After some more investigating I managed to resolve that.
> What solved it was adding ipv4 to the external_acl_type line.

Ah, darnit. I forgot about that one. Been years since anyone had a 
broken localhost interface.

> I was then able to run my own scripts as well.
> But now I'm getting the following error:
>
> 2017/05/24 20:28:57.084 kid1| 82,2| external_acl.cc(786) aclMatchExternal:
> ip_checker("192.168.1.1") = lookup needed
> 2017/05/24 20:28:57.084 kid1| 82,2| external_acl.cc(789) aclMatchExternal:
> "192.168.1.1": queueing a call.
> 2017/05/24 20:28:57.084 kid1| 28,2| Checklist.cc(129) goAsync: 0x2af3658 a
> slow ACL resumes by going async again! (loop #0)
> 2017/05/24 20:28:57.084 kid1| 82,2| external_acl.cc(1416) Start: fg lookup
> in 'ip_checker' for '192.168.1.1'
> 2017/05/24 20:28:57.084 kid1| 82,2| external_acl.cc(792) aclMatchExternal:
> "192.168.1.1": return -1.
>
> Any ideas?

Its not an error, just debug info stating what is happening. Multiple 
loops are a bit surprising but can happen.

If you have two async ACLs on the one http_access line it is normal. Or 
if you are trying to pass %LOGIN to the external ACL helper without 
first having authenticated it is normal. There may be other cases I'm 
not familiar with too.

Amos



From acctforjunk at yahoo.com  Wed May 24 21:01:53 2017
From: acctforjunk at yahoo.com (j m)
Date: Wed, 24 May 2017 21:01:53 +0000 (UTC)
Subject: [squid-users] SSL bump, SSL intercept, explicit, secure proxy,
 what is it called?
In-Reply-To: <41b65b4b-5603-ef56-5c5a-7bf68d8b0cd0@treenet.co.nz>
References: <1140034948.954341.1495590259601.ref@mail.yahoo.com>
 <1140034948.954341.1495590259601@mail.yahoo.com>
 <41b65b4b-5603-ef56-5c5a-7bf68d8b0cd0@treenet.co.nz>
Message-ID: <678419562.1792246.1495659713195@mail.yahoo.com>

Some more info: ?I tried this on Firefox 53 and got more feedback, but still doesn't work. ?Per the recommendation on bugzilla (bug 378637), I put https://myaddress:myport?into firefox and it gives me a "Your connection is not secure". ?So I add the exception, and it then displays the squid message "ERROR The requested URL could not be retrieved", as expected.
So I add the proxy to Firefox (in Advanced, Network, Settings) as the HTTP Proxy....doesn't work, "The proxy server is refusing connections". ?I then put https:// in front of the address, then it's "Server not found". ?I then add it as SSL Proxy. ?It appears to be working, but really it's simply not using the proxy at all because I stopped squid and it made no difference.
The link you reference on getting Firefox to work with this refers to Firefox 33, so by now I'd think I could directly add the proxy to the normal place in Firefox options?
squid.conf:
auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/passwdauth_param basic children 5auth_param basic realm Squid proxy-caching web serverauth_param basic credentialsttl 2 hoursauth_param basic casesensitive offacl ncsa_users proxy_auth REQUIREDhttp_access allow ncsa_users
acl auth_users proxy_auth REQUIREDacl SSL_ports port 443
acl Safe_ports port 80 ? ? ? ?# httpacl Safe_ports port 21 ? ? ? ?# ftpacl Safe_ports port 443 ? ? ? ?# httpsacl Safe_ports port 70 ? ? ? ?# gopheracl Safe_ports port 210 ? ? ? ?# waisacl Safe_ports port 1025-65535 ? ?# unregistered portsacl Safe_ports port 280 ? ? ? ?# http-mgmtacl Safe_ports port 488 ? ? ? ?# gss-httpacl Safe_ports port 591 ? ? ? ?# filemakeracl Safe_ports port 777 ? ? ? ?# multiling httpacl CONNECT method CONNECThttp_access deny !Safe_portshttp_access deny CONNECT !SSL_portshttp_access allow auth_usershttp_access allow all#http_port 8092https_port 8092 cert=/etc/squid/squid.pemcache deny allaccess_log nonenetdb_filename none

      From: Amos Jeffries <squid3 at treenet.co.nz>
 To: squid-users at lists.squid-cache.org 
 Sent: Wednesday, May 24, 2017 7:57 AM
 Subject: Re: [squid-users] SSL bump, SSL intercept, explicit, secure proxy, what is it called?
   
On 24/05/17 13:44, j m wrote:
> I'd like to set up a proxy on a home server so I can use it remotely 
> for web browsing; no filtering, nothing fancy, just a pass-through of 
> sorts to get around web filters.? That part I've got working.? The 
> part I haven't had luck with is encrypting the browser-to-proxy 
> connection.? I've found some tutorials online but part of the problem 
> is I don't know what this feature is called when searching for 
> solutions to problems.
>
> I have squid 3.5.23 on Ubuntu compiled with
>
> '--with-openssl' '--enable-ssl' '--enable-ssl-crtd'
>
> so I believe I'm set there.? However, upon finally getting a 
> squid.conf that doesn't cause immediate errors when squid is started, 
> I find that the squid process is gone after several seconds and find 
> lots of these in syslog:
>
> (squid-1): The ssl_crtd helpers are crashing too rapidly, need help!
>
> I found a suggestion to fix this problem, but it didn't help:
>
> rc-service squid stop
> rm -rf /var/lib/ssl_db
> /usr/lib/squid3/ssl_crtd -c -s /var/lib/ssl_db
> rc-service squid start
>
>
> So firstly, what is the actual name for what I want (encrypting proxy 
> to browser)?
>


Some people seem to be calling it "HTTPS", but that is not correct and 
thankfully makes it difficult to find the bad info. (that said our own 
wiki documents it on the HTTPS page referenced below :-P ).

The current IETF term for it is "TLS explicit proxy". Previously it did 
not have a formal term and often got described in words like "TLS proxy" 
or sometimes "TLS to the proxy" and variants switching "SSL" for "TLS". 
It also has some relation to early forms of "HTTP opportunistic 
security" - though that now means an HTTP version of emails STARTTLS 
that is quite unrelated to anything Squid supports at present.



> And secondly, any advice on the error?? Or even better, a good 
> tutorial on setting this up?? I thought if I follow a configuration 
> exactly, I'd be off and running with little problem.
>
>

The ssl_crtd helper in not related to TLS explicit proxy. It is a part 
of SSL-Bump features for intercepting HTTPS traffic, specifically it is 
the part that forges certificates.

You could avoid it entirely by removing the --enable-ssl-crtd build 
option if you don't need SSL-Bump features later. Otherwise check the 
directory creation and ownership permissions are correct and that Squid 
http_port is *not* setup to use ssl-bump features (yet).


The TLS explicit proxy is simply a Squid that uses https_port to receive 
proxy traffic, as opposed to http_port. You will need a server 
certificate for that, but nothing else special on Squid's side of 
things. eg:
? https_port 3128 cert=blah_public.pem key=blah_private.key

The tricky part is getting a browser to talk TLS to anything other than 
origin servers.? The details we know of are all at 
<http://wiki.squid-cache.org/Features/HTTPS#Encrypted_browser-Squid_connection>.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170524/41ba65d5/attachment.htm>

From squid3 at treenet.co.nz  Wed May 24 21:12:58 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 May 2017 09:12:58 +1200
Subject: [squid-users] RES: New Squid Server 3.5.20 on Centos 7 - Trying
 to redirect local web access to Port 80 on Linux Servers with iptables to
 Squid Server with http_port intercept
In-Reply-To: <SC1PR80MB194956E6A7A30F4ECFD508A6D0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>
References: <SC1PR80MB194956E6A7A30F4ECFD508A6D0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>
Message-ID: <bc898354-655d-179a-ed02-b048b9e14706@treenet.co.nz>

On 25/05/17 08:12, Rogerio Coelho wrote:
> On my new Squid Server running 3.5.20 on Centos 7 a try to use in many different ways.
>
> When i use wget or firefox using http_proxy conf web access go ok. But when i try to access web using iptables redirect from Linux Server i got bad request / Invalid URL.

You omitted the squid.conf dump on this post so I cannot be sure but  
that is the behaviour which happens when use a forward/explicit proxy 
port (eg 3128) to receive intercepted port-80 traffic.

You need separate http_port lines for receiving these two quite 
different types of HTTP traffic.


Amos



From squid3 at treenet.co.nz  Wed May 24 21:15:11 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 May 2017 09:15:11 +1200
Subject: [squid-users] New Squid Server 3.5.20 on Centos 7 - Trying to
 redirect local web access to Port 80 on Linux Servers with iptables to
 Squid Server with http_port intercept
In-Reply-To: <SC1PR80MB194973E5AE33EB788BFB08C5D0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>
References: <SC1PR80MB194973E5AE33EB788BFB08C5D0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>
Message-ID: <b88f571f-41ec-7f1b-69c1-039349716d9a@treenet.co.nz>

On 25/05/17 08:02, Rogerio Coelho wrote:
> Hi Squid Jedi?s,
>
> I am just a little stuck tryng to replace an old Squid 3.1.23 Server on Centos 6 that i use to redirect local web access to port 80 on linux servers to Squid Server.
>
> On my Squid 3.1.23 Server on Centos 6 i use http_port 3128 transparent mode and on my Linux servers clients i use iptables to redirect Web traffic as below ( this config works ):

FYI: if your other posts are additional info on this problem could you 
please send as a reply to the earlier message (ie this one). It helps 
those of us tracking lots of issues and the mailing list<->forum portal 
software when the relevant posts are threaded.

Anyhow, I am replying directly to your other posts.

Amos




From rogerio.coelho at gruporbs.com.br  Wed May 24 21:24:28 2017
From: rogerio.coelho at gruporbs.com.br (Rogerio Coelho)
Date: Wed, 24 May 2017 21:24:28 +0000
Subject: [squid-users] RES: RES: New Squid Server 3.5.20 on Centos 7 -
 Trying to redirect local web access to Port 80 on Linux Servers with
 iptables to Squid Server with http_port intercept
In-Reply-To: <bc898354-655d-179a-ed02-b048b9e14706@treenet.co.nz>
References: <SC1PR80MB194956E6A7A30F4ECFD508A6D0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>
 <bc898354-655d-179a-ed02-b048b9e14706@treenet.co.nz>
Message-ID: <SC1PR80MB194971ECE4FD3FECCCCADA5BD0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>

Hi Amos,

I do not know if i send with success the third email with this info. I will try again.

Using intercept mode with 3129 port :

[root at prd-rbs-squid01-poa squid]# cat /etc/squid/squid.conf | egrep -v "^#|^$"
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
acl SSL_ports port 443
acl Safe_ports port 80          # http
?
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localnet
http_access allow localhost
http_port 3128
http_port 3129 intercept
cache_dir ufs /var/spool/squid 100 16 256
coredump_dir /var/spool/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
[root at prd-rbs-squid01-poa squid]#

[root at prd-rbs-squid01-poa ~]# systemctl restart squid
[root at prd-rbs-squid01-poa squid]# systemctl start squid
[root at prd-rbs-squid01-poa squid]# cat cache.log
2017/05/18 15:22:29 kid1| Set Current Directory to /var/spool/squid
2017/05/18 15:22:29 kid1| Starting Squid Cache version 3.5.20 for x86_64-redhat-linux-gnu...
2017/05/18 15:22:29 kid1| Service Name: squid
2017/05/18 15:22:29 kid1| Process ID 6592
2017/05/18 15:22:29 kid1| Process Roles: worker
2017/05/18 15:22:29 kid1| With 16384 file descriptors available
2017/05/18 15:22:29 kid1| Initializing IP Cache...
2017/05/18 15:22:29 kid1| DNS Socket created at [::], FD 6
2017/05/18 15:22:29 kid1| DNS Socket created at 0.0.0.0, FD 8
2017/05/18 15:22:29 kid1| Adding domain RBS.NET from /etc/resolv.conf
2017/05/18 15:22:29 kid1| Adding domain rbs.com.br from /etc/resolv.conf
2017/05/18 15:22:29 kid1| Adding nameserver 10.236.68.62 from /etc/resolv.conf
2017/05/18 15:22:29 kid1| Adding nameserver 10.1.1.40 from /etc/resolv.conf
2017/05/18 15:22:29 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2017/05/18 15:22:29 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2017/05/18 15:22:29 kid1| Unlinkd pipe opened on FD 14
2017/05/18 15:22:29 kid1| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2017/05/18 15:22:29 kid1| Store logging disabled
2017/05/18 15:22:29 kid1| Swap maxSize 102400 + 262144 KB, estimated 28041 objects
2017/05/18 15:22:29 kid1| Target number of buckets: 1402
2017/05/18 15:22:29 kid1| Using 8192 Store buckets
2017/05/18 15:22:29 kid1| Max Mem  size: 262144 KB
2017/05/18 15:22:29 kid1| Max Swap size: 102400 KB
2017/05/18 15:22:29 kid1| Rebuilding storage in /var/spool/squid (dirty log)
2017/05/18 15:22:29 kid1| Using Least Load store dir selection
2017/05/18 15:22:29 kid1| Set Current Directory to /var/spool/squid
2017/05/18 15:22:29 kid1| Finished loading MIME types and icons.
2017/05/18 15:22:29 kid1| HTCP Disabled.
2017/05/18 15:22:29 kid1| Squid plugin modules loaded: 0
2017/05/18 15:22:29 kid1| Adaptation support is off.
2017/05/18 15:22:29 kid1| Accepting HTTP Socket connections at local=[::]:3128 remote=[::] FD 17 flags=9
2017/05/18 15:22:29 kid1| Accepting NAT intercepted HTTP Socket connections at local=[::]:3129 remote=[::] FD 18 flags=41
2017/05/18 15:22:29 kid1| Done reading /var/spool/squid swaplog (3 entries)
2017/05/18 15:22:29 kid1| Finished rebuilding storage from disk.
2017/05/18 15:22:29 kid1|         2 Entries scanned
2017/05/18 15:22:29 kid1|         0 Invalid entries.
2017/05/18 15:22:29 kid1|         0 With invalid flags.
2017/05/18 15:22:29 kid1|         1 Objects loaded.
2017/05/18 15:22:29 kid1|         0 Objects expired.
2017/05/18 15:22:29 kid1|         0 Objects cancelled.
2017/05/18 15:22:29 kid1|         0 Duplicate URLs purged.
2017/05/18 15:22:29 kid1|         1 Swapfile clashes avoided.
2017/05/18 15:22:29 kid1|   Took 0.01 seconds ( 91.36 objects/sec).
2017/05/18 15:22:29 kid1| Beginning Validation Procedure
2017/05/18 15:22:29 kid1|   Completed Validation Procedure
2017/05/18 15:22:29 kid1|   Validated 1 Entries
2017/05/18 15:22:29 kid1|   store_swap_size = 12.00 KB
2017/05/18 15:22:30 kid1| storeLateRelease: released 0 objects

[root at prd-rbs-squid01-poa squid]# netstat -nap | grep -i squid
tcp6       0      0 :::3128                 :::*                    LISTEN      6592/(squid-1)
tcp6       0      0 :::3129                 :::*                    LISTEN      6592/(squid-1)
udp        0      0 0.0.0.0:50868           0.0.0.0:*                           6592/(squid-1)
udp6       0      0 :::55754                :::*                                6592/(squid-1)
unix  3      [ ]         STREAM     CONNECTED     73819    6592/(squid-1)
unix  2      [ ]         DGRAM                    72824    6590/squid
[root at prd-rbs-squid01-poa squid]#

[root at prd-rbs-squid02-poa ~]# /mnt/bin/Linux/proxy3520_3129.sh
?
[root at prd-rbs-squid02-poa ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 27 packets, 1754 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain INPUT (policy ACCEPT 4 packets, 240 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 1 packets, 76 bytes)
?
 pkts bytes target     prot opt in     out     source               destination
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:443

Chain POSTROUTING (policy ACCEPT 1 packets, 76 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain PROXYSQUID (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
    0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
    0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            to:10.240.64.11:3129
[root at prd-rbs-squid02-poa ~]# rm zabbix-release-3.0-1.el7.noarch.rpm*
rm: remove regular file ???zabbix-release-3.0-1.el7.noarch.rpm???? y
rm: remove regular file ???zabbix-release-3.0-1.el7.noarch.rpm.1???? y
rm: remove regular file ???zabbix-release-3.0-1.el7.noarch.rpm.2???? y
rm: remove regular file ???zabbix-release-3.0-1.el7.noarch.rpm.3???? y
?
[root at prd-rbs-squid02-poa ~]# wget http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm -e use_proxy=yes -e http_proxy=10.240.64.11:3128
--2017-05-18 15:23:57--  http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
?
Connecting to 10.240.64.11:3128... connected.
Proxy request sent, awaiting response... 200 OK
Length: 11416 (11K) [application/x-redhat-package-manager]
Saving to: ???zabbix-release-3.0-1.el7.noarch.rpm???

100%[=======================================================================================================================================>] 11,416      --.-K/s   in 0s

2017-05-18 15:23:58 (194 MB/s) - ???zabbix-release-3.0-1.el7.noarch.rpm??? saved [11416/11416]
?

[root at prd-rbs-squid02-poa ~]# wget http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
--2017-05-18 15:24:16--  http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
?
Resolving repo.zabbix.com (repo.zabbix.com)... 162.243.159.138
Connecting to repo.zabbix.com (repo.zabbix.com)|162.243.159.138|:80... connected.
HTTP request sent, awaiting response... 403 Forbidden
2017-05-18 15:24:16 ERROR 403: Forbidden.
?

[root at prd-rbs-squid02-poa ~]# curl -v http://www.google.com
* About to connect() to www.google.com port 80 (#0)
*   Trying 216.58.222.68...
* Connected to www.google.com (216.58.222.68) port 80 (#0)
> GET / HTTP/1.1
> User-Agent: curl/7.29.0
> Host: www.google.com
> Accept: */*
>
< HTTP/1.1 403 Forbidden
< Server: squid/3.5.20
< Mime-Version: 1.0
< Date: Thu, 18 May 2017 18:24:23 GMT
< Content-Type: text/html;charset=utf-8
< Content-Length: 3707
< X-Squid-Error: ERR_ACCESS_DENIED 0
?
< Vary: Accept-Language
< Content-Language: en
< X-Cache: MISS from prd-rbs-squid01-poa.rbs.com.br
< X-Cache-Lookup: MISS from prd-rbs-squid01-poa.rbs.com.br:3128
< X-Cache: MISS from prd-rbs-squid01-poa.rbs.com.br
< X-Cache-Lookup: MISS from prd-rbs-squid01-poa.rbs.com.br:3128
< Via: 1.1 prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20), 1.1 prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20)
< Connection: keep-alive
?
</head><body id=ERR_ACCESS_DENIED>
?
<div id="titles">
<h1>ERROR</h1>
<h2>The requested URL could not be retrieved</h2>
</div>
<hr>

<div id="content">
<p>The following error was encountered while trying to retrieve the URL: <a href="http://www.google.com/">http://www.google.com/</a></p>

<blockquote id="error">
<p><b>Access Denied.</b></p>
</blockquote>

<p>Access control configuration prevents your request from being allowed at this time. Please contact your service provider if you feel this is incorrect.</p>

<p>Your cache administrator is <a href="mailto:root?subject=CacheErrorInfo%20-%20ERR_ACCESS_DENIED&amp;body=CacheHost%3A%20prd-rbs-squid01-poa.rbs.com.br%0D%0AErrPage%3A%20ERR_ACCESS_DENIED%0D%0AErr%3A%20%5Bnone%5D%0D%0ATimeStamp%3A%20Thu,%2018%20May%202017%2018%3A24%3A23%20GMT%0D%0A%0D%0AClientIP%3A%2010.240.64.11%0D%0A%0D%0AHTTP%20Request%3A%0D%0AGET%20%2F%20HTTP%2F1.1%0AUser-Agent%3A%20curl%2F7.29.0%0D%0AAccept%3A%20*%2F*%0D%0AVia%3A%201.1%20prd-rbs-squid01-poa.rbs.com.br%20(squid%2F3.5.20)%0D%0AX-Forwarded-For%3A%2010.240.64.12%0D%0ACache-Control%3A%20max-age%3D259200%0D%0AConnection%3A%20keep-alive%0D%0AHost%3A%20www.google.com%0D%0A%0D%0A%0D%0A">root</a>.</p>
?
<br>
</div>

<hr>
<div id="footer">
<p>Generated Thu, 18 May 2017 18:24:23 GMT by prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20)</p>
<!-- ERR_ACCESS_DENIED -->
</div>
</body></html>
?
* Connection #0 to host www.google.com left intact
[root at prd-rbs-squid02-poa ~]#
?
[root at prd-rbs-squid02-poa ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 238 packets, 21830 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain INPUT (policy ACCEPT 48 packets, 4956 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 4 packets, 257 bytes)
?
 pkts bytes target     prot opt in     out     source               destination
    2   120 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80
?
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:443

Chain POSTROUTING (policy ACCEPT 6 packets, 377 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain PROXYSQUID (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
    0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
    0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
    2   120 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            to:10.240.64.11:3129
[root at prd-rbs-squid02-poa ~]#

[root at prd-rbs-squid01-poa squid]# tail -f /var/log/squid/access.log
1495131838.333    470 10.240.64.12 TCP_SWAPFAIL_MISS/200 11868 GET http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - HIER_DIRECT/162.243.159.138 application/x-redhat-package-manager

1495131856.340      0 10.240.64.11 TCP_MISS/403 4352 GET http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - HIER_NONE/- text/html
1495131856.340      0 10.240.64.12 TCP_MISS/403 4517 GET http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - ORIGINAL_DST/10.240.64.11 text/html
1495131863.177      0 10.240.64.11 TCP_MISS/403 4147 GET http://www.google.com/ - HIER_NONE/- text/html
1495131863.177      3 10.240.64.12 TCP_MISS/403 4312 GET http://www.google.com/ - ORIGINAL_DST/10.240.64.11 text/html

When i add iptables nat rules on Squid Server i get Service Unavailable / ERR_CONNECT_FAIL 111 .

[root at prd-rbs-squid01-poa ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 11682 packets, 1002K bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain INPUT (policy ACCEPT 2631 packets, 243K bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 150 packets, 11353 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 150 packets, 11353 bytes)
?
 pkts bytes target     prot opt in     out     source               destination
[root at prd-rbs-squid01-poa ~]# cat /root/squid.sh
#!/bin/bash

echo "1" > /proc/sys/net/ipv4/ip_forward
echo "0" > /proc/sys/net/ipv4/conf/default/rp_filter
echo "0" > /proc/sys/net/ipv4/conf/default/accept_source_route

iptables -F -t nat
iptables -X -t nat

# your proxy IP
SQUIDIP=10.240.64.11

# your proxy listening port
SQUIDPORT=3129

iptables -t nat -A PREROUTING -s $SQUIDIP -p tcp --dport 80 -j ACCEPT
iptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to-destination $SQUIDIP:$SQUIDPORT
iptables -t nat -A POSTROUTING -j MASQUERADE
iptables -t mangle -A PREROUTING -p tcp --dport $SQUIDPORT -j DROP
[root at prd-rbs-squid01-poa ~]# /root/squid.sh
[root at prd-rbs-squid01-poa ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 13 packets, 1777 bytes)
?
 pkts bytes target     prot opt in     out     source               destination
    0     0 ACCEPT     tcp  --  *      *       10.240.64.11         0.0.0.0/0            tcp dpt:80
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80 to:10.240.64.11:3129

Chain INPUT (policy ACCEPT 6 packets, 885 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source               destination
    0     0 MASQUERADE  all  --  *      *       0.0.0.0/0            0.0.0.0/0
[root at prd-rbs-squid01-poa ~]# netstat -nap | grep -i squid
tcp6       0      0 :::3128                 :::*                    LISTEN      6592/(squid-1)
tcp6       0      0 :::3129                 :::*                    LISTEN      6592/(squid-1)
udp        0      0 0.0.0.0:50868           0.0.0.0:*                           6592/(squid-1)
udp6       0      0 :::55754                :::*                                6592/(squid-1)
unix  3      [ ]         STREAM     CONNECTED     73819    6592/(squid-1)
unix  2      [ ]         DGRAM                    72824    6590/squid
[root at prd-rbs-squid01-poa ~]# systemctl stop squid
[root at prd-rbs-squid01-poa ~]# rm /var/log/squid/* -f
?
[root at prd-rbs-squid01-poa ~]# systemctl start squid
[root at prd-rbs-squid01-poa ~]# cat /var/log/squid/cache.log
2017/05/18 15:34:48 kid1| Set Current Directory to /var/spool/squid
2017/05/18 15:34:48 kid1| Starting Squid Cache version 3.5.20 for x86_64-redhat-linux-gnu...
2017/05/18 15:34:48 kid1| Service Name: squid
2017/05/18 15:34:48 kid1| Process ID 8435
2017/05/18 15:34:48 kid1| Process Roles: worker
2017/05/18 15:34:48 kid1| With 16384 file descriptors available
2017/05/18 15:34:48 kid1| Initializing IP Cache...
2017/05/18 15:34:48 kid1| DNS Socket created at [::], FD 6
2017/05/18 15:34:48 kid1| DNS Socket created at 0.0.0.0, FD 8
2017/05/18 15:34:48 kid1| Adding domain RBS.NET from /etc/resolv.conf
2017/05/18 15:34:48 kid1| Adding domain rbs.com.br from /etc/resolv.conf
2017/05/18 15:34:48 kid1| Adding nameserver 10.236.68.62 from /etc/resolv.conf
2017/05/18 15:34:48 kid1| Adding nameserver 10.1.1.40 from /etc/resolv.conf
2017/05/18 15:34:48 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2017/05/18 15:34:48 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2017/05/18 15:34:48 kid1| Unlinkd pipe opened on FD 14
2017/05/18 15:34:48 kid1| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2017/05/18 15:34:48 kid1| Store logging disabled
2017/05/18 15:34:48 kid1| Swap maxSize 102400 + 262144 KB, estimated 28041 objects
2017/05/18 15:34:48 kid1| Target number of buckets: 1402
2017/05/18 15:34:48 kid1| Using 8192 Store buckets
2017/05/18 15:34:48 kid1| Max Mem  size: 262144 KB
2017/05/18 15:34:48 kid1| Max Swap size: 102400 KB
2017/05/18 15:34:48 kid1| Rebuilding storage in /var/spool/squid (dirty log)
2017/05/18 15:34:48 kid1| Using Least Load store dir selection
2017/05/18 15:34:48 kid1| Set Current Directory to /var/spool/squid
2017/05/18 15:34:48 kid1| Finished loading MIME types and icons.
2017/05/18 15:34:48 kid1| HTCP Disabled.
2017/05/18 15:34:48 kid1| Squid plugin modules loaded: 0
2017/05/18 15:34:48 kid1| Adaptation support is off.
2017/05/18 15:34:48 kid1| Accepting HTTP Socket connections at local=[::]:3128 remote=[::] FD 17 flags=9
2017/05/18 15:34:48 kid1| Accepting NAT intercepted HTTP Socket connections at local=[::]:3129 remote=[::] FD 18 flags=41
2017/05/18 15:34:48 kid1| Done reading /var/spool/squid swaplog (4 entries)
2017/05/18 15:34:48 kid1| Finished rebuilding storage from disk.
2017/05/18 15:34:48 kid1|         2 Entries scanned
2017/05/18 15:34:48 kid1|         0 Invalid entries.
2017/05/18 15:34:48 kid1|         0 With invalid flags.
2017/05/18 15:34:48 kid1|         1 Objects loaded.
2017/05/18 15:34:48 kid1|         0 Objects expired.
2017/05/18 15:34:48 kid1|         0 Objects cancelled.
2017/05/18 15:34:48 kid1|         0 Duplicate URLs purged.
2017/05/18 15:34:48 kid1|         1 Swapfile clashes avoided.
2017/05/18 15:34:48 kid1|   Took 0.01 seconds ( 91.74 objects/sec).
2017/05/18 15:34:48 kid1| Beginning Validation Procedure
2017/05/18 15:34:48 kid1|   Completed Validation Procedure
2017/05/18 15:34:48 kid1|   Validated 1 Entries
2017/05/18 15:34:48 kid1|   store_swap_size = 12.00 KB
2017/05/18 15:34:49 kid1| storeLateRelease: released 0 objects


[root at prd-rbs-squid02-poa ~]# /mnt/bin/Linux/proxy3520_80.sh
?
[root at prd-rbs-squid02-poa ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 8 packets, 594 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain INPUT (policy ACCEPT 0 packets, 0 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 1 packets, 76 bytes)
?
 pkts bytes target     prot opt in     out     source               destination
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80
    0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:443

Chain POSTROUTING (policy ACCEPT 1 packets, 76 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain PROXYSQUID (2 references)
 pkts bytes target     prot opt in     out     source               destination
    0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
    0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
    0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
    0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            to:10.240.64.11:80
?

[root at prd-rbs-squid02-poa ~]# wget http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm -e use_proxy=yes -e http_proxy=10.240.64.11:3128
--2017-05-18 15:35:16--  http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
?
Connecting to 10.240.64.11:3128... connected.
Proxy request sent, awaiting response... 200 OK
Length: 11416 (11K) [application/x-redhat-package-manager]
Saving to: ???zabbix-release-3.0-1.el7.noarch.rpm.1???
?

100%[=======================================================================================================================================>] 11,416      --.-K/s   in 0s

2017-05-18 15:35:16 (193 MB/s) - ???zabbix-release-3.0-1.el7.noarch.rpm.1??? saved [11416/11416]
?

[root at prd-rbs-squid02-poa ~]# wget http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
--2017-05-18 15:35:25--  http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm
?
Resolving repo.zabbix.com (repo.zabbix.com)... 162.243.159.138
Connecting to repo.zabbix.com (repo.zabbix.com)|162.243.159.138|:80... connected.
HTTP request sent, awaiting response... 503 Service Unavailable
2017-05-18 15:35:25 ERROR 503: Service Unavailable.
?

[root at prd-rbs-squid02-poa ~]# curl -v http://www.google.com
* About to connect() to www.google.com port 80 (#0)
*   Trying 216.58.222.68...
* Connected to www.google.com (216.58.222.68) port 80 (#0)
> GET / HTTP/1.1
> User-Agent: curl/7.29.0
> Host: www.google.com
> Accept: */*
>
< HTTP/1.1 503 Service Unavailable
< Server: squid/3.5.20
< Mime-Version: 1.0
< Date: Thu, 18 May 2017 18:35:42 GMT
< Content-Type: text/html;charset=utf-8
< Content-Length: 3586
< X-Squid-Error: ERR_CONNECT_FAIL 111
?
< Vary: Accept-Language
< Content-Language: en
< X-Cache: MISS from prd-rbs-squid01-poa.rbs.com.br
< X-Cache-Lookup: MISS from prd-rbs-squid01-poa.rbs.com.br:3128
< Via: 1.1 prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20)
< Connection: keep-alive
?
<
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
<meta type="copyright" content="Copyright (C) 1996-2016 The Squid Software Foundation and contributors">
<meta http-equiv="Content-Type" CONTENT="text/html; charset=utf-8">
?
</head><body id=ERR_CONNECT_FAIL>
?
<div id="titles">
<h1>ERROR</h1>
<h2>The requested URL could not be retrieved</h2>
</div>
<hr>

<div id="content">
<p>The following error was encountered while trying to retrieve the URL: <a href="http://www.google.com/">http://www.google.com/</a></p>

<blockquote id="error">
<p><b>Connection to 10.240.64.11 failed.</b></p>
</blockquote>

<p id="sysmsg">The system returned: <i>(111) Connection refused</i></p>

<p>The remote host or network may be down. Please try the request again.</p>

<p>Your cache administrator is <a href="mailto:root?subject=CacheErrorInfo%20-%20ERR_CONNECT_FAIL&amp;body=CacheHost%3A%20prd-rbs-squid01-poa.rbs.com.br%0D%0AErrPage%3A%20ERR_CONNECT_FAIL%0D%0AErr%3A%20(111)%20Connection%20refused%0D%0ATimeStamp%3A%20Thu,%2018%20May%202017%2018%3A35%3A42%20GMT%0D%0A%0D%0AClientIP%3A%2010.240.64.12%0D%0AServerIP%3A%20www.google.com%0D%0A%0D%0AHTTP%20Request%3A%0D%0AGET%20%2F%20HTTP%2F1.1%0AUser-Agent%3A%20curl%2F7.29.0%0D%0AAccept%3A%20*%2F*%0D%0AHost%3A%20www.google.com%0D%0A%0D%0A%0D%0A">root</a>.</p>
?

<br>
</div>

<hr>
<div id="footer">
<p>Generated Thu, 18 May 2017 18:35:42 GMT by prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20)</p>
<!-- ERR_CONNECT_FAIL -->
</div>
</body></html>
?
* Connection #0 to host www.google.com left intact
[root at prd-rbs-squid02-poa ~]# telnet 10.240.64.11 80
Trying 10.240.64.11...
Connected to 10.240.64.11.
Escape character is '^]'.
www.google.com.br
?
HTTP/1.1 400 Bad Request
Server: squid/3.5.20
Mime-Version: 1.0
Date: Thu, 18 May 2017 18:36:12 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 4083
X-Squid-Error: ERR_INVALID_REQ 0
?
</head><body id=ERR_INVALID_REQ>
?
<div id="titles">
<h1>ERROR</h1>
<h2>The requested URL could not be retrieved</h2>
</div>
<hr>

<div id="content">
<p><b>Invalid Request</b> error was encountered while trying to process the request:</p>

<blockquote id="data">
<pre>www.google.com.br
</pre>
</blockquote>
?

<p>Some possible problems are:</p>
<ul>
<li id="missing-method"><p>Missing or unknown request method.</p></li>
<li id="missing-url"><p>Missing URL.</p></li>
<li id="missing-protocol"><p>Missing HTTP Identifier (HTTP/1.0).</p></li>
<li><p>Request is too large.</p></li>
<li><p>Content-Length missing for POST or PUT requests.</p></li>
?
<li><p>Illegal character in hostname; underscores are not allowed.</p></li>
<li><p>HTTP/1.1 <q>Expect:</q> feature is being asked from an HTTP/1.0 software.</p></li>
</ul>

<p>Your cache administrator is <a href="mailto:root?subject=CacheErrorInfo%20-%20ERR_INVALID_REQ&amp;body=CacheHost%3A%20prd-rbs-squid01-poa.rbs.com.br%0D%0AErrPage%3A%20ERR_INVALID_REQ%0D%0AErr%3A%20%5Bnone%5D%0D%0ATimeStamp%3A%20Thu,%2018%20May%202017%2018%3A36%3A12%20GMT%0D%0A%0D%0AClientIP%3A%2010.240.64.12%0D%0A%0D%0AHTTP%20Request%3A%0D%0A%0D%0A%0D%0A">root</a>.</p>
<br>
</div>

<script language="javascript">
if ('[unknown method]' != '[unknown method]') document.getElementById('missing-method').style.display = 'none';
if ('error:invalid-request' != '[no URL]') document.getElementById('missing-url').style.display = 'none';
if ('[unknown protocol]' != '[unknown protocol]') document.getElementById('missing-protocol').style.display = 'none';
</script>

<hr>
<div id="footer">
<p>Generated Thu, 18 May 2017 18:36:12 GMT by prd-rbs-squid01-poa.rbs.com.br (squid/3.5.20)</p>
<!-- ERR_INVALID_REQ -->
</div>
</body></html>
Connection closed by foreign host.
?
[root at prd-rbs-squid02-poa ~]#


[root at prd-rbs-squid01-poa ~]# tail -f /var/log/squid/access.log



1495132516.589    414 10.240.64.12 TCP_SWAPFAIL_MISS/200 11868 GET http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - HIER_DIRECT/162.243.159.138 application/x-redhat-package-manager
1495132525.592      1 10.240.64.12 TCP_MISS/503 4275 GET http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm - ORIGINAL_DST/10.240.64.11 text/html
1495132542.412      4 10.240.64.12 TCP_MISS/503 4037 GET http://www.google.com/ - ORIGINAL_DST/10.240.64.11 text/html
1495132572.097      0 10.240.64.12 TAG_NONE/400 4518 NONE error:invalid-request - HIER_NONE/- text/html
^[[A^[[A^C
[root at prd-rbs-squid01-poa ~]#
[root at prd-rbs-squid01-poa ~]#
[root at prd-rbs-squid01-poa ~]#
[root at prd-rbs-squid01-poa ~]# iptables -L -n -v -t nat
Chain PREROUTING (policy ACCEPT 1302 packets, 114K bytes)
?
 pkts bytes target     prot opt in     out     source               destination
    0     0 ACCEPT     tcp  --  *      *       10.240.64.11         0.0.0.0/0            tcp dpt:80
    3   180 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80 to:10.240.64.11:3129

Chain INPUT (policy ACCEPT 300 packets, 26683 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain OUTPUT (policy ACCEPT 14 packets, 983 bytes)
?
 pkts bytes target     prot opt in     out     source               destination

Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes)
?
 pkts bytes target     prot opt in     out     source               destination
   14   983 MASQUERADE  all  --  *      *       0.0.0.0/0            0.0.0.0/0
[root at prd-rbs-squid01-poa ~]#

[root at prd-rbs-squid01-poa ~]# curl -v http://www.google.com
?
* About to connect() to www.google.com port 80 (#0)
*   Trying 172.217.30.4...
* Connected to www.google.com (172.217.30.4) port 80 (#0)
?
> GET / HTTP/1.1
> User-Agent: curl/7.29.0
> Host: www.google.com
> Accept: */*
>
< HTTP/1.1 302 Found
< Location: http://www.google.com.br/?gws_rd=cr&ei=wuodWZinJcmZwgTciKb4Bg
?
< Cache-Control: private
< Content-Type: text/html; charset=UTF-8
< P3P: CP="This is not a P3P policy! See https://www.google.com/support/accounts/answer/151657?hl=en for more info."
< Date: Thu, 18 May 2017 18:41:06 GMT
?
< Server: gws
< Content-Length: 262
< X-XSS-Protection: 1; mode=block
< X-Frame-Options: SAMEORIGIN
< Set-Cookie: NID=103=WzsmeICIbXNm_Pvj9tvsdijmqA-NgEXXDYt9Oiso971cJhOyXiM3GEjVwZNUxKs4QorVs9P_07jwWkPk6LhbODbhNPdchdTiTpMXh_ZIFpRKDPERbxD3w46bOVl_CngR; expires=Fri, 17-Nov-2017 18:41:06 GMT; path=/; domain=.google.com; HttpOnly
?
<
<HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
<TITLE>302 Moved</TITLE></HEAD><BODY>
<H1>302 Moved</H1>
The document has moved
<A HREF="http://www.google.com.br/?gws_rd=cr&amp;ei=wuodWZinJcmZwgTciKb4Bg">here</A>.
?




Rog?rio Ceni Coelho
Engenheiro de Infraestrutura ? Infrastructure Engineer
Diretoria de TI e Telecom - Grupo RBS
Fone: +55 (51) 3218-6983
Celular: +55 (51) 8186-2933 Claro
Celular: +55 (51) 8050-4225 Vivo
rogerio.coelho at gruporbs.com.br
http://www.gruporbs.com.br



Esta mensagem e quaisquer anexos s?o exclusivamente para o uso da parte endere?ada e poder?o conter dados privilegiados e confidenciais. Caso o leitor da mensagem n?o seja a parte a quem ela foi endere?ada, nem um representante autorizado da mesma, ficar? notificado, por meio desta, que qualquer divulga??o desta comunica??o ? estritamente proibida. Se esta comunica??o for recebida erroneamente, por favor, notifique-nos disto imediatamente por e-mail e delete a mensagem  e quaisquer anexos a ela de seu sistema.



-----Mensagem original-----
De: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Em nome de Amos Jeffries
Enviada em: quarta-feira, 24 de maio de 2017 18:13
Para: squid-users at lists.squid-cache.org
Assunto: Re: [squid-users] RES: New Squid Server 3.5.20 on Centos 7 - Trying to redirect local web access to Port 80 on Linux Servers with iptables to Squid Server with http_port intercept

On 25/05/17 08:12, Rogerio Coelho wrote:
> On my new Squid Server running 3.5.20 on Centos 7 a try to use in many different ways.
>
> When i use wget or firefox using http_proxy conf web access go ok. But when i try to access web using iptables redirect from Linux Server i got bad request / Invalid URL.

You omitted the squid.conf dump on this post so I cannot be sure but that is the behaviour which happens when use a forward/explicit proxy port (eg 3128) to receive intercepted port-80 traffic.

You need separate http_port lines for receiving these two quite different types of HTTP traffic.


Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
O Grupo RBS pauta sua atua??o por seu C?digo de ?tica e Conduta, em conformidade com a Legisla??o Brasileira. Qualquer situa??o irregular deve ser informada via Canal de ?tica pelo site https://www.contatoseguro.com.br/gruporbs ou 0800 602 1831. Este e-mail e seus anexos podem conter informa??es confidenciais. Se voc? recebeu esta mensagem por engano, por favor apague-a e notifique o remetente imediatamente.

From rogerio.coelho at gruporbs.com.br  Wed May 24 21:25:56 2017
From: rogerio.coelho at gruporbs.com.br (Rogerio Coelho)
Date: Wed, 24 May 2017 21:25:56 +0000
Subject: [squid-users] RES: New Squid Server 3.5.20 on Centos 7 - Trying to
 redirect local web access to Port 80 on Linux Servers with iptables to
 Squid Server with http_port intercept
In-Reply-To: <b88f571f-41ec-7f1b-69c1-039349716d9a@treenet.co.nz>
References: <SC1PR80MB194973E5AE33EB788BFB08C5D0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>
 <b88f571f-41ec-7f1b-69c1-039349716d9a@treenet.co.nz>
Message-ID: <SC1PR80MB1949F5C5838F126B1A849255D0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>

Hi,

Sorry about my inexpirience ( and bad English ).


Rog?rio Ceni Coelho
Engenheiro de Infraestrutura ? Infrastructure Engineer
Diretoria de TI e Telecom - Grupo RBS
Fone: +55 (51) 3218-6983
Celular: +55 (51) 8186-2933 Claro
Celular: +55 (51) 8050-4225 Vivo
rogerio.coelho at gruporbs.com.br
http://www.gruporbs.com.br



Esta mensagem e quaisquer anexos s?o exclusivamente para o uso da parte endere?ada e poder?o conter dados privilegiados e confidenciais. Caso o leitor da mensagem n?o seja a parte a quem ela foi endere?ada, nem um representante autorizado da mesma, ficar? notificado, por meio desta, que qualquer divulga??o desta comunica??o ? estritamente proibida. Se esta comunica??o for recebida erroneamente, por favor, notifique-nos disto imediatamente por e-mail e delete a mensagem  e quaisquer anexos a ela de seu sistema.



-----Mensagem original-----
De: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Em nome de Amos Jeffries
Enviada em: quarta-feira, 24 de maio de 2017 18:15
Para: squid-users at lists.squid-cache.org
Assunto: Re: [squid-users] New Squid Server 3.5.20 on Centos 7 - Trying to redirect local web access to Port 80 on Linux Servers with iptables to Squid Server with http_port intercept

On 25/05/17 08:02, Rogerio Coelho wrote:
> Hi Squid Jedi?s,
>
> I am just a little stuck tryng to replace an old Squid 3.1.23 Server on Centos 6 that i use to redirect local web access to port 80 on linux servers to Squid Server.
>
> On my Squid 3.1.23 Server on Centos 6 i use http_port 3128 transparent mode and on my Linux servers clients i use iptables to redirect Web traffic as below ( this config works ):

FYI: if your other posts are additional info on this problem could you please send as a reply to the earlier message (ie this one). It helps those of us tracking lots of issues and the mailing list<->forum portal software when the relevant posts are threaded.

Anyhow, I am replying directly to your other posts.

Amos


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
O Grupo RBS pauta sua atua??o por seu C?digo de ?tica e Conduta, em conformidade com a Legisla??o Brasileira. Qualquer situa??o irregular deve ser informada via Canal de ?tica pelo site https://www.contatoseguro.com.br/gruporbs ou 0800 602 1831. Este e-mail e seus anexos podem conter informa??es confidenciais. Se voc? recebeu esta mensagem por engano, por favor apague-a e notifique o remetente imediatamente.

From rogeriocenicoelho at gmail.com  Wed May 24 21:29:54 2017
From: rogeriocenicoelho at gmail.com (=?UTF-8?Q?Rog=C3=A9rio_Ceni_Coelho?=)
Date: Wed, 24 May 2017 21:29:54 +0000
Subject: [squid-users] RES: New Squid Server 3.5.20 on Centos 7 - Trying
 to redirect local web access to Port 80 on Linux Servers with iptables to
 Squid Server with http_port intercept
In-Reply-To: <bc898354-655d-179a-ed02-b048b9e14706@treenet.co.nz>
References: <SC1PR80MB194956E6A7A30F4ECFD508A6D0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>
 <bc898354-655d-179a-ed02-b048b9e14706@treenet.co.nz>
Message-ID: <CAPY4J208116ck7=LNCho2DAWuy2HH36kc-Md2PX_mz6yVQ21zQ@mail.gmail.com>

Please, take a look :

[root at prd-rbs-squid01-poa squid]# cat /etc/squid/squid.conf | egrep -v
"^#|^$"

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network

acl localnet src 172.16.0.0/12  # RFC1918 possible internal network acl
localnet src 192.168.0.0/16 # RFC1918 possible internal network

acl localnet src fc00::/7       # RFC 4193 local private network range

acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines

acl SSL_ports port 443

acl Safe_ports port 80          # http

?

acl Safe_ports port 21          # ftp

acl Safe_ports port 443         # https

acl Safe_ports port 70          # gopher

acl Safe_ports port 210         # wais

acl Safe_ports port 1025-65535  # unregistered ports

acl Safe_ports port 280         # http-mgmt

acl Safe_ports port 488         # gss-http

acl Safe_ports port 591         # filemaker

acl Safe_ports port 777         # multiling http

acl CONNECT method CONNECT

http_access deny !Safe_ports

http_access deny CONNECT !SSL_ports

http_access allow localhost manager

http_access deny manager

http_access allow localnet

http_access allow localhost

*http_port 3128*

*http_port 3129 intercept*

cache_dir ufs /var/spool/squid 100 16 256 coredump_dir /var/spool/squid

refresh_pattern ^ftp:           1440    20%     10080

refresh_pattern ^gopher:        1440    0%      1440

refresh_pattern -i (/cgi-bin/|\?) 0     0%      0

refresh_pattern .               0       20%     4320

[root at prd-rbs-squid01-poa squid]#
Em qua, 24 de mai de 2017 ?s 18:13, Amos Jeffries <squid3 at treenet.co.nz>
escreveu:

> On 25/05/17 08:12, Rogerio Coelho wrote:
> > On my new Squid Server running 3.5.20 on Centos 7 a try to use in many
> different ways.
> >
> > When i use wget or firefox using http_proxy conf web access go ok. But
> when i try to access web using iptables redirect from Linux Server i got
> bad request / Invalid URL.
>
> You omitted the squid.conf dump on this post so I cannot be sure but
> that is the behaviour which happens when use a forward/explicit proxy
> port (eg 3128) to receive intercepted port-80 traffic.
>
> You need separate http_port lines for receiving these two quite
> different types of HTTP traffic.
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170524/077ed2c6/attachment.htm>

From squid3 at treenet.co.nz  Wed May 24 21:47:34 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 May 2017 09:47:34 +1200
Subject: [squid-users] RES: New Squid Server 3.5.20 on Centos 7 - Trying
 to redirect local web access to Port 80 on Linux Servers with iptables to
 Squid Server with http_port intercept
In-Reply-To: <SC1PR80MB19499C09E5D9F768548EED20D0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>
References: <SC1PR80MB19499C09E5D9F768548EED20D0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>
Message-ID: <348ff774-79ba-71d9-5aaf-f74ba416ac10@treenet.co.nz>

On 25/05/17 08:16, Rogerio Coelho wrote:
> Using intercept mode with 3129 port :
>
> [root at prd-rbs-squid01-poa squid]# cat /etc/squid/squid.conf | egrep -v "^#|^$"
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> ?
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access allow localnet
> http_access allow localhost
> http_port 3128
> http_port 3129 intercept
> cache_dir ufs /var/spool/squid 100 16 256
> coredump_dir /var/spool/squid
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> [root at prd-rbs-squid01-poa squid]#
>
> [root at prd-rbs-squid01-poa ~]# systemctl restart squid
> [root at prd-rbs-squid01-poa squid]# systemctl start squid
> [root at prd-rbs-squid01-poa squid]# cat cache.log

> 2017/05/18 15:22:29 kid1| Accepting HTTP Socket connections at local=[::]:3128 remote=[::] FD 17 flags=9
> 2017/05/18 15:22:29 kid1| Accepting NAT intercepted HTTP Socket connections at local=[::]:3129 remote=[::] FD 18 flags=41


> ?
>   pkts bytes target     prot opt in     out     source               destination
>      0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80
>      0     0 PROXYSQUID  tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:443
>
> Chain POSTROUTING (policy ACCEPT 1 packets, 76 bytes)
> ?
>   pkts bytes target     prot opt in     out     source               destination
>
> Chain PROXYSQUID (2 references)
>   pkts bytes target     prot opt in     out     source               destination
>      0     0 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16
>      0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.144.0/20
>      0     0 RETURN     all  --  *      *       0.0.0.0/0            189.76.156.190
>      0     0 RETURN     all  --  *      *       0.0.0.0/0            172.16.0.0/12
>      0     0 RETURN     all  --  *      *       0.0.0.0/0            10.0.0.0/8
>      0     0 DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            to:10.240.64.11:3129

Two problems visible.

* One you have not yet encountered is that these iptables rules are 
directing port 80 and 443 to the same Squid receiving port. These two 
ports also have very different traffic from each other, more so than 
port 3128 vs 80 and Squid again requires separate receiving port for the 
intercepted port 443 traffic.

To fix this it needs an "http_port ... intercept" line for port-80, and 
a "https_port ... intercept cert=..." line for port-443. Note the extra "s".


* The second is your current problem; the NAT rules are on a different 
machine to Squid.

Squid uses the kernel NAT state directly to ensure that the traffic is 
going where it was intended to by the client (the ORIGINAL_DST). So it 
cannot work if that needed piece of kernel memory is on another machine.

To fix this you need to use routing to get the TCP packets to the 
relevant Squid machine and do the iptables DNAT (or REDIRECT target) there.


Amos



From rousskov at measurement-factory.com  Wed May 24 21:57:47 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 24 May 2017 15:57:47 -0600
Subject: [squid-users] SSL bump, SSL intercept, explicit, secure proxy,
 what is it called?
In-Reply-To: <e1e7a176-91bb-da65-a8b7-207ef8f9d1f1@treenet.co.nz>
References: <1140034948.954341.1495590259601.ref@mail.yahoo.com>
 <1140034948.954341.1495590259601@mail.yahoo.com>
 <41b65b4b-5603-ef56-5c5a-7bf68d8b0cd0@treenet.co.nz>
 <e5e5371f-74ce-0e6d-23ca-b29ddff49254@measurement-factory.com>
 <e1e7a176-91bb-da65-a8b7-207ef8f9d1f1@treenet.co.nz>
Message-ID: <c2e81917-8be8-0c49-88b6-5b9cd554a5f1@measurement-factory.com>

On 05/24/2017 01:45 PM, Amos Jeffries wrote:
> On 25/05/17 02:17, Alex Rousskov wrote:
>> On 05/24/2017 06:56 AM, Amos Jeffries wrote:
>>> On 24/05/17 13:44, j m wrote:
>>>> So firstly, what is the actual name for what I want (encrypting proxy
>>>> to browser)?

>>> Some people seem to be calling it "HTTPS", but that is not correct and
>>> thankfully makes it difficult to find the bad info.

>> What makes you think that "HTTPS proxy" is an incorrect term? That is
>> the term I have seen used the most, and that is the term I would use.
>> That is also the term that allows to locate relevant documents by
>> googling.
> 
> Two reasons;
> 
> 1) "HTTPS" has a definition (HTTP messages over TLS transport)

... which is exactly what we are discussing: A browser sending HTTP
messages to the proxy, over TLS.


> and a scheme (https://) which explicitly precludes it being used to contact
> forward proxies. 

FWIW, Curl and some other clients use https scheme to configure HTTPS
proxies. Perhaps they are violating some IETF prohibition, but I doubt
that they actually do.


> TLS to a proxy does not have a scheme of its own and
> can carry any protocol the proxy supports, not just HTTP.

Very true and emphasizes why "TLS proxy" does not define much and,
hence, is not a very useful term.


> 2) protocol nesting for HTTPS-over-HTTPS is a very different series of
> layers and message sequence(s) than HTTPS-over-TLS [to a proxy]. In
> particular it is 4 layers deep (one for each "HTTPS").

Yes, but I do not see the relevance. "HTTPS proxy" does not say what is
going on inside the CONNECT tunnels (if any). Yes, supporting HTTPS
proxies/"TLS explicit proxies" in the real world is difficult because
getting HTTPS-over-HTTPS to work is difficult, but what does that have
to do with the terminology?


>>> The current IETF term for it is "TLS explicit proxy".
>> Any supporting references?

> No direct reference sorry - it is not formal and may change

Or it may not be a result of any IETF consensus. Or it may not even exist!


> [a] https://datatracker.ietf.org/doc/draft-loreto-httpbis-trusted-proxy20/

Uses the terms "explicit proxy" and "trusted proxy" not "TLS explicit
proxy".


> [b] https://datatracker.ietf.org/doc/html/draft-rpeon-httpbis-exproxy-01

Uses the terms "configured-proxy" and "trusted-proxy" not "TLS explicit
proxy".

The "explicit" and "trusted" parts are not the problem, of course. It is
the absence of the HTTP part that is a problem IMO when we are trying to
describe a thing that expects [encrypted] HTTP requests.

Alex.



From squid3 at treenet.co.nz  Wed May 24 22:15:44 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 May 2017 10:15:44 +1200
Subject: [squid-users] SSL bump, SSL intercept, explicit, secure proxy,
 what is it called?
In-Reply-To: <678419562.1792246.1495659713195@mail.yahoo.com>
References: <1140034948.954341.1495590259601.ref@mail.yahoo.com>
 <1140034948.954341.1495590259601@mail.yahoo.com>
 <41b65b4b-5603-ef56-5c5a-7bf68d8b0cd0@treenet.co.nz>
 <678419562.1792246.1495659713195@mail.yahoo.com>
Message-ID: <c3e742d8-5bf3-02d7-dea0-2fe5b0aeec73@treenet.co.nz>

On 25/05/17 09:01, j m wrote:
> Some more info:  I tried this on Firefox 53 and got more feedback, but 
> still doesn't work.  Per the recommendation on bugzilla (bug 378637), 
> I put https://myaddress:myport <https://myaddress:myport/> into 
> firefox and it gives me a "Your connection is not secure".  So I add 
> the exception, and it then displays the squid message "ERROR The 
> requested URL could not be retrieved", as expected.
>
> So I add the proxy to Firefox (in Advanced, Network, Settings) as the 
> HTTP Proxy....doesn't work, "The proxy server is refusing 
> connections".  I then put https:// in front of the address, then it's 
> "Server not found".  I then add it as SSL Proxy.  It appears to be 
> working, but really it's simply not using the proxy at all because I 
> stopped squid and it made no difference.
>

The settings you enter via the Browser GUI are exclusively for setting 
up plain-text proxy connections.

"SSL Proxy" in the Browser GUI means the proxy to send any SSL/TLS 
traffic *through* (using CONNECT tunnel).


> The link you reference on getting Firefox to work with this refers to 
> Firefox 33, so by now I'd think I could directly add the proxy to the 
> normal place in Firefox options?

Unfortunately that would be far too sensible.  It only took ~20 years to 
get them to accept any kind of TLS/SSL security on the Browser<->proxy 
connection in the first place.

I really wish that was a joke, but I've long ago given up on expecting 
sanity from Browser people. For the topic in question, the argument 
behind not adding a simple tick-box to that somewhat hidden GUI popup to 
enable TLS/SSL to a proxy ... is unwaveringly that "changing the UI 
would cause a lot of end users some confusion and pain" or words to that 
affect - and yet I've lost count of how many graphical redesigns have 
happened to the things those end-users are directly seeing and using on 
a daily basis. But one semi-hidden tick box, oh no!

Amos



From harariboy at gmail.com  Thu May 25 00:08:20 2017
From: harariboy at gmail.com (avi_h)
Date: Wed, 24 May 2017 17:08:20 -0700 (PDT)
Subject: [squid-users] External ACL
In-Reply-To: <f6666fd7-a855-9304-d5c8-1c68c6d2329f@treenet.co.nz>
References: <1495502728560-4682519.post@n4.nabble.com>
 <046c5862-9f83-911e-0e0f-aa3d52db6a34@treenet.co.nz>
 <1495544529394-4682527.post@n4.nabble.com>
 <bb991bc6-d898-7fd6-f525-084affa93716@treenet.co.nz>
 <1495641649465-4682544.post@n4.nabble.com>
 <1495656999263-4682555.post@n4.nabble.com>
 <f6666fd7-a855-9304-d5c8-1c68c6d2329f@treenet.co.nz>
Message-ID: <1495670900382-4682566.post@n4.nabble.com>

Hi Amos,

The issue is that it still fails to authenticate.
That's why I thought those messages indicate an error.
Same thing happens both when I use my script or when I use
ext_sql_session_acl.
I missed a line in from the output:

2017/05/24 20:28:57.084 kid1| 82,2| external_acl.cc(1338)
externalAclHandleReply: reply={result=Unknown, other: "ERR message="unknown
UID ''""}

When using my script I only get the following but it's still unable to
authenticate:

2017/05/25 00:20:26.968 kid1| 82,2| external_acl.cc(786) aclMatchExternal:
ip_checker("192.168.1.1") = lookup needed
2017/05/25 00:20:26.968 kid1| 82,2| external_acl.cc(789) aclMatchExternal:
"192.168.1.1": queueing a call.
2017/05/25 00:20:26.968 kid1| 82,2| external_acl.cc(1416) Start: fg lookup
in 'ip_checker' for '192.168.1.1'
2017/05/25 00:20:26.968 kid1| 82,2| external_acl.cc(792) aclMatchExternal:
"192.168.1.1": return -1.

When using both helpers, the end result is that the browser keeps trying to
load the session.

Thanks,
Avi




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/External-ACL-tp4682519p4682566.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From webmaster at squidblacklist.org  Thu May 25 01:02:06 2017
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Wed, 24 May 2017 20:02:06 -0500
Subject: [squid-users] New Member - Just testing mail list
In-Reply-To: <SC1PR80MB194955C64F5CD37836A0883FD0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>
References: <SC1PR80MB194955C64F5CD37836A0883FD0FE0@SC1PR80MB1949.lamprd80.prod.outlook.com>
Message-ID: <d057bd1e-7a2c-0cbe-7100-906715fc0504@squidblacklist.org>

Good afternoon!


On 5/24/2017 2:53 PM, Rogerio Coelho wrote:
> Hi Squid Users !
>
> Just testing mail list.
>
> Rog?rio Ceni Coelho
> Engenheiro de Infraestrutura - Infrastructure Engineer
> Diretoria de TI e Telecom - Grupo RBS
> Fone: +55 (51) 3218-6983
> Celular: +55 (51) 8186-2933 Claro
> Celular: +55 (51) 8050-4225 Vivo
> rogerio.coelho at gruporbs.com.br
> http://www.gruporbs.com.br
>
>
>
> Esta mensagem e quaisquer anexos s?o exclusivamente para o uso da parte endere?ada e poder?o conter dados privilegiados e confidenciais. Caso o leitor da mensagem n?o seja a parte a quem ela foi endere?ada, nem um representante autorizado da mesma, ficar? notificado, por meio desta, que qualquer divulga??o desta comunica??o ? estritamente proibida. Se esta comunica??o for recebida erroneamente, por favor, notifique-nos disto imediatamente por e-mail e delete a mensagem  e quaisquer anexos a ela de seu sistema.
>
>
> O Grupo RBS pauta sua atua??o por seu C?digo de ?tica e Conduta, em conformidade com a Legisla??o Brasileira. Qualquer situa??o irregular deve ser informada via Canal de ?tica pelo site https://www.contatoseguro.com.br/gruporbs ou 0800 602 1831. Este e-mail e seus anexos podem conter informa??es confidenciais. Se voc? recebeu esta mensagem por engano, por favor apague-a e notifique o remetente imediatamente.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
--

Signed,

Benjamin E. Nichols
http://www.squidblacklist.org

1-405-397-1360 - Call Anytime.



From mbarbero at xmltravelgate.com  Thu May 25 07:51:10 2017
From: mbarbero at xmltravelgate.com (Miguel Barbero)
Date: Thu, 25 May 2017 09:51:10 +0200
Subject: [squid-users] Logs from traffic that don't belong to either
	whitelist or blacklist
Message-ID: <CAAarQVOPE9eZcmDerUFmwL2j7390FPOFy0jKXOAavPFcx=q0_g@mail.gmail.com>

Good morning,

We have a special requirement and we are not sure whether it's possible to
accomplish.

We have defined a whitelist and a blacklist on our Squid. Its behaviour is
as usual and how it could expect.

All the traffic less blacklist is passed however we are interested to get
an alert about the passed traffic that don't belong neither whitelist or
blacklist.

Is there any way to get this?

Thanks and kind regards

Saludos cordiales, Miquel
-- 

*Miquel Barbero*

*DevOps Engineer- XML Travelgate*

Tel: + 34  <+34%20871%2096%2081%2081>*34 871 968 181* | Ext: 110 |

mbarbero at xmltravelgate.com | www.xmltravelgate.com

<https://www.facebook.com/XmlTravelgate>
<https://twitter.com/XMLTravelgate>
<http://www.linkedin.com/company/xml-travelgate>
<https://plus.google.com/+Xmltravelgate/posts>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/d3e97cb1/attachment.htm>

From Walter.H at mathemainzel.info  Thu May 25 08:19:00 2017
From: Walter.H at mathemainzel.info (Walter H.)
Date: Thu, 25 May 2017 10:19:00 +0200
Subject: [squid-users] CentOS6 and squid34 package ...
Message-ID: <59269374.1060701@mathemainzel.info>

Hello

what is the essential difference between the default squid package and 
this squid34 package,
as I have problems using this squid34 package for FTP connections;
there are no shown icons, when going to e.g. ftp://ftp.adobe.com/
when I tell the browser to show the image then I get this squid 
generated message ...

the same config /etc/squid/squid.conf works with the default squid 
package ...

<message>
While trying to retrieve the URL: 
http://proxy.local:3128/squid-internal-static/icons/silk/folder.png 
<http://zbox-ci323.waldinet.local:3128/squid-internal-static/icons/silk/folder.png> 


The following error was encountered:

  * *Access Denied. *

Access control configuration prevents your request from being allowed at 
this time.
Please contact your service provider if you feel this is incorrect.

Your cache administrator is ...

------------------------------------------------------------------------
Generated Thu, 25 May 2017 06:50:02 GMT by proxy.local (squid/3.4.14)

</message>

has anybody the hint for me, what is wrong ..., here is the 
/etc/squid/squid.conf

<squid.conf>
acl localnet src 192.168.1.0/24

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access deny to_localhost
http_access allow localnet
http_access allow localhost
http_access deny all
http_reply_access allow all

http_port 3128

cache_dir ufs /var/spool/squid 16400 16 256
coredump_dir /var/spool/squid

nonhierarchical_direct off

visible_hostname proxy.local
unique_hostname proxy.local

forwarded_for off
cache_mem 2560 MB

icon_directory /usr/share/squid/icons
error_directory /etc/squid/errors

as_whois_server whois.ra.net

logformat combined %>A %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st 
"%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
access_log /var/log/squid/access.log combined

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
</squid.conf>

the same host has a running apache, where host proxy.local is a password 
protected web, which has the folling

for port 80
<virt. host>
RewriteCond %{HTTP_HOST} ^proxy\.local(:80)?$ [NC]
RewriteRule ^/(.*)$ https://proxy.local/$1 [L,R=301]
</virt. host>

for port 443
<virt. host>
<Location />
         AuthName Firewall/Router
         AuthType Basic
         AuthUserFile /var/www/passwrds
         Require User admin
</Location>
</virt. host>

/var/log/squid/access.log has this ...
<squid log>
client - - [25/May/2017:08:50:02 +0200] "GET 
http://proxy.local:3128/squid-internal-static/icons/silk/folder.png 
HTTP/1.1" 403 1655 "ftp://ftp.adobe.com/" "UserAgent" TCP_DENIED:HIER_NONE
</squid log>

the apache doesn't log anything in connection with this ...

has anybody the hint for me, what is causing this?

Thanks,
Walter

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/0fce6b1d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/0fce6b1d/attachment.bin>

From Walter.H at mathemainzel.info  Thu May 25 09:15:33 2017
From: Walter.H at mathemainzel.info (Walter H.)
Date: Thu, 25 May 2017 11:15:33 +0200
Subject: [squid-users] Logs from traffic that don't belong to either
 whitelist or blacklist
In-Reply-To: <CAAarQVOPE9eZcmDerUFmwL2j7390FPOFy0jKXOAavPFcx=q0_g@mail.gmail.com>
References: <CAAarQVOPE9eZcmDerUFmwL2j7390FPOFy0jKXOAavPFcx=q0_g@mail.gmail.com>
Message-ID: <5926A0B5.4070106@mathemainzel.info>

On 25.05.2017 09:51, Miguel Barbero wrote:
> Good morning,
>
> We have a special requirement and we are not sure whether it's 
> possible to accomplish.
>
> We have defined a whitelist and a blacklist on our Squid. Its 
> behaviour is as usual and how it could expect.
>
> All the traffic less blacklist is passed however we are interested to 
> get an alert about the passed traffic that don't belong neither 
> whitelist or blacklist.
>
> Is there any way to get this?
>
> Thanks and kind regards
>
>
you could do this with an url-rewrite-program, which does only the alert;
the same I do when the URL ends with   .mp4, I send a mail with the 
complete URL to myself
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/16600afc/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/16600afc/attachment.bin>

From squid3 at treenet.co.nz  Thu May 25 09:25:05 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 May 2017 21:25:05 +1200
Subject: [squid-users] Logs from traffic that don't belong to either
 whitelist or blacklist
In-Reply-To: <CAAarQVOPE9eZcmDerUFmwL2j7390FPOFy0jKXOAavPFcx=q0_g@mail.gmail.com>
References: <CAAarQVOPE9eZcmDerUFmwL2j7390FPOFy0jKXOAavPFcx=q0_g@mail.gmail.com>
Message-ID: <86b3d5ae-4a7c-873b-410a-5784126b9af8@treenet.co.nz>

On 25/05/17 19:51, Miguel Barbero wrote:
> Good morning,
>
> We have a special requirement and we are not sure whether it's 
> possible to accomplish.
>
> We have defined a whitelist and a blacklist on our Squid. Its 
> behaviour is as usual and how it could expect.
>
> All the traffic less blacklist is passed however we are interested to 
> get an alert about the passed traffic that don't belong neither 
> whitelist or blacklist.
>
> Is there any way to get this?

It is. I would configure it like this:


acl blacklist ...
http_access deny blocklist

acl whitelist ...
http_access allow whitelist

external_acl_type notify %% /path/to/notify_script
acl notify external notify

http_access allow notify
http_access deny all

Where the notify_script is a helper that sends your notification however 
you want and returns "OK" to Squid.


Cheers
Amos



From squid3 at treenet.co.nz  Thu May 25 10:50:04 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 25 May 2017 22:50:04 +1200
Subject: [squid-users] CentOS6 and squid34 package ...
In-Reply-To: <59269374.1060701@mathemainzel.info>
References: <59269374.1060701@mathemainzel.info>
Message-ID: <4c4b02a9-c38a-031b-db9d-fec999c64121@treenet.co.nz>

On 25/05/17 20:19, Walter H. wrote:
> Hello
>
> what is the essential difference between the default squid package and 
> this squid34 package,

Run "squid -v" to find out if there are any build options different. 
Usually its just two alternative versions from the vendor.


> as I have problems using this squid34 package for FTP connections;
> there are no shown icons, when going to e.g. ftp://ftp.adobe.com/
> when I tell the browser to show the image then I get this squid 
> generated message ...
>
> the same config /etc/squid/squid.conf works with the default squid 
> package ...
>
> <message>
> While trying to retrieve the URL: 
> http://proxy.local:3128/squid-internal-static/icons/silk/folder.png 
> <http://zbox-ci323.waldinet.local:3128/squid-internal-static/icons/silk/folder.png>
>

Notice the port number in that URL...

>
> <squid.conf>
> acl localnet src 192.168.1.0/24
>
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher

You have removed the port range 1025-65535 from Safe_ports. So traffic 
with URL port 3128 is no longer permitted.

>
> the apache doesn't log anything in connection with this ...

The request is for one of Squid's internal icon images. Apache has 
nothing to do with those or any other squid generated content.


Amos



From acctforjunk at yahoo.com  Thu May 25 11:11:53 2017
From: acctforjunk at yahoo.com (j m)
Date: Thu, 25 May 2017 11:11:53 +0000 (UTC)
Subject: [squid-users] SSL bump, SSL intercept, explicit, secure proxy,
 what is it called?
In-Reply-To: <c3e742d8-5bf3-02d7-dea0-2fe5b0aeec73@treenet.co.nz>
References: <1140034948.954341.1495590259601.ref@mail.yahoo.com>
 <1140034948.954341.1495590259601@mail.yahoo.com>
 <41b65b4b-5603-ef56-5c5a-7bf68d8b0cd0@treenet.co.nz>
 <678419562.1792246.1495659713195@mail.yahoo.com>
 <c3e742d8-5bf3-02d7-dea0-2fe5b0aeec73@treenet.co.nz>
Message-ID: <10688113.2268232.1495710713570@mail.yahoo.com>

Yay!? It works!? I got the Firefox addon Foxyproxy and checked the little SSL box, and it works perfectly.? 

How frustrating is it that Firefox and Chrome don't have this as an easy box to check?? They say it will cause confusion, but how many people even use a proxy to begin with?


      From: Amos Jeffries <squid3 at treenet.co.nz>
 To: j m <acctforjunk at yahoo.com>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Wednesday, May 24, 2017 5:15 PM
 Subject: Re: [squid-users] SSL bump, SSL intercept, explicit, secure proxy, what is it called?
   
On 25/05/17 09:01, j m wrote:
> Some more info:? I tried this on Firefox 53 and got more feedback, but 
> still doesn't work.? Per the recommendation on bugzilla (bug 378637), 
> I put https://myaddress:myport <https://myaddress:myport/> into 
> firefox and it gives me a "Your connection is not secure".? So I add 
> the exception, and it then displays the squid message "ERROR The 
> requested URL could not be retrieved", as expected.
>
> So I add the proxy to Firefox (in Advanced, Network, Settings) as the 
> HTTP Proxy....doesn't work, "The proxy server is refusing 
> connections".? I then put https:// in front of the address, then it's 
> "Server not found".? I then add it as SSL Proxy.? It appears to be 
> working, but really it's simply not using the proxy at all because I 
> stopped squid and it made no difference.
>

The settings you enter via the Browser GUI are exclusively for setting 
up plain-text proxy connections.

"SSL Proxy" in the Browser GUI means the proxy to send any SSL/TLS 
traffic *through* (using CONNECT tunnel).


> The link you reference on getting Firefox to work with this refers to 
> Firefox 33, so by now I'd think I could directly add the proxy to the 
> normal place in Firefox options?

Unfortunately that would be far too sensible.? It only took ~20 years to 
get them to accept any kind of TLS/SSL security on the Browser<->proxy 
connection in the first place.

I really wish that was a joke, but I've long ago given up on expecting 
sanity from Browser people. For the topic in question, the argument 
behind not adding a simple tick-box to that somewhat hidden GUI popup to 
enable TLS/SSL to a proxy ... is unwaveringly that "changing the UI 
would cause a lot of end users some confusion and pain" or words to that 
affect - and yet I've lost count of how many graphical redesigns have 
happened to the things those end-users are directly seeing and using on 
a daily basis. But one semi-hidden tick box, oh no!

Amos



   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/3bafa2bd/attachment.htm>

From Walter.H at mathemainzel.info  Thu May 25 11:24:08 2017
From: Walter.H at mathemainzel.info (Walter H.)
Date: Thu, 25 May 2017 13:24:08 +0200
Subject: [squid-users] Logs from traffic that don't belong to either
 whitelist or blacklist
In-Reply-To: <86b3d5ae-4a7c-873b-410a-5784126b9af8@treenet.co.nz>
References: <CAAarQVOPE9eZcmDerUFmwL2j7390FPOFy0jKXOAavPFcx=q0_g@mail.gmail.com>
 <86b3d5ae-4a7c-873b-410a-5784126b9af8@treenet.co.nz>
Message-ID: <5926BED8.1000706@mathemainzel.info>

On 25.05.2017 11:25, Amos Jeffries wrote:
> On 25/05/17 19:51, Miguel Barbero wrote:
>> Good morning,
>>
>> We have a special requirement and we are not sure whether it's 
>> possible to accomplish.
>>
>> We have defined a whitelist and a blacklist on our Squid. Its 
>> behaviour is as usual and how it could expect.
>>
>> All the traffic less blacklist is passed however we are interested to 
>> get an alert about the passed traffic that don't belong neither 
>> whitelist or blacklist.
>>
>> Is there any way to get this?
>
> It is. I would configure it like this:
>
>
> acl blacklist ...
> http_access deny blocklist
>
> acl whitelist ...
> http_access allow whitelist
>
> external_acl_type notify %% /path/to/notify_script
> acl notify external notify
>
> http_access allow notify
> http_access deny all
>
> Where the notify_script is a helper that sends your notification 
> however you want and returns "OK" to Squid. 
Hello Amos,

this helps me too, but where at the above "notify" can be a own defined 
label?

acl videourls ...
acl audiourls ...

external_acl_type notify %% /path/to/notify_script
acl notifyscript external notify

http_access allow notifyscript

how can I have two different notify_scripts?
e.g. one for acl  videourls and one for acl audiourls

Thanks,
Walter

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/4a03e703/attachment.bin>

From acctforjunk at yahoo.com  Thu May 25 12:00:46 2017
From: acctforjunk at yahoo.com (j m)
Date: Thu, 25 May 2017 12:00:46 +0000 (UTC)
Subject: [squid-users] SSL bump, SSL intercept, explicit, secure proxy,
 what is it called?
In-Reply-To: <c3e742d8-5bf3-02d7-dea0-2fe5b0aeec73@treenet.co.nz>
References: <1140034948.954341.1495590259601.ref@mail.yahoo.com>
 <1140034948.954341.1495590259601@mail.yahoo.com>
 <41b65b4b-5603-ef56-5c5a-7bf68d8b0cd0@treenet.co.nz>
 <678419562.1792246.1495659713195@mail.yahoo.com>
 <c3e742d8-5bf3-02d7-dea0-2fe5b0aeec73@treenet.co.nz>
Message-ID: <492105376.2247320.1495713646335@mail.yahoo.com>

Thought I'd try getting this to work in Chrome too.? NOTHING I try makes it work in Chrome.? Isn't running this from the Windows command line supposed to work?
chrome --proxy-server=https://mydomain:myport
When I do this, it runs Chrome, but it's still not going through the proxy despite Firefox on the same computer working just fine!



      From: Amos Jeffries <squid3 at treenet.co.nz>
 To: j m <acctforjunk at yahoo.com>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Wednesday, May 24, 2017 5:15 PM
 Subject: Re: [squid-users] SSL bump, SSL intercept, explicit, secure proxy, what is it called?
   
On 25/05/17 09:01, j m wrote:
> Some more info:? I tried this on Firefox 53 and got more feedback, but 
> still doesn't work.? Per the recommendation on bugzilla (bug 378637), 
> I put https://myaddress:myport <https://myaddress:myport/> into 
> firefox and it gives me a "Your connection is not secure".? So I add 
> the exception, and it then displays the squid message "ERROR The 
> requested URL could not be retrieved", as expected.
>
> So I add the proxy to Firefox (in Advanced, Network, Settings) as the 
> HTTP Proxy....doesn't work, "The proxy server is refusing 
> connections".? I then put https:// in front of the address, then it's 
> "Server not found".? I then add it as SSL Proxy.? It appears to be 
> working, but really it's simply not using the proxy at all because I 
> stopped squid and it made no difference.
>

The settings you enter via the Browser GUI are exclusively for setting 
up plain-text proxy connections.

"SSL Proxy" in the Browser GUI means the proxy to send any SSL/TLS 
traffic *through* (using CONNECT tunnel).


> The link you reference on getting Firefox to work with this refers to 
> Firefox 33, so by now I'd think I could directly add the proxy to the 
> normal place in Firefox options?

Unfortunately that would be far too sensible.? It only took ~20 years to 
get them to accept any kind of TLS/SSL security on the Browser<->proxy 
connection in the first place.

I really wish that was a joke, but I've long ago given up on expecting 
sanity from Browser people. For the topic in question, the argument 
behind not adding a simple tick-box to that somewhat hidden GUI popup to 
enable TLS/SSL to a proxy ... is unwaveringly that "changing the UI 
would cause a lot of end users some confusion and pain" or words to that 
affect - and yet I've lost count of how many graphical redesigns have 
happened to the things those end-users are directly seeing and using on 
a daily basis. But one semi-hidden tick box, oh no!

Amos



   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/19a0ca5a/attachment.htm>

From marcus.kool at urlfilterdb.com  Thu May 25 13:18:22 2017
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Thu, 25 May 2017 10:18:22 -0300
Subject: [squid-users] SSL bump, SSL intercept, explicit, secure proxy,
 what is it called?
In-Reply-To: <492105376.2247320.1495713646335@mail.yahoo.com>
References: <1140034948.954341.1495590259601.ref@mail.yahoo.com>
 <1140034948.954341.1495590259601@mail.yahoo.com>
 <41b65b4b-5603-ef56-5c5a-7bf68d8b0cd0@treenet.co.nz>
 <678419562.1792246.1495659713195@mail.yahoo.com>
 <c3e742d8-5bf3-02d7-dea0-2fe5b0aeec73@treenet.co.nz>
 <492105376.2247320.1495713646335@mail.yahoo.com>
Message-ID: <bee21bec-9801-27f2-8e35-daa97821df87@urlfilterdb.com>

If you use foxyproxy for firefox, you can use switchysharp for Chrome.

Marcus


On 25/05/17 09:00, j m wrote:
> Thought I'd try getting this to work in Chrome too.  NOTHING I try makes it work in Chrome.  Isn't running this from the Windows command line supposed to work?
> 
> chrome --proxy-server=https://mydomain:myport
> 
> When I do this, it runs Chrome, but it's still not going through the proxy despite Firefox on the same computer working just fine!
> 


From acctforjunk at yahoo.com  Thu May 25 16:09:09 2017
From: acctforjunk at yahoo.com (j m)
Date: Thu, 25 May 2017 16:09:09 +0000 (UTC)
Subject: [squid-users] SSL bump, SSL intercept, explicit, secure proxy,
 what is it called?
In-Reply-To: <bee21bec-9801-27f2-8e35-daa97821df87@urlfilterdb.com>
References: <1140034948.954341.1495590259601.ref@mail.yahoo.com>
 <1140034948.954341.1495590259601@mail.yahoo.com>
 <41b65b4b-5603-ef56-5c5a-7bf68d8b0cd0@treenet.co.nz>
 <678419562.1792246.1495659713195@mail.yahoo.com>
 <c3e742d8-5bf3-02d7-dea0-2fe5b0aeec73@treenet.co.nz>
 <492105376.2247320.1495713646335@mail.yahoo.com>
 <bee21bec-9801-27f2-8e35-daa97821df87@urlfilterdb.com>
Message-ID: <522960156.2448382.1495728549176@mail.yahoo.com>

This doesn't seem to have the SSL option like Foxyproxy does.? 

      From: Marcus Kool <marcus.kool at urlfilterdb.com>
 To: squid-users at lists.squid-cache.org 
 Sent: Thursday, May 25, 2017 8:18 AM
 Subject: Re: [squid-users] SSL bump, SSL intercept, explicit, secure proxy, what is it called?
   
If you use foxyproxy for firefox, you can use switchysharp for Chrome.

Marcus


On 25/05/17 09:00, j m wrote:
> Thought I'd try getting this to work in Chrome too.? NOTHING I try makes it work in Chrome.? Isn't running this from the Windows command line supposed to work?
> 
> chrome --proxy-server=https://mydomain:myport
> 
> When I do this, it runs Chrome, but it's still not going through the proxy despite Firefox on the same computer working just fine!
> 
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/5fb0b14e/attachment.htm>

From Walter.H at mathemainzel.info  Thu May 25 19:07:16 2017
From: Walter.H at mathemainzel.info (Walter H.)
Date: Thu, 25 May 2017 21:07:16 +0200
Subject: [squid-users] CentOS6 and squid34 package ...
In-Reply-To: <4c4b02a9-c38a-031b-db9d-fec999c64121@treenet.co.nz>
References: <59269374.1060701@mathemainzel.info>
 <4c4b02a9-c38a-031b-db9d-fec999c64121@treenet.co.nz>
Message-ID: <59272B64.20308@mathemainzel.info>

On 25.05.2017 12:50, Amos Jeffries wrote:
> On 25/05/17 20:19, Walter H. wrote:
>> Hello
>>
>> what is the essential difference between the default squid package 
>> and this squid34 package,
>
> Run "squid -v" to find out if there are any build options different. 
> Usually its just two alternative versions from the vendor.
>
Squid Cache: Version 3.4.14
configure options:  '--build=x86_64-redhat-linux-gnu' 
'--host=x86_64-redhat-linux-gnu' '--target=x86_64-redhat-linux-gnu' 
'--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' 
'--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' 
'--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' 
'--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib' 
'--mandir=/usr/share/man' '--infodir=/usr/share/info' 
'--enable-internal-dns' '--disable-strict-error-checking' 
'--exec_prefix=/usr' '--libexecdir=/usr/lib64/squid' 
'--localstatedir=/var' '--datadir=/usr/share/squid' 
'--sysconfdir=/etc/squid' '--with-logdir=$(localstatedir)/log/squid' 
'--with-pidfile=$(localstatedir)/run/squid.pid' 
'--disable-dependency-tracking' '--enable-arp-acl' 
'--enable-follow-x-forwarded-for' 
'--enable-auth-basic=LDAP,MSNT,NCSA,PAM,SMB,POP3,RADIUS,SASL,getpwnam,NIS,MSNT-multi-domain' 
'--enable-auth-ntlm=smb_lm,fake' 
'--enable-auth-digest=file,LDAP,eDirectory' 
'--enable-auth-negotiate=kerberos' 
'--enable-external-acl-helpers=file_userip,LDAP_group,session,unix_group,wbinfo_group' 
'--enable-cache-digests' '--enable-cachemgr-hostname=localhost' 
'--enable-delay-pools' '--enable-epoll' '--enable-icap-client' 
'--enable-ident-lookups' '--enable-linux-netfilter' 
'--enable-referer-log' '--enable-removal-policies=heap,lru' 
'--enable-snmp' '--enable-ssl' '--enable-storeio=aufs,diskd,ufs' 
'--enable-useragent-log' '--enable-wccpv2' '--enable-esi' 
'--enable-http-violations' '--with-aio' '--with-default-user=squid' 
'--with-filedescriptors=16384' '--with-dl' '--with-openssl' 
'--with-pthreads' '--disable-arch-native' 
'build_alias=x86_64-redhat-linux-gnu' 
'host_alias=x86_64-redhat-linux-gnu' 
'target_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall 
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 'CXXFLAGS=-O2 -g 
-pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 
'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig'

and

Squid Cache: Version 3.1.23
configure options:  '--build=x86_64-redhat-linux-gnu' 
'--host=x86_64-redhat-linux-gnu' '--target=x86_64-redhat-linux-gnu' 
'--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' 
'--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' 
'--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' 
'--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib' 
'--mandir=/usr/share/man' '--infodir=/usr/share/info' 
'--enable-internal-dns' '--disable-strict-error-checking' 
'--exec_prefix=/usr' '--libexecdir=/usr/lib64/squid' 
'--localstatedir=/var' '--datadir=/usr/share/squid' 
'--sysconfdir=/etc/squid' '--with-logdir=$(localstatedir)/log/squid' 
'--with-pidfile=$(localstatedir)/run/squid.pid' 
'--disable-dependency-tracking' '--enable-arp-acl' 
'--enable-follow-x-forwarded-for' 
'--enable-auth=basic,digest,ntlm,negotiate' 
'--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-domain-NTLM,SASL,DB,POP3,squid_radius_auth' 
'--enable-ntlm-auth-helpers=smb_lm,no_check,fakeauth' 
'--enable-digest-auth-helpers=password,ldap,eDirectory' 
'--enable-negotiate-auth-helpers=squid_kerb_auth' 
'--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,wbinfo_group' 
'--enable-cache-digests' '--enable-cachemgr-hostname=localhost' 
'--enable-delay-pools' '--enable-epoll' '--enable-icap-client' 
'--enable-ident-lookups' '--enable-linux-netfilter' 
'--enable-referer-log' '--enable-removal-policies=heap,lru' 
'--enable-snmp' '--enable-ssl' '--enable-storeio=aufs,diskd,ufs' 
'--enable-useragent-log' '--enable-wccpv2' '--enable-esi' 
'--enable-http-violations' '--with-aio' '--with-default-user=squid' 
'--with-filedescriptors=16384' '--with-dl' '--with-openssl' 
'--with-pthreads' 'build_alias=x86_64-redhat-linux-gnu' 
'host_alias=x86_64-redhat-linux-gnu' 
'target_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall 
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
--param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 'LDFLAGS=-pie' 
'CXXFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions 
-fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 
--with-squid=/builddir/build/BUILD/squid-3.1.23

>
>> as I have problems using this squid34 package for FTP connections;
>> there are no shown icons, when going to e.g. ftp://ftp.adobe.com/
>> when I tell the browser to show the image then I get this squid 
>> generated message ...
>>
>> the same config /etc/squid/squid.conf works with the default squid 
>> package ...
>>
>> <message>
>> While trying to retrieve the URL: 
>> http://proxy.local:3128/squid-internal-static/icons/silk/folder.png 
>> <http://zbox-ci323.waldinet.local:3128/squid-internal-static/icons/silk/folder.png> 
>>
>>
>
> Notice the port number in that URL...
>
yes I see the squid port 3128

when I do this with the default squid package, there I get the icons, 
and when I want to get the URL of such an icon,
it shows e.g. 
ftp://ftp.adobe.com/squid-internal-static/icons/anthony-dir.gif

when I add
global_internal_static off
to squid.conf at the squid34 package,
then there also no icons shown;
when I tell the browser to show the image then I get this squid 
generated message ...

<message>
The following URL could not be retrieved: 
ftp://ftp.adobe.com/squid-internal-static/icons/silk/folder.png

Squid sent the following FTP command:

    *

    CWD squid-internal-static

    * 

and then received this reply

    *

    Failed to change directory.

    * 

This might be caused by an FTP URL with an absolute path (which does not 
comply with RFC 1738).
If this is the cause, then the file can be found at 
ftp://ftp.adobe.com%2f2f/squid-internal-static/icons/silk/folder.png 
<ftp://ftp.adobe.com%2f/squid-internal-static/icons/silk/folder.png>.

Your cache administrator is ...

Generated Thu, 25 May 2017 18:57:52 GMT by proxy.local (squid/3.4.14)
</message>

what is running wrong here?
is there a setting I can change without having to allow
port 3128 traffic go through the proxy?
(this is not really logic, as the default squid package also doesn't 
allow port 3128 traffic go through ...)

>>
>> <squid.conf>
>> acl localnet src 192.168.1.0/24
>>
>> acl SSL_ports port 443
>> acl Safe_ports port 80          # http
>> acl Safe_ports port 21          # ftp
>> acl Safe_ports port 443         # https
>> acl Safe_ports port 70          # gopher
>
> You have removed the port range 1025-65535 from Safe_ports. So traffic 
> with URL port 3128 is no longer permitted.
I configured on the clients this
http://proxy.local:3128
as proxy ...

Thanks,
Walter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/c478bdd5/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/c478bdd5/attachment.bin>

From mcsnv96 at afo.net  Thu May 25 19:51:27 2017
From: mcsnv96 at afo.net (Mike)
Date: Thu, 25 May 2017 14:51:27 -0500
Subject: [squid-users] CentOS6 and squid34 package ...
In-Reply-To: <59272B64.20308@mathemainzel.info>
References: <59269374.1060701@mathemainzel.info>
 <4c4b02a9-c38a-031b-db9d-fec999c64121@treenet.co.nz>
 <59272B64.20308@mathemainzel.info>
Message-ID: <592735BF.5020500@afo.net>

Walter, what I've found is when compiling to squid 3.5.x and higher, the 
compile options change. Also remember that many of the options that were 
available with 3.1.x are depreciated and likely will not work with 3.4.x 
and higher.

The other issue is that squid is only supposed to be handling HTTP and 
HTTPS traffic, not FTP. trying to use it as a FTP proxy will need a 
different configuration than the standard HTTP/Secure proxy.


Mike


On 5/25/2017 14:07 PM, Walter H. wrote:
> On 25.05.2017 12:50, Amos Jeffries wrote:
>> On 25/05/17 20:19, Walter H. wrote:
>>> Hello
>>>
>>> what is the essential difference between the default squid package 
>>> and this squid34 package,
>>
>> Run "squid -v" to find out if there are any build options different. 
>> Usually its just two alternative versions from the vendor.
>>
> Squid Cache: Version 3.4.14
> configure options:  '--build=x86_64-redhat-linux-gnu' 
> '--host=x86_64-redhat-linux-gnu' '--target=x86_64-redhat-linux-gnu' 
> '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' 
> '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' 
> '--datadir=/usr/share' '--includedir=/usr/include' 
> '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' 
> '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' 
> '--infodir=/usr/share/info' '--enable-internal-dns' 
> '--disable-strict-error-checking' '--exec_prefix=/usr' 
> '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' 
> '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' 
> '--with-logdir=$(localstatedir)/log/squid' 
> '--with-pidfile=$(localstatedir)/run/squid.pid' 
> '--disable-dependency-tracking' '--enable-arp-acl' 
> '--enable-follow-x-forwarded-for' 
> '--enable-auth-basic=LDAP,MSNT,NCSA,PAM,SMB,POP3,RADIUS,SASL,getpwnam,NIS,MSNT-multi-domain' 
> '--enable-auth-ntlm=smb_lm,fake' 
> '--enable-auth-digest=file,LDAP,eDirectory' 
> '--enable-auth-negotiate=kerberos' 
> '--enable-external-acl-helpers=file_userip,LDAP_group,session,unix_group,wbinfo_group' 
> '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' 
> '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' 
> '--enable-ident-lookups' '--enable-linux-netfilter' 
> '--enable-referer-log' '--enable-removal-policies=heap,lru' 
> '--enable-snmp' '--enable-ssl' '--enable-storeio=aufs,diskd,ufs' 
> '--enable-useragent-log' '--enable-wccpv2' '--enable-esi' 
> '--enable-http-violations' '--with-aio' '--with-default-user=squid' 
> '--with-filedescriptors=16384' '--with-dl' '--with-openssl' 
> '--with-pthreads' '--disable-arch-native' 
> 'build_alias=x86_64-redhat-linux-gnu' 
> 'host_alias=x86_64-redhat-linux-gnu' 
> 'target_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall 
> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
> --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 'CXXFLAGS=-O2 -g 
> -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
> --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 
> 'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig'
>
> and
>
> Squid Cache: Version 3.1.23
> configure options:  '--build=x86_64-redhat-linux-gnu' 
> '--host=x86_64-redhat-linux-gnu' '--target=x86_64-redhat-linux-gnu' 
> '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' 
> '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' 
> '--datadir=/usr/share' '--includedir=/usr/include' 
> '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' 
> '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' 
> '--infodir=/usr/share/info' '--enable-internal-dns' 
> '--disable-strict-error-checking' '--exec_prefix=/usr' 
> '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' 
> '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' 
> '--with-logdir=$(localstatedir)/log/squid' 
> '--with-pidfile=$(localstatedir)/run/squid.pid' 
> '--disable-dependency-tracking' '--enable-arp-acl' 
> '--enable-follow-x-forwarded-for' 
> '--enable-auth=basic,digest,ntlm,negotiate' 
> '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-domain-NTLM,SASL,DB,POP3,squid_radius_auth' 
> '--enable-ntlm-auth-helpers=smb_lm,no_check,fakeauth' 
> '--enable-digest-auth-helpers=password,ldap,eDirectory' 
> '--enable-negotiate-auth-helpers=squid_kerb_auth' 
> '--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,wbinfo_group' 
> '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' 
> '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' 
> '--enable-ident-lookups' '--enable-linux-netfilter' 
> '--enable-referer-log' '--enable-removal-policies=heap,lru' 
> '--enable-snmp' '--enable-ssl' '--enable-storeio=aufs,diskd,ufs' 
> '--enable-useragent-log' '--enable-wccpv2' '--enable-esi' 
> '--enable-http-violations' '--with-aio' '--with-default-user=squid' 
> '--with-filedescriptors=16384' '--with-dl' '--with-openssl' 
> '--with-pthreads' 'build_alias=x86_64-redhat-linux-gnu' 
> 'host_alias=x86_64-redhat-linux-gnu' 
> 'target_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall 
> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
> --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 'LDFLAGS=-pie' 
> 'CXXFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions 
> -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 
> --with-squid=/builddir/build/BUILD/squid-3.1.23
>
>>
>>> as I have problems using this squid34 package for FTP connections;
>>> there are no shown icons, when going to e.g. ftp://ftp.adobe.com/
>>> when I tell the browser to show the image then I get this squid 
>>> generated message ...
>>>
>>> the same config /etc/squid/squid.conf works with the default squid 
>>> package ...
>>>
>>> <message>
>>> While trying to retrieve the URL: 
>>> http://proxy.local:3128/squid-internal-static/icons/silk/folder.png 
>>> <http://zbox-ci323.waldinet.local:3128/squid-internal-static/icons/silk/folder.png> 
>>>
>>>
>>
>> Notice the port number in that URL...
>>
> yes I see the squid port 3128
>
> when I do this with the default squid package, there I get the icons, 
> and when I want to get the URL of such an icon,
> it shows e.g. 
> ftp://ftp.adobe.com/squid-internal-static/icons/anthony-dir.gif
>
> when I add
> global_internal_static off
> to squid.conf at the squid34 package,
> then there also no icons shown;
> when I tell the browser to show the image then I get this squid 
> generated message ...
>
> <message>
> The following URL could not be retrieved: 
> ftp://ftp.adobe.com/squid-internal-static/icons/silk/folder.png
>
> Squid sent the following FTP command:
>
>     *
>
>     CWD squid-internal-static
>
>     * 
>
> and then received this reply
>
>     *
>
>     Failed to change directory.
>
>     * 
>
> This might be caused by an FTP URL with an absolute path (which does 
> not comply with RFC 1738).
> If this is the cause, then the file can be found at 
> ftp://ftp.adobe.com%2f2f/squid-internal-static/icons/silk/folder.png 
> <ftp://ftp.adobe.com%2f/squid-internal-static/icons/silk/folder.png>.
>
> Your cache administrator is ...
>
> Generated Thu, 25 May 2017 18:57:52 GMT by proxy.local (squid/3.4.14)
> </message>
>
> what is running wrong here?
> is there a setting I can change without having to allow
> port 3128 traffic go through the proxy?
> (this is not really logic, as the default squid package also doesn't 
> allow port 3128 traffic go through ...)
>
>>>
>>> <squid.conf>
>>> acl localnet src 192.168.1.0/24
>>>
>>> acl SSL_ports port 443
>>> acl Safe_ports port 80          # http
>>> acl Safe_ports port 21          # ftp
>>> acl Safe_ports port 443         # https
>>> acl Safe_ports port 70          # gopher
>>
>> You have removed the port range 1025-65535 from Safe_ports. So 
>> traffic with URL port 3128 is no longer permitted.
> I configured on the clients this
> http://proxy.local:3128
> as proxy ...
>
> Thanks,
> Walter
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/ca422116/attachment.htm>

From mlifshin at phantomdesign.com  Fri May 26 06:00:53 2017
From: mlifshin at phantomdesign.com (Masha Lifshin)
Date: Thu, 25 May 2017 23:00:53 -0700
Subject: [squid-users] Help troubleshooting proxy<-->client https
Message-ID: <CA+8Eki3Z=YK-6m7gTdomx2FDJCt0wfTs=rYteY+NM=Lksk8wig@mail.gmail.com>

Hello Dear Squid Users,

I am trying to configure my Squid 4.0.17 to use an https connection between
the client and the proxy.  I have added an https_port directive to
squid.conf, but it must be misconfigured. When I test with a dev version of
curl that supports https proxies, I am getting
ERR_PROTOCOL_UNKNOWN errors.  Below is the curl output, my squid.conf, and
access.log and cache.log snippets.

I appreciate any insights that you can offer.  Thank you very much,
-Masha


----------------------------------------
curl output
----------------------------------------
$ ~/bin/curl -v -x https://proxy.somwhere.com:443 https://github.com
* Rebuilt URL to: https://github.com/
*   Trying 54.210.69.61...
* TCP_NODELAY set
* Connected to proxy.somwhere.com (54.210.69.61) port 443 (#0)
* ALPN, offering http/1.1
* Cipher selection:
ALL:!EXPORT:!EXPORT40:!EXPORT56:!aNULL:!LOW:!RC4:@STRENGTH
* successfully set certificate verify locations:
*   CAfile: /etc/ssl/cert.pem
  CApath: none
* TLSv1.2 (OUT), TLS header, Certificate Status (22):
* TLSv1.2 (OUT), TLS handshake, Client hello (1):
* error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol
* Closing connection 0
curl: (35) error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown
protocol

----------------------------------------
squid.conf
----------------------------------------
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7   # RFC 4193 local private network range
acl localnet src fe80::/10  # RFC 4291 link-local (directly plugged)
machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 81          # http
acl Safe_ports port 800         # http
acl Safe_ports port 8000        # http
acl Safe_ports port 8080        # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl SSL method CONNECT
acl CONNECT method CONNECT

# Only allow cachemgr access from localhost
http_access allow manager to_localhost
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

http_access deny to_localhost

# ICAP CONFIG
icp_access deny all
htcp_access deny all

http_port 172.30.0.67:443 ssl-bump cert=/path/to/some.cert.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
tls-dh=/usr/local/squid/etc/dhparam.pem
https_port 172.30.0.67:443 cert=/path/to/other.cert.pem
cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all

access_log stdio:/usr/local/squid/var/log/access.log custom
cache_store_log stdio:/usr/local/squid/var/log/store.log custom
log_mime_hdrs on

pid_filename /usr/local/squid/var/run/custom-squid.pid

# Leave coredumps in the first cache dir
coredump_dir /usr/local/squid/var/cache

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

request_header_access Proxy-Authenticate deny all
request_header_access Proxy-Authentication-Info deny all
request_header_access Proxy-Authorization deny all
request_header_access Proxy-Connection deny all
request_header_access Proxy-support deny all
request_header_access custom-version deny all
request_header_access custom-watermark deny all
request_header_access custom-token deny all
request_header_access custom-parent-host deny all
request_header_access Via deny all
request_header_access X-Cache deny all
request_header_access X-Cache-Lookup deny all
request_header_access X-Forwarded-For deny all
reply_header_access X-XSS-Protection deny all
request_header_access Other allow all

cache_mgr cache_mgr at somewhere.com
mail_from squid at somewhere.com
icap_enable on
icap_preview_enable on
icap_preview_size 1024
icap_default_options_ttl 60
icap_persistent_connections on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_header X-Client-Username
icap_client_username_encode off

ecap_enable on
loadable_modules /usr/local/squid/modules/libcustom_ecap.so
ecap_service custom_validate_req reqmod_precache ecap://
somewhere.com/ecap/services/validate routing=on bypass=off
ecap_service custom_validate_resp respmod_precache ecap://
somewhere.com/ecap/services/validate routing=on bypass=off
#adaptation_access custom_validate allow all

icap_service custom_req reqmod_precache routing=on icap://
127.0.0.1:1344/custom_req
icap_service custom_resp respmod_precache routing=on icap://
127.0.0.1:1344/custom_resp
forwarded_for delete

# Define a service set for requests. The first service (eCAP) will
# process the request if the API token is in the local cache, and the
# user has the "Access Only" preference set. Otherwise eCAP will abort,
# causing Squid to fail over to ICAP to handle the request.
adaptation_service_set custom_req_set custom_validate_req custom_req
adaptation_service_set custom_resp_set custom_validate_resp custom_resp

adaptation_access custom_req_set allow all
adaptation_access custom_resp_set allow all

# Never stop trying to talk to the ICAP server, no matter how many times it
fails.
icap_service_failure_limit -1

# Squid uses numeric categories to control logging.
# Interesting categories:
#   93        ICAP
# debug_options ALL,3 44,0 23,0 40,0 73,0 93,3
debug_options  ALL,1 11,2 74,9,93,3
(END)



----------------------------------------
access.log
----------------------------------------
 [26/May/2017:05:35:50 +0000] "NONE error:invalid-request HTTP/1.1" 400 3824



----------------------------------------
cache.log
----------------------------------------
2017/05/26 05:35:50.115 kid1| 74,9| RequestParser.cc(359) doParse: Parse
buf={length=517, data='
2017/05/26 05:35:50.115 kid1| 74,5| RequestParser.cc(284)
parseRequestFirstLine: parsing possible request: buf.length=517
2017/05/26 05:35:50.115 kid1| 74,9| RequestParser.cc(285)
parseRequestFirstLine:
2017/05/26 05:35:50.115 kid1| 74,5| RequestParser.cc(382) doParse:
request-line: retval -1: line={517, data='
2017/05/26 05:35:50.115 kid1| 74,5| RequestParser.cc(383) doParse:
request-line: method: NONE
2017/05/26 05:35:50.115 kid1| 74,5| RequestParser.cc(384) doParse:
request-line: url:
2017/05/26 05:35:50.115 kid1| 74,5| RequestParser.cc(385) doParse:
request-line: proto: NONE/0.0
2017/05/26 05:35:50.115 kid1| 74,5| RequestParser.cc(386) doParse: Parser:
bytes processed=0
2017/05/26 05:35:50.115 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP
Client local=172.30.0.67:443 remote=75.147.129.242:64540 FD 11 flags=1
2017/05/26 05:35:50.115 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP
Client REPLY:
---------
HTTP/1.1 400 Bad Request
Server: squid/4.0.17
Mime-Version: 1.0
Date: Fri, 26 May 2017 05:35:50 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3394
X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
Vary: Accept-Language
Content-Language: en
X-Cache: MISS from ip-172-30-0-67.ec2.internal
X-Cache-Lookup: NONE from ip-172-30-0-67.ec2.internal:443
Via: 1.1 ip-172-30-0-67.ec2.internal (squid/4.0.17)
Connection: close


----------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170525/c0d9c8b6/attachment.htm>

From eduardoocarneiro at gmail.com  Fri May 26 13:09:35 2017
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Fri, 26 May 2017 06:09:35 -0700 (PDT)
Subject: [squid-users] Youtube not TCP_HIT Squid3.5.21-25
In-Reply-To: <1495745270225-4682582.post@n4.nabble.com>
References: <1495745270225-4682582.post@n4.nabble.com>
Message-ID: <1495804175132-4682584.post@n4.nabble.com>

I have the same issue. And not just Youtube, but any dynamic content cache.
If you need to rewrite doesn't work.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Youtube-not-TCP-HIT-Squid3-5-21-25-tp4682582p4682584.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Fri May 26 13:45:57 2017
From: yvoinov at gmail.com (Yuri)
Date: Fri, 26 May 2017 19:45:57 +0600
Subject: [squid-users] Youtube not TCP_HIT Squid3.5.21-25
In-Reply-To: <1495804175132-4682584.post@n4.nabble.com>
References: <1495745270225-4682582.post@n4.nabble.com>
 <1495804175132-4682584.post@n4.nabble.com>
Message-ID: <05237d2a-b83a-4602-323f-f9b34b1c3a6f@gmail.com>

With defrosting! Welcome from the cryocamera outside :-D

http://wiki.squid-cache.org/ConfigExamples/DynamicContent/YouTube/Discussion


26.05.2017 19:09, Eduardo Carneiro ?????:
> I have the same issue. And not just Youtube, but any dynamic content cache.
> If you need to rewrite doesn't work.
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Youtube-not-TCP-HIT-Squid3-5-21-25-tp4682582p4682584.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Fri May 26 14:19:04 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 26 May 2017 08:19:04 -0600
Subject: [squid-users] Help troubleshooting proxy<-->client https
In-Reply-To: <CA+8Eki3Z=YK-6m7gTdomx2FDJCt0wfTs=rYteY+NM=Lksk8wig@mail.gmail.com>
References: <CA+8Eki3Z=YK-6m7gTdomx2FDJCt0wfTs=rYteY+NM=Lksk8wig@mail.gmail.com>
Message-ID: <e2870567-f0b7-fae8-615b-9dbb8dd49ddb@measurement-factory.com>

On 05/26/2017 12:00 AM, Masha Lifshin wrote:
> I have added an https_port directive
> to squid.conf, but it must be misconfigured.

> http_port 172.30.0.67:443 ...
> https_port 172.30.0.67:443 ...

You are right -- your Squid is misconfigured. You cannot use the same
address for two ports. Unfortunately, Squid thinks that port binding
errors are a minor inconvenience and continues running after logging an
error message (that looks like many other benign error messages).

Changing one of the ports will solve the "same address" problem
described above.

Do not use port 443 for http_port. It makes triage extremely confusing
because port 443 usually implies SSL. Consider using port 3128 instead.


HTH,

Alex.



From junior.cunha at hscbrasil.com.br  Fri May 26 15:27:32 2017
From: junior.cunha at hscbrasil.com.br (Junior Cunha)
Date: Fri, 26 May 2017 12:27:32 -0300 (BRT)
Subject: [squid-users] Repeated assertions
In-Reply-To: <67279393.403.1495812419822.JavaMail.root@hscbrasil.com.br>
Message-ID: <569432405.404.1495812451993.JavaMail.root@hscbrasil.com.br>

Hi all,

   We are facing a strange problem with a squid 3.5.25 installation in one of our customers. Every minute an assertion like this "assertion failed: Read.cc:73: "fd_table[conn->fd].halfClosedReader != NULL" can be seen in the cache.log file. Below some information related to our current setup:

   - 2 physical servers running Squid 3.5.25 ( 1 instance per machine ) linked with OpenSSL 1.0.1e-57
   - haproxy to provide load balancing between the nodes + keepalived to provide vip
   - ~3000 users
   - diskd for cache
   - ssl bump enabled (config below)

http_port 58080 require-proxy-header dynamic_cert_mem_cache_size=1KB generate-host-certificates=on ssl-bump cert=/opt/hsc/webcontrol/squid/etc/ssl/myCA.pem sslflags=NO_DEFAULT_CA

   (...)

acl s1_tls_connect at_step SslBump1
sslproxy_cipher ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDSA-RSA-AES256-SHA:ECDSA-RSA-AES256:ECDHE-RSA-AES256-SHA:DHE-RSA-AES256-SHA:AES256-SHA:ECDHE-RSA-RC4-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-SHA:DHE-RSA-CAMELLIA128-SHA:AES128-SHA:RC4-SHA:HIGH:!aNULL:!MD5:!ADH
ssl_bump peek s1_tls_connect
ssl_bump bump all

   We have no idea why this is happening since we have another customer with the same setup and this doesn't happen.

   Could someone please help us to solve this problem? Our company is willing to pay for any kind of help (in this case contact me directly via e-mail or skype "juniorcunha.rs").

   Best regards.

   []s

--
Junior Cunha
HSC Brasil
telefone  55 (51) 3216-7007 | Porto Alegre
telefone  55 (11) 3522-8191 | S?o Paulo
site:  www.hscbrasil.com.br



From rentorbuy at yahoo.com  Fri May 26 15:44:02 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Fri, 26 May 2017 15:44:02 +0000 (UTC)
Subject: [squid-users] Squid TPROXY issues with Google sites
References: <589790035.698921.1495813442972.ref@mail.yahoo.com>
Message-ID: <589790035.698921.1495813442972@mail.yahoo.com>

Hi,

I'd like to block access to Google Mail but allow it to Google Drive. I also need to intercept Google Drive traffic (https) and scan its content via c-icap modules for threats (with clamav and other tools which would block potentially harmful files).

I've failed so far.

I added mail.google.com to a custom file named "denied.domains" and loaded as denied_domains ACL in Squid. I know that in TLS traffic there are only IP addresses, so I created the "server_name" ACL as seen below.

[...]
acl denied_domains dstdomain "/usr/local/share/proxy-settings/denied.domains"
http_access deny denied_domains !allowed_groups !allowed_ips
http_access deny CONNECT denied_domains !allowed_groups !allowed_ips
[...]
reply_header_access Alternate-Protocol deny all
acl AllowTroublesome ssl::server_name .google.com .gmail.com
acl DenyTroublesome ssl::server_name mail.google.com
http_access deny DenyTroublesome
ssl_bump peek all
ssl_bump splice AllowTroublesome
ssl_bump bump all

First of all, I was expecting that if a client tried to open https://mail.google.com, the connection would be blocked by Squid (DenyTroublesome ACL). It isn't. Why?

Second, I am unable to scan content since Squid is splicing all Google traffic. However, if I "bump AllowTroublesome", I can enter my username in https://accounts.google.com, but trying to access to the next step (user password) fails with an unreported error.

Any suggestions?

Vieri


From squid3 at treenet.co.nz  Fri May 26 15:49:25 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 27 May 2017 03:49:25 +1200
Subject: [squid-users] CentOS6 and squid34 package ...
In-Reply-To: <592735BF.5020500@afo.net>
References: <59269374.1060701@mathemainzel.info>
 <4c4b02a9-c38a-031b-db9d-fec999c64121@treenet.co.nz>
 <59272B64.20308@mathemainzel.info> <592735BF.5020500@afo.net>
Message-ID: <550c2028-c49f-70d4-2501-22d56148abd8@treenet.co.nz>

On 26/05/17 07:51, Mike wrote:
> Walter, what I've found is when compiling to squid 3.5.x and higher, 
> the compile options change. Also remember that many of the options 
> that were available with 3.1.x are depreciated and likely will not 
> work with 3.4.x and higher.
>
> The other issue is that squid is only supposed to be handling HTTP and 
> HTTPS traffic, not FTP. trying to use it as a FTP proxy will need a 
> different configuration than the standard HTTP/Secure proxy.
>

Well, to be correct Squid talks HTTP to the client software. It has log 
supported mapping FTP server URLs into HTTP.

This second problem seems like the symptoms of 
<http://bugs.squid-cache.org/show_bug.cgi?id=4132> which was fixed years 
ago in the Squid-3.5.5 release. But that was apparently a regression not 
affecting 3.4 or 3.1. Hmm.


Amos


>
> Mike
>
>
> On 5/25/2017 14:07 PM, Walter H. wrote:
>> On 25.05.2017 12:50, Amos Jeffries wrote:
>>> On 25/05/17 20:19, Walter H. wrote:
>>>> Hello
>>>>
>>>> what is the essential difference between the default squid package 
>>>> and this squid34 package,
>>>
>>> Run "squid -v" to find out if there are any build options different. 
>>> Usually its just two alternative versions from the vendor.
>>>
>> Squid Cache: Version 3.4.14
>> configure options:  '--build=x86_64-redhat-linux-gnu' 
>> '--host=x86_64-redhat-linux-gnu' '--target=x86_64-redhat-linux-gnu' 
>> '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' 
>> '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' 
>> '--datadir=/usr/share' '--includedir=/usr/include' 
>> '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' 
>> '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' 
>> '--infodir=/usr/share/info' '--enable-internal-dns' 
>> '--disable-strict-error-checking' '--exec_prefix=/usr' 
>> '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' 
>> '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' 
>> '--with-logdir=$(localstatedir)/log/squid' 
>> '--with-pidfile=$(localstatedir)/run/squid.pid' 
>> '--disable-dependency-tracking' '--enable-arp-acl' 
>> '--enable-follow-x-forwarded-for' 
>> '--enable-auth-basic=LDAP,MSNT,NCSA,PAM,SMB,POP3,RADIUS,SASL,getpwnam,NIS,MSNT-multi-domain' 
>> '--enable-auth-ntlm=smb_lm,fake' 
>> '--enable-auth-digest=file,LDAP,eDirectory' 
>> '--enable-auth-negotiate=kerberos' 
>> '--enable-external-acl-helpers=file_userip,LDAP_group,session,unix_group,wbinfo_group' 
>> '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' 
>> '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' 
>> '--enable-ident-lookups' '--enable-linux-netfilter' 
>> '--enable-referer-log' '--enable-removal-policies=heap,lru' 
>> '--enable-snmp' '--enable-ssl' '--enable-storeio=aufs,diskd,ufs' 
>> '--enable-useragent-log' '--enable-wccpv2' '--enable-esi' 
>> '--enable-http-violations' '--with-aio' '--with-default-user=squid' 
>> '--with-filedescriptors=16384' '--with-dl' '--with-openssl' 
>> '--with-pthreads' '--disable-arch-native' 
>> 'build_alias=x86_64-redhat-linux-gnu' 
>> 'host_alias=x86_64-redhat-linux-gnu' 
>> 'target_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall 
>> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
>> --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 'CXXFLAGS=-O2 -g 
>> -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
>> --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 
>> 'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig'
>>
>> and
>>
>> Squid Cache: Version 3.1.23
>> configure options:  '--build=x86_64-redhat-linux-gnu' 
>> '--host=x86_64-redhat-linux-gnu' '--target=x86_64-redhat-linux-gnu' 
>> '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' 
>> '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' 
>> '--datadir=/usr/share' '--includedir=/usr/include' 
>> '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' 
>> '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' 
>> '--infodir=/usr/share/info' '--enable-internal-dns' 
>> '--disable-strict-error-checking' '--exec_prefix=/usr' 
>> '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' 
>> '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' 
>> '--with-logdir=$(localstatedir)/log/squid' 
>> '--with-pidfile=$(localstatedir)/run/squid.pid' 
>> '--disable-dependency-tracking' '--enable-arp-acl' 
>> '--enable-follow-x-forwarded-for' 
>> '--enable-auth=basic,digest,ntlm,negotiate' 
>> '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SMB,YP,getpwnam,multi-domain-NTLM,SASL,DB,POP3,squid_radius_auth' 
>> '--enable-ntlm-auth-helpers=smb_lm,no_check,fakeauth' 
>> '--enable-digest-auth-helpers=password,ldap,eDirectory' 
>> '--enable-negotiate-auth-helpers=squid_kerb_auth' 
>> '--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,wbinfo_group' 
>> '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' 
>> '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' 
>> '--enable-ident-lookups' '--enable-linux-netfilter' 
>> '--enable-referer-log' '--enable-removal-policies=heap,lru' 
>> '--enable-snmp' '--enable-ssl' '--enable-storeio=aufs,diskd,ufs' 
>> '--enable-useragent-log' '--enable-wccpv2' '--enable-esi' 
>> '--enable-http-violations' '--with-aio' '--with-default-user=squid' 
>> '--with-filedescriptors=16384' '--with-dl' '--with-openssl' 
>> '--with-pthreads' 'build_alias=x86_64-redhat-linux-gnu' 
>> 'host_alias=x86_64-redhat-linux-gnu' 
>> 'target_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall 
>> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector 
>> --param=ssp-buffer-size=4 -m64 -mtune=generic -fpie' 'LDFLAGS=-pie' 
>> 'CXXFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions 
>> -fstack-protector --param=ssp-buffer-size=4 -m64 -mtune=generic 
>> -fpie' --with-squid=/builddir/build/BUILD/squid-3.1.23
>>
>>>
>>>> as I have problems using this squid34 package for FTP connections;
>>>> there are no shown icons, when going to e.g. ftp://ftp.adobe.com/
>>>> when I tell the browser to show the image then I get this squid 
>>>> generated message ...
>>>>
>>>> the same config /etc/squid/squid.conf works with the default squid 
>>>> package ...
>>>>
>>>> <message>
>>>> While trying to retrieve the URL: 
>>>> http://proxy.local:3128/squid-internal-static/icons/silk/folder.png 
>>>> <http://zbox-ci323.waldinet.local:3128/squid-internal-static/icons/silk/folder.png> 
>>>>
>>>>
>>>
>>> Notice the port number in that URL...
>>>
>> yes I see the squid port 3128
>>
>> when I do this with the default squid package, there I get the icons, 
>> and when I want to get the URL of such an icon,
>> it shows e.g. 
>> ftp://ftp.adobe.com/squid-internal-static/icons/anthony-dir.gif
>>
>> when I add
>> global_internal_static off
>> to squid.conf at the squid34 package,
>> then there also no icons shown;
>> when I tell the browser to show the image then I get this squid 
>> generated message ...
>>
>> <message>
>> The following URL could not be retrieved: 
>> ftp://ftp.adobe.com/squid-internal-static/icons/silk/folder.png
>>
>> Squid sent the following FTP command:
>>
>>     *
>>
>>     CWD squid-internal-static
>>
>>     * 
>>
>> and then received this reply
>>
>>     *
>>
>>     Failed to change directory.
>>
>>     * 
>>
>> This might be caused by an FTP URL with an absolute path (which does 
>> not comply with RFC 1738).
>> If this is the cause, then the file can be found at 
>> ftp://ftp.adobe.com%2f2f/squid-internal-static/icons/silk/folder.png.
>>
>> Your cache administrator is ...
>>
>> Generated Thu, 25 May 2017 18:57:52 GMT by proxy.local (squid/3.4.14)
>> </message>
>>
>> what is running wrong here?
>> is there a setting I can change without having to allow
>> port 3128 traffic go through the proxy?
>> (this is not really logic, as the default squid package also doesn't 
>> allow port 3128 traffic go through ...)

Er, it is using the recommended default config we ship from upstream. 
Some Vendors like to install packages that are not usable without manual 
attention. Usually by commenting out the "http_access allow localnet" 
rule though, not marking registered HTTP ports as unsafe for use with HTTP.

Anyhow:

  acl Safe_ports port 3128
  acl port3128 port 3128
  acl squid-internal urlpath_regex ^/squid-internal

Then add this directly before the "deny manager" line:

   http_access deny port3128 !squid-internal


Amos



From webmaster at squidblacklist.org  Fri May 26 15:54:08 2017
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Fri, 26 May 2017 10:54:08 -0500
Subject: [squid-users] Squid TPROXY issues with Google sites
In-Reply-To: <589790035.698921.1495813442972@mail.yahoo.com>
References: <589790035.698921.1495813442972.ref@mail.yahoo.com>
 <589790035.698921.1495813442972@mail.yahoo.com>
Message-ID: <875e7a29-0dd7-f099-009f-beeb6edf7ef5@squidblacklist.org>

Here is a list of google domains that may help you,

http://www.squidblacklist.org/downloads/whitelists/google.domains


On 5/26/2017 10:44 AM, Vieri wrote:
> Hi,
>
> I'd like to block access to Google Mail but allow it to Google Drive. I also need to intercept Google Drive traffic (https) and scan its content via c-icap modules for threats (with clamav and other tools which would block potentially harmful files).
>
> I've failed so far.
>
> I added mail.google.com to a custom file named "denied.domains" and loaded as denied_domains ACL in Squid. I know that in TLS traffic there are only IP addresses, so I created the "server_name" ACL as seen below.
>
> [...]
> acl denied_domains dstdomain "/usr/local/share/proxy-settings/denied.domains"
> http_access deny denied_domains !allowed_groups !allowed_ips
> http_access deny CONNECT denied_domains !allowed_groups !allowed_ips
> [...]
> reply_header_access Alternate-Protocol deny all
> acl AllowTroublesome ssl::server_name .google.com .gmail.com
> acl DenyTroublesome ssl::server_name mail.google.com
> http_access deny DenyTroublesome
> ssl_bump peek all
> ssl_bump splice AllowTroublesome
> ssl_bump bump all
>
> First of all, I was expecting that if a client tried to open https://mail.google.com, the connection would be blocked by Squid (DenyTroublesome ACL). It isn't. Why?
>
> Second, I am unable to scan content since Squid is splicing all Google traffic. However, if I "bump AllowTroublesome", I can enter my username in https://accounts.google.com, but trying to access to the next step (user password) fails with an unreported error.
>
> Any suggestions?
>
> Vieri
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
--

Signed,

Benjamin E. Nichols
http://www.squidblacklist.org

1-405-397-1360 - Call Anytime.



From acctforjunk at yahoo.com  Fri May 26 16:17:23 2017
From: acctforjunk at yahoo.com (j m)
Date: Fri, 26 May 2017 16:17:23 +0000 (UTC)
Subject: [squid-users] TCP_DENIED/407 accessing webserver on same machine as
	squid
References: <1249825632.662768.1495815443782.ref@mail.yahoo.com>
Message-ID: <1249825632.662768.1495815443782@mail.yahoo.com>

I have a webserver and squid 3.5 running on the same Linux machine.? The webserver is actually part of shellinabox, so it's only for me to access.? Shellinabox simply presents a terminal and login in a web browser.? I want it to be accessible only through squid for more security.
shellinabox works fine if I access it directly, but through squid I see this in access.log:
1495813953.860 79 204.155.22.30 TCP_TUNNEL/200 1440 CONNECT IP:PORT USER HIER_DIRECT/IP 
1495813962.001 0 204.155.22.30 TCP_DENIED/407 4397 CONNECT IP:PORT USER HIER_NONE/- text/html 

I've replaced the real IP, PORT, and USER with those words, however the real PORT is a nonstandard port number. There are some other posts I found mentioning a 407 error and it was said it occurs when the webpage is asking for authentication. However I don't understand this, since shellinabox only display a login prompt which I wouldn't think would be a problem. Another post said a 407 is when squid auth is failing, but I can get to external websites through squid.

Does it matter that what I'm trying to access is HTTPS instead of HTTP?


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170526/fc7dc4b4/attachment.htm>

From rousskov at measurement-factory.com  Fri May 26 16:44:35 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 26 May 2017 10:44:35 -0600
Subject: [squid-users] Squid TPROXY issues with Google sites
In-Reply-To: <589790035.698921.1495813442972@mail.yahoo.com>
References: <589790035.698921.1495813442972.ref@mail.yahoo.com>
 <589790035.698921.1495813442972@mail.yahoo.com>
Message-ID: <3e1861f4-ae5d-d199-131a-d5a0601c7e3e@measurement-factory.com>

On 05/26/2017 09:44 AM, Vieri wrote:

> I know that in TLS traffic there are only IP addresses

This is a gross exaggeration. The reality is much more nuanced.


> I added mail.google.com to a custom file named "denied.domains" and loaded as denied_domains ACL in Squid. 

> [...]
> acl denied_domains dstdomain "/usr/local/share/proxy-settings/denied.domains"
> http_access deny denied_domains !allowed_groups !allowed_ips
> http_access deny CONNECT denied_domains !allowed_groups !allowed_ips
> [...]
> reply_header_access Alternate-Protocol deny all
> acl AllowTroublesome ssl::server_name .google.com .gmail.com
> acl DenyTroublesome ssl::server_name mail.google.com
> http_access deny DenyTroublesome
> ssl_bump peek all
> ssl_bump splice AllowTroublesome
> ssl_bump bump all


> First of all, I was expecting that if a client tried to open
> https://mail.google.com, the connection would be blocked by Squid
> (DenyTroublesome ACL). It isn't. Why?

If a transaction is not blocked, then you have an http_access rule that
allows it. You need to figure out which rule does that. You can figure
that out by studying debugging logs, adding/logging annotate_transaction
ACLs, and/or altering http_access rules.


> Second, I am unable to scan content since Squid is splicing all
> Google traffic.

You told Squid to bump nothing because nothing can be bumped after
"ssl_bump peek all". You may want to study the following wiki page,
including definitions of actions such as "peek" and examples.

    http://wiki.squid-cache.org/Features/SslPeekAndSplice

Alex.



From squid3 at treenet.co.nz  Fri May 26 16:55:40 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 27 May 2017 04:55:40 +1200
Subject: [squid-users] Repeated assertions
In-Reply-To: <569432405.404.1495812451993.JavaMail.root@hscbrasil.com.br>
References: <569432405.404.1495812451993.JavaMail.root@hscbrasil.com.br>
Message-ID: <2a2beb37-df49-9b31-5fa0-5eecc91677e0@treenet.co.nz>

On 27/05/17 03:27, Junior Cunha wrote:
> Hi all,
>
>     We are facing a strange problem with a squid 3.5.25 installation in one of our customers. Every minute an assertion like this "assertion failed: Read.cc:73: "fd_table[conn->fd].halfClosedReader != NULL" can be seen in the cache.log file. Below some information related to our current setup:

<http://bugs.squid-cache.org/show_bug.cgi?id=4270>

Some of the changes in 4.0.16 - 4.0.19 (beta) releases seem to have 
resolved it though not clear which, so I'm bit doubtful the 3.5 stable 
series will see a fix any time soon.

I recommend for you to try the 4.0 even though it is a beta. The bumping 
feature there is a bit better than in 3.5.

Amos



From rousskov at measurement-factory.com  Fri May 26 16:59:29 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 26 May 2017 10:59:29 -0600
Subject: [squid-users] Repeated assertions
In-Reply-To: <569432405.404.1495812451993.JavaMail.root@hscbrasil.com.br>
References: <569432405.404.1495812451993.JavaMail.root@hscbrasil.com.br>
Message-ID: <82bcf1de-4dfe-90fc-dac1-acd6c83e614e@measurement-factory.com>

On 05/26/2017 09:27 AM, Junior Cunha wrote:

> We are facing a strange problem with a squid 3.5.25 installation in
> one of our customers. Every minute an assertion like this "assertion
> failed: Read.cc:73: "fd_table[conn->fd].halfClosedReader != NULL" can
> be seen in the cache.log file.

Could be http://bugs.squid-cache.org/show_bug.cgi?id=4554
and/or http://bugs.squid-cache.org/show_bug.cgi?id=4270

If you can collect a stack trace from that assertion, please post it to
the first bugzilla link mentioned above. A stack trace may help
developers fix this bug. AFAIK, nobody is working on that fix right now
though :-(.


Thank you,

Alex.



From squid3 at treenet.co.nz  Fri May 26 17:00:07 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 27 May 2017 05:00:07 +1200
Subject: [squid-users] Squid TPROXY issues with Google sites
In-Reply-To: <589790035.698921.1495813442972@mail.yahoo.com>
References: <589790035.698921.1495813442972.ref@mail.yahoo.com>
 <589790035.698921.1495813442972@mail.yahoo.com>
Message-ID: <f00f4540-6a5b-ffa3-aa3d-8a4e33d366a4@treenet.co.nz>

On 27/05/17 03:44, Vieri wrote:
> Hi,
>
> I'd like to block access to Google Mail but allow it to Google Drive. I also need to intercept Google Drive traffic (https) and scan its content via c-icap modules for threats (with clamav and other tools which would block potentially harmful files).
>
> I've failed so far.
>
> I added mail.google.com to a custom file named "denied.domains" and loaded as denied_domains ACL in Squid. I know that in TLS traffic there are only IP addresses, so I created the "server_name" ACL as seen below.

Erm, not quite. The raw-IP having to be dealt with comes from the use of 
TPROXY (or NAT), not TLS. It is used when Squid is deciding whether to 
permit the traffic on the TCP connection to be processed.

Once the TLS is received (by "peek") the TLS SNI (if any) becomes available.


> [...]
> acl denied_domains dstdomain "/usr/local/share/proxy-settings/denied.domains"
> http_access deny denied_domains !allowed_groups !allowed_ips
> http_access deny CONNECT denied_domains !allowed_groups !allowed_ips
> [...]
> reply_header_access Alternate-Protocol deny all
> acl AllowTroublesome ssl::server_name .google.com .gmail.com
> acl DenyTroublesome ssl::server_name mail.google.com
> http_access deny DenyTroublesome
> ssl_bump peek all
> ssl_bump splice AllowTroublesome
> ssl_bump bump all
>
> First of all, I was expecting that if a client tried to open https://mail.google.com, the connection would be blocked by Squid (DenyTroublesome ACL). It isn't. Why?

Any of the http_access lines you omitted from the config snippet might 
be letting it through. Order is important, and knowing the whole 
http_access sequence (and more) is just as important to correctly answer 
a question such as this. So take the below with a grain of salt, I am 
assuming nothing else in your config has subtle effects on the 
processing outcome.

There are several things that can lead to it;

* Google servers do have working rDNS. So raw-IP becomes a server 
hostname for dstdomain ACL to match.
  - the rDNS is within *.1e1.net so will not match your list shown, but 
it is enough to possibly evade your IP rules.

* If no provides access control lines match Squid inverted the action on 
the last one and does that.
   - yours are all deny, so the implicit action there is "allow all"

* "ssl_bump peek all" fetches the TLS SNI server name for 
ssl::server_name ACL to match.
  - so by the time Squid gets to processing the AllowTroublesome it 
already knows the client is trying to reach a *.google.com domain.

> Second, I am unable to scan content since Squid is splicing all Google traffic. However, if I "bump AllowTroublesome", I can enter my username in https://accounts.google.com, but trying to access to the next step (user password) fails with an unreported error.
>
> Any suggestions?

The rest of your related squid.conf is needed for that, including 
details of the files includes into the ACLs. In particular it is not 
clear what this "unreported error" is or why it happens.

Amos



From squid3 at treenet.co.nz  Fri May 26 17:28:51 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 27 May 2017 05:28:51 +1200
Subject: [squid-users] TCP_DENIED/407 accessing webserver on same
 machine as squid
In-Reply-To: <1249825632.662768.1495815443782@mail.yahoo.com>
References: <1249825632.662768.1495815443782.ref@mail.yahoo.com>
 <1249825632.662768.1495815443782@mail.yahoo.com>
Message-ID: <e7957308-0a94-fa66-960d-2bb508c49729@treenet.co.nz>



On 27/05/17 04:17, j m wrote:
> I have a webserver and squid 3.5 running on the same Linux machine.  > The webserver is actually part of shellinabox, so it's only for me 
to > access.  Shellinabox simply presents a terminal and login in a web 
 > browser.  I want it to be accessible only through squid for more > 
security. > > shellinabox works fine if I access it directly, but 
through squid I > see this in access.log: > > 1495813953.860     79 
204.155.22.30 TCP_TUNNEL/200 1440 CONNECT > IP:PORT USER HIER_DIRECT/IP 
 > > > 1495813962.001      0 204.155.22.30 TCP_DENIED/407 4397 CONNECT > 
IP:PORT USER HIER_NONE/- text/html > > > I've replaced the real IP, 
PORT, and USER with those words, however > the real PORT is a 
nonstandard port number.There are some other > posts I found mentioning 
a 407 error and it was said it occurs when > the webpage is asking for 
authentication.  However I don't understand > this, since shellinabox 
only display a login prompt which I wouldn't > think would be a 
problem.  Another post said a 407 is when squid auth > is failing, but I 
can get to external websites through squid. > > Does it matter that what 
I'm trying to access is HTTPS instead of > HTTP?
Yes it does. Beyond the obvious encryption there are messaging 
differences that directly effect what the proxy can do.


The first log entry indicates that something has already been done to 
let the port "work", so your config is already non-standard and probably 
doing something weird. The presence of a USER value other than "-" 
indicates that the proxy-auth is working at least for that transaction.

Yes the 407 is login to *Squid*. Nothing to do with the shellinabox 
software, the HEIR_NONE/- on the second line says shellinabox is not 
even being contacted yet for that transaction.


It is not possible to say why anything is happening here without knowing 
your config structure and intended policy. You will need to provide your 
squid.conf details to get much help.

If you need to obfuscate IP's please map them as if you were using the 
10/8 or 192.168/16 ranges so we can still identify any subtle things 
like TCP connections going wrong without revealing your public addresses.

Amos



From rousskov at measurement-factory.com  Fri May 26 17:29:37 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 26 May 2017 11:29:37 -0600
Subject: [squid-users] Repeated assertions
In-Reply-To: <2a2beb37-df49-9b31-5fa0-5eecc91677e0@treenet.co.nz>
References: <569432405.404.1495812451993.JavaMail.root@hscbrasil.com.br>
 <2a2beb37-df49-9b31-5fa0-5eecc91677e0@treenet.co.nz>
Message-ID: <c0a9af92-869d-f939-0472-7ea8b9484549@measurement-factory.com>

On 05/26/2017 10:55 AM, Amos Jeffries wrote:
> On 27/05/17 03:27, Junior Cunha wrote:
>> "assertion failed: Read.cc:73: "fd_table[conn->fd].halfClosedReader !=
>> NULL" can be seen in the cache.log file.


> I recommend for you to try the 4.0


FWIW, I second Amos recommendation -- at least consider an upgrade! It
is a hassle to upgrade, especially if you have many Squid instances, and
the upgrade itself may introduce new/different problems, but it may
still be a more efficient path forward. SslBump code in v4 is not
problem-free, but it is better than v3 code, on many levels.

Alex.



From acctforjunk at yahoo.com  Fri May 26 18:46:50 2017
From: acctforjunk at yahoo.com (j m)
Date: Fri, 26 May 2017 18:46:50 +0000 (UTC)
Subject: [squid-users] TCP_DENIED/407 accessing webserver on same
 machine as squid
In-Reply-To: <e7957308-0a94-fa66-960d-2bb508c49729@treenet.co.nz>
References: <1249825632.662768.1495815443782.ref@mail.yahoo.com>
 <1249825632.662768.1495815443782@mail.yahoo.com>
 <e7957308-0a94-fa66-960d-2bb508c49729@treenet.co.nz>
Message-ID: <1930856943.805298.1495824410829@mail.yahoo.com>

Here's my squid.conf.? For what it's worth, shellinabox can be made to use only HTTP if that's the issue.

auth_param digest program /usr/lib/squid/digest_file_auth -c /etc/squid/passwd auth_param digest realm myrealm auth_param digest children 2  acl auth_users proxy_auth REQUIRED acl SSL_ports port 443 acl SSL_ports port SHELLINABOX_PORT acl Safe_ports port SHELLINABOX_PORT acl Safe_ports port 80 # http acl Safe_ports port 21 # ftp acl Safe_ports port 443 # https acl Safe_ports port 70 # gopher acl Safe_ports port 210 # wais #acl Safe_ports port 1025-65535 # unregistered ports acl Safe_ports port 280 # http-mgmt acl Safe_ports port 488 # gss-http acl Safe_ports port 591 # filemaker acl Safe_ports port 777 # multiling http acl CONNECT method CONNECT http_access deny !Safe_ports http_access deny CONNECT !SSL_ports http_access allow auth_users http_access allow all https_port SQUID_PORT cert=/etc/squid/squid.pem cache deny all netdb_filename none 

      From: Amos Jeffries <squid3 at treenet.co.nz>
 To: squid-users at lists.squid-cache.org 
 Sent: Friday, May 26, 2017 12:29 PM
 Subject: Re: [squid-users] TCP_DENIED/407 accessing webserver on same machine as squid
   


On 27/05/17 04:17, j m wrote:
> I have a webserver and squid 3.5 running on the same Linux machine.? > The webserver is actually part of shellinabox, so it's only for me 
to > access.? Shellinabox simply presents a terminal and login in a web 
 > browser.? I want it to be accessible only through squid for more > 
security. > > shellinabox works fine if I access it directly, but 
through squid I > see this in access.log: > > 1495813953.860? ? 79 
204.155.22.30 TCP_TUNNEL/200 1440 CONNECT > IP:PORT USER HIER_DIRECT/IP 
 > > > 1495813962.001? ? ? 0 204.155.22.30 TCP_DENIED/407 4397 CONNECT > 
IP:PORT USER HIER_NONE/- text/html > > > I've replaced the real IP, 
PORT, and USER with those words, however > the real PORT is a 
nonstandard port number.There are some other > posts I found mentioning 
a 407 error and it was said it occurs when > the webpage is asking for 
authentication.? However I don't understand > this, since shellinabox 
only display a login prompt which I wouldn't > think would be a 
problem.? Another post said a 407 is when squid auth > is failing, but I 
can get to external websites through squid. > > Does it matter that what 
I'm trying to access is HTTPS instead of > HTTP?
Yes it does. Beyond the obvious encryption there are messaging 
differences that directly effect what the proxy can do.


The first log entry indicates that something has already been done to 
let the port "work", so your config is already non-standard and probably 
doing something weird. The presence of a USER value other than "-" 
indicates that the proxy-auth is working at least for that transaction.

Yes the 407 is login to *Squid*. Nothing to do with the shellinabox 
software, the HEIR_NONE/- on the second line says shellinabox is not 
even being contacted yet for that transaction.


It is not possible to say why anything is happening here without knowing 
your config structure and intended policy. You will need to provide your 
squid.conf details to get much help.

If you need to obfuscate IP's please map them as if you were using the 
10/8 or 192.168/16 ranges so we can still identify any subtle things 
like TCP connections going wrong without revealing your public addresses.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170526/730f37c0/attachment.htm>

From squid3 at treenet.co.nz  Fri May 26 19:52:52 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 27 May 2017 07:52:52 +1200
Subject: [squid-users] TCP_DENIED/407 accessing webserver on same
 machine as squid
In-Reply-To: <1930856943.805298.1495824410829@mail.yahoo.com>
References: <1249825632.662768.1495815443782.ref@mail.yahoo.com>
 <1249825632.662768.1495815443782@mail.yahoo.com>
 <e7957308-0a94-fa66-960d-2bb508c49729@treenet.co.nz>
 <1930856943.805298.1495824410829@mail.yahoo.com>
Message-ID: <aee71073-23aa-4478-0224-5ee40ef5081b@treenet.co.nz>

Ah, your problem seems to be a misunderstanding of how authentication works.

What Squid receives on messages can have three forms:

  1) no credentials at all
  2) correct credentials
  3) invalid credentials

Your definition of the auth_users ACL using "REQUIRED" takes care of the 
(1) situation. Squid will respond with 407 to get credentials from any 
client that does not send any. This is what you are seeing on that 
second log line of your previous post, and the popup in your tests.

Now the "http_access allow auth_users" line only takes care of situation 
(2), permitting valid users.

Which leaves situation (3) undefined. ... All other traffic continues on 
to the next http_access line, which is "allow all", ouch.


This is why best practice is to use a "deny" line like so:
   http_access deny !auth_users

... which makes it clear what is happening for every non-authenticated 
thing, both situation (1) and (2) traffic.

Rules permitting things through without authenticating go above that 
http_access line, and things applying to authenticated users go below it.

Amos



From squid3 at treenet.co.nz  Fri May 26 19:56:51 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 27 May 2017 07:56:51 +1200
Subject: [squid-users] TCP_DENIED/407 accessing webserver on same
 machine as squid
In-Reply-To: <aee71073-23aa-4478-0224-5ee40ef5081b@treenet.co.nz>
References: <1249825632.662768.1495815443782.ref@mail.yahoo.com>
 <1249825632.662768.1495815443782@mail.yahoo.com>
 <e7957308-0a94-fa66-960d-2bb508c49729@treenet.co.nz>
 <1930856943.805298.1495824410829@mail.yahoo.com>
 <aee71073-23aa-4478-0224-5ee40ef5081b@treenet.co.nz>
Message-ID: <8c2e3717-1cf1-e607-aab0-e5174f628c07@treenet.co.nz>

On 27/05/17 07:52, Amos Jeffries wrote:
> This is why best practice is to use a "deny" line like so:
>   http_access deny !auth_users
>
> ... which makes it clear what is happening for every non-authenticated 
> thing, both situation (1) and (2) traffic.

Sorry "both situation (1) and (3) traffic".

Amos



From rentorbuy at yahoo.com  Fri May 26 23:22:02 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Fri, 26 May 2017 23:22:02 +0000 (UTC)
Subject: [squid-users] Squid TPROXY issues with Google sites
In-Reply-To: <f00f4540-6a5b-ffa3-aa3d-8a4e33d366a4@treenet.co.nz>
References: <589790035.698921.1495813442972.ref@mail.yahoo.com>
 <589790035.698921.1495813442972@mail.yahoo.com>
 <f00f4540-6a5b-ffa3-aa3d-8a4e33d366a4@treenet.co.nz>
Message-ID: <179822685.137977.1495840922368@mail.yahoo.com>

I forgot to put the emphasis on one thing. I did not change my squid.conf or my ACLs. The only difference is in the ssl_bump configuration directives.

If I have this:

acl AllowTroublesome ssl::server_name .google.com .gmail.com
acl DenyTroublesome ssl::server_name mail.google.com
http_access deny DenyTroublesome
ssl_bump peek all
ssl_bump splice AllowTroublesome
ssl_bump bump all

then access to https://mail.google.com is allowed when I was hoping to block it.

If I replace the above snippet with this:

ssl_bump stare all
ssl_bump bump all

then access to https://mail.google.com is blocked as expected.

The above puzzles me since I haven't changed anything else.
If I had an http_access rule that allowed the transaction to take place then I would expect it to happen regardless of the ssl_bump directive.

Alex, you mention the SSLPeekAndSplice web page. I'll try to sum it up in just a few lines (correct me if I'm wrong):
- peek implies splice which means you can't do content analysis (as in scan for threats via c-icap modules)
- stare implies bump which means you can do content analysis
- you don't need to stare, you can just bump
- you need to stare before bump if you want the clients to accept a certificate with domain names instead of IP addresses
- you can bump first by ACLs and then splice the rest
- you can bump after peek but only if you do that at SslBump1

I'm asking this because the wiki page isn't all that clear to me. Especially the "Bump All Sites Except Banks" example where the next phrase contradicts the title by saying that the requests to non-banks won't be bumped.

Anyway, I'm only interested in bumping as much as possible so I can scan content for threats.

So Amos, here goes my full squid.conf:

# grep -v ^# squid.conf  | grep -v "^\$"
acl SSL_ports port 443
acl Safe_ports port 80		# http
acl Safe_ports port 21		# ftp
acl Safe_ports port 443		# https
acl Safe_ports port 70		# gopher
acl Safe_ports port 210		# wais
acl Safe_ports port 1025-65535	# unregistered ports
acl Safe_ports port 280		# http-mgmt
acl Safe_ports port 488		# gss-http
acl Safe_ports port 591		# filemaker
acl Safe_ports port 777		# multiling http
acl Safe_ports port 901		# SWAT
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
include /etc/squid/squid.custom.rules
http_access allow localhost
http_access deny all
coredump_dir /var/cache/squid
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320

# grep -v ^# squid.custom.rules  | grep -v "^\$"
http_port 3128
http_port 3129 tproxy
https_port 3130 tproxy ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cert=/etc/ssl/squid/proxyserver.pem
external_acl_type nt_group ttl=0 children-max=10 %LOGIN /usr/libexec/squid/ext_wbinfo_group_acl -K
auth_param negotiate program /usr/libexec/squid/negotiate_kerberos_auth -s HTTP/prx1.mydomain.org at MYDOMAIN.ORG
auth_param negotiate children 60
auth_param negotiate keep_alive on
auth_param basic realm MYORG proxy
acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl FHM_all proxy_auth REQUIRED
acl explicit myportname 3128
acl intercepted myportname 3129
acl interceptedssl myportname 3130
acl interceptednormal myportname 3131
acl interceptedsslnormal myportname 3132
acl allowed_ips src "/usr/local/share/proxy-settings/allowed.ips"
acl allowed_groups external nt_group "/usr/local/share/proxy-settings/allowed.groups"
acl denied_domains dstdomain "/usr/local/share/proxy-settings/denied.domains"
acl denied_ads url_regex "/usr/local/share/proxy-settings/denied.ads"
acl denied_filetypes urlpath_regex -i "/usr/local/share/proxy-settings/denied.filetypes"
acl restricted_ips src "/usr/local/share/proxy-settings/restricted.ips"
acl restricted_groups external nt_group "/usr/local/share/proxy-settings/restricted.groups"
acl restricted_domains dstdomain "/usr/local/share/proxy-settings/restricted.domains"
http_access deny restricted_ips !restricted_domains
http_access deny restricted_groups !restricted_domains
http_access deny denied_domains !allowed_groups !allowed_ips
http_access deny CONNECT denied_domains !allowed_groups !allowed_ips
http_access deny denied_ads !allowed_groups !allowed_ips
http_access deny denied_filetypes !allowed_groups !allowed_ips
http_access deny explicit !FHM_all
http_access deny intercepted !localnet
http_access deny interceptedssl !localnet
http_access deny interceptedsslnormal !localnet
http_access deny interceptednormal !localnet
cache_mgr it at mydomain.org
email_err_data on
error_directory /usr/share/squid/errors/MYORG
append_domain .mydomain.org
sslcrtd_program /usr/libexec/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 16MB
sslcrtd_children 10
reply_header_access Alternate-Protocol deny all
ssl_bump stare all
ssl_bump bump all
icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_encode off
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024
icap_service squidclamav respmod_precache bypass=0 icap://127.0.0.1:1344/clamav
adaptation_access squidclamav allow all
include /etc/squid/squid.custom.common
include /etc/squid/squid.custom.hide
cache_dir diskd /var/cache/squid 100 16 256
http_access allow localnet

# grep -v ^# squid.custom.common  | grep -v "^\$"
cache_mgr it at mydomain.org
email_err_data on
error_directory /usr/share/squid/errors/MYORG

# grep -v ^# squid.custom.hide  | grep -v "^\$"
httpd_suppress_version_string on
dns_v4_first on
via off
forwarded_for off
request_header_access Allow allow all
request_header_access Authorization allow all
request_header_access Cache-Control allow all
request_header_access Content-Encoding allow all
request_header_access Content-Length allow all
request_header_access Content-Type allow all
request_header_access Date allow all
request_header_access Expires allow all
request_header_access Host allow all
request_header_access If-Modified-Since allow all
request_header_access Last-Modified allow all
request_header_access Location allow all
request_header_access Pragma allow all
request_header_access Accept allow all
request_header_access Accept-Charset allow all
request_header_access Accept-Encoding allow all
request_header_access Accept-Language allow all
request_header_access Content-Language allow all
request_header_access Mime-Version allow all
request_header_access Retry-After allow all
request_header_access Connection allow all
request_header_access User-Agent allow all
request_header_access Cookie allow all
request_header_access All deny all

Do you require the full ACLs too?

# grep google /usr/local/share/proxy-settings/*
/usr/local/share/proxy-settings/denied.domains:play.google.com
/usr/local/share/proxy-settings/denied.domains:mail.google.com

Note that the above configuration correctly blocks access to https://mail.google.com.
It also allows access to https://accounts.google.com and I can enter my Google username. However, I cannot press "the Next button" to enter the password. I could try to study the web page's source code but at a first glance:
1) Google login works fine if I by-pass the Squid proxy or if I use "ssl_bump splice".
2) I am not denying access to any Google service except for "play" and "mail".

Not being able to press "the Next button" is what I meant by "unreported error" in my previous e-mail. It is easy to reproduce with my squid.conf.

Thanks,

Vieri


From acctforjunk at yahoo.com  Sat May 27 01:10:30 2017
From: acctforjunk at yahoo.com (j m)
Date: Sat, 27 May 2017 01:10:30 +0000 (UTC)
Subject: [squid-users] TCP_DENIED/407 accessing webserver on same
 machine as squid
In-Reply-To: <aee71073-23aa-4478-0224-5ee40ef5081b@treenet.co.nz>
References: <1249825632.662768.1495815443782.ref@mail.yahoo.com>
 <1249825632.662768.1495815443782@mail.yahoo.com>
 <e7957308-0a94-fa66-960d-2bb508c49729@treenet.co.nz>
 <1930856943.805298.1495824410829@mail.yahoo.com>
 <aee71073-23aa-4478-0224-5ee40ef5081b@treenet.co.nz>
Message-ID: <1277246723.1033708.1495847430739@mail.yahoo.com>

Yes, I sort of pieced together what I found online, which is probably dangerous. ?I really need to become familiar with how exactly this works for security's sake if nothing else.

      From: Amos Jeffries <squid3 at treenet.co.nz>
 To: j m <acctforjunk at yahoo.com>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Friday, May 26, 2017 2:53 PM
 Subject: Re: [squid-users] TCP_DENIED/407 accessing webserver on same machine as squid
   
Ah, your problem seems to be a misunderstanding of how authentication works.

What Squid receives on messages can have three forms:

? 1) no credentials at all
? 2) correct credentials
? 3) invalid credentials

Your definition of the auth_users ACL using "REQUIRED" takes care of the 
(1) situation. Squid will respond with 407 to get credentials from any 
client that does not send any. This is what you are seeing on that 
second log line of your previous post, and the popup in your tests.

Now the "http_access allow auth_users" line only takes care of situation 
(2), permitting valid users.

Which leaves situation (3) undefined. ... All other traffic continues on 
to the next http_access line, which is "allow all", ouch.


This is why best practice is to use a "deny" line like so:
? http_access deny !auth_users

... which makes it clear what is happening for every non-authenticated 
thing, both situation (1) and (2) traffic.

Rules permitting things through without authenticating go above that 
http_access line, and things applying to authenticated users go below it.

Amos



   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170527/22e9a929/attachment.htm>

From rousskov at measurement-factory.com  Sat May 27 01:53:22 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 26 May 2017 19:53:22 -0600
Subject: [squid-users] Squid TPROXY issues with Google sites
In-Reply-To: <179822685.137977.1495840922368@mail.yahoo.com>
References: <589790035.698921.1495813442972.ref@mail.yahoo.com>
 <589790035.698921.1495813442972@mail.yahoo.com>
 <f00f4540-6a5b-ffa3-aa3d-8a4e33d366a4@treenet.co.nz>
 <179822685.137977.1495840922368@mail.yahoo.com>
Message-ID: <4f6e6441-cda6-c7fc-0cee-1d32e0822671@measurement-factory.com>

On 05/26/2017 05:22 PM, Vieri wrote:

> If I have this:
> 
> ssl_bump peek all
> ssl_bump splice AllowTroublesome
> ssl_bump bump all

... then you have a configuration that does not make sense because one
cannot bump after peeking at step2. Your configuration is equivalent to

  * if the current step is 1 or 2, then peek
  * if AllowTroublesome during step 3, then splice
  * otherwise, do the impossible

which, bugs notwithstanding, is equivalent to

  ssl_bump peek all
  ssl_bump splice all

If the above does not block anything then your http_access rules allow
all CONNECTs (and you never get beyond CONNECTs because you do not bump).


> If I replace the above snippet with this:
> 
> ssl_bump stare all
> ssl_bump bump all

This configuration makes sense (but it may not do what you want).

If you want to be able to make a "splice or bump" decision, then you
have to make it during step2:

  ssl_bump peek step1
  ssl_bump splice AllowTroublesome
  ssl_bump bump all


> If I had an http_access rule that allowed the transaction to take
> place then I would expect it to happen regardless of the ssl_bump
> directive.

Your expectations are wrong. SslBump directives expose http_access rules
to more (or fewer) transactions. For example, the "splice all"
configuration does not expose http_access rules to any GET requests.


> Alex, you mention the SSLPeekAndSplice web page. I'll try to sum it
> up in just a few lines

The SslBump feature is too complex to sum it up in just a few lines
unless those lines are something like "do not use it without fully
understanding it". Once you learn the basics of SSL handshake, which
Squid steps look at what parts of the handshake, and what the essential
difference between peeking and staring is, then SslBump becomes less of
black magic. Without that knowledge, it is a dark mystery.


> - peek implies splice which means you can't do content analysis (as
> in scan for threats via c-icap modules)

Wrong. Peeking at step1 does not preclude future bumping. Peeking at
step2 precludes future bumping. If you peek at step2, then you have to
splice or terminate at step3.


> - stare implies bump which means you can do content analysis

Wrong for similar/symmetrical reasons.


> - you don't need to stare, you can just bump

Wrong in many cases -- usually you _do_ need to stare (or peek) at least
at step1, but YMMV.


> - you need to stare before bump if you want the clients to accept a
> certificate with domain names instead of IP addresses

Misleading. You need to stare or peek to get more information, including
the server domain name. That information comes from either the client or
the server, depending on the step. That information is used to generate
a fake certificate. The more info Squid has, the better it can
fake/mimic the true certificate, but learning more information restricts
the set of ssl_bump actions.


> - you can bump first by ACLs and then splice the rest

If you mean that ssl_bump rules may start with "bump" rules and end with
"splice" rules, then this is true, but the reverse is also true, and the
rules may contain a mixture of many actions.


> - you can bump after peek but only if you do that at SslBump1

Too vague to be generally useful. You can bump after peeking at step1.
You cannot bump after peeking at step2.


> the "Bump All Sites Except Banks" example where the next
> phrase contradicts the title by saying that the requests to non-banks
> won't be bumped.

Correct! The example, the title, and the warning were written by
different people. One of them is right. If you know how SslBump works,
you know which part is correct. At that time, please feel free to
propose changes to fix the wiki page. Hundreds of folks receive SslBump
help on this mailing list, but only one of them took the pains to
improve the page afterwards (thank you again, Marcus Kool!). Parts of
that page still need a lot of work.


HTH,

Alex.



From Walter.H at mathemainzel.info  Fri May 26 06:41:38 2017
From: Walter.H at mathemainzel.info (Walter H.)
Date: Fri, 26 May 2017 08:41:38 +0200
Subject: [squid-users] CentOS6 and squid34 package ...
In-Reply-To: <592735BF.5020500@afo.net>
References: <59269374.1060701@mathemainzel.info>
 <4c4b02a9-c38a-031b-db9d-fec999c64121@treenet.co.nz>
 <59272B64.20308@mathemainzel.info> <592735BF.5020500@afo.net>
Message-ID: <5927CE22.9050305@mathemainzel.info>

On 25.05.2017 21:51, Mike wrote:
> Walter, what I've found is when compiling to squid 3.5.x and higher, 
> the compile options change. Also remember that many of the options 
> that were available with 3.1.x are depreciated and likely will not 
> work with 3.4.x and higher.
>
the compile options are not really the matter ...
> The other issue is that squid is only supposed to be handling HTTP and 
> HTTPS traffic, not FTP.
this is definitely wrong ...

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170526/041b990f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170526/041b990f/attachment.bin>

From Walter.H at mathemainzel.info  Fri May 26 16:57:25 2017
From: Walter.H at mathemainzel.info (Walter H.)
Date: Fri, 26 May 2017 18:57:25 +0200
Subject: [squid-users] CentOS6 and squid34 package ...
In-Reply-To: <550c2028-c49f-70d4-2501-22d56148abd8@treenet.co.nz>
References: <59269374.1060701@mathemainzel.info>
 <4c4b02a9-c38a-031b-db9d-fec999c64121@treenet.co.nz>
 <59272B64.20308@mathemainzel.info> <592735BF.5020500@afo.net>
 <550c2028-c49f-70d4-2501-22d56148abd8@treenet.co.nz>
Message-ID: <59285E75.6090007@mathemainzel.info>

On 26.05.2017 17:49, Amos Jeffries wrote:
> On 26/05/17 07:51, Mike wrote:
>> Walter, what I've found is when compiling to squid 3.5.x and higher, 
>> the compile options change. Also remember that many of the options 
>> that were available with 3.1.x are depreciated and likely will not 
>> work with 3.4.x and higher.
>>
>> The other issue is that squid is only supposed to be handling HTTP 
>> and HTTPS traffic, not FTP. trying to use it as a FTP proxy will need 
>> a different configuration than the standard HTTP/Secure proxy.
>>
>
> Well, to be correct Squid talks HTTP to the client software. It has 
> log supported mapping FTP server URLs into HTTP.
>
> This second problem seems like the symptoms of 
> <http://bugs.squid-cache.org/show_bug.cgi?id=4132> which was fixed 
> years ago in the Squid-3.5.5 release. But that was apparently a 
> regression not affecting 3.4 or 3.1. Hmm.
>
>
Strange, isn't it?
>
>> On 5/25/2017 14:07 PM, Walter H. wrote:
>>> On 25.05.2017 12:50, Amos Jeffries wrote:
>>>
>>>> On 25/05/17 20:19, Walter H. wrote:
>>>>> Hello
>>>>>
>>>>> what is the essential difference between the default squid package 
>>>>> and this squid34 package,
>>>>
>>>>> as I have problems using this squid34 package for FTP connections;
>>>>> there are no shown icons, when going to e.g. ftp://ftp.adobe.com/
>>>>> when I tell the browser to show the image then I get this squid 
>>>>> generated message ...
>>>>>
>>>>> the same config /etc/squid/squid.conf works with the default squid 
>>>>> package ...
>>>>>
>>>>> <message>
>>>>> While trying to retrieve the URL: 
>>>>> http://proxy.local:3128/squid-internal-static/icons/silk/folder.png <http://zbox-ci323.waldinet.local:3128/squid-internal-static/icons/silk/folder.png> 
>>>>>
>>>>>
>>>>
>>>> Notice the port number in that URL...
>>>>
>>> yes I see the squid port 3128
>>>
>>> when I do this with the default squid package, there I get the 
>>> icons, and when I want to get the URL of such an icon,
>>> it shows e.g. 
>>> ftp://ftp.adobe.com/squid-internal-static/icons/anthony-dir.gif
>>>
>>> what is running wrong here?
>>> is there a setting I can change without having to allow
>>> port 3128 traffic go through the proxy?
>>> (this is not really logic, as the default squid package also doesn't 
>>> allow port 3128 traffic go through ...)
>
> Er, it is using the recommended default config we ship from upstream. 
> Some Vendors like to install packages that are not usable without 
> manual attention. Usually by commenting out the "http_access allow 
> localnet" rule though, not marking registered HTTP ports as unsafe for 
> use with HTTP.
>
> Anyhow:
>
>  acl Safe_ports port 3128
>  acl port3128 port 3128
>  acl squid-internal urlpath_regex ^/squid-internal
>
> Then add this directly before the "deny manager" line:
>
>   http_access deny port3128 !squid-internal 

Many thanks,
this shows the icons and doesn't allow port 3128 go through ...
exactly as I wanted

Walter

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170526/5cbd14d9/attachment.bin>

From eliezer at ngtech.co.il  Sat May 27 23:21:18 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Sun, 28 May 2017 02:21:18 +0300
Subject: [squid-users] Youtube not TCP_HIT Squid3.5.21-25
In-Reply-To: <1495804175132-4682584.post@n4.nabble.com>
References: <1495745270225-4682582.post@n4.nabble.com>
 <1495804175132-4682584.post@n4.nabble.com>
Message-ID: <015301d2d73f$f2012b00$d6038100$@ngtech.co.il>

Hey,

I want to make sure there is no regression in squid 3.5.21 and 3.5.25.
Let's leave YouTube as a target for now and try to focus on a much more solid objectives.
Try to verify if it works for you with the files in the list at:
https://gist.github.com/elico/258cdcf9eba04c7ccfb8a0d100ce67a7

And let me know how and if it works for you well.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eduardo Carneiro
Sent: Friday, May 26, 2017 4:10 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Youtube not TCP_HIT Squid3.5.21-25

I have the same issue. And not just Youtube, but any dynamic content cache.
If you need to rewrite doesn't work.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Youtube-not-TCP-HIT-Squid3-5-21-25-tp4682582p4682584.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From rentorbuy at yahoo.com  Sun May 28 11:40:31 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Sun, 28 May 2017 11:40:31 +0000 (UTC)
Subject: [squid-users] Squid TPROXY issues with Google sites
In-Reply-To: <4f6e6441-cda6-c7fc-0cee-1d32e0822671@measurement-factory.com>
References: <589790035.698921.1495813442972.ref@mail.yahoo.com>
 <589790035.698921.1495813442972@mail.yahoo.com>
 <f00f4540-6a5b-ffa3-aa3d-8a4e33d366a4@treenet.co.nz>
 <179822685.137977.1495840922368@mail.yahoo.com>
 <4f6e6441-cda6-c7fc-0cee-1d32e0822671@measurement-factory.com>
Message-ID: <993213090.790265.1495971631319@mail.yahoo.com>

Hi Alex et al.,

Thank you very much for your analysis and help. I really appreciate it.

Please keep in mind that I'm basically an end-user, a sys-admin. I wish I had the time to study Squid's source code. All I can do for now is read the docs that so many people have kindly published.

In 99% of my use cases, I only need this:

ssl_bump stare all
ssl_bump bump all

However, some sites simply don't behave well when accessed with Squid TPROXY. This is an example I'm reporting regarding access to https://accounts.google.com.

The use case is simple. A client browser successfully connects to https://accounts.google.com and I can see this in the access log (there might be some garbage but I'm posting it all for completeness):

# tail -f /var/log/squid/access.log | grep 10.215.145.8
1495969366.990     90 10.215.145.8 TCP_MISS/302 870 GET https://accounts.google.com/ - ORIGINAL_DST/216.58.201.141 text/html
1495969367.089     91 10.215.145.8 TCP_MISS/302 1206 GET https://accounts.google.com/ManageAccount - ORIGINAL_DST/216.58.201.141 text/html
1495969367.165    165 10.215.145.8 TAG_NONE/200 0 CONNECT 216.58.201.141:443 - ORIGINAL_DST/216.58.201.141 -
1495969367.546    452 10.215.145.8 TCP_MISS/200 254275 GET https://accounts.google.com/ServiceLogin? - ORIGINAL_DST/216.58.201.141 text/html
1495969367.684     99 10.215.145.8 TCP_MISS/200 837 GET https://accounts.google.com/_/common/diagnostics/? - ORIGINAL_DST/216.58.201.141 application/json
1495969367.799    218 10.215.145.8 TAG_NONE/200 0 CONNECT 216.58.201.141:443 - ORIGINAL_DST/216.58.201.141 -
1495969368.341    356 10.215.145.8 TCP_MISS/200 9598 GET https://ssl.gstatic.com/accounts/static/_/js/k=gaia.gaiafe_glif.es.QCvs5i6XPsY.O/m=ZJkSm,ssIgD,GJkP8c,HUb4Ab,sy3j,DnoIKd,sy1a,sy1g,YKZpNb,sy19,VI9RTb,sy18,sy24,GEsPC/am=gggAAACgARcEwFGwAlAM/rt=j/rs=ABkqax2H2XpBhaGl4fmxx-IOq5MdI_K9yw - ORIGINAL_DST/172.217.9.227 text/javascript
1495969373.609    249 10.215.145.8 TCP_MISS/200 9598 GET https://ssl.gstatic.com/accounts/static/_/js/k=gaia.gaiafe_glif.es.QCvs5i6XPsY.O/m=ZJkSm,ssIgD,GJkP8c,HUb4Ab,sy3j,DnoIKd,sy1a,sy1g,YKZpNb,sy19,VI9RTb,sy18,sy24,GEsPC/am=gggAAACgARcEwFGwAlAM/rt=j/rs=ABkqax2H2XpBhaGl4fmxx-IOq5MdI_K9yw - ORIGINAL_DST/172.217.9.227 text/javascript
1495969393.879    248 10.215.145.8 TCP_MISS/200 9598 GET https://ssl.gstatic.com/accounts/static/_/js/k=gaia.gaiafe_glif.es.QCvs5i6XPsY.O/m=ZJkSm,ssIgD,GJkP8c,HUb4Ab,sy3j,DnoIKd,sy1a,sy1g,YKZpNb,sy19,VI9RTb,sy18,sy24,GEsPC/am=gggAAACgARcEwFGwAlAM/rt=j/rs=ABkqax2H2XpBhaGl4fmxx-IOq5MdI_K9yw - ORIGINAL_DST/172.217.9.227 text/javascript
1495969393.940    166 10.215.145.8 TCP_MISS/200 452 GET http://detectportal.firefox.com/success.txt - ORIGINAL_DST/23.219.93.219 text/plain
1495969394.116    225 10.215.145.8 TCP_MISS/200 1261 GET https://ssl.gstatic.com/accounts/static/_/js/k=gaia.gaiafe_glif.es.QCvs5i6XPsY.O/m=ZJkSm/am=gggAAACgARcEwFGwAlAM/rt=j/rs=ABkqax2H2XpBhaGl4fmxx-IOq5MdI_K9yw - ORIGINAL_DST/172.217.9.227 text/javascript
1495969394.204    873 10.215.145.8 TAG_NONE/200 0 CONNECT 54.148.190.222:443 - ORIGINAL_DST/54.148.190.222 -
1495969394.724    488 10.215.145.8 TCP_MISS/200 195 POST https://incoming.telemetry.mozilla.org/submit/telemetry/3474d8df-c0c5-454b-916f-20ad7f8cb3f3/main/Firefox/52.0.2/release/20170323105023? - ORIGINAL_DST/54.148.190.222 text/plain
1495969399.355    223 10.215.145.8 TCP_MISS/200 1261 GET https://ssl.gstatic.com/accounts/static/_/js/k=gaia.gaiafe_glif.es.QCvs5i6XPsY.O/m=ZJkSm/am=gggAAACgARcEwFGwAlAM/rt=j/rs=ABkqax2H2XpBhaGl4fmxx-IOq5MdI_K9yw - ORIGINAL_DST/172.217.9.227 text/javascript

The client browser successfully renders Google's log-in page where you enter a username. However, it is NOT possible to "click next" and enter a password.
No matter what the user does on that page, nothing is logged in /var/log/squid/access.log.

The cache log reports errors but they are not necessarily related to this client as there are many others actively browsing.

# grep -i error /var/log/squid/cache.log 
2017/05/28 12:55:48 kid1| Error negotiating SSL on FD 93: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/2)
2017/05/28 12:55:48 kid1| Error negotiating SSL connection on FD 90: error:14094412:SSL routines:ssl3_read_bytes:sslv3 alert bad certificate (1/0)
2017/05/28 12:55:49 kid1| Error negotiating SSL on FD 143: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:55:50 kid1| Error negotiating SSL on FD 172: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:55:55 kid1| Error negotiating SSL on FD 57: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)
2017/05/28 12:55:55 kid1| Error negotiating SSL connection on FD 27: error:1408A0C1:SSL routines:ssl3_get_client_hello:no shared cipher (1/-1)
2017/05/28 12:55:58 kid1| Error negotiating SSL on FD 57: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:55:58 kid1| Error negotiating SSL on FD 183: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:00 kid1| Error negotiating SSL on FD 82: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:01 kid1| Error negotiating SSL on FD 82: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:02 kid1| Error negotiating SSL on FD 82: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:02 kid1| Error negotiating SSL on FD 141: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:05 kid1| Error negotiating SSL on FD 81: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:05 kid1| Error negotiating SSL on FD 57: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)
2017/05/28 12:56:05 kid1| Error negotiating SSL connection on FD 52: error:1408A0C1:SSL routines:ssl3_get_client_hello:no shared cipher (1/-1)
2017/05/28 12:56:06 kid1| Error negotiating SSL on FD 47: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:08 kid1| Error negotiating SSL on FD 47: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:09 kid1| Error negotiating SSL on FD 47: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:11 kid1| Error negotiating SSL on FD 47: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:13 kid1| Error negotiating SSL on FD 38: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:16 kid1| Error negotiating SSL on FD 38: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:16 kid1| Error negotiating SSL on FD 38: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:16 kid1| Error negotiating SSL on FD 38: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:17 kid1| Error negotiating SSL on FD 17: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:19 kid1| Error negotiating SSL on FD 17: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:20 kid1| Error negotiating SSL on FD 17: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:21 kid1| Error negotiating SSL on FD 52: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)
2017/05/28 12:56:21 kid1| Error negotiating SSL connection on FD 49: error:1408A0C1:SSL routines:ssl3_get_client_hello:no shared cipher (1/-1)
2017/05/28 12:56:21 kid1| Error negotiating SSL on FD 17: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:22 kid1| Error negotiating SSL on FD 47: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:22 kid1| Error negotiating SSL on FD 17: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:24 kid1| Error negotiating SSL on FD 17: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:25 kid1| Error negotiating SSL on FD 17: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:27 kid1| Error negotiating SSL on FD 12: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:27 kid1| Error negotiating SSL on FD 12: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:30 kid1| Error negotiating SSL on FD 12: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:30 kid1| Error negotiating SSL on FD 12: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:32 kid1| Error negotiating SSL on FD 12: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:34 kid1| Error negotiating SSL on FD 12: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)
2017/05/28 12:56:35 kid1| Error negotiating SSL on FD 12: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry (1/-1/0)

As I said, if the client browses without Squid TPROXY in the middle, there are no issues and https://accounts.google.com behaves as expected. I haven't read Google's web page source code so I don't know yet which javascript call might be failing, etc.

Is it only me or can this issue be reproduced elsewhere?
Has anyone successfully logged into https://accounts.google.com when using the following config directives in Squid?

ssl_bump stare all
ssl_bump bump all

Anyway, as a workaround I'm willing to splice/tunnel traffic to accounts.google.com *ONLY*, and bump everything else (although I'd prefer to understand why bumping isn't "working" for this site).

I've tried this:

acl GoogleAccounts ssl::server_name accounts.google.com
#acl GoogleAccounts dstdomain accounts.google.com
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump splice GoogleAccounts
ssl_bump bump all

However, traffic to accounts.google.com is not spliced, it's bumped like the rest.

Can FQDNs be used in ACLs as in the example above even when peeking at step 1?
If I need to peek at step 2 for GoogleAccounts to splice then I take it I won't be able to "bump all" (the rest).
Likewise, If I need to stare at step 2 then I'll never be able to splice GoogleAccounts.

Please let me know if I'm totally off course.

Thanks,

Vieri


From eduardoocarneiro at gmail.com  Sun May 28 14:24:54 2017
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Sun, 28 May 2017 07:24:54 -0700 (PDT)
Subject: [squid-users] Youtube not TCP_HIT Squid3.5.21-25
In-Reply-To: <015301d2d73f$f2012b00$d6038100$@ngtech.co.il>
References: <1495745270225-4682582.post@n4.nabble.com>
 <1495804175132-4682584.post@n4.nabble.com>
 <015301d2d73f$f2012b00$d6038100$@ngtech.co.il>
Message-ID: <1495981494499-4682608.post@n4.nabble.com>

As I said before, is a more larger problem. not just Youtube. If rewrite is
necessary, doesn't work the cache. I tried with Youtube, Facebook, Vimeo,
etc.

Anyway I will try these links that you suggested and put here the results.
It work very well until Squid 3.5.19. Not in newest versions.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Youtube-not-TCP-HIT-Squid3-5-21-25-tp4682582p4682608.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sun May 28 14:47:05 2017
From: yvoinov at gmail.com (Yuri)
Date: Sun, 28 May 2017 20:47:05 +0600
Subject: [squid-users] Youtube not TCP_HIT Squid3.5.21-25
In-Reply-To: <1495981494499-4682608.post@n4.nabble.com>
References: <1495745270225-4682582.post@n4.nabble.com>
 <1495804175132-4682584.post@n4.nabble.com>
 <015301d2d73f$f2012b00$d6038100$@ngtech.co.il>
 <1495981494499-4682608.post@n4.nabble.com>
Message-ID: <1e606dbe-a559-236e-0248-e577eebccc01@gmail.com>

To better understanding pls read this and all related:

http://wiki.squid-cache.org/ConfigExamples/DynamicContent

http://wiki.squid-cache.org/Features/StoreID

YT, FB, Vimeo uses dynamic content and requires additional efforts to
make content cacheable (with some restrictions).

The issue your experienced can be related (partially) with dropped
support for ignoring cache-control.

Since you do not bring any technical details, it's hard to say exactly
what you want to achieve and in what way, and also to say that you -
perhaps - are doing wrong.

28.05.2017 20:24, Eduardo Carneiro ?????:
> As I said before, is a more larger problem. not just Youtube. If rewrite is
> necessary, doesn't work the cache. I tried with Youtube, Facebook, Vimeo,
> etc.
>
> Anyway I will try these links that you suggested and put here the results.
> It work very well until Squid 3.5.19. Not in newest versions.
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Youtube-not-TCP-HIT-Squid3-5-21-25-tp4682582p4682608.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170528/e16828bd/attachment.sig>

From eduardoocarneiro at gmail.com  Sun May 28 15:09:58 2017
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Sun, 28 May 2017 08:09:58 -0700 (PDT)
Subject: [squid-users] Youtube not TCP_HIT Squid3.5.21-25
In-Reply-To: <1e606dbe-a559-236e-0248-e577eebccc01@gmail.com>
References: <1495745270225-4682582.post@n4.nabble.com>
 <1495804175132-4682584.post@n4.nabble.com>
 <015301d2d73f$f2012b00$d6038100$@ngtech.co.il>
 <1495981494499-4682608.post@n4.nabble.com>
 <1e606dbe-a559-236e-0248-e577eebccc01@gmail.com>
Message-ID: <1495984198561-4682610.post@n4.nabble.com>

Ok. Tell me what technical details you need and I post here.

But if this were an ignoring cache-control issue, wouldn't that happen on
squid 3.5.19 and previous versions as well?

With the same conf works on 3.5.19 but not in newest squid3 versions.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Youtube-not-TCP-HIT-Squid3-5-21-25-tp4682582p4682610.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sun May 28 17:21:30 2017
From: yvoinov at gmail.com (Yuri)
Date: Sun, 28 May 2017 23:21:30 +0600
Subject: [squid-users] Youtube not TCP_HIT Squid3.5.21-25
In-Reply-To: <1495984198561-4682610.post@n4.nabble.com>
References: <1495745270225-4682582.post@n4.nabble.com>
 <1495804175132-4682584.post@n4.nabble.com>
 <015301d2d73f$f2012b00$d6038100$@ngtech.co.il>
 <1495981494499-4682608.post@n4.nabble.com>
 <1e606dbe-a559-236e-0248-e577eebccc01@gmail.com>
 <1495984198561-4682610.post@n4.nabble.com>
Message-ID: <d473e07e-9975-2e8a-ccc5-a119dfa0edc8@gmail.com>



28.05.2017 21:09, Eduardo Carneiro ?????:
> Ok. Tell me what technical details you need and I post here.
Configs. Logs. Topology. Usecases. Examples for single transactions.
>
> But if this were an ignoring cache-control issue, wouldn't that happen on
> squid 3.5.19 and previous versions as well?
>
> With the same conf works on 3.5.19 but not in newest squid3 versions.
Once more. Ignoring cache-control in squid is deprecated due to RFC
requirements. So, it leads to drops down with byte HIT in general. I do
not remember when it exactly desupported in squid's code, but seems
approx. at some 3.5.x.

I can't to say exactly, because of using Squid 5.x branch right now.
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Youtube-not-TCP-HIT-Squid3-5-21-25-tp4682582p4682610.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170528/9880cbfd/attachment.sig>

From rousskov at measurement-factory.com  Sun May 28 17:54:07 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 28 May 2017 11:54:07 -0600
Subject: [squid-users] Squid TPROXY issues with Google sites
In-Reply-To: <993213090.790265.1495971631319@mail.yahoo.com>
References: <589790035.698921.1495813442972.ref@mail.yahoo.com>
 <589790035.698921.1495813442972@mail.yahoo.com>
 <f00f4540-6a5b-ffa3-aa3d-8a4e33d366a4@treenet.co.nz>
 <179822685.137977.1495840922368@mail.yahoo.com>
 <4f6e6441-cda6-c7fc-0cee-1d32e0822671@measurement-factory.com>
 <993213090.790265.1495971631319@mail.yahoo.com>
Message-ID: <c21a79dd-55e9-6c3a-4c60-fa3140d3d015@measurement-factory.com>

On 05/28/2017 05:40 AM, Vieri wrote:

> Please keep in mind that I'm basically an end-user, a sys-admin. I
> wish I had the time to study Squid's source code.

Nobody (certainly not me) has suggested anything that requires studying
Squid source code. If you think that I have, you have misinterpreted
what I have said.


> The cache log reports errors but they are not necessarily related to
> this client as there are many others actively browsing.

I recommend triaging this using a Squid instance isolated from all other
traffic. You are making both your job and the job of those who are
trying to help you more difficult by trying to save a few minutes/hours
that are usually required to set up an isolated test.


> Anyway, as a workaround I'm willing to splice/tunnel traffic to
> accounts.google.com *ONLY*, and bump everything else (although I'd
> prefer to understand why bumping isn't "working" for this site).

> I've tried this:

> acl GoogleAccounts ssl::server_name accounts.google.com
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump splice GoogleAccounts
> ssl_bump bump all

> However, traffic to accounts.google.com is not spliced, it's bumped
> like the rest.

You need to figure out why. Two common reasons are SSL-level errors and
http_access denials. Both should be reflected in access.log and
debugging cache.log.


> Can FQDNs be used in ACLs as in the example above even when peeking at step 1?

Yes. They may not work, but they can be used. They should work if the
request contains TLS SNI. Modern browser requests usually do, but you
can confirm by studying browser-Squid traffic with a tool like Wireshark.


> If I peek at step 2 then I won't be able to "bump all"

Correct.


> Likewise, If I need to stare at step 2 then I'll never be able to splice

Correct.


Alex.



From andreas.lauterbach76 at gmx.de  Sun May 28 19:52:59 2017
From: andreas.lauterbach76 at gmx.de (Andi)
Date: Sun, 28 May 2017 21:52:59 +0200
Subject: [squid-users] How to intercept ssl_bump transparent NAT https
	websites
Message-ID: <0LqV4f-1dsXrv05Uv-00e22Q@mail.gmx.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170528/fc72a732/attachment.htm>

From squid3 at treenet.co.nz  Sun May 28 21:09:50 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 29 May 2017 09:09:50 +1200
Subject: [squid-users] Youtube not TCP_HIT Squid3.5.21-25
In-Reply-To: <d473e07e-9975-2e8a-ccc5-a119dfa0edc8@gmail.com>
References: <1495745270225-4682582.post@n4.nabble.com>
 <1495804175132-4682584.post@n4.nabble.com>
 <015301d2d73f$f2012b00$d6038100$@ngtech.co.il>
 <1495981494499-4682608.post@n4.nabble.com>
 <1e606dbe-a559-236e-0248-e577eebccc01@gmail.com>
 <1495984198561-4682610.post@n4.nabble.com>
 <d473e07e-9975-2e8a-ccc5-a119dfa0edc8@gmail.com>
Message-ID: <92ec60d6-b686-ec7a-f060-8c65af0035a0@treenet.co.nz>

On 29/05/17 05:21, Yuri wrote:
>
> 28.05.2017 21:09, Eduardo Carneiro ?????:
>> Ok. Tell me what technical details you need and I post here.
> Configs. Logs. Topology. Usecases. Examples for single transactions.
>> But if this were an ignoring cache-control issue, wouldn't that happen on
>> squid 3.5.19 and previous versions as well?
>>
>> With the same conf works on 3.5.19 but not in newest squid3 versions.
> Once more. Ignoring cache-control in squid is deprecated due to RFC
> requirements. So, it leads to drops down with byte HIT in general. I do
> not remember when it exactly desupported in squid's code, but seems
> approx. at some 3.5.x.

 From 3.5.19 onwards ..

3.5.21 added support for Squid to differentiate between revalidation 
checks that were always vs sometimes necessary. Fixing the situation 
where responses had both a CC:private or CC:no-cache header and 
information stating cacheability "freshness".

3.5.22 fixed issues that were then seen with missing Last-Modified and 
old Date values, and the Collapsed Forwarding feature.

3.5.23 added support for caching objects with "Vary: *" which depended 
on the change in .21, and caching of 3034 responses. Also fixed the main 
outstanding issue behind Host verify MISS happening, and a regression in 
the .22 collapsed forwarding change.

3.5.24 fixed a regression in the "cache deny" access control handling 
which was causing some thing to be cached and revalidated when they 
should not have. This may make some things now un-cacheable if there is 
a misconfiguration in that directive.

3.5.25 fixed a stall that happens when SSL-Bump interacts with Host 
verification through the SNI value. While not strictly related, having 
it fixed allows a lot more Google/YouTube/Akamai transactions to reach 
the caching stages so their operations start to be visible instead of 
splice/tunnel'ed.


The expected effect of these changes was to fix several major 
unnecessary bandwidth uses;
  - cached YouTube videos starting mid-video when someone else using the 
proxy had only partially watched the same video - causing the user to 
force-refresh and purge the cached video.
  - Chrome and similar Google originated downloads being a MISS for 
identical objects.
  - the often cited terrible HIT reduction on some major hosting 
services (again Google, though also Akamai) traffic since 3.2 Host 
verify was added.
  - collapsed forwarding resulting in large objects being stored to the 
cache then immediately deleted by a parallel fetch.


Amos


From yvoinov at gmail.com  Sun May 28 21:19:08 2017
From: yvoinov at gmail.com (Yuri)
Date: Mon, 29 May 2017 03:19:08 +0600
Subject: [squid-users] Youtube not TCP_HIT Squid3.5.21-25
In-Reply-To: <92ec60d6-b686-ec7a-f060-8c65af0035a0@treenet.co.nz>
References: <1495745270225-4682582.post@n4.nabble.com>
 <1495804175132-4682584.post@n4.nabble.com>
 <015301d2d73f$f2012b00$d6038100$@ngtech.co.il>
 <1495981494499-4682608.post@n4.nabble.com>
 <1e606dbe-a559-236e-0248-e577eebccc01@gmail.com>
 <1495984198561-4682610.post@n4.nabble.com>
 <d473e07e-9975-2e8a-ccc5-a119dfa0edc8@gmail.com>
 <92ec60d6-b686-ec7a-f060-8c65af0035a0@treenet.co.nz>
Message-ID: <c0122f35-b8cf-49cd-247b-693c9f5cfeda@gmail.com>

Yup, thank you, Amos, for details. I do not remember all changelogs exactly.


29.05.2017 3:09, Amos Jeffries ?????:
> On 29/05/17 05:21, Yuri wrote:
>>
>> 28.05.2017 21:09, Eduardo Carneiro ?????:
>>> Ok. Tell me what technical details you need and I post here.
>> Configs. Logs. Topology. Usecases. Examples for single transactions.
>>> But if this were an ignoring cache-control issue, wouldn't that
>>> happen on
>>> squid 3.5.19 and previous versions as well?
>>>
>>> With the same conf works on 3.5.19 but not in newest squid3 versions.
>> Once more. Ignoring cache-control in squid is deprecated due to RFC
>> requirements. So, it leads to drops down with byte HIT in general. I do
>> not remember when it exactly desupported in squid's code, but seems
>> approx. at some 3.5.x.
>
> From 3.5.19 onwards ..
>
> 3.5.21 added support for Squid to differentiate between revalidation
> checks that were always vs sometimes necessary. Fixing the situation
> where responses had both a CC:private or CC:no-cache header and
> information stating cacheability "freshness".
>
> 3.5.22 fixed issues that were then seen with missing Last-Modified and
> old Date values, and the Collapsed Forwarding feature.
>
> 3.5.23 added support for caching objects with "Vary: *" which depended
> on the change in .21, and caching of 3034 responses. Also fixed the
> main outstanding issue behind Host verify MISS happening, and a
> regression in the .22 collapsed forwarding change.
>
> 3.5.24 fixed a regression in the "cache deny" access control handling
> which was causing some thing to be cached and revalidated when they
> should not have. This may make some things now un-cacheable if there
> is a misconfiguration in that directive.
>
> 3.5.25 fixed a stall that happens when SSL-Bump interacts with Host
> verification through the SNI value. While not strictly related, having
> it fixed allows a lot more Google/YouTube/Akamai transactions to reach
> the caching stages so their operations start to be visible instead of
> splice/tunnel'ed.
>
>
> The expected effect of these changes was to fix several major
> unnecessary bandwidth uses;
>  - cached YouTube videos starting mid-video when someone else using
> the proxy had only partially watched the same video - causing the user
> to force-refresh and purge the cached video.
>  - Chrome and similar Google originated downloads being a MISS for
> identical objects.
>  - the often cited terrible HIT reduction on some major hosting
> services (again Google, though also Akamai) traffic since 3.2 Host
> verify was added.
>  - collapsed forwarding resulting in large objects being stored to the
> cache then immediately deleted by a parallel fetch.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170529/06f3e7d3/attachment.sig>

From harariboy at gmail.com  Sun May 28 21:26:26 2017
From: harariboy at gmail.com (avi_h)
Date: Sun, 28 May 2017 14:26:26 -0700 (PDT)
Subject: [squid-users] External ACL
In-Reply-To: <1495670900382-4682566.post@n4.nabble.com>
References: <1495502728560-4682519.post@n4.nabble.com>
 <046c5862-9f83-911e-0e0f-aa3d52db6a34@treenet.co.nz>
 <1495544529394-4682527.post@n4.nabble.com>
 <bb991bc6-d898-7fd6-f525-084affa93716@treenet.co.nz>
 <1495641649465-4682544.post@n4.nabble.com>
 <1495656999263-4682555.post@n4.nabble.com>
 <f6666fd7-a855-9304-d5c8-1c68c6d2329f@treenet.co.nz>
 <1495670900382-4682566.post@n4.nabble.com>
Message-ID: <1496006786176-4682616.post@n4.nabble.com>

Hi Amos,

So I tried working with some older versions of squid but i still got the
same issue.
This happens both with my basic helper in python and with the
ext_sql_session_acl.
I'm kinda lost. Any chance you have any advice? Is it possible that the
issue is with the channel parameter?

Thanks,
Avi



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/External-ACL-tp4682519p4682616.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sun May 28 22:03:49 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 29 May 2017 10:03:49 +1200
Subject: [squid-users] How to intercept ssl_bump transparent NAT https
 websites
In-Reply-To: <0LqV4f-1dsXrv05Uv-00e22Q@mail.gmx.com>
References: <0LqV4f-1dsXrv05Uv-00e22Q@mail.gmx.com>
Message-ID: <93f53090-4c66-62fa-cf38-daeeb33ebf42@treenet.co.nz>

On 29/05/17 07:52, Andi wrote:
> Hi
>
>     I installed Squid 3.5.25 at debian with libecap3 too.
>
>     Now my old squid.conf file for v3.48 not work anymore for
>     redirected https websites.
>     I get SSL_ERROR_RX_RECORD_TOO_LONG in Firefox.
>     I redirected them before by Shorewall and it worked with v3.48
>     #SQUID-PORTS
>     REDIRECT    loc    3140 tcp    https    - !192.168.1.254
>     REDIRECT    loc    3139 tcp    www    - !192.168.1.254
>
>
>     If I change https_port to http_port and remove the intercept
>     option for ssl_bump it works with expicit configured clients for
>     that port even for gmail website too.
>     What I need to change to make squid 3.5 work transparently  ?
>

SSL_ERROR_RX_RECORD_TOO_LONG is apparently what gets displayed if the 
response coming back from an attempted TLS/SSL connection is not TLS/SSL 
protocol. Such as Squid responding with an HTTP error message, or 
something like that happening.


Your below config has port 3128 for explicit-proxy traffic, port 3139 
for intercepted port 80 traffic, and 3140 for intercepted port 443 traffic.

Your log startup confirms that:

 > 2017/05/28 16:07:55.701| Accepting HTTP Socket connections at 
local=0.0.0.0:3138 remote=[::] FD 28 flags=9
 > 2017/05/28 16:07:55.702| Accepting NAT intercepted HTTP Socket 
connections at local=0.0.0.0:3139 remote=[::] FD 29 flags=41
 > 2017/05/28 16:07:55.702| Accepting NAT intercepted SSL bumped HTTPS 
Socket connections at local=0.0.0.0:3140 remote=[::] FD 30 flags=41


The first thing I would check is that the shorewall definitions of 
"https" and "www" are actually 80 and 443 respectively.

Then try to find out what Squid is sending to Firefox that would result 
in that particular error. I suspect either ICAP or SquidGuard is trying 
to change or produce a plan-text response to the initial CONNECT 
messages Squid uses internally for the SSL-Bump steps.



NP: the "abandoning" messages in cache.log are nothing to worry about 
when you are ssl-bump'ing with Squid-3, it is just an annoying 
side-effect of how SSL-Bump takes the connection away from the normal 
CONNECT tunnel handling code. IIRC it has been fixed in Squid-4 along 
with a lot of similar little PITA things.

PS. I've highlighted some improvements you can make to the config below. 
They are not related to your problem though.

>     squid -v
>     Squid Cache: Version 3.5.25
>     Service Name: squid
>     configure options:  '--build=x86_64-linux-gnu' '--prefix=/usr'
>     '--localstatedir=/var/squid' '--libexecdir=/lib/squid'
>     '--srcdir=.' '--datadir=/share/squid' '--sysconfdir=/etc/squid'
>     '--disable-ipv6' '--with-default-user=proxy'
>     '--with-logdir=/var/log/squid35'
>     '--with-pidfile=/var/run/squid35.pid' '--with-openssl'
>     '--enable-ssl-crtd' '--infodir=/share/info'
>     '--includedir=/include' '--mandir=/usr/share/man'
>     '--enable-inline' '--disable-arch-native'
>     '--disable-maintainer-mode' '--disable-dependency-tracking'
>     '--disable-silent-rules' '--enable-async-io=8'
>     '--enable-storeio=ufs,aufs,diskd,rock'
>     '--enable-removal-policies=lru,heap' '--enable-delay-pools'
>     '--enable-cache-digests' '--enable-icap-client'
>     '--enable-follow-x-forwarded-for'
>     '--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB'
>     '--enable-auth-digest=file,LDAP'
>     '--enable-auth-negotiate=kerberos,wrapper'
>     '--enable-auth-ntlm=fake,smb_lm'
>     '--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,unix_group,wbinfo_group'
>     '--enable-url-rewrite-helpers=fake' '--enable-eui' '--enable-esi'
>     '--enable-icmp' '--enable-zph-qos' '--enable-ecap'
>     '--disable-translation' '--with-filedescriptors=65536'
>     '--with-large-files' '--enable-linux-netfilter' 'CFLAGS=-g -O2
>     -fPIE -fstack-protector-strong -Wformat -Werror=format-security
>     -Wall' 'LDFLAGS=-fPIE -pie -Wl,-z,relro -Wl,-z,now'
>     'CPPFLAGS=-D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -fPIE
>     -fstack-protector-strong -Wformat -Werror=format-security'
>     'build_alias=x86_64-linux-gnu'
>
>     cat /etc/squid/squid.conf:
>     debug_options ALL,6
>     #0 26,2 83,2 33,2 17,2 44,2
>     logformat datetime  %tl %6tr CLIENT:%>a = = %Ss %<Hs %rm=%>ru
>     --%[un %Sh/%<a %mt
>     access_log  /var/log/squid35/access.log datetime
>     forwarded_for on
>     error_directory /usr/share/squid/errors/de-de/
>

Have you altered or otherwise touched the files in that directory?
If not I suggest using this instead:

   error_default_language de-de
<http://master.squid-cache.org/Doc/config/error_default_language/>

>     acl localnet src 192.168.1.0/24
>     acl SSL_ports port 443
>     acl Safe_ports port 80          # http
>     acl Safe_ports port 21          # ftp
>     acl Safe_ports port 443         # https
>     acl Safe_ports port 70          # gopher
>     acl Safe_ports port 210         # wais
>     acl Safe_ports port 1025-65535  # unregistered ports
>     acl Safe_ports port 280         # http-mgmt
>     acl Safe_ports port 488         # gss-http
>     acl Safe_ports port 591         # filemaker
>     acl Safe_ports port 777         # multiling http
>     acl CONNECT method CONNECT
>     http_access deny !Safe_ports
>     http_access deny CONNECT !SSL_ports
>     http_access allow localhost manager
>     http_access deny manager
>     http_access deny to_localhost
>     http_access allow localnet
>     http_access allow localhost
>     http_reply_access allow all
>

No need to explicitly "allow all" for replies. That happens anyway. That 
directive is mostly useful to deny things.


>     http_access deny all
>     icp_access allow localnet
>     icp_access deny all
>     ### NEW for v3.5x SSL-Bump ###
>     always_direct allow all
>

That "always_direct" was a hack to workaround a bug in the first 
ssl-bump code. It is long since irrelevant. I recommend removing it.

>     acl step1 at_step SslBump1
>     acl step2 at_step SslBump2
>     acl step3 at_step SslBump3
>     ssl_bump splice localhost
>     #acl exclude_sites ssl::server_name_regex -i
>     "/var/lib/squidguard/db/BL/whitelist-ssl/whitelist.destdomainlist"
>     ssl_bump peek step1 all
>     #ssl_bump splice exclude_sites
>     ssl_bump stare step2 all
>

You don't need the "all" on the above lines. The "step2 all" is both 
unnecessary and adds confusion since that line does *not* apply to all 
step2 traffic - some was spliced instead by the previous line.

>     ssl_bump bump all
>     #############################
>     http_port 0.0.0.0:3138
>     http_port 0.0.0.0:3139 intercept
>     sslproxy_cert_adapt setCommonName ssl::certDomainMismatch
>     https_port 0.0.0.0:3140 intercept ssl-bump
>     generate-host-certificates=on dynamic_cert_mem_cache_size=16MB
>     cert=/etc/squid/myca.pem
>     sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>     sslproxy_capath /etc/ssl/certs
>     ##sslproxy_cafile /etc/ssl/certs/ca-certificates.crt
>     sslcrtd_program /bin/ssl_crtd -s /var/spool/squid_ssldb -M 16MB
>     sslcrtd_children 10
>     cache_dir ufs /etc/squid/ssl_db 100 16 256
>

Why are you storing all cacheable *HTTP* objects into /etc/squid/ssl_db ?
  especially since your SSL certificate store is /var/spool/squid_ssldb ?

>     cache_mgr admin at mainrouter
>     visible_hostname xxx
>     httpd_suppress_version_string on
>     coredump_dir /var/spool/squid
>     refresh_pattern ^ftp: 1440    20%     10080
>     refresh_pattern ^gopher: 1440    0%      1440
>     refresh_pattern -i (/cgi-bin/|\?) 0 0%      0
>     refresh_pattern                0       20%     4320
>     cache_effective_user proxy
>

You built this proxy with --with-default-user=proxy , which sets the 
default value of cache_effective_user to "proxy", no need to repeat that 
in squid.conf.

>     icap_enable on
>     icap_send_client_ip on
>     icap_send_client_username on
>     icap_client_username_encode off
>     icap_client_username_header X-Authenticated-User
>     icap_preview_enable on
>     icap_preview_size 1024
>     icap_service service_req reqmod_precache bypass=0
>     icap://127.0.0.1:1344/squidclamav
>     icap_service service_resp respmod_precache bypass=0
>     icap://127.0.0.1:1344/squidclamav
>     adaptation_access service_req allow all
>     adaptation_access service_resp allow all
>     redirect_program /usr/bin/squidGuard -c
>     /etc/squidguard/squidGuard.conf
>     cache_effective_group proxy
>

There should be no need for that cache_effective_group directive to be 
used. Simply check and limit the groups the cache_effective_user account 
is a member of.

>     dns_nameservers 8.8.8.8
>

Using that DNS service directly in Squid is particularly nasty. Each DNS 
query usually hits a different server in their farm and thus gets 
different set of response IP addresses. I strongly recommend that you 
setup some local DNS recursive resolver that both the clients and Squid 
can use. That resolver can of course pass its traffic to 8.8.8.8 if you 
actually need to.



Amos



From style9595 at gmail.com  Mon May 29 07:03:25 2017
From: style9595 at gmail.com (Dominic Kim)
Date: Mon, 29 May 2017 16:03:25 +0900
Subject: [squid-users] 503 service unavailable on connection refused
In-Reply-To: <12341987-c2ab-d01a-922c-c64f756edaa9@measurement-factory.com>
References: <CAFEpjOqc+aNX=B8pKXvPLXDj7Af+4cBtSnXC=ditUhfE0AV0yw@mail.gmail.com>
 <CAFEpjOotnQC0n_3wETRqQ8QUP8Gt9D_ANvij2vH=+W26K7hxoQ@mail.gmail.com>
 <12341987-c2ab-d01a-922c-c64f756edaa9@measurement-factory.com>
Message-ID: <CAFEpjOp=79H8MzfTs9oP3ojwyQHnkXOAxo1ukzOeuS7gbcUckQ@mail.gmail.com>

My bad..

Please find the attached log.

It looks squid is retrying many times.
And after reach maximum retry limit, it responds with 503 service
unavailable.

As you know maximum limit is 10 times.
It looks that it retries 10 times within just 3 seconds.

Are there any way to configure retry interval?

Thanks
Regards
Dominic

2017-05-23 1:13 GMT+09:00 Alex Rousskov <rousskov at measurement-factory.com>:

> On 05/22/2017 03:02 AM, Dominic Kim wrote:
> > I have tested with squid 3.3, 3.5, 4.
> > And the behavior were same.
>
> When using Squid v3.5 or v4, please reproduce the problem using a single
> HTTP transaction while collecting level-7 or higher debugging and then
> post the corresponding (compressed) cache.log.
>
> http://wiki.squid-cache.org/SquidFaq/BugReporting#
> Debugging_a_single_transaction
>
> Alex.
>
>
> > 2017-05-22 18:01 GMT+09:00 Dominic Kim:
> >
> >     When I connect to a target server via squid, if server does not
> >     exist, I get "No route to host" error.
> >     And if server exist, but port is not opened yet, I get "Connection
> >     refused" error.
> >
> >     As per the definition of "connect_retries" option, it should retry
> >     when connection attempt failed.
> >     (reference: http://www.squid-cache.org/Doc/config/connect_retries/
> >     <http://www.squid-cache.org/Doc/config/connect_retries/>)
> >
> >     IMHO, in both the cases, connection attempts failed and it is
> >     supposed to retry.
> >     However, if I enable this feature, it only retries on "No route to
> >     host" error.
> >     In case of "Connection refused", I am getting 503 service
> >     unavailable error immediately.
> >
> >     Are there anyway to fix this behavior?
> >     Kindly help me.
> >
> >     Thanks
> >     Regards
> >     Dongkyoung
> >
> >
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170529/caf89ecc/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: partail-cache.tar.gz
Type: application/x-gzip
Size: 24712 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170529/caf89ecc/attachment.bin>

From ahmed.zaeem at netstream.ps  Mon May 29 07:44:31 2017
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Mon, 29 May 2017 10:44:31 +0300
Subject: [squid-users] enable  outgoing address in LOGS
Message-ID: <C540CD9A-C329-43CD-814F-820348C07C44@netstream.ps>

Hello folks .
i have squid working on IPV6 
but i want to display the outgoing IPV6 address in logs .
as an example  if we have tcp_outgoing_Address xxxx yyyy
i want to see xxxx in logs when traffic match the acl above .



sample of logs :
#########################
1496045025.838   1172 208.85.6.130 TCP_TUNNEL/200 5530 CONNECT i.instagram.com:443 - HIER_DIRECT/2a03:2880:f223:c4:face:b00c:0:43fe -
1496045026.121   1114 208.85.6.130 TCP_TUNNEL/200 5530 CONNECT i.instagram.com:443 - HIER_DIRECT/2a03:2880:f223:c4:face:b00c:0:43fe -
1496045026.236    827 208.85.6.130 TCP_TUNNEL/200 1414 CONNECT i.instagram.com:443 - HIER_DIRECT/2a03:2880:f223:c4:face:b00c:0:43fe -
1496045026.251    846 208.85.6.130 TCP_TUNNEL/200 2592 CONNECT i.instagram.com:443 - HIER_DIRECT/2a03:2880:f223:c4:face:b00c:0:43fe -
1496045026.314    682 208.85.6.130 TCP_TUNNEL/200 2357 CONNECT i.instagram.com:443 - HIER_DIRECT/2a03:2880:f223:c4:face:b00c:0:43fe -
1496045026.828    351 208.85.6.130 TCP_TUNNEL/200 15250 CONNECT connect.facebook.net:443 - HIER_DIRECT/2a03:2880:f006:21:face:b00c:0:3 -
1496045026.957    953 208.85.6.130 TCP_TUNNEL/200 5530 CONNECT i.instagram.com:443 - HIER_DIRECT/2a03:2880:f223:c4:face:b00c:0:43fe -
1496045027.038   1024 208.85.6.130 TCP_TUNNEL/200 2341 CONNECT i.instagram.com:443 - HIER_DIRECT/2a03:2880:f223:c4:face:b00c:0:43fe -
1496045027.054    764 208.85.6.130 TCP_TUNNEL/200 2357 CONNECT i.instagram.com:443 - HIER_DIRECT/2a03:2880:f223:c4:face:b00c:0:43fe -
1496045027.231    214 208.85.6.130 TCP_TUNNEL/200 9664 CONNECT connect.facebook.net:443 - HIER_DIRECT/2a03:2880:f006:21:face:b00c:0:3 -
1496045027.552    349 208.85.6.130 TCP_TUNNEL/200 15250 CONNECT connect.facebook.net:443 - HIER_DIRECT/2a03:2880:f006:21:face:b00c:0:3 -
1496045027.569   1217 208.85.6.130 TCP_TUNNEL/200 838 CONNECT i.instagram.com:443 - HIER_DIRECT/2a03:2880:f223:c4:face:b00c:0:43fe -
1496045027.572    353 208.85.6.130 TCP_TUNNEL/200 15250 CONNECT connect.facebook.net:443 - HIER_DIRECT/2a03:2880:f006:21:face:b00c:0:3 -
1496045027.931    188 208.85.6.130 TCP_TUNNEL/200 9664 CONNECT connect.facebook.net:443 - HIER_DIRECT/2a03:2880:f006:21:face:b00c:0:3 -
1496045027.957    193 208.85.6.130 TCP_TUNNEL/200 9664 CONNECT connect.facebook.net:443 - HIER_DIRECT/2a03:2880:f006:21:face:b00c:0:3 -
1496045028.062    939 208.85.6.130 TCP_TUNNEL/200 2341 CONNECT i.instagram.com:443 - HIER_DIRECT/2a03:2880:f223:c4:face:b00c:0:43fe -
1496045028.568    344 208.85.6.130 TCP_TUNNEL/200 15250 CONNECT connect.facebook.net:443 - HIER_DIRECT/2a03:2880:f006:21:face:b00c:0:3 -
1496045029.292    544 208.85.6.130 TCP_TUNNEL/200 9664 CONNECT connect.facebook.net:443 - HIER_DIRECT/2a03:2880:f006:21:face:b00c:0:3 -
1496045030.764    919 208.85.6.130 TCP_TUNNEL/200 16479 CONNECT i.instagram.com:443 - HIER_DIRECT/2a03:2880:f223:c4:face:b00c:0:43fe -
1496045030.775  20256 208.85.6.130 TCP_TUNNEL/200 950 CONNECT i.instagram.com:443 - HIER_DIRECT/2a03:2880:f223:c4:face:b00c:0:43fe -
1496045031.157    781 208.85.6.130 TCP_TUNNEL/200 1638 CONNECT i.instagram.com:443 - HIER_DIRECT/2a03:2880:f223:c4:face:b00c:0:43fe -
1496045031.359    470 208.85.6.130 TCP_TUNNEL/200 3584 CONNECT www.instagram.com:443 - HIER_DIRECT/2a03:2880:f22d:c4:face:b00c:0:43fe -
######################################


as we see above , squid display ip address of dst address , how can i show the outgoing ip address ?


cheers 


######################################################################
www.V6Proxies.com
info at V6Proxies.com

##########################################################################
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170529/801eca57/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: c001dd831f4f4a3fdccb8587d2c7f767.png
Type: image/png
Size: 56103 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170529/801eca57/attachment.png>

From squid3 at treenet.co.nz  Mon May 29 09:12:49 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 29 May 2017 21:12:49 +1200
Subject: [squid-users] enable outgoing address in LOGS
In-Reply-To: <C540CD9A-C329-43CD-814F-820348C07C44@netstream.ps>
References: <C540CD9A-C329-43CD-814F-820348C07C44@netstream.ps>
Message-ID: <352e5e64-4eb3-0d43-3d31-7145a43a2336@treenet.co.nz>

On 29/05/17 19:44, --Ahmad-- wrote:
> Hello folks .
> i have squid working on IPV6
> but i want to display the outgoing IPV6 address in logs .
> as an example  if we have tcp_outgoing_Address xxxx yyyy
> i want to see xxxx in logs when traffic match the acl above .
>

The info you seek is documented at:
<http://www.squid-cache.org/Doc/config/logformat/>

under "Connection related format codes"...

  "<" (outgoing) "la" (local address).

Amos



From rentorbuy at yahoo.com  Mon May 29 11:47:14 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Mon, 29 May 2017 11:47:14 +0000 (UTC)
Subject: [squid-users] squid block by Content-Type or Content-Disposition
References: <1875592861.1470806.1496058434618.ref@mail.yahoo.com>
Message-ID: <1875592861.1470806.1496058434618@mail.yahoo.com>

Hi,

I'm unable to block specific file downloads in http/https traffic. For example, I'd like to block .cab files from being downloaded.

Here's what I have:

# grep cab /usr/local/proxy-settings/denied.filetypes
\.cab(\?.*)?$

# grep -v ^# squid.test.conf | grep -v ^$
http_access allow localhost manager
http_access deny manager
http_port 3228 tproxy
https_port 3229 tproxy ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cert=/etc/ssl/squid/proxyserver.pem
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl interceptedhttp myportname 3228
acl interceptedhttps myportname 3229
acl denied_filetypes urlpath_regex -i "/usr/local/proxy-settings/denied.filetypes"
acl denied_mimetypes_req req_mime_type -i application/x-cab
acl denied_mimetypes_rep rep_mime_type -i application/x-cab
http_access deny denied_mimetypes_req
http_access deny denied_mimetypes_rep
http_access deny denied_filetypes
http_access deny interceptedhttp !localnet
http_access deny interceptedhttps !localnet
sslcrtd_program /usr/libexec/squid/ssl_crtd -s /var/lib/squid/ssl_db_test -M 16MB
sslcrtd_children 10
reply_header_access Alternate-Protocol deny all
ssl_bump stare all
ssl_bump bump all
icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_encode off
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024
icap_service squidclamav respmod_precache bypass=0 icap://127.0.0.1:1344/clamav
adaptation_access squidclamav allow all
cache_dir diskd /var/cache/squid.test 100 16 256
http_access allow localnet
http_access allow localhost
http_access deny all
coredump_dir /var/cache/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
pid_filename /run/squid.test.pid
access_log daemon:/var/log/squid/access.test.log squid
cache_log /var/log/squid/cache.test.log
debug_options rotate=1 ALL,5

In cache.log I see:

Content-Type: application/x-cab
Content-Disposition: attachment;filename="fake.cab";filename*=UTF-8''fake.cab

BTW if I replace the following:

acl denied_mimetypes_req req_mime_type -i application/x-cab
acl denied_mimetypes_rep rep_mime_type -i application/x-cab

with

acl denied_mimetypes_req req_mime_type -i application/x-
acl denied_mimetypes_rep rep_mime_type -i application/x-

then the cab file downloads are correctly blocked. This is obviously too restrictive.

This must be a dumb mistake on my behalf.
What am I missing?

Thanks,

Vieri


From squid3 at treenet.co.nz  Mon May 29 12:22:03 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 30 May 2017 00:22:03 +1200
Subject: [squid-users] squid block by Content-Type or Content-Disposition
In-Reply-To: <1875592861.1470806.1496058434618@mail.yahoo.com>
References: <1875592861.1470806.1496058434618.ref@mail.yahoo.com>
 <1875592861.1470806.1496058434618@mail.yahoo.com>
Message-ID: <cdd2b521-0b26-a88f-99ae-5fa93b70da79@treenet.co.nz>

On 29/05/17 23:47, Vieri wrote:
> Hi,
>
> I'm unable to block specific file downloads in http/https traffic. For example, I'd like to block .cab files from being downloaded.
>
> Here's what I have:
>
> # grep cab /usr/local/proxy-settings/denied.filetypes
> \.cab(\?.*)?$
>
> # grep -v ^# squid.test.conf | grep -v ^$
> http_access allow localhost manager
> http_access deny manager
> http_port 3228 tproxy
> https_port 3229 tproxy ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cert=/etc/ssl/squid/proxyserver.pem
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl interceptedhttp myportname 3228
> acl interceptedhttps myportname 3229
> acl denied_filetypes urlpath_regex -i "/usr/local/proxy-settings/denied.filetypes"
> acl denied_mimetypes_req req_mime_type -i application/x-cab
> acl denied_mimetypes_rep rep_mime_type -i application/x-cab
> http_access deny denied_mimetypes_req
> http_access deny denied_mimetypes_rep
> http_access deny denied_filetypes

>
> In cache.log I see:
>
> Content-Type: application/x-cab
> Content-Disposition: attachment;filename="fake.cab";filename*=UTF-8''fake.cab
>
> BTW if I replace the following:
>
> acl denied_mimetypes_req req_mime_type -i application/x-cab
> acl denied_mimetypes_rep rep_mime_type -i application/x-cab
>
> with
>
> acl denied_mimetypes_req req_mime_type -i application/x-
> acl denied_mimetypes_rep rep_mime_type -i application/x-
>
> then the cab file downloads are correctly blocked. This is obviously too restrictive.
>
> This must be a dumb mistake on my behalf.
> What am I missing?

Several things:

1) http_access is tested only for requests.

response/reply messages are controlled though http_reply_access.
<http://www.squid-cache.org/Doc/config/http_reply_access>

2) rep_mime_type ACL (note the 'p') tests reply headers, thus for use in 
http_reply_access and will not work in http_access.

3) req_mime_type ACL (note the 'q') tests request headers. It is for 
upload file types (POST, PUT etc).


Amos



From rentorbuy at yahoo.com  Mon May 29 12:36:24 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Mon, 29 May 2017 12:36:24 +0000 (UTC)
Subject: [squid-users] squid sslbump and certificates
References: <1666824574.1494153.1496061384978.ref@mail.yahoo.com>
Message-ID: <1666824574.1494153.1496061384978@mail.yahoo.com>

Hi,

When a client browser gets the Squid error page as shown below, what does it mean?
Does it mean that Squid doesn't trust the CA mentioned below?
If I wanted to allow the connection anyway, what options would I have?


The system returned:

(71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)

SSL Certficate error: certificate issuer (CA) not known: /C=US/O=GeoTrust, Inc./OU=Domain Validated SSL/CN=Secure Site Starter DV SSL CA - G2


Thanks,

Vieri


From rafael.akchurin at diladele.com  Mon May 29 12:41:14 2017
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Mon, 29 May 2017 12:41:14 +0000
Subject: [squid-users] squid sslbump and certificates
In-Reply-To: <1666824574.1494153.1496061384978@mail.yahoo.com>
References: <1666824574.1494153.1496061384978.ref@mail.yahoo.com>
 <1666824574.1494153.1496061384978@mail.yahoo.com>
Message-ID: <DB6PR0401MB2680BA1E032D170A3D770D3F8FF30@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Hello Vieri,

This article tries to explain why it happens.
https://docs.diladele.com/faq/squid/fix_unable_to_get_issuer_cert_locally.html#ssl-certificate-test-tool-in-web-safety-5

To fix it - better use what Yuri recommended in http://squid-web-proxy-cache.1019090.n4.nabble.com/Howto-fix-X509-V-ERR-UNABLE-TO-GET-ISSUER-CERT-LOCALLY-Squid-error-td4682015.html

Raf

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Vieri
Sent: Monday, May 29, 2017 2:36 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] squid sslbump and certificates

Hi,

When a client browser gets the Squid error page as shown below, what does it mean?
Does it mean that Squid doesn't trust the CA mentioned below?
If I wanted to allow the connection anyway, what options would I have?


The system returned:

(71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)

SSL Certficate error: certificate issuer (CA) not known: /C=US/O=GeoTrust, Inc./OU=Domain Validated SSL/CN=Secure Site Starter DV SSL CA - G2


Thanks,

Vieri
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From rentorbuy at yahoo.com  Mon May 29 12:54:19 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Mon, 29 May 2017 12:54:19 +0000 (UTC)
Subject: [squid-users] squid block by Content-Type or Content-Disposition
In-Reply-To: <cdd2b521-0b26-a88f-99ae-5fa93b70da79@treenet.co.nz>
References: <1875592861.1470806.1496058434618.ref@mail.yahoo.com>
 <1875592861.1470806.1496058434618@mail.yahoo.com>
 <cdd2b521-0b26-a88f-99ae-5fa93b70da79@treenet.co.nz>
Message-ID: <511867067.1486944.1496062459596@mail.yahoo.com>


______________________________
From: Amos Jeffries <squid3 at treenet.co.nz>
>
> 1) http_access is tested only for requests.
>
> response/reply messages are controlled though http_reply_access.


I knew it was going to be a dumb question. Thanks Amos! It works now.

I suppose it's preferable to be more specific with ACL entries such as:
^application/x-cab$

Thanks,

Vieri


From acctforjunk at yahoo.com  Mon May 29 22:05:40 2017
From: acctforjunk at yahoo.com (j m)
Date: Mon, 29 May 2017 22:05:40 +0000 (UTC)
Subject: [squid-users] Any obvious security issues in my squid.conf?
References: <1450217963.2684580.1496095540250.ref@mail.yahoo.com>
Message-ID: <1450217963.2684580.1496095540250@mail.yahoo.com>

I will be remotely accessing squid 3.5 for general web usage, using an encrypted browser-to-proxy connection, and username/password authentication. ?I believe my config is reasonably secure as it's based off the default config, but I'm unsure of myself due to some confusion. ?Are there any glaring issues with what I have?
https_port PORTNUMBER cert=/etc/squid/squid.pem

acl localnet src 192.168.0.0/16 # RFC1918 possible internal networkacl localnet src fc00::/7 ? ? ? # RFC 4193 local private network rangeacl localnet src fe80::/10 ? ? ?# RFC 4291 link-local (directly plugged) machinesacl SSL_ports port 443acl Safe_ports port 80 ? ? ? ? ?# httpacl Safe_ports port 21 ? ? ? ? ?# ftpacl Safe_ports port 443 ? ? ? ? # httpsacl Safe_ports port 70 ? ? ? ? ?# gopheracl Safe_ports port 210 ? ? ? ? # waisacl Safe_ports port 280 ? ? ? ? # http-mgmtacl Safe_ports port 488 ? ? ? ? # gss-httpacl Safe_ports port 591 ? ? ? ? # filemakeracl Safe_ports port 777 ? ? ? ? # multiling httpacl Safe_ports port 1025-65535 ?# unregistered portsacl CONNECT method CONNECThttp_access deny !Safe_portshttp_access deny CONNECT !SSL_portshttp_access deny manager## INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS#auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/passwdauth_param basic children 5auth_param basic realm Squid proxy-caching web serverauth_param basic credentialsttl 2 hoursauth_param basic casesensitive onacl ncsa_users proxy_auth REQUIRED
http_access allow ncsa_usershttp_access deny all
refresh_pattern ^ftp: ? ? ? ? ? 1440 ? ?20% ? ? 10080refresh_pattern ^gopher: ? ? ? ?1440 ? ?0% ? ? ?1440refresh_pattern -i (/cgi-bin/|\?) 0 ? ? 0% ? ? ?0refresh_pattern . ? ? ? ? ? ? ? 0 ? ? ? 20% ? ? 4320
cache deny allaccess_log nonenetdb_filename none
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170529/2f92bed3/attachment.htm>

From rentorbuy at yahoo.com  Mon May 29 22:11:44 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Mon, 29 May 2017 22:11:44 +0000 (UTC)
Subject: [squid-users] squid sslbump and certificates
In-Reply-To: <DB6PR0401MB2680BA1E032D170A3D770D3F8FF30@DB6PR0401MB2680.eurprd04.prod.outlook.com>
References: <1666824574.1494153.1496061384978.ref@mail.yahoo.com>
 <1666824574.1494153.1496061384978@mail.yahoo.com>
 <DB6PR0401MB2680BA1E032D170A3D770D3F8FF30@DB6PR0401MB2680.eurprd04.prod.outlook.com>
Message-ID: <548387612.1952806.1496095904224@mail.yahoo.com>


________________________________
From: Rafael Akchurin <rafael.akchurin at diladele.com>
>
> This article tries to explain why it happens.
> https://docs.diladele.com/faq/squid/fix_unable_to_get_issuer_cert_locally.html#ssl-certificate-test-tool-in-web-safety-5
> 

> To fix it - better use what Yuri recommended in http://squid-web-proxy-cache.1019090.n4.nabble.com/Howto-fix-X509-V-ERR-UNABLE-
> TO-GET-ISSUER-CERT-LOCALLY-Squid-error-td4682015.html

Thanks Raf. That really helped.

I successfully installed the intermediate certificate as a trusted CA system-wide with openssl (used 'update-ca-certificates').

However, I tried using the Squid config directive for intermediate certs instead, but failed.

This is what I did:

# wget http://somewhere/intermediate.crt -O intermediate.der
# openssl x509 -inform der -in intermediate.der -out intermediate.crt
# cat intermediate.crt >> /usr/local/share/proxy-settings/allowed.certs
In squid.conf:
sslproxy_foreign_intermediate_certs "/usr/local/share/proxy-settings/allowed.certs"
Restarted Squid but still had the same error page.

I guess I can stick to the system-wide openssl solution for now.

Thanks again,

Vieri


From andreas.lauterbach76 at gmx.de  Tue May 30 09:55:37 2017
From: andreas.lauterbach76 at gmx.de (Andi)
Date: Tue, 30 May 2017 11:55:37 +0200
Subject: [squid-users] How to intercept ssl_bump transparent NAT
	httpswebsites
Message-ID: <0M4WRI-1e7dfI11K8-00yldi@mail.gmx.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170530/f58b92e5/attachment.htm>

From rousskov at measurement-factory.com  Tue May 30 14:22:17 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 30 May 2017 08:22:17 -0600
Subject: [squid-users] 503 service unavailable on connection refused
In-Reply-To: <CAFEpjOp=79H8MzfTs9oP3ojwyQHnkXOAxo1ukzOeuS7gbcUckQ@mail.gmail.com>
References: <CAFEpjOqc+aNX=B8pKXvPLXDj7Af+4cBtSnXC=ditUhfE0AV0yw@mail.gmail.com>
 <CAFEpjOotnQC0n_3wETRqQ8QUP8Gt9D_ANvij2vH=+W26K7hxoQ@mail.gmail.com>
 <12341987-c2ab-d01a-922c-c64f756edaa9@measurement-factory.com>
 <CAFEpjOp=79H8MzfTs9oP3ojwyQHnkXOAxo1ukzOeuS7gbcUckQ@mail.gmail.com>
Message-ID: <ee6f1c78-01fc-9bfe-5299-69a54c071db3@measurement-factory.com>

On 05/29/2017 01:03 AM, Dominic Kim wrote:

> It looks squid is retrying many times.
> And after reach maximum retry limit, it responds with 503 service
> unavailable.

> As you know maximum limit is 10 times.
> It looks that it retries 10 times within just 3 seconds.

> Are there any way to configure retry interval?

There is not -- Squid retries as fast as possible. A quality patch
adding an ACL-driven artificial retry delay and/or an exponential
backoff algorithm should be welcomed IMO.

Alex.


> 2017-05-23 1:13 GMT+09:00 Alex Rousskov:
> 
>     On 05/22/2017 03:02 AM, Dominic Kim wrote:
>     > I have tested with squid 3.3, 3.5, 4.
>     > And the behavior were same.
> 
>     When using Squid v3.5 or v4, please reproduce the problem using a single
>     HTTP transaction while collecting level-7 or higher debugging and then
>     post the corresponding (compressed) cache.log.
> 
>     http://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction
>     <http://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction>
> 
>     Alex.
> 
> 
>     > 2017-05-22 18:01 GMT+09:00 Dominic Kim:
>     >
>     >     When I connect to a target server via squid, if server does not
>     >     exist, I get "No route to host" error.
>     >     And if server exist, but port is not opened yet, I get "Connection
>     >     refused" error.
>     >
>     >     As per the definition of "connect_retries" option, it should retry
>     >     when connection attempt failed.
>     >     (reference: http://www.squid-cache.org/Doc/config/connect_retries/
>     <http://www.squid-cache.org/Doc/config/connect_retries/>
>     >     <http://www.squid-cache.org/Doc/config/connect_retries/
>     <http://www.squid-cache.org/Doc/config/connect_retries/>>)
>     >
>     >     IMHO, in both the cases, connection attempts failed and it is
>     >     supposed to retry.
>     >     However, if I enable this feature, it only retries on "No route to
>     >     host" error.
>     >     In case of "Connection refused", I am getting 503 service
>     >     unavailable error immediately.
>     >
>     >     Are there anyway to fix this behavior?
>     >     Kindly help me.


From erdosain9 at gmail.com  Tue May 30 15:23:32 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 30 May 2017 08:23:32 -0700 (PDT)
Subject: [squid-users] this config is ok? is ok the order?
Message-ID: <1496157812155-4682631.post@n4.nabble.com>

acl local_machines dst 192.168.1.0/24 

###Kerberos Auth with ActiveDirectory###
auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -s
HTTP/squid.xxxxxxx.lan at xxxxxxx.LAN
auth_param negotiate children 25 startup=0 idle=1
auth_param negotiate keep_alive on

external_acl_type i-full %LOGIN /usr/lib64/squid/ext_kerberos_ldap_group_acl
-g i-full at xxxxxxx.LAN
external_acl_type i-limitado %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-limitado at xxxxxxx.LAN

#GRUPOS
acl i-full external i-full
acl i-limitado external i-limitado

####Bloquea Publicidad ( http://pgl.yoyo.org/adservers/ )
acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
http_access deny ads
#deny_info TCP_RESET ads

####Streaming
acl youtube url_regex -i \.flv$
acl youtube url_regex -i \.mp4$
acl youtube url_regex -i watch?
acl youtube url_regex -i youtube
acl facebook url_regex -i facebook
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.jpg)\? 
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.jpg)\?

##Dominios denegados
acl dominios_denegados dstdomain "/etc/squid/listas/dominios_denegados.lst"

#Puertos
acl SSL_ports port 443
acl SSL_ports port 8443
acl SSL_ports port 8080
acl SSL_ports port 20000
acl SSL_ports port 10000
acl SSL_ports port 2083

acl Safe_ports port 631         # httpCUPS
acl Safe_ports port 85
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 8443        # httpsalt
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 8080        # edesur y otros
acl Safe_ports port 2199	# radio
acl CONNECT method CONNECT


#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow i-limitado !dominios_denegados 
http_access allow i-full !dominios_denegados 
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 127.0.0.1:3128
http_port 192.168.1.215:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pem 

acl step1 at_step SslBump1 

acl excludeSSL ssl::server_name_regex "/etc/squid/listas/excluidosSSL.lst"

ssl_bump peek step1 
ssl_bump splice excludeSSL 
ssl_bump bump all 


# Uncomment and adjust the following to add a disk cache directory.
cache_dir diskd /var/spool/squid 15000 16 256
cache_mem 1000 MB
maximum_object_size_in_memory 1 MB

cache_swap_low 90
cache_swap_high 95

cache deny local_machines
quick_abort_min 1024 KB
quick_abort_max 2048 KB
quick_abort_pct 90

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid


#Your refresh_pattern
refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
ignore-private
refresh_pattern -i ^http:\/\/www\.google\.com\/$ 0 20% 360 override-expire
override-lastmod ignore-reload ignore-no-cache ignore-no-store
reload-into-ims ignore-must-revalidate

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320

###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
via off
forwarded_for delete
###

#Pools para ancho de banda
delay_pools 5

#Ancho de Youtube
delay_class 1 2 
delay_parameters 1 1000000/1000000 50000/256000
delay_access 1 allow i-limitado youtube !facebook
delay_access 1 deny all

#Ancho de Facebook
delay_class 2 2 
delay_parameters 2 1000000/1000000 50000/256000
delay_access 2 allow i-limitado facebook !youtube
delay_access 2 deny all

#Ancho de banda YOUTUBE FULL
delay_class 3 1
delay_parameters 3 1000000/1000000
delay_access 3 allow i-full youtube !facebook
delay_access 3 deny all

#Ancho de banda LIMITADO
delay_class 4 3 
delay_parameters 4 3000000/3000000 1000000/1000000 256000/512000
delay_access 4 allow i-limitado !youtube !facebook
delay_access 4 deny all

#Ancho de banda FULL
delay_class 5 3
delay_parameters 5 1500000/1500000 750000/750000 256000/512000
delay_access 5 allow i-full !youtube !facebook
delay_access 5 deny all

dns_nameservers 192.168.1.222 8.8.8.8
visible_hostname squid.xxxxxxx.lan

# try connecting to first 25 ips of a domain name
forward_max_tries 25

# fix some ipv6 errors (recommended to comment out) 
dns_v4_first on

# c-icap integration
# -------------------------------------
# Adaptation parameters
# -------------------------------------
icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024
icap_service service_avi_req reqmod_precache
icap://127.0.0.1:1344/squidclamav bypass=on
adaptation_access service_avi_req allow all
icap_service service_avi_resp respmod_precache
icap://127.0.0.1:1344/squidclamav bypass=off
adaptation_access service_avi_resp allow all
# end integration



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/this-config-is-ok-is-ok-the-order-tp4682631.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Tue May 30 21:48:11 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 31 May 2017 09:48:11 +1200
Subject: [squid-users] squid sslbump and certificates
In-Reply-To: <548387612.1952806.1496095904224@mail.yahoo.com>
References: <1666824574.1494153.1496061384978.ref@mail.yahoo.com>
 <1666824574.1494153.1496061384978@mail.yahoo.com>
 <DB6PR0401MB2680BA1E032D170A3D770D3F8FF30@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <548387612.1952806.1496095904224@mail.yahoo.com>
Message-ID: <a982180a-e389-9d05-9a74-6b951064b9c7@treenet.co.nz>

On 30/05/17 10:11, Vieri wrote:
> From: Rafael Akchurin <rafael.akchurin at diladele.com>
>> This article tries to explain why it happens.
>> https://docs.diladele.com/faq/squid/fix_unable_to_get_issuer_cert_locally.html#ssl-certificate-test-tool-in-web-safety-5
>>
>> To fix it - better use what Yuri recommended in http://squid-web-proxy-cache.1019090.n4.nabble.com/Howto-fix-X509-V-ERR-UNABLE-
>> TO-GET-ISSUER-CERT-LOCALLY-Squid-error-td4682015.html
> Thanks Raf. That really helped.
>
> I successfully installed the intermediate certificate as a trusted CA system-wide with openssl (used 'update-ca-certificates').
>
> However, I tried using the Squid config directive for intermediate certs instead, but failed.

Which version of Squid are you using now?

Amos



From squid3 at treenet.co.nz  Wed May 31 00:31:42 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 31 May 2017 12:31:42 +1200
Subject: [squid-users] How to intercept ssl_bump transparent NAT
 httpswebsites
In-Reply-To: <0M4WRI-1e7dfI11K8-00yldi@mail.gmx.com>
References: <0M4WRI-1e7dfI11K8-00yldi@mail.gmx.com>
Message-ID: <9cc44e06-0be5-e969-ad15-cd43698e22be@treenet.co.nz>

On 30/05/17 21:55, Andi wrote:
> Thank you for all your suggestions Mister.
>
> I improved my conf by them and disabled squidguard for testing and its 
> working now fine without squidguard.
> So I need to investigate why squidguard won't run with https sites on 
> v 3.5.25
>
> squidGuard -v
> SquidGuard: 1.5 Berkeley DB 5.3.28: (September  9, 2013)
>
> How can I find out what happens between Squid, SquidGuard at debian 
> and Firefox at client side ?

The Squid<->Firefox is all HTTP so for that debug_options 11,2.
That will also show you any of the HTTP to servers if it is involved.

For the redirector debug_options 61,5



>
> I tried echo tests locally with squidguard but it only shows ERR 
> results with https sites.
> Http sites are working well as expected with squidguard

I'm not entirely surprised by that. SG has not been maintained since 
before Squid was handling https:// on a regular basis. So it may simply 
be not able to process that type of URL.


Squid can now do a lot of what SG was useful for. But if you really 
still need SG for something perhapse you should try using the ufdbguard 
helper instead. It is essentially a drop-in replacement but has extra 
features for a lot more modern traffic handling and has active support.

Amos



From andreas.lauterbach76 at gmx.de  Wed May 31 07:10:39 2017
From: andreas.lauterbach76 at gmx.de (Andi)
Date: Wed, 31 May 2017 09:10:39 +0200
Subject: [squid-users] How to intercept ssl_bump transparent
	NAThttpswebsites
Message-ID: <0Lo2EO-1drVTs3LQG-00g1Bi@mail.gmx.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170531/48b4019f/attachment.htm>

From andreas.lauterbach76 at gmx.de  Wed May 31 08:15:27 2017
From: andreas.lauterbach76 at gmx.de (Andi)
Date: Wed, 31 May 2017 10:15:27 +0200
Subject: [squid-users] How to intercept ssl_bump transparent NAT https
	websites
Message-ID: <0M1AIu-1e4dVC0ijo-00tEY6@mail.gmx.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170531/5a642b99/attachment.htm>

From squid3 at treenet.co.nz  Wed May 31 14:14:59 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 1 Jun 2017 02:14:59 +1200
Subject: [squid-users] How to intercept ssl_bump transparent NAT https
 websites
In-Reply-To: <0M1AIu-1e4dVC0ijo-00tEY6@mail.gmx.com>
References: <0M1AIu-1e4dVC0ijo-00tEY6@mail.gmx.com>
Message-ID: <cd156ccc-eb6f-16d6-fe95-1952b31a852f@treenet.co.nz>

On 31/05/17 20:15, Andi wrote:
> Squid 3.5.25 + Squidclamav(c-icap) + SquidGuard
> Here are the logs with SSL_ERROR_RX_RECORD_TOO_LONG in Firefox by 
> debug_options ALL,1 11,2 and 61,5
> https://mega.nz/#!dIdAkYra!aVEg07Sc9OxRwYiRAPk49dwegr2r-sdX2u73btEdDVk 
> <https://mega.nz/#%21dIdAkYra%21aVEg07Sc9OxRwYiRAPk49dwegr2r-sdX2u73btEdDVk>
>
> Here the squid.conf & squidguard.conf
> https://pastebin.com/v2LA8CcR
>

I see your SG is trying to redirect HTTPS tunnels (which are essentially 
collections of multiple transactions) to a single HTTP plain-text page 
URL (singular). There is a bug in Squid that is dutifully (but wrongly) 
sending that response back as-is to the client. But since this is just 
an intercepted TCP connection at this point the browser just mistakes it 
for bogus TLS handshake bytes.
  I think I saw some patches from Christos fixing some of this a while 
back, but do not recall if they made it into Squid-3. There is a lot of 
SSL-Bump redesign that only exists in Squid-4 these days.

SG should never be sent CONNECT messages anyway - it does not understand 
them, never has AFAIK. So the workaround is simply to enforce that like so:

  url_redirect_access deny CONNECT

Squid will then do any relevant bumping and pass SG the decrypted 
messages you actually want it to manage.

Amos



From andreas.lauterbach76 at gmx.de  Wed May 31 14:49:47 2017
From: andreas.lauterbach76 at gmx.de (Andi)
Date: Wed, 31 May 2017 16:49:47 +0200
Subject: [squid-users] How to intercept ssl_bump transparent NAT https
	websites
Message-ID: <0MCggg-1d6lYL1Z6g-009Tmv@mail.gmx.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170531/23965b50/attachment.htm>

From squid3 at treenet.co.nz  Wed May 31 15:29:39 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 1 Jun 2017 03:29:39 +1200
Subject: [squid-users] this config is ok? is ok the order?
In-Reply-To: <1496157812155-4682631.post@n4.nabble.com>
References: <1496157812155-4682631.post@n4.nabble.com>
Message-ID: <1f29d3f2-3d4d-c55d-ad3b-4d06748b857f@treenet.co.nz>

The answer to your question really depends on what your policies are for 
who and what the proxy can be used by.

The config tells one set of policies. But if those are not the one(s) 
you actually want to happen, then the config is incorrect even if it 
"looks okay".


If I assume that its doing what you want there are still two major 
issues that can be seen.

1) Mixing interception and authentication (ssl-bump is a type of 
interception, at least on the https:// traffic). Intercepted messages 
cannot be authenticated - though there are some workarounds in place for 
ssl-bump to authenticate the CONNECT tunnel and label all the bumped 
traffic with that username.

2) using 8.8.8.8 directly in squid.conf can be amazingly harmful to 
performance. Despite the hype and marketing around Google services, the 
behaviour of this one is actively detrimental to HTTP persistant 
connections feature - namely it load balances which of their endpoint 
servers is handling each DNS query. As such Squid often sees domains 
rotating to a completely different bunch of IP addresses every TTL, 
which in turn means it cannot easily re-use any open connections to the 
prior bunch of IPs. Resulting in a huge churn on TCP sockets and 
unnecessary delays waiting for the new ones to open.


and there are a few minor polishing things you can doing you can do. But 
its not worth spending time on them until you are sure the config 
actually imposes your real wanted policy on the traffic.

Amos



From mlifshin at phantomdesign.com  Wed May 31 20:42:53 2017
From: mlifshin at phantomdesign.com (Masha Lifshin)
Date: Wed, 31 May 2017 13:42:53 -0700
Subject: [squid-users] Help troubleshooting proxy<-->client https
Message-ID: <CA+8Eki1-a7jqQzGrM0XYwDz6d-VYi1Q6PPNK5g34HpdmF2-_Sg@mail.gmail.com>

Dear Alex,

Thank you very much for your helpful reply.

I have a follow up question.  What I am trying to achieve is an https
connection between the client and squid proxy, as well as listen on port 80
for http traffic, on port 443 for ssl traffic, and apply ssl-bump to the
ssl traffic.  I am having trouble expressing this in my config. Would the
http_port and https_port directives need to look like this?

http_port <ip_address>: <http://172.30.0.67:443/>80 ssl-bump
cert=/path/to/some.cert.pem generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB tls-dh=/usr/local/squid/etc/dhparam.pem
https_port <ip_address>:443 <http://172.30.0.67:443/>
cert=/path/to/other.cert.pem
cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+
SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+
SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!
LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

Also wondering what, if any, are the security issues with using port 80 for
the http traffic?

Thank you,
-Masha

On Fri, May 26, 2017 at 7:19 AM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 05/26/2017 12:00 AM, Masha Lifshin wrote:
> > I have added an https_port directive
> > to squid.conf, but it must be misconfigured.
>
> > http_port 172.30.0.67:443 ...
> > https_port 172.30.0.67:443 ...
>
> You are right -- your Squid is misconfigured. You cannot use the same
> address for two ports. Unfortunately, Squid thinks that port binding
> errors are a minor inconvenience and continues running after logging an
> error message (that looks like many other benign error messages).
>
> Changing one of the ports will solve the "same address" problem
> described above.
>
> Do not use port 443 for http_port. It makes triage extremely confusing
> because port 443 usually implies SSL. Consider using port 3128 instead.
>
>
> HTH,
>
> Alex.
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170531/7a3b3f2e/attachment.htm>

From rentorbuy at yahoo.com  Wed May 31 21:20:29 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Wed, 31 May 2017 21:20:29 +0000 (UTC)
Subject: [squid-users] Squid TPROXY issues with Google sites
In-Reply-To: <c21a79dd-55e9-6c3a-4c60-fa3140d3d015@measurement-factory.com>
References: <589790035.698921.1495813442972.ref@mail.yahoo.com>
 <589790035.698921.1495813442972@mail.yahoo.com>
 <f00f4540-6a5b-ffa3-aa3d-8a4e33d366a4@treenet.co.nz>
 <179822685.137977.1495840922368@mail.yahoo.com>
 <4f6e6441-cda6-c7fc-0cee-1d32e0822671@measurement-factory.com>
 <993213090.790265.1495971631319@mail.yahoo.com>
 <c21a79dd-55e9-6c3a-4c60-fa3140d3d015@measurement-factory.com>
Message-ID: <1273762356.92567.1496265629353@mail.yahoo.com>


________________________________
From: Alex Rousskov <rousskov at measurement-factory.com>
>
> You need to figure out why. Two common reasons are SSL-level errors and
> http_access denials. Both should be reflected in access.log and
> debugging cache.log.


I finally found out it was an http_access deny on an ACL match with url_regex.

Thanks Alex.

Vieri


From rentorbuy at yahoo.com  Wed May 31 21:24:07 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Wed, 31 May 2017 21:24:07 +0000 (UTC)
Subject: [squid-users] squid sslbump and certificates
In-Reply-To: <a982180a-e389-9d05-9a74-6b951064b9c7@treenet.co.nz>
References: <1666824574.1494153.1496061384978.ref@mail.yahoo.com>
 <1666824574.1494153.1496061384978@mail.yahoo.com>
 <DB6PR0401MB2680BA1E032D170A3D770D3F8FF30@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <548387612.1952806.1496095904224@mail.yahoo.com>
 <a982180a-e389-9d05-9a74-6b951064b9c7@treenet.co.nz>
Message-ID: <820815053.47827.1496265847163@mail.yahoo.com>


________________________________
From: Amos Jeffries <squid3 at treenet.co.nz>
>
> Which version of Squid are you using now?


I still haven't found the time to update my systems but the squid version I was running this on was/is 3.5.14.
I probably need to catch up for this feature to work correctly.

Vieri


From rentorbuy at yahoo.com  Wed May 31 21:49:11 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Wed, 31 May 2017 21:49:11 +0000 (UTC)
Subject: [squid-users] failed to bump Twitter
References: <1759077679.133810.1496267351414.ref@mail.yahoo.com>
Message-ID: <1759077679.133810.1496267351414@mail.yahoo.com>

Hi,

I can't seem to be able to bump Twitter.

Whenever a client tries to browse https://twitter.com there's a connection refusal error page (111).

Any clue as to what I could try?

# grep -v ^# squid.test.conf | grep -v ^$
http_access allow localhost manager
http_access deny manager
http_port 3227
http_port 3228 tproxy
https_port 3229 tproxy ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cert=/etc/ssl/squid/proxyserver.pem
acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl interceptedhttp myportname 3228
acl interceptedhttps myportname 3229
http_access deny interceptedhttp !localnet
http_access deny interceptedhttps !localnet
sslcrtd_program /usr/libexec/squid/ssl_crtd -s /var/lib/squid/ssl_db_test -M 16MB
sslcrtd_children 10
reply_header_access Alternate-Protocol deny all
ssl_bump stare all
ssl_bump bump all
cache_dir diskd /var/cache/squid.test 100 16 256
http_access allow localnet
http_access allow localhost
http_access deny all
coredump_dir /var/cache/squid
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320
pid_filename /run/squid.test.pid
access_log daemon:/var/log/squid/access.test.log squid
cache_log /var/log/squid/cache.test.log
debug_options rotate=1 ALL,5

# cat /var/log/squid/access.test.log

1496266616.296    200 10.215.144.48 TAG_NONE/200 0 CONNECT 199.16.156.6:443 - ORIGINAL_DST/199.16.156.6 -
1496266616.322      2 10.215.144.48 TAG_NONE/503 3902 GET https://twitter.com/ - HIER_NONE/- text/html

# cat /var/log/squid/cache.test.log

2017/05/31 23:36:55.778 kid1| 41,5| AsyncCall.cc(38) make: make call logfileFlush [call140]
2017/05/31 23:36:55.778 kid1| 41,5| AsyncCallQueue.cc(57) fireNext: leaving logfileFlush(0x80945048*?)
2017/05/31 23:36:56.093 kid1| 5,2| TcpAcceptor.cc(220) doAccept: New connection on FD 33
2017/05/31 23:36:56.093 kid1| 5,2| TcpAcceptor.cc(295) acceptNext: connection on local=[::]:3229 remote=[::] FD 33 flags=25
2017/05/31 23:36:56.093 kid1| 51,3| fd.cc(198) fd_open: fd_open() FD 13 HTTP Request
2017/05/31 23:36:56.093 kid1| 89,5| Intercept.cc(375) Lookup: address BEGIN: me/client= 199.16.156.6:443, destination/me= 10.215.144.48:42597
2017/05/31 23:36:56.093 kid1| 89,5| Intercept.cc(169) TproxyTransparent: address TPROXY: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17
2017/05/31 23:36:56.093 kid1| 28,4| Eui48.cc(178) lookup: id=0x80cefb18 query ARP table
2017/05/31 23:36:56.093 kid1| 28,4| Eui48.cc(221) lookup: id=0x80cefb18 query ARP on each interface (512 found)
2017/05/31 23:36:56.093 kid1| 28,4| Eui48.cc(227) lookup: id=0x80cefb18 found interface lo
2017/05/31 23:36:56.094 kid1| 28,4| Eui48.cc(227) lookup: id=0x80cefb18 found interface enp1s7
2017/05/31 23:36:56.094 kid1| 28,4| Eui48.cc(236) lookup: id=0x80cefb18 looking up ARP address for 10.215.144.48 on enp1s7
2017/05/31 23:36:56.094 kid1| 28,4| Eui48.cc(227) lookup: id=0x80cefb18 found interface enp1s7
2017/05/31 23:36:56.094 kid1| 28,4| Eui48.cc(236) lookup: id=0x80cefb18 looking up ARP address for 10.215.144.48 on enp1s7
2017/05/31 23:36:56.094 kid1| 28,4| Eui48.cc(227) lookup: id=0x80cefb18 found interface enp1s8
2017/05/31 23:36:56.094 kid1| 28,4| Eui48.cc(236) lookup: id=0x80cefb18 looking up ARP address for 10.215.144.48 on enp1s8
2017/05/31 23:36:56.094 kid1| 28,4| Eui48.cc(227) lookup: id=0x80cefb18 found interface enp2s0f0
2017/05/31 23:36:56.094 kid1| 28,4| Eui48.cc(236) lookup: id=0x80cefb18 looking up ARP address for 10.215.144.48 on enp2s0f0
2017/05/31 23:36:56.094 kid1| 28,4| Eui48.cc(227) lookup: id=0x80cefb18 found interface enp2s0f1
2017/05/31 23:36:56.094 kid1| 28,4| Eui48.cc(236) lookup: id=0x80cefb18 looking up ARP address for 10.215.144.48 on enp2s0f1
2017/05/31 23:36:56.094 kid1| 28,4| Eui48.cc(227) lookup: id=0x80cefb18 found interface enp0s8
2017/05/31 23:36:56.094 kid1| 28,4| Eui48.cc(236) lookup: id=0x80cefb18 looking up ARP address for 10.215.144.48 on enp0s8
2017/05/31 23:36:56.094 kid1| 28,4| Eui48.cc(279) lookup: id=0x80cefb18 got address 64:31:50:17:9a:fd on enp0s8
2017/05/31 23:36:56.094 kid1| 5,5| TcpAcceptor.cc(287) acceptOne: Listener: local=[::]:3229 remote=[::] FD 33 flags=25 accepted new connection local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17 handler Subscription: 0x80cef9d8*1
2017/05/31 23:36:56.094 kid1| 5,5| AsyncCall.cc(26) AsyncCall: The AsyncCall httpsAccept constructed, this=0x80d66d88 [call141]
2017/05/31 23:36:56.094 kid1| 5,5| AsyncCall.cc(93) ScheduleCall: TcpAcceptor.cc(317) will call httpsAccept(local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, MXID_2) [call141]
2017/05/31 23:36:56.094 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 33, type=1, handler=1, client_data=0x80cef6e8, timeout=0
2017/05/31 23:36:56.094 kid1| 5,5| AsyncCallQueue.cc(55) fireNext: entering httpsAccept(local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, MXID_2)
2017/05/31 23:36:56.094 kid1| 5,5| AsyncCall.cc(38) make: make call httpsAccept [call141]
2017/05/31 23:36:56.094 kid1| 33,4| client_side.cc(3920) httpsAccept: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17 accepted, starting SSL negotiation.
2017/05/31 23:36:56.094 kid1| 93,5| AsyncJob.cc(34) AsyncJob: AsyncJob constructed, this=0x80d60a74 type=Http::Server [job8]
2017/05/31 23:36:56.094 kid1| 93,5| AsyncCall.cc(26) AsyncCall: The AsyncCall AsyncJob::start constructed, this=0x80d77ce0 [call142]
2017/05/31 23:36:56.094 kid1| 93,5| AsyncCall.cc(93) ScheduleCall: AsyncJob.cc(26) will call AsyncJob::start() [call142]
2017/05/31 23:36:56.094 kid1| 5,5| AsyncCallQueue.cc(57) fireNext: leaving httpsAccept(local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, MXID_2)
2017/05/31 23:36:56.094 kid1| 93,5| AsyncCallQueue.cc(55) fireNext: entering AsyncJob::start()
2017/05/31 23:36:56.094 kid1| 93,5| AsyncCall.cc(38) make: make call AsyncJob::start [call142]
2017/05/31 23:36:56.094 kid1| 93,5| AsyncJob.cc(123) callStart: Http::Server status in: [ job8]
2017/05/31 23:36:56.094 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall ConnStateData::connStateClosed constructed, this=0x80924868 [call143]
2017/05/31 23:36:56.094 kid1| 5,5| comm.cc(993) comm_add_close_handler: comm_add_close_handler: FD 13, AsyncCall=0x80924868*1
2017/05/31 23:36:56.094 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbfb501bc
2017/05/31 23:36:56.094 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0xbfb501bc
2017/05/31 23:36:56.094 kid1| 33,5| client_side.cc(3938) postHttpsAccept: accept transparent connection: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17
2017/05/31 23:36:56.094 kid1| 23,3| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 199.16.156.6
2017/05/31 23:36:56.094 kid1| 28,3| Checklist.cc(70) preCheck: 0x80d634c8 checking slow rules
2017/05/31 23:36:56.094 kid1| 28,5| Acl.cc(138) matches: checking (ssl_bump rules)
2017/05/31 23:36:56.094 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/4is not banned
2017/05/31 23:36:56.094 kid1| 28,5| Acl.cc(138) matches: checking (ssl_bump rule)
2017/05/31 23:36:56.094 kid1| 28,5| Acl.cc(138) matches: checking all
2017/05/31 23:36:56.094 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '10.215.144.48' found
2017/05/31 23:36:56.094 kid1| 28,3| Acl.cc(158) matches: checked: all = 1
2017/05/31 23:36:56.094 kid1| 28,3| Acl.cc(158) matches: checked: (ssl_bump rule) = 1
2017/05/31 23:36:56.094 kid1| 28,3| Acl.cc(158) matches: checked: (ssl_bump rules) = 1
2017/05/31 23:36:56.094 kid1| 28,3| Checklist.cc(63) markFinished: 0x80d634c8 answer ALLOWED for match
2017/05/31 23:36:56.095 kid1| 28,3| Checklist.cc(163) checkCallback: ACLChecklist::checkCallback: 0x80d634c8 answer=ALLOWED
2017/05/31 23:36:56.095 kid1| 33,2| client_side.cc(3896) httpsSslBumpAccessCheckDone: sslBump needed for local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17 method 4
2017/05/31 23:36:56.095 kid1| 33,5| client_side.cc(3200) clientParseRequests: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17: attempting to parse
2017/05/31 23:36:56.095 kid1| 74,5| HttpParser.cc(37) reset: Request buffer is CONNECT 199.16.156.6:443 HTTP/1.1
Host: 199.16.156.6:443


2017/05/31 23:36:56.095 kid1| 74,5| HttpParser.cc(47) parseRequestFirstLine: parsing possible request: CONNECT 199.16.156.6:443 HTTP/1.1
Host: 199.16.156.6:443


2017/05/31 23:36:56.095 kid1| 74,5| HttpParser.cc(257) HttpParserParseReqLine: Parser: retval 1: from 0->34: method 0->6; url 8->23; version 25->32 (1/1)
2017/05/31 23:36:56.095 kid1| 33,3| client_side.cc(2258) parseHttpRequest: parseHttpRequest: req_hdr = {Host: 199.16.156.6:443

}
2017/05/31 23:36:56.095 kid1| 33,3| client_side.cc(2262) parseHttpRequest: parseHttpRequest: end = {
}
2017/05/31 23:36:56.095 kid1| 33,3| client_side.cc(2266) parseHttpRequest: parseHttpRequest: prefix_sz = 61, req_line_sz = 35
2017/05/31 23:36:56.095 kid1| 93,5| AsyncJob.cc(34) AsyncJob: AsyncJob constructed, this=0x80d63e80 type=ClientHttpRequest [job9]
2017/05/31 23:36:56.095 kid1| 87,3| clientStream.cc(144) clientStreamInsertHead: clientStreamInsertHead: Inserted node 0x80d65688 with data 0x80d6561c after head
2017/05/31 23:36:56.095 kid1| 33,5| client_side.cc(2282) parseHttpRequest: parseHttpRequest: Request Header is
Host: 199.16.156.6:443


2017/05/31 23:36:56.095 kid1| 33,5| client_side.cc(2303) parseHttpRequest: Prepare absolute URL from intercept
2017/05/31 23:36:56.095 kid1| 33,5| client_side.cc(2342) parseHttpRequest: parseHttpRequest: Complete request received
2017/05/31 23:36:56.095 kid1| 11,2| client_side.cc(2345) parseHttpRequest: HTTP Client local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17
2017/05/31 23:36:56.095 kid1| 11,2| client_side.cc(2346) parseHttpRequest: HTTP Client REQUEST:
---------
CONNECT 199.16.156.6:443 HTTP/1.1
Host: 199.16.156.6:443


----------
2017/05/31 23:36:56.095 kid1| 33,5| client_side.cc(3221) clientParseRequests: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17: done parsing a request
2017/05/31 23:36:56.095 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall clientLifetimeTimeout constructed, this=0x80d66d88 [call144]
2017/05/31 23:36:56.095 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17 timeout 86400
2017/05/31 23:36:56.095 kid1| 23,3| url.cc(357) urlParse: urlParse: Split URL '199.16.156.6:443' into proto='', host='199.16.156.6', port='443', path=''
2017/05/31 23:36:56.095 kid1| 23,3| HttpRequest.h(82) SetHost: HttpRequest::SetHost() given IP: 199.16.156.6
2017/05/31 23:36:56.095 kid1| 33,3| client_side.cc(873) clientSetKeepaliveFlag: http_ver = HTTP/1.1
2017/05/31 23:36:56.095 kid1| 33,3| client_side.cc(874) clientSetKeepaliveFlag: method = CONNECT
2017/05/31 23:36:56.095 kid1| 33,3| client_side.h(96) mayUseConnection: This 0x80d645d8 marked 1
2017/05/31 23:36:56.095 kid1| 33,5| client_side.cc(2422) consumeInput: in.buf has 0 unused bytes
2017/05/31 23:36:56.095 kid1| 85,3| client_side_request.cc(130) ClientRequestContext: 0x80d67898 ClientRequestContext constructed
2017/05/31 23:36:56.095 kid1| 83,3| client_side_request.cc(1684) doCallouts: Doing calloutContext->hostHeaderVerify()
2017/05/31 23:36:56.095 kid1| 85,3| client_side_request.cc(631) hostHeaderVerify: validate host=199.16.156.6, port=443, portStr=443
2017/05/31 23:36:56.095 kid1| 14,4| ipcache.cc(501) ipcache_nbgethostbyname: ipcache_nbgethostbyname: Name '199.16.156.6'.
2017/05/31 23:36:56.095 kid1| 14,4| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '199.16.156.6' == 199.16.156.6
2017/05/31 23:36:56.095 kid1| 14,4| ipcache.cc(514) ipcache_nbgethostbyname: ipcache_nbgethostbyname: BYPASS for '199.16.156.6' (already numeric)
2017/05/31 23:36:56.095 kid1| 85,3| client_side_request.cc(524) hostHeaderIpVerify: validate IP 199.16.156.6:443 possible from Host:
2017/05/31 23:36:56.095 kid1| 83,3| client_side_request.cc(1691) doCallouts: Doing calloutContext->clientAccessCheck()
2017/05/31 23:36:56.095 kid1| 28,3| Checklist.cc(70) preCheck: 0x80d678e0 checking slow rules
2017/05/31 23:36:56.095 kid1| 28,5| Acl.cc(138) matches: checking http_access
2017/05/31 23:36:56.095 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2017/05/31 23:36:56.095 kid1| 28,5| Acl.cc(138) matches: checking http_access#1
2017/05/31 23:36:56.095 kid1| 28,5| Acl.cc(138) matches: checking localhost
2017/05/31 23:36:56.095 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '10.215.144.48' NOT found
2017/05/31 23:36:56.095 kid1| 28,3| Acl.cc(158) matches: checked: localhost = 0
2017/05/31 23:36:56.095 kid1| 28,3| Acl.cc(158) matches: checked: http_access#1 = 0
2017/05/31 23:36:56.095 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'DENIED/0is not banned
2017/05/31 23:36:56.095 kid1| 28,5| Acl.cc(138) matches: checking http_access#2
2017/05/31 23:36:56.095 kid1| 28,5| Acl.cc(138) matches: checking manager
2017/05/31 23:36:56.095 kid1| 28,3| RegexData.cc(51) match: aclRegexData::match: checking '199.16.156.6:443'
2017/05/31 23:36:56.095 kid1| 28,3| RegexData.cc(62) match: aclRegexData::match: looking for '(^cache_object://)'
2017/05/31 23:36:56.095 kid1| 28,3| RegexData.cc(62) match: aclRegexData::match: looking for '(^https?://[^/]+/squid-internal-mgr/)'
2017/05/31 23:36:56.095 kid1| 28,3| Acl.cc(158) matches: checked: manager = 0
2017/05/31 23:36:56.096 kid1| 28,3| Acl.cc(158) matches: checked: http_access#2 = 0
2017/05/31 23:36:56.096 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'DENIED/0is not banned
2017/05/31 23:36:56.096 kid1| 28,5| Acl.cc(138) matches: checking http_access#3
2017/05/31 23:36:56.096 kid1| 28,5| Acl.cc(138) matches: checking interceptedhttp
2017/05/31 23:36:56.096 kid1| 28,3| StringData.cc(34) match: aclMatchStringList: checking '3229'
2017/05/31 23:36:56.096 kid1| 28,3| StringData.cc(37) match: aclMatchStringList: '3229' NOT found
2017/05/31 23:36:56.096 kid1| 28,3| Acl.cc(158) matches: checked: interceptedhttp = 0
2017/05/31 23:36:56.096 kid1| 28,3| Acl.cc(158) matches: checked: http_access#3 = 0
2017/05/31 23:36:56.096 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'DENIED/0is not banned
2017/05/31 23:36:56.096 kid1| 28,5| Acl.cc(138) matches: checking http_access#4
2017/05/31 23:36:56.096 kid1| 28,5| Acl.cc(138) matches: checking interceptedhttps
2017/05/31 23:36:56.096 kid1| 28,3| StringData.cc(34) match: aclMatchStringList: checking '3229'
2017/05/31 23:36:56.096 kid1| 28,3| StringData.cc(37) match: aclMatchStringList: '3229' found
2017/05/31 23:36:56.096 kid1| 28,3| Acl.cc(158) matches: checked: interceptedhttps = 1
2017/05/31 23:36:56.096 kid1| 28,5| Acl.cc(138) matches: checking !localnet
2017/05/31 23:36:56.096 kid1| 28,5| Acl.cc(138) matches: checking localnet
2017/05/31 23:36:56.096 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '10.215.144.48' found
2017/05/31 23:36:56.096 kid1| 28,3| Acl.cc(158) matches: checked: localnet = 1
2017/05/31 23:36:56.096 kid1| 28,3| Acl.cc(158) matches: checked: !localnet = 0
2017/05/31 23:36:56.096 kid1| 28,3| Acl.cc(158) matches: checked: http_access#4 = 0
2017/05/31 23:36:56.096 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2017/05/31 23:36:56.096 kid1| 28,5| Acl.cc(138) matches: checking http_access#5
2017/05/31 23:36:56.096 kid1| 28,5| Acl.cc(138) matches: checking localnet
2017/05/31 23:36:56.096 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '10.215.144.48' found
2017/05/31 23:36:56.096 kid1| 28,3| Acl.cc(158) matches: checked: localnet = 1
2017/05/31 23:36:56.096 kid1| 28,3| Acl.cc(158) matches: checked: http_access#5 = 1
2017/05/31 23:36:56.096 kid1| 28,3| Acl.cc(158) matches: checked: http_access = 1
2017/05/31 23:36:56.096 kid1| 28,3| Checklist.cc(63) markFinished: 0x80d678e0 answer ALLOWED for match
2017/05/31 23:36:56.096 kid1| 28,3| Checklist.cc(163) checkCallback: ACLChecklist::checkCallback: 0x80d678e0 answer=ALLOWED
2017/05/31 23:36:56.096 kid1| 85,2| client_side_request.cc(741) clientAccessCheckDone: The request CONNECT 199.16.156.6:443 is ALLOWED; last ACL checked: localnet
2017/05/31 23:36:56.096 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
2017/05/31 23:36:56.096 kid1| 83,3| client_side_request.cc(1719) doCallouts: Doing calloutContext->clientAccessCheck2()
2017/05/31 23:36:56.096 kid1| 85,2| client_side_request.cc(717) clientAccessCheck2: No adapted_http_access configuration. default: ALLOW
2017/05/31 23:36:56.096 kid1| 85,2| client_side_request.cc(741) clientAccessCheckDone: The request CONNECT 199.16.156.6:443 is ALLOWED; last ACL checked: localnet
2017/05/31 23:36:56.096 kid1| 83,3| client_side_request.cc(1737) doCallouts: Doing clientInterpretRequestHeaders()
2017/05/31 23:36:56.096 kid1| 85,5| client_side_request.cc(1173) clientInterpretRequestHeaders: clientInterpretRequestHeaders: REQ_NOCACHE = NOT SET
2017/05/31 23:36:56.096 kid1| 85,5| client_side_request.cc(1175) clientInterpretRequestHeaders: clientInterpretRequestHeaders: REQ_CACHABLE = SET
2017/05/31 23:36:56.096 kid1| 85,5| client_side_request.cc(1177) clientInterpretRequestHeaders: clientInterpretRequestHeaders: REQ_HIERARCHICAL = NOT SET
2017/05/31 23:36:56.096 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbfb4f34c
2017/05/31 23:36:56.096 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0xbfb4f34c
2017/05/31 23:36:56.096 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbfb4f34c
2017/05/31 23:36:56.096 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0xbfb4f34c
2017/05/31 23:36:56.096 kid1| 85,5| client_side_request.cc(1419) sslBumpAccessCheck: SslBump already decided (4), ignoring ssl_bump for 0x80d60950
2017/05/31 23:36:56.096 kid1| 83,3| client_side_request.cc(1528) sslBumpNeed: sslBump required: stare
2017/05/31 23:36:56.096 kid1| 85,3| client_side_request.cc(115) ~ClientRequestContext: 0x80d67898 ClientRequestContext destructed
2017/05/31 23:36:56.096 kid1| 83,3| client_side_request.cc(1828) doCallouts: calling processRequest()
2017/05/31 23:36:56.096 kid1| 85,4| client_side_request.cc(1491) processRequest: CONNECT 199.16.156.6:443
2017/05/31 23:36:56.096 kid1| 85,5| client_side_request.cc(1574) sslBumpStart: Confirming stare-bumped CONNECT tunnel on FD local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17
2017/05/31 23:36:56.096 kid1| 85,5| AsyncCall.cc(26) AsyncCall: The AsyncCall ClientSocketContext::sslBumpEstablish constructed, this=0x80d60a90 [call145]
2017/05/31 23:36:56.096 kid1| 85,5| AsyncCall.cc(93) ScheduleCall: client_side_request.cc(1584) will call ClientSocketContext::sslBumpEstablish(local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, data=0x80d63dc8) [call145]
2017/05/31 23:36:56.096 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x80d678e0
2017/05/31 23:36:56.096 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x80d678e0
2017/05/31 23:36:56.096 kid1| 33,3| client_side.cc(3233) clientParseRequests: Not parsing new requests, as this request may need the connection
2017/05/31 23:36:56.097 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x80d634c8
2017/05/31 23:36:56.097 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x80d634c8
2017/05/31 23:36:56.097 kid1| 93,5| AsyncJob.cc(152) callEnd: Http::Server status out: [ job8]
2017/05/31 23:36:56.097 kid1| 93,5| AsyncCallQueue.cc(57) fireNext: leaving AsyncJob::start()
2017/05/31 23:36:56.097 kid1| 85,5| AsyncCallQueue.cc(55) fireNext: entering ClientSocketContext::sslBumpEstablish(local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, data=0x80d63dc8)
2017/05/31 23:36:56.097 kid1| 85,5| AsyncCall.cc(38) make: make call ClientSocketContext::sslBumpEstablish [call145]
2017/05/31 23:36:56.097 kid1| 85,5| client_side_request.cc(1537) SslBumpEstablish: responded to CONNECT: 0x80d63dc8 ? 0
2017/05/31 23:36:56.097 kid1| 33,5| client_side.cc(4237) switchToHttps: converting local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17 to SSL
2017/05/31 23:36:56.097 kid1| 33,4| ServerBump.cc(27) ServerBump: will peek at 199.16.156.6:443
2017/05/31 23:36:56.097 kid1| 20,3| store.cc(779) storeCreatePureEntry: storeCreateEntry: '199.16.156.6:443'
2017/05/31 23:36:56.097 kid1| 20,5| store.cc(371) StoreEntry: StoreEntry constructed, this=0x80c213e0
2017/05/31 23:36:56.097 kid1| 20,3| MemObject.cc(97) MemObject: new MemObject 0x80d63708
2017/05/31 23:36:56.097 kid1| 20,3| store.cc(484) lock: storeCreateEntry locked key [null_store_key] e:=V/0x80c213e0*1
2017/05/31 23:36:56.097 kid1| 20,3| store_key_md5.cc(89) storeKeyPrivate: storeKeyPrivate: CONNECT 199.16.156.6:443
2017/05/31 23:36:56.097 kid1| 20,3| store.cc(448) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x80c213e0*1 key 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.097 kid1| 83,5| bio.cc(576) squid_bio_ctrl: 0x80d8fe20 104(6000, 0xbfb50158)
2017/05/31 23:36:56.097 kid1| 33,5| client_side.cc(3693) httpsCreate: will negotate SSL on local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17
2017/05/31 23:36:56.097 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=0, client_data=0, timeout=0
2017/05/31 23:36:56.097 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.097 kid1| 85,5| AsyncCallQueue.cc(57) fireNext: leaving ClientSocketContext::sslBumpEstablish(local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, data=0x80d63dc8)
2017/05/31 23:36:56.097 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.097 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.097 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.097 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.097 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.097 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.097 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.097 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.098 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.098 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.098 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.098 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.098 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.098 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.098 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.098 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.098 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.098 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.098 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.098 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.098 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.098 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.098 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.098 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.098 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.098 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.098 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.099 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.099 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.099 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.099 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.099 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.099 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.099 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.099 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.099 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.099 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.099 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.099 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.099 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.099 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.099 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.099 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.099 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.099 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.099 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.099 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.099 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.100 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.100 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.100 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.100 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.100 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.100 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.100 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.100 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.100 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.100 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.100 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.100 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.100 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(118) read: FD 13 read 11 <= 11
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(144) readAndBuffer: read 11 out of 11 bytes
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 11 bytes of TLS client Hello
2017/05/31 23:36:56.100 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.100 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.100 kid1| 83,5| client_side.cc(4267) clientPeekAndSpliceSSL: Start peek and splice on FD 13
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(118) read: FD 13 read 8 <= 11
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(144) readAndBuffer: read 8 out of 11 bytes
2017/05/31 23:36:56.100 kid1| 83,5| bio.cc(148) readAndBuffer: recorded 8 bytes of TLS client Hello
2017/05/31 23:36:56.101 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.101 kid1| 83,2| client_side.cc(4270) clientPeekAndSpliceSSL: SSL_accept failed.
2017/05/31 23:36:56.101 kid1| 83,5| client_side.cc(4284) clientPeekAndSpliceSSL: I got hello. Start forwarding the request!!! 
2017/05/31 23:36:56.101 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=0, client_data=0, timeout=0
2017/05/31 23:36:56.101 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=2, handler=0, client_data=0, timeout=0
2017/05/31 23:36:56.101 kid1| 28,3| Checklist.cc(70) preCheck: 0x80d634c8 checking slow rules
2017/05/31 23:36:56.101 kid1| 28,5| Acl.cc(138) matches: checking (ssl_bump rules)
2017/05/31 23:36:56.101 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/4is not banned
2017/05/31 23:36:56.101 kid1| 28,5| Acl.cc(138) matches: checking (ssl_bump rule)
2017/05/31 23:36:56.101 kid1| 28,5| Acl.cc(138) matches: checking all
2017/05/31 23:36:56.101 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '10.215.144.48' found
2017/05/31 23:36:56.101 kid1| 28,3| Acl.cc(158) matches: checked: all = 1
2017/05/31 23:36:56.101 kid1| 28,3| Acl.cc(158) matches: checked: (ssl_bump rule) = 1
2017/05/31 23:36:56.101 kid1| 28,3| Acl.cc(158) matches: checked: (ssl_bump rules) = 1
2017/05/31 23:36:56.101 kid1| 28,3| Checklist.cc(63) markFinished: 0x80d634c8 answer ALLOWED for match
2017/05/31 23:36:56.101 kid1| 28,3| Checklist.cc(163) checkCallback: ACLChecklist::checkCallback: 0x80d634c8 answer=ALLOWED
2017/05/31 23:36:56.101 kid1| 33,5| client_side.cc(4322) httpsSslBumpStep2AccessCheckDone: Answer: ALLOWED kind:4
2017/05/31 23:36:56.101 kid1| 17,3| FwdState.cc(331) Start: '199.16.156.6:443'
2017/05/31 23:36:56.101 kid1| 17,2| FwdState.cc(132) FwdState: Forwarding client request local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, url=199.16.156.6:443
2017/05/31 23:36:56.101 kid1| 20,3| store.cc(484) lock: FwdState locked key D1806996FC89FCA8A2553AF78760C5D4 e:=IV/0x80c213e0*2
2017/05/31 23:36:56.101 kid1| 44,3| peer_select.cc(137) peerSelect: e:=IWV/0x80c213e0*2 199.16.156.6:443
2017/05/31 23:36:56.101 kid1| 20,3| store.cc(484) lock: peerSelect locked key D1806996FC89FCA8A2553AF78760C5D4 e:=IWV/0x80c213e0*3
2017/05/31 23:36:56.101 kid1| 44,3| peer_select.cc(441) peerSelectFoo: CONNECT 199.16.156.6
2017/05/31 23:36:56.101 kid1| 44,3| peer_select.cc(401) peerCheckNetdbDirect: peerCheckNetdbDirect: MY RTT = 0 msec
2017/05/31 23:36:56.101 kid1| 44,3| peer_select.cc(402) peerCheckNetdbDirect: peerCheckNetdbDirect: minimum_direct_rtt = 400 msec
2017/05/31 23:36:56.101 kid1| 44,3| peer_select.cc(409) peerCheckNetdbDirect: peerCheckNetdbDirect: MY hops = 0
2017/05/31 23:36:56.101 kid1| 44,3| peer_select.cc(410) peerCheckNetdbDirect: peerCheckNetdbDirect: minimum_direct_hops = 4
2017/05/31 23:36:56.101 kid1| 15,3| neighbors.cc(100) whichPeer: whichPeer: from [::]
2017/05/31 23:36:56.101 kid1| 44,3| peer_select.cc(474) peerSelectFoo: peerSelectFoo: direct = DIRECT_MAYBE (default)
2017/05/31 23:36:56.101 kid1| 44,3| peer_select.cc(477) peerSelectFoo: peerSelectFoo: direct = DIRECT_MAYBE
2017/05/31 23:36:56.101 kid1| 14,3| ipcache.cc(619) ipcache_gethostbyname: ipcache_gethostbyname: '199.16.156.6', flags=0
2017/05/31 23:36:56.101 kid1| 14,4| ipcache.cc(810) ipcacheCheckNumeric: ipcacheCheckNumeric: HIT_BYPASS for '199.16.156.6' == 199.16.156.6
2017/05/31 23:36:56.101 kid1| 14,5| net_db.cc(365) networkFromInaddr: networkFromInaddr : Masked IPv4 Address to 199.16.156.6/24.
2017/05/31 23:36:56.101 kid1| 14,5| net_db.cc(369) networkFromInaddr: networkFromInaddr : Masked IPv4 Address to 199.16.156.6/24.
2017/05/31 23:36:56.101 kid1| 44,3| peer_select.cc(110) peerSelectIcpPing: peerSelectIcpPing: 199.16.156.6:443
2017/05/31 23:36:56.101 kid1| 44,5| peer_select.cc(940) peerAddFwdServer: peerAddFwdServer: adding DIRECT HIER_DIRECT
2017/05/31 23:36:56.101 kid1| 44,2| peer_select.cc(280) peerSelectDnsPaths: Found sources for '199.16.156.6:443'
2017/05/31 23:36:56.101 kid1| 44,2| peer_select.cc(281) peerSelectDnsPaths:   always_direct = DENIED
2017/05/31 23:36:56.101 kid1| 44,2| peer_select.cc(282) peerSelectDnsPaths:    never_direct = DENIED
2017/05/31 23:36:56.101 kid1| 44,2| peer_select.cc(288) peerSelectDnsPaths:    ORIGINAL_DST = local=10.215.144.48 remote=199.16.156.6:443 flags=25
2017/05/31 23:36:56.101 kid1| 44,2| peer_select.cc(295) peerSelectDnsPaths:        timedout = 0
2017/05/31 23:36:56.101 kid1| 17,3| FwdState.cc(386) startConnectionOrFail: 199.16.156.6:443
2017/05/31 23:36:56.101 kid1| 17,3| FwdState.cc(804) connectStart: fwdConnectStart: 199.16.156.6:443
2017/05/31 23:36:56.101 kid1| 48,3| pconn.cc(439) pop: lookup for key {199.16.156.6:443/199.16.156.6} failed.
2017/05/31 23:36:56.102 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbfb4fabc
2017/05/31 23:36:56.102 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0xbfb4fabc
2017/05/31 23:36:56.102 kid1| 17,3| FwdState.cc(1304) GetMarkingsToServer: from 10.215.144.48 netfilter mark 0
2017/05/31 23:36:56.102 kid1| 17,3| AsyncCall.cc(26) AsyncCall: The AsyncCall fwdConnectDoneWrapper constructed, this=0x80d92248 [call146]
2017/05/31 23:36:56.102 kid1| 93,5| AsyncJob.cc(34) AsyncJob: AsyncJob constructed, this=0x80d78b40 type=Comm::ConnOpener [job10]
2017/05/31 23:36:56.102 kid1| 93,5| AsyncCall.cc(26) AsyncCall: The AsyncCall AsyncJob::start constructed, this=0x80d92290 [call147]
2017/05/31 23:36:56.102 kid1| 93,5| AsyncCall.cc(93) ScheduleCall: AsyncJob.cc(26) will call AsyncJob::start() [call147]
2017/05/31 23:36:56.102 kid1| 44,3| peer_select.cc(79) ~ps_state: 199.16.156.6:443
2017/05/31 23:36:56.102 kid1| 20,3| store.cc(522) unlock: peerSelect unlocking key D1806996FC89FCA8A2553AF78760C5D4 e:=p2IWV/0x80c213e0*3
2017/05/31 23:36:56.102 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x80d634c8
2017/05/31 23:36:56.102 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x80d634c8
2017/05/31 23:36:56.102 kid1| 93,5| AsyncCallQueue.cc(55) fireNext: entering AsyncJob::start()
2017/05/31 23:36:56.102 kid1| 93,5| AsyncCall.cc(38) make: make call AsyncJob::start [call147]
2017/05/31 23:36:56.102 kid1| 93,5| AsyncJob.cc(123) callStart: Comm::ConnOpener status in: [ job10]
2017/05/31 23:36:56.102 kid1| 50,3| comm.cc(347) comm_openex: comm_openex: Attempt open socket for: 10.215.144.48
2017/05/31 23:36:56.102 kid1| 50,3| comm.cc(388) comm_openex: comm_openex: Opened socket local=10.215.144.48 remote=[::] FD 15 flags=1 : family=2, type=1, protocol=6
2017/05/31 23:36:56.102 kid1| 5,5| comm.cc(420) comm_init_opened: local=10.215.144.48 remote=[::] FD 15 flags=1 is a new socket
2017/05/31 23:36:56.102 kid1| 51,3| fd.cc(198) fd_open: fd_open() FD 15 199.16.156.6
2017/05/31 23:36:56.102 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall Comm::ConnOpener::earlyAbort constructed, this=0x80d90490 [call148]
2017/05/31 23:36:56.102 kid1| 5,5| comm.cc(993) comm_add_close_handler: comm_add_close_handler: FD 15, AsyncCall=0x80d90490*1
2017/05/31 23:36:56.102 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall Comm::ConnOpener::timeout constructed, this=0x80d904e0 [call149]
2017/05/31 23:36:56.102 kid1| 5,3| ConnOpener.cc(289) createFd: local=10.215.144.48 remote=199.16.156.6:443 flags=25 will timeout in 60
2017/05/31 23:36:56.102 kid1| 5,5| comm.cc(644) comm_connect_addr: sock=15, addrinfo( flags=4, family=2, socktype=1, protocol=6, &addr=0x80d922d0, addrlen=16 )
2017/05/31 23:36:56.102 kid1| 5,5| ConnOpener.cc(343) doConnect: local=10.215.144.48 remote=199.16.156.6:443 flags=25: Comm::INPROGRESS
2017/05/31 23:36:56.102 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 15, type=2, handler=1, client_data=0x80d90530, timeout=0
2017/05/31 23:36:56.102 kid1| 93,5| AsyncJob.cc(152) callEnd: Comm::ConnOpener status out: [ job10]
2017/05/31 23:36:56.102 kid1| 93,5| AsyncCallQueue.cc(57) fireNext: leaving AsyncJob::start()
2017/05/31 23:36:56.293 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 15, type=1, handler=0, client_data=0, timeout=0
2017/05/31 23:36:56.293 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall Comm::ConnOpener::doConnect constructed, this=0x80d92290 [call150]
2017/05/31 23:36:56.293 kid1| 5,4| AsyncCall.cc(93) ScheduleCall: ConnOpener.cc(460) will call Comm::ConnOpener::doConnect() [call150]
2017/05/31 23:36:56.293 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering Comm::ConnOpener::doConnect()
2017/05/31 23:36:56.293 kid1| 5,4| AsyncCall.cc(38) make: make call Comm::ConnOpener::doConnect [call150]
2017/05/31 23:36:56.293 kid1| 5,4| AsyncJob.cc(123) callStart: Comm::ConnOpener status in: [ job10]
2017/05/31 23:36:56.293 kid1| 5,5| ConnOpener.cc(365) doConnect: local=10.215.144.48 remote=199.16.156.6:443 flags=25: * - ERR tried too many times already.
2017/05/31 23:36:56.293 kid1| 17,3| AsyncCall.cc(93) ScheduleCall: ConnOpener.cc(137) will call fwdConnectDoneWrapper(local=10.215.144.48 remote=199.16.156.6:443 flags=25, errno=111, flag=-8, data=0x80d67d10) [call146]
2017/05/31 23:36:56.293 kid1| 93,5| AsyncJob.cc(84) mustStop: Comm::ConnOpener will stop, reason: Comm::ConnOpener::doConnect
2017/05/31 23:36:56.293 kid1| 93,5| AsyncJob.cc(137) callEnd: Comm::ConnOpener::doConnect() ends job [Stopped, reason:Comm::ConnOpener::doConnect job10]
2017/05/31 23:36:56.293 kid1| 5,4| ConnOpener.cc(153) cleanFd: local=10.215.144.48 remote=199.16.156.6:443 flags=25 closing temp FD 15
2017/05/31 23:36:56.293 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 15, type=2, handler=0, client_data=0, timeout=0
2017/05/31 23:36:56.293 kid1| 5,4| AsyncCall.cc(56) cancel: will not call Comm::ConnOpener::timeout [call149] because Comm::ConnOpener::cleanFd
2017/05/31 23:36:56.293 kid1| 5,5| comm.cc(1038) comm_remove_close_handler: comm_remove_close_handler: FD 15, AsyncCall=0x80d90490*2
2017/05/31 23:36:56.293 kid1| 5,4| AsyncCall.cc(56) cancel: will not call Comm::ConnOpener::earlyAbort [call148] because comm_remove_close_handler
2017/05/31 23:36:56.293 kid1| 5,3| comm.cc(868) _comm_close: comm_close: start closing FD 15
2017/05/31 23:36:56.293 kid1| 5,3| comm.cc(540) commUnsetFdTimeout: Remove timeout for FD 15
2017/05/31 23:36:56.293 kid1| 5,5| comm.cc(721) commCallCloseHandlers: commCallCloseHandlers: FD 15
2017/05/31 23:36:56.293 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall comm_close_complete constructed, this=0x80d90490 [call151]
2017/05/31 23:36:56.293 kid1| 5,4| AsyncCall.cc(93) ScheduleCall: comm.cc(941) will call comm_close_complete(FD 15) [call151]
2017/05/31 23:36:56.293 kid1| 93,5| AsyncJob.cc(40) ~AsyncJob: AsyncJob destructed, this=0x80d78b40 type=Comm::ConnOpener [job10]
2017/05/31 23:36:56.293 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving Comm::ConnOpener::doConnect()
2017/05/31 23:36:56.293 kid1| 17,3| AsyncCallQueue.cc(55) fireNext: entering fwdConnectDoneWrapper(local=10.215.144.48 remote=199.16.156.6:443 flags=25, errno=111, flag=-8, data=0x80d67d10)
2017/05/31 23:36:56.293 kid1| 17,3| AsyncCall.cc(38) make: make call fwdConnectDoneWrapper [call146]
2017/05/31 23:36:56.293 kid1| 17,3| FwdState.cc(415) fail: ERR_CONNECT_FAIL "Service Unavailable"
199.16.156.6:443
2017/05/31 23:36:56.293 kid1| 17,3| FwdState.cc(616) retryOrBail: re-forwarding (0 tries, 0 secs)
2017/05/31 23:36:56.293 kid1| 17,3| FwdState.cc(386) startConnectionOrFail: 199.16.156.6:443
2017/05/31 23:36:56.293 kid1| 17,3| FwdState.cc(403) startConnectionOrFail: Connection failed: 199.16.156.6:443
2017/05/31 23:36:56.293 kid1| 17,3| FwdState.cc(265) ~FwdState: FwdState destructor starting
2017/05/31 23:36:56.293 kid1| 46,5| access_log.cc(289) stopPeerClock: First connection started: 1496266616.101970, current total response time value: -1
2017/05/31 23:36:56.293 kid1| 4,4| errorpage.cc(603) errorAppendEntry: Creating an error page for entry 0x80c213e0 with errorstate 0x80d93298 page id 11
2017/05/31 23:36:56.293 kid1| 4,2| errorpage.cc(1262) BuildContent: No existing error page language negotiated for ERR_CONNECT_FAIL. Using default error file.
2017/05/31 23:36:56.293 kid1| 4,3| errorpage.cc(1101) Convert: errorConvert: %%l --> '/*
* Copyright (C) 1996-2015 The Squid Software Foundation and contributors
*
* Squid software is distributed under GPLv2+ license and includes
* contributions from numerous individuals and organizations.
* Please see the COPYING and CONTRIBUTORS files for details.
*/

/*
Stylesheet for Squid Error pages
[REMOVED FOR A SHORTER POST]
'
2017/05/31 23:36:56.293 kid1| 4,3| errorpage.cc(1101) Convert: errorConvert: %%; --> '%;'
2017/05/31 23:36:56.294 kid1| 4,3| errorpage.cc(1101) Convert: errorConvert: %%c --> 'ERR_CONNECT_FAIL'
2017/05/31 23:36:56.294 kid1| 4,3| errorpage.cc(1101) Convert: errorConvert: %%U --> 'https://199.16.156.6/*'
2017/05/31 23:36:56.294 kid1| 4,3| errorpage.cc(1101) Convert: errorConvert: %%U --> 'https://199.16.156.6/*'
2017/05/31 23:36:56.294 kid1| 4,3| errorpage.cc(1101) Convert: errorConvert: %%I --> '199.16.156.6'
2017/05/31 23:36:56.294 kid1| 4,3| errorpage.cc(1101) Convert: errorConvert: %%E --> '(111) Connection refused'
2017/05/31 23:36:56.294 kid1| 4,3| errorpage.cc(1101) Convert: errorConvert: %%w --> 'root'
2017/05/31 23:36:56.294 kid1| 4,3| errorpage.cc(1101) Convert: errorConvert: %%W --> '?subject=CacheErrorInfo%20-%20ERR_CONNECT_FAIL&body=CacheHost%3A%20inf-fw1%0D%0AErrPage%3A%20ERR_CONNECT_FAIL%0D%0AErr%3A%20(111)%20Connection%20refused%0D%0ATimeStamp%3A%20Wed,%2031%20May%202017%2021%3A36%3A56%20GMT%0D%0A%0D%0AClientIP%3A%2010.215.144.48%0D%0AServerIP%3A%20199.16.156.6%0D%0A%0D%0AHTTP%20Request%3A%0D%0ACONNECT%20%2F%20HTTP%2F1.1%0AHost%3A%20199.16.156.6%3A443%0D%0A%0D%0A%0D%0A'
2017/05/31 23:36:56.294 kid1| 4,3| errorpage.cc(1101) Convert: errorConvert: %%w --> 'root'
2017/05/31 23:36:56.294 kid1| 4,3| errorpage.cc(1101) Convert: errorConvert: %%T --> 'Wed, 31 May 2017 21:36:56 GMT'
2017/05/31 23:36:56.294 kid1| 4,3| errorpage.cc(1101) Convert: errorConvert: %%h --> 'inf-fw1'
2017/05/31 23:36:56.294 kid1| 4,3| errorpage.cc(1101) Convert: errorConvert: %%s --> 'squid/3.5.14'
2017/05/31 23:36:56.294 kid1| 4,3| errorpage.cc(1101) Convert: errorConvert: %%c --> 'ERR_CONNECT_FAIL'
2017/05/31 23:36:56.294 kid1| 11,5| HttpRequest.cc(474) detailError: current error details: 11/111
2017/05/31 23:36:56.294 kid1| 20,3| store.cc(484) lock: StoreEntry::storeErrorResponse locked key D1806996FC89FCA8A2553AF78760C5D4 e:=p2IWV/0x80c213e0*3
2017/05/31 23:36:56.294 kid1| 20,3| store.cc(1867) replaceHttpReply: StoreEntry::replaceHttpReply: 199.16.156.6:443
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 34 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 6 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 12 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 12 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 3 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 4 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 29 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 12 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 23 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 14 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 4 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 13 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.294 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(834) write: storeWrite: writing 20 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(834) write: storeWrite: writing 4 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(834) write: storeWrite: writing 15 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(834) write: storeWrite: writing 16 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(834) write: storeWrite: writing 2 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(834) write: storeWrite: writing 3525 bytes for 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,3| store.cc(985) checkCachable: StoreEntry::checkCachable: NO: private key
2017/05/31 23:36:56.295 kid1| 20,3| store.cc(500) setReleaseFlag: StoreEntry::setReleaseFlag: 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,3| store_swapout.cc(381) mayStartSwapOut: not cachable
2017/05/31 23:36:56.295 kid1| 20,2| store.cc(954) checkCachable: StoreEntry::checkCachable: NO: not cachable
2017/05/31 23:36:56.295 kid1| 90,3| store_client.cc(732) invokeHandlers: InvokeHandlers: D1806996FC89FCA8A2553AF78760C5D4
2017/05/31 23:36:56.295 kid1| 90,3| store_client.cc(738) invokeHandlers: StoreEntry::InvokeHandlers: checking client #0
2017/05/31 23:36:56.295 kid1| 20,3| store.cc(1053) complete: storeComplete: 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,3| store.cc(1342) validLength: storeEntryValidLength: Checking 'D1806996FC89FCA8A2553AF78760C5D4'
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(1344) validLength: storeEntryValidLength:     object_len = 3782
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(1345) validLength: storeEntryValidLength:         hdr_sz = 257
2017/05/31 23:36:56.295 kid1| 20,5| store.cc(1346) validLength: storeEntryValidLength: content_length = 3525
2017/05/31 23:36:56.295 kid1| 20,3| store_swapout.cc(356) mayStartSwapOut:  already rejected
2017/05/31 23:36:56.295 kid1| 20,2| store.cc(954) checkCachable: StoreEntry::checkCachable: NO: not cachable
2017/05/31 23:36:56.295 kid1| 90,3| store_client.cc(732) invokeHandlers: InvokeHandlers: D1806996FC89FCA8A2553AF78760C5D4
2017/05/31 23:36:56.295 kid1| 90,3| store_client.cc(738) invokeHandlers: StoreEntry::InvokeHandlers: checking client #0
2017/05/31 23:36:56.295 kid1| 20,3| store.cc(522) unlock: StoreEntry::storeErrorResponse unlocking key D1806996FC89FCA8A2553AF78760C5D4 e:=sp2XINV/0x80c213e0*3
2017/05/31 23:36:56.295 kid1| 17,4| AsyncCall.cc(26) AsyncCall: The AsyncCall ConnStateData::ConnStateData::httpsPeeked constructed, this=0x80d93320 [call152]
2017/05/31 23:36:56.295 kid1| 17,4| AsyncCall.cc(93) ScheduleCall: FwdState.cc(248) will call ConnStateData::ConnStateData::httpsPeeked() [call152]
2017/05/31 23:36:56.295 kid1| 90,3| store_client.cc(758) storePendingNClients: storePendingNClients: returning 1
2017/05/31 23:36:56.295 kid1| 20,3| store.cc(522) unlock: FwdState unlocking key D1806996FC89FCA8A2553AF78760C5D4 e:=sp2XINV/0x80c213e0*2
2017/05/31 23:36:56.295 kid1| 17,3| AsyncCall.cc(56) cancel: will not call fwdConnectDoneWrapper [call146] because FwdState destructed
2017/05/31 23:36:56.295 kid1| 17,3| FwdState.cc(292) ~FwdState: FwdState destructor done
2017/05/31 23:36:56.295 kid1| 17,3| AsyncCallQueue.cc(57) fireNext: leaving fwdConnectDoneWrapper(local=10.215.144.48 remote=199.16.156.6:443 flags=25, errno=111, flag=-8, data=0x80d67d10)
2017/05/31 23:36:56.295 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering comm_close_complete(FD 15)
2017/05/31 23:36:56.295 kid1| 5,4| AsyncCall.cc(38) make: make call comm_close_complete [call151]
2017/05/31 23:36:56.295 kid1| 51,3| fd.cc(93) fd_close: fd_close FD 15 199.16.156.6
2017/05/31 23:36:56.295 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 15, type=1, handler=0, client_data=0, timeout=0
2017/05/31 23:36:56.295 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 15, type=2, handler=0, client_data=0, timeout=0
2017/05/31 23:36:56.295 kid1| 5,5| AcceptLimiter.cc(55) kick: size=0
2017/05/31 23:36:56.295 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving comm_close_complete(FD 15)
2017/05/31 23:36:56.295 kid1| 17,4| AsyncCallQueue.cc(55) fireNext: entering ConnStateData::ConnStateData::httpsPeeked()
2017/05/31 23:36:56.295 kid1| 17,4| AsyncCall.cc(38) make: make call ConnStateData::ConnStateData::httpsPeeked [call152]
2017/05/31 23:36:56.295 kid1| 17,4| AsyncJob.cc(123) callStart: Http::Server status in: [ job8]
2017/05/31 23:36:56.295 kid1| 33,5| client_side.cc(4411) httpsPeeked: Error while bumping: 199.16.156.6
2017/05/31 23:36:56.295 kid1| 11,5| HttpRequest.cc(473) detailError: old error details: 11/111
2017/05/31 23:36:56.296 kid1| 11,5| HttpRequest.cc(474) detailError: current error details: 11/111
2017/05/31 23:36:56.296 kid1| 87,3| clientStream.cc(202) clientStreamDetach: clientStreamDetach: Detaching node 0x80d65688
2017/05/31 23:36:56.296 kid1| 87,3| clientStream.cc(287) clientStreamFree: Freeing clientStreamNode 0x80d65688
2017/05/31 23:36:56.296 kid1| 87,3| clientStream.cc(223) clientStreamDetach: clientStreamDetach: Calling 1 with cbdata 0x80d66a08
2017/05/31 23:36:56.296 kid1| 87,3| clientStream.cc(202) clientStreamDetach: clientStreamDetach: Detaching node 0x80d65638
2017/05/31 23:36:56.296 kid1| 87,3| clientStream.cc(287) clientStreamFree: Freeing clientStreamNode 0x80d65638
2017/05/31 23:36:56.296 kid1| 33,3| client_side_request.cc(246) ~ClientHttpRequest: httpRequestFree: 199.16.156.6:443
2017/05/31 23:36:56.296 kid1| 33,5| client_side.cc(576) logRequest: logging half-baked transaction: 199.16.156.6:443
2017/05/31 23:36:56.296 kid1| 28,3| Checklist.cc(70) preCheck: 0xbfb4fe7c checking fast ACLs
2017/05/31 23:36:56.296 kid1| 28,5| Acl.cc(138) matches: checking access_log daemon:/var/log/squid/access.test.log
2017/05/31 23:36:56.296 kid1| 28,5| Acl.cc(138) matches: checking (access_log daemon:/var/log/squid/access.test.log line)
2017/05/31 23:36:56.296 kid1| 28,3| Acl.cc(158) matches: checked: (access_log daemon:/var/log/squid/access.test.log line) = 1
2017/05/31 23:36:56.296 kid1| 28,3| Acl.cc(158) matches: checked: access_log daemon:/var/log/squid/access.test.log = 1
2017/05/31 23:36:56.296 kid1| 28,3| Checklist.cc(63) markFinished: 0xbfb4fe7c answer ALLOWED for match
2017/05/31 23:36:56.296 kid1| 50,5| ModDaemon.cc(65) logfileNewBuffer: logfileNewBuffer: daemon:/var/log/squid/access.test.log: new buffer
2017/05/31 23:36:56.296 kid1| 50,3| ModDaemon.cc(172) logfile_mod_daemon_append: logfile_mod_daemon_append: daemon:/var/log/squid/access.test.log: appending 1 bytes
2017/05/31 23:36:56.296 kid1| 50,3| ModDaemon.cc(176) logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 0 of 32768 bytes before append
2017/05/31 23:36:56.296 kid1| 50,3| ModDaemon.cc(172) logfile_mod_daemon_append: logfile_mod_daemon_append: daemon:/var/log/squid/access.test.log: appending 106 bytes
2017/05/31 23:36:56.296 kid1| 50,3| ModDaemon.cc(176) logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 1 of 32768 bytes before append
2017/05/31 23:36:56.296 kid1| 50,3| ModDaemon.cc(172) logfile_mod_daemon_append: logfile_mod_daemon_append: daemon:/var/log/squid/access.test.log: appending 2 bytes
2017/05/31 23:36:56.296 kid1| 50,3| ModDaemon.cc(176) logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 107 of 32768 bytes before append
2017/05/31 23:36:56.296 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 21, type=2, handler=1, client_data=0x80945048, timeout=0
2017/05/31 23:36:56.296 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0xbfb4fe7c
2017/05/31 23:36:56.296 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0xbfb4fe7c
2017/05/31 23:36:56.296 kid1| 93,5| AsyncCall.cc(26) AsyncCall: The AsyncCall Initiate::noteInitiatorAborted constructed, this=0x80d92248 [call153]
2017/05/31 23:36:56.296 kid1| 93,5| AsyncCall.cc(93) ScheduleCall: Initiator.cc(40) will call Initiate::noteInitiatorAborted() [call153]
2017/05/31 23:36:56.296 kid1| 93,5| AsyncJob.cc(40) ~AsyncJob: AsyncJob destructed, this=0x80d63e80 type=ClientHttpRequest [job9]
2017/05/31 23:36:56.296 kid1| 33,5| client_side.cc(4135) getSslContextStart: Generating SSL certificate for twitter.com using ssl_crtd.
2017/05/31 23:36:56.296 kid1| 33,5| client_side.cc(4139) getSslContextStart: SSL crtd request: new_certificate 3238 host=twitter.com
Sign=signTrusted
SignHash=SHA256
-----BEGIN CERTIFICATE-----
MII
[REMOVED FOR A SHORTER POST]
-----END CERTIFICATE-----
-----BEGIN PRIVATE KEY-----
MII
[REMOVED FOR A SHORTER POST]
-----END PRIVATE KEY-----

2017/05/31 23:36:56.296 kid1| 84,5| helper.cc(1167) GetFirstAvailable: GetFirstAvailable: Running servers 5
2017/05/31 23:36:56.296 kid1| 5,5| AsyncCall.cc(26) AsyncCall: The AsyncCall helperDispatchWriteDone constructed, this=0x80d8eef8 [call154]
2017/05/31 23:36:56.296 kid1| 5,5| Write.cc(35) Write: local=[::] remote=[::] FD 10 flags=1: sz 3260: asynCall 0x80d8eef8*1
2017/05/31 23:36:56.296 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 10, type=2, handler=1, client_data=0x808fe194, timeout=0
2017/05/31 23:36:56.296 kid1| 84,5| helper.cc(1309) helperDispatch: helperDispatch: Request sent to ssl_crtd #Hlpr1, 3260 bytes
2017/05/31 23:36:56.296 kid1| 17,4| AsyncJob.cc(152) callEnd: Http::Server status out: [ job8]
2017/05/31 23:36:56.296 kid1| 17,4| AsyncCallQueue.cc(57) fireNext: leaving ConnStateData::ConnStateData::httpsPeeked()
2017/05/31 23:36:56.297 kid1| 93,5| AsyncCallQueue.cc(55) fireNext: entering Initiate::noteInitiatorAborted()
2017/05/31 23:36:56.297 kid1| 93,5| AsyncCall.cc(38) make: make call Initiate::noteInitiatorAborted [call153]
2017/05/31 23:36:56.297 kid1| 93,5| AsyncCall.cc(56) cancel: will not call Initiate::noteInitiatorAborted [call153] because job gone
2017/05/31 23:36:56.297 kid1| 93,5| AsyncCall.cc(48) make: will not call Initiate::noteInitiatorAborted [call153] because of job gone
2017/05/31 23:36:56.297 kid1| 93,5| AsyncCallQueue.cc(57) fireNext: leaving Initiate::noteInitiatorAborted()
2017/05/31 23:36:56.297 kid1| 50,3| ModDaemon.cc(108) logfileHandleWrite: daemon:/var/log/squid/access.test.log: write returned 109
2017/05/31 23:36:56.297 kid1| 5,5| Write.cc(66) HandleWrite: local=[::] remote=[::] FD 10 flags=1: off 0, sz 3260.
2017/05/31 23:36:56.297 kid1| 5,5| Write.cc(108) HandleWrite: write() returns 3260
2017/05/31 23:36:56.297 kid1| 5,3| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 10 flags=1 (0, 0)
2017/05/31 23:36:56.297 kid1| 5,5| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperDispatchWriteDone(local=[::] remote=[::] FD 10 flags=1, data=0x809233a8, size=3260, buf=0x80d7ae10) [call154]
2017/05/31 23:36:56.297 kid1| 5,5| AsyncCallQueue.cc(55) fireNext: entering helperDispatchWriteDone(local=[::] remote=[::] FD 10 flags=1, data=0x809233a8, size=3260, buf=0x80d7ae10)
2017/05/31 23:36:56.297 kid1| 5,5| AsyncCall.cc(38) make: make call helperDispatchWriteDone [call154]
2017/05/31 23:36:56.297 kid1| 5,5| AsyncCallQueue.cc(57) fireNext: leaving helperDispatchWriteDone(local=[::] remote=[::] FD 10 flags=1, data=0x809233a8, size=3260, buf=0x80d7ae10)
2017/05/31 23:36:56.297 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 21, type=2, handler=0, client_data=0, timeout=0
2017/05/31 23:36:56.297 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 10, type=2, handler=0, client_data=0, timeout=0
2017/05/31 23:36:56.300 kid1| 5,3| Read.cc(144) HandleRead: FD 10, size 4095, retval 2905, errno 0
2017/05/31 23:36:56.300 kid1| 5,3| IoCallback.cc(116) finish: called for local=[::] remote=[::] FD 10 flags=1 (0, 0)
2017/05/31 23:36:56.300 kid1| 5,4| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 10 flags=1, data=0x809233a8, size=2905, buf=0x809234f0) [call111]
2017/05/31 23:36:56.300 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering helperHandleRead(local=[::] remote=[::] FD 10 flags=1, data=0x809233a8, size=2905, buf=0x809234f0)
2017/05/31 23:36:56.300 kid1| 5,4| AsyncCall.cc(38) make: make call helperHandleRead [call111]
2017/05/31 23:36:56.300 kid1| 84,5| helper.cc(866) helperHandleRead: helperHandleRead: 2905 bytes from ssl_crtd #Hlpr1
2017/05/31 23:36:56.300 kid1| 84,3| helper.cc(892) helperHandleRead: helperHandleRead: end of reply found
2017/05/31 23:36:56.300 kid1| 84,3| Reply.cc(29) parse: Parsing helper buffer
2017/05/31 23:36:56.300 kid1| 84,3| Reply.cc(48) parse: Buff length is larger than 2
2017/05/31 23:36:56.300 kid1| 84,3| Reply.cc(52) parse: helper Result = OK
2017/05/31 23:36:56.300 kid1| 33,5| client_side.cc(3992) sslCrtdHandleReply: Certificate for 199.16.156.6 was successfully recieved from ssl_crtd
2017/05/31 23:36:56.300 kid1| 33,5| client_side.cc(4394) doPeekAndSpliceStep: PeekAndSplice mode, proceed with client negotiation. Currrent state:SSLv2/v3 read client hello A
2017/05/31 23:36:56.300 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=2, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.301 kid1| 84,5| helper.cc(1167) GetFirstAvailable: GetFirstAvailable: Running servers 5
2017/05/31 23:36:56.301 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x80d78220 [call155]
2017/05/31 23:36:56.301 kid1| 5,5| Read.cc(58) comm_read_base: comm_read, queueing read for local=[::] remote=[::] FD 10 flags=1; asynCall 0x80d78220*1
2017/05/31 23:36:56.301 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 10, type=1, handler=1, client_data=0x808fe16c, timeout=0
2017/05/31 23:36:56.301 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 10 flags=1, data=0x809233a8, size=2905, buf=0x809234f0)
2017/05/31 23:36:56.301 kid1| 83,5| bio.cc(576) squid_bio_ctrl: 0x80d8fe20 6(0, 0x80d92248)
2017/05/31 23:36:56.301 kid1| 83,5| support.cc(2154) get_session_cb: Request to search for SSL Session of len:32272931686:268141813
2017/05/31 23:36:56.301 kid1| 54,5| MemMap.cc(148) openForReading: trying to open slot for key 669B4410F584FB0F9A063B581AD8A05B for reading in map [ssl_session_cache]
2017/05/31 23:36:56.301 kid1| 54,5| MemMap.cc(169) openForReadingAt: trying to open slot at 51 for reading in map [ssl_session_cache]
2017/05/31 23:36:56.301 kid1| 54,5| MemMap.cc(161) openForReading: failed to open slot for key 669B4410F584FB0F9A063B581AD8A05B for reading in map [ssl_session_cache]
2017/05/31 23:36:56.301 kid1| 83,5| support.cc(2169) get_session_cb: Failed to retrieved from cache

2017/05/31 23:36:56.301 kid1| 83,5| bio.cc(95) write: FD 13 wrote 918 <= 918
2017/05/31 23:36:56.301 kid1| 83,5| bio.cc(576) squid_bio_ctrl: 0x80d8fe20 11(0, 0)
2017/05/31 23:36:56.301 kid1| 83,5| bio.cc(118) read: FD 13 read -1 <= 5
2017/05/31 23:36:56.301 kid1| 83,5| bio.cc(123) read: error: 11 ignored: 1
2017/05/31 23:36:56.301 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x80d60950, timeout=0
2017/05/31 23:36:56.301 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=2, handler=0, client_data=0, timeout=0
2017/05/31 23:36:56.302 kid1| 83,5| bio.cc(118) read: FD 13 read 5 <= 5
2017/05/31 23:36:56.302 kid1| 83,5| bio.cc(118) read: FD 13 read 262 <= 262
2017/05/31 23:36:56.318 kid1| 83,5| bio.cc(118) read: FD 13 read 5 <= 5
2017/05/31 23:36:56.318 kid1| 83,5| bio.cc(118) read: FD 13 read 1 <= 1
2017/05/31 23:36:56.318 kid1| 83,5| bio.cc(118) read: FD 13 read 5 <= 5
2017/05/31 23:36:56.318 kid1| 83,5| bio.cc(118) read: FD 13 read 64 <= 64
2017/05/31 23:36:56.318 kid1| 83,5| bio.cc(95) write: FD 13 wrote 266 <= 266
2017/05/31 23:36:56.318 kid1| 83,5| bio.cc(576) squid_bio_ctrl: 0x80d8fe20 11(0, 0)
2017/05/31 23:36:56.318 kid1| 83,5| bio.cc(576) squid_bio_ctrl: 0x80d8fe20 7(0, 0x80d92248)
-----BEGIN SSL SESSION PARAMETERS-----
MGACAQECAgMDBAIALwQABDDdX0DcPIcUITJcdR7aVovBoj+LZ/5wkReoH845k907
vgdlroH/auAfzPOm6P9xXIehBgIEWS83eKIEAgIBLKQCBACmDQQLdHdpdHRlci5j
b20=
-----END SSL SESSION PARAMETERS-----
2017/05/31 23:36:56.318 kid1| 83,2| client_side.cc(3796) clientNegotiateSSL: clientNegotiateSSL: New session 0x80d8b330 on FD 13 (10.215.144.48:42597)
2017/05/31 23:36:56.318 kid1| 83,3| client_side.cc(3800) clientNegotiateSSL: clientNegotiateSSL: FD 13 negotiated cipher AES128-SHA
2017/05/31 23:36:56.318 kid1| 83,5| client_side.cc(3816) clientNegotiateSSL: clientNegotiateSSL: FD 13 has no certificate.
2017/05/31 23:36:56.318 kid1| 33,4| client_side.cc(231) readSomeData: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17: reading request...
2017/05/31 23:36:56.318 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall ConnStateData::clientReadRequest constructed, this=0x80d7abc8 [call156]
2017/05/31 23:36:56.318 kid1| 5,5| Read.cc(58) comm_read_base: comm_read, queueing read for local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17; asynCall 0x80d7abc8*1
2017/05/31 23:36:56.318 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x808fe268, timeout=0
2017/05/31 23:36:56.318 kid1| 5,3| IoCallback.cc(116) finish: called for local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17 (0, 0)
2017/05/31 23:36:56.318 kid1| 33,5| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call ConnStateData::clientReadRequest(local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, data=0x80d60950) [call156]
2017/05/31 23:36:56.318 kid1| 33,5| AsyncCallQueue.cc(55) fireNext: entering ConnStateData::clientReadRequest(local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, data=0x80d60950)
2017/05/31 23:36:56.318 kid1| 33,5| AsyncCall.cc(38) make: make call ConnStateData::clientReadRequest [call156]
2017/05/31 23:36:56.318 kid1| 33,5| AsyncJob.cc(123) callStart: Http::Server status in: [ job8]
2017/05/31 23:36:56.319 kid1| 33,5| client_side.cc(3251) clientReadRequest: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17
2017/05/31 23:36:56.319 kid1| 83,5| bio.cc(118) read: FD 13 read 5 <= 5
2017/05/31 23:36:56.319 kid1| 83,5| bio.cc(118) read: FD 13 read 432 <= 432
2017/05/31 23:36:56.319 kid1| 83,2| support.cc(1364) ssl_read_method: SSL FD 13 is pending
2017/05/31 23:36:56.319 kid1| 5,3| Read.cc(91) ReadNow: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, size 66, retval 66, errno 0
2017/05/31 23:36:56.319 kid1| 33,5| client_side.cc(3200) clientParseRequests: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17: attempting to parse
2017/05/31 23:36:56.319 kid1| 74,5| HttpParser.cc(37) reset: Request buffer is GET / HTTP/1.1
Host: twitter.com
User-Agent: Mozilla/5.0 (Window
2017/05/31 23:36:56.319 kid1| 74,5| HttpParser.cc(47) parseRequestFirstLine: parsing possible request: GET / HTTP/1.1
Host: twitter.com
User-Agent: Mozilla/5.0 (Window
2017/05/31 23:36:56.319 kid1| 74,5| HttpParser.cc(257) HttpParserParseReqLine: Parser: retval 1: from 0->15: method 0->2; url 4->4; version 6->13 (1/1)
2017/05/31 23:36:56.319 kid1| 33,5| client_side.cc(2194) parseHttpRequest: Incomplete request, waiting for end of headers
2017/05/31 23:36:56.319 kid1| 33,5| client_side.cc(3238) clientParseRequests: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17: not enough request data: 66 < 65536
2017/05/31 23:36:56.319 kid1| 33,4| client_side.cc(231) readSomeData: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17: reading request...
2017/05/31 23:36:56.319 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall ConnStateData::clientReadRequest constructed, this=0x80d8ea80 [call157]
2017/05/31 23:36:56.319 kid1| 5,5| Read.cc(58) comm_read_base: comm_read, queueing read for local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17; asynCall 0x80d8ea80*1
2017/05/31 23:36:56.319 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x808fe268, timeout=0
2017/05/31 23:36:56.319 kid1| 33,5| AsyncJob.cc(152) callEnd: Http::Server status out: [ job8]
2017/05/31 23:36:56.319 kid1| 33,5| AsyncCallQueue.cc(57) fireNext: leaving ConnStateData::clientReadRequest(local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, data=0x80d60950)
2017/05/31 23:36:56.319 kid1| 5,3| IoCallback.cc(116) finish: called for local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17 (0, 0)
2017/05/31 23:36:56.319 kid1| 33,5| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call ConnStateData::clientReadRequest(local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, data=0x80d60950) [call157]
2017/05/31 23:36:56.319 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=2, handler=0, client_data=0, timeout=0
2017/05/31 23:36:56.319 kid1| 33,5| AsyncCallQueue.cc(55) fireNext: entering ConnStateData::clientReadRequest(local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, data=0x80d60950)
2017/05/31 23:36:56.319 kid1| 33,5| AsyncCall.cc(38) make: make call ConnStateData::clientReadRequest [call157]
2017/05/31 23:36:56.319 kid1| 33,5| AsyncJob.cc(123) callStart: Http::Server status in: [ job8]
2017/05/31 23:36:56.319 kid1| 33,5| client_side.cc(3251) clientReadRequest: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17
2017/05/31 23:36:56.319 kid1| 83,2| support.cc(1364) ssl_read_method: SSL FD 13 is pending
2017/05/31 23:36:56.319 kid1| 5,3| Read.cc(91) ReadNow: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, size 61, retval 61, errno 0
2017/05/31 23:36:56.319 kid1| 33,5| client_side.cc(3200) clientParseRequests: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17: attempting to parse
2017/05/31 23:36:56.319 kid1| 74,5| HttpParser.cc(37) reset: Request buffer is GET / HTTP/1.1
Host: twitter.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:45.0) Gecko/20100101 Firefox/45.0
Accept: text/
2017/05/31 23:36:56.319 kid1| 74,5| HttpParser.cc(47) parseRequestFirstLine: parsing possible request: GET / HTTP/1.1
Host: twitter.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:45.0) Gecko/20100101 Firefox/45.0
Accept: text/
2017/05/31 23:36:56.319 kid1| 74,5| HttpParser.cc(257) HttpParserParseReqLine: Parser: retval 1: from 0->15: method 0->2; url 4->4; version 6->13 (1/1)
2017/05/31 23:36:56.319 kid1| 33,5| client_side.cc(2194) parseHttpRequest: Incomplete request, waiting for end of headers
2017/05/31 23:36:56.319 kid1| 33,5| client_side.cc(3238) clientParseRequests: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17: not enough request data: 127 < 65536
2017/05/31 23:36:56.319 kid1| 33,4| client_side.cc(231) readSomeData: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17: reading request...
2017/05/31 23:36:56.319 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall ConnStateData::clientReadRequest constructed, this=0x80d7abc8 [call158]
2017/05/31 23:36:56.319 kid1| 5,5| Read.cc(58) comm_read_base: comm_read, queueing read for local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17; asynCall 0x80d7abc8*1
2017/05/31 23:36:56.319 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=1, handler=1, client_data=0x808fe268, timeout=0
2017/05/31 23:36:56.319 kid1| 33,5| AsyncJob.cc(152) callEnd: Http::Server status out: [ job8]
2017/05/31 23:36:56.319 kid1| 33,5| AsyncCallQueue.cc(57) fireNext: leaving ConnStateData::clientReadRequest(local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, data=0x80d60950)
2017/05/31 23:36:56.319 kid1| 5,3| IoCallback.cc(116) finish: called for local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17 (0, 0)
2017/05/31 23:36:56.319 kid1| 33,5| AsyncCall.cc(93) ScheduleCall: IoCallback.cc(135) will call ConnStateData::clientReadRequest(local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, data=0x80d60950) [call158]
2017/05/31 23:36:56.319 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, type=2, handler=0, client_data=0, timeout=0
2017/05/31 23:36:56.319 kid1| 33,5| AsyncCallQueue.cc(55) fireNext: entering ConnStateData::clientReadRequest(local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, data=0x80d60950)
2017/05/31 23:36:56.319 kid1| 33,5| AsyncCall.cc(38) make: make call ConnStateData::clientReadRequest [call158]
2017/05/31 23:36:56.319 kid1| 33,5| AsyncJob.cc(123) callStart: Http::Server status in: [ job8]
2017/05/31 23:36:56.320 kid1| 33,5| client_side.cc(3251) clientReadRequest: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17
2017/05/31 23:36:56.320 kid1| 33,2| client_side.cc(2370) maybeMakeSpaceAvailable: growing request buffer: available=385 used=127
2017/05/31 23:36:56.320 kid1| 5,3| Read.cc(91) ReadNow: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17, size 385, retval 268, errno 0
2017/05/31 23:36:56.320 kid1| 33,5| client_side.cc(3200) clientParseRequests: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17: attempting to parse
2017/05/31 23:36:56.320 kid1| 74,5| HttpParser.cc(37) reset: Request buffer is GET / HTTP/1.1
Host: twitter.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:45.0) Gecko/20100101 Firefox/45.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3
Accept-Encoding: gzip, deflate, br
Cookie: guest_id=v1%3A149087497487789376; personalization_id="v1_zoGltEgEbV7jirFVg/rLKg=="
Connection: keep-alive


2017/05/31 23:36:56.320 kid1| 74,5| HttpParser.cc(47) parseRequestFirstLine: parsing possible request: GET / HTTP/1.1
Host: twitter.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:45.0) Gecko/20100101 Firefox/45.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3
Accept-Encoding: gzip, deflate, br
Cookie: guest_id=v1%3A149087497487789376; personalization_id="v1_zoGltEgEbV7jirFVg/rLKg=="
Connection: keep-alive


2017/05/31 23:36:56.320 kid1| 74,5| HttpParser.cc(257) HttpParserParseReqLine: Parser: retval 1: from 0->15: method 0->2; url 4->4; version 6->13 (1/1)
2017/05/31 23:36:56.320 kid1| 33,3| client_side.cc(2258) parseHttpRequest: parseHttpRequest: req_hdr = {Host: twitter.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:45.0) Gecko/20100101 Firefox/45.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3
Accept-Encoding: gzip, deflate, br
Cookie: guest_id=v1%3A149087497487789376; personalization_id="v1_zoGltEgEbV7jirFVg/rLKg=="
Connection: keep-alive

}
2017/05/31 23:36:56.320 kid1| 33,3| client_side.cc(2262) parseHttpRequest: parseHttpRequest: end = {
}
2017/05/31 23:36:56.320 kid1| 33,3| client_side.cc(2266) parseHttpRequest: parseHttpRequest: prefix_sz = 395, req_line_sz = 16
2017/05/31 23:36:56.320 kid1| 93,5| AsyncJob.cc(34) AsyncJob: AsyncJob constructed, this=0x80d8c238 type=ClientHttpRequest [job11]
2017/05/31 23:36:56.320 kid1| 87,3| clientStream.cc(144) clientStreamInsertHead: clientStreamInsertHead: Inserted node 0x80d65688 with data 0x80d6561c after head
2017/05/31 23:36:56.320 kid1| 33,5| client_side.cc(2282) parseHttpRequest: parseHttpRequest: Request Header is
Host: twitter.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:45.0) Gecko/20100101 Firefox/45.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3
Accept-Encoding: gzip, deflate, br
Cookie: guest_id=v1%3A149087497487789376; personalization_id="v1_zoGltEgEbV7jirFVg/rLKg=="
Connection: keep-alive


2017/05/31 23:36:56.320 kid1| 33,5| client_side.cc(2303) parseHttpRequest: Prepare absolute URL from intercept
2017/05/31 23:36:56.320 kid1| 25,5| mime_header.cc(37) mime_get_header_field: mime_get_header: looking for 'Host'
2017/05/31 23:36:56.320 kid1| 25,5| mime_header.cc(59) mime_get_header_field: mime_get_header: checking 'Host: twitter.com'
2017/05/31 23:36:56.320 kid1| 25,5| mime_header.cc(82) mime_get_header_field: mime_get_header: returning 'twitter.com'
2017/05/31 23:36:56.320 kid1| 33,5| client_side.cc(2125) prepareTransparentURL: TRANSPARENT HOST REWRITE: 'https://twitter.com/'
2017/05/31 23:36:56.320 kid1| 33,5| client_side.cc(2342) parseHttpRequest: parseHttpRequest: Complete request received
2017/05/31 23:36:56.320 kid1| 11,2| client_side.cc(2345) parseHttpRequest: HTTP Client local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17
2017/05/31 23:36:56.320 kid1| 11,2| client_side.cc(2346) parseHttpRequest: HTTP Client REQUEST:
---------
GET / HTTP/1.1
Host: twitter.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; rv:45.0) Gecko/20100101 Firefox/45.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3
Accept-Encoding: gzip, deflate, br
Cookie: guest_id=v1%3A149087497487789376; personalization_id="v1_zoGltEgEbV7jirFVg/rLKg=="
Connection: keep-alive


----------
2017/05/31 23:36:56.320 kid1| 33,5| client_side.cc(3221) clientParseRequests: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17: done parsing a request
2017/05/31 23:36:56.320 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall clientLifetimeTimeout constructed, this=0x80d92248 [call159]
2017/05/31 23:36:56.320 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17 timeout 86400
2017/05/31 23:36:56.320 kid1| 23,3| url.cc(357) urlParse: urlParse: Split URL 'https://twitter.com/' into proto='https', host='twitter.com', port='443', path='/'
2017/05/31 23:36:56.320 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'twitter.com': Name or service not known
2017/05/31 23:36:56.320 kid1| 33,3| client_side.cc(873) clientSetKeepaliveFlag: http_ver = HTTP/1.1
2017/05/31 23:36:56.320 kid1| 33,3| client_side.cc(874) clientSetKeepaliveFlag: method = GET
2017/05/31 23:36:56.320 kid1| 33,4| client_side.cc(2455) quitAfterError: Will close after error: local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17
2017/05/31 23:36:56.320 kid1| 33,5| client_side.cc(2476) serveDelayedError: Responding with delated error for https://twitter.com/
2017/05/31 23:36:56.320 kid1| 20,3| store.cc(484) lock: clientReplyContext::setReplyToStoreEntry locked key D1806996FC89FCA8A2553AF78760C5D4 e:=sp2XINV/0x80c213e0*2
2017/05/31 23:36:56.320 kid1| 11,5| HttpRequest.cc(474) detailError: current error details: 11/111
2017/05/31 23:36:56.320 kid1| 33,5| client_side.cc(1709) pullData: 0 written 0 into local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17
2017/05/31 23:36:56.320 kid1| 33,5| client_side.cc(1665) getNextRangeOffset: range: 0; http offset 0; reply 0
2017/05/31 23:36:56.320 kid1| 87,3| clientStream.cc(184) clientStreamRead: clientStreamRead: Calling 1 with cbdata 0x80d66a08 from node 0x80d65688
2017/05/31 23:36:56.320 kid1| 90,3| store_client.cc(200) copy: store_client::copy: D1806996FC89FCA8A2553AF78760C5D4, from 0, for length 4096, cb 1, cbdata 0x80d659a0
2017/05/31 23:36:56.320 kid1| 20,3| store.cc(484) lock: store_client::copy locked key D1806996FC89FCA8A2553AF78760C5D4 e:=sp2XINV/0x80c213e0*3
2017/05/31 23:36:56.320 kid1| 90,3| store_client.cc(297) storeClientCopy2: storeClientCopy2: D1806996FC89FCA8A2553AF78760C5D4
2017/05/31 23:36:56.320 kid1| 33,5| store_client.cc(329) doCopy: store_client::doCopy: co: 0, hi: 3782
2017/05/31 23:36:56.320 kid1| 90,3| store_client.cc(433) scheduleMemRead: store_client::doCopy: Copying normal from memory
2017/05/31 23:36:56.320 kid1| 88,5| client_side_reply.cc(2154) sendMoreData: clientReplyContext::sendMoreData: https://twitter.com/, 3782 bytes (3782 new bytes)
2017/05/31 23:36:56.320 kid1| 88,5| client_side_reply.cc(2158) sendMoreData: clientReplyContext::sendMoreData:local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17 '199.16.156.6:443' out.offset=0
2017/05/31 23:36:56.321 kid1| 88,2| client_side_reply.cc(2001) processReplyAccessResult: The reply for GET https://twitter.com/ is ALLOWED, because it matched (access_log daemon:/var/log/squid/access.test.log line)
2017/05/31 23:36:56.321 kid1| 20,3| store.cc(484) lock: ClientHttpRequest::loggingEntry locked key D1806996FC89FCA8A2553AF78760C5D4 e:=sp2XINV/0x80c213e0*4
2017/05/31 23:36:56.321 kid1| 88,3| client_side_reply.cc(2039) processReplyAccessResult: clientReplyContext::sendMoreData: Appending 3525 bytes after 257 bytes of headers
2017/05/31 23:36:56.321 kid1| 87,3| clientStream.cc(162) clientStreamCallback: clientStreamCallback: Calling 1 with cbdata 0x80d6561c from node 0x80d65638
2017/05/31 23:36:56.321 kid1| 11,2| client_side.cc(1391) sendStartOfMessage: HTTP Client local=199.16.156.6:443 remote=10.215.144.48 FD 13 flags=17
2017/05/31 23:36:56.321 kid1| 11,2| client_side.cc(1392) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 503 Service Unavailable
Server: squid/3.5.14
Mime-Version: 1.0
Date: Wed, 31 May 2017 21:36:56 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3525
X-Squid-Error: ERR_CONNECT_FAIL 111
Vary: Accept-Language
Content-Language: en
X-Cache: MISS from inf-fw1
X-Cache-Lookup: NONE from inf-fw1:3227
Via: 1.1 inf-fw1 (squid/3.5.14)
Connection: close

Thanks,

Vieri


From eliezer at ngtech.co.il  Wed May 31 22:53:23 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Thu, 1 Jun 2017 01:53:23 +0300
Subject: [squid-users] squid sslbump and certificates
In-Reply-To: <820815053.47827.1496265847163@mail.yahoo.com>
References: <1666824574.1494153.1496061384978.ref@mail.yahoo.com>
 <1666824574.1494153.1496061384978@mail.yahoo.com>
 <DB6PR0401MB2680BA1E032D170A3D770D3F8FF30@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <548387612.1952806.1496095904224@mail.yahoo.com>
 <a982180a-e389-9d05-9a74-6b951064b9c7@treenet.co.nz>
 <820815053.47827.1496265847163@mail.yahoo.com>
Message-ID: <028101d2da60$b51b0c50$1f5124f0$@ngtech.co.il>

What OS?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Vieri
Sent: Thursday, June 1, 2017 12:24 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid sslbump and certificates


________________________________
From: Amos Jeffries <squid3 at treenet.co.nz>
>
> Which version of Squid are you using now?


I still haven't found the time to update my systems but the squid version I was running this on was/is 3.5.14.
I probably need to catch up for this feature to work correctly.

Vieri
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



