<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] forward_max_tries 1 has no effect
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20forward_max_tries%201%20has%20no%20effect&In-Reply-To=%3Cc88e0e11-bc43-5c21-20e7-bf95dad0b212%40treenet.co.nz%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="017011.html">
   <LINK REL="Next"  HREF="017031.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] forward_max_tries 1 has no effect</H1>
    <B>Amos Jeffries</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20forward_max_tries%201%20has%20no%20effect&In-Reply-To=%3Cc88e0e11-bc43-5c21-20e7-bf95dad0b212%40treenet.co.nz%3E"
       TITLE="[squid-users] forward_max_tries 1 has no effect">squid3 at treenet.co.nz
       </A><BR>
    <I>Fri Nov 24 07:43:39 UTC 2017</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="017011.html">[squid-users] forward_max_tries 1 has no effect
</A></li>
        <LI>Next message (by thread): <A HREF="017031.html">[squid-users] forward_max_tries 1 has no effect
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#17012">[ date ]</a>
              <a href="thread.html#17012">[ thread ]</a>
              <a href="subject.html#17012">[ subject ]</a>
              <a href="author.html#17012">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>
On 24/11/17 10:03, Ivan Larionov wrote:
&gt;&gt;<i>
</I>&gt;&gt;<i> On Nov 23, 2017, at 12:32 AM, Amos Jeffries &lt;<A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid3 at treenet.co.nz</A>&gt; wrote:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> On 23/11/17 14:20, Ivan Larionov wrote:
</I>&gt;&gt;&gt;<i> Hello.
</I>&gt;&gt;&gt;<i> We have an issue with squid when it tries to re-forward / retry failed request even when forward_max_tries is set to 1. The situation when it happens is when there's no response, parent just closes the connection.
</I>&gt;&gt;<i> ...
</I>&gt;&gt;&gt;<i> It doesn't happen 100% times. Sometimes squid returns 502 after the 1st try, sometimes it retries once. Also I haven't seen more than 1 retry.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Please enable debug_options 44,2 to see what destinations your Squid is actually finding.
</I>&gt;<i> 
</I>&gt;<i> I'll check this on Monday.
</I>&gt;<i> 
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> max_forward_tries is just a rough cap on the number of server names which can be found when generating that list. The actual destinations count can exceed it if one or more of the servers happens to have multiple IPs to try.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> The overall transaction can involve retries if one of the other layers (TCP or HTTP) contains retry semantics to a single server.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Could it be a bug? We'd really like to disable these retries.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Why are trying to break HTTP?
</I>&gt;&gt;<i> What is the actual problem you are trying to resolve here?
</I>&gt;&gt;<i>
</I>&gt;<i> 
</I>&gt;<i> Why do you think I'm trying to break HTTP?
</I>&gt;<i> 
</I>&gt;<i> squid forwards the request to parent but parent misbehaves and just closes the connection after 40 seconds. I'm trying to prevent retry of request in such situation. Why squid retries if I never asked him to do it and specifically said &quot;forward_max_tries 1&quot;.
</I>&gt;<i> 
</I>&gt;<i> And this is not a connection failure, squid successfully establishes the connection and sends the request, parent ACKs it, just never responses back and proactively closes the connection.
</I>&gt;<i> 
</I>
This is not misbehaviour on the part of either Squid nor the parent.
&lt;<A HREF="https://tools.ietf.org/html/rfc7230#section-6.3.1">https://tools.ietf.org/html/rfc7230#section-6.3.1</A>&gt;
&quot;Connections can be closed at any time, with or without intention.&quot;


As has been discussed in other threads recently there are servers out 
there starting to greylist TCP connections, closing the first one some 
time *after* SYN+ACK regardless of what the proxy sends and accepting 
any followup connection attempts.

NP: That can result in exactly the behaviour you describe from the peer 
as Squid does not wait for a FIN to arrive before sending its upstream 
HTTP request - Squid will &quot;randomly&quot; get a FIN or a RST depending on 
whether the FIN or the DATA packet wins the race into the Squid machines 
TCP stack. FIN and RST have different retry properties which might 
explain your &quot;sometimes retries&quot; behaviour.


Also, TCP connections fail quite often for many other reasons anyway. 
Anything from power fluctuations at a router to BGP switching the packet 
route dropping packets. They are most often a short-term situation which 
is resolved by the time the repeat is attempted.

What you are trying to do will result in Squid being unable to cope with 
any of these transitory restrictions from the TCP environment and force 
the client to receive a terminal error page.
  That will greatly slow down detection and recovery from the slightly 
longer-lived TCP issues in Squid itself and may result in N other 
clients also unnecessarily receiving the same error response as bad 
connection attempts gets spread between many clients (all getting 
errors) instead of isolated to the one/few who hit it when the issue 
initially occurs.

Expanding the retries to large numbers (ie the recent default change to 
25), or to low numbers (eg the old default of 5) are reasonable things 
to do depending on the network stability to your upstreams. But going 
all the way to 0 retries is guaranteed to lead to more client visible 
problems than necessary.


All that asside I phrased it as a question because you might have had a 
good reason for increasing the visible failure rates.


&gt;<i> We're already fixing parent behavior, but still want to disable retries on squid side.
</I>&gt;<i> 
</I>

Since you describe this as peer misbehaviour, then treating it to Squids 
normal TCP failure recovery is the best behaviour. Retry is the intended 
correct behaviour for a proxy to perform on any non-idempotent requests. 
In your case up to a value of 1 retry before declaring non-temporary 
route failure.

NP: idempotent vs non-idempotent may be another reason behind the 
observed behaviour of retry happening only sometimes.


If you are doing this due to overall latency/delay on the affected 
client traffic you would be better off reducing the timeouts involved 
(cache_peer connect-timeout= parameter AFAICS) than aiming at a retry 
count of 0. Perhapse also requiring a few standby=N persistent 
connections to be maintained if the peer is HTTP/1.1 capable.

Amos

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="017011.html">[squid-users] forward_max_tries 1 has no effect
</A></li>
	<LI>Next message (by thread): <A HREF="017031.html">[squid-users] forward_max_tries 1 has no effect
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#17012">[ date ]</a>
              <a href="thread.html#17012">[ thread ]</a>
              <a href="subject.html#17012">[ subject ]</a>
              <a href="author.html#17012">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
