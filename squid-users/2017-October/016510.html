<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] SSL Bump Failures with Google and Wikipedia
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20SSL%20Bump%20Failures%20with%20Google%20and%20Wikipedia&In-Reply-To=%3C3d87fae7-e104-6ef1-1ab6-67bb7e0e79a8%40gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="016509.html">
   <LINK REL="Next"  HREF="016585.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] SSL Bump Failures with Google and Wikipedia</H1>
    <B>Yuri</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20SSL%20Bump%20Failures%20with%20Google%20and%20Wikipedia&In-Reply-To=%3C3d87fae7-e104-6ef1-1ab6-67bb7e0e79a8%40gmail.com%3E"
       TITLE="[squid-users] SSL Bump Failures with Google and Wikipedia">yvoinov at gmail.com
       </A><BR>
    <I>Sun Oct  1 01:08:04 UTC 2017</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="016509.html">[squid-users] SSL Bump Failures with Google and Wikipedia
</A></li>
        <LI>Next message (by thread): <A HREF="016585.html">[squid-users] SSL Bump Failures with Google and Wikipedia
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#16510">[ date ]</a>
              <a href="thread.html#16510">[ thread ]</a>
              <a href="subject.html#16510">[ subject ]</a>
              <a href="author.html#16510">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>I guess in HTTP headers. =-O :-D


01.10.2017 7:05, Eliezer Croitoru &#1087;&#1080;&#1096;&#1077;&#1090;:
&gt;<i> Hey Rafael,
</I>&gt;<i>
</I>&gt;<i> Where have you seen the details about brotli being used?
</I>&gt;<i>
</I>&gt;<i> Thanks,
</I>&gt;<i> Eliezer
</I>&gt;<i>
</I>&gt;<i> ----
</I>&gt;<i> Eliezer Croitoru
</I>&gt;<i> Linux System Administrator
</I>&gt;<i> Mobile: +972-5-28704261
</I>&gt;<i> Email: <A HREF="https://lists.squid-cache.org/listinfo/squid-users">eliezer at ngtech.co.il</A>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> -----Original Message-----
</I>&gt;<i> From: Rafael Akchurin [mailto:<A HREF="https://lists.squid-cache.org/listinfo/squid-users">rafael.akchurin at diladele.com</A>] 
</I>&gt;<i> Sent: Sunday, October 1, 2017 01:16
</I>&gt;<i> To: Jeffrey Merkey &lt;<A HREF="https://lists.squid-cache.org/listinfo/squid-users">jeffmerkey at gmail.com</A>&gt;
</I>&gt;<i> Cc: Eliezer Croitoru &lt;<A HREF="https://lists.squid-cache.org/listinfo/squid-users">eliezer at ngtech.co.il</A>&gt;; squid-users
</I>&gt;<i> &lt;<A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users at lists.squid-cache.org</A>&gt;
</I>&gt;<i> Subject: Re: [squid-users] SSL Bump Failures with Google and Wikipedia
</I>&gt;<i>
</I>&gt;<i> Hello Jeff,
</I>&gt;<i>
</I>&gt;<i> Do not forget Google and YouTube are now using brotli encoding extensively,
</I>&gt;<i> not only gzip.
</I>&gt;<i>
</I>&gt;<i> Best regards,
</I>&gt;<i> Rafael Akchurin
</I>&gt;<i>
</I>&gt;&gt;<i> Op 30 sep. 2017 om 23:49 heeft Jeffrey Merkey &lt;<A HREF="https://lists.squid-cache.org/listinfo/squid-users">jeffmerkey at gmail.com</A>&gt; het
</I>&gt;<i> volgende geschreven:
</I>&gt;&gt;&gt;<i> On 9/30/17, Eliezer Croitoru &lt;<A HREF="https://lists.squid-cache.org/listinfo/squid-users">eliezer at ngtech.co.il</A>&gt; wrote:
</I>&gt;&gt;&gt;<i> Hey Jeffrey,
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> What happens when you disable the next icap service this way:
</I>&gt;&gt;&gt;<i> icap_service service_avi_resp respmod_precache 
</I>&gt;&gt;&gt;<i> <A HREF="icap://127.0.0.1:1344/cherokee">icap://127.0.0.1:1344/cherokee</A> bypass=0 adaptation_access 
</I>&gt;&gt;&gt;<i> service_avi_resp deny all
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Is it still the same?
</I>&gt;&gt;&gt;<i> What I suspect is that the requests are defined to accept gzip 
</I>&gt;&gt;&gt;<i> compressed objects and the icap service is not &quot;gnuzip&quot; them which 
</I>&gt;&gt;&gt;<i> results in what you see.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> To make sure that squid is not at fault here try to disable both icap 
</I>&gt;&gt;&gt;<i> services and then add then one at a time and see which of this 
</I>&gt;&gt;&gt;<i> triangle is giving you trouble.
</I>&gt;&gt;&gt;<i> I enhanced an ICAP library which is written in GoLang at:
</I>&gt;&gt;&gt;<i> <A HREF="https://github.com/elico/icap">https://github.com/elico/icap</A>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> And I have couple examples on how to work with http requests and 
</I>&gt;&gt;&gt;<i> responses
</I>&gt;&gt;&gt;<i> at:
</I>&gt;&gt;&gt;<i> <A HREF="https://github.com/andybalholm/redwood/">https://github.com/andybalholm/redwood/</A>
</I>&gt;&gt;&gt;<i> <A HREF="https://github.com/andybalholm/redwood/search?utf8=%E2%9C%93&amp;q=gzip&amp;t">https://github.com/andybalholm/redwood/search?utf8=%E2%9C%93&amp;q=gzip&amp;t</A>
</I>&gt;&gt;&gt;<i> ype=
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Let me know if you need help finding out the issue.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> All The Bests,
</I>&gt;&gt;&gt;<i> Eliezer
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> ----
</I>&gt;&gt;&gt;<i> Eliezer Croitoru
</I>&gt;&gt;&gt;<i> Linux System Administrator
</I>&gt;&gt;&gt;<i> Mobile: +972-5-28704261
</I>&gt;&gt;&gt;<i> Email: <A HREF="https://lists.squid-cache.org/listinfo/squid-users">eliezer at ngtech.co.il</A>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> -----Original Message-----
</I>&gt;&gt;&gt;<i> From: squid-users [mailto:<A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users-bounces at lists.squid-cache.org</A>] 
</I>&gt;&gt;&gt;<i> On Behalf Of Jeffrey Merkey
</I>&gt;&gt;&gt;<i> Sent: Saturday, September 30, 2017 23:28
</I>&gt;&gt;&gt;<i> To: squid-users &lt;<A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users at lists.squid-cache.org</A>&gt;
</I>&gt;&gt;&gt;<i> Subject: [squid-users] SSL Bump Failures with Google and Wikipedia
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Hello All,
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> I have been working with the squid server and icap and I have been 
</I>&gt;&gt;&gt;<i> running into problems with content cached from google and wikipedia.
</I>&gt;&gt;&gt;<i> Some sites using https, such as Centos.org work perfectly with ssl 
</I>&gt;&gt;&gt;<i> bumping and I get the decrypted content as html and it's readable.
</I>&gt;&gt;&gt;<i> Other sites, such as google and wikipedia return what looks like 
</I>&gt;&gt;&gt;<i> encrypted traffic, or perhaps mime encoded data, I am not sure which.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Are there cases where squid will default to direct mode and not 
</I>&gt;&gt;&gt;<i> decrypt the traffic?  I am using the latest squid server 3.5.27.  I 
</I>&gt;&gt;&gt;<i> really would like to get this working with google and wikipedia.  I 
</I>&gt;&gt;&gt;<i> reviewed the page source code from the browser viewer and it looks 
</I>&gt;&gt;&gt;<i> nothing like the data I am getting via the icap server.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Any assistance would be greatly appreciated.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> The config I am using is:
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> #
</I>&gt;&gt;&gt;<i> # Recommended minimum configuration:
</I>&gt;&gt;&gt;<i> #
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> # Example rule allowing access from your local networks.
</I>&gt;&gt;&gt;<i> # Adapt to list your (internal) IP networks from where browsing # 
</I>&gt;&gt;&gt;<i> should be allowed
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> acl localnet src 127.0.0.1
</I>&gt;&gt;&gt;<i> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
</I>&gt;&gt;&gt;<i> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network 
</I>&gt;&gt;&gt;<i> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
</I>&gt;&gt;&gt;<i> acl localnet src fc00::/7       # RFC 4193 local private network range
</I>&gt;&gt;&gt;<i> acl localnet src fe80::/10      # RFC 4291 link-local (directly
</I>&gt;&gt;&gt;<i> plugged) machines
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> acl SSL_ports port 443
</I>&gt;&gt;&gt;<i> acl Safe_ports port 80          # http
</I>&gt;&gt;&gt;<i> acl Safe_ports port 21          # ftp
</I>&gt;&gt;&gt;<i> acl Safe_ports port 443         # https
</I>&gt;&gt;&gt;<i> acl Safe_ports port 70          # gopher
</I>&gt;&gt;&gt;<i> acl Safe_ports port 210         # wais
</I>&gt;&gt;&gt;<i> acl Safe_ports port 1025-65535  # unregistered ports
</I>&gt;&gt;&gt;<i> acl Safe_ports port 280         # http-mgmt
</I>&gt;&gt;&gt;<i> acl Safe_ports port 488         # gss-http
</I>&gt;&gt;&gt;<i> acl Safe_ports port 591         # filemaker
</I>&gt;&gt;&gt;<i> acl Safe_ports port 777         # multiling http
</I>&gt;&gt;&gt;<i> acl CONNECT method CONNECT
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> #
</I>&gt;&gt;&gt;<i> # Recommended minimum Access Permission configuration:
</I>&gt;&gt;&gt;<i> #
</I>&gt;&gt;&gt;<i> # Deny requests to certain unsafe ports http_access deny !Safe_ports
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> # Deny CONNECT to other than secure SSL ports http_access deny 
</I>&gt;&gt;&gt;<i> CONNECT !SSL_ports
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> # Only allow cachemgr access from localhost http_access allow 
</I>&gt;&gt;&gt;<i> localhost manager http_access deny manager
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> # We strongly recommend the following be uncommented to protect 
</I>&gt;&gt;&gt;<i> innocent # web applications running on the proxy server who think the 
</I>&gt;&gt;&gt;<i> only # one who can access services on &quot;localhost&quot; is a local user 
</I>&gt;&gt;&gt;<i> #http_access deny to_localhost
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> #
</I>&gt;&gt;&gt;<i> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS #
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> # Example rule allowing access from your local networks.
</I>&gt;&gt;&gt;<i> # Adapt localnet in the ACL section to list your (internal) IP 
</I>&gt;&gt;&gt;<i> networks # from where browsing should be allowed http_access allow 
</I>&gt;&gt;&gt;<i> localnet http_access allow localhost
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> # And finally deny all other access to this proxy http_access deny 
</I>&gt;&gt;&gt;<i> all
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> # Squid normally listens to port 3128 #http_port 3128
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> # Uncomment and adjust the following to add a disk cache directory.
</I>&gt;&gt;&gt;<i> #cache_dir ufs /usr/local/squid/var/cache/squid 100 16 256
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> # Leave coredumps in the first cache dir coredump_dir 
</I>&gt;&gt;&gt;<i> /usr/local/squid/var/cache/squid
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> #
</I>&gt;&gt;&gt;<i> # Add any of your own refresh_pattern entries above these.
</I>&gt;&gt;&gt;<i> #
</I>&gt;&gt;&gt;<i> refresh_pattern ^ftp:           1440    20%     10080
</I>&gt;&gt;&gt;<i> refresh_pattern ^gopher:        1440    0%      1440
</I>&gt;&gt;&gt;<i> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
</I>&gt;&gt;&gt;<i> refresh_pattern .               0       20%     4320
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> http_port 3128 ssl-bump generate-host-certificates=on 
</I>&gt;&gt;&gt;<i> dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myCA.pem 
</I>&gt;&gt;&gt;<i> http_port 3129
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> # SSL Bump Config
</I>&gt;&gt;&gt;<i> always_direct allow all
</I>&gt;&gt;&gt;<i> ssl_bump server-first all
</I>&gt;&gt;&gt;<i> sslproxy_cert_error deny all
</I>&gt;&gt;&gt;<i> sslproxy_flags DONT_VERIFY_PEER
</I>&gt;&gt;&gt;<i> sslcrtd_program /usr/local/squid/libexec/ssl_crtd -s /var/lib/ssl_db 
</I>&gt;&gt;&gt;<i> -M 4MB sslcrtd_children 8 startup=1 idle=1
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> # For squid 3.5.x
</I>&gt;&gt;&gt;<i> #sslcrtd_program /usr/local/squid/libexec/ssl_crtd -s /var/lib/ssl_db 
</I>&gt;&gt;&gt;<i> -M 4MB
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> # For squid 4.x
</I>&gt;&gt;&gt;<i> # sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s 
</I>&gt;&gt;&gt;<i> /var/lib/ssl_db -M 4MB
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> icap_enable on
</I>&gt;&gt;&gt;<i> icap_send_client_ip on
</I>&gt;&gt;&gt;<i> icap_send_client_username on
</I>&gt;&gt;&gt;<i> icap_client_username_header X-Authenticated-User icap_preview_enable 
</I>&gt;&gt;&gt;<i> on icap_preview_size 1024 icap_service service_avi_req 
</I>&gt;&gt;&gt;<i> reqmod_precache <A HREF="icap://127.0.0.1:1344/request">icap://127.0.0.1:1344/request</A>
</I>&gt;&gt;&gt;<i> bypass=1
</I>&gt;&gt;&gt;<i> adaptation_access service_avi_req allow all
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> icap_service service_avi_resp respmod_precache 
</I>&gt;&gt;&gt;<i> <A HREF="icap://127.0.0.1:1344/cherokee">icap://127.0.0.1:1344/cherokee</A> bypass=0 adaptation_access 
</I>&gt;&gt;&gt;<i> service_avi_resp allow all
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Jeff
</I>&gt;&gt;&gt;<i> _______________________________________________
</I>&gt;&gt;&gt;<i> squid-users mailing list
</I>&gt;&gt;&gt;<i> <A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users at lists.squid-cache.org</A>
</I>&gt;&gt;&gt;<i> <A HREF="http://lists.squid-cache.org/listinfo/squid-users">http://lists.squid-cache.org/listinfo/squid-users</A>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;<i> Eliezer,
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Well, you certainly hit the nail on the head.  I added the following 
</I>&gt;&gt;<i> code to check the content being sent to the icap server from squid, 
</I>&gt;&gt;<i> and here is what I found when I check the headers being sent from the 
</I>&gt;&gt;<i> remote web server:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Code to check for content type and encoding received by the icap 
</I>&gt;&gt;<i> server added to c-icap:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>    hdrs = ci_http_response_headers(req);
</I>&gt;&gt;<i>    content_type = ci_headers_value(hdrs, &quot;Content-Type&quot;);
</I>&gt;&gt;<i>    if (content_type)
</I>&gt;&gt;<i>       ci_debug_printf(1,&quot;srv_cherokee:  content-type: %s\n&quot;,
</I>&gt;&gt;<i>                       content_type);
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>    content_encoding = ci_headers_value(hdrs, &quot;Content-Encoding&quot;);
</I>&gt;&gt;<i>    if (content_encoding)
</I>&gt;&gt;<i>       ci_debug_printf(1,&quot;srv_cherokee:  content-encoding: %s\n&quot;,
</I>&gt;&gt;<i>                       content_encoding);
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> And the output from scanned pages sent over from squid:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> srv_cherokee:  init request 0x7f3dbc008eb0 pool hits:1 allocations: 1 
</I>&gt;&gt;<i> Allocating from objects pool object 5 pool hits:1 allocations: 1 
</I>&gt;&gt;<i> Geting buffer from pool 4096:1 Requested service: cherokee Read 
</I>&gt;&gt;<i> preview data if there are and process request
</I>&gt;&gt;<i> srv_cherokee:  content-type: text/html; charset=utf-8
</I>&gt;&gt;<i> srv_cherokee:  content-encoding: gzip         &lt;-- As you stated, I am
</I>&gt;&gt;<i> getting gzipped data
</I>&gt;&gt;<i> srv_cherokee:  we expect to read :-1 body data Allow 204...
</I>&gt;&gt;<i> Preview handler return allow 204 response
</I>&gt;&gt;<i> srv_cherokee:  release request 0x7f3dbc008eb0 Store buffer to long 
</I>&gt;&gt;<i> pool 4096:1 Storing to objects pool object 5 Log request to access log 
</I>&gt;&gt;<i> file /var/log/i-cap_access.log
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Wikipedia  at <A HREF="https://en.wikipedia.org/wiki/HTTP_compression">https://en.wikipedia.org/wiki/HTTP_compression</A> describes 
</I>&gt;&gt;<i> the process as:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> &quot; ...
</I>&gt;&gt;<i>   Compression scheme negotiation[edit]
</I>&gt;&gt;<i>   In most cases, excluding the SDCH, the negotiation is done in two 
</I>&gt;&gt;<i> steps, described in
</I>&gt;&gt;<i>   RFC 2616:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>   1. The web client advertises which compression schemes it supports 
</I>&gt;&gt;<i> by including a list
</I>&gt;&gt;<i>   of tokens in the HTTP request. For Content-Encoding, the list in a 
</I>&gt;&gt;<i> field called Accept -
</I>&gt;&gt;<i>   Encoding; for Transfer-Encoding, the field is called TE.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>   GET /encrypted-area HTTP/1.1
</I>&gt;&gt;<i>   Host: www.example.com
</I>&gt;&gt;<i>   Accept-Encoding: gzip, deflate
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>   2. If the server supports one or more compression schemes, the 
</I>&gt;&gt;<i> outgoing data may be
</I>&gt;&gt;<i>   compressed by one or more methods supported by both parties. If this 
</I>&gt;&gt;<i> is the case, the
</I>&gt;&gt;<i>   server will add a Content-Encoding or Transfer-Encoding field in the 
</I>&gt;&gt;<i> HTTP response with
</I>&gt;&gt;<i>   the used schemes, separated by commas.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>   HTTP/1.1 200 OK
</I>&gt;&gt;<i>   Date: mon, 26 June 2016 22:38:34 GMT
</I>&gt;&gt;<i>   Server: Apache/1.3.3.7 (Unix)  (Red-Hat/Linux)
</I>&gt;&gt;<i>   Last-Modified: Wed, 08 Jan 2003 23:11:55 GMT
</I>&gt;&gt;<i>   Accept-Ranges: bytes
</I>&gt;&gt;<i>   Content-Length: 438
</I>&gt;&gt;<i>   Connection: close
</I>&gt;&gt;<i>   Content-Type: text/html; charset=UTF-8
</I>&gt;&gt;<i>   Content-Encoding: gzip
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>   The web server is by no means obligated to use any compression method -
</I>&gt;<i> this
</I>&gt;&gt;<i>   depends on the internal settings of the web server and also may 
</I>&gt;&gt;<i> depend on the internal
</I>&gt;&gt;<i>   architecture of the website in question.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>   In case of SDCH a dictionary negotiation is also required, which may 
</I>&gt;&gt;<i> involve additional
</I>&gt;&gt;<i>   steps, like downloading a proper dictionary from .
</I>&gt;&gt;<i> ..&quot;
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> So, it looks like it is a feature of the browser.  So, is it possible 
</I>&gt;&gt;<i> to have squid gunzip the data or configure the browser not to send the 
</I>&gt;&gt;<i> header  to remove &quot;Accept-Encoding: gzip, deflate&quot; from the request 
</I>&gt;&gt;<i> sent to the remote server telling it to gzip the data?
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Thanks
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Jeff
</I>&gt;&gt;<i> _______________________________________________
</I>&gt;&gt;<i> squid-users mailing list
</I>&gt;&gt;<i> <A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users at lists.squid-cache.org</A>
</I>&gt;&gt;<i> <A HREF="http://lists.squid-cache.org/listinfo/squid-users">http://lists.squid-cache.org/listinfo/squid-users</A>
</I>&gt;<i> _______________________________________________
</I>&gt;<i> squid-users mailing list
</I>&gt;<i> <A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users at lists.squid-cache.org</A>
</I>&gt;<i> <A HREF="http://lists.squid-cache.org/listinfo/squid-users">http://lists.squid-cache.org/listinfo/squid-users</A>
</I>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: &lt;<A HREF="http://lists.squid-cache.org/pipermail/squid-users/attachments/20171001/b922d241/attachment.sig">http://lists.squid-cache.org/pipermail/squid-users/attachments/20171001/b922d241/attachment.sig</A>&gt;
</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="016509.html">[squid-users] SSL Bump Failures with Google and Wikipedia
</A></li>
	<LI>Next message (by thread): <A HREF="016585.html">[squid-users] SSL Bump Failures with Google and Wikipedia
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#16510">[ date ]</a>
              <a href="thread.html#16510">[ thread ]</a>
              <a href="subject.html#16510">[ subject ]</a>
              <a href="author.html#16510">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
