From rousskov at measurement-factory.com  Mon Apr  2 00:27:38 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 1 Apr 2018 18:27:38 -0600
Subject: [squid-users] ssl intercept and forward to privoxy
In-Reply-To: <1522364465118-0.post@n4.nabble.com>
References: <1522364465118-0.post@n4.nabble.com>
Message-ID: <904376fd-d429-c2b1-8fd8-6b73b3ea4b8a@measurement-factory.com>

On 03/29/2018 05:01 PM, teapot wrote:

> once the CONNECT is received by squid it cannot then recreate
> that command to a peer

FWIW, there is an experimental rough patch adding peering support for
SslBump in v4.0.24 [1]. We are working on a polished version for the
official submission.

I do not know whether that new functionality is enough to solve your tor
integration problems.


[1]
https://github.com/squid-cache/squid/compare/53fdd3f...measurement-factory:7a4c4ed.patch


Alex.


From squid at buglecreek.com  Mon Apr  2 15:48:41 2018
From: squid at buglecreek.com (squid at buglecreek.com)
Date: Mon, 02 Apr 2018 09:48:41 -0600
Subject: [squid-users] Disable SSLv3 Not working
In-Reply-To: <106f40f1-b0a2-0f6f-8866-4f67d2023279@treenet.co.nz>
References: <1522449692.1151928.1321764560.7E6B762F@webmail.messagingengine.com>
 <106f40f1-b0a2-0f6f-8866-4f67d2023279@treenet.co.nz>
Message-ID: <1522684121.3111957.1323737992.27ADABFE@webmail.messagingengine.com>

I missed that I needed that setting (sslproxy_options) in a reverse proxy mode of operation. We haven't had to use any pf the sslproxy_* options.  I'll test that and see if it takes care of the issue.  

Does this option need to be placed anywhere specifically in the config?  

Also, does this require and other sslproxy_* options.  Our goal is to just stop Nessus from flagging for sslv3.   Thanks

On Fri, Mar 30, 2018, at 8:29 PM, Amos Jeffries wrote:
> On 31/03/18 11:41, squid wrote:
> > We are using squid as reverse proxy and we have disabled SSLv3 :
> > 
> > https_port ... options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,CIPHER_SERVER_PREFERENCE cipher=ECDHE-ECDSA . . .. dhparams=/etc/...dhparams.pem
> 
> NP: Squid-3.5 or later is required for EC cipher support.
> 
> 
> > 
> > Using Nessus scanning tool, it reports that SSLv3 is enabled, but not SSLv2.   Looking at the ssl handshake client hello and server hellos is does seem that the sslv3 is being used.  Is there something that we are missing?
> > 
> > Version of Squid  (3.1) is stock RH6 which I know is old, but for now we need to use.  We will be upgrading to RH7, but it may be a little while so I'd like to get this solved. 
> > 
> > Secure Sockets Layer
> >     SSLv3 Record Layer: Handshake Protocol: Server Hello
> >         Content Type: Handshake (22)
> >         Version: SSL 3.0 (0x0300)
> >         Length: 74
> >         Handshake Protocol: Server Hello
> >             Handshake Type: Server Hello (2)
> >             Length: 70
> >             Version: SSL 3.0 (0x0300)
> >             Random: 5aa83ae26555f6dcc7042c341d090c6715a243a7be05d69b...
> >             Session ID Length: 32
> >             Session ID: 44bb10e985c067cc987bf2e698d458dd37d2b3c469ce9fe7...
> >             Cipher Suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA (0x0039)
> >             Compression Method: null (0)
> 
> Which of the TCP connections was that hello performed on?
> 
> You have apparently only disabled SSLv3 on the client->Squid connection.
> No information is provided about the Squid->server settings
> (sslproxy_options).
> 
> 
> Also, these options are handled by OpenSSL. They only work if the
> library Squid was built against supports them.
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Tue Apr  3 06:15:44 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 3 Apr 2018 18:15:44 +1200
Subject: [squid-users] Disable SSLv3 Not working
In-Reply-To: <1522684121.3111957.1323737992.27ADABFE@webmail.messagingengine.com>
References: <1522449692.1151928.1321764560.7E6B762F@webmail.messagingengine.com>
 <106f40f1-b0a2-0f6f-8866-4f67d2023279@treenet.co.nz>
 <1522684121.3111957.1323737992.27ADABFE@webmail.messagingengine.com>
Message-ID: <ba4db7bf-879d-b79c-a582-f8ad24547d71@treenet.co.nz>

On 03/04/18 03:48, squid wrote:
> I missed that I needed that setting (sslproxy_options) in a reverse proxy mode of operation. We haven't had to use any pf the sslproxy_* options.  I'll test that and see if it takes care of the issue.  
> 

It may or may not, that depends on the answer to the question you did
not answer yet - about which connection the handshake came from:
  squid->client or server->squid.

> Does this option need to be placed anywhere specifically in the config?  

No specific position.

> 
> Also, does this require and other sslproxy_* options.  Our goal is to just stop Nessus from flagging for sslv3.   Thanks
> 

The sslproxy_* directives are independent in regards to ordering, but
some of them (ie options and ciphers) interact with what they
permit/forbid the library to do.


Amos


From skupko.sk at gmail.com  Wed Apr  4 09:15:12 2018
From: skupko.sk at gmail.com (Peter Viskup)
Date: Wed, 4 Apr 2018 11:15:12 +0200
Subject: [squid-users] Squid4 '%<la' empty sometimes
Message-ID: <CAPa6PsE4LoaGFD+vhAB9DDCgzZPF_-n97TY3fidfoT-38dP5WA@mail.gmail.com>

On Linux Virtual Server balanced cluster the %<la is empty when Squid
errors ERR_ACCESS_DENIED or TCP_MEM_HIT are logged.

This is causing issue when processing logs on remote machine (e.g.
ELK). The "proxy node" cannot be differentiated.

This string used in logformat to differentiate Squid instance and LVS node:
proxyPort=%lp proxyIP=%la proxyNode=%<la

Example:
for ERR_ACCESS_DENIED and TCP_MEM_HIT entries:
proxyPort=3128 proxyIP=10.x.y.z proxyNode=-

for ERR_DIR_LISTING entry:
proxyPort=3128 proxyIP=10.x.y.z proxyNode=10.x.y.a

How to differentiate the nodes in such cases?
Should the bug being considered?

Peter


From squid3 at treenet.co.nz  Wed Apr  4 15:42:44 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 5 Apr 2018 03:42:44 +1200
Subject: [squid-users] Squid4 '%<la' empty sometimes
In-Reply-To: <CAPa6PsE4LoaGFD+vhAB9DDCgzZPF_-n97TY3fidfoT-38dP5WA@mail.gmail.com>
References: <CAPa6PsE4LoaGFD+vhAB9DDCgzZPF_-n97TY3fidfoT-38dP5WA@mail.gmail.com>
Message-ID: <37f70eb5-ccd2-a571-ec7e-13978c3f09f5@treenet.co.nz>

On 04/04/18 21:15, Peter Viskup wrote:
> On Linux Virtual Server balanced cluster the %<la is empty when Squid
> errors ERR_ACCESS_DENIED or TCP_MEM_HIT are logged.
> 
> This is causing issue when processing logs on remote machine (e.g.
> ELK). The "proxy node" cannot be differentiated.

It sounds to me like you are misinterpreting what is happening and/or
using the wrong logformat tags/codes.

The denied or HIT transactions you mention *do not* involve any upstream
server. Thus no upstream server connection. No logformat codes will log
details from a non-existing thing.

NP: the set of correct/valid values includes "-" for non-existing data
on most logformat codes, only a few use "0" for legacy reasons.


> 
> This string used in logformat to differentiate Squid instance and LVS node:
> proxyPort=%lp proxyIP=%la proxyNode=%<la

All of those are displaying Squid endpoint IP:port details. They just
apply to various of the multiple different connections Squid used (or
not) for the particular HTTP transaction.

"Local" in the docs there means Squid end of the TCP connections.


If you want to log the LVS IP:port details you need to log the IP:port
details of the *other* end of the connection between Squid and the LVS.

The '<' and '>' respectively denote the data being from the
client<-Squid connection or Squid->server connection(s).

NP: There many be many Squid->server connections actually used in the
event of failures. Only the final one is recorded.


> 
> Example:
> for ERR_ACCESS_DENIED and TCP_MEM_HIT entries:
> proxyPort=3128 proxyIP=10.x.y.z proxyNode=-
> 

A client (unknown) connected to Squid 10.x.y.z:3128.
No server involvement.


> for ERR_DIR_LISTING entry:
> proxyPort=3128 proxyIP=10.x.y.z proxyNode=10.x.y.a
> 

A client (unknown) connected to Squid 10.x.y.z:3128.
Squid contacted a server (unknown) from IP 10.x.y.a:(port unknown).


> How to differentiate the nodes in such cases?


So can you clarify what you mean by "Linux Virtual Server balanced
cluster" ?

Is that a cluster of LB devices/VM in front (or behind) a Squid proxy?
 or some Squid running on each node of the cluster?
 or something else?


Amos


From skupko.sk at gmail.com  Thu Apr  5 09:39:44 2018
From: skupko.sk at gmail.com (Peter Viskup)
Date: Thu, 5 Apr 2018 11:39:44 +0200
Subject: [squid-users] Squid4 '%<la' empty sometimes
In-Reply-To: <37f70eb5-ccd2-a571-ec7e-13978c3f09f5@treenet.co.nz>
References: <CAPa6PsE4LoaGFD+vhAB9DDCgzZPF_-n97TY3fidfoT-38dP5WA@mail.gmail.com>
 <37f70eb5-ccd2-a571-ec7e-13978c3f09f5@treenet.co.nz>
Message-ID: <CAPa6PsEzgLWarggrSNGai+Nqhgzy6igFwVfOZYqkarbT-EfTUw@mail.gmail.com>

On Wed, Apr 4, 2018 at 5:42 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 04/04/18 21:15, Peter Viskup wrote:
>> On Linux Virtual Server balanced cluster the %<la is empty when Squid
>> errors ERR_ACCESS_DENIED or TCP_MEM_HIT are logged.
>>
>> This is causing issue when processing logs on remote machine (e.g.
>> ELK). The "proxy node" cannot be differentiated.
>
> It sounds to me like you are misinterpreting what is happening and/or
> using the wrong logformat tags/codes.
>
> The denied or HIT transactions you mention *do not* involve any upstream
> server. Thus no upstream server connection. No logformat codes will log
> details from a non-existing thing.
>
> So can you clarify what you mean by "Linux Virtual Server balanced
> cluster" ?
>
> Is that a cluster of LB devices/VM in front (or behind) a Squid proxy?
>  or some Squid running on each node of the cluster?
>  or something else?

Two VMs with heartbeat+ldirectord+LVS. Every server running the Squid
proxy. The service IP with LVS configuration (managed by ldirectord)
is made highly available.


From squid3 at treenet.co.nz  Thu Apr  5 10:31:45 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 5 Apr 2018 22:31:45 +1200
Subject: [squid-users] Squid4 '%<la' empty sometimes
In-Reply-To: <CAPa6PsEzgLWarggrSNGai+Nqhgzy6igFwVfOZYqkarbT-EfTUw@mail.gmail.com>
References: <CAPa6PsE4LoaGFD+vhAB9DDCgzZPF_-n97TY3fidfoT-38dP5WA@mail.gmail.com>
 <37f70eb5-ccd2-a571-ec7e-13978c3f09f5@treenet.co.nz>
 <CAPa6PsEzgLWarggrSNGai+Nqhgzy6igFwVfOZYqkarbT-EfTUw@mail.gmail.com>
Message-ID: <c3df1968-0435-460c-4222-306368758b10@treenet.co.nz>

On 05/04/18 21:39, Peter Viskup wrote:
> On Wed, Apr 4, 2018 at 5:42 PM, Amos Jeffries wrote:
>> On 04/04/18 21:15, Peter Viskup wrote:
>>> On Linux Virtual Server balanced cluster the %<la is empty when Squid
>>> errors ERR_ACCESS_DENIED or TCP_MEM_HIT are logged.
>>>
>>> This is causing issue when processing logs on remote machine (e.g.
>>> ELK). The "proxy node" cannot be differentiated.
>>
>> It sounds to me like you are misinterpreting what is happening and/or
>> using the wrong logformat tags/codes.
>>
>> The denied or HIT transactions you mention *do not* involve any upstream
>> server. Thus no upstream server connection. No logformat codes will log
>> details from a non-existing thing.
>>
>> So can you clarify what you mean by "Linux Virtual Server balanced
>> cluster" ?
>>
>> Is that a cluster of LB devices/VM in front (or behind) a Squid proxy?
>>  or some Squid running on each node of the cluster?
>>  or something else?
> 
> Two VMs with heartbeat+ldirectord+LVS. Every server running the Squid
> proxy. The service IP with LVS configuration (managed by ldirectord)
> is made highly available.
> 


Okay. So..

0) you could also configure a specific unique value in each Squid's
logformat definition. So it is explicitly present in all log lines
generated by that proxy / node.

... or if you need something more dynamic ...

1) you could use the "note" directive to algorithmically determine (in
its ACL matching) a value for %note to record in a shared logformat
definition on a per-request, per-node basis.

2) If you have OpenFlows or similar recording of the inbound TCP
connections you might use the %>a:%>p:%>la tuplet (client IP:port +
Squid-IP) to match up with other info about the client TCP connection.
That is the most reliable relationship (as the server connection range
from none to many).

 [ note that %>la and %la may be different in the presence of NAT,
TPROXY, or PROXY protocol. ]

3) If the LVS is managing packet routing using TOS or packet markings
you could use the %>qos or %>nfmark to explicitly display those in the
log file.

4) If the VMs all have unique interface MAC/EUI addresses you could use
that uniqueness as node IDs with the %>eui code.

5) you could use all of the codes in #2, #3, and #4 for a 6-tuplet
identifier.


Amos


From j.emerlik at gmail.com  Thu Apr  5 20:56:57 2018
From: j.emerlik at gmail.com (j.emerlik)
Date: Thu, 05 Apr 2018 20:56:57 +0000
Subject: [squid-users] allways_direct SSL
Message-ID: <CA+ZZ2qH+ycE+0J4r-p+DU-H7Ta-dcybR7Om8Y3Qe7SbiF1UT-Q@mail.gmail.com>

(squid 3.5) I have in my config acl for some domains like:

acl mydomains dstdomain "/usr/local....."

and

cache_peer_access 10.10.x.x allow mydomains

so all http traffic to domains from my list is forwarded (port 80) to
another squid and that's works correct but only for port 80, traffic to
port 443 does work probably because there in config is set:

allways_direct allow SSL_ports

and forwarding to my another squid not working.

I would like forward mydomains to another squid and rest of ssl connections
should use allways_direct.

How to exclude domains from my mydomains list allways_direct allow
SSL_PORTS ?

Regards
MattX
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180405/123a6475/attachment.htm>

From squid3 at treenet.co.nz  Thu Apr  5 21:44:24 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 6 Apr 2018 09:44:24 +1200
Subject: [squid-users] allways_direct SSL
In-Reply-To: <CA+ZZ2qH+ycE+0J4r-p+DU-H7Ta-dcybR7Om8Y3Qe7SbiF1UT-Q@mail.gmail.com>
References: <CA+ZZ2qH+ycE+0J4r-p+DU-H7Ta-dcybR7Om8Y3Qe7SbiF1UT-Q@mail.gmail.com>
Message-ID: <b8b3e771-c371-d45f-9a09-b0c9428703d1@treenet.co.nz>

On 06/04/18 08:56, j.emerlik wrote:
> (squid 3.5) I have in my config acl for some domains like:
> 
> acl mydomains dstdomain "/usr/local....."
> 
> and
> 
> cache_peer_access 10.10.x.x allow mydomains
> 
> so all http traffic to domains from my list is forwarded (port 80)?to
> another squid and that's?works correct but only for port 80, traffic to
> port 443 does work probably because there in config is set:
> 
> allways_direct allow SSL_ports
> 
> and forwarding to?my another squid not working.

How is your cache_peer directive setup?

It is more likely because your peer is not setup to receive HTTPS
traffic, so the "mydomains" stuff is not going where you may think.

Amos


From j.emerlik at gmail.com  Fri Apr  6 08:02:43 2018
From: j.emerlik at gmail.com (j.emerlik)
Date: Fri, 06 Apr 2018 08:02:43 +0000
Subject: [squid-users] allways_direct SSL
In-Reply-To: <b8b3e771-c371-d45f-9a09-b0c9428703d1@treenet.co.nz>
References: <CA+ZZ2qH+ycE+0J4r-p+DU-H7Ta-dcybR7Om8Y3Qe7SbiF1UT-Q@mail.gmail.com>
 <b8b3e771-c371-d45f-9a09-b0c9428703d1@treenet.co.nz>
Message-ID: <CA+ZZ2qHoABYDK2QVJpaWdkfb2+fYGJT3aknyeAqOU0v_8oVCiw@mail.gmail.com>

On Thu, Apr 5, 2018, 23:44 Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 06/04/18 08:56, j.e. wrote:
> > (squid 3.5) I have in my config acl for some domains like:
> >
> > acl mydomains dstdomain "/usr/local....."
> >
> > and
> >
> > cache_peer_access 10.10.x.x allow mydomains
> >
> > so all http traffic to domains from my list is forwarded (port 80) to
> > another squid and that's works correct but only for port 80, traffic to
> > port 443 does work probably because there in config is set:
> >
> > allways_direct allow SSL_ports
> >
> > and forwarding to my another squid not working.
>
> How is your cache_peer directive setup?
>
> It is more likely because your peer is not setup to receive HTTPS
> traffic, so the "mydomains" stuff is not going where you may think.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


Thx for response , below part of my config :

cache_peer 10.10.x.x parent 31281 0 proxy-only no-tproxy

acl mydomains dstdomain "use/local....."

cache_pee_access 10.10.x.x allow mydomain

never_direct allow mydomain

peer_connect_timeout 5 seconds




>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180406/918e5bd5/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr  6 10:22:14 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 6 Apr 2018 22:22:14 +1200
Subject: [squid-users] allways_direct SSL
In-Reply-To: <CA+ZZ2qHoABYDK2QVJpaWdkfb2+fYGJT3aknyeAqOU0v_8oVCiw@mail.gmail.com>
References: <CA+ZZ2qH+ycE+0J4r-p+DU-H7Ta-dcybR7Om8Y3Qe7SbiF1UT-Q@mail.gmail.com>
 <b8b3e771-c371-d45f-9a09-b0c9428703d1@treenet.co.nz>
 <CA+ZZ2qHoABYDK2QVJpaWdkfb2+fYGJT3aknyeAqOU0v_8oVCiw@mail.gmail.com>
Message-ID: <c826f6de-f955-8e27-932d-3940d5d04baa@treenet.co.nz>

On 06/04/18 20:02, j.emerlik wrote:
> On Thu, Apr 5, 2018, 23:44 Amos Jeffries wrote:
> 
>     On 06/04/18 08:56, j.e. wrote:
>     > (squid 3.5) I have in my config acl for some domains like:
>     >
>     > acl mydomains dstdomain "/usr/local....."
>     >
>     > and
>     >
>     > cache_peer_access 10.10.x.x allow mydomains
>     >
>     > so all http traffic to domains from my list is forwarded (port 80)?to
>     > another squid and that's?works correct but only for port 80,
>     traffic to
>     > port 443 does work probably because there in config is set:
>     >
>     > allways_direct allow SSL_ports
>     >
>     > and forwarding to?my another squid not working.
> 
>     How is your cache_peer directive setup?
> 
>     It is more likely because your peer is not setup to receive HTTPS
>     traffic, so the "mydomains" stuff is not going where you may think.
> 
>     Amos
> 
> 
> Thx for response , below part of my config :
> 
> cache_peer 10.10.x.x parent 31281 0 proxy-only no-tproxy
> 
> acl mydomains dstdomain "use/local....."
> 
> cache_pee_access 10.10.x.x allow mydomain
> 
> never_direct allow mydomain
> 
> peer_connect_timeout 5 seconds
> 

Okay. So normal forward-proxy setup.

If the port 443 traffic is being intercepted then SSL-Bump'ed, then
Squid requires that cache_peer connection to be using TLS/SSL in order
to deliver it there. For that this Squid requires the 'ssl cafile='
options, with the CA one pointing to a PEM file containing public cert
of the CA which signed the peers server certificate.
 The peer of course requires its listening port (or another) to have TLS
setup at its end, and appropriate security setting for its own outbound
connections.

Other non-bumped traffic and CONNECT messages should "just work" already.


[ While TLS being end-to-end is a myth, Squid and most TLS software
still do ensure the whole connection chain stays secured. So no
conversions from HTTPS to HTTP in either direction along the way. ]

Amos


From skupko.sk at gmail.com  Fri Apr  6 12:48:20 2018
From: skupko.sk at gmail.com (Peter Viskup)
Date: Fri, 6 Apr 2018 14:48:20 +0200
Subject: [squid-users] Squid4 '%<la' empty sometimes
In-Reply-To: <c3df1968-0435-460c-4222-306368758b10@treenet.co.nz>
References: <CAPa6PsE4LoaGFD+vhAB9DDCgzZPF_-n97TY3fidfoT-38dP5WA@mail.gmail.com>
 <37f70eb5-ccd2-a571-ec7e-13978c3f09f5@treenet.co.nz>
 <CAPa6PsEzgLWarggrSNGai+Nqhgzy6igFwVfOZYqkarbT-EfTUw@mail.gmail.com>
 <c3df1968-0435-460c-4222-306368758b10@treenet.co.nz>
Message-ID: <CAPa6PsHD9yW6kt4zVjUicL_d7dYCT76Vwri+1LmGfvQpaHrOdw@mail.gmail.com>

Amos,
thank you for your helpful reply.

Setup with use of %note is working. Both servers have same
configuration from GIT. Added one include for the proxyNode note
configuration with "GIT ignore" flag on that file.
Realized the note can be used to track the ACL the transaction passed to.

Proxy node ID:
note proxyNode 10.x.y.a
logformat ... proxyNode=%{proxyNode}note ...

Passed via ACL:
acl sslstep1 at_step SslBump1
acl sslstep3 at_step SslBump3

acl test_s src <some_ip>
acl test_d dstdomain <some_domain>
acl test_ssl ssl::server_name <some_domain>
acl SSH_port port 22

# splice at step1 for SSH connections
note acl test_splice_ssh test_s test_d SSH_port
ssl_bump splice sslstep1 test_s test_d SSH_port

# splice at step3 for other TLS connections
note acl test_splice_http test_s test_ssl
ssl_bump splice sslstep3 test_s test_ssl

logformat ... acl=%{acl}note ...


On Thu, Apr 5, 2018 at 12:31 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 05/04/18 21:39, Peter Viskup wrote:
>> On Wed, Apr 4, 2018 at 5:42 PM, Amos Jeffries wrote:
>>> On 04/04/18 21:15, Peter Viskup wrote:
>>>> On Linux Virtual Server balanced cluster the %<la is empty when Squid
>>>> errors ERR_ACCESS_DENIED or TCP_MEM_HIT are logged.
>>>>
>>>> This is causing issue when processing logs on remote machine (e.g.
>>>> ELK). The "proxy node" cannot be differentiated.
>>>
>>> It sounds to me like you are misinterpreting what is happening and/or
>>> using the wrong logformat tags/codes.
>>>
>>> The denied or HIT transactions you mention *do not* involve any upstream
>>> server. Thus no upstream server connection. No logformat codes will log
>>> details from a non-existing thing.
>>>
>>> So can you clarify what you mean by "Linux Virtual Server balanced
>>> cluster" ?
>>>
>>> Is that a cluster of LB devices/VM in front (or behind) a Squid proxy?
>>>  or some Squid running on each node of the cluster?
>>>  or something else?
>>
>> Two VMs with heartbeat+ldirectord+LVS. Every server running the Squid
>> proxy. The service IP with LVS configuration (managed by ldirectord)
>> is made highly available.
>>
>
>
> Okay. So..
>
> 0) you could also configure a specific unique value in each Squid's
> logformat definition. So it is explicitly present in all log lines
> generated by that proxy / node.
>
> ... or if you need something more dynamic ...
>
> 1) you could use the "note" directive to algorithmically determine (in
> its ACL matching) a value for %note to record in a shared logformat
> definition on a per-request, per-node basis.
>
> 2) If you have OpenFlows or similar recording of the inbound TCP
> connections you might use the %>a:%>p:%>la tuplet (client IP:port +
> Squid-IP) to match up with other info about the client TCP connection.
> That is the most reliable relationship (as the server connection range
> from none to many).
>
>  [ note that %>la and %la may be different in the presence of NAT,
> TPROXY, or PROXY protocol. ]
>
> 3) If the LVS is managing packet routing using TOS or packet markings
> you could use the %>qos or %>nfmark to explicitly display those in the
> log file.
>
> 4) If the VMs all have unique interface MAC/EUI addresses you could use
> that uniqueness as node IDs with the %>eui code.
>
> 5) you could use all of the codes in #2, #3, and #4 for a 6-tuplet
> identifier.
>
>
> Amos


From squid3 at treenet.co.nz  Fri Apr  6 13:59:46 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 7 Apr 2018 01:59:46 +1200
Subject: [squid-users] Squid4 '%<la' empty sometimes
In-Reply-To: <CAPa6PsHD9yW6kt4zVjUicL_d7dYCT76Vwri+1LmGfvQpaHrOdw@mail.gmail.com>
References: <CAPa6PsE4LoaGFD+vhAB9DDCgzZPF_-n97TY3fidfoT-38dP5WA@mail.gmail.com>
 <37f70eb5-ccd2-a571-ec7e-13978c3f09f5@treenet.co.nz>
 <CAPa6PsEzgLWarggrSNGai+Nqhgzy6igFwVfOZYqkarbT-EfTUw@mail.gmail.com>
 <c3df1968-0435-460c-4222-306368758b10@treenet.co.nz>
 <CAPa6PsHD9yW6kt4zVjUicL_d7dYCT76Vwri+1LmGfvQpaHrOdw@mail.gmail.com>
Message-ID: <e1b0d696-1574-b840-840d-8ed77ace902e@treenet.co.nz>

On 07/04/18 00:48, Peter Viskup wrote:
> Amos,
> thank you for your helpful reply.
> 
> Setup with use of %note is working. Both servers have same
> configuration from GIT. Added one include for the proxyNode note
> configuration with "GIT ignore" flag on that file.
> Realized the note can be used to track the ACL the transaction passed to.
> 
> Proxy node ID:
> note proxyNode 10.x.y.a
> logformat ... proxyNode=%{proxyNode}note ...
> 
> Passed via ACL:
> acl sslstep1 at_step SslBump1
> acl sslstep3 at_step SslBump3
> 
> acl test_s src <some_ip>
> acl test_d dstdomain <some_domain>
> acl test_ssl ssl::server_name <some_domain>
> acl SSH_port port 22
> 
> # splice at step1 for SSH connections
> note acl test_splice_ssh test_s test_d SSH_port
> ssl_bump splice sslstep1 test_s test_d SSH_port

dstdomain ACL type (test_d is not valid at ssl_bump processing time. The
HTTP request the domain comes from has not (yet or ever) been decrypted
from the crypted bytes.


> 
> # splice at step3 for other TLS connections
> note acl test_splice_http test_s test_ssl
> ssl_bump splice sslstep3 test_s test_ssl
> 
> logformat ... acl=%{acl}note ...

Well, yes for this - but take care. Since the 'note ...' directive is
ONLY evaluated right at logging time it may show the wrong thing if the
ACL state changes between the initial directive (ssl_bump) evaluation
and the logging at the end of the transaction.
For example;
* the ssl_server_name ACL state changes with each SSL-Bump step that
completes, and
* dstdomain uses DNS lookups when only a raw-IP exists (eg in ssl_bump
step 1). The DNS records may expire and be changed in the time it takes
to transfer all the data in a spliced tunnel, before note re-runs the
dstdomain test_d check for logging.

Amos


From rousskov at measurement-factory.com  Fri Apr  6 14:42:51 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 6 Apr 2018 08:42:51 -0600
Subject: [squid-users] Squid4 '%<la' empty sometimes
In-Reply-To: <e1b0d696-1574-b840-840d-8ed77ace902e@treenet.co.nz>
References: <CAPa6PsE4LoaGFD+vhAB9DDCgzZPF_-n97TY3fidfoT-38dP5WA@mail.gmail.com>
 <37f70eb5-ccd2-a571-ec7e-13978c3f09f5@treenet.co.nz>
 <CAPa6PsEzgLWarggrSNGai+Nqhgzy6igFwVfOZYqkarbT-EfTUw@mail.gmail.com>
 <c3df1968-0435-460c-4222-306368758b10@treenet.co.nz>
 <CAPa6PsHD9yW6kt4zVjUicL_d7dYCT76Vwri+1LmGfvQpaHrOdw@mail.gmail.com>
 <e1b0d696-1574-b840-840d-8ed77ace902e@treenet.co.nz>
Message-ID: <ae16cd22-6305-40ce-c975-ccf45754e6f3@measurement-factory.com>

On 04/06/2018 07:59 AM, Amos Jeffries wrote:
> On 07/04/18 00:48, Peter Viskup wrote:
>> # splice at step3 for other TLS connections
>> note acl test_splice_http test_s test_ssl
>> ssl_bump splice sslstep3 test_s test_ssl
>>
>> logformat ... acl=%{acl}note ...

> Since the 'note ...' directive is
> ONLY evaluated right at logging time it may show the wrong thing if the
> ACL state changes between the initial directive (ssl_bump) evaluation
> and the logging at the end of the transaction.

Yes, and the correct solution to those problems is the new
annotate_transaction and/or annotate_client ACLs. They can be used to
reliably remember and log ACL-based decisions.

Alex.


From xpro6000 at gmail.com  Fri Apr  6 23:34:50 2018
From: xpro6000 at gmail.com (xpro)
Date: Fri, 6 Apr 2018 19:34:50 -0400
Subject: [squid-users] Proxy through another proxy possible?
Message-ID: <66bc30d9-ffad-6752-54a7-a750076fcbf0@gmail.com>

I'm not sure if Squid is the right tool for this. I'm trying to achieve 
the following.

I would have access to some exclusive proxies, but I would like for a 
limited amount of people to use these proxies without getting the 
original proxy IP. I want them to go through my proxy server and then my 
proxy server would forward them to the proxy I use.


Would this be possible with Squid?



From squid3 at treenet.co.nz  Sat Apr  7 05:05:30 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 7 Apr 2018 17:05:30 +1200
Subject: [squid-users] Proxy through another proxy possible?
In-Reply-To: <66bc30d9-ffad-6752-54a7-a750076fcbf0@gmail.com>
References: <66bc30d9-ffad-6752-54a7-a750076fcbf0@gmail.com>
Message-ID: <14d88b13-c63c-ba42-f95d-91688ebe7b6c@treenet.co.nz>

On 07/04/18 11:34, xpro wrote:
> I'm not sure if Squid is the right tool for this. I'm trying to achieve
> the following.
> 
> I would have access to some exclusive proxies, but I would like for a
> limited amount of people to use these proxies without getting the
> original proxy IP. I want them to go through my proxy server and then my
> proxy server would forward them to the proxy I use.
> 
> 
> Would this be possible with Squid?

Of course. I'm not exactly clear on what you mean by original or
exclusive proxies, but HTTP and Squid are certainly able to chain.

Amos


From xpro6000 at gmail.com  Sat Apr  7 06:02:58 2018
From: xpro6000 at gmail.com (xpro)
Date: Sat, 7 Apr 2018 02:02:58 -0400
Subject: [squid-users] Proxy through another proxy possible?
In-Reply-To: <14d88b13-c63c-ba42-f95d-91688ebe7b6c@treenet.co.nz>
References: <66bc30d9-ffad-6752-54a7-a750076fcbf0@gmail.com>
 <14d88b13-c63c-ba42-f95d-91688ebe7b6c@treenet.co.nz>
Message-ID: <8cea970b-e5af-86e0-a87c-401cca289931@gmail.com>

Would it be done like below?

http_port 3001
acl port1 myport 3001
tcp_outgoing_address myotherproxy.com:3114 port1


I want anyone connecting to my proxy using port 3001, to use the the 
proxy server on myotherproxy.com:3114


On 04/07/2018 01:05 AM, Amos Jeffries wrote:
> On 07/04/18 11:34, xpro wrote:
>> I'm not sure if Squid is the right tool for this. I'm trying to achieve
>> the following.
>>
>> I would have access to some exclusive proxies, but I would like for a
>> limited amount of people to use these proxies without getting the
>> original proxy IP. I want them to go through my proxy server and then my
>> proxy server would forward them to the proxy I use.
>>
>>
>> Would this be possible with Squid?
> Of course. I'm not exactly clear on what you mean by original or
> exclusive proxies, but HTTP and Squid are certainly able to chain.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Sat Apr  7 06:30:35 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 7 Apr 2018 18:30:35 +1200
Subject: [squid-users] Proxy through another proxy possible?
In-Reply-To: <8cea970b-e5af-86e0-a87c-401cca289931@gmail.com>
References: <66bc30d9-ffad-6752-54a7-a750076fcbf0@gmail.com>
 <14d88b13-c63c-ba42-f95d-91688ebe7b6c@treenet.co.nz>
 <8cea970b-e5af-86e0-a87c-401cca289931@gmail.com>
Message-ID: <6df9c042-4178-c44c-51ff-01772ef69f26@treenet.co.nz>

On 07/04/18 18:02, xpro wrote:
> Would it be done like below?
> 
> http_port 3001
> acl port1 myport 3001
> tcp_outgoing_address myotherproxy.com:3114 port1
> 
> 
> I want anyone connecting to my proxy using port 3001, to use the the
> proxy server on myotherproxy.com:3114

No. tcp_outgoing_address is the IP your Squid uses on its outgoing TCP
connections.

cache_peer is for configuring destination details about any specific
peer (upstream server or proxy) to relay messages through.
 see <https://wiki.squid-cache.org/Features/CacheHierarchy>

Amos


> 
> 
> On 04/07/2018 01:05 AM, Amos Jeffries wrote:
>> On 07/04/18 11:34, xpro wrote:
>>> I'm not sure if Squid is the right tool for this. I'm trying to achieve
>>> the following.
>>>
>>> I would have access to some exclusive proxies, but I would like for a
>>> limited amount of people to use these proxies without getting the
>>> original proxy IP. I want them to go through my proxy server and then my
>>> proxy server would forward them to the proxy I use.
>>>
>>>
>>> Would this be possible with Squid?
>> Of course. I'm not exactly clear on what you mean by original or
>> exclusive proxies, but HTTP and Squid are certainly able to chain.
>>
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From kalicecaprice at gmail.com  Sun Apr  8 09:04:33 2018
From: kalicecaprice at gmail.com (kalice caprice)
Date: Sun, 8 Apr 2018 11:04:33 +0200
Subject: [squid-users] Fwd: Outbound IPv6/128 - Possible ?
In-Reply-To: <CAAvX7kO8mfn0FJjzxtkjWh4sKfmuwkgn+Nc0sxQxRR3613VBwQ@mail.gmail.com>
References: <CAAvX7kO8mfn0FJjzxtkjWh4sKfmuwkgn+Nc0sxQxRR3613VBwQ@mail.gmail.com>
Message-ID: <CAAvX7kNoGVb4Bp8zGchAe4xCumQhWDs92D-aXxurBVMxB43qgw@mail.gmail.com>

Hello,

I'm trying to bound mutiples IPv4:Port entry to a different outbound IPv6
this way:

http_port 94.xxx.xxx.204:10001 name=1
acl ip1 myportname 1
tcp_outgoing_address 2a01:xxxx:xxxx:xxxx:xxxx:xxxx:eb7c:8336 ip1

http_port 94.xxx.xxx.204:10002 name=2
acl ip2 myportname 2
tcp_outgoing_address 2a01:xxxx:xxxx:xxxx:xxxx:xxxx:096f:b369 ip2

http_port 94.xxx.xxx.204:10003 name=3
acl ip3 myportname 3
tcp_outgoing_address 2a01:xxxx:xxxx:xxxx:xxxx:xxxx:5fe0:eba8 ip3

etc.

I was not able to get it working, the cache.log is giving me (99) cannot
assign requested address and fallback to the IPv4 address as an outbound
address.

I added the full IPv6 block inside the route -6 just in case, like this:
ip -6 route add to local 2a01:xxxx:xxxx:xxxx::/64 dev lo

Squid Cache: Version 3.5.23

I coudn't find anyone having the same problem while searching around so I'm
stuck and looking to know if it's possible or not to do it this way, if yes
what am I missing ? And if not, is there a way to randomize the end part of
the last 3 blocks of a /64 and if yes how ?

Thanks!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180408/3ea91246/attachment.htm>

From squid3 at treenet.co.nz  Sun Apr  8 10:14:21 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 8 Apr 2018 22:14:21 +1200
Subject: [squid-users] Fwd: Outbound IPv6/128 - Possible ?
In-Reply-To: <CAAvX7kNoGVb4Bp8zGchAe4xCumQhWDs92D-aXxurBVMxB43qgw@mail.gmail.com>
References: <CAAvX7kO8mfn0FJjzxtkjWh4sKfmuwkgn+Nc0sxQxRR3613VBwQ@mail.gmail.com>
 <CAAvX7kNoGVb4Bp8zGchAe4xCumQhWDs92D-aXxurBVMxB43qgw@mail.gmail.com>
Message-ID: <d1dfe39b-84c6-70ef-cb5d-8e6062a48826@treenet.co.nz>

On 08/04/18 21:04, kalice caprice wrote:
> Hello,
> 
> I'm trying to bound mutiples IPv4:Port entry to a different outbound
> IPv6 this way:

HTTP does not work that way. It is a stateless and multiplexing
protocol. Inbound and outbound connections are independent of each other.

> 
> http_port 94.xxx.xxx.204:10001 name=1
> acl ip1 myportname 1
> tcp_outgoing_address 2a01:xxxx:xxxx:xxxx:xxxx:xxxx:eb7c:8336 ip1
> 
> http_port 94.xxx.xxx.204:10002 name=2
> acl ip2 myportname 2
> tcp_outgoing_address 2a01:xxxx:xxxx:xxxx:xxxx:xxxx:096f:b369 ip2
> 
> http_port 94.xxx.xxx.204:10003 name=3
> acl ip3 myportname 3
> tcp_outgoing_address 2a01:xxxx:xxxx:xxxx:xxxx:xxxx:5fe0:eba8 ip3
> 
> etc.
> 
> I was not able to get it working, the cache.log is giving me (99) cannot
> assign requested address and fallback to the IPv4 address as an outbound
> address.

1) It is only possible to set an IPv6 outgoing when the server being
connected to is an IPv6 server address.

2) It is only possible for Squid to use an IP address which has been
allocated/assigned to the NIC.


> 
> I added the full IPv6 block inside the route -6 just in case, like this:
> ip -6 route add to local 2a01:xxxx:xxxx:xxxx::/64 dev lo

FYI: the lo device is hardware restricted to one machine. It is not
globally routable.


> 
> Squid Cache: Version 3.5.23
> 
> I coudn't find anyone having the same problem while searching around so
> I'm stuck and looking to know if it's possible or not to do it this way,
> if yes what am I missing ? And if not, is there a way to randomize the
> end part of the last 3 blocks of a /64 and if yes how ?

That is a feature of your system networking stack. Has nothing to do
with Squid. Lookup "Privacy Addressing" in IPv6.

Amos


From kalicecaprice at gmail.com  Sun Apr  8 12:48:42 2018
From: kalicecaprice at gmail.com (kalice caprice)
Date: Sun, 8 Apr 2018 14:48:42 +0200
Subject: [squid-users] squid-users Digest, Vol 44, Issue 8
In-Reply-To: <mailman.3.1523188802.17601.squid-users@lists.squid-cache.org>
References: <mailman.3.1523188802.17601.squid-users@lists.squid-cache.org>
Message-ID: <CAAvX7kNmpE=n87cYkUwour2L85AgHxCAjANN6_LQshBgzSHy0g@mail.gmail.com>

> 1) It is only possible to set an IPv6 outgoing when the server being
> connected to is an IPv6 server address.

It doesn't matter for me, It is just a way to get a different outbound IPv6
address depending on which port the connection is made to, and both clients
and servers has IPv6.
I saw a few threads here asking for more or less the same thing except that
I'm specifying the full address instead of implicit addressing to the
outbound, this is where I'm stuck.

> 2) It is only possible for Squid to use an IP address which has been
> allocated/assigned to the NIC.

The NIC is a network card if I understood it right. The IPv6 /64 subnet is
added to the main interface and the gateway is aswell, IPv6 is fully
working on the server.

> FYI: the lo device is hardware restricted to one machine. It is not
> globally routable.

I really don't know what I should do then... My network knowledges is
somewhat limited as you may have seen. I'd appreciate any help.

2018-04-08 14:00 GMT+02:00 <squid-users-request at lists.squid-cache.org>:

> Send squid-users mailing list submissions to
>         squid-users at lists.squid-cache.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         http://lists.squid-cache.org/listinfo/squid-users
> or, via email, send a message with subject or body 'help' to
>         squid-users-request at lists.squid-cache.org
>
> You can reach the person managing the list at
>         squid-users-owner at lists.squid-cache.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
>
>
> Today's Topics:
>
>    1. Fwd: Outbound IPv6/128 - Possible ? (kalice caprice)
>    2. Re: Fwd: Outbound IPv6/128 - Possible ? (Amos Jeffries)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sun, 8 Apr 2018 11:04:33 +0200
> From: kalice caprice <kalicecaprice at gmail.com>
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Fwd: Outbound IPv6/128 - Possible ?
> Message-ID:
>         <CAAvX7kNoGVb4Bp8zGchAe4xCumQhWDs92D-aXxurBVMxB43qgw at mail.
> gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Hello,
>
> I'm trying to bound mutiples IPv4:Port entry to a different outbound IPv6
> this way:
>
> http_port 94.xxx.xxx.204:10001 name=1
> acl ip1 myportname 1
> tcp_outgoing_address 2a01:xxxx:xxxx:xxxx:xxxx:xxxx:eb7c:8336 ip1
>
> http_port 94.xxx.xxx.204:10002 name=2
> acl ip2 myportname 2
> tcp_outgoing_address 2a01:xxxx:xxxx:xxxx:xxxx:xxxx:096f:b369 ip2
>
> http_port 94.xxx.xxx.204:10003 name=3
> acl ip3 myportname 3
> tcp_outgoing_address 2a01:xxxx:xxxx:xxxx:xxxx:xxxx:5fe0:eba8 ip3
>
> etc.
>
> I was not able to get it working, the cache.log is giving me (99) cannot
> assign requested address and fallback to the IPv4 address as an outbound
> address.
>
> I added the full IPv6 block inside the route -6 just in case, like this:
> ip -6 route add to local 2a01:xxxx:xxxx:xxxx::/64 dev lo
>
> Squid Cache: Version 3.5.23
>
> I coudn't find anyone having the same problem while searching around so I'm
> stuck and looking to know if it's possible or not to do it this way, if yes
> what am I missing ? And if not, is there a way to randomize the end part of
> the last 3 blocks of a /64 and if yes how ?
>
> Thanks!
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <http://lists.squid-cache.org/pipermail/squid-users/
> attachments/20180408/3ea91246/attachment-0001.html>
>
> ------------------------------
>
> Message: 2
> Date: Sun, 8 Apr 2018 22:14:21 +1200
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Fwd: Outbound IPv6/128 - Possible ?
> Message-ID: <d1dfe39b-84c6-70ef-cb5d-8e6062a48826 at treenet.co.nz>
> Content-Type: text/plain; charset=utf-8
>
> On 08/04/18 21:04, kalice caprice wrote:
> > Hello,
> >
> > I'm trying to bound mutiples IPv4:Port entry to a different outbound
> > IPv6 this way:
>
> HTTP does not work that way. It is a stateless and multiplexing
> protocol. Inbound and outbound connections are independent of each other.
>
> >
> > http_port 94.xxx.xxx.204:10001 name=1
> > acl ip1 myportname 1
> > tcp_outgoing_address 2a01:xxxx:xxxx:xxxx:xxxx:xxxx:eb7c:8336 ip1
> >
> > http_port 94.xxx.xxx.204:10002 name=2
> > acl ip2 myportname 2
> > tcp_outgoing_address 2a01:xxxx:xxxx:xxxx:xxxx:xxxx:096f:b369 ip2
> >
> > http_port 94.xxx.xxx.204:10003 name=3
> > acl ip3 myportname 3
> > tcp_outgoing_address 2a01:xxxx:xxxx:xxxx:xxxx:xxxx:5fe0:eba8 ip3
> >
> > etc.
> >
> > I was not able to get it working, the cache.log is giving me (99) cannot
> > assign requested address and fallback to the IPv4 address as an outbound
> > address.
>
> 1) It is only possible to set an IPv6 outgoing when the server being
> connected to is an IPv6 server address.
>
> 2) It is only possible for Squid to use an IP address which has been
> allocated/assigned to the NIC.
>
>
> >
> > I added the full IPv6 block inside the route -6 just in case, like this:
> > ip -6 route add to local 2a01:xxxx:xxxx:xxxx::/64 dev lo
>
> FYI: the lo device is hardware restricted to one machine. It is not
> globally routable.
>
>
> >
> > Squid Cache: Version 3.5.23
> >
> > I coudn't find anyone having the same problem while searching around so
> > I'm stuck and looking to know if it's possible or not to do it this way,
> > if yes what am I missing ? And if not, is there a way to randomize the
> > end part of the last 3 blocks of a /64 and if yes how ?
>
> That is a feature of your system networking stack. Has nothing to do
> with Squid. Lookup "Privacy Addressing" in IPv6.
>
> Amos
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
>
> End of squid-users Digest, Vol 44, Issue 8
> ******************************************
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180408/d6ccde7d/attachment.htm>

From xpro6000 at gmail.com  Sun Apr  8 13:06:45 2018
From: xpro6000 at gmail.com (xpro)
Date: Sun, 8 Apr 2018 09:06:45 -0400
Subject: [squid-users] Proxy through another proxy possible?
In-Reply-To: <6df9c042-4178-c44c-51ff-01772ef69f26@treenet.co.nz>
References: <66bc30d9-ffad-6752-54a7-a750076fcbf0@gmail.com>
 <14d88b13-c63c-ba42-f95d-91688ebe7b6c@treenet.co.nz>
 <8cea970b-e5af-86e0-a87c-401cca289931@gmail.com>
 <6df9c042-4178-c44c-51ff-01772ef69f26@treenet.co.nz>
Message-ID: <17c46aac-0f07-5c23-a82a-35934870d313@gmail.com>

Thank you. I did get it to work with snippet below

cache_peer myproxy.com parent 3114 0 no-query default
never_direct allow all


can you tell me how I can assign different ports to different outgoing 
proxies?


On 04/07/2018 02:30 AM, Amos Jeffries wrote:
> On 07/04/18 18:02, xpro wrote:
>> Would it be done like below?
>>
>> http_port 3001
>> acl port1 myport 3001
>> tcp_outgoing_address myotherproxy.com:3114 port1
>>
>>
>> I want anyone connecting to my proxy using port 3001, to use the the
>> proxy server on myotherproxy.com:3114
> No. tcp_outgoing_address is the IP your Squid uses on its outgoing TCP
> connections.
>
> cache_peer is for configuring destination details about any specific
> peer (upstream server or proxy) to relay messages through.
>   see <https://wiki.squid-cache.org/Features/CacheHierarchy>
>
> Amos
>
>
>>
>> On 04/07/2018 01:05 AM, Amos Jeffries wrote:
>>> On 07/04/18 11:34, xpro wrote:
>>>> I'm not sure if Squid is the right tool for this. I'm trying to achieve
>>>> the following.
>>>>
>>>> I would have access to some exclusive proxies, but I would like for a
>>>> limited amount of people to use these proxies without getting the
>>>> original proxy IP. I want them to go through my proxy server and then my
>>>> proxy server would forward them to the proxy I use.
>>>>
>>>>
>>>> Would this be possible with Squid?
>>> Of course. I'm not exactly clear on what you mean by original or
>>> exclusive proxies, but HTTP and Squid are certainly able to chain.
>>>
>>> Amos
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From skupko.sk at gmail.com  Mon Apr  9 12:03:50 2018
From: skupko.sk at gmail.com (Peter Viskup)
Date: Mon, 9 Apr 2018 14:03:50 +0200
Subject: [squid-users] Squid4 ICAP connection handling
Message-ID: <CAPa6PsEne7QzBBRN2LEt9_q-2sE04sb5K68wcMgyt+CffZpvcQ@mail.gmail.com>

Running Squid 4.0.23 the ICAP connections getting "frozen".

proxy:~ $ netstat -ntpa| grep 40620
tcp   920144      0 127.0.0.1:40620         127.0.0.1:1344
ESTABLISHED 1165/(squid-1)
tcp        0 2744857 127.0.0.1:1344          127.0.0.1:40620
ESTABLISHED 1211/esets_icap

# after ICAP service restart
proxy:~ $ netstat -ntpa| grep 40620
tcp   920144      0 127.0.0.1:40620         127.0.0.1:1344
ESTABLISHED 1165/(squid-1)
tcp        0 2744858 127.0.0.1:1344          127.0.0.1:40620
FIN_WAIT1   -

# later on - squid still keep the connection open
proxy:~ $ netstat -ntpa| grep 40620
tcp   920144      0 127.0.0.1:40620         127.0.0.1:1344
ESTABLISHED 1165/(squid-1)

How the ICAP connections are handled?
Was there any change in the code? We didn't experienced this with
Squid3.5 before.

Peter


From JOfficer at istreamfs.com  Mon Apr  9 14:10:54 2018
From: JOfficer at istreamfs.com (Joey Officer)
Date: Mon, 9 Apr 2018 14:10:54 +0000
Subject: [squid-users] unique access.log for specific ACLs
Message-ID: <EB7F56E3C9BD2744965B09892082CA541608BA1E@ad2.istreamfs.local>

Apologies if this has been covered before, but I could not find an archived discussion on the same topic.  Is it possible to assign a unique log file output to a specific ACL?  The use case is that we've begun blocking certain sites and we would like to begin logging the attempted access.

I'd suspect something similar to the following:

(squid 3.5.12)
#blocking
acl isf_blacklist dstdom_regex "/etc/squid/block.txt"
access_log daemon:/var/log/squid/blocked.log isf_blacklist
http_access deny isf_blacklist
deny_info TCP_RESET isf_blacklist

Appreciate any guidance that can be provided.

Joey

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180409/5f1b46b6/attachment.htm>

From rousskov at measurement-factory.com  Mon Apr  9 14:43:17 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 9 Apr 2018 08:43:17 -0600
Subject: [squid-users] Squid4 ICAP connection handling
In-Reply-To: <CAPa6PsEne7QzBBRN2LEt9_q-2sE04sb5K68wcMgyt+CffZpvcQ@mail.gmail.com>
References: <CAPa6PsEne7QzBBRN2LEt9_q-2sE04sb5K68wcMgyt+CffZpvcQ@mail.gmail.com>
Message-ID: <de74bbad-d17a-df05-687a-251d539dd5de@measurement-factory.com>

On 04/09/2018 06:03 AM, Peter Viskup wrote:
> Running Squid 4.0.23 the ICAP connections getting "frozen".
> 
> proxy:~ $ netstat -ntpa| grep 40620
> tcp   920144      0 127.0.0.1:40620         127.0.0.1:1344
> ESTABLISHED 1165/(squid-1)
> tcp        0 2744857 127.0.0.1:1344          127.0.0.1:40620
> ESTABLISHED 1211/esets_icap
> 
> # after ICAP service restart
> proxy:~ $ netstat -ntpa| grep 40620
> tcp   920144      0 127.0.0.1:40620         127.0.0.1:1344
> ESTABLISHED 1165/(squid-1)
> tcp        0 2744858 127.0.0.1:1344          127.0.0.1:40620
> FIN_WAIT1   -
> 
> # later on - squid still keep the connection open
> proxy:~ $ netstat -ntpa| grep 40620
> tcp   920144      0 127.0.0.1:40620         127.0.0.1:1344
> ESTABLISHED 1165/(squid-1)

> How the ICAP connections are handled?

The question is too general to give a brief useful answer.


> Was there any change in the code? 

Yes, a lot of code has changed between Squid v3 and v4, including some
ICAP-related changes.


> We didn't experienced this with Squid3.5 before.

Is there an HTTP transaction associated with (e.g., waiting for) that
stuck ICAP connection?

Can you reproduce this problem with a single HTTP transaction? Or does
it take many transactions to get Squid into this state? If you can
easily reproduce, I recommend filing a bug report with an ALL,9 trace of
the problematic transaction attached.

Alex.


From rousskov at measurement-factory.com  Mon Apr  9 16:18:24 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 9 Apr 2018 10:18:24 -0600
Subject: [squid-users] unique access.log for specific ACLs
In-Reply-To: <EB7F56E3C9BD2744965B09892082CA541608BA1E@ad2.istreamfs.local>
References: <EB7F56E3C9BD2744965B09892082CA541608BA1E@ad2.istreamfs.local>
Message-ID: <5d7affd5-b0b0-632a-347e-5a1027700316@measurement-factory.com>

On 04/09/2018 08:10 AM, Joey Officer wrote:
> Apologies if this has been covered before, but I could not find an
> archived discussion on the same topic.? Is it possible to assign a
> unique log file output to a specific ACL?

Yes, it is. See your own example below for a sketch.

> acl isf_blacklist dstdom_regex "/etc/squid/block.txt"
> access_log daemon:/var/log/squid/blocked.log isf_blacklist
> http_access deny isf_blacklist
> deny_info TCP_RESET isf_blacklist


However, please note that ACLs are evaluated in a particular directive
context so their evaluation results may change even within one HTTP
transaction scope. For example, a given ACL that did not match in
http_access rules may match when access_log rules are evaluated. There
was a more detailed discussion about that a few days ago:

http://lists.squid-cache.org/pipermail/squid-users/2018-April/018017.html


HTH,

Alex.


From uhlar at fantomas.sk  Mon Apr  9 17:49:15 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 9 Apr 2018 19:49:15 +0200
Subject: [squid-users] unique access.log for specific ACLs
In-Reply-To: <EB7F56E3C9BD2744965B09892082CA541608BA1E@ad2.istreamfs.local>
References: <EB7F56E3C9BD2744965B09892082CA541608BA1E@ad2.istreamfs.local>
Message-ID: <20180409174915.GA7208@fantomas.sk>

On 09.04.18 14:10, Joey Officer wrote:
>Apologies if this has been covered before, but I could not find an archived
> discussion on the same topic.  Is it possible to assign a unique log file
> output to a specific ACL?  The use case is that we've begun blocking
> certain sites and we would like to begin logging the attempted access.
>
>I'd suspect something similar to the following:
>
>(squid 3.5.12)
>#blocking
>acl isf_blacklist dstdom_regex "/etc/squid/block.txt"

note that dstdom_regex is quite infeffective (although not as much
as url_regex), since regulatrr expression matching is CPU hungry.
use dstdomain whenever possible.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Christian Science Programming: "Let God Debug It!".


From robertocarna36 at gmail.com  Mon Apr  9 19:00:21 2018
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Mon, 9 Apr 2018 16:00:21 -0300
Subject: [squid-users] Squid is very slow after moving to production
	environment
Message-ID: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>

Dear, I have implemented a server with Dansguardian 10.2.1.1 and Squid 3.5.23-5.

I've tested it with 5 users for along 2 months and always it worked OK.

But today when a moved it to production environment, it worked but
very very slow. I've just changed hostname and IP, in order to match
with the old proxy server and flush de ARP table of the firewall
(because ths server has the same IP but different MAC Address)....and
no more. And let me say that in production environment, there are
30-40 users at all, it's not a big number of users at all.

Where can I start to see in order to analyze the problem? Any idea to help me?

Thanking in advance, regards !!!

Robert


From pheriko.support at gmail.com  Mon Apr  9 19:04:57 2018
From: pheriko.support at gmail.com (Periko Support)
Date: Mon, 9 Apr 2018 12:04:57 -0700
Subject: [squid-users] Squid is very slow after moving to production
	environment
In-Reply-To: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
Message-ID: <CAK2yrTZfyiH+cdL46TQ9_75Xg1LVY0Dvq6Ur9TVJA7MAFAb+og@mail.gmail.com>

Hi, show the config file please and specs of the machine.

On Mon, Apr 9, 2018 at 12:00 PM, Roberto Carna <robertocarna36 at gmail.com> wrote:
> Dear, I have implemented a server with Dansguardian 10.2.1.1 and Squid 3.5.23-5.
>
> I've tested it with 5 users for along 2 months and always it worked OK.
>
> But today when a moved it to production environment, it worked but
> very very slow. I've just changed hostname and IP, in order to match
> with the old proxy server and flush de ARP table of the firewall
> (because ths server has the same IP but different MAC Address)....and
> no more. And let me say that in production environment, there are
> 30-40 users at all, it's not a big number of users at all.
>
> Where can I start to see in order to analyze the problem? Any idea to help me?
>
> Thanking in advance, regards !!!
>
> Robert
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From Antony.Stone at squid.open.source.it  Mon Apr  9 19:36:27 2018
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 9 Apr 2018 21:36:27 +0200
Subject: [squid-users] Squid is very slow after moving to production
	environment
In-Reply-To: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
Message-ID: <201804092136.28285.Antony.Stone@squid.open.source.it>

On Monday 09 April 2018 at 21:00:21, Roberto Carna wrote:

> Dear, I have implemented a server with Dansguardian 10.2.1.1 and Squid
> 3.5.23-5.
> 
> I've tested it with 5 users for along 2 months and always it worked OK.
> 
> But today when a moved it to production environment, it worked but
> very very slow.

1. What is "very very slow"?  What difference are you noticing:

 - limited bandwidth for downloads?

 - high latency for reaching new URLs?

 - reduced ability to handle new requests?

Basically, how are you measuring the difference between test performance and 
production performance?

2. Please explain your networking setups for the test and production 
environments:

 - do they share the same Internet connection?

 - do they both go through the same firewall?

 - do they both use the same DNS server, or have their own DNS servers, or 
what?

 - are the same traffic rules implemented for each procy on the firewall/s?

 - do you use any form of user authentication, and if so, please give details

3. What volume of requests per hour / minute / day / whatever is convenient 
did you have in the test environment, and what volume do you have now in the 
production environment?

> I've just changed hostname and IP, in order to match with the old proxy
> server and flush de ARP table of the firewall (because ths server has the same
> IP but different MAC Address)....and no more. And let me say that in
> production environment, there are 30-40 users at all, it's not a big number
> of users at all.
> 
> Where can I start to see in order to analyze the problem? Any idea to help
> me?


Regards,


Antony.

-- 
I thought I had type A blood, but it turned out to be a typo.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From robertocarna36 at gmail.com  Mon Apr  9 19:53:26 2018
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Mon, 9 Apr 2018 16:53:26 -0300
Subject: [squid-users] Squid is very slow after moving to production
	environment
In-Reply-To: <CAK2yrTZfyiH+cdL46TQ9_75Xg1LVY0Dvq6Ur9TVJA7MAFAb+og@mail.gmail.com>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <CAK2yrTZfyiH+cdL46TQ9_75Xg1LVY0Dvq6Ur9TVJA7MAFAb+og@mail.gmail.com>
Message-ID: <CAG2Qp6tx87wEnfU4q3mtG_Oy+jg6bdnvNxxAeoLcZ_BWsqfqdQ@mail.gmail.com>

Dear Periko, so here is what you ask to me:

CPU x 8
RAM x 12 GB
HD x 50 GB

And this is /etc/squid/squid.conf file:

acl SSL_ports port 443
acl Safe_ports port 80        # http
acl Safe_ports port 21        # ftp
acl Safe_ports port 443        # https
acl Safe_ports port 70        # gopher
acl Safe_ports port 210        # wais
acl Safe_ports port 1025-65535    # unregistered ports
acl Safe_ports port 280        # http-mgmt
acl Safe_ports port 488        # gss-http
acl Safe_ports port 591        # filemaker
acl Safe_ports port 777        # multiling http
acl CONNECT method CONNECT
coredump_dir /var/spool/squid
refresh_pattern ^ftp:        1440    20%    10080
refresh_pattern ^gopher:    1440    0%    1440
refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
refresh_pattern .        0    20%    4320
http_port localhost:3128
cache_mem 4096 MB
maximum_object_size_in_memory 4096 KB
cache_replacement_policy heap LFUDA
memory_replacement_policy lru
maximum_object_size 10 MB
cache_dir aufs /var/spool/squid 25000 16 256
cache_swap_low 90
cache_swap_high 95
access_log /var/log/squid/access.log squid
access_log syslog:local7.info
cache_log /var/log/squid/cache.log
cache_store_log /var/log/squid/store.log
store_dir_select_algorithm least-load
positive_dns_ttl 8 hours
negative_dns_ttl 30 seconds
ipcache_size 4096
ipcache_low 90
ipcache_high 95
ftp_passive on
ftp_epsv off
fqdncache_size 4096
cache_effective_user proxy
cache_effective_group proxy
httpd_suppress_version_string on
visible_hostname proxy.company.com.ar
via off
hosts_file /etc/hosts
ignore_unknown_nameservers on
request_header_max_size 64 KB
icp_port 0
htcp_port 0
icp_access deny all
htcp_access deny all
acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl netadmin src 10.8.6.3/32
http_access allow manager localhost
http_access allow manager netadmin
http_access deny manager
auth_param basic program /usr/lib/squid/squid_ldap_auth -b
"dc=company,dc=com,dc=ar" -f "uid=%s" -h ldap.company.com.ar -v 3
auth_param basic children 5
auth_param basic realm COMPANY
auth_param basic credentialsttl 4 hours
auth_param basic casesensitive on
acl LDAP proxy_auth REQUIRED
http_access allow LDAP
http_access deny all
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1
acl SSL_ports port 443
acl Safe_ports port 80        # http
acl Safe_ports port 21        # ftp
acl Safe_ports port 443        # https
acl CONNECT method CONNECT
http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny to_localhost
http_access allow localhost
acl QUERY urlpath_regex cgi-bin \? \.css \.asp \.aspx
cache deny QUERY
acl gedo dstdomain .gde.gob.ar
always_direct allow gedo
acl GOB url_regex .com.ar
http_access allow GOB
acl NOFLASH urlpath_regex .+\.swf$
http_access deny NOFLASH
http_access deny all

I've just changed the new proxy to test environment and it works very
well again....I get lost.

Thanks a lot !!!

2018-04-09 16:04 GMT-03:00 Periko Support <pheriko.support at gmail.com>:
> Hi, show the config file please and specs of the machine.
>
> On Mon, Apr 9, 2018 at 12:00 PM, Roberto Carna <robertocarna36 at gmail.com> wrote:
>> Dear, I have implemented a server with Dansguardian 10.2.1.1 and Squid 3.5.23-5.
>>
>> I've tested it with 5 users for along 2 months and always it worked OK.
>>
>> But today when a moved it to production environment, it worked but
>> very very slow. I've just changed hostname and IP, in order to match
>> with the old proxy server and flush de ARP table of the firewall
>> (because ths server has the same IP but different MAC Address)....and
>> no more. And let me say that in production environment, there are
>> 30-40 users at all, it's not a big number of users at all.
>>
>> Where can I start to see in order to analyze the problem? Any idea to help me?
>>
>> Thanking in advance, regards !!!
>>
>> Robert
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From robertocarna36 at gmail.com  Mon Apr  9 19:58:52 2018
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Mon, 9 Apr 2018 16:58:52 -0300
Subject: [squid-users] Squid is very slow after moving to production
	environment
In-Reply-To: <201804092136.28285.Antony.Stone@squid.open.source.it>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <201804092136.28285.Antony.Stone@squid.open.source.it>
Message-ID: <CAG2Qp6vLdYnDdP6Yp25d=jWdJ_ue1j4PCtok2p+hhOBo21shyA@mail.gmail.com>

Dear Antony, both proxies are virtual machines in the same DMZ....they
use the same DNS, the same firewall, the same Internet link, the same
IP but different MAC Address.

Firewall rules are the same too.

The new proxy is slow because when users try to go to a web page, it
is very slow in download the content page.....about 1 minute to do it.

The Dansguardian configuration is te same too.

I've past my configuration in the previous mail.

Thanks a lot !!!



2018-04-09 16:36 GMT-03:00 Antony Stone <Antony.Stone at squid.open.source.it>:
> On Monday 09 April 2018 at 21:00:21, Roberto Carna wrote:
>
>> Dear, I have implemented a server with Dansguardian 10.2.1.1 and Squid
>> 3.5.23-5.
>>
>> I've tested it with 5 users for along 2 months and always it worked OK.
>>
>> But today when a moved it to production environment, it worked but
>> very very slow.
>
> 1. What is "very very slow"?  What difference are you noticing:
>
>  - limited bandwidth for downloads?
>
>  - high latency for reaching new URLs?
>
>  - reduced ability to handle new requests?
>
> Basically, how are you measuring the difference between test performance and
> production performance?
>
> 2. Please explain your networking setups for the test and production
> environments:
>
>  - do they share the same Internet connection?
>
>  - do they both go through the same firewall?
>
>  - do they both use the same DNS server, or have their own DNS servers, or
> what?
>
>  - are the same traffic rules implemented for each procy on the firewall/s?
>
>  - do you use any form of user authentication, and if so, please give details
>
> 3. What volume of requests per hour / minute / day / whatever is convenient
> did you have in the test environment, and what volume do you have now in the
> production environment?
>
>> I've just changed hostname and IP, in order to match with the old proxy
>> server and flush de ARP table of the firewall (because ths server has the same
>> IP but different MAC Address)....and no more. And let me say that in
>> production environment, there are 30-40 users at all, it's not a big number
>> of users at all.
>>
>> Where can I start to see in order to analyze the problem? Any idea to help
>> me?
>
>
> Regards,
>
>
> Antony.
>
> --
> I thought I had type A blood, but it turned out to be a typo.
>
>                                                    Please reply to the list;
>                                                          please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From Antony.Stone at squid.open.source.it  Mon Apr  9 20:05:24 2018
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 9 Apr 2018 22:05:24 +0200
Subject: [squid-users] Squid is very slow after moving to production
	environment
In-Reply-To: <CAG2Qp6vLdYnDdP6Yp25d=jWdJ_ue1j4PCtok2p+hhOBo21shyA@mail.gmail.com>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <201804092136.28285.Antony.Stone@squid.open.source.it>
 <CAG2Qp6vLdYnDdP6Yp25d=jWdJ_ue1j4PCtok2p+hhOBo21shyA@mail.gmail.com>
Message-ID: <201804092205.24308.Antony.Stone@squid.open.source.it>

On Monday 09 April 2018 at 21:58:52, Roberto Carna wrote:

> Dear Antony, both proxies are virtual machines in the same DMZ....they
> use the same DNS, the same firewall, the same Internet link, the same
> IP but different MAC Address.

So, what is different between "test" and "production"?


Antony.

-- 
"Remember: the S in IoT stands for Security."

 - Jan-Piet Mens

                                                   Please reply to the list;
                                                         please *don't* CC me.


From Antony.Stone at squid.open.source.it  Mon Apr  9 20:06:53 2018
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 9 Apr 2018 22:06:53 +0200
Subject: [squid-users] Squid is very slow after moving to production
	environment
In-Reply-To: <CAG2Qp6tx87wEnfU4q3mtG_Oy+jg6bdnvNxxAeoLcZ_BWsqfqdQ@mail.gmail.com>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <CAK2yrTZfyiH+cdL46TQ9_75Xg1LVY0Dvq6Ur9TVJA7MAFAb+og@mail.gmail.com>
 <CAG2Qp6tx87wEnfU4q3mtG_Oy+jg6bdnvNxxAeoLcZ_BWsqfqdQ@mail.gmail.com>
Message-ID: <201804092206.53821.Antony.Stone@squid.open.source.it>

On Monday 09 April 2018 at 21:53:26, Roberto Carna wrote:

> I've just changed the new proxy to test environment and it works very
> well again....I get lost.

What does that change involve?  I'm trying to understand what is different 
between your "test" environment and your "production" environment, especially 
since you say they both have the same IP address.


Antony.

-- 
A user interface is like a joke.
If you have to explain it, it means it doesn't work.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From pheriko.support at gmail.com  Mon Apr  9 20:09:03 2018
From: pheriko.support at gmail.com (Periko Support)
Date: Mon, 9 Apr 2018 13:09:03 -0700
Subject: [squid-users] Squid is very slow after moving to production
	environment
In-Reply-To: <201804092205.24308.Antony.Stone@squid.open.source.it>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <201804092136.28285.Antony.Stone@squid.open.source.it>
 <CAG2Qp6vLdYnDdP6Yp25d=jWdJ_ue1j4PCtok2p+hhOBo21shyA@mail.gmail.com>
 <201804092205.24308.Antony.Stone@squid.open.source.it>
Message-ID: <CAK2yrTbB6FE1jUrt2eQYrmJRWkKmQdesjJf1dj2zEzvcZEiCRg@mail.gmail.com>

Try to add this setting:

dns_v4_first on

Latter check settings and see if there is no issue with the setting.

squid -k parse.

Then reload:

squid -k reconfigure

Test.


On Mon, Apr 9, 2018 at 1:05 PM, Antony Stone
<Antony.Stone at squid.open.source.it> wrote:
> On Monday 09 April 2018 at 21:58:52, Roberto Carna wrote:
>
>> Dear Antony, both proxies are virtual machines in the same DMZ....they
>> use the same DNS, the same firewall, the same Internet link, the same
>> IP but different MAC Address.
>
> So, what is different between "test" and "production"?
>
>
> Antony.
>
> --
> "Remember: the S in IoT stands for Security."
>
>  - Jan-Piet Mens
>
>                                                    Please reply to the list;
>                                                          please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From rafael.akchurin at diladele.com  Mon Apr  9 20:10:07 2018
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Mon, 9 Apr 2018 20:10:07 +0000
Subject: [squid-users] Squid is very slow after moving to
	production	environment
In-Reply-To: <CAG2Qp6vLdYnDdP6Yp25d=jWdJ_ue1j4PCtok2p+hhOBo21shyA@mail.gmail.com>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <201804092136.28285.Antony.Stone@squid.open.source.it>
 <CAG2Qp6vLdYnDdP6Yp25d=jWdJ_ue1j4PCtok2p+hhOBo21shyA@mail.gmail.com>
Message-ID: <HE1PR04MB1148229664D2CD27C5FA2CA28FBF0@HE1PR04MB1148.eurprd04.prod.outlook.com>

Hello Roberto,

When Squid is "slow" like users complain first thing to check is always the DNS settings.
Also sometimes switching to "IPv4 DNS resolve first" helps.

Look for "squidclient mgr:idns" and "dns_v4_first on" on Squid wiki.

Hope others have better answers.

Best regards,
Rafael Akchurin
Diladele B.V.

https://www.diladele.com/


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Roberto Carna
Sent: Monday, April 9, 2018 9:59 PM
To: Antony Stone <Antony.Stone at squid.open.source.it>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid is very slow after moving to production environment

Dear Antony, both proxies are virtual machines in the same DMZ....they use the same DNS, the same firewall, the same Internet link, the same IP but different MAC Address.

Firewall rules are the same too.

The new proxy is slow because when users try to go to a web page, it is very slow in download the content page.....about 1 minute to do it.

The Dansguardian configuration is te same too.

I've past my configuration in the previous mail.

Thanks a lot !!!



2018-04-09 16:36 GMT-03:00 Antony Stone <Antony.Stone at squid.open.source.it>:
> On Monday 09 April 2018 at 21:00:21, Roberto Carna wrote:
>
>> Dear, I have implemented a server with Dansguardian 10.2.1.1 and 
>> Squid 3.5.23-5.
>>
>> I've tested it with 5 users for along 2 months and always it worked OK.
>>
>> But today when a moved it to production environment, it worked but 
>> very very slow.
>
> 1. What is "very very slow"?  What difference are you noticing:
>
>  - limited bandwidth for downloads?
>
>  - high latency for reaching new URLs?
>
>  - reduced ability to handle new requests?
>
> Basically, how are you measuring the difference between test 
> performance and production performance?
>
> 2. Please explain your networking setups for the test and production
> environments:
>
>  - do they share the same Internet connection?
>
>  - do they both go through the same firewall?
>
>  - do they both use the same DNS server, or have their own DNS 
> servers, or what?
>
>  - are the same traffic rules implemented for each procy on the firewall/s?
>
>  - do you use any form of user authentication, and if so, please give 
> details
>
> 3. What volume of requests per hour / minute / day / whatever is 
> convenient did you have in the test environment, and what volume do 
> you have now in the production environment?
>
>> I've just changed hostname and IP, in order to match with the old 
>> proxy server and flush de ARP table of the firewall (because ths 
>> server has the same IP but different MAC Address)....and no more. And 
>> let me say that in production environment, there are 30-40 users at 
>> all, it's not a big number of users at all.
>>
>> Where can I start to see in order to analyze the problem? Any idea to 
>> help me?
>
>
> Regards,
>
>
> Antony.
>
> --
> I thought I had type A blood, but it turned out to be a typo.
>
>                                                    Please reply to the list;
>                                                          please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From eliezer at ngtech.co.il  Tue Apr 10 01:30:05 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 10 Apr 2018 04:30:05 +0300
Subject: [squid-users] Proxy through another proxy possible?
In-Reply-To: <6df9c042-4178-c44c-51ff-01772ef69f26@treenet.co.nz>
References: <66bc30d9-ffad-6752-54a7-a750076fcbf0@gmail.com>
 <14d88b13-c63c-ba42-f95d-91688ebe7b6c@treenet.co.nz>
 <8cea970b-e5af-86e0-a87c-401cca289931@gmail.com>
 <6df9c042-4178-c44c-51ff-01772ef69f26@treenet.co.nz>
Message-ID: <00fa01d3d06b$7fe134e0$7fa39ea0$@ngtech.co.il>

Hey Amos,

Would a PROXY protocol based "router" or "load balancer" be fine also?
I tested the PROXY protocol v1 against squid v3.5 at the time and It was working very well.
I believe that if the requirement is to be able to route specific clients to a specific proxy it should  be or might be done with as lowest CPU as possible.
It will however change for the case when the local proxy also needs to process specific traffic.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Saturday, April 7, 2018 09:31
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Proxy through another proxy possible?

On 07/04/18 18:02, xpro wrote:
> Would it be done like below?
> 
> http_port 3001
> acl port1 myport 3001
> tcp_outgoing_address myotherproxy.com:3114 port1
> 
> 
> I want anyone connecting to my proxy using port 3001, to use the the
> proxy server on myotherproxy.com:3114

No. tcp_outgoing_address is the IP your Squid uses on its outgoing TCP
connections.

cache_peer is for configuring destination details about any specific
peer (upstream server or proxy) to relay messages through.
 see <https://wiki.squid-cache.org/Features/CacheHierarchy>

Amos


> 
> 
> On 04/07/2018 01:05 AM, Amos Jeffries wrote:
>> On 07/04/18 11:34, xpro wrote:
>>> I'm not sure if Squid is the right tool for this. I'm trying to achieve
>>> the following.
>>>
>>> I would have access to some exclusive proxies, but I would like for a
>>> limited amount of people to use these proxies without getting the
>>> original proxy IP. I want them to go through my proxy server and then my
>>> proxy server would forward them to the proxy I use.
>>>
>>>
>>> Would this be possible with Squid?
>> Of course. I'm not exactly clear on what you mean by original or
>> exclusive proxies, but HTTP and Squid are certainly able to chain.
>>
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From jun357572957zhao at hotmail.com  Tue Apr 10 06:11:08 2018
From: jun357572957zhao at hotmail.com (=?gb2312?B?1dQgv6E=?=)
Date: Tue, 10 Apr 2018 06:11:08 +0000
Subject: [squid-users] How to configure Icap can improve the performance of
	proxy?
Message-ID: <CY4PR22MB036051541C2DFEAD6020498E98BE0@CY4PR22MB0360.namprd22.prod.outlook.com>

My Squid  with configuration of Icap like this:


 #icap
icap_enable on
icap_preview_enable on
icap_preview_size 1024
icap_send_client_ip on
adaptation_meta X-Client-Port "%>p"
icap_206_enable on
icap_persistent_connections off


icap_service service_req reqmod_precache 0 icap://192.168.10.200:1344/echo
icap_service service_res respmod_precache 1 icap://192.168.10.200:1344/echo
adaptation_access service_res allow all
adaptation_access service_req allow all


When I configured the Icap parameter of Squid , the number of new connection or the number of concurrent connections  was less than half as only Squid running.
So how to configure Icap can improve the performance of proxy?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180410/78581dc4/attachment.htm>

From squid3 at treenet.co.nz  Tue Apr 10 08:27:14 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Apr 2018 20:27:14 +1200
Subject: [squid-users] squid-users Digest, Vol 44, Issue 8
In-Reply-To: <CAAvX7kNmpE=n87cYkUwour2L85AgHxCAjANN6_LQshBgzSHy0g@mail.gmail.com>
References: <mailman.3.1523188802.17601.squid-users@lists.squid-cache.org>
 <CAAvX7kNmpE=n87cYkUwour2L85AgHxCAjANN6_LQshBgzSHy0g@mail.gmail.com>
Message-ID: <b1d3aa9b-5c0e-839b-2226-31f38ff0a254@treenet.co.nz>

On 09/04/18 00:48, kalice caprice wrote:
>> 1) It is only possible to set an IPv6 outgoing when the server being
>> connected to is an IPv6 server address.
> 
> It doesn't matter for me, It is just a way to get a different outbound
> IPv6 address depending on which port the connection is made to, and both
> clients and servers has IPv6.
> I saw a few threads here asking for more or less the same thing except
> that I'm specifying the full address instead of implicit addressing to
> the outbound, this is where I'm stuck.
> >> 2) It is only possible for Squid to use an IP address which has been
>> allocated/assigned to the NIC.
> 
> The NIC is a network card if I understood it right.

Yes.

> The IPv6 /64 subnet
> is added to the main interface and the gateway is aswell, IPv6 is fully
> working on the server.

The individual IP address being used in tcp_outgoing_address by Squid
has to be assigned to the machine before it can generate any packets
from it. That goes for both IPv4 and IPv6.

If it is unassigned or assigned by another machine you get major
problems with packet delivery.

The config you had initially should work okay for IPv6 provided the
Squid machine has been assigned those *:8336, *:b369, and *:5fe0:eba8
addresses.


Amos


From squid3 at treenet.co.nz  Tue Apr 10 08:50:55 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Apr 2018 20:50:55 +1200
Subject: [squid-users] Proxy through another proxy possible?
In-Reply-To: <00fa01d3d06b$7fe134e0$7fa39ea0$@ngtech.co.il>
References: <66bc30d9-ffad-6752-54a7-a750076fcbf0@gmail.com>
 <14d88b13-c63c-ba42-f95d-91688ebe7b6c@treenet.co.nz>
 <8cea970b-e5af-86e0-a87c-401cca289931@gmail.com>
 <6df9c042-4178-c44c-51ff-01772ef69f26@treenet.co.nz>
 <00fa01d3d06b$7fe134e0$7fa39ea0$@ngtech.co.il>
Message-ID: <05fe0e57-89fc-3ef9-6aa0-ff61d8b8f422@treenet.co.nz>

On 10/04/18 13:30, Eliezer Croitoru wrote:
> Hey Amos,
> 
> Would a PROXY protocol based "router" or "load balancer" be fine also?

Anything that acts like a S-NAT would do.

Amos


From squid3 at treenet.co.nz  Tue Apr 10 09:17:32 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Apr 2018 21:17:32 +1200
Subject: [squid-users] How to configure Icap can improve the performance
 of proxy?
In-Reply-To: <CY4PR22MB036051541C2DFEAD6020498E98BE0@CY4PR22MB0360.namprd22.prod.outlook.com>
References: <CY4PR22MB036051541C2DFEAD6020498E98BE0@CY4PR22MB0360.namprd22.prod.outlook.com>
Message-ID: <12a2d52b-fffa-6bb6-d61f-41b3af9508e7@treenet.co.nz>

On 10/04/18 18:11, ? ? wrote:
> My Squid? with configuration of Icap like this:
> 
> 
> ?#icap
> icap_enable on
> icap_preview_enable on
> icap_preview_size 1024
> icap_send_client_ip on
> adaptation_meta X-Client-Port "%>p"
> icap_206_enable on
> icap_persistent_connections off
> 
> 
> icap_service service_req reqmod_precache 0 icap://192.168.10.200:1344/echo
> icap_service service_res respmod_precache 1 icap://192.168.10.200:1344/echo
> adaptation_access service_res allow all
> adaptation_access service_req allow all
> 
> 
> When I configured the Icap parameter of Squid , the number of new
> connection or the number of concurrent connections? was less than half
> as only Squid running.
> So how to configure Icap can improve the performance of proxy?

You cannot improve it much in that aspect. ICAP is a networking protocol
for sending HTTP traffic to an external service. It uses ports and
network connections to do that.

AFAIK the best efficiency it can do is just under x2 the amount a normal
Squid uses - every inbound client connection uses +1 REQMOD socket and
every outbound server connection adds +1 RESPMOD socket. Even with
pipelining/persistence and caching that is not changed.


eCAP modules do not use the extra network resources. But whether you can
go that way depends on what you are needing it to do.

Amos


From squid3 at treenet.co.nz  Tue Apr 10 10:09:08 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Apr 2018 22:09:08 +1200
Subject: [squid-users] Squid is very slow after moving to production
 environment
In-Reply-To: <CAG2Qp6vLdYnDdP6Yp25d=jWdJ_ue1j4PCtok2p+hhOBo21shyA@mail.gmail.com>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <201804092136.28285.Antony.Stone@squid.open.source.it>
 <CAG2Qp6vLdYnDdP6Yp25d=jWdJ_ue1j4PCtok2p+hhOBo21shyA@mail.gmail.com>
Message-ID: <5cecf7cd-51b4-7caa-1147-5c3c56c5e82e@treenet.co.nz>

On 10/04/18 07:58, Roberto Carna wrote:
> Dear Antony, both proxies are virtual machines in the same DMZ....they
> use the same DNS, the same firewall, the same Internet link, the same
> IP but different MAC Address.


FYI: there were issues some years back with VMs that were cloned
operating VERY much slower for no apparent reason than the original
image they were cloned from.

If you are making production as a clone of the testing you may want to
try a non-clone to see if the problem disappears.

Amos


From omidkosari at yahoo.com  Tue Apr 10 10:32:29 2018
From: omidkosari at yahoo.com (Omid Kosari)
Date: Tue, 10 Apr 2018 03:32:29 -0700 (MST)
Subject: [squid-users] Ideas for better caching these popular urls
Message-ID: <1523356349608-0.post@n4.nabble.com>

Hello,

squid-top-domains.JPG
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t93386/squid-top-domains.JPG>  

This image shows stats from one of my squid boxes . I have question about
highlighted ones . I think they should have better hit ratio because they
are popular between clients .
I have checked a lot of things like calamaris and logs , played with
refresh_pattern , storeid rules etc .

I want gurus and community to please help for better HITs .

Also i am ready to share specific parts of access.log and others if
requested .

Thanks



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Tue Apr 10 10:43:47 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Apr 2018 22:43:47 +1200
Subject: [squid-users] Ideas for better caching these popular urls
In-Reply-To: <1523356349608-0.post@n4.nabble.com>
References: <1523356349608-0.post@n4.nabble.com>
Message-ID: <f24e1fe3-2fb4-966a-7540-78fc1d237cfa@treenet.co.nz>

On 10/04/18 22:32, Omid Kosari wrote:
> Hello,
> 
> squid-top-domains.JPG
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t93386/squid-top-domains.JPG>  
> 
> This image shows stats from one of my squid boxes . I have question about
> highlighted ones . I think they should have better hit ratio because they
> are popular between clients .

There are no URLs in that image. There are only wildcards for top-level
domains and a HIT % over the *entire* domain.

To figure out whether any of them should actually have better HIT ratios
you have to look at the actual URLs and see how much uniqueness exists
there.

Then for the _full_ URLs (scheme, domain, path, *and* ?query portions)
which are not very unique look at the response headers to see why they
are not caching well. The tool at redbot.org can help with that last part.

Amos


From skupko.sk at gmail.com  Tue Apr 10 11:01:41 2018
From: skupko.sk at gmail.com (Peter Viskup)
Date: Tue, 10 Apr 2018 13:01:41 +0200
Subject: [squid-users] Squid4 ICAP connection handling
In-Reply-To: <de74bbad-d17a-df05-687a-251d539dd5de@measurement-factory.com>
References: <CAPa6PsEne7QzBBRN2LEt9_q-2sE04sb5K68wcMgyt+CffZpvcQ@mail.gmail.com>
 <de74bbad-d17a-df05-687a-251d539dd5de@measurement-factory.com>
Message-ID: <CAPa6PsEefpuhOF0OQruwhYGrrzprtD6jKjnZ8X0O9JZMjaUDgw@mail.gmail.com>

On Mon, Apr 9, 2018 at 4:43 PM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:
> On 04/09/2018 06:03 AM, Peter Viskup wrote:
>> Running Squid 4.0.23 the ICAP connections getting "frozen".
>>
>> proxy:~ $ netstat -ntpa| grep 40620
>> tcp   920144      0 127.0.0.1:40620         127.0.0.1:1344
>> ESTABLISHED 1165/(squid-1)
>> tcp        0 2744857 127.0.0.1:1344          127.0.0.1:40620
>> ESTABLISHED 1211/esets_icap
>>
>> # after ICAP service restart
>> proxy:~ $ netstat -ntpa| grep 40620
>> tcp   920144      0 127.0.0.1:40620         127.0.0.1:1344
>> ESTABLISHED 1165/(squid-1)
>> tcp        0 2744858 127.0.0.1:1344          127.0.0.1:40620
>> FIN_WAIT1   -
>>
>> # later on - squid still keep the connection open
>> proxy:~ $ netstat -ntpa| grep 40620
>> tcp   920144      0 127.0.0.1:40620         127.0.0.1:1344
>> ESTABLISHED 1165/(squid-1)
>
>> How the ICAP connections are handled?
>
> Is there an HTTP transaction associated with (e.g., waiting for) that
> stuck ICAP connection?

Not found the HTTP transaction associated with.

> Can you reproduce this problem with a single HTTP transaction? Or does
> it take many transactions to get Squid into this state? If you can
> easily reproduce, I recommend filing a bug report with an ALL,9 trace of
> the problematic transaction attached.

I can easily reproduce. Will search for the HTTP transaction, but not sure
whether I would be able to trace it.

More information in:
https://bugs.squid-cache.org/show_bug.cgi?id=4844
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180410/49d0a5db/attachment.htm>

From omidkosari at yahoo.com  Tue Apr 10 11:19:36 2018
From: omidkosari at yahoo.com (Omid Kosari)
Date: Tue, 10 Apr 2018 04:19:36 -0700 (MST)
Subject: [squid-users] Ideas for better caching these popular urls
In-Reply-To: <f24e1fe3-2fb4-966a-7540-78fc1d237cfa@treenet.co.nz>
References: <1523356349608-0.post@n4.nabble.com>
 <f24e1fe3-2fb4-966a-7540-78fc1d237cfa@treenet.co.nz>
Message-ID: <1523359176495-0.post@n4.nabble.com>

Thanks for reply . 

I assumed the community at different scales from little isp to large ISPs
may have common domains like those i highlighted so they may have same issue
as mine . So i ignored common parts .

One of problems with redbot is it shows timeout for big files like 

http://gs2.ww.prod.dl.playstation.net/gs2/appkgo/prod/CUSA00900_00/2/f_2df8e321f37e2f5ea3930f6af4e9571144916013ee38893d881890b454b5fed6/f/UP9000-CUSA00900_00-BLOODBORNE000000_4.pkg?downloadId=00000187&du=000000000000018700e2291bda0f868f&country=us&downloadType=ob&q=aa2cd9c8d1f359feb843ae4a6c99cfcdb6569ca9cc60ad6d28b6f8de3b5fac23&threadId=0&serverIpAddr=23.57.69.81&r=00000027

http://gs2.ww.prod.dl.playstation.net/gs2/ppkgo/prod/CUSA07557_00/25/f_053bab8c9dec6fbc68a0bd9fc58793285ae350ccf7dadacb35b5840228a9d802/f/EP4001-CUSA07557_00-F12017EMASTER000-A0113-V0100_0.pkg?downloadId=00000059&du=000000000000005900e22977e62f91a2&downloadType=ob&product=0183&serverIpAddr=8.248.5.254&r=00000032


I assumed anyone with few thousand of users may have same problem and maybe
they like to share for example their refresh_pattern or storeid to solve my
problem . You better know that playstation is everywhere playstation ;)

Here is part of storeid_db file
^http:\/\/.*\.sonycoment\.loris-e\.llnwd\.net\/(.*?\.pkg)
http://playstation.net.squidinternal/$1
^http:\/\/.*\.playstation\.net\/(.*?\.pkg)
http://playstation.net.squidinternal/$1

Almost all of the playstation huge downloads are with 206 code but it will
download the file from start to end , if i remember correctly in this
situation squid will correctly cache the file .



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From akismpa at gmail.com  Tue Apr 10 12:31:55 2018
From: akismpa at gmail.com (Panagiotis Bariamis)
Date: Tue, 10 Apr 2018 15:31:55 +0300
Subject: [squid-users] Secure Web Proxy Stress Testing
Message-ID: <CAPxN_PVjJ+QKxLYU=rRJa00Mec80TWqqvF5WNJrD0-b7+-jesQ@mail.gmail.com>

Hello ,
I am trying to stress test a squid proxy (Secure Web Proxy , meaning that
client to proxy connection is encrypted ) .
I tried with Jmeter but it does not support Secure Web Proxy .
To make thing clear I use squid with option https_port and clients get the
config from a pac file that states return "HTTPS https://xxxxxxxx:3128";
Is there any stress testing tool to test with a load of 1k to 5k
simultaneous connections ?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180410/247e726e/attachment.htm>

From adamw at matrixscience.com  Tue Apr 10 14:07:35 2018
From: adamw at matrixscience.com (Adam Weremczuk)
Date: Tue, 10 Apr 2018 15:07:35 +0100
Subject: [squid-users] https proxy authentication
In-Reply-To: <93199834-4908-fc81-af85-79f017539112@treenet.co.nz>
References: <1de18b37-385c-e20f-7feb-432fd403bcdf@matrixscience.com>
 <93199834-4908-fc81-af85-79f017539112@treenet.co.nz>
Message-ID: <742f8b56-657f-8aae-5d6a-172e86d88818@matrixscience.com>

Hi Amos,


On 30/03/18 02:44, Amos Jeffries wrote:
> So, the big question is why you have this setup of Apache being a
> reverse-proxy for a Squid forward-proxy?
>
> Forward-proxy are supposed to be between clients and reverse-proxies or
> origins. Not the other way around.
This is a set up I inherited with not much being documented.
I think the purpose was to split the functionality as below:
- direct unauthenticated proxy for every day usage ("proxy")
- hopping through Apache which provides http authentication for sporadic 
testing use only ("aproxy")
> What are you actually trying to achieve here?
The big picture is we need to test some code against various proxy 
scenarios (http, https, authenticated, unauthenticated).
ATM we only have http authentication.
I would imagine real live proxy setups use encrypted https for 
authentication more often than plain text http.
Am I correct with my assumption?

If that's the case then my goal is to get https authentication working 
as well.
If there is no way I can easily get it to work with the existing config 
I guess I can set up a new Apache hop.
Authenticating over https only and called e.g. "bproxy".
Would that make most sense?

Thanks
Adam


From skupko.sk at gmail.com  Tue Apr 10 14:14:44 2018
From: skupko.sk at gmail.com (Peter Viskup)
Date: Tue, 10 Apr 2018 16:14:44 +0200
Subject: [squid-users] Squid ipcache and DNS TTL smaller than 60 seconds
Message-ID: <CAPa6PsGk30OKN8SML6QVow152Yp_MHkBoOH5vUWV88pXLqsz9Q@mail.gmail.com>

Squid use TTL of 60 seconds for DNS resource records with TTL smaller than
that value.

Some sites can have DNS TTL set to lower value due to high availability
design (DNS load balancer).

In RFCs [1][2][3] it is explained the received TTL can be lowered to the
upper bound TTL value of DNS cache, but not to increase it.

Is it possible to change that 60 seconds default somewhere in
configuration? Was the 60 seconds default chosen according some reference?

[1] https://tools.ietf.org/html/rfc2181#section-8
<https://tools.ietf.org/html/rfc2181#section-8>
[2] https://tools.ietf.org/html/rfc1035#section-3.2.1
<https://tools.ietf.org/html/rfc1035#section-3.2.1>
[3] https://tools.ietf.org/html/rfc7719#section-4
<https://tools.ietf.org/html/rfc1035#section-3.2.1>

Peter
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180410/5d87d7cb/attachment.htm>

From rousskov at measurement-factory.com  Tue Apr 10 14:22:15 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 10 Apr 2018 08:22:15 -0600
Subject: [squid-users] Secure Web Proxy Stress Testing
In-Reply-To: <CAPxN_PVjJ+QKxLYU=rRJa00Mec80TWqqvF5WNJrD0-b7+-jesQ@mail.gmail.com>
References: <CAPxN_PVjJ+QKxLYU=rRJa00Mec80TWqqvF5WNJrD0-b7+-jesQ@mail.gmail.com>
Message-ID: <3e2af5d3-8292-c509-7a3c-7879032864b8@measurement-factory.com>

On 04/10/2018 06:31 AM, Panagiotis Bariamis wrote:
> Is there any stress testing tool to test with a load of 1k to 5k
> simultaneous connections ?

Web Polygraph (www.web-polygraph.org) supports HTTPS proxies and can
create thousands of concurrent connections. Below is a PGL configuration
snippet from a recent HTTPS proxy test in our lab.

HTH,

Alex.


SslWrap sslWrap = {
    ssl_config_file = "openssl.conf";
    root_certificate = "CA-priv+pub.pem";
    session_resumption = 70%;
    session_cache = 100;
};

Server S = {
    // no ssl_wraps here unless you want to test TLS inside TLS
    ...
};

Proxy P = {
    addresses = [ ... HTTPS proxy address ... ];
    ssl_wraps = [ sslWrap ]; // this is an HTTPS proxy
};

Robot R = {
    ssl_wraps = [ sslWrap ]; // an HTTPS-capable client

    origins = S.addresses;
    http_proxies = P.addresses;

    ...
};

use(S,P,R);


From squid3 at treenet.co.nz  Tue Apr 10 15:19:35 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Apr 2018 03:19:35 +1200
Subject: [squid-users] Squid ipcache and DNS TTL smaller than 60 seconds
In-Reply-To: <CAPa6PsGk30OKN8SML6QVow152Yp_MHkBoOH5vUWV88pXLqsz9Q@mail.gmail.com>
References: <CAPa6PsGk30OKN8SML6QVow152Yp_MHkBoOH5vUWV88pXLqsz9Q@mail.gmail.com>
Message-ID: <8aa3ffd6-0bfc-d0c9-08d4-d87fa980fc50@treenet.co.nz>


On 11/04/18 02:14, Peter Viskup wrote:
> Squid use TTL of 60 seconds for DNS resource records with TTL smaller
> than that value.
> 
> Some sites can have DNS TTL set to lower value due to high availability
> design (DNS load balancer).
> 
> In RFCs [1][2][3] it is explained the received TTL can be lowered to the
> upper bound TTL value of DNS cache, but not to increase it.
> 
> Is it possible to change that 60 seconds default somewhere in
> configuration? Was the 60 seconds default chosen according some reference?
> 

<http://www.squid-cache.org/Doc/config/negative_dns_ttl/>

Please note that Best Practice for DNS records is to use *24 hour* TTLs
as the minimum. Shorter times are provided to allow for clean server
migrations, not for load balancing. RRset rotation is for DNS load
balancing, is enabled in most resolvers by default and does not require
short TTLs to operate. It is also compatible with the behaviour of load
balancing mechanisms in every protocol from TCP itself up the stack (ie
they are designed to account for rotation, not for widespread abusive TTLs).


Since you ask;

One reason Squid sets a minimum is that extremely short TTLs in DNS
conflicts directly with both HTTP persistence mechanisms and the load
balancing performed by Squid itself. The default ensures that for any
given server IP Squid can re-use persistent connections to it for ~60
seconds.

NP: These services are actually *worsening* their service times. Squid
and numerous other middleware now has to ignore already setup and
perfectly usable connections in order to perform several entire TCP (and
TLS) handshake processes all over again for the changed IPs.


Another (which no longer applies) was that Squid used to base each new
retry attempt on new DNS record lookup. If the RRset changed on every
retry it could end up trying the same IP from a large set N times in a
row and failing when a different IP from the same RRset would be fine.
 Current Squid do a single lookup and only retry the IPs found there
(think about what that means for TTL). This was explicitly to workaround
and counter the breakages caused by those servers you mention doing
short TTLs.

Consider, what would you expect to happen when DNS RRset changes
_multiple_ times within the same TTL that TCP uses for a SYN-ACK timeout
and retry?



> [1] https://tools.ietf.org/html/rfc2181#section-8
> <https://tools.ietf.org/html/rfc2181#section-8>
> [2] https://tools.ietf.org/html/rfc1035#section-3.2.1
> <https://tools.ietf.org/html/rfc1035#section-3.2.1>
> [3] https://tools.ietf.org/html/rfc7719#section-4
> <https://tools.ietf.org/html/rfc1035#section-3.2.1>

Which states:
 "Some servers are known to ignore the TTL on some RRsets (such as when
the authoritative data has a very short TTL)".

Amos


From squid3 at treenet.co.nz  Tue Apr 10 15:46:22 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Apr 2018 03:46:22 +1200
Subject: [squid-users] https proxy authentication
In-Reply-To: <742f8b56-657f-8aae-5d6a-172e86d88818@matrixscience.com>
References: <1de18b37-385c-e20f-7feb-432fd403bcdf@matrixscience.com>
 <93199834-4908-fc81-af85-79f017539112@treenet.co.nz>
 <742f8b56-657f-8aae-5d6a-172e86d88818@matrixscience.com>
Message-ID: <553f5c9e-cc4c-408c-2335-421c30d9632b@treenet.co.nz>

On 11/04/18 02:07, Adam Weremczuk wrote:
> Hi Amos,
> 
> 
> On 30/03/18 02:44, Amos Jeffries wrote:
>> So, the big question is why you have this setup of Apache being a
>> reverse-proxy for a Squid forward-proxy?
>>
>> Forward-proxy are supposed to be between clients and reverse-proxies or
>> origins. Not the other way around.
> This is a set up I inherited with not much being documented.
> I think the purpose was to split the functionality as below:
> - direct unauthenticated proxy for every day usage ("proxy")
> - hopping through Apache which provides http authentication for sporadic
> testing use only ("aproxy")

You may want to double-check that and redesign how the proxy is used.
Squid can easily do things like receive traffic on multiple IP:port and
selectively perform authentication only for traffic arriving in one.


>> What are you actually trying to achieve here?
> The big picture is we need to test some code against various proxy
> scenarios (http, https, authenticated, unauthenticated).
> ATM we only have http authentication.
> I would imagine real live proxy setups use encrypted https for
> authentication more often than plain text http.
> Am I correct with my assumption?

No. Actually the preferred HTTP authentication schemes do not send any
confidential things in-channel over the network, so do not require HTTPS
protections.

The Basic and Digest auth schemes which could have benefited normally
have to be sent unprotected over TCP instead.


( Ironically that sad situation is due to the Browser developers behind
a certain "TLS/HTTPS everywhere" campaign refusing for _decades_ to
implement TLS to proxies. Directly counter to our campaign to get them
to use TLS where it is actually most needed. )


> 
> If that's the case then my goal is to get https authentication working
> as well.
> If there is no way I can easily get it to work with the existing config
> I guess I can set up a new Apache hop.
> Authenticating over https only and called e.g. "bproxy".
> Would that make most sense?
> 
> Thanks
> Adam


I think what you are wanting is something like below. Then you just need
your testing to send traffic to the right port:

 # reverse-proxy HTTP
 http_port 80 accel
 acl port80 myportname 80

 # forward-proxy HTTP
 http_port 3128
 acl port3128 myportname 3128

 # reverse-proxy HTTPS
 https_port 443 accel cert=...
 acl port443 myportname 443

 # forward-proxy TLS-explicit
 https_port 8443
 acl port8443 myportname 8443

 auth_param ... your auth setup
 acl auth proxy_auth REQUIRED

 acl noauth ... something to determine non-auth testing.

 # ... http_access rules testing things that do not require auth

 # emulate the "deny all" ending the non-auth checks
 http_access deny noauth

 # requires auth ...
 http_access deny !auth

 # ... rules testing things that require auth credentials.


Depending on what you want your test proxy behaviour to be you can
wrangle up some very cool behaviours with the any-of and all-of ACL
types in recent versions, or various lists of ACLs following one of the
port name ones.

Amos


From uhlar at fantomas.sk  Tue Apr 10 16:08:03 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 10 Apr 2018 18:08:03 +0200
Subject: [squid-users] Squid is very slow after moving to production
 environment
In-Reply-To: <5cecf7cd-51b4-7caa-1147-5c3c56c5e82e@treenet.co.nz>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <201804092136.28285.Antony.Stone@squid.open.source.it>
 <CAG2Qp6vLdYnDdP6Yp25d=jWdJ_ue1j4PCtok2p+hhOBo21shyA@mail.gmail.com>
 <5cecf7cd-51b4-7caa-1147-5c3c56c5e82e@treenet.co.nz>
Message-ID: <20180410160803.GA13413@fantomas.sk>

>On 10/04/18 07:58, Roberto Carna wrote:
>> Dear Antony, both proxies are virtual machines in the same DMZ....they
>> use the same DNS, the same firewall, the same Internet link, the same
>> IP but different MAC Address.

On 10.04.18 22:09, Amos Jeffries wrote:
>FYI: there were issues some years back with VMs that were cloned
>operating VERY much slower for no apparent reason than the original
>image they were cloned from.
>
>If you are making production as a clone of the testing you may want to
>try a non-clone to see if the problem disappears.

maybe using "linked clones" causes the problem.
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
(R)etry, (A)bort, (C)ancer


From rousskov at measurement-factory.com  Tue Apr 10 16:10:06 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 10 Apr 2018 10:10:06 -0600
Subject: [squid-users] Squid ipcache and DNS TTL smaller than 60 seconds
In-Reply-To: <8aa3ffd6-0bfc-d0c9-08d4-d87fa980fc50@treenet.co.nz>
References: <CAPa6PsGk30OKN8SML6QVow152Yp_MHkBoOH5vUWV88pXLqsz9Q@mail.gmail.com>
 <8aa3ffd6-0bfc-d0c9-08d4-d87fa980fc50@treenet.co.nz>
Message-ID: <ef4e6340-85bc-7310-2f3b-771462ca6f48@measurement-factory.com>

On 04/10/2018 09:19 AM, Amos Jeffries wrote:

> Consider, what would you expect to happen when DNS RRset changes
> _multiple_ times within the same TTL that TCP uses for a SYN-ACK timeout
> and retry?

I would expect that nothing special happens to a good implementation:
The TCP client would not notice the TTL expiration and RRset changes
while dealing with packets on a single TCP connection.

RRset TTL does _not_ mean that the client of a DNS cache cannot use the
answer after the TTL expires. It means that the DNS cache itself should
not return a stale answer to its client after the TTL expires. There is
an architectural boundary between a DNS cache and a client of that DNS
cache. Squid implementation may violate that boundary, but that Squid
problem is not a good (long-term) justification for violating server TTLs.

Connection reuse problems that you have described could be a good
justification for a default minimum TTL of 60 seconds. IMHO, it is not a
valid long-term justification for violating server TTLs when the admin
wants to honor them.


Cheers,

Alex.


From uhlar at fantomas.sk  Tue Apr 10 16:16:58 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 10 Apr 2018 18:16:58 +0200
Subject: [squid-users] Squid is very slow after moving to production
 environment
In-Reply-To: <CAG2Qp6tx87wEnfU4q3mtG_Oy+jg6bdnvNxxAeoLcZ_BWsqfqdQ@mail.gmail.com>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <CAK2yrTZfyiH+cdL46TQ9_75Xg1LVY0Dvq6Ur9TVJA7MAFAb+og@mail.gmail.com>
 <CAG2Qp6tx87wEnfU4q3mtG_Oy+jg6bdnvNxxAeoLcZ_BWsqfqdQ@mail.gmail.com>
Message-ID: <20180410161658.GB13413@fantomas.sk>

On 09.04.18 16:53, Roberto Carna wrote:
>Dear Periko, so here is what you ask to me:
>
>CPU x 8
>RAM x 12 GB
>HD x 50 GB
>
>And this is /etc/squid/squid.conf file:

>cache_mem 4096 MB

what is squid's real memory usage?
It can be much much more than 4G, 4G is only cache, but squid also uses
buffers and indexes.

>memory_replacement_policy lru

I would use heap gdsfhere for betterhit ratio, but this should not be a
problem

>cache_dir aufs /var/spool/squid 25000 16 256

What's squid CPU usage?
here can be a problem. aufs cache_dir can be only used by one process.
Maybe you should try rock store for cache_Dir

>fqdncache_size 4096

I don't see any reason to specify this. too low fqdn cache can result into
repeated DNS fetches.

>acl manager proto cache_object

doesn't squid complain here? the "manager" acl is predefined since 3.4 iirc.
Are you sure squid uses this config file?

>auth_param basic program /usr/lib/squid/squid_ldap_auth -b
>"dc=company,dc=com,dc=ar" -f "uid=%s" -h ldap.company.com.ar -v 3
>auth_param basic children 5

aren't there too few children? it can result into waiting for authentication
result before client is allowed.
what does squid log say?

>acl QUERY urlpath_regex cgi-bin \? \.css \.asp \.aspx
>cache deny QUERY

this is useless for a long time. urlpath_regex causes squid eat much of CPU.
disable this.

>acl gedo dstdomain .gde.gob.ar
>always_direct allow gedo

you have no cache peers defined. This is therefore useless.

>I've just changed the new proxy to test environment and it works very
>well again....I get lost.

see the limits above. Some of them may be low for a production system.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
WinError #99999: Out of error messages.


From eliezer at ngtech.co.il  Tue Apr 10 16:37:24 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 10 Apr 2018 19:37:24 +0300
Subject: [squid-users] Proxy through another proxy possible?
In-Reply-To: <17c46aac-0f07-5c23-a82a-35934870d313@gmail.com>
References: <66bc30d9-ffad-6752-54a7-a750076fcbf0@gmail.com>
 <14d88b13-c63c-ba42-f95d-91688ebe7b6c@treenet.co.nz>
 <8cea970b-e5af-86e0-a87c-401cca289931@gmail.com>
 <6df9c042-4178-c44c-51ff-01772ef69f26@treenet.co.nz>
 <17c46aac-0f07-5c23-a82a-35934870d313@gmail.com>
Message-ID: <05e701d3d0ea$3522e3c0$9f68ab40$@ngtech.co.il>

Hey,

If the snipper works for you then you should be able to use a simple ACL that will pass all traffic of a certain http_port to a specific proxy.
However depends on the scenario there are couple things to consider in terms performance of this system.

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of xpro
Sent: Sunday, April 8, 2018 16:07
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Proxy through another proxy possible?

Thank you. I did get it to work with snippet below

cache_peer myproxy.com parent 3114 0 no-query default
never_direct allow all


can you tell me how I can assign different ports to different outgoing 
proxies?


On 04/07/2018 02:30 AM, Amos Jeffries wrote:
> On 07/04/18 18:02, xpro wrote:
>> Would it be done like below?
>>
>> http_port 3001
>> acl port1 myport 3001
>> tcp_outgoing_address myotherproxy.com:3114 port1
>>
>>
>> I want anyone connecting to my proxy using port 3001, to use the the
>> proxy server on myotherproxy.com:3114
> No. tcp_outgoing_address is the IP your Squid uses on its outgoing TCP
> connections.
>
> cache_peer is for configuring destination details about any specific
> peer (upstream server or proxy) to relay messages through.
>   see <https://wiki.squid-cache.org/Features/CacheHierarchy>
>
> Amos
>
>
>>
>> On 04/07/2018 01:05 AM, Amos Jeffries wrote:
>>> On 07/04/18 11:34, xpro wrote:
>>>> I'm not sure if Squid is the right tool for this. I'm trying to achieve
>>>> the following.
>>>>
>>>> I would have access to some exclusive proxies, but I would like for a
>>>> limited amount of people to use these proxies without getting the
>>>> original proxy IP. I want them to go through my proxy server and then my
>>>> proxy server would forward them to the proxy I use.
>>>>
>>>>
>>>> Would this be possible with Squid?
>>> Of course. I'm not exactly clear on what you mean by original or
>>> exclusive proxies, but HTTP and Squid are certainly able to chain.
>>>
>>> Amos
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Tue Apr 10 16:53:15 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 10 Apr 2018 19:53:15 +0300
Subject: [squid-users] Squid is very slow after moving to production
	environment
In-Reply-To: <5cecf7cd-51b4-7caa-1147-5c3c56c5e82e@treenet.co.nz>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <201804092136.28285.Antony.Stone@squid.open.source.it>
 <CAG2Qp6vLdYnDdP6Yp25d=jWdJ_ue1j4PCtok2p+hhOBo21shyA@mail.gmail.com>
 <5cecf7cd-51b4-7caa-1147-5c3c56c5e82e@treenet.co.nz>
Message-ID: <05f301d3d0ec$6b5c59b0$42150d10$@ngtech.co.il>

Well about Cloned VM's acting slower than the original...
I clearly tested it more then once and it's not true and it's a myth.
The only issue I have seen with such cloned systems(I have a very large cluster of cloned squid instances) is when the admin over-commit the physical machine.
There is another thing in the hypervisor's world that some admins just do not take into account:
- Squid can heavily load a specific CPU.
- You cannot expect the virtualization platform to "create" cycles that do not exist.
- You cannot expect the virtualization platform to.. make the disks or the network perform more than they have avaliable.

I have a fleet of more than 10 hypervisors which run's more than 90 VM's and from them more then 20 percent have Squid-Cache and other services on them.
The only time I had issues was when one of the VM's that was running a java based service took a hit of more then 50k requests per second and took\claimed brutally more CPU and RAM to spare the other VM's and... all the other VM's just crashed with a kernel panic while this specific VM "controlled" or "dominated" the hypervisor resources.

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Tuesday, April 10, 2018 13:09
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid is very slow after moving to production environment

On 10/04/18 07:58, Roberto Carna wrote:
> Dear Antony, both proxies are virtual machines in the same DMZ....they
> use the same DNS, the same firewall, the same Internet link, the same
> IP but different MAC Address.


FYI: there were issues some years back with VMs that were cloned
operating VERY much slower for no apparent reason than the original
image they were cloned from.

If you are making production as a clone of the testing you may want to
try a non-clone to see if the problem disappears.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Tue Apr 10 16:56:56 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Apr 2018 04:56:56 +1200
Subject: [squid-users] Proxy through another proxy possible?
In-Reply-To: <17c46aac-0f07-5c23-a82a-35934870d313@gmail.com>
References: <66bc30d9-ffad-6752-54a7-a750076fcbf0@gmail.com>
 <14d88b13-c63c-ba42-f95d-91688ebe7b6c@treenet.co.nz>
 <8cea970b-e5af-86e0-a87c-401cca289931@gmail.com>
 <6df9c042-4178-c44c-51ff-01772ef69f26@treenet.co.nz>
 <17c46aac-0f07-5c23-a82a-35934870d313@gmail.com>
Message-ID: <664606c0-1672-bc8b-6360-fb9fb50e90c3@treenet.co.nz>

On 09/04/18 01:06, xpro wrote:
> Thank you. I did get it to work with snippet below
> 
> cache_peer myproxy.com parent 3114 0 no-query default
> never_direct allow all
> 
> 
> can you tell me how I can assign different ports to different outgoing
> proxies?
> 

What do you mean by assign ports?

Amos


From eliezer at ngtech.co.il  Tue Apr 10 17:09:25 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 10 Apr 2018 20:09:25 +0300
Subject: [squid-users] Ideas for better caching these popular urls
In-Reply-To: <1523359176495-0.post@n4.nabble.com>
References: <1523356349608-0.post@n4.nabble.com>
 <f24e1fe3-2fb4-966a-7540-78fc1d237cfa@treenet.co.nz>
 <1523359176495-0.post@n4.nabble.com>
Message-ID: <05f601d3d0ee$ae348df0$0a9da9d0$@ngtech.co.il>

Hey Omid,

>From what I remember the basics of math to verify the patter of a specific set of numbers have some kind of pattern is to have at-least 3 items.
But in the cryptography world it another story.
I have not researched playstation downloads and will probably won't do that.
Others might offer some help but you must understand what you are trying to predict in these urls and downloads.
>From what I have seen it seem that this CDN "llnwd.net" is very cache friendly but you need to know how to handle their traffic.
They don?t use any form of ETAG headers but they do provide some pieces of information in the url's that can identify something about it.
If they use a ticketing system such as couple other CDN providers you would need to know the "ID" of the url before it's being downloaded.
You will need more then just the urls but also the response headers for these.
I might be able to write an ICAP service that will log requests and response headers and it can assist Cache admins to improve their efficiency but this can take a while.

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Omid Kosari
Sent: Tuesday, April 10, 2018 14:20
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Ideas for better caching these popular urls

Thanks for reply . 

I assumed the community at different scales from little isp to large ISPs
may have common domains like those i highlighted so they may have same issue
as mine . So i ignored common parts .

One of problems with redbot is it shows timeout for big files like 

http://gs2.ww.prod.dl.playstation.net/gs2/appkgo/prod/CUSA00900_00/2/f_2df8e321f37e2f5ea3930f6af4e9571144916013ee38893d881890b454b5fed6/f/UP9000-CUSA00900_00-BLOODBORNE000000_4.pkg?downloadId=00000187&du=000000000000018700e2291bda0f868f&country=us&downloadType=ob&q=aa2cd9c8d1f359feb843ae4a6c99cfcdb6569ca9cc60ad6d28b6f8de3b5fac23&threadId=0&serverIpAddr=23.57.69.81&r=00000027

http://gs2.ww.prod.dl.playstation.net/gs2/ppkgo/prod/CUSA07557_00/25/f_053bab8c9dec6fbc68a0bd9fc58793285ae350ccf7dadacb35b5840228a9d802/f/EP4001-CUSA07557_00-F12017EMASTER000-A0113-V0100_0.pkg?downloadId=00000059&du=000000000000005900e22977e62f91a2&downloadType=ob&product=0183&serverIpAddr=8.248.5.254&r=00000032


I assumed anyone with few thousand of users may have same problem and maybe
they like to share for example their refresh_pattern or storeid to solve my
problem . You better know that playstation is everywhere playstation ;)

Here is part of storeid_db file
^http:\/\/.*\.sonycoment\.loris-e\.llnwd\.net\/(.*?\.pkg)
http://playstation.net.squidinternal/$1
^http:\/\/.*\.playstation\.net\/(.*?\.pkg)
http://playstation.net.squidinternal/$1

Almost all of the playstation huge downloads are with 206 code but it will
download the file from start to end , if i remember correctly in this
situation squid will correctly cache the file .



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From akismpa at gmail.com  Tue Apr 10 17:24:44 2018
From: akismpa at gmail.com (Panagiotis Bariamis)
Date: Tue, 10 Apr 2018 17:24:44 +0000
Subject: [squid-users] Secure Web Proxy Stress Testing
In-Reply-To: <3e2af5d3-8292-c509-7a3c-7879032864b8@measurement-factory.com>
References: <CAPxN_PVjJ+QKxLYU=rRJa00Mec80TWqqvF5WNJrD0-b7+-jesQ@mail.gmail.com>
 <3e2af5d3-8292-c509-7a3c-7879032864b8@measurement-factory.com>
Message-ID: <CAPxN_PXNbZfZKz2Sjdt=biq6OgqSRnjm31kn7ctZPXBKcoCruA@mail.gmail.com>

Thank you for your answer  but as far as I can understand this setup is for
a regular proxy that just proxies https protocol with http connect headers
(unencrypted traffic between client and proxy on http connect request ) .
Secure web proxy encrypts traffic between client and proxy meaning that you
have an http connect request inside a tls tunnel.

On Tue, Apr 10, 2018, 17:22 Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 04/10/2018 06:31 AM, Panagiotis Bariamis wrote:
> > Is there any stress testing tool to test with a load of 1k to 5k
> > simultaneous connections ?
>
> Web Polygraph (www.web-polygraph.org) supports HTTPS proxies and can
> create thousands of concurrent connections. Below is a PGL configuration
> snippet from a recent HTTPS proxy test in our lab.
>
> HTH,
>
> Alex.
>
>
> SslWrap sslWrap = {
>     ssl_config_file = "openssl.conf";
>     root_certificate = "CA-priv+pub.pem";
>     session_resumption = 70%;
>     session_cache = 100;
> };
>
> Server S = {
>     // no ssl_wraps here unless you want to test TLS inside TLS
>     ...
> };
>
> Proxy P = {
>     addresses = [ ... HTTPS proxy address ... ];
>     ssl_wraps = [ sslWrap ]; // this is an HTTPS proxy
> };
>
> Robot R = {
>     ssl_wraps = [ sslWrap ]; // an HTTPS-capable client
>
>     origins = S.addresses;
>     http_proxies = P.addresses;
>
>     ...
> };
>
> use(S,P,R);
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180410/1ebc1307/attachment.htm>

From rousskov at measurement-factory.com  Tue Apr 10 18:11:05 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 10 Apr 2018 12:11:05 -0600
Subject: [squid-users] Secure Web Proxy Stress Testing
In-Reply-To: <CAPxN_PXNbZfZKz2Sjdt=biq6OgqSRnjm31kn7ctZPXBKcoCruA@mail.gmail.com>
References: <CAPxN_PVjJ+QKxLYU=rRJa00Mec80TWqqvF5WNJrD0-b7+-jesQ@mail.gmail.com>
 <3e2af5d3-8292-c509-7a3c-7879032864b8@measurement-factory.com>
 <CAPxN_PXNbZfZKz2Sjdt=biq6OgqSRnjm31kn7ctZPXBKcoCruA@mail.gmail.com>
Message-ID: <af73e08f-43fe-f2c5-12a2-b31360db0129@measurement-factory.com>

On 04/10/2018 11:24 AM, Panagiotis Bariamis wrote:
> Thank you for your answer? but as far as I can understand this setup is
> for a regular proxy that just proxies https protocol with http connect
> headers (unencrypted traffic between client and proxy on http connect
> request ) .

Your understanding is incorrect: All the traffic between the client and
the proxy is encrypted in that test.


> Secure web proxy encrypts traffic between client and proxy

Yes, and that is what the Polygraph workload sketch tests. The Squid
port for that workload is an https_port, not an http_port.


> meaning that you have an http connect request inside a tls tunnel.?

Yes, if the origin server is talking TLS. Just like a regular HTTP
proxy, an HTTPS proxy can proxy both plain and encrypted origin server
traffic. The latter requires a CONNECT tunnel. Whether the origin server
talks HTTP or HTTPS is a separate variable/issue, unrelated to whether
the client-proxy communication itself is secured.

Polygraph supports HTTPS proxies and HTTPS servers. IIRC, Polygraph v5
supports the combination of the two: TLS inside TLS (because HTTP/2
support essentially required that). I am not sure about Polygraph v4.
The workload I sketched uses HTTPS proxies and plain origin servers.


HTH,

Alex.



> On Tue, Apr 10, 2018, 17:22 Alex Rousskov wrote:
> 
>     On 04/10/2018 06:31 AM, Panagiotis Bariamis wrote:
>     > Is there any stress testing tool to test with a load of 1k to 5k
>     > simultaneous connections ?
> 
>     Web Polygraph (www.web-polygraph.org <http://www.web-polygraph.org>)
>     supports HTTPS proxies and can
>     create thousands of concurrent connections. Below is a PGL configuration
>     snippet from a recent HTTPS proxy test in our lab.
> 
>     HTH,
> 
>     Alex.
> 
> 
>     SslWrap sslWrap = {
>     ? ? ssl_config_file = "openssl.conf";
>     ? ? root_certificate = "CA-priv+pub.pem";
>     ? ? session_resumption = 70%;
>     ? ? session_cache = 100;
>     };
> 
>     Server S = {
>     ? ? // no ssl_wraps here unless you want to test TLS inside TLS
>     ? ? ...
>     };
> 
>     Proxy P = {
>     ? ? addresses = [ ... HTTPS proxy address ... ];
>     ? ? ssl_wraps = [ sslWrap ]; // this is an HTTPS proxy
>     };
> 
>     Robot R = {
>     ? ? ssl_wraps = [ sslWrap ]; // an HTTPS-capable client
> 
>     ? ? origins = S.addresses;
>     ? ? http_proxies = P.addresses;
> 
>     ? ? ...
>     };
> 
>     use(S,P,R);
> 



From chip_pop at hotmail.com  Tue Apr 10 18:32:15 2018
From: chip_pop at hotmail.com (joseph)
Date: Tue, 10 Apr 2018 11:32:15 -0700 (MST)
Subject: [squid-users] Squid is very slow after moving to production
	environment
In-Reply-To: <CAG2Qp6tx87wEnfU4q3mtG_Oy+jg6bdnvNxxAeoLcZ_BWsqfqdQ@mail.gmail.com>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <CAK2yrTZfyiH+cdL46TQ9_75Xg1LVY0Dvq6Ur9TVJA7MAFAb+og@mail.gmail.com>
 <CAG2Qp6tx87wEnfU4q3mtG_Oy+jg6bdnvNxxAeoLcZ_BWsqfqdQ@mail.gmail.com>
Message-ID: <1523385135965-0.post@n4.nabble.com>

hi also lower maximum_object_size_in_memory 4096 KB  to 
maximum_object_size_in_memory 1 MB  higher not wise 



-----
************************** 
***** Crash to the future  ****
**************************
--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From robertocarna36 at gmail.com  Tue Apr 10 19:10:24 2018
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Tue, 10 Apr 2018 16:10:24 -0300
Subject: [squid-users] Squid is very slow after moving to production
	environment
In-Reply-To: <1523385135965-0.post@n4.nabble.com>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <CAK2yrTZfyiH+cdL46TQ9_75Xg1LVY0Dvq6Ur9TVJA7MAFAb+og@mail.gmail.com>
 <CAG2Qp6tx87wEnfU4q3mtG_Oy+jg6bdnvNxxAeoLcZ_BWsqfqdQ@mail.gmail.com>
 <1523385135965-0.post@n4.nabble.com>
Message-ID: <CAG2Qp6vosD6uRU9x1jf9+C7p-y9L-sDhHYL3E=O80i2ME23QuA@mail.gmail.com>

Thanks to everybody...

I've reviewed what you tell me. I've executed "squid -k parse" and
everything is ok, and I've restarted de Squid entire server.

When I use the server with IP#1, it works OK, is fast....but when I
change its IP to IP#2 (the IP from the current Squid that I want to
replace), the navigation is very very slow, just 20/30 concurrent
users.

So I think the Squid configuration parameters are OK, because with
IP#1 the proxy runs perfectly.

Why just an IP change affected the performance of web browsing ????
Maybe because of something relative to Dansguardian ???

Thanks and regards !!!

2018-04-10 15:32 GMT-03:00 joseph <chip_pop at hotmail.com>:
> hi also lower maximum_object_size_in_memory 4096 KB  to
> maximum_object_size_in_memory 1 MB  higher not wise
>
>
>
> -----
> **************************
> ***** Crash to the future  ****
> **************************
> --
> Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From akismpa at gmail.com  Tue Apr 10 19:14:22 2018
From: akismpa at gmail.com (Panagiotis Bariamis)
Date: Tue, 10 Apr 2018 19:14:22 +0000
Subject: [squid-users] Secure Web Proxy Stress Testing
In-Reply-To: <af73e08f-43fe-f2c5-12a2-b31360db0129@measurement-factory.com>
References: <CAPxN_PVjJ+QKxLYU=rRJa00Mec80TWqqvF5WNJrD0-b7+-jesQ@mail.gmail.com>
 <3e2af5d3-8292-c509-7a3c-7879032864b8@measurement-factory.com>
 <CAPxN_PXNbZfZKz2Sjdt=biq6OgqSRnjm31kn7ctZPXBKcoCruA@mail.gmail.com>
 <af73e08f-43fe-f2c5-12a2-b31360db0129@measurement-factory.com>
Message-ID: <CAPxN_PVTtPL8ismf5p2vut9LYZVa9oBfH=2-1-1x6NDE8aJpZw@mail.gmail.com>

Thank you for the clarification.

On Tue, Apr 10, 2018, 21:11 Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 04/10/2018 11:24 AM, Panagiotis Bariamis wrote:
> > Thank you for your answer  but as far as I can understand this setup is
> > for a regular proxy that just proxies https protocol with http connect
> > headers (unencrypted traffic between client and proxy on http connect
> > request ) .
>
> Your understanding is incorrect: All the traffic between the client and
> the proxy is encrypted in that test.
>
>
> > Secure web proxy encrypts traffic between client and proxy
>
> Yes, and that is what the Polygraph workload sketch tests. The Squid
> port for that workload is an https_port, not an http_port.
>
>
> > meaning that you have an http connect request inside a tls tunnel.
>
> Yes, if the origin server is talking TLS. Just like a regular HTTP
> proxy, an HTTPS proxy can proxy both plain and encrypted origin server
> traffic. The latter requires a CONNECT tunnel. Whether the origin server
> talks HTTP or HTTPS is a separate variable/issue, unrelated to whether
> the client-proxy communication itself is secured.
>
> Polygraph supports HTTPS proxies and HTTPS servers. IIRC, Polygraph v5
> supports the combination of the two: TLS inside TLS (because HTTP/2
> support essentially required that). I am not sure about Polygraph v4.
> The workload I sketched uses HTTPS proxies and plain origin servers.
>
>
> HTH,
>
> Alex.
>
>
>
> > On Tue, Apr 10, 2018, 17:22 Alex Rousskov wrote:
> >
> >     On 04/10/2018 06:31 AM, Panagiotis Bariamis wrote:
> >     > Is there any stress testing tool to test with a load of 1k to 5k
> >     > simultaneous connections ?
> >
> >     Web Polygraph (www.web-polygraph.org <http://www.web-polygraph.org>)
> >     supports HTTPS proxies and can
> >     create thousands of concurrent connections. Below is a PGL
> configuration
> >     snippet from a recent HTTPS proxy test in our lab.
> >
> >     HTH,
> >
> >     Alex.
> >
> >
> >     SslWrap sslWrap = {
> >         ssl_config_file = "openssl.conf";
> >         root_certificate = "CA-priv+pub.pem";
> >         session_resumption = 70%;
> >         session_cache = 100;
> >     };
> >
> >     Server S = {
> >         // no ssl_wraps here unless you want to test TLS inside TLS
> >         ...
> >     };
> >
> >     Proxy P = {
> >         addresses = [ ... HTTPS proxy address ... ];
> >         ssl_wraps = [ sslWrap ]; // this is an HTTPS proxy
> >     };
> >
> >     Robot R = {
> >         ssl_wraps = [ sslWrap ]; // an HTTPS-capable client
> >
> >         origins = S.addresses;
> >         http_proxies = P.addresses;
> >
> >         ...
> >     };
> >
> >     use(S,P,R);
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180410/79de0370/attachment.htm>

From squid3 at treenet.co.nz  Tue Apr 10 21:04:12 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Apr 2018 09:04:12 +1200
Subject: [squid-users] Squid is very slow after moving to production
 environment
In-Reply-To: <CAG2Qp6vosD6uRU9x1jf9+C7p-y9L-sDhHYL3E=O80i2ME23QuA@mail.gmail.com>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <CAK2yrTZfyiH+cdL46TQ9_75Xg1LVY0Dvq6Ur9TVJA7MAFAb+og@mail.gmail.com>
 <CAG2Qp6tx87wEnfU4q3mtG_Oy+jg6bdnvNxxAeoLcZ_BWsqfqdQ@mail.gmail.com>
 <1523385135965-0.post@n4.nabble.com>
 <CAG2Qp6vosD6uRU9x1jf9+C7p-y9L-sDhHYL3E=O80i2ME23QuA@mail.gmail.com>
Message-ID: <ba3f8066-0c97-f975-1347-74855bb29a53@treenet.co.nz>

On 11/04/18 07:10, Roberto Carna wrote:
> Thanks to everybody...
> 
> I've reviewed what you tell me. I've executed "squid -k parse" and
> everything is ok, and I've restarted de Squid entire server.
> 
> When I use the server with IP#1, it works OK, is fast....but when I
> change its IP to IP#2 (the IP from the current Squid that I want to
> replace), the navigation is very very slow, just 20/30 concurrent
> users.
> 
> So I think the Squid configuration parameters are OK, because with
> IP#1 the proxy runs perfectly.

Then the issue is probably not with Squid. Something outside Squid is
causing the issue - either the VM itself, or the network setup.

> 
> Why just an IP change affected the performance of web browsing ????

We do not know the answer to that. None of the info so far shows any
sign of such a problem. Something you have not thought to provide yet
contains the clues.

Perhapse taking a look through the available logs (both Squid and
others) might find better information and ideas.


> Maybe because of something relative to Dansguardian ???
> 

Maybe yes, maybe no. see above.

Amos


From jun357572957zhao at hotmail.com  Wed Apr 11 01:48:07 2018
From: jun357572957zhao at hotmail.com (=?gb2312?B?1dQgv6E=?=)
Date: Wed, 11 Apr 2018 01:48:07 +0000
Subject: [squid-users] =?gb2312?b?SG93IHRvIGNvbmZpZ3VyZSBTcXVpZCBjYW4gaW1w?=
 =?gb2312?b?cm92ZSB0aGUgcGVyZm9ybWFuY2Ugo78=?=
Message-ID: <CY4PR22MB036089883BA637E38E45762198BD0@CY4PR22MB0360.namprd22.prod.outlook.com>

Thanks for reading my Email.

I have two questions:

My first question is how many maximum concurrent connection and the maximum new connection of squid are.

The second question is how to configure Squid can improve  the maximum concurrent connection,maximum new connection and the performance .

I used 3.5.27 version.

My squid.conf is:

acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
acl localnet src 172.16.0.0/12 # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
acl NCACHE method GET
store_miss deny all
via off

# Squid normally listens to port 3128
http_port 3128
https_port 192.168.XX.XXX:3129 intercept ssl-bump connection-auth=off generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/ssl_cert/myCA.pem key=/usr/local/squid/ssl_cert/myCA.pem  options=NO_SSLv3,NO_SSLv2

acl ssl_step1 at_step SslBump1
acl ssl_step2 at_step SslBump2
acl ssl_step3 at_step SslBump3

ssl_bump peek ssl_step1
ssl_bump stare ssl_step2
ssl_bump bump ssl_step3

sslcrtd_program /usr/local/squid/libexec/ssl_crtd -s /usr/local/squid/lib/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1

#Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /usr/local/squid/var/cache/squid 4096 16 256
minimum_object_size 0 KB
maximum_object_size 4096 KB
maximum_object_size_in_memory 4096 KB

ipcache_size 1024 MB
ipcache_low 90
ipcache_high 95
fqdncache_size 1024 MB

cache_mem 2048 MB
cache_swap_low 90
cache_swap_high 95

# Leave coredumps in the first cache dir
coredump_dir /usr/local/squid/var/cache/squid

#icap
icap_enable on
icap_preview_enable on
icap_preview_size 1024
icap_send_client_ip on
adaptation_meta X-Client-Port "%>p"
icap_206_enable on
icap_persistent_connections off

icap_service service_req reqmod_precache 0 icap://192.168.XX.XXX:1344/echo
icap_service service_res respmod_precache 1 icap://192.168.XX.XXX:1344/echo
adaptation_access service_res allow all
adaptation_access service_req allow all

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180411/de3eb21e/attachment.htm>

From squid3 at treenet.co.nz  Wed Apr 11 04:02:02 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 Apr 2018 16:02:02 +1200
Subject: [squid-users]
 =?utf-8?q?How_to_configure_Squid_can_improve_the_pe?=
 =?utf-8?q?rformance_=EF=BC=9F?=
In-Reply-To: <CY4PR22MB036089883BA637E38E45762198BD0@CY4PR22MB0360.namprd22.prod.outlook.com>
References: <CY4PR22MB036089883BA637E38E45762198BD0@CY4PR22MB0360.namprd22.prod.outlook.com>
Message-ID: <61834f48-d792-c5bc-9770-11ab45610281@treenet.co.nz>

On 11/04/18 13:48, ? ? wrote:
> Thanks for reading my Email.
> 
> I have two questions:
> 
> My first?question is how?many maximum concurrent connection and the
> maximum new connection of squid are.
> 


There are 64K ports on an IP address. Your Squid and machine also has a
filedescriptors (FDs) limit it is 64K by default but may be smaller (eg
on Windows it is 256). The smaller of those two numbers is the upper
limit Squid can use.

The ports number is shared between client connections, server
connections and both types of ICAP connections.

The FDs number is shared by the same things as the ports number, as well
as disk files in-use.


You can maybe increase FDs with squid.conf max_filedescriptors, or if
that does not work rebuild Squid with --max-filedescriptors= build
option. Use the ulimit tool on non-Windows machines to increase the OS
limit before starting Squid.



> The second question is how?to configure?Squid?can improve??the maximum
> concurrent connection,maximum new connection and the?performance .
> 

If FD available is being your limit you can maybe increase it with
squid.conf max_filedescriptors config option. Of if that does not work
rebuild Squid with --max-filedescriptors= build option. Use the ulimit
tool on non-Windows machines to increase the OS limit before starting Squid.


> I used 3.5.27 version.
> 
> My squid.conf is:
...
> 
> # And finally deny all other access to this proxy
> acl NCACHE method GET
> store_miss deny all

The "store_miss deny all" above will be preventing HTTP objects from
caching. That means every request will consume one extra server
connection and ICAP RESPMOD connection.
 Your Squid will need some amount of less connections if things are
caching. So you may want to remove this.


> via off
> 
> # Squid normally listens to port 3128
> http_port 3128?
> https_port 192.168.XX.XXX:3129 intercept ssl-bump connection-auth=off
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> cert=/usr/local/squid/ssl_cert/myCA.pem
> key=/usr/local/squid/ssl_cert/myCA.pem? options=NO_SSLv3,NO_SSLv2

NP: If cert= and key= are in the same file like this you do not have to
configure key=.

Also, for Squid-3.* add sslflags=NO_DEFAULT_CA on the above port line.
That will free up a lot of memory in OpenSSL for other things it may be
needed for.


> 
> acl ssl_step1 at_step SslBump1
> acl ssl_step2 at_step SslBump2
> acl ssl_step3 at_step SslBump3
> 
> ssl_bump peek ssl_step1
> ssl_bump stare ssl_step2
> ssl_bump bump ssl_step3
> 
> sslcrtd_program /usr/local/squid/libexec/ssl_crtd -s
> /usr/local/squid/lib/ssl_db -M 4MB
> sslcrtd_children 8 startup=1 idle=1
> 

ssl_crtd is a little bit unusual for helpers in that it holds up the TLS
handshake which is somewhat critical to do fast. So it is probably best
to use more than startup=1 to reduce Squid memory usage and delays.

As a general "rule of thumb" look at your running proxy and see how many
helpers it is needing to start for your normal traffic. Use that as the
startup= value.



The below cache_dir, object_size, cache_mem, and cache_swap directives
are not useful while you have "store_miss deny all" preventing cache
storage being used.

> #Uncomment and adjust the following to add a disk cache directory.
> cache_dir ufs /usr/local/squid/var/cache/squid 4096 16 256
> minimum_object_size 0 KB
> maximum_object_size 4096 KB
> maximum_object_size_in_memory 4096 KB
> 
> ipcache_size 1024 MB
> ipcache_low 90
> ipcache_high 95
> fqdncache_size 1024 MB
> 
> cache_mem 2048 MB
> cache_swap_low 90
> cache_swap_high 95
> 
> # Leave coredumps in the first cache dir
> coredump_dir /usr/local/squid/var/cache/squid
> 
> #icap
> icap_enable on
> icap_preview_enable on
> icap_preview_size 1024
> icap_send_client_ip on
> adaptation_meta X-Client-Port "%>p"
> icap_206_enable on
> icap_persistent_connections off

The above disable of persistence on ICAP connections will be slowing
Squid down since it has to repeat TCP handshakes *twice* for every
single message through the proxy.


> 
> icap_service service_req reqmod_precache 0 icap://192.168.XX.XXX:1344/echo
> icap_service service_res respmod_precache 1 icap://192.168.XX.XXX:1344/echo
> adaptation_access service_res allow all
> adaptation_access service_req allow all
> 

You can maybe improve ICAP connection use by tuning some traffic not to
use adaptation. For example CONNECT messages are being SSL-Bump'ed so
they are best not to be adapted.
For example:
  adaptation_access service_req deny CONNECT
  adaptation_access service_req allow all


Amos


From omidkosari at yahoo.com  Wed Apr 11 09:32:10 2018
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 11 Apr 2018 02:32:10 -0700 (MST)
Subject: [squid-users] Ideas for better caching these popular urls
In-Reply-To: <05f601d3d0ee$ae348df0$0a9da9d0$@ngtech.co.il>
References: <1523356349608-0.post@n4.nabble.com>
 <f24e1fe3-2fb4-966a-7540-78fc1d237cfa@treenet.co.nz>
 <1523359176495-0.post@n4.nabble.com>
 <05f601d3d0ee$ae348df0$0a9da9d0$@ngtech.co.il>
Message-ID: <1523439130641-0.post@n4.nabble.com>

Eliezer Croitoru wrote
> You will need more then just the urls but also the response headers for
> these.
> I might be able to write an ICAP service that will log requests and
> response headers and it can assist Cache admins to improve their
> efficiency but this can take a while.

Hi Eliezer,

Nice idea. I am ready to test/help/share what you need in real production
environment. Please also do a general thing which includes other domains in
first post attachment. They worth a try .

Thanks




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From eliezer at ngtech.co.il  Wed Apr 11 16:56:08 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 11 Apr 2018 19:56:08 +0300
Subject: [squid-users] Ideas for better caching these popular urls
In-Reply-To: <1523439130641-0.post@n4.nabble.com>
References: <1523356349608-0.post@n4.nabble.com>
 <f24e1fe3-2fb4-966a-7540-78fc1d237cfa@treenet.co.nz>
 <1523359176495-0.post@n4.nabble.com>
 <05f601d3d0ee$ae348df0$0a9da9d0$@ngtech.co.il>
 <1523439130641-0.post@n4.nabble.com>
Message-ID: <035a01d3d1b5$fcc522a0$f64f67e0$@ngtech.co.il>

Hey Omid,

I will try to use a file format similar to this:
## FILENAME = unixtime-sha256
ESPMOD icap://127.0.0.1:1344/dumper ICAP/1.0
date: Wed, 11 Apr 2018 16:52:13 GMT
encapsulated: req-hdr=0, res-hdr=105, res-body=413
preview: 0
allow: 204
host: 127.0.0.1:1344
Socket-Remote-Addr: 127.0.0.1:55178

GET http://ngtech.co.il/index.html HTTP/1.1
Accept: */*
User-Agent: curl/7.29.0

HTTP/1.1 200 OK
Content-Length: 17230
Accept-Ranges: bytes
Access-Control-Allow-Methods: GET, POST, OPTIONS
Access-Control-Allow-Origin: *
Content-Type: text/html
Date: Wed, 11 Apr 2018 16:52:13 GMT
Last-Modified: Tue, 03 Apr 2018 20:19:05 GMT
Server: nginx/1.10.3 (Ubuntu)
Vary: Accept-Encoding
## EOF

I have a prototype that I wrote three years ago but it needs to be polished for general use.
I will update when I will have some progress.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Omid Kosari
Sent: Wednesday, April 11, 2018 12:32
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Ideas for better caching these popular urls

Eliezer Croitoru wrote
> You will need more then just the urls but also the response headers for
> these.
> I might be able to write an ICAP service that will log requests and
> response headers and it can assist Cache admins to improve their
> efficiency but this can take a while.

Hi Eliezer,

Nice idea. I am ready to test/help/share what you need in real production
environment. Please also do a general thing which includes other domains in
first post attachment. They worth a try .

Thanks




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From aaron.hall at oath.com  Wed Apr 11 18:20:11 2018
From: aaron.hall at oath.com (Aaron Hall)
Date: Wed, 11 Apr 2018 14:20:11 -0400
Subject: [squid-users] IP Lookup Failure
Message-ID: <CAOA5C65YALb+qq1ZkYEYXNHZQiw5u6wZMyP-Sq3otQCJUA3JCA@mail.gmail.com>

Hello Users -

I've searched the forums and can't find an appropriate answer.

I'm running Squid Cache: Version 3.5.20.

I'm receiving the following line in my cache.log file:

"2018/04/11 14:05:50.370 kid1| 28,3| Eui48.cc(520) lookup:
id=0x7f9d0bd92b84 <IP REDACTED> NOT found"

The server connecting to the proxy is seeing: "Received HTTP code 0 from
proxy after CONNECT".

The client IP is called in an ACL, and that ACL is called in an
`http_access allow` statement.

Can someone point me in the direction of what this might indicate? The
internet and Google searches have failed to provide an answer.

Cheers.
--
Aaron Hall
The Paranoids
Network Security
Aaron.Hall at oath.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180411/8b6684d3/attachment.htm>

From eliezer at ngtech.co.il  Wed Apr 11 19:47:29 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 11 Apr 2018 22:47:29 +0300
Subject: [squid-users] IP Lookup Failure
In-Reply-To: <CAOA5C65YALb+qq1ZkYEYXNHZQiw5u6wZMyP-Sq3otQCJUA3JCA@mail.gmail.com>
References: <CAOA5C65YALb+qq1ZkYEYXNHZQiw5u6wZMyP-Sq3otQCJUA3JCA@mail.gmail.com>
Message-ID: <040401d3d1cd$eeb226f0$cc1674d0$@ngtech.co.il>

Hey Aaron,

If you will disclose your squid.conf and\or "squid -kparse" output it might help to understand.
The Eui48.cc file is there for a mac address lookup as far as I remember so I'm not sure what is causing it.

With more relevant details we might be able to help you understand what's wrong if at all.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Aaron Hall
Sent: Wednesday, April 11, 2018 21:20
To: squid-users at lists.squid-cache.org
Subject: [squid-users] IP Lookup Failure

Hello Users -

I've searched the forums and can't find an appropriate answer.

I'm running Squid Cache: Version 3.5.20.

I'm receiving the following line in my cache.log file:

"2018/04/11 14:05:50.370 kid1| 28,3| Eui48.cc(520) lookup: id=0x7f9d0bd92b84 <IP REDACTED> NOT found"

The server connecting to the proxy is seeing: "Received HTTP code 0 from proxy after CONNECT".

The client IP is called in an ACL, and that ACL is called in an `http_access allow` statement.

Can someone point me in the direction of what this might indicate? The internet and Google searches have failed to provide an answer.

Cheers.

--
Aaron Hall
The Paranoids
Network Security 
mailto:Aaron.Hall at oath.com



From infneurodcr.mtz at infomed.sld.cu  Wed Apr 11 20:01:54 2018
From: infneurodcr.mtz at infomed.sld.cu (Informatico Neurodesarrollo)
Date: Wed, 11 Apr 2018 16:01:54 -0400
Subject: [squid-users] Reports in Squids
Message-ID: <5ACE69B2.8080905@infomed.sld.cu>

Hi friends:
I am use openSUSE Leap 42.3 as a proxy server.
I am need send a report  monthly :

* The first 10th sites with more access and the total amount of his 
traffics.
* The first 10th users with more access  and the total amount of his 
traffics.

* Download and Upload average of total traffic between this time:

7:00     to    12:00
12:00   to    17:00
17:00   to    24:00

Which  software I can  implement it?

I hope that somebody can help me.

My best regards.


-- 

Jes?s Reyes Piedra
Admin Red Neurodesarrollo,C?rdenas
La caja dec?a:"Requiere windows 95 o superior"...
Entonces instal? LINUX.


--
Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas

Infomed: http://www.sld.cu/



From pheriko.support at gmail.com  Wed Apr 11 23:38:55 2018
From: pheriko.support at gmail.com (Periko Support)
Date: Wed, 11 Apr 2018 16:38:55 -0700
Subject: [squid-users] Reports in Squids
In-Reply-To: <5ACE69B2.8080905@infomed.sld.cu>
References: <5ACE69B2.8080905@infomed.sld.cu>
Message-ID: <CAK2yrTb-6AiwME35fp+GYrtH0GXLuA+RSB568=Zzvyp7JSRQMg@mail.gmail.com>

Check sarg.

2018-04-11 13:01 GMT-07:00 Informatico Neurodesarrollo
<infneurodcr.mtz at infomed.sld.cu>:
> Hi friends:
> I am use openSUSE Leap 42.3 as a proxy server.
> I am need send a report  monthly :
>
> * The first 10th sites with more access and the total amount of his
> traffics.
> * The first 10th users with more access  and the total amount of his
> traffics.
>
> * Download and Upload average of total traffic between this time:
>
> 7:00     to    12:00
> 12:00   to    17:00
> 17:00   to    24:00
>
> Which  software I can  implement it?
>
> I hope that somebody can help me.
>
> My best regards.
>
>
> --
>
> Jes?s Reyes Piedra
> Admin Red Neurodesarrollo,C?rdenas
> La caja dec?a:"Requiere windows 95 o superior"...
> Entonces instal? LINUX.
>
>
> --
> Este mensaje le ha llegado mediante el servicio de correo electronico que
> ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema
> Nacional de Salud. La persona que envia este correo asume el compromiso de
> usar el servicio a tales fines y cumplir con las regulaciones establecidas
>
> Infomed: http://www.sld.cu/
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From eliezer at ngtech.co.il  Wed Apr 11 23:48:29 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 12 Apr 2018 02:48:29 +0300
Subject: [squid-users] Ideas for better caching these popular urls
In-Reply-To: <1523439130641-0.post@n4.nabble.com>
References: <1523356349608-0.post@n4.nabble.com>
 <f24e1fe3-2fb4-966a-7540-78fc1d237cfa@treenet.co.nz>
 <1523359176495-0.post@n4.nabble.com>
 <05f601d3d0ee$ae348df0$0a9da9d0$@ngtech.co.il>
 <1523439130641-0.post@n4.nabble.com>
Message-ID: <001901d3d1ef$9842a610$c8c7f230$@ngtech.co.il>

Hey Omid,

I found the service I wrote and packed it in a RPM at:
http://ngtech.co.il/repo/centos/7/x86_64/response-dumper-icap-1.0.0-1.el7.centos.x86_64.rpm

If you are using other OS let me know and I will try to package it for your OS.
Currently debian\ubuntu alien converts the RPM smoothly.

The dumps directory is at:
/var/response-dumper

But the cleanup and filtering ACL's are your job.
You can define which GET requests the service dump\log into the files.
Each individual file in this directory will be name in the next format:
<int epoc time>-<8 bytes uuid>-<md5(GET:full url)>

This format will allow multiple requests happen at the same time but have a different name but the URL hash is still the same so you can filter files by this.
To calculate the hash of a URL use:
$ echo -n "GET:http:/url-to-has.com/path?query=terms"|md5sum

In each and every file the full ICAP respmod details exits ie:
ICAP Request\r\n
HTTP Request \r\n
HTTP Response\r\n

By default cookies+authorization headers are censored from both request and response in the dump to avoid some privacy law issues.

Now the only missing feature is RedBot is to feed a single request and a single response to get a full analysis.

Let me know if it works OK for you(works here fine for a while now).

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Omid Kosari
Sent: Wednesday, April 11, 2018 12:32
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Ideas for better caching these popular urls

Eliezer Croitoru wrote
> You will need more then just the urls but also the response headers for
> these.
> I might be able to write an ICAP service that will log requests and
> response headers and it can assist Cache admins to improve their
> efficiency but this can take a while.

Hi Eliezer,

Nice idea. I am ready to test/help/share what you need in real production
environment. Please also do a general thing which includes other domains in
first post attachment. They worth a try .

Thanks




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Thu Apr 12 05:54:31 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Apr 2018 17:54:31 +1200
Subject: [squid-users] Reports in Squids
In-Reply-To: <5ACE69B2.8080905@infomed.sld.cu>
References: <5ACE69B2.8080905@infomed.sld.cu>
Message-ID: <0fc21590-9e4c-c637-bdb7-d03071b4c0cc@treenet.co.nz>

On 12/04/18 08:01, Informatico Neurodesarrollo wrote:
> Hi friends:
> I am use openSUSE Leap 42.3 as a proxy server.
> I am need send a report? monthly :
> 
> * The first 10th sites with more access and the total amount of his
> traffics.
> * The first 10th users with more access? and the total amount of his
> traffics.
> 
> * Download and Upload average of total traffic between this time:
> 
> 7:00???? to??? 12:00
> 12:00?? to??? 17:00
> 17:00?? to??? 24:00
> 
> Which? software I can? implement it?
> 

Have a look at the software listed here:
 <http://www.squid-cache.org/Misc/log-analysis.html>


Amos


From squid3 at treenet.co.nz  Thu Apr 12 06:00:57 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Apr 2018 18:00:57 +1200
Subject: [squid-users] IP Lookup Failure
In-Reply-To: <040401d3d1cd$eeb226f0$cc1674d0$@ngtech.co.il>
References: <CAOA5C65YALb+qq1ZkYEYXNHZQiw5u6wZMyP-Sq3otQCJUA3JCA@mail.gmail.com>
 <040401d3d1cd$eeb226f0$cc1674d0$@ngtech.co.il>
Message-ID: <99389c20-700a-91fb-cad5-1b8b97779191@treenet.co.nz>

On 12/04/18 07:47, Eliezer Croitoru wrote:
> Hey Aaron,
> 
> If you will disclose your squid.conf and\or "squid -kparse" output it might help to understand.
> The Eui48.cc file is there for a mac address lookup as far as I remember so I'm not sure what is causing it.

Yes. Some OS do not provide MAC lookups, and it does not work on IPv4
unless the machine being looked up is directly connected to the Squid
machine.

So we will need to now which OS is being used as well as the Squid
details and what the network topology looks like.

Amos


From infneurodcr.mtz at infomed.sld.cu  Thu Apr 12 13:14:44 2018
From: infneurodcr.mtz at infomed.sld.cu (Informatico Neurodesarrollo)
Date: Thu, 12 Apr 2018 09:14:44 -0400
Subject: [squid-users] Reports in Squids
In-Reply-To: <0fc21590-9e4c-c637-bdb7-d03071b4c0cc@treenet.co.nz>
References: <5ACE69B2.8080905@infomed.sld.cu>
 <0fc21590-9e4c-c637-bdb7-d03071b4c0cc@treenet.co.nz>
Message-ID: <5ACF5BC4.70802@infomed.sld.cu>

I have installed Sarg and Mrtg, the first cron's run  30 min and the 
second 5 min interval respectively.
Thanks Amos, but I don?t have internet access. If you could send me this 
page compacted to me, I will appreciate you help.
http://www.squid-cache.org/Misc/log-analysis.html

T.I.A.

El 12/04/18 a las 01:54, Amos Jeffries escribi?:
> On 12/04/18 08:01, Informatico Neurodesarrollo wrote:
>> Hi friends:
>> I am use openSUSE Leap 42.3 as a proxy server.
>> I am need send a report  monthly :
>>
>> * The first 10th sites with more access and the total amount of his
>> traffics.
>> * The first 10th users with more access  and the total amount of his
>> traffics.
>>
>> * Download and Upload average of total traffic between this time:
>>
>> 7:00     to    12:00
>> 12:00   to    17:00
>> 17:00   to    24:00
>>
>> Which  software I can  implement it?
>>
> Have a look at the software listed here:
>   <http://www.squid-cache.org/Misc/log-analysis.html>
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 

Jes?s Reyes Piedra
Admin Red Neurodesarrollo,C?rdenas
La caja dec?a:"Requiere windows 95 o superior"...
Entonces instal? LINUX.


--
Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas

Infomed: http://www.sld.cu/



From rafael.akchurin at diladele.com  Fri Apr 13 09:15:55 2018
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 13 Apr 2018 09:15:55 +0000
Subject: [squid-users] [icap] Web Safety 6.2 web filter plugin for Squid
 proxy is Release Candidate
Message-ID: <HE1PR04MB1148150C706AC4D9D64046698FB30@HE1PR04MB1148.eurprd04.prod.outlook.com>

Greetings all,

Next version of Web Safety web filter for Squid proxy (version 6.2.0.FD48, built on April 13, 2018, Release Candidate) is now available for download.
This version contains the following fixes and improvements:


*        Added new dynamic site categorization module. This module works on both requests and response. When categorizing requests URL, Referer and Host headers are scanned. When categorizing responses - textual contents of pages are scanned. Currently there are dynamic categorizer for Nudity Pornography, Adult Themes Sexuality, Drugs and Gambling categories, but more and more categorizers will be added with each release. We target to finally have all available categories covered.


*        Redesigned and re-implemented deep content inspection engine. The speed of content inspection is a little improved. Detection is now done faster. The amount of used RAM when performing adult language detection is greatly decreased (approximately 10 times).

Pre-configured virtual appliance is available from https://www.diladele.com/download_next_version.html (should be run in VMWare ESXi/vSphere or Microsoft Hyper-V). GitHub repo with automation scripts we used to build this virtual appliance from stock Ubuntu 16 LTS image is at https://github.com/diladele/websafety-virtual-appliance/tree/release-6.2.0 .

Direct link to virtual appliance:


*        http://packages.diladele.com/websafety/6.2.0.FD48/va/ubuntu16/websafety.zip

Please deploy this version is non-too-critical environments only. Your questions/issues/bugs are welcome at support at diladele.com<mailto:support at diladele.com>
Version 6.3 will include re-implemented Surfing Now page and CTIRU URL prevention list (provided by Home Office UK).

You can join our community to get free early access to next development builds at https://www.diladele.com/community.html .

Thanks to all of you for making this possible!

Best regards,
Rafael Akchurin
Diladele B.V.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180413/0e660574/attachment.htm>

From mohammed.khallaf at gmail.com  Fri Apr 13 20:41:03 2018
From: mohammed.khallaf at gmail.com (MK2018)
Date: Fri, 13 Apr 2018 13:41:03 -0700 (MST)
Subject: [squid-users] Certificate transparency: problem for ssl-bumping,
 no effect, or?
In-Reply-To: <5c213454-0cee-51ac-7162-95be7ea6bcc6@measurement-factory.com>
References: <5817C21D.5050003@tlinx.org>
 <87221443-0972-e504-f14b-7afc6b3bc771@measurement-factory.com>
 <181d5116-9c72-c752-8da5-26d67026a16d@gmail.com>
 <5c213454-0cee-51ac-7162-95be7ea6bcc6@measurement-factory.com>
Message-ID: <1523652063823-0.post@n4.nabble.com>

Hello :)



Alex Rousskov wrote
> Believe it or not, there are still many Squid use cases where bumping is
> unnecessary. This includes, but is not limited to, HTTPS proxying cases
> with peek/splice/terminate rules and environments where Squid possesses
> the certificate issued by CAs trusted by clients. There are also IETF
> attempts to standardize transmission of encrypted but proxy-cachable
> content.
> 
> I agree that Squid user base will shrink if nobody can bump 3rd party
> traffic, but that reduction alone will not kill Squid.
> 
> Alex.

I would definitely disagree. Rich countries citizens always forget the fact
that high quality corporate leased lines and dedicated bandwidth *do* cost
so much that letting users *hide* their unwanted traffic behind the *4th
amendment* HTTPS is unaffordable.


Naturally, HTTPS standards were designed to hide traffic. I don't mind users
hiding traffic content, let users burn in hell with it, let them rejoice
with Dante!

What I do mind is hiding full URLs and/or MIME types. Give me any low cost
solution that would reliably expose those and hide anything else you want.
Otherwise, it is useless to start a business first place!

I mean, even with appliances like those from Sophos or others that claim to
have full control over traffic, it still remains an ugly guess work combined
with an admin nightmare who then must block each and every category of
unwanted traffic!

Unless the protocol design changes to expose full URLs and/or MIME types,
nothing will replace Squid Bumping.

That being said, we are headed to the vortex by 2018.05.01. Let's drown
together, while we yell and curse at Google!

MK



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From acrow at integrafin.co.uk  Fri Apr 13 22:03:00 2018
From: acrow at integrafin.co.uk (Alex Crow)
Date: Fri, 13 Apr 2018 23:03:00 +0100
Subject: [squid-users] Certificate transparency: problem for ssl-bumping,
 no effect, or?
In-Reply-To: <1523652063823-0.post@n4.nabble.com>
References: <5817C21D.5050003@tlinx.org>
 <87221443-0972-e504-f14b-7afc6b3bc771@measurement-factory.com>
 <181d5116-9c72-c752-8da5-26d67026a16d@gmail.com>
 <5c213454-0cee-51ac-7162-95be7ea6bcc6@measurement-factory.com>
 <1523652063823-0.post@n4.nabble.com>
Message-ID: <b21c5e87-1f05-1849-766e-bbeb5400ae7e@integrafin.co.uk>


> Unless the protocol design changes to expose full URLs and/or MIME types,
> nothing will replace Squid Bumping.
>
> That being said, we are headed to the vortex by 2018.05.01. Let's drown
> together, while we yell and curse at Google!
>
> MK
>
>
>

Erm, can someone elucidate the issue here? Can't see anything about this 
in the last year of mails from this list ;-)

Alex


--
This message is intended only for the addressee and may contain
confidential information. Unless you are that person, you may not
disclose its contents or use it in any way and are requested to delete
the message along with any attachments and notify us immediately.
This email is not intended to, nor should it be taken to, constitute advice.
The information provided is correct to our knowledge & belief and must not
be used as a substitute for obtaining tax, regulatory, investment, legal or
any other appropriate advice.

"Transact" is operated by Integrated Financial Arrangements Ltd.
29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax: (020) 7608 5300.
(Registered office: as above; Registered in England and Wales under
number: 3727592). Authorised and regulated by the Financial Conduct
Authority (entered on the Financial Services Register; no. 190856).


From mohammed.khallaf at gmail.com  Fri Apr 13 22:05:57 2018
From: mohammed.khallaf at gmail.com (MK2018)
Date: Fri, 13 Apr 2018 15:05:57 -0700 (MST)
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <CANAZdzVbZXA0_UpN037y4sSVjYkWHwsmtD0MQmuKxyqoxRO+9w@mail.gmail.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
 <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
 <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>
 <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>
 <CANAZdzUsamD-_P2gB9oQEbjR=Y0XEK0mnKUdYgjXtRGAxnPQUQ@mail.gmail.com>
 <f6a85fc5-50a3-9372-b487-72d8d42122fe@gmail.com>
 <CANAZdzVbZXA0_UpN037y4sSVjYkWHwsmtD0MQmuKxyqoxRO+9w@mail.gmail.com>
Message-ID: <1523657157305-0.post@n4.nabble.com>

Aaron Turner wrote
> Thanks Yuri.  That helps.  As for the "sslproxy_flags
> DONT_VERIFY_PEER", yes I understand the risks.  In my specific case,
> where my "users" are actually a bunch of automated web clients doing
> some web crawling it's the right thing to do.
> --
> Aaron Turner

I tried using bump all myself with actual human beings (200+) using browsers
ranging from Mozilla Firefox, Seamonkey, Chrome, to Safari and Opera.

I don't know why I had to face it, but with bump all I got many errors with
many websites. It only worked with me like this:

http_port 3128 ssl-bump cert=/ssl_cert/myCA.pem 
generate-host-certificates=on dynamic_cert_mem_cache_size=999MB
sslcrtd_children 100
ssl_bump none BadSSL
ssl_bump server-first all

Like you see, I'm using server-first word in place of bump word. This is the
only way I got it to work with natural human browsing. I also could not use
intercept mode, because every major browser considers it a crime to let it
go! They would just spit all sorts of errors at user's face and have you
clean the spitting up :D :D

Of course, BadSSL above is the ACL for all sites using the new fiasco of
hardcoded certificates (certificate-pinning), otherwise, they don't pass at
all!




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From mohammed.khallaf at gmail.com  Fri Apr 13 22:13:26 2018
From: mohammed.khallaf at gmail.com (MK2018)
Date: Fri, 13 Apr 2018 15:13:26 -0700 (MST)
Subject: [squid-users] Certificate transparency: problem for ssl-bumping,
 no effect, or?
In-Reply-To: <b21c5e87-1f05-1849-766e-bbeb5400ae7e@integrafin.co.uk>
References: <5817C21D.5050003@tlinx.org>
 <87221443-0972-e504-f14b-7afc6b3bc771@measurement-factory.com>
 <181d5116-9c72-c752-8da5-26d67026a16d@gmail.com>
 <5c213454-0cee-51ac-7162-95be7ea6bcc6@measurement-factory.com>
 <1523652063823-0.post@n4.nabble.com>
 <b21c5e87-1f05-1849-766e-bbeb5400ae7e@integrafin.co.uk>
Message-ID: <1523657606664-0.post@n4.nabble.com>

Alex Crow-2 wrote
>> Unless the protocol design changes to expose full URLs and/or MIME types,
>> nothing will replace Squid Bumping.
>>
>> That being said, we are headed to the vortex by 2018.05.01. Let's drown
>> together, while we yell and curse at Google!
>>
>> MK
>>
>>
>>
> 
> Erm, can someone elucidate the issue here? Can't see anything about this 
> in the last year of mails from this list ;-)
> 
> Alex
> 
> -


:D :D Sure thing, here it is:
https://aws.amazon.com/blogs/security/how-to-get-ready-for-certificate-transparency/

I had to know from AWS, otherwise I would have been terrorized on May 1st
all the sudden, just like how Google does each time.

Chrome is most probably going to spit fire at all non-CT-Logged CA
certificate. Naturally, 99% of Squid-Bumping feature use self-signed certs
(or otherwise own all real CAs in the world and still violate CA rules), so
they will end up getting into war with all Chrome users.

Hope that clears it up!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From mohammed.khallaf at gmail.com  Fri Apr 13 22:53:01 2018
From: mohammed.khallaf at gmail.com (MK2018)
Date: Fri, 13 Apr 2018 15:53:01 -0700 (MST)
Subject: [squid-users] Certificate transparency: problem for ssl-bumping,
 no effect, or?
In-Reply-To: <1523657606664-0.post@n4.nabble.com>
References: <5817C21D.5050003@tlinx.org>
 <87221443-0972-e504-f14b-7afc6b3bc771@measurement-factory.com>
 <181d5116-9c72-c752-8da5-26d67026a16d@gmail.com>
 <5c213454-0cee-51ac-7162-95be7ea6bcc6@measurement-factory.com>
 <1523652063823-0.post@n4.nabble.com>
 <b21c5e87-1f05-1849-766e-bbeb5400ae7e@integrafin.co.uk>
 <1523657606664-0.post@n4.nabble.com>
Message-ID: <1523659981552-0.post@n4.nabble.com>

MK2018 wrote
> Alex Crow-2 wrote
>>> Unless the protocol design changes to expose full URLs and/or MIME
>>> types,
>>> nothing will replace Squid Bumping.
>>>
>>> That being said, we are headed to the vortex by 2018.05.01. Let's drown
>>> together, while we yell and curse at Google!
>>>
>>> MK
>>>
>>>
>>>
>> 
>> Erm, can someone elucidate the issue here? Can't see anything about this 
>> in the last year of mails from this list ;-)
>> 
>> Alex
>> 
>> -
> 
> 
> :D :D Sure thing, here it is:
> https://aws.amazon.com/blogs/security/how-to-get-ready-for-certificate-transparency/
> 
> I had to know from AWS, otherwise I would have been terrorized on May 1st
> all the sudden, just like how Google does it each time.
> 
> Chrome is most probably going to spit fire at all non-CT-Logged CA
> certificate. Naturally, 99% of Squid-Bumping feature users use self-signed
> certs
> (or otherwise own all real CAs in the world and still violate CA rules),
> so
> they will end up getting into war with all Chrome users (which is
> basically like 80% of users).
> 
> Hope that clears it up!

I might have overlooked this: "Certificates issued from locally-trusted or
enterprise CAs that are added by users or administrators are not subject to
this requirement."

https://groups.google.com/a/chromium.org/forum/#!topic/ct-policy/wHILiYf31DE

Think there is still hope?



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From mohammed.khallaf at gmail.com  Fri Apr 13 23:13:47 2018
From: mohammed.khallaf at gmail.com (MK2018)
Date: Fri, 13 Apr 2018 16:13:47 -0700 (MST)
Subject: [squid-users] Squid is very slow after moving to production
	environment
In-Reply-To: <CAG2Qp6vosD6uRU9x1jf9+C7p-y9L-sDhHYL3E=O80i2ME23QuA@mail.gmail.com>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <CAK2yrTZfyiH+cdL46TQ9_75Xg1LVY0Dvq6Ur9TVJA7MAFAb+og@mail.gmail.com>
 <CAG2Qp6tx87wEnfU4q3mtG_Oy+jg6bdnvNxxAeoLcZ_BWsqfqdQ@mail.gmail.com>
 <1523385135965-0.post@n4.nabble.com>
 <CAG2Qp6vosD6uRU9x1jf9+C7p-y9L-sDhHYL3E=O80i2ME23QuA@mail.gmail.com>
Message-ID: <1523661227483-0.post@n4.nabble.com>

Roberto Carna wrote
> Thanks to everybody...
> 
> I've reviewed what you tell me. I've executed "squid -k parse" and
> everything is ok, and I've restarted de Squid entire server.
> 
> When I use the server with IP#1, it works OK, is fast....but when I
> change its IP to IP#2 (the IP from the current Squid that I want to
> replace), the navigation is very very slow, just 20/30 concurrent
> users.
> 
> So I think the Squid configuration parameters are OK, because with
> IP#1 the proxy runs perfectly.
> 
> Why just an IP change affected the performance of web browsing ????
> Maybe because of something relative to Dansguardian ???
> 
> Thanks and regards !!!

>From your description, this looks like a loadbalancing issue, specifically
if you are using DNS round-robin to loadbalance the 2 servers. In most
cases, users will hit the second (or last IP), because DNS round-robin works
from the bottom up.

To get away from guess work, please examine all your log files (cache.log,
access.log,...etc) they will give you a clear picture of what really
happens.

Another quick guess: a "slow" squid is usually an indication of a
"repeatedly crashing" squid, due to overload or system configuration issues.

Logs are your friend.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Sat Apr 14 01:57:53 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 13 Apr 2018 19:57:53 -0600
Subject: [squid-users] Certificate transparency: problem for ssl-bumping,
 no effect, or?
In-Reply-To: <1523652063823-0.post@n4.nabble.com>
References: <5817C21D.5050003@tlinx.org>
 <87221443-0972-e504-f14b-7afc6b3bc771@measurement-factory.com>
 <181d5116-9c72-c752-8da5-26d67026a16d@gmail.com>
 <5c213454-0cee-51ac-7162-95be7ea6bcc6@measurement-factory.com>
 <1523652063823-0.post@n4.nabble.com>
Message-ID: <efbcc4ce-e0d7-b7e3-4704-aef0194de3b6@measurement-factory.com>

On 04/13/2018 02:41 PM, MK2018 wrote:

> Alex Rousskov wrote
>> Believe it or not, there are still many Squid use cases where bumping is
>> unnecessary. This includes, but is not limited to, HTTPS proxying cases
>> with peek/splice/terminate rules and environments where Squid possesses
>> the certificate issued by CAs trusted by clients. There are also IETF
>> attempts to standardize transmission of encrypted but proxy-cachable
>> content.
>>
>> I agree that Squid user base will shrink if nobody can bump 3rd party
>> traffic, but that reduction alone will not kill Squid.

> I would definitely disagree.

With what? Nothing you said afterwards contradicts what I said above.

Alex.


From xpro6000 at gmail.com  Sat Apr 14 03:30:36 2018
From: xpro6000 at gmail.com (xpro)
Date: Fri, 13 Apr 2018 23:30:36 -0400
Subject: [squid-users] IP auth, simple username/pass authentication,
	if ip not authorized?
Message-ID: <f24d50e0-7bf2-3ad0-36d5-27217a79d25e@gmail.com>

Right now I'm using Squid with IP based authentication. Would it be 
possible to also allow the user access if their IP is not allowed, but 
they provide username/pass?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180413/77c315bf/attachment.htm>

From xpro6000 at gmail.com  Sat Apr 14 05:36:04 2018
From: xpro6000 at gmail.com (xpro6000)
Date: Sat, 14 Apr 2018 01:36:04 -0400
Subject: [squid-users] IP auth, simple username/pass authentication,
 if ip not authorized?
In-Reply-To: <f24d50e0-7bf2-3ad0-36d5-27217a79d25e@gmail.com>
References: <f24d50e0-7bf2-3ad0-36d5-27217a79d25e@gmail.com>
Message-ID: <CAFoK1axY0-FGVPR19UhS5w-Rb4g8TbChTQpJMEwY64O7ZgwKNQ@mail.gmail.com>

This should do it

acl Allowed_IPs src "/etc/squid/Allowed_IPs.txt"
http_access allow Allowed_IPs

auth_param basic program /usr/lib/squid3/basic_ncsa_auth /etc/squid/passwd
auth_param basic children 5
auth_param basic realm Squid proxy-caching web server
auth_param basic credentialsttl 2 hours
auth_param basic casesensitive off

acl ncsa_users proxy_auth REQUIRED
http_access allow ncsa_users

acl SSL_ports port 443
acl Safe_ports port 80
acl Safe_ports port 21
acl Safe_ports port 443
acl Safe_ports port 70
acl Safe_ports port 210
acl Safe_ports port 1025-65535
acl Safe_ports port 280
acl Safe_ports port 488
acl Safe_ports port 591
acl Safe_ports port 777
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
#http_access allow localhost
http_access deny all
#http_port 3128
coredump_dir /var/spool/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320


On Fri, Apr 13, 2018 at 11:30 PM, xpro <xpro6000 at gmail.com> wrote:

> Right now I'm using Squid with IP based authentication. Would it be
> possible to also allow the user access if their IP is not allowed, but they
> provide username/pass?
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180414/4b270e55/attachment.htm>

From squid3 at treenet.co.nz  Sat Apr 14 06:06:02 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 Apr 2018 18:06:02 +1200
Subject: [squid-users] IP auth, simple username/pass authentication,
 if ip not authorized?
In-Reply-To: <CAFoK1axY0-FGVPR19UhS5w-Rb4g8TbChTQpJMEwY64O7ZgwKNQ@mail.gmail.com>
References: <f24d50e0-7bf2-3ad0-36d5-27217a79d25e@gmail.com>
 <CAFoK1axY0-FGVPR19UhS5w-Rb4g8TbChTQpJMEwY64O7ZgwKNQ@mail.gmail.com>
Message-ID: <e4d9dcca-f102-4e8b-e13c-28b493a42a63@treenet.co.nz>

Yes that should do it. But to let Squid do its job against DoS and such
security attacks ...

On 14/04/18 17:36, xpro6000 wrote:
> This should do it
> 

Move all these custom rules between here ...

> acl Allowed_IPs src "/etc/squid/Allowed_IPs.txt"
> http_access allow Allowed_IPs
> 
> auth_param basic program /usr/lib/squid3/basic_ncsa_auth /etc/squid/passwd
> auth_param basic children 5
> auth_param basic realm Squid proxy-caching web server
> auth_param basic credentialsttl 2 hours
> auth_param basic casesensitive off
> 
> acl ncsa_users proxy_auth REQUIRED
> http_access allow ncsa_users
> 

... and here.


> acl SSL_ports port 443
> acl Safe_ports port 80
> acl Safe_ports port 21
> acl Safe_ports port 443
> acl Safe_ports port 70
> acl Safe_ports port 210
> acl Safe_ports port 1025-65535
> acl Safe_ports port 280
> acl Safe_ports port 488
> acl Safe_ports port 591
> acl Safe_ports port 777
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager

... Down to this position after the recommended aka Best Practice)
security protections/rules.

Amos


From squid3 at treenet.co.nz  Sat Apr 14 06:14:06 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 Apr 2018 18:14:06 +1200
Subject: [squid-users] Certificate transparency: problem for ssl-bumping,
 no effect, or?
In-Reply-To: <b21c5e87-1f05-1849-766e-bbeb5400ae7e@integrafin.co.uk>
References: <5817C21D.5050003@tlinx.org>
 <87221443-0972-e504-f14b-7afc6b3bc771@measurement-factory.com>
 <181d5116-9c72-c752-8da5-26d67026a16d@gmail.com>
 <5c213454-0cee-51ac-7162-95be7ea6bcc6@measurement-factory.com>
 <1523652063823-0.post@n4.nabble.com>
 <b21c5e87-1f05-1849-766e-bbeb5400ae7e@integrafin.co.uk>
Message-ID: <158a5469-25a1-fec2-19df-6fc151d64cbc@treenet.co.nz>

On 14/04/18 10:03, Alex Crow wrote:
> 
>> Unless the protocol design changes to expose full URLs and/or MIME types,
>> nothing will replace Squid Bumping.
>>
>> That being said, we are headed to the vortex by 2018.05.01. Let's drown
>> together, while we yell and curse at Google!
>>
>> MK
>>
>>
>>
> 
> Erm, can someone elucidate the issue here? Can't see anything about this
> in the last year of mails from this list ;-)
> 

MK1018 is re-opening an old discussion from 2016.

The discussion started when TLS/1.3 and AES encrypted payloads were
still draft-only documents in IETF working groups.  So of course the
environment and what can or cannot be done is quite different now.


This just goes to show how much TLS and HTTPS environments are changing
and why our advice to always use the lastest release of Squid when
SSL-Bumping are so important. Anything even a year old discussing the
topic is outdated and possibly irrelevant.

Amos


From squid3 at treenet.co.nz  Sat Apr 14 07:59:20 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 Apr 2018 19:59:20 +1200
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <1523657157305-0.post@n4.nabble.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
 <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
 <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>
 <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>
 <CANAZdzUsamD-_P2gB9oQEbjR=Y0XEK0mnKUdYgjXtRGAxnPQUQ@mail.gmail.com>
 <f6a85fc5-50a3-9372-b487-72d8d42122fe@gmail.com>
 <CANAZdzVbZXA0_UpN037y4sSVjYkWHwsmtD0MQmuKxyqoxRO+9w@mail.gmail.com>
 <1523657157305-0.post@n4.nabble.com>
Message-ID: <b85ff422-a199-1760-0ad3-e4515225785a@treenet.co.nz>

On 14/04/18 10:05, MK2018 wrote:
> Aaron Turner wrote
>> Thanks Yuri.  That helps.  As for the "sslproxy_flags
>> DONT_VERIFY_PEER", yes I understand the risks.  In my specific case,
>> where my "users" are actually a bunch of automated web clients doing
>> some web crawling it's the right thing to do.
>> --
>> Aaron Turner
> 
> I tried using bump all myself with actual human beings (200+) using browsers
> ranging from Mozilla Firefox, Seamonkey, Chrome, to Safari and Opera.
> 
> I don't know why I had to face it, but with bump all I got many errors with
> many websites. It only worked with me like this:
> 
> http_port 3128 ssl-bump cert=/ssl_cert/myCA.pem 
> generate-host-certificates=on dynamic_cert_mem_cache_size=999MB
> sslcrtd_children 100
> ssl_bump none BadSSL
> ssl_bump server-first all
> 

FYI this is "server-first all". peek and splice before "bump all" is
similar but also different in ways that allow it to handle more problems
in better ways.


> Like you see, I'm using server-first word in place of bump word. This is the
> only way I got it to work with natural human browsing. I also could not use
> intercept mode, because every major browser considers it a crime to let it
> go! They would just spit all sorts of errors at user's face and have you
> clean the spitting up :D :D

You do need the browser to trust your CA certificate. This is an
absolute requirement of using SSL-Bump features. Always has been.

> 
> Of course, BadSSL above is the ACL for all sites using the new fiasco of
> hardcoded certificates (certificate-pinning), otherwise, they don't pass at
> all!
> 

Indeed, its quite sad situation really. Sites using actually secure TLS
have to downgrade to using the broken CA system for passing grades on
sites that test only the "TLS everywhere" groups over-hyped way of doing
things.

Amos


From squid3 at treenet.co.nz  Sat Apr 14 08:08:16 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 Apr 2018 20:08:16 +1200
Subject: [squid-users] Squid is very slow after moving to production
 environment
In-Reply-To: <CAG2Qp6uYh5VNn6Ey+c4w9bsowBPcs46LrdoC2jW3sbjM=Rd6Og@mail.gmail.com>
References: <CAG2Qp6tc=tVzQTGOe5b_mZtBrC2N8Z6fpmaOVhsh2XSQRJm04A@mail.gmail.com>
 <CAK2yrTZfyiH+cdL46TQ9_75Xg1LVY0Dvq6Ur9TVJA7MAFAb+og@mail.gmail.com>
 <CAG2Qp6tx87wEnfU4q3mtG_Oy+jg6bdnvNxxAeoLcZ_BWsqfqdQ@mail.gmail.com>
 <1523385135965-0.post@n4.nabble.com>
 <CAG2Qp6vosD6uRU9x1jf9+C7p-y9L-sDhHYL3E=O80i2ME23QuA@mail.gmail.com>
 <ba3f8066-0c97-f975-1347-74855bb29a53@treenet.co.nz>
 <CAG2Qp6uYh5VNn6Ey+c4w9bsowBPcs46LrdoC2jW3sbjM=Rd6Og@mail.gmail.com>
Message-ID: <69cde275-226d-e88b-2f06-b5fc19baacb0@treenet.co.nz>

On 13/04/18 05:55, Roberto Carna wrote:
> People, I can't test de new proxy in the production environment
> because I affect the users. I think is a good idea to add 10/15 users
> to my new proxy, and test it with users from my IT area. Maybe the
> problem is Dansguardian....I don't know.
> 
> I'm seeing pfSense use Squidguard in place of Dansguardian....is this
> a better option to block sites and with better performance???
> 

SquidGuard is deprecated software and no longer maintained. Modern Squid
can do almost everything it provided, and the remaining cases can/should
use ufdbguard instead.

DansGuardian is also in a similar position. I'm not sure if it is being
maintained still or not, there is an e2Guardian fork project that has a
lot more recent updates though.


As for performance it depends on what you have them doing:

* URL-rewrite helpers (eg SquidGuard) work by having Squid generate a
second transaction from the "redirected" URL results. That slows down
and uses more memory than regular request processing in Squid.

* chained proxies (eg DansGuardian) require the traffic to be formatted
as HTTP traffic during each hop delivery and re-parsed re-processed by
every proxy along the way. Which naturally adds a bunch of delay overheads.

As a general rule; the less you have SquidGuard doing the more efficient
it is. The less you have DansGuardian doing the more those re-parse
overheads reduce any performance gains.


Amos


From rafael.akchurin at diladele.com  Sat Apr 14 08:13:41 2018
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sat, 14 Apr 2018 08:13:41 +0000
Subject: [squid-users] squidclient and PROXY procotol enabled http_port
Message-ID: <HE1PR04MB1148553A99BAE858EC3C3DEA8FB20@HE1PR04MB1148.eurprd04.prod.outlook.com>

Greetings to everyone,

I have the following deployment:

-         Several Squid nodes configured with "http_port 3128 require-proxy-header"

-         One haproxy what relays TCP connections to nodes

-         squidclient that is run on each node manually

Browsers pointing to haproxy are correctly serviced by Squid nodes. Everything works as expected.
But trying to run squidclient to get mgr:idns results in the following.

    squidclient -v mgr:idns -h 127.0.0.1 -p 3128
    Request:
    GET 3128 HTTP/1.0
    User-Agent: squidclient/3.5.23
    Accept: */*
   Connection: close

Cache_log inidicates:
2018/04/14 10:04:38 kid1| PROXY client not permitted by ACLs from local=[::1]:3128 remote=[::1]:38854 FD 21 flags=1

That is good and fine; but after adding 127.0.0.1 into proxy_protocol_access directive error changes into:

2018/04/14 10:10:10 kid1| PROXY protocol error: invalid header from local=127.0.0.1:3128 remote=127.0.0.1:36648 FD 23 flags=1

Question
------------
Is it possible to ask squidclient to prepend the PROXY header to its request?


-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 17841 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180414/2b0031f9/attachment.bin>

From mohammed.khallaf at gmail.com  Sat Apr 14 08:51:51 2018
From: mohammed.khallaf at gmail.com (MK2018)
Date: Sat, 14 Apr 2018 01:51:51 -0700 (MST)
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <b85ff422-a199-1760-0ad3-e4515225785a@treenet.co.nz>
References: <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
 <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
 <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>
 <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>
 <CANAZdzUsamD-_P2gB9oQEbjR=Y0XEK0mnKUdYgjXtRGAxnPQUQ@mail.gmail.com>
 <f6a85fc5-50a3-9372-b487-72d8d42122fe@gmail.com>
 <CANAZdzVbZXA0_UpN037y4sSVjYkWHwsmtD0MQmuKxyqoxRO+9w@mail.gmail.com>
 <1523657157305-0.post@n4.nabble.com>
 <b85ff422-a199-1760-0ad3-e4515225785a@treenet.co.nz>
Message-ID: <1523695911887-0.post@n4.nabble.com>

Amos Jeffries wrote
> FYI this is "server-first all". peek and splice before "bump all" is
> similar but also different in ways that allow it to handle more problems
> in better ways.

I never really got to understand how to implement peek and splice verbs. I
was glad I could get away with server-first!

Any chance someone, or yourself, would rewrite a more detailed example of
how to use them?


Amos Jeffries wrote
> You do need the browser to trust your CA certificate. This is an
> absolute requirement of using SSL-Bump features. Always has been.

To my surprise back then, it was already trusted, but still browser had the
ability to detect interception and warn user about "something bad that is
going on"!

That is why I resorted to browser-aware, user-aware, and consented explicit
bumping. Others might envy me because in my network I managed to convince
management to apply a firewall rule to drop all traffic that does not come
from squid box :) :) which makes my setup unbreakable (and unaffordable to
fail).




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Sat Apr 14 09:53:18 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 Apr 2018 21:53:18 +1200
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <1523695911887-0.post@n4.nabble.com>
References: <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
 <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
 <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>
 <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>
 <CANAZdzUsamD-_P2gB9oQEbjR=Y0XEK0mnKUdYgjXtRGAxnPQUQ@mail.gmail.com>
 <f6a85fc5-50a3-9372-b487-72d8d42122fe@gmail.com>
 <CANAZdzVbZXA0_UpN037y4sSVjYkWHwsmtD0MQmuKxyqoxRO+9w@mail.gmail.com>
 <1523657157305-0.post@n4.nabble.com>
 <b85ff422-a199-1760-0ad3-e4515225785a@treenet.co.nz>
 <1523695911887-0.post@n4.nabble.com>
Message-ID: <6325f563-3dc7-dc42-7973-b9a245b01996@treenet.co.nz>

On 14/04/18 20:51, MK2018 wrote:
> Amos Jeffries wrote
>> FYI this is "server-first all". peek and splice before "bump all" is
>> similar but also different in ways that allow it to handle more problems
>> in better ways.
> 
> I never really got to understand how to implement peek and splice verbs. I
> was glad I could get away with server-first!
> 
> Any chance someone, or yourself, would rewrite a more detailed example of
> how to use them?
> 

Peek is to look without touching the bytes on-wire. They may be relayed
as-is to make progress in the TLS sequence. So bump maybe cannot happen
later, but splice always can.

Stare is to look at the bytes on-wire and synthesize anything needing to
be sent to server. So bump can always work later, but splice maybe cannot.

Splice is to switch to opaque tunneling of the traffic immediately.

Bump is to MITM the certificate exchange injecting a fake server cert
for the clients use and stripping out any features Squid cannot support.


The old server-first receives the TCP details from the client. Then uses
that *alone* to establish a connection to the server based on TLS
features supported by your Squid. Then receives and attempts to respond
to the clientHello using what the serverHello contained.
 It requires that the client is capable of handling the same feature set
as Squid, or at least the TLS features chosen by the server from the set
Squid offered.


The authoritative document about all this is
<https://wiki.squid-cache.org/Features/SslPeekAndSplice#Processing_steps>.
That has had a few re-writes to clarify.

Which parts (if any in the current text) are you getting confused or
lost by?


Amos


From squid3 at treenet.co.nz  Sat Apr 14 09:59:20 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 Apr 2018 21:59:20 +1200
Subject: [squid-users] squidclient and PROXY procotol enabled http_port
In-Reply-To: <HE1PR04MB1148553A99BAE858EC3C3DEA8FB20@HE1PR04MB1148.eurprd04.prod.outlook.com>
References: <HE1PR04MB1148553A99BAE858EC3C3DEA8FB20@HE1PR04MB1148.eurprd04.prod.outlook.com>
Message-ID: <1b539c34-6993-4ade-1089-682347682154@treenet.co.nz>

On 14/04/18 20:13, Rafael Akchurin wrote:
> Question
> ------------
> Is it possible to ask squidclient to prepend the PROXY header to its request?
> 

It should be relatively easy to add, but has not been coded yet if thats
what you mean. Patches welcome.

Amos


From mohammed.khallaf at gmail.com  Sat Apr 14 11:22:32 2018
From: mohammed.khallaf at gmail.com (MK2018)
Date: Sat, 14 Apr 2018 04:22:32 -0700 (MST)
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <6325f563-3dc7-dc42-7973-b9a245b01996@treenet.co.nz>
References: <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
 <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>
 <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>
 <CANAZdzUsamD-_P2gB9oQEbjR=Y0XEK0mnKUdYgjXtRGAxnPQUQ@mail.gmail.com>
 <f6a85fc5-50a3-9372-b487-72d8d42122fe@gmail.com>
 <CANAZdzVbZXA0_UpN037y4sSVjYkWHwsmtD0MQmuKxyqoxRO+9w@mail.gmail.com>
 <1523657157305-0.post@n4.nabble.com>
 <b85ff422-a199-1760-0ad3-e4515225785a@treenet.co.nz>
 <1523695911887-0.post@n4.nabble.com>
 <6325f563-3dc7-dc42-7973-b9a245b01996@treenet.co.nz>
Message-ID: <1523704952698-0.post@n4.nabble.com>

Amos Jeffries wrote
> Which parts (if any in the current text) are you getting confused or
> lost by?

It is not about confusion as much as it is about syntax. Since I'm always
bumping to fight unwanted user traffic / analyze traffic consumption, I
would need to use 'stare' verb. But, I had only trouble figuring out the
correct syntax.

That said, I had used squid effectively and perfectly for more than a year
before I could understand (on my own) how to craft an 'allow' or 'deny' line
that contains all of: source acl, dst acl, connection method, HTTP command,
TCP port, excluded dst acl, excluded HTTP command! There was no clear and to
the point instructions on how to order those elements and correctly use
them.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From Antony.Stone at squid.open.source.it  Sat Apr 14 11:32:50 2018
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 14 Apr 2018 13:32:50 +0200
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <1523704952698-0.post@n4.nabble.com>
References: <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
 <6325f563-3dc7-dc42-7973-b9a245b01996@treenet.co.nz>
 <1523704952698-0.post@n4.nabble.com>
Message-ID: <201804141332.50676.Antony.Stone@squid.open.source.it>

On Saturday 14 April 2018 at 13:22:32, MK2018 wrote:

> I had used squid effectively and perfectly for more than a year before I
> could understand (on my own) how to craft an 'allow' or 'deny' line that
> contains all of: source acl, dst acl, connection method, HTTP command, TCP
> port, excluded dst acl, excluded HTTP command! There was no clear and to the
> point instructions on how to order those elements and correctly use them.

https://wiki.squid-cache.org/SquidFaq/SquidAcl

"An access list rule consists of an allow or deny keyword, followed by a list 
of ACL element names. 

An access list consists of one or more access list rules. 

Access list rules are checked in the order they are written. List searching 
terminates as soon as one of the rules is a match. 

If a rule has multiple ACL elements, it uses AND logic. In other words, all 
ACL elements of the rule must be a match in order for the rule to be a match."


"To summarize the ACL logics can be described as: (note: AND/OR below is just 
for illustration, not part of the syntax) 

http_access allow|deny acl AND acl AND ...

        OR

http_access allow|deny acl AND acl AND ...

        OR

..."

I thought that makes things quite clear.

https://wiki.squid-cache.org/SquidFaq/SquidAcl#ACL_elements has a 
comprehensive list of the things you can check for in ACLs.
 

Antony.

-- 
There's a good theatrical performance about puns on in the West End.  It's a 
play on words.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From akismpa at gmail.com  Sat Apr 14 18:08:28 2018
From: akismpa at gmail.com (Panagiotis Bariamis)
Date: Sat, 14 Apr 2018 21:08:28 +0300
Subject: [squid-users] Secure Web Proxy Stress Testing
In-Reply-To: <CAPxN_PVTtPL8ismf5p2vut9LYZVa9oBfH=2-1-1x6NDE8aJpZw@mail.gmail.com>
References: <CAPxN_PVjJ+QKxLYU=rRJa00Mec80TWqqvF5WNJrD0-b7+-jesQ@mail.gmail.com>
 <3e2af5d3-8292-c509-7a3c-7879032864b8@measurement-factory.com>
 <CAPxN_PXNbZfZKz2Sjdt=biq6OgqSRnjm31kn7ctZPXBKcoCruA@mail.gmail.com>
 <af73e08f-43fe-f2c5-12a2-b31360db0129@measurement-factory.com>
 <CAPxN_PVTtPL8ismf5p2vut9LYZVa9oBfH=2-1-1x6NDE8aJpZw@mail.gmail.com>
Message-ID: <CAPxN_PWzj3HNN=_-rG_VogOptP=SYxsoMopzYSKsdSPf8mSUcA@mail.gmail.com>

Thank you ,
Bariamis Panagiotis

On Tue, Apr 10, 2018 at 10:14 PM, Panagiotis Bariamis <akismpa at gmail.com>
wrote:

> Thank you for the clarification.
>
> On Tue, Apr 10, 2018, 21:11 Alex Rousskov <rousskov at measurement-factory.
> com> wrote:
>
>>
>>
>> >Polygraph supports HTTPS proxies and HTTPS servers. IIRC, Polygraph v5
>> >supports the combination of the two: TLS inside TLS (because HTTP/2
>> >support essentially required that). I am not sure about Polygraph v4.
>> >The workload I sketched uses HTTPS proxies and plain origin servers.
>>
>>
>> Hello Alex ,
>> I am trying to use Polygraph as suggested .
>> However  squid servers are part of the University Network so routing
>> changes are not possible as suggested by polymix-4.pg.
>> Which test you think I should use without routing changes (poly server
>> and client will have just a public ip and the regular loopback inteface)  ?
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180414/63a15f9c/attachment.htm>

From eliezer at ngtech.co.il  Sat Apr 14 23:13:32 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 15 Apr 2018 02:13:32 +0300
Subject: [squid-users] squidclient and PROXY procotol enabled http_port
Message-ID: <03e101d3d446$353325a0$9f9970e0$@ngtech.co.il>

Would a nc(netcat) bash based script that will run this kind of request
would be good enough?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
Rafael Akchurin
Sent: Saturday, April 14, 2018 11:14
To: squid-users (squid-users at lists.squid-cache.org)
<squid-users at lists.squid-cache.org>
Subject: [squid-users] squidclient and PROXY procotol enabled http_port

Greetings to everyone,

I have the following deployment:

-         Several Squid nodes configured with "http_port 3128
require-proxy-header"

-         One haproxy what relays TCP connections to nodes

-         squidclient that is run on each node manually

Browsers pointing to haproxy are correctly serviced by Squid nodes.
Everything works as expected.
But trying to run squidclient to get mgr:idns results in the following.

    squidclient -v mgr:idns -h 127.0.0.1 -p 3128
    Request:
    GET 3128 HTTP/1.0
    User-Agent: squidclient/3.5.23
    Accept: */*
   Connection: close

Cache_log inidicates:
2018/04/14 10:04:38 kid1| PROXY client not permitted by ACLs from
local=[::1]:3128 remote=[::1]:38854 FD 21 flags=1

That is good and fine; but after adding 127.0.0.1 into proxy_protocol_access
directive error changes into:

2018/04/14 10:10:10 kid1| PROXY protocol error: invalid header from
local=127.0.0.1:3128 remote=127.0.0.1:36648 FD 23 flags=1

Question
------------
Is it possible to ask squidclient to prepend the PROXY header to its
request?





From rafael.akchurin at diladele.com  Mon Apr 16 11:27:22 2018
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Mon, 16 Apr 2018 11:27:22 +0000
Subject: [squid-users] [icap] YouTube filtering module (URL redirector) for
 Squid to limit videos, categories and channels using YouTube API v3.
Message-ID: <HE1PR04MB11489F6E7748B97166F97AF08FB00@HE1PR04MB1148.eurprd04.prod.outlook.com>

Greetings all,

We have added an experimental YouTube guard module in this new early build of Web Safety ICAP web filter for Squid proxy.
This module allows administrator to limit the watched videos on YouTube by video category, channel ID and video ID.  Status of the module is experimental and we need your feedback to decide it this module is worth including into production build.

The module is implemented as Squid's URL redirector. You would need to get the free YouTube API v3 token from Google as explained in https://developers.google.com/youtube/v3/docs .  UI of Web Safety allows to configure squid.conf, list of allowed/blocked categories, channels and videos from the browser.

Completely pre-configured Virtual Appliance with Squid proxy 3.5.27 and Web Safety 6.3 is available from http://packages.diladele.com/websafety/6.3.0.C8FD/va/ubuntu16/websafety.zip

Please share your thoughts and ideas on YouTube filtering module at support at diladele.com.
Do you think it is helpful or at all needed?

Best regards,
Rafael Akchurin
Diladele B.V.
https://www.diladele.com

-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 17554 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180416/9aa8e998/attachment.bin>

From rousskov at measurement-factory.com  Mon Apr 16 21:41:29 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 16 Apr 2018 15:41:29 -0600
Subject: [squid-users] Secure Web Proxy Stress Testing
In-Reply-To: <CAPxN_PWzj3HNN=_-rG_VogOptP=SYxsoMopzYSKsdSPf8mSUcA@mail.gmail.com>
References: <CAPxN_PVjJ+QKxLYU=rRJa00Mec80TWqqvF5WNJrD0-b7+-jesQ@mail.gmail.com>
 <3e2af5d3-8292-c509-7a3c-7879032864b8@measurement-factory.com>
 <CAPxN_PXNbZfZKz2Sjdt=biq6OgqSRnjm31kn7ctZPXBKcoCruA@mail.gmail.com>
 <af73e08f-43fe-f2c5-12a2-b31360db0129@measurement-factory.com>
 <CAPxN_PVTtPL8ismf5p2vut9LYZVa9oBfH=2-1-1x6NDE8aJpZw@mail.gmail.com>
 <CAPxN_PWzj3HNN=_-rG_VogOptP=SYxsoMopzYSKsdSPf8mSUcA@mail.gmail.com>
Message-ID: <d274801f-a0a6-b6b4-980a-53a2c8f92ac6@measurement-factory.com>

On 04/14/2018 12:08 PM, Panagiotis Bariamis wrote:

>     On Tue, Apr 10, 2018, 21:11 Alex Rousskov wrote:
>> Polygraph supports HTTPS proxies and HTTPS servers. IIRC, Polygraph v5
>> supports the combination of the two: TLS inside TLS (because HTTP/2
>> support essentially required that). I am not sure about Polygraph v4.
>> The workload I sketched uses HTTPS proxies and plain origin servers.


>         I am trying to use Polygraph as suggested .
>         However? squid servers are part of the University Network so
>         routing changes are not possible as suggested by polymix-4.pg
>         Which test you think I should use without routing changes (poly
>         server and client will have just a public ip and the regular
>         loopback inteface)? ?

This mailing list is not the right place for Polygraph support[1], but I
recommend writing your own workload for your own tests: Start with
simple.pg, use the IP addresses you want to use, and then add more bells
and whistles as needed (and as you get comfortable with the tool), one
change at a time. This is the approach used by the tutorial[2] as well.

  [1] http://lists.web-polygraph.org/mailman/listinfo/users
  [2] http://www.web-polygraph.org/test/docs/userman/simple.html


Cheers,

Alex.


From rafael.akchurin at diladele.com  Tue Apr 17 07:09:45 2018
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 17 Apr 2018 07:09:45 +0000
Subject: [squid-users] squidclient and PROXY procotol enabled http_port
	(solved)
Message-ID: <HE1PR04MB1148D7BFDD1CD3148FC1E6888FB70@HE1PR04MB1148.eurprd04.prod.outlook.com>

Hello Amos, Eliezer and all,

Thanks a lot for your ideas/suggestions. Decided to go easy way:


-         added another "http_port 127.0.0.1:3128" directive to squid.conf (without require-proxy-header option)

-         directed squidclient binary to use it

Hope no side effects from this configuration.

Best regards,
Rafael Akchurin
Diladele B.V.

--
Please take a look at https://www.diladele.com - ICAP web filtering plugin for Squid proxy.


From: Rafael Akchurin
Sent: Saturday, April 14, 2018 10:14 AM
To: squid-users (squid-users at lists.squid-cache.org) <squid-users at lists.squid-cache.org>
Subject: squidclient and PROXY procotol enabled http_port

Greetings to everyone,

I have the following deployment:

-         Several Squid nodes configured with "http_port 3128 require-proxy-header"

-         One haproxy what relays TCP connections to nodes

-         squidclient that is run on each node manually

Browsers pointing to haproxy are correctly serviced by Squid nodes. Everything works as expected.
But trying to run squidclient to get mgr:idns results in the following.

    squidclient -v mgr:idns -h 127.0.0.1 -p 3128
    Request:
    GET 3128 HTTP/1.0
    User-Agent: squidclient/3.5.23
    Accept: */*
   Connection: close

Cache_log inidicates:
2018/04/14 10:04:38 kid1| PROXY client not permitted by ACLs from local=[::1]:3128 remote=[::1]:38854 FD 21 flags=1

That is good and fine; but after adding 127.0.0.1 into proxy_protocol_access directive error changes into:

2018/04/14 10:10:10 kid1| PROXY protocol error: invalid header from local=127.0.0.1:3128 remote=127.0.0.1:36648 FD 23 flags=1

Question
------------
Is it possible to ask squidclient to prepend the PROXY header to its request?


-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 23010 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180417/79c4d965/attachment.bin>

From jimoe at sohnen-moe.com  Tue Apr 17 20:50:01 2018
From: jimoe at sohnen-moe.com (James Moe)
Date: Tue, 17 Apr 2018 13:50:01 -0700
Subject: [squid-users] Access Denied for manager
Message-ID: <be83f4d3-7991-48ee-695b-1b2f02717a42@sohnen-moe.com>

Hello,
  squid v3.5.21
  linux v4.4.120-45-default x86_64

  The "manager" is suddenly denied access. I am not aware of any recent
updates. This did work 3 days ago.
  Is the ACL correct?

acl manager_admin src 192.168.69.115
#
acl localnet src fc00::/7
acl localnet src fe80::/10
#
# https, cups
acl SSL_ports port 443
acl SSL_ports port 631
#
# Jumpline cPanel ports
acl SSL_ports port 2083
acl SSL_ports port 2096
#
# sma-nas-02, cgatePro, webadmin
acl SSL_ports port 5000
acl SSL_ports port 5001
acl SSL_ports port 9010
acl SSL_ports port 9100
acl SSL_ports port 10000
#
acl Safe_ports port 80
acl Safe_ports port 21
acl Safe_ports port 443
acl Safe_ports port 563
acl Safe_ports port 631
acl Safe_ports port 70
acl Safe_ports port 210
acl Safe_ports port 1025-65535
acl Safe_ports port 280
acl Safe_ports port 488
acl Safe_ports port 591
acl Safe_ports port 777
acl Safe_ports port 9100
#
acl CONNECT method CONNECT
acl localnet src 192.168.69.0/24

access_log /var/log/squid/access.log

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow manager_admin
http_access allow manager localhost
http_access deny manager
http_access allow localnet
http_access deny all



-- 
James Moe
moe dot james at sohnen-moe dot com
520.743.3936
Think.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 181 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180417/f88bd60a/attachment.sig>

From squid3 at treenet.co.nz  Wed Apr 18 07:08:11 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 18 Apr 2018 19:08:11 +1200
Subject: [squid-users] Access Denied for manager
In-Reply-To: <be83f4d3-7991-48ee-695b-1b2f02717a42@sohnen-moe.com>
References: <be83f4d3-7991-48ee-695b-1b2f02717a42@sohnen-moe.com>
Message-ID: <ce994a5e-01f9-fee8-9990-5f802242165b@treenet.co.nz>

On 18/04/18 08:50, James Moe wrote:
> Hello,
>   squid v3.5.21
>   linux v4.4.120-45-default x86_64
> 
>   The "manager" is suddenly denied access. I am not aware of any recent
> updates. This did work 3 days ago.
>   Is the ACL correct?

Maybe, maybe not.

> 
> acl manager_admin src 192.168.69.115

Yet you have two other localnet ranges this machine can potentially be
part of:

> #
> acl localnet src fc00::/7
> acl localnet src fe80::/10
...
> acl localnet src 192.168.69.0/24

If the manager_admin machine ever tries to use those IPv6 localnet it
will not be permitted access to the "manager" reports. It can only
access them over its IP address in that manager_admin ACL.

For better ideas look as what your access.log states when the manager
report is attempted.

> 
> access_log /var/log/squid/access.log
> 
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow manager_admin
> http_access allow manager localhost
> http_access deny manager
> http_access allow localnet
> http_access deny all
> 


Amos


From squid3 at treenet.co.nz  Wed Apr 18 12:43:18 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 19 Apr 2018 00:43:18 +1200
Subject: [squid-users] [squid-announce] [ADVISORY] SQUID-2018:3 Denial of
 Service issue in ESI Response processing.
Message-ID: <6e49b05e-dcef-f217-f0a8-b304d73cd780@treenet.co.nz>

__________________________________________________________________

    Squid Proxy Cache Security Update Advisory SQUID-2018:3
__________________________________________________________________

Advisory ID:        SQUID-2018:3
Date:               April 18, 2018
Summary:            Denial of Service issue
                    in ESI Response processing.
Affected versions:  Squid 3.1.12.2 -> 3.1.23
                    Squid 3.2.0.8 -> 3.2.14
                    Squid 3.3 -> 4.0.12
Fixed in version:   Squid 4.0.13
__________________________________________________________________

    http://www.squid-cache.org/Advisories/SQUID-2018_3.txt
    http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-1172
__________________________________________________________________

Problem Description:

 Due to incorrect pointer handling Squid is vulnerable to denial
 of service attack when processing ESI responses.

__________________________________________________________________

Severity:

 This problem allows a remote server delivering ESI responses
 to trigger a denial of service for all clients accessing the
 Squid service.

 This problem is limited to Squid operating as reverse proxy.

__________________________________________________________________

Updated Packages:

 This bug is fixed by Squid version 4.0.13.

 In addition, patches addressing this problem for the stable
 releases can be found in our patch archives:

Squid 3.5:
 <http://www.squid-cache.org/Versions/v3/3.5/changesets/SQUID-2018_3.patch>

 If you are using a prepackaged version of Squid then please refer
 to the package vendor for availability information on updated
 packages.

__________________________________________________________________

Determining if your version is vulnerable:

 All Squid-2.x and older are not vulnerable.

 All Squid-3.0 and older version are not vulnerable.

 All Squid built with --disable-esi are not vulnerable.

 All Squid-3.x versions up to and including 3.4.14 built with
 --disable-ssl are not vulnerable.

 All Squid-3.x versions up to and including 3.4.14 built without
 --enable-ssl are not vulnerable.

 All Squid-3.x versions up to and including 3.5.27 built without
 --enable-esi are not vulnerable.

 All Squid-3.1.12.2 and later versions up to and including
 Squid-3.1.23 built with --enable-esi and--enable-ssl, and being
 used for reverse-proxy are vulnerable.

 All Squid-3.2.0.8 and later versions up to and including
 Squid-3.2.14 built with --enable-esi and --enable-ssl, and being
 used for reverse-proxy are vulnerable.

 All Squid-3.3 and later versions up to and including
 Squid-3.3.14 built with --enable-esi and --enable-ssl, and being
 used for reverse-proxy are vulnerable.

 All Squid-3.4 and later versions up to and including
 Squid-3.4.14 built with --enable-esi and --enable-ssl, and being
 used for reverse-proxy are vulnerable.

 All Squid-3.5 versions up to and including 3.5.27 built without
 --with-openssl are not vulnerable.

 All Squid-3.5 and later versions up to and including 3.5.27 built
 with --enable-esi and --with-openssl, and being used for
 reverse-proxy are vulnerable.

 All Squid-4 versions up to and including 4.0.12 built without
 --with-openssl are not vulnerable.

 All Squid-4 versions up to and including 4.0.12 built with
 --with-openssl and being used for reverse-proxy are vulnerable.

__________________________________________________________________

Workarounds:

Either;

 Build Squid with --disable-esi

Or,

 Build Squid-3.1 to 3.4.14 or later with "--disable-ssl"

Or,

 Build Squid-3.5 or later with "--without-openssl"

__________________________________________________________________

Contact details for the Squid project:

 For installation / upgrade support on binary packaged versions
 of Squid: Your first point of contact should be your binary
 package vendor.

 If your install and build Squid from the original Squid sources
 then the squid-users at lists.squid-cache.org mailing list is your
 primary support point. For subscription details see
 <http://www.squid-cache.org/Support/mailing-lists.html>.

 For reporting of non-security bugs in the latest STABLE release
 the squid bugzilla database should be used
 <http://bugs.squid-cache.org/>.

 For reporting of security sensitive bugs send an email to the
 squid-bugs at lists.squid-cache.org mailing list. It's a closed
 list (though anyone can post) and security related bug reports
 are treated in confidence until the impact has been established.

__________________________________________________________________

Credits:

 This vulnerability was discovered by Michael Marshall of Trend
 Micro working with Trend Micro's Zero Day Initiative.

 Fixed by Christos Tsantilas on behalf of Measurement Factory.

__________________________________________________________________

Revision history:

 2018-04-16 18:20:15 UTC Initial Report
 2018-04-16 22:02:25 UTC Patches Released
 2018-04-18 12:28:00 UTC Advisory Released
__________________________________________________________________
END
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Thu Apr 19 07:15:12 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 19 Apr 2018 19:15:12 +1200
Subject: [squid-users] Access Denied for manager
In-Reply-To: <cdd44377-1f36-6070-7f00-d99eb9cdeecb@sohnen-moe.com>
References: <be83f4d3-7991-48ee-695b-1b2f02717a42@sohnen-moe.com>
 <ce994a5e-01f9-fee8-9990-5f802242165b@treenet.co.nz>
 <cdd44377-1f36-6070-7f00-d99eb9cdeecb@sohnen-moe.com>
Message-ID: <7fbf4b36-beef-654d-d48c-3b94194d8b5b@treenet.co.nz>

[ please keep replies on-list so others having this problem can also get
answers. ]


On 19/04/18 05:39, James Moe wrote:
> On 04/18/2018 12:08 AM, Amos Jeffries wrote:
> 
>> For better ideas look as what your access.log states when the manager
>> report is attempted.
>>
>   I commented the IPv6 "localnet" ACLs, reloaded squid.
>   Still denied access. I do not see any new information here:
> 
> 1524072494.191      1 192.168.69.246 TCP_DENIED/403 4361 GET
> http://sma-server3:3128/squid-internal-mgr/info - HIER_NONE/- text/html
> 1524072494.193   5508 192.168.69.115 TCP_MISS/403 4469 GET
> http://proxy1.sma.com:3128/squid-internal-mgr/info -
> HIER_DIRECT/192.168.69.246 text/html


I see you have a forwarding loop:

 192.168.69.115 -> Squid -> 192.168.69.246 -> Squid -> DENIED.


That 192.168.69.115 is trying to fetch "http://proxy1.sma.com". But the
Squid appears to think its hostname is "sma-server3".


Hmm, "sma-server" name rings a bell. I see you brought this same issue
up on 1 Nov 2017 as well and we do not seem to have resolved the issue then.

[ the following requires an understanding of host vs domain vs FQDN names
<https://support.suso.com/supki/What_is_the_difference_between_a_hostname_and_a_domain_name>
]


To get any type of access to Squid internal resources working properly
you need both Squid and the external tools to be aware of what its
machines host name is AND that hostname to be publicly resolvable -
meaning it also has to be an FQDN.

 - for the icons ANY receiving Squid can (and usually will) respond if
it has the relevant icon.

 - for manager reports ONLY the individual proxy targeted by the URL
will respond with a successful report. The reasons for that should be
obvious.

If the machines hostname service is broken and cannot be fixed. For
example; producing something like "sma-server3" instead of the proper
sma-server3.sma.com hostname. You can workaround that with
visible_hostname and/or unique_hostname in squid.conf.
 <http://www.squid-cache.org/Doc/config/visible_hostname/>
 <http://www.squid-cache.org/Doc/config/unique_hostname/>

Be aware that any tools running on the localhost will probably still use
the machines hostname and may now appear to be broken when they "worked"
before. Those directives in squid.conf are _workarounds_ not fixes.

Amos


From fourir.akbar at gmail.com  Thu Apr 19 16:05:30 2018
From: fourir.akbar at gmail.com (fourirakbar)
Date: Thu, 19 Apr 2018 09:05:30 -0700 (MST)
Subject: [squid-users] Intercept Squid Proxy with Docker
Message-ID: <1524153930499-0.post@n4.nabble.com>

I'm using Squid version 3.5

My goal is to create a transparent proxy using docker container for each
user, so I don't need to configure manual proxy setting in user.

*So this is what I want:* 
  1. Guest login to the system (done)
  2. After login, system noted ID and IP (done)
  3. In other machine (I call it "server docker"), I create a container with
--name ID and IP and --publish specific port from the guest (done)
  4. Create iptables for the user with specific IP and PORT (done, but I'm
not sure)
  5. If guest want to connect to the internet, guest must be through that
container (not yet)

*Example:*
 ID : 5114100100
 IP CLIENT : 10.151.36.227
 IP server docker : 10.151.36.134
 PORT : 9001

*First step: I create an image*
    docker run -d -it --net bridge --name 5114100100_10.151.36.227 --publish
9001:3128 fourirakbar/debian-squid:version2

*Second step: I create rules with iptables*
    iptables -t nat -A PREROUTING -i wlp3s0 -s 10.151.36.227 -p tcp --dport
80 -j DNAT --to 10.151.36.134:9001
    iptables -t nat -A PREROUTING -i wlp3s0 -s 10.151.36.134 -p tcp --dport
443 -j DNAT --to 10.151.36.134:9001

*first my squid.conf in container*
    visible_hostname X450LD
    http_port 3128
    http_access allow all

*Then, if I set proxy setting manual in browser client (I use firefox)*
    HTTP Proxy 10.151.36.134
    Port 9001

it's working fine
===================================

Now here's the problem:

I want to make in transparent. I tried every tutorial / github other user
and I make squid.conf in container like this:

    acl SUBNETAJK src 10.151.36.0/24 
    acl client1 src 10.151.36.227
    
    acl SSL_ports port 443 
    acl Safe_ports port 80 # http 
    acl Safe_ports port 21 # ftp 
    acl Safe_ports port 443 # https 
    acl Safe_ports port 70 # gopher 
    acl Safe_ports port 210 # wais 
    acl Safe_ports port 1025-65535 # unregistered ports 
    acl Safe_ports port 280 # http-mgmt 
    acl Safe_ports port 488 # gss-http 
    acl Safe_ports port 591 # filemaker 
    acl Safe_ports port 777 # multiling http 
    acl Safe_ports port 445 # windows update 
    acl CONNECT method CONNECT 
    
    http_port 3128
    http_port 3129 intercept 
    http_access allow SUBNETAJK
    http_access deny all
    http_access deny CONNECT !SSL_ports
    http_access deny !Safe_ports 
    
    never_direct allow all 
    
    cache_mem 64 MB 
    cache_swap_low 98 
    cache_swap_high 99 
    
    refresh_pattern ^ftp:           1440    20%     10080
    refresh_pattern ^gopher:        1440    0%      1440
    refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
    refresh_pattern .               0       20%     4320

    shutdown_lifetime 1 second 
    visible_hostname X450LD

*Then I change `--publsh to 3129`. I run again `docker run` like this:*

    docker run -d -it --net bridge --name 5114100123_10.151.36.227 --publish
9001:3129 fourirakbar/debian-squid:version2

And I didn't change rules of iptables. If I do `iptables -t nat -L` in
server docker like this:

    Chain PREROUTING (policy ACCEPT)
    target     prot opt source               destination         
    DOCKER     all  --  anywhere             anywhere             ADDRTYPE
match dst-type LOCAL
    DNAT       tcp  --  10.151.36.227        anywhere             tcp
dpt:https to:10.151.36.134:9001
    DNAT       tcp  --  10.151.36.227        anywhere             tcp
dpt:http to:10.151.36.134:9001
    
    Chain INPUT (policy ACCEPT)
    target     prot opt source               destination         
    
    Chain OUTPUT (policy ACCEPT)
    target     prot opt source               destination         
    DOCKER     all  --  anywhere            !127.0.0.0/8          ADDRTYPE
match dst-type LOCAL
    
    Chain POSTROUTING (policy ACCEPT)
    target     prot opt source               destination         
    MASQUERADE  all  --  172.17.0.0/16        anywhere            
    MASQUERADE  all  --  172.18.0.0/16        anywhere            
    MASQUERADE  tcp  --  172.17.0.2           172.17.0.2           tcp
dpt:3129
    
    Chain DOCKER (2 references)
    target     prot opt source               destination         
    RETURN     all  --  anywhere             anywhere            
    RETURN     all  --  anywhere             anywhere            
    DNAT       tcp  --  anywhere             anywhere             tcp
dpt:9001 to:172.17.0.2:3129

When I try to open http website like `elearning.if.its.ac.id` or
`monta.if.its.ac.id`, it got error *unable to forward this request at this
time*

Anyone know how to fix this? I wonder that someone can help me
Thankyou very much

And this is access.log
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377437/accesslog.png> 



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From jimoe at sohnen-moe.com  Thu Apr 19 22:02:12 2018
From: jimoe at sohnen-moe.com (James Moe)
Date: Thu, 19 Apr 2018 15:02:12 -0700
Subject: [squid-users] Access Denied for manager
In-Reply-To: <7fbf4b36-beef-654d-d48c-3b94194d8b5b@treenet.co.nz>
References: <be83f4d3-7991-48ee-695b-1b2f02717a42@sohnen-moe.com>
 <ce994a5e-01f9-fee8-9990-5f802242165b@treenet.co.nz>
 <cdd44377-1f36-6070-7f00-d99eb9cdeecb@sohnen-moe.com>
 <7fbf4b36-beef-654d-d48c-3b94194d8b5b@treenet.co.nz>
Message-ID: <85363e60-98e2-f185-340e-e5d501086370@sohnen-moe.com>

On 04/19/2018 12:15 AM, Amos Jeffries wrote:

> I see you have a forwarding loop:
> 
>  192.168.69.115 -> Squid -> 192.168.69.246 -> Squid -> DENIED.
> 
> That 192.168.69.115 is trying to fetch "http://proxy1.sma.com". But the
> Squid appears to think its hostname is "sma-server3".
>
  Ah.
  It would seem the proxy configuration for opensuse LEAP 42.3 is a bit,
um, defective. I have the local domain listed as do-not-proxy; yet it
does anyway.
  Using a browser with the same proxy configuration, a manual config,
works correctly.

-- 
James Moe
moe dot james at sohnen-moe dot com
520.743.3936
Think.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 181 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180419/671cc22b/attachment.sig>

From jun357572957zhao at hotmail.com  Fri Apr 20 02:50:10 2018
From: jun357572957zhao at hotmail.com (=?gb2312?B?1dQgv6E=?=)
Date: Fri, 20 Apr 2018 02:50:10 +0000
Subject: [squid-users] =?gb2312?b?SG93IHRvIGNvbmZpZ3VyZSBtdWx0aXBsZSBpY2Fw?=
 =?gb2312?b?IHByb3RvY29sIHNlcnZpY2Vzo78=?=
Message-ID: <CY4PR22MB03609B935F30A6EF64BD5F7998B40@CY4PR22MB0360.namprd22.prod.outlook.com>

Thanks for reading my mail.
My question is whether one squid as icap client can configure multiple icap protocol services or not ..
If squid can , how to configure ?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180420/5bb0339a/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr 20 03:52:40 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Apr 2018 15:52:40 +1200
Subject: [squid-users] Intercept Squid Proxy with Docker
In-Reply-To: <1524153930499-0.post@n4.nabble.com>
References: <1524153930499-0.post@n4.nabble.com>
Message-ID: <74e31a22-501f-9b76-a278-f502f271cdf7@treenet.co.nz>

On 20/04/18 04:05, fourirakbar wrote:
> I'm using Squid version 3.5
> 
> My goal is to create a transparent proxy using docker container for each
> user, so I don't need to configure manual proxy setting in user.

Why have a different proxy per-user instead of a shared proxy?

The point of proxying is generally one of two use-cases:

1) centralized access control. Per-user proxies are not centralized.

2) caching. Which is done by the users Browser. Middle proxies like
Squid adds nothing for an individual.


> 
> *So this is what I want:* 
>   1. Guest login to the system (done)
>   2. After login, system noted ID and IP (done)
>   3. In other machine (I call it "server docker"), I create a container with
> --name ID and IP and --publish specific port from the guest (done)
>   4. Create iptables for the user with specific IP and PORT (done, but I'm
> not sure)
>   5. If guest want to connect to the internet, guest must be through that
> container (not yet)
> 
> *Example:*
>  ID : 5114100100
>  IP CLIENT : 10.151.36.227
>  IP server docker : 10.151.36.134
>  PORT : 9001
> 
> *First step: I create an image*
>     docker run -d -it --net bridge --name 5114100100_10.151.36.227 --publish
> 9001:3128 fourirakbar/debian-squid:version2
> 
> *Second step: I create rules with iptables*
>     iptables -t nat -A PREROUTING -i wlp3s0 -s 10.151.36.227 -p tcp --dport
> 80 -j DNAT --to 10.151.36.134:9001
>     iptables -t nat -A PREROUTING -i wlp3s0 -s 10.151.36.134 -p tcp --dport
> 443 -j DNAT --to 10.151.36.134:9001

Not possible. Squid requires access to the OS NAT tables. It cannot do
that when the NAT tables are on a different machine/VM/container.

You must *route* traffic to the Squid machine/container.

> 
> *first my squid.conf in container*
>     visible_hostname X450LD
>     http_port 3128
>     http_access allow all
> 

Very broken, and kind of pointless;
* you are not doing any kind of control at all, and
* caching does not work at all well because it is per-user, and
* the most you will get out of this is logs. BUT with NAT happening
outside the container the log contents will be lies.



> *Then, if I set proxy setting manual in browser client (I use firefox)*
>     HTTP Proxy 10.151.36.134
>     Port 9001
> 
> it's working fine

Because this proxy is setup as a forward-proxy ONLY.


> ===================================
> 
> Now here's the problem:
> 
> I want to make in transparent. I tried every tutorial / github other user
> and I make squid.conf in container like this:
> 
>     acl SUBNETAJK src 10.151.36.0/24 
>     acl client1 src 10.151.36.227
...
>     http_port 3128
>     http_port 3129 intercept 
>     http_access allow SUBNETAJK
>     http_access deny all
>     http_access deny CONNECT !SSL_ports
>     http_access deny !Safe_ports 
>     
>     never_direct allow all 
...
> 
> When I try to open http website like `elearning.if.its.ac.id` or
> `monta.if.its.ac.id`, it got error *unable to forward this request at this
> time*
> 

Because "never_direct allow all" forbids the proxy from looking up where
traffic is supposed to be going. It is only permitted to send traffic
through a cache_peer ... of which you have zero.


Amos


From squid3 at treenet.co.nz  Fri Apr 20 03:58:04 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Apr 2018 15:58:04 +1200
Subject: [squid-users]
 =?utf-8?q?How_to_configure_multiple_icap_protocol_s?=
 =?utf-8?q?ervices=EF=BC=9F?=
In-Reply-To: <CY4PR22MB03609B935F30A6EF64BD5F7998B40@CY4PR22MB0360.namprd22.prod.outlook.com>
References: <CY4PR22MB03609B935F30A6EF64BD5F7998B40@CY4PR22MB0360.namprd22.prod.outlook.com>
Message-ID: <fbe056f2-cae8-533f-f6bf-c308e468955c@treenet.co.nz>

On 20/04/18 14:50, ? ? wrote:
> Thanks for reading my mail.
> My question is whether one squid as icap client can configure multiple
> icap protocol services or not ..
> If squid can , how to configure ?
> 

It can. Please read the ICAP documentation:

 <https://wiki.squid-cache.org/Features/ICAP>
 <http://www.squid-cache.org/Doc/config/icap_service/>

see also the adaptation_service_set, icap_access and adaptation_access
documentation.


Amos


From akismpa at gmail.com  Fri Apr 20 17:53:52 2018
From: akismpa at gmail.com (Panagiotis Bariamis)
Date: Fri, 20 Apr 2018 20:53:52 +0300
Subject: [squid-users] Client to proxy encryption for Internet Explorer
Message-ID: <CAPxN_PWBN9jhd7-aAo-MGkk+fLirwcEesosjwH+5v9tSCCJ-AQ@mail.gmail.com>

Hello ,
I have managed to set up a forward Secure squid proxy (tls) .
Although Mozzila (through a pac file with "RETURN HTTPS x.y.z:443) and
chrome (with command line argument "--proxy-server="https://x.y.z" ) work
OK with the squid proxy , Internet Explorer seems as if doesn't support
that function .
Are there any other configuration in Internet Explorer to work or some
auxiliary program for windows to support squid server with directive
https_port for forward proxying ?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180420/6f176128/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr 20 18:25:50 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 Apr 2018 06:25:50 +1200
Subject: [squid-users] Client to proxy encryption for Internet Explorer
In-Reply-To: <CAPxN_PWBN9jhd7-aAo-MGkk+fLirwcEesosjwH+5v9tSCCJ-AQ@mail.gmail.com>
References: <CAPxN_PWBN9jhd7-aAo-MGkk+fLirwcEesosjwH+5v9tSCCJ-AQ@mail.gmail.com>
Message-ID: <869c1809-658d-9d8a-6ec4-05c593862cce@treenet.co.nz>

On 21/04/18 05:53, Panagiotis Bariamis wrote:
> Hello ,
> I have managed to set up a forward Secure squid proxy (tls) .
> Although Mozzila (through a pac file with "RETURN HTTPS x.y.z:443) and
> chrome (with command line argument "--proxy-server="https://x.y.z" )
> work OK with the squid proxy , Internet Explorer seems as if doesn't
> support that function .
> Are there any other configuration in Internet Explorer to work or some
> auxiliary program for windows to support squid server with directive
> https_port for forward proxying ?
> 

Unfortunately the answer there is "no" in regard to IE support. AFAIK
the MS team working on IE also have no plans to add it. IE is formally
on its way towards deprecation so major new functionality like that is
highly unlikely to happen. Their Edge browser may be a different story.

There are a number of tools for tunneling traffic over a proxy but they
tend to be for non-HTTP(S) protocols to go over a regular HTTTP
forward-proxy.

Which leaves only the SSL-Bump functionality in Squid to MITM the traffic.

Amos


From akismpa at gmail.com  Fri Apr 20 18:40:28 2018
From: akismpa at gmail.com (Panagiotis Bariamis)
Date: Fri, 20 Apr 2018 21:40:28 +0300
Subject: [squid-users] Client to proxy encryption for Internet Explorer
In-Reply-To: <869c1809-658d-9d8a-6ec4-05c593862cce@treenet.co.nz>
References: <CAPxN_PWBN9jhd7-aAo-MGkk+fLirwcEesosjwH+5v9tSCCJ-AQ@mail.gmail.com>
 <869c1809-658d-9d8a-6ec4-05c593862cce@treenet.co.nz>
Message-ID: <CAPxN_PU+dfOkO+CRr1-s98UrN_29bPn7R5GfaZG_PdKNMiceVA@mail.gmail.com>

 >Unfortunately the answer there is "no" in regard to IE support. AFAIK
>the MS team working on IE also have no plans to add it. IE is formally
>on its way towards deprecation so major new functionality like that is
>highly unlikely to happen. Their Edge browser may be a different story.
Well if they add in in Edge it is going to be system wide as in Internet
Explorer. Hopefully they will add the functionality at least at Edge.


>Which leaves only the SSL-Bump functionality in Squid to MITM the traffic.
This functionality does not help much as the problem is the credentials
sent over clear text to proxies .

Thank you for the clarifications.


On Fri, Apr 20, 2018 at 9:25 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 21/04/18 05:53, Panagiotis Bariamis wrote:
> > Hello ,
> > I have managed to set up a forward Secure squid proxy (tls) .
> > Although Mozzila (through a pac file with "RETURN HTTPS x.y.z:443) and
> > chrome (with command line argument "--proxy-server="https://x.y.z" )
> > work OK with the squid proxy , Internet Explorer seems as if doesn't
> > support that function .
> > Are there any other configuration in Internet Explorer to work or some
> > auxiliary program for windows to support squid server with directive
> > https_port for forward proxying ?
> >
>
> Unfortunately the answer there is "no" in regard to IE support. AFAIK
> the MS team working on IE also have no plans to add it. IE is formally
> on its way towards deprecation so major new functionality like that is
> highly unlikely to happen. Their Edge browser may be a different story.
>
> There are a number of tools for tunneling traffic over a proxy but they
> tend to be for non-HTTP(S) protocols to go over a regular HTTTP
> forward-proxy.
>
> Which leaves only the SSL-Bump functionality in Squid to MITM the traffic.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180420/a6d180d6/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr 20 18:48:49 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 Apr 2018 06:48:49 +1200
Subject: [squid-users] Client to proxy encryption for Internet Explorer
In-Reply-To: <CAPxN_PU+dfOkO+CRr1-s98UrN_29bPn7R5GfaZG_PdKNMiceVA@mail.gmail.com>
References: <CAPxN_PWBN9jhd7-aAo-MGkk+fLirwcEesosjwH+5v9tSCCJ-AQ@mail.gmail.com>
 <869c1809-658d-9d8a-6ec4-05c593862cce@treenet.co.nz>
 <CAPxN_PU+dfOkO+CRr1-s98UrN_29bPn7R5GfaZG_PdKNMiceVA@mail.gmail.com>
Message-ID: <10127e90-80da-232d-66f3-c441bc90232d@treenet.co.nz>

On 21/04/18 06:40, Panagiotis Bariamis wrote:
>>Unfortunately the answer there is "no" in regard to IE support. AFAIK
>>the MS team working on IE also have no plans to add it. IE is formally
>>on its way towards deprecation so major new functionality like that is
>>highly unlikely to happen. Their Edge browser may be a different story.
> Well if they add in in Edge it is going to be system wide as in Internet
> Explorer. Hopefully they will add the functionality at least at Edge.
> 
> 
>>Which leaves only the SSL-Bump functionality in Squid to MITM the traffic.
> This functionality does not help much as the problem is the credentials
> sent over clear text to proxies .
> 

"credentials" does not necessarily mean passwords.

TLS also sends credentials in clear. It just happens those credentials
are called certificates. Likewise all auth schemes in HTTP (except
Basic) send security tokens of various types - not passwords.

Amos


From akismpa at gmail.com  Fri Apr 20 18:55:02 2018
From: akismpa at gmail.com (Panagiotis Bariamis)
Date: Fri, 20 Apr 2018 21:55:02 +0300
Subject: [squid-users] Client to proxy encryption for Internet Explorer
In-Reply-To: <10127e90-80da-232d-66f3-c441bc90232d@treenet.co.nz>
References: <CAPxN_PWBN9jhd7-aAo-MGkk+fLirwcEesosjwH+5v9tSCCJ-AQ@mail.gmail.com>
 <869c1809-658d-9d8a-6ec4-05c593862cce@treenet.co.nz>
 <CAPxN_PU+dfOkO+CRr1-s98UrN_29bPn7R5GfaZG_PdKNMiceVA@mail.gmail.com>
 <10127e90-80da-232d-66f3-c441bc90232d@treenet.co.nz>
Message-ID: <CAPxN_PWE6mKUit_S7TsV82=pvELKadMTwTFb7L8NP4fvhKKbcQ@mail.gmail.com>

>"credentials" does not necessarily mean passwords.

>TLS also sends credentials in clear. It just happens those credentials
>are called certificates. Likewise all auth schemes in HTTP (except
>Basic) send security tokens of various types - not passwords.

When referring to credentials I mean basic ldap authentication for squid
servers.
Those are sent in plain text (well base64) in every request. So my concern
is the client to proxy encryption so as to protect those credentials.

On Fri, Apr 20, 2018 at 9:48 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 21/04/18 06:40, Panagiotis Bariamis wrote:
> >>Unfortunately the answer there is "no" in regard to IE support. AFAIK
> >>the MS team working on IE also have no plans to add it. IE is formally
> >>on its way towards deprecation so major new functionality like that is
> >>highly unlikely to happen. Their Edge browser may be a different story.
> > Well if they add in in Edge it is going to be system wide as in Internet
> > Explorer. Hopefully they will add the functionality at least at Edge.
> >
> >
> >>Which leaves only the SSL-Bump functionality in Squid to MITM the
> traffic.
> > This functionality does not help much as the problem is the credentials
> > sent over clear text to proxies .
> >
>
> "credentials" does not necessarily mean passwords.
>
> TLS also sends credentials in clear. It just happens those credentials
> are called certificates. Likewise all auth schemes in HTTP (except
> Basic) send security tokens of various types - not passwords.
>
> Amos
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180420/0482fc9d/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr 20 21:19:32 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 Apr 2018 09:19:32 +1200
Subject: [squid-users] Client to proxy encryption for Internet Explorer
In-Reply-To: <CAPxN_PWE6mKUit_S7TsV82=pvELKadMTwTFb7L8NP4fvhKKbcQ@mail.gmail.com>
References: <CAPxN_PWBN9jhd7-aAo-MGkk+fLirwcEesosjwH+5v9tSCCJ-AQ@mail.gmail.com>
 <869c1809-658d-9d8a-6ec4-05c593862cce@treenet.co.nz>
 <CAPxN_PU+dfOkO+CRr1-s98UrN_29bPn7R5GfaZG_PdKNMiceVA@mail.gmail.com>
 <10127e90-80da-232d-66f3-c441bc90232d@treenet.co.nz>
 <CAPxN_PWE6mKUit_S7TsV82=pvELKadMTwTFb7L8NP4fvhKKbcQ@mail.gmail.com>
Message-ID: <b71e5476-3e47-af95-7aa6-46bff00064ab@treenet.co.nz>

On 21/04/18 06:55, Panagiotis Bariamis wrote:
>>"credentials" does not necessarily mean passwords.
> 
>>TLS also sends credentials in clear. It just happens those credentials
>>are called certificates. Likewise all auth schemes in HTTP (except
>>Basic) send security tokens of various types - not passwords.
> 
> When referring to credentials I mean basic ldap authentication for squid
> servers.
> Those are sent in plain text (well base64) in every request. So my
> concern is the client to proxy encryption so as to protect those
> credentials.
> 

LDAP is a database type, it is not specifically tied to the type of
credentials used either. For example; have you looked into using
Kerberos authentication? this over clear-text is similar or sometimes
more secure than TLS.

 <http://www.squid-cache.org/Versions/v3/3.5/manuals/negotiate_kerberos_auth.html>
 <http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_kerberos_ldap_group_acl.html>

That is the recommended Best Practice form of authentication with MSIE
and avoids the need for TLS solely to secure the credentials. Other
reasons for TLS remain, but are less important.

Amos


From akismpa at gmail.com  Sun Apr 22 10:52:07 2018
From: akismpa at gmail.com (Panagiotis Bariamis)
Date: Sun, 22 Apr 2018 13:52:07 +0300
Subject: [squid-users] Client to proxy encryption for Internet Explorer
In-Reply-To: <b71e5476-3e47-af95-7aa6-46bff00064ab@treenet.co.nz>
References: <CAPxN_PWBN9jhd7-aAo-MGkk+fLirwcEesosjwH+5v9tSCCJ-AQ@mail.gmail.com>
 <869c1809-658d-9d8a-6ec4-05c593862cce@treenet.co.nz>
 <CAPxN_PU+dfOkO+CRr1-s98UrN_29bPn7R5GfaZG_PdKNMiceVA@mail.gmail.com>
 <10127e90-80da-232d-66f3-c441bc90232d@treenet.co.nz>
 <CAPxN_PWE6mKUit_S7TsV82=pvELKadMTwTFb7L8NP4fvhKKbcQ@mail.gmail.com>
 <b71e5476-3e47-af95-7aa6-46bff00064ab@treenet.co.nz>
Message-ID: <CAPxN_PWCudsKqDdnPYJ8=1H_bVgCes158jVVwffeJSu9KyvmTQ@mail.gmail.com>

 >LDAP is a database type, it is not specifically tied to the type of
>credentials used either. For example; have you looked into using
>Kerberos authentication? this over clear-text is similar or sometimes
>more secure than TLS.

Unfortunately administrators of LDAP can only provide basic authentication
scheme, so I am stuck with TLS proxy , plus there are 16 squid boxes that a
layer 7 load balancer routes the traffic depending on the hash of the url ,
so I think even if the administrators of openldap could provide me with
kerberos or ntlm authentication I could not load balance the traffic based
on url .

On Sat, Apr 21, 2018 at 12:19 AM, Amos Jeffries <squid3 at treenet.co.nz>
wrote:

> On 21/04/18 06:55, Panagiotis Bariamis wrote:
> >>"credentials" does not necessarily mean passwords.
> >
> >>TLS also sends credentials in clear. It just happens those credentials
> >>are called certificates. Likewise all auth schemes in HTTP (except
> >>Basic) send security tokens of various types - not passwords.
> >
> > When referring to credentials I mean basic ldap authentication for squid
> > servers.
> > Those are sent in plain text (well base64) in every request. So my
> > concern is the client to proxy encryption so as to protect those
> > credentials.
> >
>
> LDAP is a database type, it is not specifically tied to the type of
> credentials used either. For example; have you looked into using
> Kerberos authentication? this over clear-text is similar or sometimes
> more secure than TLS.
>
>  <http://www.squid-cache.org/Versions/v3/3.5/manuals/
> negotiate_kerberos_auth.html>
>  <http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_
> kerberos_ldap_group_acl.html>
>
> That is the recommended Best Practice form of authentication with MSIE
> and avoids the need for TLS solely to secure the credentials. Other
> reasons for TLS remain, but are less important.
>
> Amos
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180422/0d4d0924/attachment.htm>

From squid3 at treenet.co.nz  Sun Apr 22 12:32:26 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 Apr 2018 00:32:26 +1200
Subject: [squid-users] Client to proxy encryption for Internet Explorer
In-Reply-To: <CAPxN_PWCudsKqDdnPYJ8=1H_bVgCes158jVVwffeJSu9KyvmTQ@mail.gmail.com>
References: <CAPxN_PWBN9jhd7-aAo-MGkk+fLirwcEesosjwH+5v9tSCCJ-AQ@mail.gmail.com>
 <869c1809-658d-9d8a-6ec4-05c593862cce@treenet.co.nz>
 <CAPxN_PU+dfOkO+CRr1-s98UrN_29bPn7R5GfaZG_PdKNMiceVA@mail.gmail.com>
 <10127e90-80da-232d-66f3-c441bc90232d@treenet.co.nz>
 <CAPxN_PWE6mKUit_S7TsV82=pvELKadMTwTFb7L8NP4fvhKKbcQ@mail.gmail.com>
 <b71e5476-3e47-af95-7aa6-46bff00064ab@treenet.co.nz>
 <CAPxN_PWCudsKqDdnPYJ8=1H_bVgCes158jVVwffeJSu9KyvmTQ@mail.gmail.com>
Message-ID: <f80f62bb-e969-fa83-feab-69c93e3f3175@treenet.co.nz>

On 22/04/18 22:52, Panagiotis Bariamis wrote:
>>LDAP is a database type, it is not specifically tied to the type of
>>credentials used either. For example; have you looked into using
>>Kerberos authentication? this over clear-text is similar or sometimes
>>more secure than TLS.
> 
> Unfortunately administrators of LDAP can only provide basic
> authentication scheme, so I am stuck with TLS proxy

Which is not supported by MSIE, so you are stuck with nothing at all for
that traffic. :-(

 , plus there are 16
> squid boxes that a layer 7 load balancer routes the traffic depending on
> the hash of the url , so I think even if the administrators of openldap
> could provide me with kerberos or ntlm authentication I could not load
> balance the traffic based on url .
> 

If the LB are operating only at the TCP/IP level (most routing LB do)
they will not have any effect on the TLS, HTTP, or HTTP auth layers.
Negotiate and HTTPS will work fine (NTLM is just broken, do not go there
unless forced to).

OR,
 If the LB are really digging into the traffic sufficiently to see URLs
(from inside the encryption?) then they are HTTP(S) proxies in their own
right and need to be accounted for in your TLS-to-proxy plans.

It may be that the LB is the entity(s) which need to be sending TLS to
your Squid. With the browsers who can doing TLS to the LB proxy. That
would get a portion LB<->Squid encrypted for MSIE even if the first bit
cannot.

Amos


From akismpa at gmail.com  Sun Apr 22 13:51:35 2018
From: akismpa at gmail.com (Panagiotis Bariamis)
Date: Sun, 22 Apr 2018 16:51:35 +0300
Subject: [squid-users] Client to proxy encryption for Internet Explorer
In-Reply-To: <f80f62bb-e969-fa83-feab-69c93e3f3175@treenet.co.nz>
References: <CAPxN_PWBN9jhd7-aAo-MGkk+fLirwcEesosjwH+5v9tSCCJ-AQ@mail.gmail.com>
 <869c1809-658d-9d8a-6ec4-05c593862cce@treenet.co.nz>
 <CAPxN_PU+dfOkO+CRr1-s98UrN_29bPn7R5GfaZG_PdKNMiceVA@mail.gmail.com>
 <10127e90-80da-232d-66f3-c441bc90232d@treenet.co.nz>
 <CAPxN_PWE6mKUit_S7TsV82=pvELKadMTwTFb7L8NP4fvhKKbcQ@mail.gmail.com>
 <b71e5476-3e47-af95-7aa6-46bff00064ab@treenet.co.nz>
 <CAPxN_PWCudsKqDdnPYJ8=1H_bVgCes158jVVwffeJSu9KyvmTQ@mail.gmail.com>
 <f80f62bb-e969-fa83-feab-69c93e3f3175@treenet.co.nz>
Message-ID: <CAPxN_PUr+DRvq1JumkogXbc9QLZ62NRaNuVxf7uehpPSrPHTXg@mail.gmail.com>

 >Which is not supported by MSIE, so you are stuck with nothing at all for
>that traffic. :-(

The way things turn out , it seems like I am going to dedicate 1 or 2 proxy
servers (without authentication)
 and no tls client to proxy just for the domains that MS,Symantec and other
vendors needs for the updates ,
and populate that proxies depending on domain in the pac file.


> If the LB are really digging into the traffic sufficiently to see URLs
>(from inside the encryption?) then they are HTTP(S) proxies in their own
>right and need to be accounted for in your TLS-to-proxy plans.

My concern is the traffic client<->LB which needs to be encypted.
Traffic LB<->squid is safe.
The LB going to be used is HAProxy at layer 7 with url load balancing for
http requests
and least connections for https requests .
The LB is going to do tls termination (for the client to tls proxy
encryption part) for the squids as well .
 Problem with kerberos is the ticketing mechanism
 as far as  i know it cannot be shared between the squid proxies ,
so if at first a user authenticates at lets say at cachebox01 then every
time
he changes a cachebox during load balacning it is going to need to
authenticate again .
Unfortunately src ip tagging cannot be performed as all clients are behind
NAT.

On Sun, Apr 22, 2018 at 3:32 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 22/04/18 22:52, Panagiotis Bariamis wrote:
> >>LDAP is a database type, it is not specifically tied to the type of
> >>credentials used either. For example; have you looked into using
> >>Kerberos authentication? this over clear-text is similar or sometimes
> >>more secure than TLS.
> >
> > Unfortunately administrators of LDAP can only provide basic
> > authentication scheme, so I am stuck with TLS proxy
>
> Which is not supported by MSIE, so you are stuck with nothing at all for
> that traffic. :-(
>
>  , plus there are 16
> > squid boxes that a layer 7 load balancer routes the traffic depending on
> > the hash of the url , so I think even if the administrators of openldap
> > could provide me with kerberos or ntlm authentication I could not load
> > balance the traffic based on url .
> >
>
> If the LB are operating only at the TCP/IP level (most routing LB do)
> they will not have any effect on the TLS, HTTP, or HTTP auth layers.
> Negotiate and HTTPS will work fine (NTLM is just broken, do not go there
> unless forced to).
>
> OR,
>  If the LB are really digging into the traffic sufficiently to see URLs
> (from inside the encryption?) then they are HTTP(S) proxies in their own
> right and need to be accounted for in your TLS-to-proxy plans.
>
> It may be that the LB is the entity(s) which need to be sending TLS to
> your Squid. With the browsers who can doing TLS to the LB proxy. That
> would get a portion LB<->Squid encrypted for MSIE even if the first bit
> cannot.
>
> Amos
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180422/29daa49d/attachment.htm>

From xpro6000 at gmail.com  Mon Apr 23 00:45:45 2018
From: xpro6000 at gmail.com (xpro)
Date: Sun, 22 Apr 2018 20:45:45 -0400
Subject: [squid-users] use tcp_outgoing_address based on incoming port
	connection
Message-ID: <9229898e-329f-aa23-e74a-270ae73a0c11@gmail.com>

I have the following configuration that makes incoming connections 
coming to port 8000 to use the another proxy, in this case proxy8000

http_port 8000 name=port_8000
acl port_8000_acl myportname port_8000
always_direct deny port_8000_acl
never_direct allow port_8000_acl
cache_peer 11.12.12.12 parent 20006 0 no-query default name=proxy8000
cache_peer_access proxy8000 allow port_8000_acl
cache_peer_access proxy8000 deny all

But I want to modify it so I can tell it which local interface to use 
based on the incoming port. Right now I'm using the following in another 
Squid configuration, but it's not based on incoming port. It does it for 
all connections

tcp_outgoing_address 172.16.11.106 # <-- that's my local ip

Does tcp_outgoing_address have the same ability as cache_peer in my case?



From gecom at tubosider.it  Mon Apr 23 08:27:02 2018
From: gecom at tubosider.it (Enrico Michieletti)
Date: Mon, 23 Apr 2018 10:27:02 +0200
Subject: [squid-users] Squid keeps using ipv6 using ssl_bump
Message-ID: <4D47920BFC12481FB5CD390ACF539B22@tubosider.it>

Hi!

I'm using squid from long time, as my network isn't ipv6 enabled, I've
disabled it in squid using

dns_v4_first on

tcp_outgoing_address 0.0.0.0 all

 

and on the interface network script on centos

IPV6INIT=no

 

With this configuration, all worked fine for long time with squid 3.5.23.

But Friday I've update the squid/squid helpers packages (now I'm at 3.5.27),
and I've enabled ssl_bump with the following lines:

ssl_bump none localhost

 

ssl_bump stare

ssl_bump bump all

 

http_port 8080 ssl-bump cert=/etc/squid/certificate.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

 

And now, on few sites (including https://wiki.squid-cache.org/), it try to
open with ipv6 with the following error:

Connection to 2001:4801:7827:102:ad34:6f78:b6dc:fbed failed.

 

I've tried to disable ssl_bump (using only "http_port 8080" statement) and
all works as before.       

For now I've "fixed" using the following lines:

acl no_ssl_interception dstdomain .squid-cache.org

ssl_bump none no_ssl_interception

 

On the problematic websites.

 

How I can get rid of the ipv6??

Thanks!

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180423/c510b7cb/attachment.htm>

From squid3 at treenet.co.nz  Mon Apr 23 10:42:33 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 Apr 2018 22:42:33 +1200
Subject: [squid-users] Squid keeps using ipv6 using ssl_bump
In-Reply-To: <4D47920BFC12481FB5CD390ACF539B22@tubosider.it>
References: <4D47920BFC12481FB5CD390ACF539B22@tubosider.it>
Message-ID: <80085784-bb61-d9c9-e7dc-a1697e892665@treenet.co.nz>

On 23/04/18 20:27, Enrico Michieletti wrote:
> Hi!
> 
> I?m using squid from long time, as my network isn?t ipv6 enabled, I?ve
> disabled it in squid using
> 
> dns_v4_first on
> 

That directives means it tries IPv4 *first*, not "only".

If *all* attempts fail the last one tried will naturally be an IPv6
whenever the server has support for both v4 (tried first) and v6 (tried
last).


> tcp_outgoing_address 0.0.0.0 all
> 

This does nothing by itself but waste CPU. Outgoing address is separated
by protocol, so the above only says "use default address for all
IPv4-only traffic".

> 
> and on the interface network script on centos
> 
> IPV6INIT=no
> 

This does not prevent servers and clients outside your machine
supporting or trying to use IPv6. All it will do is break traffic going
through your proxy machine.

What you should really do is enable IPv6 and use firewall rules to block
the traffic you do not want to go through. Whether that is "all IPv6" or
something better suited to your clients needs.

Amos


From gecom at tubosider.it  Mon Apr 23 11:10:40 2018
From: gecom at tubosider.it (masterx81)
Date: Mon, 23 Apr 2018 04:10:40 -0700 (MST)
Subject: [squid-users] Squid keeps using ipv6 using ssl_bump
In-Reply-To: <80085784-bb61-d9c9-e7dc-a1697e892665@treenet.co.nz>
References: <4D47920BFC12481FB5CD390ACF539B22@tubosider.it>
 <80085784-bb61-d9c9-e7dc-a1697e892665@treenet.co.nz>
Message-ID: <1524481840144-0.post@n4.nabble.com>

But why with that 2 directives (tcp_outgoing_address and dns_v4_first,
dns_v4_first alone wasn't working) time ago fixed my problem with squid
trying always to use ipv6? Never had any problem with ip-v6 after that.
Until now...

And, why NOW i have problems with ipv6 with some sites (for example 
https://wiki.squid-cache.org) only with ssl_bump?

My router doesn't either support IP-v6...
The dns servers configured in centos are ip-v4 only (and with nslookup
returns only ip-v4 addresses). Where squid is getting that ip-v6 address???

Thank you!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Mon Apr 23 11:12:21 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 Apr 2018 23:12:21 +1200
Subject: [squid-users] use tcp_outgoing_address based on incoming port
 connection
In-Reply-To: <9229898e-329f-aa23-e74a-270ae73a0c11@gmail.com>
References: <9229898e-329f-aa23-e74a-270ae73a0c11@gmail.com>
Message-ID: <771eee6a-9aa4-f2f1-2437-bb3fc3842b13@treenet.co.nz>

On 23/04/18 12:45, xpro wrote:
> I have the following configuration that makes incoming connections
> coming to port 8000 to use the another proxy, in this case proxy8000
> 
> http_port 8000 name=port_8000
> acl port_8000_acl myportname port_8000
> always_direct deny port_8000_acl

"don't always do" ... aka sometimes do, sometimes dont DNS lookup.

> never_direct allow port_8000_acl

"never do" DNS lookup.

No need for both requirements. Just use never_direct to forbid DNS being
used for that traffic.


> cache_peer 11.12.12.12 parent 20006 0 no-query default name=proxy8000
> cache_peer_access proxy8000 allow port_8000_acl
> cache_peer_access proxy8000 deny all
> 
> But I want to modify it so I can tell it which local interface to use
> based on the incoming port. Right now I'm using the following in another
> Squid configuration, but it's not based on incoming port. It does it for
> all connections

You cannot do that. Squid is HTTP layer where you can, at most, request
from the OS that it assign a given IP address to the outgoing traffic.


> 
> tcp_outgoing_address 172.16.11.106 # <-- that's my local ip
> 
> Does tcp_outgoing_address have the same ability as cache_peer in my case?

Neither directive has the ability you are requesting.

* cache_peer determines the dst-IP for the outgoing TCP connections. If
the specific server is not available the TCP connection  will fail
(because you have never_direct).


* tcp_outgoing_ip requests a specific src-IP for the outgoing TCP
connections. If that IP is not already assigned to the machine it is
invalid and connection will be rejected.


The OS routing setup decides;
 a) whether the src-IP is valid, and
 b) whether the dst-IP is routable, and
 c) which NIC the packets with those values goes out.

Amos


From squid3 at treenet.co.nz  Mon Apr 23 12:13:30 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 24 Apr 2018 00:13:30 +1200
Subject: [squid-users] Squid keeps using ipv6 using ssl_bump
In-Reply-To: <1524481840144-0.post@n4.nabble.com>
References: <4D47920BFC12481FB5CD390ACF539B22@tubosider.it>
 <80085784-bb61-d9c9-e7dc-a1697e892665@treenet.co.nz>
 <1524481840144-0.post@n4.nabble.com>
Message-ID: <4c10540c-02a1-f127-d122-7bce2bea6568@treenet.co.nz>

On 23/04/18 23:10, masterx81 wrote:
> But why with that 2 directives (tcp_outgoing_address and dns_v4_first,
> dns_v4_first alone wasn't working) time ago fixed my problem with squid
> trying always to use ipv6? Never had any problem with ip-v6 after that.
> Until now...

What changed anywhere on the Internet? These are both directives very
much subject to external environment behaviour.

> 
> And, why NOW i have problems with ipv6 with some sites (for example 
> https://wiki.squid-cache.org) only with ssl_bump?

Something changed.

> My router doesn't either support IP-v6...
> The dns servers configured in centos are ip-v4 only (and with nslookup
> returns only ip-v4 addresses). Where squid is getting that ip-v6 address???

>From the traffic itself, or from some other DNS server it knows about
that you have not hobbled to partial service.

Amos


From tobias.wolter at b1-systems.de  Mon Apr 23 12:43:46 2018
From: tobias.wolter at b1-systems.de (Tobias Wolter)
Date: Mon, 23 Apr 2018 14:43:46 +0200
Subject: [squid-users] Multiple responses in cache objects
Message-ID: <58dd58c9b69e3e4618fca7333eb4ac8b820c4446.camel@b1-systems.de>

Cheers,

I'm having some pretty weird issues with a customer's squid
installation - we're seeing multiple responses in a single cache
object.

Sadly, this isn't a singular incident and seems to be happening more
often recently. We've rolled back all changes since the date people
first started noticing the issues, but it still hasn't helped.

This occasionally leads to e.g. fragged CSS files, which users see by
the way of the stylesheet not working.

I'm currently out of debugging ideas. Aside from the rollback, we've
thus far isolated it to the Squid; the Apache which is the originserver
for this successfully returns the correct site.

As far as the setup goes, this is the pipeline:
* Squid (terminates SSL)
* Apache (cache_peer, originserver, same host as squid)
* Tomcat (via AJP from Apache, different hos)

Apparently, there is a point when a request to the squid takes a while
(~15s), and after that, there's something corrupted in the cache.

Any hints and help would be greatly appreciated.

Some pastes, with examples and data:
/var/cache/squid # grep -acr 'HTTP/1.1' . | grep -v 1$ | grep -v
swap.state
./02/C9/0002C9D3:2
./02/55/000255F5:2
./01/B0/0001B001:2
./00/04/00000498:2
./00/7F/00007F1F:2
./00/28/0000282E:2


# grep -aA5 'HTTP/1.1' ./02/C9/0002C9D3
?HTTP/1.1 200 OK
Server: squid
Mime-Version: 1.0
Date: Mon, 23 Apr 2018 11:49:23 GMT
X-Transformed-From: HTTP/0.9

--
HTTP/1.1 304 Not Modified
Date: Mon, 23 Apr 2018 11:49:25 GMT
Server: Apache
Connection: Keep-Alive
Keep-Alive: timeout=15, max=87
ETag: "ca8-55ef60f57e009"


pws2:/var/cache/squid # grep -aA14 'HTTP/1.1' ./02/55/000255F5
FHTTP/1.1 200 OK
Server: squid
Mime-Version: 1.0
Date: Sat, 14 Apr 2018 12:07:30 GMT
X-Transformed-From: HTTP/0.9

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">;
<html>
        <head>
                <script type="text/javascript">var contextPath = '';</script>

                <script type="text/javascript" src="/js/jquery-1.11.2.min.js"></script>
            <script type="text/javascript" src="/js/layer.js"></script>
                <script type="text/javascript" src="/js/jquery.colorbox-1.5.15.min.js"></script>
                <script type="text/javascript" src="/js/cookies.js"></script>
--
HTTP/1.1 200 OK
Date: Sat, 14 Apr 2018 12:07:30 GMT
Server: Apache
X-FRAME-OPTIONS: SAMEORIGIN
X-XSS-Protection: 1; mode=block
Last-Modified: Fri, 13 Apr 2018 13:31:28 GMT
Cache-Control: max-age=300
Expires: Sat, 14 Apr 2018 12:12:30 GMT
Vary: Accept-Encoding
Content-Encoding: gzip
Keep-Alive: timeout=15, max=97
Connection: Keep-Alive
Transfer-Encoding: chunked
Content-Type: text/html;charset=ISO-8859-1

# squidclient mgr:info:
Squid Object Cache: Version 3.5.21
Build Info: 
Service Name: squid
Start Time:     Mon, 23 Apr 2018 11:50:30 GMT
Current Time:   Mon, 23 Apr 2018 12:41:11 GMT
Connection information for squid:
        Number of clients accessing cache:      407
        Number of HTTP requests received:       13262
        Number of ICP messages received:        0
        Number of ICP messages sent:    0
        Number of queued ICP replies:   0
        Number of HTCP messages received:       0
        Number of HTCP messages sent:   0
        Request failure ratio:   0.00
        Average HTTP requests per minute since start:   261.6
        Average ICP messages per minute since start:    0.0
        Select loop called: 197830 times, 15.374 ms avg
Cache information for squid:
        Hits as % of all requests:      5min: 52.3%, 60min: 64.0%
        Hits as % of bytes sent:        5min: 40.6%, 60min: 54.3%
        Memory hits as % of hit requests:       5min: 74.3%, 60min: 78.0%
        Disk hits as % of hit requests: 5min: 0.1%, 60min: 0.1%
        Storage Swap size:      3949688 KB
        Storage Swap capacity:  77.1% used, 22.9% free
        Storage Mem size:       36168 KB
        Storage Mem capacity:    4.6% used, 95.4% free
        Mean Object Size:       79.26 KB
        Requests given to unlinkd:      3272
Median Service Times (seconds)  5 min    60 min:
        HTTP Requests (All):   0.01309  0.00179
        Cache Misses:          0.02317  0.02592
        Cache Hits:            0.00000  0.00000
        Near Hits:             0.01745  0.01745
        Not-Modified Replies:  0.00000  0.00000
        DNS Lookups:           0.02231  0.02336
        ICP Queries:           0.00000  0.00000
Resource usage for squid:
        UP Time:        3041.448 seconds
        CPU Time:       49.352 seconds
        CPU Usage:      1.62%
        CPU Usage, 5 minute avg:        1.63%
        CPU Usage, 60 minute avg:       1.63%
        Maximum Resident Size: 340384 KB
        Page faults with physical i/o: 1
Memory accounted for:
        Total accounted:        49999 KB
        memPoolAlloc calls:   3344459
        memPoolFree calls:    3360309
File descriptor usage for squid:
        Maximum number of file descriptors:   4096
        Largest file desc currently in use:    101
        Number of file desc currently in use:   69
        Files queued for open:                   0
        Available number of file descriptors: 4027
        Reserved number of file descriptors:   100
        Store Disk files open:                   0
Internal Data Structures:
         49856 StoreEntries
          1421 StoreEntries with MemObjects
          1420 Hot Object Cache Items
         49829 on-disk objects

# mgr:storedir:
Store Directory Statistics:
Store Entries          : 49863
Maximum Swap Size      : 5120000 KB
Current Store Swap Size: 3949940.00 KB
Current Capacity       : 77.15% used, 22.85% free

Store Directory #0 (ufs): /var/cache/squid
FS Block Size 4096 Bytes
First level subdirectories: 16
Second level subdirectories: 256
Maximum Size: 5120000 KB
Current Size: 3949940.00 KB
Percent Used: 77.15%
Filemap bits in use: 49835 of 262144 (19%)
Filesystem Space in use: 16453040/41153856 KB (40%)
Filesystem Inodes in use: 441511/2621440 (17%)
Flags: SELECTED
Removal policy: lru
LRU reference age: 12.80 days

-towo
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: This is a digitally signed message part
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180423/9669e897/attachment.sig>

From squid3 at treenet.co.nz  Mon Apr 23 14:20:18 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 24 Apr 2018 02:20:18 +1200
Subject: [squid-users] Multiple responses in cache objects
In-Reply-To: <58dd58c9b69e3e4618fca7333eb4ac8b820c4446.camel@b1-systems.de>
References: <58dd58c9b69e3e4618fca7333eb4ac8b820c4446.camel@b1-systems.de>
Message-ID: <557634c9-2795-6ac6-97c8-1e1c5ab70a0f@treenet.co.nz>

On 24/04/18 00:43, Tobias Wolter wrote:
> Cheers,
> 
> I'm having some pretty weird issues with a customer's squid
> installation - we're seeing multiple responses in a single cache
> object.
> 

Please note the:

> X-Transformed-From: HTTP/0.9

... in your example cached objects.

Squid should not be caching these. Which implies that a) you have some
config settings forcing things to cache when they are not supposed to,
and b) either upstream server or client is broken.


 * do you have any refresh_pattern rules forcing it to do so?

 * what version of Squid are you running?

 * have you tried the latest Squid version?
 there have been a few fixes in detection this protocol version for Squid-4.


> Sadly, this isn't a singular incident and seems to be happening more
> often recently. We've rolled back all changes since the date people
> first started noticing the issues, but it still hasn't helped.
> 
> This occasionally leads to e.g. fragged CSS files, which users see by
> the way of the stylesheet not working.
> 
> I'm currently out of debugging ideas. Aside from the rollback, we've
> thus far isolated it to the Squid; the Apache which is the originserver
> for this successfully returns the correct site.


Squid is apparently receiving HTTP/0.9 response objects (a raw data
stream of octets) not HTTP 1.0 or 1.1 objects (stream of messages with
specific start and end points to each message object).


How do you determine that "successful" for the server?
 using any tool that hides away the protocols octet-level format details
 (eg curl, wget, browser, etc) can hide the HTTP/0.9 oddity from view.

Locate the URL which was originally requested by the client. The first
line of the cache file should be a single byte representing the
request-method, then the URL in plain-text ending with newline (\n). Use
squidclient to fetch that URL directly from the server like so:

  squidclient -h example.com -p 80 -V "-" http://example.com/




This is what a normal HTTP/1.x response message is supposed to look like:

( from "squidclient -h example.com -p 80 /" )

"
HTTP/1.0 404 Not Found
Content-Type: text/html
Date: Mon, 23 Apr 2018 13:56:18 GMT
Server: ECS (oxr/837F)
Content-Length: 345
Connection: close

<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
         "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
	<head>
		<title>404 - Not Found</title>
	</head>
	<body>
		<h1>404 - Not Found</h1>
	</body>
</html>
"

And this is what your cache file 000255F5 says Squid is receiving from
the upstream server (for the URL you should see in the very start of
that 000255F5 file):

"
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">;
<html>
        <head>
                <script type="text/javascript">var contextPath =
'';</script>

                <script type="text/javascript"
src="/js/jquery-1.11.2.min.js"></script>
            <script type="text/javascript" src="/js/layer.js"></script>
                <script type="text/javascript"
src="/js/jquery.colorbox-1.5.15.min.js"></script>
                <script type="text/javascript"
src="/js/cookies.js"></script>
...
"

Amos


From sanelson at gmail.com  Mon Apr 23 15:15:13 2018
From: sanelson at gmail.com (Stephen Nelson-Smith)
Date: Mon, 23 Apr 2018 16:15:13 +0100
Subject: [squid-users] Squid returns 400 to GET / HTTP/1.1 with Host Header
Message-ID: <CABqtqVRha+fWwkkakTiWhZM3Le0SoVE2aob8gmFbzdW4XdU44Q@mail.gmail.com>

Hello,

I need to demonstrate and test a Squid setup, which should blacklist
by default, and allow requests only to whitelisted URLs from known
networks. This is currently running in my staging environment, and is
working as expected, but I want to test and demo it on demand, with
nicer feedback than with curl.

I've deployed Redbot (https://github.com/mnot/redbot), which I've set
up to send all HTTP requests via the Squid proxy

Using curl -x from the Redbot machine, all my tests pass, but using
the application, Squid returns a 400 whatever happens. All requests go
to Squid, and I see every request, but instead of returning a 403 and
X-Squid-Error: ERR_ACCESS_DENIED 0, or allowing the request, every
request gets a 400, and X-Squid-Error: ERR_INVALID_URL 0.

Digging into it - logs and tcpdump - the key difference I see is that
Redbot sends a request of the form:

GET / HTTP/1.1
Host: chess.com

Curl sends:

GET http://chess.com/ HTTP/1.1
Host: chess.com

>From the RFC it seems like Redbot's request is perfectly valid, and so
I feel like Squid should do the right thing and deduce from the host
header what Redbot wants, and go through its ACLs. However, it just
errors with:

HTTP/1.1 400 Bad Request
Server: squid/3.5.27
Mime-Version: 1.0
Date: Mon, 23 Apr 2018 11:50:23 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3465
X-Squid-Error: ERR_INVALID_URL 0
X-Cache: MISS from proxy.redaction.com
Via: 1.1 proxy.redaction.com (squid/3.5.27)

Does this seem like a Squid config issue? Or do I need to make Redbot
make a request like Curl does?


From squid3 at treenet.co.nz  Mon Apr 23 15:31:44 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 24 Apr 2018 03:31:44 +1200
Subject: [squid-users] Squid returns 400 to GET / HTTP/1.1 with Host
 Header
In-Reply-To: <CABqtqVRha+fWwkkakTiWhZM3Le0SoVE2aob8gmFbzdW4XdU44Q@mail.gmail.com>
References: <CABqtqVRha+fWwkkakTiWhZM3Le0SoVE2aob8gmFbzdW4XdU44Q@mail.gmail.com>
Message-ID: <944d6f58-23c8-416c-6860-05936c9a7929@treenet.co.nz>

On 24/04/18 03:15, Stephen Nelson-Smith wrote:
> Hello,
> 
> I need to demonstrate and test a Squid setup, which should blacklist
> by default, and allow requests only to whitelisted URLs from known
> networks. This is currently running in my staging environment, and is
> working as expected, but I want to test and demo it on demand, with
> nicer feedback than with curl.
> 
> I've deployed Redbot (https://github.com/mnot/redbot), which I've set
> up to send all HTTP requests via the Squid proxy
> 
> Using curl -x from the Redbot machine, all my tests pass, but using
> the application, Squid returns a 400 whatever happens. All requests go
> to Squid, and I see every request, but instead of returning a 403 and
> X-Squid-Error: ERR_ACCESS_DENIED 0, or allowing the request, every
> request gets a 400, and X-Squid-Error: ERR_INVALID_URL 0.
> 

ERR_INVALID_URL --> the URL is the invalid part, not the Host header.

> Digging into it - logs and tcpdump - the key difference I see is that
> Redbot sends a request of the form:
> 
> GET / HTTP/1.1
> Host: chess.com
> 
> Curl sends:
> 
> GET http://chess.com/ HTTP/1.1
> Host: chess.com
> 
> From the RFC it seems like Redbot's request is perfectly valid, and so
> I feel like Squid should do the right thing and deduce from the host
> header what Redbot wants, and go through its ACLs. However, it just
> errors with:

You missed the part where it says which type of recipient the various
URL forms are valid.

The redbot example is a origin-form URL - valid only when sent to origin
servers (or reverse-proxy). The curl one is an absolute-form URL - valid
when sent to proxies and gateways.

...
> 
> Does this seem like a Squid config issue? Or do I need to make Redbot
> make a request like Curl does?

Redbot is designed primarily for debugging HTTP problems with origin
servers to check why their output is not caching in a proxy or browser
properly. If you can find an option to inform it that it is operating
through a proxy, turn that on.

Amos


From sanelson at gmail.com  Mon Apr 23 15:48:22 2018
From: sanelson at gmail.com (Stephen Nelson-Smith)
Date: Mon, 23 Apr 2018 16:48:22 +0100
Subject: [squid-users] Squid returns 400 to GET / HTTP/1.1 with Host
	Header
In-Reply-To: <944d6f58-23c8-416c-6860-05936c9a7929@treenet.co.nz>
References: <CABqtqVRha+fWwkkakTiWhZM3Le0SoVE2aob8gmFbzdW4XdU44Q@mail.gmail.com>
 <944d6f58-23c8-416c-6860-05936c9a7929@treenet.co.nz>
Message-ID: <CABqtqVRRcVy6X+aYK4vFffaefJQ-51JaMqEgjWsipWiNMfUyYg@mail.gmail.com>

Hi Amos,


On Mon, Apr 23, 2018 at 4:31 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

>> From the RFC it seems like Redbot's request is perfectly valid, and so
>> I feel like Squid should do the right thing and deduce from the host
>> header what Redbot wants, and go through its ACLs. However, it just
>> errors with:
>
> You missed the part where it says which type of recipient the various
> URL forms are valid.
>
> The redbot example is a origin-form URL - valid only when sent to origin
> servers (or reverse-proxy). The curl one is an absolute-form URL - valid
> when sent to proxies and gateways.

Thanks - that's a helpful distinction.

>> Does this seem like a Squid config issue? Or do I need to make Redbot
>> make a request like Curl does?
>
> Redbot is designed primarily for debugging HTTP problems with origin
> servers to check why their output is not caching in a proxy or browser
> properly. If you can find an option to inform it that it is operating
> through a proxy, turn that on.

There's no such option, and I had to modify RedFetcher to instantiate
with a proxy.  The constructor does support it, but there's no login
in Thor or Redbot to behave differently if going through a proxy.

Adding that functionality would be an option, but am I right in
thinking squid should be able to infer the destination from the host
header?

Just looking at the documentation for http_port, would adding
'intercept' help, or is that explicitly for interception caching in
conjunction with a traffic filter?

S.


From sanelson at gmail.com  Mon Apr 23 16:03:02 2018
From: sanelson at gmail.com (Stephen Nelson-Smith)
Date: Mon, 23 Apr 2018 17:03:02 +0100
Subject: [squid-users] Squid returns 400 to GET / HTTP/1.1 with Host
	Header
In-Reply-To: <CABqtqVRRcVy6X+aYK4vFffaefJQ-51JaMqEgjWsipWiNMfUyYg@mail.gmail.com>
References: <CABqtqVRha+fWwkkakTiWhZM3Le0SoVE2aob8gmFbzdW4XdU44Q@mail.gmail.com>
 <944d6f58-23c8-416c-6860-05936c9a7929@treenet.co.nz>
 <CABqtqVRRcVy6X+aYK4vFffaefJQ-51JaMqEgjWsipWiNMfUyYg@mail.gmail.com>
Message-ID: <CABqtqVS=gq+uGFcMm88HvuZptQAMu3yv38SxcxpPk3uBvyDAnA@mail.gmail.com>

Hi,

On Mon, Apr 23, 2018 at 4:48 PM, Stephen Nelson-Smith
<sanelson at gmail.com> wrote:

> Adding that functionality would be an option, but am I right in
> thinking squid should be able to infer the destination from the host
> header?
>
> Just looking at the documentation for http_port, would adding
> 'intercept' help, or is that explicitly for interception caching in
> conjunction with a traffic filter?

Adding `intercept` to `http_port` has resulted in the host header
appearing as the URL in the request.

Squid is now giving a 403... which it shouldn't... I think:

1524498993.558      0 10.8.0.33 TCP_MISS/403 3985 GET
http://www.openstreetmap.com/ - HIER_NONE/- text/html
1524498993.559      0 10.8.2.19 TCP_MISS/403 4077 GET
http://www.openstreetmap.com/ - ORIGINAL_DST/10.8.0.33 text/html

# Source ACLs

acl cluster src 10.8.0.0/16 # Kubernetes Cluster

# Destination ACLs

acl google dstdomain google.com
http_access allow cluster google

acl streetmap dstdomain .openstreetmap.com
http_access allow cluster streetmap

# and finally deny all other access to this proxy

http_access deny all

S.


From squid3 at treenet.co.nz  Mon Apr 23 16:58:46 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 24 Apr 2018 04:58:46 +1200
Subject: [squid-users] Squid returns 400 to GET / HTTP/1.1 with Host
 Header
In-Reply-To: <CABqtqVS=gq+uGFcMm88HvuZptQAMu3yv38SxcxpPk3uBvyDAnA@mail.gmail.com>
References: <CABqtqVRha+fWwkkakTiWhZM3Le0SoVE2aob8gmFbzdW4XdU44Q@mail.gmail.com>
 <944d6f58-23c8-416c-6860-05936c9a7929@treenet.co.nz>
 <CABqtqVRRcVy6X+aYK4vFffaefJQ-51JaMqEgjWsipWiNMfUyYg@mail.gmail.com>
 <CABqtqVS=gq+uGFcMm88HvuZptQAMu3yv38SxcxpPk3uBvyDAnA@mail.gmail.com>
Message-ID: <ffc16fdc-bc83-e0bf-f019-b520026e51db@treenet.co.nz>

On 24/04/18 04:03, Stephen Nelson-Smith wrote:
> Hi,
> 
> On Mon, Apr 23, 2018 at 4:48 PM, Stephen Nelson-Smith wrote:
> 
>> Adding that functionality would be an option,

I think that is worth asking Mark Nottingham about adding that
functionality.


>> but am I right in
>> thinking squid should be able to infer the destination from the host
>> header?

No, that is rather dangerous. The CVE-2009-0801 and related nest of
vulnerabilities are opened up if Host header is trusted by a proxy.


>>
>> Just looking at the documentation for http_port, would adding
>> 'intercept' help, or is that explicitly for interception caching in
>> conjunction with a traffic filter?
> 
> Adding `intercept` to `http_port` has resulted in the host header
> appearing as the URL in the request.
> 
> Squid is now giving a 403... which it shouldn't... I think:
> 
> 1524498993.558      0 10.8.0.33 TCP_MISS/403 3985 GET
> http://www.openstreetmap.com/ - HIER_NONE/- text/html
> 1524498993.559      0 10.8.2.19 TCP_MISS/403 4077 GET
> http://www.openstreetmap.com/ - ORIGINAL_DST/10.8.0.33 text/html
> 

That is the CVE-2009-0801 protections doing their thing for intercept'ed
traffic (second log line). The 10.8.0.33 IP is where the client was
apparently going before MITM'd into the proxy, so the server there MUST
be able to handle whatever the client is expecting back regardless of
whether the proxy trusts it for caching purposes.

But 10.8.0.33 is your Squid, so the traffic loops (first log line).
Squid detects the loop and rejects it to prevent infinite memory and TCP
port numbers being consumed.

Amos


From sanelson at gmail.com  Mon Apr 23 17:11:17 2018
From: sanelson at gmail.com (Stephen Nelson-Smith)
Date: Mon, 23 Apr 2018 18:11:17 +0100
Subject: [squid-users] Squid returns 400 to GET / HTTP/1.1 with Host
	Header
In-Reply-To: <ffc16fdc-bc83-e0bf-f019-b520026e51db@treenet.co.nz>
References: <CABqtqVRha+fWwkkakTiWhZM3Le0SoVE2aob8gmFbzdW4XdU44Q@mail.gmail.com>
 <944d6f58-23c8-416c-6860-05936c9a7929@treenet.co.nz>
 <CABqtqVRRcVy6X+aYK4vFffaefJQ-51JaMqEgjWsipWiNMfUyYg@mail.gmail.com>
 <CABqtqVS=gq+uGFcMm88HvuZptQAMu3yv38SxcxpPk3uBvyDAnA@mail.gmail.com>
 <ffc16fdc-bc83-e0bf-f019-b520026e51db@treenet.co.nz>
Message-ID: <CABqtqVR1tMmixPWGAYHEmEcTMFc-ELzPFsN7ZpA_ANVx6CR=2w@mail.gmail.com>

Hi,

On Mon, Apr 23, 2018 at 5:58 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 24/04/18 04:03, Stephen Nelson-Smith wrote:
>> Hi,
>>
>> On Mon, Apr 23, 2018 at 4:48 PM, Stephen Nelson-Smith wrote:
>>
>>> Adding that functionality would be an option,
>
> I think that is worth asking Mark Nottingham about adding that
> functionality.

I'll open an issue on the repo.  I did already fork it to add the 'use
a proxy' functionality, and would be happy to contribute such
functionality.  Would be a good way to get my head around it all
anyway.

>>> but am I right in
>>> thinking squid should be able to infer the destination from the host
>>> header?
>
> No, that is rather dangerous. The CVE-2009-0801 and related nest of
> vulnerabilities are opened up if Host header is trusted by a proxy.

Thanks for explaining - I'll look into that, but I can see what you mean.
>
>>>
>>> Just looking at the documentation for http_port, would adding
>>> 'intercept' help, or is that explicitly for interception caching in
>>> conjunction with a traffic filter?
>>
>> Adding `intercept` to `http_port` has resulted in the host header
>> appearing as the URL in the request.
>>
>> Squid is now giving a 403... which it shouldn't... I think:
>
> That is the CVE-2009-0801 protections doing their thing for intercept'ed
> traffic (second log line). The 10.8.0.33 IP is where the client was
> apparently going before MITM'd into the proxy, so the server there MUST
> be able to handle whatever the client is expecting back regardless of
> whether the proxy trusts it for caching purposes.
>
> But 10.8.0.33 is your Squid, so the traffic loops (first log line).
> Squid detects the loop and rejects it to prevent infinite memory and TCP
> port numbers being consumed.

Right.  I understand in a traditional transparent proxy environment
we'd handle this with iptables/pf.

Short of making Redbot behave better, through a proxy, is there a
solution I can use that will get me through my demo (I have to demo
this tomorrow) without resorting to a bunch of curls?  As long as
Redbot can make requests to a bunch of URLs and I can show the results
in the browser (failures and successes), I can worry about doing it
properly later - this is a throw-away environment, and won't exist
after the demo.  The point of the demo is to show the proxy working
and being used by a web app.

Thanks for your time and insight - this is all tremendously useful and
informative.

S.


From squid3 at treenet.co.nz  Mon Apr 23 17:11:35 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 24 Apr 2018 05:11:35 +1200
Subject: [squid-users] use tcp_outgoing_address based on incoming port
 connection
In-Reply-To: <CAFoK1aycPtCg0bJnzpgm0_p-e16Wr_bnByh3xJwm7G8cyo5bmw@mail.gmail.com>
References: <9229898e-329f-aa23-e74a-270ae73a0c11@gmail.com>
 <771eee6a-9aa4-f2f1-2437-bb3fc3842b13@treenet.co.nz>
 <CAFoK1aycPtCg0bJnzpgm0_p-e16Wr_bnByh3xJwm7G8cyo5bmw@mail.gmail.com>
Message-ID: <25a58e4b-d8ed-2c35-cae7-0e3dad68c6ae@treenet.co.nz>

On 24/04/18 03:45, Arya F wrote:
> You cannot do that. Squid is HTTP layer where you can, at most, request
> from the OS that it assign a given IP address to the outgoing traffic
> 
> Can you tell me how that can be done? I'm ok with using the IP address
> of the interface
> 

Either, by configuring the IP address in tcp_outgoing_address as you
wrote in your first mail. The OS *may* use the interface associated with
that IP, unless the dst-IP routing requires a different one.

OR, by doing nothing in squid.conf and letting the OS select the IP it
already knows to use on the routes to wherever the dst-IP is going.

Amos


From tobias.wolter at b1-systems.de  Mon Apr 23 20:54:34 2018
From: tobias.wolter at b1-systems.de (Tobias Wolter)
Date: Mon, 23 Apr 2018 22:54:34 +0200
Subject: [squid-users] Multiple responses in cache objects
In-Reply-To: <557634c9-2795-6ac6-97c8-1e1c5ab70a0f@treenet.co.nz>
References: <58dd58c9b69e3e4618fca7333eb4ac8b820c4446.camel@b1-systems.de>
 <557634c9-2795-6ac6-97c8-1e1c5ab70a0f@treenet.co.nz>
Message-ID: <9c4c3e78914af926bee416142406032ebd06f573.camel@b1-systems.de>

Hey Amos,

On Tue, 2018-04-24 at 02:20 +1200, Amos Jeffries wrote:
> On 24/04/18 00:43, Tobias Wolter wrote:
> > Cheers,
> > 
> > I'm having some pretty weird issues with a customer's squid
> > installation - we're seeing multiple responses in a single cache
> > object.
> > 
> 
> Please note the:
> 
> > X-Transformed-From: HTTP/0.9
> 
> ... in your example cached objects.
> 
> Squid should not be caching these. Which implies that a) you have
> some config settings forcing things to cache when they are not
> supposed to, and b) either upstream server or client is broken.

I was wondering about these, that's a good hint.

>  * do you have any refresh_pattern rules forcing it to do so?

Aye, some files were CSS files which are forced into caching. I was
speculating that the refresh_patterns might be involved, but didn't
see the connection.

>  * what version of Squid are you running?

3.5.21 on whatever patches SUSE baked into it.


>  * have you tried the latest Squid version?
>  there have been a few fixes in detection this protocol version for
> Squid-4.

Sadly non-negotiable, I'll have to make do (or tell them, ultimatively,
that it can't be done).

> Squid is apparently receiving HTTP/0.9 response objects (a raw data
> stream of octets) not HTTP 1.0 or 1.1 objects (stream of messages
> with specific start and end points to each message object).

Yup, will look into how *that* is happening.

> How do you determine that "successful" for the server?
>  using any tool that hides away the protocols octet-level format
> details
>  (eg curl, wget, browser, etc) can hide the HTTP/0.9 oddity from
> view.

Yeah, I've only been loooking at high-level clients since that's pretty
much where it broke; since it at least by assumption had always been
"working" (read: no visible/reported breakage) thus far, I didn't
bother to check for this; especially as the application hasn't been
updated in the timeframe where errors were reported.

> Locate the URL which was originally requested by the client. The
> first line of the cache file should be a single byte representing the
> request-method, then the URL in plain-text ending with newline (\n). 

my grep line handily found those; another option is to grep for '-1\s*-
1 unknown' in the cache_store_log, as there's a direct connection
between broken object storage and lack of cache timing, as we've found
out since I wrote the mail.

Kudos for the hints, Amos, they're great and'll help me a lot
(tomorrow, it's 22.54 local here).

-towo
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: This is a digitally signed message part
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180423/517563b8/attachment.sig>

From vsomaska at usc.edu  Mon Apr 23 22:46:45 2018
From: vsomaska at usc.edu (Vishali Somaskanthan)
Date: Mon, 23 Apr 2018 15:46:45 -0700
Subject: [squid-users] Fwd: Squid - Keepalive connections issue
Message-ID: <CAPYPGc326PQ4V6RUpsEWgyZs3wcByKOBDM=hL7kA-rXMMCeekw@mail.gmail.com>

Hi all,
I am working on opening up a persistent connection from Squid -> server. i
have 2 questions.

1. I find Squid sometimes sends a [FIN, ACK] signal to server as a result
of which, Squid sends RST and resets the connection. Ideally, for
persistent connections, this shouldn't be the case. Can somebody help me in
this regard? Am I missing any other config directives with respect to
establishing keep-alive connections??

2. Are there any ways to configure how many number of keep-alive
connections should be initiated to the server??


PS:
1. I am using Squid 4
2. I have my *server_persistent_connections on* and
*client_persistent_connections
on*
3. Also, I enabled persistent connections for POST requests as well by the
following lines.

*acl post_req method POST PUT*
*server_pconn_for_nonretriable allow post_req *



Thanks and Regards,

*Vishali Somaskanthan*
MS Candidate, Computer Science
University of Southern California | Viterbi School of Engineering
213-421-7157
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180423/85088096/attachment.htm>

From gecom at tubosider.it  Tue Apr 24 09:56:41 2018
From: gecom at tubosider.it (masterx81)
Date: Tue, 24 Apr 2018 02:56:41 -0700 (MST)
Subject: [squid-users] Squid keeps using ipv6 using ssl_bump
In-Reply-To: <4c10540c-02a1-f127-d122-7bce2bea6568@treenet.co.nz>
References: <4D47920BFC12481FB5CD390ACF539B22@tubosider.it>
 <80085784-bb61-d9c9-e7dc-a1697e892665@treenet.co.nz>
 <1524481840144-0.post@n4.nabble.com>
 <4c10540c-02a1-f127-d122-7bce2bea6568@treenet.co.nz>
Message-ID: <1524563801082-0.post@n4.nabble.com>

I've tried to comment out the "tcp_outgoing_address 0.0.0.0 all" directive as
you suggested, and actually all work as it should. Not know why in the past
had to add it.
By now, only one site has problem with ssl_bump and ipv6, and it's
wiki.squid-cache.org (quite hilarious). If i bump it i get the ipv6 error,
if i add it to the ssl_bump none ACL it go to the ipv4 route normally.
I've had fear that wasn't the only one, but by now i've not had any other
complain by users.
Strange. For now i'll not intercept it and problem solved.
Really thank for the support!




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Tue Apr 24 10:01:04 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 24 Apr 2018 22:01:04 +1200
Subject: [squid-users] Fwd: Squid - Keepalive connections issue
In-Reply-To: <CAPYPGc326PQ4V6RUpsEWgyZs3wcByKOBDM=hL7kA-rXMMCeekw@mail.gmail.com>
References: <CAPYPGc326PQ4V6RUpsEWgyZs3wcByKOBDM=hL7kA-rXMMCeekw@mail.gmail.com>
Message-ID: <c2ad41f7-b082-ee57-fc62-db1c4d83cb66@treenet.co.nz>

On 24/04/18 10:46, Vishali Somaskanthan wrote:
> Hi all,
> 
> I am working on opening up a persistent connection from Squid -> server.
> i have 2 questions.?
> 
> 1. I find Squid sometimes sends a [FIN, ACK] signal to server as a
> result of which, Squid sends RST and resets the connection. Ideally, for
> persistent connections, this shouldn't be the case. Can somebody help me
> in this regard? Am I missing any other config directives with respect to
> establishing keep-alive connections?? 

You are missing the part were the server (or something) is sending FIN
to Squid. FIN ACK is the _answer_ responding to a server FIN.

Connections MAY be closed at any time for any reason. It may not even be
the server sending the FIN but some hardware, router or other software
or device along the traffic route.

RST occuring after the FIN ACK is usually a sign that some other things
along the path is probably sending the FIN - not the server itself
unless you have REALLY bad routing and latency problems.
 NP: Experience tells me to start by looking for NAT devices along the
traffic path when this happens. Replacing NAT and old routers usually
makes this type of symptom magically disappear.


> 
> 2. Are there any ways to configure how many number of keep-alive
> connections should be initiated to the server??

No. The default for keep-alive is simply "all of them". Anything you can
configure will merely be a reduction in service ability.

> 
> PS:?
> 1. I am using Squid 4
> 2. I have my /server_persistent_connections on/ and
> /client_persistent_connections on/
> 3. Also, I enabled persistent connections for POST requests as well by
> the following lines.
> /acl post_req method POST PUT
> /
> /server_pconn_for_nonretriable allow post_req?/
> 

That is all you can do. Squid is at the mercy of client and server
software - if *they* do not also use every available HTTP mechanism to
enable keep-alive on messages then eventually they will send a message
that ends the connection. There is nothing Squid can do about that.


What you can do is work with the server to ensure *it* is doing its best
to retain persistence. Make sure that it supports HTTP/1.1 chunked
encoding, AND that it uses that encoding to prevent messages with
unknown-length payloads closing connections.

If the messages to your server are CONNECT messages, discard all hope.
The traffic ceases to even be HTTP right after the tunnel setup is
complete. Tunnels can stay open for long time, but when they are done
they are done absolutely and the entire TCP connection ends as well.

Amos


From gecom at tubosider.it  Tue Apr 24 12:14:05 2018
From: gecom at tubosider.it (masterx81)
Date: Tue, 24 Apr 2018 05:14:05 -0700 (MST)
Subject: [squid-users] SSLBump and squid process CPU usage
Message-ID: <1524572045107-0.post@n4.nabble.com>

Hi!
I've configured squid with ssl_bump and now the squid process (not the
helpers) takes quite load. There aren't too much clients on it (max 50).
This is the config (ripped some acl to make it readable):

------------------------------------------------------

cache_mgr x at xxx.com
visible_hostname        proxy.xxx.com
dns_v4_first on

authenticate_ip_ttl 1 hour

forward_max_tries 25

### negotiate kerberos and ntlm authentication
auth_param negotiate program /usr/local/bin/negotiate_wrapper --ntlm
/usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --domain=xxx
--kerberos /usr/local/bin/squid_kerb_auth -s GSS_C_NO_NAME
auth_param negotiate children 50
auth_param negotiate keep_alive off

### pure ntlm authentication
auth_param ntlm program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-ntlmssp --domain=xxx
auth_param ntlm children 50
auth_param ntlm keep_alive off

### provide basic authentication via ldap for clients not authenticated via
kerberos/ntlm
auth_param basic program /usr/local/squid/libexec/basic_ldap_auth -v 3 -R -b
"dc=xxx,dc=local" -D squid at xxx.local -W /etc/squid/ldappass.txt -f
sAMAccountName=%s -h srv-dc1.xxx.local

auth_param basic children 50
auth_param basic realm Proxy xxx

### ldap group authorisation
external_acl_type memberof ttl=30 %LOGIN
/usr/local/squid/libexec/ext_ldap_group_acl -v 3 -R -K -b "dc=xxx,dc=local"
-D squid at xxx.local -W  /etc/squid/ldappass.txt -f
"(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,ou=SQUID,ou=OU
xxx,dc=xxx,dc=local))" -h srv-dc1.xxx.local

### acl for proxy auth and ldap authorizations
acl auth proxy_auth REQUIRED
#   aclname             acltype  typename activedirectorygroup
acl InternetBloccato    external memberof "/etc/squid/Internet_bloccato.txt"
... etc

acl bypass dstdomain somedomains
... etc

# ACL per Windows Update e microsoft
acl windowsupdate dstdomain windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain .windowsupdate.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com
acl windowsupdate dstdomain .delivery.mp.microsoft.com

----a lot more ACL----

# ACL per bloccare per estensione
acl estensionibloccate urlpath_regex -i "/etc/squid/estensionibloccate.txt"

## Disable ssl interception for dropbox.com and hotmail.com (and localhost)
acl no_ssl_interception dstdomain somedomains

ssl_bump none localhost
ssl_bump none no_ssl_interception

ssl_bump stare
ssl_bump bump all


acl SSL_ports port 443
acl SSL_ports port 7071
acl SSL_ports port 10443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http

acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com


# Permetti FTP
acl ftp proto FTP
acl ftp_port port 21

# ACL per limiti utenti Internet_limitato
acl giorni time T W F

# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
ftp_epsv off

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

http_access allow localhost manager
http_access deny manager

http_access allow ftp_port CONNECT
http_access allow ftp

http_access allow CONNECT wuCONNECT
http_access allow windowsupdate

---- a lot more ACL ----

# DO NOT REMOVE THE FOLLOWING LINE
http_access deny all



### logging
logformat useragent  %>a [%tl] "%{User-Agent}>h"

# don't log allowedsites, prioritysites, AnonymousAccess
access_log /var/log/squid/access.log logformat=squid
#!allowedsites !prioritysites !AnonymousAccess
cache_log /var/log/squid/cache.log
cache_store_log /var/log/squid/store.log
cache_swap_log /var/log/squid/swap.log
logfile_rotate 10

# Squid normally listens to port 3128
#http_port 8080
http_port 8080 ssl-bump cert=/etc/squid/proxy.xxx.local.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
options=NO_SSLv3,NO_SSLv2 s$

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/spool/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320


#
maximum_object_size 3000 KB

#Antivirus ClamAV
icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_header X-Authenticated-User
icap_service service_req reqmod_precache bypass=1
icap://127.0.0.1:1344/squidclamav
adaptation_access service_req allow all
icap_service service_resp respmod_precache bypass=1
icap://127.0.0.1:1344/squidclamav
adaptation_access service_resp allow all


------------------------------------------------------

the content of the "/etc/squid/estensionibloccate.txt" file is 

------------------------------------------------------

\.exe(\?.*)?$
\.com(\?.*)?$
\.scr(\?.*)?$
\.cmd(\?.*)?$
\.bat(\?.*)?$
\.vbs(\?.*)?$

------------------------------------------------------

Locked for only some users via ACL, the acl is placed at the end, so that
only few users hit this acl

I've already increased the number of vcpu for the machine, but the only
process that i see eating cpu is squid, the helpers aren't eating a lot. I
see only sometimes the clamav service goind high on usage but i think that's
normal.
There is something that i miss or optimize in the config, or simply the
sslbump requires a lot of resources?

Thanks!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From tobias.wolter at b1-systems.de  Tue Apr 24 13:41:12 2018
From: tobias.wolter at b1-systems.de (Tobias Wolter)
Date: Tue, 24 Apr 2018 15:41:12 +0200
Subject: [squid-users] [SOLVED-ish] Multiple responses in cache objects
In-Reply-To: <9c4c3e78914af926bee416142406032ebd06f573.camel@b1-systems.de>
References: <58dd58c9b69e3e4618fca7333eb4ac8b820c4446.camel@b1-systems.de>
 <557634c9-2795-6ac6-97c8-1e1c5ab70a0f@treenet.co.nz>
 <9c4c3e78914af926bee416142406032ebd06f573.camel@b1-systems.de>
Message-ID: <5515f2cf620f86bd3eb5f9b3c3077018f9ef3a29.camel@b1-systems.de>

Cheers,

On Mon, 2018-04-23 at 22:54 +0200, Tobias Wolter wrote:
> Kudos for the hints, Amos, they're great and'll help me a lot
> (tomorrow, it's 22.54 local here).

Welp, we haven't really come that far, but what we can tell is that
Squid isn't at fault by itself, as we merely forced it to cache some
bad responses from the Apache.

For anyone interested: We've narrowed it down to issues accessing files
on the local filesystem or remotely; Apache seems to hang trying to put
the file into an existing HTTP/1.1 keep-alive connection. If you turn
off KeepAlive, it works (delay still present, <10s); if KeepAlive is
on, we can see from tcpdump that Apache will happily respond to
KeepAlive requests, but then dump one of the previous response joined
with another response, without <CR><LF> in between.

Not sure what's causing the hang yet, but apparently not Squid, so
thanks!

-towo
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: This is a digitally signed message part
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180424/0b58640f/attachment.sig>

From rousskov at measurement-factory.com  Tue Apr 24 14:09:23 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 24 Apr 2018 08:09:23 -0600
Subject: [squid-users] SSLBump and squid process CPU usage
In-Reply-To: <1524572045107-0.post@n4.nabble.com>
References: <1524572045107-0.post@n4.nabble.com>
Message-ID: <1632561d-56d3-4636-0c2c-a022d2476f26@measurement-factory.com>

On 04/24/2018 06:14 AM, masterx81 wrote:

> I've configured squid with ssl_bump and now the squid process (not the
> helpers) takes quite load. There aren't too much clients on it (max 50).

> I've already increased the number of vcpu for the machine, but the only
> process that i see eating cpu is squid, the helpers aren't eating a lot.
> There is something that i miss or optimize in the config, or simply the
> sslbump requires a lot of resources?

I have not studied your configuration, but doing SSL encryption and/or
decryption (including the SslBump "bump" action) does require a lot of
CPU cycles. Enabling bumping may decrease sustained peak throughput by
70% or more.

If your users are suffering, and your machine has spare physical CPU
cores, consider using SMP Squid:
https://wiki.squid-cache.org/Features/SmpScale

Alex.


From gecom at tubosider.it  Tue Apr 24 16:11:33 2018
From: gecom at tubosider.it (masterx81)
Date: Tue, 24 Apr 2018 09:11:33 -0700 (MST)
Subject: [squid-users] SSLBump and squid process CPU usage
In-Reply-To: <1632561d-56d3-4636-0c2c-a022d2476f26@measurement-factory.com>
References: <1524572045107-0.post@n4.nabble.com>
 <1632561d-56d3-4636-0c2c-a022d2476f26@measurement-factory.com>
Message-ID: <1524586293515-0.post@n4.nabble.com>

Wow, a lot to read (and understand, for a newbie like me :-|)....
>From what i've seen it's sufficient to insert the "workers n" directive in
the conf (n number of workers). With some limitations with the features that
support SMP (delay pools, cache, etc - i not think to use any of them)



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Wed Apr 25 01:34:44 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 25 Apr 2018 13:34:44 +1200
Subject: [squid-users] [SOLVED-ish] Multiple responses in cache objects
In-Reply-To: <5515f2cf620f86bd3eb5f9b3c3077018f9ef3a29.camel@b1-systems.de>
References: <58dd58c9b69e3e4618fca7333eb4ac8b820c4446.camel@b1-systems.de>
 <557634c9-2795-6ac6-97c8-1e1c5ab70a0f@treenet.co.nz>
 <9c4c3e78914af926bee416142406032ebd06f573.camel@b1-systems.de>
 <5515f2cf620f86bd3eb5f9b3c3077018f9ef3a29.camel@b1-systems.de>
Message-ID: <24006838-059b-c8f2-2acd-95510e45ad82@treenet.co.nz>

On 25/04/18 01:41, Tobias Wolter wrote:
> Cheers,
> 
> On Mon, 2018-04-23 at 22:54 +0200, Tobias Wolter wrote:
>> Kudos for the hints, Amos, they're great and'll help me a lot
>> (tomorrow, it's 22.54 local here).
> 
> Welp, we haven't really come that far, but what we can tell is that
> Squid isn't at fault by itself, as we merely forced it to cache some
> bad responses from the Apache.
> 
> For anyone interested: We've narrowed it down to issues accessing files
> on the local filesystem or remotely; Apache seems to hang trying to put
> the file into an existing HTTP/1.1 keep-alive connection. If you turn
> off KeepAlive, it works (delay still present, <10s); if KeepAlive is
> on, we can see from tcpdump that Apache will happily respond to
> KeepAlive requests, but then dump one of the previous response joined
> with another response, without <CR><LF> in between.
> 
> Not sure what's causing the hang yet, but apparently not Squid, so
> thanks!

Welcome and good luck.

FWIW; CRLF is not required between responses. If the first response has
a Content-Length the payload ends at the exact byte indicated and the
second response starts the byte after - no need for a CRLF. So don't
think that absence necessarily a bug in itself.

Amos


From rightkicktech at gmail.com  Wed Apr 25 11:44:26 2018
From: rightkicktech at gmail.com (Alex K)
Date: Wed, 25 Apr 2018 14:44:26 +0300
Subject: [squid-users] Squid with squidguard
Message-ID: <CABMULtJMNxGQbUDWjHTWvEHuqGxQn_hJpkGb4miKrn1M+_m+Ng@mail.gmail.com>

Hi all,

I was using a squid (3.1.20) + squidguard setup (to filter out several site
categories) on Debian 7 and the setup worked. The squidguard was invoked
from squid.conf as below:

redirect_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
redirect_children 7

I am now testing the setup on Debian 9 (with squid 3.5.23) with the
following lines in squid.conf:

url_rewrite_access allow
url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
url_rewrite_children 5

But I get at squid logs:

2018/04/24 12:06:57 kid1| helperOpenServers: Starting 0/5 'squidGuard'
processes
2018/04/24 12:06:57 kid1| helperOpenServers: No 'squidGuard' processes
needed.


Seems that squid is ignoring and not starting squidguard.
I have read also some have mentioned that squidguard is not maintained
anymore.

Any idea on the above?
Any better alternative to squidguard that you recommend?

thanx,
Alex
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180425/48e90bd3/attachment.htm>

From saravanan.nagarajan87 at gmail.com  Wed Apr 25 19:41:57 2018
From: saravanan.nagarajan87 at gmail.com (SaRaVanAn)
Date: Wed, 25 Apr 2018 14:41:57 -0500
Subject: [squid-users] Squid 3.5.10 - slow upload speed
Message-ID: <CA+86yMgnxGAa_nef6qgtif2q_jOAY88KFkg=CMDeT1eSFVQeBw@mail.gmail.com>

We are using Squid 3.5.10 for caching. It looks like upload is very slow
when it goes through squid . If we disable the squid, upload speed is good.
When we analyse the packet captures, it seems squid is dividing HTTP POST
request into multiple segments of 39 bytes each even though link is capable
of pushing 10 Mbps. We don't see this issue in squid 3.1.  Do we have any
known issue in squid 3.5.10 with respect to upload?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180425/e9f87fac/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 33197 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180425/e9f87fac/attachment.png>

From Mike.Mitchell at sas.com  Wed Apr 25 20:04:02 2018
From: Mike.Mitchell at sas.com (Mike Mitchell)
Date: Wed, 25 Apr 2018 20:04:02 +0000
Subject: [squid-users] Squid 3.5.10 - slow upload speed
Message-ID: <BL2PR05MB226029307FE70407BE8556CFEE8F0@BL2PR05MB2260.namprd05.prod.outlook.com>

Fixed in Squid 3.5.20.  The current stable release is Squid 3.5.27.
See http://www.squid-cache.org/Versions/v3/3.5/changesets/squid-3.5-14061.patch for details.

Mike Mitchell


From squid3 at treenet.co.nz  Thu Apr 26 01:02:27 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 26 Apr 2018 13:02:27 +1200
Subject: [squid-users] Squid with squidguard
In-Reply-To: <CABMULtJMNxGQbUDWjHTWvEHuqGxQn_hJpkGb4miKrn1M+_m+Ng@mail.gmail.com>
References: <CABMULtJMNxGQbUDWjHTWvEHuqGxQn_hJpkGb4miKrn1M+_m+Ng@mail.gmail.com>
Message-ID: <d8c6300e-1cfb-940c-15f6-3de717784401@treenet.co.nz>

On 25/04/18 23:44, Alex K wrote:
> Hi all,
> 
> I was using a squid (3.1.20) + squidguard setup (to filter out several
> site categories) on Debian 7 and the setup worked. The squidguard was
> invoked from squid.conf as below:
> 
> redirect_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
> redirect_children 7
> 
> I am now testing the setup on Debian 9 (with squid 3.5.23) with the
> following lines in squid.conf:
> 
> url_rewrite_access allow

There are no ACLs on the above line. So it cannot match anything. The
implicit default applies instead. Implicit default after any "allow"
line is "deny all".

Also, you did not configure any allow/deny previously. So why add it now?

> url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
> url_rewrite_children 5
> 
> But I get at squid logs:
> 
> 2018/04/24 12:06:57 kid1| helperOpenServers: Starting 0/5 'squidGuard'
> processes
> 2018/04/24 12:06:57 kid1| helperOpenServers: No 'squidGuard' processes
> needed.

No traffic is allowed to go to the helper. So no SG processes necessary.
Squid is correct.


> 
> Seems that squid is ignoring and not starting squidguard.
> I have read also some have mentioned that squidguard is not maintained
> anymore.
> 
> Any idea on the above?> Any better alternative to squidguard that you recommend?

ufdbguard is much better than the outdated and no longer maintained
SquidGuard (but is not packaged on Debian).

Amos


From gecom at tubosider.it  Thu Apr 26 08:40:08 2018
From: gecom at tubosider.it (masterx81)
Date: Thu, 26 Apr 2018 01:40:08 -0700 (MST)
Subject: [squid-users] tlsv1 alert unknown ca (1/0)
Message-ID: <1524732008666-0.post@n4.nabble.com>

Hi!
I've enabled the ssl-bump with following directives:
acl no_ssl_interception dstdomain .somedomain.com

ssl_bump none localhost
ssl_bump none no_ssl_interception

ssl_bump stare
ssl_bump bump all

http_port 8080 ssl-bump cert=/etc/squid/ca.pem generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB options=NO_SSLv3,NO_SSLv2
sslflags=NO_DEFAULT_CA


But in the cache.log file i have a lot of:
2018/04/26 10:27:45 kid1| Error negotiating SSL connection on FD 70:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)

tried to put the directive
sslproxy_cafile /etc/ssl/certs/ca-bundle.crt

tried to do the yum install ca-certificates to update the packages, no luck.

I've read several discussions about this, but i've not came up with
nothing...

the sites on the clients open well...

What i can try to do?
Thanks!





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Thu Apr 26 10:33:59 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 26 Apr 2018 22:33:59 +1200
Subject: [squid-users] tlsv1 alert unknown ca (1/0)
In-Reply-To: <1524732008666-0.post@n4.nabble.com>
References: <1524732008666-0.post@n4.nabble.com>
Message-ID: <95ab2b24-d319-99d2-fb40-407ab6a7860b@treenet.co.nz>

On 26/04/18 20:40, masterx81 wrote:
> 
> What i can try to do?

You can try to find out what the CA is and work from there.

Amos


From jbhasin83 at gmail.com  Thu Apr 26 12:20:18 2018
From: jbhasin83 at gmail.com (jbhasin83)
Date: Thu, 26 Apr 2018 05:20:18 -0700 (MST)
Subject: [squid-users] When does Squid reset upstream  connections?
In-Reply-To: <e09eb883fdb89e2aac9dbb59b6180122@treenet.co.nz>
References: <CAKSQQ5MESSwWSaTHCB42Miq3A25tDKX0uBrvF5jt1e8SiEkDdA@mail.gmail.com>
 <e09eb883fdb89e2aac9dbb59b6180122@treenet.co.nz>
Message-ID: <1524745218833-0.post@n4.nabble.com>

Hello,

I have a squid set up in transparent proxy. Squid sends a TCP RESET message
to the uperstream server but does not put an outgoing TCP outgoing mark.
Squid puts an outgoing TCP mark on every other packet going upstream.
Is this a bug ?

Thanks,
Jatin Bhasin



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Thu Apr 26 12:58:49 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 27 Apr 2018 00:58:49 +1200
Subject: [squid-users] When does Squid reset upstream connections?
In-Reply-To: <1524745218833-0.post@n4.nabble.com>
References: <CAKSQQ5MESSwWSaTHCB42Miq3A25tDKX0uBrvF5jt1e8SiEkDdA@mail.gmail.com>
 <e09eb883fdb89e2aac9dbb59b6180122@treenet.co.nz>
 <1524745218833-0.post@n4.nabble.com>
Message-ID: <cc87d83c-1d74-5439-5ac8-30c7ae2586c4@treenet.co.nz>

On 27/04/18 00:20, jbhasin83 wrote:
> Hello,
> 
> I have a squid set up in transparent proxy. Squid sends a TCP RESET message
> to the uperstream server but does not put an outgoing TCP outgoing mark.
> Squid puts an outgoing TCP mark on every other packet going upstream.
> Is this a bug ?

Maybe, *if* the RESET was sent by Squid. The TCP network stack itself
can also generate them if data arrives on a socket/port which was
previously closed by Squid with a FIN, FIN+ACK, or earlier RST packet.

Amos


From rightkicktech at gmail.com  Thu Apr 26 13:03:45 2018
From: rightkicktech at gmail.com (Alex K)
Date: Thu, 26 Apr 2018 16:03:45 +0300
Subject: [squid-users] Squid with squidguard
In-Reply-To: <d8c6300e-1cfb-940c-15f6-3de717784401@treenet.co.nz>
References: <CABMULtJMNxGQbUDWjHTWvEHuqGxQn_hJpkGb4miKrn1M+_m+Ng@mail.gmail.com>
 <d8c6300e-1cfb-940c-15f6-3de717784401@treenet.co.nz>
Message-ID: <CABMULt+ieUJKy+iC_3xeiNbi+aAG+KTh1AZTeN72nehXRHo9wg@mail.gmail.com>

Thank you Amos for the feedback.

I did see an example online using ACL and that tricked me.
Removing the allow line, now squid is logging that squidguard is started
(though no squidguard processes are listed, it could be due to that I have
not tested yet with actual traffic)

I will check also ufdbguard as it seems promising.

Thanx,
Alex

On Thu, Apr 26, 2018 at 4:02 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 25/04/18 23:44, Alex K wrote:
> > Hi all,
> >
> > I was using a squid (3.1.20) + squidguard setup (to filter out several
> > site categories) on Debian 7 and the setup worked. The squidguard was
> > invoked from squid.conf as below:
> >
> > redirect_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
> > redirect_children 7
> >
> > I am now testing the setup on Debian 9 (with squid 3.5.23) with the
> > following lines in squid.conf:
> >
> > url_rewrite_access allow
>
> There are no ACLs on the above line. So it cannot match anything. The
> implicit default applies instead. Implicit default after any "allow"
> line is "deny all".
>
> Also, you did not configure any allow/deny previously. So why add it now?
>
> > url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.
> conf
> > url_rewrite_children 5
> >
> > But I get at squid logs:
> >
> > 2018/04/24 12:06:57 kid1| helperOpenServers: Starting 0/5 'squidGuard'
> > processes
> > 2018/04/24 12:06:57 kid1| helperOpenServers: No 'squidGuard' processes
> > needed.
>
> No traffic is allowed to go to the helper. So no SG processes necessary.
> Squid is correct.
>
>
> >
> > Seems that squid is ignoring and not starting squidguard.
> > I have read also some have mentioned that squidguard is not maintained
> > anymore.
> >
> > Any idea on the above?> Any better alternative to squidguard that you
> recommend?
>
> ufdbguard is much better than the outdated and no longer maintained
> SquidGuard (but is not packaged on Debian).
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180426/c9a5dd54/attachment.htm>

From gecom at tubosider.it  Thu Apr 26 15:11:06 2018
From: gecom at tubosider.it (masterx81)
Date: Thu, 26 Apr 2018 08:11:06 -0700 (MST)
Subject: [squid-users] tlsv1 alert unknown ca (1/0)
In-Reply-To: <95ab2b24-d319-99d2-fb40-407ab6a7860b@treenet.co.nz>
References: <1524732008666-0.post@n4.nabble.com>
 <95ab2b24-d319-99d2-fb40-407ab6a7860b@treenet.co.nz>
Message-ID: <1524755466240-0.post@n4.nabble.com>

How i can find what is the problematic CA?
On the cache.log i have hundreds of this (aroung 10 per second), but in the
access.log i have really few TCP_DENIED connections or in general other
errors that can indicate what's causing that problem.

Thanks!!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From gecom at tubosider.it  Thu Apr 26 15:19:52 2018
From: gecom at tubosider.it (masterx81)
Date: Thu, 26 Apr 2018 08:19:52 -0700 (MST)
Subject: [squid-users] SSLBump and squid process CPU usage
In-Reply-To: <1524586293515-0.post@n4.nabble.com>
References: <1524572045107-0.post@n4.nabble.com>
 <1632561d-56d3-4636-0c2c-a022d2476f26@measurement-factory.com>
 <1524586293515-0.post@n4.nabble.com>
Message-ID: <1524755992096-0.post@n4.nabble.com>

For now i've tried with the "workers 3" directive, i can see 3 squid process,
seem that they span quite evenly the load and the page loading seem better.
Hope that fix the bottlenek...
In any case, i not know if there is somtheing wrong in the config that can
hurt the performance....



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From gecom at tubosider.it  Thu Apr 26 15:58:23 2018
From: gecom at tubosider.it (masterx81)
Date: Thu, 26 Apr 2018 08:58:23 -0700 (MST)
Subject: [squid-users] tlsv1 alert unknown ca (1/0)
In-Reply-To: <1524755466240-0.post@n4.nabble.com>
References: <1524732008666-0.post@n4.nabble.com>
 <95ab2b24-d319-99d2-fb40-407ab6a7860b@treenet.co.nz>
 <1524755466240-0.post@n4.nabble.com>
Message-ID: <1524758303257-0.post@n4.nabble.com>

Maybe i've spotted what was. Trendmicro Antivirus (cloud version). Was
generating a lot of TCP_MISS with status code 200. Added the domain
.trendmicro.com to the "not bumped" domains (with some microsoft domains
used for the update processes) and the cache file is sooooo much clean!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From eliezer at ngtech.co.il  Fri Apr 27 00:50:37 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 27 Apr 2018 03:50:37 +0300
Subject: [squid-users] Dynamically updating iptables ipset to bypass squid.
Message-ID: <008e01d3ddc1$c1fb60e0$45f222a0$@ngtech.co.il>

I talked to a developer which uses dnsmasq and it seems to have an option to
add resolved ip addresses into a linux ipset set.

So it is possible to dynamically add IP addresses of domains out of the
proxy interception.

Ideally an ICAP service will be able to see the request and redirect the
client using some 30X code to a request that will not be considered a loop.

And.. by the time the client will is being "redirected(maybe couple times)
the client traffic will no be intercept era at all leaving the OS and the
CPU to spend the right amount of resources.

 

Elizer 

 

----

Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180427/b1a0e57e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11307 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180427/b1a0e57e/attachment.png>

From squid3 at treenet.co.nz  Fri Apr 27 01:51:30 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 27 Apr 2018 13:51:30 +1200
Subject: [squid-users] SSLBump and squid process CPU usage
In-Reply-To: <1524755992096-0.post@n4.nabble.com>
References: <1524572045107-0.post@n4.nabble.com>
 <1632561d-56d3-4636-0c2c-a022d2476f26@measurement-factory.com>
 <1524586293515-0.post@n4.nabble.com> <1524755992096-0.post@n4.nabble.com>
Message-ID: <4c9a83f2-5c0a-c48d-1d00-0a8184cd11c1@treenet.co.nz>

On 27/04/18 03:19, masterx81 wrote:
> For now i've tried with the "workers 3" directive, i can see 3 squid process,
> seem that they span quite evenly the load and the page loading seem better.
> Hope that fix the bottlenek...
> In any case, i not know if there is somtheing wrong in the config that can
> hurt the performance....

Maybe yes, maybe no. The big performance drags are ICAP with extra TCP
resources requirements and delays, SSL-Bump with the TLS overheads, lots
of complex ACL processing, and regular network delays.

You mention having many ACLs but elided them so we cannot provide any
audit or hints to optimizing that part. The other parts you will have to
yourself test and check for what the actual delays are from each.

Amos


From gecom at tubosider.it  Fri Apr 27 07:46:53 2018
From: gecom at tubosider.it (masterx81)
Date: Fri, 27 Apr 2018 00:46:53 -0700 (MST)
Subject: [squid-users] SSLBump and squid process CPU usage
In-Reply-To: <4c9a83f2-5c0a-c48d-1d00-0a8184cd11c1@treenet.co.nz>
References: <1524572045107-0.post@n4.nabble.com>
 <1632561d-56d3-4636-0c2c-a022d2476f26@measurement-factory.com>
 <1524586293515-0.post@n4.nabble.com> <1524755992096-0.post@n4.nabble.com>
 <4c9a83f2-5c0a-c48d-1d00-0a8184cd11c1@treenet.co.nz>
Message-ID: <1524815213981-0.post@n4.nabble.com>

By now i not see anymore the single squid process taking all the resources,
using the multi process the load is spread and all seem work really well. I
see only sometimes the clam-d service hitting 100% for few istants but i
think that is normal, as it's a single process, but not cause any slowdown.
The ACL that i've cut are only big lists of dstdomain (i think that not
require much cpu), and acl for some groups of users (time based ACL).
Nothing really intensive.
The only thing that i think can be intensive is the extension checking for
locking some users, but only few clients hit this ACL.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From fourir.akbar at gmail.com  Sat Apr 28 08:56:23 2018
From: fourir.akbar at gmail.com (fourirakbar)
Date: Sat, 28 Apr 2018 01:56:23 -0700 (MST)
Subject: [squid-users] Squid 3.5.27 - While access https website,
 always "Your connection is not secure"
Message-ID: <1524905783708-0.post@n4.nabble.com>

Maybe this is same with  this topic
<http://squid-web-proxy-cache.1019090.n4.nabble.com/option-to-auto-recreate-the-ssl-db-td4682130.html> 
. But now I use squid version 3.5.27

Here my squid version
Squid Cache: Version 3.5.27
Service Name: squid
Ubuntu linux

This binary uses OpenSSL 1.0.2g  1 Mar 2016. For legal restrictions on
distribution see https://www.openssl.org/source/license.html

configure options:  '--build=x86_64-linux-gnu' '--prefix=/usr'
'--includedir=${prefix}/include' '--mandir=${prefix}/share/man'
'--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var'
'--libexecdir=${prefix}/lib/squid3' '--srcdir=.' '--disable-maintainer-mode'
'--disable-dependency-tracking' '--disable-silent-rules' 'BUILDCXXFLAGS=-g
-O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security
-Wdate-time -D_FORTIFY_SOURCE=2 -Wl,-Bsymbolic-functions -fPIE -pie
-Wl,-z,relro -Wl,-z,now -Wl,--as-needed' 'CXX=g++' 'CC=gcc'
'--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
'--libexecdir=/usr/lib/squid' '--mandir=/usr/share/man' '--enable-inline'
'--disable-arch-native' '--enable-async-io=8'
'--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap'
'--enable-delay-pools' '--enable-cache-digests' '--enable-icap-client'
'--enable-follow-x-forwarded-for'
'--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB'
'--enable-auth-digest=file,LDAP' '--enable-auth-negotiate=kerberos,wrapper'
'--enable-auth-ntlm=fake,smb_lm'
'--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,time_quota,unix_group,wbinfo_group'
'--enable-url-rewrite-helpers=fake' '--enable-eui' '--enable-esi'
'--enable-icmp' '--enable-zph-qos' '--enable-ecap' '--disable-translation'
'--with-swapdir=/var/spool/squid' '--with-logdir=/var/log/squid'
'--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=65536'
'--with-large-files' '--with-default-user=proxy' '--with-openssl'
'--enable-ssl' '--enable-ssl-crtd' '--enable-build-info=Ubuntu linux'
'--enable-linux-netfilter' 'build_alias=x86_64-linux-gnu' 'CFLAGS=-g -O2
-fPIE -fstack-protector-strong -Wformat -Werror=format-security -Wall'
'LDFLAGS=-Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro -Wl,-z,now
-Wl,--as-needed' 'CPPFLAGS=-Wdate-time -D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2
-fPIE -fstack-protector-strong -Wformat -Werror=format-security'


I also make follow this tutorial:  Dynamic SSL Cert
<https://wiki.squid-cache.org/Features/DynamicSslCert>   from squid wiki.

*And my squid.conf*
    acl SSL_ports port 443 
    acl Safe_ports port 80 # http
    acl Safe_ports port 21 # ftp 
    acl Safe_ports port 443 # https 
    acl Safe_ports port 70 # gopher 
    acl Safe_ports port 210 # wais 
    acl Safe_ports port 1025-65535 # unregistered ports 
    acl Safe_ports port 280 # http-mgmt 
    acl Safe_ports port 488 # gss-http 
    acl Safe_ports port 591 # filemaker 
    acl Safe_ports port 777 # multiling http 
    acl Safe_ports port 445 # windows update 
    acl CONNECT method CONNECT 

    http_port 3128 ssl-bump \
        cert=/etc/squid/ssl_cert/myCA.pem \
        generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

    http_port 3129 intercept

    https_port 3130 intercept ssl-bump \
        cert=/etc/squid/ssl_cert/myCA.pem \
        generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

    http_access allow  all

    always_direct allow all 
    ssl_bump server-first all 

    sslproxy_flags DONT_VERIFY_PEER 

    # Just try to open instagram.com, but it also can't work. Same problem
    # acl whitelist ssl::server_name .instagram.com
    # acl step1 at_step SslBump1
    # ssl_bump peek step1
    # ssl_bump splice whitelist
    # ssl_bump bump all

    http_access deny !Safe_ports
    http_access deny CONNECT !SSL_ports

    cache_mem 512 MB 
    cache_swap_low 98 
    cache_swap_high 99 

    refresh_pattern ^ftp:           1440    20%     10080
    refresh_pattern ^gopher:        1440    0%      1440
    refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
    refresh_pattern .               0       20%     4320

    #sslcrtd_program /usr/local/squid/libexec/ssl_crtd -s
/usr/local/squid/var/lib/ssl_db -M 4MB
    #sslcrtd_children 5

    shutdown_lifetime 8 second 

    visible_hostname X450LD


Now I try to open https://about.gitlab.com

*There is an error on cache log:*
   ssl_crtd helper database '/var/lib/ssl_db' failed: Failed to open file
/var/lib/ssl_db/index.txt

In browser (I use firefox), it show an error "your connection is not
secure". I try add exception and view detail about certificate. And it show
like the picture below
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377437/gitlab5.png> 

And I compare with other client that the traffic not through my squid proxy
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377437/gitlab4.png> 

Its different. How can solved this?
Thank you very much





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Sat Apr 28 15:04:47 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 29 Apr 2018 03:04:47 +1200
Subject: [squid-users] Squid 3.5.27 - While access https website,
 always "Your connection is not secure"
In-Reply-To: <1524905783708-0.post@n4.nabble.com>
References: <1524905783708-0.post@n4.nabble.com>
Message-ID: <fa25a86b-6f6c-0ba2-2373-ae785831a4b2@treenet.co.nz>

On 28/04/18 20:56, fourirakbar wrote:
> Maybe this is same with  this topic
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/option-to-auto-recreate-the-ssl-db-td4682130.html> 
> . But now I use squid version 3.5.27
> 
> Here my squid version
> Squid Cache: Version 3.5.27
> Service Name: squid
> Ubuntu linux
> 
> This binary uses OpenSSL 1.0.2g  1 Mar 2016. For legal restrictions on
> distribution see https://www.openssl.org/source/license.html
> 
...
> 
> I also make follow this tutorial:  Dynamic SSL Cert
> <https://wiki.squid-cache.org/Features/DynamicSslCert>   from squid wiki.
> 
> *And my squid.conf*
...
> 
>     http_port 3128 ssl-bump \
>         cert=/etc/squid/ssl_cert/myCA.pem \
>         generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> 
>     http_port 3129 intercept
> 
>     https_port 3130 intercept ssl-bump \
>         cert=/etc/squid/ssl_cert/myCA.pem \
>         generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> 
>     http_access allow  all

A bad idea. This disables ALL HTTP layer protections on traffic going
through this proxy.

> 
>     always_direct allow all 

No need to do this always_direct.

>     ssl_bump server-first all 

This deprecated.

>From <https://wiki.squid-cache.org/Features/SslPeekAndSplice> :
"
Old Squid-3.3 style bumping: Establish a secure connection with the
server first, then establish a secure connection with the client, using
a mimicked server certificate.

Does not support peeking, which causes various problems.

When used for intercepted traffic SNI is not available and the server
raw-IP will be used in certificates.
"

Also, the below DONT_VERIFY_PEER prevents Squid from checking that any
of those server details are in any way valid.

> 
>     sslproxy_flags DONT_VERIFY_PEER 

This disables all TLS/SSL security.

In short, do not do any of the above liens up to and including
"http_access allow all". 'insecure' is the least of your worries with
this as it currently is.

> 
>     # Just try to open instagram.com, but it also can't work. Same problem

Please explain "can't work". The below config *does not* have any Squid
involvement with instagram traffic - it is spliced. Which means it acts
exactly as if the proxy were not even there, the TLS is ONLY between the
client and server.

Also, if you leave the server-first stuff above this it takes priority
and none of the below will actually happen.

>     # acl whitelist ssl::server_name .instagram.com
>     # acl step1 at_step SslBump1
>     # ssl_bump peek step1
>     # ssl_bump splice whitelist
>     # ssl_bump bump all
> 
>     http_access deny !Safe_ports
>     http_access deny CONNECT !SSL_ports
> 

You do not have any rules permitting access to HTTP(S) traffic here.
Please at least limit the traffic through the proxy to your LAN ranges,
if not something better.

...
> 
>     #sslcrtd_program /usr/local/squid/libexec/ssl_crtd -s
> /usr/local/squid/var/lib/ssl_db -M 4MB
>     #sslcrtd_children 5
> 
>     shutdown_lifetime 8 second 
> 
>     visible_hostname X450LD
> 
> 
> Now I try to open https://about.gitlab.com
> 
> *There is an error on cache log:*
>    ssl_crtd helper database '/var/lib/ssl_db' failed: Failed to open file
> /var/lib/ssl_db/index.txt
> 
> In browser (I use firefox), it show an error "your connection is not
> secure". I try add exception and view detail about certificate. And it show
> like the picture below
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377437/gitlab5.png> 
> 
> And I compare with other client that the traffic not through my squid proxy
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377437/gitlab4.png> 
> 
> Its different. How can solved this?

The Browser needs to trust the CA "Internet Widgets Pty Ltd". One
assumes that is the name of the issuer CA you created and put in
/etc/squid/ssl_cert/myCA.pem.

This is why all our tutorials at some point mention** the requirement to
add your custom CA to the client machine/software. SSL-Bump decryption
(bump, client-first and server-first actions) *will not* work without
that having been done. If you do not do that part the result is exactly
what you see happening.


** if any don't that is an oversight, please let us know.

Amos


From dameffy at googlemail.com  Sat Apr 28 19:22:11 2018
From: dameffy at googlemail.com (Matthias Eder)
Date: Sat, 28 Apr 2018 21:22:11 +0200
Subject: [squid-users] Bypass HSTS sites in squid?
Message-ID: <CAJXuoAB1mtpJPK3isb=Ropfuf1SjBNT6=X43=K=i8bZpo59G=w@mail.gmail.com>

 I have set up after along struggle a transparent proxy with squid,
squidguard and privoxy. This works quite fine, surprisingly also for https
sites. Unfortunately the performance is not too good, but I guess the
man-in-the-middle attack is quite a lot of work for squid ;-). Before
anyone is complaining: this is for my private network at home and this is
more or less part of a project to set up a home router and learn a little
bit of this stuff :-).

Anyway, here is the problem where I am stuck at the moment: as mentioned
connection to most of the https sites works without problems, but I guess
connection to sites with public key pinning (HSTS...?) gives me a
SSL_ERROR_BAD_CERT_DOMAIN error in Firefox; here i can't add an exception
for this site (e.g. in my case https://ubuntuusers.de/). After some
googling it seems that there is no way that squid could "break" into this
connection, so the question is: is there any way to exclude or bypass some
sites so that the proxy is not used? I guess the difficulty may be the
https here...

Thanks a lot!!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180428/52ae25d1/attachment.htm>

From spinic at gmail.com  Sat Apr 28 21:57:06 2018
From: spinic at gmail.com (Rick Ellis)
Date: Sat, 28 Apr 2018 14:57:06 -0700
Subject: [squid-users] Squid 4 %R in deny_info
Message-ID: <CA+s7q3yAvRSyX8THhjeM6ub8oogX-v9MfSPXka6=61xcPmwbdA@mail.gmail.com>

Before trying squid 4 this worked as intended:

acl PORT80 myport 80
acl MYSITE dstdomain www.domain.com
http_access deny PORT80 MYSITE
deny_info 301:https://www.domain.com%R MYSITE

For 4.0.24 the %R is always blank. So all redirected go to the root of the
website. Is there something else I should be doing or is this a bug?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180428/661b4994/attachment.htm>

From squid3 at treenet.co.nz  Sat Apr 28 23:09:59 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 29 Apr 2018 11:09:59 +1200
Subject: [squid-users] Bypass HSTS sites in squid?
In-Reply-To: <CAJXuoAB1mtpJPK3isb=Ropfuf1SjBNT6=X43=K=i8bZpo59G=w@mail.gmail.com>
References: <CAJXuoAB1mtpJPK3isb=Ropfuf1SjBNT6=X43=K=i8bZpo59G=w@mail.gmail.com>
Message-ID: <e491cb84-38fb-65c2-ecde-1283744b0b21@treenet.co.nz>

On 29/04/18 07:22, Matthias Eder wrote:
> I have set up after along struggle a transparent proxy with squid,
> squidguard and privoxy. This works quite fine, surprisingly also for
> https sites. Unfortunately the performance is not too good, but I guess
> the man-in-the-middle attack is quite a lot of work for squid ;-).
> Before anyone is complaining: this is for my private network at home and
> this is more or less part of a project to set up a home router and learn
> a little bit of this stuff :-).
> 
> Anyway, here is the problem where I am stuck at the moment: as mentioned
> connection to most of the https sites works without problems, but I
> guess connection to sites with public key pinning (HSTS...?) gives me a

FYI: Current Squid releases all erase HSTS headers from traffic which
gets decrypted. So for HSTS to have any effect the Browsers need to be
fetching content without the proxy knowing about it. eg old HSTS details
received before they started use the proxy.


> SSL_ERROR_BAD_CERT_DOMAIN error in Firefox; here i can't add an
> exception for this site (e.g. in my case https://ubuntuusers.de/). After
> some googling it seems that there is no way that squid could "break"
> into this connection, so the question is: is there any way to exclude or
> bypass some sites so that the proxy is not used? I guess the difficulty
> may be the https here...

Connections that cannot (or you do not want to be) bump'ed is what the
SSL-Bump "splice" action is for. If you do not have a Squid accepting
that action you urgently need to upgrade.


Also, SG re-writes the URLs (including domain) of HTTP(S) traffic it
gets asked about. Naturally if it changes the domain for messages they
will no longer have the "old" domain which was linked explicitly to the
X.509 certificate the client was given by TLS. Some servers tolerate
that, some do not. This is one of many reasons SG (and re-writers in
general) should not be used, especially with HTTPS traffic.

Amos


From squid3 at treenet.co.nz  Sat Apr 28 23:20:04 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 29 Apr 2018 11:20:04 +1200
Subject: [squid-users] Squid 4 %R in deny_info
In-Reply-To: <CA+s7q3yAvRSyX8THhjeM6ub8oogX-v9MfSPXka6=61xcPmwbdA@mail.gmail.com>
References: <CA+s7q3yAvRSyX8THhjeM6ub8oogX-v9MfSPXka6=61xcPmwbdA@mail.gmail.com>
Message-ID: <966eb265-7c11-b5d9-2d94-6bb4cc2019d6@treenet.co.nz>

On 29/04/18 09:57, Rick Ellis wrote:
> Before trying squid 4 this worked as intended:
> 
> acl PORT80 myport 80

FYI: That ACL type is deprecated because it is so unreliable. Use
myportname (Squid listening host/IP:port or name= parameter) or
localport (the src-port from TCP) , depending on which is more
appropriate for your needs.

> acl MYSITE dstdomain www.domain.com
> http_access deny PORT80 MYSITE
> deny_info 301:https://www.domain.com%R MYSITE
> 
> For 4.0.24 the %R is always blank. So all redirected go to the root of
> the website. Is there something else I should be doing or is this a bug?
> 

That seems to be a bug. I think I can already see what is causing it, if
you open a bug report I'll attach a test patch there for you.

Amos


From fourir.akbar at gmail.com  Sun Apr 29 03:52:27 2018
From: fourir.akbar at gmail.com (fourirakbar)
Date: Sat, 28 Apr 2018 20:52:27 -0700 (MST)
Subject: [squid-users] Squid 3.5.27 - While access https website,
 always "Your connection is not secure"
In-Reply-To: <fa25a86b-6f6c-0ba2-2373-ae785831a4b2@treenet.co.nz>
References: <1524905783708-0.post@n4.nabble.com>
 <fa25a86b-6f6c-0ba2-2373-ae785831a4b2@treenet.co.nz>
Message-ID: <1524973947097-0.post@n4.nabble.com>

Thank you Amos.

> In short, do not do any of the above liens up to and including 
> "http_access allow all". 'insecure' is the least of your worries with 
> this as it currently is

Why I use http_access allow all is, at least I can access https website
first. Then I certainly use acl, and didn't use http_access allow all again

> The Browser needs to trust the CA "Internet Widgets Pty Ltd". One 
> assumes that is the name of the issuer CA you created and put in 
> /etc/squid/ssl_cert/myCA.pem. 

> This is why all our tutorials at some point mention** the requirement to 
> add your custom CA to the client machine/software. SSL-Bump decryption 
> (bump, client-first and server-first actions) *will not* work without 
> that having been done. If you do not do that part the result is exactly 
> what you see happening.

So how make the correct configuration in squid to let client access https
website? I've struggle about this configuration

Thank you very much



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From anon.amish at gmail.com  Mon Apr 30 12:54:22 2018
From: anon.amish at gmail.com (Amish)
Date: Mon, 30 Apr 2018 18:24:22 +0530
Subject: [squid-users] deny_info and squid's own IP address?
Message-ID: <88295b8a-aab4-c02c-5a59-a582f5215e7c@gmail.com>

Hello

I have 2 LAN interface on squid box, say department A (192.168.1.1/24) 
and department B (192.168.2.1/24)

I have few banned sites. Say Facebook.

I have HTTP server (running on same server as squid) which shows custom 
pages with custom logo based on IP address.

When request comes for a banned site I would like client to be 
redirected based on squid's own IP.

Something like this:

acl blockedsites url_regex facebook
http_access deny blockedsites
deny_info http://SQUID-IP/banned.html blockedsites

I need SQUID-IP to be replaced by 192.168.1.1 or 192.168.2.1 depending 
on the IP on which connection came to.

For department A it would become http://192.168.1.1/banned.html and
For department B it would become http://192.168.2.1/banned.html.

I checked deny_info documentation page: 
http://www.squid-cache.org/Doc/config/deny_info/

But there is no such option. %h gives host name and not the IP.

So how do I do that? Did I miss any thing.

Thanks in advance for any help,

Amish.



From akismpa at gmail.com  Mon Apr 30 15:37:07 2018
From: akismpa at gmail.com (Panagiotis Bariamis)
Date: Mon, 30 Apr 2018 18:37:07 +0300
Subject: [squid-users] SSL accelerator
Message-ID: <CAPxN_PWr--ai5D+1zHD+y7P3xKRVi9=3GbjqEr3YH8H+3xUWXg@mail.gmail.com>

Hello ,
Has anyone used ssl accelerators cards for squid under FreeBSD ?
I want mostly to offload processors of ssl bump .
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180430/8b80dab4/attachment.htm>

