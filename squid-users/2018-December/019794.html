<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] SslBump Peek and Splice using Squid-4.1-5 in Amazon1 Linux with Squid Helpers
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20SslBump%20Peek%20and%20Splice%20using%20Squid-4.1-5%20in%0A%20Amazon1%20Linux%20with%20Squid%20Helpers&In-Reply-To=%3C15dc44bc-ef9e-02a6-f4bb-0d05087f5a3b%40treenet.co.nz%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="019793.html">
   <LINK REL="Next"  HREF="019833.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] SslBump Peek and Splice using Squid-4.1-5 in Amazon1 Linux with Squid Helpers</H1>
    <B>Amos Jeffries</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20SslBump%20Peek%20and%20Splice%20using%20Squid-4.1-5%20in%0A%20Amazon1%20Linux%20with%20Squid%20Helpers&In-Reply-To=%3C15dc44bc-ef9e-02a6-f4bb-0d05087f5a3b%40treenet.co.nz%3E"
       TITLE="[squid-users] SslBump Peek and Splice using Squid-4.1-5 in Amazon1 Linux with Squid Helpers">squid3 at treenet.co.nz
       </A><BR>
    <I>Tue Dec 11 23:07:49 UTC 2018</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="019793.html">[squid-users] SslBump Peek and Splice using Squid-4.1-5 in	Amazon1	Linux with Squid Helpers
</A></li>
        <LI>Next message (by thread): <A HREF="019833.html">[squid-users] SslBump Peek and Splice using Squid-4.1-5 in Amazon1 Linux with Squid Helpers
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#19794">[ date ]</a>
              <a href="thread.html#19794">[ thread ]</a>
              <a href="subject.html#19794">[ subject ]</a>
              <a href="author.html#19794">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On 12/12/18 6:53 am, Enrico Heine wrote:
&gt;<i> Dear Mike,
</I>&gt;<i> 
</I>&gt;<i> Please checkout the following and let us know if you need further help.
</I>&gt;<i> 
</I>&gt;<i> <A HREF="http://www.squid-cache.org/Doc/config/sslproxy_cert_error/">http://www.squid-cache.org/Doc/config/sslproxy_cert_error/</A>
</I>&gt;<i> 
</I>
Before you use it though, please consider what the words &quot;Certificate
does not match domainname&quot; actually *mean*.

This Squid is configured to deliver a single specific custom-built
certificate to all clients who contact the proxy. Yet the proxy is being
used to receive TLS traffic for any domain and the admin is passing test
traffic for multiple different domains and raw-IP addresses.



&gt;<i> Best regards,
</I>&gt;<i> 
</I>&gt;<i> Flashdown
</I>&gt;<i> 
</I>&gt;<i> Am 11. Dezember 2018 16:41:56 MEZ schrieb Mike Quentel:
</I>&gt;<i> 
</I>&gt;<i>     Hi, I have been unsuccessfully trying to get Squid-4.1-5 in AWS
</I>&gt;<i>     (Amazon 1 Linux) to allow transparent proxy of certain domains, as
</I>&gt;<i>     well as IPs associated with those domains, whilst rejecting everything
</I>&gt;<i>     else.
</I>&gt;<i> 
</I>&gt;<i>     I have been referencing documentation at
</I>&gt;<i>     <A HREF="https://wiki.squid-cache.org/Features/SslPeekAndSplice">https://wiki.squid-cache.org/Features/SslPeekAndSplice</A>
</I>&gt;<i> 
</I>&gt;<i>     Version of Squid: 4.1-5 for Amazon 1 Linux available at
</I>&gt;<i>     <A HREF="http://faster.ngtech.co.il/repo/amzn/1/beta/x86_64/">http://faster.ngtech.co.il/repo/amzn/1/beta/x86_64/</A> (many thanks to
</I>&gt;<i>     @elico for these packages) specifically, the following:
</I>&gt;<i> 
</I>&gt;<i>     1) <A HREF="http://faster.ngtech.co.il/repo/amzn/1/beta/x86_64/squid-4.1-5.amzn1.x86_64.rpm">http://faster.ngtech.co.il/repo/amzn/1/beta/x86_64/squid-4.1-5.amzn1.x86_64.rpm</A>
</I>&gt;<i>     2) <A HREF="http://faster.ngtech.co.il/repo/amzn/1/beta/x86_64/squid-helpers-4.1-5.amzn1.x86_64.rpm">http://faster.ngtech.co.il/repo/amzn/1/beta/x86_64/squid-helpers-4.1-5.amzn1.x86_64.rpm</A>
</I>&gt;<i> 
</I>&gt;<i>     Example of tests that I am running:
</I>&gt;<i> 
</I>&gt;<i>     1) curl -kv <A HREF="https://service.us2.sumologic.com">https://service.us2.sumologic.com</A> (EXPECTED: successfully
</I>&gt;<i>     accessed; OBSERVED: successfully accessed)
</I>
The TLS SNI contains &quot;service.us2.sumologic.com&quot;, and
 - the server produced an X.509 certificate for that domain, and
 - your server_name ACL matches it as a sub-domain of &quot;.sumologic.com&quot;


Note that the -k parameter for curl only disables security on the
curl&lt;-&gt;Squid TSL connection. It has nothing to do with the
Squid&lt;-&gt;origin connections.

You should really be using &quot;curl --cacert /etc/squid/squid.pem&quot; or
connections without the -k to test what actually happens for clients
when their traffic goes through your system.


&gt;<i>     2) curl -kv <A HREF="https://54.149.155.70">https://54.149.155.70</A> (EXPECTED: successfully accessed
</I>&gt;<i>     because it resolves to service.us2.sumologic.com; OBSERVED:
</I>&gt;<i>     &quot;Certificate does not match domainname&quot;  [No Error] (TLS code:
</I>&gt;<i>     SQUID_X509_V_ERR_DOMAIN_MISMATCH))
</I>
IMO the expectation is what is wrong here.

The TLS SNI does not exist, and
 - being intercepted traffic the CONNECT authority is
&quot;54.149.155.70:443&quot;, and
 - the server produced an X.509 certificate with SubjectName of either
&quot;54.149.155.70&quot; or something else not matching your server_name ACL entries.

FYI: server_name is a text-string matching ACL. I expect you will find
there is no reverse-DNS being performed during the ssl_bump testing,
only later after contact the server has already been decided to allow.
You can confirm that with the debug log your test produced. Look for the
lines saying what each ACL is checking for and against.


&gt;<i>     3) curl -kv <A HREF="https://www.google.com">https://www.google.com</A> (EXPECTED: failed to access;
</I>&gt;<i>     OBSERVED: failed to access)
</I>
&quot;failed to access&quot; is a gross over-simplification. This transaction is
both allowed and not-allowed at the same time.

If you look into the log I expect you will see this sequence happening:

 * the http_access rules *allow* the CONNECT tunnel, then

 * the ssl_bump rules select do &quot;bump&quot; action at Step-2 (aka. using only
the TLS clientHello details), then

 * curl -k ignores the small problem that you are not presenting the
X.509 keys belonging to Google.

 * the decrypted GET request inside the tunnel gets rejected because:
 - the &quot;allowed_https_sites&quot; ACL has no X.509 server details to test
against, so does not match.
  - the &quot;allowed_http_sites&quot; ACL does not match either
  - the &quot;http_access deny all&quot; matches everything reaching it.


&gt;<i>     4) curl -kv <A HREF="https://172.217.13.164">https://172.217.13.164</A> (EXPECTED: failed to access;
</I>&gt;<i>     OBSERVED: &quot;Certificate does not match domainname&quot;  [No Error] (TLS
</I>&gt;<i>     code: SQUID_X509_V_ERR_DOMAIN_MISMATCH))
</I>
Same thing going on as for test (2).


&gt;<i> 
</I>&gt;<i>     Below is the latest version of the squid.conf being used. Apologies
</I>&gt;<i>     for any obvious errors--new to Squid here. I have been grappling with
</I>&gt;<i>     this for weeks, with many iterations of squid.conf so any advice is
</I>&gt;<i>     greatly appreciated; many thanks in advance.
</I>&gt;<i>     ------------------------------------------------------------------------
</I>&gt;<i>     visible_hostname squid
</I>
You have connected this proxy to the Internet. The above is required by
Internet RFCs to be a FQDN (fully qualified domain name).

Even if you do not want to follow that requirements it MUST be a unique
name.  If any of your HTTP traffic ever goes through another proxy
sharing this *very common* config mistake you will encounter forwarding
loop errors.


&gt;<i> 
</I>&gt;<i>     host_verify_strict off
</I>
This is the default. No need to configure it.

Also, if you added that because the errors you mentioned are talking
about domain verification - be aware that HTTP &quot;Host:&quot; header
verification is quite a different thing from TLS certificate verification.


&gt;<i> 
</I>&gt;<i>     # Handling HTTP requests
</I>&gt;<i>     http_port 3128
</I>&gt;<i>     http_port 3129 intercept
</I>&gt;<i> 
</I>&gt;<i>     sslcrtd_children 10
</I>&gt;<i> 
</I>&gt;<i>     acl CONNECT method CONNECT
</I>&gt;<i> 
</I>&gt;<i>     # AWS services domain
</I>&gt;<i>     acl allowed_http_sites dstdomain .amazonaws.com
</I>&gt;<i>     # docker hub registry
</I>&gt;<i>     acl allowed_http_sites dstdomain .docker.io
</I>&gt;<i>     acl allowed_http_sites dstdomain .docker.com
</I>&gt;<i>     acl allowed_http_sites dstdomain www.congiu.net
</I>&gt;<i> 
</I>&gt;<i>     # Handling HTTPS requests
</I>&gt;<i>     # https_port 3130 intercept ssl-bump generate-host-certificates=on
</I>&gt;<i>     dynamic_cert_mem_cache_size=100MB cert=/etc/squid/squid.pem
</I>&gt;<i>     https_port 3130 intercept ssl-bump dynamic_cert_mem_cache_size=100MB
</I>&gt;<i>     cert=/etc/squid/squid.pem
</I>
FYI: both the lines above behave identical because the generate-*
setting you removed was being set to its default value anyway.


&gt;<i>     acl SSL_port port 443
</I>&gt;<i> 
</I>&gt;<i>     # AWS services domain
</I>&gt;<i>     acl allowed_https_sites ssl::server_name .amazonaws.com
</I>&gt;<i>     # docker hub registry
</I>&gt;<i>     acl allowed_https_sites ssl::server_name .docker.io
</I>&gt;<i>     acl allowed_https_sites ssl::server_name .docker.com
</I>&gt;<i> 
</I>&gt;<i>     # project specific
</I>&gt;<i>     acl allowed_https_sites ssl::server_name www.congiu.net
</I>&gt;<i>     acl allowed_https_sites ssl::server_name mirrors.fedoraproject.org
</I>&gt;<i>     acl allowed_https_sites ssl::server_name mirror.csclub.uwaterloo.ca
</I>&gt;<i> 
</I>&gt;<i>     # nslookup resolved IPs for collectors.sumologic.com
</I>&gt;<i>     # workaround solution to support sumologic collector
</I>&gt;<i>     acl allowed_https_sites ssl::server_name .sumologic.com
</I>&gt;<i>     # THE FOLLOWING TWO LINES DO NOT SEEM TO WORK AS EXPECTED
</I>
The expectation is wrong here.

The string &quot;sslflags=DONT_VERIFY_PEER&quot; is not a valid domain nor server
hostname. So highly unlikely that the X.509 certificate SubjectName or
AltSubjectName from the origin server will contain that string.

Also, the flag sets the ACL matching algorithm. When that is set the ACL
cannot match during a ssl_bump &quot;peek step1&quot; cycle.

So one should expect this ACL to stop working when these lines are
added. Not expect that it would do anything useful.


FYI: The string &quot;sslflags=DONT_VERIFY_PEER&quot; is the name and value of a
option other directives elsewhere in squid.conf can use. But it is a
very, very, very bad idea to do so - even 'just for testing'.

 The flag DONT_VERIFY_PEER disables all of TLS security checks - meaning
the connection actively becomes *less* safe than regular/plain-text TCP
connections, while simultaneously hiding all resulting issues from
*your* admin view. Users still have problems, you just cannot see any
hint of them.
 So please purge that setting from any configs and documents you come
across. Investigate and fix any TLS problems that appear, don't just
hide the error messages and pretend everything works.
 Same reason not to be using the equivalent &quot;curl -k&quot; option for testing
TLS validation/verification problems.



&gt;<i>     # acl allowed_https_sites ssl::server_name --server-provided
</I>&gt;<i>     service.sumologic.com sslflags=DONT_VERIFY_PEER
</I>&gt;<i>     # acl allowed_https_sites ssl::server_name --server-provided
</I>&gt;<i>     service.us2.sumologic.com sslflags=DONT_VERIFY_PEER
</I>&gt;<i> 
</I>&gt;<i>     acl step1 at_step SslBump1
</I>&gt;<i>     acl step2 at_step SslBump2
</I>&gt;<i>     acl step3 at_step SslBump3
</I>&gt;<i> 
</I>&gt;<i>     ssl_bump peek step1 all
</I>
The &quot;all&quot; here is useless and only adds confusion to anyone who thinks
it has any meaning.


&gt;<i>     ssl_bump peek step2 allowed_https_sites
</I>&gt;<i>     # <A HREF="http://lists.squid-cache.org/pipermail/squid-users/2018-September/019150.html">http://lists.squid-cache.org/pipermail/squid-users/2018-September/019150.html</A>
</I>
The author of that did not understand how the ssl-bump processing was
working. That entire message thread is them attempting to learn and IMO
still not quite understanding the ideas in the end.

Blindly copying into your config from experiments by someone who does
not understand what they are doing is not a good idea. Use an actually
known-working config example (the Squid wiki has several), or try to
design your own based on your own understanding. At the very least we
can see from your self-designed attempt what you may be thinking and
hopefully teach you where any mistakes are visible.


&gt;<i>     ssl_bump bump
</I>
Please be aware that when this line when reached at step2 it performs
&quot;client-first&quot; bumping of the TLS.

That means bumping and performing TLS handshake without any real X.509
server details for your allowed_https_sites ACL to use. Only
client-provided claims about what server they are contacting (which may
be outright lies). This has side-effects on what your ssl::server_name
vs dstdomain ACL do in the later http_access checks.

Specifically when the server_name and the URL domain are different
things a simple as testing one first can change permissions for the
client in the other.


&gt;<i>     ssl_bump splice step3 allowed_https_sites
</I>
So some of your traffic will splice from the above line - but only
because of the peek (step2) then bump (step3) combination being impossible.


&gt;<i>     ssl_bump bump
</I>
There is already an unrestricted &quot;bump&quot; action earlier. This line does
nothing even if it were possibly reached.


&gt;<i>     ssl_bump terminate step2 all
</I>
There is a peek action specified earlier for step2, with an unrestricted
bump action as a fallback when allowed_https_sites fails to match. This
line is never reachable.

&gt;<i> 
</I>&gt;<i>     http_access allow CONNECT
</I>
Ouch. Really do not do the above. The default config file shipped with
Squid starts with these lines for very good reasons:

&quot;
  http_access deny !Safe_ports
  http_access deny CONNECT !SSL_ports
  http_access allow localhost manager
  http_access deny manager

  #
  # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
  #
&quot;

Those reasons (DoS and proxy relay security vulnerabilities) are still
very much relevant in your setup, with no reason to remove them. So
please add them back before you continue testing things, with your
custom http_access rules *underneath* that comment line.

Also, the default SSL_ports is already setup in a way that meets your
requirements. You can adjust Safe_ports to be only the same port, or use
the default set of safe-for-HTTP ports.

FYI: the config you have right now allows any malicious origin server
receiving trafic on port 443 to present a X.509 certificate claiming to be.


&gt;<i> 
</I>&gt;<i>     # http_access allow SSL_port
</I>&gt;<i> 
</I>&gt;<i>     http_access deny CONNECT !allowed_https_sites
</I>&gt;<i>     http_access deny CONNECT !allowed_http_sites
</I>
The above two lines do nothing in your current config. CONNECT requests
are *always* allowed by the line you had earlier.

Once you move back to the default security checks these will start to do
things. It would probably be best to remove the two lines above to
prevent the unexpected new behaviour from confusing you further.


&gt;<i>     http_access allow allowed_https_sites
</I>&gt;<i>     http_access allow allowed_http_sites
</I>
These ACLs are very badly named.

* The one called &quot;allowed_https_sites&quot;:
 - will *not* match against HTTPS traffic arriving on port 3128 unless
the CONNECT authority-uri names a domain in your list.

- *will* match against HTTP traffic on port 3128 and port 3129 with
&quot;<A HREF="https://">https://</A>&quot; URLs.

* The one called &quot;allowed_http_sites&quot; *will* match against HTTPS traffic
arriving on any port.

 --&gt; meaning that for both of them the &quot;https&quot; and &quot;http&quot; word in their
name is deceptive.

* Both these ACLs are used to *deny* traffic.
 --&gt; meaning the &quot;allowed&quot; word in their name is deceptive.

What you are left with is just &quot;sites&quot; which is so vague as to be
meaningless.


It would be a lot clearer if you renamed them:
 - &quot;allowed_https_sites&quot; to &quot;tls_servers&quot;
 - &quot;allowed_http_sites&quot; to &quot;url_domains&quot;


&gt;<i>     http_access deny all
</I>&gt;<i> 
</I>&gt;<i>     cache deny all
</I>&gt;<i> 
</I>&gt;<i>     debug_options &quot;ALL,9&quot;
</I>
Cheers
Amos

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="019793.html">[squid-users] SslBump Peek and Splice using Squid-4.1-5 in	Amazon1	Linux with Squid Helpers
</A></li>
	<LI>Next message (by thread): <A HREF="019833.html">[squid-users] SslBump Peek and Splice using Squid-4.1-5 in Amazon1 Linux with Squid Helpers
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#19794">[ date ]</a>
              <a href="thread.html#19794">[ thread ]</a>
              <a href="subject.html#19794">[ subject ]</a>
              <a href="author.html#19794">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
