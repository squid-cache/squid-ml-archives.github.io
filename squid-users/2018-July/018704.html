<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] shared_memory_locking failed to mlock
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20shared_memory_locking%20failed%20to%20mlock&In-Reply-To=%3Ce1357a97-3f47-1064-1f0f-9c249e38f81d%40measurement-factory.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="018703.html">
   <LINK REL="Next"  HREF="018711.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] shared_memory_locking failed to mlock</H1>
    <B>Alex Rousskov</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20shared_memory_locking%20failed%20to%20mlock&In-Reply-To=%3Ce1357a97-3f47-1064-1f0f-9c249e38f81d%40measurement-factory.com%3E"
       TITLE="[squid-users] shared_memory_locking failed to mlock">rousskov at measurement-factory.com
       </A><BR>
    <I>Mon Jul 16 23:38:17 UTC 2018</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="018703.html">[squid-users] shared_memory_locking failed to mlock
</A></li>
        <LI>Next message (by thread): <A HREF="018711.html">[squid-users] shared_memory_locking failed to mlock
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#18704">[ date ]</a>
              <a href="thread.html#18704">[ thread ]</a>
              <a href="subject.html#18704">[ subject ]</a>
              <a href="author.html#18704">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On 07/16/2018 05:08 PM, Gordon Hsiao wrote:
&gt;<i> On a x86/64bit ubuntu machine if I set 'workers 4' and run:
</I>
&gt;<i> squid --foreground -f /etc/squid.conf 2&gt;&amp;1 |grep mlock
</I>&gt;<i> &#160; mlock(0x7f2e5bfb2000, 8)&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; = 0
</I>&gt;<i> &#160; mlock(0x7f2e5bf9f000, 73912)&#160; &#160; &#160; &#160; &#160; &#160; = -1 ENOMEM
</I>
&gt;<i> squid -N -f /etc/squid.conf 2&gt;&amp; |grep mlock
</I>&gt;<i> &#160; mlock(0x7f8e4b7c0000, 8)&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; = 0
</I>&gt;<i> &#160; mlock(0x7f8e4b7ad000, 73912)&#160; &#160; &#160; &#160; &#160; &#160; = -1 ENOMEM
</I>
&gt;<i> Note 1; -N and --foreground made no difference as long as 'workers 4' is
</I>&gt;<i> set, I was expecting -N will ignore &quot;worker 4&quot;, does it?
</I>
IIRC, -N does not start workers. However, some (memory allocation) code
may not honor -N and still allocate memory necessary for those (disabled
by -N) workers. That would be a bug AFAICT.


&gt;<i> Now I set 'workers 2' and run the same two commands above and I got the
</I>&gt;<i> output(both are the same), which means squid started successfully:
</I>&gt;<i> &#160; mlock(0x7f0c441cc000, 8)&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; = 0
</I>&gt;<i> &#160; mlock(0x7f0c441c3000, 32852)&#160; &#160; &#160; &#160; &#160; &#160; = 0
</I>&gt;<i> &#160; mlock(0x7f0c441c2000, 52)&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160;= 0
</I>
The second allocation is probably smaller because two workers need fewer
SMP queues (or similar shared memory resources) than four workers.


&gt;<i> I have more than 4GB RAM free(this is a 8GB RAM laptop) and this
</I>&gt;<i> is a Intel i7, the mlock failure is strange.
</I>
The default amount of shared memory available to a program is often much
smaller than the total amount of RAM. I do not recall which Ubuntu
commands or sysctl settings control the former, but Squid wiki or other
web resources should have that info. The question you should ask
yourself is &quot;How much shared memory is available for the Squid process&quot;?


&gt;<i> On my target system which has 512MB RAM, even 'workers 0' won't help, I
</I>&gt;<i> still get :
</I>&gt;<i> 
</I>&gt;<i> &#160; mlock(0x778de000, 2101212)&#160; &#160; &#160; &#160; &#160; &#160; &#160; = -1 ENOMEM (Out of memory)
</I>
For &quot;workers 0&quot; concerns, please see the -N discussion above. The two
should be equivalent.


&gt;<i> I have to disable lock-memory for now and it puzzles me why the very
</I>&gt;<i> first 2MB mlock can fail.
</I>
Most likely, your OS is configured (or defaults) to provide very little
shared memory to a process when the total RAM is only 512MB.


&gt;<i> I strace|grep shm_get and shmat and found nothing,
</I>
mlock() is a system call so strace should see it, but it may be called
something else.


&gt;<i> instead there are lots of mmap calls, so Squid is using mmap
</I>&gt;<i> for its shared memory mapping,
</I>
Squid creates segments using shm_open() and attaches to them using mmap().


&gt;<i> the only question is that, is this mlock
</I>&gt;<i> file-backed-up or is it anonymous mmaped(in this case on Linux it will
</I>&gt;<i> use /dev/shm by default)?
</I>
On Ubuntu, Squid shared memory segments should all be in /dev/shm by
default. Squid does not want them to be backed by real files. See
shm_open(3).

Please note that some libc calls manipulating regular files are
translated into mmap() calls by the standard library (or some such). Not
all mmap() calls you see in strace are Squid mmap() calls.


HTH,

Alex.


&gt;<i> On Mon, Jul 16, 2018 at 11:58 AM Alex Rousskov wrote:
</I>&gt;<i> 
</I>&gt;<i>     On 07/15/2018 08:47 PM, Gordon Hsiao wrote:
</I>&gt;<i>     &gt; Just upgraded squid to 4.1, however if I enabled
</I>&gt;<i>     shared_memory_locking I
</I>&gt;<i>     &gt; failed to start squid:
</I>&gt;<i>     &gt;
</I>&gt;<i>     &gt; &quot;FATAL: shared_memory_locking on but failed to
</I>&gt;<i>     &gt; mlock(/squid-tls_session_cache.shm, 2101212): (12) Out of memory&quot;
</I>&gt;<i> 
</I>&gt;<i>     &gt; How do I know how much memory it is trying to mlock? is 2101212(~2MB)
</I>&gt;<i>     &gt; the shm size of not,
</I>&gt;<i> 
</I>&gt;<i>     Yes, Squid tried to lock a 2101212-byte segment and failed.
</I>&gt;<i> 
</I>&gt;<i> 
</I>&gt;<i>     &gt; any way to debug/looking-into/config this size?
</I>&gt;<i> 
</I>&gt;<i>     I am not sure what you mean, but please keep in mind that the failed
</I>&gt;<i>     segment could be the last straw -- most of the shared memory could be
</I>&gt;<i>     allocated earlier. You can observe all allocations/locks with 54,7
</I>&gt;<i>     debugging. Look for &quot;mlock(&quot;.
</I>&gt;<i> 
</I>&gt;<i>     You can also run &quot;strace&quot; or a similar command line tool to track
</I>&gt;<i>     allocations, but analyzing strace output may be more difficult than
</I>&gt;<i>     looking through Squid logs.
</I>&gt;<i> 
</I>&gt;<i> 
</I>&gt;<i>     &gt; Again I disabled cache etc for a memory restricted environment, also
</I>&gt;<i>     &gt; used the minimal configuration with a few enable-flags, in the
</I>&gt;<i>     meantime
</I>&gt;<i>     &gt; I want to avoid memory overcommit from squid(thus mlock)
</I>&gt;<i> 
</I>&gt;<i>     I am glad the new code is working to prevent runtime crashes in your
</I>&gt;<i>     memory-restricted environment. If studying previous mlock() calls does
</I>&gt;<i>     not help, please suggest what else Squid could do not help you.
</I>&gt;<i> 
</I>&gt;<i> 
</I>&gt;<i>     Thank you,
</I>&gt;<i> 
</I>&gt;<i>     Alex.
</I>&gt;<i> 
</I>

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="018703.html">[squid-users] shared_memory_locking failed to mlock
</A></li>
	<LI>Next message (by thread): <A HREF="018711.html">[squid-users] shared_memory_locking failed to mlock
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#18704">[ date ]</a>
              <a href="thread.html#18704">[ thread ]</a>
              <a href="subject.html#18704">[ subject ]</a>
              <a href="author.html#18704">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
