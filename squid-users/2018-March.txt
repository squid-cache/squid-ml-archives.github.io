From Thomas.Elsaesser at hzd.hessen.de  Thu Mar  1 08:42:38 2018
From: Thomas.Elsaesser at hzd.hessen.de (Thomas.Elsaesser at hzd.hessen.de)
Date: Thu, 1 Mar 2018 08:42:38 +0000
Subject: [squid-users] Understanding Fallback Authentication
Message-ID: <ead6b6c5af364398bfe8e6379e12308c@SRVSHPDAG2N1.itshessen.hessen.de>

Dear all,

i have running squid Version 3.5.27 on SLES12SP3

I have configure kerberos, ntlm and basic auth with ldap

All authentification individually run fine. Only kerberos auth run fine, only ntlm run fin etc.

I enable all 3 authentications, example:

auth_param negotiate program /usr/local/squid/libexec/negotiate_kerberos_auth ...
...
auth_param ntlm program /usr/local/samba/bin/ntlm_auth ...
...
auth_param basic program /usr/local/squid/libexec/basic_ldap_auth ...
...

In which case switch from kerberos to ntlm??

Example : if i destroy kerberos keytab file for squid, i see an error in cache.log. but not ntlm auth working. How can i configure squid,  if kerb auth give an error, switch to ntlm? If i disable kerb lines in squid.conf and restart squid, ntlm works fine.


Thanks
Regards
Thomas
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180301/1acc162a/attachment.htm>

From squid3 at treenet.co.nz  Thu Mar  1 10:35:24 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 1 Mar 2018 23:35:24 +1300
Subject: [squid-users] Understanding Fallback Authentication
In-Reply-To: <ead6b6c5af364398bfe8e6379e12308c@SRVSHPDAG2N1.itshessen.hessen.de>
References: <ead6b6c5af364398bfe8e6379e12308c@SRVSHPDAG2N1.itshessen.hessen.de>
Message-ID: <f78a759c-fb64-5651-1068-ee12302bff0e@treenet.co.nz>

On 01/03/18 21:42, Thomas.Elsaesser wrote:
> 
> Example : if i destroy kerberos keytab file for squid, i see an error in
> cache.log. but not ntlm auth working. How can i configure squid, ?if
> kerb auth give an error, switch to ntlm? If i disable kerb lines in
> squid.conf and restart squid, ntlm works fine.

You cannot. In HTTP the client decides which auth to perform and sends
credentials only for that scheme. The most Squid can do is offer the
schemes it can understand. Clients are supposed to select the most
secure auth they are capable of.


>From your description it seems like your NTLM clients are probably
trying to use Negotiate/NTLM instead of Negotiate/Kerberos. If so you
should be able to use the negotiate_wrapper helper to allow Squid to
perform Negotiate/NTLM for those clients.

Amos


From skupko.sk at gmail.com  Fri Mar  2 12:28:59 2018
From: skupko.sk at gmail.com (Peter Viskup)
Date: Fri, 2 Mar 2018 13:28:59 +0100
Subject: [squid-users] Squid SNMP remote monitoring and IP fragmentation
Message-ID: <CAPa6PsE7MPXTs8saVNFrdvhr3fFXVwd-WjuKhKRQ0vChH8q+pA@mail.gmail.com>

We do monitor our Squid's via SNMP with Zabbix and use the template
available on Zabbix share portal [1].
Retrieval of values is not reliable. Seems to be related to IP fragmentation.

The complete answer should be 4325B long.

~# snmpwalk -m /usr/share/squid3/mib.txt -v2c -CE
.1.3.6.1.4.1.3495.1.5.2.2 -Cc -c d8d385baeb54 localhost:3401
.1.3.6.1.4.1.3495.1 2>/dev/null | wc -c
4325

But on the Squid we receive one 1514B packet (not complete answer).

What are your experiences in this area?

[1] https://share.zabbix.com/cat-app/squid-proxy-snmp

-- 
Peter


From squid3 at treenet.co.nz  Fri Mar  2 13:37:46 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 3 Mar 2018 02:37:46 +1300
Subject: [squid-users] Squid SNMP remote monitoring and IP fragmentation
In-Reply-To: <CAPa6PsE7MPXTs8saVNFrdvhr3fFXVwd-WjuKhKRQ0vChH8q+pA@mail.gmail.com>
References: <CAPa6PsE7MPXTs8saVNFrdvhr3fFXVwd-WjuKhKRQ0vChH8q+pA@mail.gmail.com>
Message-ID: <705173a4-1a87-446c-fc88-212d59077b55@treenet.co.nz>

On 03/03/18 01:28, Peter Viskup wrote:
> We do monitor our Squid's via SNMP with Zabbix and use the template
> available on Zabbix share portal [1].
> Retrieval of values is not reliable. Seems to be related to IP fragmentation.
> 
> The complete answer should be 4325B long.
> 
> ~# snmpwalk -m /usr/share/squid3/mib.txt -v2c -CE
> .1.3.6.1.4.1.3495.1.5.2.2 -Cc -c d8d385baeb54 localhost:3401
> .1.3.6.1.4.1.3495.1 2>/dev/null | wc -c
> 4325
> 
> But on the Squid we receive one 1514B packet (not complete answer).

You do know there is a difference between binary and textual
representations of these things right?

The packets contain the full OID binary data, and the snmpwalk output is
abbreviated down to textual names which may be half or even a third the
size. Then there is the protocol headers in packets which in the case of
single SNMP queries like these are much larger than the OID and data itself.


Amos


From eliezer at ngtech.co.il  Tue Mar  6 10:36:03 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 6 Mar 2018 12:36:03 +0200
Subject: [squid-users] Squid SNMP remote monitoring and IP fragmentation
In-Reply-To: <705173a4-1a87-446c-fc88-212d59077b55@treenet.co.nz>
References: <CAPa6PsE7MPXTs8saVNFrdvhr3fFXVwd-WjuKhKRQ0vChH8q+pA@mail.gmail.com>
 <705173a4-1a87-446c-fc88-212d59077b55@treenet.co.nz>
Message-ID: <40bf01d3b536$ecec0ab0$c6c42010$@ngtech.co.il>

Is this SNMP value present in the cache-manager pages?
If so it would be pretty simple to write a script that will extract the relevant data via http.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Friday, March 2, 2018 15:38
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid SNMP remote monitoring and IP fragmentation

On 03/03/18 01:28, Peter Viskup wrote:
> We do monitor our Squid's via SNMP with Zabbix and use the template
> available on Zabbix share portal [1].
> Retrieval of values is not reliable. Seems to be related to IP fragmentation.
> 
> The complete answer should be 4325B long.
> 
> ~# snmpwalk -m /usr/share/squid3/mib.txt -v2c -CE
> .1.3.6.1.4.1.3495.1.5.2.2 -Cc -c d8d385baeb54 localhost:3401
> .1.3.6.1.4.1.3495.1 2>/dev/null | wc -c
> 4325
> 
> But on the Squid we receive one 1514B packet (not complete answer).

You do know there is a difference between binary and textual
representations of these things right?

The packets contain the full OID binary data, and the snmpwalk output is
abbreviated down to textual names which may be half or even a third the
size. Then there is the protocol headers in packets which in the case of
single SNMP queries like these are much larger than the OID and data itself.


Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Tue Mar  6 11:10:10 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 7 Mar 2018 00:10:10 +1300
Subject: [squid-users] Squid SNMP remote monitoring and IP fragmentation
In-Reply-To: <40bf01d3b536$ecec0ab0$c6c42010$@ngtech.co.il>
References: <CAPa6PsE7MPXTs8saVNFrdvhr3fFXVwd-WjuKhKRQ0vChH8q+pA@mail.gmail.com>
 <705173a4-1a87-446c-fc88-212d59077b55@treenet.co.nz>
 <40bf01d3b536$ecec0ab0$c6c42010$@ngtech.co.il>
Message-ID: <d8909b9c-6ac6-1f75-6b3d-3cd634c46bf3@treenet.co.nz>

On 06/03/18 23:36, Eliezer Croitoru wrote:
> Is this SNMP value present in the cache-manager pages?
> If so it would be pretty simple to write a script that will extract the relevant data via http.
> 

OID *.1.5.2.2 is the mgr:client_list table data, excluding the TCP_*
code breakdown for responses given.

Amos


From skupko.sk at gmail.com  Tue Mar  6 12:47:30 2018
From: skupko.sk at gmail.com (Peter Viskup)
Date: Tue, 6 Mar 2018 13:47:30 +0100
Subject: [squid-users] Squid SNMP remote monitoring and IP fragmentation
In-Reply-To: <d8909b9c-6ac6-1f75-6b3d-3cd634c46bf3@treenet.co.nz>
References: <CAPa6PsE7MPXTs8saVNFrdvhr3fFXVwd-WjuKhKRQ0vChH8q+pA@mail.gmail.com>
 <705173a4-1a87-446c-fc88-212d59077b55@treenet.co.nz>
 <40bf01d3b536$ecec0ab0$c6c42010$@ngtech.co.il>
 <d8909b9c-6ac6-1f75-6b3d-3cd634c46bf3@treenet.co.nz>
Message-ID: <CAPa6PsELp8H+cR6OB4iQ8XvUZ3GZYdsnNTp6+yzr88NT1F+_DA@mail.gmail.com>

Communication is ok. Problem was with pcap filtering based on port
number. Only the first fragment of the packet have this information.
All others have port fields empty. More information in tcpdump man
page in IP Fragmentation section.

In new packet capture the request for 87 OIDs is replied with 87
corresponding values.

Issue with not consistent data values in Zabbix are related to Zabbix
server post-processing.

On Tue, Mar 6, 2018 at 12:10 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 06/03/18 23:36, Eliezer Croitoru wrote:
>> Is this SNMP value present in the cache-manager pages?
>> If so it would be pretty simple to write a script that will extract the relevant data via http.
>>
>
> OID *.1.5.2.2 is the mgr:client_list table data, excluding the TCP_*
> code breakdown for responses given.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From eliezer at ngtech.co.il  Tue Mar  6 17:18:35 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 6 Mar 2018 19:18:35 +0200
Subject: [squid-users] I have found this Squid-Cache designed blacklist,
	anyone seen it?
Message-ID: <421e01d3b56f$29058020$7b108060$@ngtech.co.il>

Hey,

 

While I was wondering around github I stumbled upon this repository:

https://github.com/maravento/blackweb

 

Which claims to centralize many blacklists and designed for the use with
Squid-Cache.

Anyone have seen or tried this list?

 

I have seen it and thinking about writing an enhancement to this blacklist
scripts.


Can anyone help with this?

 

Eliezer

 

----

Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180306/ca0f21dc/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180306/ca0f21dc/attachment.png>

From rafael.akchurin at diladele.com  Wed Mar  7 10:19:23 2018
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Wed, 7 Mar 2018 10:19:23 +0000
Subject: [squid-users] [icap] Web Safety 6.1 web filter plugin for Squid
	proxy is available
Message-ID: <AM4PR0401MB2194204986CDC256AFFC931D8FD80@AM4PR0401MB2194.eurprd04.prod.outlook.com>

Greetings all,

Next version of Web Safety ICAP web filter for Squid proxy (version 6.1.0.1995 built on January 15, 2018) is now available for download. This version contains the following fixes and improvements:


-         Added URL rewriter for Google Safe Browsing (Update API v4). It is now possible to check each URL for malware and malicious links. You would need to register on Google Cloud Platform and obtain your own API key. More information is at https://developers.google.com/safe-browsing/v4/get-started.

-         Redesigned exclusions in UI. There is only one list of exclusions now. It is possible to further specify what exclusions are needed for each list entry. Supported exclusions are "Skip HTTPS decryption (SSL Bump)", "Bypass proxy authentication", "Bypass web filter and antivirus scan", "Do not cache HTML pages" and "Bypass Google Safe Browsing".

Pre-configured virtual appliance is available from https://www.diladele.com/virtual_appliance.html (should be run in VMWare ESXi/vSphere or Microsoft Hyper-V). GitHub repo with automation scripts we used to build this virtual appliance from stock Ubuntu 16 LTS image is at https://github.com/diladele/websafety-virtual-appliance/tree/master/scripts.ubuntu16 .

Direct links to virtual appliance:


-         http://packages.diladele.com/websafety/6.1.0.1995/va/ubuntu16/websafety.zip

-         http://packages.diladele.com/websafety/6.1.0.1995/va/centos7/websafety.zip

-         http://packages.diladele.com/websafety/6.1.0.1995/va/ubuntu16/websafety-hyperv.zip

Free time-limited license key can be downloaded from http://packages.diladele.com/license/6/trial/2DF0D5CC9827ABD6510DC0A11C9A5A8FF3BE87AA/license.zip .

Your questions/issues/bugs are welcome at support at diladele.com. Next version will include dynamic real-time page categorization using machine learning algorithms. You can join our community to get early access to next development builds at https://www.diladele.com/community.html .

Thanks to all of you for making this possible!

Rafael Akchurin
Diladele B.V.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180307/f4e1ee11/attachment.htm>

From abellon at cklass.com.mx  Wed Mar  7 23:56:45 2018
From: abellon at cklass.com.mx (abellon at cklass.com.mx)
Date: Wed, 7 Mar 2018 18:56:45 -0500
Subject: [squid-users] VPN ON PROXY
Message-ID: <1b7f184eb7bc952fb167eceffcb28a34.squirrel@cklass.com.mx>

Hello squidUsers,

I have a bit of a problem. Im currently on a network where there is a vpn
already configured and running. The proxy is working perfectly but for 1
issue. Te issue is as follows:

  VPN works perfectly, proxy sends ping, ssh, vnc, samba, cups protocols
by the tunnel but when trying to access local http adresses, the proxy
reads them as public http and send those protocols via wan... Making it
an error.

I have located the error (local http/https is read as public http and is
send by wan) how can I configure it so that the local http goes by the vpn
(tun1).


Thanks in advance.

Alexis





From abellon at cklass.com.mx  Wed Mar  7 23:58:57 2018
From: abellon at cklass.com.mx (abellon at cklass.com.mx)
Date: Wed, 7 Mar 2018 18:58:57 -0500
Subject: [squid-users] [Fwd:  VPN ON PROXY]
Message-ID: <89190bd9710aa9d294ed61a26be05cb4.squirrel@cklass.com.mx>

---------------------------- Original Message ----------------------------
Subject: [squid-users] VPN ON PROXY
From:    abellon at cklass.com.mx
Date:    Wed, March 7, 2018 6:56 pm
To:      squid-users at lists.squid-cache.org
--------------------------------------------------------------------------

Hello squidUsers,

I have a bit of a problem. Im currently on a network where there is a vpn
already configured and running. The proxy is working perfectly but for 1
issue. Te issue is as follows:

  VPN works perfectly, proxy sends ping, ssh, vnc, samba, cups protocols
by the tunnel but when trying to access local http adresses, the proxy
reads them as public http and send those protocols via wan... Making it
an error.

I have located the error (local http/https is read as public http and is
send by wan) how can I configure it so that the local http goes by the vpn
(tun1).


Thanks in advance.

Alexis



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users




From Antony.Stone at squid.open.source.it  Thu Mar  8 00:07:37 2018
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 8 Mar 2018 01:07:37 +0100
Subject: [squid-users] VPN ON PROXY
In-Reply-To: <1b7f184eb7bc952fb167eceffcb28a34.squirrel@cklass.com.mx>
References: <1b7f184eb7bc952fb167eceffcb28a34.squirrel@cklass.com.mx>
Message-ID: <201803080107.37821.Antony.Stone@squid.open.source.it>

On Thursday 08 March 2018 at 00:56:45, abellon at cklass.com.mx wrote:

> Hello squidUsers,
> 
> I have a bit of a problem. Im currently on a network where there is a vpn
> already configured and running.

What is the VPN connecting?  I mean, what is defined as the "local" network and 
what is defined as the "remote" network, for which traffic will pass through the 
VPN?

> The proxy is working perfectly but for 1 issue. Te issue is as follows:
> 
>   VPN works perfectly, proxy sends ping, ssh, vnc, samba, cups protocols
> by the tunnel

This sounds like you are trying to send almost everything over the VPN.

Why?  What is the purpose of this VPN?

> but when trying to access local http adresses,

Please define "local", in terms of which IP addresses you think are local, and 
how this compares to the VPN configuration.

> the proxy reads them as public

So, are these addresses RFC1918 "private" addresses, or are they simply public 
IPs which happen to exist in your local network?

> http and send those protocols via wan... Making it an error.
> 
> I have located the error (local http/https is read as public http and is
> send by wan) how can I configure it so that the local http goes by the vpn
> (tun1).

Give us some examples of addresses which are being incorrectly routed, and 
tell us how your VPN is set up, and we can give you some advice as to whether 
this is a Squid problem or a VPN / network routing problem.


Regards,


Antony.

PS: No need to send the same question twice within 2 minutes :)

-- 
"Linux is going to be part of the future. It's going to be like Unix was."

 - Peter Moore, Asia-Pacific general manager, Microsoft

                                                   Please reply to the list;
                                                         please *don't* CC me.


From abellon at cklass.com.mx  Thu Mar  8 00:43:20 2018
From: abellon at cklass.com.mx (abellon at cklass.com.mx)
Date: Wed, 7 Mar 2018 19:43:20 -0500
Subject: [squid-users] VPN ON PROXY
In-Reply-To: <201803080107.37821.Antony.Stone@squid.open.source.it>
References: <1b7f184eb7bc952fb167eceffcb28a34.squirrel@cklass.com.mx>
 <201803080107.37821.Antony.Stone@squid.open.source.it>
Message-ID: <caf5cb6a719db134ff1f8e405653a54b.squirrel@cklass.com.mx>

> On Thursday 08 March 2018 at 00:56:45, abellon at cklass.com.mx wrote:
>
>> Hello squidUsers,
>>
>> I have a bit of a problem. Im currently on a network where there is a
>> vpn
>> already configured and running.
>
> What is the VPN connecting?  I mean, what is defined as the "local"
> network and
> what is defined as the "remote" network, for which traffic will pass
> through the
> VPN?
>
>> The proxy is working perfectly but for 1 issue. Te issue is as follows:
>>
>>   VPN works perfectly, proxy sends ping, ssh, vnc, samba, cups protocols
>> by the tunnel
>
> This sounds like you are trying to send almost everything over the VPN.
>
> Why?  What is the purpose of this VPN?
>
>> but when trying to access local http adresses,
>
> Please define "local", in terms of which IP addresses you think are local,
> and
> how this compares to the VPN configuration.
>
>> the proxy reads them as public
>
> So, are these addresses RFC1918 "private" addresses, or are they simply
> public
> IPs which happen to exist in your local network?
>
>> http and send those protocols via wan... Making it an error.
>>
>> I have located the error (local http/https is read as public http and is
>> send by wan) how can I configure it so that the local http goes by the
>> vpn
>> (tun1).
>
> Give us some examples of addresses which are being incorrectly routed, and
> tell us how your VPN is set up, and we can give you some advice as to
> whether
> this is a Squid problem or a VPN / network routing problem.
>
>
> Regards,
>
>
> Antony.
>
> PS: No need to send the same question twice within 2 minutes :)
>
> --
> "Linux is going to be part of the future. It's going to be like Unix was."
>
>  - Peter Moore, Asia-Pacific general manager, Microsoft
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>





So I have to networks in differnet physical locations(11.0.15.0/24,
11.0.20.0/24) connected by VPN (11.0.3.0/24). The VPN works perfectly fine
(yo can visualize the 2 networks files, connect by ssh, ping),my only
problem is, when i try to enter local addresses by http/s protocol, lets
say the router from the other network (11.0.15.2/24) from a browser(http
protocol) will have a time-out error.

PS: when ping 11.0.15.2 you DO get a response.




From alessio.troiano at leonardocompany.com  Thu Mar  8 08:34:22 2018
From: alessio.troiano at leonardocompany.com (Troiano Alessio)
Date: Thu, 8 Mar 2018 08:34:22 +0000
Subject: [squid-users] R:  VPN ON PROXY
In-Reply-To: <26872_1520469807_5AA0872F_26872_7198_1_caf5cb6a719db134ff1f8e405653a54b.squirrel@cklass.com.mx>
References: <1b7f184eb7bc952fb167eceffcb28a34.squirrel@cklass.com.mx>
 <201803080107.37821.Antony.Stone@squid.open.source.it>
 <26872_1520469807_5AA0872F_26872_7198_1_caf5cb6a719db134ff1f8e405653a54b.squirrel@cklass.com.mx>
Message-ID: <0aa6b4f0128e4f61beb38dca3ad466c6@ocgepvsw3101.ocr.priv>

The VPN is on the proxy server or on a firewall?
In the first case it may be a problem of the software that do VPN, try to check "route" with linux command.
In the second case check that the firewall that do the VPN is the default gateway of the proxy, either you have to add static route for the address 11.x.x.x that are public address, wrong utilized in VPN...


Il presente messaggio e-mail e ogni suo allegato devono intendersi indirizzati esclusivamente al destinatario indicato e considerarsi dal contenuto strettamente riservato e confidenziale. Se non siete l'effettivo destinatario o avete ricevuto il messaggio e-mail per errore, siete pregati di avvertire immediatamente il mittente e di cancellare il suddetto messaggio e ogni suo allegato dal vostro sistema informatico. Qualsiasi utilizzo, diffusione, copia o archiviazione del presente messaggio da parte di chi non ne ? il destinatario ? strettamente proibito e pu? dar luogo a responsabilit? di carattere civile e penale punibili ai sensi di legge.
Questa e-mail ha valore legale solo se firmata digitalmente ai sensi della normativa vigente.

The contents of this email message and any attachments are intended solely for the addressee(s) and contain confidential and/or privileged information.
If you are not the intended recipient of this message, or if this message has been addressed to you in error, please immediately notify the sender and then delete this message and any attachments from your system. If you are not the intended recipient, you are hereby notified that any use, dissemination, copying, or storage of this message or its attachments is strictly prohibited. Unauthorized disclosure and/or use of information contained in this email message may result in civil and criminal liability. ?
This e-mail has legal value according to the applicable laws only if it is digitally signed by the sender
-----Messaggio originale-----
Da: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Per conto di abellon at cklass.com.mx
Inviato: gioved? 8 marzo 2018 01:43
A: squid-users at lists.squid-cache.org
Oggetto: Re: [squid-users] VPN ON PROXY

> On Thursday 08 March 2018 at 00:56:45, abellon at cklass.com.mx wrote:
>
>> Hello squidUsers,
>>
>> I have a bit of a problem. Im currently on a network where there is a
>> vpn already configured and running.
>
> What is the VPN connecting?  I mean, what is defined as the "local"
> network and
> what is defined as the "remote" network, for which traffic will pass
> through the VPN?
>
>> The proxy is working perfectly but for 1 issue. Te issue is as follows:
>>
>>   VPN works perfectly, proxy sends ping, ssh, vnc, samba, cups
>> protocols by the tunnel
>
> This sounds like you are trying to send almost everything over the VPN.
>
> Why?  What is the purpose of this VPN?
>
>> but when trying to access local http adresses,
>
> Please define "local", in terms of which IP addresses you think are
> local, and how this compares to the VPN configuration.
>
>> the proxy reads them as public
>
> So, are these addresses RFC1918 "private" addresses, or are they
> simply public IPs which happen to exist in your local network?
>
>> http and send those protocols via wan... Making it an error.
>>
>> I have located the error (local http/https is read as public http and
>> is send by wan) how can I configure it so that the local http goes by
>> the vpn (tun1).
>
> Give us some examples of addresses which are being incorrectly routed,
> and tell us how your VPN is set up, and we can give you some advice as
> to whether this is a Squid problem or a VPN / network routing problem.
>
>
> Regards,
>
>
> Antony.
>
> PS: No need to send the same question twice within 2 minutes :)
>
> --
> "Linux is going to be part of the future. It's going to be like Unix was."
>
>  - Peter Moore, Asia-Pacific general manager, Microsoft
>
>                                                    Please reply to the
> list;
>                                                          please
> *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>





So I have to networks in differnet physical locations(11.0.15.0/24,
11.0.20.0/24) connected by VPN (11.0.3.0/24). The VPN works perfectly fine (yo can visualize the 2 networks files, connect by ssh, ping),my only problem is, when i try to enter local addresses by http/s protocol, lets say the router from the other network (11.0.15.2/24) from a browser(http
protocol) will have a time-out error.

PS: when ping 11.0.15.2 you DO get a response.


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From Laurence.Finston at gmx.de  Thu Mar  8 14:29:27 2018
From: Laurence.Finston at gmx.de (Laurence Finston)
Date: Thu, 8 Mar 2018 15:29:27 +0100
Subject: [squid-users] Users Guide --- Dead link
Message-ID: <trinity-6338dd68-9d9d-40b9-8579-a7646372fad7-1520519367815@3c-app-gmx-bs58>

Hello,

I'm just starting out learning about Squid.  The link to the Squid Users Guide 
by Oskar Pearson on http://www.squid-cache.org/Doc/ is dead:

404 Not Found

    Code: NoSuchBucket
    Message: The specified bucket does not exist
    BucketName: deckle-redirects
    RequestId: 317BF36686DE608E
    HostId: hE+eXv0FqL0/9aB66vz0NV1YjtNp4Cc/hYplqLRaF+CuiELrShKSoaE8xhe3URcl3+5baEosyM8=

Could somebody repair it or let me know where I could find the document?

Thank you.

Laurence Finston


From eliezer at ngtech.co.il  Fri Mar  9 02:23:33 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 9 Mar 2018 04:23:33 +0200
Subject: [squid-users] Users Guide --- Dead link
In-Reply-To: <trinity-6338dd68-9d9d-40b9-8579-a7646372fad7-1520519367815@3c-app-gmx-bs58>
References: <trinity-6338dd68-9d9d-40b9-8579-a7646372fad7-1520519367815@3c-app-gmx-bs58>
Message-ID: <029f01d3b74d$a0c24f50$e246edf0$@ngtech.co.il>

Did you meant that this link:
https://www.deckle.co.za/squid-users-guide/

is dead?
>From what I have seen the whole domain is kind of dead now.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Laurence Finston
Sent: Thursday, March 8, 2018 16:29
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Users Guide --- Dead link

Hello,

I'm just starting out learning about Squid.  The link to the Squid Users Guide 
by Oskar Pearson on http://www.squid-cache.org/Doc/ is dead:

404 Not Found

    Code: NoSuchBucket
    Message: The specified bucket does not exist
    BucketName: deckle-redirects
    RequestId: 317BF36686DE608E
    HostId: hE+eXv0FqL0/9aB66vz0NV1YjtNp4Cc/hYplqLRaF+CuiELrShKSoaE8xhe3URcl3+5baEosyM8=

Could somebody repair it or let me know where I could find the document?

Thank you.

Laurence Finston
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From jascha.sticher at tds.fujitsu.com  Fri Mar  9 07:17:41 2018
From: jascha.sticher at tds.fujitsu.com (Sticher, Jascha)
Date: Fri, 9 Mar 2018 07:17:41 +0000
Subject: [squid-users] Users Guide --- Dead link
In-Reply-To: <029f01d3b74d$a0c24f50$e246edf0$@ngtech.co.il>
References: <trinity-6338dd68-9d9d-40b9-8579-a7646372fad7-1520519367815@3c-app-gmx-bs58>
 <029f01d3b74d$a0c24f50$e246edf0$@ngtech.co.il>
Message-ID: <E286ADE35F919742812E3076A36122E701BFCA90EF@tdsnsumbx2vp>

Hi,

you could always try the internet wayback machine at archiv.org:

https://web.archive.org/web/20120531141437/http://www.deckle.co.za:80/squid-users-guide/


Kind regards,

Jascha

>
Erleben Sie Industrie 4.0 konkret ? auf der HANNOVER MESSE.
Vom 23. bis 27. April 2018.
www.fujitsu.com/de/microsite/hmi/register/index.html?utm_source=Email&utm_medium=Signature%20EMail&utm_campaign=HANNOVER%20MESSE%20DE&utm_term=&utm_content=Ticket-anfordern

-----Urspr?ngliche Nachricht-----
> Von: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Im
> Auftrag von Eliezer Croitoru
> Gesendet: Freitag, 9. M?rz 2018 03:24
> An: 'Laurence Finston'; squid-users at lists.squid-cache.org
> Betreff: Re: [squid-users] Users Guide --- Dead link
>
> Did you meant that this link:
> https://www.deckle.co.za/squid-users-guide/
>
> is dead?
> From what I have seen the whole domain is kind of dead now.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Laurence Finston
> Sent: Thursday, March 8, 2018 16:29
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Users Guide --- Dead link
>
> Hello,
>
> I'm just starting out learning about Squid.  The link to the Squid Users Guide
> by Oskar Pearson on http://www.squid-cache.org/Doc/ is dead:
>
> 404 Not Found
>
>     Code: NoSuchBucket
>     Message: The specified bucket does not exist
>     BucketName: deckle-redirects
>     RequestId: 317BF36686DE608E
>     HostId:
> hE+eXv0FqL0/9aB66vz0NV1YjtNp4Cc/hYplqLRaF+CuiELrShKSoaE8xhe3URcl3+
> 5baEosyM8=
>
> Could somebody repair it or let me know where I could find the document?
>
> Thank you.
>
> Laurence Finston
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

From squid3 at treenet.co.nz  Fri Mar  9 08:36:11 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 9 Mar 2018 21:36:11 +1300
Subject: [squid-users] Users Guide --- Dead link
In-Reply-To: <E286ADE35F919742812E3076A36122E701BFCA90EF@tdsnsumbx2vp>
References: <trinity-6338dd68-9d9d-40b9-8579-a7646372fad7-1520519367815@3c-app-gmx-bs58>
 <029f01d3b74d$a0c24f50$e246edf0$@ngtech.co.il>
 <E286ADE35F919742812E3076A36122E701BFCA90EF@tdsnsumbx2vp>
Message-ID: <1c16c9dd-897e-a9b9-3185-77d972b25b20@treenet.co.nz>

One of the reasons it was removed is that it was VERY out of date.
Taking a glance through the wayback record shows a lot of information
that is not even true for Squid-2.6+ let alone the current Squid-3.5+.


For beginners I suggest the Beginners Guide Book and/or FAQ which are
referenced from the LHS menu on the Squid official website.

"
Documentation
    Configuration:
        Reference
        Examples
    FAQ and Wiki
    Guide Books:
        Beginners
        Definitive
"

Once you are past the very beginner stage and know what you are looking
for the wiki and configuration references provide details on specific
features.

Amos


From wehategrey at gmail.com  Fri Mar  9 13:01:21 2018
From: wehategrey at gmail.com (Grey)
Date: Fri, 9 Mar 2018 06:01:21 -0700 (MST)
Subject: [squid-users] Proxy hierarchy and FTP access
In-Reply-To: <E286ADE35F919742812E3076A36122E701BFCA766A@tdsnsumbx2vp>
References: <1519806654069-0.post@n4.nabble.com>
 <1519815525147-0.post@n4.nabble.com>
 <E286ADE35F919742812E3076A36122E701BFCA766A@tdsnsumbx2vp>
Message-ID: <1520600481053-0.post@n4.nabble.com>

Thanks a lot guys, I ended up going back to using FileZilla with my LAN Squid
as HTTP proxy and allowing CONNECT requests to unregistered port only for a
list of known FTP/SFTP destinations; probably not ideal from a security
standpoint but it's the easiest way to manage my users requests.

Thanks again for your help and patience!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From uhlar at fantomas.sk  Sat Mar 10 08:50:34 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sat, 10 Mar 2018 09:50:34 +0100
Subject: [squid-users] VPN ON PROXY
In-Reply-To: <caf5cb6a719db134ff1f8e405653a54b.squirrel@cklass.com.mx>
References: <1b7f184eb7bc952fb167eceffcb28a34.squirrel@cklass.com.mx>
 <201803080107.37821.Antony.Stone@squid.open.source.it>
 <caf5cb6a719db134ff1f8e405653a54b.squirrel@cklass.com.mx>
Message-ID: <20180310085034.GF31165@fantomas.sk>

On 07.03.18 19:43, abellon at cklass.com.mx wrote:
>So I have to networks in differnet physical locations(11.0.15.0/24,
>11.0.20.0/24) connected by VPN (11.0.3.0/24). The VPN works perfectly fine
>(yo can visualize the 2 networks files, connect by ssh, ping),my only
>problem is, when i try to enter local addresses by http/s protocol, lets
>say the router from the other network (11.0.15.2/24) from a browser(http
>protocol) will have a time-out error.

what is your browsers' proxy configuation? You apparently need to put
11.0.15.0/24, 11.0.20.0/24 and 11.0.3.0/24 in proxy exclusion list.



>PS: when ping 11.0.15.2 you DO get a response.

BTW do you work for USA department of defense?
because 11.0.0.0/8 is their IP range:

NetRange:       11.0.0.0 - 11.255.255.255
CIDR:           11.0.0.0/8
NetName:        DODIIS
NetHandle:      NET-11-0-0-0-1
Parent:          ()
NetType:        Direct Allocation
OriginAS:
Organization:   DoD Network Information Center (DNIC)
RegDate:        1984-01-19
Updated:        2007-08-22
Ref:            https://whois.arin.net/rest/net/NET-11-0-0-0-1

if not, you should probably use other private ranges, like 10.0.0.0/8

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
They that can give up essential liberty to obtain a little temporary
safety deserve neither liberty nor safety. -- Benjamin Franklin, 1759


From chiasa.men at web.de  Sat Mar 10 13:32:40 2018
From: chiasa.men at web.de (chiasa.men)
Date: Sat, 10 Mar 2018 14:32:40 +0100
Subject: [squid-users] PHP: failed to open stream: Cannot connect to HTTPS
	server through proxy
Message-ID: <7839675.62xPg2EFzW@march>

I tried to install a joomla-Plugin from behind squid. It didn't work. I could 
reproduce the error using the following php-script:


> <?php
> $url="https://downloads.joomla.org/extensions/install-from-web/1-1-1/
plg_webinstaller_3.7v1.1.1.zip";
> $ctx = stream_context_create(['http' => ['proxy' => "tcp://$proxy:$port"],
> 'ssl' => ['capture_session_meta' => TRUE]]);
> $html = file_get_contents($url , FALSE, $ctx);
> $meta = stream_context_get_options($ctx)['ssl']['session_meta']; 
> var_dump($meta);
> ?>


Results in:

> PHP Warning:  file_get_contents(): Peer certificate CN=`*.s3-us-
west-2.amazonaws.com' did not match expected CN=`downloads.joomla.org' in /
tmp/test.php on line 5
> PHP Warning:  file_get_contents(https://downloads.joomla.org/extensions/
install-from-web/1-1-1/plg_webinstaller_3.7v1.1.1.zip): failed to open stream: 
Cannot connect to HTTPS server through proxy in /tmp/test.php on line 5

For $url="https://cdn.joomla.org/images/Joomla_logo.png" it works.

Squid produces the following log:

2018/03/10 13:19:48.252 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New 
connection on FD 17
2018/03/10 13:19:48.252 kid1| 5,2| TcpAcceptor.cc(317) acceptNext: connection 
on local=localhost:localport remote=[::] FD 17 flags=9
2018/03/10 13:19:48.252 kid1| 17,2| QosConfig.cc(126) getNfmarkFromConnection: 
QOS: Failed to retrieve connection mark: (-1) (1) Operation not permitted 
(Destination localhost:localport, source localhost:47200)
2018/03/10 13:19:48.252 kid1| 11,2| client_side.cc(1329) parseHttpRequest: 
HTTP Client local=localhost:localport remote=localhost:47200 FD 18 flags=1
2018/03/10 13:19:48.252 kid1| 11,2| client_side.cc(1333) parseHttpRequest: 
HTTP Client REQUEST:
---------
CONNECT downloads.joomla.org:443 HTTP/1.0


----------
2018/03/10 13:19:48.253 kid1| 85,2| client_side_request.cc(755) 
clientAccessCheckDone: The request CONNECT downloads.joomla.org:443 is 
ALLOWED; last ACL checked: all
2018/03/10 13:19:48.253 kid1| 85,2| client_side_request.cc(731) 
clientAccessCheck2: No adapted_http_access configuration. default: ALLOW
2018/03/10 13:19:48.253 kid1| 85,2| client_side_request.cc(755) 
clientAccessCheckDone: The request CONNECT downloads.joomla.org:443 is 
ALLOWED; last ACL checked: all
2018/03/10 13:19:48.253 kid1| 44,2| peer_select.cc(282) peerSelectDnsPaths: 
Find IP destination for: downloads.joomla.org:443' via downloads.joomla.org
2018/03/10 13:19:48.253 kid1| 44,2| peer_select.cc(303) peerSelectDnsPaths: 
Found sources for 'downloads.joomla.org:443'
2018/03/10 13:19:48.253 kid1| 44,2| peer_select.cc(304) peerSelectDnsPaths:   
always_direct = DENIED
2018/03/10 13:19:48.253 kid1| 44,2| peer_select.cc(305) peerSelectDnsPaths:    
never_direct = DENIED
2018/03/10 13:19:48.253 kid1| 44,2| peer_select.cc(309) peerSelectDnsPaths:          
DIRECT = local=0.0.0.0 remote=72.29.124.146:443 flags=1
2018/03/10 13:19:48.253 kid1| 44,2| peer_select.cc(318) peerSelectDnsPaths:        
timedout = 0
2018/03/10 13:19:48.925 kid1| 33,2| client_side.cc(585) swanSong: 
local=localhost:localport remote=localhost:47200 flags=1

==> /var/log/squid/access.log <==
localhost - - [10/Mar/2018:13:19:48 +0000] "CONNECT downloads.joomla.org:443 
HTTP/1.0" 200 5843 "-" "-" TCP_TUNNEL:HIER_DIRECT [] []

==> /var/log/squid/cache.log <==
2018/03/10 13:19:48.927 kid1| 5,2| TcpAcceptor.cc(226) doAccept: New 
connection on FD 17
2018/03/10 13:19:48.928 kid1| 5,2| TcpAcceptor.cc(317) acceptNext: connection 
on local=localhost:localport remote=[::] FD 17 flags=9
2018/03/10 13:19:48.928 kid1| 17,2| QosConfig.cc(126) getNfmarkFromConnection: 
QOS: Failed to retrieve connection mark: (-1) (1) Operation not permitted 
(Destination localhost:localport, source localhost:47206)
2018/03/10 13:19:48.972 kid1| 11,2| client_side.cc(1329) parseHttpRequest: 
HTTP Client local=localhost:localport remote=localhost:47206 FD 18 flags=1
2018/03/10 13:19:48.972 kid1| 11,2| client_side.cc(1333) parseHttpRequest: 
HTTP Client REQUEST:
---------
CONNECT s3-us-west-2.amazonaws.com:443 HTTP/1.0


----------
2018/03/10 13:19:48.973 kid1| 85,2| client_side_request.cc(755) 
clientAccessCheckDone: The request CONNECT s3-us-west-2.amazonaws.com:443 is 
ALLOWED; last ACL checked: all
2018/03/10 13:19:48.973 kid1| 85,2| client_side_request.cc(731) 
clientAccessCheck2: No adapted_http_access configuration. default: ALLOW
2018/03/10 13:19:48.973 kid1| 85,2| client_side_request.cc(755) 
clientAccessCheckDone: The request CONNECT s3-us-west-2.amazonaws.com:443 is 
ALLOWED; last ACL checked: all
2018/03/10 13:19:48.973 kid1| 44,2| peer_select.cc(282) peerSelectDnsPaths: 
Find IP destination for: s3-us-west-2.amazonaws.com:443' via s3-us-
west-2.amazonaws.com
2018/03/10 13:19:49.006 kid1| 44,2| peer_select.cc(303) peerSelectDnsPaths: 
Found sources for 's3-us-west-2.amazonaws.com:443'
2018/03/10 13:19:49.006 kid1| 44,2| peer_select.cc(304) peerSelectDnsPaths:   
always_direct = DENIED
2018/03/10 13:19:49.006 kid1| 44,2| peer_select.cc(305) peerSelectDnsPaths:    
never_direct = DENIED
2018/03/10 13:19:49.006 kid1| 44,2| peer_select.cc(309) peerSelectDnsPaths:          
DIRECT = local=0.0.0.0 remote=52.218.192.176:443 flags=1
2018/03/10 13:19:49.006 kid1| 44,2| peer_select.cc(318) peerSelectDnsPaths:        
timedout = 0
2018/03/10 13:19:49.618 kid1| 33,2| client_side.cc(585) swanSong: 
local=localhost:localport remote=localhost:47206 flags=1


==> /var/log/squid/cache.log <==
2018/03/10 13:19:49.619 kid1| ctx: enter level  0: 'https://example.com/tmp/
test.php'
2018/03/10 13:19:49.619 kid1| 11,2| http.cc(720) processReplyHeader: HTTP 
Server local=intProxIp:35486 remote=intWebIp:443 FD 12 flags=1
2018/03/10 13:19:49.620 kid1| 11,2| http.cc(724) processReplyHeader: HTTP 
Server RESPONSE:
---------
HTTP/1.1 200 OK
Date: Sat, 10 Mar 2018 13:19:48 GMT
Server: Apache
Strict-Transport-Security: max-age=15768000
X-Content-Type-Options: nosniff
X-Frame-Options: sameorigin
Content-Length: 196
Keep-Alive: timeout=360, max=100
Connection: Keep-Alive
Content-Type: text/html; charset=UTF-8

----------

==> /var/log/squid/access.log <==
localhost - - [10/Mar/2018:13:19:49 +0000] "CONNECT s3-us-
west-2.amazonaws.com:443 HTTP/1.0" 200 3237 "-" "-" TCP_TUNNEL:HIER_DIRECT [] 
[]

==> /var/log/squid/cache.log <==
2018/03/10 13:19:49.620 kid1| ctx: exit level  0
2018/03/10 13:19:49.620 kid1| 20,2| store.cc(991) checkCachable: 
StoreEntry::checkCachable: NO: not cachable
2018/03/10 13:19:49.620 kid1| 20,2| store.cc(991) checkCachable: 
StoreEntry::checkCachable: NO: not cachable
2018/03/10 13:19:49.620 kid1| 88,2| client_side_reply.cc(2083) 
processReplyAccessResult: The reply for GET https://example.com/tmp/test.php 
is ALLOWED, because it matched all
2018/03/10 13:19:49.620 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP 
Client local=intProxIp:3128 remote=requestingIp:50115 FD 10 flags=1
2018/03/10 13:19:49.620 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP 
Client REPLY:
---------
HTTP/1.1 200 OK
Date: Sat, 10 Mar 2018 13:19:48 GMT
Server: Apache
Strict-Transport-Security: max-age=15768000
X-Content-Type-Options: nosniff
X-Frame-Options: sameorigin
Content-Length: 196
Content-Type: text/html; charset=UTF-8
X-Cache: MISS from www.example.com
X-Cache-Lookup: MISS from www.example.com:3129
Via: 1.1 www.example.com (squid)
Connection: keep-alive


----------
2018/03/10 13:19:49.620 kid1| 20,2| store.cc(991) checkCachable: 
StoreEntry::checkCachable: NO: not cachable
2018/03/10 13:19:49.621 kid1| 20,2| store.cc(991) checkCachable: 
StoreEntry::checkCachable: NO: not cachable
2018/03/10 13:19:49.621 kid1| 20,2| store.cc(991) checkCachable: 
StoreEntry::checkCachable: NO: not cachable
2018/03/10 13:19:49.621 kid1| 20,2| store.cc(991) checkCachable: 
StoreEntry::checkCachable: NO: not cachable




With wget, it works perfectly. Is that a PHP problem or squid related? 




From squid3 at treenet.co.nz  Sun Mar 11 06:50:37 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 11 Mar 2018 19:50:37 +1300
Subject: [squid-users] PHP: failed to open stream: Cannot connect to
 HTTPS server through proxy
In-Reply-To: <7839675.62xPg2EFzW@march>
References: <7839675.62xPg2EFzW@march>
Message-ID: <f57f2d13-6c62-66bd-bbf5-ea447b05a9aa@treenet.co.nz>


On 11/03/18 02:32, chiasa.men wrote:
> I tried to install a joomla-Plugin from behind squid. It didn't work. I could 
> reproduce the error using the following php-script:
> 
> 
>> <?php
>> $url="https://downloads.joomla.org/extensions/install-from-web/1-1-1/
> plg_webinstaller_3.7v1.1.1.zip";
>> $ctx = stream_context_create(['http' => ['proxy' => "tcp://$proxy:$port"],
>> 'ssl' => ['capture_session_meta' => TRUE]]);
>> $html = file_get_contents($url , FALSE, $ctx);
>> $meta = stream_context_get_options($ctx)['ssl']['session_meta']; 
>> var_dump($meta);
>> ?>
> 
> 
> Results in:
> 
>> PHP Warning:  file_get_contents(): Peer certificate CN=`*.s3-us-
> west-2.amazonaws.com' did not match expected CN=`downloads.joomla.org' in /
> tmp/test.php on line 5

Please read that error message.
 downloads.joomla.org is not a part of *.s3-us-west-2.amazonaws.com

This "CN=" is a TLS certificate error and has nothing to do with the proxy.

Why the proxy is being asked to connect to s3-us-west-2.amazonaws.com is
not clear, but the proxy is only doing exactly what is asked of it. Any
issues like this which occur with the data inside the CONNECT tunnel are
purely a problem between client and server.

Amos


From info at microlinux.fr  Sun Mar 11 07:51:06 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Sun, 11 Mar 2018 08:51:06 +0100
Subject: [squid-users] Introduction & Squid ports
Message-ID: <c79e7207-a304-c9c2-031a-a0e44cc3707e@microlinux.fr>

Hi,

I'm new to this list, so let me introduce myself. I'm a 50-year old
Austrian living in Montpezat (South France), and I'm the manager of a
small IT company with a focus on Linux and free software.

I've been using Squid for a few years, but only as a transparent HTTP
proxy. Here's my blog article (in French) about that configuration on
CentOS 7:

https://blog.microlinux.fr/squid-centos/

These last two weeks I've been experimenting quite a lot with using
Squid as a transparent HTTP+HTTPS proxy. I've also written a blog
article about this setup:

https://blog.microlinux.fr/squid-https-centos/

This configuration is running quite nicely, though I still have to sand
down a few rough edges. I went through quite a lot of trial and error,
using the Squid wiki as well as a handful of tutorials I found on the
Internet.

Here's the section of my squid.conf file defining ports:

--8<-------------------------------------------------------------
# Ports du proxy
http_port 3130
http_port 3128 intercept
https_port 3129 intercept ssl-bump \
  cert=/etc/squid/ssl_cert/amandine.sandbox.lan.pem \
  generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
--8<-------------------------------------------------------------

And here's the corresponding section of my firewall script:

--8<-------------------------------------------------------------
# Commandes
IPT=/usr/sbin/iptables
SYS=/usr/sbin/sysctl
SERVICE=/usr/sbin/service

# Internet
IFACE_INET=enp2s0

# R?seau local
IFACE_LAN=virbr0
IFACE_LAN_IP=192.168.2.0/24

# Serveur
SERVER_IP=192.168.2.1

...

# Squid
$IPT -A INPUT -p tcp -i $IFACE_LAN --dport 3128 -j ACCEPT
$IPT -A INPUT -p udp -i $IFACE_LAN --dport 3128 -j ACCEPT
$IPT -A PREROUTING -t nat -i $IFACE_LAN -p tcp ! -d $SERVER_IP \
  --dport 80 -j REDIRECT --to-port 3128
$IPT -A INPUT -p tcp -i $IFACE_LAN --dport 3129 -j ACCEPT
$IPT -A INPUT -p udp -i $IFACE_LAN --dport 3129 -j ACCEPT
$IPT -A PREROUTING -t nat -i $IFACE_LAN -p tcp ! -d $SERVER_IP \
  --dport 443 -j REDIRECT --to-port 3129
$IPT -A INPUT -p tcp -i $IFACE_LAN --dport 3130 -j ACCEPT
$IPT -A INPUT -p udp -i $IFACE_LAN --dport 3130 -j ACCEPT
--8<-------------------------------------------------------------

This configuration works perfectly and gives me no errors or whatsoever,
though I don't quite understand why I need all these ports. When I used
only HTTP, I had this configuration

http_port 3128 transparent

So I wonder why it wasn't possible to have something like this:

http_port 3128 transparent
https_port 3129 transparent ssl-bump

I'm not sure about how the "intercept" mode works. As far as I
understand, connections to port 80 get redirected to port 3128 by the
firewall, but what then? Does "http_port 3128 intercept" mean that Squid
redirects these again and sends them to its internal port 3130?

Similarly, connections to port 443 get redirected to port 3129 by the
firewall, so far so good. But I don't understand how to read "https_port
3129 intercept". Again, does this mean that Squid redirects these to its
internal port 3130, along with HTTP connections?

In short, my configuration works, but I'd like to get a better grasp on
*how* it works.

Cheers from the sunny South of France,

Niki Kovacs

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From info at microlinux.fr  Sun Mar 11 08:07:16 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Sun, 11 Mar 2018 09:07:16 +0100
Subject: [squid-users] Allow some domains to bypass Squid
Message-ID: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>

Hi,

I have Squid setup as a transparent HTTP+HTTPS proxy in my local
network, using SSL-Bump.

The configuration works quite nicely, according to
/var/log/squid/cache.log and /var/log/squid/access.log.

This being said, I am having trouble with a handful of domains like
Github, or my OwnCloud installation. I have an OwnCloud server installed
at https://cloud.microlinux.fr, and everytime I fire up a client, I have
to confirm the use of an untrusted certificate. And on my workstation, I
can't connect to my Github repository anymore. Here's the error I get.

  # git pull
  fatal: unable to access 'https://github.com/kikinovak/centos-
  7-desktop-kde/': Peer's certificate issuer has been marked as not
  trusted by the user.

So I thought the best thing to do is to create an exception for this
handful of domains with issues.

Can I configure some domains to simply bypass the proxy in my current
(transparent) setup? Ideally, the configuration should be able to read a
simple text file containing said domains, something like
/etc/squid/bypass-these-domains.txt. And then these bypass the proxy and
get treated regularly, as if there was no proxy?

Cheers,

Niki
-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From squid3 at treenet.co.nz  Sun Mar 11 08:24:52 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 11 Mar 2018 21:24:52 +1300
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
Message-ID: <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>

On 11/03/18 21:07, Nicolas Kovacs wrote:
> Hi,
> 
> I have Squid setup as a transparent HTTP+HTTPS proxy in my local
> network, using SSL-Bump.
> 
> The configuration works quite nicely, according to
> /var/log/squid/cache.log and /var/log/squid/access.log.
> 
> This being said, I am having trouble with a handful of domains like
> Github, or my OwnCloud installation. I have an OwnCloud server installed
> at https://cloud.microlinux.fr, and everytime I fire up a client, I have
> to confirm the use of an untrusted certificate. And on my workstation, I
> can't connect to my Github repository anymore. Here's the error I get.
> 
>   # git pull
>   fatal: unable to access 'https://github.com/kikinovak/centos-
>   7-desktop-kde/': Peer's certificate issuer has been marked as not
>   trusted by the user.
> 
> So I thought the best thing to do is to create an exception for this
> handful of domains with issues.
> 
> Can I configure some domains to simply bypass the proxy in my current
> (transparent) setup? Ideally, the configuration should be able to read a
> simple text file containing said domains, something like
> /etc/squid/bypass-these-domains.txt. And then these bypass the proxy and
> get treated regularly, as if there was no proxy?
> 

What you need to start with is switch your thinking from "domains" to
considering things in terms of connections and individual servers. Since
"domain" is a URL concept, and URLs are all hidden inside the encrypted
part of the traffic there is no knowing what that really is until after
decryption.

However when dealing with servers and connections, the connections TLS
SNI can tell you which *server* a client is connecting to and you can
decide to do the splice action based on which servers you are having
trouble with (not domains).

Or better yet, decide even earlier in your NAT system not to send that
traffic to the proxy at all.

Amos


From info at microlinux.fr  Sun Mar 11 08:33:07 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Sun, 11 Mar 2018 09:33:07 +0100
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
 <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
Message-ID: <6e6da3c5-e80a-c7de-c27c-17094082b216@microlinux.fr>

Le 11/03/2018 ? 09:24, Amos Jeffries a ?crit?:
> What you need to start with is switch your thinking from "domains" to
> considering things in terms of connections and individual servers. Since
> "domain" is a URL concept, and URLs are all hidden inside the encrypted
> part of the traffic there is no knowing what that really is until after
> decryption.
> 
> However when dealing with servers and connections, the connections TLS
> SNI can tell you which *server* a client is connecting to and you can
> decide to do the splice action based on which servers you are having
> trouble with (not domains).
> 
> Or better yet, decide even earlier in your NAT system not to send that
> traffic to the proxy at all.

I'm sorry, but I don't understand what you're saying.

Here's what I want, It's very simple.

Create a text file that contains a list of domains. For example:

  google.com
  hotmail.com
  github.com
  credit-cooperatif.fr

And then all connections that go to anyone of these domains don't get
cached, but simply pass through Squid.

Thanks,

Niki

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From squid3 at treenet.co.nz  Sun Mar 11 09:17:26 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 11 Mar 2018 22:17:26 +1300
Subject: [squid-users] Introduction & Squid ports
In-Reply-To: <c79e7207-a304-c9c2-031a-a0e44cc3707e@microlinux.fr>
References: <c79e7207-a304-c9c2-031a-a0e44cc3707e@microlinux.fr>
Message-ID: <b09786da-d877-42bc-0b73-aa8544968b63@treenet.co.nz>

On 11/03/18 20:51, Nicolas Kovacs wrote:
> 
> This configuration works perfectly and gives me no errors or whatsoever,
> though I don't quite understand why I need all these ports. When I used
> only HTTP, I had this configuration
> 
> http_port 3128 transparent

Which receives port-80 syntax traffic.

> 
> So I wonder why it wasn't possible to have something like this:
> 
> http_port 3128 transparent

Which (still) receives port-80 syntax traffic.

> https_port 3129 transparent ssl-bump
> 

Which receives port-443 syntax traffic.

> I'm not sure about how the "intercept" mode works. As far as I
> understand, connections to port 80 get redirected to port 3128 by the
> firewall, but what then? Does "http_port 3128 intercept" mean that Squid
> redirects these again and sends them to its internal port 3130?

The "intercept" mode flag tells Squid it is receiving traffic from a NAT
system. So the IP addresses need special handling, and so does the HTTP
message syntax.

> 
> Similarly, connections to port 443 get redirected to port 3129 by the
> firewall, so far so good. But I don't understand how to read "https_port
> 3129 intercept". Again, does this mean that Squid redirects these to its
> internal port 3130, along with HTTP connections?

"https_port" -> receiving HTTP wrapped in TLS (aka HTTPS),
"3129"       -> listening on port 3129,
"intercept"  -> for traffic delivered from a NAT system.

NP: "transparent" is deprecated since it does _not_ mean *transparency*.


> 
> In short, my configuration works, but I'd like to get a better grasp on
> *how* it works.

The how is a bit complex and less important than the "what". The best
place to start IMO is RFC 7230 section 5.3, which describes the
differences in HTTP messages (ie the syntax) which are delivered to
origin servers (port 80) or to proxies (port 3128).
 <https://tools.ietf.org/html/rfc7230#section-5.3>


In your config you changed your 3128 to receiving port-80 (origin-form)
syntax with "intercept". So port 3130 was necessary to takeover
receiving of the normal proxy traffic.

The TLS wrappers on HTTPS need special handling to decrypt so that needs
another port setup to do that decryption first and HTTP message handling
after. "https_port" directive sets up a port for that.

NP: the "ssl-bump" flag does not mean simply receiving HTTPS traffic, it
means specifically decrypting HTTPS traffic destined *to another server*
- ie MITM at the TLS level. Which can be done for port-443 traffic OR
for CONNECT messages in the proxy (port-3128) syntax traffic. Thus it is
applicable on both https_port and http_port traffic respectively.


HTH
Amos


From info at microlinux.fr  Sun Mar 11 09:20:23 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Sun, 11 Mar 2018 10:20:23 +0100
Subject: [squid-users] Introduction & Squid ports
In-Reply-To: <b09786da-d877-42bc-0b73-aa8544968b63@treenet.co.nz>
References: <c79e7207-a304-c9c2-031a-a0e44cc3707e@microlinux.fr>
 <b09786da-d877-42bc-0b73-aa8544968b63@treenet.co.nz>
Message-ID: <05d183b1-1d28-d7d5-59a3-6be39b2c3cf1@microlinux.fr>

Le 11/03/2018 ? 10:17, Amos Jeffries a ?crit?:
> In your config you changed your 3128 to receiving port-80 (origin-form)
> syntax with "intercept". So port 3130 was necessary to takeover
> receiving of the normal proxy traffic.
> 
> The TLS wrappers on HTTPS need special handling to decrypt so that needs
> another port setup to do that decryption first and HTTP message handling
> after. "https_port" directive sets up a port for that.
> 
> NP: the "ssl-bump" flag does not mean simply receiving HTTPS traffic, it
> means specifically decrypting HTTPS traffic destined *to another server*
> - ie MITM at the TLS level. Which can be done for port-443 traffic OR
> for CONNECT messages in the proxy (port-3128) syntax traffic. Thus it is
> applicable on both https_port and http_port traffic respectively.

Thanks very much for your detailed answer !

Cheers !

Niki

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From info at microlinux.fr  Sun Mar 11 10:03:46 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Sun, 11 Mar 2018 11:03:46 +0100
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
 <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
Message-ID: <4081e7fb-2705-726f-1fc9-e68e21eea30c@microlinux.fr>

Le 11/03/2018 ? 09:24, Amos Jeffries a ?crit?:
> What you need to start with is switch your thinking from "domains" to
> considering things in terms of connections and individual servers. Since
> "domain" is a URL concept, and URLs are all hidden inside the encrypted
> part of the traffic there is no knowing what that really is until after
> decryption.
> 
> However when dealing with servers and connections, the connections TLS
> SNI can tell you which *server* a client is connecting to and you can
> decide to do the splice action based on which servers you are having
> trouble with (not domains).
> 
> Or better yet, decide even earlier in your NAT system not to send that
> traffic to the proxy at all.

I tried to formulate your suggestion in my own words and sent it to the
CentOS mailing list, where I'm a regular, since this seems more to be of
an iptables-related problem ("earlier in the NAT system").

Here's my message:

--8<---------------------------------------------------------

Hi,

I'm currently facing a quite tricky problem. Here goes.

I have setup Squid as a transparent HTTP+HTTPS proxy in my local
network. All web traffic gets handed over to Squid by an iptables script
on the server. Here's the relevant section in /etc/squid/squid.conf:

--8<-------------------------------------------------------------
# Ports du proxy
http_port 3130
http_port 3128 intercept
https_port 3129 intercept ssl-bump \
  cert=/etc/squid/ssl_cert/amandine.sandbox.lan.pem \
  generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
--8<-------------------------------------------------------------

And here's the corresponding section of my firewall script:

--8<-------------------------------------------------------------
# Commandes
IPT=/usr/sbin/iptables
SYS=/usr/sbin/sysctl
SERVICE=/usr/sbin/service

# Internet
IFACE_INET=enp2s0

# R?seau local
IFACE_LAN=virbr0
IFACE_LAN_IP=192.168.2.0/24

# Serveur
SERVER_IP=192.168.2.1

...

# Squid
$IPT -A INPUT -p tcp -i $IFACE_LAN --dport 3128 -j ACCEPT
$IPT -A INPUT -p udp -i $IFACE_LAN --dport 3128 -j ACCEPT
$IPT -A PREROUTING -t nat -i $IFACE_LAN -p tcp ! -d $SERVER_IP \
  --dport 80 -j REDIRECT --to-port 3128
$IPT -A INPUT -p tcp -i $IFACE_LAN --dport 3129 -j ACCEPT
$IPT -A INPUT -p udp -i $IFACE_LAN --dport 3129 -j ACCEPT
$IPT -A PREROUTING -t nat -i $IFACE_LAN -p tcp ! -d $SERVER_IP \
  --dport 443 -j REDIRECT --to-port 3129
$IPT -A INPUT -p tcp -i $IFACE_LAN --dport 3130 -j ACCEPT
$IPT -A INPUT -p udp -i $IFACE_LAN --dport 3130 -j ACCEPT
--8<-------------------------------------------------------------

This setup works nicely for the vast majority of web sites.

BUT: a handful of sites has some trouble with my local certificate. For
example, I can't sync my local Github repo anymore. Or my local OwnCloud
client spews back a warning message on every startup.

I asked on the Squid mailing list if there was a possibility to create
an exception for a list of domains, so that these can simply bypass the
proxy. The problem is, according to one of the developers, I have to
tackle that problem earlier in the process, e. g. in the firewall setup.

So here's what I want to do, in plain words:

1. Redirect all HTTP traffic (port 80) to port 3128. So far so good.

2. Redirect all HTTPS traffic (port 443) to port 3129. Equally OK.

AND...

3. DO NOT REDIRECT traffic that goes to certain domains, like:

  github.com
  credit-cooperatif.coop
  cloud.microlinux.fr
  squid-cache.org
  etc.

Ideally, these domains should be read from a simple text file.

Any idea how I could do that? I don't even know if this is theoretically
possible.

Cheers,

Niki

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From squid3 at treenet.co.nz  Sun Mar 11 10:17:54 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 11 Mar 2018 23:17:54 +1300
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <6e6da3c5-e80a-c7de-c27c-17094082b216@microlinux.fr>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
 <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
 <6e6da3c5-e80a-c7de-c27c-17094082b216@microlinux.fr>
Message-ID: <15d21273-7c0b-b792-06ef-1444d900866e@treenet.co.nz>

On 11/03/18 21:33, Nicolas Kovacs wrote:
> Le 11/03/2018 ? 09:24, Amos Jeffries a ?crit?:
>> What you need to start with is switch your thinking from "domains" to
>> considering things in terms of connections and individual servers. Since
>> "domain" is a URL concept, and URLs are all hidden inside the encrypted
>> part of the traffic there is no knowing what that really is until after
>> decryption.
>>
>> However when dealing with servers and connections, the connections TLS
>> SNI can tell you which *server* a client is connecting to and you can
>> decide to do the splice action based on which servers you are having
>> trouble with (not domains).
>>
>> Or better yet, decide even earlier in your NAT system not to send that
>> traffic to the proxy at all.
> 
> I'm sorry, but I don't understand what you're saying.
> 

Once the traffic arrives at the proxy it MUST be handled. It is too late
to send it elsewhere.

So to actually bypass the proxy you have to not send the TCP packets to
it at all. But the NAT system only works with raw-IPs.


There are many ways to "handle" traffic though. Rejection is one. When
TLS is involved relaying without doing anything (aka splice) is another.

But TLS is a point-to-point security protocol. Its handshakes are
dealing with origin server names. The domain name is a secondary detail
only sometimes available at all.

see
<https://superuser.com/questions/59093/difference-between-host-name-and-domain-name/59094>



> Here's what I want, It's very simple.
> 
> Create a text file that contains a list of domains. For example:
> 
>   google.com

Talking this as an example;

"google.com" is the public domain that users enter into their browsers
to view a certain website. The browser than does a lot of stuff, and
eventually contacts one of the origin servers for "google.com".

But "google.com" is not actually the name for any of those origin
servers. The server names for Google machines are all inside the
*.1e100.net TLD name, and all their machines answer to many different
"domain names" at the HTTP level (gmail.com, google.com, youtube.com,
googlevideo.com, 1e100.net, ... and many others including all the
country-specific ccTLDs variations on those names, and a lot of common
typos eg "gogle.com").


Your MITM proxy does not receive a URL straight off. It receives a TCP
SYN+ACK packet details. Which contains only the raw-IP for that Google
server. It can lookup the DNS to find out the servers name
 ... something.1e100.net.

If you configured it to handle the TLS handshake (with ssl-bump) it will
receive various representations of that server name in TLS messages.
Which should still be something.1e100.net, usually not "google.com" -
but that depends on whether the client software (Browser or non-Browser)
is properly obeying the requirement that it indicate *server name* in
TLS SNI.
 And also on whether the Google company servers specify the "google.com"
domain as an alias (SubjectAltName) for their TLS certificate from any
particular server (some do, some do not).


All of the above has to happen and be acceptable to the proxy access
controls you have configured before it gets a chance to decrypt the HTTP
message inside the TLS encryption ... and finally find out what URL for
that message is with its domain name.
 Only then can it re-process those access controls for the HTTP(S)
message itself using the actual domain name the client wants.

The above is why we have different "dstdomain" and "ssl::server_name"
ACL types to deal with the different name information available.



>   hotmail.com
>   github.com
>   credit-cooperatif.fr
> 
> And then all connections that go to anyone of these domains don't get
> cached, but simply pass through Squid.

The process is not getting anywhere close to caching being relevant. The
error you mentioned earlier is in the TLS handshake part of the process.


HTH
Amos


From info at microlinux.fr  Sun Mar 11 10:54:38 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Sun, 11 Mar 2018 11:54:38 +0100
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <15d21273-7c0b-b792-06ef-1444d900866e@treenet.co.nz>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
 <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
 <6e6da3c5-e80a-c7de-c27c-17094082b216@microlinux.fr>
 <15d21273-7c0b-b792-06ef-1444d900866e@treenet.co.nz>
Message-ID: <180bec3e-25fe-c0ac-261a-ca7bda041e98@microlinux.fr>

Le 11/03/2018 ? 11:17, Amos Jeffries a ?crit?:
> The process is not getting anywhere close to caching being relevant. The
> error you mentioned earlier is in the TLS handshake part of the process.

I've experimented some more, and I have a partial success. Here, I'm
redirecting all HTTPS traffic *except* the one that goes to my bank:

iptables -A PREROUTING -t nat -i $IFACE_LAN -p tcp ! -d
www.credit-cooperatif.coop --dport 443 -j REDIRECT --to-port 3129

This works because my bank is hosted on a single IP. As soon as I
replace that with a domain that's hosted on multiple IP's, I get this:

iptables -A PREROUTING -t nat -i $IFACE_LAN -p tcp ! -d www.google.com
--dport 443 -j REDIRECT --to-port 3129

# firewall.sh
iptables v1.4.21: ! not allowed with multiple source or destination IP
addresses

So my question is: how can I write an iptables rule (or series of rules)
that redirect all traffic to my proxy, *except* the one going to
<list_of_domains> ?

Cheers,

Niki

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From squid3 at treenet.co.nz  Sun Mar 11 11:31:04 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 12 Mar 2018 00:31:04 +1300
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <180bec3e-25fe-c0ac-261a-ca7bda041e98@microlinux.fr>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
 <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
 <6e6da3c5-e80a-c7de-c27c-17094082b216@microlinux.fr>
 <15d21273-7c0b-b792-06ef-1444d900866e@treenet.co.nz>
 <180bec3e-25fe-c0ac-261a-ca7bda041e98@microlinux.fr>
Message-ID: <6da0bc87-e0e6-450d-ba45-71eb1cd0bea2@treenet.co.nz>

On 11/03/18 23:54, Nicolas Kovacs wrote:
> Le 11/03/2018 ? 11:17, Amos Jeffries a ?crit?:
>> The process is not getting anywhere close to caching being relevant. The
>> error you mentioned earlier is in the TLS handshake part of the process.
> 
> I've experimented some more, and I have a partial success. Here, I'm
> redirecting all HTTPS traffic *except* the one that goes to my bank:
> 
> iptables -A PREROUTING -t nat -i $IFACE_LAN -p tcp ! -d
> www.credit-cooperatif.coop --dport 443 -j REDIRECT --to-port 3129
> 
> This works because my bank is hosted on a single IP. As soon as I
> replace that with a domain that's hosted on multiple IP's, I get this:
> 
> iptables -A PREROUTING -t nat -i $IFACE_LAN -p tcp ! -d www.google.com
> --dport 443 -j REDIRECT --to-port 3129
> 
> # firewall.sh
> iptables v1.4.21: ! not allowed with multiple source or destination IP
> addresses
> 
> So my question is: how can I write an iptables rule (or series of rules)
> that redirect all traffic to my proxy, *except* the one going to
> <list_of_domains> ?

The whois system can provide info on the IP ranges owned by the
companies like Google which own their own ranges.


The alternative for ssl-bump is the splice action. For that you only
need to know the server names each company uses.

Amos


From info at microlinux.fr  Sun Mar 11 12:05:43 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Sun, 11 Mar 2018 13:05:43 +0100
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <6da0bc87-e0e6-450d-ba45-71eb1cd0bea2@treenet.co.nz>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
 <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
 <6e6da3c5-e80a-c7de-c27c-17094082b216@microlinux.fr>
 <15d21273-7c0b-b792-06ef-1444d900866e@treenet.co.nz>
 <180bec3e-25fe-c0ac-261a-ca7bda041e98@microlinux.fr>
 <6da0bc87-e0e6-450d-ba45-71eb1cd0bea2@treenet.co.nz>
Message-ID: <938ce895-28bd-ad04-b982-2edb178fef29@microlinux.fr>

Le 11/03/2018 ? 12:31, Amos Jeffries a ?crit?:
> The whois system can provide info on the IP ranges owned by the
> companies like Google which own their own ranges.
> 
> 
> The alternative for ssl-bump is the splice action. For that you only
> need to know the server names each company uses.

OK, I got something that's starting to work.

# Exceptions
EXCEPTIONS=$(egrep -v '(^\#)|(^\s+$)' /usr/local/sbin/no-proxy.txt)
for EXCEPTION in $EXCEPTIONS; do
  $IPT -A PREROUTING -t nat -i $IFACE_LAN -d $EXCEPTION -j ACCEPT
done

# Squid
$IPT -A INPUT -p tcp -i $IFACE_LAN --dport 3128 -j ACCEPT
$IPT -A INPUT -p udp -i $IFACE_LAN --dport 3128 -j ACCEPT
$IPT -A PREROUTING -t nat -i $IFACE_LAN -p tcp ! -d $SERVER_IP \
  --dport 80 -j REDIRECT --to-port 3128
$IPT -A INPUT -p tcp -i $IFACE_LAN --dport 3129 -j ACCEPT
$IPT -A INPUT -p udp -i $IFACE_LAN --dport 3129 -j ACCEPT
$IPT -A PREROUTING -t nat -i $IFACE_LAN -p tcp ! -d $SERVER_IP \
  --dport 443 -j REDIRECT --to-port 3129
$IPT -A INPUT -p tcp -i $IFACE_LAN --dport 3130 -j ACCEPT
$IPT -A INPUT -p udp -i $IFACE_LAN --dport 3130 -j ACCEPT


And here's what the no-proxy.txt file looks like:

# Ne pas utiliser le proxy pour les domaines suivants
#
# Cr?dit Coop?ratif
www.credit-cooperatif.coop
# Github
github.com
# Microlinux
microlinux.fr
microlinux.eu
# Squid
squid-cache.org
# Thunderbird
start.thunderbird.net

So far, it works fine.

Any suggestions ?

Niki


-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From info at microlinux.fr  Sun Mar 11 15:38:45 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Sun, 11 Mar 2018 16:38:45 +0100
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <6da0bc87-e0e6-450d-ba45-71eb1cd0bea2@treenet.co.nz>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
 <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
 <6e6da3c5-e80a-c7de-c27c-17094082b216@microlinux.fr>
 <15d21273-7c0b-b792-06ef-1444d900866e@treenet.co.nz>
 <180bec3e-25fe-c0ac-261a-ca7bda041e98@microlinux.fr>
 <6da0bc87-e0e6-450d-ba45-71eb1cd0bea2@treenet.co.nz>
Message-ID: <08632762-8bd6-d9a3-5b08-3a76cd456835@microlinux.fr>

Le 11/03/2018 ? 12:31, Amos Jeffries a ?crit?:
> The whois system can provide info on the IP ranges owned by the
> companies like Google which own their own ranges.
> 
> 
> The alternative for ssl-bump is the splice action. For that you only
> need to know the server names each company uses.

I'd say the problem is solved.

I wrote a little blog article to wrap it up.

https://blog.microlinux.fr/squid-exceptions/

Cheers !

Niki

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From alex at nanogherkin.com  Sun Mar 11 15:48:35 2018
From: alex at nanogherkin.com (Alex Crow)
Date: Sun, 11 Mar 2018 15:48:35 +0000
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <938ce895-28bd-ad04-b982-2edb178fef29@microlinux.fr>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
 <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
 <6e6da3c5-e80a-c7de-c27c-17094082b216@microlinux.fr>
 <15d21273-7c0b-b792-06ef-1444d900866e@treenet.co.nz>
 <180bec3e-25fe-c0ac-261a-ca7bda041e98@microlinux.fr>
 <6da0bc87-e0e6-450d-ba45-71eb1cd0bea2@treenet.co.nz>
 <938ce895-28bd-ad04-b982-2edb178fef29@microlinux.fr>
Message-ID: <4b1411cfe126e0d679c4b74e10c57429@mx.nanogherkin.com>

.
>> 
>> 
>> The alternative for ssl-bump is the splice action. For that you only
>> need to know the server names each company uses.
> 

OP,

It would be a lot easier to just create exceptions on the squid device 
for sites where bumping doesn't work which cause then to be tunnelled or 
spliced rather then bumped. You can then at least use dstdomain or 
ssl:servername rules. dstdomain will let you tunnel or splice, whereas 
ssl servername you will only be able to splice as an SSL connection must 
already have been started AFAIK. Your firewall will probably need 
restarting every time one of the IP addresses behind those hostnames 
changes. Squid will at least do a lookup every request for dstdomain 
(you need a good DNS server nearby or on the squid box).

BTW, peek/splice/bump is not just install and forget. It needs 
maintenance and care in deployment.

Adding transparent into the mix makes it more difficult, as I can see 
you have found.

Try to keep the architecture as simple as you can and use each part to 
its best ability. Simple firewalls using hostnames for rules is a path 
to severe pain where round-robin is in place. Might be OK with a big, 
expensive FW appliance that has the ability to DNS lookup for every 
connection.

Cheers

Alex




From info at microlinux.fr  Sun Mar 11 18:39:35 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Sun, 11 Mar 2018 19:39:35 +0100
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <4b1411cfe126e0d679c4b74e10c57429@mx.nanogherkin.com>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
 <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
 <6e6da3c5-e80a-c7de-c27c-17094082b216@microlinux.fr>
 <15d21273-7c0b-b792-06ef-1444d900866e@treenet.co.nz>
 <180bec3e-25fe-c0ac-261a-ca7bda041e98@microlinux.fr>
 <6da0bc87-e0e6-450d-ba45-71eb1cd0bea2@treenet.co.nz>
 <938ce895-28bd-ad04-b982-2edb178fef29@microlinux.fr>
 <4b1411cfe126e0d679c4b74e10c57429@mx.nanogherkin.com>
Message-ID: <71a9a114-cef3-569b-ced4-896ed62ad374@microlinux.fr>

Le 11/03/2018 ? 16:48, Alex Crow a ?crit?:
> 
> It would be a lot easier to just create exceptions on the squid device
> for sites where bumping doesn't work which cause then to be tunnelled or
> spliced rather then bumped. You can then at least use dstdomain or
> ssl:servername rules. dstdomain will let you tunnel or splice, whereas
> ssl servername you will only be able to splice as an SSL connection must
> already have been started AFAIK. Your firewall will probably need
> restarting every time one of the IP addresses behind those hostnames
> changes. Squid will at least do a lookup every request for dstdomain
> (you need a good DNS server nearby or on the squid box).

What would this configuration look like? Do you have a working example?

Niki

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From yvoinov at gmail.com  Sun Mar 11 18:44:34 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 12 Mar 2018 00:44:34 +0600
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <71a9a114-cef3-569b-ced4-896ed62ad374@microlinux.fr>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
 <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
 <6e6da3c5-e80a-c7de-c27c-17094082b216@microlinux.fr>
 <15d21273-7c0b-b792-06ef-1444d900866e@treenet.co.nz>
 <180bec3e-25fe-c0ac-261a-ca7bda041e98@microlinux.fr>
 <6da0bc87-e0e6-450d-ba45-71eb1cd0bea2@treenet.co.nz>
 <938ce895-28bd-ad04-b982-2edb178fef29@microlinux.fr>
 <4b1411cfe126e0d679c4b74e10c57429@mx.nanogherkin.com>
 <71a9a114-cef3-569b-ced4-896ed62ad374@microlinux.fr>
Message-ID: <b3d8bb19-0eca-1905-a8fc-561dc569a1c3@gmail.com>

Alex would like to say, splice, when implemented, more easy to
maintenance than iptables/firewall rules.

It's trivial to implement. Here is my config snippet:

# SSL bump rules
acl DiscoverSNIHost at_step SslBump1
acl NoSSLIntercept ssl::server_name_regex
"/usr/local/squid/etc/acl.url.nobump"
ssl_bump peek DiscoverSNIHost
ssl_bump splice NoSSLIntercept
ssl_bump bump all

acl.ur.nobump fragment:

# Adobe updates (web installation)
# This requires to splice due to SSL-pinned web-downloader
(get|platformdl|fpdownload|ardownload[0-9])\.adobe\.com
....

As Alex said, splice list require to maintenance all time.

Common rule is:

- Each SSL Pinning site must be spliced.

- Each OCSP stapling site must be spliced.

- Each site could not be bumped should spliced.

Feel free to make RTFM first:

https://wiki.squid-cache.org/Features/SslPeekAndSplice


12.03.2018 00:39, Nicolas Kovacs ?????:
> Le 11/03/2018 ? 16:48, Alex Crow a ?crit?:
>> It would be a lot easier to just create exceptions on the squid device
>> for sites where bumping doesn't work which cause then to be tunnelled or
>> spliced rather then bumped. You can then at least use dstdomain or
>> ssl:servername rules. dstdomain will let you tunnel or splice, whereas
>> ssl servername you will only be able to splice as an SSL connection must
>> already have been started AFAIK. Your firewall will probably need
>> restarting every time one of the IP addresses behind those hostnames
>> changes. Squid will at least do a lookup every request for dstdomain
>> (you need a good DNS server nearby or on the squid box).
> What would this configuration look like? Do you have a working example?
>
> Niki
>

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/4ba3442b/attachment.sig>

From yvoinov at gmail.com  Sun Mar 11 18:45:42 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 12 Mar 2018 00:45:42 +0600
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <71a9a114-cef3-569b-ced4-896ed62ad374@microlinux.fr>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
 <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
 <6e6da3c5-e80a-c7de-c27c-17094082b216@microlinux.fr>
 <15d21273-7c0b-b792-06ef-1444d900866e@treenet.co.nz>
 <180bec3e-25fe-c0ac-261a-ca7bda041e98@microlinux.fr>
 <6da0bc87-e0e6-450d-ba45-71eb1cd0bea2@treenet.co.nz>
 <938ce895-28bd-ad04-b982-2edb178fef29@microlinux.fr>
 <4b1411cfe126e0d679c4b74e10c57429@mx.nanogherkin.com>
 <71a9a114-cef3-569b-ced4-896ed62ad374@microlinux.fr>
Message-ID: <578a2df9-d2a4-6484-0ccf-b6870209b099@gmail.com>


Also,
feel free to read our config examples here:

https://wiki.squid-cache.org/ConfigExamples


12.03.2018 00:39, Nicolas Kovacs ?????:
> Le 11/03/2018 ? 16:48, Alex Crow a ?crit?:
>> It would be a lot easier to just create exceptions on the squid device
>> for sites where bumping doesn't work which cause then to be tunnelled or
>> spliced rather then bumped. You can then at least use dstdomain or
>> ssl:servername rules. dstdomain will let you tunnel or splice, whereas
>> ssl servername you will only be able to splice as an SSL connection must
>> already have been started AFAIK. Your firewall will probably need
>> restarting every time one of the IP addresses behind those hostnames
>> changes. Squid will at least do a lookup every request for dstdomain
>> (you need a good DNS server nearby or on the squid box).
> What would this configuration look like? Do you have a working example?
>
> Niki
>

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/6fa7963f/attachment.sig>

From info at microlinux.fr  Sun Mar 11 20:17:18 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Sun, 11 Mar 2018 21:17:18 +0100
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <b3d8bb19-0eca-1905-a8fc-561dc569a1c3@gmail.com>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
 <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
 <6e6da3c5-e80a-c7de-c27c-17094082b216@microlinux.fr>
 <15d21273-7c0b-b792-06ef-1444d900866e@treenet.co.nz>
 <180bec3e-25fe-c0ac-261a-ca7bda041e98@microlinux.fr>
 <6da0bc87-e0e6-450d-ba45-71eb1cd0bea2@treenet.co.nz>
 <938ce895-28bd-ad04-b982-2edb178fef29@microlinux.fr>
 <4b1411cfe126e0d679c4b74e10c57429@mx.nanogherkin.com>
 <71a9a114-cef3-569b-ced4-896ed62ad374@microlinux.fr>
 <b3d8bb19-0eca-1905-a8fc-561dc569a1c3@gmail.com>
Message-ID: <09781170-9450-b137-4390-fae298ff4baa@microlinux.fr>

Le 11/03/2018 ? 19:44, Yuri a ?crit?:
> It's trivial to implement. Here is my config snippet:
> 
> # SSL bump rules
> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLIntercept ssl::server_name_regex
> "/usr/local/squid/etc/acl.url.nobump"
> ssl_bump peek DiscoverSNIHost
> ssl_bump splice NoSSLIntercept
> ssl_bump bump all
> 
> acl.ur.nobump fragment:
> 
> # Adobe updates (web installation)
> # This requires to splice due to SSL-pinned web-downloader
> (get|platformdl|fpdownload|ardownload[0-9])\.adobe\.com

I gave this configuration a spin on my local proxy, and it works great,
without special firewall rules.

Thanks very much! You made my day!

Niki

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From yvoinov at gmail.com  Sun Mar 11 20:24:25 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 12 Mar 2018 02:24:25 +0600
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <09781170-9450-b137-4390-fae298ff4baa@microlinux.fr>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
 <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
 <6e6da3c5-e80a-c7de-c27c-17094082b216@microlinux.fr>
 <15d21273-7c0b-b792-06ef-1444d900866e@treenet.co.nz>
 <180bec3e-25fe-c0ac-261a-ca7bda041e98@microlinux.fr>
 <6da0bc87-e0e6-450d-ba45-71eb1cd0bea2@treenet.co.nz>
 <938ce895-28bd-ad04-b982-2edb178fef29@microlinux.fr>
 <4b1411cfe126e0d679c4b74e10c57429@mx.nanogherkin.com>
 <71a9a114-cef3-569b-ced4-896ed62ad374@microlinux.fr>
 <b3d8bb19-0eca-1905-a8fc-561dc569a1c3@gmail.com>
 <09781170-9450-b137-4390-fae298ff4baa@microlinux.fr>
Message-ID: <1695fbd4-9f77-02aa-d89d-7525d6def887@gmail.com>

You're welcome ;)

This config works several years on my servers :)


12.03.2018 02:17, Nicolas Kovacs ?????:
> Le 11/03/2018 ? 19:44, Yuri a ?crit?:
>> It's trivial to implement. Here is my config snippet:
>>
>> # SSL bump rules
>> acl DiscoverSNIHost at_step SslBump1
>> acl NoSSLIntercept ssl::server_name_regex
>> "/usr/local/squid/etc/acl.url.nobump"
>> ssl_bump peek DiscoverSNIHost
>> ssl_bump splice NoSSLIntercept
>> ssl_bump bump all
>>
>> acl.ur.nobump fragment:
>>
>> # Adobe updates (web installation)
>> # This requires to splice due to SSL-pinned web-downloader
>> (get|platformdl|fpdownload|ardownload[0-9])\.adobe\.com
> I gave this configuration a spin on my local proxy, and it works great,
> without special firewall rules.
>
> Thanks very much! You made my day!
>
> Niki
>

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/c5027de5/attachment.sig>

From eliezer at ngtech.co.il  Mon Mar 12 05:58:37 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 12 Mar 2018 07:58:37 +0200
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
Message-ID: <01b901d3b9c7$29bc19a0$7d344ce0$@ngtech.co.il>

Hey Nicolas,

If you are running a squid which doesn't have a mandatory rule of "Block first and then allow" or what in the security industry will be named "up-tight" then Yuri solution is the right path.
But... as a rule of thumb, if you don't need to pass the traffic into the proxy software don?t and allow or block whatever you can on the OS firewall level.
I wrote couple example bypass scripts:
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef
https://gist.github.com/elico/a54c2c8f8e1a2407b42210896b960f4b

For a non router\proxy linux system:
https://gist.github.com/elico/f21dae7a34e1736f56a1995977852460

The above examples are good for pre-known domains similar to the script you wrote in your blog but it gives some form of dynamics to the firewall rules.
I believe that the best formula is to combine both squid splice with ipset and domains resolution and the bypass rules.
Using  squid you will be able to splice domains automatically and with a daily log analysis of squid access.log files you might be able to find new domains that you can add into your firewall level bypassed domains.

Let me know if it sounds good and it worth a wiki article.
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Nicolas Kovacs
Sent: Sunday, March 11, 2018 10:07
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Allow some domains to bypass Squid

Hi,

I have Squid setup as a transparent HTTP+HTTPS proxy in my local
network, using SSL-Bump.

The configuration works quite nicely, according to
/var/log/squid/cache.log and /var/log/squid/access.log.

This being said, I am having trouble with a handful of domains like
Github, or my OwnCloud installation. I have an OwnCloud server installed
at https://cloud.microlinux.fr, and everytime I fire up a client, I have
to confirm the use of an untrusted certificate. And on my workstation, I
can't connect to my Github repository anymore. Here's the error I get.

  # git pull
  fatal: unable to access 'https://github.com/kikinovak/centos-
  7-desktop-kde/': Peer's certificate issuer has been marked as not
  trusted by the user.

So I thought the best thing to do is to create an exception for this
handful of domains with issues.

Can I configure some domains to simply bypass the proxy in my current
(transparent) setup? Ideally, the configuration should be able to read a
simple text file containing said domains, something like
/etc/squid/bypass-these-domains.txt. And then these bypass the proxy and
get treated regularly, as if there was no proxy?

Cheers,

Niki
-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From codemarauder at gmail.com  Mon Mar 12 06:01:56 2018
From: codemarauder at gmail.com (Nishant Sharma)
Date: Mon, 12 Mar 2018 11:31:56 +0530
Subject: [squid-users] Allow some domains to bypass Squid
In-Reply-To: <938ce895-28bd-ad04-b982-2edb178fef29@microlinux.fr>
References: <0c323652-14f0-989a-0143-ec6b75707554@microlinux.fr>
 <7f570a03-4a12-de72-ef8d-83e911d7c486@treenet.co.nz>
 <6e6da3c5-e80a-c7de-c27c-17094082b216@microlinux.fr>
 <15d21273-7c0b-b792-06ef-1444d900866e@treenet.co.nz>
 <180bec3e-25fe-c0ac-261a-ca7bda041e98@microlinux.fr>
 <6da0bc87-e0e6-450d-ba45-71eb1cd0bea2@treenet.co.nz>
 <938ce895-28bd-ad04-b982-2edb178fef29@microlinux.fr>
Message-ID: <91ca7fc3-9dd8-ec6b-7adb-c2b86012d1de@gmail.com>

Hi Nicolas,

On Sunday 11 March 2018 05:35 PM, Nicolas Kovacs wrote:
> Le 11/03/2018 ? 12:31, Amos Jeffries a ?crit?:
> OK, I got something that's starting to work.
> 
> # Exceptions
> EXCEPTIONS=$(egrep -v '(^\#)|(^\s+$)' /usr/local/sbin/no-proxy.txt)
> for EXCEPTION in $EXCEPTIONS; do
>    $IPT -A PREROUTING -t nat -i $IFACE_LAN -d $EXCEPTION -j ACCEPT
> done

The problem with this approach might be that domains are looked up for 
their IPs at the time of rule creation and not at the time of request. 
Since destinations like github.com, google.com, facebook etc use many 
large pools of IPs, your rule might not match later in the day or after 
a few days.

Better to use "ipset" along with dnsmasq and refer that ipset in the 
iptables rule to match dst.

1. ipset create _ipsetname_ bitmap:ip

2. Configure dnsmasq to populate _ipsetname_ by adding following lines 
for each domain to dnsmasq.conf:

ipset=/google.com/_ipsetname_
ipset=/github.com/_ipsetname_
...
...

3. Use dnsmasq as resolver-cache on your proxy machine and ensure that 
squid uses your dnsmasq for DNS queries.

4. Add intercept iptables rules to not NAT the traffic  to destination 
ipset:

iptables -A PREROUTING -t nat -i $IFACE_LAN -m set --match-set 
_ipsetname_ dst -j ACCEPT

Dnsmasq will keep populating the ipset as and when a resolution request 
is received for the matched domains. An ipset can hold 65534 entries.

I use this approach extensively to allow Anti-Virus and Windows updates 
to the machines which otherwise are not allowed to access Internet 
directly without configuring explicit proxy or through proxy.pac/wpad.

Regards,
Nishant


From info at microlinux.fr  Mon Mar 12 09:40:48 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Mon, 12 Mar 2018 10:40:48 +0100
Subject: [squid-users] Distribute root certificate to clients
Message-ID: <b7b0343a-7b92-ac0c-d5e7-2fe6a3d6355d@microlinux.fr>

Hi,

I have a few prospective clients who want/need to log and monitor all
their web traffic and asked me to find a viable solution for this.

After a couple of weeks of fiddling, I decided to opt for the
Squid+SquidAnalyzer setup, which works quite well. I have a sandbox
installation here in my office that already works quite satisfyingly.

While working out the solution (thanks again to you guys, you know who
you are), I took some extensive notes on my technical blog:

  * https://blog.microlinux.fr/squid-centos/

  * https://blog.microlinux.fr/squid-https-centos/

  * https://blog.microlinux.fr/squidanalyzer-centos/

  * https://blog.microlinux.fr/squid-exceptions/

I have yet one problem to tackle, and I already have a solution in mind.
Though I thought I'd rather ask here first, since this is a bit new to
me, and you guys have much more experience.

Most of my clients are small businesses with up to a few dozen client
PCs, and also wireless access.

The problem I'm currently facing is: how to provide an easy installation
of Squid's root certificate? During my tests, I wrote some short
instructions for my Linux clients with Firefox, Chrome and Konqueror:

https://blog.microlinux.fr/squid-https-centos/#navigateurs

Here's what I intend to do. Configure a local web page
http://proxy.company.lan where clients can download the certificate file
proxy.company.lan.der. This page also contains quick & dirty
instructions on how to install the certificate on the most popular
browsers/platforms (Chrome, Firefox, Safari, Internet Explorer).

Each company will also have a printed document, explaining how to access
the Internet. Something like this:

  1. Open http://proxy.company.lan in your browser.

  2. Download the proxy.company.lan.der certificate file.

  3. Follow instructions to import this file into your browser.

  4. Browse the web normally.

Before doing that, I thought I'd inquire how you guys go about that. As
a long-time Slackware user I've always been a fan of the KISS principle
(Keep It Simple Stupid), so I try to have a no-nonsense approach.

Any suggestions?

Cheers from the sunny South of France,

Niki

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From yvoinov at gmail.com  Mon Mar 12 13:49:37 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 12 Mar 2018 19:49:37 +0600
Subject: [squid-users] Distribute root certificate to clients
In-Reply-To: <b7b0343a-7b92-ac0c-d5e7-2fe6a3d6355d@microlinux.fr>
References: <b7b0343a-7b92-ac0c-d5e7-2fe6a3d6355d@microlinux.fr>
Message-ID: <28566165-52ab-3a98-746a-184e965796d5@gmail.com>

I guess, there is no easy solution for this job.

The more difficult tasks is also mobile clients.

In my case, I use just a bit simple JS-trick solution found on
serverfault once upon a time.

It is point-and-click based, but not works for each and every browser.
Just for Chrome-based/Firefox and MS Edge (with some difficults).

Also, don't forget about such thing like JRE. Sometimes it also requires
to install cache root CA.

And, such thing as Thunderbird - it does not share certificate store
with FF.

12.03.2018 15:40, Nicolas Kovacs ?????:
> Hi,
>
> I have a few prospective clients who want/need to log and monitor all
> their web traffic and asked me to find a viable solution for this.
>
> After a couple of weeks of fiddling, I decided to opt for the
> Squid+SquidAnalyzer setup, which works quite well. I have a sandbox
> installation here in my office that already works quite satisfyingly.
>
> While working out the solution (thanks again to you guys, you know who
> you are), I took some extensive notes on my technical blog:
>
>   * https://blog.microlinux.fr/squid-centos/
>
>   * https://blog.microlinux.fr/squid-https-centos/
>
>   * https://blog.microlinux.fr/squidanalyzer-centos/
>
>   * https://blog.microlinux.fr/squid-exceptions/
>
> I have yet one problem to tackle, and I already have a solution in mind.
> Though I thought I'd rather ask here first, since this is a bit new to
> me, and you guys have much more experience.
>
> Most of my clients are small businesses with up to a few dozen client
> PCs, and also wireless access.
>
> The problem I'm currently facing is: how to provide an easy installation
> of Squid's root certificate? During my tests, I wrote some short
> instructions for my Linux clients with Firefox, Chrome and Konqueror:
>
> https://blog.microlinux.fr/squid-https-centos/#navigateurs
>
> Here's what I intend to do. Configure a local web page
> http://proxy.company.lan where clients can download the certificate file
> proxy.company.lan.der. This page also contains quick & dirty
> instructions on how to install the certificate on the most popular
> browsers/platforms (Chrome, Firefox, Safari, Internet Explorer).
>
> Each company will also have a printed document, explaining how to access
> the Internet. Something like this:
>
>   1. Open http://proxy.company.lan in your browser.
>
>   2. Download the proxy.company.lan.der certificate file.
>
>   3. Follow instructions to import this file into your browser.
>
>   4. Browse the web normally.
>
> Before doing that, I thought I'd inquire how you guys go about that. As
> a long-time Slackware user I've always been a fan of the KISS principle
> (Keep It Simple Stupid), so I try to have a no-nonsense approach.
>
> Any suggestions?
>
> Cheers from the sunny South of France,
>
> Niki
>

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/e23af4f6/attachment.sig>

From danilovt at gmail.com  Mon Mar 12 14:03:24 2018
From: danilovt at gmail.com (Danilo V)
Date: Mon, 12 Mar 2018 14:03:24 +0000
Subject: [squid-users] Trouble accessing outlook.com
Message-ID: <CAHaQnLPA6wVgqVxtiAX6OJVtHd5hOn8VkYV7dbZmnDWqpmOkzw@mail.gmail.com>

Hello, I'm having trouble accessing *http://outlook.com
<http://outlook.com>* through Squid.
The browser returns: Unable to connect (ERR_TUNNEL_CONNECTION_FAILED).
This problem is intermittent, it means that at some times it's all right.
Everything else is normal. Requests without proxy are allways OK.
I also tested using a clean installation of squid 3.4.8

- Access.log:
1520862206.753    492 10.32.12.250 TCP_MISS/301 506 GET http://outlook.com/
- HIER_DIRECT/40.97.161.50 -
1520862206.757      0 10.32.12.250 TCP_MISS/503 0 CONNECT
www.outlook.com:443 - HIER_NONE/- -

- Cache.log
2018/03/12 10:43:43.505 kid1| Ip.cc(560) match: aclIpMatchIp: '
10.32.12.250:56352' found
2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked: all = 1
2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked: http_access#1 =
1
2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked: http_access = 1
2018/03/12 10:43:43.505 kid1| Checklist.cc(55) markFinished: 0x7f0f1350ada8
answer ALLOWED for match
2018/03/12 10:43:43.505 kid1| Checklist.cc(155) checkCallback:
ACLChecklist::checkCallback: 0x7f0f1350ada8 answer=ALLOWED
2018/03/12 10:43:43.505 kid1| Checklist.cc(62) preCheck: 0x7ffd6dda7e10
checking fast ACLs
2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked: (access_log
daemon:/var/log/squid3/access.log line) = 1
2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked: access_log
daemon:/var/log/squid3/access.log = 1
2018/03/12 10:43:43.505 kid1| Checklist.cc(55) markFinished: 0x7ffd6dda7e10
answer ALLOWED for match
2018/03/12 10:43:45.836 kid1| Checklist.cc(62) preCheck: 0x7ffd6dda7e10
checking fast ACLs
2018/03/12 10:43:45.836 kid1| Acl.cc(177) matches: checked: (access_log
daemon:/var/log/squid3/access.log line) = 1
2018/03/12 10:43:45.836 kid1| Acl.cc(177) matches: checked: access_log
daemon:/var/log/squid3/access.log = 1
2018/03/12 10:43:45.836 kid1| Checklist.cc(55) markFinished: 0x7ffd6dda7e10
answer ALLOWED for match

Any suggestions?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/afb89b85/attachment.htm>

From yvoinov at gmail.com  Mon Mar 12 14:05:45 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 12 Mar 2018 20:05:45 +0600
Subject: [squid-users] Trouble accessing outlook.com
In-Reply-To: <CAHaQnLPA6wVgqVxtiAX6OJVtHd5hOn8VkYV7dbZmnDWqpmOkzw@mail.gmail.com>
References: <CAHaQnLPA6wVgqVxtiAX6OJVtHd5hOn8VkYV7dbZmnDWqpmOkzw@mail.gmail.com>
Message-ID: <ef0805c8-911c-b463-891a-a081316a93c2@gmail.com>

3.4.8 is too ancient to correctly work with SSL.

At least upgrade to 3.5.27 first.


12.03.2018 20:03, Danilo V ?????:
> Hello, I'm having trouble accessing *http://outlook.com* through Squid.
> The browser returns: Unable to connect (ERR_TUNNEL_CONNECTION_FAILED).
> This problem is intermittent, it means that at some times it's all right.
> Everything else is normal. Requests without proxy are allways OK.
> I also tested using a clean installation of squid 3.4.8
>
> - Access.log:
> 1520862206.753 ? ?492 10.32.12.250 TCP_MISS/301 506 GET
> http://outlook.com/ - HIER_DIRECT/40.97.161.50 <http://40.97.161.50> -
> 1520862206.757 ? ? ?0 10.32.12.250 TCP_MISS/503 0 CONNECT
> www.outlook.com:443 <http://www.outlook.com:443> - HIER_NONE/- -
>
> - Cache.log
> 2018/03/12 10:43:43.505 kid1| Ip.cc(560) match: aclIpMatchIp:
> '10.32.12.250:56352 <http://10.32.12.250:56352>' found
> 2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked: all = 1
> 2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked:
> http_access#1 = 1
> 2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked:
> http_access = 1
> 2018/03/12 10:43:43.505 kid1| Checklist.cc(55) markFinished:
> 0x7f0f1350ada8 answer ALLOWED for match
> 2018/03/12 10:43:43.505 kid1| Checklist.cc(155) checkCallback:
> ACLChecklist::checkCallback: 0x7f0f1350ada8 answer=ALLOWED
> 2018/03/12 10:43:43.505 kid1| Checklist.cc(62) preCheck:
> 0x7ffd6dda7e10 checking fast ACLs
> 2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked:
> (access_log daemon:/var/log/squid3/access.log line) = 1
> 2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked: access_log
> daemon:/var/log/squid3/access.log = 1
> 2018/03/12 10:43:43.505 kid1| Checklist.cc(55) markFinished:
> 0x7ffd6dda7e10 answer ALLOWED for match
> 2018/03/12 10:43:45.836 kid1| Checklist.cc(62) preCheck:
> 0x7ffd6dda7e10 checking fast ACLs
> 2018/03/12 10:43:45.836 kid1| Acl.cc(177) matches: checked:
> (access_log daemon:/var/log/squid3/access.log line) = 1
> 2018/03/12 10:43:45.836 kid1| Acl.cc(177) matches: checked: access_log
> daemon:/var/log/squid3/access.log = 1
> 2018/03/12 10:43:45.836 kid1| Checklist.cc(55) markFinished:
> 0x7ffd6dda7e10 answer ALLOWED for match
>
> Any suggestions?
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/d077e581/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/d077e581/attachment.sig>

From danilovt at gmail.com  Mon Mar 12 14:19:53 2018
From: danilovt at gmail.com (Danilo V)
Date: Mon, 12 Mar 2018 14:19:53 +0000
Subject: [squid-users] Trouble accessing outlook.com
In-Reply-To: <ef0805c8-911c-b463-891a-a081316a93c2@gmail.com>
References: <CAHaQnLPA6wVgqVxtiAX6OJVtHd5hOn8VkYV7dbZmnDWqpmOkzw@mail.gmail.com>
 <ef0805c8-911c-b463-891a-a081316a93c2@gmail.com>
Message-ID: <CAHaQnLOaaKy==B_0KLD=n24_z+hJoz4hu++sVfSqb0qt6U25dQ@mail.gmail.com>

I'm not using SSL.

Em seg, 12 de mar de 2018 ?s 11:06, Yuri <yvoinov at gmail.com> escreveu:

> 3.4.8 is too ancient to correctly work with SSL.
>
> At least upgrade to 3.5.27 first.
>
> 12.03.2018 20:03, Danilo V ?????:
>
> Hello, I'm having trouble accessing *http://outlook.com
> <http://outlook.com>* through Squid.
> The browser returns: Unable to connect (ERR_TUNNEL_CONNECTION_FAILED).
> This problem is intermittent, it means that at some times it's all right.
> Everything else is normal. Requests without proxy are allways OK.
> I also tested using a clean installation of squid 3.4.8
>
> - Access.log:
> 1520862206.753    492 10.32.12.250 TCP_MISS/301 506 GET
> http://outlook.com/ - HIER_DIRECT/40.97.161.50 -
> 1520862206.757      0 10.32.12.250 TCP_MISS/503 0 CONNECT
> www.outlook.com:443 - HIER_NONE/- -
>
> - Cache.log
> 2018/03/12 10:43:43.505 kid1| Ip.cc(560) match: aclIpMatchIp: '
> 10.32.12.250:56352' found
> 2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked: all = 1
> 2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked: http_access#1
> = 1
> 2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked: http_access = 1
> 2018/03/12 10:43:43.505 kid1| Checklist.cc(55) markFinished:
> 0x7f0f1350ada8 answer ALLOWED for match
> 2018/03/12 10:43:43.505 kid1| Checklist.cc(155) checkCallback:
> ACLChecklist::checkCallback: 0x7f0f1350ada8 answer=ALLOWED
> 2018/03/12 10:43:43.505 kid1| Checklist.cc(62) preCheck: 0x7ffd6dda7e10
> checking fast ACLs
> 2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked: (access_log
> daemon:/var/log/squid3/access.log line) = 1
> 2018/03/12 10:43:43.505 kid1| Acl.cc(177) matches: checked: access_log
> daemon:/var/log/squid3/access.log = 1
> 2018/03/12 10:43:43.505 kid1| Checklist.cc(55) markFinished:
> 0x7ffd6dda7e10 answer ALLOWED for match
> 2018/03/12 10:43:45.836 kid1| Checklist.cc(62) preCheck: 0x7ffd6dda7e10
> checking fast ACLs
> 2018/03/12 10:43:45.836 kid1| Acl.cc(177) matches: checked: (access_log
> daemon:/var/log/squid3/access.log line) = 1
> 2018/03/12 10:43:45.836 kid1| Acl.cc(177) matches: checked: access_log
> daemon:/var/log/squid3/access.log = 1
> 2018/03/12 10:43:45.836 kid1| Checklist.cc(55) markFinished:
> 0x7ffd6dda7e10 answer ALLOWED for match
>
> Any suggestions?
>
>
> _______________________________________________
> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>
>
> --
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/95d8e852/attachment.htm>

From yvoinov at gmail.com  Mon Mar 12 14:21:29 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 12 Mar 2018 20:21:29 +0600
Subject: [squid-users] Trouble accessing outlook.com
In-Reply-To: <CAHaQnLOaaKy==B_0KLD=n24_z+hJoz4hu++sVfSqb0qt6U25dQ@mail.gmail.com>
References: <CAHaQnLPA6wVgqVxtiAX6OJVtHd5hOn8VkYV7dbZmnDWqpmOkzw@mail.gmail.com>
 <ef0805c8-911c-b463-891a-a081316a93c2@gmail.com>
 <CAHaQnLOaaKy==B_0KLD=n24_z+hJoz4hu++sVfSqb0qt6U25dQ@mail.gmail.com>
Message-ID: <cd43406f-1875-a4f8-5894-ad4ed3b8a226@gmail.com>

But your client do.


12.03.2018 20:19, Danilo V ?????:
> 1520862206.757 ? ? ?0 10.32.12.250 TCP_MISS/503 0 CONNECT
> www.outlook.com:443 <http://www.outlook.com:443> - HIER_NONE/- -

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/c56bd43c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/c56bd43c/attachment.sig>

From yvoinov at gmail.com  Mon Mar 12 14:47:21 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 12 Mar 2018 20:47:21 +0600
Subject: [squid-users] Trouble accessing outlook.com
In-Reply-To: <cd43406f-1875-a4f8-5894-ad4ed3b8a226@gmail.com>
References: <CAHaQnLPA6wVgqVxtiAX6OJVtHd5hOn8VkYV7dbZmnDWqpmOkzw@mail.gmail.com>
 <ef0805c8-911c-b463-891a-a081316a93c2@gmail.com>
 <CAHaQnLOaaKy==B_0KLD=n24_z+hJoz4hu++sVfSqb0qt6U25dQ@mail.gmail.com>
 <cd43406f-1875-a4f8-5894-ad4ed3b8a226@gmail.com>
Message-ID: <394f9949-e35a-1ae6-88d6-60012fcfbbc4@gmail.com>

I've just tried to reproduce your issue on my Squid 5.0.0.

1. First browser goes to http://outlook.com

2. Server redirects it to https://outlook.com, and, then redirect to
https://outlook.live.com/owa/

3. I have outlook.com and outlook.live.com in my splice ACL (I'm using
SSL bump, yes).

4. Before outlook.live.com, browser goes via

1520865842.280?? 6994 192.168.201.10 TCP_MISS/200 364906 GET
https://r1.res.offi
ce365.com/owalanding/v1.16/images/landing-macbook.png -
HIER_DIRECT/23.45.97.45
image/png

4. After this, https://outlook.live.com/owa/ correctly opens.

So, when I splice both domains on step 2, they are tunnels and, finally,
I've passed to outlook web interface.


12.03.2018 20:21, Yuri ?????:
>
> But your client do.
>
>
> 12.03.2018 20:19, Danilo V ?????:
>> 1520862206.757 ? ? ?0 10.32.12.250 TCP_MISS/503 0 CONNECT
>> www.outlook.com:443 <http://www.outlook.com:443> - HIER_NONE/- -
>
> -- 
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/fba196b7/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/fba196b7/attachment.sig>

From danilovt at gmail.com  Mon Mar 12 19:08:59 2018
From: danilovt at gmail.com (Danilo V)
Date: Mon, 12 Mar 2018 19:08:59 +0000
Subject: [squid-users] Trouble accessing outlook.com
In-Reply-To: <394f9949-e35a-1ae6-88d6-60012fcfbbc4@gmail.com>
References: <CAHaQnLPA6wVgqVxtiAX6OJVtHd5hOn8VkYV7dbZmnDWqpmOkzw@mail.gmail.com>
 <ef0805c8-911c-b463-891a-a081316a93c2@gmail.com>
 <CAHaQnLOaaKy==B_0KLD=n24_z+hJoz4hu++sVfSqb0qt6U25dQ@mail.gmail.com>
 <cd43406f-1875-a4f8-5894-ad4ed3b8a226@gmail.com>
 <394f9949-e35a-1ae6-88d6-60012fcfbbc4@gmail.com>
Message-ID: <CAHaQnLOuuAt59AZj_XNWxDxBL6aFgYpUAf53X01FR7afgf96jg@mail.gmail.com>

I've tested on 3.5.23 and everything is ok. The issue is in the squid
version.
Thank you Yuri!

Best,
Danilo

Thanks. I will test on
Em seg, 12 de mar de 2018 ?s 11:47, Yuri <yvoinov at gmail.com> escreveu:

> I've just tried to reproduce your issue on my Squid 5.0.0.
>
> 1. First browser goes to http://outlook.com
>
> 2. Server redirects it to https://outlook.com, and, then redirect to
> https://outlook.live.com/owa/
>
> 3. I have outlook.com and outlook.live.com in my splice ACL (I'm using
> SSL bump, yes).
>
> 4. Before outlook.live.com, browser goes via
>
> 1520865842.280   6994 192.168.201.10 TCP_MISS/200 364906 GET
> https://r1.res.offi
> ce365.com/owalanding/v1.16/images/landing-macbook.png - HIER_DIRECT/
> 23.45.97.45
> image/png
>
> 4. After this, https://outlook.live.com/owa/ correctly opens.
>
> So, when I splice both domains on step 2, they are tunnels and, finally,
> I've passed to outlook web interface.
>
> 12.03.2018 20:21, Yuri ?????:
>
> But your client do.
>
> 12.03.2018 20:19, Danilo V ?????:
>
> 1520862206.757      0 10.32.12.250 TCP_MISS/503 0 CONNECT
> www.outlook.com:443 - HIER_NONE/- -
>
>
> --
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************
>
>
> --
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/27a29a11/attachment.htm>

From yvoinov at gmail.com  Mon Mar 12 19:12:12 2018
From: yvoinov at gmail.com (Yuri)
Date: Tue, 13 Mar 2018 01:12:12 +0600
Subject: [squid-users] Trouble accessing outlook.com
In-Reply-To: <CAHaQnLOuuAt59AZj_XNWxDxBL6aFgYpUAf53X01FR7afgf96jg@mail.gmail.com>
References: <CAHaQnLPA6wVgqVxtiAX6OJVtHd5hOn8VkYV7dbZmnDWqpmOkzw@mail.gmail.com>
 <ef0805c8-911c-b463-891a-a081316a93c2@gmail.com>
 <CAHaQnLOaaKy==B_0KLD=n24_z+hJoz4hu++sVfSqb0qt6U25dQ@mail.gmail.com>
 <cd43406f-1875-a4f8-5894-ad4ed3b8a226@gmail.com>
 <394f9949-e35a-1ae6-88d6-60012fcfbbc4@gmail.com>
 <CAHaQnLOuuAt59AZj_XNWxDxBL6aFgYpUAf53X01FR7afgf96jg@mail.gmail.com>
Message-ID: <3c35b46f-161b-c177-f3da-9d0432ca3999@gmail.com>

You are welcome ;)

Always consider upgrade first :)


13.03.2018 01:08, Danilo V ?????:
> I've tested on 3.5.23 and everything is ok. The issue is in the squid
> version.
> Thank you Yuri!
>
> Best,
> Danilo
>
> Thanks. I will test on?
> Em seg, 12 de mar de 2018 ?s 11:47, Yuri <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com>> escreveu:
>
>     I've just tried to reproduce your issue on my Squid 5.0.0.
>
>     1. First browser goes to http://outlook.com
>
>     2. Server redirects it to https://outlook.com, and, then redirect
>     to https://outlook.live.com/owa/
>
>     3. I have outlook.com <http://outlook.com> and outlook.live.com
>     <http://outlook.live.com> in my splice ACL (I'm using SSL bump, yes).
>
>     4. Before outlook.live.com <http://outlook.live.com>, browser goes via
>
>     1520865842.280?? 6994 192.168.201.10 TCP_MISS/200 364906 GET
>     https://r1.res.offi
>     ce365.com/owalanding/v1.16/images/landing-macbook.png
>     <http://ce365.com/owalanding/v1.16/images/landing-macbook.png> -
>     HIER_DIRECT/23.45.97.45 <http://23.45.97.45>
>     image/png
>
>     4. After this, https://outlook.live.com/owa/ correctly opens.
>
>     So, when I splice both domains on step 2, they are tunnels and,
>     finally, I've passed to outlook web interface.
>
>
>     12.03.2018 20:21, Yuri ?????:
>>
>>     But your client do.
>>
>>
>>     12.03.2018 20:19, Danilo V ?????:
>>>     1520862206.757 ? ? ?0 10.32.12.250 TCP_MISS/503 0 CONNECT
>>>     www.outlook.com:443 <http://www.outlook.com:443> - HIER_NONE/- -
>>
>>     -- 
>>     "C++ seems like a language suitable for firing other people's legs."
>>
>>     *****************************
>>     * C++20 : Bug to the future *
>>     *****************************
>
>     -- 
>     "C++ seems like a language suitable for firing other people's legs."
>
>     *****************************
>     * C++20 : Bug to the future *
>     *****************************
>

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/0a09e589/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/0a09e589/attachment.sig>

From jmpatagonia at gmail.com  Mon Mar 12 19:20:14 2018
From: jmpatagonia at gmail.com (Juan Manuel P)
Date: Mon, 12 Mar 2018 16:20:14 -0300
Subject: [squid-users] TCP_MISS_ABORTED/000|
In-Reply-To: <38c28f9a-80ed-5689-8e8f-7a1ccac1e2b9@gmail.com>
References: <CADZCxsum3Kjq8OLdCfETtTW+Krfhtp9qpjGcCZtKEGYhfE5d1g@mail.gmail.com>
 <1cd01c76-5dc4-b743-c741-c0c06f58bf25@gmail.com>
 <CADZCxsssUjxNuckCJ5j4bZsgd8zSrYchWKrpOkpkgxkOQ9os0g@mail.gmail.com>
 <08f44e3e-dc16-1bfe-50ae-0df34d2c0716@gmail.com>
 <CADZCxstn8yHe5XyBq+J-Ob929y0AcFSGqTacX-yuAdPgwOBmqA@mail.gmail.com>
 <38c28f9a-80ed-5689-8e8f-7a1ccac1e2b9@gmail.com>
Message-ID: <CADZCxssHwax8qk7_FBcPdd6W7ZfxeR_qSXQ074maKHwuBvnxXw@mail.gmail.com>

I found a solutions to problem  TCP_MISS_ABORTED/000, we have a balance
router tplink betwen the squid proxy server and the ISP, just eliminate the
balance router tplinkand the problem desapear , later I will investigate
the balance router to found a final solution, and tell us.

regards

2018-02-28 18:01 GMT-03:00 Yuri <yvoinov at gmail.com>:

> Windows often spit on RFC due to do not disturb users. Squid is not.
>
> Anyway, as you can see, from my side, with well-configured infrastructure
> and well-configured squid, is also no problem.
>
> So, may be, somebody's hands like legs.... ;-)
>
> 01.03.2018 02:59, Juan Manuel P ?????:
>
> We are migrating from a old proxy server kerio-win-route on windows to a
> squid proxy server.
> The old proxy server no have problems.
>
> regards.
>
>
>
> 2018-02-28 17:56 GMT-03:00 Yuri <yvoinov at gmail.com>:
>
>> Seems so. May be, ever ISP. Misconfigured MPLS can lead this errors.
>>
>> 01.03.2018 02:55, Juan Manuel P ?????:
>>
>> Hello Yuri today on access.log a get a lot off TCP_MISS_ABORTED/000 on
>> many diferentes sites:
>>
>> 28/Feb/2018:13:50:00 -0300 || - || 10.15.43.31 || TCP_MISS_ABORTED/000||
>> GET || http://loprincipal.com.ar/wp-content/plugins/wp-facebook-liv
>> e-video/inc/style.css? || -
>> 28/Feb/2018:13:50:00 -0300 || - || 10.15.43.31 || TCP_MISS_ABORTED/000||
>> GET || http://loprincipal.com.ar/wp-content/plugins/wp-facebook-liv
>> e-video/inc/script.js? || -
>> 28/Feb/2018:13:53:37 -0300 || - || 10.15.43.31 || TCP_MISS_ABORTED/000||
>> POST || http://m.addthis.com/live/red_lojson/100eng.json? || -
>> 28/Feb/2018:13:54:09 -0300 || - || 10.15.43.31 || TCP_MISS_ABORTED/000||
>> POST || http://m.addthis.com/live/red_lojson/100eng.json? || -
>> 28/Feb/2018:14:04:19 -0300 || - || 10.14.43.147 || TCP_MISS_ABORTED/000||
>> POST || http://m.addthis.com/live/red_lojson/100eng.json? || -
>> 28/Feb/2018:14:04:19 -0300 || - || 10.14.43.147 || TCP_MISS_ABORTED/000||
>> POST || http://m.addthis.com/live/red_lojson/100eng.json? || -
>> 28/Feb/2018:14:07:56 -0300 || - || 10.14.43.88 || TCP_MISS_ABORTED/000||
>> GET || http://ocsp2.globalsign.com/gsextendvalsha2g2/ME0wSzBJMEcwRT
>> AJBgUrDgMCGgUABBRYCCQuHbjl0T2z%2Bv2quSEm8NK1fgQU2kB3Q2Uc%2BP
>> 6n4%2FRkgj5NQxMiMQICDGPo4Vlu6pcIoIq7tA%3D%3D || -
>> 28/Feb/2018:14:08:11 -0300 || - || 10.14.43.88 || TCP_MISS_ABORTED/000||
>> GET || http://crl.globalsign.com/gs/gsextendvalsha2g2.crl || -
>> 28/Feb/2018:14:11:56 -0300 || - || 10.15.43.30 || TCP_MISS_ABORTED/000||
>> GET || http://ipv6.msftncsi.com/ncsi.txt || -
>> 28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 || TCP_MISS_ABORTED/000||
>> GET || http://www.bancopatagonia.com/comunes/imas/facebook.jpg || -
>> 28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 || TCP_MISS_ABORTED/000||
>> GET || http://www.bancopatagonia.com/comunes/imas/youtube.jpg || -
>> 28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 || TCP_MISS_ABORTED/000||
>> GET || http://www.bancopatagonia.com/personas/imas/dest_espectaculos.jpg
>> || -
>> 28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 || TCP_MISS_ABORTED/000||
>> GET || http://www.bancopatagonia.com/comunes/imas/img_youtube.gif || -
>> 28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 || TCP_MISS_ABORTED/000||
>> GET || http://www.bancopatagonia.com/comunes/imas/facebook-pie.jpg || -
>> 28/Feb/2018:15:13:48 -0300 || - || 10.14.43.162 || TCP_MISS_ABORTED/000||
>> POST || http://ocsp.usertrust.com/ || -
>> 28/Feb/2018:15:34:18 -0300 || - || 10.14.43.77 || TCP_MISS_ABORTED/000||
>> GET || http://search.it.online.fr/covers/wp-content/Milo_Manara,_
>> in_Giuseppe_Bergman,_2005_(Manet).jpg || -
>> 28/Feb/2018:15:51:21 -0300 || - || 10.14.43.162 || TCP_MISS_ABORTED/000||
>> GET || http://csi.gstatic.com/csi? || -
>> 28/Feb/2018:15:51:22 -0300 || - || 10.14.43.162 || TCP_MISS_ABORTED/404||
>> GET || http://www.snehashish.com/wp-content/themes/computers/images
>> /slide-left.png || text/html
>> 28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 || TCP_MISS_ABORTED/000||
>> GET || http://www.bancopatagonia.com.ar/personas/imas/dest_espectac
>> ulos.jpg || -
>> 28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 || TCP_MISS_ABORTED/000||
>> GET || http://www.bancopatagonia.com.ar/comunes/imas/facebook.jpg || -
>> 28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 || TCP_MISS_ABORTED/000||
>> GET || http://www.bancopatagonia.com.ar/comunes/imas/img_youtube.gif || -
>> 28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 || TCP_MISS_ABORTED/000||
>> GET || http://www.bancopatagonia.com.ar/comunes/imas/facebook-pie.jpg ||
>> -
>> 28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 || TCP_MISS_ABORTED/000||
>> GET || http://www.bancopatagonia.com.ar/comunes/imas/youtube.jpg || -
>> 28/Feb/2018:16:18:53 -0300 || - || 192.168.43.57 ||
>> TCP_MISS_ABORTED/000|| GET || http://loprincipal.com.ar/wp-c
>> ontent/plugins/wp-facebook-live-video/inc/script.js? || -
>> 28/Feb/2018:16:18:53 -0300 || - || 192.168.43.57 ||
>> TCP_MISS_ABORTED/000|| GET || http://loprincipal.com.ar/wp-c
>> ontent/plugins/wp-facebook-live-video/inc/style.css? || -
>>
>> I thinking the problem is not in squid, maybe DNS or something similar.
>>
>> regards.
>>
>>
>> 2018-02-28 17:46 GMT-03:00 Yuri <yvoinov at gmail.com>:
>>
>>> Let's look on your server:
>>>
>>>  # wget -S http://rionegro.gov.ar/download/images/00033636.jpg
>>> --2018-03-01 02:37:38--  http://rionegro.gov.ar/downloa
>>> d/images/00033636.jpg
>>> Connecting to 127.0.0.1:3128... connected.
>>> Proxy request sent, awaiting response...
>>>   HTTP/1.1 200 OK
>>>   Date: Wed, 28 Feb 2018 19:38:03 GMT
>>>   Server: Apache
>>>   Last-Modified: Wed, 28 Feb 2018 16:07:15 GMT
>>>   Accept-Ranges: bytes
>>>   Content-Length: 135872
>>>   Content-Type: image/jpeg
>>>   Age: 979
>>>   X-Cache: HIT from rn-speed-unifix
>>>   X-Cache: MISS from khorne
>>>   X-Cache-Lookup: MISS from khorne:3128
>>>   Connection: keep-alive
>>> Length: 135872 (133K) [image/jpeg]
>>> Saving to: '00033636.jpg'
>>>
>>> 00033636.jpg        100%[===================>] 132.69K  2.79KB/s    in
>>> 58s
>>>
>>> 2018-03-01 02:38:39 (2.29 KB/s) - '00033636.jpg' saved [135872/135872]
>>>
>>> All seems ok. A bit slow downloading - but ok.
>>>
>>> May be, this is your regional connectivity issues? For example,
>>> slooooooooooow links, slooooooooooooow DNS, dropped packets, etc.?
>>>
>>> 01.03.2018 02:36, Juan Manuel P ?????:
>>>
>>>
>>> Hello I send more data about the problem.
>>>
>>> The problem occur for example on this page (see below). But not occur on
>>> the ssl/https version of the same page.
>>>
>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 || TCP_MISS_ABORTED/000||
>>> GET || http://rionegro.gov.ar/media/components/youtubetv/ytv.css || -
>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 || TCP_MISS_ABORTED/000||
>>> GET || http://rionegro.gov.ar/media/components/youtubetv/principal.css
>>> || -
>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 || TCP_MISS_ABORTED/000||
>>> GET || http://rionegro.gov.ar/media/components/youtubetv/ytv.js || -
>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 || TCP_MISS_ABORTED/000||
>>> GET || http://rionegro.gov.ar/media/images/disenio/ini_nav.png || -
>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 || TCP_MISS_ABORTED/000||
>>> GET || http://rionegro.gov.ar/download/images/00033645.jpg || -
>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 || TCP_MISS_ABORTED/000||
>>> GET || http://rionegro.gov.ar/download/images/00033644.jpg || -
>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>> TCP_MEM_HIT_ABORTED/200|| GET || http://rionegro.gov.ar/downloa
>>> d/banner/00002923.jpg || image/jpeg
>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 || TCP_MISS_ABORTED/000||
>>> GET || http://rionegro.gov.ar/media/images/lema.png || -
>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 || TCP_MISS_ABORTED/000||
>>> GET || http://rionegro.gov.ar/media/images/logomarcarn.png || -
>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 || TCP_MISS_ABORTED/000||
>>> GET || http://rionegro.gov.ar/download/images/00033636.jpg || -
>>>
>>>
>>> And when the problem occur the page is waiting and slowly until upload
>>> complete.
>>>
>>> Later the page upload whitout problem.
>>>
>>>
>>> I see that the TCP_MISS_ABORTED appear only on some extension file, css,
>>> js, png, jpg. When are waiting for page upload complete this elements or
>>> componentes are not charged but the rest of the page yes. Some time later
>>> all the page is upload.
>>>
>>> Regards.
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>> --
>>> *****************************
>>> * C++20 : Bug to the future *
>>> *****************************
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>
>>
>> _______________________________________________
>> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>>
>>
>> --
>> *****************************
>> * C++20 : Bug to the future *
>> *****************************
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
>
> _______________________________________________
> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>
>
> --
> *****************************
> * C++20 : Bug to the future *
> *****************************
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/5d0d0c67/attachment.htm>

From yvoinov at gmail.com  Mon Mar 12 19:21:48 2018
From: yvoinov at gmail.com (Yuri)
Date: Tue, 13 Mar 2018 01:21:48 +0600
Subject: [squid-users] TCP_MISS_ABORTED/000|
In-Reply-To: <CADZCxssHwax8qk7_FBcPdd6W7ZfxeR_qSXQ074maKHwuBvnxXw@mail.gmail.com>
References: <CADZCxsum3Kjq8OLdCfETtTW+Krfhtp9qpjGcCZtKEGYhfE5d1g@mail.gmail.com>
 <1cd01c76-5dc4-b743-c741-c0c06f58bf25@gmail.com>
 <CADZCxsssUjxNuckCJ5j4bZsgd8zSrYchWKrpOkpkgxkOQ9os0g@mail.gmail.com>
 <08f44e3e-dc16-1bfe-50ae-0df34d2c0716@gmail.com>
 <CADZCxstn8yHe5XyBq+J-Ob929y0AcFSGqTacX-yuAdPgwOBmqA@mail.gmail.com>
 <38c28f9a-80ed-5689-8e8f-7a1ccac1e2b9@gmail.com>
 <CADZCxssHwax8qk7_FBcPdd6W7ZfxeR_qSXQ074maKHwuBvnxXw@mail.gmail.com>
Message-ID: <42adbc2e-7211-ef7d-2702-59a3491af551@gmail.com>

You can also play around with squid's config parameters to fit your LAN
specifications.

13.03.2018 01:20, Juan Manuel P ?????:
> I found a solutions to problem? TCP_MISS_ABORTED/000, we have a
> balance router tplink betwen the squid proxy server and the ISP, just
> eliminate the balance router tplinkand the problem desapear , later I
> will investigate the balance router to found a final solution, and
> tell us.
>
> regards
>
> 2018-02-28 18:01 GMT-03:00 Yuri <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com>>:
>
>     Windows often spit on RFC due to do not disturb users. Squid is not.
>
>     Anyway, as you can see, from my side, with well-configured
>     infrastructure and well-configured squid, is also no problem.
>
>     So, may be, somebody's hands like legs.... ;-)
>
>
>     01.03.2018 02:59, Juan Manuel P ?????:
>>     We are migrating from a old proxy server kerio-win-route on
>>     windows to a squid proxy server.
>>     The old proxy server no have problems.
>>
>>     regards.
>>
>>
>>
>>     2018-02-28 17:56 GMT-03:00 Yuri <yvoinov at gmail.com
>>     <mailto:yvoinov at gmail.com>>:
>>
>>         Seems so. May be, ever ISP. Misconfigured MPLS can lead this
>>         errors.
>>
>>
>>         01.03.2018 02:55, Juan Manuel P ?????:
>>>         Hello Yuri today on access.log a get a lot off
>>>         TCP_MISS_ABORTED/000 on many diferentes sites:
>>>
>>>         28/Feb/2018:13:50:00 -0300 || - || 10.15.43.31 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://loprincipal.com.ar/wp-content/plugins/wp-facebook-live-video/inc/style.css
>>>         <http://loprincipal.com.ar/wp-content/plugins/wp-facebook-live-video/inc/style.css>?
>>>         || -
>>>         28/Feb/2018:13:50:00 -0300 || - || 10.15.43.31 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://loprincipal.com.ar/wp-content/plugins/wp-facebook-live-video/inc/script.js
>>>         <http://loprincipal.com.ar/wp-content/plugins/wp-facebook-live-video/inc/script.js>?
>>>         || -
>>>         28/Feb/2018:13:53:37 -0300 || - || 10.15.43.31 ||
>>>         TCP_MISS_ABORTED/000|| POST ||
>>>         http://m.addthis.com/live/red_lojson/100eng.json
>>>         <http://m.addthis.com/live/red_lojson/100eng.json>? || -
>>>         28/Feb/2018:13:54:09 -0300 || - || 10.15.43.31 ||
>>>         TCP_MISS_ABORTED/000|| POST ||
>>>         http://m.addthis.com/live/red_lojson/100eng.json
>>>         <http://m.addthis.com/live/red_lojson/100eng.json>? || -
>>>         28/Feb/2018:14:04:19 -0300 || - || 10.14.43.147 ||
>>>         TCP_MISS_ABORTED/000|| POST ||
>>>         http://m.addthis.com/live/red_lojson/100eng.json
>>>         <http://m.addthis.com/live/red_lojson/100eng.json>? || -
>>>         28/Feb/2018:14:04:19 -0300 || - || 10.14.43.147 ||
>>>         TCP_MISS_ABORTED/000|| POST ||
>>>         http://m.addthis.com/live/red_lojson/100eng.json
>>>         <http://m.addthis.com/live/red_lojson/100eng.json>? || -
>>>         28/Feb/2018:14:07:56 -0300 || - || 10.14.43.88 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://ocsp2.globalsign.com/gsextendvalsha2g2/ME0wSzBJMEcwRTAJBgUrDgMCGgUABBRYCCQuHbjl0T2z%2Bv2quSEm8NK1fgQU2kB3Q2Uc%2BP6n4%2FRkgj5NQxMiMQICDGPo4Vlu6pcIoIq7tA%3D%3D
>>>         <http://ocsp2.globalsign.com/gsextendvalsha2g2/ME0wSzBJMEcwRTAJBgUrDgMCGgUABBRYCCQuHbjl0T2z%2Bv2quSEm8NK1fgQU2kB3Q2Uc%2BP6n4%2FRkgj5NQxMiMQICDGPo4Vlu6pcIoIq7tA%3D%3D>
>>>         || -
>>>         28/Feb/2018:14:08:11 -0300 || - || 10.14.43.88 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://crl.globalsign.com/gs/gsextendvalsha2g2.crl
>>>         <http://crl.globalsign.com/gs/gsextendvalsha2g2.crl> || -
>>>         28/Feb/2018:14:11:56 -0300 || - || 10.15.43.30 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://ipv6.msftncsi.com/ncsi.txt
>>>         <http://ipv6.msftncsi.com/ncsi.txt> || -
>>>         28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://www.bancopatagonia.com/comunes/imas/facebook.jpg
>>>         <http://www.bancopatagonia.com/comunes/imas/facebook.jpg> || -
>>>         28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://www.bancopatagonia.com/comunes/imas/youtube.jpg
>>>         <http://www.bancopatagonia.com/comunes/imas/youtube.jpg> || -
>>>         28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://www.bancopatagonia.com/personas/imas/dest_espectaculos.jpg
>>>         <http://www.bancopatagonia.com/personas/imas/dest_espectaculos.jpg>
>>>         || -
>>>         28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://www.bancopatagonia.com/comunes/imas/img_youtube.gif
>>>         <http://www.bancopatagonia.com/comunes/imas/img_youtube.gif>
>>>         || -
>>>         28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://www.bancopatagonia.com/comunes/imas/facebook-pie.jpg
>>>         <http://www.bancopatagonia.com/comunes/imas/facebook-pie.jpg>
>>>         || -
>>>         28/Feb/2018:15:13:48 -0300 || - || 10.14.43.162 ||
>>>         TCP_MISS_ABORTED/000|| POST || http://ocsp.usertrust.com/ || -
>>>         28/Feb/2018:15:34:18 -0300 || - || 10.14.43.77 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://search.it.online.fr/covers/wp-content/Milo_Manara,_in_Giuseppe_Bergman,_2005_(Manet).jpg
>>>         <http://search.it.online.fr/covers/wp-content/Milo_Manara,_in_Giuseppe_Bergman,_2005_%28Manet%29.jpg>
>>>         || -
>>>         28/Feb/2018:15:51:21 -0300 || - || 10.14.43.162 ||
>>>         TCP_MISS_ABORTED/000|| GET || http://csi.gstatic.com/csi? || -
>>>         28/Feb/2018:15:51:22 -0300 || - || 10.14.43.162 ||
>>>         TCP_MISS_ABORTED/404|| GET ||
>>>         http://www.snehashish.com/wp-content/themes/computers/images/slide-left.png
>>>         <http://www.snehashish.com/wp-content/themes/computers/images/slide-left.png>
>>>         || text/html
>>>         28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://www.bancopatagonia.com.ar/personas/imas/dest_espectaculos.jpg
>>>         <http://www.bancopatagonia.com.ar/personas/imas/dest_espectaculos.jpg>
>>>         || -
>>>         28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://www.bancopatagonia.com.ar/comunes/imas/facebook.jpg
>>>         <http://www.bancopatagonia.com.ar/comunes/imas/facebook.jpg>
>>>         || -
>>>         28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://www.bancopatagonia.com.ar/comunes/imas/img_youtube.gif
>>>         <http://www.bancopatagonia.com.ar/comunes/imas/img_youtube.gif>
>>>         || -
>>>         28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://www.bancopatagonia.com.ar/comunes/imas/facebook-pie.jpg
>>>         <http://www.bancopatagonia.com.ar/comunes/imas/facebook-pie.jpg>
>>>         || -
>>>         28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://www.bancopatagonia.com.ar/comunes/imas/youtube.jpg
>>>         <http://www.bancopatagonia.com.ar/comunes/imas/youtube.jpg> || -
>>>         28/Feb/2018:16:18:53 -0300 || - || 192.168.43.57 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://loprincipal.com.ar/wp-content/plugins/wp-facebook-live-video/inc/script.js
>>>         <http://loprincipal.com.ar/wp-content/plugins/wp-facebook-live-video/inc/script.js>?
>>>         || -
>>>         28/Feb/2018:16:18:53 -0300 || - || 192.168.43.57 ||
>>>         TCP_MISS_ABORTED/000|| GET ||
>>>         http://loprincipal.com.ar/wp-content/plugins/wp-facebook-live-video/inc/style.css
>>>         <http://loprincipal.com.ar/wp-content/plugins/wp-facebook-live-video/inc/style.css>?
>>>         || -
>>>
>>>         I thinking the problem is not in squid, maybe DNS or
>>>         something?similar.
>>>
>>>         regards.
>>>
>>>
>>>         2018-02-28 17:46 GMT-03:00 Yuri <yvoinov at gmail.com
>>>         <mailto:yvoinov at gmail.com>>:
>>>
>>>             Let's look on your server:
>>>
>>>             ?# wget -S
>>>             http://rionegro.gov.ar/download/images/00033636.jpg
>>>             <http://rionegro.gov.ar/download/images/00033636.jpg>
>>>             --2018-03-01 02:37:38--?
>>>             http://rionegro.gov.ar/download/images/00033636.jpg
>>>             <http://rionegro.gov.ar/download/images/00033636.jpg>
>>>             Connecting to 127.0.0.1:3128... connected.
>>>             Proxy request sent, awaiting response...
>>>             ? HTTP/1.1 200 OK
>>>             ? Date: Wed, 28 Feb 2018 19:38:03 GMT
>>>             ? Server: Apache
>>>             ? Last-Modified: Wed, 28 Feb 2018 16:07:15 GMT
>>>             ? Accept-Ranges: bytes
>>>             ? Content-Length: 135872
>>>             ? Content-Type: image/jpeg
>>>             ? Age: 979
>>>             ? X-Cache: HIT from rn-speed-unifix
>>>             ? X-Cache: MISS from khorne
>>>             ? X-Cache-Lookup: MISS from khorne:3128
>>>             ? Connection: keep-alive
>>>             Length: 135872 (133K) [image/jpeg]
>>>             Saving to: '00033636.jpg'
>>>
>>>             00033636.jpg??????? 100%[===================>] 132.69K?
>>>             2.79KB/s??? in 58s????
>>>
>>>             2018-03-01 02:38:39 (2.29 KB/s) - '00033636.jpg' saved
>>>             [135872/135872]
>>>
>>>             All seems ok. A bit slow downloading - but ok.
>>>
>>>             May be, this is your regional connectivity issues? For
>>>             example, slooooooooooow links, slooooooooooooow DNS,
>>>             dropped packets, etc.?
>>>
>>>
>>>             01.03.2018 02:36, Juan Manuel P ?????:
>>>>
>>>>             Hello I send more data about the problem.
>>>>
>>>>             The problem occur for example on this page (see below).
>>>>             But not occur on the ssl/https version of the same page.
>>>>
>>>>             28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>>             TCP_MISS_ABORTED/000|| GET ||
>>>>             http://rionegro.gov.ar/media/components/youtubetv/ytv.css
>>>>             <http://rionegro.gov.ar/media/components/youtubetv/ytv.css>
>>>>             || -
>>>>             28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>>             TCP_MISS_ABORTED/000|| GET ||
>>>>             http://rionegro.gov.ar/media/components/youtubetv/principal.css
>>>>             <http://rionegro.gov.ar/media/components/youtubetv/principal.css>
>>>>             || -
>>>>             28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>>             TCP_MISS_ABORTED/000|| GET ||
>>>>             http://rionegro.gov.ar/media/components/youtubetv/ytv.js
>>>>             <http://rionegro.gov.ar/media/components/youtubetv/ytv.js>
>>>>             || -
>>>>             28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>>             TCP_MISS_ABORTED/000|| GET ||
>>>>             http://rionegro.gov.ar/media/images/disenio/ini_nav.png
>>>>             <http://rionegro.gov.ar/media/images/disenio/ini_nav.png>
>>>>             || -
>>>>             28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>>             TCP_MISS_ABORTED/000|| GET ||
>>>>             http://rionegro.gov.ar/download/images/00033645.jpg
>>>>             <http://rionegro.gov.ar/download/images/00033645.jpg> || -
>>>>             28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>>             TCP_MISS_ABORTED/000|| GET ||
>>>>             http://rionegro.gov.ar/download/images/00033644.jpg
>>>>             <http://rionegro.gov.ar/download/images/00033644.jpg> || -
>>>>             28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>>             TCP_MEM_HIT_ABORTED/200|| GET ||
>>>>             http://rionegro.gov.ar/download/banner/00002923.jpg
>>>>             <http://rionegro.gov.ar/download/banner/00002923.jpg>
>>>>             || image/jpeg
>>>>             28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>>             TCP_MISS_ABORTED/000|| GET ||
>>>>             http://rionegro.gov.ar/media/images/lema.png
>>>>             <http://rionegro.gov.ar/media/images/lema.png> || -
>>>>             28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>>             TCP_MISS_ABORTED/000|| GET ||
>>>>             http://rionegro.gov.ar/media/images/logomarcarn.png
>>>>             <http://rionegro.gov.ar/media/images/logomarcarn.png> || -
>>>>             28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>>             TCP_MISS_ABORTED/000|| GET ||
>>>>             http://rionegro.gov.ar/download/images/00033636.jpg
>>>>             <http://rionegro.gov.ar/download/images/00033636.jpg> || -
>>>>
>>>>
>>>>             And when the problem occur the page is waiting and
>>>>             slowly until upload complete.
>>>>
>>>>             Later the page upload whitout problem.
>>>>
>>>>
>>>>             I see that the TCP_MISS_ABORTED appear only on some
>>>>             extension file, css, js, png, jpg. When are waiting for
>>>>             page upload complete this elements or componentes are
>>>>             not charged but the rest of the page yes. Some time
>>>>             later all the page is upload.
>>>>
>>>>             Regards.
>>>>
>>>>
>>>>
>>>>             _______________________________________________
>>>>             squid-users mailing list
>>>>             squid-users at lists.squid-cache.org
>>>>             <mailto:squid-users at lists.squid-cache.org>
>>>>             http://lists.squid-cache.org/listinfo/squid-users
>>>>             <http://lists.squid-cache.org/listinfo/squid-users>
>>>
>>>             -- 
>>>             *****************************
>>>             * C++20 : Bug to the future *
>>>             *****************************
>>>
>>>
>>>             _______________________________________________
>>>             squid-users mailing list
>>>             squid-users at lists.squid-cache.org
>>>             <mailto:squid-users at lists.squid-cache.org>
>>>             http://lists.squid-cache.org/listinfo/squid-users
>>>             <http://lists.squid-cache.org/listinfo/squid-users>
>>>
>>>
>>>
>>>
>>>         _______________________________________________
>>>         squid-users mailing list
>>>         squid-users at lists.squid-cache.org
>>>         <mailto:squid-users at lists.squid-cache.org>
>>>         http://lists.squid-cache.org/listinfo/squid-users
>>>         <http://lists.squid-cache.org/listinfo/squid-users>
>>
>>         -- 
>>         *****************************
>>         * C++20 : Bug to the future *
>>         *****************************
>>
>>
>>         _______________________________________________
>>         squid-users mailing list
>>         squid-users at lists.squid-cache.org
>>         <mailto:squid-users at lists.squid-cache.org>
>>         http://lists.squid-cache.org/listinfo/squid-users
>>         <http://lists.squid-cache.org/listinfo/squid-users>
>>
>>
>>
>>
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org>
>>     http://lists.squid-cache.org/listinfo/squid-users
>>     <http://lists.squid-cache.org/listinfo/squid-users>
>
>     -- 
>     *****************************
>     * C++20 : Bug to the future *
>     *****************************
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/1d4baca4/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/1d4baca4/attachment.sig>

From arunabha.saha at gmail.com  Tue Mar 13 00:06:52 2018
From: arunabha.saha at gmail.com (Arunabha Saha)
Date: Mon, 12 Mar 2018 17:06:52 -0700
Subject: [squid-users] Exception with squid 3.5.25 in ICAP options path
Message-ID: <CABCok=Ldd18_8ScakfFuK3p9P1JW=UAbP_8wt3xf3yx7TtT6_A@mail.gmail.com>

Seeing a exception followed by termination fairly regularly with
Squid-->Icap with this stacktrace on 3.5.25.

The problem typically happens when icap has not been started yet and squid
is processing some requests and is configured for ICAP adaptation service.

It seems like the ICAP Options request goes unanswered (as it would since
ICAP is not UP) and we try to shut down the ICAP service but there's some
dangling state with respect to the options  requests that were sent.

Appreciate it if someone can comment on whether this is known and fixed
before i dig a little deeper.



#0  0x00007ff944120428 in __GI_raise (sig=sig at entry=6) at
../sysdeps/unix/sysv/linux/raise.c:54
#1  0x00007ff94412202a in __GI_abort () at abort.c:89
#2  0x00007ff944a670d5 in __gnu_cxx::__verbose_terminate_handler() () from
/usr/lib/x86_64-linux-gnu/libstdc++.so.6
#3  0x00007ff944a64cc6 in ?? () from
/usr/lib/x86_64-linux-gnu/libstdc++.so.6
#4  0x00007ff944a63bc9 in ?? () from
/usr/lib/x86_64-linux-gnu/libstdc++.so.6
#5  0x00007ff944a645b8 in __gxx_personality_v0 () from
/usr/lib/x86_64-linux-gnu/libstdc++.so.6
#6  0x00007ff9444c4f03 in ?? () from /lib/x86_64-linux-gnu/libgcc_s.so.1
#7  0x00007ff9444c5410 in _Unwind_RaiseException () from
/lib/x86_64-linux-gnu/libgcc_s.so.1
#8  0x00007ff944a64f47 in __cxa_throw () from
/usr/lib/x86_64-linux-gnu/libstdc++.so.6
#9  0x00000000006f3486 in Throw (message=message at entry=0x8ae66e
"!theOptionsFetcher", fileName=fileName at entry=0x8ae647 "ServiceRep.cc",
lineNo=lineNo at entry=50,
    id=149798962) at TextException.cc:93
#10 0x00000000008071f9 in Adaptation::Icap::ServiceRep::~ServiceRep
(this=this at entry=0x1298b58, __in_chrg=<optimized out>,
__vtt_parm=<optimized out>)
    at ServiceRep.cc:50
#11 0x00000000008073c9 in Adaptation::Icap::ServiceRep::~ServiceRep
(this=0x1298b58, __in_chrg=<optimized out>, __vtt_parm=<optimized out>) at
ServiceRep.cc:52
#12 0x000000000081d6c3 in RefCount<Adaptation::Service>::dereference
(newP=0x0, this=0x133ef88) at ../../../src/base/RefCount.h:79
#13 RefCount<Adaptation::Service>::~RefCount (this=0x133ef88,
__in_chrg=<optimized out>) at ../../../src/base/RefCount.h:35
#14 Adaptation::Icap::Launcher::~Launcher (this=0x133ef68,
__vtt_parm=0xb5e208 <VTT for Adaptation::Icap::OptXactLauncher+8>,
__in_chrg=<optimized out>)
    at Launcher.cc:32
#15 0x0000000000830137 in
Adaptation::Icap::OptXactLauncher::~OptXactLauncher (this=0x133ef68,
__in_chrg=<optimized out>, __vtt_parm=<optimized out>)
    at ../../../src/adaptation/icap/OptXact.h:55
#16 Adaptation::Icap::OptXactLauncher::~OptXactLauncher (this=0x133ef68,
__in_chrg=<optimized out>, __vtt_parm=<optimized out>)
    at ../../../src/adaptation/icap/OptXact.h:55
#17 0x00000000006f0666 in AsyncJob::callEnd (this=0x133efa8) at
AsyncJob.cc:144
#18 0x00000000007f4732 in JobDialer<Adaptation::Initiator>::dial
(this=0x153f2f0, call=...) at ../../src/base/AsyncJobCalls.h:181
#19 0x00000000006ee331 in AsyncCall::make (this=0x153f2c0) at
AsyncCall.cc:40
#20 0x00000000006f26e5 in AsyncCallQueue::fireNext (this=this at entry=0xdc2c60)
at AsyncCallQueue.cc:56
#21 0x00000000006f2b09 in AsyncCallQueue::fire (this=0xdc2c60) at
AsyncCallQueue.cc:42
#22 0x000000000057def9 in EventLoop::dispatchCalls (this=0x7fffca605010) at
EventLoop.cc:143
#23 EventLoop::runOnce (this=this at entry=0x7fffca605010) at EventLoop.cc:120
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180312/a6b91685/attachment.htm>

From rousskov at measurement-factory.com  Tue Mar 13 04:32:06 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 12 Mar 2018 22:32:06 -0600
Subject: [squid-users] Exception with squid 3.5.25 in ICAP options path
In-Reply-To: <CABCok=Ldd18_8ScakfFuK3p9P1JW=UAbP_8wt3xf3yx7TtT6_A@mail.gmail.com>
References: <CABCok=Ldd18_8ScakfFuK3p9P1JW=UAbP_8wt3xf3yx7TtT6_A@mail.gmail.com>
Message-ID: <802bb000-e886-f204-ac74-1f69a0714088@measurement-factory.com>

On 03/12/2018 06:06 PM, Arunabha Saha wrote:
> Seeing a exception followed by termination fairly regularly with
> Squid-->Icap with this stacktrace on 3.5.25.? ?

Disclaimer: The technical discussion below is more suited for squid-dev
or at least Bugzilla, not squid-users.

Please note that this exception is thrown from a destructor. If your
build environment enables C++11 (which is common these days), such
exceptions will kill Squid. Many of those exceptions were less harmful
before C++11. While well-written destructors should not have thrown even
before C++11, these deaths is one of a few seriously non-backward
compatible changes in C++11. We have only understood this a few months
ago, or I would have insisted on not enabling C++11 in v3, even
conditionally...

Modern Squids do a better job _reporting_ such deadly exceptions and a
couple of destructors have been fixed, but we have not gone through all
the relevant destructors to fix them because it takes time to analyze
and handle this properly (i.e., it is not a trivial
wrap-everything-and-forget change).


> Appreciate it if someone can comment on whether this is known and fixed
> before i dig a little deeper.? ?

FWIW, I do not recall any fixes in that area.

Alex.


> #0? 0x00007ff944120428 in __GI_raise (sig=sig at entry=6) at
> ../sysdeps/unix/sysv/linux/raise.c:54
> #1? 0x00007ff94412202a in __GI_abort () at abort.c:89
> #2? 0x00007ff944a670d5 in __gnu_cxx::__verbose_terminate_handler() ()
> from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
> #3? 0x00007ff944a64cc6 in ?? () from
> /usr/lib/x86_64-linux-gnu/libstdc++.so.6
> #4? 0x00007ff944a63bc9 in ?? () from
> /usr/lib/x86_64-linux-gnu/libstdc++.so.6
> #5? 0x00007ff944a645b8 in __gxx_personality_v0 () from
> /usr/lib/x86_64-linux-gnu/libstdc++.so.6
> #6? 0x00007ff9444c4f03 in ?? () from /lib/x86_64-linux-gnu/libgcc_s.so.1
> #7? 0x00007ff9444c5410 in _Unwind_RaiseException () from
> /lib/x86_64-linux-gnu/libgcc_s.so.1
> #8? 0x00007ff944a64f47 in __cxa_throw () from
> /usr/lib/x86_64-linux-gnu/libstdc++.so.6
> #9? 0x00000000006f3486 in Throw (message=message at entry=0x8ae66e
> "!theOptionsFetcher", fileName=fileName at entry=0x8ae647 "ServiceRep.cc",
> lineNo=lineNo at entry=50,
> ? ? id=149798962) at TextException.cc:93
> #10 0x00000000008071f9 in Adaptation::Icap::ServiceRep::~ServiceRep
> (this=this at entry=0x1298b58, __in_chrg=<optimized out>,
> __vtt_parm=<optimized out>)
> ? ? at ServiceRep.cc:50
> #11 0x00000000008073c9 in Adaptation::Icap::ServiceRep::~ServiceRep
> (this=0x1298b58, __in_chrg=<optimized out>, __vtt_parm=<optimized out>)
> at ServiceRep.cc:52
> #12 0x000000000081d6c3 in RefCount<Adaptation::Service>::dereference
> (newP=0x0, this=0x133ef88) at ../../../src/base/RefCount.h:79
> #13 RefCount<Adaptation::Service>::~RefCount (this=0x133ef88,
> __in_chrg=<optimized out>) at ../../../src/base/RefCount.h:35
> #14 Adaptation::Icap::Launcher::~Launcher (this=0x133ef68,
> __vtt_parm=0xb5e208 <VTT for Adaptation::Icap::OptXactLauncher+8>,
> __in_chrg=<optimized out>)
> ? ? at Launcher.cc:32
> #15 0x0000000000830137 in
> Adaptation::Icap::OptXactLauncher::~OptXactLauncher (this=0x133ef68,
> __in_chrg=<optimized out>, __vtt_parm=<optimized out>)
> ? ? at ../../../src/adaptation/icap/OptXact.h:55
> #16 Adaptation::Icap::OptXactLauncher::~OptXactLauncher (this=0x133ef68,
> __in_chrg=<optimized out>, __vtt_parm=<optimized out>)
> ? ? at ../../../src/adaptation/icap/OptXact.h:55
> #17 0x00000000006f0666 in AsyncJob::callEnd (this=0x133efa8) at
> AsyncJob.cc:144
> #18 0x00000000007f4732 in JobDialer<Adaptation::Initiator>::dial
> (this=0x153f2f0, call=...) at ../../src/base/AsyncJobCalls.h:181
> #19 0x00000000006ee331 in AsyncCall::make (this=0x153f2c0) at
> AsyncCall.cc:40
> #20 0x00000000006f26e5 in AsyncCallQueue::fireNext
> (this=this at entry=0xdc2c60) at AsyncCallQueue.cc:56
> #21 0x00000000006f2b09 in AsyncCallQueue::fire (this=0xdc2c60) at
> AsyncCallQueue.cc:42
> #22 0x000000000057def9 in EventLoop::dispatchCalls (this=0x7fffca605010)
> at EventLoop.cc:143
> #23 EventLoop::runOnce (this=this at entry=0x7fffca605010) at EventLoop.cc:120


From bigal.nz at gmail.com  Tue Mar 13 07:37:07 2018
From: bigal.nz at gmail.com (Al Grant)
Date: Tue, 13 Mar 2018 20:37:07 +1300
Subject: [squid-users] Settings for Bank & Health
Message-ID: <CAODtcdegmuvQ1FFLzN=4m+w=qakK8viM25MYs1nZPh7GhuMLCQ@mail.gmail.com>

Hi,

I have been told it would be good practice to respect users privacy when it
comes to banking and health websites.

I am not sure whether this means not logging those websites, not caching
them or something else?

Can someone please elaborate, and perhaps how it would be achieved? I am
currently running a non transparent proxy with wpad.

Thanks

AG


-- 
"Beat it punk!"
- Clint Eastwood
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/db2fb994/attachment.htm>

From uhlar at fantomas.sk  Tue Mar 13 08:06:24 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 13 Mar 2018 09:06:24 +0100
Subject: [squid-users] Settings for Bank & Health
In-Reply-To: <CAODtcdegmuvQ1FFLzN=4m+w=qakK8viM25MYs1nZPh7GhuMLCQ@mail.gmail.com>
References: <CAODtcdegmuvQ1FFLzN=4m+w=qakK8viM25MYs1nZPh7GhuMLCQ@mail.gmail.com>
Message-ID: <20180313080624.GA11563@fantomas.sk>

On 13.03.18 20:37, Al Grant wrote:
>I have been told it would be good practice to respect users privacy when it
>comes to banking and health websites.

it's good practice respect users privacy when it comes to all websites.

>I am not sure whether this means not logging those websites, not caching
>them or something else?

in fact, both. However it's not a problem unless you bump SSL connections.
without it, you just see CONNECT requests in proxy logs, which doesn't
violate privacy.
(at least not much, you know where user connects but that's all).

in some countries you are obligated to save the logs for some time.

>Can someone please elaborate, and perhaps how it would be achieved? I am
>currently running a non transparent proxy with wpad.

Bumping SSL connections means decrypting the traffic and removing privacy.
(SSL is designed for end-to-end encryption and valication).

Bumping decrypts the connection, provide own certificates, and make own SSL
connection to the web sites.

Users will not see the green bar commonly seen at banking sites, coming from
extended validation certificate.

if you do ssl bumping, you must be very careful - because of both legal and
technical issues. 

If you don't, you should have no problem.
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Linux IS user friendly, it's just selective who its friends are...


From bigal.nz at gmail.com  Tue Mar 13 08:17:21 2018
From: bigal.nz at gmail.com (Al Grant)
Date: Tue, 13 Mar 2018 21:17:21 +1300
Subject: [squid-users] Settings for Bank & Health
In-Reply-To: <20180313080624.GA11563@fantomas.sk>
References: <CAODtcdegmuvQ1FFLzN=4m+w=qakK8viM25MYs1nZPh7GhuMLCQ@mail.gmail.com>
 <20180313080624.GA11563@fantomas.sk>
Message-ID: <CAODtcdfNKqyGQ8WF7fupFBjOw4H=pxBO075i4SacXeQk2erCbA@mail.gmail.com>

On Tue, Mar 13, 2018 at 9:06 PM, Matus UHLAR - fantomas <uhlar at fantomas.sk>
wrote:

> On 13.03.18 20:37, Al Grant wrote:
>
>> I have been told it would be good practice to respect users privacy when
>> it
>> comes to banking and health websites.
>>
>
> it's good practice respect users privacy when it comes to all websites.
>
> I am not sure whether this means not logging those websites, not caching
>> them or something else?
>>
>
> in fact, both. However it's not a problem unless you bump SSL connections.
> without it, you just see CONNECT requests in proxy logs, which doesn't
> violate privacy.
>
>
So would you see all the URLs for a given site in the logs?


> .
>>
>
> Bumping SSL connections means decrypting the traffic and removing privacy.
> (SSL is designed for end-to-end encryption and valication).
>
> Bumping decrypts the connection, provide own certificates, and make own SSL
> connection to the web sites.
>
> Users will not see the green bar commonly seen at banking sites, coming
> from
> extended validation certificate.
>
>
I don't see the need to go as far as filtering traffic based on content.
However I would like to be able to view the URLs visited.

Thanks for the explanation.

-- 
"Beat it punk!"
- Clint Eastwood
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/24c9efa8/attachment.htm>

From jmpatagonia at gmail.com  Tue Mar 13 10:33:52 2018
From: jmpatagonia at gmail.com (Juan Manuel P)
Date: Tue, 13 Mar 2018 07:33:52 -0300
Subject: [squid-users] TCP_MISS_ABORTED/000|
In-Reply-To: <42adbc2e-7211-ef7d-2702-59a3491af551@gmail.com>
References: <CADZCxsum3Kjq8OLdCfETtTW+Krfhtp9qpjGcCZtKEGYhfE5d1g@mail.gmail.com>
 <1cd01c76-5dc4-b743-c741-c0c06f58bf25@gmail.com>
 <CADZCxsssUjxNuckCJ5j4bZsgd8zSrYchWKrpOkpkgxkOQ9os0g@mail.gmail.com>
 <08f44e3e-dc16-1bfe-50ae-0df34d2c0716@gmail.com>
 <CADZCxstn8yHe5XyBq+J-Ob929y0AcFSGqTacX-yuAdPgwOBmqA@mail.gmail.com>
 <38c28f9a-80ed-5689-8e8f-7a1ccac1e2b9@gmail.com>
 <CADZCxssHwax8qk7_FBcPdd6W7ZfxeR_qSXQ074maKHwuBvnxXw@mail.gmail.com>
 <42adbc2e-7211-ef7d-2702-59a3491af551@gmail.com>
Message-ID: <CADZCxss=JoN1xSJ3hpdC1WHkgsDxfObhxV5N7KVVurNNRh7x3Q@mail.gmail.com>

Hello, I finally found the solution to the TCP_MISS_ABORTED/000 problem,
result that the network manager person, give me a tplink load balance
router with some filters setting inside them, he forgot that setting.
This setting are in the filters setting, setting some words like porno,
sex, and similar, we disable this and start working.

Regards.

PS: Analising the all thing, I suppose that the iptables firewall inside
the router are block or cutting my connections, because that filters are
settings.


2018-03-12 16:21 GMT-03:00 Yuri <yvoinov at gmail.com>:

> You can also play around with squid's config parameters to fit your LAN
> specifications.
>
> 13.03.2018 01:20, Juan Manuel P ?????:
>
> I found a solutions to problem  TCP_MISS_ABORTED/000, we have a balance
> router tplink betwen the squid proxy server and the ISP, just eliminate the
> balance router tplinkand the problem desapear , later I will investigate
> the balance router to found a final solution, and tell us.
>
> regards
>
> 2018-02-28 18:01 GMT-03:00 Yuri <yvoinov at gmail.com>:
>
>> Windows often spit on RFC due to do not disturb users. Squid is not.
>>
>> Anyway, as you can see, from my side, with well-configured infrastructure
>> and well-configured squid, is also no problem.
>>
>> So, may be, somebody's hands like legs.... ;-)
>>
>> 01.03.2018 02:59, Juan Manuel P ?????:
>>
>> We are migrating from a old proxy server kerio-win-route on windows to a
>> squid proxy server.
>> The old proxy server no have problems.
>>
>> regards.
>>
>>
>>
>> 2018-02-28 17:56 GMT-03:00 Yuri <yvoinov at gmail.com>:
>>
>>> Seems so. May be, ever ISP. Misconfigured MPLS can lead this errors.
>>>
>>> 01.03.2018 02:55, Juan Manuel P ?????:
>>>
>>> Hello Yuri today on access.log a get a lot off TCP_MISS_ABORTED/000 on
>>> many diferentes sites:
>>>
>>> 28/Feb/2018:13:50:00 -0300 || - || 10.15.43.31 || TCP_MISS_ABORTED/000||
>>> GET || http://loprincipal.com.ar/wp-content/plugins/wp-facebook-liv
>>> e-video/inc/style.css? || -
>>> 28/Feb/2018:13:50:00 -0300 || - || 10.15.43.31 || TCP_MISS_ABORTED/000||
>>> GET || http://loprincipal.com.ar/wp-content/plugins/wp-facebook-liv
>>> e-video/inc/script.js? || -
>>> 28/Feb/2018:13:53:37 -0300 || - || 10.15.43.31 || TCP_MISS_ABORTED/000||
>>> POST || http://m.addthis.com/live/red_lojson/100eng.json? || -
>>> 28/Feb/2018:13:54:09 -0300 || - || 10.15.43.31 || TCP_MISS_ABORTED/000||
>>> POST || http://m.addthis.com/live/red_lojson/100eng.json? || -
>>> 28/Feb/2018:14:04:19 -0300 || - || 10.14.43.147 ||
>>> TCP_MISS_ABORTED/000|| POST || http://m.addthis.com/live/red_
>>> lojson/100eng.json? || -
>>> 28/Feb/2018:14:04:19 -0300 || - || 10.14.43.147 ||
>>> TCP_MISS_ABORTED/000|| POST || http://m.addthis.com/live/red_
>>> lojson/100eng.json? || -
>>> 28/Feb/2018:14:07:56 -0300 || - || 10.14.43.88 || TCP_MISS_ABORTED/000||
>>> GET || http://ocsp2.globalsign.com/gsextendvalsha2g2/ME0wSzBJMEcwRT
>>> AJBgUrDgMCGgUABBRYCCQuHbjl0T2z%2Bv2quSEm8NK1fgQU2kB3Q2Uc%2BP
>>> 6n4%2FRkgj5NQxMiMQICDGPo4Vlu6pcIoIq7tA%3D%3D || -
>>> 28/Feb/2018:14:08:11 -0300 || - || 10.14.43.88 || TCP_MISS_ABORTED/000||
>>> GET || http://crl.globalsign.com/gs/gsextendvalsha2g2.crl || -
>>> 28/Feb/2018:14:11:56 -0300 || - || 10.15.43.30 || TCP_MISS_ABORTED/000||
>>> GET || http://ipv6.msftncsi.com/ncsi.txt || -
>>> 28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 ||
>>> TCP_MISS_ABORTED/000|| GET || http://www.bancopatagonia.com/
>>> comunes/imas/facebook.jpg || -
>>> 28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 ||
>>> TCP_MISS_ABORTED/000|| GET || http://www.bancopatagonia.com/
>>> comunes/imas/youtube.jpg || -
>>> 28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 ||
>>> TCP_MISS_ABORTED/000|| GET || http://www.bancopatagonia.com/
>>> personas/imas/dest_espectaculos.jpg || -
>>> 28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 ||
>>> TCP_MISS_ABORTED/000|| GET || http://www.bancopatagonia.com/
>>> comunes/imas/img_youtube.gif || -
>>> 28/Feb/2018:14:30:13 -0300 || - || 10.14.43.101 ||
>>> TCP_MISS_ABORTED/000|| GET || http://www.bancopatagonia.com/
>>> comunes/imas/facebook-pie.jpg || -
>>> 28/Feb/2018:15:13:48 -0300 || - || 10.14.43.162 ||
>>> TCP_MISS_ABORTED/000|| POST || http://ocsp.usertrust.com/ || -
>>> 28/Feb/2018:15:34:18 -0300 || - || 10.14.43.77 || TCP_MISS_ABORTED/000||
>>> GET || http://search.it.online.fr/covers/wp-content/Milo_Manara,_in
>>> _Giuseppe_Bergman,_2005_(Manet).jpg || -
>>> 28/Feb/2018:15:51:21 -0300 || - || 10.14.43.162 ||
>>> TCP_MISS_ABORTED/000|| GET || http://csi.gstatic.com/csi? || -
>>> 28/Feb/2018:15:51:22 -0300 || - || 10.14.43.162 ||
>>> TCP_MISS_ABORTED/404|| GET || http://www.snehashish.com/wp-c
>>> ontent/themes/computers/images/slide-left.png || text/html
>>> 28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 ||
>>> TCP_MISS_ABORTED/000|| GET || http://www.bancopatagonia.com.
>>> ar/personas/imas/dest_espectaculos.jpg || -
>>> 28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 ||
>>> TCP_MISS_ABORTED/000|| GET || http://www.bancopatagonia.com.
>>> ar/comunes/imas/facebook.jpg || -
>>> 28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 ||
>>> TCP_MISS_ABORTED/000|| GET || http://www.bancopatagonia.com.
>>> ar/comunes/imas/img_youtube.gif || -
>>> 28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 ||
>>> TCP_MISS_ABORTED/000|| GET || http://www.bancopatagonia.com.
>>> ar/comunes/imas/facebook-pie.jpg || -
>>> 28/Feb/2018:15:52:42 -0300 || - || 10.14.43.159 ||
>>> TCP_MISS_ABORTED/000|| GET || http://www.bancopatagonia.com.
>>> ar/comunes/imas/youtube.jpg || -
>>> 28/Feb/2018:16:18:53 -0300 || - || 192.168.43.57 ||
>>> TCP_MISS_ABORTED/000|| GET || http://loprincipal.com.ar/wp-c
>>> ontent/plugins/wp-facebook-live-video/inc/script.js? || -
>>> 28/Feb/2018:16:18:53 -0300 || - || 192.168.43.57 ||
>>> TCP_MISS_ABORTED/000|| GET || http://loprincipal.com.ar/wp-c
>>> ontent/plugins/wp-facebook-live-video/inc/style.css? || -
>>>
>>> I thinking the problem is not in squid, maybe DNS or something similar.
>>>
>>> regards.
>>>
>>>
>>> 2018-02-28 17:46 GMT-03:00 Yuri <yvoinov at gmail.com>:
>>>
>>>> Let's look on your server:
>>>>
>>>>  # wget -S http://rionegro.gov.ar/download/images/00033636.jpg
>>>> --2018-03-01 02:37:38--  http://rionegro.gov.ar/downloa
>>>> d/images/00033636.jpg
>>>> Connecting to 127.0.0.1:3128... connected.
>>>> Proxy request sent, awaiting response...
>>>>   HTTP/1.1 200 OK
>>>>   Date: Wed, 28 Feb 2018 19:38:03 GMT
>>>>   Server: Apache
>>>>   Last-Modified: Wed, 28 Feb 2018 16:07:15 GMT
>>>>   Accept-Ranges: bytes
>>>>   Content-Length: 135872
>>>>   Content-Type: image/jpeg
>>>>   Age: 979
>>>>   X-Cache: HIT from rn-speed-unifix
>>>>   X-Cache: MISS from khorne
>>>>   X-Cache-Lookup: MISS from khorne:3128
>>>>   Connection: keep-alive
>>>> Length: 135872 (133K) [image/jpeg]
>>>> Saving to: '00033636.jpg'
>>>>
>>>> 00033636.jpg        100%[===================>] 132.69K  2.79KB/s    in
>>>> 58s
>>>>
>>>> 2018-03-01 02:38:39 (2.29 KB/s) - '00033636.jpg' saved [135872/135872]
>>>>
>>>> All seems ok. A bit slow downloading - but ok.
>>>>
>>>> May be, this is your regional connectivity issues? For example,
>>>> slooooooooooow links, slooooooooooooow DNS, dropped packets, etc.?
>>>>
>>>> 01.03.2018 02:36, Juan Manuel P ?????:
>>>>
>>>>
>>>> Hello I send more data about the problem.
>>>>
>>>> The problem occur for example on this page (see below). But not occur
>>>> on the ssl/https version of the same page.
>>>>
>>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>> TCP_MISS_ABORTED/000|| GET || http://rionegro.gov.ar/media/c
>>>> omponents/youtubetv/ytv.css || -
>>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>> TCP_MISS_ABORTED/000|| GET || http://rionegro.gov.ar/media/c
>>>> omponents/youtubetv/principal.css || -
>>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>> TCP_MISS_ABORTED/000|| GET || http://rionegro.gov.ar/media/c
>>>> omponents/youtubetv/ytv.js || -
>>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>> TCP_MISS_ABORTED/000|| GET || http://rionegro.gov.ar/media/i
>>>> mages/disenio/ini_nav.png || -
>>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>> TCP_MISS_ABORTED/000|| GET || http://rionegro.gov.ar/downloa
>>>> d/images/00033645.jpg || -
>>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>> TCP_MISS_ABORTED/000|| GET || http://rionegro.gov.ar/downloa
>>>> d/images/00033644.jpg || -
>>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>> TCP_MEM_HIT_ABORTED/200|| GET || http://rionegro.gov.ar/downloa
>>>> d/banner/00002923.jpg || image/jpeg
>>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>> TCP_MISS_ABORTED/000|| GET || http://rionegro.gov.ar/media/i
>>>> mages/lema.png || -
>>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>> TCP_MISS_ABORTED/000|| GET || http://rionegro.gov.ar/media/i
>>>> mages/logomarcarn.png || -
>>>> 28/Feb/2018:17:19:00 -0300 || - || 10.12.43.20 ||
>>>> TCP_MISS_ABORTED/000|| GET || http://rionegro.gov.ar/downloa
>>>> d/images/00033636.jpg || -
>>>>
>>>>
>>>> And when the problem occur the page is waiting and slowly until upload
>>>> complete.
>>>>
>>>> Later the page upload whitout problem.
>>>>
>>>>
>>>> I see that the TCP_MISS_ABORTED appear only on some extension file,
>>>> css, js, png, jpg. When are waiting for page upload complete this elements
>>>> or componentes are not charged but the rest of the page yes. Some time
>>>> later all the page is upload.
>>>>
>>>> Regards.
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>>
>>>> --
>>>> *****************************
>>>> * C++20 : Bug to the future *
>>>> *****************************
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>> --
>>> *****************************
>>> * C++20 : Bug to the future *
>>> *****************************
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>
>>
>> _______________________________________________
>> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>>
>>
>> --
>> *****************************
>> * C++20 : Bug to the future *
>> *****************************
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
>
> _______________________________________________
> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>
>
> --
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/217323b2/attachment.htm>

From uhlar at fantomas.sk  Tue Mar 13 11:11:51 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 13 Mar 2018 12:11:51 +0100
Subject: [squid-users] Settings for Bank & Health
In-Reply-To: <CAODtcdfNKqyGQ8WF7fupFBjOw4H=pxBO075i4SacXeQk2erCbA@mail.gmail.com>
References: <CAODtcdegmuvQ1FFLzN=4m+w=qakK8viM25MYs1nZPh7GhuMLCQ@mail.gmail.com>
 <20180313080624.GA11563@fantomas.sk>
 <CAODtcdfNKqyGQ8WF7fupFBjOw4H=pxBO075i4SacXeQk2erCbA@mail.gmail.com>
Message-ID: <20180313111151.GA13460@fantomas.sk>

>> On 13.03.18 20:37, Al Grant wrote:
>>> I have been told it would be good practice to respect users privacy when
>>> it comes to banking and health websites.
>>> I am not sure whether this means not logging those websites, not caching
>>> them or something else?

>On Tue, Mar 13, 2018 at 9:06 PM, Matus UHLAR - fantomas <uhlar at fantomas.sk>
>wrote:
>> in fact, both. However it's not a problem unless you bump SSL connections.
>> without it, you just see CONNECT requests in proxy logs, which doesn't
>> violate privacy.

On 13.03.18 21:17, Al Grant wrote:
>So would you see all the URLs for a given site in the logs?

No. CONNECT only provides host/IP and port, nothing more.

>> Bumping SSL connections means decrypting the traffic and removing privacy.
>> (SSL is designed for end-to-end encryption and valication).
>>
>> Bumping decrypts the connection, provide own certificates, and make own SSL
>> connection to the web sites.
>>
>> Users will not see the green bar commonly seen at banking sites, coming
>> from
>> extended validation certificate.
>>
>>
>I don't see the need to go as far as filtering traffic based on content.
>However I would like to be able to view the URLs visited.

viewing URLs in HTTPS connections requires decrypting SSL.
decrypting SSL removes privacy and brings problems.
don't decrypt unless you really have to.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
"To Boot or not to Boot, that's the question." [WD1270 Caviar]


From tonyemiliano at gmail.com  Tue Mar 13 11:14:04 2018
From: tonyemiliano at gmail.com (Antonio Emiliano)
Date: Tue, 13 Mar 2018 08:14:04 -0300
Subject: [squid-users] Squid Transparent Proxy with Policy Routing in pfSense
Message-ID: <CAH9+-eB_FnWJLSjn=CbodCwvQ1Z--MN9ZeJ1c4m9e7Q4yVbd0w@mail.gmail.com>

Hi guys.

This is my last attempt before going to authenticated mode.

I searched all over the internet for a way to set up a "transparent squid"
but until then the most I can get is an exhausted timeout when I go to an
http.

My environment is as follows.

- Box squid 3.5.20
- pfSense as the default network gateway.
- Desktop Windows or linux.
- Only one network /24

I was able to make it work through this documentation:
https://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect

However this environment requires that the client has configured the
gateway ip address of the squid itself.

It works. But that's not what I want.

NOTE: NAT configuration will only work when used on the squid box. This is
required to perform intercept accurately and securely. To intercept from a
gateway machine and direct traffic at a separate squid box use policy
routing.

What I want is to make a rule in pfsense through policy routing, as it
speaks in the documentation. I've tried several ways, but every time I try
to access the http page it loads until the timeout expires.

In doc it does not explain directly how to do this rule in pfsense.

I tried through nat port forwarding and through rules in firewall setting
in the squid server rule as gateway. But both do not work.

I tried to take as base these two links,
https://wiki.squid-cache.org/ConfigExamples/Intercept/IptablesPolicyRoute
https://wiki.squid-cache.org/ConfigExamples/Intercept/PfPolicyRoute

No firewall block
It's some detail that's missing either in pfsense or squid.

Please give me a light.

Att,

Antonio Emiliano
LinkedIn: https://www.linkedin.com/in/antonioemiliano

"Corra, coelho.
 Cave um buraco, esque?a o sol,
 E quando o trabalho finalmente acabar
 N?o descanse, ? hora de cavar outro."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/7aea6304/attachment.htm>

From rafael.akchurin at diladele.com  Tue Mar 13 11:17:49 2018
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 13 Mar 2018 11:17:49 +0000
Subject: [squid-users] Squid Transparent Proxy with Policy Routing in
 pfSense
In-Reply-To: <CAH9+-eB_FnWJLSjn=CbodCwvQ1Z--MN9ZeJ1c4m9e7Q4yVbd0w@mail.gmail.com>
References: <CAH9+-eB_FnWJLSjn=CbodCwvQ1Z--MN9ZeJ1c4m9e7Q4yVbd0w@mail.gmail.com>
Message-ID: <AM4PR0401MB21949124DF4C0B71BAB3C3868FD20@AM4PR0401MB2194.eurprd04.prod.outlook.com>

Hello Antonio,

Sorry no pfsense tutorials for now, but these two are *proved* to be working just fine.

https://docs.diladele.com/tutorials/policy_based_routing_squid/index.html
https://docs.diladele.com/tutorials/mikrotik_transparent_squid/index.html

Hope it helps.

Best regards,
Rafael Akchurin
Diladele B.V.



From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Antonio Emiliano
Sent: Tuesday, March 13, 2018 12:14 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid Transparent Proxy with Policy Routing in pfSense

Hi guys.

This is my last attempt before going to authenticated mode.

I searched all over the internet for a way to set up a "transparent squid" but until then the most I can get is an exhausted timeout when I go to an http.

My environment is as follows.

- Box squid 3.5.20
- pfSense as the default network gateway.
- Desktop Windows or linux.
- Only one network /24

I was able to make it work through this documentation: https://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect

However this environment requires that the client has configured the gateway ip address of the squid itself.

It works. But that's not what I want.

NOTE: NAT configuration will only work when used on the squid box. This is required to perform intercept accurately and securely. To intercept from a gateway machine and direct traffic at a separate squid box use policy routing.

What I want is to make a rule in pfsense through policy routing, as it speaks in the documentation. I've tried several ways, but every time I try to access the http page it loads until the timeout expires.

In doc it does not explain directly how to do this rule in pfsense.

I tried through nat port forwarding and through rules in firewall setting in the squid server rule as gateway. But both do not work.

I tried to take as base these two links,
https://wiki.squid-cache.org/ConfigExamples/Intercept/IptablesPolicyRoute
https://wiki.squid-cache.org/ConfigExamples/Intercept/PfPolicyRoute

No firewall block
It's some detail that's missing either in pfsense or squid.

Please give me a light.

Att,

Antonio Emiliano
LinkedIn: https://www.linkedin.com/in/antonioemiliano

"Corra, coelho.
 Cave um buraco, esque?a o sol,
 E quando o trabalho finalmente acabar
 N?o descanse, ? hora de cavar outro."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/74f30eca/attachment.htm>

From danilovt at gmail.com  Tue Mar 13 13:44:59 2018
From: danilovt at gmail.com (Danilo V)
Date: Tue, 13 Mar 2018 13:44:59 +0000
Subject: [squid-users] SSL intercept in explicit mode
Message-ID: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>

Is it possible/feasible to configure squid in explicit mode with ssl
intercept?
Due to architecture of my network it is not possible to implement
transparent proxy.
What would be the behavior of applications that dont support proxy - i.e.
dont forward requests to proxy?
Any guides?

Danilo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/0e167b31/attachment.htm>

From uhlar at fantomas.sk  Tue Mar 13 14:10:32 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 13 Mar 2018 15:10:32 +0100
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
Message-ID: <20180313141032.GA27376@fantomas.sk>

On 13.03.18 13:44, Danilo V wrote:
>Is it possible/feasible to configure squid in explicit mode with ssl
>intercept?

explicit is not intercept, intercept is not explicit.

explicit is where browser is configured (manually or automatically via WPAD)
to use the proxy.

intercept is where network device forcifully redirects http/https connections
to the proxy.

maybe you mean SSL bump in explicit mode?

>Due to architecture of my network it is not possible to implement
>transparent proxy.

excuse me?
by "transparent" people mean what we usually call "intercept".

>What would be the behavior of applications that dont support proxy - i.e.
>dont forward requests to proxy?

they mest be intercepted.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Micro$oft random number generator: 0, 0, 0, 4.33e+67, 0, 0, 0...


From danilovt at gmail.com  Tue Mar 13 14:44:15 2018
From: danilovt at gmail.com (Danilo V)
Date: Tue, 13 Mar 2018 14:44:15 +0000
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <20180313141032.GA27376@fantomas.sk>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
Message-ID: <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>

I mean SSL bump in explicit mode.
So intercept is a essencial requirement for running SSL bump?

Em ter, 13 de mar de 2018 ?s 11:10, Matus UHLAR - fantomas <
uhlar at fantomas.sk> escreveu:

> On 13.03.18 13:44, Danilo V wrote:
> >Is it possible/feasible to configure squid in explicit mode with ssl
> >intercept?
>
> explicit is not intercept, intercept is not explicit.
>
> explicit is where browser is configured (manually or automatically via
> WPAD)
> to use the proxy.
>
> intercept is where network device forcifully redirects http/https
> connections
> to the proxy.
>
> maybe you mean SSL bump in explicit mode?
>
> >Due to architecture of my network it is not possible to implement
> >transparent proxy.
>
> excuse me?
> by "transparent" people mean what we usually call "intercept".
>
> >What would be the behavior of applications that dont support proxy - i.e.
> >dont forward requests to proxy?
>
> they mest be intercepted.
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> Micro$oft random number generator: 0, 0, 0, 4.33e+67, 0, 0, 0...
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/8759eee9/attachment.htm>

From marcus.kool at urlfilterdb.com  Tue Mar 13 15:14:27 2018
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 13 Mar 2018 12:14:27 -0300
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
Message-ID: <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>

"SSL bump" is the name of a complex Squid feature.
With ssl_bump ACLs one can decide which domains can be 'spliced' (go through the proxy untouched) or can be 'bumped' (decrypted).

Interception is not a requirement for SSL bump.

Marcus

On 13/03/18 11:44, Danilo V wrote:
> I mean SSL bump in explicit mode.
> So intercept is a essencial requirement for running SSL bump?
> 
> Em ter, 13 de mar de 2018 ?s 11:10, Matus UHLAR - fantomas <uhlar at fantomas.sk <mailto:uhlar at fantomas.sk>> escreveu:
> 
>     On 13.03.18 13:44, Danilo V wrote:
>      >Is it possible/feasible to configure squid in explicit mode with ssl
>      >intercept?
> 
>     explicit is not intercept, intercept is not explicit.
> 
>     explicit is where browser is configured (manually or automatically via WPAD)
>     to use the proxy.
> 
>     intercept is where network device forcifully redirects http/https connections
>     to the proxy.
> 
>     maybe you mean SSL bump in explicit mode?
> 
>      >Due to architecture of my network it is not possible to implement
>      >transparent proxy.
> 
>     excuse me?
>     by "transparent" people mean what we usually call "intercept".
> 
>      >What would be the behavior of applications that dont support proxy - i.e.
>      >dont forward requests to proxy?
> 
>     they mest be intercepted.
> 
>     --
>     Matus UHLAR - fantomas, uhlar at fantomas.sk <mailto:uhlar at fantomas.sk> ; http://www.fantomas.sk/
>     Warning: I wish NOT to receive e-mail advertising to this address.
>     Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
>     Micro$oft random number generator: 0, 0, 0, 4.33e+67, 0, 0, 0...
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 


From yvoinov at gmail.com  Tue Mar 13 16:10:13 2018
From: yvoinov at gmail.com (Yuri)
Date: Tue, 13 Mar 2018 22:10:13 +0600
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
Message-ID: <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>

Moreover,

SSL Bump combines with interception/explicit proxy in one setup.

And works perfectly.


13.03.2018 21:14, Marcus Kool ?????:
> "SSL bump" is the name of a complex Squid feature.
> With ssl_bump ACLs one can decide which domains can be 'spliced' (go
> through the proxy untouched) or can be 'bumped' (decrypted).
>
> Interception is not a requirement for SSL bump.
>
> Marcus
>
> On 13/03/18 11:44, Danilo V wrote:
>> I mean SSL bump in explicit mode.
>> So intercept is a essencial requirement for running SSL bump?
>>
>> Em ter, 13 de mar de 2018 ?s 11:10, Matus UHLAR - fantomas
>> <uhlar at fantomas.sk <mailto:uhlar at fantomas.sk>> escreveu:
>>
>> ??? On 13.03.18 13:44, Danilo V wrote:
>> ???? >Is it possible/feasible to configure squid in explicit mode
>> with ssl
>> ???? >intercept?
>>
>> ??? explicit is not intercept, intercept is not explicit.
>>
>> ??? explicit is where browser is configured (manually or
>> automatically via WPAD)
>> ??? to use the proxy.
>>
>> ??? intercept is where network device forcifully redirects http/https
>> connections
>> ??? to the proxy.
>>
>> ??? maybe you mean SSL bump in explicit mode?
>>
>> ???? >Due to architecture of my network it is not possible to implement
>> ???? >transparent proxy.
>>
>> ??? excuse me?
>> ??? by "transparent" people mean what we usually call "intercept".
>>
>> ???? >What would be the behavior of applications that dont support
>> proxy - i.e.
>> ???? >dont forward requests to proxy?
>>
>> ??? they mest be intercepted.
>>
>> ??? --
>> ??? Matus UHLAR - fantomas, uhlar at fantomas.sk
>> <mailto:uhlar at fantomas.sk> ; http://www.fantomas.sk/
>> ??? Warning: I wish NOT to receive e-mail advertising to this address.
>> ??? Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
>> ??? Micro$oft random number generator: 0, 0, 0, 4.33e+67, 0, 0, 0...
>> ??? _______________________________________________
>> ??? squid-users mailing list
>> ??? squid-users at lists.squid-cache.org
>> <mailto:squid-users at lists.squid-cache.org>
>> ??? http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/bd141496/attachment.sig>

From synfinatic at gmail.com  Tue Mar 13 16:25:43 2018
From: synfinatic at gmail.com (Aaron Turner)
Date: Tue, 13 Mar 2018 09:25:43 -0700
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
 <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
Message-ID: <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>

What version are you using Yuri?  Can you share your config?
Everytime I use ssl bump, I have massive memory leaks.  It's been
effectively unusable for me.
--
Aaron Turner
https://synfin.net/         Twitter: @synfinatic
My father once told me that respect for the truth comes close to being
the basis for all morality.  "Something cannot emerge from nothing,"
he said.  This is profound thinking if you understand how unstable
"the truth" can be.  -- Frank Herbert, Dune


On Tue, Mar 13, 2018 at 9:10 AM, Yuri <yvoinov at gmail.com> wrote:
> Moreover,
>
> SSL Bump combines with interception/explicit proxy in one setup.
>
> And works perfectly.
>
>
> 13.03.2018 21:14, Marcus Kool ?????:
>> "SSL bump" is the name of a complex Squid feature.
>> With ssl_bump ACLs one can decide which domains can be 'spliced' (go
>> through the proxy untouched) or can be 'bumped' (decrypted).
>>
>> Interception is not a requirement for SSL bump.
>>
>> Marcus
>>
>> On 13/03/18 11:44, Danilo V wrote:
>>> I mean SSL bump in explicit mode.
>>> So intercept is a essencial requirement for running SSL bump?
>>>
>>> Em ter, 13 de mar de 2018 ?s 11:10, Matus UHLAR - fantomas
>>> <uhlar at fantomas.sk <mailto:uhlar at fantomas.sk>> escreveu:
>>>
>>>     On 13.03.18 13:44, Danilo V wrote:
>>>      >Is it possible/feasible to configure squid in explicit mode
>>> with ssl
>>>      >intercept?
>>>
>>>     explicit is not intercept, intercept is not explicit.
>>>
>>>     explicit is where browser is configured (manually or
>>> automatically via WPAD)
>>>     to use the proxy.
>>>
>>>     intercept is where network device forcifully redirects http/https
>>> connections
>>>     to the proxy.
>>>
>>>     maybe you mean SSL bump in explicit mode?
>>>
>>>      >Due to architecture of my network it is not possible to implement
>>>      >transparent proxy.
>>>
>>>     excuse me?
>>>     by "transparent" people mean what we usually call "intercept".
>>>
>>>      >What would be the behavior of applications that dont support
>>> proxy - i.e.
>>>      >dont forward requests to proxy?
>>>
>>>     they mest be intercepted.
>>>
>>>     --
>>>     Matus UHLAR - fantomas, uhlar at fantomas.sk
>>> <mailto:uhlar at fantomas.sk> ; http://www.fantomas.sk/
>>>     Warning: I wish NOT to receive e-mail advertising to this address.
>>>     Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
>>>     Micro$oft random number generator: 0, 0, 0, 4.33e+67, 0, 0, 0...
>>>     _______________________________________________
>>>     squid-users mailing list
>>>     squid-users at lists.squid-cache.org
>>> <mailto:squid-users at lists.squid-cache.org>
>>>     http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> --
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From eduardoocarneiro at gmail.com  Tue Mar 13 16:46:20 2018
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Tue, 13 Mar 2018 09:46:20 -0700 (MST)
Subject: [squid-users] ACL in custom error page
Message-ID: <1520959580472-0.post@n4.nabble.com>

Hello everyone!

Is there any way to display, in my custom error pages, the acl that denied
access?


Eduardo Carneiro



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From yvoinov at gmail.com  Tue Mar 13 16:47:30 2018
From: yvoinov at gmail.com (Yuri)
Date: Tue, 13 Mar 2018 22:47:30 +0600
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
 <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
 <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>
Message-ID: <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>

I've used it on all versions starting from 3.4.

Now I'm using Squid 5.0.0.

I'm afraid, my config is completely useless, because of it contains tons
of optimizations/tweaks/tricks and designed for customized Squid 5.0.0,
with different memory allocator for custom infrastructure.

You can't just take my config, implement it and hope it will give same
results for you.

At least, it uses non-system CA bundle, platform-specific configuration
parameters combinations, etc.

I can say, than SSL Bump is not directly related to memory leaks. Squid
itself almost not contains memory leaks now. Usually misconfiguration
leads to memory overhead.

As a recommendation, I can give some advices.

1. Use server with enough RAM. 4 Gb usually enough just for default
squid configuration. Usually whole system RAM usage should never be
bigger than 1/2 of overall physical RAM. (I.e. at least 1/3 of RAM
should always be free during normal running. This prevents OS allocator
pressure to your proxy and, also, increasing performance of proxy). In
case of medium proxy server 16 Gb of RAM seems big enough, but never try
to fill it up completely.

2. Don't set giant cache_mem. Remember how you platform allocates whole
RAM - kernel, anon pages, fs caches, etc. - and use reasonable squid's
memory-related settings.

3. Use sslflags=NO_DEFAULT_CA with your SSL Bump ports.

4. Never remember - SSL Bump increases your cache memory pressure due to
increasing caching. So, you still require to have enough memory in your
system.


13.03.2018 22:25, Aaron Turner ?????:
> What version are you using Yuri?  Can you share your config?
> Everytime I use ssl bump, I have massive memory leaks.  It's been
> effectively unusable for me.
> --
> Aaron Turner
> https://synfin.net/         Twitter: @synfinatic
> My father once told me that respect for the truth comes close to being
> the basis for all morality.  "Something cannot emerge from nothing,"
> he said.  This is profound thinking if you understand how unstable
> "the truth" can be.  -- Frank Herbert, Dune
>
>
> On Tue, Mar 13, 2018 at 9:10 AM, Yuri <yvoinov at gmail.com> wrote:
>> Moreover,
>>
>> SSL Bump combines with interception/explicit proxy in one setup.
>>
>> And works perfectly.
>>
>>
>> 13.03.2018 21:14, Marcus Kool ?????:
>>> "SSL bump" is the name of a complex Squid feature.
>>> With ssl_bump ACLs one can decide which domains can be 'spliced' (go
>>> through the proxy untouched) or can be 'bumped' (decrypted).
>>>
>>> Interception is not a requirement for SSL bump.
>>>
>>> Marcus
>>>
>>> On 13/03/18 11:44, Danilo V wrote:
>>>> I mean SSL bump in explicit mode.
>>>> So intercept is a essencial requirement for running SSL bump?
>>>>
>>>> Em ter, 13 de mar de 2018 ?s 11:10, Matus UHLAR - fantomas
>>>> <uhlar at fantomas.sk <mailto:uhlar at fantomas.sk>> escreveu:
>>>>
>>>>     On 13.03.18 13:44, Danilo V wrote:
>>>>      >Is it possible/feasible to configure squid in explicit mode
>>>> with ssl
>>>>      >intercept?
>>>>
>>>>     explicit is not intercept, intercept is not explicit.
>>>>
>>>>     explicit is where browser is configured (manually or
>>>> automatically via WPAD)
>>>>     to use the proxy.
>>>>
>>>>     intercept is where network device forcifully redirects http/https
>>>> connections
>>>>     to the proxy.
>>>>
>>>>     maybe you mean SSL bump in explicit mode?
>>>>
>>>>      >Due to architecture of my network it is not possible to implement
>>>>      >transparent proxy.
>>>>
>>>>     excuse me?
>>>>     by "transparent" people mean what we usually call "intercept".
>>>>
>>>>      >What would be the behavior of applications that dont support
>>>> proxy - i.e.
>>>>      >dont forward requests to proxy?
>>>>
>>>>     they mest be intercepted.
>>>>
>>>>     --
>>>>     Matus UHLAR - fantomas, uhlar at fantomas.sk
>>>> <mailto:uhlar at fantomas.sk> ; http://www.fantomas.sk/
>>>>     Warning: I wish NOT to receive e-mail advertising to this address.
>>>>     Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
>>>>     Micro$oft random number generator: 0, 0, 0, 4.33e+67, 0, 0, 0...
>>>>     _______________________________________________
>>>>     squid-users mailing list
>>>>     squid-users at lists.squid-cache.org
>>>> <mailto:squid-users at lists.squid-cache.org>
>>>>     http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> --
>> "C++ seems like a language suitable for firing other people's legs."
>>
>> *****************************
>> * C++20 : Bug to the future *
>> *****************************
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/e9c558f1/attachment.sig>

From synfinatic at gmail.com  Tue Mar 13 17:00:31 2018
From: synfinatic at gmail.com (Aaron Turner)
Date: Tue, 13 Mar 2018 10:00:31 -0700
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
 <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
 <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>
 <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>
Message-ID: <CANAZdzUsamD-_P2gB9oQEbjR=Y0XEK0mnKUdYgjXtRGAxnPQUQ@mail.gmail.com>

"Usually misconfiguration leads to memory overhead."

This may be true, but if you look in the list archives a few months
ago I basically chased my tail in circles and nobody could tell me
what I was doing wrong and so many of the docs are so old that they're
worse then useless, they seem to suggest the wrong thing.

It was literally leaking GB's worth of RAM.  I even disabled all
caching and process sizes were growing into the GB's.  Turn off
ssl-bump and the leak went away.

This is what I was using:

http_port 10.0.0.1:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=400MB cert=/etc/squid/ssl_cert/myCA.pem
sslflags=NO_DEFAULT_CA
http_port localhost:3128
ssl_bump bump all

sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB
sslcrtd_children 32 startup=2 idle=2
sslproxy_session_cache_size 100 MB
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER

This was on a machine (EC2 VM) with 14GB of RAM.

--
Aaron Turner
https://synfin.net/         Twitter: @synfinatic
My father once told me that respect for the truth comes close to being
the basis for all morality.  "Something cannot emerge from nothing,"
he said.  This is profound thinking if you understand how unstable
"the truth" can be.  -- Frank Herbert, Dune


On Tue, Mar 13, 2018 at 9:47 AM, Yuri <yvoinov at gmail.com> wrote:
> I've used it on all versions starting from 3.4.
>
> Now I'm using Squid 5.0.0.
>
> I'm afraid, my config is completely useless, because of it contains tons
> of optimizations/tweaks/tricks and designed for customized Squid 5.0.0,
> with different memory allocator for custom infrastructure.
>
> You can't just take my config, implement it and hope it will give same
> results for you.
>
> At least, it uses non-system CA bundle, platform-specific configuration
> parameters combinations, etc.
>
> I can say, than SSL Bump is not directly related to memory leaks. Squid
> itself almost not contains memory leaks now. Usually misconfiguration
> leads to memory overhead.
>
> As a recommendation, I can give some advices.
>
> 1. Use server with enough RAM. 4 Gb usually enough just for default
> squid configuration. Usually whole system RAM usage should never be
> bigger than 1/2 of overall physical RAM. (I.e. at least 1/3 of RAM
> should always be free during normal running. This prevents OS allocator
> pressure to your proxy and, also, increasing performance of proxy). In
> case of medium proxy server 16 Gb of RAM seems big enough, but never try
> to fill it up completely.
>
> 2. Don't set giant cache_mem. Remember how you platform allocates whole
> RAM - kernel, anon pages, fs caches, etc. - and use reasonable squid's
> memory-related settings.
>
> 3. Use sslflags=NO_DEFAULT_CA with your SSL Bump ports.
>
> 4. Never remember - SSL Bump increases your cache memory pressure due to
> increasing caching. So, you still require to have enough memory in your
> system.
>
>
> 13.03.2018 22:25, Aaron Turner ?????:
>> What version are you using Yuri?  Can you share your config?
>> Everytime I use ssl bump, I have massive memory leaks.  It's been
>> effectively unusable for me.
>> --
>> Aaron Turner
>> https://synfin.net/         Twitter: @synfinatic
>> My father once told me that respect for the truth comes close to being
>> the basis for all morality.  "Something cannot emerge from nothing,"
>> he said.  This is profound thinking if you understand how unstable
>> "the truth" can be.  -- Frank Herbert, Dune
>>
>>
>> On Tue, Mar 13, 2018 at 9:10 AM, Yuri <yvoinov at gmail.com> wrote:
>>> Moreover,
>>>
>>> SSL Bump combines with interception/explicit proxy in one setup.
>>>
>>> And works perfectly.
>>>
>>>
>>> 13.03.2018 21:14, Marcus Kool ?????:
>>>> "SSL bump" is the name of a complex Squid feature.
>>>> With ssl_bump ACLs one can decide which domains can be 'spliced' (go
>>>> through the proxy untouched) or can be 'bumped' (decrypted).
>>>>
>>>> Interception is not a requirement for SSL bump.
>>>>
>>>> Marcus
>>>>
>>>> On 13/03/18 11:44, Danilo V wrote:
>>>>> I mean SSL bump in explicit mode.
>>>>> So intercept is a essencial requirement for running SSL bump?
>>>>>
>>>>> Em ter, 13 de mar de 2018 ?s 11:10, Matus UHLAR - fantomas
>>>>> <uhlar at fantomas.sk <mailto:uhlar at fantomas.sk>> escreveu:
>>>>>
>>>>>     On 13.03.18 13:44, Danilo V wrote:
>>>>>      >Is it possible/feasible to configure squid in explicit mode
>>>>> with ssl
>>>>>      >intercept?
>>>>>
>>>>>     explicit is not intercept, intercept is not explicit.
>>>>>
>>>>>     explicit is where browser is configured (manually or
>>>>> automatically via WPAD)
>>>>>     to use the proxy.
>>>>>
>>>>>     intercept is where network device forcifully redirects http/https
>>>>> connections
>>>>>     to the proxy.
>>>>>
>>>>>     maybe you mean SSL bump in explicit mode?
>>>>>
>>>>>      >Due to architecture of my network it is not possible to implement
>>>>>      >transparent proxy.
>>>>>
>>>>>     excuse me?
>>>>>     by "transparent" people mean what we usually call "intercept".
>>>>>
>>>>>      >What would be the behavior of applications that dont support
>>>>> proxy - i.e.
>>>>>      >dont forward requests to proxy?
>>>>>
>>>>>     they mest be intercepted.
>>>>>
>>>>>     --
>>>>>     Matus UHLAR - fantomas, uhlar at fantomas.sk
>>>>> <mailto:uhlar at fantomas.sk> ; http://www.fantomas.sk/
>>>>>     Warning: I wish NOT to receive e-mail advertising to this address.
>>>>>     Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
>>>>>     Micro$oft random number generator: 0, 0, 0, 4.33e+67, 0, 0, 0...
>>>>>     _______________________________________________
>>>>>     squid-users mailing list
>>>>>     squid-users at lists.squid-cache.org
>>>>> <mailto:squid-users at lists.squid-cache.org>
>>>>>     http://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>> --
>>> "C++ seems like a language suitable for firing other people's legs."
>>>
>>> *****************************
>>> * C++20 : Bug to the future *
>>> *****************************
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>
> --
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************
>
>


From yvoinov at gmail.com  Tue Mar 13 17:44:41 2018
From: yvoinov at gmail.com (Yuri)
Date: Tue, 13 Mar 2018 23:44:41 +0600
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <CANAZdzUsamD-_P2gB9oQEbjR=Y0XEK0mnKUdYgjXtRGAxnPQUQ@mail.gmail.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
 <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
 <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>
 <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>
 <CANAZdzUsamD-_P2gB9oQEbjR=Y0XEK0mnKUdYgjXtRGAxnPQUQ@mail.gmail.com>
Message-ID: <f6a85fc5-50a3-9372-b487-72d8d42122fe@gmail.com>

AFAIK,

SSL bump subsystem uses OpenSSL memory routines. So, first of all, most
probably leaks (if any) can be OpenSSL-related, but not squid itself.

Now let's see your config snippets.

13.03.2018 23:00, Aaron Turner ?????:
> "Usually misconfiguration leads to memory overhead."
>
> This may be true, but if you look in the list archives a few months
> ago I basically chased my tail in circles and nobody could tell me
> what I was doing wrong and so many of the docs are so old that they're
> worse then useless, they seem to suggest the wrong thing.
>
> It was literally leaking GB's worth of RAM.  I even disabled all
> caching and process sizes were growing into the GB's.  Turn off
> ssl-bump and the leak went away.
>
> This is what I was using:
>
> http_port 10.0.0.1:3128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=400MB cert=/etc/squid/ssl_cert/myCA.pem
> sslflags=NO_DEFAULT_CA
> http_port localhost:3128
> ssl_bump bump all
bump all is useless without peek/splice.

Let's see on my config snippets:

https_port 3127 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=10MB cert=/usr/local/squid/etc/rootCA2.crt
key=/usr/local/squid/etc/rootCA2.key
tls-cafile=/usr/local/squid/etc/rootCA12.crt
options=SINGLE_DH_USE:SINGLE_ECDH_USE
tls-dh=secp384r1:/usr/local/squid/etc/dhparam.pem
cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
tls-no-npn sslflags=NO_DEFAULT_CA:VERIFY_CRL_ALL
http_port 3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=10MB cert=/usr/local/squid/etc/rootCA2.crt
key=/usr/local/squid/etc/rootCA2.key
tls-cafile=/usr/local/squid/etc/rootCA12.crt
options=SINGLE_DH_USE:SINGLE_ECDH_USE
tls-dh=secp384r1:/usr/local/squid/etc/dhparam.pem
cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
tls-no-npn sslflags=NO_DEFAULT_CA:VERIFY_CRL_ALL
tls_outgoing_options cafile=/usr/local/squid/etc/ca-bundle.crt
cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
# Cert database on ramdisk
sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
/ramdisk1/ssl_db -M 1GB
sslcrtd_children 32 startup=10 idle=5

# SSL bump rules
acl DiscoverSNIHost at_step SslBump1
acl NoSSLIntercept ssl::server_name_regex
"/usr/local/squid/etc/acl.url.nobump"
ssl_bump peek DiscoverSNIHost
ssl_bump splice NoSSLIntercept
ssl_bump bump all

>
> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB
> sslcrtd_children 32 startup=2 idle=2
This is defaults. Pay attention, -M is limits use ssl_db directory to 4
Mb in size. It's too few for production servers. My ramdisk for ssl db
is 1+ Gb in size:

/dev/ramdisk/ramdisk1?????????? 961M?? 14M? 890M?? 2% /ramdisk1/ssl_db

> sslproxy_session_cache_size 100 MB
This is disbalanced size instead of previous setting. Why so big?

#? TAG: sslproxy_session_cache_size
#??????? Sets the cache size to use for ssl session
#Default:
# sslproxy_session_cache_size 2 MB

> sslproxy_cert_error allow all
> sslproxy_flags DONT_VERIFY_PEER
*NEVER use this options. It is unsafe.

SSL Bump is dangerous enough itself. Don't do it more unsafe
additionally by yourself.
*
>
> This was on a machine (EC2 VM) with 14GB of RAM.
Pay attention on several places:

1. OS memory allocator.
2. OpenSSL version.
3. OS configuration (IPC, shared memory, swap - all memory related).
4. Squid's memory/pools configuration.

Don't forget about: Often memory fragmentation seems like leaks. But no
leaks occurs indeed.

Also, don't forget - squid's memory consumption is not only cache_mem,
but also caching on-disk metadata (swap.state), pools settings, working
memory areas, processes memory. And - also - such things like content
adaptation (did you know wide uses ecap gzip adapter is leaky itself?).

But this is just for example.

In any case, dig to the OpenSSL/OS side. Squid's memory in most cases is ok.

I know, this appears SSL Bump is leaky. But this is not correct.
>
> --
> Aaron Turner
> https://synfin.net/         Twitter: @synfinatic
> My father once told me that respect for the truth comes close to being
> the basis for all morality.  "Something cannot emerge from nothing,"
> he said.  This is profound thinking if you understand how unstable
> "the truth" can be.  -- Frank Herbert, Dune
>
>
> On Tue, Mar 13, 2018 at 9:47 AM, Yuri <yvoinov at gmail.com> wrote:
>> I've used it on all versions starting from 3.4.
>>
>> Now I'm using Squid 5.0.0.
>>
>> I'm afraid, my config is completely useless, because of it contains tons
>> of optimizations/tweaks/tricks and designed for customized Squid 5.0.0,
>> with different memory allocator for custom infrastructure.
>>
>> You can't just take my config, implement it and hope it will give same
>> results for you.
>>
>> At least, it uses non-system CA bundle, platform-specific configuration
>> parameters combinations, etc.
>>
>> I can say, than SSL Bump is not directly related to memory leaks. Squid
>> itself almost not contains memory leaks now. Usually misconfiguration
>> leads to memory overhead.
>>
>> As a recommendation, I can give some advices.
>>
>> 1. Use server with enough RAM. 4 Gb usually enough just for default
>> squid configuration. Usually whole system RAM usage should never be
>> bigger than 1/2 of overall physical RAM. (I.e. at least 1/3 of RAM
>> should always be free during normal running. This prevents OS allocator
>> pressure to your proxy and, also, increasing performance of proxy). In
>> case of medium proxy server 16 Gb of RAM seems big enough, but never try
>> to fill it up completely.
>>
>> 2. Don't set giant cache_mem. Remember how you platform allocates whole
>> RAM - kernel, anon pages, fs caches, etc. - and use reasonable squid's
>> memory-related settings.
>>
>> 3. Use sslflags=NO_DEFAULT_CA with your SSL Bump ports.
>>
>> 4. Never remember - SSL Bump increases your cache memory pressure due to
>> increasing caching. So, you still require to have enough memory in your
>> system.
>>
>>
>> 13.03.2018 22:25, Aaron Turner ?????:
>>> What version are you using Yuri?  Can you share your config?
>>> Everytime I use ssl bump, I have massive memory leaks.  It's been
>>> effectively unusable for me.
>>> --
>>> Aaron Turner
>>> https://synfin.net/         Twitter: @synfinatic
>>> My father once told me that respect for the truth comes close to being
>>> the basis for all morality.  "Something cannot emerge from nothing,"
>>> he said.  This is profound thinking if you understand how unstable
>>> "the truth" can be.  -- Frank Herbert, Dune
>>>
>>>
>>> On Tue, Mar 13, 2018 at 9:10 AM, Yuri <yvoinov at gmail.com> wrote:
>>>> Moreover,
>>>>
>>>> SSL Bump combines with interception/explicit proxy in one setup.
>>>>
>>>> And works perfectly.
>>>>
>>>>
>>>> 13.03.2018 21:14, Marcus Kool ?????:
>>>>> "SSL bump" is the name of a complex Squid feature.
>>>>> With ssl_bump ACLs one can decide which domains can be 'spliced' (go
>>>>> through the proxy untouched) or can be 'bumped' (decrypted).
>>>>>
>>>>> Interception is not a requirement for SSL bump.
>>>>>
>>>>> Marcus
>>>>>
>>>>> On 13/03/18 11:44, Danilo V wrote:
>>>>>> I mean SSL bump in explicit mode.
>>>>>> So intercept is a essencial requirement for running SSL bump?
>>>>>>
>>>>>> Em ter, 13 de mar de 2018 ?s 11:10, Matus UHLAR - fantomas
>>>>>> <uhlar at fantomas.sk <mailto:uhlar at fantomas.sk>> escreveu:
>>>>>>
>>>>>>     On 13.03.18 13:44, Danilo V wrote:
>>>>>>      >Is it possible/feasible to configure squid in explicit mode
>>>>>> with ssl
>>>>>>      >intercept?
>>>>>>
>>>>>>     explicit is not intercept, intercept is not explicit.
>>>>>>
>>>>>>     explicit is where browser is configured (manually or
>>>>>> automatically via WPAD)
>>>>>>     to use the proxy.
>>>>>>
>>>>>>     intercept is where network device forcifully redirects http/https
>>>>>> connections
>>>>>>     to the proxy.
>>>>>>
>>>>>>     maybe you mean SSL bump in explicit mode?
>>>>>>
>>>>>>      >Due to architecture of my network it is not possible to implement
>>>>>>      >transparent proxy.
>>>>>>
>>>>>>     excuse me?
>>>>>>     by "transparent" people mean what we usually call "intercept".
>>>>>>
>>>>>>      >What would be the behavior of applications that dont support
>>>>>> proxy - i.e.
>>>>>>      >dont forward requests to proxy?
>>>>>>
>>>>>>     they mest be intercepted.
>>>>>>
>>>>>>     --
>>>>>>     Matus UHLAR - fantomas, uhlar at fantomas.sk
>>>>>> <mailto:uhlar at fantomas.sk> ; http://www.fantomas.sk/
>>>>>>     Warning: I wish NOT to receive e-mail advertising to this address.
>>>>>>     Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
>>>>>>     Micro$oft random number generator: 0, 0, 0, 4.33e+67, 0, 0, 0...
>>>>>>     _______________________________________________
>>>>>>     squid-users mailing list
>>>>>>     squid-users at lists.squid-cache.org
>>>>>> <mailto:squid-users at lists.squid-cache.org>
>>>>>>     http://lists.squid-cache.org/listinfo/squid-users
>>>>>>
>>>>>>
>>>>>>
>>>>>> _______________________________________________
>>>>>> squid-users mailing list
>>>>>> squid-users at lists.squid-cache.org
>>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>>
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>> --
>>>> "C++ seems like a language suitable for firing other people's legs."
>>>>
>>>> *****************************
>>>> * C++20 : Bug to the future *
>>>> *****************************
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>
>> --
>> "C++ seems like a language suitable for firing other people's legs."
>>
>> *****************************
>> * C++20 : Bug to the future *
>> *****************************
>>
>>

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/d0312fc9/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/d0312fc9/attachment.sig>

From yvoinov at gmail.com  Tue Mar 13 17:50:38 2018
From: yvoinov at gmail.com (Yuri)
Date: Tue, 13 Mar 2018 23:50:38 +0600
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <f6a85fc5-50a3-9372-b487-72d8d42122fe@gmail.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
 <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
 <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>
 <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>
 <CANAZdzUsamD-_P2gB9oQEbjR=Y0XEK0mnKUdYgjXtRGAxnPQUQ@mail.gmail.com>
 <f6a85fc5-50a3-9372-b487-72d8d42122fe@gmail.com>
Message-ID: <d1b8b646-bd5d-067b-3df1-491cac826943@gmail.com>

FInally,

just take a look:

This is SSL Bump-aware setup. Seems no memory leaks, yes? Normal memory
distribution.

Let's see on overall OS memory:

No leaks.

13.03.2018 23:44, Yuri ?????:
>
> AFAIK,
>
> SSL bump subsystem uses OpenSSL memory routines. So, first of all,
> most probably leaks (if any) can be OpenSSL-related, but not squid itself.
>
> Now let's see your config snippets.
>
> 13.03.2018 23:00, Aaron Turner ?????:
>> "Usually misconfiguration leads to memory overhead."
>>
>> This may be true, but if you look in the list archives a few months
>> ago I basically chased my tail in circles and nobody could tell me
>> what I was doing wrong and so many of the docs are so old that they're
>> worse then useless, they seem to suggest the wrong thing.
>>
>> It was literally leaking GB's worth of RAM.  I even disabled all
>> caching and process sizes were growing into the GB's.  Turn off
>> ssl-bump and the leak went away.
>>
>> This is what I was using:
>>
>> http_port 10.0.0.1:3128 ssl-bump generate-host-certificates=on
>> dynamic_cert_mem_cache_size=400MB cert=/etc/squid/ssl_cert/myCA.pem
>> sslflags=NO_DEFAULT_CA
>> http_port localhost:3128
>> ssl_bump bump all
> bump all is useless without peek/splice.
>
> Let's see on my config snippets:
>
> https_port 3127 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=10MB cert=/usr/local/squid/etc/rootCA2.crt
> key=/usr/local/squid/etc/rootCA2.key
> tls-cafile=/usr/local/squid/etc/rootCA12.crt
> options=SINGLE_DH_USE:SINGLE_ECDH_USE
> tls-dh=secp384r1:/usr/local/squid/etc/dhparam.pem
> cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> tls-no-npn sslflags=NO_DEFAULT_CA:VERIFY_CRL_ALL
> http_port 3128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=10MB cert=/usr/local/squid/etc/rootCA2.crt
> key=/usr/local/squid/etc/rootCA2.key
> tls-cafile=/usr/local/squid/etc/rootCA12.crt
> options=SINGLE_DH_USE:SINGLE_ECDH_USE
> tls-dh=secp384r1:/usr/local/squid/etc/dhparam.pem
> cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> tls-no-npn sslflags=NO_DEFAULT_CA:VERIFY_CRL_ALL
> tls_outgoing_options cafile=/usr/local/squid/etc/ca-bundle.crt
> cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> # Cert database on ramdisk
> sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
> /ramdisk1/ssl_db -M 1GB
> sslcrtd_children 32 startup=10 idle=5
>
> # SSL bump rules
> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLIntercept ssl::server_name_regex
> "/usr/local/squid/etc/acl.url.nobump"
> ssl_bump peek DiscoverSNIHost
> ssl_bump splice NoSSLIntercept
> ssl_bump bump all
>
>> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB
>> sslcrtd_children 32 startup=2 idle=2
> This is defaults. Pay attention, -M is limits use ssl_db directory to
> 4 Mb in size. It's too few for production servers. My ramdisk for ssl
> db is 1+ Gb in size:
>
> /dev/ramdisk/ramdisk1?????????? 961M?? 14M? 890M?? 2% /ramdisk1/ssl_db
>
>> sslproxy_session_cache_size 100 MB
> This is disbalanced size instead of previous setting. Why so big?
>
> #? TAG: sslproxy_session_cache_size
> #??????? Sets the cache size to use for ssl session
> #Default:
> # sslproxy_session_cache_size 2 MB
>
>> sslproxy_cert_error allow all
>> sslproxy_flags DONT_VERIFY_PEER
> *NEVER use this options. It is unsafe.
>
> SSL Bump is dangerous enough itself. Don't do it more unsafe
> additionally by yourself.
> *
>> This was on a machine (EC2 VM) with 14GB of RAM.
> Pay attention on several places:
>
> 1. OS memory allocator.
> 2. OpenSSL version.
> 3. OS configuration (IPC, shared memory, swap - all memory related).
> 4. Squid's memory/pools configuration.
>
> Don't forget about: Often memory fragmentation seems like leaks. But
> no leaks occurs indeed.
>
> Also, don't forget - squid's memory consumption is not only cache_mem,
> but also caching on-disk metadata (swap.state), pools settings,
> working memory areas, processes memory. And - also - such things like
> content adaptation (did you know wide uses ecap gzip adapter is leaky
> itself?).
>
> But this is just for example.
>
> In any case, dig to the OpenSSL/OS side. Squid's memory in most cases
> is ok.
>
> I know, this appears SSL Bump is leaky. But this is not correct.
>> --
>> Aaron Turner
>> https://synfin.net/         Twitter: @synfinatic
>> My father once told me that respect for the truth comes close to being
>> the basis for all morality.  "Something cannot emerge from nothing,"
>> he said.  This is profound thinking if you understand how unstable
>> "the truth" can be.  -- Frank Herbert, Dune
>>
>>
>> On Tue, Mar 13, 2018 at 9:47 AM, Yuri <yvoinov at gmail.com> wrote:
>>> I've used it on all versions starting from 3.4.
>>>
>>> Now I'm using Squid 5.0.0.
>>>
>>> I'm afraid, my config is completely useless, because of it contains tons
>>> of optimizations/tweaks/tricks and designed for customized Squid 5.0.0,
>>> with different memory allocator for custom infrastructure.
>>>
>>> You can't just take my config, implement it and hope it will give same
>>> results for you.
>>>
>>> At least, it uses non-system CA bundle, platform-specific configuration
>>> parameters combinations, etc.
>>>
>>> I can say, than SSL Bump is not directly related to memory leaks. Squid
>>> itself almost not contains memory leaks now. Usually misconfiguration
>>> leads to memory overhead.
>>>
>>> As a recommendation, I can give some advices.
>>>
>>> 1. Use server with enough RAM. 4 Gb usually enough just for default
>>> squid configuration. Usually whole system RAM usage should never be
>>> bigger than 1/2 of overall physical RAM. (I.e. at least 1/3 of RAM
>>> should always be free during normal running. This prevents OS allocator
>>> pressure to your proxy and, also, increasing performance of proxy). In
>>> case of medium proxy server 16 Gb of RAM seems big enough, but never try
>>> to fill it up completely.
>>>
>>> 2. Don't set giant cache_mem. Remember how you platform allocates whole
>>> RAM - kernel, anon pages, fs caches, etc. - and use reasonable squid's
>>> memory-related settings.
>>>
>>> 3. Use sslflags=NO_DEFAULT_CA with your SSL Bump ports.
>>>
>>> 4. Never remember - SSL Bump increases your cache memory pressure due to
>>> increasing caching. So, you still require to have enough memory in your
>>> system.
>>>
>>>
>>> 13.03.2018 22:25, Aaron Turner ?????:
>>>> What version are you using Yuri?  Can you share your config?
>>>> Everytime I use ssl bump, I have massive memory leaks.  It's been
>>>> effectively unusable for me.
>>>> --
>>>> Aaron Turner
>>>> https://synfin.net/         Twitter: @synfinatic
>>>> My father once told me that respect for the truth comes close to being
>>>> the basis for all morality.  "Something cannot emerge from nothing,"
>>>> he said.  This is profound thinking if you understand how unstable
>>>> "the truth" can be.  -- Frank Herbert, Dune
>>>>
>>>>
>>>> On Tue, Mar 13, 2018 at 9:10 AM, Yuri <yvoinov at gmail.com> wrote:
>>>>> Moreover,
>>>>>
>>>>> SSL Bump combines with interception/explicit proxy in one setup.
>>>>>
>>>>> And works perfectly.
>>>>>
>>>>>
>>>>> 13.03.2018 21:14, Marcus Kool ?????:
>>>>>> "SSL bump" is the name of a complex Squid feature.
>>>>>> With ssl_bump ACLs one can decide which domains can be 'spliced' (go
>>>>>> through the proxy untouched) or can be 'bumped' (decrypted).
>>>>>>
>>>>>> Interception is not a requirement for SSL bump.
>>>>>>
>>>>>> Marcus
>>>>>>
>>>>>> On 13/03/18 11:44, Danilo V wrote:
>>>>>>> I mean SSL bump in explicit mode.
>>>>>>> So intercept is a essencial requirement for running SSL bump?
>>>>>>>
>>>>>>> Em ter, 13 de mar de 2018 ?s 11:10, Matus UHLAR - fantomas
>>>>>>> <uhlar at fantomas.sk <mailto:uhlar at fantomas.sk>> escreveu:
>>>>>>>
>>>>>>>     On 13.03.18 13:44, Danilo V wrote:
>>>>>>>      >Is it possible/feasible to configure squid in explicit mode
>>>>>>> with ssl
>>>>>>>      >intercept?
>>>>>>>
>>>>>>>     explicit is not intercept, intercept is not explicit.
>>>>>>>
>>>>>>>     explicit is where browser is configured (manually or
>>>>>>> automatically via WPAD)
>>>>>>>     to use the proxy.
>>>>>>>
>>>>>>>     intercept is where network device forcifully redirects http/https
>>>>>>> connections
>>>>>>>     to the proxy.
>>>>>>>
>>>>>>>     maybe you mean SSL bump in explicit mode?
>>>>>>>
>>>>>>>      >Due to architecture of my network it is not possible to implement
>>>>>>>      >transparent proxy.
>>>>>>>
>>>>>>>     excuse me?
>>>>>>>     by "transparent" people mean what we usually call "intercept".
>>>>>>>
>>>>>>>      >What would be the behavior of applications that dont support
>>>>>>> proxy - i.e.
>>>>>>>      >dont forward requests to proxy?
>>>>>>>
>>>>>>>     they mest be intercepted.
>>>>>>>
>>>>>>>     --
>>>>>>>     Matus UHLAR - fantomas, uhlar at fantomas.sk
>>>>>>> <mailto:uhlar at fantomas.sk> ; http://www.fantomas.sk/
>>>>>>>     Warning: I wish NOT to receive e-mail advertising to this address.
>>>>>>>     Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
>>>>>>>     Micro$oft random number generator: 0, 0, 0, 4.33e+67, 0, 0, 0...
>>>>>>>     _______________________________________________
>>>>>>>     squid-users mailing list
>>>>>>>     squid-users at lists.squid-cache.org
>>>>>>> <mailto:squid-users at lists.squid-cache.org>
>>>>>>>     http://lists.squid-cache.org/listinfo/squid-users
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> squid-users mailing list
>>>>>>> squid-users at lists.squid-cache.org
>>>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>>>
>>>>>> _______________________________________________
>>>>>> squid-users mailing list
>>>>>> squid-users at lists.squid-cache.org
>>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>> --
>>>>> "C++ seems like a language suitable for firing other people's legs."
>>>>>
>>>>> *****************************
>>>>> * C++20 : Bug to the future *
>>>>> *****************************
>>>>>
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>> --
>>> "C++ seems like a language suitable for firing other people's legs."
>>>
>>> *****************************
>>> * C++20 : Bug to the future *
>>> *****************************
>>>
>>>
>
> -- 
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/a1d34dfc/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: gchdeocgbabplcep.png
Type: image/png
Size: 20149 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/a1d34dfc/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ncdmadnlnjklmdpe.png
Type: image/png
Size: 17141 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/a1d34dfc/attachment-0001.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180313/a1d34dfc/attachment.sig>

From synfinatic at gmail.com  Tue Mar 13 19:15:05 2018
From: synfinatic at gmail.com (Aaron Turner)
Date: Tue, 13 Mar 2018 12:15:05 -0700
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <f6a85fc5-50a3-9372-b487-72d8d42122fe@gmail.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
 <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
 <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>
 <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>
 <CANAZdzUsamD-_P2gB9oQEbjR=Y0XEK0mnKUdYgjXtRGAxnPQUQ@mail.gmail.com>
 <f6a85fc5-50a3-9372-b487-72d8d42122fe@gmail.com>
Message-ID: <CANAZdzVbZXA0_UpN037y4sSVjYkWHwsmtD0MQmuKxyqoxRO+9w@mail.gmail.com>

Thanks Yuri.  That helps.  As for the "sslproxy_flags
DONT_VERIFY_PEER", yes I understand the risks.  In my specific case,
where my "users" are actually a bunch of automated web clients doing
some web crawling it's the right thing to do.
--
Aaron Turner
https://synfin.net/         Twitter: @synfinatic
My father once told me that respect for the truth comes close to being
the basis for all morality.  "Something cannot emerge from nothing,"
he said.  This is profound thinking if you understand how unstable
"the truth" can be.  -- Frank Herbert, Dune


On Tue, Mar 13, 2018 at 10:44 AM, Yuri <yvoinov at gmail.com> wrote:
> AFAIK,
>
> SSL bump subsystem uses OpenSSL memory routines. So, first of all, most
> probably leaks (if any) can be OpenSSL-related, but not squid itself.
>
> Now let's see your config snippets.
>
> 13.03.2018 23:00, Aaron Turner ?????:
>
> "Usually misconfiguration leads to memory overhead."
>
> This may be true, but if you look in the list archives a few months
> ago I basically chased my tail in circles and nobody could tell me
> what I was doing wrong and so many of the docs are so old that they're
> worse then useless, they seem to suggest the wrong thing.
>
> It was literally leaking GB's worth of RAM.  I even disabled all
> caching and process sizes were growing into the GB's.  Turn off
> ssl-bump and the leak went away.
>
> This is what I was using:
>
> http_port 10.0.0.1:3128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=400MB cert=/etc/squid/ssl_cert/myCA.pem
> sslflags=NO_DEFAULT_CA
> http_port localhost:3128
> ssl_bump bump all
>
> bump all is useless without peek/splice.
>
> Let's see on my config snippets:
>
> https_port 3127 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=10MB cert=/usr/local/squid/etc/rootCA2.crt
> key=/usr/local/squid/etc/rootCA2.key
> tls-cafile=/usr/local/squid/etc/rootCA12.crt
> options=SINGLE_DH_USE:SINGLE_ECDH_USE
> tls-dh=secp384r1:/usr/local/squid/etc/dhparam.pem
> cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> tls-no-npn sslflags=NO_DEFAULT_CA:VERIFY_CRL_ALL
> http_port 3128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=10MB cert=/usr/local/squid/etc/rootCA2.crt
> key=/usr/local/squid/etc/rootCA2.key
> tls-cafile=/usr/local/squid/etc/rootCA12.crt
> options=SINGLE_DH_USE:SINGLE_ECDH_USE
> tls-dh=secp384r1:/usr/local/squid/etc/dhparam.pem
> cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> tls-no-npn sslflags=NO_DEFAULT_CA:VERIFY_CRL_ALL
> tls_outgoing_options cafile=/usr/local/squid/etc/ca-bundle.crt
> cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> # Cert database on ramdisk
> sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
> /ramdisk1/ssl_db -M 1GB
> sslcrtd_children 32 startup=10 idle=5
>
> # SSL bump rules
> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLIntercept ssl::server_name_regex
> "/usr/local/squid/etc/acl.url.nobump"
> ssl_bump peek DiscoverSNIHost
> ssl_bump splice NoSSLIntercept
> ssl_bump bump all
>
>
> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB
> sslcrtd_children 32 startup=2 idle=2
>
> This is defaults. Pay attention, -M is limits use ssl_db directory to 4 Mb
> in size. It's too few for production servers. My ramdisk for ssl db is 1+ Gb
> in size:
>
> /dev/ramdisk/ramdisk1           961M   14M  890M   2% /ramdisk1/ssl_db
>
> sslproxy_session_cache_size 100 MB
>
> This is disbalanced size instead of previous setting. Why so big?
>
> #  TAG: sslproxy_session_cache_size
> #        Sets the cache size to use for ssl session
> #Default:
> # sslproxy_session_cache_size 2 MB
>
> sslproxy_cert_error allow all
> sslproxy_flags DONT_VERIFY_PEER
>
> NEVER use this options. It is unsafe.
>
> SSL Bump is dangerous enough itself. Don't do it more unsafe additionally by
> yourself.
>
> This was on a machine (EC2 VM) with 14GB of RAM.
>
> Pay attention on several places:
>
> 1. OS memory allocator.
> 2. OpenSSL version.
> 3. OS configuration (IPC, shared memory, swap - all memory related).
> 4. Squid's memory/pools configuration.
>
> Don't forget about: Often memory fragmentation seems like leaks. But no
> leaks occurs indeed.
>
> Also, don't forget - squid's memory consumption is not only cache_mem, but
> also caching on-disk metadata (swap.state), pools settings, working memory
> areas, processes memory. And - also - such things like content adaptation
> (did you know wide uses ecap gzip adapter is leaky itself?).
>
> But this is just for example.
>
> In any case, dig to the OpenSSL/OS side. Squid's memory in most cases is ok.
>
> I know, this appears SSL Bump is leaky. But this is not correct.
>
> --
> Aaron Turner
> https://synfin.net/         Twitter: @synfinatic
> My father once told me that respect for the truth comes close to being
> the basis for all morality.  "Something cannot emerge from nothing,"
> he said.  This is profound thinking if you understand how unstable
> "the truth" can be.  -- Frank Herbert, Dune
>
>
> On Tue, Mar 13, 2018 at 9:47 AM, Yuri <yvoinov at gmail.com> wrote:
>
> I've used it on all versions starting from 3.4.
>
> Now I'm using Squid 5.0.0.
>
> I'm afraid, my config is completely useless, because of it contains tons
> of optimizations/tweaks/tricks and designed for customized Squid 5.0.0,
> with different memory allocator for custom infrastructure.
>
> You can't just take my config, implement it and hope it will give same
> results for you.
>
> At least, it uses non-system CA bundle, platform-specific configuration
> parameters combinations, etc.
>
> I can say, than SSL Bump is not directly related to memory leaks. Squid
> itself almost not contains memory leaks now. Usually misconfiguration
> leads to memory overhead.
>
> As a recommendation, I can give some advices.
>
> 1. Use server with enough RAM. 4 Gb usually enough just for default
> squid configuration. Usually whole system RAM usage should never be
> bigger than 1/2 of overall physical RAM. (I.e. at least 1/3 of RAM
> should always be free during normal running. This prevents OS allocator
> pressure to your proxy and, also, increasing performance of proxy). In
> case of medium proxy server 16 Gb of RAM seems big enough, but never try
> to fill it up completely.
>
> 2. Don't set giant cache_mem. Remember how you platform allocates whole
> RAM - kernel, anon pages, fs caches, etc. - and use reasonable squid's
> memory-related settings.
>
> 3. Use sslflags=NO_DEFAULT_CA with your SSL Bump ports.
>
> 4. Never remember - SSL Bump increases your cache memory pressure due to
> increasing caching. So, you still require to have enough memory in your
> system.
>
>
> 13.03.2018 22:25, Aaron Turner ?????:
>
> What version are you using Yuri?  Can you share your config?
> Everytime I use ssl bump, I have massive memory leaks.  It's been
> effectively unusable for me.
> --
> Aaron Turner
> https://synfin.net/         Twitter: @synfinatic
> My father once told me that respect for the truth comes close to being
> the basis for all morality.  "Something cannot emerge from nothing,"
> he said.  This is profound thinking if you understand how unstable
> "the truth" can be.  -- Frank Herbert, Dune
>
>
> On Tue, Mar 13, 2018 at 9:10 AM, Yuri <yvoinov at gmail.com> wrote:
>
> Moreover,
>
> SSL Bump combines with interception/explicit proxy in one setup.
>
> And works perfectly.
>
>
> 13.03.2018 21:14, Marcus Kool ?????:
>
> "SSL bump" is the name of a complex Squid feature.
> With ssl_bump ACLs one can decide which domains can be 'spliced' (go
> through the proxy untouched) or can be 'bumped' (decrypted).
>
> Interception is not a requirement for SSL bump.
>
> Marcus
>
> On 13/03/18 11:44, Danilo V wrote:
>
> I mean SSL bump in explicit mode.
> So intercept is a essencial requirement for running SSL bump?
>
> Em ter, 13 de mar de 2018 ?s 11:10, Matus UHLAR - fantomas
> <uhlar at fantomas.sk <mailto:uhlar at fantomas.sk>> escreveu:
>
>     On 13.03.18 13:44, Danilo V wrote:
>      >Is it possible/feasible to configure squid in explicit mode
> with ssl
>      >intercept?
>
>     explicit is not intercept, intercept is not explicit.
>
>     explicit is where browser is configured (manually or
> automatically via WPAD)
>     to use the proxy.
>
>     intercept is where network device forcifully redirects http/https
> connections
>     to the proxy.
>
>     maybe you mean SSL bump in explicit mode?
>
>      >Due to architecture of my network it is not possible to implement
>      >transparent proxy.
>
>     excuse me?
>     by "transparent" people mean what we usually call "intercept".
>
>      >What would be the behavior of applications that dont support
> proxy - i.e.
>      >dont forward requests to proxy?
>
>     they mest be intercepted.
>
>     --
>     Matus UHLAR - fantomas, uhlar at fantomas.sk
> <mailto:uhlar at fantomas.sk> ; http://www.fantomas.sk/
>     Warning: I wish NOT to receive e-mail advertising to this address.
>     Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
>     Micro$oft random number generator: 0, 0, 0, 4.33e+67, 0, 0, 0...
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> --
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> --
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************
>
>
>
> --
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************


From rousskov at measurement-factory.com  Tue Mar 13 21:30:37 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 13 Mar 2018 15:30:37 -0600
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
 <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
 <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>
 <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>
Message-ID: <473c755c-0915-a284-c586-9c03c8253c99@measurement-factory.com>

Yuri,

    The quality of many of your recent mailing list posts was
exceptionally high: to-the-point, with a healthy level of technical
detail, cool triage, actionable advice, and no distractions (up to the
footer:-). Your new approach resulted in a much more enjoyable
experience for me personally and, I bet, for many other list readers.
Thank you and please keep it up!

Alex.



From yvoinov at gmail.com  Tue Mar 13 21:51:13 2018
From: yvoinov at gmail.com (Yuri)
Date: Wed, 14 Mar 2018 03:51:13 +0600
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <473c755c-0915-a284-c586-9c03c8253c99@measurement-factory.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
 <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
 <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>
 <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>
 <473c755c-0915-a284-c586-9c03c8253c99@measurement-factory.com>
Message-ID: <a50e2916-a7ae-0f83-aaa6-0d4a5842dfd6@gmail.com>

As practical experience shows, it is counterproductive to swear. :)
Especially when you need to solve the problem;)

It's just that sometimes a bad character wins :)

14.03.2018 03:30, Alex Rousskov ?????:
> Yuri,
>
>     The quality of many of your recent mailing list posts was
> exceptionally high: to-the-point, with a healthy level of technical
> detail, cool triage, actionable advice, and no distractions (up to the
> footer:-). Your new approach resulted in a much more enjoyable
> experience for me personally and, I bet, for many other list readers.
> Thank you and please keep it up!
>
> Alex.
>

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180314/5a8288f5/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180314/5a8288f5/attachment.sig>

From eliezer at ngtech.co.il  Tue Mar 13 22:35:20 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 14 Mar 2018 00:35:20 +0200
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <f6a85fc5-50a3-9372-b487-72d8d42122fe@gmail.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <94ec3c70-1d51-af2e-13d8-bd2daa42706b@urlfilterdb.com>
 <58d3b584-e845-231d-ae34-d6dc023ea876@gmail.com>
 <CANAZdzW_SMpd75ihM6rGe582mRse4O98nrGsrK758v58s0FP+A@mail.gmail.com>
 <01039110-1f93-1daf-1171-0374d390f4ad@gmail.com>
 <CANAZdzUsamD-_P2gB9oQEbjR=Y0XEK0mnKUdYgjXtRGAxnPQUQ@mail.gmail.com>
 <f6a85fc5-50a3-9372-b487-72d8d42122fe@gmail.com>
Message-ID: <07d301d3bb1b$9166a250$b433e6f0$@ngtech.co.il>

Thank Yuri!!

I believe that this post is milestone in for the SSL-BUMP feature.
Now the only thing left regarding weird memory leaks is to compare with these technical details:
3.5.27
4.0.24
5.0.0_alpha\head

I cannot test and compare it myself due to the lack of time and CPU but I believe that it will help to clear some doubts about stability of the above versions.

All The Bests and Thanks,
Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri
Sent: Tuesday, March 13, 2018 19:45
To: Aaron Turner <synfinatic at gmail.com>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] SSL intercept in explicit mode

AFAIK, 
SSL bump subsystem uses OpenSSL memory routines. So, first of all, most probably leaks (if any) can be OpenSSL-related, but not squid itself.
Now let's see your config snippets.
13.03.2018 23:00, Aaron Turner ?????:
"Usually misconfiguration leads to memory overhead."

This may be true, but if you look in the list archives a few months
ago I basically chased my tail in circles and nobody could tell me
what I was doing wrong and so many of the docs are so old that they're
worse then useless, they seem to suggest the wrong thing.

It was literally leaking GB's worth of RAM.  I even disabled all
caching and process sizes were growing into the GB's.  Turn off
ssl-bump and the leak went away.

This is what I was using:
<SNIP>
 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************



From squid3 at treenet.co.nz  Wed Mar 14 00:08:43 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 14 Mar 2018 13:08:43 +1300
Subject: [squid-users] ACL in custom error page
In-Reply-To: <1520959580472-0.post@n4.nabble.com>
References: <1520959580472-0.post@n4.nabble.com>
Message-ID: <47852979-93ae-ad03-0a6b-a5cb78e4ebf5@treenet.co.nz>

On 14/03/18 05:46, Eduardo Carneiro wrote:
> Hello everyone!
> 
> Is there any way to display, in my custom error pages, the acl that denied
> access?

Two things:

 1) There is no single ACL that denied Access. There is always an entire
sequence of checks.

2) The error page template code has not yet been updated to support
generic logformat codes which do have a code for the last ACL that was
tested (note that this may have been the one which _allowed logging_).

Amos


From rousskov at measurement-factory.com  Wed Mar 14 02:33:02 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 13 Mar 2018 20:33:02 -0600
Subject: [squid-users] ACL in custom error page
In-Reply-To: <47852979-93ae-ad03-0a6b-a5cb78e4ebf5@treenet.co.nz>
References: <1520959580472-0.post@n4.nabble.com>
 <47852979-93ae-ad03-0a6b-a5cb78e4ebf5@treenet.co.nz>
Message-ID: <dc4b8573-cf7e-9ad1-5b0e-57f6d76d3736@measurement-factory.com>

On 03/13/2018 06:08 PM, Amos Jeffries wrote:
> On 14/03/18 05:46, Eduardo Carneiro wrote:
>> Hello everyone!
>>
>> Is there any way to display, in my custom error pages, the acl that denied
>> access?
> 
> Two things:
> 
>  1) There is no single ACL that denied Access. There is always an entire
> sequence of checks.
> 
> 2) The error page template code has not yet been updated to support
> generic logformat codes which do have a code for the last ACL that was
> tested (note that this may have been the one which _allowed logging_).

And two more:

3) We are working to support major logformat %codes in error pages. The
patches are going through internal review cycles right now.

4) In modern Squids, the best way to log access denial (and similar)
decisions is often via ACL-triggered annotations (rather than the old
"the last ACL touched by somebody" hack). See annotate_transaction in
squid.conf.documented. The corresponding %note logformat code should be
available in error page templates as the result of (3).


Cheers,

Alex.


From eliezer at ngtech.co.il  Wed Mar 14 06:13:27 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 14 Mar 2018 08:13:27 +0200
Subject: [squid-users] ACL in custom error page
In-Reply-To: <dc4b8573-cf7e-9ad1-5b0e-57f6d76d3736@measurement-factory.com>
References: <1520959580472-0.post@n4.nabble.com>
 <47852979-93ae-ad03-0a6b-a5cb78e4ebf5@treenet.co.nz>
 <dc4b8573-cf7e-9ad1-5b0e-57f6d76d3736@measurement-factory.com>
Message-ID: <004501d3bb5b$91752d30$b45f8790$@ngtech.co.il>

And another one:
5) If you are using a deny_info configuration for a specific acl and you are redirecting to a url instead of squid inernal error page you can add some query term that will be used as a marker to the acl.

Example of usage:
acl blacklist-acl dstdomain block-test.org
deny_info http://<SOME SERVER NAME OR IP>/block_page/?url=%u&domain=%H&acl= blacklist-acl blacklist-acl

acl localnet src 192.168.0.0/16

http_access deny ! blacklist-acl
http_access allow localnet

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Alex Rousskov
Sent: Wednesday, March 14, 2018 04:33
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] ACL in custom error page

On 03/13/2018 06:08 PM, Amos Jeffries wrote:
> On 14/03/18 05:46, Eduardo Carneiro wrote:
>> Hello everyone!
>>
>> Is there any way to display, in my custom error pages, the acl that denied
>> access?
> 
> Two things:
> 
>  1) There is no single ACL that denied Access. There is always an entire
> sequence of checks.
> 
> 2) The error page template code has not yet been updated to support
> generic logformat codes which do have a code for the last ACL that was
> tested (note that this may have been the one which _allowed logging_).

And two more:

3) We are working to support major logformat %codes in error pages. The
patches are going through internal review cycles right now.

4) In modern Squids, the best way to log access denial (and similar)
decisions is often via ACL-triggered annotations (rather than the old
"the last ACL touched by somebody" hack). See annotate_transaction in
squid.conf.documented. The corresponding %note logformat code should be
available in error page templates as the result of (3).


Cheers,

Alex.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From info at microlinux.fr  Wed Mar 14 12:07:23 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Wed, 14 Mar 2018 13:07:23 +0100
Subject: [squid-users] Squid + SquidGuard : static block page not working
Message-ID: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>

Hi,

I've been working with Squid + SquidGuard for a few years, though only
on Slackware. I'm currently transferring my proxy expertise to CentOS 7,
and right now I'm having a little problem with that.

Squid works perfectly so far as a transparent HTTP + HTTPS cache proxy.

The next step is to add SquidGuard, so I installed it and edited the
most basic /etc/squid/squidGuard.conf file possible.

In this setup, my workstation (192.168.2.2) is allowed to access
anything on the Web, and all other client machines on the networks are
blocked and should be redirected to the avertissement.html block page
for every request.

--8<------------------------------------------------------------------
# /etc/squid/squidGuard.conf
dbhome /var/squidGuard
logdir /var/log/squidGuard

src admin {
  ip 192.168.2.2
}

acl {
  admin {
    pass any
  }
  default {
    pass none
    redirect http://nestor.microlinux.lan/avertissement.html
  }
}
--8<------------------------------------------------------------------

I appended the following lines to /etc/squid/squid.conf:

--8<------------------------------------------------------------------
# SquidGuard
url_rewrite_program /usr/bin/squidGuard -c /etc/squid/squidGuard.conf
url_rewrite_children 5
--8<------------------------------------------------------------------

Now this setup sort of works. My workstation can access anything, other
clients are blocked. Unfortunately, the block page avertissement.html is
not displayed. Instead, I get a Squid error page:

  The following error was encountered while trying to retrieve the URL:
  https://http/*

  Unable to determine IP address from host name "http".

Any idea why my static block page avertissement.html is not displayed?

Cheers,

Niki
-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From squid3 at treenet.co.nz  Wed Mar 14 12:33:06 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Mar 2018 01:33:06 +1300
Subject: [squid-users] Squid + SquidGuard : static block page not working
In-Reply-To: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
References: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
Message-ID: <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>

On 15/03/18 01:07, Nicolas Kovacs wrote:
> Hi,
> 
> I've been working with Squid + SquidGuard for a few years, though only
> on Slackware. I'm currently transferring my proxy expertise to CentOS 7,
> and right now I'm having a little problem with that.
> 
> Squid works perfectly so far as a transparent HTTP + HTTPS cache proxy.
> 
> The next step is to add SquidGuard, so I installed it and edited the
> most basic /etc/squid/squidGuard.conf file possible.
> 
> In this setup, my workstation (192.168.2.2) is allowed to access
> anything on the Web, and all other client machines on the networks are
> blocked and should be redirected to the avertissement.html block page
> for every request.

You do not need SG or any fancy redirector helpers at all for that.

Place this in your squid.conf instead:

  acl admin src 192.168.2.2
  http_access allow admin
  deny_info 302:http://nestor.microlinux.lan/avertissement.html all
  http_access deny all

If the clients can only reach nestor.microlinux.lan through the proxy
you will need an http_access rule allowing that domain before the deny line.

Amos


From info at microlinux.fr  Wed Mar 14 12:39:42 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Wed, 14 Mar 2018 13:39:42 +0100
Subject: [squid-users] Squid + SquidGuard : static block page not working
In-Reply-To: <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>
References: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
 <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>
Message-ID: <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>

Le 14/03/2018 ? 13:33, Amos Jeffries a ?crit?:
> You do not need SG or any fancy redirector helpers at all for that.

Yes, I do. Because this is part of a step-by-step course about
SquidGuard, which worked perfectly under Slackware Linux. And my
filtering rules are becoming increasingly complex.

Niki


-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From info at microlinux.fr  Wed Mar 14 12:43:41 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Wed, 14 Mar 2018 13:43:41 +0100
Subject: [squid-users] Squid + SquidGuard : static block page not working
In-Reply-To: <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>
References: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
 <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>
 <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>
Message-ID: <8194858d-1f1f-f02f-bc72-a32d5f348c68@microlinux.fr>

Le 14/03/2018 ? 13:39, Nicolas Kovacs a ?crit?:
> Yes, I do. Because this is part of a step-by-step course about
> SquidGuard, which worked perfectly under Slackware Linux. And my
> filtering rules are becoming increasingly complex.

FYI, this is the course. It's a HOWTO in simple text format.

I'm currently trying to adapt this to CentOS 7.

Niki

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32
-------------- next part --------------
================
SquidGuard HOWTO (c) Nicolas Kovacs <info at microlinux.fr>
================

Derni?re r?vision : 5 mai 2015

Ce HOWTO d?crit la mise en place du redirecteur SquidGuard pour un serveur
proxy Squid sous Slackware.

  * G?n?ralit?s et pr?requis
  * Installation
  * La page explicative
  * Une redirection simple
  * R?cup?rer les listes noires et blanches
  * Un filtre simple pour contenus probl?matiques
  * Automatiser les op?rations


G?n?ralit?s et pr?requis
------------------------

SquidGuard est un plug-in pour Squid. On doit donc disposer d'une installation
fonctionnelle de ce dernier.


Installation
------------

Installer le paquet 'squidGuard' depuis le d?p?t de paquets MLES.


La page explicative
-------------------

Lorsque SquidGuard refuse l'acc?s ? une page, c'est toujours une bonne id?e
d'expliquer les raisons de ce refus aux utilisateurs. Pour commencer, on va
donc mettre en place une page d'avertissement, qui sera h?berg?e sur le
serveur lui-m?me. 

Le r?pertoire 'template/squidguard/html/' propose un mod?le de page
explicative.

Pour la configuration d'une page web locale, voir le Apache-HOWTO.


Une redirection simple
----------------------

Nous n'avons pas encore de listes noires et blanches ni de base de donn?es,
mais nous pouvons d?j? faire un premier test de redirection :

  1. la machine 192.168.2.2 n'est pas filtr?e

  2. toutes les autres machines du r?seau local sont bloqu?es

SquidGuard se configure par le biais du fichier de configuration
'/etc/squidguard/squidguard.conf'. Sauvegardez le fichier de configuration
d'origine :

  # cd /etc/squidguard
  # mv squidguard.conf squidguard.conf.orig

?ditez un fichier de configuration minimal comme ceci :

--8<---------- /etc/squidguard/squidguard.conf -------------------------------
dbhome /var/lib/squidguard
logdir /var/log/squidguard

src admin {
  ip 192.168.2.2
}

acl {
  admin {
    pass any
  }
  default {
    pass none
    redirect http://squidguard.nestor/avertissement.html
  }
}
--8<--------------------------------------------------------------------------

  > La directive 'dbhome' indique ? SquidGuard o? trouver la base de donn?es
    des listes (que nous n'avons pas encore).

  > La directive 'logdir' sp?cifie l'endroit o? l'on d?sire r?cup?rer les
    logs.

  > Les sources d?finissent les groupes de clients. Ici, nous d?finissons une
    seule adresse IP.

  > Les 'acl' ou "Access Control Lists" permettent de d?finir quelle source
    peut aller ou ne pas aller vers quelle(s) destination(s). 

  > Lorsqu'une destination n'est pas autoris?e, la directive 'redirect' permet
    de servir une page explicative au client. 

? pr?sent, il faut configurer Squid pour qu'il utilise SquidGuard. ?diter le
fichier '/etc/squid/squid.conf' et ajouter cette stance ? la fin du fichier :

--8<---------- /etc/squid/squid.conf -----------------------------------------
url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidguard.conf
url_rewrite_children 5
--8<--------------------------------------------------------------------------

Recharger la configuration de Squid :

  # /etc/rc.d/rc.squid reload

V?rifier si la modification a bien ?t? prise en compte :

  # ps aux | grep squid | grep -v grep
  root      5043  ...  /usr/sbin/squid -F
  nobody    5045  ...  (squid) -F
  nobody    5068  ...  (squidGuard) -c /etc/squidguard/squidguard.conf
  nobody    5069  ...  (squidGuard) -c /etc/squidguard/squidguard.conf
  nobody    5070  ...  (squidGuard) -c /etc/squidguard/squidguard.conf
  nobody    5071  ...  (squidGuard) -c /etc/squidguard/squidguard.conf
  nobody    5072  ...  (squidGuard) -c /etc/squidguard/squidguard.conf

Maintenant, on peut essayer de naviguer sur Internet :

  1. avec la machine 192.168.2.2

  2. avec une machine dont l'adresse IP n'est pas 192.168.2.2


R?cup?rer les listes noires et blanches
---------------------------------------

Dans les exemples pr?sent?s ci-dessous, nous utiliserons les listes noires et
blanches maintenues par le Centre de Ressources Informatiques de l'Universit?
de Toulouse. Ces listes ne font pas partie de SquidGuard. On peut les
r?cup?rer manuellement comme ceci :
  
  # cd /var/lib/squidguard
  # wget -c ftp://ftp.ut-capitole.fr/blacklist/blacklists.tar.gz
  # tar xvzf blacklists.tar.gz
  # cd blacklists

Chacun des r?pertoires correspond ? une cat?gorie (ou "destination") du Web :

  # ls -l | awk '{print $9, $10, $11}'
  ads -> publicite
  adult  
  aggressive -> agressif
  agressif  
  arjel  
  astrology  
  audio-video  
  bank  
  bitcoin  
  blog  
  cc-by-sa-4-0.pdf  
  celebrity  
  chat  
  child  
  cleaning  
  cooking  
  dangerous_material  
  dating  
  drogue  
  drugs -> drogue
  educational_games  
  filehosting  
  financial  
  forums  
  gambling  
  games  
  global_usage  
  hacking  
  jobsearch  
  ...

On peut ?galement r?cup?rer les listes avec l'outil 'rsync'. Cette m?thode est
m?me recommand?e, ?tant donn? que 'rsync' ne t?l?chargera que la diff?rence
entre les arborescences distante et locale lors d'une mise ? jour :

  # cd /var/lib/squidguard
  # rm -rf blacklists*
  # rsync -rv rsync://ftp.ut-capitole.fr/blacklist/ .
  # cd dest

La seule diff?rence par rapport au t?l?chargement avec 'wget', c'est que nous
retrouvons nos destinations dans un r?pertoire 'dest/' et non 'blacklists/'.

Rep?rez le fichier 'global_usage' et jetez un oeil dedans. Il s'agit d'un
fichier explicatif sur le contenu des listes.


Un filtre simple pour contenus probl?matiques
---------------------------------------------

Dans ce deuxi?me exemple, nous allons filtrer les sites ? contenu
manifestement probl?matique (porno, violence, drogues) pour toutes les
machines du r?seau local. 

Dans un premier temps, nous allons adapter la directive 'dbhome' ? ce que nous
venons de t?l?charger un peu plus haut :

--8<---------- /etc/squidguard/squidguard.conf -------------------------------
dbhome /var/lib/squidguard/dest
logdir /var/log/squidguard
...
--8<--------------------------------------------------------------------------

Les sources sont l? pour sp?cifier les groupes de clients. Nous allons d?finir
tout le r?seau local "? la louche" :

--8<---------- /etc/squidguard/squidguard.conf -------------------------------
...
src microlinux {
  ip 192.168.2.0/24
}
--8<--------------------------------------------------------------------------

Les destinations d?finissent des ensembles de domaines, d'URL ou d'expressions
r?guli?res ? appliquer aux URLs. Ici, nous allons d?finir trois destinations :

--8<---------- /etc/squidguard/squidguard.conf -------------------------------
...
# Des sites adultes allant de l'?rotique ? la pornographie dure
destination adult {
  domainlist adult/domains
  urllist adult/urls
  log adult
}

# Quelques sites racistes, antis?mites et incitant ? la haine
destination agressif {
  domainlist agressif/domains
  urllist agressif/urls
  log agressif
}

# Drogues
destination drogue {
  domainlist drogue/domains
  urllist drogue/urls
  log drogue
}
--8<--------------------------------------------------------------------------

Les ACLs ("Access Control Lists") permettent de d?finir quelle source peut
aller ou ne pas aller vers quelle destination :

--8<---------- /etc/squidguard/squidguard.conf -------------------------------
...
acl {
  microlinux {
    pass !adult
    pass !agressif
    pass !drogue
    redirect http://squidguard.nestor/avertissement.html
  }
  default {
    pass none
    redirect http://squidguard.nestor/avertissement.html
  }
}
--8<--------------------------------------------------------------------------

  > Le point d'exclamation '!' ?quivaut ? une n?gation.

Au total, notre configuration ressemblera donc ? ceci :

--8<---------- /etc/squidguard/squidguard.conf -------------------------------
dbhome /var/lib/squidguard/dest
logdir /var/log/squidguard

src microlinux {
  ip 192.168.2.0/24
}

# Des sites adultes allant de l'?rotique ? la pornographie dure
destination adult {
  domainlist adult/domains
  urllist adult/urls
  log adult
}

# Quelques sites racistes, antis?mites et incitant ? la haine
destination agressif {
  domainlist agressif/domains
  urllist agressif/urls
  log agressif
}

# Drogues
destination drogue {
  domainlist drogue/domains
  urllist drogue/urls
  log drogue
}

acl {
  microlinux {
    pass !adult
    pass !agressif
    pass !drogue
    redirect http://squidguard.amandine/avertissement.html
  }
  default {
    pass none
    redirect http://squidguard.amandine/avertissement.html
  }
}
--8<--------------------------------------------------------------------------

Avant d'aller plus loin, nous devons r?gler quelques permissions.
Rappelons-nous que le proxy cache Squid tourne avec les droits de
l'utilisateur 'nobody' et du groupe 'nobody' :

--8<---------- /etc/squid/squid.conf -----------------------------------------
...
cache_effective_user nobody
cache_effective_group nobody
...
--8<--------------------------------------------------------------------------

L'arborescence '/var/lib/squidguard' doit ?tre accessible en lecture/?criture
pour Squid :

  # chown -R nobody:nobody /var/lib/squidguard/
  # ls -ld /var/lib/squidguard/
  drwxr-xr-x 3 nobody nobody 4096 nov.   2 08:56 /var/lib/squidguard/

Au cas o? le r?pertoire des logs n'existe pas, il faut le cr?er :

  # mkdir -v /var/log/squidguard
  mkdir: cr?ation du r?pertoire ??/var/log/squidguard??

L? aussi, il faut ajuster les permissions :

  # chown -R nobody:nobody /var/log/squidguard/
  # ls -ld /var/log/squidguard/
  drwxr-xr-x 2 nobody nobody 4096 nov.   2 11:08 /var/log/squidguard/

Pour pouvoir fonctionner rapidement, SquidGuard n'utilise pas les fichiers
texte, mais des bases de donn?es au format Berkeley. Ces bases de donn?es
n'existent pas encore, et nous devons les construire :

  # squidGuard -C all

Si tout s'est bien pass?, on obtient quelque chose comme ceci :

  # cat /var/log/squidguard/squidGuard.log 
  2014-11-02 11:09:39 [3897] New setting: dbhome: /var/lib/squidguard/dest
  2014-11-02 11:09:39 [3897] New setting: logdir: /var/log/squidguard
  2014-11-02 11:09:39 [3897] init domainlist
  /var/lib/squidguard/dest/adult/domains
  2014-11-02 11:09:52 [3897] create new dbfile
  /var/lib/squidguard/dest/adult/domains.db
  2014-11-02 11:09:53 [3897] init urllist /var/lib/squidguard/dest/adult/urls
  2014-11-02 11:09:53 [3897] create new dbfile
  /var/lib/squidguard/dest/adult/urls.db
  2014-11-02 11:09:54 [3897] init domainlist
  /var/lib/squidguard/dest/agressif/domains
  2014-11-02 11:09:54 [3897] create new dbfile
  /var/lib/squidguard/dest/agressif/domains.db
  2014-11-02 11:09:54 [3897] init urllist /var/lib/squidguard/dest/agressif/urls
  2014-11-02 11:09:54 [3897] create new dbfile
  /var/lib/squidguard/dest/agressif/urls.db
  2014-11-02 11:09:54 [3897] init domainlist
  /var/lib/squidguard/dest/drogue/domains
  2014-11-02 11:09:54 [3897] create new dbfile
  /var/lib/squidguard/dest/drogue/domains.db
  2014-11-02 11:09:54 [3897] init urllist /var/lib/squidguard/dest/drogue/urls
  2014-11-02 11:09:54 [3897] create new dbfile
  /var/lib/squidguard/dest/drogue/urls.db
  2014-11-02 11:09:54 [3897] squidGuard 1.4 started (1414922979.731)
  2014-11-02 11:09:54 [3897] db update done
  2014-11-02 11:09:54 [3897] squidGuard stopped (1414922994.459)

Quelques mises en garde s'imposent ici :

  1. SquidGuard est une application assez pointue, pour ne pas dire une
  v?ritable usine ? gaz. La moindre faute de frappe dans un des fichiers de
  configuration se solde g?n?ralement par un ?chec. Il est donc n?cessaire de
  porter une grande attention ? la syntaxe. 

  2. Les bases de donn?es (fichiers '*.db' en-dessous de l'arborescence
  '/var/lib/squidguard/dest/') doivent ?tre construites *apr?s* avoir ?crit le
  fichier de configuration, car seules les destinations d?finies dans ce
  fichier seront compil?es. Autrement dit, si vous devez ajouter une
  destination par la suite (malware, tricheur, etc.) il va falloir penser ?
  compiler les bases de donn?es correspondantes.

  3. En r?gle g?n?rale, ?a ne fonctionne que rarement du premier coup. Dans ce
  cas, jetez un oeil dans les logs, notamment 'squidGuard.log'. Ce dernier
  vous sera d'un grand secours, car il vous avertira de tous les probl?mes de
  configuration.

?tant donn? que la commande 'squidGuard -C all' a ?t? invoqu?e par root, les
fichiers g?n?r?s par cette commande appartiennent ? ce dernier :

  # ls -l /var/lib/squidguard/dest/adult/
  total 66704
  -rw-r--r-- 1 nobody nobody 17977204 nov.   1 11:02 domains
  -rw-r--r-- 1 root   root   44773376 nov.   2 11:09 domains.db
  -rw-r--r-- 1 nobody nobody        0 nov.   1 11:02 expressions
  -rw-r--r-- 1 nobody nobody  1959494 nov.   1 11:02 urls
  -rw-r--r-- 1 root   root    3584000 nov.   2 11:09 urls.db
  -rw-r--r-- 1 nobody nobody       17 nov.   1 11:02 usage
  ...
  # ls -l /var/log/squidguard/
  total 4
  -rw-r--r-- 1 root root    0 nov.   2 11:09 adult
  -rw-r--r-- 1 root root    0 nov.   2 11:09 agressif
  -rw-r--r-- 1 root root    0 nov.   2 11:09 drogue
  -rw-r--r-- 1 root root 1316 nov.   2 11:09 squidGuard.log

On va donc devoir rectifier le tir une deuxi?me fois pour les permissions :

  # chown -R nobody:nobody /var/lib/squidguard/
  # chown -R nobody:nobody /var/log/squidguard/

Recharger la configuration :

  # /etc/rc.d/rc.squid reload

? pr?sent, naviguer sur le Web et tester le filtrage de quelques sites
potentiellement probl?matiques :

  * http://www.nichons.com

  * http://www.whitehonor.com

  * http://www.cannabizz.com

Si tout se passe bien, les pages ne s'affichent pas, et l'utilisateur se
trouve confront? ? la page explicative. Non content de cela, sa tentative est
enregistr?e dans le fichier log correspondant ? la cat?gorie de site prohib?,
par exemple :

  # tail -f /var/log/squidguard/adult
  2014-11-02 11:28:42 ... http://www.nichons.com/ 192.168.2.3/- - GET REDIRECT
  2014-11-02 11:28:42 ... http://www.nichons.com/favicon.ico 192.168.2.3/- ...
  2014-11-02 11:28:42 ... http://www.nichons.com/favicon.ico 192.168.2.3/- ...


Automatiser les op?rations
--------------------------

Je fournis un script 'blacklist.sh' dans le r?pertoire 'template/squidguard/',
qui automatise la plupart des t?ches r?p?titives. Copier ce script dans un
endroit appropri?, par exemple '/usr/local/sbin/', et le rendre ex?cutable. Il
se charge de :

  1. r?cup?rer les listes noires et blanches

  2. mettre ? jour les listes d?j? t?l?charg?es

  3. construire les bases de donn?es Berkeley

  4. rectifier les permissions

  5. relancer Squid pour prendre en compte les modifications


------------------------------------------------------------------------------
# vim: syntax=txt

From squid3 at treenet.co.nz  Wed Mar 14 13:06:03 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Mar 2018 02:06:03 +1300
Subject: [squid-users] Squid + SquidGuard : static block page not working
In-Reply-To: <8194858d-1f1f-f02f-bc72-a32d5f348c68@microlinux.fr>
References: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
 <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>
 <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>
 <8194858d-1f1f-f02f-bc72-a32d5f348c68@microlinux.fr>
Message-ID: <1b88310f-993b-1267-8e82-593f8750facf@treenet.co.nz>

On 15/03/18 01:43, Nicolas Kovacs wrote:
> Le 14/03/2018 ? 13:39, Nicolas Kovacs a ?crit?:
>> Yes, I do. Because this is part of a step-by-step course about
>> SquidGuard, which worked perfectly under Slackware Linux. And my
>> filtering rules are becoming increasingly complex.
> 
> FYI, this is the course. It's a HOWTO in simple text format.
> 
> I'm currently trying to adapt this to CentOS 7.

Then the first thing you and your readers need to be clear on is that
SquidGuard was end-of-life'd many years ago. It is long overdue for
removal or replacement. This has impact such as the one you saw on HTTPS
traffic support which was only added to Squid-3 after SG stopped being
maintained.

The best thing to be doing these days is upgrading simple configs like
the one you presented earlier to using modern Squid features directly in
squid.conf - as I recommended earlier.

For very complex configurations (or emergency upgrades) the ufdbguard
tool can be used as a drop-in replacement for squidGuard while the
config migration is evaluated. It handles the HTTPS situation better
than SG does, but for simple configs any helper is still very much
overkill and a performance drag.

HTH
Amos


From info at microlinux.fr  Wed Mar 14 13:13:53 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Wed, 14 Mar 2018 14:13:53 +0100
Subject: [squid-users] Squid + SquidGuard : static block page not working
In-Reply-To: <1b88310f-993b-1267-8e82-593f8750facf@treenet.co.nz>
References: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
 <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>
 <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>
 <8194858d-1f1f-f02f-bc72-a32d5f348c68@microlinux.fr>
 <1b88310f-993b-1267-8e82-593f8750facf@treenet.co.nz>
Message-ID: <d934317c-ac0d-456f-a063-e95bcb9edcc7@microlinux.fr>

Le 14/03/2018 ? 14:06, Amos Jeffries a ?crit?:
> Then the first thing you and your readers need to be clear on is that
> SquidGuard was end-of-life'd many years ago. It is long overdue for
> removal or replacement. This has impact such as the one you saw on HTTPS
> traffic support which was only added to Squid-3 after SG stopped being
> maintained.
> 
> The best thing to be doing these days is upgrading simple configs like
> the one you presented earlier to using modern Squid features directly in
> squid.conf - as I recommended earlier.
> 
> For very complex configurations (or emergency upgrades) the ufdbguard
> tool can be used as a drop-in replacement for squidGuard while the
> config migration is evaluated. It handles the HTTPS situation better
> than SG does, but for simple configs any helper is still very much
> overkill and a performance drag.

This is the configuration which is currently in use at our local school.
The server is running Squid + SquidGuard on Slackware 14.1. We're
planning to move to CentOS 7 in June 2018, so I'd like to use this
working configuration without having to jump through burning loops or
having to reinvent the wheel.

--8<-----------------------------------------------------------------------
# /etc/squidguard/squidguard.conf

dbhome /var/lib/squidguard/dest
logdir /var/log/squidguard

time couvrefeu {
  weekly mtwhf 00:00-07:00
  weekly smtwh 22:30-24:00
}

src direction {
  ip 192.168.10.2-192.168.10.49
  ip 192.168.10.246-192.168.10.249
}

src scholae {
  ip 192.168.10.50-192.168.10.210
}

# Sites adultes
destination adult {
  domainlist adult/domains
  urllist adult/urls
  log adult
}

# Sites racistes, antis?mites, incitant ? la haine
destination agressif {
  domainlist agressif/domains
  urllist agressif/urls
  log agressif
}

# Sites orient?s vers l'audio et la vid?o
destination audio-video {
  domainlist audio-video/domains
  urllist audio-video/urls
  log audio-video
}

# Blogs
destination blog {
  domainlist blog/domains
  urllist blog/urls
  log blog
}

# Sites pour d?sinfecter et mettre ? jour des ordinateurs
destination cleaning {
  domainlist cleaning/domains
  urllist cleaning/urls
  log cleaning
}

# Sites d?crivant la fabrication de bombes, de poison, etc.
destination dangerous_material {
  domainlist dangerous_material/domains
  urllist dangerous_material/urls
  log dangerous_material
}

# Sites de t?l?chargement
destination download {
  domainlist download/domains
  urllist download/urls
  log download
}

# Drogue
destination drogue {
  domainlist drogue/domains
  urllist drogue/urls
  log drogue
}

# Infos financi?res
destination financial {
  domainlist financial/domains
  urllist financial/urls
  log financial
}

# Forums
destination forums {
  domainlist forums/domains
  urllist forums/urls
  log forums
}

# Jeux en ligne, casino
destination gambling {
  domainlist gambling/domains
  urllist gambling/urls
  log gambling
}

# Sites de piratage et d'agressions informatiques
destination hacking {
  domainlist hacking/domains
  urllist hacking/urls
  log hacking
}

# Sites ?ducatifs
destination liste_bu {
  domainlist liste_bu/domains
  urllist liste_bu/urls
  log liste_bu
}

# Sonneries de mobiles
destination mobile-phone {
  domainlist mobile-phone/domains
  urllist mobile-phone/urls
  log mobile-phone
}

# Phishing, pi?ges bancaires, etc.
destination phishing {
  domainlist phishing/domains
  urllist phishing/urls
  log phishing
}

# Publicit?
destination publicite {
  domainlist publicite/domains
  urllist publicite/urls
  log publicite
}

# Webradio
destination radio {
  domainlist radio/domains
  urllist radio/urls
  log radio
}

# Redirecteurs 1/3
destination redirector {
  domainlist redirector/domains
  urllist redirector/urls
  log redirector
}

# Redirecteurs 2/3
destination strict_redirector {
  domainlist strict_redirector/domains
  urllist strict_redirector/urls
  log strict_redirector
}

# Redirecteurs 3/3
destination strong_redirector {
  domainlist strong_redirector/domains
  urllist strong_redirector/urls
  log strong_redirector
}

# Sites qui expliquent comme tricher aux examens
destination tricheur {
  domainlist tricheur/domains
  urllist tricheur/urls
  log tricheur
}

# Warez
destination warez {
  domainlist warez/domains
  urllist warez/urls
  log warez
}

# Webmail
destination webmail {
  domainlist webmail/domains
  urllist webmail/urls
  log webmail
}

# Jeux
destination games {
  domainlist games/domains
  urllist games/urls
  log games
}

# Jeux ?ducatifs
destination educational_games {
  domainlist educational_games/domains
  urllist educational_games/urls
  log educational_games
}

# Sites pour adultes
destination mixed_adult {
  domainlist mixed_adult/domains
  urllist mixed_adult/urls
  log mixed_adult
}

# Sites de t?l?chargement
destination filehosting {
  domainlist filehosting/domains
  urllist filehosting/urls
  log filehosting
}

# Changement de propri?taire
destination reaffected {
  domainlist reaffected/domains
  urllist reaffected/urls
  log reaffected
}

# ?ducation sexuelle
destination sexual_education {
  domainlist sexual_education/domains
  urllist sexual_education/urls
  log sexual_education
}

# Shopping
destination shopping {
  domainlist shopping/domains
  urllist shopping/urls
  log shopping
}

# Sites de rencontres
destination dating {
  domainlist dating/domains
  urllist dating/urls
  log dating
}

# Marketing
destination marketingware {
  domainlist marketingware/domains
  urllist marketingware/urls
  log marketingware
}

# Astrologie
destination astrology {
  domainlist astrology/domains
  urllist astrology/urls
  log astrology
}

# Sectes
destination sect {
  domainlist sect/domains
  urllist sect/urls
  log sect
}

# People
destination celebrity {
  domainlist celebrity/domains
  urllist celebrity/urls
  log celebrity
}

# Mangas
destination manga {
  domainlist manga/domains
  urllist manga/urls
  log manga
}

# Sites pour les enfants
destination child {
  domainlist child/domains
  urllist child/urls
  log child
}

# Malwares
destination malware {
  domainlist malware/domains
  urllist malware/urls
  log malware
}

# Presse en ligne
destination press {
  domainlist press/domains
  urllist press/urls
  log press
}

# Messagerie instantan?e
destination chat {
  domainlist chat/domains
  urllist chat/urls
  log chat
}

# Prise de contr?le ? distance
destination remote-control {
  domainlist remote-control/domains
  urllist remote-control/urls
  log remote-control
}

# R?seaux sociaux
destination social_networks {
  domainlist social_networks/domains
  urllist social_networks/urls
  log social_networks
}

# Recherche d'emploi
destination jobsearch {
  domainlist jobsearch/domains
  log jobsearch
}

# Sport
destination sports {
  domainlist sports/domains
  log sports
}

# Banque en ligne
destination bank {
  domainlist bank/domains
  log bank
}

# Paris en ligne
destination arjel {
  domainlist arjel/domains
  log arjel
}

# Cuisine
destination cooking {
  domainlist cooking/domains
  log cooking
}

# Lingerie
destination lingerie {
  domainlist lingerie/domains
  urllist lingerie/urls
  log lingerie
}

# Traduction
destination translation {
  domainlist translation/domains
  urllist translation/urls
  log translation
}

# Bitcoin
destination bitcoin {
  domainlist bitcoin/domains
  urllist bitcoin/urls
  log bitcoin
}

# Dialers
destination dialer {
  domainlist dialer/domains
  log dialer
}

# DDoS
destination ddos {
  domainlist ddos/domains
  log ddos
}

# Mises ? jour
destination update {
  domainlist update/domains
  log update
}

# Associations religieuses
destination associations_religieuses {
  domainlist associations_religieuses/domains
  log associations_religieuses
}

# R?duction d'URL
destination shortener {
  domainlist shortener/domains
  urllist shortener/urls
  log shortener
}

acl {
  direction {
    pass all
  }
  scholae within couvrefeu {
    pass none
    redirect
http://squidguard.serveur-hp.ecole-scholae.lan/avertissement.html
  }
  scholae {
    pass !adult
    pass !agressif
    pass audio-video
    pass blog
    pass cleaning
    pass !dangerous_material
    pass !download
    pass !drogue
    pass financial
    pass forums
    pass !gambling
    pass !hacking
    pass liste_bu
    pass !mobile-phone
    pass !phishing
    pass !publicite
    pass radio
    pass !redirector
    pass !strict_redirector
    pass !strong_redirector
    pass !tricheur
    pass !warez
    pass webmail
    pass !games
    pass educational_games
    pass !mixed_adult
    pass !filehosting
    pass !reaffected
    pass sexual_education
    pass !shopping
    pass !dating
    pass !marketingware
    pass astrology
    pass !sect
    pass !celebrity
    pass !manga
    pass child
    pass !malware
    pass press
    pass !chat
    pass !remote-control
    pass social_networks
    pass jobsearch
    pass sports
    pass bank
    pass !arjel
    pass cooking
    pass !lingerie
    pass translation
    pass !bitcoin
    pass !dialer
    pass !ddos
    pass update
    pass !associations_religieuses
    pass !shortener
    redirect
http://squidguard.serveur-hp.ecole-scholae.lan/avertissement.html
  }
  default {
    pass none
    redirect
http://squidguard.serveur-hp.ecole-scholae.lan/avertissement.html
  }
}
--8<-----------------------------------------------------------------------

Cheers,

Niki
-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From uhlar at fantomas.sk  Wed Mar 14 13:26:28 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 14 Mar 2018 14:26:28 +0100
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
Message-ID: <20180314132628.GA31350@fantomas.sk>

On 13.03.18 14:44, Danilo V wrote:
>I mean SSL bump in explicit mode.
>So intercept is a essencial requirement for running SSL bump?

No, you asked for "explicit mode with ssl intercept" which I pointed out is
illogical.


>Em ter, 13 de mar de 2018 ?s 11:10, Matus UHLAR - fantomas <
>uhlar at fantomas.sk> escreveu:
>> On 13.03.18 13:44, Danilo V wrote:
>> >Is it possible/feasible to configure squid in explicit mode with ssl
>> >intercept?
>>
>> maybe you mean SSL bump in explicit mode?

It is possible to bump explicit proxy.

>> >Due to architecture of my network it is not possible to implement
>> >transparent proxy.
>>
>> excuse me?
>> by "transparent" people mean what we usually call "intercept".

>> >What would be the behavior of applications that dont support proxy - i.e.
>> >dont forward requests to proxy?
>>
>> they mest be intercepted.

"must" be intercepted. Since you said that it's not possible transparent (I
believe you have meant intercepting) proxy, it's apparently not possible to
handle applications that do not support proxy.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
2B|!2B, that's a question!


From squid3 at treenet.co.nz  Wed Mar 14 13:42:16 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Mar 2018 02:42:16 +1300
Subject: [squid-users] Squid + SquidGuard : static block page not working
In-Reply-To: <8194858d-1f1f-f02f-bc72-a32d5f348c68@microlinux.fr>
References: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
 <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>
 <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>
 <8194858d-1f1f-f02f-bc72-a32d5f348c68@microlinux.fr>
Message-ID: <77404db1-0dd0-dd95-9588-2e2aeaa50b12@treenet.co.nz>

On 15/03/18 01:43, Nicolas Kovacs wrote:
> Le 14/03/2018 ? 13:39, Nicolas Kovacs a ?crit?:
>> Yes, I do. Because this is part of a step-by-step course about
>> SquidGuard, which worked perfectly under Slackware Linux. And my
>> filtering rules are becoming increasingly complex.
> FYI, this is the course. It's a HOWTO in simple text format.
> 
> I'm currently trying to adapt this to CentOS 7.
> 
> Niki
> 
> -- Microlinux - Solutions informatiques durables 7, place de l'?glise -
> 30730 Montpezat Site : https://www.microlinux.fr Blog :
> https://blog.microlinux.fr Mail : info at microlinux.fr T?l. : 04 66 63 10 32
> 
> 

I have added some "Best Practice" config changes inline below:

> SquidGuard-HOWTO.txt
> 
> 
> ================
> SquidGuard HOWTO (c) Nicolas Kovacs <info at microlinux.fr>
> ================
> 
> Derni?re r?vision : 5 mai 2015
> 
> Ce HOWTO d?crit la mise en place du redirecteur SquidGuard pour un serveur
> proxy Squid sous Slackware.
> 
>   * G?n?ralit?s et pr?requis
>   * Installation
>   * La page explicative
>   * Une redirection simple
>   * R?cup?rer les listes noires et blanches
>   * Un filtre simple pour contenus probl?matiques
>   * Automatiser les op?rations
> 
> 
> G?n?ralit?s et pr?requis
> ------------------------
> 
> SquidGuard est un plug-in pour Squid. On doit donc disposer d'une installation
> fonctionnelle de ce dernier.
> 
> 
> Installation
> ------------
> 
> Installer le paquet 'squidGuard' depuis le d?p?t de paquets MLES.
> 
> 
> La page explicative
> -------------------
> 
> Lorsque SquidGuard refuse l'acc?s ? une page, c'est toujours une bonne id?e
> d'expliquer les raisons de ce refus aux utilisateurs. Pour commencer, on va
> donc mettre en place une page d'avertissement, qui sera h?berg?e sur le
> serveur lui-m?me. 
> 
> Le r?pertoire 'template/squidguard/html/' propose un mod?le de page
> explicative.
> 
> Pour la configuration d'une page web locale, voir le Apache-HOWTO.
> 
> 
> Une redirection simple
> ----------------------
> 
> Nous n'avons pas encore de listes noires et blanches ni de base de donn?es,
> mais nous pouvons d?j? faire un premier test de redirection :
> 
>   1. la machine 192.168.2.2 n'est pas filtr?e
> 
>   2. toutes les autres machines du r?seau local sont bloqu?es
> 
> SquidGuard se configure par le biais du fichier de configuration
> '/etc/squidguard/squidguard.conf'. Sauvegardez le fichier de configuration
> d'origine :
> 
>   # cd /etc/squidguard
>   # mv squidguard.conf squidguard.conf.orig
> 
> ?ditez un fichier de configuration minimal comme ceci :
> 
> --8<---------- /etc/squidguard/squidguard.conf -------------------------------
> dbhome /var/lib/squidguard
> logdir /var/log/squidguard
> 
> src admin {
>   ip 192.168.2.2
> }
> 
> acl {
>   admin {
>     pass any
>   }
>   default {
>     pass none
>     redirect http://squidguard.nestor/avertissement.html
>   }
> }
> --8<--------------------------------------------------------------------------
> 

In squid.conf:

  acl admin src 192.168.2.2
  http_access allow admin

  acl redirect src all
  deny_info 302:http://squidguard.nestor/avertissement.html redirect
  http_access deny redirect

No URL-rewrite use.


>   > La directive 'dbhome' indique ? SquidGuard o? trouver la base de donn?es
>     des listes (que nous n'avons pas encore).
> 
>   > La directive 'logdir' sp?cifie l'endroit o? l'on d?sire r?cup?rer les
>     logs.
> 
>   > Les sources d?finissent les groupes de clients. Ici, nous d?finissons une
>     seule adresse IP.
> 
>   > Les 'acl' ou "Access Control Lists" permettent de d?finir quelle source
>     peut aller ou ne pas aller vers quelle(s) destination(s). 
> 
>   > Lorsqu'une destination n'est pas autoris?e, la directive 'redirect' permet
>     de servir une page explicative au client. 
> 
> ? pr?sent, il faut configurer Squid pour qu'il utilise SquidGuard. ?diter le
> fichier '/etc/squid/squid.conf' et ajouter cette stance ? la fin du fichier :
> 
> --8<---------- /etc/squid/squid.conf -----------------------------------------
> url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidguard.conf
> url_rewrite_children 5

Add:
  url_rewrite_access deny CONNECT


> --8<--------------------------------------------------------------------------
> 
> Recharger la configuration de Squid :
> 
>   # /etc/rc.d/rc.squid reload
> 
> V?rifier si la modification a bien ?t? prise en compte :
> 
>   # ps aux | grep squid | grep -v grep
>   root      5043  ...  /usr/sbin/squid -F
>   nobody    5045  ...  (squid) -F
>   nobody    5068  ...  (squidGuard) -c /etc/squidguard/squidguard.conf
>   nobody    5069  ...  (squidGuard) -c /etc/squidguard/squidguard.conf
>   nobody    5070  ...  (squidGuard) -c /etc/squidguard/squidguard.conf
>   nobody    5071  ...  (squidGuard) -c /etc/squidguard/squidguard.conf
>   nobody    5072  ...  (squidGuard) -c /etc/squidguard/squidguard.conf
> 
> Maintenant, on peut essayer de naviguer sur Internet :
> 
>   1. avec la machine 192.168.2.2
> 
>   2. avec une machine dont l'adresse IP n'est pas 192.168.2.2
> 
> 
> R?cup?rer les listes noires et blanches
> ---------------------------------------
> 
> Dans les exemples pr?sent?s ci-dessous, nous utiliserons les listes noires et
> blanches maintenues par le Centre de Ressources Informatiques de l'Universit?
> de Toulouse. Ces listes ne font pas partie de SquidGuard. On peut les
> r?cup?rer manuellement comme ceci :
>   
>   # cd /var/lib/squidguard
>   # wget -c ftp://ftp.ut-capitole.fr/blacklist/blacklists.tar.gz
>   # tar xvzf blacklists.tar.gz
>   # cd blacklists
> 
> Chacun des r?pertoires correspond ? une cat?gorie (ou "destination") du Web :
> 
>   # ls -l | awk '{print $9, $10, $11}'
>   ads -> publicite
>   adult  
>   aggressive -> agressif
>   agressif  
>   arjel  
>   astrology  
>   audio-video  
>   bank  
>   bitcoin  
>   blog  
>   cc-by-sa-4-0.pdf  
>   celebrity  
>   chat  
>   child  
>   cleaning  
>   cooking  
>   dangerous_material  
>   dating  
>   drogue  
>   drugs -> drogue
>   educational_games  
>   filehosting  
>   financial  
>   forums  
>   gambling  
>   games  
>   global_usage  
>   hacking  
>   jobsearch  
>   ...
> 
> On peut ?galement r?cup?rer les listes avec l'outil 'rsync'. Cette m?thode est
> m?me recommand?e, ?tant donn? que 'rsync' ne t?l?chargera que la diff?rence
> entre les arborescences distante et locale lors d'une mise ? jour :
> 
>   # cd /var/lib/squidguard
>   # rm -rf blacklists*
>   # rsync -rv rsync://ftp.ut-capitole.fr/blacklist/ .
>   # cd dest
> 
> La seule diff?rence par rapport au t?l?chargement avec 'wget', c'est que nous
> retrouvons nos destinations dans un r?pertoire 'dest/' et non 'blacklists/'.
> 
> Rep?rez le fichier 'global_usage' et jetez un oeil dedans. Il s'agit d'un
> fichier explicatif sur le contenu des listes.
> 
> 
> Un filtre simple pour contenus probl?matiques
> ---------------------------------------------
> 
> Dans ce deuxi?me exemple, nous allons filtrer les sites ? contenu
> manifestement probl?matique (porno, violence, drogues) pour toutes les
> machines du r?seau local. 
> 
> Dans un premier temps, nous allons adapter la directive 'dbhome' ? ce que nous
> venons de t?l?charger un peu plus haut :
> 
> --8<---------- /etc/squidguard/squidguard.conf -------------------------------
> dbhome /var/lib/squidguard/dest
> logdir /var/log/squidguard
> ...
> --8<--------------------------------------------------------------------------
> 
> Les sources sont l? pour sp?cifier les groupes de clients. Nous allons d?finir
> tout le r?seau local "? la louche" :
> 
> --8<---------- /etc/squidguard/squidguard.conf -------------------------------
> ...
> src microlinux {
>   ip 192.168.2.0/24
> }
> --8<--------------------------------------------------------------------------
> 
> Les destinations d?finissent des ensembles de domaines, d'URL ou d'expressions
> r?guli?res ? appliquer aux URLs. Ici, nous allons d?finir trois destinations :
> 
> --8<---------- /etc/squidguard/squidguard.conf -------------------------------
> ...
> # Des sites adultes allant de l'?rotique ? la pornographie dure
> destination adult {
>   domainlist adult/domains
>   urllist adult/urls
>   log adult
> }
> 
> # Quelques sites racistes, antis?mites et incitant ? la haine
> destination agressif {
>   domainlist agressif/domains
>   urllist agressif/urls
>   log agressif
> }
> 
> # Drogues
> destination drogue {
>   domainlist drogue/domains
>   urllist drogue/urls
>   log drogue
> }
> --8<--------------------------------------------------------------------------
> 
> Les ACLs ("Access Control Lists") permettent de d?finir quelle source peut
> aller ou ne pas aller vers quelle destination :
> 
> --8<---------- /etc/squidguard/squidguard.conf -------------------------------
> ...
> acl {
>   microlinux {
>     pass !adult
>     pass !agressif
>     pass !drogue
>     redirect http://squidguard.nestor/avertissement.html
>   }
>   default {
>     pass none
>     redirect http://squidguard.nestor/avertissement.html
>   }
> }
> --8<--------------------------------------------------------------------------
> 
>   > Le point d'exclamation '!' ?quivaut ? une n?gation.
> 
> Au total, notre configuration ressemblera donc ? ceci :
> 
> --8<---------- /etc/squidguard/squidguard.conf -------------------------------
> dbhome /var/lib/squidguard/dest
> logdir /var/log/squidguard
> 
> src microlinux {
>   ip 192.168.2.0/24
> }

squid.conf:
  acl microlinux src 192.168.2.0/24

> 
> # Des sites adultes allant de l'?rotique ? la pornographie dure
> destination adult {
>   domainlist adult/domains
>   urllist adult/urls
>   log adult
> }
> 

squid.conf:
  acl adult_domains dstdomain "/var/lib/squidguard/dest/adult/domains"
  acl adult_urls url_regex "/var/lib/squidguard/dest/adult/urls"
  acl adult any-of adult_domains adult_urls

(or files in a location other than "lib/squidguard/".)

Note: Squid can handle regex files up to several hundred entries easily.
If they get into thousands OR are very frequently changed urldbguard can
become worth using.


The below agressif and drogue definitions can be done using the same
pattern as the adult lines above.


> # Quelques sites racistes, antis?mites et incitant ? la haine
> destination agressif {
>   domainlist agressif/domains
>   urllist agressif/urls
>   log agressif
> }
> 
> # Drogues
> destination drogue {
>   domainlist drogue/domains
>   urllist drogue/urls
>   log drogue
> }
> 
> acl {
>   microlinux {
>     pass !adult
>     pass !agressif
>     pass !drogue
>     redirect http://squidguard.amandine/avertissement.html
>   }
>   default {
>     pass none
>     redirect http://squidguard.amandine/avertissement.html
>   }
> }

squid.conf:

 acl redirect src all
 deny_info 302:http://squidguard.amandine/avertissement.html redirect
 http_access allow microlinux !adult !agressif !drogue
 http_access deny redirect


> --8<--------------------------------------------------------------------------
> 
> Avant d'aller plus loin, nous devons r?gler quelques permissions.
> Rappelons-nous que le proxy cache Squid tourne avec les droits de
> l'utilisateur 'nobody' et du groupe 'nobody' :
> 
> --8<---------- /etc/squid/squid.conf -----------------------------------------
> ...
> cache_effective_user nobody
> cache_effective_group nobody
> ...
> --8<--------------------------------------------------------------------------

Remove entirely. Pre-packaged Squid should be built with the appropriate
user account in --with-default-user= such that these do not need setting
at all.

> 
> L'arborescence '/var/lib/squidguard' doit ?tre accessible en lecture/?criture
> pour Squid :
> 
>   # chown -R nobody:nobody /var/lib/squidguard/
>   # ls -ld /var/lib/squidguard/
>   drwxr-xr-x 3 nobody nobody 4096 nov.   2 08:56 /var/lib/squidguard/
> 
> Au cas o? le r?pertoire des logs n'existe pas, il faut le cr?er :
> 
>   # mkdir -v /var/log/squidguard
>   mkdir: cr?ation du r?pertoire ??/var/log/squidguard??
> 
> L? aussi, il faut ajuster les permissions :
> 
>   # chown -R nobody:nobody /var/log/squidguard/
>   # ls -ld /var/log/squidguard/
>   drwxr-xr-x 2 nobody nobody 4096 nov.   2 11:08 /var/log/squidguard/
> 
> Pour pouvoir fonctionner rapidement, SquidGuard n'utilise pas les fichiers
> texte, mais des bases de donn?es au format Berkeley. Ces bases de donn?es
> n'existent pas encore, et nous devons les construire :
> 
>   # squidGuard -C all
> 
> Si tout s'est bien pass?, on obtient quelque chose comme ceci :
> 
>   # cat /var/log/squidguard/squidGuard.log 
>   2014-11-02 11:09:39 [3897] New setting: dbhome: /var/lib/squidguard/dest
>   2014-11-02 11:09:39 [3897] New setting: logdir: /var/log/squidguard
>   2014-11-02 11:09:39 [3897] init domainlist
>   /var/lib/squidguard/dest/adult/domains
>   2014-11-02 11:09:52 [3897] create new dbfile
>   /var/lib/squidguard/dest/adult/domains.db
>   2014-11-02 11:09:53 [3897] init urllist /var/lib/squidguard/dest/adult/urls
>   2014-11-02 11:09:53 [3897] create new dbfile
>   /var/lib/squidguard/dest/adult/urls.db
>   2014-11-02 11:09:54 [3897] init domainlist
>   /var/lib/squidguard/dest/agressif/domains
>   2014-11-02 11:09:54 [3897] create new dbfile
>   /var/lib/squidguard/dest/agressif/domains.db
>   2014-11-02 11:09:54 [3897] init urllist /var/lib/squidguard/dest/agressif/urls
>   2014-11-02 11:09:54 [3897] create new dbfile
>   /var/lib/squidguard/dest/agressif/urls.db
>   2014-11-02 11:09:54 [3897] init domainlist
>   /var/lib/squidguard/dest/drogue/domains
>   2014-11-02 11:09:54 [3897] create new dbfile
>   /var/lib/squidguard/dest/drogue/domains.db
>   2014-11-02 11:09:54 [3897] init urllist /var/lib/squidguard/dest/drogue/urls
>   2014-11-02 11:09:54 [3897] create new dbfile
>   /var/lib/squidguard/dest/drogue/urls.db
>   2014-11-02 11:09:54 [3897] squidGuard 1.4 started (1414922979.731)
>   2014-11-02 11:09:54 [3897] db update done
>   2014-11-02 11:09:54 [3897] squidGuard stopped (1414922994.459)
> 
> Quelques mises en garde s'imposent ici :
> 
>   1. SquidGuard est une application assez pointue, pour ne pas dire une
>   v?ritable usine ? gaz. La moindre faute de frappe dans un des fichiers de
>   configuration se solde g?n?ralement par un ?chec. Il est donc n?cessaire de
>   porter une grande attention ? la syntaxe. 
> 
>   2. Les bases de donn?es (fichiers '*.db' en-dessous de l'arborescence
>   '/var/lib/squidguard/dest/') doivent ?tre construites *apr?s* avoir ?crit le
>   fichier de configuration, car seules les destinations d?finies dans ce
>   fichier seront compil?es. Autrement dit, si vous devez ajouter une
>   destination par la suite (malware, tricheur, etc.) il va falloir penser ?
>   compiler les bases de donn?es correspondantes.
> 
>   3. En r?gle g?n?rale, ?a ne fonctionne que rarement du premier coup. Dans ce
>   cas, jetez un oeil dans les logs, notamment 'squidGuard.log'. Ce dernier
>   vous sera d'un grand secours, car il vous avertira de tous les probl?mes de
>   configuration.
> 
> ?tant donn? que la commande 'squidGuard -C all' a ?t? invoqu?e par root, les
> fichiers g?n?r?s par cette commande appartiennent ? ce dernier :
> 
>   # ls -l /var/lib/squidguard/dest/adult/
>   total 66704
>   -rw-r--r-- 1 nobody nobody 17977204 nov.   1 11:02 domains
>   -rw-r--r-- 1 root   root   44773376 nov.   2 11:09 domains.db
>   -rw-r--r-- 1 nobody nobody        0 nov.   1 11:02 expressions
>   -rw-r--r-- 1 nobody nobody  1959494 nov.   1 11:02 urls
>   -rw-r--r-- 1 root   root    3584000 nov.   2 11:09 urls.db
>   -rw-r--r-- 1 nobody nobody       17 nov.   1 11:02 usage
>   ...
>   # ls -l /var/log/squidguard/
>   total 4
>   -rw-r--r-- 1 root root    0 nov.   2 11:09 adult
>   -rw-r--r-- 1 root root    0 nov.   2 11:09 agressif
>   -rw-r--r-- 1 root root    0 nov.   2 11:09 drogue
>   -rw-r--r-- 1 root root 1316 nov.   2 11:09 squidGuard.log
> 
> On va donc devoir rectifier le tir une deuxi?me fois pour les permissions :
> 
>   # chown -R nobody:nobody /var/lib/squidguard/
>   # chown -R nobody:nobody /var/log/squidguard/
> 
> Recharger la configuration :
> 
>   # /etc/rc.d/rc.squid reload
> 
> ? pr?sent, naviguer sur le Web et tester le filtrage de quelques sites
> potentiellement probl?matiques :
> 
>   * http://www.nichons.com
> 
>   * http://www.whitehonor.com
> 
>   * http://www.cannabizz.com
> 
> Si tout se passe bien, les pages ne s'affichent pas, et l'utilisateur se
> trouve confront? ? la page explicative. Non content de cela, sa tentative est
> enregistr?e dans le fichier log correspondant ? la cat?gorie de site prohib?,
> par exemple :
> 
>   # tail -f /var/log/squidguard/adult
>   2014-11-02 11:28:42 ... http://www.nichons.com/ 192.168.2.3/- - GET REDIRECT
>   2014-11-02 11:28:42 ... http://www.nichons.com/favicon.ico 192.168.2.3/- ...
>   2014-11-02 11:28:42 ... http://www.nichons.com/favicon.ico 192.168.2.3/- ...
> 
> 
> Automatiser les op?rations
> --------------------------
> 
> Je fournis un script 'blacklist.sh' dans le r?pertoire 'template/squidguard/',
> qui automatise la plupart des t?ches r?p?titives. Copier ce script dans un
> endroit appropri?, par exemple '/usr/local/sbin/', et le rendre ex?cutable. Il
> se charge de :
> 
>   1. r?cup?rer les listes noires et blanches
> 
>   2. mettre ? jour les listes d?j? t?l?charg?es
> 
>   3. construire les bases de donn?es Berkeley
> 
>   4. rectifier les permissions
> 
>   5. relancer Squid pour prendre en compte les modifications
> 
> 
> ------------------------------------------------------------------------------
> # vim: syntax=txt
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 


From marcus.kool at urlfilterdb.com  Wed Mar 14 13:46:49 2018
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 14 Mar 2018 10:46:49 -0300
Subject: [squid-users] Squid + SquidGuard : static block page not working
In-Reply-To: <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>
References: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
 <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>
 <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>
Message-ID: <c79044dd-8c19-1106-ca2c-072b46b229cf@urlfilterdb.com>

ufdbGuard is the tool that you need.
It is an old fork of ufdbGuard with many new features, very good performance and it has regular maintenance.
If you have a question, you can ask the support desk at www.urlfilterdb.com.
You will get an answer from me or a colleague.

Marcus


On 14/03/18 09:39, Nicolas Kovacs wrote:
> Le 14/03/2018 ? 13:33, Amos Jeffries a ?crit?:
>> You do not need SG or any fancy redirector helpers at all for that.
> 
> Yes, I do. Because this is part of a step-by-step course about
> SquidGuard, which worked perfectly under Slackware Linux. And my
> filtering rules are becoming increasingly complex.
> 
> Niki
> 
> 


From info at microlinux.fr  Wed Mar 14 13:55:15 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Wed, 14 Mar 2018 14:55:15 +0100
Subject: [squid-users] Squid + SquidGuard : static block page not working
In-Reply-To: <c79044dd-8c19-1106-ca2c-072b46b229cf@urlfilterdb.com>
References: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
 <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>
 <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>
 <c79044dd-8c19-1106-ca2c-072b46b229cf@urlfilterdb.com>
Message-ID: <f53b34d1-61f1-37a1-259b-617ff559860d@microlinux.fr>

Le 14/03/2018 ? 14:46, Marcus Kool a ?crit?:
> ufdbGuard is the tool that you need.
> It is an old fork of ufdbGuard with many new features, very good
> performance and it has regular maintenance.
> If you have a question, you can ask the support desk at
> www.urlfilterdb.com.
> You will get an answer from me or a colleague.

Thanks for the heads-up.

On the school server running SquidGuard, I'm using the blacklist
collection of the University of Toulouse, which has several millions (!)
of URLS/domains in about a hundred different categories.

Will I be able to use these blacklists with ufdbGuard ?

Niki

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From yvoinov at gmail.com  Wed Mar 14 14:02:22 2018
From: yvoinov at gmail.com (Yuri)
Date: Wed, 14 Mar 2018 20:02:22 +0600
Subject: [squid-users] Squid + SquidGuard : static block page not working
In-Reply-To: <1b88310f-993b-1267-8e82-593f8750facf@treenet.co.nz>
References: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
 <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>
 <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>
 <8194858d-1f1f-f02f-bc72-a32d5f348c68@microlinux.fr>
 <1b88310f-993b-1267-8e82-593f8750facf@treenet.co.nz>
Message-ID: <d72fae20-7b9b-b1e5-32c8-e3c051338604@gmail.com>


14.03.2018 19:06, Amos Jeffries ?????:
> On 15/03/18 01:43, Nicolas Kovacs wrote:
>> Le 14/03/2018 ? 13:39, Nicolas Kovacs a ?crit?:
>>> Yes, I do. Because this is part of a step-by-step course about
>>> SquidGuard, which worked perfectly under Slackware Linux. And my
>>> filtering rules are becoming increasingly complex.
>> FYI, this is the course. It's a HOWTO in simple text format.
>>
>> I'm currently trying to adapt this to CentOS 7.
> Then the first thing you and your readers need to be clear on is that
> SquidGuard was end-of-life'd many years ago. It is long overdue for
> removal or replacement. This has impact such as the one you saw on HTTPS
> traffic support which was only added to Squid-3 after SG stopped being
> maintained.
>
> The best thing to be doing these days is upgrading simple configs like
> the one you presented earlier to using modern Squid features directly in
> squid.conf - as I recommended earlier.
>
> For very complex configurations (or emergency upgrades) the ufdbguard
> tool can be used as a drop-in replacement for squidGuard while the
> config migration is evaluated. It handles the HTTPS situation better
> than SG does, but for simple configs any helper is still very much
> overkill and a performance drag.
I can confirm - ufdbguard is up-to-date and very good customizable
replacement for SquidGuard. Using ufdbguard last three years gives
perfect results and bring functionality which is absent in SquidGuard.

ufdbguard has good support of https (including SSL Bump), incredible
fast (it is thread-aware) and has small memory footprint.
>
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180314/60a3f186/attachment.sig>

From marcus.kool at urlfilterdb.com  Wed Mar 14 14:05:02 2018
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 14 Mar 2018 11:05:02 -0300
Subject: [squid-users] Squid + SquidGuard : static block page not working
In-Reply-To: <f53b34d1-61f1-37a1-259b-617ff559860d@microlinux.fr>
References: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
 <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>
 <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>
 <c79044dd-8c19-1106-ca2c-072b46b229cf@urlfilterdb.com>
 <f53b34d1-61f1-37a1-259b-617ff559860d@microlinux.fr>
Message-ID: <02574fb7-3149-e87e-d07f-3e9d2d788740@urlfilterdb.com>


On 14/03/18 10:55, Nicolas Kovacs wrote:
> Le 14/03/2018 ? 14:46, Marcus Kool a ?crit?:
>> ufdbGuard is the tool that you need.
>> It is an old fork of ufdbGuard with many new features, very good
>> performance and it has regular maintenance.
>> If you have a question, you can ask the support desk at
>> www.urlfilterdb.com.
>> You will get an answer from me or a colleague.
> 
> Thanks for the heads-up.
> 
> On the school server running SquidGuard, I'm using the blacklist
> collection of the University of Toulouse, which has several millions (!)
> of URLS/domains in about a hundred different categories.
> 
> Will I be able to use these blacklists with ufdbGuard ?
> 
> Niki

yes, no problem.

Marcus


From yvoinov at gmail.com  Wed Mar 14 14:05:31 2018
From: yvoinov at gmail.com (Yuri)
Date: Wed, 14 Mar 2018 20:05:31 +0600
Subject: [squid-users] Squid + SquidGuard : static block page not working
In-Reply-To: <f53b34d1-61f1-37a1-259b-617ff559860d@microlinux.fr>
References: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
 <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>
 <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>
 <c79044dd-8c19-1106-ca2c-072b46b229cf@urlfilterdb.com>
 <f53b34d1-61f1-37a1-259b-617ff559860d@microlinux.fr>
Message-ID: <2880643a-d5a9-0a39-caa4-a741ca417125@gmail.com>



14.03.2018 19:55, Nicolas Kovacs ?????:
> Le 14/03/2018 ? 14:46, Marcus Kool a ?crit?:
>> ufdbGuard is the tool that you need.
>> It is an old fork of ufdbGuard with many new features, very good
>> performance and it has regular maintenance.
>> If you have a question, you can ask the support desk at
>> www.urlfilterdb.com.
>> You will get an answer from me or a colleague.
> Thanks for the heads-up.
>
> On the school server running SquidGuard, I'm using the blacklist
> collection of the University of Toulouse, which has several millions (!)
> of URLS/domains in about a hundred different categories.
>
> Will I be able to use these blacklists with ufdbGuard ?
Niki,

you can use any blacklist you want with ufdbguard. ufdbguard has own
commercial database, but can easy combined with any plain-text free
database by you choise. For example, with Shallalist. Or your own custom.

>
> Niki
>

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180314/dafe4c39/attachment.sig>

From squid3 at treenet.co.nz  Wed Mar 14 14:06:05 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Mar 2018 03:06:05 +1300
Subject: [squid-users] Squid + SquidGuard : static block page not working
In-Reply-To: <d934317c-ac0d-456f-a063-e95bcb9edcc7@microlinux.fr>
References: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
 <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>
 <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>
 <8194858d-1f1f-f02f-bc72-a32d5f348c68@microlinux.fr>
 <1b88310f-993b-1267-8e82-593f8750facf@treenet.co.nz>
 <d934317c-ac0d-456f-a063-e95bcb9edcc7@microlinux.fr>
Message-ID: <dbab3e07-814c-f062-0d1b-b82ab87368c0@treenet.co.nz>

On 15/03/18 02:13, Nicolas Kovacs wrote:
> Le 14/03/2018 ? 14:06, Amos Jeffries a ?crit?:
>> Then the first thing you and your readers need to be clear on is that
>> SquidGuard was end-of-life'd many years ago. It is long overdue for
>> removal or replacement. This has impact such as the one you saw on HTTPS
>> traffic support which was only added to Squid-3 after SG stopped being
>> maintained.
>>
>> The best thing to be doing these days is upgrading simple configs like
>> the one you presented earlier to using modern Squid features directly in
>> squid.conf - as I recommended earlier.
>>
>> For very complex configurations (or emergency upgrades) the ufdbguard
>> tool can be used as a drop-in replacement for squidGuard while the
>> config migration is evaluated. It handles the HTTPS situation better
>> than SG does, but for simple configs any helper is still very much
>> overkill and a performance drag.
> 
> This is the configuration which is currently in use at our local school.
> The server is running Squid + SquidGuard on Slackware 14.1. We're
> planning to move to CentOS 7 in June 2018, so I'd like to use this
> working configuration without having to jump through burning loops or
> having to reinvent the wheel.

This one is much more complex than your earlier configs. It seems
reasonable to use ufdbguard as a drop-in replacement for squidguard here.


A few things like the direction and couvrefeu ACLs can be moved easily
for better efficiency in squid.conf like so:

 acl direction src 192.168.10.2-192.168.10.49
 acl direction src 192.168.10.246-192.168.10.249

 # these are okay. Don't bother asking the helper
 url_rewrite_access deny direction

 acl couvrefeu time mtwhf 00:00-07:00
 acl couvrefeu time smtwh 22:30-24:00

 acl scholae src 192.168.10.50-192.168.10.210

 deny_info
302:http://squidguard.serveur-hp.ecole-scholae.lan/avertissement.html
couvrefeu

 http_access deny scholae couvrefeu

Note the helper will never even be asked when these are redirected by
http_access, so you do not need url_rewrite_access rule for it - scholae
things will only ever be passed to the helper during non-couvrefeu times.


Also if you want to present a fixed web page instead of redirecting. You
can configure/load a custom HTML error page in deny_info instead of
using the 302:url pattern.

HTH
Amos


From squid3 at treenet.co.nz  Wed Mar 14 14:07:47 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Mar 2018 03:07:47 +1300
Subject: [squid-users] Squid + SquidGuard : static block page not working
In-Reply-To: <f53b34d1-61f1-37a1-259b-617ff559860d@microlinux.fr>
References: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
 <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>
 <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>
 <c79044dd-8c19-1106-ca2c-072b46b229cf@urlfilterdb.com>
 <f53b34d1-61f1-37a1-259b-617ff559860d@microlinux.fr>
Message-ID: <376e4c2e-fc84-81ad-4349-ea91d589d650@treenet.co.nz>

On 15/03/18 02:55, Nicolas Kovacs wrote:
> Le 14/03/2018 ? 14:46, Marcus Kool a ?crit?:
>> ufdbGuard is the tool that you need.
>> It is an old fork of ufdbGuard with many new features, very good
>> performance and it has regular maintenance.
>> If you have a question, you can ask the support desk at
>> www.urlfilterdb.com.
>> You will get an answer from me or a colleague.
> 
> Thanks for the heads-up.
> 
> On the school server running SquidGuard, I'm using the blacklist
> collection of the University of Toulouse, which has several millions (!)
> of URLS/domains in about a hundred different categories.
> 
> Will I be able to use these blacklists with ufdbGuard ?

If squidguard could handle it, yes. ufdbguard is better.

Amos


From danilovt at gmail.com  Wed Mar 14 14:28:18 2018
From: danilovt at gmail.com (Danilo V)
Date: Wed, 14 Mar 2018 14:28:18 +0000
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <20180314132628.GA31350@fantomas.sk>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <20180314132628.GA31350@fantomas.sk>
Message-ID: <CAHaQnLOvHKx6bRCD6PS0BYckk+Kre34MghLav+4XzEvrt88tCA@mail.gmail.com>

Thanks for the explanation.
Do you have any guide?

Em qua, 14 de mar de 2018 ?s 10:26, Matus UHLAR - fantomas <
uhlar at fantomas.sk> escreveu:

> On 13.03.18 14:44, Danilo V wrote:
> >I mean SSL bump in explicit mode.
> >So intercept is a essencial requirement for running SSL bump?
>
> No, you asked for "explicit mode with ssl intercept" which I pointed out is
> illogical.
>
>
> >Em ter, 13 de mar de 2018 ?s 11:10, Matus UHLAR - fantomas <
> >uhlar at fantomas.sk> escreveu:
> >> On 13.03.18 13:44, Danilo V wrote:
> >> >Is it possible/feasible to configure squid in explicit mode with ssl
> >> >intercept?
> >>
> >> maybe you mean SSL bump in explicit mode?
>
> It is possible to bump explicit proxy.
>
> >> >Due to architecture of my network it is not possible to implement
> >> >transparent proxy.
> >>
> >> excuse me?
> >> by "transparent" people mean what we usually call "intercept".
>
> >> >What would be the behavior of applications that dont support proxy -
> i.e.
> >> >dont forward requests to proxy?
> >>
> >> they mest be intercepted.
>
> "must" be intercepted. Since you said that it's not possible transparent (I
> believe you have meant intercepting) proxy, it's apparently not possible to
> handle applications that do not support proxy.
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> 2B|!2B, that's a question!
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180314/da3190fd/attachment.htm>

From yvoinov at gmail.com  Wed Mar 14 15:34:52 2018
From: yvoinov at gmail.com (Yuri)
Date: Wed, 14 Mar 2018 21:34:52 +0600
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <CAHaQnLOvHKx6bRCD6PS0BYckk+Kre34MghLav+4XzEvrt88tCA@mail.gmail.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
 <20180313141032.GA27376@fantomas.sk>
 <CAHaQnLOwTg-Xdkpti4p8fCNyLOmk_g+0J70ZZqL3P3Dtnscxcw@mail.gmail.com>
 <20180314132628.GA31350@fantomas.sk>
 <CAHaQnLOvHKx6bRCD6PS0BYckk+Kre34MghLav+4XzEvrt88tCA@mail.gmail.com>
Message-ID: <5f7d1f6f-8644-025a-1228-a9ed696d7166@gmail.com>

I guess, your using wrong approach.

You trying to find ready-to-use solution for /custom/ configuration.

At maximum, you can find some bricks for this. And anyway you should
build your custom solution yourself.

Bricks is here: https://wiki.squid-cache.org :-)

14.03.2018 20:28, Danilo V ?????:
> Thanks for the explanation.
> Do you have any guide?
>
> Em qua, 14 de mar de 2018 ?s 10:26, Matus UHLAR - fantomas
> <uhlar at fantomas.sk <mailto:uhlar at fantomas.sk>> escreveu:
>
>     On 13.03.18 14:44, Danilo V wrote:
>     >I mean SSL bump in explicit mode.
>     >So intercept is a essencial requirement for running SSL bump?
>
>     No, you asked for "explicit mode with ssl intercept" which I
>     pointed out is
>     illogical.
>
>
>     >Em ter, 13 de mar de 2018 ?s 11:10, Matus UHLAR - fantomas <
>     >uhlar at fantomas.sk <mailto:uhlar at fantomas.sk>> escreveu:
>     >> On 13.03.18 13:44, Danilo V wrote:
>     >> >Is it possible/feasible to configure squid in explicit mode
>     with ssl
>     >> >intercept?
>     >>
>     >> maybe you mean SSL bump in explicit mode?
>
>     It is possible to bump explicit proxy.
>
>     >> >Due to architecture of my network it is not possible to implement
>     >> >transparent proxy.
>     >>
>     >> excuse me?
>     >> by "transparent" people mean what we usually call "intercept".
>
>     >> >What would be the behavior of applications that dont support
>     proxy - i.e.
>     >> >dont forward requests to proxy?
>     >>
>     >> they mest be intercepted.
>
>     "must" be intercepted. Since you said that it's not possible
>     transparent (I
>     believe you have meant intercepting) proxy, it's apparently not
>     possible to
>     handle applications that do not support proxy.
>
>     --
>     Matus UHLAR - fantomas, uhlar at fantomas.sk
>     <mailto:uhlar at fantomas.sk> ; http://www.fantomas.sk/
>     Warning: I wish NOT to receive e-mail advertising to this address.
>     Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
>     2B|!2B, that's a question!
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180314/769d9a42/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180314/769d9a42/attachment.sig>

From peedee.nick at gmail.com  Wed Mar 14 17:58:54 2018
From: peedee.nick at gmail.com (Patrick Nick)
Date: Wed, 14 Mar 2018 18:58:54 +0100
Subject: [squid-users] Squid as Kerberos client?
Message-ID: <CAH+7_B0r_1bHkrKrJfc=DxXaQEwONm5famaNJHY_KofD-dx1dg@mail.gmail.com>

Hello list,

We are in the process of Kerberizing our Big Data operation, but we have a
GUI tool in use that is not capable of Kerberos authentication. I'm looking
for a way to keep using it, which means that it needs to read data from a
Kerberos-protected service.

To be clear, I'm looking for a proxy that will take care of the
authentication so that our GUI tool does not need to know. It should
"enrich" the client's "dumb" request to an authenticated request. This
lowers security of course, but I will use other means to make sure that
only that app can talk to the proxy on the network.

I looked into nginx but didn't find a way to do what I want.

Can squid do this?
I've been trying some configs according to
https://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos, but it
seems that it always wants to pass the "negotiate" request to the client,
which I'm trying to avoid.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180314/dc20961a/attachment.htm>

From flashdown at data-core.org  Wed Mar 14 18:22:30 2018
From: flashdown at data-core.org (Enrico Heine)
Date: Wed, 14 Mar 2018 19:22:30 +0100
Subject: [squid-users] Squid as Kerberos client?
In-Reply-To: <CAH+7_B0r_1bHkrKrJfc=DxXaQEwONm5famaNJHY_KofD-dx1dg@mail.gmail.com>
References: <CAH+7_B0r_1bHkrKrJfc=DxXaQEwONm5famaNJHY_KofD-dx1dg@mail.gmail.com>
Message-ID: <97465F79-7694-4FD8-A50B-9DF67424F8D4@data-core.org>

Hi,

Easy going, you can allow traffic from a specific source or traffic to a specific destination before you require authentication on the proxy. You can also restrict it to both, src and destination and additionaly specific ports. But squid cannot authenticate those requests on the destination server if it needs authentication as well.

Best regards,
Enrico

Am 14. M?rz 2018 18:58:54 MEZ schrieb Patrick Nick <peedee.nick at gmail.com>:
>Hello list,
>
>We are in the process of Kerberizing our Big Data operation, but we
>have a
>GUI tool in use that is not capable of Kerberos authentication. I'm
>looking
>for a way to keep using it, which means that it needs to read data from
>a
>Kerberos-protected service.
>
>To be clear, I'm looking for a proxy that will take care of the
>authentication so that our GUI tool does not need to know. It should
>"enrich" the client's "dumb" request to an authenticated request. This
>lowers security of course, but I will use other means to make sure that
>only that app can talk to the proxy on the network.
>
>I looked into nginx but didn't find a way to do what I want.
>
>Can squid do this?
>I've been trying some configs according to
>https://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos, but
>it
>seems that it always wants to pass the "negotiate" request to the
>client,
>which I'm trying to avoid.

-- 
Diese Nachricht wurde von meinem Android-Ger?t mit K-9 Mail gesendet.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180314/57aa9d0a/attachment.htm>

From peedee.nick at gmail.com  Wed Mar 14 18:27:48 2018
From: peedee.nick at gmail.com (Patrick Nick)
Date: Wed, 14 Mar 2018 19:27:48 +0100
Subject: [squid-users] Squid as Kerberos client?
In-Reply-To: <97465F79-7694-4FD8-A50B-9DF67424F8D4@data-core.org>
References: <CAH+7_B0r_1bHkrKrJfc=DxXaQEwONm5famaNJHY_KofD-dx1dg@mail.gmail.com>
 <97465F79-7694-4FD8-A50B-9DF67424F8D4@data-core.org>
Message-ID: <CAH+7_B3hRJQ0sGh0XR+ft7MDSLiuE63x219F8baXGp1xRnn=eg@mail.gmail.com>

Hi Enrico,

You write

> But squid cannot authenticate those requests on the destination server if
> it needs authentication as well.


So how do I make it NOT need authentication?
I want it to authenticate the request on behalf of the client, so that my
client app does not need to authenticate.
Squid can use the keytab that I give it for that.


On Wed, Mar 14, 2018 at 7:22 PM, Enrico Heine <flashdown at data-core.org>
wrote:

> Hi,
>
> Easy going, you can allow traffic from a specific source or traffic to a
> specific destination before you require authentication on the proxy. You
> can also restrict it to both, src and destination and additionaly specific
> ports. But squid cannot authenticate those requests on the destination
> server if it needs authentication as well.
>
> Best regards,
> Enrico
>
>
> Am 14. M?rz 2018 18:58:54 MEZ schrieb Patrick Nick <peedee.nick at gmail.com
> >:
>>
>> Hello list,
>>
>> We are in the process of Kerberizing our Big Data operation, but we have
>> a GUI tool in use that is not capable of Kerberos authentication. I'm
>> looking for a way to keep using it, which means that it needs to read data
>> from a Kerberos-protected service.
>>
>> To be clear, I'm looking for a proxy that will take care of the
>> authentication so that our GUI tool does not need to know. It should
>> "enrich" the client's "dumb" request to an authenticated request. This
>> lowers security of course, but I will use other means to make sure that
>> only that app can talk to the proxy on the network.
>>
>> I looked into nginx but didn't find a way to do what I want.
>>
>> Can squid do this?
>> I've been trying some configs according to https://wiki.squid-cache.org/
>> ConfigExamples/Authenticate/Kerberos, but it seems that it always wants
>> to pass the "negotiate" request to the client, which I'm trying to avoid.
>>
>
> --
> Diese Nachricht wurde von meinem Android-Ger?t mit K-9 Mail gesendet.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180314/1625872b/attachment.htm>

From flashdown at data-core.org  Wed Mar 14 19:43:30 2018
From: flashdown at data-core.org (Enrico Heine)
Date: Wed, 14 Mar 2018 20:43:30 +0100
Subject: [squid-users] Squid as Kerberos client?
In-Reply-To: <CAH+7_B3hRJQ0sGh0XR+ft7MDSLiuE63x219F8baXGp1xRnn=eg@mail.gmail.com>
References: <CAH+7_B0r_1bHkrKrJfc=DxXaQEwONm5famaNJHY_KofD-dx1dg@mail.gmail.com>
 <97465F79-7694-4FD8-A50B-9DF67424F8D4@data-core.org>
 <CAH+7_B3hRJQ0sGh0XR+ft7MDSLiuE63x219F8baXGp1xRnn=eg@mail.gmail.com>
Message-ID: <0A34C068-BF23-4AAA-B33F-C83529B625C7@data-core.org>

Which protocols and ports is that GUI tool  using for what it's doing with it's remote endpoint that requires kerberos authentication? 

Am 14. M?rz 2018 19:27:48 MEZ schrieb Patrick Nick <peedee.nick at gmail.com>:
>Hi Enrico,
>
>You write
>
>> But squid cannot authenticate those requests on the destination
>server if
>> it needs authentication as well.
>
>
>So how do I make it NOT need authentication?
>I want it to authenticate the request on behalf of the client, so that
>my
>client app does not need to authenticate.
>Squid can use the keytab that I give it for that.
>
>
>On Wed, Mar 14, 2018 at 7:22 PM, Enrico Heine <flashdown at data-core.org>
>wrote:
>
>> Hi,
>>
>> Easy going, you can allow traffic from a specific source or traffic
>to a
>> specific destination before you require authentication on the proxy.
>You
>> can also restrict it to both, src and destination and additionaly
>specific
>> ports. But squid cannot authenticate those requests on the
>destination
>> server if it needs authentication as well.
>>
>> Best regards,
>> Enrico
>>
>>
>> Am 14. M?rz 2018 18:58:54 MEZ schrieb Patrick Nick
><peedee.nick at gmail.com
>> >:
>>>
>>> Hello list,
>>>
>>> We are in the process of Kerberizing our Big Data operation, but we
>have
>>> a GUI tool in use that is not capable of Kerberos authentication.
>I'm
>>> looking for a way to keep using it, which means that it needs to
>read data
>>> from a Kerberos-protected service.
>>>
>>> To be clear, I'm looking for a proxy that will take care of the
>>> authentication so that our GUI tool does not need to know. It should
>>> "enrich" the client's "dumb" request to an authenticated request.
>This
>>> lowers security of course, but I will use other means to make sure
>that
>>> only that app can talk to the proxy on the network.
>>>
>>> I looked into nginx but didn't find a way to do what I want.
>>>
>>> Can squid do this?
>>> I've been trying some configs according to
>https://wiki.squid-cache.org/
>>> ConfigExamples/Authenticate/Kerberos, but it seems that it always
>wants
>>> to pass the "negotiate" request to the client, which I'm trying to
>avoid.
>>>
>>
>> --
>> Diese Nachricht wurde von meinem Android-Ger?t mit K-9 Mail gesendet.
>>

-- 
Diese Nachricht wurde von meinem Android-Ger?t mit K-9 Mail gesendet.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180314/e4bc7e21/attachment.htm>

From peedee.nick at gmail.com  Wed Mar 14 22:01:57 2018
From: peedee.nick at gmail.com (Patrick Nick)
Date: Wed, 14 Mar 2018 23:01:57 +0100
Subject: [squid-users] Squid as Kerberos client?
In-Reply-To: <0A34C068-BF23-4AAA-B33F-C83529B625C7@data-core.org>
References: <CAH+7_B0r_1bHkrKrJfc=DxXaQEwONm5famaNJHY_KofD-dx1dg@mail.gmail.com>
 <97465F79-7694-4FD8-A50B-9DF67424F8D4@data-core.org>
 <CAH+7_B3hRJQ0sGh0XR+ft7MDSLiuE63x219F8baXGp1xRnn=eg@mail.gmail.com>
 <0A34C068-BF23-4AAA-B33F-C83529B625C7@data-core.org>
Message-ID: <CAH+7_B2R6dti3UjtMr4k12WijbxBVYamPQxpOToKrEdhjOpJ+w@mail.gmail.com>

It consumes the data for its graphs from a REST API via HTTP, on ports in
the 8000-9000 range.

On Wed, Mar 14, 2018 at 8:43 PM, Enrico Heine <flashdown at data-core.org>
wrote:

> Which protocols and ports is that GUI tool using for what it's doing with
> it's remote endpoint that requires kerberos authentication?
>
> Am 14. M?rz 2018 19:27:48 MEZ schrieb Patrick Nick <peedee.nick at gmail.com
> >:
>>
>> Hi Enrico,
>>
>> You write
>>
>>> But squid cannot authenticate those requests on the destination server
>>> if it needs authentication as well.
>>
>>
>> So how do I make it NOT need authentication?
>> I want it to authenticate the request on behalf of the client, so that my
>> client app does not need to authenticate.
>> Squid can use the keytab that I give it for that.
>>
>>
>> On Wed, Mar 14, 2018 at 7:22 PM, Enrico Heine <flashdown at data-core.org>
>> wrote:
>>
>>> Hi,
>>>
>>> Easy going, you can allow traffic from a specific source or traffic to a
>>> specific destination before you require authentication on the proxy. You
>>> can also restrict it to both, src and destination and additionaly specific
>>> ports. But squid cannot authenticate those requests on the destination
>>> server if it needs authentication as well.
>>>
>>> Best regards,
>>> Enrico
>>>
>>>
>>> Am 14. M?rz 2018 18:58:54 MEZ schrieb Patrick Nick <
>>> peedee.nick at gmail.com>:
>>>>
>>>> Hello list,
>>>>
>>>> We are in the process of Kerberizing our Big Data operation, but we
>>>> have a GUI tool in use that is not capable of Kerberos authentication. I'm
>>>> looking for a way to keep using it, which means that it needs to read data
>>>> from a Kerberos-protected service.
>>>>
>>>> To be clear, I'm looking for a proxy that will take care of the
>>>> authentication so that our GUI tool does not need to know. It should
>>>> "enrich" the client's "dumb" request to an authenticated request. This
>>>> lowers security of course, but I will use other means to make sure that
>>>> only that app can talk to the proxy on the network.
>>>>
>>>> I looked into nginx but didn't find a way to do what I want.
>>>>
>>>> Can squid do this?
>>>> I've been trying some configs according to
>>>> https://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos, but
>>>> it seems that it always wants to pass the "negotiate" request to the
>>>> client, which I'm trying to avoid.
>>>>
>>>
>>> --
>>> Diese Nachricht wurde von meinem Android-Ger?t mit K-9 Mail gesendet.
>>>
>>
>>
> --
> Diese Nachricht wurde von meinem Android-Ger?t mit K-9 Mail gesendet.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180314/4b1cd48c/attachment.htm>

From squid3 at treenet.co.nz  Thu Mar 15 08:44:00 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Mar 2018 21:44:00 +1300
Subject: [squid-users] Squid as Kerberos client?
In-Reply-To: <CAH+7_B2R6dti3UjtMr4k12WijbxBVYamPQxpOToKrEdhjOpJ+w@mail.gmail.com>
References: <CAH+7_B0r_1bHkrKrJfc=DxXaQEwONm5famaNJHY_KofD-dx1dg@mail.gmail.com>
 <97465F79-7694-4FD8-A50B-9DF67424F8D4@data-core.org>
 <CAH+7_B3hRJQ0sGh0XR+ft7MDSLiuE63x219F8baXGp1xRnn=eg@mail.gmail.com>
 <0A34C068-BF23-4AAA-B33F-C83529B625C7@data-core.org>
 <CAH+7_B2R6dti3UjtMr4k12WijbxBVYamPQxpOToKrEdhjOpJ+w@mail.gmail.com>
Message-ID: <4d473798-898f-cdf4-73b1-970fe998e7d6@treenet.co.nz>

On 15/03/18 11:01, Patrick Nick wrote:
> It consumes the data for its graphs from a REST API via HTTP, on ports
> in the 8000-9000 range.
> 

Then you can use cache_peer from the proxy to the origin server. See the
"AUTHENTICATION OPTIONS" section for how to send various types of
credentials to that peer.
<http://www.squid-cache.org/Doc/config/cache_peer/>

Amos


From peedee.nick at gmail.com  Thu Mar 15 10:52:41 2018
From: peedee.nick at gmail.com (Patrick Nick)
Date: Thu, 15 Mar 2018 11:52:41 +0100
Subject: [squid-users] Squid as Kerberos client?
In-Reply-To: <4d473798-898f-cdf4-73b1-970fe998e7d6@treenet.co.nz>
References: <CAH+7_B0r_1bHkrKrJfc=DxXaQEwONm5famaNJHY_KofD-dx1dg@mail.gmail.com>
 <97465F79-7694-4FD8-A50B-9DF67424F8D4@data-core.org>
 <CAH+7_B3hRJQ0sGh0XR+ft7MDSLiuE63x219F8baXGp1xRnn=eg@mail.gmail.com>
 <0A34C068-BF23-4AAA-B33F-C83529B625C7@data-core.org>
 <CAH+7_B2R6dti3UjtMr4k12WijbxBVYamPQxpOToKrEdhjOpJ+w@mail.gmail.com>
 <4d473798-898f-cdf4-73b1-970fe998e7d6@treenet.co.nz>
Message-ID: <CAH+7_B06jvV7tvzcuSHEhYBdDdg9BZ=tR5H918zS35+RykVZ0A@mail.gmail.com>

Thanks Amos, this sounded promising. Unfortunately the behavior I observe
is not what I expect.
So I added the following config:

cache_peer my.company.webserver.net parent 8081 0 no-query
login=NEGOTIATE:myPrincipal

But now squid still does not do the SPNEGO negotiation. I can see in the
logs that it connects to the specified "parent" cache_peer, which returns
"401 Unauthorized" as expected. But then squid just returns that to the
client instead of sending another request with the Kerberos ticket to
complete the negotiation.
Am I misunderstanding what's supposed to happen?
Or am I not configuring it right? (The keytab is readable by the squid user)

On Thu, Mar 15, 2018 at 9:44 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 15/03/18 11:01, Patrick Nick wrote:
> > It consumes the data for its graphs from a REST API via HTTP, on ports
> > in the 8000-9000 range.
> >
>
> Then you can use cache_peer from the proxy to the origin server. See the
> "AUTHENTICATION OPTIONS" section for how to send various types of
> credentials to that peer.
> <http://www.squid-cache.org/Doc/config/cache_peer/>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180315/0215bfd7/attachment.htm>

From info at microlinux.fr  Thu Mar 15 11:23:14 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Thu, 15 Mar 2018 12:23:14 +0100
Subject: [squid-users] Squid + SquidGuard : static block page not working
In-Reply-To: <d72fae20-7b9b-b1e5-32c8-e3c051338604@gmail.com>
References: <62856b3f-83e3-cb44-6b79-9c21ff202ab8@microlinux.fr>
 <90652726-6721-5b8b-c135-41826d98910c@treenet.co.nz>
 <ddba37f3-5bdd-8c54-d862-95a885774388@microlinux.fr>
 <8194858d-1f1f-f02f-bc72-a32d5f348c68@microlinux.fr>
 <1b88310f-993b-1267-8e82-593f8750facf@treenet.co.nz>
 <d72fae20-7b9b-b1e5-32c8-e3c051338604@gmail.com>
Message-ID: <71d13966-76be-3e88-4780-b258e6a9bf7f@microlinux.fr>

Le 14/03/2018 ? 15:02, Yuri a ?crit :
> I can confirm - ufdbguard is up-to-date and very good customizable 
> replacement for SquidGuard. Using ufdbguard last three years gives 
> perfect results and bring functionality which is absent in
> SquidGuard.
> 
> ufdbguard has good support of https (including SSL Bump), incredible 
> fast (it is thread-aware) and has small memory footprint.

Thanks everybody for your numerous suggestions.

I fiddled around much more with Squid, and for the moment, I got my
existing SquidGuard configuration from Slackware working on CentOS.

https://blog.microlinux.fr/squidguard-centos/

As soon as I have a bit of time on my hands to experiment, I'll take a
look at ufdbguard.

For the moment, SquidGuard works perfectly here.

Cheers,

Niki

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From squid3 at treenet.co.nz  Thu Mar 15 11:53:53 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 16 Mar 2018 00:53:53 +1300
Subject: [squid-users] Squid as Kerberos client?
In-Reply-To: <CAH+7_B06jvV7tvzcuSHEhYBdDdg9BZ=tR5H918zS35+RykVZ0A@mail.gmail.com>
References: <CAH+7_B0r_1bHkrKrJfc=DxXaQEwONm5famaNJHY_KofD-dx1dg@mail.gmail.com>
 <97465F79-7694-4FD8-A50B-9DF67424F8D4@data-core.org>
 <CAH+7_B3hRJQ0sGh0XR+ft7MDSLiuE63x219F8baXGp1xRnn=eg@mail.gmail.com>
 <0A34C068-BF23-4AAA-B33F-C83529B625C7@data-core.org>
 <CAH+7_B2R6dti3UjtMr4k12WijbxBVYamPQxpOToKrEdhjOpJ+w@mail.gmail.com>
 <4d473798-898f-cdf4-73b1-970fe998e7d6@treenet.co.nz>
 <CAH+7_B06jvV7tvzcuSHEhYBdDdg9BZ=tR5H918zS35+RykVZ0A@mail.gmail.com>
Message-ID: <d00622d2-31c3-d1ab-6b17-08c9f7fca851@treenet.co.nz>

On 15/03/18 23:52, Patrick Nick wrote:
> Thanks Amos, this sounded promising. Unfortunately the behavior I
> observe is not what I expect.
> So I added the following config:
> 
> cache_peer my.company.webserver.net <http://my.company.webserver.net>
> parent 8081 0 no-query login=NEGOTIATE:myPrincipal
> 

Since this is an origin server and not a proxy it requires the
"originserver" option as well.


Amos


From info at microlinux.fr  Fri Mar 16 10:37:25 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Fri, 16 Mar 2018 11:37:25 +0100
Subject: [squid-users] How to configure a "proxy home" page ?
Message-ID: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>

Hi,

I have Squid + SquidGuard + SquidAnalyzer running on my LAN server as a
transparent cache + filtering proxy, and it's working real nicely.

When a client in my company wants to connect to the wifi, all he or she
has to do is this:

1. Connect to http://nestor.microlinux.lan

2. Download the nestor.microlinux.lan.der certificate

3. Install the certificate in the web browser (Firefox does it
automatically)

4. Surf the web

Now I wonder if there is a way to configure this page as a "proxy home
page" of some sorts. User who don't have the certificate installed
normally get a big fat HTTPS error as soon as they connect to a secure
site. So what I'd like to do is redirect "new" traffic to
http://nestor.microlinux.lan, which also explains what is happening.

I don't really know how to go about that, or if it is even possible.
Maybe some basic form of authentication ?

Any suggestion ?

Cheers,

Niki
-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From yvoinov at gmail.com  Fri Mar 16 12:43:34 2018
From: yvoinov at gmail.com (Yuri)
Date: Fri, 16 Mar 2018 18:43:34 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
Message-ID: <bf691c68-bf13-a0c7-b083-db23e3cc51ca@gmail.com>

I guess better way to do this is create special ACL to catch exactly
certificate error and then redirect by 302 using deny_info to proxy page
with explanation and certificate.

Sadly, however I have no full solution for this logic (we're simple
install proxy certificate manually), but idea exists ;)


16.03.2018 16:37, Nicolas Kovacs ?????:
> Hi,
>
> I have Squid + SquidGuard + SquidAnalyzer running on my LAN server as a
> transparent cache + filtering proxy, and it's working real nicely.
>
> When a client in my company wants to connect to the wifi, all he or she
> has to do is this:
>
> 1. Connect to http://nestor.microlinux.lan
>
> 2. Download the nestor.microlinux.lan.der certificate
>
> 3. Install the certificate in the web browser (Firefox does it
> automatically)
>
> 4. Surf the web
>
> Now I wonder if there is a way to configure this page as a "proxy home
> page" of some sorts. User who don't have the certificate installed
> normally get a big fat HTTPS error as soon as they connect to a secure
> site. So what I'd like to do is redirect "new" traffic to
> http://nestor.microlinux.lan, which also explains what is happening.
>
> I don't really know how to go about that, or if it is even possible.
> Maybe some basic form of authentication ?
>
> Any suggestion ?
>
> Cheers,
>
> Niki

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180316/3af25f81/attachment.sig>

From info at microlinux.fr  Fri Mar 16 13:09:43 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Fri, 16 Mar 2018 14:09:43 +0100
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <bf691c68-bf13-a0c7-b083-db23e3cc51ca@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <bf691c68-bf13-a0c7-b083-db23e3cc51ca@gmail.com>
Message-ID: <ca86b276-f726-1bc8-38d5-d0dec7bda31c@microlinux.fr>

Le 16/03/2018 ? 13:43, Yuri a ?crit :
> I guess better way to do this is create special ACL to catch exactly 
> certificate error and then redirect by 302 using deny_info to proxy
> page with explanation and certificate.

This sounds like the way to go.

I just removed the root certificate from one of the clients and then
tried to open a few HTTPS sites. Invariably, I get the follwoing error
code :

SEC_ERROR_UNKNOWN_ISSUER

So how would I tell Squid in its own syntax to go to
http://nestor.microlinux.lan when it encounters such an error ? Is this
a trivial task, or more complicated to put in practice ?

BTW, this would be the last piece in my puzzle, and my installation
would be perfect if I got this to work.

Cheers,

Niki

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From yvoinov at gmail.com  Fri Mar 16 13:15:22 2018
From: yvoinov at gmail.com (Yuri)
Date: Fri, 16 Mar 2018 19:15:22 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <ca86b276-f726-1bc8-38d5-d0dec7bda31c@microlinux.fr>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <bf691c68-bf13-a0c7-b083-db23e3cc51ca@gmail.com>
 <ca86b276-f726-1bc8-38d5-d0dec7bda31c@microlinux.fr>
Message-ID: <a28963b1-801c-5067-fe83-5c9aa5ae33da@gmail.com>

I think, you should dig in this direction:

#??? acl aclname ssl_error errorname
#??? ? # match against SSL certificate validation error [fast]
#??? ? #
#??? ? # For valid error names see in
/usr/local/squid/share/errors/templates/error-details.txt
#??? ? # template file.
#??? ? #
#??? ? # The following can be used as shortcuts for certificate properties:
#??? ? #? [ssl::]certHasExpired: the "not after" field is in the past
#??? ? #? [ssl::]certNotYetValid: the "not before" field is in the future
#??? ? #? [ssl::]certUntrusted: The certificate issuer is not to be trusted.
#??? ? #? [ssl::]certSelfSigned: The certificate is self signed.
#??? ? #? [ssl::]certDomainMismatch: The certificate CN domain does not
#??? ? #???????? match the name the name of the host we are connecting to.
#??? ? #
#??? ? # The ssl::certHasExpired, ssl::certNotYetValid,
ssl::certDomainMismatch,
#??? ? # ssl::certUntrusted, and ssl::certSelfSigned can also be used as
#??? ? # predefined ACLs, just like the 'all' ACL.
#??? ? #
#??? ? # NOTE: The ssl_error ACL is only supported with sslproxy_cert_error,
#??? ? # sslproxy_cert_sign, and sslproxy_cert_adapt options.
#

...

#? TAG: sslproxy_cert_error
#??? Use this ACL to bypass server certificate validation errors.
#
#??? For example, the following lines will bypass all validation errors
#??? when talking to servers for example.com. All other
#??? validation errors will result in ERR_SECURE_CONNECT_FAIL error.
#
#??? ??? acl BrokenButTrustedServers dstdomain example.com
#??? ??? sslproxy_cert_error allow BrokenButTrustedServers
#??? ??? sslproxy_cert_error deny all
#
#??? This clause only supports fast acl types.
#??? See http://wiki.squid-cache.org/SquidFaq/SquidAcl for details.
#??? Using slow acl types may result in server crashes
#
#??? Without this option, all server certificate validation errors
#??? terminate the transaction to protect Squid and the client.
#
#??? SQUID_X509_V_ERR_INFINITE_VALIDATION error cannot be bypassed
#??? but should not happen unless your OpenSSL library is buggy.
#
#??? SECURITY WARNING:
#??? ??? Bypassing validation errors is dangerous because an
#??? ??? error usually implies that the server cannot be trusted
#??? ??? and the connection may be insecure.
#
#??? See also: sslproxy_flags and DONT_VERIFY_PEER.
#Default:
# Server certificate errors terminate the transaction.

#? TAG: sslproxy_cert_sign
#
#??????? sslproxy_cert_sign <signing algorithm> acl ...
#
#??????? The following certificate signing algorithms are supported:
#
#??? ?? signTrusted
#??? ??? Sign using the configured CA certificate which is usually
#??? ??? placed in and trusted by end-user browsers. This is the
#??? ??? default for trusted origin server certificates.
#
#??? ?? signUntrusted
#??? ??? Sign to guarantee an X509_V_ERR_CERT_UNTRUSTED browser error.
#??? ??? This is the default for untrusted origin server certificates
#??? ??? that are not self-signed (see ssl::certUntrusted).
#
#??? ?? signSelf
#??? ??? Sign using a self-signed certificate with the right CN to
#??? ??? generate a X509_V_ERR_DEPTH_ZERO_SELF_SIGNED_CERT error in the
#??? ??? browser. This is the default for self-signed origin server
#??? ??? certificates (see ssl::certSelfSigned).
#
#??? This clause only supports fast acl types.
#
#??? When sslproxy_cert_sign acl(s) match, Squid uses the corresponding
#??? signing algorithm to generate the certificate and ignores all
#??? subsequent sslproxy_cert_sign options (the first match wins). If no
#??? acl(s) match, the default signing algorithm is determined by errors
#??? detected when obtaining and validating the origin server certificate.
#
#??? WARNING: SQUID_X509_V_ERR_DOMAIN_MISMATCH and
ssl:certDomainMismatch can
#??? be used with sslproxy_cert_adapt, but if and only if Squid is bumping a
#??? CONNECT request that carries a domain name. In all other cases (CONNECT
#??? to an IP address or an intercepted SSL connection), Squid cannot detect
#??? the domain mismatch at certificate generation time when
#??? bump-server-first is used.
#Default:
# none

and, may be, this:

#? TAG: sslproxy_cert_adapt
#???
#??? sslproxy_cert_adapt <adaptation algorithm> acl ...
#
#??? The following certificate adaptation algorithms are supported:
#
#??? ?? setValidAfter
#??? ??? Sets the "Not After" property to the "Not After" property of
#??? ??? the CA certificate used to sign generated certificates.
#
#??? ?? setValidBefore
#??? ??? Sets the "Not Before" property to the "Not Before" property of
#??? ??? the CA certificate used to sign generated certificates.
#
#??? ?? setCommonName or setCommonName{CN}
#??? ??? Sets Subject.CN property to the host name specified as a
#??? ??? CN parameter or, if no explicit CN parameter was specified,
#??? ??? extracted from the CONNECT request. It is a misconfiguration
#??? ??? to use setCommonName without an explicit parameter for
#??? ??? intercepted or tproxied SSL connections.
#??? ???
#??? This clause only supports fast acl types.
#
#??? Squid first groups sslproxy_cert_adapt options by adaptation algorithm.
#??? Within a group, when sslproxy_cert_adapt acl(s) match, Squid uses the
#??? corresponding adaptation algorithm to generate the certificate and
#??? ignores all subsequent sslproxy_cert_adapt options in that algorithm's
#??? group (i.e., the first match wins within each algorithm group). If no
#??? acl(s) match, the default mimicking action takes place.
#
#??? WARNING: SQUID_X509_V_ERR_DOMAIN_MISMATCH and
ssl:certDomainMismatch can
#??? be used with sslproxy_cert_adapt, but if and only if Squid is bumping a
#??? CONNECT request that carries a domain name. In all other cases (CONNECT
#??? to an IP address or an intercepted SSL connection), Squid cannot detect
#??? the domain mismatch at certificate generation time when
#??? bump-server-first is used.
#Default:
# none




16.03.2018 19:09, Nicolas Kovacs ?????:
> Le 16/03/2018 ? 13:43, Yuri a ?crit :
>> I guess better way to do this is create special ACL to catch exactly 
>> certificate error and then redirect by 302 using deny_info to proxy
>> page with explanation and certificate.
> This sounds like the way to go.
>
> I just removed the root certificate from one of the clients and then
> tried to open a few HTTPS sites. Invariably, I get the follwoing error
> code :
>
> SEC_ERROR_UNKNOWN_ISSUER
Keep in mind: this is significantly wide SSL error. It can occurs also
on some sites with self-signed certs, or, in case of site's root CA is
not in your proxy certificate bundle.
>
> So how would I tell Squid in its own syntax to go to
> http://nestor.microlinux.lan when it encounters such an error ? Is this
> a trivial task, or more complicated to put in practice ?
Mmmmmmmmm. It seems not too complicated, however, AFAIK, nobody done
this yet.
>
> BTW, this would be the last piece in my puzzle, and my installation
> would be perfect if I got this to work.
>
> Cheers,
>
> Niki
>

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180316/7e23fb95/attachment.sig>

From peedee.nick at gmail.com  Fri Mar 16 17:41:30 2018
From: peedee.nick at gmail.com (Patrick Nick)
Date: Fri, 16 Mar 2018 18:41:30 +0100
Subject: [squid-users] Squid as Kerberos client?
In-Reply-To: <d00622d2-31c3-d1ab-6b17-08c9f7fca851@treenet.co.nz>
References: <CAH+7_B0r_1bHkrKrJfc=DxXaQEwONm5famaNJHY_KofD-dx1dg@mail.gmail.com>
 <97465F79-7694-4FD8-A50B-9DF67424F8D4@data-core.org>
 <CAH+7_B3hRJQ0sGh0XR+ft7MDSLiuE63x219F8baXGp1xRnn=eg@mail.gmail.com>
 <0A34C068-BF23-4AAA-B33F-C83529B625C7@data-core.org>
 <CAH+7_B2R6dti3UjtMr4k12WijbxBVYamPQxpOToKrEdhjOpJ+w@mail.gmail.com>
 <4d473798-898f-cdf4-73b1-970fe998e7d6@treenet.co.nz>
 <CAH+7_B06jvV7tvzcuSHEhYBdDdg9BZ=tR5H918zS35+RykVZ0A@mail.gmail.com>
 <d00622d2-31c3-d1ab-6b17-08c9f7fca851@treenet.co.nz>
Message-ID: <CAH+7_B1NqZ_DGQTfBXA17BcDE4BAWPgAYcXKH9BhBUQf-4fnXQ@mail.gmail.com>

Thank you. It doesn't seem that the "originserver" makes a difference to
may case though.

I was able to resolve my issue after I understood that I forgot to pay
attention to cookies. The API expects the client to use cookies, which I
didn't do until now, which resulted in a continuous "401 Unauthorized" loop.

I have more problems but will start a separate question for that.

On Thu, Mar 15, 2018 at 12:53 PM, Amos Jeffries <squid3 at treenet.co.nz>
wrote:

> On 15/03/18 23:52, Patrick Nick wrote:
> > Thanks Amos, this sounded promising. Unfortunately the behavior I
> > observe is not what I expect.
> > So I added the following config:
> >
> > cache_peer my.company.webserver.net <http://my.company.webserver.net>
> > parent 8081 0 no-query login=NEGOTIATE:myPrincipal
> >
>
> Since this is an origin server and not a proxy it requires the
> "originserver" option as well.
>
>
> Amos
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180316/cc6021f4/attachment.htm>

From peedee.nick at gmail.com  Fri Mar 16 17:57:21 2018
From: peedee.nick at gmail.com (Patrick Nick)
Date: Fri, 16 Mar 2018 18:57:21 +0100
Subject: [squid-users] Intercepting proxy creates forwading loop
Message-ID: <CAH+7_B2odG91TaLPmqEdJgiZ1rDTxyM2_dELu6S8tpUdQEOtaA@mail.gmail.com>

Hello list,

I have resolved first problem about cache_peer using Kerberos
authentication. Now I want to make that setup transparent/intercepting.
Keep in mind that my situation does NOT involve browsers or port 80 at any
point, it's a pure machine-to-machine API communication.

I have added the "intercept" keyword to my config, here is a part of my
config that seems relevant:

http_port 3128 intercept
cache_peer my.company.webserver.net parent 8081 0 no-query
login=NEGOTIATE:myPrincipal originserver

And here is how I test it by using the rather new curl option "--connect-to"
which allows to send the request to a different host:port than specified in
the "Host:" http header:

curl -b ~/cookies.txt -c ~/cookies.txt -H'Content-Type: application/json' "
http://my.company.host.net:8081/status" --connect-to "
my.company.host.net:8081:my.squid.host.net:3128" -v

The result is always "HTTP/1.1 403 Forbidden" and in the logs I see "WARNING:
Forwarding loop detected for:".

I don't understand how a loop can form. I've seen many tutorials talking
about using iptables to redirect traffic to a different port, but I don't
think that I need that, since the curl-option should take care of that.
I assume that squid should receive the request and then send it on to
what's specified in the "Host:" header. Is this wrong? What kind of loop is
forming here and how do I break it?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180316/f47baed0/attachment.htm>

From yvoinov at gmail.com  Fri Mar 16 23:08:32 2018
From: yvoinov at gmail.com (Yuri)
Date: Sat, 17 Mar 2018 05:08:32 +0600
Subject: [squid-users] Intercepting proxy creates forwading loop
In-Reply-To: <CAH+7_B2odG91TaLPmqEdJgiZ1rDTxyM2_dELu6S8tpUdQEOtaA@mail.gmail.com>
References: <CAH+7_B2odG91TaLPmqEdJgiZ1rDTxyM2_dELu6S8tpUdQEOtaA@mail.gmail.com>
Message-ID: <9f2da2d9-29c8-8d75-665d-29419c4c28ac@gmail.com>

http://www.squid-cache.org/mail-archive/squid-users/201105/0264.html

http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-1-intercept-Forwarding-loop-detected-for-td4669756.html

https://www.google.com/search?q=Squid+forwarding-loop

This can helps?


16.03.2018 23:57, Patrick Nick ?????:
> Hello list,?
>
> I have resolved first problem about cache_peer using Kerberos
> authentication. Now I want to make that setup
> transparent/intercepting. Keep in mind that my situation does NOT
> involve browsers or port 80 at any point, it's a pure
> machine-to-machine API communication.
>
> I have added the "intercept" keyword to my config, here is a part of
> my config that seems relevant:
>
> http_port 3128 intercept
> cache_peer?my.company.webserver.net
> <http://my.company.webserver.net/>?parent 8081 0 no-query
> login=NEGOTIATE:myPrincipal originserver
>
> And here is how I test it by using the rather new curl option
> "--connect-to" which allows to send the request to a different
> host:port than specified in the "Host:" http header:
>
> curl -b ~/cookies.txt -c ~/cookies.txt -H'Content-Type:
> application/json' "http://my.company.host.net:8081/status"
> --connect-to "my.company.host.net:8081
> <http://my.company.host.net:8081>:my.squid.host.net:3128
> <http://my.squid.host.net:3128>" -v
>
> The result is always "HTTP/1.1 403 Forbidden" and in the logs I see
> "WARNING: Forwarding loop detected for:".
>
> I don't understand how a loop can form. I've seen many tutorials
> talking about using iptables to redirect traffic to a different port,
> but I don't think that I need that, since the curl-option should take
> care of that.
> I assume that squid should receive the request and then send it on to
> what's specified in the "Host:" header. Is this wrong? What kind of
> loop is forming here and how do I break it?
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180317/52a896c3/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180317/52a896c3/attachment.sig>

From kirup at aism.edu.my  Sat Mar 17 11:22:44 2018
From: kirup at aism.edu.my (Kiru Pananthan)
Date: Sat, 17 Mar 2018 19:22:44 +0800
Subject: [squid-users] Reverse proxy is not responding
Message-ID: <CAEax4xXNDq3VKTBprtSFBhdhm56CeouTFRnH2VDuXDWiOcbS3g@mail.gmail.com>

Dear Team

squid  3.1.20 reverse proxy server running on Linux Debian, This has been
set up a few years before and working fine.

Recently we are planning to host a new site on our local windows server and
setup for external access using squid proxy, so we tried to modify by
adding the new site info in the squid config file for external access.

After modifying the config file, we are able to access the site externally
but the site didn't redirect automatically to HTTPS like other sites we set
up before. so I tried to remove the code lines I added in the config file
to restore it to the original setting, but now all our existing site are
not redirecting automatically to https.

Any idea what went wrong and how this can be refixed.

I have tried to restart the Squid service and also the server, still not
working as expected





-- 

Kind regards,

Kirupananthan Yogalingam,
ICT Manager

-- 
*Confidentiality Disclaimer:* This e-mail and any attachments are 
confidential and intended solely for the intended addressee and may also be 
privileged or exempt from disclosure under applicable law. If you are not 
the intended addressee, or have received this e-mail in error, please 
notify the sender immediately, delete it from your system and do not copy, 
disclose, distribute or otherwise act in reliance upon any part of this 
e-mail or its attachments. Australian International School Malaysia and all 
affiliates under Taylor's Education Group  does not accept responsibility 
for any loss arising from unauthorised access to, or interference with, any 
internet communications by any third party in reliance to this email, or 
from the transmission of any viruses. Please note that any views or 
opinions presented in this email are solely those of the author and do not 
necessarily represent those of   Australian International School Malaysia and 
all affiliates under Taylor's Education Group. Replies to this e-mail may 
be monitored by   Australian International School Malaysia and all 
affiliates under Taylor's Education Group for operational or business 
reasons.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180317/13a2a12d/attachment.htm>

From squid3 at treenet.co.nz  Sat Mar 17 13:02:16 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Mar 2018 02:02:16 +1300
Subject: [squid-users] Intercepting proxy creates forwading loop
In-Reply-To: <CAH+7_B2odG91TaLPmqEdJgiZ1rDTxyM2_dELu6S8tpUdQEOtaA@mail.gmail.com>
References: <CAH+7_B2odG91TaLPmqEdJgiZ1rDTxyM2_dELu6S8tpUdQEOtaA@mail.gmail.com>
Message-ID: <404dd128-a3a2-79f2-3bea-e810162f9fa7@treenet.co.nz>

On 17/03/18 06:57, Patrick Nick wrote:
> Hello list,?
> 
> I have resolved first problem about cache_peer using Kerberos
> authentication. Now I want to make that setup transparent/intercepting.
> Keep in mind that my situation does NOT involve browsers or port 80 at
> any point, it's a pure machine-to-machine API communication.
> 
> I have added the "intercept" keyword to my config, here is a part of my
> config that seems relevant:
> 
> http_port 3128 intercept
> cache_peer?my.company.webserver.net
> <http://my.company.webserver.net/>?parent 8081 0 no-query
> login=NEGOTIATE:myPrincipal originserver
> 
> And here is how I test it by using the rather new curl option
> "--connect-to" which allows to send the request to a different host:port
> than specified in the "Host:" http header:
> 
> curl -b ~/cookies.txt -c ~/cookies.txt -H'Content-Type:
> application/json' "http://my.company.host.net:8081/status" --connect-to
> "my.company.host.net:8081
> <http://my.company.host.net:8081>:my.squid.host.net:3128
> <http://my.squid.host.net:3128>" -v
> 
> The result is always "HTTP/1.1 403 Forbidden" and in the logs I see
> "WARNING: Forwarding loop detected for:".
> 
> I don't understand how a loop can form. I've seen many tutorials talking
> about using iptables to redirect traffic to a different port, but I
> don't think that I need that, since the curl-option should take care of
> that.

You absolutely DO need the iptables part, because Squid "intercept" is
integrated with the machines NAT system. Squid outbound connection for
intercepted traffic prefers the same IP:port the client used (aka
transparency) to avoid security issues like CVE-2009-0801.

Since curl did a "connect-to" to Squid's IP:port directly and
my.squid.host.net != my.company.host.net ... Squid copies that with a
connection to my.squid.host.net:3128 and sends the request for
my.company.host.net:8081 there. Et Voila`, Loop.


> I assume that squid should receive the request and then send it on to
> what's specified in the "Host:" header. Is this wrong?

Sort of wrong yes. Squid uses the TCP connection IP:port with
modification to undo NAT in accordance with the local machines NAT
records. Host header (and thus caching which relies on it) is only used
if it correlates reliably with those details.


> What kind of loop is forming here and how do I break it?

A transparent forwarding loop.

Add the iptables part of the config and send test requests *exactly* as
the clients would in their real traffic. No shortcuts like curl
--connect-to, unless that is actually how the client connects.


Amos


From squid3 at treenet.co.nz  Sat Mar 17 13:12:01 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Mar 2018 02:12:01 +1300
Subject: [squid-users] Reverse proxy is not responding
In-Reply-To: <CAEax4xXNDq3VKTBprtSFBhdhm56CeouTFRnH2VDuXDWiOcbS3g@mail.gmail.com>
References: <CAEax4xXNDq3VKTBprtSFBhdhm56CeouTFRnH2VDuXDWiOcbS3g@mail.gmail.com>
Message-ID: <980bfae0-42c6-7030-ef31-e7842ca1f1b9@treenet.co.nz>

On 18/03/18 00:22, Kiru Pananthan wrote:
> Dear Team
> 
> squid ?3.1.20?reverse proxy server running on Linux Debian, This has
> been set up?a few years before and working fine.
> 
> Recently we are planning to host a new site on our local windows server
> and setup for external access using squid proxy, so we tried to modify
> by adding the new site info in the squid config file for external access.
> 
> After modifying the config file, we are able to access the site
> externally but the site didn't redirect automatically to HTTPS like
> other sites we set up before. so I tried to remove the code lines I
> added in the config file to restore it to the original setting, but now
> all our existing site are not redirecting automatically to https.
> 
> Any idea what went wrong and how this can be refixed.

We will need to see what your config file contains to answer those
questions. All I can tell from this description is that probably you
missed a small vital item somewhere.

Amos


From squid3 at treenet.co.nz  Sat Mar 17 13:47:48 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Mar 2018 02:47:48 +1300
Subject: [squid-users] Squid as Kerberos client?
In-Reply-To: <CAH+7_B1NqZ_DGQTfBXA17BcDE4BAWPgAYcXKH9BhBUQf-4fnXQ@mail.gmail.com>
References: <CAH+7_B0r_1bHkrKrJfc=DxXaQEwONm5famaNJHY_KofD-dx1dg@mail.gmail.com>
 <97465F79-7694-4FD8-A50B-9DF67424F8D4@data-core.org>
 <CAH+7_B3hRJQ0sGh0XR+ft7MDSLiuE63x219F8baXGp1xRnn=eg@mail.gmail.com>
 <0A34C068-BF23-4AAA-B33F-C83529B625C7@data-core.org>
 <CAH+7_B2R6dti3UjtMr4k12WijbxBVYamPQxpOToKrEdhjOpJ+w@mail.gmail.com>
 <4d473798-898f-cdf4-73b1-970fe998e7d6@treenet.co.nz>
 <CAH+7_B06jvV7tvzcuSHEhYBdDdg9BZ=tR5H918zS35+RykVZ0A@mail.gmail.com>
 <d00622d2-31c3-d1ab-6b17-08c9f7fca851@treenet.co.nz>
 <CAH+7_B1NqZ_DGQTfBXA17BcDE4BAWPgAYcXKH9BhBUQf-4fnXQ@mail.gmail.com>
Message-ID: <384e1ff9-6071-74eb-c79c-27ecf2e7b1ad@treenet.co.nz>

On 17/03/18 06:41, Patrick Nick wrote:
> Thank you. It doesn't seem that the "originserver" makes a difference to
> may case though.
> 
> I was able to resolve my issue after I understood that I forgot to pay
> attention to cookies. The API expects the client to use cookies, which I
> didn't do until now, which resulted in a continuous "401 Unauthorized" loop.
> 

Ah, Cookies. The bane of the Internet. They can be dealt with, but you
are not going to like the difficulty level.

Your choices AFAIK (in order of easiest to seriously tricky) are to
write an eCAP module, ICAP service, or custom external ACL helper(s)
with fairly complex squid.conf settings to use the latter.

Amos


From squid3 at treenet.co.nz  Sun Mar 18 10:20:22 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Mar 2018 23:20:22 +1300
Subject: [squid-users] [squid-announce] Squid 4.0.24 beta is available
Message-ID: <1d461c24-6ddd-fb99-1e8e-0c719c33e219@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.0.24 release!


This release is a bug fix release resolving several issues found in the
prior Squid releases.


The major changes to be aware of:


* GnuTLS support for https_port

When built with GnuTLS instead of OpenSSL this Squid is now able to open
listening ports and receive HTTPS traffic in explicit proxy or reverse
proxy modes. SSL-Bump and intercept proxy are not yet supported.

With GnuTLS comes the ability to configure multiple static (or wildcard)
certificates for a single https_port. This ability is sadly not shared
by OpenSSL.

WARNING: A regression in handling of the cafile= option has been found
in this release. It may be resolved by combining the CA chain into the
PEM file configured with cert=.

With the new multi-cert support combining the certificate and its CA
chain in one PEM file becomes the new Best Practice configuration to
ensure the CA chain is associated only with the relevant certificate(s)
and keys.


* Fix SSL-Bump with an authentication type other than the Basic

This improves the Squid behaviour working with SSL-Bump'ed CONNECT
messages when the original CONNECT contained authentication credentials.

Earlier releases would unconditionally treat all such bumped traffic as
successfully authenticated. When a configuration used proxy_auth ACLs to
check access on a per-user basis or for methods other than the Basic
scheme that could incorrectly allow access to resources intended to be
hidden to some users.

This release now processes the proxy_auth ACL checks normally, but with
the CONNECT credentials so allow/deny can work as intended. ACL results
requiring re-authentication should act as an ACL non-match instead of
generating a re-authenticate challenge.


* Improved compiler support

This release fixes a number of compile errors seen with GCC-7 and
Clang-3.9 versions across several operating systems.

There are still a number of outstanding issues when building with the
latest GCC-8 versions. Fixes for those are expected to be in the next
release.



  All users of Squid-4.x are urged to upgrade to this release as
  soon as possible.

  All users of Squid-3 are encouraged to test this release out and plan
  for upgrades where possible.


See the ChangeLog for the full list of changes in this and earlier
releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

  http://www.squid-cache.org/Versions/v4/
  ftp://ftp.squid-cache.org/pub/squid/
  ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

  http://www.squid-cache.org/Download/http-mirrors.html
  http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
  http://bugs.squid-cache.org/


Amos Jeffries
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From kirup at aism.edu.my  Sun Mar 18 12:34:48 2018
From: kirup at aism.edu.my (Kiru Pananthan)
Date: Sun, 18 Mar 2018 20:34:48 +0800
Subject: [squid-users] squid-users Digest, Vol 43, Issue 33
In-Reply-To: <mailman.3.1521374401.21029.squid-users@lists.squid-cache.org>
References: <mailman.3.1521374401.21029.squid-users@lists.squid-cache.org>
Message-ID: <CAEax4xXvNbcusv92X-X6=FiAABK26Ri+PzuJpNsKc9K9JzWu-Q@mail.gmail.com>

Hi Amos

Thanks for your reply, here I have attached the squid config file link for
your view, do I need to clear the squid cache in the squid server for it
works?

Config file url
https://goo.gl/Q4a749

-- 
*Confidentiality Disclaimer:* This e-mail and any attachments are 
confidential and intended solely for the intended addressee and may also be 
privileged or exempt from disclosure under applicable law. If you are not 
the intended addressee, or have received this e-mail in error, please 
notify the sender immediately, delete it from your system and do not copy, 
disclose, distribute or otherwise act in reliance upon any part of this 
e-mail or its attachments. Australian International School Malaysia and all 
affiliates under Taylor's Education Group  does not accept responsibility 
for any loss arising from unauthorised access to, or interference with, any 
internet communications by any third party in reliance to this email, or 
from the transmission of any viruses. Please note that any views or 
opinions presented in this email are solely those of the author and do not 
necessarily represent those of   Australian International School Malaysia and 
all affiliates under Taylor's Education Group. Replies to this e-mail may 
be monitored by   Australian International School Malaysia and all 
affiliates under Taylor's Education Group for operational or business 
reasons.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180318/b435475b/attachment.htm>

From kirup at aism.edu.my  Sun Mar 18 12:48:25 2018
From: kirup at aism.edu.my (Kiru Pananthan)
Date: Sun, 18 Mar 2018 20:48:25 +0800
Subject: [squid-users] Reverse proxy is not responding
Message-ID: <CAEax4xXFrWb-E4-TA_fYWVS68w7c0=W8-fVBGSLvfTcaAHGmXQ@mail.gmail.com>

Hi Amos

Thanks for your reply, here I have attached the squid config file link for
your view, do I need to clear the squid cache in the squid server for it
works?

Config file url
https://goo.gl/Q4a749

-- 
*Confidentiality Disclaimer:* This e-mail and any attachments are 
confidential and intended solely for the intended addressee and may also be 
privileged or exempt from disclosure under applicable law. If you are not 
the intended addressee, or have received this e-mail in error, please 
notify the sender immediately, delete it from your system and do not copy, 
disclose, distribute or otherwise act in reliance upon any part of this 
e-mail or its attachments. Australian International School Malaysia and all 
affiliates under Taylor's Education Group  does not accept responsibility 
for any loss arising from unauthorised access to, or interference with, any 
internet communications by any third party in reliance to this email, or 
from the transmission of any viruses. Please note that any views or 
opinions presented in this email are solely those of the author and do not 
necessarily represent those of   Australian International School Malaysia and 
all affiliates under Taylor's Education Group. Replies to this e-mail may 
be monitored by   Australian International School Malaysia and all 
affiliates under Taylor's Education Group for operational or business 
reasons.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180318/7d343370/attachment.htm>

From squid3 at treenet.co.nz  Sun Mar 18 14:03:47 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 19 Mar 2018 03:03:47 +1300
Subject: [squid-users] Reverse proxy is not responding
In-Reply-To: <CAEax4xXFrWb-E4-TA_fYWVS68w7c0=W8-fVBGSLvfTcaAHGmXQ@mail.gmail.com>
References: <CAEax4xXFrWb-E4-TA_fYWVS68w7c0=W8-fVBGSLvfTcaAHGmXQ@mail.gmail.com>
Message-ID: <66af9ca6-55f7-f6d5-a063-29e08a7ef899@treenet.co.nz>

On 19/03/18 01:48, Kiru Pananthan wrote:
> Hi Amos
> 
> Thanks for your reply, here I have attached the squid config file link
> for your view, do I need to clear the squid cache in the squid server
> for it works?

You do not have any persistent cache enabled on that proxy. Restarting
the proxy is sufficient to wipe the memory cache.


> 
> Config file url
> https://goo.gl/Q4a749

What you have there is the documentation file for squid.conf. Please
remove all the empty line and comments (line beginning with #).
Then you and we will be able to see what the config actually is.



>From what I could see there all your cache_peer and cache_peer_access
lines are a bit muddled up. Compare what you have there to the example
it seems to have been original copy-n-pasted from:
 <https://wiki.squid-cache.org/ConfigExamples/Reverse/MultipleWebservers>


Also, your cache_peer lines for server_5 and server_7 are identical -
same IP:port and other parameters. If that 172.23.2.99:80 is the correct
destination for both the sites_server7 and sites_server_5 domains, then
you only need one cache_peer definition.
 Otherwise that is probably your problem right there.


Amos


From kirup at aism.edu.my  Sun Mar 18 14:22:26 2018
From: kirup at aism.edu.my (Kiru Pananthan)
Date: Sun, 18 Mar 2018 22:22:26 +0800
Subject: [squid-users] Reverse proxy is not responding
In-Reply-To: <66af9ca6-55f7-f6d5-a063-29e08a7ef899@treenet.co.nz>
References: <CAEax4xXFrWb-E4-TA_fYWVS68w7c0=W8-fVBGSLvfTcaAHGmXQ@mail.gmail.com>
 <66af9ca6-55f7-f6d5-a063-29e08a7ef899@treenet.co.nz>
Message-ID: <CAEax4xUUnXi_B+C71TbcKYr5p_Es1m1maBXZgoc9Ppc7fwp6YA@mail.gmail.com>

Hi Amos

Thanks for your reply,

I have restarted the squid service using the command  # /etc/init.d/squid3
restart and also reboot the Linux server too. but still, the problem exists.

I have removed the empty and # command line in the document for your
review. can you please check now and provide me with some guidance

Config file URL
 https://goo.gl/Q4a749

-- 
*Confidentiality Disclaimer:* This e-mail and any attachments are 
confidential and intended solely for the intended addressee and may also be 
privileged or exempt from disclosure under applicable law. If you are not 
the intended addressee, or have received this e-mail in error, please 
notify the sender immediately, delete it from your system and do not copy, 
disclose, distribute or otherwise act in reliance upon any part of this 
e-mail or its attachments. Australian International School Malaysia and all 
affiliates under Taylor's Education Group  does not accept responsibility 
for any loss arising from unauthorised access to, or interference with, any 
internet communications by any third party in reliance to this email, or 
from the transmission of any viruses. Please note that any views or 
opinions presented in this email are solely those of the author and do not 
necessarily represent those of   Australian International School Malaysia and 
all affiliates under Taylor's Education Group. Replies to this e-mail may 
be monitored by   Australian International School Malaysia and all 
affiliates under Taylor's Education Group for operational or business 
reasons.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180318/a3efb9ac/attachment.htm>

From squid3 at treenet.co.nz  Sun Mar 18 18:57:18 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 19 Mar 2018 07:57:18 +1300
Subject: [squid-users] Reverse proxy is not responding
In-Reply-To: <CAEax4xUUnXi_B+C71TbcKYr5p_Es1m1maBXZgoc9Ppc7fwp6YA@mail.gmail.com>
References: <CAEax4xXFrWb-E4-TA_fYWVS68w7c0=W8-fVBGSLvfTcaAHGmXQ@mail.gmail.com>
 <66af9ca6-55f7-f6d5-a063-29e08a7ef899@treenet.co.nz>
 <CAEax4xUUnXi_B+C71TbcKYr5p_Es1m1maBXZgoc9Ppc7fwp6YA@mail.gmail.com>
Message-ID: <fe6922c8-471f-fb27-8221-7e0de7c31183@treenet.co.nz>

On 19/03/18 03:22, Kiru Pananthan wrote:
> Hi Amos
> 
> Thanks for your reply,
> 
> I have restarted the squid service using the command?#
> /etc/init.d/squid3 restart and also reboot the Linux server too. but
> still, the problem exists.
> *
> *
> I have removed the empty and # command line in the document for your
> review. can you please check now and provide me with some?guidance?
> 

Thanks. That one is easier to read.


The domains dvr1.* dvr2.* and dashboard.* are accepted into the proxy
(by the our_sites ACL) but have nowhere to go - no cache_peer with an
allow for them. I guess those are the domains which you are seeing
failures for?


Some further cleanups you can do:

It is now clear that "cache_peer access server_6 deny all" is referring
to a non-existent cache_peer. Not an issue, but you can remove that line
to simplify things further.


The https_port line is missing accel mode flag.
 - Also, 'vhost' option is deprecated in current Squid Virtual hosting
is on by default now.

Also, since these are reverse-proxy the *_port lines should really be
listening on the same ports the peers are using (eg port 80, 443 and
8443) to avoid weird issues with Host header relayed to peers with
unexpected port 3128 or 8443 values (as sent by the clients).
 I also notice that traffic arriving in the HTTPS port has a default
domain of bookings.* assigned but the only peer which is expecting
traffic on/from port 8443 is the one for library.* domain. It may be
worthwhile removing the defaultsite= option entirely.



You still have the muddled peer lines making that config hard to read.
By that I mean your "acl sites_server_*" definitions are grouped amidst
cache_peer* lines for a peer which that ACL has nothing to do with.
Re-ordering those would be useful for future maintenance.

Also, the issue with server_5 and server_7 being identical is still
there. It is even more clear now that they are truly duplicates in all
respects, from cache_peer line to the server_sites_* ACLs. One of them
should be removed.


Your custom http_access line should be placed at the spot which
currently says "http_access allow localhost".


In fact, what I recommend is to move the "http_access deny all" line
down below the cache_peer config block. Then you can use the
sites_server_N ACLs to do an "http_access allow sites_server_*" instead
of duplicating domain names in that our_sites ACL.
 This way you can be sure only the traffic which has a cache_peer to go
to is allowed into the proxy at all and the reverse: all traffic which
has a peer to go to is allowed. That may be helpful to avoid this
situation repeating in future.

Amos


From kirup at aism.edu.my  Sun Mar 18 22:22:47 2018
From: kirup at aism.edu.my (Kiru Pananthan)
Date: Mon, 19 Mar 2018 06:22:47 +0800
Subject: [squid-users] Reverse proxy is not responding
In-Reply-To: <fe6922c8-471f-fb27-8221-7e0de7c31183@treenet.co.nz>
References: <CAEax4xXFrWb-E4-TA_fYWVS68w7c0=W8-fVBGSLvfTcaAHGmXQ@mail.gmail.com>
 <66af9ca6-55f7-f6d5-a063-29e08a7ef899@treenet.co.nz>
 <CAEax4xUUnXi_B+C71TbcKYr5p_Es1m1maBXZgoc9Ppc7fwp6YA@mail.gmail.com>
 <fe6922c8-471f-fb27-8221-7e0de7c31183@treenet.co.nz>
Message-ID: <CAEax4xWNHiOXaxAjDoOtQ-7r_u3SvmdVbCL8g7hkvrPoG78Jfg@mail.gmail.com>

Hi Amos

Thanks for your time and the information you shared, Great. I Have modified
the line you have requested to remove, but few other points you have
highlighted I am unsure about it, as I am new to squid and coding, can you
please correct me on my question if possible.

1. I have removed the dvr 1 to dvr 4 from code

2. I have removed the "cache_peer access server_6 deny all"

3. Unsure about the  < The https_port line is missing accel mode flag. -
Also, 'vhost' option is deprecated in current Squid Virtual hosting is on
by default now. >
What changed i need to do for this ? need your help on this

4. defaultsite= option remove - Which line is this I need to removed

5. I have reordered the acl sites_server_

Config file URL
 https://goo.gl/Q4a749

-- 
*Confidentiality Disclaimer:* This e-mail and any attachments are 
confidential and intended solely for the intended addressee and may also be 
privileged or exempt from disclosure under applicable law. If you are not 
the intended addressee, or have received this e-mail in error, please 
notify the sender immediately, delete it from your system and do not copy, 
disclose, distribute or otherwise act in reliance upon any part of this 
e-mail or its attachments. Australian International School Malaysia and all 
affiliates under Taylor's Education Group  does not accept responsibility 
for any loss arising from unauthorised access to, or interference with, any 
internet communications by any third party in reliance to this email, or 
from the transmission of any viruses. Please note that any views or 
opinions presented in this email are solely those of the author and do not 
necessarily represent those of   Australian International School Malaysia and 
all affiliates under Taylor's Education Group. Replies to this e-mail may 
be monitored by   Australian International School Malaysia and all 
affiliates under Taylor's Education Group for operational or business 
reasons.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180319/5a31cb61/attachment.htm>

From g_sterg at yahoo.com  Sun Mar 18 23:17:18 2018
From: g_sterg at yahoo.com (George S)
Date: Sun, 18 Mar 2018 23:17:18 +0000 (UTC)
Subject: [squid-users] http get request with body
References: <1189406584.2867449.1521415038487.ref@mail.yahoo.com>
Message-ID: <1189406584.2867449.1521415038487@mail.yahoo.com>

Hello folks. Need some help on this. I am not sure if it has been posted already a 100 times, so apologies for once more.
Having said that. I am in the process of deploying of a rest api layer which exposes among other things a path that entails a get request but with a heavy json body. Seems like the request breaks when going through squid.?
Is there a limitation on this front on squid as far as supporting this feature or is there possibly a configuration or component to make it possible?
-G
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180318/1c4dbbdf/attachment.htm>

From yvoinov at gmail.com  Sun Mar 18 23:36:51 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 19 Mar 2018 05:36:51 +0600
Subject: [squid-users] http get request with body
In-Reply-To: <1189406584.2867449.1521415038487@mail.yahoo.com>
References: <1189406584.2867449.1521415038487.ref@mail.yahoo.com>
 <1189406584.2867449.1521415038487@mail.yahoo.com>
Message-ID: <af9576ac-7b60-6b6a-5d79-3521f6dde156@gmail.com>

Hmmmmm, George.

In what direction your request tresspasses Squid?

Because of by default:

#? TAG: request_body_max_size??? (bytes)
#??? This specifies the maximum size for an HTTP request body.
#??? In other words, the maximum size of a PUT/POST request.
#??? A user who attempts to send a request with a body larger
#??? than this limit receives an "Invalid Request" error message.
#??? If you set this parameter to a zero (the default), there will
#??? be no limit imposed.
#
#??? See also client_request_buffer_max_size for an alternative
#??? limitation on client uploads which can be configured.
#Default:
# No limit.

and reply also:

#? TAG: reply_body_max_size??? size [acl acl...]
#??? This option specifies the maximum size of a reply body. It can be
#??? used to prevent users from downloading very large files, such as
#??? MP3's and movies. When the reply headers are received, the
#??? reply_body_max_size lines are processed, and the first line where
#??? all (if any) listed ACLs are true is used as the maximum body size
#??? for this reply.
#
#??? This size is checked twice. First when we get the reply headers,
#??? we check the content-length value.? If the content length value exists
#??? and is larger than the allowed size, the request is denied and the
#??? user receives an error message that says "the request or reply
#??? is too large." If there is no content-length, and the reply
#??? size exceeds this limit, the client's connection is just closed
#??? and they will receive a partial reply.
#
#??? WARNING: downstream caches probably can not detect a partial reply
#??? if there is no content-length header, so they will cache
#??? partial responses and give them out as hits.? You should NOT
#??? use this option if you have downstream caches.
#
#??? WARNING: A maximum size smaller than the size of squid's error messages
#??? will cause an infinite loop and crash squid. Ensure that the smallest
#??? non-zero value you use is greater that the maximum header size plus
#??? the size of your largest error page.
#
#??? If you set this parameter none (the default), there will be
#??? no limit imposed.
#
#??? Configuration Format is:
#??? ??? reply_body_max_size SIZE UNITS [acl ...]
#??? ie.
#??? ??? reply_body_max_size 10 MB
#
#Default:
# No limit is applied.

No limit.

May be, Squid's debug can light issue better?

19.03.2018 05:17, George S ?????:
> Hello folks. Need some help on this. I am not sure if it has been
> posted already a 100 times, so apologies for once more.
>
> Having said that. I am in the process of deploying of a rest api layer
> which exposes among other things a path that entails a get request but
> with a heavy json body. Seems like the request breaks when going
> through squid.?
>
> Is there a limitation on this front on squid as far as supporting this
> feature or is there possibly a configuration or component to make it
> possible?
>
> -G
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180319/74a7ff2f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180319/74a7ff2f/attachment.sig>

From yvoinov at gmail.com  Sun Mar 18 23:38:22 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 19 Mar 2018 05:38:22 +0600
Subject: [squid-users] http get request with body
In-Reply-To: <af9576ac-7b60-6b6a-5d79-3521f6dde156@gmail.com>
References: <1189406584.2867449.1521415038487.ref@mail.yahoo.com>
 <1189406584.2867449.1521415038487@mail.yahoo.com>
 <af9576ac-7b60-6b6a-5d79-3521f6dde156@gmail.com>
Message-ID: <1a5b18a7-035b-6ec9-fdd0-c4e591e96ede@gmail.com>

What else goes into head..... Hmmmmmmm......

May be timeout during long body downloading/uploading session.

Anyway, require additional info to make advice.


19.03.2018 05:36, Yuri ?????:
>
> Hmmmmm, George.
>
> In what direction your request tresspasses Squid?
>
> Because of by default:
>
> #? TAG: request_body_max_size??? (bytes)
> #??? This specifies the maximum size for an HTTP request body.
> #??? In other words, the maximum size of a PUT/POST request.
> #??? A user who attempts to send a request with a body larger
> #??? than this limit receives an "Invalid Request" error message.
> #??? If you set this parameter to a zero (the default), there will
> #??? be no limit imposed.
> #
> #??? See also client_request_buffer_max_size for an alternative
> #??? limitation on client uploads which can be configured.
> #Default:
> # No limit.
>
> and reply also:
>
> #? TAG: reply_body_max_size??? size [acl acl...]
> #??? This option specifies the maximum size of a reply body. It can be
> #??? used to prevent users from downloading very large files, such as
> #??? MP3's and movies. When the reply headers are received, the
> #??? reply_body_max_size lines are processed, and the first line where
> #??? all (if any) listed ACLs are true is used as the maximum body size
> #??? for this reply.
> #
> #??? This size is checked twice. First when we get the reply headers,
> #??? we check the content-length value.? If the content length value
> exists
> #??? and is larger than the allowed size, the request is denied and the
> #??? user receives an error message that says "the request or reply
> #??? is too large." If there is no content-length, and the reply
> #??? size exceeds this limit, the client's connection is just closed
> #??? and they will receive a partial reply.
> #
> #??? WARNING: downstream caches probably can not detect a partial reply
> #??? if there is no content-length header, so they will cache
> #??? partial responses and give them out as hits.? You should NOT
> #??? use this option if you have downstream caches.
> #
> #??? WARNING: A maximum size smaller than the size of squid's error
> messages
> #??? will cause an infinite loop and crash squid. Ensure that the smallest
> #??? non-zero value you use is greater that the maximum header size plus
> #??? the size of your largest error page.
> #
> #??? If you set this parameter none (the default), there will be
> #??? no limit imposed.
> #
> #??? Configuration Format is:
> #??? ??? reply_body_max_size SIZE UNITS [acl ...]
> #??? ie.
> #??? ??? reply_body_max_size 10 MB
> #
> #Default:
> # No limit is applied.
>
> No limit.
>
> May be, Squid's debug can light issue better?
>
> 19.03.2018 05:17, George S ?????:
>> Hello folks. Need some help on this. I am not sure if it has been
>> posted already a 100 times, so apologies for once more.
>>
>> Having said that. I am in the process of deploying of a rest api
>> layer which exposes among other things a path that entails a get
>> request but with a heavy json body. Seems like the request breaks
>> when going through squid.?
>>
>> Is there a limitation on this front on squid as far as supporting
>> this feature or is there possibly a configuration or component to
>> make it possible?
>>
>> -G
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> -- 
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180319/25ed2b6b/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180319/25ed2b6b/attachment.sig>

From squid3 at treenet.co.nz  Sun Mar 18 23:50:29 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 19 Mar 2018 12:50:29 +1300
Subject: [squid-users] Reverse proxy is not responding
In-Reply-To: <CAEax4xWNHiOXaxAjDoOtQ-7r_u3SvmdVbCL8g7hkvrPoG78Jfg@mail.gmail.com>
References: <CAEax4xXFrWb-E4-TA_fYWVS68w7c0=W8-fVBGSLvfTcaAHGmXQ@mail.gmail.com>
 <66af9ca6-55f7-f6d5-a063-29e08a7ef899@treenet.co.nz>
 <CAEax4xUUnXi_B+C71TbcKYr5p_Es1m1maBXZgoc9Ppc7fwp6YA@mail.gmail.com>
 <fe6922c8-471f-fb27-8221-7e0de7c31183@treenet.co.nz>
 <CAEax4xWNHiOXaxAjDoOtQ-7r_u3SvmdVbCL8g7hkvrPoG78Jfg@mail.gmail.com>
Message-ID: <689510d1-1183-4345-d073-59505c59a2b6@treenet.co.nz>

On 19/03/18 11:22, Kiru Pananthan wrote:
> Hi Amos
> 
> Thanks for your time and the information you shared, Great. I Have
> modified the line you have requested to remove, but few other points you
> have highlighted I am unsure about it, as I am new to squid and coding,
> can you please correct me on my question if possible.?
> 
> 1. I have removed the dvr 1 to dvr?4 from code
> 

Okay, that leaves the dashboard.* domain with that problem.

>
> 3. Unsure about the? < The https_port line is missing accel mode flag. -
> Also, 'vhost' option is deprecated in current Squid Virtual hosting is
> on by default now. >?
> What changed i need to do for this ??need your help on this

Add 'accel' after the port number on the https_port line and remove
vhost from both *_port lines.

> 
> 4. defaultsite= option remove - Which line is this I need to removed
> 

On the end of the https_port line.


> 5. I have reordered the?acl sites_server_
> 

Those look different but still all out of place and worse than before
now some ACLs are undefined before first use.

For example look at all the lines containing "server_2" - they should
all be together like this:

  cache_peer ... name=server_2
  acl sites_server_2 ...
  http_access allow sites_server_2
  cache_peer_access server_2 allow sites_server_2

* 'acl' line must go above both *_access lines that mention it.
* 'cache_peer' line must go above all 'cache_peer_access' lines that
mention it.


Please also run "squid -k parse" and see if it displays any ERROR or
FATAL issues when changing the config file. This version should have
found some FATAL issues with those ACL definitions.

Amos


From kirup at aism.edu.my  Mon Mar 19 06:13:11 2018
From: kirup at aism.edu.my (Kiru Pananthan)
Date: Mon, 19 Mar 2018 06:13:11 +0000
Subject: [squid-users] Reverse proxy is not responding
In-Reply-To: <689510d1-1183-4345-d073-59505c59a2b6@treenet.co.nz>
References: <CAEax4xXFrWb-E4-TA_fYWVS68w7c0=W8-fVBGSLvfTcaAHGmXQ@mail.gmail.com>
 <66af9ca6-55f7-f6d5-a063-29e08a7ef899@treenet.co.nz>
 <CAEax4xUUnXi_B+C71TbcKYr5p_Es1m1maBXZgoc9Ppc7fwp6YA@mail.gmail.com>
 <fe6922c8-471f-fb27-8221-7e0de7c31183@treenet.co.nz>
 <CAEax4xWNHiOXaxAjDoOtQ-7r_u3SvmdVbCL8g7hkvrPoG78Jfg@mail.gmail.com>
 <689510d1-1183-4345-d073-59505c59a2b6@treenet.co.nz>
Message-ID: <CAEax4xX3PGiiMaS_O+F9tefJ00CZNtw31u73BESpWPY0cxSANw@mail.gmail.com>

Hi Amos

I have removed *. dashboard and also timetable which is not in use.

I have added the accel after port number and removed vhost as per your
advice. Can you check the file now, am I good to go. I have not yet run the
query  "squid -k parse" , later will run it and update you on the outcome.
I need to update the config file in server once your verify the config file
for me to run the query

So basically I set this config file for below url, All this should able to
access through https by auto redirec from http to https.

Portal.aism.edu.my
Helpdesk.aism.edu.my
Booking.aism.edu.my


Config file URL
 https://goo.gl/Q4a749

>
> --

Kind regards,

Kirupananthan Yogalingam,
ICT Manager
----------------------------------------------------------------------------------------------------------
Australian International School Malaysia (AISM)
No.22 Jalan Anggerik,
The Mines Resort City,
43300 Seri Kembangan,
Selangor, Malaysia.



*T:* +60 3 8949 5000 *F*: +60 3 8949 5100
*E*: hod.ict at aism.edu.my *W*: http://www.aism.edu.my/
*Direct Line*: +60-3-8949 5055
----------------------------------------------------------------------------------------------------------

<https://www.facebook.com/aismalaysia>
<https://www.facebook.com/aismalaysia>
<https://www.facebook.com/aismalaysia>
<https://www.facebook.com/aismalaysia>
<https://www.facebook.com/aismalaysia>
<https://www.facebook.com/aismalaysia>
<https://www.facebook.com/aismalaysia>
<https://www.facebook.com/aismalaysia>
<http://www.youtube.com/user/AISMvideos>
<http://www.youtube.com/user/AISMvideos>
<http://www.youtube.com/user/AISMvideos>
<http://www.youtube.com/user/AISMvideos>
<http://www.youtube.com/user/AISMvideos>
<http://www.youtube.com/user/AISMvideos>
<http://www.youtube.com/user/AISMvideos> <https://twitter.com/AISMalaysia/>
<https://twitter.com/AISMalaysia/> <https://twitter.com/AISMalaysia/>
<https://twitter.com/AISMalaysia/> <https://twitter.com/AISMalaysia/>
<https://twitter.com/AISMalaysia/> <https://twitter.com/AISMalaysia/>
<http://www.aism.edu.my/virtualtour> <http://www.aism.edu.my/virtualtour>
<http://www.aism.edu.my/virtualtour> <http://www.aism.edu.my/virtualtour>
<http://www.aism.edu.my/virtualtour> <http://www.aism.edu.my/virtualtour>
<http://www.aism.edu.my/virtualtour>


<https://www.aism.edu.my/open-week/>

-- 
*Confidentiality Disclaimer:* This e-mail and any attachments are 
confidential and intended solely for the intended addressee and may also be 
privileged or exempt from disclosure under applicable law. If you are not 
the intended addressee, or have received this e-mail in error, please 
notify the sender immediately, delete it from your system and do not copy, 
disclose, distribute or otherwise act in reliance upon any part of this 
e-mail or its attachments. Australian International School Malaysia and all 
affiliates under Taylor's Education Group  does not accept responsibility 
for any loss arising from unauthorised access to, or interference with, any 
internet communications by any third party in reliance to this email, or 
from the transmission of any viruses. Please note that any views or 
opinions presented in this email are solely those of the author and do not 
necessarily represent those of   Australian International School Malaysia and 
all affiliates under Taylor's Education Group. Replies to this e-mail may 
be monitored by   Australian International School Malaysia and all 
affiliates under Taylor's Education Group for operational or business 
reasons.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180319/712e8df2/attachment.htm>

From t.aanoop.s at gmail.com  Mon Mar 19 10:03:51 2018
From: t.aanoop.s at gmail.com (Anoop Sreedharan)
Date: Mon, 19 Mar 2018 15:33:51 +0530
Subject: [squid-users] Volume quota management availablity
Message-ID: <CACy0pi3DKQ8BV8H3LmTYyRfkGmrtQErY5fm0GjTH57GU2L_iuA@mail.gmail.com>

Dear Team,
We have an IT environment catering to educational institute wherein we have
approx more than 1000 users accessing the internet.

having a volume based internet subscription, we are in need to have a
solution wherein i need to restrict users to a certain volume of quota per
month and upon crossing that threshold, need to either stop their access or
throttle their bandwidth speed.

following is the scenario. having an internet link of 50Mbps in my campus

1. users have to be authenticated via Active Directory  -- i.e. users in a
certain AD group should only get access to internet
2. should be able to define a volume threshold ( e.g 100GB per group/per
user)
3. upon exhaustion of the volume the user bandwidth should b throttled to,
say, 256Kbps. OR block internet access to that user completely.
4. this volume calculation should be done for both HTTP and HTTPS based
session.
5. should be able to generate a monthly report showcasing the volume
consumed by specific user during a specific time-frame by showing the
spread of the volume distributed within websites visited/downloaded from.

Kindly help to suggest this could be possible with Squid.
I am open to using some log analytics mechanism like sarg or anything
similar for reporting.

-- 
*Regards,*
*T Anoop Sreedharan*
*+91-9022078298*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180319/35d1e6a9/attachment.htm>

From kirup at aism.edu.my  Mon Mar 19 14:40:23 2018
From: kirup at aism.edu.my (Kiru Pananthan)
Date: Mon, 19 Mar 2018 22:40:23 +0800
Subject: [squid-users] Reverse proxy is not responding
In-Reply-To: <689510d1-1183-4345-d073-59505c59a2b6@treenet.co.nz>
References: <CAEax4xXFrWb-E4-TA_fYWVS68w7c0=W8-fVBGSLvfTcaAHGmXQ@mail.gmail.com>
 <66af9ca6-55f7-f6d5-a063-29e08a7ef899@treenet.co.nz>
 <CAEax4xUUnXi_B+C71TbcKYr5p_Es1m1maBXZgoc9Ppc7fwp6YA@mail.gmail.com>
 <fe6922c8-471f-fb27-8221-7e0de7c31183@treenet.co.nz>
 <CAEax4xWNHiOXaxAjDoOtQ-7r_u3SvmdVbCL8g7hkvrPoG78Jfg@mail.gmail.com>
 <689510d1-1183-4345-d073-59505c59a2b6@treenet.co.nz>
Message-ID: <CAEax4xX8ZFfyvkJOKfBhX1PFps2S-Q4pwZM7qJpVrmHW1BzSbQ@mail.gmail.com>

Hi Amos

I have run the command of "squid -k parse" and attached output in the
config file link
Config file URL
 https://goo.gl/Q4a749

-- 
*Confidentiality Disclaimer:* This e-mail and any attachments are 
confidential and intended solely for the intended addressee and may also be 
privileged or exempt from disclosure under applicable law. If you are not 
the intended addressee, or have received this e-mail in error, please 
notify the sender immediately, delete it from your system and do not copy, 
disclose, distribute or otherwise act in reliance upon any part of this 
e-mail or its attachments. Australian International School Malaysia and all 
affiliates under Taylor's Education Group  does not accept responsibility 
for any loss arising from unauthorised access to, or interference with, any 
internet communications by any third party in reliance to this email, or 
from the transmission of any viruses. Please note that any views or 
opinions presented in this email are solely those of the author and do not 
necessarily represent those of   Australian International School Malaysia and 
all affiliates under Taylor's Education Group. Replies to this e-mail may 
be monitored by   Australian International School Malaysia and all 
affiliates under Taylor's Education Group for operational or business 
reasons.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180319/e7bf06e3/attachment.htm>

From rafael.akchurin at diladele.com  Tue Mar 20 10:38:13 2018
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 20 Mar 2018 10:38:13 +0000
Subject: [squid-users] multiple log_file_daemon settings in squid.conf
Message-ID: <AM4PR0401MB219422C52A282CCDD9338EEC8FAB0@AM4PR0401MB2194.eurprd04.prod.outlook.com>

Greetings all,

I am trying to find the best (easiest, least interfering) solution for the following problem.

Our custom ICAP server writes various information about ICAP transaction (user name, policy ip, detection module, timings, words triggered detection, etc) into the record database. This happens at the time when ICAP transaction ends. Based on that information we build extensive reports of web filtering activity.

As known, end of the ICAP transaction does not mean the end of the original transaction in Squid - e.g. after scanning CONNECT request and allowing it to proceed, the actual data transfer from the Squid's perspective may end much much later. The piece of information that would be very interesting for reporting module is how many bytes were pumped through that connection. This information is only available after the original Squid transaction ends.

So somehow in the record database we must correlate the ICAP transaction(s) with original Squid transaction.

Question 1:
Is there any unique transaction ID in the Squid's inner workings that I can see in the ICAP server, by passing it as additional X-* ICAP header?
I see some references to so called "master transaction" in the docs but could not find any log format like identifier that can be used for ICAP header value.

Question 2:
If there is no such transaction ID, I can use ICAP header to pass the ICAP specific transaction ID back to Squid *and* I can get that ID written to Squid's access log as "X-WebSafety-IID=%{X-WebSafety-IID}adapt::<last_h". Is it a valid approach?

Question 3:
If q1 or q2 is answered positively, I still need to somehow get the data from squid's access log the ICAP record database. Currently the idea is to have the custom logfile_daemon setting that would fork original log_file_daemon to have log entries written to access_log *and* parse out the ICAP ID *and* update the corresponding ICAP record in the database with transferred bytes information. But this seems complex and fragile.

Is it possible to have *two* daemon log settings in the squid.conf? One (original) would write access_log is usual and another one would parse out pumped bytes and update the ICAP records database.

Hope I could explain it :(

Thanks in advance for everyone taking time to respond.

Best regards,
Rafael Akchurin
Diladele B.V.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180320/1d6856c3/attachment.htm>

From michael.adm at gmail.com  Tue Mar 20 11:11:28 2018
From: michael.adm at gmail.com (Michael Pro)
Date: Tue, 20 Mar 2018 13:11:28 +0200
Subject: [squid-users] tcp_outgoing_address and HTTPS
Message-ID: <CAA+Mow79_5nCkudiAUUQdPdW24afUSxSZF5qNAhXwVu2_apECQ@mail.gmail.com>

squid-5 master branch, not have  personal/private repository changes,
not use  cache_peer's ability, (if it's matters - not use transparent
proxying ability).

We have a set of rules (ACL's with url regex) for content, depending
on which we make a decision for the outgoing address, for example,
from 10.10.1.xx to 10.10.6.xx
-----log 1part {{{ -----
Acl.cc(151) matches: checked: tcp_outgoing_address 10.10.5.11 = 1
Checklist.cc(63) markFinished: 0x7fffffffe2b8 answer ALLOWED for match
FilledChecklist.cc(67) ~ACLFilledChecklist: ACLFilledChecklist
destroyed 0x7fffffffe2b8
Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist:
destroyed 0x7fffffffe2b8
peer_select.cc(1026) handlePath: PeerSelector3438 found
local=10.10.5.11 remote=17.253.37.204:80 HIER_DIRECT flags=1,
destination #2 for http://iosapps.itunes.apple.com/...xxx...ipa
...
peer_select.cc(1002) interestedInitiator: PeerSelector3438
peer_select.cc(112) ~PeerSelector: http://iosapps.itunes.apple.com/...xxx...ipa
store.cc(464) unlock: peerSelect unlocking key
60080000000000001C0E000001000000 e:=p2IWV/0x815c09500*3
AsyncCallQueue.cc(55) fireNext: entering AsyncJob::start()
AsyncCall.cc(38) make: make call AsyncJob::start [call195753]
AsyncJob.cc(123) callStart: Comm::ConnOpener status in: [ job10909]
comm.cc(348) comm_openex: comm_openex: Attempt open socket for: 10.10.5.11
comm.cc(391) comm_openex: comm_openex: Opened socket local=10.10.5.11
remote=[::] FD 114 flags=1 : family=2, type=1, protocol=6
-----log 1part }}} -----
In the case of normal traffic (http), everything works fine, as shuld.

In the case of HTTPS with traffic analysis (ssl_bump) we have such a picture:
-----log 2part {{{ ------
Acl.cc(151) matches: checked: tcp_outgoing_address 10.10.5.120 = 1
Checklist.cc(63) markFinished: 0x7fffffffe2b8 answer ALLOWED for match
FilledChecklist.cc(67) ~ACLFilledChecklist: ACLFilledChecklist
destroyed 0x7fffffffe2b8
Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist:
destroyed 0x7fffffffe2b8
peer_select.cc(1026) handlePath: PeerSelector569 found
local=10.10.5.120 remote=23.16.9.11:443 PINNED flags=1, destination #1
for https://some.https.com/...xxx...zip
peer_select.cc(1027) handlePath: always_direct = DENIED
peer_select.cc(1028) handlePath: never_direct = DENIED
peer_select.cc(1029) handlePath: timedout = 0
peer_select.cc(1002) interestedInitiator: PeerSelector569
FwdState.cc(443) startConnectionOrFail: https://some.https.com/...xxx...zip
HttpRequest.cc(472) clearError: old error details: 0/0
FwdState.cc(886) connectStart: fwdConnectStart:
https://some.https.com/...xxx...zip
FwdState.cc(905) connectStart: pinned peer connection: 0x812c51018
client_side.cc(4082) borrowPinnedConnection: local=10.10.2.120:47901
remote=23.16.9.11:443 HIER_DIRECT FD 28 flags=1
client_side.cc(4057) validatePinnedConnection: local=10.10.2.120:47901
remote=23.16.9.11:443 HIER_DIRECT FD 28 flags=1
AsyncCall.cc(56) cancel: will not call
ConnStateData::clientPinnedConnectionRead [call20129] because
comm_read_cancel
AsyncCall.cc(56) cancel: will not call
ConnStateData::clientPinnedConnectionRead [call20129] also because
comm_read_cancel
ModKqueue.cc(174) SetSelect: FD 28, type=1, handler=0,
client_data=0x0, timeout=0
comm.cc(964) comm_add_close_handler: comm_add_close_handler: FD 28,
handler=1, data=0x8028bf398
AsyncCall.cc(26) AsyncCall: The AsyncCall SomeCloseHandler
constructed, this=0x802a456d0 [call20139]
comm.cc(975) comm_add_close_handler: comm_add_close_handler: FD 28,
AsyncCall=0x802a456d01
FwdState.cc(987) dispatch: local=127.0.0.1:20990
remote=127.0.0.120:59799 FD 26 flags=1: Fetching GET
https://some.https.com/...xxx...zip
AsyncJob.cc(34) AsyncJob: AsyncJob constructed, this=0x81258fe38
type=HttpStateData [job1763]
store.cc(439) lock: Client locked key 3F020000000000001C0E000001000000
e:=p2IWV/0x812b2df004
...
peer_select.cc(112) ~PeerSelector: https://some.https.com/...xxx...zip
store.cc(464) unlock: peerSelect unlocking key
3F020000000000001C0E000001000000 e:=p2IWV/0x812b2df004
AsyncCallQueue.cc(55) fireNext: entering AsyncJob::start()
AsyncCall.cc(38) make: make call AsyncJob::start [call20141]
AsyncJob.cc(123) callStart: HttpStateData status in: [ job1763]
http.cc(2838) sendRequest: local=10.10.2.120:47901
remote=23.16.9.11:443 HIER_DIRECT FD 28 flags=1, request 0x8125e88005,
this 0x81258fd18.
AsyncCall.cc(26) AsyncCall: The AsyncCall HttpStateData::httpTimeout
constructed, this=0x812492f80 [call20142]
comm.cc(554) commSetConnTimeout: local=10.10.2.120:47901
remote=23.16.9.11:443 HIER_DIRECT FD 28 flags=1 timeout 86400
http.cc(2204) maybeMakeSpaceAvailable: may read up to 131072 bytes
info buf(0/131072) from local=10.10.2.120:47901
remote=213.156.90.131:443 HIER_DIRECT FD 28 flags=1
AsyncCall.cc(26) AsyncCall: The AsyncCall HttpStateData::readReply
constructed, this=0x812493020 [call20143]
Read.cc(57) comm_read_base: comm_read, queueing read for
local=10.10.2.120:47901 remote=23.16.9.11:443 HIER_DIRECT FD 28
flags=1; asynCall 0x812493020*1
ModKqueue.cc(174) SetSelect: FD 28, type=1, handler=1,
client_data=0x80ce04728, timeout=0
AsyncCall.cc(26) AsyncCall: The AsyncCall HttpStateData::wroteLast
constructed, this=0x812493160 [call20144]
-----log 2part }}} -----

I understand that without analyzing the traffic and not knowing the
final goal for the beginning, we can not manage the process further.
Question: how can we break the established channel (unpinn it) along
the old route and establish a new channel along the new route, when we
already know how.

IN 127.0.0.1:443 (22.33.44.55:443 ???) ---> OUT 10.10.1.1 ---> (Catch
22.33.44.55:443/this/is/it.zip) ---> Kill IN ... ??? OUT 10.10.1.1
---> Establish OUT 10.10.5.1 ---> 22.33.44.55:443/this/is/it.zip

I'm willing to pay a large price for traffic congestion in this case,
since the goal justifies it.


From squid3 at treenet.co.nz  Tue Mar 20 12:35:28 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 21 Mar 2018 01:35:28 +1300
Subject: [squid-users] multiple log_file_daemon settings in squid.conf
In-Reply-To: <AM4PR0401MB219422C52A282CCDD9338EEC8FAB0@AM4PR0401MB2194.eurprd04.prod.outlook.com>
References: <AM4PR0401MB219422C52A282CCDD9338EEC8FAB0@AM4PR0401MB2194.eurprd04.prod.outlook.com>
Message-ID: <ff948ebb-35cf-469d-c822-2142fb37b67a@treenet.co.nz>

On 20/03/18 23:38, Rafael Akchurin wrote:
> Greetings all,
> 
> I am trying to find the best (easiest, least interfering) solution for
> the following problem.
> 
> Our custom ICAP server writes various information about ICAP transaction
> (user name, policy ip, detection module, timings, words triggered
> detection, etc) into the record database. This happens at the time when
> ICAP transaction ends. Based on that information we build extensive
> reports of web filtering activity.
> 
> ?
> 
> As known, end of the ICAP transaction does not mean the end of the
> original transaction in Squid ? e.g. after scanning CONNECT request and
> allowing it to proceed, the actual data transfer from the Squid?s
> perspective may end much much later. The piece of information that would
> be very interesting for reporting module is how many bytes were pumped
> through that connection. This information is only available after the
> original Squid transaction ends.
> 
> ?
> 
> So somehow in the record database we must correlate the ICAP
> transaction(s) with original Squid transaction.
> 
> ?
> 
> Question 1:
> 
> Is there any unique transaction ID in the Squid?s inner workings that I
> can see in the ICAP server, by passing it as additional X-* ICAP header?
> 
> I see some references to so called ?master transaction? in the docs but
> could not find any log format like identifier that can be used for ICAP
> header value.

see <http://www.squid-cache.org/Doc/config/adaptation_meta/>

There is also the note directive. Although that is only added right at
the point of logging - so it is useful for Squid adding notes if the
ICAP service does not add any itself. All Squid helpers used for a
transaction add notes about their results to the transaction (except
security tokens for NTLM, Kerberos and Digest).
 <http://www.squid-cache.org/Doc/config/note/>


> 
> Question 2:
> 
> If there is no such transaction ID, I can use ICAP header to pass the
> ICAP specific transaction ID back to Squid **and** I can get that ID
> written to Squid?s access log as
> "X-WebSafety-IID=%{X-WebSafety-IID}adapt::<last_h". Is it a valid approach?
> 

Yes.


> ?
> 
> Question 3:
> 
> If q1 or q2 is answered positively, I still need to somehow get the data
> from squid?s access log the ICAP record database. Currently the idea is
> to have the custom logfile_daemon setting that would fork original
> log_file_daemon to have log entries written to access_log **and** parse
> out the ICAP ID **and** update the corresponding ICAP record in the
> database with transferred bytes information. But this seems complex and
> fragile.
> 

There is only one daemon at a time supported.

That said the daemon can be instructed via access_log parameter
"daemon:PLACE" to send its data to a specific output PLACE - where PLACE
is a string passed to the helper command line and interpreted in any way
the helper author desires.
 The bundled helpers treat is respectively as the name+path of a file,
or a database DSN to drop the relevant access_log lines to.


Alternatively the "tcp:" logging module can send the log lines as a raw
TCP stream to some place that handles input with the logformat defined
syntax as a series of lines.
 I've seen people defining custom logformat with variously SQL, XML and
JSON markup for delivery to custom daemon or tcp modules.


There is also the option of an external ACL helper that gets passed the
%note details along with anything else you wish it to use. That helper
can do any updates you want prior to the logformat using the same
details. The only restriction here is that it must run in a slow-group
access check. The last one that seems reasonable is http_reply_access
which preceeds ICAP RESPMOD alterations.


Amos


From squid3 at treenet.co.nz  Tue Mar 20 12:55:08 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 21 Mar 2018 01:55:08 +1300
Subject: [squid-users] Reverse proxy is not responding
In-Reply-To: <CAEax4xX8ZFfyvkJOKfBhX1PFps2S-Q4pwZM7qJpVrmHW1BzSbQ@mail.gmail.com>
References: <CAEax4xXFrWb-E4-TA_fYWVS68w7c0=W8-fVBGSLvfTcaAHGmXQ@mail.gmail.com>
 <66af9ca6-55f7-f6d5-a063-29e08a7ef899@treenet.co.nz>
 <CAEax4xUUnXi_B+C71TbcKYr5p_Es1m1maBXZgoc9Ppc7fwp6YA@mail.gmail.com>
 <fe6922c8-471f-fb27-8221-7e0de7c31183@treenet.co.nz>
 <CAEax4xWNHiOXaxAjDoOtQ-7r_u3SvmdVbCL8g7hkvrPoG78Jfg@mail.gmail.com>
 <689510d1-1183-4345-d073-59505c59a2b6@treenet.co.nz>
 <CAEax4xX8ZFfyvkJOKfBhX1PFps2S-Q4pwZM7qJpVrmHW1BzSbQ@mail.gmail.com>
Message-ID: <e8ccacdf-f017-ba42-86b4-0f75913d10a1@treenet.co.nz>

On 20/03/18 03:40, Kiru Pananthan wrote:
> Hi Amos
> 
> I have run the command of "squid -k parse" and attached output in the
> config file link?
> Config file URL
> ?https://goo.gl/Q4a749
> 

You see anything looking odd in that output?

Many of the wrong syntax things I have mentioned should also be
mentioned there in one form or another. eg the server_6 missing I see in
that image, and acl line not being before first use last time around
would have had a big fat FATAL line.

I asked you to run that so you can use it yourself in future without
having to rely on me/us for the simple stuff. It is not complete by any
means, but does get updated each release where config changed. So it is
best practice to run that and fix anything shown when editing squid.conf
or upgrading the proxy before restart/reconfigure happens to the
production service.

Amos


From squid3 at treenet.co.nz  Tue Mar 20 13:24:53 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 21 Mar 2018 02:24:53 +1300
Subject: [squid-users] Reverse proxy is not responding
In-Reply-To: <CAEax4xX3PGiiMaS_O+F9tefJ00CZNtw31u73BESpWPY0cxSANw@mail.gmail.com>
References: <CAEax4xXFrWb-E4-TA_fYWVS68w7c0=W8-fVBGSLvfTcaAHGmXQ@mail.gmail.com>
 <66af9ca6-55f7-f6d5-a063-29e08a7ef899@treenet.co.nz>
 <CAEax4xUUnXi_B+C71TbcKYr5p_Es1m1maBXZgoc9Ppc7fwp6YA@mail.gmail.com>
 <fe6922c8-471f-fb27-8221-7e0de7c31183@treenet.co.nz>
 <CAEax4xWNHiOXaxAjDoOtQ-7r_u3SvmdVbCL8g7hkvrPoG78Jfg@mail.gmail.com>
 <689510d1-1183-4345-d073-59505c59a2b6@treenet.co.nz>
 <CAEax4xX3PGiiMaS_O+F9tefJ00CZNtw31u73BESpWPY0cxSANw@mail.gmail.com>
Message-ID: <91dc318f-67f2-044c-43ab-b06823c8449a@treenet.co.nz>

On 19/03/18 19:13, Kiru Pananthan wrote:
> Hi Amos
> 
> I have removed *. dashboard and also timetable which is not in use.
> 
> I have added the accel after port number and removed vhost as per your
> advice. Can you check the file now, am I good to go. I have not yet run
> the query??"squid -k parse"?, later will run it and update you on the
> outcome. I need to update the config file in server once your verify the
> config file for me to run the query

Okay, though of course backup the config running now before you change
it. I have been known to be wrong sometimes.

> 
> So basically I set this config file for below url, All this should able
> to access through https by auto redirec from http to https.

Um, lets be clear. "redirect" means something other than what you are
doing. Your traffic is still very much clear-text HTTP on the
client/"external" side of the network. What you have is secure
connections between the proxy and peer servers (ie the *internal* network).

To have a "redirect" the proxy would be responding to all incoming
http:// URLs with a 302 message telling the client to re-try with
https:// instead. If you want that to happen it is easy enough, but
another step additional to the bit we have been trying to get working so
far.


> 
> Portal.aism.edu.my <http://Portal.aism.edu.my>
> Helpdesk.aism.edu.my <http://Helpdesk.aism.edu.my>
> Booking.aism.edu.my <http://Booking.aism.edu.my>
> 
> 
> Config file URL
> ?https://goo.gl/Q4a749
> 

Your config also proxies the bookings* and library.* domains.

Related to those your last "acl" line looks kind of odd:
  acl sites_server_2 dstdomain library.*

Is the server_2 peer accepting library.* domain as well as bookings.* ?


Your "deny all" lines for this smaller config now should be:

 cache_peer_access server_1  deny all
 cache_peer_access server_2  deny all
 cache_peer_access lib_1_SSL deny all
 cache_peer_access lib_1     deny all

 http_access deny all


(you see why its useful to group all the liens about a server together?
these should not have been able to be missed by your last edit).


Amos


From squid3 at treenet.co.nz  Tue Mar 20 13:55:38 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 21 Mar 2018 02:55:38 +1300
Subject: [squid-users] tcp_outgoing_address and HTTPS
In-Reply-To: <CAA+Mow79_5nCkudiAUUQdPdW24afUSxSZF5qNAhXwVu2_apECQ@mail.gmail.com>
References: <CAA+Mow79_5nCkudiAUUQdPdW24afUSxSZF5qNAhXwVu2_apECQ@mail.gmail.com>
Message-ID: <856483c6-3a0d-b75c-81ce-ec471aa8d18f@treenet.co.nz>

On 21/03/18 00:11, Michael Pro wrote:
> squid-5 master branch, not have  personal/private repository changes,
> not use  cache_peer's ability, (if it's matters - not use transparent
> proxying ability).
> 
> We have a set of rules (ACL's with url regex) for content, depending
> on which we make a decision for the outgoing address, for example,
> from 10.10.1.xx to 10.10.6.xx
> -----log 1part {{{ -----
> Acl.cc(151) matches: checked: tcp_outgoing_address 10.10.5.11 = 1
> Checklist.cc(63) markFinished: 0x7fffffffe2b8 answer ALLOWED for match
> FilledChecklist.cc(67) ~ACLFilledChecklist: ACLFilledChecklist
> destroyed 0x7fffffffe2b8
> Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist:
> destroyed 0x7fffffffe2b8
> peer_select.cc(1026) handlePath: PeerSelector3438 found
> local=10.10.5.11 remote=17.253.37.204:80 HIER_DIRECT flags=1,
> destination #2 for http://iosapps.itunes.apple.com/...xxx...ipa
> ...
> peer_select.cc(1002) interestedInitiator: PeerSelector3438
> peer_select.cc(112) ~PeerSelector: http://iosapps.itunes.apple.com/...xxx...ipa
> store.cc(464) unlock: peerSelect unlocking key
> 60080000000000001C0E000001000000 e:=p2IWV/0x815c09500*3
> AsyncCallQueue.cc(55) fireNext: entering AsyncJob::start()
> AsyncCall.cc(38) make: make call AsyncJob::start [call195753]
> AsyncJob.cc(123) callStart: Comm::ConnOpener status in: [ job10909]
> comm.cc(348) comm_openex: comm_openex: Attempt open socket for: 10.10.5.11
> comm.cc(391) comm_openex: comm_openex: Opened socket local=10.10.5.11
> remote=[::] FD 114 flags=1 : family=2, type=1, protocol=6
> -----log 1part }}} -----
> In the case of normal traffic (http), everything works fine, as shuld.
> 

The difference to be aware of is that there is zero security on this
type of HTTP. So while it is better not to play with destinations, and
Squid default is to go where the client wanted - it is permitted to go
elsewhere if a better source is found.


> In the case of HTTPS with traffic analysis (ssl_bump) we have such a picture:
> -----log 2part {{{ ------
> Acl.cc(151) matches: checked: tcp_outgoing_address 10.10.5.120 = 1
> Checklist.cc(63) markFinished: 0x7fffffffe2b8 answer ALLOWED for match
> FilledChecklist.cc(67) ~ACLFilledChecklist: ACLFilledChecklist
> destroyed 0x7fffffffe2b8
> Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist:
> destroyed 0x7fffffffe2b8
> peer_select.cc(1026) handlePath: PeerSelector569 found
> local=10.10.5.120 remote=23.16.9.11:443 PINNED flags=1, destination #1
> for https://some.https.com/...xxx...zip

What PINNED means to Squid is that the client TCP connection is tied up
with some details related to some specific TCP server connection.

In this case the TLS crypto used during the bumping process took crypto
details from the client connection and gave them to the server, then
from the server and gave them to the client. Resulting in a forced
end-to-end relationship between the clinet and server for all traffic
over both those connections.
 The only thing Squid can do is to server some content from cache as
normal HITs, or if you specifically configure ICAP/eCAP service they can
modify the messages as they flow. Delivering the traffic to another
server is not permissable because the HTTP messages can (and often are)
tied to the TLS crypto details as well in ways that are not visible to
Squid.

For example; it is becoming very popular for the endpoints to crypto
sign messages or embed a hash signature which can only be verified valid
using details the server and client exchanged up front. No other server
would be able to send valid values and the client breaks if it is wrong.
 This kind of thing survives even when SSL-Bump'ing because of Squid
pinning, but does add the restrictions you found.


> 
> I understand that without analyzing the traffic and not knowing the
> final goal for the beginning, we can not manage the process further.
> Question: how can we break the established channel (unpinn it) along
> the old route and establish a new channel along the new route, when we
> already know how.

There are three possibilities that I am aware of - in no particular order:

1) An ICAP service can do whatever it pleases with requests it receives.
We hold no responsibility for anything happening there and I publicly
advise against playing with the crypto that way - the above issues are
the least of the problems to be faced.


2) It is technically possible to make Squid open a CONNECT tunnel
through an HTTP peer proxy to the origin instead of going there
directly. The only thing preventing this is nobody writing the necessary
code.

It has been on my (and many others) wishlist for a long while but still
nobody has been able to work on it. Any assistance towards getting that
coded is very, very welcome.


3) The client-first type of bumping does not involve any server crypto.
This is *highly* unsafe and often encounters problems like the ICAP
approach and for all the same reasons.

BUT that said, if you are sufficiently in control of the traffic to be
sure of its safety then Squid can do it by simply using the bump action
at "step 1" of the SSL-Bump process - rather than the recommended step 2
or 3.

We have err'ed on the side of security with these things so it may not
work right now. But it is not technically required to pin for this
specific type of bumped connection - so the case could be made that it
is a bug to fix if Squid does force pinning on that traffic.

Amos


From squid3 at treenet.co.nz  Tue Mar 20 14:25:16 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 21 Mar 2018 03:25:16 +1300
Subject: [squid-users] Volume quota management availablity
In-Reply-To: <CACy0pi3DKQ8BV8H3LmTYyRfkGmrtQErY5fm0GjTH57GU2L_iuA@mail.gmail.com>
References: <CACy0pi3DKQ8BV8H3LmTYyRfkGmrtQErY5fm0GjTH57GU2L_iuA@mail.gmail.com>
Message-ID: <59ef9114-ea35-7225-8470-7761a7ed7eda@treenet.co.nz>

On 19/03/18 23:03, Anoop Sreedharan wrote:
> Dear Team,
> We have an IT environment catering to educational institute wherein we
> have approx more than 1000 users accessing the internet.
> 
> having a volume based internet subscription, we are in need to have a
> solution wherein i need to restrict users to a certain volume of quota
> per month and upon crossing that threshold, need to either stop their
> access or throttle their bandwidth speed.
> 
> following is the scenario. having an internet link of 50Mbps in my campus
> 
> 1. users have to be authenticated via Active Directory? -- i.e. users in
> a certain AD group should only get access to internet
> 2. should be able to define a volume threshold ( e.g 100GB per group/per
> user)
> 3. upon exhaustion of the volume the user bandwidth should b throttled
> to, say, 256Kbps. OR block internet access to that user completely.
> 4. this volume calculation should be done for both HTTP and HTTPS based
> session.
> 5. should be able to generate a monthly report showcasing the volume
> consumed by specific user during a specific time-frame by showing the
> spread of the volume distributed within websites visited/downloaded from.
> ?
> Kindly help to suggest this could be possible with Squid.?
> I am open to using some log analytics mechanism like sarg or anything
> similar for reporting.

Quota is not a concept easily applied to HTTP messaging since it is a
stateless protocol and operates in terms of entire messages - not
packets or bytes. As such there is intentionally no mechanism to
maintain statefulness between transactions for quota controls to use in
Squid.

There is also a rather lot of traffic details outside of HTTP an unknown
to Squid which greatly affect the relationship between what Squid sees
as bandwidth and what actually occurs "on wire". That all makes the OS
networking stack a much better place to do such management.

Most OS these days provide very capable tools for QoS bandwidth
management. Squid provides configuration features to integrate with
those, delivering packet TOS markings per-transaction or per-message for
the machines OS systems to utilize in their QoS flow identification and
accounting.



Log analysis (eg SARG) and helpers are other possibilities that worked
in the past ...

 BUT these methods have always suffered from the problem of only
accounting for traffic usage at the end of a completed HTTP transaction
and authorizing users only at the beginning. The difference can see
large amounts of over-usage and CONNECT tunnels are the worst-case
scenario there as they may last for days/weeks with "infinite" amount of
traffic usage meanwhile.

 Added to those problems we now face most traffic being HTTPS ... which
goes through proxies via CONNECT tunnels. So much for those ways of
doing quotas.


Amos


From yoinier.hn at gmail.com  Tue Mar 20 14:41:15 2018
From: yoinier.hn at gmail.com (Yoinier Hernandez Nieves)
Date: Tue, 20 Mar 2018 10:41:15 -0400
Subject: [squid-users] Volume quota management availablity
In-Reply-To: <59ef9114-ea35-7225-8470-7761a7ed7eda@treenet.co.nz>
References: <CACy0pi3DKQ8BV8H3LmTYyRfkGmrtQErY5fm0GjTH57GU2L_iuA@mail.gmail.com>
 <59ef9114-ea35-7225-8470-7761a7ed7eda@treenet.co.nz>
Message-ID: <CAHTxs6xdTVcM6b852BHH4nwspbqs7ZM8Yr6yT5PqKGChqKRcPQ@mail.gmail.com>

2018-03-20 10:25 GMT-04:00, Amos Jeffries <squid3 at treenet.co.nz>:
> On 19/03/18 23:03, Anoop Sreedharan wrote:
>> Dear Team,
>> We have an IT environment catering to educational institute wherein we
>> have approx more than 1000 users accessing the internet.
>>
>> having a volume based internet subscription, we are in need to have a
>> solution wherein i need to restrict users to a certain volume of quota
>> per month and upon crossing that threshold, need to either stop their
>> access or throttle their bandwidth speed.
>>
>> following is the scenario. having an internet link of 50Mbps in my campus
>>
>> 1. users have to be authenticated via Active Directory  -- i.e. users in
>> a certain AD group should only get access to internet
>> 2. should be able to define a volume threshold ( e.g 100GB per group/per
>> user)
>> 3. upon exhaustion of the volume the user bandwidth should b throttled
>> to, say, 256Kbps. OR block internet access to that user completely.
>> 4. this volume calculation should be done for both HTTP and HTTPS based
>> session.
>> 5. should be able to generate a monthly report showcasing the volume
>> consumed by specific user during a specific time-frame by showing the
>> spread of the volume distributed within websites visited/downloaded from.
>>
>> Kindly help to suggest this could be possible with Squid.
>> I am open to using some log analytics mechanism like sarg or anything
>> similar for reporting.
>
> Quota is not a concept easily applied to HTTP messaging since it is a
> stateless protocol and operates in terms of entire messages - not
> packets or bytes. As such there is intentionally no mechanism to
> maintain statefulness between transactions for quota controls to use in
> Squid.
>
> There is also a rather lot of traffic details outside of HTTP an unknown
> to Squid which greatly affect the relationship between what Squid sees
> as bandwidth and what actually occurs "on wire". That all makes the OS
> networking stack a much better place to do such management.
>
> Most OS these days provide very capable tools for QoS bandwidth
> management. Squid provides configuration features to integrate with
> those, delivering packet TOS markings per-transaction or per-message for
> the machines OS systems to utilize in their QoS flow identification and
> accounting.
>
>
>
> Log analysis (eg SARG) and helpers are other possibilities that worked
> in the past ...
>
>  BUT these methods have always suffered from the problem of only
> accounting for traffic usage at the end of a completed HTTP transaction
> and authorizing users only at the beginning. The difference can see
> large amounts of over-usage and CONNECT tunnels are the worst-case
> scenario there as they may last for days/weeks with "infinite" amount of
> traffic usage meanwhile.
>
>  Added to those problems we now face most traffic being HTTPS ... which
> goes through proxies via CONNECT tunnels. So much for those ways of
> doing quotas.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

You can use Squish, and project to count the squid quote navigation,
reading the log file.

Here the URL

www.mcgill.org.za/software/squish/

YnievesDotNet


From fredbmail at free.fr  Tue Mar 20 15:30:16 2018
From: fredbmail at free.fr (FredB)
Date: Tue, 20 Mar 2018 16:30:16 +0100 (CET)
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <2116621485.68337478.1521558122367.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1201938272.68444288.1521559816624.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hi all,

I'm testing SSLBump and Squid eats up all my CPU, maybe I made something wrong or maybe some updates are required ? Any advice would be greatly appreciated.

Debian 8.10 64 bits, Squid 3.5.27 + 64 Go ram + SSD + 15 Cores Xeon(R) CPU E5-2637 v2 @ 3.50GHz 
FI, I don't see anything about limit reached in kern.log (File descriptor or network)

acl nobump dstdomain "/home/squid/domains" -> Some very used websites (google, fb, etc) otherwise the system dies after less 1 minute 
http_port 3128 ssl-bump cert=/etc/squid/ca_orion/cert generate-host-certificates=on dynamic_cert_mem_cache_size=500MB
sslcrtd_program /usr/lib/squid/ssl_crtd -s /usr/lib/squid/ssl_db -M 100MB
sslcrtd_children 2000 startup=100 idle=20 
sslproxy_capath /etc/ssl/certs/
sslproxy_foreign_intermediate_certs /etc/squid/ssl_certs/imtermediate.ca.pem
acl step1 at_step SslBump1
ssl_bump peek step1 all
ssl_bump splice nobump
ssl_bump bump all

The sslcrtd_children increases quickly and permanently

root at proxyorion5:/tmp# ps -edf | grep ssl | wc -l
1321
root at proxyorion5:/tmp# ps -edf | grep ssl | wc -l
1341
root at proxyorion5:/tmp# ps -edf | grep ssl | wc -l
1341
root at proxyorion5:/tmp# ps -edf | grep ssl_crt | wc -l
1380
root at proxyorion5:/tmp# ps -edf | grep ssl_crt | wc -l
1381
root at proxyorion5:/tmp# ps -edf | grep ssl_crt | wc -l
1382
root at proxyorion5:/tmp# ps -edf | grep ssl_crt | wc -l
1395

Of course after a while 2000 is reached and the system becomes completely mad, but I already tried 200, 500, 1000, etc 

Right after squid start CPU and load average values are very, very, high 

top - 16:06:17 up 13 days,  2:46,  3 users,  load average: 102,02, 56,67, 30,75
Tasks: 1964 total,   3 running, 1961 sleeping,   0 stopped,   0 zombie
%Cpu(s): 15,3 us,  3,7 sy,  0,0 ni, 80,2 id,  0,4 wa,  0,0 hi,  0,4 si,  0,0 st
KiB Mem:  66086692 total, 52378248 used, 13708444 free,  2899764 buffers
KiB Swap:  1952764 total,        0 used,  1952764 free. 32798948 cached Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                  
23711 squid     20   0 3438832 2,976g  13784 R 100,0  4,7   6:01.02 squid                                                    
23724 squid     20   0   24868   8552   4340 S   3,6  0,0   0:02.46 ssl_crtd                                                 
23712 squid     20   0   25132   8896   4428 R   3,0  0,0   0:02.62 ssl_crtd                                                 
23714 squid     20   0   24868   8556   4344 S   2,3  0,0   0:02.43 ssl_crtd                                                 
23716 squid     20   0   24868   8636   4428 S   2,3  0,0   0:02.26 ssl_crtd                                                 
23720 squid     20   0   24868   8612   4400 S   2,3  0,0   0:02.58 ssl_crtd                                                 
23771 squid     20   0   24868   8580   4368 S   2,0  0,0   0:01.86 ssl_crtd                                                 
23780 squid     20   0   24872   8484   4268 S   2,0  0,0   0:01.86 ssl_crtd                                                 
23787 squid     20   0   24868   8612   4404 S   2,0  0,0   0:01.92 ssl_crtd  

The same system without SSLBump and e2guardian (web filtering) added (I tried without more or less 10% CPU )

Tasks: 304 total,   2 running, 302 sleeping,   0 stopped,   0 zombie
%Cpu(s):  2,0 us,  1,1 sy,  0,0 ni, 95,9 id,  0,1 wa,  0,0 hi,  0,9 si,  0,0 st
KiB Mem:  66086700 total, 65627952 used,   458748 free,  2652264 buffers
KiB Swap:  1952764 total,    20884 used,  1931880 free. 32639208 cached Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                         
20389 e2guard+  20   0  0,122t 1,133g   6144 S  28,6  1,8 191:06.50 e2guardian                      
20283 squid     20   0 21,761g 0,021t   8128 R  24,2 34,0 145:00.09 squid                           
  101 root      20   0       0      0      0 S   1,3  0,0  19:05.09 kswapd1                         
  100 root      20   0       0      0      0 S   1,0  0,0  22:41.82 kswapd0                         
    8 root      20   0       0      0      0 S   0,7  0,0  68:49.48 rcu_sched                       
   24 root      20   0       0      0      0 S   0,3  0,0   8:37.14 ksoftirqd/3                     
   65 root      20   0       0      0      0 S   0,3  0,0   8:05.02 ksoftirqd/11                    
  929 root      20   0   71928   6984   4716 S   0,3  0,0  17:53.57 syslog-ng                       
 8069 root      20   0       0      0      0 S   0,3  0,0   0:22.35 kworker/0:0                     
16624 root      20   0   25868   3236   2592 R   0,3  0,0   0:00.19 top                             
20291 squid     20   0   59504   5228   4568 S   0,3  0,0   0:03.41 digest_
  
FredB
    


From rousskov at measurement-factory.com  Tue Mar 20 15:35:51 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 20 Mar 2018 09:35:51 -0600
Subject: [squid-users] tcp_outgoing_address and HTTPS
In-Reply-To: <CAA+Mow79_5nCkudiAUUQdPdW24afUSxSZF5qNAhXwVu2_apECQ@mail.gmail.com>
References: <CAA+Mow79_5nCkudiAUUQdPdW24afUSxSZF5qNAhXwVu2_apECQ@mail.gmail.com>
Message-ID: <9cdb773a-6dfe-3fc4-96d7-6d09c88ae2c4@measurement-factory.com>

On 03/20/2018 05:11 AM, Michael Pro wrote:

> Question: how can we break the established channel (unpinn it) along
> the old route and establish a new channel along the new route, when we
> already know how.

Squid supports using multiple sequential connections for the same
from-client request, but not under the conditions you describe.
Moreover, the already supported cases are limited to simpler HTTP/TCP
failures. Complex code modifications would be required to support what
you want for HTTPS, but it is doable, and others have wanted a similar
"peek and then start from scratch" feature.


> I'm willing to pay a large price for traffic congestion in this case,
> since the goal justifies it.
Please note that some origin servers may have a different opinion about
this trade off: Some might view (repeatedly) terminated innocent
sessions as an attack and block all your traffic.


Alex.


From rousskov at measurement-factory.com  Tue Mar 20 15:44:37 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 20 Mar 2018 09:44:37 -0600
Subject: [squid-users] [squid-dev]  tcp_outgoing_address and HTTPS
In-Reply-To: <856483c6-3a0d-b75c-81ce-ec471aa8d18f@treenet.co.nz>
References: <CAA+Mow79_5nCkudiAUUQdPdW24afUSxSZF5qNAhXwVu2_apECQ@mail.gmail.com>
 <856483c6-3a0d-b75c-81ce-ec471aa8d18f@treenet.co.nz>
Message-ID: <effe0547-49ae-4356-7bc2-f7cfcf692c26@measurement-factory.com>

On 03/20/2018 07:55 AM, Amos Jeffries wrote:
> 2) It is technically possible to make Squid open a CONNECT tunnel
> through an HTTP peer proxy to the origin instead of going there
> directly. The only thing preventing this is nobody writing the necessary
> code.
> 
> It has been on my (and many others) wishlist for a long while but still
> nobody has been able to work on it.

FWIW, Factory is working on it now.

Alex.


From squid3 at treenet.co.nz  Tue Mar 20 16:01:53 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 21 Mar 2018 05:01:53 +1300
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <1201938272.68444288.1521559816624.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1201938272.68444288.1521559816624.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <04afb9cd-5c97-1215-b215-85ba94eeeec7@treenet.co.nz>

On 21/03/18 04:30, FredB wrote:
> Hi all,
> 
> I'm testing SSLBump and Squid eats up all my CPU, maybe I made something wrong or maybe some updates are required ? Any advice would be greatly appreciated.

Not sure about CPU consumption. AFAIK that is related to traffic loading
on the crypto library, mitigated by whether it is using hardware support
for the intensive math parts.


> 
> Debian 8.10 64 bits, Squid 3.5.27 + 64 Go ram + SSD + 15 Cores Xeon(R) CPU E5-2637 v2 @ 3.50GHz 
> FI, I don't see anything about limit reached in kern.log (File descriptor or network)
> 
> acl nobump dstdomain "/home/squid/domains" -> Some very used websites (google, fb, etc) otherwise the system dies after less 1 minute 
> http_port 3128 ssl-bump cert=/etc/squid/ca_orion/cert generate-host-certificates=on dynamic_cert_mem_cache_size=500MB

Definitely use sslflags=NO_DEFAULT_CA to avoid memory bloat, whether
that is your problem now or not.

> sslcrtd_program /usr/lib/squid/ssl_crtd -s /usr/lib/squid/ssl_db -M 100MB

FYI: 100MB x 2000 helpers is larger than your 64GB. Even just the 100
helpers being initialized on startup is a significant chunk out of memory.


> sslcrtd_children 2000 startup=100 idle=20 
> sslproxy_capath /etc/ssl/certs/
> sslproxy_foreign_intermediate_certs /etc/squid/ssl_certs/imtermediate.ca.pem
> acl step1 at_step SslBump1
> ssl_bump peek step1 all
> ssl_bump splice nobump
> ssl_bump bump all
> 
> The sslcrtd_children increases quickly and permanently
> 
> root at proxyorion5:/tmp# ps -edf | grep ssl | wc -l
> 1321
...
> root at proxyorion5:/tmp# ps -edf | grep ssl_crt | wc -l
> 1395
> 
> Of course after a while 2000 is reached and the system becomes completely mad, but I already tried 200, 500, 1000, etc 
> 


Can you tell how fast (or not) they are responding?
 If it is particularly slow you may benefit from the memory-only mode in
the Squid-4 helper (or might not).

Amos


From rousskov at measurement-factory.com  Tue Mar 20 16:48:05 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 20 Mar 2018 10:48:05 -0600
Subject: [squid-users] multiple log_file_daemon settings in squid.conf
In-Reply-To: <AM4PR0401MB219422C52A282CCDD9338EEC8FAB0@AM4PR0401MB2194.eurprd04.prod.outlook.com>
References: <AM4PR0401MB219422C52A282CCDD9338EEC8FAB0@AM4PR0401MB2194.eurprd04.prod.outlook.com>
Message-ID: <21c6a1e8-948b-d1ba-4c86-78186eb69466@measurement-factory.com>

On 03/20/2018 04:38 AM, Rafael Akchurin wrote:

> Is there any unique transaction ID in the Squid?s inner workings that I
> can see in the ICAP server, by passing it as additional X-* ICAP header?

Unfortunately, no. %sn comes close to that but due to implementation
bugs and backward compatibility reasons, it is not usable in adaptation
context. You can construct a fairly unique ID using SMP macros, time,
and TCP connection details, but it is not going to be reliable. Master
transaction ID is a missing Squid feature.

The first ICAP REQMOD service that sees the transaction can set this ID,
but ICAP services do not support returning annotations to Squid. Another
missing Squid feature. You might be able to work around this limitation
by using %adapt::<last_h discussed below.


> I can use ICAP header to pass the
> ICAP specific transaction ID back to Squid **and** I can get that ID
> written to Squid?s access log as
> "X-WebSafety-IID=%{X-WebSafety-IID}adapt::<last_h". Is it a valid approach?

I am not sure what your definition of "valid" in this context is, but
this approach probably can be used as a workaround.

Instead of matching Squid access log records and ICAP log records, you
can also tell Squid to log all of the ICAP details into Squid access
log, using the same %adapt::<last_h workaround. No unique IDs or ID
matching is necessary in that case. Whether to put Squid access log
records into a database (instead or in addition to the file) is up to
you, of course.


> Question 3:
> 
> If q1 or q2 is answered positively, I still need to somehow get the data
> from squid?s access log the ICAP record database. Currently the idea is
> to have the custom logfile_daemon setting that would fork original
> log_file_daemon to have log entries written to access_log **and** parse
> out the ICAP ID **and** update the corresponding ICAP record in the
> database with transferred bytes information. But this seems complex and
> fragile.

Squid supports multiple access loggers so, yes, you can also add a
non-"daemon" logger that will do the above. Please see Amos response for
details.


HTH,

Alex.


From yvoinov at gmail.com  Tue Mar 20 16:47:46 2018
From: yvoinov at gmail.com (Yuri)
Date: Tue, 20 Mar 2018 22:47:46 +0600
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <1201938272.68444288.1521559816624.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1201938272.68444288.1521559816624.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <6c74c6dd-f52f-33c0-258c-e0066885d094@gmail.com>



20.03.2018 21:30, FredB ?????:
> Hi all,
>
> I'm testing SSLBump and Squid eats up all my CPU, maybe I made something wrong or maybe some updates are required ? Any advice would be greatly appreciated.
>
> Debian 8.10 64 bits, Squid 3.5.27 + 64 Go ram + SSD + 15 Cores Xeon(R) CPU E5-2637 v2 @ 3.50GHz
Big box. How much users and traffic?
>  
> FI, I don't see anything about limit reached in kern.log (File descriptor or network)
>
> acl nobump dstdomain "/home/squid/domains" -> Some very used websites (google, fb, etc) otherwise the system dies after less 1 minute 
> http_port 3128 ssl-bump cert=/etc/squid/ca_orion/cert generate-host-certificates=on dynamic_cert_mem_cache_size=500MB
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /usr/lib/squid/ssl_db -M 100MB
Disbalanced config.

dynamic_cert_mem_cache_size=500MB

and only 100 MB on disk?

sslcrtd_program /usr/lib/squid/ssl_crtd -s /usr/lib/squid/ssl_db -M 100MB


> sslcrtd_children 2000 startup=100 idle=20 
Why so much children? Again - for what workload?
> sslproxy_capath /etc/ssl/certs/
> sslproxy_foreign_intermediate_certs /etc/squid/ssl_certs/imtermediate.ca.pem
> acl step1 at_step SslBump1
> ssl_bump peek step1 all
> ssl_bump splice nobump
> ssl_bump bump all
>
> The sslcrtd_children increases quickly and permanently
>
> root at proxyorion5:/tmp# ps -edf | grep ssl | wc -l
> 1321
> root at proxyorion5:/tmp# ps -edf | grep ssl | wc -l
> 1341
> root at proxyorion5:/tmp# ps -edf | grep ssl | wc -l
> 1341
> root at proxyorion5:/tmp# ps -edf | grep ssl_crt | wc -l
> 1380
> root at proxyorion5:/tmp# ps -edf | grep ssl_crt | wc -l
> 1381
> root at proxyorion5:/tmp# ps -edf | grep ssl_crt | wc -l
> 1382
> root at proxyorion5:/tmp# ps -edf | grep ssl_crt | wc -l
> 1395
>
> Of course after a while 2000 is reached and the system becomes completely mad, but I already tried 200, 500, 1000, etc 
>
> Right after squid start CPU and load average values are very, very, high 
>
> top - 16:06:17 up 13 days,  2:46,  3 users,  load average: 102,02, 56,67, 30,75
> Tasks: 1964 total,   3 running, 1961 sleeping,   0 stopped,   0 zombie
> %Cpu(s): 15,3 us,  3,7 sy,  0,0 ni, 80,2 id,  0,4 wa,  0,0 hi,  0,4 si,  0,0 st
> KiB Mem:  66086692 total, 52378248 used, 13708444 free,  2899764 buffers
> KiB Swap:  1952764 total,        0 used,  1952764 free. 32798948 cached Mem
>
>   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                  
> 23711 squid     20   0 3438832 2,976g  13784 R 100,0  4,7   6:01.02 squid                                                    
> 23724 squid     20   0   24868   8552   4340 S   3,6  0,0   0:02.46 ssl_crtd                                                 
> 23712 squid     20   0   25132   8896   4428 R   3,0  0,0   0:02.62 ssl_crtd                                                 
> 23714 squid     20   0   24868   8556   4344 S   2,3  0,0   0:02.43 ssl_crtd                                                 
> 23716 squid     20   0   24868   8636   4428 S   2,3  0,0   0:02.26 ssl_crtd                                                 
> 23720 squid     20   0   24868   8612   4400 S   2,3  0,0   0:02.58 ssl_crtd                                                 
> 23771 squid     20   0   24868   8580   4368 S   2,0  0,0   0:01.86 ssl_crtd                                                 
> 23780 squid     20   0   24872   8484   4268 S   2,0  0,0   0:01.86 ssl_crtd                                                 
> 23787 squid     20   0   24868   8612   4404 S   2,0  0,0   0:01.92 ssl_crtd 
.... what means some bottlenecks. Obviously.
>  
>
> The same system without SSLBump and e2guardian (web filtering) added (I tried without more or less 10% CPU )
>
> Tasks: 304 total,   2 running, 302 sleeping,   0 stopped,   0 zombie
> %Cpu(s):  2,0 us,  1,1 sy,  0,0 ni, 95,9 id,  0,1 wa,  0,0 hi,  0,9 si,  0,0 st
> KiB Mem:  66086700 total, 65627952 used,   458748 free,  2652264 buffers
> KiB Swap:  1952764 total,    20884 used,  1931880 free. 32639208 cached Mem
>
>   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                         
> 20389 e2guard+  20   0  0,122t 1,133g   6144 S  28,6  1,8 191:06.50 e2guardian                      
> 20283 squid     20   0 21,761g 0,021t   8128 R  24,2 34,0 145:00.09 squid                           
>   101 root      20   0       0      0      0 S   1,3  0,0  19:05.09 kswapd1                         
>   100 root      20   0       0      0      0 S   1,0  0,0  22:41.82 kswapd0                         
>     8 root      20   0       0      0      0 S   0,7  0,0  68:49.48 rcu_sched                       
>    24 root      20   0       0      0      0 S   0,3  0,0   8:37.14 ksoftirqd/3                     
>    65 root      20   0       0      0      0 S   0,3  0,0   8:05.02 ksoftirqd/11                    
>   929 root      20   0   71928   6984   4716 S   0,3  0,0  17:53.57 syslog-ng                       
>  8069 root      20   0       0      0      0 S   0,3  0,0   0:22.35 kworker/0:0                     
> 16624 root      20   0   25868   3236   2592 R   0,3  0,0   0:00.19 top                             
> 20291 squid     20   0   59504   5228   4568 S   0,3  0,0   0:03.41 digest_
>   
> FredB
>     
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180320/9f4f62cc/attachment.sig>

From fredbmail at free.fr  Tue Mar 20 17:03:35 2018
From: fredbmail at free.fr (FredB)
Date: Tue, 20 Mar 2018 18:03:35 +0100 (CET)
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <6c74c6dd-f52f-33c0-258c-e0066885d094@gmail.com>
Message-ID: <1945621316.68820965.1521565415196.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hi Yuri,

200 mbits, more or less 1000/2000 simultaneous users 

I increase children value, because the limit is reached very quickly 

> and only 100 MB on disk?

100 MB by process, no ? I think I should reduce this value and rather increase the max of children

Maybe such load is just impossible because I reached a limit with a single core 
Perhaps I should retry SMP but unfortunately in the past I had many issues with, and some features I'm using still SMP-unaware 


From yvoinov at gmail.com  Tue Mar 20 17:10:47 2018
From: yvoinov at gmail.com (Yuri)
Date: Tue, 20 Mar 2018 23:10:47 +0600
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <1945621316.68820965.1521565415196.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1945621316.68820965.1521565415196.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1c2ac182-f7d6-c5c1-bb85-c6380c32155f@gmail.com>



20.03.2018 23:03, FredB ?????:
> Hi Yuri,
>
> 200 mbits, more or less 1000/2000 simultaneous users 
>
> I increase children value, because the limit is reached very quickly 
Because of SSL processing to slow. Investigate, why. Simple increasing
number of children exghausting your RAM.
>
>> and only 100 MB on disk?
> 100 MB by process, no ? I think I should reduce this value and rather increase the max of children
No. This is overall fs limit to store.
>
> Maybe such load is just impossible because I reached a limit with a single core 
Hardly. SSL helper children should spread across cores by OS scheduler.
> Perhaps I should retry SMP but unfortunately in the past I had many issues with, and some features I'm using still SMP-unaware 
Squid's SMP itself does not solves SSL Bump issues. It's about different
things, and, IMHO, irrelevant your load profile.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180320/0aa599e4/attachment.sig>

From yvoinov at gmail.com  Tue Mar 20 17:14:54 2018
From: yvoinov at gmail.com (Yuri)
Date: Tue, 20 Mar 2018 23:14:54 +0600
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <1c2ac182-f7d6-c5c1-bb85-c6380c32155f@gmail.com>
References: <1945621316.68820965.1521565415196.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <1c2ac182-f7d6-c5c1-bb85-c6380c32155f@gmail.com>
Message-ID: <ff82b209-4ec0-5e33-b2bd-2673b25a2bdd@gmail.com>



20.03.2018 23:10, Yuri ?????:
>
> 20.03.2018 23:03, FredB ?????:
>> Hi Yuri,
>>
>> 200 mbits, more or less 1000/2000 simultaneous users 
>>
>> I increase children value, because the limit is reached very quickly 
> Because of SSL processing to slow. Investigate, why. Simple increasing
> number of children exghausting your RAM.
>>> and only 100 MB on disk?
>> 100 MB by process, no ? I think I should reduce this value and rather increase the max of children
> No. This is overall fs limit to store.
Look on my relatively big server (Squid 5.0) config snippet:

https_port 3127 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=10MB cert=/usr/local/squid/etc/rootCA2.crt
key=/usr/local/squid/etc/rootCA2.key
tls-cafile=/usr/local/squid/etc/rootCA12.crt
options=SINGLE_DH_USE:SINGLE_ECDH_USE
tls-dh=secp384r1:/usr/local/squid/etc/dhparam.pem
cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
tls-no-npn sslflags=NO_DEFAULT_CA:VERIFY_CRL_ALL
http_port 3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=10MB cert=/usr/local/squid/etc/rootCA2.crt
key=/usr/local/squid/etc/rootCA2.key
tls-cafile=/usr/local/squid/etc/rootCA12.crt
options=SINGLE_DH_USE:SINGLE_ECDH_USE
tls-dh=secp384r1:/usr/local/squid/etc/dhparam.pem
cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
tls-no-npn sslflags=NO_DEFAULT_CA:VERIFY_CRL_ALL
tls_outgoing_options cafile=/usr/local/squid/etc/ca-bundle.crt
cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS

# Cert database on ramdisk
sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
/ramdisk1/ssl_db -M 1GB
sslcrtd_children 32 startup=10 idle=5

Pay attention - I've put SSL db on RAM disk. :)
>> Maybe such load is just impossible because I reached a limit with a single core 
> Hardly. SSL helper children should spread across cores by OS scheduler.
>> Perhaps I should retry SMP but unfortunately in the past I had many issues with, and some features I'm using still SMP-unaware 
> Squid's SMP itself does not solves SSL Bump issues. It's about different
> things, and, IMHO, irrelevant your load profile.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180320/47be88ae/attachment.sig>

From yvoinov at gmail.com  Tue Mar 20 17:35:40 2018
From: yvoinov at gmail.com (Yuri)
Date: Tue, 20 Mar 2018 23:35:40 +0600
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <ff82b209-4ec0-5e33-b2bd-2673b25a2bdd@gmail.com>
References: <1945621316.68820965.1521565415196.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <1c2ac182-f7d6-c5c1-bb85-c6380c32155f@gmail.com>
 <ff82b209-4ec0-5e33-b2bd-2673b25a2bdd@gmail.com>
Message-ID: <6aab602f-ad00-c5c3-b062-41081d4c1cfc@gmail.com>

Forgot about:

My server is relatively modest (more resources just do not need :))

Just 8 cores (Xeon 2.3 GHz), 16 Gb RAM, SAS HDD's 10k RPM (~300 Gb in
RAID-10)? :)

Overall CPU usage is ~3% (with SSL Bump). And half of RAM is free :)


20.03.2018 23:14, Yuri ?????:
>
> 20.03.2018 23:10, Yuri ?????:
>> 20.03.2018 23:03, FredB ?????:
>>> Hi Yuri,
>>>
>>> 200 mbits, more or less 1000/2000 simultaneous users 
>>>
>>> I increase children value, because the limit is reached very quickly 
>> Because of SSL processing to slow. Investigate, why. Simple increasing
>> number of children exghausting your RAM.
>>>> and only 100 MB on disk?
>>> 100 MB by process, no ? I think I should reduce this value and rather increase the max of children
>> No. This is overall fs limit to store.
> Look on my relatively big server (Squid 5.0) config snippet:
>
> https_port 3127 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=10MB cert=/usr/local/squid/etc/rootCA2.crt
> key=/usr/local/squid/etc/rootCA2.key
> tls-cafile=/usr/local/squid/etc/rootCA12.crt
> options=SINGLE_DH_USE:SINGLE_ECDH_USE
> tls-dh=secp384r1:/usr/local/squid/etc/dhparam.pem
> cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> tls-no-npn sslflags=NO_DEFAULT_CA:VERIFY_CRL_ALL
> http_port 3128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=10MB cert=/usr/local/squid/etc/rootCA2.crt
> key=/usr/local/squid/etc/rootCA2.key
> tls-cafile=/usr/local/squid/etc/rootCA12.crt
> options=SINGLE_DH_USE:SINGLE_ECDH_USE
> tls-dh=secp384r1:/usr/local/squid/etc/dhparam.pem
> cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> tls-no-npn sslflags=NO_DEFAULT_CA:VERIFY_CRL_ALL
> tls_outgoing_options cafile=/usr/local/squid/etc/ca-bundle.crt
> cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>
> # Cert database on ramdisk
> sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
> /ramdisk1/ssl_db -M 1GB
> sslcrtd_children 32 startup=10 idle=5
>
> Pay attention - I've put SSL db on RAM disk. :)
>>> Maybe such load is just impossible because I reached a limit with a single core 
>> Hardly. SSL helper children should spread across cores by OS scheduler.
>>> Perhaps I should retry SMP but unfortunately in the past I had many issues with, and some features I'm using still SMP-unaware 
>> Squid's SMP itself does not solves SSL Bump issues. It's about different
>> things, and, IMHO, irrelevant your load profile.
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180320/991e33bb/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180320/991e33bb/attachment.sig>

From michael.adm at gmail.com  Tue Mar 20 19:12:41 2018
From: michael.adm at gmail.com (Michael Pro)
Date: Tue, 20 Mar 2018 21:12:41 +0200
Subject: [squid-users] tcp_outgoing_address and HTTPS
Message-ID: <CAA+Mow6UjHV21vZ0OrZ3=wkQ5Zf+QjagOJGVuhUjYmwDxTM6QQ@mail.gmail.com>

Totally agree with you, and at the same time - do not agree. But,
consider the following situation. There is https://site.net/ where
there is 1.jpg and 2.jpg. If I download from this site 1.jpg from the
address 1.1.1.1 and 2.jpg from the address 2.2.2.2. Even more. There
are situations when you need to release a certain connection to the
Internet through a single provider (for example, mobile), but you need
to download the largest file that is never physically downloaded by
this connection. On another no way. Squid theoretically these are
several computers (by the number of incoming connections) and, what
prevents us as different computers from using different outgoing
interfaces even for the same origin address?

I'm not saying that you need to push the unbroken. Look at the problem
from the other side.

For example, in Chrome, I set up a proxy 1.1.1.1 and download
https://site.net/1.jpg. At the same time in Mozilla I set up a proxy
2.2.2.2 and download https://site.net/2.jpg. What's the difference if
you set up the same one squid?
acl 1s-jpg url_regex ...1.jpg
acl 2s-jpg url_regex ... 2.jpg
tcp_outgoing_address 1.1.1.1 1s-jpg
tcp_outgoing_address 2.2.2.2 2s-jpg

Where is the entrance here?

Why do we try to shove it into one hole, if we can divide it into
separate processes. It may even need some new key or ACL to determine
that for these connections to create always new tunnels (TLS, ssl,
certs, ...)
acl separate_this CreateNewTunnelForNewLink

>> Question: how can we break the established channel (unpinn it) along
>> the old route and establish a new channel along the new route, when we
>> already know how.

> Squid supports using multiple sequential connections for the same
> from-client request, but not under the conditions you describe.
> Moreover, the already supported cases are limited to simpler HTTP/TCP
> failures. Complex code modifications would be required to support what
> you want for HTTPS, but it is doable, and others have wanted a similar
> "peek and then start from scratch" feature.


>> I'm willing to pay a large price for traffic congestion in this case,
>> since the goal justifies it.
> Please note that some origin servers may have a different opinion about
> this trade off: Some might view (repeatedly) terminated innocent
> sessions as an attack and block all your traffic.


From rousskov at measurement-factory.com  Wed Mar 21 01:33:00 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 20 Mar 2018 19:33:00 -0600
Subject: [squid-users] tcp_outgoing_address and HTTPS
In-Reply-To: <CAA+Mow6UjHV21vZ0OrZ3=wkQ5Zf+QjagOJGVuhUjYmwDxTM6QQ@mail.gmail.com>
References: <CAA+Mow6UjHV21vZ0OrZ3=wkQ5Zf+QjagOJGVuhUjYmwDxTM6QQ@mail.gmail.com>
Message-ID: <74072575-dd1c-9461-0145-a696e2a15fef@measurement-factory.com>

On 03/20/2018 01:12 PM, Michael Pro wrote:
> Totally agree with you, and at the same time - do not agree.

AFAICT, I only stated facts, not opinions. There is nothing to agree or
disagree with in my response.

Alex.


From squid3 at treenet.co.nz  Wed Mar 21 05:48:13 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 21 Mar 2018 18:48:13 +1300
Subject: [squid-users] tcp_outgoing_address and HTTPS
In-Reply-To: <CAA+Mow6UjHV21vZ0OrZ3=wkQ5Zf+QjagOJGVuhUjYmwDxTM6QQ@mail.gmail.com>
References: <CAA+Mow6UjHV21vZ0OrZ3=wkQ5Zf+QjagOJGVuhUjYmwDxTM6QQ@mail.gmail.com>
Message-ID: <93bd1722-4575-13fe-e168-dd8f6dca8aed@treenet.co.nz>

On 21/03/18 08:12, Michael Pro wrote:
> Totally agree with you, and at the same time - do not agree. But,
> consider the following situation. There is https://site.net/ where
> there is 1.jpg and 2.jpg. If I download from this site 1.jpg from the
> address 1.1.1.1 and 2.jpg from the address 2.2.2.2.

There is no such concept as "site" in TLS. It is a point-to-point protocol.
The client opened a single connection and sent two requests to what it
perceives to be a *single* server. If the interception proxy were not
there the content would have been served by that same server anyway.
There is no loss for the proxy to mimic the exact behaviour of the real
client.
 Also the responses have to be served to the client sequentially. So
there is little gain from fetching them any way but sequentially, AND
going to all the trouble of multiple TCP + TLS handshakes adds CPU + RAM
+ socket + time costs to the transaction. So it is a net negative to do
as proposed.


> Even more. There
> are situations when you need to release a certain connection to the
> Internet through a single provider (for example, mobile), but you need
> to download the largest file that is never physically downloaded by
> this connection. On another no way. Squid theoretically these are
> several computers (by the number of incoming connections) and, what
> prevents us as different computers from using different outgoing
> interfaces even for the same origin address?

The machine-specific TLS crypto keys. In RSA it was possible to copy
these keys between machines (but considered very bad practice). In DH
and ECDH new secret keys are generated for every individual TLS
handshake. They cannot be shared. Once those keys are started being used
the data inside (particular signed items) is locked to them.

To stop an HTTPS transfer mid-delivery requires the proxy to abort both
client and server TLS (and TCP) connections. Which is what the pinning does.

> 
> I'm not saying that you need to push the unbroken.

That sentence does not compute for me.

> Look at the problem
> from the other side.
> 
> For example, in Chrome, I set up a proxy 1.1.1.1 and download
> https://site.net/1.jpg. At the same time in Mozilla I set up a proxy
> 2.2.2.2 and download https://site.net/2.jpg. What's the difference if
> you set up the same one squid?

The differences are:
1) Squid is not a browser.
2) Squid is not the TLS "end-client".
2) Squid is not the TLS origin server.
3) different TLS sessions
4) different client TLS security keys
5) different server TLS security keys

Overall there is a 3-way TLS "origin":

  Chrome + 1.1.1.1:port + the specific IP:443 address of "site.net" that
Chrome chose to connect to.

  Mozilla + 2.2.2.2:port + the specific IP:443 address of "site.net"
that Mozilla chose to connect to.


> acl 1s-jpg url_regex ...1.jpg
> acl 2s-jpg url_regex ... 2.jpg
> tcp_outgoing_address 1.1.1.1 1s-jpg
> tcp_outgoing_address 2.2.2.2 2s-jpg
> 
> Where is the entrance here?

Please explain this word "entrance" as you mean it?

1.1.1.1 does not hold the dynamically created TLS state inside 2.2.2.2.

2.2.2.2 does not hold the dynamically created TLS state inside 1.1.1.1.

Squid does not hold the TLS state inside the client.

What Squid can do is deliver content in its cache (if caching is
permitted by the origin who generated it). Or deliver the encrypted
traffic to the origin server the client accepted TLS handshake with.


You are perhapse still thinking in traditional caching terms where Squid
is a client independent of the Browser and where TCP connections can be
freely disconnected and rewritten per HTTP request. In plain-text HTTP
that would be true.

When intercepting TLS / HTTPS that is false. The true end-client /
Browser is maintaining client-to-origin state in its TLS properties. For
*precisely* and intentionally the purpose of preventing exactly this
type of traffic rewriting by a proxy.


IF, and *only* if, the client is using "TLS explicit" as defined by TLS
to the proxy and sending regular HTTP requests over that secured
connection can the proxy do its own origin-server choosing freely. Some
people have been calling that type of setup "HTTPS", but really the
existence of proxy choice makes it a lot different from traditional
HTTPS on port 443.


> 
> Why do we try to shove it into one hole, if we can divide it into
> separate processes. It may even need some new key or ACL to determine
> that for these connections to create always new tunnels (TLS, ssl,
> certs, ...)
> acl separate_this CreateNewTunnelForNewLink

When ability to generate CONNECTs is added that should not be necessary.
Whether the cache_peer can handle the CONNECT attempt will automatically
determine whether a tunnel is possible as an alternative to
DIRECT/PINNED connection.

Amos


From fredbmail at free.fr  Wed Mar 21 08:55:53 2018
From: fredbmail at free.fr (FredB)
Date: Wed, 21 Mar 2018 09:55:53 +0100 (CET)
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <1c2ac182-f7d6-c5c1-bb85-c6380c32155f@gmail.com>
Message-ID: <113632435.70726986.1521622553336.JavaMail.root@zimbra4-e1.priv.proxad.net>


> > Perhaps I should retry SMP but unfortunately in the past I had many
> > issues with, and some features I'm using still SMP-unaware
> Squid's SMP itself does not solves SSL Bump issues. It's about
> different
> things, and, IMHO, irrelevant your load profile.


I'm thinking about that, because the single squid core is 100% CPU
I tried with 900MB and 50MB without more success, I also added sslflags-NO_DEFAULT_CA

How much simultaneous users do you have ? and bandwidth ? 

I'm using this right now, the number of process used is very better now but still an issue with CPU  

acl nobump dstdomain "/home/squid/domains"

http_port 8080 ssl-bump cert=/etc/squid/ca_orion/cert generate-host-certificates=on sslflags=NO_DEFAULT_CA dynamic_cert_mem_cache_size=500MB
sslcrtd_program /usr/lib/squid/ssl_crtd -s /usr/lib/squid/ssl_db -M 500MB
sslcrtd_children 1000 startup=100 idle=5

sslproxy_capath /etc/ssl/certs/
sslproxy_foreign_intermediate_certs /etc/squid/ssl_certs/imtermediate.ca.pem

acl step1 at_step SslBump1
ssl_bump peek step1 all
ssl_bump splice nobump
ssl_bump bump all

Maybe there is a problem with memory, but as you can see here CPU is the point 

top - 09:50:04 up 16:16,  1 user,  load average: 1,72, 1,78, 1,39
Tasks: 393 total,   3 running, 390 sleeping,   0 stopped,   0 zombie
%Cpu(s):  8,4 us,  1,2 sy,  0,0 ni, 89,6 id,  0,3 wa,  0,0 hi,  0,5 si,  0,0 st
KiB Mem:  66086692 total, 28654240 used, 37432452 free,  2974568 buffers
KiB Swap:  1952764 total,        0 used,  1952764 free. 17653336 cached Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                                                                                  
 9803 squid     20   0 3913044 3,452g  13464 R  99,9  5,5   7:47.47 squid                                                                                                                                                                    
10051 e2guard+  20   0  0,122t 284392   5124 S  25,6  0,4   1:33.10 e2guardian                                                                                                                                                               
 9804 squid     20   0   21956   5628   4420 S   7,3  0,0   0:48.93 ssl_crtd                                                                                                                                                                 
 9805 squid     20   0   21952   5672   4372 S   6,3  0,0   0:31.25 ssl_crtd                                                                                                                                                                 
 9806 squid     20   0   21952   5476   4252 S   2,7  0,0   0:19.10 ssl_crtd                                                                                                                                                                 
 9807 squid     20   0   21952   5616   4408 S   2,3  0,0   0:13.88 ssl_crtd                                                                                                                                                                 
 9808 squid     20   0   21952   5540   4332 S   2,3  0,0   0:10.59 ssl_crtd                                                                                                                                                                 
 9810 squid     20   0   21956   5536   4332 S   2,0  0,0   0:05.61 ssl_crtd                                                                                                                                                                 
 9809 squid     20   0   21952   5584   4372 S   1,7  0,0   0:07.40 ssl_crtd                                                                                                                                                                 
 9996 squid     20   0   25612   2924   2696 S   1,3  0,0   0:05.47 diskd                                                                                                                                                                    
 9995 squid     20   0   25612   2744   2516 S   1,0  0,0   0:04.41 diskd                                                                                                                                                                    
 9811 squid     20   0   21964   5588   4372 S   0,7  0,0   0:03.72 ssl_crtd                                                                                                                                                                 
 9813 squid     20   0   21848   5660   4464 S   0,7  0,0   0:01.96 ssl_crtd    

Amos, there is way to add the domain requested in message like this ?

2018/03/21 09:45:30| Error negotiating SSL on FD 1835: error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2018/03/21 09:45:30| Error negotiating SSL on FD 4782: error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)

It can be very, very, useful for analysis 

Thanks

FredB


From yvoinov at gmail.com  Wed Mar 21 12:56:41 2018
From: yvoinov at gmail.com (Yuri)
Date: Wed, 21 Mar 2018 18:56:41 +0600
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <113632435.70726986.1521622553336.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <113632435.70726986.1521622553336.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <fe05f30c-0d2c-72b0-40c7-b73509e7cdcc@gmail.com>



21.03.2018 14:55, FredB ?????:
>>> Perhaps I should retry SMP but unfortunately in the past I had many
>>> issues with, and some features I'm using still SMP-unaware
>> Squid's SMP itself does not solves SSL Bump issues. It's about
>> different
>> things, and, IMHO, irrelevant your load profile.
>
> I'm thinking about that, because the single squid core is 100% CPU
> I tried with 900MB and 50MB without more success, I also added sslflags-NO_DEFAULT_CA
>
> How much simultaneous users do you have ? and bandwidth ? 
200 users, 2 Gbps downstream.
>
> I'm using this right now, the number of process used is very better now but still an issue with CPU  
>
> acl nobump dstdomain "/home/squid/domains"
>
> http_port 8080 ssl-bump cert=/etc/squid/ca_orion/cert generate-host-certificates=on sslflags=NO_DEFAULT_CA dynamic_cert_mem_cache_size=500MB
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /usr/lib/squid/ssl_db -M 500MB
> sslcrtd_children 1000 startup=100 idle=5
It does not work that way. There are still many processes. Scaling is
rarely linear.

Pls keep in mind, squid itself is thread-unaware. So, with thousands of
children you make serialization point by yourself from squid's size.
Another serialization point is SSL db on disk, due to it uses file
locking mechanism.

Both reasons leads to make bottleneck on SSL certgen processes.

So, you can't simple set 1000 children and expect good performing.

Just for record:
Performance tuning/scaling makes different. Much different.

1. You require to set good initial approximation. Not by proportion "1
user - 1 child instance".
2. Then run your load and get performance statistics.
3. Analyze results.
4. Based on step 3, increasing/decreasing parameter value.

General rule: change only one parameter during tuning/scaling iteration.
>
> sslproxy_capath /etc/ssl/certs/
> sslproxy_foreign_intermediate_certs /etc/squid/ssl_certs/imtermediate.ca.pem
>
> acl step1 at_step SslBump1
> ssl_bump peek step1 all
> ssl_bump splice nobump
> ssl_bump bump all
>
> Maybe there is a problem with memory, but as you can see here CPU is the point 
Yes, indeed. You eat up too much RAM due to misconfiguration. But also
you have 2 waiting points descrived above.

I can recommend you get wait CPU/IO performance events to make sure.

Wait IO events can increasing CPU consumption, when such structures of
queues overflows etc. Usually this occurs on thread-aware apps with
spin-count synchronization mech, however, often can occurs on
single-threaded applications depenging implementation.
>
> top - 09:50:04 up 16:16,  1 user,  load average: 1,72, 1,78, 1,39
> Tasks: 393 total,   3 running, 390 sleeping,   0 stopped,   0 zombie
> %Cpu(s):  8,4 us,  1,2 sy,  0,0 ni, 89,6 id,  0,3 wa,  0,0 hi,  0,5 si,  0,0 st
> KiB Mem:  66086692 total, 28654240 used, 37432452 free,  2974568 buffers
> KiB Swap:  1952764 total,        0 used,  1952764 free. 17653336 cached Mem
>
>   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                                                                                  
>  9803 squid     20   0 3913044 3,452g  13464 R  99,9  5,5   7:47.47 squid                                                                                                                                                                    
> 10051 e2guard+  20   0  0,122t 284392   5124 S  25,6  0,4   1:33.10 e2guardian                                                                                                                                                               
>  9804 squid     20   0   21956   5628   4420 S   7,3  0,0   0:48.93 ssl_crtd                                                                                                                                                                 
>  9805 squid     20   0   21952   5672   4372 S   6,3  0,0   0:31.25 ssl_crtd                                                                                                                                                                 
>  9806 squid     20   0   21952   5476   4252 S   2,7  0,0   0:19.10 ssl_crtd                                                                                                                                                                 
>  9807 squid     20   0   21952   5616   4408 S   2,3  0,0   0:13.88 ssl_crtd                                                                                                                                                                 
>  9808 squid     20   0   21952   5540   4332 S   2,3  0,0   0:10.59 ssl_crtd                                                                                                                                                                 
>  9810 squid     20   0   21956   5536   4332 S   2,0  0,0   0:05.61 ssl_crtd                                                                                                                                                                 
>  9809 squid     20   0   21952   5584   4372 S   1,7  0,0   0:07.40 ssl_crtd                                                                                                                                                                 
>  9996 squid     20   0   25612   2924   2696 S   1,3  0,0   0:05.47 diskd                                                                                                                                                                    
>  9995 squid     20   0   25612   2744   2516 S   1,0  0,0   0:04.41 diskd                                                                                                                                                                    
>  9811 squid     20   0   21964   5588   4372 S   0,7  0,0   0:03.72 ssl_crtd                                                                                                                                                                 
>  9813 squid     20   0   21848   5660   4464 S   0,7  0,0   0:01.96 ssl_crtd  
As you can see, your Squid's consumes most CPU. And __not__ ssl_crtd.
So, most probably you have bottleneck between squid and ssl_crtd due to
reasons above.
>   
>
> Amos, there is way to add the domain requested in message like this ?
>
> 2018/03/21 09:45:30| Error negotiating SSL on FD 1835: error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
> 2018/03/21 09:45:30| Error negotiating SSL on FD 4782: error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
>
> It can be very, very, useful for analysis 
>
> Thanks
>
> FredB
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180321/35830dcb/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180321/35830dcb/attachment.sig>

From yvoinov at gmail.com  Wed Mar 21 13:08:09 2018
From: yvoinov at gmail.com (Yuri)
Date: Wed, 21 Mar 2018 19:08:09 +0600
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <113632435.70726986.1521622553336.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <113632435.70726986.1521622553336.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <424992eb-7af9-23f4-b156-e3ded4569f19@gmail.com>



21.03.2018 14:55, FredB ?????:
>>> Perhaps I should retry SMP but unfortunately in the past I had many
>>> issues with, and some features I'm using still SMP-unaware
>> Squid's SMP itself does not solves SSL Bump issues. It's about
>> different
>> things, and, IMHO, irrelevant your load profile.
>
> I'm thinking about that, because the single squid core is 100% CPU
> I tried with 900MB and 50MB without more success, I also added sslflags-NO_DEFAULT_CA
>
> How much simultaneous users do you have ? and bandwidth ? 
>
> I'm using this right now, the number of process used is very better now but still an issue with CPU  
>
> acl nobump dstdomain "/home/squid/domains"
>
> http_port 8080 ssl-bump cert=/etc/squid/ca_orion/cert generate-host-certificates=on sslflags=NO_DEFAULT_CA dynamic_cert_mem_cache_size=500MB
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /usr/lib/squid/ssl_db -M 500MB
> sslcrtd_children 1000 startup=100 idle=5
Still misconfiguration. Pay attention. You set

dynamic_cert_mem_cache_size=500MB

Again - why so much?

Do not think that a lot of RAM will not make anything worse.

For some unknown reason, you set dynamic_cert_mem_cache_size equal to -M
on-disk fs limit. It is enough to set dynamic_cert_mem_cache_size to
1/10-1/20 of overall SSL db on-disk size.

And still too high upper children limit. Just imagine, how much RAM will
eat by 1000 processes. Each with own heap.

It seems for me, in your case good initial approximation will be

sslcrtd_children 256 startup=100 idle=200


No more. Other changes will do only based on performance stats and
diagnostics.

> sslproxy_capath /etc/ssl/certs/
> sslproxy_foreign_intermediate_certs /etc/squid/ssl_certs/imtermediate.ca.pem
>
> acl step1 at_step SslBump1
> ssl_bump peek step1 all
> ssl_bump splice nobump
> ssl_bump bump all
>
> Maybe there is a problem with memory, but as you can see here CPU is the point 
>
> top - 09:50:04 up 16:16,  1 user,  load average: 1,72, 1,78, 1,39
> Tasks: 393 total,   3 running, 390 sleeping,   0 stopped,   0 zombie
> %Cpu(s):  8,4 us,  1,2 sy,  0,0 ni, 89,6 id,  0,3 wa,  0,0 hi,  0,5 si,  0,0 st
> KiB Mem:  66086692 total, 28654240 used, 37432452 free,  2974568 buffers
> KiB Swap:  1952764 total,        0 used,  1952764 free. 17653336 cached Mem
>
>   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                                                                                  
>  9803 squid     20   0 3913044 3,452g  13464 R  99,9  5,5   7:47.47 squid                                                                                                                                                                    
> 10051 e2guard+  20   0  0,122t 284392   5124 S  25,6  0,4   1:33.10 e2guardian                                                                                                                                                               
>  9804 squid     20   0   21956   5628   4420 S   7,3  0,0   0:48.93 ssl_crtd                                                                                                                                                                 
>  9805 squid     20   0   21952   5672   4372 S   6,3  0,0   0:31.25 ssl_crtd                                                                                                                                                                 
>  9806 squid     20   0   21952   5476   4252 S   2,7  0,0   0:19.10 ssl_crtd                                                                                                                                                                 
>  9807 squid     20   0   21952   5616   4408 S   2,3  0,0   0:13.88 ssl_crtd                                                                                                                                                                 
>  9808 squid     20   0   21952   5540   4332 S   2,3  0,0   0:10.59 ssl_crtd                                                                                                                                                                 
>  9810 squid     20   0   21956   5536   4332 S   2,0  0,0   0:05.61 ssl_crtd                                                                                                                                                                 
>  9809 squid     20   0   21952   5584   4372 S   1,7  0,0   0:07.40 ssl_crtd                                                                                                                                                                 
>  9996 squid     20   0   25612   2924   2696 S   1,3  0,0   0:05.47 diskd                                                                                                                                                                    
>  9995 squid     20   0   25612   2744   2516 S   1,0  0,0   0:04.41 diskd                                                                                                                                                                    
>  9811 squid     20   0   21964   5588   4372 S   0,7  0,0   0:03.72 ssl_crtd                                                                                                                                                                 
>  9813 squid     20   0   21848   5660   4464 S   0,7  0,0   0:01.96 ssl_crtd    
>
> Amos, there is way to add the domain requested in message like this ?
>
> 2018/03/21 09:45:30| Error negotiating SSL on FD 1835: error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
> 2018/03/21 09:45:30| Error negotiating SSL on FD 4782: error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
>
> It can be very, very, useful for analysis 
>
> Thanks
>
> FredB
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180321/898b0896/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180321/898b0896/attachment.sig>

From yvoinov at gmail.com  Wed Mar 21 13:19:19 2018
From: yvoinov at gmail.com (Yuri)
Date: Wed, 21 Mar 2018 19:19:19 +0600
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <424992eb-7af9-23f4-b156-e3ded4569f19@gmail.com>
References: <113632435.70726986.1521622553336.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <424992eb-7af9-23f4-b156-e3ded4569f19@gmail.com>
Message-ID: <606705f6-fedd-d92f-b7b0-a477399018e0@gmail.com>

Finally.

Premature optimization is the root of all evils.

Never start new setups from your assumptions only. Set good enough
starting values and monitor. Increase only if required.

And, pls, don't think all performance problems can solves with giant RAM.

It does not matter how big your RAM is. It's important how you use it.

Scaling is also done differently.


21.03.2018 19:08, Yuri ?????:
>
>
>
> 21.03.2018 14:55, FredB ?????:
>>>> Perhaps I should retry SMP but unfortunately in the past I had many
>>>> issues with, and some features I'm using still SMP-unaware
>>> Squid's SMP itself does not solves SSL Bump issues. It's about
>>> different
>>> things, and, IMHO, irrelevant your load profile.
>> I'm thinking about that, because the single squid core is 100% CPU
>> I tried with 900MB and 50MB without more success, I also added sslflags-NO_DEFAULT_CA
>>
>> How much simultaneous users do you have ? and bandwidth ? 
>>
>> I'm using this right now, the number of process used is very better now but still an issue with CPU  
>>
>> acl nobump dstdomain "/home/squid/domains"
>>
>> http_port 8080 ssl-bump cert=/etc/squid/ca_orion/cert generate-host-certificates=on sslflags=NO_DEFAULT_CA dynamic_cert_mem_cache_size=500MB
>> sslcrtd_program /usr/lib/squid/ssl_crtd -s /usr/lib/squid/ssl_db -M 500MB
>> sslcrtd_children 1000 startup=100 idle=5
> Still misconfiguration. Pay attention. You set
> dynamic_cert_mem_cache_size=500MB
> Again - why so much?
>
> Do not think that a lot of RAM will not make anything worse.
>
> For some unknown reason, you set dynamic_cert_mem_cache_size equal to
> -M on-disk fs limit. It is enough to set dynamic_cert_mem_cache_size
> to 1/10-1/20 of overall SSL db on-disk size.
>
> And still too high upper children limit. Just imagine, how much RAM
> will eat by 1000 processes. Each with own heap.
>
> It seems for me, in your case good initial approximation will be
>
> sslcrtd_children 256 startup=100 idle=200
>
> No more. Other changes will do only based on performance stats and
> diagnostics.
>
>> sslproxy_capath /etc/ssl/certs/
>> sslproxy_foreign_intermediate_certs /etc/squid/ssl_certs/imtermediate.ca.pem
>>
>> acl step1 at_step SslBump1
>> ssl_bump peek step1 all
>> ssl_bump splice nobump
>> ssl_bump bump all
>>
>> Maybe there is a problem with memory, but as you can see here CPU is the point 
>>
>> top - 09:50:04 up 16:16,  1 user,  load average: 1,72, 1,78, 1,39
>> Tasks: 393 total,   3 running, 390 sleeping,   0 stopped,   0 zombie
>> %Cpu(s):  8,4 us,  1,2 sy,  0,0 ni, 89,6 id,  0,3 wa,  0,0 hi,  0,5 si,  0,0 st
>> KiB Mem:  66086692 total, 28654240 used, 37432452 free,  2974568 buffers
>> KiB Swap:  1952764 total,        0 used,  1952764 free. 17653336 cached Mem
>>
>>   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                                                                                  
>>  9803 squid     20   0 3913044 3,452g  13464 R  99,9  5,5   7:47.47 squid                                                                                                                                                                    
>> 10051 e2guard+  20   0  0,122t 284392   5124 S  25,6  0,4   1:33.10 e2guardian                                                                                                                                                               
>>  9804 squid     20   0   21956   5628   4420 S   7,3  0,0   0:48.93 ssl_crtd                                                                                                                                                                 
>>  9805 squid     20   0   21952   5672   4372 S   6,3  0,0   0:31.25 ssl_crtd                                                                                                                                                                 
>>  9806 squid     20   0   21952   5476   4252 S   2,7  0,0   0:19.10 ssl_crtd                                                                                                                                                                 
>>  9807 squid     20   0   21952   5616   4408 S   2,3  0,0   0:13.88 ssl_crtd                                                                                                                                                                 
>>  9808 squid     20   0   21952   5540   4332 S   2,3  0,0   0:10.59 ssl_crtd                                                                                                                                                                 
>>  9810 squid     20   0   21956   5536   4332 S   2,0  0,0   0:05.61 ssl_crtd                                                                                                                                                                 
>>  9809 squid     20   0   21952   5584   4372 S   1,7  0,0   0:07.40 ssl_crtd                                                                                                                                                                 
>>  9996 squid     20   0   25612   2924   2696 S   1,3  0,0   0:05.47 diskd                                                                                                                                                                    
>>  9995 squid     20   0   25612   2744   2516 S   1,0  0,0   0:04.41 diskd                                                                                                                                                                    
>>  9811 squid     20   0   21964   5588   4372 S   0,7  0,0   0:03.72 ssl_crtd                                                                                                                                                                 
>>  9813 squid     20   0   21848   5660   4464 S   0,7  0,0   0:01.96 ssl_crtd    
>>
>> Amos, there is way to add the domain requested in message like this ?
>>
>> 2018/03/21 09:45:30| Error negotiating SSL on FD 1835: error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
>> 2018/03/21 09:45:30| Error negotiating SSL on FD 4782: error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
>>
>> It can be very, very, useful for analysis 
>>
>> Thanks
>>
>> FredB
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> -- 
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180321/7a1d5c3e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180321/7a1d5c3e/attachment.sig>

From fredbmail at free.fr  Wed Mar 21 13:23:47 2018
From: fredbmail at free.fr (FredB)
Date: Wed, 21 Mar 2018 14:23:47 +0100 (CET)
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <424992eb-7af9-23f4-b156-e3ded4569f19@gmail.com>
Message-ID: <1597935141.71704447.1521638627408.JavaMail.root@zimbra4-e1.priv.proxad.net>

Sorry, it was just a wrong cut/paste cache_size=50MB the previous result still the same
About children I tried with 256, unfortunately squid is still stuck at 100% 

Regards

Fred



From yvoinov at gmail.com  Wed Mar 21 13:43:24 2018
From: yvoinov at gmail.com (Yuri)
Date: Wed, 21 Mar 2018 19:43:24 +0600
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <1597935141.71704447.1521638627408.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1597935141.71704447.1521638627408.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <eb6ea9ec-3e47-a770-cf4a-7b2a1d81b6ca@gmail.com>

Aha, this is better.

So, next step should be detailed performance statistics to identify
bottleneck.

As I've said - check wait events first.


21.03.2018 19:23, FredB ?????:
> Sorry, it was just a wrong cut/paste cache_size=50MB the previous result still the same
> About children I tried with 256, unfortunately squid is still stuck at 100% 
>
> Regards
>
> Fred
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180321/94c62eb1/attachment.sig>

From fredbmail at free.fr  Wed Mar 21 14:05:27 2018
From: fredbmail at free.fr (FredB)
Date: Wed, 21 Mar 2018 15:05:27 +0100 (CET)
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <606705f6-fedd-d92f-b7b0-a477399018e0@gmail.com>
Message-ID: <911294857.71854874.1521641127935.JavaMail.root@zimbra4-e1.priv.proxad.net>

I agree, to be honest I started with low values updated again and again, I should have post my previous tests rather than the latest :)
 



From yvoinov at gmail.com  Wed Mar 21 14:13:12 2018
From: yvoinov at gmail.com (Yuri)
Date: Wed, 21 Mar 2018 20:13:12 +0600
Subject: [squid-users] SSLBump, system requirements ?
In-Reply-To: <911294857.71854874.1521641127935.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <911294857.71854874.1521641127935.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <2d1a7a7d-e21b-f954-20c4-95e6fb552f35@gmail.com>

Use OS performance tools. Require to identify bottleneck. Pay attention
on wait events.


21.03.2018 20:05, FredB ?????:
> I agree, to be honest I started with low values updated again and again, I should have post my previous tests rather than the latest :)
>  
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180321/b9477d3c/attachment.sig>

From paul at thepottshouse.org  Wed Mar 21 17:45:14 2018
From: paul at thepottshouse.org (paul at thepottshouse.org)
Date: Wed, 21 Mar 2018 10:45:14 -0700
Subject: [squid-users] Possible Bug? "parameters()" syntax in acl dstdomain
	results in rule not working?
Message-ID: <48ffb41d242e19eadf6a1822127f6e0a0331277c@webmail.thepottshouse.org>

Hello,

I am running squid 3.5.23 on Debian 9. My goal was to try to set up a
simple proxy server for whitelisting.

It's working now, but I had some difficulty. In the release notes I
came across this example:

http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.23-RELEASENOTES.html#s3

It shows specifying a whitelist like so:

acl whitelist dstdomain parameters("/etc/squid/whitelist.txt")

So I tried this, and spent quite some time trying to figure out why it
didn't work. I got no errors, but this rule seemed to cause rejection
of all destination domains.

I finally realized there appeared to be something wrong with the
"parameters" handling of the external file, and turned it into:

acl WHITELIST dstdomain "/etc/squid/whitelist.txt"

With that one change it worked properly.

Is this a known bug?

Thanks,

Paul
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180321/a80e81ab/attachment.htm>

From rousskov at measurement-factory.com  Wed Mar 21 18:07:31 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 21 Mar 2018 12:07:31 -0600
Subject: [squid-users] Possible Bug? "parameters()" syntax in acl
 dstdomain results in rule not working?
In-Reply-To: <48ffb41d242e19eadf6a1822127f6e0a0331277c@webmail.thepottshouse.org>
References: <48ffb41d242e19eadf6a1822127f6e0a0331277c@webmail.thepottshouse.org>
Message-ID: <53fb3c86-f0a5-03ae-5b87-2594bd4f1f57@measurement-factory.com>

On 03/21/2018 11:45 AM, paul at thepottshouse.org wrote:
> Hello,
> 
> I am running squid 3.5.23 on Debian 9. My goal was to try to set up a
> simple proxy server for whitelisting.
> 
> It's working now, but I had some difficulty. In the release notes I came
> across this example:
> 
> http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.23-RELEASENOTES.html#s3
> 
> It shows specifying a whitelist like so:
> 
> acl whitelist dstdomain parameters("/etc/squid/whitelist.txt")
> 
> So I tried this, and spent quite some time trying to figure out why it
> didn't work. I got no errors, but this rule seemed to cause rejection of
> all destination domains.
> 
> I finally realized there appeared to be something wrong with the
> "parameters" handling of the external file, and turned it into:
> 
> acl WHITELIST dstdomain "/etc/squid/whitelist.txt"
> 
> With that one change it worked properly.
> 
> Is this a known bug?

IIRC, to use parameters(), you need to turn
configuration_includes_quoted_values on:

http://www.squid-cache.org/Doc/config/configuration_includes_quoted_values/

Unfortunately, it is extremely difficult to upgrade squid.conf syntax
from the current ad hoc mess to something that can be easily validated,
extended, and improved. That directive was an attempt to solve one of
the major existing syntax problems (handling of spaces in directive
parameters), but we could not enable it by default because it could
cause difficult-to-detect problems in existing configurations. There
were also some regex-related problems IIRC.

AFAIK, nobody is working on improving this further. Rejecting or warning
about "parameters(" when configuration_includes_quoted_values is off
would be one of those improvements.


HTH,

Alex.


From Jason.Zions at microsoft.com  Wed Mar 21 19:15:37 2018
From: Jason.Zions at microsoft.com (Jason Zions)
Date: Wed, 21 Mar 2018 19:15:37 +0000
Subject: [squid-users] unsubscribe
Message-ID: <BN6PR21MB0113AB11E328A0120F08997CF7AA0@BN6PR21MB0113.namprd21.prod.outlook.com>

unsubscribe

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180321/f0397c15/attachment.htm>

From dan at getbusi.com  Wed Mar 21 22:34:52 2018
From: dan at getbusi.com (Dan Charlesworth)
Date: Thu, 22 Mar 2018 09:34:52 +1100
Subject: [squid-users] Squid 4 EL6 RPMs
Message-ID: <CAN8nrKDdLm7=yAE6-4BfbqQtgSn5fzO0LweKdzFJNPWC12THrw@mail.gmail.com>

Hello all,

I'm wondering if anyone can point to a Squid 4 RPM package for CentOS /
RHEL 6.

I've had a search around, but it seems people are only packaging it for EL7.

I did try compiling an EL6 RPM myself, based on an EL7 source RPM, but I'm
not adept in this area and couldn't get past certain unfamiliar errors.

Any advice welcome!

Best,
Dan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180322/37bd95d1/attachment.htm>

From listas_quijada at hotmail.com  Wed Mar 21 23:24:37 2018
From: listas_quijada at hotmail.com (Edwin Quijada)
Date: Wed, 21 Mar 2018 23:24:37 +0000
Subject: [squid-users] Access to different groups SQuid3
Message-ID: <BN6PR15MB1203236C207C8D0F03E2BF75E3AA0@BN6PR15MB1203.namprd15.prod.outlook.com>

Hi!
I am a newbie using SQUID and I have a question :
I have 4 different groups in my company each group has access different but I dont know how create an ACL to give access for each group.

These groups and users are in a mysql database in the same box is SQUID3.

How can I create this ACL to permit access for these groups ?

Thks

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180321/03fd8678/attachment.htm>

From Antony.Stone at squid.open.source.it  Wed Mar 21 23:37:53 2018
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 22 Mar 2018 00:37:53 +0100
Subject: [squid-users] unsubscribe
In-Reply-To: <BN6PR21MB0113AB11E328A0120F08997CF7AA0@BN6PR21MB0113.namprd21.prod.outlook.com>
References: <BN6PR21MB0113AB11E328A0120F08997CF7AA0@BN6PR21MB0113.namprd21.prod.outlook.com>
Message-ID: <201803220037.53275.Antony.Stone@squid.open.source.it>

On Wednesday 21 March 2018 at 20:15:37, Jason Zions wrote:

> unsubscribe

No, that's not how things work.

Please see the footers from every posting on this list, as shown below:

> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Alternatively please see the headers from every posting on this list, which 
any competent mail client will show you, as shown below:

List-Unsubscribe: <http://lists.squid-cache.org/options/squid-users>,
  <mailto:squid-users-request at lists.squid-cache.org?subject=unsubscribe>
List-Archive: <http://lists.squid-cache.org/pipermail/squid-users/>
List-Post: <mailto:squid-users at lists.squid-cache.org>
List-Help: <mailto:squid-users-request at lists.squid-cache.org?subject=help>
List-Subscribe: <http://lists.squid-cache.org/listinfo/squid-users>,
  <mailto:squid-users-request at lists.squid-cache.org?subject=subscribe>


Regards,


Antony.

-- 
Archaeologists have found a previously-unknown dinosaur which seems to have 
had a very large vocabulary.  They've named it Thesaurus.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From claudiu.saiz at gmail.com  Thu Mar 22 14:04:17 2018
From: claudiu.saiz at gmail.com (claudiu.saiz)
Date: Thu, 22 Mar 2018 07:04:17 -0700 (MST)
Subject: [squid-users] how to set a custom ICAP "Allow" header?
Message-ID: <1521727457827-0.post@n4.nabble.com>

I want to set a custom "Allow" header in ICAP OPTIONS messages, in order to
allow Trailer support for ICAP.

I tried:

/acl all_requests src all
adaptation_meta Allow "trailers" all_requests/

, but it doesn't work since "Allow" is a reserved header name.

Is there any way to do this?



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Thu Mar 22 14:58:31 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 23 Mar 2018 03:58:31 +1300
Subject: [squid-users] how to set a custom ICAP "Allow" header?
In-Reply-To: <1521727457827-0.post@n4.nabble.com>
References: <1521727457827-0.post@n4.nabble.com>
Message-ID: <833ebdab-caa8-f773-4f04-b79d7f821850@treenet.co.nz>

On 23/03/18 03:04, claudiu.saiz wrote:
> I want to set a custom "Allow" header in ICAP OPTIONS messages, in order to
> allow Trailer support for ICAP.

That is not how protocols work. Agents advertise what features they
support and recipients can choose to use those features they understand
(or not).

No amount of forcing headers to be sent will make feature behaviours
actually happen in the proper way (quite the opposite). Nor magically
make the necessary code exist if they are not already supported.



> 
> I tried:
> 
> /acl all_requests src all
> adaptation_meta Allow "trailers" all_requests/
> 
> , but it doesn't work since "Allow" is a reserved header name.
> 
> Is there any way to do this?


Support for the still experimental ICAP Trailers feature is only
available in Squid-5. So if you require this feature you will thus be
required to run the Squid-5.0.0 alpha code at present. And it will
*only* work if the ICAP service contains matching support for the feature.
 <http://www.squid-cache.org/Versions/v5/>


HTH
Amos


From claudiu.saiz at gmail.com  Thu Mar 22 15:07:33 2018
From: claudiu.saiz at gmail.com (claudiu.saiz)
Date: Thu, 22 Mar 2018 08:07:33 -0700 (MST)
Subject: [squid-users] how to set a custom ICAP "Allow" header?
In-Reply-To: <833ebdab-caa8-f773-4f04-b79d7f821850@treenet.co.nz>
References: <1521727457827-0.post@n4.nabble.com>
 <833ebdab-caa8-f773-4f04-b79d7f821850@treenet.co.nz>
Message-ID: <1521731253622-0.post@n4.nabble.com>

Yes, I have an ICAP service that supports trailers but negotiation is needed
in order for the service to enable the feature (as described in the errata:
http://www.measurement-factory.com/std/icap/#e3).

Thank you for the information, I will try Squid-5.

Regards



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Thu Mar 22 15:09:02 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 23 Mar 2018 04:09:02 +1300
Subject: [squid-users] Squid 4 EL6 RPMs
In-Reply-To: <CAN8nrKDdLm7=yAE6-4BfbqQtgSn5fzO0LweKdzFJNPWC12THrw@mail.gmail.com>
References: <CAN8nrKDdLm7=yAE6-4BfbqQtgSn5fzO0LweKdzFJNPWC12THrw@mail.gmail.com>
Message-ID: <40ee9112-2bf4-e21a-61a8-4ec44d9bc431@treenet.co.nz>

On 22/03/18 11:34, Dan Charlesworth wrote:
> Hello all,
> 
> I'm wondering if anyone can point to a Squid 4 RPM package for CentOS /
> RHEL 6.
> 

IIRC it is not a simple proposition. Squid-4 requires minimum compiler
versions that are not available in those ancient OS. It is often a
simpler proposition to upgrade to RHEL 7+ than to selectively upgrade
the core system libraries for C++11 support and rebuild all the things
using them.


> I've had a search around, but it seems people are only packaging it for EL7.
> 
> I did try compiling an EL6 RPM myself, based on an EL7 source RPM, but
> I'm not adept in this area and couldn't get past certain unfamiliar errors.
> 

Are you using the system default compiler or something much newer?


Amos


From squid3 at treenet.co.nz  Thu Mar 22 15:24:04 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 23 Mar 2018 04:24:04 +1300
Subject: [squid-users] Access to different groups SQuid3
In-Reply-To: <BN6PR15MB1203236C207C8D0F03E2BF75E3AA0@BN6PR15MB1203.namprd15.prod.outlook.com>
References: <BN6PR15MB1203236C207C8D0F03E2BF75E3AA0@BN6PR15MB1203.namprd15.prod.outlook.com>
Message-ID: <64265e56-419b-eb24-8efa-310db4c533f7@treenet.co.nz>

On 22/03/18 12:24, Edwin Quijada wrote:
> Hi!
> I am a newbie using SQUID and I have a question :
> I have 4 different groups in my company each group has access different
> but I dont know how create an ACL to give access for each group.
> 
> These groups and users are in a mysql database in the same box is SQUID3.
> 
> How can I create this ACL to permit access for these groups ?
> 

<https://wiki.squid-cache.org/ConfigExamples/Authenticate/Groups>

There is no helper bundled with Squid specifically to do SQL DB lookups
for groups. But you should be able to use the Basic auth DB helper to do
different SQL queries for username+group instead of username+password
easily enough.
<http://www.squid-cache.org/Versions/v3/3.5/manuals/basic_db_auth.html>

Amos


From rousskov at measurement-factory.com  Thu Mar 22 15:50:04 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 22 Mar 2018 09:50:04 -0600
Subject: [squid-users] how to set a custom ICAP "Allow" header?
In-Reply-To: <1521731253622-0.post@n4.nabble.com>
References: <1521727457827-0.post@n4.nabble.com>
 <833ebdab-caa8-f773-4f04-b79d7f821850@treenet.co.nz>
 <1521731253622-0.post@n4.nabble.com>
Message-ID: <07b78170-4386-4173-e917-8a11ae38a959@measurement-factory.com>

On 03/22/2018 09:07 AM, claudiu.saiz wrote:
> Yes, I have an ICAP service that supports trailers but negotiation is needed
> in order for the service to enable the feature (as described in the errata:
> http://www.measurement-factory.com/std/icap/#e3).

Sending ICAP Allow:trailers request header is necessary but not
sufficient for ICAP trailers support:
https://tools.ietf.org/html/draft-rousskov-icap-trailers-01

As Amos has said, the necessary code is in Squid v5 (the current master
branch).


Cheers,

Alex.


From Keith.Hartley at geocent.com  Thu Mar 22 17:10:15 2018
From: Keith.Hartley at geocent.com (Keith Hartley)
Date: Thu, 22 Mar 2018 17:10:15 +0000
Subject: [squid-users] Squid for windows Very slow downloads of large files
 through squid with normal uploads
Message-ID: <BLUPR06MB1747D5BF0659E34BFE3FE7E6EEA90@BLUPR06MB1747.namprd06.prod.outlook.com>

I am using squid 3.5 for windows as a transparent proxy to provide internet access to 7 servers in a secure environment that otherwise does not have internet access. I have two squids running behind a load balancer, each one is running server 2016 core with 2 Xeon processors that is either haswell generation with 1:1 physical processor to virtual processor mapping or a hyper-threading Broadwell generation processor that is 1:1 logical processor to virtual processor mapping, depending on how they are provisioned when they get started.

Doing a bandwidth test directly in the VM I am able to get internet throughput of 800-1200 Mbps.

Doing a file copy to and from the VM I am able to get 1200 Mbps lan throughput.

In proxied uploads I have observed speeds as high as 120 Mbps, which is more than enough for what I need and the bottleneck is likely in the backup software rather than squid. Uploads performance I am not worried about where they are at now - even if I only got 20-30 Mbps it would be adequate for what I need it for.

Downloads however are very slow. Small files do not seem to be impacted. Using the test a thinkbroadband.com/download, files up to 20 Mb will download at a reasonable 20-30 Mbps, but when I get to 50, it slows down to about 17 Mbps, and when I download AD Connect from Microsoft, which is about 80 Mb, I can see it start at about 30 Mbps, but eventually goes down to about 115 kbps and levels off. When I put an IP on the server I am using for testing that proxies through squid, I am able to download the file at several hundred mbps.  When I download the same file on the squid server - I can't tell exactly what throughput I was getting, but the 80 Mb file downloaded within 5 seconds.

In both squid servers, other than when the servers were booting, processor activity has not exceeded 9% in the last 7 days but usually sits below 2%. Memory usage has not exceeded 2 Gb, leaving 2 Gb free.

I am using OpenDNS for a DNS source, and have tried changing DNS to level3 but it made no performance difference.

I think that this may be squid trying to cache something, but had tried to turn all caching off.

My cache.log doesn't really have anything interesting in it that I can see. It's the same ~30 or so log entries each time the service starts, and that is about it. Here it is:

2018/03/22 09:47:27 kid1| Set Current Directory to /var/cache/squid
2018/03/22 09:47:27 kid1| Starting Squid Cache version 3.5.27 for x86_64-unknown-cygwin...
2018/03/22 09:47:27 kid1| Service Name: squid
2018/03/22 09:47:27 kid1| Process ID 1164
2018/03/22 09:47:27 kid1| Process Roles: worker
2018/03/22 09:47:27 kid1| With 3200 file descriptors available
2018/03/22 09:47:27 kid1| Initializing IP Cache...
2018/03/22 09:47:27 kid1| parseEtcHosts: /etc/hosts: (2) No such file or directory
2018/03/22 09:47:27 kid1| DNS Socket created at [::], FD 5
2018/03/22 09:47:27 kid1| DNS Socket created at 0.0.0.0, FD 6
2018/03/22 09:47:27 kid1| Adding nameserver 208.67.222.222 from squid.conf
2018/03/22 09:47:27 kid1| Adding nameserver 208.67.220.220 from squid.conf
2018/03/22 09:47:27 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2018/03/22 09:47:27 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2018/03/22 09:47:27 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2018/03/22 09:47:27 kid1| Store logging disabled
2018/03/22 09:47:27 kid1| Swap maxSize 0 + 262144 KB, estimated 20164 objects
2018/03/22 09:47:27 kid1| Target number of buckets: 1008
2018/03/22 09:47:27 kid1| Using 8192 Store buckets
2018/03/22 09:47:27 kid1| Max Mem  size: 262144 KB
2018/03/22 09:47:27 kid1| Max Swap size: 0 KB
2018/03/22 09:47:27 kid1| Using Least Load store dir selection
2018/03/22 09:47:27 kid1| Set Current Directory to /var/cache/squid
2018/03/22 09:47:27 kid1| Finished loading MIME types and icons.
2018/03/22 09:47:27 kid1| HTCP Disabled.
2018/03/22 09:47:27 kid1| Squid plugin modules loaded: 0
2018/03/22 09:47:27 kid1| Adaptation support is off.
2018/03/22 09:47:27 kid1| Accepting HTTP Socket connections at local=[::]:3128 remote=[::] FD 10 flags=9
2018/03/22 09:47:28 kid1| storeLateRelease: released 0 objects


And this is my squid.conf:

#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed

#acl localnet src 10.0.0.0/8           # RFC1918 possible internal network
#acl localnet src 172.16.0.0/12    # RFC1918 possible internal network
#acl localnet src 192.168.0.0/16  # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
acl WSUS src 192.168.225.4/32
acl BACKUP src 192.168.225.11/32
acl ADFS src 192.168.224.7/32
acl ADFS src 192.168.228.8/32
acl DEVWEB src 192.168.226.6/32
acl UATWEB src 192.168.226.13/32
acl PRDWEB src 192.168.226.8/32
acl PRDWEB src 192.168.226.9/32



acl SSL_ports port 443
acl Safe_ports port 80                    # http
#acl Safe_ports port 21                  # ftp
acl Safe_ports port 443                  # https
#acl Safe_ports port 70                  # gopher
#acl Safe_ports port 210                                # wais
#acl Safe_ports port 1025-65535                # unregistered ports
#acl Safe_ports port 280                                # http-mgmt
#acl Safe_ports port 488                                # gss-http
#acl Safe_ports port 591                                # filemaker
#acl Safe_ports port 777                                # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#

# Only allow cachemgr access from localhost
#http_access allow localhost manager
#http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost
http_access allow WSUS
http_access allow ADFS
http_access allow BACKUP
http_access allow DEVWEB
http_access allow UATWEB
http_access allow PRDWEB

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 3128

# Uncomment the line below to enable disk caching - path format is /cygdrive/<full path to cache folder>, i.e.
#cache_dir aufs /cygdrive/d/squid/cache 3000 16 256
cache deny all


# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:                     1440       20%        10080
refresh_pattern ^gopher:            1440       0%          1440
refresh_pattern -i (/cgi-bin/|\?) 0             0%          0
refresh_pattern .                             0              20%        4320

dns_nameservers 208.67.222.222 208.67.220.220

max_filedescriptors 3200



Does anyone see anything I am missing here?


My access.log doesn't really have anything interesting in it either, it just looks like it is working normally. I can attach that too if anyone wants to look at it after I redact some of the hosts.


Keith Hartley
Network Engineer II
MCSE: Productivity, MCSA: Server 2008, 2012, Office 365 |
Certified Meraki Network Associate, Security+
Geocent, LLC
o: 504-405-3578
a: 2219 Lakeshore drive Ste 300, New Orleans, LA 70122
w: www.geocent.com<http://www.geocent.com/>| e: khartley at geocent.com<mailto:khartley at geocent.com>




Confidentiality Notice:
This email communication may contain confidential information, may be legally privileged, and is intended only for the use of the intended recipients(s) identified. Any unauthorized review, use, distribution, downloading, or copying of this communication is strictly prohibited. If you are not the intended recipient and have received this message in error, immediately notify the sender by reply email, delete the communication, and destroy all copies. Thank you.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180322/8d460298/attachment.htm>

From yvoinov at gmail.com  Thu Mar 22 22:38:53 2018
From: yvoinov at gmail.com (Yuri)
Date: Fri, 23 Mar 2018 04:38:53 +0600
Subject: [squid-users] Squid for windows Very slow downloads of large
 files through squid with normal uploads
In-Reply-To: <BLUPR06MB1747D5BF0659E34BFE3FE7E6EEA90@BLUPR06MB1747.namprd06.prod.outlook.com>
References: <BLUPR06MB1747D5BF0659E34BFE3FE7E6EEA90@BLUPR06MB1747.namprd06.prod.outlook.com>
Message-ID: <f0bcf355-7068-0065-dd72-92b7eb937070@gmail.com>



22.03.2018 23:10, Keith Hartley ?????:
>
> I am using squid 3.5 for windows as a transparent proxy to provide
> internet access to 7 servers in a secure environment that otherwise
> does not have internet access. I have two squids running behind a load
> balancer, each one is running server 2016 core with 2 Xeon processors
> that is either haswell generation with 1:1 physical processor to
> virtual processor mapping or a hyper-threading Broadwell generation
> processor that is 1:1 logical processor to virtual processor mapping,
> depending on how they are provisioned when they get started.
>
> ?
>
> Doing a bandwidth test directly in the VM I am able to get internet
> throughput of 800-1200 Mbps.
>
> ?
>
> Doing a file copy to and from the VM I am able to get 1200 Mbps lan
> throughput.
>
> ?
>
> In proxied uploads I have observed speeds as high as 120 Mbps, which
> is more than enough for what I need and the bottleneck is likely in
> the backup software rather than squid. Uploads performance I am not
> worried about where they are at now ? even if I only got 20-30 Mbps it
> would be adequate for what I need it for.
>
> ?
>
> Downloads however are very slow. Small files do not seem to be
> impacted. Using the test a thinkbroadband.com/download, files up to 20
> Mb will download at a reasonable 20-30 Mbps, but when I get to 50, it
> slows down to about 17 Mbps, and when I download AD Connect from
> Microsoft, which is about 80 Mb, I can see it start at about 30 Mbps,
> but eventually goes down to about 115 kbps and levels off. When I put
> an IP on the server I am using for testing that proxies through squid,
> I am able to download the file at several hundred mbps. ?When I
> download the same file on the squid server ? I can?t tell exactly what
> throughput I was getting, but the 80 Mb file downloaded within 5 seconds.
>
> ?
>
> In both squid servers, other than when the servers were booting,
> processor activity has not exceeded 9% in the last 7 days but usually
> sits below 2%. Memory usage has not exceeded 2 Gb, leaving 2 Gb free.
>
> ?
>
> I am using OpenDNS for a DNS source, and have tried changing DNS to
> level3 but it made no performance difference.
>
> ?
>
> I think that this may be squid trying to cache something, but had
> tried to turn all caching off.
>
> ?
>
> My cache.log doesn?t really have anything interesting in it that I can
> see. It?s the same ~30 or so log entries each time the service starts,
> and that is about it. Here it is:
>
> ?
>
> 2018/03/22 09:47:27 kid1| Set Current Directory to /var/cache/squid
>
> 2018/03/22 09:47:27 kid1| Starting Squid Cache version 3.5.27 for
> x86_64-unknown-cygwin...
>
> 2018/03/22 09:47:27 kid1| Service Name: squid
>
> 2018/03/22 09:47:27 kid1| Process ID 1164
>
> 2018/03/22 09:47:27 kid1| Process Roles: worker
>
> 2018/03/22 09:47:27 kid1| With 3200 file descriptors available
>
> 2018/03/22 09:47:27 kid1| Initializing IP Cache...
>
> 2018/03/22 09:47:27 kid1| parseEtcHosts: /etc/hosts: (2) No such file
> or directory
>
> 2018/03/22 09:47:27 kid1| DNS Socket created at [::], FD 5
>
> 2018/03/22 09:47:27 kid1| DNS Socket created at 0.0.0.0, FD 6
>
> 2018/03/22 09:47:27 kid1| Adding nameserver 208.67.222.222 from squid.conf
>
> 2018/03/22 09:47:27 kid1| Adding nameserver 208.67.220.220 from squid.conf
>
> 2018/03/22 09:47:27 kid1| Logfile: opening log
> daemon:/var/log/squid/access.log
>
> 2018/03/22 09:47:27 kid1| Logfile Daemon: opening log
> /var/log/squid/access.log
>
> 2018/03/22 09:47:27 kid1| WARNING: no_suid: setuid(0): (22) Invalid
> argument
>
> 2018/03/22 09:47:27 kid1| Store logging disabled
>
> 2018/03/22 09:47:27 kid1| Swap maxSize 0 + 262144 KB, estimated 20164
> objects
>
> 2018/03/22 09:47:27 kid1| Target number of buckets: 1008
>
> 2018/03/22 09:47:27 kid1| Using 8192 Store buckets
>
> 2018/03/22 09:47:27 kid1| Max Mem? size: 262144 KB
>
> 2018/03/22 09:47:27 kid1| Max Swap size: 0 KB
>
> 2018/03/22 09:47:27 kid1| Using Least Load store dir selection
>
> 2018/03/22 09:47:27 kid1| Set Current Directory to /var/cache/squid
>
> 2018/03/22 09:47:27 kid1| Finished loading MIME types and icons.
>
> 2018/03/22 09:47:27 kid1| HTCP Disabled.
>
> 2018/03/22 09:47:27 kid1| Squid plugin modules loaded: 0
>
> 2018/03/22 09:47:27 kid1| Adaptation support is off.
>
> 2018/03/22 09:47:27 kid1| Accepting HTTP Socket connections at
> local=[::]:3128 remote=[::] FD 10 flags=9
>
> 2018/03/22 09:47:28 kid1| storeLateRelease: released 0 objects
>
> ?
>
> ?
>
> And this is my squid.conf:
>
> ?
>
> #
>
> # Recommended minimum configuration:
>
> #
>
> ?
>
> # Example rule allowing access from your local networks.
>
> # Adapt to list your (internal) IP networks from where browsing
>
> # should be allowed
>
> ?
>
> #acl localnet src 10.0.0.0/8?????????? # RFC1918 possible internal network
>
> #acl localnet src 172.16.0.0/12??? # RFC1918 possible internal network
>
> #acl localnet src 192.168.0.0/16? # RFC1918 possible internal network
>
> acl localnet src fc00::/7?????? # RFC 4193 local private network range
>
> acl localnet src fe80::/10????? # RFC 4291 link-local (directly
> plugged) machines
>
> acl WSUS src 192.168.225.4/32
>
> acl BACKUP src 192.168.225.11/32
>
> acl ADFS src 192.168.224.7/32
>
> acl ADFS src 192.168.228.8/32
>
> acl DEVWEB src 192.168.226.6/32
>
> acl UATWEB src 192.168.226.13/32
>
> acl PRDWEB src 192.168.226.8/32
>
> acl PRDWEB src 192.168.226.9/32
>
> ?
>
> ?
>
> ?
>
> acl SSL_ports port 443
>
> acl Safe_ports port 80??????????????????? # http
>
> #acl Safe_ports port 21????????????????? # ftp
>
> acl Safe_ports port 443????????????????? # https
>
> #acl Safe_ports port 70????????????????? # gopher
>
> #acl Safe_ports port 210??????????????????????????????? # wais
>
> #acl Safe_ports port 1025-65535??????????????? # unregistered ports
>
> #acl Safe_ports port 280??????????????????????????????? # http-mgmt
>
> #acl Safe_ports port 488??????????????????????????????? # gss-http
>
> #acl Safe_ports port 591??????????????????????????????? # filemaker
>
> #acl Safe_ports port 777??????????????????????????????? # multiling http
>
> acl CONNECT method CONNECT
>
> ?
>
> #
>
> # Recommended minimum Access Permission configuration:
>
> #
>
> ?
>
> # Only allow cachemgr access from localhost
>
> #http_access allow localhost manager
>
> #http_access deny manager
>
> ?
>
> # Deny requests to certain unsafe ports
>
> http_access deny !Safe_ports
>
> ?
>
> # Deny CONNECT to other than secure SSL ports
>
> http_access deny CONNECT !SSL_ports
>
> ?
>
> # We strongly recommend the following be uncommented to protect innocent
>
> # web applications running on the proxy server who think the only
>
> # one who can access services on "localhost" is a local user
>
> #http_access deny to_localhost
>
> ?
>
> #
>
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
>
> #
>
> ?
>
> # Example rule allowing access from your local networks.
>
> # Adapt localnet in the ACL section to list your (internal) IP networks
>
> # from where browsing should be allowed
>
> http_access allow localnet
>
> http_access allow localhost
>
> http_access allow WSUS
>
> http_access allow ADFS
>
> http_access allow BACKUP
>
> http_access allow DEVWEB
>
> http_access allow UATWEB
>
> http_access allow PRDWEB
>
> ?
>
> # And finally deny all other access to this proxy
>
> http_access deny all
>
> ?
>
> # Squid normally listens to port 3128
>
> http_port 3128
>
> ?
>
> # Uncomment the line below to enable disk caching - path format is
> /cygdrive/<full path to cache folder>, i.e.
>
> #cache_dir aufs /cygdrive/d/squid/cache 3000 16 256
>
> cache deny all
>
> ?
>
> ?
>
> # Leave coredumps in the first cache dir
>
> coredump_dir /var/cache/squid
>
> ?
>
> # Add any of your own refresh_pattern entries above these.
>
> refresh_pattern ^ftp:???????????????????? 1440?????? 20%??????? 10080
>
> refresh_pattern ^gopher:??????????? 1440?????? 0%????????? 1440
>
> refresh_pattern -i (/cgi-bin/|\?) 0???????????? 0%????????? 0
>
> refresh_pattern .???????????????????????????? 0?????????????
> 20%??????? 4320
>
> ?
>
> dns_nameservers 208.67.222.222 208.67.220.220
>
> ?
>
> max_filedescriptors 3200
>
> ?
>
> ?
>
> ?
>
> Does anyone see anything I am missing here?
>
Yes. In your almost default configuration (it is complete squid.conf?)
obvious thing is:

a) You do not use on-disk cache.
b) You use memory cache by default - i.e. 256 Mb.
c) You cache nothing due to deny all cache. So, it makes useless
cache_mem default.
d) Your configuration technically useless. I see neither proxying
parameters, nor caching. Your squid now only additional hop for files.
No more.

So, squid nothing to do here. It simple should retransmit GET (GET?)
request to server, and, without any caching/storing, retransmit it to user.

Still correct?

This put us directly to raw network IO. Without any buffering (which can
be - but don't - your squid).

On your place, I can start playing around with cache_mem parameter; of
course, only after removing cache deny all.

And after some experiments, may be, will make decision about drop out
useless Squid's box.

Seriously, what role of squid's here? Just setup border firewall to your
servers to access it to Internet. It will be enough.

> ?
>
> ?
>
> My access.log doesn?t really have anything interesting in it either,
> it just looks like it is working normally. I can attach that too if
> anyone wants to look at it after I redact some of the hosts.
>
> ?
>
> ?
>
> *Keith Hartley*
>
> /Network Engineer II/
>
> /MCSE: Productivity, MCSA: Server 2008, 2012, Office 365 / |
>
> /Certified Meraki Network Associate, Security+/
>
> *Geocent, LLC*
>
> *o:*504-405-3578
>
> *a:*2219 Lakeshore drive Ste 300, New Orleans, LA 70122
>
> *w:*www.geocent.com <http://www.geocent.com/>|*e:*khartley at geocent.com
> <mailto:khartley at geocent.com>
>
> ?
>
> ? ?
>
> ?
>
>
> Confidentiality Notice:
> This email communication may contain confidential information, may be
> legally privileged, and is intended only for the use of the intended
> recipients(s) identified. Any unauthorized review, use, distribution,
> downloading, or copying of this communication is strictly prohibited.
> If you are not the intended recipient and have received this message
> in error, immediately notify the sender by reply email, delete the
> communication, and destroy all copies. Thank you.
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180323/9c7a63ca/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180323/9c7a63ca/attachment.sig>

From yvoinov at gmail.com  Thu Mar 22 22:47:13 2018
From: yvoinov at gmail.com (Yuri)
Date: Fri, 23 Mar 2018 04:47:13 +0600
Subject: [squid-users] Squid for windows Very slow downloads of large
 files through squid with normal uploads
In-Reply-To: <f0bcf355-7068-0065-dd72-92b7eb937070@gmail.com>
References: <BLUPR06MB1747D5BF0659E34BFE3FE7E6EEA90@BLUPR06MB1747.namprd06.prod.outlook.com>
 <f0bcf355-7068-0065-dd72-92b7eb937070@gmail.com>
Message-ID: <e0f6f7e7-e438-5b1c-55c9-a9fb72903f75@gmail.com>

And also:

your configuration is not transparent proxy.

a) Squid 3.5 for windows does not built as transparent proxy (i.e. with
NAT support).

b) You do not have keyword*intercept* in your configuration.

This is simple forwarding proxy.


23.03.2018 04:38, Yuri ?????:
>
>
>
> 22.03.2018 23:10, Keith Hartley ?????:
>>
>> I am using squid 3.5 for windows as a transparent proxy to provide
>> internet access to 7 servers in a secure environment that otherwise
>> does not have internet access. I have two squids running behind a
>> load balancer, each one is running server 2016 core with 2 Xeon
>> processors that is either haswell generation with 1:1 physical
>> processor to virtual processor mapping or a hyper-threading Broadwell
>> generation processor that is 1:1 logical processor to virtual
>> processor mapping, depending on how they are provisioned when they
>> get started.
>>
>> ?
>>
>> Doing a bandwidth test directly in the VM I am able to get internet
>> throughput of 800-1200 Mbps.
>>
>> ?
>>
>> Doing a file copy to and from the VM I am able to get 1200 Mbps lan
>> throughput.
>>
>> ?
>>
>> In proxied uploads I have observed speeds as high as 120 Mbps, which
>> is more than enough for what I need and the bottleneck is likely in
>> the backup software rather than squid. Uploads performance I am not
>> worried about where they are at now ? even if I only got 20-30 Mbps
>> it would be adequate for what I need it for.
>>
>> ?
>>
>> Downloads however are very slow. Small files do not seem to be
>> impacted. Using the test a thinkbroadband.com/download, files up to
>> 20 Mb will download at a reasonable 20-30 Mbps, but when I get to 50,
>> it slows down to about 17 Mbps, and when I download AD Connect from
>> Microsoft, which is about 80 Mb, I can see it start at about 30 Mbps,
>> but eventually goes down to about 115 kbps and levels off. When I put
>> an IP on the server I am using for testing that proxies through
>> squid, I am able to download the file at several hundred mbps. ?When
>> I download the same file on the squid server ? I can?t tell exactly
>> what throughput I was getting, but the 80 Mb file downloaded within 5
>> seconds.
>>
>> ?
>>
>> In both squid servers, other than when the servers were booting,
>> processor activity has not exceeded 9% in the last 7 days but usually
>> sits below 2%. Memory usage has not exceeded 2 Gb, leaving 2 Gb free.
>>
>> ?
>>
>> I am using OpenDNS for a DNS source, and have tried changing DNS to
>> level3 but it made no performance difference.
>>
>> ?
>>
>> I think that this may be squid trying to cache something, but had
>> tried to turn all caching off.
>>
>> ?
>>
>> My cache.log doesn?t really have anything interesting in it that I
>> can see. It?s the same ~30 or so log entries each time the service
>> starts, and that is about it. Here it is:
>>
>> ?
>>
>> 2018/03/22 09:47:27 kid1| Set Current Directory to /var/cache/squid
>>
>> 2018/03/22 09:47:27 kid1| Starting Squid Cache version 3.5.27 for
>> x86_64-unknown-cygwin...
>>
>> 2018/03/22 09:47:27 kid1| Service Name: squid
>>
>> 2018/03/22 09:47:27 kid1| Process ID 1164
>>
>> 2018/03/22 09:47:27 kid1| Process Roles: worker
>>
>> 2018/03/22 09:47:27 kid1| With 3200 file descriptors available
>>
>> 2018/03/22 09:47:27 kid1| Initializing IP Cache...
>>
>> 2018/03/22 09:47:27 kid1| parseEtcHosts: /etc/hosts: (2) No such file
>> or directory
>>
>> 2018/03/22 09:47:27 kid1| DNS Socket created at [::], FD 5
>>
>> 2018/03/22 09:47:27 kid1| DNS Socket created at 0.0.0.0, FD 6
>>
>> 2018/03/22 09:47:27 kid1| Adding nameserver 208.67.222.222 from
>> squid.conf
>>
>> 2018/03/22 09:47:27 kid1| Adding nameserver 208.67.220.220 from
>> squid.conf
>>
>> 2018/03/22 09:47:27 kid1| Logfile: opening log
>> daemon:/var/log/squid/access.log
>>
>> 2018/03/22 09:47:27 kid1| Logfile Daemon: opening log
>> /var/log/squid/access.log
>>
>> 2018/03/22 09:47:27 kid1| WARNING: no_suid: setuid(0): (22) Invalid
>> argument
>>
>> 2018/03/22 09:47:27 kid1| Store logging disabled
>>
>> 2018/03/22 09:47:27 kid1| Swap maxSize 0 + 262144 KB, estimated 20164
>> objects
>>
>> 2018/03/22 09:47:27 kid1| Target number of buckets: 1008
>>
>> 2018/03/22 09:47:27 kid1| Using 8192 Store buckets
>>
>> 2018/03/22 09:47:27 kid1| Max Mem? size: 262144 KB
>>
>> 2018/03/22 09:47:27 kid1| Max Swap size: 0 KB
>>
>> 2018/03/22 09:47:27 kid1| Using Least Load store dir selection
>>
>> 2018/03/22 09:47:27 kid1| Set Current Directory to /var/cache/squid
>>
>> 2018/03/22 09:47:27 kid1| Finished loading MIME types and icons.
>>
>> 2018/03/22 09:47:27 kid1| HTCP Disabled.
>>
>> 2018/03/22 09:47:27 kid1| Squid plugin modules loaded: 0
>>
>> 2018/03/22 09:47:27 kid1| Adaptation support is off.
>>
>> 2018/03/22 09:47:27 kid1| Accepting HTTP Socket connections at
>> local=[::]:3128 remote=[::] FD 10 flags=9
>>
>> 2018/03/22 09:47:28 kid1| storeLateRelease: released 0 objects
>>
>> ?
>>
>> ?
>>
>> And this is my squid.conf:
>>
>> ?
>>
>> #
>>
>> # Recommended minimum configuration:
>>
>> #
>>
>> ?
>>
>> # Example rule allowing access from your local networks.
>>
>> # Adapt to list your (internal) IP networks from where browsing
>>
>> # should be allowed
>>
>> ?
>>
>> #acl localnet src 10.0.0.0/8?????????? # RFC1918 possible internal
>> network
>>
>> #acl localnet src 172.16.0.0/12??? # RFC1918 possible internal network
>>
>> #acl localnet src 192.168.0.0/16? # RFC1918 possible internal network
>>
>> acl localnet src fc00::/7?????? # RFC 4193 local private network range
>>
>> acl localnet src fe80::/10????? # RFC 4291 link-local (directly
>> plugged) machines
>>
>> acl WSUS src 192.168.225.4/32
>>
>> acl BACKUP src 192.168.225.11/32
>>
>> acl ADFS src 192.168.224.7/32
>>
>> acl ADFS src 192.168.228.8/32
>>
>> acl DEVWEB src 192.168.226.6/32
>>
>> acl UATWEB src 192.168.226.13/32
>>
>> acl PRDWEB src 192.168.226.8/32
>>
>> acl PRDWEB src 192.168.226.9/32
>>
>> ?
>>
>> ?
>>
>> ?
>>
>> acl SSL_ports port 443
>>
>> acl Safe_ports port 80??????????????????? # http
>>
>> #acl Safe_ports port 21????????????????? # ftp
>>
>> acl Safe_ports port 443????????????????? # https
>>
>> #acl Safe_ports port 70????????????????? # gopher
>>
>> #acl Safe_ports port 210??????????????????????????????? # wais
>>
>> #acl Safe_ports port 1025-65535??????????????? # unregistered ports
>>
>> #acl Safe_ports port 280??????????????????????????????? # http-mgmt
>>
>> #acl Safe_ports port 488??????????????????????????????? # gss-http
>>
>> #acl Safe_ports port 591??????????????????????????????? # filemaker
>>
>> #acl Safe_ports port 777??????????????????????????????? # multiling http
>>
>> acl CONNECT method CONNECT
>>
>> ?
>>
>> #
>>
>> # Recommended minimum Access Permission configuration:
>>
>> #
>>
>> ?
>>
>> # Only allow cachemgr access from localhost
>>
>> #http_access allow localhost manager
>>
>> #http_access deny manager
>>
>> ?
>>
>> # Deny requests to certain unsafe ports
>>
>> http_access deny !Safe_ports
>>
>> ?
>>
>> # Deny CONNECT to other than secure SSL ports
>>
>> http_access deny CONNECT !SSL_ports
>>
>> ?
>>
>> # We strongly recommend the following be uncommented to protect innocent
>>
>> # web applications running on the proxy server who think the only
>>
>> # one who can access services on "localhost" is a local user
>>
>> #http_access deny to_localhost
>>
>> ?
>>
>> #
>>
>> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
>>
>> #
>>
>> ?
>>
>> # Example rule allowing access from your local networks.
>>
>> # Adapt localnet in the ACL section to list your (internal) IP networks
>>
>> # from where browsing should be allowed
>>
>> http_access allow localnet
>>
>> http_access allow localhost
>>
>> http_access allow WSUS
>>
>> http_access allow ADFS
>>
>> http_access allow BACKUP
>>
>> http_access allow DEVWEB
>>
>> http_access allow UATWEB
>>
>> http_access allow PRDWEB
>>
>> ?
>>
>> # And finally deny all other access to this proxy
>>
>> http_access deny all
>>
>> ?
>>
>> # Squid normally listens to port 3128
>>
>> http_port 3128
>>
>> ?
>>
>> # Uncomment the line below to enable disk caching - path format is
>> /cygdrive/<full path to cache folder>, i.e.
>>
>> #cache_dir aufs /cygdrive/d/squid/cache 3000 16 256
>>
>> cache deny all
>>
>> ?
>>
>> ?
>>
>> # Leave coredumps in the first cache dir
>>
>> coredump_dir /var/cache/squid
>>
>> ?
>>
>> # Add any of your own refresh_pattern entries above these.
>>
>> refresh_pattern ^ftp:???????????????????? 1440?????? 20%??????? 10080
>>
>> refresh_pattern ^gopher:??????????? 1440?????? 0%????????? 1440
>>
>> refresh_pattern -i (/cgi-bin/|\?) 0???????????? 0%????????? 0
>>
>> refresh_pattern .???????????????????????????? 0?????????????
>> 20%??????? 4320
>>
>> ?
>>
>> dns_nameservers 208.67.222.222 208.67.220.220
>>
>> ?
>>
>> max_filedescriptors 3200
>>
>> ?
>>
>> ?
>>
>> ?
>>
>> Does anyone see anything I am missing here?
>>
> Yes. In your almost default configuration (it is complete squid.conf?)
> obvious thing is:
>
> a) You do not use on-disk cache.
> b) You use memory cache by default - i.e. 256 Mb.
> c) You cache nothing due to deny all cache. So, it makes useless
> cache_mem default.
> d) Your configuration technically useless. I see neither proxying
> parameters, nor caching. Your squid now only additional hop for files.
> No more.
>
> So, squid nothing to do here. It simple should retransmit GET (GET?)
> request to server, and, without any caching/storing, retransmit it to
> user.
>
> Still correct?
>
> This put us directly to raw network IO. Without any buffering (which
> can be - but don't - your squid).
>
> On your place, I can start playing around with cache_mem parameter; of
> course, only after removing cache deny all.
>
> And after some experiments, may be, will make decision about drop out
> useless Squid's box.
>
> Seriously, what role of squid's here? Just setup border firewall to
> your servers to access it to Internet. It will be enough.
>
>> ?
>>
>> ?
>>
>> My access.log doesn?t really have anything interesting in it either,
>> it just looks like it is working normally. I can attach that too if
>> anyone wants to look at it after I redact some of the hosts.
>>
>> ?
>>
>> ?
>>
>> *Keith Hartley*
>>
>> /Network Engineer II/
>>
>> /MCSE: Productivity, MCSA: Server 2008, 2012, Office 365 / |
>>
>> /Certified Meraki Network Associate, Security+/
>>
>> *Geocent, LLC*
>>
>> *o:*504-405-3578
>>
>> *a:*2219 Lakeshore drive Ste 300, New Orleans, LA 70122
>>
>> *w:*www.geocent.com
>> <http://www.geocent.com/>|*e:*khartley at geocent.com
>> <mailto:khartley at geocent.com>
>>
>> ?
>>
>> ? ?
>>
>> ?
>>
>>
>> Confidentiality Notice:
>> This email communication may contain confidential information, may be
>> legally privileged, and is intended only for the use of the intended
>> recipients(s) identified. Any unauthorized review, use, distribution,
>> downloading, or copying of this communication is strictly prohibited.
>> If you are not the intended recipient and have received this message
>> in error, immediately notify the sender by reply email, delete the
>> communication, and destroy all copies. Thank you.
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> -- 
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180323/c297146b/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180323/c297146b/attachment.sig>

From Keith.Hartley at geocent.com  Thu Mar 22 23:08:37 2018
From: Keith.Hartley at geocent.com (Keith Hartley)
Date: Thu, 22 Mar 2018 23:08:37 +0000
Subject: [squid-users] Squid for windows Very slow downloads of large
 files through squid with normal uploads
In-Reply-To: <f0bcf355-7068-0065-dd72-92b7eb937070@gmail.com>
References: <BLUPR06MB1747D5BF0659E34BFE3FE7E6EEA90@BLUPR06MB1747.namprd06.prod.outlook.com>
 <f0bcf355-7068-0065-dd72-92b7eb937070@gmail.com>
Message-ID: <SN1PR06MB175846A00C2B8602EB816BADEEA90@SN1PR06MB1758.namprd06.prod.outlook.com>

I don?t need it to cache anything ? the goal of it is not performance optimization, it is to provide restricted access to the internet. I have 1200 Mbps of network i/o available to the squid servers and can confirm I am able to reliably achieve at least 800 Mbps when I download something directly on the squid server. Additionally, it would be extremely rare that the same file ever would get downloaded more than once, if it ever actually happens.

By policy none of the servers may have direct internet access. This is to protect the data contained in the environment. Only one 4 bit subnet has internet access, where the squids are located, and 8 of the 45 servers need restricted internet access.

This config is complete at least in a base configuration. If I have time in the project I am going to add URI restrictions. The 8 servers will only need to get to about 30-40 static URIs in total and want to block the others, but first I need to get the throughput up.

I have 800 Mbps minimum available bandwidth to the squid servers that I can confirm is available in download tests from the squids. I have 1200 Mbps (these are Azure virtual machines) of bandwidth available in both directions between the servers that use the squids and the squids.

However on large files I am only getting 115 Kbps sustained download speeds.

Now if squid needs to be able to buffer the downloads to cache in order to perform well ? I could enable caching if that is the case, but would prefer to not cache anything. I very seriously doubt that I will ever download the same file two times in this environment as the only thing being downloaded is software updates that are centrally distributed from WSUS, and antivirus definitions that are released about 6-10 times per day. Most of the traffic is also https, with very little http.

Is it the case that I may see better performance if I configure it to cache the files first before sending it to clients?

Keith Hartley
Network Engineer II
khartley at geocent.com<mailto:khartley at geocent.com>
www.geocent.com<http://www.geocent.com>

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri
Sent: Thursday, March 22, 2018 5:39 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for windows Very slow downloads of large files through squid with normal uploads




22.03.2018 23:10, Keith Hartley ?????:
I am using squid 3.5 for windows as a transparent proxy to provide internet access to 7 servers in a secure environment that otherwise does not have internet access. I have two squids running behind a load balancer, each one is running server 2016 core with 2 Xeon processors that is either haswell generation with 1:1 physical processor to virtual processor mapping or a hyper-threading Broadwell generation processor that is 1:1 logical processor to virtual processor mapping, depending on how they are provisioned when they get started.

Doing a bandwidth test directly in the VM I am able to get internet throughput of 800-1200 Mbps.

Doing a file copy to and from the VM I am able to get 1200 Mbps lan throughput.

In proxied uploads I have observed speeds as high as 120 Mbps, which is more than enough for what I need and the bottleneck is likely in the backup software rather than squid. Uploads performance I am not worried about where they are at now ? even if I only got 20-30 Mbps it would be adequate for what I need it for.

Downloads however are very slow. Small files do not seem to be impacted. Using the test a thinkbroadband.com/download, files up to 20 Mb will download at a reasonable 20-30 Mbps, but when I get to 50, it slows down to about 17 Mbps, and when I download AD Connect from Microsoft, which is about 80 Mb, I can see it start at about 30 Mbps, but eventually goes down to about 115 kbps and levels off. When I put an IP on the server I am using for testing that proxies through squid, I am able to download the file at several hundred mbps.  When I download the same file on the squid server ? I can?t tell exactly what throughput I was getting, but the 80 Mb file downloaded within 5 seconds.

In both squid servers, other than when the servers were booting, processor activity has not exceeded 9% in the last 7 days but usually sits below 2%. Memory usage has not exceeded 2 Gb, leaving 2 Gb free.

I am using OpenDNS for a DNS source, and have tried changing DNS to level3 but it made no performance difference.

I think that this may be squid trying to cache something, but had tried to turn all caching off.

My cache.log doesn?t really have anything interesting in it that I can see. It?s the same ~30 or so log entries each time the service starts, and that is about it. Here it is:

2018/03/22 09:47:27 kid1| Set Current Directory to /var/cache/squid
2018/03/22 09:47:27 kid1| Starting Squid Cache version 3.5.27 for x86_64-unknown-cygwin...
2018/03/22 09:47:27 kid1| Service Name: squid
2018/03/22 09:47:27 kid1| Process ID 1164
2018/03/22 09:47:27 kid1| Process Roles: worker
2018/03/22 09:47:27 kid1| With 3200 file descriptors available
2018/03/22 09:47:27 kid1| Initializing IP Cache...
2018/03/22 09:47:27 kid1| parseEtcHosts: /etc/hosts: (2) No such file or directory
2018/03/22 09:47:27 kid1| DNS Socket created at [::], FD 5
2018/03/22 09:47:27 kid1| DNS Socket created at 0.0.0.0, FD 6
2018/03/22 09:47:27 kid1| Adding nameserver 208.67.222.222 from squid.conf
2018/03/22 09:47:27 kid1| Adding nameserver 208.67.220.220 from squid.conf
2018/03/22 09:47:27 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2018/03/22 09:47:27 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2018/03/22 09:47:27 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2018/03/22 09:47:27 kid1| Store logging disabled
2018/03/22 09:47:27 kid1| Swap maxSize 0 + 262144 KB, estimated 20164 objects
2018/03/22 09:47:27 kid1| Target number of buckets: 1008
2018/03/22 09:47:27 kid1| Using 8192 Store buckets
2018/03/22 09:47:27 kid1| Max Mem  size: 262144 KB
2018/03/22 09:47:27 kid1| Max Swap size: 0 KB
2018/03/22 09:47:27 kid1| Using Least Load store dir selection
2018/03/22 09:47:27 kid1| Set Current Directory to /var/cache/squid
2018/03/22 09:47:27 kid1| Finished loading MIME types and icons.
2018/03/22 09:47:27 kid1| HTCP Disabled.
2018/03/22 09:47:27 kid1| Squid plugin modules loaded: 0
2018/03/22 09:47:27 kid1| Adaptation support is off.
2018/03/22 09:47:27 kid1| Accepting HTTP Socket connections at local=[::]:3128 remote=[::] FD 10 flags=9
2018/03/22 09:47:28 kid1| storeLateRelease: released 0 objects


And this is my squid.conf:

#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed

#acl localnet src 10.0.0.0/8           # RFC1918 possible internal network
#acl localnet src 172.16.0.0/12    # RFC1918 possible internal network
#acl localnet src 192.168.0.0/16  # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
acl WSUS src 192.168.225.4/32
acl BACKUP src 192.168.225.11/32
acl ADFS src 192.168.224.7/32
acl ADFS src 192.168.228.8/32
acl DEVWEB src 192.168.226.6/32
acl UATWEB src 192.168.226.13/32
acl PRDWEB src 192.168.226.8/32
acl PRDWEB src 192.168.226.9/32



acl SSL_ports port 443
acl Safe_ports port 80                    # http
#acl Safe_ports port 21                  # ftp
acl Safe_ports port 443                  # https
#acl Safe_ports port 70                  # gopher
#acl Safe_ports port 210                                # wais
#acl Safe_ports port 1025-65535                # unregistered ports
#acl Safe_ports port 280                                # http-mgmt
#acl Safe_ports port 488                                # gss-http
#acl Safe_ports port 591                                # filemaker
#acl Safe_ports port 777                                # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#

# Only allow cachemgr access from localhost
#http_access allow localhost manager
#http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost
http_access allow WSUS
http_access allow ADFS
http_access allow BACKUP
http_access allow DEVWEB
http_access allow UATWEB
http_access allow PRDWEB

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 3128

# Uncomment the line below to enable disk caching - path format is /cygdrive/<full path to cache folder>, i.e.
#cache_dir aufs /cygdrive/d/squid/cache 3000 16 256
cache deny all


# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:                     1440       20%        10080
refresh_pattern ^gopher:            1440       0%          1440
refresh_pattern -i (/cgi-bin/|\?) 0             0%          0
refresh_pattern .                             0              20%        4320

dns_nameservers 208.67.222.222 208.67.220.220

max_filedescriptors 3200



Does anyone see anything I am missing here?
Yes. In your almost default configuration (it is complete squid.conf?) obvious thing is:

a) You do not use on-disk cache.
b) You use memory cache by default - i.e. 256 Mb.
c) You cache nothing due to deny all cache. So, it makes useless cache_mem default.
d) Your configuration technically useless. I see neither proxying parameters, nor caching. Your squid now only additional hop for files. No more.

So, squid nothing to do here. It simple should retransmit GET (GET?) request to server, and, without any caching/storing, retransmit it to user.

Still correct?

This put us directly to raw network IO. Without any buffering (which can be - but don't - your squid).

On your place, I can start playing around with cache_mem parameter; of course, only after removing cache deny all.

And after some experiments, may be, will make decision about drop out useless Squid's box.

Seriously, what role of squid's here? Just setup border firewall to your servers to access it to Internet. It will be enough.




My access.log doesn?t really have anything interesting in it either, it just looks like it is working normally. I can attach that too if anyone wants to look at it after I redact some of the hosts.


Keith Hartley
Network Engineer II
MCSE: Productivity, MCSA: Server 2008, 2012, Office 365 |
Certified Meraki Network Associate, Security+
Geocent, LLC
o: 504-405-3578
a: 2219 Lakeshore drive Ste 300, New Orleans, LA 70122
w: www.geocent.com<http://www.geocent.com/>| e: khartley at geocent.com<mailto:khartley at geocent.com>




Confidentiality Notice:
This email communication may contain confidential information, may be legally privileged, and is intended only for the use of the intended recipients(s) identified. Any unauthorized review, use, distribution, downloading, or copying of this communication is strictly prohibited. If you are not the intended recipient and have received this message in error, immediately notify the sender by reply email, delete the communication, and destroy all copies. Thank you.




_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

http://lists.squid-cache.org/listinfo/squid-users



--

"C++ seems like a language suitable for firing other people's legs."



*****************************

* C++20 : Bug to the future *

*****************************
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180322/580dbd67/attachment.htm>

From yvoinov at gmail.com  Thu Mar 22 23:11:48 2018
From: yvoinov at gmail.com (Yuri)
Date: Fri, 23 Mar 2018 05:11:48 +0600
Subject: [squid-users] Squid for windows Very slow downloads of large
 files through squid with normal uploads
In-Reply-To: <SN1PR06MB175846A00C2B8602EB816BADEEA90@SN1PR06MB1758.namprd06.prod.outlook.com>
References: <BLUPR06MB1747D5BF0659E34BFE3FE7E6EEA90@BLUPR06MB1747.namprd06.prod.outlook.com>
 <f0bcf355-7068-0065-dd72-92b7eb937070@gmail.com>
 <SN1PR06MB175846A00C2B8602EB816BADEEA90@SN1PR06MB1758.namprd06.prod.outlook.com>
Message-ID: <07541384-9f4b-1d2b-3905-661cefa618ac@gmail.com>



23.03.2018 05:08, Keith Hartley ?????:
>
> I don?t need it to cache anything ? the goal of it is not performance
> optimization, it is to provide restricted access to the internet. I
> have 1200 Mbps of network i/o available to the squid servers and can
> confirm I am able to reliably achieve at least 800 Mbps when I
> download something directly on the squid server. Additionally, it
> would be extremely rare that the same file ever would get downloaded
> more than once, if it ever actually happens.
>
> ?
>
> By policy none of the servers may have direct internet access. This is
> to protect the data contained in the environment. Only one 4 bit
> subnet has internet access, where the squids are located, and 8 of the
> 45 servers need restricted internet access.
>
Now your protects nothing. You don't have any advanced ACLs in your config.
>
> ?
>
> This config is complete at least in a base configuration. If I have
> time in the project I am going to add URI restrictions. The 8 servers
> will only need to get to about 30-40 static URIs in total and want to
> block the others, but first I need to get the throughput up.
>
> ?
>
> I have 800 Mbps minimum available bandwidth to the squid servers that
> I can confirm is available in download tests from the squids. I have
> 1200 Mbps (these are Azure virtual machines) of bandwidth available in
> both directions between the servers that use the squids and the squids.
>
> ?
>
> However on large files I am only getting 115 Kbps sustained download
> speeds.
>
> ?
>
> Now if squid needs to be able to buffer the downloads to cache in
> order to perform well ? I could enable caching if that is the case,
> but would prefer to not cache anything. I very seriously doubt that I
> will ever download the same file two times in this environment as the
> only thing being downloaded is software updates that are centrally
> distributed from WSUS, and antivirus definitions that are released
> about 6-10 times per day. Most of the traffic is also https, with very
> little http.
>
> ?
>
> Is it the case that I may see better performance if I configure it to
> cache the files first before sending it to clients?
>
Nothing above can not be solved by trivial border firewall.

Just imagine - now you have useless server which not buffers network IO.

Ideally just drop it. And setup border firewall. This solves all of your
problems.

Squid's (especially Windows Squid) is not appropriate tool here.
>
> *?*
>
> *Keith Hartley*
>
> /Network Engineer II/
>
> khartley at geocent.com <mailto:khartley at geocent.com>
>
> www.geocent.com <http://www.geocent.com>
>
> ?
>
> *From:*squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
> *On Behalf Of *Yuri
> *Sent:* Thursday, March 22, 2018 5:39 PM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Squid for windows Very slow downloads of
> large files through squid with normal uploads
>
> ?
>
> ?
>
> ?
>
> 22.03.2018 23:10, Keith Hartley ?????:
>
>     I am using squid 3.5 for windows as a transparent proxy to provide
>     internet access to 7 servers in a secure environment that
>     otherwise does not have internet access. I have two squids running
>     behind a load balancer, each one is running server 2016 core with
>     2 Xeon processors that is either haswell generation with 1:1
>     physical processor to virtual processor mapping or a
>     hyper-threading Broadwell generation processor that is 1:1 logical
>     processor to virtual processor mapping, depending on how they are
>     provisioned when they get started.
>
>     ?
>
>     Doing a bandwidth test directly in the VM I am able to get
>     internet throughput of 800-1200 Mbps.
>
>     ?
>
>     Doing a file copy to and from the VM I am able to get 1200 Mbps
>     lan throughput.
>
>     ?
>
>     In proxied uploads I have observed speeds as high as 120 Mbps,
>     which is more than enough for what I need and the bottleneck is
>     likely in the backup software rather than squid. Uploads
>     performance I am not worried about where they are at now ? even if
>     I only got 20-30 Mbps it would be adequate for what I need it for.
>
>     ?
>
>     Downloads however are very slow. Small files do not seem to be
>     impacted. Using the test a thinkbroadband.com/download, files up
>     to 20 Mb will download at a reasonable 20-30 Mbps, but when I get
>     to 50, it slows down to about 17 Mbps, and when I download AD
>     Connect from Microsoft, which is about 80 Mb, I can see it start
>     at about 30 Mbps, but eventually goes down to about 115 kbps and
>     levels off. When I put an IP on the server I am using for testing
>     that proxies through squid, I am able to download the file at
>     several hundred mbps. ?When I download the same file on the squid
>     server ? I can?t tell exactly what throughput I was getting, but
>     the 80 Mb file downloaded within 5 seconds.
>
>     ?
>
>     In both squid servers, other than when the servers were booting,
>     processor activity has not exceeded 9% in the last 7 days but
>     usually sits below 2%. Memory usage has not exceeded 2 Gb, leaving
>     2 Gb free.
>
>     ?
>
>     I am using OpenDNS for a DNS source, and have tried changing DNS
>     to level3 but it made no performance difference.
>
>     ?
>
>     I think that this may be squid trying to cache something, but had
>     tried to turn all caching off.
>
>     ?
>
>     My cache.log doesn?t really have anything interesting in it that I
>     can see. It?s the same ~30 or so log entries each time the service
>     starts, and that is about it. Here it is:
>
>     ?
>
>     2018/03/22 09:47:27 kid1| Set Current Directory to /var/cache/squid
>
>     2018/03/22 09:47:27 kid1| Starting Squid Cache version 3.5.27 for
>     x86_64-unknown-cygwin...
>
>     2018/03/22 09:47:27 kid1| Service Name: squid
>
>     2018/03/22 09:47:27 kid1| Process ID 1164
>
>     2018/03/22 09:47:27 kid1| Process Roles: worker
>
>     2018/03/22 09:47:27 kid1| With 3200 file descriptors available
>
>     2018/03/22 09:47:27 kid1| Initializing IP Cache...
>
>     2018/03/22 09:47:27 kid1| parseEtcHosts: /etc/hosts: (2) No such
>     file or directory
>
>     2018/03/22 09:47:27 kid1| DNS Socket created at [::], FD 5
>
>     2018/03/22 09:47:27 kid1| DNS Socket created at 0.0.0.0, FD 6
>
>     2018/03/22 09:47:27 kid1| Adding nameserver 208.67.222.222 from
>     squid.conf
>
>     2018/03/22 09:47:27 kid1| Adding nameserver 208.67.220.220 from
>     squid.conf
>
>     2018/03/22 09:47:27 kid1| Logfile: opening log
>     daemon:/var/log/squid/access.log
>
>     2018/03/22 09:47:27 kid1| Logfile Daemon: opening log
>     /var/log/squid/access.log
>
>     2018/03/22 09:47:27 kid1| WARNING: no_suid: setuid(0): (22)
>     Invalid argument
>
>     2018/03/22 09:47:27 kid1| Store logging disabled
>
>     2018/03/22 09:47:27 kid1| Swap maxSize 0 + 262144 KB, estimated
>     20164 objects
>
>     2018/03/22 09:47:27 kid1| Target number of buckets: 1008
>
>     2018/03/22 09:47:27 kid1| Using 8192 Store buckets
>
>     2018/03/22 09:47:27 kid1| Max Mem? size: 262144 KB
>
>     2018/03/22 09:47:27 kid1| Max Swap size: 0 KB
>
>     2018/03/22 09:47:27 kid1| Using Least Load store dir selection
>
>     2018/03/22 09:47:27 kid1| Set Current Directory to /var/cache/squid
>
>     2018/03/22 09:47:27 kid1| Finished loading MIME types and icons.
>
>     2018/03/22 09:47:27 kid1| HTCP Disabled.
>
>     2018/03/22 09:47:27 kid1| Squid plugin modules loaded: 0
>
>     2018/03/22 09:47:27 kid1| Adaptation support is off.
>
>     2018/03/22 09:47:27 kid1| Accepting HTTP Socket connections at
>     local=[::]:3128 remote=[::] FD 10 flags=9
>
>     2018/03/22 09:47:28 kid1| storeLateRelease: released 0 objects
>
>     ?
>
>     ?
>
>     And this is my squid.conf:
>
>     ?
>
>     #
>
>     # Recommended minimum configuration:
>
>     #
>
>     ?
>
>     # Example rule allowing access from your local networks.
>
>     # Adapt to list your (internal) IP networks from where browsing
>
>     # should be allowed
>
>     ?
>
>     #acl localnet src 10.0.0.0/8?????????? # RFC1918 possible internal
>     network
>
>     #acl localnet src 172.16.0.0/12??? # RFC1918 possible internal network
>
>     #acl localnet src 192.168.0.0/16? # RFC1918 possible internal network
>
>     acl localnet src fc00::/7?????? # RFC 4193 local private network range
>
>     acl localnet src fe80::/10????? # RFC 4291 link-local (directly
>     plugged) machines
>
>     acl WSUS src 192.168.225.4/32
>
>     acl BACKUP src 192.168.225.11/32
>
>     acl ADFS src 192.168.224.7/32
>
>     acl ADFS src 192.168.228.8/32
>
>     acl DEVWEB src 192.168.226.6/32
>
>     acl UATWEB src 192.168.226.13/32
>
>     acl PRDWEB src 192.168.226.8/32
>
>     acl PRDWEB src 192.168.226.9/32
>
>     ?
>
>     ?
>
>     ?
>
>     acl SSL_ports port 443
>
>     acl Safe_ports port 80??????????????????? # http
>
>     #acl Safe_ports port 21????????????????? # ftp
>
>     acl Safe_ports port 443????????????????? # https
>
>     #acl Safe_ports port 70????????????????? # gopher
>
>     #acl Safe_ports port 210??????????????????????????????? # wais
>
>     #acl Safe_ports port 1025-65535??????????????? # unregistered ports
>
>     #acl Safe_ports port 280??????????????????????????????? # http-mgmt
>
>     #acl Safe_ports port 488??????????????????????????????? # gss-http
>
>     #acl Safe_ports port 591??????????????????????????????? # filemaker
>
>     #acl Safe_ports port 777??????????????????????????????? #
>     multiling http
>
>     acl CONNECT method CONNECT
>
>     ?
>
>     #
>
>     # Recommended minimum Access Permission configuration:
>
>     #
>
>     ?
>
>     # Only allow cachemgr access from localhost
>
>     #http_access allow localhost manager
>
>     #http_access deny manager
>
>     ?
>
>     # Deny requests to certain unsafe ports
>
>     http_access deny !Safe_ports
>
>     ?
>
>     # Deny CONNECT to other than secure SSL ports
>
>     http_access deny CONNECT !SSL_ports
>
>     ?
>
>     # We strongly recommend the following be uncommented to protect
>     innocent
>
>     # web applications running on the proxy server who think the only
>
>     # one who can access services on "localhost" is a local user
>
>     #http_access deny to_localhost
>
>     ?
>
>     #
>
>     # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
>
>     #
>
>     ?
>
>     # Example rule allowing access from your local networks.
>
>     # Adapt localnet in the ACL section to list your (internal) IP
>     networks
>
>     # from where browsing should be allowed
>
>     http_access allow localnet
>
>     http_access allow localhost
>
>     http_access allow WSUS
>
>     http_access allow ADFS
>
>     http_access allow BACKUP
>
>     http_access allow DEVWEB
>
>     http_access allow UATWEB
>
>     http_access allow PRDWEB
>
>     ?
>
>     # And finally deny all other access to this proxy
>
>     http_access deny all
>
>     ?
>
>     # Squid normally listens to port 3128
>
>     http_port 3128
>
>     ?
>
>     # Uncomment the line below to enable disk caching - path format is
>     /cygdrive/<full path to cache folder>, i.e.
>
>     #cache_dir aufs /cygdrive/d/squid/cache 3000 16 256
>
>     cache deny all
>
>     ?
>
>     ?
>
>     # Leave coredumps in the first cache dir
>
>     coredump_dir /var/cache/squid
>
>     ?
>
>     # Add any of your own refresh_pattern entries above these.
>
>     refresh_pattern ^ftp:???????????????????? 1440?????? 20%??????? 10080
>
>     refresh_pattern ^gopher:??????????? 1440?????? 0%????????? 1440
>
>     refresh_pattern -i (/cgi-bin/|\?) 0???????????? 0%????????? 0
>
>     refresh_pattern .???????????????????????????? 0?????????????
>     20%??????? 4320
>
>     ?
>
>     dns_nameservers 208.67.222.222 208.67.220.220
>
>     ?
>
>     max_filedescriptors 3200
>
>     ?
>
>     ?
>
>     ?
>
>     Does anyone see anything I am missing here?
>
> Yes. In your almost default configuration (it is complete squid.conf?)
> obvious thing is:
>
> a) You do not use on-disk cache.
> b) You use memory cache by default - i.e. 256 Mb.
> c) You cache nothing due to deny all cache. So, it makes useless
> cache_mem default.
> d) Your configuration technically useless. I see neither proxying
> parameters, nor caching. Your squid now only additional hop for files.
> No more.
>
> So, squid nothing to do here. It simple should retransmit GET (GET?)
> request to server, and, without any caching/storing, retransmit it to
> user.
>
> Still correct?
>
> This put us directly to raw network IO. Without any buffering (which
> can be - but don't - your squid).
>
> On your place, I can start playing around with cache_mem parameter; of
> course, only after removing cache deny all.
>
> And after some experiments, may be, will make decision about drop out
> useless Squid's box.
>
> Seriously, what role of squid's here? Just setup border firewall to
> your servers to access it to Internet. It will be enough.
>
>
>     ?
>
>     ?
>
>     My access.log doesn?t really have anything interesting in it
>     either, it just looks like it is working normally. I can attach
>     that too if anyone wants to look at it after I redact some of the
>     hosts.
>
>     ?
>
>     ?
>
>     *Keith Hartley*
>
>     /Network Engineer II/
>
>     /MCSE: Productivity, MCSA: Server 2008, 2012, Office 365 / |
>
>     /Certified Meraki Network Associate, Security+/
>
>     *Geocent, LLC*
>
>     *o:*504-405-3578
>
>     *a:*2219 Lakeshore drive Ste 300, New Orleans, LA 70122
>
>     *w:*www.geocent.com
>     <http://www.geocent.com/>|*e:*khartley at geocent.com
>     <mailto:khartley at geocent.com>
>
>     ?
>
>     ? ?
>
>     ?
>
>     ?
>
>     */_Confidentiality Notice:_/*
>
>     This email communication may contain confidential information, may
>     be legally privileged, and is intended only for the use of the
>     intended recipients(s) identified. Any unauthorized review, use,
>     distribution, downloading, or copying of this communication is
>     strictly prohibited. If you are not the intended recipient and
>     have received this message in error, immediately notify the sender
>     by reply email, delete the communication, and destroy all copies.
>     Thank you.
>
>
>
>
>     _______________________________________________
>
>     squid-users mailing list
>
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> -- 
> "C++ seems like a language suitable for firing other people's legs."
> ?
> *****************************
> * C++20 : Bug to the future *
> *****************************

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180323/a2df557d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180323/a2df557d/attachment.sig>

From yvoinov at gmail.com  Thu Mar 22 23:27:13 2018
From: yvoinov at gmail.com (Yuri)
Date: Fri, 23 Mar 2018 05:27:13 +0600
Subject: [squid-users] Squid for windows Very slow downloads of large
 files through squid with normal uploads
In-Reply-To: <07541384-9f4b-1d2b-3905-661cefa618ac@gmail.com>
References: <BLUPR06MB1747D5BF0659E34BFE3FE7E6EEA90@BLUPR06MB1747.namprd06.prod.outlook.com>
 <f0bcf355-7068-0065-dd72-92b7eb937070@gmail.com>
 <SN1PR06MB175846A00C2B8602EB816BADEEA90@SN1PR06MB1758.namprd06.prod.outlook.com>
 <07541384-9f4b-1d2b-3905-661cefa618ac@gmail.com>
Message-ID: <634894e6-b954-3fed-bde0-58b84a88eb73@gmail.com>

Your task is simple - you need a simple control of access to the
Internet, for servers, without any caching. Squid here is excessive,
moreover, in your configuration it gives an excessive overhead.

You not requires advanced requests processing, SSL bumping, content
adaptation, AV real-time checking, advanced caching, content compression
- am I right yet?

So, firewall is enough.


23.03.2018 05:11, Yuri ?????:
>
>
>
> 23.03.2018 05:08, Keith Hartley ?????:
>>
>> I don?t need it to cache anything ? the goal of it is not performance
>> optimization, it is to provide restricted access to the internet. I
>> have 1200 Mbps of network i/o available to the squid servers and can
>> confirm I am able to reliably achieve at least 800 Mbps when I
>> download something directly on the squid server. Additionally, it
>> would be extremely rare that the same file ever would get downloaded
>> more than once, if it ever actually happens.
>>
>> ?
>>
>> By policy none of the servers may have direct internet access. This
>> is to protect the data contained in the environment. Only one 4 bit
>> subnet has internet access, where the squids are located, and 8 of
>> the 45 servers need restricted internet access.
>>
> Now your protects nothing. You don't have any advanced ACLs in your
> config.
>>
>> ?
>>
>> This config is complete at least in a base configuration. If I have
>> time in the project I am going to add URI restrictions. The 8 servers
>> will only need to get to about 30-40 static URIs in total and want to
>> block the others, but first I need to get the throughput up.
>>
>> ?
>>
>> I have 800 Mbps minimum available bandwidth to the squid servers that
>> I can confirm is available in download tests from the squids. I have
>> 1200 Mbps (these are Azure virtual machines) of bandwidth available
>> in both directions between the servers that use the squids and the
>> squids.
>>
>> ?
>>
>> However on large files I am only getting 115 Kbps sustained download
>> speeds.
>>
>> ?
>>
>> Now if squid needs to be able to buffer the downloads to cache in
>> order to perform well ? I could enable caching if that is the case,
>> but would prefer to not cache anything. I very seriously doubt that I
>> will ever download the same file two times in this environment as the
>> only thing being downloaded is software updates that are centrally
>> distributed from WSUS, and antivirus definitions that are released
>> about 6-10 times per day. Most of the traffic is also https, with
>> very little http.
>>
>> ?
>>
>> Is it the case that I may see better performance if I configure it to
>> cache the files first before sending it to clients?
>>
> Nothing above can not be solved by trivial border firewall.
>
> Just imagine - now you have useless server which not buffers network IO.
>
> Ideally just drop it. And setup border firewall. This solves all of
> your problems.
>
> Squid's (especially Windows Squid) is not appropriate tool here.
>>
>> *?*
>>
>> *Keith Hartley*
>>
>> /Network Engineer II/
>>
>> khartley at geocent.com <mailto:khartley at geocent.com>
>>
>> www.geocent.com <http://www.geocent.com>
>>
>> ?
>>
>> *From:*squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
>> *On Behalf Of *Yuri
>> *Sent:* Thursday, March 22, 2018 5:39 PM
>> *To:* squid-users at lists.squid-cache.org
>> *Subject:* Re: [squid-users] Squid for windows Very slow downloads of
>> large files through squid with normal uploads
>>
>> ?
>>
>> ?
>>
>> ?
>>
>> 22.03.2018 23:10, Keith Hartley ?????:
>>
>>     I am using squid 3.5 for windows as a transparent proxy to
>>     provide internet access to 7 servers in a secure environment that
>>     otherwise does not have internet access. I have two squids
>>     running behind a load balancer, each one is running server 2016
>>     core with 2 Xeon processors that is either haswell generation
>>     with 1:1 physical processor to virtual processor mapping or a
>>     hyper-threading Broadwell generation processor that is 1:1
>>     logical processor to virtual processor mapping, depending on how
>>     they are provisioned when they get started.
>>
>>     ?
>>
>>     Doing a bandwidth test directly in the VM I am able to get
>>     internet throughput of 800-1200 Mbps.
>>
>>     ?
>>
>>     Doing a file copy to and from the VM I am able to get 1200 Mbps
>>     lan throughput.
>>
>>     ?
>>
>>     In proxied uploads I have observed speeds as high as 120 Mbps,
>>     which is more than enough for what I need and the bottleneck is
>>     likely in the backup software rather than squid. Uploads
>>     performance I am not worried about where they are at now ? even
>>     if I only got 20-30 Mbps it would be adequate for what I need it for.
>>
>>     ?
>>
>>     Downloads however are very slow. Small files do not seem to be
>>     impacted. Using the test a thinkbroadband.com/download, files up
>>     to 20 Mb will download at a reasonable 20-30 Mbps, but when I get
>>     to 50, it slows down to about 17 Mbps, and when I download AD
>>     Connect from Microsoft, which is about 80 Mb, I can see it start
>>     at about 30 Mbps, but eventually goes down to about 115 kbps and
>>     levels off. When I put an IP on the server I am using for testing
>>     that proxies through squid, I am able to download the file at
>>     several hundred mbps. ?When I download the same file on the squid
>>     server ? I can?t tell exactly what throughput I was getting, but
>>     the 80 Mb file downloaded within 5 seconds.
>>
>>     ?
>>
>>     In both squid servers, other than when the servers were booting,
>>     processor activity has not exceeded 9% in the last 7 days but
>>     usually sits below 2%. Memory usage has not exceeded 2 Gb,
>>     leaving 2 Gb free.
>>
>>     ?
>>
>>     I am using OpenDNS for a DNS source, and have tried changing DNS
>>     to level3 but it made no performance difference.
>>
>>     ?
>>
>>     I think that this may be squid trying to cache something, but had
>>     tried to turn all caching off.
>>
>>     ?
>>
>>     My cache.log doesn?t really have anything interesting in it that
>>     I can see. It?s the same ~30 or so log entries each time the
>>     service starts, and that is about it. Here it is:
>>
>>     ?
>>
>>     2018/03/22 09:47:27 kid1| Set Current Directory to /var/cache/squid
>>
>>     2018/03/22 09:47:27 kid1| Starting Squid Cache version 3.5.27 for
>>     x86_64-unknown-cygwin...
>>
>>     2018/03/22 09:47:27 kid1| Service Name: squid
>>
>>     2018/03/22 09:47:27 kid1| Process ID 1164
>>
>>     2018/03/22 09:47:27 kid1| Process Roles: worker
>>
>>     2018/03/22 09:47:27 kid1| With 3200 file descriptors available
>>
>>     2018/03/22 09:47:27 kid1| Initializing IP Cache...
>>
>>     2018/03/22 09:47:27 kid1| parseEtcHosts: /etc/hosts: (2) No such
>>     file or directory
>>
>>     2018/03/22 09:47:27 kid1| DNS Socket created at [::], FD 5
>>
>>     2018/03/22 09:47:27 kid1| DNS Socket created at 0.0.0.0, FD 6
>>
>>     2018/03/22 09:47:27 kid1| Adding nameserver 208.67.222.222 from
>>     squid.conf
>>
>>     2018/03/22 09:47:27 kid1| Adding nameserver 208.67.220.220 from
>>     squid.conf
>>
>>     2018/03/22 09:47:27 kid1| Logfile: opening log
>>     daemon:/var/log/squid/access.log
>>
>>     2018/03/22 09:47:27 kid1| Logfile Daemon: opening log
>>     /var/log/squid/access.log
>>
>>     2018/03/22 09:47:27 kid1| WARNING: no_suid: setuid(0): (22)
>>     Invalid argument
>>
>>     2018/03/22 09:47:27 kid1| Store logging disabled
>>
>>     2018/03/22 09:47:27 kid1| Swap maxSize 0 + 262144 KB, estimated
>>     20164 objects
>>
>>     2018/03/22 09:47:27 kid1| Target number of buckets: 1008
>>
>>     2018/03/22 09:47:27 kid1| Using 8192 Store buckets
>>
>>     2018/03/22 09:47:27 kid1| Max Mem? size: 262144 KB
>>
>>     2018/03/22 09:47:27 kid1| Max Swap size: 0 KB
>>
>>     2018/03/22 09:47:27 kid1| Using Least Load store dir selection
>>
>>     2018/03/22 09:47:27 kid1| Set Current Directory to /var/cache/squid
>>
>>     2018/03/22 09:47:27 kid1| Finished loading MIME types and icons.
>>
>>     2018/03/22 09:47:27 kid1| HTCP Disabled.
>>
>>     2018/03/22 09:47:27 kid1| Squid plugin modules loaded: 0
>>
>>     2018/03/22 09:47:27 kid1| Adaptation support is off.
>>
>>     2018/03/22 09:47:27 kid1| Accepting HTTP Socket connections at
>>     local=[::]:3128 remote=[::] FD 10 flags=9
>>
>>     2018/03/22 09:47:28 kid1| storeLateRelease: released 0 objects
>>
>>     ?
>>
>>     ?
>>
>>     And this is my squid.conf:
>>
>>     ?
>>
>>     #
>>
>>     # Recommended minimum configuration:
>>
>>     #
>>
>>     ?
>>
>>     # Example rule allowing access from your local networks.
>>
>>     # Adapt to list your (internal) IP networks from where browsing
>>
>>     # should be allowed
>>
>>     ?
>>
>>     #acl localnet src 10.0.0.0/8?????????? # RFC1918 possible
>>     internal network
>>
>>     #acl localnet src 172.16.0.0/12??? # RFC1918 possible internal
>>     network
>>
>>     #acl localnet src 192.168.0.0/16? # RFC1918 possible internal network
>>
>>     acl localnet src fc00::/7?????? # RFC 4193 local private network
>>     range
>>
>>     acl localnet src fe80::/10????? # RFC 4291 link-local (directly
>>     plugged) machines
>>
>>     acl WSUS src 192.168.225.4/32
>>
>>     acl BACKUP src 192.168.225.11/32
>>
>>     acl ADFS src 192.168.224.7/32
>>
>>     acl ADFS src 192.168.228.8/32
>>
>>     acl DEVWEB src 192.168.226.6/32
>>
>>     acl UATWEB src 192.168.226.13/32
>>
>>     acl PRDWEB src 192.168.226.8/32
>>
>>     acl PRDWEB src 192.168.226.9/32
>>
>>     ?
>>
>>     ?
>>
>>     ?
>>
>>     acl SSL_ports port 443
>>
>>     acl Safe_ports port 80??????????????????? # http
>>
>>     #acl Safe_ports port 21????????????????? # ftp
>>
>>     acl Safe_ports port 443????????????????? # https
>>
>>     #acl Safe_ports port 70????????????????? # gopher
>>
>>     #acl Safe_ports port 210??????????????????????????????? # wais
>>
>>     #acl Safe_ports port 1025-65535??????????????? # unregistered ports
>>
>>     #acl Safe_ports port 280??????????????????????????????? # http-mgmt
>>
>>     #acl Safe_ports port 488??????????????????????????????? # gss-http
>>
>>     #acl Safe_ports port 591??????????????????????????????? # filemaker
>>
>>     #acl Safe_ports port 777??????????????????????????????? #
>>     multiling http
>>
>>     acl CONNECT method CONNECT
>>
>>     ?
>>
>>     #
>>
>>     # Recommended minimum Access Permission configuration:
>>
>>     #
>>
>>     ?
>>
>>     # Only allow cachemgr access from localhost
>>
>>     #http_access allow localhost manager
>>
>>     #http_access deny manager
>>
>>     ?
>>
>>     # Deny requests to certain unsafe ports
>>
>>     http_access deny !Safe_ports
>>
>>     ?
>>
>>     # Deny CONNECT to other than secure SSL ports
>>
>>     http_access deny CONNECT !SSL_ports
>>
>>     ?
>>
>>     # We strongly recommend the following be uncommented to protect
>>     innocent
>>
>>     # web applications running on the proxy server who think the only
>>
>>     # one who can access services on "localhost" is a local user
>>
>>     #http_access deny to_localhost
>>
>>     ?
>>
>>     #
>>
>>     # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
>>
>>     #
>>
>>     ?
>>
>>     # Example rule allowing access from your local networks.
>>
>>     # Adapt localnet in the ACL section to list your (internal) IP
>>     networks
>>
>>     # from where browsing should be allowed
>>
>>     http_access allow localnet
>>
>>     http_access allow localhost
>>
>>     http_access allow WSUS
>>
>>     http_access allow ADFS
>>
>>     http_access allow BACKUP
>>
>>     http_access allow DEVWEB
>>
>>     http_access allow UATWEB
>>
>>     http_access allow PRDWEB
>>
>>     ?
>>
>>     # And finally deny all other access to this proxy
>>
>>     http_access deny all
>>
>>     ?
>>
>>     # Squid normally listens to port 3128
>>
>>     http_port 3128
>>
>>     ?
>>
>>     # Uncomment the line below to enable disk caching - path format
>>     is /cygdrive/<full path to cache folder>, i.e.
>>
>>     #cache_dir aufs /cygdrive/d/squid/cache 3000 16 256
>>
>>     cache deny all
>>
>>     ?
>>
>>     ?
>>
>>     # Leave coredumps in the first cache dir
>>
>>     coredump_dir /var/cache/squid
>>
>>     ?
>>
>>     # Add any of your own refresh_pattern entries above these.
>>
>>     refresh_pattern ^ftp:???????????????????? 1440?????? 20%??????? 10080
>>
>>     refresh_pattern ^gopher:??????????? 1440?????? 0%????????? 1440
>>
>>     refresh_pattern -i (/cgi-bin/|\?) 0???????????? 0%????????? 0
>>
>>     refresh_pattern .???????????????????????????? 0?????????????
>>     20%??????? 4320
>>
>>     ?
>>
>>     dns_nameservers 208.67.222.222 208.67.220.220
>>
>>     ?
>>
>>     max_filedescriptors 3200
>>
>>     ?
>>
>>     ?
>>
>>     ?
>>
>>     Does anyone see anything I am missing here?
>>
>> Yes. In your almost default configuration (it is complete
>> squid.conf?) obvious thing is:
>>
>> a) You do not use on-disk cache.
>> b) You use memory cache by default - i.e. 256 Mb.
>> c) You cache nothing due to deny all cache. So, it makes useless
>> cache_mem default.
>> d) Your configuration technically useless. I see neither proxying
>> parameters, nor caching. Your squid now only additional hop for
>> files. No more.
>>
>> So, squid nothing to do here. It simple should retransmit GET (GET?)
>> request to server, and, without any caching/storing, retransmit it to
>> user.
>>
>> Still correct?
>>
>> This put us directly to raw network IO. Without any buffering (which
>> can be - but don't - your squid).
>>
>> On your place, I can start playing around with cache_mem parameter;
>> of course, only after removing cache deny all.
>>
>> And after some experiments, may be, will make decision about drop out
>> useless Squid's box.
>>
>> Seriously, what role of squid's here? Just setup border firewall to
>> your servers to access it to Internet. It will be enough.
>>
>>
>>     ?
>>
>>     ?
>>
>>     My access.log doesn?t really have anything interesting in it
>>     either, it just looks like it is working normally. I can attach
>>     that too if anyone wants to look at it after I redact some of the
>>     hosts.
>>
>>     ?
>>
>>     ?
>>
>>     *Keith Hartley*
>>
>>     /Network Engineer II/
>>
>>     /MCSE: Productivity, MCSA: Server 2008, 2012, Office 365 / |
>>
>>     /Certified Meraki Network Associate, Security+/
>>
>>     *Geocent, LLC*
>>
>>     *o:*504-405-3578
>>
>>     *a:*2219 Lakeshore drive Ste 300, New Orleans, LA 70122
>>
>>     *w:*www.geocent.com
>>     <http://www.geocent.com/>|*e:*khartley at geocent.com
>>     <mailto:khartley at geocent.com>
>>
>>     ?
>>
>>     ? ?
>>
>>     ?
>>
>>     ?
>>
>>     */_Confidentiality Notice:_/*
>>
>>     This email communication may contain confidential information,
>>     may be legally privileged, and is intended only for the use of
>>     the intended recipients(s) identified. Any unauthorized review,
>>     use, distribution, downloading, or copying of this communication
>>     is strictly prohibited. If you are not the intended recipient and
>>     have received this message in error, immediately notify the
>>     sender by reply email, delete the communication, and destroy all
>>     copies. Thank you.
>>
>>
>>
>>
>>     _______________________________________________
>>
>>     squid-users mailing list
>>
>>     squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org>
>>
>>     http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>> -- 
>> "C++ seems like a language suitable for firing other people's legs."
>> ?
>> *****************************
>> * C++20 : Bug to the future *
>> *****************************
>
> -- 
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180323/54136421/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180323/54136421/attachment.sig>

From yvoinov at gmail.com  Thu Mar 22 23:33:05 2018
From: yvoinov at gmail.com (Yuri)
Date: Fri, 23 Mar 2018 05:33:05 +0600
Subject: [squid-users] Squid for windows Very slow downloads of large
 files through squid with normal uploads
In-Reply-To: <634894e6-b954-3fed-bde0-58b84a88eb73@gmail.com>
References: <BLUPR06MB1747D5BF0659E34BFE3FE7E6EEA90@BLUPR06MB1747.namprd06.prod.outlook.com>
 <f0bcf355-7068-0065-dd72-92b7eb937070@gmail.com>
 <SN1PR06MB175846A00C2B8602EB816BADEEA90@SN1PR06MB1758.namprd06.prod.outlook.com>
 <07541384-9f4b-1d2b-3905-661cefa618ac@gmail.com>
 <634894e6-b954-3fed-bde0-58b84a88eb73@gmail.com>
Message-ID: <90aa8f69-763f-60ed-c2c3-2a11d91c37dd@gmail.com>

And, if you still insist that you need a proxy, consider Privoxy.

Lightweight primitive HTTP proxy with basic access control, has Windows
implementation, works as service.

It will be good enough.

https://www.privoxy.org/

23.03.2018 05:27, Yuri ?????:
>
> Your task is simple - you need a simple control of access to the
> Internet, for servers, without any caching. Squid here is excessive,
> moreover, in your configuration it gives an excessive overhead.
>
> You not requires advanced requests processing, SSL bumping, content
> adaptation, AV real-time checking, advanced caching, content
> compression - am I right yet?
>
> So, firewall is enough.
>
>
> 23.03.2018 05:11, Yuri ?????:
>>
>>
>>
>> 23.03.2018 05:08, Keith Hartley ?????:
>>>
>>> I don?t need it to cache anything ? the goal of it is not
>>> performance optimization, it is to provide restricted access to the
>>> internet. I have 1200 Mbps of network i/o available to the squid
>>> servers and can confirm I am able to reliably achieve at least 800
>>> Mbps when I download something directly on the squid server.
>>> Additionally, it would be extremely rare that the same file ever
>>> would get downloaded more than once, if it ever actually happens.
>>>
>>> ?
>>>
>>> By policy none of the servers may have direct internet access. This
>>> is to protect the data contained in the environment. Only one 4 bit
>>> subnet has internet access, where the squids are located, and 8 of
>>> the 45 servers need restricted internet access.
>>>
>> Now your protects nothing. You don't have any advanced ACLs in your
>> config.
>>>
>>> ?
>>>
>>> This config is complete at least in a base configuration. If I have
>>> time in the project I am going to add URI restrictions. The 8
>>> servers will only need to get to about 30-40 static URIs in total
>>> and want to block the others, but first I need to get the throughput up.
>>>
>>> ?
>>>
>>> I have 800 Mbps minimum available bandwidth to the squid servers
>>> that I can confirm is available in download tests from the squids. I
>>> have 1200 Mbps (these are Azure virtual machines) of bandwidth
>>> available in both directions between the servers that use the squids
>>> and the squids.
>>>
>>> ?
>>>
>>> However on large files I am only getting 115 Kbps sustained download
>>> speeds.
>>>
>>> ?
>>>
>>> Now if squid needs to be able to buffer the downloads to cache in
>>> order to perform well ? I could enable caching if that is the case,
>>> but would prefer to not cache anything. I very seriously doubt that
>>> I will ever download the same file two times in this environment as
>>> the only thing being downloaded is software updates that are
>>> centrally distributed from WSUS, and antivirus definitions that are
>>> released about 6-10 times per day. Most of the traffic is also
>>> https, with very little http.
>>>
>>> ?
>>>
>>> Is it the case that I may see better performance if I configure it
>>> to cache the files first before sending it to clients?
>>>
>> Nothing above can not be solved by trivial border firewall.
>>
>> Just imagine - now you have useless server which not buffers network IO.
>>
>> Ideally just drop it. And setup border firewall. This solves all of
>> your problems.
>>
>> Squid's (especially Windows Squid) is not appropriate tool here.
>>>
>>> *?*
>>>
>>> *Keith Hartley*
>>>
>>> /Network Engineer II/
>>>
>>> khartley at geocent.com <mailto:khartley at geocent.com>
>>>
>>> www.geocent.com <http://www.geocent.com>
>>>
>>> ?
>>>
>>> *From:*squid-users
>>> [mailto:squid-users-bounces at lists.squid-cache.org] *On Behalf Of *Yuri
>>> *Sent:* Thursday, March 22, 2018 5:39 PM
>>> *To:* squid-users at lists.squid-cache.org
>>> *Subject:* Re: [squid-users] Squid for windows Very slow downloads
>>> of large files through squid with normal uploads
>>>
>>> ?
>>>
>>> ?
>>>
>>> ?
>>>
>>> 22.03.2018 23:10, Keith Hartley ?????:
>>>
>>>     I am using squid 3.5 for windows as a transparent proxy to
>>>     provide internet access to 7 servers in a secure environment
>>>     that otherwise does not have internet access. I have two squids
>>>     running behind a load balancer, each one is running server 2016
>>>     core with 2 Xeon processors that is either haswell generation
>>>     with 1:1 physical processor to virtual processor mapping or a
>>>     hyper-threading Broadwell generation processor that is 1:1
>>>     logical processor to virtual processor mapping, depending on how
>>>     they are provisioned when they get started.
>>>
>>>     ?
>>>
>>>     Doing a bandwidth test directly in the VM I am able to get
>>>     internet throughput of 800-1200 Mbps.
>>>
>>>     ?
>>>
>>>     Doing a file copy to and from the VM I am able to get 1200 Mbps
>>>     lan throughput.
>>>
>>>     ?
>>>
>>>     In proxied uploads I have observed speeds as high as 120 Mbps,
>>>     which is more than enough for what I need and the bottleneck is
>>>     likely in the backup software rather than squid. Uploads
>>>     performance I am not worried about where they are at now ? even
>>>     if I only got 20-30 Mbps it would be adequate for what I need it
>>>     for.
>>>
>>>     ?
>>>
>>>     Downloads however are very slow. Small files do not seem to be
>>>     impacted. Using the test a thinkbroadband.com/download, files up
>>>     to 20 Mb will download at a reasonable 20-30 Mbps, but when I
>>>     get to 50, it slows down to about 17 Mbps, and when I download
>>>     AD Connect from Microsoft, which is about 80 Mb, I can see it
>>>     start at about 30 Mbps, but eventually goes down to about 115
>>>     kbps and levels off. When I put an IP on the server I am using
>>>     for testing that proxies through squid, I am able to download
>>>     the file at several hundred mbps. ?When I download the same file
>>>     on the squid server ? I can?t tell exactly what throughput I was
>>>     getting, but the 80 Mb file downloaded within 5 seconds.
>>>
>>>     ?
>>>
>>>     In both squid servers, other than when the servers were booting,
>>>     processor activity has not exceeded 9% in the last 7 days but
>>>     usually sits below 2%. Memory usage has not exceeded 2 Gb,
>>>     leaving 2 Gb free.
>>>
>>>     ?
>>>
>>>     I am using OpenDNS for a DNS source, and have tried changing DNS
>>>     to level3 but it made no performance difference.
>>>
>>>     ?
>>>
>>>     I think that this may be squid trying to cache something, but
>>>     had tried to turn all caching off.
>>>
>>>     ?
>>>
>>>     My cache.log doesn?t really have anything interesting in it that
>>>     I can see. It?s the same ~30 or so log entries each time the
>>>     service starts, and that is about it. Here it is:
>>>
>>>     ?
>>>
>>>     2018/03/22 09:47:27 kid1| Set Current Directory to /var/cache/squid
>>>
>>>     2018/03/22 09:47:27 kid1| Starting Squid Cache version 3.5.27
>>>     for x86_64-unknown-cygwin...
>>>
>>>     2018/03/22 09:47:27 kid1| Service Name: squid
>>>
>>>     2018/03/22 09:47:27 kid1| Process ID 1164
>>>
>>>     2018/03/22 09:47:27 kid1| Process Roles: worker
>>>
>>>     2018/03/22 09:47:27 kid1| With 3200 file descriptors available
>>>
>>>     2018/03/22 09:47:27 kid1| Initializing IP Cache...
>>>
>>>     2018/03/22 09:47:27 kid1| parseEtcHosts: /etc/hosts: (2) No such
>>>     file or directory
>>>
>>>     2018/03/22 09:47:27 kid1| DNS Socket created at [::], FD 5
>>>
>>>     2018/03/22 09:47:27 kid1| DNS Socket created at 0.0.0.0, FD 6
>>>
>>>     2018/03/22 09:47:27 kid1| Adding nameserver 208.67.222.222 from
>>>     squid.conf
>>>
>>>     2018/03/22 09:47:27 kid1| Adding nameserver 208.67.220.220 from
>>>     squid.conf
>>>
>>>     2018/03/22 09:47:27 kid1| Logfile: opening log
>>>     daemon:/var/log/squid/access.log
>>>
>>>     2018/03/22 09:47:27 kid1| Logfile Daemon: opening log
>>>     /var/log/squid/access.log
>>>
>>>     2018/03/22 09:47:27 kid1| WARNING: no_suid: setuid(0): (22)
>>>     Invalid argument
>>>
>>>     2018/03/22 09:47:27 kid1| Store logging disabled
>>>
>>>     2018/03/22 09:47:27 kid1| Swap maxSize 0 + 262144 KB, estimated
>>>     20164 objects
>>>
>>>     2018/03/22 09:47:27 kid1| Target number of buckets: 1008
>>>
>>>     2018/03/22 09:47:27 kid1| Using 8192 Store buckets
>>>
>>>     2018/03/22 09:47:27 kid1| Max Mem? size: 262144 KB
>>>
>>>     2018/03/22 09:47:27 kid1| Max Swap size: 0 KB
>>>
>>>     2018/03/22 09:47:27 kid1| Using Least Load store dir selection
>>>
>>>     2018/03/22 09:47:27 kid1| Set Current Directory to /var/cache/squid
>>>
>>>     2018/03/22 09:47:27 kid1| Finished loading MIME types and icons.
>>>
>>>     2018/03/22 09:47:27 kid1| HTCP Disabled.
>>>
>>>     2018/03/22 09:47:27 kid1| Squid plugin modules loaded: 0
>>>
>>>     2018/03/22 09:47:27 kid1| Adaptation support is off.
>>>
>>>     2018/03/22 09:47:27 kid1| Accepting HTTP Socket connections at
>>>     local=[::]:3128 remote=[::] FD 10 flags=9
>>>
>>>     2018/03/22 09:47:28 kid1| storeLateRelease: released 0 objects
>>>
>>>     ?
>>>
>>>     ?
>>>
>>>     And this is my squid.conf:
>>>
>>>     ?
>>>
>>>     #
>>>
>>>     # Recommended minimum configuration:
>>>
>>>     #
>>>
>>>     ?
>>>
>>>     # Example rule allowing access from your local networks.
>>>
>>>     # Adapt to list your (internal) IP networks from where browsing
>>>
>>>     # should be allowed
>>>
>>>     ?
>>>
>>>     #acl localnet src 10.0.0.0/8?????????? # RFC1918 possible
>>>     internal network
>>>
>>>     #acl localnet src 172.16.0.0/12??? # RFC1918 possible internal
>>>     network
>>>
>>>     #acl localnet src 192.168.0.0/16? # RFC1918 possible internal
>>>     network
>>>
>>>     acl localnet src fc00::/7?????? # RFC 4193 local private network
>>>     range
>>>
>>>     acl localnet src fe80::/10????? # RFC 4291 link-local (directly
>>>     plugged) machines
>>>
>>>     acl WSUS src 192.168.225.4/32
>>>
>>>     acl BACKUP src 192.168.225.11/32
>>>
>>>     acl ADFS src 192.168.224.7/32
>>>
>>>     acl ADFS src 192.168.228.8/32
>>>
>>>     acl DEVWEB src 192.168.226.6/32
>>>
>>>     acl UATWEB src 192.168.226.13/32
>>>
>>>     acl PRDWEB src 192.168.226.8/32
>>>
>>>     acl PRDWEB src 192.168.226.9/32
>>>
>>>     ?
>>>
>>>     ?
>>>
>>>     ?
>>>
>>>     acl SSL_ports port 443
>>>
>>>     acl Safe_ports port 80??????????????????? # http
>>>
>>>     #acl Safe_ports port 21????????????????? # ftp
>>>
>>>     acl Safe_ports port 443????????????????? # https
>>>
>>>     #acl Safe_ports port 70????????????????? # gopher
>>>
>>>     #acl Safe_ports port 210??????????????????????????????? # wais
>>>
>>>     #acl Safe_ports port 1025-65535??????????????? # unregistered ports
>>>
>>>     #acl Safe_ports port 280??????????????????????????????? # http-mgmt
>>>
>>>     #acl Safe_ports port 488??????????????????????????????? # gss-http
>>>
>>>     #acl Safe_ports port 591??????????????????????????????? # filemaker
>>>
>>>     #acl Safe_ports port 777??????????????????????????????? #
>>>     multiling http
>>>
>>>     acl CONNECT method CONNECT
>>>
>>>     ?
>>>
>>>     #
>>>
>>>     # Recommended minimum Access Permission configuration:
>>>
>>>     #
>>>
>>>     ?
>>>
>>>     # Only allow cachemgr access from localhost
>>>
>>>     #http_access allow localhost manager
>>>
>>>     #http_access deny manager
>>>
>>>     ?
>>>
>>>     # Deny requests to certain unsafe ports
>>>
>>>     http_access deny !Safe_ports
>>>
>>>     ?
>>>
>>>     # Deny CONNECT to other than secure SSL ports
>>>
>>>     http_access deny CONNECT !SSL_ports
>>>
>>>     ?
>>>
>>>     # We strongly recommend the following be uncommented to protect
>>>     innocent
>>>
>>>     # web applications running on the proxy server who think the only
>>>
>>>     # one who can access services on "localhost" is a local user
>>>
>>>     #http_access deny to_localhost
>>>
>>>     ?
>>>
>>>     #
>>>
>>>     # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
>>>
>>>     #
>>>
>>>     ?
>>>
>>>     # Example rule allowing access from your local networks.
>>>
>>>     # Adapt localnet in the ACL section to list your (internal) IP
>>>     networks
>>>
>>>     # from where browsing should be allowed
>>>
>>>     http_access allow localnet
>>>
>>>     http_access allow localhost
>>>
>>>     http_access allow WSUS
>>>
>>>     http_access allow ADFS
>>>
>>>     http_access allow BACKUP
>>>
>>>     http_access allow DEVWEB
>>>
>>>     http_access allow UATWEB
>>>
>>>     http_access allow PRDWEB
>>>
>>>     ?
>>>
>>>     # And finally deny all other access to this proxy
>>>
>>>     http_access deny all
>>>
>>>     ?
>>>
>>>     # Squid normally listens to port 3128
>>>
>>>     http_port 3128
>>>
>>>     ?
>>>
>>>     # Uncomment the line below to enable disk caching - path format
>>>     is /cygdrive/<full path to cache folder>, i.e.
>>>
>>>     #cache_dir aufs /cygdrive/d/squid/cache 3000 16 256
>>>
>>>     cache deny all
>>>
>>>     ?
>>>
>>>     ?
>>>
>>>     # Leave coredumps in the first cache dir
>>>
>>>     coredump_dir /var/cache/squid
>>>
>>>     ?
>>>
>>>     # Add any of your own refresh_pattern entries above these.
>>>
>>>     refresh_pattern ^ftp:???????????????????? 1440?????? 20%???????
>>>     10080
>>>
>>>     refresh_pattern ^gopher:??????????? 1440?????? 0%????????? 1440
>>>
>>>     refresh_pattern -i (/cgi-bin/|\?) 0???????????? 0%????????? 0
>>>
>>>     refresh_pattern .???????????????????????????? 0?????????????
>>>     20%??????? 4320
>>>
>>>     ?
>>>
>>>     dns_nameservers 208.67.222.222 208.67.220.220
>>>
>>>     ?
>>>
>>>     max_filedescriptors 3200
>>>
>>>     ?
>>>
>>>     ?
>>>
>>>     ?
>>>
>>>     Does anyone see anything I am missing here?
>>>
>>> Yes. In your almost default configuration (it is complete
>>> squid.conf?) obvious thing is:
>>>
>>> a) You do not use on-disk cache.
>>> b) You use memory cache by default - i.e. 256 Mb.
>>> c) You cache nothing due to deny all cache. So, it makes useless
>>> cache_mem default.
>>> d) Your configuration technically useless. I see neither proxying
>>> parameters, nor caching. Your squid now only additional hop for
>>> files. No more.
>>>
>>> So, squid nothing to do here. It simple should retransmit GET (GET?)
>>> request to server, and, without any caching/storing, retransmit it
>>> to user.
>>>
>>> Still correct?
>>>
>>> This put us directly to raw network IO. Without any buffering (which
>>> can be - but don't - your squid).
>>>
>>> On your place, I can start playing around with cache_mem parameter;
>>> of course, only after removing cache deny all.
>>>
>>> And after some experiments, may be, will make decision about drop
>>> out useless Squid's box.
>>>
>>> Seriously, what role of squid's here? Just setup border firewall to
>>> your servers to access it to Internet. It will be enough.
>>>
>>>
>>>     ?
>>>
>>>     ?
>>>
>>>     My access.log doesn?t really have anything interesting in it
>>>     either, it just looks like it is working normally. I can attach
>>>     that too if anyone wants to look at it after I redact some of
>>>     the hosts.
>>>
>>>     ?
>>>
>>>     ?
>>>
>>>     *Keith Hartley*
>>>
>>>     /Network Engineer II/
>>>
>>>     /MCSE: Productivity, MCSA: Server 2008, 2012, Office 365 / |
>>>
>>>     /Certified Meraki Network Associate, Security+/
>>>
>>>     *Geocent, LLC*
>>>
>>>     *o:*504-405-3578
>>>
>>>     *a:*2219 Lakeshore drive Ste 300, New Orleans, LA 70122
>>>
>>>     *w:*www.geocent.com
>>>     <http://www.geocent.com/>|*e:*khartley at geocent.com
>>>     <mailto:khartley at geocent.com>
>>>
>>>     ?
>>>
>>>     ? ?
>>>
>>>     ?
>>>
>>>     ?
>>>
>>>     */_Confidentiality Notice:_/*
>>>
>>>     This email communication may contain confidential information,
>>>     may be legally privileged, and is intended only for the use of
>>>     the intended recipients(s) identified. Any unauthorized review,
>>>     use, distribution, downloading, or copying of this communication
>>>     is strictly prohibited. If you are not the intended recipient
>>>     and have received this message in error, immediately notify the
>>>     sender by reply email, delete the communication, and destroy all
>>>     copies. Thank you.
>>>
>>>
>>>
>>>
>>>     _______________________________________________
>>>
>>>     squid-users mailing list
>>>
>>>     squid-users at lists.squid-cache.org
>>>     <mailto:squid-users at lists.squid-cache.org>
>>>
>>>     http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>>
>>> -- 
>>> "C++ seems like a language suitable for firing other people's legs."
>>> ?
>>> *****************************
>>> * C++20 : Bug to the future *
>>> *****************************
>>
>> -- 
>> "C++ seems like a language suitable for firing other people's legs."
>>
>> *****************************
>> * C++20 : Bug to the future *
>> *****************************
>
> -- 
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180323/16f99298/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180323/16f99298/attachment.sig>

From uhlar at fantomas.sk  Fri Mar 23 08:56:21 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 23 Mar 2018 09:56:21 +0100
Subject: [squid-users] Squid for windows Very slow downloads of large
 files through squid with normal uploads
In-Reply-To: <SN1PR06MB175846A00C2B8602EB816BADEEA90@SN1PR06MB1758.namprd06.prod.outlook.com>
References: <BLUPR06MB1747D5BF0659E34BFE3FE7E6EEA90@BLUPR06MB1747.namprd06.prod.outlook.com>
 <f0bcf355-7068-0065-dd72-92b7eb937070@gmail.com>
 <SN1PR06MB175846A00C2B8602EB816BADEEA90@SN1PR06MB1758.namprd06.prod.outlook.com>
Message-ID: <20180323085621.GA15687@fantomas.sk>

On 22.03.18 23:08, Keith Hartley wrote:
>However on large files I am only getting 115 Kbps sustained download speeds.

does this happen evben when you try using squid on the mavchine squid is
installed?


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
I drive way too fast to worry about cholesterol. 


From Keith.Hartley at geocent.com  Fri Mar 23 15:25:24 2018
From: Keith.Hartley at geocent.com (Keith Hartley)
Date: Fri, 23 Mar 2018 15:25:24 +0000
Subject: [squid-users] Squid for windows Very slow downloads of large
 files through squid with normal uploads
In-Reply-To: <20180323085621.GA15687@fantomas.sk>
References: <BLUPR06MB1747D5BF0659E34BFE3FE7E6EEA90@BLUPR06MB1747.namprd06.prod.outlook.com>
 <f0bcf355-7068-0065-dd72-92b7eb937070@gmail.com>
 <SN1PR06MB175846A00C2B8602EB816BADEEA90@SN1PR06MB1758.namprd06.prod.outlook.com>
 <20180323085621.GA15687@fantomas.sk>
Message-ID: <BLUPR06MB174732D6EB3641E51535883AEEA80@BLUPR06MB1747.namprd06.prod.outlook.com>

I had not thought to test that. I will do that today.

In regards to Yuri's comments on firewall vs squid - I don?t agree that a firewall would be a direct replacement in this case.

The 30-40 URIs I need to access resolve to a potential pool of several million IP addresses, and the pool of IP addresses gets updated multiple times per year. Writing rules at the network level would not be practical to implement even one time, let alone maintain over time. A more expensive firewall that is able to implement ACLs by hostname would be needed, and options for virtual firewalls hosted in Azure are limited. It would also require either implementing many static routes, or a transit network with a virtual router, and this environment will be supported by an organization that does not have a network engineer on staff.

I understand that there is very little functionality I need to leverage, but I like Squid, as it is a name that most people in IT will recognize and be able to google.

I may still review privoxy however. If it is simple enough that supporting it would be something easy to just figure out with minimal research, it may still be a good option. I like simple, but high supportability is mandatory


Keith Hartley
Network Engineer II
khartley at geocent.com
www.geocent.com

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Matus UHLAR - fantomas
Sent: Friday, March 23, 2018 3:56 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for windows Very slow downloads of large files through squid with normal uploads

On 22.03.18 23:08, Keith Hartley wrote:
>However on large files I am only getting 115 Kbps sustained download speeds.

does this happen evben when you try using squid on the mavchine squid is installed?


--
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
I drive way too fast to worry about cholesterol.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

Confidentiality Notice:
This email communication may contain confidential information, may be legally privileged, and is intended only for the use of the intended recipients(s) identified. Any unauthorized review, use, distribution, downloading, or copying of this communication is strictly prohibited. If you are not the intended recipient and have received this message in error, immediately notify the sender by reply email, delete the communication, and destroy all copies. Thank you.

From yvoinov at gmail.com  Fri Mar 23 15:41:00 2018
From: yvoinov at gmail.com (Yuri)
Date: Fri, 23 Mar 2018 21:41:00 +0600
Subject: [squid-users] Squid for windows Very slow downloads of large
 files through squid with normal uploads
In-Reply-To: <BLUPR06MB174732D6EB3641E51535883AEEA80@BLUPR06MB1747.namprd06.prod.outlook.com>
References: <BLUPR06MB1747D5BF0659E34BFE3FE7E6EEA90@BLUPR06MB1747.namprd06.prod.outlook.com>
 <f0bcf355-7068-0065-dd72-92b7eb937070@gmail.com>
 <SN1PR06MB175846A00C2B8602EB816BADEEA90@SN1PR06MB1758.namprd06.prod.outlook.com>
 <20180323085621.GA15687@fantomas.sk>
 <BLUPR06MB174732D6EB3641E51535883AEEA80@BLUPR06MB1747.namprd06.prod.outlook.com>
Message-ID: <b7895004-fe3c-2ada-8bbb-9bb2fc507d98@gmail.com>



23.03.2018 21:25, Keith Hartley ?????:
> I had not thought to test that. I will do that today.
>
> In regards to Yuri's comments on firewall vs squid - I don?t agree that a firewall would be a direct replacement in this case.
>
> The 30-40 URIs I need to access resolve to a potential pool of several million IP addresses, and the pool of IP addresses gets updated multiple times per year. Writing rules at the network level would not be practical to implement even one time, let alone maintain over time. A more expensive firewall that is able to implement ACLs by hostname would be needed, and options for virtual firewalls hosted in Azure are limited. It would also require either implementing many static routes, or a transit network with a virtual router, and this environment will be supported by an organization that does not have a network engineer on staff.
It depends. If your make Internet access for servers due to updates - in
most cases updates has limited distribution points (of course, we're not
considering CDN now). Some cases can be easy solved by server's built-in
firewall.

If we're talking about infrastructure, best solution for updates is
internal updates server (like WSUS), which only have access to Internet
with all security restrictions. You know this better than me ;) Anyway,
centralized patch/updates server behind the border firewall is best
solution.

But this is, of course, abstract discussion.
>
> I understand that there is very little functionality I need to leverage, but I like Squid, as it is a name that most people in IT will recognize and be able to google.
We're like it too, but Squid's itself is big and relatively complex
software, requires much experience to use and not always easy in
support. It has a lot of functions and can have very complex
configurations. This is why I can't recommend use it in all cases
requires proxying/caching without serious reasons.
>
> I may still review privoxy however. If it is simple enough that supporting it would be something easy to just figure out with minimal research, it may still be a good option. I like simple, but high supportability is mandatory
Yes. Privoxy is very simple instead Squid. It is non-caching proxy,
which have all functionality you require. It works with hostnames.

Don't worry - you will not require much support for it. It's just works. ;)
>
>
> Keith Hartley
> Network Engineer II
> khartley at geocent.com
> www.geocent.com
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Matus UHLAR - fantomas
> Sent: Friday, March 23, 2018 3:56 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid for windows Very slow downloads of large files through squid with normal uploads
>
> On 22.03.18 23:08, Keith Hartley wrote:
>> However on large files I am only getting 115 Kbps sustained download speeds.
> does this happen evben when you try using squid on the mavchine squid is installed?
>
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> I drive way too fast to worry about cholesterol.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> Confidentiality Notice:
> This email communication may contain confidential information, may be legally privileged, and is intended only for the use of the intended recipients(s) identified. Any unauthorized review, use, distribution, downloading, or copying of this communication is strictly prohibited. If you are not the intended recipient and have received this message in error, immediately notify the sender by reply email, delete the communication, and destroy all copies. Thank you.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180323/e91910ac/attachment.sig>

From Keith.Hartley at geocent.com  Fri Mar 23 15:48:51 2018
From: Keith.Hartley at geocent.com (Keith Hartley)
Date: Fri, 23 Mar 2018 15:48:51 +0000
Subject: [squid-users] Squid for windows Very slow downloads of large
 files through squid with normal uploads
In-Reply-To: <b7895004-fe3c-2ada-8bbb-9bb2fc507d98@gmail.com>
References: <BLUPR06MB1747D5BF0659E34BFE3FE7E6EEA90@BLUPR06MB1747.namprd06.prod.outlook.com>
 <f0bcf355-7068-0065-dd72-92b7eb937070@gmail.com>
 <SN1PR06MB175846A00C2B8602EB816BADEEA90@SN1PR06MB1758.namprd06.prod.outlook.com>
 <20180323085621.GA15687@fantomas.sk>
 <BLUPR06MB174732D6EB3641E51535883AEEA80@BLUPR06MB1747.namprd06.prod.outlook.com>
 <b7895004-fe3c-2ada-8bbb-9bb2fc507d98@gmail.com>
Message-ID: <BLUPR06MB17474C8E30A73366B1AC36A9EEA80@BLUPR06MB1747.namprd06.prod.outlook.com>

Yeah, there are some other considerations with this environment. While WSUS is the only service that downloads files in any significant quantity, there were architectural decisions made in the application that this environment hosts which requires the application to have some minimal internet access, which is what caused the need for the proxy. WSUS was originally set up exactly as you described until I learned of the application requirements, and technically it is the only thing that needs a proxy, but I didn't want to set up a different way of accessing the internet for each service that needed access and making it confusing, so went to using a proxy for everything so there would only be one path to the internet.


Keith Hartley
Network Engineer II
khartley at geocent.com
www.geocent.com

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri
Sent: Friday, March 23, 2018 10:41 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for windows Very slow downloads of large files through squid with normal uploads



23.03.2018 21:25, Keith Hartley ?????:
> I had not thought to test that. I will do that today.
>
> In regards to Yuri's comments on firewall vs squid - I don?t agree that a firewall would be a direct replacement in this case.
>
> The 30-40 URIs I need to access resolve to a potential pool of several million IP addresses, and the pool of IP addresses gets updated multiple times per year. Writing rules at the network level would not be practical to implement even one time, let alone maintain over time. A more expensive firewall that is able to implement ACLs by hostname would be needed, and options for virtual firewalls hosted in Azure are limited. It would also require either implementing many static routes, or a transit network with a virtual router, and this environment will be supported by an organization that does not have a network engineer on staff.
It depends. If your make Internet access for servers due to updates - in most cases updates has limited distribution points (of course, we're not considering CDN now). Some cases can be easy solved by server's built-in firewall.

If we're talking about infrastructure, best solution for updates is internal updates server (like WSUS), which only have access to Internet with all security restrictions. You know this better than me ;) Anyway, centralized patch/updates server behind the border firewall is best solution.

But this is, of course, abstract discussion.
>
> I understand that there is very little functionality I need to leverage, but I like Squid, as it is a name that most people in IT will recognize and be able to google.
We're like it too, but Squid's itself is big and relatively complex software, requires much experience to use and not always easy in support. It has a lot of functions and can have very complex configurations. This is why I can't recommend use it in all cases requires proxying/caching without serious reasons.
>
> I may still review privoxy however. If it is simple enough that 
> supporting it would be something easy to just figure out with minimal 
> research, it may still be a good option. I like simple, but high 
> supportability is mandatory
Yes. Privoxy is very simple instead Squid. It is non-caching proxy, which have all functionality you require. It works with hostnames.

Don't worry - you will not require much support for it. It's just works. ;)
>
>
> Keith Hartley
> Network Engineer II
> khartley at geocent.com
> www.geocent.com
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
> On Behalf Of Matus UHLAR - fantomas
> Sent: Friday, March 23, 2018 3:56 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid for windows Very slow downloads of 
> large files through squid with normal uploads
>
> On 22.03.18 23:08, Keith Hartley wrote:
>> However on large files I am only getting 115 Kbps sustained download speeds.
> does this happen evben when you try using squid on the mavchine squid is installed?
>
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> I drive way too fast to worry about cholesterol.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> Confidentiality Notice:
> This email communication may contain confidential information, may be legally privileged, and is intended only for the use of the intended recipients(s) identified. Any unauthorized review, use, distribution, downloading, or copying of this communication is strictly prohibited. If you are not the intended recipient and have received this message in error, immediately notify the sender by reply email, delete the communication, and destroy all copies. Thank you.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

--
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************



From vvv25 at gmx.net  Sat Mar 24 15:15:53 2018
From: vvv25 at gmx.net (vvv25 at gmx.net)
Date: Sat, 24 Mar 2018 16:15:53 +0100
Subject: [squid-users] delay-pool based on authentication
Message-ID: <op.zgdzcrjrek8y7k@mail.gmx.net>

Dear Comunity,

I have the following question:
Is it possible with squid to select delay pool depending on whether the  
user is authenticated or not?

Background:
I want to set up a slow delay pool by default. (for unauthenticated users)
For registered users I want to assign another delay pool with no  
restriction (full speed).

Any suggestion is welcome.

Thank you very much!

Regards,
Vitaly


From yvoinov at gmail.com  Sat Mar 24 15:20:24 2018
From: yvoinov at gmail.com (Yuri)
Date: Sat, 24 Mar 2018 21:20:24 +0600
Subject: [squid-users] delay-pool based on authentication
In-Reply-To: <op.zgdzcrjrek8y7k@mail.gmx.net>
References: <op.zgdzcrjrek8y7k@mail.gmx.net>
Message-ID: <58c2477d-46b6-6dc7-b82c-cb3cf80328d1@gmail.com>

https://wiki.squid-cache.org/Features/DelayPools


24.03.2018 21:15, vvv25 at gmx.net ?????:
> Dear Comunity,
>
> I have the following question:
> Is it possible with squid to select delay pool depending on whether
> the user is authenticated or not?
>
> Background:
> I want to set up a slow delay pool by default. (for unauthenticated
> users)
> For registered users I want to assign another delay pool with no
> restriction (full speed).
>
> Any suggestion is welcome.
>
> Thank you very much!
>
> Regards,
> Vitaly
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180324/907a080b/attachment.sig>

From squid3 at treenet.co.nz  Sat Mar 24 17:13:14 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 25 Mar 2018 06:13:14 +1300
Subject: [squid-users] delay-pool based on authentication
In-Reply-To: <op.zgdzcrjrek8y7k@mail.gmx.net>
References: <op.zgdzcrjrek8y7k@mail.gmx.net>
Message-ID: <3d16c839-515b-d9ad-a29f-45a1d80f0ad3@treenet.co.nz>

On 25/03/18 04:15, vvv25 wrote:>
> I want to set up a slow delay pool by default. (for unauthenticated users)
> For registered users I want to assign another delay pool with no
> restriction (full speed).

The thing with DelayPool is that to "set" no restriction you *dont*
assign a delay pool.

What Yuri missed out was that for per-user detailss see the "class 4"
details on that page.

Amos


From eliezer at ngtech.co.il  Sun Mar 25 09:29:28 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 25 Mar 2018 12:29:28 +0300
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
Message-ID: <152a01d3c41b$c617b580$52472080$@ngtech.co.il>

Hey Nicolas,

You can use a "splash page" concept which will contain a test page that will try to verify if the client has the root ca certificate installed.
I have created and published an example at:
https://github.com/elico/ca-cert-test-page

And a real usage at:
https://cert.rimon.net.il/

If the client will first try to access an http site it will work but if the client will try https site it will not work but once the client will get pass the error page he will be able to get instructions on how and what to install.

Will it work for your environment?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Nicolas Kovacs
Sent: Friday, March 16, 2018 12:37
To: squid-users at lists.squid-cache.org
Subject: [squid-users] How to configure a "proxy home" page ?

Hi,

I have Squid + SquidGuard + SquidAnalyzer running on my LAN server as a
transparent cache + filtering proxy, and it's working real nicely.

When a client in my company wants to connect to the wifi, all he or she
has to do is this:

1. Connect to http://nestor.microlinux.lan

2. Download the nestor.microlinux.lan.der certificate

3. Install the certificate in the web browser (Firefox does it
automatically)

4. Surf the web

Now I wonder if there is a way to configure this page as a "proxy home
page" of some sorts. User who don't have the certificate installed
normally get a big fat HTTPS error as soon as they connect to a secure
site. So what I'd like to do is redirect "new" traffic to
http://nestor.microlinux.lan, which also explains what is happening.

I don't really know how to go about that, or if it is even possible.
Maybe some basic form of authentication ?

Any suggestion ?

Cheers,

Niki
-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Sun Mar 25 11:08:48 2018
From: yvoinov at gmail.com (Yuri)
Date: Sun, 25 Mar 2018 17:08:48 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
Message-ID: <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>

Hey Eliezer,

PC browsers non-required automated installers for CA. In it all simple
do by JS directly from page.

Can you do automated installer for mobile clients? iPhones, Android? For
both - mobile browsers and apps as well?

The problem is not install proxy CA. The problem is identify client has
no proxy CA and redirect, and do it only one time.

Splash is perfect idea, but it will execute too often.

So, require more elegant solution.

25.03.2018 15:29, Eliezer Croitoru ?????:
> Hey Nicolas,
>
> You can use a "splash page" concept which will contain a test page that will try to verify if the client has the root ca certificate installed.
> I have created and published an example at:
> https://github.com/elico/ca-cert-test-page
>
> And a real usage at:
> https://cert.rimon.net.il/
>
> If the client will first try to access an http site it will work but if the client will try https site it will not work but once the client will get pass the error page he will be able to get instructions on how and what to install.
>
> Will it work for your environment?
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Nicolas Kovacs
> Sent: Friday, March 16, 2018 12:37
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] How to configure a "proxy home" page ?
>
> Hi,
>
> I have Squid + SquidGuard + SquidAnalyzer running on my LAN server as a
> transparent cache + filtering proxy, and it's working real nicely.
>
> When a client in my company wants to connect to the wifi, all he or she
> has to do is this:
>
> 1. Connect to http://nestor.microlinux.lan
>
> 2. Download the nestor.microlinux.lan.der certificate
>
> 3. Install the certificate in the web browser (Firefox does it
> automatically)
>
> 4. Surf the web
>
> Now I wonder if there is a way to configure this page as a "proxy home
> page" of some sorts. User who don't have the certificate installed
> normally get a big fat HTTPS error as soon as they connect to a secure
> site. So what I'd like to do is redirect "new" traffic to
> http://nestor.microlinux.lan, which also explains what is happening.
>
> I don't really know how to go about that, or if it is even possible.
> Maybe some basic form of authentication ?
>
> Any suggestion ?
>
> Cheers,
>
> Niki

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180325/bbcb8020/attachment.sig>

From info at microlinux.fr  Sun Mar 25 11:46:08 2018
From: info at microlinux.fr (Nicolas Kovacs)
Date: Sun, 25 Mar 2018 13:46:08 +0200
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
Message-ID: <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>

Le 25/03/2018 ? 13:08, Yuri a ?crit :
> The problem is not install proxy CA. The problem is identify client
> has no proxy CA and redirect, and do it only one time.

That is exactly the problem. And I have yet to find a solution for that.

Current method is instruct everyone - with a printed paper in the office
- to connect to proxy.company-name.lan and then get further instructions
from the page. This works, but an automatic splash page would be more
elegant.

Niki

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32


From yvoinov at gmail.com  Sun Mar 25 12:41:15 2018
From: yvoinov at gmail.com (Yuri)
Date: Sun, 25 Mar 2018 18:41:15 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
Message-ID: <b03a17a7-5309-5c7e-a458-bd69c8c27dd4@gmail.com>



25.03.2018 17:46, Nicolas Kovacs ?????:
> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>> The problem is not install proxy CA. The problem is identify client
>> has no proxy CA and redirect, and do it only one time.
> That is exactly the problem. And I have yet to find a solution for that.
>
> Current method is instruct everyone - with a printed paper in the office
> - to connect to proxy.company-name.lan and then get further instructions
> from the page. This works, but an automatic splash page would be more
> elegant.
Splash

https://wiki.squid-cache.org/ConfigExamples/Portal/Splash

will occurs too often and require external helper.

I mean more elegant using something like content adaptation, to store
in, for example, SQLite db users already covered (by any attribute) and
not to check them in the future.

Or, as I've told, using SSL error + acl functionality.

However, mobile clients still an issue in all cases, as we're all knows.

>
> Niki
>

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180325/11a97989/attachment.sig>

From uhlar at fantomas.sk  Sun Mar 25 12:42:09 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sun, 25 Mar 2018 14:42:09 +0200
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
Message-ID: <20180325124209.GA2303@fantomas.sk>

>Le 25/03/2018 ? 13:08, Yuri a ?crit :
>> The problem is not install proxy CA. The problem is identify client
>> has no proxy CA and redirect, and do it only one time.

On 25.03.18 13:46, Nicolas Kovacs wrote:
>That is exactly the problem. And I have yet to find a solution for that.
>
>Current method is instruct everyone - with a printed paper in the office
>- to connect to proxy.company-name.lan and then get further instructions
>from the page. This works, but an automatic splash page would be more
>elegant.

impossible and unsafe. The CA must be installed before such splash page shows
up and in such case the splash page is irelevant.

If you have windows domain, you can force security policy through it.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Quantum mechanics: The dreams stuff is made of. 


From yvoinov at gmail.com  Sun Mar 25 12:44:22 2018
From: yvoinov at gmail.com (Yuri)
Date: Sun, 25 Mar 2018 18:44:22 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <20180325124209.GA2303@fantomas.sk>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
Message-ID: <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>



25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>> The problem is not install proxy CA. The problem is identify client
>>> has no proxy CA and redirect, and do it only one time.
>
> On 25.03.18 13:46, Nicolas Kovacs wrote:
>> That is exactly the problem. And I have yet to find a solution for that.
>>
>> Current method is instruct everyone - with a printed paper in the office
>> - to connect to proxy.company-name.lan and then get further instructions
>> from the page. This works, but an automatic splash page would be more
>> elegant.
>
> impossible and unsafe. The CA must be installed before such splash
> page shows
Possible. "Safe/Unsafe" should not be discussion when SSL Bump
implemented already.
> up and in such case the splash page is irelevant.
>
> If you have windows domain, you can force security policy through it.
In enterprise environment with AD, yes. But hardly in service provider's
scenarious.


-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180325/cafd278a/attachment.sig>

From uhlar at fantomas.sk  Sun Mar 25 14:32:13 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sun, 25 Mar 2018 16:32:13 +0200
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
Message-ID: <20180325143213.GC2303@fantomas.sk>

>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>> The problem is not install proxy CA. The problem is identify client
>>>> has no proxy CA and redirect, and do it only one time.
>>
>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>> That is exactly the problem. And I have yet to find a solution for that.
>>>
>>> Current method is instruct everyone - with a printed paper in the office
>>> - to connect to proxy.company-name.lan and then get further instructions
>>> from the page. This works, but an automatic splash page would be more
>>> elegant.

>25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>> impossible and unsafe. The CA must be installed before such splash
>> page shows

On 25.03.18 18:44, Yuri wrote:
>Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>implemented already.

it's possible to install splash page, but not install trusted authority
certificate.  Using such authority on a proxy is the MITM attack and whole
SSL has been designed to prevent this.

without certificate, the browser complains which is a security measure
against this.

>> up and in such case the splash page is irelevant.
>>
>> If you have windows domain, you can force security policy through it.

>In enterprise environment with AD, yes. But hardly in service provider's
>scenarious.

service providers should not do this without users' permission.
at least not in countries where the privacy is guaranteed by law.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Emacs is a complicated operating system without good text editor.


From yvoinov at gmail.com  Sun Mar 25 15:41:54 2018
From: yvoinov at gmail.com (Yuri)
Date: Sun, 25 Mar 2018 21:41:54 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <20180325143213.GC2303@fantomas.sk>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
Message-ID: <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>



25.03.2018 20:32, Matus UHLAR - fantomas ?????:
>>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>>> The problem is not install proxy CA. The problem is identify client
>>>>> has no proxy CA and redirect, and do it only one time.
>>>
>>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>>> That is exactly the problem. And I have yet to find a solution for
>>>> that.
>>>>
>>>> Current method is instruct everyone - with a printed paper in the
>>>> office
>>>> - to connect to proxy.company-name.lan and then get further
>>>> instructions
>>>> from the page. This works, but an automatic splash page would be more
>>>> elegant.
>
>> 25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>>> impossible and unsafe. The CA must be installed before such splash
>>> page shows
>
> On 25.03.18 18:44, Yuri wrote:
>> Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>> implemented already.
>
> it's possible to install splash page, but not install trusted authority
> certificate.? Using such authority on a proxy is the MITM attack and
> whole
> SSL has been designed to prevent this.
Heh. If SSL designed - why SSL Bump itself possible? ;):-P
>
> without certificate, the browser complains which is a security measure
> against this.
Sure. It should.
>
>>> up and in such case the splash page is irelevant.
>>>
>>> If you have windows domain, you can force security policy through it.
>
>> In enterprise environment with AD, yes. But hardly in service provider's
>> scenarious.
>
> service providers should not do this without users' permission.
> at least not in countries where the privacy is guaranteed by law.
Thank you, Captain Obvious. :-) Enterprises also should get user
agreement before do that. Especially in BYOD scenarious.

All these things are well known here. The question was about technical
implementation, and not about the well-known truisms in the field of
security and privacy (in most cases of ephemeral).

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180325/b491d38c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180325/b491d38c/attachment.sig>

From yvoinov at gmail.com  Sun Mar 25 16:00:05 2018
From: yvoinov at gmail.com (Yuri)
Date: Sun, 25 Mar 2018 22:00:05 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
Message-ID: <a2d03fe0-9559-90df-0eda-d0fef530943c@gmail.com>

In principle, I do not consider as secure the technology that allows
MiTM (even in theory) - anyway, for what purpose.

Since this is so - HTTPS is nothing more than a security theater with a
green lock for calming users.

This does not mean that I do not care about the security and privacy of
users. But I provide it somewhat differently, carefully protecting the
proxy itself, its infrastructure and its cache.


25.03.2018 21:41, Yuri ?????:
>
>
>
> 25.03.2018 20:32, Matus UHLAR - fantomas ?????:
>>>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>>>> The problem is not install proxy CA. The problem is identify client
>>>>>> has no proxy CA and redirect, and do it only one time.
>>>>
>>>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>>>> That is exactly the problem. And I have yet to find a solution for
>>>>> that.
>>>>>
>>>>> Current method is instruct everyone - with a printed paper in the
>>>>> office
>>>>> - to connect to proxy.company-name.lan and then get further
>>>>> instructions
>>>>> from the page. This works, but an automatic splash page would be more
>>>>> elegant.
>>
>>> 25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>>>> impossible and unsafe. The CA must be installed before such splash
>>>> page shows
>>
>> On 25.03.18 18:44, Yuri wrote:
>>> Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>>> implemented already.
>>
>> it's possible to install splash page, but not install trusted authority
>> certificate.? Using such authority on a proxy is the MITM attack and
>> whole
>> SSL has been designed to prevent this.
> Heh. If SSL designed - why SSL Bump itself possible? ;):-P
>>
>> without certificate, the browser complains which is a security measure
>> against this.
> Sure. It should.
>>
>>>> up and in such case the splash page is irelevant.
>>>>
>>>> If you have windows domain, you can force security policy through it.
>>
>>> In enterprise environment with AD, yes. But hardly in service
>>> provider's
>>> scenarious.
>>
>> service providers should not do this without users' permission.
>> at least not in countries where the privacy is guaranteed by law.
> Thank you, Captain Obvious. :-) Enterprises also should get user
> agreement before do that. Especially in BYOD scenarious.
>
> All these things are well known here. The question was about technical
> implementation, and not about the well-known truisms in the field of
> security and privacy (in most cases of ephemeral).
>
> -- 
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180325/b725b5ce/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180325/b725b5ce/attachment.sig>

From yvoinov at gmail.com  Sun Mar 25 17:24:16 2018
From: yvoinov at gmail.com (Yuri)
Date: Sun, 25 Mar 2018 23:24:16 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <a2d03fe0-9559-90df-0eda-d0fef530943c@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <a2d03fe0-9559-90df-0eda-d0fef530943c@gmail.com>
Message-ID: <dc44d8cc-0f5a-f467-5965-19105f237888@gmail.com>

Therefore, please, PLEASE, never mention SSL Bump and security/privacy
in one letter.O:-)

These are mutually exclusive concepts.

Just like HTTPS and security.

25.03.2018 22:00, Yuri ?????:
>
> In principle, I do not consider as secure the technology that allows
> MiTM (even in theory) - anyway, for what purpose.
>
> Since this is so - HTTPS is nothing more than a security theater with
> a green lock for calming users.
>
> This does not mean that I do not care about the security and privacy
> of users. But I provide it somewhat differently, carefully protecting
> the proxy itself, its infrastructure and its cache.
>
>
> 25.03.2018 21:41, Yuri ?????:
>>
>>
>>
>> 25.03.2018 20:32, Matus UHLAR - fantomas ?????:
>>>>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>>>>> The problem is not install proxy CA. The problem is identify client
>>>>>>> has no proxy CA and redirect, and do it only one time.
>>>>>
>>>>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>>>>> That is exactly the problem. And I have yet to find a solution
>>>>>> for that.
>>>>>>
>>>>>> Current method is instruct everyone - with a printed paper in the
>>>>>> office
>>>>>> - to connect to proxy.company-name.lan and then get further
>>>>>> instructions
>>>>>> from the page. This works, but an automatic splash page would be
>>>>>> more
>>>>>> elegant.
>>>
>>>> 25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>>>>> impossible and unsafe. The CA must be installed before such splash
>>>>> page shows
>>>
>>> On 25.03.18 18:44, Yuri wrote:
>>>> Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>>>> implemented already.
>>>
>>> it's possible to install splash page, but not install trusted authority
>>> certificate.? Using such authority on a proxy is the MITM attack and
>>> whole
>>> SSL has been designed to prevent this.
>> Heh. If SSL designed - why SSL Bump itself possible? ;):-P
>>>
>>> without certificate, the browser complains which is a security measure
>>> against this.
>> Sure. It should.
>>>
>>>>> up and in such case the splash page is irelevant.
>>>>>
>>>>> If you have windows domain, you can force security policy through it.
>>>
>>>> In enterprise environment with AD, yes. But hardly in service
>>>> provider's
>>>> scenarious.
>>>
>>> service providers should not do this without users' permission.
>>> at least not in countries where the privacy is guaranteed by law.
>> Thank you, Captain Obvious. :-) Enterprises also should get user
>> agreement before do that. Especially in BYOD scenarious.
>>
>> All these things are well known here. The question was about
>> technical implementation, and not about the well-known truisms in the
>> field of security and privacy (in most cases of ephemeral).
>>
>> -- 
>> "C++ seems like a language suitable for firing other people's legs."
>>
>> *****************************
>> * C++20 : Bug to the future *
>> *****************************
>
> -- 
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180325/d6b4b381/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180325/d6b4b381/attachment.sig>

From squid3 at treenet.co.nz  Sun Mar 25 20:45:16 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 26 Mar 2018 09:45:16 +1300
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
Message-ID: <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>

On 26/03/18 04:41, Yuri wrote:
> 
> 
> 25.03.2018 20:32, Matus UHLAR - fantomas ?????:
>>>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>>>> The problem is not install proxy CA. The problem is identify client
>>>>>> has no proxy CA and redirect, and do it only one time.
>>>>
>>>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>>>> That is exactly the problem. And I have yet to find a solution for
>>>>> that.
>>>>>
>>>>> Current method is instruct everyone - with a printed paper in the
>>>>> office
>>>>> - to connect to proxy.company-name.lan and then get further
>>>>> instructions
>>>>> from the page. This works, but an automatic splash page would be more
>>>>> elegant.
>>
>>> 25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>>>> impossible and unsafe. The CA must be installed before such splash
>>>> page shows
>>
>> On 25.03.18 18:44, Yuri wrote:
>>> Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>>> implemented already.
>>
>> it's possible to install splash page, but not install trusted authority
>> certificate.? Using such authority on a proxy is the MITM attack and
>> whole
>> SSL has been designed to prevent this.
> Heh. If SSL designed - why SSL Bump itself possible? ;):-P

As all our SSL-Bump documentation should be saying:

   when TLS is used properly SSL-Bump *does not work*.

A client checking the cert validity and producing _its own_ error page
about missing/unknown/untrusted CA is one of those cases. Since the
client is producing the "page" itself there is no possibility of Squid
replacing that with something else.

Amos


From yvoinov at gmail.com  Sun Mar 25 20:49:01 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 02:49:01 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
Message-ID: <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>



26.03.2018 02:45, Amos Jeffries ?????:
> On 26/03/18 04:41, Yuri wrote:
>>
>> 25.03.2018 20:32, Matus UHLAR - fantomas ?????:
>>>>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>>>>> The problem is not install proxy CA. The problem is identify client
>>>>>>> has no proxy CA and redirect, and do it only one time.
>>>>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>>>>> That is exactly the problem. And I have yet to find a solution for
>>>>>> that.
>>>>>>
>>>>>> Current method is instruct everyone - with a printed paper in the
>>>>>> office
>>>>>> - to connect to proxy.company-name.lan and then get further
>>>>>> instructions
>>>>>> from the page. This works, but an automatic splash page would be more
>>>>>> elegant.
>>>> 25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>>>>> impossible and unsafe. The CA must be installed before such splash
>>>>> page shows
>>> On 25.03.18 18:44, Yuri wrote:
>>>> Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>>>> implemented already.
>>> it's possible to install splash page, but not install trusted authority
>>> certificate.? Using such authority on a proxy is the MITM attack and
>>> whole
>>> SSL has been designed to prevent this.
>> Heh. If SSL designed - why SSL Bump itself possible? ;):-P
> As all our SSL-Bump documentation should be saying:
>
>    when TLS is used properly SSL-Bump *does not work*.
>
> A client checking the cert validity and producing _its own_ error page
> about missing/unknown/untrusted CA is one of those cases. Since the
> client is producing the "page" itself there is no possibility of Squid
> replacing that with something else.
Amos,

squid is irrelevant here. "Used properly" and "Implemented properly",
and, especially, "Designed properly" - which means "Secure by design",
like SSH or The Onion Router.

HTTPS is *NOT*.

Security should not be dependent from client/user behaviour. For
example, End-to-end security in IM. It is completely independent from user.

If HTTPS permits MiTM in theory and practice by any manner - it is
insecure by design. Point.

>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/2bd7988d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/2bd7988d/attachment.sig>

From squid3 at treenet.co.nz  Sun Mar 25 21:02:38 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 26 Mar 2018 10:02:38 +1300
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
Message-ID: <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>


On 26/03/18 09:49, Yuri wrote:
> 
> 
> 26.03.2018 02:45, Amos Jeffries ?????:
>> On 26/03/18 04:41, Yuri wrote:
>>>
>>> 25.03.2018 20:32, Matus UHLAR - fantomas ?????:
>>>>>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>>>>>> The problem is not install proxy CA. The problem is identify client
>>>>>>>> has no proxy CA and redirect, and do it only one time.
>>>>>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>>>>>> That is exactly the problem. And I have yet to find a solution for
>>>>>>> that.
>>>>>>>
>>>>>>> Current method is instruct everyone - with a printed paper in the
>>>>>>> office
>>>>>>> - to connect to proxy.company-name.lan and then get further
>>>>>>> instructions
>>>>>>> from the page. This works, but an automatic splash page would be more
>>>>>>> elegant.
>>>>> 25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>>>>>> impossible and unsafe. The CA must be installed before such splash
>>>>>> page shows
>>>> On 25.03.18 18:44, Yuri wrote:
>>>>> Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>>>>> implemented already.
>>>> it's possible to install splash page, but not install trusted authority
>>>> certificate.? Using such authority on a proxy is the MITM attack and
>>>> whole
>>>> SSL has been designed to prevent this.
>>> Heh. If SSL designed - why SSL Bump itself possible? ;):-P
>> As all our SSL-Bump documentation should be saying:
>>
>>    when TLS is used properly SSL-Bump *does not work*.
>>
>> A client checking the cert validity and producing _its own_ error page
>> about missing/unknown/untrusted CA is one of those cases. Since the
>> client is producing the "page" itself there is no possibility of Squid
>> replacing that with something else.
> Amos,
> 
> squid is irrelevant here. "Used properly" and "Implemented properly",
> and, especially, "Designed properly" - which means "Secure by design",
> like SSH or The Onion Router.
> 
> HTTPS is *NOT*.
> 

You are missing the point. Sometimes TLS *is* implemented properly.

Squid is very relevant here because it is the agent producing the
un-verifiable certificate. The certificate is un-verifiable exactly
because Squids own CA is being used and the client does not trust that CA.

Amos


From yvoinov at gmail.com  Sun Mar 25 21:16:49 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 03:16:49 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
Message-ID: <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>



26.03.2018 03:02, Amos Jeffries ?????:
> On 26/03/18 09:49, Yuri wrote:
>>
>> 26.03.2018 02:45, Amos Jeffries ?????:
>>> On 26/03/18 04:41, Yuri wrote:
>>>> 25.03.2018 20:32, Matus UHLAR - fantomas ?????:
>>>>>>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>>>>>>> The problem is not install proxy CA. The problem is identify client
>>>>>>>>> has no proxy CA and redirect, and do it only one time.
>>>>>>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>>>>>>> That is exactly the problem. And I have yet to find a solution for
>>>>>>>> that.
>>>>>>>>
>>>>>>>> Current method is instruct everyone - with a printed paper in the
>>>>>>>> office
>>>>>>>> - to connect to proxy.company-name.lan and then get further
>>>>>>>> instructions
>>>>>>>> from the page. This works, but an automatic splash page would be more
>>>>>>>> elegant.
>>>>>> 25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>>>>>>> impossible and unsafe. The CA must be installed before such splash
>>>>>>> page shows
>>>>> On 25.03.18 18:44, Yuri wrote:
>>>>>> Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>>>>>> implemented already.
>>>>> it's possible to install splash page, but not install trusted authority
>>>>> certificate.? Using such authority on a proxy is the MITM attack and
>>>>> whole
>>>>> SSL has been designed to prevent this.
>>>> Heh. If SSL designed - why SSL Bump itself possible? ;):-P
>>> As all our SSL-Bump documentation should be saying:
>>>
>>>    when TLS is used properly SSL-Bump *does not work*.
>>>
>>> A client checking the cert validity and producing _its own_ error page
>>> about missing/unknown/untrusted CA is one of those cases. Since the
>>> client is producing the "page" itself there is no possibility of Squid
>>> replacing that with something else.
>> Amos,
>>
>> squid is irrelevant here. "Used properly" and "Implemented properly",
>> and, especially, "Designed properly" - which means "Secure by design",
>> like SSH or The Onion Router.
>>
>> HTTPS is *NOT*.
>>
> You are missing the point. Sometimes TLS *is* implemented properly.
>
> Squid is very relevant here because it is the agent producing the
> un-verifiable certificate. The certificate is un-verifiable exactly
> because Squids own CA is being used and the client does not trust that CA.
Waaaaaaaa, Amos, why you say "unverifiable"? You can show CA to users,
they can see your PKI by eyes, check fingerprint, read your CPS ;)
Users, in this case, trust not NSA or any abstract CA issuer, but your
personally. Client can trust or do not trust you. But in case of far far
away What-due-call-am-CA client trust them by default. Why?

Can you do the same checks against, for example, Comodo, or DigiCert? I
think no. You forced to trust them in absentia. "We swear by my mother,
everything is safe with us!"

Do your remember Trustico story?

So, what is more secure? I am here or What-due-call-am-CA there?

The point is not technical. It is rather a matter of faith.

The Onion Router uses only self-signed in they infrastructure. We're
should not trust'em due to it CA's not signed by global "trusted" CA? It
makes TOR less secure?

The same case here. Security/insecurity is not a matter of technique.
This is a question of man. The car can carry, and can kill.

However, there is secure by design things. And there is insecure by
design things.

End-to-end encryption in IM is secure by design. HTTPS is not.
End-to-end you can't be easy break. HTTPS - just install third-party CA
into your PC! HTTPS permits it.

Squid here just tool. Which can be used for MiTM. Or can't. It's
independent from you. You just manufacture the car for me. I'll deside,
how it will be uses.

So, users will decide - if they trust me, or do not trust. Me, not
abstract remote CA.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/a0748973/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/a0748973/attachment.sig>

From squid3 at treenet.co.nz  Sun Mar 25 21:55:29 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 26 Mar 2018 10:55:29 +1300
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
Message-ID: <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>

On 26/03/18 10:16, Yuri wrote:
> 
> 
> 26.03.2018 03:02, Amos Jeffries ?????:
>> On 26/03/18 09:49, Yuri wrote:
>>>
>>> 26.03.2018 02:45, Amos Jeffries ?????:
>>>> On 26/03/18 04:41, Yuri wrote:
>>>>> 25.03.2018 20:32, Matus UHLAR - fantomas ?????:
>>>>>>>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>>>>>>>> The problem is not install proxy CA. The problem is identify client
>>>>>>>>>> has no proxy CA and redirect, and do it only one time.
>>>>>>>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>>>>>>>> That is exactly the problem. And I have yet to find a solution for
>>>>>>>>> that.
>>>>>>>>>
>>>>>>>>> Current method is instruct everyone - with a printed paper in the
>>>>>>>>> office
>>>>>>>>> - to connect to proxy.company-name.lan and then get further
>>>>>>>>> instructions
>>>>>>>>> from the page. This works, but an automatic splash page would be more
>>>>>>>>> elegant.
>>>>>>> 25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>>>>>>>> impossible and unsafe. The CA must be installed before such splash
>>>>>>>> page shows
>>>>>> On 25.03.18 18:44, Yuri wrote:
>>>>>>> Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>>>>>>> implemented already.
>>>>>> it's possible to install splash page, but not install trusted authority
>>>>>> certificate.? Using such authority on a proxy is the MITM attack and
>>>>>> whole
>>>>>> SSL has been designed to prevent this.
>>>>> Heh. If SSL designed - why SSL Bump itself possible? ;):-P
>>>> As all our SSL-Bump documentation should be saying:
>>>>
>>>>    when TLS is used properly SSL-Bump *does not work*.
>>>>
>>>> A client checking the cert validity and producing _its own_ error page
>>>> about missing/unknown/untrusted CA is one of those cases. Since the
>>>> client is producing the "page" itself there is no possibility of Squid
>>>> replacing that with something else.
>>> Amos,
>>>
>>> squid is irrelevant here. "Used properly" and "Implemented properly",
>>> and, especially, "Designed properly" - which means "Secure by design",
>>> like SSH or The Onion Router.
>>>
>>> HTTPS is *NOT*.
>>>
>> You are missing the point. Sometimes TLS *is* implemented properly.
>>
>> Squid is very relevant here because it is the agent producing the
>> un-verifiable certificate. The certificate is un-verifiable exactly
>> because Squids own CA is being used and the client does not trust that CA.
> Waaaaaaaa, Amos, why you say "unverifiable"? 

Because that is the situation. The client software cannot silently
verify the certificate nor automatically install the not-trusted CA to
cause that *previous* verification attempt to succeed.

> You can show CA to users,

Er, you are now going in circles.

The initial problem was that it is not possible to verify the cert
automatically *without* showing the user things. Requiring the user to
see something to get around that problem ...

Amos


From yvoinov at gmail.com  Sun Mar 25 22:03:12 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 04:03:12 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
Message-ID: <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>



26.03.2018 03:55, Amos Jeffries ?????:
> On 26/03/18 10:16, Yuri wrote:
>>
>> 26.03.2018 03:02, Amos Jeffries ?????:
>>> On 26/03/18 09:49, Yuri wrote:
>>>> 26.03.2018 02:45, Amos Jeffries ?????:
>>>>> On 26/03/18 04:41, Yuri wrote:
>>>>>> 25.03.2018 20:32, Matus UHLAR - fantomas ?????:
>>>>>>>>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>>>>>>>>> The problem is not install proxy CA. The problem is identify client
>>>>>>>>>>> has no proxy CA and redirect, and do it only one time.
>>>>>>>>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>>>>>>>>> That is exactly the problem. And I have yet to find a solution for
>>>>>>>>>> that.
>>>>>>>>>>
>>>>>>>>>> Current method is instruct everyone - with a printed paper in the
>>>>>>>>>> office
>>>>>>>>>> - to connect to proxy.company-name.lan and then get further
>>>>>>>>>> instructions
>>>>>>>>>> from the page. This works, but an automatic splash page would be more
>>>>>>>>>> elegant.
>>>>>>>> 25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>>>>>>>>> impossible and unsafe. The CA must be installed before such splash
>>>>>>>>> page shows
>>>>>>> On 25.03.18 18:44, Yuri wrote:
>>>>>>>> Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>>>>>>>> implemented already.
>>>>>>> it's possible to install splash page, but not install trusted authority
>>>>>>> certificate.? Using such authority on a proxy is the MITM attack and
>>>>>>> whole
>>>>>>> SSL has been designed to prevent this.
>>>>>> Heh. If SSL designed - why SSL Bump itself possible? ;):-P
>>>>> As all our SSL-Bump documentation should be saying:
>>>>>
>>>>>    when TLS is used properly SSL-Bump *does not work*.
>>>>>
>>>>> A client checking the cert validity and producing _its own_ error page
>>>>> about missing/unknown/untrusted CA is one of those cases. Since the
>>>>> client is producing the "page" itself there is no possibility of Squid
>>>>> replacing that with something else.
>>>> Amos,
>>>>
>>>> squid is irrelevant here. "Used properly" and "Implemented properly",
>>>> and, especially, "Designed properly" - which means "Secure by design",
>>>> like SSH or The Onion Router.
>>>>
>>>> HTTPS is *NOT*.
>>>>
>>> You are missing the point. Sometimes TLS *is* implemented properly.
>>>
>>> Squid is very relevant here because it is the agent producing the
>>> un-verifiable certificate. The certificate is un-verifiable exactly
>>> because Squids own CA is being used and the client does not trust that CA.
>> Waaaaaaaa, Amos, why you say "unverifiable"? 
> Because that is the situation. The client software cannot silently
> verify the certificate nor automatically install the not-trusted CA to
> cause that *previous* verification attempt to succeed.
Sure. User always should:

a) Have root/administrative privilegies to install any CA in trusted
store on client
b) Device always asks users "Hey, somebody tries to install CA with
fingerprint blah-blah-blah.... you trust them? Install? (Yes/No)"

We're not talking about forced silently push proxy CA to client, right?
>
>> You can show CA to users,
> Er, you are now going in circles.
>
> The initial problem was that it is not possible to verify the cert
> automatically *without* showing the user things. Requiring the user to
> see something to get around that problem ...
Yes. We're want just to determine - is proxy CA installed? and if not,
redirect user to page to make desicion - install/not install. Get
internet/remain locally ;)
On this page we're can inform user about all require things: our CPS,
our privacy policy, warnings, legal issues, CA fingerprint, CA issuer
etc. ;)

This seems better? All same like adult CA does :)

We're all understand we're can't silently push any CA to client ;) This
is illegal, technically impossible, insecure....... ;)
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/f7607c7b/attachment.sig>

From yvoinov at gmail.com  Sun Mar 25 22:05:26 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 04:05:26 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
Message-ID: <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>

And yes, HTTPS is insecure by design and all our actions does not it
less insecure :-D


26.03.2018 04:03, Yuri ?????:
>
> 26.03.2018 03:55, Amos Jeffries ?????:
>> On 26/03/18 10:16, Yuri wrote:
>>> 26.03.2018 03:02, Amos Jeffries ?????:
>>>> On 26/03/18 09:49, Yuri wrote:
>>>>> 26.03.2018 02:45, Amos Jeffries ?????:
>>>>>> On 26/03/18 04:41, Yuri wrote:
>>>>>>> 25.03.2018 20:32, Matus UHLAR - fantomas ?????:
>>>>>>>>>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>>>>>>>>>> The problem is not install proxy CA. The problem is identify client
>>>>>>>>>>>> has no proxy CA and redirect, and do it only one time.
>>>>>>>>>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>>>>>>>>>> That is exactly the problem. And I have yet to find a solution for
>>>>>>>>>>> that.
>>>>>>>>>>>
>>>>>>>>>>> Current method is instruct everyone - with a printed paper in the
>>>>>>>>>>> office
>>>>>>>>>>> - to connect to proxy.company-name.lan and then get further
>>>>>>>>>>> instructions
>>>>>>>>>>> from the page. This works, but an automatic splash page would be more
>>>>>>>>>>> elegant.
>>>>>>>>> 25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>>>>>>>>>> impossible and unsafe. The CA must be installed before such splash
>>>>>>>>>> page shows
>>>>>>>> On 25.03.18 18:44, Yuri wrote:
>>>>>>>>> Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>>>>>>>>> implemented already.
>>>>>>>> it's possible to install splash page, but not install trusted authority
>>>>>>>> certificate.? Using such authority on a proxy is the MITM attack and
>>>>>>>> whole
>>>>>>>> SSL has been designed to prevent this.
>>>>>>> Heh. If SSL designed - why SSL Bump itself possible? ;):-P
>>>>>> As all our SSL-Bump documentation should be saying:
>>>>>>
>>>>>>    when TLS is used properly SSL-Bump *does not work*.
>>>>>>
>>>>>> A client checking the cert validity and producing _its own_ error page
>>>>>> about missing/unknown/untrusted CA is one of those cases. Since the
>>>>>> client is producing the "page" itself there is no possibility of Squid
>>>>>> replacing that with something else.
>>>>> Amos,
>>>>>
>>>>> squid is irrelevant here. "Used properly" and "Implemented properly",
>>>>> and, especially, "Designed properly" - which means "Secure by design",
>>>>> like SSH or The Onion Router.
>>>>>
>>>>> HTTPS is *NOT*.
>>>>>
>>>> You are missing the point. Sometimes TLS *is* implemented properly.
>>>>
>>>> Squid is very relevant here because it is the agent producing the
>>>> un-verifiable certificate. The certificate is un-verifiable exactly
>>>> because Squids own CA is being used and the client does not trust that CA.
>>> Waaaaaaaa, Amos, why you say "unverifiable"? 
>> Because that is the situation. The client software cannot silently
>> verify the certificate nor automatically install the not-trusted CA to
>> cause that *previous* verification attempt to succeed.
> Sure. User always should:
>
> a) Have root/administrative privilegies to install any CA in trusted
> store on client
> b) Device always asks users "Hey, somebody tries to install CA with
> fingerprint blah-blah-blah.... you trust them? Install? (Yes/No)"
>
> We're not talking about forced silently push proxy CA to client, right?
>>> You can show CA to users,
>> Er, you are now going in circles.
>>
>> The initial problem was that it is not possible to verify the cert
>> automatically *without* showing the user things. Requiring the user to
>> see something to get around that problem ...
> Yes. We're want just to determine - is proxy CA installed? and if not,
> redirect user to page to make desicion - install/not install. Get
> internet/remain locally ;)
> On this page we're can inform user about all require things: our CPS,
> our privacy policy, warnings, legal issues, CA fingerprint, CA issuer
> etc. ;)
>
> This seems better? All same like adult CA does :)
>
> We're all understand we're can't silently push any CA to client ;) This
> is illegal, technically impossible, insecure....... ;)
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/2e46c56c/attachment.sig>

From yvoinov at gmail.com  Sun Mar 25 22:11:12 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 04:11:12 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
Message-ID: <57cab373-2a9b-d1fc-c3e5-e34558303b47@gmail.com>

By the way, Amos. I have an idea spinning around. Is it possible to
specify the SSL error of the unknown certificate issuer for the correct
processing of the situation when the client does not have a proxy
certificate installed? This would greatly facilitate the task that we
are discussing.

We're can, in this case, just use deny_info to redirect client to proxy
page. ;-)


26.03.2018 04:05, Yuri ?????:
> And yes, HTTPS is insecure by design and all our actions does not it
> less insecure :-D
>
>
> 26.03.2018 04:03, Yuri ?????:
>> 26.03.2018 03:55, Amos Jeffries ?????:
>>> On 26/03/18 10:16, Yuri wrote:
>>>> 26.03.2018 03:02, Amos Jeffries ?????:
>>>>> On 26/03/18 09:49, Yuri wrote:
>>>>>> 26.03.2018 02:45, Amos Jeffries ?????:
>>>>>>> On 26/03/18 04:41, Yuri wrote:
>>>>>>>> 25.03.2018 20:32, Matus UHLAR - fantomas ?????:
>>>>>>>>>>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>>>>>>>>>>> The problem is not install proxy CA. The problem is identify client
>>>>>>>>>>>>> has no proxy CA and redirect, and do it only one time.
>>>>>>>>>>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>>>>>>>>>>> That is exactly the problem. And I have yet to find a solution for
>>>>>>>>>>>> that.
>>>>>>>>>>>>
>>>>>>>>>>>> Current method is instruct everyone - with a printed paper in the
>>>>>>>>>>>> office
>>>>>>>>>>>> - to connect to proxy.company-name.lan and then get further
>>>>>>>>>>>> instructions
>>>>>>>>>>>> from the page. This works, but an automatic splash page would be more
>>>>>>>>>>>> elegant.
>>>>>>>>>> 25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>>>>>>>>>>> impossible and unsafe. The CA must be installed before such splash
>>>>>>>>>>> page shows
>>>>>>>>> On 25.03.18 18:44, Yuri wrote:
>>>>>>>>>> Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>>>>>>>>>> implemented already.
>>>>>>>>> it's possible to install splash page, but not install trusted authority
>>>>>>>>> certificate.? Using such authority on a proxy is the MITM attack and
>>>>>>>>> whole
>>>>>>>>> SSL has been designed to prevent this.
>>>>>>>> Heh. If SSL designed - why SSL Bump itself possible? ;):-P
>>>>>>> As all our SSL-Bump documentation should be saying:
>>>>>>>
>>>>>>>    when TLS is used properly SSL-Bump *does not work*.
>>>>>>>
>>>>>>> A client checking the cert validity and producing _its own_ error page
>>>>>>> about missing/unknown/untrusted CA is one of those cases. Since the
>>>>>>> client is producing the "page" itself there is no possibility of Squid
>>>>>>> replacing that with something else.
>>>>>> Amos,
>>>>>>
>>>>>> squid is irrelevant here. "Used properly" and "Implemented properly",
>>>>>> and, especially, "Designed properly" - which means "Secure by design",
>>>>>> like SSH or The Onion Router.
>>>>>>
>>>>>> HTTPS is *NOT*.
>>>>>>
>>>>> You are missing the point. Sometimes TLS *is* implemented properly.
>>>>>
>>>>> Squid is very relevant here because it is the agent producing the
>>>>> un-verifiable certificate. The certificate is un-verifiable exactly
>>>>> because Squids own CA is being used and the client does not trust that CA.
>>>> Waaaaaaaa, Amos, why you say "unverifiable"? 
>>> Because that is the situation. The client software cannot silently
>>> verify the certificate nor automatically install the not-trusted CA to
>>> cause that *previous* verification attempt to succeed.
>> Sure. User always should:
>>
>> a) Have root/administrative privilegies to install any CA in trusted
>> store on client
>> b) Device always asks users "Hey, somebody tries to install CA with
>> fingerprint blah-blah-blah.... you trust them? Install? (Yes/No)"
>>
>> We're not talking about forced silently push proxy CA to client, right?
>>>> You can show CA to users,
>>> Er, you are now going in circles.
>>>
>>> The initial problem was that it is not possible to verify the cert
>>> automatically *without* showing the user things. Requiring the user to
>>> see something to get around that problem ...
>> Yes. We're want just to determine - is proxy CA installed? and if not,
>> redirect user to page to make desicion - install/not install. Get
>> internet/remain locally ;)
>> On this page we're can inform user about all require things: our CPS,
>> our privacy policy, warnings, legal issues, CA fingerprint, CA issuer
>> etc. ;)
>>
>> This seems better? All same like adult CA does :)
>>
>> We're all understand we're can't silently push any CA to client ;) This
>> is illegal, technically impossible, insecure....... ;)
>>> Amos
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/291d49e6/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/291d49e6/attachment.sig>

From yvoinov at gmail.com  Sun Mar 25 22:15:15 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 04:15:15 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <57cab373-2a9b-d1fc-c3e5-e34558303b47@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
 <57cab373-2a9b-d1fc-c3e5-e34558303b47@gmail.com>
Message-ID: <b8ff74b8-fa34-883c-2d5e-9b90d3be4e79@gmail.com>

I mean, for example:

SSL_ERROR_CLIENT_DOES_NOT_KNOW_THIS_CA

during TLS negotiation between client and proxy.

To be separated from rare cases when real world CA exists, but not yet
included to well-known CA's bundle.

Something like this. Now we're can't differentiate UNKNOWN_ISSUES error
- it is external or internal issue.


26.03.2018 04:11, Yuri ?????:
>
> By the way, Amos. I have an idea spinning around. Is it possible to
> specify the SSL error of the unknown certificate issuer for the
> correct processing of the situation when the client does not have a
> proxy certificate installed? This would greatly facilitate the task
> that we are discussing.
>
> We're can, in this case, just use deny_info to redirect client to
> proxy page. ;-)
>
>
> 26.03.2018 04:05, Yuri ?????:
>> And yes, HTTPS is insecure by design and all our actions does not it
>> less insecure :-D
>>
>>
>> 26.03.2018 04:03, Yuri ?????:
>>> 26.03.2018 03:55, Amos Jeffries ?????:
>>>> On 26/03/18 10:16, Yuri wrote:
>>>>> 26.03.2018 03:02, Amos Jeffries ?????:
>>>>>> On 26/03/18 09:49, Yuri wrote:
>>>>>>> 26.03.2018 02:45, Amos Jeffries ?????:
>>>>>>>> On 26/03/18 04:41, Yuri wrote:
>>>>>>>>> 25.03.2018 20:32, Matus UHLAR - fantomas ?????:
>>>>>>>>>>>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>>>>>>>>>>>> The problem is not install proxy CA. The problem is identify client
>>>>>>>>>>>>>> has no proxy CA and redirect, and do it only one time.
>>>>>>>>>>>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>>>>>>>>>>>> That is exactly the problem. And I have yet to find a solution for
>>>>>>>>>>>>> that.
>>>>>>>>>>>>>
>>>>>>>>>>>>> Current method is instruct everyone - with a printed paper in the
>>>>>>>>>>>>> office
>>>>>>>>>>>>> - to connect to proxy.company-name.lan and then get further
>>>>>>>>>>>>> instructions
>>>>>>>>>>>>> from the page. This works, but an automatic splash page would be more
>>>>>>>>>>>>> elegant.
>>>>>>>>>>> 25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>>>>>>>>>>>> impossible and unsafe. The CA must be installed before such splash
>>>>>>>>>>>> page shows
>>>>>>>>>> On 25.03.18 18:44, Yuri wrote:
>>>>>>>>>>> Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>>>>>>>>>>> implemented already.
>>>>>>>>>> it's possible to install splash page, but not install trusted authority
>>>>>>>>>> certificate.? Using such authority on a proxy is the MITM attack and
>>>>>>>>>> whole
>>>>>>>>>> SSL has been designed to prevent this.
>>>>>>>>> Heh. If SSL designed - why SSL Bump itself possible? ;):-P
>>>>>>>> As all our SSL-Bump documentation should be saying:
>>>>>>>>
>>>>>>>>    when TLS is used properly SSL-Bump *does not work*.
>>>>>>>>
>>>>>>>> A client checking the cert validity and producing _its own_ error page
>>>>>>>> about missing/unknown/untrusted CA is one of those cases. Since the
>>>>>>>> client is producing the "page" itself there is no possibility of Squid
>>>>>>>> replacing that with something else.
>>>>>>> Amos,
>>>>>>>
>>>>>>> squid is irrelevant here. "Used properly" and "Implemented properly",
>>>>>>> and, especially, "Designed properly" - which means "Secure by design",
>>>>>>> like SSH or The Onion Router.
>>>>>>>
>>>>>>> HTTPS is *NOT*.
>>>>>>>
>>>>>> You are missing the point. Sometimes TLS *is* implemented properly.
>>>>>>
>>>>>> Squid is very relevant here because it is the agent producing the
>>>>>> un-verifiable certificate. The certificate is un-verifiable exactly
>>>>>> because Squids own CA is being used and the client does not trust that CA.
>>>>> Waaaaaaaa, Amos, why you say "unverifiable"? 
>>>> Because that is the situation. The client software cannot silently
>>>> verify the certificate nor automatically install the not-trusted CA to
>>>> cause that *previous* verification attempt to succeed.
>>> Sure. User always should:
>>>
>>> a) Have root/administrative privilegies to install any CA in trusted
>>> store on client
>>> b) Device always asks users "Hey, somebody tries to install CA with
>>> fingerprint blah-blah-blah.... you trust them? Install? (Yes/No)"
>>>
>>> We're not talking about forced silently push proxy CA to client, right?
>>>>> You can show CA to users,
>>>> Er, you are now going in circles.
>>>>
>>>> The initial problem was that it is not possible to verify the cert
>>>> automatically *without* showing the user things. Requiring the user to
>>>> see something to get around that problem ...
>>> Yes. We're want just to determine - is proxy CA installed? and if not,
>>> redirect user to page to make desicion - install/not install. Get
>>> internet/remain locally ;)
>>> On this page we're can inform user about all require things: our CPS,
>>> our privacy policy, warnings, legal issues, CA fingerprint, CA issuer
>>> etc. ;)
>>>
>>> This seems better? All same like adult CA does :)
>>>
>>> We're all understand we're can't silently push any CA to client ;) This
>>> is illegal, technically impossible, insecure....... ;)
>>>> Amos
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>
> -- 
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/c1bd021b/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/c1bd021b/attachment.sig>

From squid3 at treenet.co.nz  Sun Mar 25 23:05:33 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 26 Mar 2018 12:05:33 +1300
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
Message-ID: <1b6f8ff8-1a07-0768-5b7c-692635d357e9@treenet.co.nz>

On 26/03/18 11:05, Yuri wrote:
> And yes, HTTPS is insecure by design and all our actions does not it
> less insecure :-D

We are not talking about HTTPS. Only about TLS. Because the TLS decrypt
is what is "failing" at the time any of these details we are discussing
are relevant.

The "page" mentioned is HTML created by the _client_ as its way to show
the user things. Still no HTTP(S) involvement. Squid has zero
involvement with that so cannot make it do anything active (like install
CA certs).

Amos


From yvoinov at gmail.com  Sun Mar 25 23:07:29 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 05:07:29 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <1b6f8ff8-1a07-0768-5b7c-692635d357e9@treenet.co.nz>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
 <1b6f8ff8-1a07-0768-5b7c-692635d357e9@treenet.co.nz>
Message-ID: <c1266cf7-94fc-caf5-fb3e-088d705a0de9@gmail.com>



26.03.2018 05:05, Amos Jeffries ?????:
> On 26/03/18 11:05, Yuri wrote:
>> And yes, HTTPS is insecure by design and all our actions does not it
>> less insecure :-D
> We are not talking about HTTPS. Only about TLS. Because the TLS decrypt
> is what is "failing" at the time any of these details we are discussing
> are relevant.
>
> The "page" mentioned is HTML created by the _client_ as its way to show
> the user things. Still no HTTP(S) involvement. Squid has zero
> involvement with that so cannot make it do anything active (like install
> CA certs).
Exactly. Users do. And we're almost have all required tools to implement
user'driven helper ;)
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/f8df4274/attachment.sig>

From squid3 at treenet.co.nz  Sun Mar 25 23:09:30 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 26 Mar 2018 12:09:30 +1300
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <57cab373-2a9b-d1fc-c3e5-e34558303b47@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
 <57cab373-2a9b-d1fc-c3e5-e34558303b47@gmail.com>
Message-ID: <166e7e3a-f50d-88a6-d6c8-44f7358f352a@treenet.co.nz>

On 26/03/18 11:11, Yuri wrote:
> By the way, Amos. I have an idea spinning around. Is it possible to
> specify the SSL error of the unknown certificate issuer for the correct
> processing of the situation when the client does not have a proxy
> certificate installed? This would greatly facilitate the task that we
> are discussing.
> 
> We're can, in this case, just use deny_info to redirect client to proxy
> page. ;-)
> 

"error of the unknown issuer" is an implementation detail of the SSL/TLS
library used by the client-end software.

Is that clear enough about why Squid cannot do anything?


Squid can change the cert issuer from X to A or X to Y. But cannot make
any specific issuer A or Y known when it is not already known** by the
client.


** intermediate certs that can be D/L by the client can be considered
"known" when (and only when) their root CA is already trusted. Unless
the client does not download missing intermediates.

Amos


From squid3 at treenet.co.nz  Sun Mar 25 23:14:13 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 26 Mar 2018 12:14:13 +1300
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <b8ff74b8-fa34-883c-2d5e-9b90d3be4e79@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
 <57cab373-2a9b-d1fc-c3e5-e34558303b47@gmail.com>
 <b8ff74b8-fa34-883c-2d5e-9b90d3be4e79@gmail.com>
Message-ID: <687289a0-5d81-df57-d3ff-5f119b69697a@treenet.co.nz>

On 26/03/18 11:15, Yuri wrote:
> I mean, for example:
> 
> SSL_ERROR_CLIENT_DOES_NOT_KNOW_THIS_CA
> 

Consider carefully what the words "CLIENT_DOES_NOT_KNOW_THIS_CA" mean in
normal English.


Amos


From yvoinov at gmail.com  Sun Mar 25 23:18:15 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 05:18:15 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <687289a0-5d81-df57-d3ff-5f119b69697a@treenet.co.nz>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
 <57cab373-2a9b-d1fc-c3e5-e34558303b47@gmail.com>
 <b8ff74b8-fa34-883c-2d5e-9b90d3be4e79@gmail.com>
 <687289a0-5d81-df57-d3ff-5f119b69697a@treenet.co.nz>
Message-ID: <c2a69106-a04c-68a5-0c68-7f19f8a1c32d@gmail.com>

Waaaaaaaaaa. You're right. I hurried.

Hmmmmmm.

Seems we're can't distinguish unknown server CA and unknown proxy CA.

Sadly.

26.03.2018 05:14, Amos Jeffries ?????:
> On 26/03/18 11:15, Yuri wrote:
>> I mean, for example:
>>
>> SSL_ERROR_CLIENT_DOES_NOT_KNOW_THIS_CA
>>
> Consider carefully what the words "CLIENT_DOES_NOT_KNOW_THIS_CA" mean in
> normal English.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/61a40825/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/61a40825/attachment.sig>

From squid3 at treenet.co.nz  Sun Mar 25 23:23:04 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 26 Mar 2018 12:23:04 +1300
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <c1266cf7-94fc-caf5-fb3e-088d705a0de9@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
 <1b6f8ff8-1a07-0768-5b7c-692635d357e9@treenet.co.nz>
 <c1266cf7-94fc-caf5-fb3e-088d705a0de9@gmail.com>
Message-ID: <88b9fe1e-0340-d99a-ac2b-b2938c793944@treenet.co.nz>

On 26/03/18 12:07, Yuri wrote:
> 
> 26.03.2018 05:05, Amos Jeffries ?????:
>> On 26/03/18 11:05, Yuri wrote:
>>> And yes, HTTPS is insecure by design and all our actions does not it
>>> less insecure :-D
>> We are not talking about HTTPS. Only about TLS. Because the TLS decrypt
>> is what is "failing" at the time any of these details we are discussing
>> are relevant.
>>
>> The "page" mentioned is HTML created by the _client_ as its way to show
>> the user things. Still no HTTP(S) involvement. Squid has zero
>> involvement with that so cannot make it do anything active (like install
>> CA certs).
> Exactly. Users do. And we're almost have all required tools to implement
> user'driven helper ;)

Yet again you are circled back to involving the user. Remember the
original point was trying to do things *without any user* knowing or
being involved.


This is what I mean by "TLS used properly" - proper is when it always
circles back to user deciding who they trust. No matter how indirectly,
the user installs a (root) CA causing trust or allowed someone else to
do so.

Amos


From yvoinov at gmail.com  Sun Mar 25 23:34:39 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 05:34:39 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <88b9fe1e-0340-d99a-ac2b-b2938c793944@treenet.co.nz>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
 <1b6f8ff8-1a07-0768-5b7c-692635d357e9@treenet.co.nz>
 <c1266cf7-94fc-caf5-fb3e-088d705a0de9@gmail.com>
 <88b9fe1e-0340-d99a-ac2b-b2938c793944@treenet.co.nz>
Message-ID: <7be514f0-756d-a680-138c-5f8f3bbd9af0@gmail.com>



26.03.2018 05:23, Amos Jeffries ?????:
> On 26/03/18 12:07, Yuri wrote:
>> 26.03.2018 05:05, Amos Jeffries ?????:
>>> On 26/03/18 11:05, Yuri wrote:
>>>> And yes, HTTPS is insecure by design and all our actions does not it
>>>> less insecure :-D
>>> We are not talking about HTTPS. Only about TLS. Because the TLS decrypt
>>> is what is "failing" at the time any of these details we are discussing
>>> are relevant.
>>>
>>> The "page" mentioned is HTML created by the _client_ as its way to show
>>> the user things. Still no HTTP(S) involvement. Squid has zero
>>> involvement with that so cannot make it do anything active (like install
>>> CA certs).
>> Exactly. Users do. And we're almost have all required tools to implement
>> user'driven helper ;)
> Yet again you are circled back to involving the user. Remember the
> original point was trying to do things *without any user* knowing or
> being involved.
I could not make such a stupid idea. It does not work out that way. The
user is always asked whether trust the installing CA certificate.

The only way known for me to make this silently - using AD group policy.

AFAIK, we're discussing usual way with catch error and redirect to page.
No more. Captive Portal, Splash, ACL etc.

>
>
> This is what I mean by "TLS used properly" - proper is when it always
> circles back to user deciding who they trust. No matter how indirectly,
> the user installs a (root) CA causing trust or allowed someone else to
> do so.
Generally speaking, yes.

I just mean, that in some other protocols you have no any possibility to
make MiTM by any way, whenever installing something or not. This
prevents any improper or malicious use of protocol.

TLS*have* this possibility. SSH is *not*. You can't MiTM or compromise
SSH by installing any key/certs to client. Correct? This is by design?

> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/4e5fa677/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/4e5fa677/attachment.sig>

From squid3 at treenet.co.nz  Mon Mar 26 00:30:19 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 26 Mar 2018 13:30:19 +1300
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <7be514f0-756d-a680-138c-5f8f3bbd9af0@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
 <1b6f8ff8-1a07-0768-5b7c-692635d357e9@treenet.co.nz>
 <c1266cf7-94fc-caf5-fb3e-088d705a0de9@gmail.com>
 <88b9fe1e-0340-d99a-ac2b-b2938c793944@treenet.co.nz>
 <7be514f0-756d-a680-138c-5f8f3bbd9af0@gmail.com>
Message-ID: <6df8e33d-85a5-37e7-7938-cb3eec515f1f@treenet.co.nz>

On 26/03/18 12:34, Yuri wrote:
> 
> 26.03.2018 05:23, Amos Jeffries ?????:
>> On 26/03/18 12:07, Yuri wrote:
>>> 26.03.2018 05:05, Amos Jeffries ?????:
>>>> On 26/03/18 11:05, Yuri wrote:
>>>>> And yes, HTTPS is insecure by design and all our actions does not it
>>>>> less insecure :-D
>>>> We are not talking about HTTPS. Only about TLS. Because the TLS decrypt
>>>> is what is "failing" at the time any of these details we are discussing
>>>> are relevant.
>>>>
>>>> The "page" mentioned is HTML created by the _client_ as its way to show
>>>> the user things. Still no HTTP(S) involvement. Squid has zero
>>>> involvement with that so cannot make it do anything active (like install
>>>> CA certs).
>>> Exactly. Users do. And we're almost have all required tools to implement
>>> user'driven helper ;)
>> Yet again you are circled back to involving the user. Remember the
>> original point was trying to do things *without any user* knowing or
>> being involved.
> I could not make such a stupid idea. It does not work out that way. The
> user is always asked whether trust the installing CA certificate.

"
On 17/03/18 01:43, Yuri wrote:
> I guess better way to do this is create special ACL to catch exactly
> certificate error and then redirect by 302 using deny_info to proxy page
> with explanation and certificate.

"

The mistake here was thinking the error was something Squid could see or
detect. It is not.


> 
> The only way known for me to make this silently - using AD group policy.
> 
> AFAIK, we're discussing usual way with catch error and redirect to page.
> No more. Captive Portal, Splash, ACL etc.
> 

In order to deliver that splash page or redirect requires the client to
trust the proxy CA and decrypt the proxy HTTPS response.

BUT, the problem Nicolas had in the first place was the client not
trusting the proxy CA and displaying a page of its own:

"
On 16/03/18 23:37, Nicolas Kovacs wrote:
> User who don't have the certificate installed
> normally get a big fat HTTPS error as soon as they connect
"

The idea proposed to replace the client-created page was to send a
custom one from the proxy. Which is a circle.




On 26/03/18 12:34, Yuri wrote:>
> 26.03.2018 05:23, Amos Jeffries ?????:
>>
>> This is what I mean by "TLS used properly" - proper is when it always
>> circles back to user deciding who they trust. No matter how indirectly,
>> the user installs a (root) CA causing trust or allowed someone else to
>> do so.
> Generally speaking, yes.
> 
> I just mean, that in some other protocols you have no any possibility to
> make MiTM by any way, whenever installing something or not. This
> prevents any improper or malicious use of protocol.
> 
> TLS*have* this possibility. SSH is *not*. You can't MiTM or compromise
> SSH by installing any key/certs to client. Correct? This is by design?

No. SSH is just TCP/telnet over TLS. So if the SSH software were to
trust the cert/key Squid delivers one could use SSL-Bump on that SSH
traffic.

The on_unsupported_protocol feature is for exactly this non-HTTP traffic
to be bumped (and rejected) or spliced by Squid.

NP: The only thing protecting SSH against SSL-Bump is that servers there
are *supposed* to check client certs as well as the server certs being
checked by clients. The bi-directional checking breaks bumping.

Amos


From yvoinov at gmail.com  Mon Mar 26 00:41:12 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 06:41:12 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <6df8e33d-85a5-37e7-7938-cb3eec515f1f@treenet.co.nz>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
 <1b6f8ff8-1a07-0768-5b7c-692635d357e9@treenet.co.nz>
 <c1266cf7-94fc-caf5-fb3e-088d705a0de9@gmail.com>
 <88b9fe1e-0340-d99a-ac2b-b2938c793944@treenet.co.nz>
 <7be514f0-756d-a680-138c-5f8f3bbd9af0@gmail.com>
 <6df8e33d-85a5-37e7-7938-cb3eec515f1f@treenet.co.nz>
Message-ID: <791409df-944c-ef6d-fda7-30a335f77c69@gmail.com>



26.03.2018 06:30, Amos Jeffries ?????:
> On 26/03/18 12:34, Yuri wrote:
>> 26.03.2018 05:23, Amos Jeffries ?????:
>>> On 26/03/18 12:07, Yuri wrote:
>>>> 26.03.2018 05:05, Amos Jeffries ?????:
>>>>> On 26/03/18 11:05, Yuri wrote:
>>>>>> And yes, HTTPS is insecure by design and all our actions does not it
>>>>>> less insecure :-D
>>>>> We are not talking about HTTPS. Only about TLS. Because the TLS decrypt
>>>>> is what is "failing" at the time any of these details we are discussing
>>>>> are relevant.
>>>>>
>>>>> The "page" mentioned is HTML created by the _client_ as its way to show
>>>>> the user things. Still no HTTP(S) involvement. Squid has zero
>>>>> involvement with that so cannot make it do anything active (like install
>>>>> CA certs).
>>>> Exactly. Users do. And we're almost have all required tools to implement
>>>> user'driven helper ;)
>>> Yet again you are circled back to involving the user. Remember the
>>> original point was trying to do things *without any user* knowing or
>>> being involved.
>> I could not make such a stupid idea. It does not work out that way. The
>> user is always asked whether trust the installing CA certificate.
> "
> On 17/03/18 01:43, Yuri wrote:
>> I guess better way to do this is create special ACL to catch exactly
>> certificate error and then redirect by 302 using deny_info to proxy page
>> with explanation and certificate.
> "
>
> The mistake here was thinking the error was something Squid could see or
> detect. It is not.
>
>
>> The only way known for me to make this silently - using AD group policy.
>>
>> AFAIK, we're discussing usual way with catch error and redirect to page.
>> No more. Captive Portal, Splash, ACL etc.
>>
> In order to deliver that splash page or redirect requires the client to
> trust the proxy CA and decrypt the proxy HTTPS response.
>
> BUT, the problem Nicolas had in the first place was the client not
> trusting the proxy CA and displaying a page of its own:
>
> "
> On 16/03/18 23:37, Nicolas Kovacs wrote:
>> User who don't have the certificate installed
>> normally get a big fat HTTPS error as soon as they connect
> "
>
> The idea proposed to replace the client-created page was to send a
> custom one from the proxy. Which is a circle.
My bad. Miss it. So obvious thing for me.
>
>
>
>
> On 26/03/18 12:34, Yuri wrote:>
>> 26.03.2018 05:23, Amos Jeffries ?????:
>>> This is what I mean by "TLS used properly" - proper is when it always
>>> circles back to user deciding who they trust. No matter how indirectly,
>>> the user installs a (root) CA causing trust or allowed someone else to
>>> do so.
>> Generally speaking, yes.
>>
>> I just mean, that in some other protocols you have no any possibility to
>> make MiTM by any way, whenever installing something or not. This
>> prevents any improper or malicious use of protocol.
>>
>> TLS*have* this possibility. SSH is *not*. You can't MiTM or compromise
>> SSH by installing any key/certs to client. Correct? This is by design?
> No. SSH is just TCP/telnet over TLS. So if the SSH software were to
> trust the cert/key Squid delivers one could use SSL-Bump on that SSH
> traffic.
You sure?

https://stackoverflow.com/questions/723152/difference-between-ssh-and-ssl-especially-in-terms-of-sftp-vs-ftp-over-ssl

Quote: "SSH has its own transport protocol independent from SSL, so that
means SSH DOES NOT use SSL under the hood."

Because I'm not. Different sources tells opposite.
>
> The on_unsupported_protocol feature is for exactly this non-HTTP traffic
> to be bumped (and rejected) or spliced by Squid.
>
> NP: The only thing protecting SSH against SSL-Bump is that servers there
> are *supposed* to check client certs as well as the server certs being
> checked by clients. The bi-directional checking breaks bumping.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/be9b281d/attachment.sig>

From yvoinov at gmail.com  Mon Mar 26 00:44:18 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 06:44:18 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <791409df-944c-ef6d-fda7-30a335f77c69@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
 <1b6f8ff8-1a07-0768-5b7c-692635d357e9@treenet.co.nz>
 <c1266cf7-94fc-caf5-fb3e-088d705a0de9@gmail.com>
 <88b9fe1e-0340-d99a-ac2b-b2938c793944@treenet.co.nz>
 <7be514f0-756d-a680-138c-5f8f3bbd9af0@gmail.com>
 <6df8e33d-85a5-37e7-7938-cb3eec515f1f@treenet.co.nz>
 <791409df-944c-ef6d-fda7-30a335f77c69@gmail.com>
Message-ID: <68346dcd-2711-d2d4-4c31-58512072600c@gmail.com>



26.03.2018 06:41, Yuri ?????:
>
> 26.03.2018 06:30, Amos Jeffries ?????:
>> On 26/03/18 12:34, Yuri wrote:
>>> 26.03.2018 05:23, Amos Jeffries ?????:
>>>> On 26/03/18 12:07, Yuri wrote:
>>>>> 26.03.2018 05:05, Amos Jeffries ?????:
>>>>>> On 26/03/18 11:05, Yuri wrote:
>>>>>>> And yes, HTTPS is insecure by design and all our actions does not it
>>>>>>> less insecure :-D
>>>>>> We are not talking about HTTPS. Only about TLS. Because the TLS decrypt
>>>>>> is what is "failing" at the time any of these details we are discussing
>>>>>> are relevant.
>>>>>>
>>>>>> The "page" mentioned is HTML created by the _client_ as its way to show
>>>>>> the user things. Still no HTTP(S) involvement. Squid has zero
>>>>>> involvement with that so cannot make it do anything active (like install
>>>>>> CA certs).
>>>>> Exactly. Users do. And we're almost have all required tools to implement
>>>>> user'driven helper ;)
>>>> Yet again you are circled back to involving the user. Remember the
>>>> original point was trying to do things *without any user* knowing or
>>>> being involved.
>>> I could not make such a stupid idea. It does not work out that way. The
>>> user is always asked whether trust the installing CA certificate.
>> "
>> On 17/03/18 01:43, Yuri wrote:
>>> I guess better way to do this is create special ACL to catch exactly
>>> certificate error and then redirect by 302 using deny_info to proxy page
>>> with explanation and certificate.
>> "
>>
>> The mistake here was thinking the error was something Squid could see or
>> detect. It is not.
>>
>>
>>> The only way known for me to make this silently - using AD group policy.
>>>
>>> AFAIK, we're discussing usual way with catch error and redirect to page.
>>> No more. Captive Portal, Splash, ACL etc.
>>>
>> In order to deliver that splash page or redirect requires the client to
>> trust the proxy CA and decrypt the proxy HTTPS response.
>>
>> BUT, the problem Nicolas had in the first place was the client not
>> trusting the proxy CA and displaying a page of its own:
>>
>> "
>> On 16/03/18 23:37, Nicolas Kovacs wrote:
>>> User who don't have the certificate installed
>>> normally get a big fat HTTPS error as soon as they connect
>> "
>>
>> The idea proposed to replace the client-created page was to send a
>> custom one from the proxy. Which is a circle.
> My bad. Miss it. So obvious thing for me.
>>
>>
>>
>> On 26/03/18 12:34, Yuri wrote:>
>>> 26.03.2018 05:23, Amos Jeffries ?????:
>>>> This is what I mean by "TLS used properly" - proper is when it always
>>>> circles back to user deciding who they trust. No matter how indirectly,
>>>> the user installs a (root) CA causing trust or allowed someone else to
>>>> do so.
>>> Generally speaking, yes.
>>>
>>> I just mean, that in some other protocols you have no any possibility to
>>> make MiTM by any way, whenever installing something or not. This
>>> prevents any improper or malicious use of protocol.
>>>
>>> TLS*have* this possibility. SSH is *not*. You can't MiTM or compromise
>>> SSH by installing any key/certs to client. Correct? This is by design?
>> No. SSH is just TCP/telnet over TLS. So if the SSH software were to
>> trust the cert/key Squid delivers one could use SSL-Bump on that SSH
>> traffic.
> You sure?
>
> https://stackoverflow.com/questions/723152/difference-between-ssh-and-ssl-especially-in-terms-of-sftp-vs-ftp-over-ssl
>
> Quote: "SSH has its own transport protocol independent from SSL, so that
> means SSH DOES NOT use SSL under the hood."
>
> Because I'm not. Different sources tells opposite.
I'm sure SSH using openssl under the hood. But not sure it uses same
tunneling implementation like TLS-over-HTTP. And now it is still unknown
any method to MiTM SSH, AFAIK.
>> The on_unsupported_protocol feature is for exactly this non-HTTP traffic
>> to be bumped (and rejected) or spliced by Squid.
>>
>> NP: The only thing protecting SSH against SSL-Bump is that servers there
>> are *supposed* to check client certs as well as the server certs being
>> checked by clients. The bi-directional checking breaks bumping.
>>
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/55f1ce7a/attachment.sig>

From squid3 at treenet.co.nz  Mon Mar 26 01:08:49 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 26 Mar 2018 14:08:49 +1300
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <68346dcd-2711-d2d4-4c31-58512072600c@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
 <1b6f8ff8-1a07-0768-5b7c-692635d357e9@treenet.co.nz>
 <c1266cf7-94fc-caf5-fb3e-088d705a0de9@gmail.com>
 <88b9fe1e-0340-d99a-ac2b-b2938c793944@treenet.co.nz>
 <7be514f0-756d-a680-138c-5f8f3bbd9af0@gmail.com>
 <6df8e33d-85a5-37e7-7938-cb3eec515f1f@treenet.co.nz>
 <791409df-944c-ef6d-fda7-30a335f77c69@gmail.com>
 <68346dcd-2711-d2d4-4c31-58512072600c@gmail.com>
Message-ID: <59739641-f599-fa54-ab16-26a2b31b37a3@treenet.co.nz>

On 26/03/18 13:44, Yuri wrote:
> 
> 
> 26.03.2018 06:41, Yuri ?????:
>>
>> 26.03.2018 06:30, Amos Jeffries ?????:
>>> On 26/03/18 12:34, Yuri wrote:
>>>> 26.03.2018 05:23, Amos Jeffries ?????:
>>>>> On 26/03/18 12:07, Yuri wrote:
>>>>>> 26.03.2018 05:05, Amos Jeffries ?????:
>>>>>>> On 26/03/18 11:05, Yuri wrote:

>>>
>>> On 26/03/18 12:34, Yuri wrote:>
>>>> 26.03.2018 05:23, Amos Jeffries ?????:
>>>>> This is what I mean by "TLS used properly" - proper is when it always
>>>>> circles back to user deciding who they trust. No matter how indirectly,
>>>>> the user installs a (root) CA causing trust or allowed someone else to
>>>>> do so.
>>>> Generally speaking, yes.
>>>>
>>>> I just mean, that in some other protocols you have no any possibility to
>>>> make MiTM by any way, whenever installing something or not. This
>>>> prevents any improper or malicious use of protocol.
>>>>
>>>> TLS*have* this possibility. SSH is *not*. You can't MiTM or compromise
>>>> SSH by installing any key/certs to client. Correct? This is by design?
>>> No. SSH is just TCP/telnet over TLS. So if the SSH software were to
>>> trust the cert/key Squid delivers one could use SSL-Bump on that SSH
>>> traffic.
>> You sure?
>>
>> https://stackoverflow.com/questions/723152/difference-between-ssh-and-ssl-especially-in-terms-of-sftp-vs-ftp-over-ssl
>>
>> Quote: "SSH has its own transport protocol independent from SSL, so that
>> means SSH DOES NOT use SSL under the hood."
>>
>> Because I'm not. Different sources tells opposite.
> I'm sure SSH using openssl under the hood. But not sure it uses same
> tunneling implementation like TLS-over-HTTP. And now it is still unknown
> any method to MiTM SSH, AFAIK.

I'm not 100% sure, but it uses the same message framing as TLS and
performs the same handshake sequence and security verifications.

That said *SSL* _is_ different from TLS so the quote is technically
correct either way.

Amos


From yvoinov at gmail.com  Mon Mar 26 01:12:44 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 07:12:44 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <59739641-f599-fa54-ab16-26a2b31b37a3@treenet.co.nz>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
 <1b6f8ff8-1a07-0768-5b7c-692635d357e9@treenet.co.nz>
 <c1266cf7-94fc-caf5-fb3e-088d705a0de9@gmail.com>
 <88b9fe1e-0340-d99a-ac2b-b2938c793944@treenet.co.nz>
 <7be514f0-756d-a680-138c-5f8f3bbd9af0@gmail.com>
 <6df8e33d-85a5-37e7-7938-cb3eec515f1f@treenet.co.nz>
 <791409df-944c-ef6d-fda7-30a335f77c69@gmail.com>
 <68346dcd-2711-d2d4-4c31-58512072600c@gmail.com>
 <59739641-f599-fa54-ab16-26a2b31b37a3@treenet.co.nz>
Message-ID: <eadb6a3a-1e50-80da-523d-c50216c522e4@gmail.com>



26.03.2018 07:08, Amos Jeffries ?????:
> On 26/03/18 13:44, Yuri wrote:
>>
>> 26.03.2018 06:41, Yuri ?????:
>>> 26.03.2018 06:30, Amos Jeffries ?????:
>>>> On 26/03/18 12:34, Yuri wrote:
>>>>> 26.03.2018 05:23, Amos Jeffries ?????:
>>>>>> On 26/03/18 12:07, Yuri wrote:
>>>>>>> 26.03.2018 05:05, Amos Jeffries ?????:
>>>>>>>> On 26/03/18 11:05, Yuri wrote:
>>>> On 26/03/18 12:34, Yuri wrote:>
>>>>> 26.03.2018 05:23, Amos Jeffries ?????:
>>>>>> This is what I mean by "TLS used properly" - proper is when it always
>>>>>> circles back to user deciding who they trust. No matter how indirectly,
>>>>>> the user installs a (root) CA causing trust or allowed someone else to
>>>>>> do so.
>>>>> Generally speaking, yes.
>>>>>
>>>>> I just mean, that in some other protocols you have no any possibility to
>>>>> make MiTM by any way, whenever installing something or not. This
>>>>> prevents any improper or malicious use of protocol.
>>>>>
>>>>> TLS*have* this possibility. SSH is *not*. You can't MiTM or compromise
>>>>> SSH by installing any key/certs to client. Correct? This is by design?
>>>> No. SSH is just TCP/telnet over TLS. So if the SSH software were to
>>>> trust the cert/key Squid delivers one could use SSL-Bump on that SSH
>>>> traffic.
>>> You sure?
>>>
>>> https://stackoverflow.com/questions/723152/difference-between-ssh-and-ssl-especially-in-terms-of-sftp-vs-ftp-over-ssl
>>>
>>> Quote: "SSH has its own transport protocol independent from SSL, so that
>>> means SSH DOES NOT use SSL under the hood."
>>>
>>> Because I'm not. Different sources tells opposite.
>> I'm sure SSH using openssl under the hood. But not sure it uses same
>> tunneling implementation like TLS-over-HTTP. And now it is still unknown
>> any method to MiTM SSH, AFAIK.
> I'm not 100% sure, but it uses the same message framing as TLS and
> performs the same handshake sequence and security verifications.
This is not the same as transport, yes? Because of transport is primary
target for bumping.
>
> That said *SSL* _is_ different from TLS so the quote is technically
> correct either way.
It seems to me that the difference is not of principle. Both SSL and TLS
use the same architecture, in which, in principle, it is possible to
have an MiTM certificate, which one of the parties trusts.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/840b6467/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/840b6467/attachment.sig>

From jascha.sticher at tds.fujitsu.com  Mon Mar 26 07:47:01 2018
From: jascha.sticher at tds.fujitsu.com (Sticher, Jascha)
Date: Mon, 26 Mar 2018 07:47:01 +0000
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <eadb6a3a-1e50-80da-523d-c50216c522e4@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
 <1b6f8ff8-1a07-0768-5b7c-692635d357e9@treenet.co.nz>
 <c1266cf7-94fc-caf5-fb3e-088d705a0de9@gmail.com>
 <88b9fe1e-0340-d99a-ac2b-b2938c793944@treenet.co.nz>
 <7be514f0-756d-a680-138c-5f8f3bbd9af0@gmail.com>
 <6df8e33d-85a5-37e7-7938-cb3eec515f1f@treenet.co.nz>
 <791409df-944c-ef6d-fda7-30a335f77c69@gmail.com>
 <68346dcd-2711-d2d4-4c31-58512072600c@gmail.com>
 <59739641-f599-fa54-ab16-26a2b31b37a3@treenet.co.nz>
 <eadb6a3a-1e50-80da-523d-c50216c522e4@gmail.com>
Message-ID: <E286ADE35F919742812E3076A36122E701BFCAA911@tdsnsumbx2vp>

Hi everyone,

I know this is quite off-topic, but I wanted to clarify a bit.

SSH and TLS both provide the same thing, namely a tunnel between a client and a server. While both use asymmetric crypto for authentication and symmetric crypto for data transfer and therefore the same algorithms (that's why openssh requires openssl/gnutls - as crypto library), they are independent protocols. SSH uses its own key format, which does not know such a thing as a CA ? each server generates its own server key pair (or at least it should).[1,2]

As to SSH-MiTM, this is indeed possible, in two cases:
a) The server key is unknown to the client and not verified correctly (by the user!). Then a fake server can decrypt SSH and intercept everything.
b) The client validates server certificates incorrectly or is told ignore changes in the server key (eg. ?-o StrictHostKeyChecking=no? with openssh)

There are some SSH-MITM solutions available on the internet.[3]

To conclude, if crypto is involved _every_ part of the conversation needs to do it _right_. Including the user.


Kind regards,

Jascha


[1] https://security.stackexchange.com/questions/1599/what-is-the-difference-between-ssl-vs-ssh-which-is-more-secure
[2] https://wiki.hetzner.de/index.php/Ed25519 - hetzner shipped the same elliptic-curve host key on each host for a time
[2] e.g. https://github.com/mitmproxy/mitmproxy



Von: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Im Auftrag von Yuri
Gesendet: Montag, 26. M?rz 2018 03:13
An: squid-users at lists.squid-cache.org
Betreff: Re: [squid-users] How to configure a "proxy home" page ?



26.03.2018 07:08, Amos Jeffries ?????:
On 26/03/18 13:44, Yuri wrote:


26.03.2018 06:41, Yuri ?????:

26.03.2018 06:30, Amos Jeffries ?????:
On 26/03/18 12:34, Yuri wrote:
26.03.2018 05:23, Amos Jeffries ?????:
On 26/03/18 12:07, Yuri wrote:
26.03.2018 05:05, Amos Jeffries ?????:
On 26/03/18 11:05, Yuri wrote:


On 26/03/18 12:34, Yuri wrote:>
26.03.2018 05:23, Amos Jeffries ?????:
This is what I mean by "TLS used properly" - proper is when it always
circles back to user deciding who they trust. No matter how indirectly,
the user installs a (root) CA causing trust or allowed someone else to
do so.
Generally speaking, yes.

I just mean, that in some other protocols you have no any possibility to
make MiTM by any way, whenever installing something or not. This
prevents any improper or malicious use of protocol.

TLS*have* this possibility. SSH is *not*. You can't MiTM or compromise
SSH by installing any key/certs to client. Correct? This is by design?
No. SSH is just TCP/telnet over TLS. So if the SSH software were to
trust the cert/key Squid delivers one could use SSL-Bump on that SSH
traffic.
You sure?

https://stackoverflow.com/questions/723152/difference-between-ssh-and-ssl-especially-in-terms-of-sftp-vs-ftp-over-ssl

Quote: "SSH has its own transport protocol independent from SSL, so that
means SSH DOES NOT use SSL under the hood."

Because I'm not. Different sources tells opposite.
I'm sure SSH using openssl under the hood. But not sure it uses same
tunneling implementation like TLS-over-HTTP. And now it is still unknown
any method to MiTM SSH, AFAIK.

I'm not 100% sure, but it uses the same message framing as TLS and
performs the same handshake sequence and security verifications.
This is not the same as transport, yes? Because of transport is primary target for bumping.



That said *SSL* _is_ different from TLS so the quote is technically
correct either way.
It seems to me that the difference is not of principle. Both SSL and TLS use the same architecture, in which, in principle, it is possible to have an MiTM certificate, which one of the parties trusts.


Amos

Erleben Sie Industrie 4.0 konkret ? auf der HANNOVER MESSE.
Vom 23. bis 27. April 2018.
www.fujitsu.com/de/microsite/hmi/register/index.html?utm_source=Email&utm_medium=Signature%20EMail&utm_campaign=HANNOVER%20MESSE%20DE&utm_term=&utm_content=Ticket-anfordern

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


--
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

From uhlar at fantomas.sk  Mon Mar 26 09:33:08 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 26 Mar 2018 11:33:08 +0200
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
Message-ID: <20180326093308.GA30743@fantomas.sk>

>>>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>>>> The problem is not install proxy CA. The problem is identify client
>>>>>> has no proxy CA and redirect, and do it only one time.
>>>>
>>>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>>>> That is exactly the problem. And I have yet to find a solution for
>>>>> that.
>>>>>
>>>>> Current method is instruct everyone - with a printed paper in the
>>>>> office
>>>>> - to connect to proxy.company-name.lan and then get further
>>>>> instructions
>>>>> from the page. This works, but an automatic splash page would be more
>>>>> elegant.
>>
>>> 25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>>>> impossible and unsafe. The CA must be installed before such splash
>>>> page shows
>>
>> On 25.03.18 18:44, Yuri wrote:
>>> Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>>> implemented already.

>25.03.2018 20:32, Matus UHLAR - fantomas ?????:
>> it's possible to install splash page, but not install trusted authority
>> certificate.? Using such authority on a proxy is the MITM attack and
>> whole
>> SSL has been designed to prevent this.

On 25.03.18 21:41, Yuri wrote:
>Heh. If SSL designed - why SSL Bump itself possible? ;):-P

it's not, you must break throught it to allow ssl-bump by installing your
CA certificate.  You haven't explained how to do that automatically although
you claim it's possible.

Please provide evidence.

>> without certificate, the browser complains which is a security measure
>> against this.

>Sure. It should.

and it does. unless you tweak it not to, which must be configured manually
(please provide evidence if not).

>>>> up and in such case the splash page is irelevant.
>>>>
>>>> If you have windows domain, you can force security policy through it.
>>
>>> In enterprise environment with AD, yes. But hardly in service provider's
>>> scenarious.
>>
>> service providers should not do this without users' permission.
>> at least not in countries where the privacy is guaranteed by law.

>Thank you, Captain Obvious. :-) Enterprises also should get user
>agreement before do that. Especially in BYOD scenarious.
>
>All these things are well known here. The question was about technical
>implementation, and not about the well-known truisms in the field of
>security and privacy (in most cases of ephemeral).

maybe you know that, but many of people asking for ssl bump how-to do not
know that. 

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
"Two words: Windows survives." - Craig Mundie, Microsoft senior strategist
"So does syphillis. Good thing we have penicillin." - Matthew Alton


From squid3 at treenet.co.nz  Mon Mar 26 11:16:35 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 27 Mar 2018 00:16:35 +1300
Subject: [squid-users] url_rewrite_extras can't send source port on
 tproxy mode
In-Reply-To: <HE1PR06MB30506B383E84671D373B3BBCEE570@HE1PR06MB3050.eurprd06.prod.outlook.com>
References: <HE1PR06MB30506B383E84671D373B3BBCEE570@HE1PR06MB3050.eurprd06.prod.outlook.com>
Message-ID: <f9f930b5-f57e-414b-0c5f-cd132fbf3914@treenet.co.nz>

On 09/11/17 21:43, Ibrahim Ercan wrote:
> Hi.
> I have a problem regarding tproxy.
> 
> I configured squid with tproxy by below tutorial.
> https://wiki.squid-cache.org/Features/Tproxy4
> 
> Then I configured a url rewrite program as follows
> 
> url_rewrite_program /path/to/foo.py
> url_rewrite_extras "%>a %>p"
> 
> On nat configuration it is working well, but on tproxy configuration
> my script gets source port (>p) as 0.
> 
> Do you know any idea why, and how to solve it?
> 

For anyone finding this in future. This issue was fixed in Squid-4.0.24.

Amos


From yvoinov at gmail.com  Mon Mar 26 13:11:05 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 19:11:05 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <20180326093308.GA30743@fantomas.sk>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <20180325124209.GA2303@fantomas.sk>
 <3aca800e-93da-85e3-c156-712cb51ad0fa@gmail.com>
 <20180325143213.GC2303@fantomas.sk>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <20180326093308.GA30743@fantomas.sk>
Message-ID: <a0706b8c-c113-c7de-9a56-8c8d71dd3bde@gmail.com>



26.03.2018 15:33, Matus UHLAR - fantomas ?????:
>>>>>> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>>>>>>> The problem is not install proxy CA. The problem is identify client
>>>>>>> has no proxy CA and redirect, and do it only one time.
>>>>>
>>>>> On 25.03.18 13:46, Nicolas Kovacs wrote:
>>>>>> That is exactly the problem. And I have yet to find a solution for
>>>>>> that.
>>>>>>
>>>>>> Current method is instruct everyone - with a printed paper in the
>>>>>> office
>>>>>> - to connect to proxy.company-name.lan and then get further
>>>>>> instructions
>>>>>> from the page. This works, but an automatic splash page would be
>>>>>> more
>>>>>> elegant.
>>>
>>>> 25.03.2018 18:42, Matus UHLAR - fantomas ?????:
>>>>> impossible and unsafe. The CA must be installed before such splash
>>>>> page shows
>>>
>>> On 25.03.18 18:44, Yuri wrote:
>>>> Possible. "Safe/Unsafe" should not be discussion when SSL Bump
>>>> implemented already.
>
>> 25.03.2018 20:32, Matus UHLAR - fantomas ?????:
>>> it's possible to install splash page, but not install trusted authority
>>> certificate.? Using such authority on a proxy is the MITM attack and
>>> whole
>>> SSL has been designed to prevent this.
>
> On 25.03.18 21:41, Yuri wrote:
>> Heh. If SSL designed - why SSL Bump itself possible? ;):-P
>
> it's not, you must break throught it to allow ssl-bump by installing your
> CA certificate.? You haven't explained how to do that automatically
> although
> you claim it's possible.
>
> Please provide evidence.
Waaaaaaa. No. My misunderstanding. Of course, not automatically.
>
>>> without certificate, the browser complains which is a security measure
>>> against this.
>
>> Sure. It should.
>
> and it does. unless you tweak it not to, which must be configured
> manually
> (please provide evidence if not).
Exactly. I'm talking only about it. My misunderstanding.
>
>>>>> up and in such case the splash page is irelevant.
>>>>>
>>>>> If you have windows domain, you can force security policy through it.
>>>
>>>> In enterprise environment with AD, yes. But hardly in service
>>>> provider's
>>>> scenarious.
>>>
>>> service providers should not do this without users' permission.
>>> at least not in countries where the privacy is guaranteed by law.
>
>> Thank you, Captain Obvious. :-) Enterprises also should get user
>> agreement before do that. Especially in BYOD scenarious.
>>
>> All these things are well known here. The question was about technical
>> implementation, and not about the well-known truisms in the field of
>> security and privacy (in most cases of ephemeral).
>
> maybe you know that, but many of people asking for ssl bump how-to do not
> know that.
A bit disagree.
?
This has been repeated so many times here and in Wiki that it's hard to
imagine that someone does not already know this.

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/977ef1a1/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/977ef1a1/attachment.sig>

From yvoinov at gmail.com  Mon Mar 26 13:16:37 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 19:16:37 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <E286ADE35F919742812E3076A36122E701BFCAA911@tdsnsumbx2vp>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <2b9f13bc-18ff-ecf1-c5a5-121dd2ce7541@gmail.com>
 <9a89b18e-ec38-27be-8471-8a6a10db3fb8@treenet.co.nz>
 <0dad0c68-e1e9-4cfc-3205-1d8ae274b013@gmail.com>
 <b54fe88b-74bd-e158-a5d7-4a760cb294a1@treenet.co.nz>
 <adf7b443-e15c-c19b-0fad-534bbd34d3b0@gmail.com>
 <491e7863-d225-b7c4-c15e-fcf32e8f5abd@treenet.co.nz>
 <34dd599a-67f5-5f28-ea38-5b989e72f857@gmail.com>
 <d96136f0-bf89-d3ee-af98-f8347f82c3e8@gmail.com>
 <1b6f8ff8-1a07-0768-5b7c-692635d357e9@treenet.co.nz>
 <c1266cf7-94fc-caf5-fb3e-088d705a0de9@gmail.com>
 <88b9fe1e-0340-d99a-ac2b-b2938c793944@treenet.co.nz>
 <7be514f0-756d-a680-138c-5f8f3bbd9af0@gmail.com>
 <6df8e33d-85a5-37e7-7938-cb3eec515f1f@treenet.co.nz>
 <791409df-944c-ef6d-fda7-30a335f77c69@gmail.com>
 <68346dcd-2711-d2d4-4c31-58512072600c@gmail.com>
 <59739641-f599-fa54-ab16-26a2b31b37a3@treenet.co.nz>
 <eadb6a3a-1e50-80da-523d-c50216c522e4@gmail.com>
 <E286ADE35F919742812E3076A36122E701BFCAA911@tdsnsumbx2vp>
Message-ID: <9b071499-9071-b512-c8de-6a7ef06f48cd@gmail.com>

Disagree.

My point about TLS is quite different.

SSH, by design, assumes end-to-end encryption and do not assumes any
third-party treats as trusty, like TLS does. SSH immediately notice you
when server key surprisingly changed. Any MiTM in SSH tunnel immediately
breaks connection. Of course, you can steal client private key, you can
break private key password. But you can't easy become fake server or
intermediate hop and silently decrypt tunneled SSH traffic. You can't do
this by design.

Basics of TLS (in HTTPS implementation) assumes trusted third-party,
which is authenticate both sides of conversations (i.e. Bob and Alice).
I.e., in case of this third party becomes untrusted by any reason (as
practice has shown, it is very likely), it can silently decrypt Bob and
Alice conversation without any notification - you still see green lock.
Here we're can not talking about SSL Bump itself. Just imagine - not
only you can do it with squid, but any who can get intermediate CA
signed by trusted root CA.

Yes, users is involved in both cases. However the difference still here.
SSH is end-to-end always by design (we're not talking about things like
Kerberos here), TLS is not.


26.03.2018 13:47, Sticher, Jascha ?????:
> Hi everyone,
>
> I know this is quite off-topic, but I wanted to clarify a bit.
>
> SSH and TLS both provide the same thing, namely a tunnel between a client and a server. While both use asymmetric crypto for authentication and symmetric crypto for data transfer and therefore the same algorithms (that's why openssh requires openssl/gnutls - as crypto library), they are independent protocols. SSH uses its own key format, which does not know such a thing as a CA ? each server generates its own server key pair (or at least it should).[1,2]
>
> As to SSH-MiTM, this is indeed possible, in two cases:
> a) The server key is unknown to the client and not verified correctly (by the user!). Then a fake server can decrypt SSH and intercept everything.
> b) The client validates server certificates incorrectly or is told ignore changes in the server key (eg. ?-o StrictHostKeyChecking=no? with openssh)
>
> There are some SSH-MITM solutions available on the internet.[3]
>
> To conclude, if crypto is involved _every_ part of the conversation needs to do it _right_. Including the user.
>
>
> Kind regards,
>
> Jascha
>
>
> [1] https://security.stackexchange.com/questions/1599/what-is-the-difference-between-ssl-vs-ssh-which-is-more-secure
> [2] https://wiki.hetzner.de/index.php/Ed25519 - hetzner shipped the same elliptic-curve host key on each host for a time
> [2] e.g. https://github.com/mitmproxy/mitmproxy
>
>
>
> Von: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Im Auftrag von Yuri
> Gesendet: Montag, 26. M?rz 2018 03:13
> An: squid-users at lists.squid-cache.org
> Betreff: Re: [squid-users] How to configure a "proxy home" page ?
>
>
>
> 26.03.2018 07:08, Amos Jeffries ?????:
> On 26/03/18 13:44, Yuri wrote:
>
>
> 26.03.2018 06:41, Yuri ?????:
>
> 26.03.2018 06:30, Amos Jeffries ?????:
> On 26/03/18 12:34, Yuri wrote:
> 26.03.2018 05:23, Amos Jeffries ?????:
> On 26/03/18 12:07, Yuri wrote:
> 26.03.2018 05:05, Amos Jeffries ?????:
> On 26/03/18 11:05, Yuri wrote:
>
>
> On 26/03/18 12:34, Yuri wrote:>
> 26.03.2018 05:23, Amos Jeffries ?????:
> This is what I mean by "TLS used properly" - proper is when it always
> circles back to user deciding who they trust. No matter how indirectly,
> the user installs a (root) CA causing trust or allowed someone else to
> do so.
> Generally speaking, yes.
>
> I just mean, that in some other protocols you have no any possibility to
> make MiTM by any way, whenever installing something or not. This
> prevents any improper or malicious use of protocol.
>
> TLS*have* this possibility. SSH is *not*. You can't MiTM or compromise
> SSH by installing any key/certs to client. Correct? This is by design?
> No. SSH is just TCP/telnet over TLS. So if the SSH software were to
> trust the cert/key Squid delivers one could use SSL-Bump on that SSH
> traffic.
> You sure?
>
> https://stackoverflow.com/questions/723152/difference-between-ssh-and-ssl-especially-in-terms-of-sftp-vs-ftp-over-ssl
>
> Quote: "SSH has its own transport protocol independent from SSL, so that
> means SSH DOES NOT use SSL under the hood."
>
> Because I'm not. Different sources tells opposite.
> I'm sure SSH using openssl under the hood. But not sure it uses same
> tunneling implementation like TLS-over-HTTP. And now it is still unknown
> any method to MiTM SSH, AFAIK.
>
> I'm not 100% sure, but it uses the same message framing as TLS and
> performs the same handshake sequence and security verifications.
> This is not the same as transport, yes? Because of transport is primary target for bumping.
>
>
>
> That said *SSL* _is_ different from TLS so the quote is technically
> correct either way.
> It seems to me that the difference is not of principle. Both SSL and TLS use the same architecture, in which, in principle, it is possible to have an MiTM certificate, which one of the parties trusts.
>
>
> Amos
>
> Erleben Sie Industrie 4.0 konkret ? auf der HANNOVER MESSE.
> Vom 23. bis 27. April 2018.
> www.fujitsu.com/de/microsite/hmi/register/index.html?utm_source=Email&utm_medium=Signature%20EMail&utm_campaign=HANNOVER%20MESSE%20DE&utm_term=&utm_content=Ticket-anfordern
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> --
> "C++ seems like a language suitable for firing other people's legs."
>
> *****************************
> * C++20 : Bug to the future *
> *****************************
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/60774c41/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/60774c41/attachment.sig>

From vvv25 at gmx.net  Mon Mar 26 13:46:26 2018
From: vvv25 at gmx.net (vvv25 at gmx.net)
Date: Mon, 26 Mar 2018 15:46:26 +0200
Subject: [squid-users] delay-pool based on authentication
In-Reply-To: <58c2477d-46b6-6dc7-b82c-cb3cf80328d1@gmail.com>
References: <op.zgdzcrjrek8y7k@mail.gmx.net>
 <58c2477d-46b6-6dc7-b82c-cb3cf80328d1@gmail.com>
Message-ID: <op.zghkjoisek8y7k@mail.gmx.net>

Dear Yuri,

thank you for your quick reply.
I spend weekend trying and testing some options.

My problem is, i cannot separate authenticated users from not  
authenticated.

Here in detail:
if I try to do something like this
---- cut ----
acl users proxy_auth "/etc/squid/users"
http_access allow users

delay_pools 2

delay_class 1 1
delay_parameters 1 -1/-1 # no limit

delay_access 1 allow users
delay_access 1 deny all

delay_class 2 3
delay_parameters 2 -1/-1 -1/-1 196608/786432	# no limit, no limit, 1.5  
Mbit/s per user 6.0 Mbis/s once

delay_access 2 allow all
---- cut ----

then every user is asked for authentication. If they cancel that, they  
cannot access nothing.

if I try to start with the restricted delay pool
---- cut ----
delay_pools 2

delay_class 1 1
delay_parameters 1 -1/-1 # no limit

delay_access 1 allow users
delay_access 1 deny all

delay_class 2 3
delay_parameters 2 -1/-1 -1/-1 196608/786432	# no limit, no limit, 1.5  
Mbit/s per user 6.0 Mbis/s once

delay_access 2 allow all

acl users proxy_auth "/etc/squid/users"
http_access allow users
---- cut ----
than every user is restricted and no query for authentication occurs.

How can I separate not authenticated users from authenticated?
I cannot use IPs because all IPs are in the same range.

Thank you in advance!
Regards,
Vitaly


Am Sat, 24 Mar 2018 16:20:24 +0100 schrieb Yuri <yvoinov at gmail.com>:

> https://wiki.squid-cache.org/Features/DelayPools
>
>
> 24.03.2018 21:15, vvv25 at gmx.net ?????:
>> Dear Comunity,
>>
>> I have the following question:
>> Is it possible with squid to select delay pool depending on whether
>> the user is authenticated or not?
>>
>> Background:
>> I want to set up a slow delay pool by default. (for unauthenticated
>> users)
>> For registered users I want to assign another delay pool with no
>> restriction (full speed).
>>
>> Any suggestion is welcome.
>>
>> Thank you very much!
>>
>> Regards,
>> Vitaly
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users


From vvv25 at gmx.net  Mon Mar 26 13:51:33 2018
From: vvv25 at gmx.net (vvv25 at gmx.net)
Date: Mon, 26 Mar 2018 15:51:33 +0200
Subject: [squid-users] delay-pool based on authentication
In-Reply-To: <3d16c839-515b-d9ad-a29f-45a1d80f0ad3@treenet.co.nz>
References: <op.zgdzcrjrek8y7k@mail.gmx.net>
 <3d16c839-515b-d9ad-a29f-45a1d80f0ad3@treenet.co.nz>
Message-ID: <op.zghkr7ucek8y7k@mail.gmx.net>

Thank you for your time Amos,

the thing is, I want to have the connection to be restricted by default.
May be I don't understand how to define acl's in the right order.
Or I cannot figure out how to separate authenticated users from not  
authenticated.

Do you have some suggestions?

Any help would be appretiated.

Many thanks,

Regards,
Vitaly

Am Sat, 24 Mar 2018 18:13:14 +0100 schrieb Amos Jeffries  
<squid3 at treenet.co.nz>:

> On 25/03/18 04:15, vvv25 wrote:>
>> I want to set up a slow delay pool by default. (for unauthenticated  
>> users)
>> For registered users I want to assign another delay pool with no
>> restriction (full speed).
>
> The thing with DelayPool is that to "set" no restriction you *dont*
> assign a delay pool.
>
> What Yuri missed out was that for per-user detailss see the "class 4"
> details on that page.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From yvoinov at gmail.com  Mon Mar 26 14:01:28 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 20:01:28 +0600
Subject: [squid-users] delay-pool based on authentication
In-Reply-To: <op.zghkjoisek8y7k@mail.gmx.net>
References: <op.zgdzcrjrek8y7k@mail.gmx.net>
 <58c2477d-46b6-6dc7-b82c-cb3cf80328d1@gmail.com>
 <op.zghkjoisek8y7k@mail.gmx.net>
Message-ID: <5008c845-e8a7-0d51-58f0-783e7d89b2d1@gmail.com>

Probably, yes.

I'm not so good in delay pools, but I guess you moving to right direction.

First require to make clean users separation.

I think, Amos can consult you better. ;-)


26.03.2018 19:46, vvv25 at gmx.net ?????:
> Dear Yuri,
>
> thank you for your quick reply.
> I spend weekend trying and testing some options.
>
> My problem is, i cannot separate authenticated users from not
> authenticated.
>
> Here in detail:
> if I try to do something like this
> ---- cut ----
> acl users proxy_auth "/etc/squid/users"
> http_access allow users
>
> delay_pools 2
>
> delay_class 1 1
> delay_parameters 1 -1/-1 # no limit
>
> delay_access 1 allow users
> delay_access 1 deny all
>
> delay_class 2 3
> delay_parameters 2 -1/-1 -1/-1 196608/786432??? # no limit, no limit,
> 1.5 Mbit/s per user 6.0 Mbis/s once
>
> delay_access 2 allow all
> ---- cut ----
>
> then every user is asked for authentication. If they cancel that, they
> cannot access nothing.
>
> if I try to start with the restricted delay pool
> ---- cut ----
> delay_pools 2
>
> delay_class 1 1
> delay_parameters 1 -1/-1 # no limit
>
> delay_access 1 allow users
> delay_access 1 deny all
>
> delay_class 2 3
> delay_parameters 2 -1/-1 -1/-1 196608/786432??? # no limit, no limit,
> 1.5 Mbit/s per user 6.0 Mbis/s once
>
> delay_access 2 allow all
>
> acl users proxy_auth "/etc/squid/users"
> http_access allow users
> ---- cut ----
> than every user is restricted and no query for authentication occurs.
>
> How can I separate not authenticated users from authenticated?
> I cannot use IPs because all IPs are in the same range.
>
> Thank you in advance!
> Regards,
> Vitaly
>
>
> Am Sat, 24 Mar 2018 16:20:24 +0100 schrieb Yuri <yvoinov at gmail.com>:
>
>> https://wiki.squid-cache.org/Features/DelayPools
>>
>>
>> 24.03.2018 21:15, vvv25 at gmx.net ?????:
>>> Dear Comunity,
>>>
>>> I have the following question:
>>> Is it possible with squid to select delay pool depending on whether
>>> the user is authenticated or not?
>>>
>>> Background:
>>> I want to set up a slow delay pool by default. (for unauthenticated
>>> users)
>>> For registered users I want to assign another delay pool with no
>>> restriction (full speed).
>>>
>>> Any suggestion is welcome.
>>>
>>> Thank you very much!
>>>
>>> Regards,
>>> Vitaly
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/4429a8b8/attachment.sig>

From christophe.colle at ac-nancy-metz.fr  Mon Mar 26 15:19:18 2018
From: christophe.colle at ac-nancy-metz.fr (Colle Christophe)
Date: Mon, 26 Mar 2018 17:19:18 +0200
Subject: [squid-users] Different directory authentication depending on the
	network.
Message-ID: <d8e4a1172efc99c3.5ab92b96@ac-nancy-metz.fr>

Hello,

I have a question about squid :

Several networks use the same Squid proxy server, in order to set up the authentication, I would like to know if it is possible to configure several directories according to the network of the client?

Or whether to create an instance of squid per network.

Thank you.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/c77def77/attachment.htm>

From eliezer at ngtech.co.il  Sun Mar 25 20:47:27 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 25 Mar 2018 23:47:27 +0300
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
Message-ID: <00a601d3c47a$7c67fbc0$7537f340$@ngtech.co.il>

Hey Nicolas and Yuri

I do not know your level of JS or other thing but... a splash page is mearly a transition step.
Since you can check using JS if the certificate is installed you can design it in such a way that it will be almost transparent for the user.
If the JS find's that you can access the test subject site\page then you can just pass the user using java script into the "LOGIN" page and let it move on from it.
The other case is if the user doesn't have the ROOT CA certificate installed on the browser or device.
The splash page is better then any other solution and it's very elegant.
What is required for mobile phones is a set of instructions or a tech support phone...

The example page I have introduced at:
https://cert.rimon.net.il/

was merely an example that demonstrated the potential of the detection function.
In production we have a another system based on the source code I introduced before that "clears" a client\user from having the certificate installed on his main device\machine\browser.

Do you need an example for such a splash page?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Nicolas Kovacs
Sent: Sunday, March 25, 2018 14:46
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] How to configure a "proxy home" page ?

Le 25/03/2018 ? 13:08, Yuri a ?crit :
> The problem is not install proxy CA. The problem is identify client
> has no proxy CA and redirect, and do it only one time.

That is exactly the problem. And I have yet to find a solution for that.

Current method is instruct everyone - with a printed paper in the office
- to connect to proxy.company-name.lan and then get further instructions
from the page. This works, but an automatic splash page would be more
elegant.

Niki

-- 
Microlinux - Solutions informatiques durables
7, place de l'?glise - 30730 Montpezat
Site : https://www.microlinux.fr
Blog : https://blog.microlinux.fr
Mail : info at microlinux.fr
T?l. : 04 66 63 10 32
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From uhlar at fantomas.sk  Mon Mar 26 15:36:38 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 26 Mar 2018 17:36:38 +0200
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <9b071499-9071-b512-c8de-6a7ef06f48cd@gmail.com>
References: <c1266cf7-94fc-caf5-fb3e-088d705a0de9@gmail.com>
 <88b9fe1e-0340-d99a-ac2b-b2938c793944@treenet.co.nz>
 <7be514f0-756d-a680-138c-5f8f3bbd9af0@gmail.com>
 <6df8e33d-85a5-37e7-7938-cb3eec515f1f@treenet.co.nz>
 <791409df-944c-ef6d-fda7-30a335f77c69@gmail.com>
 <68346dcd-2711-d2d4-4c31-58512072600c@gmail.com>
 <59739641-f599-fa54-ab16-26a2b31b37a3@treenet.co.nz>
 <eadb6a3a-1e50-80da-523d-c50216c522e4@gmail.com>
 <E286ADE35F919742812E3076A36122E701BFCAA911@tdsnsumbx2vp>
 <9b071499-9071-b512-c8de-6a7ef06f48cd@gmail.com>
Message-ID: <20180326153638.GC5681@fantomas.sk>

On 26.03.18 19:16, Yuri wrote:
>Disagree.
>
>My point about TLS is quite different.
>
>SSH, by design, assumes end-to-end encryption and do not assumes any
>third-party treats as trusty, like TLS does.

actually, the ssh DOES support certificate authorities that sign client or
host keys, so you don't need to transfer it over SSH server - it's just not
widely used.

https://www.ssh.com/ssh/keygen/#sec-Using-X-509-Certificates-for-Host-Authentication

> SSH immediately notice you
>when server key surprisingly changed.

only when you already have the host key installed in your client. If there's
MITM attack before you get the key, you will not notice that, unless you
get the key by other (secure) way.

unlike SSL, SSH was not designed to be used globally between everyone, more
within one or more "friend" organizations, so it didn't specify how host
keys are verified (the SSHFP DNS record just transfers trust to DNS, which
can be hijacked too).

>Yes, users is involved in both cases. However the difference still here.
>SSH is end-to-end always by design (we're not talking about things like
>Kerberos here), TLS is not.

TLS was designed to be end-to-end encryption and the certificate authority
system was built to fullfil this.  The bumping proxies, antiviruses, and
application firewalls just break this.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
They that can give up essential liberty to obtain a little temporary
safety deserve neither liberty nor safety. -- Benjamin Franklin, 1759


From yvoinov at gmail.com  Mon Mar 26 15:37:36 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 21:37:36 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <00a601d3c47a$7c67fbc0$7537f340$@ngtech.co.il>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <00a601d3c47a$7c67fbc0$7537f340$@ngtech.co.il>
Message-ID: <a3166a0b-9f14-9d6e-8655-24103db21d92@gmail.com>



26.03.2018 02:47, Eliezer Croitoru ?????:
> Hey Nicolas and Yuri
>
> I do not know your level of JS or other thing but... a splash page is mearly a transition step.
> Since you can check using JS if the certificate is installed you can design it in such a way that it will be almost transparent for the user.
> If the JS find's that you can access the test subject site\page then you can just pass the user using java script into the "LOGIN" page and let it move on from it.
> The other case is if the user doesn't have the ROOT CA certificate installed on the browser or device.
> The splash page is better then any other solution and it's very elegant.
> What is required for mobile phones is a set of instructions or a tech support phone...
>
> The example page I have introduced at:
> https://cert.rimon.net.il/
>
> was merely an example that demonstrated the potential of the detection function.
> In production we have a another system based on the source code I introduced before that "clears" a client\user from having the certificate installed on his main device\machine\browser.
>
> Do you need an example for such a splash page?
No. Splash page is not the most problem.

As I've told, the problem is quite different.

Also, personally for me - I would like to see just automated CA install
sources and Makefile :)
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Nicolas Kovacs
> Sent: Sunday, March 25, 2018 14:46
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] How to configure a "proxy home" page ?
>
> Le 25/03/2018 ? 13:08, Yuri a ?crit :
>> The problem is not install proxy CA. The problem is identify client
>> has no proxy CA and redirect, and do it only one time.
> That is exactly the problem. And I have yet to find a solution for that.
>
> Current method is instruct everyone - with a printed paper in the office
> - to connect to proxy.company-name.lan and then get further instructions
> from the page. This works, but an automatic splash page would be more
> elegant.
>
> Niki
>

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/ab9dbf76/attachment.sig>

From uhlar at fantomas.sk  Mon Mar 26 15:41:17 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 26 Mar 2018 17:41:17 +0200
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <00a601d3c47a$7c67fbc0$7537f340$@ngtech.co.il>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <00a601d3c47a$7c67fbc0$7537f340$@ngtech.co.il>
Message-ID: <20180326154117.GA8825@fantomas.sk>

On 25.03.18 23:47, Eliezer Croitoru wrote:
>I do not know your level of JS or other thing but... a splash page is mearly a transition step.
>Since you can check using JS if the certificate is installed

And how do you push the JS into the client?

when client tries to fetch https://www.google.com/ and you don't have cert
for www.google.com, answering with any other certificate by unknown
authority will produce error before the JS is loaded.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Posli tento mail 100 svojim znamim - nech vidia aky si idiot
Send this email to 100 your friends - let them see what an idiot you are


From yvoinov at gmail.com  Mon Mar 26 15:45:04 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 21:45:04 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <20180326153638.GC5681@fantomas.sk>
References: <c1266cf7-94fc-caf5-fb3e-088d705a0de9@gmail.com>
 <88b9fe1e-0340-d99a-ac2b-b2938c793944@treenet.co.nz>
 <7be514f0-756d-a680-138c-5f8f3bbd9af0@gmail.com>
 <6df8e33d-85a5-37e7-7938-cb3eec515f1f@treenet.co.nz>
 <791409df-944c-ef6d-fda7-30a335f77c69@gmail.com>
 <68346dcd-2711-d2d4-4c31-58512072600c@gmail.com>
 <59739641-f599-fa54-ab16-26a2b31b37a3@treenet.co.nz>
 <eadb6a3a-1e50-80da-523d-c50216c522e4@gmail.com>
 <E286ADE35F919742812E3076A36122E701BFCAA911@tdsnsumbx2vp>
 <9b071499-9071-b512-c8de-6a7ef06f48cd@gmail.com>
 <20180326153638.GC5681@fantomas.sk>
Message-ID: <9d686a5e-4723-b2a1-9f8d-2c9b323c669b@gmail.com>



26.03.2018 21:36, Matus UHLAR - fantomas ?????:
> On 26.03.18 19:16, Yuri wrote:
>> Disagree.
>>
>> My point about TLS is quite different.
>>
>> SSH, by design, assumes end-to-end encryption and do not assumes any
>> third-party treats as trusty, like TLS does.
>
> actually, the ssh DOES support certificate authorities that sign
> client or
> host keys, so you don't need to transfer it over SSH server - it's
> just not
> widely used.
>
> https://www.ssh.com/ssh/keygen/#sec-Using-X-509-Certificates-for-Host-Authentication
>
I know such obvious thing. But functionality you described was not
initially designed in SSH and was added later.
>
>> SSH immediately notice you
>> when server key surprisingly changed.
>
> only when you already have the host key installed in your client. If
> there's
> MITM attack before you get the key, you will not notice that, unless you
> get the key by other (secure) way.
By analogue with TLS - let's imagine I've already been on site. With SSH
client notify me - "Hey, man, you trying to connect to server with ....
fingerprint. Add it Yes/No?"

Instead this, TLS never notify me if third-party CA is known to client.

>
> unlike SSL, SSH was not designed to be used globally between everyone,
> more
> within one or more "friend" organizations, so it didn't specify how host
> keys are verified (the SSHFP DNS record just transfers trust to DNS,
> which
> can be hijacked too).
To be honest, a weak argument. A secure connection should always be
encrypted end-to-end and should not "trusted" third-parties as well.
Never. Otherwise it is insecure connection. IMHO.
>
>> Yes, users is involved in both cases. However the difference still here.
>> SSH is end-to-end always by design (we're not talking about things like
>> Kerberos here), TLS is not.
>
> TLS was designed to be end-to-end encryption and the certificate
> authority
As Stanislavsky said, "I do not believe it!"

End-to-end encryption and the (/trusted third-party/) certificate
authority these are antonyms.
> system was built to fullfil this.? The bumping proxies, antiviruses, and
> application firewalls just break this.
>
With this I can not argue.

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/519dea8e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/519dea8e/attachment.sig>

From yvoinov at gmail.com  Mon Mar 26 15:47:08 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 21:47:08 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <20180326154117.GA8825@fantomas.sk>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <00a601d3c47a$7c67fbc0$7537f340$@ngtech.co.il>
 <20180326154117.GA8825@fantomas.sk>
Message-ID: <65a533ca-fc41-f5e1-7e8b-71fed7c0526a@gmail.com>

Waaaaaaa, Matus,

the idea is trivial.

Catch SSL UNKNOWN ISSUER error on squid's acl and redirect by 302 to
proxy page with instructions. Which requires user's involving.

How much can repeat the obvious ....


26.03.2018 21:41, Matus UHLAR - fantomas ?????:
> On 25.03.18 23:47, Eliezer Croitoru wrote:
>> I do not know your level of JS or other thing but... a splash page is
>> mearly a transition step.
>> Since you can check using JS if the certificate is installed
>
> And how do you push the JS into the client?
>
> when client tries to fetch https://www.google.com/ and you don't have
> cert
> for www.google.com, answering with any other certificate by unknown
> authority will produce error before the JS is loaded.
>

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/9cf4f4d9/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/9cf4f4d9/attachment.sig>

From yvoinov at gmail.com  Mon Mar 26 15:53:40 2018
From: yvoinov at gmail.com (Yuri)
Date: Mon, 26 Mar 2018 21:53:40 +0600
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <20180326154117.GA8825@fantomas.sk>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <00a601d3c47a$7c67fbc0$7537f340$@ngtech.co.il>
 <20180326154117.GA8825@fantomas.sk>
Message-ID: <4c272ab6-4e1d-1acb-5d40-b68695dd802c@gmail.com>

Since the client should be involved, our business is to redirect him to
the instructions page where he will make a decision - whether to put a
proxy certificate or not. And on this page, in turn, is a script that
makes this task easier. But does not install the certificate
automatically - in this we came to a common opinion.

Or, we can simply send a link to this page to the user by e-mail - "Dear
user, we found that you are trying to access a secure site. To proceed,
please click on the link, otherwise access will not be granted in
accordance with our security policy "


26.03.2018 21:41, Matus UHLAR - fantomas ?????:
> On 25.03.18 23:47, Eliezer Croitoru wrote:
>> I do not know your level of JS or other thing but... a splash page is
>> mearly a transition step.
>> Since you can check using JS if the certificate is installed
>
> And how do you push the JS into the client?
>
> when client tries to fetch https://www.google.com/ and you don't have
> cert
> for www.google.com, answering with any other certificate by unknown
> authority will produce error before the JS is loaded.
>

-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/94a1e94e/attachment.sig>

From eliezer at ngtech.co.il  Mon Mar 26 17:37:48 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 26 Mar 2018 20:37:48 +0300
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <65a533ca-fc41-f5e1-7e8b-71fed7c0526a@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <00a601d3c47a$7c67fbc0$7537f340$@ngtech.co.il>
 <20180326154117.GA8825@fantomas.sk>
 <65a533ca-fc41-f5e1-7e8b-71fed7c0526a@gmail.com>
Message-ID: <023a01d3c529$289d6110$79d82330$@ngtech.co.il>

Yuri, If it requires then as many as it being asked...
What obvious to you might not be to others.
Have you ever found yourself wondering "What day is it today in the week?" or "Is there anything special today?"

Let say you got stuck on an island without any NTP server around but you get a computer that can access only a specific library of books.
You can focus on trying to figure out the time or day or date(I forgot to mention that on this island you do not have any knowledge or memory or way on how to estimate time)
and couple other things but you have a "dead line". You may or may not have company, so: would repeating things be always bad?

I have been asked this type of question for more then I can count in the last three decades and I believe that it's very important to understand that your point of view is never the same as the other.
Even if he declares that you and he or she are both on the same "page" there is always a doubt that it's not the exact page and I believe it's a blessing.
If we would all be on the same page it would be a very very weird world.

All The Bests,
Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Yuri
Sent: Monday, March 26, 2018 18:47
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] How to configure a "proxy home" page ?

Waaaaaaa, Matus,
the idea is trivial.
Catch SSL UNKNOWN ISSUER error on squid's acl and redirect by 302 to proxy page with instructions. Which requires user's involving.
How much can repeat the obvious ....

26.03.2018 21:41, Matus UHLAR - fantomas ?????:
On 25.03.18 23:47, Eliezer Croitoru wrote: 

I do not know your level of JS or other thing but... a splash page is mearly a transition step. 
Since you can check using JS if the certificate is installed 

And how do you push the JS into the client? 

when client tries to fetch https://www.google.com/ and you don't have cert 
for http://www.google.com, answering with any other certificate by unknown 
authority will produce error before the JS is loaded. 


-- 
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************



From carlos-24 at nauta.cu  Mon Mar 26 18:56:09 2018
From: carlos-24 at nauta.cu (Carlos)
Date: Mon, 26 Mar 2018 14:56:09 -0400
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <4c272ab6-4e1d-1acb-5d40-b68695dd802c@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <00a601d3c47a$7c67fbc0$7537f340$@ngtech.co.il>
 <20180326154117.GA8825@fantomas.sk>
 <4c272ab6-4e1d-1acb-5d40-b68695dd802c@gmail.com>
Message-ID: <BB8B399B-3470-4A71-88F8-568F26F23872@nauta.cu>

Hi, i want configure two squid... Squid son transparent and squid father the autentication.. How can i do that???? 
Ing.  Carlos
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180326/bc4fc371/attachment.htm>

From squidcache at mindchasers.com  Mon Mar 26 19:27:31 2018
From: squidcache at mindchasers.com (Bob Cochran)
Date: Mon, 26 Mar 2018 15:27:31 -0400
Subject: [squid-users] Google analytics screwing up a lot of sites?
Message-ID: <70787678-020c-6423-22d0-e35c2cdf88a8@mindchasers.com>

Hello,

We use squid 3.5.20 and a custom content filter to block undesirable 
(tracking) sites (e.g., google-analytics.com).

I noticed recently that many sites no longer work properly.? From 
testing, I attribute this to our blocking of either google-analytics.com 
or another google tracking URI.? I can? see blocked Google script tags & 
various errors in the browser's Javascript developer console.

It seems that Google's JavaScript ( or missing scripts ) is rendering 
various modal / dialog boxes useless (typically just see a blank modal 
and a spinning loading graphic).

I have recently seen this on BMW, Verizon, Arrow electronics, etc.? 
Shame on them all for tracking me.

Anybody have any thoughts on this?

I'm thinking that squid & our content filter is doing its job, and its 
Google that's creating havoc.

Thanks

Bob




From Walter.H at mathemainzel.info  Mon Mar 26 19:46:33 2018
From: Walter.H at mathemainzel.info (Walter H.)
Date: Mon, 26 Mar 2018 21:46:33 +0200
Subject: [squid-users] Google analytics screwing up a lot of sites?
In-Reply-To: <70787678-020c-6423-22d0-e35c2cdf88a8@mindchasers.com>
References: <70787678-020c-6423-22d0-e35c2cdf88a8@mindchasers.com>
Message-ID: <5AB94E19.9010004@mathemainzel.info>

Hello

On 26.03.2018 21:27, Bob Cochran wrote:
> We use squid 3.5.20 and a custom content filter to block undesirable 
> (tracking) sites (e.g., google-analytics.com).
get 3.5.27 ...
> It seems that Google's JavaScript ( or missing scripts ) is rendering 
> various modal / dialog boxes useless (typically just see a blank modal 
> and a spinning loading graphic).
this needn't be caused by this, it could be an invalid website admin not 
conforming to standards or just a broken browser
> I have recently seen this on BMW, Verizon, Arrow electronics, etc.  
> Shame on them all for tracking me.
do you mean   www.bmw.com with BMW?
here no problem, I do the same, blocking google analytics and some more ...
> I'm thinking that squid & our content filter is doing its job, and its 
> Google that's creating havoc.
my thought is just: when the damn website admin wants me to view his 
creation then he has to do it correct ...



From Antony.Stone at squid.open.source.it  Mon Mar 26 21:05:31 2018
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 26 Mar 2018 23:05:31 +0200
Subject: [squid-users] Different topic - was: How to configure a "proxy
	home" page ?
In-Reply-To: <BB8B399B-3470-4A71-88F8-568F26F23872@nauta.cu>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <4c272ab6-4e1d-1acb-5d40-b68695dd802c@gmail.com>
 <BB8B399B-3470-4A71-88F8-568F26F23872@nauta.cu>
Message-ID: <201803262305.31513.Antony.Stone@squid.open.source.it>

On Monday 26 March 2018 at 20:56:09, Carlos wrote:

> Hi, i want configure two squid... Squid son transparent and squid father
> the autentication.. How can i do that???? Ing.  Carlos

Please do not hijack threads (especially ones as long and tedious as this one 
has become).

Start a new thread and ask your question with an appropriate subject.

Give as much information as possible so that people can provide helpful 
answers.

In this case, for example, please specify what sort of authentication you wish 
to use, and why you are trying to use a "father - son" setup between two Squid 
proxies, rather than just a single proxy doing authentication.


Regards,


Antony.

-- 
Numerous psychological studies over the years have demonstrated that the 
majority of people genuinely believe they are not like the majority of people.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From Keith.Hartley at geocent.com  Tue Mar 27 01:24:49 2018
From: Keith.Hartley at geocent.com (Keith Hartley)
Date: Tue, 27 Mar 2018 01:24:49 +0000
Subject: [squid-users] Squid for windows Very slow downloads of large
 files through squid with normal uploads
In-Reply-To: <b7895004-fe3c-2ada-8bbb-9bb2fc507d98@gmail.com>
References: <BLUPR06MB1747D5BF0659E34BFE3FE7E6EEA90@BLUPR06MB1747.namprd06.prod.outlook.com>
 <f0bcf355-7068-0065-dd72-92b7eb937070@gmail.com>
 <SN1PR06MB175846A00C2B8602EB816BADEEA90@SN1PR06MB1758.namprd06.prod.outlook.com>
 <20180323085621.GA15687@fantomas.sk>
 <BLUPR06MB174732D6EB3641E51535883AEEA80@BLUPR06MB1747.namprd06.prod.outlook.com>
 <b7895004-fe3c-2ada-8bbb-9bb2fc507d98@gmail.com>
Message-ID: <BLUPR06MB17473790209439FCAB46C3A4EEAC0@BLUPR06MB1747.namprd06.prod.outlook.com>

Good recommendation on Privoxy. It took a few hours to get it installed, but most of that came from struggles configuring a work group server, missing a lot of the normal tools that I would have in a domain-joined server.

It took me maybe 30 minutes to figure out how to configure it and get it up and running and I think will definitely be more practical for implementing static screening of the 30-40 URIs that I need


Keith Hartley
Network Engineer II
khartley at geocent.com
www.geocent.com

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri
Sent: Friday, March 23, 2018 10:41 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for windows Very slow downloads of large files through squid with normal uploads



23.03.2018 21:25, Keith Hartley ?????:
> I had not thought to test that. I will do that today.
>
> In regards to Yuri's comments on firewall vs squid - I don?t agree that a firewall would be a direct replacement in this case.
>
> The 30-40 URIs I need to access resolve to a potential pool of several million IP addresses, and the pool of IP addresses gets updated multiple times per year. Writing rules at the network level would not be practical to implement even one time, let alone maintain over time. A more expensive firewall that is able to implement ACLs by hostname would be needed, and options for virtual firewalls hosted in Azure are limited. It would also require either implementing many static routes, or a transit network with a virtual router, and this environment will be supported by an organization that does not have a network engineer on staff.
It depends. If your make Internet access for servers due to updates - in most cases updates has limited distribution points (of course, we're not considering CDN now). Some cases can be easy solved by server's built-in firewall.

If we're talking about infrastructure, best solution for updates is internal updates server (like WSUS), which only have access to Internet with all security restrictions. You know this better than me ;) Anyway, centralized patch/updates server behind the border firewall is best solution.

But this is, of course, abstract discussion.
>
> I understand that there is very little functionality I need to leverage, but I like Squid, as it is a name that most people in IT will recognize and be able to google.
We're like it too, but Squid's itself is big and relatively complex software, requires much experience to use and not always easy in support. It has a lot of functions and can have very complex configurations. This is why I can't recommend use it in all cases requires proxying/caching without serious reasons.
>
> I may still review privoxy however. If it is simple enough that 
> supporting it would be something easy to just figure out with minimal 
> research, it may still be a good option. I like simple, but high 
> supportability is mandatory
Yes. Privoxy is very simple instead Squid. It is non-caching proxy, which have all functionality you require. It works with hostnames.

Don't worry - you will not require much support for it. It's just works. ;)
>
>
> Keith Hartley
> Network Engineer II
> khartley at geocent.com
> www.geocent.com
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
> On Behalf Of Matus UHLAR - fantomas
> Sent: Friday, March 23, 2018 3:56 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid for windows Very slow downloads of 
> large files through squid with normal uploads
>
> On 22.03.18 23:08, Keith Hartley wrote:
>> However on large files I am only getting 115 Kbps sustained download speeds.
> does this happen evben when you try using squid on the mavchine squid is installed?
>
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> I drive way too fast to worry about cholesterol.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> Confidentiality Notice:
> This email communication may contain confidential information, may be legally privileged, and is intended only for the use of the intended recipients(s) identified. Any unauthorized review, use, distribution, downloading, or copying of this communication is strictly prohibited. If you are not the intended recipient and have received this message in error, immediately notify the sender by reply email, delete the communication, and destroy all copies. Thank you.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

--
"C++ seems like a language suitable for firing other people's legs."

*****************************
* C++20 : Bug to the future *
*****************************



From squid3 at treenet.co.nz  Tue Mar 27 03:18:02 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 27 Mar 2018 16:18:02 +1300
Subject: [squid-users] delay-pool based on authentication
In-Reply-To: <op.zghkjoisek8y7k@mail.gmx.net>
References: <op.zgdzcrjrek8y7k@mail.gmx.net>
 <58c2477d-46b6-6dc7-b82c-cb3cf80328d1@gmail.com>
 <op.zghkjoisek8y7k@mail.gmx.net>
Message-ID: <9d4f8333-3bf8-cdce-9079-9dfb1541c50d@treenet.co.nz>

On 27/03/18 02:46, vvv25 at gmx.net wrote:
> Dear Yuri,
> 
> thank you for your quick reply.
> I spend weekend trying and testing some options.
> 
> My problem is, i cannot separate authenticated users from not
> authenticated.
> 

This is because
 a) nobody is allowed to even use the proxy unless they are
authenticated, and
 b) pool #2 affects all clients.


> Here in detail:
> if I try to do something like this
> ---- cut ----
> acl users proxy_auth "/etc/squid/users"
> http_access allow users
> 
> delay_pools 2
> 
> delay_class 1 1
> delay_parameters 1 -1/-1 # no limit
> 

This wastes a lot of CPU time and memory. It also does not set "no
limit". It sets this pool to unlimited bytes. Other pools can and will
limit these same clients.

To actually set "no limit" remove this pool, and use deny lines to
exclude the relevant transactions from having the other pools applied.


> delay_access 1 allow users
> delay_access 1 deny all
> 
> delay_class 2 3
> delay_parameters 2 -1/-1 -1/-1 196608/786432??? # no limit, no limit,
> 1.5 Mbit/s per user 6.0 Mbis/s once
> 
> delay_access 2 allow all

Use:
 delay_access 2 deny !users all


> ---- cut ----
> 
> then every user is asked for authentication. If they cancel that, they
> cannot access nothing.

This behaviour is what you configured with "http_access allow users".

If that is incorrect, skip the pools for a while and get your
http_access rules working first.

> 
> if I try to start with the restricted delay pool
> ---- cut ----
> delay_pools 2
> 
> delay_class 1 1
> delay_parameters 1 -1/-1 # no limit
> 
> delay_access 1 allow users
> delay_access 1 deny all
> 
> delay_class 2 3
> delay_parameters 2 -1/-1 -1/-1 196608/786432??? # no limit, no limit,
> 1.5 Mbit/s per user 6.0 Mbis/s once
> 
> delay_access 2 allow all
> 
> acl users proxy_auth "/etc/squid/users"
> http_access allow users
> ---- cut ----
> than every user is restricted and no query for authentication occurs.
> 
> How can I separate not authenticated users from authenticated?
> I cannot use IPs because all IPs are in the same range.

Depends on your Squid version.

This trick works with all Squid to deny non-authenticated users, but
only when used in the "slow" type access controls:

 acl loggedIn proxy_auth REQUIRED
 http_access deny !loggedIn all


The latest Squid versions retain a username annotation that can be
tracked independent of performing authentication and works anywhere
after authentication is checked:

 acl foo note user .*
 http_access deny !foo


Amos


From squid3 at treenet.co.nz  Tue Mar 27 03:24:31 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 27 Mar 2018 16:24:31 +1300
Subject: [squid-users] delay-pool based on authentication
In-Reply-To: <op.zghkr7ucek8y7k@mail.gmx.net>
References: <op.zgdzcrjrek8y7k@mail.gmx.net>
 <3d16c839-515b-d9ad-a29f-45a1d80f0ad3@treenet.co.nz>
 <op.zghkr7ucek8y7k@mail.gmx.net>
Message-ID: <cc7294ce-32d1-ea80-e880-034f562b6155@treenet.co.nz>

On 27/03/18 02:51, vvv25 wrote:
> Thank you for your time Amos,
> 
> the thing is, I want to have the connection to be restricted by default.
> May be I don't understand how to define acl's in the right order.
> Or I cannot figure out how to separate authenticated users from not
> authenticated.

You misunderstand. All pools which can match a transaction affect it. To
setup this "no restriction" for your certain clients you need to exclude
them from the restricted pools.

Setting them to have one restricted and one un-restricted does not help
- they will just get the minimum available bandwidth of the two.

Amos


From squid3 at treenet.co.nz  Tue Mar 27 03:29:18 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 27 Mar 2018 16:29:18 +1300
Subject: [squid-users] Different directory authentication depending on
 the network.
In-Reply-To: <d8e4a1172efc99c3.5ab92b96@ac-nancy-metz.fr>
References: <d8e4a1172efc99c3.5ab92b96@ac-nancy-metz.fr>
Message-ID: <d814be0f-d1fe-7710-cb8a-eeabd84dc896@treenet.co.nz>

On 27/03/18 04:19, Colle Christophe wrote:
> Hello,
> 
> I have a question about squid :
> 
> Several networks use the same Squid proxy server, in order to set up the
> authentication, I would like to know if it is possible to configure
> several directories according to the network of the client?

Maybe yes, maybe no.

What authentication can do depends on the type of authentication, the
auth helper being used, and the Squid version capabilities.

> 
> Or whether to create an instance of squid per network.
> 

That should not be necessary. But is the easiest quick solution if you
have the server capacity to do it.

Amos


From mika.ristimaki at gmail.com  Tue Mar 27 06:50:28 2018
From: mika.ristimaki at gmail.com (=?utf-8?Q?Mika_Ristim=C3=A4ki?=)
Date: Tue, 27 Mar 2018 09:50:28 +0300
Subject: [squid-users] Squid 4.0.x stable?
Message-ID: <a0c96594-22db-4bb5-8400-b06ddf6d0e4f@Spark>

Hi,

According to?http://www.squid-cache.org/Versions/?version 4.0.x is still in beta. Are there any timelines/plans when it becomes stable?


-Mika
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180327/53871fd7/attachment.htm>

From squid3 at treenet.co.nz  Tue Mar 27 08:19:39 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 27 Mar 2018 21:19:39 +1300
Subject: [squid-users] Squid 4.0.x stable?
In-Reply-To: <a0c96594-22db-4bb5-8400-b06ddf6d0e4f@Spark>
References: <a0c96594-22db-4bb5-8400-b06ddf6d0e4f@Spark>
Message-ID: <15243d36-3328-9eaf-6e55-6e5c67caf36a@treenet.co.nz>

On 27/03/18 19:50, Mika Ristim?ki wrote:
> Hi,
> 
> According to?http://www.squid-cache.org/Versions/?version 4.0.x is still
> in beta. Are there any timelines/plans when it becomes stable?
> 

We are now down to one major bug and one more recent regression to fix.
I'm hoping for a few weeks, but then the plan was to release it a year
ago now.

Amos


From mika.ristimaki at gmail.com  Tue Mar 27 12:31:03 2018
From: mika.ristimaki at gmail.com (=?utf-8?Q?Mika_Ristim=C3=A4ki?=)
Date: Tue, 27 Mar 2018 15:31:03 +0300
Subject: [squid-users] Squid 4.0.x stable?
In-Reply-To: <15243d36-3328-9eaf-6e55-6e5c67caf36a@treenet.co.nz>
References: <a0c96594-22db-4bb5-8400-b06ddf6d0e4f@Spark>
 <15243d36-3328-9eaf-6e55-6e5c67caf36a@treenet.co.nz>
Message-ID: <6bab4eac-7ceb-4577-809d-b97c0e6d2e74@Spark>

Thanks. I was trying to find these issues from?https://bugs.squid-cache.org/?but I couldn?t figure out how to do that. Could you pinpoint me to the issues that still need fixing? I guess the regression may be this?https://bugs.squid-cache.org/show_bug.cgi?id=4831?but I?m not sure.


-Mika

On 27 Mar 2018, 11.19 +0300, Amos Jeffries <squid3 at treenet.co.nz>, wrote:
> On 27/03/18 19:50, Mika Ristim?ki wrote:
> > Hi,
> >
> > According to?http://www.squid-cache.org/Versions/?version 4.0.x is still
> > in beta. Are there any timelines/plans when it becomes stable?
> >
>
> We are now down to one major bug and one more recent regression to fix.
> I'm hoping for a few weeks, but then the plan was to release it a year
> ago now.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180327/8b58d300/attachment.htm>

From acrow at integrafin.co.uk  Tue Mar 27 14:24:26 2018
From: acrow at integrafin.co.uk (Alex Crow)
Date: Tue, 27 Mar 2018 15:24:26 +0100
Subject: [squid-users] Assertion failed on Squid 4 when peer restarted.
Message-ID: <6b480552-daea-ec5b-dfca-c8999f98a134@integrafin.co.uk>

I have a squid 4.0.22 running peered with a 3.5.24 proxy. The latter 
machine stopped responding and I had to reboot it, and then the 4.0.22 
one crashed. Here's a log snippet:

2018/03/27 15:01:48 kid1| WARNING: failed to unpack metadata because 
store entry metadata is too big
2018/03/27 15:04:09 kid1| Detected DEAD Sibling: webproxy.ifa.net
2018/03/27 15:04:09 kid1| Detected REVIVED Sibling: webproxy.ifa.net
2018/03/27 15:06:01 kid1| Detected DEAD Sibling: webproxy.ifa.net
2018/03/27 15:06:01 kid1| Detected REVIVED Sibling: webproxy.ifa.net
2018/03/27 15:06:44 kid1| Error negotiating SSL connection on FD 216: 
(104) Connection reset by peer
2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 199: 
(104) Connection reset by peer
2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 169: 
(104) Connection reset by peer
2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 29: 
(104) Connection reset by peer
2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 188: 
(104) Connection reset by peer
2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 190: 
(104) Connection reset by peer
2018/03/27 15:07:12 kid1| Error negotiating SSL connection on FD 912: 
(104) Connection reset by peer
2018/03/27 15:07:13 kid1| Error negotiating SSL connection on FD 514: 
(104) Connection reset by peer
2018/03/27 15:07:26 kid1| ERROR: negotiating TLS on FD 236: 
error:00000000:lib(0):func(0):reason(0) (5/-1/104)

2018/03/27 15:07:41 kid1| Error negotiating SSL connection on FD 129: 
(104) Connection reset by peer
2018/03/27 15:08:17 kid1| assertion failed: store.cc:1690: "!mem_obj"

Any ideas?

Thanks,

Alex

--
This message is intended only for the addressee and may contain
confidential information. Unless you are that person, you may not
disclose its contents or use it in any way and are requested to delete
the message along with any attachments and notify us immediately.
This email is not intended to, nor should it be taken to, constitute advice.
The information provided is correct to our knowledge & belief and must not
be used as a substitute for obtaining tax, regulatory, investment, legal or
any other appropriate advice.

"Transact" is operated by Integrated Financial Arrangements Ltd.
29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax: (020) 7608 5300.
(Registered office: as above; Registered in England and Wales under
number: 3727592). Authorised and regulated by the Financial Conduct
Authority (entered on the Financial Services Register; no. 190856).


From uhlar at fantomas.sk  Tue Mar 27 17:05:49 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 27 Mar 2018 19:05:49 +0200
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <65a533ca-fc41-f5e1-7e8b-71fed7c0526a@gmail.com>
References: <64fbf476-2ba1-5a52-f773-dd96acbe3a50@microlinux.fr>
 <152a01d3c41b$c617b580$52472080$@ngtech.co.il>
 <f0e8a890-f522-66ed-fabb-316f779bc0ee@gmail.com>
 <c7e2edc0-0278-0750-2b46-2692ff3efecc@microlinux.fr>
 <00a601d3c47a$7c67fbc0$7537f340$@ngtech.co.il>
 <20180326154117.GA8825@fantomas.sk>
 <65a533ca-fc41-f5e1-7e8b-71fed7c0526a@gmail.com>
Message-ID: <20180327170549.GB14743@fantomas.sk>

On 26.03.18 21:47, Yuri wrote:
>Waaaaaaa, Matus,
>
>the idea is trivial.
>
>Catch SSL UNKNOWN ISSUER error on squid's acl and redirect by 302 to
>proxy page with instructions. Which requires user's involving.
>
>How much can repeat the obvious ....

you can't catch the "SSL UNKNOWN ISSUER" on squid, since it's a client error
(so squid can't see it) and it happens BEFORE squid sends ANYTHING to the
client.

>26.03.2018 21:41, Matus UHLAR - fantomas ?????:
>> On 25.03.18 23:47, Eliezer Croitoru wrote:
>>> I do not know your level of JS or other thing but... a splash page is
>>> mearly a transition step.
>>> Since you can check using JS if the certificate is installed
>>
>> And how do you push the JS into the client?
>>
>> when client tries to fetch https://www.google.com/ and you don't have
>> cert
>> for www.google.com, answering with any other certificate by unknown
>> authority will produce error before the JS is loaded.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Linux - It's now safe to turn on your computer.
Linux - Teraz mozete pocitac bez obav zapnut.


From uhlar at fantomas.sk  Tue Mar 27 17:19:56 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 27 Mar 2018 19:19:56 +0200
Subject: [squid-users] How to configure a "proxy home" page ?
In-Reply-To: <9d686a5e-4723-b2a1-9f8d-2c9b323c669b@gmail.com>
References: <7be514f0-756d-a680-138c-5f8f3bbd9af0@gmail.com>
 <6df8e33d-85a5-37e7-7938-cb3eec515f1f@treenet.co.nz>
 <791409df-944c-ef6d-fda7-30a335f77c69@gmail.com>
 <68346dcd-2711-d2d4-4c31-58512072600c@gmail.com>
 <59739641-f599-fa54-ab16-26a2b31b37a3@treenet.co.nz>
 <eadb6a3a-1e50-80da-523d-c50216c522e4@gmail.com>
 <E286ADE35F919742812E3076A36122E701BFCAA911@tdsnsumbx2vp>
 <9b071499-9071-b512-c8de-6a7ef06f48cd@gmail.com>
 <20180326153638.GC5681@fantomas.sk>
 <9d686a5e-4723-b2a1-9f8d-2c9b323c669b@gmail.com>
Message-ID: <20180327171956.GC14743@fantomas.sk>

>> On 26.03.18 19:16, Yuri wrote:
>>> SSH immediately notice you
>>> when server key surprisingly changed.

>26.03.2018 21:36, Matus UHLAR - fantomas ?????:
>> only when you already have the host key installed in your client. If
>> there's
>> MITM attack before you get the key, you will not notice that, unless you
>> get the key by other (secure) way.

On 26.03.18 21:45, Yuri wrote:
>By analogue with TLS - let's imagine I've already been on site. With SSH
>client notify me - "Hey, man, you trying to connect to server with ....
>fingerprint. Add it Yes/No?"
>
>Instead this, TLS never notify me if third-party CA is known to client.

TLS was designed with periodic key rollout after a time, while SSH was not.
you must take care of it manually, or not atall.

SSH was (apparently) designed with possibility of (semi-)physical access to the
server, so you can verify keys personally.

This is not applicable with TLS, where everyone should be able to
communicate with everyone.

this way SSH is more similar to PGP where users have to exchange their
public keys to be trusted.

(you can get keys from trusted friend which is in fact simmilar to CA).

>> unlike SSL, SSH was not designed to be used globally between everyone,
>> more
>> within one or more "friend" organizations, so it didn't specify how host
>> keys are verified (the SSHFP DNS record just transfers trust to DNS,
>> which
>> can be hijacked too).
>To be honest, a weak argument. A secure connection should always be
>encrypted end-to-end and should not "trusted" third-parties as well.
>Never. Otherwise it is insecure connection. IMHO.

the SSL is encrypted end-to-end. Trusted third-party CAs are just way to
avoid the need of everyone going to every company owning a site for the
server keys once in its lifetime (uaually a year).

even CA doesn't see your communication, unless they make the MITM attack
themselves.

>>> Yes, users is involved in both cases. However the difference still here.
>>> SSH is end-to-end always by design (we're not talking about things like
>>> Kerberos here), TLS is not.

>> TLS was designed to be end-to-end encryption and the certificate
>> authority

>As Stanislavsky said, "I do not believe it!"
>
>End-to-end encryption and the (/trusted third-party/) certificate
>authority these are antonyms.

Well, you can tell this to your clients but the main point - breaking into
users' communication that is supposed to be unbreakable by you - is
something you must explain to your clients and possibly to the lawyers.
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
We are but packets in the Internet of life (userfriendly.org)


From squid3 at treenet.co.nz  Wed Mar 28 01:17:50 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 28 Mar 2018 14:17:50 +1300
Subject: [squid-users] Squid 4.0.x stable?
In-Reply-To: <6bab4eac-7ceb-4577-809d-b97c0e6d2e74@Spark>
References: <a0c96594-22db-4bb5-8400-b06ddf6d0e4f@Spark>
 <15243d36-3328-9eaf-6e55-6e5c67caf36a@treenet.co.nz>
 <6bab4eac-7ceb-4577-809d-b97c0e6d2e74@Spark>
Message-ID: <5d659936-e05d-8204-ce1d-da71260e92cd@treenet.co.nz>

On 28/03/18 01:31, Mika Ristim?ki wrote:
> Thanks. I was trying to find these issues
> from?https://bugs.squid-cache.org/?but I couldn?t figure out how to do
> that. Could you pinpoint me to the issues that still need fixing? I
> guess the regression may be
> this?https://bugs.squid-cache.org/show_bug.cgi?id=4831?but I?m not sure.
> 

Yes, 4831 the regression and 4710 is the outstanding critical bug. There
is now 4840 too, but that is looking like the issue is maybe not a Squid
bug.

FYI: the "Open Bugs" section at the end of
<https://wiki.squid-cache.org/Squid-4> (or similar for each Squid
version) links to the two bug lists I work from. They are also on the
RoadMap page for beta and alpha/development versions.

Our release policy is that for Squid versions in beta all the second
list bugs ("new in this version") which are rated major/critical/blocker
have to be closed for the release to become candidate for production
release.
 <https://wiki.squid-cache.org/ReleaseProcess#General_Release_Process_Guidelines> Squid-4 is at step #3 in that process now.


Amos


From squid3 at treenet.co.nz  Wed Mar 28 01:22:43 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 28 Mar 2018 14:22:43 +1300
Subject: [squid-users] Assertion failed on Squid 4 when peer restarted.
In-Reply-To: <6b480552-daea-ec5b-dfca-c8999f98a134@integrafin.co.uk>
References: <6b480552-daea-ec5b-dfca-c8999f98a134@integrafin.co.uk>
Message-ID: <e03b491e-9ac1-b4db-64f0-02f220ed2748@treenet.co.nz>

On 28/03/18 03:24, Alex Crow wrote:
> I have a squid 4.0.22 running peered with a 3.5.24 proxy. The latter
> machine stopped responding and I had to reboot it, and then the 4.0.22
> one crashed. Here's a log snippet:
> 
> 2018/03/27 15:01:48 kid1| WARNING: failed to unpack metadata because
> store entry metadata is too big
> 2018/03/27 15:04:09 kid1| Detected DEAD Sibling: webproxy.ifa.net
> 2018/03/27 15:04:09 kid1| Detected REVIVED Sibling: webproxy.ifa.net
> 2018/03/27 15:06:01 kid1| Detected DEAD Sibling: webproxy.ifa.net
> 2018/03/27 15:06:01 kid1| Detected REVIVED Sibling: webproxy.ifa.net
> 2018/03/27 15:06:44 kid1| Error negotiating SSL connection on FD 216:
> (104) Connection reset by peer
> 2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 199:
> (104) Connection reset by peer
> 2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 169:
> (104) Connection reset by peer
> 2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 29:
> (104) Connection reset by peer
> 2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 188:
> (104) Connection reset by peer
> 2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 190:
> (104) Connection reset by peer
> 2018/03/27 15:07:12 kid1| Error negotiating SSL connection on FD 912:
> (104) Connection reset by peer
> 2018/03/27 15:07:13 kid1| Error negotiating SSL connection on FD 514:
> (104) Connection reset by peer
> 2018/03/27 15:07:26 kid1| ERROR: negotiating TLS on FD 236:
> error:00000000:lib(0):func(0):reason(0) (5/-1/104)
> 
> 2018/03/27 15:07:41 kid1| Error negotiating SSL connection on FD 129:
> (104) Connection reset by peer
> 2018/03/27 15:08:17 kid1| assertion failed: store.cc:1690: "!mem_obj"
> 
> Any ideas?
> 

First idea is to check bugzilla. I see nothing there.

Second is to upgrade to the latest v4 beta release (4.0.24 right now).

Third idea is to report to bugzilla or ask on squid-dev.

Amos


From eliezer at ngtech.co.il  Wed Mar 28 07:33:16 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 28 Mar 2018 10:33:16 +0300
Subject: [squid-users] SSL intercept in explicit mode
In-Reply-To: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
References: <CAHaQnLOkur6vJxNejCh-Hei54TQBSgx=yGfODYi+Mpar_xxXdQ@mail.gmail.com>
Message-ID: <01ee01d3c667$0a47b8c0$1ed72a40$@ngtech.co.il>

Hey Danilo,

 

I have tried to understand the issue and scenario from 0 but now I?m now sure I understood it.

What have achieved until now in your setup?

Any network can be ?simplified? in order to understand on what you do have control and what you do not.

>From your words:

?applications that dont support proxy - i.e. dont forward requests to proxy??

 

I understand that you are talking about some kind of client such as a browser or a other software.

Can you be more specific?

 

>From the older posts I understand it might involve ssl-bump but I am missing some details on the clients.

 

Please provide more details on your environment so we can somehow make a summery for your use case.

 

Thanks,

Eliezer

----

Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Danilo V
Sent: Tuesday, March 13, 2018 15:45
To: squid-users at lists.squid-cache.org
Subject: [squid-users] SSL intercept in explicit mode

 

Is it possible/feasible to configure squid in explicit mode with ssl intercept?

Due to architecture of my network it is not possible to implement transparent proxy.

What would be the behavior of applications that dont support proxy - i.e. dont forward requests to proxy?

Any guides?

 

Danilo

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180328/034f1cae/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180328/034f1cae/attachment.png>

From eliezer at ngtech.co.il  Wed Mar 28 07:36:45 2018
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 28 Mar 2018 10:36:45 +0300
Subject: [squid-users] Squid as Kerberos client?
In-Reply-To: <384e1ff9-6071-74eb-c79c-27ecf2e7b1ad@treenet.co.nz>
References: <CAH+7_B0r_1bHkrKrJfc=DxXaQEwONm5famaNJHY_KofD-dx1dg@mail.gmail.com>
 <97465F79-7694-4FD8-A50B-9DF67424F8D4@data-core.org>
 <CAH+7_B3hRJQ0sGh0XR+ft7MDSLiuE63x219F8baXGp1xRnn=eg@mail.gmail.com>
 <0A34C068-BF23-4AAA-B33F-C83529B625C7@data-core.org>
 <CAH+7_B2R6dti3UjtMr4k12WijbxBVYamPQxpOToKrEdhjOpJ+w@mail.gmail.com>
 <4d473798-898f-cdf4-73b1-970fe998e7d6@treenet.co.nz>
 <CAH+7_B06jvV7tvzcuSHEhYBdDdg9BZ=tR5H918zS35+RykVZ0A@mail.gmail.com>
 <d00622d2-31c3-d1ab-6b17-08c9f7fca851@treenet.co.nz>
 <CAH+7_B1NqZ_DGQTfBXA17BcDE4BAWPgAYcXKH9BhBUQf-4fnXQ@mail.gmail.com>
 <384e1ff9-6071-74eb-c79c-27ecf2e7b1ad@treenet.co.nz>
Message-ID: <020201d3c667$86366800$92a33800$@ngtech.co.il>

I yet to fully understand the scenario but I might have some ready to use services for some of these options.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Saturday, March 17, 2018 15:48
To: Patrick Nick <peedee.nick at gmail.com>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid as Kerberos client?

On 17/03/18 06:41, Patrick Nick wrote:
> Thank you. It doesn't seem that the "originserver" makes a difference to
> may case though.
> 
> I was able to resolve my issue after I understood that I forgot to pay
> attention to cookies. The API expects the client to use cookies, which I
> didn't do until now, which resulted in a continuous "401 Unauthorized" loop.
> 

Ah, Cookies. The bane of the Internet. They can be dealt with, but you
are not going to like the difficulty level.

Your choices AFAIK (in order of easiest to seriously tricky) are to
write an eCAP module, ICAP service, or custom external ACL helper(s)
with fairly complex squid.conf settings to use the latter.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From ahmed.zaeem at netstream.ps  Wed Mar 28 12:53:02 2018
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Wed, 28 Mar 2018 14:53:02 +0200
Subject: [squid-users] squid client or cache manager under Multi instance
	squid /SMP
Message-ID: <E9F65B2E-7632-42A9-8214-B7C720F74475@netstream.ps>

Hello Guys ,

i have no idea who to use squid client or cache manager when i have multiple instances of squid running .

say i have 2 instances 

squid -n 1 -f 1.conf
squid -n 2 -f 2.conf


all what i need is to see the request rate hitting each instance above .
how can i use the cache manager ?

is there an option for squid client app ?


more Q
if i have both ( multi instance with SMP say 4 workers )

how can i see the request rate on the total instance and request rate on the kids of this instance   ?



kind regards 

From thomas.schmiedl at web.de  Wed Mar 28 13:34:39 2018
From: thomas.schmiedl at web.de (Thomas Schmiedl)
Date: Wed, 28 Mar 2018 15:34:39 +0200
Subject: [squid-users] Squid proxychains problem
Message-ID: <6d74852e-75cc-460f-2f7c-38fe525edc45@web.de>

Hello,

I use xupnpd2 (http://xupnpd.org/xupnpd2_en.html) on my MIPS-based 
router to restream some HLS-streams from the internet to my TV. This app 
doesn't support https and has no proxy support. The author doesn't want 
to provide a newer version of xupnpd2.

I try to restream webcams from Skyline-webcams (e.g. 
http://www.skylinewebcams.com/de/webcam/czech-republic/prague/prague/old-town-bridge-tower.html), 
which uses https. But it's possible to receive the m3u8-file (the URL 
including query-string is in old-town-bridge-tower.html) in http. The 
m3u8-file contains https URLs (ts-video-files, which also can downloaded 
in http).

My idea is to use a filter proxy to replace the https URLs in the 
m3u8-file by http URLs. I use Squid 3.5.12 in Ubuntu 16 with these 
eCap-sample-adapter to replace "https" by "http" in the server response: 
http://www.e-cap.org/docs/ (victim=https and replacement=http).

A first test with a local http-server worked (URLs were replaced):
curl --proxy 127.0.0.1:3128 http://192.168.178.25:8080/live.m3u8

But with proxychains it doesn't work:
proxychains curl http://192.168.178.25:8080/live.m3u8

I also contacted the author of proxychains. He replied, I should use 
sniffing, but I have no sniffing experience.

Maybe someone in this mailing-list could help me?

Best regards,
Thomas


From alex at nanogherkin.com  Wed Mar 28 13:58:43 2018
From: alex at nanogherkin.com (Alex Crow)
Date: Wed, 28 Mar 2018 14:58:43 +0100
Subject: [squid-users] Assertion failed on Squid 4 when peer restarted.
In-Reply-To: <e03b491e-9ac1-b4db-64f0-02f220ed2748@treenet.co.nz>
References: <6b480552-daea-ec5b-dfca-c8999f98a134@integrafin.co.uk>
 <e03b491e-9ac1-b4db-64f0-02f220ed2748@treenet.co.nz>
Message-ID: <530e6610-f969-b3cb-5482-e1556e165f64@nanogherkin.com>

On 28/03/18 02:22, Amos Jeffries wrote:
> On 28/03/18 03:24, Alex Crow wrote:
>> I have a squid 4.0.22 running peered with a 3.5.24 proxy. The latter
>> machine stopped responding and I had to reboot it, and then the 4.0.22
>> one crashed. Here's a log snippet:
>>
>> 2018/03/27 15:01:48 kid1| WARNING: failed to unpack metadata because
>> store entry metadata is too big
>> 2018/03/27 15:04:09 kid1| Detected DEAD Sibling: webproxy.ifa.net
>> 2018/03/27 15:04:09 kid1| Detected REVIVED Sibling: webproxy.ifa.net
>> 2018/03/27 15:06:01 kid1| Detected DEAD Sibling: webproxy.ifa.net
>> 2018/03/27 15:06:01 kid1| Detected REVIVED Sibling: webproxy.ifa.net
>> 2018/03/27 15:06:44 kid1| Error negotiating SSL connection on FD 216:
>> (104) Connection reset by peer
>> 2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 199:
>> (104) Connection reset by peer
>> 2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 169:
>> (104) Connection reset by peer
>> 2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 29:
>> (104) Connection reset by peer
>> 2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 188:
>> (104) Connection reset by peer
>> 2018/03/27 15:06:57 kid1| Error negotiating SSL connection on FD 190:
>> (104) Connection reset by peer
>> 2018/03/27 15:07:12 kid1| Error negotiating SSL connection on FD 912:
>> (104) Connection reset by peer
>> 2018/03/27 15:07:13 kid1| Error negotiating SSL connection on FD 514:
>> (104) Connection reset by peer
>> 2018/03/27 15:07:26 kid1| ERROR: negotiating TLS on FD 236:
>> error:00000000:lib(0):func(0):reason(0) (5/-1/104)
>>
>> 2018/03/27 15:07:41 kid1| Error negotiating SSL connection on FD 129:
>> (104) Connection reset by peer
>> 2018/03/27 15:08:17 kid1| assertion failed: store.cc:1690: "!mem_obj"
>>
>> Any ideas?
>>
> First idea is to check bugzilla. I see nothing there.
>
> Second is to upgrade to the latest v4 beta release (4.0.24 right now).
>
> Third idea is to report to bugzilla or ask on squid-dev.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

I'll probably upgrade and if we still see it raise a BZ.

Cheers

Alex




From skupko.sk at gmail.com  Wed Mar 28 15:23:05 2018
From: skupko.sk at gmail.com (Peter Viskup)
Date: Wed, 28 Mar 2018 17:23:05 +0200
Subject: [squid-users] squid client or cache manager under Multi
 instance squid /SMP
In-Reply-To: <E9F65B2E-7632-42A9-8214-B7C720F74475@netstream.ps>
References: <E9F65B2E-7632-42A9-8214-B7C720F74475@netstream.ps>
Message-ID: <CAPa6PsGygJPumnTqeNwx7bcZY8hVq6oU1XTqmGV4LhjbcGuXgw@mail.gmail.com>

Hello Ahmad,
your instances should have different ports opened. Use squidclient's
options -p -h to request the appropriate instance.

Example from our server:

proxy02:/etc/squid $ squidclient -p 8080 cache_object://localhost/
mgr:info|grep "Start Time"
Start Time:     Thu, 22 Mar 2018 13:09:24 GMT
proxy02:/etc/squid $ squidclient -p 3128 cache_object://localhost/
mgr:info|grep "Start Time"
Start Time:     Fri, 23 Mar 2018 13:03:20 GMT

Not sure whether it is possible to get per-thread stats.

It also depends on the Squid's version as stated on wiki [1]. Only versions
3.5+ can be run as multi-instance with SMP enabled.
More information about how the load is distributed across SMP threads is on
another wiki page [2].

[1] https://wiki.squid-cache.org/MultipleInstances#SMP_enabled_Squid
[2]
https://wiki.squid-cache.org/Features/SmpScale#Who_decides_which_worker_gets_the_request.3F

-- 
Peter

On Wed, Mar 28, 2018 at 2:53 PM, --Ahmad-- <ahmed.zaeem at netstream.ps> wrote:

> Hello Guys ,
>
> i have no idea who to use squid client or cache manager when i have
> multiple instances of squid running .
>
> say i have 2 instances
>
> squid -n 1 -f 1.conf
> squid -n 2 -f 2.conf
>
>
> all what i need is to see the request rate hitting each instance above .
> how can i use the cache manager ?
>
> is there an option for squid client app ?
>
>
> more Q
> if i have both ( multi instance with SMP say 4 workers )
>
> how can i see the request rate on the total instance and request rate on
> the kids of this instance   ?
>
>
>
> kind regards
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180328/56e5fe6a/attachment.htm>

From vvv25 at gmx.net  Wed Mar 28 18:31:55 2018
From: vvv25 at gmx.net (vvv25 at gmx.net)
Date: Wed, 28 Mar 2018 20:31:55 +0200
Subject: [squid-users] delay-pool based on authentication
In-Reply-To: <cc7294ce-32d1-ea80-e880-034f562b6155@treenet.co.nz>
References: <op.zgdzcrjrek8y7k@mail.gmx.net>
 <3d16c839-515b-d9ad-a29f-45a1d80f0ad3@treenet.co.nz>
 <op.zghkr7ucek8y7k@mail.gmx.net>
 <cc7294ce-32d1-ea80-e880-034f562b6155@treenet.co.nz>
Message-ID: <op.zglm3hglek8y7k@mail.gmx.net>


> On 27/03/18 02:51, vvv25 wrote:
>> Thank you for your time Amos,
>>
>> the thing is, I want to have the connection to be restricted by default.
>> May be I don't understand how to define acl's in the right order.
>> Or I cannot figure out how to separate authenticated users from not
>> authenticated.
>
> You misunderstand. All pools which can match a transaction affect it. To
> setup this "no restriction" for your certain clients you need to exclude
> them from the restricted pools.
Oh, I see. Thank you for clarification.

> Setting them to have one restricted and one un-restricted does not help
> - they will just get the minimum available bandwidth of the two.

Yes, How then can I achieve following:
* limited access for non authenticated users (without credentials)
* unlimited access for those who have credentials ?

Is it possible with one instance of squid or do I have to configure 2  
instances
one with authentication on and
one with authentication off?

Or are there other ways to try?

Many thanks and best regards,

Vitaly


From squid3 at treenet.co.nz  Thu Mar 29 03:20:17 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Mar 2018 16:20:17 +1300
Subject: [squid-users] delay-pool based on authentication
In-Reply-To: <op.zglm3hglek8y7k@mail.gmx.net>
References: <op.zgdzcrjrek8y7k@mail.gmx.net>
 <3d16c839-515b-d9ad-a29f-45a1d80f0ad3@treenet.co.nz>
 <op.zghkr7ucek8y7k@mail.gmx.net>
 <cc7294ce-32d1-ea80-e880-034f562b6155@treenet.co.nz>
 <op.zglm3hglek8y7k@mail.gmx.net>
Message-ID: <804e9d55-dd9d-696f-8931-ff98bfb56565@treenet.co.nz>



On 29/03/18 07:31, vvv25 wrote:
> 
>> On 27/03/18 02:51, vvv25 wrote:
>>> Thank you for your time Amos,
>>>
>>> the thing is, I want to have the connection to be restricted by default.
>>> May be I don't understand how to define acl's in the right order.
>>> Or I cannot figure out how to separate authenticated users from not
>>> authenticated.
>>
>> You misunderstand. All pools which can match a transaction affect it. To
>> setup this "no restriction" for your certain clients you need to exclude
>> them from the restricted pools.
> Oh, I see. Thank you for clarification.
> 
>> Setting them to have one restricted and one un-restricted does not help
>> - they will just get the minimum available bandwidth of the two.
> 
> Yes, How then can I achieve following:
> * limited access for non authenticated users (without credentials)
> * unlimited access for those who have credentials ?

Yes, using the config pattern I gave in my first post to this thread.
Just replace the exclusion 'deny' with 'allow'.

"
Use:
  delay_access 2 allow !users all
"

> 
> Is it possible with one instance of squid or do I have to configure 2
> instances
> one with authentication on and
> one with authentication off?
> 

Of course.

> Or are there other ways to try?
> 

There are other ways as well. The most efficient is note ACLs which I
also mentioned in my first post.

Amos


From squid3 at treenet.co.nz  Thu Mar 29 03:36:31 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Mar 2018 16:36:31 +1300
Subject: [squid-users] Squid proxychains problem
In-Reply-To: <6d74852e-75cc-460f-2f7c-38fe525edc45@web.de>
References: <6d74852e-75cc-460f-2f7c-38fe525edc45@web.de>
Message-ID: <b94bc624-37d7-301a-8563-4adc302eb316@treenet.co.nz>

On 29/03/18 02:34, Thomas Schmiedl wrote:
> Hello,
> 
> I use xupnpd2 (http://xupnpd.org/xupnpd2_en.html) on my MIPS-based
> router to restream some HLS-streams from the internet to my TV. This app
> doesn't support https and has no proxy support. The author doesn't want
> to provide a newer version of xupnpd2.
> 

Well that sucks. Do you have any alternatives?


> I try to restream webcams from Skyline-webcams (e.g.
> http://www.skylinewebcams.com/de/webcam/czech-republic/prague/prague/old-town-bridge-tower.html),
> which uses https. But it's possible to receive the m3u8-file (the URL
> including query-string is in old-town-bridge-tower.html) in http. The
> m3u8-file contains https URLs (ts-video-files, which also can downloaded
> in http).
> 
> My idea is to use a filter proxy to replace the https URLs in the
> m3u8-file by http URLs. I use Squid 3.5.12 in Ubuntu 16 with these
> eCap-sample-adapter to replace "https" by "http" in the server response:
> http://www.e-cap.org/docs/ (victim=https and replacement=http).
> 
> A first test with a local http-server worked (URLs were replaced):
> curl --proxy 127.0.0.1:3128 http://192.168.178.25:8080/live.m3u8
> 

What I'm not clear on is why you think you need proxychains? a simple
DNAT intercept should do.

The eCAP plugin sounds like it is handling the embedded URL issues that
occur with re-writing for the xupnpd2 response traffic. All you should
need is a way to convert the http:// request URLs from xupnpd2 back into
https:// ones - in theory the eCAP adapter should do both alterations so
they reliably match up, otherwise a URL-rewrite helper can do this later
part.

Amos


From adamw at matrixscience.com  Thu Mar 29 15:24:11 2018
From: adamw at matrixscience.com (Adam Weremczuk)
Date: Thu, 29 Mar 2018 16:24:11 +0100
Subject: [squid-users] https proxy authentication
Message-ID: <1de18b37-385c-e20f-7feb-432fd403bcdf@matrixscience.com>

Hi all,

I have a solution in place with a dedicated squid LXC container (v 
3.1.20-2.2).
Both http and https proxy run on default port 3128.
Https in tunneled in http using CONNECT.
There is no authentication in place and both are working fine.

For testing purposes we also use an Apache (v 2.2.22-13) proxy forwarder 
running on a different machine on port 80 as "aproxy".

Config below:

/# Authenticated proxy for testing purposes//
//# We forward http/s requests to the local proxy server//
//ProxyRequests On//
//ProxyVia On//
//ProxyRemote http http://proxy.example.internal:3128//
//ProxyRemote https http://proxy.example.internal:3128//
//ProxyDomain .example.internal//
//NoProxy .example.internal 192.168.x.x/22//
//<Proxy *>//
//?? Order Deny,Allow//
//?? Deny from all//
//?? Allow from 192.168.x.x/22//
//?? AuthType Basic//
//?? AuthName ProxyAuth//
//?? AuthUserFile /etc/apache2/proxypasswd//
//?? Require valid-user//
//</Proxy>/

This is working as expected for http requests:

1. Unauthenticated (failure):

/$ http_proxy=http://aproxy:80//
//$ wget http://example.com 2>&1 | grep response//
//Proxy request sent, awaiting response... 407 Proxy Authentication 
Required/

2. Username with password (success):

/$ http_proxy=http://username1:password at aproxy:80//
//$ wget http://example.com 2>&1 | grep response//
//Proxy request sent, awaiting response... 200 OK/

3. Username without password (success):
/
//$ http_proxy=http://username2:@aproxy:80//
//$ wget http://example.com 2>&1 | grep response//
//Proxy request sent, awaiting response... 200 OK/

My *PROBLEM* is I can't find a way to use authentication for proxied 
https requests.

 From a LAN client trying to establish connection:

/$ echo $http_proxy//
//http://username1:password at aproxy:80//
/

/$ echo $https_proxy//
//http://username1:password at aproxy:80//
/

/$ wget --server-response https://example.com 2>&1//
//--2018-03-29 15:20:44--? https://example.com///
//Resolving aproxy (aproxy)... 192.168.x.x//
//Connecting to aproxy (aproxy)|192.168.x.x|:80... connected.//
//Proxy tunneling failed: Service Temporarily UnavailableUnable to 
establish SSL connection./

On "aproxy" only one line in apache error log (even in debug mode):

/[Thu Mar 29 15:21:59 2018] [error] (111)Connection refused: proxy: 
CONNECT: attempt to connect to 93.184.216.34:443 (example.com) failed/

Nothing is logged on squid "proxy" which is the next hop.

What's the easiest way to enable authenticated https proxying?
I don't want to enable it for our main production proxy:3128
Or maybe it's already supposed to work but I'm missing something?

Please advise.

Thanks
Adam

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20180329/937aaa92/attachment.htm>

From teapot at hexistentialist.com  Thu Mar 29 23:01:05 2018
From: teapot at hexistentialist.com (teapot)
Date: Thu, 29 Mar 2018 16:01:05 -0700 (MST)
Subject: [squid-users] ssl intercept and forward to privoxy
Message-ID: <1522364465118-0.post@n4.nabble.com>

Hi, I'm attempting to set up squid to perform SSL interception and route its
traffic through tor, and I'm a bit stuck. I've started with  this guide
<https://wiki.vpsget.com/index.php/Squid+Privoxy+Tor>  .

This works for HTTP traffic, but does not work for SSL; for the latter I get
the error 'kid1| assertion failed: PeerConnector.cc:116: "peer->use_ssl"'
from squid; however if I add the 'ssl' directive to the cache_peer, neither
type of connection will work.

Is privoxy truly required for this? If I have understood  this thread
<http://squid-web-proxy-cache.1019090.n4.nabble.com/ERR-CANNOT-FORWARD-with-Squid-Privoxy-td4681111.html>  
correctly, once the CONNECT is received by squid it cannot then recreate
that command to a peer and the SSL connection will fail. However, the only
other discussions of this topic I have found say that squid cannot send
directly to a listening tor service.

squid v3.5.23 on Debian Stretch, privoxy 3.0.26, tor 0.2.9.14



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Fri Mar 30 01:30:52 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Mar 2018 14:30:52 +1300
Subject: [squid-users] ssl intercept and forward to privoxy
In-Reply-To: <1522364465118-0.post@n4.nabble.com>
References: <1522364465118-0.post@n4.nabble.com>
Message-ID: <c97c5efd-d473-e7d6-8a6b-37f5a38270c5@treenet.co.nz>

On 30/03/18 12:01, teapot wrote:
> Hi, I'm attempting to set up squid to perform SSL interception and route its
> traffic through tor, and I'm a bit stuck. I've started with  this guide
> <https://wiki.vpsget.com/index.php/Squid+Privoxy+Tor>  .
> 
> This works for HTTP traffic, but does not work for SSL; for the latter I get
> the error 'kid1| assertion failed: PeerConnector.cc:116: "peer->use_ssl"'
> from squid; however if I add the 'ssl' directive to the cache_peer, neither
> type of connection will work.

HTTPS requires a secure connections. You cannot send it as plain-text.

Apparently privoxy does not support receiving TLS.


> 
> Is privoxy truly required for this? If I have understood  this thread
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/ERR-CANNOT-FORWARD-with-Squid-Privoxy-td4681111.html>  
> correctly, once the CONNECT is received by squid it cannot then recreate
> that command to a peer and the SSL connection will fail. However, the only
> other discussions of this topic I have found say that squid cannot send
> directly to a listening tor service.

Yes. TOR protocol is not HTTP protocol nor is it HTTPS protocol.

Amos


From squid3 at treenet.co.nz  Fri Mar 30 01:44:07 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Mar 2018 14:44:07 +1300
Subject: [squid-users] https proxy authentication
In-Reply-To: <1de18b37-385c-e20f-7feb-432fd403bcdf@matrixscience.com>
References: <1de18b37-385c-e20f-7feb-432fd403bcdf@matrixscience.com>
Message-ID: <93199834-4908-fc81-af85-79f017539112@treenet.co.nz>

On 30/03/18 04:24, Adam Weremczuk wrote:
> Hi all,
> 
> I have a solution in place with a dedicated squid LXC container (v
> 3.1.20-2.2).
> Both http and https proxy run on default port 3128.
> Https in tunneled in http using CONNECT.

That tunnel existing means Squid has no part in any of the HTTPS
requests. It cannot perform authentication of them.

What it can do is request authentication of the CONNECT message, but
once that is accepted or rejected Squids part is over.


> There is no authentication in place and both are working fine.
> 
> For testing purposes we also use an Apache (v 2.2.22-13) proxy forwarder
> running on a different machine on port 80 as "aproxy".
> 

So, the big question is why you have this setup of Apache being a
reverse-proxy for a Squid forward-proxy?

Forward-proxy are supposed to be between clients and reverse-proxies or
origins. Not the other way around.


What are you actually trying to achieve here?


Amos


From squid3 at treenet.co.nz  Fri Mar 30 07:36:03 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Mar 2018 20:36:03 +1300
Subject: [squid-users] squid client or cache manager under Multi
	instance squid /SMP
In-Reply-To: <E9F65B2E-7632-42A9-8214-B7C720F74475@netstream.ps>
References: <E9F65B2E-7632-42A9-8214-B7C720F74475@netstream.ps>
Message-ID: <5592daa6-8246-9fb3-aa2d-a98539cc3a40@treenet.co.nz>

On 29/03/18 01:53, --Ahmad-- wrote:
> Hello Guys ,
> 
> i have no idea who to use squid client or cache manager when i have multiple instances of squid running .
> 
> say i have 2 instances 
> 
> squid -n 1 -f 1.conf
> squid -n 2 -f 2.conf
> 
> 
> all what i need is to see the request rate hitting each instance above .
> how can i use the cache manager ?

Send the manager requests to a port on the instance you are trying to
get a report from.

If you are using cachemgr.cgi configure it as if each instance was a
different server with separate IP:port's.


> 
> is there an option for squid client app ?
> 

You means "squidclient" ? or any client?


> 
> more Q
> if i have both ( multi instance with SMP say 4 workers )
> 
> how can i see the request rate on the total instance and request rate on the kids of this instance   ?
> 

SMP Squid are supposed to support "kid=N" query parameters on their
manager URLs that get just that worker (kid) data. But I'm not sure that
works properly.

Amos


From vvv25 at gmx.net  Fri Mar 30 12:38:57 2018
From: vvv25 at gmx.net (vvv25 at gmx.net)
Date: Fri, 30 Mar 2018 14:38:57 +0200
Subject: [squid-users] delay-pool based on authentication
In-Reply-To: <804e9d55-dd9d-696f-8931-ff98bfb56565@treenet.co.nz>
References: <op.zgdzcrjrek8y7k@mail.gmx.net>
 <3d16c839-515b-d9ad-a29f-45a1d80f0ad3@treenet.co.nz>
 <op.zghkr7ucek8y7k@mail.gmx.net>
 <cc7294ce-32d1-ea80-e880-034f562b6155@treenet.co.nz>
 <op.zglm3hglek8y7k@mail.gmx.net>
 <804e9d55-dd9d-696f-8931-ff98bfb56565@treenet.co.nz>
Message-ID: <op.zgov27jzek8y7k@mail.gmx.net>

Thank you very much for support!

> Yes, using the config pattern I gave in my first post to this thread.
> Just replace the exclusion 'deny' with 'allow'.
>
> "
> Use:
>   delay_access 2 allow !users all
> "
This didn't work for me because users have to be authenticated first.
So I configured 2 instances now.

>> Is it possible with one instance of squid or do I have to configure 2
>> instances
>> one with authentication on and
>> one with authentication off?
>>
>
> Of course.
And this works fine for now. Thanks again!

Regards,
Vitaly


From squid at buglecreek.com  Fri Mar 30 22:41:32 2018
From: squid at buglecreek.com (squid at buglecreek.com)
Date: Fri, 30 Mar 2018 16:41:32 -0600
Subject: [squid-users] Disable SSLv3 Not working
Message-ID: <1522449692.1151928.1321764560.7E6B762F@webmail.messagingengine.com>

We are using squid as reverse proxy and we have disabled SSLv3 :

https_port XXX.XXX.XXX.XXX:443 accel defaultsite=www.example.com vhost cert=/etc/....cert.pem key=/etc/....privkey.pem options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,CIPHER_SERVER_PREFERENCE cipher=ECDHE-ECDSA . . .. dhparams=/etc/...dhparams.pem

Using Nessus scanning tool, it reports that SSLv3 is enabled, but not SSLv2.   Looking at the ssl handshake client hello and server hellos is does seem that the sslv3 is being used.  Is there something that we are missing?

Version of Squid  (3.1) is stock RH6 which I know is old, but for now we need to use.  We will be upgrading to RH7, but it may be a little while so I'd like to get this solved. 

Secure Sockets Layer
    SSLv3 Record Layer: Handshake Protocol: Server Hello
        Content Type: Handshake (22)
        Version: SSL 3.0 (0x0300)
        Length: 74
        Handshake Protocol: Server Hello
            Handshake Type: Server Hello (2)
            Length: 70
            Version: SSL 3.0 (0x0300)
            Random: 5aa83ae26555f6dcc7042c341d090c6715a243a7be05d69b...
            Session ID Length: 32
            Session ID: 44bb10e985c067cc987bf2e698d458dd37d2b3c469ce9fe7...
            Cipher Suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA (0x0039)
            Compression Method: null (0)


From squid3 at treenet.co.nz  Sat Mar 31 02:29:45 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 31 Mar 2018 15:29:45 +1300
Subject: [squid-users] Disable SSLv3 Not working
In-Reply-To: <1522449692.1151928.1321764560.7E6B762F@webmail.messagingengine.com>
References: <1522449692.1151928.1321764560.7E6B762F@webmail.messagingengine.com>
Message-ID: <106f40f1-b0a2-0f6f-8866-4f67d2023279@treenet.co.nz>

On 31/03/18 11:41, squid wrote:
> We are using squid as reverse proxy and we have disabled SSLv3 :
> 
> https_port ... options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,CIPHER_SERVER_PREFERENCE cipher=ECDHE-ECDSA . . .. dhparams=/etc/...dhparams.pem

NP: Squid-3.5 or later is required for EC cipher support.


> 
> Using Nessus scanning tool, it reports that SSLv3 is enabled, but not SSLv2.   Looking at the ssl handshake client hello and server hellos is does seem that the sslv3 is being used.  Is there something that we are missing?
> 
> Version of Squid  (3.1) is stock RH6 which I know is old, but for now we need to use.  We will be upgrading to RH7, but it may be a little while so I'd like to get this solved. 
> 
> Secure Sockets Layer
>     SSLv3 Record Layer: Handshake Protocol: Server Hello
>         Content Type: Handshake (22)
>         Version: SSL 3.0 (0x0300)
>         Length: 74
>         Handshake Protocol: Server Hello
>             Handshake Type: Server Hello (2)
>             Length: 70
>             Version: SSL 3.0 (0x0300)
>             Random: 5aa83ae26555f6dcc7042c341d090c6715a243a7be05d69b...
>             Session ID Length: 32
>             Session ID: 44bb10e985c067cc987bf2e698d458dd37d2b3c469ce9fe7...
>             Cipher Suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA (0x0039)
>             Compression Method: null (0)

Which of the TCP connections was that hello performed on?

You have apparently only disabled SSLv3 on the client->Squid connection.
No information is provided about the Squid->server settings
(sslproxy_options).


Also, these options are handled by OpenSSL. They only work if the
library Squid was built against supports them.

Amos


