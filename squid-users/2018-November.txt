From squid3 at treenet.co.nz  Thu Nov  1 04:03:59 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 1 Nov 2018 17:03:59 +1300
Subject: [squid-users] ERROR The requested URL could not be retrieved
In-Reply-To: <CAHgpA+LeHwM9p4C3hsATBuHqw4rtJM8WiSZwg1_E643DJ+puwQ@mail.gmail.com>
References: <CAHgpA+JZ1NX_JJD2py+YNtRn2-_hmw2Nfw=okAqhmRomP+LxGw@mail.gmail.com>
 <188c5209-d67d-c28b-4702-b28b2d874a6c@borrill.org.uk>
 <2e71134a-69f7-fc7b-ad27-6c9b1cd0c7b8@treenet.co.nz>
 <CAHgpA++u4BZuAqLJKmcqGnc-Bb287Gzb=fQ-C2K+6OQ3_B3ygQ@mail.gmail.com>
 <e8ba2952-42be-84da-c138-c384f0f7d3e7@treenet.co.nz>
 <CAHgpA+LeHwM9p4C3hsATBuHqw4rtJM8WiSZwg1_E643DJ+puwQ@mail.gmail.com>
Message-ID: <0cb82f1d-271c-ae47-2228-680bea4c61c0@treenet.co.nz>

On 1/11/18 4:08 AM, Uchenna Nebedum wrote:
> Thanks a lot Amos, I really didn't notice I had been sending private
> emails, Really sorry about that.?
> 
> About the config, The proxy works fine now, it bumps the traffic
> successfully.
> I've added the sites i want to be bumped but the browser errors thrown
> are too much, and it's a scenario where I can't install the certificate
> on every device.

In that case you already have it going as well as it will ever do for
this setup. Having the certificate installed on the device is the only
way to prevent the warning messages. The whole point of TLS is to
generate those warnings when an unknown or untrusted CA is used.

Amos


From squid3 at treenet.co.nz  Thu Nov  1 04:13:19 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 1 Nov 2018 17:13:19 +1300
Subject: [squid-users] redirect based on url (302)
In-Reply-To: <1540981640859-0.post@n4.nabble.com>
References: <1537541034108-0.post@n4.nabble.com>
 <dde485b6-5742-d424-8e12-f700d0b975f2@treenet.co.nz>
 <1537771119646-0.post@n4.nabble.com>
 <f35964b6-e83b-c5b6-5563-602ab666d964@treenet.co.nz>
 <1540305071062-0.post@n4.nabble.com>
 <a2ca5119-39c1-c744-0e8b-6373f7f525a3@treenet.co.nz>
 <1540900144095-0.post@n4.nabble.com>
 <23b5e473-3671-b473-572d-19a25daaefe8@treenet.co.nz>
 <1540981640859-0.post@n4.nabble.com>
Message-ID: <c2ae6317-8fb0-4136-0761-83c7280a139b@treenet.co.nz>

On 31/10/18 11:27 PM, uppsalanet wrote:
> Hi Amos,
> Is there a git that I can use to push stuff up?
> 

Do you mean to make a change PR against the official code?

The key details for people wanting to assist with Squid development are
linked from here: <https://wiki.squid-cache.org/DeveloperResources>



> I think you need to split the string in an other way, look into this
> example:
> #!/usr/bin/perl
> use strict;
> use warnings;
> 
> $|=1;
> while (<>) {
>      my $string = $_;
>      print "Received '\$_' = ".$_."\n";       
> 
>      $string =~ m/^(\d+)\s(.*)$/;
>      print "After regexp '\$string' = ".$string."\n";
>      print "After regexp '\$1' = ".$1."\n";           
>      print "After regexp '\$2' = ".$2."\n"; 
> 
>      ### Original split from sorce ###
>      ### This doesn't split anything looks like elements of an array?
>      #my ($cid, $uid) = ($1, $2);
>     
>      ### Split the string ###
>      ### Those two split based on one or more spaces
>      #my ($cid, $uid) = split(/\s+/ ,$_);
>      my ($cid, $uid) = split;
>      $cid =~ s/%(..)/pack("H*", $1)/ge;
>      $uid =~ s/%(..)/pack("H*", $1)/ge;
>      print "After split \$cid = ".$cid."\n";
>      print "After split \$uid = ".$uid."\n";
> }
> 
> Output from above with intake value '*130.238.000.00 muse.jhu.edu -*':
> Received '$_' = 130.238.000.00 muse.jhu.edu -
> After regexp '$string' = 130.238.000.00 muse.jhu.edu -
> /Use of uninitialized value $1 in concatenation (.) or string at
> ./sed_test_reg.pl line 13, <> line 1.
> After regexp '$1' = 
> Use of uninitialized value $2 in concatenation (.) or string at
> ./sed_test_reg.pl line 14, <> line 1.
> After regexp '$2' = /
> *After split $cid = 130.238.000.00
> After split $uid = muse.jhu.edu*
> 


$cid should be the concurrency channel ID.  Configured with the
"concurrency=N" option to external_acl_type in squid.conf. (Seems I
missed another bit of the config.)

If you are wanting to assist with fixing the helper, it could do with a
change to auto-detect whether the first column is a CID (numeric only)
or not (anything but whitespace following a numeral).


Amos


From SIDDH05 at gmail.com  Thu Nov  1 04:55:35 2018
From: SIDDH05 at gmail.com (Sid)
Date: Wed, 31 Oct 2018 23:55:35 -0500 (CDT)
Subject: [squid-users] Squid 4.3: SSL Bump fails to send client
	certificate
In-Reply-To: <407e2dc2-0473-46ed-469f-e2d8da2d0326@measurement-factory.com>
References: <1540888595659-0.post@n4.nabble.com>
 <6a396e03-e800-3dab-2ea8-97342edff1c7@measurement-factory.com>
 <1540961958277-0.post@n4.nabble.com>
 <407e2dc2-0473-46ed-469f-e2d8da2d0326@measurement-factory.com>
Message-ID: <1541048135029-0.post@n4.nabble.com>

Thank you Alex.

>Sounds good. Does the generated fake certificate contain the right origin
server name? 
Sid: Yes, It does contain correct IP Address in Server name sent by client.
 

>Why do you expect the client to send a client certificate to Squid? In most
deployments, TLS servers do not request client certificates and, hence, TLS
clients do not send client certificates. IIRC, you did not configure your
Squid to request a client certificate from the client? 

>Or is there a terminology problem where "client certificate sent to 
Squid" means something other than "an x509 certificate requested by a 
TLS server and sent to that server by a TLS client during TLS 
handshake"? Please note that Squid is a TLS server in this context. 

Sid: Actually in my case Server is looking for a certificate to be sent by
client; it isn't a Web Server but SBC looking for a certificate sent by
a client to grant further voice & video call. How to configure Squid to get
this certificate from client for mutual authentication?

>Perhaps the alert may not be related to certificate validation. If you want
to verify whether UCAppsCA.pem is enough to trust the origin server, you can
use "curl" or "openssl s_client" tools for a test. They should fail to
validate the server when not configured to use UCAppsCA.pem and they should
succeed otherwise. 

Sid: I have tried following which shows "Verify return code: 0 (ok)":
openssl s_client -connect <Server FQDN>:443 -CAfile
/usr/local/squid/etc/UCAppsCA.pem






--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Thu Nov  1 08:49:40 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 1 Nov 2018 21:49:40 +1300
Subject: [squid-users] Squid 4.3: SSL Bump fails to send client
 certificate
In-Reply-To: <1541048135029-0.post@n4.nabble.com>
References: <1540888595659-0.post@n4.nabble.com>
 <6a396e03-e800-3dab-2ea8-97342edff1c7@measurement-factory.com>
 <1540961958277-0.post@n4.nabble.com>
 <407e2dc2-0473-46ed-469f-e2d8da2d0326@measurement-factory.com>
 <1541048135029-0.post@n4.nabble.com>
Message-ID: <ec8ef08c-030f-42ff-c15e-c34706d01a8a@treenet.co.nz>

On 1/11/18 5:55 PM, Sid wrote:
> Thank you Alex.
> 
>> Sounds good. Does the generated fake certificate contain the right origin
> server name? 
> Sid: Yes, It does contain correct IP Address in Server name sent by client.
>  

Alex asked about *name*. IP address is not part of the considerations
because using a raw-IP is not valid for SNI. Even though having one in
the cert "name" is valid it is not supposed to happen either.

Also by "right" he means that Squid is passing on either the *same* name
value from the client SNI (bumping at step 2) or from the real server
provided certificate (bumping at step 3).


> 
>> Why do you expect the client to send a client certificate to Squid? In most
> deployments, TLS servers do not request client certificates and, hence, TLS
> clients do not send client certificates. IIRC, you did not configure your
> Squid to request a client certificate from the client? 
> 
>> Or is there a terminology problem where "client certificate sent to 
> Squid" means something other than "an x509 certificate requested by a 
> TLS server and sent to that server by a TLS client during TLS 
> handshake"? Please note that Squid is a TLS server in this context. 
> 
> Sid: Actually in my case Server is looking for a certificate to be sent by
> client; it isn't a Web Server but SBC looking for a certificate sent by
> a client to grant further voice & video call. How to configure Squid to get
> this certificate from client for mutual authentication?


Configure clientca= on the http(s)_port directive.
see <http://www.squid-cache.org/Doc/config/http_port/>

IIRC that should work when SSL-Bump functionality re-purposes the
cafile= option which was supposed to be the CA for client certificates.


> 
>> Perhaps the alert may not be related to certificate validation. If you want
> to verify whether UCAppsCA.pem is enough to trust the origin server, you can
> use "curl" or "openssl s_client" tools for a test. They should fail to
> validate the server when not configured to use UCAppsCA.pem and they should
> succeed otherwise. 
> 
> Sid: I have tried following which shows "Verify return code: 0 (ok)":
> openssl s_client -connect <Server FQDN>:443 -CAfile
> /usr/local/squid/etc/UCAppsCA.pem
> 



Amos



From rousskov at measurement-factory.com  Thu Nov  1 16:40:57 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 1 Nov 2018 10:40:57 -0600
Subject: [squid-users] Squid 4.3: SSL Bump fails to send client
 certificate
In-Reply-To: <1541048135029-0.post@n4.nabble.com>
References: <1540888595659-0.post@n4.nabble.com>
 <6a396e03-e800-3dab-2ea8-97342edff1c7@measurement-factory.com>
 <1540961958277-0.post@n4.nabble.com>
 <407e2dc2-0473-46ed-469f-e2d8da2d0326@measurement-factory.com>
 <1541048135029-0.post@n4.nabble.com>
Message-ID: <513e5713-510a-ed8c-56a6-fd8e58c16e31@measurement-factory.com>

On 10/31/18 10:55 PM, Sid wrote:

> Actually in my case Server is looking for a certificate to be sent by
> client; How to configure Squid to get
> this certificate from client for mutual authentication?

It is technically impossible to meaningfully forward a client
certificate to the origin server when _bumping_ connections, and, hence,
Squid cannot support such forwarding. You should be able to configure a
bumping Squid to send its own client certificate to the origin server
though; see tls_outgoing_options cert=... key=....

The question is, can you give Squid the same client certificate as used
by your client?

* If that client certificate is the same for all from-Squid traffic, you
have access to the client certificate key, and you can store that key
securely on the Squid server, then the answer is probably "yes". It
would not be true "forwarding", but the origin server will get the
certificate it expects, and Squid will be able to send the right TLS
CertificateVerify message to prove that Squid has the private key.

* Otherwise, the answer is probably "no", and you cannot use client
certificate-based authentication with the origin server while bumping
connections. Whether it is possible to support that by enhancing Squid
would depend on which precondition(s) in the first bullet are not
satisfied. For example, it is possible to enhance Squid to select from a
list of client certificates when bumping a server connection.


HTH,

Alex.


From jose.rodriguez at cenpalab.cu  Thu Nov  1 20:03:16 2018
From: jose.rodriguez at cenpalab.cu (=?UTF-8?Q?Jos=c3=a9_J._Rodriguez?=)
Date: Thu, 1 Nov 2018 16:03:16 -0400
Subject: [squid-users] Ubuntu 18 LTS repository for Squid 4.4 (rebuilt
 with sslbump support from sources in Debian unstable)
In-Reply-To: <AM0PR04MB4753B39F948558DB3C372AEC8FCD0@AM0PR04MB4753.eurprd04.prod.outlook.com>
References: <AM0PR04MB4753B39F948558DB3C372AEC8FCD0@AM0PR04MB4753.eurprd04.prod.outlook.com>
Message-ID: <954b3c1a-cd73-edb3-eb4c-ab97b8ef795b@cenpalab.cu>

Rafael Akchurin wrote:
> Greeting all,
> 
> The online repository with latest Squid 4.4 (rebuilt from Debian 
> unstable with sslbump support) for Ubuntu 18 LTS 64-bit is available at 
> squid44.diladele.com. Github repo at 
> https://github.com/diladele/squid-ubuntu contains the scripts we used to 
> make this compilation.
> 

Hi:

Will this work on Debian 9.X?

Regards,
Joe1962


From Shane.Poage at entrustdatacard.com  Thu Nov  1 20:46:36 2018
From: Shane.Poage at entrustdatacard.com (Shane Poage)
Date: Thu, 1 Nov 2018 20:46:36 +0000
Subject: [squid-users] URL Regex ACLs Don't Evaluate After Bumping
Message-ID: <56F1E161-4DC0-42CF-A1D7-99DAA0782DA5@entrustdatacard.com>

Hello,

I have a proxy configured to bump all traffic in order to do traffic filtering to a target server (Artifactory, in my case) from a particular environment. The proxy needs to be able to allow or permit traffic based on the path part of the URL in order to only allow access to a certain set of Artifactory repositories. I have my proxy configured to bump all traffic so that the urlpath_regex ACL can be applied, but it appears to not have any effect post-bump. I have dug through the debug logging and it evaluates the ACL before the bump occurs, but not after. I know it's bumping and decrypting the request properly because the access logs shows the information I need, but it's not actually applying the ACL.

Can anybody provide recommendations as to what I might be doing wrong? My (highly simplified, to remove possible points of failure) squid.conf is provided below, as well as the debug logs from a couple of sample requests.

Thanks,
-Shane

----  squid.conf ----------------------------
# enable ACL debug logging
debug_options 28,3

# Configure a man-in-the-middle sslbumping strategy
http_port 3128 ssl-bump \
  cert=/etc/squid/ssl_certs/artifactory_mitm_ca.pem \
  generate-host-certificates=on \
  dynamic_cert_mem_cache_size=4MB

sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB

ssl_bump bump all

# Additional custom ACLs
acl artifactory_repo_filter urlpath_regex ^/artifactory
http_access allow artifactory_repo_filter

# And finally deny all other access to this proxy
http_access deny all


----  access.log -----------------------------
1541104544.428      0 <CLIENT_IP> TCP_DENIED/200 0 CONNECT google.com:443 - HIER_NONE/- -
1541104544.433      0 <CLIENT_IP> TAG_NONE/403 3900 GET https://google.com/ - HIER_NONE/- text/html
1541104555.408      0 <CLIENT_IP> TCP_DENIED/200 0 CONNECT <ARTIFACTORY_SERVER_DOMAIN>:8443 - HIER_NONE/- -
1541104555.411      0 <CLIENT_IP> TAG_NONE/403 3975 GET https://<ARTIFACTORY_SERVER_DOMAIN>:8443/artifactory/path/matching/the_request.jar - HIER_NONE/- text/html


----  cache.log -----------------------------
2018/11/01 20:35:44.427 kid1| 28,3| Checklist.cc(70) preCheck: 0x55d5742e4918 checking slow rules
2018/11/01 20:35:44.427 kid1| 28,3| Acl.cc(158) matches: checked: artifactory_repo_filter = -1
2018/11/01 20:35:44.427 kid1| 28,3| Acl.cc(158) matches: checked: http_access#1 = 0
2018/11/01 20:35:44.427 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '<CLIENT_IP>:41736' found
2018/11/01 20:35:44.428 kid1| 28,3| Acl.cc(158) matches: checked: all = 1
2018/11/01 20:35:44.428 kid1| 28,3| Acl.cc(158) matches: checked: http_access#2 = 1
2018/11/01 20:35:44.428 kid1| 28,3| Acl.cc(158) matches: checked: http_access = 1
2018/11/01 20:35:44.428 kid1| 28,3| Checklist.cc(63) markFinished: 0x55d5742e4918 answer DENIED for match
2018/11/01 20:35:44.428 kid1| 28,3| Checklist.cc(163) checkCallback: ACLChecklist::checkCallback: 0x55d5742e4918 answer=DENIED
2018/11/01 20:35:44.428 kid1| 28,3| Checklist.cc(70) preCheck: 0x55d5742e5378 checking slow rules
2018/11/01 20:35:44.428 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '<CLIENT_IP>:41736' found
2018/11/01 20:35:44.428 kid1| 28,3| Acl.cc(158) matches: checked: all = 1
2018/11/01 20:35:44.428 kid1| 28,3| Acl.cc(158) matches: checked: (ssl_bump rule) = 1
2018/11/01 20:35:44.428 kid1| 28,3| Acl.cc(158) matches: checked: (ssl_bump rules) = 1
2018/11/01 20:35:44.428 kid1| 28,3| Checklist.cc(63) markFinished: 0x55d5742e5378 answer ALLOWED for match
2018/11/01 20:35:44.428 kid1| 28,3| Checklist.cc(163) checkCallback: ACLChecklist::checkCallback: 0x55d5742e5378 answer=ALLOWED
2018/11/01 20:35:44.428 kid1| 28,3| Checklist.cc(70) preCheck: 0x7ffebd1f0df0 checking fast ACLs
2018/11/01 20:35:44.428 kid1| 28,3| Acl.cc(158) matches: checked: (access_log daemon:/var/log/squid/access.log line) = 1
2018/11/01 20:35:44.428 kid1| 28,3| Acl.cc(158) matches: checked: access_log daemon:/var/log/squid/access.log = 1
2018/11/01 20:35:44.428 kid1| 28,3| Checklist.cc(63) markFinished: 0x7ffebd1f0df0 answer ALLOWED for match
2018/11/01 20:35:44.433 kid1| 28,3| Checklist.cc(70) preCheck: 0x7ffebd1f0ec0 checking fast ACLs
2018/11/01 20:35:44.433 kid1| 28,3| Acl.cc(158) matches: checked: (access_log daemon:/var/log/squid/access.log line) = 1
2018/11/01 20:35:44.433 kid1| 28,3| Acl.cc(158) matches: checked: access_log daemon:/var/log/squid/access.log = 1
2018/11/01 20:35:44.433 kid1| 28,3| Checklist.cc(63) markFinished: 0x7ffebd1f0ec0 answer ALLOWED for match
2018/11/01 20:35:55.408 kid1| 28,3| Checklist.cc(70) preCheck: 0x55d5742e4918 checking slow rules
2018/11/01 20:35:55.408 kid1| 28,3| Acl.cc(158) matches: checked: artifactory_repo_filter = -1
2018/11/01 20:35:55.408 kid1| 28,3| Acl.cc(158) matches: checked: http_access#1 = 0
2018/11/01 20:35:55.408 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '<CLIENT_IP>:41738' found
2018/11/01 20:35:55.408 kid1| 28,3| Acl.cc(158) matches: checked: all = 1
2018/11/01 20:35:55.408 kid1| 28,3| Acl.cc(158) matches: checked: http_access#2 = 1
2018/11/01 20:35:55.408 kid1| 28,3| Acl.cc(158) matches: checked: http_access = 1
2018/11/01 20:35:55.408 kid1| 28,3| Checklist.cc(63) markFinished: 0x55d5742e4918 answer DENIED for match
2018/11/01 20:35:55.408 kid1| 28,3| Checklist.cc(163) checkCallback: ACLChecklist::checkCallback: 0x55d5742e4918 answer=DENIED
2018/11/01 20:35:55.408 kid1| 28,3| Checklist.cc(70) preCheck: 0x55d5742e5378 checking slow rules
2018/11/01 20:35:55.408 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '<CLIENT_IP>:41738' found
2018/11/01 20:35:55.408 kid1| 28,3| Acl.cc(158) matches: checked: all = 1
2018/11/01 20:35:55.408 kid1| 28,3| Acl.cc(158) matches: checked: (ssl_bump rule) = 1
2018/11/01 20:35:55.408 kid1| 28,3| Acl.cc(158) matches: checked: (ssl_bump rules) = 1
2018/11/01 20:35:55.408 kid1| 28,3| Checklist.cc(63) markFinished: 0x55d5742e5378 answer ALLOWED for match
2018/11/01 20:35:55.408 kid1| 28,3| Checklist.cc(163) checkCallback: ACLChecklist::checkCallback: 0x55d5742e5378 answer=ALLOWED
2018/11/01 20:35:55.408 kid1| 28,3| Checklist.cc(70) preCheck: 0x7ffebd1f0df0 checking fast ACLs
2018/11/01 20:35:55.408 kid1| 28,3| Acl.cc(158) matches: checked: (access_log daemon:/var/log/squid/access.log line) = 1
2018/11/01 20:35:55.408 kid1| 28,3| Acl.cc(158) matches: checked: access_log daemon:/var/log/squid/access.log = 1
2018/11/01 20:35:55.408 kid1| 28,3| Checklist.cc(63) markFinished: 0x7ffebd1f0df0 answer ALLOWED for match
2018/11/01 20:35:55.411 kid1| 28,3| Checklist.cc(70) preCheck: 0x7ffebd1f0ec0 checking fast ACLs
2018/11/01 20:35:55.411 kid1| 28,3| Acl.cc(158) matches: checked: (access_log daemon:/var/log/squid/access.log line) = 1
2018/11/01 20:35:55.411 kid1| 28,3| Acl.cc(158) matches: checked: access_log daemon:/var/log/squid/access.log = 1
2018/11/01 20:35:55.411 kid1| 28,3| Checklist.cc(63) markFinished: 0x7ffebd1f0ec0 answer ALLOWED for match


From rafael.akchurin at diladele.com  Thu Nov  1 22:46:11 2018
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 1 Nov 2018 22:46:11 +0000
Subject: [squid-users] Ubuntu 18 LTS repository for Squid 4.4 (rebuilt
 with sslbump support from sources in Debian unstable)
In-Reply-To: <954b3c1a-cd73-edb3-eb4c-ab97b8ef795b@cenpalab.cu>
References: <AM0PR04MB4753B39F948558DB3C372AEC8FCD0@AM0PR04MB4753.eurprd04.prod.outlook.com>,
 <954b3c1a-cd73-edb3-eb4c-ab97b8ef795b@cenpalab.cu>
Message-ID: <0CDE7BA8-CF88-461D-9B66-6ED02639D88D@diladele.com>

Hello Jose,

Latest Squid is already available in Debian unstable, no need to use Ubuntu recompilation.

Best regards,
Rafael Akchurin

> Op 1 nov. 2018 om 21:08 heeft Jos? J. Rodriguez <jose.rodriguez at cenpalab.cu> het volgende geschreven:
> 
> Rafael Akchurin wrote:
>> Greeting all,
>> The online repository with latest Squid 4.4 (rebuilt from Debian unstable with sslbump support) for Ubuntu 18 LTS 64-bit is available at squid44.diladele.com. Github repo at https://github.com/diladele/squid-ubuntu contains the scripts we used to make this compilation.
> 
> Hi:
> 
> Will this work on Debian 9.X?
> 
> Regards,
> Joe1962
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

From rousskov at measurement-factory.com  Thu Nov  1 23:21:24 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 1 Nov 2018 17:21:24 -0600
Subject: [squid-users] URL Regex ACLs Don't Evaluate After Bumping
In-Reply-To: <56F1E161-4DC0-42CF-A1D7-99DAA0782DA5@entrustdatacard.com>
References: <56F1E161-4DC0-42CF-A1D7-99DAA0782DA5@entrustdatacard.com>
Message-ID: <8e76c3ea-135d-6ad9-f4e3-9404dc4193a9@measurement-factory.com>

On 11/1/18 2:46 PM, Shane Poage wrote:

> I have my proxy configured to bump all traffic so that the
> urlpath_regex ACL can be applied, but it appears to not have any
> effect post-bump.

Your proxy will deny any first post-bump request and close the tunnel
because you deny all CONNECT requests that initiate tunnels. CONNECT
requests do not have a URL path so they will never match your
"http_access allow" rule.

When a CONNECT request is denied by a bumping Squid, that Squid bumps
the tunnel and then denies the very first bumped request on that tunnel,
whatever that request is. This delayed error return is done to deliver
the "access denied" error page to the client -- browsers ignore CONNECT
error responses.


> http_port 3128 ssl-bump \
>   cert=/etc/squid/ssl_certs/artifactory_mitm_ca.pem \
>   generate-host-certificates=on \
>   dynamic_cert_mem_cache_size=4MB

> ssl_bump bump all

> acl artifactory_repo_filter urlpath_regex ^/artifactory
> http_access allow artifactory_repo_filter
> 
> # And finally deny all other access to this proxy
> http_access deny all

Insert an http_access rule to allow all safe CONNECT requests before you
deny everything else. IIRC, squid.conf.default has an example of how to
do that.

Alex.


From tarotapprentice at yahoo.com  Thu Nov  1 23:53:18 2018
From: tarotapprentice at yahoo.com (Mark James)
Date: Fri, 2 Nov 2018 10:53:18 +1100
Subject: [squid-users] Ubuntu 18 LTS repository for Squid 4.4 (rebuilt
	with sslbump support from sources in Debian unstable)
In-Reply-To: <0CDE7BA8-CF88-461D-9B66-6ED02639D88D@diladele.com>
References: <AM0PR04MB4753B39F948558DB3C372AEC8FCD0@AM0PR04MB4753.eurprd04.prod.outlook.com>
 <954b3c1a-cd73-edb3-eb4c-ab97b8ef795b@cenpalab.cu>
 <0CDE7BA8-CF88-461D-9B66-6ED02639D88D@diladele.com>
Message-ID: <C7DE43D6-B8B5-4E71-8B7C-E6FB975F03FF@yahoo.com>

Debian seem to be unwilling to push squid4 through to stretch-backports. There is a libc change in testing that makes it difficult to get the one from testing or unstable without building your own.

I have emailed their packaging team a couple of times. Given squid 3.5 is unsupported you would think they would want to get it into stretch-backports. Maybe if they got a semi-offical email from the squid developers they might reconsider.

MarkJ 

> On 2 Nov 2018, at 9:46 am, Rafael Akchurin <rafael.akchurin at diladele.com> wrote:
> 
> Hello Jose,
> 
> Latest Squid is already available in Debian unstable, no need to use Ubuntu recompilation.
> 
> Best regards,
> Rafael Akchurin
> 
>> Op 1 nov. 2018 om 21:08 heeft Jos? J. Rodriguez <jose.rodriguez at cenpalab.cu> het volgende geschreven:
>> 
>> Rafael Akchurin wrote:
>>> Greeting all,
>>> The online repository with latest Squid 4.4 (rebuilt from Debian unstable with sslbump support) for Ubuntu 18 LTS 64-bit is available at squid44.diladele.com. Github repo at https://github.com/diladele/squid-ubuntu contains the scripts we used to make this compilation.
>> 
>> Hi:
>> 
>> Will this work on Debian 9.X?
>> 
>> Regards,
>> Joe1962
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From SIDDH05 at gmail.com  Fri Nov  2 09:47:56 2018
From: SIDDH05 at gmail.com (Sid)
Date: Fri, 2 Nov 2018 04:47:56 -0500 (CDT)
Subject: [squid-users] Squid 4.3: SSL Bump fails to send client
	certificate
In-Reply-To: <513e5713-510a-ed8c-56a6-fd8e58c16e31@measurement-factory.com>
References: <1540888595659-0.post@n4.nabble.com>
 <6a396e03-e800-3dab-2ea8-97342edff1c7@measurement-factory.com>
 <1540961958277-0.post@n4.nabble.com>
 <407e2dc2-0473-46ed-469f-e2d8da2d0326@measurement-factory.com>
 <1541048135029-0.post@n4.nabble.com>
 <513e5713-510a-ed8c-56a6-fd8e58c16e31@measurement-factory.com>
Message-ID: <1541152076040-0.post@n4.nabble.com>

Thank you Amos and Alex for great help & support so far.

As per suggestions I have added lot more parameters in squid.conf for both
"http" & "tls_outgoing_options" directives:

http_port 3128 ssl-bump \
  tls-cert=/usr/local/squid/etc/ssl_cert/myCA.pem \
 
cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!DH:!ADH
\
  options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE \
  generate-host-certificates=on dynamic_cert_mem_cache_size=4MB \
  tls-cafile=/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem \
  tls-dh=prime256v1:/usr/local/squid/etc/dhparam.pem \
  tls-dh=secp384r1:/usr/local/squid/etc/dhparam.pem

tls_outgoing_options \
   default-ca=off \
   cafile=/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem \
   options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE \
  
cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!DH:!ADH
\
   flags=DONT_VERIFY_DOMAIN \
   flags=DONT_VERIFY_PEERi \
   min-version=1.2

Now, when I look into wireshark between Server <--> Squid; I no longer see
error: 61 Alert (Level: Fatal, Description: Internal Error) sent by Squid

Only issue is Squid sends:
2018-11-02_151705.jpg
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377591/2018-11-02_151705.jpg>  

How to make Squid send certificate in it?






--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Fri Nov  2 15:02:26 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 2 Nov 2018 09:02:26 -0600
Subject: [squid-users] Squid 4.3: SSL Bump fails to send client
 certificate
In-Reply-To: <1541152076040-0.post@n4.nabble.com>
References: <1540888595659-0.post@n4.nabble.com>
 <6a396e03-e800-3dab-2ea8-97342edff1c7@measurement-factory.com>
 <1540961958277-0.post@n4.nabble.com>
 <407e2dc2-0473-46ed-469f-e2d8da2d0326@measurement-factory.com>
 <1541048135029-0.post@n4.nabble.com>
 <513e5713-510a-ed8c-56a6-fd8e58c16e31@measurement-factory.com>
 <1541152076040-0.post@n4.nabble.com>
Message-ID: <fda86027-9e7b-b27a-41e0-8f0e40d7c5b2@measurement-factory.com>

On 11/2/18 3:47 AM, Sid wrote:

> tls_outgoing_options \
>    default-ca=off \
>    cafile=/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem \
>    options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE \

> Only issue is Squid sends:
> http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377591/2018-11-02_151705.jpg

> How to make Squid send certificate in it?

I believe I have answered that question in my previous email[1]. Your
current tls_outgoing_options appear to ignore my answer.

Please note that I have not tested whether tls_outgoing_options cert=...
key=.... mentioned in [1] works as it should in your environment, but
Squid documentation implies that it works. If it does not work, you may
want to file a bug report.

Alex.
[1]
http://lists.squid-cache.org/pipermail/squid-users/2018-November/019613.html


From Shane.Poage at entrustdatacard.com  Fri Nov  2 15:54:47 2018
From: Shane.Poage at entrustdatacard.com (Shane Poage)
Date: Fri, 2 Nov 2018 15:54:47 +0000
Subject: [squid-users] [EXTERNAL]Re: URL Regex ACLs Don't Evaluate After
 Bumping
In-Reply-To: <8e76c3ea-135d-6ad9-f4e3-9404dc4193a9@measurement-factory.com>
References: <56F1E161-4DC0-42CF-A1D7-99DAA0782DA5@entrustdatacard.com>
 <8e76c3ea-135d-6ad9-f4e3-9404dc4193a9@measurement-factory.com>
Message-ID: <42FD2170-919A-4895-93DB-C48B7D7EC3BC@entrustdatacard.com>

If I understand you correctly, my original squid.conf had an ACL directive corresponding to the functionality in question:

	acl CONNECT method CONNECT

Regardless, I added that back to my config and re-tested both with it inline and stand-alone. My results as follows:

http_access allow CONNECT artifactory_repo_filter
	This resulted in no traffic being passed, just like without the
	CONNECT ACL present. I assume this is what you were telling
	me to do because it's what made the most sense based off
	of your description of the problem, but it did not have the
	desired effect.

http_access allow CONNECT
http_access allow artifactory_repo_filter
	This resulted in all SSL traffic being permitted and passed through
	the proxy. This makes sense to me because the allow CONNECT
	would whitelist all CONNECT traffic, which is what all SSL traffic is
	by my understanding. I didn't think this is what you meant, but I
	tried it anyway to be sure.

Have I misunderstood you somehow, or is it not behaving as expected?

?On 11/1/18, 6:21 PM, "squid-users on behalf of Alex Rousskov" <squid-users-bounces at lists.squid-cache.org on behalf of rousskov at measurement-factory.com> wrote:
    On 11/1/18 2:46 PM, Shane Poage wrote:
    
    > I have my proxy configured to bump all traffic so that the
    > urlpath_regex ACL can be applied, but it appears to not have any
    > effect post-bump.
    
    Your proxy will deny any first post-bump request and close the tunnel
    because you deny all CONNECT requests that initiate tunnels. CONNECT
    requests do not have a URL path so they will never match your
    "http_access allow" rule.
    
    When a CONNECT request is denied by a bumping Squid, that Squid bumps
    the tunnel and then denies the very first bumped request on that tunnel,
    whatever that request is. This delayed error return is done to deliver
    the "access denied" error page to the client -- browsers ignore CONNECT
    error responses.
    
    
    > http_port 3128 ssl-bump \
    >   cert=/etc/squid/ssl_certs/artifactory_mitm_ca.pem \
    >   generate-host-certificates=on \
    >   dynamic_cert_mem_cache_size=4MB
    
    > ssl_bump bump all
    
    > acl artifactory_repo_filter urlpath_regex ^/artifactory
    > http_access allow artifactory_repo_filter
    > 
    > # And finally deny all other access to this proxy
    > http_access deny all
    
    Insert an http_access rule to allow all safe CONNECT requests before you
    deny everything else. IIRC, squid.conf.default has an example of how to
    do that.
    
    Alex.
    _______________________________________________
    squid-users mailing list
    squid-users at lists.squid-cache.org
    http://lists.squid-cache.org/listinfo/squid-users
    


From ofoerster at posteo.de  Fri Nov  2 16:02:06 2018
From: ofoerster at posteo.de (ofoerster at posteo.de)
Date: Fri, 02 Nov 2018 17:02:06 +0100
Subject: [squid-users] Parent proxy with digest authentication
Message-ID: <c06a42046922eefc3047d8eae937a32d@posteo.de>

Hello Community,

We would like to place a proxy in front of our corporate proxy. 
Unfortunately, the parent proxy is a digest authentication and this can 
not be defined in the configuration of "cache peer". Also, the login 
with username and password works only for basic authentication. Is there 
a solution to save and forward the digest authentication?

Thank you in advance,
Oliver


From squid3 at treenet.co.nz  Fri Nov  2 16:37:49 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 3 Nov 2018 05:37:49 +1300
Subject: [squid-users] Parent proxy with digest authentication
In-Reply-To: <c06a42046922eefc3047d8eae937a32d@posteo.de>
References: <c06a42046922eefc3047d8eae937a32d@posteo.de>
Message-ID: <4b75f317-a2c0-411e-71c0-594c90ae0918@treenet.co.nz>

On 3/11/18 5:02 AM, ofoerster wrote:
> Hello Community,
> 
> We would like to place a proxy in front of our corporate proxy.
> Unfortunately, the parent proxy is a digest authentication and this can
> not be defined in the configuration of "cache peer". Also, the login
> with username and password works only for basic authentication. Is there
> a solution to save and forward the digest authentication?

You can try the cache_peer option login=PASSTHRU for the config of new
proxy. It should work, but has not exactly had wide usage so there may
still be bugs not found.

Also your new frontend cannot do any authentication with the client when
using that option for auth types more complex than Basic or Bearer. The
credentials have to be transparently passed between the parent proxy and
the end-client to avoid confusing either of them about the auth state.

Amos


From rousskov at measurement-factory.com  Fri Nov  2 17:26:54 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 2 Nov 2018 11:26:54 -0600
Subject: [squid-users] [EXTERNAL]Re: URL Regex ACLs Don't Evaluate After
 Bumping
In-Reply-To: <42FD2170-919A-4895-93DB-C48B7D7EC3BC@entrustdatacard.com>
References: <56F1E161-4DC0-42CF-A1D7-99DAA0782DA5@entrustdatacard.com>
 <8e76c3ea-135d-6ad9-f4e3-9404dc4193a9@measurement-factory.com>
 <42FD2170-919A-4895-93DB-C48B7D7EC3BC@entrustdatacard.com>
Message-ID: <c0630724-78ed-dd25-63da-2e6e418d7e58@measurement-factory.com>

On 11/2/18 9:54 AM, Shane Poage wrote:

> my original squid.conf had an ACL directive corresponding to the
> functionality in question:

> 	acl CONNECT method CONNECT

That CONNECT ACL declaration is OK, but what matters is how you _use_
that declared ACL. The configuration you posted earlier did not use it
at all.


> http_access allow CONNECT artifactory_repo_filter

This "CONNECT and artifactory_repo_filter" rule does not make sense. As
I said earlier, your artifactory_repo_filter cannot match a CONNECT
request. Thus, you are joining two conditions that can never be
satisfied for the same request. For any request, you will get either
(false and true) or (true and false), which is, of course, always false.


> http_access allow CONNECT
> http_access allow artifactory_repo_filter

This "CONNECT or artifactory_repo_filter" combination makes sense, but
the first part is dangerous -- you probably should not allow CONNECT
request to arbitrary port numbers. If you look at how CONNECT requests
are handled in squid.conf.default, then you will probably come up with
something like this:

  http_access deny !Safe_ports
  http_access deny CONNECT !SSL_ports
  http_access allow CONNECT
  http_access allow artifactory_repo_filter
  http_access deny all

or a bit shorter but arguably less safe (long-term) version:

  http_access deny !Safe_ports
  http_access allow CONNECT SSL_ports
  http_access allow artifactory_repo_filter
  http_access deny all

or an even shorter but arguably even less safe (long-term) version:

  http_access allow SSL_ports CONNECT
  http_access allow Safe_ports artifactory_repo_filter
  http_access deny all


N.B. The above configurations allow plain text traffic matching
artifactory_repo_filter. I do not know whether that is what you want.


> 	This resulted in all SSL traffic being permitted and passed through
> 	the proxy.

If you are still bumping all SSL traffic, and your
artifactory_repo_filter ACL is working, then all of the above reasonable
configurations should still block bumped GET requests that match
artifactory_repo_filter.


> This makes sense to me because the allow CONNECT
> 	would whitelist all CONNECT traffic, which is what all SSL traffic is
> 	by my understanding. 

Your understanding is incorrect. Since you are bumping all CONNECT
tunnels, your http_access traffic consists of:

* CONNECT requests
* decrypted requests (e.g., GET) inside bumped CONNECT tunnels
* plain requests (e.g., GET) outside CONNECT tunnels


HTH,

Alex.


> ?On 11/1/18, 6:21 PM, Alex Rousskov wrote:
>     On 11/1/18 2:46 PM, Shane Poage wrote:
>     
>     > I have my proxy configured to bump all traffic so that the
>     > urlpath_regex ACL can be applied, but it appears to not have any
>     > effect post-bump.
>     
>     Your proxy will deny any first post-bump request and close the tunnel
>     because you deny all CONNECT requests that initiate tunnels. CONNECT
>     requests do not have a URL path so they will never match your
>     "http_access allow" rule.
>     
>     When a CONNECT request is denied by a bumping Squid, that Squid bumps
>     the tunnel and then denies the very first bumped request on that tunnel,
>     whatever that request is. This delayed error return is done to deliver
>     the "access denied" error page to the client -- browsers ignore CONNECT
>     error responses.
>     
>     
>     > http_port 3128 ssl-bump \
>     >   cert=/etc/squid/ssl_certs/artifactory_mitm_ca.pem \
>     >   generate-host-certificates=on \
>     >   dynamic_cert_mem_cache_size=4MB
>     
>     > ssl_bump bump all
>     
>     > acl artifactory_repo_filter urlpath_regex ^/artifactory
>     > http_access allow artifactory_repo_filter
>     > 
>     > # And finally deny all other access to this proxy
>     > http_access deny all
>     
>     Insert an http_access rule to allow all safe CONNECT requests before you
>     deny everything else. IIRC, squid.conf.default has an example of how to
>     do that.
>     
>     Alex.
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     http://lists.squid-cache.org/listinfo/squid-users
>     
> 



From Shane.Poage at entrustdatacard.com  Fri Nov  2 18:22:29 2018
From: Shane.Poage at entrustdatacard.com (Shane Poage)
Date: Fri, 2 Nov 2018 18:22:29 +0000
Subject: [squid-users] [EXTERNAL]Re: URL Regex ACLs Don't Evaluate After
 Bumping
In-Reply-To: <c0630724-78ed-dd25-63da-2e6e418d7e58@measurement-factory.com>
References: <56F1E161-4DC0-42CF-A1D7-99DAA0782DA5@entrustdatacard.com>
 <8e76c3ea-135d-6ad9-f4e3-9404dc4193a9@measurement-factory.com>
 <42FD2170-919A-4895-93DB-C48B7D7EC3BC@entrustdatacard.com>
 <c0630724-78ed-dd25-63da-2e6e418d7e58@measurement-factory.com>
Message-ID: <A0E968E2-DEF5-425B-8158-FDD95F889866@entrustdatacard.com>

Alex,

Thanks for all your help so far - I really appreciate it. However, I'm not sure
we're on the same page for some reason because as I said previously, the
suggestions you have made do not appear to be having the effect I'm looking
for. Let me back up a bit and clarify a few things to make sure I am
understanding properly, because there seem to be a few things that I have
thus far fundamentally misunderstood.

My understanding of how SSL bumping works is as follows, based on what
I have read in all of the documentation I could possibly find:

1. A CONNECT request comes in to the proxy from a client.
2. The proxy does access control on that CONNECT request and decides
     whether or not to permit the tunnel. For the sake of moving on, let's
     assume that it decides to allow.
3. The proxy then begins processing the rules for SSL bumping. Again, for the
     sake of simplicity, we'll say that all traffic is getting bumped.
4. The proxy begins bumping traffic and individually processing the requests
     for that session.
5. Each request within the session has the http_access rules applied to them
     as if they were normal HTTP requests made through the proxy, until the
     session is terminated.

Is this understanding correct?

Thanks again,
-Shane

?On 11/2/18, 12:26 PM, "Alex Rousskov" <rousskov at measurement-factory.com> wrote:

    On 11/2/18 9:54 AM, Shane Poage wrote:
    
    > my original squid.conf had an ACL directive corresponding to the
    > functionality in question:
    
    > 	acl CONNECT method CONNECT
    
    That CONNECT ACL declaration is OK, but what matters is how you _use_
    that declared ACL. The configuration you posted earlier did not use it
    at all.
    
    
    > http_access allow CONNECT artifactory_repo_filter
    
    This "CONNECT and artifactory_repo_filter" rule does not make sense. As
    I said earlier, your artifactory_repo_filter cannot match a CONNECT
    request. Thus, you are joining two conditions that can never be
    satisfied for the same request. For any request, you will get either
    (false and true) or (true and false), which is, of course, always false.
    
    
    > http_access allow CONNECT
    > http_access allow artifactory_repo_filter
    
    This "CONNECT or artifactory_repo_filter" combination makes sense, but
    the first part is dangerous -- you probably should not allow CONNECT
    request to arbitrary port numbers. If you look at how CONNECT requests
    are handled in squid.conf.default, then you will probably come up with
    something like this:
    
      http_access deny !Safe_ports
      http_access deny CONNECT !SSL_ports
      http_access allow CONNECT
      http_access allow artifactory_repo_filter
      http_access deny all
    
    or a bit shorter but arguably less safe (long-term) version:
    
      http_access deny !Safe_ports
      http_access allow CONNECT SSL_ports
      http_access allow artifactory_repo_filter
      http_access deny all
    
    or an even shorter but arguably even less safe (long-term) version:
    
      http_access allow SSL_ports CONNECT
      http_access allow Safe_ports artifactory_repo_filter
      http_access deny all
    
    
    N.B. The above configurations allow plain text traffic matching
    artifactory_repo_filter. I do not know whether that is what you want.
    
    
    > 	This resulted in all SSL traffic being permitted and passed through
    > 	the proxy.
    
    If you are still bumping all SSL traffic, and your
    artifactory_repo_filter ACL is working, then all of the above reasonable
    configurations should still block bumped GET requests that match
    artifactory_repo_filter.
    
    
    > This makes sense to me because the allow CONNECT
    > 	would whitelist all CONNECT traffic, which is what all SSL traffic is
    > 	by my understanding. 
    
    Your understanding is incorrect. Since you are bumping all CONNECT
    tunnels, your http_access traffic consists of:
    
    * CONNECT requests
    * decrypted requests (e.g., GET) inside bumped CONNECT tunnels
    * plain requests (e.g., GET) outside CONNECT tunnels
    
    
    HTH,
    
    Alex.
    
    
    > On 11/1/18, 6:21 PM, Alex Rousskov wrote:
    >     On 11/1/18 2:46 PM, Shane Poage wrote:
    >     
    >     > I have my proxy configured to bump all traffic so that the
    >     > urlpath_regex ACL can be applied, but it appears to not have any
    >     > effect post-bump.
    >     
    >     Your proxy will deny any first post-bump request and close the tunnel
    >     because you deny all CONNECT requests that initiate tunnels. CONNECT
    >     requests do not have a URL path so they will never match your
    >     "http_access allow" rule.
    >     
    >     When a CONNECT request is denied by a bumping Squid, that Squid bumps
    >     the tunnel and then denies the very first bumped request on that tunnel,
    >     whatever that request is. This delayed error return is done to deliver
    >     the "access denied" error page to the client -- browsers ignore CONNECT
    >     error responses.
    >     
    >     
    >     > http_port 3128 ssl-bump \
    >     >   cert=/etc/squid/ssl_certs/artifactory_mitm_ca.pem \
    >     >   generate-host-certificates=on \
    >     >   dynamic_cert_mem_cache_size=4MB
    >     
    >     > ssl_bump bump all
    >     
    >     > acl artifactory_repo_filter urlpath_regex ^/artifactory
    >     > http_access allow artifactory_repo_filter
    >     > 
    >     > # And finally deny all other access to this proxy
    >     > http_access deny all
    >     
    >     Insert an http_access rule to allow all safe CONNECT requests before you
    >     deny everything else. IIRC, squid.conf.default has an example of how to
    >     do that.
    >     
    >     Alex.
    >     _______________________________________________
    >     squid-users mailing list
    >     squid-users at lists.squid-cache.org
    >     http://lists.squid-cache.org/listinfo/squid-users
    >     
    > 
    
    


From rousskov at measurement-factory.com  Fri Nov  2 20:15:07 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 2 Nov 2018 14:15:07 -0600
Subject: [squid-users] URL Regex ACLs Don't Evaluate After Bumping
In-Reply-To: <A0E968E2-DEF5-425B-8158-FDD95F889866@entrustdatacard.com>
References: <56F1E161-4DC0-42CF-A1D7-99DAA0782DA5@entrustdatacard.com>
 <8e76c3ea-135d-6ad9-f4e3-9404dc4193a9@measurement-factory.com>
 <42FD2170-919A-4895-93DB-C48B7D7EC3BC@entrustdatacard.com>
 <c0630724-78ed-dd25-63da-2e6e418d7e58@measurement-factory.com>
 <A0E968E2-DEF5-425B-8158-FDD95F889866@entrustdatacard.com>
Message-ID: <dbfa5f8d-b033-466c-8af6-b2b06e756d50@measurement-factory.com>

On 11/2/18 12:22 PM, Shane Poage wrote:

> My understanding of how SSL bumping works is as follows, based on what
> I have read in all of the documentation I could possibly find:

To simplify, I will interpret the statements below in SslBump context.
That is, I will interpret them as they are applied to traffic received
on an http_port with ssl-bump configured.

I will also assume a bug-free implementation. In other words, the entire
text below is under the "Bugs notwithstanding..." precondition.


> 1. A CONNECT request comes in to the proxy from a client.
> 2. The proxy does access control on that CONNECT request and decides
>      whether or not to permit the tunnel. For the sake of moving on, let's
>      assume that it decides to allow.

Correct. This decision is a part of SslBump step1.

[ The decision to allow or deny CONNECT is done again during SslBump
step2 if a peek or stare action matches during step1. IIRC, those
additional checks do not happen in your configuration because your
ssl_bump rules match a bump action at step1. Thus, this additional
caveat does not apply to you. ]


> 3. The proxy then begins processing the rules for SSL bumping. Again, for the
>      sake of simplicity, we'll say that all traffic is getting bumped.

OK. This processing is a part of SslBump step1.


> 4. The proxy begins bumping traffic and individually processing the requests
>      for that session.

OK. This processing is a part of SslBump step1.

[ Again, there could be more SslBump steps in general, but, in your
specific case, the client connection is bumped here. ]


> 5. Each request within the session has the http_access rules applied to them
>      as if they were normal HTTP requests made through the proxy, until the
>      session is terminated.

These bumped requests have "https" scheme and some special properties
specific to bumped requests but, overall, they are indeed processed as
usual, including application of http_access rules to each of the bumped
request.


To make progress, I recommend identifying a specific Squid action that
contradicts either your understanding of how things should work or my
remarks and then posting the relevant details of that action along with
a clear explanation of where you see a contradiction.

Alex.


> ?On 11/2/18, 12:26 PM, "Alex Rousskov" wrote:
> 
>     On 11/2/18 9:54 AM, Shane Poage wrote:
>     
>     > my original squid.conf had an ACL directive corresponding to the
>     > functionality in question:
>     
>     > 	acl CONNECT method CONNECT
>     
>     That CONNECT ACL declaration is OK, but what matters is how you _use_
>     that declared ACL. The configuration you posted earlier did not use it
>     at all.
>     
>     
>     > http_access allow CONNECT artifactory_repo_filter
>     
>     This "CONNECT and artifactory_repo_filter" rule does not make sense. As
>     I said earlier, your artifactory_repo_filter cannot match a CONNECT
>     request. Thus, you are joining two conditions that can never be
>     satisfied for the same request. For any request, you will get either
>     (false and true) or (true and false), which is, of course, always false.
>     
>     
>     > http_access allow CONNECT
>     > http_access allow artifactory_repo_filter
>     
>     This "CONNECT or artifactory_repo_filter" combination makes sense, but
>     the first part is dangerous -- you probably should not allow CONNECT
>     request to arbitrary port numbers. If you look at how CONNECT requests
>     are handled in squid.conf.default, then you will probably come up with
>     something like this:
>     
>       http_access deny !Safe_ports
>       http_access deny CONNECT !SSL_ports
>       http_access allow CONNECT
>       http_access allow artifactory_repo_filter
>       http_access deny all
>     
>     or a bit shorter but arguably less safe (long-term) version:
>     
>       http_access deny !Safe_ports
>       http_access allow CONNECT SSL_ports
>       http_access allow artifactory_repo_filter
>       http_access deny all
>     
>     or an even shorter but arguably even less safe (long-term) version:
>     
>       http_access allow SSL_ports CONNECT
>       http_access allow Safe_ports artifactory_repo_filter
>       http_access deny all
>     
>     
>     N.B. The above configurations allow plain text traffic matching
>     artifactory_repo_filter. I do not know whether that is what you want.
>     
>     
>     > 	This resulted in all SSL traffic being permitted and passed through
>     > 	the proxy.
>     
>     If you are still bumping all SSL traffic, and your
>     artifactory_repo_filter ACL is working, then all of the above reasonable
>     configurations should still block bumped GET requests that match
>     artifactory_repo_filter.
>     
>     
>     > This makes sense to me because the allow CONNECT
>     > 	would whitelist all CONNECT traffic, which is what all SSL traffic is
>     > 	by my understanding. 
>     
>     Your understanding is incorrect. Since you are bumping all CONNECT
>     tunnels, your http_access traffic consists of:
>     
>     * CONNECT requests
>     * decrypted requests (e.g., GET) inside bumped CONNECT tunnels
>     * plain requests (e.g., GET) outside CONNECT tunnels
>     
>     
>     HTH,
>     
>     Alex.
>     
>     
>     > On 11/1/18, 6:21 PM, Alex Rousskov wrote:
>     >     On 11/1/18 2:46 PM, Shane Poage wrote:
>     >     
>     >     > I have my proxy configured to bump all traffic so that the
>     >     > urlpath_regex ACL can be applied, but it appears to not have any
>     >     > effect post-bump.
>     >     
>     >     Your proxy will deny any first post-bump request and close the tunnel
>     >     because you deny all CONNECT requests that initiate tunnels. CONNECT
>     >     requests do not have a URL path so they will never match your
>     >     "http_access allow" rule.
>     >     
>     >     When a CONNECT request is denied by a bumping Squid, that Squid bumps
>     >     the tunnel and then denies the very first bumped request on that tunnel,
>     >     whatever that request is. This delayed error return is done to deliver
>     >     the "access denied" error page to the client -- browsers ignore CONNECT
>     >     error responses.
>     >     
>     >     
>     >     > http_port 3128 ssl-bump \
>     >     >   cert=/etc/squid/ssl_certs/artifactory_mitm_ca.pem \
>     >     >   generate-host-certificates=on \
>     >     >   dynamic_cert_mem_cache_size=4MB
>     >     
>     >     > ssl_bump bump all
>     >     
>     >     > acl artifactory_repo_filter urlpath_regex ^/artifactory
>     >     > http_access allow artifactory_repo_filter
>     >     > 
>     >     > # And finally deny all other access to this proxy
>     >     > http_access deny all
>     >     
>     >     Insert an http_access rule to allow all safe CONNECT requests before you
>     >     deny everything else. IIRC, squid.conf.default has an example of how to
>     >     do that.
>     >     
>     >     Alex.
>     >     _______________________________________________
>     >     squid-users mailing list
>     >     squid-users at lists.squid-cache.org
>     >     http://lists.squid-cache.org/listinfo/squid-users
>     >     
>     > 
>     
>     
> 



From chip_pop at hotmail.com  Mon Nov  5 13:51:54 2018
From: chip_pop at hotmail.com (joseph)
Date: Mon, 5 Nov 2018 07:51:54 -0600 (CST)
Subject: [squid-users] squid helper status
Message-ID: <1541425914242-0.post@n4.nabble.com>

question on mgr:store_id

wen Flags   has    BW  
   B    BUSY
   W    WRITING
any idea wat is the caus of that
1  network uplink delay
2 squid 
3 helper
i need help thanks



-----
************************** 
***** Crash to the future  ****
**************************
--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Mon Nov  5 17:30:29 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 5 Nov 2018 10:30:29 -0700
Subject: [squid-users] squid helper status
In-Reply-To: <1541425914242-0.post@n4.nabble.com>
References: <1541425914242-0.post@n4.nabble.com>
Message-ID: <ddebf594-5be8-8256-d1bf-358d9d096960@measurement-factory.com>

On 11/5/18 6:51 AM, joseph wrote:
> question on mgr:store_id
> 
> wen Flags   has    BW  
>    B    BUSY
>    W    WRITING
> any idea wat is the caus of that

Please see the following new wiki section for the helper states
documentation:
https://wiki.squid-cache.org/Features/AddonHelpers#Helper_states


> 1 network uplink delay

Assuming this WRITING state lasts for a while, it is possible that
network delays are to blame if your helper is using a network uplink and
does not read new helper requests while waiting for that network I/O.


> 2 squid 

Assuming this WRITING state lasts for a while, it is possible that Squid
is to blame if your Squid is overloaded and cannot write to the helper
process (fast enough), accumulating more being-sent helper requests in
the helper queue.


> 3 helper

Assuming this WRITING state lasts for a while, it is possible that the
helper is to blame if your helper is overloaded (or stuck) and cannot
read requests from Squid fast enough.


The above general answers are not specific to your store_id helper. You
may narrow the list of suspects down by applying your knowledge about
your helper and Squid/OS statistics for its processes.


HTH,

Alex.


From chip_pop at hotmail.com  Mon Nov  5 17:56:32 2018
From: chip_pop at hotmail.com (joseph)
Date: Mon, 5 Nov 2018 11:56:32 -0600 (CST)
Subject: [squid-users] squid helper status
In-Reply-To: <ddebf594-5be8-8256-d1bf-358d9d096960@measurement-factory.com>
References: <1541425914242-0.post@n4.nabble.com>
 <ddebf594-5be8-8256-d1bf-358d9d096960@measurement-factory.com>
Message-ID: <1541440592662-0.post@n4.nabble.com>

first thank you for the Helper_states  page i could not find it
second i have 4 identical server 3 never have this issue 
flag = BW
all server have very hi traffic  and the timing max betwean 0.300 up to
1.500 
just one server have the BW issue and cpu get hi as well one pc behind for
testing  it was the ECC ram i never know it dose that and it raise squid
cpu% and fkp the I/O between squid and helper
thank you for your help



-----
************************** 
***** Crash to the future  ****
**************************
--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From Shane.Poage at entrustdatacard.com  Mon Nov  5 19:02:57 2018
From: Shane.Poage at entrustdatacard.com (Shane Poage)
Date: Mon, 5 Nov 2018 19:02:57 +0000
Subject: [squid-users] [EXTERNAL]Re: URL Regex ACLs Don't Evaluate After
 Bumping
In-Reply-To: <dbfa5f8d-b033-466c-8af6-b2b06e756d50@measurement-factory.com>
References: <56F1E161-4DC0-42CF-A1D7-99DAA0782DA5@entrustdatacard.com>
 <8e76c3ea-135d-6ad9-f4e3-9404dc4193a9@measurement-factory.com>
 <42FD2170-919A-4895-93DB-C48B7D7EC3BC@entrustdatacard.com>
 <c0630724-78ed-dd25-63da-2e6e418d7e58@measurement-factory.com>
 <A0E968E2-DEF5-425B-8158-FDD95F889866@entrustdatacard.com>
 <dbfa5f8d-b033-466c-8af6-b2b06e756d50@measurement-factory.com>
Message-ID: <DFD11E32-0BC9-4C51-A306-3151B0EA4374@entrustdatacard.com>

Alex,

Great, it sounds like I'm pretty much on-track in terms of understanding how bumping
works under the hood. Thanks for taking the time to step through that and confirm my
understanding.

So here's the problem: the initial solution you gave for my urlpath_regex ACL not
permitting the traffic I expected was that I needed to permit the initial CONNECT request.
That made sense, but did not appear to behave exactly as I expected. Adding the
'method CONNECT' ACL as an allow http_accept directive appears to let ALL HTTPS
traffic through the proxy and ignore the other ACLs that should apply to the subsequent
requests in the CONNECT tunnel. This doesn't make sense to me based on how I thought
I understood the way bumping functions.

So, here's the question: if I'm not misunderstanding how bumping works, have I uncovered
a bug in Squid? Either in the form of the CONNECT ACL not being applied as expected, or
in the form of the urlpath_regex not being applied... Or is there something additional that
I'm fundamentally missing?

Thanks for your continued assistance,
-Shane

?On 11/2/18, 3:15 PM, "Alex Rousskov" <rousskov at measurement-factory.com> wrote:

    WARNING: This email originated outside of Entrust Datacard.
    DO NOT CLICK links or attachments unless you trust the sender and know the content is safe.
    
    On 11/2/18 12:22 PM, Shane Poage wrote:
    
    > My understanding of how SSL bumping works is as follows, based on what
    > I have read in all of the documentation I could possibly find:
    
    To simplify, I will interpret the statements below in SslBump context.
    That is, I will interpret them as they are applied to traffic received
    on an http_port with ssl-bump configured.
    
    I will also assume a bug-free implementation. In other words, the entire
    text below is under the "Bugs notwithstanding..." precondition.
    
    
    > 1. A CONNECT request comes in to the proxy from a client.
    > 2. The proxy does access control on that CONNECT request and decides
    >      whether or not to permit the tunnel. For the sake of moving on, let's
    >      assume that it decides to allow.
    
    Correct. This decision is a part of SslBump step1.
    
    [ The decision to allow or deny CONNECT is done again during SslBump
    step2 if a peek or stare action matches during step1. IIRC, those
    additional checks do not happen in your configuration because your
    ssl_bump rules match a bump action at step1. Thus, this additional
    caveat does not apply to you. ]
    
    
    > 3. The proxy then begins processing the rules for SSL bumping. Again, for the
    >      sake of simplicity, we'll say that all traffic is getting bumped.
    
    OK. This processing is a part of SslBump step1.
    
    
    > 4. The proxy begins bumping traffic and individually processing the requests
    >      for that session.
    
    OK. This processing is a part of SslBump step1.
    
    [ Again, there could be more SslBump steps in general, but, in your
    specific case, the client connection is bumped here. ]
    
    
    > 5. Each request within the session has the http_access rules applied to them
    >      as if they were normal HTTP requests made through the proxy, until the
    >      session is terminated.
    
    These bumped requests have "https" scheme and some special properties
    specific to bumped requests but, overall, they are indeed processed as
    usual, including application of http_access rules to each of the bumped
    request.
    
    
    To make progress, I recommend identifying a specific Squid action that
    contradicts either your understanding of how things should work or my
    remarks and then posting the relevant details of that action along with
    a clear explanation of where you see a contradiction.
    
    Alex.
    
    
    > On 11/2/18, 12:26 PM, "Alex Rousskov" wrote:
    > 
    >     On 11/2/18 9:54 AM, Shane Poage wrote:
    >     
    >     > my original squid.conf had an ACL directive corresponding to the
    >     > functionality in question:
    >     
    >     > 	acl CONNECT method CONNECT
    >     
    >     That CONNECT ACL declaration is OK, but what matters is how you _use_
    >     that declared ACL. The configuration you posted earlier did not use it
    >     at all.
    >     
    >     
    >     > http_access allow CONNECT artifactory_repo_filter
    >     
    >     This "CONNECT and artifactory_repo_filter" rule does not make sense. As
    >     I said earlier, your artifactory_repo_filter cannot match a CONNECT
    >     request. Thus, you are joining two conditions that can never be
    >     satisfied for the same request. For any request, you will get either
    >     (false and true) or (true and false), which is, of course, always false.
    >     
    >     
    >     > http_access allow CONNECT
    >     > http_access allow artifactory_repo_filter
    >     
    >     This "CONNECT or artifactory_repo_filter" combination makes sense, but
    >     the first part is dangerous -- you probably should not allow CONNECT
    >     request to arbitrary port numbers. If you look at how CONNECT requests
    >     are handled in squid.conf.default, then you will probably come up with
    >     something like this:
    >     
    >       http_access deny !Safe_ports
    >       http_access deny CONNECT !SSL_ports
    >       http_access allow CONNECT
    >       http_access allow artifactory_repo_filter
    >       http_access deny all
    >     
    >     or a bit shorter but arguably less safe (long-term) version:
    >     
    >       http_access deny !Safe_ports
    >       http_access allow CONNECT SSL_ports
    >       http_access allow artifactory_repo_filter
    >       http_access deny all
    >     
    >     or an even shorter but arguably even less safe (long-term) version:
    >     
    >       http_access allow SSL_ports CONNECT
    >       http_access allow Safe_ports artifactory_repo_filter
    >       http_access deny all
    >     
    >     
    >     N.B. The above configurations allow plain text traffic matching
    >     artifactory_repo_filter. I do not know whether that is what you want.
    >     
    >     
    >     > 	This resulted in all SSL traffic being permitted and passed through
    >     > 	the proxy.
    >     
    >     If you are still bumping all SSL traffic, and your
    >     artifactory_repo_filter ACL is working, then all of the above reasonable
    >     configurations should still block bumped GET requests that match
    >     artifactory_repo_filter.
    >     
    >     
    >     > This makes sense to me because the allow CONNECT
    >     > 	would whitelist all CONNECT traffic, which is what all SSL traffic is
    >     > 	by my understanding. 
    >     
    >     Your understanding is incorrect. Since you are bumping all CONNECT
    >     tunnels, your http_access traffic consists of:
    >     
    >     * CONNECT requests
    >     * decrypted requests (e.g., GET) inside bumped CONNECT tunnels
    >     * plain requests (e.g., GET) outside CONNECT tunnels
    >     
    >     
    >     HTH,
    >     
    >     Alex.
    >     
    >     
    >     > On 11/1/18, 6:21 PM, Alex Rousskov wrote:
    >     >     On 11/1/18 2:46 PM, Shane Poage wrote:
    >     >     
    >     >     > I have my proxy configured to bump all traffic so that the
    >     >     > urlpath_regex ACL can be applied, but it appears to not have any
    >     >     > effect post-bump.
    >     >     
    >     >     Your proxy will deny any first post-bump request and close the tunnel
    >     >     because you deny all CONNECT requests that initiate tunnels. CONNECT
    >     >     requests do not have a URL path so they will never match your
    >     >     "http_access allow" rule.
    >     >     
    >     >     When a CONNECT request is denied by a bumping Squid, that Squid bumps
    >     >     the tunnel and then denies the very first bumped request on that tunnel,
    >     >     whatever that request is. This delayed error return is done to deliver
    >     >     the "access denied" error page to the client -- browsers ignore CONNECT
    >     >     error responses.
    >     >     
    >     >     
    >     >     > http_port 3128 ssl-bump \
    >     >     >   cert=/etc/squid/ssl_certs/artifactory_mitm_ca.pem \
    >     >     >   generate-host-certificates=on \
    >     >     >   dynamic_cert_mem_cache_size=4MB
    >     >     
    >     >     > ssl_bump bump all
    >     >     
    >     >     > acl artifactory_repo_filter urlpath_regex ^/artifactory
    >     >     > http_access allow artifactory_repo_filter
    >     >     > 
    >     >     > # And finally deny all other access to this proxy
    >     >     > http_access deny all
    >     >     
    >     >     Insert an http_access rule to allow all safe CONNECT requests before you
    >     >     deny everything else. IIRC, squid.conf.default has an example of how to
    >     >     do that.
    >     >     
    >     >     Alex.
    >     >     _______________________________________________
    >     >     squid-users mailing list
    >     >     squid-users at lists.squid-cache.org
    >     >     http://lists.squid-cache.org/listinfo/squid-users
    >     >     
    >     > 
    >     
    >     
    > 
    
    


From rousskov at measurement-factory.com  Mon Nov  5 19:23:24 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 5 Nov 2018 12:23:24 -0700
Subject: [squid-users] URL Regex ACLs Don't Evaluate After Bumping
In-Reply-To: <DFD11E32-0BC9-4C51-A306-3151B0EA4374@entrustdatacard.com>
References: <56F1E161-4DC0-42CF-A1D7-99DAA0782DA5@entrustdatacard.com>
 <8e76c3ea-135d-6ad9-f4e3-9404dc4193a9@measurement-factory.com>
 <42FD2170-919A-4895-93DB-C48B7D7EC3BC@entrustdatacard.com>
 <c0630724-78ed-dd25-63da-2e6e418d7e58@measurement-factory.com>
 <A0E968E2-DEF5-425B-8158-FDD95F889866@entrustdatacard.com>
 <dbfa5f8d-b033-466c-8af6-b2b06e756d50@measurement-factory.com>
 <DFD11E32-0BC9-4C51-A306-3151B0EA4374@entrustdatacard.com>
Message-ID: <a53909fb-81a7-2335-7cb8-0ed56e5dbbda@measurement-factory.com>

On 11/5/18 12:02 PM, Shane Poage wrote:

> if I'm not misunderstanding how bumping works, have I uncovered a bug
> in Squid? Either in the form of the CONNECT ACL not being applied as
> expected, or in the form of the urlpath_regex not being applied... Or
> is there something additional that I'm fundamentally missing?

It is difficult for me to say why a correct configuration does not work
in your environment because you have not supplied any relevant details
(yet). You have supplied details for some other configurations IIRC, but
not the one you should be using.

As a starting point, I recommend posting your current/correct
configuration and the corresponding compressed ALL,3 cache.log while
reproducing a problem on an isolated Squid handling a single problematic
transaction. If possible, please use curl, wget, or another
single-request HTTP client to drive that transaction, not a browser.
Please also post the corresponding access.log lines.


Thank you,

Alex.


> ?On 11/2/18, 3:15 PM, "Alex Rousskov" <rousskov at measurement-factory.com> wrote:
> 
>     WARNING: This email originated outside of Entrust Datacard.
>     DO NOT CLICK links or attachments unless you trust the sender and know the content is safe.
>     
>     On 11/2/18 12:22 PM, Shane Poage wrote:
>     
>     > My understanding of how SSL bumping works is as follows, based on what
>     > I have read in all of the documentation I could possibly find:
>     
>     To simplify, I will interpret the statements below in SslBump context.
>     That is, I will interpret them as they are applied to traffic received
>     on an http_port with ssl-bump configured.
>     
>     I will also assume a bug-free implementation. In other words, the entire
>     text below is under the "Bugs notwithstanding..." precondition.
>     
>     
>     > 1. A CONNECT request comes in to the proxy from a client.
>     > 2. The proxy does access control on that CONNECT request and decides
>     >      whether or not to permit the tunnel. For the sake of moving on, let's
>     >      assume that it decides to allow.
>     
>     Correct. This decision is a part of SslBump step1.
>     
>     [ The decision to allow or deny CONNECT is done again during SslBump
>     step2 if a peek or stare action matches during step1. IIRC, those
>     additional checks do not happen in your configuration because your
>     ssl_bump rules match a bump action at step1. Thus, this additional
>     caveat does not apply to you. ]
>     
>     
>     > 3. The proxy then begins processing the rules for SSL bumping. Again, for the
>     >      sake of simplicity, we'll say that all traffic is getting bumped.
>     
>     OK. This processing is a part of SslBump step1.
>     
>     
>     > 4. The proxy begins bumping traffic and individually processing the requests
>     >      for that session.
>     
>     OK. This processing is a part of SslBump step1.
>     
>     [ Again, there could be more SslBump steps in general, but, in your
>     specific case, the client connection is bumped here. ]
>     
>     
>     > 5. Each request within the session has the http_access rules applied to them
>     >      as if they were normal HTTP requests made through the proxy, until the
>     >      session is terminated.
>     
>     These bumped requests have "https" scheme and some special properties
>     specific to bumped requests but, overall, they are indeed processed as
>     usual, including application of http_access rules to each of the bumped
>     request.
>     
>     
>     To make progress, I recommend identifying a specific Squid action that
>     contradicts either your understanding of how things should work or my
>     remarks and then posting the relevant details of that action along with
>     a clear explanation of where you see a contradiction.
>     
>     Alex.
>     
>     
>     > On 11/2/18, 12:26 PM, "Alex Rousskov" wrote:
>     > 
>     >     On 11/2/18 9:54 AM, Shane Poage wrote:
>     >     
>     >     > my original squid.conf had an ACL directive corresponding to the
>     >     > functionality in question:
>     >     
>     >     > 	acl CONNECT method CONNECT
>     >     
>     >     That CONNECT ACL declaration is OK, but what matters is how you _use_
>     >     that declared ACL. The configuration you posted earlier did not use it
>     >     at all.
>     >     
>     >     
>     >     > http_access allow CONNECT artifactory_repo_filter
>     >     
>     >     This "CONNECT and artifactory_repo_filter" rule does not make sense. As
>     >     I said earlier, your artifactory_repo_filter cannot match a CONNECT
>     >     request. Thus, you are joining two conditions that can never be
>     >     satisfied for the same request. For any request, you will get either
>     >     (false and true) or (true and false), which is, of course, always false.
>     >     
>     >     
>     >     > http_access allow CONNECT
>     >     > http_access allow artifactory_repo_filter
>     >     
>     >     This "CONNECT or artifactory_repo_filter" combination makes sense, but
>     >     the first part is dangerous -- you probably should not allow CONNECT
>     >     request to arbitrary port numbers. If you look at how CONNECT requests
>     >     are handled in squid.conf.default, then you will probably come up with
>     >     something like this:
>     >     
>     >       http_access deny !Safe_ports
>     >       http_access deny CONNECT !SSL_ports
>     >       http_access allow CONNECT
>     >       http_access allow artifactory_repo_filter
>     >       http_access deny all
>     >     
>     >     or a bit shorter but arguably less safe (long-term) version:
>     >     
>     >       http_access deny !Safe_ports
>     >       http_access allow CONNECT SSL_ports
>     >       http_access allow artifactory_repo_filter
>     >       http_access deny all
>     >     
>     >     or an even shorter but arguably even less safe (long-term) version:
>     >     
>     >       http_access allow SSL_ports CONNECT
>     >       http_access allow Safe_ports artifactory_repo_filter
>     >       http_access deny all
>     >     
>     >     
>     >     N.B. The above configurations allow plain text traffic matching
>     >     artifactory_repo_filter. I do not know whether that is what you want.
>     >     
>     >     
>     >     > 	This resulted in all SSL traffic being permitted and passed through
>     >     > 	the proxy.
>     >     
>     >     If you are still bumping all SSL traffic, and your
>     >     artifactory_repo_filter ACL is working, then all of the above reasonable
>     >     configurations should still block bumped GET requests that match
>     >     artifactory_repo_filter.
>     >     
>     >     
>     >     > This makes sense to me because the allow CONNECT
>     >     > 	would whitelist all CONNECT traffic, which is what all SSL traffic is
>     >     > 	by my understanding. 
>     >     
>     >     Your understanding is incorrect. Since you are bumping all CONNECT
>     >     tunnels, your http_access traffic consists of:
>     >     
>     >     * CONNECT requests
>     >     * decrypted requests (e.g., GET) inside bumped CONNECT tunnels
>     >     * plain requests (e.g., GET) outside CONNECT tunnels
>     >     
>     >     
>     >     HTH,
>     >     
>     >     Alex.
>     >     
>     >     
>     >     > On 11/1/18, 6:21 PM, Alex Rousskov wrote:
>     >     >     On 11/1/18 2:46 PM, Shane Poage wrote:
>     >     >     
>     >     >     > I have my proxy configured to bump all traffic so that the
>     >     >     > urlpath_regex ACL can be applied, but it appears to not have any
>     >     >     > effect post-bump.
>     >     >     
>     >     >     Your proxy will deny any first post-bump request and close the tunnel
>     >     >     because you deny all CONNECT requests that initiate tunnels. CONNECT
>     >     >     requests do not have a URL path so they will never match your
>     >     >     "http_access allow" rule.
>     >     >     
>     >     >     When a CONNECT request is denied by a bumping Squid, that Squid bumps
>     >     >     the tunnel and then denies the very first bumped request on that tunnel,
>     >     >     whatever that request is. This delayed error return is done to deliver
>     >     >     the "access denied" error page to the client -- browsers ignore CONNECT
>     >     >     error responses.
>     >     >     
>     >     >     
>     >     >     > http_port 3128 ssl-bump \
>     >     >     >   cert=/etc/squid/ssl_certs/artifactory_mitm_ca.pem \
>     >     >     >   generate-host-certificates=on \
>     >     >     >   dynamic_cert_mem_cache_size=4MB
>     >     >     
>     >     >     > ssl_bump bump all
>     >     >     
>     >     >     > acl artifactory_repo_filter urlpath_regex ^/artifactory
>     >     >     > http_access allow artifactory_repo_filter
>     >     >     > 
>     >     >     > # And finally deny all other access to this proxy
>     >     >     > http_access deny all
>     >     >     
>     >     >     Insert an http_access rule to allow all safe CONNECT requests before you
>     >     >     deny everything else. IIRC, squid.conf.default has an example of how to
>     >     >     do that.
>     >     >     
>     >     >     Alex.
>     >     >     _______________________________________________
>     >     >     squid-users mailing list
>     >     >     squid-users at lists.squid-cache.org
>     >     >     http://lists.squid-cache.org/listinfo/squid-users
>     >     >     
>     >     > 
>     >     
>     >     
>     > 
>     
>     
> 



From Walter.H at mathemainzel.info  Mon Nov  5 20:40:25 2018
From: Walter.H at mathemainzel.info (Walter H.)
Date: Mon, 05 Nov 2018 21:40:25 +0100
Subject: [squid-users] Message with SSL-bump with a specific site ...
Message-ID: <5BE0AAB9.1020606@mathemainzel.info>

Hello,

can some explain what is causing this message

While trying to retrieve the URL: https://www.3bg.at/*
The following error was encountered:

  * *Failed to establish a secure connection to 193.138.123.75 *

The system returned:
/    (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)/

     Handshake with SSL server failed: error:1408E0F4:SSL routines:SSL3_GET_MESSAGE:unexpected message

Thanks,
Walter


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181105/a996bd84/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181105/a996bd84/attachment.bin>

From wiedergold at web.de  Mon Nov  5 21:59:37 2018
From: wiedergold at web.de (Alexander Wiedergold)
Date: Mon, 5 Nov 2018 22:59:37 +0100
Subject: [squid-users] squid-users Digest, Vol 51, Issue 6
In-Reply-To: <mailman.365.1541445807.3019.squid-users@lists.squid-cache.org>
References: <mailman.365.1541445807.3019.squid-users@lists.squid-cache.org>
Message-ID: <d3f77205-a51d-c7a3-5e67-03dc26fc12c0@web.de>



Am 05.11.2018 um 20:23 schrieb squid-users-request at lists.squid-cache.org:
> Re: [squid-users] [EXTERNAL]Re: URL Regex ACLs Don't Evaluate
> 	After Bumping
change

acl CONNECT method CONNECT
on
acl abcde method CONNECT
this word reserved



From squid3 at treenet.co.nz  Tue Nov  6 03:47:26 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Nov 2018 16:47:26 +1300
Subject: [squid-users] Message with SSL-bump with a specific site ...
In-Reply-To: <5BE0AAB9.1020606@mathemainzel.info>
References: <5BE0AAB9.1020606@mathemainzel.info>
Message-ID: <0524d935-3449-dc38-6945-87577098c950@treenet.co.nz>

On 6/11/18 9:40 AM, Walter H. wrote:
> Hello,
> 
> can some explain what is causing this message
> 
> While trying to retrieve the URL: https://www.3bg.at/*

Squid was asked to open an HTTPS connection or tunnel to that server.


> The following error was encountered:
> 
>   * *Failed to establish a secure connection to 193.138.123.75 *
> 

The connection attempt failed.


> The system returned:
> /??? (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)/
> 

The TCP connection was closed by the OS or OpenSSL with TCP code 71.

Squid is using the SQUID_ERR_SSL_HANDSHAKE to represent what type of
protocol error. To make it clearer that it is not a TCP error but a TLS
handshake error inside the TCP connection.


> Handshake with SSL server failed: error:1408E0F4:SSL
> routines:SSL3_GET_MESSAGE:unexpected message
> 

OpenSSL gave this weird string to Squid as the reason for the failure.

A quick search for the string on line find that it means what it says -
 the other end of the connection is delivering something that your
OpenSSL library does not understand.


What that something is and why it is not understood is unknown. One now
has to look at the TCP packet trace to see what went wrong with the TLS
messaging.


Amos


From squid3 at treenet.co.nz  Tue Nov  6 03:53:05 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Nov 2018 16:53:05 +1300
Subject: [squid-users] squid-users Digest, Vol 51, Issue 6
In-Reply-To: <d3f77205-a51d-c7a3-5e67-03dc26fc12c0@web.de>
References: <mailman.365.1541445807.3019.squid-users@lists.squid-cache.org>
 <d3f77205-a51d-c7a3-5e67-03dc26fc12c0@web.de>
Message-ID: <70bdb4ee-620f-f392-64b6-156b26a8a892@treenet.co.nz>

On 6/11/18 10:59 AM, Alexander Wiedergold wrote:
> 
> 
> Am 05.11.2018 um 20:23 schrieb squid-users-request
>> Re: [squid-users] [EXTERNAL]Re: URL Regex ACLs Don't Evaluate
>> ????After Bumping
> change
> 
> acl CONNECT method CONNECT
> on
> acl abcde method CONNECT
> this word reserved
> 

That depends on Squid version. Only the very latest releases define it
as a built-in ACL. The currently more common Squid-3.x still require it
in the config file.


Also, one does not have to define it with a different name. Simply use
the name which is built-in if you have a Squid version doing that part
for you.

It (and others such as "all", "localhost", "manager") are built-in
exactly so admin do not have to bother with manually defining things
that everybody needs to use.

Amos


From Shane.Poage at entrustdatacard.com  Tue Nov  6 20:26:50 2018
From: Shane.Poage at entrustdatacard.com (Shane Poage)
Date: Tue, 6 Nov 2018 20:26:50 +0000
Subject: [squid-users] [EXTERNAL]Re: URL Regex ACLs Don't Evaluate After
 Bumping
In-Reply-To: <a53909fb-81a7-2335-7cb8-0ed56e5dbbda@measurement-factory.com>
References: <56F1E161-4DC0-42CF-A1D7-99DAA0782DA5@entrustdatacard.com>
 <8e76c3ea-135d-6ad9-f4e3-9404dc4193a9@measurement-factory.com>
 <42FD2170-919A-4895-93DB-C48B7D7EC3BC@entrustdatacard.com>
 <c0630724-78ed-dd25-63da-2e6e418d7e58@measurement-factory.com>
 <A0E968E2-DEF5-425B-8158-FDD95F889866@entrustdatacard.com>
 <dbfa5f8d-b033-466c-8af6-b2b06e756d50@measurement-factory.com>
 <DFD11E32-0BC9-4C51-A306-3151B0EA4374@entrustdatacard.com>
 <a53909fb-81a7-2335-7cb8-0ed56e5dbbda@measurement-factory.com>
Message-ID: <741DAB96-CB60-4BE0-B032-F417BCFA4044@entrustdatacard.com>

Alex,

I have attached a gzipped tarball that includes three items:
1. The squid.conf for the configuration that is not behaving as I expected
2. The access.log for two requests (which I will describe in a moment)
3. The cache.log for startup, those same two requests, and shutdown of the squid instance.

The two requests made through the proxy were made using wget on another machine configured to route traffic through the proxy:
1) https://www.google.com/ - Squid permitted the traffic through. According to my understanding, it should have denied it due to the urlpath_regex ACL in the config.
2) https://sottartifactory.corporate.datacard.com:8443/artifactory/some/path/to/artifact.jar - This one was allowed through, which is expected in this case.

Please let me know if there's any more information I can provide that would be helpful, and thanks again for sticking with me on this.
-Shane


?On 11/5/18, 1:23 PM, "Alex Rousskov" <rousskov at measurement-factory.com> wrote:

    WARNING: This email originated outside of Entrust Datacard.
    DO NOT CLICK links or attachments unless you trust the sender and know the content is safe.
    
    On 11/5/18 12:02 PM, Shane Poage wrote:
    
    > if I'm not misunderstanding how bumping works, have I uncovered a bug
    > in Squid? Either in the form of the CONNECT ACL not being applied as
    > expected, or in the form of the urlpath_regex not being applied... Or
    > is there something additional that I'm fundamentally missing?
    
    It is difficult for me to say why a correct configuration does not work
    in your environment because you have not supplied any relevant details
    (yet). You have supplied details for some other configurations IIRC, but
    not the one you should be using.
    
    As a starting point, I recommend posting your current/correct
    configuration and the corresponding compressed ALL,3 cache.log while
    reproducing a problem on an isolated Squid handling a single problematic
    transaction. If possible, please use curl, wget, or another
    single-request HTTP client to drive that transaction, not a browser.
    Please also post the corresponding access.log lines.
    
    
    Thank you,
    
    Alex.
    
    
    > On 11/2/18, 3:15 PM, "Alex Rousskov" <rousskov at measurement-factory.com> wrote:
    > 
    >     WARNING: This email originated outside of Entrust Datacard.
    >     DO NOT CLICK links or attachments unless you trust the sender and know the content is safe.
    >     
    >     On 11/2/18 12:22 PM, Shane Poage wrote:
    >     
    >     > My understanding of how SSL bumping works is as follows, based on what
    >     > I have read in all of the documentation I could possibly find:
    >     
    >     To simplify, I will interpret the statements below in SslBump context.
    >     That is, I will interpret them as they are applied to traffic received
    >     on an http_port with ssl-bump configured.
    >     
    >     I will also assume a bug-free implementation. In other words, the entire
    >     text below is under the "Bugs notwithstanding..." precondition.
    >     
    >     
    >     > 1. A CONNECT request comes in to the proxy from a client.
    >     > 2. The proxy does access control on that CONNECT request and decides
    >     >      whether or not to permit the tunnel. For the sake of moving on, let's
    >     >      assume that it decides to allow.
    >     
    >     Correct. This decision is a part of SslBump step1.
    >     
    >     [ The decision to allow or deny CONNECT is done again during SslBump
    >     step2 if a peek or stare action matches during step1. IIRC, those
    >     additional checks do not happen in your configuration because your
    >     ssl_bump rules match a bump action at step1. Thus, this additional
    >     caveat does not apply to you. ]
    >     
    >     
    >     > 3. The proxy then begins processing the rules for SSL bumping. Again, for the
    >     >      sake of simplicity, we'll say that all traffic is getting bumped.
    >     
    >     OK. This processing is a part of SslBump step1.
    >     
    >     
    >     > 4. The proxy begins bumping traffic and individually processing the requests
    >     >      for that session.
    >     
    >     OK. This processing is a part of SslBump step1.
    >     
    >     [ Again, there could be more SslBump steps in general, but, in your
    >     specific case, the client connection is bumped here. ]
    >     
    >     
    >     > 5. Each request within the session has the http_access rules applied to them
    >     >      as if they were normal HTTP requests made through the proxy, until the
    >     >      session is terminated.
    >     
    >     These bumped requests have "https" scheme and some special properties
    >     specific to bumped requests but, overall, they are indeed processed as
    >     usual, including application of http_access rules to each of the bumped
    >     request.
    >     
    >     
    >     To make progress, I recommend identifying a specific Squid action that
    >     contradicts either your understanding of how things should work or my
    >     remarks and then posting the relevant details of that action along with
    >     a clear explanation of where you see a contradiction.
    >     
    >     Alex.
    >     
    >     
    >     > On 11/2/18, 12:26 PM, "Alex Rousskov" wrote:
    >     > 
    >     >     On 11/2/18 9:54 AM, Shane Poage wrote:
    >     >     
    >     >     > my original squid.conf had an ACL directive corresponding to the
    >     >     > functionality in question:
    >     >     
    >     >     > 	acl CONNECT method CONNECT
    >     >     
    >     >     That CONNECT ACL declaration is OK, but what matters is how you _use_
    >     >     that declared ACL. The configuration you posted earlier did not use it
    >     >     at all.
    >     >     
    >     >     
    >     >     > http_access allow CONNECT artifactory_repo_filter
    >     >     
    >     >     This "CONNECT and artifactory_repo_filter" rule does not make sense. As
    >     >     I said earlier, your artifactory_repo_filter cannot match a CONNECT
    >     >     request. Thus, you are joining two conditions that can never be
    >     >     satisfied for the same request. For any request, you will get either
    >     >     (false and true) or (true and false), which is, of course, always false.
    >     >     
    >     >     
    >     >     > http_access allow CONNECT
    >     >     > http_access allow artifactory_repo_filter
    >     >     
    >     >     This "CONNECT or artifactory_repo_filter" combination makes sense, but
    >     >     the first part is dangerous -- you probably should not allow CONNECT
    >     >     request to arbitrary port numbers. If you look at how CONNECT requests
    >     >     are handled in squid.conf.default, then you will probably come up with
    >     >     something like this:
    >     >     
    >     >       http_access deny !Safe_ports
    >     >       http_access deny CONNECT !SSL_ports
    >     >       http_access allow CONNECT
    >     >       http_access allow artifactory_repo_filter
    >     >       http_access deny all
    >     >     
    >     >     or a bit shorter but arguably less safe (long-term) version:
    >     >     
    >     >       http_access deny !Safe_ports
    >     >       http_access allow CONNECT SSL_ports
    >     >       http_access allow artifactory_repo_filter
    >     >       http_access deny all
    >     >     
    >     >     or an even shorter but arguably even less safe (long-term) version:
    >     >     
    >     >       http_access allow SSL_ports CONNECT
    >     >       http_access allow Safe_ports artifactory_repo_filter
    >     >       http_access deny all
    >     >     
    >     >     
    >     >     N.B. The above configurations allow plain text traffic matching
    >     >     artifactory_repo_filter. I do not know whether that is what you want.
    >     >     
    >     >     
    >     >     > 	This resulted in all SSL traffic being permitted and passed through
    >     >     > 	the proxy.
    >     >     
    >     >     If you are still bumping all SSL traffic, and your
    >     >     artifactory_repo_filter ACL is working, then all of the above reasonable
    >     >     configurations should still block bumped GET requests that match
    >     >     artifactory_repo_filter.
    >     >     
    >     >     
    >     >     > This makes sense to me because the allow CONNECT
    >     >     > 	would whitelist all CONNECT traffic, which is what all SSL traffic is
    >     >     > 	by my understanding. 
    >     >     
    >     >     Your understanding is incorrect. Since you are bumping all CONNECT
    >     >     tunnels, your http_access traffic consists of:
    >     >     
    >     >     * CONNECT requests
    >     >     * decrypted requests (e.g., GET) inside bumped CONNECT tunnels
    >     >     * plain requests (e.g., GET) outside CONNECT tunnels
    >     >     
    >     >     
    >     >     HTH,
    >     >     
    >     >     Alex.
    >     >     
    >     >     
    >     >     > On 11/1/18, 6:21 PM, Alex Rousskov wrote:
    >     >     >     On 11/1/18 2:46 PM, Shane Poage wrote:
    >     >     >     
    >     >     >     > I have my proxy configured to bump all traffic so that the
    >     >     >     > urlpath_regex ACL can be applied, but it appears to not have any
    >     >     >     > effect post-bump.
    >     >     >     
    >     >     >     Your proxy will deny any first post-bump request and close the tunnel
    >     >     >     because you deny all CONNECT requests that initiate tunnels. CONNECT
    >     >     >     requests do not have a URL path so they will never match your
    >     >     >     "http_access allow" rule.
    >     >     >     
    >     >     >     When a CONNECT request is denied by a bumping Squid, that Squid bumps
    >     >     >     the tunnel and then denies the very first bumped request on that tunnel,
    >     >     >     whatever that request is. This delayed error return is done to deliver
    >     >     >     the "access denied" error page to the client -- browsers ignore CONNECT
    >     >     >     error responses.
    >     >     >     
    >     >     >     
    >     >     >     > http_port 3128 ssl-bump \
    >     >     >     >   cert=/etc/squid/ssl_certs/artifactory_mitm_ca.pem \
    >     >     >     >   generate-host-certificates=on \
    >     >     >     >   dynamic_cert_mem_cache_size=4MB
    >     >     >     
    >     >     >     > ssl_bump bump all
    >     >     >     
    >     >     >     > acl artifactory_repo_filter urlpath_regex ^/artifactory
    >     >     >     > http_access allow artifactory_repo_filter
    >     >     >     > 
    >     >     >     > # And finally deny all other access to this proxy
    >     >     >     > http_access deny all
    >     >     >     
    >     >     >     Insert an http_access rule to allow all safe CONNECT requests before you
    >     >     >     deny everything else. IIRC, squid.conf.default has an example of how to
    >     >     >     do that.
    >     >     >     
    >     >     >     Alex.
    >     >     >     _______________________________________________
    >     >     >     squid-users mailing list
    >     >     >     squid-users at lists.squid-cache.org
    >     >     >     http://lists.squid-cache.org/listinfo/squid-users
    >     >     >     
    >     >     > 
    >     >     
    >     >     
    >     > 
    >     
    >     
    > 
    
    

-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid_debug.tar.gz
Type: application/x-gzip
Size: 33908 bytes
Desc: squid_debug.tar.gz
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181106/8e990d36/attachment.bin>

From squid3 at treenet.co.nz  Tue Nov  6 22:34:01 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 7 Nov 2018 11:34:01 +1300
Subject: [squid-users] [EXTERNAL]Re: URL Regex ACLs Don't Evaluate After
 Bumping
In-Reply-To: <741DAB96-CB60-4BE0-B032-F417BCFA4044@entrustdatacard.com>
References: <56F1E161-4DC0-42CF-A1D7-99DAA0782DA5@entrustdatacard.com>
 <8e76c3ea-135d-6ad9-f4e3-9404dc4193a9@measurement-factory.com>
 <42FD2170-919A-4895-93DB-C48B7D7EC3BC@entrustdatacard.com>
 <c0630724-78ed-dd25-63da-2e6e418d7e58@measurement-factory.com>
 <A0E968E2-DEF5-425B-8158-FDD95F889866@entrustdatacard.com>
 <dbfa5f8d-b033-466c-8af6-b2b06e756d50@measurement-factory.com>
 <DFD11E32-0BC9-4C51-A306-3151B0EA4374@entrustdatacard.com>
 <a53909fb-81a7-2335-7cb8-0ed56e5dbbda@measurement-factory.com>
 <741DAB96-CB60-4BE0-B032-F417BCFA4044@entrustdatacard.com>
Message-ID: <7398ab7f-3454-de30-95a4-249536e3ff76@treenet.co.nz>

On 7/11/18 9:26 AM, Shane Poage wrote:
> Alex,
> 
> I have attached a gzipped tarball that includes three items:
> 1. The squid.conf for the configuration that is not behaving as I expected
> 2. The access.log for two requests (which I will describe in a moment)
> 3. The cache.log for startup, those same two requests, and shutdown of the squid instance.
> 
> The two requests made through the proxy were made using wget on another machine configured to route traffic through the proxy:
> 1) https://www.google.com/ - Squid permitted the traffic through. According to my understanding, it should have denied it due to the urlpath_regex ACL in the config.
> 2) https://sottartifactory.corporate.datacard.com:8443/artifactory/some/path/to/artifact.jar - This one was allowed through, which is expected in this case.
> 
> Please let me know if there's any more information I can provide that would be helpful, and thanks again for sticking with me on this.
> -Shane
> 

This is bug 4682 which was fixed last year in 3.5.26.

Amos


From heiler.bemerguy at cinbesa.com.br  Wed Nov  7 11:24:57 2018
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Wed, 7 Nov 2018 08:24:57 -0300
Subject: [squid-users] 3.5.27 to 4.4: a worker is dead
Message-ID: <810ddb3c-d5ff-a15d-b094-469ba3be61e1@cinbesa.com.br>

After some hours the worker 4 died unexpectely and didn't come back. I 
have cleaned the rock cache store before upgrading just to be safe.. 
COLD start........

proxy??? 15478? 0.6? 1.8 9518972 1207212 ????? S??? Nov06?? 6:17 
(squid-5) --kid squid-5 -s
proxy??? 15480? 0.4? 1.4 9391808 954248 ?????? S??? Nov06?? 3:56 
(squid-3) --kid squid-3 -s
proxy??? 15481? 1.1? 2.5 9734420 1679360 ????? S??? Nov06? 10:45 
(squid-2) --kid squid-2 -s
proxy??? 26933? 0.0? 0.0 6501296 26768 ??????? S??? 00:25?? 0:01 
(squid-coord-9) --kid squid-coord-9 -s
proxy??? 26936? 0.0? 0.6 7424208 401788 ?????? S??? 00:25?? 0:07 
(squid-disk-6) --kid squid-disk-6 -s
proxy??? 27011? 0.0? 0.2 7424208 185580 ?????? S??? 00:28?? 0:03 
(squid-disk-7) --kid squid-disk-7 -s
proxy??? 27227? 0.0? 0.0 7424208 54980 ??????? S??? 00:37?? 0:01 
(squid-disk-8) --kid squid-disk-8 -s

AMD64 12-core, 64gb ram

cache_mem 5200 MB
maximum_object_size_in_memory 2 MB
maximum_object_size 4 GB
workers 5
cache_dir rock /cache2 131000 min-size=1 max-size=196608
cache_dir rock /cache3 131000 min-size=196609 max-size=624288
cache_dir rock /cache4 131000 min-size=624289 max-swap-rate=500 
swap-timeout=500

Squid Cache: Version 4.4
Service Name: squid

This binary uses OpenSSL 1.0.1t? 3 May 2016. For legal restrictions on 
distribution see https://www.openssl.org/source/license.html

configure options:? '--enable-delay-pools' '--with-openssl' 
'--enable-htcp' '--disable-maintainer-mode' 
'--disable-dependency-tracking' '--disable-wccp' '--disable-snmp' 
'--enable-inline' '--enable-async-io=32' '--enable-storeio=aufs,rock' 
'--enable-underscores' '--enable-removal-policies=lru,heap' 
'--enable-http-violations' '--disable-ident-lookups' 
'--with-large-files' '--enable-ssl' '--enable-ltdl-convenience' 
'--prefix=/usr' '--localstatedir=/var' '--libexecdir=/lib/squid' 
'--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' 
'--with-default-user=proxy' '--with-logdir=/var/log' 
'--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=16384' 
'--with-aufs-threads=32' '--disable-translation'


2018/11/07 07:06:19 kid4| clientProcessHit: URL mismatch, 
'[unknown_URI]' != 
'http://ocsp.godaddy.com//MEQwQjBAMD4wPDAJBgUrDgMCGgUABBTkIInKBAzXkF0Qh0pel3lfHJ9GPAQU0sSw0pHUTBFxs2HLPaH%2B3ahq1OMCAxvnFQ%3D%3D'
2018/11/07 07:07:11 kid4| WARNING: communication with /cache2/rock may 
be too slow or disrupted for about 7.00s; rescued 1 out of 1 I/Os
2018/11/07 07:07:11 kid4| clientProcessHit: URL mismatch, 
'[unknown_URI]' != 'http://www.orm.com.br/templates/noticiaDev.php'
2018/11/07 07:13:26 kid4| clientProcessHit: URL mismatch, 
'[unknown_URI]' != 
'http://storage.googleapis.com/update-delta/hfnkpimlhhgieaddgfemjhofmfblmnib/4803/4802/b767e40b59c48c2ec52977502ac10e35b84c00600197162f42dd941b5095cafd.crxd'
2018/11/07 07:17:03 kid4| FATAL: Dying from an exception handling 
failure; exception: check failed: false
 ??? exception location: mem/PageStack.cc(106) push

2018/11/07 07:17:03 kid4| Current Directory is /etc/init.d
2018/11/07 07:17:03 kid4| Starting Squid Cache version 4.4 for 
x86_64-pc-linux-gnu...
2018/11/07 07:17:03 kid4| Service Name: squid
2018/11/07 07:17:03 kid4| Process ID 6320
2018/11/07 07:17:03 kid4| Process Roles: worker
2018/11/07 07:17:03 kid4| With 65536 file descriptors available
2018/11/07 07:17:03 kid4| Initializing IP Cache...
2018/11/07 07:17:03 kid4| DNS Socket created at [::], FD 5
2018/11/07 07:17:03 kid4| DNS Socket created at 0.0.0.0, FD 13
2018/11/07 07:17:03 kid4| Adding domain cinbesa.pmb from /etc/resolv.conf
2018/11/07 07:17:03 kid4| Adding nameserver 127.0.0.1 from /etc/resolv.conf
2018/11/07 07:17:03 kid4| helperOpenServers: Starting 8/16 'ufdbgclient' 
processes
2018/11/07 07:17:03 kid4| helperOpenServers: Starting 10/30 
'store-id.pl' processes
2018/11/07 07:17:03 kid4| Logfile: opening log 
daemon:/var/log/squid/access.log
2018/11/07 07:17:03 kid4| Logfile Daemon: opening log 
/var/log/squid/access.log
2018/11/07 07:17:03 kid4| Store logging disabled
2018/11/07 07:17:03 kid4| WARNING: disk-cache maximum object size is too 
large for mem-cache: 4194304.00 KB > 2048.00 KB
2018/11/07 07:17:03 kid4| Swap maxSize 0 + 5324800 KB, estimated 118328 
objects
2018/11/07 07:17:03 kid4| Target number of buckets: 11832
2018/11/07 07:17:03 kid4| Using 16384 Store buckets
2018/11/07 07:17:03 kid4| Max Mem? size: 5324800 KB [shared]
2018/11/07 07:17:03 kid4| Max Swap size: 0 KB
2018/11/07 07:17:03 kid4| Using Least Load store dir selection
2018/11/07 07:17:03 kid4| Current Directory is /etc/init.d
2018/11/07 07:17:03 kid4| Finished loading MIME types and icons.
2018/11/07 07:17:03 kid4| Configuring Parent 10.1.10.10/8081/0
2018/11/07 07:17:03 kid4| Squid plugin modules loaded: 0
2018/11/07 07:17:03 kid4| Adaptation support is off.
2018/11/07 07:17:09 kid4| Closing HTTP(S) port [::]:3080
2018/11/07 07:17:09 kid4| Not currently OK to rewrite swap log.
2018/11/07 07:17:09 kid4| storeDirWriteCleanLogs: Operation aborted.
2018/11/07 07:17:09 kid4| FATAL: kid4 registration timed out
2018/11/07 07:17:09 kid4| Squid Cache (Version 4.4): Terminated abnormally.
CPU Usage: 0.036 seconds = 0.024 user + 0.012 sys
Maximum Resident Size: 156240 KB
Page faults with physical i/o: 0
2018/11/07 07:17:09 kid4| Current Directory is /etc/init.d
2018/11/07 07:17:09 kid4| Starting Squid Cache version 4.4 for 
x86_64-pc-linux-gnu...
2018/11/07 07:17:09 kid4| Service Name: squid
2018/11/07 07:17:09 kid4| Process ID 6341
2018/11/07 07:17:09 kid4| Process Roles: worker
2018/11/07 07:17:09 kid4| With 65536 file descriptors available
2018/11/07 07:17:09 kid4| Initializing IP Cache...
2018/11/07 07:17:09 kid4| DNS Socket created at [::], FD 5
2018/11/07 07:17:09 kid4| DNS Socket created at 0.0.0.0, FD 13
2018/11/07 07:17:09 kid4| Adding domain cinbesa.pmb from /etc/resolv.conf
2018/11/07 07:17:09 kid4| Adding nameserver 127.0.0.1 from /etc/resolv.conf
2018/11/07 07:17:09 kid4| helperOpenServers: Starting 8/16 'ufdbgclient' 
processes
2018/11/07 07:17:09 kid4| helperOpenServers: Starting 10/30 
'store-id.pl' processes
2018/11/07 07:17:09 kid4| Logfile: opening log 
daemon:/var/log/squid/access.log
2018/11/07 07:17:09 kid4| Logfile Daemon: opening log 
/var/log/squid/access.log
2018/11/07 07:17:09 kid4| Store logging disabled
2018/11/07 07:17:09 kid4| WARNING: disk-cache maximum object size is too 
large for mem-cache: 4194304.00 KB > 2048.00 KB
2018/11/07 07:17:09 kid4| Swap maxSize 0 + 5324800 KB, estimated 118328 
objects
2018/11/07 07:17:09 kid4| Target number of buckets: 11832
2018/11/07 07:17:09 kid4| Using 16384 Store buckets
2018/11/07 07:17:09 kid4| Max Mem? size: 5324800 KB [shared]
2018/11/07 07:17:09 kid4| Max Swap size: 0 KB
2018/11/07 07:17:09 kid4| Using Least Load store dir selection
2018/11/07 07:17:09 kid4| Current Directory is /etc/init.d
2018/11/07 07:17:09 kid4| Finished loading MIME types and icons.
2018/11/07 07:17:09 kid4| Configuring Parent 10.1.10.10/8081/0
2018/11/07 07:17:09 kid4| Squid plugin modules loaded: 0
2018/11/07 07:17:09 kid4| Adaptation support is off.
2018/11/07 07:17:15 kid4| Closing HTTP(S) port [::]:3080
2018/11/07 07:17:15 kid4| Not currently OK to rewrite swap log.
2018/11/07 07:17:15 kid4| storeDirWriteCleanLogs: Operation aborted.
2018/11/07 07:17:15 kid4| FATAL: kid4 registration timed out
2018/11/07 07:17:15 kid4| Squid Cache (Version 4.4): Terminated abnormally.
CPU Usage: 0.040 seconds = 0.024 user + 0.016 sys
Maximum Resident Size: 156496 KB
Page faults with physical i/o: 0

(loop)

-- 
Atenciosamente,

Heiler Bensimon Bemerguy - CINBESA
Analista de Redes, Wi-Fi,
Virtualiza??o e Servi?os Internet
(55) 91 98151-4894



From marko.cupac at mimar.rs  Wed Nov  7 12:00:00 2018
From: marko.cupac at mimar.rs (Marko =?UTF-8?B?Q3VwYcSH?=)
Date: Wed, 7 Nov 2018 13:00:00 +0100
Subject: [squid-users] Squid crashes with
	"!Comm::MonitorsRead(serverConnection->fd)"
Message-ID: <20181107130000.1bc6682c@efreet.kappastar.com>

Hi,

I am trying to set up ssl-bumped, kerberos-authenticated proxy with 4.3
on FreeBSD.

It works, but under load it crashes with the following message in
cache.log:

2018/11/07 12:41:45 kid1| assertion failed: http.cc:1530:
"!Comm::MonitorsRead(serverConnection->fd)"

I also get this message in squid jail's messages.log:

Nov  7 12:49:06 squid2 squid[86874]: Squid Parent: squid-1 process 3203
exited due to signal 6 with status 0

I suspected FreeBSD's low kern.ipc.somaxconn of 128, due to the
following in jail host's messages.log:
Nov  7 12:11:19 warden4 kernel: sonewconn: pcb 0xfffff8039fa301d0:
Listen queue overflow: 769 already in queue awaiting acceptance (334
occurrences)

However, after bumping it to 512 above message disappeared but squid
crashes remained.

I am monitoring queue length on jail host with `netstat -Lan', and I
notice, just before crash, queue goes way up, to more than 512, and
then goes back to 0 when squid restarts.

Maybe unrelated, but always around time of crash I see the following
line in squid's access.log:

1541590880.172      0 - TCP_MEM_HIT/200 1521 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- application/octet-stream

Notice there's no client IP address in the line. How come? How can I
find out which clients request this?

Thank you in advance,

-- 
Before enlightenment - chop wood, draw water.
After  enlightenment - chip wood, draw water.

Marko Cupa?
https://www.mimar.rs/


From rousskov at measurement-factory.com  Wed Nov  7 17:23:12 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 7 Nov 2018 10:23:12 -0700
Subject: [squid-users] Squid crashes with
 "!Comm::MonitorsRead(serverConnection->fd)"
In-Reply-To: <20181107130000.1bc6682c@efreet.kappastar.com>
References: <20181107130000.1bc6682c@efreet.kappastar.com>
Message-ID: <88b35a6c-2215-878e-073c-5827e0fe4c95@measurement-factory.com>

On 11/7/18 5:00 AM, Marko Cupa? wrote:

> 2018/11/07 12:41:45 kid1| assertion failed: http.cc:1530:
> "!Comm::MonitorsRead(serverConnection->fd)"

IIRC, there are relevant bug reports in bugzilla.


> Nov  7 12:49:06 squid2 squid[86874]: Squid Parent: squid-1 process 3203
> exited due to signal 6 with status 0

If these messages do not correlate with assertions mentioned earlier,
then please collect a stack trace from these crashes and post it to
bugzilla.


> Maybe unrelated, but always around time of crash I see the following
> line in squid's access.log:
> 
> 1541590880.172      0 - TCP_MEM_HIT/200 1521 GET
> http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
> HIER_NONE/- application/octet-stream
> 
> Notice there's no client IP address in the line. How come?

Probably a request that was generated by Squid itself (e.g., when
fetching a missing intermediate x509 certificate).

Alex.


From info at schroeffu.ch  Wed Nov  7 20:54:08 2018
From: info at schroeffu.ch (Schroeffu)
Date: Wed, 7 Nov 2018 14:54:08 -0600 (CST)
Subject: [squid-users] Ipv6 error
In-Reply-To: <81b68fb1-41c0-25cb-4d52-c82984e0f554@treenet.co.nz>
References: <1507554880116-0.post@n4.nabble.com>
 <85e8f625-03bb-d9cf-743f-0de6782fad03@treenet.co.nz>
 <1507567619725-0.post@n4.nabble.com>
 <4064383f-0dbe-d81e-5bf5-d694ced2d736@treenet.co.nz>
 <1507641845081-0.post@n4.nabble.com> <1507641979145-0.post@n4.nabble.com>
 <81b68fb1-41c0-25cb-4d52-c82984e0f554@treenet.co.nz>
Message-ID: <1541624048065-0.post@n4.nabble.com>

I have had today experienced today exactly the same issue with Squid 4.4 for
this URL: https://bugs.squid-cache.org/index.cgi
(but not https://wiki.squid-cache.org/*, that one works)

Error Message from Squid:

/The following error was encountered while trying to retrieve the URL:
https://bugs.squid-cache.org/*
Connection to 2001:4801:7827:102:ad34:6f78:b6dc:fbed failed.
The system returned: (101) Network is unreachable/

It is not only IPv6 related issue. It happens to me when denying any request
via proxy without authentification like this:

/acl Authenticated_Users proxy_auth REQUIRED
http_access deny !Authenticated_Users all/

You will see in the access log Squid is trying to hit
http://cert.int-x3.letsencrypt.org/ directly with 407 (not authenticated), i
am so confused, why is it doing that and why is it not authenticating?

1541623232.530      0 - *TCP_DENIED/407 3619 GET
http://cert.int-x3.letsencrypt.org/* - HIER_NONE/- text/html;charset=utf-8
1541623232.530    245 172.16.5.15 NONE/200 0 CONNECT
bugs.squid-cache.org:443 xxxx
HIER_DIRECT/2001:4801:7827:102:ad34:6f78:b6dc:fbed -
1541623232.546      0 172.16.5.15 NONE/503 4940 GET
https://bugs.squid-cache.org/favicon.ico xxxx HIER_NONE/- text/html

So i added another acl on top in squid.conf  to whitelist  *.letsencrypt.org
without authentification and bam, the website
https://bugs.squid-cache.org/index.cgi is opening now:

/acl white_regexp url_regex -i
"/etc/squid/domains_whitelist_regex_without_authentification.acl"
http_access allow white_regexp/

Content: 
\.letsencrypt\.org

I think somebody should track this, it is so weird! Why it happens on
https://bugs.squid-cache.org/index.cgi and how is that letsencrypt related?
I have no problems with any other letsencrypt secured domains and also not
on any site providing ipv4/ipv6 at the same time (Google/Facebook). But yes,
also my Proxy can *not*speech ipv6, if that is something related with
letsencrypt?
more specs:
- ssl bump active
- icapcan active
- ntlm and basic auth active
- dns_v4_first on/off doen't matter/doesnt change anything.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From vh1988 at yahoo.com.ar  Wed Nov  7 22:33:33 2018
From: vh1988 at yahoo.com.ar (Julian Perconti)
Date: Wed, 7 Nov 2018 19:33:33 -0300
Subject: [squid-users] Squid crashes with
	"!Comm::MonitorsRead(serverConnection->fd)"
In-Reply-To: <88b35a6c-2215-878e-073c-5827e0fe4c95@measurement-factory.com>
References: <20181107130000.1bc6682c@efreet.kappastar.com>
 <88b35a6c-2215-878e-073c-5827e0fe4c95@measurement-factory.com>
Message-ID: <01af01d476e9$eca5e6a0$c5f1b3e0$@yahoo.com.ar>

> > 2018/11/07 12:41:45 kid1| assertion failed: http.cc:1530:
> > "!Comm::MonitorsRead(serverConnection->fd)"
> 
> IIRC, there are relevant bug reports in bugzilla.
> 

Hi, 

See if this helps or its similar to your case: https://bugs.squid-cache.org/show_bug.cgi?id=4896

If your squid's crash is similar, there is a patch as a workarround.




From rousskov at measurement-factory.com  Wed Nov  7 22:57:56 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 7 Nov 2018 15:57:56 -0700
Subject: [squid-users] Ipv6 error
In-Reply-To: <1541624048065-0.post@n4.nabble.com>
References: <1507554880116-0.post@n4.nabble.com>
 <85e8f625-03bb-d9cf-743f-0de6782fad03@treenet.co.nz>
 <1507567619725-0.post@n4.nabble.com>
 <4064383f-0dbe-d81e-5bf5-d694ced2d736@treenet.co.nz>
 <1507641845081-0.post@n4.nabble.com> <1507641979145-0.post@n4.nabble.com>
 <81b68fb1-41c0-25cb-4d52-c82984e0f554@treenet.co.nz>
 <1541624048065-0.post@n4.nabble.com>
Message-ID: <7eb9a2e8-e278-2708-d90b-cc0ad98748aa@measurement-factory.com>

On 11/7/18 1:54 PM, Schroeffu wrote:
> I have had today experienced today exactly the same issue with Squid 4.4 for
> this URL: https://bugs.squid-cache.org/index.cgi

> Error Message from Squid:
> 
> /The following error was encountered while trying to retrieve the URL:
> https://bugs.squid-cache.org/*
> Connection to 2001:4801:7827:102:ad34:6f78:b6dc:fbed failed.
> The system returned: (101) Network is unreachable/
> 
> It is not only IPv6 related issue. It happens to me when denying any request
> via proxy without authentification like this:
> 
> acl Authenticated_Users proxy_auth REQUIRED
> http_access deny !Authenticated_Users all


For most modern Squids, this http_access policy is, IMO, incorrect
because it blocks internally-generated requests, such as requests for
missing intermediate certificates. Please adjust your configuration to
allow those requests (if you want them to be allowed).

[rant]It could be argued that Squid should automatically allow
internally-generated requests, but I do not think that would be a good
approach, despite the inconveniences/problems caused by the current
"apply standard http_access rules" approach.[/rant]

N.B. There is no need to say "all" after another ACL in a rule. It is
like adding "and true" to some boolean statement -- it adds no value and
creates noise/overheads.


> You will see in the access log Squid is trying to hit
> http://cert.int-x3.letsencrypt.org/ directly with 407 (not authenticated), i
> am so confused, why is it doing that and why is it not authenticating?

I suspect Squid is requesting a missing intermediate certificate for
some letsencrypt-issued origin certificate. This is "normal" -- some
https sites do not send all of the intermediate x509 certificates, and
modern Squids request them automatically instead of failing certificate
validation.

Squid does not "trying to hit letsencrypt.org with 407". HTTP 407 is a
response status code, not a part of the request. That error response is
probably generated by Squid (not letsencrypt.org); its existence and its
status code are determined/caused by your own http_access settings -- it
is your Squid that is denying the internal request, not letsencrypt.org.

HTH,

Alex.


> 1541623232.530      0 - *TCP_DENIED/407 3619 GET
> http://cert.int-x3.letsencrypt.org/* - HIER_NONE/- text/html;charset=utf-8
> 1541623232.530    245 172.16.5.15 NONE/200 0 CONNECT
> bugs.squid-cache.org:443 xxxx
> HIER_DIRECT/2001:4801:7827:102:ad34:6f78:b6dc:fbed -
> 1541623232.546      0 172.16.5.15 NONE/503 4940 GET
> https://bugs.squid-cache.org/favicon.ico xxxx HIER_NONE/- text/html

> Why it happens on
> https://bugs.squid-cache.org/index.cgi and how is that letsencrypt related?
> I have no problems with any other letsencrypt secured domains and also not
> on any site providing ipv4/ipv6 at the same time (Google/Facebook). But yes,
> also my Proxy can *not*speech ipv6, if that is something related with
> letsencrypt?
> more specs:
> - ssl bump active
> - icapcan active
> - ntlm and basic auth active
> - dns_v4_first on/off doen't matter/doesnt change anything.




From squid3 at treenet.co.nz  Thu Nov  8 03:32:03 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 8 Nov 2018 16:32:03 +1300
Subject: [squid-users] 3.5.27 to 4.4: a worker is dead
In-Reply-To: <810ddb3c-d5ff-a15d-b094-469ba3be61e1@cinbesa.com.br>
References: <810ddb3c-d5ff-a15d-b094-469ba3be61e1@cinbesa.com.br>
Message-ID: <ec26a481-104f-5315-3dbe-ec4063beb12b@treenet.co.nz>

On 8/11/18 12:24 AM, Heiler Bemerguy wrote:
> After some hours the worker 4 died unexpectely and didn't come back. I
> have cleaned the rock cache store before upgrading just to be safe..
> COLD start........
> 
> proxy??? 15478? 0.6? 1.8 9518972 1207212 ????? S??? Nov06?? 6:17
> (squid-5) --kid squid-5 -s
> proxy??? 15480? 0.4? 1.4 9391808 954248 ?????? S??? Nov06?? 3:56
> (squid-3) --kid squid-3 -s
> proxy??? 15481? 1.1? 2.5 9734420 1679360 ????? S??? Nov06? 10:45
> (squid-2) --kid squid-2 -s
> proxy??? 26933? 0.0? 0.0 6501296 26768 ??????? S??? 00:25?? 0:01
> (squid-coord-9) --kid squid-coord-9 -s
> proxy??? 26936? 0.0? 0.6 7424208 401788 ?????? S??? 00:25?? 0:07
> (squid-disk-6) --kid squid-disk-6 -s
> proxy??? 27011? 0.0? 0.2 7424208 185580 ?????? S??? 00:28?? 0:03
> (squid-disk-7) --kid squid-disk-7 -s
> proxy??? 27227? 0.0? 0.0 7424208 54980 ??????? S??? 00:37?? 0:01
> (squid-disk-8) --kid squid-disk-8 -s
> 
> AMD64 12-core, 64gb ram
> 
> cache_mem 5200 MB
> maximum_object_size_in_memory 2 MB
> maximum_object_size 4 GB
> workers 5
> cache_dir rock /cache2 131000 min-size=1 max-size=196608
> cache_dir rock /cache3 131000 min-size=196609 max-size=624288
> cache_dir rock /cache4 131000 min-size=624289 max-swap-rate=500
> swap-timeout=500
> 

The worker "kid4" died with an exception doing something with shared-memory.





> 2018/11/07 07:06:19 kid4| clientProcessHit: URL mismatch,
> '[unknown_URI]' !=
> 'http://ocsp.godaddy.com//MEQwQjBAMD4wPDAJBgUrDgMCGgUABBTkIInKBAzXkF0Qh0pel3lfHJ9GPAQU0sSw0pHUTBFxs2HLPaH%2B3ahq1OMCAxvnFQ%3D%3D'
> 

Your rock cache apparently contains at least several objects with the
exact string "[unknown URI]" as their URL / store-ID key. These are
attempting to be delivered to the client when it requested that OSCP URL.

Squid has detected the problem and will fetch a new object from the
network instead of the cache. It also begins the process of purging that
corrupt object from the cache.

... but then ...


> 2018/11/07 07:07:11 kid4| WARNING: communication with /cache2/rock may
> be too slow or disrupted for about 7.00s; rescued 1 out of 1 I/Os

Activity the worker is asking the Disker to do is taking a long time,
some actions have started to timeout. If they were fetching objects
those client transactions will be treated as MISS.
 I'm not sure what happens if those were deletions.


> 2018/11/07 07:07:11 kid4| clientProcessHit: URL mismatch,
> '[unknown_URI]' != 'http://www.orm.com.br/templates/noticiaDev.php'
> 2018/11/07 07:13:26 kid4| clientProcessHit: URL mismatch,
> '[unknown_URI]' !=
> 'http://storage.googleapis.com/update-delta/hfnkpimlhhgieaddgfemjhofmfblmnib/4803/4802/b767e40b59c48c2ec52977502ac10e35b84c00600197162f42dd941b5095cafd.crxd'
> 
> 2018/11/07 07:17:03 kid4| FATAL: Dying from an exception handling
> failure; exception: check failed: false
> ??? exception location: mem/PageStack.cc(106) push
> 

The SMP shared-memory space has been asked to allocate more memory than
it has total capacity.

...
> 2018/11/07 07:17:03 kid4| Starting Squid Cache version 4.4 for
> x86_64-pc-linux-gnu...
...
> 2018/11/07 07:17:03 kid4| WARNING: disk-cache maximum object size is too
> large for mem-cache: 4194304.00 KB > 2048.00 KB

The above might have something to do with the shared-memory problem.

It is part of rock design that the cache contents have to be able to be
stored in memory.

...
> 2018/11/07 07:17:09 kid4| storeDirWriteCleanLogs: Operation aborted.
> 2018/11/07 07:17:09 kid4| FATAL: kid4 registration timed out


The auto-recovery process keeps dying trying to re-start it because of
the very long time it takes to startup when the proxy is already under
traffic load and memory pressure. These type of delays are usually due
to Squid being configured with very large rock caches.




So, to solve this try reducing the cache size. rock was designed for
caches in the MB ranges with many small objects. So start small then
push it up until problems start to appear again.


Keep in mind that rock was designed and optimized for caches of several
hundred *MB* with millions of small 0-32KB sized objects. For large
objects the UFS caches are optimal.

Squid caching is intended for the two types to work together for best
performance at all object size ranges.

Amos


From rousskov at measurement-factory.com  Thu Nov  8 06:07:36 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 7 Nov 2018 23:07:36 -0700
Subject: [squid-users] 3.5.27 to 4.4: a worker is dead
In-Reply-To: <ec26a481-104f-5315-3dbe-ec4063beb12b@treenet.co.nz>
References: <810ddb3c-d5ff-a15d-b094-469ba3be61e1@cinbesa.com.br>
 <ec26a481-104f-5315-3dbe-ec4063beb12b@treenet.co.nz>
Message-ID: <49657bef-98fa-c109-4f8f-95fb767df71d@measurement-factory.com>

On 11/7/18 8:32 PM, Amos Jeffries wrote:

>> 2018/11/07 07:17:03 kid4| WARNING: disk-cache maximum object size is too
>> large for mem-cache: 4194304.00 KB > 2048.00 KB

> It is part of rock design that the cache contents have to be able to be
> stored in memory.

FTR, the above statement is incorrect: There is no such requirement in
rock design. Needless to say, on-disk objects larger than maximum
in-memory object size cannot be cached in memory, but that is true for
any Squid configurations, not just those using rock cache_dirs.


> rock was designed for caches in the MB ranges

The above statement is also incorrect: Rock was designed for GBs and
even TBs worth of cached content. There are still many things that can
be done in rock to support large caches better, of course, but
optimizing MBs-sized caches specifically was never a design objective.


> Keep in mind that rock was designed and optimized for caches of several
> hundred *MB* with millions of small 0-32KB sized objects.

Optimized? Probably -- most cached objects in most deployment
environments are indeed small.

Designed? No. One of the LargeRock project explicit goals was support
for cached objects that are several GBs in size:
https://wiki.squid-cache.org/Features/LargeRockStore


> Squid caching is intended for the two types to work together for best
> performance at all object size ranges.

Not really: Rock cache_dirs should not be used together with UFS-based
disk caches, especially in SMP environments where UFS-based disk caches
should not be used at all.


I realize that the above corrections may not help resolve the problem OP
is facing. I just did not want those misstatements to be archived
unaddressed.

Alex.


From info at schroeffu.ch  Thu Nov  8 08:32:36 2018
From: info at schroeffu.ch (info at schroeffu.ch)
Date: Thu, 08 Nov 2018 08:32:36 +0000
Subject: [squid-users] Ipv6 error
In-Reply-To: <7eb9a2e8-e278-2708-d90b-cc0ad98748aa@measurement-factory.com>
References: <7eb9a2e8-e278-2708-d90b-cc0ad98748aa@measurement-factory.com>
 <1507554880116-0.post@n4.nabble.com>
 <85e8f625-03bb-d9cf-743f-0de6782fad03@treenet.co.nz>
 <1507567619725-0.post@n4.nabble.com>
 <4064383f-0dbe-d81e-5bf5-d694ced2d736@treenet.co.nz>
 <1507641845081-0.post@n4.nabble.com> <1507641979145-0.post@n4.nabble.com>
 <81b68fb1-41c0-25cb-4d52-c82984e0f554@treenet.co.nz>
 <1541624048065-0.post@n4.nabble.com>
Message-ID: <0951c5311451fd394c724e1b2f9e085d@schroeffu.ch>

Hello and thanks for your explanation.
What kind of ACL would then match "all squid internal requests" to allow without authentification?

> For most modern Squids, this http_access policy is, IMO, incorrect
> because it blocks internally-generated requests, such as requests for
> missing intermediate certificates. Please adjust your configuration to
> allow those requests (if you want them to be allowed).

I found another Site missing the Intermediate in their cabundle, the same issue:

1541663927.195 0 - TCP_DENIED/407 3752 GET
http://cacerts.digicert.com/DigiCertSHA2HighAssuranceServerCA.crt - HIER_NONE/-
text/html;charset=utf-8
1541663927.195 52 172.16.5.15 NONE/200 0 CONNECT gtacknowledge.extremenetworks.com:443 xxxx
HIER_DIRECT/136.146.11.219 -
1541663927.210 0 172.16.5.15 NONE/503 5471 GET
https://gtacknowledge.extremenetworks.com/favicon.ico xxxx HIER_NONE/- text/html

Just comment out the following line does resolve the problem

acl Authenticated_Users proxy_auth REQUIRED
#http_access deny !Authenticated_Users all

but I still need the requirement that users have to auth themselv (but exclude squid-internal requests). So, what kind of ACL does catch squid internal requests to !whitelist_squid_internal_requests then? for example:

acl Authenticated_Users proxy_auth REQUIRED
acl whitelist_squid_internal_requests ????
http_access deny !Authenticated_Users !whitelist_squid_internal_requests all


From pacolopezvelasco at gmail.com  Thu Nov  8 15:46:24 2018
From: pacolopezvelasco at gmail.com (pacolo)
Date: Thu, 8 Nov 2018 09:46:24 -0600 (CST)
Subject: [squid-users] Performance issue /cache_dir / cache_mem
Message-ID: <1541691984135-0.post@n4.nabble.com>

Hello,

I am having performance issues with a deployment of a farm of 5 servers
(CentOS Linux release 7.5.1804) with Squid 3.5.20-12.el7, that are used for
the internet access of a scholar community.
This is around 7 Gbps at peak hour, including 60% of HTTPS not processed at
the moment by Squid (we will try to intercept HTTPS and processed it in the
near future).

I have noticed several error events in /var/log/audit/audit.log 
	type=ANOM_ABEND msg=audit(30/10/18 10:30:54.557:18355) : auid=unset
uid=squid gid=squid ses=unset pid=567 comm=squid reason="memory violation"
sig=SIGABRT 
	
That corresponded with another events in /var/log/squid/cache.log
	2018/10/30 10:26:15 kid1| assertion failed: filemap.cc:50: "capacity_ <= (1
<< 24)"
	2018/10/30 10:26:19 kid1| Set Current Directory to /cache
	2018/10/30 10:26:19 kid1| Starting Squid Cache version 3.5.20 for
x86_64-redhat-linux-gnu...
	2018/10/30 10:26:19 kid1| Service Name: squid
	2018/10/30 10:26:19 kid1| Process ID 567

	
There were thousands of squid's restarts per day, which appear to be the
main problem.
I have noticed that this problem could be related to the maximum value of
our cache_dir size, according to...
	https://bugs.squid-cache.org/show_bug.cgi?id=3566

I have been looking for relevant information regarding the cache_dir max
sizes, but all posts seem a little bit old, for example...

http://squid-web-proxy-cache.1019090.n4.nabble.com/size-of-cache-dir-td1033280.html

http://squid-web-proxy-cache.1019090.n4.nabble.com/cache-dir-size-td1033774.html


This is deployed in a virtual environment with an storage platform of
different rpm disks, resources aren't the problem, more could be added if it
is needed.
Each server has 4 CPU, 8 GB RAM, and LVM with an OS disk of 30 GB and a
Cache disk of 8 TB.
What we need is to deploy 8 TB per server, or as many as it is possible and
we could deploy another virtual server to reach to 40 TB total.

I have noticed that the first approach could be wrong, as we only referenced
one cache_dir with the 8000000 MB in the cache_dir...
cache_dir aufs /cache 800000 16 256

Then, the following error was returned ((squid-1): xcalloc: Unable to
allocate 18446744073566526858 blocks of 1 bytes!), until the noticed the
maximum value accepted...
These are the sentences related to the mem and disk options.

memory_replacement_policy heap GDSF
cache_mem 1024 MB
maximum_object_size_in_memory 10 MB

cache_replacement_policy heap LFUDA
cache_dir aufs /cache 5242880 16 256
maximum_object_size 1024 MB												
cache_swap_low 90
cache_swap_high 95

We noticed the errors commented as service's degradation was reported by the
customer.
By the way, with this configuration, only 2 TB aprox. was cached in each
server.

I suppose more RAM would be needed, as according to the rule "14 MB of
memory per 1 GB on disk for 64-bit Squid".
But I would need some clarifications with this, I suppose that 14 MB of
memory needed is referencing our total RAM, and 1 GB on disk is referencing
1 GB in the cache_dir (as our 8 TB are not detected, only 5TB).
So taking into account we need to deploy an 40 TB cache in total, for
example in 5 servers, with 8 TB per server, it will be needed at 112 GB of
RAM per server at least.
Am I right?

 
Please, could somebody point me in the right direction?
I have noticed about https://wiki.squid-cache.org/Features/SmpScale, but
before testing that I would like to know if there is any maximum value for
cache_dir.

Thanks!
Paco.




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From heiler.bemerguy at cinbesa.com.br  Thu Nov  8 15:49:48 2018
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Thu, 8 Nov 2018 12:49:48 -0300
Subject: [squid-users] 3.5.27 to 4.4: a worker is dead
In-Reply-To: <ec26a481-104f-5315-3dbe-ec4063beb12b@treenet.co.nz>
References: <810ddb3c-d5ff-a15d-b094-469ba3be61e1@cinbesa.com.br>
 <ec26a481-104f-5315-3dbe-ec4063beb12b@treenet.co.nz>
Message-ID: <979dc606-6623-7996-6e08-338576313789@cinbesa.com.br>


Em 08/11/2018 00:32, Amos Jeffries escreveu:

> Your rock cache apparently contains at least several objects with the
> exact string "[unknown URI]" as their URL / store-ID key. These are
> attempting to be delivered to the client when it requested that OSCP URL.
>
> Squid has detected the problem and will fetch a new object from the
> network instead of the cache. It also begins the process of purging that
> corrupt object from the cache.
This always ocurred, even with 3.5.27.. and I think it's related to 
cache_peers asking for objects. Am I the only one seeing it?
>
>> 2018/11/07 07:17:03 kid4| FATAL: Dying from an exception handling
>> failure; exception: check failed: false
>>  ??? exception location: mem/PageStack.cc(106) push
>>
> The SMP shared-memory space has been asked to allocate more memory than
> it has total capacity.

Why would it do that? 3.5.27 worked forever flawlessly with the same 
config. Should I decrease cache_mem?


-- 
Atenciosamente,

Heiler Bensimon Bemerguy - CINBESA
Analista de Redes, Wi-Fi,
Virtualiza??o e Servi?os Internet
(55) 91 98151-4894



From fredrik at pipemore.se  Thu Nov  8 15:52:38 2018
From: fredrik at pipemore.se (uppsalanet)
Date: Thu, 8 Nov 2018 09:52:38 -0600 (CST)
Subject: [squid-users] redirect based on url (302)
In-Reply-To: <c2ae6317-8fb0-4136-0761-83c7280a139b@treenet.co.nz>
References: <1537541034108-0.post@n4.nabble.com>
 <dde485b6-5742-d424-8e12-f700d0b975f2@treenet.co.nz>
 <1537771119646-0.post@n4.nabble.com>
 <f35964b6-e83b-c5b6-5563-602ab666d964@treenet.co.nz>
 <1540305071062-0.post@n4.nabble.com>
 <a2ca5119-39c1-c744-0e8b-6373f7f525a3@treenet.co.nz>
 <1540900144095-0.post@n4.nabble.com>
 <23b5e473-3671-b473-572d-19a25daaefe8@treenet.co.nz>
 <1540981640859-0.post@n4.nabble.com>
 <c2ae6317-8fb0-4136-0761-83c7280a139b@treenet.co.nz>
Message-ID: <1541692358446-0.post@n4.nabble.com>

Im stucked again :-(

It stoped working for some reason. I'm not able to trap 302 anymore. This is
my squid.conf (snippet):

##### Ext magazine domains
debug_options 11,10 58,10 82,10
acl 302 http_status 302
acl browzine dstdomain .browzine.com .thirdiron.com
http_access allow browzine

external_acl_type whitelist_add ttl=10 %SRC %<h{Location}
/etc/squid/add2db.pl

acl add_to_whitelist external whitelist_add
http_reply_access allow browzine 302 add_to_whitelist 
http_reply_access allow all
##### Ext magazine domains

This is what I get from curl on the same server:
curl -I
https://api.thirdiron.com/v2/libraries/223/articles/201309075/content
HTTP/1.1 302 Found
Server: Cowboy
Connection: keep-alive
X-Powered-By: Express
Access-Control-Allow-Origin: *
Access-Control-Allow-Headers: Content-Type, Authorization
Access-Control-Allow-Methods: DELETE,GET,PATCH,POST,PUT
Location: http://www.tandfonline.com/doi/full/10.1080/00020184.2018.1459287
Set-Cookie:
connect.sid=s%3AygAG53nVxrcphMYobmgFN4WIHWa2dgv0.29L5g8MvGC6Awk3pE5JZ4xKYcSqyI3L7vAiUXbAUmHM;
Path=/; HttpOnly
Date: Thu, 08 Nov 2018 15:39:10 GMT
Via: 1.1 vegur

I probably doing something wrong :-)
Regards
Fredrik





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Thu Nov  8 16:23:05 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 8 Nov 2018 09:23:05 -0700
Subject: [squid-users] Ipv6 error
In-Reply-To: <0951c5311451fd394c724e1b2f9e085d@schroeffu.ch>
References: <7eb9a2e8-e278-2708-d90b-cc0ad98748aa@measurement-factory.com>
 <1507554880116-0.post@n4.nabble.com>
 <85e8f625-03bb-d9cf-743f-0de6782fad03@treenet.co.nz>
 <1507567619725-0.post@n4.nabble.com>
 <4064383f-0dbe-d81e-5bf5-d694ced2d736@treenet.co.nz>
 <1507641845081-0.post@n4.nabble.com> <1507641979145-0.post@n4.nabble.com>
 <81b68fb1-41c0-25cb-4d52-c82984e0f554@treenet.co.nz>
 <1541624048065-0.post@n4.nabble.com>
 <0951c5311451fd394c724e1b2f9e085d@schroeffu.ch>
Message-ID: <5172c83e-3378-ee2e-0367-f7857afcfee9@measurement-factory.com>

On 11/8/18 1:32 AM, info at schroeffu.ch wrote:

> What kind of ACL would then match "all squid internal requests" to allow without authentification?

transaction_initiator internal

Alex.


From rousskov at measurement-factory.com  Thu Nov  8 16:42:40 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 8 Nov 2018 09:42:40 -0700
Subject: [squid-users] 3.5.27 to 4.4: a worker is dead
In-Reply-To: <979dc606-6623-7996-6e08-338576313789@cinbesa.com.br>
References: <810ddb3c-d5ff-a15d-b094-469ba3be61e1@cinbesa.com.br>
 <ec26a481-104f-5315-3dbe-ec4063beb12b@treenet.co.nz>
 <979dc606-6623-7996-6e08-338576313789@cinbesa.com.br>
Message-ID: <e7275e18-8cba-567e-ff29-275ded92a119@measurement-factory.com>

On 11/8/18 8:49 AM, Heiler Bemerguy wrote:
>>> 2018/11/07 07:17:03 kid4| FATAL: Dying from an exception handling
>>> failure; exception: check failed: false
>>> ???? exception location: mem/PageStack.cc(106) push

>> The SMP shared-memory space has been asked to allocate more memory than
>> it has total capacity.

> Why would it do that?

I am not sure that explanation is accurate. The exception is thrown when
Squid's shared memory manager is given a (previously used/allocated)
shared memory page to add/return to the index of free (i.e. available
for future use) memory pages. When trying to add that free page, Squid
found that the entire index of free shared memory pages is full -- all
previously allocated shared memory pages for the given scope/segment
were already freed/indexed, and there could not have been one more free
page.

It is not clear whether Squid is wrong about the index being full or the
calling code is giving a free page that was already index (i.e. an
equivalent of a double-free bug). There could also be some (currently
unknown) and mishandled race condition when navigating the shared memory
index.

My bet is on a bug in Squid code that attempts to recover from disker
errors (you have reported some disker-related errors/timeouts that
preceded this exception IIRC). If I am right, then this exception is a
symptom of a Squid bug located elsewhere.

Alex.


From rousskov at measurement-factory.com  Thu Nov  8 17:42:31 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 8 Nov 2018 10:42:31 -0700
Subject: [squid-users] Performance issue /cache_dir / cache_mem
In-Reply-To: <1541691984135-0.post@n4.nabble.com>
References: <1541691984135-0.post@n4.nabble.com>
Message-ID: <b2449f05-cb00-d598-f752-dcabddb11c82@measurement-factory.com>

On 11/8/18 8:46 AM, pacolo wrote:

> assertion failed: filemap.cc:50: "capacity_ <= (1 << 24)"

> I have noticed that this problem could be related to the maximum value of
> our cache_dir size, according to...
> 	https://bugs.squid-cache.org/show_bug.cgi?id=3566

As that bug discussion attempts to clarify, it is not the cache_dir size
as such, but the number of objects in that cache_dir. The latter is
limited by 16777216 objects (a hard-coded limit).


> What we need is to deploy 8 TB per server,

Divide 8 TB by your average disk-cached object size, then divide by
16777216 to find out the minimum number of cache_dirs per server.

For example, with 13KB average disk-cached object size, caching 8 TB on
disk requires 40 cache_dirs (8 * 1024 * 1024 * 1024 / 13 / 16777216).

See also: store_avg_object_size


> cache_dir aufs /cache 5242880 16 256

With default store_avg_object_size of 13KB, the above yields 412977624
objects, which is x24 more than the 16777216 limit.

I do not remember if Squid has a hard-coded maximum for the number of
cache_dirs. However, even if Squid does not, please note that several
algorithms iterate through all cache_dirs. Each iteration is relatively
fast (e.g., a complex hash lookup), but having lots of cache_dirs may
slow your Squid down because of these linear searches.

Alex.
P.S. If you move to SMP Squid, please note that you should not continue
to use aufs cache_dirs.


From squid3 at treenet.co.nz  Thu Nov  8 23:42:05 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 9 Nov 2018 12:42:05 +1300
Subject: [squid-users] Ipv6 error
In-Reply-To: <0951c5311451fd394c724e1b2f9e085d@schroeffu.ch>
References: <7eb9a2e8-e278-2708-d90b-cc0ad98748aa@measurement-factory.com>
 <1507554880116-0.post@n4.nabble.com>
 <85e8f625-03bb-d9cf-743f-0de6782fad03@treenet.co.nz>
 <1507567619725-0.post@n4.nabble.com>
 <4064383f-0dbe-d81e-5bf5-d694ced2d736@treenet.co.nz>
 <1507641845081-0.post@n4.nabble.com> <1507641979145-0.post@n4.nabble.com>
 <81b68fb1-41c0-25cb-4d52-c82984e0f554@treenet.co.nz>
 <1541624048065-0.post@n4.nabble.com>
 <0951c5311451fd394c724e1b2f9e085d@schroeffu.ch>
Message-ID: <1d827fb7-1b81-0935-9b09-7d7fefca6f48@treenet.co.nz>

On 8/11/18 9:32 PM, info at schroeffu.ch wrote:
> Hello and thanks for your explanation.
> What kind of ACL would then match "all squid internal requests" to allow without authentification?
> 
>> For most modern Squids, this http_access policy is, IMO, incorrect
>> because it blocks internally-generated requests, such as requests for
>> missing intermediate certificates. Please adjust your configuration to
>> allow those requests (if you want them to be allowed).
> 
> I found another Site missing the Intermediate in their cabundle, the same issue:
> 
> 1541663927.195 0 - TCP_DENIED/407 3752 GET
> http://cacerts.digicert.com/DigiCertSHA2HighAssuranceServerCA.crt - HIER_NONE/-
> text/html;charset=utf-8
> 1541663927.195 52 172.16.5.15 NONE/200 0 CONNECT gtacknowledge.extremenetworks.com:443 xxxx
> HIER_DIRECT/136.146.11.219 -
> 1541663927.210 0 172.16.5.15 NONE/503 5471 GET
> https://gtacknowledge.extremenetworks.com/favicon.ico xxxx HIER_NONE/- text/html
> 
> Just comment out the following line does resolve the problem
> 
> acl Authenticated_Users proxy_auth REQUIRED
> #http_access deny !Authenticated_Users all
> 
> but I still need the requirement that users have to auth themselv 

FYI: By placing that "all" ACL (or any other non-authentication ACL) at
the end of your access line you are currently making Squid *not* fetch
credentials from users.

If the UA/Browser is so insecurely configured that it broadcasts user
credentials out to the network without being asked for them your above
config would _appear_ to work, but that insecurity is a different
problem on its own.

Amos


From info at schroeffu.ch  Fri Nov  9 08:37:06 2018
From: info at schroeffu.ch (info at schroeffu.ch)
Date: Fri, 09 Nov 2018 08:37:06 +0000
Subject: [squid-users] Ipv6 error
In-Reply-To: <1d827fb7-1b81-0935-9b09-7d7fefca6f48@treenet.co.nz>
References: <1d827fb7-1b81-0935-9b09-7d7fefca6f48@treenet.co.nz>
 <7eb9a2e8-e278-2708-d90b-cc0ad98748aa@measurement-factory.com>
 <1507554880116-0.post@n4.nabble.com>
 <85e8f625-03bb-d9cf-743f-0de6782fad03@treenet.co.nz>
 <1507567619725-0.post@n4.nabble.com>
 <4064383f-0dbe-d81e-5bf5-d694ced2d736@treenet.co.nz>
 <1507641845081-0.post@n4.nabble.com> <1507641979145-0.post@n4.nabble.com>
 <81b68fb1-41c0-25cb-4d52-c82984e0f554@treenet.co.nz>
 <1541624048065-0.post@n4.nabble.com>
 <0951c5311451fd394c724e1b2f9e085d@schroeffu.ch>
Message-ID: <354794ecfa5657de52982d2797974fdf@schroeffu.ch>

> FYI: By placing that "all" ACL (or any other non-authentication ACL) at
> the end of your access line you are currently making Squid *not* fetch
> credentials from users.
> 
> If the UA/Browser is so insecurely configured that it broadcasts user
> credentials out to the network without being asked for them your above
> config would _appear_ to work, but that insecurity is a different
> problem on its own.
> 
> Amos

Oh ok I see, thanks, will change that of course

> transaction_initiator internal
> 
> Alex.

Perfect, thats the acl i was looking for, I didn't know that it exists.
So I changed my configuration and finally it fetchs now the intermediate certifications before an authentication is requried:

#Allow fetch intermediate certs before required authentication
acl fetched_certificate transaction_initiator certificate-fetching
cache allow fetched_certificate
cache deny all
http_access allow fetched_certificate

#Authentification is REQUIRED
acl Authenticated_Users proxy_auth REQUIRED
http_access deny !Authenticated_Users

It also does cache them, as described here:
http://lists.squid-cache.org/pipermail/squid-dev/2017-June/008800.html

Example Log:

1541752564.411      0 172.16.5.15 TCP_DENIED/407 4638 CONNECT bugs.squid-cache.org:443 - HIER_NONE/- text/html
1541752564.702      2 - TCP_MEM_HIT/200 1174 GET http://cert.int-x3.letsencrypt.org/ - HIER_NONE/- application/pkix-cert
1541752564.834    421 172.16.5.15 NONE/200 0 CONNECT bugs.squid-cache.org:443 xxxx HIER_DIRECT/104.130.201.120 -
1541752567.031   2180 172.16.5.15 TCP_MISS/200 3875 GET https://bugs.squid-cache.org/index.cgi xxxx HIER_DIRECT/104.130.201.120 text/html


From m.hoffmann.bs at gmail.com  Fri Nov  9 18:04:14 2018
From: m.hoffmann.bs at gmail.com (Martin Hoffmann)
Date: Fri, 9 Nov 2018 19:04:14 +0100
Subject: [squid-users] Squid4 with GnuTLS - specify ciphers or disable
	protocols
Message-ID: <CADpL81ZjE=y8+dyv6AQ48srbHmBuqRT4AMCBx-xCZqXYjqWnfA@mail.gmail.com>

I'm using squid 4.4 as remote proxy for an https server.
Squid 4.4 comes from Debian testing and is compiled with --with-gnutls (no
openssl support).

How can I disable certain cipher suites or protocols (like TLS 1.0) ?

>From my understanding I should add tls-min-version=1.1 to https_port - but
that is ignored...?
Where can I add GnuTLS priority strings to disable certain ciphers ?

I guess Documentation about https_port is somewhat misleading as it often
refers to the openssl config.

Thanks in advanced for any help.

Regards, Martin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181109/8df8e2e6/attachment.htm>

From michael.pelletier at palmbeachschools.org  Fri Nov  9 20:05:24 2018
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Fri, 9 Nov 2018 15:05:24 -0500
Subject: [squid-users] X-Forwarded-For
Message-ID: <CAEnCSG7rK7hSpPZrXdn3MWnoXBpbWG62=QZ25nFptkE9Rp+r7g@mail.gmail.com>

Hello,
I am running squid 3.5.28 and for some reason I can not get X-Forwarded-For
added to the http headers. I have "forwarded_for on" and "via on" set in
the squid.conf. Any ideas why this will not work?

-- 






*Disclaimer:?*Under Florida law, e-mail addresses are public records. 
If you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.







-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181109/44f8c8e5/attachment.htm>

From squid3 at treenet.co.nz  Sat Nov 10 00:34:59 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 10 Nov 2018 13:34:59 +1300
Subject: [squid-users] X-Forwarded-For
In-Reply-To: <CAEnCSG7rK7hSpPZrXdn3MWnoXBpbWG62=QZ25nFptkE9Rp+r7g@mail.gmail.com>
References: <CAEnCSG7rK7hSpPZrXdn3MWnoXBpbWG62=QZ25nFptkE9Rp+r7g@mail.gmail.com>
Message-ID: <5eb69a69-36fe-f4ca-50ee-4a9c2923d4f0@treenet.co.nz>

On 10/11/18 9:05 AM, Michael Pelletier wrote:
> Hello,
> I am running squid 3.5.28 and for some reason I can not get
> X-Forwarded-For added to the http headers. I have "forwarded_for on" and
> "via on" set in the squid.conf. Any ideas why this will not work?
> 

Perhapse your Squid has been patched to remove it ?

Perhapse you are looking at the wrong headers ?
 X-Forwarded-For is only added to the request headers sent to servers.

Perhapse you have a later config line setting forwarded_for to "delete"
or "transparent" ?

Amos


From michael.pelletier at palmbeachschools.org  Sat Nov 10 02:15:35 2018
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Fri, 9 Nov 2018 21:15:35 -0500
Subject: [squid-users] X-Forwarded-For
In-Reply-To: <5eb69a69-36fe-f4ca-50ee-4a9c2923d4f0@treenet.co.nz>
References: <CAEnCSG7rK7hSpPZrXdn3MWnoXBpbWG62=QZ25nFptkE9Rp+r7g@mail.gmail.com>
 <5eb69a69-36fe-f4ca-50ee-4a9c2923d4f0@treenet.co.nz>
Message-ID: <CAEnCSG4X-=96nxEhRXThYXALQ=+Fi=8Bgb5Zhn1xfMMwLBTW1w@mail.gmail.com>

Perhapse your Squid has been patched to remove it ?

I am running 3.5.28. I have not installed any patches.

Perhapse you are looking at the wrong headers ?
 X-Forwarded-For is only added to the request headers sent to servers.

Yes. The XFF should be added to the request header and be seen by the
server the proxy is communicating with. I have a sniffer on the outside
(Internet side) of the proxy and have confirmed the XFF is not being added.

Perhapse you have a later config line setting forwarded_for to "delete"
or "transparent" ?

I have the line "forwarded_for on"

On Fri, Nov 9, 2018 at 7:35 PM Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 10/11/18 9:05 AM, Michael Pelletier wrote:
> > Hello,
> > I am running squid 3.5.28 and for some reason I can not get
> > X-Forwarded-For added to the http headers. I have "forwarded_for on" and
> > "via on" set in the squid.conf. Any ideas why this will not work?
> >
>
> Perhapse your Squid has been patched to remove it ?
>
> Perhapse you are looking at the wrong headers ?
>  X-Forwarded-For is only added to the request headers sent to servers.
>
> Perhapse you have a later config line setting forwarded_for to "delete"
> or "transparent" ?
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

-- 






*Disclaimer:?*Under Florida law, e-mail addresses are public records. 
If you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.







-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181109/afb3b25e/attachment.htm>

From squid3 at treenet.co.nz  Sat Nov 10 02:53:57 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 10 Nov 2018 15:53:57 +1300
Subject: [squid-users] X-Forwarded-For
In-Reply-To: <CAEnCSG4X-=96nxEhRXThYXALQ=+Fi=8Bgb5Zhn1xfMMwLBTW1w@mail.gmail.com>
References: <CAEnCSG7rK7hSpPZrXdn3MWnoXBpbWG62=QZ25nFptkE9Rp+r7g@mail.gmail.com>
 <5eb69a69-36fe-f4ca-50ee-4a9c2923d4f0@treenet.co.nz>
 <CAEnCSG4X-=96nxEhRXThYXALQ=+Fi=8Bgb5Zhn1xfMMwLBTW1w@mail.gmail.com>
Message-ID: <8b909e0e-4c75-9b9c-4cc5-13bd2e615f76@treenet.co.nz>

On 10/11/18 3:15 PM, Michael Pelletier wrote:
> Perhapse your Squid has been patched to remove it ?
> 
> I am running 3.5.28. I have not installed any patches.
> 
> Perhapse you are looking at the wrong headers ?
> ?X-Forwarded-For is only added to the request headers sent to servers.
> 
> Yes. The XFF should be added to the request header and be seen by the
> server the proxy is communicating with. I have a sniffer on the outside
> (Internet side) of the proxy and have confirmed the XFF is not being added.
> 
> Perhapse you have a later config line setting forwarded_for to "delete"
> or "transparent" ?
> 
> I have the line "forwarded_for on"

I mean something later in the config. This directive can be set multiple
times and only uses the last value it is set to.


Another possibility is request_header_access rules removing it along
with other headers. IIRC, this header is included in one of the "Other"
or "All" categories.


Amos


From squid3 at treenet.co.nz  Sat Nov 10 03:35:03 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 10 Nov 2018 16:35:03 +1300
Subject: [squid-users] Squid4 with GnuTLS - specify ciphers or disable
 protocols
In-Reply-To: <CADpL81ZjE=y8+dyv6AQ48srbHmBuqRT4AMCBx-xCZqXYjqWnfA@mail.gmail.com>
References: <CADpL81ZjE=y8+dyv6AQ48srbHmBuqRT4AMCBx-xCZqXYjqWnfA@mail.gmail.com>
Message-ID: <82abcfdd-2d9e-f8e8-52d2-cf089c533630@treenet.co.nz>

On 10/11/18 7:04 AM, Martin Hoffmann wrote:
> I'm using squid 4.4 as remote proxy for an https server.
> Squid 4.4 comes from Debian testing and is compiled with --with-gnutls
> (no openssl support).
> 
> How can I disable certain cipher suites or protocols (like TLS 1.0) ?
> 
> From my understanding I should add tls-min-version=1.1 to https_port -
> but that is ignored...?

Hmm, I think I've found a bug in there which would cause that.


> Where can I add GnuTLS priority strings to disable certain ciphers ?
> 

Use "tls-options=". It is not yet documented since it has not had much
testing. For GnuTLS it should take a ':' separated list of priority strings.

FWIW: To work around the above tls-min-version bug, you should add the
priority string ":-VERS-TLS1.0" to that list of your custom ones. That
is what the min-version options should have been doing but clearly is not.


> I guess Documentation about https_port is somewhat misleading as it
> often refers to the openssl config.

Most documentation is still about OpenSSL because that is the older
feature set.

Settings that are named with "tls" prefixes have been given GnuTLS
support and should work for either library unless explicitly stated as
requiring one in particular.


HTH
Amos


From michael.pelletier at palmbeachschools.org  Sat Nov 10 17:27:54 2018
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Sat, 10 Nov 2018 12:27:54 -0500
Subject: [squid-users] X-Forwarded-For
In-Reply-To: <8b909e0e-4c75-9b9c-4cc5-13bd2e615f76@treenet.co.nz>
References: <CAEnCSG7rK7hSpPZrXdn3MWnoXBpbWG62=QZ25nFptkE9Rp+r7g@mail.gmail.com>
 <5eb69a69-36fe-f4ca-50ee-4a9c2923d4f0@treenet.co.nz>
 <CAEnCSG4X-=96nxEhRXThYXALQ=+Fi=8Bgb5Zhn1xfMMwLBTW1w@mail.gmail.com>
 <8b909e0e-4c75-9b9c-4cc5-13bd2e615f76@treenet.co.nz>
Message-ID: <CAEnCSG55LYR9Sj_hqrSBXO3-vj2HXuZ4gMfH0NWYPYJiALT=Rw@mail.gmail.com>

Interesting. I will check later. Thanks!

On Fri, Nov 9, 2018 at 9:54 PM Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 10/11/18 3:15 PM, Michael Pelletier wrote:
> > Perhapse your Squid has been patched to remove it ?
> >
> > I am running 3.5.28. I have not installed any patches.
> >
> > Perhapse you are looking at the wrong headers ?
> >  X-Forwarded-For is only added to the request headers sent to servers.
> >
> > Yes. The XFF should be added to the request header and be seen by the
> > server the proxy is communicating with. I have a sniffer on the outside
> > (Internet side) of the proxy and have confirmed the XFF is not being
> added.
> >
> > Perhapse you have a later config line setting forwarded_for to "delete"
> > or "transparent" ?
> >
> > I have the line "forwarded_for on"
>
> I mean something later in the config. This directive can be set multiple
> times and only uses the last value it is set to.
>
>
> Another possibility is request_header_access rules removing it along
> with other headers. IIRC, this header is included in one of the "Other"
> or "All" categories.
>
>
> Amos
>

-- 






*Disclaimer:?*Under Florida law, e-mail addresses are public records. 
If you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.







-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181110/4c1fc197/attachment.htm>

From sm+squid at samip.fi  Sat Nov 10 23:44:34 2018
From: sm+squid at samip.fi (=?UTF-8?Q?Sami_M=c3=a4ntysaari?=)
Date: Sun, 11 Nov 2018 01:44:34 +0200
Subject: [squid-users] Problems with building squid 4.4 on Ubuntu 16.04
Message-ID: <0d74b01e-39ae-53ea-a1fb-ab97c3b38c7d@samip.fi>

Dear list subscribers,

I'm unable to get a working version built, so I can use ssl-bump.

Configuration flags/args:

./configure --build=x86_64-linux-gnu \
--prefix=/usr \
--includedir=${prefix}/include \
--mandir=${prefix}/share/man \
--infodir=${prefix}/share/info \
--sysconfdir=/etc \
--localstatedir=/var \
--libexecdir=${prefix}/lib/squid4 \
--srcdir=. \
--disable-maintainer-mode \
--disable-dependency-tracking \
--disable-silent-rules \
--datadir=/usr/share/squid4 \
--sysconfdir=/etc/squid4 \
--mandir=/usr/share/man \
--enable-inline \
--enable-ssl-crtd \
--disable-arch-native \
--enable-async-io=8 \
--enable-storeio=ufs,aufs,diskd,rock \
--enable-removal-policies=lru,heap \
--enable-delay-pools \
--enable-cache-digests \
--enable-icap-client \
--enable-follow-x-forwarded-for \
--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB 
\
--enable-auth-digest=file,LDAP \
--enable-auth-negotiate=kerberos,wrapper \
--enable-auth-ntlm=fake,smb_lm \
--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,unix_group,wbinfo_group 
\
--enable-url-rewrite-helpers=fake \
--enable-eui \
--enable-esi \
--enable-icmp \
--enable-zph-qos \
--enable-ecap \
--disable-translation \
--with-swapdir=/var/spool/squid4 \
--with-logdir=/var/log/squid4 \
--with-pidfile=/var/run/squid4.pid \
--with-filedescriptors=65536 \
--with-large-files \
--with-default-user=proxy \
--enable-ssl \
--with-openssl=/usr/local/ssl \
--enable-linux-netfilter \
'CFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat 
-Werror=format-security -Wall' \
'LDFLAGS=-fPIE -pie -Wl,-z,relro -Wl,-z,now' \
'CPPFLAGS=-D_FORTIFY_SOURCE=2' \
'CXXFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat 
-Werror=format-security'

Build log:
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... no
checking for mawk... mawk
checking whether make sets $(MAKE)... yes
checking whether make supports nested variables... yes
checking whether UID '0' is supported by ustar format... yes
checking whether GID '0' is supported by ustar format... yes
checking how to create a ustar tar archive... gnutar
checking whether to enable maintainer-specific portions of Makefiles... no
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking whether gcc understands -c and -o together... yes
checking whether make supports the include directive... yes (GNU style)
checking dependency style of gcc... none
checking for g++... g++
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking dependency style of g++... none
checking build system type... x86_64-pc-linux-gnu
checking host system type... x86_64-pc-linux-gnu
configure: CPU arch native optimization enabled: no
checking simplified host os... linux (version )
checking whether g++ supports C++11 features by default... no
checking whether g++ supports C++11 features with -std=c++11... yes
checking for ranlib... ranlib
checking how to run the C preprocessor... gcc -E
checking whether ln -s works... yes
checking for egrep... /bin/egrep
checking for sh... /bin/sh
checking for false... /bin/false
checking for true... /bin/true
checking for mv... /bin/mv
checking for mkdir... /bin/mkdir
checking for ln... /bin/ln
checking for chmod... /bin/chmod
checking for tr... /usr/bin/tr
checking for rm... /bin/rm
checking for pkg-config... /usr/bin/pkg-config
checking pkg-config is at least version 0.9.0... yes
checking for perl... /usr/bin/perl
checking for pod2man... /usr/bin/pod2man
checking for ar... /usr/bin/ar
checking for linuxdoc... /bin/false
configure: strict error checking enabled: yes
checking whether to use loadable modules... yes
checking how to print strings... printf
checking for a sed that does not truncate output... /bin/sed
checking for fgrep... /bin/fgrep
checking for ld used by gcc... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
checking the name lister (/usr/bin/nm -B) interface... BSD nm
checking the maximum length of command line arguments... 1572864
checking how to convert x86_64-pc-linux-gnu file names to 
x86_64-pc-linux-gnu format... func_convert_file_noop
checking how to convert x86_64-pc-linux-gnu file names to toolchain 
format... func_convert_file_noop
checking for /usr/bin/ld option to reload object files... -r
checking for objdump... objdump
checking how to recognize dependent libraries... pass_all
checking for dlltool... no
checking how to associate runtime and link libraries... printf %s\n
checking for archiver @FILE support... @
checking for strip... strip
checking for ranlib... (cached) ranlib
checking command to parse /usr/bin/nm -B output from gcc object... ok
checking for sysroot... no
checking for a working dd... /bin/dd
checking how to truncate binary pipes... /bin/dd bs=4096 count=1
checking for mt... mt
checking if mt is a manifest tool... no
checking for dlfcn.h... yes
checking for objdir... .libs
checking if gcc supports -fno-rtti -fno-exceptions... no
checking for gcc option to produce PIC... -fPIC -DPIC
checking if gcc PIC flag -fPIC -DPIC works... yes
checking if gcc static flag -static works... no
checking if gcc supports -c -o file.o... yes
checking if gcc supports -c -o file.o... (cached) yes
checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports 
shared libraries... yes
checking whether -lc should be explicitly linked in... no
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking for shl_load... no
checking for shl_load in -ldld... no
checking for dlopen... no
checking for dlopen in -ldl... yes
checking whether a program can dlopen itself... yes
checking whether a statically linked program can dlopen itself... yes
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... yes
checking how to run the C++ preprocessor... g++ -E
checking for ld used by g++... /usr/bin/ld -m elf_x86_64
checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports 
shared libraries... yes
checking for g++ option to produce PIC... -fPIC -DPIC
checking if g++ PIC flag -fPIC -DPIC works... yes
checking if g++ static flag -static works... no
checking if g++ supports -c -o file.o... yes
checking if g++ supports -c -o file.o... (cached) yes
checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports 
shared libraries... yes
checking dynamic linker characteristics... (cached) GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking what extension is used for runtime loadable modules... .so
checking what variable specifies run-time module search path... 
LD_LIBRARY_PATH
checking for the default library search path... /lib /usr/lib 
/usr/lib/x86_64-linux-gnu/libfakeroot /usr/local/lib 
/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu 
/usr/lib/x86_64-linux-gnu/mesa-egl /usr/lib/x86_64-linux-gnu/mesa
checking for library containing dlopen... -ldl
checking for dlerror... yes
checking for shl_load... (cached) no
checking for shl_load in -ldld... (cached) no
checking for dld_link in -ldld... no
checking for _ prefix in compiled symbols... no
checking whether deplibs are loaded by dlopen... yes
checking for argz.h... yes
checking for error_t... yes
checking for argz_add... yes
checking for argz_append... yes
checking for argz_count... yes
checking for argz_create_sep... yes
checking for argz_insert... yes
checking for argz_next... yes
checking for argz_stringify... yes
checking if argz actually works... yes
checking whether libtool supports -dlopen/-dlpreopen... yes
checking for ltdl.h... yes
checking whether lt_dlinterface_register is declared... yes
checking for lt_dladvise_preload in -lltdl... yes
checking where to find libltdl headers...
checking where to find libltdl library... -lltdl
checking for unistd.h... yes
checking for dl.h... no
checking for sys/dl.h... no
checking for dld.h... no
checking for mach-o/dyld.h... no
checking for dirent.h... yes
checking for closedir... yes
checking for opendir... yes
checking for readdir... yes
checking for strlcat... no
checking for strlcpy... no
checking for library containing dlopen... (cached) -ldl
checking for dlerror... (cached) yes
checking for shl_load... (cached) no
checking for shl_load in -ldld... (cached) no
checking for dld_link in -ldld... (cached) no
checking what kind of compiler we're using... gcc
checking for compiler variant... gcc
checking whether compiler requires -Werror -Wno-deprecated-register... yes
configure: inlining optimizations enabled: yes
configure: cbdata debugging enabled: no
configure: xmalloc stats display: no
checking for library containing __atomic_load_8... -latomic
checking for library containing shm_open... -lrt
checking for DiskIO modules to be enabled...? AIO Blocking DiskDaemon 
DiskThreads IpcIo Mmapped
checking aio.h usability... yes
checking aio.h presence... yes
checking for aio.h... yes
checking for aio_read in -lrt... yes
configure: Native POSIX AIO support detected.
configure: Enabling AIO DiskIO module
configure: Enabling Blocking DiskIO module
configure: Enabling DiskDaemon DiskIO module
checking for pthread_create? in -lpthread... yes
configure: Enabling DiskThreads DiskIO module
configure: Enabling IpcIo DiskIO module
configure: Enabling Mmapped DiskIO module
configure: IO Modules built:? AIO Blocking DiskDaemon DiskThreads IpcIo 
Mmapped
configure: Store modules built:? ufs aufs diskd rock
configure: Removal policies to build: lru heap
configure: ICMP enabled
configure: Delay pools enabled
checking for main in -lexpat... yes
checking expat.h usability... yes
checking expat.h presence... yes
checking for expat.h... yes
checking for main in -lxml2... yes
checking location of libxml2 include files... checking libxml/parser.h 
usability... no
checking libxml/parser.h presence... no
checking for libxml/parser.h... no
configure: Testing in /usr/include/libxml2
checking libxml/parser.h usability... yes
checking libxml/parser.h presence... yes
checking for libxml/parser.h... yes
-I/usr/include/libxml2
checking for libxml/parser.h... (cached) yes
checking libxml/HTMLparser.h usability... yes
checking libxml/HTMLparser.h presence... yes
checking for libxml/HTMLparser.h... yes
checking libxml/HTMLtree.h usability... yes
checking libxml/HTMLtree.h presence... yes
checking for libxml/HTMLtree.h... yes
configure: Enabling ESI processor: -lexpat -lxml2
checking whether to support eCAP... yes, explicitly
checking for EXT_LIBECAP... yes
checking whether -lecap will link... yes
configure: Web Cache Coordination Protocol enabled: yes
configure: Web Cache Coordination V2 Protocol enabled: yes
configure: Kill parent on shutdown hack enabled: no
configure: SNMP support enabled: yes
checking for windows.h... no
checking for sys/sockio.h... no
checking for sys/param.h... yes
checking for net/if_arp.h... yes
checking for net/route.h... yes
checking for net/if_dl.h... no
checking for sys/sysctl.h... yes
configure: EUI (MAC address) controls enabled: yes
configure: HTCP support enabled: yes
checking for nettle_md5_init in -lnettle... yes
checking nettle/md5.h usability... yes
checking nettle/md5.h presence... yes
checking for nettle/md5.h... yes
checking nettle/base64.h usability... yes
checking nettle/base64.h presence... yes
checking for nettle/base64.h... yes
checking for Nettle 3.4 API compatibility... no
configure: Using Nettle cryptographic library: yes
checking for crypt in -lcrypt... yes
checking for MD5Init in -lmd5... no
checking for LIBGNUTLS... yes
checking gnutls/gnutls.h usability... yes
checking gnutls/gnutls.h presence... yes
checking for gnutls/gnutls.h... yes
checking gnutls/x509.h usability... yes
checking gnutls/x509.h presence... yes
checking for gnutls/x509.h... yes
checking gnutls/abstract.h usability... yes
checking gnutls/abstract.h presence... yes
checking for gnutls/abstract.h... yes
configure: GnuTLS library support: auto? -lgnutls
checking openssl/asn1.h usability... yes
checking openssl/asn1.h presence... yes
checking for openssl/asn1.h... yes
checking openssl/bio.h usability... yes
checking openssl/bio.h presence... yes
checking for openssl/bio.h... yes
checking openssl/bn.h usability... yes
checking openssl/bn.h presence... yes
checking for openssl/bn.h... yes
checking openssl/crypto.h usability... yes
checking openssl/crypto.h presence... yes
checking for openssl/crypto.h... yes
checking openssl/dh.h usability... yes
checking openssl/dh.h presence... yes
checking for openssl/dh.h... yes
checking openssl/err.h usability... yes
checking openssl/err.h presence... yes
checking for openssl/err.h... yes
checking openssl/evp.h usability... yes
checking openssl/evp.h presence... yes
checking for openssl/evp.h... yes
checking openssl/lhash.h usability... yes
checking openssl/lhash.h presence... yes
checking for openssl/lhash.h... yes
checking openssl/md5.h usability... yes
checking openssl/md5.h presence... yes
checking for openssl/md5.h... yes
checking openssl/opensslv.h usability... yes
checking openssl/opensslv.h presence... yes
checking for openssl/opensslv.h... yes
checking openssl/rsa.h usability... yes
checking openssl/rsa.h presence... yes
checking for openssl/rsa.h... yes
checking openssl/ssl.h usability... yes
checking openssl/ssl.h presence... yes
checking for openssl/ssl.h... yes
checking openssl/x509.h usability... yes
checking openssl/x509.h presence... yes
checking for openssl/x509.h... yes
checking openssl/x509v3.h usability... yes
checking openssl/x509v3.h presence... yes
checking for openssl/x509v3.h... yes
checking openssl/engine.h usability... yes
checking openssl/engine.h presence... yes
checking for openssl/engine.h... yes
checking openssl/txt_db.h usability... yes
checking openssl/txt_db.h presence... yes
checking for openssl/txt_db.h... yes
checking for LIBOPENSSL... yes
checking for OPENSSL_LH_strhash in -lcrypto... yes
checking for EVP_PKEY_get0_RSA in -lcrypto... yes
checking for BIO_meth_new in -lcrypto... yes
checking for BIO_get_data in -lcrypto... yes
checking for BIO_get_init in -lcrypto... yes
checking for ASN1_STRING_get0_data in -lcrypto... yes
checking for EVP_PKEY_up_ref in -lcrypto... yes
checking for X509_STORE_CTX_get0_cert in -lcrypto... yes
checking for X509_VERIFY_PARAM_get_depth in -lcrypto... yes
checking for X509_STORE_CTX_get0_untrusted in -lcrypto... yes
checking for X509_up_ref in -lcrypto... yes
checking for X509_CRL_up_ref in -lcrypto... yes
checking for DH_up_ref in -lcrypto... yes
checking for X509_get0_signature in -lcrypto... yes
checking for OPENSSL_init_ssl in -lssl... yes
checking for SSL_CIPHER_find in -lssl... yes
checking for SSL_CTX_set_tmp_rsa_callback in -lssl... no
checking for SSL_SESSION_get_id in -lssl... yes
checking for TLS_method in -lssl... yes
checking for TLS_client_method in -lssl... yes
checking for TLS_server_method in -lssl... yes
checking for SSL_CTX_get0_certificate in -lssl... yes
checking whether SSL_CTX_new and similar openSSL API functions require 
'const SSL_METHOD *'"... yes
checking whether SSL_get_new_ex_index() dup callback accepts 'const 
CRYPTO_EX_DATA *'"... yes
checking whether SSL_CTX_sess_set_get_cb() callback accepts a const ID 
argument"... yes
checking "whether X509_get0_signature() accepts const parameters"... yes
checking whether the TXT_DB use OPENSSL_PSTRING data member... yes
checking whether the squid workaround for buggy versions of 
sk_OPENSSL_PSTRING_value should used... no
checking whether the workaround for OpenSSL IMPLEMENT_LHASH_ macros 
should used... yes
checking whether hello message can be overwritten in SSL struct... no
configure: OpenSSL library support: yes -L/usr/local/ssl/lib -lssl -lcrypto
checking for LIB_KRB5... yes
configure: Try to find Kerberos headers in given path
checking gssapi.h usability... yes
checking gssapi.h presence... yes
checking for gssapi.h... yes
checking gssapi/gssapi.h usability... yes
checking gssapi/gssapi.h presence... yes
checking for gssapi/gssapi.h... yes
checking gssapi/gssapi_krb5.h usability... yes
checking gssapi/gssapi_krb5.h presence... yes
checking for gssapi/gssapi_krb5.h... yes
checking gssapi/gssapi_generic.h usability... yes
checking gssapi/gssapi_generic.h presence... yes
checking for gssapi/gssapi_generic.h... yes
checking krb5.h usability... yes
checking krb5.h presence... yes
checking for krb5.h... yes
checking com_err.h usability... yes
checking com_err.h presence... yes
checking for com_err.h... yes
checking et/com_err.h usability... yes
checking et/com_err.h presence... yes
checking for et/com_err.h... yes
checking profile.h usability... yes
checking profile.h presence... yes
checking for profile.h... yes
checking for error_message in -lcom_err... yes
checking for krb5_get_err_text in -lkrb5... no
checking for krb5_get_error_message in -lkrb5... yes
checking for krb5_free_error_message in -lkrb5... yes
checking for krb5_free_error_string in -lkrb5... no
checking whether krb5_kt_free_entry is declared... yes
checking for krb5_pac... yes
checking for krb5_kt_free_entry in -lkrb5... yes
checking for krb5_get_init_creds_keytab in -lkrb5... yes
checking for krb5_get_max_time_skew in -lkrb5... no
checking for krb5_get_profile in -lkrb5... yes
checking for profile_get_integer in -lkrb5... yes
checking for profile_release in -lkrb5... yes
checking for krb5_get_renewed_creds in -lkrb5... yes
checking for krb5_principal_get_realm in -lkrb5... no
checking for krb5_get_init_creds_opt_alloc in -lkrb5... yes
checking for krb5_get_init_creds_free requires krb5_context... yes
checking for gss_map_name_to_any... yes
checking for gsskrb5_extract_authz_data_from_sec_context... yes
checking for memory cache... yes
checking for memory keytab... yes
checking for working gssapi... yes
checking for spnego support... yes
checking for working krb5... yes
configure: MIT Kerberos library support: yes 
-L/usr/lib/x86_64-linux-gnu/mit-krb5 -lgssapi_krb5 -lkrb5 -lk5crypto 
-lcom_err
checking for ldap_init in -lldap... yes
checking for ber_init in -llber... yes
checking ldap.h usability... yes
checking ldap.h presence... yes
checking for ldap.h... yes
checking lber.h usability... yes
checking lber.h presence... yes
checking for lber.h... yes
checking mozldap/ldap.h usability... no
checking mozldap/ldap.h presence... no
checking for mozldap/ldap.h... no
checking for LDAP_OPT_DEBUG_LEVEL... yes
checking for working ldap... yes
checking for OpenLDAP... yes
checking for Sun LDAP SDK... no
checking for Mozilla LDAP SDK... no
checking for LDAP_REBINDPROC_CALLBACK... no
checking for LDAP_REBIND_PROC... yes
checking for LDAP_REBIND_FUNCTION... no
checking for LDAP_SCOPE_DEFAULT... yes
checking for struct ldap_url_desc.lud_scheme... yes
checking for ldapssl_client_init in -lldap... no
checking for ldap_url_desc2str in -lldap... yes
checking for ldap_url_parse in -lldap... yes
checking for ldap_start_tls_s in -lldap... yes
configure: Forw/Via database enabled: no
configure: Cache Digests enabled: yes
configure: enabling select syscall for net I/O: auto
configure: enabling poll syscall for net I/O: auto
checking sys/event.h usability... no
checking sys/event.h presence... no
checking for sys/event.h... no
checking for kqueue... no
configure: enabling kqueue for net I/O: no
configure: enabling epoll syscall for net I/O: auto
checking for library containing epoll_ctl... none required
checking sys/epoll.h usability... yes
checking sys/epoll.h presence... yes
checking for sys/epoll.h... yes
checking if epoll works... yes
configure: enabling /dev/poll for net I/O: auto
checking for ioctl... yes
checking for write... yes
checking sys/devpoll.h usability... no
checking sys/devpoll.h presence... no
checking for sys/devpoll.h... no
configure: HTTP violations support enabled: yes
configure: FreeBSD IPFW-based transparent proxying enabled: no
configure: IPF-based transparent proxying requested: no
configure: PF-based transparent proxying requested: no
configure: NAT lookups via /dev/pf: no
configure: Linux Netfilter support requested: yes
configure: Linux Netfilter Conntrack support requested: auto
checking for library containing nfct_query... -lnetfilter_conntrack
checking libnetfilter_conntrack/libnetfilter_conntrack.h usability... yes
checking libnetfilter_conntrack/libnetfilter_conntrack.h presence... yes
checking for libnetfilter_conntrack/libnetfilter_conntrack.h... yes
checking libnetfilter_conntrack/libnetfilter_conntrack_tcp.h 
usability... yes
checking libnetfilter_conntrack/libnetfilter_conntrack_tcp.h presence... yes
checking for libnetfilter_conntrack/libnetfilter_conntrack_tcp.h... yes
checking size of long... 8
configure: Using POSIX_V6_LP64_OFF64 build environment
configure: Leak Finder enabled: no
configure: Support for X-Forwarded-For enabled: yes
configure: Support for Ident lookups enabled: yes
configure: Default hosts file set to: /etc/hosts
configure: Authentication support enabled: yes
checking pwd.h usability... yes
checking pwd.h presence... yes
checking for pwd.h... yes
checking for crypt... yes
checking for unistd.h... (cached) yes
checking crypt.h usability... yes
checking crypt.h presence... yes
checking for crypt.h... yes
checking shadow.h usability... yes
checking shadow.h presence... yes
checking for shadow.h... yes
checking for ldap.h... (cached) yes
checking winldap.h usability... no
checking winldap.h presence... no
checking for winldap.h... no
checking for crypt... (cached) yes
checking for sys/types.h... yes
checking for rpc/rpc.h... yes
checking for rpcsvc/ypclnt.h... yes
checking for rpcsvc/yp_prot.h... yes
checking for crypt.h... (cached) yes
checking security/pam_appl.h usability... yes
checking security/pam_appl.h presence... yes
checking for security/pam_appl.h... yes
checking for PAM conversation struct signature type... linux
checking sasl/sasl.h usability... yes
checking sasl/sasl.h presence... yes
checking for sasl/sasl.h... yes
checking sasl.h usability... no
checking sasl.h presence... no
checking for sasl.h... no
checking for sasl_errstring in -lsasl2... yes
checking for smbclient... /usr/bin/smbclient
configure: Basic auth helpers to be built:? DB fake getpwnam LDAP NCSA 
NIS PAM POP3 RADIUS SASL SMB
checking for ldap.h... (cached) yes
checking for winldap.h... (cached) no
configure: Digest auth helpers to be built:? file LDAP
checking for vfork... yes
configure: Negotiate auth helpers to be built:? kerberos wrapper
configure: error: NTLM auth helper smb_lm ... not found

Best,
Sami M?ntysaari



From squid3 at treenet.co.nz  Sun Nov 11 23:52:52 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 12 Nov 2018 12:52:52 +1300
Subject: [squid-users] Problems with building squid 4.4 on Ubuntu 16.04
In-Reply-To: <0d74b01e-39ae-53ea-a1fb-ab97c3b38c7d@samip.fi>
References: <0d74b01e-39ae-53ea-a1fb-ab97c3b38c7d@samip.fi>
Message-ID: <5e68bd44-b80a-5d6d-75a0-04e57e60802d@treenet.co.nz>

On 11/11/18 12:44 PM, Sami M?ntysaari wrote:
> Dear list subscribers,
> 
> I'm unable to get a working version built, so I can use ssl-bump.
> 
> Configuration flags/args:
> 
...>
--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB
> \
> --enable-auth-digest=file,LDAP \
> --enable-auth-negotiate=kerberos,wrapper \
> --enable-auth-ntlm=fake,smb_lm \
> --enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,unix_group,wbinfo_group
> \
> --enable-url-rewrite-helpers=fake \

Some of the helpers have been renamed or removed since Squid-3. That is
your current problem.

Debian/Ubuntu Squid-4 packages use these helper build options:

'--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB'

'--enable-auth-digest=file,LDAP'

'--enable-auth-negotiate=kerberos,wrapper'

'--enable-auth-ntlm=fake,SMB_LM'

'--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,time_quota,unix_group,wbinfo_group'

'--enable-security-cert-validators=fake'

'--enable-storeid-rewrite-helpers=file'

'--enable-url-rewrite-helpers=fake'



FYI: The helper that used to be called "ssl_crtd" is now called
security_file_certgen. If you are following old tutorials, or using
config from a Squid-3 they may still refer to the old name.


> --enable-ssl \

Remove --enable-ssl. You are already using the --with-openssl which
replaced it.


Cheers
Amos


From suprajasridhar95 at gmail.com  Mon Nov 12 02:45:01 2018
From: suprajasridhar95 at gmail.com (supraja sridhar)
Date: Mon, 12 Nov 2018 08:15:01 +0530
Subject: [squid-users] Fwd: Encrypted browser-squid connection
In-Reply-To: <CAKL1wB0a0gd9Zd=UbjMxYTPPLU_60J0jSCVjSpGNjghP8Y-+DQ@mail.gmail.com>
References: <CAKL1wB1TnwUEyTen=UOZe1syt7L5+sRQVTLu72OWC8SYPRHS1w@mail.gmail.com>
 <CAKL1wB0a0gd9Zd=UbjMxYTPPLU_60J0jSCVjSpGNjghP8Y-+DQ@mail.gmail.com>
Message-ID: <CAKL1wB3S=q50MxcAOjWKfWcWG5SZXncMTMJdjm4YQ7z3ettaDQ@mail.gmail.com>

Hi,
When I try out the encrypted browser-squid connection, no URL loads. I get
the following error message in the squid access log.

1541989360.999      0 XXX.XX.XXX.XX NONE/000 0 NONE
> error:transaction-end-before-headers - HIER_NONE/- -
>

I have Firefox-59.0.1 running on Ubuntu  loaded with the following pac file

> function FindProxyForURL(url, host)
>
> {
>
>  return "HTTPS XXX.XX.XXX.XXX:3129"
>
> }
>
>
Squid-version: 4.4 and it runs on  Ubuntu 16.04.5 OS.

Can someone please help me debug this further?

Thanks,
Supraja



-- 
Regards,
S.SUPRAJA
MIT


-- 
Regards,
S.SUPRAJA
MIT
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181112/fa10d322/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf.rtf
Type: application/rtf
Size: 3195 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181112/fa10d322/attachment.rtf>

From squid3 at treenet.co.nz  Mon Nov 12 03:28:43 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 12 Nov 2018 16:28:43 +1300
Subject: [squid-users] Fwd: Encrypted browser-squid connection
In-Reply-To: <CAKL1wB3S=q50MxcAOjWKfWcWG5SZXncMTMJdjm4YQ7z3ettaDQ@mail.gmail.com>
References: <CAKL1wB1TnwUEyTen=UOZe1syt7L5+sRQVTLu72OWC8SYPRHS1w@mail.gmail.com>
 <CAKL1wB0a0gd9Zd=UbjMxYTPPLU_60J0jSCVjSpGNjghP8Y-+DQ@mail.gmail.com>
 <CAKL1wB3S=q50MxcAOjWKfWcWG5SZXncMTMJdjm4YQ7z3ettaDQ@mail.gmail.com>
Message-ID: <725bc38b-2346-cbab-bfba-704d15ed58fb@treenet.co.nz>

On 12/11/18 3:45 PM, supraja sridhar wrote:
> 
> Can someone please help me debug this further?
> 

First thing to do is convert your config file to plain-text (ASCII).
Squid does not use RTF format config.


Second your definition for "all" ACL is incorrect. Remove it and use the
built-in one.

Also remove that "http_access allow all" and adjust the localnet ACL to
match your actual LAN range(s) you expect clients to be using. Both IPv4
and IPv6.

Then use "squid -k parse" to verify Squid is able to use your updated
config and a full restart Squid to make extra-sure it is only using that
config.


The next debugging to do is check the actual protocol with a wireshark
full-packet trace to see what the Browser is actually sending to the proxy.


Amos


From alex at nanogherkin.com  Mon Nov 12 07:52:59 2018
From: alex at nanogherkin.com (Alex Crow)
Date: Mon, 12 Nov 2018 07:52:59 +0000
Subject: [squid-users] Fwd: Encrypted browser-squid connection
In-Reply-To: <CAKL1wB3S=q50MxcAOjWKfWcWG5SZXncMTMJdjm4YQ7z3ettaDQ@mail.gmail.com>
References: <CAKL1wB1TnwUEyTen=UOZe1syt7L5+sRQVTLu72OWC8SYPRHS1w@mail.gmail.com>
 <CAKL1wB0a0gd9Zd=UbjMxYTPPLU_60J0jSCVjSpGNjghP8Y-+DQ@mail.gmail.com>
 <CAKL1wB3S=q50MxcAOjWKfWcWG5SZXncMTMJdjm4YQ7z3ettaDQ@mail.gmail.com>
Message-ID: <2f20f9a4-3878-bd63-a850-be9796f0272f@nanogherkin.com>


On 12/11/2018 02:45, supraja sridhar wrote:
> Hi,
> When I try out the encrypted browser-squid connection, no URL loads. I 
> get the following error message in the squid access log.
>
>     1541989360.999 ? ? 0 XXX.XX.XXX.XX NONE/000 0 NONE
>     error:transaction-end-before-headers - HIER_NONE/- -
>
>
> I have Firefox-59.0.1 running on Ubuntu loaded with the following pac file
>
>         function FindProxyForURL(url, host)
>
>         {
>
>         ?return "HTTPS XXX.XX.XXX.XXX:3129"
>
>         }
>

Should be

return "PROXY XXX.XXX.XXX.XXX:3129;"




--
Insert pointless drivel here.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181112/aaf6ea53/attachment.htm>

From m.hoffmann.bs at gmail.com  Mon Nov 12 10:05:46 2018
From: m.hoffmann.bs at gmail.com (Martin Hoffmann)
Date: Mon, 12 Nov 2018 11:05:46 +0100
Subject: [squid-users] Squid4 with GnuTLS - specify ciphers or disable
	protocols
In-Reply-To: <mailman.3.1541851201.4312.squid-users@lists.squid-cache.org>
References: <mailman.3.1541851201.4312.squid-users@lists.squid-cache.org>
Message-ID: <CADpL81bKoNSQqsXyCkgWKCyL0kOpqgYGkVea-zxNWG2Aoe6BsQ@mail.gmail.com>

Thanks for your quick reply.

Are your sure that tls-options *is working*?

It seems that no matter what options I give to tls-options everything is
ignored:

https_port 192.168.x.y:443 tls-cert=/path/cert.crt tls-key=/path/cert.key
tls-dh=/path/dhparams.pem tls-options=NORMAL:-VERS-TLS1.0 accel defaultsite=
my.domain.com

I have even tried tls-options=SECURE128:+SECURE192:-VERS-ALL:+VERS-TLS1.2
- but in the end its all the same, TLS 1.0, 1.1 and 1.2 are enabled and all
the same cipher suites are active. Absolute identical to omitting
tls-options=... altogether.

Any idea?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181112/4b5c7322/attachment.htm>

From rousskov at measurement-factory.com  Mon Nov 12 19:01:21 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 12 Nov 2018 12:01:21 -0700
Subject: [squid-users] Fwd: Encrypted browser-squid connection
In-Reply-To: <2f20f9a4-3878-bd63-a850-be9796f0272f@nanogherkin.com>
References: <CAKL1wB1TnwUEyTen=UOZe1syt7L5+sRQVTLu72OWC8SYPRHS1w@mail.gmail.com>
 <CAKL1wB0a0gd9Zd=UbjMxYTPPLU_60J0jSCVjSpGNjghP8Y-+DQ@mail.gmail.com>
 <CAKL1wB3S=q50MxcAOjWKfWcWG5SZXncMTMJdjm4YQ7z3ettaDQ@mail.gmail.com>
 <2f20f9a4-3878-bd63-a850-be9796f0272f@nanogherkin.com>
Message-ID: <5c83076a-f92a-bd94-b70f-e68e0bd24797@measurement-factory.com>

On 11/12/18 12:52 AM, Alex Crow wrote:
> 
> On 12/11/2018 02:45, supraja sridhar wrote:
>> Hi,
>> When I try out the encrypted browser-squid connection, no URL loads. I
>> get the following error message in the squid access log.
>>
>>     1541989360.999? ? ? 0 XXX.XX.XXX.XX NONE/000 0 NONE
>>     error:transaction-end-before-headers - HIER_NONE/- -
>>
>>
>> I have Firefox-59.0.1 running on Ubuntu? loaded with the following pac
>> file
>>
>>         function FindProxyForURL(url, host)
>>
>>         {
>>
>>         ?return "HTTPS XXX.XX.XXX.XXX:3129"
>>
>>         }


> Should be
> 
> return "PROXY XXX.XXX.XXX.XXX:3129;"


Two problems with this suggestion:

* Major: "PROXY" is the wrong keyword for "Encrypted browser-squid
connection". OP's "HTTPS" was as correct as the email subject. See
https://developer.mozilla.org/en-US/docs/Web/HTTP/Proxy_servers_and_tunneling/Proxy_Auto-Configuration_(PAC)_file#Return_value_format

* Minor: Semicolons inside FindProxyForURL() return values are used to
delimit blocks. In this case, there is only one block so I would not add
a semicolon before the closing quote. Adding a semicolon at the end of
the return statement (i.e. _after_ the closing quote) may be a good idea
even though it is not required in this specific context IIRC.

Alex.


From squid3 at treenet.co.nz  Tue Nov 13 06:22:12 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 13 Nov 2018 19:22:12 +1300
Subject: [squid-users] Squid4 with GnuTLS - specify ciphers or disable
 protocols
In-Reply-To: <CADpL81bKoNSQqsXyCkgWKCyL0kOpqgYGkVea-zxNWG2Aoe6BsQ@mail.gmail.com>
References: <mailman.3.1541851201.4312.squid-users@lists.squid-cache.org>
 <CADpL81bKoNSQqsXyCkgWKCyL0kOpqgYGkVea-zxNWG2Aoe6BsQ@mail.gmail.com>
Message-ID: <a9578d84-5b0f-b953-8616-e5651a7433ea@treenet.co.nz>

On 12/11/18 11:05 PM, Martin Hoffmann wrote:
> Thanks for your quick reply.
> 
> Are your sure that tls-options *is working*?
> 

Nope, as I said earlier it is not tested much. Just that it builds and
passes the strings as-is to the library. It should "just work" since the
library is doing all the lifting.

The server connection side has had a bit more, testing that TLS version
restriction worked there.


> It seems that no matter what options I give to tls-options everything is
> ignored:
> 
> https_port 192.168.x.y:443 tls-cert=/path/cert.crt
> tls-key=/path/cert.key tls-dh=/path/dhparams.pem
> tls-options=NORMAL:-VERS-TLS1.0 accel defaultsite=my.domain.com
> <http://my.domain.com>
> 
> 
> I have even
> tried?tls-options=SECURE128:+SECURE192:-VERS-ALL:+VERS-TLS1.2? - but in
> the end its all the same, TLS 1.0, 1.1 and 1.2 are enabled and all the
> same cipher suites are active. Absolute identical to
> omitting?tls-options=...?altogether.
> 
> Any idea?
> 

Hmm. Looking into it now.

Amos


From ldominguezvega at gmail.com  Tue Nov 13 20:29:41 2018
From: ldominguezvega at gmail.com (Luis Felipe Dominguez Vega)
Date: Tue, 13 Nov 2018 15:29:41 -0500
Subject: [squid-users] Multiple ecap req services
Message-ID: <CAFijR=UxS3Pv4jq-rx_zP3w6nm1rV_nSpKdHgYs3ch75M3A=6g@mail.gmail.com>

Hello, i code 2 ecap_service to put into squid, each one work great in
solitary mode, but when i put them together, only that i first defined in
squid.conf is used, the other is ignored....

In ecap i need something special to tell squid that use all the services???
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181113/37cc7a16/attachment.htm>

From squid3 at treenet.co.nz  Wed Nov 14 03:42:08 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 14 Nov 2018 16:42:08 +1300
Subject: [squid-users] Multiple ecap req services
In-Reply-To: <CAFijR=UxS3Pv4jq-rx_zP3w6nm1rV_nSpKdHgYs3ch75M3A=6g@mail.gmail.com>
References: <CAFijR=UxS3Pv4jq-rx_zP3w6nm1rV_nSpKdHgYs3ch75M3A=6g@mail.gmail.com>
Message-ID: <78a6e137-9717-f74e-b86f-3df10b7dbfe7@treenet.co.nz>

On 14/11/18 9:29 AM, Luis Felipe Dominguez Vega wrote:
> Hello, i code 2 ecap_service to put into squid, each one work great in
> solitary mode, but when i put them together, only that i first defined
> in squid.conf is used, the other is ignored....
> 
> In ecap i need something special to tell squid that use all the services???
> 

Depends on what you mean by "use all the services" :

<http://www.squid-cache.org/Doc/config/adaptation_service_chain/>
<http://www.squid-cache.org/Doc/config/adaptation_service_set/>

Amos


From odhiambo at gmail.com  Wed Nov 14 11:54:34 2018
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Wed, 14 Nov 2018 14:54:34 +0300
Subject: [squid-users] Latest squid-5 compile error
Message-ID: <CAAdA2WNgKmJy7omrmtfQr=L-Fb4Z_LbY1fqx=U4oKeHToL3sPA@mail.gmail.com>

OS is FreeBSD 11.2:
squid-5.0.0-20181111-r1205859

Making all in eDirectory_userip
depbase=`echo ext_edirectory_userip_acl.o | sed
's|[^/]*$|.deps/&|;s|\.o$||'`; clang++ -DHAVE_CONFIG_H
-DDEFAULT_CONFIG_FILE=\"/opt/squid-5/etc/squid.conf\"
-DDEFAULT_SQUID_DATA_DIR=\"/opt/squid-5/share\"
-DDEFAULT_SQUID_CONFIG_DIR=\"/opt/squid-5/etc\"    -I../../../..
-I../../../../include  -I../../../../lib -I../../../../src
-I../../../../include  -I/usr/include  -I/usr/include
-I../../../../libltdl -I/usr/include -I/usr/local/include/libxml2
-I/usr/local/include -I/usr/local/include/libxml2  -Werror
-Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
-I/usr/local/include  -I/usr/local/include   -I/usr/local/include
-I/usr/local/include -I/usr/local/include/p11-kit-1  -g -O2 -march=native
-I/usr/local/include -MT ext_edirectory_userip_acl.o -MD -MP -MF
$depbase.Tpo -c -o ext_edirectory_userip_acl.o ext_edirectory_userip_acl.cc
&& mv -f $depbase.Tpo $depbase.Po
ext_edirectory_userip_acl.cc:891:31: error: use of undeclared identifier
'AF_INET6'
        if (dst->ai_family == AF_INET6) {
                              ^
ext_edirectory_userip_acl.cc:893:64: error: member access into incomplete
type 'struct sockaddr_in6'
            const char *ia = reinterpret_cast<const char
*>(sia->sin6_addr.s6_addr);
                                                               ^
ext_edirectory_userip_acl.cc:892:20: note: forward declaration of
'sockaddr_in6'
            struct sockaddr_in6 *sia = reinterpret_cast<struct sockaddr_in6
*>(dst->ai_addr);
                   ^
ext_edirectory_userip_acl.cc:893:66: error: expected ')'
            const char *ia = reinterpret_cast<const char
*>(sia->sin6_addr.s6_addr);
                                                                 ^
ext_edirectory_userip_acl.cc:893:60: note: to match this '('
            const char *ia = reinterpret_cast<const char
*>(sia->sin6_addr.s6_addr);
                                                           ^
ext_edirectory_userip_acl.cc:896:38: error: use of undeclared identifier
'AF_INET'
        } else if (dst->ai_family == AF_INET) {
                                     ^
ext_edirectory_userip_acl.cc:898:66: error: member access into incomplete
type 'struct sockaddr_in'
            const char *ia = reinterpret_cast<const char
*>(&(sia->sin_addr));
                                                                 ^
ext_edirectory_userip_acl.cc:897:20: note: forward declaration of
'sockaddr_in'
            struct sockaddr_in *sia = reinterpret_cast<struct sockaddr_in
*>(dst->ai_addr);
                   ^
5 errors generated.
*** Error code 1

Stop.
make[5]: stopped in
/usr/home/wash/Tools/Squid/5.x/squid-5.0.0-20181111-r1205859/src/acl/external/eDirectory_userip
*** Error code 1


-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181114/37df0143/attachment.htm>

From ldominguezvega at gmail.com  Wed Nov 14 13:13:46 2018
From: ldominguezvega at gmail.com (Luis Felipe Dominguez Vega)
Date: Wed, 14 Nov 2018 08:13:46 -0500
Subject: [squid-users] Multiple ecap req services
In-Reply-To: <78a6e137-9717-f74e-b86f-3df10b7dbfe7@treenet.co.nz>
References: <CAFijR=UxS3Pv4jq-rx_zP3w6nm1rV_nSpKdHgYs3ch75M3A=6g@mail.gmail.com>
 <78a6e137-9717-f74e-b86f-3df10b7dbfe7@treenet.co.nz>
Message-ID: <CAFijR=Wfxez=KZJ_3GGZGoOHb2KneAn7ztgMC2PZmCkuXj6brw@mail.gmail.com>

by "use all services" i mean, that all the ecap services set as
reqmod_precache.... see this:
if i change the order in adaptation_access, then only the first defined is
used, the another is not used, so i think that in my
ecap module i need to put something like.... "continue to next
adaptation_service"?????

*******************************************************************************************************************************************
loadable_modules /usr/libexec/squid/ecap_adapter_siteblock.so
loadable_modules /usr/libexec/squid/squid-transfer-audit.so

ecap_service ecapSquidTransferAuditRequest reqmod_precache ecap://
h3r3t1c.cu/ecap/services/transfer_audit_CLIENT_REQUEST_MODE bypass=0
ecap_service ecapBlockSiteRequest reqmod_precache ecap://
h3r3t1c.cu/ecap/services/siteblock?mode=CLIENT_REQUEST_MODE bypass=0
-----------------------------------------------------------------------------------

# HERE IS THE PROBLEM WITH ORDER
adaptation_access ecapBlockSiteRequest allow all
adaptation_access ecapSquidTransferAuditRequest allow all

*****************************************************************************************************


El mar., 13 nov. 2018 a las 22:42, Amos Jeffries (<squid3 at treenet.co.nz>)
escribi?:

> On 14/11/18 9:29 AM, Luis Felipe Dominguez Vega wrote:
> > Hello, i code 2 ecap_service to put into squid, each one work great in
> > solitary mode, but when i put them together, only that i first defined
> > in squid.conf is used, the other is ignored....
> >
> > In ecap i need something special to tell squid that use all the
> services???
> >
>
> Depends on what you mean by "use all the services" :
>
> <http://www.squid-cache.org/Doc/config/adaptation_service_chain/>
> <http://www.squid-cache.org/Doc/config/adaptation_service_set/>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181114/768e76f2/attachment.htm>

From squid3 at treenet.co.nz  Wed Nov 14 13:54:28 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Nov 2018 02:54:28 +1300
Subject: [squid-users] Multiple ecap req services
In-Reply-To: <CAFijR=Wfxez=KZJ_3GGZGoOHb2KneAn7ztgMC2PZmCkuXj6brw@mail.gmail.com>
References: <CAFijR=UxS3Pv4jq-rx_zP3w6nm1rV_nSpKdHgYs3ch75M3A=6g@mail.gmail.com>
 <78a6e137-9717-f74e-b86f-3df10b7dbfe7@treenet.co.nz>
 <CAFijR=Wfxez=KZJ_3GGZGoOHb2KneAn7ztgMC2PZmCkuXj6brw@mail.gmail.com>
Message-ID: <33398994-1a4f-4a4b-c682-ab01a2d600d6@treenet.co.nz>

On 15/11/18 2:13 AM, Luis Felipe Dominguez Vega wrote:
> by "use all services" i mean, that all the ecap services set as
> reqmod_precache.... see this:
> if i change the order in adaptation_access, then only the first defined
> is used, the another is not used, so i think that in my
> ecap module i need to put something like.... "continue to next
> adaptation_service"?????


Did you read the documentation I provided links for earlier?

There are multiple ways to group and order services. The services
themselves can even change the order of what follows. The config sample
you mention does not contain anything telling Squid those details.

You need to add one of those directives I provided links to - whichever
one meets your required ordering.

Amos


From squid3 at treenet.co.nz  Wed Nov 14 14:10:15 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Nov 2018 03:10:15 +1300
Subject: [squid-users] Latest squid-5 compile error
In-Reply-To: <CAAdA2WNgKmJy7omrmtfQr=L-Fb4Z_LbY1fqx=U4oKeHToL3sPA@mail.gmail.com>
References: <CAAdA2WNgKmJy7omrmtfQr=L-Fb4Z_LbY1fqx=U4oKeHToL3sPA@mail.gmail.com>
Message-ID: <cc41641c-6009-1c22-f7be-f6b9cb818373@treenet.co.nz>

On 15/11/18 12:54 AM, Odhiambo Washington wrote:
> OS is FreeBSD 11.2:
> squid-5.0.0-20181111-r1205859??
> 
> Making all in eDirectory_userip
> depbase=`echo ext_edirectory_userip_acl.o | sed
> 's|[^/]*$|.deps/&|;s|\.o$||'`; clang++ -DHAVE_CONFIG_H
> -DDEFAULT_CONFIG_FILE=\"/opt/squid-5/etc/squid.conf\"?
> -DDEFAULT_SQUID_DATA_DIR=\"/opt/squid-5/share\"?
> -DDEFAULT_SQUID_CONFIG_DIR=\"/opt/squid-5/etc\"? ? -I../../../..
> -I../../../../include? -I../../../../lib -I../../../../src?
> -I../../../../include? -I/usr/include? -I/usr/include?
> -I../../../../libltdl -I/usr/include -I/usr/local/include/libxml2
> -I/usr/local/include -I/usr/local/include/libxml2? -Werror
> -Qunused-arguments -Wno-deprecated-register? -D_REENTRANT
> -I/usr/local/include? -I/usr/local/include? ?-I/usr/local/include?
> -I/usr/local/include -I/usr/local/include/p11-kit-1? -g -O2
> -march=native -I/usr/local/include -MT ext_edirectory_userip_acl.o -MD
> -MP -MF $depbase.Tpo -c -o ext_edirectory_userip_acl.o
> ext_edirectory_userip_acl.cc && mv -f $depbase.Tpo $depbase.Po
> ext_edirectory_userip_acl.cc:891:31: error: use of undeclared identifier
> 'AF_INET6'
> ? ? ? ? if (dst->ai_family == AF_INET6) {
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^
> ext_edirectory_userip_acl.cc:893:64: error: member access into
> incomplete type 'struct sockaddr_in6'
> ? ? ? ? ? ? const char *ia = reinterpret_cast<const char
> *>(sia->sin6_addr.s6_addr);


So probably FreeBSD has changed its networking OS headers again in a way
that breaks the sockaddr_in6 definition. They do it every so often with
similar results to this appearing out of nowhere.

Can you figure out which one is missing? and/or what has changed with
the ordering that *BSD require software to use with these headers in 11.2?


PS. build issues with the experimental (Squid-5 currently) code should
be brought up in squid-dev mailing list or bugzilla. Not here.

Amos


From odhiambo at gmail.com  Wed Nov 14 15:31:52 2018
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Wed, 14 Nov 2018 18:31:52 +0300
Subject: [squid-users] Latest squid-5 compile error
In-Reply-To: <cc41641c-6009-1c22-f7be-f6b9cb818373@treenet.co.nz>
References: <CAAdA2WNgKmJy7omrmtfQr=L-Fb4Z_LbY1fqx=U4oKeHToL3sPA@mail.gmail.com>
 <cc41641c-6009-1c22-f7be-f6b9cb818373@treenet.co.nz>
Message-ID: <CAAdA2WNvG0CeqMmtFqCuPAVf-LZksSbWyUGfB4Z7DXPU_0yJmw@mail.gmail.com>

On Wed, 14 Nov 2018 at 17:10, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 15/11/18 12:54 AM, Odhiambo Washington wrote:
> > OS is FreeBSD 11.2:
> > squid-5.0.0-20181111-r1205859
> >
> > Making all in eDirectory_userip
> > depbase=`echo ext_edirectory_userip_acl.o | sed
> > 's|[^/]*$|.deps/&|;s|\.o$||'`; clang++ -DHAVE_CONFIG_H
> > -DDEFAULT_CONFIG_FILE=\"/opt/squid-5/etc/squid.conf\"
> > -DDEFAULT_SQUID_DATA_DIR=\"/opt/squid-5/share\"
> > -DDEFAULT_SQUID_CONFIG_DIR=\"/opt/squid-5/etc\"    -I../../../..
> > -I../../../../include  -I../../../../lib -I../../../../src
> > -I../../../../include  -I/usr/include  -I/usr/include
> > -I../../../../libltdl -I/usr/include -I/usr/local/include/libxml2
> > -I/usr/local/include -I/usr/local/include/libxml2  -Werror
> > -Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
> > -I/usr/local/include  -I/usr/local/include   -I/usr/local/include
> > -I/usr/local/include -I/usr/local/include/p11-kit-1  -g -O2
> > -march=native -I/usr/local/include -MT ext_edirectory_userip_acl.o -MD
> > -MP -MF $depbase.Tpo -c -o ext_edirectory_userip_acl.o
> > ext_edirectory_userip_acl.cc && mv -f $depbase.Tpo $depbase.Po
> > ext_edirectory_userip_acl.cc:891:31: error: use of undeclared identifier
> > 'AF_INET6'
> >         if (dst->ai_family == AF_INET6) {
> >                               ^
> > ext_edirectory_userip_acl.cc:893:64: error: member access into
> > incomplete type 'struct sockaddr_in6'
> >             const char *ia = reinterpret_cast<const char
> > *>(sia->sin6_addr.s6_addr);
>
>
> So probably FreeBSD has changed its networking OS headers again in a way
> that breaks the sockaddr_in6 definition. They do it every so often with
> similar results to this appearing out of nowhere.
>
> Can you figure out which one is missing? and/or what has changed with
> the ordering that *BSD require software to use with these headers in 11.2?
>
>
> PS. build issues with the experimental (Squid-5 currently) code should
> be brought up in squid-dev mailing list or bugzilla. Not here.
>
> Amos
> _______________________________________________
>

Actually, the same thing happened with a squid-4.4 build.
It failed the same way.

The problem is, I do not know how to find out what has changed that's
causing this.

Making all in eDirectory_userip
depbase=`echo ext_edirectory_userip_acl.o | sed
's|[^/]*$|.deps/&|;s|\.o$||'`; clang++ -DHAVE_CONFIG_H
-DDEFAULT_CONFIG_FILE=\"/opt/squid-4/etc/squid.conf\"
-DDEFAULT_SQUID_DATA_DIR=\"/opt/squid-4/share\"
-DDEFAULT_SQUID_CONFIG_DIR=\"/opt/squid-4/etc\"    -I../../../..
-I../../../../include  -I../../../../lib -I../../../../src
-I../../../../include  -I/usr/include  -I/usr/include
-I../../../../libltdl -I/usr/include -I/usr/local/include/libxml2
-I/usr/local/include -I/usr/local/include/libxml2  -Werror
-Qunused-arguments -Wno-deprecated-register  -D_REENTRANT
-I/usr/local/include  -I/usr/local/include -I/usr/local/include/p11-kit-1
-g -O2 -march=native -I/usr/local/include -MT ext_edirectory_userip_acl.o
-MD -MP -MF $depbase.Tpo -c -o ext_edirectory_userip_acl.o
ext_edirectory_userip_acl.cc && mv -f $depbase.Tpo $depbase.Po
ext_edirectory_userip_acl.cc:891:31: error: use of undeclared identifier
'AF_INET6'
        if (dst->ai_family == AF_INET6) {
                              ^
ext_edirectory_userip_acl.cc:893:64: error: member access into incomplete
type 'struct sockaddr_in6'
            const char *ia = reinterpret_cast<const char
*>(sia->sin6_addr.s6_addr);
                                                               ^
ext_edirectory_userip_acl.cc:892:20: note: forward declaration of
'sockaddr_in6'
            struct sockaddr_in6 *sia = reinterpret_cast<struct sockaddr_in6
*>(dst->ai_addr);
                   ^
ext_edirectory_userip_acl.cc:893:66: error: expected ')'
            const char *ia = reinterpret_cast<const char
*>(sia->sin6_addr.s6_addr);
                                                                 ^
ext_edirectory_userip_acl.cc:893:60: note: to match this '('
            const char *ia = reinterpret_cast<const char
*>(sia->sin6_addr.s6_addr);
                                                           ^
ext_edirectory_userip_acl.cc:896:38: error: use of undeclared identifier
'AF_INET'
        } else if (dst->ai_family == AF_INET) {
                                     ^
ext_edirectory_userip_acl.cc:898:66: error: member access into incomplete
type 'struct sockaddr_in'
            const char *ia = reinterpret_cast<const char
*>(&(sia->sin_addr));
                                                                 ^
ext_edirectory_userip_acl.cc:897:20: note: forward declaration of
'sockaddr_in'
            struct sockaddr_in *sia = reinterpret_cast<struct sockaddr_in
*>(dst->ai_addr);
                   ^
5 errors generated.
*** Error code 1



-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
"Oh, the cruft."
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181114/3d1b22d6/attachment.htm>

From ldominguezvega at gmail.com  Wed Nov 14 20:00:45 2018
From: ldominguezvega at gmail.com (Luis Felipe Dominguez Vega)
Date: Wed, 14 Nov 2018 15:00:45 -0500
Subject: [squid-users] Multiple ecap req services
In-Reply-To: <33398994-1a4f-4a4b-c682-ab01a2d600d6@treenet.co.nz>
References: <CAFijR=UxS3Pv4jq-rx_zP3w6nm1rV_nSpKdHgYs3ch75M3A=6g@mail.gmail.com>
 <78a6e137-9717-f74e-b86f-3df10b7dbfe7@treenet.co.nz>
 <CAFijR=Wfxez=KZJ_3GGZGoOHb2KneAn7ztgMC2PZmCkuXj6brw@mail.gmail.com>
 <33398994-1a4f-4a4b-c682-ab01a2d600d6@treenet.co.nz>
Message-ID: <CAFijR=V01ydoykdP_x5B+grLL3ejXjs0CONqQKPubXgcXyXuag@mail.gmail.com>

Not working.... i was added

adaptation_service_chain request_chain ecapBlockSiteRequest
ecapSquidTransferAuditRequest

and only ecapBlockSiteRequest is used.....

El mi?., 14 nov. 2018 a las 8:54, Amos Jeffries (<squid3 at treenet.co.nz>)
escribi?:

> On 15/11/18 2:13 AM, Luis Felipe Dominguez Vega wrote:
> > by "use all services" i mean, that all the ecap services set as
> > reqmod_precache.... see this:
> > if i change the order in adaptation_access, then only the first defined
> > is used, the another is not used, so i think that in my
> > ecap module i need to put something like.... "continue to next
> > adaptation_service"?????
>
>
> Did you read the documentation I provided links for earlier?
>
> There are multiple ways to group and order services. The services
> themselves can even change the order of what follows. The config sample
> you mention does not contain anything telling Squid those details.
>
> You need to add one of those directives I provided links to - whichever
> one meets your required ordering.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181114/5cd4bc1d/attachment.htm>

From info at schroeffu.ch  Thu Nov 15 09:50:09 2018
From: info at schroeffu.ch (info at schroeffu.ch)
Date: Thu, 15 Nov 2018 09:50:09 +0000
Subject: [squid-users] Squid 4.4: SSL/certification error messages not
 displayed with non-english error_directory
Message-ID: <bd57ac1dcdd8d0b133c0a13511a61f30@schroeffu.ch>

Changing the error_directory to non-english like german or italian, the ssl bump error messages like "expired certificate" or "self signed certificated" are not showing anymore. Browser is just displaying an ugly error 503. But, other error messages like "access denied" are displayed properly, also tested with German and Italian.

#error_directory /usr/share/squid/errors/German
#error_directory /usr/share/squid/errors/Italian

How do I debug that properly to raise a bugeport if required?

Squid Version: 4.4-1 (from Debian unstable on Ubuntu 18.04 Server, recompiled with openssl)
Squid Langpack Version: Version: 20170901-1 (from Debian unstable on Ubuntu 18.04 Server)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181115/d65eaecb/attachment.htm>

From squid3 at treenet.co.nz  Thu Nov 15 09:51:07 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Nov 2018 22:51:07 +1300
Subject: [squid-users] Multiple ecap req services
In-Reply-To: <CAFijR=V01ydoykdP_x5B+grLL3ejXjs0CONqQKPubXgcXyXuag@mail.gmail.com>
References: <CAFijR=UxS3Pv4jq-rx_zP3w6nm1rV_nSpKdHgYs3ch75M3A=6g@mail.gmail.com>
 <78a6e137-9717-f74e-b86f-3df10b7dbfe7@treenet.co.nz>
 <CAFijR=Wfxez=KZJ_3GGZGoOHb2KneAn7ztgMC2PZmCkuXj6brw@mail.gmail.com>
 <33398994-1a4f-4a4b-c682-ab01a2d600d6@treenet.co.nz>
 <CAFijR=V01ydoykdP_x5B+grLL3ejXjs0CONqQKPubXgcXyXuag@mail.gmail.com>
Message-ID: <59181888-11fb-f8b7-2e24-e78bbff18ae9@treenet.co.nz>

On 15/11/18 9:00 AM, Luis Felipe Dominguez Vega wrote:
> Not working.... i was added
> 
> adaptation_service_chain request_chain ecapBlockSiteRequest
> ecapSquidTransferAuditRequest
> 
> and only?ecapBlockSiteRequest is used.....
> 

This is sounding more and more like the eCAP module is broken.

Can you get a cache.log trace of what it is receiving and sending to Squid?

Amos


> El mi?., 14 nov. 2018 a las 8:54, Amos Jeffries escribi?:
> 
>     On 15/11/18 2:13 AM, Luis Felipe Dominguez Vega wrote:
>     > by "use all services" i mean, that all the ecap services set as
>     > reqmod_precache.... see this:
>     > if i change the order in adaptation_access, then only the first
>     defined
>     > is used, the another is not used, so i think that in my
>     > ecap module i need to put something like.... "continue to next
>     > adaptation_service"?????
> 
> 
>     Did you read the documentation I provided links for earlier?
> 
>     There are multiple ways to group and order services. The services
>     themselves can even change the order of what follows. The config sample
>     you mention does not contain anything telling Squid those details.
> 
>     You need to add one of those directives I provided links to - whichever
>     one meets your required ordering.
> 
>     Amos
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
> 


From squid3 at treenet.co.nz  Thu Nov 15 11:09:19 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 16 Nov 2018 00:09:19 +1300
Subject: [squid-users] Squid 4.4: SSL/certification error messages not
 displayed with non-english error_directory
In-Reply-To: <bd57ac1dcdd8d0b133c0a13511a61f30@schroeffu.ch>
References: <bd57ac1dcdd8d0b133c0a13511a61f30@schroeffu.ch>
Message-ID: <603ce06e-5ec0-d17e-a3ba-c72db3853c32@treenet.co.nz>

On 15/11/18 10:50 PM, info at schroeffu.ch wrote:
> 
> Changing the error_directory to non-english like german or italian, the
> ssl bump error messages like "expired certificate" or "self signed
> certificated" are not showing anymore. Browser is just displaying an
> ugly error 503. But, other error messages like "access denied" are
> displayed properly, also tested with German and Italian.
> 
> #error_directory /usr/share/squid/errors/German
> #error_directory /usr/share/squid/errors/Italian
> 
> How do I debug that properly to raise a bugeport if required?
> 

It is a known bug. The langpack contained empty files for some
templates. You can workaround the issue by replacing the 0-sized file(s)
with the one(s) from errors/templates/.
 A new langpack will be coming out as soon as we get the source of the
problem fixed.

Amos


From rafael.akchurin at diladele.com  Thu Nov 15 11:20:08 2018
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 15 Nov 2018 11:20:08 +0000
Subject: [squid-users] [tutorial] How to rebuild Squid 4.4 on Ubuntu 16 with
	SSLBump
Message-ID: <AM0PR04MB475304FC8BDA0BCD17A28ACB8FDC0@AM0PR04MB4753.eurprd04.prod.outlook.com>

Hello,

We have written a small tutorial on how to rebuild Squid 4.4 from Debian Unstable on Ubuntu 16 LTS.
It is available here - https://docs.diladele.com/howtos/build_squid_ubuntu16/index.html

The scripts are stored in github repo at https://github.com/diladele/squid-ubuntu/tree/master/src/ubuntu16, hopefully might be helpful for someone. Unfortunately no plans to publish online repo for the DEBs for now  (use squid44.diladele.com if you are ok with going to Ubuntu 18).

Best regards,
Rafael Akchurin
Diladele B.V.

--
Web Filter deployed in Microsoft Azure? Surely possible, see https://azuremarketplace.microsoft.com/en-us/marketplace/apps/diladele.websafety?tab=Overview


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181115/d4dbacb5/attachment.htm>

From rousskov at measurement-factory.com  Thu Nov 15 17:43:25 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 15 Nov 2018 10:43:25 -0700
Subject: [squid-users] Multiple ecap req services
In-Reply-To: <59181888-11fb-f8b7-2e24-e78bbff18ae9@treenet.co.nz>
References: <CAFijR=UxS3Pv4jq-rx_zP3w6nm1rV_nSpKdHgYs3ch75M3A=6g@mail.gmail.com>
 <78a6e137-9717-f74e-b86f-3df10b7dbfe7@treenet.co.nz>
 <CAFijR=Wfxez=KZJ_3GGZGoOHb2KneAn7ztgMC2PZmCkuXj6brw@mail.gmail.com>
 <33398994-1a4f-4a4b-c682-ab01a2d600d6@treenet.co.nz>
 <CAFijR=V01ydoykdP_x5B+grLL3ejXjs0CONqQKPubXgcXyXuag@mail.gmail.com>
 <59181888-11fb-f8b7-2e24-e78bbff18ae9@treenet.co.nz>
Message-ID: <78d43aab-632a-3782-64c2-b14c103450c2@measurement-factory.com>

On 11/15/18 2:51 AM, Amos Jeffries wrote:
> On 15/11/18 9:00 AM, Luis Felipe Dominguez Vega wrote:
>> Not working.... i was added
>>
>> adaptation_service_chain request_chain ecapBlockSiteRequest
>> ecapSquidTransferAuditRequest
>>
>> and only?ecapBlockSiteRequest is used.....


> This is sounding more and more like the eCAP module is broken.

Unless Squid configuration does not _use_ the declared request_chain. I
would ask for *all* adaptation-related lines from squid.conf first.

A good test is to reorder ecapSquidTransferAuditRequest and
ecapBlockSiteRequest in request_chain and see if ecapBlockSiteRequest is
still the only adaptation service that is being used. If it is, a
different set of adaptation_access lines is needed to enable
request_chain usage.


> Can you get a cache.log trace of what it is receiving and sending to Squid?

HTH,

Alex.


>> El mi?., 14 nov. 2018 a las 8:54, Amos Jeffries escribi?:
>>
>>     On 15/11/18 2:13 AM, Luis Felipe Dominguez Vega wrote:
>>     > by "use all services" i mean, that all the ecap services set as
>>     > reqmod_precache.... see this:
>>     > if i change the order in adaptation_access, then only the first
>>     defined
>>     > is used, the another is not used, so i think that in my
>>     > ecap module i need to put something like.... "continue to next
>>     > adaptation_service"?????
>>
>>
>>     Did you read the documentation I provided links for earlier?
>>
>>     There are multiple ways to group and order services. The services
>>     themselves can even change the order of what follows. The config sample
>>     you mention does not contain anything telling Squid those details.
>>
>>     You need to add one of those directives I provided links to - whichever
>>     one meets your required ordering.
>>
>>     Amos
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org>
>>     http://lists.squid-cache.org/listinfo/squid-users
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From fredrik at pipemore.se  Fri Nov 16 08:22:18 2018
From: fredrik at pipemore.se (uppsalanet)
Date: Fri, 16 Nov 2018 02:22:18 -0600 (CST)
Subject: [squid-users] redirect based on url (302)
In-Reply-To: <1541692358446-0.post@n4.nabble.com>
References: <dde485b6-5742-d424-8e12-f700d0b975f2@treenet.co.nz>
 <1537771119646-0.post@n4.nabble.com>
 <f35964b6-e83b-c5b6-5563-602ab666d964@treenet.co.nz>
 <1540305071062-0.post@n4.nabble.com>
 <a2ca5119-39c1-c744-0e8b-6373f7f525a3@treenet.co.nz>
 <1540900144095-0.post@n4.nabble.com>
 <23b5e473-3671-b473-572d-19a25daaefe8@treenet.co.nz>
 <1540981640859-0.post@n4.nabble.com>
 <c2ae6317-8fb0-4136-0761-83c7280a139b@treenet.co.nz>
 <1541692358446-0.post@n4.nabble.com>
Message-ID: <1542356538535-0.post@n4.nabble.com>

Just for documentation purpose. Amos suggestion works perfect:
/##### Ext magazine domains
debug_options 11,10 58,10 82,10
acl 302 http_status 302
acl browzine dstdomain .browzine.com .thirdiron.com
http_access allow browzine

external_acl_type whitelist_add ttl=10 %SRC %<h{Location}
/etc/squid/add2db.pl

acl add_to_whitelist external whitelist_add
http_reply_access allow browzine 302 add_to_whitelist
http_reply_access allow all
##### Ext magazine domains &lt;/i>

Why it's not working for me is that the site Im reaching have turned on
https encryption. TLS encrypted tunnel prevents me from seeing HTTP headers,
which means I cannot distinguish individual responses :-(

/F





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Fri Nov 16 09:57:24 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 16 Nov 2018 22:57:24 +1300
Subject: [squid-users] redirect based on url (302)
In-Reply-To: <1542356538535-0.post@n4.nabble.com>
References: <dde485b6-5742-d424-8e12-f700d0b975f2@treenet.co.nz>
 <1537771119646-0.post@n4.nabble.com>
 <f35964b6-e83b-c5b6-5563-602ab666d964@treenet.co.nz>
 <1540305071062-0.post@n4.nabble.com>
 <a2ca5119-39c1-c744-0e8b-6373f7f525a3@treenet.co.nz>
 <1540900144095-0.post@n4.nabble.com>
 <23b5e473-3671-b473-572d-19a25daaefe8@treenet.co.nz>
 <1540981640859-0.post@n4.nabble.com>
 <c2ae6317-8fb0-4136-0761-83c7280a139b@treenet.co.nz>
 <1541692358446-0.post@n4.nabble.com> <1542356538535-0.post@n4.nabble.com>
Message-ID: <2344831d-905b-ad7c-60b9-09254d81b93e@treenet.co.nz>

On 16/11/18 9:22 PM, uppsalanet wrote:
> Just for documentation purpose. Amos suggestion works perfect:
> /##### Ext magazine domains
> debug_options 11,10 58,10 82,10
> acl 302 http_status 302
> acl browzine dstdomain .browzine.com .thirdiron.com
> http_access allow browzine
> 
> external_acl_type whitelist_add ttl=10 %SRC %<h{Location}
> /etc/squid/add2db.pl
> 
> acl add_to_whitelist external whitelist_add
> http_reply_access allow browzine 302 add_to_whitelist
> http_reply_access allow all
> ##### Ext magazine domains &lt;/i>
> 
> Why it's not working for me is that the site Im reaching have turned on
> https encryption. TLS encrypted tunnel prevents me from seeing HTTP headers,
> which means I cannot distinguish individual responses :-(
> 


The only way around that is to intercept and decrypt the HTTPS using
Squid's SSL-Bump features.
 <https://wiki.squid-cache.org/Features/SslPeekAndSplice>

SSL-Bump requires that you are in a situation where you can install
trusted CA certificates into all client devices. Even if the decrypt is
possible there are legal implications which vary around the world, so
please do check with a lawyer before going ahead with it.

Amos


From ldominguezvega at gmail.com  Fri Nov 16 13:10:16 2018
From: ldominguezvega at gmail.com (Luis Felipe Dominguez Vega)
Date: Fri, 16 Nov 2018 08:10:16 -0500
Subject: [squid-users] Multiple ecap req services
In-Reply-To: <78d43aab-632a-3782-64c2-b14c103450c2@measurement-factory.com>
References: <CAFijR=UxS3Pv4jq-rx_zP3w6nm1rV_nSpKdHgYs3ch75M3A=6g@mail.gmail.com>
 <78a6e137-9717-f74e-b86f-3df10b7dbfe7@treenet.co.nz>
 <CAFijR=Wfxez=KZJ_3GGZGoOHb2KneAn7ztgMC2PZmCkuXj6brw@mail.gmail.com>
 <33398994-1a4f-4a4b-c682-ab01a2d600d6@treenet.co.nz>
 <CAFijR=V01ydoykdP_x5B+grLL3ejXjs0CONqQKPubXgcXyXuag@mail.gmail.com>
 <59181888-11fb-f8b7-2e24-e78bbff18ae9@treenet.co.nz>
 <78d43aab-632a-3782-64c2-b14c103450c2@measurement-factory.com>
Message-ID: <CAFijR=XFTXuip9rKVeqzRWBW0W-=-fBmomhmPxkO7MD3LAeHFA@mail.gmail.com>

Changing the order in request chain, only the ecapBlockSiteRequest is
working......

El jue., 15 nov. 2018 a las 12:43, Alex Rousskov (<
rousskov at measurement-factory.com>) escribi?:

> On 11/15/18 2:51 AM, Amos Jeffries wrote:
> > On 15/11/18 9:00 AM, Luis Felipe Dominguez Vega wrote:
> >> Not working.... i was added
> >>
> >> adaptation_service_chain request_chain ecapBlockSiteRequest
> >> ecapSquidTransferAuditRequest
> >>
> >> and only ecapBlockSiteRequest is used.....
>
>
> > This is sounding more and more like the eCAP module is broken.
>
> Unless Squid configuration does not _use_ the declared request_chain. I
> would ask for *all* adaptation-related lines from squid.conf first.
>
> A good test is to reorder ecapSquidTransferAuditRequest and
> ecapBlockSiteRequest in request_chain and see if ecapBlockSiteRequest is
> still the only adaptation service that is being used. If it is, a
> different set of adaptation_access lines is needed to enable
> request_chain usage.
>
>
> > Can you get a cache.log trace of what it is receiving and sending to
> Squid?
>
> HTH,
>
> Alex.
>
>
> >> El mi?., 14 nov. 2018 a las 8:54, Amos Jeffries escribi?:
> >>
> >>     On 15/11/18 2:13 AM, Luis Felipe Dominguez Vega wrote:
> >>     > by "use all services" i mean, that all the ecap services set as
> >>     > reqmod_precache.... see this:
> >>     > if i change the order in adaptation_access, then only the first
> >>     defined
> >>     > is used, the another is not used, so i think that in my
> >>     > ecap module i need to put something like.... "continue to next
> >>     > adaptation_service"?????
> >>
> >>
> >>     Did you read the documentation I provided links for earlier?
> >>
> >>     There are multiple ways to group and order services. The services
> >>     themselves can even change the order of what follows. The config
> sample
> >>     you mention does not contain anything telling Squid those details.
> >>
> >>     You need to add one of those directives I provided links to -
> whichever
> >>     one meets your required ordering.
> >>
> >>     Amos
> >>     _______________________________________________
> >>     squid-users mailing list
> >>     squid-users at lists.squid-cache.org
> >>     <mailto:squid-users at lists.squid-cache.org>
> >>     http://lists.squid-cache.org/listinfo/squid-users
> >>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> >
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181116/b45c2f21/attachment.htm>

From ldominguezvega at gmail.com  Fri Nov 16 13:11:43 2018
From: ldominguezvega at gmail.com (Luis Felipe Dominguez Vega)
Date: Fri, 16 Nov 2018 08:11:43 -0500
Subject: [squid-users] Multiple ecap req services
In-Reply-To: <59181888-11fb-f8b7-2e24-e78bbff18ae9@treenet.co.nz>
References: <CAFijR=UxS3Pv4jq-rx_zP3w6nm1rV_nSpKdHgYs3ch75M3A=6g@mail.gmail.com>
 <78a6e137-9717-f74e-b86f-3df10b7dbfe7@treenet.co.nz>
 <CAFijR=Wfxez=KZJ_3GGZGoOHb2KneAn7ztgMC2PZmCkuXj6brw@mail.gmail.com>
 <33398994-1a4f-4a4b-c682-ab01a2d600d6@treenet.co.nz>
 <CAFijR=V01ydoykdP_x5B+grLL3ejXjs0CONqQKPubXgcXyXuag@mail.gmail.com>
 <59181888-11fb-f8b7-2e24-e78bbff18ae9@treenet.co.nz>
Message-ID: <CAFijR=XajRvAxe85-dg2_NBwCJh3wGRNYbODF7_XAro38DytFg@mail.gmail.com>

Broked in what sense? there are any way into the ecap to tell to squid that
only it is executed? because i use only in ecapBlockSiteRequest the start()
function of XAction...

El jue., 15 nov. 2018 a las 4:51, Amos Jeffries (<squid3 at treenet.co.nz>)
escribi?:

> On 15/11/18 9:00 AM, Luis Felipe Dominguez Vega wrote:
> > Not working.... i was added
> >
> > adaptation_service_chain request_chain ecapBlockSiteRequest
> > ecapSquidTransferAuditRequest
> >
> > and only ecapBlockSiteRequest is used.....
> >
>
> This is sounding more and more like the eCAP module is broken.
>
> Can you get a cache.log trace of what it is receiving and sending to Squid?
>
> Amos
>
>
> > El mi?., 14 nov. 2018 a las 8:54, Amos Jeffries escribi?:
> >
> >     On 15/11/18 2:13 AM, Luis Felipe Dominguez Vega wrote:
> >     > by "use all services" i mean, that all the ecap services set as
> >     > reqmod_precache.... see this:
> >     > if i change the order in adaptation_access, then only the first
> >     defined
> >     > is used, the another is not used, so i think that in my
> >     > ecap module i need to put something like.... "continue to next
> >     > adaptation_service"?????
> >
> >
> >     Did you read the documentation I provided links for earlier?
> >
> >     There are multiple ways to group and order services. The services
> >     themselves can even change the order of what follows. The config
> sample
> >     you mention does not contain anything telling Squid those details.
> >
> >     You need to add one of those directives I provided links to -
> whichever
> >     one meets your required ordering.
> >
> >     Amos
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>
> >     http://lists.squid-cache.org/listinfo/squid-users
> >
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181116/66b0c04f/attachment.htm>

From ldominguezvega at gmail.com  Fri Nov 16 13:14:47 2018
From: ldominguezvega at gmail.com (Luis Felipe Dominguez Vega)
Date: Fri, 16 Nov 2018 08:14:47 -0500
Subject: [squid-users] Multiple ecap req services
In-Reply-To: <78d43aab-632a-3782-64c2-b14c103450c2@measurement-factory.com>
References: <CAFijR=UxS3Pv4jq-rx_zP3w6nm1rV_nSpKdHgYs3ch75M3A=6g@mail.gmail.com>
 <78a6e137-9717-f74e-b86f-3df10b7dbfe7@treenet.co.nz>
 <CAFijR=Wfxez=KZJ_3GGZGoOHb2KneAn7ztgMC2PZmCkuXj6brw@mail.gmail.com>
 <33398994-1a4f-4a4b-c682-ab01a2d600d6@treenet.co.nz>
 <CAFijR=V01ydoykdP_x5B+grLL3ejXjs0CONqQKPubXgcXyXuag@mail.gmail.com>
 <59181888-11fb-f8b7-2e24-e78bbff18ae9@treenet.co.nz>
 <78d43aab-632a-3782-64c2-b14c103450c2@measurement-factory.com>
Message-ID: <CAFijR=XqEL+u+YOsEEwhB0mYsUVeOSrpsi9uU1UzdV_8B=e37A@mail.gmail.com>

This is all source related to ecap:

ecap_enable on

adaptation_send_client_ip on
adaptation_send_username on
adaptation_masterx_shared_names X-Subscriber-ID

loadable_modules /usr/libexec/squid/ecap_adapter_siteblock.so
loadable_modules /usr/libexec/squid/squid-transfer-audit.so

ecap_service ecapSquidTransferAuditRequest reqmod_precache ecap://
h3r3t1c.cu/ecap/services/transfer_audit_CLIENT_REQUEST_MODE bypass=0
ecap_service ecapBlockSiteRequest reqmod_precache ecap://
h3r3t1c.cu/ecap/services/siteblock?mode=CLIENT_REQUEST_MODE bypass=0

adaptation_service_chain request_chain ecapSquidTransferAuditRequest
ecapBlockSiteRequest

adaptation_access ecapBlockSiteRequest allow all
adaptation_access ecapSquidTransferAuditRequest allow all



El jue., 15 nov. 2018 a las 12:43, Alex Rousskov (<
rousskov at measurement-factory.com>) escribi?:

> On 11/15/18 2:51 AM, Amos Jeffries wrote:
> > On 15/11/18 9:00 AM, Luis Felipe Dominguez Vega wrote:
> >> Not working.... i was added
> >>
> >> adaptation_service_chain request_chain ecapBlockSiteRequest
> >> ecapSquidTransferAuditRequest
> >>
> >> and only ecapBlockSiteRequest is used.....
>
>
> > This is sounding more and more like the eCAP module is broken.
>
> Unless Squid configuration does not _use_ the declared request_chain. I
> would ask for *all* adaptation-related lines from squid.conf first.
>
> A good test is to reorder ecapSquidTransferAuditRequest and
> ecapBlockSiteRequest in request_chain and see if ecapBlockSiteRequest is
> still the only adaptation service that is being used. If it is, a
> different set of adaptation_access lines is needed to enable
> request_chain usage.
>
>
> > Can you get a cache.log trace of what it is receiving and sending to
> Squid?
>
> HTH,
>
> Alex.
>
>
> >> El mi?., 14 nov. 2018 a las 8:54, Amos Jeffries escribi?:
> >>
> >>     On 15/11/18 2:13 AM, Luis Felipe Dominguez Vega wrote:
> >>     > by "use all services" i mean, that all the ecap services set as
> >>     > reqmod_precache.... see this:
> >>     > if i change the order in adaptation_access, then only the first
> >>     defined
> >>     > is used, the another is not used, so i think that in my
> >>     > ecap module i need to put something like.... "continue to next
> >>     > adaptation_service"?????
> >>
> >>
> >>     Did you read the documentation I provided links for earlier?
> >>
> >>     There are multiple ways to group and order services. The services
> >>     themselves can even change the order of what follows. The config
> sample
> >>     you mention does not contain anything telling Squid those details.
> >>
> >>     You need to add one of those directives I provided links to -
> whichever
> >>     one meets your required ordering.
> >>
> >>     Amos
> >>     _______________________________________________
> >>     squid-users mailing list
> >>     squid-users at lists.squid-cache.org
> >>     <mailto:squid-users at lists.squid-cache.org>
> >>     http://lists.squid-cache.org/listinfo/squid-users
> >>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> >
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181116/7e654db5/attachment.htm>

From rousskov at measurement-factory.com  Fri Nov 16 14:59:55 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 16 Nov 2018 07:59:55 -0700
Subject: [squid-users] Multiple ecap req services
In-Reply-To: <CAFijR=XqEL+u+YOsEEwhB0mYsUVeOSrpsi9uU1UzdV_8B=e37A@mail.gmail.com>
References: <CAFijR=UxS3Pv4jq-rx_zP3w6nm1rV_nSpKdHgYs3ch75M3A=6g@mail.gmail.com>
 <78a6e137-9717-f74e-b86f-3df10b7dbfe7@treenet.co.nz>
 <CAFijR=Wfxez=KZJ_3GGZGoOHb2KneAn7ztgMC2PZmCkuXj6brw@mail.gmail.com>
 <33398994-1a4f-4a4b-c682-ab01a2d600d6@treenet.co.nz>
 <CAFijR=V01ydoykdP_x5B+grLL3ejXjs0CONqQKPubXgcXyXuag@mail.gmail.com>
 <59181888-11fb-f8b7-2e24-e78bbff18ae9@treenet.co.nz>
 <78d43aab-632a-3782-64c2-b14c103450c2@measurement-factory.com>
 <CAFijR=XqEL+u+YOsEEwhB0mYsUVeOSrpsi9uU1UzdV_8B=e37A@mail.gmail.com>
Message-ID: <94a0cf51-5887-061f-12f3-cb2554d9255a@measurement-factory.com>

On 11/16/18 6:14 AM, Luis Felipe Dominguez Vega wrote:

> adaptation_service_chain request_chain ...
> 
> adaptation_access ecapBlockSiteRequest allow all
> adaptation_access ecapSquidTransferAuditRequest allow all

You did not tell Squid to use request_chain. You told Squid to use
ecapBlockSiteRequest and only ecapBlockSiteRequest. adaptation_access
directive selects which service (or a group of services) is going to be
used. Your directive always selects ecapBlockSiteRequest.

You may declare 100 adaptation services, service sets, and service
chains. How should Squid know which service (or set or chain) it should
send the request to? Squid evaluates adaptation_access rules to answer
that question. The first applicable matching rule determines the service
(or set or chain) that will be used at a given vectoring point for a
given transaction.

Alex.


> El jue., 15 nov. 2018 a las 12:43, Alex Rousskov escribi?:
> 
>     On 11/15/18 2:51 AM, Amos Jeffries wrote:
>     > On 15/11/18 9:00 AM, Luis Felipe Dominguez Vega wrote:
>     >> Not working.... i was added
>     >>
>     >> adaptation_service_chain request_chain ecapBlockSiteRequest
>     >> ecapSquidTransferAuditRequest
>     >>
>     >> and only?ecapBlockSiteRequest is used.....
> 
> 
>     > This is sounding more and more like the eCAP module is broken.
> 
>     Unless Squid configuration does not _use_ the declared request_chain. I
>     would ask for *all* adaptation-related lines from squid.conf first.
> 
>     A good test is to reorder ecapSquidTransferAuditRequest and
>     ecapBlockSiteRequest in request_chain and see if ecapBlockSiteRequest is
>     still the only adaptation service that is being used. If it is, a
>     different set of adaptation_access lines is needed to enable
>     request_chain usage.
> 
> 
>     > Can you get a cache.log trace of what it is receiving and sending
>     to Squid?
> 
>     HTH,
> 
>     Alex.
> 
> 
>     >> El mi?., 14 nov. 2018 a las 8:54, Amos Jeffries escribi?:
>     >>
>     >>? ? ?On 15/11/18 2:13 AM, Luis Felipe Dominguez Vega wrote:
>     >>? ? ?> by "use all services" i mean, that all the ecap services set as
>     >>? ? ?> reqmod_precache.... see this:
>     >>? ? ?> if i change the order in adaptation_access, then only the first
>     >>? ? ?defined
>     >>? ? ?> is used, the another is not used, so i think that in my
>     >>? ? ?> ecap module i need to put something like.... "continue to next
>     >>? ? ?> adaptation_service"?????
>     >>
>     >>
>     >>? ? ?Did you read the documentation I provided links for earlier?
>     >>
>     >>? ? ?There are multiple ways to group and order services. The services
>     >>? ? ?themselves can even change the order of what follows. The
>     config sample
>     >>? ? ?you mention does not contain anything telling Squid those
>     details.
>     >>
>     >>? ? ?You need to add one of those directives I provided links to -
>     whichever
>     >>? ? ?one meets your required ordering.
>     >>
>     >>? ? ?Amos
>     >>? ? ?_______________________________________________
>     >>? ? ?squid-users mailing list
>     >>? ? ?squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     >>? ? ?<mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>     >>? ? ?http://lists.squid-cache.org/listinfo/squid-users
>     >>
>     > _______________________________________________
>     > squid-users mailing list
>     > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     > http://lists.squid-cache.org/listinfo/squid-users
>     >
> 
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
> 



From mzgmedia at gmail.com  Sat Nov 17 11:58:08 2018
From: mzgmedia at gmail.com (mzgmedia)
Date: Sat, 17 Nov 2018 05:58:08 -0600 (CST)
Subject: [squid-users] limit number of simultaneous connections to a site
Message-ID: <1542455888073-0.post@n4.nabble.com>

Hello

we want to restrict the access to a site to a certain number of simultanious
connections

we have this config

acl badSite dstdom_regex ^(www\.)?SITE\.[\.a-z]{2,5}
acl badSiteCon maxconn 33
http_access deny badSite badSiteCon 


but I don't know if this works 
or 
it will restrict anybody which has at least 33 connections in total to
different sites and now tries to access the bad site



thank you for your time



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Sun Nov 18 05:24:36 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Nov 2018 18:24:36 +1300
Subject: [squid-users] limit number of simultaneous connections to a site
In-Reply-To: <1542455888073-0.post@n4.nabble.com>
References: <1542455888073-0.post@n4.nabble.com>
Message-ID: <0f03ba09-bee7-2fe8-6c6f-7aa6f4e68cf3@treenet.co.nz>

On 18/11/18 12:58 AM, mzgmedia wrote:
> Hello
> 
> we want to restrict the access to a site to a certain number of simultanious
> connections
> 
> we have this config
> 
> acl badSite dstdom_regex ^(www\.)?SITE\.[\.a-z]{2,5}
> acl badSiteCon maxconn 33
> http_access deny badSite badSiteCon 
> 
> 
> but I don't know if this works 
> or 
> it will restrict anybody which has at least 33 connections in total to
> different sites and now tries to access the bad site
> 

The latter. The problem with what you are asking for is that HTTP is a
multiplexed and stateless protocol. Your restriction requires a
statefulness which does not exist.

* Request messages from a client on their connection(s) to Squid may be
for any domain.

 Squid cannot determine what connections will be used for in future.
Only what the current request message is doing, and things like this
client already having N connections total.


* Connections from Squid to a server can (and do) multiplex many
requests from multiple clients for the same domain.

 Use cache_peer to tell Squid that it needs to have certain behaviour on
connections to a particular server. The max-conn=N option of cache_peer
prevents Squid opening more than N connections to that peer. Those N
connections are still shared by all clients requesting from the
domain(s) served by that peer.


Amos


From msyber at gmail.com  Sun Nov 18 11:35:49 2018
From: msyber at gmail.com (msyber)
Date: Sun, 18 Nov 2018 12:35:49 +0100
Subject: [squid-users] Proxy Protocol V2 - Reserved type ranges unsupported
Message-ID: <CALHsEArM9-63hgEeEucnRzVWWqTMTE4SHMRj_NxC4KJ7zg_syQ@mail.gmail.com>

Hi,

I'm working on an AWS implementation to load balance a farm of squid
instances.

AWS supports Proxy Protocol V2 through TCP Network Load Balancer.
Based on tests, NLB support a forked version of PPv2 wherein using "2.2.7
Reserved types ranges" (
https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt) which needs a
custom parser to parse this information.
Even though above doc states that Squid now supports PPv2, it doesn't look
like it can decode the Reserved type ranges.

There is a public Github repo
https://github.com/aws/elastic-load-balancing-tools/tree/master/proprot to
decode this information manually.
Structure of the binary header is there
https://github.com/aws/elastic-load-balancing-tools/tree/master/proprot/tst/com/amazonaws/proprot

Unfortunately it doesn't look like Squid natively supports this
functionality.

Any chance to have it on a next update?

Thank you.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181118/0e96fcd4/attachment.htm>

From gkinkie at gmail.com  Sun Nov 18 14:39:59 2018
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Sun, 18 Nov 2018 14:39:59 +0000
Subject: [squid-users] Proxy Protocol V2 - Reserved type ranges
	unsupported
In-Reply-To: <CALHsEArM9-63hgEeEucnRzVWWqTMTE4SHMRj_NxC4KJ7zg_syQ@mail.gmail.com>
References: <CALHsEArM9-63hgEeEucnRzVWWqTMTE4SHMRj_NxC4KJ7zg_syQ@mail.gmail.com>
Message-ID: <CA+Y8hcMhnzOK8CGz3Pb7btJXzZ0hOMQU5YPgWE0mPLBNE3hVzw@mail.gmail.com>

Can you file a feature request in our bugzilla?
On Sun, Nov 18, 2018 at 11:35 AM msyber <msyber at gmail.com> wrote:
>
> Hi,
>
> I'm working on an AWS implementation to load balance a farm of squid instances.
>
> AWS supports Proxy Protocol V2 through TCP Network Load Balancer.
> Based on tests, NLB support a forked version of PPv2 wherein using "2.2.7 Reserved types ranges" (https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt) which needs a custom parser to parse this information.
> Even though above doc states that Squid now supports PPv2, it doesn't look like it can decode the Reserved type ranges.
>
> There is a public Github repo https://github.com/aws/elastic-load-balancing-tools/tree/master/proprot to decode this information manually.
> Structure of the binary header is there https://github.com/aws/elastic-load-balancing-tools/tree/master/proprot/tst/com/amazonaws/proprot
>
> Unfortunately it doesn't look like Squid natively supports this functionality.
>
> Any chance to have it on a next update?
>
> Thank you.
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco


From msyber at gmail.com  Sun Nov 18 15:14:17 2018
From: msyber at gmail.com (msyber)
Date: Sun, 18 Nov 2018 16:14:17 +0100
Subject: [squid-users] Proxy Protocol V2 - Reserved type ranges
	unsupported
In-Reply-To: <CA+Y8hcMhnzOK8CGz3Pb7btJXzZ0hOMQU5YPgWE0mPLBNE3hVzw@mail.gmail.com>
References: <CALHsEArM9-63hgEeEucnRzVWWqTMTE4SHMRj_NxC4KJ7zg_syQ@mail.gmail.com>
 <CA+Y8hcMhnzOK8CGz3Pb7btJXzZ0hOMQU5YPgWE0mPLBNE3hVzw@mail.gmail.com>
Message-ID: <CALHsEAqZTgia8ZXS9ftRXTdSN3qZpsQ2E19XEpDqe8Q4mtK-hw@mail.gmail.com>

Done.

Le dim. 18 nov. 2018 ? 15:40, Francesco Chemolli <gkinkie at gmail.com> a
?crit :

> Can you file a feature request in our bugzilla?
> On Sun, Nov 18, 2018 at 11:35 AM msyber <msyber at gmail.com> wrote:
> >
> > Hi,
> >
> > I'm working on an AWS implementation to load balance a farm of squid
> instances.
> >
> > AWS supports Proxy Protocol V2 through TCP Network Load Balancer.
> > Based on tests, NLB support a forked version of PPv2 wherein using
> "2.2.7 Reserved types ranges" (
> https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt) which needs
> a custom parser to parse this information.
> > Even though above doc states that Squid now supports PPv2, it doesn't
> look like it can decode the Reserved type ranges.
> >
> > There is a public Github repo
> https://github.com/aws/elastic-load-balancing-tools/tree/master/proprot
> to decode this information manually.
> > Structure of the binary header is there
> https://github.com/aws/elastic-load-balancing-tools/tree/master/proprot/tst/com/amazonaws/proprot
> >
> > Unfortunately it doesn't look like Squid natively supports this
> functionality.
> >
> > Any chance to have it on a next update?
> >
> > Thank you.
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> --
>     Francesco
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181118/562621f8/attachment.htm>

From net66666 at yahoo.com.tw  Mon Nov 19 07:23:04 2018
From: net66666 at yahoo.com.tw (webmaster)
Date: Mon, 19 Nov 2018 01:23:04 -0600 (CST)
Subject: [squid-users] Https Adaptation not working after bumping
In-Reply-To: <CAHgpA+L0xQY=44E_GeQFY+1=F6d=dZfpubSz84QSkqNManZOTw@mail.gmail.com>
References: <CAHgpA+L0xQY=44E_GeQFY+1=F6d=dZfpubSz84QSkqNManZOTw@mail.gmail.com>
Message-ID: <1542612184857-0.post@n4.nabble.com>

port 443 is https,Your PROXY is fast~Good



-----
HTML5 ???? ????
--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Mon Nov 19 17:12:16 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 19 Nov 2018 10:12:16 -0700
Subject: [squid-users] Proxy Protocol V2 - Reserved type ranges
 unsupported
In-Reply-To: <CALHsEAqZTgia8ZXS9ftRXTdSN3qZpsQ2E19XEpDqe8Q4mtK-hw@mail.gmail.com>
References: <CALHsEArM9-63hgEeEucnRzVWWqTMTE4SHMRj_NxC4KJ7zg_syQ@mail.gmail.com>
 <CA+Y8hcMhnzOK8CGz3Pb7btJXzZ0hOMQU5YPgWE0mPLBNE3hVzw@mail.gmail.com>
 <CALHsEAqZTgia8ZXS9ftRXTdSN3qZpsQ2E19XEpDqe8Q4mtK-hw@mail.gmail.com>
Message-ID: <5086046d-b1fc-6dcb-91a0-09b4dfd31624@measurement-factory.com>

On 11/18/18 08:14, msyber wrote:
> Done.

FTR: https://bugs.squid-cache.org/show_bug.cgi?id=4902

Alex.

> Le?dim. 18 nov. 2018 ??15:40, Francesco Chemolli <gkinkie at gmail.com 
> <mailto:gkinkie at gmail.com>> a ?crit?:
> 
>     Can you file a feature request in our bugzilla?
>     On Sun, Nov 18, 2018 at 11:35 AM msyber <msyber at gmail.com
>     <mailto:msyber at gmail.com>> wrote:
>      >
>      > Hi,
>      >
>      > I'm working on an AWS implementation to load balance a farm of
>     squid instances.
>      >
>      > AWS supports Proxy Protocol V2 through TCP Network Load Balancer.
>      > Based on tests, NLB support a forked version of PPv2 wherein
>     using "2.2.7 Reserved types ranges"
>     (https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt) which
>     needs a custom parser to parse this information.
>      > Even though above doc states that Squid now supports PPv2, it
>     doesn't look like it can decode the Reserved type ranges.
>      >
>      > There is a public Github repo
>     https://github.com/aws/elastic-load-balancing-tools/tree/master/proprot
>     to decode this information manually.
>      > Structure of the binary header is there
>     https://github.com/aws/elastic-load-balancing-tools/tree/master/proprot/tst/com/amazonaws/proprot
>      >
>      > Unfortunately it doesn't look like Squid natively supports this
>     functionality.
>      >
>      > Any chance to have it on a next update?
>      >
>      > Thank you.
>      >
>      >
>      >
>      > _______________________________________________
>      > squid-users mailing list
>      > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      > http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> 
>     -- 
>      ? ? Francesco
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 


From zachzla at gmail.com  Mon Nov 19 20:37:39 2018
From: zachzla at gmail.com (igmaniac)
Date: Mon, 19 Nov 2018 14:37:39 -0600 (CST)
Subject: [squid-users] How to configure IPv6
Message-ID: <1542659859841-0.post@n4.nabble.com>

Hi, 

I am trying to create a simple proxy that will receive traffic and forward
it to the server IPv6 address. 
I can actually connect to proxy but when I check my IP on a browser it says
the IPv4 address of the server. 
So far my configuration is like this but I don't know if it's correct: 

hierarchy_stoplist cgi-bin ? 
acl QUERY urlpath_regex cgi-bin \? \.css 
no_cache deny QUERY 
acl NOT_TO_CACHE dstdomain "/etc/squid/list/not-to-cache.conf" 
no_cache deny NOT_TO_CACHE 
acl SSL_ports port 443 
acl Safe_ports port 80	
acl Safe_ports port 21	
acl Safe_ports port 443	
acl Safe_ports port 70	
acl Safe_ports port 210	
acl Safe_ports port 1025-65535	
acl Safe_ports port 280	
acl Safe_ports port 488	
acl Safe_ports port 591	
acl Safe_ports port 777	
acl CONNECT method CONNECT 
http_access deny !Safe_ports 
http_access deny CONNECT !SSL_ports 
http_access allow localhost manager 
http_access deny manager 
http_access allow localhost 
http_access allow all 
http_port 3128 
acl user1 myportname 3128 
acl to_ipv6 dst ipv6 
http_access deny to_ipv6 !all 
tcp_outgoing_address xxx::xxx to_ipv6 
coredump_dir /var/spool/squid 
refresh_pattern ^ftp:	1440	20%	10080 
refresh_pattern ^gopher:	1440	0%	1440 
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0 
refresh_pattern (Release|Packages(.gz)*)$      0       20%     2880 
refresh_pattern .	0	20%	4320 



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Tue Nov 20 00:20:35 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 20 Nov 2018 13:20:35 +1300
Subject: [squid-users] How to configure IPv6
In-Reply-To: <1542659859841-0.post@n4.nabble.com>
References: <1542659859841-0.post@n4.nabble.com>
Message-ID: <f7f92d2c-8cd8-144f-f763-02ea0369d274@treenet.co.nz>

On 20/11/18 9:37 am, igmaniac wrote:
> Hi, 
> 
> I am trying to create a simple proxy that will receive traffic and forward
> it to the server IPv6 address. 

Squid defaults to using IPv6 all connections unless there is something
actively preventing IPv6 from working.

If your network supports IPv6 traffic and the server you are connecting
to has an IPv6 address you do not have to do anything. Just configure
whatever ACLs and access rules you would have about whether a client is
allowed to use your proxy.


> I can actually connect to proxy but when I check my IP on a browser it says
> the IPv4 address of the server. 

What check are you doing exactly? and what exactly is it producing?

The problem is most likely that you are looking at the wrong info or the
test is broken in some other way.

Please be aware that in normal HTTP operations the Browser<->Squid
connection is fully independent of any Squid<->server connections.
Websites which tell you "your IP" (aka whatismyip.com) are often not
telling you Squid's IP they are seeking to tell you the Browser's IP.


> So far my configuration is like this but I don't know if it's correct: 
> 
> hierarchy_stoplist cgi-bin ? 

The above directive was removed in Squid-3.5.


> acl QUERY urlpath_regex cgi-bin \? \.css 
> no_cache deny QUERY 

You can remove the above lines completely. It is a workaround from
Squid-1.x for HTTP/1.0 lack of certain caching features. Squid-3.2 and
later support HTTP/1.1 caching and you already have the relevant
refresh_pattern to handle dynamic content better than the "QUERY"
workaround ever could.


> acl NOT_TO_CACHE dstdomain "/etc/squid/list/not-to-cache.conf" 
> no_cache deny NOT_TO_CACHE

Remove that "no_" prefix. The directive has been called just "cache "
since Squid-2 era.


Or, if you have Squid-3.5 or later consider using the store_miss
directive instead of "cache".


> acl SSL_ports port 443 
> acl Safe_ports port 80	
> acl Safe_ports port 21	
> acl Safe_ports port 443	
> acl Safe_ports port 70	
> acl Safe_ports port 210	
> acl Safe_ports port 1025-65535	
> acl Safe_ports port 280	
> acl Safe_ports port 488	
> acl Safe_ports port 591	
> acl Safe_ports port 777	
> acl CONNECT method CONNECT 
> http_access deny !Safe_ports 
> http_access deny CONNECT !SSL_ports 
> http_access allow localhost manager 
> http_access deny manager 
> http_access allow localhost 
> http_access allow all

Do not do that. "allow all" makes your proxy an "Open Proxy" which is a
very bad idea.

Especially when testing since it artificially makes things that are
quite abnormal "work". As evidenced by your very mangled http_access
rules later on (which are ignored since everything was already allowed
by this).


> http_port 3128 
> acl user1 myportname 3128 

The "user1" ACL is never used. You can remove the above line.


> acl to_ipv6 dst ipv6 
> http_access deny to_ipv6 !all

The "allow all" above already allowed *everything* through your Squid.
So this line is never even evaluated and its use as a trick to get Squid
to perform DNS far earlier than normal is not happening.

>From the context of your question and intended behaviour I suspect that
you were not actually wanting to do the behaviour this config trick is
designed to cause. Specifically to force Squid to perform DNS lookups
far earlier than it would normally do them - for a very minor
performance enhancement when DNS server are expected to be very slow.

That behaviour will not help with your stated intentions. So I suggest
removing this http_access line as well.


> tcp_outgoing_address xxx::xxx to_ipv6

In current Squids where it works properly this directive selects the IP
based first on which IP type the server has. You can only set IPv6
address on connections to IPv6 servers, and only set IPv4 address on
connections to IPv4 servers. Squid-3.4+ will ignore lines attempting to
set the wrong IP type.

In other words the "to_ipv6" is implicit in how this directive currently
does things and no longer needed. If you have to use the above line to
set a custom IPv6 for outgoing traffic you should use the "all" ACL here
instead.
 Or better yet, remove that line entirely. The OS networking stack will
assign an appropriate IP address for the connection.



... if you do all those changes you should notice you are pretty much
back to Squid's default config file.

Amos


From zachzla at gmail.com  Tue Nov 20 08:16:43 2018
From: zachzla at gmail.com (igmaniac)
Date: Tue, 20 Nov 2018 02:16:43 -0600 (CST)
Subject: [squid-users] How to configure IPv6
In-Reply-To: <f7f92d2c-8cd8-144f-f763-02ea0369d274@treenet.co.nz>
References: <f7f92d2c-8cd8-144f-f763-02ea0369d274@treenet.co.nz>
Message-ID: <1542701803277-0.post@n4.nabble.com>

Thank you for your reply.
I deleted my post because there was not even an issue.
I was trying to access to access websites which do not support IPv6.

Your post is very useful and I will add it to my documentation.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From heiler.bemerguy at cinbesa.com.br  Tue Nov 20 16:36:47 2018
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 20 Nov 2018 13:36:47 -0300
Subject: [squid-users] 4.4 after -k rotate
Message-ID: <8e555f5a-2042-5223-d543-3215fd4523cc@cinbesa.com.br>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181120/ecfcc8da/attachment.htm>

From squid3 at treenet.co.nz  Wed Nov 21 12:55:24 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 22 Nov 2018 01:55:24 +1300
Subject: [squid-users] 4.4 after -k rotate
In-Reply-To: <8e555f5a-2042-5223-d543-3215fd4523cc@cinbesa.com.br>
References: <8e555f5a-2042-5223-d543-3215fd4523cc@cinbesa.com.br>
Message-ID: <371db8c1-730d-cd77-fcb6-ac1e7983416c@treenet.co.nz>

On 21/11/18 5:36 am, Heiler Bemerguy wrote:
> We have a "/usr/sbin/squid -k rotate" on logrotate.d and everyday it
> seems to give this "assetion failed" right after it..
> 
> And this seems to make squid completely unstable because this kid6 is a
> disker... (SMP - 5 workers, 3 diskers...)
> 
> 2018/11/20 00:25:11 kid6| storeDirWriteCleanLogs: Starting...
> 2018/11/20 00:25:11 kid6|?? Finished.? Wrote 0 entries.
> 2018/11/20 00:25:11 kid6|?? Took 0.00 seconds (? 0.00 entries/sec).
> 2018/11/20 00:25:11 kid6| logfileRotate: daemon:/var/log/squid/access.log
> 2018/11/20 00:25:11 kid6| logfileRotate: daemon:/var/log/squid/access.log
> *2018/11/20 00:25:17 kid6| assertion failed: comm.cc:1918:
> "!isOpen(new_socket)"*
> 


Please report this to our bugzilla. This looks very similar to
<https://bugs.squid-cache.org/show_bug.cgi?id=4796> but is definitely a
different bug.

If you can replicate the problem on a proxy not actually handling
traffic please supply a cache.log produced with debug_options ALL,9.

Otherwise if ALL,8 is too large please supply a cache log made with
ALL,6 - or at minimum "ALL,2 5,5 50,5 51,5 92,5". We need to know what
FD number is being allocated with the socket and everything Squid has
previously been doing with that FD number.

Amos


From pacolopezvelasco at gmail.com  Thu Nov 22 12:52:48 2018
From: pacolopezvelasco at gmail.com (pacolo)
Date: Thu, 22 Nov 2018 06:52:48 -0600 (CST)
Subject: [squid-users] Performance issue /cache_dir / cache_mem / SMP
	workers
In-Reply-To: <b2449f05-cb00-d598-f752-dcabddb11c82@measurement-factory.com>
References: <1541691984135-0.post@n4.nabble.com>
 <b2449f05-cb00-d598-f752-dcabddb11c82@measurement-factory.com>
Message-ID: <1542891168393-0.post@n4.nabble.com>

Hello people,

@Alex, thanks for your help, we took your advise and change the deployment
to SMP, some issues were solved, but others appeared :-(.

The config files are attached, in case anybody could help or to help others
with our same issues, as we have been searching several days and we didn't
found any solution or a recent configuration guide.

df_-hT.txt
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/df_-hT.txt>  
LVM_info.txt
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/LVM_info.txt>  
fdisk_-l.txt
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/fdisk_-l.txt>  
fstab.fstab
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/fstab.fstab>  
dev_shm_permissions.txt
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/dev_shm_permissions.txt>  
cat_proc_cpuinfo.txt
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/cat_proc_cpuinfo.txt>  
systecl_-a.log
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/systecl_-a.log>  
99-sysctl.conf
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/99-sysctl.conf>  
squid.conf
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/squid.conf>  
frontend.conf
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/frontend.conf>  
backend.conf
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/backend.conf>  


1. VMWare - Hardware changes
	Changed the CPU's servers from 2 CPU with 2 sockets (2*2) to 5 CPU with 1
socket each (5*1). 
	Changed from 8 GB to 32 GB RAM
	LVM with an OS disk of 30 GB, and changed the 8TB to several disks of 2 TB,
as suggested, fewer smaller disks better than a big disk.


2. Server - LVM config disks
	Attached are the LVM info, df -hT, fstab, fdisk -l.
	4 disks of 2 TB. 
	Changed the file system from initial xfs to ext4.
	We checked the Reiserfs suggestion, we tried to change it, but found
several problems (discontinuity, system not compatible), so we decided to
remain in ext4.
	Mounted ext4 with noatime.

	
3. Server - CPU affinity
	Attached is cat /proc/cpuinfo
	I suppose the processor id in /proc/cpuinfo is the id that should be
referenced in the cpu_affinity_map, isn't it?

	cpu_affinity_map process_numbers=1,2,3,4 cores=1,2,3,4

	
4. systctl
	Taking into account several posts founded, we changed some settings in the
sysctl to improve the server's performance.

	
	Something very important are the file descriptors, though we configured
this parameter in the squid.conf.
	This actually solve the main problem, as we checked they were being quickly
exhausted.
	
	There are several parameters related to the memory, but we found some
discrepancies in the examples, so we haven't changed them.


5. shm
	Attached dev_shm permissions. 
	
	We checked the following error in the /var/log/messages at the squid
start...
		Ipc::Mem::Segment::open failed to shm_open(/squid-cache4_spaces.shm): (2)
No such file or directory	
	
	So we add the following line to the /etc/fstab file:
		shm        /dev/shm    tmpfs    nodev,nosuid,noexec    0    0

	The errors continued, so we created the files (squid-cache2_spaces.shm,
etc) that appear to be missing, and the errors changed to...
		FATAL: Ipc::Mem::Segment::attach failed to mmap(/squid-cache4_spaces.shm):
(22) Invalid argument

	Regarding this error, we have disabled the SELinux, as suggested in some
post, but the errors continued appearing.


6. Squid configuration
	Attached the squid.conf, frontend.conf and backend.conf.
	We configured them as the Wiki example, although it appears that this
example is too much old, furthermore it is suggesting to use aufs, when it
is not SMP aware.
	Then we changed several things as suggested in several posts of the Nabble
forum.
	
	We found several posts where issues are reported and Alex suggest to
update, so we updated Squid from 3.5.28 to 4.1, but the errors continued.
	We don't know whether it is coincidence, but almost everybody that is
reporting these issues have our same OS, CentOS.
	Our system is CentOS Linux release 7.5.1804 (Core).


Furthermore, we have attached the log files, in case it helps.

var_log_messages.txt
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/var_log_messages.txt>  
frontend.log
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/frontend.log>  
backend0.log
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/backend0.log>  
backend2.log
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/backend2.log>  
backend3.log
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/backend3.log>  
backend4.log
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/backend4.log>  
backend5.log
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/backend5.log>  
backend6.log
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/backend6.log>  

In summary, we don't know how to continue the troubleshooting, please help.

Thanks in advance and sorry for the brick.
Best regards,
Paco.
	
References:
https://wiki.squid-cache.org/Features/SmpScale
https://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster
https://wiki.squid-cache.org/Features/RockStore
https://wiki.squid-cache.org/BestOsForSquid
http://vietlux.blogspot.com/2012/07/squid-proxy-tuning-for-high-perfomance.html
https://wwwx.cs.unc.edu/~sparkst/howto/network_tuning.php
http://squid-web-proxy-cache.1019090.n4.nabble.com/FATAL-Ipc-Mem-Segment-create-failed-to-shm-open-squid-cf-queues-shm-17-File-exists-td4680157.html
http://squid-web-proxy-cache.1019090.n4.nabble.com/FATAL-shm-open-squid-ssl-session-cache-shm-td4683398.html




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From pacolopezvelasco at gmail.com  Fri Nov 23 14:21:22 2018
From: pacolopezvelasco at gmail.com (pacolo)
Date: Fri, 23 Nov 2018 08:21:22 -0600 (CST)
Subject: [squid-users] Performance issue /cache_dir / cache_mem / SMP
	workers
In-Reply-To: <1542891168393-0.post@n4.nabble.com>
References: <1541691984135-0.post@n4.nabble.com>
 <b2449f05-cb00-d598-f752-dcabddb11c82@measurement-factory.com>
 <1542891168393-0.post@n4.nabble.com>
Message-ID: <1542982882368-0.post@n4.nabble.com>

Hello again,

We have found an issue in backend.conf, as the Rock cache_dir is SMP aware.

Change this...
#cache_dir rock /cache${process_number} 2097152
to this...
cache_dir rock /cache1 2097152


... then the new errors are:
Nov 23 14:55:28 px06 squid[12559]: ERROR: /cache1/rock communication channel
establishment timeout
Nov 23 14:55:28 px06 squid[12559]: FATAL: Rock cache_dir at /cache1/rock
failed to open db file: (0) No error.

We have search for in the forum
(http://squid-web-proxy-cache.1019090.n4.nabble.com/RockStore-quot-Fatal-Error-quot-td4666691.html),
and tried what other people suggested without success.


/cache1
drwxr-xr-x 2 squid squid 16384 nov 21 13:05 lost+found
drwxr-xr-x 2 squid squid  4096 nov 23 12:38 rock

The permissions in /dev/shm are correct, too. Squid is writing some files.
ls_-l_dev_shm.txt
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/ls_-l_dev_shm.txt>  

In addition, it appears that Squid can write in the localstatedir...

--localstatedir=/var'
squid_-v.txt
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/squid_-v.txt>  

/var/run/squid
srwxr-x--- 1 squid squid 0 nov 23 14:55 squid-coordinator.ipc
srwxr-x--- 1 squid squid 0 nov 23 14:55 squid-kid-1.ipc
srwxr-x--- 1 squid squid 0 nov 23 14:55 squid-kid-2.ipc
srwxr-x--- 1 squid squid 0 nov 23 14:55 squid-kid-3.ipc
srwxr-x--- 1 squid squid 0 nov 23 13:00 squid-kid-4.ipc
srwxr-x--- 1 squid squid 0 nov 23 13:00 squid-kid-5.ipc


SELinux status:                 disabled

var_log_messages.txt
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/var_log_messages.txt>  

Any idea?

Best regards,
Paco.




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From heiler.bemerguy at cinbesa.com.br  Fri Nov 23 17:02:10 2018
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Fri, 23 Nov 2018 14:02:10 -0300
Subject: [squid-users] 3.5.28 partial content getting HIT but not sending
Message-ID: <30b85e02-4220-189a-e755-38f46f24e6c5@cinbesa.com.br>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181123/6fa41c3e/attachment.htm>

From heiler.bemerguy at cinbesa.com.br  Fri Nov 23 17:28:32 2018
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Fri, 23 Nov 2018 14:28:32 -0300
Subject: [squid-users] 3.5.28 partial content getting HIT but not sending
In-Reply-To: <30b85e02-4220-189a-e755-38f46f24e6c5@cinbesa.com.br>
References: <30b85e02-4220-189a-e755-38f46f24e6c5@cinbesa.com.br>
Message-ID: <ae365ec4-bb75-d884-e765-408b922f236c@cinbesa.com.br>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181123/73c20e2c/attachment.htm>

From squid3 at treenet.co.nz  Sat Nov 24 06:33:08 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 24 Nov 2018 19:33:08 +1300
Subject: [squid-users] 3.5.28 partial content getting HIT but not sending
In-Reply-To: <ae365ec4-bb75-d884-e765-408b922f236c@cinbesa.com.br>
References: <30b85e02-4220-189a-e755-38f46f24e6c5@cinbesa.com.br>
 <ae365ec4-bb75-d884-e765-408b922f236c@cinbesa.com.br>
Message-ID: <69ff84e0-9dac-c536-a928-431f5a181d5c@treenet.co.nz>

On 24/11/18 6:28 am, Heiler Bemerguy wrote:
> Hum, disabling that refresh_pattern and -k reconfigure seems to have
> fixed it.. but.. why?
> 

Something else is going on which is not visible in the details you have
shown.

 - is the TCP connection containing a message pipeline?
 if so the data and FIN may be related to a previous response message in
that pipeline.

 - are other refresh patterns being used (probably yes) ?
  - what are they? (before and after the change)

 - what did your cache.log have to say at the time of the connection
termination? (may need debug level 2 or 5 enabled)


Also, you were using override-* and ignore-* settings in that
refresh_pattern that are not necessary for the Debian/Ubuntu servers.

 At best they will be doing nothing to these responses (ie
ignore-no-store, ignore-private do nothing to Debian/Ubuntu responses).

 Some will be causing *worse* caching service from the proxy.
override-lastmod with your small [84 day] expiry vastly reduces the
_years_ these objects can actually be cached for, and prevents IMS
revalidation being used to determine changes properly and store
un-changed things longer. NP: Debian/Ubuntu official repositories do
fully support IMS revalidation.


Amos


From squid3 at treenet.co.nz  Sat Nov 24 07:10:37 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 24 Nov 2018 20:10:37 +1300
Subject: [squid-users] Performance issue /cache_dir / cache_mem / SMP
 workers
In-Reply-To: <1542982882368-0.post@n4.nabble.com>
References: <1541691984135-0.post@n4.nabble.com>
 <b2449f05-cb00-d598-f752-dcabddb11c82@measurement-factory.com>
 <1542891168393-0.post@n4.nabble.com> <1542982882368-0.post@n4.nabble.com>
Message-ID: <ef100110-3528-b0dd-7a49-8efce15a979b@treenet.co.nz>

On 24/11/18 3:21 am, pacolo wrote:
> Hello again,
> 
> We have found an issue in backend.conf, as the Rock cache_dir is SMP aware.
> 
> Change this...
> #cache_dir rock /cache${process_number} 2097152
> to this...
> cache_dir rock /cache1 2097152
> 
> 
> ... then the new errors are:
> Nov 23 14:55:28 px06 squid[12559]: ERROR: /cache1/rock communication channel
> establishment timeout
> Nov 23 14:55:28 px06 squid[12559]: FATAL: Rock cache_dir at /cache1/rock
> failed to open db file: (0) No error.
> 
> We have search for in the forum
> (http://squid-web-proxy-cache.1019090.n4.nabble.com/RockStore-quot-Fatal-Error-quot-td4666691.html),
> and tried what other people suggested without success.
> 

If you have a mix of "/cache${process_number}" and "/cache1" in your
config files you may still be mixing SMP-aware and SMP-disabled access
to the "/cache1" path.

By your mention of "backend.conf" I assume you are trying to use
something based on our example SMP CARP cluster configuration.
 If that is correct please compare what you have to the current example
config <https://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster>.

It has had a few changes since initially written, and people
copy-pasting it into tutorials without linking back to our info have got
various bugs in their texts. Sometimes because they copied old versions
that no longer work, or because they made arbitrary changes without
properly understanding the consequences.


> 
> /cache1
> drwxr-xr-x 2 squid squid 16384 nov 21 13:05 lost+found
> drwxr-xr-x 2 squid squid  4096 nov 23 12:38 rock
> 
> The permissions in /dev/shm are correct, too. Squid is writing some files.
> ls_-l_dev_shm.txt
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/ls_-l_dev_shm.txt>  
> 
> In addition, it appears that Squid can write in the localstatedir...
> 
> --localstatedir=/var'
> squid_-v.txt
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/squid_-v.txt>  
> 
> /var/run/squid
> srwxr-x--- 1 squid squid 0 nov 23 14:55 squid-coordinator.ipc
> srwxr-x--- 1 squid squid 0 nov 23 14:55 squid-kid-1.ipc
> srwxr-x--- 1 squid squid 0 nov 23 14:55 squid-kid-2.ipc
> srwxr-x--- 1 squid squid 0 nov 23 14:55 squid-kid-3.ipc
> srwxr-x--- 1 squid squid 0 nov 23 13:00 squid-kid-4.ipc
> srwxr-x--- 1 squid squid 0 nov 23 13:00 squid-kid-5.ipc
> 
> 
> SELinux status:                 disabled
> 
> var_log_messages.txt
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377599/var_log_messages.txt>  
> 

The log you provide has a mixture of multiple process outputs. But
appears to be lacking the "kidN" information Squid attaches to every log
line indicating which ${process_number} is writing to the log.

That makes it very hard to determine the source of SMP issues from a log
like this. Luckily you did provide the whole log and Squid-4 logs this
detail at the startup:

 (squid-coord-4) process 12557 started
 (squid-disk-3) process 12558 started
 (squid-2) process 12559 started
 (squid-1) process 12560 started

The Disker cannot open the configure cache_dir rock:

 Nov 23 14:55:21 px06 squid[12558]: ERROR: cannot open /cache1/rock:
(21) Is a directory

The SMP worker did not receiver any registration response from the
Disker, the cache_dir access fails. Worker aborts and enters into a loop
of constantly dying due to unresponsive Disker.

 Nov 23 14:55:28 px06 squid[12559]: ERROR: /cache1/rock communication
channel establishment timeout
 Nov 23 14:55:28 px06 squid[12559]: Not currently OK to rewrite swap log.
 Nov 23 14:55:28 px06 squid[12559]: storeDirWriteCleanLogs: Operation
aborted.
 Nov 23 14:55:28 px06 squid[12559]: FATAL: Rock cache_dir at
/cache1/rock failed to open db file: (0) No error.


So the fix is to:

1) stop Squid.

2) make sure it is fully shutdown with no residual instances or
processes running.

3) make sure the SMP /dev/shm sockets opened by Squid are fully gone.
Delete manually if necessary.

4) make sure the PID file is fully gone. Delete manually if necessary.

5) erase everything in the /cache1 directory.

5a) optionally: erase any other caches you may have.
  This will speed up the -z process, but only the cache showing errors
actually needs to be fully clean to fix this error message.

6) run "squid -z" manually and wait until it completes.

7) start Squid.


Amos


From heiler.bemerguy at cinbesa.com.br  Sat Nov 24 16:24:58 2018
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Sat, 24 Nov 2018 13:24:58 -0300
Subject: [squid-users] 3.5.28 partial content getting HIT but not sending
In-Reply-To: <69ff84e0-9dac-c536-a928-431f5a181d5c@treenet.co.nz>
References: <30b85e02-4220-189a-e755-38f46f24e6c5@cinbesa.com.br>
 <ae365ec4-bb75-d884-e765-408b922f236c@cinbesa.com.br>
 <69ff84e0-9dac-c536-a928-431f5a181d5c@treenet.co.nz>
Message-ID: <dc24f0c6-39ca-6f91-4ef3-30cc367528a9@cinbesa.com.br>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181124/5f9025e3/attachment.htm>

From squid3 at treenet.co.nz  Sun Nov 25 10:12:43 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 25 Nov 2018 23:12:43 +1300
Subject: [squid-users] 3.5.28 partial content getting HIT but not sending
In-Reply-To: <dc24f0c6-39ca-6f91-4ef3-30cc367528a9@cinbesa.com.br>
References: <30b85e02-4220-189a-e755-38f46f24e6c5@cinbesa.com.br>
 <ae365ec4-bb75-d884-e765-408b922f236c@cinbesa.com.br>
 <69ff84e0-9dac-c536-a928-431f5a181d5c@treenet.co.nz>
 <dc24f0c6-39ca-6f91-4ef3-30cc367528a9@cinbesa.com.br>
Message-ID: <42497e5d-021c-fd4b-82bc-ec6fac3676b8@treenet.co.nz>

On 25/11/18 5:24 am, Heiler Bemerguy wrote:
> No doubt, the connections were really being closed by the proxy itself,
> LIKE it was finished sending the request. It was like a loop, so it was
> infinite connections one right after another, but not in parallel.. the
> fin-packets and everything else were "in order" judgjing by their SEQ
> values too.
> 
> There were other refresh_patterns but none matching it. I didn't enable
> debug options but I can try to reproduce it.. anyway the .conf was like
> that for years and this was the first time a "loop" like this occurred.
> I upgraded from 3.5.27 to 3.5.28 but I think nothing about this was
> modified recently, right..?
> 

3.5.28 is now treating the Content-Range header better - ignoring it in
server responses where it is not valid. Older versions were truncating
responses. Wild guess but I suspect the object stored in cache
previously may have been one of those incorrectly truncated ones or
something like that.

Amos


From marcus.kool at urlfilterdb.com  Tue Nov 27 12:21:20 2018
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 27 Nov 2018 10:21:20 -0200
Subject: [squid-users] access_log acls
Message-ID: <afa7ed0a-9fdd-88e7-08a4-6622d70d42e6@urlfilterdb.com>

I have an issue with access_log acls when a load balancer sends a TCP probe.

The goal is to not log errors caused by the TCP probes of the load balancer.? All other errors must be logged.

I did a test with the following acls on one of our test systems to illustrate the issue:

logformat combha %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %Ss:%Sh %>ha
acl src_lb src 10.2.2.254/32
acl src_lb src 10.2.2.107/32
access_log stdio:/local/squid4/logs/*lb*access.log combha src_lb
access_log stdio:/local/squid4/logs/access.log?? combha !src_lb


The logging is almost as expected: all HTTP(S) traffic from 10.2.2.107 goes to lbaccess.log and all other traffic to access.log,
*but* imitating the TCP probe of the LB with a telnet session from 10.2.2.107 to the squid server which is immediately terminated or sends garbage, is logged with transaction-end-before-headers to 
access.log, not lbaccess.log.

It seems that Squid, at the moment that it logs the transaction-end-before-headers error, does not consider the access_log acls or maybe has not yet processed the source IP to make the right decision.

Should the above acls send the errors to lbaccess.log ?? If not, what set of acls can do it?

Thanks,

Marcus




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181127/045d57e8/attachment.htm>

From jmperrote at policia.rionegro.gov.ar  Tue Nov 27 13:13:06 2018
From: jmperrote at policia.rionegro.gov.ar (jmperrote)
Date: Tue, 27 Nov 2018 10:13:06 -0300
Subject: [squid-users] need help with cachemgr
Message-ID: <98859f42-88df-7566-74f2-2845abf6272c@policia.rionegro.gov.ar>

Hello need help with cachemgr, I using a squid as a reverse proxy mode, 
when I try to connect to retrive data using squidclient, connecting to 
cachemrg, only retrive squid OK, but the other values HIT, http request, 
etc,? that ara usually retrived are not retrived.

My case when I to try connect:

                    squidclient -vv cache_object://localhost/ mgr:info
                    -p 1084

                    verbosity level set to 2
                    Request:
                    GET 1084 HTTP/1.0
                    User-Agent: squidclient/3.5.12
                    Accept: */*
                    Connection: close


                    .
                    Transport detected: IPv4-only
                    Resolving localhost ...
                    Connecting... localhost (127.0.0.1:1084)
                    Connected to: localhost (127.0.0.1:1084)
                    Sending HTTP request ...
                    done.

                    verbosity level set to 2
                    Request:
                    GET 1084 HTTP/1.0
                    User-Agent: squidclient/3.5.12
                    Accept: */*
                    Connection: close


                    .
                    Transport detected: IPv4-only
                    Resolving localhost ...
                    Connecting... localhost (127.0.0.1:1084)
                    Connected to: localhost (127.0.0.1:1084)
                    Sending HTTP request ...
                    done.


Allways finish on --> "done" and not continue, do nothing


The test that are trying is local not remote.


regards.

Juan Manuel.


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181127/c358fe0f/attachment.htm>

From rousskov at measurement-factory.com  Tue Nov 27 15:58:49 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 27 Nov 2018 08:58:49 -0700
Subject: [squid-users] access_log acls
In-Reply-To: <afa7ed0a-9fdd-88e7-08a4-6622d70d42e6@urlfilterdb.com>
References: <afa7ed0a-9fdd-88e7-08a4-6622d70d42e6@urlfilterdb.com>
Message-ID: <6e715c8e-8183-00fa-7baa-2ed329838e27@measurement-factory.com>

On 11/27/18 5:21 AM, Marcus Kool wrote:

> logformat combha %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %Ss:%Sh %>ha
> acl src_lb src 10.2.2.254/32
> acl src_lb src 10.2.2.107/32
> access_log stdio:/local/squid4/logs/lbaccess.log combha src_lb
> access_log stdio:/local/squid4/logs/access.log?? combha !src_lb

> The logging is almost as expected: all HTTP(S) traffic from 10.2.2.107
> goes to lbaccess.log and all other traffic to access.log,
> *but* imitating the TCP probe of the LB with a telnet session from
> 10.2.2.107 to the squid server which is immediately terminated or sends
> garbage, is logged with transaction-end-before-headers to access.log,
> not lbaccess.log.

> Should the above acls send the errors to lbaccess.log?

Yes, src ACLs should work for all transactions associated with to-Squid
connections, including transaction-end-before-headers errors. If they do
not work, it is a Squid bug.

Alex.


From rousskov at measurement-factory.com  Tue Nov 27 16:03:44 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 27 Nov 2018 09:03:44 -0700
Subject: [squid-users] need help with cachemgr
In-Reply-To: <98859f42-88df-7566-74f2-2845abf6272c@policia.rionegro.gov.ar>
References: <98859f42-88df-7566-74f2-2845abf6272c@policia.rionegro.gov.ar>
Message-ID: <1a666c31-f6b3-8d42-a171-4d88cbfa9ee5@measurement-factory.com>

On 11/27/18 6:13 AM, jmperrote wrote:
> Hello need help with cachemgr, I using a squid as a reverse proxy mode,
> when I try to connect to retrive data using squidclient, connecting to
> cachemrg, only retrive squid OK, but the other values HIT, http request,
> etc,? that ara usually retrived are not retrived.
> 
> My case when I to try connect:
> 
>                     squidclient -vv cache_object://localhost/ mgr:info
>                     -p 1084

Place all named options before the anonymous ones and
use one (pseudo) URL at a time:

  squidclient -vv -p 1084 cache_object://localhost/
  squidclient -vv -p 1084 mgr:info

Alex.


From pcmccollum at gmail.com  Tue Nov 27 16:33:52 2018
From: pcmccollum at gmail.com (Phillip McCollum)
Date: Tue, 27 Nov 2018 08:33:52 -0800
Subject: [squid-users] Parent proxy chaining
Message-ID: <CACuTHxFub6pmxvLGWbAifq3jdqxHQVvJHQsHkB+fbckw+sqY6Q@mail.gmail.com>

Hi folks,

First off, I'll make the requisite disclaimer that I'm a squid newbie. I've
been banging my head against this problem for nearly a week--trial and
error, google searches, FAQ reviews, etc. Like Obi-Wan Kenobi, you guys are
my last resort! :)

I have a deployment in AWS in where a VPC has a transparent proxy deployed,
which forwards 80/443 requests to a parent proxy in another VPC, which I
then need to forward to another parent proxy (SaaS provider).

Essentially:
[[Client PC]] --> [[Squid Proxy (10.52.0.20)]] --> [[Parent Squid Proxy
(10.52.0.168)]] --> [[Parent SaaS Proxy]]

This is being done to centralize proxy functions and limit the number of
public IPs that the parent SaaS needs to whitelist.

I'm getting "Access Denied" messages and a review of Squid Parent proxy
access.log shows the following common errors:

HTTP:
2018/11/27 16:22:54 kid1| WARNING: Forwarding loop detected for:
GET / HTTP/1.1
Accept: text/html, application/xhtml+xml, image/jxr, */*
Accept-Language: en-US
User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like
Gecko
Accept-Encoding: gzip, deflate
Cookie: B=8nra62ldvb83a&b=3&s=ik
Via: 1.1 squid (squid/3.5.27)
X-Forwarded-For: 10.184.0.26
Cache-Control: max-age=259200
Connection: keep-alive
Host: www.yahoo.com

HTTPS:
2018/11/27 16:21:51 kid1| SECURITY ALERT: Host header forgery detected on
local=10.52.0.168:8443 remote=10.52.0.20:45520 FD 15 flags=33 (intercepted
port does not match 443)
2018/11/27 16:21:51 kid1| SECURITY ALERT: on URL: 13.82.28.61:443

Here are the various squid.conf files and iptables configurations:

[[Transparent Proxy]]:
visible_hostname squid
http_port 3129 intercept
https_port 3130 cert=/etc/squid/ssl/squid.pem ssl-bump intercept
acl HTTP_PORT port 80
acl HTTPS_PORT port 443
http_access allow all
ssl_bump splice
dns_v4_first on
#cache_peer proxy.threatpulse.net parent 8080 0 name=symantec_http no-query
proxy-only default
cache_peer 10.52.0.168 parent 8443 0 name=symantec_http no-query proxy-only
default
cache_peer_access symantec_http allow HTTP_PORT
cache_peer_access symantec_http allow HTTPS_PORT
never_direct allow all

Chain PREROUTING (policy ACCEPT 32 packets, 1704 bytes)
 pkts bytes target     prot opt in     out     source
 destination
   30  1560 REDIRECT   tcp  --  *      *       0.0.0.0/0
0.0.0.0/0            tcp dpt:80 redir ports 3129
   89  4628 REDIRECT   tcp  --  *      *       0.0.0.0/0
0.0.0.0/0            tcp dpt:443 redir ports 3130

Chain INPUT (policy ACCEPT 131 packets, 6852 bytes)
 pkts bytes target     prot opt in     out     source
 destination

Chain OUTPUT (policy ACCEPT 660 packets, 58073 bytes)
 pkts bytes target     prot opt in     out     source
 destination

Chain POSTROUTING (policy ACCEPT 680 packets, 59113 bytes)
 pkts bytes target     prot opt in     out     source
 destination

[[Squid Parent Proxy]]:
visible_hostname squid
http_port 3129 intercept
https_port 3130 cert=/etc/squid/ssl/squid.pem ssl-bump intercept
http_port 3031 cert=/etc/squid/ssl/squid.pem ssl-bump intercept
acl HTTP_PORT port 80
acl HTTPS_PORT port 443
acl FORWARD_PORT port 8443
http_access allow all
ssl_bump splice
cache_peer proxy.threatpulse.net parent 8080 0 name=symantec_http no-query
proxy-only default
cache_peer_access symantec_http allow HTTP_PORT
cache_peer_access symantec_http allow HTTPS_PORT
cache_peer_access symantec_http allow FORWARD_PORT
never_direct allow all

Chain PREROUTING (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source
 destination
    0     0 REDIRECT   tcp  --  *      *       0.0.0.0/0
0.0.0.0/0            tcp dpt:80 redir ports 3129
    0     0 REDIRECT   tcp  --  *      *       0.0.0.0/0
0.0.0.0/0            tcp dpt:443 redir ports 3130
   35  2100 REDIRECT   tcp  --  *      *       0.0.0.0/0
0.0.0.0/0            tcp dpt:8443 redir ports 3031

Chain INPUT (policy ACCEPT 35 packets, 2100 bytes)
 pkts bytes target     prot opt in     out     source
 destination

Chain OUTPUT (policy ACCEPT 2 packets, 121 bytes)
 pkts bytes target     prot opt in     out     source
 destination

Chain POSTROUTING (policy ACCEPT 2 packets, 121 bytes)
 pkts bytes target     prot opt in     out     source
 destination

---

Any thoughts or suggestions are greatly appreciated. Thanks for your time!

-Phillip
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181127/b40b5fd1/attachment.htm>

From marcus.kool at urlfilterdb.com  Tue Nov 27 16:42:51 2018
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 27 Nov 2018 14:42:51 -0200
Subject: [squid-users] access_log acls
In-Reply-To: <6e715c8e-8183-00fa-7baa-2ed329838e27@measurement-factory.com>
References: <afa7ed0a-9fdd-88e7-08a4-6622d70d42e6@urlfilterdb.com>
 <6e715c8e-8183-00fa-7baa-2ed329838e27@measurement-factory.com>
Message-ID: <0494171b-6917-50eb-8a53-33c2dcb20bda@urlfilterdb.com>


On 27/11/2018 13:58, Alex Rousskov wrote:
> On 11/27/18 5:21 AM, Marcus Kool wrote:
>
>> logformat combha %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %Ss:%Sh %>ha
>> acl src_lb src 10.2.2.254/32
>> acl src_lb src 10.2.2.107/32
>> access_log stdio:/local/squid4/logs/lbaccess.log combha src_lb
>> access_log stdio:/local/squid4/logs/access.log?? combha !src_lb
>> The logging is almost as expected: all HTTP(S) traffic from 10.2.2.107
>> goes to lbaccess.log and all other traffic to access.log,
>> *but* imitating the TCP probe of the LB with a telnet session from
>> 10.2.2.107 to the squid server which is immediately terminated or sends
>> garbage, is logged with transaction-end-before-headers to access.log,
>> not lbaccess.log.
>> Should the above acls send the errors to lbaccess.log?
> Yes, src ACLs should work for all transactions associated with to-Squid
> connections, including transaction-end-before-headers errors. If they do
> not work, it is a Squid bug.
>
> Alex.

Thanks, I filed bug 4906: https://bugs.squid-cache.org/show_bug.cgi?id=4906

Is it serious enough to get a fix in Squid 4?

Marcus




From uhlar at fantomas.sk  Tue Nov 27 16:44:54 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 27 Nov 2018 17:44:54 +0100
Subject: [squid-users] Parent proxy chaining
In-Reply-To: <CACuTHxFub6pmxvLGWbAifq3jdqxHQVvJHQsHkB+fbckw+sqY6Q@mail.gmail.com>
References: <CACuTHxFub6pmxvLGWbAifq3jdqxHQVvJHQsHkB+fbckw+sqY6Q@mail.gmail.com>
Message-ID: <20181127164454.GA20312@fantomas.sk>

On 27.11.18 08:33, Phillip McCollum wrote:
>I have a deployment in AWS in where a VPC has a transparent proxy deployed,
>which forwards 80/443 requests to a parent proxy in another VPC, which I
>then need to forward to another parent proxy (SaaS provider).
>
>Essentially:
>[[Client PC]] --> [[Squid Proxy (10.52.0.20)]] --> [[Parent Squid Proxy
>(10.52.0.168)]] --> [[Parent SaaS Proxy]]
>
>This is being done to centralize proxy functions and limit the number of
>public IPs that the parent SaaS needs to whitelist.
>
>I'm getting "Access Denied" messages and a review of Squid Parent proxy
>access.log shows the following common errors:
>
>HTTP:
>2018/11/27 16:22:54 kid1| WARNING: Forwarding loop detected for:
>GET / HTTP/1.1
>Accept: text/html, application/xhtml+xml, image/jxr, */*
>Accept-Language: en-US
>User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like
>Gecko
>Accept-Encoding: gzip, deflate
>Cookie: B=8nra62ldvb83a&b=3&s=ik
>Via: 1.1 squid (squid/3.5.27)

what are names of your proxies?
you must set different visible_name or at least unique_name so proxy knows
it's not contacting itself.

>Chain PREROUTING (policy ACCEPT 0 packets, 0 bytes)
> pkts bytes target     prot opt in     out     source
> destination
>    0     0 REDIRECT   tcp  --  *      *       0.0.0.0/0
>0.0.0.0/0            tcp dpt:80 redir ports 3129
>    0     0 REDIRECT   tcp  --  *      *       0.0.0.0/0
>0.0.0.0/0            tcp dpt:443 redir ports 3130
>   35  2100 REDIRECT   tcp  --  *      *       0.0.0.0/0
>0.0.0.0/0            tcp dpt:8443 redir ports 3031

the intercepting (often called transparent) proxy must have direct access to
world or parent proxy. Redirecting it back will create a loop.


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
BSE = Mad Cow Desease ... BSA = Mad Software Producents Desease


From uhlar at fantomas.sk  Tue Nov 27 16:47:17 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 27 Nov 2018 17:47:17 +0100
Subject: [squid-users] access_log acls
In-Reply-To: <0494171b-6917-50eb-8a53-33c2dcb20bda@urlfilterdb.com>
References: <afa7ed0a-9fdd-88e7-08a4-6622d70d42e6@urlfilterdb.com>
 <6e715c8e-8183-00fa-7baa-2ed329838e27@measurement-factory.com>
 <0494171b-6917-50eb-8a53-33c2dcb20bda@urlfilterdb.com>
Message-ID: <20181127164717.GB20312@fantomas.sk>

>>On 11/27/18 5:21 AM, Marcus Kool wrote:
>>>logformat combha %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %Ss:%Sh %>ha
>>>acl src_lb src 10.2.2.254/32
>>>acl src_lb src 10.2.2.107/32
>>>access_log stdio:/local/squid4/logs/lbaccess.log combha src_lb
>>>access_log stdio:/local/squid4/logs/access.log?? combha !src_lb
>>>The logging is almost as expected: all HTTP(S) traffic from 10.2.2.107
>>>goes to lbaccess.log and all other traffic to access.log,
>>>*but* imitating the TCP probe of the LB with a telnet session from
>>>10.2.2.107 to the squid server which is immediately terminated or sends
>>>garbage, is logged with transaction-end-before-headers to access.log,
>>>not lbaccess.log.
>>>Should the above acls send the errors to lbaccess.log?

>On 27/11/2018 13:58, Alex Rousskov wrote:
>>Yes, src ACLs should work for all transactions associated with to-Squid
>>connections, including transaction-end-before-headers errors. If they do
>>not work, it is a Squid bug.

On 27.11.18 14:42, Marcus Kool wrote:
>Thanks, I filed bug 4906: https://bugs.squid-cache.org/show_bug.cgi?id=4906
>
>Is it serious enough to get a fix in Squid 4?

which "squid 4" exactly?

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
They that can give up essential liberty to obtain a little temporary
safety deserve neither liberty nor safety. -- Benjamin Franklin, 1759


From rousskov at measurement-factory.com  Tue Nov 27 16:49:36 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 27 Nov 2018 09:49:36 -0700
Subject: [squid-users] Parent proxy chaining
In-Reply-To: <CACuTHxFub6pmxvLGWbAifq3jdqxHQVvJHQsHkB+fbckw+sqY6Q@mail.gmail.com>
References: <CACuTHxFub6pmxvLGWbAifq3jdqxHQVvJHQsHkB+fbckw+sqY6Q@mail.gmail.com>
Message-ID: <3086a242-171d-cd70-545f-7261ff8e1040@measurement-factory.com>

On 11/27/18 9:33 AM, Phillip McCollum wrote:

> 2018/11/27 16:22:54 kid1| WARNING: Forwarding loop detected for:
> Via: 1.1 squid (squid/3.5.27)

> [[Transparent Proxy]]:
> visible_hostname squid

> [[Squid Parent Proxy]]:
> visible_hostname squid

> Any thoughts or suggestions are greatly appreciated.

Squid uses Via headers to detect loops. Squid sends unique_hostname in
its Via header. unique_hostname defaults to visible_hostname. On each
Squid in your hierarchy, either use unique visible_hostname values or
use unique unique_hostname values, as appropriate in your environment.

Both directives are documented. For an expanded still-being-polished but
soon-to-become-official visible_hostname documentation, see
https://github.com/squid-cache/squid/pull/302/

Alex.


From marcus.kool at urlfilterdb.com  Tue Nov 27 17:04:25 2018
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 27 Nov 2018 15:04:25 -0200
Subject: [squid-users] access_log acls
In-Reply-To: <20181127164717.GB20312@fantomas.sk>
References: <afa7ed0a-9fdd-88e7-08a4-6622d70d42e6@urlfilterdb.com>
 <6e715c8e-8183-00fa-7baa-2ed329838e27@measurement-factory.com>
 <0494171b-6917-50eb-8a53-33c2dcb20bda@urlfilterdb.com>
 <20181127164717.GB20312@fantomas.sk>
Message-ID: <b5854c4d-1eed-0abd-9f55-1dd7b8322576@urlfilterdb.com>

4.5 would be nice.? 4.6 would also be nice.

On 27/11/2018 14:47, Matus UHLAR - fantomas wrote:
>>> On 11/27/18 5:21 AM, Marcus Kool wrote:
>>>> logformat combha %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %Ss:%Sh %>ha
>>>> acl src_lb src 10.2.2.254/32
>>>> acl src_lb src 10.2.2.107/32
>>>> access_log stdio:/local/squid4/logs/lbaccess.log combha src_lb
>>>> access_log stdio:/local/squid4/logs/access.log?? combha !src_lb
>>>> The logging is almost as expected: all HTTP(S) traffic from 10.2.2.107
>>>> goes to lbaccess.log and all other traffic to access.log,
>>>> *but* imitating the TCP probe of the LB with a telnet session from
>>>> 10.2.2.107 to the squid server which is immediately terminated or sends
>>>> garbage, is logged with transaction-end-before-headers to access.log,
>>>> not lbaccess.log.
>>>> Should the above acls send the errors to lbaccess.log?
>
>> On 27/11/2018 13:58, Alex Rousskov wrote:
>>> Yes, src ACLs should work for all transactions associated with to-Squid
>>> connections, including transaction-end-before-headers errors. If they do
>>> not work, it is a Squid bug.
>
> On 27.11.18 14:42, Marcus Kool wrote:
>> Thanks, I filed bug 4906: https://bugs.squid-cache.org/show_bug.cgi?id=4906
>>
>> Is it serious enough to get a fix in Squid 4?
>
> which "squid 4" exactly?
>


From jmperrote at policia.rionegro.gov.ar  Tue Nov 27 18:50:32 2018
From: jmperrote at policia.rionegro.gov.ar (jmperrote)
Date: Tue, 27 Nov 2018 15:50:32 -0300
Subject: [squid-users] Fwd: Re:  need help with cachemgr
In-Reply-To: <1a666c31-f6b3-8d42-a171-4d88cbfa9ee5@measurement-factory.com>
References: <98859f42-88df-7566-74f2-2845abf6272c@policia.rionegro.gov.ar>
 <1a666c31-f6b3-8d42-a171-4d88cbfa9ee5@measurement-factory.com>
Message-ID: <01758bf54c49844199f888b2157280c7@policia.rionegro.gov.ar>

Hello Alex, a think that I dont understand you. I try the sentence that 
you send my and the problem its the same. No data retrive from cachemgr.

squidclient -vv -p 1084 mgr:info

verbosity level set to 2
Request:
GET cache_object://localhost/info HTTP/1.0
Host: localhost
User-Agent: squidclient/3.5.12
Accept: */*
Connection: close


.
Transport detected: IPv4-only
Resolving localhost ...
Connecting... localhost (127.0.0.1:1084)
Connected to: localhost (127.0.0.1:1084)
Sending HTTP request ...
done.

On reverse proxy mode, the cache is generated to ? or is empty.

Regards.

-------- Mensaje Original --------
Asunto: Re: [squid-users] need help with cachemgr
Fecha: 2018-11-27 13:03
De: Alex Rousskov <rousskov at measurement-factory.com>
Destinatario: squid-users at lists.squid-cache.org

On 11/27/18 6:13 AM, jmperrote wrote:
> Hello need help with cachemgr, I using a squid as a reverse proxy mode,
> when I try to connect to retrive data using squidclient, connecting to
> cachemrg, only retrive squid OK, but the other values HIT, http 
> request,
> etc,? that ara usually retrived are not retrived.
> 
> My case when I to try connect:
> 
>                     squidclient -vv cache_object://localhost/ mgr:info
>                     -p 1084

Place all named options before the anonymous ones and
use one (pseudo) URL at a time:

   squidclient -vv -p 1084 cache_object://localhost/
   squidclient -vv -p 1084 mgr:info

Alex.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Tue Nov 27 21:21:09 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 27 Nov 2018 14:21:09 -0700
Subject: [squid-users] Fwd: Re: need help with cachemgr
In-Reply-To: <01758bf54c49844199f888b2157280c7@policia.rionegro.gov.ar>
References: <98859f42-88df-7566-74f2-2845abf6272c@policia.rionegro.gov.ar>
 <1a666c31-f6b3-8d42-a171-4d88cbfa9ee5@measurement-factory.com>
 <01758bf54c49844199f888b2157280c7@policia.rionegro.gov.ar>
Message-ID: <dd47ad1b-fab9-0b14-cceb-360ac0a9da22@measurement-factory.com>

On 11/27/18 11:50 AM, jmperrote wrote:
> I try the sentence that
> you send my and the problem its the same.

You may have several problems. The commands I sent you fixed one of
those problems. With those new commands, squidclient sends correct cache
manager URL to Squid.


> No data retrive from cachemgr.

That is another problem. I do not know why your Squid does not respond
to these Cache Manager requests. Does Squid get these requests? What
does Squid access.log say?


> squidclient -vv -p 1084 mgr:info
> 
> verbosity level set to 2
> Request:
> GET cache_object://localhost/info HTTP/1.0
> Host: localhost
> User-Agent: squidclient/3.5.12
> Accept: */*
> Connection: close
> 
> 
> .
> Transport detected: IPv4-only
> Resolving localhost ...
> Connecting... localhost (127.0.0.1:1084)
> Connected to: localhost (127.0.0.1:1084)
> Sending HTTP request ...
> done.


The above debugging/stderr output looks OK to me (unlike the output you
posted earlier that showed wrong request URLs). It should be followed by
an HTTP response (on stdout).


> On reverse proxy mode, the cache is generated to ? or is empty.

I am not sure what you mean by "the cache is generated to ? or is
empty". If you do not see any HTTP response coming from Squid, then
investigate what Squid knows/says about the request, starting with any
relevant cache.log and access.log records.


HTH,

Alex.


> -------- Mensaje Original --------
> Asunto: Re: [squid-users] need help with cachemgr
> Fecha: 2018-11-27 13:03
> De: Alex Rousskov <rousskov at measurement-factory.com>
> Destinatario: squid-users at lists.squid-cache.org
> 
> On 11/27/18 6:13 AM, jmperrote wrote:
>> Hello need help with cachemgr, I using a squid as a reverse proxy mode,
>> when I try to connect to retrive data using squidclient, connecting to
>> cachemrg, only retrive squid OK, but the other values HIT, http request,
>> etc,? that ara usually retrived are not retrived.
>>
>> My case when I to try connect:
>>
>> ??????????????????? squidclient -vv cache_object://localhost/ mgr:info
>> ??????????????????? -p 1084
> 
> Place all named options before the anonymous ones and
> use one (pseudo) URL at a time:
> 
> ? squidclient -vv -p 1084 cache_object://localhost/
> ? squidclient -vv -p 1084 mgr:info
> 
> Alex.


From schokobecher at gmail.com  Tue Nov 27 21:28:26 2018
From: schokobecher at gmail.com (Schokobecher)
Date: Wed, 28 Nov 2018 04:28:26 +0700
Subject: [squid-users] NCSA Auth doesn't recognize usernames with capital
	letters
Message-ID: <CANXaQcoTrbqN_wFFvvrr20+pCpqjunCnSC6AAKDPDteX4hjkcQ@mail.gmail.com>

Hello,

I'm facing a really weird problem at the moment.
I'm using Squid 4.2 using the default Ubuntu compile options
(self-compiled) together with the NCSA Basic Auth helper and a passwd
file generated using "httpasswd -m".

If I add a user to it that starts with a capital letter (for example
"Bob") the auth always fails - until "Bob" becomes "bob" inside the
file, then the auth instantly works... and also for "Bob" since I use an
ACL like:

acl bob proxy_auth_regex -i bob

But the other way around is a no-go.

Did I miss something here?

Cheers,
Pierre
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181128/fb77f5b5/attachment.htm>

From pcmccollum at gmail.com  Tue Nov 27 22:35:21 2018
From: pcmccollum at gmail.com (Phillip McCollum)
Date: Tue, 27 Nov 2018 14:35:21 -0800
Subject: [squid-users] Parent proxy chaining
In-Reply-To: <mailman.3202.1543354120.3019.squid-users@lists.squid-cache.org>
References: <mailman.3202.1543354120.3019.squid-users@lists.squid-cache.org>
Message-ID: <CACuTHxH=zmpgKOD9GzJVEvYfj2H_f35NOc3CSvD-0ba5Zhv5EA@mail.gmail.com>

Thank you both, Matus and Alex! Changing the name got my HTTP access
working perfectly. I was stuck on HTTPS soon after, but as soon as I
removed "intercept" from the Squid Parent proxy "http_port" line, I got
that working.

You guys rock. Thanks again for that little nudge I needed to figure this
out.

-Phillip


> Message: 2
> Date: Tue, 27 Nov 2018 17:44:54 +0100
> From: Matus UHLAR - fantomas <uhlar at fantomas.sk>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Parent proxy chaining
> Message-ID: <20181127164454.GA20312 at fantomas.sk>
> Content-Type: text/plain; charset=us-ascii; format=flowed
>
> On 27.11.18 08:33, Phillip McCollum wrote:
> >I have a deployment in AWS in where a VPC has a transparent proxy
> deployed,
> >which forwards 80/443 requests to a parent proxy in another VPC, which I
> >then need to forward to another parent proxy (SaaS provider).
> >
> >Essentially:
> >[[Client PC]] --> [[Squid Proxy (10.52.0.20)]] --> [[Parent Squid Proxy
> >(10.52.0.168)]] --> [[Parent SaaS Proxy]]
> >
> >This is being done to centralize proxy functions and limit the number of
> >public IPs that the parent SaaS needs to whitelist.
> >
> >I'm getting "Access Denied" messages and a review of Squid Parent proxy
> >access.log shows the following common errors:
> >
> >HTTP:
> >2018/11/27 16:22:54 kid1| WARNING: Forwarding loop detected for:
> >GET / HTTP/1.1
> >Accept: text/html, application/xhtml+xml, image/jxr, */*
> >Accept-Language: en-US
> >User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0)
> like
> >Gecko
> >Accept-Encoding: gzip, deflate
> >Cookie: B=8nra62ldvb83a&b=3&s=ik
> >Via: 1.1 squid (squid/3.5.27)
>
> what are names of your proxies?
> you must set different visible_name or at least unique_name so proxy knows
> it's not contacting itself.
>
> >Chain PREROUTING (policy ACCEPT 0 packets, 0 bytes)
> > pkts bytes target     prot opt in     out     source
> > destination
> >    0     0 REDIRECT   tcp  --  *      *       0.0.0.0/0
> >0.0.0.0/0            tcp dpt:80 redir ports 3129
> >    0     0 REDIRECT   tcp  --  *      *       0.0.0.0/0
> >0.0.0.0/0            tcp dpt:443 redir ports 3130
> >   35  2100 REDIRECT   tcp  --  *      *       0.0.0.0/0
> >0.0.0.0/0            tcp dpt:8443 redir ports 3031
>
> the intercepting (often called transparent) proxy must have direct access
> to
> world or parent proxy. Redirecting it back will create a loop.
>
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> BSE = Mad Cow Desease ... BSA = Mad Software Producents Desease
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181127/aaed7a36/attachment.htm>

From uhlar at fantomas.sk  Wed Nov 28 11:24:30 2018
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 28 Nov 2018 12:24:30 +0100
Subject: [squid-users] access_log acls
In-Reply-To: <b5854c4d-1eed-0abd-9f55-1dd7b8322576@urlfilterdb.com>
References: <afa7ed0a-9fdd-88e7-08a4-6622d70d42e6@urlfilterdb.com>
 <6e715c8e-8183-00fa-7baa-2ed329838e27@measurement-factory.com>
 <0494171b-6917-50eb-8a53-33c2dcb20bda@urlfilterdb.com>
 <20181127164717.GB20312@fantomas.sk>
 <b5854c4d-1eed-0abd-9f55-1dd7b8322576@urlfilterdb.com>
Message-ID: <20181128112430.GB9295@fantomas.sk>

On 27.11.18 15:04, Marcus Kool wrote:
>4.5 would be nice.? 4.6 would also be nice.

OK, I will rephrase my question: which squid version do you find this in?

>On 27/11/2018 14:47, Matus UHLAR - fantomas wrote:
>>>>On 11/27/18 5:21 AM, Marcus Kool wrote:
>>>>>logformat combha %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %Ss:%Sh %>ha
>>>>>acl src_lb src 10.2.2.254/32
>>>>>acl src_lb src 10.2.2.107/32
>>>>>access_log stdio:/local/squid4/logs/lbaccess.log combha src_lb
>>>>>access_log stdio:/local/squid4/logs/access.log?? combha !src_lb
>>>>>The logging is almost as expected: all HTTP(S) traffic from 10.2.2.107
>>>>>goes to lbaccess.log and all other traffic to access.log,
>>>>>*but* imitating the TCP probe of the LB with a telnet session from
>>>>>10.2.2.107 to the squid server which is immediately terminated or sends
>>>>>garbage, is logged with transaction-end-before-headers to access.log,
>>>>>not lbaccess.log.
>>>>>Should the above acls send the errors to lbaccess.log?
>>
>>>On 27/11/2018 13:58, Alex Rousskov wrote:
>>>>Yes, src ACLs should work for all transactions associated with to-Squid
>>>>connections, including transaction-end-before-headers errors. If they do
>>>>not work, it is a Squid bug.
>>
>>On 27.11.18 14:42, Marcus Kool wrote:
>>>Thanks, I filed bug 4906: https://bugs.squid-cache.org/show_bug.cgi?id=4906
>>>
>>>Is it serious enough to get a fix in Squid 4?
>>
>>which "squid 4" exactly?


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
- Holmes, what kind of school did you study to be a detective?
- Elementary, Watson.  -- Daffy Duck & Porky Pig


From squid3 at treenet.co.nz  Wed Nov 28 12:05:54 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Nov 2018 01:05:54 +1300
Subject: [squid-users] NCSA Auth doesn't recognize usernames with
 capital letters
In-Reply-To: <CANXaQcoTrbqN_wFFvvrr20+pCpqjunCnSC6AAKDPDteX4hjkcQ@mail.gmail.com>
References: <CANXaQcoTrbqN_wFFvvrr20+pCpqjunCnSC6AAKDPDteX4hjkcQ@mail.gmail.com>
Message-ID: <1e410f7a-c4be-c846-f077-01d600f21756@treenet.co.nz>

On 28/11/18 10:28 am, Schokobecher wrote:
> Hello,
> 
> I'm facing a really weird problem at the moment.
> I'm using Squid 4.2 using the default Ubuntu compile options
> (self-compiled) together with the NCSA Basic Auth helper and a passwd
> file generated using "httpasswd -m".
> 
> If I add a user to it that starts with a capital letter (for example
> "Bob") the auth always fails - until "Bob" becomes "bob" inside the
> file, then the auth instantly works... and also for "Bob" since I use an
> ACL like:
> 
> acl bob proxy_auth_regex -i bob
> 
> But the other way around is a no-go.
> 
> Did I miss something here?

Usernames are case sensitive. Your regex may accept insensitive values,
but the rest of the system is mandatory case sensitive.
 [ IME the systems doing UI tend to lower case inputs in order to avoid
security issues and headaches that come with with having two logins
"bob" and "Bob" for different users. ]

You can double-check what is going on with a cache.log trace from
"debug_options 11,2 28,8 29,9". The helper itself does not (yet) have
debug output unfortunately so if the issue is inside the OS crypt()
implementation it can be hard to see.

Amos


From Marcus.Kool at urlfilterdb.com  Wed Nov 28 12:10:39 2018
From: Marcus.Kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 28 Nov 2018 13:10:39 +0100
Subject: [squid-users] access_log acls
In-Reply-To: <20181128112430.GB9295@fantomas.sk>
References: <afa7ed0a-9fdd-88e7-08a4-6622d70d42e6@urlfilterdb.com>
 <6e715c8e-8183-00fa-7baa-2ed329838e27@measurement-factory.com>
 <0494171b-6917-50eb-8a53-33c2dcb20bda@urlfilterdb.com>
 <20181127164717.GB20312@fantomas.sk>
 <b5854c4d-1eed-0abd-9f55-1dd7b8322576@urlfilterdb.com>
 <20181128112430.GB9295@fantomas.sk>
Message-ID: <20181128121039.GA7181@ms2.urlfilterdb.com>

On Wed, Nov 28, 2018 at 12:24:30PM +0100, Matus UHLAR - fantomas wrote:
> On 27.11.18 15:04, Marcus Kool wrote:
> > 4.5 would be nice.? 4.6 would also be nice.
> 
> OK, I will rephrase my question: which squid version do you find this in?

This issue was found in Squid 4.3

> 
> > On 27/11/2018 14:47, Matus UHLAR - fantomas wrote:
> > > > > On 11/27/18 5:21 AM, Marcus Kool wrote:
> > > > > > logformat combha %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %Ss:%Sh %>ha
> > > > > > acl src_lb src 10.2.2.254/32
> > > > > > acl src_lb src 10.2.2.107/32
> > > > > > access_log stdio:/local/squid4/logs/lbaccess.log combha src_lb
> > > > > > access_log stdio:/local/squid4/logs/access.log?? combha !src_lb
> > > > > > The logging is almost as expected: all HTTP(S) traffic from 10.2.2.107
> > > > > > goes to lbaccess.log and all other traffic to access.log,
> > > > > > *but* imitating the TCP probe of the LB with a telnet session from
> > > > > > 10.2.2.107 to the squid server which is immediately terminated or sends
> > > > > > garbage, is logged with transaction-end-before-headers to access.log,
> > > > > > not lbaccess.log.
> > > > > > Should the above acls send the errors to lbaccess.log?
> > > 
> > > > On 27/11/2018 13:58, Alex Rousskov wrote:
> > > > > Yes, src ACLs should work for all transactions associated with to-Squid
> > > > > connections, including transaction-end-before-headers errors. If they do
> > > > > not work, it is a Squid bug.
> > > 
> > > On 27.11.18 14:42, Marcus Kool wrote:
> > > > Thanks, I filed bug 4906: https://bugs.squid-cache.org/show_bug.cgi?id=4906
> > > > 
> > > > Is it serious enough to get a fix in Squid 4?
> > > 
> > > which "squid 4" exactly?
> 
> 
> -- 
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> - Holmes, what kind of school did you study to be a detective?
> - Elementary, Watson.  -- Daffy Duck & Porky Pig
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Wed Nov 28 15:50:50 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 28 Nov 2018 08:50:50 -0700
Subject: [squid-users] need help with cachemgr
In-Reply-To: <5e58c0cd-dba2-0d25-0e5e-8aa8a3e10340@policia.rionegro.gov.ar>
References: <98859f42-88df-7566-74f2-2845abf6272c@policia.rionegro.gov.ar>
 <1a666c31-f6b3-8d42-a171-4d88cbfa9ee5@measurement-factory.com>
 <01758bf54c49844199f888b2157280c7@policia.rionegro.gov.ar>
 <dd47ad1b-fab9-0b14-cceb-360ac0a9da22@measurement-factory.com>
 <5e58c0cd-dba2-0d25-0e5e-8aa8a3e10340@policia.rionegro.gov.ar>
Message-ID: <d714b96a-765a-a592-6c43-220ca6c62981@measurement-factory.com>

On 11/28/18 4:59 AM, jmperrote wrote:

> This is the new error that I have when I tried to squidclint via https +
> certicicate.

You have many different problems.

Problem 0: You are not responding on the mailing list. Please keep this
thread on the mailing list so that others can benefit from this triage
and so that others can help you.

Problem 1: You seem to ignore errors and warnings that you can fix on
your own. Please fix the ones you can fix before asking for help with
the remaining problems. When asking for help, explain what you think
each remaining warning/error means, and why you cannot fix that problem.
This approach shows that you invest serious effort into making this work
rather than simply abusing the mailing list as a free replacement for a
system administrator.


Problem 2:

> squidclient -vvv --https --cert /soporte/ssl/educacion.crt -h 10.0.0.4 -p 1084 mgr:info

The --cert option specifies a TLS client certificate. Your reverse
proxy, AFAICT, does not use client certificates. Remove that option. See
"man squidclient" for details about each option you use.


Problem 3:

> WARNING: Failed to load Certificate from /soporte/ssl/educacion.crt

I do not know what went wrong here because you have not provided any
relevant information like whether the file is actually there and can be
read by the user squidclient runs as.


Problem 4:

> X.509 TLS handshake ...
> VERIFY DATUM: The certificate is NOT trusted. The certificate issuer is
> unknown. The name in the certificate does not match the expected.
> WARNING: Insecure Connection

Looks self-explanatory to me: Your squidclient does not trust the server
certificate used by your reverse proxy. You may need to either

* use a --trusted-ca option or
* configure your TLS library environment to always trust the CA that
signed the https_port certificate of your reverse proxy.


Problem 5:

> HTTP/1.1 401 Unauthorized
> X-Squid-Error: ERR_CACHE_ACCESS_DENIED 0
> WWW-Authenticate: Basic realm=...

Your reverse proxy requires HTTP client authentication. Depending on
your needs, you should either

* adjust your Squid http_access rules to disable authentication for
cache manager requests or
* give a valid username and password to squidclient (search "man
squidclient" manual page for "authentication" and "WWW" to discover the
right options).


Potential problem 6:

This may not be relevant to you, but please note that Squid Cache
Manager does not yet support secure queries when Squid is running in SMP
mode. For details, please see
https://wiki.squid-cache.org/Features/CacheManager#Secure_SMP_reports


HTH,

Alex.


From squid-user at tlinx.org  Thu Nov 29 12:33:58 2018
From: squid-user at tlinx.org (L A Walsh)
Date: Thu, 29 Nov 2018 04:33:58 -0800
Subject: [squid-users] how to go from connect/tunnel in squid4 ->GET
Message-ID: <5BFFDCB6.8040404@tlinx.org>

I had a version of this working in squid3.x, but it didn't work
for some sites and didn't work well with a newer Opera, but did
ok with an older FF-clone.

I bumped to squid4 a few months ago, but stil haven't gotten to the point
where I can see and cache individual requests and following config examples
@ https://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit,
I'm feeling rather clueless as to what I'm missing.

If someone could throw a few hints/clueballs my way I'd really appreciate
knowing what I'm doing wrong.

My port line looks like (it's all 1 line).
http_port ishtar.sc.tlinx.org:8118 ssl-bump 
generate-host-certificates=on dynamic_cert_mem_cache_size=64MB 
tls-cert=/etc/squid/ssl_cert/myCA.pem 
options=SINGLE_DH_USE,SINGLE_ECDH_USE 
tls-dh=secp521r1,/etc/squid/ssl_cert/dhparam-4096.pem

myCA.pem contains both private+public sigs.  I generated a separate
dhparam file, but don't know if I was supposed to include the curve
type in the generation command or if it only uses that later.

I pre-generated the cert dir and it seems to be running, but I don't
see any certs appearing in the dir


Looking at squid w/ps, I see:
root     56805     1  0 04:28 ?        00:00:00 /usr/sbin/squid
squid    56807 56805 42 04:28 ?        00:00:03 (squid-1) --kid squid-1
squid    56809 56807  0 04:28 ?        00:00:00 (security_file_certgen) 
-s /var/cache/squid/lib/ssl_db -M 64MB
squid    56810 56807  0 04:28 ?        00:00:00 (security_file_certgen) 
-s /var/cache/squid/lib/ssl_db -M 64MB
squid    56811 56807  0 04:28 ?        00:00:00 (security_file_certgen) 
-s /var/cache/squid/lib/ssl_db -M 64MB
squid    56812 56807  0 04:28 ?        00:00:00 (security_file_certgen) 
-s /var/cache/squid/lib/ssl_db -M 64MB
squid    56813 56807  0 04:28 ?        00:00:00 (security_file_certgen) 
-s /var/cache/squid/lib/ssl_db -M 64MB
squid    56814 56807  0 04:28 ?        00:00:00 (logfile-daemon) 
/var/log/squid/access.log
squid    56815 56807  0 04:28 ?        00:00:00 (pinger)

Any ideas where I might be missing things?  I can decomment and
send the active lines from the config file if that would help.

Thanks for any pointers...






From wirecutter at shadycloud.com  Thu Nov 29 14:57:08 2018
From: wirecutter at shadycloud.com (Wire Cutter)
Date: Thu, 29 Nov 2018 09:57:08 -0500
Subject: [squid-users] Question on Many Clients to Many Proxy Lists
Message-ID: <CAPL=MgeZVVAohdfXe3q8WDdhsjs78P_QL=xoAbMc8BHQyKTnog@mail.gmail.com>

I have an issue with a Squid config I can?t figure out. I?m trying to have
a many (Hosts) to many (Up stream proxies) in a single config

I?ve created 4 ports for clients to talk to, then created ACL lists for
those ports.  From there I?ve tried (and failed) to create naming groups
for cacheing peers, then added those to ACLs and it fails. Any ideas?

Here?s a link on what some people have come up with.
https://www.linuxquestions.org/questions/linux-server-73/squid-multiple-ports-multiple-destinations-4175450243/
linuxquestions.org

Squid multiple ports multiple destinations
Hello there, I want to spawn one squid instance on multiple ports (which I
already have). Code: http_port myip:9000 name=first http_port myip:9001
linuxquestions.org

Squid multiple ports multiple destinations
Hello there, I want to spawn one squid instance on multiple ports (which I
already have). Code: http_port myip:9000 name=first http_port myip:9001


Any help would be appreciated
--
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181129/1c6b3540/attachment.htm>

From rousskov at measurement-factory.com  Thu Nov 29 15:44:43 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 29 Nov 2018 08:44:43 -0700
Subject: [squid-users] Question on Many Clients to Many Proxy Lists
In-Reply-To: <CAPL=MgeZVVAohdfXe3q8WDdhsjs78P_QL=xoAbMc8BHQyKTnog@mail.gmail.com>
References: <CAPL=MgeZVVAohdfXe3q8WDdhsjs78P_QL=xoAbMc8BHQyKTnog@mail.gmail.com>
Message-ID: <a7c6a340-33df-93a3-7894-a033d3c6c7a8@measurement-factory.com>

On 11/29/18 7:57 AM, Wire Cutter wrote:

> I?ve created 4 ports for clients to talk to, then created ACL lists for
> those ports.? From there I?ve tried (and failed) to create naming groups
> for cacheing peers, then added those to ACLs and it fails. Any ideas?

Use cache_peer_access to allow http_port X traffic (and only that
traffic) to peer group Y:

  # rules for peer group A
  cache_peer_access peerA1 allow receivedOnPortForPeersA
  cache_peer_access peerA2 allow receivedOnPortForPeersA
  cache_peer_access peerA3 allow receivedOnPortForPeersA
  ...
  # rules for peer group B
  cache_peer_access peerB1 allow receivedOnPortForPeersB
  cache_peer_access peerB2 allow receivedOnPortForPeersB
  ...


Depending on your traffic and needs, you may also need to allow
non-hierarchical requests to go to peer:

  nonhierarchical_direct off

and/or to prohibit direct connections for portX:

  never_direct allow receivedOnPortForPeersA
  never_direct allow receivedOnPortForPeersB


Once you get this working, please make Squid documentation improvements
that would have allowed you to figure this out on your own.


HTH,

Alex.


From rousskov at measurement-factory.com  Thu Nov 29 15:53:11 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 29 Nov 2018 08:53:11 -0700
Subject: [squid-users] how to go from connect/tunnel in squid4 ->GET
In-Reply-To: <5BFFDCB6.8040404@tlinx.org>
References: <5BFFDCB6.8040404@tlinx.org>
Message-ID: <4800e016-6636-1972-446b-f3d69c75f345@measurement-factory.com>

On 11/29/18 5:33 AM, L A Walsh wrote:

> I bumped to squid4 a few months ago, but stil haven't gotten to the point
> where I can see and cache individual requests and following config examples
> @ https://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit,
> I'm feeling rather clueless as to what I'm missing.

What record(s) does your access.log contain for a single test
transaction (preferably using curl or wget rather than a browser)? Any
messages in cache.log for that test transaction? Any ERRORs or WARNINGs
in cache.log at Squid startup?

Alex.



> My port line looks like (it's all 1 line).
> http_port ishtar.sc.tlinx.org:8118 ssl-bump
> generate-host-certificates=on dynamic_cert_mem_cache_size=64MB
> tls-cert=/etc/squid/ssl_cert/myCA.pem
> options=SINGLE_DH_USE,SINGLE_ECDH_USE
> tls-dh=secp521r1,/etc/squid/ssl_cert/dhparam-4096.pem
> 
> myCA.pem contains both private+public sigs.? I generated a separate
> dhparam file, but don't know if I was supposed to include the curve
> type in the generation command or if it only uses that later.
> 
> I pre-generated the cert dir and it seems to be running, but I don't
> see any certs appearing in the dir


From squid-user at tlinx.org  Thu Nov 29 17:43:43 2018
From: squid-user at tlinx.org (L A Walsh)
Date: Thu, 29 Nov 2018 09:43:43 -0800
Subject: [squid-users] how to go from connect/tunnel in squid4 ->GET
Message-ID: <5C00254F.4040109@tlinx.org>

I had a version of this working in squid3.x, but it didn't work
for some sites and didn't work well with a newer Opera, but did
ok with an older FF-clone.

I bumped to squid4 a few months ago, but stil haven't gotten to the point
where I can see and cache individual requests and following config examples
@ https://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit,
I'm feeling rather clueless as to what I'm missing.

If someone could throw a few hints/clueballs my way I'd really appreciate
knowing what I'm doing wrong.

My port line looks like (it's all 1 line).
http_port ishtar.sc.tlinx.org:8118 ssl-bump 
generate-host-certificates=on dynamic_cert_mem_cache_size=64MB 
tls-cert=/etc/squid/ssl_cert/myCA.pem 
options=SINGLE_DH_USE,SINGLE_ECDH_USE 
tls-dh=secp521r1,/etc/squid/ssl_cert/dhparam-4096.pem

myCA.pem contains both private+public sigs.  I generated a separate
dhparam file, but don't know if I was supposed to include the curve
type in the generation command or if it only uses that later.

I pre-generated the cert dir and it seems to be running, but I don't
see any certs appearing in the dir


Looking at squid w/ps, I see:
root     56805     1  0 04:28 ?        00:00:00 /usr/sbin/squid
squid    56807 56805 42 04:28 ?        00:00:03 (squid-1) --kid squid-1
squid    56809 56807  0 04:28 ?        00:00:00 (security_file_certgen) 
-s /var/cache/squid/lib/ssl_db -M 64MB
squid    56810 56807  0 04:28 ?        00:00:00 (security_file_certgen) 
-s /var/cache/squid/lib/ssl_db -M 64MB
squid    56811 56807  0 04:28 ?        00:00:00 (security_file_certgen) 
-s /var/cache/squid/lib/ssl_db -M 64MB
squid    56812 56807  0 04:28 ?        00:00:00 (security_file_certgen) 
-s /var/cache/squid/lib/ssl_db -M 64MB
squid    56813 56807  0 04:28 ?        00:00:00 (security_file_certgen) 
-s /var/cache/squid/lib/ssl_db -M 64MB
squid    56814 56807  0 04:28 ?        00:00:00 (logfile-daemon) 
/var/log/squid/access.log
squid    56815 56807  0 04:28 ?        00:00:00 (pinger)

Any ideas where I might be missing things?  I can decomment and
send the active lines from the config file if that would help.

Thanks for any pointers...







From jennifer.canterbury at gmail.com  Thu Nov 29 17:46:07 2018
From: jennifer.canterbury at gmail.com (Jennifer Canterbury)
Date: Thu, 29 Nov 2018 12:46:07 -0500
Subject: [squid-users] office365 - brand new endpoint management question!!
Message-ID: <CA+MX-S4c+e6sbo7gveJnNM1b1JOso8GUnyG4mBXuWgQyOHJFkQ@mail.gmail.com>

Did anyone see the changes to office365 IP and URLs management effective as
of 11/27/18?  Microsoft appears to be be going to 3 different CDN networks
(Akamai, MarkMonitor, and ExactTarget) for office365 connectivity.

I have a few questions:
1)  How many users do you think a single virtual squid server could
handle?
2)  How many "acl bypass_parent" URLs can my cache squid proxy server
handle before browsing starts to slow?
3)  We use a pac file to redirect office365 URLs to our squid box, does
anyone have any snazzy ways of getting-managing-updating the office365 URL
list in squid I would need to configure using the new MS web service?
(product idea!!)

Waiting with bated breath!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181129/9cd855a9/attachment.htm>

From chip_pop at hotmail.com  Thu Nov 29 18:26:35 2018
From: chip_pop at hotmail.com (joseph)
Date: Thu, 29 Nov 2018 12:26:35 -0600 (CST)
Subject: [squid-users] office365 - brand new endpoint management
	question!!
In-Reply-To: <CA+MX-S4c+e6sbo7gveJnNM1b1JOso8GUnyG4mBXuWgQyOHJFkQ@mail.gmail.com>
References: <CA+MX-S4c+e6sbo7gveJnNM1b1JOso8GUnyG4mBXuWgQyOHJFkQ@mail.gmail.com>
Message-ID: <1543515995602-0.post@n4.nabble.com>

store id helper can minimize cdn links



-----
************************** 
***** Crash to the future  ****
**************************
--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid-user at tlinx.org  Thu Nov 29 18:38:55 2018
From: squid-user at tlinx.org (L A Walsh)
Date: Thu, 29 Nov 2018 10:38:55 -0800
Subject: [squid-users] how to go from connect/tunnel in squid4 ->GET
In-Reply-To: <4800e016-6636-1972-446b-f3d69c75f345@measurement-factory.com>
References: <5BFFDCB6.8040404@tlinx.org>
 <4800e016-6636-1972-446b-f3d69c75f345@measurement-factory.com>
Message-ID: <5C00323F.8090806@tlinx.org>

BTW, I posted this a 2nd time because I didn't see the 1st post
ever post (or maybe I didn't see the 2nd post post?...) but it
sorta looks like you responded to the 1st post, and my 2nd post
came in immediate after...strange...
Thank you very much, for your reply, answers are below...
Linda


On 11/29/2018 7:53 AM, Alex Rousskov wrote:
> On 11/29/18 5:33 AM, L A Walsh wrote:
>
>   
>> I bumped to squid4 a few months ago, but stil haven't gotten to the point
>> where I can see and cache individual requests and following config examples
>> @ https://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit,
>> I'm feeling rather clueless as to what I'm missing.
>>     
>
> What record(s) does your access.log contain for a single test
> transaction (preferably using curl or wget rather than a browser)? Any
> messages in cache.log for that test transaction? Any ERRORs or WARNINGs
> in cache.log at Squid startup?
>   
----
 From the latest startup:
2018/11/29 09:26:17| Created PID file (/run/squid.pid)
2018/11/29 09:26:17 kid1| Set Current Directory to /var/cache/squid
2018/11/29 09:26:17 kid1| Starting Squid Cache version 4.0.25 for 
x86_64-pc-linux-gnu...
2018/11/29 09:26:17 kid1| Service Name: squid
2018/11/29 09:26:17 kid1| Process ID 2344
2018/11/29 09:26:17 kid1| Process Roles: worker
2018/11/29 09:26:17 kid1| With 16384 file descriptors available
2018/11/29 09:26:17 kid1| Initializing IP Cache...
2018/11/29 09:26:17 kid1| DNS Socket created at 0.0.0.0, FD 5
2018/11/29 09:26:17 kid1| Adding nameserver 127.0.0.1 from /etc/resolv.conf
2018/11/29 09:26:17 kid1| Adding nameserver 192.168.3.1 from 
/etc/resolv.conf
2018/11/29 09:26:17 kid1| Adding domain sc.tlinx.org from /etc/resolv.conf
2018/11/29 09:26:17 kid1| Adding domain tlinx.org from /etc/resolv.conf
2018/11/29 09:26:17 kid1| Adding ndots 1 from /etc/resolv.conf
2018/11/29 09:26:17 kid1| helperOpenServers: Starting 5/32 
'security_file_certgen' processes
2018/11/29 09:26:17 kid1| Logfile: opening log 
daemon:/var/log/squid/access.log
2018/11/29 09:26:17 kid1| Logfile Daemon: opening log 
/var/log/squid/access.log
2018/11/29 09:26:17 kid1| Store logging disabled
2018/11/29 09:26:17 kid1| Swap maxSize 100663296 + 262144 KB, estimated 
394240 objects
2018/11/29 09:26:17 kid1| Target number of buckets: 12320
2018/11/29 09:26:17 kid1| Using 16384 Store buckets
2018/11/29 09:26:17 kid1| Max Mem  size: 262144 KB
2018/11/29 09:26:17 kid1| Max Swap size: 100663296 KB
2018/11/29 09:26:18 kid1| Rebuilding storage in /var/cache/squid (dirty log)
2018/11/29 09:26:18 kid1| Using Least Load store dir selection
2018/11/29 09:26:18 kid1| Set Current Directory to /var/cache/squid
2018/11/29 09:26:18 kid1| Finished loading MIME types and icons.
2018/11/29 09:26:18 kid1| WARNING: No ssl_bump configured. Disabling 
ssl-bump on http_port 192.168.3.1:8118
2018/11/29 09:26:18 kid1| HTCP Disabled.
2018/11/29 09:26:18 kid1| Pinger socket opened on FD 27
2018/11/29 09:26:18 kid1| Squid plugin modules loaded: 0
2018/11/29 09:26:18 kid1| Adaptation support is off.
2018/11/29 09:26:18 kid1| Accepting HTTP Socket connections at 
local=192.168.3.1:8118 remote=[::] FD 23 flags=9
2018/11/29 09:26:18 kid1| Accepting HTTP Socket connections at 
local=192.168.3.1:8080 remote=[::] FD 24 flags=9
2018/11/29 09:26:18 kid1| Accepting HTTP Socket connections at 
local=127.0.0.1:8080 remote=[::] FD 25 flags=9
2018/11/29 09:26:18 kid1| Store rebuilding is 0.60% complete
2018/11/29 09:26:18| pinger: Initialising ICMP pinger ...
2018/11/29 09:26:18| pinger: ICMP socket opened.
2018/11/29 09:26:21 kid1| Done reading /var/cache/squid swaplog (663690 
entries)
2018/11/29 09:26:21 kid1| Finished rebuilding storage from disk.
2018/11/29 09:26:21 kid1|    663558 Entries scanned
2018/11/29 09:26:21 kid1|         0 Invalid entries.
2018/11/29 09:26:21 kid1|         0 With invalid flags.
2018/11/29 09:26:21 kid1|    663504 Objects loaded.
2018/11/29 09:26:21 kid1|         0 Objects expired.
2018/11/29 09:26:21 kid1|        95 Objects cancelled.
2018/11/29 09:26:21 kid1|         0 Duplicate URLs purged.
2018/11/29 09:26:21 kid1|        54 Swapfile clashes avoided.
2018/11/29 09:26:21 kid1|   Took 3.76 seconds (176329.00 objects/sec).
2018/11/29 09:26:21 kid1| Beginning Validation Procedure
2018/11/29 09:26:21 kid1|   262144 Entries Validated so far.
2018/11/29 09:26:22 kid1|   524288 Entries Validated so far.
2018/11/29 09:26:22 kid1|   Completed Validation Procedure
2018/11/29 09:26:22 kid1|   Validated 663462 Entries
2018/11/29 09:26:22 kid1|   store_swap_size = 90578908.00 KB
2018/11/29 09:26:22 kid1| storeLateRelease: released 95 objects
2018/11/29 10:10:32 kid1| ipcacheParse No Address records in response to 
'ipv6.msftncsi.com'
2018/11/29 10:11:43 kid1| Logfile: opening log 
stdio:/var/cache/squid/cache/squid/netdb.state
2018/11/29 10:11:43 kid1| netdbSaveState 
stdio:/var/cache/squid/cache/squid/netdb.state: (0) No error.

---
When I tried to do a wget on "www.slashdot.org", I in my short-hand
monitor of the access log, I see:

[1129_101306.00]  129ms; 266  (0/2.0K) MISS/301     <Ishtar [HEAD 
http://www.slashdot.org/ - 216.105.38.15 text/html]
  +0.10    48ms; 39   (419/813) TUNNEL/200   <Ishtar [CONNECT 
www.slashdot.org:443 - 216.105.38.15 -]

---
and the form directly from the access log shows:
1543515186.809    129 192.168.3.1 TCP_MISS/301 266 HEAD 
http://www.slashdot.org/ - HIER_DIRECT/216.105.38.15 text/html 
[User-Agent: "Mozilla/4.0 (compatible; MSIE 6.1; Windows NT 
5.1)"\r\nAccept: */*\r\nConnection: Keep-Alive\r\nProxy-Connection: 
Keep-Alive\r\nHost: www.slashdot.org\r\n] [HTTP/1.1 301 Moved 
Permanently\r\nServer: nginx/1.13.12\r\nDate: Thu, 29 Nov 2018 18:13:06 
GMT\r\nContent-Type: text/html\r\nContent-Length: 186\r\nConnection: 
keep-alive\r\nLocation: https://www.slashdot.org/\r\n\r]
1543515186.902     48 192.168.3.1 TCP_TUNNEL/200 39 CONNECT 
www.slashdot.org:443 - HIER_DIRECT/216.105.38.15 - [User-Agent: 
"Mozilla/4.0 (compatible; MSIE 6.1; Windows NT 5.1)"\r\nHost: 
www.slashdot.org:443\r\n] []


---
the wget showed:

>  wget "http://www.slashdot.org"
--2018-11-29 10:13:06--  http://www.slashdot.org/
Resolving ishtar.sc.tlinx.org (ishtar.sc.tlinx.org)... 192.168.3.1
Connecting to ishtar.sc.tlinx.org 
(ishtar.sc.tlinx.org)|192.168.3.1|:8118... connected.
Proxy request sent, awaiting response... 301 Moved Permanently
Location: https://www.slashdot.org/ [following]
--2018-11-29 10:13:06--  https://www.slashdot.org/
Connecting to ishtar.sc.tlinx.org 
(ishtar.sc.tlinx.org)|192.168.3.1|:8118... connected.
Unable to establish SSL connection.
Converted 0 files in 0 seconds.

and curl shows:

>  curl --http1.0 "http://www.slashdot.org" -D headers.txt -o out_.htm
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  
Current
                                 Dload  Upload   Total   Spent    Left  
Speed
100   186  100   186    0     0   3358      0 --:--:-- --:--:-- 
--:--:--  3381
Ishtar:/tmp> cat headers.txt
HTTP/1.1 301 Moved Permanently
Server: nginx/1.13.12
Date: Thu, 29 Nov 2018 18:27:31 GMT
Content-Type: text/html
Content-Length: 186
Connection: close
Location: https://www.slashdot.org/
>  cat out_.htm
<html>
<head><title>301 Moved Permanently</title></head>
<body bgcolor="white">
<center><h1>301 Moved Permanently</h1></center>
<hr><center>nginx/1.13.12</center>
</body>
</html>










From rousskov at measurement-factory.com  Thu Nov 29 20:41:06 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 29 Nov 2018 13:41:06 -0700
Subject: [squid-users] how to go from connect/tunnel in squid4 ->GET
In-Reply-To: <5C00323F.8090806@tlinx.org>
References: <5BFFDCB6.8040404@tlinx.org>
 <4800e016-6636-1972-446b-f3d69c75f345@measurement-factory.com>
 <5C00323F.8090806@tlinx.org>
Message-ID: <0f022d21-af90-9ac4-5257-7400eb1e7c7b@measurement-factory.com>

On 11/29/18 11:38 AM, L A Walsh wrote:
 ?
>>> I bumped to squid4 a few months ago, but stil haven't gotten to the
>>> point where I can see and cache individual requests

> 2018/11/29 09:26:18 kid1| WARNING: No ssl_bump configured. Disabling
> ssl-bump on http_port 192.168.3.1:8118

You have not configured any ssl_bump rules. Thus, you are effectively
not using any SslBump features. All HTTPS traffic is simply tunneled
through without decryption/analysis.

Your final ssl_bump rule set may become completely different, but you
can start lab-testing with something simple like

    ssl_bump stare all
    ssl_bump bump all

For more rule examples and associated discussion, see
https://wiki.squid-cache.org/Features/SslPeekAndSplice


>  curl --http1.0 "http://www.slashdot.org" -D headers.txt -o out_.htm 

Please note that you should test SslBump features using https://...
URLs, not http://... URLs.

Alex.


From kevin at rentec.com  Thu Nov 29 22:53:22 2018
From: kevin at rentec.com (Kevin Kretz)
Date: Thu, 29 Nov 2018 17:53:22 -0500 (EST)
Subject: [squid-users] external ACL based on requested port?
Message-ID: <1218166078.7254349.1543532002018.JavaMail.zimbra@rentec.com>

Hi, 

I'm using an external ACL script to allow/limit access based on some factors including (authenticated) username, client IP, the domain of the requested URL. 

I'd also like to base the access on the port of the destination. Most would just be 80 or 443, but I'd like to limit/allow access to particular ports with the external script based on the other factors (a rule that would allow a connection to domain.com on port 80 from user 'user' coming from his IP address, for example), so a simple "acl allow_port port 80" would be too broad. 

It looks, though, like the <lp format code doesn't have a value until after the connection is made (or attempted) so I can't use it for this purpose. 

Is there a way to provide the desired port to the external ACL along with the other information? 


thanks 

Kevin 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181129/a1a027fc/attachment.htm>

From johnrefwe at mail.com  Thu Nov 29 23:16:45 2018
From: johnrefwe at mail.com (John Refwe)
Date: Fri, 30 Nov 2018 00:16:45 +0100
Subject: [squid-users] fi.se ssl bump error
References: <trinity-0e32b813-1745-4a5b-b3c8-159c8e2a9069-1536948675515@3c-app-mailcom-lxa08>
Message-ID: <trinity-ee4ed1a0-5c4b-457d-b6d5-3bb2b6bee668-1543533405662@3c-app-mailcom-lxa09>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181130/972019db/attachment.htm>

From rousskov at measurement-factory.com  Thu Nov 29 23:43:26 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 29 Nov 2018 16:43:26 -0700
Subject: [squid-users] external ACL based on requested port?
In-Reply-To: <1218166078.7254349.1543532002018.JavaMail.zimbra@rentec.com>
References: <1218166078.7254349.1543532002018.JavaMail.zimbra@rentec.com>
Message-ID: <24b9da16-1b30-0da9-575a-c814c00c64cc@measurement-factory.com>

On 11/29/18 3:53 PM, Kevin Kretz wrote:

> I'd also like to base the access on the port of the destination.

> Is there a way to provide the desired port to the external ACL along
> with the other information?

How about using one of the following %codes?

 [http::]>ru     Request URL from client
 [http::]>rP     Request URL port from client

You may need to handle default ports on your own, and you may need be
careful about requests on pinned connections (e.g., bumped HTTPS traffic
and connection-based authentication), but I think it should work in
principle.

Alex.


From squid3 at treenet.co.nz  Fri Nov 30 10:03:01 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Nov 2018 23:03:01 +1300
Subject: [squid-users] fi.se ssl bump error
In-Reply-To: <trinity-ee4ed1a0-5c4b-457d-b6d5-3bb2b6bee668-1543533405662@3c-app-mailcom-lxa09>
References: <trinity-0e32b813-1745-4a5b-b3c8-159c8e2a9069-1536948675515@3c-app-mailcom-lxa08>
 <trinity-ee4ed1a0-5c4b-457d-b6d5-3bb2b6bee668-1543533405662@3c-app-mailcom-lxa09>
Message-ID: <a8c9ae5f-eec5-8d2e-0917-48296119fe3f@treenet.co.nz>

On 30/11/18 12:16 pm, John Refwe wrote:
> Hi,
> ?
> I'm encountering a ssl bump error when going
> to?https://www.finansinspektionen.se/
> ?
> The error is similar in nature
> to?http://squid-web-proxy-cache.1019090.n4.nabble.com/Message-with-SSL-bump-with-a-specific-site-td4686867.html

TLS is complex protocol. "Similar to" is not enough to be accurate.

Did you do what I suggested in that thread to closer identify what was
actually happening?

> ?
> I took a packet capture and it didn't explain anything beyond what is
> discussed in the above thread. I could readily reproduce it with both
> squid 3.5 and squid 4.0. Interestingly, when I did an openssl s_client
> to the domain and then did pasted:?
> GET / HTTP/1.1
> Host: www.finansinspektionen.se
> Connection: keep-alive
> ?
> Things seemed to work. So, it doesn't immediately seem to be an openssl
> issue?
> ?

The test only shows that the default parameters your OpenSSL library
wants to use will work.

The parameters of the handshake outgoing from Squid is mediated by
settings the client uses and anything you have forced limits on through
squid.conf settings.


> Is anyone able to reproduce this / maybe provide a little bit of insight
> as to what might be happening?
> ?

Not from those clues.

Amos


From mkraju123 at gmail.com  Fri Nov 30 10:05:49 2018
From: mkraju123 at gmail.com (Raju M K)
Date: Fri, 30 Nov 2018 15:35:49 +0530
Subject: [squid-users] Caching Vimeo Videos
Message-ID: <CAGycgFh+RZq83hsTvGX3Q8M7Mf02pp8jrBX2Re9U87EYqHNjEQ@mail.gmail.com>

Need help on how to cache Vimeo videos under squid proxy.

-- 
Regards,
M K Raju.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181130/1bd6b1ac/attachment.htm>

From Antony.Stone at squid.open.source.it  Fri Nov 30 10:19:37 2018
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 30 Nov 2018 10:19:37 +0000
Subject: [squid-users] Caching Vimeo Videos
In-Reply-To: <CAGycgFh+RZq83hsTvGX3Q8M7Mf02pp8jrBX2Re9U87EYqHNjEQ@mail.gmail.com>
References: <CAGycgFh+RZq83hsTvGX3Q8M7Mf02pp8jrBX2Re9U87EYqHNjEQ@mail.gmail.com>
Message-ID: <201811301019.37579.Antony.Stone@squid.open.source.it>

On Friday 30 November 2018 at 10:05:49, Raju M K wrote:

> Need help on how to cache Vimeo videos under squid proxy.

Need info on what you tried already and how you identified it didn't work.

Antony.

-- 
Ramdisk is not an installation procedure.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From eliezer at ngtech.co.il  Fri Nov 30 10:22:42 2018
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Fri, 30 Nov 2018 12:22:42 +0200
Subject: [squid-users] Caching Vimeo Videos
In-Reply-To: <CAGycgFh+RZq83hsTvGX3Q8M7Mf02pp8jrBX2Re9U87EYqHNjEQ@mail.gmail.com>
References: <CAGycgFh+RZq83hsTvGX3Q8M7Mf02pp8jrBX2Re9U87EYqHNjEQ@mail.gmail.com>
Message-ID: <039901d48896$a0eb15a0$e2c140e0$@ngtech.co.il>

Hey,

 

There are two types of streams on Vimeo:

*	Simple mp4 files
*	HLS Dash streams

 

Example of links to mp4 files:

https://03-lvl3-pdl.vimeocdn.com/01/2370/1/36854018/84618512.mp4?expires=1543576693&token=x

https://03-lvl3-pdl.vimeocdn.com/01/2370/1/36854018/84618512.mp4?expires=1543576764 <https://03-lvl3-pdl.vimeocdn.com/01/2370/1/36854018/84618512.mp4?expires=1543576764&token=x> &token=x

 

These are almost static.

The HLS Dash streams needs more research which would look something like this:

 

Audio:

https://112skyfiregce-vimeo.akamaized.net/exp=1543576796~acl=%2F300817511%2F%2A~hmac=xyzh-mac1/300817511/sep/video/1152319175,1152319182,1152319179,1152319178,1152319177,1152319176/dash-audio.mp4

 

 

https://112skyfiregce-vimeo.akamaized.net/exp=1543576796~acl=%2F300817511%2F%2A~hmac=xyzh-mac1/300817511/sep/video/1152319175,1152319182,1152319179,1152319178,1152319177,1152319176/dash-audio.mp4

 

 

Video:

 

https://112skyfiregce-vimeo.akamaized.net/exp=1543576796~acl=%2F300817511%2F%2A~hmac=xyzh-mac1/300817511/sep/video/1152319175,1152319182,1152319179,1152319178,1152319177,1152319176/dash-video.mp4

 

PNG:

 

https://i.vimeocdn.com/filter/overlay?src0=https%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F252937377_1280x960.jpg <https://i.vimeocdn.com/filter/overlay?src0=https%3A%2F%2Fi.vimeocdn.com%2Fvideo%2F252937377_1280x960.jpg&src1=https%3A%2F%2Ff.vimeocdn.com%2Fimages_v6%2Fshare%2Fplay_icon_overlay.png> &src1=https%3A%2F%2Ff.vimeocdn.com%2Fimages_v6%2Fshare%2Fplay_icon_overlay.png

 

>From what I remember some of Vimeo videos have a download link on the video page.

To cache some of them you would need SSL-BUMP and a simple StoreID helper hat will unify the domains and the file name without some or all the query terms of the request URL.

I might be able to write an example but only in a week or more.

 

All The Bests,

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email:  <mailto:eliezer at ngtech.co.il> eliezer at ngtech.co.il



 

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Raju M K
Sent: Friday, November 30, 2018 12:06
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Caching Vimeo Videos

 

Need help on how to cache Vimeo videos under squid proxy.

-- 

Regards,
M K Raju.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181130/c9fd10f4/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11295 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181130/c9fd10f4/attachment.png>

From squid3 at treenet.co.nz  Fri Nov 30 10:23:14 2018
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Nov 2018 23:23:14 +1300
Subject: [squid-users] office365 - brand new endpoint management
 question!!
In-Reply-To: <CA+MX-S4c+e6sbo7gveJnNM1b1JOso8GUnyG4mBXuWgQyOHJFkQ@mail.gmail.com>
References: <CA+MX-S4c+e6sbo7gveJnNM1b1JOso8GUnyG4mBXuWgQyOHJFkQ@mail.gmail.com>
Message-ID: <c189973f-53c5-44f8-5e4f-05db9c7b639f@treenet.co.nz>

On 30/11/18 6:46 am, Jennifer Canterbury wrote:
> Did anyone see the changes to office365 IP and URLs management effective
> as of 11/27/18?? Microsoft appears to be be going to 3 different CDN
> networks (Akamai, MarkMonitor, and ExactTarget) for office365 connectivity.
> 
> I have a few questions:
> 1)? How many users do you think a single virtual squid server could
> handle?? 

Somewhere between 0 and infinity.

We do not measure HTTP agents in terms of "users" because one single
user can flood a network, or many tens of thousands per second be
handled easily. It depends entirely on what type of message any given
user is sending at any particular moment.

So HTTP is measured best in request-per-second (RPS). For most HTTP/1.1
traffic Squid can handle around 10-20K requests per second before
performance tuning needs to happen, after tuning twice that.


> 2)? How many "acl bypass_parent" URLs can my cache squid proxy server
> handle before browsing starts to slow?

What is being done with these URLs? Simply having them configured does
not affect browsing. Testing the same few values repeatedly likewise is
not noticable for the better ACL types.

Using something like a regex ACL or testing random URLs from the set
without any pattern to tune for all result in quite low numbers before
traffic slows.


Amos


From Sarfaraz.Ahmad at deshaw.com  Fri Nov 30 14:43:30 2018
From: Sarfaraz.Ahmad at deshaw.com (Ahmad, Sarfaraz)
Date: Fri, 30 Nov 2018 14:43:30 +0000
Subject: [squid-users] Why does Squid4 do socket(AF_NETLINK, SOCK_RAW,
 NETLINK_NETFILTER) = -1 EACCES (Permission denied) ?
Message-ID: <366f7648d49d44b0af51e3f2767be764@mbxpsc3.winmail.deshaw.com>

I think almost every time squid opens a TCP connection, It also tried to open a raw socket of type AF_NETLINK. Syscall pasted below.
All that I can make sense of this is that Squid is trying to engage with iptables subsystem somehow ?
I have SELinux enforcing and would like to know what Squid is trying to do before figuring out how to allow that.

socket(AF_INET, SOCK_STREAM, IPPROTO_IP) = 90
socket(AF_NETLINK, SOCK_RAW, NETLINK_NETFILTER) = -1 EACCES (Permission denied)

I am using WCCP and TLS interception with Squid 4.0.24 release. Everything works as expected except auditd is getting spammed with denial messages.
type=AVC msg=audit(1543478005.027:49455970): avc:  denied  { getattr } for  pid=13766 comm="squid" scontext=system_u:system_r:squid_t:s0 tcontext=sys
tem_u:system_r:squid_t:s0 tclass=netlink_socket

Any thoughts ?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181130/e83a0878/attachment.htm>

From squid-user at tlinx.org  Fri Nov 30 17:39:21 2018
From: squid-user at tlinx.org (L A Walsh)
Date: Fri, 30 Nov 2018 09:39:21 -0800
Subject: [squid-users] how to go from connect/tunnel in squid4 ->GET
In-Reply-To: <0f022d21-af90-9ac4-5257-7400eb1e7c7b@measurement-factory.com>
References: <5BFFDCB6.8040404@tlinx.org>
 <4800e016-6636-1972-446b-f3d69c75f345@measurement-factory.com>
 <5C00323F.8090806@tlinx.org>
 <0f022d21-af90-9ac4-5257-7400eb1e7c7b@measurement-factory.com>
Message-ID: <5C0175C9.50607@tlinx.org>

On 11/29/2018 12:41 PM, Alex Rousskov wrote:
> You have not configured any ssl_bump rules. Thus, you are effectively
> not using any SslBump features. All HTTPS traffic is simply tunneled
> through without decryption/analysis.
---
	Ok....I didn't do any of that in squid 3.x when I had something
working.  I had set my proxy up to have all protos use 1 port, 
like 8080 or such.  I placed a rootCA in all of the clients
that I wanted to use the proxy.  And then...it worked for 99%
of the sites.  Some things didn't work right, and maybe these 
highlight areas of misconfiguration -- most notably, Opera and
Google sites often failed to connect.  FF-derivative Palemoon
did work with google as did explorer.  I think opera was more
up-to-date with best-practices for encryption usage.

	For sites that I needed that didn't work or for sites
I wanted to remain encrypted (bank, forexample), I'd have use
a straight through connect+tunnel.

	Where were the ssl_bump options set in 3.x.  I thought
the 'ssl-bump' keyword in the http_port options enabled the bumping.

	Did it work that way in 3.x and now just doesn't work
that way in 4.x?

	I'm wanting to know why the old setup worked (mostly)
while the 4.x version seems to be missing "basic bumping"
that you highlighted.



> Please note that you should test SslBump features using https://...
> URLs, not http://... URLs.
---
	Only started with http addresses that I new redirected
to https.


What is the 'ssl-bump' option for in the http_port statement?
It seems like it it a little confusing.

Thanks much!
-linda


From kalicecaprice at gmail.com  Fri Nov 30 19:07:58 2018
From: kalicecaprice at gmail.com (kalice caprice)
Date: Fri, 30 Nov 2018 20:07:58 +0100
Subject: [squid-users] Fwd: ERROR: http_port or ACL larger than 65536 (short
	type)
In-Reply-To: <CAAvX7kN0kS-JzNcDYopnOPqxUMeXx63aBTEMH2VV9LRG9PVzPA@mail.gmail.com>
References: <CAAvX7kN0kS-JzNcDYopnOPqxUMeXx63aBTEMH2VV9LRG9PVzPA@mail.gmail.com>
Message-ID: <CAAvX7kNmZ4e7d=2LGPoiqyYZMvk1J-97P60O7jZ9nt2ZpHEodg@mail.gmail.com>

Hello,

Inside my squid.conf I'm setting up ACL like this:

http_port 0.0.0.0:20740 name=20740
acl ip10740 myportname 20740

and then

tcp_outgoing_address x.x.x.x ip10740

I've got over 65536 (about 80k) ACL inside my squid.conf and squid throws
this error:

ERROR: The value '65536' is larger than the type 'short'.

Well, that's really unfortunate, I'm good at reading C language, but does
anyone know whether there is a workaround without having to dig into the
code to change variable type of if not, what variable and where should I
change it ?

I'm afraid this could break things but it's not like I've got many choices
at the current state.

Thanks!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181130/4ce84d57/attachment.htm>

From Antony.Stone at squid.open.source.it  Fri Nov 30 18:17:32 2018
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 30 Nov 2018 18:17:32 +0000
Subject: [squid-users] Fwd: ERROR: http_port or ACL larger than 65536
	(short type)
In-Reply-To: <CAAvX7kNmZ4e7d=2LGPoiqyYZMvk1J-97P60O7jZ9nt2ZpHEodg@mail.gmail.com>
References: <CAAvX7kN0kS-JzNcDYopnOPqxUMeXx63aBTEMH2VV9LRG9PVzPA@mail.gmail.com>
 <CAAvX7kNmZ4e7d=2LGPoiqyYZMvk1J-97P60O7jZ9nt2ZpHEodg@mail.gmail.com>
Message-ID: <201811301817.32706.Antony.Stone@squid.open.source.it>

On Friday 30 November 2018 at 19:07:58, kalice caprice wrote:

> Hello,
> 
> Inside my squid.conf I'm setting up ACL like this:
> 
> http_port 0.0.0.0:20740 name=20740

So, you're using the name to represent the port number...

> acl ip10740 myportname 20740
> 
> and then
> 
> tcp_outgoing_address x.x.x.x ip10740
> 
> I've got over 65536

Well, that'll be a problem, then...

> (about 80k) ACL inside my squid.conf and squid throws this error:
> 
> ERROR: The value '65536' is larger than the type 'short'.

Indeed.  That's how many TCP port numbers you get to play with.

> Well, that's really unfortunate, I'm good at reading C language, but does
> anyone know whether there is a workaround without having to dig into the
> code to change variable type of if not, what variable and where should I
> change it ?

You'd need to change the way TCP networking works (and, no, that's not 
possible).

> I'm afraid this could break things but it's not like I've got many choices
> at the current state.

What are you really trying to achieve by defining 80,000 different port numbers 
in your ACLs?


Antony.

-- 
The Royal Society for the Prevention of Cruelty to Animals was formed in 1824.
The National Society for the Prevention of Cruelty to Children was not formed 
until 1884.
That says something about the British.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From rousskov at measurement-factory.com  Fri Nov 30 18:48:45 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 30 Nov 2018 11:48:45 -0700
Subject: [squid-users] how to go from connect/tunnel in squid4 ->GET
In-Reply-To: <5C0175C9.50607@tlinx.org>
References: <5BFFDCB6.8040404@tlinx.org>
 <4800e016-6636-1972-446b-f3d69c75f345@measurement-factory.com>
 <5C00323F.8090806@tlinx.org>
 <0f022d21-af90-9ac4-5257-7400eb1e7c7b@measurement-factory.com>
 <5C0175C9.50607@tlinx.org>
Message-ID: <079271ef-f391-9a04-04b8-a2c17e34b5d6@measurement-factory.com>

On 11/30/18 10:39 AM, L A Walsh wrote:
> On 11/29/2018 12:41 PM, Alex Rousskov wrote:
>> You have not configured any ssl_bump rules. Thus, you are effectively
>> not using any SslBump features. All HTTPS traffic is simply tunneled
>> through without decryption/analysis.

> Where were the ssl_bump options set in 3.x.

Not sure I understand the question: The location of ssl_bump directives
has not changed. They are and have always been squid.conf directives. In
modern Squids, they exact location within squid.conf does not matter
(but their order does).


> I thought
> the 'ssl-bump' keyword in the http_port options enabled the bumping.

It enables SslBump processing, which may or may not include bumping
connections (depending on the matching ssl_bump rule and other factors).

All modern Squid versions need ssl_bump rules. It is _possible_ that
(but I do not remember whether) omitting those rules worked by accident
in some older Squid versions. You should use explicit ssl_bump rules in
any modern Squid version.


> Did it work that way in 3.x and now just doesn't work
> that way in 4.x?

I do not know or do not remember. And 3.x is a large range; things may
have changed from v3.1 to v3.5... However, again, explicit ssl_bump
rules should be used in any version that supports ssl_bump directive.


> ????I'm wanting to know why the old setup worked (mostly)
> while the 4.x version seems to be missing "basic bumping"
> that you highlighted.

I understand that you want to know that. I cannot spend more free cycles
on this (secondary) question/investigation. FWIW, whether your old setup
"worked" or not, it was wrong.


> What is the 'ssl-bump' option for in the http_port statement?

To tell Squid that the corresponding http_port should pay the cost (and
take the risks) of SslBump processing (validating relevant port
configuration options, creating associated SSL structures at start time,
checking ssl_bump rules at runtime, etc.).

In many Squid deployments, only certain ports do SslBump. Consider
traffic on the other ports: What should happen to it when it matches a,
say, "ssl_bump bump" rule? The only correct answer is ... not to ask
that question in the first place! An ssl-bump flag on a _port line
allows us to avoid that question (and all the other risks/expenses
associated with SslBump).


HTH,

Alex.


From wirecutter at shadycloud.com  Fri Nov 30 18:51:45 2018
From: wirecutter at shadycloud.com (Wire Cutter)
Date: Fri, 30 Nov 2018 13:51:45 -0500
Subject: [squid-users] Question on Many Clients to Many Proxy Lists
In-Reply-To: <a7c6a340-33df-93a3-7894-a033d3c6c7a8@measurement-factory.com>
References: <CAPL=MgeZVVAohdfXe3q8WDdhsjs78P_QL=xoAbMc8BHQyKTnog@mail.gmail.com>
 <a7c6a340-33df-93a3-7894-a033d3c6c7a8@measurement-factory.com>
Message-ID: <CAPL=MgfNnTD2G0C2oR64r4AQotCu1XaZunn-GgWRpSrSqBsmqg@mail.gmail.com>

So thats exactly what I did.

#Rules for Peer group - list 1
       cache_peer_access peerA1 allow port_8080
       cache_peer_access peerA2 allow port_8080
       cache_peer_access peerA3 allow port_8080
       cache_peer_access peerA4 allow port_8080

#cache_peer
        cache_peer 192.168.1.2 parent 8800 0 round-robin no-query
name=peerA1
        cache_peer 192.168.2.2 parent 8800 0 round-robin no-query
name=peerA2
        cache_peer 192.168.2.5 parent 8800 0 round-robin no-query
name=peerA3
        cache_peer 192.168.2.6  parent 8800 0 round-robin no-query
name=peerA4

Then this is the error I get when I start the service

Nov 30 18:38:11 ubuntu systemd[1]: Starting LSB: Squid HTTP Proxy version
3.x...
Nov 30 18:38:11 ubuntu squid[13974]: Bungled /etc/squid/squid.conf line
3148: cache_peer_access peerA1 allow port_8080
Nov 30 18:38:11 ubuntu squid[13980]: Bungled /etc/squid/squid.conf line
3148: cache_peer_access peerA1 allow port_8080
Nov 30 18:38:11 ubuntu squid[13957]:  * FATAL: Bungled
/etc/squid/squid.conf line 3148: cache_peer_access peerA1 allow port_8080
Nov 30 18:38:11 ubuntu systemd[1]: squid.service: Control process exited,
code=exited status=3
Nov 30 18:38:11 ubuntu systemd[1]: squid.service: Failed with result
'exit-code'.
Nov 30 18:38:11 ubuntu systemd[1]: Failed to start LSB: Squid HTTP Proxy
version 3.x.



On Thu, Nov 29, 2018 at 10:44 AM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 11/29/18 7:57 AM, Wire Cutter wrote:
>
> > I?ve created 4 ports for clients to talk to, then created ACL lists for
> > those ports.  From there I?ve tried (and failed) to create naming groups
> > for cacheing peers, then added those to ACLs and it fails. Any ideas?
>
> Use cache_peer_access to allow http_port X traffic (and only that
> traffic) to peer group Y:
>
>   # rules for peer group A
>   cache_peer_access peerA1 allow receivedOnPortForPeersA
>   cache_peer_access peerA2 allow receivedOnPortForPeersA
>   cache_peer_access peerA3 allow receivedOnPortForPeersA
>   ...
>   # rules for peer group B
>   cache_peer_access peerB1 allow receivedOnPortForPeersB
>   cache_peer_access peerB2 allow receivedOnPortForPeersB
>   ...
>
>
> Depending on your traffic and needs, you may also need to allow
> non-hierarchical requests to go to peer:
>
>   nonhierarchical_direct off
>
> and/or to prohibit direct connections for portX:
>
>   never_direct allow receivedOnPortForPeersA
>   never_direct allow receivedOnPortForPeersB
>
>
> Once you get this working, please make Squid documentation improvements
> that would have allowed you to figure this out on your own.
>
>
> HTH,
>
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
_________________________________________________________________________________

This transmission may contain information that is privileged, confidential
and exempt from disclosure under applicable law.  If you are not the
intended recipient, you are hereby notified that any disclosure, copying,
distribution, or use of the information contained herein (including any
reliance thereon) is STRICTLY PROHIBITED.  If you received this
transmission in error, please immediately contact the sender and destroy
the material in its entirety, whether in electronic or hard copy format.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181130/bd848a29/attachment.htm>

From rousskov at measurement-factory.com  Fri Nov 30 19:17:20 2018
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 30 Nov 2018 12:17:20 -0700
Subject: [squid-users] Question on Many Clients to Many Proxy Lists
In-Reply-To: <CAPL=MgfNnTD2G0C2oR64r4AQotCu1XaZunn-GgWRpSrSqBsmqg@mail.gmail.com>
References: <CAPL=MgeZVVAohdfXe3q8WDdhsjs78P_QL=xoAbMc8BHQyKTnog@mail.gmail.com>
 <a7c6a340-33df-93a3-7894-a033d3c6c7a8@measurement-factory.com>
 <CAPL=MgfNnTD2G0C2oR64r4AQotCu1XaZunn-GgWRpSrSqBsmqg@mail.gmail.com>
Message-ID: <9ec1a695-175c-93ff-b9aa-bb241fd77871@measurement-factory.com>

On 11/30/18 11:51 AM, Wire Cutter wrote:

> cache_peer_access peerA1 allow port_8080
> 
> cache_peer 192.168.1.2 parent 8800 0 round-robin no-query name=peerA1


> Then this is the error I get when I start the service?
> 
> Bungled /etc/squid/squid.conf line 3148: cache_peer_access peerA1 allow port_8080

Did you define peerA1 and port_8080 before (you used them on) line 3148?
If not, you should.

Alex.


> On Thu, Nov 29, 2018 at 10:44 AM Alex Rousskov wrote:
> 
>     On 11/29/18 7:57 AM, Wire Cutter wrote:
> 
>     > I?ve created 4 ports for clients to talk to, then created ACL
>     lists for
>     > those ports.? From there I?ve tried (and failed) to create naming
>     groups
>     > for cacheing peers, then added those to ACLs and it fails. Any ideas?
> 
>     Use cache_peer_access to allow http_port X traffic (and only that
>     traffic) to peer group Y:
> 
>     ? # rules for peer group A
>     ? cache_peer_access peerA1 allow receivedOnPortForPeersA
>     ? cache_peer_access peerA2 allow receivedOnPortForPeersA
>     ? cache_peer_access peerA3 allow receivedOnPortForPeersA
>     ? ...
>     ? # rules for peer group B
>     ? cache_peer_access peerB1 allow receivedOnPortForPeersB
>     ? cache_peer_access peerB2 allow receivedOnPortForPeersB
>     ? ...
> 
> 
>     Depending on your traffic and needs, you may also need to allow
>     non-hierarchical requests to go to peer:
> 
>     ? nonhierarchical_direct off
> 
>     and/or to prohibit direct connections for portX:
> 
>     ? never_direct allow receivedOnPortForPeersA
>     ? never_direct allow receivedOnPortForPeersB
> 
> 
>     Once you get this working, please make Squid documentation improvements
>     that would have allowed you to figure this out on your own.
> 
> 
>     HTH,
> 
>     Alex.
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> 
> -- 
> _________________________________________________________________________________
> 
> This transmission may contain information that is privileged,
> confidential and exempt from disclosure under applicable law.? If you
> are not the intended recipient, you are hereby notified that any
> disclosure, copying, distribution, or use of the information contained
> herein (including any reliance thereon) is STRICTLY PROHIBITED.? If you
> received this transmission in error, please immediately contact the
> sender and destroy the material in its entirety, whether in electronic
> or hard copy format.?



From wirecutter at shadycloud.com  Fri Nov 30 19:57:08 2018
From: wirecutter at shadycloud.com (Wire Cutter)
Date: Fri, 30 Nov 2018 14:57:08 -0500
Subject: [squid-users] Question on Many Clients to Many Proxy Lists
In-Reply-To: <9ec1a695-175c-93ff-b9aa-bb241fd77871@measurement-factory.com>
References: <CAPL=MgeZVVAohdfXe3q8WDdhsjs78P_QL=xoAbMc8BHQyKTnog@mail.gmail.com>
 <a7c6a340-33df-93a3-7894-a033d3c6c7a8@measurement-factory.com>
 <CAPL=MgfNnTD2G0C2oR64r4AQotCu1XaZunn-GgWRpSrSqBsmqg@mail.gmail.com>
 <9ec1a695-175c-93ff-b9aa-bb241fd77871@measurement-factory.com>
Message-ID: <CAPL=MgdCgDwrFUwxeAni2ZKe5mi0qRE+Svb6i2UZqzCyX6WT=g@mail.gmail.com>

Yes both were before the cache, but I wasn't calling the correct group in
the ACL, which caused the issue.


Thanks for you help.

Now to figure out why it's slow

On Fri, Nov 30, 2018 at 2:17 PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 11/30/18 11:51 AM, Wire Cutter wrote:
>
> > cache_peer_access peerA1 allow port_8080
> >
> > cache_peer 192.168.1.2 parent 8800 0 round-robin no-query name=peerA1
>
>
> > Then this is the error I get when I start the service
> >
> > Bungled /etc/squid/squid.conf line 3148: cache_peer_access peerA1 allow
> port_8080
>
> Did you define peerA1 and port_8080 before (you used them on) line 3148?
> If not, you should.
>
> Alex.
>
>
> > On Thu, Nov 29, 2018 at 10:44 AM Alex Rousskov wrote:
> >
> >     On 11/29/18 7:57 AM, Wire Cutter wrote:
> >
> >     > I?ve created 4 ports for clients to talk to, then created ACL
> >     lists for
> >     > those ports.  From there I?ve tried (and failed) to create naming
> >     groups
> >     > for cacheing peers, then added those to ACLs and it fails. Any
> ideas?
> >
> >     Use cache_peer_access to allow http_port X traffic (and only that
> >     traffic) to peer group Y:
> >
> >       # rules for peer group A
> >       cache_peer_access peerA1 allow receivedOnPortForPeersA
> >       cache_peer_access peerA2 allow receivedOnPortForPeersA
> >       cache_peer_access peerA3 allow receivedOnPortForPeersA
> >       ...
> >       # rules for peer group B
> >       cache_peer_access peerB1 allow receivedOnPortForPeersB
> >       cache_peer_access peerB2 allow receivedOnPortForPeersB
> >       ...
> >
> >
> >     Depending on your traffic and needs, you may also need to allow
> >     non-hierarchical requests to go to peer:
> >
> >       nonhierarchical_direct off
> >
> >     and/or to prohibit direct connections for portX:
> >
> >       never_direct allow receivedOnPortForPeersA
> >       never_direct allow receivedOnPortForPeersB
> >
> >
> >     Once you get this working, please make Squid documentation
> improvements
> >     that would have allowed you to figure this out on your own.
> >
> >
> >     HTH,
> >
> >     Alex.
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>
> >     http://lists.squid-cache.org/listinfo/squid-users
> >
> >
> >
> > --
> >
> _________________________________________________________________________________
> >
> > This transmission may contain information that is privileged,
> > confidential and exempt from disclosure under applicable law.  If you
> > are not the intended recipient, you are hereby notified that any
> > disclosure, copying, distribution, or use of the information contained
> > herein (including any reliance thereon) is STRICTLY PROHIBITED.  If you
> > received this transmission in error, please immediately contact the
> > sender and destroy the material in its entirety, whether in electronic
> > or hard copy format.
>
>

-- 
_________________________________________________________________________________

This transmission may contain information that is privileged, confidential
and exempt from disclosure under applicable law.  If you are not the
intended recipient, you are hereby notified that any disclosure, copying,
distribution, or use of the information contained herein (including any
reliance thereon) is STRICTLY PROHIBITED.  If you received this
transmission in error, please immediately contact the sender and destroy
the material in its entirety, whether in electronic or hard copy format.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20181130/43d5c901/attachment.htm>

