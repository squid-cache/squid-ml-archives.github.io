From squid3 at treenet.co.nz  Sun Dec  1 08:15:30 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 1 Dec 2019 21:15:30 +1300
Subject: [squid-users] Squid 4.9 Client IP PTR lookup on connect
In-Reply-To: <ab0880df-fa27-69b7-46f0-9d86ae1fad19@measurement-factory.com>
References: <112604241575042589@vla1-b1f71bfb4f06.qloud-c.yandex.net>
 <24104547-ce2e-2150-5d25-d6b1165bc972@treenet.co.nz>
 <ab0880df-fa27-69b7-46f0-9d86ae1fad19@measurement-factory.com>
Message-ID: <f09397c0-34d7-a8b6-3475-6da8e789ce54@treenet.co.nz>

On 1/12/19 6:31 am, Alex Rousskov wrote:
> On 11/29/19 11:43 AM, Amos Jeffries wrote:
> 
>> The PTR should only need to be looked up at all if something needs to
>> use the client FQDN. Usually that is logging. I suspect your build
>> auto-enabled ICAP features which uses the FQDN for icap_log.
> 
> ... but icap_log is disabled by default, even in Squid builds that have
> ICAP support enabled, right? If a disabled icap_log triggers DNS
> lookups, there is a Squid bug we should fix.

I thought so. But something is turning on log_fqdn, there are no ACLs or
logformat lines in that config. Which leaves us the default settings, of
which only icap_log format uses %<A these days.

> 
> FWIW, the easiest way to figure out what triggered the lookup could be
> to start Squid in a debugger, and then, before starting the test
> transaction, add a breakpoint for fqdncache_nbgethostbyaddr. Post a
> stack trace from that function (when it is triggered after the
> httpAccept line is logged as shown in your cache.log).

Seconded.

Amos


From robertkwild at gmail.com  Mon Dec  2 11:19:44 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Mon, 2 Dec 2019 11:19:44 +0000
Subject: [squid-users] ssl negotiation error
Message-ID: <CAGU_CiLdbMjQU3ibtxOZCM7R1yWUXJkrKF484fT5yKJoLyQHnw@mail.gmail.com>

hi all,

managed to get squid to work at last and i can browse all website when my
browser is going through the proxy but when i run squid i see a bunch of
errors and i havnt got a clue what its about -

Error negotiating SSL connection on FD 46:
error:00000001:lib(0):func(0):reason(1) (1/0)

its weird as its still allowing me to browse the websites while its showing
this error

any help please would be much appreciated

thanks,
rob

-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191202/4656fb0e/attachment.htm>

From vieridipaola at gmail.com  Mon Dec  2 14:46:25 2019
From: vieridipaola at gmail.com (Vieri Di Paola)
Date: Mon, 2 Dec 2019 15:46:25 +0100
Subject: [squid-users] reverse proxy and HTTP redirects
Message-ID: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>

Hi,

I configured a reverse proxy with something like this:

https_port 10.215.145.81:50443 accel cert=/etc/ssl/whatever.cer
key=/etc/ssl/whatever_key_nopassphrase.pem
options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,CIPHER_SERVER_PREFERENCE,No_Compression
cipher=ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA25
6:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:DES-CBC3-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4
tls-dh=/etc/ssl/whatever/dh2048.pem defaultsite=whatever.org

cache_peer 10.215.248.40 parent 8080 0 no-query originserver
login=PASS front-end-https=on name=httpsServer

[etc]

I can load the web portal just fine from a web client connecting to
10.215.145.81:50443. However, the web server then sends an HTTP
redirection to an HTTP URL which is something like
http://10.215.248.40:8080/whatever (in other words, the page is hosted
on the same server). That breaks the browsing experience (connection
reset).

If I can't modify the server code at 10.215.248.40, is there a
workaround for this?

Thanks,

Vieri


From 0xff1f at gmail.com  Mon Dec  2 17:34:31 2019
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Mon, 2 Dec 2019 20:34:31 +0300
Subject: [squid-users] debug headers between squid --> website
Message-ID: <05CAD3AE-6AEE-4456-BF99-83531188A4D9@gmail.com>

Hello Tem ,

How can i debug Headers that is between squid??> website request made 

say we have this simple topology 

pc ??squid ?? website


?> As an example if i run curl  some website   from my device connecting to squid proxy .


$ curl -x  x.x.8.187:xx433 -U abc:abc ifconfig.io/ip  -vv
*   Trying 108.61.8.187...
* TCP_NODELAY set
* Connected to x.x.8.187 (x.x.8.187) port xx433 (#0)
* Proxy auth using Basic with user 'ben'
> GET http://ifconfig.io/ip HTTP/1.1
> Host: ifconfig.io
> Proxy-Authorization: Basic YmVuOmJlbg==
> User-Agent: curl/7.54.0
> Accept: */*
> Proxy-Connection: Keep-Alive
> 
< HTTP/1.1 200 OK
< Date: Mon, 02 Dec 2019 17:30:42 GMT
< Content-Type: text/plain; charset=utf-8
< Content-Length: 40
< Set-Cookie: __cfduid=d639c4bd01a9f8c32f0de7cb09f40671575307842; expires=Wed, 01-Jan-20 17:30:42 GMT; path=/; domain=.ifconfig.io; HttpOnly
< CF-Cache-Status: DYNAMIC
< Alt-Svc: h3-23=":443"; ma=86400
< Server: cloudflare
< CF-RAY: 53ef07bd8d28efed-EWR
< X-Cache: MISS from squid
< Via: 1.1 xyz (squid)
< Connection: keep-alive
< 
11.22.33.44
* Connection #0 to host x.x.8.187 left intact


i believe this is negotiation  above is from  pc <?> squid .


How can i see this kind of debug or header in case of squid? website level ?

i need to see what squid send headers to website 
and what website reply o squid .



Thanks 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191202/07811df3/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Dec  2 17:58:26 2019
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 2 Dec 2019 18:58:26 +0100
Subject: [squid-users] debug headers between squid --> website
In-Reply-To: <05CAD3AE-6AEE-4456-BF99-83531188A4D9@gmail.com>
References: <05CAD3AE-6AEE-4456-BF99-83531188A4D9@gmail.com>
Message-ID: <201912021858.26773.Antony.Stone@squid.open.source.it>

On Monday 02 December 2019 at 18:34:31, Ahmad Alzaeem wrote:

> Hello Tem ,
> 
> How can i debug Headers that is between squid??> website request made

Run a packet sniffer (tcpdump, wireshark, tshark...) on the Squid server, 
looking at the external interface (ie: the one pointing to the website/s).

> i need to see what squid send headers to website
> and what website reply o squid .

So long as you're doing HTTP (as per your example) and not HTTPS, any packet 
sniffer and protocol analyser (wireshark is *very* good at this) will show you 
this quite easily.


Antony.

-- 
Atheism is a non-prophet-making organisation.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From 0xff1f at gmail.com  Mon Dec  2 18:31:43 2019
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Mon, 2 Dec 2019 21:31:43 +0300
Subject: [squid-users] debug headers between squid --> website
In-Reply-To: <201912021858.26773.Antony.Stone@squid.open.source.it>
References: <201912021858.26773.Antony.Stone@squid.open.source.it>
Message-ID: <B614BF27-21F6-4AEC-9A31-9AA4B7504549@gmail.com>

Thank you for that .

Is it possible to run it from squid ?

Thanks 

Sent from my iPhone

> On Dec 2, 2019, at 8:58 PM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
> 
> ?On Monday 02 December 2019 at 18:34:31, Ahmad Alzaeem wrote:
> 
>> Hello Tem ,
>> 
>> How can i debug Headers that is between squid??> website request made
> 
> Run a packet sniffer (tcpdump, wireshark, tshark...) on the Squid server, 
> looking at the external interface (ie: the one pointing to the website/s).
> 
>> i need to see what squid send headers to website
>> and what website reply o squid .
> 
> So long as you're doing HTTP (as per your example) and not HTTPS, any packet 
> sniffer and protocol analyser (wireshark is *very* good at this) will show you 
> this quite easily.
> 
> 
> Antony.
> 
> -- 
> Atheism is a non-prophet-making organisation.
> 
>                                                   Please reply to the list;
>                                                         please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From Antony.Stone at squid.open.source.it  Mon Dec  2 18:47:53 2019
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 2 Dec 2019 19:47:53 +0100
Subject: [squid-users] debug headers between squid --> website
In-Reply-To: <B614BF27-21F6-4AEC-9A31-9AA4B7504549@gmail.com>
References: <201912021858.26773.Antony.Stone@squid.open.source.it>
 <B614BF27-21F6-4AEC-9A31-9AA4B7504549@gmail.com>
Message-ID: <201912021947.53825.Antony.Stone@squid.open.source.it>

On Monday 02 December 2019 at 19:31:43, Ahmad Alzaeem wrote:

> Thank you for that .
> 
> Is it possible to run it from squid ?

I don't understand that question.

You start Squid; it listens for incoming connections and sends them on to the 
external servers (and gets the responses etc, etc...)

At the same time, you run the packet sniffer on the machine where Squid is 
running, and it collects all the traffic passing between Squid and the rest of 
the Internet.

Then you make your request/s with a browser (or wget, curl, as you wish), and 
let Squid do its thing, and let the packet sniffer capture what happened.

After it's all over, you then have a packet capture which you can analyse (eg: 
using wireshark) to find out what Squid sent to the server/s, and what came 
back again.


Antony.

> > On Dec 2, 2019, at 8:58 PM, Antony Stone
> > <Antony.Stone at squid.open.source.it> wrote:
> > 
> > ?On Monday 02 December 2019 at 18:34:31, Ahmad Alzaeem wrote:
> >> Hello Tem ,
> >> 
> >> How can i debug Headers that is between squid??> website request made
> > 
> > Run a packet sniffer (tcpdump, wireshark, tshark...) on the Squid server,
> > looking at the external interface (ie: the one pointing to the
> > website/s).
> > 
> >> i need to see what squid send headers to website
> >> and what website reply o squid .
> > 
> > So long as you're doing HTTP (as per your example) and not HTTPS, any
> > packet sniffer and protocol analyser (wireshark is *very* good at this)
> > will show you this quite easily.
> > 
> > 
> > Antony.

-- 
"It wouldn't be a good idea to talk about him behind his back in front of 
him."

 - murble

                                                   Please reply to the list;
                                                         please *don't* CC me.


From rousskov at measurement-factory.com  Mon Dec  2 19:03:23 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 2 Dec 2019 14:03:23 -0500
Subject: [squid-users] debug headers between squid --> website
In-Reply-To: <B614BF27-21F6-4AEC-9A31-9AA4B7504549@gmail.com>
References: <201912021858.26773.Antony.Stone@squid.open.source.it>
 <B614BF27-21F6-4AEC-9A31-9AA4B7504549@gmail.com>
Message-ID: <76579fdb-6e34-5406-06e0-1f1a91dc9a5c@measurement-factory.com>

On 12/2/19 1:31 PM, Ahmad Alzaeem wrote:

> Is it possible to run it from squid ?

Packet catpure is usually better, especially for plain HTTP traffic, but
you can also get raw HTTP headers in cache.log if you set debug_options
in squid.conf to ALL,2

Alex.


>> On Dec 2, 2019, at 8:58 PM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
>>
>> ?On Monday 02 December 2019 at 18:34:31, Ahmad Alzaeem wrote:
>>
>>> Hello Tem ,
>>>
>>> How can i debug Headers that is between squid??> website request made
>>
>> Run a packet sniffer (tcpdump, wireshark, tshark...) on the Squid server, 
>> looking at the external interface (ie: the one pointing to the website/s).
>>
>>> i need to see what squid send headers to website
>>> and what website reply o squid .
>>
>> So long as you're doing HTTP (as per your example) and not HTTPS, any packet 
>> sniffer and protocol analyser (wireshark is *very* good at this) will show you 
>> this quite easily.
>>
>>
>> Antony.
>>
>> -- 
>> Atheism is a non-prophet-making organisation.
>>
>>                                                   Please reply to the list;
>>                                                         please *don't* CC me.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From 0xff1f at gmail.com  Mon Dec  2 19:19:26 2019
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Mon, 2 Dec 2019 22:19:26 +0300
Subject: [squid-users] debug headers between squid --> website
In-Reply-To: <76579fdb-6e34-5406-06e0-1f1a91dc9a5c@measurement-factory.com>
References: <76579fdb-6e34-5406-06e0-1f1a91dc9a5c@measurement-factory.com>
Message-ID: <316B06A5-E0D3-4128-B98B-34C8E3EAB872@gmail.com>

Can I do same  thing for https ?

Thanks 

Sent from my iPhone

> On Dec 2, 2019, at 10:03 PM, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> ?On 12/2/19 1:31 PM, Ahmad Alzaeem wrote:
> 
>> Is it possible to run it from squid ?
> 
> Packet catpure is usually better, especially for plain HTTP traffic, but
> you can also get raw HTTP headers in cache.log if you set debug_options
> in squid.conf to ALL,2
> 
> Alex.
> 
> 
>>>> On Dec 2, 2019, at 8:58 PM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
>>> 
>>> ?On Monday 02 December 2019 at 18:34:31, Ahmad Alzaeem wrote:
>>> 
>>>> Hello Tem ,
>>>> 
>>>> How can i debug Headers that is between squid??> website request made
>>> 
>>> Run a packet sniffer (tcpdump, wireshark, tshark...) on the Squid server, 
>>> looking at the external interface (ie: the one pointing to the website/s).
>>> 
>>>> i need to see what squid send headers to website
>>>> and what website reply o squid .
>>> 
>>> So long as you're doing HTTP (as per your example) and not HTTPS, any packet 
>>> sniffer and protocol analyser (wireshark is *very* good at this) will show you 
>>> this quite easily.
>>> 
>>> 
>>> Antony.
>>> 
>>> -- 
>>> Atheism is a non-prophet-making organisation.
>>> 
>>>                                                  Please reply to the list;
>>>                                                        please *don't* CC me.
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191202/fc4b8a57/attachment.htm>

From rousskov at measurement-factory.com  Mon Dec  2 19:31:14 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 2 Dec 2019 14:31:14 -0500
Subject: [squid-users] debug headers between squid --> website
In-Reply-To: <316B06A5-E0D3-4128-B98B-34C8E3EAB872@gmail.com>
References: <76579fdb-6e34-5406-06e0-1f1a91dc9a5c@measurement-factory.com>
 <316B06A5-E0D3-4128-B98B-34C8E3EAB872@gmail.com>
Message-ID: <e6467675-8cde-2446-36d5-705f79c0b4b0@measurement-factory.com>

On 12/2/19 2:19 PM, Ahmad Alzaeem wrote:
> Can I do same ?thing for https ?

Yes, you can. Squid logs CONNECT headers and also HTTP headers of
incoming and outgoing decrypted HTTPS requests. Squid does not see (and
cannot log) HTTP headers of encrypted traffic inside CONNECT tunnels
that are not bumped using the SslBump feature, of course.

Wireshark is often a better tool for header analysis because it makes it
easier to associate headers with connections and HTTP request-reply
exchanges. Wireshark can even handle encrypted-by-Squid traffic, but
that requires connection master keys that are not trivial to obtain.

Alex.


>> On Dec 2, 2019, at 10:03 PM, Alex Rousskov wrote:
>>
>> ?On 12/2/19 1:31 PM, Ahmad Alzaeem wrote:
>>
>>> Is it possible to run it from squid ?
>>
>> Packet catpure is usually better, especially for plain HTTP traffic, but
>> you can also get raw HTTP headers in cache.log if you set debug_options
>> in squid.conf to ALL,2
>>
>> Alex.
>>
>>
>>>> On Dec 2, 2019, at 8:58 PM, Antony Stone
>>>> <Antony.Stone at squid.open.source.it> wrote:
>>>>
>>>> ?On Monday 02 December 2019 at 18:34:31, Ahmad Alzaeem wrote:
>>>>
>>>>> Hello Tem ,
>>>>>
>>>>> How can i debug Headers that is between squid??> website request made
>>>>
>>>> Run a packet sniffer (tcpdump, wireshark, tshark...) on the Squid
>>>> server,
>>>> looking at the external interface (ie: the one pointing to the
>>>> website/s).
>>>>
>>>>> i need to see what squid send headers to website
>>>>> and what website reply o squid .
>>>>
>>>> So long as you're doing HTTP (as per your example) and not HTTPS,
>>>> any packet
>>>> sniffer and protocol analyser (wireshark is *very* good at this)
>>>> will show you
>>>> this quite easily.
>>>>
>>>>
>>>> Antony.
>>>>
>>>> -- 
>>>> Atheism is a non-prophet-making organisation.
>>>>
>>>> ?????????????????????????????????????????????????Please reply to the
>>>> list;
>>>> ???????????????????????????????????????????????????????please
>>>> *don't* CC me.
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users



From ahmed.zaeem at netstream.ps  Mon Dec  2 22:22:27 2019
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 3 Dec 2019 01:22:27 +0300
Subject: [squid-users] debug headers between squid --> website
In-Reply-To: <e6467675-8cde-2446-36d5-705f79c0b4b0@measurement-factory.com>
References: <76579fdb-6e34-5406-06e0-1f1a91dc9a5c@measurement-factory.com>
 <316B06A5-E0D3-4128-B98B-34C8E3EAB872@gmail.com>
 <e6467675-8cde-2446-36d5-705f79c0b4b0@measurement-factory.com>
Message-ID: <DE9F39D0-A6AA-4F81-AC7D-3659C573EE2A@netstream.ps>

Hi Alex ,

Thank you for your precious info .


You Said 
??
Yes, you can. Squid logs CONNECT headers and also HTTP headers of
incoming and outgoing decrypted HTTPS requests. Squid does not see (and
cannot log) HTTP headers of encrypted traffic inside CONNECT tunnels
that are not bumped using the SslBump feature, of course.
??


Can you tell me example of headers of ?Connect headers? and headers inside ? connect Tunnel ? ?



> On Dec 2, 2019, at 10:31 PM, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> Yes, you can. Squid logs CONNECT headers and also HTTP headers of
> incoming and outgoing decrypted HTTPS requests. Squid does not see (and
> cannot log) HTTP headers of encrypted traffic inside CONNECT tunnels
> that are not bumped using the SslBump feature, of course.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191203/ca764c53/attachment.htm>

From darren at ksn-systems.com  Mon Dec  2 23:17:11 2019
From: darren at ksn-systems.com (Darren Breeze)
Date: Tue, 03 Dec 2019 12:17:11 +1300
Subject: [squid-users] icap result caching in squid
In-Reply-To: <c6de8a70-e0d7-c6cc-b0bf-58902e34db66@measurement-factory.com>
References: <1e800569-1d1d-42d4-bad8-41a2100430d9@www.fastmail.com>
 <c6de8a70-e0d7-c6cc-b0bf-58902e34db66@measurement-factory.com>
Message-ID: <135d0e54-fc29-4eb0-b725-2b34d847100b@www.fastmail.com>

Thanks Alex.

That has given me the perspective I need.

I can modulate the response header Expires value via icap to get the job done when squid goes to cache it.


Darren B.

*Darren Breeze*
Director
*KSN Systems NZ Limited*
**E: *darren at ksn-systems.com*
**M:* +64 274 666 017*
**S:* dbinhk*

On Sun, Dec 1, 2019, at 6:22 AM, Alex Rousskov wrote:
> On 11/29/19 12:20 PM, Darren Breeze wrote:
> 
> > Some quick question about icap result caching in squid.
> > 
> > Does the returned Expires header control how long squid will cache the
> > result (for both a req and resp mod)?
> > 
> > Are the values that are cached keyed to the queried URL or is it cached
> > per user / url?
> 
> Squid only supports pre-cache vectoring points. Thus, bugs
> notwithstanding, post-ICAP headers should be treated (for caching
> purposes) as if Squid received the same adjusted HTTP message directly
> from an HTTP agent, and there were no ICAP modifications at all.
> 
> The above statement does not answer your question, but it changes that
> question from "How ICAP-set X affects caching?" to "How X affects
> caching?" -- a question that you may already know the answer to or, if
> you do not, a question that others on the list may be able to answer
> better or faster than I currently can.
> 
> 
> HTH,
> 
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are addressed. If you have received this email in error please notify the system manager. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. If you are not the intended recipient you are notified that disclosing, copying, distributing or taking any action in reliance on the contents of this information is strictly prohibited.



From squid3 at treenet.co.nz  Tue Dec  3 05:17:33 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 3 Dec 2019 18:17:33 +1300
Subject: [squid-users] icap result caching in squid
In-Reply-To: <135d0e54-fc29-4eb0-b725-2b34d847100b@www.fastmail.com>
References: <1e800569-1d1d-42d4-bad8-41a2100430d9@www.fastmail.com>
 <c6de8a70-e0d7-c6cc-b0bf-58902e34db66@measurement-factory.com>
 <135d0e54-fc29-4eb0-b725-2b34d847100b@www.fastmail.com>
Message-ID: <b83e7aa7-175a-e67f-c6ae-a0e73e4408ea@treenet.co.nz>

On 3/12/19 12:17 pm, Darren Breeze wrote:
> Thanks Alex.
> 
> That has given me the perspective I need.
> 
> I can modulate the response header Expires value via icap to get the job done when squid goes to cache it.
> 

Why are you needing to do this at all?

NP: please be aware that the changes you make to the HTTP headers affect
*all* downstream caches, no just your Squid.

Amos


From squid3 at treenet.co.nz  Tue Dec  3 05:32:57 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 3 Dec 2019 18:32:57 +1300
Subject: [squid-users] reverse proxy and HTTP redirects
In-Reply-To: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>
References: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>
Message-ID: <864f0d16-3d9a-6f97-f53d-c622da5f8058@treenet.co.nz>

On 3/12/19 3:46 am, Vieri Di Paola wrote:
> Hi,
> 
> I configured a reverse proxy with something like this:
> 
> https_port 10.215.145.81:50443 accel cert=/etc/ssl/whatever.cer
> key=/etc/ssl/whatever_key_nopassphrase.pem
> options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,CIPHER_SERVER_PREFERENCE,No_Compression
> cipher=ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA25
> 6:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:DES-CBC3-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4
> tls-dh=/etc/ssl/whatever/dh2048.pem defaultsite=whatever.org


NP: you have not configured any Elliptic Curve to be used, so all those
EC ciphers will not be usable. Also you configured some DES based
ciphers and then disable DES.


> 
> cache_peer 10.215.248.40 parent 8080 0 no-query originserver
> login=PASS front-end-https=on name=httpsServer
> 
> [etc]
> 
> I can load the web portal just fine from a web client connecting to
> 10.215.145.81:50443. However, the web server then sends an HTTP
> redirection to an HTTP URL which is something like
> http://10.215.248.40:8080/whatever (in other words, the page is hosted
> on the same server). That breaks the browsing experience (connection
> reset).
> 
> If I can't modify the server code at 10.215.248.40, is there a
> workaround for this?

You do not need to modify code anywhere.

The problem is that the client is talking to port 50443 and the service
is expecting port 8080 in URLs.

The best solution is to have the server and Squid using the same port
number. Preferably 443 for HTTPS services.

Alternatively you might be able to use the vport= option on https_port
to set the URL port to 8080. However, this affects *all* inbound traffic
at that port and any embedded URLs the service sends the client will
remain broken (contain port 8080).


Amos


From squid3 at treenet.co.nz  Tue Dec  3 05:53:28 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 3 Dec 2019 18:53:28 +1300
Subject: [squid-users] ssl negotiation error
In-Reply-To: <CAGU_CiLdbMjQU3ibtxOZCM7R1yWUXJkrKF484fT5yKJoLyQHnw@mail.gmail.com>
References: <CAGU_CiLdbMjQU3ibtxOZCM7R1yWUXJkrKF484fT5yKJoLyQHnw@mail.gmail.com>
Message-ID: <f9f02678-f5d0-c2e3-3c84-5a2177970590@treenet.co.nz>

On 3/12/19 12:19 am, robert k Wild wrote:
> hi all,
> 
> managed to get squid to work at last and i can browse all website when
> my browser is going through the proxy but when i run squid i see a bunch
> of errors and i havnt got a clue what its about -
> 

You will need a packet trace on the Squid to server connections to see
what is going on there.

Amos


From vieridipaola at gmail.com  Tue Dec  3 09:11:53 2019
From: vieridipaola at gmail.com (Vieri Di Paola)
Date: Tue, 3 Dec 2019 10:11:53 +0100
Subject: [squid-users] reverse proxy and HTTP redirects
In-Reply-To: <864f0d16-3d9a-6f97-f53d-c622da5f8058@treenet.co.nz>
References: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>
 <864f0d16-3d9a-6f97-f53d-c622da5f8058@treenet.co.nz>
Message-ID: <CABLYT9iqP6daryAHizn8OSUUcQTx9z2nZaQZnPaJpO7dgC-=EA@mail.gmail.com>

Hi,

On Tue, Dec 3, 2019 at 6:33 AM Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
> NP: you have not configured any Elliptic Curve to be used, so all those
> EC ciphers will not be usable. Also you configured some DES based
> ciphers and then disable DES.

I'll review that, thanks.

> The problem is that the client is talking to port 50443 and the service
> is expecting port 8080 in URLs.
>
> The best solution is to have the server and Squid using the same port
> number. Preferably 443 for HTTPS services.

I can't. Both 443 and 8080 are already in use.

> Alternatively you might be able to use the vport= option on https_port
> to set the URL port to 8080. However, this affects *all* inbound traffic
> at that port and any embedded URLs the service sends the client will
> remain broken (contain port 8080).

Whether I use vport=8080 or not, it still fails because the client
gets an HTTP redirection such as:

http://squidserver.local:50443/whatever (without vport=)

http://squidserver.local:8080/whatever (with vport=8080)

Note the http://.
So the client browser is instructed to connect to an HTTP port which
is closed/firewalled.
I would need to somehow rewrite the redirection to something like:

https://squidserver.local:50443/whatever (without vport=)

Vieri


From squid3 at treenet.co.nz  Tue Dec  3 12:40:31 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 4 Dec 2019 01:40:31 +1300
Subject: [squid-users] reverse proxy and HTTP redirects
In-Reply-To: <CABLYT9iqP6daryAHizn8OSUUcQTx9z2nZaQZnPaJpO7dgC-=EA@mail.gmail.com>
References: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>
 <864f0d16-3d9a-6f97-f53d-c622da5f8058@treenet.co.nz>
 <CABLYT9iqP6daryAHizn8OSUUcQTx9z2nZaQZnPaJpO7dgC-=EA@mail.gmail.com>
Message-ID: <d8ccb38a-887f-56ab-1b91-21b96d657ee3@treenet.co.nz>

On 3/12/19 10:11 pm, Vieri Di Paola wrote:
> 
> Whether I use vport=8080 or not, it still fails because the client
> gets an HTTP redirection such as:
> 
> http://squidserver.local:50443/whatever (without vport=)
> 
> http://squidserver.local:8080/whatever (with vport=8080)
> 
> Note the http://.
> So the client browser is instructed to connect to an HTTP port which
> is closed/firewalled.
> I would need to somehow rewrite the redirection to something like:
> 
> https://squidserver.local:50443/whatever (without vport=)
> 

Hmm, what version of Squid is this?


Can you configure "debug_options 11,2" and see what the HTTP messages
look like?

Amos


From vieridipaola at gmail.com  Tue Dec  3 14:02:29 2019
From: vieridipaola at gmail.com (Vieri Di Paola)
Date: Tue, 3 Dec 2019 15:02:29 +0100
Subject: [squid-users] reverse proxy and HTTP redirects
In-Reply-To: <d8ccb38a-887f-56ab-1b91-21b96d657ee3@treenet.co.nz>
References: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>
 <864f0d16-3d9a-6f97-f53d-c622da5f8058@treenet.co.nz>
 <CABLYT9iqP6daryAHizn8OSUUcQTx9z2nZaQZnPaJpO7dgC-=EA@mail.gmail.com>
 <d8ccb38a-887f-56ab-1b91-21b96d657ee3@treenet.co.nz>
Message-ID: <CABLYT9gGDg6sw8emknz2B=NEf10G9gDkRFzLurBFpmuqOKoctg@mail.gmail.com>

> Hmm, what version of Squid is this?

3.5.27 (yes, I'm aware of the security vulnerability, but I'm unable
to upgrade right now)

> Can you configure "debug_options 11,2" and see what the HTTP messages
> look like?

Everything looks OK until I get:

2019/12/03 14:52:26.509 kid1| 11,2| http.cc(720) processReplyHeader:
HTTP Server REPLY:
---------
HTTP/1.1 302 Moved Temporarily
Server: Apache-Coyote/1.1
Cache-Control: no-cache, no-store, max-age=0, must-revalidate
Pragma: no-cache
Expires: 0
X-XSS-Protection: 1; mode=block
X-Frame-Options: SAMEORIGIN
X-Content-Type-Options: nosniff
Set-Cookie: JSESSIONID=DQS7FWuX-JxNHXMZE+BHeQ2H; Path=/aida
Location: http://whatever.org:50443/whatever/security/afterLogin
Content-Length: 0
Date: Tue, 03 Dec 2019 13:52:25 GMT

Then the log ends with:

----------
2019/12/03 14:52:26.509 kid1| ctx: exit level  0
2019/12/03 14:52:26.509 kid1| 11,2| client_side.cc(1409)
sendStartOfMessage: HTTP Client local=10.215.145.81:50443
remote=10.215.144.48:54243 FD 12 flags=1
2019/12/03 14:52:26.509 kid1| 11,2| client_side.cc(1410)
sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 302 Found
Server: Apache-Coyote/1.1
Cache-Control: no-cache, no-store, max-age=0, must-revalidate
Pragma: no-cache
Expires: 0
X-XSS-Protection: 1; mode=block
X-Frame-Options: SAMEORIGIN
X-Content-Type-Options: nosniff
Set-Cookie: JSESSIONID=DQS7FWuX-JxNHXMZE+BHeQ2H; Path=/whatever
Location: http://whatever.org:50443/whatever/security/afterLogin
Content-Length: 0
Date: Tue, 03 Dec 2019 13:52:25 GMT
X-Cache: MISS from inf-fw2
X-Cache-Lookup: MISS from inf-fw2:50443
Via: 1.1 rev_aida (squid)
Connection: keep-alive


----------

Thanks,

Vieri


From rousskov at measurement-factory.com  Tue Dec  3 15:21:32 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 3 Dec 2019 10:21:32 -0500
Subject: [squid-users] debug headers between squid --> website
In-Reply-To: <DE9F39D0-A6AA-4F81-AC7D-3659C573EE2A@netstream.ps>
References: <76579fdb-6e34-5406-06e0-1f1a91dc9a5c@measurement-factory.com>
 <316B06A5-E0D3-4128-B98B-34C8E3EAB872@gmail.com>
 <e6467675-8cde-2446-36d5-705f79c0b4b0@measurement-factory.com>
 <DE9F39D0-A6AA-4F81-AC7D-3659C573EE2A@netstream.ps>
Message-ID: <81ed76e5-8ea2-e770-d000-d90231438b3d@measurement-factory.com>

On 12/2/19 5:22 PM, --Ahmad-- wrote:
> You Said?
> ??
> Yes, you can. Squid logs CONNECT headers and also HTTP headers of
> incoming and outgoing decrypted HTTPS requests. Squid does not see (and
> cannot log) HTTP headers of encrypted traffic inside CONNECT tunnels
> that are not bumped using the SslBump feature, of course.
> ??


> Can you tell me example of headers of ?Connect headers? and headers
> inside ? connect Tunnel ? ?

CONNECT requests are described, with examples, at
https://tools.ietf.org/html/rfc7231#section-4.3.6

Any HTTP message (both headers and body) can be sent inside a CONNECT
tunnel.

Please note that when Squid is configured to intercept HTTPS/TLS
connections, it treats the intercepted TCP connection as if that
intercepted traffic was inside a CONNECT tunnel. Squid even fakes the
CONNECT request in that case as if the TLS client sent a CONNECT request
before securing the connection.

Alex.


>> On Dec 2, 2019, at 10:31 PM, Alex Rousskov wrote:
>>
>> Yes, you can. Squid logs CONNECT headers and also HTTP headers of
>> incoming and outgoing decrypted HTTPS requests. Squid does not see (and
>> cannot log) HTTP headers of encrypted traffic inside CONNECT tunnels
>> that are not bumped using the SslBump feature, of course.
> 



From darren at ksn-systems.com  Tue Dec  3 17:05:36 2019
From: darren at ksn-systems.com (Darren Breeze)
Date: Wed, 04 Dec 2019 06:05:36 +1300
Subject: [squid-users] icap result caching in squid
In-Reply-To: <b83e7aa7-175a-e67f-c6ae-a0e73e4408ea@treenet.co.nz>
References: <1e800569-1d1d-42d4-bad8-41a2100430d9@www.fastmail.com>
 <c6de8a70-e0d7-c6cc-b0bf-58902e34db66@measurement-factory.com>
 <135d0e54-fc29-4eb0-b725-2b34d847100b@www.fastmail.com>
 <b83e7aa7-175a-e67f-c6ae-a0e73e4408ea@treenet.co.nz>
Message-ID: <f6cd7ee4-09d8-456c-b496-175c8928e995@www.fastmail.com>

Hi Amos

The Icap service is doing redirects based on client permissions (that may change). What I am doing is just setting the Expires value in the RESP_MOD response when I return a 307 redirect so I can control how long the caches (both Squid and the browser) hang on to it.



Darren B.





On Tue, Dec 3, 2019, at 6:17 PM, Amos Jeffries wrote:
> On 3/12/19 12:17 pm, Darren Breeze wrote:
> > Thanks Alex.
> > 
> > That has given me the perspective I need.
> > 
> > I can modulate the response header Expires value via icap to get the job done when squid goes to cache it.
> > 
> 
> Why are you needing to do this at all?
> 
> NP: please be aware that the changes you make to the HTTP headers affect
> *all* downstream caches, no just your Squid.
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are addressed. If you have received this email in error please notify the system manager. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. If you are not the intended recipient you are notified that disclosing, copying, distributing or taking any action in reliance on the contents of this information is strictly prohibited.



From squid3 at treenet.co.nz  Wed Dec  4 05:15:13 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 4 Dec 2019 18:15:13 +1300
Subject: [squid-users] reverse proxy and HTTP redirects
In-Reply-To: <CABLYT9gGDg6sw8emknz2B=NEf10G9gDkRFzLurBFpmuqOKoctg@mail.gmail.com>
References: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>
 <864f0d16-3d9a-6f97-f53d-c622da5f8058@treenet.co.nz>
 <CABLYT9iqP6daryAHizn8OSUUcQTx9z2nZaQZnPaJpO7dgC-=EA@mail.gmail.com>
 <d8ccb38a-887f-56ab-1b91-21b96d657ee3@treenet.co.nz>
 <CABLYT9gGDg6sw8emknz2B=NEf10G9gDkRFzLurBFpmuqOKoctg@mail.gmail.com>
Message-ID: <e9e641fe-b947-88d5-f5fd-fb62e6271fe6@treenet.co.nz>

On 4/12/19 3:02 am, Vieri Di Paola wrote:
>> Hmm, what version of Squid is this?
> 
> 3.5.27 (yes, I'm aware of the security vulnerability, but I'm unable
> to upgrade right now)
> 
>> Can you configure "debug_options 11,2" and see what the HTTP messages
>> look like?
> 
> Everything looks OK until I get:

I'm trying to see for myself if this is actually normal/OK - since I
don't know how familiar you are with HTTP accel mode syntax.

The requests in particular are most interesting, though what responses
are paired with each is also potentially important.



> 
> 2019/12/03 14:52:26.509 kid1| 11,2| http.cc(720) processReplyHeader:
> HTTP Server REPLY:
> ---------
> HTTP/1.1 302 Moved Temporarily
...
> Location: http://whatever.org:50443/whatever/security/afterLogin

That is a very good sign. The server is using the Squid listening port
in its generated URLs.


Amos


From squid3 at treenet.co.nz  Wed Dec  4 05:26:28 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 4 Dec 2019 18:26:28 +1300
Subject: [squid-users] icap result caching in squid
In-Reply-To: <f6cd7ee4-09d8-456c-b496-175c8928e995@www.fastmail.com>
References: <1e800569-1d1d-42d4-bad8-41a2100430d9@www.fastmail.com>
 <c6de8a70-e0d7-c6cc-b0bf-58902e34db66@measurement-factory.com>
 <135d0e54-fc29-4eb0-b725-2b34d847100b@www.fastmail.com>
 <b83e7aa7-175a-e67f-c6ae-a0e73e4408ea@treenet.co.nz>
 <f6cd7ee4-09d8-456c-b496-175c8928e995@www.fastmail.com>
Message-ID: <13703a9f-21f8-d7d0-05b4-fa642fdb6505@treenet.co.nz>

On 4/12/19 6:05 am, Darren Breeze wrote:
> Hi Amos
> 
> The Icap service is doing redirects based on client permissions (that may change). What I am doing is just setting the Expires value in the RESP_MOD response when I return a 307 redirect so I can control how long the caches (both Squid and the browser) hang on to it.
> 

In that case you should be using Cache-Control:max-age=NN instead where
the NN being your desired TTL in seconds. This is a *lot* simpler and
faster to deliver than calculating the timestamps needed for valid
Expires header.

Also, are you aware that current Squid versions can generate redirects
(custom headers included) based on output from an external_acl_type helper?
 A helper to lookup your permissions system plus a few extra squid.conf
settings would be a lot simpler in terms of traffic processing and
bandwidth consumption than sending everything through an external ICAP
service.


Amos


From rudi.kramer at gmail.com  Wed Dec  4 06:17:34 2019
From: rudi.kramer at gmail.com (Rudi Kramer)
Date: Wed, 4 Dec 2019 08:17:34 +0200
Subject: [squid-users] http://www1.ngtech.co.il/ - Down?
Message-ID: <CAJrXP6MrX-O2b6Dg6d7uB3YZ1Q=Ph=jh-bQYra6=-4EKEZuobw@mail.gmail.com>

Hello,

As far as I can tell, http://www1.ngtech.co.il/ is down at the moment.

Any word on how long this will be?

Thanks
Rudi
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191204/2c1d5f54/attachment.htm>

From vieridipaola at gmail.com  Wed Dec  4 07:42:46 2019
From: vieridipaola at gmail.com (Vieri Di Paola)
Date: Wed, 4 Dec 2019 08:42:46 +0100
Subject: [squid-users] reverse proxy and HTTP redirects
In-Reply-To: <e9e641fe-b947-88d5-f5fd-fb62e6271fe6@treenet.co.nz>
References: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>
 <864f0d16-3d9a-6f97-f53d-c622da5f8058@treenet.co.nz>
 <CABLYT9iqP6daryAHizn8OSUUcQTx9z2nZaQZnPaJpO7dgC-=EA@mail.gmail.com>
 <d8ccb38a-887f-56ab-1b91-21b96d657ee3@treenet.co.nz>
 <CABLYT9gGDg6sw8emknz2B=NEf10G9gDkRFzLurBFpmuqOKoctg@mail.gmail.com>
 <e9e641fe-b947-88d5-f5fd-fb62e6271fe6@treenet.co.nz>
Message-ID: <CABLYT9h9Fmgv2PzPWy45e+HrA44uQ2FrDgbvnA9gqMvQqX0wZw@mail.gmail.com>

On Wed, Dec 4, 2019 at 6:15 AM Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
> I'm trying to see for myself if this is actually normal/OK - since I
> don't know how familiar you are with HTTP accel mode syntax.
>
> The requests in particular are most interesting, though what responses
> are paired with each is also potentially important.

Hope it fits here. Otherwise, I'll pastebin it in another e-mail.

Here's the whole shebang:

2019/12/03 14:52:25.964 kid1| 11,2| client_side.cc(2372)
parseHttpRequest: HTTP Client local=10.215.145.81:50443
remote=10.215.144.48:54243 FD 12 flags=1
2019/12/03 14:52:25.964 kid1| 11,2| client_side.cc(2373)
parseHttpRequest: HTTP Client REQUEST:
---------
POST /whatever/j_spring_security_check HTTP/1.1
Host: intranet.mydomain.org:50443
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:60.0)
Gecko/20100101 Firefox/60.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.8,es-ES;q=0.6,es;q=0.4,ca;q=0.2
Accept-Encoding: gzip, deflate, br
Referer: https://intranet.mydomain.org:50443/whatever/security/login
Content-Type: application/x-www-form-urlencoded
Content-Length: 48
Cookie: JSESSIONID=pveHPU4LMS7YcbpaFwAADdL3
Connection: keep-alive
Upgrade-Insecure-Requests: 1

redirect=&username=myuser&password=mypassword
----------
2019/12/03 14:52:25.964 kid1| 11,2| http.cc(2229) sendRequest: HTTP
Server local=10.215.248.91:49470 remote=10.215.248.40:8080 FD 17
flags=1
2019/12/03 14:52:25.964 kid1| 11,2| http.cc(2230) sendRequest: HTTP
Server REQUEST:
---------
POST /whatever/j_spring_security_check HTTP/1.1
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:60.0)
Gecko/20100101 Firefox/60.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.8,es-ES;q=0.6,es;q=0.4,ca;q=0.2
Accept-Encoding: gzip, deflate, br
Referer: https://intranet.mydomain.org:50443/whatever/security/login
Content-Type: application/x-www-form-urlencoded
Content-Length: 48
Cookie: JSESSIONID=pveHPU4LMS7YcbpaFwAADdL3
Upgrade-Insecure-Requests: 1
Host: intranet.mydomain.org:50443
Via: 1.1 rev_whatever (squid)
Surrogate-Capability: inf-fw2="Surrogate/1.0"
X-Forwarded-For: 10.215.144.48
Cache-Control: max-age=259200
Connection: keep-alive


----------
2019/12/03 14:52:26.509 kid1| ctx: enter level  0:
'https://intranet.mydomain.org:50443/whatever/j_spring_security_check'
2019/12/03 14:52:26.509 kid1| 11,2| http.cc(719) processReplyHeader:
HTTP Server local=10.215.248.91:49470 remote=10.215.248.40:8080 FD 17
flags=1
2019/12/03 14:52:26.509 kid1| 11,2| http.cc(720) processReplyHeader:
HTTP Server REPLY:
---------
HTTP/1.1 302 Moved Temporarily
Server: Apache-Coyote/1.1
Cache-Control: no-cache, no-store, max-age=0, must-revalidate
Pragma: no-cache
Expires: 0
X-XSS-Protection: 1; mode=block
X-Frame-Options: SAMEORIGIN
X-Content-Type-Options: nosniff
Set-Cookie: JSESSIONID=DQS7FWuX-JxNHXMZE+BHeQ2H; Path=/whatever
Location: http://intranet.mydomain.org:50443/whatever/security/afterLogin
Content-Length: 0
Date: Tue, 03 Dec 2019 13:52:25 GMT


----------
2019/12/03 14:52:26.509 kid1| ctx: exit level  0
2019/12/03 14:52:26.509 kid1| 11,2| client_side.cc(1409)
sendStartOfMessage: HTTP Client local=10.215.145.81:50443
remote=10.215.144.48:54243 FD 12 flags=1
2019/12/03 14:52:26.509 kid1| 11,2| client_side.cc(1410)
sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 302 Found
Server: Apache-Coyote/1.1
Cache-Control: no-cache, no-store, max-age=0, must-revalidate
Pragma: no-cache
Expires: 0
X-XSS-Protection: 1; mode=block
X-Frame-Options: SAMEORIGIN
X-Content-Type-Options: nosniff
Set-Cookie: JSESSIONID=DQS7FWuX-JxNHXMZE+BHeQ2H; Path=/whatever
Location: http://intranet.mydomain.org:50443/whatever/security/afterLogin
Content-Length: 0
Date: Tue, 03 Dec 2019 13:52:25 GMT
X-Cache: MISS from inf-fw2
X-Cache-Lookup: MISS from inf-fw2:50443
Via: 1.1 rev_whatever (squid)
Connection: keep-alive


----------

> >
> > 2019/12/03 14:52:26.509 kid1| 11,2| http.cc(720) processReplyHeader:
> > HTTP Server REPLY:
> > ---------
> > HTTP/1.1 302 Moved Temporarily
> ...
> > Location: http://whatever.org:50443/whatever/security/afterLogin
>
> That is a very good sign. The server is using the Squid listening port
> in its generated URLs.

Yes, the port is fine. It's the protocol that's http instead of https.

Vieri


From tom at signagelive.com  Wed Dec  4 10:29:23 2019
From: tom at signagelive.com (tomsl)
Date: Wed, 4 Dec 2019 04:29:23 -0600 (CST)
Subject: [squid-users] Squid caching broken responses
Message-ID: <1575455363400-0.post@n4.nabble.com>

I have an odd issue running squid 4.2 as a reverse proxy in front of
rackspace cloudfiles. For some reason, something went wrong when the request
was made initially and squid has cached a broken response. The headers
returned by squid are as follows:

HTTP/1.1 200 OK
Accept-Ranges: bytes
Last-Modified: Tue, 20 Aug 2019 10:30:08 GMT
ETag: 9295f2e13cde446a4c6812163840f908
Content-Type: text/html; charset=UTF-8
Content-Length: 0
Date: Mon, 02 Dec 2019 10:41:17 GMT
Age: 167529
Warning: 113 squid/4.2 "This cache hit is still fresh and more than 1 day
old"
X-Cache: HIT from qa-stat-prox
X-Cache-Lookup: HIT from qa-stat-prox:80
Connection: keep-alive
Access-Control-Allow-Origin: *

----------------------------------------

When disabling the cache, the correct headers returned for this particular
file are:

HTTP/1.1 200 OK
Content-Length: 28272
Accept-Ranges: bytes
Last-Modified: Tue, 20 Aug 2019 10:30:08 GMT
ETag: 9295f2e13cde446a4c6812163840f908
Content-Type: image/jpeg
Date: Wed, 04 Dec 2019 09:20:44 GMT
X-Cache: MISS from qa-stat-prox
X-Cache-Lookup: MISS from qa-stat-prox:80
Connection: keep-alive
Access-Control-Allow-Origin: *

Is there a way I can stop it from caching the "broken" responses?




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Wed Dec  4 11:08:48 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 5 Dec 2019 00:08:48 +1300
Subject: [squid-users] Squid caching broken responses
In-Reply-To: <1575455363400-0.post@n4.nabble.com>
References: <1575455363400-0.post@n4.nabble.com>
Message-ID: <af044852-f7d4-8219-8d4e-6b7be64bc30b@treenet.co.nz>

On 4/12/19 11:29 pm, tomsl wrote:
> I have an odd issue running squid 4.2 as a reverse proxy in front of

Please upgrade. Current Squid-4 release is 4.9 and there are quite a few
very major security issues and bugs resolved since 4.2. Some of which
are related to cache corruption.


> 
> Is there a way I can stop it from caching the "broken" responses?
> 

Define "broken". There is nothing in the initial HTTP response to
indicate anything broken about it. So there is no reason for Squid not
to cache, in fact the object says it *can* be cached for an indefinite
amount of time.


If you know what URL these responses are for you can do:

  squidclient -H 'Cache-Control:no-cache\n' $URL

which requires Squid to fetch a clean copy.


Amos


From robertkwild at gmail.com  Wed Dec  4 11:10:32 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Wed, 4 Dec 2019 11:10:32 +0000
Subject: [squid-users] squid whitelist office365 and gmail emails
Message-ID: <CAGU_CiJcSy__z1uC43eo9x+ePU=Qiq6i4O9QbfV1ozNCn459fw@mail.gmail.com>

finally solved it and its working really nicely

what i did was to monitor the "access.log" using the watch and tail command
to see what websites it was actually going to

#Block MIME types
acl mimetype urlpath_regex -i \.exe$ \.msi$
http_access deny mimetype

#HTTPS whitelist websites
acl whitelist ssl::server_name "/etc/squid/whitelist.txt"
http_access allow whitelist
http_access deny all

cat /etc/squid/whitelist.txt
.bing.com
.msedge.net
.msftauth.net
.msauth.net
.msocdn.com
.office.com
.office365.com
.microsoft.com
.outlook.com
.live.com
.microsoftonline.com
.akamaized.net
.c.s-microsoft.com
.gfx.ms
.google.com
.google.co.uk
.googleusercontent.com
.googleapis.com
.withgoogle.com
.gstatic.com

-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191204/72c83b81/attachment.htm>

From yannick.rousseau at tutanota.com  Wed Dec  4 12:17:54 2019
From: yannick.rousseau at tutanota.com (yannick.rousseau at tutanota.com)
Date: Wed, 4 Dec 2019 13:17:54 +0100 (CET)
Subject: [squid-users] unable to open http socket
Message-ID: <LvFq5MR--3-1@tutanota.com>

Hi everybody,

I'm using debianedu (stretch) with squid 3.5.?
I would like to configure my squid through a parent proxy (172.16.103.254:3128).
I give you my issues at the beginning of this post, and my squid config at the end.
-> When I start squid on my debian stretch, and check if everything is ok, I've got the message "Unable to open HTTP Socket":

# service squid status
? squid.service - LSB: Squid HTTP Proxy version 3.x
?? Loaded: loaded (/etc/init.d/squid; generated; vendor preset: enabled)
?? Active: active (running) since Tue 2019-12-03 12:41:48 AST; 2s ago
???? Docs: man:systemd-sysv-generator(8)
? Process: 10838 ExecStop=/etc/init.d/squid stop (code=exited, status=0/SUCCESS)
? Process: 10852 ExecStart=/etc/init.d/squid start (code=exited, status=0/SUCCESS)
Main PID: 10893
??? Tasks: 6 (limit: 4915)
?? CGroup: /system.slice/squid.service <http://system.slice/squid.service>
?????????? ??? 818 /usr/sbin/squid -YC -f /etc/squid/squid-debian-edu.conf
?????????? ?? 2164 (squid-1) -YC -f /etc/squid/squid-debian-edu.conf
?????????? ?? 2165 (logfile-daemon) /var/log/squid/access.log
?????????? ?? 2166 (unlinkd)
?????????? ?? 2167 (pinger)
?????????? ??10891 /usr/sbin/squid -YC -f /etc/squid/squid-debian-edu.conf

d?c. 03 12:41:47 tjener.intern systemd[1]: Starting LSB: Squid HTTP Proxy version 3.x...
d?c. 03 12:41:47 tjener.intern squid[10891]: Squid Parent: will start 1 kids
d?c. 03 12:41:47 tjener.intern squid[10852]: Starting Squid HTTP Proxy: squid.
d?c. 03 12:41:47 tjener.intern squid[10891]: Squid Parent: (squid-1) process 10893 started
d?c. 03 12:41:47 tjener.intern systemd[1]: squid.service: PID file /var/run/squid.pid not readable (yet?) after start: No such file or directory
d?c. 03 12:41:48 tjener.intern systemd[1]: squid.service: Supervising process 10893 which is not our child. We'll most likely not notice when it exits.
d?c. 03 12:41:48 tjener.intern (squid-1)[10893]: Unable to open HTTP Socket
d?c. 03 12:41:48 tjener.intern systemd[1]: Started LSB: Squid HTTP Proxy version 3.x.
d?c. 03 12:41:48 tjener.intern squid[10891]: Squid Parent: (squid-1) process 10893 exited with status 1



-> When I look the cache log, I've got a "commBind: Cannot bind socket FD 17 to [::]:3128: (98) Address already in use":

2019/12/03 12:39:56 kid1| Closing Pinger socket on FD 19
2019/12/03 12:39:56| pinger: Initialising ICMP pinger ...
2019/12/03 12:39:56| pinger: ICMP socket opened.
2019/12/03 12:39:56| pinger: ICMPv6 socket opened
2019/12/03 12:39:56| Pinger exiting.
2019/12/03 12:41:47 kid1| Set Current Directory to /var/spool/squid
2019/12/03 12:41:47 kid1| Starting Squid Cache version 3.5.23 for x86_64-pc-linux-gnu...
2019/12/03 12:41:47 kid1| Service Name: squid
2019/12/03 12:41:47 kid1| Process ID 10893
2019/12/03 12:41:47 kid1| Process Roles: worker
2019/12/03 12:41:47 kid1| With 65535 file descriptors available
2019/12/03 12:41:47 kid1| Initializing IP Cache...
2019/12/03 12:41:47 kid1| DNS Socket created at [::], FD 6
2019/12/03 12:41:47 kid1| DNS Socket created at 0.0.0.0, FD 8
2019/12/03 12:41:47 kid1| Adding nameserver 127.0.0.1 from /etc/resolv.conf
2019/12/03 12:41:47 kid1| Adding domain intern from /etc/resolv.conf
2019/12/03 12:41:47 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2019/12/03 12:41:47 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2019/12/03 12:41:48 kid1| Unlinkd pipe opened on FD 14
2019/12/03 12:41:48 kid1| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2019/12/03 12:41:48 kid1| Store logging disabled
2019/12/03 12:41:48 kid1| Swap maxSize 11758592 + 262144 KB, estimated 924672 objects
2019/12/03 12:41:48 kid1| Target number of buckets: 46233
2019/12/03 12:41:48 kid1| Using 65536 Store buckets
2019/12/03 12:41:48 kid1| Max Mem? size: 262144 KB
2019/12/03 12:41:48 kid1| Max Swap size: 11758592 KB
2019/12/03 12:41:48 kid1| Rebuilding storage in /var/spool/squid (dirty log)
2019/12/03 12:41:48 kid1| Using Least Load store dir selection
2019/12/03 12:41:48 kid1| Set Current Directory to /var/spool/squid
2019/12/03 12:41:48 kid1| Finished loading MIME types and icons.
2019/12/03 12:41:48 kid1| commBind: Cannot bind socket FD 17 to [::]:3128: (98) Address already in use
2019/12/03 12:41:48 kid1| HTCP Disabled.
2019/12/03 12:41:48 kid1| Pinger socket opened on FD 19
2019/12/03 12:41:48 kid1| Configuring Parent 172.16.103.254/3128/0
2019/12/03 12:41:48 kid1| Squid plugin modules loaded: 0
2019/12/03 12:41:48 kid1| Adaptation support is off.
2019/12/03 12:41:48 kid1| Closing HTTP port [::]:3128
FATAL: Unable to open HTTP Socket
Squid Cache (Version 3.5.23): Terminated abnormally.



-> But when I check this with netstat, there's just squid using this port:

# netstat -anop |grep 3128
tcp6?????? 0????? 0 :::3128???????????????? :::*??????????????????? LISTEN????? 2164/(squid-1)?????? off (0.00/0/0)

So what's wrong ?



-> As I said, here is my squid config , I've added these two lines at the end :
cache_peer 172.16.103.254 parent 3128 0 proxy-only no-query
never_direct allow all

#cat squid-debian-edu.confacl CONNECT method CONNECT

# Grant access to the local networks
acl localnet src 10.0.0.0/8???? # RFC1918 possible internal network
acl localnet src 172.16.0.0/12? # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7?????? # RFC 4193 local private network range
acl localnet src fe80::/10????? # RFC 4291 link-local (directly plugged) machines

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localnet
http_access allow localhost
http_access deny all
htcp_access allow localnet
htcp_access deny all

http_port 3128

coredump_dir /var/spool/squid3



refresh_pattern ^ftp:?????????? 1440??? 20%???? 10080
refresh_pattern ^gopher:??????? 1440??? 0%????? 1440
refresh_pattern -i (/cgi-bin/|\?) 0???? 0%????? 0

# See bug #591839
refresh_pattern (Release|Packages(.gz)*)$????? 0?????? 20%????? 2880

refresh_pattern .?????????????? 0?????? 20%???? 4320

# Cache larger files to cache more debian packages
maximum_object_size 153600 KB

#? - Appends .intern to hostnames without any dots in them.
append_domain .intern

# Adjust cache size to fit size of /var/spool/squid, the capasity is
# dynamically updated using
# /usr/share/debian-edu-config/tools/squid-update-cachedir
cache_peer 172.16.103.254 parent 3128 0 proxy-only no-query
never_direct allow all
cache_dir ufs /var/spool/squid3 11432 16 256


Thanks for your help.


-- 
 Envoi s?curis? avec Tutanota. Obtenez votre propre adresse email chiffr?e : 
 https://tutanota.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191204/38343c05/attachment.htm>

From stancfg at gmail.com  Wed Dec  4 14:14:42 2019
From: stancfg at gmail.com (stancfg)
Date: Wed, 4 Dec 2019 08:14:42 -0600 (CST)
Subject: [squid-users] TCP_DENIED/407 AD auth
Message-ID: <1575468882111-0.post@n4.nabble.com>

Hello everyone, I'm facing some problem with squid.
Squid proxy is working but in access.log is showing TCP_DENIED/407 for most
of the connections.
If i remove authentication configuration from squid.conf this error is
missing in access.log.

CentOS Linux release 8.0.1905
4.18.0-147.6.el8.x86_64 
Squid Cache: Version 4.4
wbinfo -t 
checking the trust secret for domain AD via RPC calls succeeded

Any assistance in this matter would be greatly appreciated 
Regards
Stan

*squid.conf*


*smb.conf*

*nssswitch.conf*


*access.log*



*cache.log*




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From info at schroeffu.ch  Wed Dec  4 14:20:07 2019
From: info at schroeffu.ch (info at schroeffu.ch)
Date: Wed, 04 Dec 2019 14:20:07 +0000
Subject: [squid-users] TCP_DENIED/407 AD auth
In-Reply-To: <1575468882111-0.post@n4.nabble.com>
References: <1575468882111-0.post@n4.nabble.com>
Message-ID: <666842b4490958bada0301862e3ab44c@schroeffu.ch>

For my understanding, with (NTLM) authentication every request needs to be authenticated. Therefore you will see TCP_DENIED/407 anytime before TCP_***/200 because the request needs to be authenticated anytime again.

Anybody else correct me if I am wrong ;-)

Schroeffu



4. Dezember 2019 15:09, "stancfg" <stancfg at gmail.com> schrieb:

> Hello everyone, I'm facing some problem with squid.
> Squid proxy is working but in access.log is showing TCP_DENIED/407 for most
> of the connections.
> If i remove authentication configuration from squid.conf this error is
> missing in access.log.
> 
> CentOS Linux release 8.0.1905
> 4.18.0-147.6.el8.x86_64 
> Squid Cache: Version 4.4
> wbinfo -t 
> checking the trust secret for domain AD via RPC calls succeeded
> 
> Any assistance in this matter would be greatly appreciated 
> Regards
> Stan
> 
> *squid.conf*
> 
> *smb.conf*
> 
> *nssswitch.conf*
> 
> *access.log*
> 
> *cache.log*
> 
> --
> Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From stancfg at gmail.com  Wed Dec  4 14:30:46 2019
From: stancfg at gmail.com (stancfg)
Date: Wed, 4 Dec 2019 08:30:46 -0600 (CST)
Subject: [squid-users] TCP_DENIED/407 AD auth
In-Reply-To: <666842b4490958bada0301862e3ab44c@schroeffu.ch>
References: <1575468882111-0.post@n4.nabble.com>
 <666842b4490958bada0301862e3ab44c@schroeffu.ch>
Message-ID: <1575469846675-0.post@n4.nabble.com>

Hello Schroeffu 

I fully agree with you, but why some of request are authenticated and some
are not.
Is this a normal behavior.
Thank you for your help.

Stan



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From info at schroeffu.ch  Wed Dec  4 14:37:14 2019
From: info at schroeffu.ch (info at schroeffu.ch)
Date: Wed, 04 Dec 2019 14:37:14 +0000
Subject: [squid-users] TCP_DENIED/407 AD auth
In-Reply-To: <1575469846675-0.post@n4.nabble.com>
References: <1575469846675-0.post@n4.nabble.com>
 <1575468882111-0.post@n4.nabble.com>
 <666842b4490958bada0301862e3ab44c@schroeffu.ch>
Message-ID: <6fc8dbc32a46aabf3f2ac08db2c86bee@schroeffu.ch>

Hi Stan,

when you are using NTLM according the latest sentence in https://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm (very bottom): 

"Note that when using NTLM authentication, you will see two "TCP_DENIED/407" entries in access.log for every request. This is due to the challenge-response process of NTLM."

So usually any request from end-user through ntlm auth proxy should log a TCP_DENIED/407. If you have websites allowed without authentication in squid.conf before the authentication configuration - of course, these are not logging 407. The real challenge-response thing maybe somebody else can explain that better to you / or link a documentation.

For example I'm running a whitelist configured before the authentication configuration, so i can add domains to allow without NTLM (apple.com domains etc)

acl white_domain dstdomain "/etc/squid/ka/domains_noauth.acl"
http_access allow white_domain

acl white_regexp url_regex -i "/etc/squid/ka/domains_noauth_regex.acl"
http_access allow white_regexp

#Allow fetch intermediate certs before required authentication, guess this is required for SSL BUMP + NTLM
acl fetched_certificate transaction_initiator certificate-fetching
cache allow fetched_certificate
http_access allow fetched_certificate

# NTLM authentication
auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --use-cached-creds --offline-logon
(...)(ntlm configuration, check required ldap groups, blablah)
(...)
(...)
(...)

# Allow based on group membership
# Authentication required, otherwise Pop-Up to Basic Auth
acl Authenticated_Users proxy_auth REQUIRED
http_access deny !Authenticated_Users



4. Dezember 2019 15:25, "stancfg" <stancfg at gmail.com> schrieb:

> Hello Schroeffu 
> 
> I fully agree with you, but why some of request are authenticated and some
> are not.
> Is this a normal behavior.
> Thank you for your help.
> 
> Stan
> 
> --
> Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From stancfg at gmail.com  Wed Dec  4 15:01:03 2019
From: stancfg at gmail.com (stancfg)
Date: Wed, 4 Dec 2019 09:01:03 -0600 (CST)
Subject: [squid-users] TCP_DENIED/407 AD auth
In-Reply-To: <6fc8dbc32a46aabf3f2ac08db2c86bee@schroeffu.ch>
References: <1575468882111-0.post@n4.nabble.com>
 <666842b4490958bada0301862e3ab44c@schroeffu.ch>
 <1575469846675-0.post@n4.nabble.com>
 <6fc8dbc32a46aabf3f2ac08db2c86bee@schroeffu.ch>
Message-ID: <1575471663340-0.post@n4.nabble.com>

Hello Schroeffu,
Somehow I've manage to miss this last sentence 
I have another proxy in production that is working with ACL's like this, but
showing the same error ""TCP_DENIED/407" 
That is why i decide to build new one and find the "problem".
Probably will try new one with kerberos.
Thank you very much Schroeffu. 

Regards
Stan



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From darren at ksn-systems.com  Wed Dec  4 16:54:19 2019
From: darren at ksn-systems.com (Darren Breeze)
Date: Thu, 05 Dec 2019 05:54:19 +1300
Subject: [squid-users] icap result caching in squid
In-Reply-To: <13703a9f-21f8-d7d0-05b4-fa642fdb6505@treenet.co.nz>
References: <1e800569-1d1d-42d4-bad8-41a2100430d9@www.fastmail.com>
 <c6de8a70-e0d7-c6cc-b0bf-58902e34db66@measurement-factory.com>
 <135d0e54-fc29-4eb0-b725-2b34d847100b@www.fastmail.com>
 <b83e7aa7-175a-e67f-c6ae-a0e73e4408ea@treenet.co.nz>
 <f6cd7ee4-09d8-456c-b496-175c8928e995@www.fastmail.com>
 <13703a9f-21f8-d7d0-05b4-fa642fdb6505@treenet.co.nz>
Message-ID: <9acb15c5-83c1-4eb0-96ed-77098281677c@www.fastmail.com>

Thanks Amos

The Icap also does url filtering so it's a one stop shop for everything. I have to stay with V3.5 for the moment but will move up to 4.x later and re-examine my approach based on the newer features available.

Cache-Control is much cleaner and it actually is named as per what I want to do so it makes my intent clearer to others reading the code in the future.

Thanks again.

Darren B. 

On Wed, Dec 4, 2019, at 6:26 PM, Amos Jeffries wrote:
> On 4/12/19 6:05 am, Darren Breeze wrote:
> > Hi Amos
> > 
> > The Icap service is doing redirects based on client permissions (that may change). What I am doing is just setting the Expires value in the RESP_MOD response when I return a 307 redirect so I can control how long the caches (both Squid and the browser) hang on to it.
> > 
> 
> In that case you should be using Cache-Control:max-age=NN instead where
> the NN being your desired TTL in seconds. This is a *lot* simpler and
> faster to deliver than calculating the timestamps needed for valid
> Expires header.
> 
> Also, are you aware that current Squid versions can generate redirects
> (custom headers included) based on output from an external_acl_type helper?
>  A helper to lookup your permissions system plus a few extra squid.conf
> settings would be a lot simpler in terms of traffic processing and
> bandwidth consumption than sending everything through an external ICAP
> service.
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are addressed. If you have received this email in error please notify the system manager. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. If you are not the intended recipient you are notified that disclosing, copying, distributing or taking any action in reliance on the contents of this information is strictly prohibited.



From creditu at eml.cc  Thu Dec  5 00:29:51 2019
From: creditu at eml.cc (creditu at eml.cc)
Date: Wed, 04 Dec 2019 17:29:51 -0700
Subject: [squid-users] ACL reply_header_access
Message-ID: <cbd07b9f-2b43-47ac-9a70-0f0ce1c093cd@www.fastmail.com>

We have been using several squid servers in accelerator mode for a number of years mainly for load balancing to send public requests to backend servers.  The requests to the squids typically come via a well known commercial  caching service.   The squids don't do any caching, they just forward requests to the backend.

I need to remove the  X-Content-Type-Options: nosniff reply header when it's only going to a specific service that queries our web farm.

I believe I can remove it from all replies by using reply_header_access X-Content-Type-Options deny all.  But, I need an ACL that will only remove it from those responses going to that service (client).  

I'm used to writing ACLs based on Internet to our farm requests not the outbound to the clients.  I'm having trouble getting my head around the logic on the acl directives to use.  Do I need to look at the reply headers and craft the ACL based on that?   Can you write and ACL based on the original request from the client?   

What I'd like to be able to do is write a acl that does not send back the X-Content-Type header to the client that requested: https://www.example.com/sound/ID/text/abcde.txt.  


From squid3 at treenet.co.nz  Thu Dec  5 08:05:15 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 5 Dec 2019 21:05:15 +1300
Subject: [squid-users] unable to open http socket
In-Reply-To: <LvFq5MR--3-1@tutanota.com>
References: <LvFq5MR--3-1@tutanota.com>
Message-ID: <b8c10a8a-c813-5d1e-c824-6ada026a70a5@treenet.co.nz>

On 5/12/19 1:17 am, yannick.rousseau wrote:
> Hi everybody,
> 
> I'm using debianedu (stretch) with squid 3.5.?
> I would like to configure my squid through a parent proxy
> (172.16.103.254:3128).
> I give you my issues at the beginning of this post, and my squid config
> at the end.
> 
> -> When I start squid on my debian stretch, and check if everything is
> ok, I've got the message "Unable to open HTTP Socket":
> 
> # service squid status

There is your problem.

Nesting daemon managers leads to major problems tracking what PID is
responsible for what. The 'squid' process is a daemon manager, so is
systemd.

With Squid-3 the closest to a solution you will be able to get is to add
the -N command line option to disable the Squid daemon manager (and SMP
features).

Please upgrade to Squid-4 though, it has support for integrating with
systemd which does not require useful SMP features to be disabled.

Amos


From squid3 at treenet.co.nz  Thu Dec  5 08:49:21 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 5 Dec 2019 21:49:21 +1300
Subject: [squid-users] ACL reply_header_access
In-Reply-To: <cbd07b9f-2b43-47ac-9a70-0f0ce1c093cd@www.fastmail.com>
References: <cbd07b9f-2b43-47ac-9a70-0f0ce1c093cd@www.fastmail.com>
Message-ID: <25a5b27e-e8e4-949a-666d-f5fcf9b5c0f6@treenet.co.nz>

On 5/12/19 1:29 pm, creditu wrote:
> We have been using several squid servers in accelerator mode for a number of years mainly for load balancing to send public requests to backend servers.  The requests to the squids typically come via a well known commercial  caching service.   The squids don't do any caching, they just forward requests to the backend.
> 
> I need to remove the  X-Content-Type-Options: nosniff reply header when it's only going to a specific service that queries our web farm.
>

Okay.

> I believe I can remove it from all replies by using reply_header_access X-Content-Type-Options deny all.  But, I need an ACL that will only remove it from those responses going to that service (client).
> 
> I'm used to writing ACLs based on Internet to our farm requests not the outbound to the clients.  I'm having trouble getting my head around the logic on the acl directives to use.  Do I need to look at the reply headers and craft the ACL based on that?   Can you write and ACL based on the original request from the client?

There is no difference in the ACL themselves beyond what data they have
available depends on when in the transaction the directive using them
occurs.

When Squid needs to decide something there is usually a directive to
assist with the decision. reply_header_access is indeed the one to use
when deciding what HTTP reply headers get delivered to the client.


> 
> What I'd like to be able to do is write a acl that does not send back the X-Content-Type header to the client that requested: https://www.example.com/sound/ID/text/abcde.txt.  

What you need to do is find an ACL which identifies the particular
client. eg 'src' ACL is simplest if the service IP is not shared or
changing. Otherwise you may need some other detail visible in the HTTP
request headers or TCP state.


Amos


From bariq.kassir at scania.com  Thu Dec  5 09:13:36 2019
From: bariq.kassir at scania.com (Kassir Bariq)
Date: Thu, 5 Dec 2019 09:13:36 +0000
Subject: [squid-users] TCP_TUNNEL
Message-ID: <HE1PR0402MB27474A4834384C8124062264F45C0@HE1PR0402MB2747.eurprd04.prod.outlook.com>

Hi Awesome Squid Users ?

I?m using Squid transparent proxy on AWS. I?m having a small problem, but I don?t really know what is happening!

From an EC2 in Private Subnet I?m making a request to AWS Endpoints using 443, and the request is going via Squid and says Connected, but unfortunately it is not working in the Client!

Checked the Logs and found that it is going via tcp_tunnel, but still not working in the client.

1575515309.361 20029 10.131.18.170 TCP_TUNNEL/200 430 CONNECT 52.46.200.112:443 - ORIGINAL_DST/52.46.200.112 -
1575515337.544 65650 10.131.18.158 TCP_TUNNEL/200 451 CONNECT 52.46.200.130:443 - ORIGINAL_DST/52.46.200.130 -
1575515490.666 20020 10.131.18.205 TCP_TUNNEL/200 430 CONNECT 52.46.196.121:443 - ORIGINAL_DST/52.46.196.121 -

Is there anything I can add to the config file that can fix this problem ?

Regards
Bariq
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191205/f24feed4/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec  5 09:22:35 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 5 Dec 2019 22:22:35 +1300
Subject: [squid-users] TCP_TUNNEL
In-Reply-To: <HE1PR0402MB27474A4834384C8124062264F45C0@HE1PR0402MB2747.eurprd04.prod.outlook.com>
References: <HE1PR0402MB27474A4834384C8124062264F45C0@HE1PR0402MB2747.eurprd04.prod.outlook.com>
Message-ID: <4fb36b6a-5b1d-3d9f-67c5-01b8b7232db2@treenet.co.nz>

On 5/12/19 10:13 pm, Kassir Bariq wrote:
> Hi Awesome Squid Users ?
> 
> I?m using Squid transparent proxy on AWS. I?m having a small problem,
> but I don?t really know what is happening!
> 
> ?
> 
> From an EC2 in Private Subnet I?m making a request to AWS Endpoints
> using 443, and the request is going via Squid and says Connected, but
> unfortunately it is not working in the Client!
> 


> 
> Is there anything I can add to the config file that can fix this problem ?
> 

TUNNEL means Squid is just shovelling bytes to/from the client and
server. This is how CONNECT transactions always worked, they were just
not logged clearly.

Any problem that is happening in a TUNNEL transaction is a private
matter between the client and server. They are communicating directly
like the proxy is not present.


Amos


From vieridipaola at gmail.com  Thu Dec  5 10:17:00 2019
From: vieridipaola at gmail.com (Vieri Di Paola)
Date: Thu, 5 Dec 2019 11:17:00 +0100
Subject: [squid-users] reverse proxy and HTTP redirects
In-Reply-To: <e9e641fe-b947-88d5-f5fd-fb62e6271fe6@treenet.co.nz>
References: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>
 <864f0d16-3d9a-6f97-f53d-c622da5f8058@treenet.co.nz>
 <CABLYT9iqP6daryAHizn8OSUUcQTx9z2nZaQZnPaJpO7dgC-=EA@mail.gmail.com>
 <d8ccb38a-887f-56ab-1b91-21b96d657ee3@treenet.co.nz>
 <CABLYT9gGDg6sw8emknz2B=NEf10G9gDkRFzLurBFpmuqOKoctg@mail.gmail.com>
 <e9e641fe-b947-88d5-f5fd-fb62e6271fe6@treenet.co.nz>
Message-ID: <CABLYT9jPPQPKgD-UA2fqK3YPnMh-==W-j+TaB6LQ8qqKcLjHgw@mail.gmail.com>

I could try to use a redirector with location_rewrite_program, but
this directive is not available anymore.
I presume I need to use url_rewrite_program instead.
I wonder if it will rewrite the "Location" header the origin server is
sending to the client browser.

Vieri


From squid3 at treenet.co.nz  Thu Dec  5 10:48:11 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 5 Dec 2019 23:48:11 +1300
Subject: [squid-users] reverse proxy and HTTP redirects
In-Reply-To: <CABLYT9jPPQPKgD-UA2fqK3YPnMh-==W-j+TaB6LQ8qqKcLjHgw@mail.gmail.com>
References: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>
 <864f0d16-3d9a-6f97-f53d-c622da5f8058@treenet.co.nz>
 <CABLYT9iqP6daryAHizn8OSUUcQTx9z2nZaQZnPaJpO7dgC-=EA@mail.gmail.com>
 <d8ccb38a-887f-56ab-1b91-21b96d657ee3@treenet.co.nz>
 <CABLYT9gGDg6sw8emknz2B=NEf10G9gDkRFzLurBFpmuqOKoctg@mail.gmail.com>
 <e9e641fe-b947-88d5-f5fd-fb62e6271fe6@treenet.co.nz>
 <CABLYT9jPPQPKgD-UA2fqK3YPnMh-==W-j+TaB6LQ8qqKcLjHgw@mail.gmail.com>
Message-ID: <5657e4a0-1b0e-0342-7144-658be523f881@treenet.co.nz>

On 5/12/19 11:17 pm, Vieri Di Paola wrote:
> I could try to use a redirector with location_rewrite_program, but
> this directive is not available anymore.
> I presume I need to use url_rewrite_program instead.

No, that only re-writes the client requested URLs.

You can try using a rewriter on the external_acl_type helper interface.
Something like this (untested):

  external_acl_type location_rewriter %<h{Location} /path/to/rewriter
  acl bad_Location external location_rewriter

  deny_info 302:%note{location-rewrite} bad_Location
  acl 302 http_status 302
  http_reply_access deny 302 bad_Location


The idea being that you pass the helper the Location header. If that
value is http:// it produces the new URL in a response like:
  "OK location-rewrite=https://... \n"
otherwise:
  "ERR"

Since this is a Cookie based login check, you probably need to also pass
the Set-Cookie header to the helper and forward it back out as another
kv-pair so the reply_header_add directive can add that header back onto
the new Squid generated 302 message.


Alternative to his would be an eCAP module that just re-writes the
Location headers in place. That would be simpler, but requires some
coding to create the module.


Amos


From vieridipaola at gmail.com  Thu Dec  5 11:08:19 2019
From: vieridipaola at gmail.com (Vieri Di Paola)
Date: Thu, 5 Dec 2019 12:08:19 +0100
Subject: [squid-users] reverse proxy and HTTP redirects
In-Reply-To: <5657e4a0-1b0e-0342-7144-658be523f881@treenet.co.nz>
References: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>
 <864f0d16-3d9a-6f97-f53d-c622da5f8058@treenet.co.nz>
 <CABLYT9iqP6daryAHizn8OSUUcQTx9z2nZaQZnPaJpO7dgC-=EA@mail.gmail.com>
 <d8ccb38a-887f-56ab-1b91-21b96d657ee3@treenet.co.nz>
 <CABLYT9gGDg6sw8emknz2B=NEf10G9gDkRFzLurBFpmuqOKoctg@mail.gmail.com>
 <e9e641fe-b947-88d5-f5fd-fb62e6271fe6@treenet.co.nz>
 <CABLYT9jPPQPKgD-UA2fqK3YPnMh-==W-j+TaB6LQ8qqKcLjHgw@mail.gmail.com>
 <5657e4a0-1b0e-0342-7144-658be523f881@treenet.co.nz>
Message-ID: <CABLYT9gOoZS9g9qAa=+e_=JSmgHYzNkNk2Yw+zArc5hMpxp4jA@mail.gmail.com>

On Thu, Dec 5, 2019 at 11:48 AM Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
> Alternative to his would be an eCAP module that just re-writes the
> Location headers in place. That would be simpler, but requires some
> coding to create the module.

Simpler, I like how that sounds...
I presume a good starting point would be:
https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/eCAP
http://www.e-cap.org/downloads/

If you have any more hints/suggestions/quickstarts for this particular
problem with eCAP, please let me know.

Thanks,

Vieri


From tom at signagelive.com  Thu Dec  5 11:23:35 2019
From: tom at signagelive.com (tomsl)
Date: Thu, 5 Dec 2019 05:23:35 -0600 (CST)
Subject: [squid-users] Squid caching broken responses
In-Reply-To: <af044852-f7d4-8219-8d4e-6b7be64bc30b@treenet.co.nz>
References: <1575455363400-0.post@n4.nabble.com>
 <af044852-f7d4-8219-8d4e-6b7be64bc30b@treenet.co.nz>
Message-ID: <1575545015689-0.post@n4.nabble.com>

>Please upgrade. Current Squid-4 release is 4.9 and there are quite a few
>very major security issues and bugs resolved since 4.2. Some of which
>are related to cache corruption.

I have tried using squid 4.9, however am having an issue with the url
rewriter I am using to translate the urls into rackspace servicenet
requests. Squid terminates with the error:

2019/12/05 11:12:23 kid1| Squid Cache (Version 4.9): Terminated abnormally.
2019/12/05 11:12:23 kid1| ipcCreate: /etc/squid/urlrewrite.pl: (2) No such
file or directory
2019/12/05 11:12:23 kid1| ipcCreate: /etc/squid/urlrewrite.pl: (2) No such
file or directory

I don't understand why as the file is definitely there and has very loose
permissions (at the moment!).



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Thu Dec  5 12:06:20 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 6 Dec 2019 01:06:20 +1300
Subject: [squid-users] Squid caching broken responses
In-Reply-To: <1575545015689-0.post@n4.nabble.com>
References: <1575455363400-0.post@n4.nabble.com>
 <af044852-f7d4-8219-8d4e-6b7be64bc30b@treenet.co.nz>
 <1575545015689-0.post@n4.nabble.com>
Message-ID: <1f6a7832-ddba-50eb-402b-42c0e9da8b4f@treenet.co.nz>

On 6/12/19 12:23 am, tomsl wrote:
>> Please upgrade. Current Squid-4 release is 4.9 and there are quite a few
>> very major security issues and bugs resolved since 4.2. Some of which
>> are related to cache corruption.
> 
> I have tried using squid 4.9, however am having an issue with the url
> rewriter I am using to translate the urls into rackspace servicenet
> requests. Squid terminates with the error:
> 
> 2019/12/05 11:12:23 kid1| Squid Cache (Version 4.9): Terminated abnormally.
> 2019/12/05 11:12:23 kid1| ipcCreate: /etc/squid/urlrewrite.pl: (2) No such
> file or directory
> 2019/12/05 11:12:23 kid1| ipcCreate: /etc/squid/urlrewrite.pl: (2) No such
> file or directory
> 
> I don't understand why as the file is definitely there and has very loose
> permissions (at the moment!).

That is very odd. Was it in that location and working before with the
same permissions?

If there is AppArmour or SELinux on the machine their permissions for
that location/file may need updating as well.


Amos


From vieridipaola at gmail.com  Thu Dec  5 12:41:30 2019
From: vieridipaola at gmail.com (Vieri Di Paola)
Date: Thu, 5 Dec 2019 13:41:30 +0100
Subject: [squid-users] reverse proxy and HTTP redirects
In-Reply-To: <5657e4a0-1b0e-0342-7144-658be523f881@treenet.co.nz>
References: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>
 <864f0d16-3d9a-6f97-f53d-c622da5f8058@treenet.co.nz>
 <CABLYT9iqP6daryAHizn8OSUUcQTx9z2nZaQZnPaJpO7dgC-=EA@mail.gmail.com>
 <d8ccb38a-887f-56ab-1b91-21b96d657ee3@treenet.co.nz>
 <CABLYT9gGDg6sw8emknz2B=NEf10G9gDkRFzLurBFpmuqOKoctg@mail.gmail.com>
 <e9e641fe-b947-88d5-f5fd-fb62e6271fe6@treenet.co.nz>
 <CABLYT9jPPQPKgD-UA2fqK3YPnMh-==W-j+TaB6LQ8qqKcLjHgw@mail.gmail.com>
 <5657e4a0-1b0e-0342-7144-658be523f881@treenet.co.nz>
Message-ID: <CABLYT9idHPFJ-V9oobbv65k2SXzC9qw6iHd3G7EDVnie7BGppA@mail.gmail.com>

By the way, if I were to upgrade to Squid 4, would the following do the trick?

reply_header_add Strict-Transport-Security "max-age=31536000;
includeSubDomains; preload" all


From squid3 at treenet.co.nz  Thu Dec  5 13:06:00 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 6 Dec 2019 02:06:00 +1300
Subject: [squid-users] reverse proxy and HTTP redirects
In-Reply-To: <CABLYT9idHPFJ-V9oobbv65k2SXzC9qw6iHd3G7EDVnie7BGppA@mail.gmail.com>
References: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>
 <864f0d16-3d9a-6f97-f53d-c622da5f8058@treenet.co.nz>
 <CABLYT9iqP6daryAHizn8OSUUcQTx9z2nZaQZnPaJpO7dgC-=EA@mail.gmail.com>
 <d8ccb38a-887f-56ab-1b91-21b96d657ee3@treenet.co.nz>
 <CABLYT9gGDg6sw8emknz2B=NEf10G9gDkRFzLurBFpmuqOKoctg@mail.gmail.com>
 <e9e641fe-b947-88d5-f5fd-fb62e6271fe6@treenet.co.nz>
 <CABLYT9jPPQPKgD-UA2fqK3YPnMh-==W-j+TaB6LQ8qqKcLjHgw@mail.gmail.com>
 <5657e4a0-1b0e-0342-7144-658be523f881@treenet.co.nz>
 <CABLYT9idHPFJ-V9oobbv65k2SXzC9qw6iHd3G7EDVnie7BGppA@mail.gmail.com>
Message-ID: <76f31fd3-345b-95fd-58e4-d17312408f5f@treenet.co.nz>

On 6/12/19 1:41 am, Vieri Di Paola wrote:
> By the way, if I were to upgrade to Squid 4, would the following do the trick?
> 
> reply_header_add Strict-Transport-Security "max-age=31536000;
> includeSubDomains; preload" all
> 


Doubtful, but if you want to test it start with a very *small* max-age
value (eg max-age=60). So that if things go wrong you don't have to
throw away the domain name.

Amos


From vieridipaola at gmail.com  Thu Dec  5 16:46:23 2019
From: vieridipaola at gmail.com (Vieri Di Paola)
Date: Thu, 5 Dec 2019 17:46:23 +0100
Subject: [squid-users] reverse proxy and HTTP redirects
In-Reply-To: <5657e4a0-1b0e-0342-7144-658be523f881@treenet.co.nz>
References: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>
 <864f0d16-3d9a-6f97-f53d-c622da5f8058@treenet.co.nz>
 <CABLYT9iqP6daryAHizn8OSUUcQTx9z2nZaQZnPaJpO7dgC-=EA@mail.gmail.com>
 <d8ccb38a-887f-56ab-1b91-21b96d657ee3@treenet.co.nz>
 <CABLYT9gGDg6sw8emknz2B=NEf10G9gDkRFzLurBFpmuqOKoctg@mail.gmail.com>
 <e9e641fe-b947-88d5-f5fd-fb62e6271fe6@treenet.co.nz>
 <CABLYT9jPPQPKgD-UA2fqK3YPnMh-==W-j+TaB6LQ8qqKcLjHgw@mail.gmail.com>
 <5657e4a0-1b0e-0342-7144-658be523f881@treenet.co.nz>
Message-ID: <CABLYT9i5wm=ezOuhbQg=bbbtAZ2bAk0eMzO1dAz7Z+soa8fExg@mail.gmail.com>

On Thu, Dec 5, 2019 at 11:48 AM Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
>   external_acl_type location_rewriter %<h{Location} /path/to/rewriter
>   acl bad_Location external location_rewriter
>
>   deny_info 302:%note{location-rewrite} bad_Location
>   acl 302 http_status 302
>   http_reply_access deny 302 bad_Location

Sorry to bother you again with this, but what does
"%note{location-rewrite}" mean?
I'm getting this error message:
FATAL: status 302 requires a URL on '302:%note{location-rewrite}'

Thanks,

Vieri


From vieridipaola at gmail.com  Thu Dec  5 16:57:25 2019
From: vieridipaola at gmail.com (Vieri Di Paola)
Date: Thu, 5 Dec 2019 17:57:25 +0100
Subject: [squid-users] reverse proxy and HTTP redirects
In-Reply-To: <5657e4a0-1b0e-0342-7144-658be523f881@treenet.co.nz>
References: <CABLYT9jxoWBAmJDCb2MY38zzvLYyc95NLFe-mnE-MhYgtVoRtw@mail.gmail.com>
 <864f0d16-3d9a-6f97-f53d-c622da5f8058@treenet.co.nz>
 <CABLYT9iqP6daryAHizn8OSUUcQTx9z2nZaQZnPaJpO7dgC-=EA@mail.gmail.com>
 <d8ccb38a-887f-56ab-1b91-21b96d657ee3@treenet.co.nz>
 <CABLYT9gGDg6sw8emknz2B=NEf10G9gDkRFzLurBFpmuqOKoctg@mail.gmail.com>
 <e9e641fe-b947-88d5-f5fd-fb62e6271fe6@treenet.co.nz>
 <CABLYT9jPPQPKgD-UA2fqK3YPnMh-==W-j+TaB6LQ8qqKcLjHgw@mail.gmail.com>
 <5657e4a0-1b0e-0342-7144-658be523f881@treenet.co.nz>
Message-ID: <CABLYT9ijmRAa3kvQhTL6BbpsNhsT1UOKyzPbx=8DkDkjyGDG2g@mail.gmail.com>

On Thu, Dec 5, 2019 at 11:48 AM Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
>   external_acl_type location_rewriter %<h{Location} /path/to/rewriter
>   acl bad_Location external location_rewriter
>
>   deny_info 302:%note{location-rewrite} bad_Location
>   acl 302 http_status 302
>   http_reply_access deny 302 bad_Location

I just read something about %note here:
http://www.squid-cache.org/Doc/config/logformat/
However, Squid 3.x doesn't seem to accept %note{location-rewrite} as a
URL placeholder for deny_info.

Vieri


From darren at ksn-systems.com  Thu Dec  5 18:17:57 2019
From: darren at ksn-systems.com (Darren Breeze)
Date: Fri, 06 Dec 2019 07:17:57 +1300
Subject: [squid-users] icap result caching in squid
In-Reply-To: <13703a9f-21f8-d7d0-05b4-fa642fdb6505@treenet.co.nz>
References: <1e800569-1d1d-42d4-bad8-41a2100430d9@www.fastmail.com>
 <c6de8a70-e0d7-c6cc-b0bf-58902e34db66@measurement-factory.com>
 <135d0e54-fc29-4eb0-b725-2b34d847100b@www.fastmail.com>
 <b83e7aa7-175a-e67f-c6ae-a0e73e4408ea@treenet.co.nz>
 <f6cd7ee4-09d8-456c-b496-175c8928e995@www.fastmail.com>
 <13703a9f-21f8-d7d0-05b4-fa642fdb6505@treenet.co.nz>
Message-ID: <e7b2e42e-ea9e-4955-aae7-7237b19e0b3a@www.fastmail.com>

Hi Amos

I have done some digging into your suggestion, and it looks like a better way to go for what I need to do.

> Also, are you aware that current Squid versions can generate redirects
> (custom headers included) based on output from an external_acl_type helper?
>  A helper to lookup your permissions system plus a few extra squid.conf
> settings would be a lot simpler in terms of traffic processing and
> bandwidth consumption than sending everything through an external ICAP
> service.

Are you able to point me in the direction of some sample config fragments that show how this can be done please.

I am guessing that I would need to return some custom keyword / value pairs from the external_acl and set other acls based on the values.

What I am aiming at is to selectively bump or redirect (or both) based on the client status and the site being requested.

Thanks again.

Darren B.



On Wed, Dec 4, 2019, at 6:26 PM, Amos Jeffries wrote:
> On 4/12/19 6:05 am, Darren Breeze wrote:
> > Hi Amos
> > 
> > The Icap service is doing redirects based on client permissions (that may change). What I am doing is just setting the Expires value in the RESP_MOD response when I return a 307 redirect so I can control how long the caches (both Squid and the browser) hang on to it.
> > 
> 
> In that case you should be using Cache-Control:max-age=NN instead where
> the NN being your desired TTL in seconds. This is a *lot* simpler and
> faster to deliver than calculating the timestamps needed for valid
> Expires header.
> 
> Also, are you aware that current Squid versions can generate redirects
> (custom headers included) based on output from an external_acl_type helper?
>  A helper to lookup your permissions system plus a few extra squid.conf
> settings would be a lot simpler in terms of traffic processing and
> bandwidth consumption than sending everything through an external ICAP
> service.
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are addressed. If you have received this email in error please notify the system manager. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. If you are not the intended recipient you are notified that disclosing, copying, distributing or taking any action in reliance on the contents of this information is strictly prohibited.



From tom at signagelive.com  Fri Dec  6 16:33:42 2019
From: tom at signagelive.com (tomsl)
Date: Fri, 6 Dec 2019 10:33:42 -0600 (CST)
Subject: [squid-users] Squid caching broken responses
In-Reply-To: <1f6a7832-ddba-50eb-402b-42c0e9da8b4f@treenet.co.nz>
References: <1575455363400-0.post@n4.nabble.com>
 <af044852-f7d4-8219-8d4e-6b7be64bc30b@treenet.co.nz>
 <1575545015689-0.post@n4.nabble.com>
 <1f6a7832-ddba-50eb-402b-42c0e9da8b4f@treenet.co.nz>
Message-ID: <1575650022675-0.post@n4.nabble.com>

I was able to get it working by making the squid user the owner of the file. 

The upgraded squid server, however, still seems to be an issue some files
returned by the cache, as some appear complete yet have a Content-Length
value of 0, so they don't work. At this point I am thinking that the fault
here is with Rackspace servicenet/cloudfiles and not with squid, as the
issue did not happen when using the CDN. Unfortunately, the CDN costs money.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From dc.sqml at ntcomputer.de  Sat Dec  7 13:54:36 2019
From: dc.sqml at ntcomputer.de (Nikolaus)
Date: Sat, 7 Dec 2019 14:54:36 +0100
Subject: [squid-users] Resolved: Peek-and-splice not working when mixing
 TLS1.3 servers and TLS1.2 clients
In-Reply-To: <C0120FA3-A50E-4AB5-AE98-FD7874C073E7@gmail.com>
References: <a84f26eb-0580-f134-4d36-bfa7b1a4d5ea@measurement-factory.com>
 <C0120FA3-A50E-4AB5-AE98-FD7874C073E7@gmail.com>
Message-ID: <a0cb15df-648c-c0f6-f410-948176524683@ntcomputer.de>

I was able to solve the issue, fixing both squid-side
"error:1425F175:SSL routines:ssl_choose_client_version:inappropriate
fallback (1/-1/0)" and client-side certificate verification errors when
attempting to contact TLS 1.3 server over a TLS 1.3-enabled squid from a
TLS 1.2 client. I will first explain what causes the issue before
presenting my solution, which involves changes of the squid code base,
for anybody who is affected by the same problem.

I have inspected the squid source code and noticed that TLS peeking
works roughly like this:

1. The client sends a client_hello, which is parsed by squid using a
custom handshake parser.? <-- Uses TLS 1.2
2. Squid creates an OpenSSL TLS session for the peeked connection? <--
Uses TLS 1.3!
3. Squid forwards the original client_hello handshake message to the
server <-- TLS 1.2
4. Squid passes the received server_hello response to the OpenSSL
session created previously? <-- Response uses TLS 1.2 - Problem!

Now, the "problem" is that TLS 1.3 defines a set of new protocol
downgrade attack prevention mechanisms (can be found e.g. here:
https://blog.gypsyengineer.com/en/security/how-does-tls-1-3-protect-against-downgrade-attacks.html).
Both OpenSSL and most likely the server implement these. This includes
that the server random in the TLS 1.2 server_hello contains an indicator
that the server is TL 1.3-capable. The OpenSSL session created by squid
detects this, notices that it is TLS 1.3-capable itself, and closes the
connection because it assumes a protocol downgrade attack! Little does
it know, that our client actually only supports TLS 1.2, so we *want*
the lower protocol version.

My solution includes setting the maximum TLS version of the OpenSSL
session to the version received from the client. This proved a little
bit difficult, since the way TLS versions are negotiated has also been
changed by the TLS 1.3 specification, and the squid handshake parser was
not yet able to detect TLS 1.3 correctly - I have therefore also
implemented parsing of the SupportedVersions TLS Extension and a
preliminary support for sparse version ranges. You can find all these
changes at
https://github.com/nthuemmel/squid/tree/tls_downgrade_compatibility ,
which is a fork of squid 4.9. Feel free to compile & test it if you have
a transparent peek-and-splice setup and are affected by the
"inappropriate fallback" problem.

I would of course be glad if the fix could be merged into the main squid
repository. If you are a dev, please let me know what you think and if I
should open a pull request. There are still some TODOs left, because I
wasn't sure what the best way is to integrate some of the changes.
Notably, there was also a comment which discourages setting a maximum
version for the OpenSSL session to improve peek+bump compatibility - I
don't have a setup to which this applies, so I don't know how big of an
impact this is or if it is still relevant.

Best Regards
Nikolaus
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191207/3146565a/attachment.htm>

From rousskov at measurement-factory.com  Sat Dec  7 15:10:48 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 7 Dec 2019 10:10:48 -0500
Subject: [squid-users] Resolved: Peek-and-splice not working when mixing
 TLS1.3 servers and TLS1.2 clients
In-Reply-To: <a0cb15df-648c-c0f6-f410-948176524683@ntcomputer.de>
References: <a84f26eb-0580-f134-4d36-bfa7b1a4d5ea@measurement-factory.com>
 <C0120FA3-A50E-4AB5-AE98-FD7874C073E7@gmail.com>
 <a0cb15df-648c-c0f6-f410-948176524683@ntcomputer.de>
Message-ID: <fc6ff367-b5e9-6c2b-aead-cc09da2766b1@measurement-factory.com>

On 12/7/19 8:54 AM, Nikolaus wrote:

> https://github.com/nthuemmel/squid/tree/tls_downgrade_compatibility
> 
> I would of course be glad if the fix could be merged into the main squid
> repository. If you are a dev, please let me know what you think and if I
> should open a pull request.


FYI: There are two other ongoing and independent efforts related to TLS
v1.3 version handling:

[1] Fix stalled SslBump-peeked connections from older browsers
    https://github.com/measurement-factory/squid/pull/60/

[2] Bug 5011: TLS 1.3 connection get stuck when parsing ServerHello
    https://bugs.squid-cache.org/show_bug.cgi?id=5011

My team is responsible for [1]. Our unofficial (and currently very
unpolished) code should be ready for the official review in a couple of
weeks. AFAICT from a quick look through your changes, we are working on
the same or a very similar problem. If you can test [1] in your
environment, please let me know whether it works in your environment.

I am not sure what is the best way to minimize further duplication of
effort here. Here is one option: If [1] works in your environment, and
you would rather avoid porting your changes to master, then perhaps you
can help with reviewing and backporting [1] (after it is officially
reviewed) to v4 instead.

If you decide to improve your branch towards its official submission,
please see https://wiki.squid-cache.org/MergeProcedure and keep in mind
that you will need to port your changes to master. Please also consider
_not_ storing the entire array of parsed supported versions if storing
just a couple of them (or storing their implications) is sufficient.
Please also note that SSL_set_max_proto_version() is not available in
OpenSSL v1.0. If Squid still supports that older OpenSSL version, it
would be best to avoid dropping that support because of this change.

If you have technical/development comments regarding [1], they are
probably best handled as pull request comments on GitHub (or a
discussion on the squid-dev@ mailing list). The squid-users@ mailing
list is not a good place to discuss code.


Thank you,

Alex.


From g2011828 at hotmail.com  Sun Dec  8 06:53:24 2019
From: g2011828 at hotmail.com (George Sheng)
Date: Sun, 8 Dec 2019 06:53:24 +0000
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
	back to the client?
Message-ID: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>


Hi,

I?m new to this group. I just setup a squid ver 4.5 on my ubuntu machine. I configured this proxy to receive
https packets from another device on the same LAN, and modified the iptables to redirect the port 443 packets
to the squid proxy port 3130.

I can see the client https packet has been received and the proxy is ready to do the ?bump?, the fd to the client
connection is 13:

**
2019/12/07 20:48:59.586 kid1| 85,4| client_side_request.cc<http://client_side_request.cc>(1510) processRequest: CONNECT x.y.43.31:443
2019/12/07 20:48:59.586 kid1| 85,5| client_side_request.cc<http://client_side_request.cc>(1597) sslBumpStart: Confirming peek-bumped CONNECT tunnel on FD local=x.y..31:443 remote=192.168.1.25:39273 FD 13 flags=33
**


From the debug I can also see the proxy  connects towards the remote
server, and proxy has negotiated fine with the server. the proxy receives 3 certificates from the server,
and verification was fine to the server. But when the proxy trying to proceed with client negotiation, I got this error:

***
2019/12/07 20:48:59.760 kid1| 33,5| client_side.cc<http://client_side.cc>(2859) sslCrtdHandleReply: Certificate for x.y.43.31 was successfully recieved from ssl_crtd
2019/12/07 20:48:59.760 kid1| 33,5| client_side.cc<http://client_side.cc>(3335) doPeekAndSpliceStep: PeekAndSplice mode, proceed with client negotiation. Currrent state:SSLv2/v3 read client hello A
2019/12/07 20:48:59.760 kid1| 5,5| ModEpoll.cc<http://ModEpoll.cc>(117) SetSelect: FD 13, type=2, handler=1, client_data=0x15beef8, timeout=0
2019/12/07 20:48:59.760 kid1| 84,5| helper.cc<http://helper.cc>(1247) GetFirstAvailable: GetFirstAvailable: Running servers 5
2019/12/07 20:48:59.760 kid1| 5,4| AsyncCall.cc<http://AsyncCall.cc>(26) AsyncCall: The AsyncCall helperHandleRead constructed, this=0x1a37c50 [call827]
2019/12/07 20:48:59.760 kid1| 5,5| Read.cc<http://Read.cc>(57) comm_read_base: comm_read, queueing read for local=[::] remote=[::] FD 10 flags=1; asynCall 0x1a37c50*1
2019/12/07 20:48:59.760 kid1| 5,5| ModEpoll.cc<http://ModEpoll.cc>(117) SetSelect: FD 10, type=1, handler=1, client_data=0x155cce8, timeout=0
2019/12/07 20:48:59.760 kid1| 5,4| AsyncCallQueue.cc<http://AsyncCallQueue.cc>(57) fireNext: leaving helperHandleRead(local=[::] remote=[::] FD 10 flags=1, data=0x157f9a8, size=3384, buf=0x157fbd0)
2019/12/07 20:48:59.760 kid1| 83,5| bio.cc<http://bio.cc>(612) squid_bio_ctrl: 0x1a5e140 6(0, 0x1a76c00)
2019/12/07 20:48:59.761 kid1| 83,5| Session.cc<http://Session.cc>(347) get_session_cb: Request to search for SSL_SESSION of len: 321019023443:419801955
2019/12/07 20:48:59.761 kid1| 54,5| MemMap.cc<http://MemMap.cc>(156) openForReading: trying to open slot for key 5310BD3C63AB0519C4F984A35A8DC1AE for reading in map [tls_session_cache]
2019/12/07 20:48:59.761 kid1| 54,5| MemMap.cc<http://MemMap.cc>(177) openForReadingAt: trying to open slot at 18 for reading in map [tls_session_cache]
2019/12/07 20:48:59.761 kid1| 54,5| MemMap.cc<http://MemMap.cc>(169) openForReading: failed to open slot for key 5310BD3C63AB0519C4F984A35A8DC1AE for reading in map [tls_session_cache]
2019/12/07 20:48:59.761 kid1| 83,5| Session.cc<http://Session.cc>(362) get_session_cb: Failed to retrieve SSL_SESSION from cache
***

Here is my squid.conf:

#
acl localnet src 192.168.1.0/24
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3

ssl_bump peek step1
ssl_bump stare step2
ssl_bump bump all

acl SSL_ports port 443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localnet
http_access allow localhost
http_access deny all
http_port 3128
http_port 3129 intercept
https_port 3130 intercept ssl-bump cert=/usr/local/squid/etc/ssl_cert/myCA.pem generate-host-certificates=on dynamic_cert_mem_cache_size=4MB key=/usr/local/
squid/etc/ssl_cert/myCA.pem

sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s /usr/local/squid/var/logs/ssl_db -M 4MB
coredump_dir /usr/local/squid/var/cache/squid
cache_dir ufs /usr/local/squid/var/cache/squid 1000 16 256 # 1GB as Cache

##

I?m wondering if this problem is a bug, my proxy config issue, or the client does not send the correct TLS parameters.
thanks for your help in advance.

Cheers,
- George

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191208/b3a92efc/attachment.htm>

From selimakpinar at protonmail.com  Sun Dec  8 07:35:18 2019
From: selimakpinar at protonmail.com (mandev)
Date: Sun, 8 Dec 2019 01:35:18 -0600 (CST)
Subject: [squid-users] Https inception gives 503 error
Message-ID: <1575790518545-0.post@n4.nabble.com>

Hi,

I am using pfsense with squid and squidguard for web filtering without
client side certificate installation. I did manage to block pages and mostly
error free internet traffic. But for the last thing i cannot work it. I want
to redirect users to a block page and i did this with http but cannot do
this with https. When a blocked page visited it gives
"SSL_ERROR_RX_RECORD_TOO_LONG" error. Debug it a lot for this issue and my
founding are below and config files are attached (its pfsense so not much
mostly automatic files);

When i access a http page this is how squid redirects:

2019/12/08 06:32:02.735 kid1| 5,3| comm.cc(553) commSetConnTimeout:
local=34.249.120.252:80 remote=192.168.10.10:35178 FD 18 flags=33 timeout
86400
2019/12/08 06:32:02.735 kid1| 23,3| url.cc(371) urlParse: urlParse: Split
URL 'http://hurriyet.com.tr/' into proto='http', host='hurriyet.com.tr',
port='80', path='/'
2019/12/08 06:32:02.735 kid1| 14,3| Address.cc(389) lookupHostIP: Given
Non-IP 'hurriyet.com.tr': hostname nor servname provided, or not known
2019/12/08 06:32:02.735 kid1| 33,3| client_side.cc(891)
clientSetKeepaliveFlag: http_ver = HTTP/1.1

When i access a https page this happends:

2019/12/08 06:28:14.431 kid1| 23,3| url.cc(371) urlParse: urlParse: Split
URL
'http://192.168.10.1:80/sgerror.php?url=403%20&a=192.168.10.10&n=192.168.10.10&i=&s=default&t=blacklist&u=selimakpinar.com:443'
into proto='', host='http', port='443', path=''
2019/12/08 06:28:14.431 kid1| 14,3| Address.cc(389) lookupHostIP: Given
Non-IP 'http': hostname nor servname provided, or not known
2019/12/08 06:28:14.431 kid1| 61,2| client_side_request.cc(1286)
clientRedirectDone: URL-rewriter diverts URL from selimakpinar.com:443 to
http:443
2019/12/08 06:28:14.431 kid1| 83,3| client_side_request.cc(1743) doCallouts:
Doing calloutContext->clientAccessCheck2()

access.log;

1575790083.949      7 192.168.10.10 TAG_NONE/200 0 CONNECT 104.18.58.42:443
- HIER_NONE/- -
1575790084.047     99 192.168.10.10 TAG_NONE/503 0 CONNECT
selimakpinar.com:443 - HIER_NONE/- -


squid.conf
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377846/squid.conf>  
squidGuard.conf
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377846/squidGuard.conf>  





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From augustus_meyer at gmx.net  Sun Dec  8 10:01:13 2019
From: augustus_meyer at gmx.net (reinerotto)
Date: Sun, 8 Dec 2019 04:01:13 -0600 (CST)
Subject: [squid-users] Https inspection gives 503 error
In-Reply-To: <1575790518545-0.post@n4.nabble.com>
References: <1575790518545-0.post@n4.nabble.com>
Message-ID: <1575799273127-0.post@n4.nabble.com>

You can _not_ present a block page for https-block. 
Already quite a few discussions about it here on forum. Pls, use search
function.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From selimakpinar at protonmail.com  Sun Dec  8 10:38:05 2019
From: selimakpinar at protonmail.com (mandev)
Date: Sun, 8 Dec 2019 04:38:05 -0600 (CST)
Subject: [squid-users] Https inspection gives 503 error
In-Reply-To: <1575799273127-0.post@n4.nabble.com>
References: <1575790518545-0.post@n4.nabble.com>
 <1575799273127-0.post@n4.nabble.com>
Message-ID: <1575801485448-0.post@n4.nabble.com>

Thank you for the reply. Is it not possible with squid or technicly because
fortigate can do this. If you look logs that i write at first message. It's
looks like there is an error in redirects. It trys to redirect 'http'
address there is no address like 'http'.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Sun Dec  8 11:13:06 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 9 Dec 2019 00:13:06 +1300
Subject: [squid-users] Https inception gives 503 error
In-Reply-To: <1575790518545-0.post@n4.nabble.com>
References: <1575790518545-0.post@n4.nabble.com>
Message-ID: <b96bee86-88e7-8c28-3b0b-890a37ca77a9@treenet.co.nz>

On 8/12/19 8:35 pm, mandev wrote:
> Hi,
> 
> I am using pfsense with squid and squidguard for web filtering without
> client side certificate installation. I did manage to block pages and mostly
> error free internet traffic. But for the last thing i cannot work it. I want
> to redirect users to a block page and i did this with http but cannot do
> this with https. 

You cannot redirect a CONNECT transaction. It is a request to open a tunnel.

If you wish to continue using the very obsolete and unmaintained
squidguard tool you will need to add this to your squid.conf:

 url_rewrite_access deny CONNECT


To do anything like send error pages to users with intercepted HTTPS
traffic requires SSL-Bump to decrypt the tunnel contents first.

Amos


From selimakpinar at protonmail.com  Sun Dec  8 11:38:18 2019
From: selimakpinar at protonmail.com (mandev)
Date: Sun, 8 Dec 2019 05:38:18 -0600 (CST)
Subject: [squid-users] Https inception gives 503 error
In-Reply-To: <b96bee86-88e7-8c28-3b0b-890a37ca77a9@treenet.co.nz>
References: <1575790518545-0.post@n4.nabble.com>
 <b96bee86-88e7-8c28-3b0b-890a37ca77a9@treenet.co.nz>
Message-ID: <1575805098467-0.post@n4.nabble.com>

Thank you for reply. Long time i have been using squidguard. Maybe it is time
to change or start writing a new one with comminity. Thank for the help. 



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Sun Dec  8 11:53:45 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 9 Dec 2019 00:53:45 +1300
Subject: [squid-users] Https inception gives 503 error
In-Reply-To: <1575805098467-0.post@n4.nabble.com>
References: <1575790518545-0.post@n4.nabble.com>
 <b96bee86-88e7-8c28-3b0b-890a37ca77a9@treenet.co.nz>
 <1575805098467-0.post@n4.nabble.com>
Message-ID: <0b08acdf-9c4a-227e-de92-826809c9de11@treenet.co.nz>

On 9/12/19 12:38 am, mandev wrote:
> Thank you for reply. Long time i have been using squidguard. Maybe it is time
> to change or start writing a new one with comminity. Thank for the help. 
> 

There is ufdbguard.

But the fundamental thing is that you cannot respond to a TCP SYN packet
 or TLS clientHello handshake with an HTML web page. That is essentially
what your redirector is telling Squid to do.

Amos


From squid3 at treenet.co.nz  Sun Dec  8 13:49:40 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 9 Dec 2019 02:49:40 +1300
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
Message-ID: <9b0a12c8-e979-a6f9-c604-f2116a22228d@treenet.co.nz>

On 8/12/19 7:53 pm, George Sheng wrote:
> 
> Hi,
> 
> I?m new to this group. I just setup a squid ver 4.5 on my ubuntu

When using SSL-Bump one does need to use the latest release. Which is
4.9 now.

Since this is a custom build (4.5 has never been a release in Ubuntu)
you may find Squid-5 has even less issues for SSL-Bump.



...
> 2019/12/07 20:48:59.761 kid1| 83,5| Session.cc <http://Session.cc>(347)
> get_session_cb: Request to search for SSL_SESSION of
> len:?321019023443:419801955
> 2019/12/07 20:48:59.761 kid1| 54,5| MemMap.cc <http://MemMap.cc>(156)
> openForReading: trying to open slot for
> key?5310BD3C63AB0519C4F984A35A8DC1AE for reading in map [tls_session_cache]
> 2019/12/07 20:48:59.761 kid1| 54,5| MemMap.cc <http://MemMap.cc>(177)
> openForReadingAt: trying to open slot at 18 for reading in
> map?[tls_session_cache]
> 2019/12/07 20:48:59.761 kid1| 54,5| MemMap.cc <http://MemMap.cc>(169)
> openForReading: failed to open slot for
> key?5310BD3C63AB0519C4F984A35A8DC1AE for reading in map [tls_session_cache]
> 2019/12/07 20:48:59.761 kid1| 83,5| Session.cc <http://Session.cc>(362)
> get_session_cb: Failed to retrieve SSL_SESSION from cache
> ***

This is talking about Squid's internal cache of TLS sessions that
clients have negotiated previously with this Squid. It means the client
is attempting to use/resume a TLS session ID that does not exist. There
is nothing anyone can do about that.


> 
> Here is my squid.conf:
> 
...
> https_port 3130 intercept ssl-bump
> cert=/usr/local/squid/etc/ssl_cert/myCA.pem
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> key=/usr/local/
> squid/etc/ssl_cert/myCA.pem
> 

FYI: with cert= and key= pointing at the same file you do not need the
key= option.


> ##
> 
> I?m wondering if this problem is a bug, my proxy config issue, or the
> client does not send the correct TLS parameters.
> thanks for your help in advance.
> 

The problem is most likely the client.

If the session ID actually was negotiated previously with this Squid
there may be shared-memory issues on your machine. Even with only one
worker this cache uses SMP functionality

If you only just started this Squid, the session may have been
negotiated with the origin or previous Squid instance. In that case it
is normal to get at least a few of these until they timeout and/or get
renegotiated.


Amos


From g2011828 at hotmail.com  Sun Dec  8 19:58:57 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Sun, 8 Dec 2019 13:58:57 -0600 (CST)
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <9b0a12c8-e979-a6f9-c604-f2116a22228d@treenet.co.nz>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
 <9b0a12c8-e979-a6f9-c604-f2116a22228d@treenet.co.nz>
Message-ID: <1575835137690-0.post@n4.nabble.com>

Hi Amos,

thanks for the comments. I'll first try the later version as you pointed out
4.9 and see if I get the issues. Will report back.
thanks.

- George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From g2011828 at hotmail.com  Sun Dec  8 21:41:38 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Sun, 8 Dec 2019 15:41:38 -0600 (CST)
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <1575835137690-0.post@n4.nabble.com>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
 <9b0a12c8-e979-a6f9-c604-f2116a22228d@treenet.co.nz>
 <1575835137690-0.post@n4.nabble.com>
Message-ID: <1575841298196-0.post@n4.nabble.com>

Hi Amos,

i downloaded the 4.9 latest, and compiled with "./configure
--with-default-user=proxy --with-openssl --enable-ssl-crtd", not redo the
openssl and proxy certificate part, start squid with 4.9, still seeing
failure. Have not debugged in detail. 
Quick question, when compile for the bump usage case, do i need to use the
with-gnutls option also?
just wondering.

thanks.
- George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From g2011828 at hotmail.com  Mon Dec  9 05:53:30 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Sun, 8 Dec 2019 23:53:30 -0600 (CST)
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <1575841298196-0.post@n4.nabble.com>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
 <9b0a12c8-e979-a6f9-c604-f2116a22228d@treenet.co.nz>
 <1575835137690-0.post@n4.nabble.com> <1575841298196-0.post@n4.nabble.com>
Message-ID: <1575870810669-0.post@n4.nabble.com>


the version 4.9 has the same behavior, can not finish negotiate with the
client.
I have setup two different client machines, one is macOS, the other alpine
linux.

I finally got the macOS wget https to work through the squid 4.9 proxy with
ssl-bump.
So the squid config is ok.

The alpine linux, using the wget https, got error message ssl_client:
handshake failed: error:14004410:SSL routines:CONNECT_CR_SRVR_HELLO:sslv3
alert handshake failure (on the proxy log, it is the same thing, can not
somehow retrieve the ssl session, probably due to some TLS mismatch)

I'm wondering if you know normally what kind of mismatch this is between the
client and proxy.
if i'm using wget https for testing, what kind of parameters I need to
change to match them.

thanks.
- George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Mon Dec  9 05:12:31 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 9 Dec 2019 18:12:31 +1300
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <1575841298196-0.post@n4.nabble.com>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
 <9b0a12c8-e979-a6f9-c604-f2116a22228d@treenet.co.nz>
 <1575835137690-0.post@n4.nabble.com> <1575841298196-0.post@n4.nabble.com>
Message-ID: <2a90e9b1-60e4-d806-64d4-4a60b0666668@treenet.co.nz>

On 9/12/19 10:41 am, GeorgeShen wrote:
> Hi Amos,
> 
> i downloaded the 4.9 latest, and compiled with "./configure
> --with-default-user=proxy --with-openssl --enable-ssl-crtd", not redo the
> openssl and proxy certificate part, start squid with 4.9, still seeing
> failure. Have not debugged in detail. 
> Quick question, when compile for the bump usage case, do i need to use the
> with-gnutls option also?

No, GnuTLS is just an alternative to OpenSSL for those where the OpenSSL
license vs GPL incompatibility matters (anyone distributing both OPenSSL
and Squid packages - eg Ubuntu itself).

It still lacks most of the the SSL-Bump features. So eventually you
might be able to choose between them, but right now OpenSSL is needed to
do interception of HTTPS.

Amos


From vieridipaola at gmail.com  Mon Dec  9 07:49:57 2019
From: vieridipaola at gmail.com (Vieri Di Paola)
Date: Mon, 9 Dec 2019 08:49:57 +0100
Subject: [squid-users] deny_info redirect with URL placeholder
Message-ID: <CABLYT9jWy9Gjd0m5zPLJDg7xuvJ_eDuNFctCOsNRTYswgToVkw@mail.gmail.com>

Hi,

Is there a way to add a URL variable name to a deny_info 302
configuration directive?

Suppose I have the following:

external_acl_type location_rewriter ttl=86400 negative_ttl=86400
children-max=80 children-startup=10 children-idle=3 concurrency=8
%<h{Location} /my/rewrite_helper.pl -debug=1
acl bad_Location external location_rewriter
deny_info 302:URL_FROM_LOCATION_REWRITER bad_Location
acl 302 http_status 302
http_reply_access deny 302 bad_Location

How can I dynamically replace URL_FROM_LOCATION_REWRITER with the URL
redirection value produced by the helper script /my/rewrite_helper.pl?
Could it be possible to refer to the values of "message=" or "tag="
depending on the result output of the helper script?
How could I refer to these values in the deny_info 302:%* line?

Thanks,

Vieri


From squid3 at treenet.co.nz  Mon Dec  9 09:03:39 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 9 Dec 2019 22:03:39 +1300
Subject: [squid-users] deny_info redirect with URL placeholder
In-Reply-To: <CABLYT9jWy9Gjd0m5zPLJDg7xuvJ_eDuNFctCOsNRTYswgToVkw@mail.gmail.com>
References: <CABLYT9jWy9Gjd0m5zPLJDg7xuvJ_eDuNFctCOsNRTYswgToVkw@mail.gmail.com>
Message-ID: <c7e10a7f-bbb7-ae36-38f3-933967220297@treenet.co.nz>

On 9/12/19 8:49 pm, Vieri Di Paola wrote:
> Hi,
> 
> Is there a way to add a URL variable name to a deny_info 302
> configuration directive?
> 

<https://wiki.squid-cache.org/Features/CustomErrors> or as I showed
earlier with logformat codes. Though sorry that does require a later
Squid version that the one you have.


> Suppose I have the following:
> 
> external_acl_type location_rewriter ttl=86400 negative_ttl=86400
> children-max=80 children-startup=10 children-idle=3 concurrency=8
> %<h{Location} /my/rewrite_helper.pl -debug=1
> acl bad_Location external location_rewriter
> deny_info 302:URL_FROM_LOCATION_REWRITER bad_Location
> acl 302 http_status 302
> http_reply_access deny 302 bad_Location
> 
> How can I dynamically replace URL_FROM_LOCATION_REWRITER with the URL
> redirection value produced by the helper script /my/rewrite_helper.pl?
> Could it be possible to refer to the values of "message=" or "tag="
> depending on the result output of the helper script?

Not in Squid-3. The tag= is not supported by the deny_info template
codes. Only the message= can be used.


> How could I refer to these values in the deny_info 302:%* line?

 deny_info 302:https:%o bad_Location

This should do it for Squid-3 (and avoids the config parser bug). You
just have to have the helper produce the URL (without the "https:"
scheme name) as its message= value.


Amos


From vieridipaola at gmail.com  Mon Dec  9 09:20:51 2019
From: vieridipaola at gmail.com (Vieri Di Paola)
Date: Mon, 9 Dec 2019 10:20:51 +0100
Subject: [squid-users] deny_info redirect with URL placeholder
In-Reply-To: <c7e10a7f-bbb7-ae36-38f3-933967220297@treenet.co.nz>
References: <CABLYT9jWy9Gjd0m5zPLJDg7xuvJ_eDuNFctCOsNRTYswgToVkw@mail.gmail.com>
 <c7e10a7f-bbb7-ae36-38f3-933967220297@treenet.co.nz>
Message-ID: <CABLYT9h==Eph5+F76_nYxZCP6KBT_SYLxAW4cp7Dd1OT57rVuA@mail.gmail.com>

On Mon, Dec 9, 2019 at 10:04 AM Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
> > Is there a way to add a URL variable name to a deny_info 302
> > configuration directive?
> >
>
> <https://wiki.squid-cache.org/Features/CustomErrors> or as I showed
> earlier with logformat codes. Though sorry that does require a later
> Squid version that the one you have.

I set up a test server with the latest stable Squid release:

2019/12/09 10:17:43| FATAL: status 302 requires a URL on
'302:%note{location-rewrite}'
2019/12/09 10:17:43| FATAL: Bungled /etc/squid/squid.aida.include line
60: deny_info 302:%note{location-rewrite} bad_Location
2019/12/09 10:17:43| Squid Cache (Version 4.9): Terminated abnormally.

This is the offending configuration line:

deny_info 302:%note{location-rewrite} bad_Location

Is the syntax OK?

Vieri


From vieridipaola at gmail.com  Mon Dec  9 09:38:47 2019
From: vieridipaola at gmail.com (Vieri Di Paola)
Date: Mon, 9 Dec 2019 10:38:47 +0100
Subject: [squid-users] deny_info redirect with URL placeholder
In-Reply-To: <c7e10a7f-bbb7-ae36-38f3-933967220297@treenet.co.nz>
References: <CABLYT9jWy9Gjd0m5zPLJDg7xuvJ_eDuNFctCOsNRTYswgToVkw@mail.gmail.com>
 <c7e10a7f-bbb7-ae36-38f3-933967220297@treenet.co.nz>
Message-ID: <CABLYT9h-bzK5Wee0SiRTjg3k6_EMPzdb2XTXQKUWKXCxei-NBw@mail.gmail.com>

On Mon, Dec 9, 2019 at 10:04 AM Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
> > How could I refer to these values in the deny_info 302:%* line?
>
>  deny_info 302:https:%o bad_Location
>
> This should do it for Squid-3 (and avoids the config parser bug). You
> just have to have the helper produce the URL (without the "https:"
> scheme name) as its message= value.

Almost, but still not there yet.
All "/" chars are translated to %2f, as in:
https://%2f%2fserver%2fpath...
I guess I need to encode the string somehow.
The helper script is in perl and it looks something like this:

chomp;
my $string = $_;
$string =~ m/^([0-9]+)\s(\S+)$/;
my ($cid, $uri_location) = ($1, $2);
[...]
$status = $cid." OK message=\"".$uri_location."\"";
print $status."\n";

Any ideas?

Vieri


From rudi.kramer at gmail.com  Mon Dec  9 10:41:44 2019
From: rudi.kramer at gmail.com (Rudi Kramer)
Date: Mon, 9 Dec 2019 12:41:44 +0200
Subject: [squid-users] http://www1.ngtech.co.il/ - Down?
In-Reply-To: <CAJrXP6MrX-O2b6Dg6d7uB3YZ1Q=Ph=jh-bQYra6=-4EKEZuobw@mail.gmail.com>
References: <CAJrXP6MrX-O2b6Dg6d7uB3YZ1Q=Ph=jh-bQYra6=-4EKEZuobw@mail.gmail.com>
Message-ID: <CAJrXP6PAdG0FUqwqVfyNTB18qBz0SjXDdhqu4_XRzu51VZ77Qg@mail.gmail.com>

Still no word on this issue?

On Wed, 4 Dec 2019 at 08:17, Rudi Kramer <rudi.kramer at gmail.com> wrote:

> Hello,
>
> As far as I can tell, http://www1.ngtech.co.il/ is down at the moment.
>
> Any word on how long this will be?
>
> Thanks
> Rudi
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191209/1d87fb95/attachment.htm>

From rst at fomar.com.pl  Mon Dec  9 10:58:11 2019
From: rst at fomar.com.pl (=?UTF-8?Q?Rafa=C5=82_Stanilewicz?=)
Date: Mon, 9 Dec 2019 10:58:11 +0000
Subject: [squid-users] http://www1.ngtech.co.il/ - Down?
In-Reply-To: <CAJrXP6PAdG0FUqwqVfyNTB18qBz0SjXDdhqu4_XRzu51VZ77Qg@mail.gmail.com>
References: <CAJrXP6MrX-O2b6Dg6d7uB3YZ1Q=Ph=jh-bQYra6=-4EKEZuobw@mail.gmail.com>
 <CAJrXP6PAdG0FUqwqVfyNTB18qBz0SjXDdhqu4_XRzu51VZ77Qg@mail.gmail.com>
Message-ID: <CAPnyBTPXvd0_MGozU91ssGMixi=g30Zw0j2JRarrRbpf4d_mrQ@mail.gmail.com>

The mirror on
http://linuxsoft.cern.ch/mirror/www1.ngtech.co.il/repo/ still works.

HtH

On Mon, 9 Dec 2019 at 10:42, Rudi Kramer <rudi.kramer at gmail.com> wrote:
>
> Still no word on this issue?
>
> On Wed, 4 Dec 2019 at 08:17, Rudi Kramer <rudi.kramer at gmail.com> wrote:
>>
>> Hello,
>>
>> As far as I can tell, http://www1.ngtech.co.il/ is down at the moment.
>>
>> Any word on how long this will be?
>>
>> Thanks
>> Rudi
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



-- 
Zanim wydrukujesz, pomy?l o ?rodowisku.


From rousskov at measurement-factory.com  Mon Dec  9 15:41:29 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 9 Dec 2019 10:41:29 -0500
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
Message-ID: <724ee00d-44bb-a0df-aa3f-007d13b96970@measurement-factory.com>

On 12/8/19 1:53 AM, George Sheng wrote:

> From the debug I can also see the proxy ?connects towards the remote
> server, and proxy has negotiated fine with the server. the proxy
> receives 3 certificates from the server,
> and verification was fine to the server. But when the proxy trying to
> proceed with client negotiation, I got this error:

> 2019/12/07 20:48:59.761 kid1| 83,5| Session.cc(362)
> get_session_cb: Failed to retrieve SSL_SESSION from cache

As Amos has said, this failure to find a cached session is not an error
in itself. It is a cache miss. Look for problems after this log line.


> The alpine linux, using the wget https, got error message ssl_client:
> handshake failed: error:14004410:SSL routines:CONNECT_CR_SRVR_HELLO:sslv3
> alert handshake failure 

OK.


> (on the proxy log, it is the same thing, can not
> somehow retrieve the ssl session, probably due to some TLS mismatch)

What happens on Squid side _after_ the TLS session is not found in the
cache?

Alex.


From vieridipaola at gmail.com  Mon Dec  9 15:56:58 2019
From: vieridipaola at gmail.com (Vieri Di Paola)
Date: Mon, 9 Dec 2019 16:56:58 +0100
Subject: [squid-users] deny_info redirect with URL placeholder
Message-ID: <CABLYT9iYrVjkTPJ=Az+en1nsH3CCKs-Xp1b+c-i-7rpsxz=zqw@mail.gmail.com>

Is there a way to tell squid to treat %o as-is in deny_info?

In Apache2 with mod_proxy ProxyPass directives, I require to write a
config directive such as:

Header edit Location "(^http[s]?://)([^/]+)" ""

Using %note or %o in squid 4.x or 3.x would be fine, but both have
issues. The config parser in 4.x still complains that a complete URI
is required for deny_info 302.

Still in 4.x, even if I trick it into using this:

deny_info 302:https://%note{location-rewrite} bad_Location

and the helper script outputs something like:

OK location-rewrite="domain without leading protocol://"

I still get the wrong result in the client browser which is literally
trying to connect to https://%note{location-rewrite} (no variable
expansion).

Any thoughts?

Vieri


From guy20034u at yahoo.com  Mon Dec  9 16:52:25 2019
From: guy20034u at yahoo.com (simon ben)
Date: Mon, 9 Dec 2019 16:52:25 +0000 (UTC)
Subject: [squid-users] one site not working
References: <2018052354.7139044.1575910345037.ref@mail.yahoo.com>
Message-ID: <2018052354.7139044.1575910345037@mail.yahoo.com>


Dear All,

?

I am usingSquid version 3.5.2 on Centos ?7 64 bit and its working fine with no issuebut recently got a complain from one user saying that the below site Is notopening..? just says page cannot be displayed

?

https://my.esri.com

?

but if I use a machine without squid itsworking fine

?

the access logs is showing me as below

?

?

1575869460.673??6034 172.16.2.175 TCP_TUNNEL/200 0 CONNECT my.esri.com:443 -HIER_DIRECT/34.210.189.55 -

1575869461.235???559 172.16.2.175 TCP_TUNNEL/200 0 CONNECT my.esri.com:443 - HIER_DIRECT/34.210.189.55-

1575869461.801???562 172.16.2.175 TCP_TUNNEL/200 0 CONNECT my.esri.com:443 -HIER_DIRECT/34.210.189.55 -

1575869462.096???291 172.16.2.175 TCP_TUNNEL/200 0 CONNECT my.esri.com:443 -HIER_DIRECT/34.210.189.55 ?

?

?

Itried to google around and found that the the ip4 prefrence has to enabled forDNS so I did the below in squid config

?

dns_v4_firston

?

butno luck

?

appreciateyour help and advice

?

?

thanksand regards

?

simon

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191209/8dc4e4e2/attachment.htm>

From g2011828 at hotmail.com  Mon Dec  9 17:56:50 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Mon, 9 Dec 2019 11:56:50 -0600 (CST)
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <724ee00d-44bb-a0df-aa3f-007d13b96970@measurement-factory.com>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
 <724ee00d-44bb-a0df-aa3f-007d13b96970@measurement-factory.com>
Message-ID: <1575914210679-0.post@n4.nabble.com>


Hi Alex,

this time I tried, a little different, this is the log from got the server
certs to colose the
SSL with error, and at the end, it is also saying security_file_certgen
crashes rapidly!!!

below the output of log
thanks.
- George


geyBC5spVGniTZ9g4/4EALHmrmP0d4vcbw0FJugljU7jWmdiUQEpoZZCovZY+lyX
IGRmShEZ6Enq77nr6xgMpW080lJojSBBE0bG7tJj8sUeU03xVyHJZJ4cNX7VD/Dn
g0KNg0PA4UvJLMoKal8UqHzxNXjZZ778O7mOOyvdHfkHgUsFdp9a25/nzduUFQ4R
8faCm0U26P8C
-----END CERTIFICATE-----

2019/12/09 09:39:32.243 kid1| 83,5| helper.cc(136) Submit: request from
0x256a4a8 as crtGenRq12500/1
2019/12/09 09:39:32.243 kid1| 84,5| helper.cc(1247) GetFirstAvailable:
GetFirstAvailable: Running servers 5
2019/12/09 09:39:32.243 kid1| 5,5| AsyncCall.cc(26) AsyncCall: The AsyncCall
helperDispatchWriteDone constructed, this=0x2557fe0 [call2906]
2019/12/09 09:39:32.243 kid1| 5,5| Write.cc(35) Write: local=[::]
remote=[::] FD 10 flags=1: sz 5266: asynCall 0x2557fe0*1
2019/12/09 09:39:32.243 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 10,
type=2, handler=1, client_data=0x2091e30, timeout=0
2019/12/09 09:39:32.243 kid1| 84,5| helper.cc(1379) helperDispatch:
helperDispatch: Request sent to
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MB #Hlpr1, 5266 bytes
2019/12/09 09:39:32.243 kid1| 17,4| AsyncJob.cc(154) callEnd: Http1::Server
status out: [ job203]
2019/12/09 09:39:32.243 kid1| 17,4| AsyncCallQueue.cc(57) fireNext: leaving
ConnStateData::ConnStateData::httpsPeeked(local=192.168.1.35:46896
remote=X.Y.82.162:443 FD 15 flags=1, request=0x20fb630*3)
2019/12/09 09:39:32.243 kid1| 93,5| AsyncCallQueue.cc(55) fireNext: entering
Initiate::noteInitiatorAborted()
2019/12/09 09:39:32.243 kid1| 93,5| AsyncCall.cc(38) make: make call
Initiate::noteInitiatorAborted [call2905]
2019/12/09 09:39:32.243 kid1| 93,5| AsyncCall.cc(56) cancel: will not call
Initiate::noteInitiatorAborted [call2905] because job gone
2019/12/09 09:39:32.243 kid1| 93,5| AsyncCall.cc(48) make: will not call
Initiate::noteInitiatorAborted [call2905] because of job gone
2019/12/09 09:39:32.243 kid1| 93,5| AsyncCallQueue.cc(57) fireNext: leaving
Initiate::noteInitiatorAborted()
2019/12/09 09:39:32.243 kid1| 50,3| ModDaemon.cc(110) logfileHandleWrite:
daemon:/usr/local/squid/var/logs/access.log: write returned 106
2019/12/09 09:39:32.243 kid1| 5,5| Write.cc(66) HandleWrite: local=[::]
remote=[::] FD 10 flags=1: off 0, sz 5266.
2019/12/09 09:39:32.243 kid1| 5,5| Write.cc(108) HandleWrite: write()
returns 5266
2019/12/09 09:39:32.243 kid1| 5,3| IoCallback.cc(116) finish: called for
local=[::] remote=[::] FD 10 flags=1 (0, 0)
2019/12/09 09:39:32.243 kid1| 5,5| AsyncCall.cc(93) ScheduleCall:
IoCallback.cc(135) will call helperDispatchWriteDone(local=[::] remote=[::]
FD 10 flags=1, data=0x20b4b18, size=5266, buf=0x20ea960) [call2906]
2019/12/09 09:39:32.243 kid1| 5,5| AsyncCallQueue.cc(55) fireNext: entering
helperDispatchWriteDone(local=[::] remote=[::] FD 10 flags=1,
data=0x20b4b18, size=5266, buf=0x20ea960)
2019/12/09 09:39:32.243 kid1| 5,5| AsyncCall.cc(38) make: make call
helperDispatchWriteDone [call2906]
2019/12/09 09:39:32.243 kid1| 5,5| AsyncCallQueue.cc(57) fireNext: leaving
helperDispatchWriteDone(local=[::] remote=[::] FD 10 flags=1,
data=0x20b4b18, size=5266, buf=0x20ea960)
2019/12/09 09:39:32.243 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 20,
type=2, handler=0, client_data=0, timeout=0
2019/12/09 09:39:32.243 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 10,
type=2, handler=0, client_data=0, timeout=0
2019/12/09 09:39:32.244 kid1| 5,3| Read.cc(145) HandleRead: FD 10, size
32767, retval 3401, errno 0
2019/12/09 09:39:32.244 kid1| 5,3| IoCallback.cc(116) finish: called for
local=[::] remote=[::] FD 10 flags=1 (0, 0)
2019/12/09 09:39:32.244 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 10
flags=1, data=0x20b4b18, size=3401, buf=0x20b4d40) [call2841]
2019/12/09 09:39:32.244 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering
helperHandleRead(local=[::] remote=[::] FD 10 flags=1, data=0x20b4b18,
size=3401, buf=0x20b4d40)
2019/12/09 09:39:32.244 kid1| 5,4| AsyncCall.cc(38) make: make call
helperHandleRead [call2841]
2019/12/09 09:39:32.244 kid1| 84,5| helper.cc(963) helperHandleRead:
helperHandleRead: 3401 bytes from
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MB #Hlpr1
2019/12/09 09:39:32.244 kid1| 84,3| helper.cc(991) helperHandleRead:
helperHandleRead: end of reply found
2019/12/09 09:39:32.244 kid1| 84,3| Reply.cc(41) finalize: Parsing helper
buffer
2019/12/09 09:39:32.244 kid1| 84,3| Reply.cc(59) finalize: Buff length is
larger than 2
2019/12/09 09:39:32.244 kid1| 84,3| Reply.cc(63) finalize: helper Result =
OK
2019/12/09 09:39:32.244 kid1| 83,5| helper.cc(158) HandleGeneratorReply: to
0x256a4a8 in crtGenRq12500/1
2019/12/09 09:39:32.244 kid1| 33,5| client_side.cc(2870) sslCrtdHandleReply:
Certificate for X.Y.82.162 was successfully recieved from ssl_crtd
2019/12/09 09:39:32.245 kid1| 33,5| client_side.cc(3358)
doPeekAndSpliceStep: PeekAndSplice mode, proceed with client negotiation.
Currrent state:SSLv2/v3 read client hello A
2019/12/09 09:39:32.245 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 13,
type=2, handler=1, client_data=0x256a4a8, timeout=0
2019/12/09 09:39:32.245 kid1| 84,5| helper.cc(1247) GetFirstAvailable:
GetFirstAvailable: Running servers 5
2019/12/09 09:39:32.245 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
helperHandleRead constructed, this=0x258f150 [call2907]
2019/12/09 09:39:32.245 kid1| 5,5| Read.cc(57) comm_read_base: comm_read,
queueing read for local=[::] remote=[::] FD 10 flags=1; asynCall 0x258f150*1
2019/12/09 09:39:32.245 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 10,
type=1, handler=1, client_data=0x2091df8, timeout=0
2019/12/09 09:39:32.245 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving
helperHandleRead(local=[::] remote=[::] FD 10 flags=1, data=0x20b4b18,
size=3401, buf=0x20b4d40)
2019/12/09 09:39:32.245 kid1| 83,5| bio.cc(612) squid_bio_ctrl: 0x20d61f0
6(0, 0x2592b20)
2019/12/09 09:39:32.245 kid1| 83,5| bio.cc(113) write: FD 13 wrote 7 <= 7
2019/12/09 09:39:32.245 kid1| 83,5| bio.cc(612) squid_bio_ctrl: 0x20d61f0
11(0, 0)
2019/12/09 09:39:32.245 kid1| *Error negotiating SSL connection on FD 13:
error:00000001:lib(0):func(0):reason(1) (1/-1)*
2019/12/09 09:39:32.245 kid1| 5,3| comm.cc(859) _comm_close: comm_close:
start closing FD 13
2019/12/09 09:39:32.245 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
commStartTlsClose constructed, this=0x25983a0 [call2908]
2019/12/09 09:39:32.245 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(892) will call commStartTlsClose(FD 13) [call2908]
2019/12/09 09:39:32.245 kid1| 5,3| comm.cc(546) commUnsetFdTimeout: Remove
timeout for FD 13
2019/12/09 09:39:32.245 kid1| 5,5| comm.cc(727) commCallCloseHandlers:
commCallCloseHandlers: FD 13
2019/12/09 09:39:32.245 kid1| 5,5| comm.cc(735) commCallCloseHandlers:
commCallCloseHandlers: ch->handler=0x256df80*1
2019/12/09 09:39:32.245 kid1| 33,5| AsyncCall.cc(93) ScheduleCall:
comm.cc(736) will call ConnStateData::connStateClosed(FD -1, data=0x256a4a8)
[call2864]
2019/12/09 09:39:32.245 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
comm_close_complete constructed, this=0x256d600 [call2909]
2019/12/09 09:39:32.245 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(930) will call comm_close_complete(FD 13) [call2909]
2019/12/09 09:39:32.245 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering
commStartTlsClose(FD 13)
2019/12/09 09:39:32.245 kid1| 5,4| AsyncCall.cc(38) make: make call
commStartTlsClose [call2908]
2019/12/09 09:39:32.245 kid1| 83,5| Session.cc(202) SessionSendGoodbye:
session=0x259dbd0
2019/12/09 09:39:32.245 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving
commStartTlsClose(FD 13)
2019/12/09 09:39:32.245 kid1| 33,5| AsyncCallQueue.cc(55) fireNext: entering
ConnStateData::connStateClosed(FD -1, data=0x256a4a8)
2019/12/09 09:39:32.246 kid1| 33,5| AsyncCall.cc(38) make: make call
ConnStateData::connStateClosed [call2864]
2019/12/09 09:39:32.246 kid1| 33,5| AsyncJob.cc(123) callStart:
Http1::Server status in: [ job203]
2019/12/09 09:39:32.246 kid1| 93,4| AsyncJob.cc(55) deleteThis:
Http1::Server will NOT delete in-call job, reason:
ConnStateData::connStateClosed
2019/12/09 09:39:32.246 kid1| 93,5| AsyncJob.cc(139) callEnd:
ConnStateData::connStateClosed(FD -1, data=0x256a4a8) ends job [Stopped,
reason:ConnStateData::connStateClosed job203]
2019/12/09 09:39:32.246 kid1| 33,2| client_side.cc(582) swanSong:
local=X.Y.82.162:443 remote=192.168.1.25:53556 flags=33
2019/12/09 09:39:32.246 kid1| 33,3| client_side.cc(4118) unpinConnection:
local=192.168.1.35:46896 remote=X.Y.82.162:443 FD 15 flags=1
2019/12/09 09:39:32.246 kid1| 5,5| comm.cc(1030) comm_remove_close_handler:
comm_remove_close_handler: FD 15, AsyncCall=0x25b4d10*2
2019/12/09 09:39:32.246 kid1| 33,5| AsyncCall.cc(56) cancel: will not call
ConnStateData::clientPinnedConnectionClosed [call2903] because
comm_remove_close_handler
2019/12/09 09:39:32.246 kid1| 33,3| AsyncCall.cc(56) cancel: will not call
ConnStateData::clientPinnedConnectionRead [call2904] because
comm_read_cancel
2019/12/09 09:39:32.246 kid1| 33,3| AsyncCall.cc(56) cancel: will not call
ConnStateData::clientPinnedConnectionRead [call2904] also because
comm_read_cancel
2019/12/09 09:39:32.246 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 15,
type=1, handler=0, client_data=0, timeout=0
2019/12/09 09:39:32.246 kid1| 5,3| comm.cc(859) _comm_close: comm_close:
start closing FD 15
2019/12/09 09:39:32.246 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
commStartTlsClose constructed, this=0x25983a0 [call2910]
2019/12/09 09:39:32.246 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(892) will call commStartTlsClose(FD 15) [call2910]
2019/12/09 09:39:32.246 kid1| 5,3| comm.cc(546) commUnsetFdTimeout: Remove
timeout for FD 15
2019/12/09 09:39:32.246 kid1| 5,5| comm.cc(727) commCallCloseHandlers:
commCallCloseHandlers: FD 15
2019/12/09 09:39:32.246 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
comm_close_complete constructed, this=0x2598420 [call2911]
2019/12/09 09:39:32.246 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(930) will call comm_close_complete(FD 15) [call2911]
2019/12/09 09:39:32.246 kid1| 33,3| client_side.cc(612) ~ConnStateData:
local=X.Y.82.162:443 remote=192.168.1.25:53556 flags=33
2019/12/09 09:39:32.246 kid1| 33,4| ServerBump.cc(46) ~ServerBump:
destroying
2019/12/09 09:39:32.246 kid1| 33,4| ServerBump.cc(48) ~ServerBump:
e:=sp2XIV/0x25617e0*1
2019/12/09 09:39:32.246 kid1| 90,3| store_client.cc(651) storeUnregister:
storeUnregister: called for '41000000000000000E11000001000000'
2019/12/09 09:39:32.246 kid1| 20,3| store_swapout.cc(347) mayStartSwapOut: 
already rejected
2019/12/09 09:39:32.246 kid1| 20,2| store.cc(986) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2019/12/09 09:39:32.246 kid1| 20,3| store.cc(444) lock: storeUnregister
locked key 41000000000000000E11000001000000 e:=sp2XIV/0x25617e0*2
2019/12/09 09:39:32.246 kid1| 90,3| store_client.cc(764)
CheckQuickAbortIsReasonable: entry=e:=sp2XIV/0x25617e0*2
2019/12/09 09:39:32.246 kid1| 90,3| store_client.cc(755)
storePendingNClients: storePendingNClients: returning 0
2019/12/09 09:39:32.246 kid1| 90,3| store_client.cc(777)
CheckQuickAbortIsReasonable: quick-abort? NO store_status != STORE_PENDING
2019/12/09 09:39:32.246 kid1| 20,3| store.cc(469) unlock: storeUnregister
unlocking key 41000000000000000E11000001000000 e:=sp2XIV/0x25617e0*2
2019/12/09 09:39:32.246 kid1| 20,3| store.cc(469) unlock: Ssl::ServerBump
unlocking key 41000000000000000E11000001000000 e:=sp2XIV/0x25617e0*1
2019/12/09 09:39:32.246 kid1| 20,5| store.cc(485) doAbandon:
e:=sp2XIV/0x25617e0*0 via Ssl::ServerBump
2019/12/09 09:39:32.246 kid1| 90,3| store_client.cc(755)
storePendingNClients: storePendingNClients: returning 0
2019/12/09 09:39:32.246 kid1| 20,3| store.cc(1216) release: 0
e:=sp2XIV/0x25617e0*0 41000000000000000E11000001000000
2019/12/09 09:39:32.246 kid1| 20,3| store.cc(379) destroyMemObject:
0x256a240 in e:=sp2XIV/0x25617e0*0
2019/12/09 09:39:32.246 kid1| 20,3| MemObject.cc(110) ~MemObject: MemObject
destructed, this=0x256a240
2019/12/09 09:39:32.246 kid1| 20,3| store.cc(397) destroyStoreEntry:
destroyStoreEntry: destroying 0x25617e8
2019/12/09 09:39:32.246 kid1| 20,3| store.cc(379) destroyMemObject: 0 in
e:=sp2XIV/0x25617e0*0
2019/12/09 09:39:32.246 kid1| 20,5| store.cc(352) ~StoreEntry: StoreEntry
destructed, this=0x25617e0
2019/12/09 09:39:32.246 kid1| 93,5| AsyncJob.cc(40) ~AsyncJob: AsyncJob
destructed, this=0x256a788 type=Http1::Server [job203]
2019/12/09 09:39:32.246 kid1| 93,6| AsyncJob.cc(149) callEnd:
ConnStateData::connStateClosed(FD -1, data=0x256a4a8) ended 0x256a788
2019/12/09 09:39:32.246 kid1| 33,5| AsyncCallQueue.cc(57) fireNext: leaving
ConnStateData::connStateClosed(FD -1, data=0x256a4a8)
2019/12/09 09:39:32.246 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering
comm_close_complete(FD 13)
2019/12/09 09:39:32.246 kid1| 5,4| AsyncCall.cc(38) make: make call
comm_close_complete [call2909]
2019/12/09 09:39:32.246 kid1| 83,5| Session.cc(100) operator(): SSL_free
session=0x259dbd0
2019/12/09 09:39:32.246 kid1| 83,5| bio.cc(612) squid_bio_ctrl: 0x20d61f0
7(0, 0x2592b20)
2019/12/09 09:39:32.246 kid1| 83,5| ../../src/security/PeerOptions.h(112)
operator(): SSL_CTX destruct, this=0x25a0570
2019/12/09 09:39:32.246 kid1| 51,3| fd.cc(94) fd_close: fd_close FD 13
client https start
2019/12/09 09:39:32.246 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 13,
type=3, handler=0, client_data=0, timeout=0
2019/12/09 09:39:32.247 kid1| 5,5| AcceptLimiter.cc(47) kick: size=0
2019/12/09 09:39:32.247 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving
comm_close_complete(FD 13)
2019/12/09 09:39:32.247 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering
commStartTlsClose(FD 15)
2019/12/09 09:39:32.247 kid1| 5,4| AsyncCall.cc(38) make: make call
commStartTlsClose [call2910]
2019/12/09 09:39:32.247 kid1| 83,5| Session.cc(202) SessionSendGoodbye:
session=0x257cb00
2019/12/09 09:39:32.247 kid1| 83,5| bio.cc(113) write: FD 15 wrote 31 <= 31
2019/12/09 09:39:32.247 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving
commStartTlsClose(FD 15)
2019/12/09 09:39:32.247 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering
comm_close_complete(FD 15)
2019/12/09 09:39:32.247 kid1| 5,4| AsyncCall.cc(38) make: make call
comm_close_complete [call2911]
2019/12/09 09:39:32.247 kid1| 83,5| Session.cc(100) operator(): SSL_free
session=0x257cb00
2019/12/09 09:39:32.247 kid1| 51,3| fd.cc(94) fd_close: fd_close FD 15
X.Y.82.162 pinned connection for 192.168.1.25:53556 (13)
2019/12/09 09:39:32.247 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 15,
type=3, handler=0, client_data=0, timeout=0
2019/12/09 09:39:32.247 kid1| 5,5| AcceptLimiter.cc(47) kick: size=0
2019/12/09 09:39:32.247 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving
comm_close_complete(FD 15)
2019/12/09 09:39:32.800 kid1| 41,5| AsyncCall.cc(26) AsyncCall: The
AsyncCall ipcache_purgelru constructed, this=0x255e980 [call2912]
2019/12/09 09:39:32.800 kid1| 41,5| AsyncCall.cc(93) ScheduleCall:
event.cc(241) will call ipcache_purgelru() [call2912]
2019/12/09 09:39:32.800 kid1| 41,5| AsyncCallQueue.cc(55) fireNext: entering
ipcache_purgelru()
2019/12/09 09:39:32.800 kid1| 41,5| AsyncCall.cc(38) make: make call
ipcache_purgelru [call2912]
2019/12/09 09:39:32.800 kid1| 41,5| AsyncCallQueue.cc(57) fireNext: leaving
ipcache_purgelru()
2019/12/09 09:39:33.096 kid1| 41,5| AsyncCall.cc(26) AsyncCall: The
AsyncCall logfileFlush constructed, this=0x255e980 [call2913]
2019/12/09 09:39:33.097 kid1| 41,5| AsyncCall.cc(93) ScheduleCall:
event.cc(241) will call logfileFlush(0x20f1eb8*?) [call2913]
2019/12/09 09:39:33.097 kid1| 41,5| AsyncCallQueue.cc(55) fireNext: entering
logfileFlush(0x20f1eb8*?)
2019/12/09 09:39:33.097 kid1| 41,5| AsyncCall.cc(38) make: make call
logfileFlush [call2913]
2019/12/09 09:39:33.097 kid1| 41,5| AsyncCallQueue.cc(57) fireNext: leaving
logfileFlush(0x20f1eb8*?)
2019/12/09 09:39:33.171 kid1| 41,5| AsyncCall.cc(26) AsyncCall: The
AsyncCall MaintainSwapSpace constructed, this=0x255e980 [call2914]
2019/12/09 09:39:33.171 kid1| 41,5| AsyncCall.cc(93) ScheduleCall:
event.cc(241) will call MaintainSwapSpace() [call2914]
2019/12/09 09:39:33.171 kid1| 41,5| AsyncCallQueue.cc(55) fireNext: entering
MaintainSwapSpace()
2019/12/09 09:39:33.171 kid1| 41,5| AsyncCall.cc(38) make: make call
MaintainSwapSpace [call2914]
2019/12/09 09:39:33.171 kid1| 47,5| ufs/UFSSwapDir.cc(445) maintain: space
still available in /usr/local/squid/var/cache/squid
2019/12/09 09:39:33.171 kid1| 41,5| AsyncCallQueue.cc(57) fireNext: leaving
MaintainSwapSpace()
^C2019/12/09 09:39:33.337| 1,2| main.cc(1788) masterShutdownStart: received
shutdown command
2019/12/09 09:39:33.337 kid1| 5,3| Read.cc(145) HandleRead: FD 14, size
32767, retval 0, errno 0
2019/12/09 09:39:33.337 kid1| 5,3| IoCallback.cc(116) finish: called for
local=[::] remote=[::] FD 14 flags=1 (0, 0)
2019/12/09 09:39:33.337 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 14
flags=1, data=0x20c5848, size=0, buf=0x20c5b50) [call9]
2019/12/09 09:39:33.337 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 14,
type=2, handler=0, client_data=0, timeout=0
2019/12/09 09:39:33.337 kid1| 5,3| Read.cc(145) HandleRead: FD 18, size
32767, retval 0, errno 0
2019/12/09 09:39:33.337 kid1| 5,3| IoCallback.cc(116) finish: called for
local=[::] remote=[::] FD 18 flags=1 (0, 0)
2019/12/09 09:39:33.337 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 18
flags=1, data=0x20d6288, size=0, buf=0x20d6590) [call15]
2019/12/09 09:39:33.337 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 18,
type=2, handler=0, client_data=0, timeout=0
2019/12/09 09:39:33.337 kid1| 5,3| Read.cc(145) HandleRead: FD 16, size
32767, retval 0, errno 0
2019/12/09 09:39:33.337 kid1| 5,3| IoCallback.cc(116) finish: called for
local=[::] remote=[::] FD 16 flags=1 (0, 0)
2019/12/09 09:39:33.337 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 16
flags=1, data=0x20cdd68, size=0, buf=0x20ce070) [call12]
2019/12/09 09:39:33.338 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 16,
type=2, handler=0, client_data=0, timeout=0
2019/12/09 09:39:33.338 kid1| 5,3| Read.cc(145) HandleRead: FD 12, size
32767, retval 0, errno 0
2019/12/09 09:39:33.338 kid1| 5,3| IoCallback.cc(116) finish: called for
local=[::] remote=[::] FD 12 flags=1 (0, 0)
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
IoCallback.cc(135) will call helperHandleRead(local=[::] remote=[::] FD 12
flags=1, data=0x20bd328, size=0, buf=0x20bd630) [call6]
2019/12/09 09:39:33.338 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 12,
type=2, handler=0, client_data=0, timeout=0
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering
helperHandleRead(local=[::] remote=[::] FD 14 flags=1, data=0x20c5848,
size=0, buf=0x20c5b50)
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCall.cc(38) make: make call
helperHandleRead [call9]
2019/12/09 09:39:33.338 kid1| 84,5| helper.cc(963) helperHandleRead:
helperHandleRead: 0 bytes from
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MB #Hlpr3
2019/12/09 09:39:33.338 kid1| 5,3| comm.cc(859) _comm_close: comm_close:
start closing FD 14
2019/12/09 09:39:33.338 kid1| 5,3| comm.cc(546) commUnsetFdTimeout: Remove
timeout for FD 14
2019/12/09 09:39:33.338 kid1| 5,5| comm.cc(727) commCallCloseHandlers:
commCallCloseHandlers: FD 14
2019/12/09 09:39:33.338 kid1| 5,5| comm.cc(735) commCallCloseHandlers:
commCallCloseHandlers: ch->handler=0x20cdb60*1
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(736) will call helperServerFree(0x20c5848/0x20c5848) [call8]
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
comm_close_complete constructed, this=0x2598420 [call2915]
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(930) will call comm_close_complete(FD 14) [call2915]
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving
helperHandleRead(local=[::] remote=[::] flags=1, data=0x20c5848, size=0,
buf=0x20c5b50)
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering
helperHandleRead(local=[::] remote=[::] FD 18 flags=1, data=0x20d6288,
size=0, buf=0x20d6590)
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCall.cc(38) make: make call
helperHandleRead [call15]
2019/12/09 09:39:33.338 kid1| 84,5| helper.cc(963) helperHandleRead:
helperHandleRead: 0 bytes from
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MB #Hlpr5
2019/12/09 09:39:33.338 kid1| 5,3| comm.cc(859) _comm_close: comm_close:
start closing FD 18
2019/12/09 09:39:33.338 kid1| 5,3| comm.cc(546) commUnsetFdTimeout: Remove
timeout for FD 18
2019/12/09 09:39:33.338 kid1| 5,5| comm.cc(727) commCallCloseHandlers:
commCallCloseHandlers: FD 18
2019/12/09 09:39:33.338 kid1| 5,5| comm.cc(735) commCallCloseHandlers:
commCallCloseHandlers: ch->handler=0x20de5a0*1
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(736) will call helperServerFree(0x20d6288/0x20d6288) [call14]
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
comm_close_complete constructed, this=0x25b1b30 [call2916]
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(930) will call comm_close_complete(FD 18) [call2916]
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving
helperHandleRead(local=[::] remote=[::] flags=1, data=0x20d6288, size=0,
buf=0x20d6590)
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering
helperHandleRead(local=[::] remote=[::] FD 16 flags=1, data=0x20cdd68,
size=0, buf=0x20ce070)
2019/12/09 09:39:33.338 kid1| 5,4| AsyncCall.cc(38) make: make call
helperHandleRead [call12]
2019/12/09 09:39:33.338 kid1| 84,5| helper.cc(963) helperHandleRead:
helperHandleRead: 0 bytes from
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MB #Hlpr4
2019/12/09 09:39:33.338 kid1| 5,3| comm.cc(859) _comm_close: comm_close:
start closing FD 16
2019/12/09 09:39:33.338 kid1| 5,3| comm.cc(546) commUnsetFdTimeout: Remove
timeout for FD 16
2019/12/09 09:39:33.338 kid1| 5,5| comm.cc(727) commCallCloseHandlers:
commCallCloseHandlers: FD 16
2019/12/09 09:39:33.338 kid1| 5,5| comm.cc(735) commCallCloseHandlers:
commCallCloseHandlers: ch->handler=0x20d6080*1
2019/12/09 09:39:33.339 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(736) will call helperServerFree(0x20cdd68/0x20cdd68) [call11]
2019/12/09 09:39:33.339 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
comm_close_complete constructed, this=0x2564110 [call2917]
2019/12/09 09:39:33.339 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(930) will call comm_close_complete(FD 16) [call2917]
2019/12/09 09:39:33.339 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving
helperHandleRead(local=[::] remote=[::] flags=1, data=0x20cdd68, size=0,
buf=0x20ce070)
2019/12/09 09:39:33.339 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering
helperHandleRead(local=[::] remote=[::] FD 12 flags=1, data=0x20bd328,
size=0, buf=0x20bd630)
2019/12/09 09:39:33.339 kid1| 5,4| AsyncCall.cc(38) make: make call
helperHandleRead [call6]
2019/12/09 09:39:33.339 kid1| 84,5| helper.cc(963) helperHandleRead:
helperHandleRead: 0 bytes from
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MB #Hlpr2
2019/12/09 09:39:33.339 kid1| 5,3| comm.cc(859) _comm_close: comm_close:
start closing FD 12
2019/12/09 09:39:33.339 kid1| 5,3| comm.cc(546) commUnsetFdTimeout: Remove
timeout for FD 12
2019/12/09 09:39:33.339 kid1| 5,5| comm.cc(727) commCallCloseHandlers:
commCallCloseHandlers: FD 12
2019/12/09 09:39:33.339 kid1| 5,5| comm.cc(735) commCallCloseHandlers:
commCallCloseHandlers: ch->handler=0x20c5640*1
2019/12/09 09:39:33.339 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(736) will call helperServerFree(0x20bd328/0x20bd328) [call5]
2019/12/09 09:39:33.339 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
comm_close_complete constructed, this=0x25b3490 [call2918]
2019/12/09 09:39:33.339 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(930) will call comm_close_complete(FD 12) [call2918]
2019/12/09 09:39:33.339 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving
helperHandleRead(local=[::] remote=[::] flags=1, data=0x20bd328, size=0,
buf=0x20bd630)
2019/12/09 09:39:33.339 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering
helperServerFree(0x20c5848/0x20c5848)
2019/12/09 09:39:33.339 kid1| 5,4| AsyncCall.cc(38) make: make call
helperServerFree [call8]
2019/12/09 09:39:33.339 kid1| WARNING:
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MB #Hlpr3 exited
2019/12/09 09:39:33.339 kid1| Too few
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MB processes are running (need 1/32)
2019/12/09 09:39:33.339 kid1| Starting new helpers
2019/12/09 09:39:33.339 kid1| helperOpenServers: Starting 1/32
'security_file_certgen' processes
2019/12/09 09:39:33.339 kid1| 51,3| fd.cc(198) fd_open: fd_open() FD 13 IPC
UNIX STREAM Parent
2019/12/09 09:39:33.339 kid1| 51,3| fd.cc(198) fd_open: fd_open() FD 15 IPC
UNIX STREAM Parent
2019/12/09 09:39:33.339 kid1| 54,3| ipc.cc(204) ipcCreate: ipcCreate: prfd
FD 13
2019/12/09 09:39:33.339 kid1| 54,3| ipc.cc(205) ipcCreate: ipcCreate: pwfd
FD 13
2019/12/09 09:39:33.339 kid1| 54,3| ipc.cc(206) ipcCreate: ipcCreate: crfd
FD 15
2019/12/09 09:39:33.339 kid1| 54,3| ipc.cc(207) ipcCreate: ipcCreate: cwfd
FD 15
2019/12/09 09:39:33.340 kid1| 5,3| comm.cc(859) _comm_close: comm_close:
start closing FD 15
2019/12/09 09:39:33.340 kid1| 5,3| comm.cc(546) commUnsetFdTimeout: Remove
timeout for FD 15
2019/12/09 09:39:33.340 kid1| 5,5| comm.cc(727) commCallCloseHandlers:
commCallCloseHandlers: FD 15
2019/12/09 09:39:33.340 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
comm_close_complete constructed, this=0x256a970 [call2919]
2019/12/09 09:39:33.340 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(930) will call comm_close_complete(FD 15) [call2919]
2019/12/09 09:39:33.340 kid1| 21,3| tools.cc(506) leave_suid: leave_suid:
PID 4394 called
2019/12/09 09:39:33.340 kid1| 21,3| tools.cc(606) no_suid: no_suid: PID 4394
giving up root privileges forever
2019/12/09 09:39:33.340 kid1| 5,3| comm.cc(546) commUnsetFdTimeout: Remove
timeout for FD 13
2019/12/09 09:39:33.340 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
helperServerFree constructed, this=0x255e980 [call2920]
2019/12/09 09:39:33.340 kid1| 5,5| comm.cc(985) comm_add_close_handler:
comm_add_close_handler: FD 13, AsyncCall=0x255e980*1
2019/12/09 09:39:33.340 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
helperHandleRead constructed, this=0x254d4c0 [call2921]
2019/12/09 09:39:33.340 kid1| 5,5| Read.cc(57) comm_read_base: comm_read,
queueing read for local=[::] remote=[::] FD 13 flags=1; asynCall 0x254d4c0*1
2019/12/09 09:39:33.340 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 13,
type=1, handler=1, client_data=0x2091f60, timeout=0
2019/12/09 09:39:33.340 kid1| 84,5| helper.cc(1247) GetFirstAvailable:
GetFirstAvailable: Running servers 5
2019/12/09 09:39:33.340 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving
helperServerFree(0x20c5848/0x20c5848)
2019/12/09 09:39:33.340 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering
comm_close_complete(FD 14)
2019/12/09 09:39:33.340 kid1| 5,4| AsyncCall.cc(38) make: make call
comm_close_complete [call2915]
2019/12/09 09:39:33.340 kid1| 51,3| fd.cc(94) fd_close: fd_close FD 14
security_file_certgen #3
2019/12/09 09:39:33.340 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 14,
type=3, handler=0, client_data=0, timeout=0
2019/12/09 09:39:33.341 kid1| 5,5| AcceptLimiter.cc(47) kick: size=0
2019/12/09 09:39:33.341 kid1| 5,4| AsyncCallQueue.cc(57) fireNext: leaving
comm_close_complete(FD 14)
2019/12/09 09:39:33.341 kid1| 5,4| AsyncCallQueue.cc(55) fireNext: entering
helperServerFree(0x20d6288/0x20d6288)
2019/12/09 09:39:33.341 kid1| 5,4| AsyncCall.cc(38) make: make call
helperServerFree [call14]
2019/12/09 09:39:33.341 kid1| WARNING:
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MB #Hlpr5 exited
2019/12/09 09:39:33.341 kid1| Too few
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MB processes are running (need 1/32)
2019/12/09 09:39:33.341 kid1| Closing HTTP(S) port [::]:3128
2019/12/09 09:39:33.341 kid1| 5,3| comm.cc(859) _comm_close: comm_close:
start closing FD 28
2019/12/09 09:39:33.341 kid1| 5,3| comm.cc(546) commUnsetFdTimeout: Remove
timeout for FD 28
2019/12/09 09:39:33.341 kid1| 5,5| comm.cc(727) commCallCloseHandlers:
commCallCloseHandlers: FD 28
2019/12/09 09:39:33.341 kid1| 5,5| comm.cc(735) commCallCloseHandlers:
commCallCloseHandlers: ch->handler=0x20ff240*2
2019/12/09 09:39:33.341 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(736) will call Comm::TcpAcceptor::handleClosure(FD -1,
data=0x2539878) [call29]
2019/12/09 09:39:33.341 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
comm_close_complete constructed, this=0x2598420 [call2922]
2019/12/09 09:39:33.341 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(930) will call comm_close_complete(FD 28) [call2922]
2019/12/09 09:39:33.341 kid1| Closing HTTP(S) port [::]:3129
2019/12/09 09:39:33.341 kid1| 5,3| comm.cc(859) _comm_close: comm_close:
start closing FD 29
2019/12/09 09:39:33.341 kid1| 5,3| comm.cc(546) commUnsetFdTimeout: Remove
timeout for FD 29
2019/12/09 09:39:33.341 kid1| 5,5| comm.cc(727) commCallCloseHandlers:
commCallCloseHandlers: FD 29
2019/12/09 09:39:33.341 kid1| 5,5| comm.cc(735) commCallCloseHandlers:
commCallCloseHandlers: ch->handler=0x23dd590*2
2019/12/09 09:39:33.342 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(736) will call Comm::TcpAcceptor::handleClosure(FD -1,
data=0x2539d18) [call30]
2019/12/09 09:39:33.342 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
comm_close_complete constructed, this=0x254cdd0 [call2923]
2019/12/09 09:39:33.342 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(930) will call comm_close_complete(FD 29) [call2923]
2019/12/09 09:39:33.342 kid1| Closing HTTP(S) port [::]:3130
2019/12/09 09:39:33.342 kid1| 5,3| comm.cc(859) _comm_close: comm_close:
start closing FD 30
2019/12/09 09:39:33.342 kid1| 5,3| comm.cc(546) commUnsetFdTimeout: Remove
timeout for FD 30
2019/12/09 09:39:33.342 kid1| 5,5| comm.cc(727) commCallCloseHandlers:
commCallCloseHandlers: FD 30
2019/12/09 09:39:33.342 kid1| 5,5| comm.cc(735) commCallCloseHandlers:
commCallCloseHandlers: ch->handler=0x23dd620*2
2019/12/09 09:39:33.342 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(736) will call Comm::TcpAcceptor::handleClosure(FD -1,
data=0x2539d88) [call31]
2019/12/09 09:39:33.342 kid1| 5,4| AsyncCall.cc(26) AsyncCall: The AsyncCall
comm_close_complete constructed, this=0x2592b20 [call2924]
2019/12/09 09:39:33.342 kid1| 5,4| AsyncCall.cc(93) ScheduleCall:
comm.cc(930) will call comm_close_complete(FD 30) [call2924]
2019/12/09 09:39:33.342 kid1| 21,3| tools.cc(506) leave_suid: leave_suid:
PID 4366 called
2019/12/09 09:39:33.342 kid1| storeDirWriteCleanLogs: Starting...
2019/12/09 09:39:33.342 kid1| 6,5| fs_io.cc(65) file_open: FD 14
2019/12/09 09:39:33.342 kid1| 51,3| fd.cc(198) fd_open: fd_open() FD 14
/usr/local/squid/var/cache/squid/swap.state.clean
2019/12/09 09:39:33.343 kid1| 47,3| ufs/UFSSwapDir.cc(959) writeCleanStart:
opened /usr/local/squid/var/cache/squid/swap.state.clean, FD 14
2019/12/09 09:39:33.343 kid1| 6,5| fs_io.cc(120) file_close: file_close: FD
11 really closing
2019/12/09 09:39:33.343 kid1| 51,3| fd.cc(94) fd_close: fd_close FD 11
/usr/local/squid/var/cache/squid/swap.state
2019/12/09 09:39:33.343 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 11,
type=3, handler=0, client_data=0, timeout=0
2019/12/09 09:39:33.343 kid1| 47,3| ufs/UFSSwapDir.cc(764) closeLog: Cache
Dir #0 log closed on FD 11
2019/12/09 09:39:33.343 kid1| 21,2| fs_io.cc(510) FileRename: renaming
/usr/local/squid/var/cache/squid/swap.state.clean to
/usr/local/squid/var/cache/squid/swap.state
2019/12/09 09:39:33.344 kid1| 6,5| fs_io.cc(65) file_open: FD 11
2019/12/09 09:39:33.344 kid1| 51,3| fd.cc(198) fd_open: fd_open() FD 11
/usr/local/squid/var/cache/squid/swap.state.last-clean
2019/12/09 09:39:33.344 kid1| 6,5| fs_io.cc(120) file_close: file_close: FD
11 really closing
2019/12/09 09:39:33.344 kid1| 51,3| fd.cc(94) fd_close: fd_close FD 11
/usr/local/squid/var/cache/squid/swap.state.last-clean
2019/12/09 09:39:33.344 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 11,
type=3, handler=0, client_data=0, timeout=0
2019/12/09 09:39:33.344 kid1| 6,5| fs_io.cc(120) file_close: file_close: FD
14 really closing
2019/12/09 09:39:33.344 kid1| 51,3| fd.cc(94) fd_close: fd_close FD 14
/usr/local/squid/var/cache/squid/swap.state.clean
2019/12/09 09:39:33.344 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 14,
type=3, handler=0, client_data=0, timeout=0
2019/12/09 09:39:33.344 kid1|   Finished.  Wrote 213 entries.
2019/12/09 09:39:33.344 kid1|   Took 0.00 seconds (105445.54 entries/sec).
2019/12/09 09:39:33.344 kid1| *FATAL: The
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MB helpers are crashing too rapidly,
need help!*






--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From twk at ncsu.edu  Mon Dec  9 20:08:00 2019
From: twk at ncsu.edu (Tom Karches)
Date: Mon, 9 Dec 2019 15:08:00 -0500
Subject: [squid-users] Security concerns with using squidclient from a host
 separate from the server
Message-ID: <CAGZ9WNrHNpz0x7yAQZH9suUR=9fGrFhMtZWbJpnp0tJRy6h+Hw@mail.gmail.com>

Are there any security concerns with running squidclient anywhere except on
the local host? I have been told that squidclient "exposes a lot of data".
Is that because transactions are passed over an insecure connection? If so,
is there a workaround that solves this problem?

Tom

-- 
Thomas Karches
NCSU OIT CSI - Systems Specialist
M.E Student - Technology Education
Hillsborough 319 / 919.515.5508
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191209/f27f2352/attachment.htm>

From guy20034u at yahoo.com  Mon Dec  9 20:44:04 2019
From: guy20034u at yahoo.com (simon ben)
Date: Mon, 9 Dec 2019 20:44:04 +0000 (UTC)
Subject: [squid-users] one site not working using squid
References: <1345902605.7240381.1575924244538.ref@mail.yahoo.com>
Message-ID: <1345902605.7240381.1575924244538@mail.yahoo.com>


Dear All,

?

I am usingSquid version 3.5.2 on Centos ?7 64 bit and its working fine with no issuebut recently got a complain from one user saying that the below site Is notopening..? just says page cannot be displayed

?

https://my.esri.com

?

but if I use a machine without squid itsworking fine

?

the access logs is showing me as below

?

?

1575869460.673??6034 172.16.2.175 TCP_TUNNEL/200 0 CONNECT my.esri.com:443 -HIER_DIRECT/34.210.189.55 -

1575869461.235???559 172.16.2.175 TCP_TUNNEL/200 0 CONNECT my.esri.com:443 - HIER_DIRECT/34.210.189.55-

1575869461.801???562 172.16.2.175 TCP_TUNNEL/200 0 CONNECT my.esri.com:443 -HIER_DIRECT/34.210.189.55 -

1575869462.096???291 172.16.2.175 TCP_TUNNEL/200 0 CONNECT my.esri.com:443 -HIER_DIRECT/34.210.189.55 ?

?

?

Itried to google around and found that the the ip4 prefrence has to enabled forDNS so I did the below in squid config

?

dns_v4_firston

?

butno luck

?

appreciateyour help and advice

?

?

thanksand regards

?

simon



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191209/5ae66419/attachment.htm>

From g2011828 at hotmail.com  Tue Dec 10 05:46:49 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Mon, 9 Dec 2019 23:46:49 -0600 (CST)
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <1575914210679-0.post@n4.nabble.com>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
 <724ee00d-44bb-a0df-aa3f-007d13b96970@measurement-factory.com>
 <1575914210679-0.post@n4.nabble.com>
Message-ID: <1575956809995-0.post@n4.nabble.com>


I'm wondering if this issue reported last year is fixed:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-4-4-security-file-certgen-helpers-crashing-td4687098.html

or is there a work around.
thanks.

- George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Tue Dec 10 07:36:43 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Dec 2019 20:36:43 +1300
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <1575956809995-0.post@n4.nabble.com>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
 <724ee00d-44bb-a0df-aa3f-007d13b96970@measurement-factory.com>
 <1575914210679-0.post@n4.nabble.com> <1575956809995-0.post@n4.nabble.com>
Message-ID: <49292e50-d02f-4301-378a-282be8769d44@treenet.co.nz>

On 10/12/19 6:46 pm, GeorgeShen wrote:
> 
> I'm wondering if this issue reported last year is fixed:
> http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-4-4-security-file-certgen-helpers-crashing-td4687098.html
> 

That question implies that you are not using the latest Squid release,
or you already have the answer. When using SSL-Bump features (cert
generation being one) it is best to follow the updates.


Amos


From squid3 at treenet.co.nz  Tue Dec 10 07:43:15 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Dec 2019 20:43:15 +1300
Subject: [squid-users] Security concerns with using squidclient from a
 host separate from the server
In-Reply-To: <CAGZ9WNrHNpz0x7yAQZH9suUR=9fGrFhMtZWbJpnp0tJRy6h+Hw@mail.gmail.com>
References: <CAGZ9WNrHNpz0x7yAQZH9suUR=9fGrFhMtZWbJpnp0tJRy6h+Hw@mail.gmail.com>
Message-ID: <c4e40b76-7bcc-8c29-ae3d-378aff6cd4c3@treenet.co.nz>

On 10/12/19 9:08 am, Tom Karches wrote:
> Are there any security concerns with running squidclient anywhere except
> on the local host?

No more than with any HTTP software. Less than some.


> I have been told that squidclient "exposes a lot of
> data". Is that because transactions are passed over an insecure
> connection? If so, is there a workaround that solves this problem?
> 

Depends on what you consider exposure. Of what? to whom? and how?

squidclient prints the HTTP response headers and payload to its stdout.
How that info was received is up to the server/proxy being connected to.

Amos


From squid3 at treenet.co.nz  Tue Dec 10 07:57:30 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Dec 2019 20:57:30 +1300
Subject: [squid-users] one site not working
In-Reply-To: <2018052354.7139044.1575910345037@mail.yahoo.com>
References: <2018052354.7139044.1575910345037.ref@mail.yahoo.com>
 <2018052354.7139044.1575910345037@mail.yahoo.com>
Message-ID: <e3dd4985-7608-5358-6010-41051484ff19@treenet.co.nz>

On 10/12/19 5:52 am, simon ben wrote:
> Dear All,
> 
> ?
> 
> I am using Squid version 3.5.2 on Centos ?7 64 bit and its working fine
> with no issue but recently got a complain from one user saying that the
> below site Is not opening..? just says page cannot be displayed
> 

That would be one issue. Likely many others you are just not noticing.

Please upgrade. v3.5.2 is over 5 years old and obsolete. Current Squid
release is v4.9.


?
> 
> 1575869460.673?? 6034 172.16.2.175 TCP_TUNNEL/200 0 CONNECT
> my.esri.com:443 <http://my.esri.com:443> - HIER_DIRECT/34.210.189.55
> <http://34.210.189.55> -
> 
> 1575869461.235??? 559 172.16.2.175 TCP_TUNNEL/200 0 CONNECT
> my.esri.com:443 <http://my.esri.com:443> - HIER_DIRECT/34.210.189.55
> <http://34.210.189.55> -
> 
> 1575869461.801??? 562 172.16.2.175 TCP_TUNNEL/200 0 CONNECT
> my.esri.com:443 <http://my.esri.com:443> - HIER_DIRECT/34.210.189.55
> <http://34.210.189.55> -
> 
> 1575869462.096??? 291 172.16.2.175 TCP_TUNNEL/200 0 CONNECT
> my.esri.com:443 <http://my.esri.com:443> - HIER_DIRECT/34.210.189.55
> <http://34.210.189.55> ?
> 
> ?
> 
> ?
> 
> I tried to google around and found that the the ip4 prefrence has to
> enabled for DNS so I did the below in squid config
> 

No it does not. Your proxy is already connecting the tunnel to that
sites IPv4 address.


Amos


From aw_wolfe12 at yahoo.com  Tue Dec 10 11:19:40 2019
From: aw_wolfe12 at yahoo.com (aw_wolfe)
Date: Tue, 10 Dec 2019 05:19:40 -0600 (CST)
Subject: [squid-users] 4.9 https isue...unable import certificate in browser
Message-ID: <1575976780732-0.post@n4.nabble.com>

I have squid 4.9 built with https support in which I created a certificate
following tutorial. Squid starts, appears to be running fine. http whitelist
with user groups working....trying to add https support.

copy/paste from example of what I did to create certificate.

openssl req -new -newkey rsa:2048 -sha256 -days 365 -nodes -x509 -extensions
v3_ca -keyout myCA.pem  -out myCA.pem

certtool --generate-privkey --outfile ca-key.pem

certtool --generate-self-signed --load-privkey ca-key.pem --outfile myCA.pem

openssl x509 -in myCA.pem -outform DER -out myCA.der

1) problem when trying to import myCA.der certificate into firefox: "This is
not a certificate authority certificate, so it can?t be imported into the
certificate authority list"

2) My goal is simply to whitelist sites, I do not have a need to view the
traffic. Is following ssl-bump examples the right/only approach or is easier
way to let the client connect directly, but preventing any connection except
if on the whitelist?

Thanks,
Tony




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From uhlar at fantomas.sk  Tue Dec 10 11:30:07 2019
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 10 Dec 2019 12:30:07 +0100
Subject: [squid-users] 4.9 https isue...unable import certificate in
 browser
In-Reply-To: <1575976780732-0.post@n4.nabble.com>
References: <1575976780732-0.post@n4.nabble.com>
Message-ID: <20191210113007.GA960@fantomas.sk>

On 10.12.19 05:19, aw_wolfe wrote:
>I have squid 4.9 built with https support in which I created a certificate
>following tutorial. Squid starts, appears to be running fine. http whitelist
>with user groups working....trying to add https support.
>
>copy/paste from example of what I did to create certificate.
>
>openssl req -new -newkey rsa:2048 -sha256 -days 365 -nodes -x509 -extensions
>v3_ca -keyout myCA.pem  -out myCA.pem

here you create the authority with both the key and certificate in myCA.pem
using OpenSSL

>certtool --generate-privkey --outfile ca-key.pem
>
>certtool --generate-self-signed --load-privkey ca-key.pem --outfile myCA.pem

here you overwrite it by GnuTLS commands...
you misunderstood: These commands are alternative to openssl commands.

>openssl x509 -in myCA.pem -outform DER -out myCA.der

>1) problem when trying to import myCA.der certificate into firefox: "This is
>not a certificate authority certificate, so it can?t be imported into the
>certificate authority list"

try without certtool commands. According to my experience, that openssl
command should produce correct CA certificate, I don't know about certtool
commands.

note that:
1. you can import myCA.pem at least into firefox (iirc) 
2. you should not copy myCA.pem containing CA private key anywhere.

>2) My goal is simply to whitelist sites, I do not have a need to view the
>traffic. Is following ssl-bump examples the right/only approach or is easier
>way to let the client connect directly, but preventing any connection except
>if on the whitelist?

you don't need to generate own certificate for this reason.
Configuring squid to stare at SSL connections should be enough.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
The 3 biggets disasters: Hiroshima 45, Tschernobyl 86, Windows 95


From aw_wolfe12 at yahoo.com  Tue Dec 10 12:14:19 2019
From: aw_wolfe12 at yahoo.com (aw_wolfe)
Date: Tue, 10 Dec 2019 06:14:19 -0600 (CST)
Subject: [squid-users] 4.9 https isue...unable import certificate in
	browser
In-Reply-To: <20191210113007.GA960@fantomas.sk>
References: <1575976780732-0.post@n4.nabble.com>
 <20191210113007.GA960@fantomas.sk>
Message-ID: <1575980059402-0.post@n4.nabble.com>

Ok, thank  you. As you can tell, I'm kinda fumbling my way through setting
this up.

Re-creating the certification with the openssl command only fixed the issue.
Firefox accepted the certification.

I think that I would rather not have to do the install certificate on all
the browsers. So if I can configure the stare option, that would be my
preferred solution.

A bit of searching around however, didn't turn up much and I'm a little
confused by the different "steps" commands.

If you don't mind I'd appreciate a simple 1 or 2 line example or point me in
the right direction

Right now my squid.conf (not including the groups and whitelist part):

http_port 3128 ssl-bump cert=/etc/squid/ssl_cert/myCA.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
key=/etc/squid/ssl_cert/ca-key.pem

sslcrtd_program /usr/sbin/squid/libexec/security_file_certgen -s
/var/lib/ssl_db -M 4MB
sslcrtd_children 5
ssl_bump server-first all
sslproxy_cert_error allow all




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From uhlar at fantomas.sk  Tue Dec 10 12:26:34 2019
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 10 Dec 2019 13:26:34 +0100
Subject: [squid-users] 4.9 https isue...unable import certificate in
 browser
In-Reply-To: <1575980059402-0.post@n4.nabble.com>
References: <1575976780732-0.post@n4.nabble.com>
 <20191210113007.GA960@fantomas.sk>
 <1575980059402-0.post@n4.nabble.com>
Message-ID: <20191210122634.GA4793@fantomas.sk>

On 10.12.19 06:14, aw_wolfe wrote:
>Ok, thank  you. As you can tell, I'm kinda fumbling my way through setting
>this up.
>
>Re-creating the certification with the openssl command only fixed the issue.
>Firefox accepted the certification.
>
>I think that I would rather not have to do the install certificate on all
>the browsers. So if I can configure the stare option, that would be my
>preferred solution.
>
>A bit of searching around however, didn't turn up much and I'm a little
>confused by the different "steps" commands.

so am I...

>If you don't mind I'd appreciate a simple 1 or 2 line example or point me in
>the right direction

and I also plan to log based on SSL client helo (SNI option).

>Right now my squid.conf (not including the groups and whitelist part):
>
>http_port 3128 ssl-bump cert=/etc/squid/ssl_cert/myCA.pem
>generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>key=/etc/squid/ssl_cert/ca-key.pem
>
>sslcrtd_program /usr/sbin/squid/libexec/security_file_certgen -s
>/var/lib/ssl_db -M 4MB
>sslcrtd_children 5
>ssl_bump server-first all
>sslproxy_cert_error allow all

if you only want to get the requested server name, forget making
certificates at all.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Silvester Stallone: Father of the RISC concept.


From rousskov at measurement-factory.com  Tue Dec 10 14:14:58 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 10 Dec 2019 09:14:58 -0500
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <1575914210679-0.post@n4.nabble.com>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
 <724ee00d-44bb-a0df-aa3f-007d13b96970@measurement-factory.com>
 <1575914210679-0.post@n4.nabble.com>
Message-ID: <ba63ebca-810a-59b7-b3f7-9d4fac8646db@measurement-factory.com>

On 12/9/19 12:56 PM, GeorgeShen wrote:

> and at the end, it is also saying security_file_certgen crashes rapidly!!!

I would ignore anything that happens _after_ you press ^C (i.e. send
Squid a shutdown signal). While a shutdown should not "crash" any
helpers, that is not the problem you are currently trying to solve.

As for your primary problem, I see nothing interesting in the provided
logs (which does not necessarily mean there is nothing there). As Amos
has said, when dealing with SslBump problems, please make sure you are
running Squid v4.9 (or even master).


> ^C2019/12/09 09:39:33.337| 1,2| main.cc(1788) masterShutdownStart: received
> shutdown command

Alex.


From aashutosh.xyz at gmail.com  Tue Dec 10 14:48:25 2019
From: aashutosh.xyz at gmail.com (aashutosh kalyankar)
Date: Tue, 10 Dec 2019 06:48:25 -0800
Subject: [squid-users] HTTPS interception proxy having issues
Message-ID: <CABi+OR+STb5EWcNptFZHgwK5Zv3nvxc3F5zLMkdDWY0m1k2iJg@mail.gmail.com>

Hi! I am trying to set up a HTTPs intercept proxy but I cannot get it to
work. Can someone point me in the right direction?

I tried following the tutorial @ https://www.youtube.com/watch?v=Bogdplu_lsE
(Transparent HTTP+HTTPS Proxy with Squid and iptables)  for squid file.
and https://github.com/diladele/squid-ubuntu for building squid 3.5 on
ubuntu.

*squid.conf file *

acl clients src 172.16.10.0/24
acl clients src 172.18.10.0/24

http_access allow localhost
http_access allow clients
http_access deny all
http_port 8080
http_port 3128 intercept
https_port 3129 intercept ssl-bump cert=/etc/squid/ssl_certs/myCA.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all

# only wait 5 seconds to terminate active connections
shutdown_lifetime 5
~

I am forced to use old 3.5 version of squid as I am running very old
version of Vsphere supporting ubuntu 14.04 and below.
*Squid Cache: Version 3.5.19 *
Service Name: squid
Ubuntu linux
configure options:  '--build=x86_64-linux-gnu' '--prefix=/usr'
'--includedir=${prefix}/include' '--mandir=${prefix}/share/man'
'--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var'
'--libexecdir=${prefix}/lib/squid3' '--srcdir=.'
'--disable-maintainer-mode' '--disable-dependency-tracking'
'--disable-silent-rules' 'BUILDCXXFLAGS=-g -O2 -fPIE -fstack-protector
--param=ssp-buffer-size=4 -Wformat -Werror=format-security
-D_FORTIFY_SOURCE=2 -Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro
-Wl,-z,now' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
'--libexecdir=/usr/lib/squid' '--mandir=/usr/share/man' '--enable-inline'
'--disable-arch-native' '--enable-async-io=8'
'--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap'
'--enable-delay-pools' '--enable-cache-digests' '--enable-icap-client'
'--enable-follow-x-forwarded-for'
'--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB'
'--enable-auth-digest=file,LDAP' '--enable-auth-negotiate=kerberos,wrapper'
'--enable-auth-ntlm=fake,smb_lm'
'--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,time_quota,unix_group,wbinfo_group'
'--enable-url-rewrite-helpers=fake' '--enable-eui' '--enable-esi'
'--enable-icmp' '--enable-zph-qos' '--enable-ecap' '--disable-translation'
'--with-swapdir=/var/spool/squid' '--with-logdir=/var/log/squid'
'--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=65536'
'--with-large-files' '--with-default-user=proxy' '--with-openssl'
'--enable-ssl' '--enable-ssl-crtd' '--enable-build-info=Ubuntu linux'
'--enable-linux-netfilter' 'build_alias=x86_64-linux-gnu' 'CFLAGS=-g -O2
-fPIE -fstack-protector --param=ssp-buffer-size=4 -Wformat
-Werror=format-security -Wall' 'LDFLAGS=-Wl,-Bsymbolic-functions -fPIE -pie
-Wl,-z,relro -Wl,-z,now' 'CPPFLAGS=-D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2
-fPIE -fstack-protector --param=ssp-buffer-size=4 -Wformat
-Werror=format-security'


*Firewall & Nat rules added *
sudo iptables -A INPUT -j ACCEPT -p tcp --dport 3128 -m comment --comment
"squid http proxy"
sudo iptables -A INPUT -j ACCEPT -p tcp --dport 3129 -m comment --comment
"squid https proxy"
sudo iptables -A INPUT -j ACCEPT -p tcp  --dport 8080 -m comment -comment
"squid http8080 proxy

 sudo iptables -t nat -A PREROUTING -i eth0 -p tcp -m tcp --dport 80 -m
comment --comment "transparent http proxy" -j REDIRECT --to-ports 3128
 sudo iptables -t nat -A PREROUTING -i eth0 -p tcp -m tcp --dport 443 -m
comment --comment "transparent https proxy" -j REDIRECT --to-ports 3129
 sudo iptables -t nat -A PREROUTING -i eth0 -p tcp -m tcp --dport 80 -m
comment --comment " http 8080 proxy" -j REDIRECT --to-ports 8080

*CACHE.log*
My machine ip: 172.16.10.5
Squid server ip(vmware): 172.18.10.15
2019/12/09 19:42:00.677 kid1| SECURITY ALERT: Host header forgery detected
on local=172.18.10.15:3128 remote=172.16.10.5:35346 FD 21 flags=33
(intercepted port does not match 443)
2019/12/09 19:42:00.677 kid1| SECURITY ALERT: By user agent:
com.google.android.youtube/1447503000 (Linux; U; Android 7.1.1; en_US;
Google Chromebook Pixel (2015); Build/R79-12607.47.0; Cronet/80.0.3955.6)
2019/12/09 19:42:00.677 kid1| SECURITY ALERT: on URL:
www.googleadservices.com:443
2019/12/09 19:42:00.677 kid1| abandoning local=172.18.10.15:3128 remote=
172.16.10.5:35346 FD 21 flags=33

*access.log *
1575949926.409      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575949935.727      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575949935.834      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575949937.667      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575949939.207      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575949939.799      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575949945.905      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575949946.688      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575949950.602      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575949952.727      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575949958.849      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -

I am able to access neverssl.com  & example.com  (http) site but not https
site.
1575949960.868     23 172.16.10.5 TCP_MISS/200 1869 GET
http://vzwctrdxkflsnbhm.neverssl.com/online - HIER_DIRECT/13.35.127.108
 text/html
1575949960.889      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575949960.939      8 172.16.10.5 TCP_MISS/200 687 GET
http://vzwctrdxkflsnbhm.neverssl.com/favicon.ico - HIER_DIRECT/13.35.127.108
 image/png
1575949986.583      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575949986.709      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575949991.755      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575949998.720      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950005.659      1 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950015.981     32 172.16.10.5 TCP_MISS/301 387 GET http://www.apple.com/ -
HIER_DIRECT/72.247.5.53 -
1575950015.987      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950041.486      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950046.063      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950052.787      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950055.532      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950091.821      9 172.16.10.5 TCP_MISS/200 1123 GET
http://www.example.com/ - HIER_DIRECT/93.184.216.34 text/html
1575950091.891      3 172.16.10.5 TCP_MISS/404 1131 GET
http://www.example.com/favicon.ico - HIER_DIRECT/93.184.216.34 text/html
1575950092.554      0 172.18.10.15 TCP_MISS/403 4474 POST
http://stt.wifimaster.mobi/nw/ne - HIER_NONE/- text/html
1575950092.555     14 172.16.10.5 TCP_MISS/403 4576 POST
http://stt.wifimaster.mobi/nw/ne - ORIGINAL_DST/172.18.10.15 text/html
1575950092.719      0 172.16.10.5 TAG_NONE/409 4266 CONNECT
googlehomefoyer-pa.googleapis.com:443 - HIER_NONE/- text/html
1575950093.732      0 172.16.10.5 TAG_NONE/409 4266 CONNECT
googlehomefoyer-pa.googleapis.com:443 - HIER_NONE/- text/html
1575950094.152      0 172.16.10.5 TAG_NONE/409 4068 CONNECT
cast.google.com:443 - HIER_NONE/- text/html
1575950094.820      0 172.16.10.5 TAG_NONE/409 4266 CONNECT
googlehomefoyer-pa.googleapis.com:443 - HIER_NONE/- text/html
1575950095.895      0 172.16.10.5 TAG_NONE/409 4266 CONNECT
googlehomefoyer-pa.googleapis.com:443 - HIER_NONE/- text/html
1575950096.704      0 172.16.10.5 TAG_NONE/409 4266 CONNECT
googlehomefoyer-pa.googleapis.com:443 - HIER_NONE/- text/html
1575950099.451      0 172.16.10.5 TAG_NONE/409 4115 CONNECT
play.googleapis.com:443 - HIER_NONE/- text/html
1575950099.684      0 172.16.10.5 TAG_NONE/409 4115 CONNECT
play.googleapis.com:443 - HIER_NONE/- text/html
1575950099.780      0 172.16.10.5 TAG_NONE/409 4115 CONNECT
play.googleapis.com:443 - HIER_NONE/- text/html
1575950108.646      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950112.638      2 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950113.655     16 172.16.10.5 TCP_MISS/301 592 GET http://www.cnn.com/ -
HIER_DIRECT/151.101.1.67 -
1575950113.665      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950113.808      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950118.839      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950119.920      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950127.161      1 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950132.158      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950133.481      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950134.155      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950140.548      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950140.633      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950145.675      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950146.415      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950152.852      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950155.864      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950156.948      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950187.018      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950192.630      0 172.16.10.5 TAG_NONE/200 0 CONNECT 172.18.10.15:3129 -
HIER_NONE/- -
1575950196.056      7 172.16.10.5 TCP_MISS/204 449 GET
http://www.gstatic.com/generate_204 - HIER_DIRECT/172.217.6.35 -



Thanks!
Aashutosh
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191210/1e7fdccb/attachment.htm>

From rousskov at measurement-factory.com  Tue Dec 10 15:12:55 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 10 Dec 2019 10:12:55 -0500
Subject: [squid-users] 4.9 https isue...unable import certificate in
 browser
In-Reply-To: <1575976780732-0.post@n4.nabble.com>
References: <1575976780732-0.post@n4.nabble.com>
Message-ID: <afa34625-caac-fc61-63a6-aadfede083b9@measurement-factory.com>

On 12/10/19 6:19 AM, aw_wolfe wrote:
> I have squid 4.9 built with https support in which I created a certificate
> following tutorial. Squid starts, appears to be running fine. http whitelist
> with user groups working....trying to add https support.
> 
> copy/paste from example of what I did to create certificate.
> 
> openssl req -new -newkey rsa:2048 -sha256 -days 365 -nodes -x509 -extensions
> v3_ca -keyout myCA.pem  -out myCA.pem
> 
> certtool --generate-privkey --outfile ca-key.pem
> 
> certtool --generate-self-signed --load-privkey ca-key.pem --outfile myCA.pem

You seem to be combining/overlapping two alternative ways to generate a
CA certificate: OpenSSL and GnuTLS. To avoid surprises, I recommend
using either one or another. I cannot speak for GnuTLS, but I know that
the OpenSSL commands did work at some point in the past.


> 1) problem when trying to import myCA.der certificate into firefox: "This is
> not a certificate authority certificate, so it can?t be imported into the
> certificate authority list"

CA certificates have a "true" CA basic constraint. Double check that
your certificate has a true CA extension:

    $ openssl x509 -in myCA.pem -noout -text | \
      grep -A1 'Basic Constraints'
                X509v3 Basic Constraints:
                   CA:TRUE

By default, your modern browser or OS might not trust _you_ with
deciding which CAs it should trust. If that is the case, you will need
to find a way to bypass that built-in browser/OS "safety net". Modern
browsers/OSes usually have a way to do that because their
corporate/government clients require such workarounds.


> 2) My goal is simply to whitelist sites, I do not have a need to view the
> traffic. Is following ssl-bump examples the right/only approach or is easier
> way to let the client connect directly, but preventing any connection except
> if on the whitelist?

FWIW, I do not understand what you mean by "let the client connect
directly" and/or how that differs from some of the SslBump examples.
Please detail that part.

Today, the fake CA certificate is needed to enable SslBump. It will be
used to report errors (including blocked access) to users.

If you do not want to report any errors to users, then you do not need
to import your CA certificate into browsers (but you still need to give
that certificate to Squid -- it is a limitation of the current
implementation). In this case, you should configure your Squid to
terminate the from-client TLS connection on any error. Doing so may be
difficult -- there is no single directive that can do that for you.


HTH,

Alex.


From guy20034u at yahoo.com  Tue Dec 10 16:18:07 2019
From: guy20034u at yahoo.com (simon ben)
Date: Tue, 10 Dec 2019 16:18:07 +0000 (UTC)
Subject: [squid-users] one site not working
In-Reply-To: <e3dd4985-7608-5358-6010-41051484ff19@treenet.co.nz>
References: <2018052354.7139044.1575910345037.ref@mail.yahoo.com>
 <2018052354.7139044.1575910345037@mail.yahoo.com>
 <e3dd4985-7608-5358-6010-41051484ff19@treenet.co.nz>
Message-ID: <120830004.7476790.1575994687741@mail.yahoo.com>

 Dear Amos,
Thanks for the quick reply.
Yes its an old version as I use to install using yum.I will upgrade as you said and check it out
thanks once again
Regards
simon

    On Tuesday, December 10, 2019, 10:57:47 AM GMT+3, Amos Jeffries <squid3 at treenet.co.nz> wrote:  
 
 On 10/12/19 5:52 am, simon ben wrote:
> Dear All,
> 
> ?
> 
> I am using Squid version 3.5.2 on Centos ?7 64 bit and its working fine
> with no issue but recently got a complain from one user saying that the
> below site Is not opening..? just says page cannot be displayed
> 

That would be one issue. Likely many others you are just not noticing.

Please upgrade. v3.5.2 is over 5 years old and obsolete. Current Squid
release is v4.9.


?
> 
> 1575869460.673?? 6034 172.16.2.175 TCP_TUNNEL/200 0 CONNECT
> my.esri.com:443 <http://my.esri.com:443> - HIER_DIRECT/34.210.189.55
> <http://34.210.189.55> -
> 
> 1575869461.235??? 559 172.16.2.175 TCP_TUNNEL/200 0 CONNECT
> my.esri.com:443 <http://my.esri.com:443> - HIER_DIRECT/34.210.189.55
> <http://34.210.189.55> -
> 
> 1575869461.801??? 562 172.16.2.175 TCP_TUNNEL/200 0 CONNECT
> my.esri.com:443 <http://my.esri.com:443> - HIER_DIRECT/34.210.189.55
> <http://34.210.189.55> -
> 
> 1575869462.096??? 291 172.16.2.175 TCP_TUNNEL/200 0 CONNECT
> my.esri.com:443 <http://my.esri.com:443> - HIER_DIRECT/34.210.189.55
> <http://34.210.189.55> ?
> 
> ?
> 
> ?
> 
> I tried to google around and found that the the ip4 prefrence has to
> enabled for DNS so I did the below in squid config
> 

No it does not. Your proxy is already connecting the tunnel to that
sites IPv4 address.


Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191210/25e69fa5/attachment.htm>

From leonyu365 at gmail.com  Tue Dec 10 23:21:59 2019
From: leonyu365 at gmail.com (leonyuuu)
Date: Tue, 10 Dec 2019 17:21:59 -0600 (CST)
Subject: [squid-users] Sibling peer cache not working, ver 3.5.27
Message-ID: <1576020119899-0.post@n4.nabble.com>

Hi, I got some problems in working with squid when writing a network
experiment that involves squid-proxy. The topology is something looks like
this: 
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377850/experiment.png> 

The basic idea of the topology is that two squid proxies were set to
interception mode and all the traffic from h0/h1 will be routed by r0's
static route to go either proxy0 or proxy1. And the firewall will only do
nat for requests to outside. 

The experiment is carried out with linux netns and squid proxy setting is
something like this: 
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377850/sreenshot1.png> 





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From leonyu365 at gmail.com  Tue Dec 10 23:36:06 2019
From: leonyu365 at gmail.com (leonyuuu)
Date: Tue, 10 Dec 2019 17:36:06 -0600 (CST)
Subject: [squid-users] Sibling peer cache not working, ver 3.5.27
In-Reply-To: <1576020119899-0.post@n4.nabble.com>
References: <1576020119899-0.post@n4.nabble.com>
Message-ID: <1576020966404-0.post@n4.nabble.com>

Sent the unfinished mail accidentally. The body of the mail now is updated
from the original one. 



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From g2011828 at hotmail.com  Wed Dec 11 03:00:42 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Tue, 10 Dec 2019 21:00:42 -0600 (CST)
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <ba63ebca-810a-59b7-b3f7-9d4fac8646db@measurement-factory.com>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
 <724ee00d-44bb-a0df-aa3f-007d13b96970@measurement-factory.com>
 <1575914210679-0.post@n4.nabble.com>
 <ba63ebca-810a-59b7-b3f7-9d4fac8646db@measurement-factory.com>
Message-ID: <1576033242405-0.post@n4.nabble.com>

I'm running the squid latest from download site. 4.9
Ok, i suspect that was related to my ^C running the process in foreground,
but I also see before that there are warning messages in the log:
2019/12/09 19:23:12.116 kid1| WARNING:
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MB #Hlpr5 exited
2019/12/09 19:23:12.118 kid1| WARNING:
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MB #Hlpr1 exited
2019/12/09 19:23:12.123 kid1| WARNING:
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MB #Hlpr3 exited

it could be related also to my ^C, but not sure.

the other program, I have found it is related to my golang program set the
ciphersuite to some more secured cipher algorithm:
tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, and
tls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256. After removed those cipher
restrictions, the ssl-bump does work.

thanks.
- George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From g2011828 at hotmail.com  Wed Dec 11 03:08:49 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Tue, 10 Dec 2019 21:08:49 -0600 (CST)
Subject: [squid-users] Is there a scalable way in SSL-Bump forwarding
 client's certificate to server?
Message-ID: <1576033729948-0.post@n4.nabble.com>

Hi,

I've seen some post saying there is a way to configure the squid proxy to
get the client certificate. But to be scalable (assume it has many https
clients) I'm wonder if the proxy can ask for the client certificate and
modify that certificate in negotiating the session with the server; just
like the proxy dynamically generate the certificate to the client
representing the server. I understand in the current timeline, the proxy is
negotiate with the server before accepting the tls hello from client.

thanks.
- George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Wed Dec 11 03:20:52 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 10 Dec 2019 22:20:52 -0500
Subject: [squid-users] Is there a scalable way in SSL-Bump forwarding
 client's certificate to server?
In-Reply-To: <1576033729948-0.post@n4.nabble.com>
References: <1576033729948-0.post@n4.nabble.com>
Message-ID: <7411acba-6717-1821-1021-ed3c8ddc8ad4@measurement-factory.com>

On 12/10/19 10:08 PM, GeorgeShen wrote:

> I've seen some post saying there is a way to configure the squid proxy to
> get the client certificate.

Yes, look for "client certificate" in your squid.conf.documented.


> But to be scalable (assume it has many https clients) 

If you are implying that Squid would check whether the client has sent a
particular client certificate copy, then this is not how certificate
authentication works. Squid would validate whether the client has sent a
certificate _signed_ by the configured client CA certificate. A single
CA certificate can be used to sign (i.e. issue) millions of client
certificates.


> I'm wonder if the proxy can ask for the client certificate and
> modify that certificate in negotiating the session with the server;

It is possible in theory but Squid cannot do that. There could be some
very special environments where such a scheme would make sense, but keep
in mind that the server would have to share its client CA certificate
(or equivalent) with Squid for the scheme to work.


> I understand in the current timeline, the proxy is
> negotiate with the server before accepting the tls hello from client.

In most SslBump setups, Squid negotiates with the server _after_ seeing
the TLS client Hello.

Alex.


From leonyu365 at gmail.com  Wed Dec 11 04:47:32 2019
From: leonyu365 at gmail.com (leonyuuu)
Date: Tue, 10 Dec 2019 22:47:32 -0600 (CST)
Subject: [squid-users] Sibling peer cache not working, ver 3.5.27
In-Reply-To: <1576020119899-0.post@n4.nabble.com>
References: <1576020119899-0.post@n4.nabble.com>
Message-ID: <1576039652095-0.post@n4.nabble.com>

For cache digest requests between two interception squid proxies, it will
actually display "forward loop detection" in the cache.log and the last Via
host for that query(cache-digest-db) is itself. So is it also the root cause
why the cache-miss forwarding between two proxies is not working? Since the
proxy1 actually never knows the cache digest content of proxy0. 

Another question, why the interception squid proxy will append itself onto
the Via field of request? It actually forward the request by iptables
PREROUTING phase, which is before the packet is accepted by the squid
program. 




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From g2011828 at hotmail.com  Wed Dec 11 05:48:10 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Tue, 10 Dec 2019 23:48:10 -0600 (CST)
Subject: [squid-users] Is there a scalable way in SSL-Bump forwarding
 client's certificate to server?
In-Reply-To: <7411acba-6717-1821-1021-ed3c8ddc8ad4@measurement-factory.com>
References: <1576033729948-0.post@n4.nabble.com>
 <7411acba-6717-1821-1021-ed3c8ddc8ad4@measurement-factory.com>
Message-ID: <1576043290685-0.post@n4.nabble.com>

>Yes, look for "client certificate" in your squid.conf.documented.

Ok. for the 'clientca=' and 'tls-cafile=', is the purpose for proxy to
verify the client cert again this list before allow the connection to go
further? or it can use those client certificate also for other things?

Also the RFC TLS 1.2 says client send certificate only if the server asks
it, here it means the proxy. Does this configure 'clientca=' signal all the
client to send their certificate if it has one?

thanks.
- George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From 3m9n51s2ewut at thismonkey.com  Wed Dec 11 07:51:43 2019
From: 3m9n51s2ewut at thismonkey.com (Scott)
Date: Wed, 11 Dec 2019 18:51:43 +1100
Subject: [squid-users] A patch for intercepted/WCCP HTTPS and 409 errors
Message-ID: <20191211075143.GA57830@thismonkey.com>

Hi,

I understand that squid does some security checking that the SNI of an 
intercepted/WCCP HTTPS requests matches the reverse DNS of the IP of the 
connection.  Or something like that.

However with the prevalence of CDNs and badly configured DNSs and geographic 
DNSs, this breaks lots of connections (eg, I can't watch the NHL).

I run Squid on a trusted network and use it primarily for caching and 
logging, and so I while I need to run WCCP for some non-proxy capable 
devices, I don't need that security check.

It stops all of those 409 errors occurring.

Because of that I've created some patches that add a new option
"host_verify_strict_intercepted" which is off by default.  They are
for Squid 4.9.  As this is disabling a security feature of Squid do
not apply this patch unless you are prepared for any and all consequences.

--- cf.data.pre 2019-12-11 12:56:37.263665000 +1100
+++ cf.data.pre.orig    2019-12-11 11:25:20.708044000 +1100
@@ -2632,15 +2632,6 @@
        See http://wiki.squid-cache.org/SquidFaq/SquidAcl for details.
 DOC_END

-NAME: host_verify_strict_intercepted
-TYPE: onoff
-DEFAULT: on
-LOC: Config.onoff.hostStrictVerifyIntercepted
-DOC_START
-       To be completed.
-
-DOC_END
-
 NAME: host_verify_strict
 TYPE: onoff
 DEFAULT: off

--- client_side_request.cc      2019-12-11 12:52:04.552556000 +1100
+++ client_side_request.cc.orig 2019-11-06 06:14:40.000000000 +1100
@@ -642,21 +642,16 @@

     debugs(85, 3, "validate host=" << host << ", port=" << port << ", portStr=" << (portStr?portStr:"NULL"));
     if (http->request->flags.intercepted || http->request->flags.interceptTproxy) {
-        if (Config.onoff.hostStrictVerifyIntercepted) {
-            // verify the Host: port (if any) matches the apparent destination
-            if (portStr && port != http->getConn()->clientConnection->local.port()) {
-                debugs(85, 3, "FAIL on validate port " << http->getConn()->clientConnection->local.port() <<
-                       " matches Host: port " << port << " (" << portStr << ")");
-                hostHeaderVerifyFailed("intercepted port", portStr);
-            } else {
-                // XXX: match the scheme default port against the apparent destination
-
-                // verify the destination DNS is one of the Host: headers IPs
-                ipcache_nbgethostbyname(host, hostHeaderIpVerifyWrapper, this);
-            }
+        // verify the Host: port (if any) matches the apparent destination
+        if (portStr && port != http->getConn()->clientConnection->local.port()) {
+            debugs(85, 3, "FAIL on validate port " << http->getConn()->clientConnection->local.port() <<
+                   " matches Host: port " << port << " (" << portStr << ")");
+            hostHeaderVerifyFailed("intercepted port", portStr);
         } else {
-            debugs(85, 3, "validate intercept skipped.");
-            http->doCallouts();
+            // XXX: match the scheme default port against the apparent destination
+
+            // verify the destination DNS is one of the Host: headers IPs
+            ipcache_nbgethostbyname(host, hostHeaderIpVerifyWrapper, this);
         }
     } else if (!Config.onoff.hostStrictVerify) {
         debugs(85, 3, "validate skipped.");



From uhlar at fantomas.sk  Wed Dec 11 09:00:44 2019
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 11 Dec 2019 10:00:44 +0100
Subject: [squid-users] Sibling peer cache not working, ver 3.5.27
In-Reply-To: <1576020966404-0.post@n4.nabble.com>
References: <1576020119899-0.post@n4.nabble.com>
 <1576020966404-0.post@n4.nabble.com>
Message-ID: <20191211090044.GA2913@fantomas.sk>

On 10.12.19 17:36, leonyuuu wrote:
>Sent the unfinished mail accidentally. The body of the mail now is updated
>from the original one.

Don't do this.

This is not nabble, but the squid-users mailing list and I doubt people are
wanting to look at nabble's webpage to see what you have edited.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
"One World. One Web. One Program." - Microsoft promotional advertisement
"Ein Volk, ein Reich, ein Fuhrer!" - Adolf Hitler


From squid3 at treenet.co.nz  Wed Dec 11 12:05:15 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Dec 2019 01:05:15 +1300
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <1576033242405-0.post@n4.nabble.com>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
 <724ee00d-44bb-a0df-aa3f-007d13b96970@measurement-factory.com>
 <1575914210679-0.post@n4.nabble.com>
 <ba63ebca-810a-59b7-b3f7-9d4fac8646db@measurement-factory.com>
 <1576033242405-0.post@n4.nabble.com>
Message-ID: <e0fac586-eb44-d355-2a70-2c50c9d1ae31@treenet.co.nz>

On 11/12/19 4:00 pm, GeorgeShen wrote:
> I'm running the squid latest from download site. 4.9
> Ok, i suspect that was related to my ^C running the process in foreground,
> but I also see before that there are warning messages in the log:
> 2019/12/09 19:23:12.116 kid1| WARNING:
> /usr/local/squid/libexec/security_file_certgen -s
> /usr/local/squid/var/logs/ssl_db -M 4MB #Hlpr5 exited
> 2019/12/09 19:23:12.118 kid1| WARNING:
> /usr/local/squid/libexec/security_file_certgen -s
> /usr/local/squid/var/logs/ssl_db -M 4MB #Hlpr1 exited
> 2019/12/09 19:23:12.123 kid1| WARNING:
> /usr/local/squid/libexec/security_file_certgen -s
> /usr/local/squid/var/logs/ssl_db -M 4MB #Hlpr3 exited
> 
> it could be related also to my ^C, but not sure.
> 
> the other program, I have found it is related to my golang program set the
> ciphersuite to some more secured cipher algorithm:
> tls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384, and
> tls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256. After removed those cipher
> restrictions, the ssl-bump does work.

That implies that your proxy is configured in such a way that these
ciphers are not usable - and/or that the origin servers being contacted
cannot handle them.

You may want to fix that for at least Squid. To do so set the tls-dh=
option with a preference EC curve name and DHE parameters file.


Amos


From squid3 at treenet.co.nz  Wed Dec 11 12:00:23 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Dec 2019 01:00:23 +1300
Subject: [squid-users] HTTPS interception proxy having issues
In-Reply-To: <CABi+OR+STb5EWcNptFZHgwK5Zv3nvxc3F5zLMkdDWY0m1k2iJg@mail.gmail.com>
References: <CABi+OR+STb5EWcNptFZHgwK5Zv3nvxc3F5zLMkdDWY0m1k2iJg@mail.gmail.com>
Message-ID: <b0fde508-ec79-b310-385a-19070e574cd7@treenet.co.nz>

On 11/12/19 3:48 am, aashutosh kalyankar wrote:
> 
> Hi! I am trying to set up a HTTPs intercept proxy but I cannot get it to
> work. Can someone point me in the right direction??
> 
> I tried following the
> tutorial?@?https://www.youtube.com/watch?v=Bogdplu_lsE (Transparent
> HTTP+HTTPS Proxy with Squid and iptables)? for squid file.
> and?https://github.com/diladele/squid-ubuntu?for building squid 3.5 on
> ubuntu.?
> 
> *squid.conf file?*
> 
> acl clients src?172.16.10.0/24
> acl clients src?172.18.10.0/24
> 
> http_access allow localhost
> http_access allow clients
> http_access deny all
> http_port 8080
> http_port 3128 intercept
> https_port 3129 intercept ssl-bump cert=/etc/squid/ssl_certs/myCA.pem
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> 
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump bump all
> 
> # only wait 5 seconds to terminate active connections
> shutdown_lifetime 5
> ~? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
> 
> I am forced to use old 3.5 version of squid as I am running?very old
> version of Vsphere supporting ubuntu 14.04 and below. 

Such things do not apply when building from source. You can build any
version which your build tools can handle. That should be any Squid-3.5
release, including the daily auto-generated code.



> *Squid Cache: Version 3.5.19?*
> Service Name: squid
> Ubuntu linux
> configure options: ?'--build=x86_64-linux-gnu' '--prefix=/usr'
> '--includedir=${prefix}/include' '--mandir=${prefix}/share/man'
> '--infodir=${prefix}/share/info' '--sysconfdir=/etc'
> '--localstatedir=/var' '--libexecdir=${prefix}/lib/squid3' '--srcdir=.'
> '--disable-maintainer-mode' '--disable-dependency-tracking'
> '--disable-silent-rules' 'BUILDCXXFLAGS=-g -O2 -fPIE -fstack-protector
> --param=ssp-buffer-size=4 -Wformat -Werror=format-security
> -D_FORTIFY_SOURCE=2 -Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro
> -Wl,-z,now' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
> '--libexecdir=/usr/lib/squid' '--mandir=/usr/share/man'
> '--enable-inline' '--disable-arch-native' '--enable-async-io=8'
> '--enable-storeio=ufs,aufs,diskd,rock'
> '--enable-removal-policies=lru,heap' '--enable-delay-pools'
> '--enable-cache-digests' '--enable-icap-client'
> '--enable-follow-x-forwarded-for'
> '--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB'
> '--enable-auth-digest=file,LDAP'
> '--enable-auth-negotiate=kerberos,wrapper'
> '--enable-auth-ntlm=fake,smb_lm'
> '--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,time_quota,unix_group,wbinfo_group'
> '--enable-url-rewrite-helpers=fake' '--enable-eui' '--enable-esi'
> '--enable-icmp' '--enable-zph-qos' '--enable-ecap'
> '--disable-translation' '--with-swapdir=/var/spool/squid'
> '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid'
> '--with-filedescriptors=65536' '--with-large-files'
> '--with-default-user=proxy' '--with-openssl' '--enable-ssl'
> '--enable-ssl-crtd' '--enable-build-info=Ubuntu linux'
> '--enable-linux-netfilter' 'build_alias=x86_64-linux-gnu' 'CFLAGS=-g -O2
> -fPIE -fstack-protector --param=ssp-buffer-size=4 -Wformat
> -Werror=format-security -Wall' 'LDFLAGS=-Wl,-Bsymbolic-functions -fPIE
> -pie -Wl,-z,relro -Wl,-z,now' 'CPPFLAGS=-D_FORTIFY_SOURCE=2'
> 'CXXFLAGS=-g -O2 -fPIE -fstack-protector --param=ssp-buffer-size=4
> -Wformat -Werror=format-security'
> 
> 
> *Firewall & Nat rules added?*
> sudo iptables -A INPUT -j ACCEPT -p tcp --dport 3128 -m comment
> --comment "squid http proxy"
> sudo iptables -A INPUT -j ACCEPT -p tcp --dport 3129 -m comment
> --comment "squid https proxy"
> sudo iptables -A INPUT -j ACCEPT -p tcp ?--dport 8080 -m comment
> -comment "squid http8080 proxy


Irrelevant unless you have a local policy of requiring these for any
port to receive traffic.

There should be mangle table PREROUTING chain rule(s) to DROP or REJECT
any packets headed to Squid intercept ports.


> 
> ?sudo iptables -t nat -A PREROUTING -i eth0 -p tcp -m tcp --dport 80 -m
> comment --comment "transparent http proxy" -j REDIRECT --to-ports 3128
> ?sudo iptables -t nat -A PREROUTING -i eth0 -p tcp -m tcp --dport 443 -m
> comment --comment "transparent https proxy" -j REDIRECT --to-ports 3129
> ?sudo iptables -t nat -A PREROUTING -i eth0 -p tcp -m tcp --dport 80 -m
> comment --comment " http 8080 proxy" -j REDIRECT --to-ports 8080

You already REDIRECT port 80 to port 3128. This last rule will do nothing.

> 
> *CACHE.log*
> My machine ip: 172.16.10.5
> Squid server ip(vmware): 172.18.10.15
> 2019/12/09 19:42:00.677 kid1| SECURITY ALERT: Host header forgery
> detected on local=172.18.10.15:3128
> <http://172.18.10.15:3128/>?remote=172.16.10.5:35346
> <http://172.16.10.5:35346/>?FD 21 flags=33 (intercepted port does not
> match 443)


Squid is receiving a request for the URL https://172.18.10.15:3128/ or
equivalent.

It looks to me like you are making the classic mistake of sending
traffic directly to the Squid intercept port.

To test an interceptor proxy you MUST have a client making normal
requests like you would see them do in production environment ...
directly to the HTTP(S) origin servers.
 Let the intercept/NAT systems catch the traffic and deliver it to the
proxy - only then will that proxy have a chance at working as intended.



Amos


From squid3 at treenet.co.nz  Wed Dec 11 12:10:06 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Dec 2019 01:10:06 +1300
Subject: [squid-users] Is there a scalable way in SSL-Bump forwarding
 client's certificate to server?
In-Reply-To: <1576043290685-0.post@n4.nabble.com>
References: <1576033729948-0.post@n4.nabble.com>
 <7411acba-6717-1821-1021-ed3c8ddc8ad4@measurement-factory.com>
 <1576043290685-0.post@n4.nabble.com>
Message-ID: <d72bb0fc-9e98-fb53-93bd-439353ef42e5@treenet.co.nz>

On 11/12/19 6:48 pm, GeorgeShen wrote:
>> Yes, look for "client certificate" in your squid.conf.documented.
> 
> Ok. for the 'clientca=' and 'tls-cafile=', is the purpose for proxy to
> verify the client cert again this list before allow the connection to go
> further? or it can use those client certificate also for other things?

There is no "or" about it. Both.

Any client certificate given must verify.

Valid client certificates can be used for things other than verification.


> 
> Also the RFC TLS 1.2 says client send certificate only if the server asks
> it, here it means the proxy. Does this configure 'clientca=' signal all the
> client to send their certificate if it has one?
> 

Yes. Exactly so.


Amos


From squid3 at treenet.co.nz  Wed Dec 11 12:34:59 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Dec 2019 01:34:59 +1300
Subject: [squid-users] A patch for intercepted/WCCP HTTPS and 409 errors
In-Reply-To: <20191211075143.GA57830@thismonkey.com>
References: <20191211075143.GA57830@thismonkey.com>
Message-ID: <ec88975b-f054-6cf0-66fd-3e70786055bc@treenet.co.nz>

On 11/12/19 8:51 pm, Scott wrote:
> Hi,
> 
> I understand that squid does some security checking that the SNI of an 
> intercepted/WCCP HTTPS requests matches the reverse DNS of the IP of the 
> connection.  Or something like that.

Not being able to say precisely what Squid is actually doing shows that
you are lacking understanding of the processes taking place.

The security check you are posting about has many secondary consequences
and side effects to be taken into account. Quite a few people have taken
a stab at solving these rejections and what we have in Squid right now
is the best that can be done without significant redesign work (which is
underway - just very slowly, help welcome).

This is why we have the squid-dev mailing list for code change
discussion. If you want to actually help solving false-positives in this
security check please post there and we who have been working on this
issue for 10+ years now can discuss what we know about the situation,
the "gotcha" side effects we have to avoid and ideas for improvement.


> 
> However with the prevalence of CDNs and badly configured DNSs and geographic 
> DNSs, this breaks lots of connections (eg, I can't watch the NHL).
> 
> I run Squid on a trusted network and use it primarily for caching and 
> logging, and so I while I need to run WCCP for some non-proxy capable 
> devices, I don't need that security check.

Without that check you cannot call your network a "secure network"
anymore. The absence of the check opens a nest of security holes for
attackers to walk right in past all those other protections.


> 
> It stops all of those 409 errors occurring.
> 
> Because of that I've created some patches that add a new option
> "host_verify_strict_intercepted" which is off by default.  They are
> for Squid 4.9.  As this is disabling a security feature of Squid do
> not apply this patch unless you are prepared for any and all consequences.
> 

Please do not spread this around. People who want to really insist on
allowing virus/malware to spread unchecked around their networks can
make smaller patches.

Amos


From 3m9n51s2ewut at thismonkey.com  Wed Dec 11 12:49:10 2019
From: 3m9n51s2ewut at thismonkey.com (Scott)
Date: Wed, 11 Dec 2019 23:49:10 +1100
Subject: [squid-users] A patch for intercepted/WCCP HTTPS and 409 errors
In-Reply-To: <mailman.2053.1576067664.3049.squid-users@lists.squid-cache.org>
References: <mailman.2053.1576067664.3049.squid-users@lists.squid-cache.org>
Message-ID: <20191211124910.GA42725@thismonkey.com>

> On 11/12/19 8:51 pm, Scott wrote:
> > Hi,
> > 
> > I understand that squid does some security checking that the SNI of an 
> > intercepted/WCCP HTTPS requests matches the reverse DNS of the IP of the 
> > connection.  Or something like that.
> 
> Not being able to say precisely what Squid is actually doing shows that
> you are lacking understanding of the processes taking place.
> 
> The security check you are posting about has many secondary consequences
> and side effects to be taken into account. Quite a few people have taken
> a stab at solving these rejections and what we have in Squid right now
> is the best that can be done without significant redesign work (which is
> underway - just very slowly, help welcome).
> 
> This is why we have the squid-dev mailing list for code change
> discussion. If you want to actually help solving false-positives in this
> security check please post there and we who have been working on this
> issue for 10+ years now can discuss what we know about the situation,
> the "gotcha" side effects we have to avoid and ideas for improvement.
> 
> 
> > 
> > However with the prevalence of CDNs and badly configured DNSs and geographic 
> > DNSs, this breaks lots of connections (eg, I can't watch the NHL).
> > 
> > I run Squid on a trusted network and use it primarily for caching and 
> > logging, and so I while I need to run WCCP for some non-proxy capable 
> > devices, I don't need that security check.
> 
> Without that check you cannot call your network a "secure network"
> anymore. The absence of the check opens a nest of security holes for
> attackers to walk right in past all those other protections.
> 
> 
> > 
> > It stops all of those 409 errors occurring.
> > 
> > Because of that I've created some patches that add a new option
> > "host_verify_strict_intercepted" which is off by default.  They are
> > for Squid 4.9.  As this is disabling a security feature of Squid do
> > not apply this patch unless you are prepared for any and all consequences.
> > 
> 
> Please do not spread this around. People who want to really insist on
> allowing virus/malware to spread unchecked around their networks can
> make smaller patches.
> 
> Amos
> 
Hi Amos,

sorry for posting in the wrong forum.  While you're here: I've seen a handful 
of posts about the 409s and the response has been "security".  Fair enough.  

Can you please provide a concrete example of

a) why host_verify_strict is available as a toggle for non-intercepted 
requests, and
b) why intercepted requests don't have this option at all?

I'm suffering from a lack of imagination and I've yet to see any example 
given (and ok, I may have missed one somewhere) and would like one brought to 
my (and other reader's) attention.

Thanks,
Scott


From squid3 at treenet.co.nz  Wed Dec 11 12:59:03 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Dec 2019 01:59:03 +1300
Subject: [squid-users] Sibling peer cache not working, ver 3.5.27
In-Reply-To: <1576039652095-0.post@n4.nabble.com>
References: <1576020119899-0.post@n4.nabble.com>
 <1576039652095-0.post@n4.nabble.com>
Message-ID: <7806aa57-3c09-d09d-0374-fab101140a18@treenet.co.nz>

On 11/12/19 5:47 pm, leonyuuu wrote:
> For cache digest requests between two interception squid proxies, it will
> actually display "forward loop detection" in the cache.log and the last Via
> host for that query(cache-digest-db) is itself. So is it also the root cause
> why the cache-miss forwarding between two proxies is not working?

You have set the "intercept" option on your proxies port 3128 line.

You have used port 3128 as the port the two proxies are communicating
with each other. This requires an explicit/forward proxy port.


I suggest leave port 3128 for the normal proxying traffic and move the
intercept and NAT rules to a randomly selected other port number. This
other port *must not* be able to receive traffic directly, only the
machines NAT system and Squid may use it.


> Since the
> proxy1 actually never knows the cache digest content of proxy0. 
> 
> Another question, why the interception squid proxy will append itself onto
> the Via field of request?

To allow detection and debug analysis of exactly the mistake you have
made. That is the purpose of Via.


> It actually forward the request by iptables
> PREROUTING phase, which is before the packet is accepted by the squid
> program. 
> 

That idea is wrong. The digest exchange is between two proxies, which
know about each other - you configured the details of how they
communicate in cache_peer config lines.

Amos



From squid3 at treenet.co.nz  Wed Dec 11 13:27:46 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Dec 2019 02:27:46 +1300
Subject: [squid-users] A patch for intercepted/WCCP HTTPS and 409 errors
In-Reply-To: <20191211124910.GA42725@thismonkey.com>
References: <mailman.2053.1576067664.3049.squid-users@lists.squid-cache.org>
 <20191211124910.GA42725@thismonkey.com>
Message-ID: <50b0b52c-00d2-6c2e-92ee-c4017eb9e8c7@treenet.co.nz>

On 12/12/19 1:49 am, Scott wrote:
>> On 11/12/19 8:51 pm, Scott wrote:
>>> Hi,
>>>
>>> I understand that squid does some security checking that the SNI of an 
>>> intercepted/WCCP HTTPS requests matches the reverse DNS of the IP of the 
>>> connection.  Or something like that.
>>
>> Not being able to say precisely what Squid is actually doing shows that
>> you are lacking understanding of the processes taking place.
>>
>> The security check you are posting about has many secondary consequences
>> and side effects to be taken into account. Quite a few people have taken
>> a stab at solving these rejections and what we have in Squid right now
>> is the best that can be done without significant redesign work (which is
>> underway - just very slowly, help welcome).
>>
>> This is why we have the squid-dev mailing list for code change
>> discussion. If you want to actually help solving false-positives in this
>> security check please post there and we who have been working on this
>> issue for 10+ years now can discuss what we know about the situation,
>> the "gotcha" side effects we have to avoid and ideas for improvement.
>>
>>
>>>
>>> However with the prevalence of CDNs and badly configured DNSs and geographic 
>>> DNSs, this breaks lots of connections (eg, I can't watch the NHL).
>>>
>>> I run Squid on a trusted network and use it primarily for caching and 
>>> logging, and so I while I need to run WCCP for some non-proxy capable 
>>> devices, I don't need that security check.
>>
>> Without that check you cannot call your network a "secure network"
>> anymore. The absence of the check opens a nest of security holes for
>> attackers to walk right in past all those other protections.
>>
>>
>>>
>>> It stops all of those 409 errors occurring.
>>>
>>> Because of that I've created some patches that add a new option
>>> "host_verify_strict_intercepted" which is off by default.  They are
>>> for Squid 4.9.  As this is disabling a security feature of Squid do
>>> not apply this patch unless you are prepared for any and all consequences.
>>>
>>
>> Please do not spread this around. People who want to really insist on
>> allowing virus/malware to spread unchecked around their networks can
>> make smaller patches.
>>
>> Amos
>>
> Hi Amos,
> 
> sorry for posting in the wrong forum.  While you're here: I've seen a handful 
> of posts about the 409s and the response has been "security".  Fair enough.  
> 
> Can you please provide a concrete example of
> 
> a) why host_verify_strict is available as a toggle for non-intercepted 
> requests, and
> b) why intercepted requests don't have this option at all?
> 

a) Because the root vulnerability (CVE-2009-0801) which opens up the
nest of effects has no external effect on non-intercepted HTTP syntax
traffic.
 If you have a paranoid security policy or want to track down broken
software it can be useful to validate everything. So its there, but off
by default.


b) While CVE-2009-0801 appears simply a Browser issue the other side
effects that are possible include seeding the proxy cache with arbitrary
content at arbitrary URLs, using that to spread infections, to
exfiltrate data, and use that data to bypass other security mechanisms
like the network border firewalls.

The worst part is that the Squid access.log are also corrupted with
false information from the Host header (and/or SNI in HTTPS) on the
transactions where these things happen. So the attacker is hidden from
admin and security forensics. That is going too far into unsafe
territory IMO.


Other useful reading:
 <http://www.squid-cache.org/Advisories/SQUID-2011_1.txt>
 <https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery>


> I'm suffering from a lack of imagination and I've yet to see any example 
> given (and ok, I may have missed one somewhere) and would like one brought to 
> my (and other reader's) attention.
> 
> Thanks,
> Scott
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 


From rousskov at measurement-factory.com  Wed Dec 11 13:45:29 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 11 Dec 2019 08:45:29 -0500
Subject: [squid-users] Is there a scalable way in SSL-Bump forwarding
 client's certificate to server?
In-Reply-To: <d72bb0fc-9e98-fb53-93bd-439353ef42e5@treenet.co.nz>
References: <1576033729948-0.post@n4.nabble.com>
 <7411acba-6717-1821-1021-ed3c8ddc8ad4@measurement-factory.com>
 <1576043290685-0.post@n4.nabble.com>
 <d72bb0fc-9e98-fb53-93bd-439353ef42e5@treenet.co.nz>
Message-ID: <758dcf9b-c722-ff29-f36e-7979996b5c41@measurement-factory.com>

On 12/11/19 7:10 AM, Amos Jeffries wrote:
> On 11/12/19 6:48 pm, GeorgeShen wrote:
>> Ok. for the 'clientca=' and 'tls-cafile=', is the purpose for proxy to
>> verify the client cert again this list before allow the connection to go
>> further?

> Any client certificate given must verify.

And, by default, any TLS client not providing a certificate will be denied.


>> Does this configure 'clientca=' signal all the
>> client to send their certificate if it has one?

By default, the setting implies that a client has to send a client
certificate. If a client does not have a certificate, it cannot
successfully negotiate a TLS connection with a clientca-enabled https_port.

Squid has options that can change the above default behavior.

Alex.


From eype69 at gmail.com  Wed Dec 11 18:15:37 2019
From: eype69 at gmail.com (John Sweet-Escott)
Date: Wed, 11 Dec 2019 18:15:37 +0000
Subject: [squid-users] Resolved: Peek-and-splice not working when mixing
	TLS1.3 servers and TLS1.2 clients
In-Reply-To: <a0cb15df-648c-c0f6-f410-948176524683@ntcomputer.de>
References: <a0cb15df-648c-c0f6-f410-948176524683@ntcomputer.de>
Message-ID: <0EFAB3DB-D6C6-4DCC-BBD3-FAC8CA048FC4@gmail.com>

Hi Nikolaus 

This sounds exactly like the symptoms we have encountered. Will build from your patch & test to see if it works in our situation. 

John. 


> On 7 Dec 2019, at 13:54, Nikolaus <dc.sqml at ntcomputer.de> wrote:
> 
> ? I was able to solve the issue, fixing both squid-side "error:1425F175:SSL routines:ssl_choose_client_version:inappropriate fallback (1/-1/0)" and client-side certificate verification errors when attempting to contact TLS 1.3 server over a TLS 1.3-enabled squid from a TLS 1.2 client. I will first explain what causes the issue before presenting my solution, which involves changes of the squid code base, for anybody who is affected by the same problem.
> 
> I have inspected the squid source code and noticed that TLS peeking works roughly like this:
> 
> 1. The client sends a client_hello, which is parsed by squid using a custom handshake parser.  <-- Uses TLS 1.2
> 2. Squid creates an OpenSSL TLS session for the peeked connection  <-- Uses TLS 1.3!
> 3. Squid forwards the original client_hello handshake message to the server <-- TLS 1.2
> 4. Squid passes the received server_hello response to the OpenSSL session created previously  <-- Response uses TLS 1.2 - Problem!
> 
> Now, the "problem" is that TLS 1.3 defines a set of new protocol downgrade attack prevention mechanisms (can be found e.g. here: https://blog.gypsyengineer.com/en/security/how-does-tls-1-3-protect-against-downgrade-attacks.html). Both OpenSSL and most likely the server implement these. This includes that the server random in the TLS 1.2 server_hello contains an indicator that the server is TL 1.3-capable. The OpenSSL session created by squid detects this, notices that it is TLS 1.3-capable itself, and closes the connection because it assumes a protocol downgrade attack! Little does it know, that our client actually only supports TLS 1.2, so we *want* the lower protocol version.
> 
> My solution includes setting the maximum TLS version of the OpenSSL session to the version received from the client. This proved a little bit difficult, since the way TLS versions are negotiated has also been changed by the TLS 1.3 specification, and the squid handshake parser was not yet able to detect TLS 1.3 correctly - I have therefore also implemented parsing of the SupportedVersions TLS Extension and a preliminary support for sparse version ranges. You can find all these changes at https://github.com/nthuemmel/squid/tree/tls_downgrade_compatibility , which is a fork of squid 4.9. Feel free to compile & test it if you have a transparent peek-and-splice setup and are affected by the "inappropriate fallback" problem.
> 
> I would of course be glad if the fix could be merged into the main squid repository. If you are a dev, please let me know what you think and if I should open a pull request. There are still some TODOs left, because I wasn't sure what the best way is to integrate some of the changes. Notably, there was also a comment which discourages setting a maximum version for the OpenSSL session to improve peek+bump compatibility - I don't have a setup to which this applies, so I don't know how big of an impact this is or if it is still relevant.
> 
> Best Regards
> Nikolaus
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191211/e22366d4/attachment.htm>

From g2011828 at hotmail.com  Wed Dec 11 22:38:59 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Wed, 11 Dec 2019 16:38:59 -0600 (CST)
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <e0fac586-eb44-d355-2a70-2c50c9d1ae31@treenet.co.nz>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
 <724ee00d-44bb-a0df-aa3f-007d13b96970@measurement-factory.com>
 <1575914210679-0.post@n4.nabble.com>
 <ba63ebca-810a-59b7-b3f7-9d4fac8646db@measurement-factory.com>
 <1576033242405-0.post@n4.nabble.com>
 <e0fac586-eb44-d355-2a70-2c50c9d1ae31@treenet.co.nz>
Message-ID: <1576103939876-0.post@n4.nabble.com>


did a 'openssl dhparam -out dhparams.pem 4096' to generate the dhparams.pem
file, and added those into the squid.conf:

http_port 3129 ssl-bump cert=/usr/local/squid/etc/ssl_cert/myCA.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
*options=SINGLE_DH_USE:SINGLE_ECDH_USE
tls-dh=/usr/local/squid/etc/dhparams.pem*

when the client software include the ciphersuites of the above mentioned,
still fail the TLS negotiation. Do I configured this incorrectly?

thanks.
- George




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From 3m9n51s2ewut at thismonkey.com  Thu Dec 12 02:22:10 2019
From: 3m9n51s2ewut at thismonkey.com (Scott Aitken)
Date: Thu, 12 Dec 2019 13:22:10 +1100
Subject: [squid-users] A patch for intercepted/WCCP HTTPS and 409 errors
In-Reply-To: <mailman.2084.1576088288.3049.squid-users@lists.squid-cache.org>
References: <mailman.2084.1576088288.3049.squid-users@lists.squid-cache.org>
Message-ID: <20191212022210.GA15129@thismonkey.com>

> On 12/12/19 1:49 am, Scott wrote:
> >> On 11/12/19 8:51 pm, Scott wrote:
> >>> Hi,
> >>>
> >>> I understand that squid does some security checking that the SNI of an 
> >>> intercepted/WCCP HTTPS requests matches the reverse DNS of the IP of the 
> >>> connection.  Or something like that.
> >>
> >> Not being able to say precisely what Squid is actually doing shows that
> >> you are lacking understanding of the processes taking place.
> >>
> >> The security check you are posting about has many secondary consequences
> >> and side effects to be taken into account. Quite a few people have taken
> >> a stab at solving these rejections and what we have in Squid right now
> >> is the best that can be done without significant redesign work (which is
> >> underway - just very slowly, help welcome).
> >>
> >> This is why we have the squid-dev mailing list for code change
> >> discussion. If you want to actually help solving false-positives in this
> >> security check please post there and we who have been working on this
> >> issue for 10+ years now can discuss what we know about the situation,
> >> the "gotcha" side effects we have to avoid and ideas for improvement.
> >>
> >>
> >>>
> >>> However with the prevalence of CDNs and badly configured DNSs and geographic 
> >>> DNSs, this breaks lots of connections (eg, I can't watch the NHL).
> >>>
> >>> I run Squid on a trusted network and use it primarily for caching and 
> >>> logging, and so I while I need to run WCCP for some non-proxy capable 
> >>> devices, I don't need that security check.
> >>
> >> Without that check you cannot call your network a "secure network"
> >> anymore. The absence of the check opens a nest of security holes for
> >> attackers to walk right in past all those other protections.
> >>
> >>
> >>>
> >>> It stops all of those 409 errors occurring.
> >>>
> >>> Because of that I've created some patches that add a new option
> >>> "host_verify_strict_intercepted" which is off by default.  They are
> >>> for Squid 4.9.  As this is disabling a security feature of Squid do
> >>> not apply this patch unless you are prepared for any and all consequences.
> >>>
> >>
> >> Please do not spread this around. People who want to really insist on
> >> allowing virus/malware to spread unchecked around their networks can
> >> make smaller patches.
> >>
> >> Amos
> >>
> > Hi Amos,
> > 
> > sorry for posting in the wrong forum.  While you're here: I've seen a handful 
> > of posts about the 409s and the response has been "security".  Fair enough.  
> > 
> > Can you please provide a concrete example of
> > 
> > a) why host_verify_strict is available as a toggle for non-intercepted 
> > requests, and
> > b) why intercepted requests don't have this option at all?
> > 
> 
> a) Because the root vulnerability (CVE-2009-0801) which opens up the
> nest of effects has no external effect on non-intercepted HTTP syntax
> traffic.
>  If you have a paranoid security policy or want to track down broken
> software it can be useful to validate everything. So its there, but off
> by default.
> 
> 
> b) While CVE-2009-0801 appears simply a Browser issue the other side
> effects that are possible include seeding the proxy cache with arbitrary
> content at arbitrary URLs, using that to spread infections, to
> exfiltrate data, and use that data to bypass other security mechanisms
> like the network border firewalls.
> 
> The worst part is that the Squid access.log are also corrupted with
> false information from the Host header (and/or SNI in HTTPS) on the
> transactions where these things happen. So the attacker is hidden from
> admin and security forensics. That is going too far into unsafe
> territory IMO.
> 
> 
> Other useful reading:
>  <http://www.squid-cache.org/Advisories/SQUID-2011_1.txt>
>  <https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery>
> 
> 
> > I'm suffering from a lack of imagination and I've yet to see any example 
> > given (and ok, I may have missed one somewhere) and would like one brought to 
> > my (and other reader's) attention.
> > 
> > Thanks,
> > Scott
Thanks Amos,

I found 
https://www.thesecuritypractice.com/the_security_practice/TransparentProxyAbuse.pdf 
extremely useful.  Unfortunately the documentation around Squid's fix doesn't 
get into the side-effects in great detail.

The biggest side-effect is accessing non-malicious sites whose full list of A 
and AAAA records is incomplete.  This is becoming increasingly common 
especially given the preponderance of CDNs (and poor administration).

For a malicious client it's easy to circumvent Squid's fix (just don't send 
an SNI at all) - this applies to my network as I peek and splice (no MITM - 
so no HTTP headers).  But the main point of the CVE seems to be a general 
user visiting a malicious site.

My reading of the PDF is that Squid could have implemented an option to 
connect to the IP of the intercepted SYN rather than use the SNI/Host:, which 
wouldn't cause these annoying 409s.

That said, do you think the implementation of an acl of permitted dstdomains 
that aren't validated to be insecure?  I'd be happy to have a prescriptive 
list of domain names which are NOT to be verified but known to be broken from 
a DNS perspective.

eg:
acl safe_domains google.com
host_verify_strict !safe_domains

Scott


From leonyu365 at gmail.com  Thu Dec 12 04:04:32 2019
From: leonyu365 at gmail.com (leonyuuu)
Date: Wed, 11 Dec 2019 22:04:32 -0600 (CST)
Subject: [squid-users] Sibling peer cache not working, ver 3.5.27
In-Reply-To: <7806aa57-3c09-d09d-0374-fab101140a18@treenet.co.nz>
References: <1576020119899-0.post@n4.nabble.com>
 <1576039652095-0.post@n4.nabble.com>
 <7806aa57-3c09-d09d-0374-fab101140a18@treenet.co.nz>
Message-ID: <1576123472150-0.post@n4.nabble.com>

Thanks Amos for quick response! It helps a lot in understanding the previous
logs like "forward proxy port not configured", and I adjusted my
configuration later today to do another test. 

However, now the two proxies even doesn't send ICP/HTTP request to each
other anymore for cache digest and the access.log(see below) shows there are
only queries on intercepted traffic. 

<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377850/access.png> 

My new configuration for proxy0:
    http_port 3128
    http_port 9999 intercept
    icp_access allow all 
    icp_port 3130

    cache_peer 192.168.3.2 sibling 3128 3130
    cache_peer_access 192.168.3.2 allow all
    visible_hostname squid.host.1

Iptables configuration added for proxy0: 
    // for inter-proxy trafic
    "iptables -t nat -A PREROUTING -i veth20 --dport 80 -j REDIRECT
--to-port 3128"
    // for intercepted traffic
    "iptables -t nat -A PREROUTING -i veth12 --dport 80 -j REDIRECT
--to-port 9999"

With tcpdump(see below) listening on the interface that connects the other
proxy, I can see there are established tcp connections between two proxies,
is this traffic for netdb only? I am really wondering what could potentially
prevent from the Cache Digest being exchanged between siblings. 

<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377850/tcpdump.png> 

Thanks, 
Leon



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From leonyu365 at gmail.com  Thu Dec 12 04:07:30 2019
From: leonyu365 at gmail.com (leonyuuu)
Date: Wed, 11 Dec 2019 22:07:30 -0600 (CST)
Subject: [squid-users] Sibling peer cache not working, ver 3.5.27
In-Reply-To: <20191211090044.GA2913@fantomas.sk>
References: <1576020119899-0.post@n4.nabble.com>
 <1576020966404-0.post@n4.nabble.com> <20191211090044.GA2913@fantomas.sk>
Message-ID: <1576123650806-0.post@n4.nabble.com>

Matus UHLAR - fantomas wrote
> On 10.12.19 17:36, leonyuuu wrote:
>>Sent the unfinished mail accidentally. The body of the mail now is updated
>>from the original one.
> 
> Don't do this.
> 
> This is not nabble, but the squid-users mailing list and I doubt people
> are
> wanting to look at nabble's webpage to see what you have edited.
> 
> -- 
> Matus UHLAR - fantomas, 

> uhlar@

>  ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> "One World. One Web. One Program." - Microsoft promotional advertisement
> "Ein Volk, ein Reich, ein Fuhrer!" - Adolf Hitler
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users

Thanks Matus for replying. I am new here and just forgot that this channel
was mainly for mailing-list usage at that time, pleaze forgive me for doing
that. 




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From uhlar at fantomas.sk  Thu Dec 12 08:54:16 2019
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 12 Dec 2019 09:54:16 +0100
Subject: [squid-users] Sibling peer cache not working, ver 3.5.27
In-Reply-To: <1576123472150-0.post@n4.nabble.com>
References: <1576020119899-0.post@n4.nabble.com>
 <1576039652095-0.post@n4.nabble.com>
 <7806aa57-3c09-d09d-0374-fab101140a18@treenet.co.nz>
 <1576123472150-0.post@n4.nabble.com>
Message-ID: <20191212085415.GB407@fantomas.sk>

On 11.12.19 22:04, leonyuuu wrote:
>Thanks Amos for quick response! It helps a lot in understanding the previous
>logs like "forward proxy port not configured", and I adjusted my
>configuration later today to do another test.
>
>However, now the two proxies even doesn't send ICP/HTTP request to each
>other anymore for cache digest and the access.log(see below) shows there are
>only queries on intercepted traffic.
>
><http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377850/access.png>
>
>My new configuration for proxy0:
>    http_port 3128
>    http_port 9999 intercept
>    icp_access allow all
>    icp_port 3130
>
>    cache_peer 192.168.3.2 sibling 3128 3130
>    cache_peer_access 192.168.3.2 allow all
>    visible_hostname squid.host.1
>
>Iptables configuration added for proxy0:
>    // for inter-proxy trafic
>    "iptables -t nat -A PREROUTING -i veth20 --dport 80 -j REDIRECT
>--to-port 3128"

you don't need to and should not redirect inter-proxy traffic from port 80
to 3128.
the sibling proxy explicitly sends HTTP traffic to port 3128.
better remove this rule.

>    // for intercepted traffic
>    "iptables -t nat -A PREROUTING -i veth12 --dport 80 -j REDIRECT
>--to-port 9999"
>
>With tcpdump(see below) listening on the interface that connects the other
>proxy, I can see there are established tcp connections between two proxies,
>is this traffic for netdb only? I am really wondering what could potentially
>prevent from the Cache Digest being exchanged between siblings.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
2B|!2B, that's a question!


From squid3 at treenet.co.nz  Thu Dec 12 09:42:55 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 Dec 2019 22:42:55 +1300
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <1576103939876-0.post@n4.nabble.com>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
 <724ee00d-44bb-a0df-aa3f-007d13b96970@measurement-factory.com>
 <1575914210679-0.post@n4.nabble.com>
 <ba63ebca-810a-59b7-b3f7-9d4fac8646db@measurement-factory.com>
 <1576033242405-0.post@n4.nabble.com>
 <e0fac586-eb44-d355-2a70-2c50c9d1ae31@treenet.co.nz>
 <1576103939876-0.post@n4.nabble.com>
Message-ID: <af437f57-a2e2-7809-e9c0-0274e6148f20@treenet.co.nz>

On 12/12/19 11:38 am, GeorgeShen wrote:
> 
> did a 'openssl dhparam -out dhparams.pem 4096' to generate the dhparams.pem
> file, and added those into the squid.conf:
> 
> http_port 3129 ssl-bump cert=/usr/local/squid/etc/ssl_cert/myCA.pem
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> *options=SINGLE_DH_USE:SINGLE_ECDH_USE
> tls-dh=/usr/local/squid/etc/dhparams.pem*
> 
> when the client software include the ciphersuites of the above mentioned,
> still fail the TLS negotiation. Do I configured this incorrectly?

What you have so far enables the DH ciphers and algorithms, but not yet
the curve parts. For that you need to add the curve name to tls-dh option.



Amos


From eype69 at gmail.com  Thu Dec 12 17:29:09 2019
From: eype69 at gmail.com (John)
Date: Thu, 12 Dec 2019 17:29:09 +0000
Subject: [squid-users] Resolved: Peek-and-splice not working when mixing
 TLS1.3 servers and TLS1.2 clients
In-Reply-To: <a0cb15df-648c-c0f6-f410-948176524683@ntcomputer.de>
References: <a84f26eb-0580-f134-4d36-bfa7b1a4d5ea@measurement-factory.com>
 <C0120FA3-A50E-4AB5-AE98-FD7874C073E7@gmail.com>
 <a0cb15df-648c-c0f6-f410-948176524683@ntcomputer.de>
Message-ID: <CAAOXCCcqCDgSxoxQrTVf60TGTsEbQUOci3EC_L=efp7RVV704g@mail.gmail.com>

Hi Nikolaus

I have taken your patch, applied it to squid
http://http.debian.net/debian/pool/main/s/squid/squid_4.9-2.dsc, built
it as a deb package and tested it.

In use I am getting many errors of the form:
2019/12/12 16:50:19 kid1| Error parsing SSL Server Hello Message on FD 15

Turning on debug, the relevant section of the log seems to be:
2019/12/12 16:50:16.711 kid1| 24,7| BinaryTokenizer.cc(65) got:
Handshake.msg_type=2 occupying 1 bytes @0 in 0x55cd92e91c18.
2019/12/12 16:50:16.711 kid1| 24,7| BinaryTokenizer.cc(65) got:
Handshake.msg_body.length=87 occupying 3 bytes @1 in 0x55cd92e91c18.
2019/12/12 16:50:16.711 kid1| 24,7| BinaryTokenizer.cc(74) got:
Handshake.msg_body.octets= occupying 87 bytes @4 in 0x55cd92e91c18.
2019/12/12 16:50:16.711 kid1| 24,7| BinaryTokenizer.cc(57) got:
Handshake occupying 91 bytes @0 in 0x55cd92e91c18.
2019/12/12 16:50:16.711 kid1| 0,3| Handshake.cc(324)
parseHandshakeMessage: check failed: state < atHelloReceived
    exception location: Handshake.cc(324) parseHandshakeMessage

2019/12/12 16:50:16.711 kid1| 83,2| bio.cc(318) readAndParse: parsing
error on FD 15: check failed: state < atHelloReceived
    exception location: Handshake.cc(324) parseHandshakeMessage

2019/12/12 16:50:16.711 kid1| 83,7| bio.cc(324) readAndParse: Hold
flag is set, retry latter. (Hold 5bytes)
2019/12/12 16:50:16.711 kid1| 83,7| bio.cc(166) stateChanged: FD 15
now: 0x1002 TWCH (SSLv3/TLS write client hello)
2019/12/12 16:50:16.711 kid1| 83,5| PeerConnector.cc(462)
noteWantRead: local=10.12.255.133:54576 remote=52.94.56.114:443 FD 15
flags=1
2019/12/12 16:50:16.711 kid1| Error parsing SSL Server Hello Message on FD 15

However... functionally, the patch does seem to be working, allowing
TLS 1.2 traffic from the client inside my network to connect to a TLS
1.3 server (www.google.com) when the site is in the whitelist and
terminating the connection when it is removed from the whitelist.

It is unclear to me if the "Error parsing SSL Server Hello Message"
are benign or not.

John

On Sat, 7 Dec 2019 at 13:54, Nikolaus <dc.sqml at ntcomputer.de> wrote:
>
> I was able to solve the issue, fixing both squid-side "error:1425F175:SSL routines:ssl_choose_client_version:inappropriate fallback (1/-1/0)" and client-side certificate verification errors when attempting to contact TLS 1.3 server over a TLS 1.3-enabled squid from a TLS 1.2 client. I will first explain what causes the issue before presenting my solution, which involves changes of the squid code base, for anybody who is affected by the same problem.
>
> I have inspected the squid source code and noticed that TLS peeking works roughly like this:
>
> 1. The client sends a client_hello, which is parsed by squid using a custom handshake parser.  <-- Uses TLS 1.2
> 2. Squid creates an OpenSSL TLS session for the peeked connection  <-- Uses TLS 1.3!
> 3. Squid forwards the original client_hello handshake message to the server <-- TLS 1.2
> 4. Squid passes the received server_hello response to the OpenSSL session created previously  <-- Response uses TLS 1.2 - Problem!
>
> Now, the "problem" is that TLS 1.3 defines a set of new protocol downgrade attack prevention mechanisms (can be found e.g. here: https://blog.gypsyengineer.com/en/security/how-does-tls-1-3-protect-against-downgrade-attacks.html). Both OpenSSL and most likely the server implement these. This includes that the server random in the TLS 1.2 server_hello contains an indicator that the server is TL 1.3-capable. The OpenSSL session created by squid detects this, notices that it is TLS 1.3-capable itself, and closes the connection because it assumes a protocol downgrade attack! Little does it know, that our client actually only supports TLS 1.2, so we *want* the lower protocol version.
>
> My solution includes setting the maximum TLS version of the OpenSSL session to the version received from the client. This proved a little bit difficult, since the way TLS versions are negotiated has also been changed by the TLS 1.3 specification, and the squid handshake parser was not yet able to detect TLS 1.3 correctly - I have therefore also implemented parsing of the SupportedVersions TLS Extension and a preliminary support for sparse version ranges. You can find all these changes at https://github.com/nthuemmel/squid/tree/tls_downgrade_compatibility , which is a fork of squid 4.9. Feel free to compile & test it if you have a transparent peek-and-splice setup and are affected by the "inappropriate fallback" problem.
>
> I would of course be glad if the fix could be merged into the main squid repository. If you are a dev, please let me know what you think and if I should open a pull request. There are still some TODOs left, because I wasn't sure what the best way is to integrate some of the changes. Notably, there was also a comment which discourages setting a maximum version for the OpenSSL session to improve peek+bump compatibility - I don't have a setup to which this applies, so I don't know how big of an impact this is or if it is still relevant.
>
> Best Regards
> Nikolaus
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From g2011828 at hotmail.com  Thu Dec 12 17:54:58 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Thu, 12 Dec 2019 11:54:58 -0600 (CST)
Subject: [squid-users] Squid Proxy SSL Bump can not retrieve SSL session
 back to the client?
In-Reply-To: <af437f57-a2e2-7809-e9c0-0274e6148f20@treenet.co.nz>
References: <BL0PR04MB497921EB414AD0DB6D3BA21E98590@BL0PR04MB4979.namprd04.prod.outlook.com>
 <724ee00d-44bb-a0df-aa3f-007d13b96970@measurement-factory.com>
 <1575914210679-0.post@n4.nabble.com>
 <ba63ebca-810a-59b7-b3f7-9d4fac8646db@measurement-factory.com>
 <1576033242405-0.post@n4.nabble.com>
 <e0fac586-eb44-d355-2a70-2c50c9d1ae31@treenet.co.nz>
 <1576103939876-0.post@n4.nabble.com>
 <af437f57-a2e2-7809-e9c0-0274e6148f20@treenet.co.nz>
Message-ID: <1576173298285-0.post@n4.nabble.com>

Right. that works now.

thanks.
- George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From tannmann at gmail.com  Thu Dec 12 17:56:16 2019
From: tannmann at gmail.com (tannmann)
Date: Thu, 12 Dec 2019 11:56:16 -0600 (CST)
Subject: [squid-users] Resolved: Peek-and-splice not working when mixing
 TLS1.3 servers and TLS1.2 clients
In-Reply-To: <CAAOXCCcqCDgSxoxQrTVf60TGTsEbQUOci3EC_L=efp7RVV704g@mail.gmail.com>
References: <71523daa-6521-118f-7a59-b47930e562e0@ntcomputer.de>
 <43742d32-1bf7-b194-2641-d29273588d4d@measurement-factory.com>
 <1b4aabc3-fe2d-fef1-e7ff-f55bc50a3c74@ntcomputer.de>
 <a84f26eb-0580-f134-4d36-bfa7b1a4d5ea@measurement-factory.com>
 <C0120FA3-A50E-4AB5-AE98-FD7874C073E7@gmail.com>
 <a0cb15df-648c-c0f6-f410-948176524683@ntcomputer.de>
 <CAAOXCCcqCDgSxoxQrTVf60TGTsEbQUOci3EC_L=efp7RVV704g@mail.gmail.com>
Message-ID: <1576173376982-0.post@n4.nabble.com>

I've also compiled from Nikolaus's branch and get the same results as John.
It appears to fix the issues with inappropriate fallback, but I get the same
"Error parsing SSL Server Hello Message on FD 15". 

Interestingly, I also get those errors when I compile from the branch
suggested by Alex at https://github.com/measurement-factory/squid/pull/60/. 
Building from this branch, or from Nikolaus's gives me the same results, no
more inappropriate fallback errors (yay!), but now those "Error parsing SSL
Server Hello Message on FD XX" errors. I haven't found any problems related
to these new errors, everything going through the proxy appears to work
fine.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From uhlar at fantomas.sk  Thu Dec 12 19:27:36 2019
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 12 Dec 2019 20:27:36 +0100
Subject: [squid-users] peek and splice with gnutls
Message-ID: <20191212192736.GA13408@fantomas.sk>

Hello,

are any of peek and splice (optionally stare) options available when squid
is compiled with gnutls?

Thanks

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
LSD will make your ECS screen display 16.7 million colors


From squid3 at treenet.co.nz  Fri Dec 13 05:47:34 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Dec 2019 18:47:34 +1300
Subject: [squid-users] peek and splice with gnutls
Message-ID: <mailman.7.1736411444.1101126.squid-users@lists.squid-cache.org>


On 13/12/2019 08:27, Matus UHLAR - fantomas wrote:


> Hello,
>
> are any of peek and splice (optionally stare) options available when squid
> is compiled with gnutls?

Unfortunately no. But to compensate we have made it so that if you compile using --with-openssl that will be the library used even if gnutls is auto-detected.

Amos

From leonyu365 at gmail.com  Fri Dec 13 08:15:05 2019
From: leonyu365 at gmail.com (leonyuuu)
Date: Fri, 13 Dec 2019 02:15:05 -0600 (CST)
Subject: [squid-users] Sibling peer cache not working, ver 3.5.27
In-Reply-To: <20191212085415.GB407@fantomas.sk>
References: <1576020119899-0.post@n4.nabble.com>
 <1576039652095-0.post@n4.nabble.com>
 <7806aa57-3c09-d09d-0374-fab101140a18@treenet.co.nz>
 <1576123472150-0.post@n4.nabble.com> <20191212085415.GB407@fantomas.sk>
Message-ID: <1576224905743-0.post@n4.nabble.com>

Matus UHLAR - fantomas wrote
> On 11.12.19 22:04, leonyuuu wrote:
>>Thanks Amos for quick response! It helps a lot in understanding the
previous
>>logs like "forward proxy port not configured", and I adjusted my
>>configuration later today to do another test.
>>
>>However, now the two proxies even doesn't send ICP/HTTP request to each
>>other anymore for cache digest and the access.log(see below) shows there
are
>>only queries on intercepted traffic.
>>
>>&lt;http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377850/access.png&gt;
>>
>>My new configuration for proxy0:
>>    http_port 3128
>>    http_port 9999 intercept
>>    icp_access allow all
>>    icp_port 3130
>>
>>    cache_peer 192.168.3.2 sibling 3128 3130
>>    cache_peer_access 192.168.3.2 allow all
>>    visible_hostname squid.host.1
>>
>>Iptables configuration added for proxy0:
>>    // for inter-proxy trafic
>>    "iptables -t nat -A PREROUTING -i veth20 --dport 80 -j REDIRECT
>>--to-port 3128"
> 
> you don't need to and should not redirect inter-proxy traffic from port 80
> to 3128.
> the sibling proxy explicitly sends HTTP traffic to port 3128.
> better remove this rule.

yes, the http request for digest is heading for 3128 by default. 

But now I become more confused why the Cache Digest is not working at all.
My checklist for enabling Cache Digest: 
1. build option with "enable-cache-digest"
2. cache_peer setting for both proxies, server port and ICP port
3. cache_peer_access allow http traffic
4. veth pair setup for both application 
5. route table configuration for inter-proxy traffic

Plz correct me if I miss anything. 



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From leonyu365 at gmail.com  Fri Dec 13 08:29:32 2019
From: leonyu365 at gmail.com (leonyuuu)
Date: Fri, 13 Dec 2019 02:29:32 -0600 (CST)
Subject: [squid-users] Sibling peer cache not working, ver 3.5.27
In-Reply-To: <1576224905743-0.post@n4.nabble.com>
References: <1576020119899-0.post@n4.nabble.com>
 <1576039652095-0.post@n4.nabble.com>
 <7806aa57-3c09-d09d-0374-fab101140a18@treenet.co.nz>
 <1576123472150-0.post@n4.nabble.com> <20191212085415.GB407@fantomas.sk>
 <1576224905743-0.post@n4.nabble.com>
Message-ID: <1576225772009-0.post@n4.nabble.com>

I investigated into some aspects of the cache-digest, and I found there are
some aspects that I may miss out when designing the experiment. 

Item 16.10 in following squidFAQ tells that the peers cache-digest is stored
on Disks. If the cache storage on disk is a "must" for cache-digest, then I
could have a problem in designing the experiment since I haven;t turned on
the disk_dir directive in configuration. 

http://www.comfsm.fm/computing/squid/FAQ-6.html




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From uhlar at fantomas.sk  Fri Dec 13 09:36:26 2019
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 13 Dec 2019 10:36:26 +0100
Subject: [squid-users] peek and splice with gnutls
In-Reply-To: <20191213054714.8891DE09CA@lists.squid-cache.org>
References: <20191213054714.8891DE09CA@lists.squid-cache.org>
Message-ID: <20191213093626.GA29532@fantomas.sk>

>On 13/12/2019 08:27, Matus UHLAR - fantomas wrote:
>> are any of peek and splice (optionally stare) options available when squid
>> is compiled with gnutls?

On 13.12.19 18:47, Amos Jeffries wrote:
>Unfortunately no.  But to compensate we have made it so that if you compile
> using --with-openssl that will be the library used even if gnutls is
> auto-detected.

yes, but this means that we need squid compiled with openssl and iirc
there's licensing issue with distributing it as such (iirc due to openssl
and gpl licensing incompatibility)

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
- Have you got anything without Spam in it?
- Well, there's Spam egg sausage and Spam, that's not got much Spam in it.


From squid3 at treenet.co.nz  Fri Dec 13 09:59:36 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Dec 2019 22:59:36 +1300
Subject: [squid-users] peek and splice with gnutls
In-Reply-To: <20191213093626.GA29532@fantomas.sk>
References: <20191213054714.8891DE09CA@lists.squid-cache.org>
 <20191213093626.GA29532@fantomas.sk>
Message-ID: <34debdd2-2d63-ba88-2c41-ecea4809ca9b@treenet.co.nz>

On 13/12/19 10:36 pm, Matus UHLAR - fantomas wrote:
>> On 13/12/2019 08:27, Matus UHLAR - fantomas wrote:
>>> are any of peek and splice (optionally stare) options available when
>>> squid
>>> is compiled with gnutls?
> 
> On 13.12.19 18:47, Amos Jeffries wrote:
>> Unfortunately no.? But to compensate we have made it so that if you
>> compile
>> using --with-openssl that will be the library used even if gnutls is
>> auto-detected.
> 
> yes, but this means that we need squid compiled with openssl and iirc
> there's licensing issue with distributing it as such (iirc due to openssl
> and gpl licensing incompatibility)
> 

Key word being "distribute". Anyone is clear to *use* a privately built
installation.

The license clash occurs when one is distributing *both* OpenSSL and
Squid binaries.

We have NGTech and Diladele happily distributing public builds of Squid
with OpenSSL support. They just have to avoid distributing OpenSSL -
which is not a problem for them AFAIK.

Amos


From rousskov at measurement-factory.com  Fri Dec 13 12:49:59 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 13 Dec 2019 07:49:59 -0500
Subject: [squid-users] peek and splice with gnutls
In-Reply-To: <34debdd2-2d63-ba88-2c41-ecea4809ca9b@treenet.co.nz>
References: <20191213054714.8891DE09CA@lists.squid-cache.org>
 <20191213093626.GA29532@fantomas.sk>
 <34debdd2-2d63-ba88-2c41-ecea4809ca9b@treenet.co.nz>
Message-ID: <172ff63a-b052-c225-ba42-7a2904a6bb85@measurement-factory.com>

On 12/13/19 4:59 AM, Amos Jeffries wrote:
> On 13/12/19 10:36 pm, Matus UHLAR - fantomas wrote:
>> this means that we need squid compiled with openssl and iirc
>> there's licensing issue with distributing it as such (iirc due to openssl
>> and gpl licensing incompatibility)

> Key word being "distribute". Anyone is clear to *use* a privately built
> installation.
> 
> The license clash occurs when one is distributing *both* OpenSSL and
> Squid binaries.

And even the very existence of that clash and its actual effects on the
parties involved are not well understood/established/agreed upon. This
is a gray legal area full of conflicting opinions and lacking solid
legal footing.

Alex.


From uhlar at fantomas.sk  Fri Dec 13 13:00:06 2019
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 13 Dec 2019 14:00:06 +0100
Subject: [squid-users] peek and splice with gnutls
In-Reply-To: <172ff63a-b052-c225-ba42-7a2904a6bb85@measurement-factory.com>
References: <20191213054714.8891DE09CA@lists.squid-cache.org>
 <20191213093626.GA29532@fantomas.sk>
 <34debdd2-2d63-ba88-2c41-ecea4809ca9b@treenet.co.nz>
 <172ff63a-b052-c225-ba42-7a2904a6bb85@measurement-factory.com>
Message-ID: <20191213130006.GB32736@fantomas.sk>

>> On 13/12/19 10:36 pm, Matus UHLAR - fantomas wrote:
>>> this means that we need squid compiled with openssl and iirc
>>> there's licensing issue with distributing it as such (iirc due to openssl
>>> and gpl licensing incompatibility)

>On 12/13/19 4:59 AM, Amos Jeffries wrote:
>> Key word being "distribute". Anyone is clear to *use* a privately built
>> installation.
>>
>> The license clash occurs when one is distributing *both* OpenSSL and
>> Squid binaries.

On 13.12.19 07:49, Alex Rousskov wrote:
>And even the very existence of that clash and its actual effects on the
>parties involved are not well understood/established/agreed upon. This
>is a gray legal area full of conflicting opinions and lacking solid
>legal footing.

That's the reason why Debian doesn't distribute squid with openssl support.
And I prefer to use distribution-provided packages. 
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Saving Private Ryan...
Private Ryan exists. Overwrite? (Y/N)


From robertkwild at gmail.com  Sat Dec 14 01:46:03 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Sat, 14 Dec 2019 01:46:03 +0000
Subject: [squid-users] cant download microsoft cert file
Message-ID: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>

hi all,

i have squid installed and its awesome i can whitelist and block mime types
but when im trying to activate my office 365 going through the proxy i get
a http denied on this

TCP_DENIED/403 3661 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt

but i have whitelisted the domain ".microsoft.com" so i really dont
understand why this is being denied as all the other domains i have
whitelisted are fone ie there not being denied

thanks,

rob
-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191214/444567c7/attachment.htm>

From uhlar at fantomas.sk  Sat Dec 14 08:38:54 2019
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sat, 14 Dec 2019 09:38:54 +0100
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
Message-ID: <20191214083854.GA26450@fantomas.sk>

On 14.12.19 01:46, robert k Wild wrote:
>i have squid installed and its awesome i can whitelist and block mime types
>but when im trying to activate my office 365 going through the proxy i get
>a http denied on this
>
>TCP_DENIED/403 3661 GET
>http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt
>
>but i have whitelisted the domain ".microsoft.com" so i really dont
>understand why this is being denied as all the other domains i have
>whitelisted are fone ie there not being denied

looks like you whitelisted incorrectly. Maybe showing the http_access lines
with related acls could help us to find the issue...

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Save the whales. Collect the whole set.


From robertkwild at gmail.com  Sat Dec 14 15:21:15 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Sat, 14 Dec 2019 15:21:15 +0000
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <20191214083854.GA26450@fantomas.sk>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
 <20191214083854.GA26450@fantomas.sk>
Message-ID: <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>

so this is my config file -

#
# Recommended minimum configuration:
#

#SSL
http_port 3128 ssl-bump \
cert=/usr/local/squid/etc/ssl_cert/myCA.pem \
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
/var/lib/ssl_db -M 4MB
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 0.0.0.1-0.255.255.255 # RFC 1122 "this" network (LAN)
acl localnet src 10.0.0.0/8   # RFC 1918 local private network (LAN)
acl localnet src 100.64.0.0/10   # RFC 6598 shared address space (CGN)
acl localnet src 169.254.0.0/16   # RFC 3927 link-local (directly plugged)
machines
acl localnet src 172.16.0.0/12   # RFC 1918 local private network (LAN)
acl localnet src 192.168.0.0/16   # RFC 1918 local private network (LAN)
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10       # RFC 4291 link-local (directly plugged)
machines

acl SSL_ports port 443
acl Safe_ports port 80   # http
acl Safe_ports port 21   # ftp
acl Safe_ports port 443   # https
acl Safe_ports port 70   # gopher
acl Safe_ports port 210   # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280   # http-mgmt
acl Safe_ports port 488   # gss-http
acl Safe_ports port 591   # filemaker
acl Safe_ports port 777   # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# Squid normally listens to port 3128
http_port 3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /usr/local/squid/var/cache/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /usr/local/squid/var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:   1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern .   0 20% 4320

as you can see i have removed the whitelist/mime config lines

but when i come into activating office it just cant get online to do it via
the client app installed on my pc

but internet isnt blocked as i can go to any website

On Sat, 14 Dec 2019 at 08:39, Matus UHLAR - fantomas <uhlar at fantomas.sk>
wrote:

> On 14.12.19 01:46, robert k Wild wrote:
> >i have squid installed and its awesome i can whitelist and block mime
> types
> >but when im trying to activate my office 365 going through the proxy i get
> >a http denied on this
> >
> >TCP_DENIED/403 3661 GET
> >http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt
> >
> >but i have whitelisted the domain ".microsoft.com" so i really dont
> >understand why this is being denied as all the other domains i have
> >whitelisted are fone ie there not being denied
>
> looks like you whitelisted incorrectly. Maybe showing the http_access lines
> with related acls could help us to find the issue...
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> Save the whales. Collect the whole set.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191214/ce5998b5/attachment.htm>

From squid3 at treenet.co.nz  Sat Dec 14 22:35:18 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 15 Dec 2019 11:35:18 +1300
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
 <20191214083854.GA26450@fantomas.sk>
 <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>
Message-ID: <744b7a54-6697-68aa-6e04-dc51fb9f4ce6@treenet.co.nz>

On 15/12/19 4:21 am, robert k Wild wrote:
> so this is my config file -
> 
> #
> # Recommended minimum configuration:
> #
> 
> #SSL
> http_port 3128 ssl-bump \
> cert=/usr/local/squid/etc/ssl_cert/myCA.pem \
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

> sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
> /var/lib/ssl_db -M 4MB

> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump bump all
> 

(elided default localnet and port ACL definitions)

> 
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> 
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
> 
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
> 
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #

  ^^^ HINT.

> 
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
> 
> # Squid normally listens to port 3128
> http_port 3128
> 

This is the second port 3128 config, and it does not match the earlier one.


> 
> as you can see i have removed the whitelist/mime config lines
> 
> but when i come into activating office it just cant get online to do it
> via the client app installed on my pc

If that is still happening with this default config I would be starting
to suspect things outside of Squid. Like firewall or routing rules, the
client app not supporting proxies properly - stuff like that.

Though 403 in the proxy log does indicate an explicitly forbidden
action. The way you truncated the log line cut away most of the useful
info that points at where to focus the troubleshooting efforts.


> 
> but internet isnt blocked as i can go to any website
> 

Do you want it to work with the whitelisting ACL you mentioned?

If yes, then you do need to show at least the http_access directives
using it and the exact entry you added for the microsoft.com domain(s).

Same for the "mime" config lines you mention, but for those any part of
it could be relevant so we will need to see the whole of that stuff.


You have omitted the default "http_access deny all" which should be the
last http_access line in your config. Not a problem in the config as
shown, but if you have other rules they can change the implicit default
into a bad situation very easily.



Amos


From robertkwild at gmail.com  Sun Dec 15 00:16:34 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Sun, 15 Dec 2019 00:16:34 +0000
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <744b7a54-6697-68aa-6e04-dc51fb9f4ce6@treenet.co.nz>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
 <20191214083854.GA26450@fantomas.sk>
 <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>
 <744b7a54-6697-68aa-6e04-dc51fb9f4ce6@treenet.co.nz>
Message-ID: <CAGU_CiKUxoL-60CKTM2q8pojWDncKtVzNWkNLS+LVe229jyOqQ@mail.gmail.com>

hi Amos,

thank you for getting back to me about this :)

this is my new config

#
#SSL
http_port 3128 ssl-bump \
cert=/usr/local/squid/etc/ssl_cert/myCA.pem \
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
/var/lib/ssl_db -M 4MB
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all

#Windows Updates
acl windowsupdate dstdomain "/usr/local/squid/etc/wu.txt"
acl CONNECT method CONNECT
acl wuCONNECT dstdomain "/usr/local/squid/etc/wu.txt"
http_access allow CONNECT wuCONNECT
http_access allow windowsupdate

#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 0.0.0.1-0.255.255.255 # RFC 1122 "this" network (LAN)
acl localnet src 10.0.0.0/8 # RFC 1918 local private network (LAN)
acl localnet src 100.64.0.0/10 # RFC 6598 shared address space (CGN)
acl localnet src 169.254.0.0/16 # RFC 3927 link-local (directly plugged)
machines
acl localnet src 172.16.0.0/12 # RFC 1918 local private network (LAN)
acl localnet src 192.168.0.0/16 # RFC 1918 local private network (LAN)
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10       # RFC 4291 link-local (directly plugged)
machines

acl SSL_ports port 443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /usr/local/squid/var/cache/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /usr/local/squid/var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320

the reason why i have added the windows update lines at the beginning is
that the link says so (below)

https://linuxnlenux.wordpress.com/2014/10/14/howto-allow-windows-updates-through-squid/

this is my domain list

#Microsoft
.bing.com
.msn.com
.msedge.net
.msftauth.net
.msauth.net
.msocdn.com
.outlook.com
.onedrive.com
.office.net
.office.com
.office365.com
.microsoft.com
.microsoftonline.com
.c.s-microsoft.com
.live.com
.live.net
.akamaized.net
.akamaihd.net
.svc.ms
.lync.com
.skype.com
.gfx.ms
.sharepoint.com
.sharepointonline.com
.windowsupdate.com
.windows.net
.edgesuite.net
.a-msedge.net
.akamaiedge.net
.sfx.ms
.azureedge.net
.trafficmanager.net
.azure.com
#Google
.google.com
.google.co.uk
.googleusercontent.com
.googleapis.com
.withgoogle.com
.gstatic.com
#Adobe
.adobedtm.com
.adobe.io
.adobe.com
.adobelogin.com

and when im looking at the logs real time

1576368417.620     48 10.100.1.5 NONE/200 0 CONNECT
fe3cr.delivery.mp.microsoft.com:443 - HIER_DIRECT/191.232.139.2 -
1576368417.647      0 10.100.1.5 NONE/503 4363 POST
https://fe3cr.delivery.mp.microsoft.com/ClientWebService/client.asmx -
HIER_NONE/- text/html
1576368419.702      0 - TCP_MEM_HIT/200 807 GET
http://www.microsoft.com/pkiops/certs/Microsoft%20ECC%20Product%20Root%20Certificate%20Authority%202018.crt
- HIER_NONE/- application/octet-st
ream

squid works fine just as you said on certain apps/programs, so im really
struggling on this one

thanks,
rob

On Sat, 14 Dec 2019 at 22:35, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 15/12/19 4:21 am, robert k Wild wrote:
> > so this is my config file -
> >
> > #
> > # Recommended minimum configuration:
> > #
> >
> > #SSL
> > http_port 3128 ssl-bump \
> > cert=/usr/local/squid/etc/ssl_cert/myCA.pem \
> > generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>
> > sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
> > /var/lib/ssl_db -M 4MB
>
> > acl step1 at_step SslBump1
> > ssl_bump peek step1
> > ssl_bump bump all
> >
>
> (elided default localnet and port ACL definitions)
>
> >
> > #
> > # Recommended minimum Access Permission configuration:
> > #
> > # Deny requests to certain unsafe ports
> > http_access deny !Safe_ports
> >
> > # Deny CONNECT to other than secure SSL ports
> > http_access deny CONNECT !SSL_ports
> >
> > # Only allow cachemgr access from localhost
> > http_access allow localhost manager
> > http_access deny manager
> >
> > # We strongly recommend the following be uncommented to protect innocent
> > # web applications running on the proxy server who think the only
> > # one who can access services on "localhost" is a local user
> > #http_access deny to_localhost
> >
> > #
> > # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> > #
>
>   ^^^ HINT.
>
> >
> > # Example rule allowing access from your local networks.
> > # Adapt localnet in the ACL section to list your (internal) IP networks
> > # from where browsing should be allowed
> > http_access allow localnet
> > http_access allow localhost
> >
> > # Squid normally listens to port 3128
> > http_port 3128
> >
>
> This is the second port 3128 config, and it does not match the earlier one.
>
>
> >
> > as you can see i have removed the whitelist/mime config lines
> >
> > but when i come into activating office it just cant get online to do it
> > via the client app installed on my pc
>
> If that is still happening with this default config I would be starting
> to suspect things outside of Squid. Like firewall or routing rules, the
> client app not supporting proxies properly - stuff like that.
>
> Though 403 in the proxy log does indicate an explicitly forbidden
> action. The way you truncated the log line cut away most of the useful
> info that points at where to focus the troubleshooting efforts.
>
>
> >
> > but internet isnt blocked as i can go to any website
> >
>
> Do you want it to work with the whitelisting ACL you mentioned?
>
> If yes, then you do need to show at least the http_access directives
> using it and the exact entry you added for the microsoft.com domain(s).
>
> Same for the "mime" config lines you mention, but for those any part of
> it could be relevant so we will need to see the whole of that stuff.
>
>
> You have omitted the default "http_access deny all" which should be the
> last http_access line in your config. Not a problem in the config as
> shown, but if you have other rules they can change the implicit default
> into a bad situation very easily.
>
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191215/6f213991/attachment.htm>

From guy20034u at yahoo.com  Sun Dec 15 05:21:46 2019
From: guy20034u at yahoo.com (simon ben)
Date: Sun, 15 Dec 2019 05:21:46 +0000 (UTC)
Subject: [squid-users] one site not working
In-Reply-To: <120830004.7476790.1575994687741@mail.yahoo.com>
References: <2018052354.7139044.1575910345037.ref@mail.yahoo.com>
 <2018052354.7139044.1575910345037@mail.yahoo.com>
 <e3dd4985-7608-5358-6010-41051484ff19@treenet.co.nz>
 <120830004.7476790.1575994687741@mail.yahoo.com>
Message-ID: <56111984.8994758.1576387306374@mail.yahoo.com>

 Dear Amos,
I have upgraded to squid as below
[root at linproxy software]# squid -vSquid Cache: Version 4.6Service Name: squid
but the site www.esri.comis still not working ..?
just says page cannot be displayed
the access.log show the below----------------------------------
576385816.111? ? 189 172.16.2.175 TCP_REFRESH_MODIFIED/301 377 GET http://www.esri.com/ - HIER_DIRECT/23.37.177.22 -1576385816.112? 15875 172.16.2.175 TCP_TUNNEL/200 5547 CONNECT outlook.office365.com:443 - HIER_DIRECT/40.101.137.50 -1576385816.157? ? ?42 172.16.2.175 TCP_TUNNEL/200 46 CONNECT www.esri.com:443 - HIER_DIRECT/23.37.177.22 -1576385816.203? ? ?42 172.16.2.175 TCP_TUNNEL/200 46 CONNECT www.esri.com:443 - HIER_DIRECT/23.37.177.22 -1576385816.249? ? ?43 172.16.2.175 TCP_TUNNEL/200 46 CONNECT www.esri.com:443 - HIER_DIRECT/23.37.177.22 -1576385816.274? ? ?21 172.16.2.175 TCP_TUNNEL/200 39 CONNECT www.esri.com:443 - HIER_DIRECT/23.37.177.22 -----------------------------------
but hotmail and other sites working fine
anyway I can try to debug more to find the issue
apprecite your help and advice

    On Tuesday, December 10, 2019, 07:18:07 PM GMT+3, simon ben <guy20034u at yahoo.com> wrote:  
 
  Dear Amos,
Thanks for the quick reply.
Yes its an old version as I use to install using yum.I will upgrade as you said and check it out
thanks once again
Regards
simon

    On Tuesday, December 10, 2019, 10:57:47 AM GMT+3, Amos Jeffries <squid3 at treenet.co.nz> wrote:  
 
 On 10/12/19 5:52 am, simon ben wrote:
> Dear All,
> 
> ?
> 
> I am using Squid version 3.5.2 on Centos ?7 64 bit and its working fine
> with no issue but recently got a complain from one user saying that the
> below site Is not opening..? just says page cannot be displayed
> 

That would be one issue. Likely many others you are just not noticing.

Please upgrade. v3.5.2 is over 5 years old and obsolete. Current Squid
release is v4.9.


?
> 
> 1575869460.673?? 6034 172.16.2.175 TCP_TUNNEL/200 0 CONNECT
> my.esri.com:443 <http://my.esri.com:443> - HIER_DIRECT/34.210.189.55
> <http://34.210.189.55> -
> 
> 1575869461.235??? 559 172.16.2.175 TCP_TUNNEL/200 0 CONNECT
> my.esri.com:443 <http://my.esri.com:443> - HIER_DIRECT/34.210.189.55
> <http://34.210.189.55> -
> 
> 1575869461.801??? 562 172.16.2.175 TCP_TUNNEL/200 0 CONNECT
> my.esri.com:443 <http://my.esri.com:443> - HIER_DIRECT/34.210.189.55
> <http://34.210.189.55> -
> 
> 1575869462.096??? 291 172.16.2.175 TCP_TUNNEL/200 0 CONNECT
> my.esri.com:443 <http://my.esri.com:443> - HIER_DIRECT/34.210.189.55
> <http://34.210.189.55> ?
> 
> ?
> 
> ?
> 
> I tried to google around and found that the the ip4 prefrence has to
> enabled for DNS so I did the below in squid config
> 

No it does not. Your proxy is already connecting the tunnel to that
sites IPv4 address.


Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
    
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191215/7d6c8141/attachment.htm>

From squid3 at treenet.co.nz  Sun Dec 15 09:48:24 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 15 Dec 2019 22:48:24 +1300
Subject: [squid-users] one site not working
In-Reply-To: <56111984.8994758.1576387306374@mail.yahoo.com>
References: <2018052354.7139044.1575910345037.ref@mail.yahoo.com>
 <2018052354.7139044.1575910345037@mail.yahoo.com>
 <e3dd4985-7608-5358-6010-41051484ff19@treenet.co.nz>
 <120830004.7476790.1575994687741@mail.yahoo.com>
 <56111984.8994758.1576387306374@mail.yahoo.com>
Message-ID: <6907bcd5-211c-a6fa-63b8-0a3d8b2b0b27@treenet.co.nz>

On 15/12/19 6:21 pm, simon ben wrote:
> Dear Amos,
> 
> I have upgraded to squid as below
> 
> [root at linproxy software]# squid -v
> Squid Cache: Version 4.6
> Service Name: squid
> 
> but the site www.esri.com
> is still not working ..?
> just says page cannot be displayed
> 
> the access.log show the below
> ----------------------------------
> 
> 576385816.111? ? 189 172.16.2.175 TCP_REFRESH_MODIFIED/301 377 GET
> http://www.esri.com/ - HIER_DIRECT/23.37.177.22 -
> 1576385816.112? 15875 172.16.2.175 TCP_TUNNEL/200 5547 CONNECT
> outlook.office365.com:443 - HIER_DIRECT/40.101.137.50 -
> 1576385816.157? ? ?42 172.16.2.175 TCP_TUNNEL/200 46 CONNECT
> www.esri.com:443 - HIER_DIRECT/23.37.177.22 -
> 1576385816.203? ? ?42 172.16.2.175 TCP_TUNNEL/200 46 CONNECT
> www.esri.com:443 - HIER_DIRECT/23.37.177.22 -
> 1576385816.249? ? ?43 172.16.2.175 TCP_TUNNEL/200 46 CONNECT
> www.esri.com:443 - HIER_DIRECT/23.37.177.22 -
> 1576385816.274? ? ?21 172.16.2.175 TCP_TUNNEL/200 39 CONNECT
> www.esri.com:443 - HIER_DIRECT/23.37.177.22 -
> ----------------------------------
> 
> but hotmail and other sites working fine
> 
> anyway I can try to debug more to find the issue
> 
> apprecite your help and advice
> 

Its all working okay as far as Squid. The tunnels have status 200, but
either client or server are closing them pretty quickly after only a few
dozen bytes transferred.

Amos


From squid3 at treenet.co.nz  Sun Dec 15 10:40:29 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 15 Dec 2019 23:40:29 +1300
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <CAGU_CiKUxoL-60CKTM2q8pojWDncKtVzNWkNLS+LVe229jyOqQ@mail.gmail.com>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
 <20191214083854.GA26450@fantomas.sk>
 <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>
 <744b7a54-6697-68aa-6e04-dc51fb9f4ce6@treenet.co.nz>
 <CAGU_CiKUxoL-60CKTM2q8pojWDncKtVzNWkNLS+LVe229jyOqQ@mail.gmail.com>
Message-ID: <d812f44c-959b-7778-5861-0bcee625b9bf@treenet.co.nz>

On 15/12/19 1:16 pm, robert k Wild wrote:
> hi Amos,
> 
> thank you for getting back to me about this :)
> 
> this is my new config
> 
> #
> #SSL
> http_port 3128 ssl-bump \
> cert=/usr/local/squid/etc/ssl_cert/myCA.pem \
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
> /var/lib/ssl_db -M 4MB
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump bump all
> 
> #Windows Updates
> acl windowsupdate dstdomain "/usr/local/squid/etc/wu.txt"
> acl CONNECT method CONNECT
> acl wuCONNECT dstdomain "/usr/local/squid/etc/wu.txt"
> http_access allow CONNECT wuCONNECT
> http_access allow windowsupdate
> 
...
> 
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> 
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
> 
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
> 
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
> 
...

> 
> the reason why i have added the windows update lines at the beginning is
> that the link says so (below)
> 
> https://linuxnlenux.wordpress.com/2014/10/14/howto-allow-windows-updates-through-squid/
> 

That is a copy-n-paste of an old email without any of the context. See
<https://wiki.squid-cache.org/SquidFaq/WindowsUpdate> for the full
context and more up to date info.

Note that the things that need to be first are very specifically a
sub-set of the MS domains which use a non-443 port for call-home traffic
so they would normally get blocked by the SSL_ports protection.


For a generic whitelist you should still have your list where the config
says "INSERT YOUR OWN RULES ..." .


> 
> and when im looking at the logs real time
> 
> 1576368417.620 ? ? 48 10.100.1.5 NONE/200 0 CONNECT
> fe3cr.delivery.mp.microsoft.com:443
> <http://fe3cr.delivery.mp.microsoft.com:443> - HIER_DIRECT/191.232.139.2
> <http://191.232.139.2> -
> 1576368417.647 ? ? ?0 10.100.1.5 NONE/503 4363 POST
> https://fe3cr.delivery.mp.microsoft.com/ClientWebService/client.asmx -
> HIER_NONE/- text/html
> 1576368419.702 ? ? ?0 - TCP_MEM_HIT/200 807 GET
> http://www.microsoft.com/pkiops/certs/Microsoft%20ECC%20Product%20Root%20Certificate%20Authority%202018.crt
> - HIER_NONE/- application/octet-st
> ream
> 

These show good progress from where you started off. The cert is being
downloaded fine. The tunnel being bumped fine. But the POST request
which was decrypted could not be serviced.

Can you find out what the 503 message says?


Amos


From robertkwild at gmail.com  Sun Dec 15 16:24:27 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Sun, 15 Dec 2019 16:24:27 +0000
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <d812f44c-959b-7778-5861-0bcee625b9bf@treenet.co.nz>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
 <20191214083854.GA26450@fantomas.sk>
 <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>
 <744b7a54-6697-68aa-6e04-dc51fb9f4ce6@treenet.co.nz>
 <CAGU_CiKUxoL-60CKTM2q8pojWDncKtVzNWkNLS+LVe229jyOqQ@mail.gmail.com>
 <d812f44c-959b-7778-5861-0bcee625b9bf@treenet.co.nz>
Message-ID: <CAGU_CiL7_DtYB5WV3c7YHKMKp1ixEGdxa8K3RYQ5=UF9FD30JQ@mail.gmail.com>

hi Amos,

so this is my new config -

#
# Recommended minimum configuration:
#

#SSL
http_port 3128 ssl-bump \
cert=/usr/local/squid/ssl_cert/myCA.pem \
cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS \
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
/var/lib/ssl_db -M 4MB
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 0.0.0.1-0.255.255.255 # RFC 1122 "this" network (LAN)
acl localnet src 10.0.0.0/8 # RFC 1918 local private network (LAN)
acl localnet src 100.64.0.0/10 # RFC 6598 shared address space (CGN)
acl localnet src 169.254.0.0/16 # RFC 3927 link-local (directly plugged)
machines
acl localnet src 172.16.0.0/12 # RFC 1918 local private network (LAN)
acl localnet src 192.168.0.0/16 # RFC 1918 local private network (LAN)
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10       # RFC 4291 link-local (directly plugged)
machines

acl SSL_ports port 443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
#Windows Update
acl windowsupdate dstdomain .microsoft.com .windows.com .windowsupdate.com .
windows.net
acl CONNECT method CONNECT
acl wuCONNECT dstdomain .microsoft.com .windows.com .windowsupdate.com .
windows.net
http_access allow CONNECT wuCONNECT
http_access allow windowsupdate

acl DiscoverSNIHost at_step SslBump1
acl NoSSLIntercept ssl::server_name_regex -i .microsoft.com .windows.com .
windowsupdate.com .windows.net
ssl_bump splice NoSSLIntercept
ssl_bump peek DiscoverSNIHost
ssl_bump bump all

acl BrokenButTrustedServers dstdomain .microsoft.com .windows.com .
windowsupdate.com .windows.net
acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
sslproxy_cert_error deny all

#HTTP_HTTPS whitelist websites
acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
http_access allow whitelist

#URL deny MIME types
acl mimetype rep_mime_type "/usr/local/squid/etc/mimedeny.txt"
http_reply_access deny mimetype
http_access deny all

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /usr/local/squid/var/cache/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /usr/local/squid/var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320

but im still getting the exact same logs

error 503 means

503

Service Unavailable

1945 <http://tools.ietf.org/rfc/rfc1945>, 2616
<http://tools.ietf.org/rfc/rfc2616>
thanks,
rob

On Sun, 15 Dec 2019 at 10:40, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 15/12/19 1:16 pm, robert k Wild wrote:
> > hi Amos,
> >
> > thank you for getting back to me about this :)
> >
> > this is my new config
> >
> > #
> > #SSL
> > http_port 3128 ssl-bump \
> > cert=/usr/local/squid/etc/ssl_cert/myCA.pem \
> > generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> > sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
> > /var/lib/ssl_db -M 4MB
> > acl step1 at_step SslBump1
> > ssl_bump peek step1
> > ssl_bump bump all
> >
> > #Windows Updates
> > acl windowsupdate dstdomain "/usr/local/squid/etc/wu.txt"
> > acl CONNECT method CONNECT
> > acl wuCONNECT dstdomain "/usr/local/squid/etc/wu.txt"
> > http_access allow CONNECT wuCONNECT
> > http_access allow windowsupdate
> >
> ...
> >
> > #
> > # Recommended minimum Access Permission configuration:
> > #
> > # Deny requests to certain unsafe ports
> > http_access deny !Safe_ports
> >
> > # Deny CONNECT to other than secure SSL ports
> > http_access deny CONNECT !SSL_ports
> >
> > # Only allow cachemgr access from localhost
> > http_access allow localhost manager
> > http_access deny manager
> >
> > # We strongly recommend the following be uncommented to protect innocent
> > # web applications running on the proxy server who think the only
> > # one who can access services on "localhost" is a local user
> > #http_access deny to_localhost
> >
> > #
> > # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> > #
> >
> > # Example rule allowing access from your local networks.
> > # Adapt localnet in the ACL section to list your (internal) IP networks
> > # from where browsing should be allowed
> > http_access allow localnet
> > http_access allow localhost
> >
> ...
>
> >
> > the reason why i have added the windows update lines at the beginning is
> > that the link says so (below)
> >
> >
> https://linuxnlenux.wordpress.com/2014/10/14/howto-allow-windows-updates-through-squid/
> >
>
> That is a copy-n-paste of an old email without any of the context. See
> <https://wiki.squid-cache.org/SquidFaq/WindowsUpdate> for the full
> context and more up to date info.
>
> Note that the things that need to be first are very specifically a
> sub-set of the MS domains which use a non-443 port for call-home traffic
> so they would normally get blocked by the SSL_ports protection.
>
>
> For a generic whitelist you should still have your list where the config
> says "INSERT YOUR OWN RULES ..." .
>
>
> >
> > and when im looking at the logs real time
> >
> > 1576368417.620     48 10.100.1.5 NONE/200 0 CONNECT
> > fe3cr.delivery.mp.microsoft.com:443
> > <http://fe3cr.delivery.mp.microsoft.com:443> - HIER_DIRECT/191.232.139.2
> > <http://191.232.139.2> -
> > 1576368417.647      0 10.100.1.5 NONE/503 4363 POST
> > https://fe3cr.delivery.mp.microsoft.com/ClientWebService/client.asmx -
> > HIER_NONE/- text/html
> > 1576368419.702      0 - TCP_MEM_HIT/200 807 GET
> >
> http://www.microsoft.com/pkiops/certs/Microsoft%20ECC%20Product%20Root%20Certificate%20Authority%202018.crt
> > - HIER_NONE/- application/octet-st
> > ream
> >
>
> These show good progress from where you started off. The cert is being
> downloaded fine. The tunnel being bumped fine. But the POST request
> which was decrypted could not be serviced.
>
> Can you find out what the 503 message says?
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191215/52926feb/attachment.htm>

From uhlar at fantomas.sk  Sun Dec 15 17:55:27 2019
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sun, 15 Dec 2019 18:55:27 +0100
Subject: [squid-users] squid SNMP OIDs
Message-ID: <20191215175527.GA728@fantomas.sk>

Hello,

I monitor squid using cacti and SNMP.

it seems that the OIDs:

*.1.3.2.1.10.0 cacheServerRequests Integer32 2.0+ All requests from the client for the cache server
*.1.3.2.1.11.0 cacheServerErrors Integer32 2.0+ All errors for the cache server from client requests

are integer32 but according to graphs they look more like counters
(they are increasing over time).

can someone help me with explaining this?
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
WinError #98652: Operation completed successfully.


From robertkwild at gmail.com  Sun Dec 15 21:26:08 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Sun, 15 Dec 2019 21:26:08 +0000
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <CAGU_CiL7_DtYB5WV3c7YHKMKp1ixEGdxa8K3RYQ5=UF9FD30JQ@mail.gmail.com>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
 <20191214083854.GA26450@fantomas.sk>
 <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>
 <744b7a54-6697-68aa-6e04-dc51fb9f4ce6@treenet.co.nz>
 <CAGU_CiKUxoL-60CKTM2q8pojWDncKtVzNWkNLS+LVe229jyOqQ@mail.gmail.com>
 <d812f44c-959b-7778-5861-0bcee625b9bf@treenet.co.nz>
 <CAGU_CiL7_DtYB5WV3c7YHKMKp1ixEGdxa8K3RYQ5=UF9FD30JQ@mail.gmail.com>
Message-ID: <CAGU_CiL_SfAA8jz=eX_UJQA7tV5YpFxYU9m-=S8_x3e9zxJzyA@mail.gmail.com>

i have done it

i can now whitelist urls, block mime types and now i can download/install
windows updates

#
#
#Windows Update Download
acl windowsupdate dstdomain .microsoft.com .windows.com .windowsupdate.com
acl CONNECT method CONNECT
acl wuCONNECT dstdomain .microsoft.com .windows.com .windowsupdate.com
http_access allow CONNECT wuCONNECT
http_access allow windowsupdate

range_offset_limit 200 MB windowsupdate
maximum_object_size 200 MB
quick_abort_min -1

refresh_pattern -i .
microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
reload-into-ims
refresh_pattern -i .
windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
reload-into-ims
refresh_pattern -i .
windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
43200 reload-into-ims

acl DiscoverSNIHost at_step SslBump1
acl NoSSLIntercept ssl::server_name_regex -i .microsoft.com .windows.com .
windowsupdate.com
ssl_bump splice NoSSLIntercept
ssl_bump peek DiscoverSNIHost
ssl_bump bump all

acl BrokenButTrustedServers dstdomain .microsoft.com .windows.com .
windowsupdate.com
acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
sslproxy_cert_error deny all
#
#SSL
http_port 3128 ssl-bump \
cert=/usr/local/squid/etc/ssl_cert/myCA.pem \
cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS \
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
/var/lib/ssl_db -M 4MB
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all

#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 0.0.0.1-0.255.255.255 # RFC 1122 "this" network (LAN)
acl localnet src 10.0.0.0/8 # RFC 1918 local private network (LAN)
acl localnet src 100.64.0.0/10 # RFC 6598 shared address space (CGN)
acl localnet src 169.254.0.0/16 # RFC 3927 link-local (directly plugged)
machines
acl localnet src 172.16.0.0/12 # RFC 1918 local private network (LAN)
acl localnet src 192.168.0.0/16 # RFC 1918 local private network (LAN)
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10       # RFC 4291 link-local (directly plugged)
machines

acl SSL_ports port 443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
#HTTP_HTTPS whitelist websites
acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
http_access allow whitelist

#URL deny MIME types
acl mimetype rep_mime_type "/usr/local/squid/etc/mimedeny.txt"
http_reply_access deny mimetype
http_access deny all

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /usr/local/squid/var/cache/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /usr/local/squid/var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320

Amos, do you think i could make the windows update section a bit smaller or
do i need all the lines in there?

many thanks,
rob

On Sun, 15 Dec 2019 at 16:24, robert k Wild <robertkwild at gmail.com> wrote:

> hi Amos,
>
> so this is my new config -
>
> #
> # Recommended minimum configuration:
> #
>
> #SSL
> http_port 3128 ssl-bump \
> cert=/usr/local/squid/ssl_cert/myCA.pem \
> cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS \
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
> /var/lib/ssl_db -M 4MB
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump bump all
>
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 0.0.0.1-0.255.255.255 # RFC 1122 "this" network (LAN)
> acl localnet src 10.0.0.0/8 # RFC 1918 local private network (LAN)
> acl localnet src 100.64.0.0/10 # RFC 6598 shared address space (CGN)
> acl localnet src 169.254.0.0/16 # RFC 3927 link-local (directly plugged)
> machines
> acl localnet src 172.16.0.0/12 # RFC 1918 local private network (LAN)
> acl localnet src 192.168.0.0/16 # RFC 1918 local private network (LAN)
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10       # RFC 4291 link-local (directly plugged)
> machines
>
> acl SSL_ports port 443
> acl Safe_ports port 80 # http
> acl Safe_ports port 21 # ftp
> acl Safe_ports port 443 # https
> acl Safe_ports port 70 # gopher
> acl Safe_ports port 210 # wais
> acl Safe_ports port 1025-65535 # unregistered ports
> acl Safe_ports port 280 # http-mgmt
> acl Safe_ports port 488 # gss-http
> acl Safe_ports port 591 # filemaker
> acl Safe_ports port 777 # multiling http
> acl CONNECT method CONNECT
>
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
>
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
>
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
>
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> #Windows Update
> acl windowsupdate dstdomain .microsoft.com .windows.com .windowsupdate.com
> .windows.net
> acl CONNECT method CONNECT
> acl wuCONNECT dstdomain .microsoft.com .windows.com .windowsupdate.com .
> windows.net
> http_access allow CONNECT wuCONNECT
> http_access allow windowsupdate
>
> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLIntercept ssl::server_name_regex -i .microsoft.com .windows.com .
> windowsupdate.com .windows.net
> ssl_bump splice NoSSLIntercept
> ssl_bump peek DiscoverSNIHost
> ssl_bump bump all
>
> acl BrokenButTrustedServers dstdomain .microsoft.com .windows.com .
> windowsupdate.com .windows.net
> acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
> sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
> sslproxy_cert_error deny all
>
> #HTTP_HTTPS whitelist websites
> acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
> http_access allow whitelist
>
> #URL deny MIME types
> acl mimetype rep_mime_type "/usr/local/squid/etc/mimedeny.txt"
> http_reply_access deny mimetype
> http_access deny all
>
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
>
> # Uncomment and adjust the following to add a disk cache directory.
> #cache_dir ufs /usr/local/squid/var/cache/squid 100 16 256
>
> # Leave coredumps in the first cache dir
> coredump_dir /usr/local/squid/var/cache/squid
>
> #
> # Add any of your own refresh_pattern entries above these.
> #
> refresh_pattern ^ftp: 1440 20% 10080
> refresh_pattern ^gopher: 1440 0% 1440
> refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
> refresh_pattern . 0 20% 4320
>
> but im still getting the exact same logs
>
> error 503 means
>
> 503
>
> Service Unavailable
>
> 1945 <http://tools.ietf.org/rfc/rfc1945>, 2616
> <http://tools.ietf.org/rfc/rfc2616>
> thanks,
> rob
>
> On Sun, 15 Dec 2019 at 10:40, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
>> On 15/12/19 1:16 pm, robert k Wild wrote:
>> > hi Amos,
>> >
>> > thank you for getting back to me about this :)
>> >
>> > this is my new config
>> >
>> > #
>> > #SSL
>> > http_port 3128 ssl-bump \
>> > cert=/usr/local/squid/etc/ssl_cert/myCA.pem \
>> > generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>> > sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
>> > /var/lib/ssl_db -M 4MB
>> > acl step1 at_step SslBump1
>> > ssl_bump peek step1
>> > ssl_bump bump all
>> >
>> > #Windows Updates
>> > acl windowsupdate dstdomain "/usr/local/squid/etc/wu.txt"
>> > acl CONNECT method CONNECT
>> > acl wuCONNECT dstdomain "/usr/local/squid/etc/wu.txt"
>> > http_access allow CONNECT wuCONNECT
>> > http_access allow windowsupdate
>> >
>> ...
>> >
>> > #
>> > # Recommended minimum Access Permission configuration:
>> > #
>> > # Deny requests to certain unsafe ports
>> > http_access deny !Safe_ports
>> >
>> > # Deny CONNECT to other than secure SSL ports
>> > http_access deny CONNECT !SSL_ports
>> >
>> > # Only allow cachemgr access from localhost
>> > http_access allow localhost manager
>> > http_access deny manager
>> >
>> > # We strongly recommend the following be uncommented to protect innocent
>> > # web applications running on the proxy server who think the only
>> > # one who can access services on "localhost" is a local user
>> > #http_access deny to_localhost
>> >
>> > #
>> > # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
>> > #
>> >
>> > # Example rule allowing access from your local networks.
>> > # Adapt localnet in the ACL section to list your (internal) IP networks
>> > # from where browsing should be allowed
>> > http_access allow localnet
>> > http_access allow localhost
>> >
>> ...
>>
>> >
>> > the reason why i have added the windows update lines at the beginning is
>> > that the link says so (below)
>> >
>> >
>> https://linuxnlenux.wordpress.com/2014/10/14/howto-allow-windows-updates-through-squid/
>> >
>>
>> That is a copy-n-paste of an old email without any of the context. See
>> <https://wiki.squid-cache.org/SquidFaq/WindowsUpdate> for the full
>> context and more up to date info.
>>
>> Note that the things that need to be first are very specifically a
>> sub-set of the MS domains which use a non-443 port for call-home traffic
>> so they would normally get blocked by the SSL_ports protection.
>>
>>
>> For a generic whitelist you should still have your list where the config
>> says "INSERT YOUR OWN RULES ..." .
>>
>>
>> >
>> > and when im looking at the logs real time
>> >
>> > 1576368417.620     48 10.100.1.5 NONE/200 0 CONNECT
>> > fe3cr.delivery.mp.microsoft.com:443
>> > <http://fe3cr.delivery.mp.microsoft.com:443> - HIER_DIRECT/
>> 191.232.139.2
>> > <http://191.232.139.2> -
>> > 1576368417.647      0 10.100.1.5 NONE/503 4363 POST
>> > https://fe3cr.delivery.mp.microsoft.com/ClientWebService/client.asmx -
>> > HIER_NONE/- text/html
>> > 1576368419.702      0 - TCP_MEM_HIT/200 807 GET
>> >
>> http://www.microsoft.com/pkiops/certs/Microsoft%20ECC%20Product%20Root%20Certificate%20Authority%202018.crt
>> > - HIER_NONE/- application/octet-st
>> > ream
>> >
>>
>> These show good progress from where you started off. The cert is being
>> downloaded fine. The tunnel being bumped fine. But the POST request
>> which was decrypted could not be serviced.
>>
>> Can you find out what the 503 message says?
>>
>>
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
> --
> Regards,
>
> Robert K Wild.
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191215/0e36b1f9/attachment.htm>

From squid3 at treenet.co.nz  Mon Dec 16 04:56:36 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 16 Dec 2019 17:56:36 +1300
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <CAGU_CiL_SfAA8jz=eX_UJQA7tV5YpFxYU9m-=S8_x3e9zxJzyA@mail.gmail.com>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
 <20191214083854.GA26450@fantomas.sk>
 <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>
 <744b7a54-6697-68aa-6e04-dc51fb9f4ce6@treenet.co.nz>
 <CAGU_CiKUxoL-60CKTM2q8pojWDncKtVzNWkNLS+LVe229jyOqQ@mail.gmail.com>
 <d812f44c-959b-7778-5861-0bcee625b9bf@treenet.co.nz>
 <CAGU_CiL7_DtYB5WV3c7YHKMKp1ixEGdxa8K3RYQ5=UF9FD30JQ@mail.gmail.com>
 <CAGU_CiL_SfAA8jz=eX_UJQA7tV5YpFxYU9m-=S8_x3e9zxJzyA@mail.gmail.com>
Message-ID: <25f4d7c9-1c80-c6bf-ba8a-2001341b5353@treenet.co.nz>

On 16/12/19 10:26 am, robert k Wild wrote:
> i have done it
> 
> i can now whitelist urls, block mime types and now i can
> download/install windows updates
> 

Excellent.

> 
> Amos, do you think i could make the windows update section a bit smaller
> or do i need all the lines in there?
> 

Depends on what Windows OS versions and MS software you are supporting
on the network. The list we have covers Win2k and later and some older
Office products that had different domains. If you want to, you can scan
your logs for a few months and see which are actually needed.


Amos


From robertkwild at gmail.com  Mon Dec 16 07:44:05 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Mon, 16 Dec 2019 07:44:05 +0000
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <25f4d7c9-1c80-c6bf-ba8a-2001341b5353@treenet.co.nz>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
 <20191214083854.GA26450@fantomas.sk>
 <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>
 <744b7a54-6697-68aa-6e04-dc51fb9f4ce6@treenet.co.nz>
 <CAGU_CiKUxoL-60CKTM2q8pojWDncKtVzNWkNLS+LVe229jyOqQ@mail.gmail.com>
 <d812f44c-959b-7778-5861-0bcee625b9bf@treenet.co.nz>
 <CAGU_CiL7_DtYB5WV3c7YHKMKp1ixEGdxa8K3RYQ5=UF9FD30JQ@mail.gmail.com>
 <CAGU_CiL_SfAA8jz=eX_UJQA7tV5YpFxYU9m-=S8_x3e9zxJzyA@mail.gmail.com>
 <25f4d7c9-1c80-c6bf-ba8a-2001341b5353@treenet.co.nz>
Message-ID: <CAGU_CiKVKdX6rMUHJ5YFwXKrAyM-XT2gL9_PeNFtEGOLHJmY9Q@mail.gmail.com>

Thanks for that Amos,

The line below, do you think I could add multiple domains to it, ie

refresh_pattern -i .microsoft.com .windows.com
.windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
<http://microsoft.com/.*%5C.%28cab%7Cexe%7Cms%5Bi%7Cu%7Cf%5D%7C%5Bap%5Dsf%7Cwm%5Bv%7Ca%5D%7Cdat%7Czip%29>
4320
80% 43200 reload-into-ims

Thanks,
Rob

On Mon, 16 Dec 2019, 04:57 Amos Jeffries, <squid3 at treenet.co.nz> wrote:

> On 16/12/19 10:26 am, robert k Wild wrote:
> > i have done it
> >
> > i can now whitelist urls, block mime types and now i can
> > download/install windows updates
> >
>
> Excellent.
>
> >
> > Amos, do you think i could make the windows update section a bit smaller
> > or do i need all the lines in there?
> >
>
> Depends on what Windows OS versions and MS software you are supporting
> on the network. The list we have covers Win2k and later and some older
> Office products that had different domains. If you want to, you can scan
> your logs for a few months and see which are actually needed.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191216/149a5df3/attachment.htm>

From squid3 at treenet.co.nz  Mon Dec 16 08:00:51 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 16 Dec 2019 21:00:51 +1300
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <CAGU_CiKVKdX6rMUHJ5YFwXKrAyM-XT2gL9_PeNFtEGOLHJmY9Q@mail.gmail.com>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
 <20191214083854.GA26450@fantomas.sk>
 <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>
 <744b7a54-6697-68aa-6e04-dc51fb9f4ce6@treenet.co.nz>
 <CAGU_CiKUxoL-60CKTM2q8pojWDncKtVzNWkNLS+LVe229jyOqQ@mail.gmail.com>
 <d812f44c-959b-7778-5861-0bcee625b9bf@treenet.co.nz>
 <CAGU_CiL7_DtYB5WV3c7YHKMKp1ixEGdxa8K3RYQ5=UF9FD30JQ@mail.gmail.com>
 <CAGU_CiL_SfAA8jz=eX_UJQA7tV5YpFxYU9m-=S8_x3e9zxJzyA@mail.gmail.com>
 <25f4d7c9-1c80-c6bf-ba8a-2001341b5353@treenet.co.nz>
 <CAGU_CiKVKdX6rMUHJ5YFwXKrAyM-XT2gL9_PeNFtEGOLHJmY9Q@mail.gmail.com>
Message-ID: <06ab55a8-e2bb-3aa4-a4ed-17fcd7a7bf89@treenet.co.nz>

On 16/12/19 8:44 pm, robert k Wild wrote:
> Thanks for that Amos,
> 
> The line below, do you think I could add multiple domains to it, ie
> 
> refresh_pattern -i .microsoft.com .windows.com
> .windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
> <http://microsoft.com/.*%5C.%28cab%7Cexe%7Cms%5Bi%7Cu%7Cf%5D%7C%5Bap%5Dsf%7Cwm%5Bv%7Ca%5D%7Cdat%7Czip%29>?4320
> 80% 43200 reload-into-ims
> 

The parameter is a single regex pattern. You can make a pattern that
matches multiple domains.

Amos



From robertkwild at gmail.com  Mon Dec 16 08:06:03 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Mon, 16 Dec 2019 08:06:03 +0000
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <06ab55a8-e2bb-3aa4-a4ed-17fcd7a7bf89@treenet.co.nz>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
 <20191214083854.GA26450@fantomas.sk>
 <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>
 <744b7a54-6697-68aa-6e04-dc51fb9f4ce6@treenet.co.nz>
 <CAGU_CiKUxoL-60CKTM2q8pojWDncKtVzNWkNLS+LVe229jyOqQ@mail.gmail.com>
 <d812f44c-959b-7778-5861-0bcee625b9bf@treenet.co.nz>
 <CAGU_CiL7_DtYB5WV3c7YHKMKp1ixEGdxa8K3RYQ5=UF9FD30JQ@mail.gmail.com>
 <CAGU_CiL_SfAA8jz=eX_UJQA7tV5YpFxYU9m-=S8_x3e9zxJzyA@mail.gmail.com>
 <25f4d7c9-1c80-c6bf-ba8a-2001341b5353@treenet.co.nz>
 <CAGU_CiKVKdX6rMUHJ5YFwXKrAyM-XT2gL9_PeNFtEGOLHJmY9Q@mail.gmail.com>
 <06ab55a8-e2bb-3aa4-a4ed-17fcd7a7bf89@treenet.co.nz>
Message-ID: <CAGU_CiJP3mctXH7Bed++hrNReL-PukL=RhrL__oSMkLho-F3Bg@mail.gmail.com>

How can I make a pattern that matches multiple domains please Amos?

On Mon, 16 Dec 2019, 08:01 Amos Jeffries, <squid3 at treenet.co.nz> wrote:

> On 16/12/19 8:44 pm, robert k Wild wrote:
> > Thanks for that Amos,
> >
> > The line below, do you think I could add multiple domains to it, ie
> >
> > refresh_pattern -i .microsoft.com .windows.com
> > .windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
> <http://windowsupdate.com/.*%5C.(cab%7Cexe%7Cms%5Bi%7Cu%7Cf%5D%7C%5Bap%5Dsf%7Cwm%5Bv%7Ca%5D%7Cdat%7Czip)>
> > <
> http://microsoft.com/.*%5C.%28cab%7Cexe%7Cms%5Bi%7Cu%7Cf%5D%7C%5Bap%5Dsf%7Cwm%5Bv%7Ca%5D%7Cdat%7Czip%29
> > 4320
> > 80% 43200 reload-into-ims
> >
>
> The parameter is a single regex pattern. You can make a pattern that
> matches multiple domains.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191216/5bd0cb22/attachment.htm>

From alex at nanogherkin.com  Mon Dec 16 08:37:44 2019
From: alex at nanogherkin.com (Alex Crow)
Date: Mon, 16 Dec 2019 08:37:44 +0000
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <CAGU_CiJP3mctXH7Bed++hrNReL-PukL=RhrL__oSMkLho-F3Bg@mail.gmail.com>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
 <20191214083854.GA26450@fantomas.sk>
 <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>
 <744b7a54-6697-68aa-6e04-dc51fb9f4ce6@treenet.co.nz>
 <CAGU_CiKUxoL-60CKTM2q8pojWDncKtVzNWkNLS+LVe229jyOqQ@mail.gmail.com>
 <d812f44c-959b-7778-5861-0bcee625b9bf@treenet.co.nz>
 <CAGU_CiL7_DtYB5WV3c7YHKMKp1ixEGdxa8K3RYQ5=UF9FD30JQ@mail.gmail.com>
 <CAGU_CiL_SfAA8jz=eX_UJQA7tV5YpFxYU9m-=S8_x3e9zxJzyA@mail.gmail.com>
 <25f4d7c9-1c80-c6bf-ba8a-2001341b5353@treenet.co.nz>
 <CAGU_CiKVKdX6rMUHJ5YFwXKrAyM-XT2gL9_PeNFtEGOLHJmY9Q@mail.gmail.com>
 <06ab55a8-e2bb-3aa4-a4ed-17fcd7a7bf89@treenet.co.nz>
 <CAGU_CiJP3mctXH7Bed++hrNReL-PukL=RhrL__oSMkLho-F3Bg@mail.gmail.com>
Message-ID: <d2ca8056-3b2b-7e5e-9b55-ec7e1692a9ea@nanogherkin.com>

On 16/12/2019 08:06, robert k Wild wrote:
> How can I make a pattern that matches multiple domains please Amos?
>
>
>     >
>     > refresh_pattern -i .microsoft.com <http://microsoft.com>
>     .windows.com <http://windows.com>
>     >
>     .windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
>     <http://windowsupdate.com/.*%5C.(cab%7Cexe%7Cms%5Bi%7Cu%7Cf%5D%7C%5Bap%5Dsf%7Cwm%5Bv%7Ca%5D%7Cdat%7Czip)>
>     >
>     <http://microsoft.com/.*%5C.%28cab%7Cexe%7Cms%5Bi%7Cu%7Cf%5D%7C%5Bap%5Dsf%7Cwm%5Bv%7Ca%5D%7Cdat%7Czip%29>?4320
>     > 80% 43200 reload-into-ims
>     > 
>

That's not really a subject for this list - search online for "regex" 
and you will see multiple tutorials about it.

You use a syntax like "(.microsoft.com 
<http://microsoft.com>|.windows.com|( 
<http://windows.com>.windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)|foo.com)" 
<http://windowsupdate.com/.*%5C.(cab%7Cexe%7Cms%5Bi%7Cu%7Cf%5D%7C%5Bap%5Dsf%7Cwm%5Bv%7Ca%5D%7Cdat%7Czip)>

eg (x|y|z(a|b)) would match x, y, za and zb.

Cheers

Alex

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191216/254703cb/attachment.htm>

From robertkwild at gmail.com  Mon Dec 16 09:10:23 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Mon, 16 Dec 2019 09:10:23 +0000
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <d2ca8056-3b2b-7e5e-9b55-ec7e1692a9ea@nanogherkin.com>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
 <20191214083854.GA26450@fantomas.sk>
 <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>
 <744b7a54-6697-68aa-6e04-dc51fb9f4ce6@treenet.co.nz>
 <CAGU_CiKUxoL-60CKTM2q8pojWDncKtVzNWkNLS+LVe229jyOqQ@mail.gmail.com>
 <d812f44c-959b-7778-5861-0bcee625b9bf@treenet.co.nz>
 <CAGU_CiL7_DtYB5WV3c7YHKMKp1ixEGdxa8K3RYQ5=UF9FD30JQ@mail.gmail.com>
 <CAGU_CiL_SfAA8jz=eX_UJQA7tV5YpFxYU9m-=S8_x3e9zxJzyA@mail.gmail.com>
 <25f4d7c9-1c80-c6bf-ba8a-2001341b5353@treenet.co.nz>
 <CAGU_CiKVKdX6rMUHJ5YFwXKrAyM-XT2gL9_PeNFtEGOLHJmY9Q@mail.gmail.com>
 <06ab55a8-e2bb-3aa4-a4ed-17fcd7a7bf89@treenet.co.nz>
 <CAGU_CiJP3mctXH7Bed++hrNReL-PukL=RhrL__oSMkLho-F3Bg@mail.gmail.com>
 <d2ca8056-3b2b-7e5e-9b55-ec7e1692a9ea@nanogherkin.com>
Message-ID: <CAGU_CiLfckG-D5UQ8q3bfYtm8xtAODHKCJJzOVPvP9fpXaAAWQ@mail.gmail.com>

Would this work aswell

refresh_pattern -i /etc/squid/wu.txt
/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
<http://microsoft.com/.*%5C.%28cab%7Cexe%7Cms%5Bi%7Cu%7Cf%5D%7C%5Bap%5Dsf%7Cwm%5Bv%7Ca%5D%7Cdat%7Czip%29>
4320
80% 43200 reload-into-ims

And in wu.txt

.microsoft.com
.windows.com
.windowsupdate.com

Exactly like my dstdomain

On Mon, 16 Dec 2019, 08:37 Alex Crow, <alex at nanogherkin.com> wrote:

> On 16/12/2019 08:06, robert k Wild wrote:
>
> How can I make a pattern that matches multiple domains please Amos?
>
>
> >
>> > refresh_pattern -i .microsoft.com .windows.com
>> > .windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
>> <http://windowsupdate.com/.*%5C.(cab%7Cexe%7Cms%5Bi%7Cu%7Cf%5D%7C%5Bap%5Dsf%7Cwm%5Bv%7Ca%5D%7Cdat%7Czip)>
>> > <
>> http://microsoft.com/.*%5C.%28cab%7Cexe%7Cms%5Bi%7Cu%7Cf%5D%7C%5Bap%5Dsf%7Cwm%5Bv%7Ca%5D%7Cdat%7Czip%29
>> > 4320
>> > 80% 43200 reload-into-ims
>> >
>
>
> That's not really a subject for this list - search online for "regex" and
> you will see multiple tutorials about it.
>
> You use a syntax like "(.microsoft.com|.windows.com|( <http://windows.com>
> .
> windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)|foo.com)"
> <http://windowsupdate.com/.*%5C.(cab%7Cexe%7Cms%5Bi%7Cu%7Cf%5D%7C%5Bap%5Dsf%7Cwm%5Bv%7Ca%5D%7Cdat%7Czip)>
>
> eg (x|y|z(a|b)) would match x, y, za and zb.
>
> Cheers
>
> Alex
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191216/4ab7816e/attachment.htm>

From alex at nanogherkin.com  Mon Dec 16 09:39:39 2019
From: alex at nanogherkin.com (Alex Crow)
Date: Mon, 16 Dec 2019 09:39:39 +0000
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <CAGU_CiLfckG-D5UQ8q3bfYtm8xtAODHKCJJzOVPvP9fpXaAAWQ@mail.gmail.com>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
 <20191214083854.GA26450@fantomas.sk>
 <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>
 <744b7a54-6697-68aa-6e04-dc51fb9f4ce6@treenet.co.nz>
 <CAGU_CiKUxoL-60CKTM2q8pojWDncKtVzNWkNLS+LVe229jyOqQ@mail.gmail.com>
 <d812f44c-959b-7778-5861-0bcee625b9bf@treenet.co.nz>
 <CAGU_CiL7_DtYB5WV3c7YHKMKp1ixEGdxa8K3RYQ5=UF9FD30JQ@mail.gmail.com>
 <CAGU_CiL_SfAA8jz=eX_UJQA7tV5YpFxYU9m-=S8_x3e9zxJzyA@mail.gmail.com>
 <25f4d7c9-1c80-c6bf-ba8a-2001341b5353@treenet.co.nz>
 <CAGU_CiKVKdX6rMUHJ5YFwXKrAyM-XT2gL9_PeNFtEGOLHJmY9Q@mail.gmail.com>
 <06ab55a8-e2bb-3aa4-a4ed-17fcd7a7bf89@treenet.co.nz>
 <CAGU_CiJP3mctXH7Bed++hrNReL-PukL=RhrL__oSMkLho-F3Bg@mail.gmail.com>
 <d2ca8056-3b2b-7e5e-9b55-ec7e1692a9ea@nanogherkin.com>
 <CAGU_CiLfckG-D5UQ8q3bfYtm8xtAODHKCJJzOVPvP9fpXaAAWQ@mail.gmail.com>
Message-ID: <2e875b1f-fefb-2359-7a05-612f3f7b3636@nanogherkin.com>


On 16/12/2019 09:10, robert k Wild wrote:
> Would this work aswell
>
> refresh_pattern -i 
> /etc/squid/wu.txt/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 
> <http://microsoft.com/.*%5C.%28cab%7Cexe%7Cms%5Bi%7Cu%7Cf%5D%7C%5Bap%5Dsf%7Cwm%5Bv%7Ca%5D%7Cdat%7Czip%29>?4320 
> 80% 43200 reload-into-ims
>
> And in wu.txt
>
> .microsoft.com <http://microsoft.com>
> .windows.com <http://windows.com>
> .windowsupdate.com <http://windowsupdate.com>
>
> Exactly like my dstdomain
>
>

No, because /etc/squid/wu.txt would be taken literally as part of the 
URL. And I don't think filenames are supported by that directive anyway.

Alex

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191216/9c7669c4/attachment.htm>

From robertkwild at gmail.com  Mon Dec 16 10:02:03 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Mon, 16 Dec 2019 10:02:03 +0000
Subject: [squid-users] cant download microsoft cert file
In-Reply-To: <2e875b1f-fefb-2359-7a05-612f3f7b3636@nanogherkin.com>
References: <CAGU_Ci+aKm5dQxNZy59Af-xddC3bMK5j=2BE+yeMcF+d5p_LvQ@mail.gmail.com>
 <20191214083854.GA26450@fantomas.sk>
 <CAGU_Ci+FBCyU6tHDi1vyXBLJt32y-xsQxgGMr1PSANqWwVh+9Q@mail.gmail.com>
 <744b7a54-6697-68aa-6e04-dc51fb9f4ce6@treenet.co.nz>
 <CAGU_CiKUxoL-60CKTM2q8pojWDncKtVzNWkNLS+LVe229jyOqQ@mail.gmail.com>
 <d812f44c-959b-7778-5861-0bcee625b9bf@treenet.co.nz>
 <CAGU_CiL7_DtYB5WV3c7YHKMKp1ixEGdxa8K3RYQ5=UF9FD30JQ@mail.gmail.com>
 <CAGU_CiL_SfAA8jz=eX_UJQA7tV5YpFxYU9m-=S8_x3e9zxJzyA@mail.gmail.com>
 <25f4d7c9-1c80-c6bf-ba8a-2001341b5353@treenet.co.nz>
 <CAGU_CiKVKdX6rMUHJ5YFwXKrAyM-XT2gL9_PeNFtEGOLHJmY9Q@mail.gmail.com>
 <06ab55a8-e2bb-3aa4-a4ed-17fcd7a7bf89@treenet.co.nz>
 <CAGU_CiJP3mctXH7Bed++hrNReL-PukL=RhrL__oSMkLho-F3Bg@mail.gmail.com>
 <d2ca8056-3b2b-7e5e-9b55-ec7e1692a9ea@nanogherkin.com>
 <CAGU_CiLfckG-D5UQ8q3bfYtm8xtAODHKCJJzOVPvP9fpXaAAWQ@mail.gmail.com>
 <2e875b1f-fefb-2359-7a05-612f3f7b3636@nanogherkin.com>
Message-ID: <CAGU_CiLcbcBVHwMjZigX6mrXivFk9QPktntdD-jEakPFa8wSUA@mail.gmail.com>

OK thanks Alex

Thanks guys for all your help really much appreciated, thanks so much

Rob

On Mon, 16 Dec 2019, 09:39 Alex Crow, <alex at nanogherkin.com> wrote:

>
> On 16/12/2019 09:10, robert k Wild wrote:
>
> Would this work aswell
>
> refresh_pattern -i /etc/squid/wu.txt
> /.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
> <http://microsoft.com/.*%5C.%28cab%7Cexe%7Cms%5Bi%7Cu%7Cf%5D%7C%5Bap%5Dsf%7Cwm%5Bv%7Ca%5D%7Cdat%7Czip%29> 4320
> 80% 43200 reload-into-ims
>
> And in wu.txt
>
> .microsoft.com
> .windows.com
> .windowsupdate.com
>
> Exactly like my dstdomain
>
>
>
> No, because /etc/squid/wu.txt would be taken literally as part of the URL.
> And I don't think filenames are supported by that directive anyway.
>
> Alex
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191216/06eef941/attachment.htm>

From robertkwild at gmail.com  Mon Dec 16 15:05:56 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Mon, 16 Dec 2019 15:05:56 +0000
Subject: [squid-users] cant activate office365 through proxy
Message-ID: <CAGU_CiJ=37OFknAb+uSauD0qnQEd5BfjKPCnbwRxi_tQRe_-5g@mail.gmail.com>

hi all,

when i set my system proxy using squid i can open up IE and i can access
websites fine, no problem

but when i open up my office365 app client ie word/excel/outlook etc i cant
activate it as it says im not online

i have no idea why this is happening (i attach a screenshot in the link
below)

i have even hashed out the http deny all line so it can go to any website

https://i.postimg.cc/xdcy2d5d/IMG-20191216-143812.jpg

thanks,
rob

-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191216/5af25091/attachment.htm>

From belle at bazuin.nl  Mon Dec 16 15:24:05 2019
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Mon, 16 Dec 2019 16:24:05 +0100
Subject: [squid-users] cant activate office365 through proxy
In-Reply-To: <CAGU_CiJ=37OFknAb+uSauD0qnQEd5BfjKPCnbwRxi_tQRe_-5g@mail.gmail.com>
References: <CAGU_CiJ=37OFknAb+uSauD0qnQEd5BfjKPCnbwRxi_tQRe_-5g@mail.gmail.com>
Message-ID: <vmime.5df7a195.43f0.8012d135363a65@ms249-lin-003.rotterdam.bazuin.nl>

What?are your squid logs saying? 
?
Tip, close office, clear your squid logs, start office then look at the logs. 
And are you for example blocking login.microsoft.com or something like that. 
?
Greetz, 
?
Louis
?

Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens robert k Wild
Verzonden: maandag 16 december 2019 16:06
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] cant activate office365 through proxy



hi all,


when i set my system proxy using squid i can open up IE and i can access websites fine, no problem



but when i open up my office365 app client ie word/excel/outlook etc i cant activate it as it says im not online


i have no idea why this is happening (i attach a screenshot in the link below)


i have even hashed out the http deny all line so it can go to any website



https://i.postimg.cc/xdcy2d5d/IMG-20191216-143812.jpg


thanks,
rob

-- 
Regards, 

Robert K Wild.




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191216/7bd30209/attachment.htm>

From asfand0817 at gmail.com  Mon Dec 16 17:55:01 2019
From: asfand0817 at gmail.com (Null)
Date: Mon, 16 Dec 2019 11:55:01 -0600 (CST)
Subject: [squid-users] Allow proxy access only to a specific user
Message-ID: <1576518901651-0.post@n4.nabble.com>

Hi everyone,
I have a VPS with 2 different IPs:
207.x.x.x
164.x.x.x


I have two users credentials in my passwd for the ncsa auth:
user1
user2

*I am trying to configure squid such that:*
user1 can only access *207.x.x.x* but NOT /164.x.x.x/
user2 can only access /164.x.x.x/ but NOT *207.x.x.x*

*And in the case i have 4 different IPs (so 4 proxies) and i want to give
each user 2 "private" proxies, how would i do that?*

e.g:
user1 can only access *207.x.x.x, 158.x.x.x* but NOT /164.x.x.x, 125.x.x.x/
user2 can only access /164.x.x.x, 125.x.x.x/ but NOT *207.x.x.x, 158.x.x.x*


*Is it possible to have a list of proxies allowed per each user?*







--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From dm at belkam.com  Tue Dec 17 09:11:04 2019
From: dm at belkam.com (Dmitry Melekhov)
Date: Tue, 17 Dec 2019 13:11:04 +0400
Subject: [squid-users] https://web.whatsapp.com/ , no qr code
Message-ID: <71272367-cddb-c3eb-a90a-2ec7996a85e9@belkam.com>

Hello!


Users complains that they do not get qr code while using squid on 
https://web.whatsapp.com/

I checked this and got the same result with or without ssl-bump:

1576573551.547????? 0 192.168.22.229 NONE/000 0 NONE 
error:transaction-end-before-headers - HIER_NONE/- -

is all I see in logs.

squid --version
Squid Cache: Version 4.9

Firefox 71.0

Direct connection works.


Is there any way to solve this?


Thank you!




From dm at belkam.com  Tue Dec 17 09:25:24 2019
From: dm at belkam.com (dm)
Date: Tue, 17 Dec 2019 13:25:24 +0400
Subject: [squid-users] https://web.whatsapp.com/ , no qr code
In-Reply-To: <71272367-cddb-c3eb-a90a-2ec7996a85e9@belkam.com>
References: <71272367-cddb-c3eb-a90a-2ec7996a85e9@belkam.com>
Message-ID: <1431ca39-2869-1166-388e-1cac00fe0f9b@belkam.com>

17.12.2019 13:11, Dmitry Melekhov ?????:
> Hello!
>
>
> Users complains that they do not get qr code while using squid on 
> https://web.whatsapp.com/
>
> I checked this and got the same result with or without ssl-bump:
>
> 1576573551.547????? 0 192.168.22.229 NONE/000 0 NONE 
> error:transaction-end-before-headers - HIER_NONE/- -
>
> is all I see in logs.
>
> squid --version
> Squid Cache: Version 4.9
>
> Firefox 71.0
>
> Direct connection works.
>
>
> Is there any way to solve this?
>
>
> Thank you!
>
>
OK, real problem here was using the same proxy for all protocols in Firefox.

Looks like whatsapp tries to use socks, if it is available, but we 
really don't have it.

Disabled socks proxy in firefox settings and it works.


Thank you!



From sebastien at avis-verifies.com  Tue Dec 17 10:28:35 2019
From: sebastien at avis-verifies.com (=?UTF-8?Q?S=C3=A9bastien_Genesta?=)
Date: Tue, 17 Dec 2019 11:28:35 +0100
Subject: [squid-users] squidguard stopped and restart randomly
Message-ID: <CACZAUVo1c7KTHDVdEfg5G_zD3r_9iufmfGZNMPCQcy9Ndj2jjg@mail.gmail.com>

Hi,

I'm encountering strange behaviour with Squid/Squidguard.

Randomly, squidguard stopped and restart. Then sometimes never restart
until I do a /etc/init.d/squid restart

*Squidguard Logs:*

2019-12-16 11:12:55 [64335] INFO: squidGuard 1.5 started (1576491175.566)
2019-12-16 11:12:55 [64335] INFO: squidGuard ready for requests
(1576491175.572)
2019-12-16 11:13:01 [64335] INFO: squidGuard stopped (1576491181.328)
2019-12-16 11:13:01 [64334] INFO: squidGuard stopped (1576491181.328)
2019-12-16 11:13:01 [64332] INFO: squidGuard stopped (1576491181.329)
2019-12-16 11:13:01 [64333] INFO: squidGuard stopped (1576491181.329)
2019-12-16 11:13:04 [64403] INFO: New setting: dbhome:
/etc/squidguard/blacklists
2019-12-16 11:13:04 [64403] INFO: New setting: logdir: /var/log/squidguard
2019-12-16 11:13:04 [64403] init domainlist
/etc/squidguard/blacklists/ads/domains
2019-12-16 11:13:04 [64403] INFO: loading dbfile
/etc/squidguard/blacklists/ads/domains.db
[...]
2019-12-16 11:13:05 [64470] INFO: squidGuard 1.5 started (1576491185.939)
2019-12-16 11:13:05 [64470] INFO: squidGuard ready for requests
(1576491185.940)
2019-12-16 11:13:07 [64470] INFO: squidGuard stopped (1576491187.188)
2019-12-16 11:13:07 [64469] INFO: squidGuard stopped (1576491187.188)
2019-12-16 11:13:07 [64404] INFO: squidGuard stopped (1576491187.189)
2019-12-16 11:13:07 [64405] INFO: squidGuard stopped (1576491187.189)
2019-12-16 11:13:07 [64403] INFO: squidGuard stopped (1576491187.189)
2019-12-16 11:13:07 [64402] INFO: squidGuard stopped (1576491187.189)
[...]

I didn't notice anything on squid logs (except when I restart squid myself)
so it doesn't seem that squidguard restart is due to squid restart.

My blacklist is auto updated every sunday so it is also not due to that.

OS: Debian 9.6
squid version: 3.5.23-5+deb9u1
squidguard version: 1.5-5

Thanks for your help.

S?bastien GENESTA

*Sys Admin*

Tel :04 13 24 81 68 <+33413248168>
Mail :sebastien at avis-verifies.com
[image: Avis V?rifi?s] <http://www.avis-verifies.com/>

"Donnez la parole ? vos clients!"

Net Reviews, ?diteur de la solution Avis V?rifi?s, est reconnu comme l'une
des entreprises digitales les plus innovantes de France. Elle est ainsi
r?compens?e du pass French Tech.et fait partie du r?seau Bpi France
Excellence depuis 2017
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191217/05360185/attachment.htm>

From yaroslav.pushko at globallogic.com  Tue Dec 17 14:00:58 2019
From: yaroslav.pushko at globallogic.com (Yaroslav Pushko)
Date: Tue, 17 Dec 2019 16:00:58 +0200
Subject: [squid-users] Fwd: Squid 4.8 with OpenSSL 1.1.1d
In-Reply-To: <CADSgaCTS3xsUY0EBZvJY+fk2_OBqUVNBO1gMDwyxJpYYPH7_Ng@mail.gmail.com>
References: <CADSgaCTS3xsUY0EBZvJY+fk2_OBqUVNBO1gMDwyxJpYYPH7_Ng@mail.gmail.com>
Message-ID: <CADSgaCQtQAetQCukyQfR5c6Bq8B22_k76Ff3Y8OONsqm1juiPg@mail.gmail.com>

Hi All

We use Squid 4.8 with OpenSSL 1.1.1d in a transparent mode for peek and
splice interception.

With this version, we lost the possibility to connect to any HTTPS site.

There are a few issues:

   - support TLSv1.2 sites (already discussed in thread
   http://squid-web-proxy-cache.1019090.n4.nabble.com/Problem-with-ssl-choose-client-version-inappropriate-fallback-on-some-sites-when-using-TLS1-2-td4688258.html
    )
   - support TLSv1.3 sites.


Support TLSv1.2.

OpenSSL 1.1.1d adds support of TLSv1.3. These changes added some kind of
guard if we perform a handshake with a lower version of the TLS protocol
than we support. In this scenario, we receive downgrade fallback error.
Handshake version TLSv1.2 vs. max support TLSv1.3.

In such case, we have the next error:

ERROR: negotiating TLS on FD 19: error:1425F175:SSL
> routines:ssl_choose_client_version:inappropriate fallback (1/-1/0)


OpenSSL already provided a fix for it. You can configure SSL session to use
option SSL_MODE_SEND_FALLBACK_SCSV and setting SSL max proto version for
current SSL session, but squid not yet supported these features.

You can find a patch in the attachments, will be grateful for the review.


The issue with TLS 1.3 support, we are still investigating, any advice will
be pleasant.

Best regards,
Yaroslav Pushko.
-- 
Best Regards,
Yaroslav Pushko | Senior *Software Engineer*
GlobalLogic
P +380971842774  M +380634232226 S dithard
www.globallogic.com
http://www.globallogic.com/email_disclaimer.txt
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191217/7ce31211/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid-4.8-added_max_support_tlsversion.patch
Type: application/x-patch
Size: 3722 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191217/7ce31211/attachment.bin>

From rousskov at measurement-factory.com  Tue Dec 17 14:39:04 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 17 Dec 2019 09:39:04 -0500
Subject: [squid-users] Fwd: Squid 4.8 with OpenSSL 1.1.1d
In-Reply-To: <CADSgaCQtQAetQCukyQfR5c6Bq8B22_k76Ff3Y8OONsqm1juiPg@mail.gmail.com>
References: <CADSgaCTS3xsUY0EBZvJY+fk2_OBqUVNBO1gMDwyxJpYYPH7_Ng@mail.gmail.com>
 <CADSgaCQtQAetQCukyQfR5c6Bq8B22_k76Ff3Y8OONsqm1juiPg@mail.gmail.com>
Message-ID: <fc72bea5-0f98-864b-57f2-ae4d8cc9ae92@measurement-factory.com>

On 12/17/19 9:00 AM, Yaroslav Pushko wrote:
> Hi All
> 
> We use?Squid 4.8 with OpenSSL 1.1.1d in a transparent mode for peek and
> splice interception.
> 
> With this version, we lost the?possibility?to connect to any HTTPS site.
> 
> There are a few issues:?
> 
>   * support TLSv1.2 sites (already discussed in
>     thread?http://squid-web-proxy-cache.1019090.n4.nabble.com/Problem-with-ssl-choose-client-version-inappropriate-fallback-on-some-sites-when-using-TLS1-2-td4688258.html?)
>   * support TLSv1.3 sites.

Please see
http://lists.squid-cache.org/pipermail/squid-users/2019-December/021435.html
for several alternative fixes. AFAICT, those fixes are more flexible
and, after polishing, appropriate for the official inclusion because
they make fewer assumptions about the values sent via the supported
versions extension.

It is possible that your SSL_MODE_SEND_FALLBACK_SCSV change needs to be
integrated with the other fixes. Thank you for sharing that idea!

Alex.


> Support TLSv1.2.
> 
>     OpenSSL 1.1.1d adds support of TLSv1.3. These changes added some
>     kind of guard if we perform a handshake with a lower version of the
>     TLS protocol than we support. In this scenario, we receive downgrade
>     fallback?error.
>     Handshake version TLSv1.2 vs. max support TLSv1.3.
> 
>     In such case, we have the next error:
> 
>         ERROR: negotiating TLS on FD 19: error:1425F175:SSL
>         routines:ssl_choose_client_version:inappropriate fallback (1/-1/0)
> 
> 
>     OpenSSL already?provided?a fix for it. You can configure SSL session
>     to use option?SSL_MODE_SEND_FALLBACK_SCSV and setting SSL max proto
>     version for current SSL session, but squid not yet supported these
>     features.
> 
>     You can find a patch in the attachments, will be grateful for the
>     review.
> 
> 
> The issue with TLS 1.3 support, we are still investigating, any advice
> will be pleasant.
> 
> Best regards,
> Yaroslav Pushko.
> --?
> Best Regards,
> Yaroslav Pushko | Senior?*Software Engineer*
> GlobalLogic
> P +380971842774 ?M +380634232226 S?dithard
> www.globallogic.com <http://www.globallogic.com/>
> http://www.globallogic.com/email_disclaimer.txt
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From psousadp at gmail.com  Thu Dec 19 10:56:29 2019
From: psousadp at gmail.com (=?UTF-8?Q?Patr=C3=ADcia_Sousa?=)
Date: Thu, 19 Dec 2019 10:56:29 +0000
Subject: [squid-users] Block and allow connections by CA
Message-ID: <CAJiPhfm=ceN8b8MwK8NNAJaeLa+SD1Y9LN0fzi16gFDjNxJ36g@mail.gmail.com>

Hello,

I was researching a proxy service for access control, and I'm wondering if
this service is capable of doing what I want.

I would like to have an IoT device that only receives and sends requests to
and from certain devices that belong and are authenticated by a specific
certificate authority. Is it possible to block all other connections or
only allow connections from devices that belong to a specific CA?

Thank you,
Best regards
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191219/40c3f3da/attachment.htm>

From robertkwild at gmail.com  Thu Dec 19 15:02:36 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 19 Dec 2019 15:02:36 +0000
Subject: [squid-users] good guide to AntiVirus detection, squid4
Message-ID: <CAGU_CiKPrbZg776YnyQARBevU8BY7xYuSCaav=ZjDkxNyNTQNA@mail.gmail.com>

hi all, hope your all well :)

im looking after a good guide to set up real time antivirus on squid 4 for
all the traffic

i have seen numerous tools for this like clamAV, C-icap, HAVP and i have
read since squid 3, squid comes with icap

can i just use icap the build in one or shall i use something else to go
with it

if anyone has got suggestions and can show me a good guide on how to do it,
that would be great

thanks,
rob

-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191219/02ae430b/attachment.htm>

From rafael.akchurin at diladele.com  Thu Dec 19 16:07:31 2019
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 19 Dec 2019 16:07:31 +0000
Subject: [squid-users] good guide to AntiVirus detection, squid4
In-Reply-To: <CAGU_CiKPrbZg776YnyQARBevU8BY7xYuSCaav=ZjDkxNyNTQNA@mail.gmail.com>
References: <CAGU_CiKPrbZg776YnyQARBevU8BY7xYuSCaav=ZjDkxNyNTQNA@mail.gmail.com>
Message-ID: <AM0PR04MB47530BED59E053FE2D0F11698F520@AM0PR04MB4753.eurprd04.prod.outlook.com>

Hello Robert,

Please see scripts at https://github.com/diladele/websafety/tree/release-7.2.0/core.ubuntu18 on how we do that (if you do not need web filtering ? just ignore that part).

Best regards,
Rafael

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of robert k Wild
Sent: Thursday, 19 December 2019 16:03
To: squid-users at lists.squid-cache.org
Subject: [squid-users] good guide to AntiVirus detection, squid4

hi all, hope your all well :)

im looking after a good guide to set up real time antivirus on squid 4 for all the traffic

i have seen numerous tools for this like clamAV, C-icap, HAVP and i have read since squid 3, squid comes with icap

can i just use icap the build in one or shall i use something else to go with it

if anyone has got suggestions and can show me a good guide on how to do it, that would be great

thanks,
rob

--
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191219/a12163c8/attachment.htm>

From robertkwild at gmail.com  Thu Dec 19 17:52:03 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 19 Dec 2019 17:52:03 +0000
Subject: [squid-users] good guide to AntiVirus detection, squid4
In-Reply-To: <AM0PR04MB47530BED59E053FE2D0F11698F520@AM0PR04MB4753.eurprd04.prod.outlook.com>
References: <CAGU_CiKPrbZg776YnyQARBevU8BY7xYuSCaav=ZjDkxNyNTQNA@mail.gmail.com>
 <AM0PR04MB47530BED59E053FE2D0F11698F520@AM0PR04MB4753.eurprd04.prod.outlook.com>
Message-ID: <CAGU_CiLTru3qxkpKRv0y6CwKhDZcwdumZb2rJoTBiPPW+w+RcA@mail.gmail.com>

Thanks Rafael,

So to get this up and running can I install it on a centos 7 vm or does it
have to be a Ubuntu?

Also what squid version do I need to put on my vm for this to work as I
don't see a squid install script

Many thanks,
Rob

On Thu, 19 Dec 2019, 16:07 Rafael Akchurin, <rafael.akchurin at diladele.com>
wrote:

> Hello Robert,
>
>
>
> Please see scripts at
> https://github.com/diladele/websafety/tree/release-7.2.0/core.ubuntu18 on
> how we do that (if you do not need web filtering ? just ignore that part).
>
>
>
> Best regards,
>
> Rafael
>
>
>
> *From:* squid-users <squid-users-bounces at lists.squid-cache.org> *On
> Behalf Of *robert k Wild
> *Sent:* Thursday, 19 December 2019 16:03
> *To:* squid-users at lists.squid-cache.org
> *Subject:* [squid-users] good guide to AntiVirus detection, squid4
>
>
>
> hi all, hope your all well :)
>
>
>
> im looking after a good guide to set up real time antivirus on squid 4 for
> all the traffic
>
>
>
> i have seen numerous tools for this like clamAV, C-icap, HAVP and i have
> read since squid 3, squid comes with icap
>
>
>
> can i just use icap the build in one or shall i use something else to go
> with it
>
>
>
> if anyone has got suggestions and can show me a good guide on how to do
> it, that would be great
>
>
>
> thanks,
>
> rob
>
>
> --
>
> Regards,
>
> Robert K Wild.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191219/852ba6ce/attachment.htm>

From rousskov at measurement-factory.com  Thu Dec 19 20:47:55 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 19 Dec 2019 15:47:55 -0500
Subject: [squid-users] Block and allow connections by CA
In-Reply-To: <CAJiPhfm=ceN8b8MwK8NNAJaeLa+SD1Y9LN0fzi16gFDjNxJ36g@mail.gmail.com>
References: <CAJiPhfm=ceN8b8MwK8NNAJaeLa+SD1Y9LN0fzi16gFDjNxJ36g@mail.gmail.com>
Message-ID: <17619774-5c6e-171d-87fe-0cdaf29393a1@measurement-factory.com>

On 12/19/19 5:56 AM, Patr?cia Sousa wrote:

> I would like to have an IoT device that only receives and sends requests
> to and from certain devices that belong and are authenticated by a
> specific certificate authority. Is it possible to block all other
> connections or only allow connections from devices that belong to a
> specific CA?

Yes, I believe it is possible:

* Squid can check (via an https_port configuration option) that a TLS
client possesses a certificate signed by a specific CA.

* Squid can check (via a ca_cert ACL) that a TLS server uses a
certificate signed by a specific CA. This ACL can be applied during
SslBump step3 processing, but there may be a way to sneak it in without
using SslBump (or such a way can be added by modifying Squid).

If ca_cert options are not enough, Squid can check other server
certificate properties via a custom certificate validation daemon (which
you would have to write). Or one could add support for more properties
to the ca_cert ACL.

Alex.


From netadmin at aicta.ro  Fri Dec 20 08:03:29 2019
From: netadmin at aicta.ro (netadmin)
Date: Fri, 20 Dec 2019 10:03:29 +0200
Subject: [squid-users] Is Squid 4.9 gone?
Message-ID: <f14c4ca57a2008f813dd2fd8c9182b21@aicta.ro>


At the address:
http://www.squid-cache.org/Versions/
the latest version appears as 4.8 although I am running 4.9!
What happened to version 4.9?


From squid3 at treenet.co.nz  Fri Dec 20 08:35:26 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Dec 2019 21:35:26 +1300
Subject: [squid-users] Is Squid 4.9 gone?
In-Reply-To: <f14c4ca57a2008f813dd2fd8c9182b21@aicta.ro>
References: <f14c4ca57a2008f813dd2fd8c9182b21@aicta.ro>
Message-ID: <cc061398-c69d-5110-fd96-65a0c95945e8@treenet.co.nz>

On 20/12/19 9:03 pm, netadmin wrote:
> 
> At the address:
> http://www.squid-cache.org/Versions/
> the latest version appears as 4.8 although I am running 4.9!
> What happened to version 4.9?


I'm not entirely certain what happened there. I suspect it was just an
oversight on my part not copying the files from the release directory to
the web server. That has now been corrected.

As to why you could be running a version not available on the www site;
Vendors pull their release code from any one (or several) different
sources we provide them - our public git repository, FTP servers, or
rsync servers.

Amos


From 0xff1f at gmail.com  Fri Dec 20 09:08:32 2019
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Fri, 20 Dec 2019 12:08:32 +0300
Subject: [squid-users] Is Squid 4.9 gone?
In-Reply-To: <cc061398-c69d-5110-fd96-65a0c95945e8@treenet.co.nz>
References: <cc061398-c69d-5110-fd96-65a0c95945e8@treenet.co.nz>
Message-ID: <8AA42AB3-6000-4602-834C-23ECA0B3939F@gmail.com>

Perfect Amos ?

Sent from my iPhone

> On Dec 20, 2019, at 11:35 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> ?On 20/12/19 9:03 pm, netadmin wrote:
>> 
>> At the address:
>> http://www.squid-cache.org/Versions/
>> the latest version appears as 4.8 although I am running 4.9!
>> What happened to version 4.9?
> 
> 
> I'm not entirely certain what happened there. I suspect it was just an
> oversight on my part not copying the files from the release directory to
> the web server. That has now been corrected.
> 
> As to why you could be running a version not available on the www site;
> Vendors pull their release code from any one (or several) different
> sources we provide them - our public git repository, FTP servers, or
> rsync servers.
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From dm at belkam.com  Fri Dec 20 09:10:50 2019
From: dm at belkam.com (Dmitry Melekhov)
Date: Fri, 20 Dec 2019 13:10:50 +0400
Subject: [squid-users] Is Squid 4.9 gone?
In-Reply-To: <cc061398-c69d-5110-fd96-65a0c95945e8@treenet.co.nz>
References: <f14c4ca57a2008f813dd2fd8c9182b21@aicta.ro>
 <cc061398-c69d-5110-fd96-65a0c95945e8@treenet.co.nz>
Message-ID: <c73c4d03-4375-a81e-676d-d9df6f545313@belkam.com>

20.12.2019 12:35, Amos Jeffries ?????:
> On 20/12/19 9:03 pm, netadmin wrote:
>> At the address:
>> http://www.squid-cache.org/Versions/
>> the latest version appears as 4.8 although I am running 4.9!
>> What happened to version 4.9?
>
> I'm not entirely certain what happened there. I suspect it was just an
> oversight on my part not copying the files from the release directory to
> the web server. That has now been corrected.
>
> As to why you could be running a version not available on the www site;
> Vendors pull their release code from any one (or several) different
> sources we provide them - our public git repository, FTP servers, or
> rsync servers.

No, 4.9 was available on squid-cache.org some time ago :-)




From belle at bazuin.nl  Fri Dec 20 09:20:08 2019
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Fri, 20 Dec 2019 10:20:08 +0100
Subject: [squid-users] Is Squid 4.9 gone?
In-Reply-To: <c73c4d03-4375-a81e-676d-d9df6f545313@belkam.com>
References: <cc061398-c69d-5110-fd96-65a0c95945e8@treenet.co.nz>
Message-ID: <vmime.5dfc9248.2124.7c0c4ff8c5622c8@ms249-lin-003.rotterdam.bazuin.nl>

Ah.. it shows Amos is human also..  :-) 

If you need squid 4.9 in debian Buster (10) package. 

These are the package i currently provide on/for Debian Buster. 
Squid 4.9 with ssl enabled settings.

Package list:  https://apt.van-belle.nl/current-packages-in-buster-squid49-apt.txt 
(included also, squidclamav, packaged into : c-icap-module-squidclamav )

My repo setup. 
1) Choose http or https for you apt, both work, for https you need to :
apt-get install apt-transport-https

2) Import my public key
wget -O - http://apt.van-belle.nl/louis-van-belle.gpg-key.asc | apt-key add -

3) setup the repo. 
echo "deb http://apt.van-belle.nl/debian buster-squid49 main contrib non-free" | sudo tee -a /etc/apt/sources.list.d/van-belle.list

General info, :  https://apt.van-belle.nl 

Thank Amos and the squid dev team. 
I wish you guys the best, happy, healty and successfull year(s) to come. 

Greetz, 

Louis 


> -----Oorspronkelijk bericht-----
> Van: squid-users 
> [mailto:squid-users-bounces at lists.squid-cache.org] Namens 
> Dmitry Melekhov
> Verzonden: vrijdag 20 december 2019 10:11
> Aan: squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] Is Squid 4.9 gone?
> 
> 20.12.2019 12:35, Amos Jeffries ??????????:
> > On 20/12/19 9:03 pm, netadmin wrote:
> >> At the address:
> >> http://www.squid-cache.org/Versions/
> >> the latest version appears as 4.8 although I am running 4.9!
> >> What happened to version 4.9?
> >
> > I'm not entirely certain what happened there. I suspect it 
> was just an
> > oversight on my part not copying the files from the release 
> directory to
> > the web server. That has now been corrected.
> >
> > As to why you could be running a version not available on 
> the www site;
> > Vendors pull their release code from any one (or several) different
> > sources we provide them - our public git repository, FTP servers, or
> > rsync servers.
> 
> No, 4.9 was available on squid-cache.org some time ago :-)
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From netadmin at aicta.ro  Fri Dec 20 09:21:11 2019
From: netadmin at aicta.ro (netadmin)
Date: Fri, 20 Dec 2019 11:21:11 +0200
Subject: [squid-users] Is Squid 4.9 gone?
Message-ID: <b406bbdcfd1a3dc8496b5714c5c98c5e@aicta.ro>

"No, 4.9 was available on squid-cache.org some time ago :-)"

Squid 4.8 is still here
http://www.squid-cache.org/Versions/


From squid3 at treenet.co.nz  Fri Dec 20 09:40:38 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Dec 2019 22:40:38 +1300
Subject: [squid-users] Is Squid 4.9 gone?
In-Reply-To: <b406bbdcfd1a3dc8496b5714c5c98c5e@aicta.ro>
References: <b406bbdcfd1a3dc8496b5714c5c98c5e@aicta.ro>
Message-ID: <ee76c11a-002c-ae9c-b98d-008afdfb2b41@treenet.co.nz>

On 20/12/19 10:21 pm, netadmin wrote:
> "No, 4.9 was available on squid-cache.org some time ago :-)"
> 
> Squid 4.8 is still here
> http://www.squid-cache.org/Versions/

I sent my response minutes after doing the update on our master server.
The www.* servers take 2-12hrs to receive updates.

Amos


From m_zouhairy at skno.by  Fri Dec 20 10:05:16 2019
From: m_zouhairy at skno.by (Vacheslav)
Date: Fri, 20 Dec 2019 13:05:16 +0300
Subject: [squid-users] squid log analyzer
In-Reply-To: <ee76c11a-002c-ae9c-b98d-008afdfb2b41@treenet.co.nz>
References: <b406bbdcfd1a3dc8496b5714c5c98c5e@aicta.ro>
 <ee76c11a-002c-ae9c-b98d-008afdfb2b41@treenet.co.nz>
Message-ID: <df42677090ed04d94317d9fcf21837a6d62ea4ca.camel@skno.by>

i searched for a ufdb guard log analyzer and it was like looking for
aliens..so i settled for squid log analyzers..i tried calimaris which
reminded me that squid is translated to kalmar in Russian but the
version on opensuse does not provide what user went to where..i read
about lots of options..many are stopped from being updated, others
require too much setup and finally i saw sarg! almost everyone was
bashing it as slow and try this instead..but it promised to show which
user visited what url, so i installed it and tried it from command line
and it was fast but it failed to create the index file in the
configured folder so couldn't see the html results.. i suffered all day
reading this and that and experimenting and it was useless, so i tired
reaching for help on their forum and it is like i visited a ghost
town..
so who has tried  something similar to do this that is working?




From rafael.akchurin at diladele.com  Fri Dec 20 11:24:02 2019
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 20 Dec 2019 11:24:02 +0000
Subject: [squid-users] squid log analyzer
In-Reply-To: <df42677090ed04d94317d9fcf21837a6d62ea4ca.camel@skno.by>
References: <b406bbdcfd1a3dc8496b5714c5c98c5e@aicta.ro>
 <ee76c11a-002c-ae9c-b98d-008afdfb2b41@treenet.co.nz>
 <df42677090ed04d94317d9fcf21837a6d62ea4ca.camel@skno.by>
Message-ID: <AM0PR04MB47531FE5BE9439B4A2CD77298F2D0@AM0PR04MB4753.eurprd04.prod.outlook.com>

Hello Vacheslav,

We are building something like sarg/squidanalyzer/lightsquid in web safety 7.2.
See https://docs.diladele.com/administrator_guide_develop/traffic_monitoring/index.html 

It shall be easy to grab the virtual appliance, upload your Squid logs into /var/log/squid and see if the results are ok.

Best regards,
Rafael Akchurin
Diladele B.V.


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Vacheslav
Sent: Friday, 20 December 2019 11:05
To: squid-users at lists.squid-cache.org
Subject: [squid-users] squid log analyzer

i searched for a ufdb guard log analyzer and it was like looking for aliens..so i settled for squid log analyzers..i tried calimaris which reminded me that squid is translated to kalmar in Russian but the version on opensuse does not provide what user went to where..i read about lots of options..many are stopped from being updated, others require too much setup and finally i saw sarg! almost everyone was bashing it as slow and try this instead..but it promised to show which user visited what url, so i installed it and tried it from command line and it was fast but it failed to create the index file in the configured folder so couldn't see the html results.. i suffered all day reading this and that and experimenting and it was useless, so i tired reaching for help on their forum and it is like i visited a ghost town..
so who has tried  something similar to do this that is working?


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From g2011828 at hotmail.com  Sat Dec 21 05:27:21 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Fri, 20 Dec 2019 23:27:21 -0600 (CST)
Subject: [squid-users] Is there a way on client to show proxy's certificate?
Message-ID: <1576906041486-0.post@n4.nabble.com>

Running a client program through a proxy server, and I was given the proxy's
root CA certificate file. When applied, got the error on the program: "x509:
certificate signed by unknown authority". Now I'm wondering if the so called
"proxy's root CA cert" is given correctly.

I now for openssl, I can do "openssl s_client -connect remote-host:443
-showcert" to show the chain of server's CAs, is there a way to use the
openssl to show what is the CA on the proxy server? or is there someway to
find this out?

thanks.
George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Sat Dec 21 05:47:21 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 Dec 2019 18:47:21 +1300
Subject: [squid-users] Is there a way on client to show proxy's
 certificate?
In-Reply-To: <1576906041486-0.post@n4.nabble.com>
References: <1576906041486-0.post@n4.nabble.com>
Message-ID: <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>

On 21/12/19 6:27 pm, GeorgeShen wrote:
> Running a client program through a proxy server, and I was given the proxy's
> root CA certificate file. When applied, got the error on the program: "x509:
> certificate signed by unknown authority". Now I'm wondering if the so called
> "proxy's root CA cert" is given correctly.
> 
> I now for openssl, I can do "openssl s_client -connect remote-host:443
> -showcert" to show the chain of server's CAs, is there a way to use the
> openssl to show what is the CA on the proxy server? or is there someway to
> find this out?

The same openssl command can connect to any type of TLS server.


Amos


From g2011828 at hotmail.com  Sat Dec 21 06:02:30 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Sat, 21 Dec 2019 00:02:30 -0600 (CST)
Subject: [squid-users] Is there a way on client to show proxy's
	certificate?
In-Reply-To: <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
References: <1576906041486-0.post@n4.nabble.com>
 <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
Message-ID: <1576908150187-0.post@n4.nabble.com>

> The same openssl command can connect to any type of TLS server.

True. But the proxy server may not run normal TLS service or listen on the
port 443.
The proxy with SSL-Bump is listening on the 3129 for example, I have
certainly tried:

 openssl s_client -connect proxy-server-ip:3129 -showcert

and that does not work. I'm just say the proxy server may not also run a
normal TLS service.

thanks.
George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Sat Dec 21 05:59:34 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 Dec 2019 18:59:34 +1300
Subject: [squid-users] Is there a way on client to show proxy's
 certificate?
In-Reply-To: <1576908150187-0.post@n4.nabble.com>
References: <1576906041486-0.post@n4.nabble.com>
 <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
 <1576908150187-0.post@n4.nabble.com>
Message-ID: <6646d496-fe60-4c98-bc88-4261cfef3ffe@treenet.co.nz>

On 21/12/19 7:02 pm, GeorgeShen wrote:
>> The same openssl command can connect to any type of TLS server.
> 
> True. But the proxy server may not run normal TLS service or listen on the
> port 443.
> The proxy with SSL-Bump is listening on the 3129 for example, I have
> certainly tried:
> 
>  openssl s_client -connect proxy-server-ip:3129 -showcert
> 
> and that does not work. I'm just say the proxy server may not also run a
> normal TLS service.

Squid only supports normal TLS service. If the above command is not
producing proper TLS details that is the problem.

Amos


From uhlar at fantomas.sk  Sat Dec 21 09:42:14 2019
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sat, 21 Dec 2019 10:42:14 +0100
Subject: [squid-users] Is there a way on client to show proxy's
 certificate?
In-Reply-To: <1576908150187-0.post@n4.nabble.com>
References: <1576906041486-0.post@n4.nabble.com>
 <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
 <1576908150187-0.post@n4.nabble.com>
Message-ID: <20191221094214.GA4491@fantomas.sk>

>> The same openssl command can connect to any type of TLS server.

On 21.12.19 00:02, GeorgeShen wrote:
>True. But the proxy server may not run normal TLS service or listen on the
>port 443.
>The proxy with SSL-Bump is listening on the 3129 for example, I have
>certainly tried:
>
> openssl s_client -connect proxy-server-ip:3129 -showcert
>
>and that does not work. I'm just say the proxy server may not also run a
>normal TLS service.

how is port 3129 defined in squid.conf?

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Eagles may soar, but weasels don't get sucked into jet engines.


From robertkwild at gmail.com  Sat Dec 21 15:25:45 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Sat, 21 Dec 2019 15:25:45 +0000
Subject: [squid-users] c-icap documentation getting stuck
Message-ID: <CAGU_Ci+RsJuza=ywo6oomAZSBJ0YXU=j5G_rnLLcdWV_8k+b3A@mail.gmail.com>

hi all,

following this guide and so far so good

https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP

when i was configuring the clamav i followed this link

https://hostpresto.com/community/tutorials/how-to-install-clamav-on-centos-7/

im getting stuck on this bit

ln -s /var/lib/clamav /usr/local/clamav/share/clamav

theres no "/usr/local/clamav/share/clamav"

thanks all,
rob
-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191221/5821e55e/attachment.htm>

From squid3 at treenet.co.nz  Sat Dec 21 16:35:19 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 22 Dec 2019 05:35:19 +1300
Subject: [squid-users] c-icap documentation getting stuck
In-Reply-To: <CAGU_Ci+RsJuza=ywo6oomAZSBJ0YXU=j5G_rnLLcdWV_8k+b3A@mail.gmail.com>
References: <CAGU_Ci+RsJuza=ywo6oomAZSBJ0YXU=j5G_rnLLcdWV_8k+b3A@mail.gmail.com>
Message-ID: <46fa562d-cb78-ba40-8f9e-a64375430b91@treenet.co.nz>

On 22/12/19 4:25 am, robert k Wild wrote:
> hi all,
> 
> following this guide and so far so good
> 
> https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
> 
> when i was configuring the clamav i followed this link
> 
> https://hostpresto.com/community/tutorials/how-to-install-clamav-on-centos-7/
> 
> im getting stuck on this bit
> 
> ln -s /var/lib/clamav /usr/local/clamav/share/clamav
> 
> theres no "/usr/local/clamav/share/clamav"
> 

That command is for creating it.

Amos


From robertkwild at gmail.com  Sat Dec 21 17:48:27 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Sat, 21 Dec 2019 17:48:27 +0000
Subject: [squid-users] c-icap documentation getting stuck
In-Reply-To: <46fa562d-cb78-ba40-8f9e-a64375430b91@treenet.co.nz>
References: <CAGU_Ci+RsJuza=ywo6oomAZSBJ0YXU=j5G_rnLLcdWV_8k+b3A@mail.gmail.com>
 <46fa562d-cb78-ba40-8f9e-a64375430b91@treenet.co.nz>
Message-ID: <CAGU_CiKVbAec51jsNYi9cUXGOTD0TuOYE5jLTMdtF2FSc=m7_A@mail.gmail.com>

thanks Amos

i did this

mkdir -p /usr/local/clamav/share/clamav
ln -s /var/lib/clamav /usr/local/clamav/share/clamav

but how do i start up the c-icap service as that how to doesnt state how to
make a c-icap service?

thanks,
rob

On Sat, 21 Dec 2019 at 16:36, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 22/12/19 4:25 am, robert k Wild wrote:
> > hi all,
> >
> > following this guide and so far so good
> >
> > https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
> >
> > when i was configuring the clamav i followed this link
> >
> >
> https://hostpresto.com/community/tutorials/how-to-install-clamav-on-centos-7/
> >
> > im getting stuck on this bit
> >
> > ln -s /var/lib/clamav /usr/local/clamav/share/clamav
> >
> > theres no "/usr/local/clamav/share/clamav"
> >
>
> That command is for creating it.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191221/2ef0aa9c/attachment.htm>

From robertkwild at gmail.com  Sat Dec 21 18:28:02 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Sat, 21 Dec 2019 18:28:02 +0000
Subject: [squid-users] c-icap documentation getting stuck
In-Reply-To: <CAGU_CiKVbAec51jsNYi9cUXGOTD0TuOYE5jLTMdtF2FSc=m7_A@mail.gmail.com>
References: <CAGU_Ci+RsJuza=ywo6oomAZSBJ0YXU=j5G_rnLLcdWV_8k+b3A@mail.gmail.com>
 <46fa562d-cb78-ba40-8f9e-a64375430b91@treenet.co.nz>
 <CAGU_CiKVbAec51jsNYi9cUXGOTD0TuOYE5jLTMdtF2FSc=m7_A@mail.gmail.com>
Message-ID: <CAGU_CiJCjf0wu23hTZY7s7QW3hK19iS9wJmei2kPYPS++RrGgA@mail.gmail.com>

worked it out

but c-icap doesnt run, i get this error (only showing the error not the
whole info) -

/usr/local/bin/c-icap -N -D -d 10

Cannot open the pid file: /var/run/c-icap/c-icap.pid

but in my "c-icap.conf" the pid file is uncommented so i really dont know
why its not starting up

thanks,
rob

On Sat, 21 Dec 2019 at 17:48, robert k Wild <robertkwild at gmail.com> wrote:

> thanks Amos
>
> i did this
>
> mkdir -p /usr/local/clamav/share/clamav
> ln -s /var/lib/clamav /usr/local/clamav/share/clamav
>
> but how do i start up the c-icap service as that how to doesnt state how
> to make a c-icap service?
>
> thanks,
> rob
>
> On Sat, 21 Dec 2019 at 16:36, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
>> On 22/12/19 4:25 am, robert k Wild wrote:
>> > hi all,
>> >
>> > following this guide and so far so good
>> >
>> > https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
>> >
>> > when i was configuring the clamav i followed this link
>> >
>> >
>> https://hostpresto.com/community/tutorials/how-to-install-clamav-on-centos-7/
>> >
>> > im getting stuck on this bit
>> >
>> > ln -s /var/lib/clamav /usr/local/clamav/share/clamav
>> >
>> > theres no "/usr/local/clamav/share/clamav"
>> >
>>
>> That command is for creating it.
>>
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
> --
> Regards,
>
> Robert K Wild.
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191221/4dcf3135/attachment.htm>

From robertkwild at gmail.com  Sat Dec 21 18:42:27 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Sat, 21 Dec 2019 18:42:27 +0000
Subject: [squid-users] c-icap documentation getting stuck
In-Reply-To: <CAGU_CiJCjf0wu23hTZY7s7QW3hK19iS9wJmei2kPYPS++RrGgA@mail.gmail.com>
References: <CAGU_Ci+RsJuza=ywo6oomAZSBJ0YXU=j5G_rnLLcdWV_8k+b3A@mail.gmail.com>
 <46fa562d-cb78-ba40-8f9e-a64375430b91@treenet.co.nz>
 <CAGU_CiKVbAec51jsNYi9cUXGOTD0TuOYE5jLTMdtF2FSc=m7_A@mail.gmail.com>
 <CAGU_CiJCjf0wu23hTZY7s7QW3hK19iS9wJmei2kPYPS++RrGgA@mail.gmail.com>
Message-ID: <CAGU_CiKPBzjfoU+ffricH7qMeANYw=Tfs7XM9zujrdAg8q07Sw@mail.gmail.com>

finally getting somewhere, i did -

mkdir /var/run/c-icap
chown squid:squid /var/run/c-icap/
chmod 700 /var/run/c-icap/

and now when i run -

/usr/local/bin/c-icap -N -D -d 10

i dont get any errors but when i run the below i get warnings

 /usr/local/bin/c-icap
WARNING Bad configuration keyword: enable_libarchive 0
WARNING Bad configuration keyword: banmaxsize 2M

thanks,
rob




On Sat, 21 Dec 2019 at 18:28, robert k Wild <robertkwild at gmail.com> wrote:

> worked it out
>
> but c-icap doesnt run, i get this error (only showing the error not the
> whole info) -
>
> /usr/local/bin/c-icap -N -D -d 10
>
> Cannot open the pid file: /var/run/c-icap/c-icap.pid
>
> but in my "c-icap.conf" the pid file is uncommented so i really dont know
> why its not starting up
>
> thanks,
> rob
>
> On Sat, 21 Dec 2019 at 17:48, robert k Wild <robertkwild at gmail.com> wrote:
>
>> thanks Amos
>>
>> i did this
>>
>> mkdir -p /usr/local/clamav/share/clamav
>> ln -s /var/lib/clamav /usr/local/clamav/share/clamav
>>
>> but how do i start up the c-icap service as that how to doesnt state how
>> to make a c-icap service?
>>
>> thanks,
>> rob
>>
>> On Sat, 21 Dec 2019 at 16:36, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>
>>> On 22/12/19 4:25 am, robert k Wild wrote:
>>> > hi all,
>>> >
>>> > following this guide and so far so good
>>> >
>>> > https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
>>> >
>>> > when i was configuring the clamav i followed this link
>>> >
>>> >
>>> https://hostpresto.com/community/tutorials/how-to-install-clamav-on-centos-7/
>>> >
>>> > im getting stuck on this bit
>>> >
>>> > ln -s /var/lib/clamav /usr/local/clamav/share/clamav
>>> >
>>> > theres no "/usr/local/clamav/share/clamav"
>>> >
>>>
>>> That command is for creating it.
>>>
>>> Amos
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>
>>
>> --
>> Regards,
>>
>> Robert K Wild.
>>
>
>
> --
> Regards,
>
> Robert K Wild.
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191221/aa56d603/attachment.htm>

From alex at nanogherkin.com  Sat Dec 21 18:47:00 2019
From: alex at nanogherkin.com (Alex Crow)
Date: Sat, 21 Dec 2019 18:47:00 +0000
Subject: [squid-users] c-icap documentation getting stuck
In-Reply-To: <CAGU_CiKVbAec51jsNYi9cUXGOTD0TuOYE5jLTMdtF2FSc=m7_A@mail.gmail.com>
References: <CAGU_Ci+RsJuza=ywo6oomAZSBJ0YXU=j5G_rnLLcdWV_8k+b3A@mail.gmail.com>
 <46fa562d-cb78-ba40-8f9e-a64375430b91@treenet.co.nz>
 <CAGU_CiKVbAec51jsNYi9cUXGOTD0TuOYE5jLTMdtF2FSc=m7_A@mail.gmail.com>
Message-ID: <25812046-d255-33fd-fb39-9bac4a5290e0@nanogherkin.com>

robert,

I'd go the ecap way if I was you - no daemons to set up, just a library. 
c-icap has always been an issue as distros packages have never really 
acknowledged it exists in terms of permissions.

The ecap way avoids all of that mess entirely.

http://www.e-cap.org/docs/

http://www.e-cap.org/downloads/

https://wiki.squid-cache.org/Features/eCAP




From g2011828 at hotmail.com  Sat Dec 21 19:34:42 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Sat, 21 Dec 2019 13:34:42 -0600 (CST)
Subject: [squid-users] Is there a way on client to show proxy's
	certificate?
In-Reply-To: <20191221094214.GA4491@fantomas.sk>
References: <1576906041486-0.post@n4.nabble.com>
 <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
 <1576908150187-0.post@n4.nabble.com> <20191221094214.GA4491@fantomas.sk>
Message-ID: <1576956882170-0.post@n4.nabble.com>


> how is port 3129 defined in squid.conf? 

ssl_bump peek step1
ssl_bump stare step2
ssl_bump bump all
http_port 3128
http_port 3129 ssl-bump cert=/usr/local/squid/etc/ssl_cert/myCA.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
options=SINGLE_DH_USE:SINGLE_ECDH_USE
tls-dh=prime256v1:/usr/local/squid/etc/dhparams.pem

BTW, the https/TLS bump through this server works. when using the openssl
s_client, get this result,
(it says "no peer certificate available"):

$ openssl s_client -connect 192.168.1.35:3129 -showcerts
CONNECTED(00000003)
4659451500:error:1400410B:SSL routines:CONNECT_CR_SRVR_HELLO:wrong version
number:/BuildRoot/Library/Caches/com.apple.xbs/Sources/libressl/libressl-22.260.1/libressl-2.6/ssl/ssl_pkt.c:386:
---
no peer certificate available
---
No client certificate CA names sent
---
SSL handshake has read 5 bytes and written 0 bytes
---
New, (NONE), Cipher is (NONE)
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
SSL-Session:
    Protocol  : TLSv1.2
    Cipher    : 0000
    Session-ID: 
    Session-ID-ctx: 
    Master-Key: 
    Start Time: 1576955529
    Timeout   : 7200 (sec)
    Verify return code: 0 (ok)
---



and if I run this openssl s_client on the proxy itself (should use the same
version of openssl):

$ openssl s_client -connect 127.0.0.1:3129 -showcerts
CONNECTED(00000003)
140248349009560:error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown
protocol:s23_clnt.c:827:
---
no peer certificate available
---
No client certificate CA names sent
---
SSL handshake has read 7 bytes and written 311 bytes
---
New, (NONE), Cipher is (NONE)
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
SSL-Session:
    Protocol  : TLSv1.2
    Cipher    : 0000
    Session-ID: 
    Session-ID-ctx: 
    Master-Key: 
    Key-Arg   : None
    PSK identity: None
    PSK identity hint: None
    SRP username: None
    Start Time: 1576956256
    Timeout   : 300 (sec)
    Verify return code: 0 (ok)
---






--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From alex at nanogherkin.com  Sat Dec 21 22:54:12 2019
From: alex at nanogherkin.com (Alex Crow)
Date: Sat, 21 Dec 2019 22:54:12 +0000
Subject: [squid-users] c-icap documentation getting stuck
In-Reply-To: <CAGU_CiKPBzjfoU+ffricH7qMeANYw=Tfs7XM9zujrdAg8q07Sw@mail.gmail.com>
References: <CAGU_Ci+RsJuza=ywo6oomAZSBJ0YXU=j5G_rnLLcdWV_8k+b3A@mail.gmail.com>
 <46fa562d-cb78-ba40-8f9e-a64375430b91@treenet.co.nz>
 <CAGU_CiKVbAec51jsNYi9cUXGOTD0TuOYE5jLTMdtF2FSc=m7_A@mail.gmail.com>
 <CAGU_CiJCjf0wu23hTZY7s7QW3hK19iS9wJmei2kPYPS++RrGgA@mail.gmail.com>
 <CAGU_CiKPBzjfoU+ffricH7qMeANYw=Tfs7XM9zujrdAg8q07Sw@mail.gmail.com>
Message-ID: <82f2e784-988f-b8b1-9a56-fbf3da8bd8ec@nanogherkin.com>


>
> i dont get any errors but when i run the below i get warnings
>
> ?/usr/local/bin/c-icap
> WARNING Bad configuration keyword: enable_libarchive 0
> WARNING Bad configuration keyword: banmaxsize 2M
>
> thanks,
> rob
>
You should be asking these questions on whatever resources c-icap 
provide for that purpose, eg their GitHub issues page. c-icap is not 
related in any way to the Squid project.




From 0xff1f at gmail.com  Sun Dec 22 10:53:25 2019
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Sun, 22 Dec 2019 13:53:25 +0300
Subject: [squid-users] squid log responce time %6tr  or %tr ?
References: <82f2e784-988f-b8b1-9a56-fbf3da8bd8ec@nanogherkin.com>
Message-ID: <E3BAFED7-1F08-4D00-A61C-4CCCE905EB5D@gmail.com>

Hello Team ,

based on wiki :
http://www.squid-cache.org/Doc/config/logformat/ <http://www.squid-cache.org/Doc/config/logformat/>
tr is responce time , but im confused on why default response time configured as %6tr not %tr 

#################
logformat squid %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a %mt

##############


is there any difference between %tr and %6tr ?



Thanks 




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191222/d7f6defa/attachment.htm>

From uhlar at fantomas.sk  Sun Dec 22 12:56:49 2019
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sun, 22 Dec 2019 13:56:49 +0100
Subject: [squid-users] Is there a way on client to show proxy's
 certificate?
In-Reply-To: <1576956882170-0.post@n4.nabble.com>
References: <1576906041486-0.post@n4.nabble.com>
 <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
 <1576908150187-0.post@n4.nabble.com>
 <20191221094214.GA4491@fantomas.sk>
 <1576956882170-0.post@n4.nabble.com>
Message-ID: <20191222125649.GC5913@fantomas.sk>

>> how is port 3129 defined in squid.conf?

On 21.12.19 13:34, GeorgeShen wrote:
>ssl_bump peek step1
>ssl_bump stare step2
>ssl_bump bump all
>http_port 3128
>http_port 3129 ssl-bump cert=/usr/local/squid/etc/ssl_cert/myCA.pem
>generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>options=SINGLE_DH_USE:SINGLE_ECDH_USE
>tls-dh=prime256v1:/usr/local/squid/etc/dhparams.pem

this is http port, speaking http.  This is not a https port, so you can't
speak https to it.  The difference between 3128 and 3129 is, when you issue
CONNECT request to 3129, squid tries to communicate using SSL as if it was
the destination server (or, whatever you configure in ssl_bump options).

if you want to talk to squid on port 443, you must configure https_port.

>BTW, the https/TLS bump through this server works. when using the openssl
>s_client, get this result,
>(it says "no peer certificate available"):

this looks to me more like failure of setting up SSL protocol.
I really wonder something SSL related works  at all.

you should check with:

openssl s_client -proxy 192.168.1.35:3129 -connect <host:port> -showcerts

on both squid ports to see the difference.


>$ openssl s_client -connect 192.168.1.35:3129 -showcerts
>CONNECTED(00000003)
>4659451500:error:1400410B:SSL routines:CONNECT_CR_SRVR_HELLO:wrong version
>number:/BuildRoot/Library/Caches/com.apple.xbs/Sources/libressl/libressl-22.260.1/libressl-2.6/ssl/ssl_pkt.c:386:
>---
>no peer certificate available
>---
>No client certificate CA names sent
>---
>SSL handshake has read 5 bytes and written 0 bytes
>---
>New, (NONE), Cipher is (NONE)
>Secure Renegotiation IS NOT supported
>Compression: NONE
>Expansion: NONE
>No ALPN negotiated
>SSL-Session:
>    Protocol  : TLSv1.2
>    Cipher    : 0000
>    Session-ID:
>    Session-ID-ctx:
>    Master-Key:
>    Start Time: 1576955529
>    Timeout   : 7200 (sec)
>    Verify return code: 0 (ok)
>---
>
>
>
>and if I run this openssl s_client on the proxy itself (should use the same
>version of openssl):
>
>$ openssl s_client -connect 127.0.0.1:3129 -showcerts
>CONNECTED(00000003)
>140248349009560:error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown
>protocol:s23_clnt.c:827:
>---
>no peer certificate available
>---
>No client certificate CA names sent
>---
>SSL handshake has read 7 bytes and written 311 bytes
>---
>New, (NONE), Cipher is (NONE)
>Secure Renegotiation IS NOT supported
>Compression: NONE
>Expansion: NONE
>No ALPN negotiated
>SSL-Session:
>    Protocol  : TLSv1.2
>    Cipher    : 0000
>    Session-ID:
>    Session-ID-ctx:
>    Master-Key:
>    Key-Arg   : None
>    PSK identity: None
>    PSK identity hint: None
>    SRP username: None
>    Start Time: 1576956256
>    Timeout   : 300 (sec)
>    Verify return code: 0 (ok)
>---
>
>
>
>
>
>
>--
>Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
>_______________________________________________
>squid-users mailing list
>squid-users at lists.squid-cache.org
>http://lists.squid-cache.org/listinfo/squid-users

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
(R)etry, (A)bort, (C)ancer
 


From g2011828 at hotmail.com  Mon Dec 23 06:26:26 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Mon, 23 Dec 2019 00:26:26 -0600 (CST)
Subject: [squid-users] Is there a way on client to show proxy's
	certificate?
In-Reply-To: <20191222125649.GC5913@fantomas.sk>
References: <1576906041486-0.post@n4.nabble.com>
 <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
 <1576908150187-0.post@n4.nabble.com> <20191221094214.GA4491@fantomas.sk>
 <1576956882170-0.post@n4.nabble.com> <20191222125649.GC5913@fantomas.sk>
Message-ID: <1577082386236-0.post@n4.nabble.com>

>this is http port, speaking http.  This is not a https port, so you can't
>speak https to it.  The difference between 3128 and 3129 is, when you issue
>CONNECT request to 3129, squid tries to communicate using SSL as if it was
>the destination server (or, whatever you configure in ssl_bump options).

>if you want to talk to squid on port 443, you must configure https_port.

because I'm doing the explicit proxy for https on this proxy server. if I
configure
"https_port 3129 ssl-bump ...", then I get this error when doing the https
proxy:

2019/12/22 22:07:15| FATAL: ssl-bump on https_port requires tproxy/intercept
which is missing.

so this to me means, i can only configure https_port if I'm using the
intercept method, which I'm not.
Or is there a way to listern to the https_port with explicit proxy?

>>BTW, the https/TLS bump through this server works. when using the openssl
>>s_client, get this result,
>>(it says "no peer certificate available"):

>this looks to me more like failure of setting up SSL protocol.
>I really wonder something SSL related works  at all.
>you should check with:
>
>openssl s_client -proxy 192.168.1.35:3129 -connect <host:port> -showcerts
>
>on both squid ports to see the difference.

The above command works for me, but I only get the certs from the real host,
not the proxy server itself.

thanks.
George




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From g2011828 at hotmail.com  Mon Dec 23 06:45:05 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Mon, 23 Dec 2019 00:45:05 -0600 (CST)
Subject: [squid-users] Is there a way on client to show proxy's
	certificate?
In-Reply-To: <1577082386236-0.post@n4.nabble.com>
References: <1576906041486-0.post@n4.nabble.com>
 <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
 <1576908150187-0.post@n4.nabble.com> <20191221094214.GA4491@fantomas.sk>
 <1576956882170-0.post@n4.nabble.com> <20191222125649.GC5913@fantomas.sk>
 <1577082386236-0.post@n4.nabble.com>
Message-ID: <1577083505741-0.post@n4.nabble.com>


actually doing "openssl s_client -proxy 192.168.1.35:3129 -connect
<host:port> -showcerts ",
noticed two of the three certs from that display is from the proxy server I
think. the first one
is the modified host cert. maybe that's the way to get proxy server's certs.

thanks.
George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Mon Dec 23 07:22:14 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 Dec 2019 20:22:14 +1300
Subject: [squid-users] Is there a way on client to show proxy's
 certificate?
In-Reply-To: <1577083505741-0.post@n4.nabble.com>
References: <1576906041486-0.post@n4.nabble.com>
 <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
 <1576908150187-0.post@n4.nabble.com> <20191221094214.GA4491@fantomas.sk>
 <1576956882170-0.post@n4.nabble.com> <20191222125649.GC5913@fantomas.sk>
 <1577082386236-0.post@n4.nabble.com> <1577083505741-0.post@n4.nabble.com>
Message-ID: <e9a3b751-e4a6-82ef-ebab-6fc708e27e6f@treenet.co.nz>

On 23/12/19 7:45 pm, GeorgeShen wrote:
> 
> actually doing "openssl s_client -proxy 192.168.1.35:3129 -connect
> <host:port> -showcerts ",
> noticed two of the three certs from that display is from the proxy server I
> think. the first one
> is the modified host cert. maybe that's the way to get proxy server's certs.
> 

You are using SSL-Bump. There is no "proxy cert" in these connections.
There is only client cert (optional) and server cert (possibly modified
by Squid, with CA chain).

What you see there is what exists in the traffic.

Amos


From squid3 at treenet.co.nz  Mon Dec 23 09:37:45 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 Dec 2019 22:37:45 +1300
Subject: [squid-users] Is there a way on client to show proxy's
 certificate?
In-Reply-To: <1577082386236-0.post@n4.nabble.com>
References: <1576906041486-0.post@n4.nabble.com>
 <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
 <1576908150187-0.post@n4.nabble.com> <20191221094214.GA4491@fantomas.sk>
 <1576956882170-0.post@n4.nabble.com> <20191222125649.GC5913@fantomas.sk>
 <1577082386236-0.post@n4.nabble.com>
Message-ID: <9e9869ef-7cf7-c85f-454e-488ef04b027b@treenet.co.nz>

On 23/12/19 7:26 pm, GeorgeShen wrote:
>> this is http port, speaking http.  This is not a https port, so you can't
>> speak https to it.  The difference between 3128 and 3129 is, when you issue
>> CONNECT request to 3129, squid tries to communicate using SSL as if it was
>> the destination server (or, whatever you configure in ssl_bump options).
> 
>> if you want to talk to squid on port 443, you must configure https_port.
> 
> because I'm doing the explicit proxy for https on this proxy server. if I
> configure
> "https_port 3129 ssl-bump ...",

That is port 3129, not port 443.


> then I get this error when doing the https
> proxy:
> 
> 2019/12/22 22:07:15| FATAL: ssl-bump on https_port requires tproxy/intercept
> which is missing.
> 
> so this to me means, i can only configure https_port if I'm using the
> intercept method, which I'm not.

That is saying the "ssl-bump" flag requires "intercept" on that port
directive.

SSL-Bump is intercepting the TLS layer. It makes no sense for a client
to explicitly open TCP connections to Squid when trying to perform TLS
with a different server elsewhere.


> Or is there a way to listern to the https_port with explicit proxy?

There is. Remove the ssl-bump stuff from that https_port line. Configure
it with a regular server cert and key. What you have then is an
"explicit TLS proxy" - a proxy clients need to use TLS to communicate with.


> 
>>> BTW, the https/TLS bump through this server works. when using the openssl
>>> s_client, get this result,
>>> (it says "no peer certificate available"):
> 
>> this looks to me more like failure of setting up SSL protocol.
>> I really wonder something SSL related works  at all.
>> you should check with:
>>
>> openssl s_client -proxy 192.168.1.35:3129 -connect <host:port> -showcerts
>>
>> on both squid ports to see the difference.
> 
> The above command works for me, but I only get the certs from the real host,
> not the proxy server itself.


You seem(ed) to be in some confusion about what "the certs" actually
are. See my earlier response about that output.

Amos


From vieridipaola at gmail.com  Mon Dec 23 10:53:06 2019
From: vieridipaola at gmail.com (Vieri Di Paola)
Date: Mon, 23 Dec 2019 11:53:06 +0100
Subject: [squid-users] c-icap documentation getting stuck
In-Reply-To: <CAGU_CiKPBzjfoU+ffricH7qMeANYw=Tfs7XM9zujrdAg8q07Sw@mail.gmail.com>
References: <CAGU_Ci+RsJuza=ywo6oomAZSBJ0YXU=j5G_rnLLcdWV_8k+b3A@mail.gmail.com>
 <46fa562d-cb78-ba40-8f9e-a64375430b91@treenet.co.nz>
 <CAGU_CiKVbAec51jsNYi9cUXGOTD0TuOYE5jLTMdtF2FSc=m7_A@mail.gmail.com>
 <CAGU_CiJCjf0wu23hTZY7s7QW3hK19iS9wJmei2kPYPS++RrGgA@mail.gmail.com>
 <CAGU_CiKPBzjfoU+ffricH7qMeANYw=Tfs7XM9zujrdAg8q07Sw@mail.gmail.com>
Message-ID: <CABLYT9gPr4g3Mc1eh4k3683CNgz5DxBxKxNzxRiT7ip8ggaH0A@mail.gmail.com>

On Sat, Dec 21, 2019 at 7:42 PM robert k Wild <robertkwild at gmail.com> wrote:
>
> WARNING Bad configuration keyword: enable_libarchive 0
> WARNING Bad configuration keyword: banmaxsize 2M

You're probably running an outdated squidclamav.


From rousskov at measurement-factory.com  Mon Dec 23 16:38:22 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 23 Dec 2019 11:38:22 -0500
Subject: [squid-users] squid log responce time %6tr or %tr ?
In-Reply-To: <E3BAFED7-1F08-4D00-A61C-4CCCE905EB5D@gmail.com>
References: <82f2e784-988f-b8b1-9a56-fbf3da8bd8ec@nanogherkin.com>
 <E3BAFED7-1F08-4D00-A61C-4CCCE905EB5D@gmail.com>
Message-ID: <c9821099-f3e2-e5b7-2dea-3004b12533c6@measurement-factory.com>

On 12/22/19 5:53 AM, Ahmad Alzaeem wrote:

> im confused on why default response time configured as %6tr not %tr

Many Squid developers look at raw access logs. I suspect early Squid
developers wanted to first (or "left") access.log fields at a semi-fixed
position. Making most response time entries 6 characters long helps with
that goal.


> is there any difference between %tr and %6tr ?

Yes, %6tr is padded with spaces on the left (if its value is smaller
than 1000000) to make the entire value at least 6 characters long. This
is semi-documented in logformat directive description (look for
"width"): http://www.squid-cache.org/Doc/config/logformat/

Alex.


From g2011828 at hotmail.com  Mon Dec 23 18:55:14 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Mon, 23 Dec 2019 12:55:14 -0600 (CST)
Subject: [squid-users] Is there a way on client to show proxy's
	certificate?
In-Reply-To: <e9a3b751-e4a6-82ef-ebab-6fc708e27e6f@treenet.co.nz>
References: <1576906041486-0.post@n4.nabble.com>
 <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
 <1576908150187-0.post@n4.nabble.com> <20191221094214.GA4491@fantomas.sk>
 <1576956882170-0.post@n4.nabble.com> <20191222125649.GC5913@fantomas.sk>
 <1577082386236-0.post@n4.nabble.com> <1577083505741-0.post@n4.nabble.com>
 <e9a3b751-e4a6-82ef-ebab-6fc708e27e6f@treenet.co.nz>
Message-ID: <1577127314245-0.post@n4.nabble.com>


>> actually doing "openssl s_client -proxy 192.168.1.35:3129 -connect
>> <host:port> -showcerts ",
>> noticed two of the three certs from that display is from the proxy server
>> I
>> think. the first one
>> is the modified host cert. maybe that's the way to get proxy server's
>> certs.
>> 

>You are using SSL-Bump. There is no "proxy cert" in these connections.
>There is only client cert (optional) and server cert (possibly modified
>by Squid, with CA chain).
>
>What you see there is what exists in the traffic.

Sorry, but when I run the above openssl command, I do get three certs, first
one is
the modified server cert, the 2nd and third certs are the squid proxy's
certs. Yes the
proxy is configured to do the SSL-BUMP on port 3129. I would think the proxy
needs to
send it's certs to the client for that part of the TLS connection. Can this
explain I'm receiving
the proxy's cert ?

thanks.
- George




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Tue Dec 24 01:49:55 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 24 Dec 2019 14:49:55 +1300
Subject: [squid-users] Is there a way on client to show proxy's
 certificate?
In-Reply-To: <1577127314245-0.post@n4.nabble.com>
References: <1576906041486-0.post@n4.nabble.com>
 <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
 <1576908150187-0.post@n4.nabble.com> <20191221094214.GA4491@fantomas.sk>
 <1576956882170-0.post@n4.nabble.com> <20191222125649.GC5913@fantomas.sk>
 <1577082386236-0.post@n4.nabble.com> <1577083505741-0.post@n4.nabble.com>
 <e9a3b751-e4a6-82ef-ebab-6fc708e27e6f@treenet.co.nz>
 <1577127314245-0.post@n4.nabble.com>
Message-ID: <dd0b8987-c2b6-bea1-46af-cce2633a7a1a@treenet.co.nz>

On 24/12/19 7:55 am, GeorgeShen wrote:
> 
>>> actually doing "openssl s_client -proxy 192.168.1.35:3129 -connect
>>> <host:port> -showcerts ",
>>> noticed two of the three certs from that display is from the proxy server
>>> I
>>> think. the first one
>>> is the modified host cert. maybe that's the way to get proxy server's
>>> certs.
>>>
> 
>> You are using SSL-Bump. There is no "proxy cert" in these connections.
>> There is only client cert (optional) and server cert (possibly modified
>> by Squid, with CA chain).
>>
>> What you see there is what exists in the traffic.
> 
> Sorry, but when I run the above openssl command, I do get three certs, first
> one is
> the modified server cert, the 2nd and third certs are the squid proxy's
> certs.

No. You receive a server cert and the CA chain required to validate that
server cert.

Stop thinking of certs as belonging to the proxy. It seems to be
confusing you. All 3 certs can be called "the proxy's certs" and yet
none of them is a "proxy cert" in TLS definitions.

Amos


From g2011828 at hotmail.com  Tue Dec 24 02:47:59 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Mon, 23 Dec 2019 20:47:59 -0600 (CST)
Subject: [squid-users] Is there a way on client to show proxy's
	certificate?
In-Reply-To: <dd0b8987-c2b6-bea1-46af-cce2633a7a1a@treenet.co.nz>
References: <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
 <1576908150187-0.post@n4.nabble.com> <20191221094214.GA4491@fantomas.sk>
 <1576956882170-0.post@n4.nabble.com> <20191222125649.GC5913@fantomas.sk>
 <1577082386236-0.post@n4.nabble.com> <1577083505741-0.post@n4.nabble.com>
 <e9a3b751-e4a6-82ef-ebab-6fc708e27e6f@treenet.co.nz>
 <1577127314245-0.post@n4.nabble.com>
 <dd0b8987-c2b6-bea1-46af-cce2633a7a1a@treenet.co.nz>
Message-ID: <1577155679286-0.post@n4.nabble.com>



>No. You receive a server cert and the CA chain required to validate that
>server cert.
>
>Stop thinking of certs as belonging to the proxy. It seems to be
>confusing you. All 3 certs can be called "the proxy's certs" and yet
>none of them is a "proxy cert" in TLS definitions.

Amos,

but those two certs the client got is the certificate I created for the
proxy, and it is defined on the 'ssl-bump' line
cert=/usr/local/squid/etc/ssl_cert/myCA.pem. That myCA.pem has a private key
and a certificate, the client 'openssl s_client' receives two of the certs
are that certificate. I thought this had to be the 'proxy' cert. 

thanks.
- George




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From g2011828 at hotmail.com  Tue Dec 24 02:57:03 2019
From: g2011828 at hotmail.com (GeorgeShen)
Date: Mon, 23 Dec 2019 20:57:03 -0600 (CST)
Subject: [squid-users] Is there a way on client to show proxy's
	certificate?
In-Reply-To: <9e9869ef-7cf7-c85f-454e-488ef04b027b@treenet.co.nz>
References: <1576906041486-0.post@n4.nabble.com>
 <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
 <1576908150187-0.post@n4.nabble.com> <20191221094214.GA4491@fantomas.sk>
 <1576956882170-0.post@n4.nabble.com> <20191222125649.GC5913@fantomas.sk>
 <1577082386236-0.post@n4.nabble.com>
 <9e9869ef-7cf7-c85f-454e-488ef04b027b@treenet.co.nz>
Message-ID: <1577156223953-0.post@n4.nabble.com>


>That is saying the "ssl-bump" flag requires "intercept" on that port
>directive.
>
>SSL-Bump is intercepting the TLS layer. It makes no sense for a client
>to explicitly open TCP connections to Squid when trying to perform TLS
>with a different server elsewhere.

but my proxy's purpose is to do the 'SSL-BUMP', with my config:

ssl_bump peek step1
ssl_bump stare step2
ssl_bump bump all
acl SSL_ports port 443
acl CONNECT method CONNECT
http_port 3128
http_port 3129 ssl-bump cert=/usr/local/squid/etc/ssl_cert/myCA.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
options=SINGLE_DH_USE:SINGLE_ECDH_USE
tls-dh=prime256v1:/usr/local/squid/etc/dhparams.pem

the ssl-bump through this proxy seems to work. am i doing this incorrectly?

>
>> Or is there a way to listern to the https_port with explicit proxy?
>
>There is. Remove the ssl-bump stuff from that https_port line. Configure
>it with a regular server cert and key. What you have then is an
>"explicit TLS proxy" - a proxy clients need to use TLS to communicate with.

if I change the above configure to (still want to do ssl-bump operation):

http_port 3128
https_port 3129 cert=/usr/local/squid/etc/ssl_cert/myCA.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
options=SINGLE_DH_USE:SINGLE_ECDH_USE
tls-dh=prime256v1:/usr/local/squid/etc/dhparams.pem

then the wget can not get through this proxy:
$ export https_proxy=192.168.1.35:3129
 wget https://www.cnn.com
--2019-12-23 14:34:22--  https://www.cnn.com/
Connecting to 192.168.1.35:3129... connected.
Failed reading proxy response: Connection reset by peer
Retrying.

did I configure it wrong?

thanks.
- George





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Tue Dec 24 06:40:48 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 24 Dec 2019 19:40:48 +1300
Subject: [squid-users] Is there a way on client to show proxy's
 certificate?
In-Reply-To: <1577155679286-0.post@n4.nabble.com>
References: <f169a908-e889-5875-d2fc-e9312bf719a8@treenet.co.nz>
 <1576908150187-0.post@n4.nabble.com> <20191221094214.GA4491@fantomas.sk>
 <1576956882170-0.post@n4.nabble.com> <20191222125649.GC5913@fantomas.sk>
 <1577082386236-0.post@n4.nabble.com> <1577083505741-0.post@n4.nabble.com>
 <e9a3b751-e4a6-82ef-ebab-6fc708e27e6f@treenet.co.nz>
 <1577127314245-0.post@n4.nabble.com>
 <dd0b8987-c2b6-bea1-46af-cce2633a7a1a@treenet.co.nz>
 <1577155679286-0.post@n4.nabble.com>
Message-ID: <161417b0-f4ef-0e3f-1c98-32a5e298a17f@treenet.co.nz>

On 24/12/19 3:47 pm, GeorgeShen wrote:
> 
> 
>> No. You receive a server cert and the CA chain required to validate that
>> server cert.
>>
>> Stop thinking of certs as belonging to the proxy. It seems to be
>> confusing you. All 3 certs can be called "the proxy's certs" and yet
>> none of them is a "proxy cert" in TLS definitions.
> 
> Amos,
> 
> but those two certs the client got is the certificate I created for the
> proxy, and it is defined on the 'ssl-bump' line
> cert=/usr/local/squid/etc/ssl_cert/myCA.pem. That myCA.pem has a private key
> and a certificate, the client 'openssl s_client' receives two of the certs
> are that certificate. I thought this had to be the 'proxy' cert. 


Lets start with some of the basics:

TLS has the concept of a "proxy cert" - that is a certificate with a
flag stating that the server type is a proxy. That makes modifications
to how things like SNI, same-origin protections and nested encryption
are handled in clients. The traffic inside the TLS is the same as you
would see on port 3128 - its just encrypted now.


The "cert you put in the proxy" for SSL-Bump should be a CA cert. Either
a root/self-signed or intermediate CA cert. That type of cert can sign
other certs. SSL-Bump generates the 'modified host cert' and needs a CA
to sign it. The client thinks it is talking to an origin server - the
traffic inside the TLS is usually the same as you would see on port 80.


I hope that makes the situation(s) clear? (I am simplifying a few
things. But they should not matter to the basic understanding.)

If you are looking to view the cert the proxy has been _configured with_
on an ssl-bump port that 'cert' is the *entire chain* of CAs following
the server cert you called the "modified host cert". Some will have been
loaded through 'cert=' and some maybe loaded through other directives
(eg cafile or capath).


Amos


From robertkwild at gmail.com  Fri Dec 27 19:15:49 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Fri, 27 Dec 2019 19:15:49 +0000
Subject: [squid-users] squidclamav cant connect to clamd service
Message-ID: <CAGU_CiLfoNorfqCjWScpJVROCZHdJZTemNZ+vYUTX-tdFnf4Kg@mail.gmail.com>

hi all,

ive been struggling with this for a few weeks and hopefully one of you guys
can help me out as im struggling finding solutions

ive installed on my centos 7 vm machine

c-icap

c-icap modules

http://c-icap.sourceforge.net/download.html

squid 4.9

http://www.squid-cache.org/Versions/v4/

clamav

https://hostpresto.com/community/tutorials/how-to-install-clamav-on-centos-7/

squidclamav

https://sourceforge.net/projects/squidclamav/files/latest/download

and i followed this guide compiling them from source with the configure
options make and make install on all of them

https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP

squid works as a proxy just fine, just struggling with the c-icap with
squidclamav part

this is the error i get -

Sun Dec 22 21:40:44 2019, 1586/40797952, squidclamav.c(2081) dconnect: Sun
Dec 22 21:40:44 2019, 1586/40797952, ERROR Can't connect to clamd on local
socket /run/clamd.scan/clamd.sock.
Sun Dec 22 21:40:44 2019, 1586/40797952, squidclamav.c(787)
squidclamav_end_of_data_handler: Sun Dec 22 21:40:44 2019, 1586/40797952,
ERROR Can't connect to Clamd daemon.
Mon Dec 23 10:10:11 2019, main proc, c-icap server already running!
Mon Dec 23 10:37:44 2019, main proc, c-icap server already running!
[root at squid ~]# ls /run/clamd.scan/
[root at squid ~]#

but i have changed all my services to a /services directory and there all
running -

[root at squid ~]# ls /services/c-icap/
c-icap.ctl c-icap.pid
[root at squid ~]# ls /services/clamd.scan/
clamd.sock
[root at squid ~]#

so my question is why is squidclamav still looking in
"/run/clamd.scan/clamd.sock"

i have even specified in my "/etc/squidclamav.conf" where the clamd service
is

# clamd_port to the corresponding value.
clamd_local /services/clamd.scan/clamd.sock
#clamd_ip 127.0.0.1
#clamd_port 3310
but i have resolved it by this :)

so in my squid.conf i added the c-icap lines using this site as the link i
gave, gave a c-icap protocol error, everytime i opened a web page

https://www.server-world.info/en/note?os=CentOS_7&p=squid&f=5 (the c-icap
lines are at the end of the guide)

i also did this

vi /etc/tmpfiles.d/c-icap.conf
d /run/c-icap 0770 root root -

vi /etc/tmpfiles.d/clamd.scan.conf
d /run/clamd.scan 0770 root root -

i also made c-icap.conf and clamd.d/scan.conf, i made the user root just to
make my life a lot easier not to run into any troubleshooting problems

and finally this command to re-initialise squidclamav with the c-icap
configs

echo -n "squidclamav:cfgreload" > /run/c-icap/c-icap.ctl

then when i went on the http://www.eicar.org/download/eicar_com.zip

i got a virus found
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191227/e46e09fb/attachment.htm>

From robertkwild at gmail.com  Sun Dec 29 03:23:18 2019
From: robertkwild at gmail.com (robert k Wild)
Date: Sun, 29 Dec 2019 03:23:18 +0000
Subject: [squid-users] error running c-icap in squidclamav.conf
Message-ID: <CAGU_CiKO54b8estU_NNAc3oSR9DwsGEBkbbNivCk=4D1vmhtvQ@mail.gmail.com>

hi all,
got 2 errors while running c-icap

[root at lon-p-sigrly01 c_icap_modules-0.5.4]# /usr/local/bin/c-icap
WARNING Bad configuration keyword: enable_libarchive 0
WARNING Bad configuration keyword: banmaxsize 2M
[root at lon-p-sigrly01 c_icap_modules-0.5.4]#

i have installed the latest version of squidclamav (7.1) and c-icap (0.5.6)
with the modules (0.5.4) but im still getting these errors
any ideas why?

thanks
rob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20191229/85e4f0e7/attachment.htm>

From bob.wooldridge at edm-inc.com  Mon Dec 30 21:08:33 2019
From: bob.wooldridge at edm-inc.com (Robert A Wooldridge)
Date: Mon, 30 Dec 2019 15:08:33 -0600
Subject: [squid-users] Switched ISP
Message-ID: <1158f876-6043-ed00-b8d2-c19a178364bd@edm-inc.com>

We recently switched to ATT from Windstream.? After the switch there is 
a very large difference between accessing sites through squid compared 
to bypassing squid (squid is slower).? However it is not completely 
uniform.? Some sites are extremely slow and do not load at all. 
news.yahoo.com is an example.? Is there anything I should be aware of 
when switching to a different ISP?? Would the lack of a PTR record on 
the proxy server have any effect on this? Should I clear squid's cache?

Thanks?

-- 
Bob Wooldridge
EDM Incorporated



From rousskov at measurement-factory.com  Mon Dec 30 22:51:35 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 30 Dec 2019 17:51:35 -0500
Subject: [squid-users] Switched ISP
In-Reply-To: <1158f876-6043-ed00-b8d2-c19a178364bd@edm-inc.com>
References: <1158f876-6043-ed00-b8d2-c19a178364bd@edm-inc.com>
Message-ID: <ee1bddb5-d8e7-3b5d-c09b-2b9bdf23f988@measurement-factory.com>

On 12/30/19 4:08 PM, Robert A Wooldridge wrote:
> We recently switched to ATT from Windstream.? After the switch there is
> a very large difference between accessing sites through squid compared
> to bypassing squid (squid is slower).? However it is not completely
> uniform.? Some sites are extremely slow and do not load at all.
> news.yahoo.com is an example.? Is there anything I should be aware of
> when switching to a different ISP?? Would the lack of a PTR record on
> the proxy server have any effect on this? Should I clear squid's cache?

0. A lack of PTR record will slow down origin servers that try to
resolve your proxy IP address and (slowly?) fail. I do not know how
typical such sites are.

1. Are the problems related to sites that have IPv6 addresses (even
though access.log may show IPv4 transactions)? YMMV, but some ISP
networks enable IPv6 while not supporting it well, leading to random
IPv6 connection establishment timeouts.

2. Are you using AT&T's DNS resolver? YMMV, but some ISP DNS resolvers
overwrite NXDOMAIN responses. Such overwrites might have unexpected side
effects on complex sites.

Your best bet may be in triaging a single easier-to-reproduce problem
and extrapolating from there.

AFAICT, it should not be necessary to purge Squid's cache when switching
ISPs, but you can easily test by setting that cache aside and starting
Squid without it.


HTH,

Alex.


