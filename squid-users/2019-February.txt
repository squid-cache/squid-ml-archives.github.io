From squid3 at treenet.co.nz  Fri Feb  1 06:44:57 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 1 Feb 2019 19:44:57 +1300
Subject: [squid-users] Squid doesn't execute url_rewrite_program
 /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
In-Reply-To: <CAG2Qp6uNz-sKVMqbjH_OHpLZK=bALLT5gSyyjhcfi2NyEpUkBg@mail.gmail.com>
References: <CAG2Qp6uNz-sKVMqbjH_OHpLZK=bALLT5gSyyjhcfi2NyEpUkBg@mail.gmail.com>
Message-ID: <09127802-b4b8-7ceb-3df6-33059842907b@treenet.co.nz>

On 1/02/19 8:48 am, Roberto Carna wrote:
> Dear, I have Squid 3.5.23 and I use Squidguard for URL and domain filtering.
> 
> In squid.conf I have this line:
> 
> url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
> 
> but in this proxy server, the line is not executed by Squid, so
> Squidguard doesn't work at all.
> 
> Same configuration in another proxy server works OK.
> 
> Please can you tell me how I can force the execution of
> url_rewrite_program line ???


If the helper is not even being started:

Check cache.log

Check that the Squid low-privileges user account is allowed to run that
helper.

Check that there are not other copies of the line replacing the helper
with another later in the config. That includes the
backward-compatibility alias of this directive: redirector_program.

Check what startup=N option to the url_rewrite_children (and alias
redirector_children) are using. If it is set to '0' the helper will not
be started until it is necessary to handle a URL.


If the helper is starting but crashing or exiting immediately (see
cache.log):

Check that your version of SquidGuard has been patched to comply with
the Squid-3.4+ helper protocol.

Check that the Squid low-privileges user account is allowed to run that
helper.


If the helper is running but appears not to be doing anything:

Check your url_rewrite_access lines (and alias redirector_access) to
ensure that the traffic you want to re-write is allowed to be passed to
the helper.


PS. Please consider using ufdbguard instead of SquidGuard which has not
been maintained in many years.

Amos


From squid3 at treenet.co.nz  Fri Feb  1 07:37:53 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 1 Feb 2019 20:37:53 +1300
Subject: [squid-users] using clang to compile squid 4-5
In-Reply-To: <532bd24f-f92e-a3ad-2aee-c628c2a0c894@treenet.co.nz>
References: <289180401.107999.1548837503168@mail.yahoo.com>
 <vmime.5c51ccde.3cc6.66e612638aa7be@ms249-lin-003.rotterdam.bazuin.nl>
 <532bd24f-f92e-a3ad-2aee-c628c2a0c894@treenet.co.nz>
Message-ID: <ae7a51e1-e54d-97be-d161-3b3b811d6290@treenet.co.nz>

On 31/01/19 9:22 am, Amos Jeffries wrote:
> On 31/01/19 5:12 am, L.P.H. van Belle wrote:
>> Hai, 
>>
>> Good to hear there are more then Luigi :-) 
>>
>> I builded debian packages yesterday for squid 4.5 
>> Which was pretty simple and worked fine in the end. 
>>
>> Get the source of 4.4  ( apt-get source -t unstable squid  )
>> Copy the debian folder from 4.4 into the 4.5 folder.
>>
>> And changed in the changelog the squid version, builded fine. 
>> Test build failed, my change was. 
>>
>> diff squid-4.4/debian/rules squid-4.5/debian/rules
>> 22c22
>> < DEB_INSTALL_DOCS_squid-common := debian/copyright CONTRIBUTORS CREDITS QUICKSTART RELEASENOTES.html SPONSORS
>> ---
>>> DEB_INSTALL_DOCS_squid-common := debian/copyright CONTRIBUTORS CREDITS QUICKSTART SPONSORS
>>
>> 4.5 was missing : RELEASENOTES.html 
>> Uhm must say, i builded the "squid-4.5-20190128-r568e66b7c" version. 
> 
> Aye, looking into that is on my worklist for this weekend while waiting
> for the release prep testing.
> 

I am not seeing this error with GCC-8.2.0-15 on the Debian package or
the pkg-squid repo with v4.5 release in it, or my local v4 checkout of
r568e66b7c.


Amos


From grafhuy at yahoo.fr  Fri Feb  1 10:17:48 2019
From: grafhuy at yahoo.fr (graf huy)
Date: Fri, 1 Feb 2019 10:17:48 +0000 (UTC)
Subject: [squid-users] using clang to compile squid 4-5
In-Reply-To: <ae7a51e1-e54d-97be-d161-3b3b811d6290@treenet.co.nz>
References: <289180401.107999.1548837503168@mail.yahoo.com>
 <vmime.5c51ccde.3cc6.66e612638aa7be@ms249-lin-003.rotterdam.bazuin.nl>
 <532bd24f-f92e-a3ad-2aee-c628c2a0c894@treenet.co.nz>
 <ae7a51e1-e54d-97be-d161-3b3b811d6290@treenet.co.nz>
Message-ID: <1098058608.2500656.1549016268315@mail.yahoo.com>

 Hi,
>I'm not sure I follow that. Are you building with patched GCC? or a
>patched libc? or something else?
No, these are the versions used.
 
(ldd --version)

ldd (Debian GLIBC2.28-5) 2.28

Copyright ? 2018Free Software Foundation, Inc.







 (gcc -v)

Using built-inspecs.

COLLECT_GCC=gcc

COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/8/lto-wrapper

OFFLOAD_TARGET_NAMES=nvptx-none

OFFLOAD_TARGET_DEFAULT=1

Target:x86_64-linux-gnu

Configured with:../src/configure -v --with-pkgversion='Debian 8.2.0-14'--with-bugurl=file:///usr/share/doc/gcc-8/README.Bugs--enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++--prefix=/usr --with-gcc-major-version-only --program-suffix=-8--program-prefix=x86_64-linux-gnu- --enable-shared--enable-linker-build-id --libexecdir=/usr/lib--without-included-gettext --enable-threads=posix --libdir=/usr/lib--enable-nls --enable-clocale=gnu --enable-libstdcxx-debug--enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new--enable-gnu-unique-object --disable-vtable-verify --enable-libmpx--enable-plugin --enable-default-pie --with-system-zlib--with-target-system-zlib --enable-objc-gc=auto --enable-multiarch--disable-werror --with-arch-32=i686 --with-abi=m64--with-multilib-list=m32,m64,mx32 --enable-multilib--with-tune=generic --enable-offload-targets=nvptx-none--without-cuda-driver --enable-checking=release--build=x86_64-linux-gnu --host=x86_64-linux-gnu--target=x86_64-linux-gnu

Thread model: posix

gcc version 8.2.0(Debian 8.2.0-14) 

Kind regards.
    Le vendredi 1 f?vrier 2019 ? 08:38:32 UTC+1, Amos Jeffries <squid3 at treenet.co.nz> a ?crit :  
 
 On 31/01/19 9:22 am, Amos Jeffries wrote:
> On 31/01/19 5:12 am, L.P.H. van Belle wrote:
>> Hai, 
>>
>> Good to hear there are more then Luigi :-) 
>>
>> I builded debian packages yesterday for squid 4.5 
>> Which was pretty simple and worked fine in the end. 
>>
>> Get the source of 4.4? ( apt-get source -t unstable squid? )
>> Copy the debian folder from 4.4 into the 4.5 folder.
>>
>> And changed in the changelog the squid version, builded fine. 
>> Test build failed, my change was. 
>>
>> diff squid-4.4/debian/rules squid-4.5/debian/rules
>> 22c22
>> < DEB_INSTALL_DOCS_squid-common := debian/copyright CONTRIBUTORS CREDITS QUICKSTART RELEASENOTES.html SPONSORS
>> ---
>>> DEB_INSTALL_DOCS_squid-common := debian/copyright CONTRIBUTORS CREDITS QUICKSTART SPONSORS
>>
>> 4.5 was missing : RELEASENOTES.html 
>> Uhm must say, i builded the "squid-4.5-20190128-r568e66b7c" version. 
> 
> Aye, looking into that is on my worklist for this weekend while waiting
> for the release prep testing.
> 

I am not seeing this error with GCC-8.2.0-15 on the Debian package or
the pkg-squid repo with v4.5 release in it, or my local v4 checkout of
r568e66b7c.


Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190201/c066e01e/attachment.htm>

From robertocarna36 at gmail.com  Fri Feb  1 18:56:11 2019
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Fri, 1 Feb 2019 15:56:11 -0300
Subject: [squid-users] Squid doesn't execute url_rewrite_program
 /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
In-Reply-To: <09127802-b4b8-7ceb-3df6-33059842907b@treenet.co.nz>
References: <CAG2Qp6uNz-sKVMqbjH_OHpLZK=bALLT5gSyyjhcfi2NyEpUkBg@mail.gmail.com>
 <09127802-b4b8-7ceb-3df6-33059842907b@treenet.co.nz>
Message-ID: <CAG2Qp6tJBJs6AV3tqGw3P-eYxzqwfTb12mo9qpGdeN9v6u2Y5A@mail.gmail.com>

Dear Amos, thanks for your comments.

I realized that I have some clues in cache.log:

2019/02/01 15:51:44 kid1| helperOpenServers: Starting 0/20 'squidGuard'
processes
2019/02/01 15:51:44 kid1| helperOpenServers: No 'squidGuard' processes
needed.
2019/02/01 15:51:44 kid1| helperOpenServers: Starting 0/5 'squid_ldap_auth'
processes
2019/02/01 15:51:44 kid1| helperOpenServers: No 'squid_ldap_auth' processes
needed.

These lines appears after I execute "systemctl reload squid".

Users and rights are OK.

Please can you help me one more time?

Because I have compared squid.conf and squidGuard.conf between this server
and the other running OK, and both files are similar.

Thanking in advance.

Robert



El vie., 1 feb. 2019 a las 3:45, Amos Jeffries (<squid3 at treenet.co.nz>)
escribi?:

> On 1/02/19 8:48 am, Roberto Carna wrote:
> > Dear, I have Squid 3.5.23 and I use Squidguard for URL and domain
> filtering.
> >
> > In squid.conf I have this line:
> >
> > url_rewrite_program /usr/bin/squidGuard -c
> /etc/squidguard/squidGuard.conf
> >
> > but in this proxy server, the line is not executed by Squid, so
> > Squidguard doesn't work at all.
> >
> > Same configuration in another proxy server works OK.
> >
> > Please can you tell me how I can force the execution of
> > url_rewrite_program line ???
>
>
> If the helper is not even being started:
>
> Check cache.log
>
> Check that the Squid low-privileges user account is allowed to run that
> helper.
>
> Check that there are not other copies of the line replacing the helper
> with another later in the config. That includes the
> backward-compatibility alias of this directive: redirector_program.
>
> Check what startup=N option to the url_rewrite_children (and alias
> redirector_children) are using. If it is set to '0' the helper will not
> be started until it is necessary to handle a URL.
>
>
> If the helper is starting but crashing or exiting immediately (see
> cache.log):
>
> Check that your version of SquidGuard has been patched to comply with
> the Squid-3.4+ helper protocol.
>
> Check that the Squid low-privileges user account is allowed to run that
> helper.
>
>
> If the helper is running but appears not to be doing anything:
>
> Check your url_rewrite_access lines (and alias redirector_access) to
> ensure that the traffic you want to re-write is allowed to be passed to
> the helper.
>
>
> PS. Please consider using ufdbguard instead of SquidGuard which has not
> been maintained in many years.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190201/eb6834e1/attachment.htm>

From myemailhandle at gmail.com  Fri Feb  1 23:04:35 2019
From: myemailhandle at gmail.com (john doe)
Date: Fri, 1 Feb 2019 18:04:35 -0500
Subject: [squid-users] Regarding Squid SSL cipher filtering
Message-ID: <CAF9f8mK7b2O=JCNyTYHRrExZQmZjW-4djUGt9chWZbL2qhusKQ@mail.gmail.com>

Hi Squid-Community,

I've a question for which I haven't been able to find answer.

I'm using Squid 3.5 as a forward proxy and want to limit the SSL ciphers
allowed.
I see that "sslproxy_cipher" config property would allow me to do it.
But what is unclear to me is whether just setting that list is enough or it
needs SSL-Bump too?
Pardon my ignorance around this. I'm not sure if Squid has access to the
cipher list.

Any help would be much appreciated.

Thanks,
Chris
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190201/4a239ce2/attachment.htm>

From eliezer at ngtech.co.il  Sat Feb  2 05:34:42 2019
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sat, 2 Feb 2019 07:34:42 +0200
Subject: [squid-users] Squid doesn't execute
	url_rewrite_program	/usr/bin/squidGuard -c
	/etc/squidguard/squidGuard.conf
In-Reply-To: <CAG2Qp6uNz-sKVMqbjH_OHpLZK=bALLT5gSyyjhcfi2NyEpUkBg@mail.gmail.com>
References: <CAG2Qp6uNz-sKVMqbjH_OHpLZK=bALLT5gSyyjhcfi2NyEpUkBg@mail.gmail.com>
Message-ID: <0aa801d4bab8$ff84f780$fe8ee680$@ngtech.co.il>

Share your full squid.conf removing the confidential details and we might be able to understand the issue.

If you insist on using SquidGuard please use the latest version as an external ACL helper and not as a url_rewrite_program.

If you need instructions how to implement this we can try to help you.

 

Eliezer

 

----

 <http://ngtech.co.il/main-en/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Roberto Carna
Sent: Thursday, January 31, 2019 21:48
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid doesn't execute url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf

 

Dear, I have Squid 3.5.23 and I use Squidguard for URL and domain filtering.

 

In squid.conf I have this line:

url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf

 

but in this proxy server, the line is not executed by Squid, so Squidguard doesn't work at all.

 

Same configuration in another proxy server works OK.

 

Please can you tell me how I can force the execution of url_rewrite_program line ???

 

Thanks a lot !!!

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190202/36a8e261/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.png
Type: image/png
Size: 11297 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190202/36a8e261/attachment.png>

From squid3 at treenet.co.nz  Sat Feb  2 12:23:37 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 3 Feb 2019 01:23:37 +1300
Subject: [squid-users] Regarding Squid SSL cipher filtering
In-Reply-To: <CAF9f8mK7b2O=JCNyTYHRrExZQmZjW-4djUGt9chWZbL2qhusKQ@mail.gmail.com>
References: <CAF9f8mK7b2O=JCNyTYHRrExZQmZjW-4djUGt9chWZbL2qhusKQ@mail.gmail.com>
Message-ID: <3c4a5ddf-770e-e0e7-8f7c-93b27cfc1ade@treenet.co.nz>

On 2/02/19 12:04 pm, john doe wrote:
> Hi Squid-Community,
> 
> I've a question for which I haven't been able to find answer.
> 
> I'm using Squid 3.5 as a forward proxy and want to limit the SSL ciphers
> allowed.
> I see that "sslproxy_cipher" config property would allow me to do it.

The sslproxy_* directives (as of v4 called tls_outgoing_options) are for
TLS/SSL control of connections to servers.

The https_port and http_port directives have options for TLS/SSL on
connections from clients.

The cache_peer directive has options for fine tuning or locking down
TLS/SSL to each peer server.


> But what is unclear to me is whether just setting that list is enough or
> it needs SSL-Bump too?

For TLS interactions between the client and server (CONNECT tunnels)
then Yes, you need to MITM (SSL-Bump) to interact with their crypto.

For TLS between client and proxy, then no. Squid is in control already -
at least of the proxy end of the connection.



> Pardon my?ignorance around?this. I'm not sure if Squid has access to the
> cipher list.
> 

None needed. Nobody knows everything about Squid (even us official and
logn-term devs). Help is what this list is for :-)

Amos


From squid3 at treenet.co.nz  Sat Feb  2 12:32:30 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 3 Feb 2019 01:32:30 +1300
Subject: [squid-users] Squid doesn't execute url_rewrite_program
 /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
In-Reply-To: <CAG2Qp6tJBJs6AV3tqGw3P-eYxzqwfTb12mo9qpGdeN9v6u2Y5A@mail.gmail.com>
References: <CAG2Qp6uNz-sKVMqbjH_OHpLZK=bALLT5gSyyjhcfi2NyEpUkBg@mail.gmail.com>
 <09127802-b4b8-7ceb-3df6-33059842907b@treenet.co.nz>
 <CAG2Qp6tJBJs6AV3tqGw3P-eYxzqwfTb12mo9qpGdeN9v6u2Y5A@mail.gmail.com>
Message-ID: <c6330358-d1fe-3f10-0747-3fc54236cb5c@treenet.co.nz>

On 2/02/19 7:56 am, Roberto Carna wrote:
> Dear Amos, thanks for your comments.
> 
> I realized that I have some clues in cache.log:
> 
> 2019/02/01 15:51:44 kid1| helperOpenServers: Starting 0/20 'squidGuard'
> processes
> 2019/02/01 15:51:44 kid1| helperOpenServers: No 'squidGuard' processes
> needed.
> 2019/02/01 15:51:44 kid1| helperOpenServers: Starting 0/5
> 'squid_ldap_auth' processes
> 2019/02/01 15:51:44 kid1| helperOpenServers: No 'squid_ldap_auth'
> processes needed.
> 
> These lines appears after I execute "systemctl reload squid".
> 
> Users and rights are OK.
> 
> Please can you help me one more time?
> 

The above log lines indicate that Squid is waiting for traffic before
going to the trouble of starting helpers. This is the default since
Squid-3.2.

If you want to change that the relevant directives for these two helpers
are:
 <http://www.squid-cache.org/Doc/config/url_rewrite_children/>
 <http://www.squid-cache.org/Doc/config/auth_param/> under "children"

Amos


From eliezer at ngtech.co.il  Sat Feb  2 19:37:56 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Sat, 2 Feb 2019 21:37:56 +0200
Subject: [squid-users] Squid doesn't execute url_rewrite_program
	/usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
In-Reply-To: <c6330358-d1fe-3f10-0747-3fc54236cb5c@treenet.co.nz>
References: <CAG2Qp6uNz-sKVMqbjH_OHpLZK=bALLT5gSyyjhcfi2NyEpUkBg@mail.gmail.com>
 <09127802-b4b8-7ceb-3df6-33059842907b@treenet.co.nz>
 <CAG2Qp6tJBJs6AV3tqGw3P-eYxzqwfTb12mo9qpGdeN9v6u2Y5A@mail.gmail.com>
 <c6330358-d1fe-3f10-0747-3fc54236cb5c@treenet.co.nz>
Message-ID: <036901d4bb2e$cbfecc30$63fc6490$@ngtech.co.il>

Can we change the default from "startup=0" to "startup=1" ?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Saturday, February 2, 2019 14:33
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid doesn't execute url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf

On 2/02/19 7:56 am, Roberto Carna wrote:
> Dear Amos, thanks for your comments.
> 
> I realized that I have some clues in cache.log:
> 
> 2019/02/01 15:51:44 kid1| helperOpenServers: Starting 0/20 'squidGuard'
> processes
> 2019/02/01 15:51:44 kid1| helperOpenServers: No 'squidGuard' processes
> needed.
> 2019/02/01 15:51:44 kid1| helperOpenServers: Starting 0/5
> 'squid_ldap_auth' processes
> 2019/02/01 15:51:44 kid1| helperOpenServers: No 'squid_ldap_auth'
> processes needed.
> 
> These lines appears after I execute "systemctl reload squid".
> 
> Users and rights are OK.
> 
> Please can you help me one more time?
> 

The above log lines indicate that Squid is waiting for traffic before
going to the trouble of starting helpers. This is the default since
Squid-3.2.

If you want to change that the relevant directives for these two helpers
are:
 <http://www.squid-cache.org/Doc/config/url_rewrite_children/>
 <http://www.squid-cache.org/Doc/config/auth_param/> under "children"

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Sat Feb  2 20:29:30 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 2 Feb 2019 13:29:30 -0700
Subject: [squid-users] Regarding Squid SSL cipher filtering
In-Reply-To: <CAF9f8mK7b2O=JCNyTYHRrExZQmZjW-4djUGt9chWZbL2qhusKQ@mail.gmail.com>
References: <CAF9f8mK7b2O=JCNyTYHRrExZQmZjW-4djUGt9chWZbL2qhusKQ@mail.gmail.com>
Message-ID: <a0846a84-11ea-45ee-bd9e-8802554ce13f@measurement-factory.com>

On 2/1/19 4:04 PM, john doe wrote:

> I'm using Squid 3.5 as a forward proxy and want to limit the SSL ciphers
> allowed.

> I see that "sslproxy_cipher" config property would allow me to do it.
> But what is unclear to me is whether just setting that list is enough or
> it needs SSL-Bump too?
> Pardon my?ignorance around?this. I'm not sure if Squid has access to the
> cipher list.

If you want to restrict ciphers used by clients establishing a TLS
connection with the origin server (via a CONNECT tunnel through Squid)
but you do not want to bump client-origin traffic that uses permitted
ciphers, then you have several options, including:

* Deny access to clients that offer banned ciphers to servers. Requires
either a silent TCP connection termination or bumping to serve an error
page. Requires TLS Client Hello analysis that is only supported in v4+
(via an external ACL and %>handshake).

* Deny access to servers that select banned ciphers (from the list of
all ciphers offered by clients). Requires either a silent TCP connection
termination or bumping to serve an error page. Requires TLS Server Hello
analysis that is only supported in v4+ (via an external ACL and
%ssl::<negotiated_cipher).

For bumped connections, there is also %ssl::>negotiated_cipher.

Sorry, I ran out of time to polish and detail the above further, but
others on the list can help you if you need more information.


Cheers,

Alex.


From myemailhandle at gmail.com  Sun Feb  3 21:21:18 2019
From: myemailhandle at gmail.com (john doe)
Date: Sun, 3 Feb 2019 16:21:18 -0500
Subject: [squid-users] Regarding Squid SSL cipher filtering
In-Reply-To: <a0846a84-11ea-45ee-bd9e-8802554ce13f@measurement-factory.com>
References: <CAF9f8mK7b2O=JCNyTYHRrExZQmZjW-4djUGt9chWZbL2qhusKQ@mail.gmail.com>
 <a0846a84-11ea-45ee-bd9e-8802554ce13f@measurement-factory.com>
Message-ID: <CAF9f8mLCJPNs2kkLXzOe8gcOgYnngTr4T8Wx3Q7R5koj7QUxLg@mail.gmail.com>

Thanks a lot guys for providing clear explanation.
Much appreciated!

Cheers,
Chris

On Sat, Feb 2, 2019 at 3:29 PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 2/1/19 4:04 PM, john doe wrote:
>
> > I'm using Squid 3.5 as a forward proxy and want to limit the SSL ciphers
> > allowed.
>
> > I see that "sslproxy_cipher" config property would allow me to do it.
> > But what is unclear to me is whether just setting that list is enough or
> > it needs SSL-Bump too?
> > Pardon my ignorance around this. I'm not sure if Squid has access to the
> > cipher list.
>
> If you want to restrict ciphers used by clients establishing a TLS
> connection with the origin server (via a CONNECT tunnel through Squid)
> but you do not want to bump client-origin traffic that uses permitted
> ciphers, then you have several options, including:
>
> * Deny access to clients that offer banned ciphers to servers. Requires
> either a silent TCP connection termination or bumping to serve an error
> page. Requires TLS Client Hello analysis that is only supported in v4+
> (via an external ACL and %>handshake).
>
> * Deny access to servers that select banned ciphers (from the list of
> all ciphers offered by clients). Requires either a silent TCP connection
> termination or bumping to serve an error page. Requires TLS Server Hello
> analysis that is only supported in v4+ (via an external ACL and
> %ssl::<negotiated_cipher).
>
> For bumped connections, there is also %ssl::>negotiated_cipher.
>
> Sorry, I ran out of time to polish and detail the above further, but
> others on the list can help you if you need more information.
>
>
> Cheers,
>
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190203/b1693b1d/attachment.htm>

From walid.shaari at linux.com  Mon Feb  4 15:07:46 2019
From: walid.shaari at linux.com (Walid A. Shaari)
Date: Mon, 4 Feb 2019 18:07:46 +0300
Subject: [squid-users] Connection to cache peer failed "SSL Transparent
	proxy'
Message-ID: <CAN4dctrM9vU9gKtyKwkU8Km+WhvA8xXaT8W7abu4HuihpLeGXw@mail.gmail.com>

Hello,

I have a squid proxy, trying to configure it to enforce traffic from a
private cloud appliance (Azure Stack) to go over to the corporate proxy.
traffic is mostly https, I see the below errors, note that ParentProxy-22
is the parent proxy listening on port 9090.  also, why in the access logs I
have some entries not going to parent proxy   (e.g. 1549282865.527 13
192.168.3.10 NONE/200 0 CONNECT 52.138.216.83:443 - HIER_NONE/- -)

### error logs ### Feb 4 15:26:38 azproxy squid[192272]: TCP connection to
ParentProxy-22/9090 failed
Feb 4 15:26:38 azproxy squid[192272]: Error parsing SSL Server Hello
Message on FD 20
Feb 4 15:26:38 azproxy squid[192272]: ERROR: negotiating TLS on FD 20:
error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol
(1/-1/0)
Feb 4 15:26:38 azproxy squid[192272]: TCP connection to ParentProxy-22/9090
failed
Feb 4 15:26:38 azproxy squid[192272]: Detected DEAD Parent: ParentProxy-22
Feb 4 15:26:38 azproxy squid[192272]: Detected REVIVED Parent:
ParentProxy-22
Feb 4 15:26:38 azproxy squid[192272]: Error parsing SSL Server Hello
Message on FD 24
Feb 4 15:26:38 azproxy squid[192272]: ERROR: negotiating TLS on FD 24:
error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol
(1/-1/0)
Feb 4 15:26:38 azproxy squid[192272]: TCP connection to ParentProxy-22/9090
failed
The squid configuration is as follows:

### iptables setup ### [root@ azproxy ~] $ iptables -L -t nat -n -v Chain
PREROUTING (policy ACCEPT 6089 packets, 376K bytes) pkts bytes target prot
opt in out source destination 5029 261K REDIRECT tcp -- * * 0.0.0.0/0
0.0.0.0/0 tcp dpt:80 redir ports 8080
 21742 1130K REDIRECT tcp -- * * 0.0.0.0/0 0.0.0.0/0 tcp dpt:443 redir
ports 8090 ### squid.conf ## dns_v4_first on

cache_peer ParentProxy-22 parent 9090 0 no-query
sslcapath=/etc/pki/ca-trust/source/anchors/
acl local-network dstdomain .azcompany.com
acl everything src 10.0.0.0/8
http_access allow everything
never_direct deny local-network
never_direct allow all
http_port 8080 intercept
https_port 8090 intercept ssl-bump generate-host-certificates=on
cert=/etc/squid/ssl_certs/azproxyCA.pem dynamic_cert_mem_cache_size=16MB
#connection-auth=off
http_port 8100             #forward port not used.

sslcrtd_program /usr/lib64/squid/security_file_certgen -s
/var/spool/squid/ssl_db -M 4MB
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all
tls_outgoing_options /etc/pki/ca-trust/source/anchors/ca.crt
debug_options ALL,9### excerpts from access log ### 1549282836.118 44
192.168.3.11 NONE/200 0 CONNECT 23.50.187.199:443 -
FIRSTUP_PARENT/ParentProxy-22 -:
1549282836.150 14 192.168.3.11 TCP_MISS_ABORTED/503 4272 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab?
- FIRSTUP_PARENT/ParentProxy-22 text/html
1549282836.271 38 192.168.3.11 NONE/200 0 CONNECT 23.50.187.199:443 -
FIRSTUP_PARENT/ParentProxy-22 -
1549282836.300 13 192.168.3.11 NONE/200 0 CONNECT 23.50.187.199:443 -
FIRSTUP_PARENT/ParentProxy-22 -
1549282837.661 30 192.168.3.11 NONE/200 0 CONNECT 23.50.187.199:443 -
FIRSTUP_PARENT/ParentProxy-22 -
1549282837.710 19 192.168.3.11 TCP_MISS_ABORTED/503 4272 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab?
- FIRSTUP_PARENT/ParentProxy-22 text/html
1549282837.797 4 192.168.3.11 NONE/200 0 CONNECT 23.50.187.199:443 -
HIER_NONE/- -1549282837.856 42 192.168.3.11 NONE/200 0 CONNECT
23.50.187.199:443 - FIRSTUP_PARENT/ParentProxy-22 -
1549282840.277 15 192.168.3.7 TCP_MISS_ABORTED/503 4272 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/disallowedcertstl.cab?
- FIRSTUP_PARENT/ParentProxy-22 text/html
1549282840.300 17 192.168.3.7 TCP_MISS_ABORTED/503 4272 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/pinrulesstl.cab?
- FIRSTUP_PARENT/ParentProxy-22 text/html
1549282848.695 19 192.168.3.17 TCP_MISS/200 2283 GET
http://ocsp.aramco.com.sa/ocsp/MFQwUjBQME4wTDAJBgUrDgMCGgUABBTcIwl9uZE4WwaD1jq3IdqcP3CI0wQUBCvyP4WY3ATuQXNOru2Zj%2B6W%2BfcCExkAABWDWqKqrUfWBR8AAAAAFYM%3D
-
ORIGINAL_DST/10.1.152.115 application/ocsp-response
1549282853.233 17 192.168.3.10 NONE/200 0 CONNECT 23.50.187.199:443 -
FIRSTUP_PARENT/ParentProxy-22 -

1549282853.266 14 192.168.3.10 TCP_MISS_ABORTED/503 4272 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab?
- FIRSTUP_PARENT/ParentProxy-22 text/html
1549282853.299 17 192.168.3.10 NONE/200 0 CONNECT 23.50.187.199:443 -
FIRSTUP_PARENT/ParentProxy-22 -
1549282853.329 14 192.168.3.10 NONE/200 0 CONNECT 23.50.187.199:443 -
FIRSTUP_PARENT/ParentProxy-22 -
1549282865.527 13 192.168.3.10 NONE/200 0 CONNECT 52.138.216.83:443 -
HIER_NONE/- -
1549282865.552 13 192.168.3.10 TCP_MISS_ABORTED/503 4272 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/disallowedcertstl.cab?
-FIRSTUP_PARENT/ParentProxy-22 text/html
1549282865.615 57 192.168.3.10 TCP_MISS/503 4689 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab?
-FIRSTUP_PARENT/ParentProxy-22 text/html
1549282875.690 38 192.168.3.17 TCP_MISS/503 4707 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/disallowedcertstl.cab?
-FIRSTUP_PARENT/ParentProxy-22 text/html
1549282875.711 14 192.168.3.17 TCP_MISS_ABORTED/503 4272 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/pinrulesstl.cab?
- FIRSTUP_PARENT/ParentProxy-22 text/html
1549282876.012 28 10.8.101.53 NONE/200 0 CONNECT 111.221.29.254:443 -
FIRSTUP_PARENT/ParentProxy-22 -
1549282880.455 18 192.168.3.10 NONE/200 0 CONNECT 23.50.187.199:443 -
FIRSTUP_PARENT/ParentProxy-22 -
1549282880.544 42 192.168.3.10 TCP_MISS_ABORTED/500 4272 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab?
- HIER_NONE/- text/html
1549282880.614 17 192.168.3.10 NONE/200 0 CONNECT 23.50.187.199:443 -
FIRSTUP_PARENT/ParentProxy-22 -
1549282880.644 13 192.168.3.10 NONE/200 0 CONNECT 23.50.187.199:443 -
FIRSTUP_PARENT/ParentProxy-22 -
1549282880.995 22 192.168.3.4 TCP_MISS_ABORTED/503 4272 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/disallowedcertstl.cab?
- FIRSTUP_PARENT/ParentProxy-22 text/html
1549282881.026 25 192.168.3.4 TCP_MISS_ABORTED/503 4272 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/pinrulesstl.cab?
- FIRSTUP_PARENT/ParentProxy-22 text/html
1549282882.164 19 192.168.3.17 TCP_MISS/503 4689 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/pinrulesstl.cab?
- FIRSTUP_PARENT/ParentProxy-22 text/html
==== squid version and build ===
[root at azproxy ~] $ squid -v
Squid Cache: Version 4.5
Service Name: squid

This binary uses OpenSSL 1.0.2k-fips 26 Jan 2017. For legal restrictions on
distribution see https://www.openssl.org/source/license.html configure
options: '--build=x86_64-redhat-linux-gnu' '--host=x86_64-redhat-linux-gnu'
'--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr'
'--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc'
'--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64'
'--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib'
'--mandir=/usr/share/man' '--infodir=/usr/share/info' '--exec_prefix=/usr'
'--libexecdir=/usr/lib64/squid' '--localstatedir=/var'
'--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
'--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid'
'--disable-dependency-tracking' '--enable-follow-x-forwarded-for'
'--enable-auth'
'--enable-auth-basic=DB,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam,fake'
'--enable-auth-ntlm=fake' '--enable-auth-digest=file,LDAP,eDirectory'
'--enable-auth-negotiate=kerberos,wrapper' '--enable-external-acl-
helpers=wbinfo_group,kerberos_ldap_group,LDAP_group,delayer,
file_userip,SQL_session,unix_group,session,time_quota'
'--enable-cache-digests' '--enable-cachemgr-hostname=localhost'
'--enable-delay-pools' '--enable-epoll' '--enable-icap-client'
'--enable-ident-lookups' '--enable-linux-netfilter'
'--enable-removal-policies=heap,lru' '--enable-snmp'
'--enable-storeio=aufs,diskd,ufs,rock' '--enable-wccpv2' '--enable-esi'
'--enable-security-cert-generators' '--enable-security-cert-validators'
'--enable-icmp' '--with-aio' '--with-default-user=squid'
'--with-filedescriptors=16384' '--with-dl' '--with-openssl'
'--enable-ssl-crtd' '--with-pthreads' '--with-included-ltdl'
'--disable-arch-native' '--without-nettle'
'build_alias=x86_64-redhat-linux-gnu'
'host_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong
--param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic'
'LDFLAGS=-Wl,-z,relro ' 'CXXFLAGS=-O2 -g -pipe -Wall
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong
--param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC'
'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig'
--enable-ltdl-convenience
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190204/07b00ae1/attachment.htm>

From johnrefwe at mail.com  Mon Feb  4 18:25:57 2019
From: johnrefwe at mail.com (johnr)
Date: Mon, 4 Feb 2019 12:25:57 -0600 (CST)
Subject: [squid-users] Squid and ICAP using 206 response on reply
Message-ID: <1549304757650-0.post@n4.nabble.com>

Hi,

I've attempting to use a RESPMOD ICAP in squid to modify the response
headers before they get to my user. I am attempting to use the ICAP 206 code
to be able to do this. 

Everything works fine if the response payload is more than the preview that
my ICAP takes. But, if the max size of the preview is greater than the size
of the response payload, the 206 response does not do anything (and it
basically looks like a 204 where I get back the original response without
any header modification). 

Is this a known fact that if the response is smaller than the max preview
size then 206 is not a valid response? I can't find evidence for that in the
ICAP spec, so I am thinking there's a chance I'm doing something else wrong?
Thank you for any help.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Mon Feb  4 22:04:10 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 4 Feb 2019 15:04:10 -0700
Subject: [squid-users] Squid and ICAP using 206 response on reply
In-Reply-To: <1549304757650-0.post@n4.nabble.com>
References: <1549304757650-0.post@n4.nabble.com>
Message-ID: <cd371ef2-24b2-99e7-d798-2fbdc61593ca@measurement-factory.com>

On 2/4/19 11:25, johnr wrote:

> I've attempting to use a RESPMOD ICAP in squid to modify the response
> headers before they get to my user. I am attempting to use the ICAP 206 code
> to be able to do this.
> 
> Everything works fine if the response payload is more than the preview that
> my ICAP takes. But, if the max size of the preview is greater than the size
> of the response payload, the 206 response does not do anything (and it
> basically looks like a 204 where I get back the original response without
> any header modification).

> Is this a known fact that if the response is smaller than the max preview
> size then 206 is not a valid response?

IIRC, there is no such fact. In fact, 206 works in Preview by default 
(and can work outside of Preview after additional signaling from the 
ICAP client):

 > draft-icap-ext-partial-content-07.txt:
> Partial Content feature is limited to ICAP Preview by default.
>    Similar to ICAP 204 (No Content) responses, an ICAP client may enable
>    Partial Content responses outside of Preview by sending "Allow: 204,
>    206" REQMOD or RESPMOD header.



> I can't find evidence for that in the ICAP spec, so I am thinking
> there's a chance I'm doing something else wrong?

It could be a Squid bug or your ICAP service could be doing something 
wrong. Consider posting a [link to] compressed Squid cache.log with 
debug_options set to ALL,9 (or, at the very least, "ALL,3 93,9").


Cheers,

Alex.


From squid3 at treenet.co.nz  Tue Feb  5 06:24:47 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 Feb 2019 19:24:47 +1300
Subject: [squid-users] Connection to cache peer failed "SSL Transparent
 proxy'
In-Reply-To: <CAN4dctrM9vU9gKtyKwkU8Km+WhvA8xXaT8W7abu4HuihpLeGXw@mail.gmail.com>
References: <CAN4dctrM9vU9gKtyKwkU8Km+WhvA8xXaT8W7abu4HuihpLeGXw@mail.gmail.com>
Message-ID: <ec2e4d70-98d7-1354-9507-d360a8d8bec8@treenet.co.nz>

[ Rules horribly mangled by sending a web page to a plain-text mailing
list. I have fixed some where I replied, but not all. ]


On 5/02/19 4:07 am, Walid A. Shaari wrote:
> Hello,
> 
> I have a squid proxy, trying to configure it to enforce traffic from a
> private cloud appliance (Azure Stack) to go over to the corporate proxy.
> traffic is mostly https, I see the below errors, note
> that?ParentProxy-22 is the parent proxy listening on port 9090.



>? also,
> why in the access logs I have some entries not going to parent proxy?
> ?(e.g.?1549282865.527 13 192.168.3.10 NONE/200 0
> CONNECT?52.138.216.83:443 <http://52.138.216.83:443/>?- HIER_NONE/- -)
> 

Some transactions do not need server contact. The above "CONNECT" with
raw-IP:port, "NONE" status type, "NONE" peer type and 0 byte size is
what gets logged for the SSL-Bump step-1 interaction when only a TCP SYN
packet has actually happened.

NP: Each step of SSL-Bump process has a separate log entry with
incrementally more data up to the one with a 'final' result which
instead logs the decrypted transactions or the error.


> ### error logs ###Feb 4 15:26:38 azproxy squid[192272]: TCP connection
> to ParentProxy-22/9090 failed?
> Feb 4 15:26:38 azproxy squid[192272]: Error parsing SSL Server Hello
> Message on FD 20?
> Feb 4 15:26:38 azproxy squid[192272]: ERROR: negotiating TLS on FD 20:
> error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol
> (1/-1/0) 

The OpenSSL library on your proxy machine does not understand the
protocol that it is receiving in the supposedly TLS / HTTPS traffic.

Usually seeing this on peer connections means the peer is *not* a TLS
explicit proxy, nor HTTPS / TLS origin server. Such things respond in
their actual protocol with an error -> OpenSSL displays that message.


...>
> cache_peer ParentProxy-22 parent 9090 0 no-query
> sslcapath=/etc/pki/ca-trust/source/anchors/

Two things of note:

1) as above, does this peer *actually* support TLS connections on its
port 9090?
 Native TLS connections, not HTTP Upgrade or anything like that.

2) That sslcapath= is providing an entire set of CA's. Any given server
typically has one certificate, signed by one CA. So it is rare that you
would need an entire set of CA's to be trusted by this proxy.

For better security you should be able to load the specific CA that peer
uses with sslcafile= instead of the whole path.


> acl local-network dstdomain .azcompany.com
> acl everything src?10.0.0.0/8
> http_access allow everything


These are very deceptive.

 * "everything" is actually a small sub-set of 'things'.

 * "local-network" is not necessarily local. Any IP address with
reverse-DNS configured to claim its name is within *.azcompany.com will
match this ACL regardless of where in the world it actually is.


The default squid.conf defines an ACL "localnet" (Local Network) for the
permitted clients subnet.

The ACL called "all" is provided to match every transaction with a
client IP.


> never_direct deny local-network


Fine, but why are you waiting until a place (never_direct) where Squid
is unable to wait for results of reverse-DNS lookup?
 That will result in unpredictable non-match occuring whenever DNS TTL
is encountered.


> never_direct allow all
> http_port 8080 intercept
> https_port 8090 intercept ssl-bump generate-host-certificates=on
> cert=/etc/squid/ssl_certs/azproxyCA.pem dynamic_cert_mem_cache_size=16MB
> #connection-auth=off
> http_port 8100? ? ? ? ? ? ?#forward port not used.
> 
> sslcrtd_program /usr/lib64/squid/security_file_certgen -s
> /var/spool/squid/ssl_db -M 4MB
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump bump all

> tls_outgoing_options /etc/pki/ca-trust/source/anchors/ca.crt

Squid should be telling you on startup that there is no valid option
named "/etc/pki/ca-trust/source/anchors/ca.crt"

 tls_outgoing_options directive takes a set of k=v pairs setting the
options just like http(s)_port and cache_peer.



HTH
Amos


From squid3 at treenet.co.nz  Tue Feb  5 06:42:30 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 Feb 2019 19:42:30 +1300
Subject: [squid-users] using clang to compile squid 4-5
In-Reply-To: <1098058608.2500656.1549016268315@mail.yahoo.com>
References: <289180401.107999.1548837503168@mail.yahoo.com>
 <vmime.5c51ccde.3cc6.66e612638aa7be@ms249-lin-003.rotterdam.bazuin.nl>
 <532bd24f-f92e-a3ad-2aee-c628c2a0c894@treenet.co.nz>
 <ae7a51e1-e54d-97be-d161-3b3b811d6290@treenet.co.nz>
 <1098058608.2500656.1549016268315@mail.yahoo.com>
Message-ID: <d32fccc3-0621-b317-5528-76aec8d518e8@treenet.co.nz>

On 1/02/19 11:17 pm, graf huy wrote:
> Hi,
> 
>>I'm not sure I follow that. Are you building with patched GCC? or a
>>patched libc? or something else?
> 
> No, these are the versions used.
> 

Hmm. That is odd. With the exception of my GCC being one patch ahead,
mine are identical. I have followed each GCC update, so would have
tested with that *-14 for a while when it was latest and have not seen
these errors at any point.


It still may be a libc and/or kernel headers issue, but those should
affect clang builds too.

Amos


From paul at doignon.fr  Tue Feb  5 14:33:09 2019
From: paul at doignon.fr (Paul Doignon)
Date: Tue, 05 Feb 2019 15:33:09 +0100
Subject: [squid-users] Filering HTTPS URLs - A complete configuration
Message-ID: <168be13b6f9.c72dacf0274895.400411858861977298@doignon.fr>

Hi,

I'm struggling a lot to configure Squid. To improve the security of my app in my AWS private subnet, I would like to build a HTTPS proxy to whitelist *only* some URLs.
My wish is to *not* rely on SNI filtering but bump HTTPS traffic in order to filter the URLs (path) of HTTPS requests. I know that means to install a custom CA.
The thing is... I have a hard compiling a working configuration file for Squid 3.5, most examples are outdated or incomplete.

My current config is :

# ---
# General
cache_effective_user squid
cache_effective_group squid
shutdown_lifetime 1 seconds 
visible_hostname squid

# Hide some reavealing or useless headers
forwarded_for delete
httpd_suppress_version_string off
reply_header_access X-Cache deny all
reply_header_access X-Cache-Lookup deny all
via off

# Tuning
max_filedesc 10000

# Disable access to manager
http_access deny manager

# Handling HTTPS requests
https_port 8080 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl/squid.pem options=NO_SSLv3,NO_TLSv1,NO_TLSv1_1,SINGLE_DH_USE,SINGLE_ECDH_USE intercept
sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1
acl SSL_port port 443
http_access allow SSL_port

# Whitelist
acl whitelist-regex url_regex -i thirdparty.com/upload/stuff/
acl whitelist-regex url_regex -i otherthirdparty.com/specific-path/
http_access allow whitelist-regex

# SSL bump
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump whitelist-regex
ssl_bump terminate step2 !whitelist-regex

# Deny the rest
http_access deny all
# --- 

What I am missing ? Should I use squid 4 for this ?
Thanks a lot in advance !




From squid3 at treenet.co.nz  Tue Feb  5 15:35:52 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 Feb 2019 04:35:52 +1300
Subject: [squid-users] Filering HTTPS URLs - A complete configuration
In-Reply-To: <168be13b6f9.c72dacf0274895.400411858861977298@doignon.fr>
References: <168be13b6f9.c72dacf0274895.400411858861977298@doignon.fr>
Message-ID: <48ab3054-7651-564a-c79e-fc2b38db7b4a@treenet.co.nz>

On 6/02/19 3:33 am, Paul Doignon wrote:
> Hi,
> 
> I'm struggling a lot to configure Squid. To improve the security of my app in my AWS private subnet,

If it is indeed *your* app; then please alter it not to require the
interception we see below. Ability to connect to a TLS explicit proxy or
just sending regular proxy CONNECT tunnel is a leap up in security.


> I would like to build a HTTPS proxy to whitelist *only* some URLs.
> My wish is to *not* rely on SNI filtering but bump HTTPS traffic in order to filter the URLs (path) of HTTPS requests. I know that means to install a custom CA.
> The thing is... I have a hard compiling a working configuration file for Squid 3.5, most examples are outdated or incomplete.

It looks below like you are of the mistaken belief that "HTTPS requests"
are actually a distinct thing that can be manipulated and tested.

"HTTPS" is just a moniker used to describe a multi-layer system for
delivering HTTP messages securely. This has a major impact on what can
be done at any particular time, especially regarding the URLs from those
HTTP messages.


> 
> My current config is :
> 
> # ---
> # General
> cache_effective_user squid
> cache_effective_group squid
> shutdown_lifetime 1 seconds 
> visible_hostname squid
> 

Note 1) 'squid' is not a unique hostname. Ideally it should be a FQDN.
At the very least an internally resolvable name so the URLs Squid
generates with this string as the domain name will be valid for clients
needing to download objects with those URLs from Squid. Either way it
has to be unique across all proxies the traffic *might* travel -
otherwise the messages will be dropped in transit. So definitely do not
use something this simple and often-repeated as "squid" or "proxy".


> # Hide some reavealing or useless headers
> forwarded_for delete
> httpd_suppress_version_string off
> reply_header_access X-Cache deny all
> reply_header_access X-Cache-Lookup deny all
> via off
> 
> # Tuning
> max_filedesc 10000
> 
> # Disable access to manager
> http_access deny manager
> 

2) you are missing the security protections from the default squid.conf...


> # Handling HTTPS requests
> https_port 8080 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl/squid.pem options=NO_SSLv3,NO_TLSv1,NO_TLSv1_1,SINGLE_DH_USE,SINGLE_ECDH_USE intercept
> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB
> sslcrtd_children 8 startup=1 idle=1
> acl SSL_port port 443
> http_access allow SSL_port
> 

3) Not a good idea. I see a lot of admin get this far and stop looking
for the proper solution when "things work".

Since you are intercepting traffic to reach this point it should be
somewhat reasonable to limit the allowed traffic to some IP range. eg.
the subnet of IPs you are intercepting and sending into the proxy.


> # Whitelist
> acl whitelist-regex url_regex -i thirdparty.com/upload/stuff/
> acl whitelist-regex url_regex -i otherthirdparty.com/specific-path/
> http_access allow whitelist-regex

Okay.

> 
> # SSL bump
> acl step1 at_step SslBump1
> ssl_bump peek step1

 ... if the client is allowed to connect to the proxy, fetch its
clientHello details...


> ssl_bump bump whitelist-regex

... then try to do the impossible. We only have TLS details at this
point. There is no HTTP message - therefore no URL to match against.
 -> result: skip this line, never do this "bump" action.


> ssl_bump terminate step2 !whitelist-regex

... regex still cannot match.
... but a non-match (aka false) with '!' means true.

So at step2 always terminate the connection.


Notice how there has still not been anything even remotely HTTP from the
client/app and they are now disconnected.

> 
> # Deny the rest
> http_access deny all
> # --- 
> 
> What I am missing ?

It seems understanding of what ssl_bump is doing is lacking.

Please see <https://wiki.squid-cache.org/Features/SslPeekAndSplice> for
details on the TLS handshake process and what SSL-Bump does during that.


> Should I use squid 4 for this ?

TL;DR : Yes.


Long version:

TLS is a volatile environment these days and each Squid release has
large improvements to cope with that change. You will find that v4 works
okay in a lot of TLS situations where v3 would the throwing up errors
and needing extra config workarounds.

Also, v3.x are all officially deprecated / no longer supported. v4 is
the current stable release.


Amos


From walid.shaari at linux.com  Tue Feb  5 16:28:27 2019
From: walid.shaari at linux.com (Walid A. Shaari)
Date: Tue, 5 Feb 2019 19:28:27 +0300
Subject: [squid-users] Connection to cache peer failed "SSL Transparent
	proxy'
In-Reply-To: <ec2e4d70-98d7-1354-9507-d360a8d8bec8@treenet.co.nz>
References: <CAN4dctrM9vU9gKtyKwkU8Km+WhvA8xXaT8W7abu4HuihpLeGXw@mail.gmail.com>
 <ec2e4d70-98d7-1354-9507-d360a8d8bec8@treenet.co.nz>
Message-ID: <CAN4dctqz-VsR=9B7uV=OW5AGCGxHxgm=a5sMab23qQo9g6wm3Q@mail.gmail.com>

Dear Amos,


Thank you for your time and response. I have changed the configuration to
the below. I believe the parent proxy is not using SSL/TLS. I do not see
the Hello error message any longer ( I hope).  I have not used your
proposed localnet as I just saw your email, at the time being, the ACL is
quite open as I am still troubleshooting, will tighten it when I am
comfortable with a final config.

- for the 'never direct', are you suggesting I use 'never direct deny
localnet'?


by the way, my final goal is to enable https traffic through, not really
intercept it, by trial and error and reading the mailing list, that config
below is what seems to be working for me right now, can not confirm totally
as parent proxy is not under my control, nor is the appliance, however from
the access.log and system message logs, things look better than earlier.
what is the best resource to understand the peek and splice, any good
places other than squid cache main url?


I did get a couple of new errors, have not worked on them, I might have
some clues.


  1- squid[192090]: SECURITY ALERT: Host header forgery detected on local=
52.138.216.83:443 remote=192.168.3.4:1384 <http://10.8.103.4:1384/> FD 50
flags=33 (local IP does not match any domain IP)

       I believe this is covered in
https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery


   2- temporary disabling (Unauthorized) digest from 192.168.4.22
        wondering if  I should add 'always_direct deny all'  and '
nonhierarchical_direct off'?

####   Anonymous access to parent proxy

#forwarded_for  delete

#request_header_access Surrogate-Capability deny all



dns_v4_first on

cache_peer  192.168.4.22  parent 9090 0 no-query
#sslcapath=/etc/pki/ca-trust/source/anchors/

acl local-network dstdomain .azcompany.com   # tighten after finalizng
troubleshooting, maybe replace with localnet

http_access allow all

never_direct deny local-network    # revisit not using DNS for resolution

never_direct allow all

http_port 8080 intercept    # should I really use intercept in here? can I
get away without it

https_port 8090 intercept ssl-bump generate-host-certificates=on
cert=/etc/squid/ssl_certs/bccaz01CA.pem  dynamic_cert_mem_cache_size=16MB
#connection-auth=off

http_port 8100    #forward port not used, only for troubleshooting.


sslcrtd_program /usr/lib64/squid/security_file_certgen -s
/var/spool/squid/ssl_db -M 4MB


acl step1 at_step SslBump1

acl azure_sites  dstdom_regex microsoft.com azure.com azureedge.net
microsoftazurestack.com trafficmanager.net  wdcp.microsoft.com
wdcpalt.microsoft.com updates.microsoft.com

acl azure_sites2 dstdom_regex download.microsoft.com msdl.microsoft.com
crl.microsoft.com secure.aadcdn.microsoftonline-p.com

ssl_bump peek step1

ssl_bump splice  azure_sites azure_sites2 #Avoid bumping Microsoft/Azure
related sites


sslproxy_cert_error allow azure_sites azure_sites2     # is there a better
way to handle these and log them?


debug_options  ALL,9

On Tue, 5 Feb 2019 at 09:25, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> [ Rules horribly mangled by sending a web page to a plain-text mailing
> list. I have fixed some where I replied, but not all. ]
>
>
> On 5/02/19 4:07 am, Walid A. Shaari wrote:
> > Hello,
> >
> > I have a squid proxy, trying to configure it to enforce traffic from a
> > private cloud appliance (Azure Stack) to go over to the corporate proxy.
> > traffic is mostly https, I see the below errors, note
> > that ParentProxy-22 is the parent proxy listening on port 9090.
>
>
>
> >  also,
> > why in the access logs I have some entries not going to parent proxy
> >  (e.g. 1549282865.527 13 192.168.3.10 NONE/200 0
> > CONNECT 52.138.216.83:443 <http://52.138.216.83:443/> - HIER_NONE/- -)
> >
>
> Some transactions do not need server contact. The above "CONNECT" with
> raw-IP:port, "NONE" status type, "NONE" peer type and 0 byte size is
> what gets logged for the SSL-Bump step-1 interaction when only a TCP SYN
> packet has actually happened.
>
> NP: Each step of SSL-Bump process has a separate log entry with
> incrementally more data up to the one with a 'final' result which
> instead logs the decrypted transactions or the error.
>
>
> > ### error logs ###Feb 4 15:26:38 azproxy squid[192272]: TCP connection
> > to ParentProxy-22/9090 failed
> > Feb 4 15:26:38 azproxy squid[192272]: Error parsing SSL Server Hello
> > Message on FD 20
> > Feb 4 15:26:38 azproxy squid[192272]: ERROR: negotiating TLS on FD 20:
> > error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol
> > (1/-1/0)
>
> The OpenSSL library on your proxy machine does not understand the
> protocol that it is receiving in the supposedly TLS / HTTPS traffic.
>
> Usually seeing this on peer connections means the peer is *not* a TLS
> explicit proxy, nor HTTPS / TLS origin server. Such things respond in
> their actual protocol with an error -> OpenSSL displays that message.
>
>
> ...>
> > cache_peer ParentProxy-22 parent 9090 0 no-query
> > sslcapath=/etc/pki/ca-trust/source/anchors/
>
> Two things of note:
>
> 1) as above, does this peer *actually* support TLS connections on its
> port 9090?
>  Native TLS connections, not HTTP Upgrade or anything like that.
>
> 2) That sslcapath= is providing an entire set of CA's. Any given server
> typically has one certificate, signed by one CA. So it is rare that you
> would need an entire set of CA's to be trusted by this proxy.
>
> For better security you should be able to load the specific CA that peer
> uses with sslcafile= instead of the whole path.
>
>
> > acl local-network dstdomain .azcompany.com
> > acl everything src 10.0.0.0/8
> > http_access allow everything
>
>
> These are very deceptive.
>
>  * "everything" is actually a small sub-set of 'things'.
>
>  * "local-network" is not necessarily local. Any IP address with
> reverse-DNS configured to claim its name is within *.azcompany.com will
> match this ACL regardless of where in the world it actually is.
>
>
> The default squid.conf defines an ACL "localnet" (Local Network) for the
> permitted clients subnet.
>
> The ACL called "all" is provided to match every transaction with a
> client IP.
>
>
> > never_direct deny local-network
>
>
> Fine, but why are you waiting until a place (never_direct) where Squid
> is unable to wait for results of reverse-DNS lookup?
>  That will result in unpredictable non-match occuring whenever DNS TTL
> is encountered.
>
>
> > never_direct allow all
> > http_port 8080 intercept
> > https_port 8090 intercept ssl-bump generate-host-certificates=on
> > cert=/etc/squid/ssl_certs/azproxyCA.pem dynamic_cert_mem_cache_size=16MB
> > #connection-auth=off
> > http_port 8100             #forward port not used.
> >
> > sslcrtd_program /usr/lib64/squid/security_file_certgen -s
> > /var/spool/squid/ssl_db -M 4MB
> > acl step1 at_step SslBump1
> > ssl_bump peek step1
> > ssl_bump bump all
>
> > tls_outgoing_options /etc/pki/ca-trust/source/anchors/ca.crt
>
> Squid should be telling you on startup that there is no valid option
> named "/etc/pki/ca-trust/source/anchors/ca.crt"
>
>  tls_outgoing_options directive takes a set of k=v pairs setting the
> options just like http(s)_port and cache_peer.
>
>
>
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190205/8b45d05c/attachment.htm>

From Walter.H at mathemainzel.info  Tue Feb  5 20:27:59 2019
From: Walter.H at mathemainzel.info (Walter H.)
Date: Tue, 05 Feb 2019 21:27:59 +0100
Subject: [squid-users] strange thing in the squid logs ...
Message-ID: <5C59F1CF.2070307@mathemainzel.info>

Hello,

in iptables I have this:

*nat
...
-A PREROUTING -i br0 -p tcp -s 192.168.1.100 --dport 80 -j DNAT 
--to-destination 192.168.1.1:3129



192.168.1.100 is my PC and 192.168.1.1 is my NAT-Router, that has squid, 
... running

here the log

192.168.1.100 - - [05/Feb/2019:20:57:09 +0100] "CONNECT 77.74.177.233:80 
HTTP/1.1" 403 1516 "-" "-" TCP_DENIED:HIER_NONE
192.168.1.100 - - [05/Feb/2019:20:58:41 +0100] "CONNECT 
130.117.190.168:80 HTTP/1.1" 403 1520 "-" "-" TCP_DENIED:HIER_NONE
192.168.1.100 - - [05/Feb/2019:21:06:12 +0100] "CONNECT 
207.123.56.252:80 HTTP/1.1" 403 1518 "-" "-" TCP_DENIED:HIER_NONE
this are only examples in real there are many of these with exakt these 
IP addresses

what is causing such strange?


here the squid.conf

acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines

acl localnet src 192.168.1.0/24

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 3128        # squid (ftp-icons, /squid-internal) [me]
acl CONNECT method CONNECT

http_access allow localhost manager
http_access deny manager

http_access deny !Safe_ports

http_access deny CONNECT !SSL_ports    # i guess this rule is causing 
DENIED in the log, but why port 80 there???

http_access deny to_localhost

http_access allow localnet
http_access allow localhost

http_access deny all

http_reply_access allow all

http_port 127.0.0.1:3128
http_port [::1]:3128
http_port 192.168.1.1:3128
http_port 192.168.1.1:3129 intercept

cache_dir ufs /var/spool/squid 16400 16 256
coredump_dir /var/spool/squid

always_direct allow all

acl crl-mime rep_mime_type application/x-pkcs7-crl
no_cache deny crl-mime

cache_mem 2560 MB

icon_directory /usr/share/squid/icons
error_directory /etc/squid/errors

as_whois_server whois.ra.net

logformat combined %>A %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st 
"%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
access_log /var/log/squid/access.log combined

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320


-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190205/1d5e4723/attachment.bin>

From squid3 at treenet.co.nz  Wed Feb  6 02:45:26 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 Feb 2019 15:45:26 +1300
Subject: [squid-users] Connection to cache peer failed "SSL Transparent
 proxy'
In-Reply-To: <CAN4dctqz-VsR=9B7uV=OW5AGCGxHxgm=a5sMab23qQo9g6wm3Q@mail.gmail.com>
References: <CAN4dctrM9vU9gKtyKwkU8Km+WhvA8xXaT8W7abu4HuihpLeGXw@mail.gmail.com>
 <ec2e4d70-98d7-1354-9507-d360a8d8bec8@treenet.co.nz>
 <CAN4dctqz-VsR=9B7uV=OW5AGCGxHxgm=a5sMab23qQo9g6wm3Q@mail.gmail.com>
Message-ID: <3c826662-b81d-d885-3c0c-9c3430ce7316@treenet.co.nz>

On 6/02/19 5:28 am, Walid A. Shaari wrote:
> Dear Amos,
> 
> 
> Thank you for your time and response. I have changed the configuration
> to the below. I believe the parent proxy is not using SSL/TLS. I do not
> see the Hello error message any longer ( I hope).? I have not used your
> proposed localnet as I just saw your email, at the time being, the ACL
> is quite open as I am still troubleshooting, will tighten it when I am
> comfortable with a final config.
> 
> - for the 'never direct', are you suggesting I use 'never direct deny
> localnet'?

There are two ways to resolve the issue there.

1) The most often we recommend is to _also_ use the same ACL in an
earlier security check like http_access so the DNS lookup happens early
and the data is more reliably available when the fast-type check needs it.

or,

2) To use something that does not require remote lookups. IP address
tests etc.


It depends on what your policies are as to which is the better approach
to take. It is looking a bit like (2) is probably the way to go. With
the switch from dstdomain to server_name type for the ssl_bump
processing this issue may just disappear.


> 
> by the way, my final goal is to enable https traffic through, not really
> intercept it, by trial and error and reading the mailing list, that
> config below is what seems to be working for me right now, can not
> confirm totally as parent proxy is not under my control, nor is the
> appliance, however from the access.log and system message logs, things
> look better than earlier.? what is the best resource to understand the
> peek and splice, any good places other than squid cache main url?
> 

The documentation of what modern Squid SSL-Bump feature does can be
found at <https://wiki.squid-cache.org/Features/SslPeekAndSplice>. It is
community maintained and kept as up to date as we can.

That page links to the relevant squid.conf documentation for the
relevant pieces. The whole TLS situation is a bit volatile so questions
are welcome here if you are unsure about anything in regards to your
specific Squid version, or observe things not matching that text.


> 
> I did get a couple of new errors, have not worked on them, I might have
> some clues.
> 
> 
> ? 1-?squid[192090]: SECURITY ALERT: Host header forgery detected on
> local=52.138.216.83:443
> <http://52.138.216.83:443/>?remote=192.168.3.4:1384
> <http://10.8.103.4:1384/>?FD 50 flags=33 (local IP does not match any
> domain IP)
> 
> ? ? ? ?I believe this is covered in
> https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery
> 

Yes.


> 
> ? ?2-?temporary disabling (Unauthorized) digest from?192.168.4.22
> 
> ? ? ? ? wondering if ?I should add 'always_direct deny all' ?and '
> nonhierarchical_direct off'?
> 

To encourage use of the peer when it is possible but not optimal. That
"nonhierarchical_direct off" is the way to go.


But "always_direct deny ..." is a soft negative. It just means don't
*force* things to go direct. So they might still go direct to origin or
via a cache_peer as needed.

"never_direct allow ..." is the directive to force things to go to
cache_peer's or fail. Instead of via DIRECT or ORIGINAL_DST server
connections.

If you try to force things you will run up against the lack of
re-CONNECT features in Squid. That is Squid cannot yet generate CONNECT
tunnels through non-TLS peers like you have.

Given that the intercepted HTTPS traffic must leave Squid over secure
connections that effectively means it cannot use the peer as it normally
would and has to send that traffic via ORIGINAL_DST / DIRECT connections
to the HTTPS server. If those are forbidden the transaction has no
choice but to terminate with an error message.


FWIW: Measurement Factory have an experimental branch adding that
re-CONNECT functionality to Squid, if you are okay running alpha quality
code that may be of interest.
 On the other side, I am working with a client on a configuration that
should result in the needed behaviour for the stable releases. That is
just entering testing and depends on whether they are willing for the
details to be published.


> #### ? Anonymous access to parent proxy
> 
> #forwarded_for? delete
> 
> #request_header_access Surrogate-Capability deny all
> 

FYI: the bug behind the S-C header problems is now fixed in v4.5
release. Once you upgrade this can be removed.

> 
> dns_v4_first on
> 
> cache_peer? 192.168.4.22? parent 9090 0 no-query
> #sslcapath=/etc/pki/ca-trust/source/anchors/??
> 
> acl local-network dstdomain .azcompany.com ?#
> tighten after finalizng troubleshooting, maybe replace with localnet
> 
> http_access allow all
> 
> never_direct deny local-network? ? # revisit not using DNS for resolution
> 
> never_direct allow all? ??
> 
> http_port 8080 intercept? ? # should I really use intercept in here? can
> I get away without it
> 
> https_port 8090 intercept ssl-bump generate-host-certificates=on?
> cert=/etc/squid/ssl_certs/bccaz01CA.pem?
> dynamic_cert_mem_cache_size=16MB #connection-auth=off
> 
> http_port 8100? ? #forward port not used, only for troubleshooting.
> 
> 
> sslcrtd_program /usr/lib64/squid/security_file_certgen -s
> /var/spool/squid/ssl_db -M 4MB
> 
> 
> acl step1 at_step SslBump1
> 
> acl azure_sites? dstdom_regex microsoft.com <http://microsoft.com>
> azure.com <http://azure.com> azureedge.net <http://azureedge.net>
> microsoftazurestack.com <http://microsoftazurestack.com>
> trafficmanager.net <http://trafficmanager.net>? wdcp.microsoft.com
> <http://wdcp.microsoft.com> wdcpalt.microsoft.com
> <http://wdcpalt.microsoft.com> updates.microsoft.com
> <http://updates.microsoft.com>
> 
> acl azure_sites2 dstdom_regex download.microsoft.com
> <http://download.microsoft.com> msdl.microsoft.com
> <http://msdl.microsoft.com> crl.microsoft.com <http://crl.microsoft.com>
> secure.aadcdn.microsoftonline-p.com
> <http://secure.aadcdn.microsoftonline-p.com>
> 

FYI: Regex is a slow procedure so when possible should be avoided. Since
all the above are domain names it looks like dstdomain would be better
with these ACL values. Some maybe using the wildcard dstdomain syntax.

 acl azure_sites dstdomain .microsoft.com \
    .azure.com .azureedge.net \
    .microsoftazurestack.com .trafficmanager.net

 acl azure_sites2 dstdomain .microsoft.com \
    secure.aadcdn.microsoftonline-p.com


> ssl_bump peek step1
> 
> ssl_bump splice? azure_sites azure_sites2 #Avoid bumping Microsoft/Azure
> related sites
> 

The way ACLs work in Squid items on a line like "azure_sites
azure_sites2" *both* have to match for the lines action to be used.

So the above line means all those domains except *.microsoft.com will
*not* be spliced here even if a URL domain was available.


> 
> sslproxy_cert_error allow azure_sites azure_sites2? ? ?# is there a
> better way to handle these and log them?
> 


For ssl_bump you should prefer the ssl::server_name or
ssl::server_name_regex type ACLs.

All Squid has in the way of URL at that timing is the CONNECT message
from step 1, which is a raw-IP for intercepted traffic. The domain names
in TLS / ssl_bump come from TLS SNI and server X.509 certificate.

The ssl::server_name ACL uses dstdomain-like comparisons, but against
the TLS handshake values instead of the HTTP request message values or
reverse-DNS names.


Amos


From squid3 at treenet.co.nz  Wed Feb  6 03:14:48 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 Feb 2019 16:14:48 +1300
Subject: [squid-users] strange thing in the squid logs ...
In-Reply-To: <5C59F1CF.2070307@mathemainzel.info>
References: <5C59F1CF.2070307@mathemainzel.info>
Message-ID: <e1745b79-f104-6574-1fae-fbea40ff787c@treenet.co.nz>

On 6/02/19 9:27 am, Walter H. wrote:
> Hello,
> 
> in iptables I have this:
> 
> *nat
> ...
> -A PREROUTING -i br0 -p tcp -s 192.168.1.100 --dport 80 -j DNAT
> --to-destination 192.168.1.1:3129
> 
> 
> 
> 192.168.1.100 is my PC and 192.168.1.1 is my NAT-Router, that has squid,
> ... running
> 
> here the log
> 
> 192.168.1.100 - - [05/Feb/2019:20:57:09 +0100] "CONNECT 77.74.177.233:80
> HTTP/1.1" 403 1516 "-" "-" TCP_DENIED:HIER_NONE
> 192.168.1.100 - - [05/Feb/2019:20:58:41 +0100] "CONNECT
> 130.117.190.168:80 HTTP/1.1" 403 1520 "-" "-" TCP_DENIED:HIER_NONE
> 192.168.1.100 - - [05/Feb/2019:21:06:12 +0100] "CONNECT
> 207.123.56.252:80 HTTP/1.1" 403 1518 "-" "-" TCP_DENIED:HIER_NONE
> this are only examples in real there are many of these with exakt these
> IP addresses
> 
> what is causing such strange?
> 

Unknown.


> 
> here the squid.conf
> 
...
> 
> http_access deny CONNECT !SSL_ports??? # i guess this rule is causing
> DENIED in the log, but why port 80 there???
> 

Yes. This is the rule blocking those transactions.

The answer to your question though is known only to the client software
requesting those tunnels be opened.

Could be some form of attack against those servers or abusive use of
port 80 for non-HTTP. At very least it is trying to bypass the proxy for
some type of port 80 traffic.

If it worries you, then investigation of the traffic may prove fruitful.
Then you can decide what to do based on better information that your log
contains.


[ following is just some comments about polish to your squid.conf ]

> 
> http_reply_access allow all

Does the default action, but in a slow way. You can simplify your config
and speed up Squid a little by removing the above line.


> 
> always_direct allow all

Does the default action, but in a slow way. You can simplify your config
and speed up Squid a little by removing the above line.


> 
> acl crl-mime rep_mime_type application/x-pkcs7-crl
> no_cache deny crl-mime
> 

"no_cache" does not exist since Squid-1.x. It is called just "cache" so
at very least please remove that "no_" part.

Also, the "cache" directive is tested for HTTP *requests*. There is no
HTTP *reply* mime type in request messages.

Either;

a) use req_mime_type (note the 'q'), or

b) remove both the above lines as pointless config, or

c) replace the "no_cache" name with "store_miss" in latest Squid-3.5+
proxies.


FWIW: it is not clear why you forbid CRL objects from being cached. They
are public information and caching works as well as with any other HTTP
objects.


> 
> logformat combined %>A %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st
> "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
> access_log /var/log/squid/access.log combined
> 

FYI: The Apache "common" format is designed for use by web servers.
Which are quite different software from proxies. In particular they
typically do not have upstream origin-server connection and multiplexing
to deal with - which is a core part of being a proxy. So you are missing
out on several useful details the "squid" native log format provides.


Amos


From eliezer at ngtech.co.il  Wed Feb  6 03:49:12 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Wed, 6 Feb 2019 05:49:12 +0200
Subject: [squid-users] Squid 5 binaries for: Debian, Ubuntu, CentOS, Oracle,
	AWS 1+2
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAdWdqO+BvBTaBpi7w80OE2AQAAAAA=@ngtech.co.il>

I have just built a testing version of Squid 5 at:
 
*
http://ngtech.co.il/repo/bin/amzn/1/x86_64/squid-5.0.0-20190127-rc1a2df008-6
4-bin.tar.xz
*
http://ngtech.co.il/repo/bin/amzn/2/x86_64/squid-5.0.0-20190127-rc1a2df008-6
4-bin.tar.xz
*
http://ngtech.co.il/repo/bin/centos/7/x86_64/squid-5.0.0-20190127-rc1a2df008
-64-bin.tar.xz
*
http://ngtech.co.il/repo/bin/debian/jessie/amd64/squid-5.0.0-20190127-rc1a2d
f008-64-bin.tar.xz
*
http://ngtech.co.il/repo/bin/debian/stretch/amd64/squid-5.0.0-20190127-rc1a2
df008-64-bin.tar.xz
*
http://ngtech.co.il/repo/bin/oracle/7/x86_64/squid-5.0.0-20190127-rc1a2df008
-64-bin.tar.xz
*
http://ngtech.co.il/repo/bin/ubuntu/14.04/amd64/squid-5.0.0-20190127-rc1a2df
008-64-bin.tar.xz
*
http://ngtech.co.il/repo/bin/ubuntu/16.04/amd64/squid-5.0.0-20190127-rc1a2df
008-64-bin.tar.xz
*
http://ngtech.co.il/repo/bin/ubuntu/18.04/amd64/squid-5.0.0-20190127-rc1a2df
008-64-bin.tar.xz
 
In each and every directory there are couple tar.xz files:
squid-5.0.0-20190127-rc1a2df008-64-bin-stripped-only.tar.xz 
squid-5.0.0-20190127-rc1a2df008-64-bin-stripped.tar.xz
squid-5.0.0-20190127-rc1a2df008-64-bin.tar.xz
squid-5.0.0-20190127-rc1a2df008-64-debug-only.tar.xz
 
All of the above are meant for testing squid 5 without the need to build
squid by your self.
The recommended method of installation is to first install the files into a
separate directory then ROOT(/).
IE to some thing like "/opt/src/squid/"
Then make sure that the permissions for all the files and folders are right
and then and only then use couple manual commands to copy the relevant
binaries into your system.
The system should already have some version of squid installed and the
configuration should have a ready to use backup.
 
An example installer that can be used on Ubuntu and Debian can be found at:
http://gogs.ngtech.co.il/NgTech-LTD/Squid-installer
http://gogs.ngtech.co.il/NgTech-LTD/Squid-installer/src/master/install-deb-s
quid.sh
 
it was designed for 4.4 and 4.5 but can be used as a guide for 5.X.
 
If you have any questions regarding these binaries let me know.
The binaries can be downloaded securely on a HTTPS url that contains the
certificate with SHA-256 signature:
F0:CF:CD:71:0D:A5:E0:9E:7A:6B:D8:1D:09:5E:56:AB:AD:B1:39:5F:0B:9B:63:E5:A8:B
7:88:E0:DC:5B:61:9A
 
Eliezer 
 
----
 <http://ngtech.co.il/main-en/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email:  <mailto:eliezer at ngtech.co.il> eliezer at ngtech.co.il

 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190206/a1119b55/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11295 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190206/a1119b55/attachment.png>

From ygirardin at olfeo.com  Wed Feb  6 09:10:21 2019
From: ygirardin at olfeo.com (Yann Girardin)
Date: Wed, 6 Feb 2019 10:10:21 +0100
Subject: [squid-users] AIA fetching in squid
Message-ID: <DEE553E0920CFA41BAF85A4B9C6FC3498F2CAE3BD4@EXCHANGESRV1.olfeo-lab.net>

Hi all,

I am using ssl bump and it's work fine a lot of SSL sites, but some of those are misconfigured and squid won't succeed to get the correct certificate, and give me the following error :
SEC_ERROR_UNKNOWN_ISSUER

Looking on the internet I understand that this is a SSL server misconfiguration, but I know that some browser like safari, and chrome are implementing the AIA fetching to get the missing certificates using the information store in the authority information access of the certificate.

Is there a way to activate this AIA fetching in squid or do i have to implement it myself using a helper with the sslcrtvalidator_program ?

Thanks



[cid:image002.png at 01D4BE04.2B0E4890]

Yann Girardin
Product Owner
t :  +33 (0)1 84 17 71 75
e :  ygirardin at olfeo.com<mailto:ygirardin at olfeo.com>
w :  www.olfeo.com<https://www.olfeo.com/>
4 rue de Ventadour, 75001 Paris



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190206/1d3ea60c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.png
Type: image/png
Size: 13389 bytes
Desc: image002.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190206/1d3ea60c/attachment.png>

From lukgom at gmail.com  Wed Feb  6 10:14:39 2019
From: lukgom at gmail.com (Lucolo)
Date: Wed, 6 Feb 2019 04:14:39 -0600 (CST)
Subject: [squid-users] SMP-Workers + Rock Cache not caching as much as
	SMP-Workers + AUFS
Message-ID: <1549448079205-0.post@n4.nabble.com>

Hi everybody

I'm having some problems trying to best tune efficient web caching with
Squid.

After several configurations I realized that in my case SMP-Workers + AUFS
is more efficiente than SMP-Workers + Rock Cache.

I tried to use the same parameters and options in both cases, just to make
sure no options was different, apart from Rock or AUFS.

These are my files:
Workers + AUFS:
squid_SMP_Workers_AUFS.conf
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377658/squid_SMP_Workers_AUFS.conf>  

Workers + Rock Cache:
squid_CARP_SMP_Workers_Rock.conf
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377658/squid_CARP_SMP_Workers_Rock.conf>  
frontend.conf
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377658/frontend.conf>  
backend.conf
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377658/backend.conf>  

For example, my outputs:

Cache information for squid SMP-Workers + AUFS:
        Hits as % of all requests:      5min: 19.3%, 60min: 24.6%
        Hits as % of bytes sent:        5min: 8.6%, 60min: 13.3%
        Memory hits as % of hit requests:       5min: 0.0%, 60min: 0.0%
        Disk hits as % of hit requests: 5min: 65.1%, 60min: 66.4%
Files: Number of file desc currently in use: 6971

Cache information for squid SMP-Workers + Rock Cache:
        Hits as % of all requests:      5min: 4.6%, 60min: 5.3%
        Hits as % of bytes sent:        5min: 0.8%, 60min: 0.6%
        Memory hits as % of hit requests:       5min: 12.2%, 60min: 11.7%
        Disk hits as % of hit requests: 5min: 22.7%, 60min: 21.7%
Files: Number of file desc currently in use: 7366

The question is, is there any plus config or option I have to configure in
rock cache to force more web caching, at least the same as AUFS
configuration?

I actualy have 2 proxy servers, one configuration each. The two of them have
same hardware:
- centos-release-7-6.1810.2.el7.centos.x86_64
- 32 GB RAM
- 4 disk, 2 TB each, 8 TB in total
- Squid compilation info
configure options:  '--build=x86_64-redhat-linux-gnu'
'--host=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr'
'--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin'
'--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include'
'--libdir=/usr/lib64' '--libexecdir=/usr/libexec'
'--sharedstatedir=/var/lib' '--mandir=/usr/share/man'
'--infodir=/usr/share/info' '--exec_prefix=/usr'
'--libexecdir=/usr/lib64/squid' '--localstatedir=/var'
'--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
'--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid'
'--disable-dependency-tracking' '--enable-follow-x-forwarded-for'
'--enable-auth'
'--enable-auth-basic=DB,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam,fake'
'--enable-auth-ntlm=fake' '--enable-auth-digest=file,LDAP,eDirectory'
'--enable-auth-negotiate=kerberos,wrapper'
'--enable-external-acl-helpers=wbinfo_group,kerberos_ldap_group,LDAP_group,delayer,file_userip,SQL_session,unix_group,session,time_quota'
'--enable-cache-digests' '--enable-cachemgr-hostname=localhost'
'--enable-delay-pools' '--enable-epoll' '--enable-icap-client'
'--enable-ident-lookups' '--enable-linux-netfilter'
'--enable-removal-policies=heap,lru' '--enable-snmp'
'--enable-storeio=aufs,diskd,ufs,rock' '--enable-wccpv2' '--enable-esi'
'--enable-security-cert-generators' '--enable-security-cert-validators'
'--enable-icmp' '--with-aio' '--with-default-user=squid'
'--with-filedescriptors=16384' '--with-dl' '--with-openssl'
'--enable-ssl-crtd' '--with-pthreads' '--with-included-ltdl'
'--disable-arch-native' '--without-nettle'
'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu'
'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions
-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches  
-m64 -mtune=generic' 'LDFLAGS=-Wl,-z,relro ' 'CXXFLAGS=-O2 -g -pipe -Wall
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong
--param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -fPIC'
'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig'
--enable-ltdl-convenience

Thanks in advance.





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From alexmaystat at mail.ru  Wed Feb  6 10:48:19 2019
From: alexmaystat at mail.ru (alexmaystat)
Date: Wed, 6 Feb 2019 04:48:19 -0600 (CST)
Subject: [squid-users] Proxing only special file types
Message-ID: <1549450099364-0.post@n4.nabble.com>

Hello. I have squid proxy server.
Configured SSL inspection and add your JS code. 
Is it possible to inspect and add JS code only to files of a specific file
type (for example, only to JS text/javascript). 
Or it is possible to proxy only JS files, and send the rest of the content
and requests outside squid proxy?

Thanks. 



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From Antony.Stone at squid.open.source.it  Wed Feb  6 10:55:28 2019
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 6 Feb 2019 10:55:28 +0000
Subject: [squid-users] Proxing only special file types
In-Reply-To: <1549450099364-0.post@n4.nabble.com>
References: <1549450099364-0.post@n4.nabble.com>
Message-ID: <201902061055.28493.Antony.Stone@squid.open.source.it>

On Wednesday 06 February 2019 at 10:48:19, alexmaystat wrote:

> Hello. I have squid proxy server.

Version?  Operating system?

> Configured SSL inspection

How?  Give us some details.

> and add your JS code.

What?

> Is it possible to inspect and add JS code only to files of a specific file
> type (for example, only to JS text/javascript).

Yes - try content adaptation.

> Or it is possible to proxy only JS files, and send the rest of the content
> and requests outside squid proxy?

No.


Antony.

-- 
Wanted: telepath.   You know where to apply.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid at bloms.de  Wed Feb  6 10:56:47 2019
From: squid at bloms.de (Dieter Bloms)
Date: Wed, 6 Feb 2019 11:56:47 +0100
Subject: [squid-users] AIA fetching in squid
In-Reply-To: <DEE553E0920CFA41BAF85A4B9C6FC3498F2CAE3BD4@EXCHANGESRV1.olfeo-lab.net>
References: <DEE553E0920CFA41BAF85A4B9C6FC3498F2CAE3BD4@EXCHANGESRV1.olfeo-lab.net>
Message-ID: <20190206105647.ndxwwv4edha5a7fg@bloms.de>

Hello,

On Wed, Feb 06, Yann Girardin wrote:

> I am using ssl bump and it's work fine a lot of SSL sites, but some of
> those are misconfigured and squid won't succeed to get the correct
> certificate, and give me the following error :
> SEC_ERROR_UNKNOWN_ISSUER
> 
> Looking on the internet I understand that this is a SSL server
> misconfiguration, but I know that some browser like safari, and chrome
> are implementing the AIA fetching to get the missing certificates
> using the information store in the authority information access of the
> certificate.
> 
> Is there a way to activate this AIA fetching in squid or do i have to
> implement it myself using a helper with the sslcrtvalidator_program ?

I've added these few lines:

--snip--
acl fetch_intermediate_certificate transaction_initiator certificate-fetching
http_access allow fetch_intermediate_certificate
cache allow fetch_intermediate_certificate
cache deny all
--snip--


-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
>From field.


From alexmaystat at mail.ru  Wed Feb  6 11:21:57 2019
From: alexmaystat at mail.ru (alexmaystat)
Date: Wed, 6 Feb 2019 05:21:57 -0600 (CST)
Subject: [squid-users] Proxing only special file types
In-Reply-To: <201902061055.28493.Antony.Stone@squid.open.source.it>
References: <1549450099364-0.post@n4.nabble.com>
 <201902061055.28493.Antony.Stone@squid.open.source.it>
Message-ID: <1549452117492-0.post@n4.nabble.com>

Squid version - 3.5
Operation system - CentOS
SSL inspection - use SSL_Bump + ECAP for content modification.
I mean add my own JS code.

I need user ECAP with modification to parse what file type and after that,
if javascript file - inject my additional code, yes?



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From Antony.Stone at squid.open.source.it  Wed Feb  6 11:28:14 2019
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 6 Feb 2019 11:28:14 +0000
Subject: [squid-users] Proxing only special file types
In-Reply-To: <1549452117492-0.post@n4.nabble.com>
References: <1549450099364-0.post@n4.nabble.com>
 <201902061055.28493.Antony.Stone@squid.open.source.it>
 <1549452117492-0.post@n4.nabble.com>
Message-ID: <201902061128.14969.Antony.Stone@squid.open.source.it>

On Wednesday 06 February 2019 at 11:21:57, alexmaystat wrote:

> Squid version - 3.5
> Operation system - CentOS
> SSL inspection - use SSL_Bump + ECAP for content modification.
> I mean add my own JS code.
> 
> I need user ECAP with modification to parse what file type and after that,
> if javascript file - inject my additional code, yes?

Sounds good to me.


Antony.

-- 
#define SIX 1+5
#define NINE 8+1

int main() {
    printf("%d\n", SIX * NINE);
}
	- thanks to ECB for bringing this to my attention

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Wed Feb  6 12:05:21 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Feb 2019 01:05:21 +1300
Subject: [squid-users] AIA fetching in squid
In-Reply-To: <DEE553E0920CFA41BAF85A4B9C6FC3498F2CAE3BD4@EXCHANGESRV1.olfeo-lab.net>
References: <DEE553E0920CFA41BAF85A4B9C6FC3498F2CAE3BD4@EXCHANGESRV1.olfeo-lab.net>
Message-ID: <2c6810d6-dc7c-53f9-bbe0-9970b7d68fb9@treenet.co.nz>

On 6/02/19 10:10 pm, Yann Girardin wrote:
> 
> Is there a way to activate this AIA fetching in squid or do i have to

Fetching missing intermediate CA certificates is implemented in Squid-4.
All you need do is check that your access controls permit those requests
to happen.

If you have Squid-3.5 the
<http://www.squid-cache.org/Doc/config/sslproxy_foreign_intermediate_certs/>
directive can load intermediate certs to use for the missing cert chain
entries.


> implement it myself using a helper with the sslcrtvalidator_program ?
> 

That is also possible.


PS. AIA fetching requires the certificate AIA to have a value. Some of
these misconfigurations are because it is missing. In that case there is
nothing that can be done to resolve the error without already having the
relevant Issuer cert.


Amos


From squid3 at treenet.co.nz  Wed Feb  6 12:30:26 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Feb 2019 01:30:26 +1300
Subject: [squid-users] SMP-Workers + Rock Cache not caching as much as
 SMP-Workers + AUFS
In-Reply-To: <1549448079205-0.post@n4.nabble.com>
References: <1549448079205-0.post@n4.nabble.com>
Message-ID: <3bc48a45-6558-8897-db49-be56e7e347d5@treenet.co.nz>

On 6/02/19 11:14 pm, Lucolo wrote:
> Hi everybody
> 
> I'm having some problems trying to best tune efficient web caching with
> Squid.
> 
> After several configurations I realized that in my case SMP-Workers + AUFS
> is more efficiente than SMP-Workers + Rock Cache.

Do you understand why that is?


> 
> I tried to use the same parameters and options in both cases, just to make
> sure no options was different, apart from Rock or AUFS.
> 
> These are my files:
> Workers + AUFS:
> squid_SMP_Workers_AUFS.conf
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377658/squid_SMP_Workers_AUFS.conf>  
> 
> Workers + Rock Cache:
> squid_CARP_SMP_Workers_Rock.conf
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377658/squid_CARP_SMP_Workers_Rock.conf>  
> frontend.conf
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377658/frontend.conf>  
> backend.conf
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377658/backend.conf>  
> 

Er, those are vastly different configurations. The cache_dir parameters
may be the same, but the traffic flowing through has major differences.

The AUFS setup:
 - 4 workers operating independent of each other in full parallel.
 - any sized object allowed to cache.
 - TCP connection based load balancing by the OS.

The Rock setup:
 - all traffic funneled through one worker
 - 4 workers operating with shared caches.
 - objects larger than 131072 bytes not permitted to cache.
 - CARP load balancing selectively channels objects by URL to particular
worker.



> For example, my outputs:
> 
> Cache information for squid SMP-Workers + AUFS:
>         Hits as % of all requests:      5min: 19.3%, 60min: 24.6%
>         Hits as % of bytes sent:        5min: 8.6%, 60min: 13.3%
>         Memory hits as % of hit requests:       5min: 0.0%, 60min: 0.0%
>         Disk hits as % of hit requests: 5min: 65.1%, 60min: 66.4%
> Files: Number of file desc currently in use: 6971
> 
> Cache information for squid SMP-Workers + Rock Cache:
>         Hits as % of all requests:      5min: 4.6%, 60min: 5.3%
>         Hits as % of bytes sent:        5min: 0.8%, 60min: 0.6%
>         Memory hits as % of hit requests:       5min: 12.2%, 60min: 11.7%
>         Disk hits as % of hit requests: 5min: 22.7%, 60min: 21.7%
> Files: Number of file desc currently in use: 7366

Those numbers need to be placed in context of how much traffic is going
through each proxy.

For some reason you are not getting any memory hits in the AUFS setup.
Whereas >10% of the traffic in the rock setup is not being slowed down
by the disk access.


> 
> The question is, is there any plus config or option I have to configure in
> rock cache to force more web caching, at least the same as AUFS
> configuration?

That question does not make much sense. There is no option to force
caching with AUFS - so "at least the same" is already true in regards to
what you are asking for.


You missed out the rest of the squid -v output which says what
particular version and vendor build (or not) you are using.


Amos


From alexmaystat at mail.ru  Wed Feb  6 14:39:10 2019
From: alexmaystat at mail.ru (alexmaystat)
Date: Wed, 6 Feb 2019 08:39:10 -0600 (CST)
Subject: [squid-users] Proxing only special file types
In-Reply-To: <201902061128.14969.Antony.Stone@squid.open.source.it>
References: <1549450099364-0.post@n4.nabble.com>
 <201902061055.28493.Antony.Stone@squid.open.source.it>
 <1549452117492-0.post@n4.nabble.com>
 <201902061128.14969.Antony.Stone@squid.open.source.it>
Message-ID: <1549463950713-0.post@n4.nabble.com>

Do you think this is possible, right?



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From paul at doignon.fr  Wed Feb  6 14:52:26 2019
From: paul at doignon.fr (Paul Doignon)
Date: Wed, 06 Feb 2019 15:52:26 +0100
Subject: [squid-users] Filering HTTPS URLs - A complete configuration
In-Reply-To: <48ab3054-7651-564a-c79e-fc2b38db7b4a@treenet.co.nz>
References: <168be13b6f9.c72dacf0274895.400411858861977298@doignon.fr>
 <48ab3054-7651-564a-c79e-fc2b38db7b4a@treenet.co.nz>
Message-ID: <168c34bb82e.114bc9e7c22107.5629353171280088961@doignon.fr>

Thanks, I appreciate your detailed answer.

 > > I'm struggling a lot to configure Squid. To improve the security of my app in my AWS private subnet,
 > 
 > If it is indeed *your* app; then please alter it not to require the
 > interception we see below. Ability to connect to a TLS explicit proxy or
 > just sending regular proxy CONNECT tunnel is a leap up in security.

I wish I could too ! Unfortunately, we use some third party libraries that do not support proxies (or not well). What a shame : (
 
 > > # Hide some reavealing or useless headers
 > > forwarded_for delete
 > > httpd_suppress_version_string off
 > > reply_header_access X-Cache deny all
 > > reply_header_access X-Cache-Lookup deny all
 > > via off
 > > 
 > > # Tuning
 > > max_filedesc 10000
 > > 
 > > # Disable access to manager
 > > http_access deny manager
 > 
 > 2) you are missing the security protections from the default squid.conf...
 
I have not hardened Squid yet, but you mean default `acl localnet src [...]` rules ? I'm not sure about this.

 > Please see <https://wiki.squid-cache.org/Features/SslPeekAndSplice> for
 > details on the TLS handshake process and what SSL-Bump does during that.

Another read was indeed interesting, I think I corrected ssl_bump directives. However I still can't make it work.
Just for the record, I would like to block everything but some HTTPS websites for particular URLs. The ssl::server_name acl is not enough for me, I would like to use url_regex or similar.
Ant that's where it gets wrong, I can't make Squid make the link between `ssl_bump bump` and url_regex.

# --
# General
shutdown_lifetime 1 seconds 

# Hide some reavealing or useless headers
forwarded_for delete
httpd_suppress_version_string off
reply_header_access X-Cache deny all
reply_header_access X-Cache-Lookup deny all
via off

# Tuning
max_filedesc 10000

# Disable access to manager
http_access deny manager

# Misc, TODO 
http_port 3128
host_verify_strict off 

# Handling HTTPS requests
https_port 8080 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl/squid.pem options=NO_SSLv3,NO_TLSv1,NO_TLSv1_1,SINGLE_DH_USE,SINGLE_ECDH_USE intercept
sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/cache/squid/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1
acl SSL_port port 443
http_access allow SSL_port

# Whitelist
acl whitelist-regex url_regex -i thirdparty.com/upload/stuff/
acl whitelist-regex url_regex -i otherthirdparty.com/specific-path/
http_access allow whitelist-regex

# SSL bump
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
ssl_bump stare step1 all
ssl_bump stare step2 all
ssl_bump bump whitelist-regex
ssl_bump terminate all

# Deny the rest
http_access deny all
# --

 > > Should I use squid 4 for this ?
 > 
 > TL;DR : Yes.
 
I did that, thanks !
Easy to install and migrate on arch but I think I will need to compile it for Amazon Linux.


 ---- On Tue, 05 Feb 2019 16:35:52 +0100 Amos Jeffries <squid3 at treenet.co.nz> wrote ---- 
 > On 6/02/19 3:33 am, Paul Doignon wrote:
 > > Hi,
 > > 
 > > I'm struggling a lot to configure Squid. To improve the security of my app in my AWS private subnet,
 > 
 > If it is indeed *your* app; then please alter it not to require the
 > interception we see below. Ability to connect to a TLS explicit proxy or
 > just sending regular proxy CONNECT tunnel is a leap up in security.
 > 
 > 
 > > I would like to build a HTTPS proxy to whitelist *only* some URLs.
 > > My wish is to *not* rely on SNI filtering but bump HTTPS traffic in order to filter the URLs (path) of HTTPS requests. I know that means to install a custom CA.
 > > The thing is... I have a hard compiling a working configuration file for Squid 3.5, most examples are outdated or incomplete.
 > 
 > It looks below like you are of the mistaken belief that "HTTPS requests"
 > are actually a distinct thing that can be manipulated and tested.
 > 
 > "HTTPS" is just a moniker used to describe a multi-layer system for
 > delivering HTTP messages securely. This has a major impact on what can
 > be done at any particular time, especially regarding the URLs from those
 > HTTP messages.
 > 
 > 
 > > 
 > > My current config is :
 > > 
 > > # ---
 > > # General
 > > cache_effective_user squid
 > > cache_effective_group squid
 > > shutdown_lifetime 1 seconds 
 > > visible_hostname squid
 > > 
 > 
 > Note 1) 'squid' is not a unique hostname. Ideally it should be a FQDN.
 > At the very least an internally resolvable name so the URLs Squid
 > generates with this string as the domain name will be valid for clients
 > needing to download objects with those URLs from Squid. Either way it
 > has to be unique across all proxies the traffic *might* travel -
 > otherwise the messages will be dropped in transit. So definitely do not
 > use something this simple and often-repeated as "squid" or "proxy".
 > 
 > 
 > > # Hide some reavealing or useless headers
 > > forwarded_for delete
 > > httpd_suppress_version_string off
 > > reply_header_access X-Cache deny all
 > > reply_header_access X-Cache-Lookup deny all
 > > via off
 > > 
 > > # Tuning
 > > max_filedesc 10000
 > > 
 > > # Disable access to manager
 > > http_access deny manager
 > > 
 > 
 > 2) you are missing the security protections from the default squid.conf...
 > 
 > 
 > > # Handling HTTPS requests
 > > https_port 8080 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl/squid.pem options=NO_SSLv3,NO_TLSv1,NO_TLSv1_1,SINGLE_DH_USE,SINGLE_ECDH_USE intercept
 > > sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB
 > > sslcrtd_children 8 startup=1 idle=1
 > > acl SSL_port port 443
 > > http_access allow SSL_port
 > > 
 > 
 > 3) Not a good idea. I see a lot of admin get this far and stop looking
 > for the proper solution when "things work".
 > 
 > Since you are intercepting traffic to reach this point it should be
 > somewhat reasonable to limit the allowed traffic to some IP range. eg.
 > the subnet of IPs you are intercepting and sending into the proxy.
 > 
 > 
 > > # Whitelist
 > > acl whitelist-regex url_regex -i thirdparty.com/upload/stuff/
 > > acl whitelist-regex url_regex -i otherthirdparty.com/specific-path/
 > > http_access allow whitelist-regex
 > 
 > Okay.
 > 
 > > 
 > > # SSL bump
 > > acl step1 at_step SslBump1
 > > ssl_bump peek step1
 > 
 >  ... if the client is allowed to connect to the proxy, fetch its
 > clientHello details...
 > 
 > 
 > > ssl_bump bump whitelist-regex
 > 
 > ... then try to do the impossible. We only have TLS details at this
 > point. There is no HTTP message - therefore no URL to match against.
 >  -> result: skip this line, never do this "bump" action.
 > 
 > 
 > > ssl_bump terminate step2 !whitelist-regex
 > 
 > ... regex still cannot match.
 > ... but a non-match (aka false) with '!' means true.
 > 
 > So at step2 always terminate the connection.
 > 
 > 
 > Notice how there has still not been anything even remotely HTTP from the
 > client/app and they are now disconnected.
 > 
 > > 
 > > # Deny the rest
 > > http_access deny all
 > > # --- 
 > > 
 > > What I am missing ?
 > 
 > It seems understanding of what ssl_bump is doing is lacking.
 > 
 > Please see <https://wiki.squid-cache.org/Features/SslPeekAndSplice> for
 > details on the TLS handshake process and what SSL-Bump does during that.
 > 
 > 
 > > Should I use squid 4 for this ?
 > 
 > TL;DR : Yes.
 > 
 > 
 > Long version:
 > 
 > TLS is a volatile environment these days and each Squid release has
 > large improvements to cope with that change. You will find that v4 works
 > okay in a lot of TLS situations where v3 would the throwing up errors
 > and needing extra config workarounds.
 > 
 > Also, v3.x are all officially deprecated / no longer supported. v4 is
 > the current stable release.
 > 
 > 
 > Amos
 > _______________________________________________
 > squid-users mailing list
 > squid-users at lists.squid-cache.org
 > http://lists.squid-cache.org/listinfo/squid-users
 > 




From leomessi983 at yahoo.com  Wed Feb  6 14:52:06 2019
From: leomessi983 at yahoo.com (leo messi)
Date: Wed, 6 Feb 2019 14:52:06 +0000 (UTC)
Subject: [squid-users] ssl-bump does not redirect to block page
References: <1850120258.3983034.1549464726329.ref@mail.yahoo.com>
Message-ID: <1850120258.3983034.1549464726329@mail.yahoo.com>

HiMy squid config is something like this:acl blk ssl::server_name .google.com
http_access deny blk
http_access allow all


http_port 0.0.0.0:3128
http_port 0.0.0.0:3129 tproxy
https_port 3130 tproxy ssl-bump \
? cert=/etc/squid/ssl_cert/myCA.pem \
? generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
sslcrtd_program /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 4MB

acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump splice all


My problem is when i block some pages like google.com,my firefox browser show "secure connection failed",but i want it to show block page or warning page, how can i do this?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190206/eded46ec/attachment.htm>

From leomessi983 at yahoo.com  Wed Feb  6 14:55:03 2019
From: leomessi983 at yahoo.com (leo messi)
Date: Wed, 6 Feb 2019 14:55:03 +0000 (UTC)
Subject: [squid-users] ssl-bump does not redirect to block page
References: <1251104262.3976220.1549464903137.ref@mail.yahoo.com>
Message-ID: <1251104262.3976220.1549464903137@mail.yahoo.com>

HiMy squid config is something like this:acl blk ssl::server_name .google.com
http_access deny blk
http_access allow all


http_port 0.0.0.0:3128
http_port 0.0.0.0:3129 tproxy
https_port 3130 tproxy ssl-bump \
? cert=/etc/squid/ssl_cert/myCA.pem \
? generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
sslcrtd_program /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 4MB

acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump splice all


My problem is when i block some pages like google.com,my Firefox browser show "secure connection failed",but i want it to show block page or warning page, how can i do this?
  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190206/bf9ccf4c/attachment.htm>

From xeron.oskom at gmail.com  Wed Feb  6 17:39:48 2019
From: xeron.oskom at gmail.com (Ivan Larionov)
Date: Wed, 6 Feb 2019 09:39:48 -0800
Subject: [squid-users] Bad HTTP header error on non-standard HTTP response
	code
Message-ID: <CAHvB88zHN0bXHCsGNLh2i-9CA2WTGZ2jsuWr6MydLxzhf+mPaQ@mail.gmail.com>

Hello.

We've recently noticed a difference in behavior between squid v3 and v4.

On HTTP response with non-standard 4-digits HTTP code, for example
something like this:

HTTP/1.1 5009 Update Error
Connection: Closed

{"code":500911,"message":"update record error"}

squid 3 just passes this response to the client, but squid 4 returns 502
with ERR_INVALID_RESP template and writes into cache.log:

WARNING: HTTP: Invalid Response: Bad header encountered from ? AKA ?

While I understand that 4-digits response code is not standard I'd like to
know:

Is it expected behavior and is there an option to change squid 4 behavior
to match squid 3?

Thanks!

-- 
With best regards, Ivan Larionov.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190206/c07ca7f2/attachment.htm>

From walid.shaari at linux.com  Wed Feb  6 19:03:18 2019
From: walid.shaari at linux.com (Walid A. Shaari)
Date: Wed, 6 Feb 2019 22:03:18 +0300
Subject: [squid-users] Connection to cache peer failed "SSL Transparent
	proxy'
In-Reply-To: <3c826662-b81d-d885-3c0c-9c3430ce7316@treenet.co.nz>
References: <CAN4dctrM9vU9gKtyKwkU8Km+WhvA8xXaT8W7abu4HuihpLeGXw@mail.gmail.com>
 <ec2e4d70-98d7-1354-9507-d360a8d8bec8@treenet.co.nz>
 <CAN4dctqz-VsR=9B7uV=OW5AGCGxHxgm=a5sMab23qQo9g6wm3Q@mail.gmail.com>
 <3c826662-b81d-d885-3c0c-9c3430ce7316@treenet.co.nz>
Message-ID: <CAN4dctqQA+sgu6UZ1q7ycm1LaCqNenOSao6J7NCOeR8ZjcjGHQ@mail.gmail.com>

On Wed, 6 Feb 2019 at 05:53, Amos Jeffries <squid3 at treenet.co.nz> wrote:

>
> It depends on what your policies are as to which is the better approach
> to take. It is looking a bit like (2) is probably the way to go. With
> the switch from dstdomain to server_name type for the ssl_bump
> processing this issue may just disappear.
>
>
Thank you, will try it tomorow.

>
> >
> > by the way, my final goal is to enable https traffic through, not really
> > intercept it, by trial and error and reading the mailing list, that
> > config below is what seems to be working for me right now, can not
> > confirm totally as parent proxy is not under my control, nor is the
> > appliance, however from the access.log and system message logs, things
> > look better than earlier.  what is the best resource to understand the
> > peek and splice, any good places other than squid cache main url?
> >
>
> The documentation of what modern Squid SSL-Bump feature does can be
> found at <https://wiki.squid-cache.org/Features/SslPeekAndSplice>. It is
> community maintained and kept as up to date as we can.
>
> That page links to the relevant squid.conf documentation for the
> relevant pieces. The whole TLS situation is a bit volatile so questions
> are welcome here if you are unsure about anything in regards to your
> specific Squid version, or observe things not matching that text.
>
> ..... ..... ......
> If you try to force things you will run up against the lack of
> re-CONNECT features in Squid. That is Squid cannot yet generate CONNECT
> tunnels through non-TLS peers like you have.
>
> Given that the intercepted HTTPS traffic must leave Squid over secure
> connections that effectively means it cannot use the peer as it normally
> would and has to send that traffic via ORIGINAL_DST / DIRECT connections
> to the HTTPS server. If those are forbidden the transaction has no
> choice but to terminate with an error message.
>
>
> FWIW: Measurement Factory have an experimental branch adding that
> re-CONNECT functionality to Squid, if you are okay running alpha quality
> code that may be of interest.
>  On the other side, I am working with a client on a configuration that
> should result in the needed behaviour for the stable releases. That is
> just entering testing and depends on whether they are willing for the
> details to be published.
>

I am ok if it resolves my issues and does not introduce new bugs, I have
some deadlines that I need to meet or otherwise drop all of this.

>
>
>  > ####   Anonymous access to parent proxy
> >
> > #forwarded_for  delete
> >
> > #request_header_access Surrogate-Capability deny all
> >
>
> FYI: the bug behind the S-C header problems is now fixed in v4.5
> release. Once you upgrade this can be removed.
>

I am on v4.5

>
>  >
> > dns_v4_first on
> >
> > cache_peer  192.168.4.22  parent 9090 0 no-query
> > #sslcapath=/etc/pki/ca-trust/source/anchors/
> >
> > acl local-network dstdomain .azcompany.com  #
> > tighten after finalizng troubleshooting, maybe replace with localnet
> >
> > http_access allow all
> >
> > never_direct deny local-network    # revisit not using DNS for resolution
> >
> > never_direct allow all
> >
> > http_port 8080 intercept    # should I really use intercept in here? can
> > I get away without it
> >
> > https_port 8090 intercept ssl-bump generate-host-certificates=on
> > cert=/etc/squid/ssl_certs/bccaz01CA.pem
> > dynamic_cert_mem_cache_size=16MB #connection-auth=off
> >
> > http_port 8100    #forward port not used, only for troubleshooting.
> >
> >
> > sslcrtd_program /usr/lib64/squid/security_file_certgen -s
> > /var/spool/squid/ssl_db -M 4MB
> >
> >
> > acl step1 at_step SslBump1
> >
> > acl azure_sites  dstdom_regex microsoft.com <http://microsoft.com>
> > azure.com <http://azure.com> azureedge.net <http://azureedge.net>
> > microsoftazurestack.com <http://microsoftazurestack.com>
> > trafficmanager.net <http://trafficmanager.net>  wdcp.microsoft.com
> > <http://wdcp.microsoft.com> wdcpalt.microsoft.com
> > <http://wdcpalt.microsoft.com> updates.microsoft.com
> > <http://updates.microsoft.com>
> >
> > acl azure_sites2 dstdom_regex download.microsoft.com
> > <http://download.microsoft.com> msdl.microsoft.com
> > <http://msdl.microsoft.com> crl.microsoft.com <http://crl.microsoft.com>
> > secure.aadcdn.microsoftonline-p.com
> > <http://secure.aadcdn.microsoftonline-p.com>
> >
>
> FYI: Regex is a slow procedure so when possible should be avoided. Since
> all the above are domain names it looks like dstdomain would be better
> with these ACL values. Some maybe using the wildcard dstdomain syntax.
>
>  acl azure_sites dstdomain .microsoft.com \
>     .azure.com .azureedge.net \
>     .microsoftazurestack.com .trafficmanager.net
>
>  acl azure_sites2 dstdomain .microsoft.com \
>     secure.aadcdn.microsoftonline-p.com


Great, thanks, will use that definitely.

>
>
>
> > ssl_bump peek step1
> >
> > ssl_bump splice  azure_sites azure_sites2 #Avoid bumping Microsoft/Azure
> > related sites
> >
>
> The way ACLs work in Squid items on a line like "azure_sites
> azure_sites2" *both* have to match for the lines action to be used.
>
> So the above line means all those domains except *.microsoft.com will
> *not* be spliced here even if a URL domain was available.
>

Sorry, I did not get that, is it because microsoft.com is duplicated by
mistake twice on both lines?

Thank you Amos, you were great help.

Walid
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190206/4e3934ef/attachment.htm>

From eliezer at ngtech.co.il  Wed Feb  6 19:29:41 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Wed, 6 Feb 2019 21:29:41 +0200
Subject: [squid-users] Filering HTTPS URLs - A complete configuration
In-Reply-To: <168c34bb82e.114bc9e7c22107.5629353171280088961@doignon.fr>
References: <168be13b6f9.c72dacf0274895.400411858861977298@doignon.fr>
 <48ab3054-7651-564a-c79e-fc2b38db7b4a@treenet.co.nz>
 <168c34bb82e.114bc9e7c22107.5629353171280088961@doignon.fr>
Message-ID: <004801d4be52$4e69f6b0$eb3de410$@ngtech.co.il>

No need to compile and build it for AWS:
I already built it for both AWS 1 and 2:
http://ngtech.co.il/repo/amzn/

Can be downloaded and is tested to work very well on both OS.

Eliezer

* let me know if the package is good enough.

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Paul Doignon
Sent: Wednesday, February 6, 2019 16:52
To: squid-users <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Filering HTTPS URLs - A complete configuration

Thanks, I appreciate your detailed answer.

 > > I'm struggling a lot to configure Squid. To improve the security of my app in my AWS private subnet,
 > 
 > If it is indeed *your* app; then please alter it not to require the
 > interception we see below. Ability to connect to a TLS explicit proxy or
 > just sending regular proxy CONNECT tunnel is a leap up in security.

I wish I could too ! Unfortunately, we use some third party libraries that do not support proxies (or not well). What a shame : (
 
 > > # Hide some reavealing or useless headers
 > > forwarded_for delete
 > > httpd_suppress_version_string off
 > > reply_header_access X-Cache deny all
 > > reply_header_access X-Cache-Lookup deny all
 > > via off
 > > 
 > > # Tuning
 > > max_filedesc 10000
 > > 
 > > # Disable access to manager
 > > http_access deny manager
 > 
 > 2) you are missing the security protections from the default squid.conf...
 
I have not hardened Squid yet, but you mean default `acl localnet src [...]` rules ? I'm not sure about this.

 > Please see <https://wiki.squid-cache.org/Features/SslPeekAndSplice> for
 > details on the TLS handshake process and what SSL-Bump does during that.

Another read was indeed interesting, I think I corrected ssl_bump directives. However I still can't make it work.
Just for the record, I would like to block everything but some HTTPS websites for particular URLs. The ssl::server_name acl is not enough for me, I would like to use url_regex or similar.
Ant that's where it gets wrong, I can't make Squid make the link between `ssl_bump bump` and url_regex.

# --
# General
shutdown_lifetime 1 seconds 

# Hide some reavealing or useless headers
forwarded_for delete
httpd_suppress_version_string off
reply_header_access X-Cache deny all
reply_header_access X-Cache-Lookup deny all
via off

# Tuning
max_filedesc 10000

# Disable access to manager
http_access deny manager

# Misc, TODO 
http_port 3128
host_verify_strict off 

# Handling HTTPS requests
https_port 8080 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl/squid.pem options=NO_SSLv3,NO_TLSv1,NO_TLSv1_1,SINGLE_DH_USE,SINGLE_ECDH_USE intercept
sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/cache/squid/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1
acl SSL_port port 443
http_access allow SSL_port

# Whitelist
acl whitelist-regex url_regex -i thirdparty.com/upload/stuff/
acl whitelist-regex url_regex -i otherthirdparty.com/specific-path/
http_access allow whitelist-regex

# SSL bump
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
ssl_bump stare step1 all
ssl_bump stare step2 all
ssl_bump bump whitelist-regex
ssl_bump terminate all

# Deny the rest
http_access deny all
# --

 > > Should I use squid 4 for this ?
 > 
 > TL;DR : Yes.
 
I did that, thanks !
Easy to install and migrate on arch but I think I will need to compile it for Amazon Linux.


 ---- On Tue, 05 Feb 2019 16:35:52 +0100 Amos Jeffries <squid3 at treenet.co.nz> wrote ---- 
 > On 6/02/19 3:33 am, Paul Doignon wrote:
 > > Hi,
 > > 
 > > I'm struggling a lot to configure Squid. To improve the security of my app in my AWS private subnet,
 > 
 > If it is indeed *your* app; then please alter it not to require the
 > interception we see below. Ability to connect to a TLS explicit proxy or
 > just sending regular proxy CONNECT tunnel is a leap up in security.
 > 
 > 
 > > I would like to build a HTTPS proxy to whitelist *only* some URLs.
 > > My wish is to *not* rely on SNI filtering but bump HTTPS traffic in order to filter the URLs (path) of HTTPS requests. I know that means to install a custom CA.
 > > The thing is... I have a hard compiling a working configuration file for Squid 3.5, most examples are outdated or incomplete.
 > 
 > It looks below like you are of the mistaken belief that "HTTPS requests"
 > are actually a distinct thing that can be manipulated and tested.
 > 
 > "HTTPS" is just a moniker used to describe a multi-layer system for
 > delivering HTTP messages securely. This has a major impact on what can
 > be done at any particular time, especially regarding the URLs from those
 > HTTP messages.
 > 
 > 
 > > 
 > > My current config is :
 > > 
 > > # ---
 > > # General
 > > cache_effective_user squid
 > > cache_effective_group squid
 > > shutdown_lifetime 1 seconds 
 > > visible_hostname squid
 > > 
 > 
 > Note 1) 'squid' is not a unique hostname. Ideally it should be a FQDN.
 > At the very least an internally resolvable name so the URLs Squid
 > generates with this string as the domain name will be valid for clients
 > needing to download objects with those URLs from Squid. Either way it
 > has to be unique across all proxies the traffic *might* travel -
 > otherwise the messages will be dropped in transit. So definitely do not
 > use something this simple and often-repeated as "squid" or "proxy".
 > 
 > 
 > > # Hide some reavealing or useless headers
 > > forwarded_for delete
 > > httpd_suppress_version_string off
 > > reply_header_access X-Cache deny all
 > > reply_header_access X-Cache-Lookup deny all
 > > via off
 > > 
 > > # Tuning
 > > max_filedesc 10000
 > > 
 > > # Disable access to manager
 > > http_access deny manager
 > > 
 > 
 > 2) you are missing the security protections from the default squid.conf...
 > 
 > 
 > > # Handling HTTPS requests
 > > https_port 8080 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl/squid.pem options=NO_SSLv3,NO_TLSv1,NO_TLSv1_1,SINGLE_DH_USE,SINGLE_ECDH_USE intercept
 > > sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB
 > > sslcrtd_children 8 startup=1 idle=1
 > > acl SSL_port port 443
 > > http_access allow SSL_port
 > > 
 > 
 > 3) Not a good idea. I see a lot of admin get this far and stop looking
 > for the proper solution when "things work".
 > 
 > Since you are intercepting traffic to reach this point it should be
 > somewhat reasonable to limit the allowed traffic to some IP range. eg.
 > the subnet of IPs you are intercepting and sending into the proxy.
 > 
 > 
 > > # Whitelist
 > > acl whitelist-regex url_regex -i thirdparty.com/upload/stuff/
 > > acl whitelist-regex url_regex -i otherthirdparty.com/specific-path/
 > > http_access allow whitelist-regex
 > 
 > Okay.
 > 
 > > 
 > > # SSL bump
 > > acl step1 at_step SslBump1
 > > ssl_bump peek step1
 > 
 >  ... if the client is allowed to connect to the proxy, fetch its
 > clientHello details...
 > 
 > 
 > > ssl_bump bump whitelist-regex
 > 
 > ... then try to do the impossible. We only have TLS details at this
 > point. There is no HTTP message - therefore no URL to match against.
 >  -> result: skip this line, never do this "bump" action.
 > 
 > 
 > > ssl_bump terminate step2 !whitelist-regex
 > 
 > ... regex still cannot match.
 > ... but a non-match (aka false) with '!' means true.
 > 
 > So at step2 always terminate the connection.
 > 
 > 
 > Notice how there has still not been anything even remotely HTTP from the
 > client/app and they are now disconnected.
 > 
 > > 
 > > # Deny the rest
 > > http_access deny all
 > > # --- 
 > > 
 > > What I am missing ?
 > 
 > It seems understanding of what ssl_bump is doing is lacking.
 > 
 > Please see <https://wiki.squid-cache.org/Features/SslPeekAndSplice> for
 > details on the TLS handshake process and what SSL-Bump does during that.
 > 
 > 
 > > Should I use squid 4 for this ?
 > 
 > TL;DR : Yes.
 > 
 > 
 > Long version:
 > 
 > TLS is a volatile environment these days and each Squid release has
 > large improvements to cope with that change. You will find that v4 works
 > okay in a lot of TLS situations where v3 would the throwing up errors
 > and needing extra config workarounds.
 > 
 > Also, v3.x are all officially deprecated / no longer supported. v4 is
 > the current stable release.
 > 
 > 
 > Amos
 > _______________________________________________
 > squid-users mailing list
 > squid-users at lists.squid-cache.org
 > http://lists.squid-cache.org/listinfo/squid-users
 > 


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Wed Feb  6 19:52:41 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Feb 2019 08:52:41 +1300
Subject: [squid-users] Proxing only special file types
In-Reply-To: <1549463950713-0.post@n4.nabble.com>
References: <1549450099364-0.post@n4.nabble.com>
 <201902061055.28493.Antony.Stone@squid.open.source.it>
 <1549452117492-0.post@n4.nabble.com>
 <201902061128.14969.Antony.Stone@squid.open.source.it>
 <1549463950713-0.post@n4.nabble.com>
Message-ID: <5b2e24f1-92ec-f3b8-614f-0578f6d57fa2@treenet.co.nz>

On 7/02/19 3:39 am, alexmaystat wrote:
> Do you think this is possible, right?
> 

Which of the multiple questions and ideas stated earlier do you mean by
"this" ?

Content Adaptation is possible.

Causing a process which finished previously (ie send to the proxy) to
not happen based on things only found out later - is not possible.

Amos


From squid3 at treenet.co.nz  Wed Feb  6 19:57:56 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Feb 2019 08:57:56 +1300
Subject: [squid-users] ssl-bump does not redirect to block page
In-Reply-To: <1850120258.3983034.1549464726329@mail.yahoo.com>
References: <1850120258.3983034.1549464726329.ref@mail.yahoo.com>
 <1850120258.3983034.1549464726329@mail.yahoo.com>
Message-ID: <78343853-0167-c891-7cfe-1003dc80d905@treenet.co.nz>

On 7/02/19 3:52 am, leo messi wrote:
> Hi
> My squid config is something like this:
> acl blk ssl::server_name .google.com
> http_access deny blk
> http_access allow all
> 
...
> 
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump splice all
> 
> 
> My problem is when i block some pages like google.com,my firefox browser
> show "secure connection failed",but i want it to show block page or
> warning page, how can i do this?


You have chosen to splice the traffic. So far only TCP SYN packet and
TLS clientHello have happened. There is no HTTP request to 'redirect'.

To cause anything at all to display in the browser you require fully
decrypting the traffic. aka the 'bump' action.
Please see <https://wiki.squid-cache.org/Features/SslPeekAndSplice>


Amos


From squid3 at treenet.co.nz  Wed Feb  6 20:15:52 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Feb 2019 09:15:52 +1300
Subject: [squid-users] Bad HTTP header error on non-standard HTTP
 response code
In-Reply-To: <CAHvB88zHN0bXHCsGNLh2i-9CA2WTGZ2jsuWr6MydLxzhf+mPaQ@mail.gmail.com>
References: <CAHvB88zHN0bXHCsGNLh2i-9CA2WTGZ2jsuWr6MydLxzhf+mPaQ@mail.gmail.com>
Message-ID: <44fd8f82-3490-f15c-8093-2650c3ca2cf5@treenet.co.nz>

On 7/02/19 6:39 am, Ivan Larionov wrote:
> Hello.
> 
> We've recently noticed a difference in behavior between squid v3 and v4.
> 
> On HTTP response with non-standard 4-digits HTTP code, for example
> something like this:
> 
> HTTP/1.1 5009 Update Error
> Connection: Closed
> 
> {"code":500911,"message":"update record error"}


Well, according to the HTTP specification this is an HTTP/0.9 message
pretending to be an HTTP/1 message:

 HTTP/0.9 := [optional text] CRLF

 HTTP/1.x := "HTTP/1." DIGIT SP 3*DIGIT SP [optional text] CRLF


Due to complaints Squid-4 dropped implicit support for HTTP/0.9
responses to HTTP/1 requests. The client is now required to make an
HTTP/0.9 style request for 0.9 syntax to be expected.


> 
> squid 3 just passes this response to the client, but squid 4 returns 502
> with ERR_INVALID_RESP?template and writes into cache.log:
> 
> WARNING: HTTP: Invalid Response: Bad header encountered from ? AKA ?
> 
> While I understand that 4-digits response code is not standard I'd like
> to know:
> 
> Is it expected behavior and is there an option to change squid 4
> behavior to match squid 3?

This is intentional behaviour. According to the specification the
recipient (Squid) MUST treat it as a malformed 500 response. It was a
bug in Squid-3 to pass the status unchanged.


PS. If you have any contact with people in charge of the server
producing these responses please contact them an encourage proper HTTP
syntax be used. The requirements are not particularly difficult and RFC
7230 series of documents are a lot clearer to understand than the old ones.

Amos


From eliezer at ngtech.co.il  Wed Feb  6 21:39:59 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Wed, 6 Feb 2019 23:39:59 +0200
Subject: [squid-users] StoreID java example helper
Message-ID: <004a01d4be64$82af7190$880e54b0$@ngtech.co.il>

I have created a JAVA Based StoreID helper example that utilizes threads for
concurrency.
The code is at:
http://gogs.ngtech.co.il/NgTech-LTD/StoreID-JAVA-helper
 
It's an eclipse project but also has the files:
http://gogs.ngtech.co.il/NgTech-LTD/StoreID-JAVA-helper/src/master/StoreID-J
AVA.jar
http://gogs.ngtech.co.il/NgTech-LTD/StoreID-JAVA-helper/src/master/start.sh
 
If you want to use it as an executable.
Most of the StoreID related code is at:
http://gogs.ngtech.co.il/NgTech-LTD/StoreID-JAVA-helper/src/master/src/Store
ID.java
 
It's somehow similar to a perl based helper with all the if and else's but
it works much faster under heavy load.
 
Eliezer
 
----
 <http://ngtech.co.il/main-en/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email:  <mailto:eliezer at ngtech.co.il> eliezer at ngtech.co.il

 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190206/11741fac/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11295 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190206/11741fac/attachment.png>

From squid3 at treenet.co.nz  Thu Feb  7 00:46:23 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Feb 2019 13:46:23 +1300
Subject: [squid-users] Filering HTTPS URLs - A complete configuration
In-Reply-To: <168c34bb82e.114bc9e7c22107.5629353171280088961@doignon.fr>
References: <168be13b6f9.c72dacf0274895.400411858861977298@doignon.fr>
 <48ab3054-7651-564a-c79e-fc2b38db7b4a@treenet.co.nz>
 <168c34bb82e.114bc9e7c22107.5629353171280088961@doignon.fr>
Message-ID: <a34944d8-a52d-664b-8a2e-e4bfd1a753b3@treenet.co.nz>

On 7/02/19 3:52 am, Paul Doignon wrote:
> Thanks, I appreciate your detailed answer.
> 
>  > > I'm struggling a lot to configure Squid. To improve the security of my app in my AWS private subnet,
>  > 
>  > If it is indeed *your* app; then please alter it not to require the
>  > interception we see below. Ability to connect to a TLS explicit proxy or
>  > just sending regular proxy CONNECT tunnel is a leap up in security.
> 
> I wish I could too ! Unfortunately, we use some third party libraries that do not support proxies (or not well). What a shame : (
>  
>  > > # Hide some reavealing or useless headers
>  > > forwarded_for delete
>  > > httpd_suppress_version_string off
>  > > reply_header_access X-Cache deny all
>  > > reply_header_access X-Cache-Lookup deny all
>  > > via off
>  > > 
>  > > # Tuning
>  > > max_filedesc 10000
>  > > 
>  > > # Disable access to manager
>  > > http_access deny manager
>  > 
>  > 2) you are missing the security protections from the default squid.conf...
>  
> I have not hardened Squid yet, but you mean default `acl localnet src [...]` rules ? I'm not sure about this.
> 

The defaults that come with a new build or installation:

"
  http_access deny !Safe_ports
  http_access deny CONNECT !SSL_ports
  http_access allow localhost manager
  http_access deny manager

  ... your rules go here ...

  http_access deny all
"


>  > Please see <https://wiki.squid-cache.org/Features/SslPeekAndSplice> for
>  > details on the TLS handshake process and what SSL-Bump does during that.
> 
> Another read was indeed interesting, I think I corrected ssl_bump directives. However I still can't make it work.
> Just for the record, I would like to block everything but some HTTPS websites for particular URLs. The ssl::server_name acl is not enough for me, I would like to use url_regex or similar.
> Ant that's where it gets wrong, I can't make Squid make the link between `ssl_bump bump` and url_regex.


That is because ssl_bump is the access control governing the TLS
handshake process. TLS message/frames do not contain URLs. Even when a
client CONNECT request is being processed it only has an authority-URI
(not a full URL).

The http_access rules are the first point you get access to URL. The
https:// URLs start *after* the ssl_bump finishes with a successful
'bump' action.


The closest you are going to get to the above is with:
 * bump everything[1], and
 * use http_access to check the https:// URLs for your policy
 * use "deny_info TCP_RESET" [2] on the blocked requests.

[1] some things literally cannot be bumped. So a decision needs to be
made about what to do then.

[2] a regular deny error page will work fine. This TCP_RESET is just
closest to the "ssl_bump terminate" behaviour.


Amos


From squid3 at treenet.co.nz  Thu Feb  7 00:47:36 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Feb 2019 13:47:36 +1300
Subject: [squid-users] Connection to cache peer failed "SSL Transparent
 proxy'
In-Reply-To: <CAN4dctqQA+sgu6UZ1q7ycm1LaCqNenOSao6J7NCOeR8ZjcjGHQ@mail.gmail.com>
References: <CAN4dctrM9vU9gKtyKwkU8Km+WhvA8xXaT8W7abu4HuihpLeGXw@mail.gmail.com>
 <ec2e4d70-98d7-1354-9507-d360a8d8bec8@treenet.co.nz>
 <CAN4dctqz-VsR=9B7uV=OW5AGCGxHxgm=a5sMab23qQo9g6wm3Q@mail.gmail.com>
 <3c826662-b81d-d885-3c0c-9c3430ce7316@treenet.co.nz>
 <CAN4dctqQA+sgu6UZ1q7ycm1LaCqNenOSao6J7NCOeR8ZjcjGHQ@mail.gmail.com>
Message-ID: <f7e209e5-3172-fb06-baaf-c255588c80b9@treenet.co.nz>

On 7/02/19 8:03 am, Walid A. Shaari wrote:
> 
> On Wed, 6 Feb 2019 at 05:53, Amos Jeffries wrote:
> 
>     > ssl_bump peek step1
>     >
>     > ssl_bump splice? azure_sites azure_sites2 #Avoid bumping
>     Microsoft/Azure
>     > related sites
>     >
> 
>     The way ACLs work in Squid items on a line like "azure_sites
>     azure_sites2" *both* have to match for the lines action to be used.
> 
>     So the above line means all those domains except *.microsoft.com
>     <http://microsoft.com> will
>     *not* be spliced here even if a URL domain was available.
> 
> 
> Sorry, I did not get that, is it because microsoft.com
> <http://microsoft.com> is duplicated by mistake twice on both lines???
> 

I mean the names which only occur in one of the two ACL checks will do
possibly unwanted things. see the FAQ
<https://wiki.squid-cache.org/SquidFaq/SquidAcl#Common_Mistakes> for
details.

For example; when the request is for "microsoftazurestack.com" the
azure_sites2 part would be false. Which then means the splice is not done.

The only domain(s) where both azure_sites AND azure_sites2 are
matching/true are the *.microsoft.com names.



That said, I do not see any reason why you have two ACLs in the first
place. You could probably combine the two into one name and remove
azure_sites2 entirely.

PS. If the problem is line length for the list you can have multiple
'acl' lines adding different values to an ACL (like our default
Safe_Ports does) so long as the type is identical.

OR, you can also wrap config lines using a '\' right before the
end-of-line CRLF and whitespace to start the wrapped line part. Like:

 directive value1 value2 \
   value3 \
   value4

OR, you could place the list in a file and have the ACL load the values
from there.
Amos


From walid.shaari at linux.com  Thu Feb  7 03:11:12 2019
From: walid.shaari at linux.com (Walid A. Shaari)
Date: Thu, 7 Feb 2019 06:11:12 +0300
Subject: [squid-users] Connection to cache peer failed "SSL Transparent
	proxy'
In-Reply-To: <f7e209e5-3172-fb06-baaf-c255588c80b9@treenet.co.nz>
References: <CAN4dctrM9vU9gKtyKwkU8Km+WhvA8xXaT8W7abu4HuihpLeGXw@mail.gmail.com>
 <ec2e4d70-98d7-1354-9507-d360a8d8bec8@treenet.co.nz>
 <CAN4dctqz-VsR=9B7uV=OW5AGCGxHxgm=a5sMab23qQo9g6wm3Q@mail.gmail.com>
 <3c826662-b81d-d885-3c0c-9c3430ce7316@treenet.co.nz>
 <CAN4dctqQA+sgu6UZ1q7ycm1LaCqNenOSao6J7NCOeR8ZjcjGHQ@mail.gmail.com>
 <f7e209e5-3172-fb06-baaf-c255588c80b9@treenet.co.nz>
Message-ID: <CAN4dctoh-g3a0+H-uVuJkqjwVGK_AOgrYbjeLWa0947KR8EsHw@mail.gmail.com>

Got it. Thank you Amos

On Thu, 7 Feb 2019, 03:47 Amos Jeffries <squid3 at treenet.co.nz wrote:

> On 7/02/19 8:03 am, Walid A. Shaari wrote:
> >
> > On Wed, 6 Feb 2019 at 05:53, Amos Jeffries wrote:
> >
> >     > ssl_bump peek step1
> >     >
> >     > ssl_bump splice  azure_sites azure_sites2 #Avoid bumping
> >     Microsoft/Azure
> >     > related sites
> >     >
> >
> >     The way ACLs work in Squid items on a line like "azure_sites
> >     azure_sites2" *both* have to match for the lines action to be used.
> >
> >     So the above line means all those domains except *.microsoft.com
> >     <http://microsoft.com> will
> >     *not* be spliced here even if a URL domain was available.
> >
> >
> > Sorry, I did not get that, is it because microsoft.com
> > <http://microsoft.com> is duplicated by mistake twice on both lines?
> >
>
> I mean the names which only occur in one of the two ACL checks will do
> possibly unwanted things. see the FAQ
> <https://wiki.squid-cache.org/SquidFaq/SquidAcl#Common_Mistakes> for
> details.
>
> For example; when the request is for "microsoftazurestack.com" the
> azure_sites2 part would be false. Which then means the splice is not done.
>
> The only domain(s) where both azure_sites AND azure_sites2 are
> matching/true are the *.microsoft.com names.
>
>
>
> That said, I do not see any reason why you have two ACLs in the first
> place. You could probably combine the two into one name and remove
> azure_sites2 entirely.
>
> PS. If the problem is line length for the list you can have multiple
> 'acl' lines adding different values to an ACL (like our default
> Safe_Ports does) so long as the type is identical.
>
> OR, you can also wrap config lines using a '\' right before the
> end-of-line CRLF and whitespace to start the wrapped line part. Like:
>
>  directive value1 value2 \
>    value3 \
>    value4
>
> OR, you could place the list in a file and have the ACL load the values
> from there.
> Amos
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190207/e8e79ba8/attachment.htm>

From alexmaystat at mail.ru  Thu Feb  7 05:28:33 2019
From: alexmaystat at mail.ru (alexmaystat)
Date: Wed, 6 Feb 2019 23:28:33 -0600 (CST)
Subject: [squid-users] Proxing only special file types
In-Reply-To: <5b2e24f1-92ec-f3b8-614f-0578f6d57fa2@treenet.co.nz>
References: <1549450099364-0.post@n4.nabble.com>
 <201902061055.28493.Antony.Stone@squid.open.source.it>
 <1549452117492-0.post@n4.nabble.com>
 <201902061128.14969.Antony.Stone@squid.open.source.it>
 <1549463950713-0.post@n4.nabble.com>
 <5b2e24f1-92ec-f3b8-614f-0578f6d57fa2@treenet.co.nz>
Message-ID: <1549517313270-0.post@n4.nabble.com>

I mean:
Do you think that it is possible to implement the ECAP module with the
injecting code into content adaptation, after check and verify in ECAP that
content-type is js code (text/javascript)?



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From lukgom at gmail.com  Thu Feb  7 08:21:26 2019
From: lukgom at gmail.com (Lucolo)
Date: Thu, 7 Feb 2019 02:21:26 -0600 (CST)
Subject: [squid-users] SMP-Workers + Rock Cache not caching as much as
 SMP-Workers + AUFS
In-Reply-To: <3bc48a45-6558-8897-db49-be56e7e347d5@treenet.co.nz>
References: <1549448079205-0.post@n4.nabble.com>
 <3bc48a45-6558-8897-db49-be56e7e347d5@treenet.co.nz>
Message-ID: <1549527686685-0.post@n4.nabble.com>

Hi Amos

First of all, thank for your response.

I am more interested in having proper working rock cache

as you said:

The Rock setup: 
 - all traffic funneled through one worker. *is it supposed to work that
way?*
 - 4 workers operating with shared caches. *That's correct, I assume.*
  - CARP load balancing selectively channels objects by URL to particular 
worker. 

I follow your manual just to configure "CARP Cluster of SMP workers with
rock", so I assume this is a working configuration
https://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster
<https://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster>  

Since it's the basic configuration Squid recommends, I don't see much
efficiency in using this kind of configuration.


The info missing in the previus post were:

# squid -v
Squid Cache: Version 4.4
Service Name: squid
This binary uses OpenSSL 1.0.2k-fips  26 Jan 2017.

Traffic in each proxy is around 1 Gb and 6K connections.

Thanks




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Thu Feb  7 08:24:47 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Feb 2019 21:24:47 +1300
Subject: [squid-users] Proxing only special file types
In-Reply-To: <1549517313270-0.post@n4.nabble.com>
References: <1549450099364-0.post@n4.nabble.com>
 <201902061055.28493.Antony.Stone@squid.open.source.it>
 <1549452117492-0.post@n4.nabble.com>
 <201902061128.14969.Antony.Stone@squid.open.source.it>
 <1549463950713-0.post@n4.nabble.com>
 <5b2e24f1-92ec-f3b8-614f-0578f6d57fa2@treenet.co.nz>
 <1549517313270-0.post@n4.nabble.com>
Message-ID: <2871fb55-67ce-2367-5999-f5b66a470e54@treenet.co.nz>

On 7/02/19 6:28 pm, alexmaystat wrote:
> I mean:
> Do you think that it is possible to implement the ECAP module with the
> injecting code into content adaptation, after check and verify in ECAP that
> content-type is js code (text/javascript)?
> 

That is possible.

But consider this:
 It is also *possible* to take a running jump off a cliff. Sometimes one
will even survive. Does not make it a good idea.



More specifically I caution you to consider also the social and legal
consequences of altering other peoples content without their permission.

In most countries content adaptation is actually illegal and the content
providers have a right to sue for compensation of damages. The legal
situation ranges from copyright violation to fraud.

With in-transit adaptation you are:
 a) using other peoples content (piracy, theft), and
 b) without copyright permission to do so (copyright violation, theft
and digital piracy), and
 c) presenting the result as if it were by the original author
(misrepresentation, aka fraud).

Several relatively large companies were sued out of existence, and
others suffered massive reputation damage last decade by getting content
adaptation wrong. So please see a qualified lawyer before you go any
further with this idea.


PS. Most times this question of injecting javascript has come up there
were other far better and absolutely legal ways to achieve the desired
end that did not involve JS injection attacks against the clients. If
you care to explain the purpose of this JS perhapse we can help guide
you towards better ways to do the task.

Amos


From walid.shaari at linux.com  Thu Feb  7 11:28:54 2019
From: walid.shaari at linux.com (Walid A. Shaari)
Date: Thu, 7 Feb 2019 14:28:54 +0300
Subject: [squid-users] redirecting one url to another
Message-ID: <CAN4dctoezcQ8mV=YkeBf9RMZA8kLX6D1BH9U3a2EyeCjM1uEeg@mail.gmail.com>

Greetings,

due to architectural or workflow issue, I would like to utilize squid to
redirect one url to another.

e.g.  bing.com to google.com however, keep the parameters, is that doable?

I looked into "deny_info url acl", however that does not seem to pull the
trick

Best regards,

Walid
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190207/9858aa2a/attachment.htm>

From squid3 at treenet.co.nz  Thu Feb  7 12:24:06 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 8 Feb 2019 01:24:06 +1300
Subject: [squid-users] redirecting one url to another
In-Reply-To: <CAN4dctoezcQ8mV=YkeBf9RMZA8kLX6D1BH9U3a2EyeCjM1uEeg@mail.gmail.com>
References: <CAN4dctoezcQ8mV=YkeBf9RMZA8kLX6D1BH9U3a2EyeCjM1uEeg@mail.gmail.com>
Message-ID: <c3cee58a-ad71-65ff-70ad-d7c08565dc8a@treenet.co.nz>

On 8/02/19 12:28 am, Walid A. Shaari wrote:
> Greetings,
> 
> due to architectural?or workflow issue, I would like to utilize squid to
> redirect one url to another.
> 
> e.g.? bing.com to google.com
> however, keep the parameters, is that doable?
> 

There are two problems;

First is that those services no longer use HTTP. So you will need to
decrypt the HTTPS to get any access to the URLs.

Second is that they are different services by different organizations.
So the parameters have different meanings. Retaining them can cause more
problems than it solves.


Amos


From walid.shaari at linux.com  Thu Feb  7 15:55:58 2019
From: walid.shaari at linux.com (Walid A. Shaari)
Date: Thu, 7 Feb 2019 18:55:58 +0300
Subject: [squid-users] redirecting one url to another
In-Reply-To: <c3cee58a-ad71-65ff-70ad-d7c08565dc8a@treenet.co.nz>
References: <CAN4dctoezcQ8mV=YkeBf9RMZA8kLX6D1BH9U3a2EyeCjM1uEeg@mail.gmail.com>
 <c3cee58a-ad71-65ff-70ad-d7c08565dc8a@treenet.co.nz>
Message-ID: <CAN4dctoa+uYz=_1+buyS69N5=Jvi1isap4gOwSbxakfV7ao8EA@mail.gmail.com>

On Thu, 7 Feb 2019 at 15:24, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 8/02/19 12:28 am, Walid A. Shaari wrote:
> > Greetings,
> >
> > due to architectural or workflow issue, I would like to utilize squid to
> > redirect one url to another.
> >
> > e.g.  bing.com to google.com
> > however, keep the parameters, is that doable?
> >
>
> There are two problems;
>
> First is that those services no longer use HTTP. So you will need to
> decrypt the HTTPS to get any access to the URLs.
>

thats doable correct via bump and splice?

 Second is that they are different services by different organizations.

> So the parameters have different meanings. Retaining them can cause more
> problems than it solves.
>

in my case actually it is the same, it is an issue DNS whitlisting at work.
as when a cname resolution happens it happens at the proxy end not the host
end, does that make any sense?
so for example

dc.services.visualstudio.com requsted is actually a CNAME for
dc.applicationinsights.microsoft.com

I always thought DNS resolution happens first, then that is passed to the
proxy server, in my case from tcpdump, I belive the http payload host is
the one that gets resolved by the proxy, and if the proxy has a web gateway
in front of it, this is where the whitelisting/black listing happens before
any name resoultion/alias are resolved. am I right? I apperciate any good
resources on how and where name resolution happens when proxises, load
balancers and web gateways  are involved

Best regards,

Walid
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190207/5233464e/attachment.htm>

From squid3 at treenet.co.nz  Fri Feb  8 02:08:37 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 8 Feb 2019 15:08:37 +1300
Subject: [squid-users] redirecting one url to another
In-Reply-To: <CAN4dctoa+uYz=_1+buyS69N5=Jvi1isap4gOwSbxakfV7ao8EA@mail.gmail.com>
References: <CAN4dctoezcQ8mV=YkeBf9RMZA8kLX6D1BH9U3a2EyeCjM1uEeg@mail.gmail.com>
 <c3cee58a-ad71-65ff-70ad-d7c08565dc8a@treenet.co.nz>
 <CAN4dctoa+uYz=_1+buyS69N5=Jvi1isap4gOwSbxakfV7ao8EA@mail.gmail.com>
Message-ID: <68b7798d-7c6d-edc6-09bd-6d256b07d775@treenet.co.nz>

On 8/02/19 4:55 am, Walid A. Shaari wrote:
> On Thu, 7 Feb 2019 at 15:24, Amos Jeffries wrote:
> 
>     On 8/02/19 12:28 am, Walid A. Shaari wrote:
>     > Greetings,
>     >
>     > due to architectural?or workflow issue, I would like to utilize
>     squid to
>     > redirect one url to another.
>     >
>     > e.g.? bing.com to google.com 
>     > however, keep the parameters, is that doable?
>     >
> 
>     There are two problems;
> 
>     First is that those services no longer use HTTP. So you will need to
>     decrypt the HTTPS to get any access to the URLs.
> 
> 
> thats doable correct via bump and splice?

SSL-Bump is the feature for decrypting, yes.

> 
> ?Second is that they are different services by different organizations.
> 
>     So the parameters have different meanings. Retaining them can cause more
>     problems than it solves.
> 
> 
> in my case actually it is the same, it is an issue DNS whitlisting at
> work. as when a cname resolution happens it happens at the proxy end not
> the host end, does that make any sense?

Not really. Are you saying that when your users request DNS entries for
bing.com your DNS server hands them the IPs for google.com ?



> so for example
> 
> dc.services.visualstudio.com <http://dc.services.visualstudio.com>
> requsted is actually a CNAME for dc.applicationinsights.microsoft.com
> <http://dc.applicationinsights.microsoft.com>

CNAME is irrelevant unless your DNS resolver is broken. In that case the
only way to get things to work is to fix the resolver, or use a
different one.


> 
> I always thought DNS resolution happens first, then that is passed to
> the proxy server,

Not always. Only for intercepted and reverse-proxy traffic - the client
thinks it is talking directly to an origin server so it has to do its
own DNS lookups to find that origin.

With Forward/explicit proxy the client only has to lookup the proxy IP
and send requests there. The proxy performs origin server lookups and
selection on behalf of the client.


> in my case from tcpdump, I belive the http payload
> host is the one that gets resolved by the proxy,

Proxy always resolves the DNS records. Different HTTP traffic modes use
it for different things. Access controls may also need DNS resolution
for things.

[ Assuming here that by "payload host" you mean Origin Server. All HTTP
agents produce payloads. ]


> and if the proxy has a
> web gateway in front of it, this is where the whitelisting/black listing
> happens before any name resoultion/alias are resolved. am I right?

No. A web gateway is just another proxy. Access control can and does
happen at each hop. What each proxy does is up to their admins config
choices and traffic types.


> I
> apperciate any good resources on how and where name resolution happens
> when proxises, load balancers and web gateways? are involved 

Each agent which needs DNS resolution for anything does its own resolution.

What DNS is used for depends on what each agent does. It is very tricky
to give certainties about specific actions when only describing the
general role types.

Many of your questions may be resolve by reading section 2.1 to 2.3 of
the HTTP/1.1 specification
(<https://tools.ietf.org/html/rfc7230#section-2.1>).

Amos


From Sarfaraz.Ahmad at deshaw.com  Fri Feb  8 06:30:09 2019
From: Sarfaraz.Ahmad at deshaw.com (Ahmad, Sarfaraz)
Date: Fri, 8 Feb 2019 06:30:09 +0000
Subject: [squid-users] High response times with Squid
Message-ID: <88363c929cbf470a88db5986d24272eb@deshaw.com>

Hi,

I am using Squid 4.5 with WCCP. Intercepting SSL by peeking at step1 and then deciding to either splice or bump upon the SNI.
I am noticing a weird behavior for some of my TCP connections.  Squid is taking over 20s to decide what do with the ClientHello sent by the browser. It is only after 20s that it decides to send out a ClientHello to the origin server and at the same time reply to the client with a ServerHello.
This behavior is hard to reproduce and only some clients are affected.

I will try to summarize what I see in cache.log with ALL, 6 debug options.


1)      Squid's INTERCEPTION thread/program receives a TCP SYN from workstation.
2019/02/06 17:23:19.070 kid1| 89,5| Intercept.cc(405) Lookup: address BEGIN: me/client= <SQUID_IP>:23129, destination/me= <CLIENT/BROWSER_IP>:58232


2)      Squid becomes the origin server and sets up the TCP connection.
2019/02/06 17:23:19.070 kid1| 5,5| AsyncCall.cc(93) ScheduleCall: TcpAcceptor.cc(339) will call httpsAccept(local=<ORIGIN_SERVER_ON_THE_INTERNET>:443 remote=<CLIENT/BROWSER_IP>:58232 FD 40 flags=33, MXID_1101703) [call34733258]
2019/02/06 17:23:19.070 kid1| 5,5| AsyncCall.cc(38) make: make call httpsAccept [call34733258]
       2019/02/06 17:23:19.070 kid1| 33,4| client_side.cc(2776) httpsAccept: local=<ORIGIN_SERVER_ON_THE_INTERNET>:443 remote=<CLIENT/BROWSER_IP>:58232 FD 40 flags=33 accepted, starting SSL negotiation.


3)      Squid checks the SSL ACLs for the destination IP.
2019/02/06 17:23:19.071 kid1| 28,5| Acl.cc(124) matches: checking (ssl_bump rules)
2019/02/06 17:23:19.071 kid1| 28,5| Checklist.cc(397) bannedAction: Action 'ALLOWED/6' is not banned
2019/02/06 17:23:19.071 kid1| 28,5| Acl.cc(124) matches: checking (ssl_bump rule)
2019/02/06 17:23:19.071 kid1| 28,5| Acl.cc(124) matches: checking no_ssl_bump_src_ip
2019/02/06 17:23:19.071 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '<CLIENT/BROWSER_IP>:58232' NOT found
2019/02/06 17:23:19.071 kid1| 28,3| Acl.cc(151) matches: checked: no_ssl_bump_src_ip = 0


4)      Squid decides to allow connections to the remote IP i.e <ORIGIN_SERVER_ON_THE_INTERNET> and decides to peek at the SNI (will accept ClientHello), hence fakes a CONNECT request
2019/02/06 17:23:19.071 kid1| 28,3| Checklist.cc(163) checkCallback: ACLChecklist::checkCallback: 0x1fb19fd8 answer=ALLOWED
2019/02/06 17:23:19.071 kid1| 33,2| client_side.cc(2744) httpsSslBumpAccessCheckDone: sslBump action peekneeded for local=<ORIGIN_SERVER_ON_THE_INTERNET>:443 remote=<CLIENT/BROWSER_IP>:58232 FD 40 flags=33
2019/02/06 17:23:19.071 kid1| 33,2| client_side.cc(3395) fakeAConnectRequest: fake a CONNECT request to force connState to tunnel for ssl-bump


5)      The FAKE connect requests again runs through ACLs.  20ms are spent for DNS PTR lookup. A total of 30ms is spent parsing ACLs.
2019/02/06 17:23:19.103 kid1| 85,2| client_side_request.cc(758) clientAccessCheckDone: The request CONNECT <ORIGIN_SERVER_ON_THE_INTERNET> is ALLOWED; last ACL checked: localnet
2019/02/06 17:23:19.103 kid1| 93,4| AccessCheck.cc(145) checkCandidates: NO candidates left
2019/02/06 17:23:19.103 kid1| 93,3| AccessCheck.cc(196) callBack: NULL
2019/02/06 17:23:19.103 kid1| 93,5| AsyncCall.cc(26) AsyncCall: The AsyncCall Adaptation::Initiator::noteAdaptationAclCheckDone constructed, this=0x1552b0b0 [call34733267]


6)      FAKE connect is processed and Squid reads the TCP connection, gets the ClientHello and reads the SNI.
2019/02/06 17:23:19.104 kid1| 33,5| AsyncCall.cc(38) make: make call Server::doClientRead [call34733270]
2019/02/06 17:23:19.104 kid1| 33,5| AsyncJob.cc(123) callStart: Http1::Server status in: [ job2971436]
2019/02/06 17:23:19.104 kid1| 33,5| Server.cc(104) doClientRead: local=<ORIGIN_SERVER_ON_THE_INTERNET>:443 remote=<CLIENT/BROWSER_IP>:58232 FD 40 flags=33
2019/02/06 17:23:19.104 kid1| 5,3| Read.cc(92) ReadNow: local=<ORIGIN_SERVER_ON_THE_INTERNET>:443 remote=<CLIENT/BROWSER_IP>:58232 FD 40 flags=33, size 4096, retval 203, errno 0
2019/02/06 17:23:19.104 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall ConnStateData::requestTimeout constructed, this=0x3d42d40 [call34733271]
2019/02/06 17:23:19.104 kid1| 5,3| comm.cc(559) commSetConnTimeout: local=<ORIGIN_SERVER_ON_THE_INTERNET>:443 remote=<CLIENT/BROWSER_IP>:58232 FD 40 flags=33 timeout 300
2019/02/06 17:23:19.104 kid1| 83,5| Handshake.cc(404) parseExtensions: first unsupported extension: 19018
2019/02/06 17:23:19.104 kid1| 83,3| Handshake.cc(497) parseSniExtension: host_name=<ORIGIN_SERVER_SNI>


7)      This is followed by another round of ACL processing now that we have the SNI.

2019/02/06 17:23:19.106 kid1| 33,3| Pipeline.cc(35) front: Pipeline 0xc2d7b60 front 0x1ae2e730*2
2019/02/06 17:23:19.106 kid1| 33,3| Pipeline.cc(35) front: Pipeline 0xc2d7b60 front 0x1ae2e730*3
2019/02/06 17:23:19.107 kid1| 83,5| Session.cc(103) NewSessionObject: SSL_new session=0x78136a0
2019/02/06 17:23:19.107 kid1| 83,5| bio.cc(616) squid_bio_ctrl: 0xcd0fe80 104(6000, 0x7ffc32a6e6b4)
2019/02/06 17:23:19.107 kid1| 83,5| Session.cc(162) CreateSession: link FD 40 to TLS session=0x78136a0
2019/02/06 17:23:19.107 kid1| 33,5| client_side.cc(2535) httpsCreate: will negotiate TLS on local=<ORIGIN_SERVER_ON_THE_INTERNET>:443 remote=<CLIENT/BROWSER_IP>:58232 FD 40 flags=33
2019/02/06 17:23:19.107 kid1| 5,5| ModEpoll.cc(117) SetSelect: FD 40, type=1, handler=0, client_data=0, timeout=0
2019/02/06 17:23:19.107 kid1| 83,5| client_side.cc(3324) startPeekAndSplice: Peek and splice at step2 done. Start forwarding the request!!!
2019/02/06 17:23:19.107 kid1| 17,3| FwdState.cc(340) Start: '<ORIGIN_SERVER_ON_THE_INTERNET>:443'



8)      No ServerHello has been sent back to the client yet, Squid starts a TCP connection with the origin server
2019/02/06 17:23:19.110 kid1| 5,4| AsyncJob.cc(123) callStart: Comm::ConnOpener status in: [ job2971439]
2019/02/06 17:23:19.110 kid1| 5,5| ConnOpener.cc(350) doConnect: local=0.0.0.0 remote=<ORIGIN_SERVER_ON_THE_INTERNET>:443 flags=1: Comm::OK - connected
2019/02/06 17:23:19.110 kid1| 5,4| ConnOpener.cc(155) cleanFd: local=0.0.0.0 remote=<ORIGIN_SERVER_ON_THE_INTERNET>:443 flags=1 closing temp FD 50


9)      Squid starts a TLS session with the remote/origin server, sends the ClientHello. A total of 0.4 seconds in Squid sending clienthello to origin server. This is probably when Squid decides to send back the ServerHello to the browser.
2019/02/06 17:23:19.110 kid1| 83,5| Session.cc(103) NewSessionObject: SSL_new session=0x14899390
2019/02/06 17:23:19.111 kid1| 83,5| bio.cc(616) squid_bio_ctrl: 0x1492ef80 104(6001, 0x7ffc32a6e884)
2019/02/06 17:23:19.111 kid1| 83,5| Session.cc(162) CreateSession: link FD 50 to TLS session=0x14899390
2019/02/06 17:23:19.111 kid1| 83,5| PeerConnector.cc(123) initialize: local=<SQUID_IP>:44498 remote=<ORIGIN_SERVER_ON_THE_INTERNET>:443 FD 50 flags=1, session=0x14899390

So somewhere between Step 8 and Step 9, Squid is taking over 20s.

What could possibly be keeping it busy ?
I have external ACL helpers but they work just fine. Average service time is 1ms. Squid has not even spawning all helpers that it has been configured to do. (not exhausted the upper limit).
DNS resolution is also good. All CPU/MEM resources look just fine and again this affects only a subset of the traffic.  I don't have the failure logs from when this actually happens.


UPDATE: This problem statement seems local to a few websites. Outside of the proxy, those websites quite quickly as is expected.

Any thoughts on where to look ?  other bits and pieces I could check ?  I have jumbo frames enabled (9000 bytes) but am running the proxies at L2 1500 MTU.

-Ahmad



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190208/d4a505d7/attachment.htm>

From rousskov at measurement-factory.com  Fri Feb  8 09:13:18 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 8 Feb 2019 02:13:18 -0700
Subject: [squid-users] SMP-Workers + Rock Cache not caching as much as
 SMP-Workers + AUFS
In-Reply-To: <1549527686685-0.post@n4.nabble.com>
References: <1549448079205-0.post@n4.nabble.com>
 <3bc48a45-6558-8897-db49-be56e7e347d5@treenet.co.nz>
 <1549527686685-0.post@n4.nabble.com>
Message-ID: <49bcb069-31ab-38ae-4b7b-adfc6f81cd4f@measurement-factory.com>

On 2/7/19 01:21, Lucolo wrote:

> I follow your manual just to configure "CARP Cluster of SMP workers with
> rock", so I assume this is a working configuration
> https://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster

FWIW, that old configuration should not be used except, perhaps, in some 
highly unusual/rare use cases. You are probably _not_ dealing with such 
a case.


> Since it's the basic configuration Squid recommends,

It is not basic and it is not generally recommended (despite being 
published on a Squid wiki).

Most modern SMP setups should use multiple workers and multiple Rock 
diskers, without SMP macros in squid.conf. The exact number of workers 
and diskers depends on the number of physical CPU cores, desired hit 
ratio, and actual workload -- there is no "one size fits all" formula. 
However, you may be able to start with

   W=C-2
   D=1

where W is the number of SMP workers, D is the number of rock cache_dir 
lines (i.e. the number of diskers), and C is the "number of otherwise 
idle physical CPU cores" on the Squid box. If your disker becomes 
overloaded, increase D (and probably decrease W) and/or reduce disk 
load. You can find more information at

   * https://wiki.squid-cache.org/Features/SmpScale

   * The tuning section of
     https://wiki.squid-cache.org/Features/RockStore

Alex.


From lukgom at gmail.com  Fri Feb  8 14:13:45 2019
From: lukgom at gmail.com (Lucolo)
Date: Fri, 8 Feb 2019 08:13:45 -0600 (CST)
Subject: [squid-users] SMP-Workers + Rock Cache not caching as much as
 SMP-Workers + AUFS
In-Reply-To: <49bcb069-31ab-38ae-4b7b-adfc6f81cd4f@measurement-factory.com>
References: <1549448079205-0.post@n4.nabble.com>
 <3bc48a45-6558-8897-db49-be56e7e347d5@treenet.co.nz>
 <1549527686685-0.post@n4.nabble.com>
 <49bcb069-31ab-38ae-4b7b-adfc6f81cd4f@measurement-factory.com>
Message-ID: <1549635225779-0.post@n4.nabble.com>

Thanks Rousskov

I'll take a look and try to re-configure again in that way.





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Sat Feb  9 04:50:11 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 9 Feb 2019 17:50:11 +1300
Subject: [squid-users] High response times with Squid
In-Reply-To: <88363c929cbf470a88db5986d24272eb@deshaw.com>
References: <88363c929cbf470a88db5986d24272eb@deshaw.com>
Message-ID: <76c45965-061b-ecbc-46a8-b75320bfa71a@treenet.co.nz>

On 8/02/19 7:30 pm, Ahmad, Sarfaraz wrote:
> Hi,
> 
> ?
> 
> I am using Squid 4.5 with WCCP. Intercepting SSL by peeking at step1 and
> then deciding to either splice or bump upon the SNI.
> 
> I am noticing a weird behavior for some of my TCP connections. ?Squid is
> taking over 20s to decide what do with the ClientHello sent by the
> browser. It is only after 20s that it decides to send out a ClientHello
> to the origin server and at the same time reply to the client with a
> ServerHello.
> 
> This behavior is hard to reproduce and only some clients are affected.
> 
> ?
> 
> I will try to summarize what I see in cache.log with ALL, 6 debug options.
> 
> ?
> 
> 1)????? Squid's INTERCEPTION thread/program receives a TCP SYN from
> workstation.
> 
> 2019/02/06 17:23:19.070 kid1| 89,5| Intercept.cc(405) Lookup: address
> BEGIN: me/client= *<SQUID_IP>:*23129, destination/me=
> *<CLIENT/BROWSER_IP>:*58232
> 

No. This is looking up the original TCP dst-IP:port in the kernel NAT
tables.


> ?
> 
> 2)????? Squid becomes the origin server and sets up the TCP connection.
> 

No. The local= log values are a simple statement of the TCP packet
values received from the NAT system at (1). Squid is an MITM in this
setup, so the client *thinks* it is talking to the origin.

Being an MITM Squid is designed to operate as transparently as possible,
but at no time has the abilities of the origin server.


> 2019/02/06 17:23:19.070 kid1| 5,5| AsyncCall.cc(93) ScheduleCall:
> TcpAcceptor.cc(339) will call
> httpsAccept(local*=<ORIGIN_SERVER_ON_THE_INTERNET>*:443
> remote=*<CLIENT/BROWSER_IP>:*58232 FD 40 flags=33, MXID_1101703)
> [call34733258]
> 

...
> 
> 8)????? No ServerHello has been sent back to the client yet, Squid
> starts a TCP connection with the origin server
> 
> 2019/02/06 17:23:19.110 kid1| 5,4| AsyncJob.cc(123) callStart:
> Comm::ConnOpener status in: [ job2971439]
> 
> 2019/02/06 17:23:19.110 kid1| 5,5| ConnOpener.cc(350) doConnect:
> local=0.0.0.0 remote*=<ORIGIN_SERVER_ON_THE_INTERNET>:*443 flags=1:
> Comm::OK - connected
> 
> 2019/02/06 17:23:19.110 kid1| 5,4| ConnOpener.cc(155) cleanFd:
> local=0.0.0.0 remote=<*ORIGIN_SERVER_ON_THE_INTERNET*>:443 flags=1
> closing temp FD 50
> 
> ?
> 
> 9)????? Squid starts a TLS session with the remote/origin server, sends
> the ClientHello. A total of 0.4 seconds in Squid sending clienthello to
> origin server. This is probably when Squid decides to send back the
> ServerHello to the browser.

Don't guess. Check.

Either you have step2 / client-first bumping - in which case the Squid
serverHello would have been sent to the client at (7).

Or, you have step3 / server-first bumping - in which case Squid cannot
send a serverHello to the client until it has received the origin's
serverHello. Which still has not yet been received despite your trace
ending here.

...
> 
> 2019/02/06 17:23:19.111 kid1| 83,5| PeerConnector.cc(123) initialize:
> local=*<SQUID_IP>*:44498 remote=*<ORIGIN_SERVER_ON_THE_INTERNET>*:443 FD
> 50 flags=1, session=0x14899390
> 
> ?
> 
> So somewhere between Step 8 and Step 9, Squid is taking over 20s.
> 

There is only 1 millisecond between those steps.

The client connection was received at 17:23:19.070, your (9) finished at
17:23:19.111 -> so there is your 0.41 seconds. If there is any 20s gap
for this transaction it is later in the log part you have not shown.


> 
> What could possibly be keeping it busy ?
> 

Other transactions? Nothing?

What is going on at (9) is *preparing* to send a TLS clientHello. At the
point your log stops it still has not actually been written to the network.

There is actually still a good half of the SSl-Bump process to happen:
 - assemble the Squid clientHello bytes,
 - send that to origin
 - receive origin serverHello
 - validate the origin details
 - HTTP fetch missing certificates (if any)
   - re-validate the origin details (repeat fetch as necessary)
 - formulate the Squid serverHello
 - send that to client
 - receive HTTP request over the secured client connection

... then all the HTTP(S) message processing on the resulting connection.


> 
> UPDATE: This problem statement seems local to a few websites. Outside of
> the proxy, those websites quite quickly as is expected.
> 
> 
> Any thoughts on where to look ? ?other bits and pieces I could check ?
> ?I have jumbo frames enabled (9000 bytes) but am running the proxies at
> L2 1500 MTU.
> 

It is hard to say without also knowing your squid.conf settings and what
sites specifically you are having trouble with,

Could be anything from a packet loss in some remote router halfway
around the world. To misconfiguration of something in your network. To
misconfiguration by the origin server admin.

IMO that last one is most likely if the behaviour is only delay (not
errors) and with only certain domains.

Amos


From rzumpf at gmail.com  Sat Feb  9 09:37:04 2019
From: rzumpf at gmail.com (Reinhard Zumpf Dipl.-Ing.)
Date: Sat, 9 Feb 2019 10:37:04 +0100
Subject: [squid-users] Bulding Squid 3.5 for Win2k with SSL
Message-ID: <CAM=1poQ3WR45t8+99Kb7wND5OKnq-3R1=gKDBBgEmWGG6LKGsA@mail.gmail.com>

Hi,

I am having trouble Bulding Squid 3.5 for Win2k with SSL according to:
https://docs.diladele.com/howtos/build_squid_windows/index.html

Do you know why configure terminates like this? I had to switch within
Cygwin frome home dir to usr/src dir as described in section Using
Cygwin
https://www.physionet.org/physiotools/cygwin/
to comply with the guide from Diladele initially. I wonder why enable
ssl is done in this guide without including any openssl for build?

synrzu at NTB-SYN-273 ~
$     --datadir=/usr/share/squid --libexecdir=/usr/lib/squid
--disable-strict-error-checking
-bash: --datadir=/usr/share/squid: No such file or directory

synrzu at NTB-SYN-273 ~
$     --with-logdir=/var/log/squid --with-swapdir=/var/cache/squid
-bash: --with-logdir=/var/log/squid: No such file or directory

synrzu at NTB-SYN-273 ~
$     --with-pidfile=/var/run/squid.pid --enable-ssl --enable-delay-pools
-bash: --with-pidfile=/var/run/squid.pid: No such file or directory

synrzu at NTB-SYN-273 ~
$     --enable-ssl-crtd --enable-icap-client --enable-esi --disable-eui
-bash: --enable-ssl-crtd: Kommando nicht gefunden.

synrzu at NTB-SYN-273 ~
$     --localstatedir=/var/run/squid --sharedstatedir=/var/run/squid
-bash: --localstatedir=/var/run/squid: No such file or directory

synrzu at NTB-SYN-273 ~
$     --datarootdir=/usr/share/squid
--enable-disk-io="AIO,Blocking,DiskThreads,IpcIo,Mmapped"
-bash: --datarootdir=/usr/share/squid: No such file or directory

synrzu at NTB-SYN-273 ~
$     --enable-auth-basic="DB,LDAP,NCSA,POP3,RADIUS,SASL,SMB,fake,getpwnam"
-bash: --enable-auth-basic=DB,LDAP,NCSA,POP3,RADIUS,SASL,SMB,fake,getpwnam:
Kommando nicht gefunden.

synrzu at NTB-SYN-273 ~
$     --enable-auth-ntlm='fake' --enable-auth-negotiate='kerberos,wrapper'
-bash: --enable-auth-ntlm=fake: Kommando nicht gefunden.

synrzu at NTB-SYN-273 ~
$     --enable-external-acl-helpers='LDAP_group,SQL_session,eDirectory_userip,file_userip,kerberos_ldap_group,session,time_quota,unix_group,wbinfo_group'
-bash: --enable-external-acl-helpers=LDAP_group,SQL_session,eDirectory_userip,file_userip,kerberos_ldap_group,session,time_quota,unix_group,wbinfo_group:
Kommando nicht gefunden.

synrzu at NTB-SYN-273 ~
$     --with-openssl --with-filedescriptors=65536
-bash: --with-openssl: Kommando nicht gefunden.

synrzu at NTB-SYN-273 ~
$     --enable-removal-policies="lru,heap"
-bash: --enable-removal-policies=lru,heap: Kommando nicht gefunden.

synrzu at NTB-SYN-273 ~
$

Regards

Reinhard


From squid3 at treenet.co.nz  Sat Feb  9 17:00:03 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 10 Feb 2019 06:00:03 +1300
Subject: [squid-users] Bulding Squid 3.5 for Win2k with SSL
In-Reply-To: <CAM=1poQ3WR45t8+99Kb7wND5OKnq-3R1=gKDBBgEmWGG6LKGsA@mail.gmail.com>
References: <CAM=1poQ3WR45t8+99Kb7wND5OKnq-3R1=gKDBBgEmWGG6LKGsA@mail.gmail.com>
Message-ID: <b37c9a9a-27c2-bf5f-8232-e36256865e64@treenet.co.nz>

On 9/02/19 10:37 pm, Reinhard Zumpf Dipl.-Ing. wrote:
> Hi,
> 
> I am having trouble Bulding Squid 3.5 for Win2k with SSL according to:
> https://docs.diladele.com/howtos/build_squid_windows/index.html
> 
> Do you know why configure terminates like this? 


Looks like you copy-paste'd a command without accounting for line wrapping.

Notice the comment "(written as ONE line!)" directly above where you
copied the command from.


I had to switch within
> Cygwin frome home dir to usr/src dir as described in section Using
> Cygwin
> https://www.physionet.org/physiotools/cygwin/
> to comply with the guide from Diladele initially. I wonder why enable
> ssl is done in this guide without including any openssl for build?
> 

Not sure what you are talking about there. OpenSSL module is mentioned
earlier in the Diladele document, and the configure option(s) to use it
are present.


Amos


From rzumpf at gmail.com  Sun Feb 10 08:56:39 2019
From: rzumpf at gmail.com (Reinhard Zumpf Dipl.-Ing.)
Date: Sun, 10 Feb 2019 09:56:39 +0100
Subject: [squid-users] Building Squid 3.5 for Win2k with SSL
In-Reply-To: <b37c9a9a-27c2-bf5f-8232-e36256865e64@treenet.co.nz>
References: <CAM=1poQ3WR45t8+99Kb7wND5OKnq-3R1=gKDBBgEmWGG6LKGsA@mail.gmail.com>
 <b37c9a9a-27c2-bf5f-8232-e36256865e64@treenet.co.nz>
Message-ID: <CAM=1poQ6quQgUXqjMoH2Rqr_nY0QbLr6Yvye80d9oJSQZ-koaA@mail.gmail.com>

Hi,

thanks so much for helping out. I managed to get configure run through
now as described from Diladele.

But, make terminates like that:

...
mv -f $depbase.Tpo $depbase.Po
depbase=`echo SBuf.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
-DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\"
-DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I.. -I../include -I../lib
-I../src -I../include    -I../src   -I/usr/include/libxml2
-I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings
-Wcomments -Wshadow -Woverloaded-virtual -pipe -D_REENTRANT -g -O2
-march=native -MT SBuf.o -MD -MP -MF $depbase.Tpo -c -o SBuf.o SBuf.cc
&&\
mv -f $depbase.Tpo $depbase.Po
SBuf.cc: In Elementfunktion ?SBuf::size_type SBuf::rfind(char,
SBuf::size_type) const?:
SBuf.cc:760:21: Fehler: ?memrchr? wurde in diesem G?ltigkeitsbereich
nicht definiert
     const void *i = memrchr(buf(), (int)c, (size_type)endPos);
                     ^~~~~~~
SBuf.cc:760:21: Anmerkung: empfohlene Alternative: ?memchr?
     const void *i = memrchr(buf(), (int)c, (size_type)endPos);
                     ^~~~~~~
                     memchr
make[3]: *** [Makefile:7173: SBuf.o] Fehler 1
make[3]: Verzeichnis ?/home/synrzu/squid-3.5.28/src? wird verlassen
make[2]: *** [Makefile:7296: all-recursive] Fehler 1
make[2]: Verzeichnis ?/home/synrzu/squid-3.5.28/src? wird verlassen
make[1]: *** [Makefile:6157: all] Fehler 2
make[1]: Verzeichnis ?/home/synrzu/squid-3.5.28/src? wird verlassen
make: *** [Makefile:581: all-recursive] Fehler 1

It is the latest x86 cygwin with all packages mentioned by Diladele
and Squid 3.5.28 sources.

What can I do?

Regards,

Reinhard

Am Sa., 9. Feb. 2019 um 18:00 Uhr schrieb Amos Jeffries <squid3 at treenet.co.nz>:
>
> On 9/02/19 10:37 pm, Reinhard Zumpf Dipl.-Ing. wrote:
> > Hi,
> >
> > I am having trouble Bulding Squid 3.5 for Win2k with SSL according to:
> > https://docs.diladele.com/howtos/build_squid_windows/index.html
> >
> > Do you know why configure terminates like this?
>
>
> Looks like you copy-paste'd a command without accounting for line wrapping.
>
> Notice the comment "(written as ONE line!)" directly above where you
> copied the command from.
>
>
> I had to switch within
> > Cygwin frome home dir to usr/src dir as described in section Using
> > Cygwin
> > https://www.physionet.org/physiotools/cygwin/
> > to comply with the guide from Diladele initially. I wonder why enable
> > ssl is done in this guide without including any openssl for build?
> >
>
> Not sure what you are talking about there. OpenSSL module is mentioned
> earlier in the Diladele document, and the configure option(s) to use it
> are present.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Sun Feb 10 10:29:44 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 10 Feb 2019 23:29:44 +1300
Subject: [squid-users] Building Squid 3.5 for Win2k with SSL
In-Reply-To: <CAM=1poQ6quQgUXqjMoH2Rqr_nY0QbLr6Yvye80d9oJSQZ-koaA@mail.gmail.com>
References: <CAM=1poQ3WR45t8+99Kb7wND5OKnq-3R1=gKDBBgEmWGG6LKGsA@mail.gmail.com>
 <b37c9a9a-27c2-bf5f-8232-e36256865e64@treenet.co.nz>
 <CAM=1poQ6quQgUXqjMoH2Rqr_nY0QbLr6Yvye80d9oJSQZ-koaA@mail.gmail.com>
Message-ID: <b1ef1877-3db4-fc89-6e78-a3faa05c7c2f@treenet.co.nz>

On 10/02/19 9:56 pm, Reinhard Zumpf Dipl.-Ing. wrote:
> Hi,
> 
> thanks so much for helping out. I managed to get configure run through
> now as described from Diladele.
> 
> But, make terminates like that:
> 
> ...
> mv -f $depbase.Tpo $depbase.Po
> depbase=`echo SBuf.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
> g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
> -DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\"
> -DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I.. -I../include -I../lib
> -I../src -I../include    -I../src   -I/usr/include/libxml2
> -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings
> -Wcomments -Wshadow -Woverloaded-virtual -pipe -D_REENTRANT -g -O2
> -march=native -MT SBuf.o -MD -MP -MF $depbase.Tpo -c -o SBuf.o SBuf.cc
> &&\
> mv -f $depbase.Tpo $depbase.Po
> SBuf.cc: In Elementfunktion ?SBuf::size_type SBuf::rfind(char,
> SBuf::size_type) const?:
> SBuf.cc:760:21: Fehler: ?memrchr? wurde in diesem G?ltigkeitsbereich
> nicht definiert
>      const void *i = memrchr(buf(), (int)c, (size_type)endPos);
>                      ^~~~~~~
> SBuf.cc:760:21: Anmerkung: empfohlene Alternative: ?memchr?
>      const void *i = memrchr(buf(), (int)c, (size_type)endPos);
>                      ^~~~~~~
>                      memchr
> make[3]: *** [Makefile:7173: SBuf.o] Fehler 1
> make[3]: Verzeichnis ?/home/synrzu/squid-3.5.28/src? wird verlassen
> make[2]: *** [Makefile:7296: all-recursive] Fehler 1
> make[2]: Verzeichnis ?/home/synrzu/squid-3.5.28/src? wird verlassen
> make[1]: *** [Makefile:6157: all] Fehler 2
> make[1]: Verzeichnis ?/home/synrzu/squid-3.5.28/src? wird verlassen
> make: *** [Makefile:581: all-recursive] Fehler 1
> 
> It is the latest x86 cygwin with all packages mentioned by Diladele
> and Squid 3.5.28 sources.
> 
> What can I do?
> 

I'm not familiar enough with Cygwin to be specific, sorry. You will need
to track down where the memrchr is defined and make sure that file gets
included properly by the compiler.

Rafael has not mentioned this failing with 3.5 before so I assume it is
something missing from the ./configure options, or perhapse some
extension to cygwin that needs installing.

You could try and ask Rafael / Diladele directly since it is their
document you are following here.

Amos


From rafael.akchurin at diladele.com  Sun Feb 10 10:53:19 2019
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sun, 10 Feb 2019 10:53:19 +0000
Subject: [squid-users] Building Squid 3.5 for Win2k with SSL
In-Reply-To: <b1ef1877-3db4-fc89-6e78-a3faa05c7c2f@treenet.co.nz>
References: <CAM=1poQ3WR45t8+99Kb7wND5OKnq-3R1=gKDBBgEmWGG6LKGsA@mail.gmail.com>
 <b37c9a9a-27c2-bf5f-8232-e36256865e64@treenet.co.nz>
 <CAM=1poQ6quQgUXqjMoH2Rqr_nY0QbLr6Yvye80d9oJSQZ-koaA@mail.gmail.com>
 <b1ef1877-3db4-fc89-6e78-a3faa05c7c2f@treenet.co.nz>
Message-ID: <VI1PR04MB4768215F6F80555DD1EF2B188F6B0@VI1PR04MB4768.eurprd04.prod.outlook.com>

Hello Amos, Reinhard,

Interestingly enough this error does not popup when building Squid on 64-bit Cygwin.
Might be some 32-bit installation glitch?

Best regards,
Rafael Akchurin
Diladele B.V.



-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Sunday, 10 February 2019 11:30
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Building Squid 3.5 for Win2k with SSL

On 10/02/19 9:56 pm, Reinhard Zumpf Dipl.-Ing. wrote:
> Hi,
> 
> thanks so much for helping out. I managed to get configure run through 
> now as described from Diladele.
> 
> But, make terminates like that:
> 
> ...
> mv -f $depbase.Tpo $depbase.Po
> depbase=`echo SBuf.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
> g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
> -DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\"
> -DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I.. -I../include -I../lib
> -I../src -I../include    -I../src   -I/usr/include/libxml2
> -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings 
> -Wcomments -Wshadow -Woverloaded-virtual -pipe -D_REENTRANT -g -O2 
> -march=native -MT SBuf.o -MD -MP -MF $depbase.Tpo -c -o SBuf.o SBuf.cc 
> &&\ mv -f $depbase.Tpo $depbase.Po
> SBuf.cc: In Elementfunktion ?SBuf::size_type SBuf::rfind(char,
> SBuf::size_type) const?:
> SBuf.cc:760:21: Fehler: ?memrchr? wurde in diesem G?ltigkeitsbereich 
> nicht definiert
>      const void *i = memrchr(buf(), (int)c, (size_type)endPos);
>                      ^~~~~~~
> SBuf.cc:760:21: Anmerkung: empfohlene Alternative: ?memchr?
>      const void *i = memrchr(buf(), (int)c, (size_type)endPos);
>                      ^~~~~~~
>                      memchr
> make[3]: *** [Makefile:7173: SBuf.o] Fehler 1
> make[3]: Verzeichnis ?/home/synrzu/squid-3.5.28/src? wird verlassen
> make[2]: *** [Makefile:7296: all-recursive] Fehler 1
> make[2]: Verzeichnis ?/home/synrzu/squid-3.5.28/src? wird verlassen
> make[1]: *** [Makefile:6157: all] Fehler 2
> make[1]: Verzeichnis ?/home/synrzu/squid-3.5.28/src? wird verlassen
> make: *** [Makefile:581: all-recursive] Fehler 1
> 
> It is the latest x86 cygwin with all packages mentioned by Diladele 
> and Squid 3.5.28 sources.
> 
> What can I do?
> 

I'm not familiar enough with Cygwin to be specific, sorry. You will need to track down where the memrchr is defined and make sure that file gets included properly by the compiler.

Rafael has not mentioned this failing with 3.5 before so I assume it is something missing from the ./configure options, or perhapse some extension to cygwin that needs installing.

You could try and ask Rafael / Diladele directly since it is their document you are following here.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From rzumpf at gmail.com  Sun Feb 10 12:02:44 2019
From: rzumpf at gmail.com (Reinhard Zumpf Dipl.-Ing.)
Date: Sun, 10 Feb 2019 13:02:44 +0100
Subject: [squid-users] Building Squid 3.5 for Win2k with SSL
In-Reply-To: <VI1PR04MB4768215F6F80555DD1EF2B188F6B0@VI1PR04MB4768.eurprd04.prod.outlook.com>
References: <CAM=1poQ3WR45t8+99Kb7wND5OKnq-3R1=gKDBBgEmWGG6LKGsA@mail.gmail.com>
 <b37c9a9a-27c2-bf5f-8232-e36256865e64@treenet.co.nz>
 <CAM=1poQ6quQgUXqjMoH2Rqr_nY0QbLr6Yvye80d9oJSQZ-koaA@mail.gmail.com>
 <b1ef1877-3db4-fc89-6e78-a3faa05c7c2f@treenet.co.nz>
 <VI1PR04MB4768215F6F80555DD1EF2B188F6B0@VI1PR04MB4768.eurprd04.prod.outlook.com>
Message-ID: <CAM=1poTbqDAwVQaKaVN22OGG0knxCQHNu7i-cU1apE8b2RsuPg@mail.gmail.com>

Dear Gentlemen,

was anyone successful in building Squid 3.5 for Win2k with SSL (>
OpenSSL 1.0.1 / TLS 1.2) so far?

If not, I will not be able to do it without an tremendous amount of
support, which is a great pity, if Squid can only be used on x64 while
the field of application spans over mitigating TLS compatibility
problems for older x86 servers (eg. php4 with cURL w/o TLS1.2, which
is needed for several APIs), too.

Best Regards

Reinhard


Am So., 10. Feb. 2019 um 11:53 Uhr schrieb Rafael Akchurin
<rafael.akchurin at diladele.com>:
>
> Hello Amos, Reinhard,
>
> Interestingly enough this error does not popup when building Squid on 64-bit Cygwin.
> Might be some 32-bit installation glitch?
>
> Best regards,
> Rafael Akchurin
> Diladele B.V.
>
>
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
> Sent: Sunday, 10 February 2019 11:30
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Building Squid 3.5 for Win2k with SSL
>
> On 10/02/19 9:56 pm, Reinhard Zumpf Dipl.-Ing. wrote:
> > Hi,
> >
> > thanks so much for helping out. I managed to get configure run through
> > now as described from Diladele.
> >
> > But, make terminates like that:
> >
> > ...
> > mv -f $depbase.Tpo $depbase.Po
> > depbase=`echo SBuf.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
> > g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
> > -DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\"
> > -DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I.. -I../include -I../lib
> > -I../src -I../include    -I../src   -I/usr/include/libxml2
> > -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings
> > -Wcomments -Wshadow -Woverloaded-virtual -pipe -D_REENTRANT -g -O2
> > -march=native -MT SBuf.o -MD -MP -MF $depbase.Tpo -c -o SBuf.o SBuf.cc
> > &&\ mv -f $depbase.Tpo $depbase.Po
> > SBuf.cc: In Elementfunktion ?SBuf::size_type SBuf::rfind(char,
> > SBuf::size_type) const?:
> > SBuf.cc:760:21: Fehler: ?memrchr? wurde in diesem G?ltigkeitsbereich
> > nicht definiert
> >      const void *i = memrchr(buf(), (int)c, (size_type)endPos);
> >                      ^~~~~~~
> > SBuf.cc:760:21: Anmerkung: empfohlene Alternative: ?memchr?
> >      const void *i = memrchr(buf(), (int)c, (size_type)endPos);
> >                      ^~~~~~~
> >                      memchr
> > make[3]: *** [Makefile:7173: SBuf.o] Fehler 1
> > make[3]: Verzeichnis ?/home/synrzu/squid-3.5.28/src? wird verlassen
> > make[2]: *** [Makefile:7296: all-recursive] Fehler 1
> > make[2]: Verzeichnis ?/home/synrzu/squid-3.5.28/src? wird verlassen
> > make[1]: *** [Makefile:6157: all] Fehler 2
> > make[1]: Verzeichnis ?/home/synrzu/squid-3.5.28/src? wird verlassen
> > make: *** [Makefile:581: all-recursive] Fehler 1
> >
> > It is the latest x86 cygwin with all packages mentioned by Diladele
> > and Squid 3.5.28 sources.
> >
> > What can I do?
> >
>
> I'm not familiar enough with Cygwin to be specific, sorry. You will need to track down where the memrchr is defined and make sure that file gets included properly by the compiler.
>
> Rafael has not mentioned this failing with 3.5 before so I assume it is something missing from the ./configure options, or perhapse some extension to cygwin that needs installing.
>
> You could try and ask Rafael / Diladele directly since it is their document you are following here.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Sun Feb 10 14:13:13 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 11 Feb 2019 03:13:13 +1300
Subject: [squid-users] Building Squid 3.5 for Win2k with SSL
In-Reply-To: <CAM=1poTbqDAwVQaKaVN22OGG0knxCQHNu7i-cU1apE8b2RsuPg@mail.gmail.com>
References: <CAM=1poQ3WR45t8+99Kb7wND5OKnq-3R1=gKDBBgEmWGG6LKGsA@mail.gmail.com>
 <b37c9a9a-27c2-bf5f-8232-e36256865e64@treenet.co.nz>
 <CAM=1poQ6quQgUXqjMoH2Rqr_nY0QbLr6Yvye80d9oJSQZ-koaA@mail.gmail.com>
 <b1ef1877-3db4-fc89-6e78-a3faa05c7c2f@treenet.co.nz>
 <VI1PR04MB4768215F6F80555DD1EF2B188F6B0@VI1PR04MB4768.eurprd04.prod.outlook.com>
 <CAM=1poTbqDAwVQaKaVN22OGG0knxCQHNu7i-cU1apE8b2RsuPg@mail.gmail.com>
Message-ID: <990c8a32-4e29-5ace-566d-eafea8cb9309@treenet.co.nz>

On 11/02/19 1:02 am, Reinhard Zumpf Dipl.-Ing. wrote:
> Dear Gentlemen,
> 
> was anyone successful in building Squid 3.5 for Win2k with SSL (>
> OpenSSL 1.0.1 / TLS 1.2) so far?
> 

The oldest Windows I have had Squid-3.x building was Win7. But my work
was on the native builds with MinGW-w64. The Cygwin environment is a
different beast entirely - much more POSIX and Linux.



> If not, I will not be able to do it without an tremendous amount of
> support, which is a great pity, if Squid can only be used on x64 while
> the field of application spans over mitigating TLS compatibility
> problems for older x86 servers (eg. php4 with cURL w/o TLS1.2, which
> is needed for several APIs), too.
> 

Squid can be run on any machine and still do that job. You do not have
to limit yourself to old hardware or Win2k OS to achieve.

Just have routing and NAT systems enforcing clients traffic goes through
the proxy if you are the ISP for them. Or advertise the proxy IP address
instead of the old server address if you are running the service. Or
both if you have a mixed environment.

Amos


From rousskov at measurement-factory.com  Mon Feb 11 02:28:24 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 10 Feb 2019 19:28:24 -0700
Subject: [squid-users] ssl-bump does not redirect to block page
In-Reply-To: <78343853-0167-c891-7cfe-1003dc80d905@treenet.co.nz>
References: <1850120258.3983034.1549464726329.ref@mail.yahoo.com>
 <1850120258.3983034.1549464726329@mail.yahoo.com>
 <78343853-0167-c891-7cfe-1003dc80d905@treenet.co.nz>
Message-ID: <18ee45ac-e6ec-aca3-0961-5bac560be434@measurement-factory.com>

On 2/6/19 12:57 PM, Amos Jeffries wrote:
> On 7/02/19 3:52 am, leo messi wrote:
>> My squid config is something like this:
>> acl blk ssl::server_name .google.com
>> http_access deny blk
>> http_access allow all

>> ssl_bump peek step1
>> ssl_bump splice all

>> My problem is when i block some pages like google.com,my firefox browser
>> show "secure connection failed",but i want it to show block page or
>> warning page, how can i do this?


> To cause anything at all to display in the browser you require fully
> decrypting the traffic. 

Correct.


> aka the 'bump' action.

This part is misleading: Modern Squids _automatically_ bump connections
to report [access denied] errors -- no explicit bump action is required
(or even desirable). I do not know whether

* that bumping does not happen for leo (e.g., due to Squid bugs), or

* it does happen, but the browser refuses to show the error page anyway
(because of certificate pinning and/or because Squid did not have enough
information to properly bump the client connection using just step1
knowledge).

A packet capture or an ALL,2 cache.log may distinguish those two cases.

Alex.


From rousskov at measurement-factory.com  Mon Feb 11 03:01:20 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 10 Feb 2019 20:01:20 -0700
Subject: [squid-users] Bad HTTP header error on non-standard HTTP
 response code
In-Reply-To: <CAHvB88zHN0bXHCsGNLh2i-9CA2WTGZ2jsuWr6MydLxzhf+mPaQ@mail.gmail.com>
References: <CAHvB88zHN0bXHCsGNLh2i-9CA2WTGZ2jsuWr6MydLxzhf+mPaQ@mail.gmail.com>
Message-ID: <187de363-d95d-e040-c346-625191e685b4@measurement-factory.com>

On 2/6/19 10:39 AM, Ivan Larionov wrote:
> is there an option to change squid 4 behavior to match squid 3?

It is easy to relax Squid response parser to accept more syntactically
invalid HTTP responses, but one would need a good use case to do so
officially because of the problems with HTTP/0 responses (that Amos has
mentioned) and other message smuggling dangers. A single case of an
unusual/rare broken origin server is unlikely to be sufficient for this
IMHO.

Alex.
P.S. If you want to patch your Squid, look for the tok.int64() call in
Http::One::ResponseParser::parseResponseStatusAndReason().


From rousskov at measurement-factory.com  Mon Feb 11 03:19:37 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 10 Feb 2019 20:19:37 -0700
Subject: [squid-users] Proxing only special file types
In-Reply-To: <1549450099364-0.post@n4.nabble.com>
References: <1549450099364-0.post@n4.nabble.com>
Message-ID: <3b4019a9-e1b3-d625-52de-0a630b0dbe9e@measurement-factory.com>

On 2/6/19 3:48 AM, alexmaystat wrote:

> Is it possible to inspect and add JS code only to files of a specific file
> type (for example, only to JS text/javascript). 

Yes, provided you can trust Content-Type response headers (or
equivalent). If you do trust them, then you can configure Squid to adapt
only responses that have Content-Type set to, say, text/javascript.

The above assumes that by "inspect" you mean inspect by an eCAP adapter.
Squid itself would still inspect (i.e., "see" and "parse") every HTTP
message it proxies, of course.


> Or it is possible to proxy only JS files, and send the rest of the content
> and requests outside squid proxy?

This is only possible (in some cases) using client-side tools like
browser PAC configuration files. If you can write a simple Javascript
program that can determine whether the pending request is for a "JS
file", and you can configure the browser to use your program (by loading
your PAC file), then you can restrict Squid traffic to those "JS file"
transactions.


As you probably know by now, modifying proxied response content is
usually difficult and often illegal. For more details, see
https://answers.launchpad.net/ecap/+faq/1793


HTH,

Alex.


From paul at doignon.fr  Mon Feb 11 10:55:05 2019
From: paul at doignon.fr (Paul Doignon)
Date: Mon, 11 Feb 2019 11:55:05 +0100
Subject: [squid-users] Filering HTTPS URLs - A complete configuration
In-Reply-To: <a34944d8-a52d-664b-8a2e-e4bfd1a753b3@treenet.co.nz>
References: <168be13b6f9.c72dacf0274895.400411858861977298@doignon.fr>
 <48ab3054-7651-564a-c79e-fc2b38db7b4a@treenet.co.nz>
 <168c34bb82e.114bc9e7c22107.5629353171280088961@doignon.fr>
 <a34944d8-a52d-664b-8a2e-e4bfd1a753b3@treenet.co.nz>
Message-ID: <168dc323ad8.123bb865c63076.4646907180784701926@doignon.fr>

> No need to compile and build it for AWS:
> I already built it for both AWS 1 and 2:
> http://ngtech.co.il/repo/amzn/
> 
> Can be downloaded and is tested to work very well on both OS. 
> 
> Eliezer

Thanks, looks really good !
I guess those Amazon Linux 1 packages come from there : http://gogs.ngtech.co.il/NgTech-LTD/squid-amzn1-squid4-rpms ?


> The closest you are going to get to the above is with:
> * bump everything[1], and
> * use http_access to check the https:// URLs for your policy
> * use "deny_info TCP_RESET" [2] on the blocked requests.
> 
> [1] some things literally cannot be bumped. So a decision needs to be
> made about what to do then.

All right, good point. I guess adding this second line will terminate those un-bumpable requests ?

# --
ssl_bump bump all
ssl_bump terminate all
# --

> [2] a regular deny error page will work fine. This TCP_RESET is just
> closest to the "ssl_bump terminate" behaviour.
> 
> Amos

This is perfect, thanks a lot.

I leave my complete config for other users :

# --
# General
cache_effective_user squid
cache_effective_group squid
shutdown_lifetime 1 seconds 
visible_hostname squid-something.unique

# Hide some reavealing stuffs
forwarded_for delete
httpd_suppress_version_string off
reply_header_access X-Cache deny all
reply_header_access X-Cache-Lookup deny all
via off
global_internal_static off
cache deny all

# Tuning
max_filedesc 10000

# Security
http_access deny manager
host_verify_strict on
ignore_unknown_nameservers on
snmp_port 0
snmp_access deny all
icp_port 0
icp_access deny all
htcp_port 0
htcp_access deny all

http_port localhost:3128 # Squid default port

# Handling HTTPS requests
# Ciphers from https://wiki.mozilla.org/Security/Server_Side_TLS
https_port 8080 act-as-origin ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl/squid.pem cipher=ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256 options=NO_SSLv3,NO_TLSv1,NO_TLSv1_1,SINGLE_DH_USE,SINGLE_ECDH_USE intercept
sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/cache/squid/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1
#
tls_outgoing_options cipher=ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256 min-version=1.2 options=NO_SSLv3,SINGLE_DH_USE

acl TO_SSL port 443
acl LAN src 172.16.0.0/24
acl whitelist-regex url_regex -i ^https://thirdparty\.com/upload/stuff/$
acl CONNECT method CONNECT
deny_info TCP_RESET all
http_access allow LAN TO_SSL CONNECT
http_access allow LAN TO_SSL whitelist-regex
http_access deny all

# SSL bump
ssl_bump bump all
ssl_bump terminate all
# --


 ---- On Thu, 07 Feb 2019 01:46:23 +0100 Amos Jeffries <squid3 at treenet.co.nz> wrote ---- 
 > On 7/02/19 3:52 am, Paul Doignon wrote:
 > > Thanks, I appreciate your detailed answer.
 > > 
 > >  > > I'm struggling a lot to configure Squid. To improve the security of my app in my AWS private subnet,
 > >  > 
 > >  > If it is indeed *your* app; then please alter it not to require the
 > >  > interception we see below. Ability to connect to a TLS explicit proxy or
 > >  > just sending regular proxy CONNECT tunnel is a leap up in security.
 > > 
 > > I wish I could too ! Unfortunately, we use some third party libraries that do not support proxies (or not well). What a shame : (
 > >  
 > >  > > # Hide some reavealing or useless headers
 > >  > > forwarded_for delete
 > >  > > httpd_suppress_version_string off
 > >  > > reply_header_access X-Cache deny all
 > >  > > reply_header_access X-Cache-Lookup deny all
 > >  > > via off
 > >  > > 
 > >  > > # Tuning
 > >  > > max_filedesc 10000
 > >  > > 
 > >  > > # Disable access to manager
 > >  > > http_access deny manager
 > >  > 
 > >  > 2) you are missing the security protections from the default squid.conf...
 > >  
 > > I have not hardened Squid yet, but you mean default `acl localnet src [...]` rules ? I'm not sure about this.
 > > 
 > 
 > The defaults that come with a new build or installation:
 > 
 > "
 >   http_access deny !Safe_ports
 >   http_access deny CONNECT !SSL_ports
 >   http_access allow localhost manager
 >   http_access deny manager
 > 
 >   ... your rules go here ...
 > 
 >   http_access deny all
 > "
 > 
 > 
 > >  > Please see <https://wiki.squid-cache.org/Features/SslPeekAndSplice> for
 > >  > details on the TLS handshake process and what SSL-Bump does during that.
 > > 
 > > Another read was indeed interesting, I think I corrected ssl_bump directives. However I still can't make it work.
 > > Just for the record, I would like to block everything but some HTTPS websites for particular URLs. The ssl::server_name acl is not enough for me, I would like to use url_regex or similar.
 > > Ant that's where it gets wrong, I can't make Squid make the link between `ssl_bump bump` and url_regex.
 > 
 > 
 > That is because ssl_bump is the access control governing the TLS
 > handshake process. TLS message/frames do not contain URLs. Even when a
 > client CONNECT request is being processed it only has an authority-URI
 > (not a full URL).
 > 
 > The http_access rules are the first point you get access to URL. The
 > https:// URLs start *after* the ssl_bump finishes with a successful
 > 'bump' action.
 > 
 > 
 > The closest you are going to get to the above is with:
 >  * bump everything[1], and
 >  * use http_access to check the https:// URLs for your policy
 >  * use "deny_info TCP_RESET" [2] on the blocked requests.
 > 
 > [1] some things literally cannot be bumped. So a decision needs to be
 > made about what to do then.
 > 
 > [2] a regular deny error page will work fine. This TCP_RESET is just
 > closest to the "ssl_bump terminate" behaviour.
 > 
 > 
 > Amos
 > _______________________________________________
 > squid-users mailing list
 > squid-users at lists.squid-cache.org
 > http://lists.squid-cache.org/listinfo/squid-users
 > 




From rousskov at measurement-factory.com  Mon Feb 11 17:11:20 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 11 Feb 2019 10:11:20 -0700
Subject: [squid-users] Squid doesn't execute url_rewrite_program
 /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
In-Reply-To: <036901d4bb2e$cbfecc30$63fc6490$@ngtech.co.il>
References: <CAG2Qp6uNz-sKVMqbjH_OHpLZK=bALLT5gSyyjhcfi2NyEpUkBg@mail.gmail.com>
 <09127802-b4b8-7ceb-3df6-33059842907b@treenet.co.nz>
 <CAG2Qp6tJBJs6AV3tqGw3P-eYxzqwfTb12mo9qpGdeN9v6u2Y5A@mail.gmail.com>
 <c6330358-d1fe-3f10-0747-3fc54236cb5c@treenet.co.nz>
 <036901d4bb2e$cbfecc30$63fc6490$@ngtech.co.il>
Message-ID: <4847cbe7-5204-c460-b8bb-6fc1933f9e4b@measurement-factory.com>

On 2/2/19 12:37 PM, eliezer at ngtech.co.il wrote:
> Can we change the default from "startup=0" to "startup=1" ?

We obviously can. The real question is whether we should. AFAICT, the
default changed to zero in commit 48d54e4. In that commit message, I did
not find an explanation of _why_ the default was changed, but I could
have missed it. I only saw references to why the new default may cause
problems.

Before we restart changing defaults, we should agree on some principles
that should guide us in selecting the right default. Please feel free to
propose/defend them if you want to work on this change. Here is an
example of a possible principle we could use for situations where the
default option value is not clear/obvious:

* The default should maximize the chance that a misconfiguration is
discovered at startup time (rather than at runtime).

Alex.


> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
> Sent: Saturday, February 2, 2019 14:33
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid doesn't execute url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
> 
> On 2/02/19 7:56 am, Roberto Carna wrote:
>> Dear Amos, thanks for your comments.
>>
>> I realized that I have some clues in cache.log:
>>
>> 2019/02/01 15:51:44 kid1| helperOpenServers: Starting 0/20 'squidGuard'
>> processes
>> 2019/02/01 15:51:44 kid1| helperOpenServers: No 'squidGuard' processes
>> needed.
>> 2019/02/01 15:51:44 kid1| helperOpenServers: Starting 0/5
>> 'squid_ldap_auth' processes
>> 2019/02/01 15:51:44 kid1| helperOpenServers: No 'squid_ldap_auth'
>> processes needed.
>>
>> These lines appears after I execute "systemctl reload squid".
>>
>> Users and rights are OK.
>>
>> Please can you help me one more time?
>>
> 
> The above log lines indicate that Squid is waiting for traffic before
> going to the trouble of starting helpers. This is the default since
> Squid-3.2.
> 
> If you want to change that the relevant directives for these two helpers
> are:
>  <http://www.squid-cache.org/Doc/config/url_rewrite_children/>
>  <http://www.squid-cache.org/Doc/config/auth_param/> under "children"
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From squid3 at treenet.co.nz  Tue Feb 12 00:01:42 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 12 Feb 2019 13:01:42 +1300
Subject: [squid-users] Squid doesn't execute url_rewrite_program
 /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
In-Reply-To: <4847cbe7-5204-c460-b8bb-6fc1933f9e4b@measurement-factory.com>
References: <CAG2Qp6uNz-sKVMqbjH_OHpLZK=bALLT5gSyyjhcfi2NyEpUkBg@mail.gmail.com>
 <09127802-b4b8-7ceb-3df6-33059842907b@treenet.co.nz>
 <CAG2Qp6tJBJs6AV3tqGw3P-eYxzqwfTb12mo9qpGdeN9v6u2Y5A@mail.gmail.com>
 <c6330358-d1fe-3f10-0747-3fc54236cb5c@treenet.co.nz>
 <036901d4bb2e$cbfecc30$63fc6490$@ngtech.co.il>
 <4847cbe7-5204-c460-b8bb-6fc1933f9e4b@measurement-factory.com>
Message-ID: <1614bdcb-30e7-b61e-fe3b-91c20f7ece62@treenet.co.nz>

On 12/02/19 6:11 am, Alex Rousskov wrote:
> On 2/2/19 12:37 PM, eliezer at ngtech.co.il wrote:
>> Can we change the default from "startup=0" to "startup=1" ?
> 
> We obviously can. The real question is whether we should. AFAICT, the
> default changed to zero in commit 48d54e4. In that commit message, I did
> not find an explanation of _why_ the default was changed, but I could
> have missed it. I only saw references to why the new default may cause
> problems.

This feature was added with a focus on improving efficiency for small
integrated systems (OpenWRT, RaspberryPi, Android etc.) with some
additional benefits for larger systems.

The small limited-resource systems lack of RAM meant the default of 10
always running helpers of each type consumed sometimes considerably more
memory than was available in total or necessary.

Even larger resource-rick systems were having issues with admin
(mis)configuring hundreds of NTLM helpers in attempts to avoid helpers
all being busy at peak login times.

Most of that was solved by going dynamic. The default being 0 was extra
performance tuning - in hindsight perhapse not the best choice but
suited the use-case for limited memory devices and we have not had many
issues reported about it. A default of 1 would still solve most of the
issues as well as detecting helper crashes on startup. It would mean a
somewhat slower (few seconds) startup on some devices though.


> 
> Before we restart changing defaults, we should agree on some principles
> that should guide us in selecting the right default. Please feel free to
> propose/defend them if you want to work on this change. Here is an
> example of a possible principle we could use for situations where the
> default option value is not clear/obvious:
> 
> * The default should maximize the chance that a misconfiguration is
> discovered at startup time (rather than at runtime).
> 

* the default should not induce overly much RAM usage.

* the default should not cause unnecessary processes to run.

This last is the trickiest because it is a bit fuzzy and relies on
assumptions about admin behaviours - which also vary over time as
experience is gained or forgotten.

 ** Default 0 (current status-quo) assumption is that the admin might
configure a helper that is never used.

 ** Default of 1 that all helpers are needed, but maybe fast enough not
to need many forks().

 ** Default 2+ that traffic load and helper usage is going to be high
with all helpers handling a lot of I/O.


Amos


From eliezer at ngtech.co.il  Tue Feb 12 01:30:37 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Tue, 12 Feb 2019 03:30:37 +0200
Subject: [squid-users] Filering HTTPS URLs - A complete configuration
In-Reply-To: <168dc323ad8.123bb865c63076.4646907180784701926@doignon.fr>
References: <168be13b6f9.c72dacf0274895.400411858861977298@doignon.fr>
 <48ab3054-7651-564a-c79e-fc2b38db7b4a@treenet.co.nz>
 <168c34bb82e.114bc9e7c22107.5629353171280088961@doignon.fr>
 <a34944d8-a52d-664b-8a2e-e4bfd1a753b3@treenet.co.nz>
 <168dc323ad8.123bb865c63076.4646907180784701926@doignon.fr>
Message-ID: <028501d4c272$8ed1a030$ac74e090$@ngtech.co.il>

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Paul Doignon
Sent: Monday, February 11, 2019 12:55
To: squid-users <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Filering HTTPS URLs - A complete configuration

> No need to compile and build it for AWS:
> I already built it for both AWS 1 and 2:
> http://ngtech.co.il/repo/amzn/
> 
> Can be downloaded and is tested to work very well on both OS. 
> 
> Eliezer

Thanks, looks really good !
I guess those Amazon Linux 1 packages come from there : http://gogs.ngtech.co.il/NgTech-LTD/squid-amzn1-squid4-rpms ?

Right ^^

> The closest you are going to get to the above is with:
> * bump everything[1], and
> * use http_access to check the https:// URLs for your policy
> * use "deny_info TCP_RESET" [2] on the blocked requests.
> 
> [1] some things literally cannot be bumped. So a decision needs to be
> made about what to do then.
<SNIP>



From anon.amish at gmail.com  Tue Feb 12 02:35:52 2019
From: anon.amish at gmail.com (Amish)
Date: Tue, 12 Feb 2019 08:05:52 +0530
Subject: [squid-users] note macro - %{policy_}note passes old values
 along with new value
In-Reply-To: <27dde56c-da71-fecf-65fb-476adbe3ab99@gmail.com>
References: <39130abd-4d18-e284-2c80-80219786576b@gmail.com>
 <efed6d2b-d9dd-eb60-6ca8-433a3555a2cd@measurement-factory.com>
 <a2612076-9b59-b7de-0b94-d7f2011af222@gmail.com>
 <696c2b06-6ca0-b0e6-5d5b-82a86703640c@measurement-factory.com>
 <27dde56c-da71-fecf-65fb-476adbe3ab99@gmail.com>
Message-ID: <c56c1426-3351-ffff-f64d-30a5a2890424@gmail.com>



On 15/12/18 6:33 am, Amish wrote:
>
>
> On 15/12/18 5:27 am, Alex Rousskov wrote:
>>>> With modern Squids, you should not do anything special to accomplish
>>>> that. Only the latest annotation value should be preserved. If that is
>>>> not happening in your tests, consider filing a bug report, 
>>>> especially if
>>>> you can reproduce with Squid v4+.
>>>> https://github.com/squid-cache/squid/commit/457857fe7cf51037cd9e54e86c0985391d7ea594 
>>>>
>> No, the two are pretty much unrelated. The always-erase-the-old-value
>> fix (not really a feature!) in the above-referenced commit should apply
>> to all annotations, not just client connection annotations. IIRC, our
>> connection annotation work simply exposed the fact that we screwed up
>> with annotation updates earlier, and we fixed that bug in the same 
>> project.
>>
>> Alex.
>
> Bug report with steps to reproduce filed:
>
> https://bugs.squid-cache.org/show_bug.cgi?id=4912
>
> Amish

This bug is open since almost 2 months now without anyone being assigned.

Just curious if thats a right place to report the bug?

Thank you,

Amish.



From rousskov at measurement-factory.com  Tue Feb 12 04:14:07 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 11 Feb 2019 21:14:07 -0700
Subject: [squid-users] note macro - %{policy_}note passes old values
 along with new value
In-Reply-To: <c56c1426-3351-ffff-f64d-30a5a2890424@gmail.com>
References: <39130abd-4d18-e284-2c80-80219786576b@gmail.com>
 <efed6d2b-d9dd-eb60-6ca8-433a3555a2cd@measurement-factory.com>
 <a2612076-9b59-b7de-0b94-d7f2011af222@gmail.com>
 <696c2b06-6ca0-b0e6-5d5b-82a86703640c@measurement-factory.com>
 <27dde56c-da71-fecf-65fb-476adbe3ab99@gmail.com>
 <c56c1426-3351-ffff-f64d-30a5a2890424@gmail.com>
Message-ID: <4a2a4074-55e0-64c0-3456-566518af1e58@measurement-factory.com>

On 2/11/19 7:35 PM, Amish wrote:
> On 15/12/18 6:33 am, Amish wrote:
>>
>>
>> On 15/12/18 5:27 am, Alex Rousskov wrote:
>>>>> With modern Squids, you should not do anything special to accomplish
>>>>> that. Only the latest annotation value should be preserved. If that is
>>>>> not happening in your tests, consider filing a bug report,
>>>>> especially if you can reproduce with Squid v4+.
>>>>> https://github.com/squid-cache/squid/commit/457857fe7cf51037cd9e54e86c0985391d7ea594

>> Bug report with steps to reproduce filed:
>> https://bugs.squid-cache.org/show_bug.cgi?id=4912

> This bug is open since almost 2 months now without anyone being assigned.
> 
> Just curious if thats a right place to report the bug?

Yes, it is. Thank you for filing that bug report! I hope somebody
volunteers to fix that bug or sponsors a fix.

Alex.


From rousskov at measurement-factory.com  Tue Feb 12 04:37:05 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 11 Feb 2019 21:37:05 -0700
Subject: [squid-users] Squid doesn't execute url_rewrite_program
 /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
In-Reply-To: <1614bdcb-30e7-b61e-fe3b-91c20f7ece62@treenet.co.nz>
References: <CAG2Qp6uNz-sKVMqbjH_OHpLZK=bALLT5gSyyjhcfi2NyEpUkBg@mail.gmail.com>
 <09127802-b4b8-7ceb-3df6-33059842907b@treenet.co.nz>
 <CAG2Qp6tJBJs6AV3tqGw3P-eYxzqwfTb12mo9qpGdeN9v6u2Y5A@mail.gmail.com>
 <c6330358-d1fe-3f10-0747-3fc54236cb5c@treenet.co.nz>
 <036901d4bb2e$cbfecc30$63fc6490$@ngtech.co.il>
 <4847cbe7-5204-c460-b8bb-6fc1933f9e4b@measurement-factory.com>
 <1614bdcb-30e7-b61e-fe3b-91c20f7ece62@treenet.co.nz>
Message-ID: <b61d6da2-492e-3d96-20f2-74206e5c460e@measurement-factory.com>

On 2/11/19 5:01 PM, Amos Jeffries wrote:
> On 12/02/19 6:11 am, Alex Rousskov wrote:
>> On 2/2/19 12:37 PM, eliezer at ngtech.co.il wrote:
>>> Can we change the default from "startup=0" to "startup=1" ?
>>
>> We obviously can. The real question is whether we should. AFAICT, the
>> default changed to zero in commit 48d54e4. In that commit message, I did
>> not find an explanation of _why_ the default was changed

> The default being 0 was extra performance tuning

When there is a trade-off (e.g., with detecting misconfigurations), the
choice of the default should not be driven by performance optimizations
or special deployment environments IMO -- those who need to optimize
performance or accommodate special environments can and should tune
their squid.conf settings explicitly instead of relying on defaults.


>> Before we restart changing defaults, we should agree on some principles
>> that should guide us in selecting the right default. Please feel free to
>> propose/defend them if you want to work on this change. Here is an
>> example of a possible principle we could use for situations where the
>> default option value is not clear/obvious:

>> * The default should maximize the chance that a misconfiguration is
>> discovered at startup time (rather than at runtime).

> * the default should not induce overly much RAM usage.

> * the default should not cause unnecessary processes to run.

The last two are too obvious to be practically useful AFAICT: Clearly,
we do not want "overly much" or "unnecessary" of anything.


>  ** Default 0 (current status-quo) assumption is that the admin might
> configure a helper that is never used.

>  ** Default of 1 that all helpers are needed, but maybe fast enough not
> to need many forks().

>  ** Default 2+ that traffic load and helper usage is going to be high
> with all helpers handling a lot of I/O.

Yes, but those use cases are not principles that can guide us towards
selecting the right default. Clearly, any reasonable default value will
match some use case or another.

Also, "configure a helper that is never used" is arguably a
misconfiguration (that we should, to the extent possible, highlight
rather than conceal).

There is another general principle that says "Admin should only pay for
the features they enable", but it does not help in this particular
situation AFAICT because the admin _is_ configuring the helper
explicitly, so we have the right to charge the admin for that (by
increasing startup costs).

Alex.


From leomessi983 at yahoo.com  Tue Feb 12 14:21:34 2019
From: leomessi983 at yahoo.com (leomessi983 at yahoo.com)
Date: Tue, 12 Feb 2019 14:21:34 +0000 (UTC)
Subject: [squid-users] ssl-bump does not redirect to block page
References: <1479917107.2282419.1549981294109.ref@mail.yahoo.com>
Message-ID: <1479917107.2282419.1549981294109@mail.yahoo.com>

Hi againDo i have to use CA and Certificate configuration if i want to block only? HTTPS requests with splice action?!


https_port 3130 tproxy ssl-bump \
? cert=/etc/squid/ssl_cert/myCA.pem \
? generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
  sslcrtd_program /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 4MB
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190212/8311d242/attachment.htm>

From rousskov at measurement-factory.com  Tue Feb 12 15:04:08 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 12 Feb 2019 08:04:08 -0700
Subject: [squid-users] ssl-bump does not redirect to block page
In-Reply-To: <1479917107.2282419.1549981294109@mail.yahoo.com>
References: <1479917107.2282419.1549981294109.ref@mail.yahoo.com>
 <1479917107.2282419.1549981294109@mail.yahoo.com>
Message-ID: <024a80a6-6b15-e9d8-06f9-b9645fbb3058@measurement-factory.com>

On 2/12/19 7:21 AM, leomessi983 at yahoo.com wrote:

> Do i have to use CA and Certificate configuration if i want to block
> only HTTPS requests with splice action?!

IIRC, you currently need a CA certificate if you want to use SslBump,
regardless of the SslBump actions in use. In some ways, this is a
limitation of the current SslBump implementation rather than a natural
requirement, but the CA certificate is needed when Squid reports an
error to the client because Squid has to bump the client connection to
report errors.

If you do not care what happens when handling errors, then you probably
do not need to configure dynamic certificate generation. I have not
tested that, but I assume that, when reporting errors in that case,
Squid will silently revert to using the old code that generates
self-signed certificates (and the client will not trust them).


Please note that it is not clear what you mean by "to block with splice
action" -- splice does not block anything. If you are blocking requests
using http_access rules, then Squid is probably using an (implicit) bump
action to report blocking to the client, as discussed above. Blocking is
an example of errors that may happen even when you do not explicitly
bump any requests.

Alex.


> https_port 3130 tproxy ssl-bump \
> ? cert=/etc/squid/ssl_cert/myCA.pem \
> ? generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>   sslcrtd_program /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 4MB



From erdosain9 at gmail.com  Tue Feb 12 15:14:45 2019
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 12 Feb 2019 09:14:45 -0600 (CST)
Subject: [squid-users] Pass ip to server
Message-ID: <1549984485300-0.post@n4.nabble.com>

Hi.
I want to know if is possible that, for some site (sales.mydomain.com) the
proxy server send the "real ip".

Because i want to see in the logs of sales.mydomain.com the real ip of the
machine that are going (and not the proxy ip).

I know that i can see this in the log of squid... but, i want to know if it
is possible see this in the other server.

Thanks to all.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From JOfficer at istreamfs.com  Tue Feb 12 16:49:58 2019
From: JOfficer at istreamfs.com (Joey Officer)
Date: Tue, 12 Feb 2019 16:49:58 +0000
Subject: [squid-users] Pass ip to server
In-Reply-To: <1549984485300-0.post@n4.nabble.com>
References: <1549984485300-0.post@n4.nabble.com>
Message-ID: <DM5PR19MB1579C05FD36C83FF2D018DF8CD650@DM5PR19MB1579.namprd19.prod.outlook.com>

I believe the option you are referring to is the 'forwarded_for' http header.

Reference this: http://www.squid-cache.org/Doc/config/forwarded_for/

Hope that helps you.

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of erdosain9
Sent: Tuesday, February 12, 2019 9:15 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Pass ip to server

Hi.
I want to know if is possible that, for some site (sales.mydomain.com) the proxy server send the "real ip".

Because i want to see in the logs of sales.mydomain.com the real ip of the machine that are going (and not the proxy ip).

I know that i can see this in the log of squid... but, i want to know if it is possible see this in the other server.

Thanks to all.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From rousskov at measurement-factory.com  Tue Feb 12 21:48:51 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 12 Feb 2019 14:48:51 -0700
Subject: [squid-users] Filering HTTPS URLs - A complete configuration
In-Reply-To: <168dc323ad8.123bb865c63076.4646907180784701926@doignon.fr>
References: <168be13b6f9.c72dacf0274895.400411858861977298@doignon.fr>
 <48ab3054-7651-564a-c79e-fc2b38db7b4a@treenet.co.nz>
 <168c34bb82e.114bc9e7c22107.5629353171280088961@doignon.fr>
 <a34944d8-a52d-664b-8a2e-e4bfd1a753b3@treenet.co.nz>
 <168dc323ad8.123bb865c63076.4646907180784701926@doignon.fr>
Message-ID: <ed3096f0-fff0-2f8b-ddc5-e89cdbf92749@measurement-factory.com>

On 2/11/19 3:55 AM, Paul Doignon wrote:

>> The closest you are going to get to the above is with:
>> * bump everything[1], and
>> * use http_access to check the https:// URLs for your policy
>> * use "deny_info TCP_RESET" [2] on the blocked requests.
>>
>> [1] some things literally cannot be bumped. So a decision needs to be
>> made about what to do then.

> I guess adding this second line will terminate those un-bumpable requests?

No, that second ssl_bump line has no effect -- it will never be reached.

You are probably misinterpreting what was meant by "literally cannot be
bumped". What was meant by that phrase was that bumping certain
connections always results in client and/or server errors, regardless of
how you configure Squid. In those cases, Squid will still perform the
bump action if you tell it to bump, but that action will not lead to a
functioning tunnel through Squid.

In general, Squid itself cannot predict which connections can be
successfully bumped. You have to tell it (using ACLs, like the
whitelisted ACL in the example below).


> ssl_bump bump all
> ssl_bump terminate all

The first line emulates client-first bumping. That is not what you want.

To bump all connections, you could use something like this:

  ssl_bump stare all
  ssl_bump bump all

To bump all connections except whitelisted ones, you probably want
something like this:

  ssl_bump splice whitelisted
  ssl_bump stare all
  ssl_bump bump all

... where whitelisted is your ACL implementing your white listing policy
(i.e. matching TLS connections that should be spliced). It may use
ssl::server_name and probably other ACLs.

More details at https://wiki.squid-cache.org/Features/SslPeekAndSplice

Alex.


From leomessi983 at yahoo.com  Wed Feb 13 06:22:43 2019
From: leomessi983 at yahoo.com (leomessi983 at yahoo.com)
Date: Wed, 13 Feb 2019 06:22:43 +0000 (UTC)
Subject: [squid-users] ssl-bump does not redirect to block page
References: <974828205.84661.1550038963335.ref@mail.yahoo.com>
Message-ID: <974828205.84661.1550038963335@mail.yahoo.com>

>> aka the 'bump' action.

> This part is misleading: Modern Squids _automatically_ bump connections
> to report [access denied] errors -- no explicit bump action is required
> (or even desirable). I do not know whether> * that bumping does not happen for leo (e.g., due to Squid bugs), or

> * it does happen, but the browser refuses to show the error page anyway
> .(because of certificate pinning and/or because Squid did not have enough
> information to properly bump the client connection using just step1
> knowledge).

> A packet capture or an ALL,2 cache.log may distinguish those two cases.

> Alex.

Hi Alex
Actually i don't understand if it could be done or not!!
Amos said it is impossible you said no!!
can you show me the correct configuration for blocking HTTPS requests with showing access denied page to clients?!
 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190213/d8a98891/attachment.htm>

From Yann.Santschi at hopitalvs.ch  Wed Feb 13 09:26:03 2019
From: Yann.Santschi at hopitalvs.ch (Santschi Yann)
Date: Wed, 13 Feb 2019 09:26:03 +0000
Subject: [squid-users] Compiling with OpenSSL 1.1+
Message-ID: <37f66837b1b848faa3bd3c031cddec6f@hopitalvs.ch>

Hello everybody,

I'm trying to compile Squid 4.4 with OpenSSL 1.1.1a and I'm getting compilation errors like this one :


In file included from ../../src/security/Context.h:15:0,
                 from ../../src/security/forward.h:13,
                 from ../../src/SquidConfig.h:21,
                 from old_api.cc:24:
../../compat/openssl.h:121:2: error: #error missing both OpenSSL API features EVP_PKEY_up_ref (v1.1) and CRYPTO_LOCK_EVP_PKEY (v1.0)
 #error missing both OpenSSL API features EVP_PKEY_up_ref (v1.1) and CRYPTO_LOCK_EVP_PKEY (v1.0)

If I compile with the deprecated OpenSSL 1.0.2 branch it works but I don't want to use this branch. My goal is to offload SSL-Bump with hardware that needs OpenSSL 1.1.1.

I'm looking for a solution for a couple of days and I found absolutely nothing that helps in Squid documentation, source code and Google.


According to the "CompilingSquid" FAQ it should be feasible with Squid-4. Page https://wiki.squid-cache.org/SquidFaq/CompilingSquid says following :

However, please note that Squid-3.5<https://wiki.squid-cache.org/Squid-3.5> is not compatible with OpenSSL v1.1+. As of Debian Squeeze, or Ubuntu Zesty the libssl1.0-dev package must be used instead. This is resolved in the Squid-4<https://wiki.squid-cache.org/Squid-4> packages.


The configure script is run with following parameters :

./configure LDFLAGS=-ldl --prefix=/usr --includedir=/usr/include --datadir=/usr/share --bindir=/usr/sbin --libexecdir=/usr/lib/squid -localstatedir=/var --sysconfdir=/etc/squid --with-default-user=squid --with-openssl=/usr/local/ssl-1.1.1a/ --enable-ssl --enable-ssl-crtd --enable-linux-netfilter --enable-snmp --enable-useragent-log --enable-referer-log --enable-cachemgr --enable-truncate --enable-underscores --enable-stacktrace --enable-async-io=160 --enable-poll --enable-icmp --enable-ipfw-transparent --enable-forw-via-db --enable-cache-digests --with-included-ltdl --enable-ltdl-convenience


Can somebody tell me what's wrong ?


Regards


Yann

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190213/a48088d8/attachment.htm>

From squid3 at treenet.co.nz  Wed Feb 13 11:27:25 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Feb 2019 00:27:25 +1300
Subject: [squid-users] Compiling with OpenSSL 1.1+
In-Reply-To: <37f66837b1b848faa3bd3c031cddec6f@hopitalvs.ch>
References: <37f66837b1b848faa3bd3c031cddec6f@hopitalvs.ch>
Message-ID: <58df29ad-1ffd-a161-0e0b-747293e5617a@treenet.co.nz>

On 13/02/19 10:26 pm, Santschi Yann wrote:
> Hello everybody,
> 
> I'm trying to compile Squid 4.4 with OpenSSL 1.1.1a and I'm getting
> compilation errors like this one :
> 
> 
> In file included from ../../src/security/Context.h:15:0,
> ???????????????? from ../../src/security/forward.h:13,
> ???????????????? from ../../src/SquidConfig.h:21,
> ???????????????? from old_api.cc:24:
> ../../compat/openssl.h:121:2: error: #error missing both OpenSSL API
> features EVP_PKEY_up_ref (v1.1) and CRYPTO_LOCK_EVP_PKEY (v1.0)
> ?#error missing both OpenSSL API features EVP_PKEY_up_ref (v1.1) and
> CRYPTO_LOCK_EVP_PKEY (v1.0)
> 

Squid is not able to find your OpenSSL libcrypto installation. Neither
1.0 nor 1.1 version headers are available to the compiler.

The config.log file generated during the ./configure build stage should
contain hints about why that is. It should really have existed with an
error when detecting the library files, but may not have if you have
some other version of libssl or libcrypto or derivatives such as
libressl installed on the build machine in the usual (FHS) location for
such things.


You have this:

> --with-openssl=/usr/local/ssl-1.1.1a/

So please check that the libssl and libcrypto library and header
includes have been successfully *installed* at that location. Simply
expanding the library source code to there is not installation - this is
a common mistake, it has to actually be built and installed at the path
you are telling the Squid compile system to use.



> If I compile with the deprecated OpenSSL 1.0.2 branch it works but I
> don't want to use this branch. My goal is to offload SSL-Bump with
> hardware that needs OpenSSL 1.1.1.
> 
> I'm looking for a solution for a couple of days and I found absolutely
> nothing that helps in Squid documentation, source code and Google.
> 
> According to the "CompilingSquid" FAQ it should be feasible with
> Squid-4. Page https://wiki.squid-cache.org/SquidFaq/CompilingSquid says
> following?:
> 
> However, please note that Squid-3.5
> <https://wiki.squid-cache.org/Squid-3.5> is not compatible with OpenSSL
> v1.1+. As of Debian Squeeze, or Ubuntu Zesty the *libssl1.0-dev* package
> must be used instead. This is resolved in the Squid-4
> <https://wiki.squid-cache.org/Squid-4> packages.
> 

Since you are quoting the Debian and Ubuntu statements, are we to assume
that you are using one of those OS?
 If so, why not use the Debian Buster or Ubuntu Cosmic libssl-dev
package which is currently already at v1.1.1 ?


> 
> The configure script is run with following parameters :
> 
> ./configure LDFLAGS=-ldl --prefix=/usr --includedir=/usr/include
> --datadir=/usr/share --bindir=/usr/sbin --libexecdir=/usr/lib/squid
> -localstatedir=/var --sysconfdir=/etc/squid --with-default-user=squid
> --with-openssl=/usr/local/ssl-1.1.1a/ --enable-ssl --enable-ssl-crtd
> --enable-linux-netfilter --enable-snmp --enable-useragent-log
> --enable-referer-log --enable-cachemgr --enable-truncate
> --enable-underscores --enable-stacktrace --enable-async-io=160
> --enable-poll --enable-icmp --enable-ipfw-transparent
> --enable-forw-via-db --enable-cache-digests --with-included-ltdl
> --enable-ltdl-convenience

If you can spare some time please also run "./configure --help" and
remove the options from the above set which do not exist. At least the
--enable-ssl and log ones are non-existing.


HTH
Amos


From leomessi983 at yahoo.com  Wed Feb 13 12:10:33 2019
From: leomessi983 at yahoo.com (leomessi983 at yahoo.com)
Date: Wed, 13 Feb 2019 12:10:33 +0000 (UTC)
Subject: [squid-users] ssl-bump does not redirect to block page
References: <227618796.196669.1550059833071.ref@mail.yahoo.com>
Message-ID: <227618796.196669.1550059833071@mail.yahoo.com>

 I use this configuration to solve my problem.Whit this configuration at first step I use bump action for sites that i want to block and show ACCESS_DENIED page then splice all other requests!!My problem in this config is when my clients want to see block pages they first see SSL warning in their browser then after click on exception they will see ACCESS_DENIED page!!
..........acl blk ssl::server_name "/var/blkfiles/url.txt"
http_access  deny blkacl step1 at_step SslBump1ssl_bump peek step1ssl_bump bump blkssl_bump splice all

    On Wednesday, February 13, 2019, 9:55:06 AM GMT+3:30, squid-users-request at lists.squid-cache.org <squid-users-request at lists.squid-cache.org> wrote:  
 
 Send squid-users mailing list submissions to
??? squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
??? http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
??? squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
??? squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

? 1. ssl-bump does not redirect to block page (leomessi983 at yahoo.com)
? 2. Re: ssl-bump does not redirect to block page (Alex Rousskov)
? 3. Pass ip to server (erdosain9)
? 4. Re: Pass ip to server (Joey Officer)
? 5. Re: Filering HTTPS URLs - A complete configuration (Alex Rousskov)
? 6. Re: ssl-bump does not redirect to block page
? ? ? (leomessi983 at yahoo.com)


----------------------------------------------------------------------

Message: 1
Date: Tue, 12 Feb 2019 14:21:34 +0000 (UTC)
From: "leomessi983 at yahoo.com" <leomessi983 at yahoo.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] ssl-bump does not redirect to block page
Message-ID: <1479917107.2282419.1549981294109 at mail.yahoo.com>
Content-Type: text/plain; charset="utf-8"

Hi againDo i have to use CA and Certificate configuration if i want to block only? HTTPS requests with splice action?!


https_port 3130 tproxy ssl-bump \
? cert=/etc/squid/ssl_cert/myCA.pem \
? generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
? sslcrtd_program /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 4MB
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190212/8311d242/attachment-0001.html>

------------------------------

Message: 2
Date: Tue, 12 Feb 2019 08:04:08 -0700
From: Alex Rousskov <rousskov at measurement-factory.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] ssl-bump does not redirect to block page
Message-ID:
??? <024a80a6-6b15-e9d8-06f9-b9645fbb3058 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 2/12/19 7:21 AM, leomessi983 at yahoo.com wrote:

> Do i have to use CA and Certificate configuration if i want to block
> only HTTPS requests with splice action?!

IIRC, you currently need a CA certificate if you want to use SslBump,
regardless of the SslBump actions in use. In some ways, this is a
limitation of the current SslBump implementation rather than a natural
requirement, but the CA certificate is needed when Squid reports an
error to the client because Squid has to bump the client connection to
report errors.

If you do not care what happens when handling errors, then you probably
do not need to configure dynamic certificate generation. I have not
tested that, but I assume that, when reporting errors in that case,
Squid will silently revert to using the old code that generates
self-signed certificates (and the client will not trust them).


Please note that it is not clear what you mean by "to block with splice
action" -- splice does not block anything. If you are blocking requests
using http_access rules, then Squid is probably using an (implicit) bump
action to report blocking to the client, as discussed above. Blocking is
an example of errors that may happen even when you do not explicitly
bump any requests.

Alex.


> https_port 3130 tproxy ssl-bump \
> ? cert=/etc/squid/ssl_cert/myCA.pem \
> ? generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>? sslcrtd_program /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 4MB



------------------------------

Message: 3
Date: Tue, 12 Feb 2019 09:14:45 -0600 (CST)
From: erdosain9 <erdosain9 at gmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Pass ip to server
Message-ID: <1549984485300-0.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

Hi.
I want to know if is possible that, for some site (sales.mydomain.com) the
proxy server send the "real ip".

Because i want to see in the logs of sales.mydomain.com the real ip of the
machine that are going (and not the proxy ip).

I know that i can see this in the log of squid... but, i want to know if it
is possible see this in the other server.

Thanks to all.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


------------------------------

Message: 4
Date: Tue, 12 Feb 2019 16:49:58 +0000
From: Joey Officer <JOfficer at istreamfs.com>
To: erdosain9 <erdosain9 at gmail.com>,
??? "squid-users at lists.squid-cache.org"
??? <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Pass ip to server
Message-ID:
??? <DM5PR19MB1579C05FD36C83FF2D018DF8CD650 at DM5PR19MB1579.namprd19.prod.outlook.com>
??? 
Content-Type: text/plain; charset="utf-8"

I believe the option you are referring to is the 'forwarded_for' http header.

Reference this: http://www.squid-cache.org/Doc/config/forwarded_for/

Hope that helps you.

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of erdosain9
Sent: Tuesday, February 12, 2019 9:15 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Pass ip to server

Hi.
I want to know if is possible that, for some site (sales.mydomain.com) the proxy server send the "real ip".

Because i want to see in the logs of sales.mydomain.com the real ip of the machine that are going (and not the proxy ip).

I know that i can see this in the log of squid... but, i want to know if it is possible see this in the other server.

Thanks to all.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

------------------------------

Message: 5
Date: Tue, 12 Feb 2019 14:48:51 -0700
From: Alex Rousskov <rousskov at measurement-factory.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Filering HTTPS URLs - A complete
??? configuration
Message-ID:
??? <ed3096f0-fff0-2f8b-ddc5-e89cdbf92749 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 2/11/19 3:55 AM, Paul Doignon wrote:

>> The closest you are going to get to the above is with:
>> * bump everything[1], and
>> * use http_access to check the https:// URLs for your policy
>> * use "deny_info TCP_RESET" [2] on the blocked requests.
>>
>> [1] some things literally cannot be bumped. So a decision needs to be
>> made about what to do then.

> I guess adding this second line will terminate those un-bumpable requests?

No, that second ssl_bump line has no effect -- it will never be reached.

You are probably misinterpreting what was meant by "literally cannot be
bumped". What was meant by that phrase was that bumping certain
connections always results in client and/or server errors, regardless of
how you configure Squid. In those cases, Squid will still perform the
bump action if you tell it to bump, but that action will not lead to a
functioning tunnel through Squid.

In general, Squid itself cannot predict which connections can be
successfully bumped. You have to tell it (using ACLs, like the
whitelisted ACL in the example below).


> ssl_bump bump all
> ssl_bump terminate all

The first line emulates client-first bumping. That is not what you want.

To bump all connections, you could use something like this:

? ssl_bump stare all
? ssl_bump bump all

To bump all connections except whitelisted ones, you probably want
something like this:

? ssl_bump splice whitelisted
? ssl_bump stare all
? ssl_bump bump all

... where whitelisted is your ACL implementing your white listing policy
(i.e. matching TLS connections that should be spliced). It may use
ssl::server_name and probably other ACLs.

More details at https://wiki.squid-cache.org/Features/SslPeekAndSplice

Alex.


------------------------------

Message: 6
Date: Wed, 13 Feb 2019 06:22:43 +0000 (UTC)
From: "leomessi983 at yahoo.com" <leomessi983 at yahoo.com>
To: <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] ssl-bump does not redirect to block page
Message-ID: <974828205.84661.1550038963335 at mail.yahoo.com>
Content-Type: text/plain; charset="utf-8"

>> aka the 'bump' action.

> This part is misleading: Modern Squids _automatically_ bump connections
> to report [access denied] errors -- no explicit bump action is required
> (or even desirable). I do not know whether> * that bumping does not happen for leo (e.g., due to Squid bugs), or

> * it does happen, but the browser refuses to show the error page anyway
> .(because of certificate pinning and/or because Squid did not have enough
> information to properly bump the client connection using just step1
> knowledge).

> A packet capture or an ALL,2 cache.log may distinguish those two cases.

> Alex.

Hi Alex
Actually i don't understand if it could be done or not!!
Amos said it is impossible you said no!!
can you show me the correct configuration for blocking HTTPS requests with showing access denied page to clients?!
 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190213/d8a98891/attachment.html>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 54, Issue 24
*******************************************
  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190213/625df369/attachment.htm>

From n.gerasimov at rosenergo.com  Wed Feb 13 12:26:18 2019
From: n.gerasimov at rosenergo.com (=?koi8-r?B?58XSwdPJzc/XIO7Jy8nUwSD30d7F08zB18/Xyd4=?=)
Date: Wed, 13 Feb 2019 12:26:18 +0000
Subject: [squid-users] Problem rtmp traffic through Squid
Message-ID: <7d1819191fed4085a07a22b74d5e83d3@VM-MS-MAILBOX1.rosenergo.com>

Hello! In our organization, we use squid proxy server. And we found a problem with viewing webinars that run on adobe Flash. Network engineers found out that rtmp traffic on port 1935 bypasses the proxy server, which is specified in the browser settings. In this connection, the site does not work media content. The same problem is covered on the Adobe website https://forums.adobe.com/thread/905051
Can you help with providing information on configuring squid to work with adobe Flash?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190213/8a854e4c/attachment.htm>

From squid3 at treenet.co.nz  Wed Feb 13 12:36:39 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Feb 2019 01:36:39 +1300
Subject: [squid-users] ssl-bump does not redirect to block page
In-Reply-To: <227618796.196669.1550059833071@mail.yahoo.com>
References: <227618796.196669.1550059833071.ref@mail.yahoo.com>
 <227618796.196669.1550059833071@mail.yahoo.com>
Message-ID: <8266459e-7a8a-95fc-22f8-4df20f813a77@treenet.co.nz>

On 14/02/19 1:10 am, leomessi983 wrote:
> I use this configuration to solve my problem.
> Whit this configuration at first step I use bump action for sites that i
> want to block and show ACCESS_DENIED page then splice all other requests!!
> My problem in this config is when my clients want to see block pages
> they first see SSL warning in their browser then after click on
> exception they will see ACCESS_DENIED page!!

Welcome to HTTPS - where clients actually tell you if a mystery
third-party is touching your web traffic.

You know, like maybe a proxy answering on a connection that supposedly
went directly to a web server.

There is only one way to avoid these popups and that is to do as all our
documentation should have made you aware already. Install your custom /
self-signed CA into every CA storage location the clients are using.


> ..........
> 
> acl blk ssl::server_name "/var/blkfiles/url.txt"
> 
> http_access  deny blk
> 
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump bump blk
> ssl_bump splice all
> 
> 
> 
> On Wednesday, February 13, 2019, 9:55:06 AM GMT+3:30,
> squid-users-request wrote:
> 
> 
> Send squid-users mailing list submissions to


Please do set your subscription to deliver posts as individual emails
for the time when you are discussion things. Replying to the specific
message your response is about really helps keep threads properly linked
together for those of us using proper email clients and for the systems
presenting our messages in web forum formats.

Please do not quote the digest of an entire day/week/months postings in
your reply emails.

Amos


From Sarfaraz.Ahmad at deshaw.com  Wed Feb 13 12:37:24 2019
From: Sarfaraz.Ahmad at deshaw.com (Ahmad, Sarfaraz)
Date: Wed, 13 Feb 2019 12:37:24 +0000
Subject: [squid-users] Problem rtmp traffic through Squid
In-Reply-To: <7d1819191fed4085a07a22b74d5e83d3@VM-MS-MAILBOX1.rosenergo.com>
References: <7d1819191fed4085a07a22b74d5e83d3@VM-MS-MAILBOX1.rosenergo.com>
Message-ID: <6fde2ab5f9a546749ef46571c2805ea9@deshaw.com>

Did you add them to "safe_ports" acl ? ( assuming you have one )

Look here some more inputs,
http://squid-web-proxy-cache.1019090.n4.nabble.com/squid-conf-blocking-live-video-stream-td4680866.html



From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of ????????? ?????? ????????????
Sent: Wednesday, February 13, 2019 5:56 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Problem rtmp traffic through Squid

Hello! In our organization, we use squid proxy server. And we found a problem with viewing webinars that run on adobe Flash. Network engineers found out that rtmp traffic on port 1935 bypasses the proxy server, which is specified in the browser settings. In this connection, the site does not work media content. The same problem is covered on the Adobe website https://forums.adobe.com/thread/905051
Can you help with providing information on configuring squid to work with adobe Flash?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190213/0bf4c65e/attachment.htm>

From squid3 at treenet.co.nz  Wed Feb 13 13:14:30 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Feb 2019 02:14:30 +1300
Subject: [squid-users] Problem rtmp traffic through Squid
In-Reply-To: <6fde2ab5f9a546749ef46571c2805ea9@deshaw.com>
References: <7d1819191fed4085a07a22b74d5e83d3@VM-MS-MAILBOX1.rosenergo.com>
 <6fde2ab5f9a546749ef46571c2805ea9@deshaw.com>
Message-ID: <fc875f56-cee4-0888-17bd-b0d3eb7ea033@treenet.co.nz>

On 14/02/19 1:37 am, Ahmad, Sarfaraz wrote:
> Did you add them to ?safe_ports? acl ? ( assuming you have one )
> 

Port 1935 is already part of the Safe_ports ACL by default.

What it is not part of is the SSL_Ports ACL which prohibits almost all
ports having CONNECT tunnels opened.

If the Flash agent in use, or its Browser is properly using the proxy
it/they should be attempting to open a CONNECT tunnel to the RTMP server
(possibly port 1935, maybe another) for the stream to flow within.

Check your proxy access.log for these attempts and decide from there
what detail(s) you are going to use to permit access (port, server name,
or UA string, etc).
 Likely you will need to add the relevant port to SSL_Ports (preventing
it being forbidden) and then also add other http_access lines to
restrict which traffic is allowed to contact that port.


> 
> *From:* squid-users *On
> Behalf Of *????????? ?????? ????????????
> *Sent:* Wednesday, February 13, 2019 5:56 PM
> 
> Hello! In our organization, we use squid proxy server. And we found a
> problem with viewing webinars that run on adobe Flash. Network engineers
> found out that rtmp traffic on port 1935 bypasses the proxy server,
> which is specified in the browser settings. In this connection, the site
> does not work media content. The same problem is covered on the Adobe
> website https://forums.adobe.com/thread/905051
> 
> Can you help with providing information on configuring squid to work
> with adobe Flash?
> 


Amos



From Yann.Santschi at hopitalvs.ch  Wed Feb 13 13:19:46 2019
From: Yann.Santschi at hopitalvs.ch (Santschi Yann)
Date: Wed, 13 Feb 2019 13:19:46 +0000
Subject: [squid-users] Compiling with OpenSSL 1.1+
In-Reply-To: <58df29ad-1ffd-a161-0e0b-747293e5617a@treenet.co.nz>
References: <37f66837b1b848faa3bd3c031cddec6f@hopitalvs.ch>,
 <58df29ad-1ffd-a161-0e0b-747293e5617a@treenet.co.nz>
Message-ID: <3188d3f835d54ba0ad6277c7877c171e@hopitalvs.ch>

Many thanks for your help. I could have squid compiled.


Squid was unable to find the OpenSSL installation because I didn't set the "--prefix" flag when I compiled OpenSSL. Once I set it with the same value as "--openssldir" squid compilation worked.


I'm using CentOS 7 and OpenSSL 1.0.2 are installed. It explains why the squid compilation with OpenSSL 1.0.2 worked by "magic" without "--prefix".


Yann

________________________________
De : squid-users <squid-users-bounces at lists.squid-cache.org> de la part de Amos Jeffries <squid3 at treenet.co.nz>
Envoy? : mercredi, 13 f?vrier 2019 12:27:25
? : squid-users at lists.squid-cache.org
Objet : Re: [squid-users] Compiling with OpenSSL 1.1+

On 13/02/19 10:26 pm, Santschi Yann wrote:
> Hello everybody,
>
> I'm trying to compile Squid 4.4 with OpenSSL 1.1.1a and I'm getting
> compilation errors like this one :
>
>
> In file included from ../../src/security/Context.h:15:0,
>                  from ../../src/security/forward.h:13,
>                  from ../../src/SquidConfig.h:21,
>                  from old_api.cc:24:
> ../../compat/openssl.h:121:2: error: #error missing both OpenSSL API
> features EVP_PKEY_up_ref (v1.1) and CRYPTO_LOCK_EVP_PKEY (v1.0)
>  #error missing both OpenSSL API features EVP_PKEY_up_ref (v1.1) and
> CRYPTO_LOCK_EVP_PKEY (v1.0)
>

Squid is not able to find your OpenSSL libcrypto installation. Neither
1.0 nor 1.1 version headers are available to the compiler.

The config.log file generated during the ./configure build stage should
contain hints about why that is. It should really have existed with an
error when detecting the library files, but may not have if you have
some other version of libssl or libcrypto or derivatives such as
libressl installed on the build machine in the usual (FHS) location for
such things.


You have this:

> --with-openssl=/usr/local/ssl-1.1.1a/

So please check that the libssl and libcrypto library and header
includes have been successfully *installed* at that location. Simply
expanding the library source code to there is not installation - this is
a common mistake, it has to actually be built and installed at the path
you are telling the Squid compile system to use.



> If I compile with the deprecated OpenSSL 1.0.2 branch it works but I
> don't want to use this branch. My goal is to offload SSL-Bump with
> hardware that needs OpenSSL 1.1.1.
>
> I'm looking for a solution for a couple of days and I found absolutely
> nothing that helps in Squid documentation, source code and Google.
>
> According to the "CompilingSquid" FAQ it should be feasible with
> Squid-4. Page https://wiki.squid-cache.org/SquidFaq/CompilingSquid says
> following :
>
> However, please note that Squid-3.5
> <https://wiki.squid-cache.org/Squid-3.5> is not compatible with OpenSSL
> v1.1+. As of Debian Squeeze, or Ubuntu Zesty the *libssl1.0-dev* package
> must be used instead. This is resolved in the Squid-4
> <https://wiki.squid-cache.org/Squid-4> packages.
>

Since you are quoting the Debian and Ubuntu statements, are we to assume
that you are using one of those OS?
 If so, why not use the Debian Buster or Ubuntu Cosmic libssl-dev
package which is currently already at v1.1.1 ?


>
> The configure script is run with following parameters :
>
> ./configure LDFLAGS=-ldl --prefix=/usr --includedir=/usr/include
> --datadir=/usr/share --bindir=/usr/sbin --libexecdir=/usr/lib/squid
> -localstatedir=/var --sysconfdir=/etc/squid --with-default-user=squid
> --with-openssl=/usr/local/ssl-1.1.1a/ --enable-ssl --enable-ssl-crtd
> --enable-linux-netfilter --enable-snmp --enable-useragent-log
> --enable-referer-log --enable-cachemgr --enable-truncate
> --enable-underscores --enable-stacktrace --enable-async-io=160
> --enable-poll --enable-icmp --enable-ipfw-transparent
> --enable-forw-via-db --enable-cache-digests --with-included-ltdl
> --enable-ltdl-convenience

If you can spare some time please also run "./configure --help" and
remove the options from the above set which do not exist. At least the
--enable-ssl and log ones are non-existing.


HTH
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190213/a680d7df/attachment.htm>

From squid3 at treenet.co.nz  Wed Feb 13 13:38:57 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Feb 2019 02:38:57 +1300
Subject: [squid-users] Problem rtmp traffic through Squid
In-Reply-To: <678184e4d0db4300a6c204ba8ff4f397@VM-MS-MAILBOX1.rosenergo.com>
References: <7d1819191fed4085a07a22b74d5e83d3@VM-MS-MAILBOX1.rosenergo.com>
 <6fde2ab5f9a546749ef46571c2805ea9@deshaw.com>
 <fc875f56-cee4-0888-17bd-b0d3eb7ea033@treenet.co.nz>
 <678184e4d0db4300a6c204ba8ff4f397@VM-MS-MAILBOX1.rosenergo.com>
Message-ID: <780d8694-43ee-6ec8-05a1-9fe33c39ffad@treenet.co.nz>

On 14/02/19 2:19 am, ????????? ?????? ???????????? wrote:
> Thanks, but a guess we already opened:
> We have settings like this:
> 
> diff squid.conf squid.conf.old
> 40c40
> < acl SSL_ports port 443 563 1935
> ---
>> acl SSL_ports port 443 563
> 
> acl imind_ru_flash port 1935 1936
>   acl imind_ru_webrtc port 10000-30000
>   acl imind_ru_net dst 185.102.121.96/27 185.102.121.0/27
>   acl imind_ru dstdomain .imind.ru
>   http_access allow vlan_202 CONNECT imind_ru_flash imind_ru_net
>   http_access allow vlan_202 CONNECT imind_ru_webrtc imind_ru_net
>   http_access allow vlan_202 myusers imind_ru
> 
>   acl crl url_regex "/etc/squid/crl"
>   http_access allow crl
> 

Okay. That should be letting the tunnels through the proxy *if* the
transactions are attempted.

One trick that sometimes works is firewall rules to forbid direct
Browser access to those ports (aka "bypassing the proxy"). The player
may have CONNECT tunnel support as a fallback option when the usually
more reliable direct service is blocked.

Otherwise, Maybe try a different player software?
 RTMP is a standardized protocol so there are a number of software that
support it. IIRC some had at least basic support for HTTP proxies last
time I looked at these things.


NP: Do not be tempted to intercept the traffic into Squid. The proxy
will either reject the streams completely, or mangle them in ways that
cause annoying display problems worse than a clear failure-to-connect
message.

HTH
Amos


From rousskov at measurement-factory.com  Wed Feb 13 15:08:26 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 13 Feb 2019 08:08:26 -0700
Subject: [squid-users] ssl-bump does not redirect to block page
In-Reply-To: <974828205.84661.1550038963335@mail.yahoo.com>
References: <974828205.84661.1550038963335.ref@mail.yahoo.com>
 <974828205.84661.1550038963335@mail.yahoo.com>
Message-ID: <b5c73d5f-fc2f-6ae1-c54b-2b06e81fc3a8@measurement-factory.com>

On 2/12/19 11:22 PM, leomessi983 at yahoo.com wrote:

> Actually i don't understand if it could be done or not!!

And I do not know what you mean by "it" here.

* Can Squid send a blocking error page to an HTTPS client? Yes.

* Will the browser show that error page to the user without any
additional warnings or questions if you do not install your CA
certificate in the browser? No.

* Does installing your CA certificate in the browser guarantee that the
browser will display the error page without any additional warnings or
questions? No; there are other factors at play here such as certificate
pinning. Installing your CA certificate is necessary but may not be
sufficient in some cases.


> can you show me the correct configuration for blocking HTTPS requests
> with showing access denied page to clients?!

AFAICT, you already have the correct Squid configuration for blocking
HTTPS requests. In fact, your previous email appears to confirm that
your clients are getting the blocking response from Squid!

AFAICT, your current problem is that you want users to see that blocking
response as if it came from the origin server -- without any additional
browser questions or warnings. For that, you have to install your CA
certificate in client browsers (but, again, that may not be sufficient
in some cases).

Alex.


From igoryonya at yahoo.com  Thu Feb 14 09:05:50 2019
From: igoryonya at yahoo.com (Igor Rylov)
Date: Thu, 14 Feb 2019 09:05:50 +0000 (UTC)
Subject: [squid-users] squid delay_pools can't limit speed on certain
	connections
References: <848907109.784103.1550135150221.ref@mail.yahoo.com>
Message-ID: <848907109.784103.1550135150221@mail.yahoo.com>

Squid Cache: Version 3.3.8
I have the following config:

acl ip_band_limit src <ip_addr>
delay_pools 1delay_class 1 1delay_access 1 allow ip_band_limit
delay_access 1 deny all
delay_parameters 1 10240/10240

And it works most of the time, but for some reason, it doesn't work on certain connections, I guess.When I try to download torrents and when I was installing (it is an online installer, i.e. small install launcher starts downloading needed components) Visual Studio Community edition, the bendwidth doesn't get limited, but fills up all available bandwidth.
How can I limit it?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190214/fa1c0076/attachment.htm>

From Sarfaraz.Ahmad at deshaw.com  Thu Feb 14 10:38:57 2019
From: Sarfaraz.Ahmad at deshaw.com (Ahmad, Sarfaraz)
Date: Thu, 14 Feb 2019 10:38:57 +0000
Subject: [squid-users] High response times with Squid
In-Reply-To: <76c45965-061b-ecbc-46a8-b75320bfa71a@treenet.co.nz>
References: <88363c929cbf470a88db5986d24272eb@deshaw.com>
 <76c45965-061b-ecbc-46a8-b75320bfa71a@treenet.co.nz>
Message-ID: <278870b9477d47f4ac746c0995cacb7d@deshaw.com>

Hi again,
I made some progress on this.
To reiterate, I am peeking at the SNI and then bump all connections to the origin server in context of this problem. ( the origin server is seamless.com )

Here are the new findings ,
1) The 20sec lag is noticed even when I splice the connection.
2) It 99% has to do with the following slow ACL acl.

acl deny_explicit_dstdomain dstdomain "/etc/squid/acls/deny_explicit_dstdomain"

I see PTR lookups failing when Squid tries to validate my ACLs. When I disable that ACL, the 20second lag is gone. So I am pretty confident that subsequent PTR lookups are causing the delay here.
I don't see a configuration directive with which I can configure how many times Squid retries the lookup.
I see one that sets the timeout though (dns_timeout  defaults 30 seconds).

Could you guys give me some pointers on what could be happening here ?

Regards,
Ahmad


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Saturday, February 9, 2019 10:20 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] High response times with Squid

On 8/02/19 7:30 pm, Ahmad, Sarfaraz wrote:
> Hi,
> 
> ?
> 
> I am using Squid 4.5 with WCCP. Intercepting SSL by peeking at step1 
> and then deciding to either splice or bump upon the SNI.
> 
> I am noticing a weird behavior for some of my TCP connections. ?Squid 
> is taking over 20s to decide what do with the ClientHello sent by the 
> browser. It is only after 20s that it decides to send out a 
> ClientHello to the origin server and at the same time reply to the 
> client with a ServerHello.
> 
> This behavior is hard to reproduce and only some clients are affected.
> 
> ?
> 
> I will try to summarize what I see in cache.log with ALL, 6 debug options.
> 
> ?
> 
> 1)????? Squid's INTERCEPTION thread/program receives a TCP SYN from 
> workstation.
> 
> 2019/02/06 17:23:19.070 kid1| 89,5| Intercept.cc(405) Lookup: address
> BEGIN: me/client= *<SQUID_IP>:*23129, destination/me=
> *<CLIENT/BROWSER_IP>:*58232
> 

No. This is looking up the original TCP dst-IP:port in the kernel NAT tables.


> ?
> 
> 2)????? Squid becomes the origin server and sets up the TCP connection.
> 

No. The local= log values are a simple statement of the TCP packet values received from the NAT system at (1). Squid is an MITM in this setup, so the client *thinks* it is talking to the origin.

Being an MITM Squid is designed to operate as transparently as possible, but at no time has the abilities of the origin server.


> 2019/02/06 17:23:19.070 kid1| 5,5| AsyncCall.cc(93) ScheduleCall:
> TcpAcceptor.cc(339) will call
> httpsAccept(local*=<ORIGIN_SERVER_ON_THE_INTERNET>*:443
> remote=*<CLIENT/BROWSER_IP>:*58232 FD 40 flags=33, MXID_1101703) 
> [call34733258]
> 

...
> 
> 8)????? No ServerHello has been sent back to the client yet, Squid 
> starts a TCP connection with the origin server
> 
> 2019/02/06 17:23:19.110 kid1| 5,4| AsyncJob.cc(123) callStart:
> Comm::ConnOpener status in: [ job2971439]
> 
> 2019/02/06 17:23:19.110 kid1| 5,5| ConnOpener.cc(350) doConnect:
> local=0.0.0.0 remote*=<ORIGIN_SERVER_ON_THE_INTERNET>:*443 flags=1:
> Comm::OK - connected
> 
> 2019/02/06 17:23:19.110 kid1| 5,4| ConnOpener.cc(155) cleanFd:
> local=0.0.0.0 remote=<*ORIGIN_SERVER_ON_THE_INTERNET*>:443 flags=1 
> closing temp FD 50
> 
> ?
> 
> 9)????? Squid starts a TLS session with the remote/origin server, 
> sends the ClientHello. A total of 0.4 seconds in Squid sending 
> clienthello to origin server. This is probably when Squid decides to 
> send back the ServerHello to the browser.

Don't guess. Check.

Either you have step2 / client-first bumping - in which case the Squid serverHello would have been sent to the client at (7).

Or, you have step3 / server-first bumping - in which case Squid cannot send a serverHello to the client until it has received the origin's serverHello. Which still has not yet been received despite your trace ending here.

...
> 
> 2019/02/06 17:23:19.111 kid1| 83,5| PeerConnector.cc(123) initialize:
> local=*<SQUID_IP>*:44498 remote=*<ORIGIN_SERVER_ON_THE_INTERNET>*:443 
> FD
> 50 flags=1, session=0x14899390
> 
> ?
> 
> So somewhere between Step 8 and Step 9, Squid is taking over 20s.
> 

There is only 1 millisecond between those steps.

The client connection was received at 17:23:19.070, your (9) finished at
17:23:19.111 -> so there is your 0.41 seconds. If there is any 20s gap for this transaction it is later in the log part you have not shown.


> 
> What could possibly be keeping it busy ?
> 

Other transactions? Nothing?

What is going on at (9) is *preparing* to send a TLS clientHello. At the point your log stops it still has not actually been written to the network.

There is actually still a good half of the SSl-Bump process to happen:
 - assemble the Squid clientHello bytes,
 - send that to origin
 - receive origin serverHello
 - validate the origin details
 - HTTP fetch missing certificates (if any)
   - re-validate the origin details (repeat fetch as necessary)
 - formulate the Squid serverHello
 - send that to client
 - receive HTTP request over the secured client connection

... then all the HTTP(S) message processing on the resulting connection.


> 
> UPDATE: This problem statement seems local to a few websites. Outside 
> of the proxy, those websites quite quickly as is expected.
> 
> 
> Any thoughts on where to look ? ?other bits and pieces I could check ?
> ?I have jumbo frames enabled (9000 bytes) but am running the proxies 
> at
> L2 1500 MTU.
> 

It is hard to say without also knowing your squid.conf settings and what sites specifically you are having trouble with,

Could be anything from a packet loss in some remote router halfway around the world. To misconfiguration of something in your network. To misconfiguration by the origin server admin.

IMO that last one is most likely if the behaviour is only delay (not
errors) and with only certain domains.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From qead at list.ru  Thu Feb 14 11:34:08 2019
From: qead at list.ru (jetraw)
Date: Thu, 14 Feb 2019 05:34:08 -0600 (CST)
Subject: [squid-users] Auth and ip access on different ports
Message-ID: <1550144048059-0.post@n4.nabble.com>

Hello guys, i want to make configuration where i'm going user 2 different
ports for different type connection, becouse i have no opportunity to make
the second squid
and i do not want use 2 different process because it will be a problem when
i want to update squid

my configuration is so difficulty becouse in the same network i have PCs
with AD authoriztion and without, don't ask why, it is it

i make test configuration, and this did not work

acl network src 10.20.20.0/24 #just sample of network
acl auth proxy_autx REQUIRED

acl connectport myportname 3128
acl authporth myportname 3130

http_access allow auth !connectport
http_access allow network !authporth 

and if my first line is "http_access allow auth" i have REQUIRED window on
the all PCs without AD, if i set first line "http_access allow network", all
of my domain PCs go to the internet via acl network

can i use one squid port to auth, and secon to ip connection in the same
network?



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Thu Feb 14 16:46:43 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 14 Feb 2019 09:46:43 -0700
Subject: [squid-users] squid delay_pools can't limit speed on certain
 connections
In-Reply-To: <848907109.784103.1550135150221@mail.yahoo.com>
References: <848907109.784103.1550135150221.ref@mail.yahoo.com>
 <848907109.784103.1550135150221@mail.yahoo.com>
Message-ID: <cff06c35-41fe-e5b5-8107-8116cc7d0a3f@measurement-factory.com>

On 2/14/19 2:05 AM, Igor Rylov wrote:
> Squid Cache: Version 3.3.8

> When I try to download torrents and when I was installing (it is an
> online installer, i.e. small install launcher starts downloading needed
> components) Visual Studio Community edition, the bendwidth doesn't get
> limited, but fills up all available bandwidth.

> How can I limit it?

I would start by upgrading to Squid v3.5 or v4. There have been many
changes in delay pools code, including fixes in tunneling code that your
Squid v3.3 may be missing.

Alex.


From rousskov at measurement-factory.com  Thu Feb 14 16:55:52 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 14 Feb 2019 09:55:52 -0700
Subject: [squid-users] Auth and ip access on different ports
In-Reply-To: <1550144048059-0.post@n4.nabble.com>
References: <1550144048059-0.post@n4.nabble.com>
Message-ID: <7cd4e6e7-f95c-f4be-1ca3-ebc98d70ee45@measurement-factory.com>

On 2/14/19 4:34 AM, jetraw wrote:
> Hello guys, i want to make configuration where i'm going user 2 different
> ports for different type connection

> acl network src 10.20.20.0/24 #just sample of network
> acl auth proxy_autx REQUIRED
> 
> acl connectport myportname 3128
> acl authporth myportname 3130
> 
> http_access allow auth !connectport
> http_access allow network !authporth 
> 
> and if my first line is "http_access allow auth" i have REQUIRED window on
> the all PCs without AD, if i set first line "http_access allow network", all
> of my domain PCs go to the internet via acl network
> 
> can i use one squid port to auth, and secon to ip connection in the same
> network?

Yes, you can. Put your port-filtering ACLs first so that Squid does not
evaluate the authentication ACL when it does not have to. Evaluation of
an authentication ACL leads to authentication.

Here is a sketch:

  # For authporth, allow authenticated traffic only.
  http_access allow authporth auth
  http_access deny authporth

  # If you only have two ports, then you know you are dealing with
  # the second port here, so there is no need for explicit connectport.
  http_access allow network
  http_access deny all
 Needless to say, you need more http_access rules to block various bad
requests. See squid.conf.default for details.

Alex.


From squid3 at treenet.co.nz  Fri Feb 15 03:53:50 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 15 Feb 2019 16:53:50 +1300
Subject: [squid-users] High response times with Squid
In-Reply-To: <278870b9477d47f4ac746c0995cacb7d@deshaw.com>
References: <88363c929cbf470a88db5986d24272eb@deshaw.com>
 <76c45965-061b-ecbc-46a8-b75320bfa71a@treenet.co.nz>
 <278870b9477d47f4ac746c0995cacb7d@deshaw.com>
Message-ID: <dcad10c2-614e-7a21-cb2a-f1b7f66520a1@treenet.co.nz>

On 14/02/19 11:38 pm, Ahmad, Sarfaraz wrote:
> Hi again,
> I made some progress on this.
> To reiterate, I am peeking at the SNI and then bump all connections to the origin server in context of this problem. ( the origin server is seamless.com )
> 
> Here are the new findings ,
> 1) The 20sec lag is noticed even when I splice the connection.
> 2) It 99% has to do with the following slow ACL acl.
> 
> acl deny_explicit_dstdomain dstdomain "/etc/squid/acls/deny_explicit_dstdomain"
> 
> I see PTR lookups failing when Squid tries to validate my ACLs. When I disable that ACL, the 20second lag is gone. So I am pretty confident that subsequent PTR lookups are causing the delay here.
> I don't see a configuration directive with which I can configure how many times Squid retries the lookup.
> I see one that sets the timeout though (dns_timeout  defaults 30 seconds).
> 
> Could you guys give me some pointers on what could be happening here ?

Only repeat back to you what you have described to us ... DNS PTR
lookups are slow.

Your squid.conf is needed to know where those lookups are happening and
see if any can be avoided.

Amos


From qead at list.ru  Fri Feb 15 06:27:44 2019
From: qead at list.ru (jetraw)
Date: Fri, 15 Feb 2019 00:27:44 -0600 (CST)
Subject: [squid-users] Auth and ip access on different ports
In-Reply-To: <7cd4e6e7-f95c-f4be-1ca3-ebc98d70ee45@measurement-factory.com>
References: <1550144048059-0.post@n4.nabble.com>
 <7cd4e6e7-f95c-f4be-1ca3-ebc98d70ee45@measurement-factory.com>
Message-ID: <1550212064714-0.post@n4.nabble.com>

Thank you, i configured like this, and it works:

http_port 3128 name=1
http_port 3130 name=2

acl connectport myportname 1
acl authport myportname 2

http_access allow localnet !connectport
http_access allo auth

http_access deny all

and now i'm going to test this line "http_access allow authporth auth"
My issue is soloved



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From Sarfaraz.Ahmad at deshaw.com  Fri Feb 15 07:08:07 2019
From: Sarfaraz.Ahmad at deshaw.com (Ahmad, Sarfaraz)
Date: Fri, 15 Feb 2019 07:08:07 +0000
Subject: [squid-users] High response times with Squid
In-Reply-To: <dcad10c2-614e-7a21-cb2a-f1b7f66520a1@treenet.co.nz>
References: <88363c929cbf470a88db5986d24272eb@deshaw.com>
 <76c45965-061b-ecbc-46a8-b75320bfa71a@treenet.co.nz>
 <278870b9477d47f4ac746c0995cacb7d@deshaw.com>
 <dcad10c2-614e-7a21-cb2a-f1b7f66520a1@treenet.co.nz>
Message-ID: <e4e1a6ddef0941edbd89094a5eed5829@deshaw.com>

Thanks for all the pointers :) I figured it out. Seamless.com's PTR lookups are slow and end up in SERVFAIL. 
And that was causing the delay here. I purged that ACL and it's all good.


-----Original Message-----
From: Amos Jeffries <squid3 at treenet.co.nz> 
Sent: Friday, February 15, 2019 9:24 AM
To: Ahmad, Sarfaraz <Sarfaraz.Ahmad at deshaw.com>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] High response times with Squid

On 14/02/19 11:38 pm, Ahmad, Sarfaraz wrote:
> Hi again,
> I made some progress on this.
> To reiterate, I am peeking at the SNI and then bump all connections to 
> the origin server in context of this problem. ( the origin server is 
> seamless.com )
> 
> Here are the new findings ,
> 1) The 20sec lag is noticed even when I splice the connection.
> 2) It 99% has to do with the following slow ACL acl.
> 
> acl deny_explicit_dstdomain dstdomain "/etc/squid/acls/deny_explicit_dstdomain"
> 
> I see PTR lookups failing when Squid tries to validate my ACLs. When I disable that ACL, the 20second lag is gone. So I am pretty confident that subsequent PTR lookups are causing the delay here.
> I don't see a configuration directive with which I can configure how many times Squid retries the lookup.
> I see one that sets the timeout though (dns_timeout  defaults 30 seconds).
> 
> Could you guys give me some pointers on what could be happening here ?

Only repeat back to you what you have described to us ... DNS PTR lookups are slow.

Your squid.conf is needed to know where those lookups are happening and see if any can be avoided.

Amos

From walid.shaari at linux.com  Sat Feb 16 08:18:17 2019
From: walid.shaari at linux.com (Walid A. Shaari)
Date: Sat, 16 Feb 2019 11:18:17 +0300
Subject: [squid-users] Questions around https transparent chained proxy
Message-ID: <CAN4dctoye3PHcvqmJeyBrfiEY6Lg44Jeih3gQeTctCUyby-tHA@mail.gmail.com>

Greetings,

The end goal is enforcing an appliance(s) tls traffic to go through
the corporate proxy, as I understand it (splice, not interested in
decrypting)

http traffic works fine. however not clear 100% regarding https traffic.

1) does the order of the below directives (ssl_bump, never_direct, and
cacher_peer,..etc) matter where it is in the squid.conf file, or is it
just the ACLs and ssl_bump that are order strict in squid.conf?

------ partial squid.conf  # is that order ok----
ssl_bump peek all     # or should I just peek at step1
ssl_bump splice  all
#ssl_bump bump all   # not necessary in that case, traffic should have
been already spliced
never_direct allow all

cache_peer  upstream-proxy parent 8118 0 no-query no-digest
---------------------------

2) What does the only-proxy option really means for cache-peer?
3) if the parent proxy is not using SSL/tls, however, the clients are
using tls/SSL, is that an issue?
4) in an https transparent chained proxy scenario, is there a way I
can get rid of exporting the squid proxy certificates to the clients?
as the clients are part of an appliance that I do not have control
over and not all traffic is actually originating from browsers?
5)  Is squid 3.5 out of the Linux distro good enough, or should I
upgrade to latest 4.x for a guaranteed splice functionality? the
unofficial binary package for RHEL available is 3.5.27, while centos
package is 4.5-1. shouldn't both be the same?

TIA

Walid



ReplyForward


From squid3 at treenet.co.nz  Sat Feb 16 14:02:03 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 17 Feb 2019 03:02:03 +1300
Subject: [squid-users] Questions around https transparent chained proxy
In-Reply-To: <CAN4dctoye3PHcvqmJeyBrfiEY6Lg44Jeih3gQeTctCUyby-tHA@mail.gmail.com>
References: <CAN4dctoye3PHcvqmJeyBrfiEY6Lg44Jeih3gQeTctCUyby-tHA@mail.gmail.com>
Message-ID: <e46088d2-160a-7a59-8522-8d0cba96d233@treenet.co.nz>

On 16/02/19 9:18 pm, Walid A. Shaari wrote:
> Greetings,
> 
> The end goal is enforcing an appliance(s) tls traffic to go through
> the corporate proxy, as I understand it (splice, not interested in
> decrypting)
> 
> http traffic works fine. however not clear 100% regarding https traffic.
> 
> 1) does the order of the below directives (ssl_bump, never_direct, and
> cacher_peer,..etc) matter where it is in the squid.conf file, or is it
> just the ACLs and ssl_bump that are order strict in squid.conf?

The order of these directives does not matter. They are for different
"hook" / decision points in the transaction.

Lines with the same directive name are order dependent. They are
inspected in the exact order configured.


> 
> ------ partial squid.conf  # is that order ok----
> ssl_bump peek all     # or should I just peek at step1
> ssl_bump splice  all
> #ssl_bump bump all   # not necessary in that case, traffic should have
> been already spliced
> never_direct allow all
> 
> cache_peer  upstream-proxy parent 8118 0 no-query no-digest
> ---------------------------
> 
> 2) What does the only-proxy option really means for cache-peer?

Responses received from that peer can only be proxied, not cached.


> 3) if the parent proxy is not using SSL/tls, however, the clients are
> using tls/SSL, is that an issue?

Maybe. Traffic which arrive encrypted must leave encrypted.

If you apply "bump" action to a TLS connection, the resulting https://
URL requests received on that connection cannot go to an insecure peer.

If you are only splicing, then the CONNECT _can_ go to these peers.
Since the traffic is still in its original encrypted form.


> 4) in an https transparent chained proxy scenario, is there a way I
> can get rid of exporting the squid proxy certificates to the clients?

You can choose not to do it.

If you are splicing, Squid should take no part in the crypto. Therefore
no X.509 cert generated by Squid will be delivered and the client has no
need of the custom CA to verify a non-existent cert.

If bumping ever occurs (eg to deliver an error message about TLS
failure). Then TLS clients will display warnings and popups about
inability to trust the server.

It is up to you whether that error handling case is important enough to
care.


> as the clients are part of an appliance that I do not have control
> over and not all traffic is actually originating from browsers?

Being a Browser is irrelevant. All TLS clients have this behaviour. Not
to do so is a violation of TLS security requirements (aka. insecure).


> 5)  Is squid 3.5 out of the Linux distro good enough, or should I
> upgrade to latest 4.x for a guaranteed splice functionality?


TLS environment is quite volatile, and Squid is constantly being updated
to cope with that and fix issues found in the implementation. Some major
changes cannot be backported without risking instability in 'stable'
series. Most small changes are not backported as a matter of policy.

An older version may be 'good enough' but for sure the latest release
will have less annoyances.


> the
> unofficial binary package for RHEL available is 3.5.27, while centos
> package is 4.5-1. shouldn't both be the same?


Eliezer does a fair bit of extra testing on his packages and they may
not all get updated at once. (I'm fairly sure he is open to funding if
you wish to sponsor any particular work.)


Amos


From eliezer at ngtech.co.il  Sat Feb 16 20:03:02 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Sat, 16 Feb 2019 22:03:02 +0200
Subject: [squid-users] High response times with Squid
In-Reply-To: <278870b9477d47f4ac746c0995cacb7d@deshaw.com>
References: <88363c929cbf470a88db5986d24272eb@deshaw.com>
 <76c45965-061b-ecbc-46a8-b75320bfa71a@treenet.co.nz>
 <278870b9477d47f4ac746c0995cacb7d@deshaw.com>
Message-ID: <008b01d4c632$9f9c92d0$ded5b870$@ngtech.co.il>

You can replace them with dstdom_regex which will not trigger a PTR lookup.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Ahmad, Sarfaraz
Sent: Thursday, February 14, 2019 12:39
To: Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] High response times with Squid

Hi again,
I made some progress on this.
To reiterate, I am peeking at the SNI and then bump all connections to the origin server in context of this problem. ( the origin server is seamless.com )

Here are the new findings ,
1) The 20sec lag is noticed even when I splice the connection.
2) It 99% has to do with the following slow ACL acl.

acl deny_explicit_dstdomain dstdomain "/etc/squid/acls/deny_explicit_dstdomain"

I see PTR lookups failing when Squid tries to validate my ACLs. When I disable that ACL, the 20second lag is gone. So I am pretty confident that subsequent PTR lookups are causing the delay here.
I don't see a configuration directive with which I can configure how many times Squid retries the lookup.
I see one that sets the timeout though (dns_timeout  defaults 30 seconds).

Could you guys give me some pointers on what could be happening here ?

Regards,
Ahmad


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Saturday, February 9, 2019 10:20 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] High response times with Squid

On 8/02/19 7:30 pm, Ahmad, Sarfaraz wrote:
> Hi,
> 
>  
> 
> I am using Squid 4.5 with WCCP. Intercepting SSL by peeking at step1 
> and then deciding to either splice or bump upon the SNI.
> 
> I am noticing a weird behavior for some of my TCP connections.  Squid 
> is taking over 20s to decide what do with the ClientHello sent by the 
> browser. It is only after 20s that it decides to send out a 
> ClientHello to the origin server and at the same time reply to the 
> client with a ServerHello.
> 
> This behavior is hard to reproduce and only some clients are affected.
> 
>  
> 
> I will try to summarize what I see in cache.log with ALL, 6 debug options.
> 
>  
> 
> 1)      Squid's INTERCEPTION thread/program receives a TCP SYN from 
> workstation.
> 
> 2019/02/06 17:23:19.070 kid1| 89,5| Intercept.cc(405) Lookup: address
> BEGIN: me/client= *<SQUID_IP>:*23129, destination/me=
> *<CLIENT/BROWSER_IP>:*58232
> 

No. This is looking up the original TCP dst-IP:port in the kernel NAT tables.


>  
> 
> 2)      Squid becomes the origin server and sets up the TCP connection.
> 

No. The local= log values are a simple statement of the TCP packet values received from the NAT system at (1). Squid is an MITM in this setup, so the client *thinks* it is talking to the origin.

Being an MITM Squid is designed to operate as transparently as possible, but at no time has the abilities of the origin server.


> 2019/02/06 17:23:19.070 kid1| 5,5| AsyncCall.cc(93) ScheduleCall:
> TcpAcceptor.cc(339) will call
> httpsAccept(local*=<ORIGIN_SERVER_ON_THE_INTERNET>*:443
> remote=*<CLIENT/BROWSER_IP>:*58232 FD 40 flags=33, MXID_1101703) 
> [call34733258]
> 

...
> 
> 8)      No ServerHello has been sent back to the client yet, Squid 
> starts a TCP connection with the origin server
> 
> 2019/02/06 17:23:19.110 kid1| 5,4| AsyncJob.cc(123) callStart:
> Comm::ConnOpener status in: [ job2971439]
> 
> 2019/02/06 17:23:19.110 kid1| 5,5| ConnOpener.cc(350) doConnect:
> local=0.0.0.0 remote*=<ORIGIN_SERVER_ON_THE_INTERNET>:*443 flags=1:
> Comm::OK - connected
> 
> 2019/02/06 17:23:19.110 kid1| 5,4| ConnOpener.cc(155) cleanFd:
> local=0.0.0.0 remote=<*ORIGIN_SERVER_ON_THE_INTERNET*>:443 flags=1 
> closing temp FD 50
> 
>  
> 
> 9)      Squid starts a TLS session with the remote/origin server, 
> sends the ClientHello. A total of 0.4 seconds in Squid sending 
> clienthello to origin server. This is probably when Squid decides to 
> send back the ServerHello to the browser.

Don't guess. Check.

Either you have step2 / client-first bumping - in which case the Squid serverHello would have been sent to the client at (7).

Or, you have step3 / server-first bumping - in which case Squid cannot send a serverHello to the client until it has received the origin's serverHello. Which still has not yet been received despite your trace ending here.

...
> 
> 2019/02/06 17:23:19.111 kid1| 83,5| PeerConnector.cc(123) initialize:
> local=*<SQUID_IP>*:44498 remote=*<ORIGIN_SERVER_ON_THE_INTERNET>*:443 
> FD
> 50 flags=1, session=0x14899390
> 
>  
> 
> So somewhere between Step 8 and Step 9, Squid is taking over 20s.
> 

There is only 1 millisecond between those steps.

The client connection was received at 17:23:19.070, your (9) finished at
17:23:19.111 -> so there is your 0.41 seconds. If there is any 20s gap for this transaction it is later in the log part you have not shown.


> 
> What could possibly be keeping it busy ?
> 

Other transactions? Nothing?

What is going on at (9) is *preparing* to send a TLS clientHello. At the point your log stops it still has not actually been written to the network.

There is actually still a good half of the SSl-Bump process to happen:
 - assemble the Squid clientHello bytes,
 - send that to origin
 - receive origin serverHello
 - validate the origin details
 - HTTP fetch missing certificates (if any)
   - re-validate the origin details (repeat fetch as necessary)
 - formulate the Squid serverHello
 - send that to client
 - receive HTTP request over the secured client connection

... then all the HTTP(S) message processing on the resulting connection.


> 
> UPDATE: This problem statement seems local to a few websites. Outside 
> of the proxy, those websites quite quickly as is expected.
> 
> 
> Any thoughts on where to look ?  other bits and pieces I could check ?
>  I have jumbo frames enabled (9000 bytes) but am running the proxies 
> at
> L2 1500 MTU.
> 

It is hard to say without also knowing your squid.conf settings and what sites specifically you are having trouble with,

Could be anything from a packet loss in some remote router halfway around the world. To misconfiguration of something in your network. To misconfiguration by the origin server admin.

IMO that last one is most likely if the behaviour is only delay (not
errors) and with only certain domains.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Mon Feb 18 06:29:00 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 18 Feb 2019 19:29:00 +1300
Subject: [squid-users] Questions around https transparent chained proxy
In-Reply-To: <CAN4dctobEOAENnHG9ZJOb5jm5qJpYO8h_C2tTs6fuSAiwc7vuA@mail.gmail.com>
References: <CAN4dctoye3PHcvqmJeyBrfiEY6Lg44Jeih3gQeTctCUyby-tHA@mail.gmail.com>
 <e46088d2-160a-7a59-8522-8d0cba96d233@treenet.co.nz>
 <CAN4dctobEOAENnHG9ZJOb5jm5qJpYO8h_C2tTs6fuSAiwc7vuA@mail.gmail.com>
Message-ID: <19703ccc-5ee4-d220-d1e6-20f27eba90ca@treenet.co.nz>

On 18/02/19 5:04 pm, Walid A. Shaari wrote:
> Thank you again, Amos,
> 
> On Sat, 16 Feb 2019 at 17:09, Amos Jeffries wrote:
>>
>> On 16/02/19 9:18 pm, Walid A. Shaari wrote:
>>> Greetings,
>>>
>>> The end goal is enforcing an appliance(s) tls traffic to go through
>>> the corporate proxy, as I understand it (splice, not interested in
>>> decrypting)
> .... ... ...
> ------ partial squid.conf  # is that order ok----
> never_direct allow all
> ssl_bump peek all     # or should I just peek at step1
> ssl_bump splice  all

To perform a peek at step 2 needs the destination server (or peer)
connection to be using TLS/SSL.  Since you are wanting traffic to go
through a peer without TLS/SSL you will likely need to splice at step 2.

So to the question on the peek line. Yes, probably should.


> ssl_bump none all
> 

"none" action is from an old deprecated SSL-Bump design. It only has
meaning at step 1 and is equivalent to "splice" in that step.

At best it will be ignored, at worst will cause unpredictable splice or
bump operations on a per-transaction basis.

Given the environment you described earlier I suggest "terminate all" as
the fallback action if splice turns out not to be possible.



> cache_peer  upstream-proxy parent 8118 0 no-query no-digest only-proxy

Ah, apologies I thought you had just typo'd the question earlier.

The option name is actually "proxy-only".


> http_port 8080    intercept # transparent http

NP: the comment on the line above is slightly confusing.

"intercept" is for NAT interception.

"Transparent HTTP" is an entirely different thing. Which Squid does
regardless of what settings you use.


> https_port 8090 intercept ssl-bump generate-host-certificates=off
> cert=/etc/squid/ssl_certs/myCA.pem
> cafile=/etc/pki/ca-trust/source/anchors/ca.crt
> http_port 8100    #forward port
> ---- end of partial conf
> 
> Question,  What if I use 'ssl_bump none all' instead of ssl_bump
> splice all?, wouldn't I get rid for any client configuration at the
> same time https traffic will pass through to the parent proxy?

It will have no effect beyond possibly throwing up warnings in your
cache.log when mixed with peek action.


Amos


From numsys at free.fr  Tue Feb 19 08:40:19 2019
From: numsys at free.fr (FredB)
Date: Tue, 19 Feb 2019 09:40:19 +0100
Subject: [squid-users] ICAP and 403 Encapsulated answers (SSL denied
 domains)
In-Reply-To: <b877c1a4-094d-1f43-904b-1e2d7a6deaff@free.fr>
References: <0d99f322-62a8-9b7a-86cc-d0894b9a5537@free.fr>
 <8cfb73a6-6cbb-4907-f304-a43487ae3856@measurement-factory.com>
 <cc051bb8-e180-1be8-51b3-b0653c6ae2cf@free.fr>
 <6b798ccd-8653-4106-30a7-d576e4166156@measurement-factory.com>
 <b877c1a4-094d-1f43-904b-1e2d7a6deaff@free.fr>
Message-ID: <e120d750-e196-1949-fd4b-b239d7d44ae4@free.fr>

Amos, Alex

Ithought you might beinterested, there was a bug in Firefox with huge 
impact for some configurations

https://bugzilla.mozilla.org/show_bug.cgi?id=1522093


Regards

Fredb


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190219/fa13e96b/attachment.htm>

From rousskov at measurement-factory.com  Tue Feb 19 15:25:09 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 19 Feb 2019 08:25:09 -0700
Subject: [squid-users] ICAP and 403 Encapsulated answers (SSL denied
 domains)
In-Reply-To: <e120d750-e196-1949-fd4b-b239d7d44ae4@free.fr>
References: <0d99f322-62a8-9b7a-86cc-d0894b9a5537@free.fr>
 <8cfb73a6-6cbb-4907-f304-a43487ae3856@measurement-factory.com>
 <cc051bb8-e180-1be8-51b3-b0653c6ae2cf@free.fr>
 <6b798ccd-8653-4106-30a7-d576e4166156@measurement-factory.com>
 <b877c1a4-094d-1f43-904b-1e2d7a6deaff@free.fr>
 <e120d750-e196-1949-fd4b-b239d7d44ae4@free.fr>
Message-ID: <7ad1a209-0420-d437-6df3-a8cc4ee48663@measurement-factory.com>

On 2/19/19 1:40 AM, FredB wrote:
> there was a bug in Firefox with huge impact for some configurations 
> https://bugzilla.mozilla.org/show_bug.cgi?id=1522093

Congratulations on getting that Firefox bug fixed!

Alex.


From chip_pop at hotmail.com  Wed Feb 20 00:19:46 2019
From: chip_pop at hotmail.com (joseph)
Date: Tue, 19 Feb 2019 18:19:46 -0600 (CST)
Subject: [squid-users] squid -N
Message-ID: <1550621986825-0.post@n4.nabble.com>

i have
cache_effective_user proxy
cache_effective_group proxy
wen i use squid without -N group and owner ar both proxy for swap.state
wen i use squid -N swap.state group stay proxy but owner change to root
and it give access deny
is this bug ??




-----
************************** 
***** Crash to the future  ****
**************************
--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Wed Feb 20 00:49:53 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 19 Feb 2019 17:49:53 -0700
Subject: [squid-users] squid -N
In-Reply-To: <1550621986825-0.post@n4.nabble.com>
References: <1550621986825-0.post@n4.nabble.com>
Message-ID: <fffc71cc-3d0a-4eb0-c540-a51b2c833b90@measurement-factory.com>

On 2/19/19 5:19 PM, joseph wrote:
> i have
> cache_effective_user proxy
> cache_effective_group proxy
> wen i use squid without -N group and owner ar both proxy for swap.state
> wen i use squid -N swap.state group stay proxy but owner change to root
> and it give access deny
> is this bug ??

Yes, it sounds like a bug to me. Does this problem affect cache.log,
access.log, or store.log as well? I have not tested with UFS, but the
ownership for those other three logs looks correct in my -N tests.

Alex.


From chip_pop at hotmail.com  Wed Feb 20 09:26:13 2019
From: chip_pop at hotmail.com (joseph)
Date: Wed, 20 Feb 2019 03:26:13 -0600 (CST)
Subject: [squid-users] squid -N
In-Reply-To: <fffc71cc-3d0a-4eb0-c540-a51b2c833b90@measurement-factory.com>
References: <1550621986825-0.post@n4.nabble.com>
 <fffc71cc-3d0a-4eb0-c540-a51b2c833b90@measurement-factory.com>
Message-ID: <1550654773153-0.post@n4.nabble.com>

so fare swap.state affected 




-----
************************** 
***** Crash to the future  ****
**************************
--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From augustus_meyer at gmx.net  Wed Feb 20 11:46:10 2019
From: augustus_meyer at gmx.net (reinerotto)
Date: Wed, 20 Feb 2019 05:46:10 -0600 (CST)
Subject: [squid-users] squid delay_pools can't limit speed on certain
	connections
In-Reply-To: <cff06c35-41fe-e5b5-8107-8116cc7d0a3f@measurement-factory.com>
References: <848907109.784103.1550135150221@mail.yahoo.com>
 <cff06c35-41fe-e5b5-8107-8116cc7d0a3f@measurement-factory.com>
Message-ID: <1550663170426-0.post@n4.nabble.com>

I also have a problem with delay_pools on 4.4. Download speed is not
throttled. Easily to be verified when watching video from youtube, using
'statistics for nerds'.

I do not remember having this effect on 3.5

This squid runs on up-to-date openwrt device,
having limited resources.

I am happy to provide further info, in case I get
instructions for debug_options

My squid.conf:

acl localnet src 10.1.0.0/24
acl localnet src 172.16.0.0/24
acl localnet src 192.168.1.0/24
acl localnet src 192.168.2.0/24
acl ssl_ports port 443
acl safe_ports port 80
acl safe_ports port 443
acl safe_ports port 3128
acl connect method connect
http_access deny !safe_ports
http_access deny connect !ssl_ports
http_access allow localhost manager
http_access allow localnet manager
http_access deny manager
cachemgr_passwd xxxxxxxx all
acl denybin urlpath_regex \.bin
cache deny denybin
acl test_chrome_compression url_regex ^http://check.googlezip.net/connect
http_access deny test_chrome_compression
acl block_google_proxy req_header Chrome-Proxy .*
http_access deny  block_google_proxy
http_access allow localnet
http_access allow localhost
http_access deny all
reload_into_ims on
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 10080 90% 43200 override-expire
ignore-no-cache ignore-no-store ignore-private
refresh_pattern -i \.(iso|avi|wav|mp3|mp4|mpeg|swf|flv|x-flv)$ 43200 90%
432000 override-expire ignore-no-cache ignore-no-store ignore-private
refresh_pattern -i \.(deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff)$
10080 90% 43200 override-expire ignore-no-cache ignore-no-store
ignore-private
refresh_pattern -i \.index.(html|htm)$ 0 40% 10080
refresh_pattern -i \.(html|htm|css|js)$ 1440 40% 40320
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320
access_log none
cache_log /mnt/sda1/log/squid/cache.log
cache_store_log stdio:/dev/null
logfile_rotate 1
logfile_daemon /dev/null
http_port 3128
http_port 8888 intercept
https_port 3127  intercept ssl-bump cert=/etc/squid/ssl_cert/myCA.pem \
  generate-host-certificates=off
acl step1 at_step SslBump1
ssl_bump peek step1 all
ssl_bump splice all
cache_mem 8 MB
shutdown_lifetime 10 seconds
httpd_suppress_version_string on
dns_v4_first on
forwarded_for delete
pipeline_prefetch 2
via off
maximum_object_size_in_memory 128 KB
maximum_object_size 4 MB
reply_header_access Cache deny all
client_idle_pconn_timeout 1 minute
server_idle_pconn_timeout 5 minute
read_timeout 2 minute
ipcache_size 512
fqdncache_size 256
reply_header_access Alternate-Protocol deny all
reply_header_access alternate-protocol deny all
reply_header_access alt-svc deny all
pinger_enable off
digest_generation off
netdb_filename none
cache_dir ufs /mnt/sda1/cache 250 16 256
acl only512kusers src 10.1.0.0/24
delay_pools 1
delay_class 1 3
delay_access 1 allow only512kusers
delay_access 1 deny all
delay_parameters 1 -1/-1 -1/-1 64000/64000





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From walid.shaari at linux.com  Wed Feb 20 15:33:33 2019
From: walid.shaari at linux.com (Walid A. Shaari)
Date: Wed, 20 Feb 2019 18:33:33 +0300
Subject: [squid-users] Questions around https transparent chained proxy
In-Reply-To: <19703ccc-5ee4-d220-d1e6-20f27eba90ca@treenet.co.nz>
References: <CAN4dctoye3PHcvqmJeyBrfiEY6Lg44Jeih3gQeTctCUyby-tHA@mail.gmail.com>
 <e46088d2-160a-7a59-8522-8d0cba96d233@treenet.co.nz>
 <CAN4dctobEOAENnHG9ZJOb5jm5qJpYO8h_C2tTs6fuSAiwc7vuA@mail.gmail.com>
 <19703ccc-5ee4-d220-d1e6-20f27eba90ca@treenet.co.nz>
Message-ID: <CAN4dcto9VBh45o268CzpAUMdedQ4u2Ue9ZR0d84-cJ1WA+-DOA@mail.gmail.com>

On Mon, 18 Feb 2019 at 09:29, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> >> On 16/02/19 9:18 pm, Walid A. Shaari wrote:
> >>> Greetings,
> >>>
> >>> The end goal is enforcing an appliance(s) tls traffic to go through
> >>> the corporate proxy, as I understand it (splice, not interested in
> >>> decrypting)
> > .... ... ...
> > ------ partial squid.conf  # is that order ok----
> > never_direct allow all
> > ssl_bump peek all     # or should I just peek at step1
> > ssl_bump splice  all
>
> To perform a peek at step 2 needs the destination server (or peer)
> connection to be using TLS/SSL.  Since you are wanting traffic to go
> through a peer without TLS/SSL you will likely need to splice at step 2.
>
> So to the question on the peek line. Yes, probably should.

when I enable peek at step 2, squid does not last for over 2-5
minutes, crashes, went back to step 1, and will check if release
upgrade to 4.x latest solves the crashing issue.


> > cache_peer  upstream-proxy parent 8118 0 no-query no-digest only-proxy
>
> Ah, apologies I thought you had just typo'd the question earlier.
>
> The option name is actually "proxy-only".

so If I am doing splice, does proxy-only make any sense, or I should
remove it as there is also http trafic?

Thanks in advance ;-)

Walid


From dvanorder at deloitte.com  Thu Feb 21 05:23:25 2019
From: dvanorder at deloitte.com (Van Order, Drew (US - Hermitage))
Date: Thu, 21 Feb 2019 05:23:25 +0000
Subject: [squid-users] Squid for Windows Repeatedly Crashing
Message-ID: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>

Hello folks, we're running Squid 3.5.28 on four Windows 2016 VM's, each has 4 CPU, 8 GB memory, 10 GB NIC. We implemented Squid to support forwarding Azure Log Analytics data, it's all CONNECT. The Squids are load balanced through a F5. There are less than 1,000 servers sending data to Log Analytics.

All four Squids are regularly crashing, and I don't know how to interpret the errors in cache.log. It crashes if we disable caching too.

Any insight is appreciated-I've inherited this responsibility and more a cloud engineer than a network specialist.

Thanks in advance!

Typical error sequence in cache.log

2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:33 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:33 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:33 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:33 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:33 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 1
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 2
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 3
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 4
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 5
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 6
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 7
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 8
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 9
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 10
2019/02/20 09:42:33 kid1| Closing HTTP port 10.5.11.12:3128
FATAL: Event loop exited with failure.
Squid Cache (Version 3.5.28): Terminated abnormally.
CPU Usage: 12.640 seconds = 4.234 user + 8.406 sys
Maximum Resident Size: 5159680 KB
Page faults with physical i/o: 20341

Squid restarts, and will often start erroring right away:

2019/02/20 09:42:33 kid1| storeDirWriteCleanLogs: Starting...
2019/02/20 09:42:33 kid1|   Finished.  Wrote 0 entries.
2019/02/20 09:42:33 kid1|   Took 0.00 seconds (  0.00 entries/sec).
2019/02/20 09:42:36 kid1| Set Current Directory to /cygdrive/e/squid/var/coredump
2019/02/20 09:42:36 kid1| Starting Squid Cache version 3.5.28 for x86_64-unknown-cygwin...
2019/02/20 09:42:36 kid1| Service Name: squid
2019/02/20 09:42:36 kid1| Process ID 2292
2019/02/20 09:42:36 kid1| Process Roles: worker
2019/02/20 09:42:36 kid1| With 3200 file descriptors available
2019/02/20 09:42:36 kid1| Initializing IP Cache...
2019/02/20 09:42:36 kid1| parseEtcHosts: /etc/hosts: (2) No such file or directory
2019/02/20 09:42:36 kid1| DNS Socket created at [::], FD 5
2019/02/20 09:42:36 kid1| DNS Socket created at 0.0.0.0, FD 6
2019/02/20 09:42:36 kid1| Adding nameserver 208.67.220.220 from squid.conf
2019/02/20 09:42:36 kid1| Adding nameserver 208.67.222.222 from squid.conf
2019/02/20 09:42:36 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2019/02/20 09:42:36 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2019/02/20 09:42:36 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2019/02/20 09:42:36 kid1| Store logging disabled
2019/02/20 09:42:36 kid1| Swap maxSize 262144 + 262144 KB, estimated 40329 objects
2019/02/20 09:42:36 kid1| Target number of buckets: 2016
2019/02/20 09:42:36 kid1| Using 8192 Store buckets
2019/02/20 09:42:36 kid1| Max Mem  size: 262144 KB
2019/02/20 09:42:36 kid1| Max Swap size: 262144 KB
2019/02/20 09:42:36 kid1| Rebuilding storage in /cygdrive/e/squid/cache (clean log)
2019/02/20 09:42:36 kid1| Using Least Load store dir selection
2019/02/20 09:42:36 kid1| Set Current Directory to /cygdrive/e/squid/var/coredump
2019/02/20 09:42:36 kid1| Finished loading MIME types and icons.
2019/02/20 09:42:36 kid1| HTCP Disabled.
2019/02/20 09:42:36 kid1| Squid plugin modules loaded: 0
2019/02/20 09:42:36 kid1| Adaptation support is off.
2019/02/20 09:42:36 kid1| Accepting HTTP Socket connections at local=10.5.11.12:3128 remote=[::] FD 12 flags=9
2019/02/20 09:42:36 kid1| Done reading /cygdrive/e/squid/cache swaplog (0 entries)
2019/02/20 09:42:36 kid1| Store rebuilding is 0.00% complete
2019/02/20 09:42:36 kid1| Finished rebuilding storage from disk.
2019/02/20 09:42:36 kid1|         0 Entries scanned
2019/02/20 09:42:36 kid1|         0 Invalid entries.
2019/02/20 09:42:36 kid1|         0 With invalid flags.
2019/02/20 09:42:36 kid1|         0 Objects loaded.
2019/02/20 09:42:36 kid1|         0 Objects expired.
2019/02/20 09:42:36 kid1|         0 Objects cancelled.
2019/02/20 09:42:36 kid1|         0 Duplicate URLs purged.
2019/02/20 09:42:36 kid1|         0 Swapfile clashes avoided.
2019/02/20 09:42:36 kid1|   Took 0.04 seconds (  0.00 objects/sec).
2019/02/20 09:42:36 kid1| Beginning Validation Procedure
2019/02/20 09:42:36 kid1|   Completed Validation Procedure
2019/02/20 09:42:36 kid1|   Validated 0 Entries
2019/02/20 09:42:36 kid1|   store_swap_size = 0.00 KB
2019/02/20 09:42:37 kid1| storeLateRelease: released 0 objects
2019/02/20 09:42:45 kid1|  FD 12, 10.5.11.12 [ job1]: (14) Bad address


Squid.conf

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed

acl localnet src 10.0.0.0/8              # RFC1918 possible internal network
#acl localnet src 172.16.0.0/12    # RFC1918 possible internal network
#acl localnet src 192.168.0.0/16  # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80                    # http
acl Safe_ports port 21                    # ftp
acl Safe_ports port 443                  # https
acl Safe_ports port 70                    # gopher
acl Safe_ports port 210                  # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280                  # http-mgmt
acl Safe_ports port 488                  # gss-http
acl Safe_ports port 591                  # filemaker
acl Safe_ports port 777                  # multiling http
acl CONNECT method CONNECT

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
http_access deny to_localhost
# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 10.5.11.12:3128

# Uncomment the line below to enable disk caching - path format is /cygdrive/<full path to cache folder>, i.e.
cache_dir aufs /cygdrive/e/squid/cache 256 8 64
#cache deny all

# Limit number of days to keep logs
logfile_rotate 2

# Coredump directory
coredump_dir /cygdrive/e/squid/var/coredump

# Add any of your own refresh_pattern entries above these.
refresh_pattern -i (/cgi-bin/|\?) 0             0%          0
refresh_pattern .                             0              20%        4320

dns_nameservers 208.67.220.220 208.67.222.222
max_filedescriptors 3200

Typical access.log

1550724138.034    213 10.27.18.220 TCP_TUNNEL/200 4301 CONNECT ac3d8ead-8d6e-423e-8f51-1beadafe281a.ods.opinsights.azure.com:443 - HIER_DIRECT/40.71.12.224 -
1550724153.063 122686 10.27.18.220 TCP_TUNNEL/200 8820 CONNECT eus2-jobruntimedata-prod-su1.azure-automation.net:443 - HIER_DIRECT/104.208.163.218 -
1550724155.287 635036 10.27.18.220 TCP_TUNNEL/200 11107 CONNECT 593a6510-ebfc-4d6b-a8f0-a0411dfee098.ods.opinsights.azure.com:443 - HIER_DIRECT/40.71.12.224 -
1550724155.299 455045 10.27.18.220 TCP_TUNNEL/200 9280 CONNECT 593a6510-ebfc-4d6b-a8f0-a0411dfee098.ods.opinsights.azure.com:443 - HIER_DIRECT/40.71.12.224 -
1550724158.005    187 10.27.18.220 TCP_TUNNEL/200 4301 CONNECT ac3d8ead-8d6e-423e-8f51-1beadafe281a.ods.opinsights.azure.com:443 - HIER_DIRECT/40.71.12.224 -
1550724178.345    505 10.27.18.220 TCP_TUNNEL/200 4301 CONNECT ac3d8ead-8d6e-423e-8f51-1beadafe281a.ods.opinsights.azure.com:443 - HIER_DIRECT/40.71.12.224 -

Andrew Van Order
CTO | Application Delivery Services | Hosting Services - Monitoring and Configuration Services
Deloitte Services LP
Tel/Direct: +1 615 882 7836 | Fax: +1 615 750 7836
dvanorder at deloitte.com | www.deloitte.com


This message (including any attachments) contains confidential information intended for a specific individual and purpose, and is protected by law. If you are not the intended recipient, you should delete this message and any disclosure, copying, or distribution of this message, or the taking of any action based on it, by you is strictly prohibited.

v.E.1
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190221/1401a615/attachment.htm>

From chinaid at msn.com  Thu Feb 21 08:35:41 2019
From: chinaid at msn.com (WANG TOM)
Date: Thu, 21 Feb 2019 08:35:41 +0000
Subject: [squid-users] The issue NTLM_AUTH with --require-membership-of
In-Reply-To: <SG2PR01MB3222B7AE955A317459816976A57E0@SG2PR01MB3222.apcprd01.prod.exchangelabs.com>
References: <SG2PR01MB3222B7AE955A317459816976A57E0@SG2PR01MB3222.apcprd01.prod.exchangelabs.com>
Message-ID: <SG2PR01MB32223AA583FF602B43F217A5A57E0@SG2PR01MB3222.apcprd01.prod.exchangelabs.com>

Hi All,

Recently, I tried to configure a squid (4.5 on CentOS 7) proxy service with Microsoft Windows 2012 Active Directory authentication, but got a problem with "--require-membership-of" option.
----------------------------------------------------------------------------------------------
When I use "auth_param basic program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-basic"
Everything goes will, I can use my AD username and password to login and surf the internet by squid proxy services.
----------------------------------------------------------------------------------------------
But if I use "auth_param basic program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-basic --require-membership-of='IBM\Domain Users'"
OR "auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --require-membership-of='IBM\Domain Users'"
Then always gets "1550654743.129      0 192.168.0.1 TCP_DENIED/407 4252 CONNECT www.youtube.com:443 - HIER_NONE/- text/html",
Internet Explorer ask me to login again and again and again... I am sure I used correct domain, username and password, but everything is not work.
----------------------------------------------------------------------------------------------
And I have tested run ntlm_auth directly, it looks successfully.
"ntlm_auth --require-membership-of='IBM\Domain Users' --username=Administrators --password=123456
NT_STATUS_OK: The operation completed successfully. (0x0)"
----------------------------------------------------------------------------------------------
I have no idea what I have missed or made mistake, could someone can help.

Thanks!

Best regards.
TOM
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190221/fb94ff37/attachment.htm>

From squid3 at treenet.co.nz  Thu Feb 21 09:17:45 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Feb 2019 22:17:45 +1300
Subject: [squid-users] The issue NTLM_AUTH with --require-membership-of
In-Reply-To: <SG2PR01MB32223AA583FF602B43F217A5A57E0@SG2PR01MB3222.apcprd01.prod.exchangelabs.com>
References: <SG2PR01MB3222B7AE955A317459816976A57E0@SG2PR01MB3222.apcprd01.prod.exchangelabs.com>
 <SG2PR01MB32223AA583FF602B43F217A5A57E0@SG2PR01MB3222.apcprd01.prod.exchangelabs.com>
Message-ID: <bb46a0cf-6402-4aae-1818-56658745502e@treenet.co.nz>

On 21/02/19 9:35 pm, WANG TOM wrote:
> ----------------------------------------------------------------------------------------------
> And I have tested run ntlm_auth directly, it looks successfully.
> "ntlm_auth --require-membership-of='IBM\Domain Users'
> --username=Administrators --password=123456
> NT_STATUS_OK: The operation completed successfully. (0x0)"
> ----------------------------------------------------------------------------------------------
> I have no idea what I have missed or made mistake, could someone can help.
> 

Very likely that whitespace in the parameter string. Squid does not
support double-quote encoding of most parameters.

That means the helper will be passed two different environment
arguments.  One being "--require-membership-of='IBM\Domain".
The second being "Users'"

IIRC you can probably %-encode that (as "IBM\Domain%20Users").


If not that then you are going to have to debug what the helper is doing.


NP: This helper is provided by Samba, it is not part of Squid. So
questions about its abilities and encodings supported are a question for
their help channels. Someone here _might_ know, but do not count on that.


Amos


From squid3 at treenet.co.nz  Thu Feb 21 10:06:02 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Feb 2019 23:06:02 +1300
Subject: [squid-users] squid delay_pools can't limit speed on certain
 connections
In-Reply-To: <1550663170426-0.post@n4.nabble.com>
References: <848907109.784103.1550135150221@mail.yahoo.com>
 <cff06c35-41fe-e5b5-8107-8116cc7d0a3f@measurement-factory.com>
 <1550663170426-0.post@n4.nabble.com>
Message-ID: <0ecd5fdb-f421-52c5-8435-5f3869d04e3e@treenet.co.nz>

On 21/02/19 12:46 am, reinerotto wrote:
> I also have a problem with delay_pools on 4.4. Download speed is not
> throttled. Easily to be verified when watching video from youtube, using
> 'statistics for nerds'.
> 
> I do not remember having this effect on 3.5
> 
> This squid runs on up-to-date openwrt device,
> having limited resources.
> 
> I am happy to provide further info, in case I get
> instructions for debug_options
> 


ALL,9 is usually the best to get a full log of everything going on. For
more targeted logging debug section 77 is delay pools, 11 is HTTP, and
26 is the CONNECT tunnel handling.

For a device like OpenWRT you should be able to setup a Unix pipe at the
filesystem path of cache.log and divert the data written there to some
other machine with more storage.



> My squid.conf:
> 
> acl localnet src 10.1.0.0/24
> acl localnet src 172.16.0.0/24
> acl localnet src 192.168.1.0/24
> acl localnet src 192.168.2.0/24
> acl ssl_ports port 443
> acl safe_ports port 80
> acl safe_ports port 443
> acl safe_ports port 3128
> acl connect method connect
> http_access deny !safe_ports
> http_access deny connect !ssl_ports
> http_access allow localhost manager
> http_access allow localnet manager
> http_access deny manager
> cachemgr_passwd xxxxxxxx all
> acl denybin urlpath_regex \.bin
> cache deny denybin
> acl test_chrome_compression url_regex ^http://check.googlezip.net/connect
> http_access deny test_chrome_compression
> acl block_google_proxy req_header Chrome-Proxy .*
> http_access deny  block_google_proxy
> http_access allow localnet
> http_access allow localhost
> http_access deny all
> reload_into_ims on

NP: Now that Squid supports HTTP/1.1 caching by default this can cause a
lot (depending on object size) of unnecessary bandwidth to force caching
of objects that have no need to be fetched at all.


> refresh_pattern ^ftp: 1440 20% 10080
> refresh_pattern ^gopher: 1440 0% 1440
> refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 10080 90% 43200 override-expire
> ignore-no-cache ignore-no-store ignore-private
> refresh_pattern -i \.(iso|avi|wav|mp3|mp4|mpeg|swf|flv|x-flv)$ 43200 90%
> 432000 override-expire ignore-no-cache ignore-no-store ignore-private
> refresh_pattern -i \.(deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff)$
> 10080 90% 43200 override-expire ignore-no-cache ignore-no-store
> ignore-private


* ignore-no-cache no longer exists.

* override-expires tends to *shorten* caching times for the object types
above since they are most often static with years of lifetime.

* Combining ignore-no-store and ignore-private can cause information
leaks as objects that are only supposed to be delivered to a specific
client are delivered by your proxy to any other clients.
 ignore-private is not as dangerous as it used to be, but also does not
exactly save much bandwidth since everything has to be verified before
use anyway.


> refresh_pattern -i \.index.(html|htm)$ 0 40% 10080
> refresh_pattern -i \.(html|htm|css|js)$ 1440 40% 40320
> refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
> refresh_pattern . 0 20% 4320
> access_log none
> cache_log /mnt/sda1/log/squid/cache.log
> cache_store_log stdio:/dev/null

That is bad. It makes Squid do all the extra work of locating data and
formatting the log lines to be written to /dev/null.

In all Squid-3+ just remove the cache_store_log line from your config file.


> logfile_rotate 1
> logfile_daemon /dev/null
> http_port 3128
> http_port 8888 intercept
> https_port 3127  intercept ssl-bump cert=/etc/squid/ssl_cert/myCA.pem \
>   generate-host-certificates=off
> acl step1 at_step SslBump1
> ssl_bump peek step1 all
> ssl_bump splice all
> cache_mem 8 MB
> shutdown_lifetime 10 seconds
> httpd_suppress_version_string on
> dns_v4_first on
> forwarded_for delete
> pipeline_prefetch 2
> via off
> maximum_object_size_in_memory 128 KB
> maximum_object_size 4 MB
> reply_header_access Cache deny all
> client_idle_pconn_timeout 1 minute
> server_idle_pconn_timeout 5 minute
> read_timeout 2 minute
> ipcache_size 512
> fqdncache_size 256
> reply_header_access Alternate-Protocol deny all
> reply_header_access alternate-protocol deny all

NP: duplicate config line. Header names are case insensitive.

> reply_header_access alt-svc deny all
> pinger_enable off
> digest_generation off
> netdb_filename none
> cache_dir ufs /mnt/sda1/cache 250 16 256
> acl only512kusers src 10.1.0.0/24
> delay_pools 1
> delay_class 1 3
> delay_access 1 allow only512kusers
> delay_access 1 deny all
> delay_parameters 1 -1/-1 -1/-1 64000/64000
> 

FYI: The numbers above are in Bytes.

 ==> So your limit there is actually 625 KB, not 512 KB.

It is only a bug if the on-wire bytes being transmitted through the
proxy exceed 625KB/sec for any given client IP address.

* If the client uses multiple IPs - they each get separate buckets.

* If the client is using a connection that avoids the proxy - anything
the proxy does is irrelevant.

* If the client is compressing the data - on-wire may be up to 100% less
then reported by the UA.

This needs to take into consideration that HTTP/1.1, TLS, and most of
the modern protocols within TLS that all come under the term "HTTPS"
have high compression rates. So a client using any form of compression
will receive objects larger than their limit size/sec implies.

Amos


From belle at bazuin.nl  Thu Feb 21 10:14:11 2019
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Thu, 21 Feb 2019 11:14:11 +0100
Subject: [squid-users] The issue NTLM_AUTH with --require-membership-of
In-Reply-To: <bb46a0cf-6402-4aae-1818-56658745502e@treenet.co.nz>
References: <SG2PR01MB32223AA583FF602B43F217A5A57E0@SG2PR01MB3222.apcprd01.prod.exchangelabs.com>
Message-ID: <vmime.5c6e79f3.64ef.4c0663a53777e5a3@ms249-lin-003.rotterdam.bazuin.nl>

I think you problem has todo NT1. 

I assum you already tried the setting in smb.conf :  
ntlm auth =  ntlmv1-permitted 
(which is the alias for yes) 


And which samba/ntlm_auth version it this? Standard centos? 
I must say i noob in Centos, so i'll shown you what i know from debian. 
And it might be better to switch to kerberos auth. 

I know there are problems with the groups in ntlm_auth and its detection.
If i recall right, a patch passed recently, so waiting for that on the next samba version. 

I use the following.

auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \
    --kerberos /usr/lib/squid/negotiate_kerberos_auth -s HTTP/$(hostname -f)@MY_REALM \
    --ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOM

With ldap fallback
auth_param basic program /usr/lib/squid/basic_ldap_auth -R -v 3 \
    -b "ou=Office,dc=some,dc=domain,dc=tld" \
    -D ldap-bind at MY_REALM \
    -W /etc/squid/private/ldap-bind \
    -f sAMAccountName=%s \
    -H ldaps://dc1.FQDN \
    -H ldaps://dc2.FQDN

The ldap-bind account, needs, no pre-check on kerberos auth and disable passwd expire. 

The group part, now im not using it myself but per example. Should be something like this. 

Basicly its : 
Search for %LOGIN from this point : DC=office,DC=some,DC=domain,DC=tld  And get person-%a from group Proxygroups

external_acl_type ldapgroup %LOGIN /usr/lib/squid/squid_ldap_group -b DC=office,DC=some,DC=domain,DC=tld \
    -f (&(objectclass=person)(cn=%v)(groupMembership=cn=%a,ou=Proxygroups,DC=office,DC=some,DC=domain,DC=tld)) \
    -D ldap-bind at MY_REALM \
    -W /etc/squid/private/ldap-bind \
    -H ldaps://dc1.FQDN \
    -H ldaps://dc2.FQDN


external_acl_type AD_Group %LOGIN /usr/lib64/squid/squid_ldap_group -b DC=office,DC=some,DC=domain,DC=tld \
    -s sub \
    -R -v3 \
    -D ldap-bind at MY_REALM \
    -W /etc/squid/private/ldap-bind \
    -f "(&(objectclass=person)(userPrincipalName=%v)(memberof=cn=%a,ou=Proxygroups,DC=office,DC=some,DC=domain,DC=tld))" \
    -H ldaps://dc1.FQDN \
    -H ldaps://dc2.FQDN

I Hope this helps a bit. 

Greetz, 

Louis



> -----Oorspronkelijk bericht-----
> Van: squid-users 
> [mailto:squid-users-bounces at lists.squid-cache.org] Namens 
> Amos Jeffries
> Verzonden: donderdag 21 februari 2019 10:18
> Aan: squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] The issue NTLM_AUTH with 
> --require-membership-of
> 
> On 21/02/19 9:35 pm, WANG TOM wrote:
> > 
> --------------------------------------------------------------
> --------------------------------
> > And I have tested run ntlm_auth directly, it looks successfully.
> > "ntlm_auth --require-membership-of='IBM\Domain Users'
> > --username=Administrators --password=123456
> > NT_STATUS_OK: The operation completed successfully. (0x0)"
> > 
> --------------------------------------------------------------
> --------------------------------
> > I have no idea what I have missed or made mistake, could 
> someone can help.
> > 
> 
> Very likely that whitespace in the parameter string. Squid does not
> support double-quote encoding of most parameters.
> 
> That means the helper will be passed two different environment
> arguments.  One being "--require-membership-of='IBM\Domain".
> The second being "Users'"
> 
> IIRC you can probably %-encode that (as "IBM\Domain%20Users").
> 
> 
> If not that then you are going to have to debug what the 
> helper is doing.
> 
> 
> NP: This helper is provided by Samba, it is not part of Squid. So
> questions about its abilities and encodings supported are a 
> question for
> their help channels. Someone here _might_ know, but do not 
> count on that.
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From bruno.larini at riosoft.com.br  Thu Feb 21 11:58:29 2019
From: bruno.larini at riosoft.com.br (Bruno de Paula Larini)
Date: Thu, 21 Feb 2019 08:58:29 -0300
Subject: [squid-users] The issue NTLM_AUTH with --require-membership-of
In-Reply-To: <bb46a0cf-6402-4aae-1818-56658745502e@treenet.co.nz>
References: <SG2PR01MB3222B7AE955A317459816976A57E0@SG2PR01MB3222.apcprd01.prod.exchangelabs.com>
 <SG2PR01MB32223AA583FF602B43F217A5A57E0@SG2PR01MB3222.apcprd01.prod.exchangelabs.com>
 <bb46a0cf-6402-4aae-1818-56658745502e@treenet.co.nz>
Message-ID: <b3852e68-0734-c2f2-0248-ee3187a3dc37@riosoft.com.br>

Em 21/02/2019 06:17, Amos Jeffries escreveu:
> NP: This helper is provided by Samba, it is not part of Squid. So
> questions about its abilities and encodings supported are a question for
> their help channels. Someone here _might_ know, but do not count on that.
Maybe this is not the most adequate solution, but it probably would be 
easier to create a group without spaces and make the Domain Users a 
member of it.
But Tom must have figured it out already.


From squid3 at treenet.co.nz  Thu Feb 21 12:38:25 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 22 Feb 2019 01:38:25 +1300
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
Message-ID: <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>

On 21/02/19 6:23 pm, Van Order, Drew (US - Hermitage) wrote:
> Hello folks, we?re running Squid 3.5.28 on four Windows 2016 VM?s, each
> has 4 CPU, 8 GB memory, 10 GB NIC. We implemented Squid to support
> forwarding Azure Log Analytics data, it?s all CONNECT. The Squids are
> load balanced through a F5. There are less than 1,000 servers sending
> data to Log Analytics.
> 
> ?
> 
> All four Squids are regularly crashing, and I don?t know how to
> interpret the errors in cache.log. It crashes if we disable caching too.
> 
...
> 
> 2019/02/20 09:42:32 kid1|? FD 12, 10.5.11.12 [Stopped, reason:Listener
> socket closed job1]: (14) Bad address
> 

Something other than Squid closed the network socket Squid was using to
receive new client connections (the http_port socket).

The only things which should know that socket even exists are Squid and
the operating system.

This is not an error I've seen before. Is this Squid maybe running in a
container or VM which is being hibernated, or suspended, or anything
along those lines which may cause the OS filedescriptors to change
unexpectedly?

Amos


From dvanorder at deloitte.com  Thu Feb 21 14:53:38 2019
From: dvanorder at deloitte.com (Van Order, Drew (US - Hermitage))
Date: Thu, 21 Feb 2019 14:53:38 +0000
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <119101d4c9b1$98ee85b0$cacb9110$@ngtech.co.il>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <119101d4c9b1$98ee85b0$cacb9110$@ngtech.co.il>
Message-ID: <CO1PR85MB0181BE12BB1D64365BBD61C6C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>

This was my first concern with posting, having managed NetView/AIX for years-that folks may focus on the choice of OS versus the problem at hand. This is not meant to be an enterprise solution, it's something for a team of non-network engineers to use to support passing tcp/443 traffic from servers blocked from the internet. Why not choose the platform that is most familiar to the people that will need to support it?

I've got a fifth Windows Squid test box running outside the F5 that has yet to error, but it only has a handful of agents sending Log Analytics data. The F5's have been checked out, so the hope is that a Squid config or OS registry change will fix this.

However, if the consensus is that the Windows port is unstable under any kind of load, then we'd have to consider options.

From: eliezer at ngtech.co.il <eliezer at ngtech.co.il>
Sent: Thursday, February 21, 2019 12:50 AM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; squid-users at lists.squid-cache.org
Subject: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

May I ask about the usage of Windows 2016 VM's compared to CentOS or Ubuntu?

Eliezer

----
Eliezer Croitoru<http://secure-web.cisco.com/1QlNYIFwJYHHQ7Gju-o31exeEfzmLfLHD-tlPBXtA4AjezZjFRrjCjQhCtZ3finQTxn34ZnlGjGrThEMYGWtTzylNEw-ofQAp8U32g0ctuACuPLDsaX0vdvlccEM9yAFrtly-r6W9v8aAND2sTwtjG_DdCWCqHr20GzEBelQB5zTXPLSrBWKwb2lQG4S9q1TfNVRxihuQEW_4yLWhCq4aD2qelhYU-Z_IcKwsQ5SDh_RAGgz1tx_F3PIGffKM9wlJgUgh75XoWakVDRnMuUx_OdOl2IgHlZsveHKOFhCiBjHKJ5MsZCUVdB2EsQ-WarU2je57Od_AQy8Le44KosAmxe7QcJbvSFxmUm6Gea-lNQZPJ__ZRbR8U-OurUTPnV8l2paOjYM2srjFrDknyxo_5KwLIn6pqIR2O2RpC6mUFl4Jj2LOaSoPW1RPPepT4-bm-YdpU5ZU9rymMsiZWEIxrhT1IJYxMYP7HuQFJ-4MmxrZAY2yUaMbB9tiyHf2CimH/http%3A%2F%2Fngtech.co.il%2Fmain-en%2F>
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>
[cid:image001.png at 01D2675E.DCF360D0]

From: squid-users <squid-users-bounces at lists.squid-cache.org<mailto:squid-users-bounces at lists.squid-cache.org>> On Behalf Of Van Order, Drew (US - Hermitage)
Sent: Thursday, February 21, 2019 07:23
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: [squid-users] Squid for Windows Repeatedly Crashing

Hello folks, we're running Squid 3.5.28 on four Windows 2016 VM's, each has 4 CPU, 8 GB memory, 10 GB NIC. We implemented Squid to support forwarding Azure Log Analytics data, it's all CONNECT. The Squids are load balanced through a F5. There are less than 1,000 servers sending data to Log Analytics.

All four Squids are regularly crashing, and I don't know how to interpret the errors in cache.log. It crashes if we disable caching too.

Any insight is appreciated-I've inherited this responsibility and more a cloud engineer than a network specialist.

Thanks in advance!

Typical error sequence in cache.log

2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:33 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:33 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:33 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:33 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:33 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 1
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 2
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 3
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 4
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 5
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 6
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 7
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 8
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 9
2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 10
2019/02/20 09:42:33 kid1| Closing HTTP port 10.5.11.12:3128
FATAL: Event loop exited with failure.
Squid Cache (Version 3.5.28): Terminated abnormally.
CPU Usage: 12.640 seconds = 4.234 user + 8.406 sys
Maximum Resident Size: 5159680 KB
Page faults with physical i/o: 20341

Squid restarts, and will often start erroring right away:

2019/02/20 09:42:33 kid1| storeDirWriteCleanLogs: Starting...
2019/02/20 09:42:33 kid1|   Finished.  Wrote 0 entries.
2019/02/20 09:42:33 kid1|   Took 0.00 seconds (  0.00 entries/sec).
2019/02/20 09:42:36 kid1| Set Current Directory to /cygdrive/e/squid/var/coredump
2019/02/20 09:42:36 kid1| Starting Squid Cache version 3.5.28 for x86_64-unknown-cygwin...
2019/02/20 09:42:36 kid1| Service Name: squid
2019/02/20 09:42:36 kid1| Process ID 2292
2019/02/20 09:42:36 kid1| Process Roles: worker
2019/02/20 09:42:36 kid1| With 3200 file descriptors available
2019/02/20 09:42:36 kid1| Initializing IP Cache...
2019/02/20 09:42:36 kid1| parseEtcHosts: /etc/hosts: (2) No such file or directory
2019/02/20 09:42:36 kid1| DNS Socket created at [::], FD 5
2019/02/20 09:42:36 kid1| DNS Socket created at 0.0.0.0, FD 6
2019/02/20 09:42:36 kid1| Adding nameserver 208.67.220.220 from squid.conf
2019/02/20 09:42:36 kid1| Adding nameserver 208.67.222.222 from squid.conf
2019/02/20 09:42:36 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2019/02/20 09:42:36 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2019/02/20 09:42:36 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2019/02/20 09:42:36 kid1| Store logging disabled
2019/02/20 09:42:36 kid1| Swap maxSize 262144 + 262144 KB, estimated 40329 objects
2019/02/20 09:42:36 kid1| Target number of buckets: 2016
2019/02/20 09:42:36 kid1| Using 8192 Store buckets
2019/02/20 09:42:36 kid1| Max Mem  size: 262144 KB
2019/02/20 09:42:36 kid1| Max Swap size: 262144 KB
2019/02/20 09:42:36 kid1| Rebuilding storage in /cygdrive/e/squid/cache (clean log)
2019/02/20 09:42:36 kid1| Using Least Load store dir selection
2019/02/20 09:42:36 kid1| Set Current Directory to /cygdrive/e/squid/var/coredump
2019/02/20 09:42:36 kid1| Finished loading MIME types and icons.
2019/02/20 09:42:36 kid1| HTCP Disabled.
2019/02/20 09:42:36 kid1| Squid plugin modules loaded: 0
2019/02/20 09:42:36 kid1| Adaptation support is off.
2019/02/20 09:42:36 kid1| Accepting HTTP Socket connections at local=10.5.11.12:3128 remote=[::] FD 12 flags=9
2019/02/20 09:42:36 kid1| Done reading /cygdrive/e/squid/cache swaplog (0 entries)
2019/02/20 09:42:36 kid1| Store rebuilding is 0.00% complete
2019/02/20 09:42:36 kid1| Finished rebuilding storage from disk.
2019/02/20 09:42:36 kid1|         0 Entries scanned
2019/02/20 09:42:36 kid1|         0 Invalid entries.
2019/02/20 09:42:36 kid1|         0 With invalid flags.
2019/02/20 09:42:36 kid1|         0 Objects loaded.
2019/02/20 09:42:36 kid1|         0 Objects expired.
2019/02/20 09:42:36 kid1|         0 Objects cancelled.
2019/02/20 09:42:36 kid1|         0 Duplicate URLs purged.
2019/02/20 09:42:36 kid1|         0 Swapfile clashes avoided.
2019/02/20 09:42:36 kid1|   Took 0.04 seconds (  0.00 objects/sec).
2019/02/20 09:42:36 kid1| Beginning Validation Procedure
2019/02/20 09:42:36 kid1|   Completed Validation Procedure
2019/02/20 09:42:36 kid1|   Validated 0 Entries
2019/02/20 09:42:36 kid1|   store_swap_size = 0.00 KB
2019/02/20 09:42:37 kid1| storeLateRelease: released 0 objects
2019/02/20 09:42:45 kid1|  FD 12, 10.5.11.12 [ job1]: (14) Bad address


Squid.conf

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed

acl localnet src 10.0.0.0/8              # RFC1918 possible internal network
#acl localnet src 172.16.0.0/12    # RFC1918 possible internal network
#acl localnet src 192.168.0.0/16  # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80                    # http
acl Safe_ports port 21                    # ftp
acl Safe_ports port 443                  # https
acl Safe_ports port 70                    # gopher
acl Safe_ports port 210                  # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280                  # http-mgmt
acl Safe_ports port 488                  # gss-http
acl Safe_ports port 591                  # filemaker
acl Safe_ports port 777                  # multiling http
acl CONNECT method CONNECT

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
http_access deny to_localhost
# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 10.5.11.12:3128

# Uncomment the line below to enable disk caching - path format is /cygdrive/<full path to cache folder>, i.e.
cache_dir aufs /cygdrive/e/squid/cache 256 8 64
#cache deny all

# Limit number of days to keep logs
logfile_rotate 2

# Coredump directory
coredump_dir /cygdrive/e/squid/var/coredump

# Add any of your own refresh_pattern entries above these.
refresh_pattern -i (/cgi-bin/|\?) 0             0%          0
refresh_pattern .                             0              20%        4320

dns_nameservers 208.67.220.220 208.67.222.222
max_filedescriptors 3200

Typical access.log

1550724138.034    213 10.27.18.220 TCP_TUNNEL/200 4301 CONNECT ac3d8ead-8d6e-423e-8f51-1beadafe281a.ods.opinsights.azure.com:443 - HIER_DIRECT/40.71.12.224 -
1550724153.063 122686 10.27.18.220 TCP_TUNNEL/200 8820 CONNECT eus2-jobruntimedata-prod-su1.azure-automation.net:443 - HIER_DIRECT/104.208.163.218 -
1550724155.287 635036 10.27.18.220 TCP_TUNNEL/200 11107 CONNECT 593a6510-ebfc-4d6b-a8f0-a0411dfee098.ods.opinsights.azure.com:443 - HIER_DIRECT/40.71.12.224 -
1550724155.299 455045 10.27.18.220 TCP_TUNNEL/200 9280 CONNECT 593a6510-ebfc-4d6b-a8f0-a0411dfee098.ods.opinsights.azure.com:443 - HIER_DIRECT/40.71.12.224 -
1550724158.005    187 10.27.18.220 TCP_TUNNEL/200 4301 CONNECT ac3d8ead-8d6e-423e-8f51-1beadafe281a.ods.opinsights.azure.com:443 - HIER_DIRECT/40.71.12.224 -
1550724178.345    505 10.27.18.220 TCP_TUNNEL/200 4301 CONNECT ac3d8ead-8d6e-423e-8f51-1beadafe281a.ods.opinsights.azure.com:443 - HIER_DIRECT/40.71.12.224 -

Andrew Van Order
CTO | Application Delivery Services | Hosting Services - Monitoring and Configuration Services
Deloitte Services LP
Tel/Direct: +1 615 882 7836 | Fax: +1 615 750 7836
dvanorder at deloitte.com<mailto:dvanorder at deloitte.com> | www.deloitte.com<http://www.deloitte.com>


This message (including any attachments) contains confidential information intended for a specific individual and purpose, and is protected by law. If you are not the intended recipient, you should delete this message and any disclosure, copying, or distribution of this message, or the taking of any action based on it, by you is strictly prohibited.

v.E.1
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190221/eb2a8e04/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11295 bytes
Desc: image001.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190221/eb2a8e04/attachment.png>

From dvanorder at deloitte.com  Thu Feb 21 15:21:11 2019
From: dvanorder at deloitte.com (Van Order, Drew (US - Hermitage))
Date: Thu, 21 Feb 2019 15:21:11 +0000
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
Message-ID: <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>

Thank you for replying, and that's an excellent point.

Short answer--definitely not in a container, these are garden variety VMWare instances. I've already flagged the OS power settings to maximum performance, so nothing should be going to sleep. I'll doublecheck, though.

So, if I understand correctly, this error could also be indicative of an issue in between the agent and Squid. Agents first go through a firewall, then the F5 before reaching Squid.

[Stopped, reason:Listener socket closed job1]: (14) Bad address

Any thoughts on this error, which tends to be more common than the other?

2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
2019/02/20 09:42:33 kid1| Select loop Error. Retry 2



-----Original Message-----
From: Amos Jeffries <squid3 at treenet.co.nz>
Sent: Thursday, February 21, 2019 6:38 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing

On 21/02/19 6:23 pm, Van Order, Drew (US - Hermitage) wrote:
> Hello folks, we're running Squid 3.5.28 on four Windows 2016 VM's,
> each has 4 CPU, 8 GB memory, 10 GB NIC. We implemented Squid to
> support forwarding Azure Log Analytics data, it's all CONNECT. The
> Squids are load balanced through a F5. There are less than 1,000
> servers sending data to Log Analytics.
>
>
>
> All four Squids are regularly crashing, and I don't know how to
> interpret the errors in cache.log. It crashes if we disable caching too.
>
...
>
> 2019/02/20 09:42:32 kid1|  FD 12, 10.5.11.12 [Stopped, reason:Listener
> socket closed job1]: (14) Bad address
>

Something other than Squid closed the network socket Squid was using to receive new client connections (the http_port socket).

The only things which should know that socket even exists are Squid and the operating system.

This is not an error I've seen before. Is this Squid maybe running in a container or VM which is being hibernated, or suspended, or anything along those lines which may cause the OS filedescriptors to change unexpectedly?

Amos

This message (including any attachments) contains confidential information intended for a specific individual and purpose, and is protected by law. If you are not the intended recipient, you should delete this message and any disclosure, copying, or distribution of this message, or the taking of any action based on it, by you is strictly prohibited.

v.E.1


From felipeapolanco at gmail.com  Thu Feb 21 21:11:11 2019
From: felipeapolanco at gmail.com (Felipe Arturo Polanco)
Date: Thu, 21 Feb 2019 17:11:11 -0400
Subject: [squid-users] Websockets over HTTPS not working in squid 4
Message-ID: <CADcj3=4moi1mk=fVYUyu-Su6fGbV1DT=Oif7bfmgcqxx1MUbHw@mail.gmail.com>

Hi,

I have been trying to make websockets work over HTTPS but so far I haven't
been able to.

I'm trying the following websites that use websockets and none of them work:
speedtest.net
web.whatsapp.com
https://slack.com/help/test

If I explicitly splice those domain names in squid.conf they work fine.

This is a transparent HTTPS proxy.

Below is my configuration:

=============
acl SSL_ports port 443
acl CONNECT method CONNECT
log_mime_hdrs on
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
https_port 3128 intercept ssl-bump cert=/etc/squid/ssl_cert/proxyCA.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=256KB
sslcrtd_program /usr/lib64/squid/security_file_certgen -s
/var/spool/squid/ssl_db -M 4MB

acl serverIsws ssl::server_name_regex speedtest\.net$
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump splice serverIsws
ssl_bump bump !serverIsws all
on_unsupported_protocol tunnel all

debug_options ALL,1 26,1 33,9 83,9 28,9 81,9 11,2
http_access allow localnet
http_access allow localhost
http_access deny all
http_port 3129 intercept
http_port 3130

coredump_dir /var/spool/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
===================

In the logs I see 400 Bad request :

==================================================
2019/02/21 12:52:38.004 kid1| 11,2| http.cc(723) processReplyHeader: HTTP
Server RESPONSE:
---------
HTTP/1.1 400 Bad Request
Date: Thu, 21 Feb 2019 20:46:34 GMT
Transfer-Encoding: chunked
Connection: keep-alive

----------
2019/02/21 12:52:38.004 kid1| ctx: exit level  0
2019/02/21 12:52:38.004 kid1| 83,3| AccessCheck.cc(42) Start: adaptation
off, skipping
2019/02/21 12:52:38.004 kid1| 33,5| store_client.cc(319) doCopy:
store_client::doCopy: co: 0, hi: 117
2019/02/21 12:52:38.004 kid1| 33,3| Pipeline.cc(35) front: Pipeline
0x1c47830 front 0x17948a0*3
2019/02/21 12:52:38.004 kid1| 33,3| Pipeline.cc(35) front: Pipeline
0x1c47830 front 0x17948a0*3
2019/02/21 12:52:38.004 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP
Client local=31.13.67.52:443 remote=192.168.112.143:46408 FD 14 flags=33
2019/02/21 12:52:38.005 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP
Client REPLY:
---------
HTTP/1.1 400 Bad Request
Date: Thu, 21 Feb 2019 20:46:34 GMT
X-Cache: MISS from squidserver
X-Cache-Lookup: MISS from squidserver:3130
Transfer-Encoding: chunked
Via: 1.1 squidserver (squid/4.1)
Connection: keep-alive


----------
============================================

I'm not interested in bumping the websockets, I just want HTTPS
interception to work as well as websockets.

Any help is welcomed.

Thanks,
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190221/28930079/attachment.htm>

From rousskov at measurement-factory.com  Thu Feb 21 21:33:41 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 21 Feb 2019 14:33:41 -0700
Subject: [squid-users] Websockets over HTTPS not working in squid 4
In-Reply-To: <CADcj3=4moi1mk=fVYUyu-Su6fGbV1DT=Oif7bfmgcqxx1MUbHw@mail.gmail.com>
References: <CADcj3=4moi1mk=fVYUyu-Su6fGbV1DT=Oif7bfmgcqxx1MUbHw@mail.gmail.com>
Message-ID: <ad87a1d7-52a1-169b-ced8-de3e0f13c194@measurement-factory.com>

On 2/21/19 2:11 PM, Felipe Arturo Polanco wrote:

> I have been trying to make websockets?work over HTTPS but so far I
> haven't been able to.


Official Squid cannot reliably detect and proxy native WebSocket
traffic. Until that support is available, if WebSocket traffic reaches
your intercepting Squid, then splicing suspected WebSocket connections
based on TCP/TLS-level information is your only option. And, yes, that
introduces lots of maintenance headaches, policy violations, and is not
reliable.

A bit more information about the topic is available on this 2018 thread:
http://lists.squid-cache.org/pipermail/squid-users/2018-July/018581.html

Alex.


> I'm trying the following websites that use websockets and none of them work:
> speedtest.net <http://speedtest.net>
> web.whatsapp.com <http://web.whatsapp.com>
> https://slack.com/help/test
> 
> If I explicitly splice those domain names in squid.conf they work fine.
> 
> I'm not interested in bumping the websockets, I just want HTTPS
> interception to work as well as websockets.


From felipeapolanco at gmail.com  Thu Feb 21 22:19:33 2019
From: felipeapolanco at gmail.com (Felipe Arturo Polanco)
Date: Thu, 21 Feb 2019 18:19:33 -0400
Subject: [squid-users] Websockets over HTTPS not working in squid 4
In-Reply-To: <ad87a1d7-52a1-169b-ced8-de3e0f13c194@measurement-factory.com>
References: <CADcj3=4moi1mk=fVYUyu-Su6fGbV1DT=Oif7bfmgcqxx1MUbHw@mail.gmail.com>
 <ad87a1d7-52a1-169b-ced8-de3e0f13c194@measurement-factory.com>
Message-ID: <CADcj3=6cLC3uZFc-yRB76Evsu+NErmmYTSSuexjdRXFvkRauVw@mail.gmail.com>

I see.

Are you aware of any unofficial patch or something to tunnel
websockets over HTTPS in squid?



On Thu, Feb 21, 2019 at 5:33 PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 2/21/19 2:11 PM, Felipe Arturo Polanco wrote:
>
> > I have been trying to make websockets work over HTTPS but so far I
> > haven't been able to.
>
>
> Official Squid cannot reliably detect and proxy native WebSocket
> traffic. Until that support is available, if WebSocket traffic reaches
> your intercepting Squid, then splicing suspected WebSocket connections
> based on TCP/TLS-level information is your only option. And, yes, that
> introduces lots of maintenance headaches, policy violations, and is not
> reliable.
>
> A bit more information about the topic is available on this 2018 thread:
> http://lists.squid-cache.org/pipermail/squid-users/2018-July/018581.html
>
> Alex.
>
>
> > I'm trying the following websites that use websockets and none of them
> work:
> > speedtest.net <http://speedtest.net>
> > web.whatsapp.com <http://web.whatsapp.com>
> > https://slack.com/help/test
> >
> > If I explicitly splice those domain names in squid.conf they work fine.
> >
> > I'm not interested in bumping the websockets, I just want HTTPS
> > interception to work as well as websockets.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190221/614dc754/attachment.htm>

From chip_pop at hotmail.com  Fri Feb 22 00:51:35 2019
From: chip_pop at hotmail.com (joseph)
Date: Thu, 21 Feb 2019 18:51:35 -0600 (CST)
Subject: [squid-users] squid-5.0.0-20190221-re008097c6
Message-ID: <1550796695494-0.post@n4.nabble.com>

In file included from Reply.cc:14:
../../src/helper.h:264:18: error: ???map??? in namespace ???std??? does not
name a template type
     typedef std::map<uint64_t, Requests::iterator> RequestIndex;
                  ^~~
../../src/helper.h:264:13: note: ???std::map??? is defined in header
???<map>???; did you forget to ???#include <map>????
../../src/helper.h:29:1:
+#include <map>
 #include <queue>
../../src/helper.h:264:13:
     typedef std::map<uint64_t, Requests::iterator> RequestIndex;
             ^~~
../../src/helper.h:265:5: error: ???RequestIndex??? does not name a type;
did you mean ???Requests????
     RequestIndex requestsIndex; ///< maps request IDs to requests
     ^~~~~~~~~~~~
     Requests
libtool: compile:  g++ -DHAVE_CONFIG_H
-DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
-DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\"
-DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\" -I../.. -I../../include
-I../../lib -I../../src -I../../include -I/usr/include/openssl -Wall
-Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual
-Werror -pipe -D_REENTRANT -std=c++11 -Wall -m64 -O3 -pipe -march=native -MT
ChildConfig.lo -MD -MP -MF .deps/ChildConfig.Tpo -c ChildConfig.cc -o
ChildConfig.o >/dev/null 2>&1
make[3]: *** [Makefile:831: Reply.lo] Error 1
make[3]: *** Waiting for unfinished jobs....
make[3]: Leaving directory
'/var/tmp/squid-5.0.0-20190221-re008097c6/src/helper'
make[2]: *** [Makefile:6771: all-recursive] Error 1
make[2]: Leaving directory '/var/tmp/squid-5.0.0-20190221-re008097c6/src'
make[1]: *** [Makefile:5766: all] Error 2
make[1]: Leaving directory '/var/tmp/squid-5.0.0-20190221-re008097c6/src'
make: *** [Makefile:589: all-recursive] Error 1



-----
************************** 
***** Crash to the future  ****
**************************
--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From chip_pop at hotmail.com  Fri Feb 22 01:00:17 2019
From: chip_pop at hotmail.com (joseph)
Date: Thu, 21 Feb 2019 19:00:17 -0600 (CST)
Subject: [squid-users] squid-5.0.0-20190221-re008097c6
In-Reply-To: <1550796695494-0.post@n4.nabble.com>
References: <1550796695494-0.post@n4.nabble.com>
Message-ID: <1550797217337-0.post@n4.nabble.com>

Log PROXY protocol v2 TLVs; fix PROXY protocol parsing bugs
 (#342) i think



-----
************************** 
***** Crash to the future  ****
**************************
--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Fri Feb 22 05:31:16 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 22 Feb 2019 18:31:16 +1300
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
Message-ID: <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>

On 22/02/19 4:21 am, Van Order, Drew (US - Hermitage) wrote:
> Thank you for replying, and that's an excellent point.
> 
> Short answer--definitely not in a container, these are garden variety VMWare instances. I've already flagged the OS power settings to maximum performance, so nothing should be going to sleep. I'll doublecheck, though.
> 
> So, if I understand correctly, this error could also be indicative of an issue in between the agent and Squid. Agents first go through a firewall, then the F5 before reaching Squid.

No that is not what I meant.

The port Squid has already opened and used syscall listen(2) on is what
is being closed (or its address corrupted) outside of Squid. That should
only ever be closed by Squid itself. Thus the error.

It is being closed repeatedly. Thus the abort/shutdown. This is not a
crash, it is intentional shutdown by Squid due to these fatal
(non-recoverable) errors.


> 
> [Stopped, reason:Listener socket closed job1]: (14) Bad address
> 
> Any thoughts on this error, which tends to be more common than the other?
> 
> 2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
> 2019/02/20 09:42:33 kid1| Select loop Error. Retry 2
> 

Notice how the error from the OS "(14) Bad Address" is the same. This is
just another display of the same problem. Maybe the poll() layer
reporting the exact same error as Squid tries to recover. Maybe for
other non-listener ports also being corrupted somehow.

If non-listener ports are having that same error it would be a sign the
machine memory is being corrupted rather than other software touching
the listener ports specifically.


( The details you have provided so far have no hints about where the
problem may be coming from, and I am not having any ideas about
possibilities either. I just hope the above explanation of meaning can
help you think of things to look at for more hints on this very weird
issue. )

Amos


From squid3 at treenet.co.nz  Fri Feb 22 05:56:06 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 22 Feb 2019 18:56:06 +1300
Subject: [squid-users] squid-5.0.0-20190221-re008097c6
In-Reply-To: <1550796695494-0.post@n4.nabble.com>
References: <1550796695494-0.post@n4.nabble.com>
Message-ID: <b4d995f6-6b3f-dc05-4b8b-484b8530b7e0@treenet.co.nz>

<http://www.squid-cache.org/Versions/>
"
Development Versions:

Meant for Squid users who are already familiar with Squid. You should
expect to find numerous bugs and problems. We do not recommend running a
development release on your production cache. If you have any problems
with a development release please write to our
squid-bugs at lists.squid-cache.org or squid-dev at lists.squid-cache.org
lists. DO NOT write to squid-users with code-related problems.

"

Please note that last sentence. AFAIK the dev best placed to test and
fix this bug does not follow this mailing list.


This squid-users list is for general discussions. Please keep discussion
of issues to those being in the stable / production Squid versions. Even
then bugzilla is the better place for issues that are clearly code bugs.


Cheers
Amos


From rousskov at measurement-factory.com  Fri Feb 22 06:11:16 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 21 Feb 2019 23:11:16 -0700
Subject: [squid-users] squid-5.0.0-20190221-re008097c6
In-Reply-To: <1550797217337-0.post@n4.nabble.com>
References: <1550796695494-0.post@n4.nabble.com>
 <1550797217337-0.post@n4.nabble.com>
Message-ID: <8c282645-c2b1-3ea6-6d46-70d28ecdc4d5@measurement-factory.com>

On 2/21/19 6:00 PM, joseph wrote:

> src/helper.h:264:18: error: `std::map` does not name a template type

> Log PROXY protocol v2 TLVs; fix PROXY protocol parsing bugs
>  (#342) i think


Almost. It was another recent commit: "Reuse reserved Negotiate and NTLM
helpers after an idle timeout" (#59)

Proposed fix is at https://github.com/squid-cache/squid/pull/375
Add ".patch" to that URL to get a patch.

FWIW, it looks like your build environment is not one of those that the
Squid Project auto-tests.


HTH,

Alex.


From amlgp at mftsl.xyz  Fri Feb 22 06:25:55 2019
From: amlgp at mftsl.xyz (amlgp)
Date: Fri, 22 Feb 2019 00:25:55 -0600 (CST)
Subject: [squid-users] Squid proxies won't pop up authentication or even
	attempt
Message-ID: <1550816755507-0.post@n4.nabble.com>

Hi all, I've been trying to troubleshoot this for the last 2 days and it's
starting to drive me nuts.

I am running on a Centos 6 server trying to start up some proxies with
Squid.

When I manually try to enter my proxy using Firefox, no window pops up for
authentication and I just time out. I have read that this might be due to a
http access or acl error but I can't see anything wrong.

Steps I have taken so far:

-Set up network interfaces with Centos(all my IP's ping correctly from
inside the server and outside the server)
-Set up squid.conf with acl and userpass authentication

Squid version: squid-3.1.23-24.el6.x86_64

Access logs are empty, error logs are currently empty in
/var/log/squid/squid.out after I fixed the visible_hostname error. Squid
starts/restarts/stops without errors.


I have tried using the actual hostname that shows up when using the
"hostname" command and there are no changes, so I just replaced it with
localhost instead.

Also, abc 123 x are real numbers, and the IP pings but the exact numbers
have been replaced for this post.

Does anyone see what the problem might be? Thank you in advance!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From chinaid at msn.com  Fri Feb 22 06:32:35 2019
From: chinaid at msn.com (WANG TOM)
Date: Fri, 22 Feb 2019 06:32:35 +0000
Subject: [squid-users] =?utf-8?b?562U5aSNOiAgVGhlIGlzc3VlIE5UTE1fQVVUSCB3?=
 =?utf-8?q?ith_--require-membership-of?=
In-Reply-To: <vmime.5c6e79f3.64ef.4c0663a53777e5a3@ms249-lin-003.rotterdam.bazuin.nl>
References: <SG2PR01MB32223AA583FF602B43F217A5A57E0@SG2PR01MB3222.apcprd01.prod.exchangelabs.com>,
 <vmime.5c6e79f3.64ef.4c0663a53777e5a3@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <SG2PR01MB2031D3AB458606965FBF36C5A57F0@SG2PR01MB2031.apcprd01.prod.exchangelabs.com>

Hi All,

Thanks a lot!

Issue has been solved, hope it's useful for other people if they encounter the same situation as me.

--------------------------------------------

--require-membership-of="IBM\Domain Users" with Quotation Mark is not supported, has to be removed as:
--require-membership-of=IBM\Domain_Users

But what if Domain Group must has a space, use SID to instead of Domain Group Name :
--require-membership-of=S-1-5-21-1386769244-779028218-18449361

--------------------------------------------

debug:

To reduce unnecessary logs, it's good to set debug level as
debug_options 29,9

To get SID by winbind
wbinfo -n "IBM\Domain Users"

To test ntlm_auth
ntlm_auth --username=Administrator --require-membership-of="IBM\Domain_Users"
OR
ntlm_auth --username=Administrator --require-membership-of=IBM\\Domain_Users
OR
ntlm_auth --username=Administrator --require-membership-of="S-1-5-21-1386769244-779028218-18449361"
OR
ntlm_auth --username=Administrator --require-membership-of=S-1-5-21-1386769244-779028218-18449361

To join computer as a Domain Member without modify krb5.conf manually. ?
realm join --user=Administrators ibm.local -v

But Samba need to be configured manually. ?

--------------------------------------------

Working for me on CentOS7 + Squid4.5 + Windows AD

Best regards.
TOM.WANG


________________________________
???: squid-users <squid-users-bounces at lists.squid-cache.org> ?? L.P.H. van Belle <belle at bazuin.nl>
????: 2019?2?21? 10:14
???: squid-users at lists.squid-cache.org
??: Re: [squid-users] The issue NTLM_AUTH with --require-membership-of

I think you problem has todo NT1.

I assum you already tried the setting in smb.conf :
ntlm auth =  ntlmv1-permitted
(which is the alias for yes)


And which samba/ntlm_auth version it this? Standard centos?
I must say i noob in Centos, so i'll shown you what i know from debian.
And it might be better to switch to kerberos auth.

I know there are problems with the groups in ntlm_auth and its detection.
If i recall right, a patch passed recently, so waiting for that on the next samba version.

I use the following.

auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \
    --kerberos /usr/lib/squid/negotiate_kerberos_auth -s HTTP/$(hostname -f)@MY_REALM \
    --ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOM

With ldap fallback
auth_param basic program /usr/lib/squid/basic_ldap_auth -R -v 3 \
    -b "ou=Office,dc=some,dc=domain,dc=tld" \
    -D ldap-bind at MY_REALM \
    -W /etc/squid/private/ldap-bind \
    -f sAMAccountName=%s \
    -H ldaps://dc1.FQDN \
    -H ldaps://dc2.FQDN

The ldap-bind account, needs, no pre-check on kerberos auth and disable passwd expire.

The group part, now im not using it myself but per example. Should be something like this.

Basicly its :
Search for %LOGIN from this point : DC=office,DC=some,DC=domain,DC=tld  And get person-%a from group Proxygroups

external_acl_type ldapgroup %LOGIN /usr/lib/squid/squid_ldap_group -b DC=office,DC=some,DC=domain,DC=tld \
    -f (&(objectclass=person)(cn=%v)(groupMembership=cn=%a,ou=Proxygroups,DC=office,DC=some,DC=domain,DC=tld)) \
    -D ldap-bind at MY_REALM \
    -W /etc/squid/private/ldap-bind \
    -H ldaps://dc1.FQDN \
    -H ldaps://dc2.FQDN


external_acl_type AD_Group %LOGIN /usr/lib64/squid/squid_ldap_group -b DC=office,DC=some,DC=domain,DC=tld \
    -s sub \
    -R -v3 \
    -D ldap-bind at MY_REALM \
    -W /etc/squid/private/ldap-bind \
    -f "(&(objectclass=person)(userPrincipalName=%v)(memberof=cn=%a,ou=Proxygroups,DC=office,DC=some,DC=domain,DC=tld))" \
    -H ldaps://dc1.FQDN \
    -H ldaps://dc2.FQDN

I Hope this helps a bit.

Greetz,

Louis



> -----Oorspronkelijk bericht-----
> Van: squid-users
> [mailto:squid-users-bounces at lists.squid-cache.org] Namens
> Amos Jeffries
> Verzonden: donderdag 21 februari 2019 10:18
> Aan: squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] The issue NTLM_AUTH with
> --require-membership-of
>
> On 21/02/19 9:35 pm, WANG TOM wrote:
> >
> --------------------------------------------------------------
> --------------------------------
> > And I have tested run ntlm_auth directly, it looks successfully.
> > "ntlm_auth --require-membership-of='IBM\Domain Users'
> > --username=Administrators --password=123456
> > NT_STATUS_OK: The operation completed successfully. (0x0)"
> >
> --------------------------------------------------------------
> --------------------------------
> > I have no idea what I have missed or made mistake, could
> someone can help.
> >
>
> Very likely that whitespace in the parameter string. Squid does not
> support double-quote encoding of most parameters.
>
> That means the helper will be passed two different environment
> arguments.  One being "--require-membership-of='IBM\Domain".
> The second being "Users'"
>
> IIRC you can probably %-encode that (as "IBM\Domain%20Users").
>
>
> If not that then you are going to have to debug what the
> helper is doing.
>
>
> NP: This helper is provided by Samba, it is not part of Squid. So
> questions about its abilities and encodings supported are a
> question for
> their help channels. Someone here _might_ know, but do not
> count on that.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190222/f5b0416b/attachment.htm>

From m_zouhairy at skno.by  Fri Feb 22 08:48:49 2019
From: m_zouhairy at skno.by (Vacheslav Zouhairy)
Date: Fri, 22 Feb 2019 11:48:49 +0300
Subject: [squid-users] Squid proxies won't pop up authentication or even
 attempt
In-Reply-To: <1550816755507-0.post@n4.nabble.com>
References: <1550816755507-0.post@n4.nabble.com>
Message-ID: <527066fb9ef547e4ebc5db787bb6c0b8cd1b9d01.camel@skno.by>

have you made sure that you clicked use this proxy for all protocols?

On Fri, 2019-02-22 at 00:25 -0600, amlgp wrote:
> Hi all, I've been trying to troubleshoot this for the last 2 days and
> it's
> starting to drive me nuts.
> 
> I am running on a Centos 6 server trying to start up some proxies
> with
> Squid.
> 
> When I manually try to enter my proxy using Firefox, no window pops
> up for
> authentication and I just time out. I have read that this might be
> due to a
> http access or acl error but I can't see anything wrong.
> 
> Steps I have taken so far:
> 
> -Set up network interfaces with Centos(all my IP's ping correctly
> from
> inside the server and outside the server)
> -Set up squid.conf with acl and userpass authentication
> 
> Squid version: squid-3.1.23-24.el6.x86_64
> 
> Access logs are empty, error logs are currently empty in
> /var/log/squid/squid.out after I fixed the visible_hostname error.
> Squid
> starts/restarts/stops without errors.
> 
> 
> I have tried using the actual hostname that shows up when using the
> "hostname" command and there are no changes, so I just replaced it
> with
> localhost instead.
> 
> Also, abc 123 x are real numbers, and the IP pings but the exact
> numbers
> have been replaced for this post.
> 
> Does anyone see what the problem might be? Thank you in advance!
> 
> 
> 
> --
> Sent from: 
> http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users




From chip_pop at hotmail.com  Fri Feb 22 09:31:18 2019
From: chip_pop at hotmail.com (joseph)
Date: Fri, 22 Feb 2019 03:31:18 -0600 (CST)
Subject: [squid-users] squid-5.0.0-20190221-re008097c6
In-Reply-To: <8c282645-c2b1-3ea6-6d46-70d28ecdc4d5@measurement-factory.com>
References: <1550796695494-0.post@n4.nabble.com>
 <1550797217337-0.post@n4.nabble.com>
 <8c282645-c2b1-3ea6-6d46-70d28ecdc4d5@measurement-factory.com>
Message-ID: <1550827878883-0.post@n4.nabble.com>

alex its essay i do download patch by patch and do my Owen test
wen i have problem to make sure i download Latest 5.x series release and
test again
to match my problem if its bobo i made or its bug that you guys made
no auto!!!!!!!! at all  
hard work manual test is best friend
notice the Subject ^^   squid-5.0.0-20190221-re008097c6 its Latest 5.x
series release



-----
************************** 
***** Crash to the future  ****
**************************
--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From chip_pop at hotmail.com  Fri Feb 22 10:02:47 2019
From: chip_pop at hotmail.com (joseph)
Date: Fri, 22 Feb 2019 04:02:47 -0600 (CST)
Subject: [squid-users] squid-5.0.0-20190221-re008097c6
In-Reply-To: <8c282645-c2b1-3ea6-6d46-70d28ecdc4d5@measurement-factory.com>
References: <1550796695494-0.post@n4.nabble.com>
 <1550797217337-0.post@n4.nabble.com>
 <8c282645-c2b1-3ea6-6d46-70d28ecdc4d5@measurement-factory.com>
Message-ID: <1550829767915-0.post@n4.nabble.com>

please re test
Proposed fix is at https://github.com/squid-cache/squid/pull/375 did not
help fixing all
proxyp/Elements.h
#ifndef SQUID_PROXYP_ELEMENTS_H
#define SQUID_PROXYP_ELEMENTS_H

#include "sbuf/SBuf.h"
#include <map>
#include <unordered_map>
fix that and more problem after

In file included from Header.cc:11:
../../src/proxyp/Header.h:24:18: error: ???vector??? in namespace ???std???
does not name a template type
     typedef std::vector<Two::Tlv> Tlvs;
                  ^~~~~~
../../src/proxyp/Header.h:24:13: note: ???std::vector??? is defined in
header ???<vector>???; did you forget to ???#include <vector>????
../../src/proxyp/Header.h:14:1:
+#include <vector>

who know after wat will happen 



-----
************************** 
***** Crash to the future  ****
**************************
--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Fri Feb 22 10:04:16 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 22 Feb 2019 23:04:16 +1300
Subject: [squid-users] Squid proxies won't pop up authentication or even
 attempt
In-Reply-To: <1550816755507-0.post@n4.nabble.com>
References: <1550816755507-0.post@n4.nabble.com>
Message-ID: <4c2db527-69fd-0176-524a-510776bfc5b1@treenet.co.nz>

On 22/02/19 7:25 pm, amlgp wrote:
> Hi all, I've been trying to troubleshoot this for the last 2 days and it's
> starting to drive me nuts.
> 
> I am running on a Centos 6 server trying to start up some proxies with
> Squid.
> 
> When I manually try to enter my proxy using Firefox, no window pops up for
> authentication and I just time out.

Please be aware that lack of popups does not mean lack of
authentication. If the Browser is already aware of the credentials it is
expected to use from some earlier interaction it *should* be using them
seamlessly without popups.

>From your description above your actual problem is whatever causes the
timeout. That may not be related to authentication, and given your
config below they are not related here either.


Timeouts without a clearly visible error message are more usually
related to the TCP/UDP level connectivity. DNS resolving taking
extremely long times, TCP connections getting lost in routing, NAT
misconfiguration, firewalls dropping packets, Path-MTU problems, and
other things like those.


> I have read that this might be due to a
> http access or acl error but I can't see anything wrong.

You have an order issue with the auth config. More details inline below.
The timeout is a different problem.


> 
> Steps I have taken so far:
> 
> -Set up network interfaces with Centos(all my IP's ping correctly from
> inside the server and outside the server)

By "from outside the server" do you mean from some other test machine or
from the client machine where your Firefox is running?


> -Set up squid.conf with acl and userpass authentication
> > Squid version: squid-3.1.23-24.el6.x86_64
> 

Since this is a new installation please start by trying an up to date
Squid version. This month we are up to v4.6.

You can find newer packages for CentOS in Eliezers repository referenced
from <https://wiki.squid-cache.org/KnowledgeBase/CentOS>.


> Access logs are empty, error logs are currently empty in
> /var/log/squid/squid.out after I fixed the visible_hostname error. Squid
> starts/restarts/stops without errors.
> 

[ Nabble omitted the config details for some reason. I have re-pasted
the non-default config settings in here. ]

...
> 
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
> 
> # And finally deny all other access to this proxy
> http_access deny all
> 

Here is the start of your *auth* problem. Any http_access lines after
here are irrelevant.

The above rules should be letting clients through just fine without
authentication. So the auth behaviour is most likely a secondary issue
not related to the timeout.


> # Squid normally listens to port 3128
> http_port 3128
> 
...
> 
> acl my_ip_198_abc_123_x myip 198.abc.123.x
> tcp_outgoing_address 198.abc.123.x my_ip_198_abc_123_x

Any particular reason for this?

* Squid will default to letting the OS select outgoing IP based on the
rout the connection needs to travel.

* In such old Squid this will break when contacting IPv6 servers. Newer
Squid resolve that by ignoring impossible config requirements.


I suspect these lines are probably why the timeout behaviour is
happening, or that the real problem is something else that led you to
adding these as a workaround.


> 
> auth_param basic program /usr/lib64/squid/ncsa_auth /etc/squid/passwords
> auth_param basic children 5
> auth_param basic realm proxy

> acl ncsa_users proxy_auth REQUIRED
> http_access allow ncsa_users

 ... these rules of yours should be up in the area just below that line
which clearly says "INSERT YOUR OWN RULE(S) HERE".


Also, "allow" action does not require credentials. It only uses
credentials when they are presented and lets other rules do the denial.
Similarly the "REQUIRED" keyword in the ACL only required that the login
presented is correct It does not fetch credentials from the user.
So, unless those other followup denial rules also use credentials the
authentication may never happen.

It is best to do like so:

 http_access deny !ncsa_users
 http_access allow localnet


Also, the fact of the users being in NCSA is only relevant to the helper
and already clear from the name of the helper being used. If you ever
move to a different auth system, different helper (eg PAM), or even
multiple ways to login. That ACL name will become confusing and maybe
incorrect. I recommend 'login' or 'auth' as less confusing names that
help make future changes smaller.


> 
> visible_hostname localhost
>
> 
> I have tried using the actual hostname that shows up when using the
> "hostname" command and there are no changes, so I just replaced it with
> localhost instead.

I'm not sure exactly what you mean by "the visible_hostname error".
There are a few. Usually this displays messages when the hostname is not
able to resolve in DNS.

If Squid is unable to locate the host name, using the one presented by
the 'hostname' command is right. In full for FQDN, or as a subdomain of
your network domain if not.

Keeping in mind that the hostname should be an FQDN that machines in
your network can resolve with that networks DNS (or mDNS in the case of
'.local' TLD names). Newer Squid deal with these things far better and
will default to localhost without you having to do anything.


HTH
Amos


From chip_pop at hotmail.com  Fri Feb 22 10:10:23 2019
From: chip_pop at hotmail.com (joseph)
Date: Fri, 22 Feb 2019 04:10:23 -0600 (CST)
Subject: [squid-users] squid-5.0.0-20190221-re008097c6
In-Reply-To: <8c282645-c2b1-3ea6-6d46-70d28ecdc4d5@measurement-factory.com>
References: <1550796695494-0.post@n4.nabble.com>
 <1550797217337-0.post@n4.nabble.com>
 <8c282645-c2b1-3ea6-6d46-70d28ecdc4d5@measurement-factory.com>
Message-ID: <1550830223507-0.post@n4.nabble.com>

after all those missing include 
and aded missing #include <vector> to proxyp/Header.h

another issue
pconn.cc: In member function ???void PconnPool::push(const
ConnectionPointer&, const char*)???:
pconn.cc:435:32: error: ???%s??? directive output may be truncated writing
up to 777 bytes into a region of size 51 [-Werror=format-truncation=]
     snprintf(desc, FD_DESC_SZ, "Idle server: %s", aKey);
                                ^~~~~~~~~~~~~~~~~
pconn.cc:435:13: note: ???snprintf??? output between 14 and 791 bytes into a
destination of size 64
     snprintf(desc, FD_DESC_SZ, "Idle server: %s", aKey);
     ~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
ps...still using squid-5.0.0-20190221-re008097c6 Latest 5.x series release
as test to do all this patches 



-----
************************** 
***** Crash to the future  ****
**************************
--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From dvanorder at deloitte.com  Fri Feb 22 13:32:27 2019
From: dvanorder at deloitte.com (Van Order, Drew (US - Hermitage))
Date: Fri, 22 Feb 2019 13:32:27 +0000
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
Message-ID: <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>

The test box I set up outside the F5 finally started exhibiting these errors, once I pointed roughly 60 machines to it. It took a few hours. Sounds like this narrows it down to either the OS itself (seems unlikely, other apps would crash), or the litany of agents our security folks have mandated. It may indeed be necessary to move to Linux.

Thank you very much for your time!

-----Original Message-----
From: Amos Jeffries <squid3 at treenet.co.nz>
Sent: Thursday, February 21, 2019 11:31 PM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; squid-users at lists.squid-cache.org
Subject: [EXT] Re: [squid-users] Squid for Windows Repeatedly Crashing

On 22/02/19 4:21 am, Van Order, Drew (US - Hermitage) wrote:
> Thank you for replying, and that's an excellent point.
>
> Short answer--definitely not in a container, these are garden variety VMWare instances. I've already flagged the OS power settings to maximum performance, so nothing should be going to sleep. I'll doublecheck, though.
>
> So, if I understand correctly, this error could also be indicative of an issue in between the agent and Squid. Agents first go through a firewall, then the F5 before reaching Squid.

No that is not what I meant.

The port Squid has already opened and used syscall listen(2) on is what is being closed (or its address corrupted) outside of Squid. That should only ever be closed by Squid itself. Thus the error.

It is being closed repeatedly. Thus the abort/shutdown. This is not a crash, it is intentional shutdown by Squid due to these fatal
(non-recoverable) errors.


>
> [Stopped, reason:Listener socket closed job1]: (14) Bad address
>
> Any thoughts on this error, which tends to be more common than the other?
>
> 2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
> 2019/02/20 09:42:33 kid1| Select loop Error. Retry 2
>

Notice how the error from the OS "(14) Bad Address" is the same. This is just another display of the same problem. Maybe the poll() layer reporting the exact same error as Squid tries to recover. Maybe for other non-listener ports also being corrupted somehow.

If non-listener ports are having that same error it would be a sign the machine memory is being corrupted rather than other software touching the listener ports specifically.


( The details you have provided so far have no hints about where the problem may be coming from, and I am not having any ideas about possibilities either. I just hope the above explanation of meaning can help you think of things to look at for more hints on this very weird issue. )

Amos
This message (including any attachments) contains confidential information intended for a specific individual and purpose, and is protected by law. If you are not the intended recipient, you should delete this message and any disclosure, copying, or distribution of this message, or the taking of any action based on it, by you is strictly prohibited.

v.E.1

From david at articatech.com  Fri Feb 22 13:45:55 2019
From: david at articatech.com (David Touzeau)
Date: Fri, 22 Feb 2019 14:45:55 +0100
Subject: [squid-users] Squid 4.x: cache_peer PROXY_PROTOCOL support with
	squid parents
Message-ID: <015f01d4cab4$ef806480$ce812d80$@articatech.com>

Hi, 

 

We would like to use this infrastructure:

 

Squid-cache client authentication 1--------  

 
| ----> Squid Parent with ACLs per user/LDAP groups/Web filtering --->
INTERNET

Squid-cache client authentication 2 --------

 

 

Currently this kind of infrastructure cannot be done because the Squid that
acts as a client did not send credentials information to the parent proxy.

 

We think it should be done if the cache_peer is compliance with
PROXY_PROTOCOL rfc as the http_port is already compliance.

 

 

Do you have plans to add PROXY_PROTOCOL inside cache_peer feature ?

 

 

Best regards 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190222/d82e4f77/attachment.htm>

From rousskov at measurement-factory.com  Fri Feb 22 17:23:30 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 22 Feb 2019 10:23:30 -0700
Subject: [squid-users] Websockets over HTTPS not working in squid 4
In-Reply-To: <CADcj3=6cLC3uZFc-yRB76Evsu+NErmmYTSSuexjdRXFvkRauVw@mail.gmail.com>
References: <CADcj3=4moi1mk=fVYUyu-Su6fGbV1DT=Oif7bfmgcqxx1MUbHw@mail.gmail.com>
 <ad87a1d7-52a1-169b-ced8-de3e0f13c194@measurement-factory.com>
 <CADcj3=6cLC3uZFc-yRB76Evsu+NErmmYTSSuexjdRXFvkRauVw@mail.gmail.com>
Message-ID: <2823c617-b97e-879b-ed6d-232b76ee2755@measurement-factory.com>

On 2/21/19 3:19 PM, Felipe Arturo Polanco wrote:

> Are you aware of any unofficial patch or something to tunnel
> websockets?over HTTPS in squid?

Yes, Factory continues to work on this, but I am not ready to recommend
that unofficial code on this mailing list.

Alex.


> On Thu, Feb 21, 2019 at 5:33 PM Alex Rousskov wrote:
> 
>     On 2/21/19 2:11 PM, Felipe Arturo Polanco wrote:
> 
>     > I have been trying to make websockets?work over HTTPS but so far I
>     > haven't been able to.
> 
> 
>     Official Squid cannot reliably detect and proxy native WebSocket
>     traffic. Until that support is available, if WebSocket traffic reaches
>     your intercepting Squid, then splicing suspected WebSocket connections
>     based on TCP/TLS-level information is your only option. And, yes, that
>     introduces lots of maintenance headaches, policy violations, and is not
>     reliable.
> 
>     A bit more information about the topic is available on this 2018 thread:
>     http://lists.squid-cache.org/pipermail/squid-users/2018-July/018581.html
> 
>     Alex.
> 
> 
>     > I'm trying the following websites that use websockets and none of
>     them work:
>     > speedtest.net <http://speedtest.net> <http://speedtest.net>
>     > web.whatsapp.com <http://web.whatsapp.com> <http://web.whatsapp.com>
>     > https://slack.com/help/test
>     >
>     > If I explicitly splice those domain names in squid.conf they work
>     fine.
>     >
>     > I'm not interested in bumping the websockets, I just want HTTPS
>     > interception to work as well as websockets.
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
> 



From rousskov at measurement-factory.com  Fri Feb 22 17:47:40 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 22 Feb 2019 10:47:40 -0700
Subject: [squid-users] squid-5.0.0-20190221-re008097c6
In-Reply-To: <1550827878883-0.post@n4.nabble.com>
References: <1550796695494-0.post@n4.nabble.com>
 <1550797217337-0.post@n4.nabble.com>
 <8c282645-c2b1-3ea6-6d46-70d28ecdc4d5@measurement-factory.com>
 <1550827878883-0.post@n4.nabble.com>
Message-ID: <db72623c-818e-053b-01ff-78c26c4aa5c7@measurement-factory.com>

On 2/22/19 2:31 AM, joseph wrote:
> alex its essay i do download patch by patch and do my Owen test
> wen i have problem to make sure i download Latest 5.x series release and
> test again
> to match my problem if its bobo i made or its bug that you guys made
> no auto!!!!!!!! at all  
> hard work manual test is best friend
> notice the Subject ^^   squid-5.0.0-20190221-re008097c6 its Latest 5.x
> series release

FWIW, I do not know why you are saying the above. If you meant to ask a
question or disagree with something others said on this thread, please
rephrase. However, as Amos has said, we should not be discussing v5
(i.e., the current "master" branch) build problems on the squid-users
mailing list right now.

Alex.


From rousskov at measurement-factory.com  Fri Feb 22 18:05:34 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 22 Feb 2019 11:05:34 -0700
Subject: [squid-users] squid-5.0.0-20190221-re008097c6
In-Reply-To: <1550830223507-0.post@n4.nabble.com>
References: <1550796695494-0.post@n4.nabble.com>
 <1550797217337-0.post@n4.nabble.com>
 <8c282645-c2b1-3ea6-6d46-70d28ecdc4d5@measurement-factory.com>
 <1550830223507-0.post@n4.nabble.com>
Message-ID: <12dbfbd7-1da6-722b-cb5e-e7d6d770f8d8@measurement-factory.com>

On 2/22/19 3:10 AM, joseph wrote:

> aded missing #include <vector> to proxyp/Header.h

Probably fixed at https://github.com/squid-cache/squid/pull/376


> another issue
> pconn.cc: In member function ???void PconnPool::push(const
> ConnectionPointer&, const char*)???:
> pconn.cc:435:32: error: ???%s??? directive output may be truncated writing
> up to 777 bytes into a region of size 51 [-Werror=format-truncation=]
>      snprintf(desc, FD_DESC_SZ, "Idle server: %s", aKey);
>                                 ^~~~~~~~~~~~~~~~~
> pconn.cc:435:13: note: ???snprintf??? output between 14 and 791 bytes into a
> destination of size 64
>      snprintf(desc, FD_DESC_SZ, "Idle server: %s", aKey);
>      ~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

That sounds related to the following PR, but that PR is older and has
many more changes than just the build fix so apply with extra caution:
https://github.com/squid-cache/squid/pull/270


For the time being, to avoid annoying other mailing list subscribers
further, I am going to ignore squid-users emails related to problems
with building Squid v5/master.

Alex.


From squid3 at treenet.co.nz  Sat Feb 23 03:06:59 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 23 Feb 2019 16:06:59 +1300
Subject: [squid-users] Squid 4.x: cache_peer PROXY_PROTOCOL support with
 squid parents
In-Reply-To: <015f01d4cab4$ef806480$ce812d80$@articatech.com>
References: <015f01d4cab4$ef806480$ce812d80$@articatech.com>
Message-ID: <81814bd0-7c59-9156-d8a5-fa84528ebf87@treenet.co.nz>

On 23/02/19 2:45 am, David Touzeau wrote:
> Hi,
> 
> ?
> 
> We would like to use this infrastructure:
> 
> ?
> 
> Squid-cache client authentication 1--------?
> 
> ??????????????????????????????????????????????????????????????????????????????
> ???| ----> Squid Parent with ACLs per user/LDAP groups/Web filtering
> ---> INTERNET
> 
> Squid-cache client authentication 2 --------
> 
> ?
> 
> ?
> 
> Currently this kind of infrastructure cannot be done because the Squid
> that acts as a client did not send credentials information to the parent
> proxy.
> 

There are many types of "client authentication" that can exist in
multiple nested protocol layers:

* HTTP WWW-Auth* credentials

* HTTP Proxy-Auth* credentials

* TLS client X.509 certificate

* CONNECT tunnel Proxy-Auth*

* TCP connection-auth scheme credentials (NTLM, Negotiate)

* IPSEC key exchange

* EUI

* IDENT user name

Which one(s) are you talking about?


> 
> We think it should be done if the cache_peer is compliance with
> PROXY_PROTOCOL rfc as the http_port is already compliance.
> 

What are you thinking PROXY would be doing to help with the situation?

Keep in mind that the PROXY header needs to be sent before any other
bytes on the server connection. Which immediately limits the cases where
any type of client information is available.


> 
> Do you have plans to add PROXY_PROTOCOL inside cache_peer feature ?
> 
> ?

To whom are you addressing this question?


Cheers,
Amos


From david at articatech.com  Sat Feb 23 16:30:58 2019
From: david at articatech.com (David Touzeau)
Date: Sat, 23 Feb 2019 17:30:58 +0100
Subject: [squid-users] Squid 4.x: cache_peer PROXY_PROTOCOL support with
	squid parents
In-Reply-To: <81814bd0-7c59-9156-d8a5-fa84528ebf87@treenet.co.nz>
References: <015f01d4cab4$ef806480$ce812d80$@articatech.com>
 <81814bd0-7c59-9156-d8a5-fa84528ebf87@treenet.co.nz>
Message-ID: <006a01d4cb95$289a6640$79cf32c0$@articatech.com>


Currently we are working on Kerberos with Active Directory with Ha-proxy 
that
sends requests to squid using proxy_protocol.
Everything works great but we want to replace the ha-proxy with a squid.
In fact, we want to the squid client send the credentials information to a
squid parent in order to centralize ACLs on the parent proxy according to 
the user's login name.
If you have any suggestion ?

Best regards




-----Message d'origine-----
De : squid-users <squid-users-bounces at lists.squid-cache.org> De la part de
Amos Jeffries
Envoy? : samedi 23 f?vrier 2019 04:07
? : squid-users at lists.squid-cache.org
Objet : Re: [squid-users] Squid 4.x: cache_peer PROXY_PROTOCOL support with
squid parents

On 23/02/19 2:45 am, David Touzeau wrote:
> Hi,
>
>
>
> We would like to use this infrastructure:
>
>
>
> Squid-cache client authentication 1--------
>
>
>    | ----> Squid Parent with ACLs per user/LDAP groups/Web filtering
> ---> INTERNET
>
> Squid-cache client authentication 2 --------
>
>
>
>
>
> Currently this kind of infrastructure cannot be done because the Squid
> that acts as a client did not send credentials information to the
> parent proxy.
>

There are many types of "client authentication" that can exist in multiple
nested protocol layers:

* HTTP WWW-Auth* credentials

* HTTP Proxy-Auth* credentials

* TLS client X.509 certificate

* CONNECT tunnel Proxy-Auth*

* TCP connection-auth scheme credentials (NTLM, Negotiate)

* IPSEC key exchange

* EUI

* IDENT user name

Which one(s) are you talking about?


>
> We think it should be done if the cache_peer is compliance with
> PROXY_PROTOCOL rfc as the http_port is already compliance.
>

What are you thinking PROXY would be doing to help with the situation?

Keep in mind that the PROXY header needs to be sent before any other bytes
on the server connection. Which immediately limits the cases where any type
of client information is available.


>
> Do you have plans to add PROXY_PROTOCOL inside cache_peer feature ?
>
>

To whom are you addressing this question?


Cheers,
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From david at articatech.com  Sat Feb 23 16:33:19 2019
From: david at articatech.com (David Touzeau)
Date: Sat, 23 Feb 2019 17:33:19 +0100
Subject: [squid-users] squid 4.x: decided: do not cache but share because
	the entry has been released
Message-ID: <007f01d4cb95$7cb50230$761f0690$@articatech.com>

Hi

 

I'm trying to store in cache an Internet file

 

Run the squid in debug mode says: 

 

http.cc(982) haveParsedReplyHeaders: decided: do not cache but share because
the entry has been released; HTTP status 200

 

What "but share because the entry has been released" event means ?

 

 

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190223/22ac8ddf/attachment.htm>

From squid3 at treenet.co.nz  Sat Feb 23 17:03:18 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 24 Feb 2019 06:03:18 +1300
Subject: [squid-users] Squid 4.x: cache_peer PROXY_PROTOCOL support with
 squid parents
In-Reply-To: <006a01d4cb95$289a6640$79cf32c0$@articatech.com>
References: <015f01d4cab4$ef806480$ce812d80$@articatech.com>
 <81814bd0-7c59-9156-d8a5-fa84528ebf87@treenet.co.nz>
 <006a01d4cb95$289a6640$79cf32c0$@articatech.com>
Message-ID: <cd348de5-4d31-7f85-c0d7-54fa2fb834fa@treenet.co.nz>

On 24/02/19 5:30 am, David Touzeau wrote:
> 
> Currently we are working on Kerberos with Active Directory with Ha-proxy 
> that
> sends requests to squid using proxy_protocol.
> Everything works great but we want to replace the ha-proxy with a squid.
> In fact, we want to the squid client send the credentials information to a
> squid parent in order to centralize ACLs on the parent proxy according to 
> the user's login name.
> If you have any suggestion ?

Hmm, all you should need to do for that is set the "login=PASSTHRU"
option on the cache_peer line and *not* configure the first proxy to do
anything with authentication.


Amos


From squid3 at treenet.co.nz  Sat Feb 23 17:17:18 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 24 Feb 2019 06:17:18 +1300
Subject: [squid-users] squid 4.x: decided: do not cache but share
 because the entry has been released
In-Reply-To: <007f01d4cb95$7cb50230$761f0690$@articatech.com>
References: <007f01d4cb95$7cb50230$761f0690$@articatech.com>
Message-ID: <f9a1e8fe-fe95-a399-a2b8-4162a02f7621@treenet.co.nz>

On 24/02/19 5:33 am, David Touzeau wrote:
> Hi
> 
> I?m trying to store in cache an Internet file
> 
> 
> Run the squid in debug mode says:
> 
> http.cc(982) haveParsedReplyHeaders: decided: do not cache but share
> because the entry has been released; HTTP status 200
> 
> What ?but share because the entry has been released? event means ?
> 

That line syntax is "decide: X because Y"

'do not cache but share' means the reply may still be shared with other
concurrent clients (eg. collapsed forwarding), but not to bother trying
to cache it.

'entry has been released' means something else already caused the disk
copy in cache to be removed or replaced.

Amos


From eliezer at ngtech.co.il  Sat Feb 23 18:00:38 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Sat, 23 Feb 2019 20:00:38 +0200
Subject: [squid-users] Websockets over HTTPS not working in squid 4
In-Reply-To: <CADcj3=6cLC3uZFc-yRB76Evsu+NErmmYTSSuexjdRXFvkRauVw@mail.gmail.com>
References: <CADcj3=4moi1mk=fVYUyu-Su6fGbV1DT=Oif7bfmgcqxx1MUbHw@mail.gmail.com>
 <ad87a1d7-52a1-169b-ced8-de3e0f13c194@measurement-factory.com>
 <CADcj3=6cLC3uZFc-yRB76Evsu+NErmmYTSSuexjdRXFvkRauVw@mail.gmail.com>
Message-ID: <04e201d4cba1$af3d2460$0db76d20$@ngtech.co.il>

I can think of a way to try and "amend" on an error in the next websocket
connection automatically.
I believe that using an ICAP service or eCAP module that is connected to an
external acl helper you can see if specific requests for specific domains
are trying to use websockets.
Technically the basic request and response can identify such sites with the
upgrade headers.
So if something can see this and decide that a the requested domain will be
spliced next time the clients connect to it, it's possible to do so.
It's risky if you have a secured environment unless you have a set of top
level domains such as ".whatsapp.com".
I believe that we can open a list of services that must have websockets
enabled and/or being spliced and not intercepted.
 
I can start with vcenter web management services that must support
websockets.
*	Slack
*	Whatsapp
*	Others
 
If you are willing to share a set of domains that will be added to the wiki
as a "websocket" required for this service or set of domains wiki
I might be able to pull it off and write this ICAP service.
 
Eliezer
 
----
 <http://ngtech.co.il/main-en/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email:  <mailto:eliezer at ngtech.co.il> eliezer at ngtech.co.il

 
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
Felipe Arturo Polanco
Sent: Friday, February 22, 2019 00:20
To: Alex Rousskov <rousskov at measurement-factory.com>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Websockets over HTTPS not working in squid 4
 
I see.
 
Are you aware of any unofficial patch or something to tunnel websockets over
HTTPS in squid?
 
 
 
On Thu, Feb 21, 2019 at 5:33 PM Alex Rousskov
<rousskov at measurement-factory.com <mailto:rousskov at measurement-factory.com>
> wrote:
On 2/21/19 2:11 PM, Felipe Arturo Polanco wrote:

> I have been trying to make websockets work over HTTPS but so far I
> haven't been able to.


Official Squid cannot reliably detect and proxy native WebSocket
traffic. Until that support is available, if WebSocket traffic reaches
your intercepting Squid, then splicing suspected WebSocket connections
based on TCP/TLS-level information is your only option. And, yes, that
introduces lots of maintenance headaches, policy violations, and is not
reliable.

A bit more information about the topic is available on this 2018 thread:
http://lists.squid-cache.org/pipermail/squid-users/2018-July/018581.html

Alex.


> I'm trying the following websites that use websockets and none of them
work:
> speedtest.net <http://speedtest.net>  <http://speedtest.net>
> web.whatsapp.com <http://web.whatsapp.com>  <http://web.whatsapp.com>
> https://slack.com/help/test
> 
> If I explicitly splice those domain names in squid.conf they work fine.
> 
> I'm not interested in bumping the websockets, I just want HTTPS
> interception to work as well as websockets.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>

http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190223/ec531792/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11295 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190223/ec531792/attachment.png>

From eliezer at ngtech.co.il  Sat Feb 23 18:15:50 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Sat, 23 Feb 2019 20:15:50 +0200
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
 <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
Message-ID: <04fc01d4cba3$ce63ecf0$6b2bc6d0$@ngtech.co.il>

The next tool might help you to understand the status of the open
connections.
If the socket is being closed( I think Windows Server 2016 is a very good
OS...).
https://www.nirsoft.net/utils/cports.html

There is a possibility that some OS TCP limit is being reached and there for
the socket closure.
If you are using F5 you can easily find out the load at the crash point.
I assume that if a normal Squid instance can take a load of 900k requests
per second in somewhat constant rate for more then a minute then the issue
might be else where then squid.
I am not sure but pretty sure that if you do not have anyone that is
knowledgeable enough about windows sockets, sessions and FW limitations you
will either:
- learn it your self
- find an expert
- use an OS that is more then 20% supported by any of the Squid-Cache team
members and other developers around the globe.

Just to say a good word about Windows Server 2016, I compared it to a
Windows 10 under load and it seems to take a lot more load.
Also it not just takes the load but balance it well (on an open source
windows designed software).

Also if you have a specific use case maybe a specific proxy can be
customized for it.
Let me know if you wish to shed more details on the configuration so I can
take my time and understand if there is a solution else then Squid.

Eliezeer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
Van Order, Drew (US - Hermitage)
Sent: Friday, February 22, 2019 15:32
To: Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing

The test box I set up outside the F5 finally started exhibiting these
errors, once I pointed roughly 60 machines to it. It took a few hours.
Sounds like this narrows it down to either the OS itself (seems unlikely,
other apps would crash), or the litany of agents our security folks have
mandated. It may indeed be necessary to move to Linux.

Thank you very much for your time!

-----Original Message-----
From: Amos Jeffries <squid3 at treenet.co.nz>
Sent: Thursday, February 21, 2019 11:31 PM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>;
squid-users at lists.squid-cache.org
Subject: [EXT] Re: [squid-users] Squid for Windows Repeatedly Crashing

On 22/02/19 4:21 am, Van Order, Drew (US - Hermitage) wrote:
> Thank you for replying, and that's an excellent point.
>
> Short answer--definitely not in a container, these are garden variety
VMWare instances. I've already flagged the OS power settings to maximum
performance, so nothing should be going to sleep. I'll doublecheck, though.
>
> So, if I understand correctly, this error could also be indicative of an
issue in between the agent and Squid. Agents first go through a firewall,
then the F5 before reaching Squid.

No that is not what I meant.

The port Squid has already opened and used syscall listen(2) on is what is
being closed (or its address corrupted) outside of Squid. That should only
ever be closed by Squid itself. Thus the error.

It is being closed repeatedly. Thus the abort/shutdown. This is not a crash,
it is intentional shutdown by Squid due to these fatal
(non-recoverable) errors.


>
> [Stopped, reason:Listener socket closed job1]: (14) Bad address
>
> Any thoughts on this error, which tends to be more common than the other?
>
> 2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
> 2019/02/20 09:42:33 kid1| Select loop Error. Retry 2
>

Notice how the error from the OS "(14) Bad Address" is the same. This is
just another display of the same problem. Maybe the poll() layer reporting
the exact same error as Squid tries to recover. Maybe for other non-listener
ports also being corrupted somehow.

If non-listener ports are having that same error it would be a sign the
machine memory is being corrupted rather than other software touching the
listener ports specifically.


( The details you have provided so far have no hints about where the problem
may be coming from, and I am not having any ideas about possibilities
either. I just hope the above explanation of meaning can help you think of
things to look at for more hints on this very weird issue. )

Amos
This message (including any attachments) contains confidential information
intended for a specific individual and purpose, and is protected by law. If
you are not the intended recipient, you should delete this message and any
disclosure, copying, or distribution of this message, or the taking of any
action based on it, by you is strictly prohibited.

v.E.1
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From hsaltiel at gmail.com  Sat Feb 23 20:55:23 2019
From: hsaltiel at gmail.com (Hernan Saltiel)
Date: Sat, 23 Feb 2019 17:55:23 -0300
Subject: [squid-users] Issues With 3.1.20 and Windows Update
Message-ID: <CAMXef5JNjWc9D9n13RbAta4wJApW9s=HCiYmmF5LKCsC3WbPaA@mail.gmail.com>

Hi,
    I'm trying to use a Squid 3.1.20 to update several Windows Clientes
(some are Vista, some are 7, some are 10).
    We're using NTLM authentication, and some groups (some users can use
full internet, some can only on some sites) and this is working fine.
    The issue arises when trying to update Windows, using automatic
updates. We see, on the log files, messages like the following:

1550954462.404      0 192.168.42.121 TCP_DENIED/407 3980 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab?
- NONE/- text/html
1550954462.410      0 192.168.42.121 TCP_DENIED/407 4261 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab?
- NONE/- text/html
1550954462.415      0 192.168.42.121 TCP_DENIED/407 4635 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab?
- NONE/- text/html

    Some aspects concerns me...first of all, that our users cannot update
Windows. But then I noticed there is no user on that connection, as we have
in other:

1550954433.432    581 192.168.62.58 TCP_MISS/200 2853 CONNECT
gameplay.intel.com:443 *jperez* DIRECT/23.198.191.99 -

    I don't know if this is a known issue, or not...anybody can point me in
the right direction to understand the nature of this issue, and how to
solve/mitigate it?

    Thanks a lot in advance for your time and attention and best regards,

---
Some information about this installation:

root at pxyserver:/var/log/squid3# squid3 -version
Squid Cache: Version 3.1.20
configure options:  '--build=i486-linux-gnu' '--prefix=/usr'
'--includedir=${prefix}/include' '--mandir=${prefix}/share/man'
'--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var'
'--libexecdir=${prefix}/lib/squid3' '--srcdir=.'
'--disable-maintainer-mode' '--disable-dependency-tracking'
'--disable-silent-rules' '--datadir=/usr/share/squid3'
'--sysconfdir=/etc/squid3' '--mandir=/usr/share/man'
'--with-cppunit-basedir=/usr' '--enable-inline' '--enable-async-io=8'
'--enable-storeio=ufs,aufs,diskd' '--enable-removal-policies=lru,heap'
'--enable-delay-pools' '--enable-cache-digests' '--enable-underscores'
'--enable-icap-client' '--enable-follow-x-forwarded-for'
'--enable-auth=basic,digest,ntlm,negotiate'
'--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM'
'--enable-ntlm-auth-helpers=smb_lm,'
'--enable-digest-auth-helpers=ldap,password'
'--enable-negotiate-auth-helpers=squid_kerb_auth'
'--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,wbinfo_group'
'--enable-arp-acl' '--enable-esi' '--enable-zph-qos' '--enable-wccpv2'
'--disable-translation' '--with-logdir=/var/log/squid3'
'--with-pidfile=/var/run/squid3.pid' '--with-filedescriptors=65536'
'--with-large-files' '--with-default-user=proxy' '--enable-linux-netfilter'
'build_alias=i486-linux-gnu' 'CFLAGS=-g -O2 -fPIE -fstack-protector
--param=ssp-buffer-size=4 -Wformat -Werror=format-security -Wall'
'LDFLAGS=-fPIE -pie -Wl,-z,relro -Wl,-z,now' 'CPPFLAGS=-D_FORTIFY_SOURCE=2'
'CXXFLAGS=-g -O2 -fPIE -fstack-protector --param=ssp-buffer-size=4 -Wformat
-Werror=format-security'
--with-squid=/build/buildd-squid3_3.1.20-2.2-i386-3NN6Xn/squid3-3.1.20

/etc/squid3/squid.conf:

cache_mgr cache at mydomain.local
auth_param negotiate program /usr/local/bin/negotiate_wrapper --ntlm
/usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp
--domain=MYDOMAIN --kerberos /usr/lib/squid3/squid_kerb_auth -d -s
GSS_C_NO_NAME
auth_param negotiate children 10
auth_param negotiate keep_alive off
auth_param ntlm program /usr/bin/ntlm_auth --diagnostics
--helper-protocol=squid-2.5-ntlmssp --domain=MYDOMAIN
auth_param ntlm children 10
auth_param ntlm keep_alive off
auth_param basic program /usr/lib/squid3/squid_ldap_auth -R -b
"dc=mydomain,dc=local" -D squid at mydomain.local -W /etc/squid3/ldappass.txt
-f sAMAccountName=%s -h ARBERN005M.mydomain.local
auth_param basic children 10
auth_param basic realm Internet Proxy
auth_param basic credentialsttl 1 minute
external_acl_type memberof %LOGIN /usr/lib/squid3/squid_ldap_group -R -K -b
"dc=mydomain,dc=local" -D squid at mydomain.local -W /etc/squid3/ldappass.txt
-f
"(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,cn=Users,dc=mydomain,dc=local))"
-h ARBERN005M.mydomain.local
acl company src "/etc/squid3/full"
acl limitados src "/etc/squid3/limitados"
acl lentos src "/etc/squid3/lento"
acl all src all
acl manager proto cache_object
acl localhost src 127.0.0.1/32
acl to_localhost dst 127.0.0.0/8
acl purge method PURGE
acl dnld url_regex -i \.avi
acl dnld url_regex -i \.mp3
acl dnld url_regex -i \.fla
acl dnld url_regex -i \.flv
acl dnld url_regex -i \.wav
acl dnld url_regex -i \.asf
acl dnld url_regex -i \.wmf
acl dnld url_regex -i \.pif
acl dnld url_regex -i \.bat
acl dnld url_regex -i \.scr
acl dnld url_regex -i \.wdm
acl dnld url_regex -i \.wmv
acl dnld url_regex -i \.mid
acl dnld url_regex -i \.mpg
acl dnld url_regex -i \.mpg
acl dnld url_regex -i \.mpeg
acl dnld url_regex -i \.ogg
acl dnld url_regex -i \.ogm
acl dnld url_regex -i \.exe
acl dnld url_regex -i \.arj
acl dnld url_regex -i \.iso
acl dnld url_regex -i \.nrg
acl dnld url_regex -i \.bin
acl dnld url_regex -i \.dmg
acl dnld url_regex -i \.img
acl dnld url_regex -i \.pl
acl dnld_full url_regex -i \.avi
acl dnld_full url_regex -i \.mp3
acl dnld_full url_regex -i \.wav
acl dnld_full url_regex -i \.asf
acl dnld_full url_regex -i \.wmf
acl dnld_full url_regex -i \.mpg
acl dnld_full url_regex -i \.mpg
acl dnld_full url_regex -i \.mpeg
acl dnld_full url_regex -i \.ogg
acl dnld_full url_regex -i \.ogm
acl streaming browser -i ^.*NSPlayer.*
acl streaming browser -i ^.*Player.*
acl streaming browser -i ^.*Windows-Media-Player.*
acl streaming1 browser -i ^video/x-ms-asf$
acl streaming1 browser -i ^application/vnd.ms.wms-hdr.asfv1$
acl streaming1 browser -i ^application/x-mms-framed$
acl streaming1 browser -i ^audio/x-pn-realaudio$
acl streaming1 browser ^.*mms.*
acl streaming1 browser ^.*ms-hdr.*
acl streaming1 browser ^.*x-fcs.*
acl streaming1 browser ^.*x-ms-asf.*
acl streaming1 browser -i ^application/octet-stream$
acl streaming1 browser -i application/octet-stream
delay_pools 1
delay_class 1 1
delay_parameters 1 1000/100
acl dp url_regex \.flv$
acl dp url_regex -i watch?
acl dp url_regex -i youtube
acl dp url_regex -i facebook
delay_access 1 allow dp lentos
acl auth proxy_auth REQUIRED
acl internet_full       external memberof "/etc/squid3/internet_full.txt"
acl internet_limitado   external memberof
"/etc/squid3/internet_limitado.txt"
acl internet_limitado2  external memberof
"/etc/squid3/internet_limitado2.txt"
acl destinos_permitidos         dstdomain "/etc/squid3/destinos_permitidos"
acl destinos_permitidos2        dstdomain "/etc/squid3/destinos_permitidos2"
acl sitios_denegados            dstdomain "/etc/squid3/sitios_denegados"
acl prohibidos                  dstdomain "/etc/squid3/prohibidos.txt"
acl prohibidos-full             dstdomain "/etc/squid3/prohibidos-full.txt"
acl intfull-                    dstdomain "/etc/squid3/intfull-"
acl allowedsites        dstdomain "/etc/squid3/allowedsites.txt"
acl manager proto cache_object
acl SSL_ports port 443
acl CONNECT method CONNECT
http_access allow manager localhost
http_access deny manager
http_access allow localhost
http_access deny !auth
http_access deny sitios_denegados all
http_access allow allowedsites
http_access allow limitados !dnld !streaming !streaming1 !sitios_denegados
http_access allow !dnld !streaming !streaming1 destinos_permitidos
internet_limitado
http_access allow !dnld !streaming !streaming1 destinos_permitidos2
internet_limitado2
http_access allow !dnld_full !streaming !streaming1 !prohibidos-full
internet_full
http_access deny all
access_log /var/log/squid3/access.log squid !allowedsites
http_port 3128
hierarchy_stoplist cgi-bin ?
coredump_dir /var/spool/squid3
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320



-- 
HeCSa
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190223/57a4350c/attachment.htm>

From eliezer at ngtech.co.il  Sat Feb 23 22:15:20 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Sun, 24 Feb 2019 00:15:20 +0200
Subject: [squid-users] Issues With 3.1.20 and Windows Update
In-Reply-To: <CAMXef5JNjWc9D9n13RbAta4wJApW9s=HCiYmmF5LKCsC3WbPaA@mail.gmail.com>
References: <CAMXef5JNjWc9D9n13RbAta4wJApW9s=HCiYmmF5LKCsC3WbPaA@mail.gmail.com>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAC3Lh8CEfTjS4wI0QXcaNncAQAAAAA=@ngtech.co.il>

Just add before the line:
http_access deny !auth
 
a localnet allow windows update rule.
It should be something like:
## Start of config snippet
acl windows_updates  dstdomain "/etc/squid3/windows_update"
acl src locanet 192.168.42.0/24
 
http_access allow localnet windows_updates
http_access deny !auth
 
## End of config snippet
### "/etc/squid3/windows_update? contains
.windowsupdate.com
?
#
Take the regex from the domains refresh_pattern at:
https://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates
and at:
http://www1.ngtech.co.il/wpe/windows-updates-a-caching-stub-zone/
(look for dstdom_regex or download\.microsoft\.com )
 
Let me know if it helps.
 
Eliezer
 
*	Try to upgrade from 3.1 if possible.
*	I probably can compile a newer version for your OS.
 
----
 <http://ngtech.co.il/main-en/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email:  <mailto:eliezer at ngtech.co.il> eliezer at ngtech.co.il

 
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Hernan Saltiel
Sent: Saturday, February 23, 2019 22:55
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Issues With 3.1.20 and Windows Update
 
Hi,
    I'm trying to use a Squid 3.1.20 to update several Windows Clientes (some are Vista, some are 7, some are 10).
    We're using NTLM authentication, and some groups (some users can use full internet, some can only on some sites) and this is working fine. 
    The issue arises when trying to update Windows, using automatic updates. We see, on the log files, messages like the following: 
 
1550954462.404      0 192.168.42.121 TCP_DENIED/407 3980 GET http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab? - NONE/- text/html
1550954462.410      0 192.168.42.121 TCP_DENIED/407 4261 GET http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab? - NONE/- text/html
1550954462.415      0 192.168.42.121 TCP_DENIED/407 4635 GET http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab? - NONE/- text/html
   
    Some aspects concerns me...first of all, that our users cannot update Windows. But then I noticed there is no user on that connection, as we have in other: 
 
1550954433.432    581 192.168.62.58 TCP_MISS/200 2853 CONNECT gameplay.intel.com:443 <http://gameplay.intel.com:443>  jperez DIRECT/23.198.191.99 <http://23.198.191.99>  -
 
    I don't know if this is a known issue, or not...anybody can point me in the right direction to understand the nature of this issue, and how to solve/mitigate it?
 
    Thanks a lot in advance for your time and attention and best regards,
 
---
Some information about this installation: 
 
root at pxyserver:/var/log/squid3# squid3 -version
Squid Cache: Version 3.1.20
configure options:  '--build=i486-linux-gnu' '--prefix=/usr' '--includedir=${prefix}/include' '--mandir=${prefix}/share/man' '--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var' '--libexecdir=${prefix}/lib/squid3' '--srcdir=.' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--datadir=/usr/share/squid3' '--sysconfdir=/etc/squid3' '--mandir=/usr/share/man' '--with-cppunit-basedir=/usr' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth=basic,digest,ntlm,negotiate' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm,' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-external-acl-helpers=ip_user,ldap_group,session,unix_group,wbinfo_group' '--enable-arp-acl' '--enable-esi' '--enable-zph-qos' '--enable-wccpv2' '--disable-translation' '--with-logdir=/var/log/squid3' '--with-pidfile=/var/run/squid3.pid' '--with-filedescriptors=65536' '--with-large-files' '--with-default-user=proxy' '--enable-linux-netfilter' 'build_alias=i486-linux-gnu' 'CFLAGS=-g -O2 -fPIE -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -Wall' 'LDFLAGS=-fPIE -pie -Wl,-z,relro -Wl,-z,now' 'CPPFLAGS=-D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -fPIE -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security' --with-squid=/build/buildd-squid3_3.1.20-2.2-i386-3NN6Xn/squid3-3.1.20
/etc/squid3/squid.conf: 
 
cache_mgr cache at mydomain.local <mailto:cache at mydomain.local> 
auth_param negotiate program /usr/local/bin/negotiate_wrapper --ntlm /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp --domain=MYDOMAIN --kerberos /usr/lib/squid3/squid_kerb_auth -d -s GSS_C_NO_NAME
auth_param negotiate children 10
auth_param negotiate keep_alive off
auth_param ntlm program /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp --domain=MYDOMAIN
auth_param ntlm children 10
auth_param ntlm keep_alive off
auth_param basic program /usr/lib/squid3/squid_ldap_auth -R -b "dc=mydomain,dc=local" -D squid at mydomain.local <mailto:squid at mydomain.local>  -W /etc/squid3/ldappass.txt -f sAMAccountName=%s -h ARBERN005M.mydomain.local
auth_param basic children 10
auth_param basic realm Internet Proxy
auth_param basic credentialsttl 1 minute
external_acl_type memberof %LOGIN /usr/lib/squid3/squid_ldap_group -R -K -b "dc=mydomain,dc=local" -D squid at mydomain.local <mailto:squid at mydomain.local>  -W /etc/squid3/ldappass.txt -f "(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,cn=Users,dc=mydomain,dc=local))" -h ARBERN005M.mydomain.local
acl company src "/etc/squid3/full"
acl limitados src "/etc/squid3/limitados"
acl lentos src "/etc/squid3/lento"
acl all src all
acl manager proto cache_object
acl localhost src 127.0.0.1/32 <http://127.0.0.1/32> 
acl to_localhost dst 127.0.0.0/8 <http://127.0.0.0/8> 
acl purge method PURGE
acl dnld url_regex -i \.avi
acl dnld url_regex -i \.mp3
acl dnld url_regex -i \.fla
acl dnld url_regex -i \.flv
acl dnld url_regex -i \.wav
acl dnld url_regex -i \.asf
acl dnld url_regex -i \.wmf
acl dnld url_regex -i \.pif
acl dnld url_regex -i \.bat
acl dnld url_regex -i \.scr
acl dnld url_regex -i \.wdm
acl dnld url_regex -i \.wmv
acl dnld url_regex -i \.mid
acl dnld url_regex -i \.mpg
acl dnld url_regex -i \.mpg
acl dnld url_regex -i \.mpeg
acl dnld url_regex -i \.ogg
acl dnld url_regex -i \.ogm
acl dnld url_regex -i \.exe
acl dnld url_regex -i \.arj
acl dnld url_regex -i \.iso
acl dnld url_regex -i \.nrg
acl dnld url_regex -i \.bin
acl dnld url_regex -i \.dmg
acl dnld url_regex -i \.img
acl dnld url_regex -i \.pl
acl dnld_full url_regex -i \.avi
acl dnld_full url_regex -i \.mp3
acl dnld_full url_regex -i \.wav
acl dnld_full url_regex -i \.asf
acl dnld_full url_regex -i \.wmf
acl dnld_full url_regex -i \.mpg
acl dnld_full url_regex -i \.mpg
acl dnld_full url_regex -i \.mpeg
acl dnld_full url_regex -i \.ogg
acl dnld_full url_regex -i \.ogm
acl streaming browser -i ^.*NSPlayer.*
acl streaming browser -i ^.*Player.*
acl streaming browser -i ^.*Windows-Media-Player.*
acl streaming1 browser -i ^video/x-ms-asf$
acl streaming1 browser -i ^application/vnd.ms.wms-hdr.asfv1$
acl streaming1 browser -i ^application/x-mms-framed$
acl streaming1 browser -i ^audio/x-pn-realaudio$
acl streaming1 browser ^.*mms.*
acl streaming1 browser ^.*ms-hdr.*
acl streaming1 browser ^.*x-fcs.*
acl streaming1 browser ^.*x-ms-asf.*
acl streaming1 browser -i ^application/octet-stream$
acl streaming1 browser -i application/octet-stream
delay_pools 1
delay_class 1 1
delay_parameters 1 1000/100
acl dp url_regex \.flv$
acl dp url_regex -i watch?
acl dp url_regex -i youtube
acl dp url_regex -i facebook
delay_access 1 allow dp lentos
acl auth proxy_auth REQUIRED
acl internet_full       external memberof "/etc/squid3/internet_full.txt"
acl internet_limitado   external memberof "/etc/squid3/internet_limitado.txt"
acl internet_limitado2  external memberof "/etc/squid3/internet_limitado2.txt"
acl destinos_permitidos         dstdomain "/etc/squid3/destinos_permitidos"
acl destinos_permitidos2        dstdomain "/etc/squid3/destinos_permitidos2"
acl sitios_denegados            dstdomain "/etc/squid3/sitios_denegados"
acl prohibidos                  dstdomain "/etc/squid3/prohibidos.txt"
acl prohibidos-full             dstdomain "/etc/squid3/prohibidos-full.txt"
acl intfull-                    dstdomain "/etc/squid3/intfull-"
acl allowedsites        dstdomain "/etc/squid3/allowedsites.txt"
acl manager proto cache_object
acl SSL_ports port 443
acl CONNECT method CONNECT
http_access allow manager localhost
http_access deny manager
http_access allow localhost
http_access deny !auth
http_access deny sitios_denegados all
http_access allow allowedsites
http_access allow limitados !dnld !streaming !streaming1 !sitios_denegados
http_access allow !dnld !streaming !streaming1 destinos_permitidos internet_limitado
http_access allow !dnld !streaming !streaming1 destinos_permitidos2 internet_limitado2
http_access allow !dnld_full !streaming !streaming1 !prohibidos-full internet_full
http_access deny all
access_log /var/log/squid3/access.log squid !allowedsites
http_port 3128
hierarchy_stoplist cgi-bin ?
coredump_dir /var/spool/squid3
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320


 
-- 
HeCSa
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190224/f152ee2e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11295 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190224/f152ee2e/attachment.png>

From rousskov at measurement-factory.com  Sat Feb 23 22:16:25 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 23 Feb 2019 15:16:25 -0700
Subject: [squid-users] squid 4.x: decided: do not cache but share
 because the entry has been released
In-Reply-To: <f9a1e8fe-fe95-a399-a2b8-4162a02f7621@treenet.co.nz>
References: <007f01d4cb95$7cb50230$761f0690$@articatech.com>
 <f9a1e8fe-fe95-a399-a2b8-4162a02f7621@treenet.co.nz>
Message-ID: <433e34b3-f3e8-ac9f-db77-2074ade6dfe8@measurement-factory.com>

On 2/23/19 10:17 AM, Amos Jeffries wrote:
> On 24/02/19 5:33 am, David Touzeau wrote:
>> http.cc(982) haveParsedReplyHeaders: decided: do not cache but share
>> because the entry has been released; HTTP status 200

>> What ?but share because the entry has been released? event means ?

> 'do not cache but share' means the reply may still be shared with other
> concurrent clients (eg. collapsed forwarding), but not to bother trying
> to cache it.

Correct. To participate in that sharing, those concurrent clients must
already have a lock on this entry. In other words, "concurrency" here is
determined by having guaranteed access to the Store entry rather than
just overlapping transaction lifetimes.


> 'entry has been released' means something else already caused the disk
> copy in cache to be removed or replaced.

Yes, and this is not limited to the old entries in the disk cache. Entry
"release" may happen even before the entry is earmarked for any of the
caches, and the release affects both disk and memory caches.


If you want to figure out why this response is not being cached, you may
need to figure out why the corresponding Store entry was marked for
release. Look for releaseRequest lines in the debugging cache.log that
match the same entry and try to determine why releaseRequest was called.

Alex.


From eliezer at ngtech.co.il  Sat Feb 23 22:16:46 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Sun, 24 Feb 2019 00:16:46 +0200
Subject: [squid-users] Squid 4.x: cache_peer PROXY_PROTOCOL support
	with	squid parents
In-Reply-To: <006a01d4cb95$289a6640$79cf32c0$@articatech.com>
References: <015f01d4cab4$ef806480$ce812d80$@articatech.com>
 <81814bd0-7c59-9156-d8a5-fa84528ebf87@treenet.co.nz>
 <006a01d4cb95$289a6640$79cf32c0$@articatech.com>
Message-ID: <053401d4cbc5$771fb6f0$655f24d0$@ngtech.co.il>

What would be the reason to replace haproxy eactly?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of David Touzeau
Sent: Saturday, February 23, 2019 18:31
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid 4.x: cache_peer PROXY_PROTOCOL support with squid parents


Currently we are working on Kerberos with Active Directory with Ha-proxy 
that
sends requests to squid using proxy_protocol.
Everything works great but we want to replace the ha-proxy with a squid.
In fact, we want to the squid client send the credentials information to a
squid parent in order to centralize ACLs on the parent proxy according to 
the user's login name.
If you have any suggestion ?

Best regards




-----Message d'origine-----
De : squid-users <squid-users-bounces at lists.squid-cache.org> De la part de
Amos Jeffries
Envoy? : samedi 23 f?vrier 2019 04:07
? : squid-users at lists.squid-cache.org
Objet : Re: [squid-users] Squid 4.x: cache_peer PROXY_PROTOCOL support with
squid parents

On 23/02/19 2:45 am, David Touzeau wrote:
> Hi,
>
>
>
> We would like to use this infrastructure:
>
>
>
> Squid-cache client authentication 1--------
>
>
>    | ----> Squid Parent with ACLs per user/LDAP groups/Web filtering
> ---> INTERNET
>
> Squid-cache client authentication 2 --------
>
>
>
>
>
> Currently this kind of infrastructure cannot be done because the Squid
> that acts as a client did not send credentials information to the
> parent proxy.
>

There are many types of "client authentication" that can exist in multiple
nested protocol layers:

* HTTP WWW-Auth* credentials

* HTTP Proxy-Auth* credentials

* TLS client X.509 certificate

* CONNECT tunnel Proxy-Auth*

* TCP connection-auth scheme credentials (NTLM, Negotiate)

* IPSEC key exchange

* EUI

* IDENT user name

Which one(s) are you talking about?


>
> We think it should be done if the cache_peer is compliance with
> PROXY_PROTOCOL rfc as the http_port is already compliance.
>

What are you thinking PROXY would be doing to help with the situation?

Keep in mind that the PROXY header needs to be sent before any other bytes
on the server connection. Which immediately limits the cases where any type
of client information is available.


>
> Do you have plans to add PROXY_PROTOCOL inside cache_peer feature ?
>
>

To whom are you addressing this question?


Cheers,
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Sun Feb 24 02:36:17 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Sun, 24 Feb 2019 04:36:17 +0200
Subject: [squid-users] | Ignoring non-issuer CA from ... while squid -kparse
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADUp5DzvZm8R6KU0waBzIwBAQAAAAA=@ngtech.co.il>

I am testing intermediate  certificates and I have just created a key and
certificate files.
The http line for ssl bump is:
http_port 23128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=16MB  cert=/etc/squid/ssl_cert/cert.pem
key=/etc/squid/ssl_cert/key.pem
 
While running squid -kparse I get the next output:
2019/02/24 04:28:03| Using certificate in /etc/squid/ssl_cert/cert.pem
2019/02/24 04:28:03| Using certificate chain in /etc/squid/ssl_cert/cert.pem
2019/02/24 04:28:03| Ignoring non-issuer CA from
/etc/squid/ssl_cert/cert.pem: /C=IL/ST=Shomron/O=NgTech
LTD/CN=pxaa13a65c.ngtech.co.il
## END OF OUTPUT SNIPPET
 
I have seen the note in the code
// checks that the chained certs are actually part of a chain for 
validating cert
at:
https://github.com/squid-cache/squid/blob/75aadeb9cc1128bb50adf8fc629d3957e9
a88f2f/src/security/KeyData.cc#L121
 
I am not sure how to look at this.
I am almost sure I did something wrong, maybe when I created the root CA or
the intermidate?
 
The actual result is that it works and the connections are being intercepted
without errors since the signing rootCA is installed on windows and firefox.
Not sure how to look at this log..
 
Thanks,
Eliezer 
 
----
 <http://ngtech.co.il/main-en/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email:  <mailto:eliezer at ngtech.co.il> eliezer at ngtech.co.il

 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190224/b18984ea/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11295 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190224/b18984ea/attachment.png>

From squid3 at treenet.co.nz  Sun Feb 24 07:05:35 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 24 Feb 2019 20:05:35 +1300
Subject: [squid-users] Issues With 3.1.20 and Windows Update
In-Reply-To: <CAMXef5JNjWc9D9n13RbAta4wJApW9s=HCiYmmF5LKCsC3WbPaA@mail.gmail.com>
References: <CAMXef5JNjWc9D9n13RbAta4wJApW9s=HCiYmmF5LKCsC3WbPaA@mail.gmail.com>
Message-ID: <57a6f319-dc20-9e59-dff3-474083c784a7@treenet.co.nz>

On 24/02/19 9:55 am, Hernan Saltiel wrote:
> Hi,
> ??? I'm trying to use a Squid 3.1.20 to update several Windows Clientes
> (some are Vista, some are 7, some are 10).
> ??? We're using NTLM authentication, and some groups (some users can use
> full internet, some can only on some sites) and this is working fine.
> ??? The issue arises when trying to update Windows, using automatic
> updates. We see, on the log files, messages like the following:
> 
> 1550954462.404????? 0 192.168.42.121 TCP_DENIED/407 3980 GET
> http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab?
> - NONE/- text/html
> 1550954462.410????? 0 192.168.42.121 TCP_DENIED/407 4261 GET
> http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab?
> - NONE/- text/html
> 1550954462.415????? 0 192.168.42.121 TCP_DENIED/407 4635 GET
> http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab?
> - NONE/- text/html
> ??
> ??? Some aspects concerns me...first of all, that our users cannot
> update Windows. But then I noticed there is no user on that connection,
> as we have in other:
> 
> 1550954433.432??? 581 192.168.62.58 TCP_MISS/200 2853 CONNECT
> gameplay.intel.com:443  *jperez*
> DIRECT/23.198.191.99 -
> 
> ??? I don't know if this is a known issue, or not...anybody can point me
> in the right direction to understand the nature of this issue, and how
> to solve/mitigate it?

This is how NTLM works. Multiple HTTP requests exchanging type-1,2,3
tickets. Only the last one has a user name.

The absence of these multiple exchanges and all the time and bandwidth
they consume is what makes Negotiate/Kerberos have better performance.


However, if you are *only* seeing lack of username and 407/403 on the
update requests the WU agent is having problems logging in thorugh a
proxy. See
<https://wiki.squid-cache.org/SquidFaq/WindowsUpdate#Squid_problems_with_Windows_Update_v5>
and maybe
<https://wiki.squid-cache.org/SquidFaq/WindowsUpdate#How_do_I_stop_Squid_popping_up_the_Authentication_box_for_Windows_Update.3F>
for some things that may help.


Microsoft products since 2006 (Windows XP) have all had Kerberos support
and deprecated use of NTLM. If you do not have anything older to support
you may find it very useful to remove NTLM usage from the network
entirely. Remove from clients first, then servers and proxy.



Also, if you can upgrade the proxy please do. Latest release of Squid is
v4.6. There are large numbers of bugs and at least several major
security issues with all releases older than v3.5.28.


Below are some config changes you may find useful:

> /etc/squid3/squid.conf:
> 
> cache_mgr cache at mydomain.local
> auth_param negotiate program /usr/local/bin/negotiate_wrapper --ntlm
> /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp
> --domain=MYDOMAIN --kerberos /usr/lib/squid3/squid_kerb_auth -d -s
> GSS_C_NO_NAME
> auth_param negotiate children 10
> auth_param negotiate keep_alive off
> auth_param ntlm program /usr/bin/ntlm_auth --diagnostics
> --helper-protocol=squid-2.5-ntlmssp --domain=MYDOMAIN
> auth_param ntlm children 10
> auth_param ntlm keep_alive off
> auth_param basic program /usr/lib/squid3/squid_ldap_auth -R -b
> "dc=mydomain,dc=local" -D squid at mydomain.local -W
> /etc/squid3/ldappass.txt -f sAMAccountName=%s -h ARBERN005M.mydomain.local
> auth_param basic children 10
> auth_param basic realm Internet Proxy
> auth_param basic credentialsttl 1 minute
> external_acl_type memberof %LOGIN /usr/lib/squid3/squid_ldap_group -R -K
> -b "dc=mydomain,dc=local" -D squid at mydomain.local -W
> /etc/squid3/ldappass.txt -f
> "(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,cn=Users,dc=mydomain,dc=local))"
> -h ARBERN005M.mydomain.local
> acl company src "/etc/squid3/full"
> acl limitados src "/etc/squid3/limitados"
> acl lentos src "/etc/squid3/lento"
> acl all src all
> acl manager proto cache_object
> acl localhost src 127.0.0.1/32
> acl to_localhost dst 127.0.0.0/8
> acl purge method PURGE
> acl dnld url_regex -i \.avi
> acl dnld url_regex -i \.mp3
> acl dnld url_regex -i \.fla
> acl dnld url_regex -i \.flv
> acl dnld url_regex -i \.wav
> acl dnld url_regex -i \.asf
> acl dnld url_regex -i \.wmf
> acl dnld url_regex -i \.pif
> acl dnld url_regex -i \.bat
> acl dnld url_regex -i \.scr
> acl dnld url_regex -i \.wdm
> acl dnld url_regex -i \.wmv
> acl dnld url_regex -i \.mid
> acl dnld url_regex -i \.mpg
> acl dnld url_regex -i \.mpg
> acl dnld url_regex -i \.mpeg
> acl dnld url_regex -i \.ogg
> acl dnld url_regex -i \.ogm
> acl dnld url_regex -i \.exe
> acl dnld url_regex -i \.arj
> acl dnld url_regex -i \.iso
> acl dnld url_regex -i \.nrg
> acl dnld url_regex -i \.bin
> acl dnld url_regex -i \.dmg
> acl dnld url_regex -i \.img
> acl dnld url_regex -i \.pl

Regex is very slow to test. Especially when so many separate tests need
to be run just to test the ACL.

Newer Squid have optimizations that can help remove the duplicate
entries from above. But you should still combine these for less tests,
especially if you are staying with this Squid.

Also, are you really wanting to check these strings in the domain name
portion of URLs? url_path_regex is better for matching strings in the
URL-path area.

  acl dnld urlpath_regex -i \
      \.(avi|mp3|fl[av]|wav|asf|wm[fv]|pif|bat) \
      \.(scr|wdm|mid|mpe?g|og[gm]|exe|arj|iso|nrg) \
      \.(bin|[di]mg|pl)


> acl dnld_full url_regex -i \.avi
> acl dnld_full url_regex -i \.mp3
> acl dnld_full url_regex -i \.wav
> acl dnld_full url_regex -i \.asf
> acl dnld_full url_regex -i \.wmf
> acl dnld_full url_regex -i \.mpg
> acl dnld_full url_regex -i \.mpg
> acl dnld_full url_regex -i \.mpeg
> acl dnld_full url_regex -i \.ogg
> acl dnld_full url_regex -i \.ogm
> acl streaming browser -i ^.*NSPlayer.*
> acl streaming browser -i ^.*Player.*
> acl streaming browser -i ^.*Windows-Media-Player.*
> acl streaming1 browser -i ^video/x-ms-asf$
> acl streaming1 browser -i ^application/vnd.ms.wms-hdr.asfv1$
> acl streaming1 browser -i ^application/x-mms-framed$
> acl streaming1 browser -i ^audio/x-pn-realaudio$
> acl streaming1 browser ^.*mms.*
> acl streaming1 browser ^.*ms-hdr.*
> acl streaming1 browser ^.*x-fcs.*
> acl streaming1 browser ^.*x-ms-asf.*
> acl streaming1 browser -i ^application/octet-stream$
> acl streaming1 browser -i application/octet-stream

There are two problems above.

Firstly the 'browser' ACL type only matches the User-Agent HTTP header.
A lot of those regex are patterns matching Content-Type header values.
Something is very weirdly broken if they are being placed into User-Agent.

Secondly there are large overlaps in the patterns.

It looks to me like the proper value for this should be:

  acl streaming browser -i Player

  acl streaming1 req_header Content-Type -i ^audio/x-pn-realaudio$
  acl streaming1 req_header Content-Type -i mms|ms-hdr|x-ms-asf
  acl streaming1 req_header Content-Type -i application/octet-stream


> delay_pools 1
> delay_class 1 1
> delay_parameters 1 1000/100
> acl dp url_regex \.flv$
> acl dp url_regex -i watch?

Regex typo. This will match any URL with "watc" *anywhere* in it.

I think you meant  "watch\?"


> acl dp url_regex -i youtube
> acl dp url_regex -i facebook
> delay_access 1 allow dp lentos
> acl auth proxy_auth REQUIRED
> acl internet_full?????? external memberof "/etc/squid3/internet_full.txt"
> acl internet_limitado?? external memberof
> "/etc/squid3/internet_limitado.txt"
> acl internet_limitado2? external memberof
> "/etc/squid3/internet_limitado2.txt"
> acl destinos_permitidos???????? dstdomain "/etc/squid3/destinos_permitidos"
> acl destinos_permitidos2??????? dstdomain "/etc/squid3/destinos_permitidos2"
> acl sitios_denegados??????????? dstdomain "/etc/squid3/sitios_denegados"
> acl prohibidos????????????????? dstdomain "/etc/squid3/prohibidos.txt"
> acl prohibidos-full???????????? dstdomain "/etc/squid3/prohibidos-full.txt"
> acl intfull-??????????????????? dstdomain "/etc/squid3/intfull-"
> acl allowedsites??????? dstdomain "/etc/squid3/allowedsites.txt"
> acl manager proto cache_object
> acl SSL_ports port 443
> acl CONNECT method CONNECT

You are missing the rules that prevent security attacks against the
proxy. DoS and such. Please re-add them.

If there is traffic you want to go through which those rules deny you
should adjust the Safe_ports and/or SSL_ports ACLs instead of removing
these lines.

 http_access deny !Safe_ports
 http_access deny CONNECT !SSL_ports


> http_access allow manager localhost
> http_access deny manager
> http_access allow localhost
> http_access deny !auth
> http_access deny sitios_denegados all

The "all" on the line above is not useful.

> http_access allow allowedsites
> http_access allow limitados !dnld !streaming !streaming1 !sitios_denegados
> http_access allow !dnld !streaming !streaming1 destinos_permitidos
> internet_limitado
> http_access allow !dnld !streaming !streaming1 destinos_permitidos2
> internet_limitado2
> http_access allow !dnld_full !streaming !streaming1 !prohibidos-full
> internet_full


Rather than long lists of exceptions to be re-checked on every request
it would be better to order the groups by increasing level of
restrictions and deny things early.



Like this:

  http_access allow allowedsites
  http_access deny streaming
  http_access deny streaming1

  http_access allow !dnld_full !prohibidos-full internet_full

  http_access deny !dnld

  http_access allow limitados !sitios_denegados

  http_access allow destinos_permitidos internet_limitado

  http_access allow destinos_permitidos2 internet_limitado2


> http_access deny all



Cheers
Amos


From squid3 at treenet.co.nz  Sun Feb 24 08:13:59 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 24 Feb 2019 21:13:59 +1300
Subject: [squid-users] | Ignoring non-issuer CA from ... while squid
 -kparse
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADUp5DzvZm8R6KU0waBzIwBAQAAAAA=@ngtech.co.il>
References: <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADUp5DzvZm8R6KU0waBzIwBAQAAAAA=@ngtech.co.il>
Message-ID: <d3db6a2e-0fe9-5c69-c320-0461e243c721@treenet.co.nz>

On 24/02/19 3:36 pm, eliezer wrote:
> I am testing intermediate ?certificates and I have just created a key
> and certificate files.
> 
> The http line for ssl bump is:
> 
> http_port 23128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=16MB? cert=/etc/squid/ssl_cert/cert.pem
> key=/etc/squid/ssl_cert/key.pem
> 
> ?
> 
> While running squid -kparse I get the next output:
> 
> 2019/02/24 04:28:03| Using certificate in /etc/squid/ssl_cert/cert.pem
> 
> 2019/02/24 04:28:03| Using certificate chain in /etc/squid/ssl_cert/cert.pem
> 
> 2019/02/24 04:28:03| Ignoring non-issuer CA from
> /etc/squid/ssl_cert/cert.pem: /C=IL/ST=Shomron/O=NgTech
> LTD/CN=pxaa13a65c.ngtech.co.il
> 
> ## END OF OUTPUT SNIPPET
> 
> 
> I am not sure how to look at this.
> 
> I am almost sure I did something wrong, maybe when I created the root CA
> or the intermidate?
> 


Since you are not using a self-signed cert Squid is checking the
cert.pem file to see if any chain CAs exist in there.

Squid found one CA cert in the file and determined that it was not an
Issuer to place in the chain *after* the known signing CA.


Since this is the same file the cert= value came from you should expect
the first thing that it finds is the signing CA cert. That already
exists in the known bit of chain and is not its own Issuer. So should be
skipped.


>From your description the root CA was next in the chain and already
configured into the Browser. So you should not see any chain info
actually loaded for this setup. Though if you want to send even the root
CA you could add it to the file and Squid would send the full chain.


There is only a problem if:

 * the file being loaded is not one you wanted to load,
or
 * the displayed CN is something you did not expect to see in that file, or
 * the CA with that CN supposed to be part of the CA chain which
signed/issued your cert= certificate.
  - Issuer sequence broken, or
  - Issuer sequence missing an entry, or
  - CAs not in correct chain order in the file.

Amos


From david at articatech.com  Sun Feb 24 08:39:14 2019
From: david at articatech.com (David Touzeau)
Date: Sun, 24 Feb 2019 09:39:14 +0100
Subject: [squid-users] squid 4.x: decided: do not cache but share
	because the entry has been released
In-Reply-To: <433e34b3-f3e8-ac9f-db77-2074ade6dfe8@measurement-factory.com>
References: <007f01d4cb95$7cb50230$761f0690$@articatech.com>
 <f9a1e8fe-fe95-a399-a2b8-4162a02f7621@treenet.co.nz>
 <433e34b3-f3e8-ac9f-db77-2074ade6dfe8@measurement-factory.com>
Message-ID: <000301d4cc1c$6c8fc8e0$45af5aa0$@articatech.com>

Many thanks for the explanation 

There is a miss configuration in config file:

"cache deny all"

It's a shame...

-----Message d'origine-----
De : squid-users <squid-users-bounces at lists.squid-cache.org> De la part de Alex Rousskov
Envoy? : samedi 23 f?vrier 2019 23:16
? : squid-users at lists.squid-cache.org
Objet : Re: [squid-users] squid 4.x: decided: do not cache but share because the entry has been released

On 2/23/19 10:17 AM, Amos Jeffries wrote:
> On 24/02/19 5:33 am, David Touzeau wrote:
>> http.cc(982) haveParsedReplyHeaders: decided: do not cache but share 
>> because the entry has been released; HTTP status 200

>> What ?but share because the entry has been released? event means ?

> 'do not cache but share' means the reply may still be shared with 
> other concurrent clients (eg. collapsed forwarding), but not to bother 
> trying to cache it.

Correct. To participate in that sharing, those concurrent clients must already have a lock on this entry. In other words, "concurrency" here is determined by having guaranteed access to the Store entry rather than just overlapping transaction lifetimes.


> 'entry has been released' means something else already caused the disk 
> copy in cache to be removed or replaced.

Yes, and this is not limited to the old entries in the disk cache. Entry "release" may happen even before the entry is earmarked for any of the caches, and the release affects both disk and memory caches.


If you want to figure out why this response is not being cached, you may need to figure out why the corresponding Store entry was marked for release. Look for releaseRequest lines in the debugging cache.log that match the same entry and try to determine why releaseRequest was called.

Alex.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From numsys at free.fr  Sun Feb 24 10:33:08 2019
From: numsys at free.fr (FredB)
Date: Sun, 24 Feb 2019 11:33:08 +0100 (CET)
Subject: [squid-users] ICAP and 403 Encapsulated answers (SSL denied
 domains)
In-Reply-To: <7ad1a209-0420-d437-6df3-a8cc4ee48663@measurement-factory.com>
Message-ID: <1964743467.919672431.1551004388453.JavaMail.root@zimbra30-e5.priv.proxad.net>

Thanks, there a lot of impacts here, response time, load average, etc, unfortunately we should wait that FF 66 (and after) is installed everywhere to fix that ...  

I'm really surprised that there is no more messages about this

Fred



From eliezer at ngtech.co.il  Sun Feb 24 12:58:26 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Sun, 24 Feb 2019 14:58:26 +0200
Subject: [squid-users] | Ignoring non-issuer CA from ... while squid
	-kparse
In-Reply-To: <d3db6a2e-0fe9-5c69-c320-0461e243c721@treenet.co.nz>
References: <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADUp5DzvZm8R6KU0waBzIwBAQAAAAA=@ngtech.co.il>
 <d3db6a2e-0fe9-5c69-c320-0461e243c721@treenet.co.nz>
Message-ID: <0e6c01d4cc40$a1e3ef70$e5abce50$@ngtech.co.il>

I assume it's fine in general since it works.
I will try to run a request with openssl to see what is the certificate chain that I'm receiving.
The issue is that it's a special "redirect all" proxy for filtering only blacklisted domains.
So the squid receives all SSL requests and denies them with a 302 to another server so it's hard
for me to see in the browser if the chain received is full.

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Sunday, February 24, 2019 10:14
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] | Ignoring non-issuer CA from ... while squid -kparse

On 24/02/19 3:36 pm, eliezer wrote:
> I am testing intermediate  certificates and I have just created a key
> and certificate files.
> 
> The http line for ssl bump is:
> 
> http_port 23128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=16MB  cert=/etc/squid/ssl_cert/cert.pem
> key=/etc/squid/ssl_cert/key.pem
> 
>  
> 
> While running squid -kparse I get the next output:
> 
> 2019/02/24 04:28:03| Using certificate in /etc/squid/ssl_cert/cert.pem
> 
> 2019/02/24 04:28:03| Using certificate chain in /etc/squid/ssl_cert/cert.pem
> 
> 2019/02/24 04:28:03| Ignoring non-issuer CA from
> /etc/squid/ssl_cert/cert.pem: /C=IL/ST=Shomron/O=NgTech
> LTD/CN=pxaa13a65c.ngtech.co.il
> 
> ## END OF OUTPUT SNIPPET
> 
> 
> I am not sure how to look at this.
> 
> I am almost sure I did something wrong, maybe when I created the root CA
> or the intermidate?
> 


Since you are not using a self-signed cert Squid is checking the
cert.pem file to see if any chain CAs exist in there.

Squid found one CA cert in the file and determined that it was not an
Issuer to place in the chain *after* the known signing CA.


Since this is the same file the cert= value came from you should expect
the first thing that it finds is the signing CA cert. That already
exists in the known bit of chain and is not its own Issuer. So should be
skipped.


>From your description the root CA was next in the chain and already
configured into the Browser. So you should not see any chain info
actually loaded for this setup. Though if you want to send even the root
CA you could add it to the file and Squid would send the full chain.


There is only a problem if:

 * the file being loaded is not one you wanted to load,
or
 * the displayed CN is something you did not expect to see in that file, or
 * the CA with that CN supposed to be part of the CA chain which
signed/issued your cert= certificate.
  - Issuer sequence broken, or
  - Issuer sequence missing an entry, or
  - CAs not in correct chain order in the file.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Sun Feb 24 12:59:40 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Sun, 24 Feb 2019 14:59:40 +0200
Subject: [squid-users] ICAP and 403 Encapsulated answers (SSL denied
	domains)
In-Reply-To: <1964743467.919672431.1551004388453.JavaMail.root@zimbra30-e5.priv.proxad.net>
References: <7ad1a209-0420-d437-6df3-a8cc4ee48663@measurement-factory.com>
 <1964743467.919672431.1551004388453.JavaMail.root@zimbra30-e5.priv.proxad.net>
Message-ID: <0e6e01d4cc40$ce1f7b90$6a5e72b0$@ngtech.co.il>

I do not see any context, can you redirect me towards the last email?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of FredB
Sent: Sunday, February 24, 2019 12:33
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] ICAP and 403 Encapsulated answers (SSL denied domains)

Thanks, there a lot of impacts here, response time, load average, etc, unfortunately we should wait that FF 66 (and after) is installed everywhere to fix that ...  

I'm really surprised that there is no more messages about this

Fred

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From dvanorder at deloitte.com  Sun Feb 24 13:40:15 2019
From: dvanorder at deloitte.com (Van Order, Drew (US - Hermitage))
Date: Sun, 24 Feb 2019 13:40:15 +0000
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <04fc01d4cba3$ce63ecf0$6b2bc6d0$@ngtech.co.il>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
 <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <04fc01d4cba3$ce63ecf0$6b2bc6d0$@ngtech.co.il>
Message-ID: <CO1PR85MB0181275803A77F5C6DFAE39EC8790@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>

This is helpful, and I especially appreciate the time given it is the weekend.

The Squids are confusing me, as everything is well behaved at the moment. One server was erroring off and on for a few hours earlier today, but stopped after a reboot.

It does appear that redirecting roughly 125 servers to no longer use the proxy has helped. Unfortunately, our F5 guy can't tell me how many IP addresses remain coming into this F5 VIP, which would give me the number of servers, and an idea how loaded this thing is. I have good reason to believe it is under 1,000. He has shown us graphs indicating the VIP isn't stressed, but I will keep working on him, b/c I can't imagine not being able to report how many distinct IP addresses hit the VIP.

I don't have a Visio, but

Server running the Microsoft Monitoring Agent sends data over tcp/443-->Internal facing firewall(s)-->F5 VIP-->one of 4 Squids-->internet 

Each of the 4 VMWare Squids has 4 proc and 8 GB memory, 10 GB NIC.

We're a large enterprise with multiple data centers and many subnets, so there are quite a few firewalls, and most of the time a server must go through more than one firewall. Can't help but wonder if firewall exhaustion could cause the symptoms.

Revision: I typed the above last night. This morning, the server that had been erroring is at it again, but stopped. Others are fine. Interesting problem.

-----Original Message-----
From: eliezer at ngtech.co.il <eliezer at ngtech.co.il> 
Sent: Saturday, February 23, 2019 12:16 PM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

The next tool might help you to understand the status of the open connections.
If the socket is being closed( I think Windows Server 2016 is a very good OS...).
https://secure-web.cisco.com/1gLLf4HP_bwYOteW6x8gJ8EGyBrYzTMzMIi7P6q7aGi136WObNRd7uZQkrv-CKTO7ipHpLgOvHaGbzxLT7RpG6AGtkeTHUn2O8-CIAgcBOCUzn6KyZoPhqsAcpIXokXWcjlWHdUVUwlZVT0WKEhuOuAGvw2washhJEOg1Gcbsf99cy7ofqJfuTc-fS23KxfiE8W-2GLLNuF_J8q5uGJdvUMhm6HN-4CO3c_i8wxOlHrxgX3GjSLbLo8odnA6YctD5A01sjW3dpC4oiioIkGY7gDY-hjSSNYr_xoZzsixScColG-JRDlR3uktjsFF5JCkU1EROfoOfUHsDdeJ0IV2Cpk6yzbSPNNno7jV5BmZSsmR_jRgW7WJa4eVhKUvicMfy8RBespjtbfk17lUf9JamqmxPBtP2eHsiIb4_wk9iJfRr_S-aA1Ve7rPDmCXm9bZ9HRmXphi8o5AeYMWbK9DTrnmPDmFamis922AT6F4KUuBvS3PKqeCkT3EUuGmlwHXxCiJGwYBKXQmOehcFbqgfFQ/https%3A%2F%2Fwww.nirsoft.net%2Futils%2Fcports.html

There is a possibility that some OS TCP limit is being reached and there for the socket closure.
If you are using F5 you can easily find out the load at the crash point.
I assume that if a normal Squid instance can take a load of 900k requests per second in somewhat constant rate for more than a minute then the issue might be else where then squid.
I am not sure but pretty sure that if you do not have anyone that is knowledgeable enough about windows sockets, sessions and FW limitations you will either:
- learn it your self
- find an expert
- use an OS that is more then 20% supported by any of the Squid-Cache team members and other developers around the globe.

Just to say a good word about Windows Server 2016, I compared it to a Windows 10 under load and it seems to take a lot more load.
Also it not just takes the load but balance it well (on an open source windows designed software).

Also if you have a specific use case maybe a specific proxy can be customized for it.
Let me know if you wish to shed more details on the configuration so I can take my time and understand if there is a solution else then Squid.

Eliezeer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Van Order, Drew (US - Hermitage)
Sent: Friday, February 22, 2019 15:32
To: Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing

The test box I set up outside the F5 finally started exhibiting these errors, once I pointed roughly 60 machines to it. It took a few hours.
Sounds like this narrows it down to either the OS itself (seems unlikely, other apps would crash), or the litany of agents our security folks have mandated. It may indeed be necessary to move to Linux.

Thank you very much for your time!

-----Original Message-----
From: Amos Jeffries <squid3 at treenet.co.nz>
Sent: Thursday, February 21, 2019 11:31 PM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; squid-users at lists.squid-cache.org
Subject: [EXT] Re: [squid-users] Squid for Windows Repeatedly Crashing

On 22/02/19 4:21 am, Van Order, Drew (US - Hermitage) wrote:
> Thank you for replying, and that's an excellent point.
>
> Short answer--definitely not in a container, these are garden variety
VMWare instances. I've already flagged the OS power settings to maximum performance, so nothing should be going to sleep. I'll doublecheck, though.
>
> So, if I understand correctly, this error could also be indicative of 
> an
issue in between the agent and Squid. Agents first go through a firewall, then the F5 before reaching Squid.

No that is not what I meant.

The port Squid has already opened and used syscall listen(2) on is what is being closed (or its address corrupted) outside of Squid. That should only ever be closed by Squid itself. Thus the error.

It is being closed repeatedly. Thus the abort/shutdown. This is not a crash, it is intentional shutdown by Squid due to these fatal
(non-recoverable) errors.


>
> [Stopped, reason:Listener socket closed job1]: (14) Bad address
>
> Any thoughts on this error, which tends to be more common than the other?
>
> 2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
> 2019/02/20 09:42:33 kid1| Select loop Error. Retry 2
>

Notice how the error from the OS "(14) Bad Address" is the same. This is just another display of the same problem. Maybe the poll() layer reporting the exact same error as Squid tries to recover. Maybe for other non-listener ports also being corrupted somehow.

If non-listener ports are having that same error it would be a sign the machine memory is being corrupted rather than other software touching the listener ports specifically.


( The details you have provided so far have no hints about where the problem may be coming from, and I am not having any ideas about possibilities either. I just hope the above explanation of meaning can help you think of things to look at for more hints on this very weird issue. )

Amos
This message (including any attachments) contains confidential information intended for a specific individual and purpose, and is protected by law. If you are not the intended recipient, you should delete this message and any disclosure, copying, or distribution of this message, or the taking of any action based on it, by you is strictly prohibited.

v.E.1
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://secure-web.cisco.com/1rTtG7rZtQ6ZYF-exa33X6jslvqhns0Pi1uNpYErXcG6etibmd2SGhMCHECLwNvCY_z6WNGI9PaBD1nPWRtPe1XdcdZhuC10Oc9dQlldi3fS1vGPfi61VTB_e97sfZ2nE_5La5ibKly97QaMVeX4ib_qbPmqDOLDxWojYptvrbanhvTw0LMDyj92Yemr6GmVWk24CafYzhUBtvf-e8KVWHfPeNVfB537hUMROtnb3P2Ai1mcKSoamHQIIRn3kSkUD0Hg7sY7b-9LxTw617U5_JrdvsS5Qv8KJvkOYV-8jTAumLo3yhoc8WuMnYFRMDvbkwDV2T1LnqyfjyCzukxeiXxfgRMIDIrj2OBfNj33Xiw-rbU-thwedxYHIPJ0lIxU49DL4kAwlhAH173i_vZBUxMyqjVSvMIHutBPmEYNSDsnG0CVDRrYiF2BA3-7ZDPpQNjCUGUVP7K1NyA41OMZSeaRP8mtbuqrTwKT_BpNzx6IUc4_gFtkJZ_FgqpC2_uFPmtzLnSxnCM4Lz1om84BJVQ/http%3A%2F%2Flists.squid-cache.org%2Flistinfo%2Fsquid-users




From rafael.akchurin at diladele.com  Sun Feb 24 13:47:00 2019
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sun, 24 Feb 2019 13:47:00 +0000
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <CO1PR85MB0181275803A77F5C6DFAE39EC8790@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
 <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <04fc01d4cba3$ce63ecf0$6b2bc6d0$@ngtech.co.il>
 <CO1PR85MB0181275803A77F5C6DFAE39EC8790@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
Message-ID: <AM0PR04MB47539AEB5F719878A4D3BE588F790@AM0PR04MB4753.eurprd04.prod.outlook.com>

As far as I know the internal FD limit for Windows build is around 3K - might be being existed and thus unexpected behavior raising its ugly head..

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Van Order, Drew (US - Hermitage)
Sent: Sunday, 24 February 2019 14:40
To: eliezer at ngtech.co.il; 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing

This is helpful, and I especially appreciate the time given it is the weekend.

The Squids are confusing me, as everything is well behaved at the moment. One server was erroring off and on for a few hours earlier today, but stopped after a reboot.

It does appear that redirecting roughly 125 servers to no longer use the proxy has helped. Unfortunately, our F5 guy can't tell me how many IP addresses remain coming into this F5 VIP, which would give me the number of servers, and an idea how loaded this thing is. I have good reason to believe it is under 1,000. He has shown us graphs indicating the VIP isn't stressed, but I will keep working on him, b/c I can't imagine not being able to report how many distinct IP addresses hit the VIP.

I don't have a Visio, but

Server running the Microsoft Monitoring Agent sends data over tcp/443-->Internal facing firewall(s)-->F5 VIP-->one of 4 Squids-->internet 

Each of the 4 VMWare Squids has 4 proc and 8 GB memory, 10 GB NIC.

We're a large enterprise with multiple data centers and many subnets, so there are quite a few firewalls, and most of the time a server must go through more than one firewall. Can't help but wonder if firewall exhaustion could cause the symptoms.

Revision: I typed the above last night. This morning, the server that had been erroring is at it again, but stopped. Others are fine. Interesting problem.

-----Original Message-----
From: eliezer at ngtech.co.il <eliezer at ngtech.co.il>
Sent: Saturday, February 23, 2019 12:16 PM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

The next tool might help you to understand the status of the open connections.
If the socket is being closed( I think Windows Server 2016 is a very good OS...).
https://secure-web.cisco.com/1gLLf4HP_bwYOteW6x8gJ8EGyBrYzTMzMIi7P6q7aGi136WObNRd7uZQkrv-CKTO7ipHpLgOvHaGbzxLT7RpG6AGtkeTHUn2O8-CIAgcBOCUzn6KyZoPhqsAcpIXokXWcjlWHdUVUwlZVT0WKEhuOuAGvw2washhJEOg1Gcbsf99cy7ofqJfuTc-fS23KxfiE8W-2GLLNuF_J8q5uGJdvUMhm6HN-4CO3c_i8wxOlHrxgX3GjSLbLo8odnA6YctD5A01sjW3dpC4oiioIkGY7gDY-hjSSNYr_xoZzsixScColG-JRDlR3uktjsFF5JCkU1EROfoOfUHsDdeJ0IV2Cpk6yzbSPNNno7jV5BmZSsmR_jRgW7WJa4eVhKUvicMfy8RBespjtbfk17lUf9JamqmxPBtP2eHsiIb4_wk9iJfRr_S-aA1Ve7rPDmCXm9bZ9HRmXphi8o5AeYMWbK9DTrnmPDmFamis922AT6F4KUuBvS3PKqeCkT3EUuGmlwHXxCiJGwYBKXQmOehcFbqgfFQ/https%3A%2F%2Fwww.nirsoft.net%2Futils%2Fcports.html

There is a possibility that some OS TCP limit is being reached and there for the socket closure.
If you are using F5 you can easily find out the load at the crash point.
I assume that if a normal Squid instance can take a load of 900k requests per second in somewhat constant rate for more than a minute then the issue might be else where then squid.
I am not sure but pretty sure that if you do not have anyone that is knowledgeable enough about windows sockets, sessions and FW limitations you will either:
- learn it your self
- find an expert
- use an OS that is more then 20% supported by any of the Squid-Cache team members and other developers around the globe.

Just to say a good word about Windows Server 2016, I compared it to a Windows 10 under load and it seems to take a lot more load.
Also it not just takes the load but balance it well (on an open source windows designed software).

Also if you have a specific use case maybe a specific proxy can be customized for it.
Let me know if you wish to shed more details on the configuration so I can take my time and understand if there is a solution else then Squid.

Eliezeer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Van Order, Drew (US - Hermitage)
Sent: Friday, February 22, 2019 15:32
To: Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing

The test box I set up outside the F5 finally started exhibiting these errors, once I pointed roughly 60 machines to it. It took a few hours.
Sounds like this narrows it down to either the OS itself (seems unlikely, other apps would crash), or the litany of agents our security folks have mandated. It may indeed be necessary to move to Linux.

Thank you very much for your time!

-----Original Message-----
From: Amos Jeffries <squid3 at treenet.co.nz>
Sent: Thursday, February 21, 2019 11:31 PM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; squid-users at lists.squid-cache.org
Subject: [EXT] Re: [squid-users] Squid for Windows Repeatedly Crashing

On 22/02/19 4:21 am, Van Order, Drew (US - Hermitage) wrote:
> Thank you for replying, and that's an excellent point.
>
> Short answer--definitely not in a container, these are garden variety
VMWare instances. I've already flagged the OS power settings to maximum performance, so nothing should be going to sleep. I'll doublecheck, though.
>
> So, if I understand correctly, this error could also be indicative of 
> an
issue in between the agent and Squid. Agents first go through a firewall, then the F5 before reaching Squid.

No that is not what I meant.

The port Squid has already opened and used syscall listen(2) on is what is being closed (or its address corrupted) outside of Squid. That should only ever be closed by Squid itself. Thus the error.

It is being closed repeatedly. Thus the abort/shutdown. This is not a crash, it is intentional shutdown by Squid due to these fatal
(non-recoverable) errors.


>
> [Stopped, reason:Listener socket closed job1]: (14) Bad address
>
> Any thoughts on this error, which tends to be more common than the other?
>
> 2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
> 2019/02/20 09:42:33 kid1| Select loop Error. Retry 2
>

Notice how the error from the OS "(14) Bad Address" is the same. This is just another display of the same problem. Maybe the poll() layer reporting the exact same error as Squid tries to recover. Maybe for other non-listener ports also being corrupted somehow.

If non-listener ports are having that same error it would be a sign the machine memory is being corrupted rather than other software touching the listener ports specifically.


( The details you have provided so far have no hints about where the problem may be coming from, and I am not having any ideas about possibilities either. I just hope the above explanation of meaning can help you think of things to look at for more hints on this very weird issue. )

Amos
This message (including any attachments) contains confidential information intended for a specific individual and purpose, and is protected by law. If you are not the intended recipient, you should delete this message and any disclosure, copying, or distribution of this message, or the taking of any action based on it, by you is strictly prohibited.

v.E.1
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://secure-web.cisco.com/1rTtG7rZtQ6ZYF-exa33X6jslvqhns0Pi1uNpYErXcG6etibmd2SGhMCHECLwNvCY_z6WNGI9PaBD1nPWRtPe1XdcdZhuC10Oc9dQlldi3fS1vGPfi61VTB_e97sfZ2nE_5La5ibKly97QaMVeX4ib_qbPmqDOLDxWojYptvrbanhvTw0LMDyj92Yemr6GmVWk24CafYzhUBtvf-e8KVWHfPeNVfB537hUMROtnb3P2Ai1mcKSoamHQIIRn3kSkUD0Hg7sY7b-9LxTw617U5_JrdvsS5Qv8KJvkOYV-8jTAumLo3yhoc8WuMnYFRMDvbkwDV2T1LnqyfjyCzukxeiXxfgRMIDIrj2OBfNj33Xiw-rbU-thwedxYHIPJ0lIxU49DL4kAwlhAH173i_vZBUxMyqjVSvMIHutBPmEYNSDsnG0CVDRrYiF2BA3-7ZDPpQNjCUGUVP7K1NyA41OMZSeaRP8mtbuqrTwKT_BpNzx6IUc4_gFtkJZ_FgqpC2_uFPmtzLnSxnCM4Lz1om84BJVQ/http%3A%2F%2Flists.squid-cache.org%2Flistinfo%2Fsquid-users


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From dvanorder at deloitte.com  Sun Feb 24 14:26:46 2019
From: dvanorder at deloitte.com (Van Order, Drew (US - Hermitage))
Date: Sun, 24 Feb 2019 14:26:46 +0000
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <AM0PR04MB47539AEB5F719878A4D3BE588F790@AM0PR04MB4753.eurprd04.prod.outlook.com>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
 <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <04fc01d4cba3$ce63ecf0$6b2bc6d0$@ngtech.co.il>
 <CO1PR85MB0181275803A77F5C6DFAE39EC8790@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>,
 <AM0PR04MB47539AEB5F719878A4D3BE588F790@AM0PR04MB4753.eurprd04.prod.outlook.com>
Message-ID: <CO1PR85MB018181C58746E986C0103708C8790@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>

Wondered that too, and experimented with the squid.conf setting to see when warning messages appear, which was 1,000. Default cygwin setting of 3,200 is plenty.

Thanks for the idea, though!



Sent via the Samsung Galaxy S8+, an AT&T 5G Evolution smartphone


-------- Original message --------
From: Rafael Akchurin <rafael.akchurin at diladele.com>
Date: 2/24/19 8:47 AM (GMT-05:00)
To: "Van Order, Drew (US - Hermitage)" <dvanorder at deloitte.com>, eliezer at ngtech.co.il, 'Amos Jeffries' <squid3 at treenet.co.nz>, squid-users at lists.squid-cache.org
Subject: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

As far as I know the internal FD limit for Windows build is around 3K - might be being existed and thus unexpected behavior raising its ugly head..

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Van Order, Drew (US - Hermitage)
Sent: Sunday, 24 February 2019 14:40
To: eliezer at ngtech.co.il; 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing

This is helpful, and I especially appreciate the time given it is the weekend.

The Squids are confusing me, as everything is well behaved at the moment. One server was erroring off and on for a few hours earlier today, but stopped after a reboot.

It does appear that redirecting roughly 125 servers to no longer use the proxy has helped. Unfortunately, our F5 guy can't tell me how many IP addresses remain coming into this F5 VIP, which would give me the number of servers, and an idea how loaded this thing is. I have good reason to believe it is under 1,000. He has shown us graphs indicating the VIP isn't stressed, but I will keep working on him, b/c I can't imagine not being able to report how many distinct IP addresses hit the VIP.

I don't have a Visio, but

Server running the Microsoft Monitoring Agent sends data over tcp/443-->Internal facing firewall(s)-->F5 VIP-->one of 4 Squids-->internet

Each of the 4 VMWare Squids has 4 proc and 8 GB memory, 10 GB NIC.

We're a large enterprise with multiple data centers and many subnets, so there are quite a few firewalls, and most of the time a server must go through more than one firewall. Can't help but wonder if firewall exhaustion could cause the symptoms.

Revision: I typed the above last night. This morning, the server that had been erroring is at it again, but stopped. Others are fine. Interesting problem.

-----Original Message-----
From: eliezer at ngtech.co.il <eliezer at ngtech.co.il>
Sent: Saturday, February 23, 2019 12:16 PM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

The next tool might help you to understand the status of the open connections.
If the socket is being closed( I think Windows Server 2016 is a very good OS...).
https://secure-web.cisco.com/1gLLf4HP_bwYOteW6x8gJ8EGyBrYzTMzMIi7P6q7aGi136WObNRd7uZQkrv-CKTO7ipHpLgOvHaGbzxLT7RpG6AGtkeTHUn2O8-CIAgcBOCUzn6KyZoPhqsAcpIXokXWcjlWHdUVUwlZVT0WKEhuOuAGvw2washhJEOg1Gcbsf99cy7ofqJfuTc-fS23KxfiE8W-2GLLNuF_J8q5uGJdvUMhm6HN-4CO3c_i8wxOlHrxgX3GjSLbLo8odnA6YctD5A01sjW3dpC4oiioIkGY7gDY-hjSSNYr_xoZzsixScColG-JRDlR3uktjsFF5JCkU1EROfoOfUHsDdeJ0IV2Cpk6yzbSPNNno7jV5BmZSsmR_jRgW7WJa4eVhKUvicMfy8RBespjtbfk17lUf9JamqmxPBtP2eHsiIb4_wk9iJfRr_S-aA1Ve7rPDmCXm9bZ9HRmXphi8o5AeYMWbK9DTrnmPDmFamis922AT6F4KUuBvS3PKqeCkT3EUuGmlwHXxCiJGwYBKXQmOehcFbqgfFQ/https%3A%2F%2Fwww.nirsoft.net%2Futils%2Fcports.html

There is a possibility that some OS TCP limit is being reached and there for the socket closure.
If you are using F5 you can easily find out the load at the crash point.
I assume that if a normal Squid instance can take a load of 900k requests per second in somewhat constant rate for more than a minute then the issue might be else where then squid.
I am not sure but pretty sure that if you do not have anyone that is knowledgeable enough about windows sockets, sessions and FW limitations you will either:
- learn it your self
- find an expert
- use an OS that is more then 20% supported by any of the Squid-Cache team members and other developers around the globe.

Just to say a good word about Windows Server 2016, I compared it to a Windows 10 under load and it seems to take a lot more load.
Also it not just takes the load but balance it well (on an open source windows designed software).

Also if you have a specific use case maybe a specific proxy can be customized for it.
Let me know if you wish to shed more details on the configuration so I can take my time and understand if there is a solution else then Squid.

Eliezeer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Van Order, Drew (US - Hermitage)
Sent: Friday, February 22, 2019 15:32
To: Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing

The test box I set up outside the F5 finally started exhibiting these errors, once I pointed roughly 60 machines to it. It took a few hours.
Sounds like this narrows it down to either the OS itself (seems unlikely, other apps would crash), or the litany of agents our security folks have mandated. It may indeed be necessary to move to Linux.

Thank you very much for your time!

-----Original Message-----
From: Amos Jeffries <squid3 at treenet.co.nz>
Sent: Thursday, February 21, 2019 11:31 PM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; squid-users at lists.squid-cache.org
Subject: [EXT] Re: [squid-users] Squid for Windows Repeatedly Crashing

On 22/02/19 4:21 am, Van Order, Drew (US - Hermitage) wrote:
> Thank you for replying, and that's an excellent point.
>
> Short answer--definitely not in a container, these are garden variety
VMWare instances. I've already flagged the OS power settings to maximum performance, so nothing should be going to sleep. I'll doublecheck, though.
>
> So, if I understand correctly, this error could also be indicative of
> an
issue in between the agent and Squid. Agents first go through a firewall, then the F5 before reaching Squid.

No that is not what I meant.

The port Squid has already opened and used syscall listen(2) on is what is being closed (or its address corrupted) outside of Squid. That should only ever be closed by Squid itself. Thus the error.

It is being closed repeatedly. Thus the abort/shutdown. This is not a crash, it is intentional shutdown by Squid due to these fatal
(non-recoverable) errors.


>
> [Stopped, reason:Listener socket closed job1]: (14) Bad address
>
> Any thoughts on this error, which tends to be more common than the other?
>
> 2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
> 2019/02/20 09:42:33 kid1| Select loop Error. Retry 2
>

Notice how the error from the OS "(14) Bad Address" is the same. This is just another display of the same problem. Maybe the poll() layer reporting the exact same error as Squid tries to recover. Maybe for other non-listener ports also being corrupted somehow.

If non-listener ports are having that same error it would be a sign the machine memory is being corrupted rather than other software touching the listener ports specifically.


( The details you have provided so far have no hints about where the problem may be coming from, and I am not having any ideas about possibilities either. I just hope the above explanation of meaning can help you think of things to look at for more hints on this very weird issue. )

Amos
This message (including any attachments) contains confidential information intended for a specific individual and purpose, and is protected by law. If you are not the intended recipient, you should delete this message and any disclosure, copying, or distribution of this message, or the taking of any action based on it, by you is strictly prohibited.

v.E.1
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://secure-web.cisco.com/1rTtG7rZtQ6ZYF-exa33X6jslvqhns0Pi1uNpYErXcG6etibmd2SGhMCHECLwNvCY_z6WNGI9PaBD1nPWRtPe1XdcdZhuC10Oc9dQlldi3fS1vGPfi61VTB_e97sfZ2nE_5La5ibKly97QaMVeX4ib_qbPmqDOLDxWojYptvrbanhvTw0LMDyj92Yemr6GmVWk24CafYzhUBtvf-e8KVWHfPeNVfB537hUMROtnb3P2Ai1mcKSoamHQIIRn3kSkUD0Hg7sY7b-9LxTw617U5_JrdvsS5Qv8KJvkOYV-8jTAumLo3yhoc8WuMnYFRMDvbkwDV2T1LnqyfjyCzukxeiXxfgRMIDIrj2OBfNj33Xiw-rbU-thwedxYHIPJ0lIxU49DL4kAwlhAH173i_vZBUxMyqjVSvMIHutBPmEYNSDsnG0CVDRrYiF2BA3-7ZDPpQNjCUGUVP7K1NyA41OMZSeaRP8mtbuqrTwKT_BpNzx6IUc4_gFtkJZ_FgqpC2_uFPmtzLnSxnCM4Lz1om84BJVQ/http%3A%2F%2Flists.squid-cache.org%2Flistinfo%2Fsquid-users


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://secure-web.cisco.com/1Yp4oglvIuy6hUzZHykSqWJjhd1cnIyyY0c7NsY9il8SBh1aBObbh_voDSVz49Ag2jTcEVONo0o9fd7Y8EVx43GsvawkPmbymyJuELcntchcXJAQsP8QjkmG-6ndujF1n5TRZ0urNPeK-5x7WvPunADCWhPkv8tO743dAtOXjOXKAp-CBLw4Nxm9kLEPh-qOneGlR9qxMsGeRuBkGAyvXaeS4bYnY0f5VnuQN9wQ9gEux487TkTtlwE-Wu8pyryP8wkw-5ke0_jMZSXOszXYLNwhcXzVJyuTLKrtkNOdcE0Yp_S6V9C7c88f6NnRp_1FRmdpj_GURVtwUIP4Aa6E-udgS18am0j9VYBUdNvz8EdhJJQq08crZrH_OK8j6AciiRZp40QHAiW_-Moxu2NySShBoDQPQjLHNDTPssnv_pDtw0sKluNi6GXvSiIkGAq2fX6fAkyJAkW60K4aCa_2qQ9xp_ICLegvAjfKbT6fRl23NfrON7w2Bv0_2bhvAtwBL/http%3A%2F%2Flists.squid-cache.org%2Flistinfo%2Fsquid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190224/b6b34c28/attachment.htm>

From eliezer at ngtech.co.il  Sun Feb 24 18:32:33 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Sun, 24 Feb 2019 20:32:33 +0200
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <AM0PR04MB47539AEB5F719878A4D3BE588F790@AM0PR04MB4753.eurprd04.prod.outlook.com>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
 <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <04fc01d4cba3$ce63ecf0$6b2bc6d0$@ngtech.co.il>
 <CO1PR85MB0181275803A77F5C6DFAE39EC8790@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <AM0PR04MB47539AEB5F719878A4D3BE588F790@AM0PR04MB4753.eurprd04.prod.outlook.com>
Message-ID: <000001d4cc6f$4fd71980$ef854c80$@ngtech.co.il>

It depends on the hardware in the server grade Windows.
It can take more then 3k conn's for 100%.
It's possible that squid was not designed for windows 2k16....

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Rafael Akchurin <rafael.akchurin at diladele.com> 
Sent: Sunday, February 24, 2019 15:47
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; eliezer at ngtech.co.il; 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Squid for Windows Repeatedly Crashing

As far as I know the internal FD limit for Windows build is around 3K - might be being existed and thus unexpected behavior raising its ugly head..

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Van Order, Drew (US - Hermitage)
Sent: Sunday, 24 February 2019 14:40
To: eliezer at ngtech.co.il; 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing

This is helpful, and I especially appreciate the time given it is the weekend.

The Squids are confusing me, as everything is well behaved at the moment. One server was erroring off and on for a few hours earlier today, but stopped after a reboot.

It does appear that redirecting roughly 125 servers to no longer use the proxy has helped. Unfortunately, our F5 guy can't tell me how many IP addresses remain coming into this F5 VIP, which would give me the number of servers, and an idea how loaded this thing is. I have good reason to believe it is under 1,000. He has shown us graphs indicating the VIP isn't stressed, but I will keep working on him, b/c I can't imagine not being able to report how many distinct IP addresses hit the VIP.

I don't have a Visio, but

Server running the Microsoft Monitoring Agent sends data over tcp/443-->Internal facing firewall(s)-->F5 VIP-->one of 4 Squids-->internet 

Each of the 4 VMWare Squids has 4 proc and 8 GB memory, 10 GB NIC.

We're a large enterprise with multiple data centers and many subnets, so there are quite a few firewalls, and most of the time a server must go through more than one firewall. Can't help but wonder if firewall exhaustion could cause the symptoms.

Revision: I typed the above last night. This morning, the server that had been erroring is at it again, but stopped. Others are fine. Interesting problem.

-----Original Message-----
From: eliezer at ngtech.co.il <eliezer at ngtech.co.il>
Sent: Saturday, February 23, 2019 12:16 PM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

The next tool might help you to understand the status of the open connections.
If the socket is being closed( I think Windows Server 2016 is a very good OS...).
https://secure-web.cisco.com/1gLLf4HP_bwYOteW6x8gJ8EGyBrYzTMzMIi7P6q7aGi136WObNRd7uZQkrv-CKTO7ipHpLgOvHaGbzxLT7RpG6AGtkeTHUn2O8-CIAgcBOCUzn6KyZoPhqsAcpIXokXWcjlWHdUVUwlZVT0WKEhuOuAGvw2washhJEOg1Gcbsf99cy7ofqJfuTc-fS23KxfiE8W-2GLLNuF_J8q5uGJdvUMhm6HN-4CO3c_i8wxOlHrxgX3GjSLbLo8odnA6YctD5A01sjW3dpC4oiioIkGY7gDY-hjSSNYr_xoZzsixScColG-JRDlR3uktjsFF5JCkU1EROfoOfUHsDdeJ0IV2Cpk6yzbSPNNno7jV5BmZSsmR_jRgW7WJa4eVhKUvicMfy8RBespjtbfk17lUf9JamqmxPBtP2eHsiIb4_wk9iJfRr_S-aA1Ve7rPDmCXm9bZ9HRmXphi8o5AeYMWbK9DTrnmPDmFamis922AT6F4KUuBvS3PKqeCkT3EUuGmlwHXxCiJGwYBKXQmOehcFbqgfFQ/https%3A%2F%2Fwww.nirsoft.net%2Futils%2Fcports.html

There is a possibility that some OS TCP limit is being reached and there for the socket closure.
If you are using F5 you can easily find out the load at the crash point.
I assume that if a normal Squid instance can take a load of 900k requests per second in somewhat constant rate for more than a minute then the issue might be else where then squid.
I am not sure but pretty sure that if you do not have anyone that is knowledgeable enough about windows sockets, sessions and FW limitations you will either:
- learn it your self
- find an expert
- use an OS that is more then 20% supported by any of the Squid-Cache team members and other developers around the globe.

Just to say a good word about Windows Server 2016, I compared it to a Windows 10 under load and it seems to take a lot more load.
Also it not just takes the load but balance it well (on an open source windows designed software).

Also if you have a specific use case maybe a specific proxy can be customized for it.
Let me know if you wish to shed more details on the configuration so I can take my time and understand if there is a solution else then Squid.

Eliezeer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Van Order, Drew (US - Hermitage)
Sent: Friday, February 22, 2019 15:32
To: Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing

The test box I set up outside the F5 finally started exhibiting these errors, once I pointed roughly 60 machines to it. It took a few hours.
Sounds like this narrows it down to either the OS itself (seems unlikely, other apps would crash), or the litany of agents our security folks have mandated. It may indeed be necessary to move to Linux.

Thank you very much for your time!

-----Original Message-----
From: Amos Jeffries <squid3 at treenet.co.nz>
Sent: Thursday, February 21, 2019 11:31 PM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; squid-users at lists.squid-cache.org
Subject: [EXT] Re: [squid-users] Squid for Windows Repeatedly Crashing

On 22/02/19 4:21 am, Van Order, Drew (US - Hermitage) wrote:
> Thank you for replying, and that's an excellent point.
>
> Short answer--definitely not in a container, these are garden variety
VMWare instances. I've already flagged the OS power settings to maximum performance, so nothing should be going to sleep. I'll doublecheck, though.
>
> So, if I understand correctly, this error could also be indicative of 
> an
issue in between the agent and Squid. Agents first go through a firewall, then the F5 before reaching Squid.

No that is not what I meant.

The port Squid has already opened and used syscall listen(2) on is what is being closed (or its address corrupted) outside of Squid. That should only ever be closed by Squid itself. Thus the error.

It is being closed repeatedly. Thus the abort/shutdown. This is not a crash, it is intentional shutdown by Squid due to these fatal
(non-recoverable) errors.


>
> [Stopped, reason:Listener socket closed job1]: (14) Bad address
>
> Any thoughts on this error, which tends to be more common than the other?
>
> 2019/02/20 09:42:33 kid1| comm_poll: poll failure: (14) Bad address
> 2019/02/20 09:42:33 kid1| Select loop Error. Retry 2
>

Notice how the error from the OS "(14) Bad Address" is the same. This is just another display of the same problem. Maybe the poll() layer reporting the exact same error as Squid tries to recover. Maybe for other non-listener ports also being corrupted somehow.

If non-listener ports are having that same error it would be a sign the machine memory is being corrupted rather than other software touching the listener ports specifically.


( The details you have provided so far have no hints about where the problem may be coming from, and I am not having any ideas about possibilities either. I just hope the above explanation of meaning can help you think of things to look at for more hints on this very weird issue. )

Amos
This message (including any attachments) contains confidential information intended for a specific individual and purpose, and is protected by law. If you are not the intended recipient, you should delete this message and any disclosure, copying, or distribution of this message, or the taking of any action based on it, by you is strictly prohibited.

v.E.1
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://secure-web.cisco.com/1rTtG7rZtQ6ZYF-exa33X6jslvqhns0Pi1uNpYErXcG6etibmd2SGhMCHECLwNvCY_z6WNGI9PaBD1nPWRtPe1XdcdZhuC10Oc9dQlldi3fS1vGPfi61VTB_e97sfZ2nE_5La5ibKly97QaMVeX4ib_qbPmqDOLDxWojYptvrbanhvTw0LMDyj92Yemr6GmVWk24CafYzhUBtvf-e8KVWHfPeNVfB537hUMROtnb3P2Ai1mcKSoamHQIIRn3kSkUD0Hg7sY7b-9LxTw617U5_JrdvsS5Qv8KJvkOYV-8jTAumLo3yhoc8WuMnYFRMDvbkwDV2T1LnqyfjyCzukxeiXxfgRMIDIrj2OBfNj33Xiw-rbU-thwedxYHIPJ0lIxU49DL4kAwlhAH173i_vZBUxMyqjVSvMIHutBPmEYNSDsnG0CVDRrYiF2BA3-7ZDPpQNjCUGUVP7K1NyA41OMZSeaRP8mtbuqrTwKT_BpNzx6IUc4_gFtkJZ_FgqpC2_uFPmtzLnSxnCM4Lz1om84BJVQ/http%3A%2F%2Flists.squid-cache.org%2Flistinfo%2Fsquid-users


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From augustus_meyer at gmx.net  Sun Feb 24 22:34:26 2019
From: augustus_meyer at gmx.net (reinerotto)
Date: Sun, 24 Feb 2019 16:34:26 -0600 (CST)
Subject: [squid-users] squid delay_pools can't limit speed on certain
	connections
In-Reply-To: <0ecd5fdb-f421-52c5-8435-5f3869d04e3e@treenet.co.nz>
References: <848907109.784103.1550135150221@mail.yahoo.com>
 <cff06c35-41fe-e5b5-8107-8116cc7d0a3f@measurement-factory.com>
 <1550663170426-0.post@n4.nabble.com>
 <0ecd5fdb-f421-52c5-8435-5f3869d04e3e@treenet.co.nz>
Message-ID: <1551047666028-0.post@n4.nabble.com>

1) I did some tests with my own webserver, and my local openwrt-system,
running squid. 
And I can see, that http-traffic is throttled, but https is _not_.
I used 10MB of data for my tests. Download speed for http is throttled to
(my) 512kBit/s, as expected, but https is not throttled.

2) I got some debug info from the https-test; because of privacy I am
hesitating to upload here directly. 
Pls, advise.

3) Thank you very much for the enhancements regarding my squid.conf


 



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Sun Feb 24 23:37:40 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 25 Feb 2019 12:37:40 +1300
Subject: [squid-users] squid delay_pools can't limit speed on certain
 connections
In-Reply-To: <1551047666028-0.post@n4.nabble.com>
References: <848907109.784103.1550135150221@mail.yahoo.com>
 <cff06c35-41fe-e5b5-8107-8116cc7d0a3f@measurement-factory.com>
 <1550663170426-0.post@n4.nabble.com>
 <0ecd5fdb-f421-52c5-8435-5f3869d04e3e@treenet.co.nz>
 <1551047666028-0.post@n4.nabble.com>
Message-ID: <b0314914-672b-0c14-1f8a-680fc998c87d@treenet.co.nz>

On 25/02/19 11:34 am, reinerotto wrote:
> 1) I did some tests with my own webserver, and my local openwrt-system,
> running squid. 
> And I can see, that http-traffic is throttled, but https is _not_.
> I used 10MB of data for my tests. Download speed for http is throttled to
> (my) 512kBit/s, as expected, but https is not throttled.
> 
> 2) I got some debug info from the https-test; because of privacy I am
> hesitating to upload here directly. 
> Pls, advise.
> 
> 3) Thank you very much for the enhancements regarding my squid.conf
> 

Does the attached patch fix this issue?


If not, then please send us a cache.log made with "debug_options 26,6
77,6". That should contain sufficient info to know whether the pool is
being decided properly without leaking any secure info.


Amos
-------------- next part --------------
A non-text attachment was scrubbed...
Name: tunnel_no-delay_mk3.patch
Type: text/x-patch
Size: 543 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190225/e0d257fd/attachment.bin>

From augustus_meyer at gmx.net  Mon Feb 25 10:26:33 2019
From: augustus_meyer at gmx.net (reinerotto)
Date: Mon, 25 Feb 2019 04:26:33 -0600 (CST)
Subject: [squid-users] squid delay_pools can't limit speed on certain
	connections
In-Reply-To: <b0314914-672b-0c14-1f8a-680fc998c87d@treenet.co.nz>
References: <848907109.784103.1550135150221@mail.yahoo.com>
 <cff06c35-41fe-e5b5-8107-8116cc7d0a3f@measurement-factory.com>
 <1550663170426-0.post@n4.nabble.com>
 <0ecd5fdb-f421-52c5-8435-5f3869d04e3e@treenet.co.nz>
 <1551047666028-0.post@n4.nabble.com>
 <b0314914-672b-0c14-1f8a-680fc998c87d@treenet.co.nz>
Message-ID: <1551090393176-0.post@n4.nabble.com>

After application of patch _and_ activation of requested debug_options
download via https is slower as in previous tests; but I have SD-card in the
openwrt device for logging, so this might be reason of slow down.
But it still does not seem to throttle to expected speed.
Attached the cache.log with debug info.
Password for unzip via email.

cache.zip
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t376816/cache.zip>  



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From numsys at free.fr  Mon Feb 25 17:05:21 2019
From: numsys at free.fr (FredB)
Date: Mon, 25 Feb 2019 18:05:21 +0100
Subject: [squid-users] ICAP and 403 Encapsulated answers (SSL denied
 domains)
In-Reply-To: <0e6e01d4cc40$ce1f7b90$6a5e72b0$@ngtech.co.il>
References: <7ad1a209-0420-d437-6df3-a8cc4ee48663@measurement-factory.com>
 <1964743467.919672431.1551004388453.JavaMail.root@zimbra30-e5.priv.proxad.net>
 <0e6e01d4cc40$ce1f7b90$6a5e72b0$@ngtech.co.il>
Message-ID: <f9f4fb59-ccc2-9009-ac33-9c7077561ad1@free.fr>

Hello,

when a SSL website request is dropped by proxy with FF the connection is 
not well finished

Example of this here, first message:

https://bugzilla.mozilla.org/show_bug.cgi?id=1522093




From eliezer at ngtech.co.il  Tue Feb 26 00:05:58 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Tue, 26 Feb 2019 02:05:58 +0200
Subject: [squid-users] ICAP and 403 Encapsulated answers (SSL denied
	domains)
In-Reply-To: <f9f4fb59-ccc2-9009-ac33-9c7077561ad1@free.fr>
References: <7ad1a209-0420-d437-6df3-a8cc4ee48663@measurement-factory.com>
 <1964743467.919672431.1551004388453.JavaMail.root@zimbra30-e5.priv.proxad.net>
 <0e6e01d4cc40$ce1f7b90$6a5e72b0$@ngtech.co.il>
 <f9f4fb59-ccc2-9009-ac33-9c7077561ad1@free.fr>
Message-ID: <000201d4cd67$0d15e010$2741a030$@ngtech.co.il>

A simple Forward proxy with a CONNECT right?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: FredB <numsys at free.fr> 
Sent: Monday, February 25, 2019 19:05
To: eliezer at ngtech.co.il
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] ICAP and 403 Encapsulated answers (SSL denied domains)

Hello,

when a SSL website request is dropped by proxy with FF the connection is 
not well finished

Example of this here, first message:

https://bugzilla.mozilla.org/show_bug.cgi?id=1522093





From rafael.akchurin at diladele.com  Tue Feb 26 11:39:52 2019
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 26 Feb 2019 11:39:52 +0000
Subject: [squid-users] Ubuntu 18 LTS repository for Squid 4.6 (rebuilt with
 sslbump support from sources in Debian unstable)
Message-ID: <AM0PR04MB47535D4FC1FB71130F1FBCB18F7B0@AM0PR04MB4753.eurprd04.prod.outlook.com>

Greeting all,

The online repository with latest Squid 4.6 (rebuilt from Debian unstable with sslbump support) for Ubuntu 18 LTS 64-bit is available at squid46.diladele.com. Github repo at https://github.com/diladele/squid-ubuntu contains the scripts we used to make this compilation.

Hope you will find this helpful. Note that older repo of squid44.diladele.com will be taken down in one year.

Best regards,
Rafael Akchurin
Diladele B.V.

P.S. Here are simple instructions how to use the repo. For more information see readme at https://github.com/diladele/squid-ubuntu .

# add diladele apt key
wget -qO - http://packages.diladele.com/diladele_pub.asc | sudo apt-key add -

# add repo
echo "deb http://squid46.diladele.com/ubuntu/ bionic main" > /etc/apt/sources.list.d/squid46.diladele.com.list

# update the apt cache
apt-get update

# install
apt-get install squid-common
apt-get install squid
apt-get install squidclient



--
Please take a look at another our project - DNS Safety filtering server.
Sort of Web Safety implemented as DNS Server. Might be interesting in deployments where HTTPS decryption is not possible.
https://dnssafety.io/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190226/96beadf5/attachment.htm>

From stilyangeorgiev at gmail.com  Tue Feb 26 11:55:29 2019
From: stilyangeorgiev at gmail.com (Stilyan Georgiev)
Date: Tue, 26 Feb 2019 13:55:29 +0200
Subject: [squid-users] Disable tls1.3 support ,
	can't get SNI / cert details when it's used
Message-ID: <a0f24855-e1dc-bbe0-f08c-df419e06f135@gmail.com>

Hi,

Squid 4.5 with openssl support here.
SSL bumping can't obtain SNI / cert domain to perform filtering when 
tls1.3 is used.
I want to disable support for tls1.3 in config but don't find way to do 
so. There's the outdated sslproxy_options config directive which doesn't 
appear to be supported in 4.5

The goal is - allow everything , besides tls1.3

Thanks in advance.



From squid3 at treenet.co.nz  Mon Feb 25 04:22:57 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 25 Feb 2019 17:22:57 +1300
Subject: [squid-users] [squid-announce] Squid 4.6 is available
Message-ID: <4a276911-00e6-3eb2-876a-bf29bb067527@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.6 release!


This release is a security and bug fix release resolving several issues
found in the prior Squid releases.


The major changes to be aware of:


 * Fix several cases of rock cache corruption

Several bugs have been found in Squids use of shared memory by the rock
cache functionality. These may have been causing performance issues
under high loads and possible corrupting the cache objects stored in
rock format. Existing cache validation on HITs should have been catching
many of these objects and preventing use. However dues to the nature of
corruption in general we cannot be completely certain of that.

All users of rock cache type are urged to upgrade as soon as possible.

If your cache is known to contain sensitive data please also consider
wiping the existing rock cache contents to guarantee a clean state.


 * Fix BodyPipe/Sink memory leaks associated with auto-consumption

This bug shows up as a small memory leak when eCAP service blocks a
transaction, or presents a complete replacement response payload. It may
also occur in other situations that use Squids auto-consume feature to
clear unwanted HTTP message data from a connection.


 * Bug 4915: Detect IPv6 loopback binding errors

This bug shows up as helpers being started but communication not working
on machines where IPv6 has been disabled by sysctl preventing IPv6
address assignment.

This release will now detect these machine configurations and trigger
IPv4-only functionality on startup if necessary.


 * Bug 4914: Do not call setsid() in --foreground mode

Squid executed in --foreground is always a process group leader. Thus,
setsid(2) is unnecessary and always fails (with EPERM) for such Squids.


 * Bug 4856: Exit when GoIntoBackground() fork() call fails

Not exiting can leave the proxy running with inconsistent access
permissions to system resources. Squid has historically dropped
privileges anyway so this is not a security breach. But the behaviour
can confuse some third-party daemon managers.

This release will now strictly abort with an error if fork() is not
successful when starting Squid.


 * Fix OpenSSL builds that define OPENSSL_NO_ENGINE

Squid builds have been failing with compile against OpenSSL when custom
engine support is disabled. This release fixes the feature detection to
allow such builds to complete.



  All users of Squid-4 are urged to upgrade as soon as possible.

  All users of Squid-3 are encouraged to upgrade where possible.


See the ChangeLog for the full list of changes in this and earlier
releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

  http://www.squid-cache.org/Versions/v4/
  ftp://ftp.squid-cache.org/pub/squid/
  ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

  http://www.squid-cache.org/Download/http-mirrors.html
  http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
  http://bugs.squid-cache.org/


Amos Jeffries
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From numsys at free.fr  Tue Feb 26 13:41:24 2019
From: numsys at free.fr (FredB)
Date: Tue, 26 Feb 2019 14:41:24 +0100
Subject: [squid-users] ICAP and 403 Encapsulated answers (SSL denied
 domains)
In-Reply-To: <000201d4cd67$0d15e010$2741a030$@ngtech.co.il>
References: <7ad1a209-0420-d437-6df3-a8cc4ee48663@measurement-factory.com>
 <1964743467.919672431.1551004388453.JavaMail.root@zimbra30-e5.priv.proxad.net>
 <0e6e01d4cc40$ce1f7b90$6a5e72b0$@ngtech.co.il>
 <f9f4fb59-ccc2-9009-ac33-9c7077561ad1@free.fr>
 <000201d4cd67$0d15e010$2741a030$@ngtech.co.il>
Message-ID: <990f3d11-c35c-eb4b-29ac-2a0ca2ec37d7@free.fr>

Yes, here my usage case

1- Squid as explicit proxy connected to e2guardian with ICAP

2 - E2guardian block a SSL website (no bump) a 403 header is returned -> 
I tried 302, 307, 200, without more success

3 - With IE or chrome the connection is well dropped but with FF (61 -> 
next 67) the connection seems dropped but still active, you can see this 
issue with a simple refresh Firefox is waiting the website until there 
is a timeout

Fred




From rousskov at measurement-factory.com  Tue Feb 26 19:10:31 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 26 Feb 2019 12:10:31 -0700
Subject: [squid-users] Disable tls1.3 support ,
 can't get SNI / cert details when it's used
In-Reply-To: <a0f24855-e1dc-bbe0-f08c-df419e06f135@gmail.com>
References: <a0f24855-e1dc-bbe0-f08c-df419e06f135@gmail.com>
Message-ID: <0c53626c-b76d-616d-b4b3-ab0d76cb3651@measurement-factory.com>

On 2/26/19 4:55 AM, Stilyan Georgiev wrote:

> Squid 4.5 with openssl support here.
> SSL bumping can't obtain SNI / cert domain to perform filtering when
> tls1.3 is used.
> I want to disable support for tls1.3 in config but don't find way to do
> so. There's the outdated sslproxy_options config directive which doesn't
> appear to be supported in 4.5
> 
> The goal is - allow everything , besides tls1.3

Good question!

TLS v1.3 clients that use "Middlebox Compatibility Mode", including
OpenSSL s_client and popular browsers, pretend to be TLS v1.2 clients
that attempt to restore a non-existent TLS session. Squid probably does
not have ACLs that can detect those lies. However, if you think you can
detect them, you can pass TLS Hello to your external ACL via the
%>handshake logformat code.

If you are asking whether Squid can downgrade TLS v1.3 to TLS v1.2, then
I suspect the answer is "yes, but only if you bump the client connection
first": A peeking Squid cannot negotiate a different TLS version with
the client. If TLS downgrade is what you want, you can probably use an
OpenSSL version that does not support TLS v1.3. There may also be an
OpenSSL v1.1.1 configuration option to turn TLS v1.3 support off, but I
have not research that.

Finally, there may be a bug in earlier versions of Squid that breaks
peeking at TLS v1.3 servers during step2. Staring works. We have not
tested Squid v4.5 though. Please note that peeking at TLS v1.3 servers
is largely pointless because useful information in TLS v1.3 Server Hello
is encrypted.


HTH,

Alex.


From mzgmedia at gmail.com  Tue Feb 26 21:27:31 2019
From: mzgmedia at gmail.com (mzgmedia)
Date: Tue, 26 Feb 2019 15:27:31 -0600 (CST)
Subject: [squid-users] /64 ipv6
Message-ID: <1551216451445-0.post@n4.nabble.com>

hello

it will be nice if will be possible to specify an entire /64 range on the
squid config



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Tue Feb 26 22:03:47 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 27 Feb 2019 11:03:47 +1300
Subject: [squid-users] /64 ipv6
In-Reply-To: <1551216451445-0.post@n4.nabble.com>
References: <1551216451445-0.post@n4.nabble.com>
Message-ID: <b044f097-b271-192f-231f-4d123801f204@treenet.co.nz>

On 27/02/19 10:27 am, mzgmedia wrote:
> hello
> 
> it will be nice if will be possible to specify an entire /64 range on the
> squid config
>

Squid uses CIDR for settings where ranges are relevant.

If you are having a particular problem. Please state what that problem
is, what you have tried doing.

Amos


From mzgmedia at gmail.com  Tue Feb 26 22:10:53 2019
From: mzgmedia at gmail.com (mzgmedia)
Date: Tue, 26 Feb 2019 16:10:53 -0600 (CST)
Subject: [squid-users] /64 ipv6
In-Reply-To: <b044f097-b271-192f-231f-4d123801f204@treenet.co.nz>
References: <1551216451445-0.post@n4.nabble.com>
 <b044f097-b271-192f-231f-4d123801f204@treenet.co.nz>
Message-ID: <1551219053567-0.post@n4.nabble.com>

we want to add the entire /64

something like this

acl A myip a::b:c/64 
tcp_outgoing_address A  a::b:c/64



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Tue Feb 26 23:20:00 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 27 Feb 2019 12:20:00 +1300
Subject: [squid-users] /64 ipv6
In-Reply-To: <1551219053567-0.post@n4.nabble.com>
References: <1551216451445-0.post@n4.nabble.com>
 <b044f097-b271-192f-231f-4d123801f204@treenet.co.nz>
 <1551219053567-0.post@n4.nabble.com>
Message-ID: <c041606d-2c4a-2400-7ea4-50cd1ca8851b@treenet.co.nz>

On 27/02/19 11:10 am, mzgmedia wrote:
> we want to add the entire /64
> 
> something like this
> 
> acl A myip a::b:c/64 
> tcp_outgoing_address A  a::b:c/64
> 

That directive is for selecting a src-IP address of IP packets that form
a TCP connection. There can only ever be one src-IP per connection.

The operating system API enforces that by only allowing bind()'ing to a
single IP address at a time. So that above is not possible to do.


Depending on what you actually want to achieve there are probably other
features needed.

Amos


From eliezer at ngtech.co.il  Tue Feb 26 23:22:42 2019
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 27 Feb 2019 01:22:42 +0200
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <AM0PR04MB47539AEB5F719878A4D3BE588F790@AM0PR04MB4753.eurprd04.prod.outlook.com>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
 <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <04fc01d4cba3$ce63ecf0$6b2bc6d0$@ngtech.co.il>
 <CO1PR85MB0181275803A77F5C6DFAE39EC8790@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <AM0PR04MB47539AEB5F719878A4D3BE588F790@AM0PR04MB4753.eurprd04.prod.outlook.com>
Message-ID: <d9c78152489a2929b626020e59a03288@ngtech.co.il>

It depends on the hardware in the server grade Windows.
It can take more then 3k conn's for 100%.
It's possible that squid was not designed for windows 2k16....

Eliezer

On 2019-02-24 15:47, Rafael Akchurin wrote:

> As far as I know the internal FD limit for Windows build is around 3K - 
> might be being existed and thus unexpected behavior raising its ugly 
> head..
> 
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf 
> Of Van Order, Drew (US - Hermitage)
> Sent: Sunday, 24 February 2019 14:40
> To: eliezer at ngtech.co.il; 'Amos Jeffries' <squid3 at treenet.co.nz>; 
> squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing
> 
> This is helpful, and I especially appreciate the time given it is the 
> weekend.
> <SNIP>


From stilyangeorgiev at gmail.com  Wed Feb 27 08:59:05 2019
From: stilyangeorgiev at gmail.com (Stilyan Georgiev)
Date: Wed, 27 Feb 2019 10:59:05 +0200
Subject: [squid-users] Squid with custom openssl path is using the openssl
 installed in default path
Message-ID: <7e7b046a-c1a5-44c8-4915-69a419a63044@gmail.com>

Hi,

Trying to build squid using custom path for openssl and related 
libraries. My goal is to use openssl 1.1.1 which is installed in /usr/local

--
/usr/local/bin/openssl version
OpenSSL 1.1.1b? 26 Feb 2019
--

I did install it like that:

--
 ?./config --prefix=/usr/local --openssldir=/usr/local/lib/ssl 
--libdir=lib '-Wl,--enable-new-dtags,-rpath,$(LIBRPATH)' no-tls1_3 
no-ssl3 no-idea no-mdc2 no-rc5 no-zlib enable-unit-test enable-rfc3779 
enable-cms
--

On the system (Ubuntu 18.04.02) I've got earlier version of openssl 
installed , which is dependency for other packages.

--
dpkg --list |grep ssl
ii? libgnutls-openssl27:amd64???????????? 3.5.18-1ubuntu1
ii? libio-socket-ssl-perl???????????????? 2.056-1
ii? libnet-smtp-ssl-perl????????????????? 1.04-1
ii? libnet-ssleay-perl??????????????????? 1.84-1build1
ii? libssl-doc??????????????????????????? 1.1.0g-2ubuntu4.3
ii? libssl1.0.0:amd64???????????????????? 1.0.2n-1ubuntu5.2
ii? libssl1.1:amd64?????????????????????? 1.1.0g-2ubuntu4.3
ii? libxmlsec1-openssl:amd64????????????? 1.2.25-1build1
ii? libzstd1:amd64??????????????????????? 1.3.3+dfsg-2ubuntu1
ii? openssl?????????????????????????????? 1.1.0g-2ubuntu4.3
ii? perl-openssl-defaults:amd64?????????? 3build1
ii? python3-openssl?????????????????????? 17.5.0-1ubuntu1
rc? ssl-cert????????????????????????????? 1.0.39

--

I also had the libssl-dev which I successfully uninstalled in desperate 
attempts but that didn't help.

This is how I config squid (4.5 incl. latest bugfixes):

--
./configure --prefix=/usr/local/squid --with-openssl=/usr/local
--

During config I saw the line: configure: OpenSSL library support: yes 
-L/usr/local/lib -L/usr/local/lib -lssl -lcrypto

However after installation I'm pulling my hair over this:

--
/usr/local/squid/sbin/squid -v
Squid Cache: Version 4.5-20190208-r568e66b7c
Service Name: squid

This binary uses OpenSSL 1.1.0g? 2 Nov 2017. For legal restrictions on 
distribution see https://www.openssl.org/source/license.html

configure options:? '--prefix=/usr/local/squid' '--with-openssl=/usr/local'
--

Instead of using openssl 1.1.1 from path I gave it uses the system package.

Desperate attempts:

I've also tried configuring squid like so with same end result - 
non-custom openssl used

--
./configure? --prefix=/usr/local/squid --with-openssl 
'LIBOPENSSL_CFLAGS=-I/usr/local/include/openssl -L/usr/local/lib'
--

Tried config of openssl like so (note openssldir not /usr/local/lib/ssl) 
with same end result:

--
./config --prefix=/usr/local --openssldir=/usr/local/lib --libdir=lib 
'-Wl,--enable-new-dtags,-rpath,$(LIBRPATH)' no-tls1_3 no-ssl3 no-idea 
no-mdc2 no-rc5 no-zlib enable-unit-test enable-rfc3779 enable-cms
--

I'm really, really desperate over here.

Thanks in advance for helping out.



From stilyangeorgiev at gmail.com  Wed Feb 27 10:39:31 2019
From: stilyangeorgiev at gmail.com (Stilyan Georgiev)
Date: Wed, 27 Feb 2019 12:39:31 +0200
Subject: [squid-users] Squid with custom openssl path is using the
 openssl installed in default path
In-Reply-To: <7e7b046a-c1a5-44c8-4915-69a419a63044@gmail.com>
References: <7e7b046a-c1a5-44c8-4915-69a419a63044@gmail.com>
Message-ID: <12625883-3a07-615a-48ec-f01e4c63d5ce@gmail.com>

Modified Makefile, replacing LIBOPENSSL_CFLAGS = -I/usr/local/include 
with LIBOPENSSL_CFLAGS = -I/usr/local/include/openssl

Afterwards I got squid reporting it uses my custom-path openssl:

--
Squid Cache: Version 4.5-20190208-r568e66b7c
Service Name: squid

This binary uses OpenSSL 1.1.1b? 26 Feb 2019. For legal restrictions on 
distribution see https://www.openssl.org/source/license.html

configure options:? '--prefix=/usr/local/squid' '--with-openssl=/usr/local'
--

And even though I built the openssl without tls 1.3 support, I'm still 
being able to use it when browsing through the proxy.

Also tried tls_outgoing_options options=NO_TLSv1_3 in config .. then in 
cache.log I got -- 2019/02/27 10:32:10 kid1| ERROR: Unknown TLS option 
NO_TLSv1_3

Which makes me thing even though squid reports it uses openssl 1.1.1 , 
it lies to me and still uses the ubuntu version :)

Truly blocked with this.

On 2/27/2019 10:59 AM, Stilyan Georgiev wrote:
> Hi,
>
> Trying to build squid using custom path for openssl and related 
> libraries. My goal is to use openssl 1.1.1 which is installed in 
> /usr/local
>
> -- 
> /usr/local/bin/openssl version
> OpenSSL 1.1.1b? 26 Feb 2019
> -- 
>
> I did install it like that:
>
> -- 
> ?./config --prefix=/usr/local --openssldir=/usr/local/lib/ssl 
> --libdir=lib '-Wl,--enable-new-dtags,-rpath,$(LIBRPATH)' no-tls1_3 
> no-ssl3 no-idea no-mdc2 no-rc5 no-zlib enable-unit-test enable-rfc3779 
> enable-cms
> -- 
>
> On the system (Ubuntu 18.04.02) I've got earlier version of openssl 
> installed , which is dependency for other packages.
>
> -- 
> dpkg --list |grep ssl
> ii? libgnutls-openssl27:amd64???????????? 3.5.18-1ubuntu1
> ii? libio-socket-ssl-perl???????????????? 2.056-1
> ii? libnet-smtp-ssl-perl????????????????? 1.04-1
> ii? libnet-ssleay-perl??????????????????? 1.84-1build1
> ii? libssl-doc??????????????????????????? 1.1.0g-2ubuntu4.3
> ii? libssl1.0.0:amd64???????????????????? 1.0.2n-1ubuntu5.2
> ii? libssl1.1:amd64?????????????????????? 1.1.0g-2ubuntu4.3
> ii? libxmlsec1-openssl:amd64????????????? 1.2.25-1build1
> ii? libzstd1:amd64??????????????????????? 1.3.3+dfsg-2ubuntu1
> ii? openssl?????????????????????????????? 1.1.0g-2ubuntu4.3
> ii? perl-openssl-defaults:amd64?????????? 3build1
> ii? python3-openssl?????????????????????? 17.5.0-1ubuntu1
> rc? ssl-cert????????????????????????????? 1.0.39
>
> -- 
>
> I also had the libssl-dev which I successfully uninstalled in 
> desperate attempts but that didn't help.
>
> This is how I config squid (4.5 incl. latest bugfixes):
>
> -- 
> ./configure --prefix=/usr/local/squid --with-openssl=/usr/local
> -- 
>
> During config I saw the line: configure: OpenSSL library support: yes 
> -L/usr/local/lib -L/usr/local/lib -lssl -lcrypto
>
> However after installation I'm pulling my hair over this:
>
> -- 
> /usr/local/squid/sbin/squid -v
> Squid Cache: Version 4.5-20190208-r568e66b7c
> Service Name: squid
>
> This binary uses OpenSSL 1.1.0g? 2 Nov 2017. For legal restrictions on 
> distribution see https://www.openssl.org/source/license.html
>
> configure options:? '--prefix=/usr/local/squid' 
> '--with-openssl=/usr/local'
> -- 
>
> Instead of using openssl 1.1.1 from path I gave it uses the system 
> package.
>
> Desperate attempts:
>
> I've also tried configuring squid like so with same end result - 
> non-custom openssl used
>
> -- 
> ./configure? --prefix=/usr/local/squid --with-openssl 
> 'LIBOPENSSL_CFLAGS=-I/usr/local/include/openssl -L/usr/local/lib'
> -- 
>
> Tried config of openssl like so (note openssldir not 
> /usr/local/lib/ssl) with same end result:
>
> -- 
> ./config --prefix=/usr/local --openssldir=/usr/local/lib --libdir=lib 
> '-Wl,--enable-new-dtags,-rpath,$(LIBRPATH)' no-tls1_3 no-ssl3 no-idea 
> no-mdc2 no-rc5 no-zlib enable-unit-test enable-rfc3779 enable-cms
> -- 
>
> I'm really, really desperate over here.
>
> Thanks in advance for helping out.
>


From squid3 at treenet.co.nz  Wed Feb 27 13:28:39 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 28 Feb 2019 02:28:39 +1300
Subject: [squid-users] Squid with custom openssl path is using the
 openssl installed in default path
In-Reply-To: <7e7b046a-c1a5-44c8-4915-69a419a63044@gmail.com>
References: <7e7b046a-c1a5-44c8-4915-69a419a63044@gmail.com>
Message-ID: <d1c2d388-8e8b-44c0-6c76-3ebe8ec75459@treenet.co.nz>

On 27/02/19 9:59 pm, Stilyan Georgiev wrote:
> Hi,
> 
> Trying to build squid using custom path for openssl and related
> libraries. My goal is to use openssl 1.1.1 which is installed in /usr/local
> 
> -- 
> /usr/local/bin/openssl version
> OpenSSL 1.1.1b? 26 Feb 2019
> -- 
> 
> I did install it like that:
> 
> -- 
> ?./config --prefix=/usr/local --openssldir=/usr/local/lib/ssl
> --libdir=lib 


The build instructions for OpenSSL indicate that unless one is an expert
with the library those --prefix and --openssldir paths should be set to
exactly the same value, *and* avoid setting them to any default system
paths (eg. /usr).

Once you have both built and *installed* the library files. You should
use *exactly* the same path for Squids ./configure --with-openssl=PATH
value.


>  --with-openssl=/usr/local

Notice how your paths are all different at each of those three places.
This is causing a very mixed up installation.

When Squid goes looking for the headers + binaries the only consistent
thing it can fine is the default system library. So of course that is
what gets linked to.


I suggest using /usr/local/openssl-1.1.1 as your custom library path.

Build openssl with --prefix=/usr/local/openssl-1.1.1
--openssldir=/usr/local/openssl-1.1.1

Build Squid with --with-openssl=/usr/local/openssl-1.1.1

That should work a lot better without needing any edits of the build system.


Amos


From leomessi983 at yahoo.com  Wed Feb 27 13:31:18 2019
From: leomessi983 at yahoo.com (leomessi983 at yahoo.com)
Date: Wed, 27 Feb 2019 13:31:18 +0000 (UTC)
Subject: [squid-users] ssl bump
References: <827353279.5896389.1551274278389.ref@mail.yahoo.com>
Message-ID: <827353279.5896389.1551274278389@mail.yahoo.com>

Hi allCan i use this conf only for blocking purpose?!Is set dynamic_cert_mem_cache_size=0MB wrong?I have more than 1000 clients and i only want to block http and https pages. 
 
My configurations is like this:-----------------------------------------https_port 3130 tproxy ssl-bump \
??????? cert=/etc/squid/ssl_cert/myCA.pem \
??????? generate-host-certificates=off dynamic_cert_mem_cache_size=0MB
sslcrtd_program /usr/lib64/squid/security_file_certgen


acl blk ssl::server_name "/var/blk.list"
ssl_bump bump blk
http_access deny blk
acl step1 at_step SslBump1ssl_bump peek step1
ssl_bump splice all
-------------------------------------

tanx
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190227/ead55ef4/attachment.htm>

From mzgmedia at gmail.com  Wed Feb 27 13:38:50 2019
From: mzgmedia at gmail.com (mzgmedia)
Date: Wed, 27 Feb 2019 07:38:50 -0600 (CST)
Subject: [squid-users] /64 ipv6
In-Reply-To: <1551216451445-0.post@n4.nabble.com>
References: <1551216451445-0.post@n4.nabble.com>
Message-ID: <1551274730105-0.post@n4.nabble.com>

we like too add maybe 1 million of IPv6 on a single squid server but probably
the squid will crash because the config file will be too big



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Wed Feb 27 13:44:56 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 28 Feb 2019 02:44:56 +1300
Subject: [squid-users] Squid with custom openssl path is using the
 openssl installed in default path
In-Reply-To: <12625883-3a07-615a-48ec-f01e4c63d5ce@gmail.com>
References: <7e7b046a-c1a5-44c8-4915-69a419a63044@gmail.com>
 <12625883-3a07-615a-48ec-f01e4c63d5ce@gmail.com>
Message-ID: <2beca6de-8627-a61b-c504-afca88d98316@treenet.co.nz>

On 27/02/19 11:39 pm, Stilyan Georgiev wrote:
> Modified Makefile, replacing LIBOPENSSL_CFLAGS = -I/usr/local/include
> with LIBOPENSSL_CFLAGS = -I/usr/local/include/openssl
> 

Please do not touch the Makefile.

To set build environment variables such as those you simply pass them as
arguments to ./configure.

Like so:

 ./configure LIBOPENSSL_CFLAGS="-I/usr/local/include/openssl"


Though the best solution is to fix the issue with your OpenSSL build my
earlier response mentions.



> Afterwards I got squid reporting it uses my custom-path openssl:
> 
> -- 
> Squid Cache: Version 4.5-20190208-r568e66b7c
> Service Name: squid
> 
> This binary uses OpenSSL 1.1.1b? 26 Feb 2019. For legal restrictions on
> distribution see https://www.openssl.org/source/license.html
> 
> configure options:? '--prefix=/usr/local/squid' '--with-openssl=/usr/local'
> -- 
> 
> And even though I built the openssl without tls 1.3 support, I'm still
> being able to use it when browsing through the proxy.
> 
> Also tried tls_outgoing_options options=NO_TLSv1_3 in config .. then in
> cache.log I got -- 2019/02/27 10:32:10 kid1| ERROR: Unknown TLS option
> NO_TLSv1_3

That squid.conf directive controls connections *leaving * Squid towards
origin servers.

Also, your build of OpenSSL explicitly disabled TLS/1.3 functionality.
That included disabling the ability of external programs like Squid to
control whether or not TLS/1.3 is used.


> 
> Which makes me thing even though squid reports it uses openssl 1.1.1 ,
> it lies to me and still uses the ubuntu version :)
> 

No lie. That version number is not something built into Squid. It is a
string produced by the specific libssl library loaded at runtime.
So unless the library is lying about its own version that is actually
the library being loaded and used.


Keep in mind that there are multiple TCP connections, and thus multiple
agents involved. Any of the agents may be using either of the libraries
you have installed on your system.

Whatever agent you are connecting to Squid with is using one library,
Squid using the one claimed by 'squid -v', and the remote server is
using whatever exists out there.


Depending on exactly what setup you are using and how you are testing it
there are also between 1 and 3 "TLS connections" going on with TLS
version negotiated separately for each. You may only get one of those
reported by some test approaches.

If you want some assistance figuring out if our tests are accurate
and/or how to better see what is going on please provide details of whet
your production setup is intended to be, any differences in your test
setup, and how you are testing (what commands exactly). As much details
as you can provide would be helpful to anyone following up (exact crypto
key/cert values do not matter, though cert _type_ may).


Amos


From squid3 at treenet.co.nz  Wed Feb 27 14:22:30 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 28 Feb 2019 03:22:30 +1300
Subject: [squid-users] /64 ipv6
In-Reply-To: <1551274730105-0.post@n4.nabble.com>
References: <1551216451445-0.post@n4.nabble.com>
 <1551274730105-0.post@n4.nabble.com>
Message-ID: <6526d581-a452-c4ff-1c00-07a90c3932e1@treenet.co.nz>

On 28/02/19 2:38 am, mzgmedia wrote:
> we like too add maybe 1 million of IPv6 on a single squid server but probably
> the squid will crash because the config file will be too big
> 

Squid will not crash. It will determine that there are too many HTTP
ports being attempted and cleanly shutdown with an error message about that.


Use the wildcard functionality instead. Like so:

 http_port 3128

This will open *:3128 and traffic destined to _any_ IP assigned to the
machine will arrive at Squid.


PS. From the other posts in this thread you seem to be caught up on the
idea that IP addresses are somehow static things which can persist
across a proxy. This is not true, especially in IPv6 where the so-called
'privacy addressing' can cause any IP to change at any time.

HTTP is designed for this dynamic environment and has stateless
multiplexing of traffic. This means a single client<->Squid connection
can contain requests for any URL and any Squid<->server connection can
handle traffic for any client.


Amos


From leomessi983 at yahoo.com  Wed Feb 27 15:11:39 2019
From: leomessi983 at yahoo.com (leomessi983 at yahoo.com)
Date: Wed, 27 Feb 2019 15:11:39 +0000 (UTC)
Subject: [squid-users] ssl-bump
References: <1389162685.5954130.1551280299047.ref@mail.yahoo.com>
Message-ID: <1389162685.5954130.1551280299047@mail.yahoo.com>

-
-
-
-
-
Hi all
Can i use this conf only for blocking purpose?!Is set dynamic_cert_mem_cache_size=0MB wrong?I have more than 1000 clients and i only want to block http and https pages and show err page for both of those. 
 
My configurations is like this:
-----------------------------------------
https_port 3130 tproxy ssl-bump \
??????? cert=/etc/squid/ssl_cert/myCA.pem \
??????? generate-host-certificates=off dynamic_cert_mem_cache_size=0MB
sslcrtd_program /usr/lib64/squid/security_file_certgen


acl blk ssl::server_name "/var/blk.list"
ssl_bump bump blk
http_access deny blk
acl step1 at_step SslBump1ssl_bump peek step1
ssl_bump splice all
-------------------------------------

tanx
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190227/72a9f78a/attachment.htm>

From eliezer at ngtech.co.il  Wed Feb 27 15:20:16 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Wed, 27 Feb 2019 17:20:16 +0200
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <CO1PR85MB01816F3C2F31B7D6B9A86DCEC8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
 <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <04fc01d4cba3$ce63ecf0$6b2bc6d0$@ngtech.co.il>
 <CO1PR85MB0181275803A77F5C6DFAE39EC8790@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <AM0PR04MB47539AEB5F719878A4D3BE588F790@AM0PR04MB4753.eurprd04.prod.outlook.com>
 <d9c78152489a2929b626020e59a03288@ngtech.co.il>
 <CO1PR85MB01816F3C2F31B7D6B9A86DCEC8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABoy0gsMM9PQZwm278yS5ciAQAAAAA=@ngtech.co.il>

The setup itself is not clear to me.
Is it a simple proxy?
With SSL bump?
Can you share or send me the squid configuration?
There might be another solution for your use case that you have yet to try.
Also if the purpose is not caching, why do you try to use squid?
There are lots of other proxies for windows out there? (just wondering what
and why have you choose Squid)

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com> 
Sent: Wednesday, February 27, 2019 05:51
To: Eliezer Croitoru <eliezer at ngtech.co.il>; Rafael Akchurin
<rafael.akchurin at diladele.com>
Cc: 'Amos Jeffries' <squid3 at treenet.co.nz>;
squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Squid for Windows Repeatedly Crashing

Hello folks, and thanks for keeping interest. Today I spent a bit of time
learning squidclient, and have determined that the server is not in any way
resource constrained. I've attached the output from mgr:info,
mgr:client_list, and mgr:filedescriptors in between crashes. Was wondering
if someone could explain Tout, which I presume is timeout. Of interest are
the ones set to 86400, which I presume is one day. That seems like a big
problem--but where is it coming from? I'm using the Cygwin Squid config
defaults.

There seems to be a lot of Reading next request going on before Squid
recycles. I wonder if the F5 VIP is dealing with congestion through the
firewall, which, in turn, is causing congestion on the pool output side, the
10.26.25.220 address. Our F5 guys have gone silent on me, I have been asking
questions, in particular why all the F5 traffic is coming over just one IP
address in the pool.

In case folks wonder what the IP's are in the file descriptor output....

1310 Socket  898    6044*    2806  40.71.12.224:443
593a6510-ebfc-4d6b-a8f0-a0411dfee098.ods.opinsights.azure.com:443 (this is
Squid forwarding Windows event/perf data from an agent to Azure Log
Analytics)
1311 Socket  899    3015*    9208  10.26.25.220:61088    Reading next
request (10.26.25.220) is the pool IP address of the F5 in use)
1312 Socket  899    2690*    8826  10.26.25.220:61436    Reading next
request
1313 Socket  899    9169*    2884  104.208.163.218:443
eus2-jobruntimedata-prod-su1.azure-automation.net:443 (Squid to Azure)
1314 Socket  899    8787*    2508  104.208.163.218:443
eus2-jobruntimedata-prod-su1.azure-automation.net:443
1315 Socket  118     119*    3924  10.26.25.220:52153    Idle client:
Waiting for next request
1316 Socket  900    1382*    8697  10.26.25.220:54786    Reading next
request

This is from a box that restarts squid every few minutes. Typical cache.log
snippet

2019/02/26 21:24:22 kid1| storeDirWriteCleanLogs: Starting...
2019/02/26 21:24:22 kid1|   Finished.  Wrote 0 entries.
2019/02/26 21:24:22 kid1|   Took 0.00 seconds (  0.00 entries/sec).
2019/02/26 21:24:26 kid1| Set Current Directory to /var/cache/squid
2019/02/26 21:24:26 kid1| Starting Squid Cache version 3.5.28 for
x86_64-unknown-cygwin...
2019/02/26 21:24:26 kid1| Service Name: squid
2019/02/26 21:24:26 kid1| Process ID 1796
2019/02/26 21:24:26 kid1| Process Roles: worker
2019/02/26 21:24:26 kid1| With 3200 file descriptors available
2019/02/26 21:24:26 kid1| Initializing IP Cache...
2019/02/26 21:24:26 kid1| parseEtcHosts: /etc/hosts: (2) No such file or
directory
2019/02/26 21:24:26 kid1| DNS Socket created at [::], FD 5
2019/02/26 21:24:26 kid1| DNS Socket created at 0.0.0.0, FD 6
2019/02/26 21:24:26 kid1| Adding nameserver 208.67.220.220 from squid.conf
2019/02/26 21:24:26 kid1| Adding nameserver 208.67.222.222 from squid.conf
2019/02/26 21:24:26 kid1| Logfile: opening log
daemon:/var/log/squid/access.log
2019/02/26 21:24:26 kid1| Logfile Daemon: opening log
/var/log/squid/access.log
2019/02/26 21:24:26 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2019/02/26 21:24:26 kid1| Store logging disabled
2019/02/26 21:24:26 kid1| Swap maxSize 3072000 + 262144 KB, estimated 256472
objects
2019/02/26 21:24:26 kid1| Target number of buckets: 12823
2019/02/26 21:24:26 kid1| Using 16384 Store buckets
2019/02/26 21:24:26 kid1| Max Mem  size: 262144 KB
2019/02/26 21:24:26 kid1| Max Swap size: 3072000 KB
2019/02/26 21:24:26 kid1| Rebuilding storage in /cygdrive/e/squid/cache
(clean log)
2019/02/26 21:24:26 kid1| Using Least Load store dir selection
2019/02/26 21:24:26 kid1| Set Current Directory to /var/cache/squid
2019/02/26 21:24:26 kid1| Finished loading MIME types and icons.
2019/02/26 21:24:26 kid1| HTCP Disabled.
2019/02/26 21:24:26 kid1| Squid plugin modules loaded: 0
2019/02/26 21:24:26 kid1| Adaptation support is off.
2019/02/26 21:24:26 kid1| Accepting HTTP Socket connections at
local=10.26.24.65:3128 remote=[::] FD 12 flags=9
2019/02/26 21:24:26 kid1| Done reading /cygdrive/e/squid/cache swaplog (0
entries)
2019/02/26 21:24:26 kid1| Store rebuilding is 0.00% complete
2019/02/26 21:24:26 kid1| Finished rebuilding storage from disk.
2019/02/26 21:24:26 kid1|         0 Entries scanned
2019/02/26 21:24:26 kid1|         0 Invalid entries.
2019/02/26 21:24:26 kid1|         0 With invalid flags.
2019/02/26 21:24:26 kid1|         0 Objects loaded.
2019/02/26 21:24:26 kid1|         0 Objects expired.
2019/02/26 21:24:26 kid1|         0 Objects cancelled.
2019/02/26 21:24:26 kid1|         0 Duplicate URLs purged.
2019/02/26 21:24:26 kid1|         0 Swapfile clashes avoided.
2019/02/26 21:24:26 kid1|   Took 0.05 seconds (  0.00 objects/sec).
2019/02/26 21:24:26 kid1| Beginning Validation Procedure
2019/02/26 21:24:27 kid1|   Completed Validation Procedure
2019/02/26 21:24:27 kid1|   Validated 0 Entries
2019/02/26 21:24:27 kid1|   store_swap_size = 0.00 KB
2019/02/26 21:24:27 kid1| storeLateRelease: released 0 objects
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [ job1]: (14) Bad address
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [Stopped, reason:Listener
socket closed job1]: (14) Bad address
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [Stopped, reason:Listener
socket closed job1]: (14) Bad address
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 1
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 2
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 3
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 4
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 5
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 6
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 7
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 8
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 9
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 10
2019/02/26 21:25:02 kid1| Closing HTTP port 10.26.24.65:3128
FATAL: Event loop exited with failure.
Squid Cache (Version 3.5.28): Terminated abnormally.
CPU Usage: 13.187 seconds = 4.625 user + 8.562 sys
Maximum Resident Size: 5276416 KB
Page faults with physical i/o: 20822

-----Original Message-----
From: Eliezer Croitoru <eliezer at ngtech.co.il>
Sent: Tuesday, February 26, 2019 5:23 PM
To: Rafael Akchurin <rafael.akchurin at diladele.com>
Cc: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; 'Amos
Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: [EXT] Re: [squid-users] Squid for Windows Repeatedly Crashing

It depends on the hardware in the server grade Windows.
It can take more then 3k conn's for 100%.
It's possible that squid was not designed for windows 2k16....

Eliezer

On 2019-02-24 15:47, Rafael Akchurin wrote:

> As far as I know the internal FD limit for Windows build is around 3K
> - might be being existed and thus unexpected behavior raising its ugly
> head..
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On
> Behalf Of Van Order, Drew (US - Hermitage)
> Sent: Sunday, 24 February 2019 14:40
> To: eliezer at ngtech.co.il; 'Amos Jeffries' <squid3 at treenet.co.nz>;
> squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing
>
> This is helpful, and I especially appreciate the time given it is the
> weekend.
> <SNIP>
This message (including any attachments) contains confidential information
intended for a specific individual and purpose, and is protected by law. If
you are not the intended recipient, you should delete this message and any
disclosure, copying, or distribution of this message, or the taking of any
action based on it, by you is strictly prohibited.

v.E.1



From dvanorder at deloitte.com  Wed Feb 27 15:54:32 2019
From: dvanorder at deloitte.com (Van Order, Drew (US - Hermitage))
Date: Wed, 27 Feb 2019 15:54:32 +0000
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABoy0gsMM9PQZwm278yS5ciAQAAAAA=@ngtech.co.il>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
 <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <04fc01d4cba3$ce63ecf0$6b2bc6d0$@ngtech.co.il>
 <CO1PR85MB0181275803A77F5C6DFAE39EC8790@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <AM0PR04MB47539AEB5F719878A4D3BE588F790@AM0PR04MB4753.eurprd04.prod.outlook.com>
 <d9c78152489a2929b626020e59a03288@ngtech.co.il>
 <CO1PR85MB01816F3C2F31B7D6B9A86DCEC8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABoy0gsMM9PQZwm278yS5ciAQAAAAA=@ngtech.co.il>
Message-ID: <CO1PR85MB0181E7870AFA7EB911FBCBA3C8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>

Business objective is to enable MSFT Azure MMA's (Microsoft Monitoring Agents) blocked from the internet to send agent data to Azure Log Analytics

Simple proxy
No SSL bump
Squid config is attached
I tried disabling caching with Squid, found it crashed more frequently
Squid was chosen this is intended to be a stopgap solution, and it's free. It's a battle to win over security in order to have tcp/443 opened everywhere.

I'm not sure Squid is the problem, I have an identically configured Squid that bypasses the F5 working beautifully, but it's only 50 clients (MMA's) connecting, Each client takes roughly 5 connections. The clients are still going through a firewall(s). 

Our network folks say that neither the FW or F5 leading up to Squid report congestion. 

It's possible that Squid for Windows + F5 VIP are not intended to work together, but it makes sense to just have one proxy IP address.

I'm getting ready to Skype with our F5 guy to compare what I'm seeing with what he's seeing. Also trying to get how many clients are going through the F5 to compare to my 'good' Squid

-----Original Message-----
From: eliezer at ngtech.co.il <eliezer at ngtech.co.il> 
Sent: Wednesday, February 27, 2019 9:20 AM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Cc: squid-users at lists.squid-cache.org
Subject: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

The setup itself is not clear to me.
Is it a simple proxy?
With SSL bump?
Can you share or send me the squid configuration?
There might be another solution for your use case that you have yet to try.
Also if the purpose is not caching, why do you try to use squid?
There are lots of other proxies for windows out there? (just wondering what and why have you choose Squid)

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Sent: Wednesday, February 27, 2019 05:51
To: Eliezer Croitoru <eliezer at ngtech.co.il>; Rafael Akchurin <rafael.akchurin at diladele.com>
Cc: 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Squid for Windows Repeatedly Crashing

Hello folks, and thanks for keeping interest. Today I spent a bit of time learning squidclient, and have determined that the server is not in any way resource constrained. I've attached the output from mgr:info, mgr:client_list, and mgr:filedescriptors in between crashes. Was wondering if someone could explain Tout, which I presume is timeout. Of interest are the ones set to 86400, which I presume is one day. That seems like a big problem--but where is it coming from? I'm using the Cygwin Squid config defaults.

There seems to be a lot of Reading next request going on before Squid recycles. I wonder if the F5 VIP is dealing with congestion through the firewall, which, in turn, is causing congestion on the pool output side, the
10.26.25.220 address. Our F5 guys have gone silent on me, I have been asking questions, in particular why all the F5 traffic is coming over just one IP address in the pool.

In case folks wonder what the IP's are in the file descriptor output....

1310 Socket  898    6044*    2806  40.71.12.224:443
593a6510-ebfc-4d6b-a8f0-a0411dfee098.ods.opinsights.azure.com:443 (this is Squid forwarding Windows event/perf data from an agent to Azure Log
Analytics)
1311 Socket  899    3015*    9208  10.26.25.220:61088    Reading next
request (10.26.25.220) is the pool IP address of the F5 in use)
1312 Socket  899    2690*    8826  10.26.25.220:61436    Reading next
request
1313 Socket  899    9169*    2884  104.208.163.218:443
eus2-jobruntimedata-prod-su1.azure-automation.net:443 (Squid to Azure)
1314 Socket  899    8787*    2508  104.208.163.218:443
eus2-jobruntimedata-prod-su1.azure-automation.net:443
1315 Socket  118     119*    3924  10.26.25.220:52153    Idle client:
Waiting for next request
1316 Socket  900    1382*    8697  10.26.25.220:54786    Reading next
request

This is from a box that restarts squid every few minutes. Typical cache.log snippet

2019/02/26 21:24:22 kid1| storeDirWriteCleanLogs: Starting...
2019/02/26 21:24:22 kid1|   Finished.  Wrote 0 entries.
2019/02/26 21:24:22 kid1|   Took 0.00 seconds (  0.00 entries/sec).
2019/02/26 21:24:26 kid1| Set Current Directory to /var/cache/squid
2019/02/26 21:24:26 kid1| Starting Squid Cache version 3.5.28 for x86_64-unknown-cygwin...
2019/02/26 21:24:26 kid1| Service Name: squid
2019/02/26 21:24:26 kid1| Process ID 1796
2019/02/26 21:24:26 kid1| Process Roles: worker
2019/02/26 21:24:26 kid1| With 3200 file descriptors available
2019/02/26 21:24:26 kid1| Initializing IP Cache...
2019/02/26 21:24:26 kid1| parseEtcHosts: /etc/hosts: (2) No such file or directory
2019/02/26 21:24:26 kid1| DNS Socket created at [::], FD 5
2019/02/26 21:24:26 kid1| DNS Socket created at 0.0.0.0, FD 6
2019/02/26 21:24:26 kid1| Adding nameserver 208.67.220.220 from squid.conf
2019/02/26 21:24:26 kid1| Adding nameserver 208.67.222.222 from squid.conf
2019/02/26 21:24:26 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2019/02/26 21:24:26 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2019/02/26 21:24:26 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2019/02/26 21:24:26 kid1| Store logging disabled
2019/02/26 21:24:26 kid1| Swap maxSize 3072000 + 262144 KB, estimated 256472 objects
2019/02/26 21:24:26 kid1| Target number of buckets: 12823
2019/02/26 21:24:26 kid1| Using 16384 Store buckets
2019/02/26 21:24:26 kid1| Max Mem  size: 262144 KB
2019/02/26 21:24:26 kid1| Max Swap size: 3072000 KB
2019/02/26 21:24:26 kid1| Rebuilding storage in /cygdrive/e/squid/cache (clean log)
2019/02/26 21:24:26 kid1| Using Least Load store dir selection
2019/02/26 21:24:26 kid1| Set Current Directory to /var/cache/squid
2019/02/26 21:24:26 kid1| Finished loading MIME types and icons.
2019/02/26 21:24:26 kid1| HTCP Disabled.
2019/02/26 21:24:26 kid1| Squid plugin modules loaded: 0
2019/02/26 21:24:26 kid1| Adaptation support is off.
2019/02/26 21:24:26 kid1| Accepting HTTP Socket connections at
local=10.26.24.65:3128 remote=[::] FD 12 flags=9
2019/02/26 21:24:26 kid1| Done reading /cygdrive/e/squid/cache swaplog (0
entries)
2019/02/26 21:24:26 kid1| Store rebuilding is 0.00% complete
2019/02/26 21:24:26 kid1| Finished rebuilding storage from disk.
2019/02/26 21:24:26 kid1|         0 Entries scanned
2019/02/26 21:24:26 kid1|         0 Invalid entries.
2019/02/26 21:24:26 kid1|         0 With invalid flags.
2019/02/26 21:24:26 kid1|         0 Objects loaded.
2019/02/26 21:24:26 kid1|         0 Objects expired.
2019/02/26 21:24:26 kid1|         0 Objects cancelled.
2019/02/26 21:24:26 kid1|         0 Duplicate URLs purged.
2019/02/26 21:24:26 kid1|         0 Swapfile clashes avoided.
2019/02/26 21:24:26 kid1|   Took 0.05 seconds (  0.00 objects/sec).
2019/02/26 21:24:26 kid1| Beginning Validation Procedure
2019/02/26 21:24:27 kid1|   Completed Validation Procedure
2019/02/26 21:24:27 kid1|   Validated 0 Entries
2019/02/26 21:24:27 kid1|   store_swap_size = 0.00 KB
2019/02/26 21:24:27 kid1| storeLateRelease: released 0 objects
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [ job1]: (14) Bad address
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 1
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 2
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 3
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 4
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 5
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 6
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 7
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 8
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 9
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 10
2019/02/26 21:25:02 kid1| Closing HTTP port 10.26.24.65:3128
FATAL: Event loop exited with failure.
Squid Cache (Version 3.5.28): Terminated abnormally.
CPU Usage: 13.187 seconds = 4.625 user + 8.562 sys Maximum Resident Size: 5276416 KB Page faults with physical i/o: 20822

-----Original Message-----
From: Eliezer Croitoru <eliezer at ngtech.co.il>
Sent: Tuesday, February 26, 2019 5:23 PM
To: Rafael Akchurin <rafael.akchurin at diladele.com>
Cc: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: [EXT] Re: [squid-users] Squid for Windows Repeatedly Crashing

It depends on the hardware in the server grade Windows.
It can take more then 3k conn's for 100%.
It's possible that squid was not designed for windows 2k16....

Eliezer

On 2019-02-24 15:47, Rafael Akchurin wrote:

> As far as I know the internal FD limit for Windows build is around 3K
> - might be being existed and thus unexpected behavior raising its ugly 
> head..
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On 
> Behalf Of Van Order, Drew (US - Hermitage)
> Sent: Sunday, 24 February 2019 14:40
> To: eliezer at ngtech.co.il; 'Amos Jeffries' <squid3 at treenet.co.nz>; 
> squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing
>
> This is helpful, and I especially appreciate the time given it is the 
> weekend.
> <SNIP>
This message (including any attachments) contains confidential information intended for a specific individual and purpose, and is protected by law. If you are not the intended recipient, you should delete this message and any disclosure, copying, or distribution of this message, or the taking of any action based on it, by you is strictly prohibited.

v.E.1

-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf
Type: application/octet-stream
Size: 2581 bytes
Desc: squid.conf
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190227/a12920d3/attachment.obj>

From rafael.akchurin at diladele.com  Wed Feb 27 16:30:49 2019
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Wed, 27 Feb 2019 16:30:49 +0000
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <CO1PR85MB0181E7870AFA7EB911FBCBA3C8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
 <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <04fc01d4cba3$ce63ecf0$6b2bc6d0$@ngtech.co.il>
 <CO1PR85MB0181275803A77F5C6DFAE39EC8790@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <AM0PR04MB47539AEB5F719878A4D3BE588F790@AM0PR04MB4753.eurprd04.prod.outlook.com>
 <d9c78152489a2929b626020e59a03288@ngtech.co.il>
 <CO1PR85MB01816F3C2F31B7D6B9A86DCEC8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABoy0gsMM9PQZwm278yS5ciAQAAAAA=@ngtech.co.il>
 <CO1PR85MB0181E7870AFA7EB911FBCBA3C8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
Message-ID: <AM0PR04MB4753D8DD23581CFE21D2031B8F740@AM0PR04MB4753.eurprd04.prod.outlook.com>

I would try deploying Squid on Linux machine running within Hyper-V just to be sure the Squid part itself works fine. Then only specifics of it running on Cygwin will remain to be uncovered. Should be very easy to setup. Couple of hours at most (you have already dedicated much more time to this).

For example here is how we do it https://github.com/diladele/websafety-virtual-appliance/blob/master/scripts.ubuntu18/03_squid.sh
It is even easier if you do not need to sslbump. Just

apt-get update && apt-get install -y squid

And voila!

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Van Order, Drew (US - Hermitage)
Sent: Wednesday, 27 February 2019 16:55
To: eliezer at ngtech.co.il
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing

Business objective is to enable MSFT Azure MMA's (Microsoft Monitoring Agents) blocked from the internet to send agent data to Azure Log Analytics

Simple proxy
No SSL bump
Squid config is attached
I tried disabling caching with Squid, found it crashed more frequently Squid was chosen this is intended to be a stopgap solution, and it's free. It's a battle to win over security in order to have tcp/443 opened everywhere.

I'm not sure Squid is the problem, I have an identically configured Squid that bypasses the F5 working beautifully, but it's only 50 clients (MMA's) connecting, Each client takes roughly 5 connections. The clients are still going through a firewall(s). 

Our network folks say that neither the FW or F5 leading up to Squid report congestion. 

It's possible that Squid for Windows + F5 VIP are not intended to work together, but it makes sense to just have one proxy IP address.

I'm getting ready to Skype with our F5 guy to compare what I'm seeing with what he's seeing. Also trying to get how many clients are going through the F5 to compare to my 'good' Squid

-----Original Message-----
From: eliezer at ngtech.co.il <eliezer at ngtech.co.il>
Sent: Wednesday, February 27, 2019 9:20 AM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Cc: squid-users at lists.squid-cache.org
Subject: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

The setup itself is not clear to me.
Is it a simple proxy?
With SSL bump?
Can you share or send me the squid configuration?
There might be another solution for your use case that you have yet to try.
Also if the purpose is not caching, why do you try to use squid?
There are lots of other proxies for windows out there? (just wondering what and why have you choose Squid)

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Sent: Wednesday, February 27, 2019 05:51
To: Eliezer Croitoru <eliezer at ngtech.co.il>; Rafael Akchurin <rafael.akchurin at diladele.com>
Cc: 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Squid for Windows Repeatedly Crashing

Hello folks, and thanks for keeping interest. Today I spent a bit of time learning squidclient, and have determined that the server is not in any way resource constrained. I've attached the output from mgr:info, mgr:client_list, and mgr:filedescriptors in between crashes. Was wondering if someone could explain Tout, which I presume is timeout. Of interest are the ones set to 86400, which I presume is one day. That seems like a big problem--but where is it coming from? I'm using the Cygwin Squid config defaults.

There seems to be a lot of Reading next request going on before Squid recycles. I wonder if the F5 VIP is dealing with congestion through the firewall, which, in turn, is causing congestion on the pool output side, the
10.26.25.220 address. Our F5 guys have gone silent on me, I have been asking questions, in particular why all the F5 traffic is coming over just one IP address in the pool.

In case folks wonder what the IP's are in the file descriptor output....

1310 Socket  898    6044*    2806  40.71.12.224:443
593a6510-ebfc-4d6b-a8f0-a0411dfee098.ods.opinsights.azure.com:443 (this is Squid forwarding Windows event/perf data from an agent to Azure Log
Analytics)
1311 Socket  899    3015*    9208  10.26.25.220:61088    Reading next
request (10.26.25.220) is the pool IP address of the F5 in use)
1312 Socket  899    2690*    8826  10.26.25.220:61436    Reading next
request
1313 Socket  899    9169*    2884  104.208.163.218:443
eus2-jobruntimedata-prod-su1.azure-automation.net:443 (Squid to Azure)
1314 Socket  899    8787*    2508  104.208.163.218:443
eus2-jobruntimedata-prod-su1.azure-automation.net:443
1315 Socket  118     119*    3924  10.26.25.220:52153    Idle client:
Waiting for next request
1316 Socket  900    1382*    8697  10.26.25.220:54786    Reading next
request

This is from a box that restarts squid every few minutes. Typical cache.log snippet

2019/02/26 21:24:22 kid1| storeDirWriteCleanLogs: Starting...
2019/02/26 21:24:22 kid1|   Finished.  Wrote 0 entries.
2019/02/26 21:24:22 kid1|   Took 0.00 seconds (  0.00 entries/sec).
2019/02/26 21:24:26 kid1| Set Current Directory to /var/cache/squid
2019/02/26 21:24:26 kid1| Starting Squid Cache version 3.5.28 for x86_64-unknown-cygwin...
2019/02/26 21:24:26 kid1| Service Name: squid
2019/02/26 21:24:26 kid1| Process ID 1796
2019/02/26 21:24:26 kid1| Process Roles: worker
2019/02/26 21:24:26 kid1| With 3200 file descriptors available
2019/02/26 21:24:26 kid1| Initializing IP Cache...
2019/02/26 21:24:26 kid1| parseEtcHosts: /etc/hosts: (2) No such file or directory
2019/02/26 21:24:26 kid1| DNS Socket created at [::], FD 5
2019/02/26 21:24:26 kid1| DNS Socket created at 0.0.0.0, FD 6
2019/02/26 21:24:26 kid1| Adding nameserver 208.67.220.220 from squid.conf
2019/02/26 21:24:26 kid1| Adding nameserver 208.67.222.222 from squid.conf
2019/02/26 21:24:26 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2019/02/26 21:24:26 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2019/02/26 21:24:26 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2019/02/26 21:24:26 kid1| Store logging disabled
2019/02/26 21:24:26 kid1| Swap maxSize 3072000 + 262144 KB, estimated 256472 objects
2019/02/26 21:24:26 kid1| Target number of buckets: 12823
2019/02/26 21:24:26 kid1| Using 16384 Store buckets
2019/02/26 21:24:26 kid1| Max Mem  size: 262144 KB
2019/02/26 21:24:26 kid1| Max Swap size: 3072000 KB
2019/02/26 21:24:26 kid1| Rebuilding storage in /cygdrive/e/squid/cache (clean log)
2019/02/26 21:24:26 kid1| Using Least Load store dir selection
2019/02/26 21:24:26 kid1| Set Current Directory to /var/cache/squid
2019/02/26 21:24:26 kid1| Finished loading MIME types and icons.
2019/02/26 21:24:26 kid1| HTCP Disabled.
2019/02/26 21:24:26 kid1| Squid plugin modules loaded: 0
2019/02/26 21:24:26 kid1| Adaptation support is off.
2019/02/26 21:24:26 kid1| Accepting HTTP Socket connections at
local=10.26.24.65:3128 remote=[::] FD 12 flags=9
2019/02/26 21:24:26 kid1| Done reading /cygdrive/e/squid/cache swaplog (0
entries)
2019/02/26 21:24:26 kid1| Store rebuilding is 0.00% complete
2019/02/26 21:24:26 kid1| Finished rebuilding storage from disk.
2019/02/26 21:24:26 kid1|         0 Entries scanned
2019/02/26 21:24:26 kid1|         0 Invalid entries.
2019/02/26 21:24:26 kid1|         0 With invalid flags.
2019/02/26 21:24:26 kid1|         0 Objects loaded.
2019/02/26 21:24:26 kid1|         0 Objects expired.
2019/02/26 21:24:26 kid1|         0 Objects cancelled.
2019/02/26 21:24:26 kid1|         0 Duplicate URLs purged.
2019/02/26 21:24:26 kid1|         0 Swapfile clashes avoided.
2019/02/26 21:24:26 kid1|   Took 0.05 seconds (  0.00 objects/sec).
2019/02/26 21:24:26 kid1| Beginning Validation Procedure
2019/02/26 21:24:27 kid1|   Completed Validation Procedure
2019/02/26 21:24:27 kid1|   Validated 0 Entries
2019/02/26 21:24:27 kid1|   store_swap_size = 0.00 KB
2019/02/26 21:24:27 kid1| storeLateRelease: released 0 objects
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [ job1]: (14) Bad address
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 1
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 2
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 3
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 4
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 5
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 6
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 7
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 8
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 9
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 10
2019/02/26 21:25:02 kid1| Closing HTTP port 10.26.24.65:3128
FATAL: Event loop exited with failure.
Squid Cache (Version 3.5.28): Terminated abnormally.
CPU Usage: 13.187 seconds = 4.625 user + 8.562 sys Maximum Resident Size: 5276416 KB Page faults with physical i/o: 20822

-----Original Message-----
From: Eliezer Croitoru <eliezer at ngtech.co.il>
Sent: Tuesday, February 26, 2019 5:23 PM
To: Rafael Akchurin <rafael.akchurin at diladele.com>
Cc: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: [EXT] Re: [squid-users] Squid for Windows Repeatedly Crashing

It depends on the hardware in the server grade Windows.
It can take more then 3k conn's for 100%.
It's possible that squid was not designed for windows 2k16....

Eliezer

On 2019-02-24 15:47, Rafael Akchurin wrote:

> As far as I know the internal FD limit for Windows build is around 3K
> - might be being existed and thus unexpected behavior raising its ugly 
> head..
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On 
> Behalf Of Van Order, Drew (US - Hermitage)
> Sent: Sunday, 24 February 2019 14:40
> To: eliezer at ngtech.co.il; 'Amos Jeffries' <squid3 at treenet.co.nz>; 
> squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing
>
> This is helpful, and I especially appreciate the time given it is the 
> weekend.
> <SNIP>
This message (including any attachments) contains confidential information intended for a specific individual and purpose, and is protected by law. If you are not the intended recipient, you should delete this message and any disclosure, copying, or distribution of this message, or the taking of any action based on it, by you is strictly prohibited.

v.E.1



From andrejvanderzee at gmail.com  Wed Feb 27 17:30:28 2019
From: andrejvanderzee at gmail.com (Andrej van der Zee)
Date: Wed, 27 Feb 2019 18:30:28 +0100
Subject: [squid-users] HTTP2
Message-ID: <CAFSk7pS8rAi2=y6r=aqCkrk8S2015dNBuNBQ+N8aLQXiLxGpVw@mail.gmail.com>

Hi,

I understood that http2 is work in progress. Is there anything to say about
when this might be released?

Thank you,
Andrej
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190227/ac1e09d1/attachment.htm>

From eliezer at ngtech.co.il  Wed Feb 27 20:43:40 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Wed, 27 Feb 2019 22:43:40 +0200
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <CO1PR85MB0181E7870AFA7EB911FBCBA3C8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
 <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <04fc01d4cba3$ce63ecf0$6b2bc6d0$@ngtech.co.il>
 <CO1PR85MB0181275803A77F5C6DFAE39EC8790@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <AM0PR04MB47539AEB5F719878A4D3BE588F790@AM0PR04MB4753.eurprd04.prod.outlook.com>
 <d9c78152489a2929b626020e59a03288@ngtech.co.il>
 <CO1PR85MB01816F3C2F31B7D6B9A86DCEC8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABoy0gsMM9PQZwm278yS5ciAQAAAAA=@ngtech.co.il>
 <CO1PR85MB0181E7870AFA7EB911FBCBA3C8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
Message-ID: <001601d4cedd$1f2304f0$5d690ed0$@ngtech.co.il>

So just to be on the clear.
You need a basic forward proxy that does CONNECT requests for any LAN client
to safe ports?

Do you have any other requirements then being Windows 2k16 compatbile and
the mentioned ACL's?

If you Insist on a Windows proxy there are couple I collected...
http://www1.ngtech.co.il/wpe/2016/05/02/proxy-per-internet-user-is-it-realis
tic/

I know that RedWood might be good for your needs to compare...:
http://ngtech.co.il/static/redwood/redwood-0.2.0.tar.xz
https://github.com/andybalholm/redwood

I wrote a tiny proxy the other day which should also work fine for you as
long as you have a working and properly configured firewall on the Server.
Let me know if something fit your needs.
If so you can try and test and maybe find the right culprit(ie windows or
linux).

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com> 
Sent: Wednesday, February 27, 2019 17:55
To: eliezer at ngtech.co.il
Cc: squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Squid for Windows Repeatedly Crashing

Business objective is to enable MSFT Azure MMA's (Microsoft Monitoring
Agents) blocked from the internet to send agent data to Azure Log Analytics

Simple proxy
No SSL bump
Squid config is attached
I tried disabling caching with Squid, found it crashed more frequently
Squid was chosen this is intended to be a stopgap solution, and it's free.
It's a battle to win over security in order to have tcp/443 opened
everywhere.

I'm not sure Squid is the problem, I have an identically configured Squid
that bypasses the F5 working beautifully, but it's only 50 clients (MMA's)
connecting, Each client takes roughly 5 connections. The clients are still
going through a firewall(s). 

Our network folks say that neither the FW or F5 leading up to Squid report
congestion. 

It's possible that Squid for Windows + F5 VIP are not intended to work
together, but it makes sense to just have one proxy IP address.

I'm getting ready to Skype with our F5 guy to compare what I'm seeing with
what he's seeing. Also trying to get how many clients are going through the
F5 to compare to my 'good' Squid

-----Original Message-----
From: eliezer at ngtech.co.il <eliezer at ngtech.co.il> 
Sent: Wednesday, February 27, 2019 9:20 AM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Cc: squid-users at lists.squid-cache.org
Subject: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

The setup itself is not clear to me.
Is it a simple proxy?
With SSL bump?
Can you share or send me the squid configuration?
There might be another solution for your use case that you have yet to try.
Also if the purpose is not caching, why do you try to use squid?
There are lots of other proxies for windows out there? (just wondering what
and why have you choose Squid)

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Sent: Wednesday, February 27, 2019 05:51
To: Eliezer Croitoru <eliezer at ngtech.co.il>; Rafael Akchurin
<rafael.akchurin at diladele.com>
Cc: 'Amos Jeffries' <squid3 at treenet.co.nz>;
squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Squid for Windows Repeatedly Crashing

Hello folks, and thanks for keeping interest. Today I spent a bit of time
learning squidclient, and have determined that the server is not in any way
resource constrained. I've attached the output from mgr:info,
mgr:client_list, and mgr:filedescriptors in between crashes. Was wondering
if someone could explain Tout, which I presume is timeout. Of interest are
the ones set to 86400, which I presume is one day. That seems like a big
problem--but where is it coming from? I'm using the Cygwin Squid config
defaults.

There seems to be a lot of Reading next request going on before Squid
recycles. I wonder if the F5 VIP is dealing with congestion through the
firewall, which, in turn, is causing congestion on the pool output side, the
10.26.25.220 address. Our F5 guys have gone silent on me, I have been asking
questions, in particular why all the F5 traffic is coming over just one IP
address in the pool.

In case folks wonder what the IP's are in the file descriptor output....

1310 Socket  898    6044*    2806  40.71.12.224:443
593a6510-ebfc-4d6b-a8f0-a0411dfee098.ods.opinsights.azure.com:443 (this is
Squid forwarding Windows event/perf data from an agent to Azure Log
Analytics)
1311 Socket  899    3015*    9208  10.26.25.220:61088    Reading next
request (10.26.25.220) is the pool IP address of the F5 in use)
1312 Socket  899    2690*    8826  10.26.25.220:61436    Reading next
request
1313 Socket  899    9169*    2884  104.208.163.218:443
eus2-jobruntimedata-prod-su1.azure-automation.net:443 (Squid to Azure)
1314 Socket  899    8787*    2508  104.208.163.218:443
eus2-jobruntimedata-prod-su1.azure-automation.net:443
1315 Socket  118     119*    3924  10.26.25.220:52153    Idle client:
Waiting for next request
1316 Socket  900    1382*    8697  10.26.25.220:54786    Reading next
request

This is from a box that restarts squid every few minutes. Typical cache.log
snippet

2019/02/26 21:24:22 kid1| storeDirWriteCleanLogs: Starting...
2019/02/26 21:24:22 kid1|   Finished.  Wrote 0 entries.
2019/02/26 21:24:22 kid1|   Took 0.00 seconds (  0.00 entries/sec).
2019/02/26 21:24:26 kid1| Set Current Directory to /var/cache/squid
2019/02/26 21:24:26 kid1| Starting Squid Cache version 3.5.28 for
x86_64-unknown-cygwin...
2019/02/26 21:24:26 kid1| Service Name: squid
2019/02/26 21:24:26 kid1| Process ID 1796
2019/02/26 21:24:26 kid1| Process Roles: worker
2019/02/26 21:24:26 kid1| With 3200 file descriptors available
2019/02/26 21:24:26 kid1| Initializing IP Cache...
2019/02/26 21:24:26 kid1| parseEtcHosts: /etc/hosts: (2) No such file or
directory
2019/02/26 21:24:26 kid1| DNS Socket created at [::], FD 5
2019/02/26 21:24:26 kid1| DNS Socket created at 0.0.0.0, FD 6
2019/02/26 21:24:26 kid1| Adding nameserver 208.67.220.220 from squid.conf
2019/02/26 21:24:26 kid1| Adding nameserver 208.67.222.222 from squid.conf
2019/02/26 21:24:26 kid1| Logfile: opening log
daemon:/var/log/squid/access.log
2019/02/26 21:24:26 kid1| Logfile Daemon: opening log
/var/log/squid/access.log
2019/02/26 21:24:26 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2019/02/26 21:24:26 kid1| Store logging disabled
2019/02/26 21:24:26 kid1| Swap maxSize 3072000 + 262144 KB, estimated 256472
objects
2019/02/26 21:24:26 kid1| Target number of buckets: 12823
2019/02/26 21:24:26 kid1| Using 16384 Store buckets
2019/02/26 21:24:26 kid1| Max Mem  size: 262144 KB
2019/02/26 21:24:26 kid1| Max Swap size: 3072000 KB
2019/02/26 21:24:26 kid1| Rebuilding storage in /cygdrive/e/squid/cache
(clean log)
2019/02/26 21:24:26 kid1| Using Least Load store dir selection
2019/02/26 21:24:26 kid1| Set Current Directory to /var/cache/squid
2019/02/26 21:24:26 kid1| Finished loading MIME types and icons.
2019/02/26 21:24:26 kid1| HTCP Disabled.
2019/02/26 21:24:26 kid1| Squid plugin modules loaded: 0
2019/02/26 21:24:26 kid1| Adaptation support is off.
2019/02/26 21:24:26 kid1| Accepting HTTP Socket connections at
local=10.26.24.65:3128 remote=[::] FD 12 flags=9
2019/02/26 21:24:26 kid1| Done reading /cygdrive/e/squid/cache swaplog (0
entries)
2019/02/26 21:24:26 kid1| Store rebuilding is 0.00% complete
2019/02/26 21:24:26 kid1| Finished rebuilding storage from disk.
2019/02/26 21:24:26 kid1|         0 Entries scanned
2019/02/26 21:24:26 kid1|         0 Invalid entries.
2019/02/26 21:24:26 kid1|         0 With invalid flags.
2019/02/26 21:24:26 kid1|         0 Objects loaded.
2019/02/26 21:24:26 kid1|         0 Objects expired.
2019/02/26 21:24:26 kid1|         0 Objects cancelled.
2019/02/26 21:24:26 kid1|         0 Duplicate URLs purged.
2019/02/26 21:24:26 kid1|         0 Swapfile clashes avoided.
2019/02/26 21:24:26 kid1|   Took 0.05 seconds (  0.00 objects/sec).
2019/02/26 21:24:26 kid1| Beginning Validation Procedure
2019/02/26 21:24:27 kid1|   Completed Validation Procedure
2019/02/26 21:24:27 kid1|   Validated 0 Entries
2019/02/26 21:24:27 kid1|   store_swap_size = 0.00 KB
2019/02/26 21:24:27 kid1| storeLateRelease: released 0 objects
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [ job1]: (14) Bad address
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [Stopped, reason:Listener
socket closed job1]: (14) Bad address
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [Stopped, reason:Listener
socket closed job1]: (14) Bad address
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 1
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 2
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 3
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 4
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 5
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 6
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 7
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 8
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 9
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 10
2019/02/26 21:25:02 kid1| Closing HTTP port 10.26.24.65:3128
FATAL: Event loop exited with failure.
Squid Cache (Version 3.5.28): Terminated abnormally.
CPU Usage: 13.187 seconds = 4.625 user + 8.562 sys Maximum Resident Size:
5276416 KB Page faults with physical i/o: 20822

-----Original Message-----
From: Eliezer Croitoru <eliezer at ngtech.co.il>
Sent: Tuesday, February 26, 2019 5:23 PM
To: Rafael Akchurin <rafael.akchurin at diladele.com>
Cc: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; 'Amos
Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: [EXT] Re: [squid-users] Squid for Windows Repeatedly Crashing

It depends on the hardware in the server grade Windows.
It can take more then 3k conn's for 100%.
It's possible that squid was not designed for windows 2k16....

Eliezer

On 2019-02-24 15:47, Rafael Akchurin wrote:

> As far as I know the internal FD limit for Windows build is around 3K
> - might be being existed and thus unexpected behavior raising its ugly 
> head..
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On 
> Behalf Of Van Order, Drew (US - Hermitage)
> Sent: Sunday, 24 February 2019 14:40
> To: eliezer at ngtech.co.il; 'Amos Jeffries' <squid3 at treenet.co.nz>; 
> squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing
>
> This is helpful, and I especially appreciate the time given it is the 
> weekend.
> <SNIP>
This message (including any attachments) contains confidential information
intended for a specific individual and purpose, and is protected by law. If
you are not the intended recipient, you should delete this message and any
disclosure, copying, or distribution of this message, or the taking of any
action based on it, by you is strictly prohibited.

v.E.1




From russel_mcdonald at swbell.net  Wed Feb 27 21:22:10 2019
From: russel_mcdonald at swbell.net (Russel McDonald)
Date: Wed, 27 Feb 2019 21:22:10 +0000 (UTC)
Subject: [squid-users] Any way to get the client's connecting port number?
References: <1000353910.6201625.1551302530657.ref@mail.yahoo.com>
Message-ID: <1000353910.6201625.1551302530657@mail.yahoo.com>

Hi, is there any way to get the port number of the connecting client available to the adapter through ECAP interface? Not just the IP but the port number as well. I found that I can do that by a tiny change but it has to be int he squid source:In adaptation\ecap\XActionRep.cc, method clientIpValue:I added the sprintf:sprintf(&ntoabuf[strlen(ntoabuf)], ":%d", client_addr.port());? ? ? ? ? ? return libecap::Area::FromTempBuffer(ntoabuf, strlen(ntoabuf));
The adapter then has access to the client's connecting port. I use that information to then look up the PID of the connecting process and hence user, using a Windows dll and method with increased privs.
So is there any existing way to get that port without a squid change? And if not then would the team be amenable to my joining as a dev contributor and submitting that? It could be as a separate value/option so as to not break any existing apps relying on that particular string just having the IP.
Russel McDonald
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190227/6da25550/attachment.htm>

From alex at dvm.esines.cu  Wed Feb 27 21:47:40 2019
From: alex at dvm.esines.cu (=?UTF-8?Q?Alex_Guti=c3=a9rrez_Mart=c3=adnez?=)
Date: Wed, 27 Feb 2019 16:47:40 -0500
Subject: [squid-users] problem compiling squid 4 on ubuntu 18.04
Message-ID: <215821b2-eb79-4cc7-b1da-32fb68e8d70c@dvm.esines.cu>

Hello comunity, can someone be so nice to tell me what i?m doing wrong


Im compiling squid 4.5 on ubuntu 18.04


this are the dependency i have installed


apt-get -y install libcppunit-dev libsasl2-dev libxml2-dev libkrb5-dev 
libdb-dev libnetfilter-conntrack-dev libexpat1-dev libcap2-dev 
libldap2-dev libpam0g-dev libgnutls28-dev libssl-dev libdbi-perl 
libecap3 libecap3-dev libntlm0-dev libkf5kiontlm5 samba-dev ldap-utils


this are the options for squid

./configure --build=x86_64-linux-gnu --enable-delay-pools 
--enable-cache-digests --enable-icap-client --enable-ssl 
--enable-ssl-crtd --with-openssl --enable-follow-x-forwarded-for 
--enable-auth-basic="DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB" 
--enable-auth-digest="file,LDAP" --prefix=/usr 
--includedir=${prefix}/include --mandir=${prefix}/share/man 
--infodir=${prefix}/share/info --sysconfdir=/etc --localstatedir=/var 
--libexecdir=${prefix}/lib/squid --srcdir=. --disable-maintainer-mode 
--disable-dependency-tracking --disable-silent-rules 
--datadir=/usr/share/squid --sysconfdir=/etc/squid 
--mandir=/usr/share/man --enable-inline --disable-arch-native 
--enable-async-io=8 --enable-storeio=ufs,aufs,diskd,rock 
--enable-removal-policies=lru,heap --enable-delay-pools 
--enable-cache-digests --enable-icap-client 
--enable-follow-x-forwarded-for --enable-auth-negotiate=kerberos,wrapper 
--enable-auth-ntlm=fake,smb_lm 
--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,unix_group,wbinfo_group 
--enable-url-rewrite-helpers=fake --enable-eui --enable-esi 
--enable-zph-qos --enable-ecap --disable-translation 
--with-swapdir=/var/spool/squid --with-logdir=/var/log/squid 
--with-pidfile=/var/run/squid.pid --with-filedescriptors=65536 
--with-large-files --with-default-user=proxy --enable-ssl 
--with-open-ssl=/etc/ssl/openssl.cnf --enable-linux-netfilter 'CFLAGS=-g 
-O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security 
-Wall' 'LDFLAGS=-fPIE -pie -Wl,-z,relro -Wl,-z,now' 
'CPPFLAGS=-D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -fPIE 
-fstack-protector-strong -Wformat -Werror=format-security'


im getting this error


error: NTLM auth helper smb_lm ... not found


thanks in advance


-- 
Saludos Cordiales

Lic. Alex Guti?rrez Mart?nez

Tel. +53 7 2710327





From rousskov at measurement-factory.com  Wed Feb 27 21:54:44 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 27 Feb 2019 14:54:44 -0700
Subject: [squid-users] Any way to get the client's connecting port
	number?
In-Reply-To: <1000353910.6201625.1551302530657@mail.yahoo.com>
References: <1000353910.6201625.1551302530657.ref@mail.yahoo.com>
 <1000353910.6201625.1551302530657@mail.yahoo.com>
Message-ID: <86d95c20-e387-eda2-7151-cb5f0e162eb8@measurement-factory.com>

On 2/27/19 2:22 PM, Russel McDonald wrote:
> is there any way to get the port number of the connecting client
> available to the adapter through ECAP interface?

Yes, there is: http://www.squid-cache.org/Doc/config/adaptation_meta/

For example, the following configuration snippet relays (where
available) the MAC address (or equivalent), the source IP address, and
the TCP source port of the client-to-Squid connection to the adaptation
transaction via the X-Client-Details ICAP header or the eCAP meta-header:

  adaptation_meta X-Client-Details "%>eui@%>a:%>p"

Alex.


From stilyangeorgiev at gmail.com  Wed Feb 27 22:06:39 2019
From: stilyangeorgiev at gmail.com (Stilyan Georgiev)
Date: Thu, 28 Feb 2019 00:06:39 +0200
Subject: [squid-users] Squid with custom openssl path is using the
 openssl installed in default path
In-Reply-To: <CAGWmD=wb+SN5MmYYYkdGtxnwA3bwfO4xaExbb25imcmrOg=v0g@mail.gmail.com>
References: <7e7b046a-c1a5-44c8-4915-69a419a63044@gmail.com>
 <d1c2d388-8e8b-44c0-6c76-3ebe8ec75459@treenet.co.nz>
 <b0dd6d9f-e869-2457-c2d5-37ee34ab6980@gmail.com>
 <9ae90f7d-56d9-fec5-1989-e53fa96541f3@gmail.com>
 <CAGWmD=wb+SN5MmYYYkdGtxnwA3bwfO4xaExbb25imcmrOg=v0g@mail.gmail.com>
Message-ID: <CAGWmD=y+Yyj3REz3Fvti5v3fm-QsiEPCa2GKvwpT1j6iR06aYg@mail.gmail.com>

On Thu, Feb 28, 2019 at 12:05 AM Stilyan Georgiev <stilyangeorgiev at gmail.com>
wrote:

> Tried everything , including upgrading the system to version that has
> openssl1.1.1-1 , recompiling the package to exclude TLS 1.3 support , using
> -- tls_outgoing_options options=NO_TLSv1_3 where NO_TLSv1_3 simply wasn't
> recognized as something of use.
> TLS1.3 is still being used for sites, and our blocking based on SNI
> doesn't work.
>
> 1 thing left to try - specify list of ciphers where tls1.3 ciphers are not
> included. If that doesn't work we're probably switching to nginx , so we
> can use their config - ssl_protocols TLSv1.2; as too many hours were
> already spent on solving the problem here :(
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190228/bba562e0/attachment.htm>

From eliezer at ngtech.co.il  Wed Feb 27 22:28:13 2019
From: eliezer at ngtech.co.il (eliezer at ngtech.co.il)
Date: Thu, 28 Feb 2019 00:28:13 +0200
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <001601d4cedd$1f2304f0$5d690ed0$@ngtech.co.il>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
 <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <04fc01d4cba3$ce63ecf0$6b2bc6d0$@ngtech.co.il>
 <CO1PR85MB0181275803A77F5C6DFAE39EC8790@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <AM0PR04MB47539AEB5F719878A4D3BE588F790@AM0PR04MB4753.eurprd04.prod.outlook.com>
 <d9c78152489a2929b626020e59a03288@ngtech.co.il>
 <CO1PR85MB01816F3C2F31B7D6B9A86DCEC8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABoy0gsMM9PQZwm278yS5ciAQAAAAA=@ngtech.co.il>
 <CO1PR85MB0181E7870AFA7EB911FBCBA3C8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <001601d4cedd$1f2304f0$5d690ed0$@ngtech.co.il>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABEhIPWaARbTbyJaQgTTfNOAQAAAAA=@ngtech.co.il>

Forgot to mention that this simple proxy:
http://gogs.ngtech.co.il/elicro/golang-http-proxy

Is a simple forward proxy I wrote.
A binary packaged for any OS that GoLang supports including Windows 2k16 is there:
http://gogs.ngtech.co.il/NgTech-LTD/golang-http-proxy/src/master/golang-http-proxy.tar.xz

You will need some software to make it a service but these are easy to find.
If you need a recommendation for one I will try to find.

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of eliezer at ngtech.co.il
Sent: Wednesday, February 27, 2019 22:44
To: 'Van Order, Drew (US - Hermitage)' <dvanorder at deloitte.com>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing

So just to be on the clear.
You need a basic forward proxy that does CONNECT requests for any LAN client
to safe ports?

Do you have any other requirements then being Windows 2k16 compatbile and
the mentioned ACL's?

If you Insist on a Windows proxy there are couple I collected...
http://www1.ngtech.co.il/wpe/2016/05/02/proxy-per-internet-user-is-it-realis
tic/

I know that RedWood might be good for your needs to compare...:
http://ngtech.co.il/static/redwood/redwood-0.2.0.tar.xz
https://github.com/andybalholm/redwood

I wrote a tiny proxy the other day which should also work fine for you as
long as you have a working and properly configured firewall on the Server.
Let me know if something fit your needs.
If so you can try and test and maybe find the right culprit(ie windows or
linux).

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com> 
Sent: Wednesday, February 27, 2019 17:55
To: eliezer at ngtech.co.il
Cc: squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Squid for Windows Repeatedly Crashing

Business objective is to enable MSFT Azure MMA's (Microsoft Monitoring
Agents) blocked from the internet to send agent data to Azure Log Analytics

Simple proxy
No SSL bump
Squid config is attached
I tried disabling caching with Squid, found it crashed more frequently
Squid was chosen this is intended to be a stopgap solution, and it's free.
It's a battle to win over security in order to have tcp/443 opened
everywhere.

I'm not sure Squid is the problem, I have an identically configured Squid
that bypasses the F5 working beautifully, but it's only 50 clients (MMA's)
connecting, Each client takes roughly 5 connections. The clients are still
going through a firewall(s). 

Our network folks say that neither the FW or F5 leading up to Squid report
congestion. 

It's possible that Squid for Windows + F5 VIP are not intended to work
together, but it makes sense to just have one proxy IP address.

I'm getting ready to Skype with our F5 guy to compare what I'm seeing with
what he's seeing. Also trying to get how many clients are going through the
F5 to compare to my 'good' Squid

-----Original Message-----
From: eliezer at ngtech.co.il <eliezer at ngtech.co.il> 
Sent: Wednesday, February 27, 2019 9:20 AM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Cc: squid-users at lists.squid-cache.org
Subject: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

The setup itself is not clear to me.
Is it a simple proxy?
With SSL bump?
Can you share or send me the squid configuration?
There might be another solution for your use case that you have yet to try.
Also if the purpose is not caching, why do you try to use squid?
There are lots of other proxies for windows out there? (just wondering what
and why have you choose Squid)

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Sent: Wednesday, February 27, 2019 05:51
To: Eliezer Croitoru <eliezer at ngtech.co.il>; Rafael Akchurin
<rafael.akchurin at diladele.com>
Cc: 'Amos Jeffries' <squid3 at treenet.co.nz>;
squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Squid for Windows Repeatedly Crashing

Hello folks, and thanks for keeping interest. Today I spent a bit of time
learning squidclient, and have determined that the server is not in any way
resource constrained. I've attached the output from mgr:info,
mgr:client_list, and mgr:filedescriptors in between crashes. Was wondering
if someone could explain Tout, which I presume is timeout. Of interest are
the ones set to 86400, which I presume is one day. That seems like a big
problem--but where is it coming from? I'm using the Cygwin Squid config
defaults.

There seems to be a lot of Reading next request going on before Squid
recycles. I wonder if the F5 VIP is dealing with congestion through the
firewall, which, in turn, is causing congestion on the pool output side, the
10.26.25.220 address. Our F5 guys have gone silent on me, I have been asking
questions, in particular why all the F5 traffic is coming over just one IP
address in the pool.

In case folks wonder what the IP's are in the file descriptor output....

1310 Socket  898    6044*    2806  40.71.12.224:443
593a6510-ebfc-4d6b-a8f0-a0411dfee098.ods.opinsights.azure.com:443 (this is
Squid forwarding Windows event/perf data from an agent to Azure Log
Analytics)
1311 Socket  899    3015*    9208  10.26.25.220:61088    Reading next
request (10.26.25.220) is the pool IP address of the F5 in use)
1312 Socket  899    2690*    8826  10.26.25.220:61436    Reading next
request
1313 Socket  899    9169*    2884  104.208.163.218:443
eus2-jobruntimedata-prod-su1.azure-automation.net:443 (Squid to Azure)
1314 Socket  899    8787*    2508  104.208.163.218:443
eus2-jobruntimedata-prod-su1.azure-automation.net:443
1315 Socket  118     119*    3924  10.26.25.220:52153    Idle client:
Waiting for next request
1316 Socket  900    1382*    8697  10.26.25.220:54786    Reading next
request

This is from a box that restarts squid every few minutes. Typical cache.log
snippet

2019/02/26 21:24:22 kid1| storeDirWriteCleanLogs: Starting...
2019/02/26 21:24:22 kid1|   Finished.  Wrote 0 entries.
2019/02/26 21:24:22 kid1|   Took 0.00 seconds (  0.00 entries/sec).
2019/02/26 21:24:26 kid1| Set Current Directory to /var/cache/squid
2019/02/26 21:24:26 kid1| Starting Squid Cache version 3.5.28 for
x86_64-unknown-cygwin...
2019/02/26 21:24:26 kid1| Service Name: squid
2019/02/26 21:24:26 kid1| Process ID 1796
2019/02/26 21:24:26 kid1| Process Roles: worker
2019/02/26 21:24:26 kid1| With 3200 file descriptors available
2019/02/26 21:24:26 kid1| Initializing IP Cache...
2019/02/26 21:24:26 kid1| parseEtcHosts: /etc/hosts: (2) No such file or
directory
2019/02/26 21:24:26 kid1| DNS Socket created at [::], FD 5
2019/02/26 21:24:26 kid1| DNS Socket created at 0.0.0.0, FD 6
2019/02/26 21:24:26 kid1| Adding nameserver 208.67.220.220 from squid.conf
2019/02/26 21:24:26 kid1| Adding nameserver 208.67.222.222 from squid.conf
2019/02/26 21:24:26 kid1| Logfile: opening log
daemon:/var/log/squid/access.log
2019/02/26 21:24:26 kid1| Logfile Daemon: opening log
/var/log/squid/access.log
2019/02/26 21:24:26 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2019/02/26 21:24:26 kid1| Store logging disabled
2019/02/26 21:24:26 kid1| Swap maxSize 3072000 + 262144 KB, estimated 256472
objects
2019/02/26 21:24:26 kid1| Target number of buckets: 12823
2019/02/26 21:24:26 kid1| Using 16384 Store buckets
2019/02/26 21:24:26 kid1| Max Mem  size: 262144 KB
2019/02/26 21:24:26 kid1| Max Swap size: 3072000 KB
2019/02/26 21:24:26 kid1| Rebuilding storage in /cygdrive/e/squid/cache
(clean log)
2019/02/26 21:24:26 kid1| Using Least Load store dir selection
2019/02/26 21:24:26 kid1| Set Current Directory to /var/cache/squid
2019/02/26 21:24:26 kid1| Finished loading MIME types and icons.
2019/02/26 21:24:26 kid1| HTCP Disabled.
2019/02/26 21:24:26 kid1| Squid plugin modules loaded: 0
2019/02/26 21:24:26 kid1| Adaptation support is off.
2019/02/26 21:24:26 kid1| Accepting HTTP Socket connections at
local=10.26.24.65:3128 remote=[::] FD 12 flags=9
2019/02/26 21:24:26 kid1| Done reading /cygdrive/e/squid/cache swaplog (0
entries)
2019/02/26 21:24:26 kid1| Store rebuilding is 0.00% complete
2019/02/26 21:24:26 kid1| Finished rebuilding storage from disk.
2019/02/26 21:24:26 kid1|         0 Entries scanned
2019/02/26 21:24:26 kid1|         0 Invalid entries.
2019/02/26 21:24:26 kid1|         0 With invalid flags.
2019/02/26 21:24:26 kid1|         0 Objects loaded.
2019/02/26 21:24:26 kid1|         0 Objects expired.
2019/02/26 21:24:26 kid1|         0 Objects cancelled.
2019/02/26 21:24:26 kid1|         0 Duplicate URLs purged.
2019/02/26 21:24:26 kid1|         0 Swapfile clashes avoided.
2019/02/26 21:24:26 kid1|   Took 0.05 seconds (  0.00 objects/sec).
2019/02/26 21:24:26 kid1| Beginning Validation Procedure
2019/02/26 21:24:27 kid1|   Completed Validation Procedure
2019/02/26 21:24:27 kid1|   Validated 0 Entries
2019/02/26 21:24:27 kid1|   store_swap_size = 0.00 KB
2019/02/26 21:24:27 kid1| storeLateRelease: released 0 objects
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [ job1]: (14) Bad address
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [Stopped, reason:Listener
socket closed job1]: (14) Bad address
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [Stopped, reason:Listener
socket closed job1]: (14) Bad address
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 1
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 2
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 3
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 4
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 5
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 6
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 7
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 8
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 9
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 10
2019/02/26 21:25:02 kid1| Closing HTTP port 10.26.24.65:3128
FATAL: Event loop exited with failure.
Squid Cache (Version 3.5.28): Terminated abnormally.
CPU Usage: 13.187 seconds = 4.625 user + 8.562 sys Maximum Resident Size:
5276416 KB Page faults with physical i/o: 20822

-----Original Message-----
From: Eliezer Croitoru <eliezer at ngtech.co.il>
Sent: Tuesday, February 26, 2019 5:23 PM
To: Rafael Akchurin <rafael.akchurin at diladele.com>
Cc: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; 'Amos
Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: [EXT] Re: [squid-users] Squid for Windows Repeatedly Crashing

It depends on the hardware in the server grade Windows.
It can take more then 3k conn's for 100%.
It's possible that squid was not designed for windows 2k16....

Eliezer

On 2019-02-24 15:47, Rafael Akchurin wrote:

> As far as I know the internal FD limit for Windows build is around 3K
> - might be being existed and thus unexpected behavior raising its ugly 
> head..
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On 
> Behalf Of Van Order, Drew (US - Hermitage)
> Sent: Sunday, 24 February 2019 14:40
> To: eliezer at ngtech.co.il; 'Amos Jeffries' <squid3 at treenet.co.nz>; 
> squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing
>
> This is helpful, and I especially appreciate the time given it is the 
> weekend.
> <SNIP>
This message (including any attachments) contains confidential information
intended for a specific individual and purpose, and is protected by law. If
you are not the intended recipient, you should delete this message and any
disclosure, copying, or distribution of this message, or the taking of any
action based on it, by you is strictly prohibited.

v.E.1


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From dvanorder at deloitte.com  Wed Feb 27 22:47:11 2019
From: dvanorder at deloitte.com (Van Order, Drew (US - Hermitage))
Date: Wed, 27 Feb 2019 22:47:11 +0000
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABEhIPWaARbTbyJaQgTTfNOAQAAAAA=@ngtech.co.il>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
 <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <04fc01d4cba3$ce63ecf0$6b2bc6d0$@ngtech.co.il>
 <CO1PR85MB0181275803A77F5C6DFAE39EC8790@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <AM0PR04MB47539AEB5F719878A4D3BE588F790@AM0PR04MB4753.eurprd04.prod.outlook.com>
 <d9c78152489a2929b626020e59a03288@ngtech.co.il>
 <CO1PR85MB01816F3C2F31B7D6B9A86DCEC8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABoy0gsMM9PQZwm278yS5ciAQAAAAA=@ngtech.co.il>
 <CO1PR85MB0181E7870AFA7EB911FBCBA3C8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <001601d4cedd$1f2304f0$5d690ed0$@ngtech.co.il>
 <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABEhIPWaARbTbyJaQgTTfNOAQAAAAA=@ngtech.co.il>
Message-ID: <CO1PR85MB0181BC9EB0A38A334B58E79EC8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>

Wow. This is very generous Eliezer. I am humbled by your generosity!

Before I try your proxy for Windows, I've decided it's time to eliminate the OS as a variable. I quickly tacked up Squid running on a sandbox RHEL, and submitted a ticket to have it added to the F5 VIP. 

If the issue vanishes, bye bye Windows, and some folks are going to have to teach themselves Linux quickly :-) 

Stay tuned.......

-----Original Message-----
From: eliezer at ngtech.co.il <eliezer at ngtech.co.il> 
Sent: Wednesday, February 27, 2019 4:28 PM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Cc: squid-users at lists.squid-cache.org
Subject: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

Forgot to mention that this simple proxy:
http://secure-web.cisco.com/11Ju3FBMy81J840cSoCXGXdubwW80knGlevOiEwmFux7MQTjMwodNApLbJYerezA5dSOY7bJJChXO2aVi80fseEIMDaEj12mh4Ig4yNYzxviiWXlGyk_IUiyoo4tIFc-tnaWbefXsQ49afvPY1yTX-B3H7BK3voG5Dfw2WmyZJ1N8lEwnCwquwbLcdnYnYw8zp5qIMe-Rq4fl-399jML9snz7QIUgE4jK46s-OgXDOPlHDlMfqgp66UhJL7cw-AkWDYfQV_uIGnUEWpvvmS1qEfhOLC89KnTzH3WCIRGR-Zh3LgWUo5yr4vW_nmyO0deNOGfNP4t2D-JjK85rZEahU_JLuFgzQLJC95M-uzoATapIbxqkCdSJ9ibyDaLhZWNdCyV6H64olDKlBBonUSnOTeu2C-RaoCUoOPhOL4I2zX_vyKrB5zGX2qWpo4TVQxRWd1z-WVIOJb0AS9J9m86mpQ-Op-Govz_L9XwqaMOHngH2bb1UB9JWMHbW8fcZny9nFZR2VeG6N9X87shN9Ek1dQ/http%3A%2F%2Fgogs.ngtech.co.il%2Felicro%2Fgolang-http-proxy

Is a simple forward proxy I wrote.
A binary packaged for any OS that GoLang supports including Windows 2k16 is there:
http://secure-web.cisco.com/1ySd839vtqkoCLOWAs5SXi2Fzc8RNRQd0Vk53qQWH0XChRYXvX7qhbT1_QhocdaqgeVsDhkDZscU9PQNRd-4mhsOlnZHRKyqrSW4zlw4x-BaRogwP4jInaTbDEhCTTt4wUSiKS9VaahRIdiCoI81Sy46jhpq4i14fB5KSHtSywhD1SzmqDQfokkEr0vUFP0x2RdYtkY9axCTbSljyVgdDMk0QQfIPQ8nmFs5FULbfd4Xrts9UPlcmoNleo0YXHCWlrizaT2JCuRqW23kq9baAB8VOk06MtwBkmdFLY7AMT49HqRhTwgHHPTuL2jyL7IA4FYG-RAlo3JU0GyLgZWeX2ruEk66ZhadtuwLNkyucJwAoyoQMIyhM5ps0lC2DdHWEamYLT8M7NoW4TZju03jD76ixc8xMPzbnN0IBFznWcnZPYIooUHeAxyAaYEBp47vR-pAMV4kur_zcuU_Exv7B2jY9lfXLPAnPUW-c20el5ZGTosbPeV6bF9D7XofMf6FvnbsqTkf_VgUDynE-tnLDsw/http%3A%2F%2Fgogs.ngtech.co.il%2FNgTech-LTD%2Fgolang-http-proxy%2Fsrc%2Fmaster%2Fgolang-http-proxy.tar.xz

You will need some software to make it a service but these are easy to find.
If you need a recommendation for one I will try to find.

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of eliezer at ngtech.co.il
Sent: Wednesday, February 27, 2019 22:44
To: 'Van Order, Drew (US - Hermitage)' <dvanorder at deloitte.com>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing

So just to be on the clear.
You need a basic forward proxy that does CONNECT requests for any LAN client to safe ports?

Do you have any other requirements then being Windows 2k16 compatbile and the mentioned ACL's?

If you Insist on a Windows proxy there are couple I collected...
http://secure-web.cisco.com/17a99t4PIGRmHeQmTLY5KRhYDoGTUPwyYGXT0fAV0DVh9MsSteT4Pi-0sb_DM-mY6nLb-NLB1ftORaQ0bC7KstwyrnAci2lsLoKWzNgOiKHwBGQSVL7MMHSGJ1zHRTGIcyEuDlGdldzgihQb6_79nG9yppR2yvpbWX2uvTAEr-qZB46PVCd_d3YtLah9RzDxyJymPdDeyaAw66X6Agmqs512eb5uI1oCN3auT9qbjI11NDr8edlo3R04C-tHHqBAka4hQXEs9LavQUNcBcHFWhME6PEBNCdLVBeitC3d9ZF2rtYKIP5iFYZs1w72GL_-Xh0zawz7uiX9GcwN60Tx0m8MJQQoEMPp4v3cfSiM-pFHI7YAJRvcCfFENvZcgNXFQrzX4ZVaLIxPkV5q2fN8uGObAZKRTWkqAXwo2LE40s9waGLpTDmiXy76gE6sGFerW5m1mImQElzPWjajbWJfqSi8aD7W1TC0w42AGOqQJ60VnXhZw4CuupXzmylyd8E6D_GPtTtAdp5VPrXTEQCT20w/http%3A%2F%2Fwww1.ngtech.co.il%2Fwpe%2F2016%2F05%2F02%2Fproxy-per-internet-user-is-it-realis
tic/

I know that RedWood might be good for your needs to compare...:
http://secure-web.cisco.com/1ETToAy7lpIzQDnVWVx4VN460yeA4V0c0irlIMN9P5wE50B-0kLELWsz8usawuOgy7IZPOJ6iV2FTApPTEaJH1nHFLR-pnUkuG7C5E6f_fZdUofEV5UX__yh2g0MRKI7XB3x1uEdiMhlhtodTsSeJYzqWK_5Zij6_rNjYlWlY8573ATbmhIZNgkfwcaoRJl4FwO50zEAueB_tlGyikPc8FfJGgKZbcRYa7frdZcwsn9JKeQh_GISsi-_BpAETFQf6ZeZ5SGXQ5TB4z9GoPlncAf0vxingBSktcPgqF-jRLgxwHQ9nv6a-Ses-94UmCser4hIzsd6pTOHLVYY8u0OWUjlB5rRqROlH_IMkslBcFtEXaRYl1Fy2LEgL9RWaSuNFG-wRWmFw4BRtweHIpRnypuF24a2vKjwnN929-EHwHv-t-rCk8FSTQ5OfkHkP78sN0ErpcZv9GFBXOPA_7y0MTp3evd2SWbD4YBfXSZ5a3BCL4iM2Jx4KfG9SBK5KIz2TkdGzjQXIWujLFeWtOd5KIw/http%3A%2F%2Fngtech.co.il%2Fstatic%2Fredwood%2Fredwood-0.2.0.tar.xz
https://secure-web.cisco.com/14Y9nKqTcPsVkJBCkyIkxFkE_XO9jqzDvqIf1yzNdAIfhtJDiPPfe1HdfUmXxsFWMojRBhFGJfxGogPbIh16U9bdtA5l-XZkZAXM-KcwTAto3X-WRpC6ogpKA9wuNMuWwgKlRAPdgz1hvOAho8mcmXlY3Zct0t1WX6qy5RJ4Yjm_Nwfk5gBzAn_HXuCRAVkwmXYtzSqdwxpxhZ7bG-nsO4bHr0CwqU2WmvzUSsTQEHERFcVTMX0B5PrzmySJtmZlzv33zvGFFwrW8SSSTSqVrxZtiiHJly8tc9e42bpY2v7tmkhkacmX50Vn5w7FcsqjKVew6Qey7TAPp2K6_7n-Dr15pHPvpunEiHUVC-ewcE5OXL3uf1bruR-XsF2xLNe1UN2TxTQdLNO5od_wmbO1KzFAq70T8o5gS7Tf5xPbUqX_GHNbHWi53302aJvDUpIH6Dlr7llzwKR1J51WdEL2XCiu61T2w-Sn7rmzQnoS8kkwzadmdrJAxXyaOcJTO82wmRT8W4fcPPWVIRzwdyAXjqg/https%3A%2F%2Fgithub.com%2Fandybalholm%2Fredwood

I wrote a tiny proxy the other day which should also work fine for you as long as you have a working and properly configured firewall on the Server.
Let me know if something fit your needs.
If so you can try and test and maybe find the right culprit(ie windows or linux).

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Sent: Wednesday, February 27, 2019 17:55
To: eliezer at ngtech.co.il
Cc: squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Squid for Windows Repeatedly Crashing

Business objective is to enable MSFT Azure MMA's (Microsoft Monitoring
Agents) blocked from the internet to send agent data to Azure Log Analytics

Simple proxy
No SSL bump
Squid config is attached
I tried disabling caching with Squid, found it crashed more frequently Squid was chosen this is intended to be a stopgap solution, and it's free.
It's a battle to win over security in order to have tcp/443 opened everywhere.

I'm not sure Squid is the problem, I have an identically configured Squid that bypasses the F5 working beautifully, but it's only 50 clients (MMA's) connecting, Each client takes roughly 5 connections. The clients are still going through a firewall(s). 

Our network folks say that neither the FW or F5 leading up to Squid report congestion. 

It's possible that Squid for Windows + F5 VIP are not intended to work together, but it makes sense to just have one proxy IP address.

I'm getting ready to Skype with our F5 guy to compare what I'm seeing with what he's seeing. Also trying to get how many clients are going through the
F5 to compare to my 'good' Squid

-----Original Message-----
From: eliezer at ngtech.co.il <eliezer at ngtech.co.il>
Sent: Wednesday, February 27, 2019 9:20 AM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Cc: squid-users at lists.squid-cache.org
Subject: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

The setup itself is not clear to me.
Is it a simple proxy?
With SSL bump?
Can you share or send me the squid configuration?
There might be another solution for your use case that you have yet to try.
Also if the purpose is not caching, why do you try to use squid?
There are lots of other proxies for windows out there? (just wondering what and why have you choose Squid)

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Sent: Wednesday, February 27, 2019 05:51
To: Eliezer Croitoru <eliezer at ngtech.co.il>; Rafael Akchurin <rafael.akchurin at diladele.com>
Cc: 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Squid for Windows Repeatedly Crashing

Hello folks, and thanks for keeping interest. Today I spent a bit of time learning squidclient, and have determined that the server is not in any way resource constrained. I've attached the output from mgr:info, mgr:client_list, and mgr:filedescriptors in between crashes. Was wondering if someone could explain Tout, which I presume is timeout. Of interest are the ones set to 86400, which I presume is one day. That seems like a big problem--but where is it coming from? I'm using the Cygwin Squid config defaults.

There seems to be a lot of Reading next request going on before Squid recycles. I wonder if the F5 VIP is dealing with congestion through the firewall, which, in turn, is causing congestion on the pool output side, the
10.26.25.220 address. Our F5 guys have gone silent on me, I have been asking questions, in particular why all the F5 traffic is coming over just one IP address in the pool.

In case folks wonder what the IP's are in the file descriptor output....

1310 Socket  898    6044*    2806  40.71.12.224:443
593a6510-ebfc-4d6b-a8f0-a0411dfee098.ods.opinsights.azure.com:443 (this is Squid forwarding Windows event/perf data from an agent to Azure Log
Analytics)
1311 Socket  899    3015*    9208  10.26.25.220:61088    Reading next
request (10.26.25.220) is the pool IP address of the F5 in use)
1312 Socket  899    2690*    8826  10.26.25.220:61436    Reading next
request
1313 Socket  899    9169*    2884  104.208.163.218:443
eus2-jobruntimedata-prod-su1.azure-automation.net:443 (Squid to Azure)
1314 Socket  899    8787*    2508  104.208.163.218:443
eus2-jobruntimedata-prod-su1.azure-automation.net:443
1315 Socket  118     119*    3924  10.26.25.220:52153    Idle client:
Waiting for next request
1316 Socket  900    1382*    8697  10.26.25.220:54786    Reading next
request

This is from a box that restarts squid every few minutes. Typical cache.log snippet

2019/02/26 21:24:22 kid1| storeDirWriteCleanLogs: Starting...
2019/02/26 21:24:22 kid1|   Finished.  Wrote 0 entries.
2019/02/26 21:24:22 kid1|   Took 0.00 seconds (  0.00 entries/sec).
2019/02/26 21:24:26 kid1| Set Current Directory to /var/cache/squid
2019/02/26 21:24:26 kid1| Starting Squid Cache version 3.5.28 for x86_64-unknown-cygwin...
2019/02/26 21:24:26 kid1| Service Name: squid
2019/02/26 21:24:26 kid1| Process ID 1796
2019/02/26 21:24:26 kid1| Process Roles: worker
2019/02/26 21:24:26 kid1| With 3200 file descriptors available
2019/02/26 21:24:26 kid1| Initializing IP Cache...
2019/02/26 21:24:26 kid1| parseEtcHosts: /etc/hosts: (2) No such file or directory
2019/02/26 21:24:26 kid1| DNS Socket created at [::], FD 5
2019/02/26 21:24:26 kid1| DNS Socket created at 0.0.0.0, FD 6
2019/02/26 21:24:26 kid1| Adding nameserver 208.67.220.220 from squid.conf
2019/02/26 21:24:26 kid1| Adding nameserver 208.67.222.222 from squid.conf
2019/02/26 21:24:26 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2019/02/26 21:24:26 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2019/02/26 21:24:26 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2019/02/26 21:24:26 kid1| Store logging disabled
2019/02/26 21:24:26 kid1| Swap maxSize 3072000 + 262144 KB, estimated 256472 objects
2019/02/26 21:24:26 kid1| Target number of buckets: 12823
2019/02/26 21:24:26 kid1| Using 16384 Store buckets
2019/02/26 21:24:26 kid1| Max Mem  size: 262144 KB
2019/02/26 21:24:26 kid1| Max Swap size: 3072000 KB
2019/02/26 21:24:26 kid1| Rebuilding storage in /cygdrive/e/squid/cache (clean log)
2019/02/26 21:24:26 kid1| Using Least Load store dir selection
2019/02/26 21:24:26 kid1| Set Current Directory to /var/cache/squid
2019/02/26 21:24:26 kid1| Finished loading MIME types and icons.
2019/02/26 21:24:26 kid1| HTCP Disabled.
2019/02/26 21:24:26 kid1| Squid plugin modules loaded: 0
2019/02/26 21:24:26 kid1| Adaptation support is off.
2019/02/26 21:24:26 kid1| Accepting HTTP Socket connections at
local=10.26.24.65:3128 remote=[::] FD 12 flags=9
2019/02/26 21:24:26 kid1| Done reading /cygdrive/e/squid/cache swaplog (0
entries)
2019/02/26 21:24:26 kid1| Store rebuilding is 0.00% complete
2019/02/26 21:24:26 kid1| Finished rebuilding storage from disk.
2019/02/26 21:24:26 kid1|         0 Entries scanned
2019/02/26 21:24:26 kid1|         0 Invalid entries.
2019/02/26 21:24:26 kid1|         0 With invalid flags.
2019/02/26 21:24:26 kid1|         0 Objects loaded.
2019/02/26 21:24:26 kid1|         0 Objects expired.
2019/02/26 21:24:26 kid1|         0 Objects cancelled.
2019/02/26 21:24:26 kid1|         0 Duplicate URLs purged.
2019/02/26 21:24:26 kid1|         0 Swapfile clashes avoided.
2019/02/26 21:24:26 kid1|   Took 0.05 seconds (  0.00 objects/sec).
2019/02/26 21:24:26 kid1| Beginning Validation Procedure
2019/02/26 21:24:27 kid1|   Completed Validation Procedure
2019/02/26 21:24:27 kid1|   Validated 0 Entries
2019/02/26 21:24:27 kid1|   store_swap_size = 0.00 KB
2019/02/26 21:24:27 kid1| storeLateRelease: released 0 objects
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [ job1]: (14) Bad address
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 1
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 2
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 3
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 4
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 5
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 6
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 7
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 8
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 9
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 10
2019/02/26 21:25:02 kid1| Closing HTTP port 10.26.24.65:3128
FATAL: Event loop exited with failure.
Squid Cache (Version 3.5.28): Terminated abnormally.
CPU Usage: 13.187 seconds = 4.625 user + 8.562 sys Maximum Resident Size:
5276416 KB Page faults with physical i/o: 20822

-----Original Message-----
From: Eliezer Croitoru <eliezer at ngtech.co.il>
Sent: Tuesday, February 26, 2019 5:23 PM
To: Rafael Akchurin <rafael.akchurin at diladele.com>
Cc: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: [EXT] Re: [squid-users] Squid for Windows Repeatedly Crashing

It depends on the hardware in the server grade Windows.
It can take more then 3k conn's for 100%.
It's possible that squid was not designed for windows 2k16....

Eliezer

On 2019-02-24 15:47, Rafael Akchurin wrote:

> As far as I know the internal FD limit for Windows build is around 3K
> - might be being existed and thus unexpected behavior raising its ugly 
> head..
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On 
> Behalf Of Van Order, Drew (US - Hermitage)
> Sent: Sunday, 24 February 2019 14:40
> To: eliezer at ngtech.co.il; 'Amos Jeffries' <squid3 at treenet.co.nz>; 
> squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing
>
> This is helpful, and I especially appreciate the time given it is the 
> weekend.
> <SNIP>
This message (including any attachments) contains confidential information intended for a specific individual and purpose, and is protected by law. If you are not the intended recipient, you should delete this message and any disclosure, copying, or distribution of this message, or the taking of any action based on it, by you is strictly prohibited.

v.E.1


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://secure-web.cisco.com/1QaWJJeGQzVtr7er4_2VR8x7s6gFT4wjkA8x85dYsl37jmR3uDRD9kUV2i_MVxbEt-oDF_9BXrUfSk03eD0nmwaXQ5MpVCTQtsnrpkAhcP9tUwqQ7R4BddSmai1NmhcOSLib8g-S6l7LiyiJ_tLM8ZUKvhUkISHWgfBv0tyhzB90I0pdUSsoglrsHNyKpse1y17_Fl2kblE8wfq3OjUOGytxNyP45Rfmmc7i1xBsj6-rfsIjwC1Zzsy1WBzlAQSAyZmSZtSywg_8EDGfinpLwe29V3X1YXz4sDrMGdZJB7HPx4h7lmZ4Biv5oJZbKmetDzwTffKXOzFz77qVL14IQk6bjavIe1Rs7J5-qT9459Twbp3oWKulNp7NdMdpQyovPDZRdAjd-zkJpikePTCheZHJ5F5EgcOzUWflpSfE400lOJ4xjl7M8xEScxdVikcIfZ8deAae91AN-d2lBvPZn2iMULlxIBKaeRcxofH-Dk4ZHEMvzvfWhMrf80X0jU_KYPSJjn2fxuxoRLfxE77PjxA/http%3A%2F%2Flists.squid-cache.org%2Flistinfo%2Fsquid-users



From stilyangeorgiev at gmail.com  Wed Feb 27 23:13:16 2019
From: stilyangeorgiev at gmail.com (Stilyan Georgiev)
Date: Thu, 28 Feb 2019 01:13:16 +0200
Subject: [squid-users] Disable tls1.3 support ,
 can't get SNI / cert details when it's used
In-Reply-To: <0c53626c-b76d-616d-b4b3-ab0d76cb3651@measurement-factory.com>
References: <a0f24855-e1dc-bbe0-f08c-df419e06f135@gmail.com>
 <0c53626c-b76d-616d-b4b3-ab0d76cb3651@measurement-factory.com>
Message-ID: <CAGWmD=yXuOvdGi5Q=ctTF1mYQMy6uNawGE22MQCqdumEEm=ynQ@mail.gmail.com>

Thanks for the input Alex.
I had many, many issues compiling openssl without tls1.3. At first i tried
doing it side by side with version I had in OS but failed miserably, with
squid continuing to use the OS package.
Eventually I release upgraded the OS and now have the 1.1.1-1 package from
repo, rebuilt it with no-tls1_3 in CONFARGS

And to my amazement squid continues serving tls1.3 :)

Any suggestions on to how to allow tls1.1 and tls1.2 only are very welcome.
Maybe tls_outgoing_options cipher= ...

Thanks in advance for helping out!

On Tue, Feb 26, 2019 at 9:10 PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 2/26/19 4:55 AM, Stilyan Georgiev wrote:
>
> > Squid 4.5 with openssl support here.
> > SSL bumping can't obtain SNI / cert domain to perform filtering when
> > tls1.3 is used.
> > I want to disable support for tls1.3 in config but don't find way to do
> > so. There's the outdated sslproxy_options config directive which doesn't
> > appear to be supported in 4.5
> >
> > The goal is - allow everything , besides tls1.3
>
> Good question!
>
> TLS v1.3 clients that use "Middlebox Compatibility Mode", including
> OpenSSL s_client and popular browsers, pretend to be TLS v1.2 clients
> that attempt to restore a non-existent TLS session. Squid probably does
> not have ACLs that can detect those lies. However, if you think you can
> detect them, you can pass TLS Hello to your external ACL via the
> %>handshake logformat code.
>
> If you are asking whether Squid can downgrade TLS v1.3 to TLS v1.2, then
> I suspect the answer is "yes, but only if you bump the client connection
> first": A peeking Squid cannot negotiate a different TLS version with
> the client. If TLS downgrade is what you want, you can probably use an
> OpenSSL version that does not support TLS v1.3. There may also be an
> OpenSSL v1.1.1 configuration option to turn TLS v1.3 support off, but I
> have not research that.
>
> Finally, there may be a bug in earlier versions of Squid that breaks
> peeking at TLS v1.3 servers during step2. Staring works. We have not
> tested Squid v4.5 though. Please note that peeking at TLS v1.3 servers
> is largely pointless because useful information in TLS v1.3 Server Hello
> is encrypted.
>
>
> HTH,
>
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
Yours Sincerely,

*Stilyan Georgiev*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190228/dac1357d/attachment.htm>

From stilyangeorgiev at gmail.com  Wed Feb 27 23:25:40 2019
From: stilyangeorgiev at gmail.com (Stilyan Georgiev)
Date: Thu, 28 Feb 2019 01:25:40 +0200
Subject: [squid-users] Disable tls1.3 support ,
 can't get SNI / cert details when it's used
In-Reply-To: <CAGWmD=yXuOvdGi5Q=ctTF1mYQMy6uNawGE22MQCqdumEEm=ynQ@mail.gmail.com>
References: <a0f24855-e1dc-bbe0-f08c-df419e06f135@gmail.com>
 <0c53626c-b76d-616d-b4b3-ab0d76cb3651@measurement-factory.com>
 <CAGWmD=yXuOvdGi5Q=ctTF1mYQMy6uNawGE22MQCqdumEEm=ynQ@mail.gmail.com>
Message-ID: <CAGWmD=w3aC4e9zMuO85b_UwWRh9_V4d3t5+_DQVizYbg3FJiWQ@mail.gmail.com>

When testing like so: openssl s_client -connect google.com:443
I get tls1.2 back

Via mobile chrome browser (android) and the proxy I get tls1.3
Truly don't understand :)

----- Some output -----
Service Name: squid
This binary uses OpenSSL 1.1.1  11 Sep 2018.

dpkg --list |grep ssl
ii  libgnutls-openssl27:amd64             3.6.4-2ubuntu1.1
amd64        GNU TLS library - OpenSSL wrapper
ii  libio-socket-ssl-perl                 2.060-3
all          Perl module implementing object oriented interface to SSL
sockets
ii  libnet-smtp-ssl-perl                  1.04-1
all          Perl module providing SSL support to Net::SMTP
ii  libnet-ssleay-perl                    1.85-2ubuntu2
amd64        Perl module for Secure Sockets Layer (SSL)
ii  libssl-dev:amd64                      1.1.1-1ubuntu2.1
amd64        Secure Sockets Layer toolkit - development files
ii  libssl1.0.0:amd64                     1.0.2n-1ubuntu6.2
amd64        Secure Sockets Layer toolkit - shared libraries
ii  libssl1.1:amd64                       1.1.1-1ubuntu2.1
amd64        Secure Sockets Layer toolkit - shared libraries
ii  libxmlsec1-openssl:amd64              1.2.26-3
amd64        Openssl engine for the XML security library
ii  libzstd1:amd64                        1.3.5+dfsg-1ubuntu1
amd64        fast lossless compression algorithm
ii  openssl                               1.1.1-1ubuntu2.1
amd64        Secure Sockets Layer toolkit - cryptographic utility
ii  perl-openssl-defaults:amd64           3build1
amd64        version compatibility baseline for Perl OpenSSL packages
ii  python3-openssl                       18.0.0-1
all          Python 3 wrapper around the OpenSSL library
rc  ssl-cert                              1.0.39
all          simple debconf wrapper for OpenSSL


On Thu, Feb 28, 2019 at 1:13 AM Stilyan Georgiev <stilyangeorgiev at gmail.com>
wrote:

> Thanks for the input Alex.
> I had many, many issues compiling openssl without tls1.3. At first i tried
> doing it side by side with version I had in OS but failed miserably, with
> squid continuing to use the OS package.
> Eventually I release upgraded the OS and now have the 1.1.1-1 package from
> repo, rebuilt it with no-tls1_3 in CONFARGS
>
> And to my amazement squid continues serving tls1.3 :)
>
> Any suggestions on to how to allow tls1.1 and tls1.2 only are very
> welcome. Maybe tls_outgoing_options cipher= ...
>
> Thanks in advance for helping out!
>
> On Tue, Feb 26, 2019 at 9:10 PM Alex Rousskov <
> rousskov at measurement-factory.com> wrote:
>
>> On 2/26/19 4:55 AM, Stilyan Georgiev wrote:
>>
>> > Squid 4.5 with openssl support here.
>> > SSL bumping can't obtain SNI / cert domain to perform filtering when
>> > tls1.3 is used.
>> > I want to disable support for tls1.3 in config but don't find way to do
>> > so. There's the outdated sslproxy_options config directive which doesn't
>> > appear to be supported in 4.5
>> >
>> > The goal is - allow everything , besides tls1.3
>>
>> Good question!
>>
>> TLS v1.3 clients that use "Middlebox Compatibility Mode", including
>> OpenSSL s_client and popular browsers, pretend to be TLS v1.2 clients
>> that attempt to restore a non-existent TLS session. Squid probably does
>> not have ACLs that can detect those lies. However, if you think you can
>> detect them, you can pass TLS Hello to your external ACL via the
>> %>handshake logformat code.
>>
>> If you are asking whether Squid can downgrade TLS v1.3 to TLS v1.2, then
>> I suspect the answer is "yes, but only if you bump the client connection
>> first": A peeking Squid cannot negotiate a different TLS version with
>> the client. If TLS downgrade is what you want, you can probably use an
>> OpenSSL version that does not support TLS v1.3. There may also be an
>> OpenSSL v1.1.1 configuration option to turn TLS v1.3 support off, but I
>> have not research that.
>>
>> Finally, there may be a bug in earlier versions of Squid that breaks
>> peeking at TLS v1.3 servers during step2. Staring works. We have not
>> tested Squid v4.5 though. Please note that peeking at TLS v1.3 servers
>> is largely pointless because useful information in TLS v1.3 Server Hello
>> is encrypted.
>>
>>
>> HTH,
>>
>> Alex.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
> --
> Yours Sincerely,
>
> *Stilyan Georgiev*
>
>


-- 
Yours Sincerely,

*Stilyan Georgiev*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190228/51bc2eaa/attachment.htm>

From squid3 at treenet.co.nz  Thu Feb 28 00:41:39 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 28 Feb 2019 13:41:39 +1300
Subject: [squid-users] problem compiling squid 4 on ubuntu 18.04
In-Reply-To: <215821b2-eb79-4cc7-b1da-32fb68e8d70c@dvm.esines.cu>
References: <215821b2-eb79-4cc7-b1da-32fb68e8d70c@dvm.esines.cu>
Message-ID: <678a4eb0-6181-ddd3-b377-578f42bfe9a9@treenet.co.nz>

On 28/02/19 10:47 am, Alex Guti?rrez Mart?nez wrote:
> Hello comunity, can someone be so nice to tell me what i?m doing wrong
> 
> 
> Im compiling squid 4.5 on ubuntu 18.04
> 

...
> 
> 
> im getting this error
> 
> 
> error: NTLM auth helper smb_lm ... not found
> 


<http://www.squid-cache.org/Versions/v4/squid-4.6-RELEASENOTES.html#ss2.4>


Amos


From squid3 at treenet.co.nz  Thu Feb 28 01:52:04 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 28 Feb 2019 14:52:04 +1300
Subject: [squid-users] Disable tls1.3 support ,
 can't get SNI / cert details when it's used
In-Reply-To: <CAGWmD=w3aC4e9zMuO85b_UwWRh9_V4d3t5+_DQVizYbg3FJiWQ@mail.gmail.com>
References: <a0f24855-e1dc-bbe0-f08c-df419e06f135@gmail.com>
 <0c53626c-b76d-616d-b4b3-ab0d76cb3651@measurement-factory.com>
 <CAGWmD=yXuOvdGi5Q=ctTF1mYQMy6uNawGE22MQCqdumEEm=ynQ@mail.gmail.com>
 <CAGWmD=w3aC4e9zMuO85b_UwWRh9_V4d3t5+_DQVizYbg3FJiWQ@mail.gmail.com>
Message-ID: <44a02e5c-a17c-bdc2-32a6-23d257d4d245@treenet.co.nz>

On 28/02/19 12:25 pm, Stilyan Georgiev wrote:
> When testing like so: openssl s_client -connect google.com:443
> I get tls1.2 back
> 
> Via mobile chrome browser (android) and the proxy I get tls1.3
> Truly don't understand :)
> 

I expect that Chrome is using their own custom SSL library and HTTP/3
protocol which does not go through Squid.

The openssl test will be strictly using a single TCP connection with a
CONNECT tunnels through your Squid. The SSL-Bump process you have setup
will be bumpign that and Squid begotiating teh TLS versio you have
configured.

The Chrome on the other hand may be negotiating TLS/1.3 handshake via
side channels and then resuming it as a normal TLS session resumption
over the Squid connection, OR possibly not even going via the proxy at
all (aka QUIC, HTTP/3).

Google products also has a preference for using Googles custom SSL
library rather than OpenSSL - so your custom OpenSSL may not be relevant
at the client endpoint. Whereas the openssl tools will be naturally be
using libssl like Squid.


If you are not using SSL-Bump in the way(s) indicated previously by
Alex, then your custom OpenSSL build and squid.conf options are
irrelevant. The CONNECT traffic would be going straight through the
proxy without being touched. To have any control over TLS the proxy must
be an _active_ agent participating in the TLS handshake.

HTH
Amos


From squid3 at treenet.co.nz  Thu Feb 28 02:27:20 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 28 Feb 2019 15:27:20 +1300
Subject: [squid-users] HTTP2
In-Reply-To: <CAFSk7pS8rAi2=y6r=aqCkrk8S2015dNBuNBQ+N8aLQXiLxGpVw@mail.gmail.com>
References: <CAFSk7pS8rAi2=y6r=aqCkrk8S2015dNBuNBQ+N8aLQXiLxGpVw@mail.gmail.com>
Message-ID: <17416ea0-01e0-b9ec-a929-19e22fa025f8@treenet.co.nz>

On 28/02/19 6:30 am, Andrej van der Zee wrote:
> Hi,
> 
> I understood that http2 is work in progress. Is there anything to say
> about when this might be released??
> 

No ETA sorry. Progress has slowed down so much I stopped even saying
"soon-ish" a year ago.

If anyone wants to jump in and lend a hand my HTTP/2 work is up on
github. IMO the best tasks to collaborate on would be designing cppunit
tests to ensure the code correctness of the HPACK coder, and/or to find
h2/h2c Parser bugs. Drop me a mail if that sounds interesting.

Amos


From squid3 at treenet.co.nz  Thu Feb 28 04:12:07 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 28 Feb 2019 17:12:07 +1300
Subject: [squid-users] ssl bump
In-Reply-To: <827353279.5896389.1551274278389@mail.yahoo.com>
References: <827353279.5896389.1551274278389.ref@mail.yahoo.com>
 <827353279.5896389.1551274278389@mail.yahoo.com>
Message-ID: <1a23a75f-4181-41a5-3fcc-67c83e7aead8@treenet.co.nz>

On 28/02/19 2:31 am, leomessi983 wrote:
> Hi all
> Can i use this conf only for blocking purpose?!

You could.

I suggest you keep the default security Safe_ports and SSL_ports ACL and
http_access rules though. They exist to protect your proxy against
malicious attacks and Dos situations.

Your custom settings should go below these defaults at the place where
default squid.conf says "INSERT YOUR RULES HERE".


> Is set dynamic_cert_mem_cache_size=0MB wrong?

Probably fine. You have disabled certificate generating. So there is
nothing to go in that cache. So no need for it to exist.


> I have more than 1000 clients and i only want to block http and https
> pages.

There is no such thing as 'page' in HTTP or HTTPS. What we humans call a
page is a collection of many objects from HTTP viewpoint. You can block
some or all of these objects individually to prevent the display
happening, but it is difficult block abstract things like "pages".

Your config implies things very different to what you stated above.

 * it has no way to receive HTTP traffic happening on port 80 or 3128.
Implying you do not care about http:// stuff.

 * is splices some TLS traffic. Indicating that you do *not* want to
block some https:// traffic.




> 
> My configurations is like this:
> -----------------------------------------
> https_port 3130 tproxy ssl-bump \
> ??????? cert=/etc/squid/ssl_cert/myCA.pem \
> ??????? generate-host-certificates=off dynamic_cert_mem_cache_size=0MB
> sslcrtd_program /usr/lib64/squid/security_file_certgen
> 
> 
> acl blk ssl::server_name "/var/blk.list"
> ssl_bump bump blk
> http_access deny blk

The value checked by 'blk' ACL can change when the bump action is
performed. That means these ssl_bump and http_access may produce
different match results.

Since you are only intercepting traffic I suggest your http_access rule
be this instead:

  acl HTTPS proto HTTPS
  http_access deny HTTPS
  http_access allow CONNECT localnet


> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump splice all
> -------------------------------------

Cheers
Amos


From rafael.akchurin at diladele.com  Thu Feb 28 06:51:40 2019
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 28 Feb 2019 06:51:40 +0000
Subject: [squid-users] problem compiling squid 4 on ubuntu 18.04
In-Reply-To: <215821b2-eb79-4cc7-b1da-32fb68e8d70c@dvm.esines.cu>
References: <215821b2-eb79-4cc7-b1da-32fb68e8d70c@dvm.esines.cu>
Message-ID: <AM0PR04MB4753678F7E4BECB47336D9518F750@AM0PR04MB4753.eurprd04.prod.outlook.com>

Hello Alex,

Please take a look at how we recompile Squid 4.6 for Ubuntu 18.
It compiles and runs nicely without errors.

See https://docs.diladele.com/howtos/build_squid_4_on_ubuntu/index.html

Best regards,
Rafael Akchurin
Diladele B.V.


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Alex Guti?rrez Mart?nez
Sent: Wednesday, 27 February 2019 22:48
To: squid-users at lists.squid-cache.org
Subject: [squid-users] problem compiling squid 4 on ubuntu 18.04

Hello comunity, can someone be so nice to tell me what i?m doing wrong


Im compiling squid 4.5 on ubuntu 18.04


this are the dependency i have installed


apt-get -y install libcppunit-dev libsasl2-dev libxml2-dev libkrb5-dev libdb-dev libnetfilter-conntrack-dev libexpat1-dev libcap2-dev libldap2-dev libpam0g-dev libgnutls28-dev libssl-dev libdbi-perl
libecap3 libecap3-dev libntlm0-dev libkf5kiontlm5 samba-dev ldap-utils


this are the options for squid

./configure --build=x86_64-linux-gnu --enable-delay-pools --enable-cache-digests --enable-icap-client --enable-ssl --enable-ssl-crtd --with-openssl --enable-follow-x-forwarded-for --enable-auth-basic="DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB" 
--enable-auth-digest="file,LDAP" --prefix=/usr --includedir=${prefix}/include --mandir=${prefix}/share/man --infodir=${prefix}/share/info --sysconfdir=/etc --localstatedir=/var --libexecdir=${prefix}/lib/squid --srcdir=. --disable-maintainer-mode --disable-dependency-tracking --disable-silent-rules --datadir=/usr/share/squid --sysconfdir=/etc/squid --mandir=/usr/share/man --enable-inline --disable-arch-native
--enable-async-io=8 --enable-storeio=ufs,aufs,diskd,rock
--enable-removal-policies=lru,heap --enable-delay-pools --enable-cache-digests --enable-icap-client --enable-follow-x-forwarded-for --enable-auth-negotiate=kerberos,wrapper
--enable-auth-ntlm=fake,smb_lm
--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,unix_group,wbinfo_group
--enable-url-rewrite-helpers=fake --enable-eui --enable-esi --enable-zph-qos --enable-ecap --disable-translation --with-swapdir=/var/spool/squid --with-logdir=/var/log/squid --with-pidfile=/var/run/squid.pid --with-filedescriptors=65536 --with-large-files --with-default-user=proxy --enable-ssl --with-open-ssl=/etc/ssl/openssl.cnf --enable-linux-netfilter 'CFLAGS=-g
-O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security -Wall' 'LDFLAGS=-fPIE -pie -Wl,-z,relro -Wl,-z,now' 
'CPPFLAGS=-D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security'


im getting this error


error: NTLM auth helper smb_lm ... not found


thanks in advance


--
Saludos Cordiales

Lic. Alex Guti?rrez Mart?nez

Tel. +53 7 2710327



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From augustus_meyer at gmx.net  Thu Feb 28 09:05:02 2019
From: augustus_meyer at gmx.net (reinerotto)
Date: Thu, 28 Feb 2019 03:05:02 -0600 (CST)
Subject: [squid-users] squid delay_pools can't limit speed on certain
	connections
In-Reply-To: <1551090393176-0.post@n4.nabble.com>
References: <848907109.784103.1550135150221@mail.yahoo.com>
 <cff06c35-41fe-e5b5-8107-8116cc7d0a3f@measurement-factory.com>
 <1550663170426-0.post@n4.nabble.com>
 <0ecd5fdb-f421-52c5-8435-5f3869d04e3e@treenet.co.nz>
 <1551047666028-0.post@n4.nabble.com>
 <b0314914-672b-0c14-1f8a-680fc998c87d@treenet.co.nz>
 <1551090393176-0.post@n4.nabble.com>
Message-ID: <1551344702195-0.post@n4.nabble.com>

Hi Amos,
I assume, you got the password for the logfile via email.

Then, how to proceed here ? Should I file an official bug ?



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From dvanorder at deloitte.com  Thu Feb 28 17:11:06 2019
From: dvanorder at deloitte.com (Van Order, Drew (US - Hermitage))
Date: Thu, 28 Feb 2019 17:11:06 +0000
Subject: [squid-users] Squid for Windows Repeatedly Crashing
In-Reply-To: <CO1PR85MB0181BC9EB0A38A334B58E79EC8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
References: <CO1PR85MB01813A5458178FD1CA99B62EC87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <5fa308ec-4c17-aed3-8209-b1455aac39e8@treenet.co.nz>
 <CO1PR85MB01811043577EBDD2888620E9C87E0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <f5be33d1-6e90-e051-8d40-9d6c10fd32e5@treenet.co.nz>
 <CO1PR85MB0181A61F80377A62F14516D7C87F0@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <04fc01d4cba3$ce63ecf0$6b2bc6d0$@ngtech.co.il>
 <CO1PR85MB0181275803A77F5C6DFAE39EC8790@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <AM0PR04MB47539AEB5F719878A4D3BE588F790@AM0PR04MB4753.eurprd04.prod.outlook.com>
 <d9c78152489a2929b626020e59a03288@ngtech.co.il>
 <CO1PR85MB01816F3C2F31B7D6B9A86DCEC8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABoy0gsMM9PQZwm278yS5ciAQAAAAA=@ngtech.co.il>
 <CO1PR85MB0181E7870AFA7EB911FBCBA3C8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
 <001601d4cedd$1f2304f0$5d690ed0$@ngtech.co.il>
 <!&!AAAAAAAAAAAuAAAAAAAAANdDuvHk9MdNkXRSPO6m5z0BAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABEhIPWaARbTbyJaQgTTfNOAQAAAAA=@ngtech.co.il>
 <CO1PR85MB0181BC9EB0A38A334B58E79EC8740@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>
Message-ID: <CO1PR85MB0181B99FDA351848B0DF468FC8750@CO1PR85MB0181.NAMPRD85.PROD.OUTLOOK.COM>

It is confirmed that the problems experienced under Windows Server 2016 do not occur under Linux. All traffic in the VIP is going to the Linux Squid (using 4K file descriptors), but I've requisitioned another for redundancy.

Thanks to everyone for their advice!

-----Original Message-----
From: Van Order, Drew (US - Hermitage) 
Sent: Wednesday, February 27, 2019 4:47 PM
To: 'eliezer at ngtech.co.il' <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: RE: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

Wow. This is very generous Eliezer. I am humbled by your generosity!

Before I try your proxy for Windows, I've decided it's time to eliminate the OS as a variable. I quickly tacked up Squid running on a sandbox RHEL, and submitted a ticket to have it added to the F5 VIP. 

If the issue vanishes, bye bye Windows, and some folks are going to have to teach themselves Linux quickly :-) 

Stay tuned.......

-----Original Message-----
From: eliezer at ngtech.co.il <eliezer at ngtech.co.il>
Sent: Wednesday, February 27, 2019 4:28 PM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Cc: squid-users at lists.squid-cache.org
Subject: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

Forgot to mention that this simple proxy:
http://secure-web.cisco.com/11Ju3FBMy81J840cSoCXGXdubwW80knGlevOiEwmFux7MQTjMwodNApLbJYerezA5dSOY7bJJChXO2aVi80fseEIMDaEj12mh4Ig4yNYzxviiWXlGyk_IUiyoo4tIFc-tnaWbefXsQ49afvPY1yTX-B3H7BK3voG5Dfw2WmyZJ1N8lEwnCwquwbLcdnYnYw8zp5qIMe-Rq4fl-399jML9snz7QIUgE4jK46s-OgXDOPlHDlMfqgp66UhJL7cw-AkWDYfQV_uIGnUEWpvvmS1qEfhOLC89KnTzH3WCIRGR-Zh3LgWUo5yr4vW_nmyO0deNOGfNP4t2D-JjK85rZEahU_JLuFgzQLJC95M-uzoATapIbxqkCdSJ9ibyDaLhZWNdCyV6H64olDKlBBonUSnOTeu2C-RaoCUoOPhOL4I2zX_vyKrB5zGX2qWpo4TVQxRWd1z-WVIOJb0AS9J9m86mpQ-Op-Govz_L9XwqaMOHngH2bb1UB9JWMHbW8fcZny9nFZR2VeG6N9X87shN9Ek1dQ/http%3A%2F%2Fgogs.ngtech.co.il%2Felicro%2Fgolang-http-proxy

Is a simple forward proxy I wrote.
A binary packaged for any OS that GoLang supports including Windows 2k16 is there:
http://secure-web.cisco.com/1ySd839vtqkoCLOWAs5SXi2Fzc8RNRQd0Vk53qQWH0XChRYXvX7qhbT1_QhocdaqgeVsDhkDZscU9PQNRd-4mhsOlnZHRKyqrSW4zlw4x-BaRogwP4jInaTbDEhCTTt4wUSiKS9VaahRIdiCoI81Sy46jhpq4i14fB5KSHtSywhD1SzmqDQfokkEr0vUFP0x2RdYtkY9axCTbSljyVgdDMk0QQfIPQ8nmFs5FULbfd4Xrts9UPlcmoNleo0YXHCWlrizaT2JCuRqW23kq9baAB8VOk06MtwBkmdFLY7AMT49HqRhTwgHHPTuL2jyL7IA4FYG-RAlo3JU0GyLgZWeX2ruEk66ZhadtuwLNkyucJwAoyoQMIyhM5ps0lC2DdHWEamYLT8M7NoW4TZju03jD76ixc8xMPzbnN0IBFznWcnZPYIooUHeAxyAaYEBp47vR-pAMV4kur_zcuU_Exv7B2jY9lfXLPAnPUW-c20el5ZGTosbPeV6bF9D7XofMf6FvnbsqTkf_VgUDynE-tnLDsw/http%3A%2F%2Fgogs.ngtech.co.il%2FNgTech-LTD%2Fgolang-http-proxy%2Fsrc%2Fmaster%2Fgolang-http-proxy.tar.xz

You will need some software to make it a service but these are easy to find.
If you need a recommendation for one I will try to find.

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of eliezer at ngtech.co.il
Sent: Wednesday, February 27, 2019 22:44
To: 'Van Order, Drew (US - Hermitage)' <dvanorder at deloitte.com>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing

So just to be on the clear.
You need a basic forward proxy that does CONNECT requests for any LAN client to safe ports?

Do you have any other requirements then being Windows 2k16 compatbile and the mentioned ACL's?

If you Insist on a Windows proxy there are couple I collected...
http://secure-web.cisco.com/17a99t4PIGRmHeQmTLY5KRhYDoGTUPwyYGXT0fAV0DVh9MsSteT4Pi-0sb_DM-mY6nLb-NLB1ftORaQ0bC7KstwyrnAci2lsLoKWzNgOiKHwBGQSVL7MMHSGJ1zHRTGIcyEuDlGdldzgihQb6_79nG9yppR2yvpbWX2uvTAEr-qZB46PVCd_d3YtLah9RzDxyJymPdDeyaAw66X6Agmqs512eb5uI1oCN3auT9qbjI11NDr8edlo3R04C-tHHqBAka4hQXEs9LavQUNcBcHFWhME6PEBNCdLVBeitC3d9ZF2rtYKIP5iFYZs1w72GL_-Xh0zawz7uiX9GcwN60Tx0m8MJQQoEMPp4v3cfSiM-pFHI7YAJRvcCfFENvZcgNXFQrzX4ZVaLIxPkV5q2fN8uGObAZKRTWkqAXwo2LE40s9waGLpTDmiXy76gE6sGFerW5m1mImQElzPWjajbWJfqSi8aD7W1TC0w42AGOqQJ60VnXhZw4CuupXzmylyd8E6D_GPtTtAdp5VPrXTEQCT20w/http%3A%2F%2Fwww1.ngtech.co.il%2Fwpe%2F2016%2F05%2F02%2Fproxy-per-internet-user-is-it-realis
tic/

I know that RedWood might be good for your needs to compare...:
http://secure-web.cisco.com/1ETToAy7lpIzQDnVWVx4VN460yeA4V0c0irlIMN9P5wE50B-0kLELWsz8usawuOgy7IZPOJ6iV2FTApPTEaJH1nHFLR-pnUkuG7C5E6f_fZdUofEV5UX__yh2g0MRKI7XB3x1uEdiMhlhtodTsSeJYzqWK_5Zij6_rNjYlWlY8573ATbmhIZNgkfwcaoRJl4FwO50zEAueB_tlGyikPc8FfJGgKZbcRYa7frdZcwsn9JKeQh_GISsi-_BpAETFQf6ZeZ5SGXQ5TB4z9GoPlncAf0vxingBSktcPgqF-jRLgxwHQ9nv6a-Ses-94UmCser4hIzsd6pTOHLVYY8u0OWUjlB5rRqROlH_IMkslBcFtEXaRYl1Fy2LEgL9RWaSuNFG-wRWmFw4BRtweHIpRnypuF24a2vKjwnN929-EHwHv-t-rCk8FSTQ5OfkHkP78sN0ErpcZv9GFBXOPA_7y0MTp3evd2SWbD4YBfXSZ5a3BCL4iM2Jx4KfG9SBK5KIz2TkdGzjQXIWujLFeWtOd5KIw/http%3A%2F%2Fngtech.co.il%2Fstatic%2Fredwood%2Fredwood-0.2.0.tar.xz
https://secure-web.cisco.com/14Y9nKqTcPsVkJBCkyIkxFkE_XO9jqzDvqIf1yzNdAIfhtJDiPPfe1HdfUmXxsFWMojRBhFGJfxGogPbIh16U9bdtA5l-XZkZAXM-KcwTAto3X-WRpC6ogpKA9wuNMuWwgKlRAPdgz1hvOAho8mcmXlY3Zct0t1WX6qy5RJ4Yjm_Nwfk5gBzAn_HXuCRAVkwmXYtzSqdwxpxhZ7bG-nsO4bHr0CwqU2WmvzUSsTQEHERFcVTMX0B5PrzmySJtmZlzv33zvGFFwrW8SSSTSqVrxZtiiHJly8tc9e42bpY2v7tmkhkacmX50Vn5w7FcsqjKVew6Qey7TAPp2K6_7n-Dr15pHPvpunEiHUVC-ewcE5OXL3uf1bruR-XsF2xLNe1UN2TxTQdLNO5od_wmbO1KzFAq70T8o5gS7Tf5xPbUqX_GHNbHWi53302aJvDUpIH6Dlr7llzwKR1J51WdEL2XCiu61T2w-Sn7rmzQnoS8kkwzadmdrJAxXyaOcJTO82wmRT8W4fcPPWVIRzwdyAXjqg/https%3A%2F%2Fgithub.com%2Fandybalholm%2Fredwood

I wrote a tiny proxy the other day which should also work fine for you as long as you have a working and properly configured firewall on the Server.
Let me know if something fit your needs.
If so you can try and test and maybe find the right culprit(ie windows or linux).

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Sent: Wednesday, February 27, 2019 17:55
To: eliezer at ngtech.co.il
Cc: squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Squid for Windows Repeatedly Crashing

Business objective is to enable MSFT Azure MMA's (Microsoft Monitoring
Agents) blocked from the internet to send agent data to Azure Log Analytics

Simple proxy
No SSL bump
Squid config is attached
I tried disabling caching with Squid, found it crashed more frequently Squid was chosen this is intended to be a stopgap solution, and it's free.
It's a battle to win over security in order to have tcp/443 opened everywhere.

I'm not sure Squid is the problem, I have an identically configured Squid that bypasses the F5 working beautifully, but it's only 50 clients (MMA's) connecting, Each client takes roughly 5 connections. The clients are still going through a firewall(s). 

Our network folks say that neither the FW or F5 leading up to Squid report congestion. 

It's possible that Squid for Windows + F5 VIP are not intended to work together, but it makes sense to just have one proxy IP address.

I'm getting ready to Skype with our F5 guy to compare what I'm seeing with what he's seeing. Also trying to get how many clients are going through the
F5 to compare to my 'good' Squid

-----Original Message-----
From: eliezer at ngtech.co.il <eliezer at ngtech.co.il>
Sent: Wednesday, February 27, 2019 9:20 AM
To: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Cc: squid-users at lists.squid-cache.org
Subject: [EXT] RE: [squid-users] Squid for Windows Repeatedly Crashing

The setup itself is not clear to me.
Is it a simple proxy?
With SSL bump?
Can you share or send me the squid configuration?
There might be another solution for your use case that you have yet to try.
Also if the purpose is not caching, why do you try to use squid?
There are lots of other proxies for windows out there? (just wondering what and why have you choose Squid)

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>
Sent: Wednesday, February 27, 2019 05:51
To: Eliezer Croitoru <eliezer at ngtech.co.il>; Rafael Akchurin <rafael.akchurin at diladele.com>
Cc: 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Squid for Windows Repeatedly Crashing

Hello folks, and thanks for keeping interest. Today I spent a bit of time learning squidclient, and have determined that the server is not in any way resource constrained. I've attached the output from mgr:info, mgr:client_list, and mgr:filedescriptors in between crashes. Was wondering if someone could explain Tout, which I presume is timeout. Of interest are the ones set to 86400, which I presume is one day. That seems like a big problem--but where is it coming from? I'm using the Cygwin Squid config defaults.

There seems to be a lot of Reading next request going on before Squid recycles. I wonder if the F5 VIP is dealing with congestion through the firewall, which, in turn, is causing congestion on the pool output side, the
10.26.25.220 address. Our F5 guys have gone silent on me, I have been asking questions, in particular why all the F5 traffic is coming over just one IP address in the pool.

In case folks wonder what the IP's are in the file descriptor output....

1310 Socket  898    6044*    2806  40.71.12.224:443
593a6510-ebfc-4d6b-a8f0-a0411dfee098.ods.opinsights.azure.com:443 (this is Squid forwarding Windows event/perf data from an agent to Azure Log
Analytics)
1311 Socket  899    3015*    9208  10.26.25.220:61088    Reading next
request (10.26.25.220) is the pool IP address of the F5 in use)
1312 Socket  899    2690*    8826  10.26.25.220:61436    Reading next
request
1313 Socket  899    9169*    2884  104.208.163.218:443
eus2-jobruntimedata-prod-su1.azure-automation.net:443 (Squid to Azure)
1314 Socket  899    8787*    2508  104.208.163.218:443
eus2-jobruntimedata-prod-su1.azure-automation.net:443
1315 Socket  118     119*    3924  10.26.25.220:52153    Idle client:
Waiting for next request
1316 Socket  900    1382*    8697  10.26.25.220:54786    Reading next
request

This is from a box that restarts squid every few minutes. Typical cache.log snippet

2019/02/26 21:24:22 kid1| storeDirWriteCleanLogs: Starting...
2019/02/26 21:24:22 kid1|   Finished.  Wrote 0 entries.
2019/02/26 21:24:22 kid1|   Took 0.00 seconds (  0.00 entries/sec).
2019/02/26 21:24:26 kid1| Set Current Directory to /var/cache/squid
2019/02/26 21:24:26 kid1| Starting Squid Cache version 3.5.28 for x86_64-unknown-cygwin...
2019/02/26 21:24:26 kid1| Service Name: squid
2019/02/26 21:24:26 kid1| Process ID 1796
2019/02/26 21:24:26 kid1| Process Roles: worker
2019/02/26 21:24:26 kid1| With 3200 file descriptors available
2019/02/26 21:24:26 kid1| Initializing IP Cache...
2019/02/26 21:24:26 kid1| parseEtcHosts: /etc/hosts: (2) No such file or directory
2019/02/26 21:24:26 kid1| DNS Socket created at [::], FD 5
2019/02/26 21:24:26 kid1| DNS Socket created at 0.0.0.0, FD 6
2019/02/26 21:24:26 kid1| Adding nameserver 208.67.220.220 from squid.conf
2019/02/26 21:24:26 kid1| Adding nameserver 208.67.222.222 from squid.conf
2019/02/26 21:24:26 kid1| Logfile: opening log daemon:/var/log/squid/access.log
2019/02/26 21:24:26 kid1| Logfile Daemon: opening log /var/log/squid/access.log
2019/02/26 21:24:26 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
2019/02/26 21:24:26 kid1| Store logging disabled
2019/02/26 21:24:26 kid1| Swap maxSize 3072000 + 262144 KB, estimated 256472 objects
2019/02/26 21:24:26 kid1| Target number of buckets: 12823
2019/02/26 21:24:26 kid1| Using 16384 Store buckets
2019/02/26 21:24:26 kid1| Max Mem  size: 262144 KB
2019/02/26 21:24:26 kid1| Max Swap size: 3072000 KB
2019/02/26 21:24:26 kid1| Rebuilding storage in /cygdrive/e/squid/cache (clean log)
2019/02/26 21:24:26 kid1| Using Least Load store dir selection
2019/02/26 21:24:26 kid1| Set Current Directory to /var/cache/squid
2019/02/26 21:24:26 kid1| Finished loading MIME types and icons.
2019/02/26 21:24:26 kid1| HTCP Disabled.
2019/02/26 21:24:26 kid1| Squid plugin modules loaded: 0
2019/02/26 21:24:26 kid1| Adaptation support is off.
2019/02/26 21:24:26 kid1| Accepting HTTP Socket connections at
local=10.26.24.65:3128 remote=[::] FD 12 flags=9
2019/02/26 21:24:26 kid1| Done reading /cygdrive/e/squid/cache swaplog (0
entries)
2019/02/26 21:24:26 kid1| Store rebuilding is 0.00% complete
2019/02/26 21:24:26 kid1| Finished rebuilding storage from disk.
2019/02/26 21:24:26 kid1|         0 Entries scanned
2019/02/26 21:24:26 kid1|         0 Invalid entries.
2019/02/26 21:24:26 kid1|         0 With invalid flags.
2019/02/26 21:24:26 kid1|         0 Objects loaded.
2019/02/26 21:24:26 kid1|         0 Objects expired.
2019/02/26 21:24:26 kid1|         0 Objects cancelled.
2019/02/26 21:24:26 kid1|         0 Duplicate URLs purged.
2019/02/26 21:24:26 kid1|         0 Swapfile clashes avoided.
2019/02/26 21:24:26 kid1|   Took 0.05 seconds (  0.00 objects/sec).
2019/02/26 21:24:26 kid1| Beginning Validation Procedure
2019/02/26 21:24:27 kid1|   Completed Validation Procedure
2019/02/26 21:24:27 kid1|   Validated 0 Entries
2019/02/26 21:24:27 kid1|   store_swap_size = 0.00 KB
2019/02/26 21:24:27 kid1| storeLateRelease: released 0 objects
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [ job1]: (14) Bad address
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/26 21:25:02 kid1|  FD 12, 10.26.24.65 [Stopped, reason:Listener socket closed job1]: (14) Bad address
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 1
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 2
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 3
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 4
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 5
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 6
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 7
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 8
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 9
2019/02/26 21:25:02 kid1| comm_poll: poll failure: (14) Bad address
2019/02/26 21:25:02 kid1| Select loop Error. Retry 10
2019/02/26 21:25:02 kid1| Closing HTTP port 10.26.24.65:3128
FATAL: Event loop exited with failure.
Squid Cache (Version 3.5.28): Terminated abnormally.
CPU Usage: 13.187 seconds = 4.625 user + 8.562 sys Maximum Resident Size:
5276416 KB Page faults with physical i/o: 20822

-----Original Message-----
From: Eliezer Croitoru <eliezer at ngtech.co.il>
Sent: Tuesday, February 26, 2019 5:23 PM
To: Rafael Akchurin <rafael.akchurin at diladele.com>
Cc: Van Order, Drew (US - Hermitage) <dvanorder at deloitte.com>; 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: [EXT] Re: [squid-users] Squid for Windows Repeatedly Crashing

It depends on the hardware in the server grade Windows.
It can take more then 3k conn's for 100%.
It's possible that squid was not designed for windows 2k16....

Eliezer

On 2019-02-24 15:47, Rafael Akchurin wrote:

> As far as I know the internal FD limit for Windows build is around 3K
> - might be being existed and thus unexpected behavior raising its ugly 
> head..
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On 
> Behalf Of Van Order, Drew (US - Hermitage)
> Sent: Sunday, 24 February 2019 14:40
> To: eliezer at ngtech.co.il; 'Amos Jeffries' <squid3 at treenet.co.nz>; 
> squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid for Windows Repeatedly Crashing
>
> This is helpful, and I especially appreciate the time given it is the 
> weekend.
> <SNIP>
This message (including any attachments) contains confidential information intended for a specific individual and purpose, and is protected by law. If you are not the intended recipient, you should delete this message and any disclosure, copying, or distribution of this message, or the taking of any action based on it, by you is strictly prohibited.

v.E.1


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://secure-web.cisco.com/1QaWJJeGQzVtr7er4_2VR8x7s6gFT4wjkA8x85dYsl37jmR3uDRD9kUV2i_MVxbEt-oDF_9BXrUfSk03eD0nmwaXQ5MpVCTQtsnrpkAhcP9tUwqQ7R4BddSmai1NmhcOSLib8g-S6l7LiyiJ_tLM8ZUKvhUkISHWgfBv0tyhzB90I0pdUSsoglrsHNyKpse1y17_Fl2kblE8wfq3OjUOGytxNyP45Rfmmc7i1xBsj6-rfsIjwC1Zzsy1WBzlAQSAyZmSZtSywg_8EDGfinpLwe29V3X1YXz4sDrMGdZJB7HPx4h7lmZ4Biv5oJZbKmetDzwTffKXOzFz77qVL14IQk6bjavIe1Rs7J5-qT9459Twbp3oWKulNp7NdMdpQyovPDZRdAjd-zkJpikePTCheZHJ5F5EgcOzUWflpSfE400lOJ4xjl7M8xEScxdVikcIfZ8deAae91AN-d2lBvPZn2iMULlxIBKaeRcxofH-Dk4ZHEMvzvfWhMrf80X0jU_KYPSJjn2fxuxoRLfxE77PjxA/http%3A%2F%2Flists.squid-cache.org%2Flistinfo%2Fsquid-users



From rousskov at measurement-factory.com  Thu Feb 28 17:27:54 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 28 Feb 2019 10:27:54 -0700
Subject: [squid-users] HTTP2
In-Reply-To: <CAFSk7pS8rAi2=y6r=aqCkrk8S2015dNBuNBQ+N8aLQXiLxGpVw@mail.gmail.com>
References: <CAFSk7pS8rAi2=y6r=aqCkrk8S2015dNBuNBQ+N8aLQXiLxGpVw@mail.gmail.com>
Message-ID: <53069a68-981d-0f40-bcab-fa42bbe9920c@measurement-factory.com>

On 2/27/19 10:30 AM, Andrej van der Zee wrote:

> I understood that http2 is work in progress. 
> Is there anything to say about when this might be released??

IMO, given the way the Squid Project operates right now, the correct
answer to that question is close to "hopefully not in the foreseeable
future": We cannot add quality HTTP/2 support right now, and adding some
hacky version of it would be disastrous for Squid stability, support,
and development. Combined with where the popular clients and origin
servers are going, it may be better to fantasize about HTTP/3 support
instead.

Based on Factory experience with adding HTTP/2 support to Web Polygraph,
I consider the following (partially overlapping) preconditions as
necessary for serious HTTP/2 (or HTTP/3) work in Squid:

  1. Proper QA infrastructure.

  2. Elimination of technical debt that prevents proper restructuring
     of HTTP/2-sensitive code.

  3. An agreement regarding overall HTTP/2 code architecture.

  4. An efficient way to accept huge code changes.

  5. A project lead capable, willing, trusted, and funded
     to orchestrate such a big change from beginning to end.

Right now, *none* of the above preconditions are satisfied.

There is slow but steady progress with #1 and areas of #2.

The situation with #3 and #4 is worse than it was a few years ago -- we
are wasting insane amounts of time on getting much simpler code changes
reviewed and accepted. Many changes require a rewrite before they should
be accepted (and some are indeed rewritten). Nobody can afford to
rewrite a pull request with initial HTTP/2 support!

We have nobody who can satisfy #5 criteria right now.


On 2/27/19 7:27 PM, Amos Jeffries wrote:

> If anyone wants to jump in and lend a hand my HTTP/2 work is up on 
> github. IMO the best tasks to collaborate on would be designing
> cppunit tests
Creating more unofficial code is a bad idea at this time IMO.

Alex.


From leomessi983 at yahoo.com  Thu Feb 28 20:18:41 2019
From: leomessi983 at yahoo.com (leomessi983 at yahoo.com)
Date: Thu, 28 Feb 2019 20:18:41 +0000 (UTC)
Subject: [squid-users] ssl bump
References: <1015061526.6752705.1551385121327.ref@mail.yahoo.com>
Message-ID: <1015061526.6752705.1551385121327@mail.yahoo.com>

---
Hi againtax for your reply Amos.My problem is when i disable generate-host-certificates
sslcrtd_program
I cant redirect HTTPS requests to block err page!!I don't really understand what this configuration do!What does actually this configurations "generate-host-certificates and dynamic-cert-mem-cach-size" do? generate cert for squid to communicate to server or client? why when i disable it squid does not show block err page for HTTPS requests? i don't want to use? sslcrtd_program db in my host and i want to block HTTPS requests based of my acl and splice all? of other requests and also show block err page to clients!Is that possible or? i have to use sslcrtd_program db?
Tank you
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190228/580614f1/attachment.htm>

From andrejvanderzee at gmail.com  Thu Feb 28 22:35:44 2019
From: andrejvanderzee at gmail.com (Andrej van der Zee)
Date: Thu, 28 Feb 2019 23:35:44 +0100
Subject: [squid-users] HTTP2
In-Reply-To: <53069a68-981d-0f40-bcab-fa42bbe9920c@measurement-factory.com>
References: <CAFSk7pS8rAi2=y6r=aqCkrk8S2015dNBuNBQ+N8aLQXiLxGpVw@mail.gmail.com>
 <53069a68-981d-0f40-bcab-fa42bbe9920c@measurement-factory.com>
Message-ID: <CAFSk7pSC_eMmJOTv-WO=f=e83GLR_PWtzM-_LE5rTf-yuQopcg@mail.gmail.com>

Hi Alex / Amos,

It sounds like its still a long way to get HTTP/2 support released and
contributing therefore is not an option in company time.

Maybe a bit blunt, in our case it means looking for either
Squid-workarounds for HTTP/2 servers we have to address (Apple APNS
notification server for example), or change to another proxy with HTTP/2
support.

Best regards,
Andrej




On Thu, Feb 28, 2019 at 6:28 PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 2/27/19 10:30 AM, Andrej van der Zee wrote:
>
> > I understood that http2 is work in progress.
> > Is there anything to say about when this might be released?
>
> IMO, given the way the Squid Project operates right now, the correct
> answer to that question is close to "hopefully not in the foreseeable
> future": We cannot add quality HTTP/2 support right now, and adding some
> hacky version of it would be disastrous for Squid stability, support,
> and development. Combined with where the popular clients and origin
> servers are going, it may be better to fantasize about HTTP/3 support
> instead.
>
> Based on Factory experience with adding HTTP/2 support to Web Polygraph,
> I consider the following (partially overlapping) preconditions as
> necessary for serious HTTP/2 (or HTTP/3) work in Squid:
>
>   1. Proper QA infrastructure.
>
>   2. Elimination of technical debt that prevents proper restructuring
>      of HTTP/2-sensitive code.
>
>   3. An agreement regarding overall HTTP/2 code architecture.
>
>   4. An efficient way to accept huge code changes.
>
>   5. A project lead capable, willing, trusted, and funded
>      to orchestrate such a big change from beginning to end.
>
> Right now, *none* of the above preconditions are satisfied.
>
> There is slow but steady progress with #1 and areas of #2.
>
> The situation with #3 and #4 is worse than it was a few years ago -- we
> are wasting insane amounts of time on getting much simpler code changes
> reviewed and accepted. Many changes require a rewrite before they should
> be accepted (and some are indeed rewritten). Nobody can afford to
> rewrite a pull request with initial HTTP/2 support!
>
> We have nobody who can satisfy #5 criteria right now.
>
>
> On 2/27/19 7:27 PM, Amos Jeffries wrote:
>
> > If anyone wants to jump in and lend a hand my HTTP/2 work is up on
> > github. IMO the best tasks to collaborate on would be designing
> > cppunit tests
> Creating more unofficial code is a bad idea at this time IMO.
>
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
Andrej van der Zee
Oranje-Vrijstaatkade 49
1093KS Amsterdam
+31-(0)6-8133-9388
https://www.linkedin.com/in/andrejvanderzee/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190228/f27df11d/attachment.htm>

From alex at dvm.esines.cu  Thu Feb 28 21:03:00 2019
From: alex at dvm.esines.cu (=?UTF-8?Q?Alex_Guti=c3=a9rrez_Mart=c3=adnez?=)
Date: Thu, 28 Feb 2019 16:03:00 -0500
Subject: [squid-users] compiling squid 4
Message-ID: <6b3ee0ff-fa7d-87e2-9c46-8fbfe063f463@dvm.esines.cu>

Hello again community, I still have problems compiling squid 4. This is 
what i did this time

Soporte b?sico necesario:

# apt install arj bzip2 xz-utils cabextract cpio file lzma lhasa lzop 
rpm2cpio gzip nomarch pax lzop rar unrar unzip zoo unace razor pyzor 
tnef ripole zip p7zip-full mc multitail ccze libcppunit-dev libsasl2-dev 
libxml2-dev libkrb5-dev libdb-dev libnetfilter-conntrack-dev 
libexpat1-dev libcap2-dev libldap2-dev libpam0g-dev libgnutls28-dev 
libssl-dev libdbi-perl libecap3 libecap3-dev libntlm0-dev libkf5kiontlm5 
samba-dev ldap-utils

Instalar binarios necesarios para compilar Squid4, the system retunr a 
error whe in start the service:

sudo apt install logrotate acl attr autoconf bison nettle-dev 
build-essential libacl1-dev libaio-dev libattr1-dev libblkid-dev 
libbsd-dev libcap2-dev libcppunit-dev libldap2-dev pkg-config 
libxml2-dev libdb-dev libgnutls28-dev openssl devscripts fakeroot 
libdbi-perl libssl1.0-dev libcppunit-dev libecap3-dev libkrb5-dev 
comerr-dev libnetfilter-conntrack-dev libpam0g-dev libsasl2-dev

 ?sudo groupadd -g 13 proxy
 ?sudo mkdir -p /var/spool/squid
 ?sudo mkdir -p /var/log/squid
 ?sudo useradd --system -g proxy -u 13 -d /var/spool/squid -M -s 
/usr/sbin/nologin proxy
 ?sudo chown proxy:proxy /var/spool/squid
 ?sudo chown proxy:proxy /var/log/squid

cd /opt
wget -c http://www.squid-cache.org/Versions/v4/squid-4.6.tar.xz
 ?tar xfv squid-4.6.tar.xz

Configuramos las opciones b?sicas que podamos necesitar:

./configure --srcdir=. --prefix=/usr --localstatedir=/var/lib/squid 
--libexecdir=/usr/lib/squid --datadir=/usr/share/squid 
--sysconfdir=/etc/squid --with-default-user=proxy 
--with-logdir=/var/log/squid --with-open-ssl=/etc/ssl/openssl.cnf 
--with-openssl --enable-ssl --enable-ssl-crtd --build=x86_64-linux-gnu 
--with-pidfile=/var/run/squid.pid --enable-removal-policies=lru,heap 
--enable-delay-pools --enable-cache-digests --enable-icap-client 
--enable-ecap --enable-follow-x-forwarded-for --with-large-files 
--with-filedescriptors=65536 
--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB 
--enable-auth-digest=file,LDAP --enable-auth-negotiate=kerberos,wrapper 
--enable-auth-ntlm=fake --enable-linux-netfilter 
--with-swapdir=/var/spool/squid --enable-useragent-log --enable-htpc 
--infodir=/usr/share/info --mandir=/usr/share/man 
--includedir=/usr/include --disable-maintainer-mode 
--disable-dependency-tracking --disable-silent-rules --enable-inline 
--enable-async-io --enable-storeio=ufs,aufs,diskd,rock --enable-eui 
--enable-esi --enable-icmp --enable-zph-qos 
--enable-external-acl-helpers=file_userip,kerberos_ldap_group,time_quota,LDAP_group,session,SQL_session,unix_group,wbinfo_group 
--enable-url-rewrite-helpers=fake --enable-translation --enable-epoll 
--enable-snmp --enable-wccpv2 --with-aio --with-pthreads

Compiling with? 4 cores:

make -j 4

Installing:

sudo? make install

create initi script:

sudo nano /etc/init.d/squid

initi content:

######################################################################################################
######################################################################################################
######################################################################################################
# squid4???? Startup script for the SQUID HTTP proxy-cache.
#
# Version:?? @(#)squid4 init script? 1.0? 20-Feb-2019 leslie84 at nauta.cu
########################################################################

### BEGIN INIT INFO
# Provides:????????? squid
# Required-Start:??? $network $remote_fs $syslog
# Required-Stop:???? $network $remote_fs $syslog
# Should-Start:????? $named
# Should-Stop:?????? $named
# Default-Start:???? 2 3 4 5
# Default-Stop:????? 0 1 6
# Short-Description: Squid HTTP Proxy version 4.x
### END INIT INFO

NAME=squid
DESC="Squid HTTP Proxy 4.x"
DAEMON=/usr/sbin/squid
PIDFILE=/var/run/$NAME.pid
CONFIG=/etc/squid/squid.conf
SQUID_ARGS="-YC -f $CONFIG"

[ ! -f /etc/default/squid ] || . /etc/default/squid

. /lib/lsb/init-functions

PATH=/bin:/usr/bin:/sbin:/usr/sbin

[ -x $DAEMON ] || exit 0

ulimit -n 65535

find_cache_dir () {
 ??????? w="???? " # space tab
 ??????? res=`sed -ne '
s/^'$1'['"$w"']\+[^'"$w"']\+['"$w"']\+\([^'"$w"']\+\).*$/\1/p;
 ??????????????? t end;
 ??????????????? d;
 ??????????????? :end q' < $CONFIG`
 ??????? [ -n "$res" ] || res=$2
 ??????? echo "$res"
}

find_cache_type () {
 ??????? w="???? " # space tab
 ??????? res=`sed -ne '
 ??????????????? s/^'$1'['"$w"']\+\([^'"$w"']\+\).*$/\1/p;
 ??????????????? t end;
 ??????????????? d;
 ??????????????? :end q' < $CONFIG`
 ??????? [ -n "$res" ] || res=$2
 ??????? echo "$res"
}

start () {
 ??????? cache_dir=`find_cache_dir cache_dir`
 ??????? cache_type=`find_cache_type cache_dir`

 ??????? #
 ??????? # Create spool dirs if they don't exist.
 ??????? #
 ??????? if [ "$cache_type" = "coss" -a -d "$cache_dir" -a ! -f 
"$cache_dir/stripe" ] || [ "$cache_type" != "coss" -a -d "$cache_dir" -a 
! -d "$cache_dir/00" ]
 ??????? then
 ??????????????? log_warning_msg "Creating $DESC cache structure"
 ??????????????? $DAEMON -z -f $CONFIG
 ??????? fi

 ??????? umask 027
 ??????? ulimit -n 65535
 ??????? cd $cache_dir
 ??????? start-stop-daemon --quiet --start \
 ??????????????? --pidfile $PIDFILE \
 ??????????????? --exec $DAEMON -- $SQUID_ARGS < /dev/null
 ??????? return $?
}

stop () {
 ??????? PID=`cat $PIDFILE 2>/dev/null`
 ??????? start-stop-daemon --stop --quiet --pidfile $PIDFILE --exec $DAEMON
 ??????? #
 ??????? #?????? Now we have to wait until squid has _really_ stopped.
 ??????? #
 ??????? sleep 2
 ??????? if test -n "$PID" && kill -0 $PID 2>/dev/null
 ??????? then
 ??????????????? log_action_begin_msg " Waiting"
 ??????????????? cnt=0
 ??????????????? while kill -0 $PID 2>/dev/null
 ??????????????? do
 ??????????????????????? cnt=`expr $cnt + 1`
 ??????????????????????? if [ $cnt -gt 24 ]
 ??????????????????????? then
 ??????????????????????????????? log_action_end_msg 1
 ??????????????????????????????? return 1
 ??????????????????????? fi
 ??????????????????????? sleep 5
 ??????????????????????? log_action_cont_msg ""
 ??????????????? done
 ??????????????? log_action_end_msg 0
 ??????????????? return 0
 ??????? else
 ??????????????? return 0
 ??????? fi
}

case "$1" in
 ??? start)
 ??????? log_daemon_msg "Starting $DESC" "$NAME"
 ??????? if start ; then
 ??????????????? log_end_msg $?
 ??????? else
 ??????????????? log_end_msg $?
 ??????? fi
 ??????? ;;
 ??? stop)
 ??????? log_daemon_msg "Stopping $DESC" "$NAME"
 ??????? if stop ; then
 ??????????????? log_end_msg $?
 ??????? else
 ??????????????? log_end_msg $?
 ??????? fi
 ??????? ;;
 ??? reload|force-reload)
 ??????? log_action_msg "Reloading $DESC configuration files"
 ??????? start-stop-daemon --stop --signal 1 \
 ??????????????? --pidfile $PIDFILE --quiet --exec $DAEMON
 ??????? log_action_end_msg 0
 ??????? ;;
 ??? restart)
 ??????? log_daemon_msg "Restarting $DESC" "$NAME"
 ??????? stop
 ??????? if start ; then
 ??????????????? log_end_msg $?
 ??????? else
 ??????????????? log_end_msg $?
 ??????? fi
 ??????? ;;
 ??? status)
 ??????? status_of_proc -p $PIDFILE $DAEMON $NAME && exit 0 || exit 3
 ??????? ;;
 ??? *)
 ??????? echo "Usage: /etc/init.d/$NAME 
{start|stop|reload|force-reload|restart|status}"
 ??????? exit 3
 ??????? ;;
esac

exit 0
######################################################################################################
######################################################################################################
######################################################################################################

set permissions:

cambiar permisos al archivo
 ???? sudo chmod +x /etc/init.d/squid

activar servicio de squid
 ???? sudo update-rc.d squid defaults



After all this when i start the service this is the response from the system


 ?systemctl status squid.service
? squid.service
 ?? Loaded: loaded (/etc/init.d/squid; generated)
 ?? Active: failed (Result: exit-code) since Thu 2019-02-28 15:52:15 
CST; 5s ago
 ???? Docs: man:systemd-sysv-generator(8)
 ? Process: 18732 ExecStart=/etc/init.d/squid start (code=exited, 
status=203/EXEC)

feb 28 15:52:15 sq4 systemd[1]: Starting squid.service...
feb 28 15:52:15 sq4 systemd[18732]: squid.service: Failed to execute 
command: Exec format error
feb 28 15:52:15 sq4 systemd[18732]: squid.service: Failed at step EXEC 
spawning /etc/init.d/squid: Exec format error
feb 28 15:52:15 sq4 systemd[1]: squid.service: Control process exited, 
code=exited status=203
feb 28 15:52:15 sq4 systemd[1]: squid.service: Failed with result 
'exit-code'.
feb 28 15:52:15 sq4 systemd[1]: Failed to start squid.service.


Im using Ubuntu 18.04.2, thanks in advance.


PD: Thanks for your answer? Rafael Akchurin but unforntunately the 
article that you suggest won?t work for me.

-- 
Saludos Cordiales

Lic. Alex Guti?rrez Mart?nez

Tel. +53 7 2710327





