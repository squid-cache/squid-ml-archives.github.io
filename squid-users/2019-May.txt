From leomessi983 at yahoo.com  Wed May  1 23:57:16 2019
From: leomessi983 at yahoo.com (leomessi983 at yahoo.com)
Date: Wed, 1 May 2019 23:57:16 +0000 (UTC)
Subject: [squid-users] udp log buffer size
References: <904525924.1485.1556755036362.ref@mail.yahoo.com>
Message-ID: <904525924.1485.1556755036362@mail.yahoo.com>

Hi, 
Is this git version is stable?What is the different between git version and squid website stable v4??
thank you!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190501/c6044cce/attachment.htm>

From squid3 at treenet.co.nz  Thu May  2 05:54:40 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 2 May 2019 17:54:40 +1200
Subject: [squid-users] udp log buffer size
In-Reply-To: <904525924.1485.1556755036362@mail.yahoo.com>
References: <904525924.1485.1556755036362.ref@mail.yahoo.com>
 <904525924.1485.1556755036362@mail.yahoo.com>
Message-ID: <a1e96bfb-00db-e9ce-4c2f-ec448a1e032e@treenet.co.nz>

On 2/05/19 11:57 am, leomessi983 wrote:
> Hi,
> Is this git version is stable?
> What is the different between git version and squid website stable v4??
> 

The git branches usually include a few patches which are being
accumulated and will be released in the next release of Squid in that
series. The git "v4" branch will become v4.7 package release in a few
days - there are only a few more patches to backport before that
happens. The PR Alex referred to will be included there.

The website tarball packages are built from the git branches when some
additional automated QA builds have been performed. So we are sure that
the code is going to at least build and probably run fine for a range of
the most popular OS.


Squid-4 tarballs have been blocked as non-building these past few months
due to some of the QA systems having GCC 4.8 (CentOS 6), GCC-8 (Debian
Sid) and GCC-9 (Fedora Rawhide). The fixes for those GCC issues 8/9 have
been slow to go through our QA process, so not many snapshots have been
published.

Unless you are using one of those compiler versions the code from git
"v4" branch should build fine and is sufficiently stable for production use.

Cheers
Amos


From giacomo at gtrovato.com  Thu May  2 14:01:39 2019
From: giacomo at gtrovato.com (Giacomo Trovato)
Date: Thu, 02 May 2019 16:01:39 +0200
Subject: [squid-users] SSL_ERROR_RX_RECORD_TOO_LONG
In-Reply-To: <5eefd13a-b9ad-ffff-a6df-33c1da2e6c29@measurement-factory.com>
References: <5966bff0eb74aecf2edacffcbb58fbcf@gtrovato.com>
 <5eefd13a-b9ad-ffff-a6df-33c1da2e6c29@measurement-factory.com>
Message-ID: <fcbbb371952b60ba95565f834b44bd00@gtrovato.com>

Hi Alex, 

thanks for the answer! 

My pfSense has version 3.5.27_3.

---

Giacomo Trovato

Il 30/04/2019 16:36 Alex Rousskov ha scritto:

> On 4/30/19 8:04 AM, Giacomo Trovato wrote:
> 
>> I've pfSense with Squid + SquidGuard (Splice All - no CA certificate).
>> It worked well until one month ago, now sometimes appears the error
>> message SSL_ERROR_RX_RECORD_TOO_LONG (see attachment).
>> It appears randomly on all PC / smartphone on different HTTPS sites.
>> The devices connected directly (no proxy) work properly.
>> Any hint?
> 
> What is your current Squid version?
> 
> The browser claims that your Squid sent it a very long (most likely
> malformed) TLS record. If this does not happen without Squid, then this
> is likely a Squid bug. I see references to similar problems in old
> (Squid v3) web posts.
> 
> * If you can reproduce with Squid v4 or later, the best next step is to
> share a packet capture of the offending transaction along with the
> cache.log after setting debug_options to ALL,9. Please compress large
> files before sharing.
> 
> * If you cannot reproduce with Squid v4 or later, then the best next
> step is to upgrade your Squid.
> 
> HTH,
> 
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190502/93595410/attachment.htm>

From leomessi983 at yahoo.com  Sun May  5 09:09:58 2019
From: leomessi983 at yahoo.com (leomessi983 at yahoo.com)
Date: Sun, 5 May 2019 09:09:58 +0000 (UTC)
Subject: [squid-users] security_file_certgen problem
References: <648194123.1521534.1557047398356.ref@mail.yahoo.com>
Message-ID: <648194123.1521534.1557047398356@mail.yahoo.com>

Hi;I compiled last git version of squid 4.6-VCS my last problem with UDP log is solved but I still have problem with security_file_certgen!I reported this problem before with squid 4.6.When I use last security_file_certgen binary file that created with compiled files of squid 4.6-VCS or squid 4.6, I can not open HTTPS site and squid restart over and over with error below!
When i use security_file_certgen binary file from squid4.3 that I compiled before and create my new .deb package of squid 4.6-VCS compiled files with security_file_certgen binary, problem solved.
I dont know why?Do you know how can I solve this problem?

My cach.log:2019/05/05 12:50:07| Removing PID file (/var/run/squid.pid)
2019/05/05 12:50:07| Created PID file (/var/run/squid.pid)
2019/05/05 12:50:07| Current Directory is /
2019/05/05 12:50:07| Starting Squid Cache version 4.6-VCS for x86_64-unknown-linux-gnu...
2019/05/05 12:50:07| Service Name: squid
2019/05/05 12:50:07| Process ID 7839
2019/05/05 12:50:07| Process Roles: master worker
2019/05/05 12:50:07| With 65536 file descriptors available
2019/05/05 12:50:07| Initializing IP Cache...
2019/05/05 12:50:07| DNS Socket created at [::], FD 3
2019/05/05 12:50:07| DNS Socket created at 0.0.0.0, FD 11
2019/05/05 12:50:07| Adding nameserver 8.8.8.8 from /etc/resolv.conf
2019/05/05 12:50:07| helperOpenServers: Starting 5/10 'security_file_certgen' processes
2019/05/05 12:50:07| Logfile: opening log udp://127.0.0.1:12188
2019/05/05 12:50:07| Store logging disabled
2019/05/05 12:50:07| Swap maxSize 0 + 0 KB, estimated 0 objects
2019/05/05 12:50:07| Target number of buckets: 0
2019/05/05 12:50:07| Using 8192 Store buckets
2019/05/05 12:50:07| Max Mem? size: 0 KB
2019/05/05 12:50:07| Max Swap size: 0 KB
2019/05/05 12:50:07| Using Least Load store dir selection
2019/05/05 12:50:07| Current Directory is /
2019/05/05 12:50:07| Finished loading MIME types and icons.
2019/05/05 12:50:07| HTCP Disabled.
2019/05/05 12:50:07| Squid plugin modules loaded: 0
2019/05/05 12:50:07| Adaptation support is off.
2019/05/05 12:50:07| Accepting HTTP Socket connections at local=0.0.0.0:3128 remote=[::] FD 23 flags=9
2019/05/05 12:50:07| Accepting TPROXY intercepted HTTP Socket connections at local=0.0.0.0:3129 remote=[::] FD 24 flags=25
2019/05/05 12:50:07| Accepting TPROXY intercepted SSL bumped HTTPS Socket connections at local=[::]:3130 remote=[::] FD 25 flags=25
2019/05/05 12:50:08| WARNING: /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB #Hlpr1 exited
2019/05/05 12:50:08| Too few /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB processes are running (need 1/10)
2019/05/05 12:50:08| Closing HTTP(S) port 0.0.0.0:3128
2019/05/05 12:50:08| Closing HTTP(S) port 0.0.0.0:3129
2019/05/05 12:50:08| Closing HTTP(S) port [::]:3130
2019/05/05 12:50:08| storeDirWriteCleanLogs: Starting...
2019/05/05 12:50:08|?? Finished.? Wrote 0 entries.
2019/05/05 12:50:08|?? Took 0.00 seconds (? 0.00 entries/sec).
2019/05/05 12:50:08| FATAL: The /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB helpers are crashing too rapidly, need help!

2019/05/05 12:50:08| Squid Cache (Version 4.6-VCS): Terminated abnormally.
CPU Usage: 0.086 seconds = 0.067 user + 0.019 sys
Maximum Resident Size: 113648 KB
Page faults with physical i/o: 0
2019/05/05 12:50:08| Removing PID file (/var/run/squid.pid)
squid -v:root at debian:~# squid -v
Squid Cache: Version 4.6-VCS
Service Name: squid

This binary uses OpenSSL 1.0.1t? 3 May 2016. For legal restrictions on distribution see https://www.openssl.org/source/license.html

configure options:? '--with-openssl' '--enable-ssl-crtd' '--prefix=/usr' '--enable-linux-netfilter' '--with-netfilter-conntrack' '--exec-prefix=/usr' '--includedir=/usr/include' '--datadir=/usr/share/squid' '--libdir=/usr/lib64' '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' '--sysconfdir=/etc/squid/' '--sharedstatedir=/var/lib/' '--with-logdir=/var/log/squid/' '--enable-ltdl-convenience' '--enable-http-violations'


Thank you.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190505/b70b57ae/attachment.htm>

From squid3 at treenet.co.nz  Mon May  6 07:20:18 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 6 May 2019 19:20:18 +1200
Subject: [squid-users] security_file_certgen problem
In-Reply-To: <648194123.1521534.1557047398356@mail.yahoo.com>
References: <648194123.1521534.1557047398356.ref@mail.yahoo.com>
 <648194123.1521534.1557047398356@mail.yahoo.com>
Message-ID: <31c93d8c-98b7-7c66-2db8-34eedc7b5dd5@treenet.co.nz>

Does your system happen to have an /etc/apparmour.d/usr.sbin.squid file?

Amos


From leomessi983 at yahoo.com  Mon May  6 13:29:05 2019
From: leomessi983 at yahoo.com (leomessi983 at yahoo.com)
Date: Mon, 6 May 2019 13:29:05 +0000 (UTC)
Subject: [squid-users] security_file_certgen problem
References: <1331390629.1922226.1557149345580.ref@mail.yahoo.com>
Message-ID: <1331390629.1922226.1557149345580@mail.yahoo.com>

Hi again;No my system does not have that file!


Leo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190506/67883c24/attachment.htm>

From dacvinh0993 at gmail.com  Mon May  6 16:19:09 2019
From: dacvinh0993 at gmail.com (TRAN DAC)
Date: Mon, 6 May 2019 18:19:09 +0200
Subject: [squid-users] Secure ICAP
Message-ID: <CAFUC1xe7b0kQs+UVic1s1H9iib5edD=m-=pnAquKOR-gPq4qQA@mail.gmail.com>

Hello,

I am trying to secure ICAP connections between my Squid proxy and my ICAP
Server. On my ICAP Server, i use stunnel with this configuration file (with
self signed certificate):

*cert = crt.pem*
*key= key.pem*
*CAfile=crt.pem*

*[icaps]*

*accept = 10.2.2.236:11344 <http://10.2.2.236:11344/>*
*connect = 10.2.2.236:1344 <http://10.2.2.236:1344/>*


squid.conf file on the proxy Squid:

*icap_enable on*
*icap_send_client_ip on*
*icap_service service_req reqmod_precache icaps://10.2.2.236:11344/request
<http://10.2.2.236:11344/request> tls-cafile=crt.pem*
*adaptation_access service_req allow all*

*//to decrypt ssl traffic*
*http_port 3128 ssl-bump cert=/usr/local/squid/etc/ssl_cert/myCA.pem
generate-host-certificates=on
dynamic_cert_mem_cache_size=4MBsslcrtd_program
/usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/var/logs/ssl_db -M 4MBssl_bump bump allssl_bump peek step1*

However i have still these errors:

 *WARNING: Squid got an invalid ICAP OPTIONS response from service
icaps://10.2.2.236:11344/request <http://10.2.2.236:11344/request>; error:
unsupported status code of OPTIONS response*
*2019/05/06 17:50:27 kid1| essential ICAP service is down after an options
fetch failure: icaps://10.2.2.236:11344/request
<http://10.2.2.236:11344/request> [down,!valid]*
*2019/05/06 17:53:28 kid1| WARNING: Squid got an invalid ICAP OPTIONS
response from service icaps://10.2.2.236:11344/request
<http://10.2.2.236:11344/request>; error: unsupported status code of
OPTIONS response*
*2019/05/06 17:56:28 kid1| WARNING: Squid got an invalid ICAP OPTIONS
response from service icaps://10.2.2.236:11344/request
<http://10.2.2.236:11344/request>; error: unsupported status code of
OPTIONS response*

And from the ICAP server stunnel logs the ssl initiation worked fine but it
can't connect to the port1344I ensure that non secure ICAP works perfectly
and my iptables rules are fine.

Thanks in advance for your help.

Kind regards,
Tran Dac.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190506/df005f10/attachment.htm>

From rousskov at measurement-factory.com  Mon May  6 23:52:17 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 6 May 2019 17:52:17 -0600
Subject: [squid-users] Secure ICAP
In-Reply-To: <CAFUC1xe7b0kQs+UVic1s1H9iib5edD=m-=pnAquKOR-gPq4qQA@mail.gmail.com>
References: <CAFUC1xe7b0kQs+UVic1s1H9iib5edD=m-=pnAquKOR-gPq4qQA@mail.gmail.com>
Message-ID: <c0a9a520-54a4-427e-6fbb-21da8d7227ac@measurement-factory.com>

On 5/6/19 10:19 AM, TRAN DAC wrote:
> accept =?10.2.2.236:11344
> connect =?10.2.2.236:1344

> WARNING: Squid got an invalid ICAP OPTIONS response from service
> icaps://10.2.2.236:11344/request;
> error: unsupported status code of OPTIONS response

> 2019/05/06 17:50:27 kid1| essential ICAP service is down after an
> options fetch failure: icaps://10.2.2.236:11344/request ?[down,!valid]/

> And from the ICAP server stunnel logs the ssl initiation worked fine but
> it can't connect?to the port 1344

Why not? In other words, what prevents your stunnel from connecting to
your ICAP server? That problem seems to be unrelated to Squid or even
secure ICAP.

Alex.


From gaardiolor at gmail.com  Tue May  7 15:37:18 2019
From: gaardiolor at gmail.com (Marc)
Date: Tue, 7 May 2019 17:37:18 +0200
Subject: [squid-users] ephemeral port selection
Message-ID: <CAPxJK5CbBchR1awUioXJq7wUxeCOk63h_wrh4-7AVyEs7KKcvg@mail.gmail.com>

Dear all,

We're considering running squid for thousands of users. Squid will use
a single parent proxy IP address. A lot of connections will go from
the Child squid to the Parent proxy. Often, the Parent proxy initiates
closing the TCP connecting by sending the first FIN. This results the
connection going to TIME_WAIT at the Parent proxy, but not at the
Child squid proxy, as per RFC. This means, from the perspective of the
Child squid proxy, it's perfectly legal to re-use the same sourceport
immediately. Or, at least, before the TIME_WAIT of the Parent Proxy
(and the Firewalls in between) expires.

This will result in timeouts / slowness. Not very often, since we can
configure an ephemeral port range 1025-65535 = 64511 available ports,
but it does happen occasionaly considering the large amount of
connections we have from the Child squid proxy to the Parent proxy.

This is not a theoretical exercise, we have seen this in the past.
Currently, using other proxy servers, we overcome this issue by
disabling TCP Ephemeral Port Randomization. This mitigates this issue
entirely, since not all 64511 ports are used within the TIME_WAIT
timeout. Security impact is low since it's local traffic.

I think squid relies on the OS to select the ephemeral source port,
and in linux I can see no way to disable this. Is it possible to
disable ephemeral port randomization within squid ? If it is
impossible, can this be considered as a new feature ?

Thanks!


From rousskov at measurement-factory.com  Tue May  7 16:34:14 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 7 May 2019 10:34:14 -0600
Subject: [squid-users] ephemeral port selection
In-Reply-To: <CAPxJK5CbBchR1awUioXJq7wUxeCOk63h_wrh4-7AVyEs7KKcvg@mail.gmail.com>
References: <CAPxJK5CbBchR1awUioXJq7wUxeCOk63h_wrh4-7AVyEs7KKcvg@mail.gmail.com>
Message-ID: <153e701b-31f7-c255-a107-a4db9594266c@measurement-factory.com>

On 5/7/19 9:37 AM, Marc wrote:

> I think squid relies on the OS to select the ephemeral source port,

Correct.


> Is it possible to disable ephemeral port randomization within squid?

Not yet.


> If it is impossible, can this be considered as a new feature ?

Yes, it is a valid feature request, and I have seen similar requests in
the past. The default ephemeral port management on Linux (and probably
other OSes) does not satisfy the needs of some busy proxies. Moreover,
we have implemented an explicit source port manager algorithm in Web
Polygraph, for similar high-performance reasons, so we know how to do it
and that it actually works/helps.

https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F


Alex.


From lukasycas at gmail.com  Tue May  7 20:41:14 2019
From: lukasycas at gmail.com (=?UTF-8?Q?Lukas_Y=C4=8Das?=)
Date: Tue, 7 May 2019 23:41:14 +0300
Subject: [squid-users] Squid File Upload Blocking
Message-ID: <CAJNHcRPpaXo+FCjaiPRuY3F53T6pi87gKWNNNhs5zQ5A83rXhw@mail.gmail.com>

Hello,

I am currently attempting to block File Upload with squid -

squid.conf:
acl filesblock2 req_mime_type
"/usr/local/squid/etc/blocked_up_extensions.acl"
http_access deny filesblock2

blocked_up_extensions.acl:
application/msword
application/vnd.openxmlformats-officedocument.wordprocessingml.document

With these settings applied I'm still able to upload .doc / .docx files for
example via this website:
https://uploadfiles.io/

Am I missing something? How can I make it work?

P.S. I somehow do not receive replies via this mailing list, I can only
read the daily digest, if you could add my email to CC while replying I
would be very glad.

Regards,
Lukas
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190507/5cc820b1/attachment.htm>

From info at schroeffu.ch  Tue May  7 22:45:36 2019
From: info at schroeffu.ch (info at schroeffu.ch)
Date: Tue, 07 May 2019 22:45:36 +0000
Subject: [squid-users] Squid File Upload Blocking
In-Reply-To: <CAJNHcRPpaXo+FCjaiPRuY3F53T6pi87gKWNNNhs5zQ5A83rXhw@mail.gmail.com>
References: <CAJNHcRPpaXo+FCjaiPRuY3F53T6pi87gKWNNNhs5zQ5A83rXhw@mail.gmail.com>
Message-ID: <6a18482e627c4ff486dc2b02d6e6913e@schroeffu.ch>

Hi Lukas

for my understanding you have to decrypt the SSL connection with SSL bump, otherwise Squid is unable to read what mime type is going through the ssl tunneled connection.

lot regards
schroeffu

7. Mai 2019 22:41, "Lukas Y?as" <lukasycas at gmail.com (mailto:lukasycas at gmail.com?to=%22Lukas%20Y%C4%8Das%22%20<lukasycas at gmail.com>)> schrieb:
Hello,
I am currently attempting to block File Upload with squid -

squid.conf:
acl filesblock2 req_mime_type "/usr/local/squid/etc/blocked_up_extensions.acl" 
http_access deny filesblock2

blocked_up_extensions.acl:
application/msword 
application/vnd.openxmlformats-officedocument.wordprocessingml.document 
With these settings applied I'm still able to upload .doc / .docx files for example via this website:
https://uploadfiles.io/ (https://uploadfiles.io/)

Am I missing something? How can I make it work?

P.S. I somehow do not receive replies via this mailing list, I can only read the daily digest, if you could add my email to CC while replying I would be very glad.

Regards, 
Lukas
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190507/b632dcaa/attachment.htm>

From guzzy at bol.com.br  Tue May  7 23:03:24 2019
From: guzzy at bol.com.br (Fabricio Ferreira)
Date: Tue, 7 May 2019 20:03:24 -0300
Subject: [squid-users] Squid File Upload Blocking
In-Reply-To: <6a18482e627c4ff486dc2b02d6e6913e@schroeffu.ch>
References: <CAJNHcRPpaXo+FCjaiPRuY3F53T6pi87gKWNNNhs5zQ5A83rXhw@mail.gmail.com>
 <6a18482e627c4ff486dc2b02d6e6913e@schroeffu.ch>
Message-ID: <001101d50529$13edd790$3bc986b0$@bol.com.br>

Hello Lukas,

For sure Schroeffu is right. Without the SSL Interception (a.k.a. MITM ? Man in the middle) squid can?t filter any HTTPS request as it doesn?t know what you have inside the SSL tunnel.

 

 

 

 

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of info at schroeffu.ch
Sent: Tuesday, May 7, 2019 7:46 PM
To: Lukas Y?as <lukasycas at gmail.com>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid File Upload Blocking

 

Hi Lukas

for my understanding you have to decrypt the SSL connection with SSL bump, otherwise Squid is unable to read what mime type is going through the ssl tunneled connection.

lot regards
schroeffu

7. Mai 2019 22:41, "Lukas Y?as" <lukasycas at gmail.com <mailto:lukasycas at gmail.com?to=%22Lukas%20Y%C4%8Das%22%20%3clukasycas at gmail.com%3e> > schrieb:

Hello,

I am currently attempting to block File Upload with squid -

squid.conf:

acl filesblock2 req_mime_type "/usr/local/squid/etc/blocked_up_extensions.acl"

http_access deny filesblock2

blocked_up_extensions.acl:

application/msword

application/vnd.openxmlformats-officedocument.wordprocessingml.document

With these settings applied I'm still able to upload .doc / .docx files for example via this website:
https://uploadfiles.io/

Am I missing something? How can I make it work?

P.S. I somehow do not receive replies via this mailing list, I can only read the daily digest, if you could add my email to CC while replying I would be very glad.

Regards,

Lukas






-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190507/847f684a/attachment.htm>

From squid3 at treenet.co.nz  Wed May  8 01:50:41 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 8 May 2019 13:50:41 +1200
Subject: [squid-users] Squid File Upload Blocking
In-Reply-To: <001101d50529$13edd790$3bc986b0$@bol.com.br>
References: <CAJNHcRPpaXo+FCjaiPRuY3F53T6pi87gKWNNNhs5zQ5A83rXhw@mail.gmail.com>
 <6a18482e627c4ff486dc2b02d6e6913e@schroeffu.ch>
 <001101d50529$13edd790$3bc986b0$@bol.com.br>
Message-ID: <d2b39015-a2a6-ea07-cea4-60bcc7aeefac@treenet.co.nz>

On 8/05/19 11:03 am, Fabricio Ferreira wrote:
> Hello Lukas,
> 
> For sure Schroeffu is right. Without the SSL Interception (a.k.a. MITM ?
> Man in the middle) squid can?t filter any HTTPS request as it doesn?t
> know what you have inside the SSL tunnel.
> 
> ?

Also, in case the problem remains after SSL-Bump is done - the mime type
may not be set properly by the software doing the upload. Website upload
forms used to be particularly bad for that, but YMMV these days.

So you will want to set "debug_options 11,2" at the proxy for testing an
upload. The cache.log will then log a copy of the HTTP PUT/POST message
headers to see what mime types are actually happening and adjust your
blacklist appropriately.

HTH
Amos


From gaardiolor at gmail.com  Wed May  8 19:26:57 2019
From: gaardiolor at gmail.com (Marc)
Date: Wed, 8 May 2019 21:26:57 +0200
Subject: [squid-users] ephemeral port selection
In-Reply-To: <153e701b-31f7-c255-a107-a4db9594266c@measurement-factory.com>
References: <CAPxJK5CbBchR1awUioXJq7wUxeCOk63h_wrh4-7AVyEs7KKcvg@mail.gmail.com>
 <153e701b-31f7-c255-a107-a4db9594266c@measurement-factory.com>
Message-ID: <CAPxJK5ATE=Lu-R7Fx7_OmUknxebGfYjC+O+U6noJtfjTfai4AA@mail.gmail.com>

> Yes, it is a valid feature request, and I have seen similar requests in
> the past. The default ephemeral port management on Linux (and probably
> other OSes) does not satisfy the needs of some busy proxies. Moreover,
> we have implemented an explicit source port manager algorithm in Web
> Polygraph, for similar high-performance reasons, so we know how to do it
> and that it actually works/helps.
>
> https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F

Thanks for your reply! I will check the wiki to make a feature request.


From johnrefwe at mail.com  Fri May 10 18:18:02 2019
From: johnrefwe at mail.com (johnr)
Date: Fri, 10 May 2019 13:18:02 -0500 (CDT)
Subject: [squid-users] Squid 4 pconn_lifetime questions
Message-ID: <1557512282209-0.post@n4.nabble.com>

Hi,

The configuration directive pconn_lifetime
(http://www.squid-cache.org/Doc/config/pconn_lifetime/), seems to give the
squid admin control over whether squid closes idle connections or moves them
into the 'idle connection pool'... I am curious if in squid3, the connection
was automatically terminated after being idle or if it was automatically
moved to the idle connection pool. Given the default value for this config
(to always move to the idle connection pool), I assume the default
functionality between squid 3 and 4 is the same?

I ask because I am seeing a strange, not consistently reproducible scenario
where I navigate to an origin through squid (SSL bump), and then after some
time if I click on a link that navigates somewhere within the same domain,
the browser hangs for a bit until eventually making the navigation. On the
squid side, in the logs, I can see that there is an event in the access logs
that is "NONE error:transaction-end-before-headers HTTP/0.0" before then
seeing the browser issue a fresh CONNECT at which point everything seems to
work. 

It seems like the client is trying to use the same connection, but from the
squid side that connection is in a strange state, and so some amount of time
transpires before squid deems the connection closed. I can use this
pconn_lifetime configuration to 'fix' this problem, but I'm weary of
potentially causing some other side effects by too aggressively closing
connections? Since this doesn't reproduce in squid3, I thought I would ask
if the behavior has changed in anyway in this path..

Thank you for any help,

John



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Fri May 10 22:48:09 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 10 May 2019 16:48:09 -0600
Subject: [squid-users] Squid 4 pconn_lifetime questions
In-Reply-To: <1557512282209-0.post@n4.nabble.com>
References: <1557512282209-0.post@n4.nabble.com>
Message-ID: <71d634f0-2275-5d3a-b1ba-b01cdb53b18f@measurement-factory.com>

On 5/10/19 12:18 PM, johnr wrote:

> The configuration directive pconn_lifetime
> (http://www.squid-cache.org/Doc/config/pconn_lifetime/), seems to give the
> squid admin control over whether squid closes idle connections or moves them
> into the 'idle connection pool'...

Correct. I would say "now-idle" or "connections that just became idle"
instead of just "idle connections" to clarify a little.


> I am curious if in squid3, the connection
> was automatically terminated after being idle or if it was automatically
> moved to the idle connection pool.

It was moved to the idle connection pool. Rare pipelining cases aside,
if all connections are terminated just after they become idle, there
would be no connection reuse -- there would never be a connection in the
pool that can be reused.

In this context, pipelining aside, "became idle" simply means "done
processing the previous request".


> Given the default value for this config
> (to always move to the idle connection pool), I assume the default
> functionality between squid 3 and 4 is the same?

Correct.


> I ask because I am seeing a strange, not consistently reproducible scenario
> where I navigate to an origin through squid (SSL bump), and then after some
> time if I click on a link that navigates somewhere within the same domain,
> the browser hangs for a bit until eventually making the navigation. On the
> squid side, in the logs, I can see that there is an event in the access logs
> that is "NONE error:transaction-end-before-headers HTTP/0.0" before then
> seeing the browser issue a fresh CONNECT at which point everything seems to
> work. 

I believe error:transaction-end-before-headers can only happen for brand
new connections, not [idle] persistent ones. The same closure event
would not make sense to report as an error for an idle persistent
connection -- idle connection closures are normal benign
protocol-prescribed events, not errors or potentially abusive client
behavior.


HTH,

Alex.


From schroedh at gmail.com  Mon May 13 11:54:12 2019
From: schroedh at gmail.com (Henning Schroeder)
Date: Mon, 13 May 2019 13:54:12 +0200
Subject: [squid-users] Using access_log directive to filter based on src IP
	or regex
Message-ID: <CAALcTeH-ORim4696gnA+-8CX8XGGKHapsydo-5g9TU74ngAJmA@mail.gmail.com>

Hi there,

I'm hosting two squid servers (Version 4.6) on CentOS in Azure, which are
placed behing an Azure load balancer.

The LB has a health probe which constantly polls the squid servers on port
3128.

In the access.log, I can find a whole lot of entries like:

1557738944.935      0 168.63.129.16 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- -

Basically, the log gets flooded with this every few seconds. The source IP
168.63.129.16 is a platform IP of the Azure software-defined network, in
this case it is the source of the LB health probe.

I tried to filter these log entries by using the access_log directive. E.g.:

Option 1)
acl azurelb src 168.63.129.16/32
access_log none azurelb
access_log daemon:/var/log/squid/access.log squid

Option 2)  (read about a bug in an older 3.x version, which can be worked
around by using this)
acl azurelb src 168.63.129.16/32
access_log daemon:/var/log/squid/access.log squid !azurelb

Option 3)
acl azurelbprobe url_regex ^error:transaction-end-before-headers
access_log none azurelbprobe
access_log daemon:/var/log/squid/access.log squid

None of this worked. I still get the same entries in access.log.
Any suggestion or hint will be appreciated.

Thanks & regards
Henning
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190513/b60729a6/attachment.htm>

From rousskov at measurement-factory.com  Mon May 13 14:51:33 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 13 May 2019 08:51:33 -0600
Subject: [squid-users] Using access_log directive to filter based on src
 IP or regex
In-Reply-To: <CAALcTeH-ORim4696gnA+-8CX8XGGKHapsydo-5g9TU74ngAJmA@mail.gmail.com>
References: <CAALcTeH-ORim4696gnA+-8CX8XGGKHapsydo-5g9TU74ngAJmA@mail.gmail.com>
Message-ID: <4c8a0d71-666c-4d38-107c-28117190649f@measurement-factory.com>

On 5/13/19 5:54 AM, Henning Schroeder wrote:
> I'm hosting two squid servers (Version 4.6) on CentOS in Azure, which
> are placed behing an Azure load balancer.?
> 
> The LB has a health probe which constantly polls the squid servers on
> port 3128.
> 
> In the access.log, I can find a whole lot of entries like:
> 
> 1557738944.935? ? ? 0 168.63.129.16 NONE/000 0 NONE error:transaction-end-before-headers - HIER_NONE/- -

> I tried to filter these log entries by using the access_log directive

> acl azurelb src 168.63.129.16/32

Please see https://bugs.squid-cache.org/show_bug.cgi?id=4906

If you want to test experimental unofficial v5-based code fixing the
problem, ask for a git branch link there. Otherwise, wait for the
official fix.

You may also be interested in the discussion at
https://bugs.squid-cache.org/show_bug.cgi?id=4944 because it might
contain a usable workaround.


> acl azurelbprobe url_regex ^error:transaction-end-before-headers

This may be the same or a different bug. I recommend asking that
question by adding a comment to bug #4906: If the fix Eduard is
currently working on does _not_ address url_regex matching, then a new
bug report may be warranted.


HTH,

Alex.


From gkjoshi at gmail.com  Mon May 13 15:49:05 2019
From: gkjoshi at gmail.com (gkjo)
Date: Mon, 13 May 2019 10:49:05 -0500 (CDT)
Subject: [squid-users] Host Header Forgery issue even after applying patch
Message-ID: <1557762545990-0.post@n4.nabble.com>

Hi There 

I have installed Squid 3.5-20 in transparent mode (using WCCP ) and facing
lots of false 

positive for SSL sites (Host header forgery detected ), we are using just
Peak and slice and 

not actually bump-ing the traffic . 

2019/05/08 23:51:05 kid1| SECURITY ALERT: on URL: outlook.office365.com:443
2019/05/08 23:51:05 kid1| SECURITY ALERT: Host header forgery detected on
local=40.100.2.98:443 

remote=10.1.1.3:58714 FD 36 flags=33 (local IP does not match any domain IP)

2019/05/08 23:51:05 kid1| SECURITY ALERT: on URL: outlook.office365.com:443
2019/05/08 23:51:16 kid1| SECURITY ALERT: Host header forgery detected on
local=52.98.77.98:443 

remote=10.1.1.3:58717 FD 60 flags=33 (local IP does not match any domain IP)


I did apply the patch (
https://github.com/NethServer/squid/blob/c7/SOURCES/squid-3.5.20-ssl-

forgery.patch) while compile the squid but still getting  same error . is
there anyway to 

verify that "HostHeaderForgery" is disabled and patch is applied correctly ? 

Or is there any other alternative to resolve this issue (not with explicit
proxy). I have verified client and squid have same DNS . 

Regards
Gjoshi



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From johnrefwe at mail.com  Tue May 14 06:25:02 2019
From: johnrefwe at mail.com (johnr)
Date: Tue, 14 May 2019 01:25:02 -0500 (CDT)
Subject: [squid-users] Squid 4 pconn_lifetime questions
In-Reply-To: <71d634f0-2275-5d3a-b1ba-b01cdb53b18f@measurement-factory.com>
References: <1557512282209-0.post@n4.nabble.com>
 <71d634f0-2275-5d3a-b1ba-b01cdb53b18f@measurement-factory.com>
Message-ID: <1557815102007-0.post@n4.nabble.com>

Alex - thank you for the reply.

If in the context of this directive became idle means "done processing the
previous request" then how is the pconn_lifetime directive different than
the client_idle_pconn_timeout and server_idle_pconn_timeout (other than
affecting both at the same time)? If my question doesn't make sense, then
perhaps what I'm asking is better stated as: how do the pconn_lifetime and
client_idle_pconn_timeout interact?

Thank you for your help,

John



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Tue May 14 11:42:25 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 14 May 2019 23:42:25 +1200
Subject: [squid-users] Squid 4 pconn_lifetime questions
In-Reply-To: <1557815102007-0.post@n4.nabble.com>
References: <1557512282209-0.post@n4.nabble.com>
 <71d634f0-2275-5d3a-b1ba-b01cdb53b18f@measurement-factory.com>
 <1557815102007-0.post@n4.nabble.com>
Message-ID: <6009a0c2-db74-239a-73f1-b54dd3870f1b@treenet.co.nz>

On 14/05/19 6:25 pm, johnr wrote:
> Alex - thank you for the reply.
> 
> If in the context of this directive became idle means "done processing the
> previous request" then how is the pconn_lifetime directive different than
> the client_idle_pconn_timeout and server_idle_pconn_timeout (other than
> affecting both at the same time)?


Lifetime is essentially TCP level timeout. TCP connections which go past
it will be closed, the HTTP keep-alive / persistence mechanism will no
longer keep the connection alive. Squid should negotiate for "close" on
any pending HTTP transactions.


The *_idle_pconn_timeout directives (both server and client) manage the
maximum allowed time between completing one HTTP transaction and
starting the next. Connections which go past this timeout should be
closed as soon as doing so is possible without breaking any existing
transactions.


There is an obvious edge case for very long duration transactions. Where
Squid may negotiate keep-alive when it starts, but the lifetime limit is
reached before it completes. I believe those connections should just
close at that completion point despite the negotiated keep-alive.

Amos


From rousskov at measurement-factory.com  Tue May 14 14:07:58 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 14 May 2019 08:07:58 -0600
Subject: [squid-users] Squid 4 pconn_lifetime questions
In-Reply-To: <1557815102007-0.post@n4.nabble.com>
References: <1557512282209-0.post@n4.nabble.com>
 <71d634f0-2275-5d3a-b1ba-b01cdb53b18f@measurement-factory.com>
 <1557815102007-0.post@n4.nabble.com>
Message-ID: <7bd72310-52b8-3bd7-b601-9a60f39f9a7f@measurement-factory.com>

On 5/14/19 12:25 AM, johnr wrote:

> If in the context of this directive became idle means "done processing the
> previous request" then how is the pconn_lifetime directive different than
> the client_idle_pconn_timeout and server_idle_pconn_timeout (other than
> affecting both at the same time)?

The former directive limits the lifetime of a connection. The latter
directives limit the time a connection can stay in the idle pool.

In other words, the clock for the first directive starts ticking when
the connection is created while the clock for the other two directives
starts ticking when the connection is placed in the idle connection pool.


> If my question doesn't make sense, then
> perhaps what I'm asking is better stated as: how do the pconn_lifetime and
> client_idle_pconn_timeout interact?

There should be virtually no interaction: The former limit is checked
just when a connection becomes idle and Squid decides whether to pool
the connection or close it. The latter timeout is checked for the
already pooled connections.

GitHub pull requests clarifying documentation are welcomed.

Alex.


From rousskov at measurement-factory.com  Tue May 14 14:15:20 2019
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 14 May 2019 08:15:20 -0600
Subject: [squid-users] Squid 4 pconn_lifetime questions
In-Reply-To: <7bd72310-52b8-3bd7-b601-9a60f39f9a7f@measurement-factory.com>
References: <1557512282209-0.post@n4.nabble.com>
 <71d634f0-2275-5d3a-b1ba-b01cdb53b18f@measurement-factory.com>
 <1557815102007-0.post@n4.nabble.com>
 <7bd72310-52b8-3bd7-b601-9a60f39f9a7f@measurement-factory.com>
Message-ID: <65ce0622-c91e-d006-c1cd-a89ab55dabfe@measurement-factory.com>

On 5/14/19 8:07 AM, Alex Rousskov wrote:
> On 5/14/19 12:25 AM, johnr wrote:
>> how do the pconn_lifetime and client_idle_pconn_timeout interact?

> There should be virtually no interaction: The former limit is checked
> just when a connection becomes idle and Squid decides whether to pool
> the connection or close it. The latter timeout is checked for the
> already pooled connections.

Correction: The time an idle connection can be pooled is limited by both
pconn_lifetime and *_idle_pconn_timeout. This may be considered as
"interaction".

  lifetime_remaining = pconn_lifetime - actual_connection_lifetime
  maximum_time_in_pool = min(lifetime_remaining, x_idle_pconn_timeout)

Pooled idle connections are closed after maximum_time_in_pool.

Alex.

> GitHub pull requests clarifying documentation are welcomed.


From augustus_meyer at gmx.net  Tue May 14 20:13:40 2019
From: augustus_meyer at gmx.net (reinerotto)
Date: Tue, 14 May 2019 15:13:40 -0500 (CDT)
Subject: [squid-users] Host Header Forgery issue even after applying
	patch
In-Reply-To: <1557762545990-0.post@n4.nabble.com>
References: <1557762545990-0.post@n4.nabble.com>
Message-ID: <1557864820716-0.post@n4.nabble.com>

To get rid off the messages, on my 4.x, this squid.conf-option works for me:
debug_options ALL,0




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From jmperrote at policia.rionegro.gov.ar  Wed May 15 00:09:06 2019
From: jmperrote at policia.rionegro.gov.ar (jmperrote)
Date: Tue, 14 May 2019 21:09:06 -0300
Subject: [squid-users] help with reverse proxy sending user to peer
Message-ID: <ce6a44556b1f9fde95f10561754c7dfb@policia.rionegro.gov.ar>

hello I need a help to know it is posible with squid to pass the 
username autenticated on reverse proxy to the peer ?

I have a reverse proxy, with external autentification type on ldap 
repository, once the user is validated on reverse
proxy and redirect to the peer, I need to send the username, o something 
that permit to the webserver server (peer) know
the username that was autenticated on squid.

The idea is that the webserver aplication can catch like POST method or 
similar the username logued and autenticated on reverse proxy-

regards-



From squid3 at treenet.co.nz  Wed May 15 13:50:43 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 16 May 2019 01:50:43 +1200
Subject: [squid-users] help with reverse proxy sending user to peer
In-Reply-To: <ce6a44556b1f9fde95f10561754c7dfb@policia.rionegro.gov.ar>
References: <ce6a44556b1f9fde95f10561754c7dfb@policia.rionegro.gov.ar>
Message-ID: <bf905417-540e-1f51-d804-0cdcbbf62fa8@treenet.co.nz>

On 15/05/19 12:09 pm, jmperrote wrote:
> hello I need a help to know it is posible with squid to pass the
> username autenticated on reverse proxy to the peer ?
> 

Firstly, please be aware that the username you may see in proxy logs is
not required to be authenticated. In modern Squid it just has to be sent.


> 
> The idea is that the webserver aplication can catch like POST method or
> similar the username logued and autenticated on reverse proxy-
> 

You can use the request_header_add directive to add custom headers with
any information Squid has at the time those headers are generated for
delivery to the upstream peer/server.
  <http://www.squid-cache.org/Doc/config/request_header_add/>

But ... which username?

"
    ul	User name from authentication
    ue	User name from external acl helper
    ui	User name from ident
    un	A user name. Expands to the first available name
	from the following list of information sources:
	- authenticated user name, like %ul
	- user name supplied by an external ACL, like %ue
	- SSL client name, like %us
	- ident user name, like %ui

  credentials   Client credentials. The exact meaning depends on
		the authentication scheme: For Basic authentication,
		it is the password; for Digest, the realm sent by the
		client; for NTLM and Negotiate, the client challenge
		or client credentials prefixed with "YR " or "KK ".
"


Amos


From rafaelsilvadaniel at gmail.com  Wed May 15 17:45:22 2019
From: rafaelsilvadaniel at gmail.com (Rafael Silva Daniel)
Date: Wed, 15 May 2019 12:45:22 -0500 (CDT)
Subject: [squid-users] Squid V 3.5.23 authenticating in AD: User names not
	showing in log
Message-ID: <1557942322957-0.post@n4.nabble.com>

Helo! im in need of serious help, in my company we need the access logs by
user name, is the only reason the proxy is setted to authenticate. but it
just dont show it, the relevant parts of the .conf is looking like this:

(...)
auth_param ntlm program /usr/bin/ntlm_auth --diagnostics
--helper-protocol=squid-2.5-ntlmssp --domain=XXXXX(domain name)
auth_param ntlm children 100
auth_param ntlm keep_alive off

external_acl_type NT_global_group %LOGIN /usr/lib/squid/ext_wbinfo_group_acl
acl users external NT_global_group "/etc/squid/fapgrp"
(...)

(...)
http_access deny !users
http_access allow users
http_access deny !auth
(...)

***("/etc/squid/fapgrp" is a text file with the text "Usu?rios do d?minio",
its "Domain Users" in portuguese)

when i test the helper:

/usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp
--domain=XXXXX
user password
BH SPNEGO request invalid prefix

i read somewhere that ntlmssp can be tested like this, because we are
sending the credentials as plain text, so i tested with basic and the result
is this:

/usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-basic
--domain=XXXXX
user password
OK
user password
ERR

so, im assuming that the way squid is processing the challenges are fine, is
it right?

but the part that is making me furious is that the access.log are like this:

1557939698.081    218 10.85.xx.xx TCP_MISS/200 1962 GET
http://squid-web-proxy-cache.1019090.n4.nabble.com/util/minmax.js *USERNAME*
HIER_DIRECT/199.38.86.66 application/x-javascript
1557939698.313    231 10.85.xx.xx TCP_MISS/200 1073 GET
http://squid-web-proxy-cache.1019090.n4.nabble.com/images/image.png
*USERNAME* HIER_DIRECT/199.38.86.66 image/png
1557939698.360    263 10.85.xx.xx TCP_MISS/200 738 GET
http://squid-web-proxy-cache.1019090.n4.nabble.com/images/bold.png
*USERNAME* HIER_DIRECT/199.38.86.66 image/png

when the id is TCP_MISS the user name always shows correctly, but when the
id is:

1557941156.213 240238 10.85.XX.XX TCP_TUNNEL/200 1788 CONNECT
www.google.com:443 - HIER_DIRECT/172.217.29.228 -
1557941156.670 240355 10.85.XX.XX TCP_TUNNEL/200 2892 CONNECT
s2.googleusercontent.com:443 - HIER_DIRECT/172.217.172.129 -
1557941159.712 243740 10.85.XX.XX TCP_TUNNEL/200 132341 CONNECT
www.google.com:443 - HIER_DIRECT/172.217.29.228 -

TCP_TUNNEL the user name is never showed, and the majority of the access log
have these TCP_TUNNEL stuff


theres a way to all the pages that are accessed shows the username? its our
only need, to see the user names in all the logs

Thanks in advance!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Thu May 16 09:13:14 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 16 May 2019 21:13:14 +1200
Subject: [squid-users] Squid V 3.5.23 authenticating in AD: User names
 not showing in log
In-Reply-To: <1557942322957-0.post@n4.nabble.com>
References: <1557942322957-0.post@n4.nabble.com>
Message-ID: <fe75573b-7e4b-70ed-50a4-8030522786f7@treenet.co.nz>

On 16/05/19 5:45 am, Rafael Silva Daniel wrote:
> Helo! im in need of serious help, in my company we need the access logs by
> user name, is the only reason the proxy is setted to authenticate. but it
> just dont show it, the relevant parts of the .conf is looking like this:
> 
> (...)
> auth_param ntlm program /usr/bin/ntlm_auth --diagnostics
> --helper-protocol=squid-2.5-ntlmssp --domain=XXXXX(domain name)
> auth_param ntlm children 100
> auth_param ntlm keep_alive off
> 
> external_acl_type NT_global_group %LOGIN /usr/lib/squid/ext_wbinfo_group_acl
> acl users external NT_global_group "/etc/squid/fapgrp"
> (...)
> 
> (...)
> http_access deny !users
> http_access allow users
> http_access deny !auth
> (...)
> 

There is no natural reason why those CONNECT should be exempt from
authenticating.

I usually find situations like what you describe happen where someone
has misunderstood the default security rules and "customized" them a
bit. They are finely tuned rules, so vast changes to proxy behaviour
(like complete bypass of auth) can result if updates to them are not
done correctly.

Can you please show more of your http_access rules? all of them would be
best. At minimum all of the ones above that "http_access deny !auth"
line, and the definition lines for any ACLs used in those rules (include
that "auth" ACL definition too please).



> ***("/etc/squid/fapgrp" is a text file with the text "Usu?rios do d?minio",
> its "Domain Users" in portuguese)
> 
> when i test the helper:
> 
> /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp
> --domain=XXXXX
> user password
> BH SPNEGO request invalid prefix
> 
> i read somewhere that ntlmssp can be tested like this, because we are
> sending the credentials as plain text, so i tested with basic and the result
> is this:
> 
> /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-basic
> --domain=XXXXX
> user password
> OK
> user password
> ERR
> 
> so, im assuming that the way squid is processing the challenges are fine, is
> it right?

That is a test that the helper is talking to the AD service okay. It
cannot tell you whether the client and Squid are communicating the NTLM
credentials.


The NTLM protocol does not deliver passwords across the network. NTLM
uses (weak) encrypted tokens instead. All Squid does is pass the token
as-is to the helper. The helper then informs Squid what username to log
for that token (if any).
 So to test that part you need to locate a valid token and pass that to
the helper instead of username/password.

However, before you go to any trouble over that. I do not think the
helper or auth are the problem here. Something is clearly letting the
CONNECT happen without even going near the auth process.


Amos


From belle at bazuin.nl  Thu May 16 09:48:36 2019
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Thu, 16 May 2019 11:48:36 +0200
Subject: [squid-users] Squid V 3.5.23 authenticating in AD: User names
 not showing in log
In-Reply-To: <fe75573b-7e4b-70ed-50a4-8030522786f7@treenet.co.nz>
References: <1557942322957-0.post@n4.nabble.com>
Message-ID: <vmime.5cdd31f4.5261.29dda5ac16a7bf34@ms249-lin-003.rotterdam.bazuin.nl>

This is related to samba and MS disabling NTLM (smb1)
What is the samba version in question and the running OS? 

But first thing you can try is set in smb.conf 

ntlm auth = yes


Greetz, 

Louis


> -----Oorspronkelijk bericht-----
> Van: squid-users 
> [mailto:squid-users-bounces at lists.squid-cache.org] Namens 
> Amos Jeffries
> Verzonden: donderdag 16 mei 2019 11:13
> Aan: squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] Squid V 3.5.23 authenticating in 
> AD: User names not showing in log
> 
> On 16/05/19 5:45 am, Rafael Silva Daniel wrote:
> > Helo! im in need of serious help, in my company we need the 
> access logs by
> > user name, is the only reason the proxy is setted to 
> authenticate. but it
> > just dont show it, the relevant parts of the .conf is 
> looking like this:
> > 
> > (...)
> > auth_param ntlm program /usr/bin/ntlm_auth --diagnostics
> > --helper-protocol=squid-2.5-ntlmssp --domain=XXXXX(domain name)
> > auth_param ntlm children 100
> > auth_param ntlm keep_alive off
> > 
> > external_acl_type NT_global_group %LOGIN 
> /usr/lib/squid/ext_wbinfo_group_acl
> > acl users external NT_global_group "/etc/squid/fapgrp"
> > (...)
> > 
> > (...)
> > http_access deny !users
> > http_access allow users
> > http_access deny !auth
> > (...)
> > 
> 
> There is no natural reason why those CONNECT should be exempt from
> authenticating.
> 
> I usually find situations like what you describe happen where someone
> has misunderstood the default security rules and "customized" them a
> bit. They are finely tuned rules, so vast changes to proxy behaviour
> (like complete bypass of auth) can result if updates to them are not
> done correctly.
> 
> Can you please show more of your http_access rules? all of 
> them would be
> best. At minimum all of the ones above that "http_access deny !auth"
> line, and the definition lines for any ACLs used in those 
> rules (include
> that "auth" ACL definition too please).
> 
> 
> 
> > ***("/etc/squid/fapgrp" is a text file with the text 
> "Usu?rios do d?minio",
> > its "Domain Users" in portuguese)
> > 
> > when i test the helper:
> > 
> > /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp
> > --domain=XXXXX
> > user password
> > BH SPNEGO request invalid prefix
> > 
> > i read somewhere that ntlmssp can be tested like this, 
> because we are
> > sending the credentials as plain text, so i tested with 
> basic and the result
> > is this:
> > 
> > /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-basic
> > --domain=XXXXX
> > user password
> > OK
> > user password
> > ERR
> > 
> > so, im assuming that the way squid is processing the 
> challenges are fine, is
> > it right?
> 
> That is a test that the helper is talking to the AD service okay. It
> cannot tell you whether the client and Squid are 
> communicating the NTLM
> credentials.
> 
> 
> The NTLM protocol does not deliver passwords across the network. NTLM
> uses (weak) encrypted tokens instead. All Squid does is pass the token
> as-is to the helper. The helper then informs Squid what 
> username to log
> for that token (if any).
>  So to test that part you need to locate a valid token and 
> pass that to
> the helper instead of username/password.
> 
> However, before you go to any trouble over that. I do not think the
> helper or auth are the problem here. Something is clearly letting the
> CONNECT happen without even going near the auth process.
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From jmperrote at policia.rionegro.gov.ar  Thu May 16 10:28:23 2019
From: jmperrote at policia.rionegro.gov.ar (jmperrote)
Date: Thu, 16 May 2019 07:28:23 -0300
Subject: [squid-users] help with reverse proxy sending user to peer
In-Reply-To: <6da3c208-1081-f88b-a6e6-d9ddb80854ed@treenet.co.nz>
References: <ce6a44556b1f9fde95f10561754c7dfb@policia.rionegro.gov.ar>
 <bf905417-540e-1f51-d804-0cdcbbf62fa8@treenet.co.nz>
 <e3e9f759-e118-8538-9599-5265cddc716b@policia.rionegro.gov.ar>
 <6da3c208-1081-f88b-a6e6-d9ddb80854ed@treenet.co.nz>
Message-ID: <3b9b2f09-0cbb-5533-5451-97975b36efb5@policia.rionegro.gov.ar>

Thanks a lot Amos, a try to use this for testing.


Regards.


El 16/5/19 a las 06:24, Amos Jeffries escribi?:
> On 16/05/19 3:26 am, jmperrote wrote:
>> Hello Amos, we use
>>
>> --> auth_param basic program ...../.../auth.php
>>
>> for authenticate teh user to the reverse proxy.
>
> auth_param is full HTTP authentication. So the %ul code is what you need
> to use in your custom header value for username from that helper.
>
>
> The %ue is for the external_acl_type helpers output. "user name" is
> different from "username" - the single space may seem pedantic but with
> security the minor distinction can mean vast differences in risk.
>
> The label in %ue is authorized, but not guaranteed to be valid. Whereas
> %ul is authenticated and thus guaranteed valid.
>
> Amos


From jmperrote at policia.rionegro.gov.ar  Thu May 16 14:56:16 2019
From: jmperrote at policia.rionegro.gov.ar (jmperrote)
Date: Thu, 16 May 2019 11:56:16 -0300
Subject: [squid-users] help with reverse proxy sending user to peer
In-Reply-To: <3b9b2f09-0cbb-5533-5451-97975b36efb5@policia.rionegro.gov.ar>
References: <ce6a44556b1f9fde95f10561754c7dfb@policia.rionegro.gov.ar>
 <bf905417-540e-1f51-d804-0cdcbbf62fa8@treenet.co.nz>
 <e3e9f759-e118-8538-9599-5265cddc716b@policia.rionegro.gov.ar>
 <6da3c208-1081-f88b-a6e6-d9ddb80854ed@treenet.co.nz>
 <3b9b2f09-0cbb-5533-5451-97975b36efb5@policia.rionegro.gov.ar>
Message-ID: <41b851a2-f241-fb56-5e6c-f27b8138c956@policia.rionegro.gov.ar>

Hello again Amos, finally on my reverse-proxy a could deliver to the 
upstream peer/server the data (username) that I need, using the directive

request_header_add X-Remote-User "%ul"

This is the user captured from authentication (%ul? User name) and 
validated for --> auth_param basic program auth.php

My helper auth.php go to a internal ldap for validate the user and the 
helper say OK/ERR how response.

OK now I want to know it is posible to get or recover from the ldap an 
attribute for later deliver this attribute to the peer server on same 
way that I deliver on the header the username.

Regards,



El 16/5/19 a las 07:28, jmperrote escribi?:
> Thanks a lot Amos, a try to use this for testing.
>
>
> Regards.
>
>
> El 16/5/19 a las 06:24, Amos Jeffries escribi?:
>> On 16/05/19 3:26 am, jmperrote wrote:
>>> Hello Amos, we use
>>>
>>> --> auth_param basic program ...../.../auth.php
>>>
>>> for authenticate teh user to the reverse proxy.
>>
>> auth_param is full HTTP authentication. So the %ul code is what you need
>> to use in your custom header value for username from that helper.
>>
>>
>> The %ue is for the external_acl_type helpers output. "user name" is
>> different from "username" - the single space may seem pedantic but with
>> security the minor distinction can mean vast differences in risk.
>>
>> The label in %ue is authorized, but not guaranteed to be valid. Whereas
>> %ul is authenticated and thus guaranteed valid.
>>
>> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From rafaelsilvadaniel at gmail.com  Thu May 16 17:36:57 2019
From: rafaelsilvadaniel at gmail.com (Rafael Silva Daniel)
Date: Thu, 16 May 2019 12:36:57 -0500 (CDT)
Subject: [squid-users] Squid V 3.5.23 authenticating in AD: User names
 not showing in log
In-Reply-To: <fe75573b-7e4b-70ed-50a4-8030522786f7@treenet.co.nz>
References: <1557942322957-0.post@n4.nabble.com>
 <fe75573b-7e4b-70ed-50a4-8030522786f7@treenet.co.nz>
Message-ID: <1558028217554-0.post@n4.nabble.com>

"There is no natural reason why those CONNECT should be exempt from 
authenticating. 

I usually find situations like what you describe happen where someone 
has misunderstood the default security rules and "customized" them a 
bit. They are finely tuned rules, so vast changes to proxy behaviour 
(like complete bypass of auth) can result if updates to them are not 
done correctly."

This is very possible, i inherited this server and tried my best to
implement what my boss asked, but i think it exceded my knowledge of squid,
i came up with these settings searching foruns around the internet but i can
messed it up a bit D:

"Can you please show more of your http_access rules? all of them would be 
best. At minimum all of the ones above that "http_access deny !auth" 
line, and the definition lines for any ACLs used in those rules (include 
that "auth" ACL definition too please). "

suree, thanks for taking a look on it!, this is the complete file, i just
edited the ips:


http_port 3128

dns_nameservers XXXXXXX
visible_hostname proxy
cache_dir ufs /var/spool/squid 100 16 256
coredump_dir /var/spool/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
strip_query_terms off
err_html_text /usr/share/squid-langpack/pt-br/
url_rewrite_program /usr/bin/squidGuard

auth_param ntlm program /usr/bin/ntlm_auth --diagnostics
--helper-protocol=squid-2.5-ntlmssp --domain=FAPEMIG
auth_param ntlm children 100
auth_param ntlm keep_alive off

external_acl_type NT_global_group %LOGIN /usr/lib/squid/ext_wbinfo_group_acl

acl SSL_ports port 443
acl SSL_ports port 8443
acl Safe_ports port 80 # http
acl Safe_ports port 90 # metodo
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl Safe_ports port 8080 # CNPq
acl Safe_ports port 3342 #
acl CONNECT method CONNECT
acl auth proxy_auth REQUIRED

acl users external NT_global_group "/etc/squid/fapgrp"

http_access deny !Safe_ports
http_access allow CONNECT
http_access allow localhost manager
http_access deny manager
http_access allow localhost
http_access deny !users
http_access allow users
http_access deny !auth
http_access allow auth


what do you think? if theres a simpler way to get the AD users of the people
browsing i would use that too,

really thanks, Amos!




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Fri May 17 03:06:17 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 17 May 2019 15:06:17 +1200
Subject: [squid-users] Squid V 3.5.23 authenticating in AD: User names
 not showing in log
In-Reply-To: <1558028217554-0.post@n4.nabble.com>
References: <1557942322957-0.post@n4.nabble.com>
 <fe75573b-7e4b-70ed-50a4-8030522786f7@treenet.co.nz>
 <1558028217554-0.post@n4.nabble.com>
Message-ID: <b2fe1c8033353b4708d0ee90fbb6f635@treenet.co.nz>

On 2019-05-17 05:36, Rafael Silva Daniel wrote:
> 
> 
> http_port 3128
> 
> dns_nameservers XXXXXXX
> visible_hostname proxy
> cache_dir ufs /var/spool/squid 100 16 256
> coredump_dir /var/spool/squid
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> strip_query_terms off
> err_html_text /usr/share/squid-langpack/pt-br/

The above directive has not been supported since Squid-3.1. Please 
remove.

You seem to be wanting that pt-br to be your default error page 
language?

If that is correct, then use this instead:
   error_default_language pt-br


> url_rewrite_program /usr/bin/squidGuard
> 
> auth_param ntlm program /usr/bin/ntlm_auth --diagnostics
> --helper-protocol=squid-2.5-ntlmssp --domain=FAPEMIG
> auth_param ntlm children 100
> auth_param ntlm keep_alive off
> 
> external_acl_type NT_global_group %LOGIN 
> /usr/lib/squid/ext_wbinfo_group_acl
> 
> acl SSL_ports port 443
> acl SSL_ports port 8443
> acl Safe_ports port 80 # http
> acl Safe_ports port 90 # metodo
> acl Safe_ports port 21 # ftp
> acl Safe_ports port 443 # https
> acl Safe_ports port 70 # gopher
> acl Safe_ports port 210 # wais
> acl Safe_ports port 1025-65535 # unregistered ports
> acl Safe_ports port 280 # http-mgmt
> acl Safe_ports port 488 # gss-http
> acl Safe_ports port 591 # filemaker
> acl Safe_ports port 777 # multiling http
> acl Safe_ports port 8080 # CNPq
> acl Safe_ports port 3342 #

8080 and 3342 are already part of the 1024-65535 range. You can remove 
them from the above list.


> acl CONNECT method CONNECT
> acl auth proxy_auth REQUIRED
> 
> acl users external NT_global_group "/etc/squid/fapgrp"
> 
> http_access deny !Safe_ports
> http_access allow CONNECT

Here is the problem, exactly as suspected. The above line is supposed to 
be:
   http_access deny CONNECT !SSL_Ports

After this change alone you will find that HTTPS is only accessible to 
users once they login.

If you then find out some CONNECT tunnels need to go to any other ports, 
then you can add those numbers to the SSL_Ports list.
Just be careful and investigate whether that is a real need first due to 
how CONNECT lets arbitrary traffic through the proxy.


> http_access allow localhost manager
> http_access deny manager
> http_access allow localhost

NP: traffic from localhost (127.0.0.1/8 or [::1]/128 IP ranges) will not 
be logged with a username.

> http_access deny !users
> http_access allow users
> http_access deny !auth
> http_access allow auth
> 

"allow users" is redundant with "allow auth". And users test relies on 
auth having already happened.

I would reorder these few lines to be:

  http_access deny !auth
  http_access deny !users
  http_access allow auth

That removes several helper lookups from being needed. Which gives a 
small performance gain.
NTLM is still the worst cause of delays with this whole setup though.


> 
> what do you think? if theres a simpler way to get the AD users of the 
> people
> browsing i would use that too,
> 

I recommend you start looking into Kerberos authentication against AD.
While its not exactly simpler for admin, it is a huge performance boost 
and security improvement.

Microsoft also officially deprecated NTLM in 2006 and been formally 
removing support from their software since Vista.
So there is future-proofing the network security system as another gain.

Amos


From squid3 at treenet.co.nz  Fri May 17 04:28:18 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 17 May 2019 16:28:18 +1200
Subject: [squid-users] help with reverse proxy sending user to peer
In-Reply-To: <41b851a2-f241-fb56-5e6c-f27b8138c956@policia.rionegro.gov.ar>
References: <ce6a44556b1f9fde95f10561754c7dfb@policia.rionegro.gov.ar>
 <bf905417-540e-1f51-d804-0cdcbbf62fa8@treenet.co.nz>
 <e3e9f759-e118-8538-9599-5265cddc716b@policia.rionegro.gov.ar>
 <6da3c208-1081-f88b-a6e6-d9ddb80854ed@treenet.co.nz>
 <3b9b2f09-0cbb-5533-5451-97975b36efb5@policia.rionegro.gov.ar>
 <41b851a2-f241-fb56-5e6c-f27b8138c956@policia.rionegro.gov.ar>
Message-ID: <aaebc361-8ac0-ff84-eee9-08216b9654e1@treenet.co.nz>

On 17/05/19 2:56 am, jmperrote wrote:
> 
> OK now I want to know it is posible to get or recover from the ldap an
> attribute for later deliver this attribute to the peer server on same
> way that I deliver on the header the username.

See
<https://wiki.squid-cache.org/Features/AddonHelpers#Basic_Scheme>

Amos


From rafaelsilvadaniel at gmail.com  Sat May 18 00:41:57 2019
From: rafaelsilvadaniel at gmail.com (Rafael Silva Daniel)
Date: Fri, 17 May 2019 19:41:57 -0500 (CDT)
Subject: [squid-users] Squid V 3.5.23 authenticating in AD: User names
 not showing in log
In-Reply-To: <b2fe1c8033353b4708d0ee90fbb6f635@treenet.co.nz>
References: <1557942322957-0.post@n4.nabble.com>
 <fe75573b-7e4b-70ed-50a4-8030522786f7@treenet.co.nz>
 <1558028217554-0.post@n4.nabble.com>
 <b2fe1c8033353b4708d0ee90fbb6f635@treenet.co.nz>
Message-ID: <1558140117216-0.post@n4.nabble.com>

Man, thanks! spot on! when i applied your suggestion the problem was solved
immediatly, i feel very emberrased, i got that http_access structure
suggested in a forum, and worked fine, but one day a important site that
needed to be accessed through 9021 port was being denied, so i changed the
"deny CONNECT !SSL_PORTS" to "allow CONNECT", so the problem was that i was
managing a tool that i dont understand entirily, i will practice more and
read deep into it, and experiment on how to correctly change to kerberos

thanks Amos! for real!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From je at ktf.rtu.lv  Sat May 18 17:45:32 2019
From: je at ktf.rtu.lv (=?utf-8?b?SsSBbmlz?=)
Date: Sat, 18 May 2019 20:45:32 +0300
Subject: [squid-users] CFG for access using certificates
Message-ID: <20190518204532.Horde.sMk0jPL3t6wCV0_IT8vDEHx@inbox.dv.lv>

Hi!

It is clear for me how to limit access to proxy from specific IPs using ACL.
I wish to create the config for the use of proxy over ssl from any  
address. How would basic cfg look like assuming it is the only way how  
to use proxy?

Janis


From squid3 at treenet.co.nz  Sun May 19 02:53:33 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 19 May 2019 14:53:33 +1200
Subject: [squid-users] CFG for access using certificates
In-Reply-To: <20190518204532.Horde.sMk0jPL3t6wCV0_IT8vDEHx@inbox.dv.lv>
References: <20190518204532.Horde.sMk0jPL3t6wCV0_IT8vDEHx@inbox.dv.lv>
Message-ID: <78c042e4-e47b-1d13-2bf6-6686d04955cc@treenet.co.nz>

On 19/05/19 5:45 am, J?nis wrote:
> Hi!
> 
> It is clear for me how to limit access to proxy from specific IPs using
> ACL.
> I wish to create the config for the use of proxy over ssl from any
> address. How would basic cfg look like assuming it is the only way how
> to use proxy?
> 


 https_port 3127 tls-cert=/etc/squid/proxy.pem
 http_access allow all

I hope you can see that this is *not* secure in any way. Simple TLS to a
proxy only protects the in-transit bytes against spying. The proxy is an
open-proxy for any attacker to use at will, and the TLS can trivially be
MITM'd.

You still need to have security checks (http_access rules) to check
whether the client is authorized to use the proxy.

Amos


From ebedsat at gmail.com  Sun May 19 03:47:17 2019
From: ebedsat at gmail.com (Ebed)
Date: Sun, 19 May 2019 10:47:17 +0700
Subject: [squid-users] Cache cellphone
Message-ID: <CAMcTSO2Op7gxE2FYhRDXZbSBCxOz7KSwjFrpet6XR+wFSwaFUg@mail.gmail.com>

I'm trying to setup squid for my wifi which mainly for cell phones and tv
box with ssl-bump for the sake of bandwidth saving and my kids
protection. Is it posible for squid to directly inject root CA as per
request by applications? As i found hardly to setup my root ca to cellphone
apps. I had tried install using user credentiall setup but its still failed
and impossible for me to reflash the android os just to install the CA cert
into the trusted credentialls table. I had try ssl_bump option combination
with no luck, peek and bump produce alot of handshake errors. Here's my
squid.conf, just guide me to the right way.

###################################################
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
acl localnet src 172.16.0.0/12 # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines

acl SSL_ports port 443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
#http_port 3127 intercept
https_port 10.0.1.2:3127 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
dhparams=/etc/squid/ssl_cert/dhparam.pem

#############################################################
# tproxy setting
# ausearch -c 'squid' --raw | audit2allow -M my-squid
# semodule -i my-squid.pp
#http_port 10.0.1.2:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem version=1
options=NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE
http_port 10.0.1.2:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
dhparams=/etc/squid/ssl_cert/dhparam.pem

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/spool/squid 100 16 256
cache_dir aufs /var/spool/squid 5000 100 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

cache_mem 8 MB
maximum_object_size_in_memory 32 KB
memory_replacement_policy heap GDSF
cache_replacement_policy heap LFUDA
maximum_object_size 128000 KB
cache_swap_low 95
cache_swap_high 99
strip_query_terms off

# semanage fcontext -a -t FILE_TYPE 'index.txt'
# #where FILE_TYPE is one of the following: NetworkManager_tmp_t,
abrt_helper_exec
# # Then execute:
#restorecon -vr 'index.txt'
sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB

sslproxy_foreign_intermediate_certs /etc/squid/ssl_cert/myca.pem
#sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
sslproxy_cafile /etc/squid/ssl_cert/myca.pem
sslproxy_cipher EECDH+ECDSA+AESGCM:E$

acl step1 at_step sslbump1
acl step2 at_step sslbump2
acl step3 at_step sslbump3

ssl_bump stare step1
ssl_bump peek step2
ssl_bump bump step3

# When a peek rule matches during step1, Squid proceeds to step2 where it
parses the TLS Client Hello and extracts SNI
# (if any). When a peek rule matches during step 2, Squid proceeds to step3
where it parses the TLS Server Hello
# and extracts server certificate while preserving the possibility of
splicing the client and server connections;
# peeking at the server certificate usually precludes future bumping (see
Limitations).
#ssl_bump peek all

# When a stare rule matches during step1, Squid proceeds to step2 where it
parses the TLS Client Hello and extracts SNI
# (if any). When a stare rule matches during step2, Squid proceeds to step3
where it parses the TLS Server Hello and extracts
# server certificate while preserving the possibility of bumping the client
and server connections; staring at the server
# certificate usually precludes future splicing (see Limitations).
#ssl_bump stare all

# Become a TCP tunnel without decoding the connection. The client and the
server exchange data as if there is no proxy in
# between. Step 1, 2 and sometime 3
#ssl_bump splice all

# Establish a TLS connection with the server (using client SNI, if any) and
establish a TLS connection with the client
# (using a mimicked server certificate). However, this is not what actually
happens right now if a bump rule matches during
# step1.
#ssl_bump bump all

# Close client and server connections.
#ssl_bump terminate all

acl ARCHIEVES url_regex -i
\.(rpm|cab|deb|exe|msi|msu|zip|tar|xz|bz|bz2|lzma|gz|tgz|rar|bin|7z|doc?|xls?|ppt?|pdf|nth|psd|sis)*
acl PICS url_regex -i \.(gif|png|jp?g|ico|bmp|tiff?)*
acl MOVIES url_regex -i
\.(avi|iso|wav|mid|mp?|mpeg|mov|3gp|wm?|swf|flv|x-flv|axd|ism?)*
acl FILES url_regex -i \.(html|htm|css|js)*
acl IDXS url_regex -i \.index.(html|htm)*
acl GV url_regex -i \.googlevideo\.com*

#never_direct allow ARCHIEVES
#never_direct allow PICS
#never_direct allow MOVIES
#never_direct allow FILES
#never_direct allow IDXS

cache allow ARCHIEVES
cache allow PICS
cache allow MOVIES
cache allow FILES
cache allow IDXS
cache allow GV

#never_direct deny alldst
#always_direct allow alldst

request_header_access From deny all
request_header_access Server deny all
request_header_access WWW-Authenticate deny all
request_header_access Link deny all
request_header_access Cache-Control deny all
request_header_access Proxy-Connection deny all
request_header_access X-Cache deny all
request_header_access X-Cache-Lookup deny all
request_header_access Via deny all
request_header_access X-Forwarded-For deny all
request_header_access Pragma deny all
request_header_access Keep-Alive deny all

refresh_pattern ^ftp:       1440    20% 10080
refresh_pattern ^gopher:    1440    0%  1440
refresh_pattern -i (/cgi-bin/|\?) 0 0%  0
refresh_pattern (Release|Packages(.gz)*)*      0       20%     2880
refresh_pattern -i \.(gif|png|jp?g|ico|bmp|tiff?)* 10080 95% 43200
refresh_pattern -i
\.(rpm|cab|deb|exe|msi|msu|zip|tar|xz|bz|bz2|lzma|gz|tgz|rar|bin|7z|doc?|xls?|ppt?|pdf|nth|psd|sis)*
10080 90% 43200
refresh_pattern -i
\.(avi|iso|wav|mid|mp?|mpeg|mov|3gp|wm?|swf|flv|x-flv|axd)* 43200 95% 432000
refresh_pattern -i \.(html|htm|css|js)* 1440 75% 40320
refresh_pattern -i \.index.(html|htm)* 0 75% 10080
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern -i \.googlevideo\.com* 43200 95% 432000
refresh_pattern . 1440 90% 10080

quick_abort_min 0 KB
quick_abort_max 0 KB
quick_abort_pct 100
store_avg_object_size 13 KB

dns_nameservers 10.0.1.2 192.168.19.2
visible_hostname ws1.ebedsat.net
shutdown_lifetime 3 second
via off
forwarded_for off

logformat logaccess [%{%d/%b/%Y %H:%M:%S}tl] %>a %Ss/%03>Hs %<st %rm %ru
%un %Sh/%<A %mt
access_log daemon:/var/log/squid/access.log logaccess

#
# Add any of your own refresh_pattern entries above these.
#
#refresh_pattern ^ftp: 1440 20% 10080
#refresh_pattern ^gopher: 1440 0% 1440
#refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
#refresh_pattern . 0 20% 4320
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190519/04405582/attachment.htm>

From squid3 at treenet.co.nz  Sun May 19 04:47:05 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 19 May 2019 16:47:05 +1200
Subject: [squid-users] Cache cellphone
In-Reply-To: <CAMcTSO2Op7gxE2FYhRDXZbSBCxOz7KSwjFrpet6XR+wFSwaFUg@mail.gmail.com>
References: <CAMcTSO2Op7gxE2FYhRDXZbSBCxOz7KSwjFrpet6XR+wFSwaFUg@mail.gmail.com>
Message-ID: <be50107f-3dce-92c1-fb61-b1be1d0b10d2@treenet.co.nz>

On 19/05/19 3:47 pm, Ebed wrote:
> I'm trying to setup squid for my wifi which mainly for cell phones and
> tv box with ssl-bump for the sake of bandwidth saving and my kids
> protection.?Is it posible for squid to directly inject root CA as per
> request by applications?


No. If the clients do not trust your root CA there is nothing Squid can
do to make them. TLS is designed to prevent that type of trivial attack.

Your ssl_bump config looks a bit suspicious though. Doing peek at step2
should prevent bump from being possible at step3. You might have better
behaviour by swapping the peek and stare order. To be "peek step1" then
"stare step2".


> As i found hardly to setup my root ca to
> cellphone apps. I had tried install using user credentiall setup but its
> still failed and impossible for me to reflash the android os just to
> install the CA cert into the trusted credentialls table. I had try
> ssl_bump option combination with no luck, peek and bump produce alot of
> handshake errors. Here's my squid.conf, just guide me to the right way.
> 

Look at what those errors are saying. That should lead you towards
fixing them.



Also, what version of Squid are you using? there seem to be a jumbled
mix of old and new settings in this config file.

...

> https_port 10.0.1.2:3127 intercept ssl-bump
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> cert=/etc/squid/ssl_cert/myca.pem dhparams=/etc/squid/ssl_cert/dhparam.pem
> 
> #############################################################
> # tproxy setting
> # ausearch -c 'squid' --raw | audit2allow -M my-squid
> # semodule -i my-squid.pp
...
> http_port 10.0.1.2:3128 ssl-bump
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> cert=/etc/squid/ssl_cert/myca.pem dhparams=/etc/squid/ssl_cert/dhparam.pem
> 
...
> cache_dir aufs /var/spool/squid 5000 100 256
> 
...
> cache_mem 8 MB
> maximum_object_size_in_memory 32 KB
> memory_replacement_policy heap GDSF
> cache_replacement_policy heap LFUDA
> maximum_object_size 128000 KB
> cache_swap_low 95
> cache_swap_high 99
> strip_query_terms off
> 
...
> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
> 
> sslproxy_foreign_intermediate_certs /etc/squid/ssl_cert/myca.pem
...
> sslproxy_cafile /etc/squid/ssl_cert/myca.pem
> sslproxy_cipher EECDH+ECDSA+AESGCM:E$
> 

NP: the missing part of the above cipher setting may give clues to some
of those handshake errors. Squid will have problems connecting to any
server which requires a cipher not in that list.


...
> 
> ssl_bump stare step1
> ssl_bump peek step2
> ssl_bump bump step3
> 
...
> 
> acl ARCHIEVES url_regex -i
> \.(rpm|cab|deb|exe|msi|msu|zip|tar|xz|bz|bz2|lzma|gz|tgz|rar|bin|7z|doc?|xls?|ppt?|pdf|nth|psd|sis)*

This regex pattern matches every URL that contains a "." _anywhere_ in
the URL. For example any URL which has a domain name.
The 3-letter part is optional (due to "*" suffix).


...
> 
> cache allow ARCHIEVES

ARCHIEVES will always match. So the following "cache" rules are pointless.

...
> 
> request_header_access From deny all
> request_header_access Server deny all

Server is a reply header. This line does nothing.

> request_header_access WWW-Authenticate deny all
> request_header_access Link deny all
> request_header_access Cache-Control deny all
> request_header_access Proxy-Connection deny all
> request_header_access X-Cache deny all
> request_header_access X-Cache-Lookup deny all
> request_header_access Via deny all

You are using "via off" setting. Which makes the above rule pointless.

> request_header_access X-Forwarded-For deny all

Use "forwarded_for delete" instead of the above line and "forwarded_for
off" you have later.

> request_header_access Pragma deny all
> request_header_access Keep-Alive deny all
> 

NP: Pragma, WWW_Authenticate, Cache-Control and Link will do nothing
useful and actively break HTTP going through this proxy. You had best
remove those lines.

The Proxy-Connection and Keep-Alive headers are hop-by-hop and
deprecated in HTTP/1.1. Which means any current Squid *always* removes
them. You do not need rules to make that happen.



> refresh_pattern ^ftp: ? ? ? 1440 ? ?20% 10080
> refresh_pattern ^gopher: ? ?1440 ? ?0% ?1440
> refresh_pattern -i (/cgi-bin/|\?) 0 0% ?0
> refresh_pattern (Release|Packages(.gz)*)* ? ? ?0 ? ? ? 20% ? ? 2880

The above is equivalent to:

   refresh_pattern . 0 20% 2880

Which means the following regex rules are pointless.


...
> via off
> forwarded_for off
> 
> logformat logaccess [%{%d/%b/%Y %H:%M:%S}tl] %>a %Ss/%03>Hs %<st %rm %ru
> %un %Sh/%<A %mt
> access_log daemon:/var/log/squid/access.log logaccess
> 


Amos


From Peter.Spencer at idegroup.com  Mon May 20 08:43:56 2019
From: Peter.Spencer at idegroup.com (Peter Spencer)
Date: Mon, 20 May 2019 08:43:56 +0000
Subject: [squid-users] Squid proxy in Azure
In-Reply-To: <CWXP265MB0487DC21A5BD8A492625C80286060@CWXP265MB0487.GBRP265.PROD.OUTLOOK.COM>
References: <CWXP265MB0487DC21A5BD8A492625C80286060@CWXP265MB0487.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CWXP265MB04876288D3B78F1ED54DFA3286060@CWXP265MB0487.GBRP265.PROD.OUTLOOK.COM>

Good morning

Was hoping you could please advise.. we are looking to put a squid proxy in Azure. Reason being, we have two sites with network resilience. At the moment, we have one squid proxy on one of our local site DCs, and would ideally like to place this in Azure. So if either site goes down, internet traffic is routed via Azure and is still monitored. Does the squid proxy work over WAN?

Thanks

Peter






Peter Spencer
Systems Escalation Engineer

Email:  Peter.Spencer at idegroup.com
Tel:    +448448741462
Web:    idegroup.com<http://www.idegroup.com>
[http://idegroup.com/wp-content/uploads/2017/11/Email_Logo_IDE.jpg]<http://idegroup.com>
Twitter<http://www.twitter.com/_idegroup>       |       Linkedin<https://www.linkedin.com/company/27109080/>

|

Latest News<http://www.idegroup.com/news-events/news>
[http://idegroup.com/wp-content/uploads/2017/11/sig_banner.jpg]<https://www.idegroup.com/services/training//>

This email has been sent by and on behalf of IDE Group Holdings plc (and/ or its subsidiaries), a public company registered in Scotland (company number SC368538) with registered office at 24 Dublin Street, Edinburgh, EH1 3PP ("IDE Group").
The information in this email including any attachment is confidential, may be privileged and is intended solely for the addressee. If it is not addressed to you, please do not read, disclose, copy, forward it on or keep a record of this email and/or the information within it.
If you receive this email in error, please advise the sender immediately of any error in transmission, and then delete the email without making copies. Any disclosure, copying, distribution or action taken, or omitted to be taken, in reliance upon the contents of this email by unauthorised recipients is prohibited and may be unlawful.
Please note that we may intercept, monitor and store emails and any communications with IDE Group may be monitored for the purposes of ensuring compliance with law, our policies and for audit purposes.
We have tried to ensure this email does not contain any viruses and we cannot accept any responsibility for damage caused by a virus. It is therefore recommended that upon receipt from us that you should scan all emails for viruses.
No contracts or commitments may be concluded on behalf of IDE Group or its group companies by means of email, and no statement or representation made in this email is binding on IDE Group.

________________________________
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190520/d246b8f0/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon May 20 09:04:36 2019
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 20 May 2019 10:04:36 +0100
Subject: [squid-users] Squid proxy in Azure
In-Reply-To: <CWXP265MB04876288D3B78F1ED54DFA3286060@CWXP265MB0487.GBRP265.PROD.OUTLOOK.COM>
References: <CWXP265MB0487DC21A5BD8A492625C80286060@CWXP265MB0487.GBRP265.PROD.OUTLOOK.COM>
 <CWXP265MB04876288D3B78F1ED54DFA3286060@CWXP265MB0487.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <201905201004.36642.Antony.Stone@squid.open.source.it>

On Monday 20 May 2019 at 09:43:56, Peter Spencer wrote:

> Good morning
> 
> Was hoping you could please advise.. we are looking to put a squid proxy in
> Azure. Reason being, we have two sites with network resilience. At the
> moment, we have one squid proxy on one of our local site DCs, and would
> ideally like to place this in Azure. So if either site goes down, internet
> traffic is routed via Azure and is still monitored. Does the squid proxy
> work over WAN?

Squid doesn't care how the requests get routed to it, or how its requests get 
routed to the origin servers, or how the replies work, so long as they do.

You can use LAN, WAN, VPN, private addresses, public addresses, IPv4, IPv6, 
anything to get the packets where they need to be.  Squid doesn't care.


Antony.

-- 
Wanted: telepath.   You know where to apply.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From ngtech1ltd at gmail.com  Mon May 20 16:44:11 2019
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Mon, 20 May 2019 19:44:11 +0300
Subject: [squid-users] CFG for access using certificates
In-Reply-To: <78c042e4-e47b-1d13-2bf6-6686d04955cc@treenet.co.nz>
References: <20190518204532.Horde.sMk0jPL3t6wCV0_IT8vDEHx@inbox.dv.lv>
 <78c042e4-e47b-1d13-2bf6-6686d04955cc@treenet.co.nz>
Message-ID: <0acd01d50f2b$41095a40$c31c0ec0$@gmail.com>

What about a key?
Either I do not understand something or there is something new in squid.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Sunday, May 19, 2019 5:54 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] CFG for access using certificates

On 19/05/19 5:45 am, J?nis wrote:
> Hi!
> 
> It is clear for me how to limit access to proxy from specific IPs using
> ACL.
> I wish to create the config for the use of proxy over ssl from any
> address. How would basic cfg look like assuming it is the only way how
> to use proxy?
> 


 https_port 3127 tls-cert=/etc/squid/proxy.pem
 http_access allow all

I hope you can see that this is *not* secure in any way. Simple TLS to a
proxy only protects the in-transit bytes against spying. The proxy is an
open-proxy for any attacker to use at will, and the TLS can trivially be
MITM'd.

You still need to have security checks (http_access rules) to check
whether the client is authorized to use the proxy.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Tue May 21 05:27:12 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 21 May 2019 17:27:12 +1200
Subject: [squid-users] CFG for access using certificates
In-Reply-To: <0acd01d50f2b$41095a40$c31c0ec0$@gmail.com>
References: <20190518204532.Horde.sMk0jPL3t6wCV0_IT8vDEHx@inbox.dv.lv>
 <78c042e4-e47b-1d13-2bf6-6686d04955cc@treenet.co.nz>
 <0acd01d50f2b$41095a40$c31c0ec0$@gmail.com>
Message-ID: <f12888c2-5ed1-94a0-c23e-48e3949dce5a@treenet.co.nz>

On 21/05/19 4:44 am, ngtech1ltd wrote:
> What about a key?
> Either I do not understand something or there is something new in squid.
> 

Should be in the PEM file. I assume it is since the issue is not about
errors on startup.

Amos


From amlgp at mftsl.xyz  Thu May 23 08:37:44 2019
From: amlgp at mftsl.xyz (amlgp)
Date: Thu, 23 May 2019 03:37:44 -0500 (CDT)
Subject: [squid-users] Squid auth helpers aren't installing
Message-ID: <1558600664676-0.post@n4.nabble.com>

Hi, I am using Centos 6 and for some reason the Squid helpers aren't
installing. I go to /usr/lib64 after installing squid and there is no auth
helpers in there at all. I am on a 64bit computer and I have checked
/usr/lib and they both don't have any auth helpers at all. I am using "Squid
7:3.5.28-1.el6".

What could be wrong? Thank you in advance.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From Antony.Stone at squid.open.source.it  Thu May 23 08:50:35 2019
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 23 May 2019 09:50:35 +0100
Subject: [squid-users] Squid auth helpers aren't installing
In-Reply-To: <1558600664676-0.post@n4.nabble.com>
References: <1558600664676-0.post@n4.nabble.com>
Message-ID: <201905230950.36056.Antony.Stone@squid.open.source.it>

On Thursday 23 May 2019 at 09:37:44, amlgp wrote:

> Hi, I am using Centos 6 and for some reason the Squid helpers aren't
> installing. I go to /usr/lib64 after installing squid and there is no auth
> helpers in there at all. I am on a 64bit computer and I have checked
> /usr/lib and they both don't have any auth helpers at all. I am using
> "Squid 7:3.5.28-1.el6".
> 
> What could be wrong? Thank you in advance.

Well, firstly, please show us the commands you are using to install Squid and 
its helpers, plus any output which doesn't look encouraging (warnings, error 
messages, comments about something not being found, etc...)

If you're installing from packages, please also tell us which package 
repositories you are using.


Antony.

-- 
"It is easy to be blinded to the essential uselessness of them by the sense of 
achievement you get from getting them to work at all. In other words - and 
this is the rock solid principle on which the whole of the Corporation's 
Galaxy-wide success is founded - their fundamental design flaws are completely 
hidden by their superficial design flaws."

 - Douglas Noel Adams

                                                   Please reply to the list;
                                                         please *don't* CC me.


From amlgp at mftsl.xyz  Thu May 23 09:08:31 2019
From: amlgp at mftsl.xyz (amlgp)
Date: Thu, 23 May 2019 04:08:31 -0500 (CDT)
Subject: [squid-users] Squid auth helpers aren't installing
In-Reply-To: <201905230950.36056.Antony.Stone@squid.open.source.it>
References: <1558600664676-0.post@n4.nabble.com>
 <201905230950.36056.Antony.Stone@squid.open.source.it>
Message-ID: <1558602511480-0.post@n4.nabble.com>

I started off with installing it from 

yum install
http://ngtech.co.il/repo/centos/7/squid-repo-1-1.el7.centos.noarch.rpm -y 

But I removed it thinking there might be something wrong and then the second
time I tried to point to the repo manually by doing 

nano /etc/yum.repos.d/SQUID.repo

[squid] 
name=Squid repo for CentOS 6 
baseurl=http://www1.ngtech.co.il/rpm/centos/6/x86_64
failovermethod=priority 
enabled=1
gpgcheck=0

Then I did

yum clean all
yum repolist
yum install squid

I created a user and password file called passwords with one username and
password in it.

ncsa auth is supposed to be installed with squid but it doesn't exist
anywhere other than one location and here is what I get when I use locate-

locate ncsa
/usr/share/man/man8/basic_ncsa_auth.8.gz

My squid.conf calls on the ncsa auth but it didn't seem to have installed
with the rest of squid.

2019/05/23 04:55:59| Processing: auth_param basic program
/usr/lib64/squid/basic                                                                                                            
_ncsa_auth /etc/squid/passwords
2019/05/23 04:55:59| FATAL: Authentication helper program
/usr/lib64/squid/basic                                                                                                            
_ncsa_auth: (2) No such file or directory





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Thu May 23 09:43:52 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 May 2019 21:43:52 +1200
Subject: [squid-users] Squid auth helpers aren't installing
In-Reply-To: <1558602511480-0.post@n4.nabble.com>
References: <1558600664676-0.post@n4.nabble.com>
 <201905230950.36056.Antony.Stone@squid.open.source.it>
 <1558602511480-0.post@n4.nabble.com>
Message-ID: <594858bd-d2c1-d8a0-f6e9-79b447e106b2@treenet.co.nz>

On 23/05/19 9:08 pm, amlgp wrote:
> I started off with installing it from 
> 
> yum install
> http://ngtech.co.il/repo/centos/7/squid-repo-1-1.el7.centos.noarch.rpm -y 
> 
> But I removed it thinking there might be something wrong and then the second
> time I tried to point to the repo manually by doing 
> 

Eliezer packages the helpers separately in a package is called
"squid-helpers".

Amos


From kike at elamedia.es  Fri May 24 13:45:49 2019
From: kike at elamedia.es (Enrique Calatayud)
Date: Fri, 24 May 2019 15:45:49 +0200
Subject: [squid-users] TAG_NONE/403 on www.mediavida.com
Message-ID: <CACZfUT7siwBmuiAsGhMZrbM1vy2TNv=tYby_4_nYo8h1sDgkpA@mail.gmail.com>

Hello everyone!

I'm getting a TAG_NONE/403 error with the basic configuration on my squid
proxy server. I've been working on this since the last week but still no
positive results.

I tried several things, even a whitelist. Here is my squid.conf.

acl blocksitelist dstdomain "/etc/squid/websbloqueadas.lst"
acl whitelist dstdomain .mediavida.com
acl localhost src 127.0.0.1/32
acl localnet src 192.168.0.0/24
acl SSL_ports port 443
acl Safe_ports port 80    # http
acl Safe_ports port 21    # ftp
acl Safe_ports port 443   # https
acl Safe_ports port 70    # gopher
acl Safe_ports port 210   # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280   # http-mgmt
acl Safe_ports port 488   # gss-http
acl Safe_ports port 591   # filemaker
acl Safe_ports port 777   # multiling http
acl CONNECT method CONNECT
ssl_bump allow all
dns_v4_first on
pinger_enable off
half_closed_clients off
quick_abort_min 0 KB
quick_abort_max 0 KB
quick_abort_pct 95
client_persistent_connections off
server_persistent_connections off
via off
forwarded_for off
http_access deny blocksitelist
http_access allow whitelist
http_access allow CONNECT whitelist
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localnet
http_access allow localhost
http_access allow all
http_port 0.0.0.0:3128
https_port 0.0.0.0:3128 ssl-bump cert=/etc/squid/squid-cert/cert.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
coredump_dir /var/spool/squid
refresh_pattern ^ftp:   1440  20% 10080
refresh_pattern ^gopher:  1440  0%  1440
refresh_pattern -i (/cgi-bin/|\?) 0 0%  0
refresh_pattern .   0 20% 4320

I tried not using certs, using "http_access allow all" on top of the rules
and disabling others, decrypting ssl...
Is not happening with other websites. I'm starting to think that this is
not my problem...

So, any of you have troubles with www.mediavida.com under your squid proxy
server? Or any of  you have any clue about what I am missing here?

Thank you all!

-- 



C/ Amparo, 10328012 - Madrid - Espa?a
+34 91 821 60 72
www.elamedia.es 
<http://www.elamedia.es/>
facebook.com/elamedia 
<http://facebook.com/elamedia>
twitter.com/elamedia 
<http://twitter.com/elamedia>








---- ADVERTENCIA ----?

La 
informaci?n contenida en este correo electr?nico, y en su caso, cualquier 
fichero anexo al mismo, son de car?cter privado y confidencial siendo para 
uso exclusivo de su destinatario. Si usted no es el destinatario correcto, 
el empleado o agente responsable de entregar el mensaje al destinatario, o 
ha recibido esta comunicaci?n por error, le informamos que est? totalmente 
prohibida cualquier divulgaci?n, distribuci?n o reproducci?n de esta 
comunicaci?n seg?n la legislaci?n vigente y le rogamos que nos lo notifique 
inmediatamente, procediendo a su destrucci?n sin continuar su lectura.

Le 
informamos que su direcci?n de correo electr?nico, as? como el resto de los 
datos de car?cter personal de la tarjeta de visita que nos facilite, 
podr?an ser objeto de tratamiento automatizado en nuestros sistemas de 
informaci?n, con la finalidad de gestionar la agenda de contactos de 
ELAMEDIA, S.L.U. Usted podr? en cualquier momento ejercer sus derechos de 
acceso, rectificaci?n, cancelaci?n y oposici?n en los t?rminos establecidos 
en el Reglamento (UE) 2016/679 de Protecci?n de Datos ?mediante 
notificaci?n escrita, aportando copia del DNI o tarjeta identificativa, a 
nuestro correo: protecciondatos at elamedia.es. 

Vd. puede consultar nuestra 
pol?tica de Protecci?n de Datos en nuestra web www.elamedia.es 
<http://www.elamedia.es/>. ????

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190524/a7fd1cbb/attachment.htm>

From squid3 at treenet.co.nz  Fri May 24 15:29:03 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 25 May 2019 03:29:03 +1200
Subject: [squid-users] TAG_NONE/403 on www.mediavida.com
In-Reply-To: <CACZfUT7siwBmuiAsGhMZrbM1vy2TNv=tYby_4_nYo8h1sDgkpA@mail.gmail.com>
References: <CACZfUT7siwBmuiAsGhMZrbM1vy2TNv=tYby_4_nYo8h1sDgkpA@mail.gmail.com>
Message-ID: <4d5bbb1c-203d-ced7-6e8f-ce35c29ad207@treenet.co.nz>

On 25/05/19 1:45 am, Enrique Calatayud wrote:
> Hello everyone!
> 
> I'm getting a TAG_NONE/403 error with the basic configuration on my
> squid proxy server. I've been working on this since the last week but
> still no positive results.
> 
> I tried several things, even a whitelist. Here is my squid.conf.

...

> ssl_bump allow all

"allow" is not a valid action for this directive.

<https://wiki.squid-cache.org/Features/SslPeekAndSplice#Actions>

...
> http_access deny blocksitelist
> http_access allow whitelist
> http_access allow CONNECT whitelist

Complex access controls being done before even the most
simple/fast/basic security check to prevent DOS attacks.

Move the above http_access lines ...

> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager

... down to here where custom access controls should be.

Except for the "allow CONNECT whitelist" line which you can delete
completely. It is pointless behind "allow whitelist".


> http_access allow localnet
> http_access allow localhost
> http_access allow all

This is now an "open proxy" - not a good idea.


> http_port 0.0.0.0:3128 
> https_port 0.0.0.0:3128 ssl-bump
> cert=/etc/squid/squid-cert/cert.pem generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB

So port 3128 is simultaneously receiving TLS and non-TLS (plain-text)
traffic syntax?

That is not possible. With the above settings, Squid should log a
complaint in cache.log and only open the first (http_port) to use the
specific IP:port value.

To work at all port directives need unique IP:port settings.


...
> 
> I tried not using certs, using "http_access allow all" on top of the
> rules and disabling others, decrypting ssl...
> Is not happening with other websites. I'm starting to think that this is
> not my problem...

"403 Forbidden" can be sent by any HTTP agent.


> 
> So, any of you have troubles with www.mediavida.com
> <http://www.mediavida.com> under your squid proxy server? Or any of? you
> have any clue about what I am missing here?

You are missing the rest of the access.log line. The parts which tell
you (and us) what was being done that got forbidden, which agent was
doing it, what other agents were involved with the decision, and when
all this happened.


Amos


From hsaltiel at gmail.com  Mon May 27 14:15:22 2019
From: hsaltiel at gmail.com (Hernan Saltiel)
Date: Mon, 27 May 2019 11:15:22 -0300
Subject: [squid-users] Arch + Squid 4.7 + Active Directory Auth
Message-ID: <CAMXef5JjZigigN74MrNgLVnAm=jnRBYY883jfMcNV-cxicpw0g@mail.gmail.com>

Hi all,
    I'm trying to install a brand new Squid 4.7 on an Arch GNU/Linux
(Kernel 5.0.7), authorizing its users against Active Directory, based on a
Windows 2008 R2 Domain.
    I configured samba4 on the Arch machine, and it looks working well.
wbinfo commands get executed and with correct output.
    But when using the Squid, I get all the time messages like:

2019/05/27 04:08:12 kid1| Set Current Directory to /var/spool/squid
2019/05/27 04:08:12 kid1| Starting Squid Cache version 4.7 for
x86_64-pc-linux-gnu...
2019/05/27 04:08:12 kid1| Service Name: squid
2019/05/27 04:08:12 kid1| Process ID 7584
2019/05/27 04:08:12 kid1| Process Roles: worker
2019/05/27 04:08:12 kid1| With 1024 file descriptors available
2019/05/27 04:08:12 kid1| Initializing IP Cache...
2019/05/27 04:08:12 kid1| DNS Socket created at [::], FD 7
2019/05/27 04:08:12 kid1| DNS Socket created at 0.0.0.0, FD 10
2019/05/27 04:08:12 kid1| Adding domain ciabernal.local from
/etc/resolv.conf
2019/05/27 04:08:12 kid1| Adding domain ciabernal.local from
/etc/resolv.conf
2019/05/27 04:08:12 kid1| Adding nameserver 192.168.32.5 from
/etc/resolv.conf
2019/05/27 04:08:12 kid1| helperOpenServers: Starting 0/10
'negotiate_wrapper' processes
2019/05/27 04:08:12 kid1| helperStatefulOpenServers: No 'negotiate_wrapper'
processes needed.
2019/05/27 04:08:12 kid1| helperOpenServers: Starting 0/10 'ntlm_auth'
processes
2019/05/27 04:08:12 kid1| helperStatefulOpenServers: No 'ntlm_auth'
processes needed.
2019/05/27 04:08:12 kid1| helperOpenServers: Starting 0/10
'basic_ldap_auth' processes
2019/05/27 04:08:12 kid1| helperOpenServers: No 'basic_ldap_auth' processes
needed.
2019/05/27 04:08:12 kid1| helperOpenServers: Starting 0/5
'ext_ldap_group_acl' processes
2019/05/27 04:08:12 kid1| helperOpenServers: No 'ext_ldap_group_acl'
processes needed.
2019/05/27 04:08:12 kid1| Logfile: opening log /var/log/squid/access.log
2019/05/27 04:08:12 kid1| WARNING: log name now starts with a module name.
Use 'stdio:/var/log/squid/access.log'
2019/05/27 04:08:12 kid1| Local cache digest enabled; rebuild/rewrite every
3600/3600 sec
2019/05/27 04:08:12 kid1| Store logging disabled
2019/05/27 04:08:12 kid1| Swap maxSize 0 + 262144 KB, estimated 20164
objects
2019/05/27 04:08:12 kid1| Target number of buckets: 1008
2019/05/27 04:08:12 kid1| Using 8192 Store buckets
2019/05/27 04:08:12 kid1| Max Mem  size: 262144 KB
2019/05/27 04:08:12 kid1| Max Swap size: 0 KB
2019/05/27 04:08:12 kid1| Using Least Load store dir selection
2019/05/27 04:08:12 kid1| Set Current Directory to /var/spool/squid
2019/05/27 04:08:12 kid1| Finished loading MIME types and icons.
2019/05/27 04:08:12 kid1| HTCP Disabled.
2019/05/27 04:08:12 kid1| Squid plugin modules loaded: 0
2019/05/27 04:08:12 kid1| Adaptation support is off.
2019/05/27 04:08:12 kid1| Accepting HTTP Socket connections at
local=[::]:3128 remote=[::] FD 12 flags=9
2019/05/27 04:08:13 kid1| storeLateRelease: released 0 objects
2019/05/27 04:08:22 kid1| Starting new negotiateauthenticator helpers...
2019/05/27 04:08:22 kid1| helperOpenServers: Starting 1/10
'negotiate_wrapper' processes
negotiate_kerberos_auth.cc(489): pid=7586 :2019/05/27 04:08:22|
negotiate_kerberos_auth: INFO: Starting version 3.1.0sq
negotiate_kerberos_auth.cc(548): pid=7586 :2019/05/27 04:08:22|
negotiate_kerberos_auth: INFO: Setting keytab to FILE:/etc/krb5.keytab
negotiate_kerberos_auth.cc(572): pid=7586 :2019/05/27 04:08:22|
negotiate_kerberos_auth: INFO: Changed keytab to
MEMORY:negotiate_kerberos_auth_7586
directory_create_or_exist_strict: invalid ownership on directory
/var/cache/samba/msg.lock
cmdline_messaging_context: Unable to initialize messaging context.
lp_load_ex: refreshing parameters
Initialising global parameters
rlimit_max: increasing rlimit_max (1024) to minimum Windows limit (16384)
Processing section "[Global]"
GENSEC backend 'gssapi_spnego' registered
GENSEC backend 'gssapi_krb5' registered
GENSEC backend 'gssapi_krb5_sasl' registered
GENSEC backend 'spnego' registered
GENSEC backend 'schannel' registered
GENSEC backend 'naclrpc_as_system' registered
GENSEC backend 'sasl-EXTERNAL' registered
GENSEC backend 'ntlmssp' registered
GENSEC backend 'ntlmssp_resume_ccache' registered
GENSEC backend 'http_basic' registered
GENSEC backend 'http_ntlm' registered
GENSEC backend 'http_negotiate' registered
GENSEC backend 'krb5' registered
GENSEC backend 'fake_gssapi_krb5' registered
Got NTLMSSP neg_flags=0xe2088297
Got user=[user01] domain=[mydomain] workstation=[MYPC] len1=24 len2=304
Login for user [mydomain]\[user01]@[MYPC] failed due to [Reading winbind
reply failed!]
GENSEC login failed: NT_STATUS_UNSUCCESSFUL
2019/05/27 04:08:22 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: NT_STATUS_UNSUCCESSFUL
NT_STATUS_UNSUCCESSFUL; }}

    Some questions I have:

1) About the message:

directory_create_or_exist_strict: invalid ownership on directory
/var/cache/samba/msg.lock
cmdline_messaging_context: Unable to initialize messaging context.

    Checking the permissions, it has 755, so I really do not understand why
it?s showing this. Don't know if there is some ownership rule or something
like this...

2) About the message:

Login for user [mydomain]\[user01]@[MYPC] failed due to [Reading winbind
reply failed!]

    I tried debugging Samba, but see no message indicating something here.
Any help would be really appreciated.

3) Is there any example configuration for Squid 4 + Samba 4 + Active
Directory? Sorry for this, but I see tons of information about Active
Directory for Samba 4 and Squid3, but not much about the configuration I'm
trying to have.
    I see several differences, for instance:

1) Use of "negotiate_wrapper".
2) Several aspects of files located on /var/lib/squid, where I do not see
the equivalence between them and the ones listed for Squid3, and visible on
tons of documentation.
3) Some docs say NTLM is deprecated, some are still showing ntlm_auth on
config files. This is why I really need to see if there is any example for
this config...

    Thanks a lot in advance for your time and attention, and best regards.

-- 
HeCSa
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190527/48fec5d5/attachment.htm>

From je at ktf.rtu.lv  Tue May 28 11:56:29 2019
From: je at ktf.rtu.lv (=?utf-8?b?SsSBbmlz?=)
Date: Tue, 28 May 2019 14:56:29 +0300
Subject: [squid-users] CFG for access using certificates
In-Reply-To: <78c042e4-e47b-1d13-2bf6-6686d04955cc@treenet.co.nz>
References: <20190518204532.Horde.sMk0jPL3t6wCV0_IT8vDEHx@inbox.dv.lv>
 <78c042e4-e47b-1d13-2bf6-6686d04955cc@treenet.co.nz>
Message-ID: <20190528145629.Horde.RxKICLu6Pk4RqwR4ivjXsx-@inbox.dv.lv>


Cit?ts Amos Jeffries <squid3 at treenet.co.nz>
Sun, 19 May 2019 14:53:33 +1200:

> On 19/05/19 5:45 am, J?nis wrote:
>> Hi!
>>
>> It is clear for me how to limit access to proxy from specific IPs using
>> ACL.
>> I wish to create the config for the use of proxy over ssl from any
>> address. How would basic cfg look like assuming it is the only way how
>> to use proxy?
>
>  https_port 3127 tls-cert=/etc/squid/proxy.pem
>  http_access allow all
>
> I hope you can see that this is *not* secure in any way. Simple TLS to a
> proxy only protects the in-transit bytes against spying. The proxy is an
> open-proxy for any attacker to use at will, and the TLS can trivially be
> MITM'd.
>
> You still need to have security checks (http_access rules) to check
> whether the client is authorized to use the proxy.

Could it be user/password authentification? Is it plain-text or also over SSL?

The other solution could be using ssl tunnels with private key  
authentification.

Janis


From adilias3 at gmx.com  Wed May 29 04:41:34 2019
From: adilias3 at gmx.com (Ilias Clifton)
Date: Wed, 29 May 2019 06:41:34 +0200
Subject: [squid-users] LDAP authentication from android and iphones
Message-ID: <trinity-67746683-2701-481a-b366-509a20d76fc6-1559104894285@3c-app-mailcom-bs12>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190529/f50b6aa9/attachment.htm>

From belle at bazuin.nl  Wed May 29 07:04:18 2019
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 29 May 2019 09:04:18 +0200
Subject: [squid-users] LDAP authentication from android and iphones
In-Reply-To: <trinity-67746683-2701-481a-b366-509a20d76fc6-1559104894285@3c-app-mailcom-bs12>
References: <trinity-67746683-2701-481a-b366-509a20d76fc6-1559104894285@3c-app-mailcom-bs12>
Message-ID: <vmime.5cee2ef2.3961.5445e297381f2781@ms249-lin-003.rotterdam.bazuin.nl>

Hai, 
?
You are probely missing in you smb.conf: 
?
ntlm auth = yes 
?
?
Greetz, 
?
Louis
?

Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Ilias Clifton
Verzonden: woensdag 29 mei 2019 6:42
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] LDAP authentication from android and iphones



Hi All,
?
I have Squid 3.5.27 running on Ubuntu 18.04.2, and have been unsuccesfull in being able to authenticate users via ldap (kerberos is working well)
?
Currently it's iphone and android users that are having the issue - all other users are authenticating via kerberos.
?
In squid.conf, I have:
auth_param basic program /usr/lib/squid/basic_ldap_auth -d -R -b "OU=users,DC=domain,DC=com" -D squid at domain.com -W /etc/squid/ldappass.txt -f sAMAccountName=%s -h dc.domain.com
?
When a user attempts to browse via the proxy, I see in access.log:
?
1559096820.116 ? ? ?0 10.99.88.77 TCP_DENIED/407 2248 GET http://www.google.com - HIER_NONE/- text/html
?
And the user is prompted for a username and password..
?
I then see in cache.log:
?
basic_ldap_auth.cc(691): pid=32625 :user filter 'sAMAccountName=username', searchbase 'OU=users,DC=domain,DC=com'
basic_ldap_auth.cc(746): pid=32625 :attempting to authenticate user 'CN=Users Fullname,OU=users,DC=domain,DC=com'
?
But the user just keeps getting prompted for username and password over and over, and I continue to see:
?
1559096820.116 ? ? ?0 10.99.88.77 TCP_DENIED/407 2248 GET http://www.google.com - HIER_NONE/- text/html
?
?
If I run the following on the command line, it appears to authenticate correctly:
?
/usr/lib/squid/basic_ldap_auth -d -R -b "OU=users,DC=domain,DC=com" -D squid at domain.com -W /etc/squid/ldappass.txt -f sAMAccountName=%s -h dc.domain.com
username password
?
basic_ldap_auth.cc(691): pid=32625 :user filter 'sAMAccountName=username', searchbase 'OU=users,DC=domain,DC=com'
basic_ldap_auth.cc(746): pid=32625 :attempting to authenticate user 'CN=Users Fullname,OU=users,DC=domain,DC=com'
OK
?
?
What else can I do for troubleshooting?
?
?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190529/77206973/attachment.htm>

From info at schroeffu.ch  Wed May 29 07:23:38 2019
From: info at schroeffu.ch (info at schroeffu.ch)
Date: Wed, 29 May 2019 07:23:38 +0000
Subject: [squid-users] Arch + Squid 4.7 + Active Directory Auth
In-Reply-To: <CAMXef5JjZigigN74MrNgLVnAm=jnRBYY883jfMcNV-cxicpw0g@mail.gmail.com>
References: <CAMXef5JjZigigN74MrNgLVnAm=jnRBYY883jfMcNV-cxicpw0g@mail.gmail.com>
Message-ID: <fe965ebcc22245700b5f8d12b27508ae@schroeffu.ch>

Hi Hernan Saltiel,

I can tell you my working NTLM auth configuration for Squid 4.6 (will work for 4.7 too). My documentation is an ansible playbook created by myself for the need of our company, so I don't remember from where I got all the information for a working configuration. Whenever I have to re-install one of our 17+ proxies, I just run the playbook once on a provisioned server :#)

IMHO: Kerberos is better than NTLM, because Kerberos is a standard protocol while NTLM is Windows only. But my config below is for the moment also NTLM only. NTLM is easier to setup while KRB5 takes a little time to understand the keytab file generation things.
About the wrapper in Squid: The names of this wrapper_files may changed and they are sometimes on other places. In my case the NTLM wrapper for Squid4 is /usr/lib/squid/ext_ldap_group_acl.

About NTLM and [mydomain][user01]@[MYPC] failed due to [Reading winbind reply failed!]: You should test if NTLM auth with winbind is working on your server before run ntlm auth in squid, with: wbinfo -g or wbinfo -u on the command line which must give you as an answer the users or groups from your AD (winbind > smb.conf). There is also somewhere a wrapper-file to check wbinfo with squid wrapper too, but i dont remember which it is.

So below is a working configuration (for me) on Ubuntu 18.04 server with squid 4.6 compiled from debian testing source (with ssl bump). 

- name: Install AD WinBind Authentification Packages
 apt:
 state: present
 name:
 - samba
 - winbind
 notify: restart winbind smbd
 when: activedirectory_winbind_authentification == True
 - name: Upload smb.conf for WinBind
 template:
 src: smb.conf.j2
 dest: /etc/samba/smb.conf
 notify: restart winbind smbd
 when: activedirectory_winbind_authentification == True

################################################################
#/etc/samba/smb.conf
################################################################
#======================= Global Settings =======================

[global]
netbios name = proxy01xx
workgroup = DOM-COMPANY
realm = companydomain.DE
server string =
security = ADS
encrypt passwords = true
log level = 3
log file = /var/log/samba/%m
wins support = no
preferred master = no
domain master = no
local master = no
template shell = /bin/false
template homedir = /home/%D/%U
winbind uid = 10000-20000
winbind gid = 10000-20000
idmap config * : backend = tdb
idmap config * : range = 3000-7999
idmap config DOM-COMPANY:backend = rid
idmap config DOM-COMPANY:schema_mode = rfc2307
idmap config DOM-COMPANY:range = 8000-80000
enhanced browsing = no
winbind use default domain = yes
winbind enum users = no
winbind enum groups = no
idmap cache time = 604800
idmap negative cache time = 20
winbind cache time = 600

password server = 192.168.xx.xx 172.16.x.x 172.16.x.x 172.16.x.x
load printers = no
printing = bsd
printcap name = /dev/null
disable spoolss = yes
################################################################
- name: Add "winbind" to /etc/nsswitch.conf at the end of passwd line
 replace:
 backup: yes
 dest: /etc/nsswitch.conf
 regexp: '^(group(?!.*bwinbindb).*)$'
 replace: '1 winbind'
 notify: restart winbind smbd
 when: activedirectory_winbind_authentification == True
 tags: nsswitch

################################################################
# /etc/nsswitch.conf
#
# Example configuration of GNU Name Service Switch functionality.
# If you have the `glibc-doc-reference' and `info' packages installed, try:
# `info libc "Name Service Switch"' for information about this file.

passwd: compat systemd winbind
group: compat systemd winbind
shadow: compat
gshadow: files

hosts: files dns
networks: files

protocols: db files
services: db files
ethers: db files
rpc: db files

netgroup: nis
################################################################
- name: adding existing user "proxy" to group "winbindd_priv", via https://www.linuxquestions.org/questions/linux-server-73/prompts-password-for-squid-using-ntlm-673036/#post4977410
 user:
 name: proxy
 groups: winbindd_priv
 append: yes
 notify: restart squid
 when: activedirectory_winbind_authentification == True

################################################################
#/etc/group 
################################################################
#(...)
winbindd_priv:x:116:proxy
#(...)
#This is the only step I don't have yet in my ansible playbook automated, but its required once after installing winbind for sure:
#Winbind join the server into the domain: 
net ads join -U administrator
#test if winbind works:
wbinfo -g
wbinfo -u
- name: Upload squid.conf
 template:
 src: "{{ item }}.j2"
 dest: /etc/squid/{{ item }}
 owner: proxy
 group: proxy
 backup: yes
 with_items:
 - squid.conf
 notify: restart squid
 tags: squidconfonly
################################################################
#/etc/squid.conf 
#relevant content for NTLM auth
################################################################
######################################################### NTLM #########################################################
# NTLM authentication, caching not neccessary, because the connection will be authenticated against the token
auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --use-cached-creds --offline-logon
auth_param ntlm realm Proxy-Anmeldung NTLM: Bitte DomaeneBenutzername und Windows-Kennwort eingeben.
auth_param ntlm children 50

#Allow fetch intermediate certs before required authentication (required when SSL Bump + proxy_auth REQUIRED)
acl fetched_certificate transaction_initiator certificate-fetching
cache allow fetched_certificate
cache deny all
http_access allow fetched_certificate

######################################################### Allow based on group membership #########################################################
# Authentication required, otherwise Login Pop-Up
acl Authenticated_Users proxy_auth REQUIRED
http_access deny !Authenticated_Users

# Define external acl
external_acl_type ldap_group ipv4 ttl=3600 negative_ttl=1800 children-max=150 children-startup=10 %LOGIN /usr/lib/squid/ext_ldap_group_acl -K -S -R 
-b "DC=companydomain,DC=de" 
-D "CN=anLDAPuserwithREADaccess,OU=Sonstige,DC=companydomain,DC=de" 
-w PASSWORDHERE 
-f "(&(objectclass=user)(sAMAccountName=%v)(memberof=CN=%a,CN=Users,DC=companydomain,DC=de))" 
-h 192.168.xx.xx 172.16.xx.xx 172.16.xx.xx 172.16.xx.xx

## Get group "InternetAccess3" from AD/LDAP and use this group in squid.conf as "ldap_InternetAccess3"
acl ldap_InternetAccess3 external ldap_group InternetAccess3

acl FTP_ports port 21
acl SSL_ports port 443
acl SSL_ports port 8443
acl SSH_ports port 22
acl Safe_ports port 21 #FTP
acl Safe_ports port 22 # SSH
acl Safe_ports port 80 # http
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl Safe_ports port 8443 # Plesk
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports !SSH_ports !FTP_ports

http_access allow ldap_InternetAccess3 !FTP_ports !SSH_ports !streaming !badfileending

http_access allow localhost manager
http_access deny manager
acl localdom dstdomain .ourcompany.de ourcompanydomain2.com
acl NOCACHE dstdomain ourcompany.de
no_cache allow NOCACHE
http_access allow localhost
http_access deny all
################################################################
Hope it helps. 
Good luck
Schroeffu
27. Mai 2019 16:16, "Hernan Saltiel" <hsaltiel at gmail.com (mailto:hsaltiel at gmail.com?to=%22Hernan%20Saltiel%22%20<hsaltiel at gmail.com>)> schrieb:
Hi all, 
I'm trying to install a brand new Squid 4.7 on an Arch GNU/Linux (Kernel 5.0.7), authorizing its users against Active Directory, based on a Windows 2008 R2 Domain. 
I configured samba4 on the Arch machine, and it looks working well. wbinfo commands get executed and with correct output. 
But when using the Squid, I get all the time messages like: 
2019/05/27 04:08:12 kid1| Set Current Directory to /var/spool/squid
2019/05/27 04:08:12 kid1| Starting Squid Cache version 4.7 for x86_64-pc-linux-gnu...
2019/05/27 04:08:12 kid1| Service Name: squid
2019/05/27 04:08:12 kid1| Process ID 7584
2019/05/27 04:08:12 kid1| Process Roles: worker
2019/05/27 04:08:12 kid1| With 1024 file descriptors available
2019/05/27 04:08:12 kid1| Initializing IP Cache...
2019/05/27 04:08:12 kid1| DNS Socket created at [::], FD 7
2019/05/27 04:08:12 kid1| DNS Socket created at 0.0.0.0, FD 10
2019/05/27 04:08:12 kid1| Adding domain ciabernal.local from /etc/resolv.conf
2019/05/27 04:08:12 kid1| Adding domain ciabernal.local from /etc/resolv.conf
2019/05/27 04:08:12 kid1| Adding nameserver 192.168.32.5 from /etc/resolv.conf
2019/05/27 04:08:12 kid1| helperOpenServers: Starting 0/10 'negotiate_wrapper' processes
2019/05/27 04:08:12 kid1| helperStatefulOpenServers: No 'negotiate_wrapper' processes needed.
2019/05/27 04:08:12 kid1| helperOpenServers: Starting 0/10 'ntlm_auth' processes
2019/05/27 04:08:12 kid1| helperStatefulOpenServers: No 'ntlm_auth' processes needed.
2019/05/27 04:08:12 kid1| helperOpenServers: Starting 0/10 'basic_ldap_auth' processes
2019/05/27 04:08:12 kid1| helperOpenServers: No 'basic_ldap_auth' processes needed.
2019/05/27 04:08:12 kid1| helperOpenServers: Starting 0/5 'ext_ldap_group_acl' processes
2019/05/27 04:08:12 kid1| helperOpenServers: No 'ext_ldap_group_acl' processes needed.
2019/05/27 04:08:12 kid1| Logfile: opening log /var/log/squid/access.log
2019/05/27 04:08:12 kid1| WARNING: log name now starts with a module name. Use 'stdio:/var/log/squid/access.log'
2019/05/27 04:08:12 kid1| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2019/05/27 04:08:12 kid1| Store logging disabled
2019/05/27 04:08:12 kid1| Swap maxSize 0 + 262144 KB, estimated 20164 objects
2019/05/27 04:08:12 kid1| Target number of buckets: 1008
2019/05/27 04:08:12 kid1| Using 8192 Store buckets
2019/05/27 04:08:12 kid1| Max Mem size: 262144 KB
2019/05/27 04:08:12 kid1| Max Swap size: 0 KB
2019/05/27 04:08:12 kid1| Using Least Load store dir selection
2019/05/27 04:08:12 kid1| Set Current Directory to /var/spool/squid
2019/05/27 04:08:12 kid1| Finished loading MIME types and icons.
2019/05/27 04:08:12 kid1| HTCP Disabled.
2019/05/27 04:08:12 kid1| Squid plugin modules loaded: 0
2019/05/27 04:08:12 kid1| Adaptation support is off.
2019/05/27 04:08:12 kid1| Accepting HTTP Socket connections at local=[::]:3128 remote=[::] FD 12 flags=9
2019/05/27 04:08:13 kid1| storeLateRelease: released 0 objects
2019/05/27 04:08:22 kid1| Starting new negotiateauthenticator helpers...
2019/05/27 04:08:22 kid1| helperOpenServers: Starting 1/10 'negotiate_wrapper' processes
negotiate_kerberos_auth.cc(489): pid=7586 :2019/05/27 04:08:22| negotiate_kerberos_auth: INFO: Starting version 3.1.0sq
negotiate_kerberos_auth.cc(548): pid=7586 :2019/05/27 04:08:22| negotiate_kerberos_auth: INFO: Setting keytab to FILE:/etc/krb5.keytab
negotiate_kerberos_auth.cc(572): pid=7586 :2019/05/27 04:08:22| negotiate_kerberos_auth: INFO: Changed keytab to MEMORY:negotiate_kerberos_auth_7586
directory_create_or_exist_strict: invalid ownership on directory /var/cache/samba/msg.lock
cmdline_messaging_context: Unable to initialize messaging context.
lp_load_ex: refreshing parameters
Initialising global parameters
rlimit_max: increasing rlimit_max (1024) to minimum Windows limit (16384)
Processing section "[Global]"
GENSEC backend 'gssapi_spnego' registered
GENSEC backend 'gssapi_krb5' registered
GENSEC backend 'gssapi_krb5_sasl' registered
GENSEC backend 'spnego' registered
GENSEC backend 'schannel' registered
GENSEC backend 'naclrpc_as_system' registered
GENSEC backend 'sasl-EXTERNAL' registered
GENSEC backend 'ntlmssp' registered
GENSEC backend 'ntlmssp_resume_ccache' registered
GENSEC backend 'http_basic' registered
GENSEC backend 'http_ntlm' registered
GENSEC backend 'http_negotiate' registered
GENSEC backend 'krb5' registered
GENSEC backend 'fake_gssapi_krb5' registered
Got NTLMSSP neg_flags=0xe2088297
Got user=[user01] domain=[mydomain] workstation=[MYPC] len1=24 len2=304
Login for user [mydomain][user01]@[MYPC] failed due to [Reading winbind reply failed!]
GENSEC login failed: NT_STATUS_UNSUCCESSFUL
2019/05/27 04:08:22 kid1| ERROR: Negotiate Authentication validating user. Result: {result=BH, notes={message: NT_STATUS_UNSUCCESSFUL NT_STATUS_UNSUCCESSFUL; }} 
Some questions I have: 
1) About the message: 
directory_create_or_exist_strict: invalid ownership on directory /var/cache/samba/msg.lock
cmdline_messaging_context: Unable to initialize messaging context. 
Checking the permissions, it has 755, so I really do not understand why it?s showing this. Don't know if there is some ownership rule or something like this... 
2) About the message: 
Login for user [mydomain][user01]@[MYPC] failed due to [Reading winbind reply failed!] 
I tried debugging Samba, but see no message indicating something here. Any help would be really appreciated. 
3) Is there any example configuration for Squid 4 + Samba 4 + Active Directory? Sorry for this, but I see tons of information about Active Directory for Samba 4 and Squid3, but not much about the configuration I'm trying to have. 
I see several differences, for instance: 
1) Use of "negotiate_wrapper". 
2) Several aspects of files located on /var/lib/squid, where I do not see the equivalence between them and the ones listed for Squid3, and visible on tons of documentation. 
3) Some docs say NTLM is deprecated, some are still showing ntlm_auth on config files. This is why I really need to see if there is any example for this config... 
Thanks a lot in advance for your time and attention, and best regards. 
--HeCSa
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190529/596ffb04/attachment.htm>

From kike at elamedia.es  Wed May 29 09:47:58 2019
From: kike at elamedia.es (Kike)
Date: Wed, 29 May 2019 04:47:58 -0500 (CDT)
Subject: [squid-users] TAG_NONE/403 on www.mediavida.com
In-Reply-To: <4d5bbb1c-203d-ced7-6e8f-ce35c29ad207@treenet.co.nz>
References: <CACZfUT7siwBmuiAsGhMZrbM1vy2TNv=tYby_4_nYo8h1sDgkpA@mail.gmail.com>
 <4d5bbb1c-203d-ced7-6e8f-ce35c29ad207@treenet.co.nz>
Message-ID: <1559123278624-0.post@n4.nabble.com>

Amos Jeffries wrote
> "allow" is not a valid action for this directive.
> &lt;https://wiki.squid-cache.org/Features/SslPeekAndSplice#Actions&gt;

I don't know what I was thinking, thank you
I deleted the ssl_bump line, I try splicing too with ssl_bump peek all and
ssl_bump splice all, but it also didn't work too.


Amos Jeffries wrote
>> http_access deny blocksitelist
>> http_access allow whitelist
>> http_access allow CONNECT whitelist
> 
> Complex access controls being done before even the most
> simple/fast/basic security check to prevent DOS attacks.
> 
> Move the above http_access lines ...
> 
>> http_access deny !Safe_ports
>> http_access deny CONNECT !SSL_ports
>> http_access allow localhost manager
>> http_access deny manager
> 
> ... down to here where custom access controls should be.
> 
> Except for the "allow CONNECT whitelist" line which you can delete
> completely. It is pointless behind "allow whitelist".

Fixed it. Thanks!


Amos Jeffries wrote
> This is now an "open proxy" - not a good idea.

Of course is not a good idea. In my desperation I tried to keep the proxy
open as much as possible after the rules but it didn't work either.
This is not a long term configuration. I just need to bypass this issue just
because it could happen with other websites (funny think i couldn't find
another one). When this is solved I'll cap the proxy as much as possible.


Amos Jeffries wrote
> So port 3128 is simultaneously receiving TLS and non-TLS (plain-text)
> traffic syntax?
> 
> That is not possible. With the above settings, Squid should log a
> complaint in cache.log and only open the first (http_port) to use the
> specific IP:port value.
> 
> To work at all port directives need unique IP:port settings.

It turns out the cert line and the rest of it wasn't working at all. I just
left "http_port 0.0.0.0:3128". My concern was how about squid proxy manages
443 conections with the same port but all websites works just fine and in
the access.log I can see a lot TCP_TUNNEL/200 like:
TCP_TUNNEL/200 1093 CONNECT www.cisco.com:443 - HIER_DIRECT/104.126.39.51
TCP_TUNNEL/200 11488 CONNECT www.ultratools.com:443 -
HIER_DIRECT/156.154.208.10 



Amos Jeffries wrote
> "403 Forbidden" can be sent by any HTTP agent.

It was 503, sorry.


Amos Jeffries wrote
> You are missing the rest of the access.log line. The parts which tell
> you (and us) what was being done that got forbidden, which agent was
> doing it, what other agents were involved with the decision, and when
> all this happened.

The rest of the access.log file? Sure

1559122901.583  16384 192.168.0.51 TCP_TUNNEL/200 4048 CONNECT
gum.criteo.com:443 - HIER_DIRECT/178.250.2.146 -
1559122902.462  40211 192.168.0.51 TCP_TUNNEL/200 68725 CONNECT
secure-ds.serving-sys.com:443 - HIER_DIRECT/184.25.40.188 -
1559122902.726  15313 192.168.0.51 TCP_TUNNEL/200 3277 CONNECT
gem.gbc.criteo.com:443 - HIER_DIRECT/185.235.84.183 -
1559122902.804  15595 192.168.0.51 TCP_TUNNEL/200 918 CONNECT
smetrics.el-mundo.net:443 - HIER_DIRECT/185.34.188.24 -
1559122904.127  17686 192.168.0.51 TCP_TUNNEL/200 135863 CONNECT
pixel.adsafeprotected.com:443 - HIER_DIRECT/199.166.0.26 -
1559122904.498  12987 192.168.0.51 TCP_TUNNEL/200 1177 CONNECT
dt.adsafeprotected.com:443 - HIER_DIRECT/104.244.36.20 -
1559122904.507  12996 192.168.0.51 TCP_TUNNEL/200 1177 CONNECT
dt.adsafeprotected.com:443 - HIER_DIRECT/104.244.36.20 -
1559122904.629  10142 192.168.0.51 TCP_TUNNEL/200 6787 CONNECT
secure.adnxs.com:443 - HIER_DIRECT/185.33.223.83 -
1559122904.746 1865256 192.168.0.60 TCP_TUNNEL/200 12205 CONNECT
manage.mediashuttle.com:443 - HIER_DIRECT/52.21.207.90 -
1559122904.872  10736 192.168.0.51 TCP_TUNNEL/200 847 CONNECT
dt.adsafeprotected.com:443 - HIER_DIRECT/104.244.36.20 -
1559122905.083  10999 192.168.0.51 TCP_TUNNEL/200 7364 CONNECT
x.bidswitch.net:443 - HIER_DIRECT/18.153.11.1 -
1559122905.676  13345 192.168.0.51 TCP_TUNNEL/200 7176 CONNECT
bs.serving-sys.com:443 - HIER_DIRECT/80.252.91.53 -
1559122906.414  19991 192.168.0.51 TCP_TUNNEL/200 9138 CONNECT
bs.serving-sys.com:443 - HIER_DIRECT/80.252.91.53 -
1559122906.716  11341 192.168.0.51 TCP_TUNNEL/200 3252 CONNECT
csm.fr.eu.criteo.net:443 - HIER_DIRECT/178.250.0.162 -
1559122906.917  18429 192.168.0.51 TCP_MISS/200 360 GET
http://192.168.0.15/v3/api/backchannel? - HIER_DIRECT/192.168.0.15
application/json
1559122907.774 130868 192.168.0.60 TCP_TUNNEL/200 1534 CONNECT
ps6.pubnub.com:443 - HIER_DIRECT/54.93.254.233 -
1559122914.376  19351 192.168.0.51 TCP_TUNNEL/200 6695 CONNECT
farm.plista.com:443 - HIER_DIRECT/176.9.103.51 -
1559122914.665  30180 192.168.0.51 TCP_TUNNEL/200 833 CONNECT
prisacom.sc.omtrdc.net:443 - HIER_DIRECT/172.82.228.19 -
1559122914.780  18976 192.168.0.51 TCP_MISS/200 360 GET
http://192.168.0.16/v3/api/backchannel? - HIER_DIRECT/192.168.0.16
application/json
1559122915.099  66824 192.168.0.51 TCP_TUNNEL/200 286551 CONNECT
newchat-001.servers.prgn.misp.co.uk:443 - HIER_DIRECT/185.52.25.72 -
1559122915.172  65116 192.168.0.51 TCP_TUNNEL/200 4392 CONNECT
newchat-001.servers.prgn.misp.co.uk:443 - HIER_DIRECT/185.52.25.72 -
1559122917.919      0 192.168.0.51 TAG_NONE/503 0 CONNECT
www.mediavida.com:443 - HIER_NONE/- -
1559122918.298  60477 192.168.0.51 TCP_TUNNEL/200 5691 CONNECT
mpc.nicequest.com:443 - HIER_DIRECT/34.224.49.39 -

All TCP_TUNNEL, TCP_MISS allows me to reach the web. The TCP_NONE doesn't.
This all is happening right now. 29/05/2019 at 11:40 pm.

Thank you for your dedicated efforts Amos!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From kike at elamedia.es  Wed May 29 10:15:48 2019
From: kike at elamedia.es (Kike)
Date: Wed, 29 May 2019 05:15:48 -0500 (CDT)
Subject: [squid-users] TAG_NONE/403 on www.mediavida.com
In-Reply-To: <1559123278624-0.post@n4.nabble.com>
References: <CACZfUT7siwBmuiAsGhMZrbM1vy2TNv=tYby_4_nYo8h1sDgkpA@mail.gmail.com>
 <4d5bbb1c-203d-ced7-6e8f-ce35c29ad207@treenet.co.nz>
 <1559123278624-0.post@n4.nabble.com>
Message-ID: <1559124948902-0.post@n4.nabble.com>

Okay. Found the issue.

I was doing ping to google, everything fine. I then pinged www.mediavida.com
and got returned by 127.0.0.1...
Then I check the /etc/hosts while I was saying to myself "oh no, oh no, oh
no..." and there it was, a rule that I put in the file a whole time ago I
didn't even remember: 127.0.0.1 www.mediavida.com

I removed it and, of course it worked!

Soooooo embarrased, I spent sooooo much time on this looking to other
stuff... my god 

So sorry Amos and thank you soooo much!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From m_zouhairy at skno.by  Wed May 29 10:53:10 2019
From: m_zouhairy at skno.by (Vacheslav Zouhairy)
Date: Wed, 29 May 2019 13:53:10 +0300
Subject: [squid-users] TAG_NONE/403 on www.mediavida.com
In-Reply-To: <1559124948902-0.post@n4.nabble.com>
References: <CACZfUT7siwBmuiAsGhMZrbM1vy2TNv=tYby_4_nYo8h1sDgkpA@mail.gmail.com>
 <4d5bbb1c-203d-ced7-6e8f-ce35c29ad207@treenet.co.nz>
 <1559123278624-0.post@n4.nabble.com> <1559124948902-0.post@n4.nabble.com>
Message-ID: <bc119133cb0fb41966ccf433de76f504b7457b12.camel@skno.by>

and in order for this not happen again start suspecting yourself at
first instead of others


On Wed, 2019-05-29 at 05:15 -0500, Kike wrote:
> Okay. Found the issue.
> 
> I was doing ping to google, everything fine. I then pinged 
> www.mediavida.com
> and got returned by 127.0.0.1...
> Then I check the /etc/hosts while I was saying to myself "oh no, oh
> no, oh
> no..." and there it was, a rule that I put in the file a whole time
> ago I
> didn't even remember: 127.0.0.1 www.mediavida.com
> 
> I removed it and, of course it worked!
> 
> Soooooo embarrased, I spent sooooo much time on this looking to other
> stuff... my god 
> 
> So sorry Amos and thank you soooo much!
> 
> 
> 
> --
> Sent from: 
> http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users




From kike at elamedia.es  Wed May 29 11:03:16 2019
From: kike at elamedia.es (Kike)
Date: Wed, 29 May 2019 06:03:16 -0500 (CDT)
Subject: [squid-users] TAG_NONE/403 on www.mediavida.com
In-Reply-To: <bc119133cb0fb41966ccf433de76f504b7457b12.camel@skno.by>
References: <CACZfUT7siwBmuiAsGhMZrbM1vy2TNv=tYby_4_nYo8h1sDgkpA@mail.gmail.com>
 <4d5bbb1c-203d-ced7-6e8f-ce35c29ad207@treenet.co.nz>
 <1559123278624-0.post@n4.nabble.com> <1559124948902-0.post@n4.nabble.com>
 <bc119133cb0fb41966ccf433de76f504b7457b12.camel@skno.by>
Message-ID: <1559127796851-0.post@n4.nabble.com>

I didn't think it was a squid proxy problem, I though it was a
www.mediavida.com problem since every other website worked really well under
squid proxy.

I'm old enough to not blame others without any sensible proofs and even that
I said "I'm starting to think...".

But yeah, you are totally right, I'll think more carefully before I say
something inappropiate. Thanks.





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Wed May 29 13:45:03 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 30 May 2019 01:45:03 +1200
Subject: [squid-users] CFG for access using certificates
In-Reply-To: <20190528145629.Horde.RxKICLu6Pk4RqwR4ivjXsx-@inbox.dv.lv>
References: <20190518204532.Horde.sMk0jPL3t6wCV0_IT8vDEHx@inbox.dv.lv>
 <78c042e4-e47b-1d13-2bf6-6686d04955cc@treenet.co.nz>
 <20190528145629.Horde.RxKICLu6Pk4RqwR4ivjXsx-@inbox.dv.lv>
Message-ID: <519dd3f8-9cad-30fd-3cee-605252101888@treenet.co.nz>

On 28/05/19 11:56 pm, J?nis wrote:
> 
> Cit?ts Amos Jeffries
> Sun, 19 May 2019 14:53:33 +1200:
> 
>> On 19/05/19 5:45 am, J?nis wrote:
>>> Hi!
>>>
>>> It is clear for me how to limit access to proxy from specific IPs using
>>> ACL.
>>> I wish to create the config for the use of proxy over ssl from any
>>> address. How would basic cfg look like assuming it is the only way how
>>> to use proxy?
>>
>> ?https_port 3127 tls-cert=/etc/squid/proxy.pem
>> ?http_access allow all
>>
>> I hope you can see that this is *not* secure in any way. Simple TLS to a
>> proxy only protects the in-transit bytes against spying. The proxy is an
>> open-proxy for any attacker to use at will, and the TLS can trivially be
>> MITM'd.
>>
>> You still need to have security checks (http_access rules) to check
>> whether the client is authorized to use the proxy.
> 
> Could it be user/password authentification? Is it plain-text or also
> over SSL?


If that suits your needs. The in-transit protection of TLS allows things
like Basic auth to be more secure than they are normally.

Almost anything is better than allowing anyone who can contact the proxy
to use it for *anything* they wish.

> 
> The other solution could be using ssl tunnels with private key
> authentification.
> 

That would be the polar opposite in terms of security from what you have
now. More secure is generally better. But YMMV on how far you can go
before things get too difficult for clients.

Amos


From adilias3 at gmx.com  Thu May 30 00:25:53 2019
From: adilias3 at gmx.com (Ilias Clifton)
Date: Thu, 30 May 2019 02:25:53 +0200
Subject: [squid-users] LDAP authentication from android and iphones
In-Reply-To: <vmime.5cee2ef2.3961.5445e297381f2781@ms249-lin-003.rotterdam.bazuin.nl>
References: <trinity-67746683-2701-481a-b366-509a20d76fc6-1559104894285@3c-app-mailcom-bs12>
 <vmime.5cee2ef2.3961.5445e297381f2781@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <trinity-f2aa8f40-fb59-4765-b09b-9d8940b839c1-1559175953301@3c-app-mailcom-bs03>

>> Sent: Wednesday, May 29 2019 6:42
>> From: Ilias Clifton
>> 
>> I have Squid 3.5.27 running on Ubuntu 18.04.2, and have been unsuccesfull in being able to authenticate users via ldap (kerberos is working well)
>> ?
>> What else can I do for troubleshooting?
>> ?
> Sent:?Wednesday, May 29, 2019 at 5:04 PM
> From:?"L.P.H. van Belle" <belle at bazuin.nl>
> 
> 
> Hai,
> ?
> You are probely missing in you smb.conf:
> ?
> ntlm auth = yes
> ?
> ?
> Greetz,
> ?
> Louis


I don't have Samba installed on this server - I can authenticate Firefox users via LDAP, just not Android or iPhones.

To authenticate Android and iPhone users - do I need to use NTLM instead?



From squid3 at treenet.co.nz  Thu May 30 04:36:38 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 30 May 2019 16:36:38 +1200
Subject: [squid-users] LDAP authentication from android and iphones
Message-ID: <mailman.5.1736411439.1101126.squid-users@lists.squid-cache.org>

On 30/05/2019 12:25, Ilias Clifton wrote:


> >> Sent: Wednesday, May 29 2019 6:42
> >> From: Ilias Clifton
> >> 
> >> I have Squid 3.5.27 running on Ubuntu 18.04.2, and have been unsuccesfull in being able to authenticate users via ldap (kerberos is working well)
> >> ?
> >> What else can I do for troubleshooting?
> >> ?

What I do is take one of the access.log lines and read through the squid.conf (whole thing) to see what squid would do with that transaction. Most 40* status problems are with http_access ordering, so quickly spotted.

If you can provide those details in full im happy to do so for you. Or someone experienced with a similar config may spot the issue.

If that is not possible, then you will need to do the above yourself. debug_options ALL,6 can be used to get a cache.log trace to read if you are not confident doing it by-eye or to double-check the expectations. 

> > Sent:?Wednesday, May 29, 2019 at 5:04 PM
> > From:?"L.P.H. van Belle"
> > 
> > 
> > Hai,
> > ?
> > You are probely missing in you smb.conf:
> > ?
> > ntlm auth = yes
> > ?
> > ?
> > Greetz,
> > ?
> > Louis
>
> I don't have Samba installed on this server - I can authenticate Firefox users via LDAP, just not Android or iPhones.
>
> To authenticate Android and iPhone users - do I need to use NTLM instead?
>
>

You should not have to. NTLM is worse than basic in many regards.

If basic has the right credentials from client (check that) and producing a 407/401 then you have a config issue somewhere.

May not be in squid.conf though, could be LDAP service account, or other permissions in the network between squid and the auth backend. The -d helper option should help track that kind of thing down.

FYI; LDAP is not an auth type. It is just a protocol for contacting the database backend where you store the user account credentials. There may be other ways to contact the aurh backend if necessary. But since your manual test worked I agree it should work for squid too. 


Amos

From Joseph.Garbacik at netapp.com  Thu May 30 11:47:42 2019
From: Joseph.Garbacik at netapp.com (Garbacik, Joe)
Date: Thu, 30 May 2019 11:47:42 +0000
Subject: [squid-users] Squid Logs Partially duplicated when denied
Message-ID: <7627BFA8-6104-42BE-986C-521F4E5DCB79@contoso.com>

I have the following for each of my rules (except for my last rule: http_access deny all rule):
http_access allow AllowedSrc AllowedInternalDst
note ruleid ACCESS2INTERNAL  AllowedSrc AllowedInternalDst
note ruletype ALLOW AllowedSrc AllowedInternalDst

I have the following log-format entry used for all logs (note the last two fields now indicate to which rule I matched and the expected behavior):
logformat MyLogFormat  ---> local_time="[%tl]" squid_service=%{service}note squid_status=%Ss squid_hierarchy_status=%Sh ** haproxy_id=%{X-Request-Id}>h orig_src_ip=%{X-Forwarded-For}>h haproxy_egress_ip=%>a haproxy_port=%>p squid_ingress_port=%>lp squid_egress_port=%<lp dst_ip=%<a dst_host=%<A dst_port=%<p ident_username=%[ui username=%[un request_method=%rm request="%rm %ru HTTP/%rv" status_code_from_server=%>Hs status_code_to_client=%<Hs referer="%{Referer}>h" user_agent="%{User-Agent}>h" protocol_version=%rv ** dns_response_time=%dt response_time=%tr mime_type=%mt *XFER*  total_request_size=%>st total_reply_size=%<st ** %{src_zone}note %{dst_zone}note %{method_category}note %{dst_category}note %{file_upload}note ** REQUEST HEADERS %>h *** RESPONSE HEADERS %<h *** tag_returned=%et tag_string="%ea" previous_hop_mac=%>eui peer_response_time=%<pt total_response_time=%<tt *SSL* src_ssl_negotiated_version=%ssl::>negotiated_version dst_ssl_negotiated_version=%ssl::<negotiated_version src_tls_hello_version=%ssl::>received_hello_version  dst_tls_hello_version=%ssl::<received_hello_version src_tls_max_version=%ssl::>received_supported_version dst_tls_max_version=%ssl::<received_supported_version src_tls_cipher=%ssl::>negotiated_cipher dst_tls_cipher=%ssl::<negotiated_cipher ssl_bump=%<bs ssl_bump_mode=%ssl::bump_mode ssl_sni=%ssl::>sni src_cert_subject="%ssl::>cert_subject" src_cert_issuer="%ssl::>cert_issuer" dst_cert_subject="%ssl::<cert_subject" dst_cert_issuer="%ssl::<cert_issuer" cert_errors="%ssl::<cert_errors" *** error_page_presented=%err_code err_detail="%err_detail"  rule_id=%{ruleid}note rule_type=%{ruletype}note

So when traffic is allowed, everything works as expected (Note the orig_src_ip, rule_id, rule, type are all populated):
---> local_time="[30/May/2019:07:25:12 -0400]" squid_service=explicit squid_status=TCP_TUNNEL squid_hierarchy_status=HIER_DIRECT ** haproxy_id=5CEFBD98_0AFB14CC_0AFB1621_206C_9E79_461F orig_src_ip=10.10.2.24 <TRUNCATED>  rule_id= ACCESS2INTERNAL  rule_type=ALLOW

When a client is denied, it creates two log entries, each with portion of the logs filled out (i.e. orig_src_ip in the first log, and the requested url and the  rule that I expected to match in second log):
---> local_time="[30/May/2019:07:20:32 -0400]" squid_service=explicit squid_status=TCP_DENIED squid_hierarchy_status=HIER_NONE ** haproxy_id=5CEFBC7F_0AFB14CC_0AFB1621_206C_9DBE_461F orig_src_ip=10.10.2.24 <TRUNCATED> error_page_presented=ERR_ACCESS_DENIED err_detail="-"  rule_id=- rule_type=-

---> local_time="[30/May/2019:07:20:32 -0400]" squid_service=explicit squid_status=NONE squid_hierarchy_status=HIER_NONE ** haproxy_id=- orig_src_ip=- <TRUNCATED>  request_method=GET request="GET https://example.org/ HTTP/1.1" status_code_from_server=403 status_code_to_client=- <TRUNCATED> error_page_presented=ERR_ACCESS_DENIED err_detail="-"  rule_id= ACCESS2INTERNAL  rule_type=
ALLOW

So my questions are these:

  1.  Is there a better way to log which rules a connection matches?
  2.  Why does the denied log twice and not as a single log entry? Why isn't the requested URL logged in the first log entry and then done.
  3.  Why do I see two squid_status types on the denied (TCP_DENIED and NONE)?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20190530/2bb3f21b/attachment.htm>

From adilias3 at gmx.com  Thu May 30 22:28:10 2019
From: adilias3 at gmx.com (Ilias Clifton)
Date: Fri, 31 May 2019 00:28:10 +0200
Subject: [squid-users] LDAP authentication from android and iphones
In-Reply-To: <20190530043615.4B797E029C@lists.squid-cache.org>
References: <20190530043615.4B797E029C@lists.squid-cache.org>
Message-ID: <trinity-28772a7a-c296-4980-b1ff-14cf1219136a-1559255290231@3c-app-mailcom-bs01>

> > >> Sent: Wednesday, May 29 2019 6:42
> > >> From: Ilias Clifton
> > >>
> > >> I have Squid 3.5.27 running on Ubuntu 18.04.2, and have been unsuccesfull in being able to authenticate users via ldap (kerberos is working well)
> > >>
> > >> What else can I do for troubleshooting?
> > >>
>
> What I do is take one of the access.log lines and read through the squid.conf (whole thing) to see what squid would do with that transaction. Most 40* status problems are with http_access ordering, so quickly spotted.
>
> If you can provide those details in full im happy to do so for you. Or someone experienced with a similar config may spot the issue.
>


See squid.conf below.. Any other config files you need to see?

The users authenticating via ldap on phones are in an Active directory group listed in the file /etc/squid/full_access.txt - They do get full internet access when authenticating via kerberos.

I've checked they are entering the correct passwords - although there are special characters in the passwords eg. `^( - Not sure if that could make a difference. Like I said, it works when running basic_ldap_auth on the command line.

### cache manager
cache_mgr proxy at domain.com

auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -k /etc/squid/PROXY.keytab -r -s GSS_C_NO_NAME
auth_param negotiate children 10 startup=2 idle=1
auth_param negotiate keep_alive on

auth_param basic program /usr/lib/squid/basic_ldap_auth -d -R -b "DC=domain,DC=com" -D proxyuser at domain.com -W /etc/squid/ldappass.txt -f sAMAccountName=%s -h dc.domain.com
auth_param basic children 10 startup=2 idle=1
auth_param basic realm Internet Proxy
auth_param basic credentialsttl 10 minutes

external_acl_type memberof %LOGIN /usr/lib/squid/ext_ldap_group_acl -R -K -S -b "DC=domain,DC=com" -D proxyuser at domain.com -W /etc/squid/ldappass.txt -f "(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,OU=Proxy, DC=domain, DC=com))" -h dc.domain.com

### acl for proxy auth and ldap authorizations
acl auth proxy_auth REQUIRED
acl BlockedAccess   external memberof "/etc/squid/blocked_access.txt"
acl StandardAccess  external memberof "/etc/squid/standard_access.txt"
acl FullAccess      external memberof "/etc/squid/full_access.txt"

acl allowedsites    dstdomain "/etc/squid/allowedsites.txt"
acl blockedsites    dstdomain "/etc/squid/blockedsites.txt"

acl macaddresses	arp "/etc/squid/macaddresses.txt"

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

http_access allow manager localhost
http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost

# allow unauthenticated access to macaddresses in list
http_access allow macaddresses
http_access deny !auth
http_access deny BlockedAccess all

http_access allow allowedsites
http_access allow FullAccess auth

http_access deny blockedsites
http_access allow StandardAccess auth

http_access deny all

cache_mem 1024 MB
cache_dir aufs /var/spool/squid 27648 16 256

### logging
ccess_log /var/log/squid/access.log squid
err_page_stylesheet /etc/squid/errorpage.css
error_directory /etc/squid/error_pages

### squid Debian defaults
http_port 3128
hierarchy_stoplist cgi-bin ?
coredump_dir /var/spool/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320


From squid3 at treenet.co.nz  Fri May 31 04:53:41 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 31 May 2019 16:53:41 +1200
Subject: [squid-users] Squid Logs Partially duplicated when denied
In-Reply-To: <7627BFA8-6104-42BE-986C-521F4E5DCB79@contoso.com>
References: <7627BFA8-6104-42BE-986C-521F4E5DCB79@contoso.com>
Message-ID: <7e1fa213-0173-bd73-7cdf-4ea3eabf0190@treenet.co.nz>



On 30/05/19 11:47 pm, Garbacik, Joe wrote:
> I have the following for each of my rules (except for my last rule:
> http_access deny all rule):
> 
> http_access allow AllowedSrc AllowedInternalDst
> 
> note ruleid ACCESS2INTERNAL? AllowedSrc AllowedInternalDst
> 
> note ruletype ALLOW AllowedSrc AllowedInternalDst
> 
> ?
> 
> I have the following log-format entry used for all logs (note the last
> two fields now indicate to which rule I matched and the expected behavior):
> 
> logformat MyLogFormat? ---> local_time="[%tl]"
> squid_service=%{service}note squid_status=%Ss squid_hierarchy_status=%Sh
> ** haproxy_id=%{X-Request-Id}>h orig_src_ip=%{X-Forwarded-For}>h
> haproxy_egress_ip=%>a haproxy_port=%>p squid_ingress_port=%>lp
> squid_egress_port=%<lp dst_ip=%<a dst_host=%<A dst_port=%<p
> ident_username=%[ui username=%[un request_method=%rm request="%rm %ru
> HTTP/%rv" status_code_from_server=%>Hs status_code_to_client=%<Hs
> referer="%{Referer}>h" user_agent="%{User-Agent}>h" protocol_version=%rv
> ** dns_response_time=%dt response_time=%tr mime_type=%mt *XFER*?
> total_request_size=%>st total_reply_size=%<st ** %{src_zone}note
> %{dst_zone}note %{method_category}note %{dst_category}note
> %{file_upload}note ** REQUEST HEADERS %>h *** RESPONSE HEADERS %<h ***
> tag_returned=%et tag_string="%ea" previous_hop_mac=%>eui
> peer_response_time=%<pt total_response_time=%<tt *SSL*
> src_ssl_negotiated_version=%ssl::>negotiated_version
> dst_ssl_negotiated_version=%ssl::<negotiated_version
> src_tls_hello_version=%ssl::>received_hello_version?
> dst_tls_hello_version=%ssl::<received_hello_version
> src_tls_max_version=%ssl::>received_supported_version
> dst_tls_max_version=%ssl::<received_supported_version
> src_tls_cipher=%ssl::>negotiated_cipher
> dst_tls_cipher=%ssl::<negotiated_cipher ssl_bump=%<bs
> ssl_bump_mode=%ssl::bump_mode ssl_sni=%ssl::>sni
> src_cert_subject="%ssl::>cert_subject"
> src_cert_issuer="%ssl::>cert_issuer"
> dst_cert_subject="%ssl::<cert_subject"
> dst_cert_issuer="%ssl::<cert_issuer" cert_errors="%ssl::<cert_errors"
> *** error_page_presented=%err_code err_detail="%err_detail"?
> rule_id=%{ruleid}note rule_type=%{ruletype}note
> 

Please be aware that there are length limits to log lines. 8KB is
hard-coded in all current releases. With each logging module having its
own I/O limit - which may be smaller than the general 8KB limit in some
modules.


> 
> So when traffic is allowed, everything works as expected (Note the
> orig_src_ip, rule_id, rule, type are all populated):
> 
> ---> local_time="[30/May/2019:07:25:12 -0400]" squid_service=explicit
> squid_status=TCP_TUNNEL squid_hierarchy_status=HIER_DIRECT **
> haproxy_id=5CEFBD98_0AFB14CC_0AFB1621_206C_9E79_461F
> orig_src_ip=10.10.2.24 <TRUNCATED>? rule_id=ACCESS2INTERNAL? rule_type=ALLOW
> 
> ?
> 
> When a client is denied, it creates two log entries, each with portion
> of the logs filled out (i.e. orig_src_ip in the first log, and the
> requested url and the ?rule that I expected to match in second log):
> 
> *---> local_time="[30/May/2019:07:20:32 -0400]"* squid_service=explicit
> squid_status=TCP_DENIED squid_hierarchy_status=HIER_NONE **
> haproxy_id=5CEFBC7F_0AFB14CC_0AFB1621_206C_9DBE_461F
> orig_src_ip=10.10.2.24 <TRUNCATED>
> error_page_presented=ERR_ACCESS_DENIED err_detail="-"? rule_id=- rule_type=-
> 
> *?*
> 
> *---> local_time="[30/May/2019:07:20:32 -0400]"* squid_service=explicit
> squid_status=NONE squid_hierarchy_status=HIER_NONE ** haproxy_id=-
> orig_src_ip=- <TRUNCATED> ?request_method=GET request="GET
> https://example.org/ HTTP/1.1" status_code_from_server=403
> status_code_to_client=- <TRUNCATED>
> error_page_presented=ERR_ACCESS_DENIED err_detail="-"?
> rule_id=ACCESS2INTERNAL? rule_type=
> 
> ALLOW
> 
> ?
> 
> So my questions are these:
> 
>  1. Is there a better way to log which rules a connection matches?


No. The case you have is a very good example of why.

-> There many ACLs all being evaluated for any one transaction.

-> There are multiple protocol levels. Each with different ACLs being
applied.

-> There are multiple *transactions* at the HTTP level that those ACLs
are all being tested one. With possibly conflicting or otherwise vastly
different results.

In aggregate no one ACL can be said to 'cause' the behaviour. They are
just small steps in a quite large sequence of choices.



>  2. Why does the denied log twice and not as a single log entry? Why
>     isn't the requested URL logged in the first log entry and then done.

Because there are two transactions to log.



>  3. Why do I see two squid_status types on the denied (TCP_DENIED and NONE)?
> 

You appear to be using SSL-Bump features. Which means;

The ALLOW case was a spliced transaction. The tunnel data remains
untouched - so only the tunnel layer to log. Thus TCP_TUNNEL

The DENY case requires delivery of a error page to clients. Because of
how Browsers treat error responses to CONNECT requests the TUNNEL must
be bumped to inject the error page in a place where it will get show to
the Browser user, which means two transactions now exist;
 a) the TUNNEL transaction
 b) the decrypted HTTPS request which gets the HTTP format error
response injected.


Amos


From squid3 at treenet.co.nz  Fri May 31 05:33:43 2019
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 31 May 2019 17:33:43 +1200
Subject: [squid-users] LDAP authentication from android and iphones
In-Reply-To: <trinity-28772a7a-c296-4980-b1ff-14cf1219136a-1559255290231@3c-app-mailcom-bs01>
References: <20190530043615.4B797E029C@lists.squid-cache.org>
 <trinity-28772a7a-c296-4980-b1ff-14cf1219136a-1559255290231@3c-app-mailcom-bs01>
Message-ID: <6afbddd9-fbcd-ef79-f7d5-c41c3362cd33@treenet.co.nz>

On 31/05/19 10:28 am, Ilias Clifton wrote:
>>>>> Sent: Wednesday, May 29 2019 6:42
>>>>> From: Ilias Clifton
>>>>>
>>>>> I have Squid 3.5.27 running on Ubuntu 18.04.2, and have been unsuccesfull in being able to authenticate users via ldap (kerberos is working well)
>>>>>
>>>>> What else can I do for troubleshooting?
>>>>>
>>
>> What I do is take one of the access.log lines and read through the squid.conf (whole thing) to see what squid would do with that transaction. Most 40* status problems are with http_access ordering, so quickly spotted.
>>
>> If you can provide those details in full im happy to do so for you. Or someone experienced with a similar config may spot the issue.
>>
> 
> 
> See squid.conf below.. Any other config files you need to see?
> 

This seems sufficient for config. A few possible issues are visible
already, noted below.

If fixing those does not work an access.log line will be needed to do
the troubleshooting sequence check I mentioned.


> The users authenticating via ldap on phones are in an Active directory group listed in the file /etc/squid/full_access.txt - They do get full internet access when authenticating via kerberos.
> 
> I've checked they are entering the correct passwords - although there are special characters in the passwords eg. `^( - Not sure if that could make a difference. Like I said, it works when running basic_ldap_auth on the command line.
> 
> ### cache manager
> cache_mgr proxy at domain.com
> 
> auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -k /etc/squid/PROXY.keytab -r -s GSS_C_NO_NAME
> auth_param negotiate children 10 startup=2 idle=1
> auth_param negotiate keep_alive on
> 
> auth_param basic program /usr/lib/squid/basic_ldap_auth -d -R -b "DC=domain,DC=com" -D proxyuser at domain.com -W /etc/squid/ldappass.txt -f sAMAccountName=%s -h dc.domain.com
> auth_param basic children 10 startup=2 idle=1
> auth_param basic realm Internet Proxy
> auth_param basic credentialsttl 10 minutes
> 


Ah. Sorry I overlooked this mention of Kerberos existing in your initial
mail. This adds something else to check on.

HTTP auth is negotiated starting with the scheme. Clients are required
to attempt the most secure auth scheme from the servers initial 407
response. That means any client which supports Negotiate is required to
use it - no Basic for them.

One thing about Negotiate is that Kerberos keytabs can be setup on some
clients or types of client (ie all iPhones, all Android etc) in a way
that makes it not work when all others do.

Another thing is that clients can also try to use it for Negotiate/NTLM
flavour of auth. Which is not supported by your proxy.

So you do need to check a cache.log trace made with "debug_options 11,2"
to verify that the clients are actually attempting to use Basic or
Kerberos flavour of Negotiate.



> external_acl_type memberof %LOGIN /usr/lib/squid/ext_ldap_group_acl -R -K -S -b "DC=domain,DC=com" -D proxyuser at domain.com -W /etc/squid/ldappass.txt -f "(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%g,OU=Proxy, DC=domain, DC=com))" -h dc.domain.com
> 

I see a whitespace in the -f parameter string "OU=Proxy, DC=domain"
section. Squid-3 does not support whitespace in helper command line
parameters. So that alone may be the problem.


> ### acl for proxy auth and ldap authorizations
> acl auth proxy_auth REQUIRED
> acl BlockedAccess   external memberof "/etc/squid/blocked_access.txt"
> acl StandardAccess  external memberof "/etc/squid/standard_access.txt"
> acl FullAccess      external memberof "/etc/squid/full_access.txt"
> 
> acl allowedsites    dstdomain "/etc/squid/allowedsites.txt"
> acl blockedsites    dstdomain "/etc/squid/blockedsites.txt"
> 
> acl macaddresses	arp "/etc/squid/macaddresses.txt"
> 
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> 
> http_access allow manager localhost
> http_access deny manager
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost
> 

NP: current recommendation/default is to have the manager ACL test after
the localhost one, like so:

 http_access deny !Safe_ports
 http_access deny CONNECT !SSL_ports
 http_access allow localhost
 http_access deny manager


> # allow unauthenticated access to macaddresses in list
> http_access allow macaddresses
> http_access deny !auth

NP: all users are guaranteed to be logged in from this point onwards. So
any use of "auth" ACL in later http_access lines and (most) other
directives should be pointless. Making those lines more suspect for
issues when troubleshooting.


> http_access deny BlockedAccess all
> 
> http_access allow allowedsites
> http_access allow FullAccess auth
> 
If you want clients to re-login whenever they fail the FullAccess group
check then just remove the auth on this line.

 ==> please be aware that the repeated 407 you report seeing is how
re-login shows up. Though best-case does only one 407 loop, there is no
limitation on how many can actually happen. Safari is known to never
stop trying the non-working credentials.


If you do not want re-logins to happen then replace "auth" with "all"


> http_access deny blockedsites
> http_access allow StandardAccess auth
> 

Same here.


> http_access deny all
> 
> cache_mem 1024 MB
> cache_dir aufs /var/spool/squid 27648 16 256
> 
> ### logging
> ccess_log /var/log/squid/access.log squid
> err_page_stylesheet /etc/squid/errorpage.css
> error_directory /etc/squid/error_pages
> 
> ### squid Debian defaults
> http_port 3128
> hierarchy_stoplist cgi-bin ?
> coredump_dir /var/spool/squid
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> 



Amos


