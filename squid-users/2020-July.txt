From anon.amish at gmail.com  Wed Jul  1 05:46:41 2020
From: anon.amish at gmail.com (Amish)
Date: Wed, 1 Jul 2020 11:16:41 +0530
Subject: [squid-users] Squid 4.12 Arch Linux Google Chrome fails -
 OpenSSL 1.1.1g
In-Reply-To: <1e52e43d-9d69-4ba0-6710-4411a97bb183@measurement-factory.com>
References: <72DD5D5CF661B5459DC08A060BF26B5301089333@kjj-server.KJJ.local>
 <17949f91-f48e-2558-bf76-969affa77d03@gmail.com>
 <c90411ab-f15f-29cd-6e9d-496b8a1ef914@measurement-factory.com>
 <6c9233cc-1116-c91a-ef63-f26c239a2dd8@gmail.com>
 <1e52e43d-9d69-4ba0-6710-4411a97bb183@measurement-factory.com>
Message-ID: <c8e6543f-b0a3-e102-85a7-1ebbd4ed1e9b@gmail.com>


On 30/06/20 6:37 pm, Alex Rousskov wrote:
> On 6/29/20 8:56 PM, Amish wrote:
>> On 30/06/20 1:22 am, Alex Rousskov wrote:
>>> On 6/29/20 11:18 AM, Amish wrote:
>>>> I am using Arch Linux and today I upgraded squid to 4.12 (from 4.10)
>>>> Firefox and IE work fine. But in Google chrome - sites dont open.
>>> You may need a fix for TLS GREASEd values. The following master/v6 PR
>>> has not been backported to v4 yet AFAICT, but it might work "as is":
>>>
>>>  ???? https://github.com/squid-cache/squid/pull/663
>> But I am confused that PR has just 1 file changed, but if I read the
>> comments in PR, it has many more commits.
> Many commits may modify one file. If you are not familiar with git, the
> easiest way to get cumulative PR changes is to add ".diff" to the PR
> URL. See the very bottom of any PR page on GitHub for the link/reminder.
>
>      https://github.com/squid-cache/squid/pull/663.diff
>
> HTH,
>
> Alex.

You misunderstood my question or may be I didnt explain it in detail.

I know how to use git. My question was that in that PR, I saw commits 
modifying files like Hasdshake.h, bio.cc.

But in final PR only modification was done to Handshake.cc

So I got confused. But I guess, the final PR is only what matters for my 
problem.

Thanks for the response,

Regards,

Amish.



From patrick.mkhael at hotmail.com  Wed Jul  1 17:45:40 2020
From: patrick.mkhael at hotmail.com (patrick mkhael)
Date: Wed, 1 Jul 2020 17:45:40 +0000
Subject: [squid-users] rock issue
Message-ID: <AM6PR09MB3221DC6FBC09852FDED01EF4916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>

Dears,

Kindly note that i have a lab, where the internet traffic is 100 Mb/s  of pure http targeted traffic, i m trying to achieve cache gain ratio of 60% , i was able to do this using ufs cache dir  and single worker.
But i found that i need to work with rock cache dir since the real traffic is 1000 Mb/s , so one procesor won't be able to
handle all the traffic , so i used the same config , i only switched from ufs to rock , the gain ratio dropped from 60% to 6%.

below is the config that i m using : [ i didn't include the refresh pattern]

workers 10
cpu_affinity_map process_numbers=1,2,3,4,5,6,7,8,9,10 cores=1,2,3,4,5,6,7,8,9,10
cache_mem 20 GB
maximum_object_size_in_memory 50 MB
maximum_object_size 2 GB
cache_miss_revalidate off
quick_abort_pct 85
cache_dir rock /mnt/sdb/1 2048 max-size=10000 max-swap-rate=200 swap-timeout=300
cache_dir rock /mnt/sdb/2 2048 max-size=10000 max-swap-rate=200 swap-timeout=300
cache_dir rock /mnt/sdb/3 4960 max-size=50000 max-swap-rate=200 swap-timeout=300
cache_dir rock /mnt/sdb/4 4960 max-size=50000 max-swap-rate=200 swap-timeout=300
cache_dir rock /mnt/sdb/5 10000 max-size=100000 max-swap-rate=200 swap-timeout=300
cache_dir rock /mnt/sdb/6 10000 max-size=100000 max-swap-rate=200 swap-timeout=300
cache_dir rock /mnt/sdb/7 20000 max-size=500000 max-swap-rate=200 swap-timeout=300
cache_dir rock /mnt/sdb/8 20000 max-size=500000 max-swap-rate=200 swap-timeout=300
cache_dir rock /mnt/sdb/9 40000 max-size=1000000 max-swap-rate=200 swap-timeout=300
cache_dir rock /mnt/sdb/10 40000 max-size=1000000 max-swap-rate=200 swap-timeout=300
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200701/e99f4d98/attachment.htm>

From rousskov at measurement-factory.com  Wed Jul  1 19:26:41 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 1 Jul 2020 15:26:41 -0400
Subject: [squid-users] rock issue
In-Reply-To: <AM6PR09MB3221DC6FBC09852FDED01EF4916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
References: <AM6PR09MB3221DC6FBC09852FDED01EF4916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
Message-ID: <46d7c8ad-4f49-68ad-92f9-537138fca05c@measurement-factory.com>

On 7/1/20 1:45 PM, patrick mkhael wrote:

> Kindly note that i have a lab, where the internet traffic is 100 Mb/s?
> of pure http targeted traffic, i m trying to achieve cache gain ratio of
> 60% , i was able to do this using ufs cache dir? and single worker.
> But i found that i need to work with rock cache dir since the real
> traffic is 1000 Mb/s , so one procesor won't be able to?
> handle all the traffic , so i used the same config , i only switched
> from ufs to rock , the gain ratio dropped from 60% to 6%.

> workers 10
> cpu_affinity_map process_numbers=1,2,3,4,5,6,7,8,9,10 cores=1,2,3,4,5,6,7,8,9,10

Please note that you have 20 kids worth mapping (10 workers and 10
diskers), but you map only the first 10. This is _not_ the reason for a
drop in hit ratio though.

> cache_dir rock /mnt/sdb/1   2048 max-size=10000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/2   2048 max-size=10000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/3   4960 max-size=50000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/4   4960 max-size=50000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/5  10000 max-size=100000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/6  10000 max-size=100000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/7  20000 max-size=500000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/8  20000 max-size=500000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/9  40000 max-size=1000000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/10 40000 max-size=1000000 max-swap-rate=200 swap-timeout=300

Why do you have 10 rock caches of various sizes? The number of caches
itself should not affect the hit ratio directly, but a large number of
caches may complicate analysis and, if you do not have enough
independent disk "spindles", it may slow down disk I/O and lead to
timeouts and rate-based rejections (that do affect hit ratio).

How many independent disk spindles (or equivalent) do you have? All
other factors being equal (they rarely are), you want to dedicate one
independent disk spindle to one rock cache_dir.

How did you select the swap rate limits and timeouts for cache_dirs?

Do you see any ERRORs or WARNINGs in cache log?


Thank you,

Alex.


From patrick.mkhael at hotmail.com  Wed Jul  1 20:45:18 2020
From: patrick.mkhael at hotmail.com (patrick mkhael)
Date: Wed, 1 Jul 2020 20:45:18 +0000
Subject: [squid-users] rock issue
In-Reply-To: <46d7c8ad-4f49-68ad-92f9-537138fca05c@measurement-factory.com>
References: <AM6PR09MB3221DC6FBC09852FDED01EF4916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>,
 <46d7c8ad-4f49-68ad-92f9-537138fca05c@measurement-factory.com>
Message-ID: <AM6PR09MB322116222A6AE6E87562B55E916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>


***Please note that you have 20 kids worth mapping (10 workers and 10
diskers), but you map only the first 10.?{since i did not get the point of the diskers ,as far as i understood  , it should be like  (simple example)
 >workers 2
> cpu_affinity_map process_numbers=1,2,3,4 cores=1,2,3,4
> cache_dir rock /mnt/sdb/1   2048 max-size=10000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/2   2048 max-size=10000 max-swap-rate=200 swap-timeout=300



***Why do you have 10 rock caches of various sizes?  [ to be honest , i saw in many websites that it should be like this from the smallest to the bigest with diff size, i tought it should serve from small size pool to high ]

*****How many independent disk spindles (or equivalent) do you have? [ i have one raid 5 ssd disks , used by the 10 rock cache dir]

***How did you select the swap rate limits and timeouts for cache_dirs? [I took it also from online forum , can i leave it empty for both]


****Do you see any ERRORs or WARNINGs in cache log? [NO error or warning found in cache]

thank u so much !

________________________________
From: Alex Rousskov <rousskov at measurement-factory.com>
Sent: Wednesday, July 1, 2020 10:26 PM
To: patrick mkhael <patrick.mkhael at hotmail.com>; squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] rock issue

On 7/1/20 1:45 PM, patrick mkhael wrote:

> Kindly note that i have a lab, where the internet traffic is 100 Mb/s
> of pure http targeted traffic, i m trying to achieve cache gain ratio of
> 60% , i was able to do this using ufs cache dir  and single worker.
> But i found that i need to work with rock cache dir since the real
> traffic is 1000 Mb/s , so one procesor won't be able to
> handle all the traffic , so i used the same config , i only switched
> from ufs to rock , the gain ratio dropped from 60% to 6%.

> workers 10
> cpu_affinity_map process_numbers=1,2,3,4,5,6,7,8,9,10 cores=1,2,3,4,5,6,7,8,9,10

Please note that you have 20 kids worth mapping (10 workers and 10
diskers), but you map only the first 10. This is _not_ the reason for a
drop in hit ratio though.

> cache_dir rock /mnt/sdb/1   2048 max-size=10000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/2   2048 max-size=10000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/3   4960 max-size=50000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/4   4960 max-size=50000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/5  10000 max-size=100000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/6  10000 max-size=100000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/7  20000 max-size=500000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/8  20000 max-size=500000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/9  40000 max-size=1000000 max-swap-rate=200 swap-timeout=300
> cache_dir rock /mnt/sdb/10 40000 max-size=1000000 max-swap-rate=200 swap-timeout=300

Why do you have 10 rock caches of various sizes? The number of caches
itself should not affect the hit ratio directly, but a large number of
caches may complicate analysis and, if you do not have enough
independent disk "spindles", it may slow down disk I/O and lead to
timeouts and rate-based rejections (that do affect hit ratio).

How many independent disk spindles (or equivalent) do you have? All
other factors being equal (they rarely are), you want to dedicate one
independent disk spindle to one rock cache_dir.

How did you select the swap rate limits and timeouts for cache_dirs?

Do you see any ERRORs or WARNINGs in cache log?


Thank you,

Alex.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200701/a216f0bc/attachment.htm>

From premchand142 at gmail.com  Thu Jul  2 09:49:06 2020
From: premchand142 at gmail.com (Prem Chand)
Date: Thu, 2 Jul 2020 15:19:06 +0530
Subject: [squid-users] Redirect request to cache_peer using username and
	passwords
Message-ID: <CACbtF4PP2WOpY0fg+8TmHh5MhQz7T+1LgVw1so17nmZ=1_pANg@mail.gmail.com>

Hi,

I need to redirect my clients requests to different Cache_peers using
username and passwords through my proxy. Below is the rough sketch. Can
someone suggest to me how I can achieve this?

Client1(Username1:password1) ->Proxy:443 -> Cache_peer:3218
Client 2(Username2:password2)->Proxy:443-> Cache_peer:3219
.
.
.
.

This is my current configuration, I'm doing round robin through cache_peers
when authenticated with a single username and password in
/etc/squid/squidpasswdfile file

auth_param basic program /usr/lib64/squid/ncsa_auth
/etc/squid/squidpasswdfile
auth_param basic realm proxy
acl auth_users proxy_auth REQUIRED
http_access allow auth_users
http_access deny all
cache_peer Peer1 parent 3218 0 round-robin no-query weight=1
connect-fail-limit=1
cache_peer Peer2 parent 3219 0 round-robin no-query weight=1
connect-fail-limit=1
cache_peer Peer3 parent 3219 0 round-robin no-query weight=1
connect-fail-limit=1

Thanks & Regards
Premchand.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200702/dcf89fc0/attachment.htm>

From squid3 at treenet.co.nz  Thu Jul  2 10:20:08 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 2 Jul 2020 22:20:08 +1200
Subject: [squid-users] rock issue
In-Reply-To: <AM6PR09MB322116222A6AE6E87562B55E916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
References: <AM6PR09MB3221DC6FBC09852FDED01EF4916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <46d7c8ad-4f49-68ad-92f9-537138fca05c@measurement-factory.com>
 <AM6PR09MB322116222A6AE6E87562B55E916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
Message-ID: <3e3d3eac-a515-0948-e14b-0fef7f9b0c85@treenet.co.nz>

On 2/07/20 8:45 am, patrick mkhael wrote:
> 
> ***Please note that you have 20 kids worth mapping (10 workers and 10
> diskers), but you map only the first 10.?{since i did not get the point
> of the diskers ,as far as i understood? , it should be like? (simple
> example)
> ?>workers 2
>> cpu_affinity_map process_numbers=1,2,3,4 cores=1,2,3,4
>> cache_dir rock /mnt/sdb/1?? 2048 max-size=10000 max-swap-rate=200 swap-timeout=300
>> cache_dir rock /mnt/sdb/2?? 2048 max-size=10000 max-swap-rate=200 swap-timeout=300
> 
> 
> 
> ***Why do you have 10 rock caches of various sizes??[ to be honest , i
> saw in many websites that it should be like this from the smallest to
> the bigest with diff size, i tought it should serve from small size pool
> to high ]
> 

In general yes. BUT the size ranges to use should be determined via
traffic analysis. Specifically measure and graph the object sizes being
handled. There will be a wavy / cyclic line resulting. The size
boundaries should be set to the *minimum* point(s) along that line.


That said. Since you are comparing the new rock to an old UFS setup. It
would be best to start with the rock being setup as similar to the UFS
as you can - number of cache_dir, ranges of objects stored there etc.

ie. if these ranges were in the old UFS, then keep them for now. That
can be re-calculated after the HIT ratio drop is identified.


> *****How many independent disk spindles (or equivalent) do you have? [ i
> have one raid 5 ssd disks , used by the 10 rock cache dir]
> 

Ouch.

Ideally you would have either:

 5x SSD disks separately mounted. With one rock cache on each.

or,

 1x RAID 10 with one rock cache per disk pair/stripe. This requires
ability for controller to map a sub-directory tree exclusively onto one
of the sub-array stripes.

or,

 2x RAID 1 (drive pair mirroring) with one rock cache on each pair. This
is the simplest way to achieve above when sub-array feature is not
available in RAID 10.

or,

 1x RAID 10 with a single rock cache



The reasons;

Squid I/O pattern is mostly writes and erase. Low on reads.

RAID types in order of best->worst for that pattern are:
  none, RAID 1, RAID 10, RAID 5, RAID 0
<https://wiki.squid-cache.org/SquidFaq/RAID>

Normal SSD controllers cannot handle the Squid I/O pattern well. Squid
*will* age the disk much faster than manufacturer measured statistics
indicate. (True for even HDD, just less of a problem there).

This means that the design needs to plan for coping with relatively
frequent disk failures. Loss of the data itself irrelevant. Only the
outage time + reduction in HIT ratio actually matter on failures.

Look for SSD with high write cycle measurements, and for RAID hot-swap
capability (even if the machine itself cant do that).



> ***How did you select the swap rate limits and timeouts for
> cache_dirs?[I took it also from online forum , can i leave it empty for
> both]
> 

Alex may have better ideas if you can refer us to which tutorials or
documents you found that info in.

Without specific details on why they were chosen I would go with one
rock cache with default values to start with. Only changing them if
followup analysis indicates some other value is better.


Amos


From squid3 at treenet.co.nz  Thu Jul  2 10:43:54 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 2 Jul 2020 22:43:54 +1200
Subject: [squid-users] Redirect request to cache_peer using username and
 passwords
In-Reply-To: <CACbtF4PP2WOpY0fg+8TmHh5MhQz7T+1LgVw1so17nmZ=1_pANg@mail.gmail.com>
References: <CACbtF4PP2WOpY0fg+8TmHh5MhQz7T+1LgVw1so17nmZ=1_pANg@mail.gmail.com>
Message-ID: <29ff57e4-4bcd-0070-fa7b-f33a4d52e16e@treenet.co.nz>

On 2/07/20 9:49 pm, Prem Chand wrote:
> 
> Hi,
> 
> I need to redirect my clients requests to different Cache_peers using
> username and passwords through my proxy. Below is the rough sketch. Can
> someone suggest to me how I can achieve this?


FYI: "redirect" is the wrong word, has a meaning in HTTP completely
different from what you are talking about.

Peers are for message *routing*.

> 
> Client1(Username1:password1) ->Proxy:443 -> Cache_peer:3218
> Client 2(Username2:password2)->Proxy:443-> Cache_peer:3219
> .

That is possible.

However, what do you want to happen when that users dedicated peer is
unavailable?
 Stop all access for them?

 Failover to going "DIRECT" instead of through the peer?

 Use some other peer, and if so which one and based on what criteria?


> 
> This is my current configuration, I'm doing round robin through
> cache_peers when authenticated with a single username and password in
> /etc/squid/squidpasswdfile file

Are you wanting to keep this behaviour?

You can select a group of peers that each user has access to and apply
round-robin to them. However, any peer that is used by more than one
user will have its RR calculation implemented by *both* to prevent overuse.
 So the RR behaviour will not be easily visible. Selected peer (single
only) will be whichever one the user is allowed to access *and*
currently had least traffic going there.


Amos


From patrick.mkhael at hotmail.com  Thu Jul  2 11:04:53 2020
From: patrick.mkhael at hotmail.com (patrick mkhael)
Date: Thu, 2 Jul 2020 11:04:53 +0000
Subject: [squid-users] rock issue
In-Reply-To: <3e3d3eac-a515-0948-e14b-0fef7f9b0c85@treenet.co.nz>
References: <AM6PR09MB3221DC6FBC09852FDED01EF4916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <46d7c8ad-4f49-68ad-92f9-537138fca05c@measurement-factory.com>
 <AM6PR09MB322116222A6AE6E87562B55E916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>,
 <3e3d3eac-a515-0948-e14b-0fef7f9b0c85@treenet.co.nz>
Message-ID: <AM6PR09MB3221CE0231D46B85698F6681916D0@AM6PR09MB3221.eurprd09.prod.outlook.com>

Dear Amos,

**i will use each rock dir with one physical disk , i m going to set up it now. + i will change to default rock dir optional values.

**Please note that i m switching to rock, since one processor won't hande 800 Mb/s traffic

**theoratically would squid with rock cache dir , give me the same gain ratio of ufs cache dir ? [for 100mb/s ufs gave me 70%]



**how much do u think of (worker+RAM) is needed for 800 Mb/s traffic?

thank u

________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Amos Jeffries <squid3 at treenet.co.nz>
Sent: Thursday, July 2, 2020 1:20 PM
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] rock issue

On 2/07/20 8:45 am, patrick mkhael wrote:
>
> ***Please note that you have 20 kids worth mapping (10 workers and 10
> diskers), but you map only the first 10.?{since i did not get the point
> of the diskers ,as far as i understood  , it should be like  (simple
> example)
>  >workers 2
>> cpu_affinity_map process_numbers=1,2,3,4 cores=1,2,3,4
>> cache_dir rock /mnt/sdb/1   2048 max-size=10000 max-swap-rate=200 swap-timeout=300
>> cache_dir rock /mnt/sdb/2   2048 max-size=10000 max-swap-rate=200 swap-timeout=300
>
>
>
> ***Why do you have 10 rock caches of various sizes? [ to be honest , i
> saw in many websites that it should be like this from the smallest to
> the bigest with diff size, i tought it should serve from small size pool
> to high ]
>

In general yes. BUT the size ranges to use should be determined via
traffic analysis. Specifically measure and graph the object sizes being
handled. There will be a wavy / cyclic line resulting. The size
boundaries should be set to the *minimum* point(s) along that line.


That said. Since you are comparing the new rock to an old UFS setup. It
would be best to start with the rock being setup as similar to the UFS
as you can - number of cache_dir, ranges of objects stored there etc.

ie. if these ranges were in the old UFS, then keep them for now. That
can be re-calculated after the HIT ratio drop is identified.


> *****How many independent disk spindles (or equivalent) do you have? [ i
> have one raid 5 ssd disks , used by the 10 rock cache dir]
>

Ouch.

Ideally you would have either:

 5x SSD disks separately mounted. With one rock cache on each.

or,

 1x RAID 10 with one rock cache per disk pair/stripe. This requires
ability for controller to map a sub-directory tree exclusively onto one
of the sub-array stripes.

or,

 2x RAID 1 (drive pair mirroring) with one rock cache on each pair. This
is the simplest way to achieve above when sub-array feature is not
available in RAID 10.

or,

 1x RAID 10 with a single rock cache



The reasons;

Squid I/O pattern is mostly writes and erase. Low on reads.

RAID types in order of best->worst for that pattern are:
  none, RAID 1, RAID 10, RAID 5, RAID 0
<https://wiki.squid-cache.org/SquidFaq/RAID>

Normal SSD controllers cannot handle the Squid I/O pattern well. Squid
*will* age the disk much faster than manufacturer measured statistics
indicate. (True for even HDD, just less of a problem there).

This means that the design needs to plan for coping with relatively
frequent disk failures. Loss of the data itself irrelevant. Only the
outage time + reduction in HIT ratio actually matter on failures.

Look for SSD with high write cycle measurements, and for RAID hot-swap
capability (even if the machine itself cant do that).



> ***How did you select the swap rate limits and timeouts for
> cache_dirs?[I took it also from online forum , can i leave it empty for
> both]
>

Alex may have better ideas if you can refer us to which tutorials or
documents you found that info in.

Without specific details on why they were chosen I would go with one
rock cache with default values to start with. Only changing them if
followup analysis indicates some other value is better.


Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200702/35d47f95/attachment.htm>

From premchand142 at gmail.com  Thu Jul  2 12:59:19 2020
From: premchand142 at gmail.com (Prem Chand)
Date: Thu, 2 Jul 2020 18:29:19 +0530
Subject: [squid-users] Redirect request to cache_peer using username and
	passwords
In-Reply-To: <CACbtF4PP2WOpY0fg+8TmHh5MhQz7T+1LgVw1so17nmZ=1_pANg@mail.gmail.com>
References: <CACbtF4PP2WOpY0fg+8TmHh5MhQz7T+1LgVw1so17nmZ=1_pANg@mail.gmail.com>
Message-ID: <CACbtF4PRB2rWKFkAMnHUoAgYzoxq+nUVAPcEJ5Zf5d5EsC=Ahg@mail.gmail.com>

Hi Amos,

Thanks for the response.

However, what do you want to happen when that user's dedicated peer is
unavailable?
Can it be routed to another peer if a dedicated peer is unavailable?
because each peer is accessed by a different username and password. If
there is an option to route then I will keep a backup peer(Peer4) so if any
one of the peers(Peer1,Peer2,Peer3) is unavailable it can route to the
backup peer and once the unavailable peer become available then traffic
should auto route to them from backup peer.

If there is no option that fits as I explained above then I want to stop
all access for them.

Are you wanting to keep this behaviour?
I don't want to use the round-robin behaviour. I want to route requests to
dedicated Peer/Client.

On Thu, Jul 2, 2020 at 3:19 PM Prem Chand <premchand142 at gmail.com> wrote:

>
> Hi,
>
> I need to redirect my clients requests to different Cache_peers using
> username and passwords through my proxy. Below is the rough sketch. Can
> someone suggest to me how I can achieve this?
>
> Client1(Username1:password1) ->Proxy:443 -> Cache_peer:3218
> Client 2(Username2:password2)->Proxy:443-> Cache_peer:3219
> .
> .
> .
> .
>
> This is my current configuration, I'm doing round robin through
> cache_peers when authenticated with a single username and password in
> /etc/squid/squidpasswdfile file
>
> auth_param basic program /usr/lib64/squid/ncsa_auth
> /etc/squid/squidpasswdfile
> auth_param basic realm proxy
> acl auth_users proxy_auth REQUIRED
> http_access allow auth_users
> http_access deny all
> cache_peer Peer1 parent 3218 0 round-robin no-query weight=1
> connect-fail-limit=1
> cache_peer Peer2 parent 3219 0 round-robin no-query weight=1
> connect-fail-limit=1
> cache_peer Peer3 parent 3219 0 round-robin no-query weight=1
> connect-fail-limit=1
>
> Thanks & Regards
> Premchand.
>


-- 
prem
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200702/5f229db9/attachment.htm>

From rousskov at measurement-factory.com  Thu Jul  2 13:24:03 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 2 Jul 2020 09:24:03 -0400
Subject: [squid-users] rock issue
In-Reply-To: <AM6PR09MB322116222A6AE6E87562B55E916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
References: <AM6PR09MB3221DC6FBC09852FDED01EF4916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <46d7c8ad-4f49-68ad-92f9-537138fca05c@measurement-factory.com>
 <AM6PR09MB322116222A6AE6E87562B55E916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
Message-ID: <945439f5-b10c-63ac-795b-e865128abfab@measurement-factory.com>

On 7/1/20 4:45 PM, patrick mkhael wrote:

> ***Please note that you have 20 kids worth mapping (10 workers and 10
> diskers), but you map only the first 10.?{since i did not get the point
> of the diskers ,as far as i understood? , it should be like? (simple
> example)

>> workers 2
>> cpu_affinity_map process_numbers=1,2,3,4 cores=1,2,3,4
>> cache_dir rock ...
>> cache_dir rock ...

The above looks OK. Each worker is a kid process. Each rock cache_dir is
a kid process (we call them diskers).  If you have physical CPU cores to
spare, give each kid process its own physical core. Otherwise, give each
worker process its own physical core (if you can). Diskers can share
physical cores with less harm because they usually do not consume much
CPU cycles. Squid wiki has more detailed information about that:
https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F


> ***Why do you have 10 rock caches of various sizes??[ to be honest , i
> saw in many websites that it should be like this from the smallest to
> the bigest with diff size, i tought it should serve from small size pool
> to high ]

IMHO, you should stop reading those web pages :-). There is no general
need to segregate objects by sizes, especially when you are using the
same slot size for all cache_dirs. Such segregation may be necessary in
some special cases, but we have not yet established that your case is
special.


> *****How many independent disk spindles (or equivalent) do you have? [ i
> have one raid 5 ssd disks , used by the 10 rock cache dir]

Do not use RAID. If possible, use one rock cache_dir per SSD disk. The
only reason this may not be possible, AFAICT, is if you want to cache
more (per SSD disk) than a single Squid cache_dir can hold, but I would
not worry about overcoming that limit at the beginning. If you want to
know more about the limit, look for "33554431" in
http://www.squid-cache.org/mail-archive/squid-users/201312/0034.html


> ***How did you select the swap rate limits and timeouts for
> cache_dirs?[I took it also from online forum , can i leave it empty for
> both]

If you want a simple answer, then it is "yes". Unfortunately, there is
no simple correct answer to that question. To understand what is going
on and how to tune things, I recommend studying the Performance Tuning
section of https://wiki.squid-cache.org/Features/RockStore


> ****Do you see any ERRORs or WARNINGs in cache log?[NO error or warning
> found in cache]

Good. I assume you do see some regular messages in cache.log. Keep an
eye for ERRORs and WARNINGs as you change settings.


HTH,

Alex.


From squid3 at treenet.co.nz  Thu Jul  2 14:00:40 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 3 Jul 2020 02:00:40 +1200
Subject: [squid-users] Redirect request to cache_peer using username and
	passwords
In-Reply-To: <CACbtF4PRB2rWKFkAMnHUoAgYzoxq+nUVAPcEJ5Zf5d5EsC=Ahg@mail.gmail.com>
References: <CACbtF4PP2WOpY0fg+8TmHh5MhQz7T+1LgVw1so17nmZ=1_pANg@mail.gmail.com>
 <CACbtF4PRB2rWKFkAMnHUoAgYzoxq+nUVAPcEJ5Zf5d5EsC=Ahg@mail.gmail.com>
Message-ID: <0f9e2e8d-e403-9600-9d09-30807cded72a@treenet.co.nz>

On 3/07/20 12:59 am, Prem Chand wrote:
> Hi Amos,
> 
> Thanks for the response.
> 
> However, what do you want to happen when that user's dedicated peer is
> unavailable?
> Can it be routed to another peer if a dedicated peer is unavailable?
> because each peer is accessed by a different username and password. If
> there is an option to route then I will keep a backup peer(Peer4) so if
> any one of the peers(Peer1,Peer2,Peer3) is unavailable it can route to
> the backup peer and once the unavailable peer become available then
> traffic should auto route to them from backup peer.
> 
> If there is no option that fits as I explained above then I want to stop
> all access for them.
> 
> Are you wanting to keep this behaviour?
> I don't want to use the round-robin behaviour. I want to route requests
> to dedicated Peer/Client.
> 


So what you want requires Squid-3.4 or later and looks something like this:


 auth_param ...
 acl authed proxy_auth REQUIRED
 http_access deny !authed
 http_access allow authed

 acl user1 note user username1
 acl user2 note user username2
 acl user3 note user username3

 # per-user peers first (preferred)
 cache_peer peer1 ...
 cache_peer_access peer1 allow user1
 cache_peer_access peer1 deny all

 cache_peer peer2 ...
 cache_peer_access peer2 allow user2
 cache_peer_access peer2 deny all

 cache_peer peer3 ...
 cache_peer_access peer3 allow user3
 cache_peer_access peer3 deny all

 # last peer for any user (if above are unavailable)
 cache_peer peer4 ...
 cache_peer_access allow all

 # forbid DIRECT traffic
 never_direct allow all



HTH
Amos


From patrick.mkhael at hotmail.com  Fri Jul  3 08:50:05 2020
From: patrick.mkhael at hotmail.com (patrick mkhael)
Date: Fri, 3 Jul 2020 08:50:05 +0000
Subject: [squid-users] rock issue
In-Reply-To: <945439f5-b10c-63ac-795b-e865128abfab@measurement-factory.com>
References: <AM6PR09MB3221DC6FBC09852FDED01EF4916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <46d7c8ad-4f49-68ad-92f9-537138fca05c@measurement-factory.com>
 <AM6PR09MB322116222A6AE6E87562B55E916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>,
 <945439f5-b10c-63ac-795b-e865128abfab@measurement-factory.com>
Message-ID: <AM6PR09MB3221808296CA72297AF6748C916A0@AM6PR09MB3221.eurprd09.prod.outlook.com>

Dear Alex,

kindly note that i have adjusted the config , in addition to checking the provided links.
First i have 3 disk with no RAID config, each rock cache_dir has it own disk to write to.
then each disker and worker have it own process. In addition to this i have adjusted some value as per "https://wiki.squid-cache.org/Features/RockStore" recomandation.

Below is the new config:


workers 3
cpu_affinity_map process_numbers=1,2,3,4,5,6 cores=1,2,3,4,5,6
cache_dir rock /rock1 200000 max-size=32000 swap-timeout=300 max-swap-rate=100
cache_dir rock /rock2 200000 max-size=32000 max-swap-rate=100 swap-timeout=300
cache_dir rock /rock3 200000 max-size=32000 max-swap-rate=100 swap-timeout=300
cache_mem 17 GB
maximum_object_size_in_memory 25 MB
maximum_object_size 1 GB
cache_miss_revalidate off
quick_abort_pct 95

This config is giving 4% of cache gain ratio,
in addition as i already mentionned before if i take the same above config without worker and cach_dir with the same traffiic using aufs on one of the disks ,  i have automatically i har 60 % cache ratio. [ my lab i 250 Mb/s]

Shoud rock give me the same performance as aufs ?

for a traffic of 1 Gb/s , is there a way to use aufs ?

thank u


________________________________
From: Alex Rousskov <rousskov at measurement-factory.com>
Sent: Thursday, July 2, 2020 4:24 PM
To: patrick mkhael <patrick.mkhael at hotmail.com>; squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] rock issue

On 7/1/20 4:45 PM, patrick mkhael wrote:

> ***Please note that you have 20 kids worth mapping (10 workers and 10
> diskers), but you map only the first 10.?{since i did not get the point
> of the diskers ,as far as i understood  , it should be like  (simple
> example)

>> workers 2
>> cpu_affinity_map process_numbers=1,2,3,4 cores=1,2,3,4
>> cache_dir rock ...
>> cache_dir rock ...

The above looks OK. Each worker is a kid process. Each rock cache_dir is
a kid process (we call them diskers).  If you have physical CPU cores to
spare, give each kid process its own physical core. Otherwise, give each
worker process its own physical core (if you can). Diskers can share
physical cores with less harm because they usually do not consume much
CPU cycles. Squid wiki has more detailed information about that:
https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F


> ***Why do you have 10 rock caches of various sizes? [ to be honest , i
> saw in many websites that it should be like this from the smallest to
> the bigest with diff size, i tought it should serve from small size pool
> to high ]

IMHO, you should stop reading those web pages :-). There is no general
need to segregate objects by sizes, especially when you are using the
same slot size for all cache_dirs. Such segregation may be necessary in
some special cases, but we have not yet established that your case is
special.


> *****How many independent disk spindles (or equivalent) do you have? [ i
> have one raid 5 ssd disks , used by the 10 rock cache dir]

Do not use RAID. If possible, use one rock cache_dir per SSD disk. The
only reason this may not be possible, AFAICT, is if you want to cache
more (per SSD disk) than a single Squid cache_dir can hold, but I would
not worry about overcoming that limit at the beginning. If you want to
know more about the limit, look for "33554431" in
http://www.squid-cache.org/mail-archive/squid-users/201312/0034.html


> ***How did you select the swap rate limits and timeouts for
> cache_dirs?[I took it also from online forum , can i leave it empty for
> both]

If you want a simple answer, then it is "yes". Unfortunately, there is
no simple correct answer to that question. To understand what is going
on and how to tune things, I recommend studying the Performance Tuning
section of https://wiki.squid-cache.org/Features/RockStore


> ****Do you see any ERRORs or WARNINGs in cache log?[NO error or warning
> found in cache]

Good. I assume you do see some regular messages in cache.log. Keep an
eye for ERRORs and WARNINGs as you change settings.


HTH,

Alex.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200703/52c5bcf5/attachment.htm>

From loucansky.lukas at kjj.cz  Fri Jul  3 17:50:14 2020
From: loucansky.lukas at kjj.cz (=?UTF-8?B?THVrw6HFoSBMb3XEjWFuc2vDvQ==?=)
Date: Fri, 3 Jul 2020 19:50:14 +0200
Subject: [squid-users] rock issue
In-Reply-To: <AM6PR09MB3221808296CA72297AF6748C916A0@AM6PR09MB3221.eurprd09.prod.outlook.com>
References: <AM6PR09MB3221DC6FBC09852FDED01EF4916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <46d7c8ad-4f49-68ad-92f9-537138fca05c@measurement-factory.com>
 <AM6PR09MB322116222A6AE6E87562B55E916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <945439f5-b10c-63ac-795b-e865128abfab@measurement-factory.com>
 <AM6PR09MB3221808296CA72297AF6748C916A0@AM6PR09MB3221.eurprd09.prod.outlook.com>
Message-ID: <c5028d30-815b-0bd3-8f03-afd380844514@kjj.cz>

By my observation while you set workers squid spawns multiples processes 
something like this (example workers = 2, 3 rock cache_dir diskers):

squid parent -> worker 1, worker 2, disker 1, disker 2, disker 3, squid 
smp coordinator

Process names like squid-1 or squid-disk-3 (note process number after dash).

I have more rock cache_dirs with diferent slot-sizes, max and min sizes 
and aufs cache_dir for each of my workers (I'm aware of possible 
multiple copies of cached object).? But I use rock dirs up-to 4MB max 
size (estimated experimental size. Why do you cap max-size to 32000? 
I've seen this https://wiki.squid-cache.org/Features/RockStore, but what 
about large rock 
<https://wiki.squid-cache.org/Features/RockStore>https://wiki.squid-cache.org/Features/LargeRockStore 
<https://wiki.squid-cache.org/Features/LargeRockStore>You have 
maximum_object_size 1 GB vs max-size=3200.

By Store Directory Stats I can clearly see that my 32k-4MB rock 
cache_dir is beeing filled. So how do you compare your hitrate ratios? 
Do you cap object size in your aufs config as well? What do you mean by 
"cache gain ratio"?

LL



From hsmtkk at gmail.com  Fri Jul  3 23:49:57 2020
From: hsmtkk at gmail.com (=?UTF-8?B?5qmL5pys57SY5biM?=)
Date: Sat, 4 Jul 2020 08:49:57 +0900
Subject: [squid-users] squid 5.0.3 Segment Violation when using ssl bump and
	cache peer
Message-ID: <CAAif--oH=Yyf7TbgL+a4eK63bqnScTnc5vigjV_K0Ss=xOEpgg@mail.gmail.com>

I have a problem with squid 5.0.3.

I would like to use "Peering support for SSL-Bump" introduced in squid 5.
http://squid.mirror.colo-serv.net/archive/5/squid-5.0.2-RELEASENOTES.html#ss2.6

I configured this environment using docker-compose.
client -> childproxy -> parentproxy -> server

When I communicated client to server via childproxy and parentproxy,
"Segment Violation" happened and squid exited abnormally.

Do I need any extra configuration to use "Peering support for SSL-Bump" feature?


* squid --version output
Squid Cache: Version 5.0.3
Service Name: squid

This binary uses OpenSSL 1.1.1g  21 Apr 2020. For legal restrictions
on distribution see https://www.openssl.org/source/license.html

configure options:  '--prefix=/usr/local/squid' '--enable-ssl-crtd'
'--disable-optimizations' '--with-openssl=/usr/local/openssl'
--enable-ltdl-convenience

* executed command and its output

$ docker exec client curl -k -x childproxy:3128 https://server/hello.html
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
curl: (35) OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to server:443

* error log

childproxy     | 2020/07/03 22:55:53 kid1| FATAL: Received Segment
Violation...dying.
childproxy     |     current master transaction: master53
childproxy     | 2020/07/03 22:55:53 kid1| Closing HTTP(S) port 0.0.0.0:3128
childproxy     |     current master transaction: master53
childproxy     | 2020/07/03 22:55:53 kid1| storeDirWriteCleanLogs: Starting...
childproxy     |     current master transaction: master53
childproxy     | 2020/07/03 22:55:53 kid1|   Finished.  Wrote 0 entries.
childproxy     |     current master transaction: master53
childproxy     | 2020/07/03 22:55:53 kid1|   Took 0.00 seconds (  0.00
entries/sec).
childproxy     |     current master transaction: master53
childproxy     | CPU Usage: 0.235 seconds = 0.106 user + 0.129 sys
childproxy     | Maximum Resident Size: 600336 KB
childproxy     | Page faults with physical i/o: 0

* core dump backtrace

#0  0x00007f8b433da387 in raise () from /lib64/libc.so.6
#1  0x00007f8b433dba78 in abort () from /lib64/libc.so.6
#2  0x000000000088b4bc in death (sig=11) at tools.cc:359
#3  <signal handler called>
#4  0x00000000009dbd12 in Comm::Connection::getPeer (this=0x0) at
Connection.cc:102
#5  0x00000000009dbed8 in Comm::Connection::connectTimeout (this=0x0,
fwdStart=1593816953) at Connection.cc:143
#6  0x00000000007b1332 in FwdState::connectingTimeout (this=0x2870a48,
conn=...) at FwdState.cc:1381
#7  0x00000000007ae351 in FwdState::establishTunnelThruProxy
(this=0x2870a48, conn=...) at FwdState.cc:850
#8  0x00000000007adba5 in FwdState::__lambda2::operator()
(__closure=0x7ffead0888f0) at FwdState.cc:836
#9  0x00000000007b1ca7 in
FwdState::advanceDestination<FwdState::noteConnection(HappyConnOpener::Answer&)::__lambda2>(const
char *, const Comm::ConnectionPointer &, const FwdState::__lambda2 &)
(this=0x2870a48,
    stepDescription=0xb487f0 "establish tunnel through proxy",
conn=..., startStep=...) at FwdState.cc:777
#10 0x00000000007ae1ca in FwdState::noteConnection (this=0x2870a48,
answer=...) at FwdState.cc:837
#11 0x00000000007b5f64 in HappyConnOpener::CbDialer<FwdState>::dial
(this=0x2871af8) at HappyConnOpener.h:120
#12 0x00000000007b56ed in
AsyncCallT<HappyConnOpener::CbDialer<FwdState> >::fire
(this=0x2871ac0)
    at ../src/base/AsyncCall.h:150
#13 0x000000000096c293 in AsyncCall::make (this=0x2871ac0) at AsyncCall.cc:44
#14 0x000000000096cfca in AsyncCallQueue::fireNext (this=0x23b6ec0) at
AsyncCallQueue.cc:60
#15 0x000000000096cd43 in AsyncCallQueue::fire (this=0x23b6ec0) at
AsyncCallQueue.cc:43
#16 0x000000000079afbf in EventLoop::dispatchCalls
(this=0x7ffead088c80) at EventLoop.cc:144
#17 0x000000000079aee7 in EventLoop::runOnce (this=0x7ffead088c80) at
EventLoop.cc:121
#18 0x000000000079ad4e in EventLoop::run (this=0x7ffead088c80) at
EventLoop.cc:83
#19 0x000000000081ce58 in SquidMain (argc=3, argv=0x7ffead088fb8) at
main.cc:1716
#20 0x000000000081c2c3 in SquidMainSafe (argc=3, argv=0x7ffead088fb8)
at main.cc:1403
#21 0x000000000081c296 in main (argc=3, argv=0x7ffead088fb8) at main.cc:1391

* I submitted all my configs and logs to my github page.
https://github.com/hsmtkk/squid5_sslbump_cachepeer/issues/1


Best regards,
Kouki Hashimoto
hsmtkk at gmail.com
-------------- next part --------------
A non-text attachment was scrubbed...
Name: parent-squid.conf
Type: application/octet-stream
Size: 453 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200704/55a9d257/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: child-squid.conf
Type: application/octet-stream
Size: 551 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200704/55a9d257/attachment-0001.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: child-cache.log
Type: application/octet-stream
Size: 4626 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200704/55a9d257/attachment-0002.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: parent-cache.log
Type: application/octet-stream
Size: 1931 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200704/55a9d257/attachment-0003.obj>

From bjd2385 at aperiodicity.com  Sat Jul  4 00:01:18 2020
From: bjd2385 at aperiodicity.com (Brandon Doyle)
Date: Sat, 4 Jul 2020 00:01:18 +0000
Subject: [squid-users] squid 5.0.3 Segment Violation when using ssl bump
 and	cache peer
In-Reply-To: <CAAif--oH=Yyf7TbgL+a4eK63bqnScTnc5vigjV_K0Ss=xOEpgg@mail.gmail.com>
References: <CAAif--oH=Yyf7TbgL+a4eK63bqnScTnc5vigjV_K0Ss=xOEpgg@mail.gmail.com>
Message-ID: <BL0PR14MB38591C38D670621C697A6EA0DF6B0@BL0PR14MB3859.namprd14.prod.outlook.com>

How do I unsubscribe from this? Been a good couple years, but I'd appreciate some help :)
________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of ???? <hsmtkk at gmail.com>
Sent: Friday, July 3, 2020 7:49:57 PM
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: [squid-users] squid 5.0.3 Segment Violation when using ssl bump and cache peer

I have a problem with squid 5.0.3.

I would like to use "Peering support for SSL-Bump" introduced in squid 5.
http://squid.mirror.colo-serv.net/archive/5/squid-5.0.2-RELEASENOTES.html#ss2.6

I configured this environment using docker-compose.
client -> childproxy -> parentproxy -> server

When I communicated client to server via childproxy and parentproxy,
"Segment Violation" happened and squid exited abnormally.

Do I need any extra configuration to use "Peering support for SSL-Bump" feature?


* squid --version output
Squid Cache: Version 5.0.3
Service Name: squid

This binary uses OpenSSL 1.1.1g  21 Apr 2020. For legal restrictions
on distribution see https://www.openssl.org/source/license.html

configure options:  '--prefix=/usr/local/squid' '--enable-ssl-crtd'
'--disable-optimizations' '--with-openssl=/usr/local/openssl'
--enable-ltdl-convenience

* executed command and its output

$ docker exec client curl -k -x childproxy:3128 https://server/hello.html
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
curl: (35) OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to server:443

* error log

childproxy     | 2020/07/03 22:55:53 kid1| FATAL: Received Segment
Violation...dying.
childproxy     |     current master transaction: master53
childproxy     | 2020/07/03 22:55:53 kid1| Closing HTTP(S) port 0.0.0.0:3128
childproxy     |     current master transaction: master53
childproxy     | 2020/07/03 22:55:53 kid1| storeDirWriteCleanLogs: Starting...
childproxy     |     current master transaction: master53
childproxy     | 2020/07/03 22:55:53 kid1|   Finished.  Wrote 0 entries.
childproxy     |     current master transaction: master53
childproxy     | 2020/07/03 22:55:53 kid1|   Took 0.00 seconds (  0.00
entries/sec).
childproxy     |     current master transaction: master53
childproxy     | CPU Usage: 0.235 seconds = 0.106 user + 0.129 sys
childproxy     | Maximum Resident Size: 600336 KB
childproxy     | Page faults with physical i/o: 0

* core dump backtrace

#0  0x00007f8b433da387 in raise () from /lib64/libc.so.6
#1  0x00007f8b433dba78 in abort () from /lib64/libc.so.6
#2  0x000000000088b4bc in death (sig=11) at tools.cc:359
#3  <signal handler called>
#4  0x00000000009dbd12 in Comm::Connection::getPeer (this=0x0) at
Connection.cc:102
#5  0x00000000009dbed8 in Comm::Connection::connectTimeout (this=0x0,
fwdStart=1593816953) at Connection.cc:143
#6  0x00000000007b1332 in FwdState::connectingTimeout (this=0x2870a48,
conn=...) at FwdState.cc:1381
#7  0x00000000007ae351 in FwdState::establishTunnelThruProxy
(this=0x2870a48, conn=...) at FwdState.cc:850
#8  0x00000000007adba5 in FwdState::__lambda2::operator()
(__closure=0x7ffead0888f0) at FwdState.cc:836
#9  0x00000000007b1ca7 in
FwdState::advanceDestination<FwdState::noteConnection(HappyConnOpener::Answer&)::__lambda2>(const
char *, const Comm::ConnectionPointer &, const FwdState::__lambda2 &)
(this=0x2870a48,
    stepDescription=0xb487f0 "establish tunnel through proxy",
conn=..., startStep=...) at FwdState.cc:777
#10 0x00000000007ae1ca in FwdState::noteConnection (this=0x2870a48,
answer=...) at FwdState.cc:837
#11 0x00000000007b5f64 in HappyConnOpener::CbDialer<FwdState>::dial
(this=0x2871af8) at HappyConnOpener.h:120
#12 0x00000000007b56ed in
AsyncCallT<HappyConnOpener::CbDialer<FwdState> >::fire
(this=0x2871ac0)
    at ../src/base/AsyncCall.h:150
#13 0x000000000096c293 in AsyncCall::make (this=0x2871ac0) at AsyncCall.cc:44
#14 0x000000000096cfca in AsyncCallQueue::fireNext (this=0x23b6ec0) at
AsyncCallQueue.cc:60
#15 0x000000000096cd43 in AsyncCallQueue::fire (this=0x23b6ec0) at
AsyncCallQueue.cc:43
#16 0x000000000079afbf in EventLoop::dispatchCalls
(this=0x7ffead088c80) at EventLoop.cc:144
#17 0x000000000079aee7 in EventLoop::runOnce (this=0x7ffead088c80) at
EventLoop.cc:121
#18 0x000000000079ad4e in EventLoop::run (this=0x7ffead088c80) at
EventLoop.cc:83
#19 0x000000000081ce58 in SquidMain (argc=3, argv=0x7ffead088fb8) at
main.cc:1716
#20 0x000000000081c2c3 in SquidMainSafe (argc=3, argv=0x7ffead088fb8)
at main.cc:1403
#21 0x000000000081c296 in main (argc=3, argv=0x7ffead088fb8) at main.cc:1391

* I submitted all my configs and logs to my github page.
https://github.com/hsmtkk/squid5_sslbump_cachepeer/issues/1


Best regards,
Kouki Hashimoto
hsmtkk at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200704/5938de61/attachment.htm>

From squid3 at treenet.co.nz  Sat Jul  4 00:16:15 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 4 Jul 2020 12:16:15 +1200
Subject: [squid-users] squid 5.0.3 Segment Violation when using ssl bump
 and cache peer
In-Reply-To: <BL0PR14MB38591C38D670621C697A6EA0DF6B0@BL0PR14MB3859.namprd14.prod.outlook.com>
References: <CAAif--oH=Yyf7TbgL+a4eK63bqnScTnc5vigjV_K0Ss=xOEpgg@mail.gmail.com>
 <BL0PR14MB38591C38D670621C697A6EA0DF6B0@BL0PR14MB3859.namprd14.prod.outlook.com>
Message-ID: <6f90a933-a50f-c4fe-a170-2a86a8c0c8e5@treenet.co.nz>

On 4/07/20 12:01 pm, Brandon Doyle wrote:
> How do I unsubscribe from this? Been a good couple years, but I'd
> appreciate some help :)

List subscriptions are managed at
<http://lists.squid-cache.org/options/squid-users>.

I have initiated the process. There should be a confirmation email in
your mailbox by now, just follow the instructions it contains.


Amos


From rousskov at measurement-factory.com  Sat Jul  4 00:40:07 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 3 Jul 2020 20:40:07 -0400
Subject: [squid-users] rock issue
In-Reply-To: <AM6PR09MB3221808296CA72297AF6748C916A0@AM6PR09MB3221.eurprd09.prod.outlook.com>
References: <AM6PR09MB3221DC6FBC09852FDED01EF4916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <46d7c8ad-4f49-68ad-92f9-537138fca05c@measurement-factory.com>
 <AM6PR09MB322116222A6AE6E87562B55E916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <945439f5-b10c-63ac-795b-e865128abfab@measurement-factory.com>
 <AM6PR09MB3221808296CA72297AF6748C916A0@AM6PR09MB3221.eurprd09.prod.outlook.com>
Message-ID: <b1419b5e-ab29-3ad9-7e6c-6fc144a15354@measurement-factory.com>

On 7/3/20 4:50 AM, patrick mkhael wrote:

> workers 3
> cpu_affinity_map process_numbers=1,2,3,4,5,6 cores=1,2,3,4,5,6
> cache_dir rock /rock1 200000 max-size=32000 swap-timeout=300 max-swap-rate=100
> cache_dir rock /rock2 200000 max-size=32000 max-swap-rate=100 swap-timeout=300
> cache_dir rock /rock3 200000 max-size=32000 max-swap-rate=100 swap-timeout=300
> cache_mem 17 GB
> maximum_object_size_in_memory 25 MB
> maximum_object_size 1 GB
> cache_miss_revalidate off
> quick_abort_pct 95


FYI: The combination of 1GB maximum_object_size and much smaller size
limits for objects in memory and disk caches does not make sense: There
is no cache to store a, say, 26MB object. If Squid lacks the
corresponding configuration "lint" check, somebody should add it.


> This config is giving 4% of cache gain ratio,?

> in addition as i already mentionned before if i take the same above
> config without worker and cach_dir with the same traffiic using aufs on
> one of the disks ,? i have automatically i har 60 % cache ratio.

When using AUFS, do you limit disk-cached object sizes to 32KB like you
do with rock? If not, then you should remove the max-size limit from
rock cache_dirs. Modern rock cache_dirs are capable of storing large
objects.

What kind of hit ratio do you get with rock if you do not limit
swap-rate and do not specify swap-timeout?

What kind of hit ratio do you get with rock if you use one worker, one
rock cache_dir, do not limit swap-rate, do not specify swap-timeout, and
start Squid with -N to disable SMP?

As you can see, I am trying to understand whether the size limitation,
the rate limiting, or SMP problems explain the drop in hit ratio.


> Shoud rock give me the same performance as aufs ?

It is a difficult question to answer correctly (for me). The goal is for
rock performance to exceed that of (a)ufs, but I doubt we have reached
that goal in every environment that matters (including yours).

* In a non-SMP environment, I would expect similar hit ratios in most
cases, but I would not be surprised if there are significant exceptions.
Rock is focused on SMP support, and there are complexities/costs
associated with SMP. Rock is getting better, but there are some known
areas where rock cannot yet do what ufs (including aufs) can.

* In a SMP environment, the question is mostly meaningless because there
is no SMP support for ufs-based caches. Folks use squid.conf
preprocessor hacks to configure ufs-based caches in SMP mode, but those
setups usually violate HTTP and may cause serious problems. YMMV.


> for a traffic of 1 Gb/s , is there a way to use aufs ?

Before trying unsupported combinations of aufs and SMP, I would try to
understand why your hit ratio is so low with rock. The questions above
may be a good start in that investigation.


Cheers,

Alex.


> ------------------------------------------------------------------------
> *From:* Alex Rousskov <rousskov at measurement-factory.com>
> *Sent:* Thursday, July 2, 2020 4:24 PM
> *To:* patrick mkhael <patrick.mkhael at hotmail.com>;
> squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
> *Subject:* Re: [squid-users] rock issue
> ?
> On 7/1/20 4:45 PM, patrick mkhael wrote:
> 
>> ***Please note that you have 20 kids worth mapping (10 workers and 10
>> diskers), but you map only the first 10.?{since i did not get the point
>> of the diskers ,as far as i understood? , it should be like? (simple
>> example)
> 
>>> workers 2
>>> cpu_affinity_map process_numbers=1,2,3,4 cores=1,2,3,4
>>> cache_dir rock ...
>>> cache_dir rock ...
> 
> The above looks OK. Each worker is a kid process. Each rock cache_dir is
> a kid process (we call them diskers).? If you have physical CPU cores to
> spare, give each kid process its own physical core. Otherwise, give each
> worker process its own physical core (if you can). Diskers can share
> physical cores with less harm because they usually do not consume much
> CPU cycles. Squid wiki has more detailed information about that:
> https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F
> 
> 
>> ***Why do you have 10 rock caches of various sizes??[ to be honest , i
>> saw in many websites that it should be like this from the smallest to
>> the bigest with diff size, i tought it should serve from small size pool
>> to high ]
> 
> IMHO, you should stop reading those web pages :-). There is no general
> need to segregate objects by sizes, especially when you are using the
> same slot size for all cache_dirs. Such segregation may be necessary in
> some special cases, but we have not yet established that your case is
> special.
> 
> 
>> *****How many independent disk spindles (or equivalent) do you have? [ i
>> have one raid 5 ssd disks , used by the 10 rock cache dir]
> 
> Do not use RAID. If possible, use one rock cache_dir per SSD disk. The
> only reason this may not be possible, AFAICT, is if you want to cache
> more (per SSD disk) than a single Squid cache_dir can hold, but I would
> not worry about overcoming that limit at the beginning. If you want to
> know more about the limit, look for "33554431" in
> http://www.squid-cache.org/mail-archive/squid-users/201312/0034.html
> 
> 
>> ***How did you select the swap rate limits and timeouts for
>> cache_dirs?[I took it also from online forum , can i leave it empty for
>> both]
> 
> If you want a simple answer, then it is "yes". Unfortunately, there is
> no simple correct answer to that question. To understand what is going
> on and how to tune things, I recommend studying the Performance Tuning
> section of https://wiki.squid-cache.org/Features/RockStore
> 
> 
>> ****Do you see any ERRORs or WARNINGs in cache log?[NO error or warning
>> found in cache]
> 
> Good. I assume you do see some regular messages in cache.log. Keep an
> eye for ERRORs and WARNINGs as you change settings.
> 
> 
> HTH,
> 
> Alex.



From rousskov at measurement-factory.com  Sat Jul  4 00:59:08 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 3 Jul 2020 20:59:08 -0400
Subject: [squid-users] squid 5.0.3 Segment Violation when using ssl bump
 and cache peer
In-Reply-To: <CAAif--oH=Yyf7TbgL+a4eK63bqnScTnc5vigjV_K0Ss=xOEpgg@mail.gmail.com>
References: <CAAif--oH=Yyf7TbgL+a4eK63bqnScTnc5vigjV_K0Ss=xOEpgg@mail.gmail.com>
Message-ID: <091fa965-6a56-036e-e3d1-5d3ccd1b069b@measurement-factory.com>

On 7/3/20 7:49 PM, ???? wrote:
> I have a problem with squid 5.0.3.
> 
> I would like to use "Peering support for SSL-Bump" introduced in squid 5.
> http://squid.mirror.colo-serv.net/archive/5/squid-5.0.2-RELEASENOTES.html#ss2.6
> 
> I configured this environment using docker-compose.
> client -> childproxy -> parentproxy -> server
> 
> When I communicated client to server via childproxy and parentproxy,
> "Segment Violation" happened and squid exited abnormally.

You need Squid v5 commit 056ad44 or the corresponding patch:
https://github.com/squid-cache/squid/commit/056ad44.patch

FTR, the commit message lies about the second case being benign. I must
have looked at the wrong code base when writing that description. Sorry.
Both cases are deadly.


> Do I need any extra configuration to use "Peering support for SSL-Bump" feature?

I do not think so.


HTH,

Alex.


> Squid Cache: Version 5.0.3

> #0  0x00007f8b433da387 in raise () from /lib64/libc.so.6
> #1  0x00007f8b433dba78 in abort () from /lib64/libc.so.6
> #2  0x000000000088b4bc in death (sig=11) at tools.cc:359
> #3  <signal handler called>
> #4  0x00000000009dbd12 in Comm::Connection::getPeer (this=0x0) at
> Connection.cc:102
> #5  0x00000000009dbed8 in Comm::Connection::connectTimeout (this=0x0,
> fwdStart=1593816953) at Connection.cc:143
> #6  0x00000000007b1332 in FwdState::connectingTimeout (this=0x2870a48,
> conn=...) at FwdState.cc:1381
> #7  0x00000000007ae351 in FwdState::establishTunnelThruProxy
> (this=0x2870a48, conn=...) at FwdState.cc:850
> #8  0x00000000007adba5 in FwdState::__lambda2::operator()
> (__closure=0x7ffead0888f0) at FwdState.cc:836
> #9  0x00000000007b1ca7 in
> FwdState::advanceDestination<FwdState::noteConnection(HappyConnOpener::Answer&)::__lambda2>(const
> char *, const Comm::ConnectionPointer &, const FwdState::__lambda2 &)
> (this=0x2870a48,
>     stepDescription=0xb487f0 "establish tunnel through proxy",
> conn=..., startStep=...) at FwdState.cc:777
> #10 0x00000000007ae1ca in FwdState::noteConnection (this=0x2870a48,
> answer=...) at FwdState.cc:837
> #11 0x00000000007b5f64 in HappyConnOpener::CbDialer<FwdState>::dial
> (this=0x2871af8) at HappyConnOpener.h:120
> #12 0x00000000007b56ed in
> AsyncCallT<HappyConnOpener::CbDialer<FwdState> >::fire
> (this=0x2871ac0)
>     at ../src/base/AsyncCall.h:150
> #13 0x000000000096c293 in AsyncCall::make (this=0x2871ac0) at AsyncCall.cc:44
> #14 0x000000000096cfca in AsyncCallQueue::fireNext (this=0x23b6ec0) at
> AsyncCallQueue.cc:60
> #15 0x000000000096cd43 in AsyncCallQueue::fire (this=0x23b6ec0) at
> AsyncCallQueue.cc:43
> #16 0x000000000079afbf in EventLoop::dispatchCalls
> (this=0x7ffead088c80) at EventLoop.cc:144
> #17 0x000000000079aee7 in EventLoop::runOnce (this=0x7ffead088c80) at
> EventLoop.cc:121
> #18 0x000000000079ad4e in EventLoop::run (this=0x7ffead088c80) at
> EventLoop.cc:83
> #19 0x000000000081ce58 in SquidMain (argc=3, argv=0x7ffead088fb8) at
> main.cc:1716
> #20 0x000000000081c2c3 in SquidMainSafe (argc=3, argv=0x7ffead088fb8)
> at main.cc:1403
> #21 0x000000000081c296 in main (argc=3, argv=0x7ffead088fb8) at main.cc:1391


From hsmtkk at gmail.com  Sat Jul  4 22:34:37 2020
From: hsmtkk at gmail.com (=?UTF-8?B?5qmL5pys57SY5biM?=)
Date: Sun, 5 Jul 2020 07:34:37 +0900
Subject: [squid-users] squid 5.0.3 Segment Violation when using ssl bump
 and cache peer
In-Reply-To: <091fa965-6a56-036e-e3d1-5d3ccd1b069b@measurement-factory.com>
References: <CAAif--oH=Yyf7TbgL+a4eK63bqnScTnc5vigjV_K0Ss=xOEpgg@mail.gmail.com>
 <091fa965-6a56-036e-e3d1-5d3ccd1b069b@measurement-factory.com>
Message-ID: <CAAif--r0DheaOtm1TGiKk1wfU6c6o4PexReR=zAEAi6NeP98SA@mail.gmail.com>

Thank you Alex.

> You need Squid v5 commit 056ad44 or the corresponding patch:
> https://github.com/squid-cache/squid/commit/056ad44.patch

The patch solved the problem.
I compiled squid from the latest github source v5 branch.
Now the client can communicate the server through childproxy and
parentproxy with ssl bump.

Best regards,
Kouki Hashimoto
hsmtkk at gmail.com


From tarotapprentice at yahoo.com  Sun Jul  5 01:30:50 2020
From: tarotapprentice at yahoo.com (TarotApprentice)
Date: Sun, 5 Jul 2020 11:30:50 +1000
Subject: [squid-users] [squid-announce] [ADVISORY] SQUID-2020:7 Cache
	Poisoning Issue in HTTP Request processing
In-Reply-To: <bdbf8f6f-01b0-48c0-0446-ae409a4c19dd@treenet.co.nz>
References: <bdbf8f6f-01b0-48c0-0446-ae409a4c19dd@treenet.co.nz>
Message-ID: <45A9AD9C-6202-4831-8107-420AF13EFA8D@yahoo.com>

Debian bug 964283 raised. If you are talking to the Debian security team you might want to discuss pushing it into buster with one of their point releases.

MarkJ

> On 28 Jun 2020, at 12:57 am, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> ?On 28/06/20 2:27 am, TarotApprentice wrote:
>> Any plans to get this into Debian, or if they?ll apply the patch to 4.11?
>> 
> 
> v4.12 package is already being worked on. I'm not sure of ETA though,
> its already taken longer than usual.
> 
> Can't speak for the security team about the stable Debian packages.
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From ben.goz87 at gmail.com  Sun Jul  5 11:38:49 2020
From: ben.goz87 at gmail.com (Ben Goz)
Date: Sun, 5 Jul 2020 14:38:49 +0300
Subject: [squid-users] Bypass squid using iptables
In-Reply-To: <47a37011-2a32-bb50-0687-3d81ae7c8066@treenet.co.nz>
References: <CADAqQfwdpUJ8SQgdrJEczvmtr=SgcvffH_pq+swwx+ay5-fyCA@mail.gmail.com>
 <915a225e-022f-70a1-d48a-cbdcd2b3b478@treenet.co.nz>
 <CADAqQfwT599AKw71B9QZuCV58EmzATqPDkzvX14NciE6XVMobA@mail.gmail.com>
 <47a37011-2a32-bb50-0687-3d81ae7c8066@treenet.co.nz>
Message-ID: <CADAqQfyYquExjQfLNxOmO_8+KAiUmmE4p1Xop=rRM07ypZSYRg@mail.gmail.com>

B.H
Sorry I tried this and it doesn't work.
Any other suggestions please?

??????? ??? ??, 25 ???? 2020 ?-13:40 ??? ?Amos Jeffries?? <?
squid3 at treenet.co.nz??>:?

> On 25/05/20 10:09 pm, Ben Goz wrote:
> > B.H
> >>Tunneling it elsewhere,
> > Where can I tunnel it? and how can I configure my machine to support it?
> >
>
> You will need at least Squid-4, with this line in squid.conf:
>
>   on_unsupported_protocol tunnel
>
> see also <http://www.squid-cache.org/Doc/config/on_unsupported_protocol/>
>
> Squid will blindly tunnel the protocols it does not understand to
> whatever server IP:port the client was trying to connect to.
>
>
> Amos
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200705/af45ae2a/attachment.htm>

From ngtech1ltd at gmail.com  Sun Jul  5 16:57:59 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Sun, 5 Jul 2020 19:57:59 +0300
Subject: [squid-users] Squid memory consumption problem
In-Reply-To: <AM5PR0102MB2756FCFC8EC86E26D166441C936F0@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
References: <AM5PR0102MB27564C95912983EA0E6401E493860@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>,
 <7c81730e-64f4-24d7-e540-c027fb2c2b77@measurement-factory.com>
 <5967FC66-09A7-44AE-869B-9C6299D84F48@hxcore.ol>,
 <AM5PR0102MB27563FE044CFA5B57138F1B093830@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
 <D130E594-17F6-4833-BB7A-9622A531441C@hxcore.ol>,
 <AM5PR0102MB27569DC251607D12468B0D2B93830@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
 <F2702CF4-D5C3-46CE-914E-BD6A5843852C@hxcore.ol>,
 <AM5PR0102MB27560AE240283C7DAC58648C93800@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
 <4C837D1A-C7A1-44FC-B591-2F404173539A@hxcore.ol>,
 <AM5PR0102MB275689506D68A171E4EF245E939D0@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
 <22186F7E-2BC4-44CD-940A-02072A2D92E6@hxcore.ol>,
 <AM5PR0102MB2756B10588909C4F4635B23A93980@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
 <B2FC1ADC-2403-4FD8-936C-C830DD22AFB3@hxcore.ol>
 <AM5PR0102MB2756AE61B5D0035049B9BC7993920@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>,
 <AM5PR0102MB2
 756A4397BC6A6C95B4CACDC93920@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
 <13040F9E-CAF9-4E99-B0F6-ED8927C72545@hxcore.ol>,
 <VI1PR0102MB2767221111907FD0278DC0E4936F0@VI1PR0102MB2767.eurprd01.prod.exchangelabs.com>,
 <8D009722-1EF8-4648-B77E-A7060F3F7D24@hxcore.ol>
 <8B3071BC-5B3C-426B-B38D-688ED3C311B6@hxcore.ol>
 <AM5PR0102MB2756C2EB1208B52C586DA670936F0@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
 <AM5PR0102MB2756FCFC8EC86E26D166441C936F0@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAEGQtNYT0SBEjroouRDlGygigQAAEAAAACDLHcf9RhBKhXcoQQ6TGB4BAAAAAA==@gmail.com>

Hey,

 

What happen with this issue?

I am waiting for any input about this issue to understand with what I can try to help.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com

 

From: DIXIT Ankit [mailto:Ankit.Dixit at eurostar.com] 
Sent: Tuesday, June 30, 2020 12:35 PM
To: Eliezer Croitoru; Squid Users
Cc: SETHI Konica
Subject: RE: [squid-users] Squid memory consumption problem

 

For your information, we have added below configurations but again same issue.

 

tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

 

tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: DIXIT Ankit 
Sent: Tuesday, June 30, 2020 10:25 AM
To: Eliezer Croitoru <ngtech1ltd at gmail.com>; Squid Users <squid-users at lists.squid-cache.org>
Cc: SETHI Konica <Konica.Sethi at eurostar.com>
Subject: RE: [squid-users] Squid memory consumption problem

 

Eliezer,

 

Clients are facing some SSL related issues after upgrade. I could see below error. Please suggest, its little urgent.

 

quid[6706]: Error negotiating SSL connection on FD 167: error:00000001:lib(0):func(0):reason(1) (1/0)
Jun 30 09:17:38 squid[6706]: Error parsing SSL Server Hello Message on FD 77
Jun 30 09:17:38 squid[6706]: Error negotiating SSL connection on FD 75: error:00000001:lib(0):func(0):reason(1) (1/0)

 

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: Eliezer Croitoru <ngtech1ltd at gmail.com> 
Sent: Tuesday, June 30, 2020 9:10 AM
To: Squid Users <squid-users at lists.squid-cache.org>; DIXIT Ankit <Ankit.Dixit at eurostar.com>
Subject: RE: [squid-users] Squid memory consumption problem

 




 

The first thing to do is look at:

https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery

 

It should clear couple doubts for you.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com

 

From: DIXIT Ankit <mailto:Ankit.Dixit at eurostar.com> 
Sent: Tuesday, June 30, 2020 10:46 AM
To: Eliezer Croitoru <mailto:ngtech1ltd at gmail.com> ; Alex Rousskov <mailto:rousskov at measurement-factory.com> ; squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Squid memory consumption problem

 

Elizer,

 

We installed Squid 4.12 on production server, amazon Linux 2, successfully but I could see below messages in the logs for SECURITY ALERT: Host header forgery detected. These are getting generated very frequently.

Can we ignore this Or is it advised to suppress these alerts?

 

kid2| SECURITY ALERT: on URL: 5-25-3-app.agent.datadoghq.com:443

2020/06/30 07:41:29 kid1| SECURITY ALERT: Host header forgery detected on local=IP remote=IP FD 97 flags=33 (local IP does not match any domain IP)

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

 

  _____  

This email (including any attachments) is intended only for the addressee(s), is confidential and may be legally privileged. If you are not the intended recipient, do not use, disclose, copy, or forward this email. Please notify the sender immediately and then delete it. Eurostar International Limited and its affiliates ("EIL") do not accept any liability for action taken in reliance on this email. EIL makes no representation that this email is free of viruses and addressees should check this email for viruses. The comments or statements expressed in this email are not necessarily those of EIL. 

Eurostar International Ltd 
Times House, Bravingtons Walk, London N1 9AW Registered in England and Wales No. 2462001 

  _____  

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200705/6148148c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.jpg
Type: image/jpeg
Size: 19517 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200705/6148148c/attachment.jpg>

From antonino.sanacori at unibs.it  Mon Jul  6 09:50:37 2020
From: antonino.sanacori at unibs.it (Antonino Gianfranco Sanacori)
Date: Mon, 6 Jul 2020 11:50:37 +0200
Subject: [squid-users] ERROR: helper
Message-ID: <c300e6a5-563b-e38a-3620-81c9d1a920e0@unibs.it>

Hi all.

In my cache.log i try very very much messages of this:

kid1| ERROR: helper: {result=*BH*, notes={message: Success; }}, attempt 
#1 of 2
kid1| ERROR: helper: {result=*BH*, notes={message: Success; message: 
Success; }}, attempt #2 of 2

I? runned the comand "squid -k parse" and i got? the following messages:

Processing: ssl_bump splice whitelist
ERROR: 'ssl_bump' requires --with-openssl

Is it possible that the helper error messages derive from incorrect 
configuration of? my directive ssl_bump? configuration? I use "ssl_bump 
splice whitelist" to tunnel ssl traffic on some external domains.

Many thanks.

Antonino



-- 


Informativa sulla Privacy: http://www.unibs.it/node/8155 
<http://www.unibs.it/node/8155>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200706/7ed0dd9c/attachment.htm>

From uhlar at fantomas.sk  Mon Jul  6 10:02:05 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 6 Jul 2020 12:02:05 +0200
Subject: [squid-users] ERROR: helper
In-Reply-To: <c300e6a5-563b-e38a-3620-81c9d1a920e0@unibs.it>
References: <c300e6a5-563b-e38a-3620-81c9d1a920e0@unibs.it>
Message-ID: <20200706100205.GA6185@fantomas.sk>

On 06.07.20 11:50, Antonino Gianfranco Sanacori wrote:
>In my cache.log i try very very much messages of this:
>
>kid1| ERROR: helper: {result=*BH*, notes={message: Success; }}, 
>attempt #1 of 2
>kid1| ERROR: helper: {result=*BH*, notes={message: Success; message: 
>Success; }}, attempt #2 of 2
>
>I? runned the comand "squid -k parse" and i got? the following messages:
>
>Processing: ssl_bump splice whitelist
>ERROR: 'ssl_bump' requires --with-openssl
>
>Is it possible that the helper error messages derive from incorrect 
>configuration of? my directive ssl_bump? configuration? I use 
>"ssl_bump splice whitelist" to tunnel ssl traffic on some external 
>domains.

your squid instance was not compiled with SSL support.  If you are running a
distro like debian or ubuntu, you will need to compile it yourself.


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
(R)etry, (A)bort, (C)ancer


From premchand142 at gmail.com  Mon Jul  6 10:30:05 2020
From: premchand142 at gmail.com (Prem Chand)
Date: Mon, 6 Jul 2020 16:00:05 +0530
Subject: [squid-users] Redirect request to cache_peer using username and
	passwords
In-Reply-To: <CACbtF4PRB2rWKFkAMnHUoAgYzoxq+nUVAPcEJ5Zf5d5EsC=Ahg@mail.gmail.com>
References: <CACbtF4PP2WOpY0fg+8TmHh5MhQz7T+1LgVw1so17nmZ=1_pANg@mail.gmail.com>
 <CACbtF4PRB2rWKFkAMnHUoAgYzoxq+nUVAPcEJ5Zf5d5EsC=Ahg@mail.gmail.com>
Message-ID: <CACbtF4Nhm38pJk=o_9ohAkAcshf0t9Y_5+E5ZkEop6rPf4yJpQ@mail.gmail.com>

Hi Amos,

I tried the configuration that you suggested but I'm getting below error.
It seems the requests are not getting forward to cache_peer. I'm unable to
figure out what is the cause of the issue. If I revert it to my previous
configuration I'm not seeing any issue with  cache_peer's.

** Establish HTTP proxy tunnel to www.google.com:443
* Proxy auth using Basic with user 'username1'
> CONNECT www.google.com:443 HTTP/1.1
> Host: www.google.com:443
> Proxy-Authorization: Basic bGluZTE6dGVzdGluZw==
> User-Agent: curl/7.58.0
> Proxy-Connection: Keep-Alive
>
< HTTP/1.1 503 Service Unavailable
< Server: squid/3.5.27
< Mime-Version: 1.0
< Date: Mon, 06 Jul 2020 10:24:28 GMT
< Content-Type: text/html;charset=utf-8
< Content-Length: 3905
< X-Squid-Error: ERR_CANNOT_FORWARD 0
< Vary: Accept-Language
< Content-Language: en
<
* Received HTTP code 503 from proxy after CONNECT
* CONNECT phase completed!
* Closing connection 0
curl: (56) Received HTTP code 503 from proxy after CONNECT

On Thu, Jul 2, 2020 at 6:29 PM Prem Chand <premchand142 at gmail.com> wrote:

> Hi Amos,
>
> Thanks for the response.
>
> However, what do you want to happen when that user's dedicated peer is
> unavailable?
> Can it be routed to another peer if a dedicated peer is unavailable?
> because each peer is accessed by a different username and password. If
> there is an option to route then I will keep a backup peer(Peer4) so if any
> one of the peers(Peer1,Peer2,Peer3) is unavailable it can route to the
> backup peer and once the unavailable peer become available then traffic
> should auto route to them from backup peer.
>
> If there is no option that fits as I explained above then I want to stop
> all access for them.
>
> Are you wanting to keep this behaviour?
> I don't want to use the round-robin behaviour. I want to route requests to
> dedicated Peer/Client.
>
> On Thu, Jul 2, 2020 at 3:19 PM Prem Chand <premchand142 at gmail.com> wrote:
>
>>
>> Hi,
>>
>> I need to redirect my clients requests to different Cache_peers using
>> username and passwords through my proxy. Below is the rough sketch. Can
>> someone suggest to me how I can achieve this?
>>
>> Client1(Username1:password1) ->Proxy:443 -> Cache_peer:3218
>> Client 2(Username2:password2)->Proxy:443-> Cache_peer:3219
>> .
>> .
>> .
>> .
>>
>> This is my current configuration, I'm doing round robin through
>> cache_peers when authenticated with a single username and password in
>> /etc/squid/squidpasswdfile file
>>
>> auth_param basic program /usr/lib64/squid/ncsa_auth
>> /etc/squid/squidpasswdfile
>> auth_param basic realm proxy
>> acl auth_users proxy_auth REQUIRED
>> http_access allow auth_users
>> http_access deny all
>> cache_peer Peer1 parent 3218 0 round-robin no-query weight=1
>> connect-fail-limit=1
>> cache_peer Peer2 parent 3219 0 round-robin no-query weight=1
>> connect-fail-limit=1
>> cache_peer Peer3 parent 3219 0 round-robin no-query weight=1
>> connect-fail-limit=1
>>
>> Thanks & Regards
>> Premchand.
>>
>
>
> --
> prem
>


-- 
prem
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200706/abc3cc2d/attachment.htm>

From premchand142 at gmail.com  Mon Jul  6 15:58:30 2020
From: premchand142 at gmail.com (Prem Chand)
Date: Mon, 6 Jul 2020 21:28:30 +0530
Subject: [squid-users] Redirect request to cache_peer using username and
	passwords
In-Reply-To: <CACbtF4Nhm38pJk=o_9ohAkAcshf0t9Y_5+E5ZkEop6rPf4yJpQ@mail.gmail.com>
References: <CACbtF4PP2WOpY0fg+8TmHh5MhQz7T+1LgVw1so17nmZ=1_pANg@mail.gmail.com>
 <CACbtF4PRB2rWKFkAMnHUoAgYzoxq+nUVAPcEJ5Zf5d5EsC=Ahg@mail.gmail.com>
 <CACbtF4Nhm38pJk=o_9ohAkAcshf0t9Y_5+E5ZkEop6rPf4yJpQ@mail.gmail.com>
Message-ID: <CACbtF4Pq8EOBQijBzvD3BXMh7MQuSHHqfei8m06+BbybxDOWfg@mail.gmail.com>

Hi Amos,

On further digging I understood that acl route  via cache_peer_access
(cache_peer_access  Peer1 allow user1)  is not working hence requests are
failing. I'm not sure the exact reason. Can you please suggest how to fix
this?

acl user1 note user username1
cache_peer Peer1 parent 3218 0 round-robin no-query weight=1
connect-fail-limit=1 name=Peer1
cache_peer_access  Peer1 allow user1
cache_peer_access deny all


On Mon, Jul 6, 2020 at 4:00 PM Prem Chand <premchand142 at gmail.com> wrote:

> Hi Amos,
>
> I tried the configuration that you suggested but I'm getting below error.
> It seems the requests are not getting forward to cache_peer. I'm unable to
> figure out what is the cause of the issue. If I revert it to my previous
> configuration I'm not seeing any issue with  cache_peer's.
>
> ** Establish HTTP proxy tunnel to www.google.com:443
> * Proxy auth using Basic with user 'username1'
> > CONNECT www.google.com:443 HTTP/1.1
> > Host: www.google.com:443
> > Proxy-Authorization: Basic bGluZTE6dGVzdGluZw==
> > User-Agent: curl/7.58.0
> > Proxy-Connection: Keep-Alive
> >
> < HTTP/1.1 503 Service Unavailable
> < Server: squid/3.5.27
> < Mime-Version: 1.0
> < Date: Mon, 06 Jul 2020 10:24:28 GMT
> < Content-Type: text/html;charset=utf-8
> < Content-Length: 3905
> < X-Squid-Error: ERR_CANNOT_FORWARD 0
> < Vary: Accept-Language
> < Content-Language: en
> <
> * Received HTTP code 503 from proxy after CONNECT
> * CONNECT phase completed!
> * Closing connection 0
> curl: (56) Received HTTP code 503 from proxy after CONNECT
>
> On Thu, Jul 2, 2020 at 6:29 PM Prem Chand <premchand142 at gmail.com> wrote:
>
>> Hi Amos,
>>
>> Thanks for the response.
>>
>> However, what do you want to happen when that user's dedicated peer is
>> unavailable?
>> Can it be routed to another peer if a dedicated peer is unavailable?
>> because each peer is accessed by a different username and password. If
>> there is an option to route then I will keep a backup peer(Peer4) so if any
>> one of the peers(Peer1,Peer2,Peer3) is unavailable it can route to the
>> backup peer and once the unavailable peer become available then traffic
>> should auto route to them from backup peer.
>>
>> If there is no option that fits as I explained above then I want to stop
>> all access for them.
>>
>> Are you wanting to keep this behaviour?
>> I don't want to use the round-robin behaviour. I want to route requests
>> to dedicated Peer/Client.
>>
>> On Thu, Jul 2, 2020 at 3:19 PM Prem Chand <premchand142 at gmail.com> wrote:
>>
>>>
>>> Hi,
>>>
>>> I need to redirect my clients requests to different Cache_peers using
>>> username and passwords through my proxy. Below is the rough sketch. Can
>>> someone suggest to me how I can achieve this?
>>>
>>> Client1(Username1:password1) ->Proxy:443 -> Cache_peer:3218
>>> Client 2(Username2:password2)->Proxy:443-> Cache_peer:3219
>>> .
>>> .
>>> .
>>> .
>>>
>>> This is my current configuration, I'm doing round robin through
>>> cache_peers when authenticated with a single username and password in
>>> /etc/squid/squidpasswdfile file
>>>
>>> auth_param basic program /usr/lib64/squid/ncsa_auth
>>> /etc/squid/squidpasswdfile
>>> auth_param basic realm proxy
>>> acl auth_users proxy_auth REQUIRED
>>> http_access allow auth_users
>>> http_access deny all
>>> cache_peer Peer1 parent 3218 0 round-robin no-query weight=1
>>> connect-fail-limit=1
>>> cache_peer Peer2 parent 3219 0 round-robin no-query weight=1
>>> connect-fail-limit=1
>>> cache_peer Peer3 parent 3219 0 round-robin no-query weight=1
>>> connect-fail-limit=1
>>>
>>> Thanks & Regards
>>> Premchand.
>>>
>>
>>
>> --
>> prem
>>
>
>
> --
> prem
>


-- 
prem
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200706/524e9be6/attachment.htm>

From ngtech1ltd at gmail.com  Mon Jul  6 16:20:19 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Mon, 6 Jul 2020 19:20:19 +0300
Subject: [squid-users] [squid-announce] [ADVISORY] SQUID-2020:7 Cache
	Poisoning Issue in HTTP Request processing
In-Reply-To: <45A9AD9C-6202-4831-8107-420AF13EFA8D@yahoo.com>
References: <bdbf8f6f-01b0-48c0-0446-ae409a4c19dd@treenet.co.nz>
 <45A9AD9C-6202-4831-8107-420AF13EFA8D@yahoo.com>
Message-ID: <007801d653b1$58bf30d0$0a3d9270$@gmail.com>

If someone need I can try to compile a Debian Buster compatible binary as a drop in replacement.

Eliezer

----
Eliezer Croitoru
Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of TarotApprentice
Sent: Sunday, July 5, 2020 4:31 AM
To: Squid Users
Subject: Re: [squid-users] [squid-announce] [ADVISORY] SQUID-2020:7 Cache Poisoning Issue in HTTP Request processing

Debian bug 964283 raised. If you are talking to the Debian security team you might want to discuss pushing it into buster with one of their point releases.

MarkJ

> On 28 Jun 2020, at 12:57 am, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> ?On 28/06/20 2:27 am, TarotApprentice wrote:
>> Any plans to get this into Debian, or if they?ll apply the patch to 4.11?
>> 
> 
> v4.12 package is already being worked on. I'm not sure of ETA though,
> its already taken longer than usual.
> 
> Can't speak for the security team about the stable Debian packages.
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From premchand142 at gmail.com  Mon Jul  6 16:59:14 2020
From: premchand142 at gmail.com (Prem Chand)
Date: Mon, 6 Jul 2020 22:29:14 +0530
Subject: [squid-users] Redirect request to cache_peer using username and
	passwords
In-Reply-To: <CACbtF4Pq8EOBQijBzvD3BXMh7MQuSHHqfei8m06+BbybxDOWfg@mail.gmail.com>
References: <CACbtF4PP2WOpY0fg+8TmHh5MhQz7T+1LgVw1so17nmZ=1_pANg@mail.gmail.com>
 <CACbtF4PRB2rWKFkAMnHUoAgYzoxq+nUVAPcEJ5Zf5d5EsC=Ahg@mail.gmail.com>
 <CACbtF4Nhm38pJk=o_9ohAkAcshf0t9Y_5+E5ZkEop6rPf4yJpQ@mail.gmail.com>
 <CACbtF4Pq8EOBQijBzvD3BXMh7MQuSHHqfei8m06+BbybxDOWfg@mail.gmail.com>
Message-ID: <CACbtF4NhgYodwcw4XK2Q5XXD9H=ZpsvOjZ8mhO8sH5mAt0UpwA@mail.gmail.com>

Below is the right config that I updated in my squid.conf file

acl user1 note user username1
cache_peer Peer1 parent 3218 0  no-query  connect-fail-limit=1 name=Peer1
cache_peer_access  Peer1 allow user1
cache_peer_access  Peer1 deny all

On Mon, Jul 6, 2020 at 9:28 PM Prem Chand <premchand142 at gmail.com> wrote:

> Hi Amos,
>
> On further digging I understood that acl route  via cache_peer_access
> (cache_peer_access  Peer1 allow user1)  is not working hence requests are
> failing. I'm not sure the exact reason. Can you please suggest how to fix
> this?
>
> acl user1 note user username1
> cache_peer Peer1 parent 3218 0 round-robin no-query weight=1
> connect-fail-limit=1 name=Peer1
> cache_peer_access  Peer1 allow user1
> cache_peer_access deny all
>
>
> On Mon, Jul 6, 2020 at 4:00 PM Prem Chand <premchand142 at gmail.com> wrote:
>
>> Hi Amos,
>>
>> I tried the configuration that you suggested but I'm getting below error.
>> It seems the requests are not getting forward to cache_peer. I'm unable to
>> figure out what is the cause of the issue. If I revert it to my previous
>> configuration I'm not seeing any issue with  cache_peer's.
>>
>> ** Establish HTTP proxy tunnel to www.google.com:443
>> * Proxy auth using Basic with user 'username1'
>> > CONNECT www.google.com:443 HTTP/1.1
>> > Host: www.google.com:443
>> > Proxy-Authorization: Basic bGluZTE6dGVzdGluZw==
>> > User-Agent: curl/7.58.0
>> > Proxy-Connection: Keep-Alive
>> >
>> < HTTP/1.1 503 Service Unavailable
>> < Server: squid/3.5.27
>> < Mime-Version: 1.0
>> < Date: Mon, 06 Jul 2020 10:24:28 GMT
>> < Content-Type: text/html;charset=utf-8
>> < Content-Length: 3905
>> < X-Squid-Error: ERR_CANNOT_FORWARD 0
>> < Vary: Accept-Language
>> < Content-Language: en
>> <
>> * Received HTTP code 503 from proxy after CONNECT
>> * CONNECT phase completed!
>> * Closing connection 0
>> curl: (56) Received HTTP code 503 from proxy after CONNECT
>>
>> On Thu, Jul 2, 2020 at 6:29 PM Prem Chand <premchand142 at gmail.com> wrote:
>>
>>> Hi Amos,
>>>
>>> Thanks for the response.
>>>
>>> However, what do you want to happen when that user's dedicated peer is
>>> unavailable?
>>> Can it be routed to another peer if a dedicated peer is unavailable?
>>> because each peer is accessed by a different username and password. If
>>> there is an option to route then I will keep a backup peer(Peer4) so if any
>>> one of the peers(Peer1,Peer2,Peer3) is unavailable it can route to the
>>> backup peer and once the unavailable peer become available then traffic
>>> should auto route to them from backup peer.
>>>
>>> If there is no option that fits as I explained above then I want to stop
>>> all access for them.
>>>
>>> Are you wanting to keep this behaviour?
>>> I don't want to use the round-robin behaviour. I want to route requests
>>> to dedicated Peer/Client.
>>>
>>> On Thu, Jul 2, 2020 at 3:19 PM Prem Chand <premchand142 at gmail.com>
>>> wrote:
>>>
>>>>
>>>> Hi,
>>>>
>>>> I need to redirect my clients requests to different Cache_peers using
>>>> username and passwords through my proxy. Below is the rough sketch. Can
>>>> someone suggest to me how I can achieve this?
>>>>
>>>> Client1(Username1:password1) ->Proxy:443 -> Cache_peer:3218
>>>> Client 2(Username2:password2)->Proxy:443-> Cache_peer:3219
>>>> .
>>>> .
>>>> .
>>>> .
>>>>
>>>> This is my current configuration, I'm doing round robin through
>>>> cache_peers when authenticated with a single username and password in
>>>> /etc/squid/squidpasswdfile file
>>>>
>>>> auth_param basic program /usr/lib64/squid/ncsa_auth
>>>> /etc/squid/squidpasswdfile
>>>> auth_param basic realm proxy
>>>> acl auth_users proxy_auth REQUIRED
>>>> http_access allow auth_users
>>>> http_access deny all
>>>> cache_peer Peer1 parent 3218 0 round-robin no-query weight=1
>>>> connect-fail-limit=1
>>>> cache_peer Peer2 parent 3219 0 round-robin no-query weight=1
>>>> connect-fail-limit=1
>>>> cache_peer Peer3 parent 3219 0 round-robin no-query weight=1
>>>> connect-fail-limit=1
>>>>
>>>> Thanks & Regards
>>>> Premchand.
>>>>
>>>
>>>
>>> --
>>> prem
>>>
>>
>>
>> --
>> prem
>>
>
>
> --
> prem
>


-- 
prem
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200706/3268f982/attachment.htm>

From simon.beswick at gmail.com  Tue Jul  7 09:44:33 2020
From: simon.beswick at gmail.com (Simon Beswick)
Date: Tue, 7 Jul 2020 10:44:33 +0100
Subject: [squid-users] Bandwidth Trottle
Message-ID: <CAMT1ZzxnnZCVUA_RArPzknQeshhN1RUX=rFP_mjjXtS++1pVLw@mail.gmail.com>

Can you please assist.

I am looking to utilise the Windows version of Squid Proxy 3.5 to throttle
a backup application by pointing all backup servers at the proxy server and
limit the total bandwidth that is available to 70mbps. All devices will
share this available bandwidth. If someone could provide the relevant
entries that need to be made in the config file to implement this i would
be grateful?

Thanks in advance
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200707/545d1db2/attachment.htm>

From patrick.mkhael at hotmail.com  Tue Jul  7 10:26:16 2020
From: patrick.mkhael at hotmail.com (patrick mkhael)
Date: Tue, 7 Jul 2020 10:26:16 +0000
Subject: [squid-users] rock issue
In-Reply-To: <b1419b5e-ab29-3ad9-7e6c-6fc144a15354@measurement-factory.com>
References: <AM6PR09MB3221DC6FBC09852FDED01EF4916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <46d7c8ad-4f49-68ad-92f9-537138fca05c@measurement-factory.com>
 <AM6PR09MB322116222A6AE6E87562B55E916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <945439f5-b10c-63ac-795b-e865128abfab@measurement-factory.com>
 <AM6PR09MB3221808296CA72297AF6748C916A0@AM6PR09MB3221.eurprd09.prod.outlook.com>,
 <b1419b5e-ab29-3ad9-7e6c-6fc144a15354@measurement-factory.com>
Message-ID: <AM6PR09MB3221CBD28BDF7EA3B25066A591660@AM6PR09MB3221.eurprd09.prod.outlook.com>

Dear Alex,


**What kind of hit ratio do you get with rock if you do not limit swap-rate and do not specify swap-timeout? [i also removed the max size as recomended], the gain ratio is max 13 %.

?**What kind of hit ratio do you get with rock if you use one worker, one
rock cache_dir, do not limit swap-rate, do not specify swap-timeout, and
start Squid with -N to disable SMP? [ as recomended, only one rock cache_dir , no limit swap and excuted with -N option,the gain ration is 7%]

additonial info:
i have a total of 24 GB RAM which i use 15 GB of them as cache_mem and i use ext4 in fstab.

thank u


________________________________
From: Alex Rousskov <rousskov at measurement-factory.com>
Sent: Saturday, July 4, 2020 3:40 AM
To: patrick mkhael <patrick.mkhael at hotmail.com>; squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] rock issue

On 7/3/20 4:50 AM, patrick mkhael wrote:

> workers 3
> cpu_affinity_map process_numbers=1,2,3,4,5,6 cores=1,2,3,4,5,6
> cache_dir rock /rock1 200000 max-size=32000 swap-timeout=300 max-swap-rate=100
> cache_dir rock /rock2 200000 max-size=32000 max-swap-rate=100 swap-timeout=300
> cache_dir rock /rock3 200000 max-size=32000 max-swap-rate=100 swap-timeout=300
> cache_mem 17 GB
> maximum_object_size_in_memory 25 MB
> maximum_object_size 1 GB
> cache_miss_revalidate off
> quick_abort_pct 95


FYI: The combination of 1GB maximum_object_size and much smaller size
limits for objects in memory and disk caches does not make sense: There
is no cache to store a, say, 26MB object. If Squid lacks the
corresponding configuration "lint" check, somebody should add it.


> This config is giving 4% of cache gain ratio,

> in addition as i already mentionned before if i take the same above
> config without worker and cach_dir with the same traffiic using aufs on
> one of the disks ,  i have automatically i har 60 % cache ratio.

When using AUFS, do you limit disk-cached object sizes to 32KB like you
do with rock? If not, then you should remove the max-size limit from
rock cache_dirs. Modern rock cache_dirs are capable of storing large
objects.

What kind of hit ratio do you get with rock if you do not limit
swap-rate and do not specify swap-timeout?

What kind of hit ratio do you get with rock if you use one worker, one
rock cache_dir, do not limit swap-rate, do not specify swap-timeout, and
start Squid with -N to disable SMP?

As you can see, I am trying to understand whether the size limitation,
the rate limiting, or SMP problems explain the drop in hit ratio.


> Shoud rock give me the same performance as aufs ?

It is a difficult question to answer correctly (for me). The goal is for
rock performance to exceed that of (a)ufs, but I doubt we have reached
that goal in every environment that matters (including yours).

* In a non-SMP environment, I would expect similar hit ratios in most
cases, but I would not be surprised if there are significant exceptions.
Rock is focused on SMP support, and there are complexities/costs
associated with SMP. Rock is getting better, but there are some known
areas where rock cannot yet do what ufs (including aufs) can.

* In a SMP environment, the question is mostly meaningless because there
is no SMP support for ufs-based caches. Folks use squid.conf
preprocessor hacks to configure ufs-based caches in SMP mode, but those
setups usually violate HTTP and may cause serious problems. YMMV.


> for a traffic of 1 Gb/s , is there a way to use aufs ?

Before trying unsupported combinations of aufs and SMP, I would try to
understand why your hit ratio is so low with rock. The questions above
may be a good start in that investigation.


Cheers,

Alex.


> ------------------------------------------------------------------------
> *From:* Alex Rousskov <rousskov at measurement-factory.com>
> *Sent:* Thursday, July 2, 2020 4:24 PM
> *To:* patrick mkhael <patrick.mkhael at hotmail.com>;
> squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
> *Subject:* Re: [squid-users] rock issue
>
> On 7/1/20 4:45 PM, patrick mkhael wrote:
>
>> ***Please note that you have 20 kids worth mapping (10 workers and 10
>> diskers), but you map only the first 10.?{since i did not get the point
>> of the diskers ,as far as i understood  , it should be like  (simple
>> example)
>
>>> workers 2
>>> cpu_affinity_map process_numbers=1,2,3,4 cores=1,2,3,4
>>> cache_dir rock ...
>>> cache_dir rock ...
>
> The above looks OK. Each worker is a kid process. Each rock cache_dir is
> a kid process (we call them diskers).  If you have physical CPU cores to
> spare, give each kid process its own physical core. Otherwise, give each
> worker process its own physical core (if you can). Diskers can share
> physical cores with less harm because they usually do not consume much
> CPU cycles. Squid wiki has more detailed information about that:
> https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F
>
>
>> ***Why do you have 10 rock caches of various sizes? [ to be honest , i
>> saw in many websites that it should be like this from the smallest to
>> the bigest with diff size, i tought it should serve from small size pool
>> to high ]
>
> IMHO, you should stop reading those web pages :-). There is no general
> need to segregate objects by sizes, especially when you are using the
> same slot size for all cache_dirs. Such segregation may be necessary in
> some special cases, but we have not yet established that your case is
> special.
>
>
>> *****How many independent disk spindles (or equivalent) do you have? [ i
>> have one raid 5 ssd disks , used by the 10 rock cache dir]
>
> Do not use RAID. If possible, use one rock cache_dir per SSD disk. The
> only reason this may not be possible, AFAICT, is if you want to cache
> more (per SSD disk) than a single Squid cache_dir can hold, but I would
> not worry about overcoming that limit at the beginning. If you want to
> know more about the limit, look for "33554431" in
> http://www.squid-cache.org/mail-archive/squid-users/201312/0034.html
>
>
>> ***How did you select the swap rate limits and timeouts for
>> cache_dirs?[I took it also from online forum , can i leave it empty for
>> both]
>
> If you want a simple answer, then it is "yes". Unfortunately, there is
> no simple correct answer to that question. To understand what is going
> on and how to tune things, I recommend studying the Performance Tuning
> section of https://wiki.squid-cache.org/Features/RockStore
>
>
>> ****Do you see any ERRORs or WARNINGs in cache log?[NO error or warning
>> found in cache]
>
> Good. I assume you do see some regular messages in cache.log. Keep an
> eye for ERRORs and WARNINGs as you change settings.
>
>
> HTH,
>
> Alex.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200707/55119587/attachment.htm>

From rousskov at measurement-factory.com  Tue Jul  7 13:32:20 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 7 Jul 2020 09:32:20 -0400
Subject: [squid-users] rock issue
In-Reply-To: <AM6PR09MB3221CBD28BDF7EA3B25066A591660@AM6PR09MB3221.eurprd09.prod.outlook.com>
References: <AM6PR09MB3221DC6FBC09852FDED01EF4916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <46d7c8ad-4f49-68ad-92f9-537138fca05c@measurement-factory.com>
 <AM6PR09MB322116222A6AE6E87562B55E916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <945439f5-b10c-63ac-795b-e865128abfab@measurement-factory.com>
 <AM6PR09MB3221808296CA72297AF6748C916A0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <b1419b5e-ab29-3ad9-7e6c-6fc144a15354@measurement-factory.com>
 <AM6PR09MB3221CBD28BDF7EA3B25066A591660@AM6PR09MB3221.eurprd09.prod.outlook.com>
Message-ID: <d92d70b1-a8bd-b8ee-b2c2-d6d805840350@measurement-factory.com>

On 7/7/20 6:26 AM, patrick mkhael wrote:

> **What kind of hit ratio do you get with rock if you do not
> limit?swap-rate and do not specify swap-timeout? [i also removed the max
> size as recomended], the gain ratio is max 13 %.

Noted, thank you.


> ?**What kind of hit ratio do you get with rock if you use one worker, one
> rock cache_dir, do not limit swap-rate, do not specify swap-timeout, and
> start Squid with -N to disable SMP? [ as recomended, only one rock
> cache_dir , no limit swap and excuted with -N option,the gain ration is 7%]

Was this 7% measured with max-size=32000 or without?


When using AUFS (without rock), do you limit disk-cached object sizes to
~32KB (max-size=32000)?


Finally, what is your Squid version?


Thank you,

Alex.


> ------------------------------------------------------------------------
> *From:* Alex Rousskov <rousskov at measurement-factory.com>
> *Sent:* Saturday, July 4, 2020 3:40 AM
> *To:* patrick mkhael <patrick.mkhael at hotmail.com>;
> squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
> *Subject:* Re: [squid-users] rock issue
> ?
> On 7/3/20 4:50 AM, patrick mkhael wrote:
> 
>> workers 3
>> cpu_affinity_map process_numbers=1,2,3,4,5,6 cores=1,2,3,4,5,6
>> cache_dir rock /rock1 200000 max-size=32000 swap-timeout=300 max-swap-rate=100
>> cache_dir rock /rock2 200000 max-size=32000 max-swap-rate=100 swap-timeout=300
>> cache_dir rock /rock3 200000 max-size=32000 max-swap-rate=100 swap-timeout=300
>> cache_mem 17 GB
>> maximum_object_size_in_memory 25 MB
>> maximum_object_size 1 GB
>> cache_miss_revalidate off
>> quick_abort_pct 95
> 
> 
> FYI: The combination of 1GB maximum_object_size and much smaller size
> limits for objects in memory and disk caches does not make sense: There
> is no cache to store a, say, 26MB object. If Squid lacks the
> corresponding configuration "lint" check, somebody should add it.
> 
> 
>> This config is giving 4% of cache gain ratio,?
> 
>> in addition as i already mentionned before if i take the same above
>> config without worker and cach_dir with the same traffiic using aufs on
>> one of the disks ,? i have automatically i har 60 % cache ratio.
> 
> When using AUFS, do you limit disk-cached object sizes to 32KB like you
> do with rock? If not, then you should remove the max-size limit from
> rock cache_dirs. Modern rock cache_dirs are capable of storing large
> objects.
> 
> What kind of hit ratio do you get with rock if you do not limit
> swap-rate and do not specify swap-timeout?
> 
> What kind of hit ratio do you get with rock if you use one worker, one
> rock cache_dir, do not limit swap-rate, do not specify swap-timeout, and
> start Squid with -N to disable SMP?
> 
> As you can see, I am trying to understand whether the size limitation,
> the rate limiting, or SMP problems explain the drop in hit ratio.
> 
> 
>> Shoud rock give me the same performance as aufs ?
> 
> It is a difficult question to answer correctly (for me). The goal is for
> rock performance to exceed that of (a)ufs, but I doubt we have reached
> that goal in every environment that matters (including yours).
> 
> * In a non-SMP environment, I would expect similar hit ratios in most
> cases, but I would not be surprised if there are significant exceptions.
> Rock is focused on SMP support, and there are complexities/costs
> associated with SMP. Rock is getting better, but there are some known
> areas where rock cannot yet do what ufs (including aufs) can.
> 
> * In a SMP environment, the question is mostly meaningless because there
> is no SMP support for ufs-based caches. Folks use squid.conf
> preprocessor hacks to configure ufs-based caches in SMP mode, but those
> setups usually violate HTTP and may cause serious problems. YMMV.
> 
> 
>> for a traffic of 1 Gb/s , is there a way to use aufs ?
> 
> Before trying unsupported combinations of aufs and SMP, I would try to
> understand why your hit ratio is so low with rock. The questions above
> may be a good start in that investigation.
> 
> 
> Cheers,
> 
> Alex.
> 
> 
>> ------------------------------------------------------------------------
>> *From:* Alex Rousskov <rousskov at measurement-factory.com>
>> *Sent:* Thursday, July 2, 2020 4:24 PM
>> *To:* patrick mkhael <patrick.mkhael at hotmail.com>;
>> squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
>> *Subject:* Re: [squid-users] rock issue
>> ?
>> On 7/1/20 4:45 PM, patrick mkhael wrote:
>> 
>>> ***Please note that you have 20 kids worth mapping (10 workers and 10
>>> diskers), but you map only the first 10.?{since i did not get the point
>>> of the diskers ,as far as i understood? , it should be like? (simple
>>> example)
>> 
>>>> workers 2
>>>> cpu_affinity_map process_numbers=1,2,3,4 cores=1,2,3,4
>>>> cache_dir rock ...
>>>> cache_dir rock ...
>> 
>> The above looks OK. Each worker is a kid process. Each rock cache_dir is
>> a kid process (we call them diskers).? If you have physical CPU cores to
>> spare, give each kid process its own physical core. Otherwise, give each
>> worker process its own physical core (if you can). Diskers can share
>> physical cores with less harm because they usually do not consume much
>> CPU cycles. Squid wiki has more detailed information about that:
>> https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F
>> 
>> 
>>> ***Why do you have 10 rock caches of various sizes??[ to be honest , i
>>> saw in many websites that it should be like this from the smallest to
>>> the bigest with diff size, i tought it should serve from small size pool
>>> to high ]
>> 
>> IMHO, you should stop reading those web pages :-). There is no general
>> need to segregate objects by sizes, especially when you are using the
>> same slot size for all cache_dirs. Such segregation may be necessary in
>> some special cases, but we have not yet established that your case is
>> special.
>> 
>> 
>>> *****How many independent disk spindles (or equivalent) do you have? [ i
>>> have one raid 5 ssd disks , used by the 10 rock cache dir]
>> 
>> Do not use RAID. If possible, use one rock cache_dir per SSD disk. The
>> only reason this may not be possible, AFAICT, is if you want to cache
>> more (per SSD disk) than a single Squid cache_dir can hold, but I would
>> not worry about overcoming that limit at the beginning. If you want to
>> know more about the limit, look for "33554431" in
>> http://www.squid-cache.org/mail-archive/squid-users/201312/0034.html
>> 
>> 
>>> ***How did you select the swap rate limits and timeouts for
>>> cache_dirs?[I took it also from online forum , can i leave it empty for
>>> both]
>> 
>> If you want a simple answer, then it is "yes". Unfortunately, there is
>> no simple correct answer to that question. To understand what is going
>> on and how to tune things, I recommend studying the Performance Tuning
>> section of https://wiki.squid-cache.org/Features/RockStore
>> 
>> 
>>> ****Do you see any ERRORs or WARNINGs in cache log?[NO error or warning
>>> found in cache]
>> 
>> Good. I assume you do see some regular messages in cache.log. Keep an
>> eye for ERRORs and WARNINGs as you change settings.
>> 
>> 
>> HTH,
>> 
>> Alex.
> 



From patrick.mkhael at hotmail.com  Tue Jul  7 13:44:26 2020
From: patrick.mkhael at hotmail.com (patrick mkhael)
Date: Tue, 7 Jul 2020 13:44:26 +0000
Subject: [squid-users] rock issue
In-Reply-To: <d92d70b1-a8bd-b8ee-b2c2-d6d805840350@measurement-factory.com>
References: <AM6PR09MB3221DC6FBC09852FDED01EF4916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <46d7c8ad-4f49-68ad-92f9-537138fca05c@measurement-factory.com>
 <AM6PR09MB322116222A6AE6E87562B55E916C0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <945439f5-b10c-63ac-795b-e865128abfab@measurement-factory.com>
 <AM6PR09MB3221808296CA72297AF6748C916A0@AM6PR09MB3221.eurprd09.prod.outlook.com>
 <b1419b5e-ab29-3ad9-7e6c-6fc144a15354@measurement-factory.com>
 <AM6PR09MB3221CBD28BDF7EA3B25066A591660@AM6PR09MB3221.eurprd09.prod.outlook.com>,
 <d92d70b1-a8bd-b8ee-b2c2-d6d805840350@measurement-factory.com>
Message-ID: <AM6PR09MB3221CC07B5B58C30114D31A491660@AM6PR09MB3221.eurprd09.prod.outlook.com>

dear alex,

Was this 7% measured with max-size=32000 or without? [ i did not use max-size option]

When using AUFS (without rock), do you limit disk-cached object sizes to
~32KB (max-size=32000)?
[ i use maximum_object_size_in_memory 250 MB and maximum_object_size 2 GB] // which i also use it in rock ]


squid version [ Version 4.8]
 thank u
________________________________
From: Alex Rousskov <rousskov at measurement-factory.com>
Sent: Tuesday, July 7, 2020 4:32 PM
To: patrick mkhael <patrick.mkhael at hotmail.com>; squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] rock issue

On 7/7/20 6:26 AM, patrick mkhael wrote:

> **What kind of hit ratio do you get with rock if you do not
> limit swap-rate and do not specify swap-timeout? [i also removed the max
> size as recomended], the gain ratio is max 13 %.

Noted, thank you.


> ?**What kind of hit ratio do you get with rock if you use one worker, one
> rock cache_dir, do not limit swap-rate, do not specify swap-timeout, and
> start Squid with -N to disable SMP? [ as recomended, only one rock
> cache_dir , no limit swap and excuted with -N option,the gain ration is 7%]




When using AUFS (without rock), do you limit disk-cached object sizes to
~32KB (max-size=32000)?


Finally, what is your Squid version?


Thank you,

Alex.


> ------------------------------------------------------------------------
> *From:* Alex Rousskov <rousskov at measurement-factory.com>
> *Sent:* Saturday, July 4, 2020 3:40 AM
> *To:* patrick mkhael <patrick.mkhael at hotmail.com>;
> squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
> *Subject:* Re: [squid-users] rock issue
>
> On 7/3/20 4:50 AM, patrick mkhael wrote:
>
>> workers 3
>> cpu_affinity_map process_numbers=1,2,3,4,5,6 cores=1,2,3,4,5,6
>> cache_dir rock /rock1 200000 max-size=32000 swap-timeout=300 max-swap-rate=100
>> cache_dir rock /rock2 200000 max-size=32000 max-swap-rate=100 swap-timeout=300
>> cache_dir rock /rock3 200000 max-size=32000 max-swap-rate=100 swap-timeout=300
>> cache_mem 17 GB
>> maximum_object_size_in_memory 25 MB
>> maximum_object_size 1 GB
>> cache_miss_revalidate off
>> quick_abort_pct 95
>
>
> FYI: The combination of 1GB maximum_object_size and much smaller size
> limits for objects in memory and disk caches does not make sense: There
> is no cache to store a, say, 26MB object. If Squid lacks the
> corresponding configuration "lint" check, somebody should add it.
>
>
>> This config is giving 4% of cache gain ratio,
>
>> in addition as i already mentionned before if i take the same above
>> config without worker and cach_dir with the same traffiic using aufs on
>> one of the disks ,  i have automatically i har 60 % cache ratio.
>
> When using AUFS, do you limit disk-cached object sizes to 32KB like you
> do with rock? If not, then you should remove the max-size limit from
> rock cache_dirs. Modern rock cache_dirs are capable of storing large
> objects.
>
> What kind of hit ratio do you get with rock if you do not limit
> swap-rate and do not specify swap-timeout?
>
> What kind of hit ratio do you get with rock if you use one worker, one
> rock cache_dir, do not limit swap-rate, do not specify swap-timeout, and
> start Squid with -N to disable SMP?
>
> As you can see, I am trying to understand whether the size limitation,
> the rate limiting, or SMP problems explain the drop in hit ratio.
>
>
>> Shoud rock give me the same performance as aufs ?
>
> It is a difficult question to answer correctly (for me). The goal is for
> rock performance to exceed that of (a)ufs, but I doubt we have reached
> that goal in every environment that matters (including yours).
>
> * In a non-SMP environment, I would expect similar hit ratios in most
> cases, but I would not be surprised if there are significant exceptions.
> Rock is focused on SMP support, and there are complexities/costs
> associated with SMP. Rock is getting better, but there are some known
> areas where rock cannot yet do what ufs (including aufs) can.
>
> * In a SMP environment, the question is mostly meaningless because there
> is no SMP support for ufs-based caches. Folks use squid.conf
> preprocessor hacks to configure ufs-based caches in SMP mode, but those
> setups usually violate HTTP and may cause serious problems. YMMV.
>
>
>> for a traffic of 1 Gb/s , is there a way to use aufs ?
>
> Before trying unsupported combinations of aufs and SMP, I would try to
> understand why your hit ratio is so low with rock. The questions above
> may be a good start in that investigation.
>
>
> Cheers,
>
> Alex.
>
>
>> ------------------------------------------------------------------------
>> *From:* Alex Rousskov <rousskov at measurement-factory.com>
>> *Sent:* Thursday, July 2, 2020 4:24 PM
>> *To:* patrick mkhael <patrick.mkhael at hotmail.com>;
>> squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
>> *Subject:* Re: [squid-users] rock issue
>>
>> On 7/1/20 4:45 PM, patrick mkhael wrote:
>>
>>> ***Please note that you have 20 kids worth mapping (10 workers and 10
>>> diskers), but you map only the first 10.?{since i did not get the point
>>> of the diskers ,as far as i understood  , it should be like  (simple
>>> example)
>>
>>>> workers 2
>>>> cpu_affinity_map process_numbers=1,2,3,4 cores=1,2,3,4
>>>> cache_dir rock ...
>>>> cache_dir rock ...
>>
>> The above looks OK. Each worker is a kid process. Each rock cache_dir is
>> a kid process (we call them diskers).  If you have physical CPU cores to
>> spare, give each kid process its own physical core. Otherwise, give each
>> worker process its own physical core (if you can). Diskers can share
>> physical cores with less harm because they usually do not consume much
>> CPU cycles. Squid wiki has more detailed information about that:
>> https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F
>>
>>
>>> ***Why do you have 10 rock caches of various sizes? [ to be honest , i
>>> saw in many websites that it should be like this from the smallest to
>>> the bigest with diff size, i tought it should serve from small size pool
>>> to high ]
>>
>> IMHO, you should stop reading those web pages :-). There is no general
>> need to segregate objects by sizes, especially when you are using the
>> same slot size for all cache_dirs. Such segregation may be necessary in
>> some special cases, but we have not yet established that your case is
>> special.
>>
>>
>>> *****How many independent disk spindles (or equivalent) do you have? [ i
>>> have one raid 5 ssd disks , used by the 10 rock cache dir]
>>
>> Do not use RAID. If possible, use one rock cache_dir per SSD disk. The
>> only reason this may not be possible, AFAICT, is if you want to cache
>> more (per SSD disk) than a single Squid cache_dir can hold, but I would
>> not worry about overcoming that limit at the beginning. If you want to
>> know more about the limit, look for "33554431" in
>> http://www.squid-cache.org/mail-archive/squid-users/201312/0034.html
>>
>>
>>> ***How did you select the swap rate limits and timeouts for
>>> cache_dirs?[I took it also from online forum , can i leave it empty for
>>> both]
>>
>> If you want a simple answer, then it is "yes". Unfortunately, there is
>> no simple correct answer to that question. To understand what is going
>> on and how to tune things, I recommend studying the Performance Tuning
>> section of https://wiki.squid-cache.org/Features/RockStore
>>
>>
>>> ****Do you see any ERRORs or WARNINGs in cache log?[NO error or warning
>>> found in cache]
>>
>> Good. I assume you do see some regular messages in cache.log. Keep an
>> eye for ERRORs and WARNINGs as you change settings.
>>
>>
>> HTH,
>>
>> Alex.
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200707/6903faa2/attachment.htm>

From matt at mockingbirdconsulting.co.uk  Tue Jul  7 14:52:04 2020
From: matt at mockingbirdconsulting.co.uk (Matthew Macdonald-Wallace)
Date: Tue, 7 Jul 2020 15:52:04 +0100
Subject: [squid-users] Forcing squid to fail when the whitelist doesn't exist
Message-ID: <CAN3von4=k=hxZ8C9X7=u1UPZ90geW7NOvcjAhpWGPHt0U7EdRw@mail.gmail.com>

Hey all,

We're re-configuring a squid proxy solution for a client and as part of it
we made the assumption that squid would fail if we asked it to read a
whitelist that wasn't present.

We've now discovered that Squid fails to read the file, throws an error in
the log ( Error: Cannot open file /etc/squid/whitelist.txt for reading ),
and then starts up anyway and listens on port 3128 but without the
whitelist present.

I've also discovered the "-C" flag that helps us ignore even more serious
issues, however I can't find anything either in the documentation or by
searching that shows us how to make squid stop as soon as it encounters an
error.

Is this possible? I've searched the FAQ and various other sources, but of
course "stop squid from starting when error" or similar just returns a load
of results about how to fix various errors that stop squid from starting,
rather than deliberately wanting Squid to fail.

Thanks in advance,

Matt


--
Matthew Macdonald-Wallace MIET
Co-Founder
Mockingbird Consulting
Connecting you with your environment

w: www.mockingbirdconsulting.co.uk
e: matt at mockingbirdconsulting.co.uk
t: +44 (0) 1600 717142

Bridges Centre,
Drybridge House,
Monmouth,
NP25 5AS

Registered in England and Wales, Company Number 10488438

-- 

--
Mockingbird Consulting

Connecting you with your environment


w:?
www.mockingbirdconsulting.co.uk <http://www.mockingbirdconsulting.co.uk/>

e:?info at mockingbirdconsulting.co.uk 
<mailto:matt at mockingbirdconsulting.co.uk>
t: +44 (0)?1600 717142


Bridges 
Centre,
Drybridge House,
Monmouth,
NP25 5AS

Registered in England and 
Wales, Company Number 10488438
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200707/9cd8ac97/attachment.htm>

From rousskov at measurement-factory.com  Tue Jul  7 17:52:49 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 7 Jul 2020 13:52:49 -0400
Subject: [squid-users] Forcing squid to fail when the whitelist doesn't
 exist
In-Reply-To: <CAN3von4=k=hxZ8C9X7=u1UPZ90geW7NOvcjAhpWGPHt0U7EdRw@mail.gmail.com>
References: <CAN3von4=k=hxZ8C9X7=u1UPZ90geW7NOvcjAhpWGPHt0U7EdRw@mail.gmail.com>
Message-ID: <0bcacc01-0c3a-233e-ba30-dca0735daf51@measurement-factory.com>

On 7/7/20 10:52 AM, Matthew Macdonald-Wallace wrote:

> We're re-configuring a squid proxy solution for a client and as part of
> it we made the assumption that squid would fail if we asked it to read a
> whitelist that wasn't present.
> 
> We've now discovered that Squid fails to read the file, throws an error
> in the log ( Error: Cannot open file /etc/squid/whitelist.txt for
> reading ), and then starts up anyway

Yes, this kind of error ignorance is an old known Squid problem. Some
developers have thought that it is better to start Squid "if at all
possible" than to fail on (in their view "minor") error. New features
are usually more "conservative", but even now that "conservative"
approach does not always win.

IMO, quality pull requests making missing files a fatal configuration
error should be welcomed. They may not be backported to stable versions,
of course. The solution would probably revolve around throwing an
exception in ConfigParser::strtokFile(). Making missing file treatment
configurable, especially on a per-file basis should be welcomed as well,
probably by extending the new parameters syntax mentioned below.

Meanwhile, try using the newer parameters() syntax instead of abusing
double quotes. It should work the way you expect. Here is the
corresponding quote from squid.conf.documented:

> Squid supports reading configuration option parameters from external
> files using the syntax:
>     parameters("/path/filename")
> For example:
>     acl whitelist dstdomain parameters("/etc/squid/whitelist.txt")


HTH,

Alex.


From matt at mockingbirdconsulting.co.uk  Tue Jul  7 17:57:01 2020
From: matt at mockingbirdconsulting.co.uk (Matthew Macdonald-Wallace)
Date: Tue, 7 Jul 2020 18:57:01 +0100
Subject: [squid-users] Forcing squid to fail when the whitelist doesn't
	exist
In-Reply-To: <0bcacc01-0c3a-233e-ba30-dca0735daf51@measurement-factory.com>
References: <CAN3von4=k=hxZ8C9X7=u1UPZ90geW7NOvcjAhpWGPHt0U7EdRw@mail.gmail.com>
 <0bcacc01-0c3a-233e-ba30-dca0735daf51@measurement-factory.com>
Message-ID: <CAN3von7dEwkk7naoyEud7gXSWZvitN6n1T2-=ysx018P9JhKkw@mail.gmail.com>

On Tue, 7 Jul 2020 at 18:53, Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 7/7/20 10:52 AM, Matthew Macdonald-Wallace wrote:
>
> > We're re-configuring a squid proxy solution for a client and as part of
> > it we made the assumption that squid would fail if we asked it to read a
> > whitelist that wasn't present.
> >
> > We've now discovered that Squid fails to read the file, throws an error
> > in the log ( Error: Cannot open file /etc/squid/whitelist.txt for
> > reading ), and then starts up anyway
>
> Yes, this kind of error ignorance is an old known Squid problem. Some
> developers have thought that it is better to start Squid "if at all
> possible" than to fail on (in their view "minor") error. New features
> are usually more "conservative", but even now that "conservative"
> approach does not always win.
>
> IMO, quality pull requests making missing files a fatal configuration
> error should be welcomed. They may not be backported to stable versions,
> of course. The solution would probably revolve around throwing an
> exception in ConfigParser::strtokFile(). Making missing file treatment
> configurable, especially on a per-file basis should be welcomed as well,
> probably by extending the new parameters syntax mentioned below.
>
>
Thanks, it did seem a bit odd as a default behaviour, good to know
something like this would be welcomed (by you at least!).


> Meanwhile, try using the newer parameters() syntax instead of abusing
> double quotes. It should work the way you expect. Here is the
> corresponding quote from squid.conf.documented:
>
> > Squid supports reading configuration option parameters from external
> > files using the syntax:
> >     parameters("/path/filename")
> > For example:
> >     acl whitelist dstdomain parameters("/etc/squid/whitelist.txt")
>
>
I'll check the version that we're running and see if I can do this.  I
suspect that due to "enterprise requirements" our version won't be the
latest, but hopefully it will support this.

Thanks again,

Matt

-- 

--
Mockingbird Consulting

Connecting you with your environment


w:?
www.mockingbirdconsulting.co.uk <http://www.mockingbirdconsulting.co.uk/>

e:?info at mockingbirdconsulting.co.uk 
<mailto:matt at mockingbirdconsulting.co.uk>
t: +44 (0)?1600 717142


Bridges 
Centre,
Drybridge House,
Monmouth,
NP25 5AS

Registered in England and 
Wales, Company Number 10488438
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200707/61a474c3/attachment.htm>

From rousskov at measurement-factory.com  Tue Jul  7 18:38:23 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 7 Jul 2020 14:38:23 -0400
Subject: [squid-users] Forcing squid to fail when the whitelist doesn't
 exist
In-Reply-To: <CAN3von7dEwkk7naoyEud7gXSWZvitN6n1T2-=ysx018P9JhKkw@mail.gmail.com>
References: <CAN3von4=k=hxZ8C9X7=u1UPZ90geW7NOvcjAhpWGPHt0U7EdRw@mail.gmail.com>
 <0bcacc01-0c3a-233e-ba30-dca0735daf51@measurement-factory.com>
 <CAN3von7dEwkk7naoyEud7gXSWZvitN6n1T2-=ysx018P9JhKkw@mail.gmail.com>
Message-ID: <b9bff261-daf8-323b-8d37-afc2a56c00a8@measurement-factory.com>

On 7/7/20 1:57 PM, Matthew Macdonald-Wallace wrote:
> On Tue, 7 Jul 2020 at 18:53, Alex Rousskov
>     Meanwhile, try using the newer parameters() syntax instead of abusing
>     double quotes. It should work the way you expect. Here is the
>     corresponding quote from squid.conf.documented:

>     > Squid supports reading configuration option parameters from external
>     > files using the syntax:
>     >? ? ?parameters("/path/filename")
>     > For example:
>     >? ? ?acl whitelist dstdomain parameters("/etc/squid/whitelist.txt")


> I'll check the version that we're running and see if I can do this.? I
> suspect that due to "enterprise requirements" our version won't be the
> latest, but hopefully it will support this.

AFAICT, all supported Squid versions have parameters(). You will need to
enable configuration_includes_quoted_values in squid.conf to get that
feature. IIRC, that directive was supposed to be on by default, but that
cannot happen until we fix regex support (at least).

Alex.


From ngtech1ltd at gmail.com  Wed Jul  8 10:11:36 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Wed, 8 Jul 2020 13:11:36 +0300
Subject: [squid-users] Bandwidth Trottle
In-Reply-To: <CAMT1ZzxnnZCVUA_RArPzknQeshhN1RUX=rFP_mjjXtS++1pVLw@mail.gmail.com>
References: <CAMT1ZzxnnZCVUA_RArPzknQeshhN1RUX=rFP_mjjXtS++1pVLw@mail.gmail.com>
Message-ID: <009701d65510$2b550c40$81ff24c0$@gmail.com>

Hey Simon,

 

I think that if possible you should perform qos on the network level rather in the application.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email:  <mailto:ngtech1ltd at gmail.com> ngtech1ltd at gmail.com

 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Simon Beswick
Sent: Tuesday, July 7, 2020 12:45 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Bandwidth Trottle

 

Can you please assist.

 

I am looking to utilise the Windows version of Squid Proxy 3.5 to throttle a backup application by pointing all backup servers at the proxy server and limit the total bandwidth that is available to 70mbps. All devices will share this available bandwidth. If someone could provide the relevant entries that need to be made in the config file to implement this i would be grateful?

 

Thanks in advance  

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200708/abdb979a/attachment.htm>

From antonino.sanacori at unibs.it  Wed Jul  8 13:23:23 2020
From: antonino.sanacori at unibs.it (Antonino Sanacori)
Date: Wed, 8 Jul 2020 15:23:23 +0200
Subject: [squid-users] Again Error Helper messages
Message-ID: <62f16094-67bb-8def-0a8d-3ea857f14b55@unibs.it>

Hi all.

I get the following errors on cache.log and daemon.log on my debian 
server with Squid 4.6

14:42:49 squid squid[512]: ERROR: helper: {result=BH, notes={message: 
Success; }}, attempt #1 of 2

14:42:49 squid squid[512]: ERROR: helper: {result=BH, notes={message: 
Success; message: Success; }}, attempt #2 of 2

The messages are repeated continually.

Running debug_options 84, 6 i get the followings logs:

*14:29:17.974 kid1| ERROR: helper: {result=BH, notes={message: Success; 
message: Success; }}, attempt #2 of 2*
 ? 14:29:17.975 kid1| 84,5| helper.cc(1247) GetFirstAvailable: 
GetFirstAvailable: Running servers 5
 ? 14:29:17.975 kid1| 84,5| helper.cc(1379) helperDispatch: 
helperDispatch: Request sent to basicauthenticator #Hlpr1, 26 bytes
 ? 14:29:17.975 kid1| 84,5| helper.cc(1247) GetFirstAvailable: 
GetFirstAvailable: Running servers 5
 ? 14:29:17.988 kid1| 84,5| helper.cc(963) helperHandleRead: 
helperHandleRead: 11 bytes from basicauthenticator #Hlpr1
 ? 14:29:17.988 kid1| 84,3| helper.cc(991) helperHandleRead: 
helperHandleRead: end of reply found
 ? 14:29:17.988 kid1| 84,3| Reply.cc(41) finalize: Parsing helper buffer
 ? 14:29:17.989 kid1| 84,3| Reply.cc(59) finalize: Buff length is larger 
than 2
 ? 14:29:17.989 kid1| 84,3| Reply.cc(71) finalize: helper Result = BH
 ? 14:29:17.992 kid1| 84,5| helper.cc(1247) GetFirstAvailable: 
GetFirstAvailable: Running servers 5
 ? 14:29:17.997 kid1| 84,5| helper.cc(1247) GetFirstAvailable: 
GetFirstAvailable: Running servers 5
 ? 14:29:17.997 kid1| 84,5| helper.cc(1379) helperDispatch: 
helperDispatch: Request sent to basicauthenticator #Hlpr1, 26 bytes
 ? 14:29:18.011 kid1| 84,5| helper.cc(963) helperHandleRead: 
helperHandleRead: 11 bytes from basicauthenticator #Hlpr1
 ? 14:29:18.011 kid1| 84,3| helper.cc(991) helperHandleRead: 
helperHandleRead: end of reply found
 ? 14:29:18.012 kid1| 84,3| Reply.cc(41) finalize: Parsing helper buffer
 ? 14:29:18.012 kid1| 84,3| Reply.cc(59) *finalize: Buff length is 
larger than 2*
 ? 14:29:18.012 kid1| 84,3| Reply.cc(71) finalize: helper Result = BH
 ? 14:29:18.012 kid1| *ERROR: helper: {result=BH, notes={message: 
Success; }}, attempt #1 of 2*
 ? 14:29:18.013 kid1| 84,5| helper.cc(1247) GetFirstAvailable: 
GetFirstAvailable: Running servers 5
 ? 14:29:18.013 kid1| 84,5| helper.cc(1379) helperDispatch: 
helperDispatch: Request sent to basicauthenticator #Hlpr1, 26 bytes
 ? 14:29:18.013 kid1| 84,5| helper.cc(1247) GetFirstAvailable: 
GetFirstAvailable: Running servers 5
 ? 14:29:18.027 kid1| 84,5| helper.cc(963) helperHandleRead: 
helperHandleRead: 3 bytes from basicauthenticator #Hlpr1
 ? 14:29:18.027 kid1| 84,5| helper.cc(963) helperHandleRead: 
helperHandleRead: 7 bytes from basicauthenticator #Hlpr1
 ? 14:29:18.028 kid1| 84,5| helper.cc(963) helperHandleRead: 
helperHandleRead: 1 bytes from basicauthenticator #Hlpr1
 ? 14:29:18.028 kid1| 84,3| helper.cc(991) helperHandleRead: 
helperHandleRead: end of reply found
 ? 14:29:18.028 kid1| 84,3| Reply.cc(41) finalize: Parsing helper buffer
 ? 14:29:18.028 kid1| 84,3| Reply.cc(59) *finalize: Buff length is 
larger than 2*
 ? 14:29:18.028 kid1| 84,3| Reply.cc(71) finalize: helper Result = BH
 ? 14:29:18.028 kid1| *ERROR: helper: {result=BH, notes={message: 
Success; message: Success; }}, attempt #2 of 2*
 ? 14:29:18.028 kid1| 84,5| helper.cc(1247) GetFirstAvailable: 
GetFirstAvailable: Running servers 5

...........................................

Any advices, please?

Thank you.

Antonino



-- 


Informativa sulla Privacy: http://www.unibs.it/node/8155 
<http://www.unibs.it/node/8155>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200708/8d9c5483/attachment.htm>

From rousskov at measurement-factory.com  Wed Jul  8 13:34:37 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 8 Jul 2020 09:34:37 -0400
Subject: [squid-users] Again Error Helper messages
In-Reply-To: <62f16094-67bb-8def-0a8d-3ea857f14b55@unibs.it>
References: <62f16094-67bb-8def-0a8d-3ea857f14b55@unibs.it>
Message-ID: <7e0702cd-7724-3457-a74f-a2ed6b536dc7@measurement-factory.com>

On 7/8/20 9:23 AM, Antonino Sanacori wrote:

> I get the following errors on cache.log and daemon.log on my debian
> server with Squid 4.6

> 14:42:49 squid squid[512]: ERROR: helper: {result=BH ...

> Any advices, please?

AFAICT, your helper tells you that it is broken (BH means "Broken
Helper"). You need to figure out why the helper is unhappy. Perhaps the
helper has built-in debugging that you can enable? If not, you may have
to add that debugging.

The underlying problem is most likely unrelated to the following change,
but the new observable side effects are probably due to
https://github.com/squid-cache/squid/commit/2498f93


HTH,

Alex.


From matt at mockingbirdconsulting.co.uk  Thu Jul  9 06:25:06 2020
From: matt at mockingbirdconsulting.co.uk (Matthew Macdonald-Wallace)
Date: Thu, 9 Jul 2020 07:25:06 +0100
Subject: [squid-users] Forcing squid to fail when the whitelist doesn't
	exist
In-Reply-To: <b9bff261-daf8-323b-8d37-afc2a56c00a8@measurement-factory.com>
References: <CAN3von4=k=hxZ8C9X7=u1UPZ90geW7NOvcjAhpWGPHt0U7EdRw@mail.gmail.com>
 <0bcacc01-0c3a-233e-ba30-dca0735daf51@measurement-factory.com>
 <CAN3von7dEwkk7naoyEud7gXSWZvitN6n1T2-=ysx018P9JhKkw@mail.gmail.com>
 <b9bff261-daf8-323b-8d37-afc2a56c00a8@measurement-factory.com>
Message-ID: <CAN3von5nF9QtbVn1KCQKxdELWJnjczMQZGtsAKoAvT0QrNaaSA@mail.gmail.com>

> > I'll check the version that we're running and see if I can do this.  I
> > suspect that due to "enterprise requirements" our version won't be the
> > latest, but hopefully it will support this.
>
> AFAICT, all supported Squid versions have parameters(). You will need to
> enable configuration_includes_quoted_values in squid.conf to get that
> feature. IIRC, that directive was supposed to be on by default, but that
> cannot happen until we fix regex support (at least).
>
> Alex.
>

Turns out we're running 3.5.x - I see from the wiki that this is a
deprecated release as of two years ago, but is still the most recent
release from rhel.

The parameters trick above doesn't seem to be working as expected, I'm
wondering if we need to be on v4 to get this behaviour?

Cheers,

Matt

>

-- 

--
Mockingbird Consulting

Connecting you with your environment


w:?
www.mockingbirdconsulting.co.uk <http://www.mockingbirdconsulting.co.uk/>

e:?info at mockingbirdconsulting.co.uk 
<mailto:matt at mockingbirdconsulting.co.uk>
t: +44 (0)?1600 717142


Bridges 
Centre,
Drybridge House,
Monmouth,
NP25 5AS

Registered in England and 
Wales, Company Number 10488438
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200709/a88bc392/attachment.htm>

From antonino.sanacori at unibs.it  Thu Jul  9 09:44:51 2020
From: antonino.sanacori at unibs.it (Antonino Gianfranco Sanacori)
Date: Thu, 9 Jul 2020 11:44:51 +0200
Subject: [squid-users] Double method of authentication, possible?
Message-ID: <955cc46a-7aae-2959-361f-ff4fc44f45ca@unibs.it>

Hi.

I normally use a ldap authentication for my user but i would use the 
basic authentication for some user.

How can i configure squid to support both methods?

Thank you.

Antonino



-- 


Informativa sulla Privacy: http://www.unibs.it/node/8155 
<http://www.unibs.it/node/8155>


From rousskov at measurement-factory.com  Thu Jul  9 15:30:39 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 9 Jul 2020 11:30:39 -0400
Subject: [squid-users] Forcing squid to fail when the whitelist doesn't
 exist
In-Reply-To: <CAN3von5nF9QtbVn1KCQKxdELWJnjczMQZGtsAKoAvT0QrNaaSA@mail.gmail.com>
References: <CAN3von4=k=hxZ8C9X7=u1UPZ90geW7NOvcjAhpWGPHt0U7EdRw@mail.gmail.com>
 <0bcacc01-0c3a-233e-ba30-dca0735daf51@measurement-factory.com>
 <CAN3von7dEwkk7naoyEud7gXSWZvitN6n1T2-=ysx018P9JhKkw@mail.gmail.com>
 <b9bff261-daf8-323b-8d37-afc2a56c00a8@measurement-factory.com>
 <CAN3von5nF9QtbVn1KCQKxdELWJnjczMQZGtsAKoAvT0QrNaaSA@mail.gmail.com>
Message-ID: <eafa187f-a3be-b098-5354-c3f0a679a250@measurement-factory.com>

On 7/9/20 2:25 AM, Matthew Macdonald-Wallace wrote:
> 
>     > I'll check the version that we're running and see if I can do this.? I
>     > suspect that due to "enterprise requirements" our version won't be the
>     > latest, but hopefully it will support this.
> 
>     AFAICT, all supported Squid versions have parameters(). You will need to
>     enable configuration_includes_quoted_values in squid.conf to get that
>     feature. IIRC, that directive was supposed to be on by default, but that
>     cannot happen until we fix regex support (at least).

> Turns out we're running 3.5.x

I have not tested this, but if my quick reading of the latest v3.5 code
is correct, then the missing parameters() file is treated as a FATAL
configuration error (in ConfigParser::NextToken). How do you use
parameters()? What happens when you use parameters() with an existing
file? A missing file?

Alex.


From matt at mockingbirdconsulting.co.uk  Thu Jul  9 15:51:27 2020
From: matt at mockingbirdconsulting.co.uk (Matthew Macdonald-Wallace)
Date: Thu, 9 Jul 2020 16:51:27 +0100
Subject: [squid-users] Forcing squid to fail when the whitelist doesn't
	exist
In-Reply-To: <eafa187f-a3be-b098-5354-c3f0a679a250@measurement-factory.com>
References: <CAN3von4=k=hxZ8C9X7=u1UPZ90geW7NOvcjAhpWGPHt0U7EdRw@mail.gmail.com>
 <0bcacc01-0c3a-233e-ba30-dca0735daf51@measurement-factory.com>
 <CAN3von7dEwkk7naoyEud7gXSWZvitN6n1T2-=ysx018P9JhKkw@mail.gmail.com>
 <b9bff261-daf8-323b-8d37-afc2a56c00a8@measurement-factory.com>
 <CAN3von5nF9QtbVn1KCQKxdELWJnjczMQZGtsAKoAvT0QrNaaSA@mail.gmail.com>
 <eafa187f-a3be-b098-5354-c3f0a679a250@measurement-factory.com>
Message-ID: <CAN3von7-47jbqwTgKvC+32OUKaMif+80jqW-=zZY=wY1xDUEvg@mail.gmail.com>

On Thu, 9 Jul 2020 at 16:30, Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 7/9/20 2:25 AM, Matthew Macdonald-Wallace wrote:
> >
> >     > I'll check the version that we're running and see if I can do
> this.  I
> >     > suspect that due to "enterprise requirements" our version won't be
> the
> >     > latest, but hopefully it will support this.
> >
> >     AFAICT, all supported Squid versions have parameters(). You will
> need to
> >     enable configuration_includes_quoted_values in squid.conf to get that
> >     feature. IIRC, that directive was supposed to be on by default, but
> that
> >     cannot happen until we fix regex support (at least).
>
> > Turns out we're running 3.5.x
>
> I have not tested this, but if my quick reading of the latest v3.5 code
> is correct, then the missing parameters() file is treated as a FATAL
> configuration error (in ConfigParser::NextToken). How do you use
> parameters()? What happens when you use parameters() with an existing
> file? A missing file?
>

For some reason, the behaviour is the same (it starts regardless).

For now, I've added a conditional into the SystemD service file that checks
for the whitelist and only starts if it is present, and that works.

I've also logged a ticket in our internal tracker to look into upgrading to
v4 of squid, so for now it's working even if it's not the prettiest
behaviour!

Thanks for all your help :)

Matt

-- 

--
Mockingbird Consulting

Connecting you with your environment


w:?
www.mockingbirdconsulting.co.uk <http://www.mockingbirdconsulting.co.uk/>

e:?info at mockingbirdconsulting.co.uk 
<mailto:matt at mockingbirdconsulting.co.uk>
t: +44 (0)?1600 717142


Bridges 
Centre,
Drybridge House,
Monmouth,
NP25 5AS

Registered in England and 
Wales, Company Number 10488438
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200709/01467477/attachment.htm>

From rousskov at measurement-factory.com  Thu Jul  9 18:25:27 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 9 Jul 2020 14:25:27 -0400
Subject: [squid-users] Forcing squid to fail when the whitelist doesn't
 exist
In-Reply-To: <CAN3von7-47jbqwTgKvC+32OUKaMif+80jqW-=zZY=wY1xDUEvg@mail.gmail.com>
References: <CAN3von4=k=hxZ8C9X7=u1UPZ90geW7NOvcjAhpWGPHt0U7EdRw@mail.gmail.com>
 <0bcacc01-0c3a-233e-ba30-dca0735daf51@measurement-factory.com>
 <CAN3von7dEwkk7naoyEud7gXSWZvitN6n1T2-=ysx018P9JhKkw@mail.gmail.com>
 <b9bff261-daf8-323b-8d37-afc2a56c00a8@measurement-factory.com>
 <CAN3von5nF9QtbVn1KCQKxdELWJnjczMQZGtsAKoAvT0QrNaaSA@mail.gmail.com>
 <eafa187f-a3be-b098-5354-c3f0a679a250@measurement-factory.com>
 <CAN3von7-47jbqwTgKvC+32OUKaMif+80jqW-=zZY=wY1xDUEvg@mail.gmail.com>
Message-ID: <771c654c-87fc-799b-0e08-9201407f33db@measurement-factory.com>

On 7/9/20 11:51 AM, Matthew Macdonald-Wallace wrote:
> > Turns out we're running 3.5.x
> 
> I have not tested this, but if my quick reading of the latest v3.5 code
> is correct, then the missing parameters() file is treated as a FATAL
> configuration error (in ConfigParser::NextToken).


FWIW, Squid v3.5.26 works as expected in my test:

> configuration_includes_quoted_values on
> acl goodGuys ssl::server_name parameters("/missing/goodGuys.acl")
> configuration_includes_quoted_values off


> 2020/07/09 14:15:17| WARNING: file :/missing/goodGuys.acl not found
> 2020/07/09 14:15:17| FATAL: Error opening config file: parameters
> FATAL: Bungled /usr/local/squid/./etc/squid-v3p5.conf line 60: acl goodGuys ssl::server_name parameters("/missing/goodGuys.acl")
> Squid Cache (Version 3.5.26-BZR): Terminated abnormally.

Please note that configuration_includes_quoted_values is required.
Without it, Squid interprets the string
`parameters("/missing/goodGuys.acl")` as a single domain name.


HTH,

Alex.


From matt at mockingbirdconsulting.co.uk  Thu Jul  9 18:27:24 2020
From: matt at mockingbirdconsulting.co.uk (Matthew Macdonald-Wallace)
Date: Thu, 9 Jul 2020 19:27:24 +0100
Subject: [squid-users] Forcing squid to fail when the whitelist doesn't
	exist
In-Reply-To: <771c654c-87fc-799b-0e08-9201407f33db@measurement-factory.com>
References: <CAN3von4=k=hxZ8C9X7=u1UPZ90geW7NOvcjAhpWGPHt0U7EdRw@mail.gmail.com>
 <0bcacc01-0c3a-233e-ba30-dca0735daf51@measurement-factory.com>
 <CAN3von7dEwkk7naoyEud7gXSWZvitN6n1T2-=ysx018P9JhKkw@mail.gmail.com>
 <b9bff261-daf8-323b-8d37-afc2a56c00a8@measurement-factory.com>
 <CAN3von5nF9QtbVn1KCQKxdELWJnjczMQZGtsAKoAvT0QrNaaSA@mail.gmail.com>
 <eafa187f-a3be-b098-5354-c3f0a679a250@measurement-factory.com>
 <CAN3von7-47jbqwTgKvC+32OUKaMif+80jqW-=zZY=wY1xDUEvg@mail.gmail.com>
 <771c654c-87fc-799b-0e08-9201407f33db@measurement-factory.com>
Message-ID: <CAN3von5Q1JRRsoFW19WkZgp9f2XKVR2bBNvN3wpCuJ2kqBWvEQ@mail.gmail.com>

Awesome, thanks!

On Thu, 9 Jul 2020, 19:25 Alex Rousskov, <rousskov at measurement-factory.com>
wrote:

> On 7/9/20 11:51 AM, Matthew Macdonald-Wallace wrote:
> > > Turns out we're running 3.5.x
> >
> > I have not tested this, but if my quick reading of the latest v3.5 code
> > is correct, then the missing parameters() file is treated as a FATAL
> > configuration error (in ConfigParser::NextToken).
>
>
> FWIW, Squid v3.5.26 works as expected in my test:
>
> > configuration_includes_quoted_values on
> > acl goodGuys ssl::server_name parameters("/missing/goodGuys.acl")
> > configuration_includes_quoted_values off
>
>
> > 2020/07/09 14:15:17| WARNING: file :/missing/goodGuys.acl not found
> > 2020/07/09 14:15:17| FATAL: Error opening config file: parameters
> > FATAL: Bungled /usr/local/squid/./etc/squid-v3p5.conf line 60: acl
> goodGuys ssl::server_name parameters("/missing/goodGuys.acl")
> > Squid Cache (Version 3.5.26-BZR): Terminated abnormally.
>
> Please note that configuration_includes_quoted_values is required.
> Without it, Squid interprets the string
> `parameters("/missing/goodGuys.acl")` as a single domain name.
>
>
> HTH,
>
> Alex.
>

-- 

--
Mockingbird Consulting

Connecting you with your environment


w:?
www.mockingbirdconsulting.co.uk <http://www.mockingbirdconsulting.co.uk/>

e:?info at mockingbirdconsulting.co.uk 
<mailto:matt at mockingbirdconsulting.co.uk>
t: +44 (0)?1600 717142


Bridges 
Centre,
Drybridge House,
Monmouth,
NP25 5AS

Registered in England and 
Wales, Company Number 10488438
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200709/9a3ad927/attachment.htm>

From orion at nwra.com  Thu Jul  9 21:54:24 2020
From: orion at nwra.com (Orion Poplawski)
Date: Thu, 9 Jul 2020 15:54:24 -0600
Subject: [squid-users] Explicitly use direct client IP in acl
Message-ID: <07970bac-e012-df12-ec44-ec95dd0f06b7@nwra.com>

Hello -

   We're using a setup like this:

client -> e2guardian -> squid -> internet

e2guardian is providing filtering and SSL inspection.  Currently we only 
allow access to e2guardian from our internal network.  Currently we 
enforce access to squid come from localhost, except for some specific 
sites which do not work with SSL inspection.

Then we allow:

client -> squid -> internet

this is based on the (non-forwarded) client IP.

We would like to open up access to e2g from the internet but require 
authentication in that case.  This would require the use of forwarded 
IPs so the squid could distinguish between them (e2g does not do auth 
directly - it lets squid handle that).  But then this breaks our config 
above because we no longer can distinguish between connections from e2g 
and direct ones.

Is there any way in an acl to explicitly request the "direct" (i.e. 
non-indirect) IP address?  This would allow use to use one type for some 
acls and the other for other acls.  This doesn't seem possible from what 
I can see.

I'm guessing we'll need to implement a separate proxy configuration for 
external access, but I'd like to avoid it if possible.

Thanks,
   Orion

-- 
Orion Poplawski
Manager of NWRA Technical Systems          720-772-5637
NWRA, Boulder/CoRA Office             FAX: 303-415-9702
3380 Mitchell Lane                       orion at nwra.com
Boulder, CO 80301                 https://www.nwra.com/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3799 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200709/d3ac1dd3/attachment.bin>

From squid3 at treenet.co.nz  Fri Jul 10 00:39:14 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 10 Jul 2020 12:39:14 +1200
Subject: [squid-users] Double method of authentication, possible?
In-Reply-To: <955cc46a-7aae-2959-361f-ff4fc44f45ca@unibs.it>
References: <955cc46a-7aae-2959-361f-ff4fc44f45ca@unibs.it>
Message-ID: <38bd8079-d698-a7f6-da45-a8e0ad343f39@treenet.co.nz>

On 9/07/20 9:44 pm, Antonino Gianfranco Sanacori wrote:
> Hi.
> 
> I normally use a ldap authentication for my user but i would use the
> basic authentication for some user.
> 
> How can i configure squid to support both methods?


They are not two methods. So no. But yes it is possible.

-> Basic is the *scheme* in HTTP auth for representing credentials.

-> LDAP is a protocol API for talking to auth services.


HTTP supports using multiple *schemes* to authenticate clients.

Squid supports *one* helper per scheme to authenticate the credentials
provided using that scheme.

The helper you configure may *use* multiple backend services with
different APIs to check those Basic credentials coming from your
clients. Squid does not provide a helper to check multiple backends for
Basic scheme, but it is easy to write one of your own based on the
"fake" helper provided.


Amos


From squid3 at treenet.co.nz  Fri Jul 10 00:50:11 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 10 Jul 2020 12:50:11 +1200
Subject: [squid-users] Explicitly use direct client IP in acl
In-Reply-To: <07970bac-e012-df12-ec44-ec95dd0f06b7@nwra.com>
References: <07970bac-e012-df12-ec44-ec95dd0f06b7@nwra.com>
Message-ID: <cc3cbefa-8e91-5c6a-51c7-7619a38fb84f@treenet.co.nz>

On 10/07/20 9:54 am, Orion Poplawski wrote:
> Hello -
> 
> ? We're using a setup like this:
> 
> client -> e2guardian -> squid -> internet
> 
> e2guardian is providing filtering and SSL inspection.? Currently we only
> allow access to e2guardian from our internal network.? Currently we
> enforce access to squid come from localhost, except for some specific
> sites which do not work with SSL inspection.
> 
> Then we allow:
> 
> client -> squid -> internet
> 
> this is based on the (non-forwarded) client IP.
> 
> We would like to open up access to e2g from the internet but require
> authentication in that case.

Okay.

>? This would require the use of forwarded
> IPs so the squid could distinguish between them (e2g does not do auth
> directly - it lets squid handle that).? But then this breaks our config
> above because we no longer can distinguish between connections from e2g
> and direct ones.


How do you come to that conclusion?

What is your Squid version?

What is your current squid.conf contents?


Amos


From orion at nwra.com  Fri Jul 10 02:10:55 2020
From: orion at nwra.com (Orion Poplawski)
Date: Thu, 9 Jul 2020 20:10:55 -0600
Subject: [squid-users] Explicitly use direct client IP in acl
In-Reply-To: <cc3cbefa-8e91-5c6a-51c7-7619a38fb84f@treenet.co.nz>
References: <07970bac-e012-df12-ec44-ec95dd0f06b7@nwra.com>
 <cc3cbefa-8e91-5c6a-51c7-7619a38fb84f@treenet.co.nz>
Message-ID: <27726c02-cb19-7587-db0c-003e42bb4328@nwra.com>

On 7/9/20 6:50 PM, Amos Jeffries wrote:
> On 10/07/20 9:54 am, Orion Poplawski wrote:
>> Hello -
>>
>>  ? We're using a setup like this:
>>
>> client -> e2guardian -> squid -> internet
>>
>> e2guardian is providing filtering and SSL inspection.? Currently we only
>> allow access to e2guardian from our internal network.? Currently we
>> enforce access to squid come from localhost, except for some specific
>> sites which do not work with SSL inspection.
>>
>> Then we allow:
>>
>> client -> squid -> internet
>>
>> this is based on the (non-forwarded) client IP.
>>
>> We would like to open up access to e2g from the internet but require
>> authentication in that case.
> 
> Okay.
> 
>>  ? This would require the use of forwarded
>> IPs so the squid could distinguish between them (e2g does not do auth
>> directly - it lets squid handle that).? But then this breaks our config
>> above because we no longer can distinguish between connections from e2g
>> and direct ones.
> 
> 
> How do you come to that conclusion?

I don't know how to distinguish between connections that go through e2g 
and connections that do not.  Currently anything with a client IP of 
localhost has gone through e2g.  Anything with a different client IP has 
not.  If I use the X-Forwarded-As IP to distinguish between internal and 
external (for auth purposes) I no longer know how to distinguish between 
forwarded connections and non-forwarded connections.  Is there a 
forwarded flag that can be used as an acl?  I couldn't see anything in 
the acl docs.

> What is your Squid version?

3.5.20 (EL7), though I may be able to update 4.4 (EL8).

> What is your current squid.conf contents?

This part of our ansible template.  Essentially we have a list of hosts 
in "Allowed_SSL_Hosts" and "Allowed_HTTP_Hosts: that we allow any client 
to connect directly through squid to (via HTTPS/HTTP respectively).

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network

acl SSL_ports port 443
acl SSL_Ports port 563          # smtps
acl SSL_Ports port 5228         # mtalk.google.com
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl CONNECT method CONNECT

acl Allowed_SSL_Hosts ssl::server_name {{ ansible_nodename }}

# We can't MITM these, but allow them through the proxy
{% for domain in allowed_ssl_hosts %}
acl Allowed_SSL_Hosts ssl::server_name {{ domain }}
{% endfor %}
# Some hosts present problems for e2guardian for unknown reasons
{% for domain in allowed_http_hosts %}
acl Allowed_HTTP_Hosts dstdomain {{ domain }}
{% endfor %}

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# macOS Catalina is using CONNECT to gs.apple.com:80
http_access allow localnet Allowed_HTTP_Hosts

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
http_access deny to_localhost

# All traffic should be coming via e2guardian on localhost
http_access allow localhost

# Allow certain sites to be connected to directly
http_access allow CONNECT localnet Allowed_SSL_Hosts

# Allow some users/applications to connect from outside
auth_param digest realm "NWRA Proxy"
auth_param digest program /usr/lib64/squid/digest_file_auth 
/etc/squid/passwd
# freshclam only supports basic auth - 
https://bugzilla.clamav.net/show_bug.cgi?id=12468
auth_param basic realm "NWRA Proxy"
auth_param basic program /usr/lib64/squid/basic_ncsa_auth 
/etc/squid/htpasswd
acl authenticated_users proxy_auth REQUIRED
http_access allow CONNECT authenticated_users Allowed_SSL_Hosts
# freshclam 0.101.5 uses HTTP
http_access allow authenticated_users Allowed_HTTP_Hosts

# And finally deny all other access to this proxy
http_access deny all

Thank you,

   Orion

-- 
Orion Poplawski
Manager of NWRA Technical Systems          720-772-5637
NWRA, Boulder/CoRA Office             FAX: 303-415-9702
3380 Mitchell Lane                       orion at nwra.com
Boulder, CO 80301                 https://www.nwra.com/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3799 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200709/08db21ca/attachment.bin>

From squid3 at treenet.co.nz  Fri Jul 10 04:47:44 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 10 Jul 2020 16:47:44 +1200
Subject: [squid-users] Explicitly use direct client IP in acl
In-Reply-To: <27726c02-cb19-7587-db0c-003e42bb4328@nwra.com>
References: <07970bac-e012-df12-ec44-ec95dd0f06b7@nwra.com>
 <cc3cbefa-8e91-5c6a-51c7-7619a38fb84f@treenet.co.nz>
 <27726c02-cb19-7587-db0c-003e42bb4328@nwra.com>
Message-ID: <c9411cf4-ae35-6bbb-0d7e-25202e17f27f@treenet.co.nz>

On 10/07/20 2:10 pm, Orion Poplawski wrote:
> On 7/9/20 6:50 PM, Amos Jeffries wrote:
>> On 10/07/20 9:54 am, Orion Poplawski wrote:
>>> Hello -
>>>
>>> ?? We're using a setup like this:
>>>
>>> client -> e2guardian -> squid -> internet
>>>
>>> e2guardian is providing filtering and SSL inspection.? Currently we only
>>> allow access to e2guardian from our internal network.? Currently we
>>> enforce access to squid come from localhost, except for some specific
>>> sites which do not work with SSL inspection.
>>>
>>> Then we allow:
>>>
>>> client -> squid -> internet
>>>
>>> this is based on the (non-forwarded) client IP.
>>>
>>> We would like to open up access to e2g from the internet but require
>>> authentication in that case.
>>
>> Okay.
>>
>>> ?? This would require the use of forwarded
>>> IPs so the squid could distinguish between them (e2g does not do auth
>>> directly - it lets squid handle that).? But then this breaks our config
>>> above because we no longer can distinguish between connections from e2g
>>> and direct ones.
>>
>>
>> How do you come to that conclusion?
> 
> I don't know how to distinguish between connections that go through e2g
> and connections that do not.? Currently anything with a client IP of
> localhost has gone through e2g.? Anything with a different client IP has
> not.? If I use the X-Forwarded-As IP to distinguish between internal and
> external (for auth purposes) I no longer know how to distinguish between
> forwarded connections and non-forwarded connections.? Is there a
> forwarded flag that can be used as an acl?? I couldn't see anything in
> the acl docs.

The purpose of XFF feature is to see the IP beyond the e2g relay.
Properly configured Squid will have no problem determining the
difference between LAN and WAN IP ranges.

Configure e2g to set the header (if needed, it may do so by default).
Then make the following squid.conf adjustments to have only the
non-localnet clients authenticate.


> 
>> What is your Squid version?
> 
> 3.5.20 (EL7), though I may be able to update 4.4 (EL8).
> 
>> What is your current squid.conf contents?
> 
> This part of our ansible template.? Essentially we have a list of hosts
> in "Allowed_SSL_Hosts" and "Allowed_HTTP_Hosts: that we allow any client
> to connect directly through squid to (via HTTPS/HTTP respectively).
> 
> acl localnet src 10.0.0.0/8???? # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> 
> acl SSL_ports port 443
> acl SSL_Ports port 563????????? # smtps
> acl SSL_Ports port 5228???????? # mtalk.google.com
> acl Safe_ports port 80????????? # http
> acl Safe_ports port 21????????? # ftp
> acl Safe_ports port 443???????? # https
> acl CONNECT method CONNECT
> 
> acl Allowed_SSL_Hosts ssl::server_name {{ ansible_nodename }}
> 
> # We can't MITM these, but allow them through the proxy
> {% for domain in allowed_ssl_hosts %}
> acl Allowed_SSL_Hosts ssl::server_name {{ domain }}
> {% endfor %}
> # Some hosts present problems for e2guardian for unknown reasons
> {% for domain in allowed_http_hosts %}
> acl Allowed_HTTP_Hosts dstdomain {{ domain }}
> {% endfor %}
> 
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
> 
> # macOS Catalina is using CONNECT to gs.apple.com:80
> http_access allow localnet Allowed_HTTP_Hosts
> 
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> 
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
> 
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> http_access deny to_localhost
> 
> # All traffic should be coming via e2guardian on localhost

Instead use:

 # only use the XFF header(s) set by e2guardian
 follow_x_forwarded_for allow localhost
 follow_x_forwarded_for deny all

Which updates the IP Squid sees on traffic coming through e2g.


> 
> # Allow certain sites to be connected to directly
> http_access allow CONNECT localnet Allowed_SSL_Hosts

Move this down ...

> 
> # Allow some users/applications to connect from outside
> auth_param digest realm "NWRA Proxy"
> auth_param digest program /usr/lib64/squid/digest_file_auth
> /etc/squid/passwd
> # freshclam only supports basic auth -
> https://bugzilla.clamav.net/show_bug.cgi?id=12468
> auth_param basic realm "NWRA Proxy"
> auth_param basic program /usr/lib64/squid/basic_ncsa_auth
> /etc/squid/htpasswd
> acl authenticated_users proxy_auth REQUIRED
> http_access allow CONNECT authenticated_users Allowed_SSL_Hosts

Instead use:
  http_access deny !localnet !authenticated_users


... to here:
  http_access allow CONNECT Allowed_SSL_Hosts

> # freshclam 0.101.5 uses HTTP
> http_access allow authenticated_users Allowed_HTTP_Hosts
> 

Instead use:
  http_access allow !localnet Allowed_HTTP_Hosts


> # And finally deny all other access to this proxy
> http_access deny all
> 
> Thank you,
> 
> ? Orion
> 


HTH
Amos


From squid3 at treenet.co.nz  Fri Jul 10 05:03:41 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 10 Jul 2020 17:03:41 +1200
Subject: [squid-users] Squid 4.11 Howto create SSL Bump certificates
 with only 3-12 months date of expiry
In-Reply-To: <3375f400073c90c55debdd21ab57da60@schroeffu.ch>
References: <3375f400073c90c55debdd21ab57da60@schroeffu.ch>
Message-ID: <1d89a878-4c18-32bb-ab17-b8d83c8554ce@treenet.co.nz>

On 30/06/20 3:13 am, info wrote:
> 
> Hi Squid Community,
> 
> how can I configure Squid to create SSL Bump Certifications with only
> 3-12 months date of expiry?
> 

As you know Squid uses a helper to generate the certificates. You can
write a helper of your own to generate certificates with any
customizations you like.


> Currently, Squid SSL bumped Certifications are valid 20 years in my
> case, way too long, as Apple & Google & Mozilla will trust only <1 Year
> SSL certifications in the future.
> 

The helper bundled with Squid is supposed to be generating certificates
that mimic the same values received from the origin server.

... except that your config below shows that you are requiring
certificates to be generated without any origin Server information.
Which IIRC means that the CA certificate you configured is used as the
information source for dates etc.


> Thanks for any help!
> Schroeffu
> 
> my conf:
> 
> http_port {{ inventory_hostname }}:{{ squid_port }} ssl-bump
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> cert=/etc/squid/certs/(***).pem key=/etc/squid/certs/(***).pem
> sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/lib/ssl_db
> -M 4MB
> always_direct allow all

always_direct is *not* required for SSL-Bump. It was only ever needed
for a 2-week period many years ago for a bug workaround. Please remove
unless you explicitly have other reasons to use it.

> ssl_bump bump !domains_dont_sslbump

There are three solutions you might use. In order of best to worst they are:

1) Fix the ssl_bump behaviour:

 acl step1 at_step SslBump1
 ssl_bump peek step1
 ssl_bump splice domains_dont_sslbump
 ssl_bump stare all
 ssl_bump bump all


2) Fix the CA certificate you are using

Check the dates configured there give that cert a sort validity time. I
expect you have one saying 20-years right now.

You may want to do this even if you do option #1 above.


3) write your own cert generator helper


Amos


From squid3 at treenet.co.nz  Fri Jul 10 05:11:28 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 10 Jul 2020 17:11:28 +1200
Subject: [squid-users] Squid 4.12 Arch Linux Google Chrome fails -
 OpenSSL 1.1.1g
In-Reply-To: <c8e6543f-b0a3-e102-85a7-1ebbd4ed1e9b@gmail.com>
References: <72DD5D5CF661B5459DC08A060BF26B5301089333@kjj-server.KJJ.local>
 <17949f91-f48e-2558-bf76-969affa77d03@gmail.com>
 <c90411ab-f15f-29cd-6e9d-496b8a1ef914@measurement-factory.com>
 <6c9233cc-1116-c91a-ef63-f26c239a2dd8@gmail.com>
 <1e52e43d-9d69-4ba0-6710-4411a97bb183@measurement-factory.com>
 <c8e6543f-b0a3-e102-85a7-1ebbd4ed1e9b@gmail.com>
Message-ID: <c6087c8c-e038-c339-7547-820b53324a78@treenet.co.nz>

On 1/07/20 5:46 pm, Amish wrote:
> 
> I know how to use git. My question was that in that PR, I saw commits
> modifying files like Hasdshake.h, bio.cc.
> 
> But in final PR only modification was done to Handshake.cc
> 
> So I got confused. But I guess, the final PR is only what matters for my
> problem.
> 

Yes exactly. Only the final (or latest) version of a PR matters when
applying to test/use.

FWIW; The original author thought the code changes needed to be done one
way, but after some cycles of QA review, cleaning and polishing it
turned out the changes should be simpler.


Amos


From antonino.sanacori at unibs.it  Fri Jul 10 10:48:07 2020
From: antonino.sanacori at unibs.it (Antonino Gianfranco Sanacori)
Date: Fri, 10 Jul 2020 12:48:07 +0200
Subject: [squid-users] Double method of authentication, possible?
In-Reply-To: <38bd8079-d698-a7f6-da45-a8e0ad343f39@treenet.co.nz>
References: <955cc46a-7aae-2959-361f-ff4fc44f45ca@unibs.it>
 <38bd8079-d698-a7f6-da45-a8e0ad343f39@treenet.co.nz>
Message-ID: <d21be697-9c80-975e-e720-86da97f32d4c@unibs.it>

Thanks Amos.

But if i had another Squid istance on different port? to configure one 
scheme on instance A and one scheme on instance B?

Il 10/07/2020 02:39, Amos Jeffries ha scritto:
> On 9/07/20 9:44 pm, Antonino Gianfranco Sanacori wrote:
>> Hi.
>>
>> I normally use a ldap authentication for my user but i would use the
>> basic authentication for some user.
>>
>> How can i configure squid to support both methods?
>
> They are not two methods. So no. But yes it is possible.
>
> -> Basic is the *scheme* in HTTP auth for representing credentials.
>
> -> LDAP is a protocol API for talking to auth services.
>
>
> HTTP supports using multiple *schemes* to authenticate clients.
>
> Squid supports *one* helper per scheme to authenticate the credentials
> provided using that scheme.
>
> The helper you configure may *use* multiple backend services with
> different APIs to check those Basic credentials coming from your
> clients. Squid does not provide a helper to check multiple backends for
> Basic scheme, but it is easy to write one of your own based on the
> "fake" helper provided.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-- 


Informativa sulla Privacy: http://www.unibs.it/node/8155 
<http://www.unibs.it/node/8155>


From squid3 at treenet.co.nz  Fri Jul 10 12:07:54 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 11 Jul 2020 00:07:54 +1200
Subject: [squid-users] Double method of authentication, possible?
In-Reply-To: <d21be697-9c80-975e-e720-86da97f32d4c@unibs.it>
References: <955cc46a-7aae-2959-361f-ff4fc44f45ca@unibs.it>
 <38bd8079-d698-a7f6-da45-a8e0ad343f39@treenet.co.nz>
 <d21be697-9c80-975e-e720-86da97f32d4c@unibs.it>
Message-ID: <4de70143-f361-d407-78cd-5436a6980dcc@treenet.co.nz>

On 10/07/20 10:48 pm, Antonino Gianfranco Sanacori wrote:
> Thanks Amos.
> 
> But if i had another Squid istance on different port? to configure one
> scheme on instance A and one scheme on instance B?
> 

You would then have two proxies. That is not what you asked for help with.

Amos


From rousskov at measurement-factory.com  Fri Jul 10 13:11:10 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 10 Jul 2020 09:11:10 -0400
Subject: [squid-users] Squid 4.11 Howto create SSL Bump certificates
 with only 3-12 months date of expiry
In-Reply-To: <3375f400073c90c55debdd21ab57da60@schroeffu.ch>
References: <3375f400073c90c55debdd21ab57da60@schroeffu.ch>
Message-ID: <8856dacc-dabb-0eb0-fcbc-012057637692@measurement-factory.com>

On 6/29/20 11:13 AM, info at schroeffu.ch wrote:

> how can I configure Squid to create SSL Bump Certifications with only
> 3-12 months date of expiry?

See sslproxy_cert_adapt and its setValidAfter/setValidBefore algorithms.
You will need to use the corresponding dates in your fake CA. These
algorithms copy the dates from your fake CA to the generated certificate.

    http://www.squid-cache.org/Doc/config/sslproxy_cert_adapt/

HTH,

Alex.


From orion at nwra.com  Fri Jul 10 16:44:46 2020
From: orion at nwra.com (Orion Poplawski)
Date: Fri, 10 Jul 2020 10:44:46 -0600
Subject: [squid-users] Explicitly use direct client IP in acl
In-Reply-To: <c9411cf4-ae35-6bbb-0d7e-25202e17f27f@treenet.co.nz>
References: <07970bac-e012-df12-ec44-ec95dd0f06b7@nwra.com>
 <cc3cbefa-8e91-5c6a-51c7-7619a38fb84f@treenet.co.nz>
 <27726c02-cb19-7587-db0c-003e42bb4328@nwra.com>
 <c9411cf4-ae35-6bbb-0d7e-25202e17f27f@treenet.co.nz>
Message-ID: <678a3279-7743-ba07-162b-7fed86f24106@nwra.com>

On 7/9/20 10:47 PM, Amos Jeffries wrote:
> On 10/07/20 2:10 pm, Orion Poplawski wrote:
>> On 7/9/20 6:50 PM, Amos Jeffries wrote:
>>> On 10/07/20 9:54 am, Orion Poplawski wrote:
>>>> Hello -
>>>>
>>>> ?? We're using a setup like this:
>>>>
>>>> client -> e2guardian -> squid -> internet
>>>>
>>>> e2guardian is providing filtering and SSL inspection.? Currently we only
>>>> allow access to e2guardian from our internal network.? Currently we
>>>> enforce access to squid come from localhost, except for some specific
>>>> sites which do not work with SSL inspection.
>>>>
>>>> Then we allow:
>>>>
>>>> client -> squid -> internet
>>>>
>>>> this is based on the (non-forwarded) client IP.
>>>>
>>>> We would like to open up access to e2g from the internet but require
>>>> authentication in that case.
>>>
>>> Okay.
>>>
>>>> ?? This would require the use of forwarded
>>>> IPs so the squid could distinguish between them (e2g does not do auth
>>>> directly - it lets squid handle that).? But then this breaks our config
>>>> above because we no longer can distinguish between connections from e2g
>>>> and direct ones.
>>>
>>>
>>> How do you come to that conclusion?
>>
>> I don't know how to distinguish between connections that go through e2g
>> and connections that do not.? Currently anything with a client IP of
>> localhost has gone through e2g.? Anything with a different client IP has
>> not.? If I use the X-Forwarded-As IP to distinguish between internal and
>> external (for auth purposes) I no longer know how to distinguish between
>> forwarded connections and non-forwarded connections.? Is there a
>> forwarded flag that can be used as an acl?? I couldn't see anything in
>> the acl docs.
> 
> The purpose of XFF feature is to see the IP beyond the e2g relay.
> Properly configured Squid will have no problem determining the
> difference between LAN and WAN IP ranges.
> 
> Configure e2g to set the header (if needed, it may do so by default).
> Then make the following squid.conf adjustments to have only the
> non-localnet clients authenticate.
> 
> 
>>
>>> What is your Squid version?
>>
>> 3.5.20 (EL7), though I may be able to update 4.4 (EL8).
>>
>>> What is your current squid.conf contents?
>>
>> This part of our ansible template.? Essentially we have a list of hosts
>> in "Allowed_SSL_Hosts" and "Allowed_HTTP_Hosts: that we allow any client
>> to connect directly through squid to (via HTTPS/HTTP respectively).
>>
>> acl localnet src 10.0.0.0/8???? # RFC1918 possible internal network
>> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
>>
>> acl SSL_ports port 443
>> acl SSL_Ports port 563????????? # smtps
>> acl SSL_Ports port 5228???????? # mtalk.google.com
>> acl Safe_ports port 80????????? # http
>> acl Safe_ports port 21????????? # ftp
>> acl Safe_ports port 443???????? # https
>> acl CONNECT method CONNECT
>>
>> acl Allowed_SSL_Hosts ssl::server_name {{ ansible_nodename }}
>>
>> # We can't MITM these, but allow them through the proxy
>> {% for domain in allowed_ssl_hosts %}
>> acl Allowed_SSL_Hosts ssl::server_name {{ domain }}
>> {% endfor %}
>> # Some hosts present problems for e2guardian for unknown reasons
>> {% for domain in allowed_http_hosts %}
>> acl Allowed_HTTP_Hosts dstdomain {{ domain }}
>> {% endfor %}
>>
>> # Deny requests to certain unsafe ports
>> http_access deny !Safe_ports
>>
>> # macOS Catalina is using CONNECT to gs.apple.com:80
>> http_access allow localnet Allowed_HTTP_Hosts
>>
>> # Deny CONNECT to other than secure SSL ports
>> http_access deny CONNECT !SSL_ports
>>
>> # Only allow cachemgr access from localhost
>> http_access allow localhost manager
>> http_access deny manager
>>
>> # We strongly recommend the following be uncommented to protect innocent
>> # web applications running on the proxy server who think the only
>> # one who can access services on "localhost" is a local user
>> http_access deny to_localhost
>>
>> # All traffic should be coming via e2guardian on localhost
> 
> Instead use:
> 
>  # only use the XFF header(s) set by e2guardian
>  follow_x_forwarded_for allow localhost
>  follow_x_forwarded_for deny all
> 
> Which updates the IP Squid sees on traffic coming through e2g.
> 
> 
>>
>> # Allow certain sites to be connected to directly
>> http_access allow CONNECT localnet Allowed_SSL_Hosts
> 
> Move this down ...
> 
>>
>> # Allow some users/applications to connect from outside
>> auth_param digest realm "NWRA Proxy"
>> auth_param digest program /usr/lib64/squid/digest_file_auth
>> /etc/squid/passwd
>> # freshclam only supports basic auth -
>> https://bugzilla.clamav.net/show_bug.cgi?id=12468
>> auth_param basic realm "NWRA Proxy"
>> auth_param basic program /usr/lib64/squid/basic_ncsa_auth
>> /etc/squid/htpasswd
>> acl authenticated_users proxy_auth REQUIRED
>> http_access allow CONNECT authenticated_users Allowed_SSL_Hosts
> 
> Instead use:
>   http_access deny !localnet !authenticated_users
> 
> 
> ... to here:
>   http_access allow CONNECT Allowed_SSL_Hosts
> 
>> # freshclam 0.101.5 uses HTTP
>> http_access allow authenticated_users Allowed_HTTP_Hosts
>>
> 
> Instead use:
>   http_access allow !localnet Allowed_HTTP_Hosts
> 
> 
>> # And finally deny all other access to this proxy
>> http_access deny all

IIUIC - this mainly gives me:

http_access deny !localnet !authenticated_users
http_access allow CONNECT Allowed_SSL_Hosts
http_access allow !localnet Allowed_HTTP_Hosts
http_access deny all

But this will only allow connections to the sites listed in Allowed_SSL_Hosts
or Allowed_HTTP_Hosts (from remote) and not to anything else.  This is not
what I want.  I want to allow access to any site from a connection that is
forwarded from e2g.

-- 
Orion Poplawski
Manager of NWRA Technical Systems          720-772-5637
NWRA, Boulder/CoRA Office             FAX: 303-415-9702
3380 Mitchell Lane                       orion at nwra.com
Boulder, CO 80301                 https://www.nwra.com/


From squid3 at treenet.co.nz  Sat Jul 11 04:27:11 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 11 Jul 2020 16:27:11 +1200
Subject: [squid-users] Explicitly use direct client IP in acl
In-Reply-To: <678a3279-7743-ba07-162b-7fed86f24106@nwra.com>
References: <07970bac-e012-df12-ec44-ec95dd0f06b7@nwra.com>
 <cc3cbefa-8e91-5c6a-51c7-7619a38fb84f@treenet.co.nz>
 <27726c02-cb19-7587-db0c-003e42bb4328@nwra.com>
 <c9411cf4-ae35-6bbb-0d7e-25202e17f27f@treenet.co.nz>
 <678a3279-7743-ba07-162b-7fed86f24106@nwra.com>
Message-ID: <3bf58304-8265-2034-9979-2f13943f89d8@treenet.co.nz>

On 11/07/20 4:44 am, Orion Poplawski wrote:
> 
> IIUIC - this mainly gives me:
> 
> http_access deny !localnet !authenticated_users
> http_access allow CONNECT Allowed_SSL_Hosts
> http_access allow !localnet Allowed_HTTP_Hosts
> http_access deny all
> 
> But this will only allow connections to the sites listed in Allowed_SSL_Hosts
> or Allowed_HTTP_Hosts (from remote) and not to anything else.  This is not
> what I want.  I want to allow access to any site from a connection that is
> forwarded from e2g.
> 


Yes. The earlier stated policy was:

> We would like to open up access to e2g from the internet but require
> authentication in that case.

I provided the rule adjustment to add that to your existing
restrictions. As you can see the LAN is represented by localnet ACL and
the WAN clients by !localnet.


To match traffic arriving from a specific client application (aka e2g)
you have a couple of options.

a) Simplest is to use a dedicated http_port for that application. The
myportname ACL can then match all that applications traffic.
 This is quick and easy but does not prevent other applications sending
traffic to the port. Additional firewall settings are needed to prevent
that.


b) The system QoS service marking packets coming out of e2g. The
clientside_mark / clientside_tos ACLs can match this marking.


Amos


From uhlar at fantomas.sk  Wed Jul 15 07:51:44 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 15 Jul 2020 09:51:44 +0200
Subject: [squid-users] wiki timeout
Message-ID: <20200715075144.GC8230@fantomas.sk>

Hello,

hen trying to access squid wiki, I get:


Gateway Timeout

The gateway did not receive a timely response from the upstream server or application.
Apache/2.4.18 (Ubuntu) Server at wiki.squid-cache.org Port 443


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
"Two words: Windows survives." - Craig Mundie, Microsoft senior strategist
"So does syphillis. Good thing we have penicillin." - Matthew Alton


From gkinkie at gmail.com  Wed Jul 15 08:34:23 2020
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Wed, 15 Jul 2020 11:34:23 +0300
Subject: [squid-users] wiki timeout
In-Reply-To: <20200715075144.GC8230@fantomas.sk>
References: <20200715075144.GC8230@fantomas.sk>
Message-ID: <CA+Y8hcNKqPWTDPTcFo8Y2D2xMfx9L4PLZKNz5M7DCuMoT+6LbQ@mail.gmail.com>

Thanks for notifying; it's now fixed.
Apache gets stuck sometimes :(

On Wed, Jul 15, 2020 at 10:51 AM Matus UHLAR - fantomas <uhlar at fantomas.sk>
wrote:

> Hello,
>
> hen trying to access squid wiki, I get:
>
>
> Gateway Timeout
>
> The gateway did not receive a timely response from the upstream server or
> application.
> Apache/2.4.18 (Ubuntu) Server at wiki.squid-cache.org Port 443
>
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> "Two words: Windows survives." - Craig Mundie, Microsoft senior strategist
> "So does syphillis. Good thing we have penicillin." - Matthew Alton
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
    Francesco
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200715/d959d814/attachment.htm>

From uhlar at fantomas.sk  Wed Jul 15 08:40:04 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 15 Jul 2020 10:40:04 +0200
Subject: [squid-users] wiki timeout
In-Reply-To: <CA+Y8hcNKqPWTDPTcFo8Y2D2xMfx9L4PLZKNz5M7DCuMoT+6LbQ@mail.gmail.com>
References: <20200715075144.GC8230@fantomas.sk>
 <CA+Y8hcNKqPWTDPTcFo8Y2D2xMfx9L4PLZKNz5M7DCuMoT+6LbQ@mail.gmail.com>
Message-ID: <20200715084004.GD8230@fantomas.sk>

On 15.07.20 11:34, Francesco Chemolli wrote:
>Thanks for notifying; it's now fixed.

is it? I'm getting the same error.

>Apache gets stuck sometimes :(


>On Wed, Jul 15, 2020 at 10:51 AM Matus UHLAR - fantomas <uhlar at fantomas.sk>
>wrote:
>> hen trying to access squid wiki, I get:
>>
>>
>> Gateway Timeout
>>
>> The gateway did not receive a timely response from the upstream server or
>> application.
>> Apache/2.4.18 (Ubuntu) Server at wiki.squid-cache.org Port 443

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Save the whales. Collect the whole set.


From gkinkie at gmail.com  Wed Jul 15 08:45:21 2020
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Wed, 15 Jul 2020 11:45:21 +0300
Subject: [squid-users] wiki timeout
In-Reply-To: <20200715084004.GD8230@fantomas.sk>
References: <20200715075144.GC8230@fantomas.sk>
 <CA+Y8hcNKqPWTDPTcFo8Y2D2xMfx9L4PLZKNz5M7DCuMoT+6LbQ@mail.gmail.com>
 <20200715084004.GD8230@fantomas.sk>
Message-ID: <CA+Y8hcMRjcUvE+eh6dGsViDS25BvMA1M-zyOO_inzPmCgfu7yw@mail.gmail.com>

On Wed, Jul 15, 2020 at 11:40 AM Matus UHLAR - fantomas <uhlar at fantomas.sk>
wrote:

> On 15.07.20 11:34, Francesco Chemolli wrote:
> >Thanks for notifying; it's now fixed.
>
> is it? I'm getting the same error.
>

Works for me, and there's no evidence of problem on the server. Can you try
reloading?

-- 
    Francesco
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200715/076ad792/attachment.htm>

From uhlar at fantomas.sk  Wed Jul 15 08:53:24 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 15 Jul 2020 10:53:24 +0200
Subject: [squid-users] wiki timeout
In-Reply-To: <CA+Y8hcMRjcUvE+eh6dGsViDS25BvMA1M-zyOO_inzPmCgfu7yw@mail.gmail.com>
References: <20200715075144.GC8230@fantomas.sk>
 <CA+Y8hcNKqPWTDPTcFo8Y2D2xMfx9L4PLZKNz5M7DCuMoT+6LbQ@mail.gmail.com>
 <20200715084004.GD8230@fantomas.sk>
 <CA+Y8hcMRjcUvE+eh6dGsViDS25BvMA1M-zyOO_inzPmCgfu7yw@mail.gmail.com>
Message-ID: <20200715085324.GE8230@fantomas.sk>

>> On 15.07.20 11:34, Francesco Chemolli wrote:
>> >Thanks for notifying; it's now fixed.

>On Wed, Jul 15, 2020 at 11:40 AM Matus UHLAR - fantomas <uhlar at fantomas.sk>
>wrote:
>> is it? I'm getting the same error.

On 15.07.20 11:45, Francesco Chemolli wrote:
>Works for me, and there's no evidence of problem on the server. Can you try
>reloading?

I think I did - it waited some seconds, threw error again (so I assumed it's
not a problem on my side)

I reloaded, it works now - thanks.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Silvester Stallone: Father of the RISC concept.


From squid at gabucino.hu  Sat Jul 18 15:43:38 2020
From: squid at gabucino.hu (Gabor Berczi)
Date: Sat, 18 Jul 2020 17:43:38 +0200
Subject: [squid-users] Assertion failed (mempool.cc)
Message-ID: <3F62D8E4-9619-411B-86F7-EE7468662AFC@gabucino.hu>

Greets.

I've fucked up something and now newly compiled squid executables  
don't start. The previous one does. Where do I start looking?

Assertion failed: (aLabel != NULL && aSize), function  
MemImplementingAllocator, file MemPool.cc, line 394.

Program received signal SIGABRT, Aborted.
[Switching to Thread 8024041c0 (LWP 100089/initial thread)]
0x00000008020d022c in kill () from /lib/libc.so.7
(gdb) bt
#0  0x00000008020d022c in kill () from /lib/libc.so.7
#1  0x00000008020cf02b in abort () from /lib/libc.so.7
#2  0x00000008020b8355 in __assert () from /lib/libc.so.7
#3  0x00000000008188e8 in MemImplementingAllocator (this=0x80240e7c0,
     aLabel=0x845614 "Short Strings", aSize=0) at MemPool.cc:394
#4  0x000000000081a220 in MemPoolMalloc (this=0x80240e7c0,
     aLabel=<value optimized out>, aSize=<value optimized out>)
     at MemPoolMalloc.cc:96
#5  0x0000000000817d3f in MemPools::create (this=<value optimized out>,
     label=0x845614 "Short Strings", obj_size=0) at MemPool.cc:111
#6  0x00000000005d2089 in Mem::Init () at mem.cc:454
#7  0x00000000005cefce in SquidMain (argc=1, argv=0x7fffffffe7c8) at  
main.cc:1391
#8  0x00000000005cfcc3 in main (argc=<value optimized out>,
     argv=<value optimized out>) at main.cc:1265

Or with -v:

(gdb) r -v
Starting program: /tmp/squid-3.5.28/src/squid -v
[New LWP 100093]
[New Thread 8024041c0 (LWP 100093/initial thread)]
Squid Cache: Version 3.5.28

Program received signal SIGSEGV, Segmentation fault.
[Switching to Thread 8024041c0 (LWP 100093/initial thread)]
0x00000000005fe2ee in SBuf::rawContent (this=0xbf7220) at SBuf.cc:545
545         ++stats.rawAccess;
(gdb) bt
#0  0x00000000005fe2ee in SBuf::rawContent (this=0xbf7220) at SBuf.cc: 
545
#1  0x00000000005cdd9e in mainParseOptions (argc=2, argv=0x7fffffffe7b8)
     at main.cc:563
#2  0x00000000005cef9f in SquidMain (argc=2, argv=0x7fffffffe7b8) at  
main.cc:1356
#3  0x00000000005cfcc3 in main (argc=<value optimized out>,
     argv=<value optimized out>) at main.cc:1265




From squid3 at treenet.co.nz  Sat Jul 18 17:59:28 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 19 Jul 2020 05:59:28 +1200
Subject: [squid-users] Assertion failed (mempool.cc)
In-Reply-To: <3F62D8E4-9619-411B-86F7-EE7468662AFC@gabucino.hu>
References: <3F62D8E4-9619-411B-86F7-EE7468662AFC@gabucino.hu>
Message-ID: <4755f4c4-1f83-2dfc-3591-9c6f52fa3782@treenet.co.nz>

On 19/07/20 3:43 am, Gabor Berczi wrote:
> Greets.
> 
> I've fucked up something and now newly compiled squid executables don't
> start. The previous one does. Where do I start looking?
> 

Are you building in a clean build directory from a clean set of sources?

What OS are you building on?

Are you building Squid from source code fetched directly from
squid-cache.org, or from a vendor (eg your OS packages)?

What (if any) patches have been applied to the code before building?


Also, is there a particular reason you are building 3.5?
 When building software yourself it is usually best to use the latest
version available. For Squid today that is version 4.12


HTH
Amos


From squid at gabucino.hu  Sat Jul 18 18:51:00 2020
From: squid at gabucino.hu (Gabor Berczi)
Date: Sat, 18 Jul 2020 20:51:00 +0200
Subject: [squid-users] Assertion failed (mempool.cc)
In-Reply-To: <4755f4c4-1f83-2dfc-3591-9c6f52fa3782@treenet.co.nz>
References: <3F62D8E4-9619-411B-86F7-EE7468662AFC@gabucino.hu>
 <4755f4c4-1f83-2dfc-3591-9c6f52fa3782@treenet.co.nz>
Message-ID: <CFA06560-34C1-43B7-93E7-75028A44F148@gabucino.hu>


On Jul 18, 2020, at 7:59 PM, Amos Jeffries wrote:

> Are you building in a clean build directory from a clean set of  
> sources?

Yes.

> What OS are you building on?

FreeBSD 8.4 amd64 but all of it is irrelevant. I know this is PEBKAC,  
but what I'm interested in is where/why. Already tried different gcc/ 
binutils/ssl.

>
> Are you building Squid from source code fetched directly from
> squid-cache.org

Yes.

> What (if any) patches have been applied to the code before building?

No.



From rousskov at measurement-factory.com  Sat Jul 18 21:15:53 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 18 Jul 2020 17:15:53 -0400
Subject: [squid-users] Assertion failed (mempool.cc)
In-Reply-To: <3F62D8E4-9619-411B-86F7-EE7468662AFC@gabucino.hu>
References: <3F62D8E4-9619-411B-86F7-EE7468662AFC@gabucino.hu>
Message-ID: <d3ee06ee-f6e9-a0de-ba54-d57954ac2997@measurement-factory.com>

On 7/18/20 11:43 AM, Gabor Berczi wrote:

> newly compiled squid executables don't
> start. The previous one does. Where do I start looking?

I would try building the previous one again, using the exact same
procedure as you are using to build the new executable. Does the freshly
rebuilt old executable start OK? If yes, rebuild the new one from a
fresh directory. Just in case.

Also, checking (e.g., using "ldd") that both working and broken
executables are usining the same shared libraries may be useful.

Your gdb sessions suggest a broken/malformed executable. If that is what
happened, debugging it further is unlikely to be fruitful.


Good luck,

Alex.


> Assertion failed: (aLabel != NULL && aSize), function
> MemImplementingAllocator, file MemPool.cc, line 394.
> 
> Program received signal SIGABRT, Aborted.
> [Switching to Thread 8024041c0 (LWP 100089/initial thread)]
> 0x00000008020d022c in kill () from /lib/libc.so.7
> (gdb) bt
> #0? 0x00000008020d022c in kill () from /lib/libc.so.7
> #1? 0x00000008020cf02b in abort () from /lib/libc.so.7
> #2? 0x00000008020b8355 in __assert () from /lib/libc.so.7
> #3? 0x00000000008188e8 in MemImplementingAllocator (this=0x80240e7c0,
> ??? aLabel=0x845614 "Short Strings", aSize=0) at MemPool.cc:394
> #4? 0x000000000081a220 in MemPoolMalloc (this=0x80240e7c0,
> ??? aLabel=<value optimized out>, aSize=<value optimized out>)
> ??? at MemPoolMalloc.cc:96
> #5? 0x0000000000817d3f in MemPools::create (this=<value optimized out>,
> ??? label=0x845614 "Short Strings", obj_size=0) at MemPool.cc:111
> #6? 0x00000000005d2089 in Mem::Init () at mem.cc:454
> #7? 0x00000000005cefce in SquidMain (argc=1, argv=0x7fffffffe7c8) at
> main.cc:1391
> #8? 0x00000000005cfcc3 in main (argc=<value optimized out>,
> ??? argv=<value optimized out>) at main.cc:1265
> 
> Or with -v:
> 
> (gdb) r -v
> Starting program: /tmp/squid-3.5.28/src/squid -v
> [New LWP 100093]
> [New Thread 8024041c0 (LWP 100093/initial thread)]
> Squid Cache: Version 3.5.28
> 
> Program received signal SIGSEGV, Segmentation fault.
> [Switching to Thread 8024041c0 (LWP 100093/initial thread)]
> 0x00000000005fe2ee in SBuf::rawContent (this=0xbf7220) at SBuf.cc:545
> 545???????? ++stats.rawAccess;
> (gdb) bt
> #0? 0x00000000005fe2ee in SBuf::rawContent (this=0xbf7220) at SBuf.cc:545
> #1? 0x00000000005cdd9e in mainParseOptions (argc=2, argv=0x7fffffffe7b8)
> ??? at main.cc:563
> #2? 0x00000000005cef9f in SquidMain (argc=2, argv=0x7fffffffe7b8) at
> main.cc:1356
> #3? 0x00000000005cfcc3 in main (argc=<value optimized out>,
> ??? argv=<value optimized out>) at main.cc:1265



From squid at gabucino.hu  Sun Jul 19 07:35:18 2020
From: squid at gabucino.hu (Gabor Berczi)
Date: Sun, 19 Jul 2020 09:35:18 +0200
Subject: [squid-users] Assertion failed (mempool.cc)
In-Reply-To: <d3ee06ee-f6e9-a0de-ba54-d57954ac2997@measurement-factory.com>
References: <3F62D8E4-9619-411B-86F7-EE7468662AFC@gabucino.hu>
 <d3ee06ee-f6e9-a0de-ba54-d57954ac2997@measurement-factory.com>
Message-ID: <14218509-34AB-4F45-AF4F-E8688D8AD5B2@gabucino.hu>


On Jul 18, 2020, at 11:15 PM, Alex Rousskov wrote:

> I would try building the previous one again, using the exact same
> procedure as you are using to build the new executable. Does the freshly
> rebuilt old executable start OK? If yes, rebuild the new one from a
> fresh directory. Just in case.

I'm using the same shell script (e.g. options). But a plain ./configure && make
procedure is similarly unable to produce a working exe.

> Also, checking (e.g., using "ldd") that both working and broken
> executables are usining the same shared libraries may be useful.

They do.

Ah found the culprit. Turns out I was using "as" from binutils-2.27 (only checked "ld" before), mixed up with everything else.

-- 
G



From antonino.sanacori at unibs.it  Mon Jul 20 08:18:28 2020
From: antonino.sanacori at unibs.it (Antonino Sanacori)
Date: Mon, 20 Jul 2020 10:18:28 +0200
Subject: [squid-users] UDP traffic on Squid proxy
Message-ID: <647f7149-53c5-89ec-36e5-146710237477@unibs.it>

Hi.

I must use my squid proxy server to support Microsoft Teams traffic.

I would know how i can to carry udp traffic.

Thanks.

Antonino



-- 


Informativa sulla Privacy: http://www.unibs.it/node/8155 
<http://www.unibs.it/node/8155>


From squid3 at treenet.co.nz  Mon Jul 20 09:01:47 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 20 Jul 2020 21:01:47 +1200
Subject: [squid-users] UDP traffic on Squid proxy
In-Reply-To: <647f7149-53c5-89ec-36e5-146710237477@unibs.it>
References: <647f7149-53c5-89ec-36e5-146710237477@unibs.it>
Message-ID: <fbece5ec-fd43-08da-12f6-a26d49e1df92@treenet.co.nz>

On 20/07/20 8:18 pm, Antonino Sanacori wrote:
> Hi.
> 
> I must use my squid proxy server to support Microsoft Teams traffic.
> 
> I would know how i can to carry udp traffic.


Squid does not support UDP as a transport protocol at present.

Amos


From jon at thepeng.eu  Mon Jul 20 09:13:46 2020
From: jon at thepeng.eu (Jon P.)
Date: Mon, 20 Jul 2020 17:13:46 +0800
Subject: [squid-users] UDP traffic on Squid proxy
In-Reply-To: <fbece5ec-fd43-08da-12f6-a26d49e1df92@treenet.co.nz>
References: <647f7149-53c5-89ec-36e5-146710237477@unibs.it>
 <fbece5ec-fd43-08da-12f6-a26d49e1df92@treenet.co.nz>
Message-ID: <ef815181-1179-6c55-0deb-d435927ea5ec@thepeng.eu>

Hi Amos

Amos Jeffries wrote:
> Squid does not support UDP as a transport protocol at present.

Does squid support MQTT proxy? current or in future?

Thank you.


From squid3 at treenet.co.nz  Mon Jul 20 09:49:36 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 20 Jul 2020 21:49:36 +1200
Subject: [squid-users] UDP traffic on Squid proxy
In-Reply-To: <ef815181-1179-6c55-0deb-d435927ea5ec@thepeng.eu>
References: <647f7149-53c5-89ec-36e5-146710237477@unibs.it>
 <fbece5ec-fd43-08da-12f6-a26d49e1df92@treenet.co.nz>
 <ef815181-1179-6c55-0deb-d435927ea5ec@thepeng.eu>
Message-ID: <d84f96e2-c93f-ebfe-9fde-fad0d3205d82@treenet.co.nz>

On 20/07/20 9:13 pm, Jon P. wrote:
> Hi Amos
> 
> Amos Jeffries wrote:
>> Squid does not support UDP as a transport protocol at present.
> 
> Does squid support MQTT proxy? current or in future?
> 

Squid supports HTTP, HTTPS, ICY, FTP using TCP.

Squid supports ICP, HTCP, SNMP cache management using UDP.


I am not aware of any intention to support MQTT.

HTTP CONNECT tunnels do supply the transport requirements it needs, so
if the client software is able to open such tunnels through Squid then
it may be possible to use it that way.

Amos


From antonino.sanacori at unibs.it  Mon Jul 20 10:27:10 2020
From: antonino.sanacori at unibs.it (Antonino Sanacori)
Date: Mon, 20 Jul 2020 12:27:10 +0200
Subject: [squid-users] UDP traffic on Squid proxy
In-Reply-To: <d84f96e2-c93f-ebfe-9fde-fad0d3205d82@treenet.co.nz>
References: <647f7149-53c5-89ec-36e5-146710237477@unibs.it>
 <fbece5ec-fd43-08da-12f6-a26d49e1df92@treenet.co.nz>
 <ef815181-1179-6c55-0deb-d435927ea5ec@thepeng.eu>
 <d84f96e2-c93f-ebfe-9fde-fad0d3205d82@treenet.co.nz>
Message-ID: <f6ff174c-886a-3bbd-08d3-dab4ec8c664c@unibs.it>

Thanks Amos, but in my case these "HTTP CONNECT tunnels" are opened by 
squid administrator (and how?) or must the user to configure Microsoft 
Teams?

Antonino

On 20/07/2020 11:49, Amos Jeffries wrote:
> On 20/07/20 9:13 pm, Jon P. wrote:
>> Hi Amos
>>
>> Amos Jeffries wrote:
>>> Squid does not support UDP as a transport protocol at present.
>> Does squid support MQTT proxy? current or in future?
>>
> Squid supports HTTP, HTTPS, ICY, FTP using TCP.
>
> Squid supports ICP, HTCP, SNMP cache management using UDP.
>
>
> I am not aware of any intention to support MQTT.
>
> HTTP CONNECT tunnels do supply the transport requirements it needs, so
> if the client software is able to open such tunnels through Squid then
> it may be possible to use it that way.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-- 


Informativa sulla Privacy: http://www.unibs.it/node/8155 
<http://www.unibs.it/node/8155>


From ivan.bulatovic at gmail.com  Mon Jul 20 20:46:27 2020
From: ivan.bulatovic at gmail.com (Ivan Bulatovic)
Date: Mon, 20 Jul 2020 22:46:27 +0200
Subject: [squid-users] High memory usage under load with caching disabled,
 memory is not being freed even with no load
Message-ID: <CAFJ4_4sj09OixfRXb=2WBXMfDWB3ecUQ+24wg6UOez9OKpMyOg@mail.gmail.com>

Hi all,

I am trying to configure squid to run as a forward proxy with no
caching (cache deny all) with an option to choose the outgoing IP
address based on the username. So all squid has to do is to use a
certain outgoing IP address for a certain user, return the data from
the server to that user and cache nothing.

For that I created a special authentication helper and used the ACLs
and tcp_outgoing_address to create a lot of users and outgoing IP
addresses (about 260 at the moment). Example (not the real IP I use,
of course):

acl use_IP1 proxy_auth user1
tcp_outgoing_address 1.2.3.4   use_IP1

I also configured the squid to use 4 workers, but this happens even
when I use only one worker (default)

And this works. However, under heavy load, Squid eats all of the RAM
and then starts going to swap. And the memory usage does not drop when
I remove all the load from squid (I shut down all clients).

I left it to see if the memory will be freed but even after leaving it
for an hour the info page reports this:
Cache information for squid:
        Hits as % of all requests:      5min: 0.0%, 60min: 0.0%
        Hits as % of bytes sent:        5min: 0.0%, 60min: 1.1%
        Memory hits as % of hit requests:       5min: 0.0%, 60min: 0.0%
        Disk hits as % of hit requests: 5min: 0.0%, 60min: 100.0%
        Storage Swap size:      0 KB
        Storage Swap capacity:   0.0% used, 100.0% free
        Storage Mem size:       0 KB
        Storage Mem capacity:    0.0% used, 100.0% free
        Mean Object Size:       0.00 KB
        Requests given to unlinkd:      0

Resource usage for squid:
        UP Time:        255334.875 seconds
        CPU Time:       7122.436 seconds
        CPU Usage:      2.79%
        CPU Usage, 5 minute avg:        0.05%
        CPU Usage, 60 minute avg:       37.66%
        Maximum Resident Size: 41500720 KB
        Page faults with physical i/o: 1003410

And here is the listing of free and top commands (with no load on the server):

# free -h
              total        used        free      shared  buff/cache   available
Mem:            11G         10G        791M        676K        491M        1.0G
Swap:           11G        5.5G        6.5G

# top
top - 14:12:32 up 3 days,  1:30,  1 user,  load average: 0.00, 0.00, 0.00
Tasks: 177 total,   1 running, 102 sleeping,   0 stopped,   0 zombie
%Cpu0  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu1  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu2  :  0.0 us,  0.3 sy,  0.0 ni, 99.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu3  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu4  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu5  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu6  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu7  :  0.0 us,  0.0 sy,  0.0 ni,100.0 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem : 91.2/12251688
[|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||
        ]
KiB Swap: 45.8/12582904
[||||||||||||||||||||||||||||||||||||||||||||||
                              ]

   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
  7851 proxy     20   0 6946872 2.514g   8084 S   0.0 21.5  29:43.74 squid
  7832 proxy     20   0 6711480 2.464g   8040 S   0.0 21.1  29:58.17 squid
  7814 proxy     20   0 6834928 2.454g  10024 S   0.0 21.0  29:47.56 squid
  7843 proxy     20   0 6906252 2.436g   8208 S   0.0 20.8  29:15.60 squid
  1329 root      20   0 2416672 167272  12680 S   0.0  1.4 136:18.57 metricbeat
  1321 root      20   0 1831804  48364  11648 S   0.0  0.4  14:32.10 filebeat
   474 root      19  -1  127796  17576  17144 S   0.0  0.1   0:27.01
systemd-journal
  7811 proxy     20   0  549384  14168   8372 S   0.0  0.1   0:20.87 squid
  1166 root      20   0 1749724  10596   4468 S   0.0  0.1   0:31.83 snapd
 43940 proxy     20   0   28884   9608   5384 S   0.0  0.1   0:00.14 python3
 43941 proxy     20   0   28884   9552   5328 S   0.0  0.1   0:00.10 python3
 43939 proxy     20   0   28884   9524   5308 S   0.0  0.1   0:00.12 python3
 43938 proxy     20   0   28884   9452   5232 S   0.0  0.1   0:00.16 python3
 48848 root      20   0  105688   6960   5968 S   0.0  0.1   0:00.02 sshd
 48974 janitor   20   0  108120   5380   4372 S   0.0  0.0   0:00.00 sshd
     1 root      20   0   86360   4364   2488 S   0.0  0.0  32:46.22 systemd
...
... lines ommited
...

In the attachment you can find the printout from squidclient mgr:info
and squidclient mgr:mem. These are both taken at the moment when there
is no more load on the proxy. I also included my squid.conf file
(minus the two files where acls are defined and outgoing IP addresses,
these two contain only acl and tcp_outgoing_address lines as in the
example above).

Machine info:
OS: Ubuntu 18.04 with latest updates
Squid version 4.12 (from diladele repository)
Hardware: Hyper-V virtual machine with 8 vCPU, 12GB of RAM

I can not understand what is eating all of the memory, if I disabled the cache.

Maybe I configured something wrong but I can not find what.

Thank you for any help you can provide.

Best regards,
Ivan
-------------- next part --------------
HTTP/1.1 200 OK
Server: squid
Mime-Version: 1.0
Date: Mon, 20 Jul 2020 19:45:24 GMT
Content-Type: text/plain
Expires: Mon, 20 Jul 2020 19:45:24 GMT
Last-Modified: Mon, 20 Jul 2020 19:45:24 GMT
Connection: close

by kid1 {
Current memory usage:
Pool	 Obj Size	Chunks							Allocated					In Use					Idle			Allocations Saved			Rate	
 	 (bytes)	KB/ch	 obj/ch	(#)	 used	 free	 part	 %Frag	 (#)	 (KB)	 high (KB)	 high (hrs)	 %Tot	(#)	 (KB)	 high (KB)	 high (hrs)	 %alloc	(#)	 (KB)	 high (KB)	(#)	 %cnt	 %vol	(#)/sec	
mem_node            	 4136	 	 	 	 	 	 	 	 130	 526	 796	 1.58	 24.513	 127	 513	 796	 1.58	 97.692	 3	 13	 291	 133952	 0.217	 2.426	 0.179
net_db_name         	   32	 	 	 	 	 	 	 	 5712	 179	 180	 1.47	 8.333	 5712	 179	 180	 1.47	 100.000	 0	 0	 3	 129	 0.000	 0.000	 0.000
netdbEntry          	  168	 	 	 	 	 	 	 	 983	 162	 165	 2.07	 7.529	 983	 162	 165	 2.07	 100.000	 0	 0	 17	 66	 0.000	 0.000	 0.000
cbdata idns_query (18)	 8696	 	 	 	 	 	 	 	 15	 128	 247	 1.86	 5.947	 0	 0	 247	 1.86	 0.000	 15	 128	 247	 93211	 0.151	 3.550	 0.000
Short Strings       	   40	 	 	 	 	 	 	 	 3237	 127	 22532	 2.33	 5.903	 3072	 120	 22532	 2.33	 94.903	 165	 7	 1152	 25706063	 41.632	 4.503	 0.583
ipcache_entry       	  128	 	 	 	 	 	 	 	 930	 117	 126	 1.79	 5.427	 920	 115	 126	 1.79	 98.925	 10	 2	 11	 60137	 0.097	 0.034	 0.000
HttpRequest         	 1880	 	 	 	 	 	 	 	 63	 116	 75579	 2.33	 5.400	 51	 94	 75579	 2.33	 80.952	 12	 23	 3884	 717076	 1.161	 5.904	 0.000
cbdata clientReplyContext (20)	 4352	 	 	 	 	 	 	 	 12	 51	 174739	 2.33	 2.381	 0	 0	 174739	 2.33	 0.000	 12	 51	 8989	 717004	 1.161	 13.666	 0.000
HttpHeaderEntry     	   56	 	 	 	 	 	 	 	 914	 50	 9043	 2.33	 2.333	 861	 48	 9043	 2.33	 94.201	 53	 3	 463	 6280435	 10.171	 1.540	 0.000
Stream              	 4216	 	 	 	 	 	 	 	 12	 50	 169279	 2.33	 2.306	 0	 0	 169279	 2.33	 0.000	 12	 50	 8708	 717004	 1.161	 13.239	 0.000
4KB Strings         	 4096	 	 	 	 	 	 	 	 12	 48	 164460	 2.33	 2.241	 0	 0	 164460	 2.33	 0.000	 12	 48	 8456	 721270	 1.168	 12.938	 0.000
cbdata Tree (1)     	  176	 	 	 	 	 	 	 	 274	 48	 48	 71.60	 2.199	 274	 48	 48	 71.60	 100.000	 0	 0	 48	 274	 0.000	 0.000	 0.000
ClientInfo          	  448	 	 	 	 	 	 	 	 98	 43	 43	 0.65	 2.002	 98	 43	 43	 0.65	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
MemObject           	  344	 	 	 	 	 	 	 	 124	 42	 43	 1.68	 1.945	 124	 42	 43	 1.68	 100.000	 0	 0	 3	 128878	 0.209	 0.194	 0.045
HttpReply           	  288	 	 	 	 	 	 	 	 124	 35	 38	 1.68	 1.628	 124	 35	 38	 1.68	 100.000	 0	 0	 4	 388311	 0.629	 0.490	 0.045
MemBlob             	   48	 	 	 	 	 	 	 	 737	 35	 5823	 2.33	 1.613	 700	 33	 5823	 2.33	 94.980	 37	 2	 298	 3967500	 6.426	 0.834	 0.090
AndNode             	  120	 	 	 	 	 	 	 	 282	 34	 34	 0.96	 1.543	 282	 34	 34	 0.96	 100.000	 0	 0	 33	 281	 0.000	 0.000	 0.000
32K Buffer          	 32768	 	 	 	 	 	 	 	 1	 32	 64	 31.34	 1.494	 1	 32	 64	 31.34	 100.000	 0	 0	 32	 157	 0.000	 0.023	 0.000
Medium Strings      	  128	 	 	 	 	 	 	 	 238	 30	 10566	 2.33	 1.389	 212	 27	 10566	 2.33	 89.076	 26	 4	 546	 3031586	 4.910	 1.699	 0.000
ACLProxyAuth        	  112	 	 	 	 	 	 	 	 265	 29	 29	 71.60	 1.353	 265	 29	 29	 71.60	 100.000	 0	 0	 29	 265	 0.000	 0.000	 0.000
acl_proxy_auth_match_cache	   40	 	 	 	 	 	 	 	 725	 29	 1472	 1.22	 1.322	 725	 29	 1472	 1.22	 100.000	 0	 0	 943	 4445	 0.007	 0.001	 0.000
MimeEntry           	  144	 	 	 	 	 	 	 	 177	 25	 25	 71.60	 1.162	 177	 25	 25	 71.60	 100.000	 0	 0	 25	 177	 0.000	 0.000	 0.000
Auth::Basic::User   	  224	 	 	 	 	 	 	 	 97	 22	 62	 1.22	 0.991	 96	 21	 62	 1.22	 98.969	 1	 1	 42	 664827	 1.077	 0.652	 0.000
cbdata Address (3)  	   72	 	 	 	 	 	 	 	 264	 19	 19	 71.60	 0.867	 264	 19	 19	 71.60	 100.000	 0	 0	 19	 264	 0.000	 0.000	 0.000
ACLUserData         	   64	 	 	 	 	 	 	 	 265	 17	 17	 71.60	 0.773	 265	 17	 17	 71.60	 100.000	 0	 0	 17	 265	 0.000	 0.000	 0.000
fqdncache_entry     	  160	 	 	 	 	 	 	 	 104	 17	 17	 1.98	 0.759	 104	 17	 17	 1.98	 100.000	 0	 0	 2	 319	 0.001	 0.000	 0.000
16KB Strings        	 16384	 	 	 	 	 	 	 	 1	 16	 80	 2.14	 0.747	 0	 0	 80	 2.14	 0.000	 1	 16	 80	 3348	 0.005	 0.240	 0.000
8K Buffer           	 8192	 	 	 	 	 	 	 	 2	 16	 40	 2.00	 0.747	 1	 8	 40	 2.00	 50.000	 1	 8	 32	 130347	 0.211	 4.676	 0.000
StoreEntry          	  120	 	 	 	 	 	 	 	 124	 15	 15	 1.68	 0.678	 124	 15	 15	 1.68	 100.000	 0	 0	 1	 128878	 0.209	 0.068	 0.045
Comm::Connection    	  208	 	 	 	 	 	 	 	 66	 14	 40186	 2.33	 0.626	 7	 2	 40186	 2.33	 10.606	 59	 12	 1871	 3342006	 5.413	 3.044	 0.090
2K Buffer           	 2048	 	 	 	 	 	 	 	 5	 10	 16	 2.44	 0.467	 3	 6	 16	 2.44	 60.000	 2	 4	 10	 1169737	 1.894	 10.491	 0.000
cbdata Server (16)  	  800	 	 	 	 	 	 	 	 12	 10	 32211	 2.33	 0.438	 0	 0	 32211	 2.33	 0.000	 12	 10	 1652	 718260	 1.163	 2.516	 0.000
cbdata MemBuf (7)   	   72	 	 	 	 	 	 	 	 126	 9	 10	 1.68	 0.414	 125	 9	 10	 1.68	 99.206	 1	 1	 1	 647341	 1.048	 0.204	 0.045
AuthUserIP          	   64	 	 	 	 	 	 	 	 96	 6	 25	 1.80	 0.280	 96	 6	 25	 1.80	 100.000	 0	 0	 12	 333768	 0.541	 0.094	 0.000
HttpHdrCc           	   96	 	 	 	 	 	 	 	 51	 5	 6	 2.28	 0.223	 51	 5	 6	 2.28	 100.000	 0	 0	 1	 5440	 0.009	 0.002	 0.000
cbdata ClientHttpRequest (19)	  392	 	 	 	 	 	 	 	 12	 5	 15740	 2.33	 0.214	 0	 0	 15740	 2.33	 0.000	 12	 5	 810	 717004	 1.161	 1.231	 0.000
cbdata UdsSender (8)	 4528	 	 	 	 	 	 	 	 1	 5	 9	 71.60	 0.206	 0	 0	 9	 71.60	 0.000	 1	 5	 9	 17	 0.000	 0.000	 0.045
cbdata Strand (9)   	 4520	 	 	 	 	 	 	 	 1	 5	 5	 71.60	 0.206	 1	 5	 5	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
cbdata TunnelStateData (26)	  352	 	 	 	 	 	 	 	 12	 5	 14133	 2.33	 0.193	 0	 0	 14133	 2.33	 0.000	 12	 5	 728	 587849	 0.952	 0.906	 0.000
cbdata Filler (12)  	 4216	 	 	 	 	 	 	 	 1	 5	 5	 71.39	 0.192	 1	 5	 5	 71.39	 100.000	 0	 0	 5	 9	 0.000	 0.000	 0.045
4K Buffer           	 4096	 	 	 	 	 	 	 	 1	 4	 20	 1.71	 0.187	 0	 0	 20	 1.71	 0.000	 1	 4	 20	 131717	 0.213	 2.363	 0.000
cbdata ACLFilledChecklist (23)	  496	 	 	 	 	 	 	 	 7	 4	 7	 1.86	 0.158	 0	 0	 7	 1.86	 0.000	 7	 4	 7	 1456592	 2.359	 3.164	 0.000
cbdata clientStreamNode (21)	  128	 	 	 	 	 	 	 	 24	 3	 10279	 2.33	 0.140	 0	 0	 10279	 2.33	 0.000	 24	 3	 529	 1422674	 2.304	 0.798	 0.000
MD5 digest          	   16	 	 	 	 	 	 	 	 124	 2	 2	 1.68	 0.090	 124	 2	 2	 1.68	 100.000	 0	 0	 1	 129021	 0.209	 0.009	 0.045
acl_ip_data         	   96	 	 	 	 	 	 	 	 10	 1	 1	 71.60	 0.044	 10	 1	 1	 71.60	 100.000	 0	 0	 1	 14	 0.000	 0.000	 0.000
cbdata Logfile (5)  	  352	 	 	 	 	 	 	 	 2	 1	 1	 70.85	 0.032	 1	 1	 1	 70.85	 50.000	 1	 1	 1	 67	 0.000	 0.000	 0.000
ev_entry            	   48	 	 	 	 	 	 	 	 14	 1	 1	 2.45	 0.031	 13	 1	 1	 2.45	 92.857	 1	 1	 1	 607481	 0.984	 0.128	 2.378
cbdata ClientRequestContext (22)	  104	 	 	 	 	 	 	 	 6	 1	 2	 1.86	 0.028	 0	 0	 2	 1.86	 0.000	 6	 1	 2	 791483	 1.282	 0.360	 0.000
ACLStrategised      	  120	 	 	 	 	 	 	 	 5	 1	 1	 71.60	 0.027	 5	 1	 1	 71.60	 100.000	 0	 0	 1	 5	 0.000	 0.000	 0.000
RefreshPattern      	  144	 	 	 	 	 	 	 	 4	 1	 1	 71.60	 0.026	 4	 1	 1	 71.60	 100.000	 0	 0	 1	 4	 0.000	 0.000	 0.000
Auth::Basic::UserRequest	   48	 	 	 	 	 	 	 	 12	 1	 1928	 2.33	 0.026	 0	 0	 1928	 2.33	 0.000	 12	 1	 100	 590172	 0.956	 0.124	 0.000
cbdata ConnOpener (28)	  136	 	 	 	 	 	 	 	 4	 1	 14	 1.80	 0.025	 0	 0	 14	 1.80	 0.000	 4	 1	 14	 660001	 1.069	 0.393	 0.000
cbdata generic_cbdata (17)	   32	 	 	 	 	 	 	 	 13	 1	 1	 1.86	 0.019	 0	 0	 1	 1.86	 0.000	 13	 1	 1	 74078	 0.120	 0.010	 0.000
cbdata helper_server (15)	  336	 	 	 	 	 	 	 	 1	 1	 1	 31.34	 0.015	 1	 1	 1	 31.34	 100.000	 0	 0	 1	 2	 0.000	 0.000	 0.000
ACLSslErrorData     	   64	 	 	 	 	 	 	 	 5	 1	 1	 71.60	 0.015	 5	 1	 1	 71.60	 100.000	 0	 0	 1	 5	 0.000	 0.000	 0.000
ACLSourceIP         	  104	 	 	 	 	 	 	 	 3	 1	 1	 71.60	 0.014	 3	 1	 1	 71.60	 100.000	 0	 0	 1	 3	 0.000	 0.000	 0.000
cbdata helper (4)   	  296	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.013	 1	 1	 1	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
cbdata TcpAcceptor (11)	   96	 	 	 	 	 	 	 	 3	 1	 1	 71.60	 0.013	 3	 1	 1	 71.60	 100.000	 0	 0	 1	 3	 0.000	 0.000	 0.000
cbdata ps_state (27)	  256	 	 	 	 	 	 	 	 1	 1	 1	 10.01	 0.012	 0	 0	 1	 10.01	 0.000	 1	 1	 1	 665101	 1.077	 0.746	 0.000
ACLStrategised      	  120	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.011	 2	 1	 1	 71.60	 100.000	 0	 0	 1	 2	 0.000	 0.000	 0.000
NotNode             	  120	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.011	 2	 1	 1	 71.60	 100.000	 0	 0	 1	 2	 0.000	 0.000	 0.000
cbdata ErrorState (29)	  240	 	 	 	 	 	 	 	 1	 1	 1	 1.63	 0.011	 0	 0	 1	 1.63	 0.000	 1	 1	 1	 128166	 0.208	 0.135	 0.000
cbdata RemovalPolicy (2)	  104	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.009	 2	 1	 1	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
Helper::Xaction     	  184	 	 	 	 	 	 	 	 1	 1	 1	 10.01	 0.008	 0	 0	 1	 10.01	 0.000	 1	 1	 1	 379	 0.001	 0.000	 0.000
cbdata LocalSearch (10)	   80	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.007	 1	 1	 1	 71.60	 50.000	 1	 1	 1	 69	 0.000	 0.000	 0.000
cbdata store_client (13)	  160	 	 	 	 	 	 	 	 1	 1	 1	 1.68	 0.007	 1	 1	 1	 1.68	 100.000	 0	 0	 1	 128893	 0.209	 0.090	 0.045
ACLStrategised      	  120	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.005	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
ACLStrategised      	  120	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.005	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
ACLDestinationIP    	  112	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.005	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
cbdata Forwarder (33)	  112	 	 	 	 	 	 	 	 1	 1	 1	 1.43	 0.005	 0	 0	 1	 1.43	 0.000	 1	 1	 1	 0	 0.000	 0.000	 0.000
cbdata CredentialsCache (24)	   96	 	 	 	 	 	 	 	 1	 1	 1	 10.01	 0.004	 1	 1	 1	 10.01	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
wordlist            	   16	 	 	 	 	 	 	 	 4	 1	 1	 0.96	 0.003	 4	 1	 1	 0.96	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
cbdata StateData (25)	   48	 	 	 	 	 	 	 	 1	 1	 1	 10.01	 0.002	 0	 0	 1	 10.01	 0.000	 1	 1	 1	 379	 0.001	 0.000	 0.000
CacheDigest         	   40	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.002	 1	 1	 1	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
ACLRegexData        	   32	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.001	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
ACLMethodData       	   32	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.001	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
FwdServer           	   32	 	 	 	 	 	 	 	 1	 1	 1	 10.01	 0.001	 0	 0	 1	 10.01	 0.000	 1	 1	 1	 665101	 1.077	 0.093	 0.000
Long Strings        	  512	 	 	 	 	 	 	 	 0	 0	 8	 1.90	 0.000	 0	 0	 8	 1.90	 -1.000	 0	 0	 8	 9705	 0.016	 0.022	 0.000
1KB Strings         	 1024	 	 	 	 	 	 	 	 0	 0	 3	 2.41	 0.000	 0	 0	 3	 2.41	 -1.000	 0	 0	 3	 1387	 0.002	 0.006	 0.000
16K Buffer          	 16384	 	 	 	 	 	 	 	 0	 0	 16	 2.45	 0.000	 0	 0	 16	 2.45	 -1.000	 0	 0	 16	 469	 0.001	 0.034	 0.000
64K Buffer          	 65536	 	 	 	 	 	 	 	 0	 0	 64	 2.29	 0.000	 0	 0	 64	 2.29	 -1.000	 0	 0	 64	 47	 0.000	 0.013	 0.000
dwrite_q            	   48	 	 	 	 	 	 	 	 0	 0	 1	 71.60	 0.000	 0	 0	 1	 71.60	 -1.000	 0	 0	 1	 0	 0.000	 0.000	 0.000
cbdata RebuildState (6)	  920	 	 	 	 	 	 	 	 0	 0	 1	 71.60	 0.000	 0	 0	 1	 71.60	 -1.000	 0	 0	 1	 0	 0.000	 0.000	 0.000
cbdata RemovalPolicyWalker (14)	   56	 	 	 	 	 	 	 	 0	 0	 1	 55.34	 0.000	 0	 0	 1	 55.34	 -1.000	 0	 0	 1	 2	 0.000	 0.000	 0.000
Auth::QueueNode     	   32	 	 	 	 	 	 	 	 0	 0	 1	 9.94	 0.000	 0	 0	 1	 9.94	 -1.000	 0	 0	 1	 6	 0.000	 0.000	 0.000
cbdata FwdState (30)	  176	 	 	 	 	 	 	 	 0	 0	 1	 2.45	 0.000	 0	 0	 1	 2.45	 -1.000	 0	 0	 1	 2118	 0.003	 0.002	 0.000
cbdata HttpStateData (31)	  352	 	 	 	 	 	 	 	 0	 0	 2	 2.44	 0.000	 0	 0	 2	 2.44	 -1.000	 0	 0	 2	 2024	 0.003	 0.003	 0.000
cbdata CbDataList (32)	   96	 	 	 	 	 	 	 	 0	 0	 1	 2.44	 0.000	 0	 0	 1	 2.44	 -1.000	 0	 0	 1	 148	 0.000	 0.000	 0.000
Total               	    1	 	 	 	 	 	 	 	 16570	 2143	 749487	 2.33	 100.000	 16035	 1740	 746197	 2.33	 81.227	 535	 403	 37679	 58585225	 94.881	 93.661	 2769894.513
Cumulative allocated volume: 22.834 GB
Current overhead: 28155 bytes (1.580%)
Idle pool limit: 5.00 MB
Total Pools created: 90
Pools ever used:     88 (shown above)
Currently in use:    55
String Pool	 Impact		
 	 (%strings)	 (%volume)
Short Strings       	 96	 84
Medium Strings      	 7	 18
Long Strings        	 0	 0
1KB Strings         	 0	 0
4KB Strings         	 0	 0
16KB Strings        	 0	 0
Other Strings       	 -2	 -2147483648

Large buffers: 0 (0 KB)
} by kid1

by kid2 {
Current memory usage:
Pool	 Obj Size	Chunks							Allocated					In Use					Idle			Allocations Saved			Rate	
 	 (bytes)	KB/ch	 obj/ch	(#)	 used	 free	 part	 %Frag	 (#)	 (KB)	 high (KB)	 high (hrs)	 %Tot	(#)	 (KB)	 high (KB)	 high (hrs)	 %alloc	(#)	 (KB)	 high (KB)	(#)	 %cnt	 %vol	(#)/sec	
mem_node            	 4136	 	 	 	 	 	 	 	 130	 526	 792	 1.58	 25.857	 127	 513	 792	 1.58	 97.692	 3	 13	 287	 131865	 0.215	 2.410	 0.179
net_db_name         	   32	 	 	 	 	 	 	 	 5569	 175	 175	 1.40	 8.570	 5569	 175	 175	 1.40	 100.000	 0	 0	 2	 89	 0.000	 0.000	 0.000
netdbEntry          	  168	 	 	 	 	 	 	 	 944	 155	 165	 2.05	 7.627	 944	 155	 165	 2.05	 100.000	 0	 0	 17	 77	 0.000	 0.000	 0.000
Short Strings       	   40	 	 	 	 	 	 	 	 3180	 125	 22988	 2.33	 6.117	 3067	 120	 22988	 2.33	 96.447	 113	 5	 1296	 25498081	 41.620	 4.508	 0.583
ipcache_entry       	  128	 	 	 	 	 	 	 	 925	 116	 125	 1.79	 5.694	 920	 115	 125	 1.79	 99.459	 5	 1	 11	 58261	 0.095	 0.033	 0.000
HttpRequest         	 1880	 	 	 	 	 	 	 	 61	 112	 77110	 2.33	 5.515	 51	 94	 77110	 2.33	 83.607	 10	 19	 4383	 712250	 1.163	 5.918	 0.000
cbdata idns_query (24)	 8696	 	 	 	 	 	 	 	 8	 68	 323	 2.46	 3.346	 0	 0	 323	 2.46	 0.000	 8	 68	 323	 90355	 0.147	 3.473	 0.000
HttpHeaderEntry     	   56	 	 	 	 	 	 	 	 897	 50	 9224	 2.33	 2.416	 861	 48	 9224	 2.33	 95.987	 36	 2	 522	 6226159	 10.163	 1.541	 0.000
cbdata Tree (1)     	  176	 	 	 	 	 	 	 	 274	 48	 48	 71.60	 2.319	 274	 48	 48	 71.60	 100.000	 0	 0	 48	 274	 0.000	 0.000	 0.000
ClientInfo          	  448	 	 	 	 	 	 	 	 98	 43	 43	 0.96	 2.111	 98	 43	 43	 0.96	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
cbdata clientReplyContext (14)	 4352	 	 	 	 	 	 	 	 10	 43	 178284	 2.33	 2.093	 0	 0	 178284	 2.33	 0.000	 10	 43	 10145	 712177	 1.162	 13.698	 0.000
MemObject           	  344	 	 	 	 	 	 	 	 124	 42	 43	 1.67	 2.051	 124	 42	 43	 1.67	 100.000	 0	 0	 3	 127385	 0.208	 0.194	 0.045
Stream              	 4216	 	 	 	 	 	 	 	 10	 42	 172712	 2.33	 2.027	 0	 0	 172712	 2.33	 0.000	 10	 42	 9828	 712177	 1.162	 13.270	 0.000
4KB Strings         	 4096	 	 	 	 	 	 	 	 10	 40	 167796	 2.33	 1.970	 0	 0	 167796	 2.33	 0.000	 10	 40	 9548	 716170	 1.169	 12.965	 0.000
HttpReply           	  288	 	 	 	 	 	 	 	 125	 36	 38	 1.66	 1.731	 124	 35	 38	 1.66	 99.200	 1	 1	 4	 383847	 0.627	 0.489	 0.045
MemBlob             	   48	 	 	 	 	 	 	 	 717	 34	 5940	 2.33	 1.655	 695	 33	 5940	 2.33	 96.932	 22	 2	 336	 3938205	 6.428	 0.835	 0.090
AndNode             	  120	 	 	 	 	 	 	 	 282	 34	 34	 0.96	 1.627	 282	 34	 34	 0.96	 100.000	 0	 0	 33	 281	 0.000	 0.000	 0.000
32K Buffer          	 32768	 	 	 	 	 	 	 	 1	 32	 64	 31.34	 1.576	 1	 32	 64	 31.34	 100.000	 0	 0	 32	 130	 0.000	 0.019	 0.000
ACLProxyAuth        	  112	 	 	 	 	 	 	 	 265	 29	 29	 71.60	 1.427	 265	 29	 29	 71.60	 100.000	 0	 0	 29	 265	 0.000	 0.000	 0.000
Medium Strings      	  128	 	 	 	 	 	 	 	 231	 29	 10801	 2.28	 1.422	 212	 27	 10801	 2.28	 91.775	 19	 3	 624	 3010597	 4.914	 1.703	 0.000
acl_proxy_auth_match_cache	   40	 	 	 	 	 	 	 	 725	 29	 1397	 2.47	 1.395	 725	 29	 1397	 2.47	 100.000	 0	 0	 825	 4645	 0.008	 0.001	 0.000
MimeEntry           	  144	 	 	 	 	 	 	 	 177	 25	 25	 71.60	 1.226	 177	 25	 25	 71.60	 100.000	 0	 0	 25	 177	 0.000	 0.000	 0.000
Auth::Basic::User   	  224	 	 	 	 	 	 	 	 93	 21	 58	 2.47	 1.002	 91	 20	 58	 2.47	 97.849	 2	 1	 40	 660911	 1.079	 0.654	 0.000
cbdata Address (3)  	   72	 	 	 	 	 	 	 	 264	 19	 19	 71.60	 0.914	 264	 19	 19	 71.60	 100.000	 0	 0	 19	 264	 0.000	 0.000	 0.000
ACLUserData         	   64	 	 	 	 	 	 	 	 265	 17	 17	 71.60	 0.816	 265	 17	 17	 71.60	 100.000	 0	 0	 17	 265	 0.000	 0.000	 0.000
fqdncache_entry     	  160	 	 	 	 	 	 	 	 104	 17	 17	 1.95	 0.800	 104	 17	 17	 1.95	 100.000	 0	 0	 2	 319	 0.001	 0.000	 0.000
16KB Strings        	 16384	 	 	 	 	 	 	 	 1	 16	 80	 2.39	 0.788	 0	 0	 80	 2.39	 0.000	 1	 16	 80	 3181	 0.005	 0.230	 0.000
8K Buffer           	 8192	 	 	 	 	 	 	 	 2	 16	 56	 1.66	 0.788	 1	 8	 56	 1.66	 50.000	 1	 8	 48	 128359	 0.210	 4.647	 0.000
StoreEntry          	  120	 	 	 	 	 	 	 	 124	 15	 15	 1.67	 0.716	 124	 15	 15	 1.67	 100.000	 0	 0	 1	 127385	 0.208	 0.068	 0.045
2K Buffer           	 2048	 	 	 	 	 	 	 	 5	 10	 14	 2.45	 0.492	 3	 6	 14	 2.45	 60.000	 2	 4	 8	 1156300	 1.887	 10.466	 0.000
Comm::Connection    	  208	 	 	 	 	 	 	 	 45	 10	 40916	 2.33	 0.450	 7	 2	 40916	 2.33	 15.556	 38	 8	 1910	 3323770	 5.425	 3.055	 0.090
cbdata MemBuf (7)   	   72	 	 	 	 	 	 	 	 127	 9	 10	 1.66	 0.440	 125	 9	 10	 1.66	 98.425	 2	 1	 1	 640021	 1.045	 0.204	 0.045
4K Buffer           	 4096	 	 	 	 	 	 	 	 2	 8	 24	 1.66	 0.394	 0	 0	 24	 1.66	 0.000	 2	 8	 24	 130506	 0.213	 2.363	 0.000
cbdata Server (12)  	  800	 	 	 	 	 	 	 	 10	 8	 32853	 2.33	 0.385	 0	 0	 32853	 2.33	 0.000	 10	 8	 1868	 713074	 1.164	 2.521	 0.000
AuthUserIP          	   64	 	 	 	 	 	 	 	 92	 6	 25	 2.37	 0.283	 91	 6	 25	 2.37	 98.913	 1	 1	 12	 333689	 0.545	 0.094	 0.000
HttpHdrCc           	   96	 	 	 	 	 	 	 	 51	 5	 6	 2.27	 0.235	 51	 5	 6	 2.27	 100.000	 0	 0	 1	 5098	 0.008	 0.002	 0.000
cbdata UdsSender (8)	 4528	 	 	 	 	 	 	 	 1	 5	 9	 71.60	 0.218	 0	 0	 9	 71.60	 0.000	 1	 5	 9	 18	 0.000	 0.000	 0.045
cbdata Strand (9)   	 4520	 	 	 	 	 	 	 	 1	 5	 5	 71.60	 0.217	 1	 5	 5	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
cbdata Filler (20)  	 4216	 	 	 	 	 	 	 	 1	 5	 5	 71.39	 0.203	 1	 5	 5	 71.39	 100.000	 0	 0	 5	 8	 0.000	 0.000	 0.045
cbdata ClientHttpRequest (13)	  392	 	 	 	 	 	 	 	 10	 4	 16059	 2.33	 0.189	 0	 0	 16059	 2.33	 0.000	 10	 4	 914	 712177	 1.162	 1.234	 0.000
cbdata TunnelStateData (27)	  352	 	 	 	 	 	 	 	 9	 4	 14420	 2.33	 0.152	 0	 0	 14420	 2.33	 0.000	 9	 4	 821	 584493	 0.954	 0.909	 0.000
cbdata clientStreamNode (15)	  128	 	 	 	 	 	 	 	 20	 3	 10488	 2.33	 0.123	 0	 0	 10488	 2.33	 0.000	 20	 3	 597	 1413096	 2.307	 0.799	 0.000
MD5 digest          	   16	 	 	 	 	 	 	 	 124	 2	 2	 1.67	 0.095	 124	 2	 2	 1.67	 100.000	 0	 0	 1	 127528	 0.208	 0.009	 0.045
cbdata ACLFilledChecklist (17)	  496	 	 	 	 	 	 	 	 4	 2	 10	 2.46	 0.095	 0	 0	 10	 2.46	 0.000	 4	 2	 10	 1447338	 2.362	 3.173	 0.000
acl_ip_data         	   96	 	 	 	 	 	 	 	 10	 1	 1	 71.60	 0.046	 10	 1	 1	 71.60	 100.000	 0	 0	 1	 14	 0.000	 0.000	 0.000
ev_entry            	   48	 	 	 	 	 	 	 	 15	 1	 1	 0.96	 0.035	 13	 1	 1	 0.96	 86.667	 2	 1	 1	 607472	 0.992	 0.129	 2.422
cbdata Logfile (5)  	  352	 	 	 	 	 	 	 	 2	 1	 1	 70.85	 0.034	 1	 1	 1	 70.85	 50.000	 1	 1	 1	 67	 0.000	 0.000	 0.000
ACLStrategised      	  120	 	 	 	 	 	 	 	 5	 1	 1	 71.60	 0.029	 5	 1	 1	 71.60	 100.000	 0	 0	 1	 5	 0.000	 0.000	 0.000
RefreshPattern      	  144	 	 	 	 	 	 	 	 4	 1	 1	 71.60	 0.028	 4	 1	 1	 71.60	 100.000	 0	 0	 1	 4	 0.000	 0.000	 0.000
Auth::Basic::UserRequest	   48	 	 	 	 	 	 	 	 9	 1	 1967	 2.33	 0.021	 0	 0	 1967	 2.33	 0.000	 9	 1	 112	 586725	 0.958	 0.124	 0.000
cbdata ConnOpener (29)	  136	 	 	 	 	 	 	 	 3	 1	 13	 1.70	 0.020	 0	 0	 13	 1.70	 0.000	 3	 1	 13	 656019	 1.071	 0.394	 0.000
cbdata helper_server (22)	  336	 	 	 	 	 	 	 	 1	 1	 1	 31.34	 0.016	 1	 1	 1	 31.34	 100.000	 0	 0	 1	 2	 0.000	 0.000	 0.000
ACLSslErrorData     	   64	 	 	 	 	 	 	 	 5	 1	 1	 71.60	 0.015	 5	 1	 1	 71.60	 100.000	 0	 0	 1	 5	 0.000	 0.000	 0.000
ACLSourceIP         	  104	 	 	 	 	 	 	 	 3	 1	 1	 71.60	 0.015	 3	 1	 1	 71.60	 100.000	 0	 0	 1	 3	 0.000	 0.000	 0.000
cbdata ClientRequestContext (16)	  104	 	 	 	 	 	 	 	 3	 1	 2	 2.46	 0.015	 0	 0	 2	 2.46	 0.000	 3	 1	 2	 786169	 1.283	 0.361	 0.000
cbdata helper (4)   	  296	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.014	 1	 1	 1	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
cbdata TcpAcceptor (11)	   96	 	 	 	 	 	 	 	 3	 1	 1	 71.60	 0.014	 3	 1	 1	 71.60	 100.000	 0	 0	 1	 3	 0.000	 0.000	 0.000
cbdata ps_state (28)	  256	 	 	 	 	 	 	 	 1	 1	 1	 1.65	 0.012	 0	 0	 1	 1.65	 0.000	 1	 1	 1	 661162	 1.079	 0.748	 0.000
ACLStrategised      	  120	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.012	 2	 1	 1	 71.60	 100.000	 0	 0	 1	 2	 0.000	 0.000	 0.000
NotNode             	  120	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.012	 2	 1	 1	 71.60	 100.000	 0	 0	 1	 2	 0.000	 0.000	 0.000
cbdata ErrorState (30)	  240	 	 	 	 	 	 	 	 1	 1	 1	 2.03	 0.012	 0	 0	 1	 2.03	 0.000	 1	 1	 1	 126773	 0.207	 0.134	 0.000
cbdata generic_cbdata (23)	   32	 	 	 	 	 	 	 	 7	 1	 2	 2.46	 0.011	 0	 0	 2	 2.46	 0.000	 7	 1	 2	 71880	 0.117	 0.010	 0.000
cbdata RemovalPolicy (2)	  104	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.010	 2	 1	 1	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
Helper::Xaction     	  184	 	 	 	 	 	 	 	 1	 1	 1	 10.01	 0.009	 0	 0	 1	 10.01	 0.000	 1	 1	 1	 373	 0.001	 0.000	 0.000
cbdata LocalSearch (10)	   80	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.008	 1	 1	 1	 71.60	 50.000	 1	 1	 1	 69	 0.000	 0.000	 0.000
cbdata store_client (18)	  160	 	 	 	 	 	 	 	 1	 1	 1	 1.67	 0.008	 1	 1	 1	 1.67	 100.000	 0	 0	 1	 127405	 0.208	 0.090	 0.045
ACLStrategised      	  120	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.006	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
ACLStrategised      	  120	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.006	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
ACLDestinationIP    	  112	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.005	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
cbdata Forwarder (19)	  112	 	 	 	 	 	 	 	 1	 1	 1	 71.39	 0.005	 0	 0	 1	 71.39	 0.000	 1	 1	 1	 0	 0.000	 0.000	 0.000
cbdata CredentialsCache (25)	   96	 	 	 	 	 	 	 	 1	 1	 1	 10.01	 0.005	 1	 1	 1	 10.01	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
wordlist            	   16	 	 	 	 	 	 	 	 4	 1	 1	 0.96	 0.003	 4	 1	 1	 0.96	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
cbdata StateData (26)	   48	 	 	 	 	 	 	 	 1	 1	 1	 10.01	 0.002	 0	 0	 1	 10.01	 0.000	 1	 1	 1	 373	 0.001	 0.000	 0.000
CacheDigest         	   40	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.002	 1	 1	 1	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
ACLRegexData        	   32	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.002	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
ACLMethodData       	   32	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.002	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
FwdServer           	   32	 	 	 	 	 	 	 	 1	 1	 1	 1.65	 0.002	 0	 0	 1	 1.65	 0.000	 1	 1	 1	 661162	 1.079	 0.094	 0.000
Auth::QueueNode     	   32	 	 	 	 	 	 	 	 1	 1	 1	 2.48	 0.002	 0	 0	 1	 2.48	 0.000	 1	 1	 1	 0	 0.000	 0.000	 0.000
Long Strings        	  512	 	 	 	 	 	 	 	 0	 0	 11	 1.92	 0.000	 0	 0	 11	 1.92	 -1.000	 0	 0	 11	 8904	 0.015	 0.020	 0.000
1KB Strings         	 1024	 	 	 	 	 	 	 	 0	 0	 3	 2.41	 0.000	 0	 0	 3	 2.41	 -1.000	 0	 0	 3	 1409	 0.002	 0.006	 0.000
16K Buffer          	 16384	 	 	 	 	 	 	 	 0	 0	 16	 2.45	 0.000	 0	 0	 16	 2.45	 -1.000	 0	 0	 16	 476	 0.001	 0.034	 0.000
64K Buffer          	 65536	 	 	 	 	 	 	 	 0	 0	 64	 2.33	 0.000	 0	 0	 64	 2.33	 -1.000	 0	 0	 64	 26	 0.000	 0.008	 0.000
dwrite_q            	   48	 	 	 	 	 	 	 	 0	 0	 1	 71.60	 0.000	 0	 0	 1	 71.60	 -1.000	 0	 0	 1	 0	 0.000	 0.000	 0.000
cbdata RebuildState (6)	  920	 	 	 	 	 	 	 	 0	 0	 1	 71.60	 0.000	 0	 0	 1	 71.60	 -1.000	 0	 0	 1	 0	 0.000	 0.000	 0.000
cbdata RemovalPolicyWalker (21)	   56	 	 	 	 	 	 	 	 0	 0	 1	 55.34	 0.000	 0	 0	 1	 55.34	 -1.000	 0	 0	 1	 2	 0.000	 0.000	 0.000
cbdata FwdState (31)	  176	 	 	 	 	 	 	 	 0	 0	 1	 1.80	 0.000	 0	 0	 1	 1.80	 -1.000	 0	 0	 1	 2022	 0.003	 0.002	 0.000
cbdata HttpStateData (32)	  352	 	 	 	 	 	 	 	 0	 0	 2	 2.45	 0.000	 0	 0	 2	 2.45	 -1.000	 0	 0	 2	 1918	 0.003	 0.003	 0.000
cbdata CbDataList (33)	   96	 	 	 	 	 	 	 	 0	 0	 1	 2.43	 0.000	 0	 0	 1	 2.43	 -1.000	 0	 0	 1	 103	 0.000	 0.000	 0.000
Total               	    1	 	 	 	 	 	 	 	 16216	 2031	 764562	 2.33	 100.000	 15833	 1728	 762852	 2.33	 85.056	 383	 304	 42995	 58131821	 94.888	 93.646	 2748135.816
Cumulative allocated volume: 22.626 GB
Current overhead: 28155 bytes (1.592%)
Idle pool limit: 5.00 MB
Total Pools created: 90
Pools ever used:     88 (shown above)
Currently in use:    55
String Pool	 Impact		
 	 (%strings)	 (%volume)
Short Strings       	 96	 83
Medium Strings      	 7	 18
Long Strings        	 0	 0
1KB Strings         	 0	 0
4KB Strings         	 0	 0
16KB Strings        	 0	 0
Other Strings       	 -2	 -2147483648

Large buffers: 0 (0 KB)
} by kid2

by kid3 {
Current memory usage:
Pool	 Obj Size	Chunks							Allocated					In Use					Idle			Allocations Saved			Rate	
 	 (bytes)	KB/ch	 obj/ch	(#)	 used	 free	 part	 %Frag	 (#)	 (KB)	 high (KB)	 high (hrs)	 %Tot	(#)	 (KB)	 high (KB)	 high (hrs)	 %alloc	(#)	 (KB)	 high (KB)	(#)	 %cnt	 %vol	(#)/sec	
mem_node            	 4136	 	 	 	 	 	 	 	 130	 526	 788	 1.58	 22.569	 127	 513	 788	 1.58	 97.692	 3	 13	 283	 135738	 0.216	 2.421	 0.180
net_db_name         	   32	 	 	 	 	 	 	 	 5458	 171	 171	 1.30	 7.331	 5458	 171	 171	 1.30	 100.000	 0	 0	 3	 184	 0.000	 0.000	 0.000
netdbEntry          	  168	 	 	 	 	 	 	 	 941	 155	 165	 2.07	 6.636	 941	 155	 165	 2.07	 100.000	 0	 0	 17	 94	 0.000	 0.000	 0.000
HttpRequest         	 1880	 	 	 	 	 	 	 	 75	 138	 78467	 2.36	 5.918	 51	 94	 78467	 2.36	 68.000	 24	 45	 9867	 717586	 1.144	 5.817	 0.045
Short Strings       	   40	 	 	 	 	 	 	 	 3330	 131	 23400	 2.36	 5.591	 3089	 121	 23400	 2.36	 92.763	 241	 10	 2935	 26024779	 41.492	 4.489	 2.468
ipcache_entry       	  128	 	 	 	 	 	 	 	 928	 116	 129	 1.79	 4.986	 920	 115	 129	 1.79	 99.138	 8	 1	 15	 60466	 0.096	 0.033	 0.000
cbdata clientReplyContext (20)	 4352	 	 	 	 	 	 	 	 24	 102	 181424	 2.36	 4.384	 0	 0	 181424	 2.36	 0.000	 24	 102	 22840	 717514	 1.144	 13.465	 0.045
Stream              	 4216	 	 	 	 	 	 	 	 24	 99	 175755	 2.36	 4.247	 0	 0	 175755	 2.36	 0.000	 24	 99	 22126	 717514	 1.144	 13.045	 0.045
4KB Strings         	 4096	 	 	 	 	 	 	 	 24	 96	 170756	 2.36	 4.126	 0	 0	 170756	 2.36	 0.000	 24	 96	 21496	 721832	 1.151	 12.750	 0.045
cbdata idns_query (18)	 8696	 	 	 	 	 	 	 	 9	 77	 247	 1.55	 3.285	 0	 0	 247	 1.55	 0.000	 9	 77	 247	 93490	 0.149	 3.506	 0.000
32K Buffer          	 32768	 	 	 	 	 	 	 	 2	 64	 96	 2.45	 2.751	 1	 32	 96	 2.45	 50.000	 1	 32	 64	 126	 0.000	 0.018	 0.000
HttpHeaderEntry     	   56	 	 	 	 	 	 	 	 950	 52	 9386	 2.36	 2.233	 861	 48	 9386	 2.36	 90.632	 89	 5	 1176	 6356819	 10.135	 1.535	 0.224
cbdata Tree (1)     	  176	 	 	 	 	 	 	 	 274	 48	 48	 71.60	 2.024	 274	 48	 48	 71.60	 100.000	 0	 0	 48	 274	 0.000	 0.000	 0.000
ClientInfo          	  448	 	 	 	 	 	 	 	 97	 43	 43	 2.19	 1.824	 97	 43	 43	 2.19	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
MemObject           	  344	 	 	 	 	 	 	 	 124	 42	 45	 1.55	 1.790	 124	 42	 45	 1.55	 100.000	 0	 0	 4	 131325	 0.209	 0.195	 0.090
MemBlob             	   48	 	 	 	 	 	 	 	 788	 37	 6044	 2.36	 1.588	 717	 34	 6044	 2.36	 90.990	 71	 4	 756	 4009796	 6.393	 0.830	 0.404
HttpReply           	  288	 	 	 	 	 	 	 	 125	 36	 40	 1.55	 1.511	 124	 35	 40	 1.55	 99.200	 1	 1	 6	 395595	 0.631	 0.491	 0.090
AndNode             	  120	 	 	 	 	 	 	 	 282	 34	 34	 0.96	 1.420	 282	 34	 34	 0.96	 100.000	 0	 0	 33	 281	 0.000	 0.000	 0.000
Medium Strings      	  128	 	 	 	 	 	 	 	 262	 33	 10932	 2.36	 1.408	 212	 27	 10932	 2.36	 80.916	 50	 7	 1359	 3058277	 4.876	 1.688	 0.000
ACLProxyAuth        	  112	 	 	 	 	 	 	 	 265	 29	 29	 71.60	 1.246	 265	 29	 29	 71.60	 100.000	 0	 0	 29	 265	 0.000	 0.000	 0.000
acl_proxy_auth_match_cache	   40	 	 	 	 	 	 	 	 725	 29	 1809	 1.22	 1.217	 725	 29	 1809	 1.22	 100.000	 0	 0	 1260	 3168	 0.005	 0.001	 0.000
Auth::Basic::User   	  224	 	 	 	 	 	 	 	 121	 27	 77	 1.22	 1.138	 116	 26	 77	 1.22	 95.868	 5	 2	 53	 675424	 1.077	 0.652	 0.000
MimeEntry           	  144	 	 	 	 	 	 	 	 177	 25	 25	 71.60	 1.070	 177	 25	 25	 71.60	 100.000	 0	 0	 25	 177	 0.000	 0.000	 0.000
Comm::Connection    	  208	 	 	 	 	 	 	 	 99	 21	 41496	 2.36	 0.864	 7	 2	 41496	 2.36	 7.071	 92	 19	 4303	 3327739	 5.305	 2.985	 0.180
cbdata Server (16)  	  800	 	 	 	 	 	 	 	 24	 19	 33459	 2.36	 0.806	 0	 0	 33459	 2.36	 0.000	 24	 19	 4199	 718432	 1.145	 2.478	 0.045
cbdata Address (3)  	   72	 	 	 	 	 	 	 	 264	 19	 19	 71.60	 0.798	 264	 19	 19	 71.60	 100.000	 0	 0	 19	 264	 0.000	 0.000	 0.000
ACLUserData         	   64	 	 	 	 	 	 	 	 265	 17	 17	 71.60	 0.712	 265	 17	 17	 71.60	 100.000	 0	 0	 17	 265	 0.000	 0.000	 0.000
fqdncache_entry     	  160	 	 	 	 	 	 	 	 103	 17	 17	 1.99	 0.692	 103	 17	 17	 1.99	 100.000	 0	 0	 2	 317	 0.001	 0.000	 0.000
16KB Strings        	 16384	 	 	 	 	 	 	 	 1	 16	 80	 2.12	 0.688	 0	 0	 80	 2.12	 0.000	 1	 16	 80	 3286	 0.005	 0.232	 0.045
8K Buffer           	 8192	 	 	 	 	 	 	 	 2	 16	 80	 1.55	 0.688	 1	 8	 80	 1.55	 50.000	 1	 8	 72	 132292	 0.211	 4.673	 0.000
StoreEntry          	  120	 	 	 	 	 	 	 	 124	 15	 16	 1.55	 0.625	 124	 15	 16	 1.55	 100.000	 0	 0	 2	 131325	 0.209	 0.068	 0.090
2K Buffer           	 2048	 	 	 	 	 	 	 	 5	 10	 14	 2.50	 0.430	 3	 6	 14	 2.50	 60.000	 2	 4	 8	 1191218	 1.899	 10.520	 0.000
cbdata ClientHttpRequest (19)	  392	 	 	 	 	 	 	 	 24	 10	 16342	 2.36	 0.395	 0	 0	 16342	 2.36	 0.000	 24	 10	 2058	 717514	 1.144	 1.213	 0.045
cbdata MemBuf (7)   	   72	 	 	 	 	 	 	 	 127	 9	 11	 1.55	 0.384	 125	 9	 11	 1.55	 98.425	 2	 1	 2	 659460	 1.051	 0.205	 0.090
cbdata TunnelStateData (26)	  352	 	 	 	 	 	 	 	 24	 9	 14674	 2.36	 0.355	 0	 0	 14674	 2.36	 0.000	 24	 9	 1848	 585900	 0.934	 0.889	 0.000
4K Buffer           	 4096	 	 	 	 	 	 	 	 2	 8	 36	 1.55	 0.344	 0	 0	 36	 1.55	 0.000	 2	 8	 36	 134179	 0.214	 2.370	 0.000
AuthUserIP          	   64	 	 	 	 	 	 	 	 120	 8	 27	 1.80	 0.322	 116	 8	 27	 1.80	 96.667	 4	 1	 16	 327376	 0.522	 0.090	 0.000
cbdata clientStreamNode (21)	  128	 	 	 	 	 	 	 	 48	 6	 10672	 2.36	 0.258	 0	 0	 10672	 2.36	 0.000	 48	 6	 1344	 1427962	 2.277	 0.788	 0.090
HttpHdrCc           	   96	 	 	 	 	 	 	 	 51	 5	 6	 2.09	 0.206	 51	 5	 6	 2.09	 100.000	 0	 0	 1	 5375	 0.009	 0.002	 0.000
cbdata UdsSender (8)	 4528	 	 	 	 	 	 	 	 1	 5	 9	 71.60	 0.190	 0	 0	 9	 71.60	 0.000	 1	 5	 9	 24	 0.000	 0.000	 0.090
cbdata Strand (9)   	 4520	 	 	 	 	 	 	 	 1	 5	 5	 71.60	 0.190	 1	 5	 5	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
cbdata Filler (12)  	 4216	 	 	 	 	 	 	 	 1	 5	 5	 71.39	 0.177	 1	 5	 5	 71.39	 100.000	 0	 0	 5	 9	 0.000	 0.000	 0.045
MD5 digest          	   16	 	 	 	 	 	 	 	 124	 2	 3	 1.55	 0.083	 124	 2	 3	 1.55	 100.000	 0	 0	 1	 131468	 0.210	 0.009	 0.090
cbdata ACLFilledChecklist (23)	  496	 	 	 	 	 	 	 	 4	 2	 8	 1.55	 0.083	 0	 0	 8	 1.55	 0.000	 4	 2	 8	 1480340	 2.360	 3.166	 0.045
Auth::Basic::UserRequest	   48	 	 	 	 	 	 	 	 24	 2	 2001	 2.36	 0.048	 0	 0	 2001	 2.36	 0.000	 24	 2	 252	 588238	 0.938	 0.122	 0.000
acl_ip_data         	   96	 	 	 	 	 	 	 	 10	 1	 1	 71.60	 0.040	 10	 1	 1	 71.60	 100.000	 0	 0	 1	 14	 0.000	 0.000	 0.000
cbdata Logfile (5)  	  352	 	 	 	 	 	 	 	 2	 1	 1	 70.85	 0.030	 1	 1	 1	 70.85	 50.000	 1	 1	 1	 67	 0.000	 0.000	 0.000
ev_entry            	   48	 	 	 	 	 	 	 	 14	 1	 1	 2.45	 0.028	 13	 1	 1	 2.45	 92.857	 1	 1	 1	 607450	 0.968	 0.126	 2.468
cbdata helper_server (15)	  336	 	 	 	 	 	 	 	 2	 1	 1	 31.34	 0.028	 1	 1	 1	 31.34	 50.000	 1	 1	 1	 3	 0.000	 0.000	 0.000
ACLStrategised      	  120	 	 	 	 	 	 	 	 5	 1	 1	 71.60	 0.025	 5	 1	 1	 71.60	 100.000	 0	 0	 1	 5	 0.000	 0.000	 0.000
RefreshPattern      	  144	 	 	 	 	 	 	 	 4	 1	 1	 71.60	 0.024	 4	 1	 1	 71.60	 100.000	 0	 0	 1	 4	 0.000	 0.000	 0.000
cbdata ConnOpener (28)	  136	 	 	 	 	 	 	 	 3	 1	 15	 1.80	 0.017	 0	 0	 15	 1.80	 0.000	 3	 1	 15	 670639	 1.069	 0.393	 0.000
ACLSslErrorData     	   64	 	 	 	 	 	 	 	 5	 1	 1	 71.60	 0.013	 5	 1	 1	 71.60	 100.000	 0	 0	 1	 5	 0.000	 0.000	 0.000
ACLSourceIP         	  104	 	 	 	 	 	 	 	 3	 1	 1	 71.60	 0.013	 3	 1	 1	 71.60	 100.000	 0	 0	 1	 3	 0.000	 0.000	 0.000
cbdata ClientRequestContext (22)	  104	 	 	 	 	 	 	 	 3	 1	 2	 1.55	 0.013	 0	 0	 2	 1.55	 0.000	 3	 1	 2	 804569	 1.283	 0.361	 0.045
cbdata helper (4)   	  296	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.012	 1	 1	 1	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
cbdata TcpAcceptor (11)	   96	 	 	 	 	 	 	 	 3	 1	 1	 71.60	 0.012	 3	 1	 1	 71.60	 100.000	 0	 0	 1	 3	 0.000	 0.000	 0.000
cbdata ps_state (27)	  256	 	 	 	 	 	 	 	 1	 1	 1	 10.01	 0.011	 0	 0	 1	 10.01	 0.000	 1	 1	 1	 675775	 1.077	 0.746	 0.000
ACLStrategised      	  120	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.010	 2	 1	 1	 71.60	 100.000	 0	 0	 1	 2	 0.000	 0.000	 0.000
NotNode             	  120	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.010	 2	 1	 1	 71.60	 100.000	 0	 0	 1	 2	 0.000	 0.000	 0.000
cbdata ErrorState (29)	  240	 	 	 	 	 	 	 	 1	 1	 1	 2.35	 0.010	 0	 0	 1	 2.35	 0.000	 1	 1	 1	 130552	 0.208	 0.135	 0.000
cbdata RemovalPolicy (2)	  104	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.009	 2	 1	 1	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
cbdata generic_cbdata (17)	   32	 	 	 	 	 	 	 	 6	 1	 1	 1.55	 0.008	 0	 0	 1	 1.55	 0.000	 6	 1	 1	 74180	 0.118	 0.010	 0.000
Helper::Xaction     	  184	 	 	 	 	 	 	 	 1	 1	 1	 2.50	 0.008	 0	 0	 1	 2.50	 0.000	 1	 1	 1	 403	 0.001	 0.000	 0.000
cbdata LocalSearch (10)	   80	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.007	 1	 1	 1	 71.60	 50.000	 1	 1	 1	 69	 0.000	 0.000	 0.000
cbdata store_client (13)	  160	 	 	 	 	 	 	 	 1	 1	 2	 1.55	 0.007	 1	 1	 2	 1.55	 100.000	 0	 0	 2	 131334	 0.209	 0.091	 0.090
ACLStrategised      	  120	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.005	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
ACLStrategised      	  120	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.005	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
ACLDestinationIP    	  112	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.005	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
cbdata Forwarder (32)	  112	 	 	 	 	 	 	 	 1	 1	 1	 4.75	 0.005	 0	 0	 1	 4.75	 0.000	 1	 1	 1	 2	 0.000	 0.000	 0.045
cbdata CredentialsCache (24)	   96	 	 	 	 	 	 	 	 1	 1	 1	 10.01	 0.004	 1	 1	 1	 10.01	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
wordlist            	   16	 	 	 	 	 	 	 	 4	 1	 1	 0.96	 0.003	 4	 1	 1	 0.96	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
cbdata StateData (25)	   48	 	 	 	 	 	 	 	 1	 1	 1	 2.50	 0.002	 0	 0	 1	 2.50	 0.000	 1	 1	 1	 403	 0.001	 0.000	 0.000
CacheDigest         	   40	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.002	 1	 1	 1	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
ACLRegexData        	   32	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.001	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
ACLMethodData       	   32	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.001	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
FwdServer           	   32	 	 	 	 	 	 	 	 1	 1	 1	 10.01	 0.001	 0	 0	 1	 10.01	 0.000	 1	 1	 1	 675775	 1.077	 0.093	 0.000
Long Strings        	  512	 	 	 	 	 	 	 	 0	 0	 11	 2.09	 0.000	 0	 0	 11	 2.09	 -1.000	 0	 0	 11	 9785	 0.016	 0.022	 0.000
1KB Strings         	 1024	 	 	 	 	 	 	 	 0	 0	 3	 2.42	 0.000	 0	 0	 3	 2.42	 -1.000	 0	 0	 3	 1435	 0.002	 0.006	 0.000
16K Buffer          	 16384	 	 	 	 	 	 	 	 0	 0	 16	 2.45	 0.000	 0	 0	 16	 2.45	 -1.000	 0	 0	 16	 453	 0.001	 0.032	 0.000
64K Buffer          	 65536	 	 	 	 	 	 	 	 0	 0	 64	 2.37	 0.000	 0	 0	 64	 2.37	 -1.000	 0	 0	 64	 20	 0.000	 0.006	 0.000
dwrite_q            	   48	 	 	 	 	 	 	 	 0	 0	 1	 71.60	 0.000	 0	 0	 1	 71.60	 -1.000	 0	 0	 1	 0	 0.000	 0.000	 0.000
cbdata RebuildState (6)	  920	 	 	 	 	 	 	 	 0	 0	 1	 71.60	 0.000	 0	 0	 1	 71.60	 -1.000	 0	 0	 1	 0	 0.000	 0.000	 0.000
cbdata RemovalPolicyWalker (14)	   56	 	 	 	 	 	 	 	 0	 0	 1	 55.34	 0.000	 0	 0	 1	 55.34	 -1.000	 0	 0	 1	 2	 0.000	 0.000	 0.000
cbdata FwdState (30)	  176	 	 	 	 	 	 	 	 0	 0	 1	 2.11	 0.000	 0	 0	 1	 2.11	 -1.000	 0	 0	 1	 2146	 0.003	 0.002	 0.000
cbdata HttpStateData (31)	  352	 	 	 	 	 	 	 	 0	 0	 2	 2.11	 0.000	 0	 0	 2	 2.11	 -1.000	 0	 0	 2	 2032	 0.003	 0.003	 0.000
Auth::QueueNode     	   32	 	 	 	 	 	 	 	 0	 0	 1	 9.82	 0.000	 0	 0	 1	 9.82	 -1.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
cbdata CbDataList (33)	   96	 	 	 	 	 	 	 	 0	 0	 1	 2.44	 0.000	 0	 0	 1	 2.44	 -1.000	 0	 0	 1	 152	 0.000	 0.000	 0.000
Total               	    1	 	 	 	 	 	 	 	 16660	 2327	 777950	 2.36	 100.000	 15811	 1732	 771970	 2.36	 74.428	 849	 595	 96877	 59170997	 94.337	 92.776	 2815018.784
Cumulative allocated volume: 23.190 GB
Current overhead: 28155 bytes (1.588%)
Idle pool limit: 5.00 MB
Total Pools created: 90
Pools ever used:     88 (shown above)
Currently in use:    55
String Pool	 Impact		
 	 (%strings)	 (%volume)
Short Strings       	 96	 84
Medium Strings      	 7	 18
Long Strings        	 0	 0
1KB Strings         	 0	 0
4KB Strings         	 0	 0
16KB Strings        	 0	 0
Other Strings       	 -2	 -2147483648

Large buffers: 0 (0 KB)
} by kid3

by kid4 {
Current memory usage:
Pool	 Obj Size	Chunks							Allocated					In Use					Idle			Allocations Saved			Rate	
 	 (bytes)	KB/ch	 obj/ch	(#)	 used	 free	 part	 %Frag	 (#)	 (KB)	 high (KB)	 high (hrs)	 %Tot	(#)	 (KB)	 high (KB)	 high (hrs)	 %alloc	(#)	 (KB)	 high (KB)	(#)	 %cnt	 %vol	(#)/sec	
mem_node            	 4136	 	 	 	 	 	 	 	 131	 530	 788	 1.58	 21.771	 127	 513	 788	 1.58	 96.947	 4	 17	 283	 132824	 0.217	 2.432	 0.180
net_db_name         	   32	 	 	 	 	 	 	 	 5583	 175	 175	 1.31	 7.179	 5583	 175	 175	 1.31	 100.000	 0	 0	 3	 129	 0.000	 0.000	 0.000
netdbEntry          	  168	 	 	 	 	 	 	 	 926	 152	 165	 2.08	 6.251	 926	 152	 165	 2.08	 100.000	 0	 0	 17	 84	 0.000	 0.000	 0.000
HttpRequest         	 1880	 	 	 	 	 	 	 	 82	 151	 77997	 2.36	 6.194	 51	 94	 77997	 2.36	 62.195	 31	 57	 4199	 707830	 1.159	 5.892	 0.000
cbdata clientReplyContext (18)	 4352	 	 	 	 	 	 	 	 31	 132	 180336	 2.36	 5.421	 0	 0	 180336	 2.36	 0.000	 31	 132	 9720	 707758	 1.159	 13.638	 0.000
Stream              	 4216	 	 	 	 	 	 	 	 31	 128	 174701	 2.36	 5.252	 0	 0	 174701	 2.36	 0.000	 31	 128	 9417	 707758	 1.159	 13.212	 0.000
Short Strings       	   40	 	 	 	 	 	 	 	 3208	 126	 23263	 2.36	 5.156	 3085	 121	 23263	 2.36	 96.166	 123	 5	 1247	 25427557	 41.631	 4.503	 0.583
4KB Strings         	 4096	 	 	 	 	 	 	 	 31	 124	 169728	 2.36	 5.102	 0	 0	 169728	 2.36	 0.000	 31	 124	 9152	 711768	 1.165	 12.908	 0.000
ipcache_entry       	  128	 	 	 	 	 	 	 	 930	 117	 125	 2.08	 4.783	 920	 115	 125	 2.08	 98.925	 10	 2	 10	 59602	 0.098	 0.034	 0.000
cbdata idns_query (16)	 8696	 	 	 	 	 	 	 	 9	 77	 230	 1.80	 3.145	 0	 0	 230	 1.80	 0.000	 9	 77	 230	 92264	 0.151	 3.552	 0.000
HttpHeaderEntry     	   56	 	 	 	 	 	 	 	 985	 54	 9329	 2.36	 2.216	 861	 48	 9329	 2.36	 87.411	 124	 7	 501	 6216202	 10.178	 1.541	 0.000
cbdata Tree (1)     	  176	 	 	 	 	 	 	 	 274	 48	 48	 71.60	 1.938	 274	 48	 48	 71.60	 100.000	 0	 0	 48	 274	 0.000	 0.000	 0.000
ClientInfo          	  448	 	 	 	 	 	 	 	 98	 43	 43	 2.03	 1.764	 98	 43	 43	 2.03	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
MemObject           	  344	 	 	 	 	 	 	 	 124	 42	 43	 1.80	 1.714	 124	 42	 43	 1.80	 100.000	 0	 0	 3	 127756	 0.209	 0.195	 0.045
acl_proxy_auth_match_cache	   40	 	 	 	 	 	 	 	 990	 39	 1397	 2.47	 1.591	 990	 39	 1397	 2.47	 100.000	 0	 0	 875	 6050	 0.010	 0.001	 0.000
MemBlob             	   48	 	 	 	 	 	 	 	 808	 38	 6008	 2.36	 1.558	 713	 34	 6008	 2.36	 88.243	 95	 5	 322	 3924753	 6.426	 0.834	 0.090
HttpReply           	  288	 	 	 	 	 	 	 	 125	 36	 38	 1.80	 1.447	 124	 35	 38	 1.80	 99.200	 1	 1	 4	 384929	 0.630	 0.491	 0.045
Medium Strings      	  128	 	 	 	 	 	 	 	 279	 35	 10851	 2.36	 1.435	 212	 27	 10851	 2.36	 75.986	 67	 9	 587	 2993704	 4.901	 1.697	 0.000
AndNode             	  120	 	 	 	 	 	 	 	 282	 34	 34	 0.96	 1.360	 282	 34	 34	 0.96	 100.000	 0	 0	 33	 281	 0.000	 0.000	 0.000
32K Buffer          	 32768	 	 	 	 	 	 	 	 1	 32	 64	 55.34	 1.317	 1	 32	 64	 55.34	 100.000	 0	 0	 32	 167	 0.000	 0.024	 0.000
ACLProxyAuth        	  112	 	 	 	 	 	 	 	 265	 29	 29	 71.60	 1.193	 265	 29	 29	 71.60	 100.000	 0	 0	 29	 265	 0.000	 0.000	 0.000
Comm::Connection    	  208	 	 	 	 	 	 	 	 134	 28	 40840	 2.36	 1.120	 7	 2	 40840	 2.36	 5.224	 127	 26	 1963	 3309608	 5.419	 3.048	 0.135
Auth::Basic::User   	  224	 	 	 	 	 	 	 	 114	 25	 60	 1.22	 1.026	 112	 25	 60	 1.22	 98.246	 2	 1	 38	 656469	 1.075	 0.651	 0.000
MimeEntry           	  144	 	 	 	 	 	 	 	 177	 25	 25	 71.60	 1.024	 177	 25	 25	 71.60	 100.000	 0	 0	 25	 177	 0.000	 0.000	 0.000
cbdata Server (14)  	  800	 	 	 	 	 	 	 	 31	 25	 33252	 2.36	 0.996	 0	 0	 33252	 2.36	 0.000	 31	 25	 1793	 708565	 1.160	 2.510	 0.000
cbdata Address (3)  	   72	 	 	 	 	 	 	 	 264	 19	 19	 71.60	 0.764	 264	 19	 19	 71.60	 100.000	 0	 0	 19	 264	 0.000	 0.000	 0.000
ACLUserData         	   64	 	 	 	 	 	 	 	 265	 17	 17	 71.60	 0.681	 265	 17	 17	 71.60	 100.000	 0	 0	 17	 265	 0.000	 0.000	 0.000
fqdncache_entry     	  160	 	 	 	 	 	 	 	 104	 17	 17	 1.73	 0.669	 104	 17	 17	 1.73	 100.000	 0	 0	 2	 321	 0.001	 0.000	 0.000
16KB Strings        	 16384	 	 	 	 	 	 	 	 1	 16	 80	 2.44	 0.658	 0	 0	 80	 2.44	 0.000	 1	 16	 80	 3344	 0.005	 0.243	 0.000
8K Buffer           	 8192	 	 	 	 	 	 	 	 2	 16	 56	 2.30	 0.658	 1	 8	 56	 2.30	 50.000	 1	 8	 48	 129239	 0.212	 4.688	 0.000
StoreEntry          	  120	 	 	 	 	 	 	 	 124	 15	 15	 1.80	 0.598	 124	 15	 15	 1.80	 100.000	 0	 0	 1	 127756	 0.209	 0.068	 0.045
cbdata ClientHttpRequest (17)	  392	 	 	 	 	 	 	 	 31	 12	 16244	 2.36	 0.488	 0	 0	 16244	 2.36	 0.000	 31	 12	 876	 707758	 1.159	 1.228	 0.000
cbdata TunnelStateData (31)	  352	 	 	 	 	 	 	 	 31	 11	 14586	 2.36	 0.438	 0	 0	 14586	 2.36	 0.000	 31	 11	 787	 579322	 0.948	 0.903	 0.000
2K Buffer           	 2048	 	 	 	 	 	 	 	 5	 10	 14	 2.45	 0.411	 3	 6	 14	 2.45	 60.000	 2	 4	 8	 1159902	 1.899	 10.518	 0.000
cbdata MemBuf (7)   	   72	 	 	 	 	 	 	 	 127	 9	 10	 1.80	 0.367	 125	 9	 10	 1.80	 98.425	 2	 1	 1	 641640	 1.051	 0.205	 0.045
4K Buffer           	 4096	 	 	 	 	 	 	 	 2	 8	 24	 2.30	 0.329	 0	 0	 24	 2.30	 0.000	 2	 8	 24	 130725	 0.214	 2.371	 0.000
cbdata clientStreamNode (19)	  128	 	 	 	 	 	 	 	 62	 8	 10608	 2.36	 0.319	 0	 0	 10608	 2.36	 0.000	 62	 8	 572	 1404372	 2.299	 0.796	 0.000
AuthUserIP          	   64	 	 	 	 	 	 	 	 113	 8	 27	 1.80	 0.291	 112	 7	 27	 1.80	 99.115	 1	 1	 11	 330252	 0.541	 0.094	 0.000
HttpHdrCc           	   96	 	 	 	 	 	 	 	 53	 5	 6	 1.80	 0.204	 51	 5	 6	 1.80	 96.226	 2	 1	 1	 5494	 0.009	 0.002	 0.000
cbdata UdsSender (8)	 4528	 	 	 	 	 	 	 	 1	 5	 9	 71.60	 0.182	 0	 0	 9	 71.60	 0.000	 1	 5	 9	 22	 0.000	 0.000	 0.045
cbdata Strand (9)   	 4520	 	 	 	 	 	 	 	 1	 5	 5	 71.60	 0.182	 1	 5	 5	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
cbdata Filler (12)  	 4216	 	 	 	 	 	 	 	 1	 5	 5	 71.39	 0.169	 1	 5	 5	 71.39	 100.000	 0	 0	 5	 9	 0.000	 0.000	 0.045
cbdata ACLFilledChecklist (21)	  496	 	 	 	 	 	 	 	 5	 3	 6	 1.61	 0.100	 0	 0	 6	 1.61	 0.000	 5	 3	 6	 1438774	 2.356	 3.160	 0.000
MD5 digest          	   16	 	 	 	 	 	 	 	 124	 2	 2	 1.80	 0.080	 124	 2	 2	 1.80	 100.000	 0	 0	 1	 127899	 0.209	 0.009	 0.045
Auth::Basic::UserRequest	   48	 	 	 	 	 	 	 	 31	 2	 1989	 2.36	 0.060	 0	 0	 1989	 2.36	 0.000	 31	 2	 108	 581676	 0.952	 0.124	 0.000
acl_ip_data         	   96	 	 	 	 	 	 	 	 10	 1	 1	 71.60	 0.039	 10	 1	 1	 71.60	 100.000	 0	 0	 1	 14	 0.000	 0.000	 0.000
cbdata Logfile (5)  	  352	 	 	 	 	 	 	 	 2	 1	 1	 70.85	 0.028	 1	 1	 1	 70.85	 50.000	 1	 1	 1	 67	 0.000	 0.000	 0.000
ev_entry            	   48	 	 	 	 	 	 	 	 14	 1	 1	 2.45	 0.027	 13	 1	 1	 2.45	 92.857	 1	 1	 1	 607511	 0.995	 0.129	 2.379
ACLStrategised      	  120	 	 	 	 	 	 	 	 5	 1	 1	 71.60	 0.024	 5	 1	 1	 71.60	 100.000	 0	 0	 1	 5	 0.000	 0.000	 0.000
RefreshPattern      	  144	 	 	 	 	 	 	 	 4	 1	 1	 71.60	 0.023	 4	 1	 1	 71.60	 100.000	 0	 0	 1	 4	 0.000	 0.000	 0.000
cbdata ConnOpener (27)	  136	 	 	 	 	 	 	 	 4	 1	 13	 1.71	 0.022	 0	 0	 13	 1.71	 0.000	 4	 1	 13	 651773	 1.067	 0.392	 0.000
Long Strings        	  512	 	 	 	 	 	 	 	 1	 1	 8	 1.80	 0.021	 0	 0	 8	 1.80	 0.000	 1	 1	 8	 9446	 0.015	 0.021	 0.000
cbdata ClientRequestContext (20)	  104	 	 	 	 	 	 	 	 4	 1	 2	 1.66	 0.017	 0	 0	 2	 1.66	 0.000	 4	 1	 2	 782014	 1.280	 0.360	 0.000
cbdata HttpStateData (28)	  352	 	 	 	 	 	 	 	 1	 1	 2	 1.80	 0.014	 0	 0	 2	 1.80	 0.000	 1	 1	 2	 2058	 0.003	 0.003	 0.000
cbdata helper_server (24)	  336	 	 	 	 	 	 	 	 1	 1	 1	 55.34	 0.014	 1	 1	 1	 55.34	 100.000	 0	 0	 1	 3	 0.000	 0.000	 0.000
ACLSslErrorData     	   64	 	 	 	 	 	 	 	 5	 1	 1	 71.60	 0.013	 5	 1	 1	 71.60	 100.000	 0	 0	 1	 5	 0.000	 0.000	 0.000
ACLSourceIP         	  104	 	 	 	 	 	 	 	 3	 1	 1	 71.60	 0.013	 3	 1	 1	 71.60	 100.000	 0	 0	 1	 3	 0.000	 0.000	 0.000
cbdata helper (4)   	  296	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.012	 1	 1	 1	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
cbdata TcpAcceptor (11)	   96	 	 	 	 	 	 	 	 3	 1	 1	 71.60	 0.012	 3	 1	 1	 71.60	 100.000	 0	 0	 1	 3	 0.000	 0.000	 0.000
cbdata generic_cbdata (15)	   32	 	 	 	 	 	 	 	 8	 1	 1	 1.66	 0.010	 0	 0	 1	 1.66	 0.000	 8	 1	 1	 73382	 0.120	 0.010	 0.000
cbdata ps_state (26)	  256	 	 	 	 	 	 	 	 1	 1	 1	 71.11	 0.010	 0	 0	 1	 71.11	 0.000	 1	 1	 1	 656751	 1.075	 0.744	 0.000
ACLStrategised      	  120	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.010	 2	 1	 1	 71.60	 100.000	 0	 0	 1	 2	 0.000	 0.000	 0.000
NotNode             	  120	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.010	 2	 1	 1	 71.60	 100.000	 0	 0	 1	 2	 0.000	 0.000	 0.000
cbdata ErrorState (30)	  240	 	 	 	 	 	 	 	 1	 1	 1	 2.03	 0.010	 0	 0	 1	 2.03	 0.000	 1	 1	 1	 126975	 0.208	 0.135	 0.000
cbdata RemovalPolicy (2)	  104	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.008	 2	 1	 1	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
Helper::Xaction     	  184	 	 	 	 	 	 	 	 1	 1	 1	 71.11	 0.007	 0	 0	 1	 71.11	 0.000	 1	 1	 1	 395	 0.001	 0.000	 0.000
cbdata FwdState (25)	  176	 	 	 	 	 	 	 	 1	 1	 1	 1.80	 0.007	 0	 0	 1	 1.80	 0.000	 1	 1	 1	 2153	 0.004	 0.002	 0.000
cbdata LocalSearch (10)	   80	 	 	 	 	 	 	 	 2	 1	 1	 71.60	 0.006	 1	 1	 1	 71.60	 50.000	 1	 1	 1	 69	 0.000	 0.000	 0.000
cbdata store_client (13)	  160	 	 	 	 	 	 	 	 1	 1	 2	 1.80	 0.006	 1	 1	 2	 1.80	 100.000	 0	 0	 2	 127771	 0.209	 0.091	 0.045
ACLStrategised      	  120	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.005	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
ACLStrategised      	  120	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.005	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
ACLDestinationIP    	  112	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.005	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
cbdata Forwarder (33)	  112	 	 	 	 	 	 	 	 1	 1	 1	 2.03	 0.005	 0	 0	 1	 2.03	 0.000	 1	 1	 1	 2	 0.000	 0.000	 0.000
cbdata CredentialsCache (22)	   96	 	 	 	 	 	 	 	 1	 1	 1	 71.11	 0.004	 1	 1	 1	 71.11	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
Auth::QueueNode     	   32	 	 	 	 	 	 	 	 3	 1	 1	 0.96	 0.004	 0	 0	 1	 0.96	 0.000	 3	 1	 1	 3	 0.000	 0.000	 0.000
wordlist            	   16	 	 	 	 	 	 	 	 4	 1	 1	 0.96	 0.003	 4	 1	 1	 0.96	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
cbdata StateData (23)	   48	 	 	 	 	 	 	 	 1	 1	 1	 71.11	 0.002	 0	 0	 1	 71.11	 0.000	 1	 1	 1	 395	 0.001	 0.000	 0.000
CacheDigest         	   40	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.002	 1	 1	 1	 71.60	 100.000	 0	 0	 0	 0	 0.000	 0.000	 0.000
ACLRegexData        	   32	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.001	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
ACLMethodData       	   32	 	 	 	 	 	 	 	 1	 1	 1	 71.60	 0.001	 1	 1	 1	 71.60	 100.000	 0	 0	 1	 1	 0.000	 0.000	 0.000
FwdServer           	   32	 	 	 	 	 	 	 	 1	 1	 1	 71.11	 0.001	 0	 0	 1	 71.11	 0.000	 1	 1	 1	 656751	 1.075	 0.093	 0.000
1KB Strings         	 1024	 	 	 	 	 	 	 	 0	 0	 3	 2.41	 0.000	 0	 0	 3	 2.41	 -1.000	 0	 0	 3	 1406	 0.002	 0.006	 0.000
16K Buffer          	 16384	 	 	 	 	 	 	 	 0	 0	 16	 2.45	 0.000	 0	 0	 16	 2.45	 -1.000	 0	 0	 16	 518	 0.001	 0.038	 0.000
64K Buffer          	 65536	 	 	 	 	 	 	 	 0	 0	 64	 2.25	 0.000	 0	 0	 64	 2.25	 -1.000	 0	 0	 64	 39	 0.000	 0.011	 0.000
dwrite_q            	   48	 	 	 	 	 	 	 	 0	 0	 1	 71.60	 0.000	 0	 0	 1	 71.60	 -1.000	 0	 0	 1	 0	 0.000	 0.000	 0.000
cbdata RebuildState (6)	  920	 	 	 	 	 	 	 	 0	 0	 1	 71.60	 0.000	 0	 0	 1	 71.60	 -1.000	 0	 0	 1	 0	 0.000	 0.000	 0.000
cbdata RemovalPolicyWalker (29)	   56	 	 	 	 	 	 	 	 0	 0	 1	 55.34	 0.000	 0	 0	 1	 55.34	 -1.000	 0	 0	 1	 2	 0.000	 0.000	 0.000
cbdata CbDataList (32)	   96	 	 	 	 	 	 	 	 0	 0	 1	 1.68	 0.000	 0	 0	 1	 1.68	 -1.000	 0	 0	 1	 175	 0.000	 0.000	 0.000
Total               	    1	 	 	 	 	 	 	 	 17092	 2431	 772828	 2.36	 100.000	 16172	 1743	 770330	 2.36	 71.697	 920	 688	 41234	 57945510	 94.872	 93.610	 2741180.346
Cumulative allocated volume: 22.585 GB
Current overhead: 28155 bytes (1.578%)
Idle pool limit: 5.00 MB
Total Pools created: 90
Pools ever used:     88 (shown above)
Currently in use:    55
String Pool	 Impact		
 	 (%strings)	 (%volume)
Short Strings       	 96	 84
Medium Strings      	 7	 18
Long Strings        	 0	 0
1KB Strings         	 0	 0
4KB Strings         	 0	 0
16KB Strings        	 0	 0
Other Strings       	 -2	 -2147483648

Large buffers: 0 (0 KB)
} by kid4

-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf
Type: application/octet-stream
Size: 3917 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200720/8de8791f/attachment.obj>
-------------- next part --------------
HTTP/1.1 200 OK
Server: squid
Mime-Version: 1.0
Date: Mon, 20 Jul 2020 19:45:56 GMT
Content-Type: text/plain
Expires: Mon, 20 Jul 2020 19:45:56 GMT
Last-Modified: Mon, 20 Jul 2020 19:45:56 GMT
Connection: close

Squid Object Cache: Version 4.12
Build Info: Ubuntu linux
Service Name: squid
Start Time:	Fri, 17 Jul 2020 20:09:10 GMT
Current Time:	Mon, 20 Jul 2020 19:45:56 GMT
Connection information for squid:
	Number of clients accessing cache:	391
	Number of HTTP requests received:	3166565
	Number of ICP messages received:	0
	Number of ICP messages sent:	0
	Number of queued ICP replies:	0
	Number of HTCP messages received:	0
	Number of HTCP messages sent:	0
	Request failure ratio:	 0.00
	Average HTTP requests per minute since start:	737.0
	Average ICP messages per minute since start:	0.0
	Select loop called: 22265151 times, 47.499 ms avg
Cache information for squid:
	Hits as % of all requests:	5min: 0.0%, 60min: 0.0%
	Hits as % of bytes sent:	5min: 0.0%, 60min: 0.8%
	Memory hits as % of hit requests:	5min: 0.0%, 60min: 0.0%
	Disk hits as % of hit requests:	5min: 0.0%, 60min: 0.0%
	Storage Swap size:	0 KB
	Storage Swap capacity:	 0.0% used, 100.0% free
	Storage Mem size:	0 KB
	Storage Mem capacity:	 0.0% used, 100.0% free
	Mean Object Size:	0.00 KB
	Requests given to unlinkd:	0
Median Service Times (seconds)  5 min    60 min:
	HTTP Requests (All):   0.00000  4.37905
	Cache Misses:          0.00000  0.00000
	Cache Hits:            0.00000  0.00000
	Near Hits:             0.00000  0.00000
	Not-Modified Replies:  0.00000  0.00000
	DNS Lookups:           0.00000  0.02789
	ICP Queries:           0.00000  0.00000
Resource usage for squid:
	UP Time:	257805.349 seconds
	CPU Time:	7124.296 seconds
	CPU Usage:	2.76%
	CPU Usage, 5 minute avg:	0.05%
	CPU Usage, 60 minute avg:	0.15%
	Maximum Resident Size: 41500720 KB
	Page faults with physical i/o: 1003454
Memory accounted for:
	Total accounted:         8930 KB
	memPoolAlloc calls: 233834032
	memPoolFree calls:  246746981
File descriptor usage for squid:
	Maximum number of file descriptors:   1048572
	Largest file desc currently in use:     34
	Number of file desc currently in use:   44
	Files queued for open:                   0
	Available number of file descriptors: 1048528
	Reserved number of file descriptors:   400
	Store Disk files open:                   0
Internal Data Structures:
	   496 StoreEntries
	   496 StoreEntries with MemObjects
	     0 Hot Object Cache Items
	     0 on-disk objects

From squid.org at bloms.de  Tue Jul 21 07:41:12 2020
From: squid.org at bloms.de (Dieter Bloms)
Date: Tue, 21 Jul 2020 09:41:12 +0200
Subject: [squid-users] squid doesn't fetch the intermediate certificate for
	some sites
Message-ID: <20200721074112.dmx4vefjg5ukbdvz@bloms.de>

Hello,

we use the sslbump feature and it works very well.
But some sites can't be reached because of missing intermediate
certificate.

In squid.conf we have configured the following parameters:

--snip--
# allow fetching of missing intermediate certificates
acl fetch_intermediate_certificate transaction_initiator certificate-fetching
http_access allow fetch_intermediate_certificate
cache allow fetch_intermediate_certificate
cache deny all
--snip--

and fetching the intermediate certificate works for sites like: https://incomplete-chain.badssl.com/

but for some sites like https://mycase.cloudapps.cisco.com/
squid doesn't fetch the intermediate certificate and returns X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY

In my eyes the certificate of mycase.cloudapps.cisco.com contains an AiA
record.

output of openssl on certificate of mycase.cloudapps.cisco.com
--snip--
            Authority Information Access: 
                CA Issuers - URI:http://trust.quovadisglobal.com/hydsslg2.crt
                OCSP - URI:http://ocsp.quovadisglobal.com
--snip--

so does anybody see what's the reason, why squid doesn't download the
intermediate certificate for mycase.cloudapps.cisco.com ?


-- 
Regards

  Dieter Bloms

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
>From field.


From uhlar at fantomas.sk  Tue Jul 21 08:59:49 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 21 Jul 2020 10:59:49 +0200
Subject: [squid-users] squid doesn't fetch the intermediate certificate
 for some sites
In-Reply-To: <20200721074112.dmx4vefjg5ukbdvz@bloms.de>
References: <20200721074112.dmx4vefjg5ukbdvz@bloms.de>
Message-ID: <20200721085949.GB8980@fantomas.sk>

On 21.07.20 09:41, Dieter Bloms wrote:
>we use the sslbump feature and it works very well.
>But some sites can't be reached because of missing intermediate
>certificate.
>
>In squid.conf we have configured the following parameters:
>
>--snip--
># allow fetching of missing intermediate certificates
>acl fetch_intermediate_certificate transaction_initiator certificate-fetching
>http_access allow fetch_intermediate_certificate
>cache allow fetch_intermediate_certificate
>cache deny all
>--snip--
>
>and fetching the intermediate certificate works for sites like: https://incomplete-chain.badssl.com/
>
>but for some sites like https://mycase.cloudapps.cisco.com/
>squid doesn't fetch the intermediate certificate and returns X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY
>
>In my eyes the certificate of mycase.cloudapps.cisco.com contains an AiA
>record.
>
>output of openssl on certificate of mycase.cloudapps.cisco.com
>--snip--
>            Authority Information Access:
>                CA Issuers - URI:http://trust.quovadisglobal.com/hydsslg2.crt
>                OCSP - URI:http://ocsp.quovadisglobal.com
>--snip--
>
>so does anybody see what's the reason, why squid doesn't download the
>intermediate certificate for mycase.cloudapps.cisco.com ?

squid can't download certificates other than the website provides.
if a website does not provide valid certificate chain, it's up to the client
to produce an error. With browser, you can allow the certificate explicitly.

It is also possible that browser has the intermediace certificate
remembered.

testing certificate for mycase.cloudapps.cisco.com shows only one
certificate I can see:

Certificate chain
 0 s:C = US, ST = California, L = San Jose, O = "Cisco Systems, Inc.", CN = mycase.cloudapps.cisco.com
   i:C = US, O = HydrantID (Avalanche Cloud Corporation), CN = HydrantID SSL ICA G2

the HydrantID SSL ICA G2 certificate seems to be missing here.



-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Windows 2000: 640 MB ought to be enough for anybody


From squid.org at bloms.de  Tue Jul 21 09:18:33 2020
From: squid.org at bloms.de (Dieter Bloms)
Date: Tue, 21 Jul 2020 11:18:33 +0200
Subject: [squid-users] squid doesn't fetch the intermediate certificate
 for some sites
In-Reply-To: <20200721085949.GB8980@fantomas.sk>
References: <20200721074112.dmx4vefjg5ukbdvz@bloms.de>
 <20200721085949.GB8980@fantomas.sk>
Message-ID: <20200721091833.5sp7o7p7yijrbk4o@bloms.de>

Hello Matus,

thank you for your answer.

On Tue, Jul 21, Matus UHLAR - fantomas wrote:

> On 21.07.20 09:41, Dieter Bloms wrote:
> > we use the sslbump feature and it works very well.
> > But some sites can't be reached because of missing intermediate
> > certificate.
> > 
> > In squid.conf we have configured the following parameters:
> > 
> > --snip--
> > # allow fetching of missing intermediate certificates
> > acl fetch_intermediate_certificate transaction_initiator certificate-fetching
> > http_access allow fetch_intermediate_certificate
> > cache allow fetch_intermediate_certificate
> > cache deny all
> > --snip--
> > 
> > and fetching the intermediate certificate works for sites like: https://incomplete-chain.badssl.com/
> > 
> > but for some sites like https://mycase.cloudapps.cisco.com/
> > squid doesn't fetch the intermediate certificate and returns X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY
> > 
> > In my eyes the certificate of mycase.cloudapps.cisco.com contains an AiA
> > record.
> > 
> > output of openssl on certificate of mycase.cloudapps.cisco.com
> > --snip--
> >            Authority Information Access:
> >                CA Issuers - URI:http://trust.quovadisglobal.com/hydsslg2.crt
> >                OCSP - URI:http://ocsp.quovadisglobal.com
> > --snip--
> > 
> > so does anybody see what's the reason, why squid doesn't download the
> > intermediate certificate for mycase.cloudapps.cisco.com ?
> 
> squid can't download certificates other than the website provides.

that's not true:

from site: https://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
"Squid-4 is capable of downloading missing intermediate CA certificates,
like popular browsers do."

> if a website does not provide valid certificate chain, it's up to the client
> to produce an error. With browser, you can allow the certificate explicitly.

with ssbump the browser doesn't see the origin webserver certificate,
but sees the squid created one.

> It is also possible that browser has the intermediace certificate
> remembered.

as I already wrote, we use sslbump.

> testing certificate for mycase.cloudapps.cisco.com shows only one
> certificate I can see:
> 
> Certificate chain
> 0 s:C = US, ST = California, L = San Jose, O = "Cisco Systems, Inc.", CN = mycase.cloudapps.cisco.com
>   i:C = US, O = HydrantID (Avalanche Cloud Corporation), CN = HydrantID SSL ICA G2
> 
> the HydrantID SSL ICA G2 certificate seems to be missing here.
> 
> 
> 
> -- 
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> Windows 2000: 640 MB ought to be enough for anybody
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Gru?

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
From field.


From klaus_brandl at genua.de  Tue Jul 21 14:41:40 2020
From: klaus_brandl at genua.de (Klaus Brandl)
Date: Tue, 21 Jul 2020 16:41:40 +0200
Subject: [squid-users] squid kerberos auth, acl note group
Message-ID: <9473896.LjNUQkeJut@cairon>

Hi there,

we have a problem with the squid kerberos auth helper and the note acl 
matching to user groups in an active directory.
First the user was in one group, which was configured via the groupSid base64 
string as a note acl, and this was working very well.
Then there was added a new group to the user, and the note acl was changed to 
this new groupSid string, but now this group is not matching. We also do not 
see this group string in the debug output from the auth helper like this:

/tmp/ports.squid-4.11pg0.AFNuqpKCuX/squid-4.11/src/auth/negotiate/kerberos/negot
iate_kerberos_auth.cc(806): pid=32868 :2020/07/21 14:34:54| 
negotiate_kerberos_a
uth: DEBUG: Groups group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdjV0AAA== 
group=AQUAAAAA
AAUVAAAAMq9NXuhR/XHUeZSdAQIAAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdIXIAAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdkE8AAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdKUMAAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSd2UAAAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdh0wAAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdZk4AAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdFFsAAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdH0cAAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSd+1QAAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdDFEAAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdWlIAAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdOEAAAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdPUMAAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdJ3AAAA== 
group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdOMQAAA== group=AQEAAAAAABIBAAAA

The config is like this:

auth_param negotiate program /usr/local/libexec/squid/negotiate_kerberos_auth 
\
-i -d -s GSS_C_NO_NAME
auth_param negotiate children 100
auth_param negotiate keep_alive on
acl authenticated proxy_auth REQUIRED
acl surfen note group AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdmZ0AAA==
http_access allow authenticated surfen
http_access deny all

Any idea, what the problem could be?
Where are this groups from in the debug output, are they from the decoded 
authentication token from the client, or from the kerberos connection to the 
domain controller?
And why does the last group string looks like truncated?

Thanks for your help!

Regards

Klaus


---

genua GmbH
Domagkstrasse 7, 85551 Kirchheim bei Muenchen
tel +49 89 991950-0, fax -999, www.genua.de

Geschaeftsfuehrer: Matthias Ochs, Marc Tesch
Amtsgericht Muenchen HRB 98238
genua ist ein Unternehmen der Bundesdruckerei-Gruppe.


From rousskov at measurement-factory.com  Tue Jul 21 15:58:53 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 21 Jul 2020 11:58:53 -0400
Subject: [squid-users] squid doesn't fetch the intermediate certificate
 for some sites
In-Reply-To: <20200721074112.dmx4vefjg5ukbdvz@bloms.de>
References: <20200721074112.dmx4vefjg5ukbdvz@bloms.de>
Message-ID: <3997c0de-721c-b5a5-9f85-d79aa562f730@measurement-factory.com>

On 7/21/20 3:41 AM, Dieter Bloms wrote:

> for some sites like https://mycase.cloudapps.cisco.com/
> squid doesn't fetch the intermediate certificate and returns X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY

The underlying problem is not specific to SslBump AFAICT. The
combination of unfortunate OpenSSL design decisions and TLS v1.3 secrecy
creates a serious problem for Squid. For details, please see

  https://bugs.squid-cache.org/show_bug.cgi?id=5067#c2

Alex.


From rousskov at measurement-factory.com  Tue Jul 21 18:21:46 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 21 Jul 2020 14:21:46 -0400
Subject: [squid-users] squid kerberos auth, acl note group
In-Reply-To: <9473896.LjNUQkeJut@cairon>
References: <9473896.LjNUQkeJut@cairon>
Message-ID: <8805045d-b0f8-b0e5-b1b8-cbaad9350557@measurement-factory.com>

On 7/21/20 10:41 AM, Klaus Brandl wrote:

> we have a problem with the squid kerberos auth helper and the note acl 
> matching to user groups in an active directory.
> First the user was in one group, which was configured via the groupSid base64 
> string as a note acl, and this was working very well.
> Then there was added a new group to the user, and the note acl was changed to 
> this new groupSid string, but now this group is not matching. We also do not 
> see this group string in the debug output from the auth helper like this:

If the helper is not returning the new groupSid to Squid then the note
ACL using that new groupSid should not match. Unfortunately, I do not
know enough about that helper to tell you why it does not tell Squid
about the new group.


> /tmp/ports.squid-4.11pg0.AFNuqpKCuX/squid-4.11/src/auth/negotiate/kerberos/negot
> iate_kerberos_auth.cc(806): pid=32868 :2020/07/21 14:34:54| 
> negotiate_kerberos_auth: DEBUG: Groups group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdjV0AAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdAQIAAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdIXIAAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdkE8AAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdKUMAAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSd2UAAAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdh0wAAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdZk4AAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdFFsAAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdH0cAAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSd+1QAAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdDFEAAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdWlIAAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdOEAAAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdPUMAAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdJ3AAAA== 
> group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdOMQAAA== group=AQEAAAAAABIBAAAA
> 
> The config is like this:
> 
> auth_param negotiate program /usr/local/libexec/squid/negotiate_kerberos_auth 
> \
> -i -d -s GSS_C_NO_NAME
> auth_param negotiate children 100
> auth_param negotiate keep_alive on
> acl authenticated proxy_auth REQUIRED
> acl surfen note group AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdmZ0AAA==
> http_access allow authenticated surfen
> http_access deny all
> 
> Any idea, what the problem could be?
> Where are this groups from in the debug output, are they from the decoded 
> authentication token from the client, or from the kerberos connection to the 
> domain controller?

The group membership info should be coming from the authentication
service, not the client.


> And why does the last group string looks like truncated?

I could not find the source of the debug() function used by the helper,
but I would not be surprised it that function has a fixed buffer that
does not accommodate all the groups. It is also possible that there is
not enough space in the helper buffers to store the actual groups -- I
cannot tell whether that is the case from the debugging output you
shared (and the source code has many conditional branches that allocate
this space differently based on various factors AFAICT).

A local developer or a very capable local admin should be able to answer
this question by studying (and possibly adding more) helper debugging.


Please also note that there are a couple of possibly related known bugs:

* https://bugs.squid-cache.org/show_bug.cgi?id=5063
* https://bugs.squid-cache.org/show_bug.cgi?id=5063

Alex.


From squid3 at treenet.co.nz  Wed Jul 22 03:58:11 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 22 Jul 2020 15:58:11 +1200
Subject: [squid-users] Squid typo fixes for 4.12
In-Reply-To: <vmime.5efaebf4.2df9.34d1bbac35781934@ms249-lin-003.rotterdam.bazuin.nl>
References: <vmime.5efaebf4.2df9.34d1bbac35781934@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <9e9832f6-b838-98ed-a19c-2c61f78d0fee@treenet.co.nz>

On 30/06/20 7:38 pm, L.P.H. van Belle wrote:
> Hai, 
>  
> Sorry for not pushing this through git.
> If you want some typo fixed, here you go.
> 
> 
> Fixed typo's found by Lintian on Debian Buster.
> --- a/src/ssl/crtd_message.cc
> +++ b/src/ssl/crtd_message.cc
> @@ -206,7 +206,7 @@
>      i = map.find(Ssl::CrtdMessage::param_Sign);
>      if (i != map.end()) {
>          if ((certProperties.signAlgorithm = Ssl::certSignAlgorithmId(i->second.c_str())) == Ssl::algSignEnd) {
> -            error = "Wrong signing algoritm: ";
> +            error = "Wrong signing algorithm: ";
>              error += i->second;
>              return false;
>          }
> --- a/CREDITS
> +++ b/CREDITS
> @@ -1631,7 +1631,7 @@
>   * (C) 2000 Antonino Iannella, Stellar-X Pty Ltd
>   * Released under GPL, see COPYING-2.0 for details.
> 
> - * Released under GNU Public License
> + * Released under GNU General Public License
>   *
>   * This program is free software; you can redistribute it and/or modify
>   * it under the terms of the GNU General Public License as published by


FTR; License text is not subject to trivial re-writing. The third-party
code being used by Squid was supplied with that particular wording for
their license description and we must not change it without permission.
("GNU Public License" was an actual license back in the dawn of time).

In absence of contact with the copyright holder we may only replace the
code wholesale with an updated version from that author where they
provide a different license text, or a cleanroom implementation from
someone else.


The rest of the patch is fine. Though please be aware that some of the
error messages have translation texts which will be prevented from
appearing when changed.


Amos


From belle at bazuin.nl  Wed Jul 22 07:15:37 2020
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 22 Jul 2020 09:15:37 +0200
Subject: [squid-users] Squid typo fixes for 4.12
In-Reply-To: <9e9832f6-b838-98ed-a19c-2c61f78d0fee@treenet.co.nz>
References: <vmime.5efaebf4.2df9.34d1bbac35781934@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <vmime.5f17e799.1e25.343fff2f558a66a9@ms249-lin-003.rotterdam.bazuin.nl>

Hai, 

Thanks for the info Amos. 

Ok so i need to reverse the Licence/Credits due to the licencing.
I'll reverse these and add these in the lintian overrides then. 

On the error messages translation text part, should think in squid langpack? 
For now i just used the debian supplied package with my own build, because i dont really need error messages.
But, i'll go through these also when we hit the next update if its needed. 

And thankyou for the review and pointers, most welkom. :-) 


Greetz, 

Louis


> -----Oorspronkelijk bericht-----
> Van: squid-users 
> [mailto:squid-users-bounces at lists.squid-cache.org] Namens 
> Amos Jeffries
> Verzonden: woensdag 22 juli 2020 5:58
> Aan: squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] Squid typo fixes for 4.12
> 
> On 30/06/20 7:38 pm, L.P.H. van Belle wrote:
> > Hai, 
> >  
> > Sorry for not pushing this through git.
> > If you want some typo fixed, here you go.
> > 
> > 
> > Fixed typo's found by Lintian on Debian Buster.
> > --- a/src/ssl/crtd_message.cc
> > +++ b/src/ssl/crtd_message.cc
> > @@ -206,7 +206,7 @@
> >      i = map.find(Ssl::CrtdMessage::param_Sign);
> >      if (i != map.end()) {
> >          if ((certProperties.signAlgorithm = 
> Ssl::certSignAlgorithmId(i->second.c_str())) == Ssl::algSignEnd) {
> > -            error = "Wrong signing algoritm: ";
> > +            error = "Wrong signing algorithm: ";
> >              error += i->second;
> >              return false;
> >          }
> > --- a/CREDITS
> > +++ b/CREDITS
> > @@ -1631,7 +1631,7 @@
> >   * (C) 2000 Antonino Iannella, Stellar-X Pty Ltd
> >   * Released under GPL, see COPYING-2.0 for details.
> > 
> > - * Released under GNU Public License
> > + * Released under GNU General Public License
> >   *
> >   * This program is free software; you can redistribute it 
> and/or modify
> >   * it under the terms of the GNU General Public License as 
> published by
> 
> 
> FTR; License text is not subject to trivial re-writing. The 
> third-party
> code being used by Squid was supplied with that particular wording for
> their license description and we must not change it without 
> permission.
> ("GNU Public License" was an actual license back in the dawn of time).
> 
> In absence of contact with the copyright holder we may only 
> replace the
> code wholesale with an updated version from that author where they
> provide a different license text, or a cleanroom implementation from
> someone else.
> 
> 
> The rest of the patch is fine. Though please be aware that some of the
> error messages have translation texts which will be prevented from
> appearing when changed.
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From klaus_brandl at genua.de  Wed Jul 22 08:59:41 2020
From: klaus_brandl at genua.de (Klaus Brandl)
Date: Wed, 22 Jul 2020 10:59:41 +0200
Subject: [squid-users] squid kerberos auth, acl note group
In-Reply-To: <8805045d-b0f8-b0e5-b1b8-cbaad9350557@measurement-factory.com>
References: <9473896.LjNUQkeJut@cairon>
 <8805045d-b0f8-b0e5-b1b8-cbaad9350557@measurement-factory.com>
Message-ID: <9312048.eM79Cvr8H9@cairon>

On Tuesday 21 July 2020 14:21:46 Alex Rousskov wrote:
> On 7/21/20 10:41 AM, Klaus Brandl wrote:
> > we have a problem with the squid kerberos auth helper and the note acl
> > matching to user groups in an active directory.
> > First the user was in one group, which was configured via the groupSid
> > base64 string as a note acl, and this was working very well.
> > Then there was added a new group to the user, and the note acl was changed
> > to this new groupSid string, but now this group is not matching. We also
> > do not
> > see this group string in the debug output from the auth helper like this:
> If the helper is not returning the new groupSid to Squid then the note
> ACL using that new groupSid should not match. Unfortunately, I do not
> know enough about that helper to tell you why it does not tell Squid
> about the new group.
> 
> > /tmp/ports.squid-4.11pg0.AFNuqpKCuX/squid-4.11/src/auth/negotiate/kerberos
> > /negot iate_kerberos_auth.cc(806): pid=32868 :2020/07/21 14:34:54|
> > negotiate_kerberos_auth: DEBUG: Groups
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdjV0AAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdAQIAAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdIXIAAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdkE8AAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdKUMAAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSd2UAAAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdh0wAAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdZk4AAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdFFsAAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdH0cAAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSd+1QAAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdDFEAAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdWlIAAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdOEAAAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdPUMAAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdJ3AAAA==
> > group=AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdOMQAAA== group=AQEAAAAAABIBAAAA
> > 
> > The config is like this:
> > 
> > auth_param negotiate program
> > /usr/local/libexec/squid/negotiate_kerberos_auth \
> > -i -d -s GSS_C_NO_NAME
> > auth_param negotiate children 100
> > auth_param negotiate keep_alive on
> > acl authenticated proxy_auth REQUIRED
> > acl surfen note group AQUAAAAAAAUVAAAAMq9NXuhR/XHUeZSdmZ0AAA==
> > http_access allow authenticated surfen
> > http_access deny all
> > 
> > Any idea, what the problem could be?
> > Where are this groups from in the debug output, are they from the decoded
> > authentication token from the client, or from the kerberos connection to
> > the domain controller?
> 
> The group membership info should be coming from the authentication
> service, not the client.

but i have compared the encoded string from the auth helper with the string at 
the Proxy-Authentication header from the client with tcpdump, and it's exactly 
the same:

Proxy-Authorization: Negotiate YIIGpQYGKwYBBQUCoIIGmTCCBpWgMDAuBgkqhkiC9xIB...

/tmp/ports.squid-4.11pg0.AFNuqpKCuX/squid-4.11/src/auth/negotiate/kerberos/negotiate_kerberos_auth.cc(612): 
pid=28796 :2020/07/21 16:15:12| negotiate_kerberos_auth: DEBUG: Got 'YR 
YIIGpQYGKwYBBQUCoIIGmTCCBpWgMDAuBgkqhkiC9xIB...

On the kerberos connection(port 88) i see only the service prinzipal, so i am 
nearly sure, this groups are from the client.

> 
> > And why does the last group string looks like truncated?
> 
> I could not find the source of the debug() function used by the helper,
> but I would not be surprised it that function has a fixed buffer that
> does not accommodate all the groups. It is also possible that there is
> not enough space in the helper buffers to store the actual groups -- I
> cannot tell whether that is the case from the debugging output you
> shared (and the source code has many conditional branches that allocate
> this space differently based on various factors AFAICT).
> 
> A local developer or a very capable local admin should be able to answer
> this question by studying (and possibly adding more) helper debugging.
> 
> 
> Please also note that there are a couple of possibly related known bugs:
> 
> * https://bugs.squid-cache.org/show_bug.cgi?id=5063
> * https://bugs.squid-cache.org/show_bug.cgi?id=5063
> 
> Alex.

Klaus

---

genua GmbH
Domagkstrasse 7, 85551 Kirchheim bei Muenchen
tel +49 89 991950-0, fax -999, www.genua.de

Geschaeftsfuehrer: Matthias Ochs, Marc Tesch
Amtsgericht Muenchen HRB 98238
genua ist ein Unternehmen der Bundesdruckerei-Gruppe.


From squid3 at treenet.co.nz  Wed Jul 22 12:16:45 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jul 2020 00:16:45 +1200
Subject: [squid-users] squid kerberos auth, acl note group
In-Reply-To: <9312048.eM79Cvr8H9@cairon>
References: <9473896.LjNUQkeJut@cairon>
 <8805045d-b0f8-b0e5-b1b8-cbaad9350557@measurement-factory.com>
 <9312048.eM79Cvr8H9@cairon>
Message-ID: <15d265ac-3e06-d6ca-1480-fda8506da49d@treenet.co.nz>

On 22/07/20 8:59 pm, Klaus Brandl wrote:
> 
> but i have compared the encoded string from the auth helper with the string at 
> the Proxy-Authentication header from the client with tcpdump, and it's exactly 
> the same:
> 
> Proxy-Authorization: Negotiate YIIGpQYGKwYBBQUCoIIGmTCCBpWgMDAuBgkqhkiC9xIB...
> 
> /tmp/ports.squid-4.11pg0.AFNuqpKCuX/squid-4.11/src/auth/negotiate/kerberos/negotiate_kerberos_auth.cc(612): 
> pid=28796 :2020/07/21 16:15:12| negotiate_kerberos_auth: DEBUG: Got 'YR 
> YIIGpQYGKwYBBQUCoIIGmTCCBpWgMDAuBgkqhkiC9xIB...
> 
> On the kerberos connection(port 88) i see only the service prinzipal, so i am 
> nearly sure, this groups are from the client.
> 

Okay. If you run the helper manually on command line and pass that same
"YR ..." line Squid is delivering. How long is the result that comes back?

The helper I/O buffer is 32KB in current Squid. The above test will show
how large it needs to be for your network. Unfortunately changes to this
buffer do need a patch.


Amos


From klaus_brandl at genua.de  Wed Jul 22 12:53:14 2020
From: klaus_brandl at genua.de (Klaus Brandl)
Date: Wed, 22 Jul 2020 14:53:14 +0200
Subject: [squid-users] squid kerberos auth, acl note group
In-Reply-To: <15d265ac-3e06-d6ca-1480-fda8506da49d@treenet.co.nz>
References: <9473896.LjNUQkeJut@cairon> <9312048.eM79Cvr8H9@cairon>
 <15d265ac-3e06-d6ca-1480-fda8506da49d@treenet.co.nz>
Message-ID: <12080330.Prj8ev6qeJ@cairon>

On Thursday 23 July 2020 00:16:45 Amos Jeffries wrote:
> On 22/07/20 8:59 pm, Klaus Brandl wrote:
> > but i have compared the encoded string from the auth helper with the
> > string at the Proxy-Authentication header from the client with tcpdump,
> > and it's exactly the same:
> > 
> > Proxy-Authorization: Negotiate
> > YIIGpQYGKwYBBQUCoIIGmTCCBpWgMDAuBgkqhkiC9xIB...
> > 
> > /tmp/ports.squid-4.11pg0.AFNuqpKCuX/squid-4.11/src/auth/negotiate/kerberos
> > /negotiate_kerberos_auth.cc(612): pid=28796 :2020/07/21 16:15:12|
> > negotiate_kerberos_auth: DEBUG: Got 'YR
> > YIIGpQYGKwYBBQUCoIIGmTCCBpWgMDAuBgkqhkiC9xIB...
> > 
> > On the kerberos connection(port 88) i see only the service prinzipal, so i
> > am nearly sure, this groups are from the client.
> 
> Okay. If you run the helper manually on command line and pass that same
> "YR ..." line Squid is delivering. How long is the result that comes back?

thank you, i think you mean this:

DEBUG: OK token=oYG3MIG0oAMKAQChCwYJKoZIgvcSAQIC...

This is only 254 bytes.

> 
> The helper I/O buffer is 32KB in current Squid. The above test will show
> how large it needs to be for your network. Unfortunately changes to this
> buffer do need a patch.
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Klaus
---

genua GmbH
Domagkstrasse 7, 85551 Kirchheim bei Muenchen
tel +49 89 991950-0, fax -999, www.genua.de

Geschaeftsfuehrer: Matthias Ochs, Marc Tesch
Amtsgericht Muenchen HRB 98238
genua ist ein Unternehmen der Bundesdruckerei-Gruppe.


From squid3 at treenet.co.nz  Wed Jul 22 13:26:06 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jul 2020 01:26:06 +1200
Subject: [squid-users] squid kerberos auth, acl note group
In-Reply-To: <12080330.Prj8ev6qeJ@cairon>
References: <9473896.LjNUQkeJut@cairon> <9312048.eM79Cvr8H9@cairon>
 <15d265ac-3e06-d6ca-1480-fda8506da49d@treenet.co.nz>
 <12080330.Prj8ev6qeJ@cairon>
Message-ID: <1ef6cafe-19f6-9b9c-9612-90552430bdb4@treenet.co.nz>

On 23/07/20 12:53 am, Klaus Brandl wrote:
> On Thursday 23 July 2020 00:16:45 Amos Jeffries wrote:
>> On 22/07/20 8:59 pm, Klaus Brandl wrote:
>>> but i have compared the encoded string from the auth helper with the
>>> string at the Proxy-Authentication header from the client with tcpdump,
>>> and it's exactly the same:
>>>
>>> Proxy-Authorization: Negotiate
>>> YIIGpQYGKwYBBQUCoIIGmTCCBpWgMDAuBgkqhkiC9xIB...
>>>
>>> /tmp/ports.squid-4.11pg0.AFNuqpKCuX/squid-4.11/src/auth/negotiate/kerberos
>>> /negotiate_kerberos_auth.cc(612): pid=28796 :2020/07/21 16:15:12|
>>> negotiate_kerberos_auth: DEBUG: Got 'YR
>>> YIIGpQYGKwYBBQUCoIIGmTCCBpWgMDAuBgkqhkiC9xIB...
>>>
>>> On the kerberos connection(port 88) i see only the service prinzipal, so i
>>> am nearly sure, this groups are from the client.
>>
>> Okay. If you run the helper manually on command line and pass that same
>> "YR ..." line Squid is delivering. How long is the result that comes back?
> 
> thank you, i think you mean this:
> 
> DEBUG: OK token=oYG3MIG0oAMKAQChCwYJKoZIgvcSAQIC...
> 
> This is only 254 bytes.
> 



Ah. Sorry. I should have checked the protocol sequence, it has been a
while since last I played with these tokens.

For Kerberos there should be a test_negotiate_auth.sh script and
negotiate_kerberos_auth_test binary available for debugging these auth
details.

Run the test_negotiate_auth.sh with with your Squid hostname as its
command line parameter.


Amos


From dagershman at dagertech.net  Thu Jul 23 01:47:22 2020
From: dagershman at dagertech.net (David A. Gershman)
Date: Wed, 22 Jul 2020 18:47:22 -0700
Subject: [squid-users] Not working:
	http://www.squid-cache.org/cgi-bin/swish-query.cgi
Message-ID: <c3e3d1ca-fda2-5014-230b-32df479d395c@dagertech.net>

Hello,

The mailing list site

 ??? http://www.squid-cache.org/Support/mailing-lists.html

states a search engine is available at

 ??? http://www.squid-cache.org/cgi-bin/swish-query.cgi

However, going here results in a 404 not found.? Is there another search 
engine?

--David
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200722/bdae91b8/attachment.htm>

From dagershman at dagertech.net  Thu Jul 23 02:22:05 2020
From: dagershman at dagertech.net (David A. Gershman)
Date: Wed, 22 Jul 2020 19:22:05 -0700
Subject: [squid-users] Simple REGEX not working...
Message-ID: <09d24d10-df92-2832-5828-b1cabdb4e308@dagertech.net>

Hello,

I have the following in my config file:

 ??? acl user_allowed url_regex ^https://example\.com/

but surfing to that site fails (authentication works fine).? My ultimate 
goal is to have an RE comparable to the PCRE of:

 ??? ^https?:\/\/.*?example\.com\/

While the PCRE works just fine in other tools (my own scripts, online, 
etc.), I was unable to get it to work within Squid3.? As I stripped away 
pieces of the RE in the config file, the only RE which seemed to work was:

 ??? example\.com

...not even having the ending '/'.? However, this obviously does not 
meet my needs.

I'm on Debian 10 and am unable to determine which RE library Debian 
compiled Squid3 against (I've got a Tweet out to them to see if they can 
point me in the right direction).

Ultimately, I would like to get Squid to use PCREs.

Ideas?

Thanks!

--David
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200722/d0dfecc3/attachment.htm>

From dagershman at dagertech.net  Thu Jul 23 03:27:37 2020
From: dagershman at dagertech.net (David A. Gershman)
Date: Wed, 22 Jul 2020 20:27:37 -0700
Subject: [squid-users] Simple REGEX not working...
In-Reply-To: <09d24d10-df92-2832-5828-b1cabdb4e308@dagertech.net>
References: <09d24d10-df92-2832-5828-b1cabdb4e308@dagertech.net>
Message-ID: <0ed40f83-a724-6879-fee0-7a6ff049387c@dagertech.net>

Hello again,

After further testing, the looks like the only thing being regex'd 
against is the domain name.? I shrunk the RE down to just:

 ??? acl user_allowed url_regex http? # nothing more, just 'http'

and it /*still*/ failed!!!? It's as if the "whole url" (claimed by the 
docs) is /not/ being compared against.? I'm just posting this here as an 
FYI...no solution has been found. :(

--David

On 7/22/20 7:22 PM, David A. Gershman wrote:
> Hello,
>
> I have the following in my config file:
>
> ??? acl user_allowed url_regex ^https://example\.com/
>
> but surfing to that site fails (authentication works fine).? My 
> ultimate goal is to have an RE comparable to the PCRE of:
>
> ??? ^https?:\/\/.*?example\.com\/
>
> While the PCRE works just fine in other tools (my own scripts, online, 
> etc.), I was unable to get it to work within Squid3.? As I stripped 
> away pieces of the RE in the config file, the only RE which seemed to 
> work was:
>
> ??? example\.com
>
> ...not even having the ending '/'.? However, this obviously does not 
> meet my needs.
>
> I'm on Debian 10 and am unable to determine which RE library Debian 
> compiled Squid3 against (I've got a Tweet out to them to see if they 
> can point me in the right direction).
>
> Ultimately, I would like to get Squid to use PCREs.
>
> Ideas?
>
> Thanks!
>
> --David
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200722/1fecd140/attachment.htm>

From squid3 at treenet.co.nz  Thu Jul 23 03:58:50 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jul 2020 15:58:50 +1200
Subject: [squid-users] Simple REGEX not working...
In-Reply-To: <0ed40f83-a724-6879-fee0-7a6ff049387c@dagertech.net>
References: <09d24d10-df92-2832-5828-b1cabdb4e308@dagertech.net>
 <0ed40f83-a724-6879-fee0-7a6ff049387c@dagertech.net>
Message-ID: <df3abb61-ec02-d17c-ca9a-280575815eb7@treenet.co.nz>

On 23/07/20 3:27 pm, David A. Gershman wrote:
> Hello again,
> 
> After further testing, the looks like the only thing being regex'd
> against is the domain name.? I shrunk the RE down to just:
> 
> ??? acl user_allowed url_regex http? # nothing more, just 'http'
> 
> and it /*still*/ failed!!!? It's as if the "whole url" (claimed by the
> docs) is /not/ being compared against.? I'm just posting this here as an
> FYI...no solution has been found. :(
> 

Squid uses basic regex without extensions - the basic operators that
work in both GNU regex and POSIX regex can be expected to work.

Your mistake is thinking that URL always looks like "https://example.com/".

For HTTPS traffic going through an HTTP proxy the URL is in
authority-form which looks like "example.com:443".
<https://tools.ietf.org/html/rfc7230#section-5.3.3>


> 
> On 7/22/20 7:22 PM, David A. Gershman wrote:
>> Hello,
>>
>> I have the following in my config file:
>>
>> ??? acl user_allowed url_regex ^https://example\.com/
>>
>> but surfing to that site fails (authentication works fine).? My
>> ultimate goal is to have an RE comparable to the PCRE of:
>>
>> ??? ^https?:\/\/.*?example\.com\/
>>
>> While the PCRE works just fine in other tools (my own scripts, online,
>> etc.), I was unable to get it to work within Squid3.? As I stripped
>> away pieces of the RE in the config file, the only RE which seemed to
>> work was:
>>
>> ??? example\.com
>>
>> ...not even having the ending '/'.? However, this obviously does not
>> meet my needs.
>>

To get to the scheme and path information for HTTPS traffic you need
SSL-Bump functionality built into the proxy and configured to decrypt
the TLS traffic layer.

OpenSSL license currently (soon to change, yay!) does not permit Debian
to distribute a Squid binary package with that feature enabled so you
will have to rebuild the squid package yourself with relevant additions
or install a package from an independent repository.



>> I'm on Debian 10 and am unable to determine which RE library Debian
>> compiled Squid3 against (I've got a Tweet out to them to see if they
>> can point me in the right direction).

Squid3 has been removed from Debian long ago. You should be using
"squid" package these days which is Squid-4 on all current Debian.


HTH
Amos


From dagershman at dagertech.net  Thu Jul 23 04:14:34 2020
From: dagershman at dagertech.net (David A. Gershman)
Date: Wed, 22 Jul 2020 21:14:34 -0700
Subject: [squid-users] Simple REGEX not working...
In-Reply-To: <df3abb61-ec02-d17c-ca9a-280575815eb7@treenet.co.nz>
References: <09d24d10-df92-2832-5828-b1cabdb4e308@dagertech.net>
 <0ed40f83-a724-6879-fee0-7a6ff049387c@dagertech.net>
 <df3abb61-ec02-d17c-ca9a-280575815eb7@treenet.co.nz>
Message-ID: <4d541f21-e141-ed05-2342-b27dc5d4bf4d@dagertech.net>

Thank Amos.? Ironically I just found that out with testing and then a 
search pointing me here:

 ??? https://wiki.squid-cache.org/Features/HTTPS

Sadly, I should have thought of that.? Been a long day I guess.

Thanks again!

--David

On 7/22/20 8:58 PM, Amos Jeffries wrote:
> On 23/07/20 3:27 pm, David A. Gershman wrote:
>> Hello again,
>>
>> After further testing, the looks like the only thing being regex'd
>> against is the domain name.? I shrunk the RE down to just:
>>
>>  ??? acl user_allowed url_regex http? # nothing more, just 'http'
>>
>> and it /*still*/ failed!!!? It's as if the "whole url" (claimed by the
>> docs) is /not/ being compared against.? I'm just posting this here as an
>> FYI...no solution has been found. :(
>>
> Squid uses basic regex without extensions - the basic operators that
> work in both GNU regex and POSIX regex can be expected to work.
>
> Your mistake is thinking that URL always looks like "https://example.com/".
>
> For HTTPS traffic going through an HTTP proxy the URL is in
> authority-form which looks like "example.com:443".
> <https://tools.ietf.org/html/rfc7230#section-5.3.3>
>
>
>> On 7/22/20 7:22 PM, David A. Gershman wrote:
>>> Hello,
>>>
>>> I have the following in my config file:
>>>
>>>  ??? acl user_allowed url_regex ^https://example\.com/
>>>
>>> but surfing to that site fails (authentication works fine).? My
>>> ultimate goal is to have an RE comparable to the PCRE of:
>>>
>>>  ??? ^https?:\/\/.*?example\.com\/
>>>
>>> While the PCRE works just fine in other tools (my own scripts, online,
>>> etc.), I was unable to get it to work within Squid3.? As I stripped
>>> away pieces of the RE in the config file, the only RE which seemed to
>>> work was:
>>>
>>>  ??? example\.com
>>>
>>> ...not even having the ending '/'.? However, this obviously does not
>>> meet my needs.
>>>
> To get to the scheme and path information for HTTPS traffic you need
> SSL-Bump functionality built into the proxy and configured to decrypt
> the TLS traffic layer.
>
> OpenSSL license currently (soon to change, yay!) does not permit Debian
> to distribute a Squid binary package with that feature enabled so you
> will have to rebuild the squid package yourself with relevant additions
> or install a package from an independent repository.
>
>
>
>>> I'm on Debian 10 and am unable to determine which RE library Debian
>>> compiled Squid3 against (I've got a Tweet out to them to see if they
>>> can point me in the right direction).
> Squid3 has been removed from Debian long ago. You should be using
> "squid" package these days which is Squid-4 on all current Debian.
>
>
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200722/bb18a89d/attachment.htm>

From 3m9n51s2ewut at thismonkey.com  Thu Jul 23 05:39:16 2020
From: 3m9n51s2ewut at thismonkey.com (Scott)
Date: Thu, 23 Jul 2020 15:39:16 +1000
Subject: [squid-users] error:invalid-request HTTP/1.1 (iPhone requesting
	icloud.com)
Message-ID: <20200723053916.GA69311@thismonkey.com>

Hi,

some iOS requests to gateway.icloud.com via squid (explicit) throw the 
following error in the logs:

2020-07-23T15:31:08+10:00 00.11.22.68 (squid-1): ABCD::17 (iphoneXs.domain.com) - via -:- - - [23/Jul/2020:15:31:08 +1000] "- error:invalid-request HTTP/1.1" 400 3739 "-" "-" NONE_NONE:HIER _NONE (mode:- sni:-)

Cache file logging of HTTP only shows Squid's response (not the client 
request).

tcpdump gives the following TCP stream (in ASCII):

C->S:
................_\...&_<. at 4..../..K.......' ........z...h.q.B..H..c....0L>...4.......,.+.$.#.
.	...0./.(.'...........=.<.5./.....
..................gateway.icloud.com.....
..............................................h2.http/1.1.......3.&.$... R..{V$_<]..yM..L...1b	..d...).
..-.....+.	..........
.
.........................................................................................................................................................................................................................

S->C:
HTTP/1.1 400 Bad Request
Server: squid/5.0.1-20200312-r8a511d5e0
Mime-Version: 1.0
Date: Thu, 23 Jul 2020 05:00:20 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3406
X-Squid-Error: ERR_PROTOCOL_UNKNOWN 0
Vary: Accept-Language
Content-Language: en
X-Cache: MISS from proxy-01.thismonkey.com
Connection: close

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
<meta type="copyright" content="Copyright (C) 1996-2020 The Squid Software Foundation and contributors">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>ERROR: The requested URL could not be retrieved</title>
<style type="text/css"><!-- 

<snip>

Does anyone know what type of request the client is sending?  And why squid is unhappy with it?

To my eye it doesn't look like HTTP - perhaps the h2 is a clue?

Thanks


From gkinkie at gmail.com  Thu Jul 23 08:56:14 2020
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Thu, 23 Jul 2020 10:56:14 +0200
Subject: [squid-users] Not working:
	http://www.squid-cache.org/cgi-bin/swish-query.cgi
In-Reply-To: <c3e3d1ca-fda2-5014-230b-32df479d395c@dagertech.net>
References: <c3e3d1ca-fda2-5014-230b-32df479d395c@dagertech.net>
Message-ID: <CA+Y8hcMHMnWnkh+xc9+wBCCFzt_MjiunRqLSyWdAyoQ9GzFQfQ@mail.gmail.com>

Hi,
  unfortunately not. You can use google search to search through the
archives.

On Thu, Jul 23, 2020 at 3:47 AM David A. Gershman <dagershman at dagertech.net>
wrote:

> Hello,
>
> The mailing list site
>
>     http://www.squid-cache.org/Support/mailing-lists.html
>
> states a search engine is available at
>
>     http://www.squid-cache.org/cgi-bin/swish-query.cgi
>
> However, going here results in a 404 not found.  Is there another search
> engine?
>
> --David
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
    Francesco
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200723/820f1bcb/attachment.htm>

From ryanlele264 at gmail.com  Thu Jul 23 13:22:56 2020
From: ryanlele264 at gmail.com (Ryan Le)
Date: Thu, 23 Jul 2020 09:22:56 -0400
Subject: [squid-users] Squid and multipart form decode
Message-ID: <CANqqF0qJ_LNLcWNk_pt3Xpz2bf=P1z3ws4TBnYVfb4-V8oS9hg@mail.gmail.com>

I have been trying to configure squid to decode and send multipart form
data to another service. Is there an acl or build parameter needed for
multipart form data support?

Thanks,
Ryan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200723/eeb93274/attachment.htm>

From Antony.Stone at squid.open.source.it  Thu Jul 23 13:27:35 2020
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 23 Jul 2020 15:27:35 +0200
Subject: [squid-users] Squid and multipart form decode
In-Reply-To: <CANqqF0qJ_LNLcWNk_pt3Xpz2bf=P1z3ws4TBnYVfb4-V8oS9hg@mail.gmail.com>
References: <CANqqF0qJ_LNLcWNk_pt3Xpz2bf=P1z3ws4TBnYVfb4-V8oS9hg@mail.gmail.com>
Message-ID: <202007231527.35212.Antony.Stone@squid.open.source.it>

On Thursday 23 July 2020 at 15:22:56, Ryan Le wrote:

> I have been trying to configure squid to decode and send multipart form
> data to another service.

What do you mean by "decode"?

> Is there an acl or build parameter needed for multipart form data support?

No; Squid sends on what it gets from the client.


Antony.

-- 
The next sentence is untrue.
The previous sentence is true.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From ryanlele264 at gmail.com  Thu Jul 23 13:33:01 2020
From: ryanlele264 at gmail.com (Ryan Le)
Date: Thu, 23 Jul 2020 09:33:01 -0400
Subject: [squid-users] Squid and multipart form decode
In-Reply-To: <202007231527.35212.Antony.Stone@squid.open.source.it>
References: <CANqqF0qJ_LNLcWNk_pt3Xpz2bf=P1z3ws4TBnYVfb4-V8oS9hg@mail.gmail.com>
 <202007231527.35212.Antony.Stone@squid.open.source.it>
Message-ID: <CANqqF0puF0vB0Mkbz=r4c-LRiwKuYSuWP_QGA4paFoWfERNLyQ@mail.gmail.com>

sorry not decode, just parse to send headers to icap as well.

On Thu, Jul 23, 2020 at 9:27 AM Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Thursday 23 July 2020 at 15:22:56, Ryan Le wrote:
>
> > I have been trying to configure squid to decode and send multipart form
> > data to another service.
>
> What do you mean by "decode"?
>
> > Is there an acl or build parameter needed for multipart form data
> support?
>
> No; Squid sends on what it gets from the client.
>
>
> Antony.
>
> --
> The next sentence is untrue.
> The previous sentence is true.
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200723/2bbd2dc6/attachment.htm>

From Antony.Stone at squid.open.source.it  Thu Jul 23 13:39:18 2020
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 23 Jul 2020 15:39:18 +0200
Subject: [squid-users] Squid and multipart form decode
In-Reply-To: <CANqqF0puF0vB0Mkbz=r4c-LRiwKuYSuWP_QGA4paFoWfERNLyQ@mail.gmail.com>
References: <CANqqF0qJ_LNLcWNk_pt3Xpz2bf=P1z3ws4TBnYVfb4-V8oS9hg@mail.gmail.com>
 <202007231527.35212.Antony.Stone@squid.open.source.it>
 <CANqqF0puF0vB0Mkbz=r4c-LRiwKuYSuWP_QGA4paFoWfERNLyQ@mail.gmail.com>
Message-ID: <202007231539.18829.Antony.Stone@squid.open.source.it>

On Thursday 23 July 2020 at 15:33:01, Ryan Le wrote:

> sorry not decode, just parse to send headers to icap as well.

Aha, icap - sorry, I can't help you there, but I'm pretty sure there are 
others here who have used it.

> On Thu, Jul 23, 2020 at 9:27 AM Antony Stone wrote:
> > On Thursday 23 July 2020 at 15:22:56, Ryan Le wrote:
> > > I have been trying to configure squid to decode and send multipart form
> > > data to another service.
> > 
> > What do you mean by "decode"?
> > 
> > > Is there an acl or build parameter needed for multipart form data
> > > support?
> > 
> > No; Squid sends on what it gets from the client.

Antony.

-- 
I bought a book on memory techniques, but I've forgotten where I put it.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From rousskov at measurement-factory.com  Thu Jul 23 15:15:59 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 23 Jul 2020 11:15:59 -0400
Subject: [squid-users] Squid and multipart form decode
In-Reply-To: <CANqqF0qJ_LNLcWNk_pt3Xpz2bf=P1z3ws4TBnYVfb4-V8oS9hg@mail.gmail.com>
References: <CANqqF0qJ_LNLcWNk_pt3Xpz2bf=P1z3ws4TBnYVfb4-V8oS9hg@mail.gmail.com>
Message-ID: <6388ee6b-dcf7-a67b-73ee-ce47db7a61dc@measurement-factory.com>

On 7/23/20 9:22 AM, Ryan Le wrote:
> I have been trying to configure squid to decode and send multipart form
> data to another service. Is there an acl or build parameter needed for
> multipart form data support?

No, there is no need to allow any specific Content-Type, including
multipart. Squid does not know anything about multipart/form-data. If a
multipart/form-data message is well-formed from HTTP point of view, then
Squid will process it as any other message, including passing it to
ICAP/eCAP (where configured).

Cheers,

Alex.


From service.mv at gmail.com  Thu Jul 23 15:36:07 2020
From: service.mv at gmail.com (Service MV)
Date: Thu, 23 Jul 2020 12:36:07 -0300
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
	authentication
Message-ID: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>

Hi, everybody.
I have a SQUID 4.11 compiled on Debian 9.8 with kerberos integration
authenticating and browsing without problems:
cache.log
squid_kerb_auth: User some.user authenticated
access.log
10.10.10.203 TCP_TUNNEL/200 5264 CONNECT update.googleapis.com:443
some.user HIER_DIRECT/172.217.162.3 -

The problem starts when I try to configure a HAProxy 1.8 load balancer to
which by redundancy I configured a virtual IP with the keepalived service.
When I point my browser to the DNS A record (balancer.mydomain.local) which
in turn points to the keepalived virtual IP, the authentication stops
working:
cache.log
no records
access.log
10.10.8.207 TCP_DENIED/407 4142 CONNECT update.googleapis.com:443 -
HIER_NONE/- text/

In the client browser a prompt appears requesting authentication.

I find it strange that the IP registered by SQUID is 10.10.8.207, which is
the physical IP of my VM, instead of the virtual IP configured in HAProxy,
which is the IP 10.10.8.213.

I send you all the configurations that I have made to see if you can help
me to find where my configuration error is.

keepalived.conf
  global_defs {
     notification_email {
       some.user at mydomain.local
     }
     notification_email_from balancer1 at mydomain.local
     smtp_server smtp. mydomain.local
     smtp_connect_timeout 60
  }

  vrrp_instance VI_1 {
      state MASTER
      interface eth0
      virtual_router_id 101
      priority 101
      advert_int 1
      authentication {
          auth_type PASS
          auth_pass somepass123
      }
      virtual_ipaddress {
          10.10.8.213
      }
  }


haproxy.conf
global
log /dev/log local0
log /dev/log local1 notice
chroot /var/lib/haproxy
stats socket /run/haproxy/admin.sock mode 660 level admin
stats timeout 30s
user haproxy
group haproxy
daemon
maxconn 4000
ca-base /etc/ssl/certs
crt-base /etc/ssl/private
server=haproxy
ssl-default-bind-ciphers
ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS
ssl-default-bind-options no-sslv3

defaults
balance source
log global
mode http
option httplog
option dontlognull
option http-server-close
option forwardfor except 127.0.0.0/8
timeout connect 5000
timeout client 50000
timeout server 50000

errorfile 400 /etc/haproxy/errors/400.http
errorfile 403 /etc/haproxy/errors/403.http
errorfile 408 /etc/haproxy/errors/408.http
errorfile 500 /etc/haproxy/errors/500.http
errorfile 502 /etc/haproxy/errors/502.http
errorfile 503 /etc/haproxy/errors/503.http
errorfile 504 /etc/haproxy/errors/504.http

### statistics
listen stats
bind 10.10.8.213:1936
mode http
stats enable
stats hide-version
stats realm Haproxy\ Statistics
stats uri /haproxy?stats
stats auth haproxy:somepass123

### balancer
listen squid
bind 10.10.8.213:3128
  mode http
  option httplog
  balance source
  hash-type consistent
  option httpclose
  cookie SERVERID insert indirect nocache
  option forwardfor header X-Client
  server proxy1 10.10.8.205:3128 check inter 2000 rise 2 fall 5
  server proxy2 10.10.8.206:3128 check inter 2000 rise 2 fall 5


squid.conf
# minimal configuration for testing
visible_hostname proxy1.mydomain.local
http_port 3128
debug_options ALL, 1 33, 2 28, 9
maximum_object_size 8192 KB
error_directory /opt/squid411/share/errors/es-ar
shutdown_lifetime 0 seconds
forwarded_for on
auth_param negotiate program /usr/local/bin/squid_kerb_auth -i -r -s
GSS_C_NO_NAME
auth_param negotiate children 300 startup=150 idle=10
auth_param negotiate keep_alive on
acl auth proxy_auth REQUIRED
http_access allow auth
acl SSL_ports port 443
acl Safe_ports port 80
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny all


squid -v
Squid Cache: Version 4.11
Service Name: squid

This binary uses OpenSSL 1.0.2u  20 Dec 2019. For legal restrictions on
distribution see https://www.openssl.org/source/license.html

configure options:  '--prefix=/opt/squid411' '--includedir=/include'
'--mandir=/share/man' '--infodir=/share/info'
'--localstatedir=/opt/squid411/var' '--disable-maintainer-mode'
'--disable-dependency-tracking' '--disable-silent-rules' '--enable-inline'
'--enable-async-io' '--enable-storeio=ufs,aufs,diskd'
'--enable-removal-policies=lru,heap' '--enable-delay-pools'
'--enable-cache-digests' '--enable-underscores' '--enable-icap-client'
'--enable-follow-x-forwarded-for' '--enable-auth'
'--enable-digest-auth-helpers' '--enable-negotiate-auth-helpers'
'--enable-auth-ntlm' '--enable-arp-acl' '--enable-esi--disable-translation'
'--with-logdir=/var/log/squid411' '--with-pidfile=/var/run/squid411.pid'
'--with-filedescriptors=65536' '--with-large-files'
'--with-default-user=proxy' '--enable-linux-netfilter'
'--enable-ltdl-convenience' '--with-openssl' '--enable-ssl'
'--enable-ssl-crtd'


env
KRB5_KTNAME=/opt/squid411/etc/PROXY.keytab
KRB5RCACHETYPE=none


/etc/krb5.conf
[libdefaults]
    default_realm = MYDOMAIN.LOCAL
    dns_lookup_kdc = yes
    dns_lookup_realm = yes
    ticket_lifetime = 24h

        default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5
        default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5
        permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5

[realms]
    MYDOMAIN.LOCAL = {
        kdc = s-dc00.mydomain.local
        kdc = s-dc01.mydomain.local
        kdc = s-dc02.mydomain.local
        admin_server = s-dc00.mydomain.local
    }

[domain_realm]
    .mydomain.local = MYDOMAIN.LOCAL
    mydomain.local = MYDOMAIN.LOCAL


msktutil -c -b "OU=SERVIDORES" -s HTTP/debian-proxy.mydomain.local -k
/opt/squid411/etc/PROXY.keytab --computer-name DEBIAN-PROXY --upn
HTTP/debian-proxy.mydomain.local --server s-dc00.mydomain.local --verbose
--enctypes 28


# permissions for kaytab file
chgrp proxy /opt/squid411/etc/PROXY.keytab
chmod g+r /opt/squid411/etc/PROXY.keytab


klist
Ticket cache: FILE:/tmp/krb5cc_0
Default principal: some.user at MYDOMAIN.LOCAL

Valid starting       Expires              Service principal
07/23/2020 11:59:45  07/23/2020 21:59:45
 krbtgt/MYDOMAIN.LOCAL at MYDOMAIN.LOCAL
        renew until 07/24/2020 11:59:40


One thing I didn't quite understand is the procedure to authenticate from
HAProxy. According to the documentation I read, I did the following:

I created a DNS A record and its PTR in my DNS server pointing to the
virtual IP of the keepalived (10.10.8.213) in the HAProxy.
Then I created a "HTTP_inet" user account in Active Directory.
Then on my domain controller, in a CMD with administrator permissions, I
ran:
setspn -S HTTP/inet.mydomain.local HTTP_inet
setspn -S HTTP/inet HTTP_inet
In both cases the message was: object updated.
Then in my SQUID servers, I executed:
kinit HTTP_inet at MYDOMAIN.LOCAL
It asks for the user's password.
Start the ktutil tool
That's where I write:
addent -password -p HTTP/inet.mydomain.local -k 2 -e rc4-hmac
Ask the user password
addent -password -p HTTP/inet -k 2 -e rc4-hmac
Ask the user password
wkt /opt/squid411/etc/PROXY.keytab
quit

list the keys in keytab:
ktutil
read_kt /opt/squid411/etc/PROXY.keytab
   1 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
   2 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
   3 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
   4 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
   5 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
   6 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
   7 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
   8 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
   9 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
  10 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
  11 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
  12 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
  13 2 HTTP/inet.mydomain.local at MYDOMAIN.LOCAL
  14 2 HTTP/inet at MYDOMAIN.LOCAL

It's this last part I understand the least, maybe the mistake is there. Or
somewhere else.
I appreciate any help you can offer me.

Best regards,

Gabriel
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200723/5c2ed207/attachment.htm>

From ryanlele264 at gmail.com  Thu Jul 23 15:46:59 2020
From: ryanlele264 at gmail.com (Ryan Le)
Date: Thu, 23 Jul 2020 11:46:59 -0400
Subject: [squid-users] Squid and multipart form decode
In-Reply-To: <6388ee6b-dcf7-a67b-73ee-ce47db7a61dc@measurement-factory.com>
References: <CANqqF0qJ_LNLcWNk_pt3Xpz2bf=P1z3ws4TBnYVfb4-V8oS9hg@mail.gmail.com>
 <6388ee6b-dcf7-a67b-73ee-ce47db7a61dc@measurement-factory.com>
Message-ID: <CANqqF0pBoEyZrsZLXSMgVMtnFxQBDLiogBKgMky1meRBEiysDg@mail.gmail.com>

Thanks,

I have been looking at the squid debug and can see that it is getting the
multipart.

POST http://bbbbbb.com
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:78.0)
Gecko/20100101 Firefox/78.0
Accept: application/json
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
Referer: http://bbbbb.com
Cache-Control: no-cache
X-Requested-With: XMLHttpRequest
Content-Type: multipart/form-data;
boundary=---------------------------328901485836611227811186534509
Content-Length: 1245
Origin: http://bbbbb.com
Cookie: cookie
Host: bbbbbbb.com
Via: ICAP/1.0

4dd
-----------------------------328901485836611227811186534509
Content-Disposition: form-data; name="action"

frm_submit_dropzone
-----------------------------328901485836611227811186534509
Content-Disposition: form-data; name="field_id"

8
-----------------------------328901485836611227811186534509
Content-Disposition: form-data; name="form_id"

5
-----------------------------328901485836611227811186534509
Content-Disposition: form-data; name="nonce"

e1aca92777
-----------------------------328901485836611227811186534509
Content-Disposition: form-data; name="file8"; filename="translate.zip"
Content-Type: application/x-zip-compressed

On Thu, Jul 23, 2020 at 11:16 AM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 7/23/20 9:22 AM, Ryan Le wrote:
> > I have been trying to configure squid to decode and send multipart form
> > data to another service. Is there an acl or build parameter needed for
> > multipart form data support?
>
> No, there is no need to allow any specific Content-Type, including
> multipart. Squid does not know anything about multipart/form-data. If a
> multipart/form-data message is well-formed from HTTP point of view, then
> Squid will process it as any other message, including passing it to
> ICAP/eCAP (where configured).
>
> Cheers,
>
> Alex.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200723/88af5f07/attachment.htm>

From klaus_brandl at genua.de  Thu Jul 23 16:07:39 2020
From: klaus_brandl at genua.de (Klaus Brandl)
Date: Thu, 23 Jul 2020 18:07:39 +0200
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
 authentication
In-Reply-To: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
References: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
Message-ID: <5815088.fB3ryEAXG5@cairon>

Hi Gabriel,

same problem here on our HA systems.
I think, this is caused by kerberos overall, the tickets are always bound to 
the hosts realname and address, look at "klist" on your client, and only 
exactly this name could be used as proxy entry.

But if anyone knows a solution, i will spread my ears :)

Klaus

---

genua GmbH
Domagkstrasse 7, 85551 Kirchheim bei Muenchen
tel +49 89 991950-0, fax -999, www.genua.de

Geschaeftsfuehrer: Matthias Ochs, Marc Tesch
Amtsgericht Muenchen HRB 98238
genua ist ein Unternehmen der Bundesdruckerei-Gruppe.


From service.mv at gmail.com  Thu Jul 23 17:09:51 2020
From: service.mv at gmail.com (Service MV)
Date: Thu, 23 Jul 2020 14:09:51 -0300
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
	authentication
In-Reply-To: <5815088.fB3ryEAXG5@cairon>
References: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
 <5815088.fB3ryEAXG5@cairon>
Message-ID: <CA+d==oGmKBxTvAKxDLA5rC+0p5sc1qMHVH9D2s6Dfc8W=wiAgg@mail.gmail.com>

Hi Klaus,
I think something similar. But I understand that you can use the Kerberos
delegation in AD. That's partly why I'm not convinced by the documentation
I read, which tells me to create a user account in Active Directory. And I
don't understand what a user account has to do here. Maybe the
documentation is wrong and actually refers to a computer account, and the
operation of adding a Service Principal Name should be done to the computer
object. I don't know. But I'm going to try to do it and see what I can
achieve.

I'll be back.

El jue., 23 de jul. de 2020 a la(s) 13:16, Klaus Brandl (
klaus_brandl at genua.de) escribi?:

> Hi Gabriel,
>
> same problem here on our HA systems.
> I think, this is caused by kerberos overall, the tickets are always bound
> to
> the hosts realname and address, look at "klist" on your client, and only
> exactly this name could be used as proxy entry.
>
> But if anyone knows a solution, i will spread my ears :)
>
> Klaus
>
> ---
>
> genua GmbH
> Domagkstrasse 7, 85551 Kirchheim bei Muenchen
> tel +49 89 991950-0, fax -999, www.genua.de
>
> Geschaeftsfuehrer: Matthias Ochs, Marc Tesch
> Amtsgericht Muenchen HRB 98238
> genua ist ein Unternehmen der Bundesdruckerei-Gruppe.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200723/bd33c997/attachment.htm>

From brett.lymn at baesystems.com  Fri Jul 24 00:23:03 2020
From: brett.lymn at baesystems.com (Brett Lymn)
Date: Fri, 24 Jul 2020 09:53:03 +0930
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
 authentication
In-Reply-To: <5815088.fB3ryEAXG5@cairon>
References: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
 <5815088.fB3ryEAXG5@cairon>
Message-ID: <20200724002303.GA3183@baea.com.au>

On Thu, Jul 23, 2020 at 06:07:39PM +0200, Klaus Brandl wrote:
> 
> But if anyone knows a solution, i will spread my ears :)
> 

What we do is:

1) create a user account in AD that will be used for the HA front end,
set a password and export the keytab for this user
2) Use ktadmin to import the keytab entries for the user created in step
1 into the keytab for squid on the squid servers.
3) Set a SPN (setspn) in AD that maps HTTP://ha.fqdn.address to the user
created in 1

The SPN (service principal name) tells kerberos to use the user details
set up in step 1 to authenticate http requests.  This works for us, has
been for years.

One thing, if you want to know the IP addresses of your clients in the
squid logs you will need to do some extra stuff because all accesses
will appear to come from the HA loadbalancer.  We have configured our
load balancers to insert the X-Forwarded-For header into the http
traffic and then modified the logging to log both the loadblancer and
client IP.

-- 
Brett Lymn
This email has been sent on behalf of one of the following companies within the BAE Systems Australia group of companies:

BAE Systems Australia Limited - Australian Company Number 008 423 005
BAE Systems Australia Defence Pty Limited - Australian Company Number 006 870 846
ASC Shipbuilding Pty Limited - Australian Company Number 051 899 864

BAE Systems Australia's registered office is Evans Building, Taranaki Road, Edinburgh Parks, Edindurgh, South Australia, 5111.
ASC Shipbuilding's registered office is Level 2, 80 Flinders Street, Adelaide, South Australia, 5000.
If the identity of the sending company is not clear from the content of this email, please contact the sender.

This email and any attachments may contain confidential and legally privileged information. If you are not the intended recipient, do not copy or disclose its content, but please reply to this email immediately and highlight the error to the sender and then immediately delete the message.



From squid3 at treenet.co.nz  Fri Jul 24 03:06:18 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 24 Jul 2020 15:06:18 +1200
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
 authentication
In-Reply-To: <CA+d==oGmKBxTvAKxDLA5rC+0p5sc1qMHVH9D2s6Dfc8W=wiAgg@mail.gmail.com>
References: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
 <5815088.fB3ryEAXG5@cairon>
 <CA+d==oGmKBxTvAKxDLA5rC+0p5sc1qMHVH9D2s6Dfc8W=wiAgg@mail.gmail.com>
Message-ID: <6f4e066f-f95c-c1e8-bfe8-29a106d3d7a8@treenet.co.nz>

On 24/07/20 5:09 am, Service MV wrote:
> Hi Klaus,
> I think something similar. But I understand that you can use the
> Kerberos delegation in AD. That's partly why I'm not convinced by the
> documentation I read, which tells me to create a user account in Active
> Directory. And I don't understand what a user account has to do here.
> Maybe the documentation is wrong and actually refers to a computer
> account, and the operation of adding a Service Principal Name should be
> done to the computer object. I don't know. But I'm going to try to do it
> and see what I can achieve.
> 

Kerberos authentication in HTTP uses the Negotiate scheme. The model for
that scheme is that it authenticates the exact TCP connection over which
the credentials are transmitted.

So for it to work *through* a proxy (eg HAProxy) that proxy must ensure
the *two* TCP connections it is handling (from-client and to-Squid) are
pinned together with all HTTP multiplexing features disabled _and_ the
Proxy-Auth* headers are not touched or used along the way.

 => If either of those conditions is broken the auth will not work and
users will definitely get the behaviour you are seeing. That behaviour
may also occur anyway if later stages are broken - this is just the
first and most non-obvious problem for beginners.


[ below is simplified a bit/lot to ensure you have the basic
understanding. There is a steep learning curve for Kerberos tools and
one needs basics before troubleshooting exposes the gory details ]

The HTTP agent which is doing the Kerberos auth validation (eg Squid)
must be configured with an account that can perform authentication tasks
with the central domain server.
 This can be either User or Machine account as you know. The important
difference is their policy on passwords. User accounts need password
rotation, machines are effectively permanent. Since keytab used by Squid
has to be re-generated every time the account password changes User
accounts are naturally far more complex to administrate for reliable auth.

 => So ... your choice and YMMV. But we recommend a machine account
unless you have reason to go the more complex way.


At the other end the client software needs a keytab with a "Principal"
name telling it what to request from the central domain server when it
needs a token that Squid can validate.

 => The principal name has to match up with the account details used by
the proxy which is checking the auth credentials. This is why the middle
proxy (eg HAProxy) cannot touch the authentication on its way to Squid.

 => The principal name is also case-sensitive and and must survive
*exact* string comparisons despite DNS resolve being involved [ because
reasons :( ].  So be sure to use full FQDN rather than host name
abbreviations.



> I'll be back.
> 
> El jue., 23 de jul. de 2020 a la(s) 13:16, Klaus Brandl escribi?:
> 
>     Hi Gabriel,
> 
>     same problem here on our HA systems.
>     I think, this is caused by kerberos overall, the tickets are always
>     bound to
>     the hosts realname and address, look at "klist" on your client, and
>     only
>     exactly this name could be used as proxy entry.


Indeed. Use of wrong names (eg not using the full FQDN), wrong case, or
the hostnames not being DNS resolvable are common causes of Kerberos not
working.


Amos



From elsaesser at animate.de  Fri Jul 24 07:06:43 2020
From: elsaesser at animate.de (Thomas Elsaesser)
Date: Fri, 24 Jul 2020 09:06:43 +0200
Subject: [squid-users] squid4.12 access_log
Message-ID: <3ce5a2b58f878a233f6c84fd5025460b@animate.de>

Dear all,

my squid server are behind  HW loadbalancer. This make TCP  Healthchecks 
on squid port.
Now(after update from squid 3 to 4) i have in the log massive  messages: 
how can i discard this messages from this two LB ip's?

acl noTransactionError src 10.XX.XX.XX 10.XX.XX.XX
access_log              /var/log/squid4/access.log combined  
!noTransactionError


not working .

Many thanks.

Thomas

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x49FCC5E8.asc
Type: application/pgp-keys
Size: 3847 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200724/422a81dd/attachment.key>

From klaus_brandl at genua.de  Fri Jul 24 08:44:34 2020
From: klaus_brandl at genua.de (Klaus Brandl)
Date: Fri, 24 Jul 2020 10:44:34 +0200
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
 authentication
In-Reply-To: <20200724002303.GA3183@baea.com.au>
References: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
 <5815088.fB3ryEAXG5@cairon> <20200724002303.GA3183@baea.com.au>
Message-ID: <5284125.Xo1gdhAW2t@cairon>

Hi Brett,

but then you have a single point of failure, if your loadbalancer is down, 
nothing will work. We need a solution, that each system can work by itself. So 
at the moment we merge the keytabs of each system together, and we are able to 
takeover the addresses of the other systems. Then we have no loadbalancing, 
but a fallback solution, what is more important on our systems.

On Friday 24 July 2020 09:53:03 Brett Lymn wrote:
> On Thu, Jul 23, 2020 at 06:07:39PM +0200, Klaus Brandl wrote:
> > But if anyone knows a solution, i will spread my ears :)
> 
> What we do is:
> 
> 1) create a user account in AD that will be used for the HA front end,
> set a password and export the keytab for this user
> 2) Use ktadmin to import the keytab entries for the user created in step
> 1 into the keytab for squid on the squid servers.
> 3) Set a SPN (setspn) in AD that maps HTTP://ha.fqdn.address to the user
> created in 1
> 
> The SPN (service principal name) tells kerberos to use the user details
> set up in step 1 to authenticate http requests.  This works for us, has
> been for years.
> 
> One thing, if you want to know the IP addresses of your clients in the
> squid logs you will need to do some extra stuff because all accesses
> will appear to come from the HA loadbalancer.  We have configured our
> load balancers to insert the X-Forwarded-For header into the http
> traffic and then modified the logging to log both the loadblancer and
> client IP.

Klaus

---

genua GmbH
Domagkstrasse 7, 85551 Kirchheim bei Muenchen
tel +49 89 991950-0, fax -999, www.genua.de

Geschaeftsfuehrer: Matthias Ochs, Marc Tesch
Amtsgericht Muenchen HRB 98238
genua ist ein Unternehmen der Bundesdruckerei-Gruppe.


From belle at bazuin.nl  Fri Jul 24 08:46:09 2020
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Fri, 24 Jul 2020 10:46:09 +0200
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
 authentication
In-Reply-To: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
References: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
Message-ID: <vmime.5f1a9fd1.21b1.710fb8b73f27f661@ms249-lin-003.rotterdam.bazuin.nl>

i would recommend to ..
1) use debian buster,
2) use squid 4.12
3) use samba (winbind). 
?
needed??in smb.conf ( only shown whats really needed ), there is more offcourse. 

??? dedicated keytab file = /etc/krb5.keytab
??? kerberos method = secrets and keytab
?
??? # renew the kerberos ticket
??? winbind refresh tickets = yes

??? # Added for freeradius support
????#ntlm auth = mschapv2-and-ntlmv2-only


apt install winbind krb5-user?should be sufficient. 

samba joins the domain. 
/etc/krb5.keytab contains the default part and refreshed the server kerberos passworks/tickes. 

And for squid its keytab. 

kinit Administrator
export KRB5_KTNAME=FILE:/etc/squid/HTTP-$(hostname -s).keytab
net ads keytab add_update_ads?HTTP/$(hostname -f) -U Administrator

# alias name to keytab
net ads keytab ADD HTTP/CNAME.FQDN?

# check keytab file.
klist -ke /etc/squid/HTTP-$(hostname -s).keytab
unset KRB5_KTNAME

# set rights.
chgrp proxy /etc/squid/HTTP-$(hostname -s).keytab
chmod g+r /etc/squid/HTTP-$(hostname -s).keytab

And i use? in squid 
auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \
??? --kerberos /usr/lib/squid/negotiate_kerberos_auth -k /etc/squid/HTTP-hostname.keytab \
??? -s HTTP/hostname.fqdn at REALM?-s HTTP/CNAME.FQDN at REALM 
??? --ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOM 

Point to think about. 


server IP's needs?A + PTR?
use CNAMEs in the DNS. 
and make sure the resolving is setup correctly. 

Add a caching DNS to the proxy. ( and let squid use it also ) 

I had this working (without HAproxy) but with keepalived. 

As far i can tel, your problem is in how the hostnames and ip are used.?
but above might give you ideas. 


Greetz, 


Louis


?

Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Service MV
Verzonden: donderdag 23 juli 2020 17:36
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos authentication



Hi, everybody.
I have a SQUID 4.11 compiled on Debian 9.8 with kerberos integration authenticating and browsing without problems:
cache.log
squid_kerb_auth: User some.user authenticated
access.log
10.10.10.203 TCP_TUNNEL/200 5264 CONNECT update.googleapis.com:443 some.user HIER_DIRECT/MailScanner warning: numerical links are often malicious: 172.217.162.3 -

The problem starts when I try to configure a HAProxy 1.8 load balancer to which by redundancy I configured a virtual IP with the keepalived service. When I point my browser to the DNS A record (balancer.mydomain.local) which in turn points to the keepalived virtual IP, the authentication stops working:
cache.log no records
access.log
10.10.8.207 TCP_DENIED/407 4142 CONNECT update.googleapis.com:443 - HIER_NONE/- text/


In the client browser a prompt appears requesting authentication.

I find it strange that the IP registered by SQUID is 10.10.8.207, which is the physical IP of my VM, instead of the virtual IP configured in HAProxy, which is the IP 10.10.8.213.

I send you all the configurations that I have made to see if you can help me to find where my configuration error is.

keepalived.conf ? global_defs {
? ? ?notification_email {
? ? ? ?some.user at mydomain.local
? ? ?}
? ? ?notification_email_from balancer1 at mydomain.local
? ? ?smtp_server smtp. mydomain.local 
? ? ?smtp_connect_timeout 60
? }

? vrrp_instance VI_1 {
? ? ? state MASTER
? ? ? interface eth0
? ? ? virtual_router_id 101
? ? ? priority 101
? ? ? advert_int 1
? ? ? authentication {
? ? ? ? ? auth_type PASS
? ? ? ? ? auth_pass somepass123
? ? ? }
? ? ? virtual_ipaddress {
? ? ? ? ? 10.10.8.213
? ? ? }
? }




haproxy.conf
global
log /dev/log local0
log /dev/log local1 notice
chroot /var/lib/haproxy
stats socket /run/haproxy/admin.sock mode 660 level admin
stats timeout 30s
user haproxy
group haproxy
daemon
maxconn 4000
ca-base /etc/ssl/certs
crt-base /etc/ssl/private
server=haproxy
ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS
ssl-default-bind-options no-sslv3

defaults
balance source
log global
mode http
option httplog
option dontlognull
option http-server-close
option forwardfor except MailScanner warning: numerical links are often malicious: 127.0.0.0/8
timeout connect 5000
timeout client 50000
timeout server 50000

errorfile 400 /etc/haproxy/errors/400.http
errorfile 403 /etc/haproxy/errors/403.http
errorfile 408 /etc/haproxy/errors/408.http
errorfile 500 /etc/haproxy/errors/500.http
errorfile 502 /etc/haproxy/errors/502.http
errorfile 503 /etc/haproxy/errors/503.http
errorfile 504 /etc/haproxy/errors/504.http

### statistics
listen stats
bind MailScanner warning: numerical links are often malicious: 10.10.8.213:1936
mode http
stats enable
stats hide-version
stats realm Haproxy\ Statistics
stats uri /haproxy?stats
stats auth haproxy:somepass123

### balancer
listen squid
bind MailScanner warning: numerical links are often malicious: 10.10.8.213:3128
? mode http
? option httplog
? balance source
? hash-type consistent
? option httpclose
? cookie SERVERID insert indirect nocache
? option forwardfor header X-Client
? server proxy1 MailScanner warning: numerical links are often malicious: 10.10.8.205:3128 check inter 2000 rise 2 fall 5

? server proxy2 MailScanner warning: numerical links are often malicious: 10.10.8.206:3128 check inter 2000 rise 2 fall 5







squid.conf
# minimal configuration for testing
visible_hostname proxy1.mydomain.local
http_port 3128
debug_options ALL, 1 33, 2 28, 9
maximum_object_size 8192 KB
error_directory /opt/squid411/share/errors/es-ar
shutdown_lifetime 0 seconds
forwarded_for on
auth_param negotiate program /usr/local/bin/squid_kerb_auth -i -r -s GSS_C_NO_NAME
auth_param negotiate children 300 startup=150 idle=10
auth_param negotiate keep_alive on
acl auth proxy_auth REQUIRED
http_access allow auth
acl SSL_ports port 443
acl Safe_ports port 80
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny all





squid -v
Squid Cache: Version 4.11
Service Name: squid

This binary uses OpenSSL 1.0.2u ?20 Dec 2019. For legal restrictions on distribution see https://www.openssl.org/source/license.html

configure options: ?'--prefix=/opt/squid411' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--localstatedir=/opt/squid411/var' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--enable-inline' '--enable-async-io' '--enable-storeio=ufs,aufs,diskd' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-digest-auth-helpers' '--enable-negotiate-auth-helpers' '--enable-auth-ntlm' '--enable-arp-acl' '--enable-esi--disable-translation' '--with-logdir=/var/log/squid411' '--with-pidfile=/var/run/squid411.pid' '--with-filedescriptors=65536' '--with-large-files' '--with-default-user=proxy' '--enable-linux-netfilter' '--enable-ltdl-convenience' '--with-openssl' '--enable-ssl' '--enable-ssl-crtd'





env
KRB5_KTNAME=/opt/squid411/etc/PROXY.keytab
KRB5RCACHETYPE=none





/etc/krb5.conf
[libdefaults]
? ? default_realm = MYDOMAIN.LOCAL
? ? dns_lookup_kdc = yes
? ? dns_lookup_realm = yes 
? ? ticket_lifetime = 24h

? ? ? ? default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5
? ? ? ? default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5
? ? ? ? permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5

[realms]
? ? MYDOMAIN.LOCAL = {
? ? ? ? kdc = s-dc00.mydomain.local
? ? ? ? kdc = s-dc01.mydomain.local
? ? ? ? kdc = s-dc02.mydomain.local
? ? ? ? admin_server = s-dc00.mydomain.local
? ? }

[domain_realm]
? ? .mydomain.local = MYDOMAIN.LOCAL
? ? mydomain.local = MYDOMAIN.LOCAL





msktutil -c -b "OU=SERVIDORES" -s HTTP/debian-proxy.mydomain.local -k /opt/squid411/etc/PROXY.keytab --computer-name DEBIAN-PROXY --upn HTTP/debian-proxy.mydomain.local --server s-dc00.mydomain.local --verbose --enctypes 28





# permissions for kaytab file
chgrp proxy /opt/squid411/etc/PROXY.keytab
chmod g+r /opt/squid411/etc/PROXY.keytab





klist
Ticket cache: FILE:/tmp/krb5cc_0
Default principal: some.user at MYDOMAIN.LOCAL

Valid starting ? ? ? Expires ? ? ? ? ? ? ?Service principal
07/23/2020 11:59:45 ?07/23/2020 21:59:45 ?krbtgt/MYDOMAIN.LOCAL at MYDOMAIN.LOCAL
? ? ? ? renew until 07/24/2020 11:59:40





One thing I didn't quite understand is the procedure to authenticate from HAProxy. According to the documentation I read, I did the following:

I created a DNS A record and its PTR in my DNS server pointing to the virtual IP of the keepalived (10.10.8.213) in the HAProxy.?
Then I created a "HTTP_inet" user account in Active Directory.
Then on my domain controller, in a CMD with administrator permissions, I ran:
setspn -S HTTP/inet.mydomain.local HTTP_inet
setspn -S HTTP/inet HTTP_inet 
In both cases the message was: object updated.
Then in my SQUID servers, I executed:
kinit HTTP_inet at MYDOMAIN.LOCAL
It asks for the user's password.
Start the ktutil tool
That's where I write:
addent -password -p HTTP/inet.mydomain.local -k 2 -e rc4-hmac
Ask the user password
addent -password -p HTTP/inet -k 2 -e rc4-hmac
Ask the user password
wkt /opt/squid411/etc/PROXY.keytab
quit

list the keys in keytab:
ktutil
read_kt /opt/squid411/etc/PROXY.keytab
? ?1 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
? ?2 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
? ?3 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
? ?4 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
? ?5 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
? ?6 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
? ?7 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
? ?8 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
? ?9 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
? 10 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
? 11 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
? 12 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
? 13 2 HTTP/inet.mydomain.local at MYDOMAIN.LOCAL
? 14 2 HTTP/inet at MYDOMAIN.LOCAL

It's this last part I understand the least, maybe the mistake is there. Or somewhere else.
I appreciate any help you can offer me. 

Best regards,

Gabriel





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200724/7434a12f/attachment.htm>

From belle at bazuin.nl  Fri Jul 24 08:52:53 2020
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Fri, 24 Jul 2020 10:52:53 +0200
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
 authentication
In-Reply-To: <vmime.5f1a9fd1.21b1.710fb8b73f27f661@ms249-lin-003.rotterdam.bazuin.nl>
References: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
Message-ID: <vmime.5f1aa165.2c44.7eb4bc368baef35@ms249-lin-003.rotterdam.bazuin.nl>

forgot 1 thing. (sorry) 
# 
adduser proxyuser winbind_priv 

or things might not work. 

?

Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens L.P.H. van Belle
Verzonden: vrijdag 24 juli 2020 10:46
Aan: squid-users at lists.squid-cache.org
Onderwerp: Re: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos authentication



i would recommend to ..
1) use debian buster,
2) use squid 4.12
3) use samba (winbind). 
?
needed??in smb.conf ( only shown whats really needed ), there is more offcourse. 

??? dedicated keytab file = /etc/krb5.keytab
??? kerberos method = secrets and keytab
?
??? # renew the kerberos ticket
??? winbind refresh tickets = yes

??? # Added for freeradius support
????#ntlm auth = mschapv2-and-ntlmv2-only


apt install winbind krb5-user?should be sufficient. 

samba joins the domain. 
/etc/krb5.keytab contains the default part and refreshed the server kerberos passworks/tickes. 

And for squid its keytab. 

kinit Administrator
export KRB5_KTNAME=FILE:/etc/squid/HTTP-$(hostname -s).keytab
net ads keytab add_update_ads?HTTP/$(hostname -f) -U Administrator

# alias name to keytab
net ads keytab ADD HTTP/CNAME.FQDN?

# check keytab file.
klist -ke /etc/squid/HTTP-$(hostname -s).keytab
unset KRB5_KTNAME

# set rights.
chgrp proxy /etc/squid/HTTP-$(hostname -s).keytab
chmod g+r /etc/squid/HTTP-$(hostname -s).keytab

And i use? in squid 
auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \
??? --kerberos /usr/lib/squid/negotiate_kerberos_auth -k /etc/squid/HTTP-hostname.keytab \
??? -s HTTP/hostname.fqdn at REALM?-s HTTP/CNAME.FQDN at REALM 
??? --ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOM 

Point to think about. 


server IP's needs?A + PTR?
use CNAMEs in the DNS. 
and make sure the resolving is setup correctly. 

Add a caching DNS to the proxy. ( and let squid use it also ) 

I had this working (without HAproxy) but with keepalived. 

As far i can tel, your problem is in how the hostnames and ip are used.?
but above might give you ideas. 


Greetz, 


Louis


?

Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Service MV
Verzonden: donderdag 23 juli 2020 17:36
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos authentication



Hi, everybody.
I have a SQUID 4.11 compiled on Debian 9.8 with kerberos integration authenticating and browsing without problems:
cache.log
squid_kerb_auth: User some.user authenticated
access.log
10.10.10.203 TCP_TUNNEL/200 5264 CONNECT update.googleapis.com:443 some.user HIER_DIRECT/MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: 172.217.162.3 -

The problem starts when I try to configure a HAProxy 1.8 load balancer to which by redundancy I configured a virtual IP with the keepalived service. When I point my browser to the DNS A record (balancer.mydomain.local) which in turn points to the keepalived virtual IP, the authentication stops working:
cache.log no records
access.log
10.10.8.207 TCP_DENIED/407 4142 CONNECT update.googleapis.com:443 - HIER_NONE/- text/


In the client browser a prompt appears requesting authentication.

I find it strange that the IP registered by SQUID is 10.10.8.207, which is the physical IP of my VM, instead of the virtual IP configured in HAProxy, which is the IP 10.10.8.213.

I send you all the configurations that I have made to see if you can help me to find where my configuration error is.

keepalived.conf ? global_defs {
? ? ?notification_email {
? ? ? ?some.user at mydomain.local
? ? ?}
? ? ?notification_email_from balancer1 at mydomain.local
? ? ?smtp_server smtp. mydomain.local 
? ? ?smtp_connect_timeout 60
? }

? vrrp_instance VI_1 {
? ? ? state MASTER
? ? ? interface eth0
? ? ? virtual_router_id 101
? ? ? priority 101
? ? ? advert_int 1
? ? ? authentication {
? ? ? ? ? auth_type PASS
? ? ? ? ? auth_pass somepass123
? ? ? }
? ? ? virtual_ipaddress {
? ? ? ? ? 10.10.8.213
? ? ? }
? }




haproxy.conf
global
log /dev/log local0
log /dev/log local1 notice
chroot /var/lib/haproxy
stats socket /run/haproxy/admin.sock mode 660 level admin
stats timeout 30s
user haproxy
group haproxy
daemon
maxconn 4000
ca-base /etc/ssl/certs
crt-base /etc/ssl/private
server=haproxy
ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS
ssl-default-bind-options no-sslv3

defaults
balance source
log global
mode http
option httplog
option dontlognull
option http-server-close
option forwardfor except MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: 127.0.0.0/8
timeout connect 5000
timeout client 50000
timeout server 50000

errorfile 400 /etc/haproxy/errors/400.http
errorfile 403 /etc/haproxy/errors/403.http
errorfile 408 /etc/haproxy/errors/408.http
errorfile 500 /etc/haproxy/errors/500.http
errorfile 502 /etc/haproxy/errors/502.http
errorfile 503 /etc/haproxy/errors/503.http
errorfile 504 /etc/haproxy/errors/504.http

### statistics
listen stats
bind MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: 10.10.8.213:1936
mode http
stats enable
stats hide-version
stats realm Haproxy\ Statistics
stats uri /haproxy?stats
stats auth haproxy:somepass123

### balancer
listen squid
bind MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: 10.10.8.213:3128
? mode http
? option httplog
? balance source
? hash-type consistent
? option httpclose
? cookie SERVERID insert indirect nocache
? option forwardfor header X-Client
? server proxy1 MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: 10.10.8.205:3128 check inter 2000 rise 2 fall 5

? server proxy2 MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: 10.10.8.206:3128 check inter 2000 rise 2 fall 5







squid.conf
# minimal configuration for testing
visible_hostname proxy1.mydomain.local
http_port 3128
debug_options ALL, 1 33, 2 28, 9
maximum_object_size 8192 KB
error_directory /opt/squid411/share/errors/es-ar
shutdown_lifetime 0 seconds
forwarded_for on
auth_param negotiate program /usr/local/bin/squid_kerb_auth -i -r -s GSS_C_NO_NAME
auth_param negotiate children 300 startup=150 idle=10
auth_param negotiate keep_alive on
acl auth proxy_auth REQUIRED
http_access allow auth
acl SSL_ports port 443
acl Safe_ports port 80
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny all





squid -v
Squid Cache: Version 4.11
Service Name: squid

This binary uses OpenSSL 1.0.2u ?20 Dec 2019. For legal restrictions on distribution see https://www.openssl.org/source/license.html

configure options: ?'--prefix=/opt/squid411' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--localstatedir=/opt/squid411/var' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--enable-inline' '--enable-async-io' '--enable-storeio=ufs,aufs,diskd' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-digest-auth-helpers' '--enable-negotiate-auth-helpers' '--enable-auth-ntlm' '--enable-arp-acl' '--enable-esi--disable-translation' '--with-logdir=/var/log/squid411' '--with-pidfile=/var/run/squid411.pid' '--with-filedescriptors=65536' '--with-large-files' '--with-default-user=proxy' '--enable-linux-netfilter' '--enable-ltdl-convenience' '--with-openssl' '--enable-ssl' '--enable-ssl-crtd'





env
KRB5_KTNAME=/opt/squid411/etc/PROXY.keytab
KRB5RCACHETYPE=none





/etc/krb5.conf
[libdefaults]
? ? default_realm = MYDOMAIN.LOCAL
? ? dns_lookup_kdc = yes
? ? dns_lookup_realm = yes 
? ? ticket_lifetime = 24h

? ? ? ? default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5
? ? ? ? default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5
? ? ? ? permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5

[realms]
? ? MYDOMAIN.LOCAL = {
? ? ? ? kdc = s-dc00.mydomain.local
? ? ? ? kdc = s-dc01.mydomain.local
? ? ? ? kdc = s-dc02.mydomain.local
? ? ? ? admin_server = s-dc00.mydomain.local
? ? }

[domain_realm]
? ? .mydomain.local = MYDOMAIN.LOCAL
? ? mydomain.local = MYDOMAIN.LOCAL





msktutil -c -b "OU=SERVIDORES" -s HTTP/debian-proxy.mydomain.local -k /opt/squid411/etc/PROXY.keytab --computer-name DEBIAN-PROXY --upn HTTP/debian-proxy.mydomain.local --server s-dc00.mydomain.local --verbose --enctypes 28





# permissions for kaytab file
chgrp proxy /opt/squid411/etc/PROXY.keytab
chmod g+r /opt/squid411/etc/PROXY.keytab





klist
Ticket cache: FILE:/tmp/krb5cc_0
Default principal: some.user at MYDOMAIN.LOCAL

Valid starting ? ? ? Expires ? ? ? ? ? ? ?Service principal
07/23/2020 11:59:45 ?07/23/2020 21:59:45 ?krbtgt/MYDOMAIN.LOCAL at MYDOMAIN.LOCAL
? ? ? ? renew until 07/24/2020 11:59:40





One thing I didn't quite understand is the procedure to authenticate from HAProxy. According to the documentation I read, I did the following:

I created a DNS A record and its PTR in my DNS server pointing to the virtual IP of the keepalived (10.10.8.213) in the HAProxy.?
Then I created a "HTTP_inet" user account in Active Directory.
Then on my domain controller, in a CMD with administrator permissions, I ran:
setspn -S HTTP/inet.mydomain.local HTTP_inet
setspn -S HTTP/inet HTTP_inet 
In both cases the message was: object updated.
Then in my SQUID servers, I executed:
kinit HTTP_inet at MYDOMAIN.LOCAL
It asks for the user's password.
Start the ktutil tool
That's where I write:
addent -password -p HTTP/inet.mydomain.local -k 2 -e rc4-hmac
Ask the user password
addent -password -p HTTP/inet -k 2 -e rc4-hmac
Ask the user password
wkt /opt/squid411/etc/PROXY.keytab
quit

list the keys in keytab:
ktutil
read_kt /opt/squid411/etc/PROXY.keytab
? ?1 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
? ?2 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
? ?3 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
? ?4 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
? ?5 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
? ?6 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
? ?7 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
? ?8 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
? ?9 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
? 10 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
? 11 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
? 12 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
? 13 2 HTTP/inet.mydomain.local at MYDOMAIN.LOCAL
? 14 2 HTTP/inet at MYDOMAIN.LOCAL

It's this last part I understand the least, maybe the mistake is there. Or somewhere else.
I appreciate any help you can offer me. 

Best regards,

Gabriel





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200724/e5ab81c9/attachment.htm>

From rafael.akchurin at diladele.com  Fri Jul 24 09:39:08 2020
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 24 Jul 2020 09:39:08 +0000
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
 authentication
In-Reply-To: <20200724002303.GA3183@baea.com.au>
References: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
 <5815088.fB3ryEAXG5@cairon> <20200724002303.GA3183@baea.com.au>
Message-ID: <AM0PR04MB4753F781987A43938D17D9FB8F770@AM0PR04MB4753.eurprd04.prod.outlook.com>

Hello Klaus, Brett, all list members,

This is the scheme with haproxy and Squid we use all the time in our test lab for Web Safety - we need to constantly add/remove test nodes to the cluster without breaking/changing anything in Kerberos settings for the constantly running client pool - https://docs.diladele.com/administrator_guide_stable/active_directory_extra/redundancy/haproxy_proxy_protocol.html

And yes we do *not* use computer account, we use *user* account instead.
See the reasoning  in the tutorial.

Best regards,
Rafael Akchurin
Diladele B.V.

  

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Brett Lymn
Sent: Friday, July 24, 2020 2:23 AM
To: Klaus Brandl <klaus_brandl at genua.de>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos authentication

On Thu, Jul 23, 2020 at 06:07:39PM +0200, Klaus Brandl wrote:
> 
> But if anyone knows a solution, i will spread my ears :)
> 

What we do is:

1) create a user account in AD that will be used for the HA front end, set a password and export the keytab for this user
2) Use ktadmin to import the keytab entries for the user created in step
1 into the keytab for squid on the squid servers.
3) Set a SPN (setspn) in AD that maps HTTP://ha.fqdn.address to the user created in 1

The SPN (service principal name) tells kerberos to use the user details set up in step 1 to authenticate http requests.  This works for us, has been for years.

One thing, if you want to know the IP addresses of your clients in the squid logs you will need to do some extra stuff because all accesses will appear to come from the HA loadbalancer.  We have configured our load balancers to insert the X-Forwarded-For header into the http traffic and then modified the logging to log both the loadblancer and client IP.

--
Brett Lymn
This email has been sent on behalf of one of the following companies within the BAE Systems Australia group of companies:

BAE Systems Australia Limited - Australian Company Number 008 423 005 BAE Systems Australia Defence Pty Limited - Australian Company Number 006 870 846 ASC Shipbuilding Pty Limited - Australian Company Number 051 899 864

BAE Systems Australia's registered office is Evans Building, Taranaki Road, Edinburgh Parks, Edindurgh, South Australia, 5111.
ASC Shipbuilding's registered office is Level 2, 80 Flinders Street, Adelaide, South Australia, 5000.
If the identity of the sending company is not clear from the content of this email, please contact the sender.

This email and any attachments may contain confidential and legally privileged information. If you are not the intended recipient, do not copy or disclose its content, but please reply to this email immediately and highlight the error to the sender and then immediately delete the message.

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From rafael.akchurin at diladele.com  Fri Jul 24 09:44:48 2020
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 24 Jul 2020 09:44:48 +0000
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
 authentication
In-Reply-To: <5284125.Xo1gdhAW2t@cairon>
References: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
 <5815088.fB3ryEAXG5@cairon> <20200724002303.GA3183@baea.com.au>
 <5284125.Xo1gdhAW2t@cairon>
Message-ID: <AM0PR04MB475399C21B6BFEDDB8F155008F770@AM0PR04MB4753.eurprd04.prod.outlook.com>

Sorry forgot to add to Amos'es answer - use haproxy to handle *tcp* connections and let the sslbump/authentication run on the cluster of squids - thus you would get working auth on squid side and use keepalived/haproxy on the client side.

I do not see any reason why it cannot work unless you specifically desire to use some haproxy's features for l7 loadbalancing.

Best regards,
Rafael Akchurin
Diladele B.V.

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Klaus Brandl
Sent: Friday, July 24, 2020 10:45 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos authentication

Hi Brett,

but then you have a single point of failure, if your loadbalancer is down, 
nothing will work. We need a solution, that each system can work by itself. So 
at the moment we merge the keytabs of each system together, and we are able to 
takeover the addresses of the other systems. Then we have no loadbalancing, 
but a fallback solution, what is more important on our systems.

On Friday 24 July 2020 09:53:03 Brett Lymn wrote:
> On Thu, Jul 23, 2020 at 06:07:39PM +0200, Klaus Brandl wrote:
> > But if anyone knows a solution, i will spread my ears :)
> 
> What we do is:
> 
> 1) create a user account in AD that will be used for the HA front end,
> set a password and export the keytab for this user
> 2) Use ktadmin to import the keytab entries for the user created in step
> 1 into the keytab for squid on the squid servers.
> 3) Set a SPN (setspn) in AD that maps HTTP://ha.fqdn.address to the user
> created in 1
> 
> The SPN (service principal name) tells kerberos to use the user details
> set up in step 1 to authenticate http requests.  This works for us, has
> been for years.
> 
> One thing, if you want to know the IP addresses of your clients in the
> squid logs you will need to do some extra stuff because all accesses
> will appear to come from the HA loadbalancer.  We have configured our
> load balancers to insert the X-Forwarded-For header into the http
> traffic and then modified the logging to log both the loadblancer and
> client IP.

Klaus

---

genua GmbH
Domagkstrasse 7, 85551 Kirchheim bei Muenchen
tel +49 89 991950-0, fax -999, www.genua.de

Geschaeftsfuehrer: Matthias Ochs, Marc Tesch
Amtsgericht Muenchen HRB 98238
genua ist ein Unternehmen der Bundesdruckerei-Gruppe.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From belle at bazuin.nl  Fri Jul 24 10:31:31 2020
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Fri, 24 Jul 2020 12:31:31 +0200
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
 authentication
In-Reply-To: <AM0PR04MB4753F781987A43938D17D9FB8F770@AM0PR04MB4753.eurprd04.prod.outlook.com>
References: <20200724002303.GA3183@baea.com.au>
Message-ID: <vmime.5f1ab883.6cc6.6e8b99518efe533@ms249-lin-003.rotterdam.bazuin.nl>

Hai Rafael,

First, thank you for maintaining diladele, each time i read them,
i learned something :-) As usual, your manuals look great. 

I have a few suggestion if i may point these out, just small update for the site. 

https://docs.diladele.com/administrator_guide_stable/active_directory/kerberos/keytab.html
This part, The krb5.conf should be updated it with. 

; for Windows 2008+ with AES support ( you might want to remove rc4 and des, its there for compatibility)
    default_tgs_enctypes = aes128-cts-hmac-sha1-96 aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5
    default_tkt_enctypes = aes128-cts-hmac-sha1-96 aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5
    permitted_enctypes = aes128-cts-hmac-sha1-96 aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5


https://docs.diladele.com/administrator_guide_stable/active_directory/create_user/index.html
/quote: 
Some tutorials describing integration of Squid with Active Directory rely on creating special computer account in AD for the same goal. Unfortunately it ties the proxy machine to Active Directory and prevents us from making and restoring VM snapshots because the restored snapshot loses the AD join state and needs to be rejoined manually.
/quote.

Well, all i can say here is, this works fine for me, but i understand where its coming from. 
As your pointing out, yes, i did use a "user" account also in the past.
But if samba/winbind is setup correcty with its hostName, and you use CNAMES for the proxy it's serviceName, 
after a backup/restore of a VM and samba/winbind starts, winbind handles the "computername" keytab and its password.
Squid has its own keytab file and CNAME and is untouched. 

Resulting in, you can restore a VM. I do this on XenServers, i suggest, give it a try. 
But note, i dont have HAProxy running (yet), so i cant say anyting about that part,
The logical parts should be the same (hostname A - PTR and CNAMES for serices) 

The COMPUTER needs A and PTR (this is the real hostname) 
Now you can setup any CNAME SPN for the proxy it's "ServiceName" 
You can use or the computer account or a separated account for the Squid CNAME-ed SPN's. 
Als long these are somewhere to findable in AD. 

You might want to test this, this setup removed the need of ktpass in windows, 
which was always giving problems at my side. 

And last, if winbind is use and you want to add a automounted homedir with NFS or CIFS.
Then half of the work is already done. 
It basicly only needs : nfs-common nfs4-acl-tools 
And : 
net ads keytab add_update_ads nfs/$(hostname -f) -U Administrator
And/or 
net ads keytab add_update_ads cifs/$(hostname -f) -U Administrator

In the Haproxy setup, well, thats next on my list, 
i saw something i liked and dont have it running yet.  
Learning a lot here. :-) 

Main difference between your setups, i dont have any windows servers. 
I running fully on Samba AD-DC's and member servers and my client PC's are windows 10. 

I hope I could give you someone ideas here and people can use them. 
If you have questions, just ask. 


Greetz, 

Louis



> -----Oorspronkelijk bericht-----
> Van: squid-users 
> [mailto:squid-users-bounces at lists.squid-cache.org] Namens 
> Rafael Akchurin
> Verzonden: vrijdag 24 juli 2020 11:39
> Aan: Brett Lymn; Klaus Brandl
> CC: squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] Problem with HAProxy + Squid 
> 4.11 + Kerberos authentication
> 
> Hello Klaus, Brett, all list members,
> 
> This is the scheme with haproxy and Squid we use all the time 
> in our test lab for Web Safety - we need to constantly 
> add/remove test nodes to the cluster without 
> breaking/changing anything in Kerberos settings for the 
> constantly running client pool - 
> https://docs.diladele.com/administrator_guide_stable/active_di
> rectory_extra/redundancy/haproxy_proxy_protocol.html
> 
> And yes we do *not* use computer account, we use *user* 
> account instead.
> See the reasoning  in the tutorial.
> 
> Best regards,
> Rafael Akchurin
> Diladele B.V.
> 
>   
> 
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> 
> On Behalf Of Brett Lymn
> Sent: Friday, July 24, 2020 2:23 AM
> To: Klaus Brandl <klaus_brandl at genua.de>
> Cc: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Problem with HAProxy + Squid 4.11 
> + Kerberos authentication
> 
> On Thu, Jul 23, 2020 at 06:07:39PM +0200, Klaus Brandl wrote:
> > 
> > But if anyone knows a solution, i will spread my ears :)
> > 
> 
> What we do is:
> 
> 1) create a user account in AD that will be used for the HA 
> front end, set a password and export the keytab for this user
> 2) Use ktadmin to import the keytab entries for the user 
> created in step
> 1 into the keytab for squid on the squid servers.
> 3) Set a SPN (setspn) in AD that maps HTTP://ha.fqdn.address 
> to the user created in 1
> 
> The SPN (service principal name) tells kerberos to use the 
> user details set up in step 1 to authenticate http requests.  
> This works for us, has been for years.
> 
> One thing, if you want to know the IP addresses of your 
> clients in the squid logs you will need to do some extra 
> stuff because all accesses will appear to come from the HA 
> loadbalancer.  We have configured our load balancers to 
> insert the X-Forwarded-For header into the http traffic and 
> then modified the logging to log both the loadblancer and client IP.
> 
> --
> Brett Lymn
> This email has been sent on behalf of one of the following 
> companies within the BAE Systems Australia group of companies:
> 
> BAE Systems Australia Limited - Australian Company Number 008 
> 423 005 BAE Systems Australia Defence Pty Limited - 
> Australian Company Number 006 870 846 ASC Shipbuilding Pty 
> Limited - Australian Company Number 051 899 864
> 
> BAE Systems Australia's registered office is Evans Building, 
> Taranaki Road, Edinburgh Parks, Edindurgh, South Australia, 5111.
> ASC Shipbuilding's registered office is Level 2, 80 Flinders 
> Street, Adelaide, South Australia, 5000.
> If the identity of the sending company is not clear from the 
> content of this email, please contact the sender.
> 
> This email and any attachments may contain confidential and 
> legally privileged information. If you are not the intended 
> recipient, do not copy or disclose its content, but please 
> reply to this email immediately and highlight the error to 
> the sender and then immediately delete the message.
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From service.mv at gmail.com  Fri Jul 24 13:13:55 2020
From: service.mv at gmail.com (Service MV)
Date: Fri, 24 Jul 2020 10:13:55 -0300
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
	authentication
In-Reply-To: <20200724002303.GA3183@baea.com.au>
References: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
 <5815088.fB3ryEAXG5@cairon> <20200724002303.GA3183@baea.com.au>
Message-ID: <CA+d==oHtnK1DH97SvNBdPHL1VdEBVrdYxvm_jtNw38aJKWE8gQ@mail.gmail.com>

Thanks, Brett, for the answer. I did exactly the same thing and it's
working for me now.
I only have to decrypt how to see the client's IP in SQUID's logs. I will
follow your instructions to try to achieve it.

Best regards,

Gabriel


El jue., 23 de jul. de 2020 a la(s) 21:23, Brett Lymn (
brett.lymn at baesystems.com) escribi?:

> On Thu, Jul 23, 2020 at 06:07:39PM +0200, Klaus Brandl wrote:
> >
> > But if anyone knows a solution, i will spread my ears :)
> >
>
> What we do is:
>
> 1) create a user account in AD that will be used for the HA front end,
> set a password and export the keytab for this user
> 2) Use ktadmin to import the keytab entries for the user created in step
> 1 into the keytab for squid on the squid servers.
> 3) Set a SPN (setspn) in AD that maps HTTP://ha.fqdn.address to the user
> created in 1
>
> The SPN (service principal name) tells kerberos to use the user details
> set up in step 1 to authenticate http requests.  This works for us, has
> been for years.
>
> One thing, if you want to know the IP addresses of your clients in the
> squid logs you will need to do some extra stuff because all accesses
> will appear to come from the HA loadbalancer.  We have configured our
> load balancers to insert the X-Forwarded-For header into the http
> traffic and then modified the logging to log both the loadblancer and
> client IP.
>
> --
> Brett Lymn
> This email has been sent on behalf of one of the following companies
> within the BAE Systems Australia group of companies:
>
> BAE Systems Australia Limited - Australian Company Number 008 423 005
> BAE Systems Australia Defence Pty Limited - Australian Company Number 006
> 870 846
> ASC Shipbuilding Pty Limited - Australian Company Number 051 899 864
>
> BAE Systems Australia's registered office is Evans Building, Taranaki
> Road, Edinburgh Parks, Edindurgh, South Australia, 5111.
> ASC Shipbuilding's registered office is Level 2, 80 Flinders Street,
> Adelaide, South Australia, 5000.
> If the identity of the sending company is not clear from the content of
> this email, please contact the sender.
>
> This email and any attachments may contain confidential and legally
> privileged information. If you are not the intended recipient, do not copy
> or disclose its content, but please reply to this email immediately and
> highlight the error to the sender and then immediately delete the message.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200724/c4d123a9/attachment.htm>

From squid3 at treenet.co.nz  Fri Jul 24 13:19:33 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 25 Jul 2020 01:19:33 +1200
Subject: [squid-users] squid4.12 access_log
In-Reply-To: <3ce5a2b58f878a233f6c84fd5025460b@animate.de>
References: <3ce5a2b58f878a233f6c84fd5025460b@animate.de>
Message-ID: <061512e3-3974-8a6c-509f-b0cd0bb096ed@treenet.co.nz>

On 24/07/20 7:06 pm, Thomas Elsaesser wrote:
> Dear all,
> 
> my squid server are behind? HW loadbalancer. This make TCP? Healthchecks
> on squid port.
> Now(after update from squid 3 to 4) i have in the log massive? messages:
> how can i discard this messages from this two LB ip's?
> 
> acl noTransactionError src 10.XX.XX.XX 10.XX.XX.XX
> access_log????????????? /var/log/squid4/access.log combined?
> !noTransactionError
> 

Place this as the first access_log line (order matters for these):

  access_Log none noTransactionError


I would also name that ACL something different. An IP address is not an
error and this choice of rule will prevent logging of *all* traffic from
that IP. "loadbalancer" would be clearer name.


I have not tested this, but you may want to add this extra condition so
when the LB sends actual HTTP it will appear in the logs:

  acl hasRequest has request
  acl dontLog all-of !hasRequest noTransactionError
  access_Log none dontLog


Amos


From service.mv at gmail.com  Fri Jul 24 14:23:27 2020
From: service.mv at gmail.com (Service MV)
Date: Fri, 24 Jul 2020 11:23:27 -0300
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
	authentication
In-Reply-To: <6f4e066f-f95c-c1e8-bfe8-29a106d3d7a8@treenet.co.nz>
References: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
 <5815088.fB3ryEAXG5@cairon>
 <CA+d==oGmKBxTvAKxDLA5rC+0p5sc1qMHVH9D2s6Dfc8W=wiAgg@mail.gmail.com>
 <6f4e066f-f95c-c1e8-bfe8-29a106d3d7a8@treenet.co.nz>
Message-ID: <CA+d==oEJ08CsFz4DZyjbcZqN04dbMdCyV1+PzCDCnfMJ+_GH2w@mail.gmail.com>

Thanks Amos, Kerberos is really hard to learn for a rookie like me, but you
explained it in an excellent and concise way.
In my case, the SQUID servers are joined to the domain with their
respective SPN and UPN that I mentioned in the msktutil command.
And in the case of the Load Balancer HAProxy I used a user account and I
set that the password does not expire. I know this may not be the safest
way to do it, but I couldn't find a way to do it with a computer account. I
guess I should join the HAProxy to the domain as well.
The detail, as you mentioned, is that the DNS A record (eg
inet.mydomain.local) is to match exactly the SPN for that user account,
which at this point is a service account.

Thanks again

Gabriel

El vie., 24 de jul. de 2020 a la(s) 00:10, Amos Jeffries (
squid3 at treenet.co.nz) escribi?:

> On 24/07/20 5:09 am, Service MV wrote:
> > Hi Klaus,
> > I think something similar. But I understand that you can use the
> > Kerberos delegation in AD. That's partly why I'm not convinced by the
> > documentation I read, which tells me to create a user account in Active
> > Directory. And I don't understand what a user account has to do here.
> > Maybe the documentation is wrong and actually refers to a computer
> > account, and the operation of adding a Service Principal Name should be
> > done to the computer object. I don't know. But I'm going to try to do it
> > and see what I can achieve.
> >
>
> Kerberos authentication in HTTP uses the Negotiate scheme. The model for
> that scheme is that it authenticates the exact TCP connection over which
> the credentials are transmitted.
>
> So for it to work *through* a proxy (eg HAProxy) that proxy must ensure
> the *two* TCP connections it is handling (from-client and to-Squid) are
> pinned together with all HTTP multiplexing features disabled _and_ the
> Proxy-Auth* headers are not touched or used along the way.
>
>  => If either of those conditions is broken the auth will not work and
> users will definitely get the behaviour you are seeing. That behaviour
> may also occur anyway if later stages are broken - this is just the
> first and most non-obvious problem for beginners.
>
>
> [ below is simplified a bit/lot to ensure you have the basic
> understanding. There is a steep learning curve for Kerberos tools and
> one needs basics before troubleshooting exposes the gory details ]
>
> The HTTP agent which is doing the Kerberos auth validation (eg Squid)
> must be configured with an account that can perform authentication tasks
> with the central domain server.
>  This can be either User or Machine account as you know. The important
> difference is their policy on passwords. User accounts need password
> rotation, machines are effectively permanent. Since keytab used by Squid
> has to be re-generated every time the account password changes User
> accounts are naturally far more complex to administrate for reliable auth.
>
>  => So ... your choice and YMMV. But we recommend a machine account
> unless you have reason to go the more complex way.
>
>
> At the other end the client software needs a keytab with a "Principal"
> name telling it what to request from the central domain server when it
> needs a token that Squid can validate.
>
>  => The principal name has to match up with the account details used by
> the proxy which is checking the auth credentials. This is why the middle
> proxy (eg HAProxy) cannot touch the authentication on its way to Squid.
>
>  => The principal name is also case-sensitive and and must survive
> *exact* string comparisons despite DNS resolve being involved [ because
> reasons :( ].  So be sure to use full FQDN rather than host name
> abbreviations.
>
>
>
> > I'll be back.
> >
> > El jue., 23 de jul. de 2020 a la(s) 13:16, Klaus Brandl escribi?:
> >
> >     Hi Gabriel,
> >
> >     same problem here on our HA systems.
> >     I think, this is caused by kerberos overall, the tickets are always
> >     bound to
> >     the hosts realname and address, look at "klist" on your client, and
> >     only
> >     exactly this name could be used as proxy entry.
>
>
> Indeed. Use of wrong names (eg not using the full FQDN), wrong case, or
> the hostnames not being DNS resolvable are common causes of Kerberos not
> working.
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200724/f18afcff/attachment.htm>

From klaus_brandl at genua.de  Fri Jul 24 14:48:07 2020
From: klaus_brandl at genua.de (Klaus Brandl)
Date: Fri, 24 Jul 2020 16:48:07 +0200
Subject: [squid-users] squid kerberos auth, acl note group
In-Reply-To: <1ef6cafe-19f6-9b9c-9612-90552430bdb4@treenet.co.nz>
References: <9473896.LjNUQkeJut@cairon> <12080330.Prj8ev6qeJ@cairon>
 <1ef6cafe-19f6-9b9c-9612-90552430bdb4@treenet.co.nz>
Message-ID: <11252591.tFmiVPXsx0@cairon>

sorry, i did not found this script, and the binary is not available on our 
product, because i'm no developer...

But i think, we have a caching problem here, i found out, that the group 
informations are only updated on a squid reconfigure.

And also the acl note group ... seems to be cached as long as squid is 
restarted completely. I removed the configured group from the user, but i could 
see this group still maching in the cache.log, also after a reconfigure, when 
the auth_helper does not tell about this group any more.

> Ah. Sorry. I should have checked the protocol sequence, it has been a
> while since last I played with these tokens.
> 
> For Kerberos there should be a test_negotiate_auth.sh script and
> negotiate_kerberos_auth_test binary available for debugging these auth
> details.
> 
> Run the test_negotiate_auth.sh with with your Squid hostname as its
> command line parameter.
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Klaus

---

genua GmbH
Domagkstrasse 7, 85551 Kirchheim bei Muenchen
tel +49 89 991950-0, fax -999, www.genua.de

Geschaeftsfuehrer: Matthias Ochs, Marc Tesch
Amtsgericht Muenchen HRB 98238
genua ist ein Unternehmen der Bundesdruckerei-Gruppe.


From squid3 at treenet.co.nz  Sat Jul 25 06:13:05 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 25 Jul 2020 18:13:05 +1200
Subject: [squid-users] squid kerberos auth, acl note group
In-Reply-To: <11252591.tFmiVPXsx0@cairon>
References: <9473896.LjNUQkeJut@cairon> <12080330.Prj8ev6qeJ@cairon>
 <1ef6cafe-19f6-9b9c-9612-90552430bdb4@treenet.co.nz>
 <11252591.tFmiVPXsx0@cairon>
Message-ID: <704e36b3-4cd8-611c-0643-231c02045db6@treenet.co.nz>

On 25/07/20 2:48 am, Klaus Brandl wrote:
> sorry, i did not found this script, and the binary is not available on our 
> product, because i'm no developer...
> 

Darn. Okay that hinders testing a bit.

> But i think, we have a caching problem here, i found out, that the group 
> informations are only updated on a squid reconfigure.
> 
> And also the acl note group ... seems to be cached as long as squid is 
> restarted completely. I removed the configured group from the user, but i could 
> see this group still maching in the cache.log, also after a reconfigure, when 
> the auth_helper does not tell about this group any more.
> 

The groups are attached to credentials which are attached to the TCP
connection (TTL only as long as the connection is open) and a token
replay cache for up to authenticate_ttl directive time (default 1 hour).

Setting that TTL to something very short, eg:

  authenticate_ttl 10 seconds

... and disabling connection keep-alive:

  client_persistent_connections off

... should work around the cache for testing. At least on HTTP traffic.
HTTPS traffic goes through the proxy as a single tunnel request - so the
entire HTTPS session is just one request/response pair to Squid.

Amos


From huaraz at moeller.plus.com  Sat Jul 25 15:43:13 2020
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Sat, 25 Jul 2020 16:43:13 +0100
Subject: [squid-users] squid kerberos auth, acl note group
In-Reply-To: <704e36b3-4cd8-611c-0643-231c02045db6@treenet.co.nz>
References: <9473896.LjNUQkeJut@cairon> <12080330.Prj8ev6qeJ@cairon>
 <1ef6cafe-19f6-9b9c-9612-90552430bdb4@treenet.co.nz>
 <11252591.tFmiVPXsx0@cairon>
 <704e36b3-4cd8-611c-0643-231c02045db6@treenet.co.nz>
Message-ID: <rfhjuj$17js$1@ciao.gmane.io>

Hi Klaus,

    Is the group you added a security group ?  Only security groups are part 
of the Kerberos ticket.  Which authorisation helper do you use or is this 
just based on the auth helper output ?

    What do you see on the client ?  e.g. in powershell run whoami /groups

    Did you clear the client Kerberos cache e.g. by login out and in again 
or use klist purge ?


Markus

"Amos Jeffries"  wrote in message 
news:704e36b3-4cd8-611c-0643-231c02045db6 at treenet.co.nz...

On 25/07/20 2:48 am, Klaus Brandl wrote:
> sorry, i did not found this script, and the binary is not available on our
> product, because i'm no developer...
>

Darn. Okay that hinders testing a bit.

> But i think, we have a caching problem here, i found out, that the group
> informations are only updated on a squid reconfigure.
>
> And also the acl note group ... seems to be cached as long as squid is
> restarted completely. I removed the configured group from the user, but i 
> could
> see this group still maching in the cache.log, also after a reconfigure, 
> when
> the auth_helper does not tell about this group any more.
>

The groups are attached to credentials which are attached to the TCP
connection (TTL only as long as the connection is open) and a token
replay cache for up to authenticate_ttl directive time (default 1 hour).

Setting that TTL to something very short, eg:

  authenticate_ttl 10 seconds

... and disabling connection keep-alive:

  client_persistent_connections off

... should work around the cache for testing. At least on HTTP traffic.
HTTPS traffic goes through the proxy as a single tunnel request - so the
entire HTTPS session is just one request/response pair to Squid.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 




From huaraz at moeller.plus.com  Sat Jul 25 16:11:12 2020
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Sat, 25 Jul 2020 17:11:12 +0100
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
 authentication
In-Reply-To: <vmime.5f1aa165.2c44.7eb4bc368baef35@ms249-lin-003.rotterdam.bazuin.nl>
References: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
 <vmime.5f1aa165.2c44.7eb4bc368baef35@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <rfhlj1$10sf$1@ciao.gmane.io>

Hi 


Maybe some general comments about LB, CNAMEs and Squid Kerberos will help.  The kerberos client will try to request a ticket based on the used hostname. e.g. if you configure in your browser the proxy name as  ha-proxy.slb.example.com then the client will look for a serviceprincipal of HTTP/ha-proxy.slb.example.com. If this is a Cname then you may have browser dependencies e.g. 

  ha-proxy.slb.example.com CNAME HA-server1.real.example.com 

Some browsers will use HTTP/ha-proxy.slb.example.com  and some will use HTTP/HA-server1.real.example.com  

Now if your squid server name is squid1.real.example.com you will have probably only HTTP/squid1.real.example.com  in your keytab.  


There are now 2 Options:

1 ) Create one entry in AD for all squid servers  i.e. the AD entry will have at least number of servers + 2  service principals associated to it, extract the key to a keytab and use the option ?s GSS_C_NO_NAME with the negotiate_kerberos_auth helper 
     .e.g HTTP/squid1.real.example.com , HTTP/squid2.real.example.com , HTTP/HA-server1.real.example.com  ,  HTTP/ha-proxy.slb.example.com  
2) Create separate entries in AD for each squid server, the LB and the CNAMEs and then merge the keys into one keytab to be used on all squid servers.

Kind Regards
Markus



"L.P.H. van Belle" <belle at bazuin.nl> wrote in message news:vmime.5f1aa165.2c44.7eb4bc368baef35 at ms249-lin-003.rotterdam.bazuin.nl...
forgot 1 thing. (sorry) 
# 
adduser proxyuser winbind_priv 

or things might not work. 

 



------------------------------------------------------------------------------
  Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens L.P.H. van Belle
  Verzonden: vrijdag 24 juli 2020 10:46
  Aan: squid-users at lists.squid-cache.org
  Onderwerp: Re: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos authentication


  i would recommend to ..
  1) use debian buster,
  2) use squid 4.12
  3) use samba (winbind). 

  needed  in smb.conf ( only shown whats really needed ), there is more offcourse. 

      dedicated keytab file = /etc/krb5.keytab
      kerberos method = secrets and keytab

      # renew the kerberos ticket
      winbind refresh tickets = yes

      # Added for freeradius support
      #ntlm auth = mschapv2-and-ntlmv2-only


  apt install winbind krb5-user should be sufficient. 

  samba joins the domain. 
  /etc/krb5.keytab contains the default part and refreshed the server kerberos passworks/tickes. 

  And for squid its keytab. 

  kinit Administrator
  export KRB5_KTNAME=FILE:/etc/squid/HTTP-$(hostname -s).keytab
  net ads keytab add_update_ads HTTP/$(hostname -f) -U Administrator

  # alias name to keytab
  net ads keytab ADD HTTP/CNAME.FQDN 

  # check keytab file.
  klist -ke /etc/squid/HTTP-$(hostname -s).keytab
  unset KRB5_KTNAME

  # set rights.
  chgrp proxy /etc/squid/HTTP-$(hostname -s).keytab
  chmod g+r /etc/squid/HTTP-$(hostname -s).keytab

  And i use  in squid 
  auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \
      --kerberos /usr/lib/squid/negotiate_kerberos_auth -k /etc/squid/HTTP-hostname.keytab \
      -s HTTP/hostname.fqdn at REALM -s HTTP/CNAME.FQDN at REALM 
      --ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOM 

  Point to think about. 

  server IP's needs A + PTR 
  use CNAMEs in the DNS. 
  and make sure the resolving is setup correctly. 

  Add a caching DNS to the proxy. ( and let squid use it also ) 

  I had this working (without HAproxy) but with keepalived. 

  As far i can tel, your problem is in how the hostnames and ip are used. 
  but above might give you ideas. 


  Greetz, 

  Louis






----------------------------------------------------------------------------
    Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Service MV
    Verzonden: donderdag 23 juli 2020 17:36
    Aan: squid-users at lists.squid-cache.org
    Onderwerp: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos authentication


    Hi, everybody.
    I have a SQUID 4.11 compiled on Debian 9.8 with kerberos integration authenticating and browsing without problems:
    cache.log
    squid_kerb_auth: User some.user authenticated
    access.log
    10.10.10.203 TCP_TUNNEL/200 5264 CONNECT update.googleapis.com:443 some.user HIER_DIRECT/MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: 172.217.162.3 -

    The problem starts when I try to configure a HAProxy 1.8 load balancer to which by redundancy I configured a virtual IP with the keepalived service. When I point my browser to the DNS A record (balancer.mydomain.local) which in turn points to the keepalived virtual IP, the authentication stops working:
    cache.log 
    no records
    access.log
    10.10.8.207 TCP_DENIED/407 4142 CONNECT update.googleapis.com:443 - HIER_NONE/- text/

    In the client browser a prompt appears requesting authentication.

    I find it strange that the IP registered by SQUID is 10.10.8.207, which is the physical IP of my VM, instead of the virtual IP configured in HAProxy, which is the IP 10.10.8.213.

    I send you all the configurations that I have made to see if you can help me to find where my configuration error is.

    keepalived.conf 
      global_defs {
         notification_email {
           some.user at mydomain.local
         }
         notification_email_from balancer1 at mydomain.local
         smtp_server smtp. mydomain.local 
         smtp_connect_timeout 60
      }

      vrrp_instance VI_1 {
          state MASTER
          interface eth0
          virtual_router_id 101
          priority 101
          advert_int 1
          authentication {
              auth_type PASS
              auth_pass somepass123
          }
          virtual_ipaddress {
              10.10.8.213
          }
      }



    haproxy.conf
    global
    log /dev/log local0
    log /dev/log local1 notice
    chroot /var/lib/haproxy
    stats socket /run/haproxy/admin.sock mode 660 level admin
    stats timeout 30s
    user haproxy
    group haproxy
    daemon
    maxconn 4000
    ca-base /etc/ssl/certs
    crt-base /etc/ssl/private
    server=haproxy
    ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS
    ssl-default-bind-options no-sslv3

    defaults
    balance source
    log global
    mode http
    option httplog
    option dontlognull
    option http-server-close
    option forwardfor except MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: 127.0.0.0/8
    timeout connect 5000
    timeout client 50000
    timeout server 50000

    errorfile 400 /etc/haproxy/errors/400.http
    errorfile 403 /etc/haproxy/errors/403.http
    errorfile 408 /etc/haproxy/errors/408.http
    errorfile 500 /etc/haproxy/errors/500.http
    errorfile 502 /etc/haproxy/errors/502.http
    errorfile 503 /etc/haproxy/errors/503.http
    errorfile 504 /etc/haproxy/errors/504.http

    ### statistics
    listen stats
    bind MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: 10.10.8.213:1936
    mode http
    stats enable
    stats hide-version
    stats realm Haproxy\ Statistics
    stats uri /haproxy?stats
    stats auth haproxy:somepass123

    ### balancer
    listen squid
    bind MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: 10.10.8.213:3128
      mode http
      option httplog
      balance source
      hash-type consistent
      option httpclose
      cookie SERVERID insert indirect nocache
      option forwardfor header X-Client
      server proxy1 MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: 10.10.8.205:3128 check inter 2000 rise 2 fall 5

      server proxy2 MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: MailScanner warning: numerical links are often malicious: 10.10.8.206:3128 check inter 2000 rise 2 fall 5



    squid.conf
    # minimal configuration for testing
    visible_hostname proxy1.mydomain.local
    http_port 3128
    debug_options ALL, 1 33, 2 28, 9
    maximum_object_size 8192 KB
    error_directory /opt/squid411/share/errors/es-ar
    shutdown_lifetime 0 seconds
    forwarded_for on
    auth_param negotiate program /usr/local/bin/squid_kerb_auth -i -r -s GSS_C_NO_NAME
    auth_param negotiate children 300 startup=150 idle=10
    auth_param negotiate keep_alive on
    acl auth proxy_auth REQUIRED
    http_access allow auth
    acl SSL_ports port 443
    acl Safe_ports port 80
    acl CONNECT method CONNECT
    http_access deny !Safe_ports
    http_access deny CONNECT !SSL_ports
    http_access deny all



    squid -v
    Squid Cache: Version 4.11
    Service Name: squid

    This binary uses OpenSSL 1.0.2u  20 Dec 2019. For legal restrictions on distribution see https://www.openssl.org/source/license.html

    configure options:  '--prefix=/opt/squid411' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--localstatedir=/opt/squid411/var' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--enable-inline' '--enable-async-io' '--enable-storeio=ufs,aufs,diskd' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-digest-auth-helpers' '--enable-negotiate-auth-helpers' '--enable-auth-ntlm' '--enable-arp-acl' '--enable-esi--disable-translation' '--with-logdir=/var/log/squid411' '--with-pidfile=/var/run/squid411.pid' '--with-filedescriptors=65536' '--with-large-files' '--with-default-user=proxy' '--enable-linux-netfilter' '--enable-ltdl-convenience' '--with-openssl' '--enable-ssl' '--enable-ssl-crtd'



    env
    KRB5_KTNAME=/opt/squid411/etc/PROXY.keytab
    KRB5RCACHETYPE=none



    /etc/krb5.conf
    [libdefaults]
        default_realm = MYDOMAIN.LOCAL
        dns_lookup_kdc = yes
        dns_lookup_realm = yes 
        ticket_lifetime = 24h

            default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5
            default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5
            permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5

    [realms]
        MYDOMAIN.LOCAL = {
            kdc = s-dc00.mydomain.local
            kdc = s-dc01.mydomain.local
            kdc = s-dc02.mydomain.local
            admin_server = s-dc00.mydomain.local
        }

    [domain_realm]
        .mydomain.local = MYDOMAIN.LOCAL
        mydomain.local = MYDOMAIN.LOCAL



    msktutil -c -b "OU=SERVIDORES" -s HTTP/debian-proxy.mydomain.local -k /opt/squid411/etc/PROXY.keytab --computer-name DEBIAN-PROXY --upn HTTP/debian-proxy.mydomain.local --server s-dc00.mydomain.local --verbose --enctypes 28



    # permissions for kaytab file
    chgrp proxy /opt/squid411/etc/PROXY.keytab
    chmod g+r /opt/squid411/etc/PROXY.keytab



    klist
    Ticket cache: FILE:/tmp/krb5cc_0
    Default principal: some.user at MYDOMAIN.LOCAL

    Valid starting       Expires              Service principal
    07/23/2020 11:59:45  07/23/2020 21:59:45  krbtgt/MYDOMAIN.LOCAL at MYDOMAIN.LOCAL
            renew until 07/24/2020 11:59:40



    One thing I didn't quite understand is the procedure to authenticate from HAProxy. According to the documentation I read, I did the following:

    I created a DNS A record and its PTR in my DNS server pointing to the virtual IP of the keepalived (10.10.8.213) in the HAProxy. 
    Then I created a "HTTP_inet" user account in Active Directory.
    Then on my domain controller, in a CMD with administrator permissions, I ran:
    setspn -S HTTP/inet.mydomain.local HTTP_inet
    setspn -S HTTP/inet HTTP_inet 
    In both cases the message was: object updated.
    Then in my SQUID servers, I executed:
    kinit HTTP_inet at MYDOMAIN.LOCAL
    It asks for the user's password.
    Start the ktutil tool
    That's where I write:
    addent -password -p HTTP/inet.mydomain.local -k 2 -e rc4-hmac
    Ask the user password
    addent -password -p HTTP/inet -k 2 -e rc4-hmac
    Ask the user password
    wkt /opt/squid411/etc/PROXY.keytab
    quit

    list the keys in keytab:
    ktutil
    read_kt /opt/squid411/etc/PROXY.keytab
       1 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
       2 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
       3 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
       4 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
       5 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
       6 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
       7 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
       8 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
       9 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
      10 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
      11 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
      12 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
      13 2 HTTP/inet.mydomain.local at MYDOMAIN.LOCAL
      14 2 HTTP/inet at MYDOMAIN.LOCAL

    It's this last part I understand the least, maybe the mistake is there. Or somewhere else.
    I appreciate any help you can offer me. 

    Best regards,

    Gabriel




--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200725/781b0d0f/attachment.htm>

From required.website.email at gmail.com  Sun Jul 26 17:17:04 2020
From: required.website.email at gmail.com (required.website.email at gmail.com)
Date: Sun, 26 Jul 2020 12:17:04 -0500
Subject: [squid-users] Is strip_query_terms supported in v4?
Message-ID: <001e01d66370$95844950$c08cdbf0$@gmail.com>

I am struggling to understand why this won't work. 

 

Squid.config:

# does this work?

strip_query_terms off

 

logformat sandbox      %ts %rm %ru

access_log  /usr/local/squid/var/logs/sandbox2.log  sandbox

 

gives me this:

1595783176 CONNECT secure.adnxs.com:443

1595783177 CONNECT alb.reddit.com:443

1595783178 CONNECT compass-errors.deliverimp.com:443

1595783178 CONNECT
ca8842081dbc9ebe4952b58bc777466c.safeframe.googlesyndication.com:443

1595783180 CONNECT ap.lijit.com:443

 

 

 

Thank you everyone, I am super appreciative!

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200726/76f8fffd/attachment.htm>

From ambrose.li at gmail.com  Sun Jul 26 17:54:21 2020
From: ambrose.li at gmail.com (Ambrose Li)
Date: Sun, 26 Jul 2020 13:54:21 -0400
Subject: [squid-users] Is strip_query_terms supported in v4?
In-Reply-To: <001e01d66370$95844950$c08cdbf0$@gmail.com>
References: <001e01d66370$95844950$c08cdbf0$@gmail.com>
Message-ID: <20200726175421.GB9542@pingviini>

On Sun, Jul 26, 2020 at 12:17:04PM -0500, required.website.email at gmail.com wrote:
> strip_query_terms off
[...]
> gives me this:
> 
> 1595783176 CONNECT secure.adnxs.com:443
> 
> 1595783177 CONNECT alb.reddit.com:443
[...]

That's because https is encrypted. If you're not using ssl bump, squid has no idea what the browser is doing; that's why nothing is logged.

-- 
Ambrose Li <ambrose.li at gmail.com> | Time zone: UTC-4 (Eastern)
ambroseli.ca

???We need to put ourselves into positions where we are comfortable for
 being uncomfortable??? ??? Gaby Brink <aiga.org/video-gain-2012-brink/>



From brett.lymn at baesystems.com  Mon Jul 27 00:04:33 2020
From: brett.lymn at baesystems.com (Brett Lymn)
Date: Mon, 27 Jul 2020 09:34:33 +0930
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
 authentication
In-Reply-To: <5284125.Xo1gdhAW2t@cairon>
References: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
 <5815088.fB3ryEAXG5@cairon> <20200724002303.GA3183@baea.com.au>
 <5284125.Xo1gdhAW2t@cairon>
Message-ID: <20200727000433.GA11230@baea.com.au>

On Fri, Jul 24, 2020 at 10:44:34AM +0200, Klaus Brandl wrote:
> 
> but then you have a single point of failure, if your loadbalancer is down, 
> nothing will work. We need a solution, that each system can work by itself. So 
> at the moment we merge the keytabs of each system together, and we are able to 
> takeover the addresses of the other systems. Then we have no loadbalancing, 
> but a fallback solution, what is more important on our systems.
> 

No, you don't have a single point of failure, this is why I mentioned
using ktutil (well, I said ktadmin, my bad).  You merge the keytab for
the machine with the keytab for the HA user.  This way the clients are
able to both auth to the HA and to the the underlying machine.  It is
what we do, it works fine.

-- 
Brett Lymn
This email has been sent on behalf of one of the following companies within the BAE Systems Australia group of companies:

BAE Systems Australia Limited - Australian Company Number 008 423 005
BAE Systems Australia Defence Pty Limited - Australian Company Number 006 870 846
ASC Shipbuilding Pty Limited - Australian Company Number 051 899 864

BAE Systems Australia's registered office is Evans Building, Taranaki Road, Edinburgh Parks, Edindurgh, South Australia, 5111.
ASC Shipbuilding's registered office is Level 2, 80 Flinders Street, Adelaide, South Australia, 5000.
If the identity of the sending company is not clear from the content of this email, please contact the sender.

This email and any attachments may contain confidential and legally privileged information. If you are not the intended recipient, do not copy or disclose its content, but please reply to this email immediately and highlight the error to the sender and then immediately delete the message.



From tarotapprentice at yahoo.com  Mon Jul 27 00:45:58 2020
From: tarotapprentice at yahoo.com (Mark James)
Date: Mon, 27 Jul 2020 10:45:58 +1000
Subject: [squid-users] [squid-announce] [ADVISORY] SQUID-2020:7 Cache
 Poisoning Issue in HTTP Request processing
In-Reply-To: <007801d653b1$58bf30d0$0a3d9270$@gmail.com>
References: <007801d653b1$58bf30d0$0a3d9270$@gmail.com>
Message-ID: <BEC9E2E1-0896-4A75-B6CC-7C11BE870B09@yahoo.com>

It seems they decided to patch the 4.6 they have in Debian Buster.

There is no update on my Debian bug regarding promoting 4.12 to buster-backports.

MarkJ 

> On 7 Jul 2020, at 2:20 am, Eliezer Croitor <ngtech1ltd at gmail.com> wrote:
> 
> ?If someone need I can try to compile a Debian Buster compatible binary as a drop in replacement.
> 
> Eliezer
> 
> ----
> Eliezer Croitoru
> Tech Support
> Mobile: +972-5-28704261
> Email: ngtech1ltd at gmail.com
> 
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of TarotApprentice
> Sent: Sunday, July 5, 2020 4:31 AM
> To: Squid Users
> Subject: Re: [squid-users] [squid-announce] [ADVISORY] SQUID-2020:7 Cache Poisoning Issue in HTTP Request processing
> 
> Debian bug 964283 raised. If you are talking to the Debian security team you might want to discuss pushing it into buster with one of their point releases.
> 
> MarkJ
> 
>>> On 28 Jun 2020, at 12:57 am, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>> 
>>> ?On 28/06/20 2:27 am, TarotApprentice wrote:
>>> Any plans to get this into Debian, or if they?ll apply the patch to 4.11?
>>> 
>> 
>> v4.12 package is already being worked on. I'm not sure of ETA though,
>> its already taken longer than usual.
>> 
>> Can't speak for the security team about the stable Debian packages.
>> 
>> 
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From amaury at tin.it  Mon Jul 27 10:30:33 2020
From: amaury at tin.it (amaury at tin.it)
Date: Mon, 27 Jul 2020 12:30:33 +0200 (CEST)
Subject: [squid-users] filter NONE/000 NONE
 error:transaction-end-before-headers
Message-ID: <1738fd2f381.amaury@tin.it>

Hello
I would like to filter the message NONE/000 NONE error:
transaction-end-before-headers - HIER_NONE/- - - HTTP/0.0 "-" 0 0 that 
it arrives from
loadbalancer keep alived. I have red that It was/is a 
bug.
I'm using squid-4.12 and reading documentation there are this two 
point, that I could be useful:

#       acl aclname note [-m
[=delimiters]] name [value ...]
#         # match transaction 
annotation [fast]
#         # Without values, matches any annotation 
with a given name.
#         # With value(s), matches any annotation 
with a given name that
#         # also has one of the given values.

#         # If the -m flag is used, then the value of the named

#         # annotation is interpreted as a list of tokens, and the ACL

#         # matches individual name=token pairs rather than whole

#         # name=value pairs. See "ACL Options" above for more info.

#         # Annotation sources include note and adaptation_meta 
directives
#         # as well as helper and eCAP responses.


#       
acl aclname has component
#         # matches a transaction "component" 
[fast]
#         #
#         # Supported transaction components are:

#         #  request: transaction has a request header (at least)

#         #  response: transaction has a response header (at least)

#         #  ALE: transaction has an internally-generated Access Log 
Entry
#         #       structure; bugs notwithstanding, all 
transaction have it 
#         #
#         # For example, the following 
configuration helps when dealing with HTTP
#         # clients that 
close connections without sending a request header:
#         #

#         #  acl hasRequest has request
#         #  acl logMe note 
important_transaction
#         #  # avoid "logMe ACL is used in 
context without an HTTP request" warnings
#         #  access_log ... 
logformat=detailed hasRequest logMe
#         #  # log request-less 
transactions, instead of ignoring them
#         #  access_log ... 
logformat=brief !hasRequest
#         #
#         # Multiple components 
are not supported for one "acl" rule, but
#         # can be specified 
(and are ORed) using multiple same-name rules:
#         #
#         #  
# OK, this strange logging daemon needs request or response,
#         
#  # but can work without either a request or a response:
#         #  
acl hasWhatMyLoggingDaemonNeeds has request
#         #  acl 
hasWhatMyLoggingDaemonNeeds has response

Please could you give me a 
practical example example that how it works the:
#       acl aclname 
note [-m[=delimiters]] name [value ...] ?

Thank you
Best regards





From amaury at tin.it  Mon Jul 27 11:44:04 2020
From: amaury at tin.it (amaury at tin.it)
Date: Mon, 27 Jul 2020 13:44:04 +0200 (CEST)
Subject: [squid-users] set hide on
Message-ID: <1739016430b.amaury@tin.it>

set hide on


From rousskov at measurement-factory.com  Mon Jul 27 13:19:04 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 27 Jul 2020 09:19:04 -0400
Subject: [squid-users] filter NONE/000 NONE
 error:transaction-end-before-headers
In-Reply-To: <1738fd2f381.amaury@tin.it>
References: <1738fd2f381.amaury@tin.it>
Message-ID: <55d3128e-8b62-62c2-d234-9959570bbcce@measurement-factory.com>

On 7/27/20 6:30 AM, amaury at tin.it wrote:

> I would like to filter the message NONE/000 NONE error:
> transaction-end-before-headers - HIER_NONE/- - - HTTP/0.0 "-" 0 0 that 
> it arrives from loadbalancer keep alived. 


> I have red that It was/is a bug.

Those records are not a bug if your loadbalancer does open connections
to Squid's http_port.


> Please could you give me a 
> practical example example that how it works the:
> # acl aclname note [-m[=delimiters]] name [value ...] ?

The "note" ACL tests prior annotations. It is unlikely to help in your
use case because nothing will be able to annotate these half-baked
short-lived transactions until they are logged.

Please see whether Amos' recent suggestion works for you:

http://lists.squid-cache.org/pipermail/squid-users/2020-July/022461.html


HTH,

Alex.


From klaus_brandl at genua.de  Mon Jul 27 16:36:25 2020
From: klaus_brandl at genua.de (Klaus Brandl)
Date: Mon, 27 Jul 2020 18:36:25 +0200
Subject: [squid-users] squid kerberos auth, acl note group
In-Reply-To: <rfhjuj$17js$1@ciao.gmane.io>
References: <9473896.LjNUQkeJut@cairon>
 <704e36b3-4cd8-611c-0643-231c02045db6@treenet.co.nz>
 <rfhjuj$17js$1@ciao.gmane.io>
Message-ID: <19230339.6rUmX2M3JR@cairon>

Hi Markus and Amos,

thanks for your answers, it is working now, after the group was deleted and 
created new. Most likely it was no security object...

Regards

On Saturday 25 July 2020 16:43:13 Markus Moeller wrote:
> Hi Klaus,
> 
>     Is the group you added a security group ?  Only security groups are part
> of the Kerberos ticket.  Which authorisation helper do you use or is this
> just based on the auth helper output ?
> 
>     What do you see on the client ?  e.g. in powershell run whoami /groups
> 
>     Did you clear the client Kerberos cache e.g. by login out and in again
> or use klist purge ?
> 
> 
> Markus
> 
> "Amos Jeffries"  wrote in message
> news:704e36b3-4cd8-611c-0643-231c02045db6 at treenet.co.nz...
> 
> On 25/07/20 2:48 am, Klaus Brandl wrote:
> > sorry, i did not found this script, and the binary is not available on our
> > product, because i'm no developer...
> 
> Darn. Okay that hinders testing a bit.
> 
> > But i think, we have a caching problem here, i found out, that the group
> > informations are only updated on a squid reconfigure.
> > 
> > And also the acl note group ... seems to be cached as long as squid is
> > restarted completely. I removed the configured group from the user, but i
> > could
> > see this group still maching in the cache.log, also after a reconfigure,
> > when
> > the auth_helper does not tell about this group any more.
> 
> The groups are attached to credentials which are attached to the TCP
> connection (TTL only as long as the connection is open) and a token
> replay cache for up to authenticate_ttl directive time (default 1 hour).
> 
> Setting that TTL to something very short, eg:
> 
>   authenticate_ttl 10 seconds
> 
> ... and disabling connection keep-alive:
> 
>   client_persistent_connections off
> 
> ... should work around the cache for testing. At least on HTTP traffic.
> HTTPS traffic goes through the proxy as a single tunnel request - so the
> entire HTTPS session is just one request/response pair to Squid.
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Klaus

---

genua GmbH
Domagkstrasse 7, 85551 Kirchheim bei Muenchen
tel +49 89 991950-0, fax -999, www.genua.de

Geschaeftsfuehrer: Matthias Ochs, Marc Tesch
Amtsgericht Muenchen HRB 98238
genua ist ein Unternehmen der Bundesdruckerei-Gruppe.


From service.mv at gmail.com  Mon Jul 27 20:41:12 2020
From: service.mv at gmail.com (Service MV)
Date: Mon, 27 Jul 2020 17:41:12 -0300
Subject: [squid-users] Limit large downloads to autenticated users
Message-ID: <CA+d==oFfh+NPG_LgDONgTHwt9Mcw8doVWiOsbxyjC9roSM8b5Q@mail.gmail.com>

Hi everybody!
I read in the squid mailing lists that delay_pools doesn't work in v4.x,
but in the documentation I don't see anything about it.
I would like to know if in my SQUID 4.11 configuration with Kerberos + LDAP
authentication I can setup a delay_pools to limit large downloads of any
authenticated user.

This is my test configuration that I try to do, but I cannot limit the
downloads.

squid.conf
visible_hostname debian-proxy.mydomain.local
http_port 3128 require-proxy-header
acl haproxy src 10.10.8.213
proxy_protocol_access allow haproxy
debug_options ALL, 1 33, 2 28, 9
maximum_object_size 8192 KB
error_directory /opt/squid411/share/errors/es-ar
shutdown_lifetime 0 seconds
forwarded_for transparent
auth_param negotiate program /usr/local/bin/squid_kerb_auth -i -r -s
GSS_C_NO_NAME
auth_param negotiate children 300 startup=150 idle=10
auth_param negotiate keep_alive on
auth_param basic program /opt/squid411/libexec/basic_ldap_auth -P -R -b
"dc=mydomain,dc=local" -D "cn=ldap,cn=Users,dc=mydomain,dc=local" -W
/opt/squid411/etc/ldappass.txt -f sAMAccountName=%s -h dc1.mydomain.local
auth_param basic children 30
auth_param basic realm Proxy Authentication
auth_param basic credentialsttl 4 hour
acl auth proxy_auth REQUIRED
delay_pools 1
delay_class 1 2
delay_parameters 1 64000/64000 64000/64000
#delay_parameters 1 1310720/1966080 917504/1310720
delay_access 1 allow auth
http_access allow auth
acl SSL_ports port 443
acl Safe_ports port 80
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

http_access deny all


squid -v
Squid Cache: Version 4.11
Service Name: squid

This binary uses OpenSSL 1.0.2u  20 Dec 2019. For legal restrictions on
distribution see https://www.openssl.org/source/license.html

configure options:  '--prefix=/opt/squid411' '--includedir=/include'
'--mandir=/share/man' '--infodir=/share/info'
'--localstatedir=/opt/squid411/var' '--disable-maintainer-mode'
'--disable-dependency-tracking' '--disable-silent-rules' '--enable-inline'
'--enable-async-io' '--enable-storeio=ufs,aufs,diskd'
'--enable-removal-policies=lru,heap' '--enable-delay-pools'
'--enable-cache-digests' '--enable-underscores' '--enable-icap-client'
'--enable-follow-x-forwarded-for' '--enable-auth'
'--enable-digest-auth-helpers' '--enable-negotiate-auth-helpers'
'--enable-auth-ntlm' '--enable-arp-acl' '--enable-esi--disable-translation'
'--with-logdir=/var/log/squid411' '--with-pidfile=/var/run/squid411.pid'
'--with-filedescriptors=65536' '--with-large-files'
'--with-default-user=proxy' '--enable-linux-netfilter'
'--enable-ltdl-convenience' '--with-openssl' '--enable-ssl'
'--enable-ssl-crtd'

Thanks in advance for any help!
Best regards,

Gabriel
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200727/f76d88e8/attachment.htm>

From service.mv at gmail.com  Mon Jul 27 21:12:50 2020
From: service.mv at gmail.com (Service MV)
Date: Mon, 27 Jul 2020 18:12:50 -0300
Subject: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
 authentication
In-Reply-To: <AM0PR04MB475399C21B6BFEDDB8F155008F770@AM0PR04MB4753.eurprd04.prod.outlook.com>
References: <CA+d==oFGrUcOHO4FfmekmsKJu9RQ5f6N_O8BQ14wOJX7QWgpgQ@mail.gmail.com>
 <5815088.fB3ryEAXG5@cairon> <20200724002303.GA3183@baea.com.au>
 <5284125.Xo1gdhAW2t@cairon>
 <AM0PR04MB475399C21B6BFEDDB8F155008F770@AM0PR04MB4753.eurprd04.prod.outlook.com>
Message-ID: <CA+d==oFG0TBgbS+-OsEgyeegaAjtzANoUmDGSEugE0YyeB_a9Q@mail.gmail.com>

Hi everybody!
I am just writing to thank you all for the excellent comments, you have
been very helpful.

I also take this opportunity to mention which operating model I decided to
use, which is working well so far.

DNS A and PTR record "balancer.mydomain.local" pointing to keepalived
virtual IP of HAProxy. This is my HA frontend.
Haproxy server in TCP mode.
The SQUID nodes joined to the domain and authenticated by Kerberos and LDAP.
In each SQUID node I added the credentials of the AD user account in the
keytab. I configured the AD user account 'without expiring the password'
and 'not requiring pre-authentication kerberos'.
If anyone wants or needs more information just let me know.

Best regards

Gabriel


squid.conf
visible_hostname debian-proxy.mydomain.local
http_port 3128 require-proxy-header
acl haproxy src 10.10.8.213
proxy_protocol_access allow haproxy
debug_options ALL, 1 33, 2 28, 9
maximum_object_size 8192 KB
error_directory /opt/squid411/share/errors/es-ar
shutdown_lifetime 0 seconds
forwarded_for transparent
auth_param negotiate program /usr/local/bin/squid_kerb_auth -i -r -s
GSS_C_NO_NAME
auth_param negotiate children 300 startup=150 idle=10
auth_param negotiate keep_alive on
auth_param basic program /opt/squid411/libexec/basic_ldap_auth -P -R -b
"dc=mydomain,dc=local" -D "cn=ldap,cn=Users,dc=mydomain,dc=local" -W
/opt/squid411/etc/ldappass.txt -f sAMAccountName=%s -h dc1.mydomain.local
auth_param basic children 30
auth_param basic realm Proxy Authentication
auth_param basic credentialsttl 4 hour
acl auth proxy_auth REQUIRED
http_access allow auth
acl SSL_ports port 443
acl Safe_ports port 80
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

http_access deny all


haproxy.cfg
global
    log /dev/log    local0
    log /dev/log    local1 notice
    chroot /var/lib/haproxy
    stats socket /run/haproxy/admin.sock mode 660 level admin
    stats timeout 30s
    user haproxy
    group haproxy
    daemon

defaults
    log     global
    mode    tcp
    option  tcplog
    option  dontlognull
    timeout connect 5000
    timeout client  50000
    timeout server  50000

frontend squid
    bind 10.10.8.213:3128
    default_backend squid_pool

backend squid_pool
    balance source
    mode tcp
    option tcp-check
    tcp-check connect port 3128
    server squid1 10.10.8.205:3128 check inter 2000 rise 2 fall 3 send-proxy
    server squid2 10.10.8.214:3128 check inter 2000 rise 2 fall 3 send-proxy

ktutil
read_kt /opt/squid411/etc/PROXY.keytab
list
   1 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
   2 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
   3 1 DEBIAN-PROXY$@MYDOMAIN.LOCAL
   4 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
   5 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
   6 1 HTTP/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
   7 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
   8 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
   9 1 host/DEBIAN-PROXY at MYDOMAIN.LOCAL
  10 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
  11 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
  12 1 host/debian-proxy.mydomain.local at MYDOMAIN.LOCAL
  13 2 HTTP/inet.mydomain.local at MYDOMAIN.LOCAL
  14 2 HTTP/inet at MYDOMAIN.LOCAL

global_defs {
    notification_email {
      some.user at mydomain.local
    }
    notification_email_from pxbalancer01 at mydomain.local
    smtp_server smtp.mydomain.local
    smtp_connect_timeout 60
    router_id pxbalancer01
    }

    vrrp_instance VI_1 {
      state MASTER
      interface eth0
      virtual_router_id 114
      priority 110
      advert_int 1
      authentication {
        auth_type PASS
        auth_pass SomePASS123
        }
      virtual_ipaddress {
        10.10.8.213
        }
      virtual_routes {
        10.10.8.0/22 via 10.10.8.207 src 10.10.8.213
        }
}


El vie., 24 de jul. de 2020 a la(s) 06:44, Rafael Akchurin (
rafael.akchurin at diladele.com) escribi?:

> Sorry forgot to add to Amos'es answer - use haproxy to handle *tcp*
> connections and let the sslbump/authentication run on the cluster of squids
> - thus you would get working auth on squid side and use keepalived/haproxy
> on the client side.
>
> I do not see any reason why it cannot work unless you specifically desire
> to use some haproxy's features for l7 loadbalancing.
>
> Best regards,
> Rafael Akchurin
> Diladele B.V.
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf
> Of Klaus Brandl
> Sent: Friday, July 24, 2020 10:45 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Problem with HAProxy + Squid 4.11 + Kerberos
> authentication
>
> Hi Brett,
>
> but then you have a single point of failure, if your loadbalancer is down,
> nothing will work. We need a solution, that each system can work by
> itself. So
> at the moment we merge the keytabs of each system together, and we are
> able to
> takeover the addresses of the other systems. Then we have no
> loadbalancing,
> but a fallback solution, what is more important on our systems.
>
> On Friday 24 July 2020 09:53:03 Brett Lymn wrote:
> > On Thu, Jul 23, 2020 at 06:07:39PM +0200, Klaus Brandl wrote:
> > > But if anyone knows a solution, i will spread my ears :)
> >
> > What we do is:
> >
> > 1) create a user account in AD that will be used for the HA front end,
> > set a password and export the keytab for this user
> > 2) Use ktadmin to import the keytab entries for the user created in step
> > 1 into the keytab for squid on the squid servers.
> > 3) Set a SPN (setspn) in AD that maps HTTP://ha.fqdn.address to the user
> > created in 1
> >
> > The SPN (service principal name) tells kerberos to use the user details
> > set up in step 1 to authenticate http requests.  This works for us, has
> > been for years.
> >
> > One thing, if you want to know the IP addresses of your clients in the
> > squid logs you will need to do some extra stuff because all accesses
> > will appear to come from the HA loadbalancer.  We have configured our
> > load balancers to insert the X-Forwarded-For header into the http
> > traffic and then modified the logging to log both the loadblancer and
> > client IP.
>
> Klaus
>
> ---
>
> genua GmbH
> Domagkstrasse 7, 85551 Kirchheim bei Muenchen
> tel +49 89 991950-0, fax -999, www.genua.de
>
> Geschaeftsfuehrer: Matthias Ochs, Marc Tesch
> Amtsgericht Muenchen HRB 98238
> genua ist ein Unternehmen der Bundesdruckerei-Gruppe.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200727/11458cde/attachment.htm>

From squid3 at treenet.co.nz  Tue Jul 28 05:44:15 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 28 Jul 2020 17:44:15 +1200
Subject: [squid-users] set hide on
In-Reply-To: <1739016430b.amaury@tin.it>
References: <1739016430b.amaury@tin.it>
Message-ID: <d58545df-1bbb-db61-ccb0-a58948672507@treenet.co.nz>

On 27/07/20 11:44 pm, amaury wrote:
> set hide on

FAIL

Amos


From rajashankaran.slm at gmail.com  Tue Jul 28 11:30:44 2020
From: rajashankaran.slm at gmail.com (Sankar S)
Date: Tue, 28 Jul 2020 17:00:44 +0530
Subject: [squid-users] Disable authentication for squidclient
Message-ID: <CAFnHO818k7GD-FqfzQecnJVSDd1-z7SZQZ4Jsfjom8dm=6GKdg@mail.gmail.com>

Hi All,

               I have been running a squid proxy 4.9 compiled version for
my users externally domain accessibility with authentication enabled. now I
want to check my proxy stats via squidclient cache manager.  when I tried
to run this command in my proxy server it throws 407 authentication
required error.  Is it possible to disable authentication for this
operation alone


~/squid_4.9/bin>./squidclient -p 8080 mgr:info
HTTP/1.1 407 Proxy Authentication Required
Server: squid/4.9
Mime-Version: 1.0
Date: Tue, 28 Jul 2020 07:28:47 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 1661
X-Squid-Error: ERR_CACHE_ACCESS_DENIED 0
Proxy-Authenticate: Basic realm="Squid proxy-caching web server"
X-Cache: MISS from x.x.x.x
Via: 1.1 172.20.24.39 (squid/4.9)
Connection: close

When I send a connection with authentication, it throws 400 bad request

squid_4.9/bin>./squidclient -p 8080 mgr:info -u zorro
proxy password:
HTTP/1.1 400 Bad Request
Server: squid/4.9
Mime-Version: 1.0
Date: Tue, 28 Jul 2020 07:30:46 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 1661
X-Squid-Error: ERR_INVALID_URL 0
X-Cache: MISS from x.x.x.x
Via: 1.1 172.20.24.39 (squid/4.9)
Connection: close


Kindly let me know if there is any way to get squid stats via squid client
without authentication.
-- 
Thanks & Regards
Sankaranarayanan.S
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200728/c57cac63/attachment.htm>

From amaury at tin.it  Tue Jul 28 11:35:28 2020
From: amaury at tin.it (amaury at tin.it)
Date: Tue, 28 Jul 2020 13:35:28 +0200 (CEST)
Subject: [squid-users] filter NONE/000 NONE
 error:transaction-end-before-headers
Message-ID: <1739534bd70.amaury@tin.it>

Hi Alex
thank for your suggestion.

I have tried with:
acl 

noTransactionLvs src 10.xxx.xxx.xxx/32
acl noTransactionLvs src 10.xxx.

xxx.xxx/32

acl hasRequest has request
acl dontLog all-of !hasRequest 

noTransactionLvs
access_log none dontLog

and with
acl 
noTransactionLvs 
src 10.xxx.xxx.xxx/32
acl noTransactionLvs src 10.xxx.
xxx.xxx/32


access_log none noTransactionLvs
access_log              

/var/log/squid4/access.log combined !noTransactionLvs

but without 

result.

M.


From squid3 at treenet.co.nz  Tue Jul 28 12:36:39 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jul 2020 00:36:39 +1200
Subject: [squid-users] Disable authentication for squidclient
In-Reply-To: <CAFnHO818k7GD-FqfzQecnJVSDd1-z7SZQZ4Jsfjom8dm=6GKdg@mail.gmail.com>
References: <CAFnHO818k7GD-FqfzQecnJVSDd1-z7SZQZ4Jsfjom8dm=6GKdg@mail.gmail.com>
Message-ID: <ead6d074-34f7-8bfb-a260-7e5fb61092a3@treenet.co.nz>

On 28/07/20 11:30 pm, Sankar S wrote:
> Hi All,
> ?
> ? ? ? ? ? ? ? ?I have been running a squid proxy?4.9 compiled version
> for my users externally domain accessibility?with authentication
> enabled. now I want to check my proxy stats via squidclient cache
> manager.? when I tried to run this command in my proxy server it throws
> 407 authentication required error.? Is it possible to disable
> authentication for this operation?alone?
> 

The default configuration for Squid is to allow this and other manager
tools requests.

It seems you have explicitly removed that ability and/or forced
authentication to happen before checking management access. All you need
to do is fix that in squid.conf.


> 
> ~/squid_4.9/bin>./squidclient -p 8080 mgr:info
> HTTP/1.1 407 Proxy Authentication Required
> Server: squid/4.9
> Mime-Version: 1.0
> Date: Tue, 28 Jul 2020 07:28:47 GMT
> Content-Type: text/html;charset=utf-8
> Content-Length: 1661
> X-Squid-Error: ERR_CACHE_ACCESS_DENIED 0
> Proxy-Authenticate: Basic realm="Squid proxy-caching web server"
> X-Cache: MISS from x.x.x.x
> Via: 1.1 172.20.24.39 (squid/4.9)
> Connection: close
> 
> When I send a connection with authentication, it throws 400 bad request?
> 
> squid_4.9/bin>./squidclient -p 8080 mgr:info -u zorro

All parameters are supposed to be before the URL (mgr:info). squidclient
works fine for me with authentication.

Amos


From squid3 at treenet.co.nz  Tue Jul 28 12:57:02 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jul 2020 00:57:02 +1200
Subject: [squid-users] squid4.12 access_log
In-Reply-To: <b8680dd595a9d8d075b1d489070cd506@animate.de>
References: <3ce5a2b58f878a233f6c84fd5025460b@animate.de>
 <061512e3-3974-8a6c-509f-b0cd0bb096ed@treenet.co.nz>
 <b8680dd595a9d8d075b1d489070cd506@animate.de>
Message-ID: <12d6b44d-0183-9756-bab2-4239bbee4bed@treenet.co.nz>

On 28/07/20 7:38 pm, Thomas Els??er wrote:
> Dear all,
> 
> thnks for the answer. I have tested following config:
> 
> acl Loadbalancer src 10.12.56.46 10.12.56.48
> access_log none Loadbalancer
> acl hasRequest has request
> acl dontLog all-of !hasRequest Loadbalancer
> access_log none dontLog
> access_log????????????? /var/log/squid4/access.log combined !Loadbalancer
> 
> I need no requests from this IP's in my log.
> 
> But this not working.
> 
> 10.12.56.48 - - [28/Jul/2020:09:36:44 +0200] "NONE
> error:transaction-end-before-headers NONE/0.0" 0 0 "-" "-" NONE:HIER_NONE
> 10.12.56.46 - - [28/Jul/2020:09:36:46 +0200] "NONE
> error:transaction-end-before-headers NONE/0.0" 0 0 "-" "-" NONE:HIER_NONE
> 
> in my logfile.
> 

Did you clean the log (eg squid -k rotate) after reconfigure with the
updated squid.conf?

Something is broken in squid.conf if the IP based ACL did not work:

 acl Loadbalancer src 10.12.56.46 10.12.56.48
 access_log none Loadbalancer


Amos


From squid3 at treenet.co.nz  Tue Jul 28 13:21:23 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jul 2020 01:21:23 +1200
Subject: [squid-users] Limit large downloads to autenticated users
In-Reply-To: <CA+d==oFfh+NPG_LgDONgTHwt9Mcw8doVWiOsbxyjC9roSM8b5Q@mail.gmail.com>
References: <CA+d==oFfh+NPG_LgDONgTHwt9Mcw8doVWiOsbxyjC9roSM8b5Q@mail.gmail.com>
Message-ID: <087792a3-3c6b-c1bc-95a1-929ffba5ac87@treenet.co.nz>

On 28/07/20 8:41 am, Service MV wrote:
> Hi everybody!
> I read in the squid mailing lists that delay_pools doesn't work in v4.x,
> but in the documentation I don't see anything about it.

* Delay pools is a fairly major feature.

* "Dont work" is a very vague claim.

* mailing list threads are typically started by people who don't know
how to use a feature properly and having trouble because of that
misunderstanding.

* 4.x is an entire series of releases with many bug fixes across the
(ongoing) year(s) long lifecycle.

Draw your own conclusion about the accuracy of such statement on the
mailing list.



> I would like to know if in my SQUID 4.11 configuration with Kerberos +
> LDAP authentication I can setup a delay_pools to limit large downloads
> of any authenticated user.
> 

Yes. That should be entirely possible.


> This is my test configuration that I try to do, but I cannot limit the
> downloads.
> 
> squid.conf
...
> acl auth proxy_auth REQUIRED
> delay_pools 1
> delay_class 1 2
> delay_parameters 1 64000/64000 64000/64000

> delay_access 1 allow auth

The first problem is here. proxy_auth ACL is a "slow" type and
delay_access only supports "fast" types.

Squid-4 provides transaction annotations feature that can bridge this
gap. It is a fast type ACL that checks for annotations set by helper
lookups etc.

  acl hasUsername note user
  delay_access 1 allow hasUser
  delay_access 1 deny all



> http_access allow auth

This should be down just above the "http_access deny all"


> acl SSL_ports port 443
> acl Safe_ports port 80
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> 
> http_access deny all
> 
> 

Amos


From rousskov at measurement-factory.com  Tue Jul 28 14:01:30 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 28 Jul 2020 10:01:30 -0400
Subject: [squid-users] filter NONE/000 NONE
 error:transaction-end-before-headers
In-Reply-To: <17394ca0c65.amaury@tin.it>
References: <17394ca0c65.amaury@tin.it>
Message-ID: <91806993-6371-6c40-a65e-77d81ae4c879@measurement-factory.com>

On 7/28/20 5:38 AM, amaury at tin.it wrote:
> thank for your suggestion.

That specific suggestion was not mine :-)

For free Squid support, please keep the conversation on squid-users.


> I have tried with:

> acl noTransactionLvs src 10.xxx.xxx.xxx/32
> acl noTransactionLvs src 10.xxx.xxx.xxx/32
> 
> acl hasRequest has request
> acl dontLog all-of !hasRequest noTransactionLvs
> access_log none dontLog

> and with

> acl noTransactionLvs src 10.xxx.xxx.xxx/32
> acl noTransactionLvs src 10.xxx.xxx.xxx/32
> 
> access_log none noTransactionLvs
> access_log /var/log/squid4/access.log combined !noTransactionLvs

> but without result.


What is your Squid version?


None of the configs below is the right long-term solution, but just for
testing purposes, please try these three tests:

* Test 1 (should log nothing):

  access_log none all
  # and no other access_log lines


* Test 2 (should also log nothing):

  acl hasRequest has request
  access_log none !hasRequest
  access_log /var/log/squid4/access.log combined
  # and no other access_log lines


* Test 3 (should only log regular transactions):

  acl hasRequest has request
  access_log none !hasRequest
  access_log /var/log/squid4/access.log combined
  # and no other access_log lines

For each of the tests, please report whether regular transactions are
logged to /var/log/squid4/access.log _and_ whether the loadbalancer
probes are logged to /var/log/squid4/access.log


Thank you,

Alex.



> ----Messaggio originale----
> Da: rousskov at measurement-
> factory.com
> Data: 27-lug-2020 15.19
> A: "amaury at tin.it"<amaury at tin.it>, 
> <squid-users at lists.squid-cache.org>
> Ogg: Re: [squid-users] filter 
> NONE/000 NONE error:transaction-end-before-headers
> 
> On 7/27/20 6:30 AM, 
> amaury at tin.it wrote:
> 
>> I would like to filter the message NONE/000 
> NONE error:
>> transaction-end-before-headers - HIER_NONE/- - - HTTP/0.0 
> "-" 0 0 that 
>> it arrives from loadbalancer keep alived. 
> 
> 
>> I have 
> red that It was/is a bug.
> 
> Those records are not a bug if your 
> loadbalancer does open connections
> to Squid's http_port.
> 
> 
>> Please 
> could you give me a 
>> practical example example that how it works the:
> 
>> # acl aclname note [-m[=delimiters]] name [value ...] ?
> 
> The "note" 
> ACL tests prior annotations. It is unlikely to help in your
> use case 
> because nothing will be able to annotate these half-baked
> short-lived 
> transactions until they are logged.
> 
> Please see whether Amos' recent 
> suggestion works for you:
> 
> http://lists.squid-cache.org/pipermail/squid-users/2020-July/022461.html
> 
> 
> HTH,
> 
> Alex.
> 
> 



From marcus.kool at urlfilterdb.com  Tue Jul 28 14:09:36 2020
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 28 Jul 2020 15:09:36 +0100
Subject: [squid-users] filter NONE/000 NONE
 error:transaction-end-before-headers
In-Reply-To: <91806993-6371-6c40-a65e-77d81ae4c879@measurement-factory.com>
References: <17394ca0c65.amaury@tin.it>
 <91806993-6371-6c40-a65e-77d81ae4c879@measurement-factory.com>
Message-ID: <b9f81c9e-f0fe-e5a3-8951-7f1560f96b96@urlfilterdb.com>

bugs.squid-cache.org is not working now, but I think this is bug 4906.

Marcus



On 2020-07-28 15:01, Alex Rousskov wrote:
> On 7/28/20 5:38 AM, amaury at tin.it wrote:
>> thank for your suggestion.
> That specific suggestion was not mine :-)
>
> For free Squid support, please keep the conversation on squid-users.
>
>
>> I have tried with:
>> acl noTransactionLvs src 10.xxx.xxx.xxx/32
>> acl noTransactionLvs src 10.xxx.xxx.xxx/32
>>
>> acl hasRequest has request
>> acl dontLog all-of !hasRequest noTransactionLvs
>> access_log none dontLog
>> and with
>> acl noTransactionLvs src 10.xxx.xxx.xxx/32
>> acl noTransactionLvs src 10.xxx.xxx.xxx/32
>>
>> access_log none noTransactionLvs
>> access_log /var/log/squid4/access.log combined !noTransactionLvs
>> but without result.
>
> What is your Squid version?
>
>
> None of the configs below is the right long-term solution, but just for
> testing purposes, please try these three tests:
>
> * Test 1 (should log nothing):
>
>    access_log none all
>    # and no other access_log lines
>
>
> * Test 2 (should also log nothing):
>
>    acl hasRequest has request
>    access_log none !hasRequest
>    access_log /var/log/squid4/access.log combined
>    # and no other access_log lines
>
>
> * Test 3 (should only log regular transactions):
>
>    acl hasRequest has request
>    access_log none !hasRequest
>    access_log /var/log/squid4/access.log combined
>    # and no other access_log lines
>
> For each of the tests, please report whether regular transactions are
> logged to /var/log/squid4/access.log _and_ whether the loadbalancer
> probes are logged to /var/log/squid4/access.log
>
>
> Thank you,
>
> Alex.
>
>
>
>> ----Messaggio originale----
>> Da: rousskov at measurement-
>> factory.com
>> Data: 27-lug-2020 15.19
>> A: "amaury at tin.it"<amaury at tin.it>,
>> <squid-users at lists.squid-cache.org>
>> Ogg: Re: [squid-users] filter
>> NONE/000 NONE error:transaction-end-before-headers
>>
>> On 7/27/20 6:30 AM,
>> amaury at tin.it wrote:
>>
>>> I would like to filter the message NONE/000
>> NONE error:
>>> transaction-end-before-headers - HIER_NONE/- - - HTTP/0.0
>> "-" 0 0 that
>>> it arrives from loadbalancer keep alived.
>>
>>> I have
>> red that It was/is a bug.
>>
>> Those records are not a bug if your
>> loadbalancer does open connections
>> to Squid's http_port.
>>
>>
>>> Please
>> could you give me a
>>> practical example example that how it works the:
>>> # acl aclname note [-m[=delimiters]] name [value ...] ?
>> The "note"
>> ACL tests prior annotations. It is unlikely to help in your
>> use case
>> because nothing will be able to annotate these half-baked
>> short-lived
>> transactions until they are logged.
>>
>> Please see whether Amos' recent
>> suggestion works for you:
>>
>> http://lists.squid-cache.org/pipermail/squid-users/2020-July/022461.html
>>
>>
>> HTH,
>>
>> Alex.
>>
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Tue Jul 28 15:01:24 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 28 Jul 2020 11:01:24 -0400
Subject: [squid-users] filter NONE/000 NONE
 error:transaction-end-before-headers
In-Reply-To: <b9f81c9e-f0fe-e5a3-8951-7f1560f96b96@urlfilterdb.com>
References: <17394ca0c65.amaury@tin.it>
 <91806993-6371-6c40-a65e-77d81ae4c879@measurement-factory.com>
 <b9f81c9e-f0fe-e5a3-8951-7f1560f96b96@urlfilterdb.com>
Message-ID: <7ac46f0c-42fa-4617-0f50-b3929c5b0d2b@measurement-factory.com>

On 7/28/20 10:09 AM, Marcus Kool wrote:
> bugs.squid-cache.org is not working now, but I think this is bug 4906.

I bet you are right! If it is bug 4906 "src ACL mismatches when access
logging TCP probes" then IP-based ACLs will not work in the
transaction-end-before-headers context. I hope the "Test 3" approach
quoted below can be used as a temporary workaround in supported Squid
versions.

FWIW, Factory has a (large) project fixing bug 4906 and many similar
bugs. It is going through painful internal review cycles, but I hope we
will request an official review soon.


Cheers,

Alex.


> On 2020-07-28 15:01, Alex Rousskov wrote:
>> On 7/28/20 5:38 AM, amaury at tin.it wrote:
>>> thank for your suggestion.
>> That specific suggestion was not mine :-)
>>
>> For free Squid support, please keep the conversation on squid-users.
>>
>>
>>> I have tried with:
>>> acl noTransactionLvs src 10.xxx.xxx.xxx/32
>>> acl noTransactionLvs src 10.xxx.xxx.xxx/32
>>>
>>> acl hasRequest has request
>>> acl dontLog all-of !hasRequest noTransactionLvs
>>> access_log none dontLog
>>> and with
>>> acl noTransactionLvs src 10.xxx.xxx.xxx/32
>>> acl noTransactionLvs src 10.xxx.xxx.xxx/32
>>>
>>> access_log none noTransactionLvs
>>> access_log /var/log/squid4/access.log combined !noTransactionLvs
>>> but without result.
>>
>> What is your Squid version?
>>
>>
>> None of the configs below is the right long-term solution, but just for
>> testing purposes, please try these three tests:
>>
>> * Test 1 (should log nothing):
>>
>> ?? access_log none all
>> ?? # and no other access_log lines
>>
>>
>> * Test 2 (should also log nothing):
>>
>> ?? acl hasRequest has request
>> ?? access_log none !hasRequest
>> ?? access_log /var/log/squid4/access.log combined
>> ?? # and no other access_log lines
>>
>>
>> * Test 3 (should only log regular transactions):
>>
>> ?? acl hasRequest has request
>> ?? access_log none !hasRequest
>> ?? access_log /var/log/squid4/access.log combined
>> ?? # and no other access_log lines
>>
>> For each of the tests, please report whether regular transactions are
>> logged to /var/log/squid4/access.log _and_ whether the loadbalancer
>> probes are logged to /var/log/squid4/access.log
>>
>>
>> Thank you,
>>
>> Alex.
>>
>>
>>
>>> ----Messaggio originale----
>>> Da: rousskov at measurement-
>>> factory.com
>>> Data: 27-lug-2020 15.19
>>> A: "amaury at tin.it"<amaury at tin.it>,
>>> <squid-users at lists.squid-cache.org>
>>> Ogg: Re: [squid-users] filter
>>> NONE/000 NONE error:transaction-end-before-headers
>>>
>>> On 7/27/20 6:30 AM,
>>> amaury at tin.it wrote:
>>>
>>>> I would like to filter the message NONE/000
>>> NONE error:
>>>> transaction-end-before-headers - HIER_NONE/- - - HTTP/0.0
>>> "-" 0 0 that
>>>> it arrives from loadbalancer keep alived.
>>>
>>>> I have
>>> red that It was/is a bug.
>>>
>>> Those records are not a bug if your
>>> loadbalancer does open connections
>>> to Squid's http_port.
>>>
>>>
>>>> Please
>>> could you give me a
>>>> practical example example that how it works the:
>>>> # acl aclname note [-m[=delimiters]] name [value ...] ?
>>> The "note"
>>> ACL tests prior annotations. It is unlikely to help in your
>>> use case
>>> because nothing will be able to annotate these half-baked
>>> short-lived
>>> transactions until they are logged.
>>>
>>> Please see whether Amos' recent
>>> suggestion works for you:
>>>
>>> http://lists.squid-cache.org/pipermail/squid-users/2020-July/022461.html
>>>
>>>
>>> HTH,
>>>
>>> Alex.
>>>
>>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From contato at konntrol.com.br  Wed Jul 29 01:07:19 2020
From: contato at konntrol.com.br (Contato - KONNTROL)
Date: Tue, 28 Jul 2020 22:07:19 -0300
Subject: [squid-users] SQUID with cache_peer config + E2guardian - too many
 connections
Message-ID: <006601d66544$9c2d14f0$d4873ed0$@konntrol.com.br>

Hello Everyone,
Greetings.

Background:
OS - FreeBSD 12.1
SQUID ver 4.10
OpenSSL 1.0.2u

I am trying to use SQUID in front of E2Guardian (content filter) with the
following configuration at the SQUID side.

###
cache_peer 127.0.0.1 parent 8080 0 login=*:password
client_persistent_connections on
always_direct deny all
never_direct allow all
###

It works fine till the point  SQUID exhausts all E2Guardian threads/workers,
no matter the amount you set. If 1000, SQUID is opening 1000 connections. If
10.000, squid also opens 10.000 connections.
I tried the directive "client_persistent_connections on and off" with no
success.
Even using a single browser for testing purposes, for some reason SQUID
opens thousands of connections against the E2guardian.
I did a wireshark capture to "see" what is  happening and it seems like a
lot of ACK/SYN with no payload.

Any idea? Maybe I am using a wrong configuration.

By the way, I am using SQUID in front of E2Guardian cause I use Kerberos
authentication (not supported by E2guardian) with FORWARDX option enable.

Thanks In advance,

Cordially.
Fabricio.




From squid3 at treenet.co.nz  Wed Jul 29 02:50:11 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jul 2020 14:50:11 +1200
Subject: [squid-users] SQUID with cache_peer config + E2guardian - too
 many connections
In-Reply-To: <006601d66544$9c2d14f0$d4873ed0$@konntrol.com.br>
References: <006601d66544$9c2d14f0$d4873ed0$@konntrol.com.br>
Message-ID: <908969db-4b54-70a7-3758-a295d2f7f4a4@treenet.co.nz>

On 29/07/20 1:07 pm, Contato - KONNTROL wrote:
> Hello Everyone,
> Greetings.
> 
> Background:
> OS - FreeBSD 12.1
> SQUID ver 4.10
> OpenSSL 1.0.2u
> 
> I am trying to use SQUID in front of E2Guardian (content filter) with the
> following configuration at the SQUID side.
> 
> ###
> cache_peer 127.0.0.1 parent 8080 0 login=*:password
> client_persistent_connections on
> always_direct deny all
> never_direct allow all
> ###
> 
> It works fine till the point  SQUID exhausts all E2Guardian threads/workers,
> no matter the amount you set. If 1000, SQUID is opening 1000 connections. If
> 10.000, squid also opens 10.000 connections.
> I tried the directive "client_persistent_connections on and off" with no
> success.
> Even using a single browser for testing purposes, for some reason SQUID
> opens thousands of connections against the E2guardian.
> I did a wireshark capture to "see" what is  happening and it seems like a
> lot of ACK/SYN with no payload.
> 
> Any idea? Maybe I am using a wrong configuration.
> 

You are. BUT, I think you have a forwarding loop happening so the
correct config for limiting connections will not help.

You should be able to test for loops by enabling the Via header. If your
squid.conf contains "via off" remove that line. Assuming e2g is not
removing that header Squid will reject loops with an error message.


Check that the traffic leaving e2g is not going back into Squid. With
the setup described e2g should be connecting directly to
upstream/Internet servers - it should have no settings about Squid
except those for processing the X-Forwarded-For header.

If you are intercepting traffic to deliver it to Squid make sure the
connections leaving e2g are not being caught by those firewall rules.


If you are certain there is no loop the cache_peer max-conn=N is the way
to limit the connections made to a peer. This will only help if the
problem is high traffic flow. It will not help if there is a forwarding
loop happening.


> By the way, I am using SQUID in front of E2Guardian cause I use Kerberos
> authentication (not supported by E2guardian) with FORWARDX option enable.
> 

Sure. You may want to look at the features of e2g you are using and see
whether Squid can do them instead. The idea there being to make deny
decisions early as possible to minimize the total amount of processing
work those transactions consume.
 You may find you can get rid of e2g entirely, which will improve
overall performance and reduce management headaches from layers of proxy.


Cheers
Amos


From klaus_brandl at genua.de  Wed Jul 29 08:29:33 2020
From: klaus_brandl at genua.de (Klaus Brandl)
Date: Wed, 29 Jul 2020 10:29:33 +0200
Subject: [squid-users] SQUID with cache_peer config + E2guardian - too
 many connections
In-Reply-To: <908969db-4b54-70a7-3758-a295d2f7f4a4@treenet.co.nz>
References: <006601d66544$9c2d14f0$d4873ed0$@konntrol.com.br>
 <908969db-4b54-70a7-3758-a295d2f7f4a4@treenet.co.nz>
Message-ID: <3907751.zxWiKnfj9y@cairon>

On Wednesday 29 July 2020 14:50:11 Amos Jeffries wrote:
> On 29/07/20 1:07 pm, Contato - KONNTROL wrote:
> > Hello Everyone,
> > Greetings.
> > 
> > Background:
> > OS - FreeBSD 12.1
> > SQUID ver 4.10
> > OpenSSL 1.0.2u
> > 
> > I am trying to use SQUID in front of E2Guardian (content filter) with the
> > following configuration at the SQUID side.
> > 
> > ###
> > cache_peer 127.0.0.1 parent 8080 0 login=*:password
> > client_persistent_connections on
> > always_direct deny all
> > never_direct allow all
> > ###
> > 
> > It works fine till the point  SQUID exhausts all E2Guardian
> > threads/workers, no matter the amount you set. If 1000, SQUID is opening
> > 1000 connections. If 10.000, squid also opens 10.000 connections.
> > I tried the directive "client_persistent_connections on and off" with no
> > success.
> > Even using a single browser for testing purposes, for some reason SQUID
> > opens thousands of connections against the E2guardian.
> > I did a wireshark capture to "see" what is  happening and it seems like a
> > lot of ACK/SYN with no payload.
> > 
> > Any idea? Maybe I am using a wrong configuration.
> 
> You are. BUT, I think you have a forwarding loop happening so the
> correct config for limiting connections will not help.
> 
> You should be able to test for loops by enabling the Via header. If your
> squid.conf contains "via off" remove that line. Assuming e2g is not
> removing that header Squid will reject loops with an error message.

Setting an other "visible_hostname" may also help.

Klaus

---

genua GmbH
Domagkstrasse 7, 85551 Kirchheim bei Muenchen
tel +49 89 991950-0, fax -999, www.genua.de

Geschaeftsfuehrer: Matthias Ochs, Marc Tesch
Amtsgericht Muenchen HRB 98238
genua ist ein Unternehmen der Bundesdruckerei-Gruppe.


From squid3 at treenet.co.nz  Wed Jul 29 11:03:43 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jul 2020 23:03:43 +1200
Subject: [squid-users] SQUID with cache_peer config + E2guardian - too
 many connections
In-Reply-To: <3907751.zxWiKnfj9y@cairon>
References: <006601d66544$9c2d14f0$d4873ed0$@konntrol.com.br>
 <908969db-4b54-70a7-3758-a295d2f7f4a4@treenet.co.nz>
 <3907751.zxWiKnfj9y@cairon>
Message-ID: <b7df2455-44ba-e60a-7f60-064a0484010c@treenet.co.nz>

On 29/07/20 8:29 pm, Klaus Brandl wrote:
> 
> Setting an other "visible_hostname" may also help.
> 

Why do you think the hostname has any relation to the problem?

Amos


From klaus_brandl at genua.de  Wed Jul 29 11:58:55 2020
From: klaus_brandl at genua.de (Klaus Brandl)
Date: Wed, 29 Jul 2020 13:58:55 +0200
Subject: [squid-users] SQUID with cache_peer config + E2guardian - too
 many connections
In-Reply-To: <b7df2455-44ba-e60a-7f60-064a0484010c@treenet.co.nz>
References: <006601d66544$9c2d14f0$d4873ed0$@konntrol.com.br>
 <3907751.zxWiKnfj9y@cairon>
 <b7df2455-44ba-e60a-7f60-064a0484010c@treenet.co.nz>
Message-ID: <1937967.qLpGSdpPDY@cairon>

On Wednesday 29 July 2020 23:03:43 Amos Jeffries wrote:
> On 29/07/20 8:29 pm, Klaus Brandl wrote:
> > Setting an other "visible_hostname" may also help.
> 
> Why do you think the hostname has any relation to the problem?

because we had also a forwarding loop by connection 2 squids on the same host 
together via a parent statement. Then in the via header there was the same 
hostname 2 times, and this issued squid to detect a forwarding loop.
Setting an other visible_hostname on one of the squids solved this problem.

Klaus

---

genua GmbH
Domagkstrasse 7, 85551 Kirchheim bei Muenchen
tel +49 89 991950-0, fax -999, www.genua.de

Geschaeftsfuehrer: Matthias Ochs, Marc Tesch
Amtsgericht Muenchen HRB 98238
genua ist ein Unternehmen der Bundesdruckerei-Gruppe.


From uhlar at fantomas.sk  Wed Jul 29 12:11:02 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 29 Jul 2020 14:11:02 +0200
Subject: [squid-users] SQUID with cache_peer config + E2guardian - too
 many connections
In-Reply-To: <1937967.qLpGSdpPDY@cairon>
References: <006601d66544$9c2d14f0$d4873ed0$@konntrol.com.br>
 <3907751.zxWiKnfj9y@cairon>
 <b7df2455-44ba-e60a-7f60-064a0484010c@treenet.co.nz>
 <1937967.qLpGSdpPDY@cairon>
Message-ID: <20200729121102.GA21572@fantomas.sk>

>> On 29/07/20 8:29 pm, Klaus Brandl wrote:
>> > Setting an other "visible_hostname" may also help.

>On Wednesday 29 July 2020 23:03:43 Amos Jeffries wrote:
>> Why do you think the hostname has any relation to the problem?

On 29.07.20 13:58, Klaus Brandl wrote:
>because we had also a forwarding loop by connection 2 squids on the same host
>together via a parent statement. Then in the via header there was the same
>hostname 2 times, and this issued squid to detect a forwarding loop.
>Setting an other visible_hostname on one of the squids solved this problem.

there's a specific setting "unique_hostname" for these cases.

#  TAG: unique_hostname
#       If you want to have multiple machines with the same
#       'visible_hostname' you must give each machine a different
#       'unique_hostname' so forwarding loops can be detected.
#Default:
# Copy the value from visible_hostname


I just wonder why is this not set to $HOSTNAME by default, so setting same
visible_hostname on different servers would not require setting different
unique_hostname

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
The only substitute for good manners is fast reflexes.


From squid3 at treenet.co.nz  Wed Jul 29 12:24:52 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 30 Jul 2020 00:24:52 +1200
Subject: [squid-users] SQUID with cache_peer config + E2guardian - too
 many connections
In-Reply-To: <1937967.qLpGSdpPDY@cairon>
References: <006601d66544$9c2d14f0$d4873ed0$@konntrol.com.br>
 <3907751.zxWiKnfj9y@cairon>
 <b7df2455-44ba-e60a-7f60-064a0484010c@treenet.co.nz>
 <1937967.qLpGSdpPDY@cairon>
Message-ID: <562fb0a9-4198-dc95-04fd-c705184e13b4@treenet.co.nz>

On 29/07/20 11:58 pm, Klaus Brandl wrote:
> On Wednesday 29 July 2020 23:03:43 Amos Jeffries wrote:
>> On 29/07/20 8:29 pm, Klaus Brandl wrote:
>>> Setting an other "visible_hostname" may also help.
>>
>> Why do you think the hostname has any relation to the problem?
> 
> because we had also a forwarding loop by connection 2 squids on the same host 
> together via a parent statement. Then in the via header there was the same 
> hostname 2 times, and this issued squid to detect a forwarding loop.
> Setting an other visible_hostname on one of the squids solved this problem.>

In your situation the parent proxy was wrongly reporting loops since it
saw its own name coming out of the child proxy. That is not a real loop,
just a misconfiguration on your part to begin with.

NP: Klaus, unique_hostname is probably a better solution to your
problem. That lets loop detection work properly but both proxies send
URLs containing the shared visible_hostname to clients when they need to
reference proxy resources.


For this thread the OP has only one Squid and it is first in the proxy
chain.

For a loop to happen the peer must already be accepting traffic from
Squid with its current visible/public hostname. Only after that the
traffic might loop back to Squid to begin another circle. So setting the
Squid hostname to a different value will not stop any real loops, only
alter the string placed in the Via header each cycle.

Right now in the troubleshooting we are trying to get loops to show up
to see whether that is the hidden problem.

Amos


From klaus_brandl at genua.de  Wed Jul 29 12:37:16 2020
From: klaus_brandl at genua.de (Klaus Brandl)
Date: Wed, 29 Jul 2020 14:37:16 +0200
Subject: [squid-users] SQUID with cache_peer config + E2guardian - too
 many connections
In-Reply-To: <562fb0a9-4198-dc95-04fd-c705184e13b4@treenet.co.nz>
References: <006601d66544$9c2d14f0$d4873ed0$@konntrol.com.br>
 <1937967.qLpGSdpPDY@cairon>
 <562fb0a9-4198-dc95-04fd-c705184e13b4@treenet.co.nz>
Message-ID: <3413865.S5VLEreaBR@cairon>

On Thursday 30 July 2020 00:24:52 Amos Jeffries wrote:
> On 29/07/20 11:58 pm, Klaus Brandl wrote:
> > On Wednesday 29 July 2020 23:03:43 Amos Jeffries wrote:
> >> On 29/07/20 8:29 pm, Klaus Brandl wrote:
> >>> Setting an other "visible_hostname" may also help.
> >> 
> >> Why do you think the hostname has any relation to the problem?
> > 
> > because we had also a forwarding loop by connection 2 squids on the same
> > host together via a parent statement. Then in the via header there was
> > the same hostname 2 times, and this issued squid to detect a forwarding
> > loop. Setting an other visible_hostname on one of the squids solved this
> > problem.>
> In your situation the parent proxy was wrongly reporting loops since it
> saw its own name coming out of the child proxy. That is not a real loop,
> just a misconfiguration on your part to begin with.
> 
> NP: Klaus, unique_hostname is probably a better solution to your
> problem. That lets loop detection work properly but both proxies send
> URLs containing the shared visible_hostname to clients when they need to
> reference proxy resources.

ok, thank you, i will use this next time we have this problem.

> 
> 
> For this thread the OP has only one Squid and it is first in the proxy
> chain.

i saw the "cache_peer 127.0.0.1 parent 8080..." entry and it remembered me to 
our problem, sorry.

> 
> For a loop to happen the peer must already be accepting traffic from
> Squid with its current visible/public hostname. Only after that the
> traffic might loop back to Squid to begin another circle. So setting the
> Squid hostname to a different value will not stop any real loops, only
> alter the string placed in the Via header each cycle.
> 
> Right now in the troubleshooting we are trying to get loops to show up
> to see whether that is the hidden problem.
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Klaus

---

genua GmbH
Domagkstrasse 7, 85551 Kirchheim bei Muenchen
tel +49 89 991950-0, fax -999, www.genua.de

Geschaeftsfuehrer: Matthias Ochs, Marc Tesch
Amtsgericht Muenchen HRB 98238
genua ist ein Unternehmen der Bundesdruckerei-Gruppe.


From contato at konntrol.com.br  Wed Jul 29 14:33:04 2020
From: contato at konntrol.com.br (Contato - KONNTROL)
Date: Wed, 29 Jul 2020 11:33:04 -0300
Subject: [squid-users] SQUID with cache_peer config + E2guardian - too
 many connections
In-Reply-To: <3413865.S5VLEreaBR@cairon>
References: <006601d66544$9c2d14f0$d4873ed0$@konntrol.com.br>
 <1937967.qLpGSdpPDY@cairon>
 <562fb0a9-4198-dc95-04fd-c705184e13b4@treenet.co.nz>
 <3413865.S5VLEreaBR@cairon>
Message-ID: <006101d665b5$2ba94d90$82fbe8b0$@konntrol.com.br>

Thanks Amos, Klaus and Fantomas.
I already send another message with a lot of info and an attachment, that is now under moderator's review. If blocked, I will delete the attachment and send it again.

Thanks
Fabricio.


-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Klaus Brandl
Sent: Wednesday, July 29, 2020 9:37 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] SQUID with cache_peer config + E2guardian - too many connections

On Thursday 30 July 2020 00:24:52 Amos Jeffries wrote:
> On 29/07/20 11:58 pm, Klaus Brandl wrote:
> > On Wednesday 29 July 2020 23:03:43 Amos Jeffries wrote:
> >> On 29/07/20 8:29 pm, Klaus Brandl wrote:
> >>> Setting an other "visible_hostname" may also help.
> >> 
> >> Why do you think the hostname has any relation to the problem?
> > 
> > because we had also a forwarding loop by connection 2 squids on the 
> > same host together via a parent statement. Then in the via header 
> > there was the same hostname 2 times, and this issued squid to detect 
> > a forwarding loop. Setting an other visible_hostname on one of the 
> > squids solved this problem.>
> In your situation the parent proxy was wrongly reporting loops since 
> it saw its own name coming out of the child proxy. That is not a real 
> loop, just a misconfiguration on your part to begin with.
> 
> NP: Klaus, unique_hostname is probably a better solution to your 
> problem. That lets loop detection work properly but both proxies send 
> URLs containing the shared visible_hostname to clients when they need 
> to reference proxy resources.

ok, thank you, i will use this next time we have this problem.

> 
> 
> For this thread the OP has only one Squid and it is first in the proxy 
> chain.

i saw the "cache_peer 127.0.0.1 parent 8080..." entry and it remembered me to our problem, sorry.

> 
> For a loop to happen the peer must already be accepting traffic from 
> Squid with its current visible/public hostname. Only after that the 
> traffic might loop back to Squid to begin another circle. So setting 
> the Squid hostname to a different value will not stop any real loops, 
> only alter the string placed in the Via header each cycle.
> 
> Right now in the troubleshooting we are trying to get loops to show up 
> to see whether that is the hidden problem.
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Klaus

---

genua GmbH
Domagkstrasse 7, 85551 Kirchheim bei Muenchen tel +49 89 991950-0, fax -999, www.genua.de

Geschaeftsfuehrer: Matthias Ochs, Marc Tesch Amtsgericht Muenchen HRB 98238 genua ist ein Unternehmen der Bundesdruckerei-Gruppe.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From contato at konntrol.com.br  Wed Jul 29 14:50:20 2020
From: contato at konntrol.com.br (Contato - KONNTROL)
Date: Wed, 29 Jul 2020 11:50:20 -0300
Subject: [squid-users] SQUID with cache_peer config + E2guardian - too
 many connections
References: <006601d66544$9c2d14f0$d4873ed0$@konntrol.com.br>
 <908969db-4b54-70a7-3758-a295d2f7f4a4@treenet.co.nz> 
Message-ID: <000201d665b7$94e144a0$bea3cde0$@konntrol.com.br>

Hello Amos/Klaus/Fantomas,
Thanks for your help.

I have searched for the "via off"  and "via on" - The directive was not present on the config file but I am assuming "via on" it's the default option. Anyway I added it to the config file. No Success.
I also checked the visible_hostname, as suggested by Klaus (Thanks Klaus for the help!!) . It was set to localhost, then I changed to something different. No success as well.

So, I decided to make another test using Wireshark. For that, I put the squid down before starting the capture, then started Squid after capturing.
What I can see is squid sending thousands of requests (like a machine gun) against the E2G (loopback interface on port 8080) with thousands of "408 Request Time Out" entries.
I also see the following HTTP GET: "http://127.0.0.1:8080/squid-internal-dynamic/netdb"  by the way,  8080 is E2G port. Not sure what it is. The 408 above are probably because of this calling.

Attached you can see the capture file, just in case you have wireshark or any other software able to read .cap file. Don't worry, there is nothing confidential on the file. That's a LAB environment.
That is really confusing me.

Thank You very Much!

Regards
Fabricio.



-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Tuesday, July 28, 2020 11:50 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] SQUID with cache_peer config + E2guardian - too many connections

On 29/07/20 1:07 pm, Contato - KONNTROL wrote:
> Hello Everyone,
> Greetings.
> 
> Background:
> OS - FreeBSD 12.1
> SQUID ver 4.10
> OpenSSL 1.0.2u
> 
> I am trying to use SQUID in front of E2Guardian (content filter) with 
> the following configuration at the SQUID side.
> 
> ###
> cache_peer 127.0.0.1 parent 8080 0 login=*:password 
> client_persistent_connections on always_direct deny all never_direct 
> allow all ###
> 
> It works fine till the point  SQUID exhausts all E2Guardian 
> threads/workers, no matter the amount you set. If 1000, SQUID is 
> opening 1000 connections. If 10.000, squid also opens 10.000 connections.
> I tried the directive "client_persistent_connections on and off" with 
> no success.
> Even using a single browser for testing purposes, for some reason 
> SQUID opens thousands of connections against the E2guardian.
> I did a wireshark capture to "see" what is  happening and it seems 
> like a lot of ACK/SYN with no payload.
> 
> Any idea? Maybe I am using a wrong configuration.
> 

You are. BUT, I think you have a forwarding loop happening so the correct config for limiting connections will not help.

You should be able to test for loops by enabling the Via header. If your squid.conf contains "via off" remove that line. Assuming e2g is not removing that header Squid will reject loops with an error message.


Check that the traffic leaving e2g is not going back into Squid. With the setup described e2g should be connecting directly to upstream/Internet servers - it should have no settings about Squid except those for processing the X-Forwarded-For header.

If you are intercepting traffic to deliver it to Squid make sure the connections leaving e2g are not being caught by those firewall rules.


If you are certain there is no loop the cache_peer max-conn=N is the way to limit the connections made to a peer. This will only help if the problem is high traffic flow. It will not help if there is a forwarding loop happening.


> By the way, I am using SQUID in front of E2Guardian cause I use 
> Kerberos authentication (not supported by E2guardian) with FORWARDX option enable.
> 

Sure. You may want to look at the features of e2g you are using and see whether Squid can do them instead. The idea there being to make deny decisions early as possible to minimize the total amount of processing work those transactions consume.
 You may find you can get rid of e2g entirely, which will improve overall performance and reduce management headaches from layers of proxy.


Cheers
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Squid_E2G_Loopback_Capture.zip
Type: application/x-zip-compressed
Size: 46988 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200729/e78dbafb/attachment.bin>

From klaus_brandl at genua.de  Wed Jul 29 15:27:16 2020
From: klaus_brandl at genua.de (Klaus Brandl)
Date: Wed, 29 Jul 2020 17:27:16 +0200
Subject: [squid-users] SQUID with cache_peer config + E2guardian - too
 many connections
In-Reply-To: <000201d665b7$94e144a0$bea3cde0$@konntrol.com.br>
References: <006601d66544$9c2d14f0$d4873ed0$@konntrol.com.br>
 <908969db-4b54-70a7-3758-a295d2f7f4a4@treenet.co.nz>
 <000201d665b7$94e144a0$bea3cde0$@konntrol.com.br>
Message-ID: <4143278.v3S3GTx8OB@cairon>

tried to add the option "no-netdb-exchange" on your cache_peer line?

On Wednesday 29 July 2020 11:50:20 Contato - KONNTROL wrote:
> Hello Amos/Klaus/Fantomas,
> Thanks for your help.
> 
> I have searched for the "via off"  and "via on" - The directive was not
> present on the config file but I am assuming "via on" it's the default
> option. Anyway I added it to the config file. No Success. I also checked
> the visible_hostname, as suggested by Klaus (Thanks Klaus for the help!!) .
> It was set to localhost, then I changed to something different. No success
> as well.
> 
> So, I decided to make another test using Wireshark. For that, I put the
> squid down before starting the capture, then started Squid after capturing.
> What I can see is squid sending thousands of requests (like a machine gun)
> against the E2G (loopback interface on port 8080) with thousands of "408
> Request Time Out" entries. I also see the following HTTP GET:
> "http://127.0.0.1:8080/squid-internal-dynamic/netdb"  by the way,  8080 is
> E2G port. Not sure what it is. The 408 above are probably because of this
> calling.
> 
> Attached you can see the capture file, just in case you have wireshark or
> any other software able to read .cap file. Don't worry, there is nothing
> confidential on the file. That's a LAB environment. That is really
> confusing me.
> 
> Thank You very Much!
> 
> Regards
> Fabricio.
> 
> 

Klaus

---

genua GmbH
Domagkstrasse 7, 85551 Kirchheim bei Muenchen
tel +49 89 991950-0, fax -999, www.genua.de

Geschaeftsfuehrer: Matthias Ochs, Marc Tesch
Amtsgericht Muenchen HRB 98238
genua ist ein Unternehmen der Bundesdruckerei-Gruppe.


From ryanlele264 at gmail.com  Wed Jul 29 15:38:08 2020
From: ryanlele264 at gmail.com (Ryan Le)
Date: Wed, 29 Jul 2020 11:38:08 -0400
Subject: [squid-users] Squid and multipart form decode
In-Reply-To: <CANqqF0pBoEyZrsZLXSMgVMtnFxQBDLiogBKgMky1meRBEiysDg@mail.gmail.com>
References: <CANqqF0qJ_LNLcWNk_pt3Xpz2bf=P1z3ws4TBnYVfb4-V8oS9hg@mail.gmail.com>
 <6388ee6b-dcf7-a67b-73ee-ce47db7a61dc@measurement-factory.com>
 <CANqqF0pBoEyZrsZLXSMgVMtnFxQBDLiogBKgMky1meRBEiysDg@mail.gmail.com>
Message-ID: <CANqqF0pUoRBn1L6Dq9Tyb-yjHSP4Kvn6UCh2OTezF2tUkJTd+g@mail.gmail.com>

Even though it looks like TeChunkedParser is getting all the
additional headers I can't seem to create ACL or output them using
logformat. I was trying to request these headers with
req_mime_type/resp_mime_type. and alos had log_mime_hdrs on and then in
logformat just had all.

On Thu, Jul 23, 2020 at 11:46 AM Ryan Le <ryanlele264 at gmail.com> wrote:

> Thanks,
>
> I have been looking at the squid debug and can see that it is getting the
> multipart.
>
> POST http://bbbbbb.com
> User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:78.0)
> Gecko/20100101 Firefox/78.0
> Accept: application/json
> Accept-Language: en-US,en;q=0.5
> Accept-Encoding: gzip, deflate
> Referer: http://bbbbb.com
> Cache-Control: no-cache
> X-Requested-With: XMLHttpRequest
> Content-Type: multipart/form-data;
> boundary=---------------------------328901485836611227811186534509
> Content-Length: 1245
> Origin: http://bbbbb.com
> Cookie: cookie
> Host: bbbbbbb.com
> Via: ICAP/1.0
>
> 4dd
> -----------------------------328901485836611227811186534509
> Content-Disposition: form-data; name="action"
>
> frm_submit_dropzone
> -----------------------------328901485836611227811186534509
> Content-Disposition: form-data; name="field_id"
>
> 8
> -----------------------------328901485836611227811186534509
> Content-Disposition: form-data; name="form_id"
>
> 5
> -----------------------------328901485836611227811186534509
> Content-Disposition: form-data; name="nonce"
>
> e1aca92777
> -----------------------------328901485836611227811186534509
> Content-Disposition: form-data; name="file8"; filename="translate.zip"
> Content-Type: application/x-zip-compressed
>
> On Thu, Jul 23, 2020 at 11:16 AM Alex Rousskov <
> rousskov at measurement-factory.com> wrote:
>
>> On 7/23/20 9:22 AM, Ryan Le wrote:
>> > I have been trying to configure squid to decode and send multipart form
>> > data to another service. Is there an acl or build parameter needed for
>> > multipart form data support?
>>
>> No, there is no need to allow any specific Content-Type, including
>> multipart. Squid does not know anything about multipart/form-data. If a
>> multipart/form-data message is well-formed from HTTP point of view, then
>> Squid will process it as any other message, including passing it to
>> ICAP/eCAP (where configured).
>>
>> Cheers,
>>
>> Alex.
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200729/a3598320/attachment.htm>

From rousskov at measurement-factory.com  Wed Jul 29 16:16:15 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 29 Jul 2020 12:16:15 -0400
Subject: [squid-users] Squid and multipart form decode
In-Reply-To: <CANqqF0pUoRBn1L6Dq9Tyb-yjHSP4Kvn6UCh2OTezF2tUkJTd+g@mail.gmail.com>
References: <CANqqF0qJ_LNLcWNk_pt3Xpz2bf=P1z3ws4TBnYVfb4-V8oS9hg@mail.gmail.com>
 <6388ee6b-dcf7-a67b-73ee-ce47db7a61dc@measurement-factory.com>
 <CANqqF0pBoEyZrsZLXSMgVMtnFxQBDLiogBKgMky1meRBEiysDg@mail.gmail.com>
 <CANqqF0pUoRBn1L6Dq9Tyb-yjHSP4Kvn6UCh2OTezF2tUkJTd+g@mail.gmail.com>
Message-ID: <b3b8f9ad-e46a-2c64-5502-1c9864ed047c@measurement-factory.com>

On 7/29/20 11:38 AM, Ryan Le wrote:
> Even though it looks like TeChunkedParser is getting all the
> additional?headers 

TeChunkedParser has nothing to do with multipart/form-data bodies.
TeChunkedParser parses chunked encoding, and even then it is applied to
remove _transfer_ encoding, not to interpret the actual resource content
inside the chunks.

I am not sure, but it looks like you have pasted a part of an ICAP
message. TeChunkedParser is used to parse chunked transfer encoding used
for a part of the ICAP message body. Beyond decoding those chunks, it is
all opaque data to Squid.

To avoid misunderstanding, in your pasted example, the contents of the
first chunk starts with these two lines:

> -----------------------------328901485836611227811186534509
> Content-Disposition: form-data; name="action"

It does _not_ start with the "Content-Disposition:..." line or the
"frm_submit_dropzone" line.


> I can't seem to create ACL or output them using
> logformat. I was trying to request these headers with
> req_mime_type/resp_mime_type. 

If by "them" you mean MIME headers inside multipart parts, then Squid
does not see them and does not operate on them. The insides of each
chunk is opaque data to Squid.


> and alos had log_mime_hdrs on and then in
> logformat just had all.

You should be able to log the HTTP request header values using %>h or
%>ha. You will not be able to log or match any message body snippets,
including things like MIME Content-Disposition values. Squid does not
look inside the body of the POSTed resource.


If you need further help, you may want to clarify what you are trying to
achieve. You said "send multipart form data to another service". Are you
trying to _route_ request messages based on multipart form _contents_?


HTH,

Alex.


> On Thu, Jul 23, 2020 at 11:46 AM Ryan Le wrote:
> 
>     Thanks,?
> 
>     I have been looking at the squid debug and can see that it is
>     getting the multipart.
> 
>     POST http://bbbbbb.com
>     User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:78.0)
>     Gecko/20100101 Firefox/78.0
>     Accept: application/json
>     Accept-Language: en-US,en;q=0.5
>     Accept-Encoding: gzip, deflate
>     Referer: http://bbbbb.com
>     Cache-Control: no-cache
>     X-Requested-With: XMLHttpRequest
>     Content-Type: multipart/form-data;
>     boundary=---------------------------328901485836611227811186534509
>     Content-Length: 1245
>     Origin: http://bbbbb.com
>     Cookie: cookie
>     Host: bbbbbbb.com <http://bbbbbbb.com>
>     Via: ICAP/1.0?
> 
>     4dd
>     -----------------------------328901485836611227811186534509
>     Content-Disposition: form-data; name="action"
> 
>     frm_submit_dropzone
>     -----------------------------328901485836611227811186534509
>     Content-Disposition: form-data; name="field_id"
> 
>     8
>     -----------------------------328901485836611227811186534509
>     Content-Disposition: form-data; name="form_id"
> 
>     5
>     -----------------------------328901485836611227811186534509
>     Content-Disposition: form-data; name="nonce"
> 
>     e1aca92777
>     -----------------------------328901485836611227811186534509
>     Content-Disposition: form-data; name="file8"; filename="translate.zip"
>     Content-Type: application/x-zip-compressed
> 
>     On Thu, Jul 23, 2020 at 11:16 AM Alex Rousskov
>     <rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>> wrote:
> 
>         On 7/23/20 9:22 AM, Ryan Le wrote:
>         > I have been trying to configure squid to decode and send
>         multipart form
>         > data to another service. Is there an acl or build parameter
>         needed for
>         > multipart form data support?
> 
>         No, there is no need to allow any specific Content-Type, including
>         multipart. Squid does not know anything about
>         multipart/form-data. If a
>         multipart/form-data message is well-formed from HTTP point of
>         view, then
>         Squid will process it as any other message, including passing it to
>         ICAP/eCAP (where configured).
> 
>         Cheers,
> 
>         Alex.
> 



From contato at konntrol.com.br  Wed Jul 29 16:36:40 2020
From: contato at konntrol.com.br (Contato - KONNTROL)
Date: Wed, 29 Jul 2020 13:36:40 -0300
Subject: [squid-users] SQUID with cache_peer config + E2guardian - too
 many connections - RESOLVED
Message-ID: <001b01d665c6$723f7660$56be6320$@konntrol.com.br>

Klaus, You got it!  Thanks a lot!!

I just added the directive like:  

cache_peer 127.0.0.1 parent 8080 0 login=*:password no-netdb-exchange
always_direct deny all
never_direct allow all

It worked fine now.  All those thousands of connections disappeared.
Just curious what is that "option" of "netdb-exchange".  Where can I find further info about it?

Thanks everyone!! Closed-Resolved.
Fabricio.




-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Klaus Brandl
Sent: Wednesday, July 29, 2020 12:27 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] SQUID with cache_peer config + E2guardian - too many connections

tried to add the option "no-netdb-exchange" on your cache_peer line?

On Wednesday 29 July 2020 11:50:20 Contato - KONNTROL wrote:
> Hello Amos/Klaus/Fantomas,
> Thanks for your help.
> 
> I have searched for the "via off"  and "via on" - The directive was 
> not present on the config file but I am assuming "via on" it's the 
> default option. Anyway I added it to the config file. No Success. I 
> also checked the visible_hostname, as suggested by Klaus (Thanks Klaus for the help!!) .
> It was set to localhost, then I changed to something different. No 
> success as well.
> 
> So, I decided to make another test using Wireshark. For that, I put 
> the squid down before starting the capture, then started Squid after capturing.
> What I can see is squid sending thousands of requests (like a machine 
> gun) against the E2G (loopback interface on port 8080) with thousands 
> of "408 Request Time Out" entries. I also see the following HTTP GET:
> "http://127.0.0.1:8080/squid-internal-dynamic/netdb"  by the way,  
> 8080 is E2G port. Not sure what it is. The 408 above are probably 
> because of this calling.
> 
> Attached you can see the capture file, just in case you have wireshark 
> or any other software able to read .cap file. Don't worry, there is 
> nothing confidential on the file. That's a LAB environment. That is 
> really confusing me.
> 
> Thank You very Much!
> 
> Regards
> Fabricio.
> 
> 

Klaus

---

genua GmbH
Domagkstrasse 7, 85551 Kirchheim bei Muenchen tel +49 89 991950-0, fax -999, www.genua.de

Geschaeftsfuehrer: Matthias Ochs, Marc Tesch Amtsgericht Muenchen HRB 98238 genua ist ein Unternehmen der Bundesdruckerei-Gruppe.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From ryanlele264 at gmail.com  Wed Jul 29 16:47:40 2020
From: ryanlele264 at gmail.com (Ryan Le)
Date: Wed, 29 Jul 2020 12:47:40 -0400
Subject: [squid-users] Squid and multipart form decode
In-Reply-To: <b3b8f9ad-e46a-2c64-5502-1c9864ed047c@measurement-factory.com>
References: <CANqqF0qJ_LNLcWNk_pt3Xpz2bf=P1z3ws4TBnYVfb4-V8oS9hg@mail.gmail.com>
 <6388ee6b-dcf7-a67b-73ee-ce47db7a61dc@measurement-factory.com>
 <CANqqF0pBoEyZrsZLXSMgVMtnFxQBDLiogBKgMky1meRBEiysDg@mail.gmail.com>
 <CANqqF0pUoRBn1L6Dq9Tyb-yjHSP4Kvn6UCh2OTezF2tUkJTd+g@mail.gmail.com>
 <b3b8f9ad-e46a-2c64-5502-1c9864ed047c@measurement-factory.com>
Message-ID: <CANqqF0pwh8XxkyXWzPjsHoXEyHenm+_Ws-5W+6o2DpgLJ-tYEQ@mail.gmail.com>

I do apologize I do not have logs of that specific file but I have an
example from the same site and doing the same post.

> Even though it looks like TeChunkedParser is getting all the
> additional headers

>TeChunkedParser has nothing to do with multipart/form-data bodies.
>TeChunkedParser parses chunked encoding, and even then it is applied to
>remove _transfer_ encoding, not to interpret the actual resource content
>inside the chunks.

I do see it in two locations.

2020/07/26 23:11:12.921 kid6| 74,9| TeChunkedParser.cc(45) parse: Parse
buf={length=3667, data='e47
-----------------------------351645264024548376901231954897
Content-Disposition: form-data; name="action"

frm_submit_dropzone
-----------------------------351645264024548376901231954897
Content-Disposition: form-data; name="field_id"

8
-----------------------------351645264024548376901231954897
Content-Disposition: form-data; name="form_id"

5
-----------------------------351645264024548376901231954897
Content-Disposition: form-data; name="nonce"

6bb20c0bd7
-----------------------------351645264024548376901231954897
Content-Disposition: form-data; name="file8"; filename="file.zip"
Content-Type: application/x-zip-compressed

As well as the following location

2020/07/26 23:11:12.921 kid6| 58,9| HttpMsg.cc(198) parse: HttpMsg::parse
success (689 bytes) near 'POST http://bbbb.com/post HTTP/1.1
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:78.0)
Gecko/20100101 Firefox/78.0
Accept: application/json
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
Cache-Control: no-cache
X-Requested-With: XMLHttpRequest
Content-Type: multipart/form-data;
boundary=---------------------------351645264024548376901231954897
Content-Length: 3655
Origin: http://bbbbbb.com
Referer: http://bbbbb.com.com/http-post/
Cookie: _ga=GA1.2.1194289608.1595640198; _gid=GA1.2.252592555.1595804428;
_gat_gtag_UA_47458108_3=1
Host: bbbbbbb.com
Via: ICAP/1.0 (C-ICAP/0.5.6 ICAP service )

e47
-----------------------------351645264024548376901231954897
Content-Disposition: form-data; name="action"

frm_submit_dropzone
-----------------------------351645264024548376901231954897
Content-Disposition: form-data; name="field_id"

8
-----------------------------351645264024548376901231954897
Content-Disposition: form-data; name="form_id"

5
-----------------------------351645264024548376901231954897
Content-Disposition: form-data; name="nonce"

6bb20c0bd7
-----------------------------351645264024548376901231954897
Content-Disposition: form-data; name="file8"; filename="file.zip"
Content-Type: application/x-zip-compressed


>I am not sure, but it looks like you have pasted a part of an ICAP
>message. TeChunkedParser is used to parse chunked transfer encoding used
>for a part of the ICAP message body. Beyond decoding those chunks, it is
>all opaque data to Squid.

Thanks for that information.


>To avoid misunderstanding, in your pasted example, the contents of the
>first chunk starts with these two lines:

> -----------------------------328901485836611227811186534509
> Content-Disposition: form-data; name="action"

>It does _not_ start with the "Content-Disposition:..." line or the
>"frm_submit_dropzone" line.


> I can't seem to create ACL or output them using
> logformat. I was trying to request these headers with
> req_mime_type/resp_mime_type.

>If by "them" you mean MIME headers inside multipart parts, then Squid
>does not see them and does not operate on them. The insides of each
>chunk is opaque data to Squid.


> and also had log_mime_hdrs on and then in
> logformat just had all.

>You should be able to log the HTTP request header values using %>h or
>%>ha. You will not be able to log or match any message body snippets,
>including things like MIME Content-Disposition values. Squid does not
>look inside the body of the POSTed resource.

I will test with the two examples given and see what they return.


>If you need further help, you may want to clarify what you are trying to
>achieve. You said "send multipart form data to another service". Are you
>trying to _route_ request messages based on multipart form _contents_?

What I am ultimately trying to accomplish is to see the best way to get
more detail and have an action on sites
that are posting using multipart/form-data as the Content-Type header. This
is mainly to separate action taken on an actual form being submitted
versus a file being submitted or as you stated route request messages based
on the content.
Whether that be logformat with headers and passing the headers to a custom
external service or within squid itself.

On Wed, Jul 29, 2020 at 12:16 PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 7/29/20 11:38 AM, Ryan Le wrote:
> > Even though it looks like TeChunkedParser is getting all the
> > additional headers
>
> TeChunkedParser has nothing to do with multipart/form-data bodies.
> TeChunkedParser parses chunked encoding, and even then it is applied to
> remove _transfer_ encoding, not to interpret the actual resource content
> inside the chunks.
>
> I am not sure, but it looks like you have pasted a part of an ICAP
> message. TeChunkedParser is used to parse chunked transfer encoding used
> for a part of the ICAP message body. Beyond decoding those chunks, it is
> all opaque data to Squid.
>
> To avoid misunderstanding, in your pasted example, the contents of the
> first chunk starts with these two lines:
>
> > -----------------------------328901485836611227811186534509
> > Content-Disposition: form-data; name="action"
>
> It does _not_ start with the "Content-Disposition:..." line or the
> "frm_submit_dropzone" line.
>
>
> > I can't seem to create ACL or output them using
> > logformat. I was trying to request these headers with
> > req_mime_type/resp_mime_type.
>
> If by "them" you mean MIME headers inside multipart parts, then Squid
> does not see them and does not operate on them. The insides of each
> chunk is opaque data to Squid.
>
>
> > and alos had log_mime_hdrs on and then in
> > logformat just had all.
>
> You should be able to log the HTTP request header values using %>h or
> %>ha. You will not be able to log or match any message body snippets,
> including things like MIME Content-Disposition values. Squid does not
> look inside the body of the POSTed resource.
>
>
> If you need further help, you may want to clarify what you are trying to
> achieve. You said "send multipart form data to another service". Are you
> trying to _route_ request messages based on multipart form _contents_?
>
>
> HTH,
>
> Alex.
>
>
> > On Thu, Jul 23, 2020 at 11:46 AM Ryan Le wrote:
> >
> >     Thanks,
> >
> >     I have been looking at the squid debug and can see that it is
> >     getting the multipart.
> >
> >     POST http://bbbbbb.com
> >     User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:78.0)
> >     Gecko/20100101 Firefox/78.0
> >     Accept: application/json
> >     Accept-Language: en-US,en;q=0.5
> >     Accept-Encoding: gzip, deflate
> >     Referer: http://bbbbb.com
> >     Cache-Control: no-cache
> >     X-Requested-With: XMLHttpRequest
> >     Content-Type: multipart/form-data;
> >     boundary=---------------------------328901485836611227811186534509
> >     Content-Length: 1245
> >     Origin: http://bbbbb.com
> >     Cookie: cookie
> >     Host: bbbbbbb.com <http://bbbbbbb.com>
> >     Via: ICAP/1.0
> >
> >     4dd
> >     -----------------------------328901485836611227811186534509
> >     Content-Disposition: form-data; name="action"
> >
> >     frm_submit_dropzone
> >     -----------------------------328901485836611227811186534509
> >     Content-Disposition: form-data; name="field_id"
> >
> >     8
> >     -----------------------------328901485836611227811186534509
> >     Content-Disposition: form-data; name="form_id"
> >
> >     5
> >     -----------------------------328901485836611227811186534509
> >     Content-Disposition: form-data; name="nonce"
> >
> >     e1aca92777
> >     -----------------------------328901485836611227811186534509
> >     Content-Disposition: form-data; name="file8";
> filename="translate.zip"
> >     Content-Type: application/x-zip-compressed
> >
> >     On Thu, Jul 23, 2020 at 11:16 AM Alex Rousskov
> >     <rousskov at measurement-factory.com
> >     <mailto:rousskov at measurement-factory.com>> wrote:
> >
> >         On 7/23/20 9:22 AM, Ryan Le wrote:
> >         > I have been trying to configure squid to decode and send
> >         multipart form
> >         > data to another service. Is there an acl or build parameter
> >         needed for
> >         > multipart form data support?
> >
> >         No, there is no need to allow any specific Content-Type,
> including
> >         multipart. Squid does not know anything about
> >         multipart/form-data. If a
> >         multipart/form-data message is well-formed from HTTP point of
> >         view, then
> >         Squid will process it as any other message, including passing it
> to
> >         ICAP/eCAP (where configured).
> >
> >         Cheers,
> >
> >         Alex.
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200729/64679e12/attachment.htm>

From rousskov at measurement-factory.com  Wed Jul 29 17:49:41 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 29 Jul 2020 13:49:41 -0400
Subject: [squid-users] Squid and multipart form decode
In-Reply-To: <CANqqF0pwh8XxkyXWzPjsHoXEyHenm+_Ws-5W+6o2DpgLJ-tYEQ@mail.gmail.com>
References: <CANqqF0qJ_LNLcWNk_pt3Xpz2bf=P1z3ws4TBnYVfb4-V8oS9hg@mail.gmail.com>
 <6388ee6b-dcf7-a67b-73ee-ce47db7a61dc@measurement-factory.com>
 <CANqqF0pBoEyZrsZLXSMgVMtnFxQBDLiogBKgMky1meRBEiysDg@mail.gmail.com>
 <CANqqF0pUoRBn1L6Dq9Tyb-yjHSP4Kvn6UCh2OTezF2tUkJTd+g@mail.gmail.com>
 <b3b8f9ad-e46a-2c64-5502-1c9864ed047c@measurement-factory.com>
 <CANqqF0pwh8XxkyXWzPjsHoXEyHenm+_Ws-5W+6o2DpgLJ-tYEQ@mail.gmail.com>
Message-ID: <7f759101-c7e3-f07c-9564-4c6bfd2c4d1a@measurement-factory.com>

On 7/29/20 12:47 PM, Ryan Le wrote:

>>> Even though it looks like TeChunkedParser is getting all the
>>> additional?headers

>> TeChunkedParser has nothing to do with multipart/form-data bodies.

> I do see it in two locations.

> 2020/07/26 23:11:12.921 kid6| 74,9| TeChunkedParser.cc(45) parse: Parse
> buf={length=3667, data='e47
> -----------------------------351645264024548376901231954897
> Content-Disposition: form-data; name="action"
...

You see the parser reporting the raw input buffer that it is about to
parse. The parser will treat everything you see after the first "e47"
line (which specifies the chunk size in hex) as opaque body bytes (until
the start of the next chunk metadata).


> As well as the following location

> 2020/07/26 23:11:12.921 kid6| 58,9| HttpMsg.cc(198) parse:
> HttpMsg::parse success (689 bytes) near 'POST http://bbbb.com/post HTTP/1.1
> User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:78.0)
...

Same problem. It is just a raw input buffer dump.


> What I am ultimately trying to accomplish is to see the best way to get
> more detail and have an action on sites?
> that are posting using multipart/form-data as the Content-Type header.

ACL-driven actions based on the Content-Type header value should work
fine. Logging of the Content-Type header value to access.log should work
fine.  If something does not work, please provide a specific non-working
configuration example.

Some of your earlier messages sounded like you want Squid to act based
on MIME headers inside the message body or even the values of HTML form
entries. Squid cannot do that on its own. To analyze message bodies
(even in read-only mode), you will need a custom ICAP or eCAP service:
https://wiki.squid-cache.org/SquidFaq/ContentAdaptation


HTH,

Alex.



> On Wed, Jul 29, 2020 at 12:16 PM Alex Rousskov wrote:
> 
>     On 7/29/20 11:38 AM, Ryan Le wrote:
>     > Even though it looks like TeChunkedParser is getting all the
>     > additional?headers
> 
>     TeChunkedParser has nothing to do with multipart/form-data bodies.
>     TeChunkedParser parses chunked encoding, and even then it is applied to
>     remove _transfer_ encoding, not to interpret the actual resource content
>     inside the chunks.
> 
>     I am not sure, but it looks like you have pasted a part of an ICAP
>     message. TeChunkedParser is used to parse chunked transfer encoding used
>     for a part of the ICAP message body. Beyond decoding those chunks, it is
>     all opaque data to Squid.
> 
>     To avoid misunderstanding, in your pasted example, the contents of the
>     first chunk starts with these two lines:
> 
>     > -----------------------------328901485836611227811186534509
>     > Content-Disposition: form-data; name="action"
> 
>     It does _not_ start with the "Content-Disposition:..." line or the
>     "frm_submit_dropzone" line.
> 
> 
>     > I can't seem to create ACL or output them using
>     > logformat. I was trying to request these headers with
>     > req_mime_type/resp_mime_type.
> 
>     If by "them" you mean MIME headers inside multipart parts, then Squid
>     does not see them and does not operate on them. The insides of each
>     chunk is opaque data to Squid.
> 
> 
>     > and alos had log_mime_hdrs on and then in
>     > logformat just had all.
> 
>     You should be able to log the HTTP request header values using %>h or
>     %>ha. You will not be able to log or match any message body snippets,
>     including things like MIME Content-Disposition values. Squid does not
>     look inside the body of the POSTed resource.
> 
> 
>     If you need further help, you may want to clarify what you are trying to
>     achieve. You said "send multipart form data to another service". Are you
>     trying to _route_ request messages based on multipart form _contents_?
> 
> 
>     HTH,
> 
>     Alex.
> 
> 
>     > On Thu, Jul 23, 2020 at 11:46 AM Ryan Le wrote:
>     >
>     >? ? ?Thanks,?
>     >
>     >? ? ?I have been looking at the squid debug and can see that it is
>     >? ? ?getting the multipart.
>     >
>     >? ? ?POST http://bbbbbb.com
>     >? ? ?User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:78.0)
>     >? ? ?Gecko/20100101 Firefox/78.0
>     >? ? ?Accept: application/json
>     >? ? ?Accept-Language: en-US,en;q=0.5
>     >? ? ?Accept-Encoding: gzip, deflate
>     >? ? ?Referer: http://bbbbb.com
>     >? ? ?Cache-Control: no-cache
>     >? ? ?X-Requested-With: XMLHttpRequest
>     >? ? ?Content-Type: multipart/form-data;
>     >? ? ?boundary=---------------------------328901485836611227811186534509
>     >? ? ?Content-Length: 1245
>     >? ? ?Origin: http://bbbbb.com
>     >? ? ?Cookie: cookie
>     >? ? ?Host: bbbbbbb.com <http://bbbbbbb.com> <http://bbbbbbb.com>
>     >? ? ?Via: ICAP/1.0?
>     >
>     >? ? ?4dd
>     >? ? ?-----------------------------328901485836611227811186534509
>     >? ? ?Content-Disposition: form-data; name="action"
>     >
>     >? ? ?frm_submit_dropzone
>     >? ? ?-----------------------------328901485836611227811186534509
>     >? ? ?Content-Disposition: form-data; name="field_id"
>     >
>     >? ? ?8
>     >? ? ?-----------------------------328901485836611227811186534509
>     >? ? ?Content-Disposition: form-data; name="form_id"
>     >
>     >? ? ?5
>     >? ? ?-----------------------------328901485836611227811186534509
>     >? ? ?Content-Disposition: form-data; name="nonce"
>     >
>     >? ? ?e1aca92777
>     >? ? ?-----------------------------328901485836611227811186534509
>     >? ? ?Content-Disposition: form-data; name="file8";
>     filename="translate.zip"
>     >? ? ?Content-Type: application/x-zip-compressed
>     >
>     >? ? ?On Thu, Jul 23, 2020 at 11:16 AM Alex Rousskov
>     >? ? ?<rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>
>     >? ? ?<mailto:rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>>> wrote:
>     >
>     >? ? ? ? ?On 7/23/20 9:22 AM, Ryan Le wrote:
>     >? ? ? ? ?> I have been trying to configure squid to decode and send
>     >? ? ? ? ?multipart form
>     >? ? ? ? ?> data to another service. Is there an acl or build parameter
>     >? ? ? ? ?needed for
>     >? ? ? ? ?> multipart form data support?
>     >
>     >? ? ? ? ?No, there is no need to allow any specific Content-Type,
>     including
>     >? ? ? ? ?multipart. Squid does not know anything about
>     >? ? ? ? ?multipart/form-data. If a
>     >? ? ? ? ?multipart/form-data message is well-formed from HTTP point of
>     >? ? ? ? ?view, then
>     >? ? ? ? ?Squid will process it as any other message, including
>     passing it to
>     >? ? ? ? ?ICAP/eCAP (where configured).
>     >
>     >? ? ? ? ?Cheers,
>     >
>     >? ? ? ? ?Alex.
>     >
> 



From doconnor at transsee.ca  Wed Jul 29 22:34:05 2020
From: doconnor at transsee.ca (Darwin O'Connor)
Date: Wed, 29 Jul 2020 18:34:05 -0400
Subject: [squid-users] Caching https data
Message-ID: <ce708a9b-9395-1b7f-3b2f-f6c5419f08b6@transsee.ca>

I run a transit prediction web app <https://www.transsee.ca/>. It 
connects to a variety of web APIs to collect the real time data it 
needs. The apps activities are split among many processes. They 
currently uses libcurl to connect to squid for caching (often for as 
little as 10-30 seconds) and benefits of connection sharing, but some of 
the APIs use https, so in that case the data passes through squid 
without the benefits of caching or connection sharing.

I would like to configure squid to connect to these servers securely and 
pass it unencrypted to clients. Security isn't really an issue since 
this step is all within the one server. I'll have to configure libcurl 
to allow unencrypted data.



From squid3 at treenet.co.nz  Thu Jul 30 09:11:02 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 30 Jul 2020 21:11:02 +1200
Subject: [squid-users] Caching https data
In-Reply-To: <ce708a9b-9395-1b7f-3b2f-f6c5419f08b6@transsee.ca>
References: <ce708a9b-9395-1b7f-3b2f-f6c5419f08b6@transsee.ca>
Message-ID: <e4416845-a5a6-64ca-b434-812344b3c8c5@treenet.co.nz>

On 30/07/20 10:34 am, Darwin O'Connor wrote:
> I run a transit prediction web app <https://www.transsee.ca/>. It
> connects to a variety of web APIs to collect the real time data it
> needs. The apps activities are split among many processes. They
> currently uses libcurl to connect to squid for caching (often for as
> little as 10-30 seconds) and benefits of connection sharing, but some of
> the APIs use https, so in that case the data passes through squid
> without the benefits of caching or connection sharing.
> 
> I would like to configure squid to connect to these servers securely and
> pass it unencrypted to clients. Security isn't really an issue since
> this step is all within the one server. I'll have to configure libcurl
> to allow unencrypted data.
> 

There are several approaches you can take;

1) configure libcurl and/or the apps to send https:// URLs to Squid in
regular HTTP requests. Leaving Squid to handle all the HTTPS portion.
  <>


2) configure libcurl and/or the apps to send https:// URLs to a Squid
secure listening port (https_port) in regular HTTP requests. Leaving
Squid to handle all the HTTPS portion with servers. I'm not sure about
libcurl, but some clients allow this when they prohibit (1) because it
is somewhat more secure.

<https://wiki.squid-cache.org/Features/HTTPS#Encrypted_browser-Squid_connection>


3) SSL-Bump to decrypt the CONNECT tunnels clients tend to prefer when
using an HTTP proxy.
  <https://wiki.squid-cache.org/Features/SslPeekAndSplice>


Current Squid (v4 or later) support (1) and (2) with either GnuTLS or
OpenSSL. (3) requires OpenSSL.

Once decrypted the https:// URLs are subject to normal HTTP caching rules.


Amos


From rousskov at measurement-factory.com  Thu Jul 30 16:08:16 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 30 Jul 2020 12:08:16 -0400
Subject: [squid-users] Caching https data
In-Reply-To: <e4416845-a5a6-64ca-b434-812344b3c8c5@treenet.co.nz>
References: <ce708a9b-9395-1b7f-3b2f-f6c5419f08b6@transsee.ca>
 <e4416845-a5a6-64ca-b434-812344b3c8c5@treenet.co.nz>
Message-ID: <232462c6-bdc5-5b87-8e2f-5d754aaa21dc@measurement-factory.com>

On 7/30/20 5:11 AM, Amos Jeffries wrote:
> On 30/07/20 10:34 am, Darwin O'Connor wrote:
>> I run a transit prediction web app <https://www.transsee.ca/>. It
>> connects to a variety of web APIs to collect the real time data it
>> needs. The apps activities are split among many processes. They
>> currently uses libcurl to connect to squid for caching (often for as
>> little as 10-30 seconds) and benefits of connection sharing, but some of
>> the APIs use https, so in that case the data passes through squid
>> without the benefits of caching or connection sharing.
>>
>> I would like to configure squid to connect to these servers securely and
>> pass it unencrypted to clients. Security isn't really an issue since
>> this step is all within the one server. I'll have to configure libcurl
>> to allow unencrypted data.


> There are several approaches you can take;
> 
> 1) configure libcurl and/or the apps to send https:// URLs to Squid in
> regular HTTP requests. Leaving Squid to handle all the HTTPS portion.

In 2017, curl did not support "GET https" requests:
https://curl.haxx.se/mail/lib-2017-12/0019.html

AFAICT from the curl v7.68 man page, curl still does not support "GET
https" requests: The https scheme in the request URI implies CONNECT
through the proxy (including through the HTTPS proxy discussed below).

Perhaps there is an API trick to force libcurl into sending "GET https"
requests to proxies. If not, you would have to use SslBump (item 3 on
Amos' list).


> 2) configure libcurl and/or the apps to send https:// URLs to a Squid
> secure listening port (https_port) in regular HTTP requests. Leaving
> Squid to handle all the HTTPS portion with servers. I'm not sure about
> libcurl

Modern curl versions support HTTPS proxies -- a Factory project added
that support to curl. I am pretty sure the library has the same level of
HTTPS proxies support as the command line client. The problem is with
convincing libcurl to send "GET https" requests.


HTH,

Alex.


> <https://wiki.squid-cache.org/Features/HTTPS#Encrypted_browser-Squid_connection>
> 
> 
> 3) SSL-Bump to decrypt the CONNECT tunnels clients tend to prefer when
> using an HTTP proxy.
>   <https://wiki.squid-cache.org/Features/SslPeekAndSplice>
> 
> 
> Current Squid (v4 or later) support (1) and (2) with either GnuTLS or
> OpenSSL. (3) requires OpenSSL.
> 
> Once decrypted the https:// URLs are subject to normal HTTP caching rules.
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From marciobacci at gmail.com  Thu Jul 30 17:36:32 2020
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Thu, 30 Jul 2020 14:36:32 -0300
Subject: [squid-users] Squid authentication issues
Message-ID: <CA+0TdyqPHyOhKRgJRw5-TODJ0wJ6d4AWwpfaiW6VOmpZYOdroA@mail.gmail.com>

Hi,

I set up Squid 4.6 on Debian 10 and I'm having problems with browser
authentication on a Windows station.

I did the tests on the command line and apparently it's OK.

root at proxy:/etc/squid/acls# /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-basic
Registered MSG_REQ_POOL_USAGE
Registered MSG_REQ_DMALLOC_MARK and LOG_CHANGED
lp_load_ex: refreshing parameters
Initialising global parameters
rlimit_max: increasing rlimit_max (1024) to minimum Windows limit (16384)
Processing section "[global]"
EMPRESA+mane XXXXX
NT_STATUS_OK: The operation completed successfully. (0x0)
OK

Here are my configuration files:

#/ETC/SAMBA/SMB.CONF
[global]
    netbios name = PROXY
    workgroup = EMPRESA
    security = ADS
    realm = EMPRESA.COM.BR
    encrypt passwords = yes
    username map = /etc/samba/user.map

    log file = /var/log/samba/%m.log
    log level = 3 passdb:5 auth:5

    idmap config * : backend = tdb
    idmap config * : range = 3000-7999

    idmap config EMPRESA:backend = ad
    idmap config EMPRESA:schema_mode = rfc2307
    idmap config EMPRESA:range = 10000-999999
    idmap config EMPRESA:unix_nss_info = yes
    idmap config EMPRESA:unix_primary_group = yes

    winbind refresh tickets = Yes
    winbind use default domain = yes
    winbind separator = +
    winbind enum users = yes
    winbind enum groups = yes

    vfs objects = acl_xattr
    map acl inherit = yes
    store dos attributes = yes

    template shell = /bin/bash
    template homedir = /home/%U

    dedicated keytab file = /etc/krb5.keytab
    kerberos method = secrets and keytab

    load printers = no
    printing = bsd
    printcap name = /dev/null
    disable spoolss = yes

#ETC/NSSWITCH.CONF
# /etc/nsswitch.conf
#
# Example configuration of GNU Name Service Switch functionality.
# If you have the `glibc-doc-reference' and `info' packages installed, try:
# `info libc "Name Service Switch"' for information about this file.

passwd:         compat winbind
group:          compat winbind
shadow:         compat
gshadow:        files

hosts:          files dns
networks:       files

protocols:      db files
services:       db files
ethers:         db files
rpc:            db files
netgroup:       nis

#/ETC/KRB5.CONF
[libdefaults]
    dns_lookup_realm = false
    dns_lookup_kdc = true
    default_realm = EMPRESA.COM.BR

#/ETC/SQUID/SQUID.CONF

http_port 3128

cache_mem 512 MB
cache_swap_low 80
cache_swap_high 90

maximum_object_size 512 MB
minimum_object_size 0 KB

maximum_object_size_in_memory 4096 KB

cache_replacement_policy heap LFUDA
memory_replacement_policy heap LFUDA

quick_abort_min -1 KB

detect_broken_pconn on

fqdncache_size 1024

refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320

access_log /var/log/squid/access.log
cache_log /var/log/squid/cache.log

cache_dir aufs /var/spool/squid 600 16 256

auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-basic
auth_param ntlm children 20 startup=0 idle=1
auth_param ntlm keep_alive on

visible_hostname "Monitoramento de Acesso ? Internet"
### acls
#acl manager proto cache_object
acl localhost src 192.168.1.17/32
acl to_localhost dst 192.168.1.17/32
acl SSL_ports port 22 80 3456 443 563 587 993 2811 3001 3322 7071 8443 9191
10000 23000
acl Safe_ports port 21 # ftp
acl Safe_ports port 70 # gopher
acl Safe_ports port 80 # http
acl Safe_ports port 88 # kerberos
acl Safe_ports port 123 # ntp
acl Safe_ports port 210 # wais
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 3456 # Siafi
acl Safe_ports port 389 # ldap
acl Safe_ports port 443 # https
acl Safe_ports port 488 # gss-http
acl Safe_ports port 563 # snews
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl Safe_ports port 3001         # imprenssa nacional
acl Safe_ports port 8080 # http
acl Safe_ports port 8443 # http
acl Safe_ports port 1025-65535 # unregistered ports

acl purge method PURGE
acl CONNECT method CONNECT

# ---- Windows Update ----
acl microsoft url_regex "/etc/squid/acls/ms-update"
acl atualizacoes dstdomain microsoft.com
http_access allow microsoft
http_access allow atualizacoes

http_access allow localhost
http_access allow purge localhost
http_access deny purge
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

acl autenticados proxy_auth REQUIRED
http_access deny !autenticados

acl sites_liberados url_regex -i "/etc/squid/acls/sites-permitidos"
http_access allow sites_liberados

acl extensoes_bloqueadas url_regex -i "/etc/squid/acls/extensoes-proibidas"
http_access deny extensoes_bloqueadas

### Bloqueia sites por URL
acl sites_bloqueados url_regex -i "/etc/squid/acls/sites-proibidos"
http_access deny sites_bloqueados

### Rede LAN #####
acl rede_usuarios src 192.168.0.0/24

### Nega acesso de quem nao esta na rede local
http_access allow rede_usuarios
acl extensoes_bloqueadas url_regex -i "/etc/squid/acls/extensoes-proibidas"
acl sites_liberados url_regex -i "/etc/squid/acls/sites-permitidos"
http_access allow sites_liberados
http_access deny extensoes_bloqueadas
http_access allow autenticados
http_access deny all

error_directory /usr/share/squid/errors/pt-br

coredump_dir /var/spool/squid

can anybody help me?

Regards,

M?rcio Bacci
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200730/5027ef86/attachment.htm>

From doconnor at transsee.ca  Thu Jul 30 20:12:52 2020
From: doconnor at transsee.ca (Darwin O'Connor)
Date: Thu, 30 Jul 2020 16:12:52 -0400
Subject: [squid-users] Caching https data
In-Reply-To: <232462c6-bdc5-5b87-8e2f-5d754aaa21dc@measurement-factory.com>
References: <ce708a9b-9395-1b7f-3b2f-f6c5419f08b6@transsee.ca>
 <e4416845-a5a6-64ca-b434-812344b3c8c5@treenet.co.nz>
 <232462c6-bdc5-5b87-8e2f-5d754aaa21dc@measurement-factory.com>
Message-ID: <93b9357f-a058-b41e-ca38-94f7afda5687@transsee.ca>

On 2020-07-30 12:08 p.m., Alex Rousskov wrote:

> On 7/30/20 5:11 AM, Amos Jeffries wrote:
>> On 30/07/20 10:34 am, Darwin O'Connor wrote:
>>> I run a transit prediction web app <https://www.transsee.ca/>. It
>>> connects to a variety of web APIs to collect the real time data it
>>> needs. The apps activities are split among many processes. They
>>> currently uses libcurl to connect to squid for caching (often for as
>>> little as 10-30 seconds) and benefits of connection sharing, but some of
>>> the APIs use https, so in that case the data passes through squid
>>> without the benefits of caching or connection sharing.
>>>
>>> I would like to configure squid to connect to these servers securely and
>>> pass it unencrypted to clients. Security isn't really an issue since
>>> this step is all within the one server. I'll have to configure libcurl
>>> to allow unencrypted data.
>
>> There are several approaches you can take;
>>
>> 1) configure libcurl and/or the apps to send https:// URLs to Squid in
>> regular HTTP requests. Leaving Squid to handle all the HTTPS portion.
> In 2017, curl did not support "GET https" requests:
> https://curl.haxx.se/mail/lib-2017-12/0019.html
>
> AFAICT from the curl v7.68 man page, curl still does not support "GET
> https" requests: The https scheme in the request URI implies CONNECT
> through the proxy (including through the HTTPS proxy discussed below).
>
> Perhaps there is an API trick to force libcurl into sending "GET https"
> requests to proxies. If not, you would have to use SslBump (item 3 on
> Amos' list).

Reading further into the thread you linked I found the suggestion to use 
the request-target option of curl. By setting the url to the proxy 
location and the request-target to the actual url it is working exactly 
the way I want. API trick for the win.




From belle at bazuin.nl  Fri Jul 31 07:01:23 2020
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Fri, 31 Jul 2020 09:01:23 +0200
Subject: [squid-users] Squid authentication issues
In-Reply-To: <CA+0TdyqPHyOhKRgJRw5-TODJ0wJ6d4AWwpfaiW6VOmpZYOdroA@mail.gmail.com>
References: <CA+0TdyqPHyOhKRgJRw5-TODJ0wJ6d4AWwpfaiW6VOmpZYOdroA@mail.gmail.com>
Message-ID: <vmime.5f23c1c3.f69.7b407a55461f6273@ms249-lin-003.rotterdam.bazuin.nl>

I use this : 

You need this in smb.conf 
# Added for freeradius or squid proxy support
# Obligated to set on both AD-DC and Member server.
ntlm auth = mschapv2-and-ntlmv2-only 

And this or something like that, i have more working auth setups for squid, 
But i use this primarly. 

auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \
    --kerberos /usr/lib/squid/negotiate_kerberos_auth -k /etc/squid/HTTP.keytab \
    -s HTTP/proxy1.internal.domain.tld at REALM \
    --ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOM

Still not working try/change above line to : 
    --ntlm /usr/bin/ntlm_auth --allow-mschapv2 --helper-protocol=gss-spnego --domain=NTDOM

But should not be needed. 

And dont forget to add the HTTP spn on the member server.
net ads keytab add_update_ads HTTP/proxy1.internal.domain.tld -UAdministrator

Also, A+PTR records are a must for the proxy with kerberos auth, 


And do remove from smb.conf : 
>     winbind enum users = yes
>     winbind enum groups = yes
Or set these to no. 

I use that on Debian 10 with now squid 4.12. (ssl enabled)
(since debian 8 and squid 3.x ) 
There are more options here, but start with above.

My setup does, in this order. 
Negotiated Kerberos/NTLM auth with LDAP auth as fall back.

Beside these few small point, your setup looks great to me. 


Greetz, 

Louis


________________________________

	Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Marcio Demetrio Bacci
	Verzonden: donderdag 30 juli 2020 19:37
	Aan: Squid Users
	Onderwerp: [squid-users] Squid authentication issues
	
	
	Hi,
	
	I set up Squid 4.6 on Debian 10 and I'm having problems with browser authentication on a Windows station.
	
	I did the tests on the command line and apparently it's OK.
	
	root at proxy:/etc/squid/acls# /usr/bin/ntlm_auth --helper-protocol=squid-2.5-basic
	Registered MSG_REQ_POOL_USAGE
	Registered MSG_REQ_DMALLOC_MARK and LOG_CHANGED
	lp_load_ex: refreshing parameters
	Initialising global parameters
	rlimit_max: increasing rlimit_max (1024) to minimum Windows limit (16384)
	Processing section "[global]"
	EMPRESA+mane XXXXX
	NT_STATUS_OK: The operation completed successfully. (0x0)
	OK
	
	Here are my configuration files:
	
	#/ETC/SAMBA/SMB.CONF
	[global]
	    netbios name = PROXY
	    workgroup = EMPRESA
	    security = ADS
	    realm = EMPRESA.COM.BR
	    encrypt passwords = yes
	    username map = /etc/samba/user.map
	
	    log file = /var/log/samba/%m.log
	    log level = 3 passdb:5 auth:5
	
	    idmap config * : backend = tdb
	    idmap config * : range = 3000-7999
	
	    idmap config EMPRESA:backend = ad
	    idmap config EMPRESA:schema_mode = rfc2307
	    idmap config EMPRESA:range = 10000-999999
	    idmap config EMPRESA:unix_nss_info = yes
	    idmap config EMPRESA:unix_primary_group = yes
	
	    winbind refresh tickets = Yes
	    winbind use default domain = yes
	    winbind separator = +
	    winbind enum users = yes
	    winbind enum groups = yes
	
	    vfs objects = acl_xattr
	    map acl inherit = yes
	    store dos attributes = yes
	
	    template shell = /bin/bash
	    template homedir = /home/%U
	
	    dedicated keytab file = /etc/krb5.keytab
	    kerberos method = secrets and keytab
	
	    load printers = no
	    printing = bsd
	    printcap name = /dev/null
	    disable spoolss = yes
	
	#ETC/NSSWITCH.CONF
	# /etc/nsswitch.conf
	#
	# Example configuration of GNU Name Service Switch functionality.
	# If you have the `glibc-doc-reference' and `info' packages installed, try:
	# `info libc "Name Service Switch"' for information about this file.
	
	passwd:         compat winbind 
	group:          compat winbind 
	shadow:         compat
	gshadow:        files
	
	hosts:          files dns
	networks:       files
	
	protocols:      db files
	services:       db files
	ethers:         db files
	rpc:            db files
	netgroup:       nis
	
	#/ETC/KRB5.CONF
	[libdefaults]
	    dns_lookup_realm = false
	    dns_lookup_kdc = true
	    default_realm = EMPRESA.COM.BR
	
	#/ETC/SQUID/SQUID.CONF
	
	http_port 3128
	
	cache_mem 512 MB
	cache_swap_low 80
	cache_swap_high 90
	
	maximum_object_size 512 MB
	minimum_object_size 0 KB
	
	maximum_object_size_in_memory 4096 KB
	
	cache_replacement_policy heap LFUDA
	memory_replacement_policy heap LFUDA
	
	quick_abort_min -1 KB
	
	detect_broken_pconn on
	
	fqdncache_size 1024
	
	refresh_pattern ^ftp: 1440 20% 10080
	refresh_pattern ^gopher: 1440 0% 1440
	refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
	refresh_pattern . 0 20% 4320
	
	access_log /var/log/squid/access.log
	cache_log /var/log/squid/cache.log
	
	cache_dir aufs /var/spool/squid 600 16 256
	
	auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-basic
	auth_param ntlm children 20 startup=0 idle=1
	auth_param ntlm keep_alive on
	
	visible_hostname "Monitoramento de Acesso ? Internet"
	### acls
	#acl manager proto cache_object
	acl localhost src MailScanner warning: numerical links are often malicious: 192.168.1.17/32 <http://192.168.1.17/32> 
	acl to_localhost dst MailScanner warning: numerical links are often malicious: 192.168.1.17/32 <http://192.168.1.17/32> 
	acl SSL_ports port 22 80 3456 443 563 587 993 2811 3001 3322 7071 8443 9191 10000 23000 
	acl Safe_ports port 21 # ftp
	acl Safe_ports port 70 # gopher
	acl Safe_ports port 80 # http
	acl Safe_ports port 88 # kerberos
	acl Safe_ports port 123 # ntp
	acl Safe_ports port 210 # wais
	acl Safe_ports port 280 # http-mgmt
	acl Safe_ports port 3456 # Siafi
	acl Safe_ports port 389 # ldap
	acl Safe_ports port 443 # https
	acl Safe_ports port 488 # gss-http
	acl Safe_ports port 563 # snews
	acl Safe_ports port 591 # filemaker
	acl Safe_ports port 777 # multiling http
	acl Safe_ports port 3001         # imprenssa nacional
	acl Safe_ports port 8080 # http
	acl Safe_ports port 8443 # http
	acl Safe_ports port 1025-65535 # unregistered ports
	
	acl purge method PURGE
	acl CONNECT method CONNECT
	
	# ---- Windows Update ----
	acl microsoft url_regex "/etc/squid/acls/ms-update"
	acl atualizacoes dstdomain microsoft.com
	http_access allow microsoft
	http_access allow atualizacoes
	
	http_access allow localhost
	http_access allow purge localhost
	http_access deny purge
	http_access deny !Safe_ports
	http_access deny CONNECT !SSL_ports
	
	acl autenticados proxy_auth REQUIRED
	http_access deny !autenticados
	
	acl sites_liberados url_regex -i "/etc/squid/acls/sites-permitidos"
	http_access allow sites_liberados
	
	acl extensoes_bloqueadas url_regex -i "/etc/squid/acls/extensoes-proibidas"
	http_access deny extensoes_bloqueadas
	
	### Bloqueia sites por URL
	acl sites_bloqueados url_regex -i "/etc/squid/acls/sites-proibidos"
	http_access deny sites_bloqueados
	
	### Rede LAN #####
	acl rede_usuarios src MailScanner warning: numerical links are often malicious: 192.168.0.0/24 <http://192.168.0.0/24> 
	
	
	### Nega acesso de quem nao esta na rede local
	http_access allow rede_usuarios
	acl extensoes_bloqueadas url_regex -i "/etc/squid/acls/extensoes-proibidas"
	acl sites_liberados url_regex -i "/etc/squid/acls/sites-permitidos"
	http_access allow sites_liberados
	http_access deny extensoes_bloqueadas
	http_access allow autenticados
	http_access deny all
	
	error_directory /usr/share/squid/errors/pt-br
	
	coredump_dir /var/spool/squid
	
	can anybody help me?
	
	Regards,
	
	M?rcio Bacci
	




From ceo at teo-en-ming.com  Fri Jul 31 13:29:44 2020
From: ceo at teo-en-ming.com (Turritopsis Dohrnii Teo En Ming)
Date: Fri, 31 Jul 2020 21:29:44 +0800
Subject: [squid-users] [PDF Manual Part 3] Configuring pfSense Firewall,
 Squid Proxy Server, and ClamAV to Scan Internet Traffic for Malware
Message-ID: <1ff738ebafb2e8e2fd08c68843454b83@teo-en-ming.com>

Subject: [PDF Manual Part 3] Configuring pfSense Firewall, Squid Proxy 
Server, and ClamAV to Scan Internet Traffic for Malware
==============================================================================================================================

Just sharing my knowledge and experience.

Author: Mr. Turritopsis Dohrnii Teo En Ming (Targeted Individual)
Country: Singapore
Date: 31 July 2020 Friday Singapore Time

Redundant Google Drive download links [of the PDF manual]:

[1] 
https://drive.google.com/file/d/1PjWwBj963L9lpu8hOan7hbTEEQMRi-U9/view?usp=sharing

[2] 
https://drive.google.com/file/d/1pY1R6qhUfiFSjE3FiszQrwQhPuzFtYMx/view?usp=sharing

[3] 
https://drive.google.com/file/d/1tfyMC9svG2LmqPrFq6CdGHA38wFCLFQv/view?usp=sharing

[4] 
https://drive.google.com/file/d/1Y6q4iKV_mjTxH9nbphjAhGdAhHkP1R8T/view?usp=sharing

[5] 
https://drive.google.com/file/d/1gTOJaZS8kUpFN5s3fKfBknCZcQAbjub5/view?usp=sharing

[6] 
https://drive.google.com/file/d/1vEtTGKd4BFMLBxXUTBg4MGMw6qc_Qe99/view?usp=sharing

If you are interested in Part 1 and Part 2 of the PDF manual series, you 
may search for them in my redundant RAID 1 mirroring blogs (links in my 
signature below).







-----BEGIN EMAIL SIGNATURE-----

The Gospel for all Targeted Individuals (TIs):

[The New York Times] Microwave Weapons Are Prime Suspect in Ills of
U.S. Embassy Workers

Link: 
https://www.nytimes.com/2018/09/01/science/sonic-attack-cuba-microwave.html

********************************************************************************************

Singaporean Mr. Turritopsis Dohrnii Teo En Ming's Academic
Qualifications as at 14 Feb 2019 and refugee seeking attempts at the 
United Nations Refugee Agency Bangkok (21 Mar 2017), in Taiwan (5 Aug 
2019) and Australia (25 Dec 2019 to 9 Jan 2020):

[1] https://tdtemcerts.wordpress.com/

[2] https://tdtemcerts.blogspot.sg/

[3] https://www.scribd.com/user/270125049/Teo-En-Ming

-----END EMAIL SIGNATURE-----


From alvaro.gasco at externos.correo.gob.es  Fri Jul 31 13:50:05 2020
From: alvaro.gasco at externos.correo.gob.es (Alvaro SGAD)
Date: Fri, 31 Jul 2020 15:50:05 +0200
Subject: [squid-users] Wrong openssl version into Squid -v info
Message-ID: <E7786D87-B706-46F3-AB2F-BA55D11D4E95@externos.correo.gob.es>

Hi List!!

My name is Alvaro, from Spain, and i would like to know if you can help me about a problem with my new squid version. 

In my company, we want to update our squid version to 4.12 because our actual version has a vulnerability problem. Our openssl version is 1.1.1g.

When i update squid version and want to know if the process has finished correctly, i run squid -v into and this is that i receive.

Squid Cache: Version 4.12
Service Name: squid

This binary uses OpenSSL 1.0.2k-fips  26 Jan 2017. For legal restrictions on distribution seehttps://www.openssl.org/source/license.html
(Here is the problem, this is my old OpenSSL version)

configure options:  '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share' '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--verbose' '--exec_prefix=/usr' '--libexecdir=/usr/lib64/squid' '--localstatedir=/var' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '--disable-dependency-tracking' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-auth-basic=DB,NCSA,NIS,POP3,RADIUS,SMB,getpwnam,fake' '--enable-auth-ntlm=fake,SMB_LM' '--enable-auth-digest=file' '--enable-auth-negotiate=kerberos,wrapper' '--enable-external-acl-helpers=file_userip,kerberos_ldap_group,SQL_session,unix_group,wbinfo_group' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' '--enable-ident-lookups' '--enable-linux-netfilter' '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-storeio=aufs,diskd,ufs,rock' '--enable-wccpv2' '--enable-esi' '--enable-ssl-crtd' '--enable-icmp' '--with-aio' '--with-default-user=squid' '--with-filedescriptors=16384' '--with-dl' '--with-openssl=/usr/local/ssl' '--with-pthreads' '--with-included-ltdl' '--disable-arch-native' '--enable-ecap' '--without-nettle' 'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2' 'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig' '?enable-ltdl-convenience' 'LIBOPENSSL_CFLAGS=-I/opt/openssl/include/openssl' 'target_alias=?enable-ltdl-convenience' --enable-ltdl-convenience



My openssl version is.

openssl version -a
OpenSSL 1.1.1g  21 Apr 2020
built on: Thu Jul  9 12:28:11 2020 UTC
platform: linux-x86_64
options:  bn(64,64) rc4(16x,int) des(int) idea(int) blowfish(ptr)
compiler: gcc -fPIC -pthread -m64 -Wa,--noexecstack -Wall -O3 -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DNDEBUG
OPENSSLDIR: "/usr/local/ssl"
ENGINESDIR: "/opt/openssl/lib/engines-1.1"

I have CentOS 7.

If you need more info ill send you ASAP.

Regards



-- 
?lvaro Javier Gasco Fern?ndez
Sistemas Correo
Secretar?a General de Administraci?n Digital
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200731/d04bf04f/attachment.htm>

From rousskov at measurement-factory.com  Fri Jul 31 18:09:28 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 31 Jul 2020 14:09:28 -0400
Subject: [squid-users] Wrong openssl version into Squid -v info
In-Reply-To: <E7786D87-B706-46F3-AB2F-BA55D11D4E95@externos.correo.gob.es>
References: <E7786D87-B706-46F3-AB2F-BA55D11D4E95@externos.correo.gob.es>
Message-ID: <f063025d-063c-7bb5-f2f5-06806c4a665e@measurement-factory.com>

On 7/31/20 9:50 AM, Alvaro SGAD wrote:
> Our openssl version is 1.1.1g.

> When i update squid version and want to know if the process has finished
> correctly, i run?*squid -v*?into and this is that i receive.

> Squid Cache: Version 4.12
> This binary uses OpenSSL 1.0.2k-fips 26 Jan 2017.

How did you obtain your Squid binary? If you built it from sources, then
the build picked up a different OpenSSL version than you expected. If
you downloaded a binary Squid package, then that Squid binary was built
against a different OpenSSL version than you have on your box. In either
case, your Squid may work just fine, but YMMV. IMHO, it is best when the
build uses an OpenSSL version that matches the installed one.

Please note that you may have multiple OpenSSL versions installed.

Alex.

> configure options: ...
> '--with-openssl=/usr/local/ssl'
...
> 'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig'
...
> 'LIBOPENSSL_CFLAGS=-I/opt/openssl/include/openssl'

> My openssl version is.
> 
> *openssl version -a*
> OpenSSL 1.1.1g? 21 Apr 2020
> built on: Thu Jul? 9 12:28:11?2020 UTC <x-apple-data-detectors://4>
> platform: linux-x86_64
> options:? bn(64,64) rc4(16x,int) des(int) idea(int) blowfish(ptr)
> compiler: gcc -fPIC -pthread -m64 -Wa,--noexecstack -Wall -O3
> -DOPENSSL_USE_NODELETE -DL_ENDIAN -DOPENSSL_PIC -DOPENSSL_CPUID_OBJ
> -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5
> -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM
> -DKECCAK1600_ASM -DRC4_ASM -DMD5_ASM -DAESNI_ASM -DVPAES_ASM -DGHASH_ASM
> -DECP_NISTZ256_ASM -DX25519_ASM -DPOLY1305_ASM -DNDEBUG
> OPENSSLDIR: "/usr/local/ssl"
> ENGINESDIR: "/opt/openssl/lib/engines-1.1"
> 
> I have CentOS 7.



From aimeec1995 at mail.com  Fri Jul 31 23:17:29 2020
From: aimeec1995 at mail.com (skel eton)
Date: Sat, 1 Aug 2020 01:17:29 +0200
Subject: [squid-users] youtube-dl
Message-ID: <trinity-42a09e87-601c-4c75-b73e-1e3e37661271-1596237449359@3c-app-mailcom-lxa07>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200801/70fd392d/attachment.htm>

