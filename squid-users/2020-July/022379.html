<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] rock issue
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20rock%20issue&In-Reply-To=%3CAM6PR09MB3221CBD28BDF7EA3B25066A591660%40AM6PR09MB3221.eurprd09.prod.outlook.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="022366.html">
   <LINK REL="Next"  HREF="022380.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] rock issue</H1>
    <B>patrick mkhael</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20rock%20issue&In-Reply-To=%3CAM6PR09MB3221CBD28BDF7EA3B25066A591660%40AM6PR09MB3221.eurprd09.prod.outlook.com%3E"
       TITLE="[squid-users] rock issue">patrick.mkhael at hotmail.com
       </A><BR>
    <I>Tue Jul  7 10:26:16 UTC 2020</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="022366.html">[squid-users] rock issue
</A></li>
        <LI>Next message (by thread): <A HREF="022380.html">[squid-users] rock issue
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#22379">[ date ]</a>
              <a href="thread.html#22379">[ thread ]</a>
              <a href="subject.html#22379">[ subject ]</a>
              <a href="author.html#22379">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Dear Alex,


**What kind of hit ratio do you get with rock if you do not limit swap-rate and do not specify swap-timeout? [i also removed the max size as recomended], the gain ratio is max 13 %.

&#8203;**What kind of hit ratio do you get with rock if you use one worker, one
rock cache_dir, do not limit swap-rate, do not specify swap-timeout, and
start Squid with -N to disable SMP? [ as recomended, only one rock cache_dir , no limit swap and excuted with -N option,the gain ration is 7%]

additonial info:
i have a total of 24 GB RAM which i use 15 GB of them as cache_mem and i use ext4 in fstab.

thank u


________________________________
From: Alex Rousskov &lt;<A HREF="https://lists.squid-cache.org/listinfo/squid-users">rousskov at measurement-factory.com</A>&gt;
Sent: Saturday, July 4, 2020 3:40 AM
To: patrick mkhael &lt;<A HREF="https://lists.squid-cache.org/listinfo/squid-users">patrick.mkhael at hotmail.com</A>&gt;; <A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users at lists.squid-cache.org</A> &lt;<A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users at lists.squid-cache.org</A>&gt;
Subject: Re: [squid-users] rock issue

On 7/3/20 4:50 AM, patrick mkhael wrote:

&gt;<i> workers 3
</I>&gt;<i> cpu_affinity_map process_numbers=1,2,3,4,5,6 cores=1,2,3,4,5,6
</I>&gt;<i> cache_dir rock /rock1 200000 max-size=32000 swap-timeout=300 max-swap-rate=100
</I>&gt;<i> cache_dir rock /rock2 200000 max-size=32000 max-swap-rate=100 swap-timeout=300
</I>&gt;<i> cache_dir rock /rock3 200000 max-size=32000 max-swap-rate=100 swap-timeout=300
</I>&gt;<i> cache_mem 17 GB
</I>&gt;<i> maximum_object_size_in_memory 25 MB
</I>&gt;<i> maximum_object_size 1 GB
</I>&gt;<i> cache_miss_revalidate off
</I>&gt;<i> quick_abort_pct 95
</I>

FYI: The combination of 1GB maximum_object_size and much smaller size
limits for objects in memory and disk caches does not make sense: There
is no cache to store a, say, 26MB object. If Squid lacks the
corresponding configuration &quot;lint&quot; check, somebody should add it.


&gt;<i> This config is giving 4% of cache gain ratio,
</I>
&gt;<i> in addition as i already mentionned before if i take the same above
</I>&gt;<i> config without worker and cach_dir with the same traffiic using aufs on
</I>&gt;<i> one of the disks ,  i have automatically i har 60 % cache ratio.
</I>
When using AUFS, do you limit disk-cached object sizes to 32KB like you
do with rock? If not, then you should remove the max-size limit from
rock cache_dirs. Modern rock cache_dirs are capable of storing large
objects.

What kind of hit ratio do you get with rock if you do not limit
swap-rate and do not specify swap-timeout?

What kind of hit ratio do you get with rock if you use one worker, one
rock cache_dir, do not limit swap-rate, do not specify swap-timeout, and
start Squid with -N to disable SMP?

As you can see, I am trying to understand whether the size limitation,
the rate limiting, or SMP problems explain the drop in hit ratio.


&gt;<i> Shoud rock give me the same performance as aufs ?
</I>
It is a difficult question to answer correctly (for me). The goal is for
rock performance to exceed that of (a)ufs, but I doubt we have reached
that goal in every environment that matters (including yours).

* In a non-SMP environment, I would expect similar hit ratios in most
cases, but I would not be surprised if there are significant exceptions.
Rock is focused on SMP support, and there are complexities/costs
associated with SMP. Rock is getting better, but there are some known
areas where rock cannot yet do what ufs (including aufs) can.

* In a SMP environment, the question is mostly meaningless because there
is no SMP support for ufs-based caches. Folks use squid.conf
preprocessor hacks to configure ufs-based caches in SMP mode, but those
setups usually violate HTTP and may cause serious problems. YMMV.


&gt;<i> for a traffic of 1 Gb/s , is there a way to use aufs ?
</I>
Before trying unsupported combinations of aufs and SMP, I would try to
understand why your hit ratio is so low with rock. The questions above
may be a good start in that investigation.


Cheers,

Alex.


&gt;<i> ------------------------------------------------------------------------
</I>&gt;<i> *From:* Alex Rousskov &lt;<A HREF="https://lists.squid-cache.org/listinfo/squid-users">rousskov at measurement-factory.com</A>&gt;
</I>&gt;<i> *Sent:* Thursday, July 2, 2020 4:24 PM
</I>&gt;<i> *To:* patrick mkhael &lt;<A HREF="https://lists.squid-cache.org/listinfo/squid-users">patrick.mkhael at hotmail.com</A>&gt;;
</I>&gt;<i> <A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users at lists.squid-cache.org</A> &lt;<A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users at lists.squid-cache.org</A>&gt;
</I>&gt;<i> *Subject:* Re: [squid-users] rock issue
</I>&gt;<i>
</I>&gt;<i> On 7/1/20 4:45 PM, patrick mkhael wrote:
</I>&gt;<i>
</I>&gt;&gt;<i> ***Please note that you have 20 kids worth mapping (10 workers and 10
</I>&gt;&gt;<i> diskers), but you map only the first 10.&#8203;{since i did not get the point
</I>&gt;&gt;<i> of the diskers ,as far as i understood  , it should be like  (simple
</I>&gt;&gt;<i> example)
</I>&gt;<i>
</I>&gt;&gt;&gt;<i> workers 2
</I>&gt;&gt;&gt;<i> cpu_affinity_map process_numbers=1,2,3,4 cores=1,2,3,4
</I>&gt;&gt;&gt;<i> cache_dir rock ...
</I>&gt;&gt;&gt;<i> cache_dir rock ...
</I>&gt;<i>
</I>&gt;<i> The above looks OK. Each worker is a kid process. Each rock cache_dir is
</I>&gt;<i> a kid process (we call them diskers).  If you have physical CPU cores to
</I>&gt;<i> spare, give each kid process its own physical core. Otherwise, give each
</I>&gt;<i> worker process its own physical core (if you can). Diskers can share
</I>&gt;<i> physical cores with less harm because they usually do not consume much
</I>&gt;<i> CPU cycles. Squid wiki has more detailed information about that:
</I>&gt;<i> <A HREF="https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F">https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F</A>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;&gt;<i> ***Why do you have 10 rock caches of various sizes? [ to be honest , i
</I>&gt;&gt;<i> saw in many websites that it should be like this from the smallest to
</I>&gt;&gt;<i> the bigest with diff size, i tought it should serve from small size pool
</I>&gt;&gt;<i> to high ]
</I>&gt;<i>
</I>&gt;<i> IMHO, you should stop reading those web pages :-). There is no general
</I>&gt;<i> need to segregate objects by sizes, especially when you are using the
</I>&gt;<i> same slot size for all cache_dirs. Such segregation may be necessary in
</I>&gt;<i> some special cases, but we have not yet established that your case is
</I>&gt;<i> special.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;&gt;<i> *****How many independent disk spindles (or equivalent) do you have? [ i
</I>&gt;&gt;<i> have one raid 5 ssd disks , used by the 10 rock cache dir]
</I>&gt;<i>
</I>&gt;<i> Do not use RAID. If possible, use one rock cache_dir per SSD disk. The
</I>&gt;<i> only reason this may not be possible, AFAICT, is if you want to cache
</I>&gt;<i> more (per SSD disk) than a single Squid cache_dir can hold, but I would
</I>&gt;<i> not worry about overcoming that limit at the beginning. If you want to
</I>&gt;<i> know more about the limit, look for &quot;33554431&quot; in
</I>&gt;<i> <A HREF="http://www.squid-cache.org/mail-archive/squid-users/201312/0034.html">http://www.squid-cache.org/mail-archive/squid-users/201312/0034.html</A>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;&gt;<i> ***How did you select the swap rate limits and timeouts for
</I>&gt;&gt;<i> cache_dirs?[I took it also from online forum , can i leave it empty for
</I>&gt;&gt;<i> both]
</I>&gt;<i>
</I>&gt;<i> If you want a simple answer, then it is &quot;yes&quot;. Unfortunately, there is
</I>&gt;<i> no simple correct answer to that question. To understand what is going
</I>&gt;<i> on and how to tune things, I recommend studying the Performance Tuning
</I>&gt;<i> section of <A HREF="https://wiki.squid-cache.org/Features/RockStore">https://wiki.squid-cache.org/Features/RockStore</A>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;&gt;<i> ****Do you see any ERRORs or WARNINGs in cache log?[NO error or warning
</I>&gt;&gt;<i> found in cache]
</I>&gt;<i>
</I>&gt;<i> Good. I assume you do see some regular messages in cache.log. Keep an
</I>&gt;<i> eye for ERRORs and WARNINGs as you change settings.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> HTH,
</I>&gt;<i>
</I>&gt;<i> Alex.
</I>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://lists.squid-cache.org/pipermail/squid-users/attachments/20200707/55119587/attachment.htm">http://lists.squid-cache.org/pipermail/squid-users/attachments/20200707/55119587/attachment.htm</A>&gt;
</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="022366.html">[squid-users] rock issue
</A></li>
	<LI>Next message (by thread): <A HREF="022380.html">[squid-users] rock issue
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#22379">[ date ]</a>
              <a href="thread.html#22379">[ thread ]</a>
              <a href="subject.html#22379">[ subject ]</a>
              <a href="author.html#22379">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
