From g2011828 at hotmail.com  Sun Mar  1 02:57:03 2020
From: g2011828 at hotmail.com (GeorgeShen)
Date: Sat, 29 Feb 2020 20:57:03 -0600 (CST)
Subject: [squid-users] how to configure squid to check server certificate?
Message-ID: <1583031423038-0.post@n4.nabble.com>


Is there a way, not using ssl-bump, on squid to verify the remote server has
the certificate signed by some well-known CA or self-signed? does that
change if the server is running TLS 1.2 or 1.3?

thanks.
George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Sun Mar  1 09:18:19 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 1 Mar 2020 22:18:19 +1300
Subject: [squid-users] how to configure squid to check server
	certificate?
In-Reply-To: <1583031423038-0.post@n4.nabble.com>
References: <1583031423038-0.post@n4.nabble.com>
Message-ID: <ff0c3a53-d05d-ad9c-fc11-3c1d94cacbde@treenet.co.nz>

On 1/03/20 3:57 pm, GeorgeShen wrote:
> 
> Is there a way, not using ssl-bump, on squid to verify the remote server has
> the certificate signed by some well-known CA or self-signed?

What are you trying to do exactly?

All root CAs are self-signed, even the "well-known" ones. It is just a
matter of who did the self-sign.

So the answer you need may be one of several things - which may not even
involve cert inspection.


> does that
> change if the server is running TLS 1.2 or 1.3?
> 

No.

Amos


From ml at netfence.it  Sun Mar  1 09:30:52 2020
From: ml at netfence.it (Andrea Venturoli)
Date: Sun, 1 Mar 2020 10:30:52 +0100
Subject: [squid-users] Squid and DoH
In-Reply-To: <20200229131753.GC15379@fantomas.sk>
References: <e5755f7c-927c-05c0-04de-568d7556ef57@netfence.it>
 <2f5d1e29-1388-ac38-226a-7c06c4678aeb@treenet.co.nz>
 <20200229131753.GC15379@fantomas.sk>
Message-ID: <a9046668-b4e0-6d92-e013-af671b992798@netfence.it>

On 2020-02-29 14:17, Matus UHLAR - fantomas wrote:

> I guess DoH means dns over https and thus needs sslbump enabled.? the easy
> but limited way would be to disable connections to publicly available DoH
> servers.

Thanks.
Is someone maintaining such a list?

  bye
	av.


From ml at netfence.it  Sun Mar  1 09:31:57 2020
From: ml at netfence.it (Andrea Venturoli)
Date: Sun, 1 Mar 2020 10:31:57 +0100
Subject: [squid-users] Squid and DoH
In-Reply-To: <2f5d1e29-1388-ac38-226a-7c06c4678aeb@treenet.co.nz>
References: <e5755f7c-927c-05c0-04de-568d7556ef57@netfence.it>
 <2f5d1e29-1388-ac38-226a-7c06c4678aeb@treenet.co.nz>
Message-ID: <aaa9c86e-3d79-e7d7-f57b-28ff520acdd6@netfence.it>

On 2020-02-29 10:19, Amos Jeffries wrote:

> With ACL that identify the relevant messages:
> 
>    acl dns-query-url urlpath_regex ^/dns-query\??
>    acl dns-req-message req_header Content-Type ^application/dns-message$
> 
>    acl doh_request any-of dns-query-url dns-req-message
> 
>    acl doh_reply rep_header Content-Type ^application/dns-message$

Thanks a lot.
I thought maybe there was a specific ready-made keyword, but the above 
is fine.

  bye
	av.


From squid3 at treenet.co.nz  Sun Mar  1 12:18:58 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 2 Mar 2020 01:18:58 +1300
Subject: [squid-users] Invalid URL when trying to access cachemgr
In-Reply-To: <20200229031109.GA64494@thismonkey.com>
References: <20200229031109.GA64494@thismonkey.com>
Message-ID: <055d6ad1-fec6-1aa2-5eed-71012177af20@treenet.co.nz>

On 29/02/20 4:11 pm, Scott wrote:
> Hi all,
> 
> I have three squid proxies, two of which respond normally to cachemgr 
> requests:
> 
> # printf "GET cache_object://localhost/info HTTP/1.0\r\n\r\n" | nc HOSTNAME 
> 3128
> 
> The third proxy however returns an html error page:
> 

Which Squid version is this one?


Amos


From g2011828 at hotmail.com  Sun Mar  1 22:32:27 2020
From: g2011828 at hotmail.com (GeorgeShen)
Date: Sun, 1 Mar 2020 16:32:27 -0600 (CST)
Subject: [squid-users] how to configure squid to check server
	certificate?
In-Reply-To: <ff0c3a53-d05d-ad9c-fc11-3c1d94cacbde@treenet.co.nz>
References: <1583031423038-0.post@n4.nabble.com>
 <ff0c3a53-d05d-ad9c-fc11-3c1d94cacbde@treenet.co.nz>
Message-ID: <1583101947646-0.post@n4.nabble.com>


Sorry, I should have said 'Trusted self-signed' CA vs non-Trusted. I was in
one enterprise, they use proxy server, when I went to a non-trusted CA
server, I got TLS handshaking error; but it worked fine when going to a
'trusted' CA server. And I know my connection on the proxy was not a
SSL-Bump. I was trying to see how does the proxy server decide a server is a
trusted, vs non-trusted in splice. If I were going to implement this on the
squid, how to configure such a policy.

thanks.
George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Mon Mar  2 05:27:58 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 2 Mar 2020 18:27:58 +1300
Subject: [squid-users] how to configure squid to check server
	certificate?
In-Reply-To: <1583101947646-0.post@n4.nabble.com>
References: <1583031423038-0.post@n4.nabble.com>
 <ff0c3a53-d05d-ad9c-fc11-3c1d94cacbde@treenet.co.nz>
 <1583101947646-0.post@n4.nabble.com>
Message-ID: <3f4ae76a-39a5-fcdb-5f09-8eaee7256ced@treenet.co.nz>

On 2/03/20 11:32 am, GeorgeShen wrote:
> 
> Sorry, I should have said 'Trusted self-signed' CA vs non-Trusted. I was in
> one enterprise, they use proxy server, when I went to a non-trusted CA
> server, I got TLS handshaking error; but it worked fine when going to a
> 'trusted' CA server. And I know my connection on the proxy was not a
> SSL-Bump. I was trying to see how does the proxy server decide a server is a
> trusted, vs non-trusted in splice. If I were going to implement this on the
> squid, how to configure such a policy.
> 

*IF* that error was from the proxy and the proxy was a Squid, then it
can be done at step 3 with a helper after a peek or stare at step 2.

There should not need to be anything configured though. Rejecting
unknown root CAs is how TLS is designed to work. With splice the error
should be produced by your UA/Browser.

Amos


From Ralf.Hildebrandt at charite.de  Mon Mar  2 08:46:48 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Mon, 2 Mar 2020 09:46:48 +0100
Subject: [squid-users] [ext] Re:  Squid and DoH
In-Reply-To: <a9046668-b4e0-6d92-e013-af671b992798@netfence.it>
References: <e5755f7c-927c-05c0-04de-568d7556ef57@netfence.it>
 <2f5d1e29-1388-ac38-226a-7c06c4678aeb@treenet.co.nz>
 <20200229131753.GC15379@fantomas.sk>
 <a9046668-b4e0-6d92-e013-af671b992798@netfence.it>
Message-ID: <20200302084648.s6paeany2a6buxtf@charite.de>

* Andrea Venturoli <ml at netfence.it>:
> On 2020-02-29 14:17, Matus UHLAR - fantomas wrote:
> 
> > I guess DoH means dns over https and thus needs sslbump enabled.? the easy
> > but limited way would be to disable connections to publicly available DoH
> > servers.
> 
> Thanks.
> Is someone maintaining such a list?

There's one in the wikipedia entry.

Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 195 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200302/81b8d423/attachment.sig>

From Ralf.Hildebrandt at charite.de  Mon Mar  2 08:51:53 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Mon, 2 Mar 2020 09:51:53 +0100
Subject: [squid-users] [ext] Re:  Squid and DoH
In-Reply-To: <20200302084648.s6paeany2a6buxtf@charite.de>
References: <e5755f7c-927c-05c0-04de-568d7556ef57@netfence.it>
 <2f5d1e29-1388-ac38-226a-7c06c4678aeb@treenet.co.nz>
 <20200229131753.GC15379@fantomas.sk>
 <a9046668-b4e0-6d92-e013-af671b992798@netfence.it>
 <20200302084648.s6paeany2a6buxtf@charite.de>
Message-ID: <20200302085153.c6n5htfs43wj27rw@charite.de>

* Ralf Hildebrandt <Ralf.Hildebrandt at charite.de>:
> * Andrea Venturoli <ml at netfence.it>:
> > On 2020-02-29 14:17, Matus UHLAR - fantomas wrote:
> > 
> > > I guess DoH means dns over https and thus needs sslbump enabled.? the easy
> > > but limited way would be to disable connections to publicly available DoH
> > > servers.
> > 
> > Thanks.
> > Is someone maintaining such a list?
> 
> There's one in the wikipedia entry.

In the German entry: https://de.wikipedia.org/wiki/DNS_over_HTTPS

Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From marcus.kool at urlfilterdb.com  Mon Mar  2 08:52:34 2020
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Mon, 2 Mar 2020 08:52:34 +0000
Subject: [squid-users] [ext] Re: Squid and DoH
In-Reply-To: <20200302084648.s6paeany2a6buxtf@charite.de>
References: <e5755f7c-927c-05c0-04de-568d7556ef57@netfence.it>
 <2f5d1e29-1388-ac38-226a-7c06c4678aeb@treenet.co.nz>
 <20200229131753.GC15379@fantomas.sk>
 <a9046668-b4e0-6d92-e013-af671b992798@netfence.it>
 <20200302084648.s6paeany2a6buxtf@charite.de>
Message-ID: <eb1f9f8a-22e3-08a8-3daa-0598d23123fe@urlfilterdb.com>

On 02/03/2020 08:46, Ralf Hildebrandt wrote:
> * Andrea Venturoli <ml at netfence.it>:
>> On 2020-02-29 14:17, Matus UHLAR - fantomas wrote:
>>
>>> I guess DoH means dns over https and thus needs sslbump enabled.? the easy
>>> but limited way would be to disable connections to publicly available DoH
>>> servers.
>> Thanks.
>> Is someone maintaining such a list?
> There's one in the wikipedia entry.
>
> Ralf Hildebrandt
> Charit? - Universit?tsmedizin Berlin
> Gesch?ftsbereich IT | Abteilung Netzwerk
One can also use the URL database of URLfilterDB which includes the dnsoverhttps category.
See also https://www.urlfilterdb.com/suggestentries/lookup_url.html for an online database query.

Marcus



From 3m9n51s2ewut at thismonkey.com  Mon Mar  2 14:31:09 2020
From: 3m9n51s2ewut at thismonkey.com (Scott)
Date: Tue, 3 Mar 2020 01:31:09 +1100
Subject: [squid-users] Invalid URL when trying to access cachemgr
In-Reply-To: <mailman.2.1583150402.24971.squid-users@lists.squid-cache.org>
References: <mailman.2.1583150402.24971.squid-users@lists.squid-cache.org>
Message-ID: <20200302143109.GA64462@thismonkey.com>

> Date: Mon, 2 Mar 2020 01:18:58 +1300
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Invalid URL when trying to access cachemgr
> 
> On 29/02/20 4:11 pm, Scott wrote:
> > Hi all,
> > 
> > I have three squid proxies, two of which respond normally to cachemgr 
> > requests:
> > 
> > # printf "GET cache_object://localhost/info HTTP/1.0\r\n\r\n" | nc HOSTNAME 
> > 3128
> > 
> > The third proxy however returns an html error page:
> > 
> 
> Which Squid version is this one?
>
All three are running 4.9

Scott


From g2011828 at hotmail.com  Wed Mar  4 01:02:10 2020
From: g2011828 at hotmail.com (GeorgeShen)
Date: Tue, 3 Mar 2020 19:02:10 -0600 (CST)
Subject: [squid-users] how to configure squid to check server
	certificate?
In-Reply-To: <3f4ae76a-39a5-fcdb-5f09-8eaee7256ced@treenet.co.nz>
References: <1583031423038-0.post@n4.nabble.com>
 <ff0c3a53-d05d-ad9c-fc11-3c1d94cacbde@treenet.co.nz>
 <1583101947646-0.post@n4.nabble.com>
 <3f4ae76a-39a5-fcdb-5f09-8eaee7256ced@treenet.co.nz>
Message-ID: <1583283730075-0.post@n4.nabble.com>

>There should not need to be anything configured though. Rejecting
>unknown root CAs is how TLS is designed to work. With splice the error
>should be produced by your UA/Browser.

Although the client I have has the root cert of that untrusted CA from
server but getting the TLS handshaking error, it was not the client locally
rejects that. Does that change anything regarding the splice operation does
not need any configure for that operation (if it's a squid)?

thanks.
George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Thu Mar  5 07:55:13 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 5 Mar 2020 20:55:13 +1300
Subject: [squid-users] how to configure squid to check server
	certificate?
In-Reply-To: <1583283730075-0.post@n4.nabble.com>
References: <1583031423038-0.post@n4.nabble.com>
 <ff0c3a53-d05d-ad9c-fc11-3c1d94cacbde@treenet.co.nz>
 <1583101947646-0.post@n4.nabble.com>
 <3f4ae76a-39a5-fcdb-5f09-8eaee7256ced@treenet.co.nz>
 <1583283730075-0.post@n4.nabble.com>
Message-ID: <78cb9aca-8e72-9b29-c7c7-d45bd9813b33@treenet.co.nz>

On 4/03/20 2:02 pm, GeorgeShen wrote:
>> There should not need to be anything configured though. Rejecting
>> unknown root CAs is how TLS is designed to work. With splice the error
>> should be produced by your UA/Browser.
> 
> Although the client I have has the root cert of that untrusted CA from
> server but getting the TLS handshaking error, it was not the client locally
> rejects that. Does that change anything regarding the splice operation does
> not need any configure for that operation (if it's a squid)?

Splice means Squid has decided to have no part in the TLS or any of the
traffic. It blindly relays the exact bytes between client and upstream
server.

If Squid is doing *anything* to alter those bytes it is not splicing. It
is performing one of: stare, bump, terminate, or client-first.


Amos


From rentorbuy at yahoo.com  Thu Mar  5 10:26:53 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Thu, 5 Mar 2020 10:26:53 +0000 (UTC)
Subject: [squid-users] external helper
References: <1684706091.652818.1583404013325.ref@mail.yahoo.com>
Message-ID: <1684706091.652818.1583404013325@mail.yahoo.com>

Hi,

I'm using a perl helper script in Squid, and I've migrating to Squid 4 from Squid 3. It seems that there's an extra field in the string Squid passes to the helper program.

I'd like to know what the character "-" means at the end of the passed string as in this message:

external_acl.cc(1085) Start: externalAclLookup: will wait for the result of 'http www.fltk.org 80 / -' in 'bllookup' (ch=0x5633eaab2118).

Thanks,

Vieri


From squid3 at treenet.co.nz  Thu Mar  5 10:37:08 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 5 Mar 2020 23:37:08 +1300
Subject: [squid-users] external helper
In-Reply-To: <1684706091.652818.1583404013325@mail.yahoo.com>
References: <1684706091.652818.1583404013325.ref@mail.yahoo.com>
 <1684706091.652818.1583404013325@mail.yahoo.com>
Message-ID: <0ff2b845-c252-cc5d-2643-2df56b828182@treenet.co.nz>

On 5/03/20 11:26 pm, Vieri wrote:
> Hi,
> 
> I'm using a perl helper script in Squid, and I've migrating to Squid 4 from Squid 3. It seems that there's an extra field in the string Squid passes to the helper program.
> 
> I'd like to know what the character "-" means at the end of the passed string as in this message:
> 
> external_acl.cc(1085) Start: externalAclLookup: will wait for the result of 'http www.fltk.org 80 / -' in 'bllookup' (ch=0x5633eaab2118).
> 

It means the 'acl' line in squid.conf did not contain any value to pass
as extra parameter(s) to that helper lookup.

See
<https://wiki.squid-cache.org/Features/AddonHelpers#Access_Control_.28ACL.29>

Amos


From rentorbuy at yahoo.com  Thu Mar  5 10:47:19 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Thu, 5 Mar 2020 10:47:19 +0000 (UTC)
Subject: [squid-users] external helper
In-Reply-To: <0ff2b845-c252-cc5d-2643-2df56b828182@treenet.co.nz>
References: <1684706091.652818.1583404013325.ref@mail.yahoo.com>
 <1684706091.652818.1583404013325@mail.yahoo.com>
 <0ff2b845-c252-cc5d-2643-2df56b828182@treenet.co.nz>
Message-ID: <531403749.684340.1583405239599@mail.yahoo.com>


On Thursday, March 5, 2020, 11:37:28 AM GMT+1, Amos Jeffries <squid3 at treenet.co.nz> wrote: 

>
> It means the 'acl' line in squid.conf did not contain any value to pass as extra parameter(s) to that helper lookup.
>
> See
> <https://wiki.squid-cache.org/Features/AddonHelpers#Access_Control_.28ACL.29>

Thanks!


From squid3 at treenet.co.nz  Fri Mar  6 09:08:57 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 6 Mar 2020 22:08:57 +1300
Subject: [squid-users] TCP Fast open and squid4
In-Reply-To: <9122f0e0-fb79-5256-9347-b920c52b6982@articatech.com>
References: <9122f0e0-fb79-5256-9347-b920c52b6982@articatech.com>
Message-ID: <5b8f975e-9df0-22fc-d1a2-2a3255ca5dcd@treenet.co.nz>

On 22/02/20 1:11 am, David Touzeau wrote:
> Hi
> 
> Is Squid handle TCP Fast open on modern kernel ?
> 

Not currently.
 AIUI the kernel may be configured with the feature on inbound
connections. But Squid does not read it until at least one I/O cycle
after the handshake completion anyway, so I would expect little
performance gain unless the connection RTT is large.


> Has anyone tried to implement this directive and noticed a performance
> improvement ?
> 

Not that I am aware of.

For inbound traffic;

 Kernels that support fast-open do not really need Squid support. They
can buffer the early data until Squid reads it in.

Adding support to Squid for this should not be too difficult. Patches or
PR's welcome.


For outbound traffic;

 Squid is designed to open connections first (possibly a very long time)
before data is sent. So fast-open would require a significant re-design
of the task scheduling systems.

IMO we would get better gains by simply re-ordering the tasks so
connection opening operated in parallel to assembly of the outbound
request. Anyone wanting to attempt that should get in touch via squid-dev.


Amos


From rousskov at measurement-factory.com  Fri Mar  6 14:54:43 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 6 Mar 2020 09:54:43 -0500
Subject: [squid-users] TCP Fast open and squid4
In-Reply-To: <5b8f975e-9df0-22fc-d1a2-2a3255ca5dcd@treenet.co.nz>
References: <9122f0e0-fb79-5256-9347-b920c52b6982@articatech.com>
 <5b8f975e-9df0-22fc-d1a2-2a3255ca5dcd@treenet.co.nz>
Message-ID: <f4a910b9-26e7-947c-3e85-c8e1bbe78b05@measurement-factory.com>

On 3/6/20 4:08 AM, Amos Jeffries wrote:
> Squid is designed to open connections first (possibly a very long time)
> before data is sent. So fast-open would require a significant re-design
> of the task scheduling systems.
> 
> IMO we would get better gains by simply re-ordering the tasks so
> connection opening operated in parallel to assembly of the outbound
> request. Anyone wanting to attempt that should get in touch via squid-dev.
 FWIW, I doubt that redesigning for "reordering" is better than
redesigning for the "fast open" support, but I very much agree that, if
anybody wants to work on one or the other, then this should be discussed
on squid-dev before starting the development.


Thank you,

Alex.


From ml at netfence.it  Fri Mar  6 15:22:39 2020
From: ml at netfence.it (Andrea Venturoli)
Date: Fri, 6 Mar 2020 16:22:39 +0100
Subject: [squid-users] Squid + ClamAV
Message-ID: <d5b9452d-78b1-c282-a632-da0b672a6eaf@netfence.it>

Hello.

Is this the right place to discuss Squid + C-ICAP + SquidClamAV + ClamAV?
Normally I'd look for a specific mailing list, but it seems SquidClamAV 
has none.
If this isn't the right place, can someone give a pointer on where to go?



I setup the whole thing and it's working.
However I often get terrible performance (with ClamAV eating a lot of 
CPU), but find it hard to understand what is being scanned that takes so 
long, ad I find the logs of little help.
Also, this does not seem to be always reproducible, since many sites 
will sometimes be very fast and sometimes very slow.

I looked for suggestions on how to tweak ClamAV and/or SquidClamaAV 
(e.g. with whitelists), but came up empty.

Any hint?

  bye & Thanks
	av.


From Ralf.Hildebrandt at charite.de  Fri Mar  6 15:24:34 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Fri, 6 Mar 2020 16:24:34 +0100
Subject: [squid-users] [ext]  Squid + ClamAV
In-Reply-To: <d5b9452d-78b1-c282-a632-da0b672a6eaf@netfence.it>
References: <d5b9452d-78b1-c282-a632-da0b672a6eaf@netfence.it>
Message-ID: <20200306152434.be52vj5ab74qfezy@charite.de>

* Andrea Venturoli <ml at netfence.it>:
> Hello.
> 
> Is this the right place to discuss Squid + C-ICAP + SquidClamAV + ClamAV?

What do you need SquidClamAV for?
I'm running Squid + C-ICAP + ClamAV only.

Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From ml at netfence.it  Sun Mar  8 10:28:58 2020
From: ml at netfence.it (Andrea Venturoli)
Date: Sun, 8 Mar 2020 11:28:58 +0100
Subject: [squid-users] [ext] Squid + ClamAV
In-Reply-To: <20200306152434.be52vj5ab74qfezy@charite.de>
References: <d5b9452d-78b1-c282-a632-da0b672a6eaf@netfence.it>
 <20200306152434.be52vj5ab74qfezy@charite.de>
Message-ID: <50b25c30-d283-fee2-f5fd-5b3fac025eb1@netfence.it>

On 2020-03-06 16:24, Ralf Hildebrandt wrote:
> * Andrea Venturoli <ml at netfence.it>:
>> Hello.
>>
>> Is this the right place to discuss Squid + C-ICAP + SquidClamAV + ClamAV?
> 
> What do you need SquidClamAV for?

Interesting question.

I find information on the web scarce, but here (*) it states "In 
practice, configuration with clamd and squidclamav is fastest".

(*) https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP

Is that wrong? Outdated?
Also, squidclamav allows for whitelists, which I don't see mentioned in 
the other setups.



Do you believe any of the different configuration outlined in that 
document is better?

What do you suggest?
I-CAP + clamd?
I-CAP + libclamav?

Keep in mind I will run clamd anyway for other services.

Or should I ignore that document completely and use something else?

Also, I heard about e-cap, but IIUIC it's still immature. Is that correct?



In any case, are you getting satisfactory performance? Did you need any 
tweak to ClamAV config?



  bye & Thanks
	av.


From service.mv at gmail.com  Mon Mar  9 14:43:14 2020
From: service.mv at gmail.com (Service MV)
Date: Mon, 9 Mar 2020 11:43:14 -0300
Subject: [squid-users] Allowing a port only to certain IP/host
Message-ID: <CA+d==oGYTLDbvdjaKyJw1L6Ybu=d1-01264OvunX0rpR0J1R_w@mail.gmail.com>

Hello everyone, I need to enable port 22 in squid but only to a certain
server (host.domain.com) in particular, so that the rest of the world
cannot be accessed via SSH.
I would like to know this is the right way to do it:

# SFTP policy
acl SSH_port port 22
acl SFTP_policy dst 1.2.3.4
http_access allow SFTP_policy SSH_port localnet
[...]
http_access deny !Safe_ports
[...]

I'd appreciate your comments.
Kind regards
Gabriel
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200309/9628fe54/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Mar  9 14:48:06 2020
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 9 Mar 2020 15:48:06 +0100
Subject: [squid-users] Allowing a port only to certain IP/host
In-Reply-To: <CA+d==oGYTLDbvdjaKyJw1L6Ybu=d1-01264OvunX0rpR0J1R_w@mail.gmail.com>
References: <CA+d==oGYTLDbvdjaKyJw1L6Ybu=d1-01264OvunX0rpR0J1R_w@mail.gmail.com>
Message-ID: <202003091548.06247.Antony.Stone@squid.open.source.it>

On Monday 09 March 2020 at 15:43:14, Service MV wrote:

> Hello everyone, I need to enable port 22 in squid but only to a certain
> server (host.domain.com) in particular, so that the rest of the world
> cannot be accessed via SSH.

Squid does not support SSH.

> I would like to know this is the right way to do it:

Use iptables or whatever other firewall software you use on your gateway router 
to block all TCP port 22 outbound access except destination host.domain.com


Antony.

-- 
"640 kilobytes (of RAM) should be enough for anybody."

 - Bill Gates

                                                   Please reply to the list;
                                                         please *don't* CC me.


From chip_pop at hotmail.com  Mon Mar  9 15:01:24 2020
From: chip_pop at hotmail.com (joseph)
Date: Mon, 9 Mar 2020 10:01:24 -0500 (CDT)
Subject: [squid-users] bugzilla  error ?
Message-ID: <1583766084989-0.post@n4.nabble.com>

Software error:
Can't connect to the database.
Error: Access denied for user 'bugs'@'localhost' (using password: YES)
  Is your database installed and up and running?
  Do you have the correct username and password selected in localconfig?

For help, please send mail to the webmaster ([no address given]), giving
this error message and the time and date of the error.



-----
************************** 
***** Crash to the future  ****
**************************
--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From Ralf.Hildebrandt at charite.de  Mon Mar  9 15:01:26 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Mon, 9 Mar 2020 16:01:26 +0100
Subject: [squid-users] [ext] Squid + ClamAV
In-Reply-To: <50b25c30-d283-fee2-f5fd-5b3fac025eb1@netfence.it>
References: <d5b9452d-78b1-c282-a632-da0b672a6eaf@netfence.it>
 <20200306152434.be52vj5ab74qfezy@charite.de>
 <50b25c30-d283-fee2-f5fd-5b3fac025eb1@netfence.it>
Message-ID: <20200309150126.3ki3kj3afprokpuy@charite.de>

* Andrea Venturoli <ml at netfence.it>:
> On 2020-03-06 16:24, Ralf Hildebrandt wrote:
> > * Andrea Venturoli <ml at netfence.it>:
> > > Hello.
> > > 
> > > Is this the right place to discuss Squid + C-ICAP + SquidClamAV + ClamAV?
> > 
> > What do you need SquidClamAV for?
> 
> Interesting question.
> 
> I find information on the web scarce, but here (*) it states "In practice,
> configuration with clamd and squidclamav is fastest".
> 
> (*) https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
> 
> Is that wrong? Outdated?

Actually, I don't know :)

In my setung I'm using squid & c-icap with CLAMD. I'm scanning a few
types only:

virus_scan.ScanFileTypes EXECUTABLE ARCHIVE FWS CWS DOCUMENT DATA TEXT
--
Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From ml at netfence.it  Mon Mar  9 17:04:20 2020
From: ml at netfence.it (Andrea Venturoli)
Date: Mon, 9 Mar 2020 18:04:20 +0100
Subject: [squid-users] [ext] Squid + ClamAV
In-Reply-To: <20200309150126.3ki3kj3afprokpuy@charite.de>
References: <d5b9452d-78b1-c282-a632-da0b672a6eaf@netfence.it>
 <20200306152434.be52vj5ab74qfezy@charite.de>
 <50b25c30-d283-fee2-f5fd-5b3fac025eb1@netfence.it>
 <20200309150126.3ki3kj3afprokpuy@charite.de>
Message-ID: <87be620c-2849-f322-d34c-5c8caaf3deaf@netfence.it>

On 2020-03-09 16:01, Ralf Hildebrandt wrote:

> Actually, I don't know :)

Thanks anyway.



> In my setung I'm using squid & c-icap with CLAMD. I'm scanning a few
> types only:
> 
> virus_scan.ScanFileTypes EXECUTABLE ARCHIVE FWS CWS DOCUMENT DATA TEXT

That was an idea I had to, i.e. limiting scanned types.
With FWS and CWS you mean Flash???

I see you don't scan JavaScript: I thought it would be the first thing 
to look into...
Any reasoning behind this?



  bye & Thanks
	av.


From squid3 at treenet.co.nz  Tue Mar 10 04:54:04 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 Mar 2020 17:54:04 +1300
Subject: [squid-users] bugzilla error ?
In-Reply-To: <1583766084989-0.post@n4.nabble.com>
References: <1583766084989-0.post@n4.nabble.com>
Message-ID: <c32b0916-1e6c-c89d-5654-f967233a79f2@treenet.co.nz>

On 10/03/20 4:01 am, joseph wrote:
> Software error:
> Can't connect to the database.
> Error: Access denied for user 'bugs'@'localhost' (using password: YES)
>   Is your database installed and up and running?
>   Do you have the correct username and password selected in localconfig?
> 
> For help, please send mail to the webmaster ([no address given]), giving
> this error message and the time and date of the error.
> 

We had a DB move for the project recently and some things seem to have
broken only a few days after. This one is fixed now.

Amos


From m_zouhairy at skno.by  Tue Mar 10 06:17:19 2020
From: m_zouhairy at skno.by (Majed Zouhairy)
Date: Tue, 10 Mar 2020 09:17:19 +0300
Subject: [squid-users] Allowing a port only to certain IP/host
In-Reply-To: <202003091548.06247.Antony.Stone@squid.open.source.it>
References: <CA+d==oGYTLDbvdjaKyJw1L6Ybu=d1-01264OvunX0rpR0J1R_w@mail.gmail.com>
 <202003091548.06247.Antony.Stone@squid.open.source.it>
Message-ID: <04f6c7bd88ad7cede85b21efb86f6713c0dcc355.camel@skno.by>



On Mon, 2020-03-09 at 15:48 +0100, Antony Stone wrote:
> On Monday 09 March 2020 at 15:43:14, Service MV wrote:
> 
> > Hello everyone, I need to enable port 22 in squid but only to a
> > certain
> > server (host.domain.com) in particular, so that the rest of the
> > world
> > cannot be accessed via SSH.
> 
> Squid does not support SSH.
> 
> > I would like to know this is the right way to do it:
> 
> Use iptables or whatever other firewall software you use on your
> gateway router 
> to block all TCP port 22 outbound access except destination
> host.domain.com
> 
> 
> Antony.
> 
yeah he's up to no good again

https://articles.mercola.com/sites/articles/archive/2020/03/10/why-bill-gates-accelerating-toxic-food-system.aspx?cid_source=dnl&cid_medium=email&cid_content=art2ReadMore&cid=20200310Z1&et_cid=DM478066&et_rid=826674687




From Ralf.Hildebrandt at charite.de  Tue Mar 10 08:24:27 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 10 Mar 2020 09:24:27 +0100
Subject: [squid-users] [ext] Squid + ClamAV
In-Reply-To: <87be620c-2849-f322-d34c-5c8caaf3deaf@netfence.it>
References: <d5b9452d-78b1-c282-a632-da0b672a6eaf@netfence.it>
 <20200306152434.be52vj5ab74qfezy@charite.de>
 <50b25c30-d283-fee2-f5fd-5b3fac025eb1@netfence.it>
 <20200309150126.3ki3kj3afprokpuy@charite.de>
 <87be620c-2849-f322-d34c-5c8caaf3deaf@netfence.it>
Message-ID: <20200310082427.5ujdua7vavidf5ha@charite.de>

* Andrea Venturoli <ml at netfence.it>:

> > virus_scan.ScanFileTypes EXECUTABLE ARCHIVE FWS CWS DOCUMENT DATA TEXT
> 
> That was an idea I had to, i.e. limiting scanned types.
> With FWS and CWS you mean Flash???

0:FWS:SWF:Shockwave Flash data:GRAPHICS
0:CWS:SWF:Shockwave Flash data:GRAPHICS
 
> I see you don't scan JavaScript: I thought it would be the first thing to
> look into...

All the filetypes are recognized using the "c-icap.magic" file. That
file doesn't have a js/javascript category at all.

CURRENT GROUPS in that fixe are: TEXT DATA EXECUTABLE ARCHIVE GRAPHICS STREAM DOCUMENT
(as you see in my example above, Shockwave Flash is grouped under GRAPHICS)

They probably fall into the TEXT category.

Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From listes at e-gaulue.com  Tue Mar 10 09:53:02 2020
From: listes at e-gaulue.com (=?UTF-8?Q?Edouard_Gaulu=c3=a9?=)
Date: Tue, 10 Mar 2020 10:53:02 +0100
Subject: [squid-users] ssl bump and url_rewrite_program (like squidguard)
In-Reply-To: <b0d1d249-f52a-4179-378b-f4345ea381ce@e-gaulue.com>
References: <563939D3.20804@e-gaulue.com>
 <b0d1d249-f52a-4179-378b-f4345ea381ce@e-gaulue.com>
Message-ID: <de54f7c6-978a-d957-b063-3b25cc06b560@e-gaulue.com>

Hi all,

I know it's an old subject but I come back on it as I moved my old proxy 
server to Debian Buster.

I now have a 4.10 version from git.

Here are my last tests regarding this subject :
 ?* Using c-icap for virus detection works well. I mean if I download a 
virus from an HTTPS server like 
https://www.blablasecurity.com/wp-content/downloads/eicar_com.zip, I get 
redirected to the squidclamav cgi page (even if it is HTTP, I mean HTTPS 
redirect to HTTP).
 ?* url_rewrite_program with squidguard using a basic configuration 
works well with all non-HTTPS request. With HTTPS, it shows a SQUID 
error : *Unable to determine IP address from host name "http"*
 ?* url_rewrite_program with squidguard that is not triggered by the 
CONNECT method (through this configuration: url_rewrite_access deny 
CONNECT) but by the subsequent one gives a 404 coming from the remote 
site. In the log, you see squid get the redirection from the 
url_rewrite_program but at the end it forges a request to the remote 
HTTPS site with a GET content of the redirection.

So c-icap manages to handle it well but url_rewrite_program doesn't.

Is there any new option since 3.4.8, that I could try to manage it as 
good as c-icap redirection?

Best regards, Edouard


Le 04/05/2017 ? 11:03, Edouard Gaulu? a ?crit?:
> Hi community,
>
> Any news about this?
>
> I've tried 3.5.25 but still observe this behaviour.
>
> I understand it well since I read: 
> https://serverfault.com/questions/727262/how-to-redirect-https-connect-request-with-squid-explicit-proxy
>
> But how to let the CONNECT request succeed and later block/redirect 
> next HTTP request coming through this established connection tunnel?
>
> Best Regards,
>
> Le 03/11/2015 ? 23:48, Edouard Gaulu? a ?crit :
>> Hi community,
>>
>> I've followed
>> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit? to
>> set my server. It looks really interesting and it's said to be the more
>> common configuration.
>>
>> I often observe (example here withwww.youtube.com) :
>> ***************************
>> The following error was encountered while trying to retrieve the URL:
>> https://http/*
>>
>> ??? *Unable to determine IP address from host name "http"*
>>
>> The DNS server returned:
>>
>> ??? Name Error: The domain name does not exist.
>> ****************************
>>
>> This happens while the navigator (Mozilla) is trying to get a frame at
>> https://ad.doubleclick.net/N4061/adi/com.ythome/_default;sz=970x250;tile=1;ssl=1;dc_yt=1;kbsg=HPFR151103;kga=-1;kgg=-1;klg=fr;kmyd=ad_creative_1;ytexp=9406852,9408210,9408502,9417689,9419444,9419802,9420440,9420473,9421645,9421711,9422141,9422865,9423510,9423563,9423789;ord=968558538238386? 
>>
>>
>> That's ads so I'm not so fond of it...
>>
>> But this leads me to the fact I get this behavior each time the site is
>> banned by squidguard.
>>
>> Is there something to do to avoid this behavior? I mean, squidguard
>> should send :
>>
>> *********************************
>> ? Access denied
>>
>> Supplementary info???? :
>> Client address???? =???? 192.168.XXX.XXX
>> Client name???? =???? 192.168.XXX.XXX
>> User ident???? =
>> Client group???? =???? XXXXXXX
>> URL???? =???? https://ad.doubleclick.net/
>> Target class???? =???? ads
>>
>> If this is wrong, contact your administrator
>> **********************************
>>
>> squidguard is an url_rewrite_program that looks to respect squid
>> requirements. Redirect looks like this :
>> http://proxyweb.myserver.mydomain/cgi-bin/squidGuard-simple.cgi?clientaddr=... 
>>
>>
>> I've played arround trying to change the redirect URL and it leads me to
>> the idea ssl_bump tries to analyse the part until the ":". Is there a 
>> way
>> to avoid this? Is this just a configuration matter?
>>
>> Could putting a ssl_bump rule saying "every server that name match 
>> "http" or
>> "https" should splice" solve the problem?
>>
>> Regards, EG
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users





From rafael.akchurin at diladele.com  Tue Mar 10 11:16:40 2020
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 10 Mar 2020 11:16:40 +0000
Subject: [squid-users] [icap] Web Safety 7.3 web filter for Squid proxy is
	available
Message-ID: <VI1PR04MB4768952C5FC536FA61E42ED68FFF0@VI1PR04MB4768.eurprd04.prod.outlook.com>

Greetings everyone,

Web Safety 7.3 - ICAP web filter for Squid proxy and Admin UI for Squid Proxy is now available for production use. The following changes and improvements are included into this build.


  *   Optimized all parts of the report generation module - the application now requires less time to build the reports and is able to handle reporting of more users than before.
  *   Added a setting to allow automatic download of missing intermediate HTTPS certificates. Disabled by default.
  *   Fixed some minor issues in report generation, added more debug output to the report log allowing for better understanding how much time was spent during reporting.
  *   Added support for Squid 4.10 on Ubuntu 18/Debian 10.
  *   Improved cluster configuration sync. The client nodes are able to upload the Squid's access logs to the server node. The report building process at server node can now create integrated traffic history for the whole cluster.
  *   It is now possible to completely disable traffic monitoring and reporting from the Admin UI.

See the version history page for other changes - https://docs.diladele.com/version_history/index.html.

Download Links


  *   Virtual appliance for VMware ESXi/vSphere<http://packages.diladele.com/websafety-va/7.3/websafety.zip>
  *   Virtual appliance for Microsoft Hyper-V<http://packages.diladele.com/websafety-va/7.3/websafety-hyperv.zip><https://azuremarketplace.microsoft.com/en-us/marketplace/apps/diladele.websafety>
  *   Microsoft Azure<https://azuremarketplace.microsoft.com/en-us/marketplace/apps/diladele.websafety> appliance (both 7.3 PAYG and BYOL instances)
  *   Amazon AWS<https://aws.amazon.com/marketplace/pp/B07KJHLHKC> appliance (7.3 BYOL instance is being published)

Best regards,
Rafael Akchurin
Diladele B.V.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200310/742c0df5/attachment.htm>

From listes at e-gaulue.com  Tue Mar 10 11:43:58 2020
From: listes at e-gaulue.com (=?UTF-8?Q?Edouard_Gaulu=c3=a9?=)
Date: Tue, 10 Mar 2020 12:43:58 +0100
Subject: [squid-users] ssl bump and url_rewrite_program (like squidguard)
In-Reply-To: <de54f7c6-978a-d957-b063-3b25cc06b560@e-gaulue.com>
References: <563939D3.20804@e-gaulue.com>
 <b0d1d249-f52a-4179-378b-f4345ea381ce@e-gaulue.com>
 <de54f7c6-978a-d957-b063-3b25cc06b560@e-gaulue.com>
Message-ID: <c4b81f45-bac4-015d-b85a-3a90d43dc0c3@e-gaulue.com>

Hi,

Sorry for the noise. In fact, it works. It's just squid couldn't connect 
to the local cgi page (while it could for squidclamav), and then did its 
best that was rather strange.

I confirm "url_rewrite_access deny CONNECT" works like a charm to avoid 
redirection during connection establishment and squid getting mad.

Best regards,

Le 10/03/2020 ? 10:53, Edouard Gaulu? a ?crit?:
> Hi all,
>
> I know it's an old subject but I come back on it as I moved my old 
> proxy server to Debian Buster.
>
> I now have a 4.10 version from git.
>
> Here are my last tests regarding this subject :
> ?* Using c-icap for virus detection works well. I mean if I download a 
> virus from an HTTPS server like 
> https://www.blablasecurity.com/wp-content/downloads/eicar_com.zip, I 
> get redirected to the squidclamav cgi page (even if it is HTTP, I mean 
> HTTPS redirect to HTTP).
> ?* url_rewrite_program with squidguard using a basic configuration 
> works well with all non-HTTPS request. With HTTPS, it shows a SQUID 
> error : *Unable to determine IP address from host name "http"*
> ?* url_rewrite_program with squidguard that is not triggered by the 
> CONNECT method (through this configuration: url_rewrite_access deny 
> CONNECT) but by the subsequent one gives a 404 coming from the remote 
> site. In the log, you see squid get the redirection from the 
> url_rewrite_program but at the end it forges a request to the remote 
> HTTPS site with a GET content of the redirection.
>
> So c-icap manages to handle it well but url_rewrite_program doesn't.
>
> Is there any new option since 3.4.8, that I could try to manage it as 
> good as c-icap redirection?
>
> Best regards, Edouard
>
>
> Le 04/05/2017 ? 11:03, Edouard Gaulu? a ?crit?:
>> Hi community,
>>
>> Any news about this?
>>
>> I've tried 3.5.25 but still observe this behaviour.
>>
>> I understand it well since I read: 
>> https://serverfault.com/questions/727262/how-to-redirect-https-connect-request-with-squid-explicit-proxy
>>
>> But how to let the CONNECT request succeed and later block/redirect 
>> next HTTP request coming through this established connection tunnel?
>>
>> Best Regards,
>>
>> Le 03/11/2015 ? 23:48, Edouard Gaulu? a ?crit :
>>> Hi community,
>>>
>>> I've followed
>>> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit? 
>>> to
>>> set my server. It looks really interesting and it's said to be the more
>>> common configuration.
>>>
>>> I often observe (example here withwww.youtube.com) :
>>> ***************************
>>> The following error was encountered while trying to retrieve the URL:
>>> https://http/*
>>>
>>> ??? *Unable to determine IP address from host name "http"*
>>>
>>> The DNS server returned:
>>>
>>> ??? Name Error: The domain name does not exist.
>>> ****************************
>>>
>>> This happens while the navigator (Mozilla) is trying to get a frame at
>>> https://ad.doubleclick.net/N4061/adi/com.ythome/_default;sz=970x250;tile=1;ssl=1;dc_yt=1;kbsg=HPFR151103;kga=-1;kgg=-1;klg=fr;kmyd=ad_creative_1;ytexp=9406852,9408210,9408502,9417689,9419444,9419802,9420440,9420473,9421645,9421711,9422141,9422865,9423510,9423563,9423789;ord=968558538238386? 
>>>
>>>
>>> That's ads so I'm not so fond of it...
>>>
>>> But this leads me to the fact I get this behavior each time the site is
>>> banned by squidguard.
>>>
>>> Is there something to do to avoid this behavior? I mean, squidguard
>>> should send :
>>>
>>> *********************************
>>> ? Access denied
>>>
>>> Supplementary info???? :
>>> Client address???? =???? 192.168.XXX.XXX
>>> Client name???? =???? 192.168.XXX.XXX
>>> User ident???? =
>>> Client group???? =???? XXXXXXX
>>> URL???? =???? https://ad.doubleclick.net/
>>> Target class???? =???? ads
>>>
>>> If this is wrong, contact your administrator
>>> **********************************
>>>
>>> squidguard is an url_rewrite_program that looks to respect squid
>>> requirements. Redirect looks like this :
>>> http://proxyweb.myserver.mydomain/cgi-bin/squidGuard-simple.cgi?clientaddr=... 
>>>
>>>
>>> I've played arround trying to change the redirect URL and it leads 
>>> me to
>>> the idea ssl_bump tries to analyse the part until the ":". Is there 
>>> a way
>>> to avoid this? Is this just a configuration matter?
>>>
>>> Could putting a ssl_bump rule saying "every server that name match 
>>> "http" or
>>> "https" should splice" solve the problem?
>>>
>>> Regards, EG
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users




From listes at e-gaulue.com  Wed Mar 11 15:59:31 2020
From: listes at e-gaulue.com (=?UTF-8?Q?Edouard_Gaulu=c3=a9?=)
Date: Wed, 11 Mar 2020 16:59:31 +0100
Subject: [squid-users] tls12_check_peer_sigalg:wrong signature type
Message-ID: <78b49e9c-9961-fe6b-9376-12120517fad3@e-gaulue.com>

Hi Community,

We moved from 3.4.8 to 4.10 two days ago (and more generally to Buster).

Some users complain today about HTTPS sites that are not reachable while 
it was before (we bump). They are reachable from browsers without proxy.

An example is : www.marches-securises.fr.

In the log I get :

ERROR: negotiating TLS on FD 57: error:1414D172:SSL 
routines:tls12_check_peer_sigalg:wrong signature type (1/-1/0)

openssl s_client -connect www.marches-securises.fr:443 is OK

I believed in the beginning, it was an intermediate certificate trouble, 
but it doesn't look so. I read this : 
https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=934453

I'm not sure squid is involved, but maybe some of you have already 
overcome this kind of trouble through squid or openssl configuration.

If ever, please share,

Best regards, Edouard



From rentorbuy at yahoo.com  Thu Mar 12 11:15:41 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Thu, 12 Mar 2020 11:15:41 +0000 (UTC)
Subject: [squid-users] debug a failure connection
References: <792239595.4310077.1584011741513.ref@mail.yahoo.com>
Message-ID: <792239595.4310077.1584011741513@mail.yahoo.com>

Hi,

I'm trying to understand what could cause Squid not to connect to the following site:

2020/03/12 11:48:24.115 kid1| 17,4| AsyncCallQueue.cc(55) fireNext: entering FwdState::ConnectedToPeer(0x561b8b5c7918, local=10.215.144.48:51303 remote=1.2.3.4:443 FD 784 flags=25, 0x561b8a7ee5b8/0x561b8a7ee5b8)
2020/03/12 11:48:24.115 kid1| 17,4| AsyncCall.cc(37) make: make call FwdState::ConnectedToPeer [call219229]
2020/03/12 11:48:24.115 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0x561b8b5c7918
2020/03/12 11:48:24.115 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0x561b8b5c7918
2020/03/12 11:48:24.115 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0x561b8a7ee5b8
2020/03/12 11:48:24.115 kid1| 17,3| FwdState.cc(447) fail: ERR_SECURE_CONNECT_FAIL "Service Unavailable"
??????? 1.2.3.4:443


A direct connection by-passing Squid shows that the https site opens fine but with a 3DES cipher. In my Squid 4 test I set this temp values just in case:
tls_outgoing_options flags=DONT_VERIFY_PEER cipher=ALL options=ALL


I don't know how to interpret the messages previous to the ERR_SECURE_CONNECT_FAIL line. Do I need to send them all? Which debug options would be more useful?

Regards,

Vieri


From g2011828 at hotmail.com  Thu Mar 12 23:44:41 2020
From: g2011828 at hotmail.com (GeorgeShen)
Date: Thu, 12 Mar 2020 18:44:41 -0500 (CDT)
Subject: [squid-users] how to configure squid to check server
	certificate?
In-Reply-To: <78cb9aca-8e72-9b29-c7c7-d45bd9813b33@treenet.co.nz>
References: <1583031423038-0.post@n4.nabble.com>
 <ff0c3a53-d05d-ad9c-fc11-3c1d94cacbde@treenet.co.nz>
 <1583101947646-0.post@n4.nabble.com>
 <3f4ae76a-39a5-fcdb-5f09-8eaee7256ced@treenet.co.nz>
 <1583283730075-0.post@n4.nabble.com>
 <78cb9aca-8e72-9b29-c7c7-d45bd9813b33@treenet.co.nz>
Message-ID: <1584056681455-0.post@n4.nabble.com>


Understood. not altering the bytes. My question is simple:
if using squid to do splicing proxy action of https sessions, is there a
squid configuration to block/drop the session if the remote server's
certificate is signed by a 'untrusted' CA?

thanks.
George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Fri Mar 13 07:04:40 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Mar 2020 20:04:40 +1300
Subject: [squid-users] debug a failure connection
In-Reply-To: <792239595.4310077.1584011741513@mail.yahoo.com>
References: <792239595.4310077.1584011741513.ref@mail.yahoo.com>
 <792239595.4310077.1584011741513@mail.yahoo.com>
Message-ID: <1db7d9ff-cd04-99bc-0fe0-c35bb9b75ced@treenet.co.nz>

On 13/03/20 12:15 am, Vieri wrote:
> Hi,
> 
> I'm trying to understand what could cause Squid not to connect to the following site:
> 
> 2020/03/12 11:48:24.115 kid1| 17,4| AsyncCallQueue.cc(55) fireNext: entering FwdState::ConnectedToPeer(0x561b8b5c7918, local=10.215.144.48:51303 remote=1.2.3.4:443 FD 784 flags=25, 0x561b8a7ee5b8/0x561b8a7ee5b8)
> 2020/03/12 11:48:24.115 kid1| 17,4| AsyncCall.cc(37) make: make call FwdState::ConnectedToPeer [call219229]
> 2020/03/12 11:48:24.115 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0x561b8b5c7918
> 2020/03/12 11:48:24.115 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0x561b8b5c7918
> 2020/03/12 11:48:24.115 kid1| 45,9| cbdata.cc(419) cbdataReferenceValid: 0x561b8a7ee5b8
> 2020/03/12 11:48:24.115 kid1| 17,3| FwdState.cc(447) fail: ERR_SECURE_CONNECT_FAIL "Service Unavailable"
> ??????? 1.2.3.4:443
> 
> 
> A direct connection by-passing Squid shows that the https site opens fine but with a 3DES cipher. In my Squid 4 test I set this temp values just in case:
> tls_outgoing_options 


> flags=DONT_VERIFY_PEER

Prevents TLS security being checks. Any problems will be hidden from the
proxy admin and logs.

They still break TLS. You just wont be told what happened. This is
pretty much the opposite of what you want to be doing.

> cipher=ALL

Enables OpenSSL ciphers that client or server may may detect as
forbidden and trigger termination. eg ROT13 and NUL encryption.

If you leave this unset instead, Squid's library will use the machines
default ciphers. You need to see what those are to know which ciphers to
add or remove to fix any problem with the set.


>  options=ALL

Enables lots of OpenSSL features which are a) experimental - breaking
TLS, or b) highly dangerous - breaking TLS, or c) forbidden by an
endpoint - terminating TLS.

Also the opposite of what you want. Leave unset to see what the library
is preferring. Then identify the problem. Then set any specific option
you might need for the problem you find.



There may be multiple problems leading to the same error message,
affecting different transaction(s). So troubleshooting has to be careful
here. Find a repeatable request, debug that for one fix. Then see if the
error still shows up for other traffic and repeat to find the second
problem, etc.


> 
> I don't know how to interpret the messages previous to the ERR_SECURE_CONNECT_FAIL line. Do I need to send them all? Which debug options would be more useful?
> 

The [call219229] is the ID of a Call informing FwdState of the problem.
Find where it was a) created, and b) scheduled to 'dial'. That will tell
you what operation was happening that hit the problem. It may be the
source, or may have received info from somewhere else - trace backwards
until you find the start of the error handlers.

NP: debug info in the TLS logic is a bit absent so you may find it more
useful or faster to get a packet dump and inspect with with Wireshark.


If you do not know what a message means and unsure it can be helpful to
include just in case. All messages from *one* transaction should be
sufficient to see the problem with that transaction.

Note though this list has a 100KB limit on total mail size to avoid hugs
log posts being posted to everyone.


Amos


From squid3 at treenet.co.nz  Fri Mar 13 07:27:58 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Mar 2020 20:27:58 +1300
Subject: [squid-users] tls12_check_peer_sigalg:wrong signature type
In-Reply-To: <78b49e9c-9961-fe6b-9376-12120517fad3@e-gaulue.com>
References: <78b49e9c-9961-fe6b-9376-12120517fad3@e-gaulue.com>
Message-ID: <9181ec11-8794-0750-224e-22264b6271c3@treenet.co.nz>

On 12/03/20 4:59 am, Edouard Gaulu? wrote:
> Hi Community,
> 
> We moved from 3.4.8 to 4.10 two days ago (and more generally to Buster).
> 
> Some users complain today about HTTPS sites that are not reachable while
> it was before (we bump). They are reachable from browsers without proxy.
> 
> An example is : www.marches-securises.fr.
> 
> In the log I get :
> 
> ERROR: negotiating TLS on FD 57: error:1414D172:SSL
> routines:tls12_check_peer_sigalg:wrong signature type (1/-1/0)
> 

This is an error from your Squid machines OpenSSL library.


> openssl s_client -connect www.marches-securises.fr:443 is OK
> 
> I believed in the beginning, it was an intermediate certificate trouble,
> but it doesn't look so. I read this :
> https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=934453
> 
> I'm not sure squid is involved, but maybe some of you have already
> overcome this kind of trouble through squid or openssl configuration.
> 

If you can get a packet trace and inspect the TLS messages with
wireshark you should be able to determine what is actually happening.

If you can find for certain what the cause of problem is we might be
able to help with solutions (if not obvious to you by then).

Amos


From squid3 at treenet.co.nz  Fri Mar 13 07:44:13 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 Mar 2020 20:44:13 +1300
Subject: [squid-users] how to configure squid to check server
	certificate?
In-Reply-To: <1584056681455-0.post@n4.nabble.com>
References: <1583031423038-0.post@n4.nabble.com>
 <ff0c3a53-d05d-ad9c-fc11-3c1d94cacbde@treenet.co.nz>
 <1583101947646-0.post@n4.nabble.com>
 <3f4ae76a-39a5-fcdb-5f09-8eaee7256ced@treenet.co.nz>
 <1583283730075-0.post@n4.nabble.com>
 <78cb9aca-8e72-9b29-c7c7-d45bd9813b33@treenet.co.nz>
 <1584056681455-0.post@n4.nabble.com>
Message-ID: <5ec29ff8-f04f-81cb-5a87-14b113fe597b@treenet.co.nz>

On 13/03/20 12:44 pm, GeorgeShen wrote:
> 
> Understood. not altering the bytes. My question is simple:
> if using squid to do splicing proxy action of https sessions, is there a
> squid configuration to block/drop the session if the remote server's
> certificate is signed by a 'untrusted' CA?


You should be able to do something like this:

 ssl_bump peek all
 ssl_bump terminate ssl::certUntrusted
 ssl_bump splice all

I have not tried that myself, so not sure if it would terminate on
client certs.


Amos


From listes at e-gaulue.com  Fri Mar 13 12:08:42 2020
From: listes at e-gaulue.com (=?UTF-8?Q?Edouard_Gaulu=c3=a9?=)
Date: Fri, 13 Mar 2020 13:08:42 +0100
Subject: [squid-users] tls12_check_peer_sigalg:wrong signature type
In-Reply-To: <9181ec11-8794-0750-224e-22264b6271c3@treenet.co.nz>
References: <78b49e9c-9961-fe6b-9376-12120517fad3@e-gaulue.com>
 <9181ec11-8794-0750-224e-22264b6271c3@treenet.co.nz>
Message-ID: <54d78b9b-2849-adea-7f40-b01c620e1425@e-gaulue.com>


>> ERROR: negotiating TLS on FD 57: error:1414D172:SSL
>> routines:tls12_check_peer_sigalg:wrong signature type (1/-1/0)
>>
> This is an error from your Squid machines OpenSSL library.
That's what I thought. I also have: tls_process_ske_dhe:dh_key_too_small 
for ssl server using SHA1.
>> openssl s_client -connect www.marches-securises.fr:443 is OK
>>
>> I believed in the beginning, it was an intermediate certificate trouble,
>> but it doesn't look so. I read this :
>> https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=934453
>>
>> I'm not sure squid is involved, but maybe some of you have already
>> overcome this kind of trouble through squid or openssl configuration.
>>
> If you can get a packet trace and inspect the TLS messages with
> wireshark you should be able to determine what is actually happening.
>
> If you can find for certain what the cause of problem is we might be
> able to help with solutions (if not obvious to you by then).
>
Yes, that's a way. But as the provided link mentioned (and also some 
issues on SSLLabs), it often looks to be a trouble with SSL server 
configuration and even on big or prestigious sites.

I've set the "sslproxy_cert_error" option to "allow all", but despite 
this I still get SQUID_ERR_SSL_HANDSHAKE.

Maybe there is a configuration to tell squid to allow (better than the 
one above) or to splice in case of such trouble with handshake?

Best regards, Edouard



From jr488m at att.com  Wed Mar 18 17:22:39 2020
From: jr488m at att.com (REED, JOHN)
Date: Wed, 18 Mar 2020 17:22:39 +0000
Subject: [squid-users] Squid + Proxy Protocol v2 + TLV
Message-ID: <db6b546e4e034a798c793993756372a5@att.com>

I am using Proxy Protocol V2 and I'm able to use the ACLs in the squid proxy to route my traffic based on a source IP and destination IP/URL.

I have a use case where I may not have source IP uniqueness, however I will have a unique identifier within the custom TLV field within the proxy protocol v2 header, i.e. the link id from Azure private link.

I wanted to reach out and see if any work was being done on squid supporting routing based on this custom TLV field. I have done extensive searching online and I do see where logging this TLV is supported in version 5, but I haven't found anything about routing/ACLs based on the TLV field.

Thanks,

John Reed
Cloud Security Architect 
AT&T



From rousskov at measurement-factory.com  Wed Mar 18 18:01:44 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 18 Mar 2020 14:01:44 -0400
Subject: [squid-users] Squid + Proxy Protocol v2 + TLV
In-Reply-To: <db6b546e4e034a798c793993756372a5@att.com>
References: <db6b546e4e034a798c793993756372a5@att.com>
Message-ID: <deebfeb0-8bfb-81f7-fbe2-fedf39edde68@measurement-factory.com>

On 3/18/20 1:22 PM, REED, JOHN wrote:

> I wanted to reach out and see if any work was being done on squid
> supporting routing based on this custom TLV field. I have done
> extensive searching online and I do see where logging this TLV is
> supported in version 5, but I haven't found anything about
> routing/ACLs based on the TLV field.

IIRC, nobody contributed or sponsored direct ACL support for PROXY TLVs,
but TLVs can be analyzed in v5 external ACLs: External ACL requests
support logformat %codes, such as %proxy_protocol::>h. Please see v5
documentation for the external_acl_type directive.

HTH,

Alex.


From g2011828 at hotmail.com  Fri Mar 20 00:41:20 2020
From: g2011828 at hotmail.com (GeorgeShen)
Date: Thu, 19 Mar 2020 19:41:20 -0500 (CDT)
Subject: [squid-users] how to configure squid to check server
	certificate?
In-Reply-To: <5ec29ff8-f04f-81cb-5a87-14b113fe597b@treenet.co.nz>
References: <1583031423038-0.post@n4.nabble.com>
 <ff0c3a53-d05d-ad9c-fc11-3c1d94cacbde@treenet.co.nz>
 <1583101947646-0.post@n4.nabble.com>
 <3f4ae76a-39a5-fcdb-5f09-8eaee7256ced@treenet.co.nz>
 <1583283730075-0.post@n4.nabble.com>
 <78cb9aca-8e72-9b29-c7c7-d45bd9813b33@treenet.co.nz>
 <1584056681455-0.post@n4.nabble.com>
 <5ec29ff8-f04f-81cb-5a87-14b113fe597b@treenet.co.nz>
Message-ID: <1584664880446-0.post@n4.nabble.com>

thanks Amos.

- George



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From michaelchen8176 at gmail.com  Fri Mar 20 05:31:24 2020
From: michaelchen8176 at gmail.com (Michael Chen)
Date: Fri, 20 Mar 2020 13:31:24 +0800
Subject: [squid-users] How to Configure Proxy Chaining with ssl-bump
Message-ID: <CABBwf4qOxh_3qCx0uktb49R6FVHaeagHz4+sDVZiopKBCSzqXA@mail.gmail.com>

Hi,
I would like to proxy chaining squid to parent proxy on the cloud, Netskope
proxy.
First of all, I configure http_port 3128 ssl-bump, without proxy chaining
to parent proxy. And it works fine. However, my next step to add cache_peer
to parent proxy with Netskope certificates loaded. It failed and shows
sslv3 certificate unknown.
Below are my configuration and test results:

The first Test without proxy chaining to Netskope (just ssl-bump on squid
proxy): normally access internet
My config:
*http_port 3128 ssl-bump cert=/etc/squid/ssl_cert/myCA9.pem
key=/etc/squid/ssl_cert/myCA9.pem generate-host-certification=on
dynamic_cert_mem_cache_size=4MB*

*acl step1 at_step SslBump1*
*ssl_bump peek step1*
*ssl_bump bump all*

Cache.log:

[image: image.png]
  normally access https://translate.google.com

The second test is squid proxy chaining to Netskope (with ssl  enabled):
Result is failed to access internet (HTTP/HTTPS)
My config: (where I put Netskope intermediate & root certs on
/etc/squid/ssl_cert/)
*http_port 3128 ssl-bump cert=/etc/squid/ssl_cert/myCA9.pem
key=/etc/squid/ssl_cert/myCA9.pem generate-host-certification=on
dynamic_cert_mem_cache_size=4MB*

*cache_peer pxc-sasesg-tpe.eu.goskope.com
<http://pxc-sasesg-tpe.eu.goskope.com/> parent 8080 0 no-query default ssl
sslpath=/etc/squid/ssl_cert/
sslcafile=/etc/squid/ssl_cert/cacert-2020-01-01.pem login=PASSTHRU
ssloptions=NO_SSLv2 sslflags=DONT_VERIFY_DOMAIN*

*never_direct allow all*

*acl step1 at_step SslBump1*
*ssl_bump peek step1*
*ssl_bump bump all*

Cache.log once squid restart, It shows ? sslv3 alert certificate unknown?
[image: image.png]

CANNOT access https://translate.google.com

Do you see anything wrong?
BR,
Michael
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200320/9b3dbceb/attachment.htm>

From squid3 at treenet.co.nz  Fri Mar 20 05:40:26 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Mar 2020 18:40:26 +1300
Subject: [squid-users] How to Configure Proxy Chaining with ssl-bump
In-Reply-To: <CABBwf4qOxh_3qCx0uktb49R6FVHaeagHz4+sDVZiopKBCSzqXA@mail.gmail.com>
References: <CABBwf4qOxh_3qCx0uktb49R6FVHaeagHz4+sDVZiopKBCSzqXA@mail.gmail.com>
Message-ID: <b06c7be2-9bae-7bb1-5b27-c52208dca772@treenet.co.nz>

On 20/03/20 6:31 pm, Michael Chen wrote:
> Hi,
> I would like to proxy chaining squid to parent proxy on the cloud,
> Netskope proxy.

Output of "squid -v" please. The version matters a lot when it comes to
what you are trying to configure.


Amos


From squid3 at treenet.co.nz  Fri Mar 20 06:36:07 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Mar 2020 19:36:07 +1300
Subject: [squid-users] How to Configure Proxy Chaining with ssl-bump
In-Reply-To: <CABBwf4r6xcedo7gCmaaq_Fnv+oSdiPt4fMm2r=b3npfz+rjd2g@mail.gmail.com>
References: <CABBwf4qOxh_3qCx0uktb49R6FVHaeagHz4+sDVZiopKBCSzqXA@mail.gmail.com>
 <b06c7be2-9bae-7bb1-5b27-c52208dca772@treenet.co.nz>
 <CABBwf4r6xcedo7gCmaaq_Fnv+oSdiPt4fMm2r=b3npfz+rjd2g@mail.gmail.com>
Message-ID: <be8d1306-1956-1508-dbcf-496a765a7d44@treenet.co.nz>

On 20/03/20 7:12 pm, Michael Chen wrote:
> Hi Amos,
> Squid version 3.5.28

Squid-3 cannot do what you are wanting.

You require Squid-4 or later if the peer supports TLS/SSL connections,
and Squid-5 or later if it does not.



> image.png
> BR,
> Michael
> 

Please avoid posting things images. They often do not make it through
the mailing list, are very hard to read and even worse to grep/search
for significant values.

Amos


From michaelchen8176 at gmail.com  Fri Mar 20 07:27:39 2020
From: michaelchen8176 at gmail.com (Michael Chen)
Date: Fri, 20 Mar 2020 15:27:39 +0800
Subject: [squid-users] How to Configure Proxy Chaining with ssl-bump
In-Reply-To: <be8d1306-1956-1508-dbcf-496a765a7d44@treenet.co.nz>
References: <CABBwf4qOxh_3qCx0uktb49R6FVHaeagHz4+sDVZiopKBCSzqXA@mail.gmail.com>
 <b06c7be2-9bae-7bb1-5b27-c52208dca772@treenet.co.nz>
 <CABBwf4r6xcedo7gCmaaq_Fnv+oSdiPt4fMm2r=b3npfz+rjd2g@mail.gmail.com>
 <be8d1306-1956-1508-dbcf-496a765a7d44@treenet.co.nz>
Message-ID: <CABBwf4rzqvTKN4tQnH=d59T0J6LvqjbiobtCi2EkOhEa7N6aEQ@mail.gmail.com>

Hi Amos,
May I know which function Squid v3.5.28 cannot do for my scenario?
Because Squid v3.5 still has command of cache_peer and ssl .....

BR,
Michael

Amos Jeffries <squid3 at treenet.co.nz> ? 2020?3?20? ?? ??2:46???

> On 20/03/20 7:12 pm, Michael Chen wrote:
> > Hi Amos,
> > Squid version 3.5.28
>
> Squid-3 cannot do what you are wanting.
>
> You require Squid-4 or later if the peer supports TLS/SSL connections,
> and Squid-5 or later if it does not.
>
>
>
> > image.png
> > BR,
> > Michael
> >
>
> Please avoid posting things images. They often do not make it through
> the mailing list, are very hard to read and even worse to grep/search
> for significant values.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200320/50bb2bb2/attachment.htm>

From squid3 at treenet.co.nz  Fri Mar 20 09:29:14 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 Mar 2020 22:29:14 +1300
Subject: [squid-users] How to Configure Proxy Chaining with ssl-bump
In-Reply-To: <CABBwf4rzqvTKN4tQnH=d59T0J6LvqjbiobtCi2EkOhEa7N6aEQ@mail.gmail.com>
References: <CABBwf4qOxh_3qCx0uktb49R6FVHaeagHz4+sDVZiopKBCSzqXA@mail.gmail.com>
 <b06c7be2-9bae-7bb1-5b27-c52208dca772@treenet.co.nz>
 <CABBwf4r6xcedo7gCmaaq_Fnv+oSdiPt4fMm2r=b3npfz+rjd2g@mail.gmail.com>
 <be8d1306-1956-1508-dbcf-496a765a7d44@treenet.co.nz>
 <CABBwf4rzqvTKN4tQnH=d59T0J6LvqjbiobtCi2EkOhEa7N6aEQ@mail.gmail.com>
Message-ID: <c9628d3c-cf83-338b-5586-5d85d8b3b4f4@treenet.co.nz>

On 20/03/20 8:27 pm, Michael Chen wrote:
> Hi Amos,
> May I know which function Squid v3.5.28 cannot do for my scenario?
> Because Squid v3.5 still has command of cache_peer and ssl .....
> 

TLS is a volatile environment, with many changes going on constantly.
Squid-3 has been deprecated since 2018 and is far behind in support
needed for current TLS practices.

Especially when bumping you should always have the latest Squid version.


This first bit can be tested with Squid-3. It is just about getting a
secure connection to the peer, any Squid should be able to do that.

Ensure that the peer proxy is delivering its CA *chain* properly.
 * All the intermediates should be supplied during the server handshake.
 * cache_peer should only need the root CA for that chain. Configured in
the sslca= or tls-ca= option.

At this point your Squid should be able to pass traffic to the peer.
Test that with regular http:// URL requests to your Squid. *Not* HTTPS
or bumped traffic.


You can test this following with Squid-3, but do not expect it to work
very well. Squid-4 is better in a lot of cases, but still not completely.

Your ssl_bump rules should peek at the client cert, then stare at the
server cert, then bump the crypto. Like so:

 ssl_bump peek  step1
 ssl_bump stare all
 ssl_bump bump  all


Amos


From michaelchen8176 at gmail.com  Fri Mar 20 13:13:03 2020
From: michaelchen8176 at gmail.com (Michael Chen)
Date: Fri, 20 Mar 2020 21:13:03 +0800
Subject: [squid-users] How to Configure Proxy Chaining with ssl-bump
In-Reply-To: <c9628d3c-cf83-338b-5586-5d85d8b3b4f4@treenet.co.nz>
References: <CABBwf4qOxh_3qCx0uktb49R6FVHaeagHz4+sDVZiopKBCSzqXA@mail.gmail.com>
 <b06c7be2-9bae-7bb1-5b27-c52208dca772@treenet.co.nz>
 <CABBwf4r6xcedo7gCmaaq_Fnv+oSdiPt4fMm2r=b3npfz+rjd2g@mail.gmail.com>
 <be8d1306-1956-1508-dbcf-496a765a7d44@treenet.co.nz>
 <CABBwf4rzqvTKN4tQnH=d59T0J6LvqjbiobtCi2EkOhEa7N6aEQ@mail.gmail.com>
 <c9628d3c-cf83-338b-5586-5d85d8b3b4f4@treenet.co.nz>
Message-ID: <CABBwf4r-DFfM097Xe=Pih2v6gu6gRG8ysLAEuvOJ6tPXmupCxg@mail.gmail.com>

Hi Amos,
Thanks for your explanation.
Could you instruct me how to install squid v5 based on CentOS 7?
Based on url
https://wiki.squid-cache.org/SquidFaq/BinaryPackages#KnowledgeBase.2FCentOS.Stable_Repository_Package_.28like_epel-release.29,
CentOS seems not support squid v5.

BR,
Michael

Amos Jeffries <squid3 at treenet.co.nz> ? 2020?3?20? ?? ??5:29???

> On 20/03/20 8:27 pm, Michael Chen wrote:
> > Hi Amos,
> > May I know which function Squid v3.5.28 cannot do for my scenario?
> > Because Squid v3.5 still has command of cache_peer and ssl .....
> >
>
> TLS is a volatile environment, with many changes going on constantly.
> Squid-3 has been deprecated since 2018 and is far behind in support
> needed for current TLS practices.
>
> Especially when bumping you should always have the latest Squid version.
>
>
> This first bit can be tested with Squid-3. It is just about getting a
> secure connection to the peer, any Squid should be able to do that.
>
> Ensure that the peer proxy is delivering its CA *chain* properly.
>  * All the intermediates should be supplied during the server handshake.
>  * cache_peer should only need the root CA for that chain. Configured in
> the sslca= or tls-ca= option.
>
> At this point your Squid should be able to pass traffic to the peer.
> Test that with regular http:// URL requests to your Squid. *Not* HTTPS
> or bumped traffic.
>
>
> You can test this following with Squid-3, but do not expect it to work
> very well. Squid-4 is better in a lot of cases, but still not completely.
>
> Your ssl_bump rules should peek at the client cert, then stare at the
> server cert, then bump the crypto. Like so:
>
>  ssl_bump peek  step1
>  ssl_bump stare all
>  ssl_bump bump  all
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200320/1ec16094/attachment.htm>

From laviier at gmail.com  Fri Mar 20 21:48:49 2020
From: laviier at gmail.com (laviier)
Date: Fri, 20 Mar 2020 16:48:49 -0500 (CDT)
Subject: [squid-users] How to perform regex only after Squid knows the full
 url with SslBump
Message-ID: <1584740929482-0.post@n4.nabble.com>

Hi,

I have a use case that I want to access a certain URL path of a domain but
not other. i.e. I want client to be able to access example.com/abc/login,
but not other paths.

Hence, I created ACL rule to achieve that, see below:

```
acl to_domain_whitelist url_regex "/squid-config/whitelist/allow.acl"
acl http port 80
acl https port 443
acl connect method CONNECT

http_access allow all to_domain_whitelist
http_access deny all

http_reply_access allow all

acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3

ssl_bump peek step3
ssl_bump bump all
```

However the above code does not work properly, the URL regex matching
happens before Squid performs decryption so that it can only match against
the host name instead of full URL path. I wonder if there's a way to perform
the URL regex only after Squid knows the full url with SslBump? Below is a
briefing of the log. Thank you so much!!!!
```
---------
CONNECT example.com:443 HTTP/1.1
Host: example.com:443
User-Agent: curl/7.54.0
Proxy-Connection: Keep-Alive
X-Forwarded-For: xx.xxx.xx.xx
----------
...
2020/03/20 14:51:43.067| 28,3| Acl.cc(158) matches: checked:
to_domain_whitelist = 0
2020/03/20 14:51:43.071| 85,2| client_side_request.cc(745)
clientAccessCheckDone: The request CONNECT example.com:443 is DENIED; last
ACL checked: all
...
---------
GET /abc/login HTTP/1.1
Host: example.com
User-Agent: curl/7.54.0
Accept: */*
----------
....
```



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Sun Mar 22 15:19:00 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 22 Mar 2020 11:19:00 -0400
Subject: [squid-users] How to perform regex only after Squid knows the
 full url with SslBump
In-Reply-To: <1584740929482-0.post@n4.nabble.com>
References: <1584740929482-0.post@n4.nabble.com>
Message-ID: <8b83c735-ec55-ae11-2e75-55afd8be0e6f@measurement-factory.com>

On 3/20/20 5:48 PM, laviier wrote:
> Hi,
> 
> I have a use case that I want to access a certain URL path of a domain but
> not other. i.e. I want client to be able to access example.com/abc/login,
> but not other paths.
> 
> Hence, I created ACL rule to achieve that, see below:
> 
> ```
> acl to_domain_whitelist url_regex "/squid-config/whitelist/allow.acl"
> acl http port 80
> acl https port 443
> acl connect method CONNECT
> 
> http_access allow all to_domain_whitelist
> http_access deny all
> 
> http_reply_access allow all
> 
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> 
> ssl_bump peek step3
> ssl_bump bump all
> ```
> 
> However the above code does not work properly, the URL regex matching
> happens before Squid performs decryption so that it can only match against
> the host name instead of full URL path. I wonder if there's a way to perform
> the URL regex only after Squid knows the full url with SslBump? Below is a
> briefing of the log. Thank you so much!!!!
> ```
> ---------
> CONNECT example.com:443 HTTP/1.1
> Host: example.com:443
> User-Agent: curl/7.54.0
> Proxy-Connection: Keep-Alive
> X-Forwarded-For: xx.xxx.xx.xx
> ----------
> ...
> 2020/03/20 14:51:43.067| 28,3| Acl.cc(158) matches: checked:
> to_domain_whitelist = 0
> 2020/03/20 14:51:43.071| 85,2| client_side_request.cc(745)
> clientAccessCheckDone: The request CONNECT example.com:443 is DENIED; last
> ACL checked: all
> ...

If you want to make allow/deny decision based on individual request
URLs, your http_access rules must allow the CONNECT request. Once Squid
establishes (and bumps) the CONNECT tunnel, it will start processing
individual requests and apply http_access rules to each of them.

To allow a CONNECT request, do not use regular URL syntax because
CONNECT requests use a different URI syntax. Sorry, I do not know
whether a url_regex ACL can be used for CONNECT URIs, but you can use
other ACLs if/as needed, of course.


HTH,

Alex.


> ---------
> GET /abc/login HTTP/1.1
> Host: example.com
> User-Agent: curl/7.54.0
> Accept: */*
> ----------
> ....
> ```
> 
> 
> 
> --
> Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From squid3 at treenet.co.nz  Mon Mar 23 05:38:36 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 Mar 2020 18:38:36 +1300
Subject: [squid-users] How to perform regex only after Squid knows the
 full url with SslBump
In-Reply-To: <8b83c735-ec55-ae11-2e75-55afd8be0e6f@measurement-factory.com>
References: <1584740929482-0.post@n4.nabble.com>
 <8b83c735-ec55-ae11-2e75-55afd8be0e6f@measurement-factory.com>
Message-ID: <2b944200-40a2-9fb3-5ab3-3e58e981b2ce@treenet.co.nz>

On 23/03/20 4:19 am, Alex Rousskov wrote:
> 
> To allow a CONNECT request, do not use regular URL syntax because
> CONNECT requests use a different URI syntax. Sorry, I do not know
> whether a url_regex ACL can be used for CONNECT URIs, but you can use
> other ACLs if/as needed, of course.
> 

It can so long as the pattern only needs to match the authority-URI section.

Amos


From squid3 at treenet.co.nz  Mon Mar 23 06:01:40 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 Mar 2020 19:01:40 +1300
Subject: [squid-users] How to Configure Proxy Chaining with ssl-bump
In-Reply-To: <CABBwf4r-DFfM097Xe=Pih2v6gu6gRG8ysLAEuvOJ6tPXmupCxg@mail.gmail.com>
References: <CABBwf4qOxh_3qCx0uktb49R6FVHaeagHz4+sDVZiopKBCSzqXA@mail.gmail.com>
 <b06c7be2-9bae-7bb1-5b27-c52208dca772@treenet.co.nz>
 <CABBwf4r6xcedo7gCmaaq_Fnv+oSdiPt4fMm2r=b3npfz+rjd2g@mail.gmail.com>
 <be8d1306-1956-1508-dbcf-496a765a7d44@treenet.co.nz>
 <CABBwf4rzqvTKN4tQnH=d59T0J6LvqjbiobtCi2EkOhEa7N6aEQ@mail.gmail.com>
 <c9628d3c-cf83-338b-5586-5d85d8b3b4f4@treenet.co.nz>
 <CABBwf4r-DFfM097Xe=Pih2v6gu6gRG8ysLAEuvOJ6tPXmupCxg@mail.gmail.com>
Message-ID: <f141e486-fcce-be0e-78ae-692929d49623@treenet.co.nz>

On 21/03/20 2:13 am, Michael Chen wrote:
> Hi Amos,
> Thanks for your explanation.
> Could you instruct me how to install squid v5 based on CentOS 7?
> Based on
> url?https://wiki.squid-cache.org/SquidFaq/BinaryPackages#KnowledgeBase.2FCentOS.Stable_Repository_Package_.28like_epel-release.29,
> CentOS seems not support squid v5.
> 

There do not seem to be packages yet. You should be able to build from
sources easily enough though following the wiki instructions:
 <https://wiki.squid-cache.org/KnowledgeBase/CentOS#Compiling>

Amos


From bob.le.pirate at free.fr  Mon Mar 23 12:02:07 2020
From: bob.le.pirate at free.fr (Bob le pirate)
Date: Mon, 23 Mar 2020 13:02:07 +0100
Subject: [squid-users] Squid vs Signal Messenger or Hangouts
In-Reply-To: <45a488ea-9f92-5978-226e-b057f085e7bf@free.fr>
References: <45a488ea-9f92-5978-226e-b057f085e7bf@free.fr>
Message-ID: <b269cbd0-defb-d304-199f-a6613efb41ce@free.fr>

> Hello,
>
> On my computer, I installed the Squid proxy for my children's Android 
> smartphones.
> Everything works well, except that the video call does not work for 
> HANGOUTS and that the push notification does not work for SIGNAL and 
> HANGOUTS (they must start the application to see the messages)
>
> Does anyone use Squid with these applications, how can I fix my problem?
>
> Here is my squid.conf :
>
>     |acl localnet src 192.168.x.x/24 # RFC 1918 local private network
>     (LAN) acl SSL_ports port 443 acl Safe_ports port 80 # http acl
>     Safe_ports port 21 # ftp acl Safe_ports port 443 # https acl
>     Safe_ports port 70 # gopher acl Safe_ports port 210 # wais acl
>     Safe_ports port 1025-65535 # unregistered ports acl Safe_ports
>     port 280 # http-mgmt acl Safe_ports port 488 # gss-http acl
>     Safe_ports port 591 # filemaker acl Safe_ports port 777 #
>     multiling http acl SSL_ports port 4433 8443 # Signal Messenger acl
>     CONNECT method CONNECT http_access deny !Safe_ports http_access
>     deny CONNECT !SSL_ports http_access allow localhost manager
>     http_access deny manager http_access allow localnet http_access
>     allow localhost http_reply_access allow localnet http_reply_access
>     allow localhost acl ident_aware_hosts src 198.168.x.x/24
>     ident_lookup_access allow ident_aware_hosts ident_lookup_access
>     deny all http_access deny all http_reply_access deny all http_port
>     3128 coredump_dir /var/cache/squid refresh_pattern ^ftp: 1440 20%
>     10080 refresh_pattern ^gopher: 1440 0% 1440 refresh_pattern -i
>     (/cgi-bin/|\?) 0 0% 0 refresh_pattern . 0 20% 4320
>     cache_effective_user proxy cache_effective_group proxy|
>
> Thank you for your help.
>
> Regards.
>
> Bob.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200323/7df79b85/attachment.htm>

From sebastien at avis-verifies.com  Mon Mar 23 15:01:10 2020
From: sebastien at avis-verifies.com (=?UTF-8?Q?S=C3=A9bastien_Genesta?=)
Date: Mon, 23 Mar 2020 16:01:10 +0100
Subject: [squid-users] Squid - Kerberos - update keytab issue
Message-ID: <CACZAUVqGcHDMX6oMZtTwcMJBB7Gx7mFP7F0GfDDBvdAcMmvA0Q@mail.gmail.com>

Hi,

I'm encountering an issue using Kerberos authentication. Indeed, every 30
days, my kerberos authentication breaks.
(currently, to bypass this issue, I regenerate keytab file).

Here, the command that I run every 6h to keep my keytab up to date.

/usr/sbin/msktutil --auto-update --verbose --computer-name KRB-PROX -k
/etc/squid/squid.keytab

Below log I have every run (when everything is ok):

*samedi 21 mars 2020, 06:00:01 (UTC+0100) -- init_password: Wiping the
computer password structure -- generate_new_password: Generating a new,
random password for the computer account -- generate_new_password:
Characters read from /dev/urandom = 88 -- get_dc_host: Attempting to find
Domain Controller to use via DNS SRV record in domain XXXXXX.LOCAL for
procotol tcp -- get_dc_host: Found DC: xxxxxxxxx.xxxxxxxxx.local --
get_dc_host: Canonicalizing DC through forward/reverse lookup... --
get_dc_host: Found Domain Controller: xxxxxxxx.xxxxxxxxxx.local --
create_fake_krb5_conf: Created a fake krb5.conf file:
/tmp/.msktkrb5.conf-ze3JWq -- reload: Reloading Kerberos Context --
finalize_exec: SAM Account Name is: KRB-PROX$ -- try_machine_keytab_princ:
Trying to authenticate for KRB-PROX$ from local keytab... --
switch_default_ccache: Using the local credential cache:
FILE:/tmp/.mskt_krb5_ccache-t1AykD -- finalize_exec: Authenticated using
method 1 -- LDAPConnection: Connecting to LDAP server:
xxxxxxxxxx.xxxxxxxxxxxxx.local -- ldap_get_base_dn: Determining default
LDAP base: dc=xxxxxxxxxxxxx,dc=LOCAL -- get_default_ou: Determining default
OU: CN=Computers,DC=xxxxxxxxxxxxxxx,DC=local -- ldap_get_pwdLastSet:
pwdLastSet is 132267790228776214 -- execute: Password last set 28 days ago.
-- execute: Exiting because password was changed recently. -- ~KRB5Context:
Destroying Kerberos Context*

Below logs when things gone bad:

*lundi 23 mars 2020, 00:00:01 (UTC+0100) -- init_password: Wiping the
computer password structure -- generate_new_password: Generating a new,
random password for the computer account -- generate_new_password:
Characters read from /dev/urandom = 93 -- get_dc_host: Attempting to find
Domain Controller to use via DNS SRV record in domain XXXXXX.LOCAL for
procotol tcp -- get_dc_host: Found DC: xxxxxxxxxxxx.xxxxxxxxxxx.local --
get_dc_host: Canonicalizing DC through forward/reverse lookup... --
get_dc_host: Found Domain Controller: xxxxxxxxxxxx.xxxxxxxxxxx.local --
create_fake_krb5_conf: Created a fake krb5.conf file:
/tmp/.msktkrb5.conf-UYDFiO -- reload: Reloading Kerberos Context --
finalize_exec: SAM Account Name is: KRB-PROX$ -- try_machine_keytab_princ:
Trying to authenticate for KRB-PROX$ from local keytab... --
switch_default_ccache: Using the local credential cache:
FILE:/tmp/.mskt_krb5_ccache-p6KtWW -- finalize_exec: Authenticated using
method 1 -- LDAPConnection: Connecting to LDAP server:
xxxxxxxxxxxx.xxxxxxxxxxxx.local -- ldap_get_base_dn: Determining default
LDAP base: dc=xxxxxxxxxxxxxx,dc=LOCAL -- get_default_ou: Determining
default OU: CN=Computers,DC=xxxxxxxxxxxxxxx,DC=local --
ldap_get_pwdLastSet: pwdLastSet is 132267790228776214 -- execute: Password
last set 30 days ago. -- ldap_check_account: Checking that a computer
account for KRB-PROX$ exists -- ldap_check_account: Checking computer
account - found -- ldap_check_account: Found userAccountControl = 0x1000 --
ldap_check_account: Found supportedEncryptionTypes = 28 --
ldap_check_account: Found dNSHostName = xxxxxxxx.xxxxxxxxxxx.local --
ldap_check_account: Found Principal: HTTP/xxxxxxxxxx.xxxxxxxxxxx.local --
ldap_check_account: Found User Principal:
HTTP/proxy.xxxxxxxxxxxxxxxxx.local -- ldap_check_account_strings:
Inspecting (and updating) computer account attributes --
ldap_set_supportedEncryptionTypes: No need to change
msDs-supportedEncryptionTypes they are 28 --
ldap_set_userAccountControl_flag: Setting userAccountControl bit at
0x200000 to 0x0 -- ldap_set_userAccountControl_flag: userAccountControl not
changed 0x1000 -- ldap_get_kvno: KVNO is 1 -- set_password: Attempting to
reset computer's password -- set_password: Try using keytab for KRB-PROX$
to change password -- ldap_get_pwdLastSet: pwdLastSet is 132267790228776214
-- set_password: krb5_change_password failed using keytab: (3)
Authentication error -- ~KRB5Context: Destroying Kerberos Context*

*lundi 23 mars 2020, 06:00:01 (UTC+0100) -- init_password: Wiping the
computer password structure -- generate_new_password: Generating a new,
random password for the computer account -- generate_new_password:
Characters read from /dev/urandom = 90 -- get_dc_host: Attempting to find
Domain Controller to use via DNS SRV record in domain xxxxxxxxx.LOCAL for
procotol tcp -- get_dc_host: Found DC: xxxxxxxxx.xxxxxxxxx.local --
get_dc_host: Canonicalizing DC through forward/reverse lookup... --
get_dc_host: Found Domain Controller: xxxxxxxxxx.xxxxxxx.local --
create_fake_krb5_conf: Created a fake krb5.conf file:
/tmp/.msktkrb5.conf-9XY0Qp -- reload: Reloading Kerberos Context --
finalize_exec: SAM Account Name is: KRB-PROX$ -- try_machine_keytab_princ:
Trying to authenticate for KRB-PROX$ from local keytab... --
try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed
(Preauthentication failed) -- try_machine_keytab_princ: Authentication with
keytab failed -- try_machine_keytab_princ: Trying to authenticate for
KRB-PROX$ from local keytab... -- try_machine_keytab_princ: Error:
krb5_get_init_creds_keytab failed (Preauthentication failed) --
try_machine_keytab_princ: Authentication with keytab failed --
try_machine_keytab_princ: Trying to authenticate for
host/xxxxxxxxxxx.xxxxxxxxxx.local from local keytab... --
try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed (Key
table entry not found) -- try_machine_keytab_princ: Authentication with
keytab failed -- try_machine_password: Trying to authenticate for KRB-PROX$
with password. -- create_default_machine_password: Default machine password
for KRB-PROX$ is krb-prox -- try_machine_password: Error:
krb5_get_init_creds_keytab failed (Preauthentication failed) --
try_machine_password: Authentication with password failed --
try_user_creds: Checking if default ticket cache has tickets... --
finalize_exec: Authenticated using method 5 -- LDAPConnection: Connecting
to LDAP server: xxxxxxxxx.xxxxxxxxx.local -- ~KRB5Context: Destroying
Kerberos Context*

Technical information:
-Windows 2016 server (Kerberos)
-Squid 3-x
-msktutil version 1.0

Thanks for your help!

Seb


*S?bastien GENESTA*

System & Network Administrator

Avis V?rifi?s
+334 13 25 81 70 <+334%1325%8170>
sebastien at avis-verifies.com
www.avis-verifies.com
[image: facebook] <https://www.facebook.com/avisverifies>
[image: twitter] <https://twitter.com/avis_verifies>
[image: linkedin] <https://fr.linkedin.com/showcase/avis-v%C3%A9rifi%C3%A9s>

[image:
https://www.avis-verifies.com/api.php?action=act_api_redirection_signature&locale=fr&type=url]
<https://www.avis-verifies.com/api.php?action=act_api_redirection_signature&locale=fr&type=url>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200323/755b5d49/attachment.htm>

From laviier at gmail.com  Mon Mar 23 15:20:30 2020
From: laviier at gmail.com (laviier)
Date: Mon, 23 Mar 2020 11:20:30 -0400
Subject: [squid-users] How to perform regex only after Squid knows the
 full url with SslBump
In-Reply-To: <8b83c735-ec55-ae11-2e75-55afd8be0e6f@measurement-factory.com>
References: <1584740929482-0.post@n4.nabble.com>
 <8b83c735-ec55-ae11-2e75-55afd8be0e6f@measurement-factory.com>
Message-ID: <CADuwAKUAe8qQavhBa4Ug0_Ccxb2CWuSSsUPhmVf1jC+5XKu20g@mail.gmail.com>

Thank you for the suggestion!

I did think of allowing the domain name first during CONNECT phase, and
then the full URL after connection established. However, other paths under
the same site wont be blocked.

i.e. I can ask Squid to let example.com pass through during CONNECT, and
then let example.com/abc/logcin pass through after connection established.
However, this will let other paths of example.com pass Squid too (such as
example.com/not_to_pass) because the it passes the ACL check during CONNECT
phase.



On Sun, Mar 22, 2020 at 11:19 AM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 3/20/20 5:48 PM, laviier wrote:
> > Hi,
> >
> > I have a use case that I want to access a certain URL path of a domain
> but
> > not other. i.e. I want client to be able to access example.com/abc/login
> ,
> > but not other paths.
> >
> > Hence, I created ACL rule to achieve that, see below:
> >
> > ```
> > acl to_domain_whitelist url_regex "/squid-config/whitelist/allow.acl"
> > acl http port 80
> > acl https port 443
> > acl connect method CONNECT
> >
> > http_access allow all to_domain_whitelist
> > http_access deny all
> >
> > http_reply_access allow all
> >
> > acl step1 at_step SslBump1
> > acl step2 at_step SslBump2
> > acl step3 at_step SslBump3
> >
> > ssl_bump peek step3
> > ssl_bump bump all
> > ```
> >
> > However the above code does not work properly, the URL regex matching
> > happens before Squid performs decryption so that it can only match
> against
> > the host name instead of full URL path. I wonder if there's a way to
> perform
> > the URL regex only after Squid knows the full url with SslBump? Below is
> a
> > briefing of the log. Thank you so much!!!!
> > ```
> > ---------
> > CONNECT example.com:443 HTTP/1.1
> > Host: example.com:443
> > User-Agent: curl/7.54.0
> > Proxy-Connection: Keep-Alive
> > X-Forwarded-For: xx.xxx.xx.xx
> > ----------
> > ...
> > 2020/03/20 14:51:43.067| 28,3| Acl.cc(158) matches: checked:
> > to_domain_whitelist = 0
> > 2020/03/20 14:51:43.071| 85,2| client_side_request.cc(745)
> > clientAccessCheckDone: The request CONNECT example.com:443 is DENIED;
> last
> > ACL checked: all
> > ...
>
> If you want to make allow/deny decision based on individual request
> URLs, your http_access rules must allow the CONNECT request. Once Squid
> establishes (and bumps) the CONNECT tunnel, it will start processing
> individual requests and apply http_access rules to each of them.
>
> To allow a CONNECT request, do not use regular URL syntax because
> CONNECT requests use a different URI syntax. Sorry, I do not know
> whether a url_regex ACL can be used for CONNECT URIs, but you can use
> other ACLs if/as needed, of course.
>
>
> HTH,
>
> Alex.
>
>
> > ---------
> > GET /abc/login HTTP/1.1
> > Host: example.com
> > User-Agent: curl/7.54.0
> > Accept: */*
> > ----------
> > ....
> > ```
> >
> >
> >
> > --
> > Sent from:
> http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200323/aff324bf/attachment.htm>

From belle at bazuin.nl  Mon Mar 23 15:36:31 2020
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Mon, 23 Mar 2020 16:36:31 +0100
Subject: [squid-users] Squid - Kerberos - update keytab issue
In-Reply-To: <CACZAUVqGcHDMX6oMZtTwcMJBB7Gx7mFP7F0GfDDBvdAcMmvA0Q@mail.gmail.com>
References: <CACZAUVqGcHDMX6oMZtTwcMJBB7Gx7mFP7F0GfDDBvdAcMmvA0Q@mail.gmail.com>
Message-ID: <vmime.5e78d77f.6b20.2100aa7932b7edef@ms249-lin-003.rotterdam.bazuin.nl>

Hai, 
?
Use winbind and never have this problem again.
?
* install winbind only is sufficient, below works since squid 3.2 up to 4.10
?
An?example of a minimal smb.conf for it. 
?
[global]
??? # Auth-Only setup with winbind. ( no Shares )
?
??? workgroup =?NTDOM
??? security = ADS
??? realm =?YOUR.REALM.TLD
??? netbios name = PROXY1
?
??? preferred master = no
??? domain master = no
??? host msdfs = no
??? dns proxy = yes
??? interfaces = IP_OR_INTERFACENAME 127.0.0.1
??? bind interfaces only = yes
?
??? ### OBLIGATED PART begin 
??? ## map id's outside to domain to tdb files.
??? idmap config *: backend = tdb
??? idmap config *: range = 2000-9999
?
??? ## map ids from the domain and (*) the range may not overlap !
??? idmap config NTDOM: backend =?rid
??? idmap config NTDOM: range = 100000-3999999
?
??? kerberos method = secrets and keytab
??? dedicated keytab file = /etc/krb5.keytab
??? # renew the kerberos ticket
??? winbind refresh tickets = yes
?
??? ### OBLIGATED PART end
?
??? # Disable usershares create.. ( removes??(unneeded )?error from the logs ) 
??? usershare path =
?
??? # Disable printing completely ( removes also?(unneeded ) error from the logs. )
??? load printers = no
??? printing = bsd
??? printcap name = /dev/null
??? disable spoolss = yes
?
--?--- 
?
and join the Windows domain. 
kinit administrator
net ads join -k
?
Allow the server in the AD to Delegate Kerberos for Squid. ( or all services ). thats up to you. 
After thats done, then 
?
Create Squid keytab: 
export KRB5_KTNAME=FILE:/etc/squid/HTTP-$(hostname -s).keytab
net ads keytab ADD HTTP/$(hostname -f) ?
Verify it : klist -ke /etc/squid/HTTP-$(hostname -s).keytab 
unset KRB5_KTNAME
?
# set rights.
chgrp proxy /etc/squid/HTTP-$(hostname -s).keytab
chmod g+r /etc/squid/HTTP-$(hostname -s).keytab
?
?
! Optional krb5.conf ( most of the time the default should be sufficient. 
?
[libdefaults]
??? default_realm = YOUR.REALM.TLD

????## below her is optional.
??? dns_lookup_kdc = true
??? dns_lookup_realm = false
??? ticket_lifetime = 24h
??? ccache_type = 4
??? forwardable = true
??? proxiable = true

??? ;https://bugs.launchpad.net/ubuntu/+source/heimdal/+bug/1484262
??? ignore_k5login = true

and the squid auth part. 
auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \
??? --kerberos /usr/lib/squid/negotiate_kerberos_auth -k /etc/squid/krb5-squid-HTTP-proxy1.keytab \
??? -s HTTP/proxy1.your.DNSdomain.tld at YOUR.REALM.TLD \
??? --ntlm /usr/bin/ntlm_auth --helper-protocol=gss-spnego --domain=NTDOM

Good luck. 
?
Greetz, 
?
Louis
?
?


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens S?bastien Genesta
Verzonden: maandag 23 maart 2020 16:01
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] Squid - Kerberos - update keytab issue




Hi,

I'm encountering an issue using Kerberos authentication. Indeed, every 30 days, my kerberos authentication breaks.
(currently, to bypass this issue, I regenerate keytab file).

Here, the command that I run every 6h to keep my keytab up to date.

/usr/sbin/msktutil --auto-update --verbose --computer-name KRB-PROX -k /etc/squid/squid.keytab

Below log I have every run (when everything is ok):

samedi 21 mars 2020, 06:00:01 (UTC+0100) -- init_password: Wiping the computer password structure -- generate_new_password: Generating a new, random password for the computer account -- generate_new_password: Characters read from /dev/urandom = 88 -- get_dc_host: Attempting to find Domain Controller to use via DNS SRV record in domain XXXXXX.LOCAL for procotol tcp -- get_dc_host: Found DC: xxxxxxxxx.xxxxxxxxx.local -- get_dc_host: Canonicalizing DC through forward/reverse lookup... -- get_dc_host: Found Domain Controller: xxxxxxxx.xxxxxxxxxx.local -- create_fake_krb5_conf: Created a fake krb5.conf file: /tmp/.msktkrb5.conf-ze3JWq -- reload: Reloading Kerberos Context -- finalize_exec: SAM Account Name is: KRB-PROX$ -- try_machine_keytab_princ: Trying to authenticate for KRB-PROX$ from local keytab... -- switch_default_ccache: Using the local credential cache: FILE:/tmp/.mskt_krb5_ccache-t1AykD -- finalize_exec: Authenticated using method 1 -- LDAPConnection: Connecting to LDAP server: xxxxxxxxxx.xxxxxxxxxxxxx.local -- ldap_get_base_dn: Determining default LDAP base: dc=xxxxxxxxxxxxx,dc=LOCAL -- get_default_ou: Determining default OU: CN=Computers,DC=xxxxxxxxxxxxxxx,DC=local -- ldap_get_pwdLastSet: pwdLastSet is 132267790228776214 -- execute: Password last set 28 days ago. -- execute: Exiting because password was changed recently. -- ~KRB5Context: Destroying Kerberos Context

Below logs when things gone bad:

lundi 23 mars 2020, 00:00:01 (UTC+0100) -- init_password: Wiping the computer password structure -- generate_new_password: Generating a new, random password for the computer account -- generate_new_password: Characters read from /dev/urandom = 93 -- get_dc_host: Attempting to find Domain Controller to use via DNS SRV record in domain XXXXXX.LOCAL for procotol tcp -- get_dc_host: Found DC: xxxxxxxxxxxx.xxxxxxxxxxx.local -- get_dc_host: Canonicalizing DC through forward/reverse lookup... -- get_dc_host: Found Domain Controller: xxxxxxxxxxxx.xxxxxxxxxxx.local -- create_fake_krb5_conf: Created a fake krb5.conf file: /tmp/.msktkrb5.conf-UYDFiO -- reload: Reloading Kerberos Context -- finalize_exec: SAM Account Name is: KRB-PROX$ -- try_machine_keytab_princ: Trying to authenticate for KRB-PROX$ from local keytab... -- switch_default_ccache: Using the local credential cache: FILE:/tmp/.mskt_krb5_ccache-p6KtWW -- finalize_exec: Authenticated using method 1 -- LDAPConnection: Connecting to LDAP server: xxxxxxxxxxxx.xxxxxxxxxxxx.local -- ldap_get_base_dn: Determining default LDAP base: dc=xxxxxxxxxxxxxx,dc=LOCAL -- get_default_ou: Determining default OU: CN=Computers,DC=xxxxxxxxxxxxxxx,DC=local -- ldap_get_pwdLastSet: pwdLastSet is 132267790228776214 -- execute: Password last set 30 days ago. -- ldap_check_account: Checking that a computer account for KRB-PROX$ exists -- ldap_check_account: Checking computer account - found -- ldap_check_account: Found userAccountControl = 0x1000 -- ldap_check_account: Found supportedEncryptionTypes = 28 -- ldap_check_account: Found dNSHostName = xxxxxxxx.xxxxxxxxxxx.local -- ldap_check_account: Found Principal: HTTP/xxxxxxxxxx.xxxxxxxxxxx.local -- ldap_check_account: Found User Principal: HTTP/proxy.xxxxxxxxxxxxxxxxx.local -- ldap_check_account_strings: Inspecting (and updating) computer account attributes -- ldap_set_supportedEncryptionTypes: No need to change msDs-supportedEncryptionTypes they are 28 -- ldap_set_userAccountControl_flag: Setting userAccountControl bit at 0x200000 to 0x0 -- ldap_set_userAccountControl_flag: userAccountControl not changed 0x1000 -- ldap_get_kvno: KVNO is 1 -- set_password: Attempting to reset computer's password -- set_password: Try using keytab for KRB-PROX$ to change password -- ldap_get_pwdLastSet: pwdLastSet is 132267790228776214 -- set_password: krb5_change_password failed using keytab: (3) Authentication error -- ~KRB5Context: Destroying Kerberos Context

lundi 23 mars 2020, 06:00:01 (UTC+0100) -- init_password: Wiping the computer password structure -- generate_new_password: Generating a new, random password for the computer account -- generate_new_password: Characters read from /dev/urandom = 90 -- get_dc_host: Attempting to find Domain Controller to use via DNS SRV record in domain xxxxxxxxx.LOCAL for procotol tcp -- get_dc_host: Found DC: xxxxxxxxx.xxxxxxxxx.local -- get_dc_host: Canonicalizing DC through forward/reverse lookup... -- get_dc_host: Found Domain Controller: xxxxxxxxxx.xxxxxxx.local -- create_fake_krb5_conf: Created a fake krb5.conf file: /tmp/.msktkrb5.conf-9XY0Qp -- reload: Reloading Kerberos Context -- finalize_exec: SAM Account Name is: KRB-PROX$ -- try_machine_keytab_princ: Trying to authenticate for KRB-PROX$ from local keytab... -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed (Preauthentication failed) -- try_machine_keytab_princ: Authentication with keytab failed -- try_machine_keytab_princ: Trying to authenticate for KRB-PROX$ from local keytab... -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed (Preauthentication failed) -- try_machine_keytab_princ: Authentication with keytab failed -- try_machine_keytab_princ: Trying to authenticate for host/xxxxxxxxxxx.xxxxxxxxxx.local from local keytab... -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed (Key table entry not found) -- try_machine_keytab_princ: Authentication with keytab failed -- try_machine_password: Trying to authenticate for KRB-PROX$ with password. -- create_default_machine_password: Default machine password for KRB-PROX$ is krb-prox -- try_machine_password: Error: krb5_get_init_creds_keytab failed (Preauthentication failed) -- try_machine_password: Authentication with password failed -- try_user_creds: Checking if default ticket cache has tickets... -- finalize_exec: Authenticated using method 5 -- LDAPConnection: Connecting to LDAP server: xxxxxxxxx.xxxxxxxxx.local -- ~KRB5Context: Destroying Kerberos Context

Technical information:
-Windows 2016 server (Kerberos)
-Squid 3-x
-msktutil version 1.0

Thanks for your help!

Seb

S?bastien GENESTA


System & Network Administrator

Avis V?rifi?s
	
		
		+334 13 25 81?70
	sebastien at avis-verifies.com 
	www.avis-verifies.com 
		
		
		








-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200323/c55eea05/attachment.htm>

From rousskov at measurement-factory.com  Mon Mar 23 19:09:19 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 23 Mar 2020 15:09:19 -0400
Subject: [squid-users] How to perform regex only after Squid knows the
 full url with SslBump
In-Reply-To: <CADuwAKUAe8qQavhBa4Ug0_Ccxb2CWuSSsUPhmVf1jC+5XKu20g@mail.gmail.com>
References: <1584740929482-0.post@n4.nabble.com>
 <8b83c735-ec55-ae11-2e75-55afd8be0e6f@measurement-factory.com>
 <CADuwAKUAe8qQavhBa4Ug0_Ccxb2CWuSSsUPhmVf1jC+5XKu20g@mail.gmail.com>
Message-ID: <5c6ac563-c5df-4492-6d12-2c05bf25474d@measurement-factory.com>

On 3/23/20 11:20 AM, laviier wrote:

> I did think of allowing the domain name first during CONNECT phase, and
> then the full URL after connection established. However, other paths
> under the same site wont be blocked.

What will (or will not be) blocked is for you to decide.


> i.e. I can ask Squid to let example.com pass
> through during CONNECT, and then let example.com/abc/logcin
> pass through after?connection established. 

Yes, you can.


> However, this will let other paths of example.com
> pass Squid too (such as example.com/not_to_pass

Only if your http_access rules allow them. Your rules can include
request methods and bump stages, among other things.


> because the it passes the ACL check during CONNECT phase.

You can make that first example.com check be specific to the "CONNECT
phase". That specific rule does not have to match after the connection
was bumped -- you control that. Squid ACLs are very flexible. Do not
think about one ACL (with several regexes). Think of a combination of
different ACLs. Think of multiple http_access lines. Think of any-of and
all-of ACLs. For example:

  acl ...
  ...
  acl allowedAtTcpLevel ...
  acl allowedAtSniLevel ...
  acl allowedPlainAndBumpedTraffic ...

  http_access allow step1 allowedAtTcpLevel
  http_access deny step1
  http_access allow step2 allowedAtSniLevel
  http_access deny step2
  http_access allow allowedPlainAndBumpedTraffic
  http_access deny all

There are many ways to express what you want. The above is just one
excessively generic sketch. Your best solution will be different. I am
just illustrating the concept.


HTH,

Alex.


> On Sun, Mar 22, 2020 at 11:19 AM Alex Rousskov wrote:
> 
>     On 3/20/20 5:48 PM, laviier wrote:
>     > Hi,
>     >
>     > I have a use case that I want to access a certain URL path of a
>     domain but
>     > not other. i.e. I want client to be able to access
>     example.com/abc/login <http://example.com/abc/login>,
>     > but not other paths.
>     >
>     > Hence, I created ACL rule to achieve that, see below:
>     >
>     > ```
>     > acl to_domain_whitelist url_regex "/squid-config/whitelist/allow.acl"
>     > acl http port 80
>     > acl https port 443
>     > acl connect method CONNECT
>     >
>     > http_access allow all to_domain_whitelist
>     > http_access deny all
>     >
>     > http_reply_access allow all
>     >
>     > acl step1 at_step SslBump1
>     > acl step2 at_step SslBump2
>     > acl step3 at_step SslBump3
>     >
>     > ssl_bump peek step3
>     > ssl_bump bump all
>     > ```
>     >
>     > However the above code does not work properly, the URL regex matching
>     > happens before Squid performs decryption so that it can only match
>     against
>     > the host name instead of full URL path. I wonder if there's a way
>     to perform
>     > the URL regex only after Squid knows the full url with SslBump?
>     Below is a
>     > briefing of the log. Thank you so much!!!!
>     > ```
>     > ---------
>     > CONNECT example.com:443 <http://example.com:443> HTTP/1.1
>     > Host: example.com:443 <http://example.com:443>
>     > User-Agent: curl/7.54.0
>     > Proxy-Connection: Keep-Alive
>     > X-Forwarded-For: xx.xxx.xx.xx
>     > ----------
>     > ...
>     > 2020/03/20 14:51:43.067| 28,3| Acl.cc(158) matches: checked:
>     > to_domain_whitelist = 0
>     > 2020/03/20 14:51:43.071| 85,2| client_side_request.cc(745)
>     > clientAccessCheckDone: The request CONNECT example.com:443
>     <http://example.com:443> is DENIED; last
>     > ACL checked: all
>     > ...
> 
>     If you want to make allow/deny decision based on individual request
>     URLs, your http_access rules must allow the CONNECT request. Once Squid
>     establishes (and bumps) the CONNECT tunnel, it will start processing
>     individual requests and apply http_access rules to each of them.
> 
>     To allow a CONNECT request, do not use regular URL syntax because
>     CONNECT requests use a different URI syntax. Sorry, I do not know
>     whether a url_regex ACL can be used for CONNECT URIs, but you can use
>     other ACLs if/as needed, of course.
> 
> 
>     HTH,
> 
>     Alex.
> 
> 
>     > ---------
>     > GET /abc/login HTTP/1.1
>     > Host: example.com <http://example.com>
>     > User-Agent: curl/7.54.0
>     > Accept: */*
>     > ----------
>     > ....
>     > ```
>     >
>     >
>     >
>     > --
>     > Sent from:
>     http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
>     > _______________________________________________
>     > squid-users mailing list
>     > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     > http://lists.squid-cache.org/listinfo/squid-users
>     >
> 



From gengchao62 at gmail.com  Sun Mar 29 22:58:26 2020
From: gengchao62 at gmail.com (saiyan_gc)
Date: Sun, 29 Mar 2020 17:58:26 -0500 (CDT)
Subject: [squid-users] Error negotiating SSL connection on FD 16
Message-ID: <1585522706899-0.post@n4.nabble.com>

Hi, I am trying to setup a https proxy server, and after I followed some
tutorial, created self signed certificate, configure the squid.conf, I also
copied the certificate to the client host and setup the https_proxy global
environment variable, I can do *curl https://www.google.com*. I saw
"172.16.0.16 TCP_TUNNEL/200 16567 CONNECT www.google.com:443 abc
HIER_DIRECT/216.58.193.68 -".

But I am trying to use my aws cli with "aws s3 ls", the access log will
throw "172.16.0.16 NONE/000 0 NONE error:transaction-end-before-headers -
HIER_NONE/ - -". 

And it throw "Error negotiating SSL connection on FD 16" in cahe.log

I am pretty new to squid, can anyone help me on this stupid question?

Here is my config file:

*https_port 3130 cert=/etc/squid/ssl_cert/example.com.cert \
    key=/etc/squid/ssl_cert/example.com.private  
auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/passwords
auth_param basic children 5 startup=0 idle=1
auth_param basic credentialsttl 2 hours
auth_param basic casesensitive off
acl ncsa_users proxy_auth REQUIRED
http_access deny !ncsa_users
http_access allow all*




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Tue Mar 31 14:15:08 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 1 Apr 2020 03:15:08 +1300
Subject: [squid-users] Error negotiating SSL connection on FD 16
In-Reply-To: <1585522706899-0.post@n4.nabble.com>
References: <1585522706899-0.post@n4.nabble.com>
Message-ID: <f4c77e1a-5c4f-7c6b-7969-98e96cb4a5d3@treenet.co.nz>

On 30/03/20 11:58 am, saiyan_gc wrote:
> Hi, I am trying to setup a https proxy server, and after I followed some
> tutorial, 

Which tutorial?

> created self signed certificate, configure the squid.conf, I also
> copied the certificate to the client host 

Which certificate?
 Where did you put it?
 Do both curl and the aws tool use that location?

> and setup the https_proxy global
> environment variable,

How did you set it up?

Do both curl and the aws tool use that non-standard environment variable?


> I can do *curl https://www.google.com*. I saw
> "172.16.0.16 TCP_TUNNEL/200 16567 CONNECT www.google.com:443 abc
> HIER_DIRECT/216.58.193.68 -".

This curl request does not match the squid.conf you provided. No
authentication credentials are provided, yet username "abc" is being logged.


> 
> But I am trying to use my aws cli with "aws s3 ls", the access log will
> throw "172.16.0.16 NONE/000 0 NONE error:transaction-end-before-headers -
> HIER_NONE/ - -". 

The TCP connection from client closed before any HTTP was received.

> 
> And it throw "Error negotiating SSL connection on FD 16" in cahe.log
> 

TLS handshake failure is likely why the TCP connection closed.

 Find out what failure is happening.


> 
> Here is my config file:
> 
> *https_port 3130 cert=/etc/squid/ssl_cert/example.com.cert \
>     key=/etc/squid/ssl_cert/example.com.private  
> auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/passwords
> auth_param basic children 5 startup=0 idle=1
> auth_param basic credentialsttl 2 hours
> auth_param basic casesensitive off
> acl ncsa_users proxy_auth REQUIRED
> http_access deny !ncsa_users
> http_access allow all*
> 
> 


Amos


