From akshay.k.hegde at gmail.com  Fri May  1 05:20:25 2020
From: akshay.k.hegde at gmail.com (Akshay Hegde)
Date: Fri, 1 May 2020 10:50:25 +0530
Subject: [squid-users] squid logging disable based on ACL & kernel: Out of
	memory
Message-ID: <CAH1tzCQ5m6+hUuPpcVnVVM=rWJh-nrXyscacgyXnMKhi8S82-A@mail.gmail.com>

Dear All,
I got 2 query which are as follows

*1. How to disable logging of few ACLs ? for example I have below ACL which
I trust and I do not enable caching *

[root at proxy squid]# cat no_cache_domain.txt
.ubuntu.com
.googlevideo.com
.googleapis.com
.googleusercontent.com
.windows.com
.windowsupdate.com
.kaspersky.com
.copernicus.eu
.praction.in
.webwerks.in

# and in squid.conf
acl no-cache-domains dstdomain "/etc/squid/no_cache_domain.txt"
cache deny no-cache-domains

*2. Kernel Out of Memory ( I currently have logrotate on weekly basis ),
how this issue can be fixed it runs nearly 12 hours without any error*

Log error is as follows:

May  1 08:45:20 proxy kernel: Out of memory: Kill process 24384 (squid)
score 961 or sacrifice child
May  1 08:45:20 proxy kernel: Killed process 24384, UID 0, (squid)
total-vm:23620544kB, anon-rss:15381672kB, file-rss:292kB
May  1 08:45:22 proxy squid[24382]: Squid Parent: child process 24384
exited due to signal 9 with status 0

[root at proxy squid]# cat /proc/swaps
Filename  Type Size Used Priority
/dev/sda3                               partition 8191992 38984 -1

[root at proxy squid]# cat /etc/redhat-release
Red Hat Enterprise Linux Server release 6.3 (Santiago)

[root at proxy squid]# squid -v
Squid Cache: Version 3.1.10

[root at proxy squid]# ll -sh /var/log/squid/access.log
37G -rw-r----- 1 squid squid 37G May  1 10:47 /var/log/squid/access.log

[root at proxy squid]# ll -sh /var/log/squid/store.log
52G -rw-r----- 1 squid squid 52G May  1 10:47 /var/log/squid/store.log

[root at proxy squid]# du -sh /cache/
23G /cache/

[root at proxy squid]# grep '^cache_dir' /etc/squid/squid.conf
cache_dir ufs /cache 25000 16 256

[root at proxy squid]# vmstat -s
     16334568  total memory
     16165900  used memory
       916616  active memory
     14824916  inactive memory
       168668  free memory
       111912  buffer memory
     14773484  swap cache
      8191992  total swap
        38984  used swap
      8153008  free swap
    150918525 non-nice user cpu ticks
      1039325 nice user cpu ticks
     88617581 system cpu ticks
   3955184009 idle cpu ticks
      8975352 IO-wait cpu ticks
      6237581 IRQ cpu ticks
     35714514 softirq cpu ticks
            0 stolen cpu ticks
   3099830316 pages paged in
    546843845 pages paged out
      2155651 pages swapped in
     11728162 pages swapped out
     78924125 interrupts
   3426967839 CPU context switches
   1577614862 boot time
       547399 forks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200501/be0e4a6a/attachment.htm>

From rousskov at measurement-factory.com  Fri May  1 13:35:02 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 1 May 2020 09:35:02 -0400
Subject: [squid-users] squid logging disable based on ACL & kernel: Out
 of memory
In-Reply-To: <CAH1tzCQ5m6+hUuPpcVnVVM=rWJh-nrXyscacgyXnMKhi8S82-A@mail.gmail.com>
References: <CAH1tzCQ5m6+hUuPpcVnVVM=rWJh-nrXyscacgyXnMKhi8S82-A@mail.gmail.com>
Message-ID: <7bbdbf59-0e43-2cf0-b074-47c8eb4b5846@measurement-factory.com>

On 5/1/20 1:20 AM, Akshay Hegde wrote:

> *1. How to disable logging of few ACLs ?

Use "access_log none aclX" to prevent creation of access.log records for
transactions matching aclX. See
http://lists.squid-cache.org/pipermail/squid-users/2020-April/021876.html for
some related caveats.


> *2. Kernel Out of Memory

This problem is most likely unrelated to logging. If your Squid is
gradually leaking memory (rather than just being overwhelmed with
traffic), then the first step towards removing those memory leaks would
be to upgrade your Squid from the unsupported and buggy v3.1.10.


HTH,

Alex.


From Cyoho at umpublishing.org  Fri May  1 14:56:20 2020
From: Cyoho at umpublishing.org (Cindy Yoho)
Date: Fri, 1 May 2020 14:56:20 +0000
Subject: [squid-users] Passing XML through squid proxy
Message-ID: <BN8PR08MB6420802EE795041C9002FD39DDAB0@BN8PR08MB6420.namprd08.prod.outlook.com>

Hi Folks,

I am brand new to squid, my main work areas being storage, VMware and linux.   I was asked to setup a forward proxy server on a CentOS VMware guest.   I initially chose nginx, which seemed to work fine most of the time but about once a week would stop working and require a reboot to get going again.   When I tried to get assistance with the nginx issue, I was told it was not supported as a forward proxy, and I should use squid.

So I started over, CentOS 7, squid 7:3.5.20-15.el7_6.1, and kept more or less the default config.  In my config I commented out all the possible internal networks except the ones in use, and added

acl  GOOD dstdomain .vertexsmb.com

The use case is as follows:

Our Order Entry server will request a tax calculation from a Vertex cloud server by sending XML code (below) through the squid server.   There is a firewall between us and the Vertex cloud.

The squid server returns the expected display when I put the test url into the browser on the squid server.   So the firewall is allowing squid to vertex.  When the Order Entry server sends the XML code, however, we get an error returned to the server making the request (below also).  I have also included the error I see in wireshark on the squid server when watching the transaction.   Any help would be greatly appreciated.

TIA
Cindy

XML CODE:

<soapenv:Envelope xmlns:soapenv="http://schemas.xmlsoap.org/soap/envelope/">
   <soapenv:Body xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema">
      <VertexEnvelope xmlns="urn:vertexinc:o-series:tps:7:0">
         <Login>
            <TrustedId>xxxxxxxxxxxxxxx</TrustedId>
         </Login>
         <QuotationRequest transactionType="SALE" returnAssistedParametersIndicator="true" documentDate="2019-11-18" documentNumber="TestNewTax">
            <Seller>
               <Company>ABC Widgets</Company>
               <PhysicalOrigin>
                  <City>NASHVILLE</City>
                  <MainDivision>TN</MainDivision>
                  <PostalCode>372281306</PostalCode>
               </PhysicalOrigin>
            </Seller>
            <Customer>
               <CustomerCode>nnnnnnnnn</CustomerCode>
               <Destination>
                  <City>HENDERSONVILLE</City>
                  <MainDivision>TN</MainDivision>
                  <PostalCode>370754525</PostalCode>
               </Destination>
            </Customer>
            <LineItem>
               <Product productClass="AEU">9781426740565</Product>
               <Quantity>1</Quantity>
               <ExtendedPrice>10.00</ExtendedPrice>
               <FlexibleFields>
                     <FlexibleCodeField fieldId="1">G1</FlexibleCodeField>
               </FlexibleFields>
            </LineItem>
         </QuotationRequest>
         <ApplicationData>
            <Sender>Ecometry</Sender>
         </ApplicationData>
      </VertexEnvelope>
   </soapenv:Body>
</soapenv:Envelope>

XML ERROR:

ERROR:  The requested URL could not be retrieved.
Missing or incorrect access protocol

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
<meta type="copyright" content="Copyright (C) 1996-2016 The Squid Software Foundation and contributors">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>ERROR: The requested URL could not be retrieved</title>
<style type="text/css"><!--
 /*
* Copyright (C) 1996-2016 The Squid Software Foundation and contributors
*
* Squid software is distributed under GPLv2+ license and includes
* contributions from numerous individuals and organizations.
* Please see the COPYING and CONTRIBUTORS files for details.
*/

WIRESHARK ERROR on Squid Server:

HTTP     3606 HTTP/1.1 400 Bad Request (text/html)

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200501/c14f4fa3/attachment.htm>

From rousskov at measurement-factory.com  Fri May  1 16:26:22 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 1 May 2020 12:26:22 -0400
Subject: [squid-users] Passing XML through squid proxy
In-Reply-To: <BN8PR08MB6420802EE795041C9002FD39DDAB0@BN8PR08MB6420.namprd08.prod.outlook.com>
References: <BN8PR08MB6420802EE795041C9002FD39DDAB0@BN8PR08MB6420.namprd08.prod.outlook.com>
Message-ID: <8c6d575c-6388-0522-386a-0bfcbe4d9014@measurement-factory.com>

On 5/1/20 10:56 AM, Cindy Yoho wrote:

> When the Order Entry server sends the XML code,
> we get an error returned to the server making the request

Perhaps your Order Entry server does not use HTTP when talking to Squid?

Squid does not really care about the request payload, but the request
has to use the HTTP transport protocol. So sending a SOAP/XML request
payload over HTTP is OK, but sending raw SOAP (or SOAP over something
other than HTTP) is not.

If you can post a packet capture of the Order Entry server talking to
Squid (not the text interpretation of Squid response but the actual
packets going from the Order Entry server to Squid; use libpcap format
which is often the default for Wireshark export), then we should be able
to confirm whether your Order Entry server is using the right protocol
to talk to/through Squid.

The same packet capture can point to HTTP request problems if the Order
Entry server is using HTTP but sending some HTTP token that Squid does
not like (or not sending an HTTP token that Squid needs).


HTH,

Alex.


From akshay.k.hegde at gmail.com  Fri May  1 16:43:48 2020
From: akshay.k.hegde at gmail.com (Akshay Hegde)
Date: Fri, 1 May 2020 22:13:48 +0530
Subject: [squid-users] squid logging disable based on ACL & kernel: Out
	of memory
In-Reply-To: <7bbdbf59-0e43-2cf0-b074-47c8eb4b5846@measurement-factory.com>
References: <CAH1tzCQ5m6+hUuPpcVnVVM=rWJh-nrXyscacgyXnMKhi8S82-A@mail.gmail.com>
 <7bbdbf59-0e43-2cf0-b074-47c8eb4b5846@measurement-factory.com>
Message-ID: <CAH1tzCS+Skk40RVqFZwK+32fyqdeyv3L2=eZ6rrwS3gYck_4cA@mail.gmail.com>

Dear Alex,

Thanks a lot, I started installing new squid on centos8 as you suggested.

I got one more doubt its about logging.

I have below option globally, which I don't want to make "off"
strip_query_terms on

and my ACL as follows:
logformat squid_custom %ts.%03tu %6tr %>a %Ss/%>Hs %<st %rm %ru %un %Sh/%<A
%mt
acl track dstdomain "/etc/squid/sites_track.txt"
access_log /var/log/squid/full_site_links.log squid_custom track

however for specific ACL I would like to log full URL with query
parameters, how this can be done ?

- Akshay


On Fri, May 1, 2020 at 7:05 PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 5/1/20 1:20 AM, Akshay Hegde wrote:
>
> > *1. How to disable logging of few ACLs ?
>
> Use "access_log none aclX" to prevent creation of access.log records for
> transactions matching aclX. See
> http://lists.squid-cache.org/pipermail/squid-users/2020-April/021876.html
> for
> some related caveats.
>
>
> > *2. Kernel Out of Memory
>
> This problem is most likely unrelated to logging. If your Squid is
> gradually leaking memory (rather than just being overwhelmed with
> traffic), then the first step towards removing those memory leaks would
> be to upgrade your Squid from the unsupported and buggy v3.1.10.
>
>
> HTH,
>
> Alex.
>


-- 
<https://about.me/akshay.k.hegde?promo=email_sig&utm_source=product&utm_medium=email_sig&utm_campaign=edit_panel&utm_content=thumb>
Akshay Hegde
about.me/akshay.k.hegde
<https://about.me/akshay.k.hegde?promo=email_sig&utm_source=product&utm_medium=email_sig&utm_campaign=edit_panel&utm_content=thumb>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200501/2d6106e3/attachment.htm>

From rousskov at measurement-factory.com  Fri May  1 19:30:38 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 1 May 2020 15:30:38 -0400
Subject: [squid-users] squid logging disable based on ACL & kernel: Out
 of memory
In-Reply-To: <CAH1tzCS+Skk40RVqFZwK+32fyqdeyv3L2=eZ6rrwS3gYck_4cA@mail.gmail.com>
References: <CAH1tzCQ5m6+hUuPpcVnVVM=rWJh-nrXyscacgyXnMKhi8S82-A@mail.gmail.com>
 <7bbdbf59-0e43-2cf0-b074-47c8eb4b5846@measurement-factory.com>
 <CAH1tzCS+Skk40RVqFZwK+32fyqdeyv3L2=eZ6rrwS3gYck_4cA@mail.gmail.com>
Message-ID: <3a2cb6ba-958c-5ef6-6826-28bccf1a807a@measurement-factory.com>

On 5/1/20 12:43 PM, Akshay Hegde wrote:

> I have below option globally, which I don't want to make "off"
> strip_query_terms on

> acl track dstdomain "/etc/squid/sites_track.txt"
> access_log /var/log/squid/full_site_links.log squid_custom track

> however for specific ACL I would like to log full URL with query
> parameters, how this can be done ?

I have not tested this, and the results may be version-dependent, but
according to logformat documentation[1], %ru honors strip_query_terms
while %>ru does not:

    logformat strippedFormat %ts... %ru ...
    access_log ... strippedFormat track !specific_ACL

    logformat detailedFormat %ts... %>ru ...
    access_log ... detailedFormat track specific_ACL

[1] http://www.squid-cache.org/Doc/config/logformat/


HTH,

Alex.

> On Fri, May 1, 2020 at 7:05 PM Alex Rousskov wrote:
> 
>     On 5/1/20 1:20 AM, Akshay Hegde wrote:
> 
>     > *1. How to disable logging of few ACLs ?
> 
>     Use "access_log none aclX" to prevent creation of access.log records for
>     transactions matching aclX. See
>     http://lists.squid-cache.org/pipermail/squid-users/2020-April/021876.html
>     for
>     some related caveats.
> 
> 
>     > *2. Kernel Out of Memory
> 
>     This problem is most likely unrelated to logging. If your Squid is
>     gradually leaking memory (rather than just being overwhelmed with
>     traffic), then the first step towards removing those memory leaks would
>     be to upgrade your Squid from the unsupported and buggy v3.1.10.
> 
> 
>     HTH,
> 
>     Alex.
> 
> 
> 
> -- 
> <https://about.me/akshay.k.hegde?promo=email_sig&utm_source=product&utm_medium=email_sig&utm_campaign=edit_panel&utm_content=thumb>
> 	
> Akshay Hegde
> about.me/akshay.k.hegde
> <https://about.me/akshay.k.hegde?promo=email_sig&utm_source=product&utm_medium=email_sig&utm_campaign=edit_panel&utm_content=thumb>
> 
> 



From squid3 at treenet.co.nz  Fri May  1 19:32:45 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 2 May 2020 07:32:45 +1200
Subject: [squid-users] squid logging disable based on ACL & kernel: Out
 of memory
In-Reply-To: <CAH1tzCS+Skk40RVqFZwK+32fyqdeyv3L2=eZ6rrwS3gYck_4cA@mail.gmail.com>
References: <CAH1tzCQ5m6+hUuPpcVnVVM=rWJh-nrXyscacgyXnMKhi8S82-A@mail.gmail.com>
 <7bbdbf59-0e43-2cf0-b074-47c8eb4b5846@measurement-factory.com>
 <CAH1tzCS+Skk40RVqFZwK+32fyqdeyv3L2=eZ6rrwS3gYck_4cA@mail.gmail.com>
Message-ID: <43d04d79-8f7f-56bc-956a-ab588f3093b1@treenet.co.nz>

On 2/05/20 4:43 am, Akshay Hegde wrote:
> Dear Alex,
> 
> Thanks a lot, I started installing new squid on centos8 as you suggested.
> 
> I got one more doubt its about logging.
> 
> I have below option globally, which I don't want to make "off"
> strip_query_terms on
> 
> and my ACL as follows:
> logformat squid_custom %ts.%03tu %6tr %>a %Ss/%>Hs %<st %rm %ru %un
> %Sh/%<A %mt
> acl track dstdomain "/etc/squid/sites_track.txt"
> access_log /var/log/squid/full_site_links.log squid_custom track
> 
> however for specific ACL I would like to log full URL with query
> parameters, how this can be done ?
> 

If you are upgrading to a Squid with annotation support you can use an
external ACL helper to do the URL mangling you want for a custom log
%note column.
 Otherwise there is only that global on/off setting.


NP: stripping query-string is a very weak workaround for
security+privacy flaws. Any details hidden are being published elsewhere
anyway. All it does is prevent local detection of important information
leaks.

Amos


From akshay.k.hegde at gmail.com  Sat May  2 12:54:26 2020
From: akshay.k.hegde at gmail.com (Akshay Hegde)
Date: Sat, 2 May 2020 18:24:26 +0530
Subject: [squid-users] squid logging disable based on ACL & kernel: Out
	of memory
In-Reply-To: <3a2cb6ba-958c-5ef6-6826-28bccf1a807a@measurement-factory.com>
References: <CAH1tzCQ5m6+hUuPpcVnVVM=rWJh-nrXyscacgyXnMKhi8S82-A@mail.gmail.com>
 <7bbdbf59-0e43-2cf0-b074-47c8eb4b5846@measurement-factory.com>
 <CAH1tzCS+Skk40RVqFZwK+32fyqdeyv3L2=eZ6rrwS3gYck_4cA@mail.gmail.com>
 <3a2cb6ba-958c-5ef6-6826-28bccf1a807a@measurement-factory.com>
Message-ID: <CAH1tzCQv0vJAG5w7TzrqktGpchBNOLMCW3dZ1w+izNdwXjBB+Q@mail.gmail.com>

Dear Alex,

Thank you so much, I will test on new squid,  on old 3.1 it didn't work as
you said.

-Akshay

On Sat, May 2, 2020, 1:00 AM Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 5/1/20 12:43 PM, Akshay Hegde wrote:
>
> > I have below option globally, which I don't want to make "off"
> > strip_query_terms on
>
> > acl track dstdomain "/etc/squid/sites_track.txt"
> > access_log /var/log/squid/full_site_links.log squid_custom track
>
> > however for specific ACL I would like to log full URL with query
> > parameters, how this can be done ?
>
> I have not tested this, and the results may be version-dependent, but
> according to logformat documentation[1], %ru honors strip_query_terms
> while %>ru does not:
>
>     logformat strippedFormat %ts... %ru ...
>     access_log ... strippedFormat track !specific_ACL
>
>     logformat detailedFormat %ts... %>ru ...
>     access_log ... detailedFormat track specific_ACL
>
> [1] http://www.squid-cache.org/Doc/config/logformat/
>
>
> HTH,
>
> Alex.
>
> > On Fri, May 1, 2020 at 7:05 PM Alex Rousskov wrote:
> >
> >     On 5/1/20 1:20 AM, Akshay Hegde wrote:
> >
> >     > *1. How to disable logging of few ACLs ?
> >
> >     Use "access_log none aclX" to prevent creation of access.log records
> for
> >     transactions matching aclX. See
> >
> http://lists.squid-cache.org/pipermail/squid-users/2020-April/021876.html
> >     for
> >     some related caveats.
> >
> >
> >     > *2. Kernel Out of Memory
> >
> >     This problem is most likely unrelated to logging. If your Squid is
> >     gradually leaking memory (rather than just being overwhelmed with
> >     traffic), then the first step towards removing those memory leaks
> would
> >     be to upgrade your Squid from the unsupported and buggy v3.1.10.
> >
> >
> >     HTH,
> >
> >     Alex.
> >
> >
> >
> > --
> > <
> https://about.me/akshay.k.hegde?promo=email_sig&utm_source=product&utm_medium=email_sig&utm_campaign=edit_panel&utm_content=thumb
> >
> >
> > Akshay Hegde
> > about.me/akshay.k.hegde
> > <
> https://about.me/akshay.k.hegde?promo=email_sig&utm_source=product&utm_medium=email_sig&utm_campaign=edit_panel&utm_content=thumb
> >
> >
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200502/793eca36/attachment.htm>

From akshay.k.hegde at gmail.com  Sat May  2 12:58:29 2020
From: akshay.k.hegde at gmail.com (Akshay Hegde)
Date: Sat, 2 May 2020 18:28:29 +0530
Subject: [squid-users] squid logging disable based on ACL & kernel: Out
	of memory
In-Reply-To: <43d04d79-8f7f-56bc-956a-ab588f3093b1@treenet.co.nz>
References: <CAH1tzCQ5m6+hUuPpcVnVVM=rWJh-nrXyscacgyXnMKhi8S82-A@mail.gmail.com>
 <7bbdbf59-0e43-2cf0-b074-47c8eb4b5846@measurement-factory.com>
 <CAH1tzCS+Skk40RVqFZwK+32fyqdeyv3L2=eZ6rrwS3gYck_4cA@mail.gmail.com>
 <43d04d79-8f7f-56bc-956a-ab588f3093b1@treenet.co.nz>
Message-ID: <CAH1tzCTWcYAnOJ4BBTqqZPwbOprki-P1sYXRjaRTU8qdzrBPYA@mail.gmail.com>

Dear Amos,

Can you please elaborate, I didnt understand. If possible can you explain
with one example ? I mean behaviour of security and privacy flaws when
strip_query_terms is on and when strip_query_terms is off.

- Akshay

On Sat, May 2, 2020, 1:03 AM Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 2/05/20 4:43 am, Akshay Hegde wrote:
> > Dear Alex,
> >
> > Thanks a lot, I started installing new squid on centos8 as you suggested.
> >
> > I got one more doubt its about logging.
> >
> > I have below option globally, which I don't want to make "off"
> > strip_query_terms on
> >
> > and my ACL as follows:
> > logformat squid_custom %ts.%03tu %6tr %>a %Ss/%>Hs %<st %rm %ru %un
> > %Sh/%<A %mt
> > acl track dstdomain "/etc/squid/sites_track.txt"
> > access_log /var/log/squid/full_site_links.log squid_custom track
> >
> > however for specific ACL I would like to log full URL with query
> > parameters, how this can be done ?
> >
>
> If you are upgrading to a Squid with annotation support you can use an
> external ACL helper to do the URL mangling you want for a custom log
> %note column.
>  Otherwise there is only that global on/off setting.
>
>
> NP: stripping query-string is a very weak workaround for
> security+privacy flaws. Any details hidden are being published elsewhere
> anyway. All it does is prevent local detection of important information
> leaks.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200502/1c67b6f5/attachment.htm>

From email_arjun at yahoo.com  Sun May  3 11:51:02 2020
From: email_arjun at yahoo.com (Arjun K)
Date: Sun, 3 May 2020 11:51:02 +0000 (UTC)
Subject: [squid-users] Squid Proxy not blocking websites
References: <2093095721.337076.1588506662085.ref@mail.yahoo.com>
Message-ID: <2093095721.337076.1588506662085@mail.yahoo.com>

Hi All
The below is the configuration defined in the proxy server.The issue is that the proxy is not blocking the websites mentioned in a file named denylist.txt.
Kindly let me know what needs to be changed to block the websites.


####IP Ranges allowed to use proxyacl localnet src 10.196.0.0/16
acl localnet src 10.197.0.0/16acl localnet src 10.198.0.0/16acl localnet src 10.199.0.0/16acl localnet src 10.200.0.0/16
####Allowed and Denied URLsacl allowedurl dstdomain /etc/squid/allowed_url.txtacl denylist dstdomain /etc/squid/denylist.txt
acl windowsupdate dstdomain windowsupdate.microsoft.comacl windowsupdate dstdomain .update.microsoft.comacl windowsupdate dstdomain download.windowsupdate.comacl windowsupdate dstdomain redir.metaservices.microsoft.comacl windowsupdate dstdomain images.metaservices.microsoft.comacl windowsupdate dstdomain c.microsoft.comacl windowsupdate dstdomain www.download.windowsupdate.comacl windowsupdate dstdomain wustat.windows.comacl windowsupdate dstdomain crl.microsoft.comacl windowsupdate dstdomain sls.microsoft.comacl windowsupdate dstdomain productactivation.one.microsoft.comacl windowsupdate dstdomain ntservicepack.microsoft.comacl windowsupdate dstdomain eu.vortex-win.data.microsoft.comacl windowsupdate dstdomain eu-v20.events.data.microsoft.comacl windowsupdate dstdomain usseu1northprod.blob.core.windows.netacl windowsupdate dstdomain usseu1westprod.blob.core.windows.netacl windowsupdate dstdomain winatp-gw-neu.microsoft.comacl windowsupdate dstdomain winatp-gw-weu.microsoft.comacl windowsupdate dstdomain wseu1northprod.blob.core.windows.netacl windowsupdate dstdomain wseu1westprod.blob.core.windows.netacl windowsupdate dstdomain automatedirstrprdweu.blob.core.windows.netacl windowsupdate dstdomain automatedirstrprdneu.blob.core.windows.netacl windowsupdate dstdomain play.google.comacl windowsupdate dstdomain go.microsoft.com
acl CONNECT method CONNECTacl wuCONNECT dstdomain www.update.microsoft.comacl wuCONNECT dstdomain sls.microsoft.comhttp_access allow CONNECT wuCONNECT localnethttp_access allow windowsupdate localnet
acl Safe_ports port 80 # httpacl Safe_ports port 443 # httpsacl CONNECT method CONNECT
http_access allow allowedurlhttp_access deny denylisthttp_access allow localhost managerhttp_access allow localhosthttp_access allow localnethttp_access deny managerhttp_access deny !Safe_portshttp_access deny all
http_port 8080
cache_dir ufs /var/spool/squid 10000 16 256coredump_dir /var/spool/squid
refresh_pattern ^ftp:? ? ? ? ? ?1440? ? 20%? ? ?10080refresh_pattern ^gopher:? ? ? ? 1440? ? 0%? ? ? 1440refresh_pattern -i (/cgi-bin/|\?) 0? ? ?0%? ? ? 0refresh_pattern .? ? ? ? ? ? ? ?0? ? ? ?20%? ? ?4320refresh_pattern -i windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-imsrefresh_pattern -i microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-imsrefresh_pattern -i windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims



RegardsArjun K.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200503/343cf3e0/attachment.htm>

From 3m9n51s2ewut at thismonkey.com  Mon May  4 02:41:08 2020
From: 3m9n51s2ewut at thismonkey.com (Scott)
Date: Mon, 4 May 2020 12:41:08 +1000
Subject: [squid-users] Best way to prevent squid from bumping CONNECTs
In-Reply-To: <9d5db430-5186-1080-fb3e-abe409aed50a@measurement-factory.com>
References: <mailman.520.1588063344.3558.squid-users@lists.squid-cache.org>
 <20200430161030.GA87833@thismonkey.com>
 <9d5db430-5186-1080-fb3e-abe409aed50a@measurement-factory.com>
Message-ID: <20200504024107.GA16341@thismonkey.com>

On Thu, Apr 30, 2020 at 04:05:43PM -0400, Alex Rousskov wrote:
> On 4/30/20 12:10 PM, Scott wrote:
> 
> >> * For http_port configured with an ssl-bump flag, HTTP CONNECT tunnels
> >> are sent to the SslBump code.
> >>
> >> * For https_port configured with an ssl-bump flag, all traffic is sent
> >> to the SslBump code (by faking a corresponding HTTP CONNECT request).
> 
> 
> > These `fake' CONNECT requests I assume only contain the IP address of the 
> > upstream server, not the hostname, as intercepted SSL connections are TCP 
> > OPENs.
> 
> Modern Squid replaces TCP-derived destination IP address with TLS
> SNI-derived domain name when generating the second fake CONNECT request.
> The second CONNECT is generated during SslBump step2, after parsing TLS
> client handshake.
> 
> 
> > Am I right then in saying that using ssl::server_name is useless for bumped 
> > intercepted connections?
> 
> It may be useful for ACLs checked during SslBump step2 (because it will
> check the TLS client SNI-derived domain name) and during step3 (when it
> will check TLS server certificate-derived CN and SubjectAltName).

acl tcp_open_connect_sslbump at_step SslBump1
acl ssl_splice_sni ssl::server_name "/usr/local/etc/squid/acls/splice_sni"
acl guest_net_src src x.y.z.0/24

ssl_bump peek tcp_open_connect_sslbump
ssl_bump splice ssl_splice_sni
ssl_bump bump guest_net_src
ssl_bump splice

where I splice instead of bump for destinations that are often used with 
certificate pinning software (.apple.com with iOS for example).

https://wiki.squid-cache.org/Features/SslPeekAndSplice says "At no point 
during ssl_bump processing will dstdomain ACL work".

Does that also imply that `ssl::server_name' won't work (or is not required) 
for `http_access' statements?

I have config like this:

acl no_proxy_dstdomain dstdomain "/usr/local/etc/squid/acls/no_proxy_dstdomain"
http_access deny no_proxy_dstdomain
acl no_proxy_sni ssl::server_name "/usr/local/etc/squid/acls/no_proxy_dstdomain"
http_access deny no_proxy_sni

Are the last two lines redundant?
Or are they required for spliced connections?
Or should I just convert those lines into ssl_bump terminate no_proxy_sni ?

And finally, I want to use a different outgoing tcp address for intercepted 
connections.  What's the best ACL to match those?  Or should I just match 
explicit proxy connections by port? (ie !myport 3128)

Thanks for your help,
Scott



From rousskov at measurement-factory.com  Mon May  4 16:31:57 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 4 May 2020 12:31:57 -0400
Subject: [squid-users] Best way to prevent squid from bumping CONNECTs
In-Reply-To: <20200504024107.GA16341@thismonkey.com>
References: <mailman.520.1588063344.3558.squid-users@lists.squid-cache.org>
 <20200430161030.GA87833@thismonkey.com>
 <9d5db430-5186-1080-fb3e-abe409aed50a@measurement-factory.com>
 <20200504024107.GA16341@thismonkey.com>
Message-ID: <6f609033-54d4-db72-0e69-66c54fc085af@measurement-factory.com>

On 5/3/20 10:41 PM, Scott wrote:

> acl tcp_open_connect_sslbump at_step SslBump1
> acl ssl_splice_sni ssl::server_name "/usr/local/etc/squid/acls/splice_sni"
> acl guest_net_src src x.y.z.0/24
> 
> ssl_bump peek tcp_open_connect_sslbump
> ssl_bump splice ssl_splice_sni
> ssl_bump bump guest_net_src
> ssl_bump splice


> where I splice instead of bump for destinations that are often used with 
> certificate pinning software (.apple.com with iOS for example).


> https://wiki.squid-cache.org/Features/SslPeekAndSplice says "At no point 
> during ssl_bump processing will dstdomain ACL work".

I have not tested this, but I would expect the dstdomain ACL to work
during SslBump steps using the destination address from the (real or
fake) CONNECT request URI. It is possible that, for the author of that
wiki statement, that kind of functionality is equivalent to "not work",
but I personally would not phrase it that way.


> Does that also imply that `ssl::server_name' won't work
> for `http_access' statements?

No, it does not. Both ACLs should "work". Naturally, both ACLs have
their own limitations and intended purposes. If you find problems with
their documentation in squid.conf.documented (or want to improve it),
please consider filing a bug report (or submitting a pull request). You
can also improve the wiki page, of course, but I recommend coordinating
with the paragraph author before changing that paragraph:

https://wiki.squid-cache.org/action/diff/Features/SslPeekAndSplice?action=diff&rev1=19&rev2=20



> I have config like this:

> acl no_proxy_dstdomain dstdomain "/usr/local/etc/squid/acls/no_proxy_dstdomain"
> http_access deny no_proxy_dstdomain
> acl no_proxy_sni ssl::server_name "/usr/local/etc/squid/acls/no_proxy_dstdomain"
> http_access deny no_proxy_sni

> Are the last two lines redundant?

I bet there are transactions (or transaction processing steps) that
either one of the two ACLs will match while the other will not, but I
have not studied this in detail.


> Or are they required for spliced connections?

"Required" may be too strong of a word because, as you said below, you
can probably accomplish similar outcome using terminate rules. However,
the details of that outcome would differ, so I can imagine that
http_access is the right or the best approach in _some_ cases.


> Or should I just convert those lines into ssl_bump terminate no_proxy_sni ?

A matching "http_access deny" forces Squid to generate an HTTP error
response. If that happens during SslBump processing, the connection with
the client will be bumped (in hope) to deliver that response. If such
bumping is no longer possible, I am not sure what happens, but I would
expect Squid to close the underlying TLS/TCP connection.

A matching "ssl_bump terminate" rule closes the client TLS/TCP
connection without generating an HTTP error response. It can only match
during SslBump processing.

Use appropriate rule(s) to accomplish what you actually want to
accomplish. And test that your expectations match what Squid is doing.

I apologize that I cannot give simpler yes/no answers to your
(implicitly loaded) questions. I hope the above responses give you
enough information to find the answers you are looking for.


> And finally, I want to use a different outgoing tcp address for intercepted 
> connections.  What's the best ACL to match those?  Or should I just match 
> explicit proxy connections by port? (ie !myport 3128)

I would start by testing the myportname ACL(s).


HTH,

Alex.


From mariolatif741 at yandex.com  Tue May  5 09:04:15 2020
From: mariolatif741 at yandex.com (mariolatif741)
Date: Tue, 5 May 2020 04:04:15 -0500 (CDT)
Subject: [squid-users] Let Squid use SSL certificate for a parent cache peer
Message-ID: <1588669455105-0.post@n4.nabble.com>

Hello,

I have a Squid proxy server (proxy A) and I redirect all its traffic to
another proxy (proxy B) using a parent cache peer.

However, proxy B requires a SSL certificate to be used so it can intercept
the HTTPS requests and read them.

I want to specify the path of the CA certificate to Squid in proxy A so my
users can be redirected to proxy B without having to install the CA
certificate.

Is it possible?



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Tue May  5 09:19:42 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 May 2020 21:19:42 +1200
Subject: [squid-users] squid logging disable based on ACL & kernel: Out
 of memory
In-Reply-To: <CAH1tzCTWcYAnOJ4BBTqqZPwbOprki-P1sYXRjaRTU8qdzrBPYA@mail.gmail.com>
References: <CAH1tzCQ5m6+hUuPpcVnVVM=rWJh-nrXyscacgyXnMKhi8S82-A@mail.gmail.com>
 <7bbdbf59-0e43-2cf0-b074-47c8eb4b5846@measurement-factory.com>
 <CAH1tzCS+Skk40RVqFZwK+32fyqdeyv3L2=eZ6rrwS3gYck_4cA@mail.gmail.com>
 <43d04d79-8f7f-56bc-956a-ab588f3093b1@treenet.co.nz>
 <CAH1tzCTWcYAnOJ4BBTqqZPwbOprki-P1sYXRjaRTU8qdzrBPYA@mail.gmail.com>
Message-ID: <395cb8f6-599a-f468-28af-eddae0240a6f@treenet.co.nz>

On 3/05/20 12:58 am, Akshay Hegde wrote:
> Dear Amos,
> 
> Can you please elaborate, I didnt understand. If possible can you
> explain with one example ? I mean behaviour of security and privacy
> flaws when?
> strip_query_terms is on and when?strip_query_terms is off.
> 

That directive only affects the URLs visible in your logs etc. on the
proxy machine. It's main purpose is to prevent security/privacy
information leaks when site store sensitive info in the query-string of
the URL. The benefit is that your service is not a vector for those leaks.

On the other hand, it also prevents you being able to troubleshoot a lot
of types of issue with any site using query strings. Both allowing a
range of security attacks to hide themselves, and preventing you being
aware when sensitive info is wrongly placed in the URL.

It is up to you to decide which type of security/privacy issue is the
most important to prevent.


I bring this up because there have recently been several high-profile
services caught for major credential leaks - noticed only because some
people paid attention to their query-string's.

Amos


From squid3 at treenet.co.nz  Tue May  5 09:30:34 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 May 2020 21:30:34 +1200
Subject: [squid-users] Let Squid use SSL certificate for a parent cache
 peer
In-Reply-To: <1588669455105-0.post@n4.nabble.com>
References: <1588669455105-0.post@n4.nabble.com>
Message-ID: <08ad2f6d-4e18-4120-f009-613e345ee965@treenet.co.nz>

On 5/05/20 9:04 pm, mariolatif741 wrote:
> Hello,
> 
> I have a Squid proxy server (proxy A) and I redirect all its traffic to
> another proxy (proxy B) using a parent cache peer.
> 
> However, proxy B requires a SSL certificate to be used so it can intercept
> the HTTPS requests and read them.
> 
> I want to specify the path of the CA certificate to Squid in proxy A so my
> users can be redirected to proxy B without having to install the CA
> certificate.
> 
> Is it possible?

If the client is participating in the TLS handshake it *always* requires
the CA to be installed.


To use TLS on the connection between proxyA and proxyB:

  cache_peer proxyB parent 3128 0 tls-ca=/path/to/proxyB_CA.pem

Note that this is only to encrypt traffic between the proxies. When the
client is not involved.


To further improve security you should also use a client certificate for
proxyA and setup client cert validation between the proxies.

Amos


From squid3 at treenet.co.nz  Tue May  5 09:38:39 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 May 2020 21:38:39 +1200
Subject: [squid-users] Best way to prevent squid from bumping CONNECTs
In-Reply-To: <6f609033-54d4-db72-0e69-66c54fc085af@measurement-factory.com>
References: <mailman.520.1588063344.3558.squid-users@lists.squid-cache.org>
 <20200430161030.GA87833@thismonkey.com>
 <9d5db430-5186-1080-fb3e-abe409aed50a@measurement-factory.com>
 <20200504024107.GA16341@thismonkey.com>
 <6f609033-54d4-db72-0e69-66c54fc085af@measurement-factory.com>
Message-ID: <6be17362-5021-b268-6129-0d2e075d3b9d@treenet.co.nz>

On 5/05/20 4:31 am, Alex Rousskov wrote:
> On 5/3/20 10:41 PM, Scott wrote:
> 
>> acl tcp_open_connect_sslbump at_step SslBump1
>> acl ssl_splice_sni ssl::server_name "/usr/local/etc/squid/acls/splice_sni"
>> acl guest_net_src src x.y.z.0/24
>>
>> ssl_bump peek tcp_open_connect_sslbump
>> ssl_bump splice ssl_splice_sni
>> ssl_bump bump guest_net_src
>> ssl_bump splice
> 
> 
>> where I splice instead of bump for destinations that are often used with 
>> certificate pinning software (.apple.com with iOS for example).
> 
> 
>> https://wiki.squid-cache.org/Features/SslPeekAndSplice says "At no point 
>> during ssl_bump processing will dstdomain ACL work".
> 
> I have not tested this, but I would expect the dstdomain ACL to work
> during SslBump steps using the destination address from the (real or
> fake) CONNECT request URI. It is possible that, for the author of that
> wiki statement, that kind of functionality is equivalent to "not work",
> but I personally would not phrase it that way.
> 

We do not save the CONNECT tunnel message objects in the TLS handshake
state objects. As such the state needed by dstdomain is not available
during ssl_bump ACL processing.

Only state from the TCP connection and the underway TLS handshake are
guaranteed to be available to the ssl_bump ACLs. Anything else is
best-effort.

 At least that was the situation when that documentation was written.
The bugs we have about other CONNECT state not being available are still
open so I doubt the situation has changed even with the more recent
refactoring.

Amos


From mariolatif741 at yandex.com  Tue May  5 09:48:12 2020
From: mariolatif741 at yandex.com (mariolatif741)
Date: Tue, 5 May 2020 04:48:12 -0500 (CDT)
Subject: [squid-users] Let Squid use SSL certificate for a parent cache
	peer
In-Reply-To: <08ad2f6d-4e18-4120-f009-613e345ee965@treenet.co.nz>
References: <1588669455105-0.post@n4.nabble.com>
 <08ad2f6d-4e18-4120-f009-613e345ee965@treenet.co.nz>
Message-ID: <1588672092253-0.post@n4.nabble.com>

Since you said "If the client is participating in the TLS handshake it
*always* requires 
the CA to be installed.", then I guess what I want to do is not possible.

Can I make Squid send the requests received from the client to the cache
peer? (so the cache peer would see the requests coming from the Squid server
and not from the client), I think if this is possible then it'd help in my
case.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From Antony.Stone at squid.open.source.it  Tue May  5 10:06:34 2020
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 5 May 2020 12:06:34 +0200
Subject: [squid-users] Let Squid use SSL certificate for a parent cache
	peer
In-Reply-To: <1588672092253-0.post@n4.nabble.com>
References: <1588669455105-0.post@n4.nabble.com>
 <08ad2f6d-4e18-4120-f009-613e345ee965@treenet.co.nz>
 <1588672092253-0.post@n4.nabble.com>
Message-ID: <202005051206.34187.Antony.Stone@squid.open.source.it>

On Tuesday 05 May 2020 at 11:48:12, mariolatif741 wrote:

> Since you said "If the client is participating in the TLS handshake it
> *always* requires the CA to be installed.", then I guess what I want to do
> is not possible.
> 
> Can I make Squid send the requests received from the client to the cache
> peer? (so the cache peer would see the requests coming from the Squid
> server and not from the client), I think if this is possible then it'd
> help in my case.

What are you trying to achieve?

It sounds as though you want the client to talk to proxy A, which talks to 
proxy B, which sends requests to the Internet, and you want to do content 
inspection / filtering on proxy B.

What is the purpose of proxy A?

Regards,


Antony.

-- 
"Remember: the S in IoT stands for Security."

 - Jan-Piet Mens

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Tue May  5 10:14:01 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 May 2020 22:14:01 +1200
Subject: [squid-users] Let Squid use SSL certificate for a parent cache
 peer
In-Reply-To: <1588672092253-0.post@n4.nabble.com>
References: <1588669455105-0.post@n4.nabble.com>
 <08ad2f6d-4e18-4120-f009-613e345ee965@treenet.co.nz>
 <1588672092253-0.post@n4.nabble.com>
Message-ID: <31067165-52ff-b54c-c66d-4a08e8b75d79@treenet.co.nz>

On 5/05/20 9:48 pm, mariolatif741 wrote:
> Since you said "If the client is participating in the TLS handshake it
> *always* requires 
> the CA to be installed.", then I guess what I want to do is not possible.
> 
> Can I make Squid send the requests received from the client to the cache
> peer? (so the cache peer would see the requests coming from the Squid server
> and not from the client), I think if this is possible then it'd help in my
> case.

That is what peers are for. So yes - with the caveat that it is not
clear whether what you are calling "requests" are actually HTTP messages.


Amos


From mariolatif741 at yandex.com  Tue May  5 10:21:19 2020
From: mariolatif741 at yandex.com (mariolatif741)
Date: Tue, 5 May 2020 05:21:19 -0500 (CDT)
Subject: [squid-users] Let Squid use SSL certificate for a parent cache
	peer
In-Reply-To: <202005051206.34187.Antony.Stone@squid.open.source.it>
References: <1588669455105-0.post@n4.nabble.com>
 <08ad2f6d-4e18-4120-f009-613e345ee965@treenet.co.nz>
 <1588672092253-0.post@n4.nabble.com>
 <202005051206.34187.Antony.Stone@squid.open.source.it>
Message-ID: <1588674079539-0.post@n4.nabble.com>

The purpose of proxy A is that its the proxy that will be given to my
clients. The purpose of all what I am doing is to let my clients use proxy B
indirectly through proxy A (so they can use proxy B without installing the
CA certificate)


Antony Stone wrote
> On Tuesday 05 May 2020 at 11:48:12, mariolatif741 wrote:
> 
>> Since you said "If the client is participating in the TLS handshake it
>> *always* requires the CA to be installed.", then I guess what I want to
>> do
>> is not possible.
>> 
>> Can I make Squid send the requests received from the client to the cache
>> peer? (so the cache peer would see the requests coming from the Squid
>> server and not from the client), I think if this is possible then it'd
>> help in my case.
> 
> What are you trying to achieve?
> 
> It sounds as though you want the client to talk to proxy A, which talks to 
> proxy B, which sends requests to the Internet, and you want to do content 
> inspection / filtering on proxy B.
> 
> What is the purpose of proxy A?
> 
> Regards,
> 
> 
> Antony.
> 
> -- 
> "Remember: the S in IoT stands for Security."
> 
>  - Jan-Piet Mens
> 
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From Antony.Stone at squid.open.source.it  Tue May  5 10:26:58 2020
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 5 May 2020 12:26:58 +0200
Subject: [squid-users] Let Squid use SSL certificate for a parent cache
	peer
In-Reply-To: <1588674079539-0.post@n4.nabble.com>
References: <1588669455105-0.post@n4.nabble.com>
 <202005051206.34187.Antony.Stone@squid.open.source.it>
 <1588674079539-0.post@n4.nabble.com>
Message-ID: <202005051226.58191.Antony.Stone@squid.open.source.it>

On Tuesday 05 May 2020 at 12:21:19, mariolatif741 wrote:

> The purpose of proxy A is that its the proxy that will be given to my
> clients. The purpose of all what I am doing is to let my clients use proxy
> B indirectly through proxy A (so they can use proxy B without installing
> the CA certificate)

Won't work.

If you are doing HTTPS / SSL / TLS interception *at any point* in the chain 
between the client and the real server, then the machine doing the 
interception is going to have to generate a fake certificate for what it sends 
back to the client (no matter whether that passes through an intermediate 
proxy or not), therefore the client needs to have the fake CA certificate 
installed in order to trust what it receives.

There is no way for the client to get the "real" certificate from the "real" 
server if a machine in between intercepts and decrypts the communication.  If 
there were, TLS security would be meaningless.

Regards,


Antony.

-- 
"Measuring average network latency is about as useful as measuring the mean 
temperature of patients in a hospital."

 - St?phane Bortzmeyer

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Tue May  5 10:30:10 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 May 2020 22:30:10 +1200
Subject: [squid-users] Let Squid use SSL certificate for a parent cache
 peer
In-Reply-To: <1588674079539-0.post@n4.nabble.com>
References: <1588669455105-0.post@n4.nabble.com>
 <08ad2f6d-4e18-4120-f009-613e345ee965@treenet.co.nz>
 <1588672092253-0.post@n4.nabble.com>
 <202005051206.34187.Antony.Stone@squid.open.source.it>
 <1588674079539-0.post@n4.nabble.com>
Message-ID: <8a3715ff-1221-a63c-598a-28f3293b9325@treenet.co.nz>

On 5/05/20 10:21 pm, mariolatif741 wrote:
> The purpose of proxy A is that its the proxy that will be given to my
> clients. The purpose of all what I am doing is to let my clients use proxy B
> indirectly through proxy A (so they can use proxy B without installing the
> CA certificate)
> 

It sounds to me like you only need one proxy. Squid can listen on
multiple ports and treat traffic differently per-port.

If you do not want to (or cannot) install a custom CA on clients that is
fine. It just prevents you from using the SSL-Bump 'bump' action on the
TLS traffic from those clients. More than one proxy will not help with
that restriction.


Amos


From robertkwild at gmail.com  Tue May  5 11:38:34 2020
From: robertkwild at gmail.com (robert k Wild)
Date: Tue, 5 May 2020 12:38:34 +0100
Subject: [squid-users] allowing zip only for a specific url regex
Message-ID: <CAGU_CiL58Z9gpA--wQFQ9dz5icJ1rEsBLZ42+MYhAitdvAq53A@mail.gmail.com>

hi all,

i wanto to allow only zip files via a specific url regex

atm im allowing all attachments

^https://attachments.office.net/owa/.*

could i do this to lock it down to only zips

^https://attachments.office.net/owa/.zip

thanks,
rob

-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200505/5c3bb264/attachment.htm>

From squid3 at treenet.co.nz  Tue May  5 12:26:31 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 May 2020 00:26:31 +1200
Subject: [squid-users] allowing zip only for a specific url regex
In-Reply-To: <CAGU_CiL58Z9gpA--wQFQ9dz5icJ1rEsBLZ42+MYhAitdvAq53A@mail.gmail.com>
References: <CAGU_CiL58Z9gpA--wQFQ9dz5icJ1rEsBLZ42+MYhAitdvAq53A@mail.gmail.com>
Message-ID: <193e1b04-4c70-1c6c-be53-f1cac4bd3dbc@treenet.co.nz>

On 5/05/20 11:38 pm, robert k Wild wrote:
> hi all,
> 
> i wanto to allow only zip files via a specific url regex
> 
> atm im allowing all attachments
> 
> ^https://attachments.office.net/owa/.*
> 
> could i do this to lock it down to only zips
> 
> ^https://attachments.office.net/owa/.zip
> 

That regex will only match a small set of URLs which are unlikely ever
to exist.

What you want is:

 acl downloads url_regex https://attachments.office.net/owa/
 acl dotZip urlpath_regex \.zip(\?)?.*$
 http_access allow downloads !dotZip

 acl zipCt rep_header Content-Type application/zip
 http_reply_access deny zipCt


Amos


From robertkwild at gmail.com  Tue May  5 12:42:33 2020
From: robertkwild at gmail.com (robert k Wild)
Date: Tue, 5 May 2020 13:42:33 +0100
Subject: [squid-users] allowing zip only for a specific url regex
In-Reply-To: <193e1b04-4c70-1c6c-be53-f1cac4bd3dbc@treenet.co.nz>
References: <CAGU_CiL58Z9gpA--wQFQ9dz5icJ1rEsBLZ42+MYhAitdvAq53A@mail.gmail.com>
 <193e1b04-4c70-1c6c-be53-f1cac4bd3dbc@treenet.co.nz>
Message-ID: <CAGU_CiKEeEPZnHDdu0O0p=XsV2J-1fS9N9dGMxRPY_FMEnqDGw@mail.gmail.com>

cool thanks Amos :)

if your interested these are my lines in my config

#allow special URL paths
acl special_url url_regex "/usr/local/squid/etc/urlspecial.txt"

#deny MIME types
acl mimetype rep_mime_type "/usr/local/squid/etc/mimedeny.txt"
http_reply_access allow special_url
http_reply_access deny mimetype

urlspecial.txt

http://updater.maxon.net/server_test
http://updater.maxon.net/customer/R21.0/updates15
http://updater.maxon.net/customer/general/updates15
^http://ccmdl.adobe.com/AdobeProducts/KCCC/1/win64/packages/.*
^http://ccmdl.adobe.com/AdobeProducts/KCCC/1/osx10/packages/.*
^http://www.eztitles.com/download.php?
^https://attachments.office.net/owa/.*

mimedeny.txt

application/octet-stream
application/x-msi
application/zip
application/vnd.ms-cab-compressed

is this the best way of doing it?

thanks,
rob


On Tue, 5 May 2020 at 13:27, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 5/05/20 11:38 pm, robert k Wild wrote:
> > hi all,
> >
> > i wanto to allow only zip files via a specific url regex
> >
> > atm im allowing all attachments
> >
> > ^https://attachments.office.net/owa/.*
> >
> > could i do this to lock it down to only zips
> >
> > ^https://attachments.office.net/owa/.zip
> >
>
> That regex will only match a small set of URLs which are unlikely ever
> to exist.
>
> What you want is:
>
>  acl downloads url_regex https://attachments.office.net/owa/
>  acl dotZip urlpath_regex \.zip(\?)?.*$
>  http_access allow downloads !dotZip
>
>  acl zipCt rep_header Content-Type application/zip
>  http_reply_access deny zipCt
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200505/5bfa30f5/attachment.htm>

From email_arjun at yahoo.com  Tue May  5 12:58:57 2020
From: email_arjun at yahoo.com (Arjun K)
Date: Tue, 5 May 2020 12:58:57 +0000 (UTC)
Subject: [squid-users] Squid Proxy not blocking websites
In-Reply-To: <2093095721.337076.1588506662085@mail.yahoo.com>
References: <2093095721.337076.1588506662085.ref@mail.yahoo.com>
 <2093095721.337076.1588506662085@mail.yahoo.com>
Message-ID: <951697970.1126998.1588683537565@mail.yahoo.com>

 Hi All
Can any one help on the below issue.
I tried changing the order of deny and allow acl but it did not yield any result.
RegardsArjun K

    On Sunday, 3 May, 2020, 05:21:02 pm IST, Arjun K <email_arjun at yahoo.com> wrote:  
 
 Hi All
The below is the configuration defined in the proxy server.The issue is that the proxy is not blocking the websites mentioned in a file named denylist.txt.
Kindly let me know what needs to be changed to block the websites.


####IP Ranges allowed to use proxyacl localnet src 10.196.0.0/16
acl localnet src 10.197.0.0/16acl localnet src 10.198.0.0/16acl localnet src 10.199.0.0/16acl localnet src 10.200.0.0/16
####Allowed and Denied URLsacl allowedurl dstdomain /etc/squid/allowed_url.txtacl denylist dstdomain /etc/squid/denylist.txt
acl windowsupdate dstdomain windowsupdate.microsoft.comacl windowsupdate dstdomain .update.microsoft.comacl windowsupdate dstdomain download.windowsupdate.comacl windowsupdate dstdomain redir.metaservices.microsoft.comacl windowsupdate dstdomain images.metaservices.microsoft.comacl windowsupdate dstdomain c.microsoft.comacl windowsupdate dstdomain www.download.windowsupdate.comacl windowsupdate dstdomain wustat.windows.comacl windowsupdate dstdomain crl.microsoft.comacl windowsupdate dstdomain sls.microsoft.comacl windowsupdate dstdomain productactivation.one.microsoft.comacl windowsupdate dstdomain ntservicepack.microsoft.comacl windowsupdate dstdomain eu.vortex-win.data.microsoft.comacl windowsupdate dstdomain eu-v20.events.data.microsoft.comacl windowsupdate dstdomain usseu1northprod.blob.core.windows.netacl windowsupdate dstdomain usseu1westprod.blob.core.windows.netacl windowsupdate dstdomain winatp-gw-neu.microsoft.comacl windowsupdate dstdomain winatp-gw-weu.microsoft.comacl windowsupdate dstdomain wseu1northprod.blob.core.windows.netacl windowsupdate dstdomain wseu1westprod.blob.core.windows.netacl windowsupdate dstdomain automatedirstrprdweu.blob.core.windows.netacl windowsupdate dstdomain automatedirstrprdneu.blob.core.windows.netacl windowsupdate dstdomain play.google.comacl windowsupdate dstdomain go.microsoft.com
acl CONNECT method CONNECTacl wuCONNECT dstdomain www.update.microsoft.comacl wuCONNECT dstdomain sls.microsoft.comhttp_access allow CONNECT wuCONNECT localnethttp_access allow windowsupdate localnet
acl Safe_ports port 80 # httpacl Safe_ports port 443 # httpsacl CONNECT method CONNECT
http_access allow allowedurlhttp_access deny denylisthttp_access allow localhost managerhttp_access allow localhosthttp_access allow localnethttp_access deny managerhttp_access deny !Safe_portshttp_access deny all
http_port 8080
cache_dir ufs /var/spool/squid 10000 16 256coredump_dir /var/spool/squid
refresh_pattern ^ftp:? ? ? ? ? ?1440? ? 20%? ? ?10080refresh_pattern ^gopher:? ? ? ? 1440? ? 0%? ? ? 1440refresh_pattern -i (/cgi-bin/|\?) 0? ? ?0%? ? ? 0refresh_pattern .? ? ? ? ? ? ? ?0? ? ? ?20%? ? ?4320refresh_pattern -i windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-imsrefresh_pattern -i microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-imsrefresh_pattern -i windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims



RegardsArjun K.  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200505/b3883e91/attachment.htm>

From rousskov at measurement-factory.com  Tue May  5 13:02:34 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 5 May 2020 09:02:34 -0400
Subject: [squid-users] Best way to prevent squid from bumping CONNECTs
In-Reply-To: <6be17362-5021-b268-6129-0d2e075d3b9d@treenet.co.nz>
References: <mailman.520.1588063344.3558.squid-users@lists.squid-cache.org>
 <20200430161030.GA87833@thismonkey.com>
 <9d5db430-5186-1080-fb3e-abe409aed50a@measurement-factory.com>
 <20200504024107.GA16341@thismonkey.com>
 <6f609033-54d4-db72-0e69-66c54fc085af@measurement-factory.com>
 <6be17362-5021-b268-6129-0d2e075d3b9d@treenet.co.nz>
Message-ID: <4768ba15-a9c4-f57d-8719-18fd5a313735@measurement-factory.com>

On 5/5/20 5:38 AM, Amos Jeffries wrote:
> On 5/05/20 4:31 am, Alex Rousskov wrote:
>> On 5/3/20 10:41 PM, Scott wrote:
>>> https://wiki.squid-cache.org/Features/SslPeekAndSplice says "At no point 
>>> during ssl_bump processing will dstdomain ACL work".

>> I have not tested this, but I would expect the dstdomain ACL to work
>> during SslBump steps using the destination address from the (real or
>> fake) CONNECT request URI.

> We do not save the CONNECT tunnel message objects in the TLS handshake
> state objects. As such the state needed by dstdomain is not available
> during ssl_bump ACL processing.

I do not know what you mean by "CONNECT tunnel message objects" and "TLS
handshake state objects" exactly but HttpRequest with the (real or fake)
CONNECT request should exist and be available to ssl_bump and
http_access ACLs during SslBump steps. The dstdomain ACL uses
HttpRequest AFAICT.

Most deployed http_access configurations allow those CONNECT requests
while peeking at TLS; and many broken configurations deny them (too
soon), triggering support queries on this mailing list.


> Only state from the TCP connection and the underway TLS handshake are
> guaranteed to be available to the ssl_bump ACLs. Anything else is
> best-effort.

For intercepted connections, the fake CONNECT request carries
information extracted from the TCP connection and the TLS handshake.

For other cases, there is a real CONNECT request to carry that
information (and more). It is adjusted with SNI info if possible.

At least that is the way SslBump should work in modern Squids. I agree
that many SslBump bugs have been fixed since the quoted wiki paragraph
was written, but the presence of the CONNECT HttpRequest is rather
fundamental since the beginning of Peek and Splice approach because
http_access rules are difficult to write without it, especially because
we did not want to make "step" ACLs officially available for the
http_access rules.


HTH,

Alex.


From squid3 at treenet.co.nz  Tue May  5 13:02:55 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 May 2020 01:02:55 +1200
Subject: [squid-users] allowing zip only for a specific url regex
In-Reply-To: <CAGU_CiKEeEPZnHDdu0O0p=XsV2J-1fS9N9dGMxRPY_FMEnqDGw@mail.gmail.com>
References: <CAGU_CiL58Z9gpA--wQFQ9dz5icJ1rEsBLZ42+MYhAitdvAq53A@mail.gmail.com>
 <193e1b04-4c70-1c6c-be53-f1cac4bd3dbc@treenet.co.nz>
 <CAGU_CiKEeEPZnHDdu0O0p=XsV2J-1fS9N9dGMxRPY_FMEnqDGw@mail.gmail.com>
Message-ID: <ee48d1fc-280c-9700-b8ea-15f135c5ca0e@treenet.co.nz>

On 6/05/20 12:42 am, robert k Wild wrote:
> cool thanks Amos :)
> 
> if your interested these are my lines in my config
> 
> #allow special URL paths
> acl special_url url_regex "/usr/local/squid/etc/urlspecial.txt"
> 
> #deny MIME types
> acl mimetype rep_mime_type "/usr/local/squid/etc/mimedeny.txt"
> http_reply_access allow special_url

The above is wrong. It is allowing by URL, regardless of the mime type.

> http_reply_access deny mimetype
> 

That is the opposite of your stated requirement. It will *prevent* the
mime type check from identifying downloads in the special_url.

A better way to write the above policy would be:

  http_reply_access deny !special_url mimetype


Also, be aware that http_reply_access denial only prevents the download
reaching the client. It still has to be fully downloaded by Squid - lots
of bandwidth and processing cycles wasted.
 If you are blocking traffic by URL do that in http_access instead.


> urlspecial.txt
> 
> http://updater.maxon.net/server_test
> http://updater.maxon.net/customer/R21.0/updates15
> http://updater.maxon.net/customer/general/updates15
> ^http://ccmdl.adobe.com/AdobeProducts/KCCC/1/win64/packages/.*
> ^http://ccmdl.adobe.com/AdobeProducts/KCCC/1/osx10/packages/.*
> ^http://www.eztitles.com/download.php?
> ^https://attachments.office.net/owa/.*
> 

Do not put .* on the end of regex patterns. That only forces the regex
library to scan longer than necessary and waste memory.

Also this pattern:

 ^http://www.eztitles.com/download.php?

actually means:

 ^http://www.eztitles.com/download.ph

('?' is a regex special character. Like '*' it is deceptively harmful at
the start or end of a pattern)


Amos


From squid3 at treenet.co.nz  Tue May  5 13:31:32 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 May 2020 01:31:32 +1200
Subject: [squid-users] Squid Proxy not blocking websites
In-Reply-To: <951697970.1126998.1588683537565@mail.yahoo.com>
References: <2093095721.337076.1588506662085.ref@mail.yahoo.com>
 <2093095721.337076.1588506662085@mail.yahoo.com>
 <951697970.1126998.1588683537565@mail.yahoo.com>
Message-ID: <f92498d8-5156-0294-0ff7-cd222bfd6497@treenet.co.nz>

On 6/05/20 12:58 am, Arjun K wrote:
> Hi All
> 
> Can any one help on the below issue.
> I tried changing the order of deny and allow acl but it did not yield
> any result.
> 

What is the contents of the denylist.txt file?

This usually happens when things in there are not the right dstdomain
syntax.





> Regards
> Arjun K
> 
> 
> On Sunday, 3 May, 2020, 05:21:02 pm IST, Arjun K <email_arjun at yahoo.com>
> wrote:
> 
> 
> Hi All
> 
> The below is the configuration defined in the proxy server.
> The issue is that the proxy is not blocking the websites mentioned in a
> file named denylist.txt.
> Kindly let me know what needs to be changed to block the websites.
> 
> 
> 
> ####IP Ranges allowed to use proxy
> acl localnet src 10.196.0.0/16
> acl localnet src 10.197.0.0/16
> acl localnet src 10.198.0.0/16
> acl localnet src 10.199.0.0/16
> acl localnet src 10.200.0.0/16

These can be simplified:

 acl localnet 10.196.0.0-10.200.0.0/16


> 
> ####Allowed and Denied URLs
> acl allowedurl dstdomain /etc/squid/allowed_url.txt

dstdomain and URL are different things. The name of this ACL is deceptive.

> acl denylist dstdomain /etc/squid/denylist.txt
> 
...

You are missing the DoS protection checks:

 http_access deny !Safe_ports
 http_access deny CONNECT !SSL_ports

All custom rules should follow those.


> http_access allow CONNECT wuCONNECT localnet
> http_access allow windowsupdate localnet
> 
> acl Safe_ports port 80 # http
> acl Safe_ports port 443 # https
> acl CONNECT method CONNECT
> 
> http_access allow allowedurl
> http_access deny denylist
> http_access allow localhost manager
> http_access allow localhost
> http_access allow localnet
> http_access deny manager
> http_access deny !Safe_ports

The manager and Safe_Ports checks are useless down here. Their entire
purpose is to prevent unauthorized access to dangerous protocols and
security sensitive proxy management API.


> http_access deny all
> 
...
> 
> refresh_pattern ^ftp:? ? ? ? ? ?1440? ? 20%? ? ?10080
> refresh_pattern ^gopher:? ? ? ? 1440? ? 0%? ? ? 1440
> refresh_pattern -i (/cgi-bin/|\?) 0? ? ?0%? ? ? 0
> refresh_pattern .? ? ? ? ? ? ? ?0? ? ? ?20%? ? ?4320

No refresh_pattern following this line will ever match. The "." pattern
matches every URL possible. Order is important.

> refresh_pattern -i
> windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320
> 80% 43200 reload-into-ims
> refresh_pattern -i
> microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims
> refresh_pattern -i
> windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims
> 


Amos


From robertkwild at gmail.com  Tue May  5 13:39:41 2020
From: robertkwild at gmail.com (robert k Wild)
Date: Tue, 5 May 2020 14:39:41 +0100
Subject: [squid-users] allowing zip only for a specific url regex
In-Reply-To: <ee48d1fc-280c-9700-b8ea-15f135c5ca0e@treenet.co.nz>
References: <CAGU_CiL58Z9gpA--wQFQ9dz5icJ1rEsBLZ42+MYhAitdvAq53A@mail.gmail.com>
 <193e1b04-4c70-1c6c-be53-f1cac4bd3dbc@treenet.co.nz>
 <CAGU_CiKEeEPZnHDdu0O0p=XsV2J-1fS9N9dGMxRPY_FMEnqDGw@mail.gmail.com>
 <ee48d1fc-280c-9700-b8ea-15f135c5ca0e@treenet.co.nz>
Message-ID: <CAGU_Ci+Tnu5+hm1Qf2PstNHt22w43VLYR9EE83rBzAHcm3u__w@mail.gmail.com>

Thanks Amos,

so how would I allow these urls with a wild card then

Http://domain.com/path/1/to/any/where

Http://domain.com/path/2/to/any/where

Would I do this

Http://domain.com/path/*

Thanks,
Rob

On Tue, 5 May 2020, 14:04 Amos Jeffries, <squid3 at treenet.co.nz> wrote:

> On 6/05/20 12:42 am, robert k Wild wrote:
> > cool thanks Amos :)
> >
> > if your interested these are my lines in my config
> >
> > #allow special URL paths
> > acl special_url url_regex "/usr/local/squid/etc/urlspecial.txt"
> >
> > #deny MIME types
> > acl mimetype rep_mime_type "/usr/local/squid/etc/mimedeny.txt"
> > http_reply_access allow special_url
>
> The above is wrong. It is allowing by URL, regardless of the mime type.
>
> > http_reply_access deny mimetype
> >
>
> That is the opposite of your stated requirement. It will *prevent* the
> mime type check from identifying downloads in the special_url.
>
> A better way to write the above policy would be:
>
>   http_reply_access deny !special_url mimetype
>
>
> Also, be aware that http_reply_access denial only prevents the download
> reaching the client. It still has to be fully downloaded by Squid - lots
> of bandwidth and processing cycles wasted.
>  If you are blocking traffic by URL do that in http_access instead.
>
>
> > urlspecial.txt
> >
> > http://updater.maxon.net/server_test
> > http://updater.maxon.net/customer/R21.0/updates15
> > http://updater.maxon.net/customer/general/updates15
> > ^http://ccmdl.adobe.com/AdobeProducts/KCCC/1/win64/packages/.*
> > ^http://ccmdl.adobe.com/AdobeProducts/KCCC/1/osx10/packages/.*
> > ^http://www.eztitles.com/download.php?
> > ^https://attachments.office.net/owa/.*
> >
>
> Do not put .* on the end of regex patterns. That only forces the regex
> library to scan longer than necessary and waste memory.
>
> Also this pattern:
>
>  ^http://www.eztitles.com/download.php?
>
> actually means:
>
>  ^http://www.eztitles.com/download.ph
>
> ('?' is a regex special character. Like '*' it is deceptively harmful at
> the start or end of a pattern)
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200505/073bf800/attachment.htm>

From squid3 at treenet.co.nz  Tue May  5 13:54:38 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 May 2020 01:54:38 +1200
Subject: [squid-users] allowing zip only for a specific url regex
In-Reply-To: <CAGU_Ci+Tnu5+hm1Qf2PstNHt22w43VLYR9EE83rBzAHcm3u__w@mail.gmail.com>
References: <CAGU_CiL58Z9gpA--wQFQ9dz5icJ1rEsBLZ42+MYhAitdvAq53A@mail.gmail.com>
 <193e1b04-4c70-1c6c-be53-f1cac4bd3dbc@treenet.co.nz>
 <CAGU_CiKEeEPZnHDdu0O0p=XsV2J-1fS9N9dGMxRPY_FMEnqDGw@mail.gmail.com>
 <ee48d1fc-280c-9700-b8ea-15f135c5ca0e@treenet.co.nz>
 <CAGU_Ci+Tnu5+hm1Qf2PstNHt22w43VLYR9EE83rBzAHcm3u__w@mail.gmail.com>
Message-ID: <15d910b5-270c-83b8-3fa2-349cf2b1e9b8@treenet.co.nz>

On 6/05/20 1:39 am, robert k Wild wrote:
> Thanks Amos,
> 
> so how would I allow these urls with a wild card then?
> 
> Http://domain.com/path/1/to/any/where
> 
> Http://domain.com/path/2/to/any/where
> 
> Would I do this
> 
> Http://domain.com/path/*
> 

No. As the url_regex ACL name says, these are regex patterns.

You have to use special anchors (^ and $) to *prevent* them being
wildcard matches.

Simply do like this:

  ^http://domain\.com/path/



Cheers
Amos


From ryanlele264 at gmail.com  Tue May  5 14:18:57 2020
From: ryanlele264 at gmail.com (Ryan Le)
Date: Tue, 5 May 2020 10:18:57 -0400
Subject: [squid-users] Encrypt CONNECT Header
Message-ID: <CANqqF0pgVy496QoEJAbCbPKLyz4XaSy_Y_CKAsUTw0-mZoaiWg@mail.gmail.com>

Is there plans to support explicit forward proxy over HTTPS to the proxy
with
ssl-bump? We would like to use https_port ssl-bump without using the
intercept or tproxy option. Clients will use PAC with a HTTPS directive
rather than a PROXY directive. The goal is to also encrypted the CONNECT
header which exposes the domain in plain text while it traverses to the
proxy.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200505/7e8f3dc5/attachment.htm>

From Cyoho at umpublishing.org  Tue May  5 14:22:43 2020
From: Cyoho at umpublishing.org (Cindy Yoho)
Date: Tue, 5 May 2020 14:22:43 +0000
Subject: [squid-users] [External] Re:  Passing XML through squid proxy
In-Reply-To: <8c6d575c-6388-0522-386a-0bfcbe4d9014@measurement-factory.com>
References: <BN8PR08MB6420802EE795041C9002FD39DDAB0@BN8PR08MB6420.namprd08.prod.outlook.com>
 <8c6d575c-6388-0522-386a-0bfcbe4d9014@measurement-factory.com>
Message-ID: <BN8PR08MB64204E2EB9D9948679DF2559DDA70@BN8PR08MB6420.namprd08.prod.outlook.com>

Alex, thank you for the quick reply.      
They are not actually passing a url to the squid server.   The nginx config allowed me to have a line as such:

proxy_pass https://calcconnect.vertexsmb.com/vertex-ws/services/CalculateTax

The xml just got passed straight through to the url in the config file.    Is there something comparable in squid I can set to tell it where to pass the code?   I am working on getting the wireshark packets but the  server is in a secure zone so there aren't any easy options for getting a file from it. 

Thanks~
Cindy

-----Original Message-----
From: Alex Rousskov <rousskov at measurement-factory.com> 
Sent: Friday, May 1, 2020 11:26 AM
To: Cindy Yoho <Cyoho at umpublishing.org>; squid-users at lists.squid-cache.org
Subject: [External] Re: [squid-users] Passing XML through squid proxy

On 5/1/20 10:56 AM, Cindy Yoho wrote:

> When the Order Entry server sends the XML code, we get an error 
> returned to the server making the request

Perhaps your Order Entry server does not use HTTP when talking to Squid?

Squid does not really care about the request payload, but the request has to use the HTTP transport protocol. So sending a SOAP/XML request payload over HTTP is OK, but sending raw SOAP (or SOAP over something other than HTTP) is not.

If you can post a packet capture of the Order Entry server talking to Squid (not the text interpretation of Squid response but the actual packets going from the Order Entry server to Squid; use libpcap format which is often the default for Wireshark export), then we should be able to confirm whether your Order Entry server is using the right protocol to talk to/through Squid.

The same packet capture can point to HTTP request problems if the Order Entry server is using HTTP but sending some HTTP token that Squid does not like (or not sending an HTTP token that Squid needs).


HTH,

Alex.


From felipeapolanco at gmail.com  Tue May  5 14:24:35 2020
From: felipeapolanco at gmail.com (Felipe Polanco)
Date: Tue, 5 May 2020 10:24:35 -0400
Subject: [squid-users] Encrypt CONNECT Header
In-Reply-To: <CANqqF0pgVy496QoEJAbCbPKLyz4XaSy_Y_CKAsUTw0-mZoaiWg@mail.gmail.com>
References: <CANqqF0pgVy496QoEJAbCbPKLyz4XaSy_Y_CKAsUTw0-mZoaiWg@mail.gmail.com>
Message-ID: <CADcj3=5aXHu0OXMSK9--_c9KQP4NPewUWHtTdBcyBYZFsxpcQg@mail.gmail.com>

I may be mistaken but I believe you don't need to use ssl-bump with
explicit https proxy.

In your browser settings, use an HTTPS proxy instead of HTTP.

On Tue, May 5, 2020 at 10:19 AM Ryan Le <ryanlele264 at gmail.com> wrote:

> Is there plans to support explicit forward proxy over HTTPS to the proxy
> with
> ssl-bump? We would like to use https_port ssl-bump without using the
> intercept or tproxy option. Clients will use PAC with a HTTPS directive
> rather than a PROXY directive. The goal is to also encrypted the CONNECT
> header which exposes the domain in plain text while it traverses to the
> proxy.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200505/b73d5317/attachment.htm>

From robertkwild at gmail.com  Tue May  5 14:27:04 2020
From: robertkwild at gmail.com (robert k Wild)
Date: Tue, 5 May 2020 15:27:04 +0100
Subject: [squid-users] allowing zip only for a specific url regex
In-Reply-To: <15d910b5-270c-83b8-3fa2-349cf2b1e9b8@treenet.co.nz>
References: <CAGU_CiL58Z9gpA--wQFQ9dz5icJ1rEsBLZ42+MYhAitdvAq53A@mail.gmail.com>
 <193e1b04-4c70-1c6c-be53-f1cac4bd3dbc@treenet.co.nz>
 <CAGU_CiKEeEPZnHDdu0O0p=XsV2J-1fS9N9dGMxRPY_FMEnqDGw@mail.gmail.com>
 <ee48d1fc-280c-9700-b8ea-15f135c5ca0e@treenet.co.nz>
 <CAGU_Ci+Tnu5+hm1Qf2PstNHt22w43VLYR9EE83rBzAHcm3u__w@mail.gmail.com>
 <15d910b5-270c-83b8-3fa2-349cf2b1e9b8@treenet.co.nz>
Message-ID: <CAGU_CiJKTg=Cem+eANeX3HeWm3pyQZrfsovmn3pEKqh7B=KJsQ@mail.gmail.com>

Thanks a lot Amos, as always you have been very helpful

Much appreciated mate

Rob

On Tue, 5 May 2020, 14:55 Amos Jeffries, <squid3 at treenet.co.nz> wrote:

> On 6/05/20 1:39 am, robert k Wild wrote:
> > Thanks Amos,
> >
> > so how would I allow these urls with a wild card then
> >
> > Http://domain.com/path/1/to/any/where
> >
> > Http://domain.com/path/2/to/any/where
> >
> > Would I do this
> >
> > Http://domain.com/path/*
> >
>
> No. As the url_regex ACL name says, these are regex patterns.
>
> You have to use special anchors (^ and $) to *prevent* them being
> wildcard matches.
>
> Simply do like this:
>
>   ^http://domain\.com/path/
>
>
>
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200505/3aa0b170/attachment.htm>

From Christian.Molecki at stala.bwl.de  Tue May  5 14:29:50 2020
From: Christian.Molecki at stala.bwl.de (Molecki, Christian (STL))
Date: Tue, 5 May 2020 14:29:50 +0000
Subject: [squid-users] Squid negotation auth for Java webstart not working
Message-ID: <cf2a9f6f5c5d445bb286b06b4be4db62@stala.bwl.de>

Hello,
 
we are using Squid 3.5.21 and trying to implement the negotation authentification, based on kerberos and ntlm.
Browsing in the internet works fine, even with acls based on active directory groups.
 
 
Unfortunately we can't call java web start applications:
java.io.IOException: Unable to tunnel through proxy. Proxy returns "HTTP/1.1 407 Proxy Authentication Required"

We are using Java 1.8.0_221 on the clients.
 
Squid.conf
auth_param negotiate program /usr/sbin/negotiate_wrapper_auth -d --ntlm /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp --domain=STL --kerberos /usr/sbin/negotiate_kerberos_auth -d -s GSS_C_NO_NAME
auth_param negotiate children 10
auth_param negotiate keep_alive off
 
acl grp-www external nt_group GRP_WWW
acl www-auth proxy_auth REQUIRED
 
http_access allow p-http  grp-www www-auth
http_access allow p-https grp-www www-auth
 
Without grp-www and www-auth the calls work fine, but there is also no authentification.
 
cache.log (last entry of kerberos debug)
negotiate_kerberos_auth.cc(801): pid=2876 :2020/05/05 16:12:02| negotiate_kerberos_auth: DEBUG: AF oYG3MIG0oAMKAQChCwYJKoZIgvcSAQICooGfBIGcYIGZBgkqhkiG9xIBAgICAG+BiTCBhqADAgEFoQMCAQ+iejB4oAMCARKicQRv5cOyDbJ0+OYmI5iv0/mdKKd3Ez6ewG43c2U2rzYvooNfdMUT4ap5vufPMNSw3fGLJvPKgupMawOvcduXlBkCHqa5pqkmczvXGAdJvC2yRSJagDSrpuvjC9/XXaZCJl906Pluwo2ovPaYcKCXDy9c <myuser>
 
 The wiki says: AF - Success. Valid credentials. Deprecated by OK result from Squid-3.4 onwards.
 
Does anyone have a clue or a similar behavior?
 
 
 
Best Regards
Christian Molecki



From uhlar at fantomas.sk  Tue May  5 15:08:59 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 5 May 2020 17:08:59 +0200
Subject: [squid-users] Encrypt CONNECT Header
In-Reply-To: <CADcj3=5aXHu0OXMSK9--_c9KQP4NPewUWHtTdBcyBYZFsxpcQg@mail.gmail.com>
References: <CANqqF0pgVy496QoEJAbCbPKLyz4XaSy_Y_CKAsUTw0-mZoaiWg@mail.gmail.com>
 <CADcj3=5aXHu0OXMSK9--_c9KQP4NPewUWHtTdBcyBYZFsxpcQg@mail.gmail.com>
Message-ID: <20200505150859.GA23678@fantomas.sk>

On 05.05.20 10:24, Felipe Polanco wrote:
>I may be mistaken but I believe you don't need to use ssl-bump with
>explicit https proxy.
>
>In your browser settings, use an HTTPS proxy instead of HTTP.

and squid needs https_port to accept https traffic.

>On Tue, May 5, 2020 at 10:19 AM Ryan Le <ryanlele264 at gmail.com> wrote:
>> Is there plans to support explicit forward proxy over HTTPS to the proxy
>> with
>> ssl-bump? We would like to use https_port ssl-bump without using the
>> intercept or tproxy option. Clients will use PAC with a HTTPS directive
>> rather than a PROXY directive. The goal is to also encrypted the CONNECT
>> header which exposes the domain in plain text while it traverses to the
>> proxy.

people will still be able to see SNI SSL header.

however, ssl-bump is different feature.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
WinError #99999: Out of error messages.


From rousskov at measurement-factory.com  Tue May  5 15:19:15 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 5 May 2020 11:19:15 -0400
Subject: [squid-users] Passing XML through squid proxy
In-Reply-To: <BN8PR08MB64204E2EB9D9948679DF2559DDA70@BN8PR08MB6420.namprd08.prod.outlook.com>
References: <BN8PR08MB6420802EE795041C9002FD39DDAB0@BN8PR08MB6420.namprd08.prod.outlook.com>
 <8c6d575c-6388-0522-386a-0bfcbe4d9014@measurement-factory.com>
 <BN8PR08MB64204E2EB9D9948679DF2559DDA70@BN8PR08MB6420.namprd08.prod.outlook.com>
Message-ID: <95970dbd-32e8-28c9-29a5-1d6596317bbf@measurement-factory.com>

On 5/5/20 10:22 AM, Cindy Yoho wrote:

> They are not actually passing a url to the squid server. The nginx config allowed me to have a line as such:
> 
> proxy_pass https://calcconnect.vertexsmb.com/vertex-ws/services/CalculateTax

> The xml just got passed straight through to the url in the config
> file.    Is there something comparable in squid I can set to tell it
> where to pass the code?   I am working on getting the wireshark
> packets but the  server is in a secure zone so there aren't any easy
> options for getting a file from it.

I am not intimate with nginx, but its proxy_pass configuration sounds
similar to Squid's cache_peer directive:
http://www.squid-cache.org/Doc/config/cache_peer/

Beyond that, without packet traces (or Squid cache.logs with
debug_options set to "ALL,2" or higher), it would be difficult for me to
say anything specific.


Good luck,

Alex.



> -----Original Message-----
> From: Alex Rousskov <rousskov at measurement-factory.com> 
> Sent: Friday, May 1, 2020 11:26 AM
> To: Cindy Yoho <Cyoho at umpublishing.org>; squid-users at lists.squid-cache.org
> Subject: [External] Re: [squid-users] Passing XML through squid proxy
> 
> On 5/1/20 10:56 AM, Cindy Yoho wrote:
> 
>> When the Order Entry server sends the XML code, we get an error 
>> returned to the server making the request
> 
> Perhaps your Order Entry server does not use HTTP when talking to Squid?
> 
> Squid does not really care about the request payload, but the request has to use the HTTP transport protocol. So sending a SOAP/XML request payload over HTTP is OK, but sending raw SOAP (or SOAP over something other than HTTP) is not.
> 
> If you can post a packet capture of the Order Entry server talking to Squid (not the text interpretation of Squid response but the actual packets going from the Order Entry server to Squid; use libpcap format which is often the default for Wireshark export), then we should be able to confirm whether your Order Entry server is using the right protocol to talk to/through Squid.
> 
> The same packet capture can point to HTTP request problems if the Order Entry server is using HTTP but sending some HTTP token that Squid does not like (or not sending an HTTP token that Squid needs).
> 
> 
> HTH,
> 
> Alex.
> 



From rousskov at measurement-factory.com  Tue May  5 15:33:25 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 5 May 2020 11:33:25 -0400
Subject: [squid-users] Encrypt CONNECT Header
In-Reply-To: <CANqqF0pgVy496QoEJAbCbPKLyz4XaSy_Y_CKAsUTw0-mZoaiWg@mail.gmail.com>
References: <CANqqF0pgVy496QoEJAbCbPKLyz4XaSy_Y_CKAsUTw0-mZoaiWg@mail.gmail.com>
Message-ID: <e3dbcfb1-4e93-466e-e8d9-dc3b74d5093f@measurement-factory.com>

On 5/5/20 10:18 AM, Ryan Le wrote:
> Is there plans to support explicit forward proxy over HTTPS to the proxy
> with ssl-bump?

There have been a few requests for TLS-inside-TLS support, but I am not
aware of any actual sponsors or features on the road map. It is a
complicated project, even though each of its two components already
works today.


> We would like to use https_port ssl-bump without using the
> intercept or tproxy option. Clients will use PAC with a HTTPS directive
> rather than a PROXY directive. The goal is to also encrypted the CONNECT
> header which exposes the domain in plain text while it traverses to the
> proxy.

Yes, it is a valid use case (that few people understand).


> Felipe: you don't need to use ssl-bump with explicit https proxy.

Popular browsers barely support HTTPS proxies and refuse to delegate TLS
handling to them. Thus, a connection to a secure origin server will be
encrypted by the browser and sent over an encrypted channel through the
HTTPS proxy -- TLS-inside-TLS. If you want to look inside that browser
connection, you have to remove both TLS layers. To remove the outer
layer, you need an https_port in a forward proxy configuration. To
remove the inner layer, you need SslBump. The combination is not yet
supported.


> Matus: people will still be able to see SNI SSL header.

... but not the origin server SNI. Only the proxy SNI is exposed in this
use case, and that exposure is usually not a problem.


Cheers,

Alex.


From email_arjun at yahoo.com  Tue May  5 16:47:35 2020
From: email_arjun at yahoo.com (Arjun K)
Date: Tue, 5 May 2020 16:47:35 +0000 (UTC)
Subject: [squid-users] Squid Proxy not blocking websites
In-Reply-To: <f92498d8-5156-0294-0ff7-cd222bfd6497@treenet.co.nz>
References: <2093095721.337076.1588506662085.ref@mail.yahoo.com>
 <2093095721.337076.1588506662085@mail.yahoo.com>
 <951697970.1126998.1588683537565@mail.yahoo.com>
 <f92498d8-5156-0294-0ff7-cd222bfd6497@treenet.co.nz>
Message-ID: <1284055797.1180517.1588697255715@mail.yahoo.com>

 Hi Amos
Thanks for your response and suggestions and I will incorporate your inputs in the configuration.Please find the below contents of denylist as I am unable to attach as a document due to restrictions.
 .hotmail.com*.appex-rf.msn.com*.itunes.apple.comauth.gfx.msbroadcast.skype.comc.bing.comc.live.comcl2.apple.comclient.hip.live.comd.docs.live.netdirectory.services.live.comdocs.live.neten-us.appex-rf.msn.comfoodanddrink.services.appex.bing.comlogin.live.commail.google.comms.tific.comodcsm.officeapps.live.comofficeimg.vo.msecnd.netoutlook.uservoice.comp100-sandbox.itunes.apple.compartnerservices.getmicrosoftkey.comprotection.office.comroaming.officeapps.live.comsas.office.microsoft.comsdk.hockeyapp.netsecure.meetup.comsignup.live.comsocial.yahooapis.comview.atdmt.comwatson.telemetry.microsoft.comweather.tile.appex.bing.comwww.dropbox.comwww.googleapis.comwww.wunderlist.com*.appex.bing.com*.broadcast.skype.com*.mail.protection.outlook.com*.protection.office.com*.protection.outlook.com*.skype.com*.skypeforbusiness.coma.wunderlist.comaccount.live.comaccounts.google.comacompli.helpshift.comapi.diagnostics.office.comapi.dropboxapi.comapi.login.yahoo.comapi.meetup.comapp.adjust.comapp.box.combit.ly, www.acompli.comby.uservoice.comdata.flurry.complay.google.comrink.hockeyapp.netwww.evernote.comwww.google-analytics.comwww.youtube.com*.facebook.com*.yahoo.com*.msn.comclients4.google.comwww.reddit.com



Please find my responses and queries as well.
1. Instead of dstdomain , I tried the url_regex as defined below and even it is not blocking the sites through the proxy.
Kindly let me know how to allow and block the sites ?

acl allowedurl url_regex /etc/squid/allowed_url.txtacl denylist url_regex /etc/squid/denylist.txt
2.? I have defined only two ports 80 and 443 and removed all other ports. May I know whether the below order must be used since you stated the below "All custom rules should follow those." Kindly let me know whether the below order is correct or not.

http_access deny !Safe_ports
http_access deny denylisthttp_access allow allowedurlhttp_access allow localhost managerhttp_access allow localhosthttp_access allow localnethttp_access deny managerhttp_access deny all

RegardsArjun K.
    On Tuesday, 5 May, 2020, 07:02:46 pm IST, Amos Jeffries <squid3 at treenet.co.nz> wrote:  
 
 On 6/05/20 12:58 am, Arjun K wrote:
> Hi All
> 
> Can any one help on the below issue.
> I tried changing the order of deny and allow acl but it did not yield
> any result.
> 

What is the contents of the denylist.txt file?

This usually happens when things in there are not the right dstdomain
syntax.





> Regards
> Arjun K
> 
> 
> On Sunday, 3 May, 2020, 05:21:02 pm IST, Arjun K <email_arjun at yahoo.com>
> wrote:
> 
> 
> Hi All
> 
> The below is the configuration defined in the proxy server.
> The issue is that the proxy is not blocking the websites mentioned in a
> file named denylist.txt.
> Kindly let me know what needs to be changed to block the websites.
> 
> 
> 
> ####IP Ranges allowed to use proxy
> acl localnet src 10.196.0.0/16
> acl localnet src 10.197.0.0/16
> acl localnet src 10.198.0.0/16
> acl localnet src 10.199.0.0/16
> acl localnet src 10.200.0.0/16

These can be simplified:

 acl localnet 10.196.0.0-10.200.0.0/16


> 
> ####Allowed and Denied URLs
> acl allowedurl dstdomain /etc/squid/allowed_url.txt

dstdomain and URL are different things. The name of this ACL is deceptive.

> acl denylist dstdomain /etc/squid/denylist.txt
> 
...

You are missing the DoS protection checks:

 http_access deny !Safe_ports
 http_access deny CONNECT !SSL_ports

All custom rules should follow those.


> http_access allow CONNECT wuCONNECT localnet
> http_access allow windowsupdate localnet
> 
> acl Safe_ports port 80 # http
> acl Safe_ports port 443 # https
> acl CONNECT method CONNECT
> 
> http_access allow allowedurl
> http_access deny denylist
> http_access allow localhost manager
> http_access allow localhost
> http_access allow localnet
> http_access deny manager
> http_access deny !Safe_ports

The manager and Safe_Ports checks are useless down here. Their entire
purpose is to prevent unauthorized access to dangerous protocols and
security sensitive proxy management API.


> http_access deny all
> 
...
> 
> refresh_pattern ^ftp:? ? ? ? ? ?1440? ? 20%? ? ?10080
> refresh_pattern ^gopher:? ? ? ? 1440? ? 0%? ? ? 1440
> refresh_pattern -i (/cgi-bin/|\?) 0? ? ?0%? ? ? 0
> refresh_pattern .? ? ? ? ? ? ? ?0? ? ? ?20%? ? ?4320

No refresh_pattern following this line will ever match. The "." pattern
matches every URL possible. Order is important.

> refresh_pattern -i
> windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320
> 80% 43200 reload-into-ims
> refresh_pattern -i
> microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims
> refresh_pattern -i
> windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims
> 


Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200505/9801dcd2/attachment.htm>

From ryanlele264 at gmail.com  Tue May  5 21:29:04 2020
From: ryanlele264 at gmail.com (Ryan Le)
Date: Tue, 5 May 2020 17:29:04 -0400
Subject: [squid-users] Encrypt CONNECT Header
In-Reply-To: <e3dbcfb1-4e93-466e-e8d9-dc3b74d5093f@measurement-factory.com>
References: <CANqqF0pgVy496QoEJAbCbPKLyz4XaSy_Y_CKAsUTw0-mZoaiWg@mail.gmail.com>
 <e3dbcfb1-4e93-466e-e8d9-dc3b74d5093f@measurement-factory.com>
Message-ID: <CANqqF0qG_VfYfiSW3Z5tWZP9NyxORZxNZX4tQ1vnC_uSXwQ7gg@mail.gmail.com>

Hi All,
Thanks for providing the information.
The issue is not related to the server certificate SNI. It's related to
exposing a few other sensitive data points such as the domain which is
clearly exposed in the CONNECT header. This would be exposed regardless of
TLS 1.3. Also, there are other headers that are sensitive and outside the
encrypted payload including User-Agent and Proxy-Authorization. The
Proxy-Authorization is of concern here. Most modern browsers now support
PAC with HTTPS versus PROXY.

The Proxy-Authorization can carry the Basic Auth (and NTLM) credentials
which is of concern currently since all users are mobile.

Being proactive before this become a problem at causes unnecessary
exposure. Zoom had a lot of issues and wouldn't want this to affect squid
or squid users.

On Tue, May 5, 2020 at 11:33 AM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 5/5/20 10:18 AM, Ryan Le wrote:
> > Is there plans to support explicit forward proxy over HTTPS to the proxy
> > with ssl-bump?
>
> There have been a few requests for TLS-inside-TLS support, but I am not
> aware of any actual sponsors or features on the road map. It is a
> complicated project, even though each of its two components already
> works today.
>
>
> > We would like to use https_port ssl-bump without using the
> > intercept or tproxy option. Clients will use PAC with a HTTPS directive
> > rather than a PROXY directive. The goal is to also encrypted the CONNECT
> > header which exposes the domain in plain text while it traverses to the
> > proxy.
>
> Yes, it is a valid use case (that few people understand).
>
>
> > Felipe: you don't need to use ssl-bump with explicit https proxy.
>
> Popular browsers barely support HTTPS proxies and refuse to delegate TLS
> handling to them. Thus, a connection to a secure origin server will be
> encrypted by the browser and sent over an encrypted channel through the
> HTTPS proxy -- TLS-inside-TLS. If you want to look inside that browser
> connection, you have to remove both TLS layers. To remove the outer
> layer, you need an https_port in a forward proxy configuration. To
> remove the inner layer, you need SslBump. The combination is not yet
> supported.
>
>
> > Matus: people will still be able to see SNI SSL header.
>
> ... but not the origin server SNI. Only the proxy SNI is exposed in this
> use case, and that exposure is usually not a problem.
>
>
> Cheers,
>
> Alex.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200505/e29f1b30/attachment.htm>

From squid3 at treenet.co.nz  Tue May  5 21:52:23 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 May 2020 09:52:23 +1200
Subject: [squid-users] Squid Proxy not blocking websites
In-Reply-To: <1284055797.1180517.1588697255715@mail.yahoo.com>
References: <2093095721.337076.1588506662085.ref@mail.yahoo.com>
 <2093095721.337076.1588506662085@mail.yahoo.com>
 <951697970.1126998.1588683537565@mail.yahoo.com>
 <f92498d8-5156-0294-0ff7-cd222bfd6497@treenet.co.nz>
 <1284055797.1180517.1588697255715@mail.yahoo.com>
Message-ID: <6520d592-915c-93e0-d228-d2aa92df1822@treenet.co.nz>

On 6/05/20 4:47 am, Arjun K wrote:
> Hi Amos
> 
> Thanks for your response and suggestions and I will incorporate your
> inputs in the configuration.
> Please find the below contents of denylist as I am unable to attach as a
> document due to restrictions.
> 
> .hotmail.com

The above is dstdomain wildcard syntax.

Below is dstdomain FQDN syntax.


> *.appex-rf.msn.com
> *.itunes.apple.com

The format is a series of domain segments/labels. They get exact-string
compared against the domain, starting at the TLD and working left.

A '.' at the start of the line means "all subdomain labels match".

See also the FAQ
<https://wiki.squid-cache.org/SquidFaq/SquidAcl#Squid_doesn.27t_match_my_subdomains>

Amos


From akshay.k.hegde at gmail.com  Wed May  6 12:58:17 2020
From: akshay.k.hegde at gmail.com (Akshay Hegde)
Date: Wed, 6 May 2020 18:28:17 +0530
Subject: [squid-users] squid logging disable based on ACL & kernel: Out
	of memory
In-Reply-To: <3a2cb6ba-958c-5ef6-6826-28bccf1a807a@measurement-factory.com>
References: <CAH1tzCQ5m6+hUuPpcVnVVM=rWJh-nrXyscacgyXnMKhi8S82-A@mail.gmail.com>
 <7bbdbf59-0e43-2cf0-b074-47c8eb4b5846@measurement-factory.com>
 <CAH1tzCS+Skk40RVqFZwK+32fyqdeyv3L2=eZ6rrwS3gYck_4cA@mail.gmail.com>
 <3a2cb6ba-958c-5ef6-6826-28bccf1a807a@measurement-factory.com>
Message-ID: <CAH1tzCR4G7Bzr0bgC1eXcp2jStFgc2zPW16kiYNFqoEhymvFVw@mail.gmail.com>

Hi Alex,

I updated to latest squid as you suggested, and I tried SSL-Bump using
below config (which filters URLs which are in 443 too), however I have 600
users (windows, linux, Mac, mobile OS like Androd, Windows etc), so asking
them to import CA certificate in browser is not feasible.

1. Is there any way to filter HTTPS URLs without importing CA certificates
on client side? if available can you share config snippet
2. for 16GB RAM, 4 core CPU, 8GB Swap, expected to have 10GB cache,  how to
calculate configurations parameters, is there any thumb rule ? please share
how you usually calculate.

# config
cache_mgr webmaster
cache deny QUERY
cache_mem 256 MB
cache_swap_low 90
cache_swap_high 95
maximum_object_size 4 MB
minimum_object_size 0 KB
maximum_object_size_in_memory 512 kB
ipcache_size 2048
ipcache_low 90
ipcache_high 95
fqdncache_size 1024
cache_replacement_policy lru
memory_replacement_policy lru
cache_dir ufs /var/spool/squid 10000 16 256
cache_effective_user squid
cache_effective_group squid
cache_log /var/log/squid/cache.log
cache_store_log /var/log/squid/store.log
memory_pools on
memory_pools_limit 5 MB

# SSL-Bump -working but not feasible.
http_port 3128 ssl-bump cert=/etc/squid/sslcert/proxyCA.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
sslcrtd_program /usr/lib64/squid/security_file_certgen -s
 /var/spool/squid/ssl_db -M 4MB
sslcrtd_children 5
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all

------------------------------------ My New Environment --------------------
# squid -v
Squid Cache: Version 4.4
Service Name: squid

# cat /etc/redhat-release
CentOS Linux release 8.1.1911 (Core)


# Tested ACLs
logformat test_log %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %>ru %[un %Sh/%<a
%mt
acl test_sites dstdomain "/etc/squid/acls/test_sites.acl"
access_log /var/log/squid/test_site.log test_log test_sites

# tail -f /var/log/squid/test_site.log
1588678050.178   3247 10.0.2.15 TCP_TUNNEL/200 28073 CONNECT
nav.sciencedirect.com:443 akshay HIER_DIRECT/91.235.133.74 -
1588678050.189   3942 10.0.2.15 TCP_TUNNEL/200 24000 CONNECT
nav.sciencedirect.com:443 akshay HIER_DIRECT/91.235.133.74 -
1588678050.355   2552 10.0.2.15 TCP_TUNNEL/200 788 CONNECT
nav.sciencedirect.com:443 akshay HIER_DIRECT/91.235.133.74 -
1588681419.635    647 10.0.2.15 TCP_MISS/200 402 POST
http://scratchpads.eu/modules/statistics/statistics.php akshay HIER_DIRECT/
157.140.2.32 text/html
1588681420.055   1069 10.0.2.15 TCP_MISS/200 46772 GET
http://scratchpads.eu/sites/all/themes/scratchpads_eu/images/shrimp-202px.png
akshay HIER_DIRECT/157.140.2.32 image/png




On Sat, May 2, 2020 at 1:00 AM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 5/1/20 12:43 PM, Akshay Hegde wrote:
>
> > I have below option globally, which I don't want to make "off"
> > strip_query_terms on
>
> > acl track dstdomain "/etc/squid/sites_track.txt"
> > access_log /var/log/squid/full_site_links.log squid_custom track
>
> > however for specific ACL I would like to log full URL with query
> > parameters, how this can be done ?
>
> I have not tested this, and the results may be version-dependent, but
> according to logformat documentation[1], %ru honors strip_query_terms
> while %>ru does not:
>
>     logformat strippedFormat %ts... %ru ...
>     access_log ... strippedFormat track !specific_ACL
>
>     logformat detailedFormat %ts... %>ru ...
>     access_log ... detailedFormat track specific_ACL
>
> [1] http://www.squid-cache.org/Doc/config/logformat/
>
>
> HTH,
>
> Alex.
>
> > On Fri, May 1, 2020 at 7:05 PM Alex Rousskov wrote:
> >
> >     On 5/1/20 1:20 AM, Akshay Hegde wrote:
> >
> >     > *1. How to disable logging of few ACLs ?
> >
> >     Use "access_log none aclX" to prevent creation of access.log records
> for
> >     transactions matching aclX. See
> >
> http://lists.squid-cache.org/pipermail/squid-users/2020-April/021876.html
> >     for
> >     some related caveats.
> >
> >
> >     > *2. Kernel Out of Memory
> >
> >     This problem is most likely unrelated to logging. If your Squid is
> >     gradually leaking memory (rather than just being overwhelmed with
> >     traffic), then the first step towards removing those memory leaks
> would
> >     be to upgrade your Squid from the unsupported and buggy v3.1.10.
> >
> >
> >     HTH,
> >
> >     Alex.
> >
> >
> >
> > --
> > <
> https://about.me/akshay.k.hegde?promo=email_sig&utm_source=product&utm_medium=email_sig&utm_campaign=edit_panel&utm_content=thumb
> >
> >
> > Akshay Hegde
> > about.me/akshay.k.hegde
> > <
> https://about.me/akshay.k.hegde?promo=email_sig&utm_source=product&utm_medium=email_sig&utm_campaign=edit_panel&utm_content=thumb
> >
> >
> >
>
>

-- 
<https://about.me/akshay.k.hegde?promo=email_sig&utm_source=product&utm_medium=email_sig&utm_campaign=edit_panel&utm_content=thumb>
Akshay Hegde
about.me/akshay.k.hegde
<https://about.me/akshay.k.hegde?promo=email_sig&utm_source=product&utm_medium=email_sig&utm_campaign=edit_panel&utm_content=thumb>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200506/b710bb17/attachment.htm>

From rousskov at measurement-factory.com  Wed May  6 14:26:22 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 6 May 2020 10:26:22 -0400
Subject: [squid-users] squid logging disable based on ACL & kernel: Out
 of memory
In-Reply-To: <CAH1tzCR4G7Bzr0bgC1eXcp2jStFgc2zPW16kiYNFqoEhymvFVw@mail.gmail.com>
References: <CAH1tzCQ5m6+hUuPpcVnVVM=rWJh-nrXyscacgyXnMKhi8S82-A@mail.gmail.com>
 <7bbdbf59-0e43-2cf0-b074-47c8eb4b5846@measurement-factory.com>
 <CAH1tzCS+Skk40RVqFZwK+32fyqdeyv3L2=eZ6rrwS3gYck_4cA@mail.gmail.com>
 <3a2cb6ba-958c-5ef6-6826-28bccf1a807a@measurement-factory.com>
 <CAH1tzCR4G7Bzr0bgC1eXcp2jStFgc2zPW16kiYNFqoEhymvFVw@mail.gmail.com>
Message-ID: <5d08b65c-2eb3-e9fa-6926-c58dc13fe254@measurement-factory.com>

On 5/6/20 8:58 AM, Akshay Hegde wrote:

> 1. Is there any way to filter HTTPS URLs without importing CA
> certificates on client side?

No, there is no way for a proxy to look at request URLs without the
browser trusting the proxy certificate. There are other ways to police
traffic (e.g., browser plugins), but they all require fiddling with the
client environment.


> 2. for 16GB RAM, 4 core CPU, 8GB Swap, expected to have 10GB cache,? how
> to calculate configurations parameters, is there any thumb rule ?

I believe there is some related advice on Squid wiki:
https://wiki.squid-cache.org/SquidFaq/SquidMemory

HTH,

Alex.


> # config
> cache_mgr webmaster
> cache deny QUERY
> cache_mem 256 MB
> cache_swap_low 90
> cache_swap_high 95
> maximum_object_size 4 MB
> minimum_object_size 0 KB
> maximum_object_size_in_memory 512 kB
> ipcache_size 2048
> ipcache_low 90
> ipcache_high 95
> fqdncache_size 1024
> cache_replacement_policy lru
> memory_replacement_policy lru
> cache_dir ufs /var/spool/squid 10000 16 256
> cache_effective_user squid
> cache_effective_group squid
> cache_log /var/log/squid/cache.log
> cache_store_log /var/log/squid/store.log
> memory_pools on
> memory_pools_limit 5 MB
> 
> # SSL-Bump -working but not feasible.
> http_port 3128 ssl-bump cert=/etc/squid/sslcert/proxyCA.pem
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> sslcrtd_program /usr/lib64/squid/security_file_certgen -s
> ?/var/spool/squid/ssl_db -M 4MB
> sslcrtd_children 5
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump bump all
> 
> ------------------------------------ My New Environment --------------------
> # squid -v
> Squid Cache: Version 4.4
> Service Name: squid
> 
> # cat /etc/redhat-release
> CentOS Linux release 8.1.1911 (Core)
> 
> 
> # Tested ACLs
> logformat test_log %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %>ru %[un
> %Sh/%<a %mt
> acl test_sites dstdomain "/etc/squid/acls/test_sites.acl"
> access_log /var/log/squid/test_site.log test_log test_sites
> 
> # tail -f /var/log/squid/test_site.log
> 1588678050.178 ? 3247 10.0.2.15 TCP_TUNNEL/200 28073 CONNECT
> nav.sciencedirect.com:443 <http://nav.sciencedirect.com:443> akshay
> HIER_DIRECT/91.235.133.74 <http://91.235.133.74> -
> 1588678050.189 ? 3942 10.0.2.15 TCP_TUNNEL/200 24000 CONNECT
> nav.sciencedirect.com:443 <http://nav.sciencedirect.com:443> akshay
> HIER_DIRECT/91.235.133.74 <http://91.235.133.74> -
> 1588678050.355 ? 2552 10.0.2.15 TCP_TUNNEL/200 788 CONNECT
> nav.sciencedirect.com:443 <http://nav.sciencedirect.com:443> akshay
> HIER_DIRECT/91.235.133.74 <http://91.235.133.74> -
> 1588681419.635 ? ?647 10.0.2.15 TCP_MISS/200 402 POST
> http://scratchpads.eu/modules/statistics/statistics.php akshay
> HIER_DIRECT/157.140.2.32 <http://157.140.2.32> text/html
> 1588681420.055 ? 1069 10.0.2.15 TCP_MISS/200 46772 GET
> http://scratchpads.eu/sites/all/themes/scratchpads_eu/images/shrimp-202px.png
> akshay HIER_DIRECT/157.140.2.32 <http://157.140.2.32> image/png
> 
> 
> 
> 
> On Sat, May 2, 2020 at 1:00 AM Alex Rousskov
> <rousskov at measurement-factory.com
> <mailto:rousskov at measurement-factory.com>> wrote:
> 
>     On 5/1/20 12:43 PM, Akshay Hegde wrote:
> 
>     > I have below option globally, which I don't want to make "off"
>     > strip_query_terms on
> 
>     > acl track dstdomain "/etc/squid/sites_track.txt"
>     > access_log /var/log/squid/full_site_links.log squid_custom track
> 
>     > however for specific ACL I would like to log full URL with query
>     > parameters, how this can be done ?
> 
>     I have not tested this, and the results may be version-dependent, but
>     according to logformat documentation[1], %ru honors strip_query_terms
>     while %>ru does not:
> 
>     ? ? logformat strippedFormat %ts... %ru ...
>     ? ? access_log ... strippedFormat track !specific_ACL
> 
>     ? ? logformat detailedFormat %ts... %>ru ...
>     ? ? access_log ... detailedFormat track specific_ACL
> 
>     [1] http://www.squid-cache.org/Doc/config/logformat/
> 
> 
>     HTH,
> 
>     Alex.
> 
>     > On Fri, May 1, 2020 at 7:05 PM Alex Rousskov wrote:
>     >
>     >? ? ?On 5/1/20 1:20 AM, Akshay Hegde wrote:
>     >
>     >? ? ?> *1. How to disable logging of few ACLs ?
>     >
>     >? ? ?Use "access_log none aclX" to prevent creation of access.log
>     records for
>     >? ? ?transactions matching aclX. See
>     >? ?
>     ?http://lists.squid-cache.org/pipermail/squid-users/2020-April/021876.html
>     >? ? ?for
>     >? ? ?some related caveats.
>     >
>     >
>     >? ? ?> *2. Kernel Out of Memory
>     >
>     >? ? ?This problem is most likely unrelated to logging. If your Squid is
>     >? ? ?gradually leaking memory (rather than just being overwhelmed with
>     >? ? ?traffic), then the first step towards removing those memory
>     leaks would
>     >? ? ?be to upgrade your Squid from the unsupported and buggy v3.1.10.
>     >


From felipeapolanco at gmail.com  Wed May  6 14:34:50 2020
From: felipeapolanco at gmail.com (Felipe Polanco)
Date: Wed, 6 May 2020 10:34:50 -0400
Subject: [squid-users] Encrypt CONNECT Header
In-Reply-To: <CANqqF0qG_VfYfiSW3Z5tWZP9NyxORZxNZX4tQ1vnC_uSXwQ7gg@mail.gmail.com>
References: <CANqqF0pgVy496QoEJAbCbPKLyz4XaSy_Y_CKAsUTw0-mZoaiWg@mail.gmail.com>
 <e3dbcfb1-4e93-466e-e8d9-dc3b74d5093f@measurement-factory.com>
 <CANqqF0qG_VfYfiSW3Z5tWZP9NyxORZxNZX4tQ1vnC_uSXwQ7gg@mail.gmail.com>
Message-ID: <CADcj3=6c-fnp26yF3JbfUvL3TSDMeO7NZR=nbVDHrm=noB3sag@mail.gmail.com>

If you need to encrypt the traffic between the browser and the proxy
perhaps you can use a VPN or a browser extension for this, that way your
traffic is encrypted on its way to the proxy.

On Tue, May 5, 2020 at 5:29 PM Ryan Le <ryanlele264 at gmail.com> wrote:

> Hi All,
> Thanks for providing the information.
> The issue is not related to the server certificate SNI. It's related to
> exposing a few other sensitive data points such as the domain which is
> clearly exposed in the CONNECT header. This would be exposed regardless of
> TLS 1.3. Also, there are other headers that are sensitive and outside the
> encrypted payload including User-Agent and Proxy-Authorization. The
> Proxy-Authorization is of concern here. Most modern browsers now support
> PAC with HTTPS versus PROXY.
>
> The Proxy-Authorization can carry the Basic Auth (and NTLM) credentials
> which is of concern currently since all users are mobile.
>
> Being proactive before this become a problem at causes unnecessary
> exposure. Zoom had a lot of issues and wouldn't want this to affect squid
> or squid users.
>
> On Tue, May 5, 2020 at 11:33 AM Alex Rousskov <
> rousskov at measurement-factory.com> wrote:
>
>> On 5/5/20 10:18 AM, Ryan Le wrote:
>> > Is there plans to support explicit forward proxy over HTTPS to the proxy
>> > with ssl-bump?
>>
>> There have been a few requests for TLS-inside-TLS support, but I am not
>> aware of any actual sponsors or features on the road map. It is a
>> complicated project, even though each of its two components already
>> works today.
>>
>>
>> > We would like to use https_port ssl-bump without using the
>> > intercept or tproxy option. Clients will use PAC with a HTTPS directive
>> > rather than a PROXY directive. The goal is to also encrypted the CONNECT
>> > header which exposes the domain in plain text while it traverses to the
>> > proxy.
>>
>> Yes, it is a valid use case (that few people understand).
>>
>>
>> > Felipe: you don't need to use ssl-bump with explicit https proxy.
>>
>> Popular browsers barely support HTTPS proxies and refuse to delegate TLS
>> handling to them. Thus, a connection to a secure origin server will be
>> encrypted by the browser and sent over an encrypted channel through the
>> HTTPS proxy -- TLS-inside-TLS. If you want to look inside that browser
>> connection, you have to remove both TLS layers. To remove the outer
>> layer, you need an https_port in a forward proxy configuration. To
>> remove the inner layer, you need SslBump. The combination is not yet
>> supported.
>>
>>
>> > Matus: people will still be able to see SNI SSL header.
>>
>> ... but not the origin server SNI. Only the proxy SNI is exposed in this
>> use case, and that exposure is usually not a problem.
>>
>>
>> Cheers,
>>
>> Alex.
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200506/84f74bc0/attachment.htm>

From akshay.k.hegde at gmail.com  Wed May  6 14:45:55 2020
From: akshay.k.hegde at gmail.com (Akshay Hegde)
Date: Wed, 6 May 2020 20:15:55 +0530
Subject: [squid-users] squid logging disable based on ACL & kernel: Out
	of memory
In-Reply-To: <5d08b65c-2eb3-e9fa-6926-c58dc13fe254@measurement-factory.com>
References: <CAH1tzCQ5m6+hUuPpcVnVVM=rWJh-nrXyscacgyXnMKhi8S82-A@mail.gmail.com>
 <7bbdbf59-0e43-2cf0-b074-47c8eb4b5846@measurement-factory.com>
 <CAH1tzCS+Skk40RVqFZwK+32fyqdeyv3L2=eZ6rrwS3gYck_4cA@mail.gmail.com>
 <3a2cb6ba-958c-5ef6-6826-28bccf1a807a@measurement-factory.com>
 <CAH1tzCR4G7Bzr0bgC1eXcp2jStFgc2zPW16kiYNFqoEhymvFVw@mail.gmail.com>
 <5d08b65c-2eb3-e9fa-6926-c58dc13fe254@measurement-factory.com>
Message-ID: <CAH1tzCSLnf8zhO6DeoPck5SmaWiA5TQOKoV=uxynU8PVWz0UbQ@mail.gmail.com>

Hi Alex,

Thanks for confirming, I lost hope. Can you share some link or details
about below

> There are other ways to police
traffic (e.g., browser plugins), but they all require fiddling with the
client environment.

On Wed, May 6, 2020, 7:56 PM Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 5/6/20 8:58 AM, Akshay Hegde wrote:
>
> > 1. Is there any way to filter HTTPS URLs without importing CA
> > certificates on client side?
>
> No, there is no way for a proxy to look at request URLs without the
> browser trusting the proxy certificate. There are other ways to police
> traffic (e.g., browser plugins), but they all require fiddling with the
> client environment.
>
>
> > 2. for 16GB RAM, 4 core CPU, 8GB Swap, expected to have 10GB cache,  how
> > to calculate configurations parameters, is there any thumb rule ?
>
> I believe there is some related advice on Squid wiki:
> https://wiki.squid-cache.org/SquidFaq/SquidMemory
>
> HTH,
>
> Alex.
>
>
> > # config
> > cache_mgr webmaster
> > cache deny QUERY
> > cache_mem 256 MB
> > cache_swap_low 90
> > cache_swap_high 95
> > maximum_object_size 4 MB
> > minimum_object_size 0 KB
> > maximum_object_size_in_memory 512 kB
> > ipcache_size 2048
> > ipcache_low 90
> > ipcache_high 95
> > fqdncache_size 1024
> > cache_replacement_policy lru
> > memory_replacement_policy lru
> > cache_dir ufs /var/spool/squid 10000 16 256
> > cache_effective_user squid
> > cache_effective_group squid
> > cache_log /var/log/squid/cache.log
> > cache_store_log /var/log/squid/store.log
> > memory_pools on
> > memory_pools_limit 5 MB
> >
> > # SSL-Bump -working but not feasible.
> > http_port 3128 ssl-bump cert=/etc/squid/sslcert/proxyCA.pem
> > generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> > sslcrtd_program /usr/lib64/squid/security_file_certgen -s
> >  /var/spool/squid/ssl_db -M 4MB
> > sslcrtd_children 5
> > acl step1 at_step SslBump1
> > ssl_bump peek step1
> > ssl_bump bump all
> >
> > ------------------------------------ My New Environment
> --------------------
> > # squid -v
> > Squid Cache: Version 4.4
> > Service Name: squid
> >
> > # cat /etc/redhat-release
> > CentOS Linux release 8.1.1911 (Core)
> >
> >
> > # Tested ACLs
> > logformat test_log %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %>ru %[un
> > %Sh/%<a %mt
> > acl test_sites dstdomain "/etc/squid/acls/test_sites.acl"
> > access_log /var/log/squid/test_site.log test_log test_sites
> >
> > # tail -f /var/log/squid/test_site.log
> > 1588678050.178   3247 10.0.2.15 TCP_TUNNEL/200 28073 CONNECT
> > nav.sciencedirect.com:443 <http://nav.sciencedirect.com:443> akshay
> > HIER_DIRECT/91.235.133.74 <http://91.235.133.74> -
> > 1588678050.189   3942 10.0.2.15 TCP_TUNNEL/200 24000 CONNECT
> > nav.sciencedirect.com:443 <http://nav.sciencedirect.com:443> akshay
> > HIER_DIRECT/91.235.133.74 <http://91.235.133.74> -
> > 1588678050.355   2552 10.0.2.15 TCP_TUNNEL/200 788 CONNECT
> > nav.sciencedirect.com:443 <http://nav.sciencedirect.com:443> akshay
> > HIER_DIRECT/91.235.133.74 <http://91.235.133.74> -
> > 1588681419.635    647 10.0.2.15 TCP_MISS/200 402 POST
> > http://scratchpads.eu/modules/statistics/statistics.php akshay
> > HIER_DIRECT/157.140.2.32 <http://157.140.2.32> text/html
> > 1588681420.055   1069 10.0.2.15 TCP_MISS/200 46772 GET
> >
> http://scratchpads.eu/sites/all/themes/scratchpads_eu/images/shrimp-202px.png
> > akshay HIER_DIRECT/157.140.2.32 <http://157.140.2.32> image/png
> >
> >
> >
> >
> > On Sat, May 2, 2020 at 1:00 AM Alex Rousskov
> > <rousskov at measurement-factory.com
> > <mailto:rousskov at measurement-factory.com>> wrote:
> >
> >     On 5/1/20 12:43 PM, Akshay Hegde wrote:
> >
> >     > I have below option globally, which I don't want to make "off"
> >     > strip_query_terms on
> >
> >     > acl track dstdomain "/etc/squid/sites_track.txt"
> >     > access_log /var/log/squid/full_site_links.log squid_custom track
> >
> >     > however for specific ACL I would like to log full URL with query
> >     > parameters, how this can be done ?
> >
> >     I have not tested this, and the results may be version-dependent, but
> >     according to logformat documentation[1], %ru honors strip_query_terms
> >     while %>ru does not:
> >
> >         logformat strippedFormat %ts... %ru ...
> >         access_log ... strippedFormat track !specific_ACL
> >
> >         logformat detailedFormat %ts... %>ru ...
> >         access_log ... detailedFormat track specific_ACL
> >
> >     [1] http://www.squid-cache.org/Doc/config/logformat/
> >
> >
> >     HTH,
> >
> >     Alex.
> >
> >     > On Fri, May 1, 2020 at 7:05 PM Alex Rousskov wrote:
> >     >
> >     >     On 5/1/20 1:20 AM, Akshay Hegde wrote:
> >     >
> >     >     > *1. How to disable logging of few ACLs ?
> >     >
> >     >     Use "access_log none aclX" to prevent creation of access.log
> >     records for
> >     >     transactions matching aclX. See
> >     >
> >
> http://lists.squid-cache.org/pipermail/squid-users/2020-April/021876.html
> >     >     for
> >     >     some related caveats.
> >     >
> >     >
> >     >     > *2. Kernel Out of Memory
> >     >
> >     >     This problem is most likely unrelated to logging. If your
> Squid is
> >     >     gradually leaking memory (rather than just being overwhelmed
> with
> >     >     traffic), then the first step towards removing those memory
> >     leaks would
> >     >     be to upgrade your Squid from the unsupported and buggy
> v3.1.10.
> >     >
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200506/6151953a/attachment.htm>

From rousskov at measurement-factory.com  Wed May  6 14:51:50 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 6 May 2020 10:51:50 -0400
Subject: [squid-users] squid logging disable based on ACL & kernel: Out
 of memory
In-Reply-To: <CAH1tzCSLnf8zhO6DeoPck5SmaWiA5TQOKoV=uxynU8PVWz0UbQ@mail.gmail.com>
References: <CAH1tzCQ5m6+hUuPpcVnVVM=rWJh-nrXyscacgyXnMKhi8S82-A@mail.gmail.com>
 <7bbdbf59-0e43-2cf0-b074-47c8eb4b5846@measurement-factory.com>
 <CAH1tzCS+Skk40RVqFZwK+32fyqdeyv3L2=eZ6rrwS3gYck_4cA@mail.gmail.com>
 <3a2cb6ba-958c-5ef6-6826-28bccf1a807a@measurement-factory.com>
 <CAH1tzCR4G7Bzr0bgC1eXcp2jStFgc2zPW16kiYNFqoEhymvFVw@mail.gmail.com>
 <5d08b65c-2eb3-e9fa-6926-c58dc13fe254@measurement-factory.com>
 <CAH1tzCSLnf8zhO6DeoPck5SmaWiA5TQOKoV=uxynU8PVWz0UbQ@mail.gmail.com>
Message-ID: <adce0a2e-10b5-72e0-3d9d-b2b40ca59417@measurement-factory.com>

On 5/6/20 10:45 AM, Akshay Hegde wrote:

> Can you share some link or details about below

Sorry, I cannot -- it has been many years since I worked on browser
plugins, and I have heard that there were significant changes in
APIs/rights since then. Perhaps others on the mailing list can help you.
If not, most of the related information should be publicly available.

Alex.

>> There are other ways to police
> traffic (e.g., browser plugins), but they all require fiddling with the
> client environment.
> 
> On Wed, May 6, 2020, 7:56 PM Alex Rousskov wrote:
> 
>     On 5/6/20 8:58 AM, Akshay Hegde wrote:
> 
>     > 1. Is there any way to filter HTTPS URLs without importing CA
>     > certificates on client side?
> 
>     No, there is no way for a proxy to look at request URLs without the
>     browser trusting the proxy certificate. There are other ways to police
>     traffic (e.g., browser plugins), but they all require fiddling with the
>     client environment.
> 
> 
>     > 2. for 16GB RAM, 4 core CPU, 8GB Swap, expected to have 10GB
>     cache,? how
>     > to calculate configurations parameters, is there any thumb rule ?
> 
>     I believe there is some related advice on Squid wiki:
>     https://wiki.squid-cache.org/SquidFaq/SquidMemory
> 
>     HTH,
> 
>     Alex.
> 
> 
>     > # config
>     > cache_mgr webmaster
>     > cache deny QUERY
>     > cache_mem 256 MB
>     > cache_swap_low 90
>     > cache_swap_high 95
>     > maximum_object_size 4 MB
>     > minimum_object_size 0 KB
>     > maximum_object_size_in_memory 512 kB
>     > ipcache_size 2048
>     > ipcache_low 90
>     > ipcache_high 95
>     > fqdncache_size 1024
>     > cache_replacement_policy lru
>     > memory_replacement_policy lru
>     > cache_dir ufs /var/spool/squid 10000 16 256
>     > cache_effective_user squid
>     > cache_effective_group squid
>     > cache_log /var/log/squid/cache.log
>     > cache_store_log /var/log/squid/store.log
>     > memory_pools on
>     > memory_pools_limit 5 MB
>     >
>     > # SSL-Bump -working but not feasible.
>     > http_port 3128 ssl-bump cert=/etc/squid/sslcert/proxyCA.pem
>     > generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>     > sslcrtd_program /usr/lib64/squid/security_file_certgen -s
>     > ?/var/spool/squid/ssl_db -M 4MB
>     > sslcrtd_children 5
>     > acl step1 at_step SslBump1
>     > ssl_bump peek step1
>     > ssl_bump bump all
>     >
>     > ------------------------------------ My New Environment
>     --------------------
>     > # squid -v
>     > Squid Cache: Version 4.4
>     > Service Name: squid
>     >
>     > # cat /etc/redhat-release
>     > CentOS Linux release 8.1.1911 (Core)
>     >
>     >
>     > # Tested ACLs
>     > logformat test_log %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %>ru %[un
>     > %Sh/%<a %mt
>     > acl test_sites dstdomain "/etc/squid/acls/test_sites.acl"
>     > access_log /var/log/squid/test_site.log test_log test_sites
>     >
>     > # tail -f /var/log/squid/test_site.log
>     > 1588678050.178 ? 3247 10.0.2.15 TCP_TUNNEL/200 28073 CONNECT
>     > nav.sciencedirect.com:443 <http://nav.sciencedirect.com:443>
>     <http://nav.sciencedirect.com:443> akshay
>     > HIER_DIRECT/91.235.133.74 <http://91.235.133.74>
>     <http://91.235.133.74> -
>     > 1588678050.189 ? 3942 10.0.2.15 TCP_TUNNEL/200 24000 CONNECT
>     > nav.sciencedirect.com:443 <http://nav.sciencedirect.com:443>
>     <http://nav.sciencedirect.com:443> akshay
>     > HIER_DIRECT/91.235.133.74 <http://91.235.133.74>
>     <http://91.235.133.74> -
>     > 1588678050.355 ? 2552 10.0.2.15 TCP_TUNNEL/200 788 CONNECT
>     > nav.sciencedirect.com:443 <http://nav.sciencedirect.com:443>
>     <http://nav.sciencedirect.com:443> akshay
>     > HIER_DIRECT/91.235.133.74 <http://91.235.133.74>
>     <http://91.235.133.74> -
>     > 1588681419.635 ? ?647 10.0.2.15 TCP_MISS/200 402 POST
>     > http://scratchpads.eu/modules/statistics/statistics.php akshay
>     > HIER_DIRECT/157.140.2.32 <http://157.140.2.32>
>     <http://157.140.2.32> text/html
>     > 1588681420.055 ? 1069 10.0.2.15 TCP_MISS/200 46772 GET
>     >
>     http://scratchpads.eu/sites/all/themes/scratchpads_eu/images/shrimp-202px.png
>     > akshay HIER_DIRECT/157.140.2.32 <http://157.140.2.32>
>     <http://157.140.2.32> image/png
>     >
>     >
>     >
>     >
>     > On Sat, May 2, 2020 at 1:00 AM Alex Rousskov
>     > <rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>
>     > <mailto:rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>>> wrote:
>     >
>     >? ? ?On 5/1/20 12:43 PM, Akshay Hegde wrote:
>     >
>     >? ? ?> I have below option globally, which I don't want to make "off"
>     >? ? ?> strip_query_terms on
>     >
>     >? ? ?> acl track dstdomain "/etc/squid/sites_track.txt"
>     >? ? ?> access_log /var/log/squid/full_site_links.log squid_custom track
>     >
>     >? ? ?> however for specific ACL I would like to log full URL with query
>     >? ? ?> parameters, how this can be done ?
>     >
>     >? ? ?I have not tested this, and the results may be
>     version-dependent, but
>     >? ? ?according to logformat documentation[1], %ru honors
>     strip_query_terms
>     >? ? ?while %>ru does not:
>     >
>     >? ? ?? ? logformat strippedFormat %ts... %ru ...
>     >? ? ?? ? access_log ... strippedFormat track !specific_ACL
>     >
>     >? ? ?? ? logformat detailedFormat %ts... %>ru ...
>     >? ? ?? ? access_log ... detailedFormat track specific_ACL
>     >
>     >? ? ?[1] http://www.squid-cache.org/Doc/config/logformat/
>     >
>     >
>     >? ? ?HTH,
>     >
>     >? ? ?Alex.
>     >
>     >? ? ?> On Fri, May 1, 2020 at 7:05 PM Alex Rousskov wrote:
>     >? ? ?>
>     >? ? ?>? ? ?On 5/1/20 1:20 AM, Akshay Hegde wrote:
>     >? ? ?>
>     >? ? ?>? ? ?> *1. How to disable logging of few ACLs ?
>     >? ? ?>
>     >? ? ?>? ? ?Use "access_log none aclX" to prevent creation of access.log
>     >? ? ?records for
>     >? ? ?>? ? ?transactions matching aclX. See
>     >? ? ?>? ?
>     >? ?
>     ??http://lists.squid-cache.org/pipermail/squid-users/2020-April/021876.html
>     >? ? ?>? ? ?for
>     >? ? ?>? ? ?some related caveats.
>     >? ? ?>
>     >? ? ?>
>     >? ? ?>? ? ?> *2. Kernel Out of Memory
>     >? ? ?>
>     >? ? ?>? ? ?This problem is most likely unrelated to logging. If
>     your Squid is
>     >? ? ?>? ? ?gradually leaking memory (rather than just being
>     overwhelmed with
>     >? ? ?>? ? ?traffic), then the first step towards removing those memory
>     >? ? ?leaks would
>     >? ? ?>? ? ?be to upgrade your Squid from the unsupported and buggy
>     v3.1.10.
>     >? ? ?>
> 



From uhlar at fantomas.sk  Wed May  6 15:18:03 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 6 May 2020 17:18:03 +0200
Subject: [squid-users] Encrypt CONNECT Header
In-Reply-To: <CANqqF0qG_VfYfiSW3Z5tWZP9NyxORZxNZX4tQ1vnC_uSXwQ7gg@mail.gmail.com>
References: <CANqqF0pgVy496QoEJAbCbPKLyz4XaSy_Y_CKAsUTw0-mZoaiWg@mail.gmail.com>
 <e3dbcfb1-4e93-466e-e8d9-dc3b74d5093f@measurement-factory.com>
 <CANqqF0qG_VfYfiSW3Z5tWZP9NyxORZxNZX4tQ1vnC_uSXwQ7gg@mail.gmail.com>
Message-ID: <20200506151803.GF26685@fantomas.sk>

On 05.05.20 17:29, Ryan Le wrote:
>The issue is not related to the server certificate SNI. It's related to
>exposing a few other sensitive data points such as the domain which is
>clearly exposed in the CONNECT header. This would be exposed regardless of
>TLS 1.3.

not if you talk to the proxy over https.
you don't need "forward proxy over HTTPS to the proxy with ssl-bump"
you only need "proxy over https".

I wonder that you are OK with proxy doing ssl-bump then.  You don't want
anyone to see traffic between browser and proxy, but are you OK that
the proxy will see what you browse on the destination servers?

> Also, there are other headers that are sensitive and outside the
>encrypted payload including User-Agent and Proxy-Authorization. The
>Proxy-Authorization is of concern here. Most modern browsers now support
>PAC with HTTPS versus PROXY.


>The Proxy-Authorization can carry the Basic Auth (and NTLM) credentials
>which is of concern currently since all users are mobile.
>
>Being proactive before this become a problem at causes unnecessary
>exposure. Zoom had a lot of issues and wouldn't want this to affect squid
>or squid users.

well, using "https_port" on squid and connecting to squid over https is just
enough for you.

>On Tue, May 5, 2020 at 11:33 AM Alex Rousskov <
>rousskov at measurement-factory.com> wrote:
>
>> On 5/5/20 10:18 AM, Ryan Le wrote:
>> > Is there plans to support explicit forward proxy over HTTPS to the proxy
>> > with ssl-bump?
>>
>> There have been a few requests for TLS-inside-TLS support, but I am not
>> aware of any actual sponsors or features on the road map. It is a
>> complicated project, even though each of its two components already
>> works today.
>>
>>
>> > We would like to use https_port ssl-bump without using the
>> > intercept or tproxy option. Clients will use PAC with a HTTPS directive
>> > rather than a PROXY directive. The goal is to also encrypted the CONNECT
>> > header which exposes the domain in plain text while it traverses to the
>> > proxy.
>>
>> Yes, it is a valid use case (that few people understand).
>>
>>
>> > Felipe: you don't need to use ssl-bump with explicit https proxy.
>>
>> Popular browsers barely support HTTPS proxies and refuse to delegate TLS
>> handling to them. Thus, a connection to a secure origin server will be
>> encrypted by the browser and sent over an encrypted channel through the
>> HTTPS proxy -- TLS-inside-TLS. If you want to look inside that browser
>> connection, you have to remove both TLS layers. To remove the outer
>> layer, you need an https_port in a forward proxy configuration. To
>> remove the inner layer, you need SslBump. The combination is not yet
>> supported.
>>
>>
>> > Matus: people will still be able to see SNI SSL header.
>>
>> ... but not the origin server SNI. Only the proxy SNI is exposed in this
>> use case, and that exposure is usually not a problem.


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Remember half the people you know are below average.


From squid3 at treenet.co.nz  Wed May  6 22:48:11 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 May 2020 10:48:11 +1200
Subject: [squid-users] Squid Proxy not blocking websites
In-Reply-To: <1505284137.157995.1588760454986@mail.yahoo.com>
References: <2093095721.337076.1588506662085.ref@mail.yahoo.com>
 <2093095721.337076.1588506662085@mail.yahoo.com>
 <951697970.1126998.1588683537565@mail.yahoo.com>
 <f92498d8-5156-0294-0ff7-cd222bfd6497@treenet.co.nz>
 <1284055797.1180517.1588697255715@mail.yahoo.com>
 <6520d592-915c-93e0-d228-d2aa92df1822@treenet.co.nz>
 <1505284137.157995.1588760454986@mail.yahoo.com>
Message-ID: <ebe6e9ba-1ec5-61bc-41c8-ce77f19da8a3@treenet.co.nz>

On 6/05/20 10:20 pm, Arjun K wrote:
> Hi Amos
> 
> Could you please share a sample configuration file containing allow and
> deny sites defined in a text file so that I can put the same format with
> my acls and validate in my environment.
> 

I did in my earlier post. If you want more search the wiki for
"dstdomain" - it is used in a lot of examples.



> With respect to denylist format, can you let me know which format I
> should use for blocking in dstdomain
> 
> .<website>.com? ? ?(or)?
> www.website.com <http://www.website.com>? (or )
> *. <website.com>?
> 

If you are to manage Squid without someone else doing your work for you
every time, then you need to understand the config syntax.

The only think I can add that has not already been written is that you
consider the question:
  Have you ever seen a URL with "*" in the domain name?


Amos


From squid3 at treenet.co.nz  Thu May  7 00:10:49 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 May 2020 12:10:49 +1200
Subject: [squid-users] Encrypt CONNECT Header
In-Reply-To: <20200506151803.GF26685@fantomas.sk>
References: <CANqqF0pgVy496QoEJAbCbPKLyz4XaSy_Y_CKAsUTw0-mZoaiWg@mail.gmail.com>
 <e3dbcfb1-4e93-466e-e8d9-dc3b74d5093f@measurement-factory.com>
 <CANqqF0qG_VfYfiSW3Z5tWZP9NyxORZxNZX4tQ1vnC_uSXwQ7gg@mail.gmail.com>
 <20200506151803.GF26685@fantomas.sk>
Message-ID: <f6e74c0e-6a61-6cee-a56f-519c7c6cedb7@treenet.co.nz>

Alex has already covered the main point for your issue. The below are
details I think it worth you spending some time on in addition to the
encryption.


On 7/05/20 3:18 am, Matus UHLAR - fantomas wrote:
> On 05.05.20 17:29, Ryan Le wrote:
>> Proxy-Authorization is of concern here. Most modern browsers now support
>> PAC with HTTPS versus PROXY.
> 

It sounds like you know something about the browser support. If you have
any more information than we document at
<https://wiki.squid-cache.org/Features/HTTPS#Encrypted_browser-Squid_connection>
please mention it.

> 
>> The Proxy-Authorization can carry the Basic Auth (and NTLM) credentials
>> which is of concern currently since all users are mobile.

Only if the proxy explicitly requests those credentials. It is highly
recommended that you upgrade any insecure authentication protocols
regardless of whether TLS is used.

NTLM is the worst auth scheme and has been superseded by Kerberos
decades ago. Please at least upgrade that.


Amos


From squid3 at treenet.co.nz  Thu May  7 03:52:45 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 May 2020 15:52:45 +1200
Subject: [squid-users] Problem with Debugging Useragent
In-Reply-To: <AB0CD787-5DD4-4539-B927-CAE9ECD3E3F8@gmail.com>
References: <AB0CD787-5DD4-4539-B927-CAE9ECD3E3F8@gmail.com>
Message-ID: <70aef093-4e13-cd71-dc27-a78143f46e10@treenet.co.nz>

On 7/05/20 4:11 am, Ahmad Alzaeem wrote:
> Hello Floks ,
> 
> 
> We have squid 4.x
> 
> We need to debug the user agents being  sent from our local network .
> 
> We added :
> logformat useragent  %>a [%tl] "%{User-Agent}>h"
> access_log stdio:/var/log/squid/${service_name}-useragent.log useragent
> 

The only thing wrong with that config is that the "useragent" is a
built-in logformat name. Do not re-define it.

If you want any differences to the built-in, use a different name for
your custom format.


> 
> But out logs only logs as below :
> 
> 
> 12.14.49.200 [06/May/2020:12:09:56 -0400] "-"
...
> 
> It seems to be ?-?   , Not the useragent we suppose to see .
> 

What makes you think those transactions have User-Agent headers?
The '-' means no such header present.


> 
> How can we let squid debug the incoming user agent and the outgoing user agent what go out  to the website ?
> 

You can try this to see what the headers actually contain.

  logformat ualog  %>a [%tl] "%{User-Agent}>h" "%>h"
  access_log stdio:/var/log/squid/${service_name}-useragent.log ualog

If the string with full headers contain 'User-Agent:' when "-" is
displayed first there is a bug, otherwise it is just your expectation
being incorrect.

Amos


From osantosmyr at gmail.com  Thu May  7 07:44:38 2020
From: osantosmyr at gmail.com (russel0901)
Date: Thu, 7 May 2020 02:44:38 -0500 (CDT)
Subject: [squid-users] Squid - Can't visit (government site and Banking
 Site) - Please help
In-Reply-To: <5741c5aa-27cc-6e46-942f-62cf7cb6d058@treenet.co.nz>
References: <1587762543811-0.post@n4.nabble.com>
 <f2e77210-801a-d043-f007-4d97ca95c318@treenet.co.nz>
 <1587906880308-0.post@n4.nabble.com> <20200426163320.GA21705@fantomas.sk>
 <1587990661078-0.post@n4.nabble.com> <20200427131204.GA19023@fantomas.sk>
 <1588000625812-0.post@n4.nabble.com> <20200428125914.GC16296@fantomas.sk>
 <1588085797128-0.post@n4.nabble.com>
 <5741c5aa-27cc-6e46-942f-62cf7cb6d058@treenet.co.nz>
Message-ID: <1588837478027-0.post@n4.nabble.com>

Hi,

I already resolved my problem....


my problem is on PATH MTU discovery....

may eth0 is set to have a MTU = 1500

and I read on another forums that he set the MTU to 1400.. and it works...

Thank you all for the comments, advise and suggestion, really helpful.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Thu May  7 07:58:52 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 May 2020 19:58:52 +1200
Subject: [squid-users] Squid - Can't visit (government site and Banking
 Site) - Please help
In-Reply-To: <1588837478027-0.post@n4.nabble.com>
References: <1587762543811-0.post@n4.nabble.com>
 <f2e77210-801a-d043-f007-4d97ca95c318@treenet.co.nz>
 <1587906880308-0.post@n4.nabble.com> <20200426163320.GA21705@fantomas.sk>
 <1587990661078-0.post@n4.nabble.com> <20200427131204.GA19023@fantomas.sk>
 <1588000625812-0.post@n4.nabble.com> <20200428125914.GC16296@fantomas.sk>
 <1588085797128-0.post@n4.nabble.com>
 <5741c5aa-27cc-6e46-942f-62cf7cb6d058@treenet.co.nz>
 <1588837478027-0.post@n4.nabble.com>
Message-ID: <5594d2f5-310b-d6f4-c0b5-284be080186e@treenet.co.nz>

On 7/05/20 7:44 pm, russel0901 wrote:
> Hi,
> 
> I already resolved my problem....
> 
> 
> my problem is on PATH MTU discovery....
> 
> may eth0 is set to have a MTU = 1500
> 
> and I read on another forums that he set the MTU to 1400.. and it works...
> 
> Thank you all for the comments, advise and suggestion, really helpful.
> 

I hope you at least understand the reason behind the change working?

Hint: IP encapsulation layers somewhere in the network(s). Probably
4-in-4 or 6-in-4 tunnels.


Cheers
Amos


From osantosmyr at gmail.com  Thu May  7 08:24:46 2020
From: osantosmyr at gmail.com (russel0901)
Date: Thu, 7 May 2020 03:24:46 -0500 (CDT)
Subject: [squid-users] Squid - Can't visit (government site and Banking
 Site) - Please help
In-Reply-To: <5594d2f5-310b-d6f4-c0b5-284be080186e@treenet.co.nz>
References: <1587906880308-0.post@n4.nabble.com>
 <20200426163320.GA21705@fantomas.sk> <1587990661078-0.post@n4.nabble.com>
 <20200427131204.GA19023@fantomas.sk> <1588000625812-0.post@n4.nabble.com>
 <20200428125914.GC16296@fantomas.sk> <1588085797128-0.post@n4.nabble.com>
 <5741c5aa-27cc-6e46-942f-62cf7cb6d058@treenet.co.nz>
 <1588837478027-0.post@n4.nabble.com>
 <5594d2f5-310b-d6f4-c0b5-284be080186e@treenet.co.nz>
Message-ID: <1588839886501-0.post@n4.nabble.com>

Hi,

Actually I didn't understand the problem but will take a look into it and
study it about that.....

IP encapsulation layers somewhere in the network(s). Probably
4-in-4 or 6-in-4 tunnels.




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From leomessi983 at yahoo.com  Sun May 10 18:58:03 2020
From: leomessi983 at yahoo.com (leomessi983 at yahoo.com)
Date: Sun, 10 May 2020 18:58:03 +0000 (UTC)
Subject: [squid-users] Terminate squid abnormally
References: <1582157051.1035599.1589137083526.ref@mail.yahoo.com>
Message-ID: <1582157051.1035599.1589137083526@mail.yahoo.com>

hi 
I have an intercepted squid proxy for HTTP and HTTPS requests in my network.
I use same DNS-Server on my clients and my squid server, but when my clients try to get HTTPS URLs they got error messages and can not open any URL.
Is there any configuration directive in squid to does not resolve requested URLs from client or use their resolved IP addresses?
In my squid server I got this error messages:


May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: Host header forgery detected on local=157.240.20.52:443 remote=172.30.28.38:52346 FD 524 flags=17 (local IP does not match any domain IP)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: on URL: web.whatsapp.com:443
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: Host header forgery detected on local=157.240.20.52:443 remote=172.30.28.38:52347 FD 508 flags=17 (local IP does not match any domain IP)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: on URL: web.whatsapp.com:443
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: Host header forgery detected on local=157.240.20.52:443 remote=172.30.31.31:51567 FD 508 flags=17 (local IP does not match any domain IP)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: on URL: web.whatsapp.com:443
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: Host header forgery detected on local=157.240.20.52:443 remote=172.30.31.31:51568 FD 508 flags=17 (local IP does not match any domain IP)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: on URL: web.whatsapp.com:443
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| ERROR: negotiating TLS on FD 523: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| Error negotiating SSL connection on FD 518: error:00000001:lib(0):func(0):reason(1) (1/0)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| ERROR: negotiating TLS on FD 502: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| Error negotiating SSL connection on FD 509: error:00000001:lib(0):func(0):reason(1) (1/0)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| ERROR: negotiating TLS on FD 527: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| Error negotiating SSL connection on FD 526: error:00000001:lib(0):func(0):reason(1) (1/0)
May 10 12:47:55 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:55| SECURITY ALERT: Host header forgery detected on local=17.57.12.11:443 remote=172.30.14.50:11985 FD 510 flags=17 (local IP does not match any domain IP)
May 10 12:47:55 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:55| SECURITY ALERT: on URL: gsp64-ssl.ls.apple.com:443
May 10 12:47:55 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:55| SECURITY ALERT: Host header forgery detected on local=17.57.12.11:443 remote=172.30.14.50:11986 FD 510 flags=17 (local IP does not match any domain IP)
May 10 12:47:55 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:55| SECURITY ALERT: on URL: gsp64-ssl.ls.apple.com:443
May 10 12:47:55 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:55| SECURITY ALERT: Host header forgery detected on local=17.57.12.11:443 remote=172.30.14.50:12069 FD 510 flags=17 (local IP does not match any domain IP)
May 10 12:47:55 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:55| SECURITY ALERT: on URL: gsp64-ssl.ls.apple.com:443
May 10 12:47:56 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:56| SECURITY ALERT: Host header forgery detected on local=193.23.244.244:443 remote=217.11.23.195:59994 FD 534 flags=17 (local IP does not match any domain IP)
May 10 12:47:56 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:56| SECURITY ALERT: on URL: www.h7ftf4spvav27.com:443
May 10 12:47:57 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:57| ERROR: negotiating TLS on FD 523: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)
May 10 12:47:57 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:57| Error negotiating SSL connection on FD 260: error:00000001:lib(0):func(0):reason(1) (1/0)
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Preparing for shutdown after 1786 requests
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Waiting 5 seconds for active connections to finish
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Closing HTTP(S) port 0.0.0.0:3128
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Closing HTTP(S) port 0.0.0.0:3129
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Closing HTTP(S) port 0.0.0.0:3130
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| WARNING: /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB #Hlpr3 exited
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Too few /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB processes are running (need 1/10)
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Starting new helpers
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| helperOpenServers: Starting 1/10 'security_file_certgen' processes
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| WARNING: /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB #Hlpr4 exited
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Too few /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB processes are running (need 1/10)
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| storeDirWriteCleanLogs: Starting...
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58|   Finished.  Wrote 0 entries.
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58|   Took 0.00 seconds (  0.00 entries/sec).
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| FATAL: The /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB helpers are crashing too rapidly, need help!
May 10 12:47:58 squid[] [user:alert:09]: FATAL: The /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB helpers are crashing too rapidly, need help!
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Squid Cache (Version 4.7): Terminated abnormally.
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Removing PID file (/var/run/squid.pid)


From arignacio80 at gmail.com  Sun May 10 20:26:44 2020
From: arignacio80 at gmail.com (Allan Raymond Ignacio)
Date: Sun, 10 May 2020 15:26:44 -0500
Subject: [squid-users] (SQUID 4.11) SSl_bump Fails on IOS and Android devices
Message-ID: <CAEOOCCW5TBc4SnwfefhoCy1DHyzSLB9QEWo-vCyHONxmXLkFRw@mail.gmail.com>

I have compiled and installed SQUID_4.11-3 with SSL, CRTD on debian10 and
here is my configuration -


##### SQUID.CONF  SNAPSHOT (START) ######


# Manual connection on 3128

http_port 3128


# Standard intercept

http_port 3129 intercept


# intercept & bump SSL connections

https_port 3130 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl/squid-ca-cert-key.pem
dhparams=/usr/local/etc/squid/certs/dhparam.pem


sslcrtd_children 5


tls_outgoing_options cafile=/etc/ssl/certs/ca-certificates.crt

tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE


acl foreignProtocol squid_error ERR_PROTOCOL_UNKNOWN ERR_TOO_BIG

acl serverTalksFirstProtocol squid_error ERR_REQUEST_START_TIMEOUT

on_unsupported_protocol tunnel foreignProtocol

on_unsupported_protocol tunnel serverTalksFirstProtocol

on_unsupported_protocol tunnel all


acl step1 at_step SslBump1

acl step2 at_step SslBump2

acl step3 at_step SslBump3


#acl noBumpSites ssl::server_name_regex -i "/etc/squid/url.nobump"

acl noBumpSites ssl::server_name .app.seesaw.me .schoology.com .dropbox.com

ssl_bump peek step1 all

ssl_bump peek step2 noBumpSites

ssl_bump splice step3 noBumpSites

ssl_bump stare step2

ssl_bump bump step3


##### CONFIG SNAPSHOT (END) ######


I created the certificates by doing the following -


openssl dhparam -outform PEM -out dhparam.pem 2048


openssl req -new -newkey rsa:2048 -sha256 -days 365 -nodes -x509
-extensions v3_ca -keyout squid-ca-key.pem -out squid-ca-cert.pem


cat squid-ca-cert.pem squid-ca-key.pem >> squid-ca-cert-key.pem


chown proxy:proxy /etc/squid/ssl/dhparam.pem

chown proxy:proxy /etc/squid/ssl/squid-ca-key.pem


chmod 400 dhparam.pem

chmod 400 squid-ca-key.pem


/usr/lib/squid/security_file_certgen -c -s /var/spool/squid/ssl_db -M 4MB


chown -R proxy:proxy /etc/squid/ssl


chown -R proxy:proxy /var/spool/squid/ssl_db


openssl x509 -hash -fingerprint -noout -in
/etc/ssl/certs/ca-certificates.crt


### for my firewall, I issued this


iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE

iptables -A FORWARD -s 192.168.10.0/24 -j ACCEPT

iptables -A INPUT -j ACCEPT -p tcp --dport 3128 -m comment --comment "squid
http proxy"

iptables -A INPUT -j ACCEPT -p tcp --dport 3129 -m comment --comment "squid
http proxy (intercept)"

iptables -A INPUT -j ACCEPT -p tcp --dport 3130 -m comment --comment "squid
https proxy (intercept"

iptables -t nat -A PREROUTING -m iprange --src-range
192.168.10.8-192.168.10.30 -p tcp --dport 80 -m comment --comment
"transparent http proxy" -j DNAT --to-destination 192.168.10.8:3129

iptables -t nat -A PREROUTING -m iprange --src-range
192.168.10.8-192.168.10.30 -p tcp --dport 443 -m comment --comment
"transparent https proxy" -j DNAT --to-destination 192.168.10.8:3130


### I can browse https on laptops BUT when I used IOS devices or android, I
get errors with this -


1589083941.053      1 192.168.10.15 NONE_ABORTED/200 0 CONNECT
157.240.18.35:443 - HIER_NONE/- -

1589083941.072      4 192.168.10.10 NONE_ABORTED/200 0 CONNECT
52.94.224.113:443 - HIER_NONE/- -

1589083941.205      5 192.168.10.10 NONE_ABORTED/200 0 CONNECT
52.94.224.113:443 - HIER_NONE/- -

1589083941.860     32 192.168.10.10 NONE_ABORTED/200 0 CONNECT
52.94.232.0:443 - HIER_NONE/- -

1589083941.862      4 192.168.10.10 NONE_ABORTED/200 0 CONNECT
54.239.27.116:443 - HIER_NONE/- -

1589083941.864     38 192.168.10.10 NONE_ABORTED/200 0 CONNECT
52.94.224.113:443 - HIER_NONE/- -

1589083941.983      5 192.168.10.10 NONE_ABORTED/200 0 CONNECT
52.94.224.113:443 - HIER_NONE/- -

1589083942.642     20 192.168.10.10 NONE_ABORTED/200 0 CONNECT
54.239.27.116:443 - HIER_NONE/- -

1589083942.645     48 192.168.10.10 NONE_ABORTED/200 0 CONNECT
52.94.224.113:443 - HIER_NONE/- -


What am I doing it wrong? I read everything about ssl bump, etc. with these
links

- https://wiki.squid-cache.org/Features/SslPeekAndSplice

- https://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

-
http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-4-6-Transparent-HTTP-amp-HTTPS-Proxy-td4687578.html


If anyone can point to me what's wrong with my squid.conf configuration or
can provide me with a working squid.conf for ssl_bump, I will be indebted
to you.


Thanks.



Jeremy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200510/3b85b4f0/attachment.htm>

From robertkwild at gmail.com  Sun May 10 23:00:58 2020
From: robertkwild at gmail.com (robert k Wild)
Date: Mon, 11 May 2020 00:00:58 +0100
Subject: [squid-users] deny extensions not working for some https
Message-ID: <CAGU_Ci+Ng84Sw8mDYVQdYZ3qxfPfGCpUORJ8KmNSbqGT8vknMg@mail.gmail.com>

so i have made this

#deny extension types
acl exttype urlpath_regex -i "/usr/local/squid/etc/extdeny.txt"
http_access deny exttype

/usr/local/squid/etc/extdeny.txt

\.exe(\?.*)?$
\.msi(\?.*)?$
\.msu(\?.*)?$
\.zip(\?.*)?$
\.iso(\?.*)?$

the majority of websites it works, like 7zip, anydesk, teamviewer etc etc

but when i go on this link below it downloads it and i dont know why

https://www.microsoft.com/en-us/download/confirmation.aspx?id=5842

thanks,
rob


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200511/ea66649d/attachment.htm>

From squid3 at treenet.co.nz  Mon May 11 00:04:35 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 11 May 2020 12:04:35 +1200
Subject: [squid-users] deny extensions not working for some https
In-Reply-To: <CAGU_Ci+Ng84Sw8mDYVQdYZ3qxfPfGCpUORJ8KmNSbqGT8vknMg@mail.gmail.com>
References: <CAGU_Ci+Ng84Sw8mDYVQdYZ3qxfPfGCpUORJ8KmNSbqGT8vknMg@mail.gmail.com>
Message-ID: <901ddfd3-a587-a23d-c4be-104692ecbe56@treenet.co.nz>

On 11/05/20 11:00 am, robert k Wild wrote:
> so i have made this
> 
> #deny extension types
> acl exttype urlpath_regex -i "/usr/local/squid/etc/extdeny.txt"
> http_access deny exttype
> 
> /usr/local/squid/etc/extdeny.txt
> 
> \.exe(\?.*)?$
> \.msi(\?.*)?$
> \.msu(\?.*)?$
> \.zip(\?.*)?$
> \.iso(\?.*)?$
> 
> the majority of websites it works, like 7zip, anydesk, teamviewer etc etc
> 
> but when i go on this link below it downloads it and i dont know why
> 
> https://www.microsoft.com/en-us/download/confirmation.aspx?id=5842
> 


Because that URL does not contain any of the forbidden "file type" strings.


Amos


From robertkwild at gmail.com  Mon May 11 00:17:15 2020
From: robertkwild at gmail.com (robert k Wild)
Date: Mon, 11 May 2020 01:17:15 +0100
Subject: [squid-users] deny extensions not working for some https
In-Reply-To: <901ddfd3-a587-a23d-c4be-104692ecbe56@treenet.co.nz>
References: <CAGU_Ci+Ng84Sw8mDYVQdYZ3qxfPfGCpUORJ8KmNSbqGT8vknMg@mail.gmail.com>
 <901ddfd3-a587-a23d-c4be-104692ecbe56@treenet.co.nz>
Message-ID: <CAGU_Ci+7Nvo4qX2zHKcxzEnL03jmmYu-cEg9J=fC1E2uDLtn=w@mail.gmail.com>

It ends in an iso extension tho or am I wrong?

On Mon, 11 May 2020, 01:06 Amos Jeffries, <squid3 at treenet.co.nz> wrote:

> On 11/05/20 11:00 am, robert k Wild wrote:
> > so i have made this
> >
> > #deny extension types
> > acl exttype urlpath_regex -i "/usr/local/squid/etc/extdeny.txt"
> > http_access deny exttype
> >
> > /usr/local/squid/etc/extdeny.txt
> >
> > \.exe(\?.*)?$
> > \.msi(\?.*)?$
> > \.msu(\?.*)?$
> > \.zip(\?.*)?$
> > \.iso(\?.*)?$
> >
> > the majority of websites it works, like 7zip, anydesk, teamviewer etc etc
> >
> > but when i go on this link below it downloads it and i dont know why
> >
> > https://www.microsoft.com/en-us/download/confirmation.aspx?id=5842
> >
>
>
> Because that URL does not contain any of the forbidden "file type" strings.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200511/48446b9c/attachment.htm>

From robertkwild at gmail.com  Mon May 11 00:21:32 2020
From: robertkwild at gmail.com (robert k Wild)
Date: Mon, 11 May 2020 01:21:32 +0100
Subject: [squid-users] deny extensions not working for some https
In-Reply-To: <CAGU_Ci+7Nvo4qX2zHKcxzEnL03jmmYu-cEg9J=fC1E2uDLtn=w@mail.gmail.com>
References: <CAGU_Ci+Ng84Sw8mDYVQdYZ3qxfPfGCpUORJ8KmNSbqGT8vknMg@mail.gmail.com>
 <901ddfd3-a587-a23d-c4be-104692ecbe56@treenet.co.nz>
 <CAGU_Ci+7Nvo4qX2zHKcxzEnL03jmmYu-cEg9J=fC1E2uDLtn=w@mail.gmail.com>
Message-ID: <CAGU_CiLVOD65v-fL90P=C5ffZwe5pdq_k_7bd6TR=CL5L=2+JQ@mail.gmail.com>

Sorry I mean when you click that url link it downloads an iso file

Your right that url link ends with

id=5842


On Mon, 11 May 2020, 01:17 robert k Wild, <robertkwild at gmail.com> wrote:

> It ends in an iso extension tho or am I wrong?
>
> On Mon, 11 May 2020, 01:06 Amos Jeffries, <squid3 at treenet.co.nz> wrote:
>
>> On 11/05/20 11:00 am, robert k Wild wrote:
>> > so i have made this
>> >
>> > #deny extension types
>> > acl exttype urlpath_regex -i "/usr/local/squid/etc/extdeny.txt"
>> > http_access deny exttype
>> >
>> > /usr/local/squid/etc/extdeny.txt
>> >
>> > \.exe(\?.*)?$
>> > \.msi(\?.*)?$
>> > \.msu(\?.*)?$
>> > \.zip(\?.*)?$
>> > \.iso(\?.*)?$
>> >
>> > the majority of websites it works, like 7zip, anydesk, teamviewer etc
>> etc
>> >
>> > but when i go on this link below it downloads it and i dont know why
>> >
>> > https://www.microsoft.com/en-us/download/confirmation.aspx?id=5842
>> >
>>
>>
>> Because that URL does not contain any of the forbidden "file type"
>> strings.
>>
>>
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200511/be90e750/attachment.htm>

From squid3 at treenet.co.nz  Mon May 11 00:44:43 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 11 May 2020 12:44:43 +1200
Subject: [squid-users] deny extensions not working for some https
In-Reply-To: <CAGU_CiLVOD65v-fL90P=C5ffZwe5pdq_k_7bd6TR=CL5L=2+JQ@mail.gmail.com>
References: <CAGU_Ci+Ng84Sw8mDYVQdYZ3qxfPfGCpUORJ8KmNSbqGT8vknMg@mail.gmail.com>
 <901ddfd3-a587-a23d-c4be-104692ecbe56@treenet.co.nz>
 <CAGU_Ci+7Nvo4qX2zHKcxzEnL03jmmYu-cEg9J=fC1E2uDLtn=w@mail.gmail.com>
 <CAGU_CiLVOD65v-fL90P=C5ffZwe5pdq_k_7bd6TR=CL5L=2+JQ@mail.gmail.com>
Message-ID: <5ab2db52-22c8-ca30-a7d2-4bd8056d8787@treenet.co.nz>

On 11/05/20 12:21 pm, robert k Wild wrote:
> Sorry I mean when you click that url link it downloads an iso file
> 
> Your right that url link ends with
> 
> id=5842
> 

Actually that is ".aspx" - the pattern I gave you ignores the query-string.

There is actually no relationship between file type and URL - it is an
illusion from some sites design. This is why the Content-Type response
header *also* has to be checked.

Amos


From squid3 at treenet.co.nz  Mon May 11 00:59:01 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 11 May 2020 12:59:01 +1200
Subject: [squid-users] (SQUID 4.11) SSl_bump Fails on IOS and Android
 devices
In-Reply-To: <CAEOOCCW5TBc4SnwfefhoCy1DHyzSLB9QEWo-vCyHONxmXLkFRw@mail.gmail.com>
References: <CAEOOCCW5TBc4SnwfefhoCy1DHyzSLB9QEWo-vCyHONxmXLkFRw@mail.gmail.com>
Message-ID: <d42cf8d3-3add-b077-7c2d-f17b9887e46a@treenet.co.nz>

On 11/05/20 8:26 am, Allan Raymond Ignacio wrote:
> I have compiled and installed SQUID_4.11-3 with SSL, CRTD on debian10
> and here is my configuration -?
> 
> 
...
> 
> ### I can browse https on laptops BUT when I used IOS devices or
> android, I get errors with this -
> 
> 
> 1589083941.053? ? ? 1 192.168.10.15 NONE_ABORTED/200 0 CONNECT
> 157.240.18.35:443 <http://157.240.18.35:443> - HIER_NONE/- -
> 

The client is disconnecting during the TLS handshake. Worth looking into
the TLS traffic to see what is going on, but expect good chances that
cert pinning or TLS/1.3 is being used here.


> 
> If anyone can point to me what's wrong with my squid.conf configuration
> or can provide me with a working squid.conf for ssl_bump, I will be
> indebted to you.?
> 

Looks like a reasonable config to me.

An always-working config is not possible at this time. TLS is still a
volatile environment and the SSL-Bump features constantly undergoing
improvements. Which some of its behaviours are gaining stability, the
SSL-Bump feature overall is still experimental.

Amos


From arignacio80 at gmail.com  Mon May 11 01:27:39 2020
From: arignacio80 at gmail.com (Allan Raymond Ignacio)
Date: Sun, 10 May 2020 20:27:39 -0500
Subject: [squid-users] (SQUID 4.11) SSl_bump Fails on IOS and Android
	devices
In-Reply-To: <d42cf8d3-3add-b077-7c2d-f17b9887e46a@treenet.co.nz>
References: <CAEOOCCW5TBc4SnwfefhoCy1DHyzSLB9QEWo-vCyHONxmXLkFRw@mail.gmail.com>
 <d42cf8d3-3add-b077-7c2d-f17b9887e46a@treenet.co.nz>
Message-ID: <CAEOOCCWvCq34f6VNjq5QeZ1u7=qQfudy-6tmmJ_bhVN8Y02BHg@mail.gmail.com>

Any other suggestions besides TLS cause i need to have this running for my
kids' home schooling as they rely on their ipads (schoology and seesaw)?

On Sun, May 10, 2020, 8:00 PM Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 11/05/20 8:26 am, Allan Raymond Ignacio wrote:
> > I have compiled and installed SQUID_4.11-3 with SSL, CRTD on debian10
> > and here is my configuration -
> >
> >
> ...
> >
> > ### I can browse https on laptops BUT when I used IOS devices or
> > android, I get errors with this -
> >
> >
> > 1589083941.053      1 192.168.10.15 NONE_ABORTED/200 0 CONNECT
> > 157.240.18.35:443 <http://157.240.18.35:443> - HIER_NONE/- -
> >
>
> The client is disconnecting during the TLS handshake. Worth looking into
> the TLS traffic to see what is going on, but expect good chances that
> cert pinning or TLS/1.3 is being used here.
>
>
> >
> > If anyone can point to me what's wrong with my squid.conf configuration
> > or can provide me with a working squid.conf for ssl_bump, I will be
> > indebted to you.
> >
>
> Looks like a reasonable config to me.
>
> An always-working config is not possible at this time. TLS is still a
> volatile environment and the SSL-Bump features constantly undergoing
> improvements. Which some of its behaviours are gaining stability, the
> SSL-Bump feature overall is still experimental.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200510/b9899917/attachment.htm>

From rafael.akchurin at diladele.com  Mon May 11 07:23:26 2020
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Mon, 11 May 2020 07:23:26 +0000
Subject: [squid-users] [icap] Web Safety 7.4 web filter for Squid proxy is
	available
Message-ID: <AM0PR04MB4753CDBE0A39BD22485C84148FA10@AM0PR04MB4753.eurprd04.prod.outlook.com>

Greetings everyone,

Web Safety 7.4 - ICAP web filter for Squid proxy and Admin UI for Squid Proxy is now available for production use. The following changes and improvements are included into this build.

  *   Added ability to limit bandwidth usage per policy (bandwidth throttling is implemented using Squid's delay pool configuration parameters). See this documentation article<https://docs.diladele.com/administrator_guide_stable/web_filter/policies/bandwidth_limitation.html>.
  *   Statistics storage optimized, the daily CSV files are packed as GZ files, reducing the storage requirements up to 10 times.
  *   Fixed an issue with cluster traffic log uploads from more than two cluster nodes.
  *   Fixed issues with rotating of Web Safety logs.
  *   Added support for Squid 4.11 on Ubuntu 18/Debian 10.
  *   Virtual appliance generation infrastructure moved to VMware ESXi 6.7 so some unknown issues might occur on older VMware vSphere/ESXi deployments.

Download Links

  *   Virtual appliance for VMware ESXi/vSphere<http://packages.diladele.com/websafety-va/7.4/websafety.zip>
  *   Virtual appliance for Microsoft Hyper-V<http://packages.diladele.com/websafety-va/7.4/websafety-hyperv.zip>
  *   The Microsoft Azure and Amazon AWS images are being published now so check the download page<https://www.diladele.com/download.html> later in a week.
If you find bugs or issues with this new build (especially bandwidth limitation code) be sure to create an issue<https://github.com/diladele/websafety/issues/new> at our GitHub repository.

Thanks to all of you for making this possible.
Stay safe.

Best regards,
Rafael Akchurin
Diladele B.V.


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200511/cb49af6d/attachment.htm>

From leomessi983 at yahoo.com  Mon May 11 08:57:15 2020
From: leomessi983 at yahoo.com (leomessi983 at yahoo.com)
Date: Mon, 11 May 2020 08:57:15 +0000 (UTC)
Subject: [squid-users] SQUID PROBLEM WITH SITES THAT HAVE MORE THAN ONE IP
	ADDRESSES
References: <1673148591.1232288.1589187435213.ref@mail.yahoo.com>
Message-ID: <1673148591.1232288.1589187435213@mail.yahoo.com>

HICOULD YOU PLEASE HELP ME? 
IN INTERCEPTED TOPOLOGY WITH TPROXY I HAVE PROBLEM.
WHAT IS SQUID SOLUTION FOR SITES THAT HAVE MORE THAN ONE IP ADDRESSES? FOR EXAMPLE SITE LIKE GOOGLE.COM RETURN DIFFERENT IP ADDRESS IN EVERY REQUEST AND IF CLIENT GET IP ADDRESS FOR EXAMPLE 1.1.1.1 THAT IS POSSIBLE THAT SQUID GET 2.2.2.2 FOR GOOGLE AND SQUID CAN NOT WORK PROBABLE AND SHOW FORGERY DETECTED ERROR.
IS THERE ANY WAY TO IGNORE THIS OR USE ONLY ONE DNS SERVER OR PREVENT SQUID OR CLIENT TO NOT RESOLVE URLS?
I use same DNS-Server on my clients and my squid server.
Is there any configuration directive in squid to does not resolve requested URLs from client or use their resolved IP addresses?
I use this configuration:
acl acl1 clientside_mark *****tcp_outgoing_mark ***** acl1acl https1 ssl::server_name "/Files/blklist"
ssl_bump bump https1 acl1acl url1 dstdomain "/Files/blklist"
acl Regex1 url_regex "/Files/Reglist"
http_access deny Regex1 acl1http_access deny url1 acl1

#Http configurations
http_access allow all
http_port 0.0.0.0:3128
http_port 0.0.0.0:3129 tproxy disable-pmtu-discovery=transparent


#Https configurations
reply_header_access Strict-Transport-Security deny all
https_port 3130 tproxy ssl-bump \
??????? tls-cert=/conf/cert.cer \
??????? tls-key=/conf/cert.key \
??????? generate-host-certificates=on dynamic_cert_mem_cache_size=20MB disable-pmtu-discovery=transparent
sslcrtd_program /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB
sslcrtd_children 10 startup=5 idle=1
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump splice all

I got this error messeges:
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: Host header forgery detected on local=157.240.20.52:443 remote=172.30.28.38:52346 FD 524 flags=17 (local IP does not match any domain IP)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: on URL: web.whatsapp.com:443
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: Host header forgery detected on local=157.240.20.52:443 remote=172.30.28.38:52347 FD 508 flags=17 (local IP does not match any domain IP)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: on URL: web.whatsapp.com:443
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: Host header forgery detected on local=157.240.20.52:443 remote=172.30.31.31:51567 FD 508 flags=17 (local IP does not match any domain IP)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: on URL: web.whatsapp.com:443
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: Host header forgery detected on local=157.240.20.52:443 remote=172.30.31.31:51568 FD 508 flags=17 (local IP does not match any domain IP)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| SECURITY ALERT: on URL: web.whatsapp.com:443
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| ERROR: negotiating TLS on FD 523: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| Error negotiating SSL connection on FD 518: error:00000001:lib(0):func(0):reason(1) (1/0)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| ERROR: negotiating TLS on FD 502: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| Error negotiating SSL connection on FD 509: error:00000001:lib(0):func(0):reason(1) (1/0)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| ERROR: negotiating TLS on FD 527: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)
May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| Error negotiating SSL connection on FD 526: error:00000001:lib(0):func(0):reason(1) (1/0)
May 10 12:47:55 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:55| SECURITY ALERT: Host header forgery detected on local=17.57.12.11:443 remote=172.30.14.50:11985 FD 510 flags=17 (local IP does not match any domain IP)
May 10 12:47:55 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:55| SECURITY ALERT: on URL: gsp64-ssl.ls.apple.com:443
May 10 12:47:55 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:55| SECURITY ALERT: Host header forgery detected on local=17.57.12.11:443 remote=172.30.14.50:11986 FD 510 flags=17 (local IP does not match any domain IP)
May 10 12:47:55 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:55| SECURITY ALERT: on URL: gsp64-ssl.ls.apple.com:443
May 10 12:47:55 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:55| SECURITY ALERT: Host header forgery detected on local=17.57.12.11:443 remote=172.30.14.50:12069 FD 510 flags=17 (local IP does not match any domain IP)
May 10 12:47:55 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:55| SECURITY ALERT: on URL: gsp64-ssl.ls.apple.com:443
May 10 12:47:56 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:56| SECURITY ALERT: Host header forgery detected on local=193.23.244.244:443 remote=217.11.23.195:59994 FD 534 flags=17 (local IP does not match any domain IP)
May 10 12:47:56 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:56| SECURITY ALERT: on URL: www.h7ftf4spvav27.com:443
May 10 12:47:57 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:57| ERROR: negotiating TLS on FD 523: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)
May 10 12:47:57 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:57| Error negotiating SSL connection on FD 260: error:00000001:lib(0):func(0):reason(1) (1/0)
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Preparing for shutdown after 1786 requests
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Waiting 5 seconds for active connections to finish
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Closing HTTP(S) port 0.0.0.0:3128
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Closing HTTP(S) port 0.0.0.0:3129
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Closing HTTP(S) port 0.0.0.0:3130
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| WARNING: /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB #Hlpr3 exited
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Too few /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB processes are running (need 1/10)
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Starting new helpers
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| helperOpenServers: Starting 1/10 'security_file_certgen' processes
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| WARNING: /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB #Hlpr4 exited
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Too few /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB processes are running (need 1/10)
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| storeDirWriteCleanLogs: Starting...
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58|   Finished.  Wrote 0 entries.
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58|   Took 0.00 seconds (  0.00 entries/sec).
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| FATAL: The /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB helpers are crashing too rapidly, need help!
May 10 12:47:58 squid[] [user:alert:09]: FATAL: The /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB helpers are crashing too rapidly, need help!
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Squid Cache (Version 4.7): Terminated abnormally.
May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Removing PID file (/var/run/squid.pid)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200511/acabf955/attachment.htm>

From squid3 at treenet.co.nz  Mon May 11 09:17:24 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 11 May 2020 21:17:24 +1200
Subject: [squid-users] SQUID PROBLEM WITH SITES THAT HAVE MORE THAN ONE
 IP ADDRESSES
In-Reply-To: <1673148591.1232288.1589187435213@mail.yahoo.com>
References: <1673148591.1232288.1589187435213.ref@mail.yahoo.com>
 <1673148591.1232288.1589187435213@mail.yahoo.com>
Message-ID: <20f4fe4b-972b-09d8-58ac-33ce62cb03fe@treenet.co.nz>

On 11/05/20 8:57 pm, leomessi983 at yahoo.com wrote:
> HI
> COULD YOU PLEASE HELP ME?

Please don't yell.

> IN INTERCEPTED TOPOLOGY WITH TPROXY I HAVE PROBLEM.
> 
> WHAT IS SQUID SOLUTION FOR SITES THAT HAVE MORE THAN ONE IP ADDRESSES?
> FOR EXAMPLE SITE LIKE GOOGLE.COM RETURN DIFFERENT IP ADDRESS IN EVERY
> REQUEST AND IF CLIENT GET IP ADDRESS FOR EXAMPLE 1.1.1.1 THAT IS
> POSSIBLE THAT SQUID GET 2.2.2.2 FOR GOOGLE AND SQUID CAN NOT WORK
> PROBABLE AND SHOW FORGERY DETECTED ERROR.
> 

Squid will still serve requests with Host header forgery issues. All
that will happen is Squid will not cache the response - so no other
clients get corrupted.


> IS THERE ANY WAY TO IGNORE THIS OR USE ONLY ONE DNS SERVER OR PREVENT
> SQUID OR CLIENT TO NOT RESOLVE URLS?


see <https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery>

Amos

> 
> I use same DNS-Server on my clients and my squid server.
> 
> Is there any configuration directive in squid to does not resolve requested URLs from client or use their resolved IP addresses?
> 
> 
> I use this configuration:
> 
> acl acl1 clientside_mark *****
> tcp_outgoing_mark ***** acl1
> acl https1 ssl::server_name "/Files/blklist"
> ssl_bump bump https1 acl1
> acl url1 dstdomain "/Files/blklist"
> acl Regex1 url_regex "/Files/Reglist"
> http_access deny Regex1 acl1
> http_access deny url1 acl1
> 
> 
> #Http configurations
> http_access allow all

Do not do that.


> http_port 0.0.0.0:3128
> http_port 0.0.0.0:3129 tproxy disable-pmtu-discovery=transparent
> 
> 
> #Https configurations
> reply_header_access Strict-Transport-Security deny all
> https_port 3130 tproxy ssl-bump \
> ??????? tls-cert=/conf/cert.cer \
> ??????? tls-key=/conf/cert.key \
> ??????? generate-host-certificates=on dynamic_cert_mem_cache_size=20MB
> disable-pmtu-discovery=transparent
> sslcrtd_program /usr/lib64/squid/security_file_certgen -s
> /var/lib/ssl_db -M 20MB
> sslcrtd_children 10 startup=5 idle=1
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump splice all
> 
> I got this error messeges:
> 
...
> May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| ERROR: negotiating TLS on FD 523: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)
> May 10 12:47:54 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:54| Error negotiating SSL connection on FD 518: error:00000001:lib(0):func(0):reason(1) (1/0)

So TLS is not working. This is your worst problem.

> May 10 12:47:58 squid[23231] [daemon:info:1e]: 2020/05/10 12:47:58| Squid Cache (Version 4.7): Terminated abnormally.

Please upgrade. Current v4 is 4.11.

You may want to consider upgrade to the latest v5 release for better
SSL-Bump behaviour.

Amos


From leomessi983 at yahoo.com  Mon May 11 09:53:15 2020
From: leomessi983 at yahoo.com (leomessi983 at yahoo.com)
Date: Mon, 11 May 2020 09:53:15 +0000 (UTC)
Subject: [squid-users] SQUID PROBLEM WITH SITES THAT HAVE MORE THAN ONE IP
	ADDRESSES
References: <2109068709.1256026.1589190795975.ref@mail.yahoo.com>
Message-ID: <2109068709.1256026.1589190795975@mail.yahoo.com>

Hi againthank you for your reply. 
sorry but I didn't yell only asked for help!
Is any way to disable security checks or disable host header forgery check in squid?If I use host_verify_strict or client_lifetime or client_dst_passthru , can I prevent this error to be happens?

you said TLS is not working, Is there any way to force TLS to work?

thanx again
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200511/f46273e9/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon May 11 10:08:43 2020
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 11 May 2020 12:08:43 +0200
Subject: [squid-users] SQUID PROBLEM WITH SITES THAT HAVE MORE THAN ONE
	IP ADDRESSES
In-Reply-To: <2109068709.1256026.1589190795975@mail.yahoo.com>
References: <2109068709.1256026.1589190795975.ref@mail.yahoo.com>
 <2109068709.1256026.1589190795975@mail.yahoo.com>
Message-ID: <202005111208.43594.Antony.Stone@squid.open.source.it>

On Monday 11 May 2020 at 11:53:15, leomessi983 at yahoo.com wrote:

> Hi againthank you for your reply.
> sorry but I didn't yell only asked for help!

Writing in all capital letters (see your Subject line, for example) in online 
communications is generally interpreted as shouting.


Regards,


Antony.

-- 
"I estimate there's a world market for about five computers."

 - Thomas J Watson, Chairman of IBM

                                                   Please reply to the list;
                                                         please don't CC me.


From uhlar at fantomas.sk  Mon May 11 13:01:38 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 11 May 2020 15:01:38 +0200
Subject: [squid-users] "intercepted port does not match 443"
Message-ID: <20200511130138.GC10458@fantomas.sk>

Hello,

we have intercepting squid on one router and these messages started appear
sometimes:

2020/05/11 13:41:23 kid1| SECURITY ALERT: Host header forgery detected on local=[XXX]:80 remote=192.168.1.224:1040 FD 69 flags=33 (intercepted port does not match 443)
2020/05/11 13:41:23 kid1| SECURITY ALERT: By user agent: Microsoft BITS/6.7
2020/05/11 13:41:23 kid1| SECURITY ALERT: on URL: armmf.adobe.com:443
2020/05/11 13:41:23 kid1| kick abandoning local=[XXX]:80 remote=192.168.1.224:1040 FD 69 flags=33

I am aware of possible interception issues but what exactly does this
message mean?  The original destination port is 80, why does squid complain
about it not being port 443?

the iptable rules:

Chain PREROUTING (policy ACCEPT 1759K packets, 217M bytes)
 pkts bytes target     prot opt in     out     source               destination
37068 1966K REDIRECT   tcp  --  lan0   *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80 redir ports 8888

thanks.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Windows 2000: 640 MB ought to be enough for anybody


From rousskov at measurement-factory.com  Mon May 11 16:28:08 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 11 May 2020 12:28:08 -0400
Subject: [squid-users] Terminate squid abnormally
In-Reply-To: <1582157051.1035599.1589137083526@mail.yahoo.com>
References: <1582157051.1035599.1589137083526.ref@mail.yahoo.com>
 <1582157051.1035599.1589137083526@mail.yahoo.com>
Message-ID: <46a4be29-72bc-0556-c32f-e9187aae4cc9@measurement-factory.com>

On 5/10/20 2:58 PM, leomessi983 at yahoo.com wrote:

> FATAL: The /usr/lib64/squid/security_file_certgen -s /var/lib/ssl_db -M 20MB helpers are crashing too rapidly, need help!

This fatal error needs your attention. Most likely, your certificate
generator cannot use its database, either because it was not initialized
or because the generator lacks permissions to access the database. Many
similar problems are triaged on this mailing list. You may want to
search for those emails.

Fixing this problem will not remove the "SECURITY ALERT" messages.


> Is there any configuration directive in squid to does not resolve
> requested URLs from client or use their resolved IP addresses?

There is not yet. It may be difficult to convince all the gatekeepers to
allow such directive(s), but it may possible to do so if Squid still
does not cache the response of the tainted transaction. If anybody wants
to make or sponsor the corresponding changes, I recommend starting with
posting an RFC on squid-dev.


Cheers,

Alex.


From patrick.chemla at performance-managers.com  Tue May 12 11:40:59 2020
From: patrick.chemla at performance-managers.com (Patrick Chemla)
Date: Tue, 12 May 2020 14:40:59 +0300
Subject: [squid-users] domains with accented international characters fail
	with Invalid URL
Message-ID: <f5604772-888f-96fb-ee13-a0437c0b72fb@performance-managers.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200512/78559a87/attachment.htm>

From david at articatech.com  Tue May 12 11:42:13 2020
From: david at articatech.com (David Touzeau)
Date: Tue, 12 May 2020 13:42:13 +0200
Subject: [squid-users] Squid 4.x acl server_cert_fingerprint for bump no
	matches
Message-ID: <78deb686-453b-a1a8-a396-b5d9adadc449@articatech.com>


Hi, i'm trying to play with acl "server_cert_fingerprint" for splicing 
websites.

First, get the fingerprint :

openssl s_client -host www.clubic.com -port 443 2> /dev/null | openssl 
x509 -fingerprint -noout


# Build the acl

acl TestFinger server_cert_fingerprint 
77:F6:8D:C1:0A:DF:94:8B:43:1F:8E:0E:91:5E:0C:32:42:8B:99:C9


#???? I want squid to not bump this fingerprint.

acl ssl_step1 at_step SslBump1
acl ssl_step2 at_step SslBump2
acl ssl_step3 at_step SslBump3
ssl_bump peek ssl_step1
ssl_bump splice TestFinger
ssl_bump stare ssl_step2 all
ssl_bump bump all

But browsing on the website still receive squid certificate and not the 
original one.
Seems TestFinger Acls did not matches in any case

Did i'm wrong somewhere ?


Regards.


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200512/058f2744/attachment.htm>

From patrick.chemla at performance-managers.com  Tue May 12 12:20:28 2020
From: patrick.chemla at performance-managers.com (Patrick Chemla)
Date: Tue, 12 May 2020 15:20:28 +0300
Subject: [squid-users] domains with accented international characters
 fail with Invalid URL
In-Reply-To: <f5604772-888f-96fb-ee13-a0437c0b72fb@performance-managers.com>
References: <f5604772-888f-96fb-ee13-a0437c0b72fb@performance-managers.com>
Message-ID: <c52deb6d-ef8a-decc-9f05-3997ef46c8f6@performance-managers.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200512/92790730/attachment.htm>

From squid3 at treenet.co.nz  Tue May 12 14:58:34 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 13 May 2020 02:58:34 +1200
Subject: [squid-users] domains with accented international characters
 fail with Invalid URL
In-Reply-To: <c52deb6d-ef8a-decc-9f05-3997ef46c8f6@performance-managers.com>
References: <f5604772-888f-96fb-ee13-a0437c0b72fb@performance-managers.com>
 <c52deb6d-ef8a-decc-9f05-3997ef46c8f6@performance-managers.com>
Message-ID: <b3693e7d-6eb0-d22e-faea-12de340ccbc4@treenet.co.nz>

On 13/05/20 12:20 am, Patrick Chemla wrote:
> Sorry for this, it seems it is not linked to accented characters. Other
> not accented domains don't work too.
> 


This is a huge clue in your log:

>>
>> *- 88.88.88.xx - - - [12/May/2020:08:05:43 +0200] "
>> @%F1%F4%EA%F8?%80%E6Q%EAWH%D5%04zEa)%B1%A7%C1%9B%AA - HTTP/1.1" 400
>> 3941 0 "-" "-" TAG_NONE:HIER_NONE


Whatever client is generating this traffic is not talking HTTP to the proxy.


Amos


From michal.bruncko at ssrk.sk  Wed May 13 13:44:31 2020
From: michal.bruncko at ssrk.sk (Michal Bruncko)
Date: Wed, 13 May 2020 15:44:31 +0200
Subject: [squid-users] Client IP PTR lookup on connect
Message-ID: <16d9af75-cb1b-7117-62a0-fcb4c6046f19@ssrk.sk>

Hello guys

following the original thread "[squid-users] Squid 4.9 Client IP PTR 
lookup on connect"

I am observing exactly same bahavour on 
squid-4.4-8.module_el8.1.0+197+0c39cdc8.x86_64 on CentOS 8.
Almost for each client connection to squid port 3128 is squid doing a 
client IP PTR resolution request. I am not using "srcdomain"-based ACLs 
nor icap_log setting.
Normally I wouldnt notice this, but today our proxy server get flooded 
by huge amount of requests (which were actually all denied on this 
proxy) coming from awesome nvidia control panel/tool (immediate 
connection request repeat after rejection from proxy) from newly 
deployed workstations and this flood of proxy requests caused another 
flood of DNS PTR lookups of randomized IPv6 client IPs which werent in 
reverse zones at all.
At first I was suspecting some squid module (auth helper 
(gssapi/ntlm/basic), URL rewriter) or syslog (which we use for sending 
access logs to remote server) but those DNS queries are coming directly 
from squid process (same as the one doing standard forward DNS lookups).

here is snip from strace of squid where you can see incoming connection 
from client and basically immediate DNS PTR lookup

accept(144, {sa_family=AF_INET6, sin6_port=htons(58574), 
inet_pton(AF_INET6, "2001:4118:804:f000::103", &sin6_addr), 
sin6_flowinfo=htonl(0), sin6_scope_id=0}, [28]) = 12
getsockname(12, {sa_family=AF_INET6, sin6_port=htons(3128), 
inet_pton(AF_INET6, "2001:4118:804:f000::200", &sin6_addr), 
sin6_flowinfo=htonl(0), sin6_scope_id=0}, [28]) = 0
fcntl(12, F_GETFD)????????????????????? = 0
fcntl(12, F_SETFD, FD_CLOEXEC)????????? = 0
fcntl(12, F_GETFL)????????????????????? = 0x2 (flags O_RDWR)
fcntl(12, F_SETFL, O_RDWR|O_NONBLOCK)?? = 0
sendto(10, 
"l\370\1\0\0\1\0\0\0\0\0\0\0013\0010\0011\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\1f\0014\0010\18\0010\18\0011\0011\0014\0011\0010\0010\0012\3ip6\4arpa\0\0\f\0\1", 
90, 0, {sa_family=AF_INET, sin_port=htons(53), 
sin_addr=inet_addr("10.20.10.18")}, 16) = 90
epoll_ctl(6, EPOLL_CTL_ADD, 12, {EPOLLIN|EPOLLERR|EPOLLHUP, {u32=12, 
u64=12}}) = 0
epoll_wait(6, [{EPOLLIN, {u32=12, u64=12}}], 4096, 987) = 1
read(12, "GET 
http://i5.c.eset.com:80/v1/auth/851A4855CEEAB5292C10/updlist/0/eid/7033368/lid/7033484 
HTTP/1.1\r\nHost: i5.c.eset.com:80\r\nCon"..., 4096) = 181
sendto(10, 
"\342|\1\0\0\1\0\0\0\0\0\0\0013\0010\0011\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\1f\0014\0010\18\0010\18\0011\0011\0014\0011\0010\0010\0012\3ip6\4arpa\0\0\f\0\1", 
90, 0, {sa_family=AF_INET, sin_port=htons(53), 
sin_addr=inet_addr("10.20.10.18")}, 16) = 90
epoll_ctl(6, EPOLL_CTL_MOD, 16, {EPOLLIN|EPOLLOUT|EPOLLERR|EPOLLHUP, 
{u32=16, u64=16}}) = 0
epoll_wait(6, [{EPOLLOUT, {u32=16, u64=16}}], 4096, 972) = 1
write(16, 
"http://i5.c.eset.com/v1/auth/851A4855CEEAB5292C10/updlist/0/eid/7033368/lid/7033484 
2001:4118:804:f000::103/2001:4118:804:f000::"..., 179) = 179
epoll_wait(6, [{EPOLLIN|EPOLLOUT, {u32=16, u64=16}}], 4096, 970) = 1
read(16, "\n", 32767)?????????????????? = 1
epoll_ctl(6, EPOLL_CTL_MOD, 16, {EPOLLIN|EPOLLERR|EPOLLHUP, {u32=16, 
u64=16}}) = 0
sendto(10, "!6\1\0\0\1\0\0\0\0\0\0\2i5\1c\4eset\3com\0\0\1\0\1", 31, 0, 
{sa_family=AF_INET, sin_port=htons(53), 
sin_addr=inet_addr("10.20.10.18")}, 16) = 31
sendto(10, "\367$\1\0\0\1\0\0\0\0\0\0\2i5\1c\4eset\3com\0\0\34\0\1", 31, 
0, {sa_family=AF_INET, sin_port=htons(53), 
sin_addr=inet_addr("10.20.10.18")}, 16) = 31
epoll_wait(6, [{EPOLLIN, {u32=10, u64=10}}], 4096, 970) = 1
recvfrom(10, 
"l\370\205\200\0\1\0\1\0\0\0\0\0013\0010\0011\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\1f\0014\0010\18\0010\18\0011\0011\0014\0011\0010\0010\0012\3ip6\4arpa\0\0\f\0\1\300\f\0\f\0\1\0\0\4\260\0\23\6server\2ad\4example\2sk\0", 
16384, 0, {sa_family=AF_INET, sin_port=htons(53), 
sin_addr=inet_addr("10.20.10.18")}, [28->16]) = 121
recvfrom(10, 0x556dee0c0020, 16384, 0, 0x556df02562c0, [28]) = -1 EAGAIN 
(Resource temporarily unavailable)
epoll_wait(6, [{EPOLLIN, {u32=10, u64=10}}], 4096, 762) = 1
recvfrom(10, 
"\342|\205\200\0\1\0\1\0\0\0\0\0013\0010\0011\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\0010\1f\0014\0010\18\0010\18\0011\0011\0014\0011\0010\0010\0012\3ip6\4arpa\0\0\f\0\1\300\f\0\f\0\1\0\0\4\260\0\23\6server\2ad\4example\2sk\0", 
16384, 0, {sa_family=AF_INET, sin_port=htons(53), 
sin_addr=inet_addr("10.20.10.18")}, [28->16]) = 121
recvfrom(10, 0x556dee0c0020, 16384, 0, 0x556df02562c0, [28]) = -1 EAGAIN 
(Resource temporarily unavailable)
epoll_wait(6, [{EPOLLIN, {u32=10, u64=10}}], 4096, 635) = 1
recvfrom(10, 
"\367$\201\200\0\1\0\1\0\1\0\0\2i5\1c\4eset\3com\0\0\34\0\1\300\f\0\5\0\1\0\5\315\351\0\n\2i5\4cwip\300\21\300.\0\6\0\1\0\0\t[\0/\vh1-f5lb01-s\300\21\nhostmaster\300\21\0\0\0034\0\0\250\300\0\0\3\204\0\22u\0\0\1Q\200", 
16384, 0, {sa_family=AF_INET, sin_port=htons(53), 
sin_addr=inet_addr("10.20.10.18")}, [28->16]) = 112
recvfrom(10, 0x556dee0c0020, 16384, 0, 0x556df02562c0, [28]) = -1 EAGAIN 
(Resource temporarily unavailable)
epoll_wait(6, [{EPOLLIN, {u32=10, u64=10}}], 4096, 626) = 1
recvfrom(10, 
"!6\201\200\0\1\0\3\0\0\0\0\2i5\1c\4eset\3com\0\0\1\0\1\300\f\0\5\0\1\0\5\315\351\0\n\2i5\4cwip\300\21\300+\0\1\0\1\0\0\0\36\0\4[\344\245,\300+\0\1\0\1\0\0\0\36\0\4[\344\247.", 
16384, 0, {sa_family=AF_INET, sin_port=htons(53), 
sin_addr=inet_addr("10.20.10.18")}, [28->16]) = 85
..

anybody has any idea why is this happening?

thanks

michal





From david at articatech.com  Sun May 17 22:15:12 2020
From: david at articatech.com (David Touzeau)
Date: Mon, 18 May 2020 00:15:12 +0200
Subject: [squid-users] squid 4.10: ssl-bump on https_port requires
 tproxy/intercept which is missing in secure proxy method
Message-ID: <799b7312-c961-aeb7-261a-da249a163a41@articatech.com>



Hi we want to use squid as * * * Secure Proxy * * * using https_port
We have tested major browsers and it seems working good.

To make it work, we need to deploy the proxy certificate on all browsers 
to make the secure connection running.

In this case, squid forward requests without decrypting them.because 
ssl-bump is not added.

But Adding the ssl-bump in https_port is not permitted :

"sl-bump on https_port requires tproxy/intercept which is missing"

why bumping is not allowed ?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200518/f8576628/attachment.htm>

From John.Turnbull at utoledo.edu  Sat May 16 03:08:35 2020
From: John.Turnbull at utoledo.edu (Turnbull, John)
Date: Sat, 16 May 2020 03:08:35 +0000
Subject: [squid-users] Squid with connmark
Message-ID: <MN2PR01MB54210E1F4B33219D76A9DA8EEBBA0@MN2PR01MB5421.prod.exchangelabs.com>

What is the best way to intercept marked packets with squid and squid to be aware of mark and create an ACL on the mark?

I have tried setting the mark and then DNAT and redirect  to the intercept port and when printing the nmark I am getting 0

Is it required to use tproxy with tproxy-mark?

Thanks,

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200516/e15891da/attachment.htm>

From david at articatech.com  Fri May 15 07:28:56 2020
From: david at articatech.com (David Touzeau)
Date: Fri, 15 May 2020 09:28:56 +0200
Subject: [squid-users] Squid 4.x acl server_cert_fingerprint for bump no
 matches
In-Reply-To: <45902ecb-f05f-9189-a3a2-caa8fd9dd19b@measurement-factory.com>
References: <78deb686-453b-a1a8-a396-b5d9adadc449@articatech.com>
 <45902ecb-f05f-9189-a3a2-caa8fd9dd19b@measurement-factory.com>
Message-ID: <93e35d58-df6d-e339-dd0d-d2a594dffb70@articatech.com>


Thanks alex, made this one on squid 4.10


acl TestFinger server_cert_fingerprint 
77:F6:8D:C1:0A:DF:94:8B:43:1F:8E:0E:91:5E:0C:32:42:8B:99:C9
acl ssl_step1 at_step SslBump1
acl ssl_step2 at_step SslBump2
acl ssl_step3 at_step SslBump3
ssl_bump peek ssl_step2
ssl_bump splice ssl_step3 TestFinger
ssl_bump stare ssl_step2 all
ssl_bump bump all

But no luck, website still decrypted.




Le 13/05/2020 ? 21:33, Alex Rousskov a ?crit?:
> On 5/12/20 7:42 AM, David Touzeau wrote:
>> ssl_bump peek ssl_step1
>> ssl_bump splice TestFinger
>> ssl_bump stare ssl_step2 all
>> ssl_bump bump all
>> Seems TestFinger Acls did not matches in any case
> You are trying to use step3 information (i.e., the server certificate)
> during SslBump step2: The "splice TestFinger" line is tested during
> step2 and mismatches because the server certificate is still unknown
> during that step. That mismatch results in Squid staring during step2.
> The "splice TestFinger" line is not tested during step3 because splicing
> is not possible after staring. Thus, Squid reaches "bump all" and bumps.
>
> For a detailed description of what happens (and what information is
> available) during each SslBump step, please see
> https://wiki.squid-cache.org/Features/SslPeekAndSplice
>
> Also, if you are running v4.9 or earlier, please upgrade. We fixed one
> server_cert_fingerprint bug, and that fix became a part of the v4.10
> release (commit e0eca4c).
>
>
> HTH,
>
> Alex.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200515/df713817/attachment.htm>

From 3m9n51s2ewut at thismonkey.com  Thu May 14 06:13:45 2020
From: 3m9n51s2ewut at thismonkey.com (Scott)
Date: Thu, 14 May 2020 16:13:45 +1000
Subject: [squid-users] Dumping sslbump'd decrytped http using icap protocol
Message-ID: <20200514061344.GA93629@thismonkey.com>




From squid3 at treenet.co.nz  Sun May 17 10:36:18 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 17 May 2020 22:36:18 +1200
Subject: [squid-users] Client IP PTR lookup on connect
In-Reply-To: <16d9af75-cb1b-7117-62a0-fcb4c6046f19@ssrk.sk>
References: <16d9af75-cb1b-7117-62a0-fcb4c6046f19@ssrk.sk>
Message-ID: <49b8d624-6c5f-33f6-66d4-0fe3aa5b2f9c@treenet.co.nz>

On 14/05/20 1:44 am, Michal Bruncko wrote:
> Hello guys
> 
> following the original thread "[squid-users] Squid 4.9 Client IP PTR
> lookup on connect"
> 
> I am observing exactly same bahavour on
> squid-4.4-8.module_el8.1.0+197+0c39cdc8.x86_64 on CentOS 8.

Certainly 4.4 is older than 4.9.


> At first I was suspecting some squid module (auth helper
> (gssapi/ntlm/basic), URL rewriter) or syslog (which we use for sending
> access logs to remote server) but those DNS queries are coming directly
> from squid process (same as the one doing standard forward DNS lookups).

The URL-rewriter input includes the rDNS name of the client IP. I expect
your Squid is trying to fetch that information to send the re-writer.


> write(16,
> "http://i5.c.eset.com/v1/auth/851A4855CEEAB5292C10/updlist/0/eid/7033368/lid/7033484
> 2001:4118:804:f000::103/2001:4118:804:f000::"..., 179) = 179

If that information is not actually needed by your re-writer, then
configure the url_rewrite_extras directive to alter what gets sent.


Amos


From squid3 at treenet.co.nz  Sun May 17 10:58:49 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 17 May 2020 22:58:49 +1200
Subject: [squid-users] "intercepted port does not match 443"
In-Reply-To: <20200511130138.GC10458@fantomas.sk>
References: <20200511130138.GC10458@fantomas.sk>
Message-ID: <c00c2057-c689-049d-816b-c05084d1868d@treenet.co.nz>

On 12/05/20 1:01 am, Matus UHLAR - fantomas wrote:
> Hello,
> 
> we have intercepting squid on one router and these messages started appear
> sometimes:
> 
> 2020/05/11 13:41:23 kid1| SECURITY ALERT: Host header forgery detected
> on local=[XXX]:80 remote=192.168.1.224:1040 FD 69 flags=33 (intercepted
> port does not match 443)
> 2020/05/11 13:41:23 kid1| SECURITY ALERT: By user agent: Microsoft BITS/6.7
> 2020/05/11 13:41:23 kid1| SECURITY ALERT: on URL: armmf.adobe.com:443
> 2020/05/11 13:41:23 kid1| kick abandoning local=[XXX]:80
> remote=192.168.1.224:1040 FD 69 flags=33
> 
> I am aware of possible interception issues but what exactly does this
> message mean?? The original destination port is 80, why does squid complain
> about it not being port 443?

The HTTP Host header says the client was connecting to a server on port
443. Yet the TCP packets came, as you say from port 80.


Amos


From squid3 at treenet.co.nz  Tue May 19 11:15:41 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 19 May 2020 23:15:41 +1200
Subject: [squid-users] squid 4.10: ssl-bump on https_port requires
 tproxy/intercept which is missing in secure proxy method
In-Reply-To: <799b7312-c961-aeb7-261a-da249a163a41@articatech.com>
References: <799b7312-c961-aeb7-261a-da249a163a41@articatech.com>
Message-ID: <dab3194d-6596-7a8b-ff71-99248e18b688@treenet.co.nz>

On 18/05/20 10:15 am, David Touzeau wrote:
> ??
> 
> Hi we want to use squid as * * * Secure Proxy * * * using https_port
> We have tested major browsers and it seems working good.
> 
> To make it work, we need to deploy the proxy certificate on all browsers
> to make the secure connection running.
> 
> In this case, squid forward requests without decrypting them.because
> ssl-bump is not added.
> 
> But Adding the ssl-bump in https_port is not permitted :
> 
> "sl-bump on https_port requires tproxy/intercept which is missing"
> 
> why bumping is not allowed ?
> 

Because origin server and explicit proxy traffic are mutually exclusive
syntax at the HTTP level, and use different types of SSL certificate at
the TLS level.

A "Secure proxy" receives explicit-proxy HTTP traffic over TLS. That
traffic gets decrypted normally on receipt by the https_port, using a
proxy server certificate.

SSL-Bump auto-generates a server certificate to decrypt with, and
expects origin form HTTP syntax once decrypted.


HTTPS traffic as we know it (CONNECT tunnels to port 443) might still be
sent to a secure proxy. In which case there are two layers of encryption
nested inside each other. Decrypting the interior layer of at is not yet
supported by Squid.


Amos


From squid3 at treenet.co.nz  Tue May 19 11:18:10 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 19 May 2020 23:18:10 +1200
Subject: [squid-users] Squid 4.x acl server_cert_fingerprint for bump no
 matches
In-Reply-To: <93e35d58-df6d-e339-dd0d-d2a594dffb70@articatech.com>
References: <78deb686-453b-a1a8-a396-b5d9adadc449@articatech.com>
 <45902ecb-f05f-9189-a3a2-caa8fd9dd19b@measurement-factory.com>
 <93e35d58-df6d-e339-dd0d-d2a594dffb70@articatech.com>
Message-ID: <e8d75997-8bab-aa36-9f24-792a5dea732d@treenet.co.nz>

On 15/05/20 7:28 pm, David Touzeau wrote:
> 
> Thanks alex, made this one on squid 4.10
> 
> 
> acl TestFinger server_cert_fingerprint
> 77:F6:8D:C1:0A:DF:94:8B:43:1F:8E:0E:91:5E:0C:32:42:8B:99:C9

Is that a SHA1 fingerprint or a newer algorithm?

AFAIK only SHA1 is supported by Squid currently.

Also, it is matched against what the server SSL certificate contains. So
that has to be a SHA1 fingerprint as well.

Amos


From michal.bruncko at ssrk.sk  Tue May 19 12:31:43 2020
From: michal.bruncko at ssrk.sk (Michal Bruncko)
Date: Tue, 19 May 2020 14:31:43 +0200
Subject: [squid-users] Client IP PTR lookup on connect
In-Reply-To: <49b8d624-6c5f-33f6-66d4-0fe3aa5b2f9c@treenet.co.nz>
References: <16d9af75-cb1b-7117-62a0-fcb4c6046f19@ssrk.sk>
 <49b8d624-6c5f-33f6-66d4-0fe3aa5b2f9c@treenet.co.nz>
Message-ID: <fa4178a2-6ad8-3f6a-3f92-91124bcd89c6@ssrk.sk>

Hi Amos

thank you for very valuable response. I can confirm that amending 
default url_rewrite_extras value did the trick!

thanks
michal

On 5/17/2020 12:36 PM, Amos Jeffries wrote:
> On 14/05/20 1:44 am, Michal Bruncko wrote:
>> Hello guys
>>
>> following the original thread "[squid-users] Squid 4.9 Client IP PTR
>> lookup on connect"
>>
>> I am observing exactly same bahavour on
>> squid-4.4-8.module_el8.1.0+197+0c39cdc8.x86_64 on CentOS 8.
> Certainly 4.4 is older than 4.9.
>
>
>> At first I was suspecting some squid module (auth helper
>> (gssapi/ntlm/basic), URL rewriter) or syslog (which we use for sending
>> access logs to remote server) but those DNS queries are coming directly
>> from squid process (same as the one doing standard forward DNS lookups).
> The URL-rewriter input includes the rDNS name of the client IP. I expect
> your Squid is trying to fetch that information to send the re-writer.
>
>
>> write(16,
>> "http://i5.c.eset.com/v1/auth/851A4855CEEAB5292C10/updlist/0/eid/7033368/lid/7033484
>> 2001:4118:804:f000::103/2001:4118:804:f000::"..., 179) = 179
> If that information is not actually needed by your re-writer, then
> configure the url_rewrite_extras directive to alter what gets sent.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From uhlar at fantomas.sk  Tue May 19 13:24:42 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 19 May 2020 15:24:42 +0200
Subject: [squid-users] squid 4.10: ssl-bump on https_port requires
 tproxy/intercept which is missing in secure proxy method
In-Reply-To: <dab3194d-6596-7a8b-ff71-99248e18b688@treenet.co.nz>
References: <799b7312-c961-aeb7-261a-da249a163a41@articatech.com>
 <dab3194d-6596-7a8b-ff71-99248e18b688@treenet.co.nz>
Message-ID: <20200519132442.GA2562@fantomas.sk>

>On 18/05/20 10:15 am, David Touzeau wrote:
>> Hi we want to use squid as * * * Secure Proxy * * * using https_port
>> We have tested major browsers and it seems working good.
>>
>> To make it work, we need to deploy the proxy certificate on all browsers
>> to make the secure connection running.
>>
>> In this case, squid forward requests without decrypting them.because
>> ssl-bump is not added.
>>
>> But Adding the ssl-bump in https_port is not permitted :
>>
>> "sl-bump on https_port requires tproxy/intercept which is missing"
>>
>> why bumping is not allowed ?

On 19.05.20 23:15, Amos Jeffries wrote:
>Because origin server and explicit proxy traffic are mutually exclusive
>syntax at the HTTP level, and use different types of SSL certificate at
>the TLS level.
>
>A "Secure proxy" receives explicit-proxy HTTP traffic over TLS. That
>traffic gets decrypted normally on receipt by the https_port, using a
>proxy server certificate.
>
>SSL-Bump auto-generates a server certificate to decrypt with, and
>expects origin form HTTP syntax once decrypted.

David, note that requiring browsers to connect to your proxy over encrypted
(https) connection, and then decrypting tunnels to real server will lower
the clients' security:
Clients will talk HTTPS to proxy, but proxy to server connection might be as
well unencrypted (or, decrypted by proxy).
This makes thinge like SSL authentication impossible.
I understand that you might scan connections for viruses or disabled
content, but the security will be harmed.

>HTTPS traffic as we know it (CONNECT tunnels to port 443) might still be
>sent to a secure proxy. In which case there are two layers of encryption
>nested inside each other. Decrypting the interior layer of at is not yet
>supported by Squid.

so, this is the real problem :-)


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
42.7 percent of all statistics are made up on the spot.


From rousskov at measurement-factory.com  Tue May 19 14:25:57 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 19 May 2020 10:25:57 -0400
Subject: [squid-users] Squid 4.x acl server_cert_fingerprint for bump no
 matches
In-Reply-To: <93e35d58-df6d-e339-dd0d-d2a594dffb70@articatech.com>
References: <78deb686-453b-a1a8-a396-b5d9adadc449@articatech.com>
 <45902ecb-f05f-9189-a3a2-caa8fd9dd19b@measurement-factory.com>
 <93e35d58-df6d-e339-dd0d-d2a594dffb70@articatech.com>
Message-ID: <f9d2d5ce-e80d-9dca-4c51-2ed7da8a9af3@measurement-factory.com>

On 5/15/20 3:28 AM, David Touzeau wrote:

> acl TestFinger server_cert_fingerprint 77:F6:8D:C1:0A:DF:94:8B:43:1F:8E:0E:91:5E:0C:32:42:8B:99:C9
> ssl_bump peek ssl_step2
> ssl_bump splice ssl_step3 TestFinger
> ssl_bump stare ssl_step2 all
> ssl_bump bump all

> But no luck, website still decrypted.

That should be expected: During step1, the only ssl_bump rule that
matches now is ... "bump all".

Also, you have two ssl_step2 rules but only the first one can match.
Perhaps the first one has a typo, and you meant to put ssl_step1 there?


Amos is correct that Squid uses SHA1. So does my openssl x509 (by
default). However, FWIW, I get a different SHA1 fingerprint when I run
your command:

> openssl s_client -host www.clubic.com -port 443 2> /dev/null | openssl x509 -fingerprint -noout
> SHA1 Fingerprint=2A:F4:A6:8E:31:15:AD:A5:52:A9:5F:03:80:42:BE:CA:01:12:2C:E7

Perhaps www.clubic.com uses different certificates for different clients.


HTH,

Alex.


> Le 13/05/2020 ? 21:33, Alex Rousskov a ?crit?:
>> On 5/12/20 7:42 AM, David Touzeau wrote:
>>> ssl_bump peek ssl_step1
>>> ssl_bump splice TestFinger
>>> ssl_bump stare ssl_step2 all
>>> ssl_bump bump all
>>> Seems TestFinger Acls did not matches in any case
>> You are trying to use step3 information (i.e., the server certificate)
>> during SslBump step2: The "splice TestFinger" line is tested during
>> step2 and mismatches because the server certificate is still unknown
>> during that step. That mismatch results in Squid staring during step2.
>> The "splice TestFinger" line is not tested during step3 because splicing
>> is not possible after staring. Thus, Squid reaches "bump all" and bumps.
>>
>> For a detailed description of what happens (and what information is
>> available) during each SslBump step, please see
>> https://wiki.squid-cache.org/Features/SslPeekAndSplice
>>
>> Also, if you are running v4.9 or earlier, please upgrade. We fixed one
>> server_cert_fingerprint bug, and that fix became a part of the v4.10
>> release (commit e0eca4c).
>>
>>
>> HTH,
>>
>> Alex.
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From rousskov at measurement-factory.com  Tue May 19 14:38:29 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 19 May 2020 10:38:29 -0400
Subject: [squid-users] squid 4.10: ssl-bump on https_port requires
 tproxy/intercept which is missing in secure proxy method
In-Reply-To: <dab3194d-6596-7a8b-ff71-99248e18b688@treenet.co.nz>
References: <799b7312-c961-aeb7-261a-da249a163a41@articatech.com>
 <dab3194d-6596-7a8b-ff71-99248e18b688@treenet.co.nz>
Message-ID: <31953344-3d78-ebb7-0f8d-1dcc0e1162e5@measurement-factory.com>

On 5/19/20 7:15 AM, Amos Jeffries wrote:
> On 18/05/20 10:15 am, David Touzeau wrote:
>> ??
>>
>> Hi we want to use squid as * * * Secure Proxy * * * using https_port
>> We have tested major browsers and it seems working good.
>>
>> To make it work, we need to deploy the proxy certificate on all browsers
>> to make the secure connection running.
>>
>> In this case, squid forward requests without decrypting them.because
>> ssl-bump is not added.
>>
>> But Adding the ssl-bump in https_port is not permitted :
>>
>> "sl-bump on https_port requires tproxy/intercept which is missing"
>>
>> why bumping is not allowed ?
>>
> 
> Because origin server and explicit proxy traffic are mutually exclusive
> syntax at the HTTP level, and use different types of SSL certificate at
> the TLS level.
> 
> A "Secure proxy" receives explicit-proxy HTTP traffic over TLS. That
> traffic gets decrypted normally on receipt by the https_port, using a
> proxy server certificate.
> 
> SSL-Bump auto-generates a server certificate to decrypt with, and
> expects origin form HTTP syntax once decrypted.
> 
> 
> HTTPS traffic as we know it (CONNECT tunnels to port 443) might still be
> sent to a secure proxy. In which case there are two layers of encryption
> nested inside each other. Decrypting the interior layer of at is not yet
> supported by Squid.


David,

    Just to avoid misunderstanding: The answer to your question is in
the last sentence of the last paragraph by Amos -- Squid lacks the code
that is necessary to do what you want. There are no fundamental reasons
it cannot be done. There have been a few requests for TLS-inside-TLS
support, but I am not aware of any actual sponsors or features on the
road map. It is a complicated project, even though each of its two
components already works today.


Cheers,

Alex.


From rousskov at measurement-factory.com  Tue May 19 14:46:39 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 19 May 2020 10:46:39 -0400
Subject: [squid-users] squid 4.10: ssl-bump on https_port requires
 tproxy/intercept which is missing in secure proxy method
In-Reply-To: <20200519132442.GA2562@fantomas.sk>
References: <799b7312-c961-aeb7-261a-da249a163a41@articatech.com>
 <dab3194d-6596-7a8b-ff71-99248e18b688@treenet.co.nz>
 <20200519132442.GA2562@fantomas.sk>
Message-ID: <2cd07c05-f9da-0e14-5faf-59bc534428b5@measurement-factory.com>

>> On 18/05/20 10:15 am, David Touzeau wrote:
>>> Hi we want to use squid as * * * Secure Proxy * * * using https_port
>>> We have tested major browsers and it seems working good.
>>>
>>> To make it work, we need to deploy the proxy certificate on all browsers
>>> to make the secure connection running.

I hope that deployment is not necessary -- an HTTPS proxy should be
using a certificate issued for its domain name and signed by a
well-known CA already trusted by browsers. An HTTPS proxy is not faking
anything. If browsers do require CA certificate import in this
environment, it is their limitation.


On 5/19/20 9:24 AM, Matus UHLAR - fantomas wrote:
> David, note that requiring browsers to connect to your proxy over encrypted
> (https) connection, and then decrypting tunnels to real server will lower
> the clients' security

A proper SslBump implementation for HTTPS proxy will not be "decrypting
tunnels to real server". The security of such an implementation will be
the same as of SslBump supported today (plus the additional protections
offered by securing the browser-proxy communication).

Cheers,

Alex.


From ronanlucio at gmail.com  Tue May 19 17:07:07 2020
From: ronanlucio at gmail.com (Ronan Lucio)
Date: Wed, 20 May 2020 05:07:07 +1200
Subject: [squid-users] Sending CONNECT method requests over HTTPS
Message-ID: <CAF-5T9E7eRo=pTftE7ZjTeTDNFjhFEnLQP9YzFzf3F7HEY7Ncg@mail.gmail.com>

Hi all,

I read a similar thread a couple of weeks ago, but my scenario has
some differences.
Anyway, my need is sending CONNECT method requests over HTTPS as well.

If read the docs and just would like to confirm with you if I got it right:

1)
To send CONNECT method requests over HTTPS I'm supposed to use https_port.
May I use it on the same way as http_port (without intercept, proxy,
or accelerate)?

2)
If I need to apply ACL rules to restrict some destinations, I'm
supposed to use bump_ssl.

Is it right?

Thank you,
Ronan


From 0xff1f at gmail.com  Tue May 19 22:19:11 2020
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Wed, 20 May 2020 01:19:11 +0300
Subject: [squid-users] Squid with QOS marking
Message-ID: <55DAB775-E78B-4F73-8AF6-78D030A075B7@gmail.com>

Hello Folks ,

Im trying to mark outgoing squid request based on Mark linux matching .

I added to squid conf :

qos_flows mark local-hit=0xd7
qos_flows mark local-miss=0xd7

-A OUTPUT -m mark --mark 0xd7 -j ACCEPT

But on iptables there is no match with the mark d7 


Im testing  marking with squid and matching with iptables  but its not matching , always statistics = 0 on linux iptables  That mean  its not matched .

Squid version is 4.8
Also squid was complied with '--enable-zph-qos? flag 

So not sure if I need specific config for squid .

Thanks 

From 0xff1f at gmail.com  Tue May 19 22:22:04 2020
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Wed, 20 May 2020 01:22:04 +0300
Subject: [squid-users] Squid with QOS marking
In-Reply-To: <55DAB775-E78B-4F73-8AF6-78D030A075B7@gmail.com>
References: <55DAB775-E78B-4F73-8AF6-78D030A075B7@gmail.com>
Message-ID: <8C163569-2F90-4AA0-84DE-B5166BCBAAB2@gmail.com>

Following :

https://wiki.squid-cache.org/Features/QualityOfService <https://wiki.squid-cache.org/Features/QualityOfService>

Based on it we need kernel patch for TOS , but I dont need TOS ,  I just need Layer 3 DSP , Linux mark rule based .


Thanks 


> On May 20, 2020, at 1:19 AM, Ahmad Alzaeem <0xff1f at gmail.com> wrote:
> 
> Hello Folks ,
> 
> Im trying to mark outgoing squid request based on Mark linux matching .
> 
> I added to squid conf :
> 
> qos_flows mark local-hit=0xd7
> qos_flows mark local-miss=0xd7
> 
> -A OUTPUT -m mark --mark 0xd7 -j ACCEPT
> 
> But on iptables there is no match with the mark d7 
> 
> 
> Im testing  marking with squid and matching with iptables  but its not matching , always statistics = 0 on linux iptables  That mean  its not matched .
> 
> Squid version is 4.8
> Also squid was complied with '--enable-zph-qos? flag 
> 
> So not sure if I need specific config for squid .
> 
> Thanks 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200520/8b123028/attachment.htm>

From david at articatech.com  Wed May 20 07:51:32 2020
From: david at articatech.com (David Touzeau)
Date: Wed, 20 May 2020 09:51:32 +0200
Subject: [squid-users] squid 4.10: ssl-bump on https_port requires
 tproxy/intercept which is missing in secure proxy method
In-Reply-To: <2cd07c05-f9da-0e14-5faf-59bc534428b5@measurement-factory.com>
References: <799b7312-c961-aeb7-261a-da249a163a41@articatech.com>
 <dab3194d-6596-7a8b-ff71-99248e18b688@treenet.co.nz>
 <20200519132442.GA2562@fantomas.sk>
 <2cd07c05-f9da-0e14-5faf-59bc534428b5@measurement-factory.com>
Message-ID: <b8c87db9-9b5b-5391-9ee9-4341235da3a2@articatech.com>

Thanks for the answer details

How to be a sponsor ? ( cost ) of such feature
Could you think it can be planned for 5.x ?
I think it should be a "future" "standard" in the same way of DNS over SSL

Le 19/05/2020 ? 16:46, Alex Rousskov a ?crit?:
>>> On 18/05/20 10:15 am, David Touzeau wrote:
>>>> Hi we want to use squid as * * * Secure Proxy * * * using https_port
>>>> We have tested major browsers and it seems working good.
>>>>
>>>> To make it work, we need to deploy the proxy certificate on all browsers
>>>> to make the secure connection running.
> I hope that deployment is not necessary -- an HTTPS proxy should be
> using a certificate issued for its domain name and signed by a
> well-known CA already trusted by browsers. An HTTPS proxy is not faking
> anything. If browsers do require CA certificate import in this
> environment, it is their limitation.
>
>
> On 5/19/20 9:24 AM, Matus UHLAR - fantomas wrote:
>> David, note that requiring browsers to connect to your proxy over encrypted
>> (https) connection, and then decrypting tunnels to real server will lower
>> the clients' security
> A proper SslBump implementation for HTTPS proxy will not be "decrypting
> tunnels to real server". The security of such an implementation will be
> the same as of SslBump supported today (plus the additional protections
> offered by securing the browser-proxy communication).
>
> Cheers,
>
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200520/2b324e49/attachment.htm>

From uhlar at fantomas.sk  Wed May 20 10:02:38 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 20 May 2020 12:02:38 +0200
Subject: [squid-users] squid 4.10: ssl-bump on https_port requires
 tproxy/intercept which is missing in secure proxy method
In-Reply-To: <2cd07c05-f9da-0e14-5faf-59bc534428b5@measurement-factory.com>
References: <799b7312-c961-aeb7-261a-da249a163a41@articatech.com>
 <dab3194d-6596-7a8b-ff71-99248e18b688@treenet.co.nz>
 <20200519132442.GA2562@fantomas.sk>
 <2cd07c05-f9da-0e14-5faf-59bc534428b5@measurement-factory.com>
Message-ID: <20200520100238.GA4558@fantomas.sk>

>>> On 18/05/20 10:15 am, David Touzeau wrote:
>>>> Hi we want to use squid as * * * Secure Proxy * * * using https_port
>>>> We have tested major browsers and it seems working good.
>>>>
>>>> To make it work, we need to deploy the proxy certificate on all browsers
>>>> to make the secure connection running.

On 19.05.20 10:46, Alex Rousskov wrote:
>I hope that deployment is not necessary -- an HTTPS proxy should be
>using a certificate issued for its domain name and signed by a
>well-known CA already trusted by browsers. An HTTPS proxy is not faking
>anything. If browsers do require CA certificate import in this
>environment, it is their limitation.

That means, SSL connection from brower to the proxy will be encrypted and
signed by certificate installed on the proxy, which may be signed by public
authority, provided the proxy has public DNS name 
(public authorities only sign public domains)

the traffic inside of the SSL tunnel will be standard proxy communication -
GET, POST, CONNECT requests.

CONNECT requests will ask the proxy to build tunnel to destination server,
which will usually contain encrypted HTTPS communication between browser and
final server.  So, CONNECT will create HTTPS connection (browser-server)
inside of HTTPS connection (browser-proxy)

>On 5/19/20 9:24 AM, Matus UHLAR - fantomas wrote:
>> David, note that requiring browsers to connect to your proxy over encrypted
>> (https) connection, and then decrypting tunnels to real server will lower
>> the clients' security
>
>A proper SslBump implementation for HTTPS proxy will not be "decrypting
>tunnels to real server". The security of such an implementation will be
>the same as of SslBump supported today (plus the additional protections
>offered by securing the browser-proxy communication).

If David wants to ssl-bump the traffic inside the HTTPS tunel (and I from
Davis's request I believe he wants to do that), it means that the
communication between browser and server has to be decrypted on squid, squid
will talk to server using HTTPS and create HTTPS endpoint to the client that
provides data, which means:

- squid will see the communication between browser and server
  (which is what HTTPS is designed to avoid)
- squid will need to dynamically creste certificated for sites it bumps
  using local CA
- clients will need to install the CA as trusted.

This is exactly what SSL Bump is about. 

My point is that David wants to provide "secure" proxy which may compromise
the security instead by bumping connections.

I am not objecting against doing it, but I want to note that whole point of
HTTPS (where the "S" means secure) is that noone in the middle sees what is
the content of communication between client and server.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
On the other hand, you have different fingers.


From uhlar at fantomas.sk  Wed May 20 10:07:47 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 20 May 2020 12:07:47 +0200
Subject: [squid-users] Sending CONNECT method requests over HTTPS
In-Reply-To: <CAF-5T9E7eRo=pTftE7ZjTeTDNFjhFEnLQP9YzFzf3F7HEY7Ncg@mail.gmail.com>
References: <CAF-5T9E7eRo=pTftE7ZjTeTDNFjhFEnLQP9YzFzf3F7HEY7Ncg@mail.gmail.com>
Message-ID: <20200520100747.GB4558@fantomas.sk>

On 20.05.20 05:07, Ronan Lucio wrote:
>I read a similar thread a couple of weeks ago, but my scenario has
>some differences.
>Anyway, my need is sending CONNECT method requests over HTTPS as well.

already possible.

>If read the docs and just would like to confirm with you if I got it right:
>
>1)
>To send CONNECT method requests over HTTPS I'm supposed to use https_port.

no. It's very common to use HTTP proxy over HTTP, and the CONNECT requests
creates communication between client and server

>May I use it on the same way as http_port (without intercept, proxy,
>or accelerate)?

yes.

>2)
>If I need to apply ACL rules to restrict some destinations, I'm
>supposed to use bump_ssl.

without bumping, you can only see the destination host:port and possible
hostname sent in the SNI request and contents of the SSL certificate.

for anything else (like the https path) you must bump the connection:
decrypt the SSL tunnel, behave as the server to the client (providing it
with certificate client trusts) and behave as client to the server
(which makes e.g. SSL authentication impossible).

Note that doing this can compromise clients' security and can cause legal
issues.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Linux - It's now safe to turn on your computer.
Linux - Teraz mozete pocitac bez obav zapnut.


From leonardo at lbasolutions.com  Wed May 20 10:13:59 2020
From: leonardo at lbasolutions.com (Leonardo Bacha Abrantes)
Date: Wed, 20 May 2020 07:13:59 -0300
Subject: [squid-users] Block file extension over https
Message-ID: <CAG+8EEbTQGRKR5cNw-0-7Lz19jODfw6riuhBa3jjT4_yOu+FaQ@mail.gmail.com>

Hi guys,

Please does anyone has a effective way how to block file download over
https connection?
I tried many things but didn't work. Only worked over http.

Sorry for my english.

Thanks!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200520/ce14b5df/attachment.htm>

From uhlar at fantomas.sk  Wed May 20 11:06:21 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 20 May 2020 13:06:21 +0200
Subject: [squid-users] Block file extension over https
In-Reply-To: <CAG+8EEbTQGRKR5cNw-0-7Lz19jODfw6riuhBa3jjT4_yOu+FaQ@mail.gmail.com>
References: <CAG+8EEbTQGRKR5cNw-0-7Lz19jODfw6riuhBa3jjT4_yOu+FaQ@mail.gmail.com>
Message-ID: <20200520110621.GA10377@fantomas.sk>

On 20.05.20 07:13, Leonardo Bacha Abrantes wrote:
>Please does anyone has a effective way how to block file download over
>https connection?

>I tried many things but didn't work. Only worked over http.

this requires SSL bumping. in https, you don't see the content unless you
bump, and therefore decrypt the connection.
It is not secure anymore.

https://wiki.squid-cache.org/Features/SslPeekAndSplice

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Your mouse has moved. Windows NT will now restart for changes to take
to take effect. [OK]


From rousskov at measurement-factory.com  Wed May 20 13:42:12 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 20 May 2020 09:42:12 -0400
Subject: [squid-users] Sending CONNECT method requests over HTTPS
In-Reply-To: <20200520100747.GB4558@fantomas.sk>
References: <CAF-5T9E7eRo=pTftE7ZjTeTDNFjhFEnLQP9YzFzf3F7HEY7Ncg@mail.gmail.com>
 <20200520100747.GB4558@fantomas.sk>
Message-ID: <4666633b-9f98-5111-119e-43201d80b51b@measurement-factory.com>

On 5/20/20 6:07 AM, Matus UHLAR - fantomas wrote:
> On 20.05.20 05:07, Ronan Lucio wrote:
>> I read a similar thread a couple of weeks ago, but my scenario has
>> some differences.
>> Anyway, my need is sending CONNECT method requests over HTTPS as well.

> already possible.

I assume that, here and below, "over HTTPS" means "to an HTTPS proxy".

Yes, any HTTP request, including CONNECT can be sent to an HTTPS proxy.


>> 1) To send CONNECT method requests over HTTPS I'm supposed to use
>> https_port.

> no. It's very common to use HTTP proxy over HTTP, and the CONNECT requests
> creates communication between client and server

The question is difficult to interpret correctly. Here are arguably
better questions (with answers):

Q: If I want to use an HTTPS proxy, what Squid port should I configure?
A: You must use an https_port directive.

Q: Does https_port support CONNECT requests?
A: Yes. Squid https_port supports all HTTP requests supported by
   http_port, including CONNECT.

Q: How does Squid, in an HTTPS proxy mode, handle a CONNECT request?
A: Squid handles it as it would handle a CONNECT request
   received over an http_port (by default) -- by establishing a TCP
   tunnel to the origin server and shoveling bytes back and force.
   The client-Squid portion of that tunnel would be protected by
   TLS in this case, of course -- that is always true for an HTTPS
   proxy. SslBump features are not supported in HTTPS mode (yet).


>> May I use it on the same way as http_port (without intercept, proxy,
>> or accelerate)?

> yes.

Q: Can https_port be used without an explicit mode (i.e., without
   an intercept, tproxy, accel, or ssl-bump parameter)?
A: Yes. The https_port directive supports the default (i.e. forward
   proxy) mode.

Q: What happens when https_port is used without an explicit mode?
A: Traffic on such https_port is treated as if Squid was an HTTPS proxy.


>> 2) If I need to apply ACL rules to restrict some destinations, I'm
>> supposed to use bump_ssl.
> 
> without bumping, you can only see the destination host:port and possible
> hostname sent in the SNI request and contents of the SSL certificate.

Again, it is difficult to interpret this question correctly. Here are a
few versions with correct answers:

Q: Can I use ssl_bump with an HTTPS proxy?
A: No, that is not supported yet.

Q: What ACLs can I use in an HTTPS proxy mode?
A: All ACLs that do not require inspecting packets inside
   TLS connections from client to origin. Please note that
   a single client-origin TLS connection involves two
   TCP connections. That inspection is what SslBump does (among
   other things). This answer is (too) complex. Unfortunately,
   there is currently no documentation that, for every ACL,
   details precisely what information sources are required for
   that ACL to work. Some ACLs use multiple information sources,
   depending on Squid configuration and/or transaction state,
   complicating the matters further.

Q: Is TLS origin SNI available to Squid ACLs in HTTPS proxy mode?
A: No, not today. SslBump features are not yet supported in that mode.

Q: Are URL paths of HTTP requests inside CONNECT tunnels
   available to Squid ACLS in HTTPS proxy mode?
A: No, not today. SslBump features are not yet supported in that mode.


HTH,

Alex.



From rousskov at measurement-factory.com  Wed May 20 14:14:21 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 20 May 2020 10:14:21 -0400
Subject: [squid-users] squid 4.10: ssl-bump on https_port requires
 tproxy/intercept which is missing in secure proxy method
In-Reply-To: <b8c87db9-9b5b-5391-9ee9-4341235da3a2@articatech.com>
References: <799b7312-c961-aeb7-261a-da249a163a41@articatech.com>
 <dab3194d-6596-7a8b-ff71-99248e18b688@treenet.co.nz>
 <20200519132442.GA2562@fantomas.sk>
 <2cd07c05-f9da-0e14-5faf-59bc534428b5@measurement-factory.com>
 <b8c87db9-9b5b-5391-9ee9-4341235da3a2@articatech.com>
Message-ID: <00773822-eb72-06e0-cb73-de62efdc1468@measurement-factory.com>

On 5/20/20 3:51 AM, David Touzeau wrote:

> How to be a sponsor?

There are many ways, including these two:

1. You privately find a developer (a person or an organization) and pay
them for implementing the changes you need.

2. You post an RFQ to squid-dev and solicit quotes/bids from developers.

If substantial changes you sponsored are officially accepted, you can
request to be officially listed in SPONSORS. Needless to say, you can
pull resources with other co-sponsors.

For a complex feature like TLS-inside-TLS bumping, please make sure that

a) The required architectural changes are deemed acceptable to the Squid
Project before the development starts. Otherwise, you may end up with a
large piece of code that you would have to pay somebody to maintain
forever. Such preliminary acceptance can be secured via discussions on
squid-dev. Such discussions should be initiated by (the developer)
posting a Request For Comments outlining major anticipated changes.

b) The developer will support the changes throughout Squid Project
review and initial deployment. It is very likely that the initial
version of the "working" code will need to be adjusted (for many reasons).

The following FAQ may be useful in this context:
https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F


> ( cost ) of such feature

That would be determined by the developer, subject to the usual business
negotiations (warranties, deadlines, backporting support, payment terms,
etc.). The most common pitfalls here are underestimating the complexity
of the changes, the overheads related to getting the changes officially
accepted, and medium-term support costs. FWIW, if I were to get a quote
that equates this project with a week worth of work, I would laugh at it.

Please note that the Squid Project itself does not do Squid development
and does not receive any money for Squid development. Some developers
contribute back to the Project (in various ways), but there is no
requirement to do so. This is typical for many open source projects, of
course.


> Could you think it can be planned for 5.x ?

IMO, no. The change is too big to qualify for any reasonable v5 freeze
exception. Squid v6 is your best bet right now. If the developer knows
what they are doing, there are ways to mitigate associated risks.


HTH,

Alex.


> Le 19/05/2020 ? 16:46, Alex Rousskov a ?crit?:
>>>> On 18/05/20 10:15 am, David Touzeau wrote:
>>>>> Hi we want to use squid as * * * Secure Proxy * * * using https_port
>>>>> We have tested major browsers and it seems working good.
>>>>>
>>>>> To make it work, we need to deploy the proxy certificate on all browsers
>>>>> to make the secure connection running.
>> I hope that deployment is not necessary -- an HTTPS proxy should be
>> using a certificate issued for its domain name and signed by a
>> well-known CA already trusted by browsers. An HTTPS proxy is not faking
>> anything. If browsers do require CA certificate import in this
>> environment, it is their limitation.
>>
>>
>> On 5/19/20 9:24 AM, Matus UHLAR - fantomas wrote:
>>> David, note that requiring browsers to connect to your proxy over encrypted
>>> (https) connection, and then decrypting tunnels to real server will lower
>>> the clients' security
>> A proper SslBump implementation for HTTPS proxy will not be "decrypting
>> tunnels to real server". The security of such an implementation will be
>> the same as of SslBump supported today (plus the additional protections
>> offered by securing the browser-proxy communication).
>>
>> Cheers,
>>
>> Alex.


From rousskov at measurement-factory.com  Wed May 20 14:38:02 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 20 May 2020 10:38:02 -0400
Subject: [squid-users] squid 4.10: ssl-bump on https_port requires
 tproxy/intercept which is missing in secure proxy method
In-Reply-To: <20200520100238.GA4558@fantomas.sk>
References: <799b7312-c961-aeb7-261a-da249a163a41@articatech.com>
 <dab3194d-6596-7a8b-ff71-99248e18b688@treenet.co.nz>
 <20200519132442.GA2562@fantomas.sk>
 <2cd07c05-f9da-0e14-5faf-59bc534428b5@measurement-factory.com>
 <20200520100238.GA4558@fantomas.sk>
Message-ID: <c81db5af-3ef9-c957-40d1-f5e2597abb74@measurement-factory.com>

On 5/20/20 6:02 AM, Matus UHLAR - fantomas wrote:
>> On 5/19/20 9:24 AM, Matus UHLAR - fantomas wrote:
>>> David, note that requiring browsers to connect to your proxy over
>>> encrypted (https) connection, and then decrypting tunnels to real server will
>>> lower the clients' security

> On 19.05.20 10:46, Alex Rousskov wrote:
>> A proper SslBump implementation for HTTPS proxy will not be "decrypting
>> tunnels to real server". The security of such an implementation will be
>> the same as of SslBump supported today (plus the additional protections
>> offered by securing the browser-proxy communication).

> If David wants to ssl-bump the traffic inside the HTTPS tunel, it means that the
> communication between browser and server has to be decrypted on squid,
> squid will talk to server using HTTPS

You are right. Due to insufficient shared terminology, we are simply
talking about two different things:

* I am talking about Squid (in a bumping HTTPS proxy role) sending
bumped requests to plain servers, exposing previously encrypted traffic.
While that is technically possible to support (in some cases) and even
occasionally explicitly requested (in a peering environment), that
should _not_ happen if the existing SslBump support is added to the
existing HTTPS proxy mode.

* You are talking about Squid (in a bumping HTTPS proxy role) inspecting
TLS traffic that the client meant for to origin servers eyes only. That
will happen, of course. This is what SslBump is about.


> My point is that David wants to provide "secure" proxy which may compromise
> the security instead by bumping connections.

Right. And my point is that adding SslBump support to HTTPS proxy does
not make things _worse_ as far as "security" and "privacy" are
concerned. Compared to using SslBump in an HTTP proxy, adding SslBump
support to HTTPS proxy may make things better. How much better depends
on your threat model, of course.

No sane person would argue that bumping is a good solution. My point was
that if you have to bump, then using an HTTPS proxy is not going to make
things worse.

It would be better if popular browsers would send plain https://... URLs
to an HTTPS proxy they trust, but they refuse to support that "GET
https" mode.


Cheers,

Alex.


From ben.goz87 at gmail.com  Wed May 20 15:49:17 2020
From: ben.goz87 at gmail.com (Ben Goz)
Date: Wed, 20 May 2020 18:49:17 +0300
Subject: [squid-users] Bypass squid using iptables
Message-ID: <CADAqQfwdpUJ8SQgdrJEczvmtr=SgcvffH_pq+swwx+ay5-fyCA@mail.gmail.com>

B.H.

I'm using squid with c-icap module for specific content filtering. I
configured squid with ssl bump so website with WSS won't work on it as
mentioned on squid documentation. So for such URLs (with WSS) I need
bypassing squid. I read in some posts that squid doesn't fully supports
bypassing URLs and best way is to bypasses it via iptables.

Eventually I redirects browser traffic to my proxy machine using local
machine proxy settings, and Its redirects traffic to my machine with IP
x.x.x.x port 3128.

If I want to use the conservative iptables bypassing how should I config my
machine? and how iptables rules should looks like?

Any help will be appreciated.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200520/8882cf95/attachment.htm>

From sjmeyer at us.ibm.com  Wed May 20 16:20:41 2020
From: sjmeyer at us.ibm.com (sjmeyer)
Date: Wed, 20 May 2020 11:20:41 -0500 (CDT)
Subject: [squid-users] squid 3.5 reverse proxy https configuration problem
Message-ID: <1589991641825-0.post@n4.nabble.com>

I have a squid configured as a reverse proxy on RHEL 7.8

the certificates on the squid box seem okay the squid -k parse passes,
however when I attempt to access the back-end server via squid I get

 Error negotiating SSL connection on FD 13: error:14094416:SSL
routines:ssl3_read_bytes:sslv3 alert certificate unknown (1/0)

It'd my understanding to resolve the SSL error I need to add the CA of the
backend sever to the RHEL trust store - I have done that, copied the ca to
/etc/pki/ca-trust/source/anchors/
ran update-ca-trust extract,
confirmed the CA is in the file
/etc/pki/ca-trust/extracted/openssl/ca-bundle.trust.crt

however no change. I have seen references to the ssl_crtd project however
from the examples I've seen that isn't required. is this my issue?

Contents of my squid.conf file are below, would appreciate
# reverse proxy site
#
acl localnet src 10.0.0.0/8
# - debug options
# 0 client database
# 1 start up and main loop
# 2 Unlink Daemon
# 3 configuration file parsing
# 4 error generation
# 5 socket functions
# 11 HTTP
# 23 URL parsing
debug_options All,1 9


acl SSL_ports port 5443
acl Safe_ports port 80
acl Safe_ports port 21
acl Safe_ports port 443
acl Safe_ports port 8902
acl Safe_ports port 70
acl Safe_ports port 210
acl Safe_ports port 280
acl Safe_ports port 488
acl Safe_ports port 591
acl Safe_ports port 777
acl Safe_ports port 5443
acl Safe_ports port 1025-65535
acl CONNECT method CONNECT


http_port 3128 transparent

http_access allow Safe_ports
#http_access deny !Safe_ports

http_access allow localnet




https_port 5443 accel defaultsite=10.234.48.183
cert=/etc/squid/tls/devi_public.pem key=/etc/squid/tls/devi_private.key
cafile=/etc/squid/tls/devi_ca.crt vhost


sslproxy_options NO_SSLv2:NO_SSLv3:NO_TLSv1:NO_TLSv1_1




cache_peer 10.234.49.188 parent 5443 0 no-query originserver ssl
sslflags=DONT_VERIFY_PEER connection-auth=off name=dev-api

acl BrokenButTrustedServers dstdomain 10.234.49.188 devi.mlms.cms.gov
#sslproxy_cert_error allow BrokenButTrustedServers
sslproxy_cert_error allow all
#sslproxy_cert_error deny all
sslproxy_flags DONT_VERIFY_PEER

#ssl_bump splice #localhost
# configure backend

acl our_sites dstdomain dev.app.lb.local 10.234.49.188
http_access allow our_sites
cache_peer_access dev-int allow our_sites
cache_peer_access dev-api allow our_sites



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Wed May 20 16:59:47 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 20 May 2020 12:59:47 -0400
Subject: [squid-users] squid 3.5 reverse proxy https configuration
	problem
In-Reply-To: <1589991641825-0.post@n4.nabble.com>
References: <1589991641825-0.post@n4.nabble.com>
Message-ID: <e97386d3-dc98-88cc-b5cf-391d6dcdad8b@measurement-factory.com>

On 5/20/20 12:20 PM, sjmeyer wrote:
> I have a squid configured as a reverse proxy on RHEL 7.8
> 
> the certificates on the squid box seem okay the squid -k parse passes,
> however when I attempt to access the back-end server via squid I get
> 
> Error negotiating SSL connection on FD 13: error:14094416:SSL
> routines:ssl3_read_bytes:sslv3 alert certificate unknown (1/0)

AFAICT, your client (e.g., a browser) probably does not trust Squid's
certificate (i.e., /etc/squid/tls/devi_public.pem). Should it? What does
the client say?


> It'd my understanding to resolve the SSL error I need to add the CA of the
> backend sever to the RHEL trust store

If my understanding about the scope of the error is correct, then the
backend server is irrelevant. The error is between the TLS/HTTPS client
and Squid, not Squid and cache_peer. Squid has not yet contacted the
cache_peer at the time of this error.


HTH,

Alex.


> - I have done that, copied the ca to
> /etc/pki/ca-trust/source/anchors/
> ran update-ca-trust extract,
> confirmed the CA is in the file
> /etc/pki/ca-trust/extracted/openssl/ca-bundle.trust.crt
> 
> however no change. I have seen references to the ssl_crtd project however
> from the examples I've seen that isn't required. is this my issue?
> 
> Contents of my squid.conf file are below, would appreciate
> # reverse proxy site
> #
> acl localnet src 10.0.0.0/8
> # - debug options
> # 0 client database
> # 1 start up and main loop
> # 2 Unlink Daemon
> # 3 configuration file parsing
> # 4 error generation
> # 5 socket functions
> # 11 HTTP
> # 23 URL parsing
> debug_options All,1 9
> 
> 
> acl SSL_ports port 5443
> acl Safe_ports port 80
> acl Safe_ports port 21
> acl Safe_ports port 443
> acl Safe_ports port 8902
> acl Safe_ports port 70
> acl Safe_ports port 210
> acl Safe_ports port 280
> acl Safe_ports port 488
> acl Safe_ports port 591
> acl Safe_ports port 777
> acl Safe_ports port 5443
> acl Safe_ports port 1025-65535
> acl CONNECT method CONNECT
> 
> 
> http_port 3128 transparent
> 
> http_access allow Safe_ports
> #http_access deny !Safe_ports
> 
> http_access allow localnet
> 
> 
> 
> 
> https_port 5443 accel defaultsite=10.234.48.183
> cert=/etc/squid/tls/devi_public.pem key=/etc/squid/tls/devi_private.key
> cafile=/etc/squid/tls/devi_ca.crt vhost
> 
> 
> sslproxy_options NO_SSLv2:NO_SSLv3:NO_TLSv1:NO_TLSv1_1
> 
> 
> 
> 
> cache_peer 10.234.49.188 parent 5443 0 no-query originserver ssl
> sslflags=DONT_VERIFY_PEER connection-auth=off name=dev-api
> 
> acl BrokenButTrustedServers dstdomain 10.234.49.188 devi.mlms.cms.gov
> #sslproxy_cert_error allow BrokenButTrustedServers
> sslproxy_cert_error allow all
> #sslproxy_cert_error deny all
> sslproxy_flags DONT_VERIFY_PEER
> 
> #ssl_bump splice #localhost
> # configure backend
> 
> acl our_sites dstdomain dev.app.lb.local 10.234.49.188
> http_access allow our_sites
> cache_peer_access dev-int allow our_sites
> cache_peer_access dev-api allow our_sites
> 
> 
> 
> --
> Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From ronanlucio at gmail.com  Wed May 20 17:00:23 2020
From: ronanlucio at gmail.com (Ronan Lucio)
Date: Thu, 21 May 2020 05:00:23 +1200
Subject: [squid-users] Sending CONNECT method requests over HTTPS
In-Reply-To: <4666633b-9f98-5111-119e-43201d80b51b@measurement-factory.com>
References: <CAF-5T9E7eRo=pTftE7ZjTeTDNFjhFEnLQP9YzFzf3F7HEY7Ncg@mail.gmail.com>
 <20200520100747.GB4558@fantomas.sk>
 <4666633b-9f98-5111-119e-43201d80b51b@measurement-factory.com>
Message-ID: <CAF-5T9GAudOSLB-D=aB3rCdF6=gZ7tR+60OS20PPZVcDWuAVNA@mail.gmail.com>

OK guys, I think you got my point.
@Alex, thank you for the well-detailed answer.

My main need is to encrypt/protect username and password (or
Proxy-Authentication header) sent on the first CONNECT to the proxy
server, in a way this username and password can't be sniffed.

The other need is creating a rule allowing only some dstdomain's.

So I understand that I can achieve that:
1. Enabling "https_port" directive (on a specific port)
2. Using an ACL rule like
    acl allowed_target dstdomain api.mydomain.com
    http_access allow auth_users allowed_target

Is that right?

My scenario is:
I have a serverless API that needs to connect to a couple specific
targets from a static IP.
As this serverless API doesn't have a static IP, I thought to do this
through a proxy server.
That's why I need to enforce security on the authentication layer.

Thanks
Ronan

On Thu, May 21, 2020 at 1:43 AM Alex Rousskov
<rousskov at measurement-factory.com> wrote:
>
> On 5/20/20 6:07 AM, Matus UHLAR - fantomas wrote:
> > On 20.05.20 05:07, Ronan Lucio wrote:
> >> I read a similar thread a couple of weeks ago, but my scenario has
> >> some differences.
> >> Anyway, my need is sending CONNECT method requests over HTTPS as well.
>
> > already possible.
>
> I assume that, here and below, "over HTTPS" means "to an HTTPS proxy".
>
> Yes, any HTTP request, including CONNECT can be sent to an HTTPS proxy.
>
>
> >> 1) To send CONNECT method requests over HTTPS I'm supposed to use
> >> https_port.
>
> > no. It's very common to use HTTP proxy over HTTP, and the CONNECT requests
> > creates communication between client and server
>
> The question is difficult to interpret correctly. Here are arguably
> better questions (with answers):
>
> Q: If I want to use an HTTPS proxy, what Squid port should I configure?
> A: You must use an https_port directive.
>
> Q: Does https_port support CONNECT requests?
> A: Yes. Squid https_port supports all HTTP requests supported by
>    http_port, including CONNECT.
>
> Q: How does Squid, in an HTTPS proxy mode, handle a CONNECT request?
> A: Squid handles it as it would handle a CONNECT request
>    received over an http_port (by default) -- by establishing a TCP
>    tunnel to the origin server and shoveling bytes back and force.
>    The client-Squid portion of that tunnel would be protected by
>    TLS in this case, of course -- that is always true for an HTTPS
>    proxy. SslBump features are not supported in HTTPS mode (yet).
>
>
> >> May I use it on the same way as http_port (without intercept, proxy,
> >> or accelerate)?
>
> > yes.
>
> Q: Can https_port be used without an explicit mode (i.e., without
>    an intercept, tproxy, accel, or ssl-bump parameter)?
> A: Yes. The https_port directive supports the default (i.e. forward
>    proxy) mode.
>
> Q: What happens when https_port is used without an explicit mode?
> A: Traffic on such https_port is treated as if Squid was an HTTPS proxy.
>
>
> >> 2) If I need to apply ACL rules to restrict some destinations, I'm
> >> supposed to use bump_ssl.
> >
> > without bumping, you can only see the destination host:port and possible
> > hostname sent in the SNI request and contents of the SSL certificate.
>
> Again, it is difficult to interpret this question correctly. Here are a
> few versions with correct answers:
>
> Q: Can I use ssl_bump with an HTTPS proxy?
> A: No, that is not supported yet.
>
> Q: What ACLs can I use in an HTTPS proxy mode?
> A: All ACLs that do not require inspecting packets inside
>    TLS connections from client to origin. Please note that
>    a single client-origin TLS connection involves two
>    TCP connections. That inspection is what SslBump does (among
>    other things). This answer is (too) complex. Unfortunately,
>    there is currently no documentation that, for every ACL,
>    details precisely what information sources are required for
>    that ACL to work. Some ACLs use multiple information sources,
>    depending on Squid configuration and/or transaction state,
>    complicating the matters further.
>
> Q: Is TLS origin SNI available to Squid ACLs in HTTPS proxy mode?
> A: No, not today. SslBump features are not yet supported in that mode.
>
> Q: Are URL paths of HTTP requests inside CONNECT tunnels
>    available to Squid ACLS in HTTPS proxy mode?
> A: No, not today. SslBump features are not yet supported in that mode.
>
>
> HTH,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Wed May 20 17:09:22 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 20 May 2020 13:09:22 -0400
Subject: [squid-users] Sending CONNECT method requests over HTTPS
In-Reply-To: <CAF-5T9GAudOSLB-D=aB3rCdF6=gZ7tR+60OS20PPZVcDWuAVNA@mail.gmail.com>
References: <CAF-5T9E7eRo=pTftE7ZjTeTDNFjhFEnLQP9YzFzf3F7HEY7Ncg@mail.gmail.com>
 <20200520100747.GB4558@fantomas.sk>
 <4666633b-9f98-5111-119e-43201d80b51b@measurement-factory.com>
 <CAF-5T9GAudOSLB-D=aB3rCdF6=gZ7tR+60OS20PPZVcDWuAVNA@mail.gmail.com>
Message-ID: <d87832fb-acac-4721-ec10-88a8fba0735c@measurement-factory.com>

On 5/20/20 1:00 PM, Ronan Lucio wrote:
> My main need is to encrypt/protect username and password (or
> Proxy-Authentication header) sent on the first CONNECT to the proxy
> server, in a way this username and password can't be sniffed.
> 
> The other need is creating a rule allowing only some dstdomain's.
> 
> So I understand that I can achieve that:
> 1. Enabling "https_port" directive (on a specific port)
> 2. Using an ACL rule like
>     acl allowed_target dstdomain api.mydomain.com
>     http_access allow auth_users allowed_target
> 
> Is that right?

Your plan looks OK to me if the client is going to send domain names in
its CONNECT requests. Many clients use IP addresses instead. The
dstdomain ACL will attempt to do a reverse DNS lookup for an IP address,
but that is often not reliable.


> My scenario is:
> I have a serverless API that needs to connect to a couple specific
> targets from a static IP.
> As this serverless API doesn't have a static IP, I thought to do this
> through a proxy server.
> That's why I need to enforce security on the authentication layer.

And, I presume, you do not trust the API to only request what it should.
If you trust the API, then you do not need the allowed_target check.

Also, if possible, consider using certificate-based authentication
rather than HTTP authentication to authenticate your clients to Squid.
Certificate-based authentication happens earlier, before Squid has to
deal with all the dangers of HTTP negotiations.

Alex.


> On Thu, May 21, 2020 at 1:43 AM Alex Rousskov wrote:
>>
>> On 5/20/20 6:07 AM, Matus UHLAR - fantomas wrote:
>>> On 20.05.20 05:07, Ronan Lucio wrote:
>>>> I read a similar thread a couple of weeks ago, but my scenario has
>>>> some differences.
>>>> Anyway, my need is sending CONNECT method requests over HTTPS as well.
>>
>>> already possible.
>>
>> I assume that, here and below, "over HTTPS" means "to an HTTPS proxy".
>>
>> Yes, any HTTP request, including CONNECT can be sent to an HTTPS proxy.
>>
>>
>>>> 1) To send CONNECT method requests over HTTPS I'm supposed to use
>>>> https_port.
>>
>>> no. It's very common to use HTTP proxy over HTTP, and the CONNECT requests
>>> creates communication between client and server
>>
>> The question is difficult to interpret correctly. Here are arguably
>> better questions (with answers):
>>
>> Q: If I want to use an HTTPS proxy, what Squid port should I configure?
>> A: You must use an https_port directive.
>>
>> Q: Does https_port support CONNECT requests?
>> A: Yes. Squid https_port supports all HTTP requests supported by
>>    http_port, including CONNECT.
>>
>> Q: How does Squid, in an HTTPS proxy mode, handle a CONNECT request?
>> A: Squid handles it as it would handle a CONNECT request
>>    received over an http_port (by default) -- by establishing a TCP
>>    tunnel to the origin server and shoveling bytes back and force.
>>    The client-Squid portion of that tunnel would be protected by
>>    TLS in this case, of course -- that is always true for an HTTPS
>>    proxy. SslBump features are not supported in HTTPS mode (yet).
>>
>>
>>>> May I use it on the same way as http_port (without intercept, proxy,
>>>> or accelerate)?
>>
>>> yes.
>>
>> Q: Can https_port be used without an explicit mode (i.e., without
>>    an intercept, tproxy, accel, or ssl-bump parameter)?
>> A: Yes. The https_port directive supports the default (i.e. forward
>>    proxy) mode.
>>
>> Q: What happens when https_port is used without an explicit mode?
>> A: Traffic on such https_port is treated as if Squid was an HTTPS proxy.
>>
>>
>>>> 2) If I need to apply ACL rules to restrict some destinations, I'm
>>>> supposed to use bump_ssl.
>>>
>>> without bumping, you can only see the destination host:port and possible
>>> hostname sent in the SNI request and contents of the SSL certificate.
>>
>> Again, it is difficult to interpret this question correctly. Here are a
>> few versions with correct answers:
>>
>> Q: Can I use ssl_bump with an HTTPS proxy?
>> A: No, that is not supported yet.
>>
>> Q: What ACLs can I use in an HTTPS proxy mode?
>> A: All ACLs that do not require inspecting packets inside
>>    TLS connections from client to origin. Please note that
>>    a single client-origin TLS connection involves two
>>    TCP connections. That inspection is what SslBump does (among
>>    other things). This answer is (too) complex. Unfortunately,
>>    there is currently no documentation that, for every ACL,
>>    details precisely what information sources are required for
>>    that ACL to work. Some ACLs use multiple information sources,
>>    depending on Squid configuration and/or transaction state,
>>    complicating the matters further.
>>
>> Q: Is TLS origin SNI available to Squid ACLs in HTTPS proxy mode?
>> A: No, not today. SslBump features are not yet supported in that mode.
>>
>> Q: Are URL paths of HTTP requests inside CONNECT tunnels
>>    available to Squid ACLS in HTTPS proxy mode?
>> A: No, not today. SslBump features are not yet supported in that mode.
>>
>>
>> HTH,
>>
>> Alex.
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From ronanlucio at gmail.com  Wed May 20 17:38:04 2020
From: ronanlucio at gmail.com (Ronan Lucio)
Date: Thu, 21 May 2020 05:38:04 +1200
Subject: [squid-users] Sending CONNECT method requests over HTTPS
In-Reply-To: <d87832fb-acac-4721-ec10-88a8fba0735c@measurement-factory.com>
References: <CAF-5T9E7eRo=pTftE7ZjTeTDNFjhFEnLQP9YzFzf3F7HEY7Ncg@mail.gmail.com>
 <20200520100747.GB4558@fantomas.sk>
 <4666633b-9f98-5111-119e-43201d80b51b@measurement-factory.com>
 <CAF-5T9GAudOSLB-D=aB3rCdF6=gZ7tR+60OS20PPZVcDWuAVNA@mail.gmail.com>
 <d87832fb-acac-4721-ec10-88a8fba0735c@measurement-factory.com>
Message-ID: <CAF-5T9HCN5ksTUhBvCLR3OWKiKoiASgneUHWKaBocqYd5DKeKA@mail.gmail.com>

Hi Alex,

> > My scenario is:
> > I have a serverless API that needs to connect to a couple specific
> > targets from a static IP.
> > As this serverless API doesn't have a static IP, I thought to do this
> > through a proxy server.
> > That's why I need to enforce security on the authentication layer.
>
> And, I presume, you do not trust the API to only request what it should.
> If you trust the API, then you do not need the allowed_target check.
>
> Also, if possible, consider using certificate-based authentication
> rather than HTTP authentication to authenticate your clients to Squid.
> Certificate-based authentication happens earlier, before Squid has to
> deal with all the dangers of HTTP negotiations.

That's a good point.
First, I can trust the requester API, but I can't trust the source
network, it's on the cloud and sure it has other applications in the
same public network.
I also plan to send these requests through NAT from a static IP, so I
can accept requests only from a specific IP.

The idea of using Certificate-based authentication is really good.
Is it possible to do this between client-squid or do you mean
client-to-other-end?

Thanks
Ronan


From rousskov at measurement-factory.com  Wed May 20 19:54:36 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 20 May 2020 15:54:36 -0400
Subject: [squid-users] Sending CONNECT method requests over HTTPS
In-Reply-To: <CAF-5T9HCN5ksTUhBvCLR3OWKiKoiASgneUHWKaBocqYd5DKeKA@mail.gmail.com>
References: <CAF-5T9E7eRo=pTftE7ZjTeTDNFjhFEnLQP9YzFzf3F7HEY7Ncg@mail.gmail.com>
 <20200520100747.GB4558@fantomas.sk>
 <4666633b-9f98-5111-119e-43201d80b51b@measurement-factory.com>
 <CAF-5T9GAudOSLB-D=aB3rCdF6=gZ7tR+60OS20PPZVcDWuAVNA@mail.gmail.com>
 <d87832fb-acac-4721-ec10-88a8fba0735c@measurement-factory.com>
 <CAF-5T9HCN5ksTUhBvCLR3OWKiKoiASgneUHWKaBocqYd5DKeKA@mail.gmail.com>
Message-ID: <13e84236-14db-cf77-0dcd-a6a43d1d7401@measurement-factory.com>

On 5/20/20 1:38 PM, Ronan Lucio wrote:
>>> My scenario is:
>>> I have a serverless API that needs to connect to a couple specific
>>> targets from a static IP.
>>> As this serverless API doesn't have a static IP, I thought to do this
>>> through a proxy server.
>>> That's why I need to enforce security on the authentication layer.


>> And, I presume, you do not trust the API to only request what it should.
>> If you trust the API, then you do not need the allowed_target check.
>>
>> Also, if possible, consider using certificate-based authentication
>> rather than HTTP authentication to authenticate your clients to Squid.
>> Certificate-based authentication happens earlier, before Squid has to
>> deal with all the dangers of HTTP negotiations.


> I can't trust the source network, it's on the cloud and sure it has
> other applications in the same public network. I also plan to send
> these requests through NAT from a static IP, so I can accept requests
> only from a specific IP.

That is fine, but, FWIW, the above does not justify the need for the
allowed_target check AFAICT. It only justifies the need for authentication.


> The idea of using Certificate-based authentication is really good.
> Is it possible to do this between client-squid or do you mean
> client-to-other-end?

Certificate-based authentication works between any two TLS agents that
support it. Squid supports it on the https_port.

If the client and the origin server (what you called the "other" end)
also support it, then the client can authenticate itself to both Squid
and the origin server. Please note that in this case, there will be two
(partially concurrent) TLS connections and two (sequential)
authentications going on -- Squid cannot "forward" certificate-based
authentication (and, without bumping, cannot modify the client-origin
TLS connection, including the TLS client Hello message that contains the
client certificate).


HTH,

Alex.


From ronanlucio at gmail.com  Wed May 20 23:39:25 2020
From: ronanlucio at gmail.com (Ronan Lucio)
Date: Thu, 21 May 2020 11:39:25 +1200
Subject: [squid-users] Sending CONNECT method requests over HTTPS
In-Reply-To: <13e84236-14db-cf77-0dcd-a6a43d1d7401@measurement-factory.com>
References: <CAF-5T9E7eRo=pTftE7ZjTeTDNFjhFEnLQP9YzFzf3F7HEY7Ncg@mail.gmail.com>
 <20200520100747.GB4558@fantomas.sk>
 <4666633b-9f98-5111-119e-43201d80b51b@measurement-factory.com>
 <CAF-5T9GAudOSLB-D=aB3rCdF6=gZ7tR+60OS20PPZVcDWuAVNA@mail.gmail.com>
 <d87832fb-acac-4721-ec10-88a8fba0735c@measurement-factory.com>
 <CAF-5T9HCN5ksTUhBvCLR3OWKiKoiASgneUHWKaBocqYd5DKeKA@mail.gmail.com>
 <13e84236-14db-cf77-0dcd-a6a43d1d7401@measurement-factory.com>
Message-ID: <CAF-5T9G7AX+7pYD93GWJo+9PqZmty0eUXb91LV6_ObXm-xpTdg@mail.gmail.com>

Hi Alex,

Good news. It's working now fine.
I have it running on https_port and can successfully make requests
using https://proxy.

Just adding some comments:
>> I can't trust the source network, it's on the cloud and sure it has
>> other applications in the same public network. I also plan to send
>> these requests through NAT from a static IP, so I can accept requests
>> only from a specific IP.
>
> That is fine, but, FWIW, the above does not justify the need for the
> allowed_target check AFAICT. It only justifies the need for authentication

For sure. I like to add additional security layers.

Thank you very much for your time and special attention.

Cheers,
Ronan

On Thu, May 21, 2020 at 7:54 AM Alex Rousskov
<rousskov at measurement-factory.com> wrote:
>
> On 5/20/20 1:38 PM, Ronan Lucio wrote:
> >>> My scenario is:
> >>> I have a serverless API that needs to connect to a couple specific
> >>> targets from a static IP.
> >>> As this serverless API doesn't have a static IP, I thought to do this
> >>> through a proxy server.
> >>> That's why I need to enforce security on the authentication layer.
>
>
> >> And, I presume, you do not trust the API to only request what it should.
> >> If you trust the API, then you do not need the allowed_target check.
> >>
> >> Also, if possible, consider using certificate-based authentication
> >> rather than HTTP authentication to authenticate your clients to Squid.
> >> Certificate-based authentication happens earlier, before Squid has to
> >> deal with all the dangers of HTTP negotiations.
>
>
> > I can't trust the source network, it's on the cloud and sure it has
> > other applications in the same public network. I also plan to send
> > these requests through NAT from a static IP, so I can accept requests
> > only from a specific IP.
>
> That is fine, but, FWIW, the above does not justify the need for the
> allowed_target check AFAICT. It only justifies the need for authentication.
>
>
> > The idea of using Certificate-based authentication is really good.
> > Is it possible to do this between client-squid or do you mean
> > client-to-other-end?
>
> Certificate-based authentication works between any two TLS agents that
> support it. Squid supports it on the https_port.
>
> If the client and the origin server (what you called the "other" end)
> also support it, then the client can authenticate itself to both Squid
> and the origin server. Please note that in this case, there will be two
> (partially concurrent) TLS connections and two (sequential)
> authentications going on -- Squid cannot "forward" certificate-based
> authentication (and, without bumping, cannot modify the client-origin
> TLS connection, including the TLS client Hello message that contains the
> client certificate).
>
>
> HTH,
>
> Alex.


From 0xff1f at gmail.com  Thu May 21 00:03:02 2020
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Thu, 21 May 2020 03:03:02 +0300
Subject: [squid-users] Squid marking QOS and matching marks with linux
	iptables problem !
Message-ID: <88B0E012-762D-4023-9AE8-4AB69398A5CA@gmail.com>

Hello Folks ,

Im trying to mark outgoing squid request based on Mark linux matching .

I added to squid conf :

qos_flows mark local-hit=0xd7
qos_flows mark local-miss=0xd7

-A OUTPUT -m mark --mark 0xd7 -j ACCEPT

But on iptables there is no match with the mark 0xd7 


Im testing  marking with squid and matching with iptables  but its not matching , always statistics = 0 on linux iptables  That mean  its not matched .

Squid version is 4.8
Also squid was complied with '--enable-zph-qos? flag 

So not sure if I need specific config for squid .

Following :

https://wiki.squid-cache.org/Features/QualityOfService

Based on it we need kernel patch for TOS , but I dont need TOS ,  I just need Layer 3 DSP , Linux mark rule based .


i even tried to match traffic by mark and connmark and both did not help .

-A OUTPUT -m mark --mark 0xd7 -j ACCEPT
-A OUTPUT -m connmark --mark 0xd4 -j ACCEPT


So both rules above was not able to pickup squid marking .

Any helping Team on this case ?


Thank you 

From davidsiao0514 at gmail.com  Thu May 21 09:35:20 2020
From: davidsiao0514 at gmail.com (david770514)
Date: Thu, 21 May 2020 04:35:20 -0500 (CDT)
Subject: [squid-users] Squid does not cache file download by FileZilla and
 apache FTPCLIENT
Message-ID: <1590053720044-0.post@n4.nabble.com>

Hello everyone,

I need to implement FTP transfer via Squid proxy.
I use Web browser (Firefox, IE) to download file by my PC after the PC
already set the proxy server from Windows setting. The message in store.log
shows Squid has cached the file on it properly.

The problem is it isn't working when I use "FileZilla" or
"apache.commons.net.ftp.FTPHTTPClient" to download file. I still be able to
download the file from FTP server via Squid proxy, but Squid won't cache the
file. I can't get message about the cache in store.log file.

I tried set proxy server in FileZilla directly(don't set proxy on windows),
and it still not cache, only download the file. Do I need have some special
setting on FTPHTTPClient to make it happen?

Is there anyone can help me?



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Thu May 21 11:11:17 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 May 2020 23:11:17 +1200
Subject: [squid-users] Squid does not cache file download by FileZilla
 and apache FTPCLIENT
In-Reply-To: <1590053720044-0.post@n4.nabble.com>
References: <1590053720044-0.post@n4.nabble.com>
Message-ID: <5fc39877-fa2a-4e2d-c739-3a024d2a3b4d@treenet.co.nz>

On 21/05/20 9:35 pm, david770514 wrote:
> Hello everyone,
> 
> I need to implement FTP transfer via Squid proxy.
> I use Web browser (Firefox, IE) to download file by my PC after the PC
> already set the proxy server from Windows setting. The message in store.log
> shows Squid has cached the file on it properly.
> 
> The problem is it isn't working when I use "FileZilla" or
> "apache.commons.net.ftp.FTPHTTPClient" to download file. I still be able to
> download the file from FTP server via Squid proxy, but Squid won't cache the
> file. I can't get message about the cache in store.log file.
> 
> I tried set proxy server in FileZilla directly(don't set proxy on windows),
> and it still not cache, only download the file. Do I need have some special
> setting on FTPHTTPClient to make it happen?
> 
> Is there anyone can help me?
> 

Look at what requests is Squid seeing in access.log when you do these
downloads. Then find out what type of messaging the various settings in
that "apache.commons.net.ftp." config do.

* FTP sent as CONNECT tunnels through the proxy cannot be cached.

* FTP Native relay feature of Squid does not yet support caching IIRC.

* FTP sent as ftp:// URLs through the proxy should cache in accordance
with whatever details Squid is able to fetch from the FTP server about
file creation and modification times vs the Cache-Control limits sent by
the client.


Amos


From 0xff1f at gmail.com  Sat May 23 13:17:07 2020
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Sat, 23 May 2020 16:17:07 +0300
Subject: [squid-users] Squid marking QOS and matching marks with linux
 iptables problem !
In-Reply-To: <88B0E012-762D-4023-9AE8-4AB69398A5CA@gmail.com>
References: <88B0E012-762D-4023-9AE8-4AB69398A5CA@gmail.com>
Message-ID: <C1C6B46A-8DE6-433E-A0DD-E4AE88F03893@gmail.com>

Hello Folks , any one in the mailing list can help me on the case ?

Thanks 


> On May 21, 2020, at 3:03 AM, Ahmad Alzaeem <0xff1f at gmail.com> wrote:
> 
> Hello Folks ,
> 
> Im trying to mark outgoing squid request based on Mark linux matching .
> 
> I added to squid conf :
> 
> qos_flows mark local-hit=0xd7
> qos_flows mark local-miss=0xd7
> 
> -A OUTPUT -m mark --mark 0xd7 -j ACCEPT
> 
> But on iptables there is no match with the mark 0xd7 
> 
> 
> Im testing  marking with squid and matching with iptables  but its not matching , always statistics = 0 on linux iptables  That mean  its not matched .
> 
> Squid version is 4.8
> Also squid was complied with '--enable-zph-qos? flag 
> 
> So not sure if I need specific config for squid .
> 
> Following :
> 
> https://wiki.squid-cache.org/Features/QualityOfService
> 
> Based on it we need kernel patch for TOS , but I dont need TOS ,  I just need Layer 3 DSP , Linux mark rule based .
> 
> 
> i even tried to match traffic by mark and connmark and both did not help .
> 
> -A OUTPUT -m mark --mark 0xd7 -j ACCEPT
> -A OUTPUT -m connmark --mark 0xd4 -j ACCEPT
> 
> 
> So both rules above was not able to pickup squid marking .
> 
> Any helping Team on this case ?
> 
> 
> Thank you



From ngtech1ltd at gmail.com  Sun May 24 00:15:58 2020
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Sun, 24 May 2020 03:15:58 +0300
Subject: [squid-users] Squid marking QOS and matching marks with linux
 iptables problem !
Message-ID: <5ec9bcc1.1c69fb81.9ced1.a755@mx.google.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200524/e9aba868/attachment.htm>

From 0xff1f at gmail.com  Sun May 24 00:17:45 2020
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Sun, 24 May 2020 03:17:45 +0300
Subject: [squid-users] Squid marking QOS and matching marks with linux
 iptables problem !
In-Reply-To: <5ec9bcc1.1c69fb81.9ced1.a755@mx.google.com>
References: <5ec9bcc1.1c69fb81.9ced1.a755@mx.google.com>
Message-ID: <D63795EB-7071-41EB-8A3A-F943A0E4B55C@gmail.com>

Tested on both OS below :

Centos 7.7  64 bits  & Centos 6.10


Same result , squid is not marking traffic .

Is there a way to run squid into debug mode and debug to see if its making DSCP or not ?



Thanks 



> On May 24, 2020, at 3:15 AM, Eliezer Croitoru <ngtech1ltd at gmail.com> wrote:
> 
> What OS?
>  
> Sent from Mail <https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10
>  
> From: Ahmad Alzaeem <mailto:0xff1f at gmail.com>
> Sent: Saturday, May 23, 2020 11:40 PM
> To: Squid Users <mailto:squid-users at lists.squid-cache.org>
> Subject: Re: [squid-users] Squid marking QOS and matching marks with linux iptables problem !
>  
> Hello Folks , any one in the mailing list can help me on the case ?
>  
> Thanks 
>  
>  
> > On May 21, 2020, at 3:03 AM, Ahmad Alzaeem <0xff1f at gmail.com <mailto:0xff1f at gmail.com>> wrote:
> > 
> > Hello Folks ,
> > 
> > Im trying to mark outgoing squid request based on Mark linux matching .
> > 
> > I added to squid conf :
> > 
> > qos_flows mark local-hit=0xd7
> > qos_flows mark local-miss=0xd7
> > 
> > -A OUTPUT -m mark --mark 0xd7 -j ACCEPT
> > 
> > But on iptables there is no match with the mark 0xd7 
> > 
> > 
> > Im testing  marking with squid and matching with iptables  but its not matching , always statistics = 0 on linux iptables  That mean  its not matched .
> > 
> > Squid version is 4.8
> > Also squid was complied with '--enable-zph-qos? flag 
> > 
> > So not sure if I need specific config for squid .
> > 
> > Following :
> > 
> > https://wiki.squid-cache.org/Features/QualityOfService <https://wiki.squid-cache.org/Features/QualityOfService>
> > 
> > Based on it we need kernel patch for TOS , but I dont need TOS ,  I just need Layer 3 DSP , Linux mark rule based .
> > 
> > 
> > i even tried to match traffic by mark and connmark and both did not help .
> > 
> > -A OUTPUT -m mark --mark 0xd7 -j ACCEPT
> > -A OUTPUT -m connmark --mark 0xd4 -j ACCEPT
> > 
> > 
> > So both rules above was not able to pickup squid marking .
> > 
> > Any helping Team on this case ?
> > 
> > 
> > Thank you
>  
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
> http://lists.squid-cache.org/listinfo/squid-users <http://lists.squid-cache.org/listinfo/squid-users>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200524/1f20bdcf/attachment.htm>

From joshuakronemeyer at gmail.com  Sun May 24 03:31:35 2020
From: joshuakronemeyer at gmail.com (Joshua Bazgrim)
Date: Sat, 23 May 2020 20:31:35 -0700
Subject: [squid-users] SMP + Ssl-Bump squid-tls_session_cache.shm
Message-ID: <CAF1CunTW5+7MTdaAVceWDSF7bUdy3nCXh1EEKvjzcJ3GYUhuxw@mail.gmail.com>

Squid 4.9
Ubuntu 18.04.03

I'm trying to implement ssl-bumping into the frontend of a squid smp setup,
but I keep getting the following error:
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-tls_session_cache.shm): (2) No such file or directory

shm is working correctly and generating/reading from other squid shm files,
but not properly generating this file upon start-up in SMP mode.

My ssl-bump configuration works fine in non-smp mode.
I'm guessing it's some sort of race condition to do with improperly setup
config files for ssl-bumping, but unsure of how to correct it.

Thanks in advance

########## squid.conf #########

debug_options ALL,3
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 0.0.0.1-0.255.255.255 # RFC 1122 "this" network (LAN)
acl localnet src 10.0.0.0/8 # RFC 1918 local private network (LAN)
acl localnet src 100.64.0.0/10 # RFC 6598 shared address space (CGN)
acl localhet src 169.254.0.0/16 # RFC 3927 link-local (directly plugged)
machines
acl localnet src 172.16.0.0/12 # RFC 1918 local private network (LAN)
acl localnet src 192.168.0.0/16 # RFC 1918 local private network (LAN)
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10       # RFC 4291 link-local (directly plugged)
machines

acl SSL_ports port 443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
#http_access allow localhost manager
#http_access deny manager

# Set cache user
cache_effective_user nobody

workers 3
if ${process_number} = 1
include /etc/squid/frontend.conf
else
include /etc/squid/backend.conf
endif

http_access deny all

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320


####### frontend.conf - some names changed/omitted##########
# Squid normally listens to port 3128
http_port 3128 ssl-bump \
cert=/etc/squid/ssl_cert/mycert.pem \
key=/etc/squid/ssl_cert/mycert.pem \
generate-host-certificates=on \
dynamic_cert_mem_cache_size=4mb

# Where to look for ssl cert
sslcrtd_program /usr/lib/squid/security_file_certgen -s
/var/lib/squid/ssl_db -M 4MB
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all

# Enable URL Params
strip_query_terms off

# add user authentication and similar options here
http_access allow manager localhost
http_access deny manager

http_access allow localnet
http_access allow localhost

# add backends - one line for each additional worker you configured
# NOTE how the port number matches the kid number
cache_peer localhost parent 4002 0 carp login=PASS name=backend-kid2
cache_peer localhost parent 4003 0 carp login=PASS name=backend-kid3

#you want the frontend to have a significant cache_mem
cache_mem 512 MB

# change /tmp to your own log directory, e.g. /var/log/squid
access_log /var/log/squid/frontend.access.log
cache_log /var/log/squid/frontend.cache.log

# the frontend requires a different name to the backend(s)
visible_hostname Squid-Test

########## backend.conf #############
# each backend must listen on a unique port
# without this the CARP algorithm would be useless
http_port 400${process_number}

# TODO: Change 512 to larger after testing is done
cache_dir rock /var/log/squid/cacheRock 512 max-size=32768

# NP: for now AUFS does not support SMP but the CARP algorithm helps reduce
object duplications
# TODO: Change 512 to larger after testing is done
cache_dir aufs /var/log/squid/cache${process_number} 512 128 128
min-size=32769

# the default maximum cached object size is a bit small
# you want the backend to be able to cache some fairly large objects
maximum_object_size 512 MB

# you want the backend to have a small cache_mem
cache_mem 4 MB

# the backends require a different name to frontends, but can share one
# this prevents forwarding loops between backends while allowing
# frontend to forward via the backend
visible_hostname Squid-Test${process_number}

# change /var/log/squid to your own log directory
access_log /var/log/squid/backend${process_number}.access.log
cache_log /var/log/squid/backend${process_number}.cache.log

# add just enough access permissions to allow the frontend
http_access allow localhost
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200523/7683df69/attachment.htm>

From ngtech1ltd at gmail.com  Sun May 24 05:56:44 2020
From: ngtech1ltd at gmail.com (NgTech LTD)
Date: Sun, 24 May 2020 08:56:44 +0300
Subject: [squid-users] SMP + Ssl-Bump squid-tls_session_cache.shm
In-Reply-To: <CAF1CunTW5+7MTdaAVceWDSF7bUdy3nCXh1EEKvjzcJ3GYUhuxw@mail.gmail.com>
References: <CAF1CunTW5+7MTdaAVceWDSF7bUdy3nCXh1EEKvjzcJ3GYUhuxw@mail.gmail.com>
Message-ID: <CABA8h=RaD648twgccEkKgr4eEagb=CJZbSJgUbEry08DjmxP=Q@mail.gmail.com>

can you send the output of:
squid -v

Eliezer

On Sun, May 24, 2020, 06:31 Joshua Bazgrim <joshuakronemeyer at gmail.com>
wrote:

> Squid 4.9
> Ubuntu 18.04.03
>
> I'm trying to implement ssl-bumping into the frontend of a squid smp
> setup, but I keep getting the following error:
> FATAL: Ipc::Mem::Segment::open failed to
> shm_open(/squid-tls_session_cache.shm): (2) No such file or directory
>
> shm is working correctly and generating/reading from other squid shm
> files, but not properly generating this file upon start-up in SMP mode.
>
> My ssl-bump configuration works fine in non-smp mode.
> I'm guessing it's some sort of race condition to do with improperly setup
> config files for ssl-bumping, but unsure of how to correct it.
>
> Thanks in advance
>
> ########## squid.conf #########
>
> debug_options ALL,3
> #
> # Recommended minimum configuration:
> #
>
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 0.0.0.1-0.255.255.255 # RFC 1122 "this" network (LAN)
> acl localnet src 10.0.0.0/8 # RFC 1918 local private network (LAN)
> acl localnet src 100.64.0.0/10 # RFC 6598 shared address space (CGN)
> acl localhet src 169.254.0.0/16 # RFC 3927 link-local (directly plugged)
> machines
> acl localnet src 172.16.0.0/12 # RFC 1918 local private network (LAN)
> acl localnet src 192.168.0.0/16 # RFC 1918 local private network (LAN)
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10       # RFC 4291 link-local (directly plugged)
> machines
>
> acl SSL_ports port 443
> acl Safe_ports port 80 # http
> acl Safe_ports port 21 # ftp
> acl Safe_ports port 443 # https
> acl Safe_ports port 70 # gopher
> acl Safe_ports port 210 # wais
> acl Safe_ports port 1025-65535 # unregistered ports
> acl Safe_ports port 280 # http-mgmt
> acl Safe_ports port 488 # gss-http
> acl Safe_ports port 591 # filemaker
> acl Safe_ports port 777 # multiling http
> acl CONNECT method CONNECT
>
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
>
> # Only allow cachemgr access from localhost
> #http_access allow localhost manager
> #http_access deny manager
>
> # Set cache user
> cache_effective_user nobody
>
> workers 3
> if ${process_number} = 1
> include /etc/squid/frontend.conf
> else
> include /etc/squid/backend.conf
> endif
>
> http_access deny all
>
> #
> # Add any of your own refresh_pattern entries above these.
> #
> refresh_pattern ^ftp: 1440 20% 10080
> refresh_pattern ^gopher: 1440 0% 1440
> refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
> refresh_pattern . 0 20% 4320
>
>
> ####### frontend.conf - some names changed/omitted##########
> # Squid normally listens to port 3128
> http_port 3128 ssl-bump \
> cert=/etc/squid/ssl_cert/mycert.pem \
> key=/etc/squid/ssl_cert/mycert.pem \
> generate-host-certificates=on \
> dynamic_cert_mem_cache_size=4mb
>
> # Where to look for ssl cert
> sslcrtd_program /usr/lib/squid/security_file_certgen -s
> /var/lib/squid/ssl_db -M 4MB
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump bump all
>
> # Enable URL Params
> strip_query_terms off
>
> # add user authentication and similar options here
> http_access allow manager localhost
> http_access deny manager
>
> http_access allow localnet
> http_access allow localhost
>
> # add backends - one line for each additional worker you configured
> # NOTE how the port number matches the kid number
> cache_peer localhost parent 4002 0 carp login=PASS name=backend-kid2
> cache_peer localhost parent 4003 0 carp login=PASS name=backend-kid3
>
> #you want the frontend to have a significant cache_mem
> cache_mem 512 MB
>
> # change /tmp to your own log directory, e.g. /var/log/squid
> access_log /var/log/squid/frontend.access.log
> cache_log /var/log/squid/frontend.cache.log
>
> # the frontend requires a different name to the backend(s)
> visible_hostname Squid-Test
>
> ########## backend.conf #############
> # each backend must listen on a unique port
> # without this the CARP algorithm would be useless
> http_port 400${process_number}
>
> # TODO: Change 512 to larger after testing is done
> cache_dir rock /var/log/squid/cacheRock 512 max-size=32768
>
> # NP: for now AUFS does not support SMP but the CARP algorithm helps
> reduce object duplications
> # TODO: Change 512 to larger after testing is done
> cache_dir aufs /var/log/squid/cache${process_number} 512 128 128
> min-size=32769
>
> # the default maximum cached object size is a bit small
> # you want the backend to be able to cache some fairly large objects
> maximum_object_size 512 MB
>
> # you want the backend to have a small cache_mem
> cache_mem 4 MB
>
> # the backends require a different name to frontends, but can share one
> # this prevents forwarding loops between backends while allowing
> # frontend to forward via the backend
> visible_hostname Squid-Test${process_number}
>
> # change /var/log/squid to your own log directory
> access_log /var/log/squid/backend${process_number}.access.log
> cache_log /var/log/squid/backend${process_number}.cache.log
>
> # add just enough access permissions to allow the frontend
> http_access allow localhost
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200524/350ad9b0/attachment.htm>

From squid3 at treenet.co.nz  Sun May 24 07:38:32 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 24 May 2020 19:38:32 +1200
Subject: [squid-users] SMP + Ssl-Bump squid-tls_session_cache.shm
In-Reply-To: <CAF1CunTW5+7MTdaAVceWDSF7bUdy3nCXh1EEKvjzcJ3GYUhuxw@mail.gmail.com>
References: <CAF1CunTW5+7MTdaAVceWDSF7bUdy3nCXh1EEKvjzcJ3GYUhuxw@mail.gmail.com>
Message-ID: <1b45b88d-4145-d9b9-9880-1c85ce4d7045@treenet.co.nz>

On 24/05/20 3:31 pm, Joshua Bazgrim wrote:
> Squid 4.9
> Ubuntu 18.04.03
> 
> I'm trying to implement ssl-bumping into the frontend of a squid smp
> setup, but I keep getting the following error:
> FATAL: Ipc::Mem::Segment::open failed to
> shm_open(/squid-tls_session_cache.shm): (2) No such file or directory
> 
> shm is working correctly and generating/reading from other squid shm
> files, but not properly generating this file upon start-up in SMP mode.
> 
> My ssl-bump configuration works fine in non-smp mode.
> I'm guessing it's some sort of race condition to do with improperly
> setup config files for ssl-bumping, but unsure of how to correct it.
> 


The SHM problem is likely an issue between the frontend and coordinator
processes creating and accessing the /dev/shm path with different share
names.


However, you will have a bigger problem using SSL-Bump with this
configuration.
 To cache the traffic requires the frontend to be using TLS to contact
the backends. Which will make the frontend see the backend *proxy*
certificate as the one to be mimic'd instead of the real origin certificate.


You will need to separate these into a full multi-tenant configuration
with SSL-Bump at both layers and interception of traffic leaving the
frontend diverted into the backend.
 <https://wiki.squid-cache.org/MultipleInstances>


Amos


From squid3 at treenet.co.nz  Sun May 24 09:24:34 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 24 May 2020 21:24:34 +1200
Subject: [squid-users] Squid marking QOS and matching marks with linux
 iptables problem !
In-Reply-To: <D63795EB-7071-41EB-8A3A-F943A0E4B55C@gmail.com>
References: <5ec9bcc1.1c69fb81.9ced1.a755@mx.google.com>
 <D63795EB-7071-41EB-8A3A-F943A0E4B55C@gmail.com>
Message-ID: <76423f3c-626b-f9df-9885-8d1f56f0f2a7@treenet.co.nz>

On 24/05/20 12:17 pm, Ahmad Alzaeem wrote:
> Tested on both OS below :
> 
> Centos 7.7 ?64 bits ?& Centos 6.10
> 
> 
> Same result , squid is not marking traffic .
> 
> Is there a way to run squid into debug mode and debug to see if its
> making DSCP or not ?


'mark' are Netfilter MARK values within the local TCP stack. Accessed
with Netfilter conntrack.

'tos' is what sets DSCP values on packets between machines.


DSCP values should remain 0x0 in the config you showed unless you have
iptables rules converting MARK into TOS values.


You can set "debug_options 33,5 17,5 50,5" to see what squid is doing.


Amos


From 3m9n51s2ewut at thismonkey.com  Sun May 24 12:56:46 2020
From: 3m9n51s2ewut at thismonkey.com (Scott)
Date: Sun, 24 May 2020 22:56:46 +1000
Subject: [squid-users] Dumping sslbump'd decrytped http using icap protocol
Message-ID: <20200524125646.GA86132@thismonkey.com>

Hi,

Can someone recommend an ICAP application that will allow me to dump the HTTP 
of a client-server conversation?

I am doing some forensics on an app - I have sslbump configured correctly and 
I can get the traffic to c-icap (for example).

I'd like to dump this to a text file.

Is there a dump option for c-icap?  I couldn't find one.

Thanks,
Scott


From 0xff1f at gmail.com  Sun May 24 16:26:22 2020
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Sun, 24 May 2020 19:26:22 +0300
Subject: [squid-users] Squid marking QOS and matching marks with linux
 iptables problem !
In-Reply-To: <88B0E012-762D-4023-9AE8-4AB69398A5CA@gmail.com>
References: <88B0E012-762D-4023-9AE8-4AB69398A5CA@gmail.com>
Message-ID: <9E9756F7-5532-4F2F-BE07-F22D57F965FF@gmail.com>

Hi Amos , 

Sorry I'm confused a a bit ?

Are my results expected not to work with below :


qos_flows mark local-hit=0xd7
qos_flows mark local-miss=0xd7


-A OUTPUT -m mark --mark 0xd7 -j ACCEPT
-A OUTPUT -m connmark --mark 0xd7 -j ACCEPT

?

Do I need to edit squid/iptables ?


Thanks 


> On May 21, 2020, at 3:03 AM, Ahmad Alzaeem <0xff1f at gmail.com> wrote:
> 
> -A OUTPUT -m mark --mark 0xd7 -j ACCEPT
> -A OUTPUT -m connmark --mark 0xd4 -j ACCEPT

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200524/fd4dbef8/attachment.htm>

From prabu.mohan at outlook.com  Sun May 24 16:29:54 2020
From: prabu.mohan at outlook.com (pmohan)
Date: Sun, 24 May 2020 11:29:54 -0500 (CDT)
Subject: [squid-users] Docker squid container setup
In-Reply-To: <5d730232-39e2-124f-8b99-3285c76da30e@treenet.co.nz>
References: <1582667325630-0.post@n4.nabble.com>
 <5d730232-39e2-124f-8b99-3285c76da30e@treenet.co.nz>
Message-ID: <1590337794019-0.post@n4.nabble.com>

how do you set siblings in a docker swam setup .. squid config has to be
different isnt it ?



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From davidsiao0514 at gmail.com  Mon May 25 06:06:39 2020
From: davidsiao0514 at gmail.com (david770514)
Date: Mon, 25 May 2020 01:06:39 -0500 (CDT)
Subject: [squid-users] Squid does not cache file download by FileZilla
 and apache FTPCLIENT
In-Reply-To: <5fc39877-fa2a-4e2d-c739-3a024d2a3b4d@treenet.co.nz>
References: <1590053720044-0.post@n4.nabble.com>
 <5fc39877-fa2a-4e2d-c739-3a024d2a3b4d@treenet.co.nz>
Message-ID: <1590386799806-0.post@n4.nabble.com>

Hi Amos,

The "apache.commons.net.ftp.FTPHTTPClient" is sent as CONNECT tunnels
through the proxy. Can I make it work through modifying the Squid? Let Squid
can cache file when I sent as CONNECT tunnels through the proxy?



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Mon May 25 06:23:53 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 25 May 2020 18:23:53 +1200
Subject: [squid-users] Docker squid container setup
In-Reply-To: <1590337794019-0.post@n4.nabble.com>
References: <1582667325630-0.post@n4.nabble.com>
 <5d730232-39e2-124f-8b99-3285c76da30e@treenet.co.nz>
 <1590337794019-0.post@n4.nabble.com>
Message-ID: <7ed536f2-8cda-325e-bea7-56850bfa1c44@treenet.co.nz>

On 25/05/20 4:29 am, pmohan wrote:
> how do you set siblings in a docker swam setup .. squid config has to be
> different isnt it ?

That depends on how the containers are configured. Modern Squid use mDNS
or regular DNS name lookup for cache_peer.

So long as the containers have different IPs each, the (m)DNS can
provide those to hostname looks, and your network setup allows them to
communicate there should be no difference between a bunch of VMs,
containers, hardware devices, or any combo you want.


With squid.conf using ${process_name} you could also mix in multi-tenant
instead of containerizing the Squid.


Amos


From squid3 at treenet.co.nz  Mon May 25 06:34:19 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 25 May 2020 18:34:19 +1200
Subject: [squid-users] Dumping sslbump'd decrytped http using icap
 protocol
In-Reply-To: <20200524125646.GA86132@thismonkey.com>
References: <20200524125646.GA86132@thismonkey.com>
Message-ID: <72c95707-e4b4-eb48-b69e-31eea7671574@treenet.co.nz>

On 25/05/20 12:56 am, Scott wrote:
> Hi,
> 
> Can someone recommend an ICAP application that will allow me to dump the HTTP 
> of a client-server conversation?
> 
> I am doing some forensics on an app - I have sslbump configured correctly and 
> I can get the traffic to c-icap (for example).
> 
> I'd like to dump this to a text file.
> 
> Is there a dump option for c-icap?  I couldn't find one.
> 

FYI; this action is illegal in a lot of places. Even answering your
question can be quite risky.


To perform traffic forensics you can use the Squid cache.log directly
and not involve any insecure third-party software or communication
dumps. See <https://wiki.squid-cache.org/KnowledgeBase/DebugSections>
for more details.

"debug_Options 11,2" is probably all you need.


Amos


From squid3 at treenet.co.nz  Mon May 25 06:44:42 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 25 May 2020 18:44:42 +1200
Subject: [squid-users] Squid does not cache file download by FileZilla
 and apache FTPCLIENT
In-Reply-To: <1590386799806-0.post@n4.nabble.com>
References: <1590053720044-0.post@n4.nabble.com>
 <5fc39877-fa2a-4e2d-c739-3a024d2a3b4d@treenet.co.nz>
 <1590386799806-0.post@n4.nabble.com>
Message-ID: <c5b23342-adfd-5923-cd40-a90414ea5230@treenet.co.nz>

On 25/05/20 6:06 pm, david770514 wrote:
> Hi Amos,
> 
> The "apache.commons.net.ftp.FTPHTTPClient" is sent as CONNECT tunnels
> through the proxy. Can I make it work through modifying the Squid? Let Squid
> can cache file when I sent as CONNECT tunnels through the proxy?
> 

Since it uses the tunnel mechanism. No you cannot cache it.

What is inside the tunnel is not just a "file" downloaded. It is a whole
set of FTP messages going back and forth negotiating how the client is
logging into the server (anonymous or not), moving working directory
around within the FTP server and files (possibly more than one)
accessed, metadata about the files, and any temporary TCP connection
details of other tunnels being used for additional pieces of the
communication.

There is simply no way all that stuff can be cached and replayed as-is
to any other client without serious breakage happening.

Sorry, but unless you can find a way to get the client(s) to send Squid
ftp:// URLs requests in HTTP messages there is no caching.

Amos


From squid3 at treenet.co.nz  Mon May 25 06:54:43 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 25 May 2020 18:54:43 +1200
Subject: [squid-users] Bypass squid using iptables
In-Reply-To: <CADAqQfwdpUJ8SQgdrJEczvmtr=SgcvffH_pq+swwx+ay5-fyCA@mail.gmail.com>
References: <CADAqQfwdpUJ8SQgdrJEczvmtr=SgcvffH_pq+swwx+ay5-fyCA@mail.gmail.com>
Message-ID: <915a225e-022f-70a1-d48a-cbdcd2b3b478@treenet.co.nz>

On 21/05/20 3:49 am, Ben Goz wrote:
> B.H.
> 
> I'm using squid with c-icap module for specific content filtering. I
> configured squid with ssl bump so website with WSS won't work on it as
> mentioned on squid documentation. So for such URLs (with WSS) I need
> bypassing squid. I read in some posts that squid doesn't fully supports
> bypassing URLs and best way is to bypasses it via iptables.
> 
> Eventually I redirects browser traffic to my proxy machine using local
> machine proxy settings, and Its redirects traffic to my machine with IP
> x.x.x.x port 3128.
> 
> If I want to use the conservative iptables bypassing how should I config
> my machine? and how iptables rules should looks like?
> 

Since you are redirecting the traffic to Squid in the first place. All
you have to do is *not* redirect the relevant traffic. See your firewall
software documentation on how to configure that.


The hard part is figuring out which traffic you want the proxy to
service, and what to bypass given only a TCP SYN packet.


Be aware that once a TCP SYN+ACK packet is delivered to accept the
connection Squid *has* to service that TCP connection in its entirety.
Such 'service' may mean terminating it without any traffic, tunneling it
elsewhere, or full processing of the traffic.
 Either way Squid is the agent servicing it. You cannot have iptables
suddenly divert packets to other software mid-stream.


HTH
Amos


From squid3 at treenet.co.nz  Mon May 25 07:02:18 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 25 May 2020 19:02:18 +1200
Subject: [squid-users] Squid marking QOS and matching marks with linux
 iptables problem !
In-Reply-To: <9E9756F7-5532-4F2F-BE07-F22D57F965FF@gmail.com>
References: <88B0E012-762D-4023-9AE8-4AB69398A5CA@gmail.com>
 <9E9756F7-5532-4F2F-BE07-F22D57F965FF@gmail.com>
Message-ID: <79d33dc5-e086-aa80-82a7-4439fd0948e1@treenet.co.nz>

[NP: it would help if you replied through the list instead of directly
to me, even as a CC. Your messages keep getting diverted to spam folder. ]

On 25/05/20 4:26 am, Ahmad Alzaeem wrote:
> Hi Amos ,?
> 
> Sorry I'm confused a a bit ?
> 
> Are my results expected not to work with below :
> 
> 
> qos_flows mark local-hit=0xd7
> qos_flows mark local-miss=0xd7
> 
> 
> -A OUTPUT -m mark --mark 0xd7 -j ACCEPT
> -A OUTPUT -m connmark --mark 0xd7 -j ACCEPT
> 
> ?

Squid should be MARK'ing packets with 0xd7.

Those iptables rules should match the packets MARK'ed with 0xd7.

Whether those statements are of any relevance depends on where your
iptables rules are configured in relation to all other rules and chains
your iptables is processing.


> 
> Do I need to edit squid/iptables ?
> 

Probably iptables. But not enough info to say how.


You asked about how to debug Squid MARK'ing earlier. What were the
results of that? did you see Squid doing any marking?


Amos


From m992493 at gmail.com  Mon May 25 07:14:21 2020
From: m992493 at gmail.com (Amiq Nahas)
Date: Mon, 25 May 2020 12:44:21 +0530
Subject: [squid-users] squid configuration with c-icap
Message-ID: <CAPicJaH-3AhR-nUnXmE2n66KkzHOkRDPADbqSbv5B6qF-QxnAA@mail.gmail.com>

Hi Guys,

At this point, I have got squid installed on my system. I think it is
working fine since I can browse the internet by adding a manual proxy
in firefox at localhost:3128.

What I want now is to configure squid such that it passes the request
to c-icap. Something like mentioned in this image
https://postimg.cc/qgsfRbWc

To elaborate, I want to run a squid proxy such that every time the
browser or any other application on a system makes request to a url,
the squid proxy receives it. Then, squid sends it to the c-icap
server. On the c-icap server there would be a custom module (C
program) which takes the url as the input and the custom module will
decide whether the url should be allowed or not.

https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
The link above shows the configuration using squidclamav. I do not
want to use that. I just want squid proxy to send requested urls to
c-icap server after that the c-icap server will decide whether to
block or allow the url. I will handle the block and allow part later.
For now I would like to know about how to configure squid such that
all requests from my system are first given to squid proxy which
further passes it to c-icap.

Thanks
Amiq


From andkuha at gmail.com  Mon May 25 08:09:15 2020
From: andkuha at gmail.com (Andrey Etush-Koukharenko)
Date: Mon, 25 May 2020 11:09:15 +0300
Subject: [squid-users] Squid cache with SSL
Message-ID: <CADCth7zsf+ghRWY3SiUzy4mtC=8-fUjaCnuQdGu=Ta1aCEW7mw@mail.gmail.com>

Hello, I'm trying to set up a cache for GCP signed URLs using squid 4.10
I've set ssl_bump:







*http_port 3128 ssl-bump cert=/etc/ssl/squid_ca.pem
generate-host-certificates=on
dynamic_cert_mem_cache_size=4MBsslcrtd_program
/usr/lib/squid/security_file_certgen -s /var/lib/ssl_db -M 4MBacl step1
at_step SslBump1ssl_bump peek step1ssl_bump bump all*

I've set cache like this:

*refresh_pattern -i my-dev.storage.googleapis.com/.*
<https://urldefense.proofpoint.com/v2/url?u=http-3A__my-2Ddev.storage.googleapis.com_.-2A&d=DwMFaQ&c=V9IgWpI5PvzTw83UyHGVSoW3Uc1MFWe5J8PTfkrzVSo&r=1mJtF4AWJIR5drMqecglyWB1YONyKEwvGYJOP89bCno&m=e5WrWef5AGz1A3EyZZJIgADr8-CyXnjTF4-XlKUORFo&s=GVr7hG6qzdEYkhWWvj2u4y7qLxXUiOY6Yg_o-EmQaV8&e=>
4320 80% 43200 override-expire ignore-reload ignore-no-store ignore-private*

In the cache directory, I see that object was stored after the first call,
but when I try to re-run the URL I get always get:
*TCP_REFRESH_UNMODIFIED_ABORTED/200*

and I get the empty object, I've tried to play with *refresh_pattern *params
but still no luck.

Thanks for your help
Andrey
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200525/08911a99/attachment.htm>

From 0xff1f at gmail.com  Mon May 25 09:25:07 2020
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Mon, 25 May 2020 12:25:07 +0300
Subject: [squid-users] Squid marking QOS and matching marks with linux
 iptables problem !
In-Reply-To: <79d33dc5-e086-aa80-82a7-4439fd0948e1@treenet.co.nz>
References: <88B0E012-762D-4023-9AE8-4AB69398A5CA@gmail.com>
 <9E9756F7-5532-4F2F-BE07-F22D57F965FF@gmail.com>
 <79d33dc5-e086-aa80-82a7-4439fd0948e1@treenet.co.nz>
Message-ID: <053E8340-6B3D-4B4D-BD5A-F2FC54119B76@gmail.com>

Here is debug result :



2020/05/25 12:04:58.043 kid1| 33,5| client_side.cc(1375) parseHttpRequest: Prepare absolute URL from 
2020/05/25 12:04:58.043 kid1| 33,5| client_side.cc(2106) clientParseRequests: local=45.150.17.10:3128 remote=50.254.22.18:62916 FD 540 flags=1: done parsing a request
2020/05/25 12:04:58.043 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x43d98a0 add request 1 0x41e43f0*4
2020/05/25 12:04:58.043 kid1| 33,5| Http1Server.cc(188) buildHttpRequest: normalize 1 Host header using analytics.yopify.com:443
2020/05/25 12:04:58.043 kid1| 33,3| client_side.cc(641) clientSetKeepaliveFlag: http_ver = HTTP/1.1
2020/05/25 12:04:58.043 kid1| 33,3| client_side.cc(642) clientSetKeepaliveFlag: method = CONNECT
2020/05/25 12:04:58.043 kid1| 33,3| http/Stream.h(141) mayUseConnection: This 0x41e43f0 marked 1
2020/05/25 12:04:58.043 kid1| 50,3| comm.cc(946) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 8 using Port 55332
2020/05/25 12:04:58.043 kid1| 50,3| comm.cc(946) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 8.8.8.8:53 using FD 8 using Port 55332
2020/05/25 12:04:58.043 kid1| 33,3| client_side.cc(2119) clientParseRequests: Not parsing new requests, as this request may need the connection
2020/05/25 12:04:58.044 kid1| 33,5| AsyncJob.cc(154) callEnd: Http1::Server status out: [ job690]
2020/05/25 12:04:58.044 kid1| 33,5| AsyncCallQueue.cc(57) fireNext: leaving Server::doClientRead(local=45.150.17.10:3128 remote=50.254.22.18:62916 FD 540 flags=1, data=0x43d9858)
2020/05/25 12:04:58.056 kid1| 17,3| FwdState.cc(1339) GetMarkingsToServer: from 45.150.17.10 netfilter mark 0
2020/05/25 12:04:58.056 kid1| 50,3| comm.cc(350) comm_openex: comm_openex: Attempt open socket for: 45.150.17.10
2020/05/25 12:04:58.056 kid1| 50,3| comm.cc(393) comm_openex: comm_openex: Opened socket local=45.150.17.10 remote=[::] FD 542 flags=1 : family=2, type=1, protocol=6
2020/05/25 12:04:58.064 kid1| 33,4| client_side.cc(2510) httpAccept: local=45.150.17.10:3128 remote=50.254.22.18:62917 FD 543 flags=1: accepted
2020/05/25 12:04:58.064 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall ConnStateData::connStateClosed constructed, this=0x4024ec0 [call6687]
2020/05/25 12:04:58.064 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall Http1::Server::requestTimeout constructed, this=0x422ab40 [call6688]
2020/05/25 12:04:58.064 kid1| 33,4| Server.cc(90) readSomeData: local=45.150.17.10:3128 remote=50.254.22.18:62917 FD 543 flags=1: reading request...
2020/05/25 12:04:58.064 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall Server::doClientRead constructed, this=0x4025c50 [call6689]



I see mark 0 and mark 1 , Dont see any 0xd7 or so .

Thanks 

> On May 25, 2020, at 10:02 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> [NP: it would help if you replied through the list instead of directly
> to me, even as a CC. Your messages keep getting diverted to spam folder. ]
> 
> On 25/05/20 4:26 am, Ahmad Alzaeem wrote:
>> Hi Amos , 
>> 
>> Sorry I'm confused a a bit ?
>> 
>> Are my results expected not to work with below :
>> 
>> 
>> qos_flows mark local-hit=0xd7
>> qos_flows mark local-miss=0xd7
>> 
>> 
>> -A OUTPUT -m mark --mark 0xd7 -j ACCEPT
>> -A OUTPUT -m connmark --mark 0xd7 -j ACCEPT
>> 
>> ?
> 
> Squid should be MARK'ing packets with 0xd7.
> 
> Those iptables rules should match the packets MARK'ed with 0xd7.
> 
> Whether those statements are of any relevance depends on where your
> iptables rules are configured in relation to all other rules and chains
> your iptables is processing.
> 
> 
>> 
>> Do I need to edit squid/iptables ?
>> 
> 
> Probably iptables. But not enough info to say how.
> 
> 
> You asked about how to debug Squid MARK'ing earlier. What were the
> results of that? did you see Squid doing any marking?
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
> http://lists.squid-cache.org/listinfo/squid-users <http://lists.squid-cache.org/listinfo/squid-users>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200525/daeeb6c9/attachment.htm>

From squid3 at treenet.co.nz  Mon May 25 09:26:11 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 25 May 2020 21:26:11 +1200
Subject: [squid-users] squid configuration with c-icap
In-Reply-To: <CAPicJaH-3AhR-nUnXmE2n66KkzHOkRDPADbqSbv5B6qF-QxnAA@mail.gmail.com>
References: <CAPicJaH-3AhR-nUnXmE2n66KkzHOkRDPADbqSbv5B6qF-QxnAA@mail.gmail.com>
Message-ID: <ad26c2e3-7ffe-cbb7-b525-b8a22ec0d20b@treenet.co.nz>

On 25/05/20 7:14 pm, Amiq Nahas wrote:
> Hi Guys,
> 
> At this point, I have got squid installed on my system. I think it is
> working fine since I can browse the internet by adding a manual proxy
> in firefox at localhost:3128.
> 
> What I want now is to configure squid such that it passes the request
> to c-icap. Something like mentioned in this image
> https://postimg.cc/qgsfRbWc
> 
> To elaborate, I want to run a squid proxy such that every time the
> browser or any other application on a system makes request to a url,
> the squid proxy receives it. Then, squid sends it to the c-icap
> server. On the c-icap server there would be a custom module (C
> program) which takes the url as the input and the custom module will
> decide whether the url should be allowed or not.

>From that API description there is no need for ICAP which is a very
processing-expensive system.

A simple external ACL helper can perform exactly what you describe far
more efficiently.

Like so:

 external_acl_type urlChecker %>ru /path/to/helper
 acl urlCheck external urlChecker
 http_access deny !urlCheck


Useful documentation on the protocol the helper needs to communicate
with Squid can be found at:
 <https://wiki.squid-cache.org/Features/AddonHelpers#Access_Control_.28ACL.29>


> 
> https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
> The link above shows the configuration using squidclamav. I do not
> want to use that.

Squid is just an ICAP client. What C-ICAP uses internally is irrelevant
to Squid. squidclamav is just a module people tend to ask for, so the
example shows it. The squid.conf rules will be the same or similar for
whatever your system has (assuming you stay with ICAP instead of moving
to external ACL for access control).

Amos


From ben.maling42 at gmail.com  Mon May 25 09:59:34 2020
From: ben.maling42 at gmail.com (ben benml)
Date: Mon, 25 May 2020 11:59:34 +0200
Subject: [squid-users] Squid 4.4 https_port and ssl-bump : Fatal bungled line
Message-ID: <CACTby66gbiTxsj6Ftv-ZFwzwmTZSavD3CaoWGSxHWeQAWmGcQA@mail.gmail.com>

Hello,

I'm contacting you for some help.
I need to deploy a secure proxy based on Squid.

I try to use https_port combined with sslbump. I get an error message about
a bungled line.

The reasons I want to do this :
- secure connection between the client browser and the proxy server, so
using https_port to do it. encrypted  traffic in TLS between the client and
the server.
- secure login connection. So I need to use https_port to do this.
Otherwise If I use http_port, the login/password can be read on the network.
- Do ssl inspection of the traffic goeing through the proxy


What I have done with success :
- https_port without sslbump  (traffic between the brownser and the client
is encrypted. The login/password can't be read on the network)
- ssl-bump on http_port. The ssl inspection is working  ... but the
connexion between the browser and the proxy service is not encrypted

But can't get  'https_port 3129 ssl-bump' working.
FATAL: ssl-bump on https_port requires tproxy/intercept which is missing.
FATAL: Bungled squid.conf line 49: https_port 3129 ssl-bump
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
tls-cert=/etc/squid/squid-cert.pem options=SINGLE_DH_USE,SINGLE_ECDH_USE
tls-dh=/etc/squid/dhparam.pem

Is there something  I have misunderstood ? Or doing wrong ?

I have generated the certificate and CA with openssl :
* openssl req -new -newkey rsa:2048 -days 365 -nodes -x509 -keyout
squid-cert.pem -out squid-cert.pem
* openssl x509 -in squid-cert.pem -outform DER -out squid-CA-browser.der
* openssl dhparam -outform PEM -out dhparam.pem 2048

Squid version : 4.4 from EPEL on centos 8 with  '--enable-ssl'
'--enable-ssl-crtd' '--with-openssl'

Squid configuration as follow :
===============================================================
auth_param basic program /usr/lib64/squid/basic_ncsa_auth
/etc/squid/htpasswd
auth_param basic children 10
auth_param basic realm Squid proxy-caching web server
auth_param basic credentialsttl 2 hours

acl localnet src 0.0.0.1-0.255.255.255
acl localnet src 192.168.0.0/24

acl SSL_ports port 443
acl Safe_ports port 80
acl Safe_ports port 443
acl CONNECT method CONNECT

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

#squid mgmt interface access
http_access allow localhost manager
http_access deny manager

acl auth_users proxy_auth REQUIRED
http_access allow auth_users

http_access allow localnet
http_access allow localhost

#squid mgmt interface access
http_access allow localhost manager
http_access deny manager

#http_access deny to_localhost
http_access deny all

##Many Tests here :
#http_port 3128 ssl-bump cert=/etc/squid/squid-cert.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
#http_port 3128 ssl-bump tls-cert=/etc/squid/squid-cert.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

#http_port 3128 ssl-bump cert=/etc/squid/squid-cert.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
cipher=HIGH:MEDIUM:!LOW:!RC4:!SEED:!IDEA:!3DES:!MD5:!EXP:!PSK:!DSS
options=NO_TLSv1,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

#https_port 3129 cert=/etc/squid/squid-cert.pem
#https_port 3129 tls-cert=/etc/squid/squid-cert.pem

https_port 3129 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB tls-cert=/etc/squid/squid-cert.pem
options=SINGLE_DH_USE,SINGLE_ECDH_USE tls-dh=/etc/squid/dhparam.pem

sslcrtd_program /usr/lib64/squid/security_file_certgen

acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all



tls_outgoing_options min-version=1.0
cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

#LOGS : deux options. Envoie des logs directe
access_log daemon:/var/log/squid/access.log squid
#access_log tcp://[ip]:[port] squid
access_log syslog:local0.info squid
cache_log /var/log/squid/cache.log rotate=10

#Cache
cache_mem 512 MB
cache_dir ufs /var/spool/squid 10000 16 256
coredump_dir /var/spool/squid
===============================================================

Thank you in advance !

Regards,
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200525/789146b2/attachment.htm>

From squid3 at treenet.co.nz  Mon May 25 09:55:00 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 25 May 2020 21:55:00 +1200
Subject: [squid-users] Squid cache with SSL
In-Reply-To: <CADCth7zsf+ghRWY3SiUzy4mtC=8-fUjaCnuQdGu=Ta1aCEW7mw@mail.gmail.com>
References: <CADCth7zsf+ghRWY3SiUzy4mtC=8-fUjaCnuQdGu=Ta1aCEW7mw@mail.gmail.com>
Message-ID: <5b565926-53ea-5a38-53ba-13b93d3ab243@treenet.co.nz>

On 25/05/20 8:09 pm, Andrey Etush-Koukharenko wrote:
> Hello, I'm trying to set up a cache for GCP signed URLs using squid 4.10
> I've set ssl_bump:
> *http_port 3128 ssl-bump cert=/etc/ssl/squid_ca.pem
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> 
> sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/lib/ssl_db
> -M 4MB
> 
> acl step1 at_step SslBump1
> 
> ssl_bump peek step1
> ssl_bump bump all*

The above SSL-Bump configuration tries to auto-generate server
certificates based only on details in the TLS client handshake. This
leads to a huge number of problems, not least of which is completely
breaking TLS security properties.

Prefer doing the bump at step3,


> *
> I've set cache like this:
> 
> *refresh_pattern -i?my-dev.storage.googleapis.com/.* 
> 4320 80% 43200?override-expire ignore-reload ignore-no-store ignore-private*
> *

FYI: that does not setup the cache. It provides *default* parameters for
the heuristic expiry algorithm.

* override-expire replaces the max-age (or Expires header) parameter
with 43200 minutes from object creation.
  This often has the effect of forcing objects to expire from cache long
before they normally would.

* ignore-reload makes Squid ignore requests from the client to update
its cached content.
 This forces content which is stale, outdated, corrupt, or plain wrong
to remain in cache no matter how many times clients try to re-fetch for
a valid response.

* ignore-private makes Squid content that is never supposed to be shared
between clients.
 To prevent personal data being shared between clients who should never
see it Squid will revalidate these objects. Usually different data will
return, making this just a waste of cache space.

* ignore-no-store makes Squid cache objects that are explicitly
*forbidden* to be stored in a cache.
  80% of 0 seconds == 0 seconds before these objects become stale and
expire from cache.

Given that you described this as a problem with an API doing *signing*
of things I expect that at least some of those objects will be security
keys. Possibly generated specifically per-item keys, where forced
caching is a *BAD* idea.

I recommend removing that line entirely from your config file and
letting the Google developers instructions do what they are intended to
do with the cacheability. At the very least start from the default
caching behaviour and see how it works normally before adding protocol
violations and unusual (mis)behvaviours to how the proxy caches things.


> *
> In the cache directory, I see that object was stored after the first
> call, but when I try to re-run the URL I get always
> get:?*TCP_REFRESH_UNMODIFIED_ABORTED/200*

What makes you think anything is going wrong?

 Squid found the object in cache (HIT).
 The object requirements were to check with the origin server about
whether it could still be used (HIT becomes REFRESH).
 The origin server said it was fine to deliver (UNMODIFIED).
 Squid started delivery (status 200).
 The client disconnected before the response could be completed delivery
(ABORTED).

Clients are allowed to disconnect at any time, for any reason.


Amos


From ben.goz87 at gmail.com  Mon May 25 10:09:46 2020
From: ben.goz87 at gmail.com (Ben Goz)
Date: Mon, 25 May 2020 13:09:46 +0300
Subject: [squid-users] Bypass squid using iptables
In-Reply-To: <915a225e-022f-70a1-d48a-cbdcd2b3b478@treenet.co.nz>
References: <CADAqQfwdpUJ8SQgdrJEczvmtr=SgcvffH_pq+swwx+ay5-fyCA@mail.gmail.com>
 <915a225e-022f-70a1-d48a-cbdcd2b3b478@treenet.co.nz>
Message-ID: <CADAqQfwT599AKw71B9QZuCV58EmzATqPDkzvX14NciE6XVMobA@mail.gmail.com>

B.H
>Tunneling it elsewhere,
Where can I tunnel it? and how can I configure my machine to support it?

>You cannot have iptables suddenly divert packets to other software
mid-stream.
I want to tunnel it by IP or translate a group of URLs to IPs I'm not sure
if this is the case that you mentioned,
Because I can do it before squid handles TCP session initialization.

The issue here is as I said that I want bypass WSS and other stuff that
squid can't technically support for known list of IPs (or URLS).
Do you have any recommended configuration for this requirement?

Regards,
Ben
suddenly divert packets to other software mid-stream.

??????? ??? ??, 25 ???? 2020 ?-9:56 ??? ?Amos Jeffries?? <?
squid3 at treenet.co.nz??>:?

> On 21/05/20 3:49 am, Ben Goz wrote:
> > B.H.
> >
> > I'm using squid with c-icap module for specific content filtering. I
> > configured squid with ssl bump so website with WSS won't work on it as
> > mentioned on squid documentation. So for such URLs (with WSS) I need
> > bypassing squid. I read in some posts that squid doesn't fully supports
> > bypassing URLs and best way is to bypasses it via iptables.
> >
> > Eventually I redirects browser traffic to my proxy machine using local
> > machine proxy settings, and Its redirects traffic to my machine with IP
> > x.x.x.x port 3128.
> >
> > If I want to use the conservative iptables bypassing how should I config
> > my machine? and how iptables rules should looks like?
> >
>
> Since you are redirecting the traffic to Squid in the first place. All
> you have to do is *not* redirect the relevant traffic. See your firewall
> software documentation on how to configure that.
>
>
> The hard part is figuring out which traffic you want the proxy to
> service, and what to bypass given only a TCP SYN packet.
>
>
> Be aware that once a TCP SYN+ACK packet is delivered to accept the
> connection Squid *has* to service that TCP connection in its entirety.
> Such 'service' may mean terminating it without any traffic, tunneling it
> elsewhere, or full processing of the traffic.
>  Either way Squid is the agent servicing it. You cannot have iptables
> suddenly divert packets to other software mid-stream.
>
>
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200525/4c91768c/attachment.htm>

From squid3 at treenet.co.nz  Mon May 25 10:15:43 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 25 May 2020 22:15:43 +1200
Subject: [squid-users] Squid marking QOS and matching marks with linux
 iptables problem !
In-Reply-To: <053E8340-6B3D-4B4D-BD5A-F2FC54119B76@gmail.com>
References: <88B0E012-762D-4023-9AE8-4AB69398A5CA@gmail.com>
 <9E9756F7-5532-4F2F-BE07-F22D57F965FF@gmail.com>
 <79d33dc5-e086-aa80-82a7-4439fd0948e1@treenet.co.nz>
 <053E8340-6B3D-4B4D-BD5A-F2FC54119B76@gmail.com>
Message-ID: <3815057c-54a6-79f3-ed87-ad6fa1a02698@treenet.co.nz>

On 25/05/20 9:25 pm, Ahmad Alzaeem wrote:
> Here is debug result :
> 
> 
> 
> 2020/05/25 12:04:58.043 kid1| 33,5| client_side.cc
> <http://client_side.cc>(1375) parseHttpRequest: Prepare absolute URL from?
> 2020/05/25 12:04:58.043 kid1| 33,5| client_side.cc
> <http://client_side.cc>(2106) clientParseRequests:
> local=45.150.17.10:3128 remote=50.254.22.18:62916 FD 540 flags=1: done
> parsing a request

The client connection on FD 540 was open long before this log trace
begins. Any netfilter details fetched are back at the point it was accepted.



> 2020/05/25 12:04:58.043 kid1| 33,3| http/Stream.h(141) mayUseConnection:
> This 0x41e43f0 marked 1

NP: this is a different kind of marking, about whether it is persistent
or not. Not relevant.


...
> 2020/05/25 12:04:58.056 kid1| 17,3| FwdState.cc
> <http://FwdState.cc>(1339) GetMarkingsToServer: from 45.150.17.10
> netfilter mark 0

This 0 mark is what iptables has set on returning packets for the origin
server connection.

That lien existing at least confirms absolutely that the library and
relevant code is built properly - what Eliezer was looking for with the
squid -v request.


> 2020/05/25 12:04:58.056 kid1| 50,3| comm.cc <http://comm.cc>(350)
> comm_openex: comm_openex: Attempt open socket for: 45.150.17.10
> 2020/05/25 12:04:58.056 kid1| 50,3| comm.cc <http://comm.cc>(393)
> comm_openex: comm_openex: Opened socket local=45.150.17.10 remote=[::]
> FD 542 flags=1 : family=2, type=1, protocol=6

New connection opened, but the log snippet ends before the per-message
socket options are updated for the outgoing HTTP request message.

...



To find the most relevant lines look for "doNfmarkLocalHit",
"doNfmarkLocalMiss" and "setSockNfmark".

If there are errors receiving a MARK from iptables
"getNfmarkFromConnection" will show up too.

When you have found the relevant places, use the FD value on those lines
to grep for more details on what is happening on that connection.


Amos


From squid3 at treenet.co.nz  Mon May 25 10:25:21 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 25 May 2020 22:25:21 +1200
Subject: [squid-users] Squid 4.4 https_port and ssl-bump : Fatal bungled
 line
In-Reply-To: <CACTby66gbiTxsj6Ftv-ZFwzwmTZSavD3CaoWGSxHWeQAWmGcQA@mail.gmail.com>
References: <CACTby66gbiTxsj6Ftv-ZFwzwmTZSavD3CaoWGSxHWeQAWmGcQA@mail.gmail.com>
Message-ID: <467d0766-1821-8a25-81cc-dab40188e664@treenet.co.nz>

On 25/05/20 9:59 pm, ben benml wrote:
> Hello,
> 
> I'm contacting you for some help.
> I need to deploy a secure proxy based on Squid.
> 
> I try to use https_port combined with sslbump. I get an error message
> about a bungled line.
> 
> The reasons I want to do this :
> - secure connection between the client browser and the proxy server, so
> using https_port to do it. encrypted? traffic in TLS between the client
> and the server.

Fine. Simply using https_port does that.

> - secure login connection. So I need to use https_port to do this.

Fine. Simply using https_port does that.

> - Do ssl inspection of the traffic goeing through the proxy

Squid does not yet support SSL-Bump decrypt of traffic already being
decrypted for the secure proxy.


Please see
<http://lists.squid-cache.org/pipermail/squid-users/2020-May/022120.html> if
you want details.

Amos


From squid3 at treenet.co.nz  Mon May 25 10:38:32 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 25 May 2020 22:38:32 +1200
Subject: [squid-users] Bypass squid using iptables
In-Reply-To: <CADAqQfwT599AKw71B9QZuCV58EmzATqPDkzvX14NciE6XVMobA@mail.gmail.com>
References: <CADAqQfwdpUJ8SQgdrJEczvmtr=SgcvffH_pq+swwx+ay5-fyCA@mail.gmail.com>
 <915a225e-022f-70a1-d48a-cbdcd2b3b478@treenet.co.nz>
 <CADAqQfwT599AKw71B9QZuCV58EmzATqPDkzvX14NciE6XVMobA@mail.gmail.com>
Message-ID: <47a37011-2a32-bb50-0687-3d81ae7c8066@treenet.co.nz>

On 25/05/20 10:09 pm, Ben Goz wrote:
> B.H
>>Tunneling it elsewhere,
> Where can I tunnel it? and how can I configure my machine to support it?
> 

You will need at least Squid-4, with this line in squid.conf:

  on_unsupported_protocol tunnel

see also <http://www.squid-cache.org/Doc/config/on_unsupported_protocol/>

Squid will blindly tunnel the protocols it does not understand to
whatever server IP:port the client was trying to connect to.


Amos


From 3m9n51s2ewut at thismonkey.com  Mon May 25 11:39:56 2020
From: 3m9n51s2ewut at thismonkey.com (Scott)
Date: Mon, 25 May 2020 21:39:56 +1000
Subject: [squid-users] Dumping sslbump'd decrytped http using icap
 protocol
In-Reply-To: <72c95707-e4b4-eb48-b69e-31eea7671574@treenet.co.nz>
References: <20200524125646.GA86132@thismonkey.com>
 <72c95707-e4b4-eb48-b69e-31eea7671574@treenet.co.nz>
Message-ID: <20200525113956.GA60696@thismonkey.com>

On Mon, May 25, 2020 at 06:34:19PM +1200, Amos Jeffries wrote:
> On 25/05/20 12:56 am, Scott wrote:
> > Hi,
> > 
> > Can someone recommend an ICAP application that will allow me to dump the HTTP 
> > of a client-server conversation?
> > 
> > I am doing some forensics on an app - I have sslbump configured correctly and 
> > I can get the traffic to c-icap (for example).
> > 
> > I'd like to dump this to a text file.
> > 
> > Is there a dump option for c-icap?  I couldn't find one.
> > 
> 
> FYI; this action is illegal in a lot of places. Even answering your
> question can be quite risky.
> 
> 
> To perform traffic forensics you can use the Squid cache.log directly
> and not involve any insecure third-party software or communication
> dumps. See <https://wiki.squid-cache.org/KnowledgeBase/DebugSections>
> for more details.
> 
> "debug_Options 11,2" is probably all you need.
> 
> 
> Amos
> 
Thanks,

I'm inspecting my own data between my own endpoints as part of a some 
proving-of-concept, so there's no illegality here, but I appreciate the 
caution.

Using the cache.log and debug provided me with too much data.  With ICAP I'm 
able to apply ACLs to limit the traffic sent to the ICAP server.

Am I right in saying that it is possible to do, I just need the right ICAP 
server?  I'm happy to write one myself, I'm just surprised that it's not been 
done before.  I thought perhaps I was missing an option, say in c-icap or 
some other server.



From ben.maling42 at gmail.com  Mon May 25 12:10:15 2020
From: ben.maling42 at gmail.com (ben benml)
Date: Mon, 25 May 2020 14:10:15 +0200
Subject: [squid-users] Squid 4.4 https_port and ssl-bump : Fatal bungled
	line
In-Reply-To: <467d0766-1821-8a25-81cc-dab40188e664@treenet.co.nz>
References: <CACTby66gbiTxsj6Ftv-ZFwzwmTZSavD3CaoWGSxHWeQAWmGcQA@mail.gmail.com>
 <467d0766-1821-8a25-81cc-dab40188e664@treenet.co.nz>
Message-ID: <CACTby66UXqfEXE8zvD8VmX3q33EzY7VHMqzJcjzgAoT5TQBh+A@mail.gmail.com>

Hello,

Thank you for your prompt and precise answer.

Well I'm permit myself another question, sorry. If you have an opinion
about securing the authentification without https_port :
With a FreeIPA central users directory, what could be the best way to
secure/protect the  authentication process, the login/password.
Or more generally what could be the best options to secure the
login/password with only the http_port. So no directly encrypted traffic.

I was assuming https connection could secure the authentication process ..
but if ssl-dump  is really wanted, so I need another options to secure the
login/password.

Did you see my point / what I'm trying to talk about ?

Thank you in advance.

Regards,


Le lun. 25 mai 2020 ? 12:26, Amos Jeffries <squid3 at treenet.co.nz> a ?crit :

> On 25/05/20 9:59 pm, ben benml wrote:
> > Hello,
> >
> > I'm contacting you for some help.
> > I need to deploy a secure proxy based on Squid.
> >
> > I try to use https_port combined with sslbump. I get an error message
> > about a bungled line.
> >
> > The reasons I want to do this :
> > - secure connection between the client browser and the proxy server, so
> > using https_port to do it. encrypted  traffic in TLS between the client
> > and the server.
>
> Fine. Simply using https_port does that.
>
> > - secure login connection. So I need to use https_port to do this.
>
> Fine. Simply using https_port does that.
>
> > - Do ssl inspection of the traffic goeing through the proxy
>
> Squid does not yet support SSL-Bump decrypt of traffic already being
> decrypted for the secure proxy.
>
>
> Please see
> <http://lists.squid-cache.org/pipermail/squid-users/2020-May/022120.html>
> if
> you want details.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200525/c001b889/attachment.htm>

From ngtech1ltd at gmail.com  Mon May 25 15:10:46 2020
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Mon, 25 May 2020 18:10:46 +0300
Subject: [squid-users] Dumping sslbump'd decrytped http using icap
 protocol
Message-ID: <5ecbdffa.1c69fb81.c6591.8afd@mx.google.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200525/89e1ef0e/attachment.htm>

From m992493 at gmail.com  Tue May 26 03:29:59 2020
From: m992493 at gmail.com (Amiq Nahas)
Date: Tue, 26 May 2020 08:59:59 +0530
Subject: [squid-users] squid and c-icap configuration
Message-ID: <CAPicJaGcihvM9vir9JYt8h9zoSnR0oxdcNG+Vdz+iGufN9LYFA@mail.gmail.com>

Hi Guys,

This is what I want:
Browse the internet through a browser such that every url request goes
to squid proxy first and then the squid proxy sends it to c-icap
server. Finally the url should be logged into `/var/log/access.log`


This is what I have tried:
############################
c-icap.conf:
############################
PidFile /var/run/c-icap/c-icap.pid
CommandsSocket /var/run/c-icap/c-icap.ctl
Timeout 300
MaxKeepAliveRequests 100
KeepAliveTimeout 600
StartServers 3
MaxServers 10
MinSpareThreads     10
MaxSpareThreads     20
ThreadsPerChild     10
MaxRequestsPerChild  0
Port 1344
ServerAdmin you at your.address
ServerName YourServerName
TmpDir /var/tmp
MaxMemObject 131072
DebugLevel 1
Pipelining on
SupportBuggyClients off
ModulesDir /usr/local/lib/c_icap
ServicesDir /usr/local/lib/c_icap
TemplateDir /usr/local/share/c_icap/templates/
TemplateDefaultLanguage en
LoadMagicFile /usr/local/etc/c-icap.magic
RemoteProxyUsers off
RemoteProxyUserHeader X-Authenticated-User
RemoteProxyUserHeaderEncoded on
acl all src 0.0.0.0/0.0.0.0
LogFormat myFormat "%tl, %la %a %im %iu %is %huo"
ServerLog /usr/local/var/log/server.log
AccessLog /usr/local/var/log/access.log myFormat all
Service echo srv_echo.so

############################
squid.conf
############################
icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024
icap_service service_req reqmod_precache bypass=1 icap://127.0.0.1:1344/request
adaptation_access service_req allow all
icap_service service_resp respmod_precache bypass=0
icap://127.0.0.1:1344/response
adaptation_access service_resp allow all


This is the result I have got by doing the above:
############################
/var/log/access.log
############################
19/May/2020:11:43:54 +0530, 127.0.0.1 127.0.0.1 UNKNOWN - 400 -
19/May/2020:11:45:15 +0530, 127.0.0.1 127.0.0.1 OPTIONS request 404 -
20/May/2020:00:44:56 +0530, 127.0.0.1 127.0.0.1 UNKNOWN - 400 -
20/May/2020:00:44:57 +0530, 127.0.0.1 127.0.0.1 UNKNOWN - 400 -
20/May/2020:00:45:00 +0530, 127.0.0.1 127.0.0.1 UNKNOWN - 400 -
20/May/2020:00:45:01 +0530, 127.0.0.1 127.0.0.1 UNKNOWN - 400 -
20/May/2020:00:45:15 +0530, 127.0.0.1 127.0.0.1 OPTIONS request 404 -
20/May/2020:00:48:15 +0530, 127.0.0.1 127.0.0.1 OPTIONS request 404 -
20/May/2020:00:51:15 +0530, 127.0.0.1 127.0.0.1 OPTIONS request 404 -
20/May/2020:00:54:15 +0530, 127.0.0.1 127.0.0.1 OPTIONS request 404 -
20/May/2020:00:57:15 +0530, 127.0.0.1 127.0.0.1 OPTIONS request 404 -


What am I doing wrong ? I should mention that

Thanks
Amiq


From julien.tehery at mediactivegroup.com  Tue May 26 07:24:46 2020
From: julien.tehery at mediactivegroup.com (Julien  TEHERY)
Date: Tue, 26 May 2020 07:24:46 +0000
Subject: [squid-users] HTTPS_PORT AND SSL CERT
Message-ID: <PR2P264MB0894BA1216C861126843039AEBB00@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>

Hi there,

I'm actually facing a problem with Squid 4.6-1 (Debian 10).
I'm using squid with https_port directive, using an SSL certficate ( a true one, not self signed)

Here is the simple setup:

https_port X.X.X.X:8443 tls-cert=/etc/squid/mywildcard.com.pem

The fact is that setup works for all firefox version using a proxy.pac file for HTTPS connexions to the squid server.
But for chrome this is quite different. Indeed chrome uses the system's proxy settings and i noticed that sometimes it would work and sometinles it would fail.
To make it work all the time i had to add my intermediate certificate (thawte) in the local store, so that means intermediate certificate has not been delivered by the squid server as it should.

The pem file in the above setup allreadycontains this (pem file done by concatenating  private key, cert, intermediate and root CA. I also tried the following syntax:

https_port X.X.X.X:8443 cert=/etc/squid/mywildcard..com.cer key=/etc/squid/mywildcard.com.key cafile=/etc/squid/mywildcard..com-intermediaire.txt

but each time i try to see with openssl client if my intermediate is delivered, it's not
I use "openssl s_client -showcerts -connect myproxy.com:8443"

If i do the same thing on an apache server with the same certificate files i can see both certificate and intermediate. Why squid isn't able to show it, did i miss something ?


Thanks for your help
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200526/c5bcd368/attachment.htm>

From squid3 at treenet.co.nz  Tue May 26 15:17:12 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 27 May 2020 03:17:12 +1200
Subject: [squid-users] HTTPS_PORT AND SSL CERT
In-Reply-To: <PR2P264MB0894BA1216C861126843039AEBB00@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>
References: <PR2P264MB0894BA1216C861126843039AEBB00@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>
Message-ID: <eac98376-9115-2990-7325-714b07202549@treenet.co.nz>

On 26/05/20 7:24 pm, Julien TEHERY wrote:
> To make it work all the time i had to add my intermediate certificate
> (thawte) in the local store, so that means intermediate certificate has
> not been delivered by the squid server as it should.

The experimental GnuTLS support in Debian package does not yet support
certificate chains. That is still some ways off.

For now if there is a chain with intermediate certificates you still
need to use an OpenSSL build of Squid.

Amos


From rousskov at measurement-factory.com  Tue May 26 20:30:00 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 26 May 2020 16:30:00 -0400
Subject: [squid-users] SMP + Ssl-Bump squid-tls_session_cache.shm
In-Reply-To: <CAF1CunTW5+7MTdaAVceWDSF7bUdy3nCXh1EEKvjzcJ3GYUhuxw@mail.gmail.com>
References: <CAF1CunTW5+7MTdaAVceWDSF7bUdy3nCXh1EEKvjzcJ3GYUhuxw@mail.gmail.com>
Message-ID: <0398b9d8-dde3-baee-0595-a277bbe3095d@measurement-factory.com>

On 5/23/20 11:31 PM, Joshua Bazgrim wrote:

> cache_dir aufs /var/log/squid/cache${process_number} 512 128 128
> min-size=32769

I do not know the answer your question, but please keep in mind that
UFS-based caches are not officially supported in SMP configurations.
This kind of configuration has an ever-increasing chance of breaking
with every Squid update, and some breakage can be silent.

Alex.


From ryanlele264 at gmail.com  Tue May 26 21:59:31 2020
From: ryanlele264 at gmail.com (Ryan Le)
Date: Tue, 26 May 2020 17:59:31 -0400
Subject: [squid-users] iptables CONNMARK with squid
Message-ID: <CANqqF0rTVyYbuzsx9W0QAwEqYMNivgsZQ4BidPRwyKhpvb5xMA@mail.gmail.com>

I have the following setup:

squid -v
Squid Cache: Version 4.8
Service Name: squid
201909121340

This binary uses OpenSSL 1.0.2k-fips  26 Jan 2017. For legal restrictions
on distribution see https://www.openssl.org/source/license.html

configure options:  '--enable-ssl-crtd' '--enable-build-info=201909121340'
'--disable-arch-native' '--with-large-files' '--enable-wccpv2'
'--enable-delay-pools' '--enable-icap-client' '--with-openssl'
'--enable-ssl' '--enable-ltdl-convenience' '--enable-linux-netfilter'
'--enable-auth' '--with-libcap' '--with-default-user=squid'
'--sysconfdir=/etc/squid' '--with-logdir=/var/log/squid'
'--with-swapdir=/var/spool/squid'

squid.conf
     qos_flows mark

iptables
     target     prot opt in     out     source               destination
     CONNMARK   tcp  --  interface2  *       0.0.0.0/0            0.0.0.0/0
           tcp dpt:443 CONNMARK xset 0x6b0000/0x7fff0000

DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0
 tcp dpt:443 mark match 0x6b0000 to:IP:9443

ip rule show
     204:    from all fwmark 0x6b0000/0x7fff0000 lookup 107

ip route show table 107
     10.0.0.0/8 dev interface2 scope link
     127.0.0.1 dev lo scope link
     172.16.0.0/12 dev interface2 scope link
      192.168.0.0/16 dev interface2 scope link

I do see the packet in squid log which appears to have the mark

2020/05/26 17:22:20.557 kid3| 28,3| Eui48.cc(516) lookup: id=0x17b20b4
192.168.128.2 NOT found

2020/05/26 17:22:20.557 kid3| 17,3| QosConfig.cc(148) getNfmarkCallback:
0x6b0000


2020/05/26 17:22:20.557 kid3| 51,3| fd.cc(198) fd_open: fd_open() FD 26
HTTP Request
2020/05/26 17:22:20.557 kid3| 5,5| TcpAcceptor.cc(301) acceptOne: Listener:
local=localIP remote=[::] FD 23 flags=33 ac
cepted new connection local=websiteIP remote=192.168.128.2:59769 FD 26
flags=33 handler Subscription: 0xee7580*1

It doesn't seem to preserve the mark when making the request to the server.

I have two questions

Is it better to use tproxy versus dnat when trying to preserve the mark?

It also appears even though I mark the packet and have a separate routing
table the packet never seems to make it to squid unless I have a route for
the source address in the main table, is there a way to make squid use the
second routing table?

Thanks,
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200526/4949580e/attachment.htm>

From txie145 at gmail.com  Tue May 26 23:43:53 2020
From: txie145 at gmail.com (hanxie)
Date: Tue, 26 May 2020 18:43:53 -0500 (CDT)
Subject: [squid-users] ssl_bump problems with pypi servers
Message-ID: <1590536633516-0.post@n4.nabble.com>

Hi all, 

I am experiencing somewhat of a strange error with squid using ssl-bump. I
think I am running a somewhat typical set up in which we run a squid proxy
server fleet that is used by our other servers and we use "ssl_bump" to
man-in-the-middle all our traffic. 

The problem is that occasionally requests to "https://pypi.org" will time
out. Even weirder, we are running in Google Compute Platform and the same
squid container will error out depending on different regions. This bug has
been confounding us for months now and any help would be greatly
appreciated. 

We have tried turning on verbose debugging and I think I have found the logs
in which squid encounters an error with the request:

2020/05/21 19:27:28.567| 83,5| PeerConnector.cc(88) prepareSocket:
local=172.17.0.2:57012 remote=151.101.0.223:443 FD 14 flags=1,
this=0x1d3b788
2020/05/21 19:27:28.567| 83,5| PeerConnector.cc(94) prepareSocket:
local=172.17.0.2:57012 remote=151.101.0.223:443 FD 14 flags=1
2020/05/21 19:27:28.567| 9,5| AsyncCall.cc(26) AsyncCall: The AsyncCall
Security::PeerConnector::commCloseHandler constructed, this=0x1d2c990
[call2471]
2020/05/21 19:27:28.567| 5,5| comm.cc(985) comm_add_close_handler:
comm_add_close_handler: FD 14, AsyncCall=0x1d2c990*1
2020/05/21 19:27:28.567| 83,5| PeerConnector.cc(107) initialize:
local=172.17.0.2:57012 remote=151.101.0.223:443 FD 14 flags=1, ctx=0x176ea70
2020/05/21 19:27:28.567| 83,5| Session.cc(103) NewSessionObject: SSL_new
session=0x1d37d50
2020/05/21 19:27:28.567| 83,5| bio.cc(612) squid_bio_ctrl: 0x1d1a380
104(6001, 0x7ffe0c004ee4)
2020/05/21 19:27:28.567| 83,5| Session.cc(161) CreateSession: link FD 14 to
TLS session=0x1d37d50
2020/05/21 19:27:28.567| 83,5| PeerConnector.cc(123) initialize:
local=172.17.0.2:57012 remote=151.101.0.223:443 FD 14 flags=1,
session=0x1d37d50
2020/05/21 19:27:28.567| 14,3| Address.cc(382) lookupHostIP: Given Non-IP
'pypi.org': Name or service not known
2020/05/21 19:27:28.567| 83,5| BlindPeerConnector.cc(60) initialize: success
2020/05/21 19:27:28.567| 83,5| PeerConnector.cc(188) negotiate: SSL_connect
session=0x1d37d50
2020/05/21 19:27:28.567| 83,5| bio.cc(612) squid_bio_ctrl: 0x1d1a380 6(0,
0x1d16bf0)
2020/05/21 19:27:28.568| 83,5| bio.cc(113) write: FD 14 wrote 314 <= 314
2020/05/21 19:27:28.568| 83,5| bio.cc(612) squid_bio_ctrl: 0x1d1a380 11(0,
0)
2020/05/21 19:27:28.568| 83,5| bio.cc(136) read: FD 14 read -1 <= 65535
2020/05/21 19:27:28.568| 83,5| bio.cc(141) read: error: 11 ignored: 1
2020/05/21 19:27:28.568| 83,5| PeerConnector.cc(462) noteWantRead:
local=172.17.0.2:57012 remote=151.101.0.223:443 FD 14 flags=1
2020/05/21 19:27:28.568| 5,3| comm.cc(559) commSetConnTimeout:
local=172.17.0.2:57012 remote=151.101.0.223:443 FD 14 flags=1 timeout 60
2020/05/21 19:27:28.568| 5,5| ModEpoll.cc(117) SetSelect: FD 14, type=1,
handler=1, client_data=0x1d2ca60, timeout=0
2020/05/21 19:27:28.568| 93,5| AsyncJob.cc(154) callEnd:
Security::BlindPeerConnector status out: [ FD 14 job74]
2020/05/21 19:27:28.568| 93,5| AsyncCallQueue.cc(57) fireNext: leaving
AsyncJob::start()
2020/05/21 19:27:28.580| 83,5| PeerConnector.cc(188) negotiate: SSL_connect
session=0x1d37d50
2020/05/21 19:27:28.580| 83,5| bio.cc(136) read: FD 14 read 4143 <= 65535
2020/05/21 19:27:28.580| 83,5| Handshake.cc(405) parseExtensions: first
unsupported extension: 43
2020/05/21 19:27:28.580| 24,5| BinaryTokenizer.cc(47) want: 1 more bytes for
TLSPlaintext.type occupying 1 bytes @4143 in 0x1b94840;
2020/05/21 19:27:28.580| 83,5| Handshake.cc(533) parseHello: need more data
2020/05/21 19:27:28.580| 83,5| PeerConnector.cc(462) noteWantRead:
local=172.17.0.2:57012 remote=151.101.0.223:443 FD 14 flags=1
2020/05/21 19:27:28.580| 5,3| comm.cc(559) commSetConnTimeout:
local=172.17.0.2:57012 remote=151.101.0.223:443 FD 14 flags=1 timeout 60
2020/05/21 19:27:28.580| 5,5| ModEpoll.cc(117) SetSelect: FD 14, type=1,
handler=1, client_data=0x1d18730, timeout=0
2020/05/21 19:27:29.129| 41,5| AsyncCall.cc(26) AsyncCall: The AsyncCall
logfileFlush constructed, this=0x1d018e0 [call2473]
2020/05/21 19:27:29.129| 41,5| AsyncCall.cc(93) ScheduleCall: event.cc(241)
will call logfileFlush(0x1895498*?) [call2473]
2020/05/21 19:27:29.129| 41,5| AsyncCallQueue.cc(55) fireNext: entering
logfileFlush(0x1895498*?)
2020/05/21 19:27:29.129| 41,5| AsyncCall.cc(38) make: make call logfileFlush
[call2473]
2020/05/21 19:27:29.129| 41,5| AsyncCallQueue.cc(57) fireNext: leaving
logfileFlush(0x1895498*?)
2020/05/21 19:27:29.129| 41,5| AsyncCall.cc(26) AsyncCall: The AsyncCall
MaintainSwapSpace constructed, this=0x1d018e0 [call2474]
2020/05/21 19:27:29.129| 41,5| AsyncCall.cc(93) ScheduleCall: event.cc(241)
will call MaintainSwapSpace() [call2474]
2020/05/21 19:27:29.129| 41,5| AsyncCallQueue.cc(55) fireNext: entering
MaintainSwapSpace()
2020/05/21 19:27:29.129| 41,5| AsyncCall.cc(38) make: make call
MaintainSwapSpace [call2474]
2020/05/21 19:27:29.129| 41,5| AsyncCallQueue.cc(57) fireNext: leaving
MaintainSwapSpace()
2020/05/21 19:27:29.651| 41,5| AsyncCall.cc(26) AsyncCall: The AsyncCall
memPoolCleanIdlePools constructed, this=0x1d018e0 [call2475]


We are running squid 4.9 with the following configs:

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 0.0.0.1-0.255.255.255  # RFC 1122 "this" network (LAN)
acl localnet src 10.0.0.0/8             # RFC 1918 local private network
(LAN)
acl localnet src 100.64.0.0/10          # RFC 6598 shared address space
(CGN)
acl localnet src 169.254.0.0/16         # RFC 3927 link-local (directly
plugged) machines
acl localnet src 172.16.0.0/12          # RFC 1918 local private network
(LAN)
acl localnet src 192.168.0.0/16         # RFC 1918 local private network
(LAN)
acl localnet src fc00::/7               # RFC 4193 local private network
range
acl localnet src fe80::/10              # RFC 4291 link-local (directly
plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

acl google_bq_storage ssl::server_name bigquerystorage.googleapis.com

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager

### Custom rules follows: ###

# Logging rules
cache_log /var/log/squid/cache.log
access_log daemon:/var/log/squid/access.log squid

# Intercept all egress and man-the-middle with our own certificate
ssl_bump splice google_bq_storage

ssl_bump bump all
http_port 3128 ssl-bump tls-cert=/etc/squid/ssl_cert/our_cert.pem
tls-key=/etc/squid/ssl_cert/our_cert.pem
options=SINGLE_DH_USE,SINGLE_ECDH_USE
sslcrtd_program
/nix/store/3pwrqm8fjf6bljp3rk50bk5n3ziwaz0a-squid-4.9/libexec/security_file_certgen
-s
/nix/store/3pwrqm8fjf6bljp3rk50bk5n3ziwaz0a-squid-4.9/var/cache/squid/ssl_db
-M 4MB

# Additional certificate authorities to trust. Used when squid establishes
TLS with the target site.
tls_outgoing_options cafile=/etc/squid/ssl_cert/additional_root_certs.crt

cache deny all
### Custom rules end: ###

coredump_dir /squid/var/cache/squid

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From ronanlucio at gmail.com  Wed May 27 00:08:00 2020
From: ronanlucio at gmail.com (Ronan Lucio)
Date: Wed, 27 May 2020 12:08:00 +1200
Subject: [squid-users] Squid 4.4 https_port and ssl-bump : Fatal bungled
	line
In-Reply-To: <CACTby66UXqfEXE8zvD8VmX3q33EzY7VHMqzJcjzgAoT5TQBh+A@mail.gmail.com>
References: <CACTby66gbiTxsj6Ftv-ZFwzwmTZSavD3CaoWGSxHWeQAWmGcQA@mail.gmail.com>
 <467d0766-1821-8a25-81cc-dab40188e664@treenet.co.nz>
 <CACTby66UXqfEXE8zvD8VmX3q33EzY7VHMqzJcjzgAoT5TQBh+A@mail.gmail.com>
Message-ID: <CAF-5T9H6eaAvsm1xFwSqDCOZeMApygk=5oHtmdDTMHeiJ9SCOw@mail.gmail.com>

Hi Ben,

I made working just using https_port (without ssl-bump).

I think it's a good way to secure squid authentication.
You can also use some tool (like certbot) to generate and
automatically renew certificates, so you can work with a short period
expiration time.

Hope that helps,
Ronan

On Tue, May 26, 2020 at 12:10 AM ben benml <ben.maling42 at gmail.com> wrote:
>
> Hello,
>
> Thank you for your prompt and precise answer.
>
> Well I'm permit myself another question, sorry. If you have an opinion about securing the authentification without https_port :
> With a FreeIPA central users directory, what could be the best way to secure/protect the  authentication process, the login/password.
> Or more generally what could be the best options to secure the login/password with only the http_port. So no directly encrypted traffic.
>
> I was assuming https connection could secure the authentication process .. but if ssl-dump  is really wanted, so I need another options to secure the login/password.
>
> Did you see my point / what I'm trying to talk about ?
>
> Thank you in advance.
>
> Regards,
>
>
> Le lun. 25 mai 2020 ? 12:26, Amos Jeffries <squid3 at treenet.co.nz> a ?crit :
>>
>> On 25/05/20 9:59 pm, ben benml wrote:
>> > Hello,
>> >
>> > I'm contacting you for some help.
>> > I need to deploy a secure proxy based on Squid.
>> >
>> > I try to use https_port combined with sslbump. I get an error message
>> > about a bungled line.
>> >
>> > The reasons I want to do this :
>> > - secure connection between the client browser and the proxy server, so
>> > using https_port to do it. encrypted  traffic in TLS between the client
>> > and the server.
>>
>> Fine. Simply using https_port does that.
>>
>> > - secure login connection. So I need to use https_port to do this.
>>
>> Fine. Simply using https_port does that.
>>
>> > - Do ssl inspection of the traffic goeing through the proxy
>>
>> Squid does not yet support SSL-Bump decrypt of traffic already being
>> decrypted for the secure proxy.
>>
>>
>> Please see
>> <http://lists.squid-cache.org/pipermail/squid-users/2020-May/022120.html> if
>> you want details.
>>
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From ronanlucio at gmail.com  Wed May 27 00:10:40 2020
From: ronanlucio at gmail.com (Ronan Lucio)
Date: Wed, 27 May 2020 12:10:40 +1200
Subject: [squid-users] HTTPS_PORT AND SSL CERT
In-Reply-To: <PR2P264MB0894BA1216C861126843039AEBB00@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>
References: <PR2P264MB0894BA1216C861126843039AEBB00@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>
Message-ID: <CAF-5T9GHtx2Lona77dW8W83h+u+8kwMwhuK=0_tZkofBmoZVvg@mail.gmail.com>

If your server listens on a public IP, you can use a valid certificate.

On Tue, May 26, 2020 at 7:24 PM Julien TEHERY
<julien.tehery at mediactivegroup.com> wrote:
>
> Hi there,
>
> I'm actually facing a problem with Squid 4.6-1 (Debian 10).
> I'm using squid with https_port directive, using an SSL certficate ( a true one, not self signed)
>
> Here is the simple setup:
>
> https_port X.X.X.X:8443 tls-cert=/etc/squid/mywildcard.com.pem
>
> The fact is that setup works for all firefox version using a proxy.pac file for HTTPS connexions to the squid server.
> But for chrome this is quite different. Indeed chrome uses the system's proxy settings and i noticed that sometimes it would work and sometinles it would fail.
> To make it work all the time i had to add my intermediate certificate (thawte) in the local store, so that means intermediate certificate has not been delivered by the squid server as it should.
>
> The pem file in the above setup allreadycontains this (pem file done by concatenating  private key, cert, intermediate and root CA. I also tried the following syntax:
>
> https_port X.X.X.X:8443 cert=/etc/squid/mywildcard..com.cer key=/etc/squid/mywildcard.com.key cafile=/etc/squid/mywildcard..com-intermediaire.txt
>
> but each time i try to see with openssl client if my intermediate is delivered, it's not
> I use "openssl s_client -showcerts -connect myproxy.com:8443"
>
> If i do the same thing on an apache server with the same certificate files i can see both certificate and intermediate. Why squid isn't able to show it, did i miss something ?
>
>
> Thanks for your help
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From julien.tehery at mediactivegroup.com  Wed May 27 06:10:55 2020
From: julien.tehery at mediactivegroup.com (Julien  TEHERY)
Date: Wed, 27 May 2020 06:10:55 +0000
Subject: [squid-users] HTTPS_PORT AND SSL CERT
In-Reply-To: <CAF-5T9GHtx2Lona77dW8W83h+u+8kwMwhuK=0_tZkofBmoZVvg@mail.gmail.com>
References: <PR2P264MB0894BA1216C861126843039AEBB00@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>,
 <CAF-5T9GHtx2Lona77dW8W83h+u+8kwMwhuK=0_tZkofBmoZVvg@mail.gmail.com>
Message-ID: <PR0P264MB0890251806F6285461318338EBB10@PR0P264MB0890.FRAP264.PROD.OUTLOOK.COM>

It's allready the case, the server as a public IP and a valid cert.
As Amos says, it is related to the gnutls implementation which is experimental. squid has to be built with openssl to support chain certificates.
________________________________
De : Ronan Lucio <ronanlucio at gmail.com>
Envoy? : mercredi 27 mai 2020 02:10
? : Julien TEHERY <julien.tehery at mediactivegroup.com>
Cc : squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Objet : Re: [squid-users] HTTPS_PORT AND SSL CERT

If your server listens on a public IP, you can use a valid certificate.

On Tue, May 26, 2020 at 7:24 PM Julien TEHERY
<julien.tehery at mediactivegroup.com> wrote:
>
> Hi there,
>
> I'm actually facing a problem with Squid 4.6-1 (Debian 10).
> I'm using squid with https_port directive, using an SSL certficate ( a true one, not self signed)
>
> Here is the simple setup:
>
> https_port X.X.X.X:8443 tls-cert=/etc/squid/mywildcard.com.pem
>
> The fact is that setup works for all firefox version using a proxy.pac file for HTTPS connexions to the squid server.
> But for chrome this is quite different. Indeed chrome uses the system's proxy settings and i noticed that sometimes it would work and sometinles it would fail.
> To make it work all the time i had to add my intermediate certificate (thawte) in the local store, so that means intermediate certificate has not been delivered by the squid server as it should.
>
> The pem file in the above setup allreadycontains this (pem file done by concatenating  private key, cert, intermediate and root CA. I also tried the following syntax:
>
> https_port X.X.X.X:8443 cert=/etc/squid/mywildcard..com.cer key=/etc/squid/mywildcard.com.key cafile=/etc/squid/mywildcard..com-intermediaire.txt
>
> but each time i try to see with openssl client if my intermediate is delivered, it's not
> I use "openssl s_client -showcerts -connect myproxy.com:8443"
>
> If i do the same thing on an apache server with the same certificate files i can see both certificate and intermediate. Why squid isn't able to show it, did i miss something ?
>
>
> Thanks for your help
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200527/c36a05f6/attachment.htm>

From julien.tehery at mediactivegroup.com  Wed May 27 07:54:57 2020
From: julien.tehery at mediactivegroup.com (Julien  TEHERY)
Date: Wed, 27 May 2020 07:54:57 +0000
Subject: [squid-users] HTTPS_PORT AND SSL CERT
In-Reply-To: <eac98376-9115-2990-7325-714b07202549@treenet.co.nz>
References: <PR2P264MB0894BA1216C861126843039AEBB00@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>,
 <eac98376-9115-2990-7325-714b07202549@treenet.co.nz>
Message-ID: <PR0P264MB08900281642C191292DA016BEBB10@PR0P264MB0890.FRAP264.PROD.OUTLOOK.COM>

Unfortunately, i've just compiled/ and built deb packages a fresh new squid 4.11
Now SSL support should be fully operational, but the certificate i still not showing the intermediate.

I just tried https_port 8443 tls-cert=/etc/squid/wildcard.mycompany.com.pem
where in the pem file i have in this precise order:


  *   cert key
  *   server cert
  *   intermediate cert

openssl client shows only the cert issuer, as it should show both.
Did I missed something ?

On 26/05/20 7:24 pm, Julien TEHERY wrote:
> To make it work all the time i had to add my intermediate certificate
> (thawte) in the local store, so that means intermediate certificate has
> not been delivered by the squid server as it should.

The experimental GnuTLS support in Debian package does not yet support
certificate chains. That is still some ways off.

For now if there is a chain with intermediate certificates you still
need to use an OpenSSL build of Squid.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200527/b4a28beb/attachment.htm>

From rousskov at measurement-factory.com  Wed May 27 12:30:18 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 27 May 2020 08:30:18 -0400
Subject: [squid-users] ssl_bump problems with pypi servers
In-Reply-To: <1590536633516-0.post@n4.nabble.com>
References: <1590536633516-0.post@n4.nabble.com>
Message-ID: <55264e49-f328-1263-3b4b-c8619c4466bb@measurement-factory.com>

On 5/26/20 7:43 PM, hanxie wrote:

> We have tried turning on verbose debugging and I think I have found the logs
> in which squid encounters an error with the request:

I did not find anything particularly suspicious in that log snippet. I
suggest posting a link to a much larger, compressed log sample.

Alex.


From ngtech1ltd at gmail.com  Wed May 27 19:45:57 2020
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Wed, 27 May 2020 22:45:57 +0300
Subject: [squid-users] Squid cache with SSL
In-Reply-To: <5b565926-53ea-5a38-53ba-13b93d3ab243@treenet.co.nz>
References: <CADCth7zsf+ghRWY3SiUzy4mtC=8-fUjaCnuQdGu=Ta1aCEW7mw@mail.gmail.com>,
 <5b565926-53ea-5a38-53ba-13b93d3ab243@treenet.co.nz>
Message-ID: <1B3446AF-D760-4CB6-BEFF-46E1F84227DE@hxcore.ol>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200527/fce8fc58/attachment.htm>

From txie145 at gmail.com  Wed May 27 21:05:43 2020
From: txie145 at gmail.com (hanxie)
Date: Wed, 27 May 2020 16:05:43 -0500 (CDT)
Subject: [squid-users] ssl_bump problems with pypi servers
In-Reply-To: <55264e49-f328-1263-3b4b-c8619c4466bb@measurement-factory.com>
References: <1590536633516-0.post@n4.nabble.com>
 <55264e49-f328-1263-3b4b-c8619c4466bb@measurement-factory.com>
Message-ID: <1590613543280-0.post@n4.nabble.com>

Hi Alex thanks for the response!

I have posted a link to a larger log snippet that was the more full trace
from the previous request. Let me know if I could provide anything else as
well.

squid_debug.txt
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t377946/squid_debug.txt>  



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From gengchao62 at gmail.com  Thu May 28 04:36:23 2020
From: gengchao62 at gmail.com (saiyan_gc)
Date: Wed, 27 May 2020 23:36:23 -0500 (CDT)
Subject: [squid-users] SSL certificate not working for windows update
Message-ID: <1590640583823-0.post@n4.nabble.com>

Hi, I have proxy server that use self signed certificate/basic
username/password authentication for the http port 2128. Some how the
windows update is not working for my proxy box.

The proxy server is working fine with wget in powershell. 

Below are my error log, not sure why it's failing at 503.

1590640145.751      0 52.202.5.238 TCP_DENIED/407 3930 CONNECT
login.live.com:443 - HIER_NONE/- text/html
1590640145.794      0 52.202.5.238 TCP_DENIED/407 3930 CONNECT
login.live.com:443 - HIER_NONE/- text/html
1590640147.298      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640147.305      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640147.453      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640147.453    966 52.202.5.238 NONE/200 0 CONNECT
fe2.update.microsoft.com:443 - HIER_DIRECT/40.91.75.5 -
1590640147.483      0 52.202.5.238 NONE/503 4430 POST
https://fe2.update.microsoft.com/v6/ClientWebService/client.asmx -
HIER_NONE/- text/html
1590640149.511      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640149.517      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640149.663      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640149.664    161 52.202.5.238 NONE/200 0 CONNECT
fe2.update.microsoft.com:443 - HIER_DIRECT/2a01:111:f335:1792::a61 -
1590640149.671      0 52.202.5.238 NONE/503 3948 POST
https://fe2.update.microsoft.com/v6/ClientWebService/client.asmx -
HIER_NONE/- text/html
1590640151.697      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640151.848      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640151.853      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640151.854    164 52.202.5.238 NONE/200 0 CONNECT
fe2.update.microsoft.com:443 - HIER_DIRECT/20.185.109.208 -
1590640151.861      0 52.202.5.238 NONE/503 4434 POST
https://fe2.update.microsoft.com/v6/ClientWebService/client.asmx -
HIER_NONE/- text/html
1590640152.045      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640152.045    179 52.202.5.238 NONE/200 0 CONNECT
sls.update.microsoft.com:443 - HIER_DIRECT/13.74.179.117 -
1590640152.053      0 52.202.5.238 NONE/503 4433 GET
https://sls.update.microsoft.com/SLS/%7B9482F4B4-E343-43B6-B170-9A65BC822C77%7D/x64/10.0.14393.0/0?
- HIER_NONE/- text/html
1590640152.194      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640152.195    137 52.202.5.238 NONE/200 0 CONNECT
sls.update.microsoft.com:443 - HIER_DIRECT/2a01:111:f307:1790::f001:7a5 -
1590640152.202      0 52.202.5.238 NONE/503 3953 GET
https://sls.update.microsoft.com/SLS/%7B9482F4B4-E343-43B6-B170-9A65BC822C77%7D/x64/10.0.14393.0/0?
- HIER_NONE/- text/html
1590640152.342      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640152.343    136 52.202.5.238 NONE/200 0 CONNECT
sls.update.microsoft.com:443 - HIER_DIRECT/2a01:111:f307:1790::f001:7a5 -
1590640152.349      0 52.202.5.238 NONE/503 3953 GET
https://sls.update.microsoft.com/SLS/%7B9482F4B4-E343-43B6-B170-9A65BC822C77%7D/x64/10.0.14393.0/0?
- HIER_NONE/- text/html
1590640152.488      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640152.489    136 52.202.5.238 NONE/200 0 CONNECT
sls.update.microsoft.com:443 - HIER_DIRECT/2a01:111:f307:1790::f001:7a5 -
1590640152.496      0 52.202.5.238 NONE/503 3953 GET
https://sls.update.microsoft.com/SLS/%7B9482F4B4-E343-43B6-B170-9A65BC822C77%7D/x64/10.0.14393.0/0?
- HIER_NONE/- text/html
1590640152.637      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640152.638    138 52.202.5.238 NONE/200 0 CONNECT
sls.update.microsoft.com:443 - HIER_DIRECT/2a01:111:f307:1790::f001:7a5 -
1590640152.644      0 52.202.5.238 NONE/503 3953 GET
https://sls.update.microsoft.com/SLS/%7B9482F4B4-E343-43B6-B170-9A65BC822C77%7D/x64/10.0.14393.0/0?
- HIER_NONE/- text/html
1590640152.783      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640152.783    136 52.202.5.238 NONE/200 0 CONNECT
sls.update.microsoft.com:443 - HIER_DIRECT/2a01:111:f307:1790::f001:7a5 -
1590640152.790      0 52.202.5.238 NONE/503 3953 GET
https://sls.update.microsoft.com/SLS/%7B9482F4B4-E343-43B6-B170-9A65BC822C77%7D/x64/10.0.14393.0/0?
- HIER_NONE/- text/html
1590640152.930      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640152.931    136 52.202.5.238 NONE/200 0 CONNECT
sls.update.microsoft.com:443 - HIER_DIRECT/2a01:111:f307:1790::f001:7a5 -
1590640152.938      0 52.202.5.238 NONE/503 3953 GET
https://sls.update.microsoft.com/SLS/%7B9482F4B4-E343-43B6-B170-9A65BC822C77%7D/x64/10.0.14393.0/0?
- HIER_NONE/- text/html
1590640153.076      0 - TCP_DENIED/407 3720 GET
http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt -
HIER_NONE/- text/html;charset=utf-8
1590640153.077    137 52.202.5.238 NONE/200 0 CONNECT
sls.update.microsoft.com:443 - HIER_DIRECT/2a01:111:f307:1790::f001:7a5 -
1590640153.084      0 52.202.5.238 NONE/503 3953 GET
https://sls.update.microsoft.com/SLS/%7B9482F4B4-E343-43B6-B170-9A65BC822C77%7D/x64/10.0.14393.0/0?
- HIER_NONE/- text/html


I check the page in https://wiki.squid-cache.org/SquidFaq/WindowsUpdate, and
add the settings on top but it still not working (only tested http_port,
https_port is not working :)

acl windowsupdate dstdomain windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain download.windowsupdate.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain www.download.windowsupdate.com
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com

acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com
http_access allow CONNECT wuCONNECT
http_access allow windowsupdate

http_port 2128 ssl-bump tls-cert=/etc/squid/ssl_cert/example.com.cert \
    tls-key=/etc/squid/ssl_cert/example.com.private \
    generate-host-certificates=on \
    dynamic_cert_mem_cache_size=4MB
https_port 3130 cert=/etc/squid/ssl_cert/example.com.cert \
    key=/etc/squid/ssl_cert/example.com.private
auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/passwords
auth_param basic children 5 startup=0 idle=1
auth_param basic credentialsttl 2 hours
auth_param basic casesensitive off
acl ncsa_users proxy_auth REQUIRED
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all
http_access deny !ncsa_users
http_access allow ncsa_users



Based on the instruction, it seems that we are skipping ssl bump for windows
update, right? Does it mean windows server will not work with any SSL
authentication? 


Thank you so much!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From julien.tehery at mediactivegroup.com  Thu May 28 06:32:17 2020
From: julien.tehery at mediactivegroup.com (Julien  TEHERY)
Date: Thu, 28 May 2020 06:32:17 +0000
Subject: [squid-users] HTTPS_PORT AND SSL CERT
In-Reply-To: <PR0P264MB08900281642C191292DA016BEBB10@PR0P264MB0890.FRAP264.PROD.OUTLOOK.COM>
References: <PR2P264MB0894BA1216C861126843039AEBB00@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>,
 <eac98376-9115-2990-7325-714b07202549@treenet.co.nz>,
 <PR0P264MB08900281642C191292DA016BEBB10@PR0P264MB0890.FRAP264.PROD.OUTLOOK.COM>
Message-ID: <PR2P264MB0894D801A35733C2D51C83EFEB8E0@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>

I retried everything possible in terms of order in the pem file.
from my workstation, if i do "openssl s_client -showcerts -connect mysquid.mycompany.com:8443" i only get one certificate/issuer, but the same command on same server but different port (apache listenning on 443), i correctly get 2 certificates/issuers:

I precise my https configuration isn't for ssl_bump purpose but only to provide secure access to the http proxy through the WAN with a valid certificate.
Do you some of you use complete certificates (including intermediate) with squid? If yes please tell me how you made it work.
I do have the latest stable squid version built with openssl support.

If squid isn't able to do that, as we  do with so many other softwares, I should consider to use an haproxy server or apache reverse proxy in front of the squid to handle correctly the SSL cert.

Regards,



________________________________
De : Julien TEHERY <julien.tehery at mediactivegroup.com>
Envoy? : mercredi 27 mai 2020 09:54
? : Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Objet : RE: [squid-users] HTTPS_PORT AND SSL CERT

Unfortunately, i've just compiled/ and built deb packages a fresh new squid 4.11
Now SSL support should be fully operational, but the certificate i still not showing the intermediate.

I just tried https_port 8443 tls-cert=/etc/squid/wildcard.mycompany.com.pem
where in the pem file i have in this precise order:


  *   cert key
  *   server cert
  *   intermediate cert

openssl client shows only the cert issuer, as it should show both.
Did I missed something ?

On 26/05/20 7:24 pm, Julien TEHERY wrote:
> To make it work all the time i had to add my intermediate certificate
> (thawte) in the local store, so that means intermediate certificate has
> not been delivered by the squid server as it should.

The experimental GnuTLS support in Debian package does not yet support
certificate chains. That is still some ways off.

For now if there is a chain with intermediate certificates you still
need to use an OpenSSL build of Squid.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200528/44139403/attachment.htm>

From antonino.sanacori at unibs.it  Thu May 28 07:19:44 2020
From: antonino.sanacori at unibs.it (Antonino Gianfranco Sanacori)
Date: Thu, 28 May 2020 09:19:44 +0200
Subject: [squid-users] HTTPS and HTTP bypass authentication for certain sites
Message-ID: <73f3a715-e0ef-ee69-b3ee-b4d77e031629@unibs.it>

Hi.

I have a 4.6 server Squid, i want to configure it for to permit the free 
access, with http and https,? to some ip address to my users.

I have read that i can use ssl_bump splice acl, then i can configure in 
this way?

acl list dstdomain "file.acl"

ssl_bump splice list

http_access allow list

https_access allow list

Many thanks.

Antonino



-- 


Informativa sulla Privacy: http://www.unibs.it/node/8155 
<http://www.unibs.it/node/8155>


From uhlar at fantomas.sk  Thu May 28 08:12:33 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 28 May 2020 10:12:33 +0200
Subject: [squid-users] HTTPS_PORT AND SSL CERT
In-Reply-To: <PR2P264MB0894D801A35733C2D51C83EFEB8E0@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>
References: <PR2P264MB0894BA1216C861126843039AEBB00@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>
 <eac98376-9115-2990-7325-714b07202549@treenet.co.nz>
 <PR0P264MB08900281642C191292DA016BEBB10@PR0P264MB0890.FRAP264.PROD.OUTLOOK.COM>
 <PR2P264MB0894D801A35733C2D51C83EFEB8E0@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>
Message-ID: <20200528081233.GC12668@fantomas.sk>

On 28.05.20 06:32, Julien  TEHERY wrote:
>I retried everything possible in terms of order in the pem file.  from my
>workstation, if i do "openssl s_client -showcerts -connect
>mysquid.mycompany.com:8443" i only get one certificate/issuer, but the same
>command on same server but different port (apache listenning on 443), i
>correctly get 2 certificates/issuers:
>
>I precise my https configuration isn't for ssl_bump purpose but only to provide secure access to the http proxy through the WAN with a valid certificate.
>Do you some of you use complete certificates (including intermediate) with squid? If yes please tell me how you made it work.
>I do have the latest stable squid version built with openssl support.

you apparnetly need ptovide concatenated list of your squid certificate and
intermediate certificate that signed your squid certificate.

You don't need to provide the root certificate that signed intermediate
certificate, since browsers  to have that certificate installed
(otherwise they wouldn't trust the certificate at all).


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
- Have you got anything without Spam in it?
- Well, there's Spam egg sausage and Spam, that's not got much Spam in it.


From julien.tehery at mediactivegroup.com  Thu May 28 09:00:00 2020
From: julien.tehery at mediactivegroup.com (Julien  TEHERY)
Date: Thu, 28 May 2020 09:00:00 +0000
Subject: [squid-users] HTTPS_PORT AND SSL CERT
In-Reply-To: <20200528081233.GC12668@fantomas.sk>
References: <PR2P264MB0894BA1216C861126843039AEBB00@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>
 <eac98376-9115-2990-7325-714b07202549@treenet.co.nz>
 <PR0P264MB08900281642C191292DA016BEBB10@PR0P264MB0890.FRAP264.PROD.OUTLOOK.COM>
 <PR2P264MB0894D801A35733C2D51C83EFEB8E0@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>,
 <20200528081233.GC12668@fantomas.sk>
Message-ID: <PR2P264MB0894094C3B1A4D38482BEC67EB8E0@PR2P264MB0894.FRAP264.PROD.OUTLOOK.COM>

Yes, that's what i did. As I explained before, i provided to squid a pem file containing:


  *   sever key
  *   server cert
  *   intermediate cert

with in squid.conf:

https_port 8443 tls-cert=path/to/my/wildcard.pem

I did not try to add root cert as i'm aware it's not necessary

I've spent so many hours on something that should work quickly..
________________________________
De : squid-users <squid-users-bounces at lists.squid-cache.org> de la part de Matus UHLAR - fantomas <uhlar at fantomas.sk>
Envoy? : jeudi 28 mai 2020 10:12
? : squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Objet : Re: [squid-users] HTTPS_PORT AND SSL CERT

On 28.05.20 06:32, Julien  TEHERY wrote:
>I retried everything possible in terms of order in the pem file.  from my
>workstation, if i do "openssl s_client -showcerts -connect
>mysquid.mycompany.com:8443" i only get one certificate/issuer, but the same
>command on same server but different port (apache listenning on 443), i
>correctly get 2 certificates/issuers:
>
>I precise my https configuration isn't for ssl_bump purpose but only to provide secure access to the http proxy through the WAN with a valid certificate.
>Do you some of you use complete certificates (including intermediate) with squid? If yes please tell me how you made it work.
>I do have the latest stable squid version built with openssl support.

you apparnetly need ptovide concatenated list of your squid certificate and
intermediate certificate that signed your squid certificate.

You don't need to provide the root certificate that signed intermediate
certificate, since browsers  to have that certificate installed
(otherwise they wouldn't trust the certificate at all).


--
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
- Have you got anything without Spam in it?
- Well, there's Spam egg sausage and Spam, that's not got much Spam in it.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200528/3cbdebc2/attachment.htm>

From rousskov at measurement-factory.com  Thu May 28 17:19:58 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 28 May 2020 13:19:58 -0400
Subject: [squid-users] HTTPS and HTTP bypass authentication for certain
 sites
In-Reply-To: <73f3a715-e0ef-ee69-b3ee-b4d77e031629@unibs.it>
References: <73f3a715-e0ef-ee69-b3ee-b4d77e031629@unibs.it>
Message-ID: <237acaeb-5afd-07de-d7d6-c7e554a99dc6@measurement-factory.com>

On 5/28/20 3:19 AM, Antonino Gianfranco Sanacori wrote:
> I have a 4.6 server Squid, i want to configure it for to permit the free
> access, with http and https,? to some ip address to my users.

> I have read that i can use ssl_bump splice acl, then i can configure in
> this way?

You do not need SslBump if you only need to block by the destination IP
address.


> acl list dstdomain "file.acl"

FYI: You said "to some ip address", but the dstdomain ACL is using
domain names. Squid can try to reverse-lookup destination IP addresses
(to match them to the provided domain names), but DNS reverse lookups
are often unreliable.

If you can indeed block by the destination IP address, then consider
using the "dst" ACL instead. The "dst" ACL may also require (forward)
DNS lookups, but they are often more reliable.


> https_access allow list

There is no https_access directive. HTTPS (and FTP) traffic uses the
(arguably misnamed) http_access directive.

Please note that the configuration snippet you posted does not cover the
"my users" part of your requirement summary. It also allows establishing
TCP tunnels to arbitrary ports (on the allowed destination addresses).
Most likely, you want neither.


HTH,

Alex.


> acl list dstdomain "file.acl"
> ssl_bump splice list
> http_access allow list
> https_access allow list 



From rousskov at measurement-factory.com  Fri May 29 18:27:22 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 29 May 2020 14:27:22 -0400
Subject: [squid-users] ssl_bump problems with pypi servers
In-Reply-To: <1590613543280-0.post@n4.nabble.com>
References: <1590536633516-0.post@n4.nabble.com>
 <55264e49-f328-1263-3b4b-c8619c4466bb@measurement-factory.com>
 <1590613543280-0.post@n4.nabble.com>
Message-ID: <4c6c1368-0dba-7103-ebd9-35245dd0dc9d@measurement-factory.com>

On 5/26/20 7:43 PM, hanxie wrote:

> The problem is that occasionally requests to "https://pypi.org" will 
> time out.

I believe you are dealing with a TLS v1.3 server. TLS v1.3 fakes its
handshakes to pretend that they are TLS v1.2 handshakes. However, IIRC,
those fake handshakes do not end with a plain text ServerHelloDone
message like TLS v1.2 handshakes do. Squid v4.9 will wait for that plain
text ServerHelloDone which will never come from (some?) TLS v1.3
servers, leading to a timeout.

TLS v1.3-related improvements are currently available in Squid v5
(commit 4d714a3) or master/v6 (commits 699ade2 and cd29a42). The
corresponding v4 change is coming via
https://github.com/squid-cache/squid/pull/648

I do not know whether those changes will solve your specific problem,
but trying them could be the best next step.


HTH,

Alex.


From Joseph.Garbacik at netapp.com  Sat May 30 23:58:14 2020
From: Joseph.Garbacik at netapp.com (Garbacik, Joe)
Date: Sat, 30 May 2020 23:58:14 +0000
Subject: [squid-users] Squid and cross-signed certificates
Message-ID: <6DE934BB-C44D-4D85-8DE8-2C045302433E@netapp.com>

Has anyone else noticed that any issues with the expiration of the Sectigo certificates today that appear to be related to this issue:
https://support.sectigo.com/Com_KnowledgeDetailPage?Id=kA03l00000117LT
https://support.sectigo.com/Com_KnowledgeDetailPage?Id=kA01N000000rgSZ

I started see this in my logs today for a site that has always worked.

... cert_errors="X509_V_ERR_CERT_HAS_EXPIRED at depth=3" ...

I also noticed that with a browser, bypassing the proxy,  the certificate is fine.
I also noticed that testing with openssl, it indicates expired as well.

    Verify return code: 10 (certificate has expired)

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200530/fd39509f/attachment.htm>

From marcus.kool at urlfilterdb.com  Sun May 31 12:17:46 2020
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Sun, 31 May 2020 13:17:46 +0100
Subject: [squid-users] Squid and cross-signed certificates
In-Reply-To: <6DE934BB-C44D-4D85-8DE8-2C045302433E@netapp.com>
References: <6DE934BB-C44D-4D85-8DE8-2C045302433E@netapp.com>
Message-ID: <48114f80-efcb-229d-c571-af2c7827c140@urlfilterdb.com>

yes, I have seen this with Squid _with_ ssl_bump.? In trying to resolve the issue I also upgraded to Squid 4.11, removed the certificate cache and still had messages that the certificate expired on 
May 30 2020.? Doublechecked all certificates but none has this expiry date.

We have a wildcard certificate of sectigo that we use for *.urlfilterdb.com?? The really strange thing is that the issue does not appear for all subdomains:

'www' subdomain is OK

'files' subdomain has expired certificate

www.sectigo.com also has an expiration issue when used with the Squid proxy and sslbump (peek+bump mode).

My *guess* is that the certificate checking code used by ssl_bump does not check all certificate signing paths.

Marcus


On 2020-05-31 00:58, Garbacik, Joe wrote:
> Has anyone else noticed that any issues with the expiration of the Sectigo certificates today that appear to be related to this issue:
> https://support.sectigo.com/Com_KnowledgeDetailPage?Id=kA03l00000117LT
> https://support.sectigo.com/Com_KnowledgeDetailPage?Id=kA01N000000rgSZ
>
> I started see this in my logs today for a site that has always worked.
>
> ... cert_errors="X509_V_ERR_CERT_HAS_EXPIRED at depth=3" ...
>
> I also noticed that with a browser, bypassing the proxy, ?the certificate is fine.
> I also noticed that testing with openssl, it indicates expired as well.
>
> ? ??Verify return code: 10 (certificate has expired)
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200531/d11a5f6a/attachment.htm>

From panchal.santosh1986 at gmail.com  Sat May 30 11:06:12 2020
From: panchal.santosh1986 at gmail.com (santosh panchal)
Date: Sat, 30 May 2020 11:06:12 -0000
Subject: [squid-users] Help
Message-ID: <CABi3FSkGcwg43BYL8ehV2jrHbZV=tOoEW=WYhm08Yw+avKQ-ww@mail.gmail.com>

Hi Team

We have setup outbound proxy in AWS for private infra

We have put required entry in /etc/profile and try to install package on
ubuntu machine but getting error as it is not going over the internet

Error
Connecting to AP-south-1.ec2.archive.ubuntu.com

Also we are unable to curl google.com even after whitelisting the domain in
Cloudformation template

Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200530/e567ca75/attachment.htm>

