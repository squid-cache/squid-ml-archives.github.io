From squid3 at treenet.co.nz  Thu Oct  1 03:00:36 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 1 Oct 2020 16:00:36 +1300
Subject: [squid-users] ACL matches when it shouldn't
In-Reply-To: <1105910057.70354.1601417013244@mail.yahoo.com>
References: <1105910057.70354.1601417013244.ref@mail.yahoo.com>
 <1105910057.70354.1601417013244@mail.yahoo.com>
Message-ID: <614889e8-894c-c3f2-8d2a-7f69bcc95fa7@treenet.co.nz>

Ah. Think I found it.

Line 9600 in the earlier file contains a URL with un-escaped "||"
sequence. Pipe is a reserved character in regex so needs \-escaping like
'?' '*' '.', '$', '^, '[', ']', '(', ')', '$' and '\' in the original URL.


See the note below though for long-term fix ...


On 30/09/20 11:03 am, Vieri wrote:
>> None of the file entries are anchored regex. So any one of them could match.
> 
>>> Can anyone please let me know if there's a match, or how to enable debugging? to see which record in this ACL is actually triggering the denial?
>>
>> To do that we will need to see the complete and exact URL which is being blocked incorrectly.
> 
> One of them is https://www.google.com/.
> 
>> NP: a large number of that files entries can be far more efficiently blocked using the dstdomain ACL type. For example:
>>
>> ? acl blacklist dstdomain .appspot.com
> 
> Agreed. However, this file is generated by an external process I don't control (SOC). It's like a "threat feed" I need to load in Squid.
> The easiest way for me would be to tell Squid that it's just a list of exact URLs, not a list of regexps. I understand that's not possible.
> 

Not with the built-in ACLs, but an external ACL helper can do any checks
you want it to. I think that would probably be best to use here.



Amos


From rst at fomar.com.pl  Thu Oct  1 09:45:33 2020
From: rst at fomar.com.pl (=?UTF-8?Q?Rafa=C5=82_Stanilewicz?=)
Date: Thu, 1 Oct 2020 10:45:33 +0100
Subject: [squid-users] measuring latency of squid in different scenarios
In-Reply-To: <CA+d==oFHUEnaLOWyCFCpxVYHvPzmHp2+G9KfTkJasF-UF+Upfg@mail.gmail.com>
References: <CAPnyBTPt+3WyVpk25UQ_1v3Jk2bjMv9tdtNESwSQ3a+Q32beOg@mail.gmail.com>
 <CA+d==oGjm5BgsCgLV9Hxcaut+hxTxB=_DFG+aEPy=vAH_hvazg@mail.gmail.com>
 <CAPnyBTPNOp9UC3iCpzRWCyHYf4qFgW1GFbVpOuHd-T6wQCqPhw@mail.gmail.com>
 <CA+d==oFHUEnaLOWyCFCpxVYHvPzmHp2+G9KfTkJasF-UF+Upfg@mail.gmail.com>
Message-ID: <CAPnyBTORKctxFecio4bCtv0xw3rsstCSdLfUgW5HJBWmod+Osw@mail.gmail.com>

 Hi Gabriel,

thank you very much, I confirm I downloaded successfully the document, and
I'm going to read it carefully, although it will take me some time.

Still, my second question remains: is there any way of measuring the time
of getting some resource through squid?

Best regards,

Rafal Stanilewicz

On Wed, 30 Sep 2020 at 14:23, Service MV <service.mv at gmail.com> wrote:

> Below I leave the link. I think that with this you could achieve your
> goal. In this project there are more things that you might not want to use
> or maybe you do. To begin I believe that it is well.
>
>
>    - High availability load balancing frontend between users and backend
>    proxy nodes.
>    - VIP (floating IP) for the load balancers.
>    - Automatic configuration script for internal routing.
>    - Proxy pool with integrated Kerberos and LDAP authentication in
>    Active Directory
>    - Domain, IP, and port filtering
>    - Active Directory group browsing permissions
>    - Navigation reports by cost centers and/or individual users
>    - Bandwidth usage control per user.
>
>
> https://drive.google.com/file/d/1L3HiYs0LXaDZJOEHXVz8WrRFeJXXUBzU/view?usp=sharing
>
> Any question you may have, please reply with a copy to SQUID's mailing
> list in order to share with the community of users information that they
> may find useful.
>
> Best regards,
> Gabriel
>
> El mi?., 30 de sep. de 2020 a la(s) 05:12, Rafa? Stanilewicz (
> rst at fomar.com.pl) escribi?:
>
>> Hi Gabriel,
>>
>> although I do not know Spanish, a few of my friends do. Also, the most
>> important pieces will be code samples, which do not need translation. So if
>> you would be so kind and share the manual with me, I'd appreciate it very
>> much!
>>
>> Rafal
>>
>> On Tue, 29 Sep 2020 at 23:07, Service MV <service.mv at gmail.com> wrote:
>>
>>> Hi Rafal, if you wish I've a manual redacted in SPANISH for build a VM
>>> whit Debian 10.5 running SQUID compiled from source, with kerberos and LDAP
>>> authentication, plus AD groups authorizations.
>>>
>>> I haven't had time to translate it into English yet.
>>> Let me know if it works for you and I'll share it with you.
>>>
>>> Best regards,
>>> Gabriel
>>>
>>>
>>>
>>>
>>> El lun., 28 sep. 2020 10:19, Rafa? Stanilewicz <rst at fomar.com.pl>
>>> escribi?:
>>>
>>>> Hello,
>>>>
>>>> I'm planning the deployment of web proxy in my environment. It's not
>>>> very big, around 80 typical windows 10 workstations, active directory, plus
>>>> some DMZ servers. For now, there is very basic L7 inspection on the edge
>>>> firewall.
>>>>
>>>> I plan to use two separate squid instances, one for explicit proxy
>>>> traffic, forced by AD GPO settings, and second for traffic still being sent
>>>> directly to the Internet (as several applications we use tend to ignore the
>>>> system proxy settings). The first instance will use (hopefully) AD
>>>> authentication, while the second will use only srcIP-based rules. I will be
>>>> grateful for any comments, what should I focus on, or some quirks - I've
>>>> never deployed squid from scratch.
>>>>
>>>> But my main point of writing is:
>>>>
>>>> I'd like to get some numbers about squid-introduced latency of getting
>>>> some particular web resource. Is there any benchmarking program I could
>>>> use? I'd like to see what is the current latency of getting the resource
>>>> without any proxying, then of getting the same resource with explicit proxy
>>>> settings, then of implicit (intercepting) proxy option, as well as for
>>>> different options of caching.
>>>>
>>>> How should I start? Is there any software I can use to measure that,
>>>> besides analysis of HAR files?
>>>>
>>>> So far, I used squid only in home environment, and without a need for
>>>> granular measurement.
>>>>
>>>> Best regards,
>>>>
>>>> Rafal Stanilewicz
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>
>>
>> --
>> Zanim wydrukujesz, pomy?l o ?rodowisku.
>>
>

-- 
Zanim wydrukujesz, pomy?l o ?rodowisku.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201001/7debc436/attachment.htm>

From rentorbuy at yahoo.com  Thu Oct  1 13:25:07 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Thu, 1 Oct 2020 13:25:07 +0000 (UTC)
Subject: [squid-users] ACL matches when it shouldn't
References: <1086964811.736322.1601558707999.ref@mail.yahoo.com>
Message-ID: <1086964811.736322.1601558707999@mail.yahoo.com>

Thank you very much.
I will try to set up an external ACL so I don't have to worry about regular expressions.

Vieri


From tamurin0525 at gmail.com  Fri Oct  2 02:15:22 2020
From: tamurin0525 at gmail.com (m k)
Date: Fri, 2 Oct 2020 11:15:22 +0900
Subject: [squid-users] I want to know the concerns of load testing
Message-ID: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>

Hello,

I'm planning a proxy renewal for a company with 45k clients.
I'm looking at the performance of a single Squid to determine the number of
Squids.

Environment: Virtual (OpenStack)
OS: CentOS8.1
CPU: 4 cores
MEM: 8GB
DISK: SATA30GB / 100GB
Squid 4.4
 SSL Bump
 Blacklist: 1,700k
 auth: NTLM
 cache: 4GB

In an environment with authentication disabled and SSL decoding enabled
A load test was performed with Jmeter.

Result: CPU high load (100rps-1000rps: CPU Usage 80-90%)
(Confirm with top command)

Added multi-core support settings to squid.conf
"workers 4"

A load test with Jmeter was performed again.

Result: CPU load is distributed to 4 cores (CPU Usage 20-40%)
(Confirm with top command)

Question
1. 1. How much will CPU Usage increase if NTLM authentication is enabled?
2. 2. Are there any concerns other than CPU Usage in Squid?
3. 3. When I enabled the cache in this test, the CPU Usage decreased, but
in general, does the Squid cache increase the CPU Usage?

Thank you,
Kitamura
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201002/2d62f839/attachment.htm>

From tamurin0525 at gmail.com  Fri Oct  2 05:26:56 2020
From: tamurin0525 at gmail.com (m k)
Date: Fri, 2 Oct 2020 14:26:56 +0900
Subject: [squid-users] I want to know the concerns of load testing
In-Reply-To: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>
References: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>
Message-ID: <CAL-uOnGoC96=OAnbjsUHcj_SkGs3Czw5vxZbPaYc51TwXXHNWw@mail.gmail.com>

Hello Please tell me additionally. 4. I only know Squid up to 3000 users.
Is there any case where Squid is used by a company that is used by more
than 30,000 users? Please let me know if there is a large company using
Squid. 5. What are the important point when using the "wokers" setting for
multiple processes?

Kitamura

2020?10?2?(?) 11:15 m k <tamurin0525 at gmail.com>:

> Hello,
>
> I'm planning a proxy renewal for a company with 45k clients.
> I'm looking at the performance of a single Squid to determine the number
> of Squids.
>
> Environment: Virtual (OpenStack)
> OS: CentOS8.1
> CPU: 4 cores
> MEM: 8GB
> DISK: SATA30GB / 100GB
> Squid 4.4
>  SSL Bump
>  Blacklist: 1,700k
>  auth: NTLM
>  cache: 4GB
>
> In an environment with authentication disabled and SSL decoding enabled
> A load test was performed with Jmeter.
>
> Result: CPU high load (100rps-1000rps: CPU Usage 80-90%)
> (Confirm with top command)
>
> Added multi-core support settings to squid.conf
> "workers 4"
>
> A load test with Jmeter was performed again.
>
> Result: CPU load is distributed to 4 cores (CPU Usage 20-40%)
> (Confirm with top command)
>
> Question
> 1. 1. How much will CPU Usage increase if NTLM authentication is enabled?
> 2. 2. Are there any concerns other than CPU Usage in Squid?
> 3. 3. When I enabled the cache in this test, the CPU Usage decreased, but
> in general, does the Squid cache increase the CPU Usage?
>
> Thank you,
> Kitamura
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201002/ad3b3818/attachment.htm>

From squid3 at treenet.co.nz  Fri Oct  2 06:08:27 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 2 Oct 2020 19:08:27 +1300
Subject: [squid-users] I want to know the concerns of load testing
In-Reply-To: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>
References: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>
Message-ID: <2e0b245d-8e3e-b9a9-c440-e6c820a22339@treenet.co.nz>

On 2/10/20 3:15 pm, m k wrote:
> Hello,
> 
> I'm planning a proxy renewal for a company with 45k clients.
> I'm looking at the performance of a single Squid to determine the number
> of Squids.
> 
> Environment: Virtual (OpenStack)
> OS: CentOS8.1
> CPU: 4 cores
> MEM: 8GB
> DISK: SATA30GB / 100GB

See our notes on relative disk JBOD / RAID performances.
<https://wiki.squid-cache.org/SquidFaq/RAID>


> Squid 4.4

I know it can be hard to get hold of newer packages on CentOS. Please do
try hard to upgrade to the 4.13 release for production. There have been
more than a few critical security issues fixed this past year.


> ?SSL Bump
> ?Blacklist: 1,700k
> ?auth: NTLM

NTLM is a major performance issue. With every request needing to be sent
twice it will essentially halve the traffic your proxy can serve to clients.

I do know that Squid used to be able to handle way more RPS than Windows
DC would like to handle. So the DC may be a bottleneck there.

Negotiate/Kerberos auth is the solution to all those problems. If you
are really interested in good performance avoid NTLM.


> ?cache: 4GB
> 
> In an environment with authentication disabled and SSL decoding enabled
> A load test was performed with Jmeter.
> 
> Result: CPU high load (100rps-1000rps: CPU Usage 80-90%)
> (Confirm with top command)
> 

If the proxy is not using 100% of the core(s) it is supposed to be
using. Then you have not reached the capacity limits of the proxy.

What you do about that depends on whether you are trying to find
theoretical limits, or performance for a specific traffic profile.


For a specific traffic profile the measurement is likely hitting disk
I/O or network I/O limits. Double-check which it was - that is what to
change to improve performance.


For theoretical limits the same detail about I/O applies. But also to
max the proxy out fully you may need to tune the test traffic load for
either higher TCP connection concurrency, or to utilize less resource
consuming features. eg requests that will HIT on memory cached (small)
objects and only need simple fast-type ACL checks. Memory-only traffic
is approximately 100x faster than any involving disk I/O.

 To be clear this is to find the theoretical maximum performance. You
cannot tune clients real traffic like this.



> Added multi-core support settings to squid.conf
> "workers 4"
> 
> A load test with Jmeter was performed again.
> 
> Result: CPU load is distributed to 4 cores (CPU Usage 20-40%)
> (Confirm with top command)

See above. That 20% implies the same 80% is spread over 4 cores.


> 
> Question
> 1. 1. How much will CPU Usage increase if NTLM authentication is enabled?

NTLM requires 2 HTTP messages to authenticate every new TCP connection.
So there will be one extra HTTP message on every set of pipelined requests.

It depends on how many requests are pipelined on each TCP connection as
to how much impact that auth overhead is.


After disk I/O capacity the CPU cycles are what limit Squid most. The
RPS achievable is capped out when all CPU cores assigned for Squid reach
100%.


> 2. 2. Are there any concerns other than CPU Usage in Squid?

The usual bottlenecks:

 * disk I/O limits
 * Network latency (DNS in particular. In general, TCP to _everywhere_)
 * features used (CPU drains)
 * memory

The order is my own experience of service impact, YMMV


> 3. 3. When I enabled the cache in this test, the CPU Usage decreased,
> but in general, does the Squid cache increase the CPU Usage?


In general cache should have little effect on CPU. Processing HTTP
headers is by far the major use of CPU cycles in Squid. SSL-Bump is
expected to be a close second, especially if decrypting.

In some cases it can. A large number of small cache objects can consume
many cycles CPU searching for an object. Or Range requests on very large
objects can spend a lot of cycles to generate the Range response HIT
payload.



HTH
Amos


From squid3 at treenet.co.nz  Fri Oct  2 06:20:50 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 2 Oct 2020 19:20:50 +1300
Subject: [squid-users] I want to know the concerns of load testing
In-Reply-To: <CAL-uOnGoC96=OAnbjsUHcj_SkGs3Czw5vxZbPaYc51TwXXHNWw@mail.gmail.com>
References: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>
 <CAL-uOnGoC96=OAnbjsUHcj_SkGs3Czw5vxZbPaYc51TwXXHNWw@mail.gmail.com>
Message-ID: <0e09892e-6ad4-35e4-3dd6-42d801f42b18@treenet.co.nz>

On 2/10/20 6:26 pm, m k wrote:
> Hello Please tell me additionally. 4. I only know Squid up to 3000
> users. Is there any case where Squid is used by a company that is used
> by more than 30,000 users? Please let me know if there is a large
> company using Squid. 5. What are the important point when using the
> "wokers" setting for multiple processes?? 


We do not measure HTTP proxies in terms of users because this is a
meaningless measurement.

One single User can flood the network and overload the proxy with traffic.

Or, many thousands could be connected and waiting with barely any
requests going through.

Or anything in between.


The important number is how many users you expect to make requests of
the proxy simultaneously at peak traffic time.

Be aware that what happens when Squid "overloads" its capacity is just
an increase in service latency. Users still receives and processes every
transaction. It can just take a short while longer than normal to
complete each - depending on which resource bottleneck that transaction
interacts with.

Amos


From rentorbuy at yahoo.com  Fri Oct  2 09:08:14 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Fri, 2 Oct 2020 09:08:14 +0000 (UTC)
Subject: [squid-users] ACL matches when it shouldn't
References: <1969449828.1124895.1601629694883.ref@mail.yahoo.com>
Message-ID: <1969449828.1124895.1601629694883@mail.yahoo.com>


Regarding the use of an external ACL I quickly implemented a perl script that "does the job", but it seems to be somewhat sluggish.

This is how it's configured in squid.conf:
external_acl_type bllookup ttl=86400 negative_ttl=86400 children-max=80 children-startup=10 children-idle=3 concurrency=8 %PROTO %DST %PORT %PATH /opt/custom/scripts/squid/ext_txt_blwl_acl.pl --categories=adv,aggressive,alcohol,anonvpn,automobile_bikes,automobile_boats,automobile_cars,automobile_planes,chat,costtraps,dating,drugs,dynamic,finance_insurance,finance_moneylending,finance_other,finance_realestate,finance_trading,fortunetelling,forum,gamble,hacking,hobby_cooking,hobby_games-misc,hobby_games-online,hobby_gardening,hobby_pets,homestyle,ibs,imagehosting,isp,jobsearch,military,models,movies,music,podcasts,politics,porn,radiotv,recreation_humor,recreation_martialarts,recreation_restaurants,recreation_sports,recreation_travel,recreation_wellness,redirector,religion,remotecontrol,ringtones,science_astronomy,science_chemistry,sex_education,sex_lingerie,shopping,socialnet,spyware,tracker,updatesites,urlshortener,violence,warez,weapons,webphone,webradio,webtv

I'd like to avoid the use of a DB if possible, but maybe someone here has an idea to share on flat file text searches.

Currently the dir structure of my blacklists is:

topdir
category1 ... categoryN
domains urls

So basically one example file to search in is topdir/category8/urls, etc.

The helper perl script contains this code to decide whether to block access or not:

foreach( @categories )
{
??????? chomp($s_urls = qx{grep -nwx '$uri_dst$uri_path' $cats_where/$_/urls | head -n 1 | cut -f1 -d:});

??????? if (length($s_urls) > 0) {
??????????? if ($whitelist == 0) {
??????????????? $status = $cid." ERR message=\"URL ".$uri_dst." in BL ".$_." (line ".$s_urls.")\"";
??????????? } else {
??????????????? $status = $cid." ERR message=\"URL ".$uri_dst." not in WL ".$_." (line ".$s_urls.")\"";
??????????? }
??????????? next;
??????? }

??????? chomp($s_urls = qx{grep -nwx '$uri_dst' $cats_where/$_/domains | head -n 1 | cut -f1 -d:});

??????? if (length($s_urls) > 0) {
??????????? if ($whitelist == 0) {
??????????????? $status = $cid." ERR message=\"Domain ".$uri_dst." in BL ".$_." (line ".$s_urls.")\"";
??????????? } else {
??????????????? $status = $cid." ERR message=\"Domain ".$uri_dst." not in WL ".$_." (line ".$s_urls.")\"";
??????????? }
??????????? next;
??????? }
}

There are currently 66 "categories" with around 50MB of text data in all.
So that's a lot to go through each time there's an HTTP request.
Apart from placing these blacklists on a ramdisk (currently on an M.2 SSD disk so I'm not sure I'll notice anything) what else can I try?
Should I reindex the lists and group them all alphabetically?
For instance should I process the lists in order to generate a dir structure as follows?

topdir
a b c d e f ... x y z 0 1 2 3 ... 7 8 9
domains urls

An example for a client requesting https://www.google.com/ would lead to searching only 2 files:
topdir/w/domains
topdir/w/urls

An example for a client requesting https://01.whatever.com/x would also lead to searching only 2 files:
topdir/0/domains
topdir/0/urls

An example for a client requesting https://8.8.8.8/xyz would also lead to searching only 2 files:
topdir/8/domains
topdir/8/urls

Any ideas or links to scripts that already prepare lists for this?

Thanks,

Vieri


From marcus.kool at urlfilterdb.com  Fri Oct  2 10:28:57 2020
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Fri, 2 Oct 2020 11:28:57 +0100
Subject: [squid-users] ACL matches when it shouldn't
In-Reply-To: <1969449828.1124895.1601629694883@mail.yahoo.com>
References: <1969449828.1124895.1601629694883.ref@mail.yahoo.com>
 <1969449828.1124895.1601629694883@mail.yahoo.com>
Message-ID: <603c5ae1-9fbe-c67e-08e1-a1b5c279cbad@urlfilterdb.com>

Of course this script is sluggish since it reads many category files and forks at least 3-6 times.

If you *really* want to implement this with a perl script, it should read all files at startup and the script does a lookup using perl data structures.

But I suggest to look at ufdbGuard which is a URL filter that is way faster and has all functionality that you need.

Marcus


On 2020-10-02 10:08, Vieri wrote:
> Regarding the use of an external ACL I quickly implemented a perl script that "does the job", but it seems to be somewhat sluggish.
>
> This is how it's configured in squid.conf:
> external_acl_type bllookup ttl=86400 negative_ttl=86400 children-max=80 children-startup=10 children-idle=3 concurrency=8 %PROTO %DST %PORT %PATH /opt/custom/scripts/squid/ext_txt_blwl_acl.pl --categories=adv,aggressive,alcohol,anonvpn,automobile_bikes,automobile_boats,automobile_cars,automobile_planes,chat,costtraps,dating,drugs,dynamic,finance_insurance,finance_moneylending,finance_other,finance_realestate,finance_trading,fortunetelling,forum,gamble,hacking,hobby_cooking,hobby_games-misc,hobby_games-online,hobby_gardening,hobby_pets,homestyle,ibs,imagehosting,isp,jobsearch,military,models,movies,music,podcasts,politics,porn,radiotv,recreation_humor,recreation_martialarts,recreation_restaurants,recreation_sports,recreation_travel,recreation_wellness,redirector,religion,remotecontrol,ringtones,science_astronomy,science_chemistry,sex_education,sex_lingerie,shopping,socialnet,spyware,tracker,updatesites,urlshortener,violence,warez,weapons,webphone,webradio,webtv
>
> I'd like to avoid the use of a DB if possible, but maybe someone here has an idea to share on flat file text searches.
>
> Currently the dir structure of my blacklists is:
>
> topdir
> category1 ... categoryN
> domains urls
>
> So basically one example file to search in is topdir/category8/urls, etc.
>
> The helper perl script contains this code to decide whether to block access or not:
>
> foreach( @categories )
> {
>  ??????? chomp($s_urls = qx{grep -nwx '$uri_dst$uri_path' $cats_where/$_/urls | head -n 1 | cut -f1 -d:});
>
>  ??????? if (length($s_urls) > 0) {
>  ??????????? if ($whitelist == 0) {
>  ??????????????? $status = $cid." ERR message=\"URL ".$uri_dst." in BL ".$_." (line ".$s_urls.")\"";
>  ??????????? } else {
>  ??????????????? $status = $cid." ERR message=\"URL ".$uri_dst." not in WL ".$_." (line ".$s_urls.")\"";
>  ??????????? }
>  ??????????? next;
>  ??????? }
>
>  ??????? chomp($s_urls = qx{grep -nwx '$uri_dst' $cats_where/$_/domains | head -n 1 | cut -f1 -d:});
>
>  ??????? if (length($s_urls) > 0) {
>  ??????????? if ($whitelist == 0) {
>  ??????????????? $status = $cid." ERR message=\"Domain ".$uri_dst." in BL ".$_." (line ".$s_urls.")\"";
>  ??????????? } else {
>  ??????????????? $status = $cid." ERR message=\"Domain ".$uri_dst." not in WL ".$_." (line ".$s_urls.")\"";
>  ??????????? }
>  ??????????? next;
>  ??????? }
> }
>
> There are currently 66 "categories" with around 50MB of text data in all.
> So that's a lot to go through each time there's an HTTP request.
> Apart from placing these blacklists on a ramdisk (currently on an M.2 SSD disk so I'm not sure I'll notice anything) what else can I try?
> Should I reindex the lists and group them all alphabetically?
> For instance should I process the lists in order to generate a dir structure as follows?
>
> topdir
> a b c d e f ... x y z 0 1 2 3 ... 7 8 9
> domains urls
>
> An example for a client requesting https://www.google.com/ would lead to searching only 2 files:
> topdir/w/domains
> topdir/w/urls
>
> An example for a client requesting https://01.whatever.com/x would also lead to searching only 2 files:
> topdir/0/domains
> topdir/0/urls
>
> An example for a client requesting https://8.8.8.8/xyz would also lead to searching only 2 files:
> topdir/8/domains
> topdir/8/urls
>
> Any ideas or links to scripts that already prepare lists for this?
>
> Thanks,
>
> Vieri
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Fri Oct  2 14:01:20 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 2 Oct 2020 10:01:20 -0400
Subject: [squid-users] I want to know the concerns of load testing
In-Reply-To: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>
References: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>
Message-ID: <f9037b85-6364-f395-f0e1-57194c355f0a@measurement-factory.com>

On 10/1/20 10:15 PM, m k wrote:

> 1. How much will CPU Usage increase if NTLM authentication is enabled?

Depends on the portion of requests that need to be authenticated,
credentials caching effectiveness, and authenticator response times.
Nothing is easy in performance testing, but it is often easier to
measure performance than to predict it -- good proxy benchmarking tools
support testing proxy authentication.


> 2. Are there any concerns other than CPU Usage in Squid?

On servers dedicated to Squids, CPU usage is not really a concern as
such. It is a convenient but often misleading proxy (i.e. indirect
measure) for real concerns. The real concerns are errors, response times
and, in some environments, bandwidth usage. A good benchmark should
report those measurements.


> 3. When I enabled the cache in this test, the CPU Usage decreased,
> but in general, does the Squid cache increase the CPU Usage?

The answer depends on many factors such as document hit ratio, byte hit
ratio, the portion of the contents that comes from the disk cache
(rather than memory cache), hot subset, and server delays. Bugs
notwithstanding, if caching is worth enabling at all, then a correctly
configured cache decreases CPU usage in most environments (because it
decreases the amount of work that Squid should do for an average
transaction).

Please keep in mind that benchmarking a _caching_ proxy correctly is far
from trivial! Make sure your setup does not measure performance of a
cache with artificially high (or low) hit ratio, performance of a
virtually empty cache, etc.


HTH,

Alex.


From rousskov at measurement-factory.com  Fri Oct  2 14:08:59 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 2 Oct 2020 10:08:59 -0400
Subject: [squid-users] I want to know the concerns of load testing
In-Reply-To: <CAL-uOnGoC96=OAnbjsUHcj_SkGs3Czw5vxZbPaYc51TwXXHNWw@mail.gmail.com>
References: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>
 <CAL-uOnGoC96=OAnbjsUHcj_SkGs3Czw5vxZbPaYc51TwXXHNWw@mail.gmail.com>
Message-ID: <d8b350cf-9f9e-992a-a08a-0c5d9fc60918@measurement-factory.com>

On 10/2/20 1:26 AM, m k wrote:

> Is there any case where Squid is used by a company that is used
> by more than 30,000 users?

Yes, some Squid (hierarchies) probably serve millions of users. I know
several companies using Squids for serving large user populations, but I
cannot name customer names.


> What are the important point when using the
> "wokers" setting for multiple processes???

For a few starting points, please see

*
https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F

* the recently added "worker-queues" configuration option:
  https://github.com/squid-cache/squid/pull/369


HTH,

Alex.


> 2020?10?2?(?) 11:15 m k:
> 
>     Hello,
> 
>     I'm planning a proxy renewal for a company with 45k clients.
>     I'm looking at the performance of a single Squid to determine the
>     number of Squids.
> 
>     Environment: Virtual (OpenStack)
>     OS: CentOS8.1
>     CPU: 4 cores
>     MEM: 8GB
>     DISK: SATA30GB / 100GB
>     Squid 4.4
>     ?SSL Bump
>     ?Blacklist: 1,700k
>     ?auth: NTLM
>     ?cache: 4GB
> 
>     In an environment with authentication disabled and SSL decoding enabled
>     A load test was performed with Jmeter.
> 
>     Result: CPU high load (100rps-1000rps: CPU Usage 80-90%)
>     (Confirm with top command)
> 
>     Added multi-core support settings to squid.conf
>     "workers 4"
> 
>     A load test with Jmeter was performed again.
> 
>     Result: CPU load is distributed to 4 cores (CPU Usage 20-40%)
>     (Confirm with top command)
> 
>     Question
>     1. 1. How much will CPU Usage increase if NTLM authentication is
>     enabled?
>     2. 2. Are there any concerns other than CPU Usage in Squid?
>     3. 3. When I enabled the cache in this test, the CPU Usage
>     decreased, but in general, does the Squid cache increase the CPU Usage?
> 
>     Thank you,
>     Kitamura
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From mrumph68 at gmail.com  Fri Oct  2 16:48:54 2020
From: mrumph68 at gmail.com (Mike Rumph)
Date: Fri, 2 Oct 2020 09:48:54 -0700
Subject: [squid-users] measuring latency of squid in different scenarios
In-Reply-To: <CAPnyBTORKctxFecio4bCtv0xw3rsstCSdLfUgW5HJBWmod+Osw@mail.gmail.com>
References: <CAPnyBTPt+3WyVpk25UQ_1v3Jk2bjMv9tdtNESwSQ3a+Q32beOg@mail.gmail.com>
 <CA+d==oGjm5BgsCgLV9Hxcaut+hxTxB=_DFG+aEPy=vAH_hvazg@mail.gmail.com>
 <CAPnyBTPNOp9UC3iCpzRWCyHYf4qFgW1GFbVpOuHd-T6wQCqPhw@mail.gmail.com>
 <CA+d==oFHUEnaLOWyCFCpxVYHvPzmHp2+G9KfTkJasF-UF+Upfg@mail.gmail.com>
 <CAPnyBTORKctxFecio4bCtv0xw3rsstCSdLfUgW5HJBWmod+Osw@mail.gmail.com>
Message-ID: <CAKkihnz4kgEbP6CXhGrmW=y3W0MGGs0BKb8E5keHe0R+N1C8cQ@mail.gmail.com>

Hello Rafal,

I have run some performance tests with WRK for Squid running as a proxy to
a backend Apache httpd server.
This gives an example of latency measurements for Squid.
-
https://github.com/mrumph/futurewei-ecosystems/blob/master/tests/wrk/squid_proxy.txt

Maybe this will be useful for you.

Thanks,

Mike Rumph

On Thu, Oct 1, 2020 at 2:45 AM Rafa? Stanilewicz <rst at fomar.com.pl> wrote:

>  Hi Gabriel,
>
> thank you very much, I confirm I downloaded successfully the document, and
> I'm going to read it carefully, although it will take me some time.
>
> Still, my second question remains: is there any way of measuring the time
> of getting some resource through squid?
>
> Best regards,
>
> Rafal Stanilewicz
>
> On Wed, 30 Sep 2020 at 14:23, Service MV <service.mv at gmail.com> wrote:
>
>> Below I leave the link. I think that with this you could achieve your
>> goal. In this project there are more things that you might not want to use
>> or maybe you do. To begin I believe that it is well.
>>
>>
>>    - High availability load balancing frontend between users and backend
>>    proxy nodes.
>>    - VIP (floating IP) for the load balancers.
>>    - Automatic configuration script for internal routing.
>>    - Proxy pool with integrated Kerberos and LDAP authentication in
>>    Active Directory
>>    - Domain, IP, and port filtering
>>    - Active Directory group browsing permissions
>>    - Navigation reports by cost centers and/or individual users
>>    - Bandwidth usage control per user.
>>
>>
>> https://drive.google.com/file/d/1L3HiYs0LXaDZJOEHXVz8WrRFeJXXUBzU/view?usp=sharing
>>
>> Any question you may have, please reply with a copy to SQUID's mailing
>> list in order to share with the community of users information that they
>> may find useful.
>>
>> Best regards,
>> Gabriel
>>
>> El mi?., 30 de sep. de 2020 a la(s) 05:12, Rafa? Stanilewicz (
>> rst at fomar.com.pl) escribi?:
>>
>>> Hi Gabriel,
>>>
>>> although I do not know Spanish, a few of my friends do. Also, the most
>>> important pieces will be code samples, which do not need translation. So if
>>> you would be so kind and share the manual with me, I'd appreciate it very
>>> much!
>>>
>>> Rafal
>>>
>>> On Tue, 29 Sep 2020 at 23:07, Service MV <service.mv at gmail.com> wrote:
>>>
>>>> Hi Rafal, if you wish I've a manual redacted in SPANISH for build a VM
>>>> whit Debian 10.5 running SQUID compiled from source, with kerberos and LDAP
>>>> authentication, plus AD groups authorizations.
>>>>
>>>> I haven't had time to translate it into English yet.
>>>> Let me know if it works for you and I'll share it with you.
>>>>
>>>> Best regards,
>>>> Gabriel
>>>>
>>>>
>>>>
>>>>
>>>> El lun., 28 sep. 2020 10:19, Rafa? Stanilewicz <rst at fomar.com.pl>
>>>> escribi?:
>>>>
>>>>> Hello,
>>>>>
>>>>> I'm planning the deployment of web proxy in my environment. It's not
>>>>> very big, around 80 typical windows 10 workstations, active directory, plus
>>>>> some DMZ servers. For now, there is very basic L7 inspection on the edge
>>>>> firewall.
>>>>>
>>>>> I plan to use two separate squid instances, one for explicit proxy
>>>>> traffic, forced by AD GPO settings, and second for traffic still being sent
>>>>> directly to the Internet (as several applications we use tend to ignore the
>>>>> system proxy settings). The first instance will use (hopefully) AD
>>>>> authentication, while the second will use only srcIP-based rules. I will be
>>>>> grateful for any comments, what should I focus on, or some quirks - I've
>>>>> never deployed squid from scratch.
>>>>>
>>>>> But my main point of writing is:
>>>>>
>>>>> I'd like to get some numbers about squid-introduced latency of getting
>>>>> some particular web resource. Is there any benchmarking program I could
>>>>> use? I'd like to see what is the current latency of getting the resource
>>>>> without any proxying, then of getting the same resource with explicit proxy
>>>>> settings, then of implicit (intercepting) proxy option, as well as for
>>>>> different options of caching.
>>>>>
>>>>> How should I start? Is there any software I can use to measure that,
>>>>> besides analysis of HAR files?
>>>>>
>>>>> So far, I used squid only in home environment, and without a need for
>>>>> granular measurement.
>>>>>
>>>>> Best regards,
>>>>>
>>>>> Rafal Stanilewicz
>>>>>
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>>>
>>>
>>> --
>>> Zanim wydrukujesz, pomy?l o ?rodowisku.
>>>
>>
>
> --
> Zanim wydrukujesz, pomy?l o ?rodowisku.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201002/2409bb79/attachment.htm>

From Ralf.Hildebrandt at charite.de  Mon Oct  5 14:06:06 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Mon, 5 Oct 2020 16:06:06 +0200
Subject: [squid-users] ERR_TUNNEL_CONNECTION_FAILED
Message-ID: <20201005140606.mnzjung2wrwcahef@charite.de>

I'm getting "ERR_TUNNEL_CONNECTION_FAILED" errors in Chrome when
connecting to https://securefiles.laborberlin.com/

Squid logs:

1601906504.874      0 141.42.231.251 NONE_NONE/500 0 CONNECT securefiles.laborberlin.com:443 - HIER_NONE/- - accessRule=- -
1601906505.047      0 141.42.231.251 NONE_NONE/500 0 CONNECT securefiles.laborberlin.com:443 - HIER_NONE/- - accessRule=- -
1601906505.225      0 141.42.231.251 NONE_NONE/500 0 CONNECT securefiles.laborberlin.com:443 - HIER_NONE/- - accessRule=- -

The squid process should be able to resolve the hostname...

I explicitly set an dns_nameservers entry, like this:
dns_nameservers 141.42.5.156 141.42.5.157

Testin on the squid machine:

# dig +short @141.42.5.156 securefiles.laborberlin.com 
607748248.dracoon.cloud.
# dig +short @141.42.5.156 607748248.dracoon.cloud
213.95.134.242

# dig +short @141.42.5.157 securefiles.laborberlin.com
607748248.dracoon.cloud.
# dig +short @141.42.5.157 607748248.dracoon.cloud
213.95.134.242

So what is the reason for the NONE_NONE/500 error?


Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From Ralf.Hildebrandt at charite.de  Mon Oct  5 14:08:54 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Mon, 5 Oct 2020 16:08:54 +0200
Subject: [squid-users] [ext]  ERR_TUNNEL_CONNECTION_FAILED
In-Reply-To: <20201005140606.mnzjung2wrwcahef@charite.de>
References: <20201005140606.mnzjung2wrwcahef@charite.de>
Message-ID: <20201005140854.ddnvh5l22tx75dk6@charite.de>

* Ralf Hildebrandt <Ralf.Hildebrandt at charite.de>:
> I'm getting "ERR_TUNNEL_CONNECTION_FAILED" errors in Chrome when
> connecting to https://securefiles.laborberlin.com/

And Firefox!

> # dig +short @141.42.5.156 607748248.dracoon.cloud
> 213.95.134.242

https://607748248.dracoon.cloud/
ist working ok!

Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From Ralf.Hildebrandt at charite.de  Mon Oct  5 15:46:52 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Mon, 5 Oct 2020 17:46:52 +0200
Subject: [squid-users] [ext]  ERR_TUNNEL_CONNECTION_FAILED
In-Reply-To: <20201005140606.mnzjung2wrwcahef@charite.de>
References: <20201005140606.mnzjung2wrwcahef@charite.de>
Message-ID: <20201005154652.xecyxvaahl4hll5x@charite.de>

> 1601906504.874      0 141.42.231.251 NONE_NONE/500 0 CONNECT securefiles.laborberlin.com:443 - HIER_NONE/- - accessRule=- -
> 1601906505.047      0 141.42.231.251 NONE_NONE/500 0 CONNECT securefiles.laborberlin.com:443 - HIER_NONE/- - accessRule=- -
> 1601906505.225      0 141.42.231.251 NONE_NONE/500 0 CONNECT securefiles.laborberlin.com:443 - HIER_NONE/- - accessRule=- -

cache.log is more verbose with a similar domain (iris.charite.de):
2020/10/05 17:45:37| DNS error while resolving iris.charite.de: No valid address records

# dig +short @141.42.5.157 iris.charite.de
charite.science-it.ch.

# dig +short @141.42.5.157 charite.science-it.ch
iris.science-it.ch.
35.180.69.77

Huh? No valid address records?



Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From rousskov at measurement-factory.com  Mon Oct  5 16:02:23 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 5 Oct 2020 12:02:23 -0400
Subject: [squid-users] [ext] ERR_TUNNEL_CONNECTION_FAILED
In-Reply-To: <20201005154652.xecyxvaahl4hll5x@charite.de>
References: <20201005140606.mnzjung2wrwcahef@charite.de>
 <20201005154652.xecyxvaahl4hll5x@charite.de>
Message-ID: <e09ff3e8-6e11-d382-82ed-45abf41fdcc5@measurement-factory.com>

On 10/5/20 11:46 AM, Ralf Hildebrandt wrote:

> 2020/10/05 17:45:37| DNS error while resolving iris.charite.de: No valid address records

> # dig +short @141.42.5.157 iris.charite.de
> charite.science-it.ch.

By "valid address records" Squid means "valid A or AAAA address
records". The above response does not contain such records.

Squid does not do DNS recursion, CNAME resolution, etc. Make sure your
resolver does all that.


HTH,

Alex.


From nisa.balakrishnan at servian.com  Tue Oct  6 00:35:56 2020
From: nisa.balakrishnan at servian.com (Nisa Balakrishnan)
Date: Tue, 6 Oct 2020 11:35:56 +1100
Subject: [squid-users] sslproxy_options on squid 3.5.20
Message-ID: <CAKKyJc-EspaZOtGBqPUZ7fB3djHqPZQ6Bvrm-O_B-rKA+g4o=w@mail.gmail.com>

Hi,

I am trying to allow access for only tls versions 1.2 and above on Squid
3.5.20

For testing purposes, I have set options in squid config as follows.

```
https_port 3130 cert=/etc/squid/ssl/squid.pem ssl-bump intercept
options=NO_SSLv2,NO_SSLv3,NO_TLSv1,NO_TLSv1_2

sslproxy_options NO_SSLv2,NO_SSLv3,NO_TLSv1,NO_TLSv1_2
```

I test using curl
```
curl -v https://api.github.com/users/xyz
```

I am able to access github and the ssl connection is tls 1.2

```
*   Trying 13.236.14.80...
* TCP_NODELAY set
* Connected to api.github.com (13.236.14.80) port 443 (#0)
* ALPN, offering h2
* ALPN, offering http/1.1
* Cipher selection:
ALL:!EXPORT:!EXPORT40:!EXPORT56:!aNULL:!LOW:!RC4:@STRENGTH
* successfully set certificate verify locations:
*   CAfile: /etc/pki/tls/certs/ca-bundle.crt
  CApath: none
* TLSv1.2 (OUT), TLS header, Certificate Status (22):
* TLSv1.2 (OUT), TLS handshake, Client hello (1):
* TLSv1.2 (IN), TLS handshake, Server hello (2):
* TLSv1.2 (IN), TLS handshake, Certificate (11):
* TLSv1.2 (IN), TLS handshake, Server key exchange (12):
* TLSv1.2 (IN), TLS handshake, Server finished (14):
* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):
* TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1):
* TLSv1.2 (OUT), TLS handshake, Finished (20):
* TLSv1.2 (IN), TLS change cipher, Change cipher spec (1):
* TLSv1.2 (IN), TLS handshake, Finished (20):
* SSL connection using TLSv1.2 / ECDHE-RSA-AES128-GCM-SHA256
* ALPN, server accepted to use http/1.1
* Server certificate:
*  subject: C=US; ST=California; L=San Francisco; O=GitHub, Inc.; CN=*.
github.com
*  start date: Jun 22 00:00:00 2020 GMT
*  expire date: Aug 17 12:00:00 2022 GMT
*  subjectAltName: host "api.github.com" matched cert's "*.github.com"
*  issuer: C=US; O=DigiCert Inc; OU=www.digicert.com; CN=DigiCert SHA2 High
Assurance Server CA
*  SSL certificate verify ok.
> GET /users/xyz HTTP/1.1
> Host: api.github.com
> User-Agent: curl/7.61.1
> Accept: */*
>
< HTTP/1.1 200 OK
< date: Mon, 05 Oct 2020 22:57:40 GMT
< content-type: application/json; charset=utf-8
< server: GitHub.com
< status: 200 OK
< cache-control: public, max-age=60, s-maxage=60
< vary: Accept, Accept-Encoding, Accept, X-Requested-With, Accept-Encoding
< etag: W/"3d107946387d86803650c009a9371dc5efd5ba2d670e838c30af583505243e83"
< last-modified: Wed, 23 May 2018 19:43:26 GMT
< x-github-media-type: github.v3; format=json
< access-control-expose-headers: ETag, Link, Location, Retry-After,
X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used,
X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes,
X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset
< access-control-allow-origin: *
< strict-transport-security: max-age=31536000; includeSubdomains; preload
< x-frame-options: deny
< x-content-type-options: nosniff
< x-xss-protection: 1; mode=block
< referrer-policy: origin-when-cross-origin, strict-origin-when-cross-origin
< content-security-policy: default-src 'none'
< X-Ratelimit-Limit: 60
< X-Ratelimit-Remaining: 59
< X-Ratelimit-Reset: 1601942260
< X-Ratelimit-Used: 1
< Accept-Ranges: bytes
< Content-Length: 1220
< X-GitHub-Request-Id: A62E:3674:BB684:D9799:5F7BA4E4
<
{
  "login": "xyz",
  "id": 14513,
  "node_id": "MDQ6VXNlcjE0NTEz",
  "avatar_url": "https://avatars1.githubusercontent.com/u/14513?v=4",
  "gravatar_id": "",
  "url": "https://api.github.com/users/xyz",
  "html_url": "https://github.com/xyz",
  "followers_url": "https://api.github.com/users/xyz/followers",
  "following_url": "https://api.github.com/users/xyz/following{/other_user}
",
  "gists_url": "https://api.github.com/users/xyz/gists{/gist_id}",
  "starred_url": "https://api.github.com/users/xyz/starred{/owner}{/repo}",
  "subscriptions_url": "https://api.github.com/users/xyz/subscriptions",
  "organizations_url": "https://api.github.com/users/xyz/orgs",
  "repos_url": "https://api.github.com/users/xyz/repos",
  "events_url": "https://api.github.com/users/xyz/events{/privacy}",
  "received_events_url": "https://api.github.com/users/xyz/received_events",
  "type": "User",
  "site_admin": false,
  "name": "xyz",
  "company": null,
  "blog": "",
  "location": null,
  "email": null,
  "hireable": null,
  "bio": null,
  "twitter_username": null,
  "public_repos": 1,
  "public_gists": 0,
  "followers": 8,
  "following": 1,
  "created_at": "2008-06-21T11:58:01Z",
  "updated_at": "2018-05-23T19:43:26Z"
}
* Connection #0 to host api.github.com left intact
```
Despite setting no tls 1.2, I am able to successfully make a connection.
What am I missing here?
Any help much appreciated.

-- 

*Nisa Balakrishnan*      AutomationEngineer | m: 0473942819 | p: 03 9081
3700 <+61390813700>
Level 20, Tower 5, Collins Square, 727 Collins Street, Docklands VIC 3008

Vibrato has merged with Servian! Check out the news article here
<https://www.arnnet.com.au/article/664971/servian-nabs-vibrato-multi-million-dollar-deal/>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201006/54d1f667/attachment.htm>

From squid3 at treenet.co.nz  Tue Oct  6 09:27:54 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Oct 2020 22:27:54 +1300
Subject: [squid-users] sslproxy_options on squid 3.5.20
In-Reply-To: <CAKKyJc-EspaZOtGBqPUZ7fB3djHqPZQ6Bvrm-O_B-rKA+g4o=w@mail.gmail.com>
References: <CAKKyJc-EspaZOtGBqPUZ7fB3djHqPZQ6Bvrm-O_B-rKA+g4o=w@mail.gmail.com>
Message-ID: <2923e609-4944-ddc8-5416-c96d68816f47@treenet.co.nz>

On 6/10/20 1:35 pm, Nisa Balakrishnan wrote:
> Hi,
> 
> I am trying to allow access for only tls versions 1.2 and above on Squid
> 3.5.20
> 

Note that "above 1.2" are not supported by that ancient version of
Squid. Your test disables everything except SSLv1 code in the library.


> For testing purposes, I have set options in squid config as follows.
> 
> ```
> https_port 3130 cert=/etc/squid/ssl/squid.pem ssl-bump intercept
> options=NO_SSLv2,NO_SSLv3,NO_TLSv1,NO_TLSv1_2
> 
> sslproxy_options NO_SSLv2,NO_SSLv3,NO_TLSv1,NO_TLSv1_2
> ```
> 

Support for all those options depends on the version, build options, and
global config settings of the OpenSSL library being used. They are just
flags Squid passes to the library on connection setup.


FWIW 3.1.20 is over 4 years old and a huge amount of change has happened
to TLS since then. Please try to upgrade to current Squid-4 stable, or
for best SSL-Bump behaviour the current Squid-5 beta.

Amos


From ronanlucio at gmail.com  Wed Oct  7 01:16:03 2020
From: ronanlucio at gmail.com (Ronan Lucio)
Date: Wed, 7 Oct 2020 14:16:03 +1300
Subject: [squid-users] SSL on different ports
Message-ID: <CAF-5T9GVm5tJ6V9_M=wxA66AeSfutkJw5F0x+uUuUqfVxV1ryw@mail.gmail.com>

Hi,

By default, Squid accepts SSL connection only to port 443.
Are there any security concerns when need to accept HTTPS connections
on other ports?

Thank you,
Ronan


From nisa.balakrishnan at servian.com  Wed Oct  7 01:22:56 2020
From: nisa.balakrishnan at servian.com (Nisa Balakrishnan)
Date: Wed, 7 Oct 2020 12:22:56 +1100
Subject: [squid-users] sslproxy_options on squid 3.5.20
In-Reply-To: <2923e609-4944-ddc8-5416-c96d68816f47@treenet.co.nz>
References: <CAKKyJc-EspaZOtGBqPUZ7fB3djHqPZQ6Bvrm-O_B-rKA+g4o=w@mail.gmail.com>
 <2923e609-4944-ddc8-5416-c96d68816f47@treenet.co.nz>
Message-ID: <CAKKyJc8YKyqkzBTWJrzP+BdKVLwCCF7pNEhnqKA7dWK4bie_1A@mail.gmail.com>

Thanks Amos.

I have verified that squid build is done with openssl that supports 1.2 but
not 1.3.
I am worried that squid does not pass the flag set via options.
I am able to lock squid to tls 1.2 only with sslproxy_version

To be a bit more clear, the squid implementation is a whitelist filtering
proxy. It does not bump ssl requests. It does peek and splice on intercept.

On Tue, 6 Oct 2020 at 20:34, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 6/10/20 1:35 pm, Nisa Balakrishnan wrote:
> > Hi,
> >
> > I am trying to allow access for only tls versions 1.2 and above on Squid
> > 3.5.20
> >
>
> Note that "above 1.2" are not supported by that ancient version of
> Squid. Your test disables everything except SSLv1 code in the library.
>
>
> > For testing purposes, I have set options in squid config as follows.
> >
> > ```
> > https_port 3130 cert=/etc/squid/ssl/squid.pem ssl-bump intercept
> > options=NO_SSLv2,NO_SSLv3,NO_TLSv1,NO_TLSv1_2
> >
> > sslproxy_options NO_SSLv2,NO_SSLv3,NO_TLSv1,NO_TLSv1_2
> > ```
> >
>
> Support for all those options depends on the version, build options, and
> global config settings of the OpenSSL library being used. They are just
> flags Squid passes to the library on connection setup.
>
>
> FWIW 3.1.20 is over 4 years old and a huge amount of change has happened
> to TLS since then. Please try to upgrade to current Squid-4 stable, or
> for best SSL-Bump behaviour the current Squid-5 beta.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 

*Nisa Balakrishnan*      AutomationEngineer | m: 0473942819 | p: 03 9081
3700 <+61390813700>
Level 20, Tower 5, Collins Square, 727 Collins Street, Docklands VIC 3008

Vibrato has merged with Servian! Check out the news article here
<https://www.arnnet.com.au/article/664971/servian-nabs-vibrato-multi-million-dollar-deal/>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201007/5c2ef255/attachment.htm>

From squid3 at treenet.co.nz  Wed Oct  7 03:39:32 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 7 Oct 2020 16:39:32 +1300
Subject: [squid-users] SSL on different ports
In-Reply-To: <CAF-5T9GVm5tJ6V9_M=wxA66AeSfutkJw5F0x+uUuUqfVxV1ryw@mail.gmail.com>
References: <CAF-5T9GVm5tJ6V9_M=wxA66AeSfutkJw5F0x+uUuUqfVxV1ryw@mail.gmail.com>
Message-ID: <c6ec9766-3309-8751-d7d4-43c7672ae9ae@treenet.co.nz>

On 7/10/20 2:16 pm, Ronan Lucio wrote:
> Hi,
> 
> By default, Squid accepts SSL connection only to port 443.

You are referring to the SSL_ports ACL ?

That does not mean accepting SSL connections. Only that the port is
known to be used primarily for SSL. So that opening opaque CONNECT
tunnels there have lower security risk.


> Are there any security concerns when need to accept HTTPS connections
> on other ports?
> 

Anything at all can go through a CONNECT tunnel and all your egress
firewall and other security will be able to tell is that the traffic
came from Squid.

If you are certain the traffic is actually HTTPS and not something else
it should be okay. But do check for that first.

Amos


From rentorbuy at yahoo.com  Wed Oct  7 08:08:24 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Wed, 7 Oct 2020 08:08:24 +0000 (UTC)
Subject: [squid-users] websockets through Squid
References: <437483657.133936.1602058104273.ref@mail.yahoo.com>
Message-ID: <437483657.133936.1602058104273@mail.yahoo.com>

Hi,

I'd like to allow websockets from specific domains through Squid in intercept sslbump mode.

One of the clients reports:

Firefox can?t establish a connection to the server at
wss://ed1lncb62202.webex.com/direct?type=websocket&dtype=binary&rand=1602057495268&uuidtag=C99EG7B6-G550-43CG-AD72-7EA5F2CA80B0&gatewayip=X.X.X.X.

This is what I have in my squid configuration:

acl foreignProtocol squid_error ERR_PROTOCOL_UNKNOWN ERR_TOO_BIG
acl serverTalksFirstProtocol squid_error ERR_REQUEST_START_TIMEOUT
on_unsupported_protocol tunnel foreignProtocol
on_unsupported_protocol tunnel serverTalksFirstProtocol
on_unsupported_protocol respond all

I am obviously not using on_unsupported_protocol properly.

Any suggestions?

Regards,

Vieri



From rentorbuy at yahoo.com  Wed Oct  7 08:49:03 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Wed, 7 Oct 2020 08:49:03 +0000 (UTC)
Subject: [squid-users] websockets through Squid
References: <1175542091.139598.1602060543039.ref@mail.yahoo.com>
Message-ID: <1175542091.139598.1602060543039@mail.yahoo.com>

I also tried:

on_unsupported_protocol tunnel all

on Squid v. 4.13.

I don't see any denials in the access log.
The only thing I see regarding the URL I mentioned earlier is:

TCP_MISS/200 673 GET https://ed1lncb62202.webex.com/direct? - ORIGINAL_DST/62.109.225.31 text/html

It is easy to reproduce by going to the webex test site:

https://www.webex.com/test-meeting.html


From rentorbuy at yahoo.com  Wed Oct  7 09:17:13 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Wed, 7 Oct 2020 09:17:13 +0000 (UTC)
Subject: [squid-users] websockets through Squid
References: <916920543.132419.1602062233555.ref@mail.yahoo.com>
Message-ID: <916920543.132419.1602062233555@mail.yahoo.com>

Hi,

Using Google Chrome instead of Firefox gives me the same result:

Error during WebSocket handshake: Unexpected response code: 200

I'm not sure what to look for in cache.log.


From rousskov at measurement-factory.com  Wed Oct  7 13:02:09 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 7 Oct 2020 09:02:09 -0400
Subject: [squid-users] websockets through Squid
In-Reply-To: <437483657.133936.1602058104273@mail.yahoo.com>
References: <437483657.133936.1602058104273.ref@mail.yahoo.com>
 <437483657.133936.1602058104273@mail.yahoo.com>
Message-ID: <b64b91cf-81ae-be52-544d-aa1593ac4dd4@measurement-factory.com>

On 10/7/20 4:08 AM, Vieri wrote:

> I'd like to allow websockets from specific domains through Squid in
> intercept sslbump mode.

> I am obviously not using on_unsupported_protocol properly.

WebSocket handshake looks like HTTP so on_unsupported_protocol is not
applicable to the WebSocket protocol -- Squid obviously supports HTTP.

To allow WebSocket tunnels, you need http_upgrade_request_protocols
available since v5.0.4. IIRC, the feature is compatible with bumped
connections, but I did not check closely.


HTH,

Alex.


From rentorbuy at yahoo.com  Wed Oct  7 13:29:51 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Wed, 7 Oct 2020 13:29:51 +0000 (UTC)
Subject: [squid-users] websockets through Squid
References: <1348526407.207449.1602077391513.ref@mail.yahoo.com>
Message-ID: <1348526407.207449.1602077391513@mail.yahoo.com>

> To allow WebSocket tunnels, you need http_upgrade_request_protocols available since v5.0.4

Thanks for the info.
My distro does not include v. 5 yet as it's still beta, although I could try compiling it.

Just a thought though. What would the easiest way be to allow websockets through in v. 4? That is, for trusted domains, allow a direct connection maybe?

eg. 
acl direct_dst_domains dstdomain "/opt/custom/proxy-settings/allowed.direct"
# or:
# acl direct_dst_domains ssl::server_name_regex "/opt/custom/proxy-settings/allowed.direct"
always_direct allow direct_dst_domains

Thanks

Vieri


From squid3 at treenet.co.nz  Wed Oct  7 13:57:11 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 8 Oct 2020 02:57:11 +1300
Subject: [squid-users] websockets through Squid
In-Reply-To: <1348526407.207449.1602077391513@mail.yahoo.com>
References: <1348526407.207449.1602077391513.ref@mail.yahoo.com>
 <1348526407.207449.1602077391513@mail.yahoo.com>
Message-ID: <ceaf56e9-15d7-7595-1f56-0060dc92c168@treenet.co.nz>

On 8/10/20 2:29 am, Vieri wrote:
>> To allow WebSocket tunnels, you need http_upgrade_request_protocols available since v5.0.4
> 
> Thanks for the info.
> My distro does not include v. 5 yet as it's still beta, although I could try compiling it.
> 
> Just a thought though. What would the easiest way be to allow websockets through in v. 4? That is, for trusted domains, allow a direct connection maybe?
> 

No. If the WS client properly supports the HTTP fallback mode of
WebSockets then it should "just work", nothing special needed from
Squid. Otherwise it is requiring Upgrade behaviour and the "error" you
got is not an error at all, just a statement about the WS client (lack
of) feature support.

Amos


From rousskov at measurement-factory.com  Wed Oct  7 14:09:48 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 7 Oct 2020 10:09:48 -0400
Subject: [squid-users] websockets through Squid
In-Reply-To: <1348526407.207449.1602077391513@mail.yahoo.com>
References: <1348526407.207449.1602077391513.ref@mail.yahoo.com>
 <1348526407.207449.1602077391513@mail.yahoo.com>
Message-ID: <21954715-cd13-76d0-4e96-330f34c8d790@measurement-factory.com>

On 10/7/20 9:29 AM, Vieri wrote:
>> To allow WebSocket tunnels, you need http_upgrade_request_protocols available since v5.0.4

> What would the easiest way be to allow websockets through in v. 4?

Backport (the essential parts of) v5 changes to v4.


> That is, for trusted domains, allow a direct connection maybe?

Direct connections are allowed by default. That is not the issue here.

To proxy a WebSocket handshake, Squid has to, at a minimum, send an
Upgrade header to the origin server, forward the HTTP 101 response from
the origin server to the client, and then become a TCP tunnel. The last
part is impossible to accomplish in v4 with configuration options alone:
There is simply no "become a tunnel" directive that is checked after
forwarding a 1xx control message.

Alex.


From ronanlucio at gmail.com  Thu Oct  8 01:18:03 2020
From: ronanlucio at gmail.com (Ronan Lucio)
Date: Thu, 8 Oct 2020 14:18:03 +1300
Subject: [squid-users] SSL on different ports
In-Reply-To: <c6ec9766-3309-8751-d7d4-43c7672ae9ae@treenet.co.nz>
References: <CAF-5T9GVm5tJ6V9_M=wxA66AeSfutkJw5F0x+uUuUqfVxV1ryw@mail.gmail.com>
 <c6ec9766-3309-8751-d7d4-43c7672ae9ae@treenet.co.nz>
Message-ID: <CAF-5T9Ht--hNCBpo0-20KfAmcTMQUmVH2gMWaxMzc4f+SJ9dMg@mail.gmail.com>

Hi Amos,

> You are referring to the SSL_ports ACL ?

Yes.
Got your point.

Thanks for the clarification
Ronan


On Wed, Oct 7, 2020 at 4:55 PM Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
> On 7/10/20 2:16 pm, Ronan Lucio wrote:
> > Hi,
> >
> > By default, Squid accepts SSL connection only to port 443.
>
> You are referring to the SSL_ports ACL ?
>
> That does not mean accepting SSL connections. Only that the port is
> known to be used primarily for SSL. So that opening opaque CONNECT
> tunnels there have lower security risk.
>
>
> > Are there any security concerns when need to accept HTTPS connections
> > on other ports?
> >
>
> Anything at all can go through a CONNECT tunnel and all your egress
> firewall and other security will be able to tell is that the traffic
> came from Squid.
>
> If you are certain the traffic is actually HTTPS and not something else
> it should be okay. But do check for that first.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From rentorbuy at yahoo.com  Thu Oct  8 09:11:02 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Thu, 8 Oct 2020 09:11:02 +0000 (UTC)
Subject: [squid-users] websockets through Squid
References: <879190082.573962.1602148262795.ref@mail.yahoo.com>
Message-ID: <879190082.573962.1602148262795@mail.yahoo.com>

OK, so I'm now trying to compile Squid 5 instead of backporting to V 4, but I'm getting this silly error:

cp ../../src/tests/stub_fd.cc tests/stub_fd.cc
cp: cannot create regular file 'tests/stub_fd.cc': No such file or directory
make[3]: *** [Makefile:1452: tests/stub_fd.cc] Error 1

I guess it may be because the script is not in the right subdir.

Is this? a known issue?
Can I simply disable building the tests?


From rousskov at measurement-factory.com  Thu Oct  8 15:00:36 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 8 Oct 2020 11:00:36 -0400
Subject: [squid-users] websockets through Squid
In-Reply-To: <879190082.573962.1602148262795@mail.yahoo.com>
References: <879190082.573962.1602148262795.ref@mail.yahoo.com>
 <879190082.573962.1602148262795@mail.yahoo.com>
Message-ID: <84450a62-2928-0d05-756b-1d72b1caf9d6@measurement-factory.com>

On 10/8/20 5:11 AM, Vieri wrote:
> OK, so I'm now trying to compile Squid 5 instead of backporting to V 4, but I'm getting this silly error:

> cp ../../src/tests/stub_fd.cc tests/stub_fd.cc
> cp: cannot create regular file 'tests/stub_fd.cc': No such file or directory
> make[3]: *** [Makefile:1452: tests/stub_fd.cc] Error 1

> Is this? a known issue?

Probably bug #5060: https://bugs.squid-cache.org/show_bug.cgi?id=5060

As a workaround, try sequential build ("make" instead of "make -j...").
To speed things up, you can build in parallel as much as possible and
then finish with a sequential make ("make -k -j... || make").


> Can I simply disable building the tests?

Tests are not built by default -- you have to run "make check" or
equivalent to build them. However, I am not sure your build fails when
you are building the tests; stubs may be used for non-test tools as
well. The bug report linked above has more information about this mess.


HTH,

Alex.


From rentorbuy at yahoo.com  Thu Oct  8 22:56:37 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Thu, 8 Oct 2020 22:56:37 +0000 (UTC)
Subject: [squid-users] websockets through Squid
References: <1774725936.884207.1602197797908.ref@mail.yahoo.com>
Message-ID: <1774725936.884207.1602197797908@mail.yahoo.com>

> As a workaround, try sequential build ("make" instead of "make -j...")

I removed -j, but I'm still getting a similar error:

cp ../../src/tests/stub_fd.cc tests/stub_fd.cc
cp: cannot create regular file 'tests/stub_fd.cc': No such file or directory
make[3]: *** [Makefile:1402: tests/stub_fd.cc] Error 1
make[3]: Leaving directory '/var/tmp/portage/net-proxy/squid-5.0.4/work/squid-5.0.4-20200825-rf4ade365f/src/icmp'
make[2]: *** [Makefile:6667: all-recursive] Error 1
make[2]: Leaving directory '/var/tmp/portage/net-proxy/squid-5.0.4/work/squid-5.0.4-20200825-rf4ade365f/src'
make[1]: *** [Makefile:5662: all] Error 2
make[1]: Leaving directory '/var/tmp/portage/net-proxy/squid-5.0.4/work/squid-5.0.4-20200825-rf4ade365f/src'
make: *** [Makefile:591: all-recursive] Error 1

Thanks for the suggestion. I'll try a few other things. Which version of automake do you use?


From squid3 at treenet.co.nz  Fri Oct  9 01:20:55 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 9 Oct 2020 14:20:55 +1300
Subject: [squid-users] websockets through Squid
In-Reply-To: <1774725936.884207.1602197797908@mail.yahoo.com>
References: <1774725936.884207.1602197797908.ref@mail.yahoo.com>
 <1774725936.884207.1602197797908@mail.yahoo.com>
Message-ID: <7f976ade-921f-02a9-e0f4-1237aad3ce66@treenet.co.nz>

On 9/10/20 11:56 am, Vieri wrote:
>> As a workaround, try sequential build ("make" instead of "make -j...")
> 
> I removed -j, but I'm still getting a similar error:
> 

Not just similar. The same one.

FYI, some make do parallel by default. I advise explicitly using -j1 for
the workaround build. That ensures single-sequence build.

Amos


From tamurin0525 at gmail.com  Fri Oct  9 12:59:32 2020
From: tamurin0525 at gmail.com (m k)
Date: Fri, 9 Oct 2020 21:59:32 +0900
Subject: [squid-users] I want to know the concerns of load testing
In-Reply-To: <d8b350cf-9f9e-992a-a08a-0c5d9fc60918@measurement-factory.com>
References: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>
 <CAL-uOnGoC96=OAnbjsUHcj_SkGs3Czw5vxZbPaYc51TwXXHNWw@mail.gmail.com>
 <d8b350cf-9f9e-992a-a08a-0c5d9fc60918@measurement-factory.com>
Message-ID: <CAL-uOnFWDVjU4UXhAtM3-XpDaCCLTqM+NiGDRJeb5eECtph++A@mail.gmail.com>

Amos san, Alex san,

Thank you for your reply.

Change squid to compile from source.
Also change the NTLM authentication to KRB.

I understand that error and response speed are more important than CPU.

The CPU is not 100%, but the number of simultaneous connections does not
exceed 450. In netstat, FIN_WAIT was over 10000. Is there a way to reduce
FiN_WAIT?

Also, can socks proxy be used with squid? If not, what are you using as an
alternative?

thank you,
kitamura

2020?10?2?(?) 23:09 Alex Rousskov <rousskov at measurement-factory.com>:

> On 10/2/20 1:26 AM, m k wrote:
>
>
>
> > Is there any case where Squid is used by a company that is used
>
> > by more than 30,000 users?
>
>
>
> Yes, some Squid (hierarchies) probably serve millions of users. I know
>
> several companies using Squids for serving large user populations, but I
>
> cannot name customer names.
>
>
>
>
>
> > What are the important point when using the
>
> > "wokers" setting for multiple processes?
>
>
>
> For a few starting points, please see
>
>
>
> *
>
>
> https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F
>
>
>
> * the recently added "worker-queues" configuration option:
>
>   https://github.com/squid-cache/squid/pull/369
>
>
>
>
>
> HTH,
>
>
>
> Alex.
>
>
>
>
>
> > 2020?10?2?(?) 11:15 m k:
>
> >
>
> >     Hello,
>
> >
>
> >     I'm planning a proxy renewal for a company with 45k clients.
>
> >     I'm looking at the performance of a single Squid to determine the
>
> >     number of Squids.
>
> >
>
> >     Environment: Virtual (OpenStack)
>
> >     OS: CentOS8.1
>
> >     CPU: 4 cores
>
> >     MEM: 8GB
>
> >     DISK: SATA30GB / 100GB
>
> >     Squid 4.4
>
> >      SSL Bump
>
> >      Blacklist: 1,700k
>
> >      auth: NTLM
>
> >      cache: 4GB
>
> >
>
> >     In an environment with authentication disabled and SSL decoding
> enabled
>
> >     A load test was performed with Jmeter.
>
> >
>
> >     Result: CPU high load (100rps-1000rps: CPU Usage 80-90%)
>
> >     (Confirm with top command)
>
> >
>
> >     Added multi-core support settings to squid.conf
>
> >     "workers 4"
>
> >
>
> >     A load test with Jmeter was performed again.
>
> >
>
> >     Result: CPU load is distributed to 4 cores (CPU Usage 20-40%)
>
> >     (Confirm with top command)
>
> >
>
> >     Question
>
> >     1. 1. How much will CPU Usage increase if NTLM authentication is
>
> >     enabled?
>
> >     2. 2. Are there any concerns other than CPU Usage in Squid?
>
> >     3. 3. When I enabled the cache in this test, the CPU Usage
>
> >     decreased, but in general, does the Squid cache increase the CPU
> Usage?
>
> >
>
> >     Thank you,
>
> >     Kitamura
>
> >
>
> >
>
> > _______________________________________________
>
> > squid-users mailing list
>
> > squid-users at lists.squid-cache.org
>
> > http://lists.squid-cache.org/listinfo/squid-users
>
> >
>
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201009/1f520361/attachment.htm>

From Ralf.Hildebrandt at charite.de  Fri Oct  9 13:16:05 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Fri, 9 Oct 2020 15:16:05 +0200
Subject: [squid-users] [ext] Re: I want to know the concerns of load
 testing
In-Reply-To: <CAL-uOnFWDVjU4UXhAtM3-XpDaCCLTqM+NiGDRJeb5eECtph++A@mail.gmail.com>
References: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>
 <CAL-uOnGoC96=OAnbjsUHcj_SkGs3Czw5vxZbPaYc51TwXXHNWw@mail.gmail.com>
 <d8b350cf-9f9e-992a-a08a-0c5d9fc60918@measurement-factory.com>
 <CAL-uOnFWDVjU4UXhAtM3-XpDaCCLTqM+NiGDRJeb5eECtph++A@mail.gmail.com>
Message-ID: <20201009131605.uhzwb5grnpuqvrch@charite.de>

* m k <tamurin0525 at gmail.com>:

> The CPU is not 100%, but the number of simultaneous connections does not
> exceed 450. In netstat, FIN_WAIT was over 10000. Is there a way to reduce
> FiN_WAIT?

We use these sysctl settings:

--- snip ---
# Tuning

net.ipv4.tcp_fin_timeout=10
# down from 60

net.ipv4.tcp_tw_reuse=1

net.ipv4.ip_local_port_range=10000 65001
# http://www.fromdual.com/huge-amount-of-time-wait-connections

net.ipv4.tcp_mtu_probing=1
net.ipv4.tcp_base_mss=1024
# https://blog.cloudflare.com/path-mtu-discovery-in-practice/
--- snip ---


> Also, can socks proxy be used with squid? 

No.

> If not, what are you using as an alternative?

I had a look at dante https://www.inet.no/dante/

FYI: for a company with about 15.000 machines we're using a cluster of
4 proxies.

Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From roberto.nunnari at edu.ti.ch  Fri Oct  9 13:54:37 2020
From: roberto.nunnari at edu.ti.ch (Roberto Nunnari)
Date: Fri, 9 Oct 2020 15:54:37 +0200
Subject: [squid-users] Trouble with an app
Message-ID: <001f01d69e43$ba1760a0$2e4621e0$@edu.ti.ch>

Hello.

 

I work in secondary school and our access to internet is protected in two
points:

1)      Squid proxy (I manage this)

2)      Internet service provider (they change *.google.com ssl certificate
with zscaler)

 

We install these zscaler certificates on all our clients, but I believe this
java app doesn't care to use it.

 

Now, can somebody explain these logs to me, please?

 

Thank you and best regards.

Roberto

 

 

Fri Oct  9 15:44:41 2020.521      1 10.20.8.212 TCP_DENIED/407 4076 CONNECT
google.ch:443 - HIER_NONE/- text/html

Fri Oct  9 15:44:41 2020.534      4 10.20.8.212 TCP_DENIED/407 4445 CONNECT
google.ch:443 - HIER_NONE/- text/html

Fri Oct  9 15:44:41 2020.660    122 10.20.8.212 TCP_TUNNEL/200 3552 CONNECT
google.ch:443 CPT\\docente.test HIER_DIRECT/216.58.215.227 -

Fri Oct  9 15:44:41 2020.756     92 10.20.8.212 TCP_TUNNEL/200 4742 CONNECT
google.com:443 - HIER_DIRECT/172.217.168.14 -

Fri Oct  9 15:44:52 2020.461      0 10.20.8.212 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- -

Fri Oct  9 15:45:02 2020.746      0 10.20.8.212 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- -

Fri Oct  9 15:45:12 2020.995      0 10.20.8.212 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- -

Fri Oct  9 15:45:22 2020.995      0 10.20.8.212 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- -

Fri Oct  9 15:45:23 2020.411      0 10.20.8.212 TCP_DENIED/407 4076 CONNECT
google.ch:443 - HIER_NONE/- text/html

Fri Oct  9 15:45:23 2020.417      3 10.20.8.212 TCP_DENIED/407 4445 CONNECT
google.ch:443 - HIER_NONE/- text/html

Fri Oct  9 15:45:24 2020.023    603 10.20.8.212 TCP_TUNNEL/200 3552 CONNECT
google.ch:443 CPT\\docente.test HIER_DIRECT/216.58.215.227 -

Fri Oct  9 15:45:24 2020.107     81 10.20.8.212 TCP_TUNNEL/200 4742 CONNECT
google.com:443 - HIER_DIRECT/172.217.168.14 -

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201009/f9e2994b/attachment.htm>

From rousskov at measurement-factory.com  Fri Oct  9 14:10:04 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 9 Oct 2020 10:10:04 -0400
Subject: [squid-users] I want to know the concerns of load testing
In-Reply-To: <CAL-uOnFWDVjU4UXhAtM3-XpDaCCLTqM+NiGDRJeb5eECtph++A@mail.gmail.com>
References: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>
 <CAL-uOnGoC96=OAnbjsUHcj_SkGs3Czw5vxZbPaYc51TwXXHNWw@mail.gmail.com>
 <d8b350cf-9f9e-992a-a08a-0c5d9fc60918@measurement-factory.com>
 <CAL-uOnFWDVjU4UXhAtM3-XpDaCCLTqM+NiGDRJeb5eECtph++A@mail.gmail.com>
Message-ID: <a05436c2-bcf4-1a9f-d47d-782fd1ecaea2@measurement-factory.com>

On 10/9/20 8:59 AM, m k wrote:

> The CPU is not 100%, but the number of simultaneous connections does not
> exceed 450. 

The average number of active concurrent connections is offered request
rate multiplied by mean response time. Thus, if you want to see more
active concurrent connections, you have to increase request rate and/or
delay packets/origin responses, but be aware that this metric is a
derivative, and playing with derivatives often leads to misleading results.

I hope others will answer your other questions about socks and FIN_WAIT.
You might also be able to find answers to those questions in the mailing
list archive.


HTH,

Alex.


> 2020?10?2?(?) 23:09 Alex Rousskov:
> 
>     On 10/2/20 1:26 AM, m k wrote:
> 
> 
> 
>     > Is there any case where Squid is used by a company that is used
> 
>     > by more than 30,000 users?
> 
> 
> 
>     Yes, some Squid (hierarchies) probably serve millions of users. I know
> 
>     several companies using Squids for serving large user populations, but I
> 
>     cannot name customer names.
> 
> 
> 
> 
> 
>     > What are the important point when using the
> 
>     > "wokers" setting for multiple processes???
> 
> 
> 
>     For a few starting points, please see
> 
> 
> 
>     *
> 
>     https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F
> 
> 
> 
>     * the recently added "worker-queues" configuration option:
> 
>     ? https://github.com/squid-cache/squid/pull/369
> 
> 
> 
> 
> 
>     HTH,
> 
> 
> 
>     Alex.
> 
> 
> 
> 
> 
>     > 2020?10?2?(?) 11:15 m k:
> 
>     >
> 
>     >? ? ?Hello,
> 
>     >
> 
>     >? ? ?I'm planning a proxy renewal for a company with 45k clients.
> 
>     >? ? ?I'm looking at the performance of a single Squid to determine the
> 
>     >? ? ?number of Squids.
> 
>     >
> 
>     >? ? ?Environment: Virtual (OpenStack)
> 
>     >? ? ?OS: CentOS8.1
> 
>     >? ? ?CPU: 4 cores
> 
>     >? ? ?MEM: 8GB
> 
>     >? ? ?DISK: SATA30GB / 100GB
> 
>     >? ? ?Squid 4.4
> 
>     >? ? ??SSL Bump
> 
>     >? ? ??Blacklist: 1,700k
> 
>     >? ? ??auth: NTLM
> 
>     >? ? ??cache: 4GB
> 
>     >
> 
>     >? ? ?In an environment with authentication disabled and SSL
>     decoding enabled
> 
>     >? ? ?A load test was performed with Jmeter.
> 
>     >
> 
>     >? ? ?Result: CPU high load (100rps-1000rps: CPU Usage 80-90%)
> 
>     >? ? ?(Confirm with top command)
> 
>     >
> 
>     >? ? ?Added multi-core support settings to squid.conf
> 
>     >? ? ?"workers 4"
> 
>     >
> 
>     >? ? ?A load test with Jmeter was performed again.
> 
>     >
> 
>     >? ? ?Result: CPU load is distributed to 4 cores (CPU Usage 20-40%)
> 
>     >? ? ?(Confirm with top command)
> 
>     >
> 
>     >? ? ?Question
> 
>     >? ? ?1. 1. How much will CPU Usage increase if NTLM authentication is
> 
>     >? ? ?enabled?
> 
>     >? ? ?2. 2. Are there any concerns other than CPU Usage in Squid?
> 
>     >? ? ?3. 3. When I enabled the cache in this test, the CPU Usage
> 
>     >? ? ?decreased, but in general, does the Squid cache increase the
>     CPU Usage?
> 
>     >
> 
>     >? ? ?Thank you,
> 
>     >? ? ?Kitamura
> 
>     >
> 
>     >
> 
>     > _______________________________________________
> 
>     > squid-users mailing list
> 
>     > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
> 
>     > http://lists.squid-cache.org/listinfo/squid-users
> 
>     >
> 
> 
> 



From rentorbuy at yahoo.com  Sat Oct 10 09:30:32 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Sat, 10 Oct 2020 09:30:32 +0000 (UTC)
Subject: [squid-users] websockets through Squid
In-Reply-To: <7f976ade-921f-02a9-e0f4-1237aad3ce66@treenet.co.nz>
References: <1774725936.884207.1602197797908.ref@mail.yahoo.com>
 <1774725936.884207.1602197797908@mail.yahoo.com>
 <7f976ade-921f-02a9-e0f4-1237aad3ce66@treenet.co.nz>
Message-ID: <1908994065.53834.1602322232762@mail.yahoo.com>

On Friday, October 9, 2020, 3:28:01 AM GMT+2, Amos Jeffries <squid3 at treenet.co.nz> wrote: 

 > I advise explicitly using -j1 for the workaround build.


Well, I'm running with -j1, but I'm still getting the same error message.

Here's a snippet of the build log:

make -j1
Making all in compat
make[1]: Entering directory '/var/tmp/portage/net-proxy/squid-5.0.4/work/squid-5.0.4-20200825-rf4ade365f/compat'
/bin/sh ../libtool? --tag=CXX?? --mode=compile x86_64-pc-linux-gnu-g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\" -DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\" -DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"?? -I.. -I../include -I../lib -I../src -I../include???? -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -pipe -D_REENTRANT -O2 -pipe -c -o assert.lo assert.cc

It finally ends with:

cp ../../src/tests/stub_fd.cc tests/stub_fd.cc
cp: cannot create regular file 'tests/stub_fd.cc': No such file or directory

Would you like to review the full build log?

Regards,

Vieri


From rentorbuy at yahoo.com  Sat Oct 10 17:13:10 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Sat, 10 Oct 2020 17:13:10 +0000 (UTC)
Subject: [squid-users] websockets through Squid
References: <1382821762.117959.1602349990455.ref@mail.yahoo.com>
Message-ID: <1382821762.117959.1602349990455@mail.yahoo.com>

I'm also getting this other file that can't be copied:

cp ../../src/tests/stub_debug.cc tests/stub_debug.cc
cp: cannot create regular file 'tests/stub_debug.cc': No such file or directory
make[3]: *** [Makefile:1490: tests/stub_debug.cc] Error 1

Tried "make" and "make -j1", but the error message is the same.

Are you using a specific version of automake?




From squid3 at treenet.co.nz  Sun Oct 11 00:40:49 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 11 Oct 2020 13:40:49 +1300
Subject: [squid-users] Trouble with an app
In-Reply-To: <001f01d69e43$ba1760a0$2e4621e0$@edu.ti.ch>
References: <001f01d69e43$ba1760a0$2e4621e0$@edu.ti.ch>
Message-ID: <b37841d6-ffb7-523a-ca06-0b8b0b2a0200@treenet.co.nz>

On 10/10/20 2:54 am, Roberto Nunnari wrote:
> Hello.
> 
> ?
> 
> I work in secondary school and our access to internet is protected in
> two points:
> 
> 1)????? Squid proxy (I manage this)
> 
> 2)????? Internet service provider (they change *.google.com ssl
> certificate with zscaler)
> 
> ?
> 
> We install these zscaler certificates on all our clients, but I believe
> this java app doesn?t care to use it.
> 
> ?
> 
> Now, can somebody explain these logs to me, please?
> 

Sure:

> 
> Fri Oct? 9 15:44:41 2020.521????? 1 10.20.8.212 TCP_DENIED/407 4076
> CONNECT google.ch:443 - HIER_NONE/- text/html
> 

Client sent a CONNECT request to the proxy. It did not have credentials,
so Squid responded with a 407 message informing it that credentials are
required.


> Fri Oct? 9 15:44:41 2020.660??? 122 10.20.8.212 TCP_TUNNEL/200 3552
> CONNECT google.ch:443 CPT\\docente.test HIER_DIRECT/216.58.215.227 -
> 

Client sent CONNECT requests with credentials.
Squid opened a tunnel to the relevant server as requested by client.
Client spent 122ms using the tunnel for something.


> Fri Oct? 9 15:44:52 2020.461????? 0 10.20.8.212 NONE/000 0 NONE
> error:transaction-end-before-headers - HIER_NONE/- -
> 

Client opened TCP connection to the proxy. Then closed it.

This is fairly common side effect of "Happy Eyeballs" behaviour where
clients open multiple connections and only use the first to succeed.

Or possibly the client had some other reason for closing. The log record
is just informative so you know it is happening and useful to explain
many sockets having TCP TIME_WAIT status if that becomes a problem.


HTH
Amos


From squid3 at treenet.co.nz  Sun Oct 11 00:49:14 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 11 Oct 2020 13:49:14 +1300
Subject: [squid-users] websockets through Squid
In-Reply-To: <1382821762.117959.1602349990455@mail.yahoo.com>
References: <1382821762.117959.1602349990455.ref@mail.yahoo.com>
 <1382821762.117959.1602349990455@mail.yahoo.com>
Message-ID: <31667cd7-24f2-1824-1ab4-d730d9e7ac2e@treenet.co.nz>

On 11/10/20 6:13 am, Vieri wrote:
> I'm also getting this other file that can't be copied:
> 
> cp ../../src/tests/stub_debug.cc tests/stub_debug.cc
> cp: cannot create regular file 'tests/stub_debug.cc': No such file or directory
> make[3]: *** [Makefile:1490: tests/stub_debug.cc] Error 1
> 
> Tried "make" and "make -j1", but the error message is the same.
> 
> Are you using a specific version of automake?
> 


I use automake 1.16 on Debian 11 and do not see this behaviour. Previous
few versions have been the same.


Amos


From rousskov at measurement-factory.com  Sun Oct 11 01:08:16 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 10 Oct 2020 21:08:16 -0400
Subject: [squid-users] websockets through Squid
In-Reply-To: <1382821762.117959.1602349990455@mail.yahoo.com>
References: <1382821762.117959.1602349990455.ref@mail.yahoo.com>
 <1382821762.117959.1602349990455@mail.yahoo.com>
Message-ID: <87f0a112-0a53-4913-b11b-e72ef6a3a857@measurement-factory.com>

On 10/10/20 1:13 PM, Vieri wrote:
> I'm also getting this other file that can't be copied:
> 
> cp ../../src/tests/stub_debug.cc tests/stub_debug.cc
> cp: cannot create regular file 'tests/stub_debug.cc': No such file or directory
> make[3]: *** [Makefile:1490: tests/stub_debug.cc] Error 1
> 
> Tried "make" and "make -j1", but the error message is the same.

Try undoing v5 commit 2c0c3d8. That commit (and master 9ba9313) changed
relevant Makefile stub targets from "foo" to "tests/foo", and I
speculate that nothing creates that "tests" directory in your environment.

FWIW, my automake (v1.16.1) does create those "tests" directories. Here
is a snippet from tools/Makefile.in after a successful master-based build:

> tests/$(am__dirstamp):
>         @$(MKDIR_P) tests
>         @: > tests/$(am__dirstamp)


Please keep us posted on your progress. It is possible we need to adjust
something in the official sources to resolve this problem.


Thank you,

Alex.


From rentorbuy at yahoo.com  Sun Oct 11 15:03:08 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Sun, 11 Oct 2020 15:03:08 +0000 (UTC)
Subject: [squid-users] websockets through Squid
In-Reply-To: <87f0a112-0a53-4913-b11b-e72ef6a3a857@measurement-factory.com>
References: <1382821762.117959.1602349990455.ref@mail.yahoo.com>
 <1382821762.117959.1602349990455@mail.yahoo.com>
 <87f0a112-0a53-4913-b11b-e72ef6a3a857@measurement-factory.com>
Message-ID: <1114748747.282768.1602428588679@mail.yahoo.com>


Just a quick test and question.

If I manually create the tests subdirs and run make then I get an error such as:

/bin/sh ../../libtool? --tag=CXX?? --mode=link x86_64-pc-linux-gnu-g++ -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -pipe -D_REENTRANT -O2 -pipe? -Wl,-O1 -Wl,--as-needed -o libdiskio.la? DiskIOModule.lo ReadRequest.lo WriteRequest.lo libtests.la AIO/libAIO.la -lrt Blocking/libBlocking.la DiskDaemon/libDiskDaemon.la DiskThreads/libDiskThreads.la -lpthread IpcIo/libIpcIo.la Mmapped/libMmapped.la
libtool:?? error: cannot find the library 'libtests.la' or unhandled argument 'libtests.la'
make[4]: *** [Makefile:868: libdiskio.la] Error 1
make[4]: Leaving directory '/var/tmp/portage/net-proxy/squid-5.0.4/work/squid-5.0.4/src/DiskIO'


This may be a dumb question, but where are the build instructions for libtests.la?


From rousskov at measurement-factory.com  Sun Oct 11 16:08:09 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 11 Oct 2020 12:08:09 -0400
Subject: [squid-users] websockets through Squid
In-Reply-To: <1114748747.282768.1602428588679@mail.yahoo.com>
References: <1382821762.117959.1602349990455.ref@mail.yahoo.com>
 <1382821762.117959.1602349990455@mail.yahoo.com>
 <87f0a112-0a53-4913-b11b-e72ef6a3a857@measurement-factory.com>
 <1114748747.282768.1602428588679@mail.yahoo.com>
Message-ID: <1b8eb38a-2206-a7d4-0d43-12a5d1664f8d@measurement-factory.com>

On 10/11/20 11:03 AM, Vieri wrote:

> If I manually create the tests subdirs and run make then I get an error such as:
> 
> /bin/sh ../../libtool? --tag=CXX?? --mode=link x86_64-pc-linux-gnu-g++ -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -pipe -D_REENTRANT -O2 -pipe? -Wl,-O1 -Wl,--as-needed -o libdiskio.la? DiskIOModule.lo ReadRequest.lo WriteRequest.lo libtests.la AIO/libAIO.la -lrt Blocking/libBlocking.la DiskDaemon/libDiskDaemon.la DiskThreads/libDiskThreads.la -lpthread IpcIo/libIpcIo.la Mmapped/libMmapped.la
> libtool:?? error: cannot find the library 'libtests.la' or unhandled argument 'libtests.la'
> make[4]: *** [Makefile:868: libdiskio.la] Error 1
> make[4]: Leaving directory '/var/tmp/portage/net-proxy/squid-5.0.4/work/squid-5.0.4/src/DiskIO'

Your build environment or procedure is broken or unusual. Unfortunately,
I cannot say more based on the tiny error snippets you have shared so
far. Do you use git sources or bootstrapped tarballs? If you use git, I
would start from scratch and share the complete output of the following
commands:

    git checkout f4ade36
    make -k distclean > /dev/null
    ./bootstrap.sh && ./configure && make -j1


> This may be a dumb question, but where are the build instructions for libtests.la?

AFAICT, that library does not exist in my v5- and master-based builds.
However, you may be able to answer questions like that by searching
bootstrapped sources. For example:

    fgrep -RI libtests /var/tmp/portage/net-proxy/squid-5.0.4


Cheers,

Alex.


From ngtech1ltd at gmail.com  Mon Oct 12 06:45:06 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Mon, 12 Oct 2020 09:45:06 +0300
Subject: [squid-users] I want to know the concerns of load testing
In-Reply-To: <2e0b245d-8e3e-b9a9-c440-e6c820a22339@treenet.co.nz>
References: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>
 <2e0b245d-8e3e-b9a9-c440-e6c820a22339@treenet.co.nz>
Message-ID: <000b01d6a063$39505220$abf0f660$@gmail.com>

Hey Amos,

Just wondering if someone is willing to host RPM's?
These can be built using:
https://github.com/elico/squid-docker-build-nodes

I can build the RPMs however I cannot host them.

Eliezer

* In any case 4 GB of RAM for 45k Clients on a single proxy would probably result high SWAPPING at peek hours..

----
Eliezer Croitoru
Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Friday, October 2, 2020 9:08 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] I want to know the concerns of load testing

On 2/10/20 3:15 pm, m k wrote:
> Hello,
> 
> I'm planning a proxy renewal for a company with 45k clients.
> I'm looking at the performance of a single Squid to determine the number
> of Squids.
> 
> Environment: Virtual (OpenStack)
> OS: CentOS8.1
> CPU: 4 cores
> MEM: 8GB
> DISK: SATA30GB / 100GB

See our notes on relative disk JBOD / RAID performances.
<https://wiki.squid-cache.org/SquidFaq/RAID>


> Squid 4.4

I know it can be hard to get hold of newer packages on CentOS. Please do
try hard to upgrade to the 4.13 release for production. There have been
more than a few critical security issues fixed this past year.


>  SSL Bump
>  Blacklist: 1,700k
>  auth: NTLM

NTLM is a major performance issue. With every request needing to be sent
twice it will essentially halve the traffic your proxy can serve to clients.

I do know that Squid used to be able to handle way more RPS than Windows
DC would like to handle. So the DC may be a bottleneck there.

Negotiate/Kerberos auth is the solution to all those problems. If you
are really interested in good performance avoid NTLM.


>  cache: 4GB
> 
> In an environment with authentication disabled and SSL decoding enabled
> A load test was performed with Jmeter.
> 
> Result: CPU high load (100rps-1000rps: CPU Usage 80-90%)
> (Confirm with top command)
> 

If the proxy is not using 100% of the core(s) it is supposed to be
using. Then you have not reached the capacity limits of the proxy.

What you do about that depends on whether you are trying to find
theoretical limits, or performance for a specific traffic profile.


For a specific traffic profile the measurement is likely hitting disk
I/O or network I/O limits. Double-check which it was - that is what to
change to improve performance.


For theoretical limits the same detail about I/O applies. But also to
max the proxy out fully you may need to tune the test traffic load for
either higher TCP connection concurrency, or to utilize less resource
consuming features. eg requests that will HIT on memory cached (small)
objects and only need simple fast-type ACL checks. Memory-only traffic
is approximately 100x faster than any involving disk I/O.

 To be clear this is to find the theoretical maximum performance. You
cannot tune clients real traffic like this.



> Added multi-core support settings to squid.conf
> "workers 4"
> 
> A load test with Jmeter was performed again.
> 
> Result: CPU load is distributed to 4 cores (CPU Usage 20-40%)
> (Confirm with top command)

See above. That 20% implies the same 80% is spread over 4 cores.


> 
> Question
> 1. 1. How much will CPU Usage increase if NTLM authentication is enabled?

NTLM requires 2 HTTP messages to authenticate every new TCP connection.
So there will be one extra HTTP message on every set of pipelined requests.

It depends on how many requests are pipelined on each TCP connection as
to how much impact that auth overhead is.


After disk I/O capacity the CPU cycles are what limit Squid most. The
RPS achievable is capped out when all CPU cores assigned for Squid reach
100%.


> 2. 2. Are there any concerns other than CPU Usage in Squid?

The usual bottlenecks:

 * disk I/O limits
 * Network latency (DNS in particular. In general, TCP to _everywhere_)
 * features used (CPU drains)
 * memory

The order is my own experience of service impact, YMMV


> 3. 3. When I enabled the cache in this test, the CPU Usage decreased,
> but in general, does the Squid cache increase the CPU Usage?


In general cache should have little effect on CPU. Processing HTTP
headers is by far the major use of CPU cycles in Squid. SSL-Bump is
expected to be a close second, especially if decrypting.

In some cases it can. A large number of small cache objects can consume
many cycles CPU searching for an object. Or Range requests on very large
objects can spend a lot of cycles to generate the Range response HIT
payload.



HTH
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From tamurin0525 at gmail.com  Mon Oct 12 11:31:11 2020
From: tamurin0525 at gmail.com (m k)
Date: Mon, 12 Oct 2020 20:31:11 +0900
Subject: [squid-users] I want to know the concerns of load testing
In-Reply-To: <000b01d6a063$39505220$abf0f660$@gmail.com>
References: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>
 <2e0b245d-8e3e-b9a9-c440-e6c820a22339@treenet.co.nz>
 <000b01d6a063$39505220$abf0f660$@gmail.com>
Message-ID: <CAL-uOnHCEnfhCRUcgPFnn6nsAJnO7b9Ahq0hzqbvcCot4=XR4g@mail.gmail.com>

>
> hello,
>
> Switching from NTLM certification to Kerberos certification.
> Sure enough, I'm in trouble.
>
> Kerberos authentication doesn't work.
> Please let me know if there is a mistake in the settings.
>
>
> SPN creation
> WINTEST(Active Directory)
> ktpass.exe /princ HTTP/
> c0528004l.wintest.example.co.jp at WINTEST.EXAMPLE.CO.JP /mapuser
> S139821admin at WINTEST.EXAMPLE.CO.JP /crypto AES256-SHA1 /ptype
> KRB5_NT_PRINCIPAL /pass 20201002 /out C:\squid.keytab
>
>
> PTR record setting
> # nslookup 10.217.192.22
> 22.192.217.10.in-addr.arpa      name = c0528004l.wintest.example.co.jp.
>
>
> # klist
> Ticket cache: KCM:1001
> Default principal: lx17070028admin at WIN.EXAMPLE.CO.JP
>
> Valid starting       Expires              Service principal
> 10/12/2020 16:05:10  10/13/2020 02:04:04  ldap/
> a9413001l.win.example.co.jp at WIN.EXAMPLE.CO.JP
>         renew until 10/13/2020 02:04:04
> 10/12/2020 16:04:04  10/13/2020 02:04:04  krbtgt/
> WIN.EXAMPLE.CO.JP at WIN.EXAMPLE.CO.JP
>         renew until 10/13/2020 02:04:04
> 10/12/2020 16:07:21  10/13/2020 02:04:04  ldap/
> a9401002l.win.example.co.jp at WIN.EXAMPLE.CO.JP
>         renew until 10/13/2020 02:04:04
>
>
> config setting
> /etc/squid/squid.conf
> # Kerberos Auth
> auth_param negotiate program /usr/lib64/squid/negotiate_kerberos_auth -k
> /etc/squid/squid.keytab -s HTTP/
> c0528004l.wintest.example.co.jp at WINTEST.EXAMPLE.CO.JP
> auth_param negotiate children 20
> auth_param negotiate keep_alive on
> acl kerb-auth proxy_auth REQUIRED
> http_access allow kerb-auth
>
> --->I get a windows security pop-up in IE.
>
>
> error message
> /var/log/squid/cache.log
> 2020/10/12 20:06:31 kid1| ERROR: Negotiate Authentication validating user.
> Result: {result=BH, notes={message: gss_accept_sec_context() failed:
> Unspecified GSS failure.  Minor code may provide more information. Service
> key not available; }}
>
>
> Create SPN from server
> c0528004l(CentOS8.1)
> # net ads keytab create -U S139821admin at WINTEST.EXAMPLE.CO.JP
> Warning: "kerberos method" must be set to a keytab method to use keytab
> functions.
> Enter S139821admin at WINTEST.EXAMPLE.CO.JP's password:
> ads_keytab_open: Invalid kerberos method set (0)
>
> ---> An error occurs and keytab cannot be created.
>
>
> Please let me know if you have any other information you need.
>
> Hi Eliezer,
>
> docker is already installed.
> We are considering a configuration of at least 6 servers.
> Whether it will be 8 or 10 has not been verified.
>
>
> thank you,
> kitamura
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201012/fb4f9c6e/attachment.htm>

From ngtech1ltd at gmail.com  Mon Oct 12 11:31:19 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Mon, 12 Oct 2020 14:31:19 +0300
Subject: [squid-users] sslproxy_options on squid 3.5.20
In-Reply-To: <CAKKyJc8YKyqkzBTWJrzP+BdKVLwCCF7pNEhnqKA7dWK4bie_1A@mail.gmail.com>
References: <CAKKyJc-EspaZOtGBqPUZ7fB3djHqPZQ6Bvrm-O_B-rKA+g4o=w@mail.gmail.com>
 <2923e609-4944-ddc8-5416-c96d68816f47@treenet.co.nz>
 <CAKKyJc8YKyqkzBTWJrzP+BdKVLwCCF7pNEhnqKA7dWK4bie_1A@mail.gmail.com>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAGg7dk9mYqJGhbBt3m/ghGwBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAA/p8Xvc7o3Q4y5uDVwC3i8AQAAAAA=@gmail.com>

Hey Nisa,

 

Just wondering, if it?s only a whitelist filtering proxy for TLS/SSL/443
Wouldn?t it be better to use a basic SNI proxy with a whitelist?

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Nisa Balakrishnan
Sent: Wednesday, October 7, 2020 4:23 AM
To: Amos Jeffries <squid3 at treenet.co.nz>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] sslproxy_options on squid 3.5.20

 

Thanks Amos.

 

I have verified that squid build is done with openssl that supports 1.2 but not 1.3.

I am worried that squid does not pass the flag set via options.

I am able to lock squid to tls 1.2 only with sslproxy_version 

 

To be a bit more clear, the squid implementation is a whitelist filtering proxy. It does not bump ssl requests. It does peek and splice on intercept.

 

On Tue, 6 Oct 2020 at 20:34, Amos Jeffries <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz> > wrote:

On 6/10/20 1:35 pm, Nisa Balakrishnan wrote:
> Hi,
> 
> I am trying to allow access for only tls versions 1.2 and above on Squid
> 3.5.20
> 

Note that "above 1.2" are not supported by that ancient version of
Squid. Your test disables everything except SSLv1 code in the library.


> For testing purposes, I have set options in squid config as follows.
> 
> ```
> https_port 3130 cert=/etc/squid/ssl/squid.pem ssl-bump intercept
> options=NO_SSLv2,NO_SSLv3,NO_TLSv1,NO_TLSv1_2
> 
> sslproxy_options NO_SSLv2,NO_SSLv3,NO_TLSv1,NO_TLSv1_2
> ```
> 

Support for all those options depends on the version, build options, and
global config settings of the OpenSSL library being used. They are just
flags Squid passes to the library on connection setup.


FWIW 3.1.20 is over 4 years old and a huge amount of change has happened
to TLS since then. Please try to upgrade to current Squid-4 stable, or
for best SSL-Bump behaviour the current Squid-5 beta.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users




 

-- 

 


  <https://email-signature.servian.com/servian_email_142x23.png> 

  <https://email-signature.servian.com/vibrato.png> 

Nisa Balakrishnan      AutomationEngineer | m:  <tel:0473942819> 0473942819 | p:  <tel:+61390813700> 03 9081 3700
Level 20, Tower 5, Collins Square, 727 Collins Street, Docklands VIC 3008

Vibrato has merged with Servian! Check out the news article  <https://www.arnnet.com.au/article/664971/servian-nabs-vibrato-multi-million-dollar-deal/> here

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201012/1e0754c4/attachment.htm>

From ngtech1ltd at gmail.com  Mon Oct 12 11:37:44 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Mon, 12 Oct 2020 14:37:44 +0300
Subject: [squid-users] SSL issue on Squid version 4 after blacklisting
In-Reply-To: <DB6PR0102MB27603E5519932014BC566B2593360@DB6PR0102MB2760.eurprd01.prod.exchangelabs.com>
References: <AM5PR0102MB2756FB157CFBE6C65DB56EB693200@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
 <DB6PR0102MB27603E5519932014BC566B2593360@DB6PR0102MB2760.eurprd01.prod.exchangelabs.com>
Message-ID: <001801d6a08c$1ad683e0$50838ba0$@gmail.com>

Hey Dixit,

 

Have you seen the next bug report:

https://bugs.squid-cache.org/show_bug.cgi?id=5067#c4

 

Alex/Amos: I assume that this specific issue deserve a DEBUG which will describe and relate to this BUG:5067 report.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit <Ankit.Dixit at eurostar.com> 
Sent: Friday, September 25, 2020 4:22 PM
To: Eliezer Croitor <ngtech1ltd at gmail.com>; 'Squid Users' <squid-users at lists.squid-cache.org>
Subject: RE: SSL issue on Squid version 4 after blacklisting

 

Elizer/Team,

 

Any help would be appreciated.

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: DIXIT Ankit 
Sent: Tuesday, September 15, 2020 1:24 PM
To: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >; 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: SSL issue on Squid version 4 after blacklisting

 

Subject changed

 

Elizer/Team,

 

Connecting with you again after we upgraded to Squid version 4.

 

We have blacklisted the domain categories  on Squid Proxy, but we are getting below exception in cache.log and due to this internet is not flowing from client servers via squid. 

This blacklist category is having thousands of blacklisted domains.

 

kid1| Error negotiating SSL on FD 33: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)

kid1| Error negotiating SSL connection on FD 26: (104) Connection reset by peer

 

Is there any specific ssl certificate, we need to configure? Or any other issue, you see here?

 

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: DIXIT Ankit 
Sent: Monday, July 6, 2020 8:50 AM
To: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >; 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: RE: [squid-users] Squid memory consumption problem

 

Elizer,

 

SSL was failing for few applications but was working fine for other applications. So we reverted back to old version.

I am not sure what ssl certificate dependency was there. 

 

Would be great, if you can suggest memory leak solutions in 3.12 version.

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Sent: Sunday, July 5, 2020 5:58 PM
To: DIXIT Ankit <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com> >; 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Cc: SETHI Konica <Konica.Sethi at eurostar.com <mailto:Konica.Sethi at eurostar.com> >
Subject: RE: [squid-users] Squid memory consumption problem

 




 

Hey,

 

What happen with this issue?

I am waiting for any input about this issue to understand with what I can try to help.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit [mailto:Ankit.Dixit at eurostar.com] 
Sent: Tuesday, June 30, 2020 12:35 PM
To: Eliezer Croitoru; Squid Users
Cc: SETHI Konica
Subject: RE: [squid-users] Squid memory consumption problem

 

For your information, we have added below configurations but again same issue.

 

tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

 

tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: DIXIT Ankit 
Sent: Tuesday, June 30, 2020 10:25 AM
To: Eliezer Croitoru <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >; Squid Users <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Cc: SETHI Konica <Konica.Sethi at eurostar.com <mailto:Konica.Sethi at eurostar.com> >
Subject: RE: [squid-users] Squid memory consumption problem

 

Eliezer,

 

Clients are facing some SSL related issues after upgrade. I could see below error. Please suggest, its little urgent.

 

quid[6706]: Error negotiating SSL connection on FD 167: error:00000001:lib(0):func(0):reason(1) (1/0)
Jun 30 09:17:38 squid[6706]: Error parsing SSL Server Hello Message on FD 77
Jun 30 09:17:38 squid[6706]: Error negotiating SSL connection on FD 75: error:00000001:lib(0):func(0):reason(1) (1/0)

 

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: Eliezer Croitoru <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Sent: Tuesday, June 30, 2020 9:10 AM
To: Squid Users <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >; DIXIT Ankit <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com> >
Subject: RE: [squid-users] Squid memory consumption problem

 




 

The first thing to do is look at:

https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery

 

It should clear couple doubts for you.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit <mailto:Ankit.Dixit at eurostar.com> 
Sent: Tuesday, June 30, 2020 10:46 AM
To: Eliezer Croitoru <mailto:ngtech1ltd at gmail.com> ; Alex Rousskov <mailto:rousskov at measurement-factory.com> ; squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Subject: RE: [squid-users] Squid memory consumption problem

 

Elizer,

 

We installed Squid 4.12 on production server, amazon Linux 2, successfully but I could see below messages in the logs for SECURITY ALERT: Host header forgery detected. These are getting generated very frequently.

Can we ignore this Or is it advised to suppress these alerts?

 

kid2| SECURITY ALERT: on URL: 5-25-3-app.agent.datadoghq.com:443 <http://5-25-3-app.agent.datadoghq.com:443> 

2020/06/30 07:41:29 kid1| SECURITY ALERT: Host header forgery detected on local=IP remote=IP FD 97 flags=33 (local IP does not match any domain IP)

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

 

  _____  

This email (including any attachments) is intended only for the addressee(s), is confidential and may be legally privileged. If you are not the intended recipient, do not use, disclose, copy, or forward this email. Please notify the sender immediately and then delete it. Eurostar International Limited and its affiliates ("EIL") do not accept any liability for action taken in reliance on this email. EIL makes no representation that this email is free of viruses and addressees should check this email for viruses. The comments or statements expressed in this email are not necessarily those of EIL. 

Eurostar International Ltd 
Times House, Bravingtons Walk, London N1 9AW Registered in England and Wales No. 2462001 

  _____  

 

 

  _____  

This email (including any attachments) is intended only for the addressee(s), is confidential and may be legally privileged. If you are not the intended recipient, do not use, disclose, copy, or forward this email. Please notify the sender immediately and then delete it. Eurostar International Limited and its affiliates ("EIL") do not accept any liability for action taken in reliance on this email. EIL makes no representation that this email is free of viruses and addressees should check this email for viruses. The comments or statements expressed in this email are not necessarily those of EIL. 

Eurostar International Ltd 
Times House, Bravingtons Walk, London N1 9AW Registered in England and Wales No. 2462001 

  _____  

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201012/63b08bc8/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.jpg
Type: image/jpeg
Size: 19517 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201012/63b08bc8/attachment.jpg>

From ronanlucio at gmail.com  Mon Oct 12 19:20:42 2020
From: ronanlucio at gmail.com (Ronan Lucio)
Date: Tue, 13 Oct 2020 08:20:42 +1300
Subject: [squid-users] How to configure squid to not cache
Message-ID: <CAF-5T9HGvYUOKXmukoWMDYMHjQXtmbzJZ_8WMDvsnwCjKbtwXg@mail.gmail.com>

Hi,
I'd like to configure squid for proxy only, no caching any content.

Looking at squid docs, it instructs to use "cache deny all", but I
didn't find this option for Squid-4:
http://www.squid-cache.org/Versions/v4/cfgman/

I didn't set any cache_dir directive, but I'm still wondering about cache_mem.

Any help would be appreciated,
Ronan


From ronanlucio at gmail.com  Mon Oct 12 19:37:24 2020
From: ronanlucio at gmail.com (Ronan Lucio)
Date: Tue, 13 Oct 2020 08:37:24 +1300
Subject: [squid-users] How to configure squid to not cache
In-Reply-To: <CAF-5T9HGvYUOKXmukoWMDYMHjQXtmbzJZ_8WMDvsnwCjKbtwXg@mail.gmail.com>
References: <CAF-5T9HGvYUOKXmukoWMDYMHjQXtmbzJZ_8WMDvsnwCjKbtwXg@mail.gmail.com>
Message-ID: <CAF-5T9GB6Hd5_jeRe2_PaONokCXtg996EHsp7NYEpepnRvV=fA@mail.gmail.com>

I'm sorry. My bad.
Just found it

On Tue, Oct 13, 2020 at 8:20 AM Ronan Lucio <ronanlucio at gmail.com> wrote:
>
> Hi,
> I'd like to configure squid for proxy only, no caching any content.
>
> Looking at squid docs, it instructs to use "cache deny all", but I
> didn't find this option for Squid-4:
> http://www.squid-cache.org/Versions/v4/cfgman/
>
> I didn't set any cache_dir directive, but I'm still wondering about cache_mem.
>
> Any help would be appreciated,
> Ronan


From rentorbuy at yahoo.com  Mon Oct 12 23:35:06 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Mon, 12 Oct 2020 23:35:06 +0000 (UTC)
Subject: [squid-users] websockets through Squid
References: <1847593709.769369.1602545706734.ref@mail.yahoo.com>
Message-ID: <1847593709.769369.1602545706734@mail.yahoo.com>

I'm compiling on a Gentoo Linux system the tarball taken from http://www.squid-cache.org/Versions/v5/squid-5.0.4.tar.gz.

The build log (failed) is here (notice the call to make -j1):

https://drive.google.com/file/d/1no0uV3Ti1ILZavAaiOyFIY9W0eLRv87q/view?usp=sharing

If I build from git f4ade36 all's well:

https://drive.google.com/file/d/1y-3wlDT_OrwSp7epvDq63xpkYv8gu9Pq/view?usp=sharing

So now I'm just going to have to spot the difference.

Thanks,

Vieri


From roberto.nunnari at edu.ti.ch  Tue Oct 13 07:59:45 2020
From: roberto.nunnari at edu.ti.ch (Roberto Nunnari)
Date: Tue, 13 Oct 2020 09:59:45 +0200
Subject: [squid-users] R:  Trouble with an app
In-Reply-To: <b37841d6-ffb7-523a-ca06-0b8b0b2a0200@treenet.co.nz>
References: <001f01d69e43$ba1760a0$2e4621e0$@edu.ti.ch>
 <b37841d6-ffb7-523a-ca06-0b8b0b2a0200@treenet.co.nz>
Message-ID: <005a01d6a136$d0c7cfb0$72576f10$@edu.ti.ch>

Hi Amos.

Thank you for your help.

Could it be that the client received the zscaler certificate and because it's wrong for google it closed the connection?
Unfortunately, the logs on the client don't show no clue about it..

Thank you and best regards.
Roberto



-----Messaggio originale-----
Da: squid-users <squid-users-bounces at lists.squid-cache.org> Per conto di Amos Jeffries
Inviato: domenica, 11 ottobre 2020 02:41
A: squid-users at lists.squid-cache.org
Oggetto: Re: [squid-users] Trouble with an app

On 10/10/20 2:54 am, Roberto Nunnari wrote:
> Hello.
> 
>  
> 
> I work in secondary school and our access to internet is protected in 
> two points:
> 
> 1)      Squid proxy (I manage this)
> 
> 2)      Internet service provider (they change *.google.com ssl 
> certificate with zscaler)
> 
>  
> 
> We install these zscaler certificates on all our clients, but I 
> believe this java app doesn?t care to use it.
> 
>  
> 
> Now, can somebody explain these logs to me, please?
> 

Sure:

> 
> Fri Oct  9 15:44:41 2020.521      1 10.20.8.212 TCP_DENIED/407 4076 
> CONNECT google.ch:443 - HIER_NONE/- text/html
> 

Client sent a CONNECT request to the proxy. It did not have credentials, so Squid responded with a 407 message informing it that credentials are required.


> Fri Oct  9 15:44:41 2020.660    122 10.20.8.212 TCP_TUNNEL/200 3552 
> CONNECT google.ch:443 CPT\\docente.test HIER_DIRECT/216.58.215.227 -
> 

Client sent CONNECT requests with credentials.
Squid opened a tunnel to the relevant server as requested by client.
Client spent 122ms using the tunnel for something.


> Fri Oct  9 15:44:52 2020.461      0 10.20.8.212 NONE/000 0 NONE 
> error:transaction-end-before-headers - HIER_NONE/- -
> 

Client opened TCP connection to the proxy. Then closed it.

This is fairly common side effect of "Happy Eyeballs" behaviour where clients open multiple connections and only use the first to succeed.

Or possibly the client had some other reason for closing. The log record is just informative so you know it is happening and useful to explain many sockets having TCP TIME_WAIT status if that becomes a problem.


HTH
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From tamurin0525 at gmail.com  Tue Oct 13 10:59:52 2020
From: tamurin0525 at gmail.com (m k)
Date: Tue, 13 Oct 2020 19:59:52 +0900
Subject: [squid-users] how to use one server to simulate multi-user login?
Message-ID: <CAL-uOnFZj1vmRjSz7fc+Mdob_Z+7qsf3m1KT78qJvcwYVsTqWg@mail.gmail.com>

Hello,

I've installed Kerberos on my cluster with Single Sign On Authentication
and it works correctly.

Yet, I need to check the performance(CPU usage, response time, etc) of
Kerberos authentication while multi-user sign in.
Could you give me pieces of advice about how to use one server to simulate
multi-user login?

I'll be grateful if you help me to understand this issue.

Thank you,
kitamura
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201013/47b66f20/attachment.htm>

From squid3 at treenet.co.nz  Tue Oct 13 11:41:22 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 14 Oct 2020 00:41:22 +1300
Subject: [squid-users] How to configure squid to not cache
In-Reply-To: <CAF-5T9GB6Hd5_jeRe2_PaONokCXtg996EHsp7NYEpepnRvV=fA@mail.gmail.com>
References: <CAF-5T9HGvYUOKXmukoWMDYMHjQXtmbzJZ_8WMDvsnwCjKbtwXg@mail.gmail.com>
 <CAF-5T9GB6Hd5_jeRe2_PaONokCXtg996EHsp7NYEpepnRvV=fA@mail.gmail.com>
Message-ID: <0cff08a2-c8d4-080b-13a4-5205a889ca22@treenet.co.nz>

On 13/10/20 8:37 am, Ronan Lucio wrote:
> I'm sorry. My bad.
> Just found it
> 
> On Tue, Oct 13, 2020 at 8:20 AM Ronan Lucio <ronanlucio at gmail.com> wrote:
>>
>> Hi,
>> I'd like to configure squid for proxy only, no caching any content.
>>
>> Looking at squid docs, it instructs to use "cache deny all", but I
>> didn't find this option for Squid-4:
>> http://www.squid-cache.org/Versions/v4/cfgman/
>>
>> I didn't set any cache_dir directive, but I'm still wondering about cache_mem.
>>

You should set "cache_mem 0" to prevent Squid allocating MB of memory
for cache that is never used.

Amos


From squid3 at treenet.co.nz  Tue Oct 13 11:46:02 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 14 Oct 2020 00:46:02 +1300
Subject: [squid-users] R:  Trouble with an app
In-Reply-To: <005a01d6a136$d0c7cfb0$72576f10$@edu.ti.ch>
References: <001f01d69e43$ba1760a0$2e4621e0$@edu.ti.ch>
 <b37841d6-ffb7-523a-ca06-0b8b0b2a0200@treenet.co.nz>
 <005a01d6a136$d0c7cfb0$72576f10$@edu.ti.ch>
Message-ID: <6954a2a3-ab63-7a9d-43d6-33b434f854a8@treenet.co.nz>

On 13/10/20 8:59 pm, Roberto Nunnari wrote:
> Hi Amos.
> 
> Thank you for your help.
> 
> Could it be that the client received the zscaler certificate and because it's wrong for google it closed the connection?
> Unfortunately, the logs on the client don't show no clue about it..
> 

That is possible too. Though the logs says 0 bytes were transferred on
the connection. So I am thinking unlikely.

Amos


From uhlar at fantomas.sk  Tue Oct 13 12:02:56 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 13 Oct 2020 14:02:56 +0200
Subject: [squid-users] How to configure squid to not cache
In-Reply-To: <CAF-5T9HGvYUOKXmukoWMDYMHjQXtmbzJZ_8WMDvsnwCjKbtwXg@mail.gmail.com>
References: <CAF-5T9HGvYUOKXmukoWMDYMHjQXtmbzJZ_8WMDvsnwCjKbtwXg@mail.gmail.com>
Message-ID: <20201013120256.GA12209@fantomas.sk>

On 13.10.20 08:20, Ronan Lucio wrote:
>I'd like to configure squid for proxy only, no caching any content.
>
>Looking at squid docs, it instructs to use "cache deny all", but I
>didn't find this option for Squid-4:
>http://www.squid-cache.org/Versions/v4/cfgman/

it's in the section "OPTIONS FOR TUNING THE CACHE"

and here:

http://www.squid-cache.org/Doc/config/cache/

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
I feel like I'm diagonally parked in a parallel universe.


From rousskov at measurement-factory.com  Tue Oct 13 13:55:54 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 13 Oct 2020 09:55:54 -0400
Subject: [squid-users] websockets through Squid
In-Reply-To: <1847593709.769369.1602545706734@mail.yahoo.com>
References: <1847593709.769369.1602545706734.ref@mail.yahoo.com>
 <1847593709.769369.1602545706734@mail.yahoo.com>
Message-ID: <e729c158-2091-bfb9-9005-905bbaa4791e@measurement-factory.com>

On 10/12/20 7:35 PM, Vieri wrote:

> I'm compiling on a Gentoo Linux system the tarball taken from
> http://www.squid-cache.org/Versions/v5/squid-5.0.4.tar.gz.

> The build log (failed) is here (notice the call to make -j1):

> https://drive.google.com/file/d/1no0uV3Ti1ILZavAaiOyFIY9W0eLRv87q/view?usp=sharing

The beginning of the above log appears to show some unofficial
bootstrapping steps.

* If you do not have to bootstrap official tarballed sources, then start
with the ./configure step.

* If you have to bootstrap tarballed sources, then use ./bootstrap.sh to
do that.

In most cases, the first bullet is applicable if you have not modified
any auto-generated source files.


> If I build from git f4ade36 all's well:

> https://drive.google.com/file/d/1y-3wlDT_OrwSp7epvDq63xpkYv8gu9Pq/view?usp=sharing

FWIW, this log appears to show the official bootstrapping sequence
(bootstrap.sh).

Alex.


From rentorbuy at yahoo.com  Tue Oct 13 15:21:37 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Tue, 13 Oct 2020 15:21:37 +0000 (UTC)
Subject: [squid-users] websockets through Squid
In-Reply-To: <e729c158-2091-bfb9-9005-905bbaa4791e@measurement-factory.com>
References: <1847593709.769369.1602545706734.ref@mail.yahoo.com>
 <1847593709.769369.1602545706734@mail.yahoo.com>
 <e729c158-2091-bfb9-9005-905bbaa4791e@measurement-factory.com>
Message-ID: <106440999.150012.1602602497115@mail.yahoo.com>


On Tuesday, October 13, 2020, 3:55:56 PM GMT+2, Alex Rousskov <rousskov at measurement-factory.com> wrote: 

> The beginning of the above log appears to show some unofficial bootstrapping steps.


Yes, I was looking into this today and I saw that the actual difference between a manual build and a Gentoo Linux build is with the following:

1) the build fails as mentioned earlier in this thread when running Gentoo-specific "configure" scripts. Bootstrapping makes no real difference.

econf: updating squid-5.0.4-20200825-rf4ade365f/cfgaux/config.sub with /usr/share/gnuconfig/config.sub
econf: updating squid-5.0.4-20200825-rf4ade365f/cfgaux/config.guess with /usr/share/gnuconfig/config.guess
./configure --prefix=/usr --build=x86_64-pc-linux-gnu --host=x86_64-pc-linux-gnu --mandir=/usr/share/man --infodir=/usr/share/info --datadir=/usr/share --sysconfdir=/etc --localstatedir=/var/lib --disable-dependency-tracking --disable-silent-rules --docdir=/usr/share/doc/squid-5.0.4 --htmldir=/usr/share/doc/squid-5.0.4/html --with-sysroot=/ --libdir=/usr/lib64

Correct me if I'm wrong, but I don't see anything wrong with the third line and the parameters passed to configure (unless disable-dependency-tracking could have some side-effects).
So I guess the problem might be with the first and second lines where some config scripts seem to be replaced.
The timestamps in /usr/share/gnuconfig/config.{sub,guess} are more recent than the ones distributed in the Squid tarball.

2) the build succeeds even when using the Gentoo build environment just as long as I do not run the Gentoo-specific econf (configure) script but "./configure" instead.

I guess I will need to bring this up on the Gentoo forum to see what's going on. I am not instructing the build system to "patch" cfgaux so I guess "econf" automatically detects something in the squid tarball that makes it patch the config.* files.

Thanks for your time.

Vieri


From rousskov at measurement-factory.com  Tue Oct 13 16:14:17 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 13 Oct 2020 12:14:17 -0400
Subject: [squid-users] websockets through Squid
In-Reply-To: <106440999.150012.1602602497115@mail.yahoo.com>
References: <1847593709.769369.1602545706734.ref@mail.yahoo.com>
 <1847593709.769369.1602545706734@mail.yahoo.com>
 <e729c158-2091-bfb9-9005-905bbaa4791e@measurement-factory.com>
 <106440999.150012.1602602497115@mail.yahoo.com>
Message-ID: <2cd16d24-f37c-7c60-5474-556110bbb334@measurement-factory.com>

On 10/13/20 11:21 AM, Vieri wrote:

> I saw that the actual difference between a manual build and a Gentoo Linux build is with the following:

> 1) the build fails as mentioned earlier in this thread when running
> Gentoo-specific "configure" scripts. Bootstrapping makes no real
> difference.

> econf: updating squid-5.0.4-20200825-rf4ade365f/cfgaux/config.sub with /usr/share/gnuconfig/config.sub
> econf: updating squid-5.0.4-20200825-rf4ade365f/cfgaux/config.guess with /usr/share/gnuconfig/config.guess
> ./configure --prefix=/usr --build=x86_64-pc-linux-gnu --host=x86_64-pc-linux-gnu --mandir=/usr/share/man --infodir=/usr/share/info --datadir=/usr/share --sysconfdir=/etc --localstatedir=/var/lib --disable-dependency-tracking --disable-silent-rules --docdir=/usr/share/doc/squid-5.0.4 --htmldir=/usr/share/doc/squid-5.0.4/html --with-sysroot=/ --libdir=/usr/lib64

> I don't see anything wrong with the third line and the parameters
> passed to configure (unless disable-dependency-tracking could have
> some side-effects).

* I speculate that disabling dependency tracking results in such
dependencies as the target creating the "tests" directory being skipped
or even not-generated, but I do not know the actual details.

* Customizing various installation directories should not affect the build.

* I assume the host settings are correct.

* Disabling silent rules is a bad idea during build triage, but should
not affect the build outcome AFAICT.


> So I guess the problem might be with the first and second lines where
> some config scripts seem to be replaced.

You can easily test this theory. I cannot, but my first bet would be on
--disable-dependency-tracking.


> 2) the build succeeds even when using the Gentoo build environment just as long as I do not run the Gentoo-specific econf (configure) script but "./configure" instead.

Glad we could identify the primary suspect. You should probably follow
up with Gentoo folks responsible for this Squid customization.


Cheers,

Alex.


From tamurin0525 at gmail.com  Wed Oct 14 09:19:54 2020
From: tamurin0525 at gmail.com (m k)
Date: Wed, 14 Oct 2020 18:19:54 +0900
Subject: [squid-users] Is there a worker option in the source build?
Message-ID: <CAL-uOnGD9d3iDKia83k-7EJWf=Ux0wu9o=cixk0qh3dLP9yCbA@mail.gmail.com>

hi all,

I have installed squid 4.13.
When I set workers, squid doesn't work.
Do you need any options at compile time?

kitamura

*****
The keytab setting doesn't work because haproxy is in front of squid.
I am in trouble because there are many problems one after another....
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201014/a9038927/attachment.htm>

From Antony.Stone at squid.open.source.it  Wed Oct 14 09:24:59 2020
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 14 Oct 2020 11:24:59 +0200
Subject: [squid-users] Is there a worker option in the source build?
In-Reply-To: <CAL-uOnGD9d3iDKia83k-7EJWf=Ux0wu9o=cixk0qh3dLP9yCbA@mail.gmail.com>
References: <CAL-uOnGD9d3iDKia83k-7EJWf=Ux0wu9o=cixk0qh3dLP9yCbA@mail.gmail.com>
Message-ID: <202010141124.59272.Antony.Stone@squid.open.source.it>

On Wednesday 14 October 2020 at 11:19:54, m k wrote:

> hi all,
> 
> I have installed squid 4.13.

How?  Package?  Compiled from source?

What O/S have you installed it on?

> When I set workers,

Give us a clue how you're doing that?

> squid doesn't work.

In what way?  Doesn't start?  Gives an error in the log file?  Starts but 
doesn't process requests?  Let us know details.

> Do you need any options at compile time?

I do not believe so, but someone else may know better than I.


Antony.

-- 
I still maintain the point that designing a monolithic kernel in 1991 is a 
fundamental error.  Be thankful you are not my student.  You would not get a 
high grade for such a design :-)
 - Andrew Tanenbaum to Linus Torvalds

                                                   Please reply to the list;
                                                         please *don't* CC me.


From tamurin0525 at gmail.com  Wed Oct 14 09:29:58 2020
From: tamurin0525 at gmail.com (m k)
Date: Wed, 14 Oct 2020 18:29:58 +0900
Subject: [squid-users] Is there a worker option in the source build?
In-Reply-To: <202010141124.59272.Antony.Stone@squid.open.source.it>
References: <CAL-uOnGD9d3iDKia83k-7EJWf=Ux0wu9o=cixk0qh3dLP9yCbA@mail.gmail.com>
 <202010141124.59272.Antony.Stone@squid.open.source.it>
Message-ID: <CAL-uOnHUJF=OwH9a2EF1TibhWcLcuMuqB6zssZdpjNs5sacDig@mail.gmail.com>

hi Antony,

4.13 is a compiler from source.

workers just write in squid.conf.

If it doesn't work, it starts for a moment when you start squid and then
stops immediately.

Workers squid works fine with the 4.4 package.

thank you,
kitamura

2020?10?14?(?) 18:25 Antony Stone <Antony.Stone at squid.open.source.it>:

> On Wednesday 14 October 2020 at 11:19:54, m k wrote:
>
> > hi all,
> >
> > I have installed squid 4.13.
>
> How?  Package?  Compiled from source?
>
> What O/S have you installed it on?
>
> > When I set workers,
>
> Give us a clue how you're doing that?
>
> > squid doesn't work.
>
> In what way?  Doesn't start?  Gives an error in the log file?  Starts but
> doesn't process requests?  Let us know details.
>
> > Do you need any options at compile time?
>
> I do not believe so, but someone else may know better than I.
>
>
> Antony.
>
> --
> I still maintain the point that designing a monolithic kernel in 1991 is a
> fundamental error.  Be thankful you are not my student.  You would not get
> a
> high grade for such a design :-)
>  - Andrew Tanenbaum to Linus Torvalds
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201014/9e60bc3a/attachment.htm>

From Antony.Stone at squid.open.source.it  Wed Oct 14 09:36:25 2020
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 14 Oct 2020 11:36:25 +0200
Subject: [squid-users] Is there a worker option in the source build?
In-Reply-To: <CAL-uOnHUJF=OwH9a2EF1TibhWcLcuMuqB6zssZdpjNs5sacDig@mail.gmail.com>
References: <CAL-uOnGD9d3iDKia83k-7EJWf=Ux0wu9o=cixk0qh3dLP9yCbA@mail.gmail.com>
 <202010141124.59272.Antony.Stone@squid.open.source.it>
 <CAL-uOnHUJF=OwH9a2EF1TibhWcLcuMuqB6zssZdpjNs5sacDig@mail.gmail.com>
Message-ID: <202010141136.25892.Antony.Stone@squid.open.source.it>

On Wednesday 14 October 2020 at 11:29:58, m k wrote:

> hi Antony,
> 
> 4.13 is a compiler from source.

Show us the command you use to compile it.

> workers just write in squid.conf.

I don't think you understood what I meant by "details" - show us exactly what 
you have put into the config file so that we might be able to try the same thing 
on another machine, or perhaps spot a syntax error, or otherwise help to 
identify the problem.

As it is, you've basically said "I've done something, and the result doesn't 
work."  You haven't shown us what the "something" is, and you haven't shown us 
any output of the way in which it fails, so we have no real information to go 
on to help resolve the problem.

> If it doesn't work, it starts for a moment when you start squid and then
> stops immediately.

What is written into the log file?

> Workers squid works fine with the 4.4 package.

Good.


Antony.

-- 
The words "e pluribus unum" on the Great Seal of the United States are from a 
poem by Virgil entitled "Moretum", which is about cheese and garlic salad 
dressing.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From rousskov at measurement-factory.com  Wed Oct 14 13:23:51 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 14 Oct 2020 09:23:51 -0400
Subject: [squid-users] Is there a worker option in the source build?
In-Reply-To: <CAL-uOnGD9d3iDKia83k-7EJWf=Ux0wu9o=cixk0qh3dLP9yCbA@mail.gmail.com>
References: <CAL-uOnGD9d3iDKia83k-7EJWf=Ux0wu9o=cixk0qh3dLP9yCbA@mail.gmail.com>
Message-ID: <b3bf4fa6-9f2f-f195-0898-28d226e4f54f@measurement-factory.com>

On 10/14/20 5:19 AM, m k wrote:
> When I set workers, squid doesn't work.

As Antony has asked, please share your cache.log from those "does not
work" failures. We cannot guess what went wrong without those details.
Sharing a cache.log from a successful start (without workers in
squid.conf) may also be useful. Comparing the two logs may yield more
clues about the problem.


> Do you need any options at compile time?

No, basic SMP is supported for all supported Squid builds on all
supported platforms.


HTH,

Alex.


From service.mv at gmail.com  Wed Oct 14 18:52:35 2020
From: service.mv at gmail.com (Service MV)
Date: Wed, 14 Oct 2020 15:52:35 -0300
Subject: [squid-users] Help with with delay pools
Message-ID: <CA+d==oGpXWE+cuf=7M2QhsvVjYoMvPx_XdKf+c95QzxCVseuyQ@mail.gmail.com>

Hello everyone, I don't know if anyone can help me with this configuration.

acl Domain_Users note group AQUAAAAAAAUVAAAA7TIfbORUj8PLQv4YAQIAAA==
delay_pools 1
delay_class 1 1
delay_parameters 1 2500000/2500000
delay_access 1 allow Domain_User

What I am looking for is to limit each individual user to 20 Mbit/s. But I
don't know if I'm really limiting all users to 20 Mbit/s with this
configuration.
Please, if someone with more experience could tell me if I am doing it
right?
Thank you very much in advance.

PS.: I only have that doubt, the note acl is already matching transaction
annotation of negotiate_kerberos_auth helper

squid -v
Squid Cache: Version 5.0.3
Service Name: squid

This binary uses OpenSSL 1.1.1d  10 Sep 2019. For legal restrictions on
distribution see https://www.openssl.org/source/license.html

configure options:  '--prefix=/opt/squid-503' '--includedir=/include'
'--mandir=/share/man' '--infodir=/share/info'
'--localstatedir=/opt/squid-503/var' '--disable-maintainer-mode'
'--disable-dependency-tracking' '--disable-silent-rules' '--enable-inline'
'--enable-async-io' '--enable-storeio=ufs,aufs,diskd'
'--enable-removal-policies=lru,heap' '--enable-delay-pools'
'--enable-cache-digests' '--enable-underscores' '--enable-icap-client'
'--enable-follow-x-forwarded-for' '--enable-auth-basic=fake,LDAP'
'--enable-auth-digest=file,LDAP' '--enable-auth-negotiate=kerberos,wrapper'
'--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group'
'--enable-arp-acl' '--enable-esi--disable-translation'
'--with-logdir=/var/log/squid-503' '--with-pidfile=/var/run/squid-503.pid'
'--with-filedescriptors=65536' '--with-large-files'
'--with-default-user=proxy' '--enable-linux-netfilter'
'--enable-ltdl-convenience' '--with-openssl' '--enable-ssl'
'--enable-ssl-crtd'
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201014/18df4b7e/attachment.htm>

From squid3 at treenet.co.nz  Wed Oct 14 23:12:14 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Oct 2020 12:12:14 +1300
Subject: [squid-users] Help with with delay pools
In-Reply-To: <CA+d==oGpXWE+cuf=7M2QhsvVjYoMvPx_XdKf+c95QzxCVseuyQ@mail.gmail.com>
References: <CA+d==oGpXWE+cuf=7M2QhsvVjYoMvPx_XdKf+c95QzxCVseuyQ@mail.gmail.com>
Message-ID: <b0973adb-f1cd-04a4-b36b-a5fcae35e18e@treenet.co.nz>

On 15/10/20 7:52 am, Service MV wrote:
> Hello everyone, I don't know if anyone can help me with this configuration.
> 
> acl Domain_Users note group AQUAAAAAAAUVAAAA7TIfbORUj8PLQv4YAQIAAA==
> delay_pools 1
> delay_class 1 1
> delay_parameters 1 2500000/2500000
> delay_access 1 allow Domain_User
> 
> What I am looking for is to limit each individual user to 20 Mbit/s. But
> I don't know if I'm really limiting all users to 20 Mbit/s with this
> configuration.
> Please, if someone with more experience could tell me if I am doing it
> right?


You are not. The above limits all members of that group across the
entire network to share 19/Mbit/s.

To fix:

* for 20Mbit/s absolute speed set -1/2621440. That means maximum of
20Mbit (2621440) can be available for use, and fully refill the
available amount each second.

* for per-username limits set a class 4 pool with "none" (or older Squid
"-1/-1") for the limit parameters your policy does not care about.


So it should look like:

 delay_pools 1
 delay_class 1 4
 delay_parameters 1 none none none -1/2621440
 delay_access 1 allow Domain_User


HTH
Amos


From squid at borrill.org.uk  Thu Oct 15 08:07:54 2020
From: squid at borrill.org.uk (Stephen Borrill)
Date: Thu, 15 Oct 2020 09:07:54 +0100
Subject: [squid-users] BUG 3556
Message-ID: <074fa628-2b78-7d97-755e-6f059f534e7c@borrill.org.uk>

At a few installations of squid 4.12 (patched for GREASE) on NetBSD 9,
I'm seeing that occasionally one of the listening ports no longer
accepts connections (it doesn't reject them, but a connection does not
get established). The port appears random; it's not the same every time
and isn't related to ports with SSL interception. A restart of squid
fixes it.

Looking through the logs, this appears to coincide with lines such as:

2020/10/14 22:32:16 kid1| ERROR: getsockname() failed to locate local-IP
on local=[::] remote=10.0.106.147:61996 FD 25 flags=1: (22) Invalid argument
2020/10/14 22:32:16 kid1| BUG 3556: FD 25 is not an open socket.

This looks similar to Alex Rousskov's recent observations:
https://bugs.squid-cache.org/show_bug.cgi?id=3556#c15

However, we have also seen with at sites where there is no SSL
interception (the above lines are from such an installation).

Based on this, I have 4 questions;

1) Am I right that triggering BUG 3556 could lead to the described symptoms?

2) Is this a squid bug or triggered by a problem in the underlying OS?
If the latter, where to start looking?

3) What workarounds are there? Given that a restart fixes it, in some
respects it would be better for squid to quit so it can be restarted
rather than continue to run in a half-working state.

4) Related to 3), are there any other ways to detect the problem when it
is happening besides parsing logs or testing if all ports are accepting
connections? This could be used to trigger an automated restart as a
temporary workaround.

-- 
Stephen


From rousskov at measurement-factory.com  Thu Oct 15 13:59:03 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 15 Oct 2020 09:59:03 -0400
Subject: [squid-users] BUG 3556
In-Reply-To: <074fa628-2b78-7d97-755e-6f059f534e7c@borrill.org.uk>
References: <074fa628-2b78-7d97-755e-6f059f534e7c@borrill.org.uk>
Message-ID: <ce35e7b8-db00-aee1-6dbf-a1c5e09a9edd@measurement-factory.com>

On 10/15/20 4:07 AM, Stephen Borrill wrote:
> At a few installations of squid 4.12 (patched for GREASE) on NetBSD
> 9, I'm seeing that occasionally one of the listening ports no longer 
> accepts connections (it doesn't reject them, but a connection does
> not get established).> The port appears random; it's not the same
> every time and isn't related to ports with SSL interception. A
> restart of squid fixes it.

> Looking through the logs, this appears to coincide with lines such as:
> 
> 2020/10/14 22:32:16 kid1| ERROR: getsockname() failed to locate local-IP
> on local=[::] remote=10.0.106.147:61996 FD 25 flags=1: (22) Invalid argument
> 2020/10/14 22:32:16 kid1| BUG 3556: FD 25 is not an open socket.
> 
> This looks similar to Alex Rousskov's recent observations:
> https://bugs.squid-cache.org/show_bug.cgi?id=3556#c15

Please keep in mind that those "BUG 3556" messages warn us about Squid
bugs elsewhere/somewhere in Squid code. For each particular message
instance, the exact bug is unknown a priori, and several different bugs
have triggered these messages in the past. While the original bug 3556
report was for a specific bug, the log messages were not (and are not).


> However, we have also seen with at sites where there is no SSL
> interception (the above lines are from such an installation).

> 1) Am I right that triggering BUG 3556 could lead to the described symptoms?

I would rephrase this as "Failure to obtain the (intended) IP address of
an (intercepted) connection leads to BUG 3556 messages."


> 2) Is this a squid bug or triggered by a problem in the underlying OS?

Those "BUG 3556" messages indicate a Squid bug. There is no question
about that. However, the ERROR messages may indicate a Squid
bug/deficiency and/or an environment (OS configuration, etc.) problem.
In summary, you are dealing with multiple problems here. You should
focus on the ERROR messages, not "BUG 3556" messages.


> If the latter, where to start looking?

Check system log for errors. Perhaps you are exhausting some system
resource?

I would also try to map ERROR messages to client transactions in hope to
spot some common pattern behind those failed transactions.
Unfortunately, I do not know whether Squid (especially Squid v4) would
log these failed transactions.


> 3) What workarounds are there?

a) Monitor logs and automatically restart the Squid instance if needed.

b) Patch Squid to kill the affected process. Adding "assert(false);"
after the ERROR message is printed in Comm::TcpAcceptor::oldAccept()
will kill the process. Killing a single worker may or may not be enough
in SMP mode; it would be interesting and potentially useful to know
whether that is enough.

You may be able to easily test your workaround using the trick I
outlined in https://bugs.squid-cache.org/show_bug.cgi?id=3556#c15


> Given that a restart fixes it, in some
> respects it would be better for squid to quit so it can be restarted
> rather than continue to run in a half-working state.

Yes, earlier Squids were written using the "Do whatever you can to stay
up" or "Damn the torpedoes!" principle. FWIW, I am pushing for reversing
the relevant code logic to follow the "Squid instance that cannot
provide an essential service explicitly requested by the admin should
quit with an error" principle, but it will take time to achieve that ideal.


> 4) Related to 3), are there any other ways to detect the problem when it
> is happening besides parsing logs or testing if all ports are accepting
> connections? This could be used to trigger an automated restart as a
> temporary workaround.

Yes, see suggestion 3b above.


HTH,

Alex.


From squid at borrill.org.uk  Thu Oct 15 14:06:04 2020
From: squid at borrill.org.uk (Stephen Borrill)
Date: Thu, 15 Oct 2020 15:06:04 +0100
Subject: [squid-users] BUG 3556
In-Reply-To: <ce35e7b8-db00-aee1-6dbf-a1c5e09a9edd@measurement-factory.com>
References: <074fa628-2b78-7d97-755e-6f059f534e7c@borrill.org.uk>
 <ce35e7b8-db00-aee1-6dbf-a1c5e09a9edd@measurement-factory.com>
Message-ID: <ba47da5d-4694-a25b-e63e-b5fb0293a8b7@borrill.org.uk>

On 15/10/2020 14:59, Alex Rousskov wrote:
> On 10/15/20 4:07 AM, Stephen Borrill wrote:
>> At a few installations of squid 4.12 (patched for GREASE) on NetBSD
>> 9, I'm seeing that occasionally one of the listening ports no longer 
>> accepts connections (it doesn't reject them, but a connection does
>> not get established).> The port appears random; it's not the same
>> every time and isn't related to ports with SSL interception. A
>> restart of squid fixes it.
> 
>> Looking through the logs, this appears to coincide with lines such as:
>>
>> 2020/10/14 22:32:16 kid1| ERROR: getsockname() failed to locate local-IP
>> on local=[::] remote=10.0.106.147:61996 FD 25 flags=1: (22) Invalid argument
>> 2020/10/14 22:32:16 kid1| BUG 3556: FD 25 is not an open socket.
>>
>> This looks similar to Alex Rousskov's recent observations:
>> https://bugs.squid-cache.org/show_bug.cgi?id=3556#c15
> 
> Please keep in mind that those "BUG 3556" messages warn us about Squid
> bugs elsewhere/somewhere in Squid code. For each particular message
> instance, the exact bug is unknown a priori, and several different bugs
> have triggered these messages in the past. While the original bug 3556
> report was for a specific bug, the log messages were not (and are not).
> 
> 
>> However, we have also seen with at sites where there is no SSL
>> interception (the above lines are from such an installation).
> 
>> 1) Am I right that triggering BUG 3556 could lead to the described symptoms?
> 
> I would rephrase this as "Failure to obtain the (intended) IP address of
> an (intercepted) connection leads to BUG 3556 messages."
> 
> 
>> 2) Is this a squid bug or triggered by a problem in the underlying OS?
> 
> Those "BUG 3556" messages indicate a Squid bug. There is no question
> about that. However, the ERROR messages may indicate a Squid
> bug/deficiency and/or an environment (OS configuration, etc.) problem.
> In summary, you are dealing with multiple problems here. You should
> focus on the ERROR messages, not "BUG 3556" messages.
> 
> 
>> If the latter, where to start looking?
> 
> Check system log for errors. Perhaps you are exhausting some system
> resource?

That's always my first port of call anyway, there are no reports.

> I would also try to map ERROR messages to client transactions in hope to
> spot some common pattern behind those failed transactions.
> Unfortunately, I do not know whether Squid (especially Squid v4) would
> log these failed transactions.
> 
> 
>> 3) What workarounds are there?
> 
> a) Monitor logs and automatically restart the Squid instance if needed.
> 
> b) Patch Squid to kill the affected process. Adding "assert(false);"
> after the ERROR message is printed in Comm::TcpAcceptor::oldAccept()
> will kill the process. Killing a single worker may or may not be enough
> in SMP mode; it would be interesting and potentially useful to know
> whether that is enough.

We aren't using SMP mode.

> You may be able to easily test your workaround using the trick I
> outlined in https://bugs.squid-cache.org/show_bug.cgi?id=3556#c15

I have also been pointed to your comment here:
https://bugs.squid-cache.org/show_bug.cgi?id=5069#c1

I'm currently testing the COMM_ERROR -> NOMESSAGE patch as bug 5069
sounds identical.

>> Given that a restart fixes it, in some
>> respects it would be better for squid to quit so it can be restarted
>> rather than continue to run in a half-working state.
> 
> Yes, earlier Squids were written using the "Do whatever you can to stay
> up" or "Damn the torpedoes!" principle. FWIW, I am pushing for reversing
> the relevant code logic to follow the "Squid instance that cannot
> provide an essential service explicitly requested by the admin should
> quit with an error" principle, but it will take time to achieve that ideal.
> 
> 
>> 4) Related to 3), are there any other ways to detect the problem when it
>> is happening besides parsing logs or testing if all ports are accepting
>> connections? This could be used to trigger an automated restart as a
>> temporary workaround.
> 
> Yes, see suggestion 3b above.
> 
> 
> HTH,
> 
> Alex.
> 



From rentorbuy at yahoo.com  Thu Oct 15 14:08:09 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Thu, 15 Oct 2020 14:08:09 +0000 (UTC)
Subject: [squid-users] websockets through Squid
In-Reply-To: <2cd16d24-f37c-7c60-5474-556110bbb334@measurement-factory.com>
References: <1847593709.769369.1602545706734.ref@mail.yahoo.com>
 <1847593709.769369.1602545706734@mail.yahoo.com>
 <e729c158-2091-bfb9-9005-905bbaa4791e@measurement-factory.com>
 <106440999.150012.1602602497115@mail.yahoo.com>
 <2cd16d24-f37c-7c60-5474-556110bbb334@measurement-factory.com>
Message-ID: <500754459.961112.1602770889399@mail.yahoo.com>

 On Tuesday, October 13, 2020, 6:14:18 PM GMT+2, Alex Rousskov <rousskov at measurement-factory.com> wrote: 

> You should probably follow up with Gentoo folks responsible for this Squid customization.

Squid 5 now builds and installs perfectly on Gentoo Linux with a few custom changes to the distro's package installation script. I hope the devs will include these changes so Squid 5 can be readily available to everyone.
BTW it "makes" in parallel fine with -jx where x > 1, so no issues there either.

So, coming back to the original post: websockets.

I added this to Squid 5:

http_upgrade_request_protocols OTHER allow all

Am I right if I state that this should allow any protocol not just WebSockets?
In other words, I do not need to be specific with 'http_upgrade_request_protocols WebSocket allow all' unless I want to, right?

Unfortunately, after reloading Squid 5 the client browser still states the same:

The connection to wss://ed1lncb65702.webex.com/direct?type=websocket&dtype=binary&rand=1602769907574&uuidtag=9E73C14G-1580-43B4-B8D4-91453FCF1939&gatewayip=MY_IP_ADDR was interrupted while the page was loading.

And in access.log I can see this:

[Thu Oct 15 15:52:27 2020].411? 29846 10.215.144.48 TCP_TUNNEL/101 0 GET https://ed1lncb65702.webex.com/direct? - ORIGINAL_DST/62.109.225.174 -
[Thu Oct 15 15:52:27 2020].831??? 125 10.215.144.48 NONE_NONE/000 0 CONNECT 62.109.225.174:443 - ORIGINAL_DST/62.109.225.174 -
[Thu Oct 15 15:52:28 2020].786???? 11 10.215.111.210 NONE_NONE_ABORTED/000 0 CONNECT 44.233.111.149:443 - HIER_NONE/- -
[Thu Oct 15 15:52:37 2020].414? 29870 10.215.144.48 TCP_TUNNEL/101 0 GET https://ed1lncb65702.webex.com/direct? - ORIGINAL_DST/62.109.225.174 -
[Thu Oct 15 15:52:37 2020].919??? 107 10.215.144.48 NONE_NONE/000 0 CONNECT 62.109.225.174:443 - ORIGINAL_DST/62.109.225.174 -

What does NONE_NONE/000 mean?

Where can I go from here?
What can I try to debug this further?

Vieri


From rousskov at measurement-factory.com  Thu Oct 15 15:02:54 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 15 Oct 2020 11:02:54 -0400
Subject: [squid-users] BUG 3556
In-Reply-To: <ba47da5d-4694-a25b-e63e-b5fb0293a8b7@borrill.org.uk>
References: <074fa628-2b78-7d97-755e-6f059f534e7c@borrill.org.uk>
 <ce35e7b8-db00-aee1-6dbf-a1c5e09a9edd@measurement-factory.com>
 <ba47da5d-4694-a25b-e63e-b5fb0293a8b7@borrill.org.uk>
Message-ID: <22b77c5c-3328-c7da-538e-57bda2fb19ba@measurement-factory.com>

On 10/15/20 10:06 AM, Stephen Borrill wrote:
> I have also been pointed to your comment here:
> https://bugs.squid-cache.org/show_bug.cgi?id=5069#c1

Aha, I thought there was another related bug but did not check. Glad you
found it!


> I'm currently testing the COMM_ERROR -> NOMESSAGE patch as bug 5069
> sounds identical.

Please update 5069 bug report if that code change works for you too. It
will give whoever volunteers the final solution more confidence that
they are on the right path. The key here is whether the error has a
transient nature and does not affect the listening socket ability to
accept other transactions.

Alex.


From squid at borrill.org.uk  Thu Oct 15 15:08:44 2020
From: squid at borrill.org.uk (Stephen Borrill)
Date: Thu, 15 Oct 2020 16:08:44 +0100
Subject: [squid-users] BUG 3556
In-Reply-To: <22b77c5c-3328-c7da-538e-57bda2fb19ba@measurement-factory.com>
References: <074fa628-2b78-7d97-755e-6f059f534e7c@borrill.org.uk>
 <ce35e7b8-db00-aee1-6dbf-a1c5e09a9edd@measurement-factory.com>
 <ba47da5d-4694-a25b-e63e-b5fb0293a8b7@borrill.org.uk>
 <22b77c5c-3328-c7da-538e-57bda2fb19ba@measurement-factory.com>
Message-ID: <a2a7e1b7-7a53-ddf9-4309-b506fb07abb1@borrill.org.uk>

On 15/10/2020 16:02, Alex Rousskov wrote:
> On 10/15/20 10:06 AM, Stephen Borrill wrote:
>> I have also been pointed to your comment here:
>> https://bugs.squid-cache.org/show_bug.cgi?id=5069#c1
> 
> Aha, I thought there was another related bug but did not check. Glad you
> found it!
> 
>> I'm currently testing the COMM_ERROR -> NOMESSAGE patch as bug 5069
>> sounds identical.
> 
> Please update 5069 bug report if that code change works for you too.

Will do.

> It
> will give whoever volunteers the final solution more confidence that
> they are on the right path. The key here is whether the error has a
> transient nature and does not affect the listening socket ability to
> accept other transactions.

Yes, that's what I'm curious to know too. The problem seems to occur
once every few days and because the error will still be logged, it
should be easy to test whether operation continues afterwards.

-- 
Stephen




From rousskov at measurement-factory.com  Thu Oct 15 15:28:01 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 15 Oct 2020 11:28:01 -0400
Subject: [squid-users] websockets through Squid
In-Reply-To: <500754459.961112.1602770889399@mail.yahoo.com>
References: <1847593709.769369.1602545706734.ref@mail.yahoo.com>
 <1847593709.769369.1602545706734@mail.yahoo.com>
 <e729c158-2091-bfb9-9005-905bbaa4791e@measurement-factory.com>
 <106440999.150012.1602602497115@mail.yahoo.com>
 <2cd16d24-f37c-7c60-5474-556110bbb334@measurement-factory.com>
 <500754459.961112.1602770889399@mail.yahoo.com>
Message-ID: <6d6f7953-b550-4aa5-2cee-f87501772834@measurement-factory.com>

On 10/15/20 10:08 AM, Vieri wrote:
>  On Tuesday, October 13, 2020, 6:14:18 PM GMT+2, Alex Rousskov wrote: 
>> You should probably follow up with Gentoo folks responsible for this Squid customization.

> Squid 5 now builds and installs perfectly on Gentoo Linux with a few
> custom changes to the distro's package installation script. I hope
> the devs will include these changes so Squid 5 can be readily
> available to everyone.

Thank you for reporting your fixes to Gentoo.


> I added this to Squid 5:

> http_upgrade_request_protocols OTHER allow all

> Am I right if I state that this should allow any protocol not just WebSockets?

Yes.

> In other words, I do not need to be specific with
> 'http_upgrade_request_protocols WebSocket allow all' unless I want
> to, right?

Just in case somebody else starts copy-pasting the above rule into their
configurations: The standard (RFC 6455) WebSocket protocol name in HTTP
Upgrade requests is "websocket". Squid uses case-sensitive comparison
for those names so you should use "websocket" in squid.conf.

Other than that correction, you are right -- a bare OTHER rule is more
risky in general but is sufficient for allowing WebSocket upgrades.


> Unfortunately, after reloading Squid 5 the client browser still states the same:
> 
> The connection to wss://ed1lncb65702.webex.com/direct?type=websocket&dtype=binary&rand=1602769907574&uuidtag=9E73C14G-1580-43B4-B8D4-91453FCF1939&gatewayip=MY_IP_ADDR was interrupted while the page was loading.
> 
> And in access.log I can see this:
> 
> [Thu Oct 15 15:52:27 2020].411? 29846 10.215.144.48 TCP_TUNNEL/101 0 GET https://ed1lncb65702.webex.com/direct? - ORIGINAL_DST/62.109.225.174 -
> [Thu Oct 15 15:52:27 2020].831??? 125 10.215.144.48 NONE_NONE/000 0 CONNECT 62.109.225.174:443 - ORIGINAL_DST/62.109.225.174 -
> [Thu Oct 15 15:52:28 2020].786???? 11 10.215.111.210 NONE_NONE_ABORTED/000 0 CONNECT 44.233.111.149:443 - HIER_NONE/- -
> [Thu Oct 15 15:52:37 2020].414? 29870 10.215.144.48 TCP_TUNNEL/101 0 GET https://ed1lncb65702.webex.com/direct? - ORIGINAL_DST/62.109.225.174 -
> [Thu Oct 15 15:52:37 2020].919??? 107 10.215.144.48 NONE_NONE/000 0 CONNECT 62.109.225.174:443 - ORIGINAL_DST/62.109.225.174 -

> What does NONE_NONE/000 mean?

It is a (relatively minor) bug in Squid. Squid probably forgot to set
the exact outcome of the transaction at transaction logging time and
probably logged absent status code as 000. We already have a project
that should fix the status code handling in such cases.

The important part here is the existence of those extra transactions.
They may be related to SslBump if you are bumbing this traffic, but then
I would expect a slightly different access.log composition.


> Where can I go from here?
> What can I try to debug this further?

The log shows successful tunnel negotiation (two TCP_TUNNEL/101 entries)
and potentially problematic transactions. It is not clear (to me)
whether they all correspond to the same client interaction. It is
possible that the client successfully tunneled some websocket
transactions but failed to tunnel others. It is also possible, although
less likely, that the client has detected a proxy presence and refused
to tunnel despite receiving a successful 101 response from Squid.

IMO, further triage requires analyzing debugging cache.log. In my
experience, such analysis usually requires developer expertise. You can
try posting a link to compressed cache.log containing just the
corresponding transactions/interactions with debug_options set to
"ALL,9" (this may log passwords, keys, and such so be careful). Somebody
here may volunteer to analyze your log for you.

https://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction


HTH,

Alex.


From tamurin0525 at gmail.com  Thu Oct 15 23:53:15 2020
From: tamurin0525 at gmail.com (m k)
Date: Fri, 16 Oct 2020 08:53:15 +0900
Subject: [squid-users] I want to know the concerns of load testing
In-Reply-To: <CAL-uOnHCEnfhCRUcgPFnn6nsAJnO7b9Ahq0hzqbvcCot4=XR4g@mail.gmail.com>
References: <CAL-uOnHHK-XxGJ3J-jLpOq=7bW0Up8uuDs6yYk0BN6gx3XMmHA@mail.gmail.com>
 <2e0b245d-8e3e-b9a9-c440-e6c820a22339@treenet.co.nz>
 <000b01d6a063$39505220$abf0f660$@gmail.com>
 <CAL-uOnHCEnfhCRUcgPFnn6nsAJnO7b9Ahq0hzqbvcCot4=XR4g@mail.gmail.com>
Message-ID: <CAL-uOnEV97vHrFdrZUGxG8v_BjCqpKfNsXTpt6tyMGT_CyGBpQ@mail.gmail.com>

hi all,

Good news.
I was able to solve the problem yesterday.
I created a key tab for haproxy and added the following options to
negotiate_kerberos_auth in squid.conf.

-s GSS_C_NO_NAME

(squid.conf)
auth_param negotiate program /usr/lib64/squid/negotiate_kerberos_auth -k
/etc/krb5.keytab -s HTTP/
c0528004l.wintest.example.co.jp at WINTEST.EXAMPLE.CO.JP -s GSS_C_NO_NAME

Kerberos authentication is also possible on the load balancer backend
server.

Thank you,
kitamura

2020?10?12?(?) 20:31 m k <tamurin0525 at gmail.com>:

> hello,
>>
>> Switching from NTLM certification to Kerberos certification.
>> Sure enough, I'm in trouble.
>>
>> Kerberos authentication doesn't work.
>> Please let me know if there is a mistake in the settings.
>>
>>
>> SPN creation
>> WINTEST(Active Directory)
>> ktpass.exe /princ HTTP/
>> c0528004l.wintest.example.co.jp at WINTEST.EXAMPLE.CO.JP /mapuser
>> S139821admin at WINTEST.EXAMPLE.CO.JP /crypto AES256-SHA1 /ptype
>> KRB5_NT_PRINCIPAL /pass 20201002 /out C:\squid.keytab
>>
>>
>> PTR record setting
>> # nslookup 10.217.192.22
>> 22.192.217.10.in-addr.arpa      name = c0528004l.wintest.example.co.jp.
>>
>>
>> # klist
>> Ticket cache: KCM:1001
>> Default principal: lx17070028admin at WIN.EXAMPLE.CO.JP
>>
>> Valid starting       Expires              Service principal
>> 10/12/2020 16:05:10  10/13/2020 02:04:04  ldap/
>> a9413001l.win.example.co.jp at WIN.EXAMPLE.CO.JP
>>         renew until 10/13/2020 02:04:04
>> 10/12/2020 16:04:04  10/13/2020 02:04:04  krbtgt/
>> WIN.EXAMPLE.CO.JP at WIN.EXAMPLE.CO.JP
>>         renew until 10/13/2020 02:04:04
>> 10/12/2020 16:07:21  10/13/2020 02:04:04  ldap/
>> a9401002l.win.example.co.jp at WIN.EXAMPLE.CO.JP
>>         renew until 10/13/2020 02:04:04
>>
>>
>> config setting
>> /etc/squid/squid.conf
>> # Kerberos Auth
>> auth_param negotiate program /usr/lib64/squid/negotiate_kerberos_auth -k
>> /etc/squid/squid.keytab -s HTTP/
>> c0528004l.wintest.example.co.jp at WINTEST.EXAMPLE.CO.JP
>> auth_param negotiate children 20
>> auth_param negotiate keep_alive on
>> acl kerb-auth proxy_auth REQUIRED
>> http_access allow kerb-auth
>>
>> --->I get a windows security pop-up in IE.
>>
>>
>> error message
>> /var/log/squid/cache.log
>> 2020/10/12 20:06:31 kid1| ERROR: Negotiate Authentication validating
>> user. Result: {result=BH, notes={message: gss_accept_sec_context() failed:
>> Unspecified GSS failure.  Minor code may provide more information. Service
>> key not available; }}
>>
>>
>> Create SPN from server
>> c0528004l(CentOS8.1)
>> # net ads keytab create -U S139821admin at WINTEST.EXAMPLE.CO.JP
>> Warning: "kerberos method" must be set to a keytab method to use keytab
>> functions.
>> Enter S139821admin at WINTEST.EXAMPLE.CO.JP's password:
>> ads_keytab_open: Invalid kerberos method set (0)
>>
>> ---> An error occurs and keytab cannot be created.
>>
>>
>> Please let me know if you have any other information you need.
>>
>> Hi Eliezer,
>>
>> docker is already installed.
>> We are considering a configuration of at least 6 servers.
>> Whether it will be 8 or 10 has not been verified.
>>
>>
>> thank you,
>> kitamura
>>
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201016/3299c934/attachment.htm>

From rentorbuy at yahoo.com  Fri Oct 16 07:35:24 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Fri, 16 Oct 2020 07:35:24 +0000 (UTC)
Subject: [squid-users] websockets through Squid
In-Reply-To: <6d6f7953-b550-4aa5-2cee-f87501772834@measurement-factory.com>
References: <1847593709.769369.1602545706734.ref@mail.yahoo.com>
 <1847593709.769369.1602545706734@mail.yahoo.com>
 <e729c158-2091-bfb9-9005-905bbaa4791e@measurement-factory.com>
 <106440999.150012.1602602497115@mail.yahoo.com>
 <2cd16d24-f37c-7c60-5474-556110bbb334@measurement-factory.com>
 <500754459.961112.1602770889399@mail.yahoo.com>
 <6d6f7953-b550-4aa5-2cee-f87501772834@measurement-factory.com>
Message-ID: <521057048.90055.1602833724243@mail.yahoo.com>


 On Thursday, October 15, 2020, 5:28:03 PM GMT+2, Alex Rousskov <rousskov at measurement-factory.com> wrote: 

>> In other words, I do not need to be specific with
>> 'http_upgrade_request_protocols WebSocket allow all' unless I want
>> to, right?
>
> Just in case somebody else starts copy-pasting the above rule into their
> configurations: The standard (RFC 6455) WebSocket protocol name in HTTP
> Upgrade requests is "websocket". Squid uses case-sensitive comparison
> for those names so you should use "websocket" in squid.conf.

OK, good to know because:

squid-5.0.4-20200825-rf4ade365f/src/cf.data.pre contains:
??????? Usage: http_upgrade_request_protocols <protocol> allow|deny [!]acl ...

??????? The required "protocol" parameter is either an all-caps word OTHER or an
??????? explicit protocol name (e.g. "WebSocket") optionally followed by a slash
??????? and a version token (e.g. "HTTP/3"). Explicit protocol names and
??????? versions are case sensitive.

That's why I used "WebSocket" instead of "websocket" in my example. To avoid confusion, cf.data.pre could be updated to be more clear.


> The important part here is the existence of those extra transactions.
> They may be related to SslBump if you are bumbing this traffic, but then
> I would expect a slightly different access.log composition.

Hmm, I'm supposed to be sslbumping, yes. I can share my full squid config & iptables redirection entries if you wish.

> https://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction

 I enabled debugging on a test system where I was the only client (one Firefox instance).

The access log is here:

https://drive.google.com/file/d/1jryX5BW4yxLTSBe0QDavPSiKLBpOvtnV/view?usp=sharing

The only odd thing I see is a few ABORTED but they are all WOFF fonts which should be unimportant except for https://join-test.webex.com/mw3300/mywebex/header.do which is only a TCP refresh "abort".

The overwhelming cache log is here (I've sed'ed a few strings for privacy reasons):

https://drive.google.com/file/d/1QYRr-0F-DGnCZtyuuAw8RsEgcHICN_0c/view?usp=sharing

I can see the upgrade messages are parsed:

HttpHeader.cc(1548) parse: parsed HttpHeaderEntry: 'Upgrade: WebSocket'

I suppose that adding the "Upgrade[66]" entry is as expected.

Then, I get lost. I can see that Squid is trying to open ed1lncb62801.webex.com with https, but it is unclear to me why the ciient complains that the connection to the wss:// site is being interrupted:

The connection to wss://ed1lncb62801.webex.com/direct?type=websocket&dtype=binary&rand=1602830016480&uuidtag=5659FGE6-DF29-47A7-859A-G4D5FDC937A2&gatewayip=PUB_IPv4_ADDR_2 was interrupted while the page was loading.

Thanks for all the help you can give me.

Vieri



From guy20034u at yahoo.com  Fri Oct 16 09:21:17 2020
From: guy20034u at yahoo.com (simon ben)
Date: Fri, 16 Oct 2020 09:21:17 +0000 (UTC)
Subject: [squid-users] allow certian user ips to access only 2 domains and
 disallow everything
References: <646869700.68648.1602840077695.ref@mail.yahoo.com>
Message-ID: <646869700.68648.1602840077695@mail.yahoo.com>

I have squid running perfectly fine on centos 7 64 bit with no issuesI want to allow certain user ips to access a few sites and block everything else so below is the configthe sites are?1) paloaltonetworks.com2) redcloak.secureworks.com
in squid.conf-------------------acl userlist src "/etc/squid/userlist"acl sitelist dstdomain "/etc/squid/sitelist"http_access allow userlist sitelist
-------------------
user list file has the ips-----------
192.168.62.128192.168.62.1192.168.62.129192.168.61.1192.168.62.130192.168.62.3192.168.61.128172.16.120.160------------------------------
site list file has the sites----------------------------------------.paloaltonetworks.com.secureworks.comhttps://ch-baladia.traps.paloaltonetworks.combaladia.xdr.eu.paloaltonetworks.comidentity.paloaltonetworks.comlogin.paloaltonetworks.comassets.adobedtm.comwww.paloaltonetworks.comredcloak.secureworks.com

------------------------------------------------
I see that the first page and some links are working but some do not . also there is a huge deny logs in squid access logsappreciate if you can advise me on how i can have the above access list so as to have minimum denies when being accessed from the above ips

Thanks and Regards

simon??


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201016/46fcbecf/attachment.htm>

From rentorbuy at yahoo.com  Fri Oct 16 14:07:42 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Fri, 16 Oct 2020 14:07:42 +0000 (UTC)
Subject: [squid-users] websockets through Squid
References: <2087065749.160095.1602857262544.ref@mail.yahoo.com>
Message-ID: <2087065749.160095.1602857262544@mail.yahoo.com>

Hi,

I think I found something in the cache.log I posted before.

sendRequest: HTTP Server conn* local=PUB_IPv4_ADDR_3
...
sendRequest: HTTP Server conn* local=PUB_IPv4_ADDR_2

It seems that Squid sometimes connects to the remote HTTP server with either one of the available addresses on the Squid box (eg. PUB_IPv4_ADDR_2, PUB_IPv4_ADDR_3, etc). These addresses are on ppp interfaces. In fact, I noticed that if the Firefox client shows this error message in its console as in my previous post:

The connection to wss://ed1lncb62801.webex.com/direct?type=websocket&dtype=binary&rand=1602830016480&uuidtag=5659FGE6-DF29-47A7-859A-G4D5FDC937A2&gatewayip=PUB_IPv4_ADDR_2 was interrupted while the page was loading.

then I see a corresponding 'sendRequest: HTTP Server conn* local=PUB_IPv4_ADDR_3' when trying to connect to the same origin. So I'm deducing that the remote websocket server is expecting a client connection from PUB_IPv4_ADDR_2 when in fact Squid is trying to connect from PUB_IPv4_ADDR_3 -- hence the "interruption" message.

My test Squid instance is running on a multi-ISP router, so I guess I have to figure out how to either force connections out one interface only for the Squid cache or tell Squid to only bind to one interface.

It's only a wild guess though.

Vieri



From rentorbuy at yahoo.com  Fri Oct 16 14:41:47 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Fri, 16 Oct 2020 14:41:47 +0000 (UTC)
Subject: [squid-users] websockets through Squid
References: <1626472963.180117.1602859307164.ref@mail.yahoo.com>
Message-ID: <1626472963.180117.1602859307164@mail.yahoo.com>

BTW how does Squid decide which IP address to use for "local" here below?

sendRequest: HTTP Server conn* local=<SQUID_PICKS_ONE>

I tried specifying a bind address in http_port and https_port as well as routing traffic from that address out through just one ppp interface, but that doesn't seem to change the way "local" is assigned an address.

Is there a way to keep "local" always the same?

Vieri


From rousskov at measurement-factory.com  Fri Oct 16 14:43:59 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 16 Oct 2020 10:43:59 -0400
Subject: [squid-users] websockets through Squid
In-Reply-To: <521057048.90055.1602833724243@mail.yahoo.com>
References: <1847593709.769369.1602545706734.ref@mail.yahoo.com>
 <1847593709.769369.1602545706734@mail.yahoo.com>
 <e729c158-2091-bfb9-9005-905bbaa4791e@measurement-factory.com>
 <106440999.150012.1602602497115@mail.yahoo.com>
 <2cd16d24-f37c-7c60-5474-556110bbb334@measurement-factory.com>
 <500754459.961112.1602770889399@mail.yahoo.com>
 <6d6f7953-b550-4aa5-2cee-f87501772834@measurement-factory.com>
 <521057048.90055.1602833724243@mail.yahoo.com>
Message-ID: <ad17809d-05f5-a65a-d64c-e409d26959da@measurement-factory.com>

On 10/16/20 3:35 AM, Vieri wrote:
> squid-5.0.4-20200825-rf4ade365f/src/cf.data.pre contains:
> ??????? Usage: http_upgrade_request_protocols <protocol> allow|deny [!]acl ...
> 
> ??????? The required "protocol" parameter is either an all-caps word OTHER or an
> ??????? explicit protocol name (e.g. "WebSocket") optionally followed by a slash
> ??????? and a version token (e.g. "HTTP/3"). Explicit protocol names and
> ??????? versions are case sensitive.

> That's why I used "WebSocket" instead of "websocket" in my example.
> To avoid confusion, cf.data.pre could be updated to be more clear.

My email saying "websocket" was based on an actual traffic sample that I
have seen. I agree that the text should be changed, but I would prefer
that this change is done by somebody more knowledgeable about the
prevailing WebSocket spelling(s) in Upgrade headers (than I am).


> https://drive.google.com/file/d/1jryX5BW4yxLTSBe0QDavPSiKLBpOvtnV/view?usp=sharing
> https://drive.google.com/file/d/1QYRr-0F-DGnCZtyuuAw8RsEgcHICN_0c/view?usp=sharing

> The connection to wss://ed1lncb62801.webex.com/direct?type=websocket&dtype=binary&rand=1602830016480&uuidtag=5659FGE6-DF29-47A7-859A-G4D5FDC937A2&gatewayip=PUB_IPv4_ADDR_2 was interrupted while the page was loading.

AFAICT, Squid did not see this particular HTTP Upgrade request. While
there are approximately 6 requests mentioning
5659FGE6-DF29-47A7-859A-G4D5FDC937A2, none of them have
rand=1602830016480. It is possible that the random number changes in the
middle of a connection, I guess, but that does not help with
identification of the relevant HTTP transaction.


> Thanks for all the help you can give me.

Debugging logs are meant for Squid developers so do not feel bad about
being unable to use them in this triage. Unfortunately, I cannot help
you with interpreting this particular log right now because the log
contains too many transactions -- I do not know which transaction
corresponds to the client complaint, and I do not have enough time to
look through all 50+ HTTP requests in the log.

One way you can help is to use browser (or client-side) debugging tools
to identify the client port (or at least the millisecond-precision
timestamps) of the problematic transaction. This can help narrow down
the suspects in the new set of logs.


FWIW, I see 467 TLS server handshake parsing "state < atHelloReceived"
failures in your log, but I did not investigate further. They may be
normal/expected or problematic but unrelated to the problem at hand.

Alex.


From rousskov at measurement-factory.com  Fri Oct 16 14:48:53 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 16 Oct 2020 10:48:53 -0400
Subject: [squid-users] websockets through Squid
In-Reply-To: <1626472963.180117.1602859307164@mail.yahoo.com>
References: <1626472963.180117.1602859307164.ref@mail.yahoo.com>
 <1626472963.180117.1602859307164@mail.yahoo.com>
Message-ID: <d24b2583-4959-99d2-9d22-ba3141f595cd@measurement-factory.com>

On 10/16/20 10:41 AM, Vieri wrote:
> BTW how does Squid decide which IP address to use for "local" here below?
> 
> sendRequest: HTTP Server conn* local=<SQUID_PICKS_ONE>

By default, Squid does not make that decision. The OS does it for Squid.
You can try to force Squid to bind to a specific source address for
outgoing TCP connections using tcp_outgoing_address.


> I tried specifying a bind address in http_port and https_port as well as routing traffic from that address out through just one ppp interface, but that doesn't seem to change the way "local" is assigned an address.

By default, there is no direct relationship between Squid listening port
address and the source address of outgoing TCP connections.

Alex.


From rentorbuy at yahoo.com  Fri Oct 16 15:58:50 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Fri, 16 Oct 2020 15:58:50 +0000 (UTC)
Subject: [squid-users] websockets through Squid
In-Reply-To: <d24b2583-4959-99d2-9d22-ba3141f595cd@measurement-factory.com>
References: <1626472963.180117.1602859307164.ref@mail.yahoo.com>
 <1626472963.180117.1602859307164@mail.yahoo.com>
 <d24b2583-4959-99d2-9d22-ba3141f595cd@measurement-factory.com>
Message-ID: <1798348484.217408.1602863930213@mail.yahoo.com>


On Friday, October 16, 2020, 4:48:55 PM GMT+2, Alex Rousskov <rousskov at measurement-factory.com> wrote: 

> tcp_outgoing_address.


OK, I fixed the "local" address issue, but I'm still seeing the same behavior.

I pinpointed one particular request that's failing:

2020/10/16 16:56:37.250 kid1| 85,2| client_side_request.cc(745) clientAccessCheckDone: The request GET https://ed1lncb62601.webex.com/direct?type=websocket&dtype=binary&rand=1602860196950&uuidtag=G7609603-81A2-4B8D-A1C0-C379CC9B12G9&gatewayip=PUB_IPv4_ADDR_2 is ALLOWED; last ACL checked: all

It is in this log:

https://drive.google.com/file/d/1OrB42Cvom2PNmV-dnfLVrnMY5IhJkcpS/view?usp=sharing

I see a lot of '101 Switching Protocols' and references to upgrade to websockets, but I'm not sure where it is actually failing.

I don't know how to narrow this down further, but if someone could give it another peak I'd be most grateful.

Vieri



From squid3 at treenet.co.nz  Sat Oct 17 02:58:54 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 17 Oct 2020 15:58:54 +1300
Subject: [squid-users] allow certian user ips to access only 2 domains
 and disallow everything
In-Reply-To: <646869700.68648.1602840077695@mail.yahoo.com>
References: <646869700.68648.1602840077695.ref@mail.yahoo.com>
 <646869700.68648.1602840077695@mail.yahoo.com>
Message-ID: <e64648f2-c570-35f8-e6bf-c9f4bc3eeb46@treenet.co.nz>

On 16/10/20 10:21 pm, simon ben wrote:
> I have squid running perfectly fine on centos 7 64 bit with no issues
> I want to allow certain user ips to access a few sites and block
> everything else so below is the config
> the sites are?
> 1) paloaltonetworks.com
> 2) redcloak.secureworks.com
> 

Notice the sitelist file contains the entire range of *.secureworks.com
domains and some others.


> in squid.conf
> -------------------
> acl userlist src "/etc/squid/userlist"
> acl sitelist dstdomain "/etc/squid/sitelist"


# allow certain user ips to access a few sites
> http_access allow userlist sitelist
> 

# ...  and block everything else

?? nothing specified for that part of your policy.


So, you need to followup with either:

  http_access deny all

or,

  http_access deny userips


> -------------------
> 
> user list file has the ips
> -----------
> 192.168.62.128
> 192.168.62.1
> 192.168.62.129
> 192.168.61.1
> 192.168.62.130
> 192.168.62.3
> 192.168.61.128
> 172.16.120.160
> ------------------------------
> 

Er, these are not "users" these are IP addresses. Aka clients.

The difference is important because one machine/IP can be used by
multiple users. There is no difference to the proxy whether the IP is
switched between users or shared by multiple simultaneously.

Also, sorting the file can ease management. There are some entries which
could be represented by a IP-range for more efficient matching instead
of listed individually.



> site list file has the sites
> ----------------------------------------
> .paloaltonetworks.com
> .secureworks.com
> https://ch-baladia.traps.paloaltonetworks.com
> baladia.xdr.eu.paloaltonetworks.com
> identity.paloaltonetworks.com
> login.paloaltonetworks.com
> assets.adobedtm.com
> www.paloaltonetworks.com
> redcloak.secureworks.com
> 
> ------------------------------------------------
> 
> I see that the first page and some links are working but some do not .

Only the first two lines of that file are "sites".

The third is a URL. This will never match with dstdomain.

The rest are individual domains. They will only match the one domain
within their site.

Also, most of your entries are sub-domains of the sites listed on the
first lines. The contents of this file redux to:


  .paloaltonetworks.com
  .secureworks.com
  assets.adobedtm.com


However, your stated policy says that it should only contain:

  .paloaltonetworks.com
  .redcloak.secureworks.com


Amos


From squid3 at treenet.co.nz  Sat Oct 17 03:03:00 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 17 Oct 2020 16:03:00 +1300
Subject: [squid-users] websockets through Squid
In-Reply-To: <2087065749.160095.1602857262544@mail.yahoo.com>
References: <2087065749.160095.1602857262544.ref@mail.yahoo.com>
 <2087065749.160095.1602857262544@mail.yahoo.com>
Message-ID: <b6c6058f-504f-546e-73a6-838e74044514@treenet.co.nz>

On 17/10/20 3:07 am, Vieri wrote:
> Hi,
> 
> I think I found something in the cache.log I posted before.
> 
> sendRequest: HTTP Server conn* local=PUB_IPv4_ADDR_3
> ...
> sendRequest: HTTP Server conn* local=PUB_IPv4_ADDR_2
> 
> It seems that Squid sometimes connects to the remote HTTP server with either one of the available addresses on the Squid box (eg. PUB_IPv4_ADDR_2, PUB_IPv4_ADDR_3, etc). These addresses are on ppp interfaces. In fact, I noticed that if the Firefox client shows this error message in its console as in my previous post:
> 
> The connection to wss://ed1lncb62801.webex.com/direct?type=websocket&dtype=binary&rand=1602830016480&uuidtag=5659FGE6-DF29-47A7-859A-G4D5FDC937A2&gatewayip=PUB_IPv4_ADDR_2 was interrupted while the page was loading.
> 
> then I see a corresponding 'sendRequest: HTTP Server conn* local=PUB_IPv4_ADDR_3' when trying to connect to the same origin. So I'm deducing that the remote websocket server is expecting a client connection from PUB_IPv4_ADDR_2 when in fact Squid is trying to connect from PUB_IPv4_ADDR_3 -- hence the "interruption" message.

That implies a broken server. For new connections through a proxy there
is no guarantee of any particular IP address being used. As you can see
from that behaviour the OS may select any of its available addresses if
it needs to.


> 
> My test Squid instance is running on a multi-ISP router, so I guess I have to figure out how to either force connections out one interface only for the Squid cache or tell Squid to only bind to one interface.
> 

tcp_outgoing_* directives can send details to the OS to hint at
preferred server connection details. It is up to the OS whether those
are followed or not.


Amos


From rentorbuy at yahoo.com  Sat Oct 17 15:50:58 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Sat, 17 Oct 2020 15:50:58 +0000 (UTC)
Subject: [squid-users] websockets through Squid
In-Reply-To: <b6c6058f-504f-546e-73a6-838e74044514@treenet.co.nz>
References: <2087065749.160095.1602857262544.ref@mail.yahoo.com>
 <2087065749.160095.1602857262544@mail.yahoo.com>
 <b6c6058f-504f-546e-73a6-838e74044514@treenet.co.nz>
Message-ID: <1102607393.539506.1602949858804@mail.yahoo.com>


On Saturday, October 17, 2020, 5:10:08 AM GMT+2, Amos Jeffries <squid3 at treenet.co.nz> wrote: 

> tcp_outgoing_* directives can send details to the OS to hint at preferred server connection details. It is up to the OS whether those are followed or not.


Yes, I finally solved my network issue, and now Squid is sending traffic as expected (same interface).

In fact, I know Squid 5.0.4 and websockets are "working" because I can properly test this protocol here:

https://www.websocket.org/echo.html

and elsewhere. The above site did not work with Squid 4, but it's working now with Squid 5.0.4.

However, the webex test site is still failing with the same client error message.

Maybe someone on this list can reproduce the problem or share a squid configuration that actually works with or without sslbump (for the webex test site, that is).

Here's a simple sslbump config that only requires redirecting tcp 443 traffic to the custom Squid port 3130 (tproxy can be ignored in this example):

# cat squid.conf
# optional:
# tcp_outgoing_address 1.2.3.4

http_port 3128
http_port 3129 tproxy
https_port 3130 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cert=/etc/ssl/squid/proxyserver.pem
sslcrtd_program /usr/libexec/squid/security_file_certgen -s /var/lib/squid/ssl_db -M 16MB
sslcrtd_children 40 startup=20 idle=10

acl SSL_ports port 443

acl Safe_ports port 443
acl Safe_ports port 80

acl CONNECT method CONNECT

acl localnet src your.local.net.work

http_access deny !Safe_ports

http_access deny CONNECT !SSL_ports

http_access deny all !localnet

http_access allow CONNECT localnet SSL_ports

http_upgrade_request_protocols OTHER allow all

http_access allow localnet all
http_reply_access allow localnet all

debug_options rotate=1 ALL,9

ssl_bump stare all
ssl_bump bump all

http_access allow localhost

http_access deny all

-------------------------------------

You can then go to https://www.webex.com/test-meeting.html to see if the websocket test actually works.

There has to be a glitch there or something I'm overlooking.

Thanks,

Vieri


From guy20034u at yahoo.com  Sat Oct 17 16:12:56 2020
From: guy20034u at yahoo.com (simon ben)
Date: Sat, 17 Oct 2020 16:12:56 +0000 (UTC)
Subject: [squid-users] allow certian user ips to access only 2 domains
 and disallow everything
In-Reply-To: <e64648f2-c570-35f8-e6bf-c9f4bc3eeb46@treenet.co.nz>
References: <646869700.68648.1602840077695.ref@mail.yahoo.com>
 <646869700.68648.1602840077695@mail.yahoo.com>
 <e64648f2-c570-35f8-e6bf-c9f4bc3eeb46@treenet.co.nz>
Message-ID: <2104989990.381911.1602951176379@mail.yahoo.com>

 Dear Amos,
Thanks for the quick replywill check and let you know

regards
simon
    On Saturday, October 17, 2020, 06:06:13 AM GMT+3, Amos Jeffries <squid3 at treenet.co.nz> wrote:  
 
 On 16/10/20 10:21 pm, simon ben wrote:
> I have squid running perfectly fine on centos 7 64 bit with no issues
> I want to allow certain user ips to access a few sites and block
> everything else so below is the config
> the sites are?
> 1) paloaltonetworks.com
> 2) redcloak.secureworks.com
> 

Notice the sitelist file contains the entire range of *.secureworks.com
domains and some others.


> in squid.conf
> -------------------
> acl userlist src "/etc/squid/userlist"
> acl sitelist dstdomain "/etc/squid/sitelist"


# allow certain user ips to access a few sites
> http_access allow userlist sitelist
> 

# ...? and block everything else

?? nothing specified for that part of your policy.


So, you need to followup with either:

? http_access deny all

or,

? http_access deny userips


> -------------------
> 
> user list file has the ips
> -----------
> 192.168.62.128
> 192.168.62.1
> 192.168.62.129
> 192.168.61.1
> 192.168.62.130
> 192.168.62.3
> 192.168.61.128
> 172.16.120.160
> ------------------------------
> 

Er, these are not "users" these are IP addresses. Aka clients.

The difference is important because one machine/IP can be used by
multiple users. There is no difference to the proxy whether the IP is
switched between users or shared by multiple simultaneously.

Also, sorting the file can ease management. There are some entries which
could be represented by a IP-range for more efficient matching instead
of listed individually.



> site list file has the sites
> ----------------------------------------
> .paloaltonetworks.com
> .secureworks.com
> https://ch-baladia.traps.paloaltonetworks.com
> baladia.xdr.eu.paloaltonetworks.com
> identity.paloaltonetworks.com
> login.paloaltonetworks.com
> assets.adobedtm.com
> www.paloaltonetworks.com
> redcloak.secureworks.com
> 
> ------------------------------------------------
> 
> I see that the first page and some links are working but some do not .

Only the first two lines of that file are "sites".

The third is a URL. This will never match with dstdomain.

The rest are individual domains. They will only match the one domain
within their site.

Also, most of your entries are sub-domains of the sites listed on the
first lines. The contents of this file redux to:


? .paloaltonetworks.com
? .secureworks.com
? assets.adobedtm.com


However, your stated policy says that it should only contain:

? .paloaltonetworks.com
? .redcloak.secureworks.com


Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201017/7b9da3da/attachment.htm>

From rousskov at measurement-factory.com  Sat Oct 17 20:36:45 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 17 Oct 2020 16:36:45 -0400
Subject: [squid-users] websockets through Squid
In-Reply-To: <1798348484.217408.1602863930213@mail.yahoo.com>
References: <1626472963.180117.1602859307164.ref@mail.yahoo.com>
 <1626472963.180117.1602859307164@mail.yahoo.com>
 <d24b2583-4959-99d2-9d22-ba3141f595cd@measurement-factory.com>
 <1798348484.217408.1602863930213@mail.yahoo.com>
Message-ID: <3f7b01cd-f71c-6fb0-27bf-74fbda532384@measurement-factory.com>

On 10/16/20 11:58 AM, Vieri wrote:

> I pinpointed one particular request that's failing:
> 
> 2020/10/16 16:56:37.250 kid1| 85,2| client_side_request.cc(745) clientAccessCheckDone: The request GET https://ed1lncb62601.webex.com/direct?type=websocket&dtype=binary&rand=1602860196950&uuidtag=G7609603-81A2-4B8D-A1C0-C379CC9B12G9&gatewayip=PUB_IPv4_ADDR_2 is ALLOWED; last ACL checked: all
> 
> It is in this log:
> 
> https://drive.google.com/file/d/1OrB42Cvom2PNmV-dnfLVrnMY5IhJkcpS/view?usp=sharing

Thank you, that helped a lot!

I see that Squid decides that the client has closed the connection.
Squid propagates that connection closure to the server. Due to a Squid
bug (or my misunderstanding), cache.log does not contain enough details
to tell whether the client actually closed the connection in this case
and, if it did, whether it did so nicely or due to some TLS error.

I filed bug #5084 in hope to improve handling of this case. At the very
least, the log should categorize the closure, but it is also possible
that the client did not actually close the connection, and Squid is
completely mishandling the situation (in addition to being silent about
it). See https://bugs.squid-cache.org/show_bug.cgi?id=5084 for details.

I cannot volunteer to work on this further right now, but I hope this
triage will help another volunteer (or a paid contractor) to make
further progress.

https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F

Alex.


From juraj.masar at gmail.com  Sat Oct 17 21:14:50 2020
From: juraj.masar at gmail.com (Juraj Masar)
Date: Sat, 17 Oct 2020 21:14:50 +0000
Subject: [squid-users] Request timing headers
Message-ID: <kge6dhm7.0a3266a5-001c-481a-bb4d-912f289dfac0@we.are.superhuman.com>

Hi guys,

First of all, thank you all for the wonderful work you've done on Squid!

Is it possible for Squid to return request timing information in response headers?

I'm looking for something similar to cURL: namelookup time/connect time/total time/etc.

Is there a configuration directive or a plugin I'm missing?

Thank you & have a great weekend!

Best,

Juraj
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201017/057fdec6/attachment.htm>

From rousskov at measurement-factory.com  Sat Oct 17 21:35:01 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 17 Oct 2020 17:35:01 -0400
Subject: [squid-users] Request timing headers
In-Reply-To: <kge6dhm7.0a3266a5-001c-481a-bb4d-912f289dfac0@we.are.superhuman.com>
References: <kge6dhm7.0a3266a5-001c-481a-bb4d-912f289dfac0@we.are.superhuman.com>
Message-ID: <6058301c-08fb-2f9d-1181-1a9dd7b5ea4e@measurement-factory.com>

On 10/17/20 5:14 PM, Juraj Masar wrote:

> Is it possible for Squid to return request timing information in
> response headers?

Interesting question! In theory, a custom response header can use
logformat %codes, including %codes that carry timing information, such
as %tr and %dt. You will need to quote the whole customer header value
for those %codes to be honored. See reply_header_add and logformat
directives for more info.

However, I did not test whether this actually works. Some Squid code may
(increasingly incorrectly) assume that a particular %code is only
expanded after the master transaction is done. Needless to say, the
transaction is still ongoing when the response header is being formed.
If you face such problems, you may want to just add %master_xaction to
your custom response header (and to access.log records) and then match
the response with the access log record containing all the details.
Adding %tS may also help in this case (if that %code works in the
response header context).


HTH,

Alex.

> 		tr	Response time (milliseconds)
> 		dt	Total time spent making DNS lookups (milliseconds)
> 		tS	Approximate master transaction start time in 
> 			<full seconds since epoch>.<fractional seconds> format.
> 			Currently, Squid considers the master transaction
> 			started when a complete HTTP request header initiating
> 			the transaction is received from the client. This is
> 			the same value that Squid uses to calculate transaction
> 			response time when logging %tr to access.log. Currently,
> 			Squid uses millisecond resolution for %tS values,
> 			similar to the default access.log "current time" field
> 			(%ts.%03tu).


From rentorbuy at yahoo.com  Sun Oct 18 22:07:53 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Sun, 18 Oct 2020 22:07:53 +0000 (UTC)
Subject: [squid-users] websockets through Squid
In-Reply-To: <3f7b01cd-f71c-6fb0-27bf-74fbda532384@measurement-factory.com>
References: <1626472963.180117.1602859307164.ref@mail.yahoo.com>
 <1626472963.180117.1602859307164@mail.yahoo.com>
 <d24b2583-4959-99d2-9d22-ba3141f595cd@measurement-factory.com>
 <1798348484.217408.1602863930213@mail.yahoo.com>
 <3f7b01cd-f71c-6fb0-27bf-74fbda532384@measurement-factory.com>
Message-ID: <1304872121.821246.1603058873508@mail.yahoo.com>


On Saturday, October 17, 2020, 10:36:47 PM GMT+2, Alex Rousskov <rousskov at measurement-factory.com> wrote: 

> or due to some TLS error.
> I filed bug #5084 

 Hi again,

Thanks for opening a bug report.

I don't want to add anything there myself because I wouldn't want to confuse whoever might take this issue into account, but I'd like to comment on this list that I've captured the traffic between Squid and the destination server.
It's here:

https://drive.google.com/file/d/1WS7Y62Fng5ggXryzKGW1JOsJ16cyR0mg/view?usp=sharing

I can see a client hello, Server Hello Done, Cipher Spec, etc, but then it starts over and over again.
So, could it be a TLS issue as you hinted?

I also captured the client console regarding the wss messages (Firefox).
It won't reveal much, but here it is anyway:

https://drive.google.com/file/d/1u4uXW0TCTwClE2kt2nbJSGt5VLdKC03t/view?usp=sharing
NB: the destination server is not the same one as in the packet trace, but that's what the client gets each time (it keeps showing '101 Switching Protocols' over and over).

Please let me know if I should add something to the bug report, or if you see anything of interest in the data I've sent.

Thanks,

Vieri



From squid3 at treenet.co.nz  Mon Oct 19 07:44:16 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 19 Oct 2020 20:44:16 +1300
Subject: [squid-users] websockets through Squid
In-Reply-To: <1304872121.821246.1603058873508@mail.yahoo.com>
References: <1626472963.180117.1602859307164.ref@mail.yahoo.com>
 <1626472963.180117.1602859307164@mail.yahoo.com>
 <d24b2583-4959-99d2-9d22-ba3141f595cd@measurement-factory.com>
 <1798348484.217408.1602863930213@mail.yahoo.com>
 <3f7b01cd-f71c-6fb0-27bf-74fbda532384@measurement-factory.com>
 <1304872121.821246.1603058873508@mail.yahoo.com>
Message-ID: <b3ec2e0c-8e46-dfec-cac2-d884cfb6e3b7@treenet.co.nz>

On 19/10/20 11:07 am, Vieri wrote:
> 
> On Saturday, October 17, 2020, 10:36:47 PM GMT+2, Alex Rousskov wrote: 
> 
>> or due to some TLS error.
>> I filed bug #5084 
> 
>  Hi again,
> 
> Thanks for opening a bug report.
> 
> I don't want to add anything there myself because I wouldn't want to confuse whoever might take this issue into account, but I'd like to comment on this list that I've captured the traffic between Squid and the destination server.
> It's here:
> 
> https://drive.google.com/file/d/1WS7Y62Fng5ggXryzKGW1JOsJ16cyR0mg/view?usp=sharing
> 
> I can see a client hello, Server Hello Done, Cipher Spec, etc, but then it starts over and over again.
> So, could it be a TLS issue as you hinted?
> 

I'm not seeing anything particularly unusual in there.

The many handshakes are all on different TCP connections, each is
successful, and followed by at least several "application data"
encrypted packets and a TLS connection closure alert before TCP FIN.


Amos


From klaus_brandl at genua.de  Mon Oct 19 12:33:38 2020
From: klaus_brandl at genua.de (Klaus Brandl)
Date: Mon, 19 Oct 2020 12:33:38 +0000
Subject: [squid-users] squid kerberos auth, acl note group
In-Reply-To: <704e36b3-4cd8-611c-0643-231c02045db6@treenet.co.nz>
References: <9473896.LjNUQkeJut@cairon> <12080330.Prj8ev6qeJ@cairon>
 <1ef6cafe-19f6-9b9c-9612-90552430bdb4@treenet.co.nz>
 <11252591.tFmiVPXsx0@cairon>
 <704e36b3-4cd8-611c-0643-231c02045db6@treenet.co.nz>
Message-ID: <5cc6310267efa40625b59b61ccc6781f257c8804.camel@genua.de>

> > But i think, we have a caching problem here, i found out, that the
> > group 
> > informations are only updated on a squid reconfigure.
> > 
> > And also the acl note group ... seems to be cached as long as squid
> > is 
> > restarted completely. I removed the configured group from the user,
> > but i could 
> > see this group still maching in the cache.log, also after a
> > reconfigure, when 
> > the auth_helper does not tell about this group any more.
> > 
> 
> The groups are attached to credentials which are attached to the TCP
> connection (TTL only as long as the connection is open) and a token
> replay cache for up to authenticate_ttl directive time (default 1
> hour).
> 
> Setting that TTL to something very short, eg:
> 
>   authenticate_ttl 10 seconds
> 
> ... and disabling connection keep-alive:
> 
>   client_persistent_connections off
> 
> ... should work around the cache for testing. At least on HTTP
> traffic.
> HTTPS traffic goes through the proxy as a single tunnel request - so
> the
> entire HTTPS session is just one request/response pair to Squid.
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

sorry again, but i still have this caching problem with the groups in
the note ACL. I have tested the options you suggested, but it takes no
effekt, the group is still matching until squid is completely
restarted. It looks like the note ACL is always appended only.
Or is there a way, to flush this content?

Regards

Klaus




From rentorbuy at yahoo.com  Mon Oct 19 15:39:05 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Mon, 19 Oct 2020 15:39:05 +0000 (UTC)
Subject: [squid-users] sslbump https intercepted or tproxy
References: <2036280346.1069803.1603121945761.ref@mail.yahoo.com>
Message-ID: <2036280346.1069803.1603121945761@mail.yahoo.com>

Hi,

It's unclear to me if I can use TPROXY for HTTPS traffic.

If I divert traffic and use tproxy in the Linux kernel and then set this in squid:

https_port 3130 tproxy ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cert=/etc/ssl/squid/proxyserver.pem

it seems to be working fine, just as if I were to REDIRECT https traffic and then use this in Squid:

https_port 3130 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cert=/etc/ssl/squid/proxyserver.pem

So, does anyone know if it's not recommended / not supported to use tproxy with https traffic?
I'm asking because I don't see any issues with tproxy, with the added advantage of being able to route on the gateway per source IP addr. (in intercepted mode, the source is always Squid).

Are there any reasons for which one would not use TPROXY with HTTPS?

Vieri


From ngtech1ltd at gmail.com  Mon Oct 19 17:16:05 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Mon, 19 Oct 2020 20:16:05 +0300
Subject: [squid-users] SSL issue on Squid version 4 after blacklisting
In-Reply-To: <AM5PR0102MB27562AE35494A01781EB3EAC931E0@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
References: <AM5PR0102MB2756FB157CFBE6C65DB56EB693200@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
 <DB6PR0102MB27603E5519932014BC566B2593360@DB6PR0102MB2760.eurprd01.prod.exchangelabs.com>
 <001801d6a08c$1ad683e0$50838ba0$@gmail.com>
 <AM5PR0102MB27562AE35494A01781EB3EAC931E0@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
Message-ID: <003e01d6a63b$884c6e80$98e54b80$@gmail.com>

Hey Dixit,

 

To get a response you would need to respond in the Bugzilla.

Maybe Alex might be able to answer some of your questions about the subject.

 

All The Bests,

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit <Ankit.Dixit at eurostar.com> 
Sent: Monday, October 19, 2020 3:11 PM
To: Eliezer Croitor <ngtech1ltd at gmail.com>
Cc: 'Squid Users' <squid-users at lists.squid-cache.org>
Subject: RE: SSL issue on Squid version 4 after blacklisting

 

Elizer,

 

1.	I am not able to identify from below like what exactly needs to be done and in which file?

 

* Short-term: Essentially disable OpenSSL built-in certificate validation (for certificates with missing intermediate CAs) and perform that validation from Squid, using X509_verify_cert(), after SSL_connect() returns control to Squid and Squid fetches the missing CAs. This approach still requires some non-trivial Squid development and keeping an eye on OpenSSL built-in validation logic, but it can be completed without OpenSSL modifications and, IMHO, without replicating a lot of OpenSSL internal validation logic.

 

* Long-term: We need a new OpenSSL callback for pausing OpenSSL processing after TLS v1.3 server handshake is decrypted and before certificate validation starts.

 

2.	Apart from above, I want to also understand if we have below configuration in Squid version 3.5 in squid.conf then how would I replace and to what ,if we move to Squid version 4.12

 

sslproxy_cipher HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE 

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Sent: Monday, October 12, 2020 12:38 PM
To: DIXIT Ankit <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com> >
Cc: 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: RE: SSL issue on Squid version 4 after blacklisting

 




 

Hey Dixit,

 

Have you seen the next bug report:

https://bugs.squid-cache.org/show_bug.cgi?id=5067#c4

 

Alex/Amos: I assume that this specific issue deserve a DEBUG which will describe and relate to this BUG:5067 report.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com> > 
Sent: Friday, September 25, 2020 4:22 PM
To: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >; 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: RE: SSL issue on Squid version 4 after blacklisting

 

Elizer/Team,

 

Any help would be appreciated.

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: DIXIT Ankit 
Sent: Tuesday, September 15, 2020 1:24 PM
To: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >; 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: SSL issue on Squid version 4 after blacklisting

 

Subject changed

 

Elizer/Team,

 

Connecting with you again after we upgraded to Squid version 4.

 

We have blacklisted the domain categories  on Squid Proxy, but we are getting below exception in cache.log and due to this internet is not flowing from client servers via squid. 

This blacklist category is having thousands of blacklisted domains.

 

kid1| Error negotiating SSL on FD 33: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)

kid1| Error negotiating SSL connection on FD 26: (104) Connection reset by peer

 

Is there any specific ssl certificate, we need to configure? Or any other issue, you see here?

 

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: DIXIT Ankit 
Sent: Monday, July 6, 2020 8:50 AM
To: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >; 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: RE: [squid-users] Squid memory consumption problem

 

Elizer,

 

SSL was failing for few applications but was working fine for other applications. So we reverted back to old version.

I am not sure what ssl certificate dependency was there. 

 

Would be great, if you can suggest memory leak solutions in 3.12 version.

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Sent: Sunday, July 5, 2020 5:58 PM
To: DIXIT Ankit <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com> >; 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Cc: SETHI Konica <Konica.Sethi at eurostar.com <mailto:Konica.Sethi at eurostar.com> >
Subject: RE: [squid-users] Squid memory consumption problem

 




 

Hey,

 

What happen with this issue?

I am waiting for any input about this issue to understand with what I can try to help.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit [mailto:Ankit.Dixit at eurostar.com] 
Sent: Tuesday, June 30, 2020 12:35 PM
To: Eliezer Croitoru; Squid Users
Cc: SETHI Konica
Subject: RE: [squid-users] Squid memory consumption problem

 

For your information, we have added below configurations but again same issue.

 

tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

 

tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: DIXIT Ankit 
Sent: Tuesday, June 30, 2020 10:25 AM
To: Eliezer Croitoru <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >; Squid Users <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Cc: SETHI Konica <Konica.Sethi at eurostar.com <mailto:Konica.Sethi at eurostar.com> >
Subject: RE: [squid-users] Squid memory consumption problem

 

Eliezer,

 

Clients are facing some SSL related issues after upgrade. I could see below error. Please suggest, its little urgent.

 

quid[6706]: Error negotiating SSL connection on FD 167: error:00000001:lib(0):func(0):reason(1) (1/0)
Jun 30 09:17:38 squid[6706]: Error parsing SSL Server Hello Message on FD 77
Jun 30 09:17:38 squid[6706]: Error negotiating SSL connection on FD 75: error:00000001:lib(0):func(0):reason(1) (1/0)

 

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: Eliezer Croitoru <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Sent: Tuesday, June 30, 2020 9:10 AM
To: Squid Users <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >; DIXIT Ankit <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com> >
Subject: RE: [squid-users] Squid memory consumption problem

 




 

The first thing to do is look at:

https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery

 

It should clear couple doubts for you.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit <mailto:Ankit.Dixit at eurostar.com> 
Sent: Tuesday, June 30, 2020 10:46 AM
To: Eliezer Croitoru <mailto:ngtech1ltd at gmail.com> ; Alex Rousskov <mailto:rousskov at measurement-factory.com> ; squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Subject: RE: [squid-users] Squid memory consumption problem

 

Elizer,

 

We installed Squid 4.12 on production server, amazon Linux 2, successfully but I could see below messages in the logs for SECURITY ALERT: Host header forgery detected. These are getting generated very frequently.

Can we ignore this Or is it advised to suppress these alerts?

 

kid2| SECURITY ALERT: on URL: 5-25-3-app.agent.datadoghq.com:443 <http://5-25-3-app.agent.datadoghq.com:443> 

2020/06/30 07:41:29 kid1| SECURITY ALERT: Host header forgery detected on local=IP remote=IP FD 97 flags=33 (local IP does not match any domain IP)

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

 

  _____  

This email (including any attachments) is intended only for the addressee(s), is confidential and may be legally privileged. If you are not the intended recipient, do not use, disclose, copy, or forward this email. Please notify the sender immediately and then delete it. Eurostar International Limited and its affiliates ("EIL") do not accept any liability for action taken in reliance on this email. EIL makes no representation that this email is free of viruses and addressees should check this email for viruses. The comments or statements expressed in this email are not necessarily those of EIL. 

Eurostar International Ltd 
Times House, Bravingtons Walk, London N1 9AW Registered in England and Wales No. 2462001 

  _____  

 

 

  _____  

This email (including any attachments) is intended only for the addressee(s), is confidential and may be legally privileged. If you are not the intended recipient, do not use, disclose, copy, or forward this email. Please notify the sender immediately and then delete it. Eurostar International Limited and its affiliates ("EIL") do not accept any liability for action taken in reliance on this email. EIL makes no representation that this email is free of viruses and addressees should check this email for viruses. The comments or statements expressed in this email are not necessarily those of EIL. 

Eurostar International Ltd 
Times House, Bravingtons Walk, London N1 9AW Registered in England and Wales No. 2462001 

  _____  

 

 

  _____  

This email (including any attachments) is intended only for the addressee(s), is confidential and may be legally privileged. If you are not the intended recipient, do not use, disclose, copy, or forward this email. Please notify the sender immediately and then delete it. Eurostar International Limited and its affiliates ("EIL") do not accept any liability for action taken in reliance on this email. EIL makes no representation that this email is free of viruses and addressees should check this email for viruses. The comments or statements expressed in this email are not necessarily those of EIL. 

Eurostar International Ltd 
Times House, Bravingtons Walk, London N1 9AW Registered in England and Wales No. 2462001 

  _____  

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201019/27b43881/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.jpg
Type: image/jpeg
Size: 19517 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201019/27b43881/attachment.jpg>

From rousskov at measurement-factory.com  Mon Oct 19 18:30:30 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 19 Oct 2020 14:30:30 -0400
Subject: [squid-users] SSL issue on Squid version 4 after blacklisting
In-Reply-To: <003e01d6a63b$884c6e80$98e54b80$@gmail.com>
References: <AM5PR0102MB2756FB157CFBE6C65DB56EB693200@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
 <DB6PR0102MB27603E5519932014BC566B2593360@DB6PR0102MB2760.eurprd01.prod.exchangelabs.com>
 <001801d6a08c$1ad683e0$50838ba0$@gmail.com>
 <AM5PR0102MB27562AE35494A01781EB3EAC931E0@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
 <003e01d6a63b$884c6e80$98e54b80$@gmail.com>
Message-ID: <94a90300-2823-77ef-1518-ed73e5669573@measurement-factory.com>

On 10/19/20 1:16 PM, Eliezer Croitor wrote:

> To get a response you would need to respond in the Bugzilla.
> Maybe Alex might be able to answer some of your questions about the subject.

FWIW, the October 19 email from Ankit Dixit (quoted below) did not reach
me. It probably did not reach others on squid-users either because the
mailing list archive does not show it.

The short answer to that "what needs to be done" question is "serious
development". It is not a simple change, but we are making progress with it.

Alex.

 ?

> *From:* DIXIT Ankit <Ankit.Dixit at eurostar.com>
> *Sent:* Monday, October 19, 2020 3:11 PM
> *To:* Eliezer Croitor <ngtech1ltd at gmail.com>
> *Cc:* 'Squid Users' <squid-users at lists.squid-cache.org>
> *Subject:* RE: SSL issue on Squid version 4 after blacklisting
> 
> ?
> 
> Elizer,
> 
> ?
> 
>  1. I am not able to identify from below like what exactly needs to be
>     done and in which file?
> 
> ?
> 
> * Short-term: Essentially disable OpenSSL built-in certificate
> validation (for certificates with missing intermediate CAs) and perform
> that validation from Squid, using X509_verify_cert(), after
> SSL_connect() returns control to Squid and Squid fetches the missing
> CAs. This approach still requires some non-trivial Squid development and
> keeping an eye on OpenSSL built-in validation logic, but it can be
> completed without OpenSSL modifications and, IMHO, without replicating a
> lot of OpenSSL internal validation logic.
> 
> ?
> 
> * Long-term: We need a new OpenSSL callback for pausing OpenSSL
> processing after TLS v1.3 server handshake is decrypted and before
> certificate validation starts.
> 
> ?
> 
>  2. Apart from above, I want to also understand if we have below
>     configuration in Squid version 3.5 in squid.conf then how would I
>     replace and to what ,if we move to Squid version 4.12
> 
> ?
> 
> sslproxy_cipher
> HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> 
> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE
> 
> ?
> 
> *Regards,*
> 
> *Ankit Dixit|IS Cloud Team*
> 
> *Eurostar International Ltd*
> 
> *Times House | Bravingtons Walk | London N1 9AW*
> 
> *Office: +44 (0)207 84 35550 (Extension? 35530)*
> 
> ?
> 
> *From:* Eliezer Croitor <ngtech1ltd at gmail.com
> <mailto:ngtech1ltd at gmail.com>>
> *Sent:* Monday, October 12, 2020 12:38 PM
> *To:* DIXIT Ankit <Ankit.Dixit at eurostar.com
> <mailto:Ankit.Dixit at eurostar.com>>
> *Cc:* 'Squid Users' <squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>
> *Subject:* RE: SSL issue on Squid version 4 after blacklisting
> 
> ?
> 
> ?
> 
> Hey Dixit,
> 
> ?
> 
> Have you seen the next bug report:
> 
> https://bugs.squid-cache.org/show_bug.cgi?id=5067#c4
> 
> ?
> 
> Alex/Amos: I assume that this specific issue deserve a DEBUG which will
> describe and relate to this BUG:5067 report.
> 
> ?
> 
> Eliezer
> 
> ?
> 
> ----
> 
> Eliezer Croitoru
> 
> Tech Support
> 
> Mobile: +972-5-28704261
> 
> Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com>
> 
> ?
> 
> *From:* DIXIT Ankit <Ankit.Dixit at eurostar.com
> <mailto:Ankit.Dixit at eurostar.com>>
> *Sent:* Friday, September 25, 2020 4:22 PM
> *To:* Eliezer Croitor <ngtech1ltd at gmail.com
> <mailto:ngtech1ltd at gmail.com>>; 'Squid Users'
> <squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>
> *Subject:* RE: SSL issue on Squid version 4 after blacklisting
> 
> ?
> 
> Elizer/Team,
> 
> ?
> 
> Any help would be appreciated.
> 
> ?
> 
> *Regards,*
> 
> *Ankit Dixit|IS Cloud Team*
> 
> *Eurostar International Ltd*
> 
> *Times House | Bravingtons Walk | London N1 9AW*
> 
> *Office: +44 (0)207 84 35550 (Extension? 35530)*
> 
> ?
> 
> *From:* DIXIT Ankit
> *Sent:* Tuesday, September 15, 2020 1:24 PM
> *To:* Eliezer Croitor <ngtech1ltd at gmail.com
> <mailto:ngtech1ltd at gmail.com>>; 'Squid Users'
> <squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>
> *Subject:* SSL issue on Squid version 4 after blacklisting
> 
> ?
> 
> *_Subject changed_*
> 
> *?*
> 
> Elizer/Team,
> 
> ?
> 
> Connecting with you again after we upgraded to Squid version 4.
> 
> ?
> 
> We have blacklisted the domain categories ?on Squid Proxy, but we are
> getting below exception in cache.log and due to this internet is not
> flowing from client servers via squid.
> 
> This blacklist category is having thousands of blacklisted domains.
> 
> ?
> 
> kid1| Error negotiating SSL on FD 33: error:14090086:SSL
> routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)
> 
> kid1| Error negotiating SSL connection on FD 26: (104) Connection reset
> by peer
> 
> ?
> 
> Is there any specific ssl certificate, we need to configure? Or any
> other issue, you see here?
> 
> ?
> 
> ?
> 
> *Regards,*
> 
> *Ankit Dixit|IS Cloud Team*
> 
> *Eurostar International Ltd*
> 
> *Times House | Bravingtons Walk | London N1 9AW*
> 
> *Office: +44 (0)207 84 35550 (Extension? 35530)*
> 
> ?
> 
> *From:* DIXIT Ankit
> *Sent:* Monday, July 6, 2020 8:50 AM
> *To:* Eliezer Croitor <ngtech1ltd at gmail.com
> <mailto:ngtech1ltd at gmail.com>>; 'Squid Users'
> <squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>
> *Subject:* RE: [squid-users] Squid memory consumption problem
> 
> ?
> 
> Elizer,
> 
> ?
> 
> SSL was failing for few applications but was working fine for other
> applications. So we reverted back to old version.
> 
> I am not sure what ssl certificate dependency was there.
> 
> ?
> 
> Would be great, if you can suggest memory leak solutions in 3.12 version.
> 
> ?
> 
> *Regards,*
> 
> *Ankit Dixit|IS Cloud Team*
> 
> *Eurostar International Ltd*
> 
> *Times House | Bravingtons Walk | London N1 9AW*
> 
> *Office: +44 (0)207 84 35550 (Extension? 35530)*
> 
> ?
> 
> *From:* Eliezer Croitor <ngtech1ltd at gmail.com
> <mailto:ngtech1ltd at gmail.com>>
> *Sent:* Sunday, July 5, 2020 5:58 PM
> *To:* DIXIT Ankit <Ankit.Dixit at eurostar.com
> <mailto:Ankit.Dixit at eurostar.com>>; 'Squid Users'
> <squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>
> *Cc:* SETHI Konica <Konica.Sethi at eurostar.com
> <mailto:Konica.Sethi at eurostar.com>>
> *Subject:* RE: [squid-users] Squid memory consumption problem
> 
> ?
> 
> ?
> 
> Hey,
> 
> ?
> 
> What happen with this issue?
> 
> I am waiting for any input about this issue to understand with what I
> can try to help.
> 
> ?
> 
> Eliezer
> 
> ?
> 
> ----
> 
> Eliezer Croitoru
> 
> Tech Support
> 
> Mobile: +972-5-28704261
> 
> Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com>
> 
> ?
> 
> *From:*DIXIT Ankit [mailto:Ankit.Dixit at eurostar.com]
> *Sent:* Tuesday, June 30, 2020 12:35 PM
> *To:* Eliezer Croitoru; Squid Users
> *Cc:* SETHI Konica
> *Subject:* RE: [squid-users] Squid memory consumption problem
> 
> ?
> 
> For your information, we have added below configurations but again same
> issue.
> 
> ?
> 
> tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 
> ?
> 
> tls_outgoing_options
> cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> 
> ?
> 
> *Regards,*
> 
> *Ankit Dixit|IS Cloud Team*
> 
> *Eurostar International Ltd*
> 
> *Times House | Bravingtons Walk | London N1 9AW*
> 
> *Office: +44 (0)207 84 35550 (Extension? 35530)*
> 
> ?
> 
> *From:* DIXIT Ankit
> *Sent:* Tuesday, June 30, 2020 10:25 AM
> *To:* Eliezer Croitoru <ngtech1ltd at gmail.com
> <mailto:ngtech1ltd at gmail.com>>; Squid Users
> <squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>
> *Cc:* SETHI Konica <Konica.Sethi at eurostar.com
> <mailto:Konica.Sethi at eurostar.com>>
> *Subject:* RE: [squid-users] Squid memory consumption problem
> 
> ?
> 
> Eliezer,
> 
> ?
> 
> Clients are facing some SSL related issues after upgrade. I could see
> below error. Please suggest, its little urgent.
> 
> ?
> 
> quid[6706]: Error negotiating SSL connection on FD 167:
> error:00000001:lib(0):func(0):reason(1) (1/0)
> Jun 30 09:17:38 squid[6706]: Error parsing SSL Server Hello Message on FD 77
> Jun 30 09:17:38 squid[6706]: Error negotiating SSL connection on FD 75:
> error:00000001:lib(0):func(0):reason(1) (1/0)
> 
> ?
> 
> ?
> 
> *Regards,*
> 
> *Ankit Dixit|IS Cloud Team*
> 
> *Eurostar International Ltd*
> 
> *Times House | Bravingtons Walk | London N1 9AW*
> 
> *Office: +44 (0)207 84 35550 (Extension? 35530)*
> 
> ?
> 
> *From:* Eliezer Croitoru <ngtech1ltd at gmail.com
> <mailto:ngtech1ltd at gmail.com>>
> *Sent:* Tuesday, June 30, 2020 9:10 AM
> *To:* Squid Users <squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>; DIXIT Ankit
> <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com>>
> *Subject:* RE: [squid-users] Squid memory consumption problem
> 
> ?
> 
> ?
> 
> The first thing to do is look at:
> 
> https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery
> 
> ?
> 
> It should clear couple doubts for you.
> 
> ?
> 
> Eliezer
> 
> ?
> 
> ----
> 
> Eliezer Croitoru
> 
> Tech Support
> 
> Mobile: +972-5-28704261
> 
> Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com>
> 
> ?
> 
> *From: *DIXIT Ankit <mailto:Ankit.Dixit at eurostar.com>
> *Sent: *Tuesday, June 30, 2020 10:46 AM
> *To: *Eliezer Croitoru <mailto:ngtech1ltd at gmail.com>; Alex Rousskov
> <mailto:rousskov at measurement-factory.com>;
> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
> *Subject: *RE: [squid-users] Squid memory consumption problem
> 
> ?
> 
> Elizer,
> 
> ?
> 
> We installed Squid 4.12 on production server, amazon Linux 2,
> successfully but I could see below messages in the logs for SECURITY
> ALERT: Host header forgery detected. These are getting generated very
> frequently.
> 
> Can we ignore this Or is it advised to suppress these alerts?
> 
> ?
> 
> kid2| SECURITY ALERT: on URL: 5-25-3-app.agent.datadoghq.com:443
> <http://5-25-3-app.agent.datadoghq.com:443>
> 
> 2020/06/30 07:41:29 kid1| SECURITY ALERT: Host header forgery detected
> on local=IP remote=IP FD 97 flags=33 (local IP does not match any domain IP)
> 
> ?
> 
> *Regards,*
> 
> *Ankit Dixit|IS Cloud Team*
> 
> *Eurostar International Ltd*
> 
> *Times House | Bravingtons Walk | London N1 9AW*
> 
> *Office: +44 (0)207 84 35550 (Extension? 35530)*
> 
> ?
> 
> ?
> 
> ------------------------------------------------------------------------
> 
> This email (including any attachments) is intended only for the
> addressee(s), is confidential and may be legally privileged. If you are
> not the intended recipient, do not use, disclose, copy, or forward this
> email. Please notify the sender immediately and then delete it. Eurostar
> International Limited and its affiliates ("EIL") do not accept any
> liability for action taken in reliance on this email. EIL makes no
> representation that this email is free of viruses and addressees should
> check this email for viruses. The comments or statements expressed in
> this email are not necessarily those of EIL.
> 
> Eurostar International Ltd
> Times House, Bravingtons Walk, London N1 9AW Registered in England and
> Wales No. 2462001
> 
> ------------------------------------------------------------------------
> 
> ?
> 
> ?
> 
> ------------------------------------------------------------------------
> 
> This email (including any attachments) is intended only for the
> addressee(s), is confidential and may be legally privileged. If you are
> not the intended recipient, do not use, disclose, copy, or forward this
> email. Please notify the sender immediately and then delete it. Eurostar
> International Limited and its affiliates ("EIL") do not accept any
> liability for action taken in reliance on this email. EIL makes no
> representation that this email is free of viruses and addressees should
> check this email for viruses. The comments or statements expressed in
> this email are not necessarily those of EIL.
> 
> Eurostar International Ltd
> Times House, Bravingtons Walk, London N1 9AW Registered in England and
> Wales No. 2462001
> 
> ------------------------------------------------------------------------
> 
> ?
> 
> ?
> 
> ------------------------------------------------------------------------
> 
> This email (including any attachments) is intended only for the
> addressee(s), is confidential and may be legally privileged. If you are
> not the intended recipient, do not use, disclose, copy, or forward this
> email. Please notify the sender immediately and then delete it. Eurostar
> International Limited and its affiliates ("EIL") do not accept any
> liability for action taken in reliance on this email. EIL makes no
> representation that this email is free of viruses and addressees should
> check this email for viruses. The comments or statements expressed in
> this email are not necessarily those of EIL.
> 
> Eurostar International Ltd
> Times House, Bravingtons Walk, London N1 9AW Registered in England and
> Wales No. 2462001
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From Anton.Kornexl at uni-passau.de  Tue Oct 20 05:18:43 2020
From: Anton.Kornexl at uni-passau.de (Kornexl, Anton)
Date: Tue, 20 Oct 2020 05:18:43 +0000
Subject: [squid-users] Squid doesn't call helper
Message-ID: <cd926b3de9c5454faff2d90ee925a5fe@ads.uni-passau.de>

Squid 4.10 on Ubuntu 20.04

The configured program is started but not called (or the result not used)
The authentication window does not show up in the browser
All request are denied because acl proxyuser doesn't match
The same config runs on squid 3.5.27 on Ubuntu 18.04 and squid 4.13 on opensuse 4.13

How can i debug this problem
Other helpers are also not called/used

The squid user can execute the configured program
/usr/local/bin/mysql_auth and returns an OK

sudo -u squid /usr/local/bin/mysql_auth
test testing
OK

-------------------
auth_param basic program /usr/local/bin/mysql_auth
auth_param basic children 10 startup=5 idle=1
auth_param basic utf8 on
auth_param basic realm "Squid proxy-caching web server"
auth_param basic credentialsttl 2 hours

acl jufi1 src 1.2.3.4/32
acl jufi1-6 src  2a01:.....::2
acl jufi2 src 1.2.3.5/32
acl jufi2-6 src 2a01:.....::2

acl proxyusers proxy_auth REQUIRED

http_access allow jufi1
http_access allow jufi1-6
http_access allow jufi2
http_access allow jufi2-6

http_access allow proxyusers

-----------------------

Yours
Anton Kornexl
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201020/83ad65f9/attachment.htm>

From clp.pub at orange.fr  Tue Oct 20 09:44:23 2020
From: clp.pub at orange.fr (Christophe Leloup)
Date: Tue, 20 Oct 2020 11:44:23 +0200 (CEST)
Subject: [squid-users] active directory 2008.
Message-ID: <267750665.1308994.1603187063694.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>

Good morning all,

I am French. excuse me for my English.
I am looking for a tutorial. how integrated an active directory 2008 with squid.

do you have any leads or websites?

thank you


From squid3 at treenet.co.nz  Tue Oct 20 11:38:20 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 21 Oct 2020 00:38:20 +1300
Subject: [squid-users] Squid doesn't call helper
In-Reply-To: <cd926b3de9c5454faff2d90ee925a5fe@ads.uni-passau.de>
References: <cd926b3de9c5454faff2d90ee925a5fe@ads.uni-passau.de>
Message-ID: <71236fda-fd8a-6055-a287-7c2e60058f58@treenet.co.nz>

On 20/10/20 6:18 pm, Kornexl, Anton wrote:
> Squid 4.10 on Ubuntu 20.04
> 
> ?
> 
> The configured program is started but not called (or the result not used)
> 

Please check cache.log to find out which of those two very different
things is happening.

One means the ACL is not being checked or credentials not provided. The
other means credentials are invalid.

You may need to set this directive:
  debug_options 11,2 29,5 28,4

> The authentication window does not show up in the browser

That means the auth result was not deny.


> 
> All request are denied because acl proxyuser doesn?t match
> 

There is no deny line in your shown config using auth ACLs.


> The same config runs on squid 3.5.27 on Ubuntu 18.04 and squid 4.13 on
> opensuse 4.13
> 
> ?
> 
> How can i debug this problem
> 

Check cache.log with this directive set:
  debug_options 11,2 29,5 28,4


> Other helpers are also not called/used
> 
> ?

That strongly implies you have an ordering problem in your config file.
One early ACL allowing or denying traffic before any helpers get checked.


> 
> http_access allow jufi1
> 
> http_access allow jufi1-6
> 
> http_access allow jufi2
> 
> http_access allow jufi2-6
> 

Since they are all the same type, and used the same way at the same time
You can combine all those ACLs into one name.

> 
> http_access allow proxyusers
> 

Please try the recommended auth config:

  http_access deny !proxyusers
  http_access allow localnet



Amos


From squid3 at treenet.co.nz  Tue Oct 20 11:42:16 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 21 Oct 2020 00:42:16 +1300
Subject: [squid-users] active directory 2008.
In-Reply-To: <267750665.1308994.1603187063694.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>
References: <267750665.1308994.1603187063694.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>
Message-ID: <353a6a87-17ad-d6a3-b254-047377615485@treenet.co.nz>

On 20/10/20 10:44 pm, Christophe Leloup wrote:
> Good morning all,
> 
> I am French. excuse me for my English.
> I am looking for a tutorial. how integrated an active directory 2008 with squid.
> 
> do you have any leads or websites?
> 

That depends on what you are trying to make Squid do, which you have not
mentioned. For better help please provide details.

<https://wiki.squid-cache.org/> has a lot of info.

Amos


From squid3 at treenet.co.nz  Tue Oct 20 11:50:02 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 21 Oct 2020 00:50:02 +1300
Subject: [squid-users] sslbump https intercepted or tproxy
In-Reply-To: <2036280346.1069803.1603121945761@mail.yahoo.com>
References: <2036280346.1069803.1603121945761.ref@mail.yahoo.com>
 <2036280346.1069803.1603121945761@mail.yahoo.com>
Message-ID: <fe85a09e-7034-e944-fcfa-3c5dc976214b@treenet.co.nz>

On 20/10/20 4:39 am, Vieri wrote:
> Hi,
> 
> It's unclear to me if I can use TPROXY for HTTPS traffic.

You can. It is just an alternative to NAT.


Amos


From clp.pub at orange.fr  Tue Oct 20 12:24:34 2020
From: clp.pub at orange.fr (Christophe Leloup)
Date: Tue, 20 Oct 2020 14:24:34 +0200 (CEST)
Subject: [squid-users] active directory 2008.
In-Reply-To: <1061698431.1318969.1603196615823.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>
References: <267750665.1308994.1603187063694.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>
 <353a6a87-17ad-d6a3-b254-047377615485@treenet.co.nz>
 <1061698431.1318969.1603196615823.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>
Message-ID: <1670501042.1319050.1603196674982.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201020/271dbffe/attachment.htm>

From squid3 at treenet.co.nz  Tue Oct 20 12:32:15 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 21 Oct 2020 01:32:15 +1300
Subject: [squid-users] active directory 2008.
In-Reply-To: <1670501042.1319050.1603196674982.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>
References: <267750665.1308994.1603187063694.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>
 <353a6a87-17ad-d6a3-b254-047377615485@treenet.co.nz>
 <1061698431.1318969.1603196615823.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>
 <1670501042.1319050.1603196674982.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>
Message-ID: <e7255392-43f4-c9e8-d72c-3d5167eaec1c@treenet.co.nz>

On 21/10/20 1:24 am, Christophe Leloup wrote:
> Hi,
> 
> I have connected my debian to my active directory. I don't have machine
> authentication by user but only by ip. attached my squid.conf.
> 

Well. Yes, that looks true.

Amos


From philipp.gesang at intra2net.com  Tue Oct 20 12:41:15 2020
From: philipp.gesang at intra2net.com (Philipp Gesang)
Date: Tue, 20 Oct 2020 14:41:15 +0200
Subject: [squid-users] Suppressing authentication schemes
Message-ID: <20201020124115.GA4848@crust.m.i2n>

Hi,

a while back we received a report from a customer that Windows
hosts will not fall back on conventional authentication
mechanisms if Squid advertises Negotiate. That is unfortunate as
not all systems in that customer?s network are Kerberos enabled;
some of them should just continue using other authentication
schemes. (We don?t do NTLM.)

To deal with the situation we are patching Squid to selectively
omit the Negotiate mechanism in the initial reply via the notes
mechanism. That seems to do the job reasonably well judging by
the silence from the customer since we rolled out the patch some
time last year. A version of that patch against 5.0.1 is
attached; it?s completely untested though as we?re still on
3.5.28 but it should serve as example for what I mean.

Naturally we would prefer a solution that doesn?t involve
patching so if there?s already a built-in alternative that we
could use instead, I?d appreciate a pointer. If not, what would
have to be done to get this functionality into the official
release?

Thank you and stay healthy everyone,
Philipp

-------------- next part --------------
From b61451421081a7c5233ac6b2e579a0576a7f8558 Mon Sep 17 00:00:00 2001
From: Philipp Gesang <philipp.gesang at intra2net.com>
Date: Fri, 12 Jul 2019 09:10:21 +0200
Subject: [PATCH] allow blacklisting authentication mechanisms

Abuse the ``notes'' ACL to tag connections to suppress SPNEGO.
This must happen during the initial reply so the client never
receives a Proxy-Authenticate: header offering negotiate in
the first place.

In squid.conf, use ``blacklistAuthSchemes'' as the note key to
mark a connection:

    acl no_spnego src 10.0.42.1/32
    note blacklistAuthSchemes negotiate no_spnego

If this ACL matches while Squid decides what authentication
headers to send to the client, the ``negotiate'' scheme will be
omitted for clients connecting from the given IP address.

Multiple authentication schemes may be specified as a comma
separated list like so:

    note blacklistAuthSchemes negotiate,basic no_spnego

[Patch ported from the original written against 3.5.28.]
---
 src/auth/UserRequest.cc | 62 +++++++++++++++++++++++++++++++++++++----
 1 file changed, 57 insertions(+), 5 deletions(-)

diff --git a/src/auth/UserRequest.cc b/src/auth/UserRequest.cc
index a921feb4e..322edda97 100644
--- a/src/auth/UserRequest.cc
+++ b/src/auth/UserRequest.cc
@@ -26,6 +26,9 @@
 #include "HttpRequest.h"
 #include "MemBuf.h"
 
+#include "SquidConfig.h"
+#include "Notes.h"
+
 /* Generic Functions */
 
 char const *
@@ -475,6 +478,52 @@ schemesConfig(HttpRequest *request, HttpReply *rep)
     return Auth::TheConfig.schemes;
 }
 
+static bool
+scheme_is_blacklisted (const char  *scheme_type,
+                       HttpReply   *reply,
+                       HttpRequest *request)
+{
+    Notes::iterator note;
+
+    if (scheme_type == NULL)
+    {
+        return false;
+    }
+
+    for (note = ::Config.notes.begin();
+         note != ::Config.notes.end();
+         ++note)
+    {
+        if ((*note)->key().cmp("blacklistAuthSchemes") == 0) {
+            SBuf value;
+
+            if (!(*note)->match(request, reply, AccessLogEntryPointer(), value)) {
+                continue;
+            }
+
+            const char *start = value.c_str();
+            while (true) {
+                const char *end = strchrnul (start, ',');
+                if (start == end) {
+                    break;
+                }
+
+                const size_t len = end - start;
+                if (strncmp (scheme_type, start, len) == 0) {
+                    /* Note indeed applies to the current request. */
+                    debugs(29, 9, HERE << "[i2n] note: match " << (*note)->key()
+                           << " in [" << value << "] => blacklisting [" << scheme_type << "]");
+                    return true;
+                }
+
+                start = end + 1;
+            }
+        }
+    }
+
+    return false;
+}
+
 void
 Auth::UserRequest::AddReplyAuthHeader(HttpReply * rep, Auth::UserRequest::Pointer auth_user_request, HttpRequest * request, int accelerated, int internal)
 /* send the auth types we are configured to support (and have compiled in!) */
@@ -515,15 +564,18 @@ Auth::UserRequest::AddReplyAuthHeader(HttpReply * rep, Auth::UserRequest::Pointe
             Auth::ConfigVector &configs = schemesConfig(request, rep);
             for (auto *scheme : configs) {
                 if (scheme->active()) {
-                    if (auth_user_request != NULL && auth_user_request->scheme()->type() == scheme->type())
-                        scheme->fixHeader(auth_user_request, rep, type, request);
-                    else
-                        scheme->fixHeader(NULL, rep, type, request);
+                    if (scheme_is_blacklisted(scheme->type(), rep, request))
+                        debugs(29, 1, HERE << "Configured scheme " << scheme->type() << " suppressed by ACL");
+                    else {
+                        if (auth_user_request != NULL && auth_user_request->scheme()->type() == scheme->type())
+                            scheme->fixHeader(auth_user_request, rep, type, request);
+                        else
+                            scheme->fixHeader(NULL, rep, type, request);
+                    }
                 } else
                     debugs(29, 4, HERE << "Configured scheme " << scheme->type() << " not Active");
             }
         }
-
     }
 
     /*
-- 
2.26.2

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201020/b59edbdd/attachment.sig>

From squid3 at treenet.co.nz  Tue Oct 20 12:34:28 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 21 Oct 2020 01:34:28 +1300
Subject: [squid-users] active directory 2008.
In-Reply-To: <1670501042.1319050.1603196674982.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>
References: <267750665.1308994.1603187063694.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>
 <353a6a87-17ad-d6a3-b254-047377615485@treenet.co.nz>
 <1061698431.1318969.1603196615823.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>
 <1670501042.1319050.1603196674982.JavaMail.open-xchange@opme11oxm22nd1.rouen.francetelecom.fr>
Message-ID: <aa4f481f-c7a8-9abf-5d2b-749f97b7e603@treenet.co.nz>

On 21/10/20 1:24 am, Christophe Leloup wrote:
> Hi,
> 
> I have connected my debian to my active directory. I don't have machine
> authentication by user but only by ip. attached my squid.conf.
> 
> 

Have a read of this:
 <https://wiki.squid-cache.org/Features/Authentication>

Amos


From rousskov at measurement-factory.com  Tue Oct 20 13:53:45 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 20 Oct 2020 09:53:45 -0400
Subject: [squid-users] Suppressing authentication schemes
In-Reply-To: <20201020124115.GA4848@crust.m.i2n>
References: <20201020124115.GA4848@crust.m.i2n>
Message-ID: <e9121a80-0b1d-8f63-7279-0d6b1221a84b@measurement-factory.com>

On 10/20/20 8:41 AM, Philipp Gesang wrote:

> a while back we received a report from a customer that Windows
> hosts will not fall back on conventional authentication
> mechanisms if Squid advertises Negotiate. That is unfortunate as
> not all systems in that customer?s network are Kerberos enabled

We have added the auth_schemes directive to address this and similar
problems. Unfortunately, the squid.conf renderer on the official site
does not include v5+ options, but you can see raw documentation at
https://github.com/squid-cache/squid/blob/710f160/src/cf.data.pre#L2139

HTH,

Alex.


From Anton.Kornexl at uni-passau.de  Tue Oct 20 14:39:35 2020
From: Anton.Kornexl at uni-passau.de (Kornexl, Anton)
Date: Tue, 20 Oct 2020 14:39:35 +0000
Subject: [squid-users] Squid doesn't call helper
In-Reply-To: <71236fda-fd8a-6055-a287-7c2e60058f58@treenet.co.nz>
References: <cd926b3de9c5454faff2d90ee925a5fe@ads.uni-passau.de>
 <71236fda-fd8a-6055-a287-7c2e60058f58@treenet.co.nz>
Message-ID: <ff4f11af6b77449b9aa8d887e5695ba0@ads.uni-passau.de>

Thank you very much

With the debug option i found the error

An external acl program  later in the config returned a number and OK in one line (5:OK or 10:ERR)
The acl handler in squid got an exception handling this returned result and all requests got DENIED

After correcting the external handler squid works OK 
AAAHHHH  

Yours 
Anton Kornexl


-----Urspr?ngliche Nachricht-----
Von: squid-users <squid-users-bounces at lists.squid-cache.org> Im Auftrag von Amos Jeffries
Gesendet: Dienstag, 20. Oktober 2020 13:38
An: squid-users at lists.squid-cache.org
Betreff: Re: [squid-users] Squid doesn't call helper

On 20/10/20 6:18 pm, Kornexl, Anton wrote:
> Squid 4.10 on Ubuntu 20.04
> 
> ?
> 
> The configured program is started but not called (or the result not used)
> 

Please check cache.log to find out which of those two very different
things is happening.

One means the ACL is not being checked or credentials not provided. The
other means credentials are invalid.

You may need to set this directive:
  debug_options 11,2 29,5 28,4

> The authentication window does not show up in the browser

That means the auth result was not deny.


> 
> All request are denied because acl proxyuser doesn?t match
> 

There is no deny line in your shown config using auth ACLs.


> The same config runs on squid 3.5.27 on Ubuntu 18.04 and squid 4.13 on
> opensuse 4.13
> 
> ?
> 
> How can i debug this problem
> 

Check cache.log with this directive set:
  debug_options 11,2 29,5 28,4


> Other helpers are also not called/used
> 
> ?

That strongly implies you have an ordering problem in your config file.
One early ACL allowing or denying traffic before any helpers get checked.


> 
> http_access allow jufi1
> 
> http_access allow jufi1-6
> 
> http_access allow jufi2
> 
> http_access allow jufi2-6
> 

Since they are all the same type, and used the same way at the same time
You can combine all those ACLs into one name.

> 
> http_access allow proxyusers
> 

Please try the recommended auth config:

  http_access deny !proxyusers
  http_access allow localnet



Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From philipp.gesang at intra2net.com  Tue Oct 20 14:44:44 2020
From: philipp.gesang at intra2net.com (Philipp Gesang)
Date: Tue, 20 Oct 2020 16:44:44 +0200
Subject: [squid-users] Suppressing authentication schemes
In-Reply-To: <e9121a80-0b1d-8f63-7279-0d6b1221a84b@measurement-factory.com>
References: <20201020124115.GA4848@crust.m.i2n>
 <e9121a80-0b1d-8f63-7279-0d6b1221a84b@measurement-factory.com>
Message-ID: <20201020144444.GB4848@crust.m.i2n>

Hey Alex,

On Tuesday, 2020-10-20 09:53:45 -0400 Alex Rousskov <rousskov at measurement-factory.com> wrote 
> > a while back we received a report from a customer that Windows
> > hosts will not fall back on conventional authentication
> > mechanisms if Squid advertises Negotiate. That is unfortunate as
> > not all systems in that customer?s network are Kerberos enabled
> 
> We have added the auth_schemes directive to address this and similar
> problems. Unfortunately, the squid.conf renderer on the official site
> does not include v5+ options, but you can see raw documentation at
> https://github.com/squid-cache/squid/blob/710f160/src/cf.data.pre#L2139

fantastic, thanks! That looks like it?s exactly what we need. So this
will be a 5.x only feature?

Philipp
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201020/20db06d4/attachment.sig>

From rousskov at measurement-factory.com  Tue Oct 20 14:59:41 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 20 Oct 2020 10:59:41 -0400
Subject: [squid-users] Suppressing authentication schemes
In-Reply-To: <20201020144444.GB4848@crust.m.i2n>
References: <20201020124115.GA4848@crust.m.i2n>
 <e9121a80-0b1d-8f63-7279-0d6b1221a84b@measurement-factory.com>
 <20201020144444.GB4848@crust.m.i2n>
Message-ID: <1d6356db-1c45-dda6-7c0b-18cec3122193@measurement-factory.com>

On 10/20/20 10:44 AM, Philipp Gesang wrote:
> On Tuesday, 2020-10-20 09:53:45 -0400 Alex Rousskov wrote 
>>> a while back we received a report from a customer that Windows
>>> hosts will not fall back on conventional authentication
>>> mechanisms if Squid advertises Negotiate. That is unfortunate as
>>> not all systems in that customer?s network are Kerberos enabled
>>
>> We have added the auth_schemes directive to address this and similar
>> problems. Unfortunately, the squid.conf renderer on the official site
>> does not include v5+ options, but you can see raw documentation at
>> https://github.com/squid-cache/squid/blob/710f160/src/cf.data.pre#L2139

> That looks like it?s exactly what we need. So this will be a 5.x only
> feature?

It is a v5+ feature (i.e. it is in v5 now and should be in v6, v7, etc.).

You can, of course, lobby Amos, the v4 maintainer, for making a policy
exception and officially including (a backport of) auth_schemes into v4.
Factory may even have a v4-based branch somewhere that we can resurrect
as a starting point for that backporting effort.


Cheers,

Alex.


From gabi_io at yahoo.com  Wed Oct 21 05:10:54 2020
From: gabi_io at yahoo.com (Medan Gavril)
Date: Wed, 21 Oct 2020 05:10:54 +0000 (UTC)
Subject: [squid-users] a simple digest authentication example needed
References: <71265894.1390178.1603257054812.ref@mail.yahoo.com>
Message-ID: <71265894.1390178.1603257054812@mail.yahoo.com>

Hi all,
I want to make sure my proxy(version 4.10) digest authentication is fine. I did not find an example on the online documentation and I used this as a reference.
The client is a simple java app that just connects to a page? through the proxy. I use ->Authenticator.setDefault(new Authenticator() { . Which works fine for the basic_ncsa_auth or without authentication
The error I get using the digest authentication is.:
on client side:java.net.ProtocolException: Server redirected too many? times (20) at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1908)?
I do not see any errors on proxy access .log
Can you please let me know if my config is correct and how can I test my squid proxy digest auth?
Below if my squid.conf
##### LOG ####################cache_log /var/log/squid/cache.logaccess_log /var/log/squid/access.log squidcache_store_log nonelogfile_rotate 10
## disable cachecache deny all

## Digest Authentication?auth_param digest program /usr/lib/squid/digest_file_auth? /etc/squid/passwd_digest?auth_param digest realm squiddigest#auth_param digest utf8 onauth_param digest children 20auth_param digest nonce_garbage_interval 5 minutesauth_param digest nonce_max_duration 30 minutes#auth_param digest nonce_max_count 50auth_param digest nonce_strictness off#auth_param digest check_nonce_count on

acl no_auth myport 3130acl digest_users proxy_auth REQUIRED myport 3131??## Permissions list. Do not change the order!http_access allow no_authhttp_access allow digest_usershttp_access deny all
## listening porthttp_port 3130 transparenthttp_port 3131 transparent


and content of passwd_digestsquid:squiddigest:310dc627ec8633cbbc61d9bc02608287
Thanks,

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201021/d4691c3d/attachment.htm>

From philipp.gesang at intra2net.com  Wed Oct 21 06:53:06 2020
From: philipp.gesang at intra2net.com (Philipp Gesang)
Date: Wed, 21 Oct 2020 08:53:06 +0200
Subject: [squid-users] Suppressing authentication schemes
In-Reply-To: <1d6356db-1c45-dda6-7c0b-18cec3122193@measurement-factory.com>
References: <20201020124115.GA4848@crust.m.i2n>
 <e9121a80-0b1d-8f63-7279-0d6b1221a84b@measurement-factory.com>
 <20201020144444.GB4848@crust.m.i2n>
 <1d6356db-1c45-dda6-7c0b-18cec3122193@measurement-factory.com>
Message-ID: <20201021065306.GA5207@crust.m.i2n>

On Tuesday, 2020-10-20 10:59:41 -0400 Alex Rousskov <rousskov at measurement-factory.com> wrote 
> On 10/20/20 10:44 AM, Philipp Gesang wrote:
> > On Tuesday, 2020-10-20 09:53:45 -0400 Alex Rousskov wrote 
> >>> a while back we received a report from a customer that Windows
> >>> hosts will not fall back on conventional authentication
> >>> mechanisms if Squid advertises Negotiate. That is unfortunate as
> >>> not all systems in that customer?s network are Kerberos enabled
> >>
> >> We have added the auth_schemes directive to address this and similar
> >> problems. Unfortunately, the squid.conf renderer on the official site
> >> does not include v5+ options, but you can see raw documentation at
> >> https://github.com/squid-cache/squid/blob/710f160/src/cf.data.pre#L2139
> 
> > That looks like it?s exactly what we need. So this will be a 5.x only
> > feature?
> 
> It is a v5+ feature (i.e. it is in v5 now and should be in v6, v7, etc.).

How far away in the future do you think is an official v5 release
from now? Going by the git log it?s been in the making for quite
a while.

> You can, of course, lobby Amos, the v4 maintainer, for making a policy
> exception and officially including (a backport of) auth_schemes into v4.
> Factory may even have a v4-based branch somewhere that we can resurrect
> as a starting point for that backporting effort.

As a last resort, maybe. I?d rather see that effort invested in
moving ahead with v5. ;)

Best regards,
Philipp

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201021/2a12ae0e/attachment.sig>

From squid3 at treenet.co.nz  Wed Oct 21 11:43:24 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 22 Oct 2020 00:43:24 +1300
Subject: [squid-users] Suppressing authentication schemes
In-Reply-To: <20201021065306.GA5207@crust.m.i2n>
References: <20201020124115.GA4848@crust.m.i2n>
 <e9121a80-0b1d-8f63-7279-0d6b1221a84b@measurement-factory.com>
 <20201020144444.GB4848@crust.m.i2n>
 <1d6356db-1c45-dda6-7c0b-18cec3122193@measurement-factory.com>
 <20201021065306.GA5207@crust.m.i2n>
Message-ID: <3f789563-11d0-3b39-0f4a-996cffc8856c@treenet.co.nz>

On 21/10/20 7:53 pm, Philipp Gesang wrote:
> On Tuesday, 2020-10-20 10:59:41 -0400 Alex Rousskov wrote 
>> On 10/20/20 10:44 AM, Philipp Gesang wrote:
>>> On Tuesday, 2020-10-20 09:53:45 -0400 Alex Rousskov wrote 
>>>>> a while back we received a report from a customer that Windows
>>>>> hosts will not fall back on conventional authentication
>>>>> mechanisms if Squid advertises Negotiate. That is unfortunate as
>>>>> not all systems in that customer?s network are Kerberos enabled
>>>>
>>>> We have added the auth_schemes directive to address this and similar
>>>> problems. Unfortunately, the squid.conf renderer on the official site
>>>> does not include v5+ options, but you can see raw documentation at
>>>> https://github.com/squid-cache/squid/blob/710f160/src/cf.data.pre#L2139
>>
>>> That looks like it?s exactly what we need. So this will be a 5.x only
>>> feature?
>>
>> It is a v5+ feature (i.e. it is in v5 now and should be in v6, v7, etc.).
> 
> How far away in the future do you think is an official v5 release
> from now? Going by the git log it?s been in the making for quite
> a while.

There are a few criteria. The current stage of beta release is waiting
on there being no major bugs added by Version 5:

 <https://bugs.squid-cache.org/buglist.cgi?bug_id_type=anyexact&bug_severity=blocker&bug_severity=critical&bug_severity=major&bug_status=UNCONFIRMED&bug_status=NEW&bug_status=ASSIGNED&bug_status=REOPENED&columnlist=bug_severity%2Cversion%2Cop_sys%2Cshort_desc&f1=version&list_id=7846&o1=lessthaneq&o2=equals&order=version%20DESC%2Cbug_severity%2Cbug_id&product=Squid&query_format=advanced&v1=5&v2=unspecified>

The ones with Vers saying "5" are release blockers. Older ones are
wishlist as far as release goes.

After that we need at least half a beta release cycle with no new major
bugs being found.


> 
>> You can, of course, lobby Amos, the v4 maintainer, for making a policy
>> exception and officially including (a backport of) auth_schemes into v4.
>> Factory may even have a v4-based branch somewhere that we can resurrect
>> as a starting point for that backporting effort.
> 
> As a last resort, maybe. I?d rather see that effort invested in
> moving ahead with v5. ;)
> 

All assistance welcome. Since you are going to use the auth_schemes
feature working on <https://bugs.squid-cache.org/show_bug.cgi?id=4832>
should be a good mutual RoI.


Alternatively, <https://github.com/squid-cache/squid/pull/308> is needed
by Squid but original author no longer has interest in doing the polish
to pass our QA process.


Cheers,
Amos


From christos at chtsanti.net  Wed Oct 21 16:26:57 2020
From: christos at chtsanti.net (Christos Tsantilas)
Date: Wed, 21 Oct 2020 19:26:57 +0300
Subject: [squid-users] websockets through Squid
In-Reply-To: <3f7b01cd-f71c-6fb0-27bf-74fbda532384@measurement-factory.com>
References: <1626472963.180117.1602859307164.ref@mail.yahoo.com>
 <1626472963.180117.1602859307164@mail.yahoo.com>
 <d24b2583-4959-99d2-9d22-ba3141f595cd@measurement-factory.com>
 <1798348484.217408.1602863930213@mail.yahoo.com>
 <3f7b01cd-f71c-6fb0-27bf-74fbda532384@measurement-factory.com>
Message-ID: <3d76b9ee-01b5-772c-3b79-15443ebdefa6@chtsanti.net>

Hi Vieri,

I attached a patch to bug5084 which may help us to debug the issue:
    https://bugs.squid-cache.org/attachment.cgi?id=3772

The patch is for squid-v5 and produces debug messages at debug level 1.

Regards,
    Christos




On 17/10/20 11:36 ?.?., Alex Rousskov wrote:
> On 10/16/20 11:58 AM, Vieri wrote:
> 
>> I pinpointed one particular request that's failing:
>>
>> 2020/10/16 16:56:37.250 kid1| 85,2| client_side_request.cc(745) clientAccessCheckDone: The request GET https://ed1lncb62601.webex.com/direct?type=websocket&dtype=binary&rand=1602860196950&uuidtag=G7609603-81A2-4B8D-A1C0-C379CC9B12G9&gatewayip=PUB_IPv4_ADDR_2 is ALLOWED; last ACL checked: all
>>
>> It is in this log:
>>
>> https://drive.google.com/file/d/1OrB42Cvom2PNmV-dnfLVrnMY5IhJkcpS/view?usp=sharing
> 
> Thank you, that helped a lot!
> 
> I see that Squid decides that the client has closed the connection.
> Squid propagates that connection closure to the server. Due to a Squid
> bug (or my misunderstanding), cache.log does not contain enough details
> to tell whether the client actually closed the connection in this case
> and, if it did, whether it did so nicely or due to some TLS error.
> 
> I filed bug #5084 in hope to improve handling of this case. At the very
> least, the log should categorize the closure, but it is also possible
> that the client did not actually close the connection, and Squid is
> completely mishandling the situation (in addition to being silent about
> it). See https://bugs.squid-cache.org/show_bug.cgi?id=5084 for details.
> 
> I cannot volunteer to work on this further right now, but I hope this
> triage will help another volunteer (or a paid contractor) to make
> further progress.
> 
> https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F
> 
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 


From rahul.negi at orange.com  Fri Oct 23 09:40:55 2020
From: rahul.negi at orange.com (rahul.negi at orange.com)
Date: Fri, 23 Oct 2020 09:40:55 +0000
Subject: [squid-users] Running squid inside docker container
Message-ID: <6066_1603446056_5F92A528_6066_47_4_BC8558EDF572F04D9DEAED25CCC290DB5D5F6E@OPEXCNORM51.corporate.adroot.infra.ftgroup>

Hi Team,

I am trying to run squid service inside docker container and following this page https://hub.docker.com/r/datadog/squid/

The steps which I performed are as follows:

*         docker pull datadog/squid

*          docker run --name squid -d -p 443:443 --volume /home/squid/cache:/var/spool/squid datadog/squid

After I ran above command, I am getting below error "FATAL: xcalloc: Unable to allocate 1048576 blocks of 392 bytes!"

While it's trying to create sub-directories under /var/spool/squid, then it's failing. I am using squid configuration with cache_dir ufs /var/spool/squid 100 16 256

Did anyone faced this problem before or someone can point out if I am missing some configuration or can provide the solution here.

Thanks and Regards,
Rahul Negi

_________________________________________________________________________________________________________________________

Ce message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc
pas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler
a l'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d'alteration,
Orange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.

This message and its attachments may contain confidential or privileged information that may be protected by law;
they should not be distributed, used or copied without authorisation.
If you have received this email in error, please notify the sender and delete this message and its attachments.
As emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.
Thank you.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201023/8115a0c6/attachment.htm>

From squid3 at treenet.co.nz  Fri Oct 23 12:53:17 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 24 Oct 2020 01:53:17 +1300
Subject: [squid-users] Running squid inside docker container
In-Reply-To: <6066_1603446056_5F92A528_6066_47_4_BC8558EDF572F04D9DEAED25CCC290DB5D5F6E@OPEXCNORM51.corporate.adroot.infra.ftgroup>
References: <6066_1603446056_5F92A528_6066_47_4_BC8558EDF572F04D9DEAED25CCC290DB5D5F6E@OPEXCNORM51.corporate.adroot.infra.ftgroup>
Message-ID: <6621e606-d0a9-c535-1ad5-a51ecf194b73@treenet.co.nz>

On 23/10/20 10:40 pm, rahul.negi wrote:
> 
> After I ran above command, I am getting below error ?FATAL: xcalloc: 
> Unable to allocate 1048576 blocks of 392 bytes!?
> 

There is not enough RAM available to Squid.

Check the total available on the machine, the per-process limits on the 
machine, what is being made available for use by docker images, and the 
per-process limits inside the docker container. One of those is likely 
far too small.


Amos


From ben.goz87 at gmail.com  Mon Oct 26 14:40:40 2020
From: ben.goz87 at gmail.com (Ben Goz)
Date: Mon, 26 Oct 2020 16:40:40 +0200
Subject: [squid-users] When connection closed when trying connect some urls
Message-ID: <CADAqQfytcihnoBsmxO_sMPpdWVKojOzXov64yKqRhfq_FbEM5A@mail.gmail.com>

B.H
Hi,
I saw that this question was asked several times, but I didn't get an
answer that solves the problem.

This is the squidclient prompet I get:
x at x:~$ squidclient -v https://discountbank.co.il
Request:
GET https://discountbank.co.il HTTP/1.0
Host: discountbank.co.il
User-Agent: squidclient/3.5.27
Accept: */*
Connection: close

Any help will be appreciated.
Thanks,
Ben
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201026/dde3c879/attachment.htm>

From rousskov at measurement-factory.com  Mon Oct 26 15:31:06 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Oct 2020 11:31:06 -0400
Subject: [squid-users] When connection closed when trying connect some
 urls
In-Reply-To: <CADAqQfytcihnoBsmxO_sMPpdWVKojOzXov64yKqRhfq_FbEM5A@mail.gmail.com>
References: <CADAqQfytcihnoBsmxO_sMPpdWVKojOzXov64yKqRhfq_FbEM5A@mail.gmail.com>
Message-ID: <5216ebde-39ce-be3e-c9b6-e9c6f9a2a020@measurement-factory.com>

On 10/26/20 10:40 AM, Ben Goz wrote:
> I saw that this question was asked several times, but I didn't get an
> answer that solves the problem.

> This is the squidclient prompet I get:
> x at x:~$ squidclient -v https://discountbank.co.il
> Request:
> GET https://discountbank.co.il HTTP/1.0
> Host: discountbank.co.il <http://discountbank.co.il>
> User-Agent: squidclient/3.5.27
> Accept: */*
> Connection: close

I am not sure what the actual question here is, but, AFAICT, squidclient
never submits more than one HTTP request and, hence, squidclient always
closes the connection after the first transaction.

You can control the value of the HTTP Connection header sent by
squidclient using the -k command line option. Again, regardless of that
option, squidclient will naturally close the connection after receiving
the response. My guess is that the command line option was added for
(Squid) testing purposes; it has no practical use beyond that very
limited scope.


HTH,

Alex.


From ben.goz87 at gmail.com  Mon Oct 26 15:43:26 2020
From: ben.goz87 at gmail.com (Ben Goz)
Date: Mon, 26 Oct 2020 17:43:26 +0200
Subject: [squid-users] When connection closed when trying connect some
 urls
In-Reply-To: <5216ebde-39ce-be3e-c9b6-e9c6f9a2a020@measurement-factory.com>
References: <CADAqQfytcihnoBsmxO_sMPpdWVKojOzXov64yKqRhfq_FbEM5A@mail.gmail.com>
 <5216ebde-39ce-be3e-c9b6-e9c6f9a2a020@measurement-factory.com>
Message-ID: <CADAqQfwXF-wPW_8gMoyKO7pXw4OmOk6y91MdpqtJZP91LxwGog@mail.gmail.com>

B.H
Hi Alex,
Thanks for your quick answer, the example with squidclient is not a good
example.
The real issue is that I get TCP_MISSED_ABORTED/000 and the browsers gets
timed out when connecting to
https://dicountbank.co.il.

How can i further investigate this issue and reconfig squid so it'll work.

Thanks,
Ben
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201026/880a31ef/attachment.htm>

From uhlar at fantomas.sk  Mon Oct 26 16:08:00 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 26 Oct 2020 17:08:00 +0100
Subject: [squid-users] When connection closed when trying connect some
 urls
In-Reply-To: <CADAqQfwXF-wPW_8gMoyKO7pXw4OmOk6y91MdpqtJZP91LxwGog@mail.gmail.com>
References: <CADAqQfytcihnoBsmxO_sMPpdWVKojOzXov64yKqRhfq_FbEM5A@mail.gmail.com>
 <5216ebde-39ce-be3e-c9b6-e9c6f9a2a020@measurement-factory.com>
 <CADAqQfwXF-wPW_8gMoyKO7pXw4OmOk6y91MdpqtJZP91LxwGog@mail.gmail.com>
Message-ID: <20201026160800.GA9804@fantomas.sk>

On 26.10.20 17:43, Ben Goz wrote:
>Thanks for your quick answer, the example with squidclient is not a good
>example.
>The real issue is that I get TCP_MISSED_ABORTED/000 and the browsers gets
>timed out when connecting to
>https://dicountbank.co.il.
>
>How can i further investigate this issue and reconfig squid so it'll work.

I guess squidclient can not handle https connections.

https connections are to be tunneled by squid to destination server, where
client itself will decrypt the connection. squidclient is not this kind of
client.

try wget or curl.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Atheism is a non-prophet organization.


From ben.goz87 at gmail.com  Mon Oct 26 16:18:50 2020
From: ben.goz87 at gmail.com (Ben Goz)
Date: Mon, 26 Oct 2020 18:18:50 +0200
Subject: [squid-users] When connection closed when trying connect some
 urls
In-Reply-To: <20201026160800.GA9804@fantomas.sk>
References: <CADAqQfytcihnoBsmxO_sMPpdWVKojOzXov64yKqRhfq_FbEM5A@mail.gmail.com>
 <5216ebde-39ce-be3e-c9b6-e9c6f9a2a020@measurement-factory.com>
 <CADAqQfwXF-wPW_8gMoyKO7pXw4OmOk6y91MdpqtJZP91LxwGog@mail.gmail.com>
 <20201026160800.GA9804@fantomas.sk>
Message-ID: <CADAqQfz63bAz8x1w-HN5=-GwYnamqgAsd+AwU5M_uYEoe=S0Hw@mail.gmail.com>

B.H
As I said, squidclient is not the issue here.
I'm getting TCP_MISSED_ABOTED when connecting via browser using squid as a
non transparent proxy.
Squid configured with ssl bump and I'm trying to splice this url but it's
still not working.
How can I further investigate and what squid configuration should I need to
consider in order to fix it?


??????? ??? ??, 26 ????? 2020 ?-18:08 ??? ?Matus UHLAR - fantomas?? <?
uhlar at fantomas.sk??>:?

> On 26.10.20 17:43, Ben Goz wrote:
> >Thanks for your quick answer, the example with squidclient is not a good
> >example.
> >The real issue is that I get TCP_MISSED_ABORTED/000 and the browsers gets
> >timed out when connecting to
> >https://dicountbank.co.il.
> >
> >How can i further investigate this issue and reconfig squid so it'll work.
>
> I guess squidclient can not handle https connections.
>
> https connections are to be tunneled by squid to destination server, where
> client itself will decrypt the connection. squidclient is not this kind of
> client.
>
> try wget or curl.
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> Atheism is a non-prophet organization.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201026/c370bd68/attachment.htm>

From rousskov at measurement-factory.com  Mon Oct 26 18:31:01 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Oct 2020 14:31:01 -0400
Subject: [squid-users] When connection closed when trying connect some
 urls
In-Reply-To: <CADAqQfwXF-wPW_8gMoyKO7pXw4OmOk6y91MdpqtJZP91LxwGog@mail.gmail.com>
References: <CADAqQfytcihnoBsmxO_sMPpdWVKojOzXov64yKqRhfq_FbEM5A@mail.gmail.com>
 <5216ebde-39ce-be3e-c9b6-e9c6f9a2a020@measurement-factory.com>
 <CADAqQfwXF-wPW_8gMoyKO7pXw4OmOk6y91MdpqtJZP91LxwGog@mail.gmail.com>
Message-ID: <526abe71-b35e-a625-69c9-2fef2771074c@measurement-factory.com>

On 10/26/20 11:43 AM, Ben Goz wrote:

> The real issue is that I get TCP_MISSED_ABORTED/000 and the browsers
> gets timed out when connecting to https://dicountbank.co.il.

> How can i further investigate?this issue

On the surface, it sounds like your Squid does not receive a response
from the DNS or HTTP server (fast enough), resulting in client timeouts
and TCP_MISS_ABORTED/000 access.log records.

There are several ways to find out the reason behind the timeouts. For
example, one can exclude or confirm DNS timeouts by monitoring DNS
transactions using wireshark. The easiest method for _me_ is to analyze
Squid debugging logs, but I do not recommend doing that without good
Squid code knowledge.

Can you isolate the problem to a single transaction that you can
reproduce at will, with no other traffic going through your Squid? If
yes, then you can try posting a link to a compressed cache.log with
debug_options set to ALL,9 while reproducing the problem. Hopefully,
somebody with enough Squid code knowledge will triage the problem for
you. See Squid FAQ for more details:
https://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction

Alex.


From 3m9n51s2ewut at thismonkey.com  Tue Oct 27 09:24:04 2020
From: 3m9n51s2ewut at thismonkey.com (Scott)
Date: Tue, 27 Oct 2020 20:24:04 +1100
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading - not working on IE/Chrome
Message-ID: <20201027092404.GA90645@thismonkey.com>

Hi,

I've been trying to track down why, when reverse proxying Microsoft Exchange 
OWA (Outlook Web Access), recent versions of IE and Chrome don't get past the 
logon page.  Upon entering a username and password the browser just goes back 
to the login page with no error displayed.  Firefox works fine.

It seems to be something to do with SSL offloading (when the cache peer is 
HTTP/80).  Without SSL offloading (cache peer is HTTPS/443) everything works 
as expected.

I did some debugging and noticed that the cookie sent from the server when 
SSL offloading is ON (squid <-> OWA is HTTP) is missing the "secure" 
attribute, whereas it is present when the data is HTTPS.

This makes perfect sense, and I'm wondering if that's the reason why some of 
the browsers are not working.

Given that the browser <-> Squid traffic is HTTPS, is there a way to get 
squid to add the "secure" attribute to cookies?  At least for testing it 
clarify what's going on.

Thanks,
Scott


From ngtech1ltd at gmail.com  Tue Oct 27 12:23:09 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Tue, 27 Oct 2020 14:23:09 +0200
Subject: [squid-users] SSL issue on Squid version 4 after blacklisting
In-Reply-To: <AM5PR0102MB27561AEDDBD188B422F5ACDE931F0@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
References: <AM5PR0102MB2756FB157CFBE6C65DB56EB693200@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
 <DB6PR0102MB27603E5519932014BC566B2593360@DB6PR0102MB2760.eurprd01.prod.exchangelabs.com>
 <001801d6a08c$1ad683e0$50838ba0$@gmail.com>
 <AM5PR0102MB27562AE35494A01781EB3EAC931E0@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
 <003e01d6a63b$884c6e80$98e54b80$@gmail.com>
 <AM5PR0102MB27561AEDDBD188B422F5ACDE931F0@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
Message-ID: <023b01d6ac5b$ef5f2600$ce1d7200$@gmail.com>

https://bugs.squid-cache.org/createaccount.cgi

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit <Ankit.Dixit at eurostar.com> 
Sent: Tuesday, October 20, 2020 8:02 PM
To: Eliezer Croitor <ngtech1ltd at gmail.com>
Cc: 'Squid Users' <squid-users at lists.squid-cache.org>
Subject: RE: SSL issue on Squid version 4 after blacklisting

 

Eliezer,

 

How to access Bugzilla?

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Sent: Monday, October 19, 2020 6:16 PM
To: DIXIT Ankit <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com> >
Cc: 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: RE: SSL issue on Squid version 4 after blacklisting

 




 

Hey Dixit,

 

To get a response you would need to respond in the Bugzilla.

Maybe Alex might be able to answer some of your questions about the subject.

 

All The Bests,

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com> > 
Sent: Monday, October 19, 2020 3:11 PM
To: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >
Cc: 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: RE: SSL issue on Squid version 4 after blacklisting

 

Elizer,

 

1.	I am not able to identify from below like what exactly needs to be done and in which file?

 

* Short-term: Essentially disable OpenSSL built-in certificate validation (for certificates with missing intermediate CAs) and perform that validation from Squid, using X509_verify_cert(), after SSL_connect() returns control to Squid and Squid fetches the missing CAs. This approach still requires some non-trivial Squid development and keeping an eye on OpenSSL built-in validation logic, but it can be completed without OpenSSL modifications and, IMHO, without replicating a lot of OpenSSL internal validation logic.

 

* Long-term: We need a new OpenSSL callback for pausing OpenSSL processing after TLS v1.3 server handshake is decrypted and before certificate validation starts.

 

2.	Apart from above, I want to also understand if we have below configuration in Squid version 3.5 in squid.conf then how would I replace and to what ,if we move to Squid version 4.12

 

sslproxy_cipher HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE 

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Sent: Monday, October 12, 2020 12:38 PM
To: DIXIT Ankit <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com> >
Cc: 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: RE: SSL issue on Squid version 4 after blacklisting

 




 

Hey Dixit,

 

Have you seen the next bug report:

https://bugs.squid-cache.org/show_bug.cgi?id=5067#c4

 

Alex/Amos: I assume that this specific issue deserve a DEBUG which will describe and relate to this BUG:5067 report.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com> > 
Sent: Friday, September 25, 2020 4:22 PM
To: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >; 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: RE: SSL issue on Squid version 4 after blacklisting

 

Elizer/Team,

 

Any help would be appreciated.

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: DIXIT Ankit 
Sent: Tuesday, September 15, 2020 1:24 PM
To: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >; 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: SSL issue on Squid version 4 after blacklisting

 

Subject changed

 

Elizer/Team,

 

Connecting with you again after we upgraded to Squid version 4.

 

We have blacklisted the domain categories  on Squid Proxy, but we are getting below exception in cache.log and due to this internet is not flowing from client servers via squid. 

This blacklist category is having thousands of blacklisted domains.

 

kid1| Error negotiating SSL on FD 33: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)

kid1| Error negotiating SSL connection on FD 26: (104) Connection reset by peer

 

Is there any specific ssl certificate, we need to configure? Or any other issue, you see here?

 

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: DIXIT Ankit 
Sent: Monday, July 6, 2020 8:50 AM
To: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >; 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: RE: [squid-users] Squid memory consumption problem

 

Elizer,

 

SSL was failing for few applications but was working fine for other applications. So we reverted back to old version.

I am not sure what ssl certificate dependency was there. 

 

Would be great, if you can suggest memory leak solutions in 3.12 version.

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Sent: Sunday, July 5, 2020 5:58 PM
To: DIXIT Ankit <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com> >; 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Cc: SETHI Konica <Konica.Sethi at eurostar.com <mailto:Konica.Sethi at eurostar.com> >
Subject: RE: [squid-users] Squid memory consumption problem

 




 

Hey,

 

What happen with this issue?

I am waiting for any input about this issue to understand with what I can try to help.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit [mailto:Ankit.Dixit at eurostar.com] 
Sent: Tuesday, June 30, 2020 12:35 PM
To: Eliezer Croitoru; Squid Users
Cc: SETHI Konica
Subject: RE: [squid-users] Squid memory consumption problem

 

For your information, we have added below configurations but again same issue.

 

tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

 

tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: DIXIT Ankit 
Sent: Tuesday, June 30, 2020 10:25 AM
To: Eliezer Croitoru <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >; Squid Users <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Cc: SETHI Konica <Konica.Sethi at eurostar.com <mailto:Konica.Sethi at eurostar.com> >
Subject: RE: [squid-users] Squid memory consumption problem

 

Eliezer,

 

Clients are facing some SSL related issues after upgrade. I could see below error. Please suggest, its little urgent.

 

quid[6706]: Error negotiating SSL connection on FD 167: error:00000001:lib(0):func(0):reason(1) (1/0)
Jun 30 09:17:38 squid[6706]: Error parsing SSL Server Hello Message on FD 77
Jun 30 09:17:38 squid[6706]: Error negotiating SSL connection on FD 75: error:00000001:lib(0):func(0):reason(1) (1/0)

 

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: Eliezer Croitoru <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Sent: Tuesday, June 30, 2020 9:10 AM
To: Squid Users <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >; DIXIT Ankit <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com> >
Subject: RE: [squid-users] Squid memory consumption problem

 




 

The first thing to do is look at:

https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery

 

It should clear couple doubts for you.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit <mailto:Ankit.Dixit at eurostar.com> 
Sent: Tuesday, June 30, 2020 10:46 AM
To: Eliezer Croitoru <mailto:ngtech1ltd at gmail.com> ; Alex Rousskov <mailto:rousskov at measurement-factory.com> ; squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Subject: RE: [squid-users] Squid memory consumption problem

 

Elizer,

 

We installed Squid 4.12 on production server, amazon Linux 2, successfully but I could see below messages in the logs for SECURITY ALERT: Host header forgery detected. These are getting generated very frequently.

Can we ignore this Or is it advised to suppress these alerts?

 

kid2| SECURITY ALERT: on URL: 5-25-3-app.agent.datadoghq.com:443 <http://5-25-3-app.agent.datadoghq.com:443> 

2020/06/30 07:41:29 kid1| SECURITY ALERT: Host header forgery detected on local=IP remote=IP FD 97 flags=33 (local IP does not match any domain IP)

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

 

  _____  

This email (including any attachments) is intended only for the addressee(s), is confidential and may be legally privileged. If you are not the intended recipient, do not use, disclose, copy, or forward this email. Please notify the sender immediately and then delete it. Eurostar International Limited and its affiliates ("EIL") do not accept any liability for action taken in reliance on this email. EIL makes no representation that this email is free of viruses and addressees should check this email for viruses. The comments or statements expressed in this email are not necessarily those of EIL. 

Eurostar International Ltd 
Times House, Bravingtons Walk, London N1 9AW Registered in England and Wales No. 2462001 

  _____  

 

 

  _____  

This email (including any attachments) is intended only for the addressee(s), is confidential and may be legally privileged. If you are not the intended recipient, do not use, disclose, copy, or forward this email. Please notify the sender immediately and then delete it. Eurostar International Limited and its affiliates ("EIL") do not accept any liability for action taken in reliance on this email. EIL makes no representation that this email is free of viruses and addressees should check this email for viruses. The comments or statements expressed in this email are not necessarily those of EIL. 

Eurostar International Ltd 
Times House, Bravingtons Walk, London N1 9AW Registered in England and Wales No. 2462001 

  _____  

 

 

  _____  

This email (including any attachments) is intended only for the addressee(s), is confidential and may be legally privileged. If you are not the intended recipient, do not use, disclose, copy, or forward this email. Please notify the sender immediately and then delete it. Eurostar International Limited and its affiliates ("EIL") do not accept any liability for action taken in reliance on this email. EIL makes no representation that this email is free of viruses and addressees should check this email for viruses. The comments or statements expressed in this email are not necessarily those of EIL. 

Eurostar International Ltd 
Times House, Bravingtons Walk, London N1 9AW Registered in England and Wales No. 2462001 

  _____  

 

 

  _____  

This email (including any attachments) is intended only for the addressee(s), is confidential and may be legally privileged. If you are not the intended recipient, do not use, disclose, copy, or forward this email. Please notify the sender immediately and then delete it. Eurostar International Limited and its affiliates ("EIL") do not accept any liability for action taken in reliance on this email. EIL makes no representation that this email is free of viruses and addressees should check this email for viruses. The comments or statements expressed in this email are not necessarily those of EIL. 

Eurostar International Ltd 
Times House, Bravingtons Walk, London N1 9AW Registered in England and Wales No. 2462001 

  _____  

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201027/000e1306/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.jpg
Type: image/jpeg
Size: 19517 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201027/000e1306/attachment.jpg>

From rousskov at measurement-factory.com  Tue Oct 27 14:40:41 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 27 Oct 2020 10:40:41 -0400
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading - not working on IE/Chrome
In-Reply-To: <20201027092404.GA90645@thismonkey.com>
References: <20201027092404.GA90645@thismonkey.com>
Message-ID: <e6b5b5e3-a4a1-a66a-c99e-ba9e5f27e95c@measurement-factory.com>

On 10/27/20 5:24 AM, Scott wrote:

> Given that the browser <-> Squid traffic is HTTPS, is there a way to get 
> squid to add the "secure" attribute to cookies?  At least for testing it 
> clarify what's going on.

If Squid sees decrypted/plain HTTP messages, then it is possible to
adapt HTTP response headers. The following page has a good introduction:
https://wiki.squid-cache.org/SquidFaq/ContentAdaptation

* Custom eCAP or ICAP services can definitely do that.

* In some cases, it is also possible to adapt headers using squid.conf
directives like reply_header_replace , but those features may not have
enough support to add a Cookie attribute. If they do not, perhaps that
is something we can improve, but I did not investigate the details.

* Just for _testing_ your hypothesis, temporary hacking Squid code to
add the desired attribute may be the best solution.


HTH,

Alex.


From ngtech1ltd at gmail.com  Tue Oct 27 19:30:16 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Tue, 27 Oct 2020 21:30:16 +0200
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading - not working on IE/Chrome
In-Reply-To: <20201027092404.GA90645@thismonkey.com>
References: <20201027092404.GA90645@thismonkey.com>
Message-ID: <00af01d6ac97$99cfa610$cd6ef230$@gmail.com>

Hey Scott,

Can you attach any example cookie with and without the secure value?
(replace sensitive data)

Thanks,
Eliezer

----
Eliezer Croitoru
Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Scott
Sent: Tuesday, October 27, 2020 11:24 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL offloading - not working on IE/Chrome

Hi,

I've been trying to track down why, when reverse proxying Microsoft Exchange OWA (Outlook Web Access), recent versions of IE and Chrome don't get past the logon page.  Upon entering a username and password the browser just goes back to the login page with no error displayed.  Firefox works fine.

It seems to be something to do with SSL offloading (when the cache peer is HTTP/80).  Without SSL offloading (cache peer is HTTPS/443) everything works as expected.

I did some debugging and noticed that the cookie sent from the server when SSL offloading is ON (squid <-> OWA is HTTP) is missing the "secure" 
attribute, whereas it is present when the data is HTTPS.

This makes perfect sense, and I'm wondering if that's the reason why some of the browsers are not working.

Given that the browser <-> Squid traffic is HTTPS, is there a way to get squid to add the "secure" attribute to cookies?  At least for testing it clarify what's going on.

Thanks,
Scott
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From 3m9n51s2ewut at thismonkey.com  Wed Oct 28 04:25:25 2020
From: 3m9n51s2ewut at thismonkey.com (Scott)
Date: Wed, 28 Oct 2020 15:25:25 +1100
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading - not working on IE/Chrome
In-Reply-To: <00af01d6ac97$99cfa610$cd6ef230$@gmail.com>
References: <20201027092404.GA90645@thismonkey.com>
 <00af01d6ac97$99cfa610$cd6ef230$@gmail.com>
Message-ID: <20201028042524.GA7104@thismonkey.com>

On Tue, Oct 27, 2020 at 09:30:16PM +0200, Eliezer Croitor wrote:
> Hey Scott,
> 
> Can you attach any example cookie with and without the secure value?
> (replace sensitive data)
> 
> Thanks,
> Eliezer
> 
> ----
> Eliezer Croitoru
> Tech Support
> Mobile: +972-5-28704261
> Email: ngtech1ltd at gmail.com
> 
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Scott
> Sent: Tuesday, October 27, 2020 11:24 AM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL offloading - not working on IE/Chrome
> 
> Hi,
> 
> I've been trying to track down why, when reverse proxying Microsoft Exchange OWA (Outlook Web Access), recent versions of IE and Chrome don't get past the logon page.  Upon entering a username and password the browser just goes back to the login page with no error displayed.  Firefox works fine.
> 
> It seems to be something to do with SSL offloading (when the cache peer is HTTP/80).  Without SSL offloading (cache peer is HTTPS/443) everything works as expected.
> 
> I did some debugging and noticed that the cookie sent from the server when SSL offloading is ON (squid <-> OWA is HTTP) is missing the "secure" 
> attribute, whereas it is present when the data is HTTPS.
> 
> This makes perfect sense, and I'm wondering if that's the reason why some of the browsers are not working.
> 
> Given that the browser <-> Squid traffic is HTTPS, is there a way to get squid to add the "secure" attribute to cookies?  At least for testing it clarify what's going on.
> 
> Thanks,
> Scott
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 
>

Here are the logs (first not working, followed by working).

Note this is the login attempt, not the loading of the initial page.  You'll 
see in the NOT WORKING section that the browser does NOT return a cookie to 
the server, which is where the problem may be.  Again, I'm not sure why - I'm 
thinking perhaps the browser/javascript is rejecting the cookie as it's 
missing the "secure" attribute (because the back-end is talking plain HTTP).

As mentioned above Firefox has no issue with this.  I've fired up an iCAP 
server but need to brush up on my Python before I can test what happens if I 
add the "secure" attribute.

My cache peers are:
cache_peer exchange.domain.com parent  80 0 proxy-only no-query no-digest front-end-https originserver login=PASSTHRU connection-auth=on connect-timeout=3600 name=peer_exchange_80
cache_peer exchange.domain.com parent 443 0 proxy-only no-query no-digest front-end-https originserver login=PASSTHRU connection-auth=on connect-timeout=3600 ssl sslflags=DONT_VERIFY_PEER name=peer_exchange_443

Logs:

NOT WORKING

---------
2020/10/28 14:56:12.614 kid1| 11,2| client_side.cc(1306) parseHttpRequest: HTTP Client local=squid-external:443 remote=client-browser:22884 FD 19 flags=1
2020/10/28 14:56:12.614 kid1| 11,2| client_side.cc(1310) parseHttpRequest: HTTP Client REQUEST:
---------
POST /owa/auth.owa HTTP/1.1
Host: webmail.domain.com
Connection: keep-alive
Content-Length: 140
Cache-Control: max-age=0
Upgrade-Insecure-Requests: 1
Origin: https://webmail.domain.com
Content-Type: application/x-www-form-urlencoded
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36 Edg/86.0.622.51
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: navigate
Sec-Fetch-User: ?1
Sec-Fetch-Dest: document
Referer: https://webmail.domain.com/owa/auth/logon.aspx?replaceCurrent=1&url=https%3a%2f%2fwebmail.domain.com%2fowa
Accept-Encoding: gzip, deflate, br
Accept-Language: en-GB,en;q=0.9,en-US;q=0.8
Cookie: sm_spd_caution=0LCGM6rKJqGWF; PrivateComputer=true; PBack=0


----------
2020/10/28 14:56:12.627 kid1| 11,2| http.cc(2263) sendRequest: HTTP Server local=squid-internal:42139 remote=exchange:80 FD 17 flags=1
2020/10/28 14:56:12.628 kid1| 11,2| http.cc(2264) sendRequest: HTTP Server REQUEST:
---------
POST /owa/auth.owa HTTP/1.1
Content-Length: 140
Upgrade-Insecure-Requests: 1
Origin: https://webmail.domain.com
Content-Type: application/x-www-form-urlencoded
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36 Edg/86.0.622.51
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: navigate
Sec-Fetch-User: ?1
Sec-Fetch-Dest: document
Referer: https://webmail.domain.com/owa/auth/logon.aspx?replaceCurrent=1&url=https%3a%2f%2fwebmail.domain.com%2fowa
Accept-Language: en-GB,en;q=0.9,en-US;q=0.8
Cookie: sm_spd_caution=0LCGM6rKJqGWF; PrivateComputer=true; PBack=0
Host: webmail.domain.com
Surrogate-Capability: webmail.domain.com="Surrogate/1.0"
X-Forwarded-For: client-browser
Cache-Control: max-age=0
Connection: keep-alive
Front-End-Https: On


----------
2020/10/28 14:56:12.748 kid1| ctx: enter level  0: 'https://webmail.domain.com/owa/auth.owa'
2020/10/28 14:56:12.748 kid1| 11,2| http.cc(719) processReplyHeader: HTTP Server local=squid-internal:42139 remote=exchange:80 FD 17 flags=1
2020/10/28 14:56:12.748 kid1| 11,2| http.cc(723) processReplyHeader: HTTP Server RESPONSE:
---------
HTTP/1.1 302 Found
Cache-Control: private
Content-Type: text/html; charset=utf-8
Location: https://webmail.domain.com/owa
Server: Microsoft-IIS/8.5
request-id: 85e28b7c-5a4c-4e89-a740-116359551a19
X-AspNet-Version: 4.0.30319
Set-Cookie: cadata=<data>; path=/;SameSite=None; HttpOnly
Set-Cookie: cadataTTL=<data>; path=/;SameSite=None; HttpOnly
Set-Cookie: cadataKey=<data>; path=/;SameSite=None; HttpOnly
Set-Cookie: cadataIV=<data>; path=/;SameSite=None; HttpOnly
Set-Cookie: cadataSig=<data>; path=/;SameSite=None; HttpOnly
X-Powered-By: ASP.NET
X-FEServer: exchange
Date: Wed, 28 Oct 2020 03:56:17 GMT
Content-Length: 151

----------
2020/10/28 14:56:12.748 kid1| ctx: exit level  0
2020/10/28 14:56:12.748 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP Client local=squid-external:443 remote=client-browser:22884 FD 19 flags=1
2020/10/28 14:56:12.748 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 302 Found
Cache-Control: private
Content-Type: text/html; charset=utf-8
Location: https://webmail.domain.com/owa
Server: Microsoft-IIS/8.5
request-id: 85e28b7c-5a4c-4e89-a740-116359551a19
X-AspNet-Version: 4.0.30319
Set-Cookie: cadata=<data>; path=/;SameSite=None; HttpOnly
Set-Cookie: cadataTTL=<data>; path=/;SameSite=None; HttpOnly
Set-Cookie: cadataKey=<data>; path=/;SameSite=None; HttpOnly
Set-Cookie: cadataIV=<data>; path=/;SameSite=None; HttpOnly
Set-Cookie: cadataSig=<data>; path=/;SameSite=None; HttpOnly
X-Powered-By: ASP.NET
X-FEServer: exchange
Date: Wed, 28 Oct 2020 03:56:17 GMT
Content-Length: 151
X-Cache: MISS from webmail.domain.com
X-Cache-Lookup: MISS from webmail.domain.com:443
Connection: keep-alive


----------
2020/10/28 14:56:12.838 kid1| 11,2| client_side.cc(1306) parseHttpRequest: HTTP Client local=squid-external:443 remote=client-browser:22884 FD 19 flags=1
2020/10/28 14:56:12.838 kid1| 11,2| client_side.cc(1310) parseHttpRequest: HTTP Client REQUEST:
---------
GET /owa HTTP/1.1
Host: webmail.domain.com
Connection: keep-alive
Cache-Control: max-age=0
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36 Edg/86.0.622.51
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: navigate 
Sec-Fetch-User: ?1
Sec-Fetch-Dest: document
Referer: https://webmail.domain.com/owa/auth/logon.aspx?replaceCurrent=1&url=https%3a%2f%2fwebmail.domain.com%2fowa
Accept-Encoding: gzip, deflate, br
Accept-Language: en-GB,en;q=0.9,en-US;q=0.8
Cookie: sm_spd_caution=0LCGM6rKJqGWF; PrivateComputer=true; PBack=0


----------
2020/10/28 14:56:12.838 kid1| 11,2| http.cc(2263) sendRequest: HTTP Server local=squid-internal:42139 remote=exchange:80 FD 17 flags=1
2020/10/28 14:56:12.838 kid1| 11,2| http.cc(2264) sendRequest: HTTP Server REQUEST:
---------
GET /owa HTTP/1.1
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36 Edg/86.0.622.51
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: navigate
Sec-Fetch-User: ?1
Sec-Fetch-Dest: document
Referer: https://webmail.domain.com/owa/auth/logon.aspx?replaceCurrent=1&url=https%3a%2f%2fwebmail.domain.com%2fowa
Accept-Language: en-GB,en;q=0.9,en-US;q=0.8
Cookie: sm_spd_caution=0LCGM6rKJqGWF; PrivateComputer=true; PBack=0
Host: webmail.domain.com
Surrogate-Capability: webmail.domain.com="Surrogate/1.0"
X-Forwarded-For: client-browser
Cache-Control: max-age=0
Connection: keep-alive
Front-End-Https: On


----------
2020/10/28 14:56:12.847 kid1| ctx: enter level  0: 'https://webmail.domain.com/owa'
2020/10/28 14:56:12.847 kid1| 11,2| http.cc(719) processReplyHeader: HTTP Server local=squid-internal:42139 remote=exchange:80 FD 17 flags=1
2020/10/28 14:56:12.847 kid1| 11,2| http.cc(723) processReplyHeader: HTTP Server RESPONSE:
---------
HTTP/1.1 302 Found
Content-Type: text/html; charset=utf-8
Location: https://webmail.domain.com/owa/auth/logon.aspx?url=https%3a%2f%2fwebmail.domain.com%2fowa&reason=0
Server: Microsoft-IIS/8.5
request-id: 8c3318c8-2eee-40bf-bfe0-dd94b20a5197
X-Powered-By: ASP.NET
X-FEServer: exchange
Date: Wed, 28 Oct 2020 03:56:17 GMT
Content-Length: 227

----------
2020/10/28 14:56:12.848 kid1| ctx: exit level  0
2020/10/28 14:56:12.848 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP Client local=squid-external:443 remote=client-browser:22884 FD 19 flags=1
2020/10/28 14:56:12.848 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 302 Found
Content-Type: text/html; charset=utf-8
Location: https://webmail.domain.com/owa/auth/logon.aspx?url=https%3a%2f%2fwebmail.domain.com%2fowa&reason=0
Server: Microsoft-IIS/8.5
request-id: 8c3318c8-2eee-40bf-bfe0-dd94b20a5197
X-Powered-By: ASP.NET
X-FEServer: exchange
Date: Wed, 28 Oct 2020 03:56:17 GMT
Content-Length: 227  
X-Cache: MISS from webmail.domain.com
X-Cache-Lookup: MISS from webmail.domain.com:443
Connection: keep-alive


----------
2020/10/28 14:56:12.861 kid1| 11,2| client_side.cc(1306) parseHttpRequest: HTTP Client local=squid-external:443 remote=client-browser:22884 FD 19 flags=1
2020/10/28 14:56:12.861 kid1| 11,2| client_side.cc(1310) parseHttpRequest: HTTP Client REQUEST:
---------
GET /owa/auth/logon.aspx?url=https%3a%2f%2fwebmail.domain.com%2fowa&reason=0 HTTP/1.1
Host: webmail.domain.com
Connection: keep-alive
Cache-Control: max-age=0
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36 Edg/86.0.622.51
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: navigate
Sec-Fetch-User: ?1
Sec-Fetch-Dest: document
Referer: https://webmail.domain.com/owa/auth/logon.aspx?replaceCurrent=1&url=https%3a%2f%2fwebmail.domain.com%2fowa
Accept-Encoding: gzip, deflate, br
Accept-Language: en-GB,en;q=0.9,en-US;q=0.8
Cookie: cookieTest=1; logondata=acc=0&lgn=user; sm_spd_caution=0LCGM6rKJqGWF; PrivateComputer=true; PBack=0


----------
2020/10/28 14:56:12.862 kid1| 11,2| http.cc(2263) sendRequest: HTTP Server local=squid-internal:42139 remote=exchange:80 FD 17 flags=1
2020/10/28 14:56:12.862 kid1| 11,2| http.cc(2264) sendRequest: HTTP Server REQUEST:
---------
GET /owa/auth/logon.aspx?url=https%3a%2f%2fwebmail.domain.com%2fowa&reason=0 HTTP/1.1
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36 Edg/86.0.622.51
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: navigate
Sec-Fetch-User: ?1
Sec-Fetch-Dest: document
Referer: https://webmail.domain.com/owa/auth/logon.aspx?replaceCurrent=1&url=https%3a%2f%2fwebmail.domain.com%2fowa
Accept-Language: en-GB,en;q=0.9,en-US;q=0.8
Cookie: cookieTest=1; logondata=acc=0&lgn=user; sm_spd_caution=0LCGM6rKJqGWF; PrivateComputer=true; PBack=0
Host: webmail.domain.com
Surrogate-Capability: webmail.domain.com="Surrogate/1.0"
X-Forwarded-For: client-browser
Cache-Control: max-age=0
Connection: keep-alive
Front-End-Https: On


----------
2020/10/28 14:56:12.873 kid1| ctx: enter level  0: 'https://webmail.domain.com/owa/auth/logon.aspx?url=https%3a%2f%2fwebmail.domain.com%2fowa&reason=0'
2020/10/28 14:56:12.873 kid1| 11,2| http.cc(719) processReplyHeader: HTTP Server local=squid-internal:42139 remote=exchange:80 FD 17 flags=1
2020/10/28 14:56:12.874 kid1| 11,2| http.cc(723) processReplyHeader: HTTP Server RESPONSE:
---------
HTTP/1.1 200 OK
Cache-Control: no-cache, no-store
Pragma: no-cache
Content-Type: text/html; charset=utf-8
Expires: -1
Server: Microsoft-IIS/8.5
request-id: 076d002d-4d66-4bc7-93d2-0109bbb67892
X-Frame-Options: SAMEORIGIN
X-AspNet-Version: 4.0.30319
X-Powered-By: ASP.NET
Date: Wed, 28 Oct 2020 03:56:17 GMT
Content-Length: 27968

----------
2020/10/28 14:56:12.874 kid1| ctx: exit level  0
2020/10/28 14:56:12.874 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP Client local=squid-external:443 remote=client-browser:22884 FD 19 flags=1
2020/10/28 14:56:12.874 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 200 OK
Cache-Control: no-cache, no-store
Pragma: no-cache
Content-Type: text/html; charset=utf-8
Expires: -1
Server: Microsoft-IIS/8.5
request-id: 076d002d-4d66-4bc7-93d2-0109bbb67892
X-Frame-Options: SAMEORIGIN
X-AspNet-Version: 4.0.30319
X-Powered-By: ASP.NET
Date: Wed, 28 Oct 2020 03:56:17 GMT
Content-Length: 27968
X-Cache: MISS from webmail.domain.com
X-Cache-Lookup: MISS from webmail.domain.com:443
Connection: keep-alive


----------
2020/10/28 14:56:12.943 kid1| 11,2| client_side.cc(1306) parseHttpRequest: HTTP Client local=squid-external:443 remote=client-browser:22884 FD 19 flags=1
2020/10/28 14:56:12.943 kid1| 11,2| client_side.cc(1310) parseHttpRequest: HTTP Client REQUEST:
---------
GET /owa/auth/logon.aspx?replaceCurrent=1&url=https%3a%2f%2fwebmail.domain.com%2fowa HTTP/1.1
Host: webmail.domain.com
Connection: keep-alive
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36 Edg/86.0.622.51
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: navigate
Sec-Fetch-Dest: document
Referer: https://webmail.domain.com/owa/auth/logon.aspx?url=https%3a%2f%2fwebmail.domain.com%2fowa&reason=0
Accept-Encoding: gzip, deflate, br
Accept-Language: en-GB,en;q=0.9,en-US;q=0.8
Cookie: cookieTest=1; logondata=acc=0&lgn=user; sm_spd_caution=0LCGM6rKJqGWF; PrivateComputer=true; PBack=0


----------
2020/10/28 14:56:12.944 kid1| 11,2| http.cc(2263) sendRequest: HTTP Server local=squid-internal:42139 remote=exchange:80 FD 17 flags=1
2020/10/28 14:56:12.944 kid1| 11,2| http.cc(2264) sendRequest: HTTP Server REQUEST:
---------
GET /owa/auth/logon.aspx?replaceCurrent=1&url=https%3a%2f%2fwebmail.domain.com%2fowa HTTP/1.1
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36 Edg/86.0.622.51
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: navigate
Sec-Fetch-Dest: document
Referer: https://webmail.domain.com/owa/auth/logon.aspx?url=https%3a%2f%2fwebmail.domain.com%2fowa&reason=0
Accept-Language: en-GB,en;q=0.9,en-US;q=0.8
Cookie: cookieTest=1; logondata=acc=0&lgn=user; sm_spd_caution=0LCGM6rKJqGWF; PrivateComputer=true; PBack=0
Host: webmail.domain.com
Surrogate-Capability: webmail.domain.com="Surrogate/1.0"
X-Forwarded-For: client-browser
Cache-Control: max-age=259200
Connection: keep-alive
Front-End-Https: On


----------
2020/10/28 14:56:12.955 kid1| ctx: enter level  0: 'https://webmail.domain.com/owa/auth/logon.aspx?replaceCurrent=1&url=https%3a%2f%2fwebmail.domain.com%2fowa'
2020/10/28 14:56:12.955 kid1| 11,2| http.cc(719) processReplyHeader: HTTP Server local=squid-internal:42139 remote=exchange:80 FD 17 flags=1
2020/10/28 14:56:12.955 kid1| 11,2| http.cc(723) processReplyHeader: HTTP Server RESPONSE:
---------
HTTP/1.1 200 OK
Cache-Control: no-cache, no-store
Pragma: no-cache
Content-Type: text/html; charset=utf-8
Expires: -1
Server: Microsoft-IIS/8.5
request-id: 5b1807dd-0007-4d1e-8f5c-c6daf4d9dfa8
X-Frame-Options: SAMEORIGIN
X-AspNet-Version: 4.0.30319
X-Powered-By: ASP.NET
Date: Wed, 28 Oct 2020 03:56:17 GMT
Content-Length: 58778

----------
2020/10/28 14:56:12.955 kid1| ctx: exit level  0
2020/10/28 14:56:12.956 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP Client local=squid-external:443 remote=client-browser:22884 FD 19 flags=1
2020/10/28 14:56:12.956 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 200 OK
Cache-Control: no-cache, no-store
Pragma: no-cache
Content-Type: text/html; charset=utf-8
Expires: -1
Server: Microsoft-IIS/8.5
request-id: 5b1807dd-0007-4d1e-8f5c-c6daf4d9dfa8
X-Frame-Options: SAMEORIGIN
X-AspNet-Version: 4.0.30319
X-Powered-By: ASP.NET
Date: Wed, 28 Oct 2020 03:56:17 GMT
Content-Length: 58778
X-Cache: MISS from webmail.domain.com
X-Cache-Lookup: MISS from webmail.domain.com:443
Connection: keep-alive



WORKING

----------
2020/10/28 12:01:23.527 kid1| 11,2| client_side.cc(1306) parseHttpRequest: HTTP Client local=squid-external:443 remote=client-browser:2600 FD 24 flags=1
2020/10/28 12:01:23.527 kid1| 11,2| client_side.cc(1310) parseHttpRequest: HTTP Client REQUEST:
---------
POST /owa/auth.owa HTTP/1.1
Host: webmail.domain.com
Connection: keep-alive
Content-Length: 143
Cache-Control: max-age=0
Upgrade-Insecure-Requests: 1
Origin: https://webmail.domain.com
Content-Type: application/x-www-form-urlencoded
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36 Edg/86.0.622.51
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: navigate
Sec-Fetch-User: ?1
Sec-Fetch-Dest: document
Referer: https://webmail.domain.com/owa/auth/logon.aspx?replaceCurrent=1&url=https%3a%2f%2fwebmail.domain.com%2fowa%2f
Accept-Encoding: gzip, deflate, br
Accept-Language: en-GB,en;q=0.9,en-US;q=0.8
Cookie: sm_spd_caution=qPZGM6JTJHMDM; PrivateComputer=true; PBack=0

----------
2020/10/28 12:01:23.549 kid1| 11,2| http.cc(2263) sendRequest: HTTP Server local=squid-internal:62597 remote=exchange:443 FD 30 flags=1
2020/10/28 12:01:23.549 kid1| 11,2| http.cc(2264) sendRequest: HTTP Server REQUEST:
---------
POST /owa/auth.owa HTTP/1.1
Content-Length: 143
Upgrade-Insecure-Requests: 1
Origin: https://webmail.domain.com
Content-Type: application/x-www-form-urlencoded
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36 Edg/86.0.622.51
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: navigate
Sec-Fetch-User: ?1
Sec-Fetch-Dest: document
Referer: https://webmail.domain.com/owa/auth/logon.aspx?replaceCurrent=1&url=https%3a%2f%2fwebmail.domain.com%2fowa%2f
Accept-Language: en-GB,en;q=0.9,en-US;q=0.8
Cookie: sm_spd_caution=qPZGM6JTJHMDM; PrivateComputer=true; PBack=0
Host: webmail.domain.com
Surrogate-Capability: webmail.domain.com="Surrogate/1.0"
X-Forwarded-For: client-browser
Cache-Control: max-age=0
Connection: keep-alive
Front-End-Https: On

----------
2020/10/28 12:01:23.649 kid1| ctx: enter level  0: 'https://webmail.domain.com/owa/auth.owa'
2020/10/28 12:01:23.649 kid1| 11,2| http.cc(719) processReplyHeader: HTTP Server local=squid-internal:62597 remote=exchange:443 FD 30 flags=1
2020/10/28 12:01:23.650 kid1| 11,2| http.cc(723) processReplyHeader: HTTP Server RESPONSE:
---------
HTTP/1.1 302 Found
Cache-Control: private
Content-Type: text/html; charset=utf-8
Location: https://webmail.domain.com/owa/
Server: Microsoft-IIS/8.5
request-id: 320cfc6b-e678-480e-8fa9-87126ee679d4
X-AspNet-Version: 4.0.30319
Set-Cookie: cadata=<data>; path=/;SameSite=None; secure; HttpOnly
Set-Cookie: cadataTTL=<data>; path=/;SameSite=None; secure; HttpOnly
Set-Cookie: cadataKey=<data>; path=/;SameSite=None; secure; HttpOnly
Set-Cookie: cadataIV=<data>; path=/;SameSite=None; secure; HttpOnly
Set-Cookie: cadataSig=<data>; path=/;SameSite=None; secure; HttpOnly
X-Powered-By: ASP.NET
X-FEServer: exchange
Date: Wed, 28 Oct 2020 01:01:28 GMT
Content-Length: 152

----------
2020/10/28 12:01:23.651 kid1| ctx: exit level  0
2020/10/28 12:01:23.651 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP Client local=squid-external:443 remote=client-browser:2600 FD 24 flags=1
2020/10/28 12:01:23.651 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 302 Found
Cache-Control: private
Content-Type: text/html; charset=utf-8
Location: https://webmail.domain.com/owa/
Server: Microsoft-IIS/8.5
request-id: 320cfc6b-e678-480e-8fa9-87126ee679d4
X-AspNet-Version: 4.0.30319
Set-Cookie: cadata=<data>; path=/;SameSite=None; secure; HttpOnly
Set-Cookie: cadataTTL=<data>; path=/;SameSite=None; secure; HttpOnly
Set-Cookie: cadataKey=<data>; path=/;SameSite=None; secure; HttpOnly
Set-Cookie: cadataIV=<data>; path=/;SameSite=None; secure; HttpOnly
Set-Cookie: cadataSig=<data>; path=/;SameSite=None; secure; HttpOnly
X-Powered-By: ASP.NET
X-FEServer: exchange
Date: Wed, 28 Oct 2020 01:01:28 GMT
Content-Length: 152
X-Cache: MISS from webmail.domain.com
X-Cache-Lookup: MISS from webmail.domain.com:443
Connection: keep-alive

----------
2020/10/28 12:01:23.750 kid1| 11,2| client_side.cc(1306) parseHttpRequest: HTTP Client local=squid-external:443 remote=client-browser:2600 FD 24 flags=1
2020/10/28 12:01:23.750 kid1| 11,2| client_side.cc(1310) parseHttpRequest: HTTP Client REQUEST:
---------
GET /owa/ HTTP/1.1
Host: webmail.domain.com
Connection: keep-alive
Cache-Control: max-age=0
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36 Edg/86.0.622.51
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: navigate
Sec-Fetch-User: ?1
Sec-Fetch-Dest: document
Referer: https://webmail.domain.com/owa/auth/logon.aspx?replaceCurrent=1&url=https%3a%2f%2fwebmail.domain.com%2fowa%2f
Accept-Encoding: gzip, deflate, br
Accept-Language: en-GB,en;q=0.9,en-US;q=0.8
Cookie: sm_spd_caution=qPZGM6JTJHMDM; PrivateComputer=true; PBack=0; cadata=<data>; cadataTTL=<data>; cadataKey=<data>; cadataIV=<data>; cadataSig=<data>

----------
2020/10/28 12:01:23.751 kid1| 11,2| http.cc(2263) sendRequest: HTTP Server local=squid-internal:62597 remote=exchange:443 FD 30 flags=1
2020/10/28 12:01:23.751 kid1| 11,2| http.cc(2264) sendRequest: HTTP Server REQUEST:
---------
GET /owa/ HTTP/1.1
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36 Edg/86.0.622.51
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: navigate
Sec-Fetch-User: ?1
Sec-Fetch-Dest: document
Referer: https://webmail.domain.com/owa/auth/logon.aspx?replaceCurrent=1&url=https%3a%2f%2fwebmail.domain.com%2fowa%2f
Accept-Language: en-GB,en;q=0.9,en-US;q=0.8
Cookie: sm_spd_caution=qPZGM6JTJHMDM; PrivateComputer=true; PBack=0; cadata=<data>; cadataTTL=<data>; cadataKey=<data>; cadataIV=<data>; cadataSig=<data>
Host: webmail.domain.com
Surrogate-Capability: webmail.domain.com="Surrogate/1.0"
X-Forwarded-For: client-browser
Cache-Control: max-age=0
Connection: keep-alive
Front-End-Https: On

----------
2020/10/28 12:01:23.896 kid1| ctx: enter level  0: 'https://webmail.domain.com/owa/'
2020/10/28 12:01:23.896 kid1| 11,2| http.cc(719) processReplyHeader: HTTP Server local=squid-internal:62597 remote=exchange:443 FD 30 flags=1
2020/10/28 12:01:23.896 kid1| 11,2| http.cc(723) processReplyHeader: HTTP Server RESPONSE:
---------
HTTP/1.1 200 OK
Cache-Control: no-cache
Pragma: no-cache
Transfer-Encoding: chunked
Content-Type: text/html; charset=utf-8
Expires: -1
Server: Microsoft-IIS/8.5
request-id: ea651da4-e232-4990-995e-72e015c573fb
X-CalculatedBETarget: exchange.domain.com
X-Content-Type-Options: nosniff
X-OWA-Version: 15.1.1979.3
X-OWA-OWSVersion: V2017_08_18
X-OWA-MinimumSupportedOWSVersion: V2_6
X-Frame-Options: SAMEORIGIN
X-OWA-DiagnosticsInfo: 46;15;7
X-BackEnd-Begin: 2020-10-28T12:01:28.905
X-BackEnd-End: 2020-10-28T12:01:28.952
X-DiagInfo: exchange
X-BEServer: exchange
X-UA-Compatible: IE=EmulateIE7
X-AspNet-Version: 4.0.30319
Set-Cookie: ClientId=567C1AE2155A441B9B9135F021DE8E49; expires=Thu, 28-Oct-2021 01:01:28 GMT; path=/; secure
Set-Cookie: UC=5caf337600204e1aa6add4af567d64ba; path=/; secure; HttpOnly
Set-Cookie: X-OWA-CANARY=ALo_AnoqYkOZD3FVdSCHPoDMmQDdetgI1eFx8F31UnwyEefwAxmPCeDfu7qodXti7-KYJeZb_Ts.; path=/; secure
Set-Cookie: X-BackEndCookie=<data>; expires=Fri, 27-Nov-2020 01:01:28 GMT; path=/owa; secure; HttpOnly
X-Powered-By: ASP.NET
X-FEServer: exchange
Date: Wed, 28 Oct 2020 01:01:28 GMT 

----------
2020/10/28 12:01:23.897 kid1| ctx: exit level  0
2020/10/28 12:01:23.897 kid1| 11,2| Stream.cc(266) sendStartOfMessage: HTTP Client local=squid-external:443 remote=client-browser:2600 FD 24 flags=1
2020/10/28 12:01:23.897 kid1| 11,2| Stream.cc(267) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 200 OK
Cache-Control: no-cache
Pragma: no-cache
Content-Type: text/html; charset=utf-8
Expires: -1
Server: Microsoft-IIS/8.5
request-id: ea651da4-e232-4990-995e-72e015c573fb
X-CalculatedBETarget: exchange.domain.com
X-Content-Type-Options: nosniff
X-OWA-Version: 15.1.1979.3
X-OWA-OWSVersion: V2017_08_18
X-OWA-MinimumSupportedOWSVersion: V2_6
X-Frame-Options: SAMEORIGIN
X-OWA-DiagnosticsInfo: 46;15;7
X-BackEnd-Begin: 2020-10-28T12:01:28.905
X-BackEnd-End: 2020-10-28T12:01:28.952
X-DiagInfo: exchange
X-BEServer: exchange
X-UA-Compatible: IE=EmulateIE7
X-AspNet-Version: 4.0.30319
Set-Cookie: ClientId=567C1AE2155A441B9B9135F021DE8E49; expires=Thu, 28-Oct-2021 01:01:28 GMT; path=/; secure
Set-Cookie: UC=5caf337600204e1aa6add4af567d64ba; path=/; secure; HttpOnly
Set-Cookie: X-OWA-CANARY=ALo_AnoqYkOZD3FVdSCHPoDMmQDdetgI1eFx8F31UnwyEefwAxmPCeDfu7qodXti7-KYJeZb_Ts.; path=/; secure
Set-Cookie: X-BackEndCookie=<data>; expires=Fri, 27-Nov-2020 01:01:28 GMT; path=/owa; secure; HttpOnly
X-Powered-By: ASP.NET
X-FEServer: exchange
Date: Wed, 28 Oct 2020 01:01:28 GMT
X-Cache: MISS from webmail.domain.com
X-Cache-Lookup: MISS from webmail.domain.com:443
Transfer-Encoding: chunked
Connection: keep-alive


From squid3 at treenet.co.nz  Wed Oct 28 11:08:34 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Oct 2020 00:08:34 +1300
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading - not working on IE/Chrome
In-Reply-To: <20201028042524.GA7104@thismonkey.com>
References: <20201027092404.GA90645@thismonkey.com>
 <00af01d6ac97$99cfa610$cd6ef230$@gmail.com>
 <20201028042524.GA7104@thismonkey.com>
Message-ID: <aa2370e8-9787-d3cb-4031-8387079bd0ff@treenet.co.nz>

On 28/10/20 5:25 pm, Scott wrote:
> 
> Here are the logs (first not working, followed by working).
> 
> Note this is the login attempt, not the loading of the initial page.  You'll
> see in the NOT WORKING section that the browser does NOT return a cookie to
> the server, which is where the problem may be.  Again, I'm not sure why - I'm
> thinking perhaps the browser/javascript is rejecting the cookie as it's
> missing the "secure" attribute (because the back-end is talking plain HTTP).
> 

The complete absence of a cookie may be expected to break something.

The absence of a "secure" flag should only make the cookie vulnerable to 
leaking. It should not affect anything depending on that cookies value.


Amos


From 3m9n51s2ewut at thismonkey.com  Wed Oct 28 12:25:05 2020
From: 3m9n51s2ewut at thismonkey.com (Scott)
Date: Wed, 28 Oct 2020 23:25:05 +1100
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading - not working on IE/Chrome
In-Reply-To: <mailman.0.1603886401.20089.squid-users@lists.squid-cache.org>
References: <mailman.0.1603886401.20089.squid-users@lists.squid-cache.org>
Message-ID: <20201028122505.GA62082@thismonkey.com>

On Wed, Oct 28, 2020 at 12:00:01PM +0000, squid-users-request at lists.squid-cache.org wrote:
> Date: Thu, 29 Oct 2020 00:08:34 +1300
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Reverse proxying Exchange OWA wembail with SSL
>  offloading - not working on IE/Chrome
> 
> On 28/10/20 5:25 pm, Scott wrote:
> > 
> > Here are the logs (first not working, followed by working).
> > 
> > Note this is the login attempt, not the loading of the initial page.  You'll
> > see in the NOT WORKING section that the browser does NOT return a cookie to
> > the server, which is where the problem may be.  Again, I'm not sure why - I'm
> > thinking perhaps the browser/javascript is rejecting the cookie as it's
> > missing the "secure" attribute (because the back-end is talking plain HTTP).
> > 
> 
> The complete absence of a cookie may be expected to break something.
> 
> The absence of a "secure" flag should only make the cookie vulnerable to 
> leaking. It should not affect anything depending on that cookies value.
> 
> 
> Amos
> 

My current theory is that the browser ignores the server-supplied cookie 
because it is missing the "secure" flag.  I could be completely wrong of 
course.  But that flag is one of the few differences between a working 
session and a not-working session.

I did find this site: 
https://support.kemptechnologies.com/hc/en-us/articles/202154165-How-to-Add-an-SSL-Secure-and-HTTP-only-flag-to-cookies-from-a-Real-Server 
that is in the same ball park of my suspicions.

I've tried building an ICAP server using the examples from PyICAP and have 
got as far as receiving the data and altering the header but I can't work out 
how to send the modified header and data back to Squid.

My code is:

   def cookie_RESPMOD(self):
       self.set_icap_response(200)

       self.set_enc_status(b' '.join(self.enc_res_status))
       for h in self.enc_res_headers:
           for v in self.enc_res_headers[h]:
               if h == "set-cookie" and re.search(r'HttpOnly', v) and not re.search(r'secure', v):
                   v = v.replace('; HttpOnly', '; secure; HttpOnly')
                   print("h: ", h, "v: ", v)
               self.set_enc_header(h, v)

       if not self.has_body:
           self.send_headers(False)
           return

       self.send_headers(True)
           return

I'm sure it's something simple like not sending the body.  I really need to read the ICAP docs/RFCs.

The script generates the following:
10.2.255.1 - - [28/Oct/2020 23:17:21] "OPTIONS icap://10.2.255.1:40000/cookie ICAP/1.0" 200 -
10.2.255.1 - - [28/Oct/2020 23:17:21] "RESPMOD icap://10.2.255.1:40000/cookie ICAP/1.0" 200 -
10.2.255.1 - - [28/Oct/2020 23:17:21] code 400, message B
10.2.255.1 - - [28/Oct/2020 23:17:31] "RESPMOD icap://10.2.255.1:40000/cookie ICAP/1.0" 200 -
10.2.255.1 - - [28/Oct/2020 23:17:31] code 400, message B
10.2.255.1 - - [28/Oct/2020 23:17:31] "RESPMOD icap://10.2.255.1:40000/cookie ICAP/1.0" 200 -
10.2.255.1 - - [28/Oct/2020 23:17:31] code 400, message B

I might look into a code hack as a means of testing.


From 3m9n51s2ewut at thismonkey.com  Wed Oct 28 23:06:40 2020
From: 3m9n51s2ewut at thismonkey.com (Scott)
Date: Thu, 29 Oct 2020 10:06:40 +1100
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading
In-Reply-To: <mailman.0.1603886401.20089.squid-users@lists.squid-cache.org>
References: <mailman.0.1603886401.20089.squid-users@lists.squid-cache.org>
Message-ID: <20201028230640.GA70286@thismonkey.com>

On Wed, Oct 28, 2020 at 12:00:01PM +0000, squid-users-request at lists.squid-cache.org wrote:
> Date: Thu, 29 Oct 2020 00:08:34 +1300
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Reverse proxying Exchange OWA wembail with SSL
>  offloading - not working on IE/Chrome
> 
> On 28/10/20 5:25 pm, Scott wrote:
> > 
> > Here are the logs (first not working, followed by working).
> > 
> > Note this is the login attempt, not the loading of the initial page.  You'll
> > see in the NOT WORKING section that the browser does NOT return a cookie to
> > the server, which is where the problem may be.  Again, I'm not sure why - I'm
> > thinking perhaps the browser/javascript is rejecting the cookie as it's
> > missing the "secure" attribute (because the back-end is talking plain HTTP).
> > 
> 
> The complete absence of a cookie may be expected to break something.
> 
> The absence of a "secure" flag should only make the cookie vulnerable to 
> leaking. It should not affect anything depending on that cookies value.
> 
> 
> Amos
> 

After some more research and experimentation I've confirmed that my 
suspicions are correct.

Recent browsers are no longer accepting cookies with the SameSite flag set 
without the Secure flag set.

It's not an issue with Squid (although one Squid could solve - but I'm unsure 
of the implications).

Here is a useful link:
https://docs.microsoft.com/en-us/office365/troubleshoot/miscellaneous/chrome-behavior-affects-applications

I tested Chrome 85 on Windows - the default settings DO NOT allow for these 
cookies.  However after setting
	Cookies without SameSite must be secure
to Disabled, these cookies are permitted and OWA works.

There are obvious implications for sites doing SSL offloading here.  Are 
sites no longer doing SSL offload?  Or are reverse proxies adding the Secure 
flag?

Interesting.


From squid3 at treenet.co.nz  Thu Oct 29 09:08:42 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Oct 2020 22:08:42 +1300
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading
In-Reply-To: <20201028230640.GA70286@thismonkey.com>
References: <mailman.0.1603886401.20089.squid-users@lists.squid-cache.org>
 <20201028230640.GA70286@thismonkey.com>
Message-ID: <3492e3df-e38b-2af9-9029-f49d4203f5e9@treenet.co.nz>

On 29/10/20 12:06 pm, Scott wrote:
> On Wed, Oct 28, 2020 at 12:00:01PM +0000, squid-users-reques wrote:
>> Date: Thu, 29 Oct 2020 00:08:34 +1300
>> From: Amos Jeffries
>>
>> On 28/10/20 5:25 pm, Scott wrote:
>>>
>>> Here are the logs (first not working, followed by working).
>>>
>>> Note this is the login attempt, not the loading of the initial page.  You'll
>>> see in the NOT WORKING section that the browser does NOT return a cookie to
>>> the server, which is where the problem may be.  Again, I'm not sure why - I'm
>>> thinking perhaps the browser/javascript is rejecting the cookie as it's
>>> missing the "secure" attribute (because the back-end is talking plain HTTP).
>>>
>>
>> The complete absence of a cookie may be expected to break something.
>>
>> The absence of a "secure" flag should only make the cookie vulnerable to
>> leaking. It should not affect anything depending on that cookies value.
>>
>>
>> Amos
>>
> 
> After some more research and experimentation I've confirmed that my
> suspicions are correct.
> 
> Recent browsers are no longer accepting cookies with the SameSite flag set
> without the Secure flag set.
> 
> It's not an issue with Squid (although one Squid could solve - but I'm unsure
> of the implications).

Implications are that the server may have intentionally used the 
combination it did, no mistakes.

The server is given "Front-End-Https: On" so that it is aware the client 
is using HTTPS and can set (or not) the secure flag appropriately to 
what it needs. Squid is not aware of whether the cookie is safe to use 
on HTTP or restrict to just HTTPS.


> 
> Here is a useful link:
> https://docs.microsoft.com/en-us/office365/troubleshoot/miscellaneous/chrome-behavior-affects-applications
> 
> I tested Chrome 85 on Windows - the default settings DO NOT allow for these
> cookies.  However after setting
> 	Cookies without SameSite must be secure
> to Disabled, these cookies are permitted and OWA works.
> 
> There are obvious implications for sites doing SSL offloading here.  Are
> sites no longer doing SSL offload?  Or are reverse proxies adding the Secure
> flag?


Neither. When a site frontend is entirely https:// with no http:// 
resources mixed in the Secure flag can be used by the server regardless 
of what the internal connections are.


Amos


From ngtech1ltd at gmail.com  Thu Oct 29 12:05:42 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Thu, 29 Oct 2020 14:05:42 +0200
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading
In-Reply-To: <20201028230640.GA70286@thismonkey.com>
References: <mailman.0.1603886401.20089.squid-users@lists.squid-cache.org>
 <20201028230640.GA70286@thismonkey.com>
Message-ID: <005101d6adeb$d39f4a80$7adddf80$@gmail.com>

Hey Scott,

In many frontends there is a basic way to signal about the existence of a Frontend and the relevant
details about the client and other factors of the connection.

Specifically with haproxy these settings are used:
    http-request set-header X-Forwarded-Host %[req.hdr(Host)]
    http-request set-header X-Forwarded-Proto https

https://www.haproxy.com/blog/ssl-offloading-impact-on-web-applications/
https://www.digitalocean.com/community/tutorials/how-to-implement-ssl-termination-with-haproxy-on-ubuntu-14-04

In nginx:
https://www.nginx.com/resources/wiki/start/topics/examples/forwarded/
https://www.digitalocean.com/community/tutorials/how-to-set-up-nginx-load-balancing-with-ssl-termination


In squid you can use:
http://www.squid-cache.org/Doc/config/request_header_replace/
http://www.squid-cache.org/Doc/config/request_header_add/

An example should be provided in wiki some day be someone(not me).

----
Eliezer Croitoru
Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Scott
Sent: Thursday, October 29, 2020 1:07 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Reverse proxying Exchange OWA wembail with SSL offloading

On Wed, Oct 28, 2020 at 12:00:01PM +0000, squid-users-request at lists.squid-cache.org wrote:
> Date: Thu, 29 Oct 2020 00:08:34 +1300
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Reverse proxying Exchange OWA wembail with SSL
>  offloading - not working on IE/Chrome
> 
> On 28/10/20 5:25 pm, Scott wrote:
> > 
> > Here are the logs (first not working, followed by working).
> > 
> > Note this is the login attempt, not the loading of the initial page.  You'll
> > see in the NOT WORKING section that the browser does NOT return a cookie to
> > the server, which is where the problem may be.  Again, I'm not sure why - I'm
> > thinking perhaps the browser/javascript is rejecting the cookie as it's
> > missing the "secure" attribute (because the back-end is talking plain HTTP).
> > 
> 
> The complete absence of a cookie may be expected to break something.
> 
> The absence of a "secure" flag should only make the cookie vulnerable to 
> leaking. It should not affect anything depending on that cookies value.
> 
> 
> Amos
> 

After some more research and experimentation I've confirmed that my 
suspicions are correct.

Recent browsers are no longer accepting cookies with the SameSite flag set 
without the Secure flag set.

It's not an issue with Squid (although one Squid could solve - but I'm unsure 
of the implications).

Here is a useful link:
https://docs.microsoft.com/en-us/office365/troubleshoot/miscellaneous/chrome-behavior-affects-applications

I tested Chrome 85 on Windows - the default settings DO NOT allow for these 
cookies.  However after setting
	Cookies without SameSite must be secure
to Disabled, these cookies are permitted and OWA works.

There are obvious implications for sites doing SSL offloading here.  Are 
sites no longer doing SSL offload?  Or are reverse proxies adding the Secure 
flag?

Interesting.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From 3m9n51s2ewut at thismonkey.com  Fri Oct 30 02:27:31 2020
From: 3m9n51s2ewut at thismonkey.com (Scott)
Date: Fri, 30 Oct 2020 13:27:31 +1100
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading
In-Reply-To: <3492e3df-e38b-2af9-9029-f49d4203f5e9@treenet.co.nz>
References: <mailman.0.1603886401.20089.squid-users@lists.squid-cache.org>
 <20201028230640.GA70286@thismonkey.com>
 <3492e3df-e38b-2af9-9029-f49d4203f5e9@treenet.co.nz>
Message-ID: <20201030022731.GA76846@thismonkey.com>

On Thu, Oct 29, 2020 at 10:08:42PM +1300, Amos Jeffries wrote:
> On 29/10/20 12:06 pm, Scott wrote:
> > On Wed, Oct 28, 2020 at 12:00:01PM +0000, squid-users-reques wrote:
> >> Date: Thu, 29 Oct 2020 00:08:34 +1300
> >> From: Amos Jeffries
> >>
> >> On 28/10/20 5:25 pm, Scott wrote:
> >>>
> >>> Here are the logs (first not working, followed by working).
> >>>
> >>> Note this is the login attempt, not the loading of the initial page.  You'll
> >>> see in the NOT WORKING section that the browser does NOT return a cookie to
> >>> the server, which is where the problem may be.  Again, I'm not sure why - I'm
> >>> thinking perhaps the browser/javascript is rejecting the cookie as it's
> >>> missing the "secure" attribute (because the back-end is talking plain HTTP).
> >>>
> >>
> >> The complete absence of a cookie may be expected to break something.
> >>
> >> The absence of a "secure" flag should only make the cookie vulnerable to
> >> leaking. It should not affect anything depending on that cookies value.
> >>
> >>
> >> Amos
> >>
> > 
> > After some more research and experimentation I've confirmed that my
> > suspicions are correct.
> > 
> > Recent browsers are no longer accepting cookies with the SameSite flag set
> > without the Secure flag set.
> > 
> > It's not an issue with Squid (although one Squid could solve - but I'm unsure
> > of the implications).
> 
> Implications are that the server may have intentionally used the 
> combination it did, no mistakes.
> 
> The server is given "Front-End-Https: On" so that it is aware the client 
> is using HTTPS and can set (or not) the secure flag appropriately to 
> what it needs. Squid is not aware of whether the cookie is safe to use 
> on HTTP or restrict to just HTTPS.
> 
> 
> > 
> > Here is a useful link:
> > https://docs.microsoft.com/en-us/office365/troubleshoot/miscellaneous/chrome-behavior-affects-applications
> > 
> > I tested Chrome 85 on Windows - the default settings DO NOT allow for these
> > cookies.  However after setting
> > 	Cookies without SameSite must be secure
> > to Disabled, these cookies are permitted and OWA works.
> > 
> > There are obvious implications for sites doing SSL offloading here.  Are
> > sites no longer doing SSL offload?  Or are reverse proxies adding the Secure
> > flag?
> 
> 
> Neither. When a site frontend is entirely https:// with no http:// 
> resources mixed in the Secure flag can be used by the server regardless 
> of what the internal connections are.
> 
> 
> Amos

My point is that, assuming browsers are now enforcing SameSite cookies must 
be secure, then doing SSL offload (whereby the origin server does NOT flag 
the cookie as secure) will break.

In this particular case, I use squid to do reverse proxy with SSL offload to 
a MS Exchange server.
Because the requests are HTTP IIS does not set the secure flag on cookies, 
and browsers now reject them.  This breaks things.

I've fixed it by switching back to HTTPS on the backend (no SSL offload), and 
so the secure flag is now being set by IIS.  Problem solved.

In the long term it seems doing SSL offload to MS Exchange (and Sharepoint I 
think) will not be an option.  I've seen other proxy manufacturers provide 
cookie manipulation; I assume for this kind of issue.

Do you think Squid should have such a feature?

Thanks


From squid3 at treenet.co.nz  Fri Oct 30 11:49:16 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 31 Oct 2020 00:49:16 +1300
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading
In-Reply-To: <20201030022731.GA76846@thismonkey.com>
References: <mailman.0.1603886401.20089.squid-users@lists.squid-cache.org>
 <20201028230640.GA70286@thismonkey.com>
 <3492e3df-e38b-2af9-9029-f49d4203f5e9@treenet.co.nz>
 <20201030022731.GA76846@thismonkey.com>
Message-ID: <048c5f54-64ff-1c73-7c0b-b9ad235341f0@treenet.co.nz>

On 30/10/20 3:27 pm, Scott wrote:
> On Thu, Oct 29, 2020 at 10:08:42PM +1300, Amos Jeffries wrote:
>> On 29/10/20 12:06 pm, Scott wrote:
>>> On Wed, Oct 28, 2020 at 12:00:01PM +0000, squid-users-reques wrote:
>>>> Date: Thu, 29 Oct 2020 00:08:34 +1300
>>>> From: Amos Jeffries
>>>>
>>>> On 28/10/20 5:25 pm, Scott wrote:
>>>>>
>>>>> Here are the logs (first not working, followed by working).
>>>>>
>>>>> Note this is the login attempt, not the loading of the initial page.  You'll
>>>>> see in the NOT WORKING section that the browser does NOT return a cookie to
>>>>> the server, which is where the problem may be.  Again, I'm not sure why - I'm
>>>>> thinking perhaps the browser/javascript is rejecting the cookie as it's
>>>>> missing the "secure" attribute (because the back-end is talking plain HTTP).
>>>>>
>>>>
>>>> The complete absence of a cookie may be expected to break something.
>>>>
>>>> The absence of a "secure" flag should only make the cookie vulnerable to
>>>> leaking. It should not affect anything depending on that cookies value.
>>>>
>>>>
>>>> Amos
>>>>
>>>
>>> After some more research and experimentation I've confirmed that my
>>> suspicions are correct.
>>>
>>> Recent browsers are no longer accepting cookies with the SameSite flag set
>>> without the Secure flag set.
>>>
>>> It's not an issue with Squid (although one Squid could solve - but I'm unsure
>>> of the implications).
>>
>> Implications are that the server may have intentionally used the
>> combination it did, no mistakes.
>>
>> The server is given "Front-End-Https: On" so that it is aware the client
>> is using HTTPS and can set (or not) the secure flag appropriately to
>> what it needs. Squid is not aware of whether the cookie is safe to use
>> on HTTP or restrict to just HTTPS.
>>
>>
>>>
>>> Here is a useful link:
>>> https://docs.microsoft.com/en-us/office365/troubleshoot/miscellaneous/chrome-behavior-affects-applications
>>>
>>> I tested Chrome 85 on Windows - the default settings DO NOT allow for these
>>> cookies.  However after setting
>>> 	Cookies without SameSite must be secure
>>> to Disabled, these cookies are permitted and OWA works.
>>>
>>> There are obvious implications for sites doing SSL offloading here.  Are
>>> sites no longer doing SSL offload?  Or are reverse proxies adding the Secure
>>> flag?
>>
>>
>> Neither. When a site frontend is entirely https:// with no http://
>> resources mixed in the Secure flag can be used by the server regardless
>> of what the internal connections are.
>>
>>
>> Amos
> 
> My point is that, assuming browsers are now enforcing SameSite cookies must
> be secure, then doing SSL offload (whereby the origin server does NOT flag
> the cookie as secure) will break.

But offloading does not mean the server omits the secure flag.

Servers which choose to send it when offloading work fine. Servers that 
choose to omit it have problems with the Google paranoid interpretation 
of security.


> 
> In this particular case, I use squid to do reverse proxy with SSL offload to
> a MS Exchange server.

You also have a TLS connection to the exchange:443 peer.

Notice that in the logs you showed transactions sent to that peer get 
the secure flag set, despite the SSL offload being done by Squid at the 
same time.



> Because the requests are HTTP IIS does not set the secure flag on cookies,
> and browsers now reject them.  This breaks things.
> 
> I've fixed it by switching back to HTTPS on the backend (no SSL offload), and
> so the secure flag is now being set by IIS.  Problem solved.
> 
> In the long term it seems doing SSL offload to MS Exchange (and Sharepoint I
> think) will not be an option.  I've seen other proxy manufacturers provide
> cookie manipulation; I assume for this kind of issue.
> 
> Do you think Squid should have such a feature?

We have ICAP, eCAP, and *_header_replace features already. So any 
proposed new feature would have to be better than what they already provide.


Amos


From 3m9n51s2ewut at thismonkey.com  Fri Oct 30 14:20:35 2020
From: 3m9n51s2ewut at thismonkey.com (Scott)
Date: Sat, 31 Oct 2020 01:20:35 +1100
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading
In-Reply-To: <048c5f54-64ff-1c73-7c0b-b9ad235341f0@treenet.co.nz>
References: <mailman.0.1603886401.20089.squid-users@lists.squid-cache.org>
 <20201028230640.GA70286@thismonkey.com>
 <3492e3df-e38b-2af9-9029-f49d4203f5e9@treenet.co.nz>
 <20201030022731.GA76846@thismonkey.com>
 <048c5f54-64ff-1c73-7c0b-b9ad235341f0@treenet.co.nz>
Message-ID: <20201030142034.GA41498@thismonkey.com>

On Sat, Oct 31, 2020 at 12:49:16AM +1300, Amos Jeffries wrote:
> On 30/10/20 3:27 pm, Scott wrote:
> > On Thu, Oct 29, 2020 at 10:08:42PM +1300, Amos Jeffries wrote:
> >> On 29/10/20 12:06 pm, Scott wrote:
> >>> On Wed, Oct 28, 2020 at 12:00:01PM +0000, squid-users-reques wrote:
> >>>> Date: Thu, 29 Oct 2020 00:08:34 +1300
> >>>> From: Amos Jeffries
> >>>>
> >>>> On 28/10/20 5:25 pm, Scott wrote:
> >>>>>
> >>>>> Here are the logs (first not working, followed by working).
> >>>>>
> >>>>> Note this is the login attempt, not the loading of the initial page.  You'll
> >>>>> see in the NOT WORKING section that the browser does NOT return a cookie to
> >>>>> the server, which is where the problem may be.  Again, I'm not sure why - I'm
> >>>>> thinking perhaps the browser/javascript is rejecting the cookie as it's
> >>>>> missing the "secure" attribute (because the back-end is talking plain HTTP).
> >>>>>
> >>>>
> >>>> The complete absence of a cookie may be expected to break something.
> >>>>
> >>>> The absence of a "secure" flag should only make the cookie vulnerable to
> >>>> leaking. It should not affect anything depending on that cookies value.
> >>>>
> >>>>
> >>>> Amos
> >>>>
> >>>
> >>> After some more research and experimentation I've confirmed that my
> >>> suspicions are correct.
> >>>
> >>> Recent browsers are no longer accepting cookies with the SameSite flag set
> >>> without the Secure flag set.
> >>>
> >>> It's not an issue with Squid (although one Squid could solve - but I'm unsure
> >>> of the implications).
> >>
> >> Implications are that the server may have intentionally used the
> >> combination it did, no mistakes.
> >>
> >> The server is given "Front-End-Https: On" so that it is aware the client
> >> is using HTTPS and can set (or not) the secure flag appropriately to
> >> what it needs. Squid is not aware of whether the cookie is safe to use
> >> on HTTP or restrict to just HTTPS.
> >>
> >>
> >>>
> >>> Here is a useful link:
> >>> https://docs.microsoft.com/en-us/office365/troubleshoot/miscellaneous/chrome-behavior-affects-applications
> >>>
> >>> I tested Chrome 85 on Windows - the default settings DO NOT allow for these
> >>> cookies.  However after setting
> >>> 	Cookies without SameSite must be secure
> >>> to Disabled, these cookies are permitted and OWA works.
> >>>
> >>> There are obvious implications for sites doing SSL offloading here.  Are
> >>> sites no longer doing SSL offload?  Or are reverse proxies adding the Secure
> >>> flag?
> >>
> >>
> >> Neither. When a site frontend is entirely https:// with no http://
> >> resources mixed in the Secure flag can be used by the server regardless
> >> of what the internal connections are.
> >>
> >>
> >> Amos
> > 
> > My point is that, assuming browsers are now enforcing SameSite cookies must
> > be secure, then doing SSL offload (whereby the origin server does NOT flag
> > the cookie as secure) will break.
> 
> But offloading does not mean the server omits the secure flag.
> 
> Servers which choose to send it when offloading work fine. Servers that 
> choose to omit it have problems with the Google paranoid interpretation 
> of security.

Aren't origin servers oblivious to SSL offloading?  I thought they just 
happily accepted HTTP connections with no knowledge of any secure channel 
between client and reverse proxy.

If that's correct then, although not proscribed by the RFC, it's unlikely 
that a Set-Cookie header would ever contain a Secure flag because the server 
would be saying "I insist this Cookie be transmitted securely, but here it is 
over an insecure channel".

> 
> 
> > 
> > In this particular case, I use squid to do reverse proxy with SSL offload to
> > a MS Exchange server.
> 
> You also have a TLS connection to the exchange:443 peer.

I have both for testing, but only one is active at any one time (as 
referenced in a cache_peer_access).  Yes I now use the 443 peer because 
Chrome/IE/Edge + SSL Offloading no longer works.

> 
> Notice that in the logs you showed transactions sent to that peer get 
> the secure flag set, despite the SSL offload being done by Squid at the 
> same time.
> 
> 

Not true AFAICT.  Any cookies you see in those logs with Secure set are shown 
under the "WORKING" heading whose entries are:
2020/10/28 12:01:23.549 kid1| 11,2| http.cc(2263) sendRequest: HTTP Server local=squid-internal:62597 remote=exchange:443 FD 30 flags=1

No SSL offloading there.  Otherwise it would say "remote=exchange:80"

> 
> > Because the requests are HTTP IIS does not set the secure flag on cookies,
> > and browsers now reject them.  This breaks things.
> > 
> > I've fixed it by switching back to HTTPS on the backend (no SSL offload), and
> > so the secure flag is now being set by IIS.  Problem solved.
> > 
> > In the long term it seems doing SSL offload to MS Exchange (and Sharepoint I
> > think) will not be an option.  I've seen other proxy manufacturers provide
> > cookie manipulation; I assume for this kind of issue.
> > 
> > Do you think Squid should have such a feature?
> 
> We have ICAP, eCAP, and *_header_replace features already. So any 
> proposed new feature would have to be better than what they already provide.
> 

Unless I'm reading the online command reference incorrectly, *_header_replace 
does not allow for the insertion of text so can't help here.  Please tell me 
I'm wrong - I'd love for Squid to have this capability like other proxies.

> 
> Amos
> 

I can't tell if we're agreeing or not :).  Suffice to say SSL offloading of 
OWA with modern browsers is becoming a thing of the past, at least with Squid 
(without ICAP).

This MS article basically sums up what we've discussed here.
https://docs.microsoft.com/en-us/answers/questions/73384/chrome-80-samesite-feature-causes-owa-login-loop.html

The advice therein talks about:
- Toggling the setting in Chrome
- Do a cookie rewrite on the SSL offloader device if possible
- change the backend communication to HTTPS (turn off SSL offloading)

Anyway this conversation may help someone else.
Thanks


From rousskov at measurement-factory.com  Fri Oct 30 15:49:11 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 30 Oct 2020 11:49:11 -0400
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading
In-Reply-To: <20201030022731.GA76846@thismonkey.com>
References: <mailman.0.1603886401.20089.squid-users@lists.squid-cache.org>
 <20201028230640.GA70286@thismonkey.com>
 <3492e3df-e38b-2af9-9029-f49d4203f5e9@treenet.co.nz>
 <20201030022731.GA76846@thismonkey.com>
Message-ID: <aedb4260-8418-898e-0e99-9a667aa1281b@measurement-factory.com>

On 10/29/20 10:27 PM, Scott wrote:

> My point is that, assuming browsers are now enforcing SameSite cookies must 
> be secure, then doing SSL offload (whereby the origin server does NOT flag 
> the cookie as secure) will break.

...

> I've seen other proxy manufacturers provide 
> cookie manipulation; I assume for this kind of issue.

> Do you think Squid should have such a feature?

Yes, I do.

Alex.


From roeeklinger60 at gmail.com  Sat Oct 31 00:34:38 2020
From: roeeklinger60 at gmail.com (roee klinger)
Date: Sat, 31 Oct 2020 02:34:38 +0200
Subject: [squid-users] Best practice for adding or removing ACLs dynamically
 ?
Message-ID: <75C05DB7-2C0E-4B77-88A4-66F581A035ED@gmail.com>

?
Hey,
I have Squid configured to send users to different outgoing interface like so:

..
auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/htpassword
acl acl_for_user3002 proxy_auth user2
tcp_outgoing_address 192.168.8.12 acl_for_user3002
http_port 3002 name=3002
http_access allow authenticated
..

When I wanted to change the username:password for user2, I run a bash script to change it in squid.conf and also in htpassword and then I run "squid -k reconfigure", if I don't reconfigure the old user still has access to the proxy and the new one doesn't for about 30 minutes.

I am expecting to have 100s of users soon that will change credentials often, and also I would like to blacklist websites often and on the fly, so I was searching for a better way to manage this without reconfiguring every time, since sometimes a reconfigure can take up to 10-15 seconds.

I am new to Squid and wasn't able to find any info on this, am I doing this currently or there is a better way to change users/ACLs on the fly without reloading Squid?

Thanks,
Roee Klinger

From rentorbuy at yahoo.com  Sat Oct 31 11:02:42 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Sat, 31 Oct 2020 11:02:42 +0000 (UTC)
Subject: [squid-users] squid restart
References: <2076232307.120171.1604142162886.ref@mail.yahoo.com>
Message-ID: <2076232307.120171.1604142162886@mail.yahoo.com>

Hi,

Around every hour or so, the Squid proxy client experience comes to a crawl.
It takes a very long time to load a simple web page.

This is a snapshot taken when this happens:

# squidclient mgr:info
HTTP/1.1 200 OK
Server: squid
Mime-Version: 1.0
Date: Sat, 31 Oct 2020 10:43:21 GMT
Content-Type: text/plain;charset=utf-8
Expires: Sat, 31 Oct 2020 10:43:21 GMT
Last-Modified: Sat, 31 Oct 2020 10:43:21 GMT
X-Cache: MISS from inf-fw1
X-Cache-Lookup: MISS from inf-fw1:3128
Connection: close

Squid Object Cache: Version 5.0.4-20201013-r6b13b73d3
Build Info:
Service Name: squid
Start Time:???? Sat, 31 Oct 2020 04:50:45 GMT
Current Time:?? Sat, 31 Oct 2020 10:43:21 GMT
Connection information for squid:
??????? Number of clients accessing cache:????? 320
??????? Number of HTTP requests received:?????? 519828
??????? Number of ICP messages received:??????? 0
??????? Number of ICP messages sent:??? 0
??????? Number of queued ICP replies:?? 0
??????? Number of HTCP messages received:?????? 0
??????? Number of HTCP messages sent:?? 0
??????? Request failure ratio:?? 0.00
??????? Average HTTP requests per minute since start:?? 1474.3
??????? Average ICP messages per minute since start:??? 0.0
??????? Select loop called: 9044075 times, 2.339 ms avg
Cache information for squid:
??????? Hits as % of all requests:????? 5min: 2.1%, 60min: 2.5%
??????? Hits as % of bytes sent:??????? 5min: -68.9%, 60min: -402.5%
??????? Memory hits as % of hit requests:?????? 5min: 78.3%, 60min: 62.3%
??????? Disk hits as % of hit requests: 5min: 0.0%, 60min: 1.7%
??????? Storage Swap size:????? 29040 KB
??????? Storage Swap capacity:? 88.6% used, 11.4% free
??????? Storage Mem size:?????? 29212 KB
??????? Storage Mem capacity:?? 89.1% used, 10.9% free
??????? Mean Object Size:?????? 17.31 KB
??????? Requests given to unlinkd:????? 11815
Median Service Times (seconds)? 5 min??? 60 min:
??????? HTTP Requests (All):?? 0.04519? 0.04776
??????? Cache Misses:????????? 0.06286? 0.06286
??????? Cache Hits:??????????? 0.00000? 0.00000
??????? Near Hits:???????????? 0.04277? 0.02317
??????? Not-Modified Replies:? 0.00000? 0.00000
??????? DNS Lookups:?????????? 0.00000? 0.00000
??????? ICP Queries:?????????? 0.00000? 0.00000
Resource usage for squid:
??????? UP Time:??????? 21155.513 seconds
??????? CPU Time:?????? 1334.166 seconds
??????? CPU Usage:????? 6.31%
??????? CPU Usage, 5 minute avg:??????? 8.60%
??????? CPU Usage, 60 minute avg:?????? 9.88%
??????? Maximum Resident Size: 4287872 KB
??????? Page faults with physical i/o: 0
Memory accounted for:
??????? Total accounted:?????? 744703 KB
??????? memPoolAlloc calls: 136343652
??????? memPoolFree calls:? 140190831
File descriptor usage for squid:
??????? Maximum number of file descriptors:?? 4096
??????? Largest file desc currently in use:?? 4009
??????? Number of file desc currently in use: 3997
??????? Files queued for open:?????????????????? 0
??????? Available number of file descriptors:?? 99
??????? Reserved number of file descriptors:?? 100
??????? Store Disk files open:?????????????????? 0
Internal Data Structures:
????????? 1852 StoreEntries
????????? 1849 StoreEntries with MemObjects
????????? 1754 Hot Object Cache Items
????????? 1678 on-disk objects

If I issue the '-k reconfigure' command then the user experience is "great again".

A data snapshot taken right after the latter command shows this:

# squidclient mgr:info
HTTP/1.1 200 OK
Server: squid
Mime-Version: 1.0
Date: Sat, 31 Oct 2020 10:48:40 GMT
Content-Type: text/plain;charset=utf-8
Expires: Sat, 31 Oct 2020 10:48:40 GMT
Last-Modified: Sat, 31 Oct 2020 10:48:40 GMT
X-Cache: MISS from inf-fw1
X-Cache-Lookup: MISS from inf-fw1:3128
Connection: close

Squid Object Cache: Version 5.0.4-20201013-r6b13b73d3
Build Info:
Service Name: squid
Start Time:???? Sat, 31 Oct 2020 10:46:51 GMT
Current Time:?? Sat, 31 Oct 2020 10:48:40 GMT
Connection information for squid:
??????? Number of clients accessing cache:????? 179
??????? Number of HTTP requests received:?????? 4663
??????? Number of ICP messages received:??????? 0
??????? Number of ICP messages sent:??? 0
??????? Number of queued ICP replies:?? 0
??????? Number of HTCP messages received:?????? 0
??????? Number of HTCP messages sent:?? 0
??????? Request failure ratio:?? 0.00
??????? Average HTTP requests per minute since start:?? 2575.3
??????? Average ICP messages per minute since start:??? 0.0
??????? Select loop called: 51220 times, 2.121 ms avg
Cache information for squid:
??????? Hits as % of all requests:????? 5min: 0.3%, 60min: 0.3%
??????? Hits as % of bytes sent:??????? 5min: 3.6%, 60min: 3.6%
??????? Memory hits as % of hit requests:?????? 5min: 60.0%, 60min: 60.0%
??????? Disk hits as % of hit requests: 5min: 0.0%, 60min: 0.0%
??????? Storage Swap size:????? 10292 KB
??????? Storage Swap capacity:? 31.4% used, 68.6% free
??????? Storage Mem size:?????? 10456 KB
??????? Storage Mem capacity:?? 31.9% used, 68.1% free
??????? Mean Object Size:?????? 15.07 KB
??????? Requests given to unlinkd:????? 4657
Median Service Times (seconds)? 5 min??? 60 min:
??????? HTTP Requests (All):?? 0.05046? 0.05046
??????? Cache Misses:????????? 0.06286? 0.06286
??????? Cache Hits:??????????? 0.00000? 0.00000
??????? Near Hits:???????????? 0.15048? 0.15048
??????? Not-Modified Replies:? 0.00000? 0.00000
??????? DNS Lookups:?????????? 0.00000? 0.00000
??????? ICP Queries:?????????? 0.00000? 0.00000
Resource usage for squid:
??????? UP Time:??????? 108.639 seconds
??????? CPU Time:?????? 10.588 seconds
??????? CPU Usage:????? 9.75%
??????? CPU Usage, 5 minute avg:??????? 12.90%
??????? CPU Usage, 60 minute avg:?????? 12.90%
??????? Maximum Resident Size: 462736 KB
??????? Page faults with physical i/o: 0
Memory accounted for:
??????? Total accounted:??????? 37879 KB
??????? memPoolAlloc calls:?? 1256976
??????? memPoolFree calls:??? 1307898
File descriptor usage for squid:
??????? Maximum number of file descriptors:?? 4096
??????? Largest file desc currently in use:??? 567
??????? Number of file desc currently in use:? 559
??????? Files queued for open:?????????????????? 0
??????? Available number of file descriptors: 3537
??????? Reserved number of file descriptors:?? 100
??????? Store Disk files open:?????????????????? 0
Internal Data Structures:
?????????? 997 StoreEntries
?????????? 997 StoreEntries with MemObjects
?????????? 683 Hot Object Cache Items
?????????? 683 on-disk objects

This did not happen with Squid 4, or maybe it wasn't as obvious.


I guess the reason could be for this:

??????? Maximum number of file descriptors:?? 4096
??????? Largest file desc currently in use:?? 4009
??????? Number of file desc currently in use: 3997

However, I set the following directive in squid.conf:

max_filedescriptors 65536

It doesn't seem to be honored here unless I stop and restart the squid service again (/etc/init.d/squid restart from command line):

File descriptor usage for squid:
??????? Maximum number of file descriptors:?? 65535

It seems that if I run the same command (/etc/init.d/squid restart) from crontab, that ulimit is not honored. I guess that's the root cause of my issue because I am asking cron to restart Squid once daily. I'll try not to, but I was hoping to see if there was a reliable way to fully restart the Squid process.

Vieri





From squid3 at treenet.co.nz  Sat Oct 31 15:00:33 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 1 Nov 2020 04:00:33 +1300
Subject: [squid-users] squid restart
In-Reply-To: <2076232307.120171.1604142162886@mail.yahoo.com>
References: <2076232307.120171.1604142162886.ref@mail.yahoo.com>
 <2076232307.120171.1604142162886@mail.yahoo.com>
Message-ID: <45922024-b7e6-be8d-af33-f285ca76b877@treenet.co.nz>

On 1/11/20 12:02 am, Vieri wrote:
> Hi,
> 
> Around every hour or so, the Squid proxy client experience comes to a crawl.
> It takes a very long time to load a simple web page.

...

> 
> I guess the reason could be for this:
> 
>  ??????? Maximum number of file descriptors:?? 4096
>  ??????? Largest file desc currently in use:?? 4009
>  ??????? Number of file desc currently in use: 3997
> 

Yes, that looks like it.


> However, I set the following directive in squid.conf:
> 
> max_filedescriptors 65536
> 

Are you using systemd, SysV or another init ?

systemd default limits has this as a known issue for initial startup.


> It doesn't seem to be honored here unless I stop and restart the squid service again (/etc/init.d/squid restart from command line):
> 
> File descriptor usage for squid:
>  ??????? Maximum number of file descriptors:?? 65535
> 
> It seems that if I run the same command (/etc/init.d/squid restart) from crontab, that ulimit is not honored. I guess that's the root cause of my issue because I am asking cron to restart Squid once daily. I'll try not to, but I was hoping to see if there was a reliable way to fully restart the Squid process.
> 
> Vieri
> 

The init system restart command is the preferred one - it handles any 
system details that need updating. Alternatively, "squid -k restart" can 
be used.


Amos


From squid3 at treenet.co.nz  Sat Oct 31 15:40:17 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 1 Nov 2020 04:40:17 +1300
Subject: [squid-users] Best practice for adding or removing ACLs
 dynamically ?
In-Reply-To: <75C05DB7-2C0E-4B77-88A4-66F581A035ED@gmail.com>
References: <75C05DB7-2C0E-4B77-88A4-66F581A035ED@gmail.com>
Message-ID: <e7119d05-4ab8-59f3-b616-dd7ce2d48ccb@treenet.co.nz>

On 31/10/20 1:34 pm, roee klinger wrote:
> ?
> Hey,
> I have Squid configured to send users to different outgoing interface like so:
> 
> ..
> auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/htpassword
> acl acl_for_user3002 proxy_auth user2
> tcp_outgoing_address 192.168.8.12 acl_for_user3002
> http_port 3002 name=3002


No need to name a *_port like this. The default name is the first 
parameter string ("3002" on this line).


> http_access allow authenticated
> ..
> 
> When I wanted to change the username:password for user2, I run a bash script to change it in squid.conf and also in htpassword and then I run "squid -k reconfigure", if I don't reconfigure the old user still has access to the proxy and the new one doesn't for about 30 minutes.
> 

No need to restart for that change. The helper you have there will 
automatically detect changes to the htpassword file and reload it.

It is a little odd that the new user was not able to authenticate. Check 
that your test did not lookup and cache a non-existence result for them 
prior to being added.


The delay is due to the credentials being valid for a period of time. To 
reduce workload on the auth system Squid caches credential details for a 
while.

Set "auth_param basic credentialsttl " to shorter values to reduce the 
delay (default is 2hrs).


> I am expecting to have 100s of users soon that will change credentials often, and also I would like to blacklist websites often and on the fly, so I was searching for a better way to manage this without reconfiguring every time, since sometimes a reconfigure can take up to 10-15 seconds.
> 

This helper does not need a reconfigure at all as far as I can tell from 
the code.

All the reconfigure was doing for you previously was triggering an early 
prune of the records in the credentials cache. Probably why you saw 
about 30min delay instead of about 2hrs.


> I am new to Squid and wasn't able to find any info on this, am I doing this currently or there is a better way to change users/ACLs on the fly without reloading Squid?
> 

Config changes in squid.conf itself needs a reconfigure or sometimes a 
restart.


For auth and ACLs whose values that come into Squid from a helper it 
depends on the helper itself. Most can auto-detect changes to their 
background databases and not need anything from Squid to update the 
outputs. All helpers do have some form of caching of their results by 
Squid, so there are settings in squid.conf to tune that to your needs - 
as you can see from the auth issue above.


For ACLs with values that are expected to change often it is best to use 
an external_acl_type helper that manages the updates or fetches from 
somewhere the updates are handled without a reload.



Amos


From squid3 at treenet.co.nz  Sat Oct 31 16:09:09 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 1 Nov 2020 05:09:09 +1300
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading
In-Reply-To: <20201030142034.GA41498@thismonkey.com>
References: <mailman.0.1603886401.20089.squid-users@lists.squid-cache.org>
 <20201028230640.GA70286@thismonkey.com>
 <3492e3df-e38b-2af9-9029-f49d4203f5e9@treenet.co.nz>
 <20201030022731.GA76846@thismonkey.com>
 <048c5f54-64ff-1c73-7c0b-b9ad235341f0@treenet.co.nz>
 <20201030142034.GA41498@thismonkey.com>
Message-ID: <49d903ca-8723-0a6a-fcd2-c6a892a36e21@treenet.co.nz>

On 31/10/20 3:20 am, Scott wrote:
> On Sat, Oct 31, 2020 at 12:49:16AM +1300, Amos Jeffries wrote:
>> On 30/10/20 3:27 pm, Scott wrote:
>>> On Thu, Oct 29, 2020 at 10:08:42PM +1300, Amos Jeffries wrote:
>>>> On 29/10/20 12:06 pm, Scott wrote:
>>>>> On Wed, Oct 28, 2020 at 12:00:01PM +0000, squid-users-reques wrote:
>>>>>> Date: Thu, 29 Oct 2020 00:08:34 +1300
>>>>>> From: Amos Jeffries
>>>>>>
>>>>>> On 28/10/20 5:25 pm, Scott wrote:
>>>>>>>
>>>>>>> Here are the logs (first not working, followed by working).
>>>>>>>
>>>>>>> Note this is the login attempt, not the loading of the initial page.  You'll
>>>>>>> see in the NOT WORKING section that the browser does NOT return a cookie to
>>>>>>> the server, which is where the problem may be.  Again, I'm not sure why - I'm
>>>>>>> thinking perhaps the browser/javascript is rejecting the cookie as it's
>>>>>>> missing the "secure" attribute (because the back-end is talking plain HTTP).
>>>>>>>
>>>>>>
>>>>>> The complete absence of a cookie may be expected to break something.
>>>>>>
>>>>>> The absence of a "secure" flag should only make the cookie vulnerable to
>>>>>> leaking. It should not affect anything depending on that cookies value.
>>>>>>
>>>>>>
>>>>>> Amos
>>>>>>
>>>>>
>>>>> After some more research and experimentation I've confirmed that my
>>>>> suspicions are correct.
>>>>>
>>>>> Recent browsers are no longer accepting cookies with the SameSite flag set
>>>>> without the Secure flag set.
>>>>>
>>>>> It's not an issue with Squid (although one Squid could solve - but I'm unsure
>>>>> of the implications).
>>>>
>>>> Implications are that the server may have intentionally used the
>>>> combination it did, no mistakes.
>>>>
>>>> The server is given "Front-End-Https: On" so that it is aware the client
>>>> is using HTTPS and can set (or not) the secure flag appropriately to
>>>> what it needs. Squid is not aware of whether the cookie is safe to use
>>>> on HTTP or restrict to just HTTPS.
>>>>
>>>>
>>>>>
>>>>> Here is a useful link:
>>>>> https://docs.microsoft.com/en-us/office365/troubleshoot/miscellaneous/chrome-behavior-affects-applications
>>>>>
>>>>> I tested Chrome 85 on Windows - the default settings DO NOT allow for these
>>>>> cookies.  However after setting
>>>>> 	Cookies without SameSite must be secure
>>>>> to Disabled, these cookies are permitted and OWA works.
>>>>>
>>>>> There are obvious implications for sites doing SSL offloading here.  Are
>>>>> sites no longer doing SSL offload?  Or are reverse proxies adding the Secure
>>>>> flag?
>>>>
>>>>
>>>> Neither. When a site frontend is entirely https:// with no http://
>>>> resources mixed in the Secure flag can be used by the server regardless
>>>> of what the internal connections are.
>>>>
>>>>
>>>> Amos
>>>
>>> My point is that, assuming browsers are now enforcing SameSite cookies must
>>> be secure, then doing SSL offload (whereby the origin server does NOT flag
>>> the cookie as secure) will break.
>>
>> But offloading does not mean the server omits the secure flag.
>>
>> Servers which choose to send it when offloading work fine. Servers that
>> choose to omit it have problems with the Google paranoid interpretation
>> of security.
> 
> Aren't origin servers oblivious to SSL offloading?  I thought they just
> happily accepted HTTP connections with no knowledge of any secure channel
> between client and reverse proxy.


It varies.  Mozilla have a brief writeup about the headers used:
<https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Forwarded-Proto>


> 
> If that's correct then, although not proscribed by the RFC, it's unlikely
> that a Set-Cookie header would ever contain a Secure flag because the server
> would be saying "I insist this Cookie be transmitted securely, but here it is
> over an insecure channel".
> 

That assumes the only type of security is HTTPS. The channel between 
proxy and server may be secured via other means than TLS, even as it 
transmits "plain text" HTTP.

There should be server settings to administrate that. I do not use OWA 
or IIS though, so now sure if they are available for your case.


>>>
>>> In this particular case, I use squid to do reverse proxy with SSL offload to
>>> a MS Exchange server.
>>
>> You also have a TLS connection to the exchange:443 peer.
> 
> I have both for testing, but only one is active at any one time (as
> referenced in a cache_peer_access).  Yes I now use the 443 peer because
> Chrome/IE/Edge + SSL Offloading no longer works.
> 

Please understand that with Squid acting as a reverse-proxy "offloading" 
is still happening. It is the cert you put in the https_port in 
Squid.conf that the clients are dealing with, and Squid which is doing 
any client cert validation.


For working security on the cache_peer you should identify the CA cert 
which signed the peer server's TLS certificate. Load that into Squid as 
cache_peer tls-cafile=  and you can drop the DONT_VERIFY_PEER flag.


>>
>> Notice that in the logs you showed transactions sent to that peer get
>> the secure flag set, despite the SSL offload being done by Squid at the
>> same time.
>>
>>
> 
> Not true AFAICT.  Any cookies you see in those logs with Secure set are shown
> under the "WORKING" heading whose entries are:
> 2020/10/28 12:01:23.549 kid1| 11,2| http.cc(2263) sendRequest: HTTP Server local=squid-internal:62597 remote=exchange:443 FD 30 flags=1
> 
> No SSL offloading there.  Otherwise it would say "remote=exchange:80"
> 

Squid is receiving the HTTP(S) message. That means Squid is terminating 
the TLS from client, decrypting the traffic. Which is offloading.

The connection to the server is independent. Squid will actually be 
multiplexing traffic for multiple clients on that connection. No client 
has participation or knowledge of that TLS existence.


A non-offloading setup would be a CONNECT tunnel through Squid to the 
server so TLS can be negotiated between client and server.




>>
>>> Because the requests are HTTP IIS does not set the secure flag on cookies,
>>> and browsers now reject them.  This breaks things.
>>>
>>> I've fixed it by switching back to HTTPS on the backend (no SSL offload), and
>>> so the secure flag is now being set by IIS.  Problem solved.
>>>
>>> In the long term it seems doing SSL offload to MS Exchange (and Sharepoint I
>>> think) will not be an option.  I've seen other proxy manufacturers provide
>>> cookie manipulation; I assume for this kind of issue.
>>>
>>> Do you think Squid should have such a feature?
>>
>> We have ICAP, eCAP, and *_header_replace features already. So any
>> proposed new feature would have to be better than what they already provide.
>>
> 
> Unless I'm reading the online command reference incorrectly, *_header_replace
> does not allow for the insertion of text so can't help here.  Please tell me
> I'm wrong - I'd love for Squid to have this capability like other proxies.


Aye. There are limits and issues with all those features. I was speaking 
there about what a new feature proposal would need to work with for 
consideration.


The options right now are (in order of preference):

* create an eCAP module that just edits the headers as-needed.

* create an ICAP service to do header edits as-needed.

* create an external_acl_type helper that takes the reply headers as 
input and delivers Squid a set of annotations that can be injected as 
Set-Cookie headers by http_reply_header_add. With *header_access to 
remove broken values first.

* new feature in Squid.


Amos


From squid3 at treenet.co.nz  Sat Oct 31 16:10:34 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 1 Nov 2020 05:10:34 +1300
Subject: [squid-users] Reverse proxying Exchange OWA wembail with SSL
 offloading
In-Reply-To: <20201030142034.GA41498@thismonkey.com>
References: <mailman.0.1603886401.20089.squid-users@lists.squid-cache.org>
 <20201028230640.GA70286@thismonkey.com>
 <3492e3df-e38b-2af9-9029-f49d4203f5e9@treenet.co.nz>
 <20201030022731.GA76846@thismonkey.com>
 <048c5f54-64ff-1c73-7c0b-b9ad235341f0@treenet.co.nz>
 <20201030142034.GA41498@thismonkey.com>
Message-ID: <391b8f63-748b-4151-16e8-985d20df30cc@treenet.co.nz>

On 31/10/20 3:20 am, Scott wrote:
> On Sat, Oct 31, 2020 at 12:49:16AM +1300, Amos Jeffries wrote:
>> On 30/10/20 3:27 pm, Scott wrote:
>>> On Thu, Oct 29, 2020 at 10:08:42PM +1300, Amos Jeffries wrote:
>>>> On 29/10/20 12:06 pm, Scott wrote:
>>>>> On Wed, Oct 28, 2020 at 12:00:01PM +0000, squid-users-reques wrote:
>>>>>> Date: Thu, 29 Oct 2020 00:08:34 +1300
>>>>>> From: Amos Jeffries
>>>>>>
>>>>>> On 28/10/20 5:25 pm, Scott wrote:
>>>>>>>
>>>>>>> Here are the logs (first not working, followed by working).
>>>>>>>
>>>>>>> Note this is the login attempt, not the loading of the initial page.  You'll
>>>>>>> see in the NOT WORKING section that the browser does NOT return a cookie to
>>>>>>> the server, which is where the problem may be.  Again, I'm not sure why - I'm
>>>>>>> thinking perhaps the browser/javascript is rejecting the cookie as it's
>>>>>>> missing the "secure" attribute (because the back-end is talking plain HTTP).
>>>>>>>
>>>>>>
>>>>>> The complete absence of a cookie may be expected to break something.
>>>>>>
>>>>>> The absence of a "secure" flag should only make the cookie vulnerable to
>>>>>> leaking. It should not affect anything depending on that cookies value.
>>>>>>
>>>>>>
>>>>>> Amos
>>>>>>
>>>>>
>>>>> After some more research and experimentation I've confirmed that my
>>>>> suspicions are correct.
>>>>>
>>>>> Recent browsers are no longer accepting cookies with the SameSite flag set
>>>>> without the Secure flag set.
>>>>>
>>>>> It's not an issue with Squid (although one Squid could solve - but I'm unsure
>>>>> of the implications).
>>>>
>>>> Implications are that the server may have intentionally used the
>>>> combination it did, no mistakes.
>>>>
>>>> The server is given "Front-End-Https: On" so that it is aware the client
>>>> is using HTTPS and can set (or not) the secure flag appropriately to
>>>> what it needs. Squid is not aware of whether the cookie is safe to use
>>>> on HTTP or restrict to just HTTPS.
>>>>
>>>>
>>>>>
>>>>> Here is a useful link:
>>>>> https://docs.microsoft.com/en-us/office365/troubleshoot/miscellaneous/chrome-behavior-affects-applications
>>>>>
>>>>> I tested Chrome 85 on Windows - the default settings DO NOT allow for these
>>>>> cookies.  However after setting
>>>>> 	Cookies without SameSite must be secure
>>>>> to Disabled, these cookies are permitted and OWA works.
>>>>>
>>>>> There are obvious implications for sites doing SSL offloading here.  Are
>>>>> sites no longer doing SSL offload?  Or are reverse proxies adding the Secure
>>>>> flag?
>>>>
>>>>
>>>> Neither. When a site frontend is entirely https:// with no http://
>>>> resources mixed in the Secure flag can be used by the server regardless
>>>> of what the internal connections are.
>>>>
>>>>
>>>> Amos
>>>
>>> My point is that, assuming browsers are now enforcing SameSite cookies must
>>> be secure, then doing SSL offload (whereby the origin server does NOT flag
>>> the cookie as secure) will break.
>>
>> But offloading does not mean the server omits the secure flag.
>>
>> Servers which choose to send it when offloading work fine. Servers that
>> choose to omit it have problems with the Google paranoid interpretation
>> of security.
> 
> Aren't origin servers oblivious to SSL offloading?  I thought they just
> happily accepted HTTP connections with no knowledge of any secure channel
> between client and reverse proxy.


It varies.  Mozilla have a brief writeup about the headers used:
<https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Forwarded-Proto>


> 
> If that's correct then, although not proscribed by the RFC, it's unlikely
> that a Set-Cookie header would ever contain a Secure flag because the server
> would be saying "I insist this Cookie be transmitted securely, but here it is
> over an insecure channel".
> 

That assumes the only type of security is HTTPS. The channel between 
proxy and server may be secured via other means than TLS, even as it 
transmits "plain text" HTTP.

There should be server settings to administrate that. I do not use OWA 
or IIS though, so now sure if they are available for your case.


>>>
>>> In this particular case, I use squid to do reverse proxy with SSL offload to
>>> a MS Exchange server.
>>
>> You also have a TLS connection to the exchange:443 peer.
> 
> I have both for testing, but only one is active at any one time (as
> referenced in a cache_peer_access).  Yes I now use the 443 peer because
> Chrome/IE/Edge + SSL Offloading no longer works.
> 

Please understand that with Squid acting as a reverse-proxy "offloading" 
is still happening. It is the cert you put in the https_port in 
Squid.conf that the clients are dealing with, and Squid which is doing 
any client cert validation.


For working security on the cache_peer you should identify the CA cert 
which signed the peer server's TLS certificate. Load that into Squid as 
cache_peer tls-cafile=  and you can drop the DONT_VERIFY_PEER flag.


>>
>> Notice that in the logs you showed transactions sent to that peer get
>> the secure flag set, despite the SSL offload being done by Squid at the
>> same time.
>>
>>
> 
> Not true AFAICT.  Any cookies you see in those logs with Secure set are shown
> under the "WORKING" heading whose entries are:
> 2020/10/28 12:01:23.549 kid1| 11,2| http.cc(2263) sendRequest: HTTP Server local=squid-internal:62597 remote=exchange:443 FD 30 flags=1
> 
> No SSL offloading there.  Otherwise it would say "remote=exchange:80"
> 

Squid is receiving the HTTP(S) message. That means Squid is terminating 
the TLS from client, decrypting the traffic. Which is what I understand 
to be offloading.

The connection to the server is independent. Squid will actually be 
multiplexing traffic for multiple clients on that connection. No client 
has participation or knowledge of that TLS existence.


Non-offloading would be a CONNECT tunnel through Squid to the server so 
TLS can be negotiated directly between client and server.


>>
>>> Because the requests are HTTP IIS does not set the secure flag on cookies,
>>> and browsers now reject them.  This breaks things.
>>>
>>> I've fixed it by switching back to HTTPS on the backend (no SSL offload), and
>>> so the secure flag is now being set by IIS.  Problem solved.
>>>
>>> In the long term it seems doing SSL offload to MS Exchange (and Sharepoint I
>>> think) will not be an option.  I've seen other proxy manufacturers provide
>>> cookie manipulation; I assume for this kind of issue.
>>>
>>> Do you think Squid should have such a feature?
>>
>> We have ICAP, eCAP, and *_header_replace features already. So any
>> proposed new feature would have to be better than what they already provide.
>>
> 
> Unless I'm reading the online command reference incorrectly, *_header_replace
> does not allow for the insertion of text so can't help here.  Please tell me
> I'm wrong - I'd love for Squid to have this capability like other proxies.


Aye. There are limits and issues with all those features. I was speaking 
there about what a new feature proposal would need to work with for 
consideration.


The options right now are (in order of preference):

* create an eCAP module that just edits the headers as-needed.

* create an ICAP service to do header edits as-needed.

* create an external_acl_type helper that takes the reply headers as 
input and delivers Squid a set of annotations that can be injected as 
Set-Cookie headers by http_reply_header_add. With *header_access to 
remove broken values first.

* new feature in Squid.


Amos


From roeeklinger60 at gmail.com  Sat Oct 31 23:27:06 2020
From: roeeklinger60 at gmail.com (roee klinger)
Date: Sun, 1 Nov 2020 01:27:06 +0200
Subject: [squid-users] Best practice for adding or removing ACLs
 dynamically ?
In-Reply-To: <e7119d05-4ab8-59f3-b616-dd7ce2d48ccb@treenet.co.nz>
References: <75C05DB7-2C0E-4B77-88A4-66F581A035ED@gmail.com>
 <e7119d05-4ab8-59f3-b616-dd7ce2d48ccb@treenet.co.nz>
Message-ID: <CAGCa14qSmFGD3+ercC2JDEa3WKeLmU1d9scEgoWYWCUzztx7ww@mail.gmail.com>

Thanks Amos!

I updated "auth_param basic credentialsttl" according to your advice and it
is working great.

I am still having issues with the "tcp_outgoing_address 192.168.8.12
acl_for_user3002" part, you mentioned:
> For ACLs with values that are expected to change often it is best to use
> an external_acl_type helper that manages the updates or fetches from
> somewhere the updates are handled without a reload.

My script updates the authenticator successfully, but when I update "acl
acl_for_user3002 proxy_auth user2" to the new username I have to
reconfigure to take effect.
I read online for hours but to my best understanding external_acl_type are
for auth and access control, but they don't work for my needs I believe.

Is there any way to use external_acl_type in a way I don't understand to
solve this problem? Do I have to reconfigure every time I make changes to
an ACL in squid.conf?

Thanks again for your help.

On Sat, Oct 31, 2020 at 5:48 PM Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 31/10/20 1:34 pm, roee klinger wrote:
> > ?
> > Hey,
> > I have Squid configured to send users to different outgoing interface
> like so:
> >
> > ..
> > auth_param basic program /usr/lib/squid/basic_ncsa_auth
> /etc/squid/htpassword
> > acl acl_for_user3002 proxy_auth user2
> > tcp_outgoing_address 192.168.8.12 acl_for_user3002
> > http_port 3002 name=3002
>
>
> No need to name a *_port like this. The default name is the first
> parameter string ("3002" on this line).
>
>
> > http_access allow authenticated
> > ..
> >
> > When I wanted to change the username:password for user2, I run a bash
> script to change it in squid.conf and also in htpassword and then I run
> "squid -k reconfigure", if I don't reconfigure the old user still has
> access to the proxy and the new one doesn't for about 30 minutes.
> >
>
> No need to restart for that change. The helper you have there will
> automatically detect changes to the htpassword file and reload it.
>
> It is a little odd that the new user was not able to authenticate. Check
> that your test did not lookup and cache a non-existence result for them
> prior to being added.
>
>
> The delay is due to the credentials being valid for a period of time. To
> reduce workload on the auth system Squid caches credential details for a
> while.
>
> Set "auth_param basic credentialsttl " to shorter values to reduce the
> delay (default is 2hrs).
>
>
> > I am expecting to have 100s of users soon that will change credentials
> often, and also I would like to blacklist websites often and on the fly, so
> I was searching for a better way to manage this without reconfiguring every
> time, since sometimes a reconfigure can take up to 10-15 seconds.
> >
>
> This helper does not need a reconfigure at all as far as I can tell from
> the code.
>
> All the reconfigure was doing for you previously was triggering an early
> prune of the records in the credentials cache. Probably why you saw
> about 30min delay instead of about 2hrs.
>
>
> > I am new to Squid and wasn't able to find any info on this, am I doing
> this currently or there is a better way to change users/ACLs on the fly
> without reloading Squid?
> >
>
> Config changes in squid.conf itself needs a reconfigure or sometimes a
> restart.
>
>
> For auth and ACLs whose values that come into Squid from a helper it
> depends on the helper itself. Most can auto-detect changes to their
> background databases and not need anything from Squid to update the
> outputs. All helpers do have some form of caching of their results by
> Squid, so there are settings in squid.conf to tune that to your needs -
> as you can see from the auth issue above.
>
>
> For ACLs with values that are expected to change often it is best to use
> an external_acl_type helper that manages the updates or fetches from
> somewhere the updates are handled without a reload.
>
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20201101/3a8c242e/attachment.htm>

