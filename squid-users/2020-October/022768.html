<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] ACL matches when it shouldn't
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20ACL%20matches%20when%20it%20shouldn%27t&In-Reply-To=%3C603c5ae1-9fbe-c67e-08e1-a1b5c279cbad%40urlfilterdb.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="022767.html">
   <LINK REL="Next"  HREF="022761.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] ACL matches when it shouldn't</H1>
    <B>Marcus Kool</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20ACL%20matches%20when%20it%20shouldn%27t&In-Reply-To=%3C603c5ae1-9fbe-c67e-08e1-a1b5c279cbad%40urlfilterdb.com%3E"
       TITLE="[squid-users] ACL matches when it shouldn't">marcus.kool at urlfilterdb.com
       </A><BR>
    <I>Fri Oct  2 10:28:57 UTC 2020</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="022767.html">[squid-users] ACL matches when it shouldn't
</A></li>
        <LI>Next message (by thread): <A HREF="022761.html">[squid-users] measuring latency of squid in different scenarios
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#22768">[ date ]</a>
              <a href="thread.html#22768">[ thread ]</a>
              <a href="subject.html#22768">[ subject ]</a>
              <a href="author.html#22768">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Of course this script is sluggish since it reads many category files and forks at least 3-6 times.

If you *really* want to implement this with a perl script, it should read all files at startup and the script does a lookup using perl data structures.

But I suggest to look at ufdbGuard which is a URL filter that is way faster and has all functionality that you need.

Marcus


On 2020-10-02 10:08, Vieri wrote:
&gt;<i> Regarding the use of an external ACL I quickly implemented a perl script that &quot;does the job&quot;, but it seems to be somewhat sluggish.
</I>&gt;<i>
</I>&gt;<i> This is how it's configured in squid.conf:
</I>&gt;<i> external_acl_type bllookup ttl=86400 negative_ttl=86400 children-max=80 children-startup=10 children-idle=3 concurrency=8 %PROTO %DST %PORT %PATH /opt/custom/scripts/squid/ext_txt_blwl_acl.pl --categories=adv,aggressive,alcohol,anonvpn,automobile_bikes,automobile_boats,automobile_cars,automobile_planes,chat,costtraps,dating,drugs,dynamic,finance_insurance,finance_moneylending,finance_other,finance_realestate,finance_trading,fortunetelling,forum,gamble,hacking,hobby_cooking,hobby_games-misc,hobby_games-online,hobby_gardening,hobby_pets,homestyle,ibs,imagehosting,isp,jobsearch,military,models,movies,music,podcasts,politics,porn,radiotv,recreation_humor,recreation_martialarts,recreation_restaurants,recreation_sports,recreation_travel,recreation_wellness,redirector,religion,remotecontrol,ringtones,science_astronomy,science_chemistry,sex_education,sex_lingerie,shopping,socialnet,spyware,tracker,updatesites,urlshortener,violence,warez,weapons,webphone,webradio,webtv
</I>&gt;<i>
</I>&gt;<i> I'd like to avoid the use of a DB if possible, but maybe someone here has an idea to share on flat file text searches.
</I>&gt;<i>
</I>&gt;<i> Currently the dir structure of my blacklists is:
</I>&gt;<i>
</I>&gt;<i> topdir
</I>&gt;<i> category1 ... categoryN
</I>&gt;<i> domains urls
</I>&gt;<i>
</I>&gt;<i> So basically one example file to search in is topdir/category8/urls, etc.
</I>&gt;<i>
</I>&gt;<i> The helper perl script contains this code to decide whether to block access or not:
</I>&gt;<i>
</I>&gt;<i> foreach( @categories )
</I>&gt;<i> {
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160; chomp($s_urls = qx{grep -nwx '$uri_dst$uri_path' $cats_where/$_/urls | head -n 1 | cut -f1 -d:});
</I>&gt;<i>
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160; if (length($s_urls) &gt; 0) {
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; if ($whitelist == 0) {
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; $status = $cid.&quot; ERR message=\&quot;URL &quot;.$uri_dst.&quot; in BL &quot;.$_.&quot; (line &quot;.$s_urls.&quot;)\&quot;&quot;;
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; } else {
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; $status = $cid.&quot; ERR message=\&quot;URL &quot;.$uri_dst.&quot; not in WL &quot;.$_.&quot; (line &quot;.$s_urls.&quot;)\&quot;&quot;;
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; next;
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160; }
</I>&gt;<i>
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160; chomp($s_urls = qx{grep -nwx '$uri_dst' $cats_where/$_/domains | head -n 1 | cut -f1 -d:});
</I>&gt;<i>
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160; if (length($s_urls) &gt; 0) {
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; if ($whitelist == 0) {
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; $status = $cid.&quot; ERR message=\&quot;Domain &quot;.$uri_dst.&quot; in BL &quot;.$_.&quot; (line &quot;.$s_urls.&quot;)\&quot;&quot;;
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; } else {
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; $status = $cid.&quot; ERR message=\&quot;Domain &quot;.$uri_dst.&quot; not in WL &quot;.$_.&quot; (line &quot;.$s_urls.&quot;)\&quot;&quot;;
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; }
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; next;
</I>&gt;<i>  &#160;&#160;&#160;&#160;&#160;&#160;&#160; }
</I>&gt;<i> }
</I>&gt;<i>
</I>&gt;<i> There are currently 66 &quot;categories&quot; with around 50MB of text data in all.
</I>&gt;<i> So that's a lot to go through each time there's an HTTP request.
</I>&gt;<i> Apart from placing these blacklists on a ramdisk (currently on an M.2 SSD disk so I'm not sure I'll notice anything) what else can I try?
</I>&gt;<i> Should I reindex the lists and group them all alphabetically?
</I>&gt;<i> For instance should I process the lists in order to generate a dir structure as follows?
</I>&gt;<i>
</I>&gt;<i> topdir
</I>&gt;<i> a b c d e f ... x y z 0 1 2 3 ... 7 8 9
</I>&gt;<i> domains urls
</I>&gt;<i>
</I>&gt;<i> An example for a client requesting <A HREF="https://www.google.com/">https://www.google.com/</A> would lead to searching only 2 files:
</I>&gt;<i> topdir/w/domains
</I>&gt;<i> topdir/w/urls
</I>&gt;<i>
</I>&gt;<i> An example for a client requesting <A HREF="https://01.whatever.com/x">https://01.whatever.com/x</A> would also lead to searching only 2 files:
</I>&gt;<i> topdir/0/domains
</I>&gt;<i> topdir/0/urls
</I>&gt;<i>
</I>&gt;<i> An example for a client requesting <A HREF="https://8.8.8.8/xyz">https://8.8.8.8/xyz</A> would also lead to searching only 2 files:
</I>&gt;<i> topdir/8/domains
</I>&gt;<i> topdir/8/urls
</I>&gt;<i>
</I>&gt;<i> Any ideas or links to scripts that already prepare lists for this?
</I>&gt;<i>
</I>&gt;<i> Thanks,
</I>&gt;<i>
</I>&gt;<i> Vieri
</I>&gt;<i> _______________________________________________
</I>&gt;<i> squid-users mailing list
</I>&gt;<i> <A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users at lists.squid-cache.org</A>
</I>&gt;<i> <A HREF="http://lists.squid-cache.org/listinfo/squid-users">http://lists.squid-cache.org/listinfo/squid-users</A>
</I>
</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="022767.html">[squid-users] ACL matches when it shouldn't
</A></li>
	<LI>Next message (by thread): <A HREF="022761.html">[squid-users] measuring latency of squid in different scenarios
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#22768">[ date ]</a>
              <a href="thread.html#22768">[ thread ]</a>
              <a href="subject.html#22768">[ subject ]</a>
              <a href="author.html#22768">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
