From anon.amish at gmail.com  Tue Sep  1 06:32:05 2020
From: anon.amish at gmail.com (Amish)
Date: Tue, 1 Sep 2020 12:02:05 +0530
Subject: [squid-users] squid.service with Type=Notify is not always reliable
 (Arch Linux)
Message-ID: <40fe50ea-6c26-63cc-de32-ba8366d0d234@gmail.com>

Hello,

I have frequently observed an issue with squid.service but I am not able 
to detect the real cause. As mostly it works but sometimes does not.

I am using Arch Linux with squid 4.13 (but I had noticed same issue in 
4.10 as well)

Most likely I am noticing this issue ever since service Type was changed 
from forking to notify in squid.service

Commit: 
https://github.com/squid-cache/squid/commit/6fa8c66435d55a2e713db0222cdca3a9dccf5bbe

What happens is squid starts correctly, but systemd does not seem to be 
getting the notification from squid that it has started.

Sep 01 06:40:04 foo systemd[1]: Starting Squid Web Proxy Server...
Sep 01 06:41:34 foo systemd[1]: squid.service: start operation timed 
out. Terminating.
Sep 01 06:42:06 foo systemd[1]: squid.service: Failed with result 'timeout'.
Sep 01 06:42:06 foo systemd[1]: Failed to start Squid Web Proxy Server.

Then it kills squid process.

Squid cache.log shows no error w.r.t. notify and seems to start correctly.

What surprises me is that it works most of the times. Just randomly the 
above timeout error occurs.

If in service override file, I change type to forking and remove 
--foreground. It starts working again.

Like this: (comment lines are original lines when the issue occurs)

[Service]
#Type=notify
Type=forking
ExecStart=
#ExecStart=/usr/bin/squid -f /etc/squid/custom.conf --foreground -sYC
ExecStart=/usr/bin/squid -f /etc/squid/custom.conf -sYC

Any idea what could be issue? Is there any squid.conf setting which I 
may using and stopping notify randomly?

Any help would be highly appreciated.

Thanks and regards,

Amish



From Ralf.Hildebrandt at charite.de  Tue Sep  1 07:51:14 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 1 Sep 2020 09:51:14 +0200
Subject: [squid-users] New log message: "Bad header encountered from..."
Message-ID: <20200901075114.fsgxoyxlcqbdkzg4@charite.de>

This may just be coincidence, but in the last one or two days I'm
seeing those log entries:

2020/09/01 07:56:36| WARNING: HTTP: Invalid Response: Bad header encountered from http://dev-ci.id-berlin.de:9090/builds/iknow/iknow.jar.md5 AKA http://dev-ci.id-berlin.de:9090/builds/iknow/iknow.jar.md5
    current master transaction: master46663356

quite often. What is the bad header here:

HTTP/1.0 200 OK
Server: ID DIACOS App-Server
Date: Tue Sep 01 09:50:41 CEST 2020
Content-Length: 74
Last Modified: Thu Feb 13 13:06:30 CET 2020


Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From squid3 at treenet.co.nz  Tue Sep  1 09:48:40 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 1 Sep 2020 21:48:40 +1200
Subject: [squid-users] New log message: "Bad header encountered from..."
In-Reply-To: <20200901075114.fsgxoyxlcqbdkzg4@charite.de>
References: <20200901075114.fsgxoyxlcqbdkzg4@charite.de>
Message-ID: <0afc1a16-a556-b648-9ceb-117f86b1a3c3@treenet.co.nz>

On 1/09/20 7:51 pm, Ralf Hildebrandt wrote:
> This may just be coincidence, but in the last one or two days I'm
> seeing those log entries:
> 
> 2020/09/01 07:56:36| WARNING: HTTP: Invalid Response: Bad header encountered from http://dev-ci.id-berlin.de:9090/builds/iknow/iknow.jar.md5 AKA http://dev-ci.id-berlin.de:9090/builds/iknow/iknow.jar.md5
>     current master transaction: master46663356
> 
> quite often. What is the bad header here:
> 
> HTTP/1.0 200 OK
> Server: ID DIACOS App-Server
> Date: Tue Sep 01 09:50:41 CEST 2020
> Content-Length: 74
> Last Modified: Thu Feb 13 13:06:30 CET 2020
> 
> 

"Last Modified" is not a valid header name (whitespace is forbidden).

Also both headers containing timestamps have invalid formats. They
should look like below, including the "GMT" timezone:
  Date: Mon, 31 Aug 2020 17:37:40 GMT

Amos


From rousskov at measurement-factory.com  Tue Sep  1 13:47:08 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 1 Sep 2020 09:47:08 -0400
Subject: [squid-users] squid.service with Type=Notify is not always
 reliable (Arch Linux)
In-Reply-To: <40fe50ea-6c26-63cc-de32-ba8366d0d234@gmail.com>
References: <40fe50ea-6c26-63cc-de32-ba8366d0d234@gmail.com>
Message-ID: <b2df83c6-1214-4493-abbd-79c542e883bb@measurement-factory.com>

On 9/1/20 2:32 AM, Amish wrote:

> I have frequently observed an issue with squid.service but I am not able
> to detect the real cause. As mostly it works but sometimes does not.

> What happens is squid starts correctly, but systemd does not seem to be
> getting the notification from squid that it has started.

> Sep 01 06:40:04 foo systemd[1]: Starting Squid Web Proxy Server...
> Sep 01 06:41:34 foo systemd[1]: squid.service: start operation timed out. Terminating.
> Sep 01 06:42:06 foo systemd[1]: squid.service: Failed with result 'timeout'.
> Sep 01 06:42:06 foo systemd[1]: Failed to start Squid Web Proxy Server.

When did your Squid workers print their "Accepting ... connections at
..." message(s)? Those messages will give you the approximate time of
sd_notify() calls made by Squid workers.


> Squid cache.log shows no error w.r.t. notify and seems to start correctly.

AFAICT, Squid code does not report sd_notify() failure to notify iff
that failure was due to an unset $NOTIFY_SOCKET variable. The first
sd_notify() call in Squid also unsets $NOTIFY_SOCKET variable (in the
calling worker). However, I cannot explain why that variable would be
unset during the first sd_notify() call _sometimes_.

Perhaps systemd is confused by concurrent notifications coming from
multiple workers?

Can you enable some kind of sd_notify() debugging that would show us
what the first sd_notify() call was doing and when/whether systemd
received the notification from Squid?

Alex.


From anon.amish at gmail.com  Tue Sep  1 14:27:08 2020
From: anon.amish at gmail.com (Amish)
Date: Tue, 1 Sep 2020 19:57:08 +0530
Subject: [squid-users] squid.service with Type=Notify is not always
 reliable (Arch Linux)
In-Reply-To: <b2df83c6-1214-4493-abbd-79c542e883bb@measurement-factory.com>
References: <40fe50ea-6c26-63cc-de32-ba8366d0d234@gmail.com>
 <b2df83c6-1214-4493-abbd-79c542e883bb@measurement-factory.com>
Message-ID: <dbc68688-a688-5f10-dc5b-089f6eae2d24@gmail.com>


On 01/09/20 7:17 pm, Alex Rousskov wrote:
> On 9/1/20 2:32 AM, Amish wrote:
>
>> I have frequently observed an issue with squid.service but I am not able
>> to detect the real cause. As mostly it works but sometimes does not.
>> What happens is squid starts correctly, but systemd does not seem to be
>> getting the notification from squid that it has started.
>> Sep 01 06:40:04 foo systemd[1]: Starting Squid Web Proxy Server...
>> Sep 01 06:41:34 foo systemd[1]: squid.service: start operation timed out. Terminating.
>> Sep 01 06:42:06 foo systemd[1]: squid.service: Failed with result 'timeout'.
>> Sep 01 06:42:06 foo systemd[1]: Failed to start Squid Web Proxy Server.
> When did your Squid workers print their "Accepting ... connections at
> ..." message(s)? Those messages will give you the approximate time of
> sd_notify() calls made by Squid workers.

Accepting ... connections at ...? message came almost immediately (in 1 
second).

Sep 01 06:40:05 foo squid[8446]: Set Current Directory to /var/cache/squid
Sep 01 06:40:05 foo squid[8446]: Starting Squid Cache version 4.13 for 
x86_64-pc-linux-gnu...
Sep 01 06:40:05 foo squid[8446]: Service Name: squid
Sep 01 06:40:05 foo squid[8446]: Process ID 8446
Sep 01 06:40:05 foo squid[8446]: Process Roles: worker
Sep 01 06:40:05 foo squid[8446]: With 16384 file descriptors available
Sep 01 06:40:05 foo squid[8446]: Initializing IP Cache...
Sep 01 06:40:05 foo squid[8446]: DNS Socket created at [::], FD 5
Sep 01 06:40:05 foo squid[8446]: DNS Socket created at 0.0.0.0, FD 10
Sep 01 06:40:05 foo squid[8446]: Adding domain localdomain from 
/etc/resolv.conf
Sep 01 06:40:05 foo squid[8446]: Adding nameserver 127.0.0.1 from 
/etc/resolv.conf
Sep 01 06:40:05 foo squid[8446]: helperOpenServers: Starting 5/32 
'security_file_certgen' processes
Sep 01 06:40:05 foo squid[8446]: helperOpenServers: Starting 1/1 'prrdr' 
processes
Sep 01 06:40:05 foo squid[8446]: helperOpenServers: Starting 1/1 'prusr' 
processes
Sep 01 06:40:05 foo squid[8446]: Logfile: opening log 
daemon:/var/log/squid/access.log
Sep 01 06:40:05 foo squid[8446]: Logfile Daemon: opening log 
/var/log/squid/access.log
Sep 01 06:40:05 foo squid[8446]: Local cache digest enabled; 
rebuild/rewrite every 3600/3600 sec
Sep 01 06:40:05 foo squid[8446]: Store logging disabled
Sep 01 06:40:05 foo squid[8446]: Swap maxSize 0 + 262144 KB, estimated 
20164 objects
Sep 01 06:40:05 foo squid[8446]: Target number of buckets: 1008
Sep 01 06:40:05 foo squid[8446]: Using 8192 Store buckets
Sep 01 06:40:05 foo squid[8446]: Max Mem? size: 262144 KB
Sep 01 06:40:05 foo squid[8446]: Max Swap size: 0 KB
Sep 01 06:40:05 foo squid[8446]: Using Least Load store dir selection
Sep 01 06:40:05 foo squid[8446]: Set Current Directory to /var/cache/squid
Sep 01 06:40:05 foo squid[8446]: Finished loading MIME types and icons.
Sep 01 06:40:05 foo squid[8446]: HTCP Disabled.
Sep 01 06:40:05 foo squid[8446]: Squid plugin modules loaded: 0
Sep 01 06:40:05 foo squid[8446]: Adaptation support is on
Sep 01 06:40:05 foo squid[8446]: Accepting SSL bumped HTTP Socket 
connections at local=[::]:3128 remote=[::] FD 27 flags=9
Sep 01 06:40:06 foo squid[8446]: storeLateRelease: released 0 objects
Sep 01 06:40:06 foo squid[8446]: ERROR: negotiating TLS on FD 23: 
error:1416F086:SSL routines:tls_process_server_certificate:certificate 
verify failed (1/-1/0)
Sep 01 06:40:06 foo squid[8446]: ERROR: negotiating TLS on FD 26: 
error:1416F086:SSL routines:tls_process_server_certificate:certificate 
verify failed (1/-1/0)

Browser was able to access the websites after this point. Many such 
lines and then

Sep 01 06:41:26 foo squid[8446]: parse URL too large (11871 bytes)
Sep 01 06:41:26 foo squid[8446]: ERROR: negotiating TLS on FD 96: 
error:1416F086:SSL routines:tls_process_server_certificate:certificate 
verify failed (1/-1/0)
Sep 01 06:41:27 foo squid[8446]: ERROR: negotiating TLS on FD 76: 
error:1416F086:SSL routines:tls_process_server_certificate:certificate 
verify failed (1/-1/0)
Sep 01 06:41:30 foo squid[8446]: Error negotiating SSL connection on FD 
54: error:00000001:lib(0):func(0):reason(1) (1/-1)
Sep 01 06:41:32 foo squid[8446]: ERROR: negotiating TLS on FD 78: 
error:1416F086:SSL routines:tls_process_server_certificate:certificate 
verify failed (1/-1/0)
Sep 01 06:41:33 foo squid[8446]: ERROR: negotiating TLS on FD 90: 
error:1416F086:SSL routines:tls_process_server_certificate:certificate 
verify failed (1/-1/0)
Sep 01 06:41:33 foo squid[8446]: ERROR: negotiating TLS on FD 95: 
error:1416F086:SSL routines:tls_process_server_certificate:certificate 
verify failed (1/-1/0)
Sep 01 06:41:34 foo systemd[1]: squid.service: start operation timed 
out. Terminating.
Sep 01 06:41:34 foo squid[8446]: Preparing for shutdown after 692 requests
Sep 01 06:41:34 foo squid[8446]: Waiting 30 seconds for active 
connections to finish
Sep 01 06:41:34 foo squid[8446]: Closing HTTP(S) port [::]:3128
Sep 01 06:42:05 foo squid[8446]: Shutdown: NTLM authentication.
Sep 01 06:42:05 foo squid[8446]: Shutdown: Negotiate authentication.
Sep 01 06:42:05 foo squid[8446]: Shutdown: Digest authentication.
Sep 01 06:42:05 foo squid[8446]: Shutdown: Basic authentication.
Sep 01 06:42:06 foo squid[8446]: Shutting down...
Sep 01 06:42:06 foo squid[8446]: storeDirWriteCleanLogs: Starting...
Sep 01 06:42:06 foo squid[8446]:?? Finished.? Wrote 0 entries.
Sep 01 06:42:06 foo squid[8446]:?? Took 0.00 seconds (? 0.00 entries/sec).
Sep 01 06:42:06 foo squid[8446]: Logfile: closing log 
daemon:/var/log/squid/access.log
Sep 01 06:42:06 foo squid[8446]: Logfile Daemon: closing log 
daemon:/var/log/squid/access.log
Sep 01 06:42:06 foo squid[8446]: Open FD READ/WRITE?? 11 
security_file_certgen #1
Sep 01 06:42:06 foo squid[8446]: Open FD READ/WRITE?? 13 
security_file_certgen #2
Sep 01 06:42:06 foo squid[8446]: Open FD UNSTARTED??? 15 
security_file_certgen #3
Sep 01 06:42:06 foo squid[8446]: Open FD UNSTARTED??? 17 
security_file_certgen #4
Sep 01 06:42:06 foo squid[8446]: Open FD UNSTARTED??? 19 
security_file_certgen #5
Sep 01 06:42:06 foo squid[8446]: Open FD READ/WRITE?? 21 prrdr #1
Sep 01 06:42:06 foo squid[8446]: Open FD READ/WRITE?? 24 prusr #1
Sep 01 06:42:06 foo squid[8446]: Open FD UNSTARTED??? 25 IPC UNIX STREAM 
Parent
Sep 01 06:42:06 foo squid[8446]: Squid Cache (Version 4.13): Exiting 
normally.
Sep 01 06:42:06 foo squid[8444]: Squid Parent: squid-1 process 8446 
exited with status 0
Sep 01 06:42:06 foo squid[8444]: Removing PID file (/run/squid.pid)
Sep 01 06:42:06 foo systemd[1]: squid.service: Failed with result 'timeout'.
Sep 01 06:42:06 foo systemd[1]: Failed to start Squid Web Proxy Server.

Not sure that parse URL line has anything to do with this bug as 
sd_notify() was expected to happen long before that.

There are 3-4 other servers (all Arch linux and squid 4.13) which I 
control, as of now they are working fine with Type=Notify.

>> Squid cache.log shows no error w.r.t. notify and seems to start correctly.
> AFAICT, Squid code does not report sd_notify() failure to notify iff
> that failure was due to an unset $NOTIFY_SOCKET variable. The first
> sd_notify() call in Squid also unsets $NOTIFY_SOCKET variable (in the
> calling worker). However, I cannot explain why that variable would be
> unset during the first sd_notify() call _sometimes_.
>
> Perhaps systemd is confused by concurrent notifications coming from
> multiple workers?
>
> Can you enable some kind of sd_notify() debugging that would show us
> what the first sd_notify() call was doing and when/whether systemd
> received the notification from Squid?

I have no idea how to do that. If you know then please do let me know.

I will try if I can. Server is production / live server, and without 
knowing how to replicate this bug, its difficult for me to test. As I 
can not have too much downtime for testing.

Thank you for your response,

Amish.


From rousskov at measurement-factory.com  Tue Sep  1 15:01:20 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 1 Sep 2020 11:01:20 -0400
Subject: [squid-users] squid.service with Type=Notify is not always
 reliable (Arch Linux)
In-Reply-To: <dbc68688-a688-5f10-dc5b-089f6eae2d24@gmail.com>
References: <40fe50ea-6c26-63cc-de32-ba8366d0d234@gmail.com>
 <b2df83c6-1214-4493-abbd-79c542e883bb@measurement-factory.com>
 <dbc68688-a688-5f10-dc5b-089f6eae2d24@gmail.com>
Message-ID: <6242263b-d765-8184-a3ae-127854902918@measurement-factory.com>

On 9/1/20 10:27 AM, Amish wrote:

> Accepting ... connections at ...? message came almost immediately (in 1
> second).
> Sep 01 06:40:05 foo squid[8446]: Accepting SSL bumped HTTP Socket
> connections at local=[::]:3128 remote=[::] FD 27 flags=9

OK, so you are not using SMP Squid and, assuming your Squid build
supports calling sd_notify(), sd_notify() was called. We need to figure
out why it had no effect. Suggested next steps:

1. Adjust Squid to print the value of $NOTIFY_SOCKET together with the
"Accepting..." line. This will confirm that the variable is set. It
should be set. This debugging can be added without fear of producing too
much info but it is unlikely to be insightful.

2. Add some kind of sd_notify() debugging that would show us what the
first sd_notify() call was doing and when/whether systemd received the
notification from Squid. I have not researched how to do that, but I am
sure it is possible. I bet there are not enough notifications happening
on your production server to cause problems, but you should practice on
a lab server first, of course.


> Not sure that parse URL line has anything to do with this bug as
> sd_notify() was expected to happen long before that.

Right. I would only worry if that line appears every time Squid starts,
indicating some kind of automated systemd-related(?) probe/test (which
fails).


HTH,

Alex.


From m_zouhairy at skno.by  Tue Sep  1 07:50:43 2020
From: m_zouhairy at skno.by (Majed Zouhairy)
Date: Tue, 01 Sep 2020 10:50:43 +0300
Subject: [squid-users] limit bandwidth
In-Reply-To: <7e727b46-dace-eb5f-17ec-dfa705c77ff8@treenet.co.nz>
References: <3d7ba9d6-aacb-8907-3440-31c1bd709615@skno.by>
 <7e727b46-dace-eb5f-17ec-dfa705c77ff8@treenet.co.nz>
Message-ID: <a81d28a8d0d2bccbb166af270f1b3315991f21ab.camel@skno.by>

On Tue, 2020-09-01 at 05:10 +1200, Amos Jeffries wrote:
> On 31/08/20 8:24 pm, Vacheslav wrote:
> > Peace,
> > 
> > been suffering for many hours so i'd rather ask for aid..
> > 
> > i'm trying to limit the flow mainly for the most maximize people
> > 
> 
> Okay.
> 
> What Squid version are you using?
> 
> 
sudo squid -v
Squid Cache: Version 4.13
Service Name: squid

> > acl slower src 10.46.0.74 10.46.0.107
> 
> One of the reasons this posting git held up for moderation was that
> the
> lines which are supposed to contain ASCII tab characters contained
> Unicode characters "\c3\82".
this is now another email client..so let's confirm that
> 
> If those Unicode characters are actually present in your squid.conf
> file
> then you need to go through and remove them all.

i went ahead and typed those added lines in nano and deleted the
original ones..still not a trump!
> 
> ...
> > acl localnet src 10.46.0.0/24		#  local private
> > network (LAN)
> 
> ...
> > acl blockfiles urlpath_regex -i "/etc/squid/blocks.files.acl"
> > 
> ...
> 
> > error_directory /usr/share/squid/errors/en
> 
> The above is a default value. Remove that line from your config.
this? error_directory /usr/share/squid/errors/en
> 
> > delay_pools 1
> > delay_class 1 3
> > delay_access 1 allow slower !localnet
> 
> All IPs which match "slower" ACL are also matched by "localnet" ACL.
> 
> It is impossible for an IP to be both part of slower and not part of
> localnet. So this line never matches and all traffic is not-delayed.
> 
> To fix, remove the "!localnet" requirement from the above line.
i already tried that, i was thinking that there would be an option like
acl slower src 10.46.0.74 10.46.0.107
acl localnet src !10.46.0.74 10.46.0.0/24
so as not type the whole subnet individual addresses


> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users




From andreas.voneuw at axa.com  Wed Sep  2 06:45:07 2020
From: andreas.voneuw at axa.com (VON EUW Andreas)
Date: Wed, 2 Sep 2020 06:45:07 +0000
Subject: [squid-users] [EXTERNAL] Re:  Squid 3.5 - icap parsing error
In-Reply-To: <dccc62c4-3426-8e4a-bc07-1eece3b6bb3e@measurement-factory.com>
References: <AM6PR04MB56533F4A3507C26D4FF704DA9D520@AM6PR04MB5653.eurprd04.prod.outlook.com>
 <189bad49-98aa-9a9b-8360-394420331ac1@treenet.co.nz>
 <dccc62c4-3426-8e4a-bc07-1eece3b6bb3e@measurement-factory.com>
Message-ID: <AM6PR04MB5653AB9FDB8195D24535F4689D2F0@AM6PR04MB5653.eurprd04.prod.outlook.com>

> Message headers are supposed to be ended by an empty line. 
> As this log entry says "failed to find end of headers" and you can see from the buffer content displayed, 
> there is no empty line.

Thank you for pointing out this. I'll try to get a fix from Symantec. 

Cheers, Andy


Ce message est confidentiel; Son contenu ne represente en aucun cas
un engagement de la part de AXA  sous reserve de tout accord conclu
par ecrit  entre vous et  AXA.  Toute publication,  utilisation  ou 
diffusion,  meme partielle,  doit etre autorisee prealablement.  Si
vous  n'etes pas  destinataire  de ce message,  merci  d'en avertir 
immediatement l'expediteur.

This message is  confidential;  its  contents  do not  constitute a
commitment by AXA  except where provided for in a written agreement 
between you and AXA.  Any unauthorised disclosure,  use or dissemi-
nation, either whole or partial,  is prohibited. If you are not the
intended recipient of the message,  please notify  the sender imme-
diately.

From anon.amish at gmail.com  Wed Sep  2 07:01:20 2020
From: anon.amish at gmail.com (Amish)
Date: Wed, 2 Sep 2020 12:31:20 +0530
Subject: [squid-users] squid.service with Type=Notify is not always
 reliable (Arch Linux)
In-Reply-To: <6242263b-d765-8184-a3ae-127854902918@measurement-factory.com>
References: <40fe50ea-6c26-63cc-de32-ba8366d0d234@gmail.com>
 <b2df83c6-1214-4493-abbd-79c542e883bb@measurement-factory.com>
 <dbc68688-a688-5f10-dc5b-089f6eae2d24@gmail.com>
 <6242263b-d765-8184-a3ae-127854902918@measurement-factory.com>
Message-ID: <83425264-67f7-6337-d8b9-70c83a2b8bbf@gmail.com>


On 01/09/20 8:31 pm, Alex Rousskov wrote:
> On 9/1/20 10:27 AM, Amish wrote:
>
>> Accepting ... connections at ...? message came almost immediately (in 1
>> second).
>> Sep 01 06:40:05 foo squid[8446]: Accepting SSL bumped HTTP Socket
>> connections at local=[::]:3128 remote=[::] FD 27 flags=9
> OK, so you are not using SMP Squid and, assuming your Squid build
> supports calling sd_notify(), sd_notify() was called. We need to figure
> out why it had no effect. Suggested next steps:
>
> 1. Adjust Squid to print the value of $NOTIFY_SOCKET together with the
> "Accepting..." line. This will confirm that the variable is set. It
> should be set. This debugging can be added without fear of producing too
> much info but it is unlikely to be insightful.
>
> 2. Add some kind of sd_notify() debugging that would show us what the
> first sd_notify() call was doing and when/whether systemd received the
> notification from Squid. I have not researched how to do that, but I am
> sure it is possible. I bet there are not enough notifications happening
> on your production server to cause problems, but you should practice on
> a lab server first, of course.

Ok. I will try above. But here is a note from "man sd_notify" about race 
condition that MAY occur.

Conversely, if an auxiliary process of the unit sends an sd_notify() 
message and immediately exits, the service manager might not be able to 
properly attribute the message to the unit, and thus will ignore it, 
even if NotifyAccess=all is set for it.

Hence, to eliminate all race conditions involving lookup of the client's 
unit and attribution of notifications to units correctly, 
sd_notify_barrier() may be used. This call acts as a synchronization 
point and ensures all notifications sent before this call have been 
picked up by the service manager when it returns successfully. Use of 
sd_notify_barrier() is needed for clients which are not invoked by the 
service manager, otherwise this synchronization mechanism is unnecessary 
for attribution of notifications to the unit.

Example 5. Eliminating race conditions

When the client sending the notifications is not spawned by the service 
manager, it may exit too quickly and the service manager may fail to 
attribute them correctly to the unit. To prevent such races, use 
sd_notify_barrier() to synchronize against reception of all 
notifications sent before this call is made.

 ?????????? sd_notify(0, "READY=1");
 ???????????????? /* set timeout to 5 seconds */
 ???????????????? sd_notify_barrier(0, 5 * 1000000);


I am not sure if this is related. I have no clue about sd_notify(). But 
can it be the reason?

Amish



From rousskov at measurement-factory.com  Wed Sep  2 14:21:08 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 2 Sep 2020 10:21:08 -0400
Subject: [squid-users] squid.service with Type=Notify is not always
 reliable (Arch Linux)
In-Reply-To: <83425264-67f7-6337-d8b9-70c83a2b8bbf@gmail.com>
References: <40fe50ea-6c26-63cc-de32-ba8366d0d234@gmail.com>
 <b2df83c6-1214-4493-abbd-79c542e883bb@measurement-factory.com>
 <dbc68688-a688-5f10-dc5b-089f6eae2d24@gmail.com>
 <6242263b-d765-8184-a3ae-127854902918@measurement-factory.com>
 <83425264-67f7-6337-d8b9-70c83a2b8bbf@gmail.com>
Message-ID: <e3f31532-fc12-3b33-9358-2af28304529c@measurement-factory.com>

On 9/2/20 3:01 AM, Amish wrote:
> On 01/09/20 8:31 pm, Alex Rousskov wrote:
>> 1. Adjust Squid to print the value of $NOTIFY_SOCKET together with the
>> "Accepting..." line. This will confirm that the variable is set. It
>> should be set. This debugging can be added without fear of producing too
>> much info but it is unlikely to be insightful.
>>
>> 2. Add some kind of sd_notify() debugging that would show us what the
>> first sd_notify() call was doing and when/whether systemd received the
>> notification from Squid. I have not researched how to do that, but I am
>> sure it is possible. I bet there are not enough notifications happening
>> on your production server to cause problems, but you should practice on
>> a lab server first, of course.

> Ok. I will try above. But here is a note from "man sd_notify" about race
> condition that MAY occur.

> Conversely, if an auxiliary process of the unit sends an sd_notify()
> message and immediately exits, the service manager might not be able to
> properly attribute the message to the unit, and thus will ignore it,
> even if NotifyAccess=all is set for it.

Since the Squid worker that calls sd_notify() keeps running under normal
conditions (and if it _does_ exit quickly, then its notification should
be indeed ignored!), the above caveat seems irrelevant to me.

Disclaimer: I do not know much about systemd and sd_notify(). I am just
reading the documentation you found and applying it to Squid.

Alex.


From squid3 at treenet.co.nz  Wed Sep  2 14:35:00 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 3 Sep 2020 02:35:00 +1200
Subject: [squid-users] squid.service with Type=Notify is not always
 reliable (Arch Linux)
In-Reply-To: <83425264-67f7-6337-d8b9-70c83a2b8bbf@gmail.com>
References: <40fe50ea-6c26-63cc-de32-ba8366d0d234@gmail.com>
 <b2df83c6-1214-4493-abbd-79c542e883bb@measurement-factory.com>
 <dbc68688-a688-5f10-dc5b-089f6eae2d24@gmail.com>
 <6242263b-d765-8184-a3ae-127854902918@measurement-factory.com>
 <83425264-67f7-6337-d8b9-70c83a2b8bbf@gmail.com>
Message-ID: <2d0f01d2-1c9b-040d-4019-4b6b13111cd5@treenet.co.nz>

On 2/09/20 7:01 pm, Amish wrote:
> 
> On 01/09/20 8:31 pm, Alex Rousskov wrote:
>> On 9/1/20 10:27 AM, Amish wrote:
>>
>>> Accepting ... connections at ...? message came almost immediately (in 1
>>> second).
>>> Sep 01 06:40:05 foo squid[8446]: Accepting SSL bumped HTTP Socket
>>> connections at local=[::]:3128 remote=[::] FD 27 flags=9
>> OK, so you are not using SMP Squid and, assuming your Squid build
>> supports calling sd_notify(), sd_notify() was called. We need to figure
>> out why it had no effect. Suggested next steps:
>>
>> 1. Adjust Squid to print the value of $NOTIFY_SOCKET together with the
>> "Accepting..." line. This will confirm that the variable is set. It
>> should be set. This debugging can be added without fear of producing too
>> much info but it is unlikely to be insightful.
>>
>> 2. Add some kind of sd_notify() debugging that would show us what the
>> first sd_notify() call was doing and when/whether systemd received the
>> notification from Squid. I have not researched how to do that, but I am
>> sure it is possible. I bet there are not enough notifications happening
>> on your production server to cause problems, but you should practice on
>> a lab server first, of course.
> 
> Ok. I will try above. But here is a note from "man sd_notify" about race
> condition that MAY occur.


You are guessing now. Please don't do that until every possible check
has been done and narrowed the vast range of possibilities down.

The purpose of the checks suggested by Alex was to identify whether a
race is occuring or not.

Amos


From squid3 at treenet.co.nz  Wed Sep  2 15:23:29 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 3 Sep 2020 03:23:29 +1200
Subject: [squid-users] limit bandwidth
In-Reply-To: <a81d28a8d0d2bccbb166af270f1b3315991f21ab.camel@skno.by>
References: <3d7ba9d6-aacb-8907-3440-31c1bd709615@skno.by>
 <7e727b46-dace-eb5f-17ec-dfa705c77ff8@treenet.co.nz>
 <a81d28a8d0d2bccbb166af270f1b3315991f21ab.camel@skno.by>
Message-ID: <a52f4e34-1681-2288-b40c-bb5f8d3dde7c@treenet.co.nz>

On 1/09/20 7:50 pm, Majed Zouhairy wrote:
> On Tue, 2020-09-01 at 05:10 +1200, Amos Jeffries wrote:
>> On 31/08/20 8:24 pm, Vacheslav wrote:
>>> Peace,
>>>
>>> been suffering for many hours so i'd rather ask for aid..
>>>
>>> i'm trying to limit the flow mainly for the most maximize people
>>>
>>
>> Okay.
>>
>> What Squid version are you using?
>>
>>
> sudo squid -v
> Squid Cache: Version 4.13
> Service Name: squid
> 
>>> acl slower src 10.46.0.74 10.46.0.107
>>
>> One of the reasons this posting git held up for moderation was that
>> the
>> lines which are supposed to contain ASCII tab characters contained
>> Unicode characters "\c3\82".
> this is now another email client..so let's confirm that
>>
>> If those Unicode characters are actually present in your squid.conf
>> file
>> then you need to go through and remove them all.
> 
> i went ahead and typed those added lines in nano and deleted the
> original ones..still not a trump!
>>
>> ...
>>> acl localnet src 10.46.0.0/24		#  local private
>>> network (LAN)
>>
>> ...
>>> acl blockfiles urlpath_regex -i "/etc/squid/blocks.files.acl"
>>>
>> ...
>>
>>> error_directory /usr/share/squid/errors/en
>>
>> The above is a default value. Remove that line from your config.
> this? error_directory /usr/share/squid/errors/en

Yes, that one.

>>
>>> delay_pools 1
>>> delay_class 1 3
>>> delay_access 1 allow slower !localnet
>>
>> All IPs which match "slower" ACL are also matched by "localnet" ACL.
>>
>> It is impossible for an IP to be both part of slower and not part of
>> localnet. So this line never matches and all traffic is not-delayed.
>>
>> To fix, remove the "!localnet" requirement from the above line.
> i already tried that, i was thinking that there would be an option like
> acl slower src 10.46.0.74 10.46.0.107
> acl localnet src !10.46.0.74 10.46.0.0/24
> so as not type the whole subnet individual addresses
> 

It is possible to define an ACL like localnet with holes. But that would
not do what you are wanting.


"delay_access 1 allow slower"  does what you are asking for in terms of
only the IPs listed in "slower" having their traffic slowed down.

If that is not working, then you may be hitting a bug or something is
different from what you have told us about the traffic. eg CONNECT
tunnels do not always have delay pools applied in Squid-4.


Amos


From anon.amish at gmail.com  Thu Sep  3 00:38:19 2020
From: anon.amish at gmail.com (Amish)
Date: Thu, 3 Sep 2020 06:08:19 +0530
Subject: [squid-users] squid.service with Type=Notify is not always
 reliable (Arch Linux)
In-Reply-To: <2d0f01d2-1c9b-040d-4019-4b6b13111cd5@treenet.co.nz>
References: <40fe50ea-6c26-63cc-de32-ba8366d0d234@gmail.com>
 <b2df83c6-1214-4493-abbd-79c542e883bb@measurement-factory.com>
 <dbc68688-a688-5f10-dc5b-089f6eae2d24@gmail.com>
 <6242263b-d765-8184-a3ae-127854902918@measurement-factory.com>
 <83425264-67f7-6337-d8b9-70c83a2b8bbf@gmail.com>
 <2d0f01d2-1c9b-040d-4019-4b6b13111cd5@treenet.co.nz>
Message-ID: <5899cdab-bce9-6b95-4551-8d3c023bf019@gmail.com>


On 02/09/20 8:05 pm, Amos Jeffries wrote:
> On 2/09/20 7:01 pm, Amish wrote:
>> On 01/09/20 8:31 pm, Alex Rousskov wrote:
>>> On 9/1/20 10:27 AM, Amish wrote:
>>>
>>>> Accepting ... connections at ...? message came almost immediately (in 1
>>>> second).
>>>> Sep 01 06:40:05 foo squid[8446]: Accepting SSL bumped HTTP Socket
>>>> connections at local=[::]:3128 remote=[::] FD 27 flags=9
>>> OK, so you are not using SMP Squid and, assuming your Squid build
>>> supports calling sd_notify(), sd_notify() was called. We need to figure
>>> out why it had no effect. Suggested next steps:
>>>
>>> 1. Adjust Squid to print the value of $NOTIFY_SOCKET together with the
>>> "Accepting..." line. This will confirm that the variable is set. It
>>> should be set. This debugging can be added without fear of producing too
>>> much info but it is unlikely to be insightful.
>>>
>>> 2. Add some kind of sd_notify() debugging that would show us what the
>>> first sd_notify() call was doing and when/whether systemd received the
>>> notification from Squid. I have not researched how to do that, but I am
>>> sure it is possible. I bet there are not enough notifications happening
>>> on your production server to cause problems, but you should practice on
>>> a lab server first, of course.
>> Ok. I will try above. But here is a note from "man sd_notify" about race
>> condition that MAY occur.
> You are guessing now. Please don't do that until every possible check
> has been done and narrowed the vast range of possibilities down.
>
> The purpose of the checks suggested by Alex was to identify whether a
> race is occuring or not.

For initial testing, I had already added debug message for step 1. And I 
tried replicate the problem at my end.

But I simply could not replicate the problem at my end. Debug output was 
on expected lines. (on my own machine)

Sep 03 05:11:54 amish squid[1086]: Accepting NAT intercepted HTTP Socket 
connections at local=[::]:3128 remote=[::] FD 33 flags=41
Sep 03 05:11:54 amish squid[1086]: NOTIFY_SOCKET before sd_notify() is 
/run/systemd/notify
Sep 03 05:11:54 amish systemd[1]: Started Squid Web Proxy Server.
Sep 03 05:11:54 amish squid[1086]: NOTIFY_SOCKET after sd_notify() is
Sep 03 05:11:54 amish squid[1086]: Accepting SSL bumped HTTP Socket 
connections at local=[::]:8080 remote=[::] FD 34 flags=9
Sep 03 05:11:54 amish squid[1086]: NOTIFY_SOCKET before sd_notify() is
Sep 03 05:11:54 amish squid[1086]: NOTIFY_SOCKET after sd_notify() is
Sep 03 05:11:54 amish squid[1086]: Accepting NAT intercepted SSL bumped 
HTTPS Socket connections at local=[::]:8081 remote=[::] FD 35 flags=41
Sep 03 05:11:54 amish squid[1086]: NOTIFY_SOCKET before sd_notify() is
Sep 03 05:11:54 amish squid[1086]: NOTIFY_SOCKET after sd_notify() is

For step 2, I first need to read systemd documentation about sd_notify() 
and thats when I came across mention of above race condition.

Race conditions are not easy to reproduce. That's when you look at the 
code and guess where the race can be, if there can be a race. Since 
sd_notify() documentation kind of insists on using sd_notify_barrier() 
and that does not exist in squid code. I thought that could be missing 
piece.

What is strange is I had observed that when there was this issue, no 
matter how many times I restart the squid, the problem came every single 
time. And then changing Type=forking worked. May be there is no race. 
But something else?

But now based on your and Alex replies, I will go ahead and find a way 
to add more debug to code for tracking systemd and squid notify 
communication. And then hope that issue occurs in my system.

Now I will post back about this, if at all I can do something and find 
something. :)

Thank you to both and regards,

Amish.



From squid3 at treenet.co.nz  Thu Sep  3 02:10:31 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 3 Sep 2020 14:10:31 +1200
Subject: [squid-users] seeking assistance for home users wanting to
 cache https contents
In-Reply-To: <CAO7iuad0UWD8JjiyPorrOHUk6fzOtBr+0fMW2JC3fna=bWCVKg@mail.gmail.com>
References: <CAO7iuacWfas1+qdtD_Ef8dzNu7E_yTO7ibBH5f0vp2Cbd8CNkA@mail.gmail.com>
 <45ddd73d-cb27-13ba-08c5-1feff524a4e0@treenet.co.nz>
 <CAO7iuad0UWD8JjiyPorrOHUk6fzOtBr+0fMW2JC3fna=bWCVKg@mail.gmail.com>
Message-ID: <76e86a03-e6d8-48ec-d1f3-d9018004982e@treenet.co.nz>

On 1/09/20 6:52 am, Michael Davis wrote:
> ?The github repo is actually for refresh patterns specifically
> 
> ?I extensively read over almost every squid wiki page, but unfortunately
> my attempts to understand them felt kind of useless, i did read likely
> well over fifty different attempts guides, and found myself realizing to
> your point, most info IS highly outdated
> 
> ?my config for everything is fine so far, so we can ignore pfsense snd
> things unrelated to squid safely, thank heavens for that one
> 
> ? as far as i can tell, squid is properly?? Caching non ssl delivered
> contents *disclaimer, i am fully guessing on this one* it shows bulk
> access logs of tcp_miss/200 | tcp_tunnel/200 | tcp_inm_hit/200 |
> none/200 real time results


Okay. So some HTTP(S) is happening.

You can possibly do some finer grain tests to see which of these are for
regular http:// requests by the Browser and which are for https://
traffic. That is, checking to see which of port 80 and 443 got
intercepted and how the log looks from that.


> 
> ? "FYI, "proper" caching has nothing to do with SSL-Bump.
> 
> Separate any changes you want in relation to caching from the SSL-Bump
> changes. Test each set of changes independently to get one feature going
> before you move on to the other." ...... much as i don't want to admit
> this,? THAT should have been obvious, but i think i might have over
> looked that fact....
> 
> ? "So what I am understanding from your description is that you are
> trying to:
> ?A) intercept traffic with pfsense
> ?B) SSL-Bump the TLS which arrives at the proxy
> ?C) cache the decrypted HTTP messages
> 
> Is that correct?"? THAT is exactly what my goals are, yes.
> 
> ? as for that bare bones config example, that's exactly what im using
> right now, but admittedly im not knowledgeable enough to fully and
> confidently tell if it's working at this point, i feel it isnt however
> 


IIRC SSL-Bump traffic from that minimal test ssl_bump config should log
as one NONE/200 [if I remember wrong this might be TCP_TUNNEL/200] with
"CONNECT raw-IP:port" (the "peek" happening) followed by a
TCP_TUNNEL/200 (the "splice") with "CONNECT domain:port" - depending on
client sending TLS SNI.

Squid does not have any part in the TLS handshakes for that minimal
config, so any TLS errors are between the client and origin server.


If that all checks out as what you are seeing. Adding a "stare step2"
instead of splice, and a "bump all" final line starts Squid decrypting.
You should see the two CONNECT transactions mentioned above will still
be logged, maybe a third one as well from the "stare" with updated
domain name from the server cert. But the main sign of bump happening is
that log now also contains normal GET/POST etc lines where the URL
starts with "https://" scheme.


Amos


From andreas.voneuw at axa.com  Fri Sep  4 13:18:38 2020
From: andreas.voneuw at axa.com (VON EUW Andreas)
Date: Fri, 4 Sep 2020 13:18:38 +0000
Subject: [squid-users] Squid ICAP DNS lookup failure fixed?
Message-ID: <AM6PR04MB565385DC6311CCD5C9A21D519D2D0@AM6PR04MB5653.eurprd04.prod.outlook.com>

Hi all,

I'm using squid 3.5.20 and I'm having the same problem as Aashima Madaan in his Mailing list thread from 4 years ago.
After Squid Server Restart the ICAP Integration is failing, after some minutes DNS resolution was done successfully and everything is fine.
Like in the Post from Aashima:
https://squid-users.squid-cache.narkive.com/YZLtJNiW/dns-lookup-fails-initially-for-fqdn-in-squid#post12

>From the thread I can see that there was made some kind of patch. Is this DNS resolving issue fixed in a new Squid version?

Regards, Andy

Ce message est confidentiel; Son contenu ne represente en aucun cas
un engagement de la part de AXA  sous reserve de tout accord conclu
par ecrit  entre vous et  AXA.  Toute publication,  utilisation  ou 
diffusion,  meme partielle,  doit etre autorisee prealablement.  Si
vous  n'etes pas  destinataire  de ce message,  merci  d'en avertir 
immediatement l'expediteur.

This message is  confidential;  its  contents  do not  constitute a
commitment by AXA  except where provided for in a written agreement 
between you and AXA.  Any unauthorised disclosure,  use or dissemi-
nation, either whole or partial,  is prohibited. If you are not the
intended recipient of the message,  please notify  the sender imme-
diately.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200904/18e5f5a4/attachment.htm>

From rousskov at measurement-factory.com  Fri Sep  4 13:39:53 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 4 Sep 2020 09:39:53 -0400
Subject: [squid-users] Squid ICAP DNS lookup failure fixed?
In-Reply-To: <AM6PR04MB565385DC6311CCD5C9A21D519D2D0@AM6PR04MB5653.eurprd04.prod.outlook.com>
References: <AM6PR04MB565385DC6311CCD5C9A21D519D2D0@AM6PR04MB5653.eurprd04.prod.outlook.com>
Message-ID: <0708c1f4-6c4d-61d1-21bd-2dd99c4e7c29@measurement-factory.com>

On 9/4/20 9:18 AM, VON EUW Andreas wrote:

> After Squid Server Restart the ICAP Integration is failing, after some
> minutes DNS resolution was done successfully and everything is fine.

> Is this DNS resolving issue fixed in a new Squid version?

I did not check carefully, but I do not see any relevant changes in git
logs. The following email probably reflects the current situation well:

http://lists.squid-cache.org/pipermail/squid-users/2016-June/010994.html

Alex.


From uhlar at fantomas.sk  Fri Sep  4 14:52:16 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 4 Sep 2020 16:52:16 +0200
Subject: [squid-users] deny_info page not shown
In-Reply-To: <c9352b1d-7a4c-e3f9-8452-f7c5d1b95e9e@measurement-factory.com>
References: <20200828000838.2b6c089ac5b72a0920059afc@3dresearch.com>
 <a4c90341-395e-7489-f6e2-7e8350e2d973@treenet.co.nz>
 <20200828022254.e448e17cf0af48f1cc1b37b8@3dresearch.com>
 <791e9a90-b60a-9229-13f0-6a7dedf8ad09@treenet.co.nz>
 <20200828042344.ee422fccda905b9b187bd038@3dresearch.com>
 <20200828083141.GA7917@fantomas.sk>
 <c9352b1d-7a4c-e3f9-8452-f7c5d1b95e9e@measurement-factory.com>
Message-ID: <20200904145216.GA22909@fantomas.sk>

>>> Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>>> CONNECT is a request to open a TCP connection. Delivering an HTTP
>>>> page, or even a URL redirect in response to a TCP connection request
>>>> is completely the wrong type of result.
>
>>>> Like asking someone to open a door because you have a load of things
>>>> needing to go through it - and they instead throw a basket of apples
>>>> at you. Not want you expected, and more harm than good.
>
>
>On 8/28/20 4:31 AM, Matus UHLAR - fantomas wrote:
>> when you ask via HTTP for HTTP page and get HTTP answer, it is different
>> than asking via HTTP for CONNECT and getting CONNECT denied via HTTP.
>>
>> in the latter case it is clear that the request was denied by proxy and
>> since secure content was requested, the insecure response must not be
>> shown.
>>
>> That's the security provided.

On 28.08.20 16:10, Alex Rousskov wrote:
>I believe the above explanations and analogies are rather misleading!
>There are no conceptual or protocol problems with HTTP error responses
>to HTTP CONNECT requests. The browser knows where the response is coming
>from. The browser knows that the response is an error. The browser
>already anticipates and processes some error CONNECT responses specially
>(think proxy authentication). There is no confusion, harm,
>inappropriateness, or some new insecurity here!
>
>What is actually happening (AFAICT) is that browser folks do not want to
>spend their resources on properly informing the user of the error. There
>are ways to do it, but they all require non-trivial work in a
>controversial area, and browser folks simply do not consider this
>specific use case important enough to support. At the end of the day,
>you are not their customer. They do not want you as their customer. You
>lost.

This is what I wanted to say. Browsers don't want to show "unsecure" page
gotten via HTTP from proxy, when they expect "secure" content from
webserver.

They show error instead. I don't want to guess what could happen, if user
entering HTTPS page got HTML from proxy rendered, behaving as if it was the
page from the server.

>While opinions on the underlying causes may differ, the end result is
>still the same -- a forward proxy cannot display an error page to a user
>behind a popular browser in a modern environment (without bumping the
>browser connection first).


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
There's a long-standing bug relating to the x86 architecture that
allows you to install Windows.   -- Matthew D. Fuller


From piyush.gaba at orange.com  Tue Sep  8 09:01:27 2020
From: piyush.gaba at orange.com (piyush.gaba at orange.com)
Date: Tue, 8 Sep 2020 09:01:27 +0000
Subject: [squid-users] Forwarded-for functionality(squid)
Message-ID: <31718_1599555688_5F574868_31718_1_2_FB9F07820FAE75499D7A4E37F6CD7664AA810A@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>

Hi Team,

I would like to ask for your inputs/resolution for one of the issues that I am facing while using forwarded_for functionality with new version of squid i.e. v4.13

UseCase:
I have a client, a webserver and squid hosted in 3 different VMs. I have set up interfaces in such a way that Client cannot access webserver directly, but only through squid proxy.(Works fine)

Now, When I append forwarded_for off to my squid.conf and then curl the webserver from client [ curl {Webserver.mgmtIP} ], the expected logs on webserver should have, "unknown" at the end of line.
And if there is nothing appended or forwarded_for on is appended, it should have "Client_IP" at the end of the line in log file.
But I am not getting expected output.

PFA squid.conf ,output at httpd , httpd.conf.

After several tries, I am looking forward for your help/advice.

Thank You.

Bien cordialement,
Piyush Gaba
Software Engineer
TGI/OLN- INDIA
Tower B, 8th Floor, DLF Infinity Towers,
DLF Cyber City Phase - II
Gurgaon - 122002, Haryana, INDIA
* Mobile: +91-9818498198
[Email] piyush.gaba at orange.com<mailto:piyush.gaba at orange.com>


_________________________________________________________________________________________________________________________

Ce message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc
pas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler
a l'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d'alteration,
Orange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.

This message and its attachments may contain confidential or privileged information that may be protected by law;
they should not be distributed, used or copied without authorisation.
If you have received this email in error, please notify the sender and delete this message and its attachments.
As emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.
Thank you.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200908/d6f5c668/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: httpd.conf
Type: application/octet-stream
Size: 12093 bytes
Desc: httpd.conf
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200908/d6f5c668/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: httpdlogsaftercurl.PNG
Type: image/png
Size: 50415 bytes
Desc: httpdlogsaftercurl.PNG
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200908/d6f5c668/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf
Type: application/octet-stream
Size: 2838 bytes
Desc: squid.conf
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200908/d6f5c668/attachment-0001.obj>

From uhlar at fantomas.sk  Tue Sep  8 09:52:43 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 8 Sep 2020 11:52:43 +0200
Subject: [squid-users] Forwarded-for functionality(squid)
In-Reply-To: <31718_1599555688_5F574868_31718_1_2_FB9F07820FAE75499D7A4E37F6CD7664AA810A@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
References: <31718_1599555688_5F574868_31718_1_2_FB9F07820FAE75499D7A4E37F6CD7664AA810A@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
Message-ID: <20200908095243.GB22048@fantomas.sk>

On 08.09.20 09:01, piyush.gaba at orange.com wrote:
>I would like to ask for your inputs/resolution for one of the issues that I am facing while using forwarded_for functionality with new version of squid i.e. v4.13
>
>UseCase:
>I have a client, a webserver and squid hosted in 3 different VMs.  I have
> set up interfaces in such a way that Client cannot access webserver
> directly, but only through squid proxy.(Works fine)
>
>Now, When I append forwarded_for off to my squid.conf and then curl the
> webserver from client [ curl {Webserver.mgmtIP} ], the expected logs on
> webserver should have, "unknown" at the end of line.

You can configure webserver to log contents of X-Forwarded-For: line.
Note that that line can contain anything clients can send.
So, unless you really want to see that content, don't log it.

>And if there is nothing appended or forwarded_for on is appended, it should have "Client_IP" at the end of the line in log file.
>But I am not getting expected output.


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
He who laughs last thinks slowest.


From squid3 at treenet.co.nz  Tue Sep  8 11:21:46 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 8 Sep 2020 23:21:46 +1200
Subject: [squid-users] Forwarded-for functionality(squid)
In-Reply-To: <20200908095243.GB22048@fantomas.sk>
References: <31718_1599555688_5F574868_31718_1_2_FB9F07820FAE75499D7A4E37F6CD7664AA810A@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
 <20200908095243.GB22048@fantomas.sk>
Message-ID: <0b382d0a-6c35-6c56-43bd-2413f504cd12@treenet.co.nz>

On 8/09/20 9:52 pm, Matus UHLAR - fantomas wrote:
> On 08.09.20 09:01, piyush.gaba wrote:
>> I would like to ask for your inputs/resolution for one of the issues
>> that I am facing while using forwarded_for functionality with new
>> version of squid i.e. v4.13
>>
>> UseCase:
>> I have a client, a webserver and squid hosted in 3 different VMs.? I have
>> set up interfaces in such a way that Client cannot access webserver
>> directly, but only through squid proxy.(Works fine)
>>
>> Now, When I append forwarded_for off to my squid.conf and then curl the
>> webserver from client [ curl {Webserver.mgmtIP} ], the expected logs on
>> webserver should have, "unknown" at the end of line.
> 
> You can configure webserver to log contents of X-Forwarded-For: line.
> Note that that line can contain anything clients can send.
> So, unless you really want to see that content, don't log it.
> 
>> And if there is nothing appended or forwarded_for on is appended, it
>> should have "Client_IP" at the end of the line in log file.
>> But I am not getting expected output.
> 

In squid.conf add this to see the HTTP messages going through Squid and
understand what is going on:

  debug_options 11,2


HTH
Amos


From piyush.gaba at orange.com  Tue Sep  8 13:15:57 2020
From: piyush.gaba at orange.com (piyush.gaba at orange.com)
Date: Tue, 8 Sep 2020 13:15:57 +0000
Subject: [squid-users] Forwarded-for functionality(squid)
In-Reply-To: <20200908095243.GB22048@fantomas.sk>
References: <31718_1599555688_5F574868_31718_1_2_FB9F07820FAE75499D7A4E37F6CD7664AA810A@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
 <20200908095243.GB22048@fantomas.sk>
Message-ID: <15343_1599570962_5F578412_15343_93_1_03f4a0be-7496-48ec-b76c-904a48f9e9a4@OPEXCAUBM33.corporate.adroot.infra.ftgroup>

Hi Matus,

Thank you for your reply.

I think my whole struggle is to get the desired output as:
<ip>- - [17/Aug/2018:08:43:29 +0200] "GET /index1.html HTTP/1.1" 200 36 "-" "curl/7.29.0" unknown

Which has "unknown" at the end because forwarded_for was set to "off".

But now when I am working with squid 4.13 I am not getting the desired output, I am getting the output as,
<ip> - - [08/Sep/2020:15:07:19 +0200] "GET /index1.html HTTP/1.1" 200 8 "-" "curl/7.29.0"

Which does not have anything at the end, while the forwarded_for is set to "off".

Please let me know if you have any advice to give for this logging problem.

I am using below log format in my httpd file,
LogFormat "%{X-Forwarded-For}i %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"" combined

Bien cordialement,
Piyush Gaba
Software Engineer
TGI/OLN- INDIA
Tower B, 8th Floor, DLF Infinity Towers, 
DLF Cyber City Phase - II
Gurgaon - 122002, Haryana, INDIA
 [Email] piyush.gaba at orange.com


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Matus UHLAR - fantomas
Sent: Tuesday, September 8, 2020 15:23
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Forwarded-for functionality(squid)

On 08.09.20 09:01, piyush.gaba at orange.com wrote:
>I would like to ask for your inputs/resolution for one of the issues that I am facing while using forwarded_for functionality with new version of squid i.e. v4.13
>
>UseCase:
>I have a client, a webserver and squid hosted in 3 different VMs.  I have
> set up interfaces in such a way that Client cannot access webserver
> directly, but only through squid proxy.(Works fine)
>
>Now, When I append forwarded_for off to my squid.conf and then curl the
> webserver from client [ curl {Webserver.mgmtIP} ], the expected logs on
> webserver should have, "unknown" at the end of line.

You can configure webserver to log contents of X-Forwarded-For: line.
Note that that line can contain anything clients can send.
So, unless you really want to see that content, don't log it.

>And if there is nothing appended or forwarded_for on is appended, it should have "Client_IP" at the end of the line in log file.
>But I am not getting expected output.


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
He who laughs last thinks slowest.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_________________________________________________________________________________________________________________________

Ce message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc
pas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler
a l'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d'alteration,
Orange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.

This message and its attachments may contain confidential or privileged information that may be protected by law;
they should not be distributed, used or copied without authorisation.
If you have received this email in error, please notify the sender and delete this message and its attachments.
As emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.
Thank you.


From squid3 at treenet.co.nz  Tue Sep  8 15:11:42 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 9 Sep 2020 03:11:42 +1200
Subject: [squid-users] Forwarded-for functionality(squid)
In-Reply-To: <15343_1599570962_5F578412_15343_93_1_03f4a0be-7496-48ec-b76c-904a48f9e9a4@OPEXCAUBM33.corporate.adroot.infra.ftgroup>
References: <31718_1599555688_5F574868_31718_1_2_FB9F07820FAE75499D7A4E37F6CD7664AA810A@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
 <20200908095243.GB22048@fantomas.sk>
 <15343_1599570962_5F578412_15343_93_1_03f4a0be-7496-48ec-b76c-904a48f9e9a4@OPEXCAUBM33.corporate.adroot.infra.ftgroup>
Message-ID: <8dba5633-66ce-372c-9080-dc316e967cd0@treenet.co.nz>

On 9/09/20 1:15 am, piyush.gaba wrote:
> Hi Matus,
> 
> Thank you for your reply.
> 
> I think my whole struggle is to get the desired output as:
> <ip>- - [17/Aug/2018:08:43:29 +0200] "GET /index1.html HTTP/1.1" 200 36 "-" "curl/7.29.0" unknown
> 
> Which has "unknown" at the end because forwarded_for was set to "off".
> 
> But now when I am working with squid 4.13 I am not getting the desired output, I am getting the output as,
> <ip> - - [08/Sep/2020:15:07:19 +0200] "GET /index1.html HTTP/1.1" 200 8 "-" "curl/7.29.0"
> 
> Which does not have anything at the end, while the forwarded_for is set to "off".
> 
> Please let me know if you have any advice to give for this logging problem.
> 
> I am using below log format in my httpd file,
> LogFormat "%{X-Forwarded-For}i %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"" combined
> 

That LogFormat tells us the first column of the log file is the contents
of the X-Forwarded-For header. The first column of the log lines you
showed is "<ip>" - the value of XFF header is supposed to be one or more
IPs, so that looks like it is working.

Use the debug_options setting I gave you to *actually* see what is
happening. The Apache log is only showing you what values are _after_
the httpd process and all modules have done their modifications to the
HTTP input ... including replacing the transaction client-IP with any
value from XFF header.


Amos


From piyush.gaba at orange.com  Tue Sep  8 16:32:57 2020
From: piyush.gaba at orange.com (piyush.gaba at orange.com)
Date: Tue, 8 Sep 2020 16:32:57 +0000
Subject: [squid-users] Forwarded-for functionality(squid)
In-Reply-To: <8dba5633-66ce-372c-9080-dc316e967cd0@treenet.co.nz>
References: <31718_1599555688_5F574868_31718_1_2_FB9F07820FAE75499D7A4E37F6CD7664AA810A@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
 <20200908095243.GB22048@fantomas.sk>
 <15343_1599570962_5F578412_15343_93_1_03f4a0be-7496-48ec-b76c-904a48f9e9a4@OPEXCAUBM33.corporate.adroot.infra.ftgroup>
 <8dba5633-66ce-372c-9080-dc316e967cd0@treenet.co.nz>
Message-ID: <4058_1599582778_5F57B23A_4058_397_1_FB9F07820FAE75499D7A4E37F6CD7664AA81BC@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>

Hi Amos,

Thank you so much for your reply.

I did debug and I found below output in the squid logs,

1599582079.051      3 <Client_Ip> TCP_MISS/200 430 GET http:// <webserverIp>/index1.html - HIER_DIRECT/<webserverIp> text/html

I would like to share a URL for squid directive and that is the output I am expecting at the end of the line of my output and as I have given in the trail.
http://www.squid-cache.org/Doc/config/forwarded_for/ 

When set to off, it should show "unknown". Right ? 

Bien cordialement,
Piyush Gaba
Software Engineer
TGI/OLN- INDIA
Tower B, 8th Floor, DLF Infinity Towers, 
DLF Cyber City Phase - II
Gurgaon - 122002, Haryana, INDIA
[Email] piyush.gaba at orange.com


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Tuesday, September 8, 2020 20:42
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Forwarded-for functionality(squid)

On 9/09/20 1:15 am, piyush.gaba wrote:
> Hi Matus,
> 
> Thank you for your reply.
> 
> I think my whole struggle is to get the desired output as:
> <ip>- - [17/Aug/2018:08:43:29 +0200] "GET /index1.html HTTP/1.1" 200 36 "-" "curl/7.29.0" unknown
> 
> Which has "unknown" at the end because forwarded_for was set to "off".
> 
> But now when I am working with squid 4.13 I am not getting the desired output, I am getting the output as,
> <ip> - - [08/Sep/2020:15:07:19 +0200] "GET /index1.html HTTP/1.1" 200 8 "-" "curl/7.29.0"
> 
> Which does not have anything at the end, while the forwarded_for is set to "off".
> 
> Please let me know if you have any advice to give for this logging problem.
> 
> I am using below log format in my httpd file,
> LogFormat "%{X-Forwarded-For}i %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"" combined
> 

That LogFormat tells us the first column of the log file is the contents
of the X-Forwarded-For header. The first column of the log lines you
showed is "<ip>" - the value of XFF header is supposed to be one or more
IPs, so that looks like it is working.

Use the debug_options setting I gave you to *actually* see what is
happening. The Apache log is only showing you what values are _after_
the httpd process and all modules have done their modifications to the
HTTP input ... including replacing the transaction client-IP with any
value from XFF header.


Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_________________________________________________________________________________________________________________________

Ce message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc
pas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler
a l'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d'alteration,
Orange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.

This message and its attachments may contain confidential or privileged information that may be protected by law;
they should not be distributed, used or copied without authorisation.
If you have received this email in error, please notify the sender and delete this message and its attachments.
As emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.
Thank you.


From piyush.gaba at orange.com  Tue Sep  8 16:42:00 2020
From: piyush.gaba at orange.com (piyush.gaba at orange.com)
Date: Tue, 8 Sep 2020 16:42:00 +0000
Subject: [squid-users] Forwarded-for functionality(squid)
In-Reply-To: <8dba5633-66ce-372c-9080-dc316e967cd0@treenet.co.nz>
References: <31718_1599555688_5F574868_31718_1_2_FB9F07820FAE75499D7A4E37F6CD7664AA810A@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
 <20200908095243.GB22048@fantomas.sk>
 <15343_1599570962_5F578412_15343_93_1_03f4a0be-7496-48ec-b76c-904a48f9e9a4@OPEXCAUBM33.corporate.adroot.infra.ftgroup>
 <8dba5633-66ce-372c-9080-dc316e967cd0@treenet.co.nz>
Message-ID: <19136_1599583321_5F57B459_19136_344_27_FB9F07820FAE75499D7A4E37F6CD7664AA81C9@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>

By the way guys. It just worked. Thanks alot Amos and Matus. 

Thank You.

Bien cordialement,
Piyush Gaba
Software Engineer
TGI/OLN- INDIA
Tower B, 8th Floor, DLF Infinity Towers,?
DLF Cyber City Phase - II
Gurgaon - 122002, Haryana, INDIA
G?Mobile: +91-9818498198
[Email] piyush.gaba at orange.com 


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Tuesday, September 8, 2020 20:42
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Forwarded-for functionality(squid)

On 9/09/20 1:15 am, piyush.gaba wrote:
> Hi Matus,
> 
> Thank you for your reply.
> 
> I think my whole struggle is to get the desired output as:
> <ip>- - [17/Aug/2018:08:43:29 +0200] "GET /index1.html HTTP/1.1" 200 36 "-" "curl/7.29.0" unknown
> 
> Which has "unknown" at the end because forwarded_for was set to "off".
> 
> But now when I am working with squid 4.13 I am not getting the desired output, I am getting the output as,
> <ip> - - [08/Sep/2020:15:07:19 +0200] "GET /index1.html HTTP/1.1" 200 8 "-" "curl/7.29.0"
> 
> Which does not have anything at the end, while the forwarded_for is set to "off".
> 
> Please let me know if you have any advice to give for this logging problem.
> 
> I am using below log format in my httpd file,
> LogFormat "%{X-Forwarded-For}i %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"" combined
> 

That LogFormat tells us the first column of the log file is the contents
of the X-Forwarded-For header. The first column of the log lines you
showed is "<ip>" - the value of XFF header is supposed to be one or more
IPs, so that looks like it is working.

Use the debug_options setting I gave you to *actually* see what is
happening. The Apache log is only showing you what values are _after_
the httpd process and all modules have done their modifications to the
HTTP input ... including replacing the transaction client-IP with any
value from XFF header.


Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_________________________________________________________________________________________________________________________

Ce message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc
pas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler
a l'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d'alteration,
Orange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.

This message and its attachments may contain confidential or privileged information that may be protected by law;
they should not be distributed, used or copied without authorisation.
If you have received this email in error, please notify the sender and delete this message and its attachments.
As emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.
Thank you.


From standby24x7 at gmail.com  Wed Sep  9 05:44:59 2020
From: standby24x7 at gmail.com (Masanari Iida)
Date: Wed, 9 Sep 2020 14:44:59 +0900
Subject: [squid-users] squid supprts HTTP long-polling?
Message-ID: <CALLJCT3O0pizR9bhW7wZx1HdAMtDPy_pPS_tR4uTJM2N6O-Q5A@mail.gmail.com>

Hello List,
I would like to know if squid support "HTTP Long-polling".
As I see  https://wiki.squid-cache.org/StandardsCompliance
page, HTTP Long-Polling (RFC6202) is not on the list.
So I guess the squid does not support "HTTP Long-polling".
Correct?

Regards,
Masanari


From uhlar at fantomas.sk  Wed Sep  9 08:43:16 2020
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 9 Sep 2020 10:43:16 +0200
Subject: [squid-users] Forwarded-for functionality(squid)
In-Reply-To: <19136_1599583321_5F57B459_19136_344_27_FB9F07820FAE75499D7A4E37F6CD7664AA81C9@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
References: <31718_1599555688_5F574868_31718_1_2_FB9F07820FAE75499D7A4E37F6CD7664AA810A@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
 <20200908095243.GB22048@fantomas.sk>
 <15343_1599570962_5F578412_15343_93_1_03f4a0be-7496-48ec-b76c-904a48f9e9a4@OPEXCAUBM33.corporate.adroot.infra.ftgroup>
 <8dba5633-66ce-372c-9080-dc316e967cd0@treenet.co.nz>
 <19136_1599583321_5F57B459_19136_344_27_FB9F07820FAE75499D7A4E37F6CD7664AA81C9@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
Message-ID: <20200909084316.GA1140@fantomas.sk>

On 08.09.20 16:42, piyush.gaba at orange.com wrote:
>By the way guys. It just worked. Thanks alot Amos and Matus.

just to make sure - are you aware that anything in the X-Forwarded-For:
header can be fake and you should only use trusted IPs?

The follow_x_forwarded_for describes how:
http://www.squid-cache.org/Doc/config/follow_x_forwarded_for/


>On 9/09/20 1:15 am, piyush.gaba wrote:
>> I think my whole struggle is to get the desired output as:
>> <ip>- - [17/Aug/2018:08:43:29 +0200] "GET /index1.html HTTP/1.1" 200 36 "-" "curl/7.29.0" unknown
>>
>> Which has "unknown" at the end because forwarded_for was set to "off".
>>
>> But now when I am working with squid 4.13 I am not getting the desired output, I am getting the output as,
>> <ip> - - [08/Sep/2020:15:07:19 +0200] "GET /index1.html HTTP/1.1" 200 8 "-" "curl/7.29.0"
>>
>> Which does not have anything at the end, while the forwarded_for is set to "off".
>>
>> Please let me know if you have any advice to give for this logging problem.
>>
>> I am using below log format in my httpd file,
>> LogFormat "%{X-Forwarded-For}i %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"" combined

>-----Original Message-----
>From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
>Sent: Tuesday, September 8, 2020 20:42
>To: squid-users at lists.squid-cache.org
>Subject: Re: [squid-users] Forwarded-for functionality(squid)

>That LogFormat tells us the first column of the log file is the contents
>of the X-Forwarded-For header. The first column of the log lines you
>showed is "<ip>" - the value of XFF header is supposed to be one or more
>IPs, so that looks like it is working.
>
>Use the debug_options setting I gave you to *actually* see what is
>happening. The Apache log is only showing you what values are _after_
>the httpd process and all modules have done their modifications to the
>HTTP input ... including replacing the transaction client-IP with any
>value from XFF header.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Saving Private Ryan...
Private Ryan exists. Overwrite? (Y/N)


From piyush.gaba at orange.com  Wed Sep  9 10:02:55 2020
From: piyush.gaba at orange.com (piyush.gaba at orange.com)
Date: Wed, 9 Sep 2020 10:02:55 +0000
Subject: [squid-users] Forwarded-for functionality(squid)
In-Reply-To: <20200909084316.GA1140@fantomas.sk>
References: <31718_1599555688_5F574868_31718_1_2_FB9F07820FAE75499D7A4E37F6CD7664AA810A@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
 <20200908095243.GB22048@fantomas.sk>
 <15343_1599570962_5F578412_15343_93_1_03f4a0be-7496-48ec-b76c-904a48f9e9a4@OPEXCAUBM33.corporate.adroot.infra.ftgroup>
 <8dba5633-66ce-372c-9080-dc316e967cd0@treenet.co.nz>
 <19136_1599583321_5F57B459_19136_344_27_FB9F07820FAE75499D7A4E37F6CD7664AA81C9@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
 <20200909084316.GA1140@fantomas.sk>
Message-ID: <3940_1599645775_5F58A84F_3940_192_15_FB9F07820FAE75499D7A4E37F6CD7664AA82AC@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>

Yes Matus, I understand. It's just for temporary purpose since I am just testing the capabilities of squid v4.13.

Bien cordialement,
Piyush Gaba

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Matus UHLAR - fantomas
Sent: Wednesday, September 9, 2020 14:13
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Forwarded-for functionality(squid)

On 08.09.20 16:42, piyush.gaba at orange.com wrote:
>By the way guys. It just worked. Thanks alot Amos and Matus.

just to make sure - are you aware that anything in the X-Forwarded-For:
header can be fake and you should only use trusted IPs?

The follow_x_forwarded_for describes how:
http://www.squid-cache.org/Doc/config/follow_x_forwarded_for/


>On 9/09/20 1:15 am, piyush.gaba wrote:
>> I think my whole struggle is to get the desired output as:
>> <ip>- - [17/Aug/2018:08:43:29 +0200] "GET /index1.html HTTP/1.1" 200 36 "-" "curl/7.29.0" unknown
>>
>> Which has "unknown" at the end because forwarded_for was set to "off".
>>
>> But now when I am working with squid 4.13 I am not getting the desired output, I am getting the output as,
>> <ip> - - [08/Sep/2020:15:07:19 +0200] "GET /index1.html HTTP/1.1" 200 8 "-" "curl/7.29.0"
>>
>> Which does not have anything at the end, while the forwarded_for is set to "off".
>>
>> Please let me know if you have any advice to give for this logging problem.
>>
>> I am using below log format in my httpd file,
>> LogFormat "%{X-Forwarded-For}i %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"" combined

>-----Original Message-----
>From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
>Sent: Tuesday, September 8, 2020 20:42
>To: squid-users at lists.squid-cache.org
>Subject: Re: [squid-users] Forwarded-for functionality(squid)

>That LogFormat tells us the first column of the log file is the contents
>of the X-Forwarded-For header. The first column of the log lines you
>showed is "<ip>" - the value of XFF header is supposed to be one or more
>IPs, so that looks like it is working.
>
>Use the debug_options setting I gave you to *actually* see what is
>happening. The Apache log is only showing you what values are _after_
>the httpd process and all modules have done their modifications to the
>HTTP input ... including replacing the transaction client-IP with any
>value from XFF header.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Saving Private Ryan...
Private Ryan exists. Overwrite? (Y/N)
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_________________________________________________________________________________________________________________________

Ce message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc
pas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler
a l'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d'alteration,
Orange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.

This message and its attachments may contain confidential or privileged information that may be protected by law;
they should not be distributed, used or copied without authorisation.
If you have received this email in error, please notify the sender and delete this message and its attachments.
As emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.
Thank you.


From m_zouhairy at ckta.by  Wed Sep  9 12:18:14 2020
From: m_zouhairy at ckta.by (Majed Zouhairy)
Date: Wed, 9 Sep 2020 15:18:14 +0300
Subject: [squid-users] limit bandwidth
Message-ID: <a99dbcff-80e3-1524-c72b-ffd3fbdfa7f2@ckta.by>

 >>> ...
 >>>
 >>>> error_directory /usr/share/squid/errors/en
 >>> The above is a default value. Remove that line from your config.
 >> this? error_directory /usr/share/squid/errors/en
 > Yes, that one.
so it's not the email client even
 >
 >>>> delay_pools 1
 >>>> delay_class 1 3
 >>>> delay_access 1 allow slower !localnet
 >>> All IPs which match "slower" ACL are also matched by "localnet" ACL.
 >>>
 >>> It is impossible for an IP to be both part of slower and not part of
 >>> localnet. So this line never matches and all traffic is not-delayed.
 >>>
 >>> To fix, remove the "!localnet" requirement from the above line.
 >> i already tried that, i was thinking that there would be an option like
 >> acl slower src 10.46.0.74 10.46.0.107
 >> acl localnet src !10.46.0.74 10.46.0.0/24
 >> so as not type the whole subnet individual addresses
 >>
 > It is possible to define an ACL like localnet with holes. But that would
 > not do what you are wanting.
still that would be very nice to know
 >
 >
 > "delay_access 1 allow slower"  does what you are asking for in terms of
 > only the IPs listed in "slower" having their traffic slowed down.
 >
 > If that is not working, then you may be hitting a bug or something is
 > different from what you have told us about the traffic. eg CONNECT
 > tunnels do not always have delay pools applied in Squid-4.
 >
 >
 > Amos

it's only working on http downloads,

might it have any relationship with ufdbguard is being used?

the rest of the config

delay_pools 1
delay_class 1 3
delay_access 1 allow slower
delay_access 1 deny all
delay_parameters 1 51200/51200 -1/-1 51200/25600

http_access allow localnet
http_access allow localhost



# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 8080

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/cache/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid

cache_mem 512 MB

netdb_filename none

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:        1440    20%    10080
refresh_pattern ^gopher:    1440    0%    1440
refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
refresh_pattern .        0    20%    4320

url_rewrite_program /usr/local/ufdbguard/bin/ufdbgclient -m 4 -l 
/var/log/squid/
url_rewrite_children 16 startup=8 idle=2 concurrency=4
#debug_options ALL,1 33,2 28,9


From antonino.sanacori at unibs.it  Wed Sep  9 12:49:29 2020
From: antonino.sanacori at unibs.it (Antonino Gianfranco Sanacori)
Date: Wed, 9 Sep 2020 14:49:29 +0200
Subject: [squid-users] LDAP authentication using multiple branches
Message-ID: <f509e9f5-85d2-6816-5cb8-2108577a32c0@unibs.it>

Hi.

I have to configure my squid to use multiple ldap branches for 
authentication of my users, is it possible?

Many thanks!

Antonino



-- 


Informativa sulla Privacy: http://www.unibs.it/node/8155 
<http://www.unibs.it/node/8155>


From squid3 at treenet.co.nz  Wed Sep  9 13:34:42 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 10 Sep 2020 01:34:42 +1200
Subject: [squid-users] squid supprts HTTP long-polling?
In-Reply-To: <CALLJCT3O0pizR9bhW7wZx1HdAMtDPy_pPS_tR4uTJM2N6O-Q5A@mail.gmail.com>
References: <CALLJCT3O0pizR9bhW7wZx1HdAMtDPy_pPS_tR4uTJM2N6O-Q5A@mail.gmail.com>
Message-ID: <3dc99c1f-263d-cbcd-6a9c-907e33f29956@treenet.co.nz>

On 9/09/20 5:44 pm, Masanari Iida wrote:
> Hello List,
> I would like to know if squid support "HTTP Long-polling".
> As I see  https://wiki.squid-cache.org/StandardsCompliance
> page, HTTP Long-Polling (RFC6202) is not on the list.
> So I guess the squid does not support "HTTP Long-polling".
> Correct?


That RFC is not a feature or extension specification. There is nothing
specific for Squid to support.

What that RFC does is define the a technique for how to *use* HTTP
mechanisms and a list of problems that can occur when the behaviour is
relied on.

Squid supports all the HTTP mechanisms relied on by long polling.
Though you can expect serious admin to have tuned their proxies to
prevent the network abuse and security risks that behaviour relies on.

Amos


From arifordsham at gmail.com  Thu Sep 10 16:07:45 2020
From: arifordsham at gmail.com (Ari Fordsham)
Date: Thu, 10 Sep 2020 17:07:45 +0100
Subject: [squid-users] Configuring squid to fake Internet connection
Message-ID: <CAPQL5p+oDDKELNyWcHRzm7=cKWoDDDjpfMhKvknfVgZ_-N0j-A@mail.gmail.com>

Hi, I'm brand new to Squid.

I am trying to use Squid to solve the following problem -
I work on the road, often without an Internet connection. Unfortunately, an
application I am using downloads some files from the Internet on every
interface navigation, and when offline, waits (2 minutes!) for the
connection to time out before responding. This makes the
application completely unusable. The actual content of the download is
unimportant (probably even a 404 error would be fine) but I cannot prevent
the application from waiting for connection timeout.

To this end I installed squid, and have successfully routed the traffic
from said problematic application through it, to the exclusion of regular
Internet, including browsing traffic, which does not go through squid, and
successfully configured internet access through squid.

I would now like to configure squid so that i can run the application (with
internet on), loading its downloads into squid's cache, and then have squid
serve that up to the application instantly on every subsequent request,
irrelevant of internet connectivity and content expiry headers, including
from a fresh boot while offline.

Can someone point me toward the correct configuration/directives?

Thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200910/b7d725ef/attachment.htm>

From squid3 at treenet.co.nz  Fri Sep 11 23:28:25 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 12 Sep 2020 11:28:25 +1200
Subject: [squid-users] Configuring squid to fake Internet connection
In-Reply-To: <CAPQL5p+oDDKELNyWcHRzm7=cKWoDDDjpfMhKvknfVgZ_-N0j-A@mail.gmail.com>
References: <CAPQL5p+oDDKELNyWcHRzm7=cKWoDDDjpfMhKvknfVgZ_-N0j-A@mail.gmail.com>
Message-ID: <c6708c26-d593-f1b0-37eb-3666a605f707@treenet.co.nz>

On 11/09/20 4:07 am, Ari Fordsham wrote:
> Hi, I'm brand new to Squid.
> 
> I am trying to use Squid to solve the following problem -
> I work on the road, often without an Internet connection. Unfortunately,
> an application I am using downloads some files from the Internet on
> every interface navigation, and when offline, waits (2 minutes!) for the
> connection to time out before responding. This makes the
> application?completely unusable. The actual content of the download is
> unimportant (probably even a 404 error would be fine) but I cannot
> prevent the application from waiting for connection timeout.

Have you disabled ICMP on this network?

ICMP is used by routers to inform other devices about network
connectivity being offline etc. When ICMP is working the software would
not be able to have a hung connection waiting for timeout - it would be
terminated immediately upon the routers command.

This is important to fix because if you have disabled ICMP then Squid
will have the same timeout issues that software is having. Things might
even get *worse* because Squid tries multiple times to fetch content
before giving up and has even longer timeouts.


> 
> To this end I installed squid, and have successfully routed the traffic
> from said problematic application through it, to the exclusion of
> regular Internet, including browsing traffic, which does not go through
> squid, and successfully configured internet access through squid.
> 

I assume that means you have any environment, interception or
application proxy settings already configured and working.


> I would now like to configure squid so that i can run the application
> (with internet on), loading its downloads into squid's cache, and then
> have squid serve that up to the application instantly on every
> subsequent request, irrelevant of internet connectivity and content
> expiry headers,

Those headers exist in the traffic for very good reasons.  The nature of
web applications is that the content is *generated* on demand based on
dynamic state from the client. There is no way for Squid to know the
internal code and design of any application in order to generate those
responses or even request them ahead of time.

You said the content of the download is fine. So errors generated by
Squid saying it could not get connectivity should be fine instead of
trying to cache everything.


> including from a fresh boot while offline.
> 
> Can someone point me toward the correct configuration/directives?


Squid by default caches everything which is cacheable. No settings to do
for that part of things. If the traffic is http:// then there is nothing
else to configure.


If the traffic is HTTPS and the client software opening CONNECT tunnels
to use the proxy, then you will need SSL-Bump feature configured to
decrypt the traffic before caching can be done. Details on that can be
found in the wiki <https://wiki.squid-cache.org/Features/SslPeekAndSplice>


Amos


From squid3 at treenet.co.nz  Fri Sep 11 23:33:32 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 12 Sep 2020 11:33:32 +1200
Subject: [squid-users] LDAP authentication using multiple branches
In-Reply-To: <f509e9f5-85d2-6816-5cb8-2108577a32c0@unibs.it>
References: <f509e9f5-85d2-6816-5cb8-2108577a32c0@unibs.it>
Message-ID: <5e0e14b8-ed44-39e9-2dc1-8cb762de5d9d@treenet.co.nz>

On 10/09/20 12:49 am, Antonino Gianfranco Sanacori wrote:
> Hi.
> 
> I have to configure my squid to use multiple ldap branches for
> authentication of my users, is it possible?
> 

Squid uses helpers to authenticate credentials.

What the helper does is up to the helper. Some perform LDAP searches,
some allow multiple branches, and some do not.

Check the manual for the helper you are wanting to use and see if it can
do what you need:
<http://www.squid-cache.org/Doc/man/>


Amos


From piyush.gaba at orange.com  Mon Sep 14 07:06:56 2020
From: piyush.gaba at orange.com (piyush.gaba at orange.com)
Date: Mon, 14 Sep 2020 07:06:56 +0000
Subject: [squid-users] How is Proxy chaining done ?
Message-ID: <17179_1600067217_5F5F1691_17179_209_6_FB9F07820FAE75499D7A4E37F6CD76640603735E@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>

Hi All,

I am looking forward to understand the concept of proxy chaining.

Now I have two squid proxies, one client and one webserver. These two proxies are pingable from each other and both can individually "curl" from webserver.
But I want to send HTTP request from Client to Server via Chaining Proxy.


*Expected Output is *: 1. Request will be made to proxy1.
                                         2. Request should go from proxy1 to proxy2.
                                          3. proxy2 should forward the Request to Server

Also, of course Client IP is not be visible to Server.

Looking forward to your valuable advices.

Bien cordialement,
Piyush Gaba
Tower B, 8th Floor, DLF Infinity Towers,
DLF Cyber City Phase - II
Gurgaon - 122002, Haryana, INDIA
[Email] piyush.gaba at orange.com<mailto:piyush.gaba at orange.com>

_________________________________________________________________________________________________________________________

Ce message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc
pas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler
a l'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d'alteration,
Orange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.

This message and its attachments may contain confidential or privileged information that may be protected by law;
they should not be distributed, used or copied without authorisation.
If you have received this email in error, please notify the sender and delete this message and its attachments.
As emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.
Thank you.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200914/241dfba9/attachment.htm>

From rentorbuy at yahoo.com  Mon Sep 14 12:50:45 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Mon, 14 Sep 2020 12:50:45 +0000 (UTC)
Subject: [squid-users] Cannot access web servers with a specific browser
References: <1301775678.2016326.1600087845253.ref@mail.yahoo.com>
Message-ID: <1301775678.2016326.1600087845253@mail.yahoo.com>

Hi,

Before digging into the whole squid configuration, I'd like to know what the following line means:

NONE_ABORTED/200 0 CONNECT 216.58.211.36:443 - HIER_NONE/- -

I get this when trying to access a web page with a specific browser (Google Chrome).

However, from the exact same client host, any other browser works fine (IE, Firefox) and I get this in the cache log:

NONE/200 0 CONNECT 216.58.211.36:443 - ORIGINAL_DST/216.58.211.36 -

along with many other log messages that follow.

So what does NONE_ABORTED mean and what should I search for to fix this so the client can use Chrome?

Thanks,

Vieri



From Walter.H at mathemainzel.info  Mon Sep 14 14:00:13 2020
From: Walter.H at mathemainzel.info (Walter H.)
Date: Mon, 14 Sep 2020 16:00:13 +0200
Subject: [squid-users] Cannot access web servers with a specific browser
In-Reply-To: <1301775678.2016326.1600087845253@mail.yahoo.com>
References: <1301775678.2016326.1600087845253.ref@mail.yahoo.com>
 <1301775678.2016326.1600087845253@mail.yahoo.com>
Message-ID: <08fa3634-fc8f-6060-e260-bbdd8aa0b064@mathemainzel.info>

On 14.09.2020 14:50, Vieri wrote:
> Hi,
>
> Before digging into the whole squid configuration, I'd like to know what the following line means:
>
> NONE_ABORTED/200 0 CONNECT 216.58.211.36:443 - HIER_NONE/- -
>
> I get this when trying to access a web page with a specific browser (Google Chrome).
>
> However, from the exact same client host, any other browser works fine (IE, Firefox) and I get this in the cache log:
>
> NONE/200 0 CONNECT 216.58.211.36:443 - ORIGINAL_DST/216.58.211.36 -
>
> along with many other log messages that follow.
>
> So what does NONE_ABORTED mean and what should I search for to fix this so the client can use Chrome?
>
What about Microsoft Edge?

(especially the chromium based one)

as I see you don't do SSL-bump,

could it be that the clients (Chrome) capability of useable ciphersuites 
may not confirm to the ones offered by the server; the reason for 
'NONE_ABORTED'?

Walter


-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3511 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200914/b9acce28/attachment.bin>

From rentorbuy at yahoo.com  Mon Sep 14 15:37:59 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Mon, 14 Sep 2020 15:37:59 +0000 (UTC)
Subject: [squid-users] Cannot access web servers with a specific browser
In-Reply-To: <08fa3634-fc8f-6060-e260-bbdd8aa0b064@mathemainzel.info>
References: <1301775678.2016326.1600087845253.ref@mail.yahoo.com>
 <1301775678.2016326.1600087845253@mail.yahoo.com>
 <08fa3634-fc8f-6060-e260-bbdd8aa0b064@mathemainzel.info>
Message-ID: <1936283825.2085962.1600097879588@mail.yahoo.com>


On Monday, September 14, 2020, 4:00:30 PM GMT+2, Walter H. <walter.h at mathemainzel.info> wrote: 


>> So what does NONE_ABORTED mean and what should I search for to fix this so the client can use Chrome?
>>
> What about Microsoft Edge?

The client is Windows 7, so no Edge.
So I got hold of a Windows 10 client and tried Edge there. I got the same NONE_ABORTED issue while every other non-chromium browser works fine.

> as I see you don't do SSL-bump,

I am. I could send the whole config here. I also set up an explicit proxy, but it seems I'm having issues with kerberos. As a side question, how can one test negotiate_kerberos_auth on the command line? I run:
# /usr/libexec/squid/negotiate_kerberos_auth -s HTTP/fqdn at DOMAIN
WRITE_SOMETHING
BH Invalid request

What is the format/syntax of WRITE_SOMETHING?

I'd like to try the explciit proxy instead of ssl-bump to see if there's a difference.
Still, the Firefox and Chrome clients are in the same conditions and only one is failing.

> could it be that the clients (Chrome) capability of useable ciphersuites 
> may not confirm to the ones offered by the server; the reason for 
> 'NONE_ABORTED'?

If I let the clients by-pass the Squid proxy and connect directly to the servers the web pages are properly accessed -- no issues.

Thanks,

Vieri


From rousskov at measurement-factory.com  Mon Sep 14 16:01:41 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 14 Sep 2020 12:01:41 -0400
Subject: [squid-users] Cannot access web servers with a specific browser
In-Reply-To: <1301775678.2016326.1600087845253@mail.yahoo.com>
References: <1301775678.2016326.1600087845253.ref@mail.yahoo.com>
 <1301775678.2016326.1600087845253@mail.yahoo.com>
Message-ID: <d1b6385c-20af-ecf3-a13c-6ca506547fc3@measurement-factory.com>

On 9/14/20 8:50 AM, Vieri wrote:

> I get this when trying to access a web page with a specific browser (Google Chrome).

What is your Squid version? Does it have a fix for GREASE support as
detailed in https://github.com/squid-cache/squid/pull/663 ?

Alex.


From rentorbuy at yahoo.com  Mon Sep 14 16:08:41 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Mon, 14 Sep 2020 16:08:41 +0000 (UTC)
Subject: [squid-users] Cannot access web servers with a specific browser
In-Reply-To: <d1b6385c-20af-ecf3-a13c-6ca506547fc3@measurement-factory.com>
References: <1301775678.2016326.1600087845253.ref@mail.yahoo.com>
 <1301775678.2016326.1600087845253@mail.yahoo.com>
 <d1b6385c-20af-ecf3-a13c-6ca506547fc3@measurement-factory.com>
Message-ID: <92764236.2095913.1600099721065@mail.yahoo.com>


On Monday, September 14, 2020, 6:01:43 PM GMT+2, Alex Rousskov <rousskov at measurement-factory.com> wrote: 


>> I get this when trying to access a web page with a specific browser (Google Chrome).
>
> What is your Squid version? Does it have a fix for GREASE support as
> detailed in https://github.com/squid-cache/squid/pull/663 ?

I have squid-4.12.



From flashdown at data-core.org  Mon Sep 14 17:06:43 2020
From: flashdown at data-core.org (Flashdown)
Date: Mon, 14 Sep 2020 19:06:43 +0200
Subject: [squid-users] How is Proxy chaining done ?
In-Reply-To: <17179_1600067217_5F5F1691_17179_209_6_FB9F07820FAE75499D7A4E37F6CD76640603735E@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
References: <17179_1600067217_5F5F1691_17179_209_6_FB9F07820FAE75499D7A4E37F6CD76640603735E@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
Message-ID: <06ED5C6C-D77F-4A2F-BBF7-23D4489B44E4@data-core.org>

Dear Piyush,

Here you can find answers: https://wiki.squid-cache.org/ConfigExamples/Reverse/MultipleWebservers


BR, Flashdown


Am 14. September 2020 09:06:56 MESZ schrieb piyush.gaba at orange.com:
>Hi All,
>
>I am looking forward to understand the concept of proxy chaining.
>
>Now I have two squid proxies, one client and one webserver. These two
>proxies are pingable from each other and both can individually "curl"
>from webserver.
>But I want to send HTTP request from Client to Server via Chaining
>Proxy.
>
>
>*Expected Output is *: 1. Request will be made to proxy1.
>                            2. Request should go from proxy1 to proxy2.
>                         3. proxy2 should forward the Request to Server
>
>Also, of course Client IP is not be visible to Server.
>
>Looking forward to your valuable advices.
>
>Bien cordialement,
>Piyush Gaba
>Tower B, 8th Floor, DLF Infinity Towers,
>DLF Cyber City Phase - II
>Gurgaon - 122002, Haryana, INDIA
>[Email] piyush.gaba at orange.com<mailto:piyush.gaba at orange.com>
>
>_________________________________________________________________________________________________________________________
>
>Ce message et ses pieces jointes peuvent contenir des informations
>confidentielles ou privilegiees et ne doivent donc
>pas etre diffuses, exploites ou copies sans autorisation. Si vous avez
>recu ce message par erreur, veuillez le signaler
>a l'expediteur et le detruire ainsi que les pieces jointes. Les
>messages electroniques etant susceptibles d'alteration,
>Orange decline toute responsabilite si ce message a ete altere, deforme
>ou falsifie. Merci.
>
>This message and its attachments may contain confidential or privileged
>information that may be protected by law;
>they should not be distributed, used or copied without authorisation.
>If you have received this email in error, please notify the sender and
>delete this message and its attachments.
>As emails may be altered, Orange is not liable for messages that have
>been modified, changed or falsified.
>Thank you.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200914/5def29bd/attachment.htm>

From squid3 at treenet.co.nz  Mon Sep 14 18:04:14 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 15 Sep 2020 06:04:14 +1200
Subject: [squid-users] How is Proxy chaining done ?
In-Reply-To: <06ED5C6C-D77F-4A2F-BBF7-23D4489B44E4@data-core.org>
References: <17179_1600067217_5F5F1691_17179_209_6_FB9F07820FAE75499D7A4E37F6CD76640603735E@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
 <06ED5C6C-D77F-4A2F-BBF7-23D4489B44E4@data-core.org>
Message-ID: <c3e18ed8-dad7-a52e-1227-5b573512f008@treenet.co.nz>


On 15/09/20 5:06 am, Flashdown wrote:
> Dear Piyush,
> 
> Here you can find answers:
> https://wiki.squid-cache.org/ConfigExamples/Reverse/MultipleWebservers
> 

And <https://wiki.squid-cache.org/Features/CacheHierarchy>

Amos


From service.mv at gmail.com  Mon Sep 14 18:34:19 2020
From: service.mv at gmail.com (Service MV)
Date: Mon, 14 Sep 2020 15:34:19 -0300
Subject: [squid-users] compilation error
Message-ID: <CA+d==oEekXJSy-uqRmQh7xCviOfEQan8V=mLoRFpm+YCWmxrBQ@mail.gmail.com>

Hi everyone, I don't know if you can help me with this. I?m trying to
compile SQUID beta 5.0.4 on Debian 10 but I get an error:

cp ../../src/tests/stub_debug.cc tests/stub_debug.cc
cp: cannot create regular file 'tests/stub_debug.cc': No such file or
directory
make[3]: *** [Makefile:1518: tests/stub_debug.cc] Error 1
make[3]: Leaving directory '/root/squid-5.0.4/tools/squidclient'
make[2]: *** [Makefile:1049: all-recursive] Error 1
make[2]: Leaving directory '/root/squid-5.0.4/tools/squidclient'
make[1]: *** [Makefile:1191: all-recursive] Error 1
make[1]: Leaving directory '/root/squid-5.0.4/tools'
make: *** [Makefile:591: all-recursive] Error 1

I attach the script:
./configure --prefix=/opt/squid-504 --includedir=/include
--mandir=/share/man --infodir=/share/info
--localstatedir=/opt/squid-504/var --disable-maintainer-mode
--disable-dependency-tracking --disable-silent-rules --enable-inline
--enable-async-io --enable-storeio=ufs,aufs,diskd
--enable-removal-policies=lru,heap --enable-delay-pools
--enable-cache-digests --enable-underscores --enable-icap-client
--enable-follow-x-forwarded-for --enable-auth-basic=fake,LDAP
--enable-auth-digest=file,LDAP --enable-auth-negotiate=kerberos,wrapper
--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group
--enable-arp-acl --enable-esi--disable-translation
--with-logdir=/var/log/squid-504 --with-pidfile=/var/run/squid-504.pid
--with-filedescriptors=65536 --with-large-files --with-default-user=proxy
--enable-linux-netfilter --enable-ltdl-convenience --with-openssl
--enable-ssl --enable-ssl-crtd

make && make install

Any help would be welcome, thank you very much.

Greetings
Gabriel
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200914/ff64e3ae/attachment.htm>

From rousskov at measurement-factory.com  Mon Sep 14 19:22:50 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 14 Sep 2020 15:22:50 -0400
Subject: [squid-users] Cannot access web servers with a specific browser
In-Reply-To: <92764236.2095913.1600099721065@mail.yahoo.com>
References: <1301775678.2016326.1600087845253.ref@mail.yahoo.com>
 <1301775678.2016326.1600087845253@mail.yahoo.com>
 <d1b6385c-20af-ecf3-a13c-6ca506547fc3@measurement-factory.com>
 <92764236.2095913.1600099721065@mail.yahoo.com>
Message-ID: <3217bd56-1042-ae3a-032f-34ae07f3ae6f@measurement-factory.com>

On 9/14/20 12:08 PM, Vieri wrote:

> On Monday, September 14, 2020, 6:01:43 PM GMT+2, Alex Rousskov wrote: 

>>> I get this when trying to access a web page with a specific browser (Google Chrome).

>> What is your Squid version? Does it have a fix for GREASE support as
>> detailed in https://github.com/squid-cache/squid/pull/663 ?

> I have squid-4.12.

.. which means that the answer to my second question is "no". You need
to upgrade to Squid v4.13 (for several reasons).

Alex.


From squid3 at treenet.co.nz  Mon Sep 14 20:56:31 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 15 Sep 2020 08:56:31 +1200
Subject: [squid-users] compilation error
In-Reply-To: <CA+d==oEekXJSy-uqRmQh7xCviOfEQan8V=mLoRFpm+YCWmxrBQ@mail.gmail.com>
References: <CA+d==oEekXJSy-uqRmQh7xCviOfEQan8V=mLoRFpm+YCWmxrBQ@mail.gmail.com>
Message-ID: <48fcb91d-0078-6a7f-1aaf-077f4a686632@treenet.co.nz>

On 15/09/20 6:34 am, Service MV wrote:
> Hi everyone, I don't know if you can help me with this. I?m trying to
> compile SQUID beta 5.0.4 on Debian 10 but I get an error:
> 

Is this ocurring in a fresh download of the sources tarball? or fetched
via some other method?

Amos


From service.mv at gmail.com  Mon Sep 14 21:04:25 2020
From: service.mv at gmail.com (Service MV)
Date: Mon, 14 Sep 2020 18:04:25 -0300
Subject: [squid-users] compilation error
In-Reply-To: <48fcb91d-0078-6a7f-1aaf-077f4a686632@treenet.co.nz>
References: <CA+d==oEekXJSy-uqRmQh7xCviOfEQan8V=mLoRFpm+YCWmxrBQ@mail.gmail.com>
 <48fcb91d-0078-6a7f-1aaf-077f4a686632@treenet.co.nz>
Message-ID: <CA+d==oHSNzoN3iEzWbkdON+DC88emtUdkwGsbnWKUytAV5_G6Q@mail.gmail.com>

Fresh download of source code in a fresh server.


El lun., 14 sep. 2020 18:02, Amos Jeffries <squid3 at treenet.co.nz> escribi?:

> On 15/09/20 6:34 am, Service MV wrote:
> > Hi everyone, I don't know if you can help me with this. I?m trying to
> > compile SQUID beta 5.0.4 on Debian 10 but I get an error:
> >
>
> Is this ocurring in a fresh download of the sources tarball? or fetched
> via some other method?
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200914/98c15e57/attachment.htm>

From service.mv at gmail.com  Mon Sep 14 21:07:16 2020
From: service.mv at gmail.com (Service MV)
Date: Mon, 14 Sep 2020 18:07:16 -0300
Subject: [squid-users] compilation error
In-Reply-To: <CA+d==oHSNzoN3iEzWbkdON+DC88emtUdkwGsbnWKUytAV5_G6Q@mail.gmail.com>
References: <CA+d==oEekXJSy-uqRmQh7xCviOfEQan8V=mLoRFpm+YCWmxrBQ@mail.gmail.com>
 <48fcb91d-0078-6a7f-1aaf-077f4a686632@treenet.co.nz>
 <CA+d==oHSNzoN3iEzWbkdON+DC88emtUdkwGsbnWKUytAV5_G6Q@mail.gmail.com>
Message-ID: <CA+d==oFXuwRj6kO7DT8W2v5XUFbfxT+PP7Tf_tw3nB_VMkj+gQ@mail.gmail.com>

Exactly this:

wget http://www.squid-cache.org/Versions/v5/squid-5.0.4.tar.gz


El lun., 14 sep. 2020 18:04, Service MV <service.mv at gmail.com> escribi?:

> Fresh download of source code in a fresh server.
>
>
> El lun., 14 sep. 2020 18:02, Amos Jeffries <squid3 at treenet.co.nz>
> escribi?:
>
>> On 15/09/20 6:34 am, Service MV wrote:
>> > Hi everyone, I don't know if you can help me with this. I?m trying to
>> > compile SQUID beta 5.0.4 on Debian 10 but I get an error:
>> >
>>
>> Is this ocurring in a fresh download of the sources tarball? or fetched
>> via some other method?
>>
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200914/0527ddc8/attachment.htm>

From squid3 at treenet.co.nz  Mon Sep 14 21:37:45 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 15 Sep 2020 09:37:45 +1200
Subject: [squid-users] compilation error
In-Reply-To: <CA+d==oHSNzoN3iEzWbkdON+DC88emtUdkwGsbnWKUytAV5_G6Q@mail.gmail.com>
References: <CA+d==oEekXJSy-uqRmQh7xCviOfEQan8V=mLoRFpm+YCWmxrBQ@mail.gmail.com>
 <48fcb91d-0078-6a7f-1aaf-077f4a686632@treenet.co.nz>
 <CA+d==oHSNzoN3iEzWbkdON+DC88emtUdkwGsbnWKUytAV5_G6Q@mail.gmail.com>
Message-ID: <62e84b90-e950-a3df-6ede-6688490234c9@treenet.co.nz>

On 15/09/20 9:04 am, Service MV wrote:
> Fresh download of source code in a fresh server.
> 

Thanks. Looks like I've got some more digging to do on this issue.


It should work okay if you use "make -j1" for the build stage.

Amos

> 
> El lun., 14 sep. 2020 18:02, Amos Jeffries escribi?:
> 
>     On 15/09/20 6:34 am, Service MV wrote:
>     > Hi everyone, I don't know if you can help me with this. I?m trying to
>     > compile SQUID beta 5.0.4 on Debian 10 but I get an error:
>     >
> 
>     Is this ocurring in a fresh download of the sources tarball? or fetched
>     via some other method?
> 
>     Amos
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
> 


From jasonl at loel.fr  Tue Sep 15 07:08:25 2020
From: jasonl at loel.fr (Jason Loel)
Date: Tue, 15 Sep 2020 11:08:25 +0400
Subject: [squid-users] Proxy auth exception
In-Reply-To: <f1053714996ce474f343d5e0b86e9104@loel.fr>
References: <f1053714996ce474f343d5e0b86e9104@loel.fr>
Message-ID: <f7b1e4eb563eba5b37903f8c66eedc00@loel.fr>

Hi,

I use Squid 4.6 with Debian 10 (Buster).

I use Kerberos Authentication and it works :

   auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s 
HTTP/proxy.lab.lan at LAB.LAN
   auth_param negotiate children 10
   auth_param negotiate keep_alive on
   acl lan proxy_auth REQUIRED
   icap_send_client_username on
   http_access allow lan

I have a local web server named "hotline", itself uses also kerberos 
auth (Apache).

If i don't use the proxy, i can browse http://hotline
If i use the proxy, i can't browse the page, i get "this site can't be 
reached"
If i remove this 6 lines in squid.conf, the website is available.

How can i add an exception for "http://hotline" to not use the acl lan ?

Merci !

Jasaon L.


From jasonl at loel.fr  Tue Sep 15 07:26:35 2020
From: jasonl at loel.fr (Jason Loel)
Date: Tue, 15 Sep 2020 11:26:35 +0400
Subject: [squid-users] Proxy auth exception
In-Reply-To: <f7b1e4eb563eba5b37903f8c66eedc00@loel.fr>
References: <f1053714996ce474f343d5e0b86e9104@loel.fr>
 <f7b1e4eb563eba5b37903f8c66eedc00@loel.fr>
Message-ID: <214d09051dd295ec7b44f9087d640551@loel.fr>

Got it !
Just add the following line before :

acl vip dst 192.168.1.10
http_access allow vip

Sorry for the noise.

Le 2020-09-15 11:08, Jason Loel a ?crit?:
> Hi,
> 
> I use Squid 4.6 with Debian 10 (Buster).
> 
> I use Kerberos Authentication and it works :
> 
>   auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth
> -s HTTP/proxy.lab.lan at LAB.LAN
>   auth_param negotiate children 10
>   auth_param negotiate keep_alive on
>   acl lan proxy_auth REQUIRED
>   icap_send_client_username on
>   http_access allow lan
> 
> I have a local web server named "hotline", itself uses also kerberos
> auth (Apache).
> 
> If i don't use the proxy, i can browse http://hotline
> If i use the proxy, i can't browse the page, i get "this site can't be 
> reached"
> If i remove this 6 lines in squid.conf, the website is available.
> 
> How can i add an exception for "http://hotline" to not use the acl lan 
> ?
> 
> Merci !
> 
> Jasaon L.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From belle at bazuin.nl  Tue Sep 15 08:15:47 2020
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Tue, 15 Sep 2020 10:15:47 +0200
Subject: [squid-users] compilation error
In-Reply-To: <62e84b90-e950-a3df-6ede-6688490234c9@treenet.co.nz>
References: <CA+d==oHSNzoN3iEzWbkdON+DC88emtUdkwGsbnWKUytAV5_G6Q@mail.gmail.com>
Message-ID: <vmime.5f607833.653f.3c3ed76541af27e3@ms249-lin-003.rotterdam.bazuin.nl>

Hai Amos, 

Just a small question. If i may hop in this thread. 

Based on TP starter, i also took a 5.0.4 to build on debian, i build in pbuilder/cowbuilder env. 

I first attempted to build and that errored on time_quote. 
I found that i had to add libtdb-dev to the build depends in debian/control 
And now its building, only Im ending with this eror. (ideas?)


x86_64-linux-gnu-g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\" -DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\" -DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I../.. -I../../include -I../../lib -I../../src -I../../include  -isystem /usr/include/mit-krb5  -Wdate-time -D_FORTIFY_SOURCE=2 -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -Werror -pipe -D_REENTRANT -I/usr/include/libxml2 -I/usr/include/p11-kit-1 -g -O2 -fdebug-prefix-map=/build/squid-5.0.4=. -fstack-protector-strong -Wformat -Werror=format-security -c -o Transport.o Transport.cc
cp ../../src/tests/stub_debug.cc tests/stub_debug.cc
cp: cannot create regular file 'tests/stub_debug.cc': No such file or directory
make[4]: *** [Makefile:1518: tests/stub_debug.cc] Error 1
make[4]: *** Waiting for unfinished jobs....
make[4]: Leaving directory '/build/squid-5.0.4/tools/squidclient'
make[3]: *** [Makefile:1049: all-recursive] Error 1
make[3]: Leaving directory '/build/squid-5.0.4/tools/squidclient'
make[2]: *** [Makefile:1191: all-recursive] Error 1
make[2]: Leaving directory '/build/squid-5.0.4/tools'
make[1]: *** [Makefile:591: all-recursive] Error 1
make[1]: Leaving directory '/build/squid-5.0.4'
make: *** [/usr/share/cdbs/1/class/makefile.mk:77: debian/stamp-makefile-build] Error 2
dpkg-buildpackage: error: debian/rules build subprocess returned exit status 2
I: copying local configuration

This part, 
cp ../../src/tests/stub_debug.cc tests/stub_debug.cc
cp: cannot create regular file 'tests/stub_debug.cc'

I checked for : tests/stub_debug.cc its there.. 
So why this is, i dont know. (yet)

How i make the packages. 
I get the sid sources, get latest squid-caches sources.
Copy the debian folder in the new, update where needed,refreshed patches,
and mostl of the time, i hardly need to change things.
Squid 4.13 runs great, and was done in the same way. 

Only thing i miss/dont know is, how can i find which packages are needed,to build squid,
based on the new sources.tar.gz of squid. I think i still miss a package but im not sure here.

Thanks in advance, Amos. 
Great work on squid on debian you doing. 
Its a long time ago squid errored in building and im doing this since 3.x.x :-) 


Greetz, 

Louis



> -----Oorspronkelijk bericht-----
> Van: squid-users 
> [mailto:squid-users-bounces at lists.squid-cache.org] Namens 
> Amos Jeffries
> Verzonden: maandag 14 september 2020 23:38
> Aan: Service MV
> CC: Squid Users
> Onderwerp: Re: [squid-users] compilation error
> 
> On 15/09/20 9:04 am, Service MV wrote:
> > Fresh download of source code in a fresh server.
> > 
> 
> Thanks. Looks like I've got some more digging to do on this issue.
> 
> 
> It should work okay if you use "make -j1" for the build stage.
> 
> Amos
> 
> > 
> > El lun., 14 sep. 2020 18:02, Amos Jeffries escribi?:
> > 
> >     On 15/09/20 6:34 am, Service MV wrote:
> >     > Hi everyone, I don't know if you can help me with 
> this. I?m trying to
> >     > compile SQUID beta 5.0.4 on Debian 10 but I get an error:
> >     >
> > 
> >     Is this ocurring in a fresh download of the sources 
> tarball? or fetched
> >     via some other method?
> > 
> >     Amos
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>
> >     http://lists.squid-cache.org/listinfo/squid-users
> > 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From rentorbuy at yahoo.com  Tue Sep 15 16:52:05 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Tue, 15 Sep 2020 16:52:05 +0000 (UTC)
Subject: [squid-users] Cannot access web servers with a specific browser
In-Reply-To: <3217bd56-1042-ae3a-032f-34ae07f3ae6f@measurement-factory.com>
References: <1301775678.2016326.1600087845253.ref@mail.yahoo.com>
 <1301775678.2016326.1600087845253@mail.yahoo.com>
 <d1b6385c-20af-ecf3-a13c-6ca506547fc3@measurement-factory.com>
 <92764236.2095913.1600099721065@mail.yahoo.com>
 <3217bd56-1042-ae3a-032f-34ae07f3ae6f@measurement-factory.com>
Message-ID: <981792300.2610864.1600188725712@mail.yahoo.com>


On Monday, September 14, 2020, 9:22:52 PM GMT+2, Alex Rousskov <rousskov at measurement-factory.com> wrote: 


>> I have squid-4.12.
>
> .. which means that the answer to my second question is "no". You need
> to upgrade to Squid v4.13 (for several reasons).

As simple as that.
Thank you very much. I can confirm that fixed the issue.

Vieri


From ngtech1ltd at gmail.com  Tue Sep 15 17:17:17 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Tue, 15 Sep 2020 20:17:17 +0300
Subject: [squid-users] Squid ICAP DNS lookup failure fixed?
In-Reply-To: <AM6PR04MB565385DC6311CCD5C9A21D519D2D0@AM6PR04MB5653.eurprd04.prod.outlook.com>
References: <AM6PR04MB565385DC6311CCD5C9A21D519D2D0@AM6PR04MB5653.eurprd04.prod.outlook.com>
Message-ID: <000201d68b84$10b9e310$322da930$@gmail.com>

Hey Andy,

 

What have you tried in your debug?

What OS are you using Squid ontop?

 

It's possible that this issue is not related 100% to squid and it might be a
different issue then in the post by Aashima.

Have you tried debugging DNS resolution with tcpdump or dnstap or Squid
debug?

If so please post the relevant details.

 

If it can be reproduced in any environment with the same OS I believe it
would be much simpler to fix somehow.

(I am not volunteering to fix it.)

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email:  <mailto:ngtech1ltd at gmail.com> ngtech1ltd at gmail.com

 

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
VON EUW Andreas
Sent: Friday, September 4, 2020 4:19 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid ICAP DNS lookup failure fixed?

 

Hi all, 

 

I'm using squid 3.5.20 and I'm having the same problem as Aashima Madaan in
his Mailing list thread from 4 years ago. 

After Squid Server Restart the ICAP Integration is failing, after some
minutes DNS resolution was done successfully and everything is fine. 
Like in the Post from Aashima: 

https://squid-users.squid-cache.narkive.com/YZLtJNiW/dns-lookup-fails-initia
lly-for-fqdn-in-squid#post12 

 

>From the thread I can see that there was made some kind of patch. Is this
DNS resolving issue fixed in a new Squid version?

 

Regards, Andy

 

Ce message est confidentiel; Son contenu ne represente en aucun cas
un engagement de la part de AXA sous reserve de tout accord conclu
par ecrit entre vous et AXA. Toute publication, utilisation ou 
diffusion, meme partielle, doit etre autorisee prealablement. Si
vous n'etes pas destinataire de ce message, merci d'en avertir 
immediatement l'expediteur.

This message is confidential; its contents do not constitute a
commitment by AXA except where provided for in a written agreement 
between you and AXA. Any unauthorised disclosure, use or dissemi-
nation, either whole or partial, is prohibited. If you are not the
intended recipient of the message, please notify the sender imme-
diately.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200915/1069dc8f/attachment.htm>

From ngtech1ltd at gmail.com  Tue Sep 15 17:24:52 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Tue, 15 Sep 2020 20:24:52 +0300
Subject: [squid-users] compilation error
In-Reply-To: <vmime.5f607833.653f.3c3ed76541af27e3@ms249-lin-003.rotterdam.bazuin.nl>
References: <CA+d==oHSNzoN3iEzWbkdON+DC88emtUdkwGsbnWKUytAV5_G6Q@mail.gmail.com>
 <vmime.5f607833.653f.3c3ed76541af27e3@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <000001d68b85$200d44a0$6027cde0$@gmail.com>

I will try to test 5.0.4 build on couple local OS's.

It seems that at-least CentOS 8 is showing the same issue.

Eliezer
----
Eliezer Croitoru
Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of L.P.H. van Belle
Sent: Tuesday, September 15, 2020 11:16 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] compilation error

Hai Amos, 

Just a small question. If i may hop in this thread. 

Based on TP starter, i also took a 5.0.4 to build on debian, i build in pbuilder/cowbuilder env. 

I first attempted to build and that errored on time_quote. 
I found that i had to add libtdb-dev to the build depends in debian/control 
And now its building, only Im ending with this eror. (ideas?)


x86_64-linux-gnu-g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\" -DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\" -DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I../.. -I../../include -I../../lib -I../../src -I../../include  -isystem /usr/include/mit-krb5  -Wdate-time -D_FORTIFY_SOURCE=2 -I/usr/include/libxml2 -Wall -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -Werror -pipe -D_REENTRANT -I/usr/include/libxml2 -I/usr/include/p11-kit-1 -g -O2 -fdebug-prefix-map=/build/squid-5.0.4=. -fstack-protector-strong -Wformat -Werror=format-security -c -o Transport.o Transport.cc
cp ../../src/tests/stub_debug.cc tests/stub_debug.cc
cp: cannot create regular file 'tests/stub_debug.cc': No such file or directory
make[4]: *** [Makefile:1518: tests/stub_debug.cc] Error 1
make[4]: *** Waiting for unfinished jobs....
make[4]: Leaving directory '/build/squid-5.0.4/tools/squidclient'
make[3]: *** [Makefile:1049: all-recursive] Error 1
make[3]: Leaving directory '/build/squid-5.0.4/tools/squidclient'
make[2]: *** [Makefile:1191: all-recursive] Error 1
make[2]: Leaving directory '/build/squid-5.0.4/tools'
make[1]: *** [Makefile:591: all-recursive] Error 1
make[1]: Leaving directory '/build/squid-5.0.4'
make: *** [/usr/share/cdbs/1/class/makefile.mk:77: debian/stamp-makefile-build] Error 2
dpkg-buildpackage: error: debian/rules build subprocess returned exit status 2
I: copying local configuration

This part, 
cp ../../src/tests/stub_debug.cc tests/stub_debug.cc
cp: cannot create regular file 'tests/stub_debug.cc'

I checked for : tests/stub_debug.cc its there.. 
So why this is, i dont know. (yet)

How i make the packages. 
I get the sid sources, get latest squid-caches sources.
Copy the debian folder in the new, update where needed,refreshed patches,
and mostl of the time, i hardly need to change things.
Squid 4.13 runs great, and was done in the same way. 

Only thing i miss/dont know is, how can i find which packages are needed,to build squid,
based on the new sources.tar.gz of squid. I think i still miss a package but im not sure here.

Thanks in advance, Amos. 
Great work on squid on debian you doing. 
Its a long time ago squid errored in building and im doing this since 3.x.x :-) 


Greetz, 

Louis



> -----Oorspronkelijk bericht-----
> Van: squid-users 
> [mailto:squid-users-bounces at lists.squid-cache.org] Namens 
> Amos Jeffries
> Verzonden: maandag 14 september 2020 23:38
> Aan: Service MV
> CC: Squid Users
> Onderwerp: Re: [squid-users] compilation error
> 
> On 15/09/20 9:04 am, Service MV wrote:
> > Fresh download of source code in a fresh server.
> > 
> 
> Thanks. Looks like I've got some more digging to do on this issue.
> 
> 
> It should work okay if you use "make -j1" for the build stage.
> 
> Amos
> 
> > 
> > El lun., 14 sep. 2020 18:02, Amos Jeffries escribi?:
> > 
> >     On 15/09/20 6:34 am, Service MV wrote:
> >     > Hi everyone, I don't know if you can help me with 
> this. I?m trying to
> >     > compile SQUID beta 5.0.4 on Debian 10 but I get an error:
> >     >
> > 
> >     Is this ocurring in a fresh download of the sources 
> tarball? or fetched
> >     via some other method?
> > 
> >     Amos
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>
> >     http://lists.squid-cache.org/listinfo/squid-users
> > 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From wangangelo at hotmail.com  Thu Sep 17 03:32:10 2020
From: wangangelo at hotmail.com (Angelo Wang)
Date: Thu, 17 Sep 2020 03:32:10 +0000
Subject: [squid-users] Squid Subnet Help?
Message-ID: <BLAPR16MB38914298517732C9558DDA6EDE3E0@BLAPR16MB3891.namprd16.prod.outlook.com>

Hi,


1 . If i have a multiple subnet and would like to disallow a user to access the subnet ips how would i be able to do this?


Example I have subnet 138.12.14.0/24 and 138.100.140/24


And would only like to allow X user via IP or via USER:PW to access only 138.12.14.0/26, and then block him from accessing other subnets?


2. How do I configure it in a way that I can add another USER/IP and have them access 138.12.14.10/30 for example?


Thanks so much

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200917/1d115c4b/attachment.htm>

From squid3 at treenet.co.nz  Thu Sep 17 04:36:13 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 17 Sep 2020 16:36:13 +1200
Subject: [squid-users] Squid Subnet Help?
In-Reply-To: <BLAPR16MB38914298517732C9558DDA6EDE3E0@BLAPR16MB3891.namprd16.prod.outlook.com>
References: <BLAPR16MB38914298517732C9558DDA6EDE3E0@BLAPR16MB3891.namprd16.prod.outlook.com>
Message-ID: <a52de99e-cac8-d3e1-4c1d-f3cf25767ce1@treenet.co.nz>

On 17/09/20 3:32 pm, Angelo Wang wrote:
> Hi,
> 
> 
> 1 . If i have a multiple subnet and would like to disallow a user to
> access the subnet ips how would i be able to do this?
> 
> 
> Example I have subnet 138.12.14.0/24 and 138.100.140/24
> 
> 
> And would only like to allow X user via IP or via USER:PW to access only
> 138.12.14.0/26, and then block him from accessing other subnets??
> 

Be aware that HTTP protocol has no concept of subnets, only resources.
Any resource could have servers in both the allowed and non-allowed areas.

  acl userX note user X
  acl subnet12 dst 138.12.14.0/24
  miss_access deny userX subnet12


Amos


From zingfrontlzf at gmail.com  Thu Sep 17 05:22:14 2020
From: zingfrontlzf at gmail.com (Wind Lee)
Date: Thu, 17 Sep 2020 13:22:14 +0800
Subject: [squid-users] Help Request: How to deal with Basic Authentication
Message-ID: <f9e0e530-6548-c01d-a948-4ebbf990d267@gmail.com>

Hi all,

I'm trying to set up a http(s) proxy with Basic Authentication, for now 
it works fine without auth, but as long as I add those auth part, it 
keeps rejecting auth request from client side, such as keeps requesting 
username and password on google chrome.

I've checked the /usr/lib64/squid/basic_ncsa_auth /PATH/TO/PASSWD_FILE 
in console, and it returns OK when I type correct username/password.

Distribution is CentOS 7, squid version is 4.9

I really don't know what to do next, here's the configuration:

https://paste.ubuntu.com/p/SXf6tN8cCg/

Thanks.

Wind Lee.

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From piyush.gaba at orange.com  Thu Sep 17 08:51:02 2020
From: piyush.gaba at orange.com (piyush.gaba at orange.com)
Date: Thu, 17 Sep 2020 08:51:02 +0000
Subject: [squid-users] Client <--> Squid <--> FTP usecase
Message-ID: <1553_1600332663_5F632377_1553_399_1_FB9F07820FAE75499D7A4E37F6CD76640603AFF0@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>

Hi All,

I have been working to check squid v4.13 functionality with a FTP.
My use case is simple and it says we have a file on FTP at root and I just have to wget that file from my client.

So I have,

-->Created a file on root of FTP "touch test.txt"
-->Allowed the destination IP of FTP in my squid.conf

Then I have exported proxy on my client as
export ftp_proxy=http://${squid.IP}:${Squid.Port}/
and
Now when I try to download the file like this,
wget -m ftp://<id>:<pass>@${FTP.Prod_IP}/test.txt

I am facing below error on client:

Proxy request sent, awaiting response... 502 Bad Gateway

which indicates that the squid (server acting as a proxy) was not able to get a valid or any response from the FTP server.
So, I tried wget directly from my squid to FTP, it ended in error,

"Logging in as root ... Error in server greeting. Retrying." (which is my concern)

It'd be great, If there is any advice I could get from you guys as about where I am wrong or what am I missing.

Thank You

Bien cordialement,
Piyush Gaba
Tower B, 8th Floor, DLF Infinity Towers,
DLF Cyber City Phase - II
Gurgaon - 122002, Haryana, INDIA
[Email] piyush.gaba at orange.com<mailto:piyush.gaba at orange.com>

_________________________________________________________________________________________________________________________

Ce message et ses pieces jointes peuvent contenir des informations confidentielles ou privilegiees et ne doivent donc
pas etre diffuses, exploites ou copies sans autorisation. Si vous avez recu ce message par erreur, veuillez le signaler
a l'expediteur et le detruire ainsi que les pieces jointes. Les messages electroniques etant susceptibles d'alteration,
Orange decline toute responsabilite si ce message a ete altere, deforme ou falsifie. Merci.

This message and its attachments may contain confidential or privileged information that may be protected by law;
they should not be distributed, used or copied without authorisation.
If you have received this email in error, please notify the sender and delete this message and its attachments.
As emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.
Thank you.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200917/35205303/attachment.htm>

From squid3 at treenet.co.nz  Thu Sep 17 10:34:06 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 17 Sep 2020 22:34:06 +1200
Subject: [squid-users] Help Request: How to deal with Basic
 Authentication
In-Reply-To: <f9e0e530-6548-c01d-a948-4ebbf990d267@gmail.com>
References: <f9e0e530-6548-c01d-a948-4ebbf990d267@gmail.com>
Message-ID: <88ec9481-2114-c70f-9861-f5b9b53b8c4c@treenet.co.nz>

On 17/09/20 5:22 pm, Wind Lee wrote:
> Hi all,
> 
> I'm trying to set up a http(s) proxy with Basic Authentication, for now
> it works fine without auth, but as long as I add those auth part, it
> keeps rejecting auth request from client side, such as keeps requesting
> username and password on google chrome.
> 

What do the Squid logs say is going on?

> I've checked the /usr/lib64/squid/basic_ncsa_auth /PATH/TO/PASSWD_FILE
> in console, and it returns OK when I type correct username/password.
> 
> Distribution is CentOS 7, squid version is 4.9
> 

Please upgrade to 4.13.


> I really don't know what to do next, here's the configuration:
> 
> https://paste.ubuntu.com/p/SXf6tN8cCg/
> 

I see Squid being told to accept valid credentials. What about missing
ones? invalid ones? garbage credentials?

Best practice for auth is to deny all non-valid credentials before
accepting.

  http_access deny !auth
  http_access allow localnet


Amos



From zingfrontlzf at gmail.com  Thu Sep 17 11:34:40 2020
From: zingfrontlzf at gmail.com (Wind Lee)
Date: Thu, 17 Sep 2020 19:34:40 +0800
Subject: [squid-users] Help Request: How to deal with Basic
 Authentication
In-Reply-To: <88ec9481-2114-c70f-9861-f5b9b53b8c4c@treenet.co.nz>
References: <f9e0e530-6548-c01d-a948-4ebbf990d267@gmail.com>
 <88ec9481-2114-c70f-9861-f5b9b53b8c4c@treenet.co.nz>
Message-ID: <7406a2ca-3fe8-1f87-79e7-8a28ee0f4046@gmail.com>

Thanks Amos, problems has been fixed, it's because of my passwd file 
couldn't be read by user squid, I wrongly placed it at root user's home 
directory and forgot to change its owner attributes.

On 2020/9/17 6:34 PM, Amos Jeffries wrote:
> I see Squid being told to accept valid credentials. What about missing
> ones? invalid ones? garbage credentials?
>
> Best practice for auth is to deny all non-valid credentials before
> accepting.
>
>    http_access deny !auth
>    http_access allow localnet
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Thu Sep 17 13:24:07 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 18 Sep 2020 01:24:07 +1200
Subject: [squid-users] Client <--> Squid <--> FTP usecase
In-Reply-To: <1553_1600332663_5F632377_1553_399_1_FB9F07820FAE75499D7A4E37F6CD76640603AFF0@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
References: <1553_1600332663_5F632377_1553_399_1_FB9F07820FAE75499D7A4E37F6CD76640603AFF0@OPEXCAUBMA1.corporate.adroot.infra.ftgroup>
Message-ID: <41264b5f-3899-86fb-57cc-453f2fc5bbd3@treenet.co.nz>

On 17/09/20 8:51 pm, piyush.gaba wrote:
> Hi All,
> 
> 
> I have been working to check squid v4.13 functionality with a FTP.
> 
> My use case is simple and it says we have a file on FTP at root and I
> just have to wget that file from my client.
> 

Then simply have Squid setup as a normal proxy and use:

  wget -X ${squid.IP}:${Squid.Port} \
    -m ftp://<id>:<pass>@${FTP.Prod_IP}/test.txt


> ?
> 
> So I have,
> 
> ?> 
> ?Created a file on root of FTP ?*touch test.txt*?
> 
> ?Allowed the destination IP of FTP in my squid.conf
> 
> ?
> 
> Then I have exported proxy on my *client* as
> 
> *export ftp_proxy=http://${squid.IP}:${Squid.Port}/*
> 
> and
> 
> Now when I try to download the file like this,
> 
> *wget -m ftp://<id>:<pass>@${FTP.Prod_IP}/test.txt*
> 
> ?
> 
> I am facing below error on *client*:
> 
> ?
> 
> *Proxy request sent, awaiting response... 502 Bad Gateway*
> 
> *?*
> 
> which indicates that the squid (server acting as a proxy) was not able
> to get a valid or any response from the FTP server.
> 
> So, I tried wget directly from my *squid* to *FTP, *it ended in error,
> 

What? exact details of this alternative command please.

> ?
> 
> *?Logging in as root ... Error in server greeting. Retrying.? *(which is
> my concern)**
> 
> ?
> 
> It?d be great, If there is any advice I could get from you guys as about
> where I am wrong or what am I missing.
> 

Make use of the wget --verbose debugging output and Squid logs to get
more information about what is actually going on.


Amos


From squid3 at treenet.co.nz  Thu Sep 17 13:32:30 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 18 Sep 2020 01:32:30 +1200
Subject: [squid-users] Help Request: How to deal with Basic
 Authentication
In-Reply-To: <7406a2ca-3fe8-1f87-79e7-8a28ee0f4046@gmail.com>
References: <f9e0e530-6548-c01d-a948-4ebbf990d267@gmail.com>
 <88ec9481-2114-c70f-9861-f5b9b53b8c4c@treenet.co.nz>
 <7406a2ca-3fe8-1f87-79e7-8a28ee0f4046@gmail.com>
Message-ID: <391c719d-84a5-7a08-da00-75d3ada690b9@treenet.co.nz>

FYI;
 if this file is only accessed by the Squid auth helper (usually the
case) it should be in /etc/squid or a sub-dir under there and have the
proxy group read access (no write). Ownership should be root or an admin
account with permission to add/remove entries, Squid does not need those
permissions.

If it is shared with other systems, then there should be an appropriate
group that Squid can be added to gain read-only access for validating
the credentials in it.

Amos


On 17/09/20 11:34 pm, Wind Lee wrote:
> Thanks Amos, problems has been fixed, it's because of my passwd file
> couldn't be read by user squid, I wrongly placed it at root user's home
> directory and forgot to change its owner attributes.
> 
> On 2020/9/17 6:34 PM, Amos Jeffries wrote:
>> I see Squid being told to accept valid credentials. What about missing
>> ones? invalid ones? garbage credentials?
>>
>> Best practice for auth is to deny all non-valid credentials before
>> accepting.
>>
>> ?? http_access deny !auth
>> ?? http_access allow localnet
>>
>>
>> Amos
>>


From Ralf.Hildebrandt at charite.de  Tue Sep 22 07:47:37 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 22 Sep 2020 09:47:37 +0200
Subject: [squid-users] Change of server hardware (?) resulted in massive
 increase of crashes
Message-ID: <20200922074737.7twi6ffghibfpqgg@charite.de>

I've been running squid-5 and squid-6 (both release and HEAD) on my
old proxy farm. Four machines, ubuntu bionic. All was well, except for
the occasional crash.

I filed bug reports, and the preliminary patches helped with the
crashes:

https://bugs.squid-cache.org/show_bug.cgi?id=5055
https://bugs.squid-cache.org/show_bug.cgi?id=5056

Recently, I set up a new cluster of four up to date machines with new
hardware (still ubuntu, focal though, still x64, assloads of CPUs and
memeory) and tested that cluster with the users from our department.
All went well, squid never once crashed.

Then we took the old cluster offline, and let the new cluster take over.

Now I'm getting (with the same hand-build squid versions!) a LOT
(about once every 15 Minutes) of crashes like this one:

2020/09/22 09:34:07| FATAL: check failed: opening()
    exception location: tunnel.cc(1305) noteDestinationsEnd
    current master transaction: master359979

My infrastructure generates backtraces upon crash, but in the case I'm
not getting any. Which is odd, given I start squid in gdb with
"/usr/sbin/squid -sYNC"

--
Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From Ralf.Hildebrandt at charite.de  Tue Sep 22 13:47:33 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 22 Sep 2020 15:47:33 +0200
Subject: [squid-users] Change of server hardware (?) resulted in massive
 increase of crashes
In-Reply-To: <20200922074737.7twi6ffghibfpqgg@charite.de>
References: <20200922074737.7twi6ffghibfpqgg@charite.de>
Message-ID: <20200922134733.7jxxilmucfwwxmpb@charite.de>

* Ralf Hildebrandt <Ralf.Hildebrandt at charite.de>:

> 2020/09/22 09:34:07| FATAL: check failed: opening()
>     exception location: tunnel.cc(1305) noteDestinationsEnd
>     current master transaction: master359979

I had to go back as far as 5.0.2 to exclude master commit 25b0ce4, now
it's stable (running for an hour without a crash now).

Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From rousskov at measurement-factory.com  Tue Sep 22 13:52:57 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 22 Sep 2020 09:52:57 -0400
Subject: [squid-users] Change of server hardware (?) resulted in massive
 increase of crashes
In-Reply-To: <20200922074737.7twi6ffghibfpqgg@charite.de>
References: <20200922074737.7twi6ffghibfpqgg@charite.de>
Message-ID: <e9f72fbc-29e2-1dc4-935f-c1170797ddcc@measurement-factory.com>

On 9/22/20 3:47 AM, Ralf Hildebrandt wrote:
> I'm getting (with the same hand-build squid versions!) a LOT
> (about once every 15 Minutes) of crashes like this one:
> 
> 2020/09/22 09:34:07| FATAL: check failed: opening()
>     exception location: tunnel.cc(1305) noteDestinationsEnd
>     current master transaction: master359979

This is still bug #5055. I hope we will post an official pull request
properly addressing it soon.

In my environment, Squid v5 is hardly usable without those fixes but, as
you know, YMMV. Your OS upgrade could trigger different DNS resolution
timings, the new cluster may have different IPv6 connectivity profile,
or there can be similar minor/innocent changes that result in slightly
different Squid state and more exceptions. I would not spend time trying
to pinpoint the exact trigger.

I updated bug #5055 with a patch that covers the tunneling case:
https://bugs.squid-cache.org/show_bug.cgi?id=5055#c5


> My infrastructure generates backtraces upon crash, but in the case I'm
> not getting any.

Unlike "assertion failed" FATAL messages, the "check failed" FATAL
messages are the result of an unhandled (for the lack of a better word)
exception. Today, such exceptions do not generate core dumps because the
low-level stack is pretty much lost by the time the exception is caught
by the high-level code. Unhandled exception handling (yes, I know) may
change in the future, but that is a separate issue.


HTH,

Alex.


From Ralf.Hildebrandt at charite.de  Tue Sep 22 14:03:43 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 22 Sep 2020 16:03:43 +0200
Subject: [squid-users] [ext] Re: Change of server hardware (?) resulted
 in massive increase of crashes
In-Reply-To: <e9f72fbc-29e2-1dc4-935f-c1170797ddcc@measurement-factory.com>
References: <20200922074737.7twi6ffghibfpqgg@charite.de>
 <e9f72fbc-29e2-1dc4-935f-c1170797ddcc@measurement-factory.com>
Message-ID: <20200922140343.ju5m3hbtqlaj6mdu@charite.de>

> > 2020/09/22 09:34:07| FATAL: check failed: opening()
> >     exception location: tunnel.cc(1305) noteDestinationsEnd
> >     current master transaction: master359979
> 
> This is still bug #5055. I hope we will post an official pull request
> properly addressing it soon.

I can easily test it here :)

> In my environment, Squid v5 is hardly usable without those fixes but, as
> you know, YMMV.

Yes.

> Your OS upgrade could trigger different DNS resolution
> timings, the new cluster may have different IPv6 connectivity profile,
> or there can be similar minor/innocent changes that result in slightly
> different Squid state and more exceptions. I would not spend time trying
> to pinpoint the exact trigger.
> 
> I updated bug #5055 with a patch that covers the tunneling case:
> https://bugs.squid-cache.org/show_bug.cgi?id=5055#c5

Thanks, I'll try that once the dust has settled.


Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From ajb23 at ymail.com  Tue Sep 22 20:35:36 2020
From: ajb23 at ymail.com (Ajb B)
Date: Tue, 22 Sep 2020 20:35:36 +0000 (UTC)
Subject: [squid-users] How to select parent proxy based on user password
References: <145855392.312629.1600806936763.ref@mail.yahoo.com>
Message-ID: <145855392.312629.1600806936763@mail.yahoo.com>

I know you can map a username to a parent proxy (i.e. cache_peer) using and acl directive, e.g.

```
acl parent_proxy_testuser_1 proxy_auth testuser1
cache_peer <IP> parent <port> 0 proxy-only
cache_peer_access parent1 allow parent_proxy_testuser_1
cache_peer_access parent1 deny !parent_proxy_testuser_1
``` 

But how can you map the user password to a parent proxy?

E.g, so that

testuser1:qvmgPUJ5xW-121 at 18.234.74.214:3292
testuser1:qvmgPUJ5xW-122 at 18.234.74.214:3292
testuser1:qvmgPUJ5xW-123 at 18.234.74.214:3292
map to a different parent proxy?
I know that the external_acl_type directive allows you to create a custom ACL helper, but it does not accept a user password parameter.
Any help appreciated.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200922/fdf7d39f/attachment.htm>

From Antony.Stone at squid.open.source.it  Tue Sep 22 20:54:56 2020
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 22 Sep 2020 22:54:56 +0200
Subject: [squid-users] How to select parent proxy based on user password
In-Reply-To: <145855392.312629.1600806936763@mail.yahoo.com>
References: <145855392.312629.1600806936763.ref@mail.yahoo.com>
 <145855392.312629.1600806936763@mail.yahoo.com>
Message-ID: <202009222254.56539.Antony.Stone@squid.open.source.it>

On Tuesday 22 September 2020 at 22:35:36, Ajb B wrote:

> how can you map the user password to a parent proxy?
> 
> so that
> 
> testuser1:qvmgPUJ5xW-121 at 18.234.74.214:3292
> testuser1:qvmgPUJ5xW-122 at 18.234.74.214:3292
> testuser1:qvmgPUJ5xW-123 at 18.234.74.214:3292
> map to a different parent proxy?

It makes no sense to me to have one username with multiple passwords.

The username is the identifier - this tells the system who this "user" is and 
the system can then find out what this "user" can do, provided they are 
authenticated.

The password is the authenticator - this tells the system that the entity 
trying to connect really is that user.

If you want one entity (person, script, application, whatever) to have access 
to different upstream proxies (presumably for different purposes), you should 
give them different identities (usernames) in order to access those proxies.

They then use the appropriate username for the access they require at the 
time.


What would be the use case for one username with multiple passwords?


Antony.

-- 
Neurotics build castles in the sky;
Psychotics live in them;
Psychiatrists collect the rent.


                                                   Please reply to the list;
                                                         please *don't* CC me.


From ngtech1ltd at gmail.com  Wed Sep 23 08:37:44 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Wed, 23 Sep 2020 11:37:44 +0300
Subject: [squid-users] How to select parent proxy based on user password
In-Reply-To: <145855392.312629.1600806936763@mail.yahoo.com>
References: <145855392.312629.1600806936763.ref@mail.yahoo.com>
 <145855392.312629.1600806936763@mail.yahoo.com>
Message-ID: <003001d69184$cfb981c0$6f2c8540$@gmail.com>

Hey,

You can use a customized password helper.
I am not sure if it is possible but you might be able to add ?note? with your helper which will do just that.
With the username alone you cannot do what you want.
You might be able to use the same username but with a different realm but I am not sure
if squid has native support for multiple realms.

Maybe someone else might know if it is possible to write a auth helper which can add note for an authentication session.

Eliezer

----
Eliezer Croitoru
Tech Support
Mobile: +972-5-28704261
Email: mailto:ngtech1ltd at gmail.com

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Ajb B
Sent: Tuesday, September 22, 2020 11:36 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] How to select parent proxy based on user password

I know you can map a username to a parent proxy (i.e. cache_peer) using and acl directive, e.g.


```
acl parent_proxy_testuser_1 proxy_auth testuser1 

cache_peer <IP> parent <port> 0 proxy-only
cache_peer_access parent1 allow parent_proxy_testuser_1
cache_peer_access parent1 deny !parent_proxy_testuser_1
``` 
But how can you map the user password to a parent proxy?
E.g, so that
testuser1:qvmgPUJ5xW-121 at 18.234.74.214:3292
testuser1:qvmgPUJ5xW-122 at 18.234.74.214:3292
testuser1:qvmgPUJ5xW-123 at 18.234.74.214:3292
map to a different parent proxy?

I know that the external_acl_type directive allows you to create a custom ACL helper, but it does not accept a user password parameter.

Any help appreciated.



From ajb23 at ymail.com  Wed Sep 23 16:14:25 2020
From: ajb23 at ymail.com (Ajb B)
Date: Wed, 23 Sep 2020 16:14:25 +0000 (UTC)
Subject: [squid-users] How to select parent proxy based on user password
In-Reply-To: <202009222254.56539.Antony.Stone@squid.open.source.it>
References: <145855392.312629.1600806936763.ref@mail.yahoo.com>
 <145855392.312629.1600806936763@mail.yahoo.com>
 <202009222254.56539.Antony.Stone@squid.open.source.it>
Message-ID: <1015889741.7876186.1600877665397@mail.yahoo.com>

 
Hey Anthony,
I see you're point. It makes sense to have multiple usernames if I want a user to access multiple proxies. But I'm trying to create a "reseller" proxy service, so multiple usernames for a single user won't really make sense. I can just give users different passwords to access different proxies.
Also, I know PacketStream (https://packetstream.io/) does this and I'm pretty sure they use Squid.


Thanks,Adrian
    On Tuesday, September 22, 2020, 3:55:15 PM CDT, Antony Stone <antony.stone at squid.open.source.it> wrote:  
 
 On Tuesday 22 September 2020 at 22:35:36, Ajb B wrote:

> how can you map the user password to a parent proxy?
> 
> so that
> 
> testuser1:qvmgPUJ5xW-121 at 18.234.74.214:3292
> testuser1:qvmgPUJ5xW-122 at 18.234.74.214:3292
> testuser1:qvmgPUJ5xW-123 at 18.234.74.214:3292
> map to a different parent proxy?

It makes no sense to me to have one username with multiple passwords.

The username is the identifier - this tells the system who this "user" is and 
the system can then find out what this "user" can do, provided they are 
authenticated.

The password is the authenticator - this tells the system that the entity 
trying to connect really is that user.

If you want one entity (person, script, application, whatever) to have access 
to different upstream proxies (presumably for different purposes), you should 
give them different identities (usernames) in order to access those proxies.

They then use the appropriate username for the access they require at the 
time.


What would be the use case for one username with multiple passwords?


Antony.

-- 
Neurotics build castles in the sky;
Psychotics live in them;
Psychiatrists collect the rent.


? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Please reply to the list;
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200923/1e7947d4/attachment.htm>

From squid3 at treenet.co.nz  Thu Sep 24 02:38:15 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 24 Sep 2020 14:38:15 +1200
Subject: [squid-users] How to select parent proxy based on user password
In-Reply-To: <1015889741.7876186.1600877665397@mail.yahoo.com>
References: <145855392.312629.1600806936763.ref@mail.yahoo.com>
 <145855392.312629.1600806936763@mail.yahoo.com>
 <202009222254.56539.Antony.Stone@squid.open.source.it>
 <1015889741.7876186.1600877665397@mail.yahoo.com>
Message-ID: <019d3131-5e07-8608-792f-7dac6b8d32be@treenet.co.nz>

On 24/09/20 4:14 am, Ajb B wrote:
> 
> Hey Anthony,
> 
> I see you're point. It makes sense to have multiple usernames if I want
> a user to access multiple proxies. But I'm trying to create a "reseller"
> proxy service, so multiple usernames for a single user won't really make
> sense. I can just give users different passwords to access different
> proxies.


I don't see the connection being a reseller service has to do with
routing to specific proxies.

Surely the routing is based on something entirely different - such as
the users credit balance with services, or which packages they have
bought from you, which region(s) they are trying to access etc.

That type of info is traditionally managed via assigning users to
groups. In modern Squid it is more efficiently done with annotations and
"note" ACL as mentioned by Eliezer already.


> 
> Also, I know PacketStream (https://packetstream.io/) does this and I'm
> pretty sure they use Squid.


There is nothing in the PacketStream documentation or FAQ that indicates
routing to specific proxies based on user/password details.

Their on-sellers simply add/remove login accounts and payments to the
main system.

Amos


From ajb23 at ymail.com  Thu Sep 24 14:32:33 2020
From: ajb23 at ymail.com (Ajb B)
Date: Thu, 24 Sep 2020 14:32:33 +0000 (UTC)
Subject: [squid-users] How to select parent proxy based on user password
In-Reply-To: <019d3131-5e07-8608-792f-7dac6b8d32be@treenet.co.nz>
References: <145855392.312629.1600806936763.ref@mail.yahoo.com>
 <145855392.312629.1600806936763@mail.yahoo.com>
 <202009222254.56539.Antony.Stone@squid.open.source.it>
 <1015889741.7876186.1600877665397@mail.yahoo.com>
 <019d3131-5e07-8608-792f-7dac6b8d32be@treenet.co.nz>
Message-ID: <486666812.249776.1600957953923@mail.yahoo.com>

> I don't see the connection being a reseller service has to do with
> routing to specific proxies.
> 
> Surely the routing is based on something entirely different - such as
> the users credit balance with services, or which packages they have
> bought from you, which region(s) they are trying to access etc.
So the reason for my reseller service is bot and webscrape tools. These tools get banned on websites quickly if coming from the same IP (I know because I've been using them for a year). The reason for the reseller service is to add features on top of proxy services such as specific proxy rotation time.
> There is nothing in the PacketStream documentation or FAQ that indicates
> routing to specific proxies based on user/password details.
> 
> Their on-sellers simply add/remove login accounts and payments to the
> main system.
PacketStream does in fact route specific proxies based on the user password (I have an account with them).

It uses country and stick/random IPs categories.

E.g. this routes to a random country proxy AND constantly changes the IP:

mark251:fq4zEWC1B5A194C1:proxy.packetstream.io:
This routes to a United States proxy AND constantly changes the IP:

mark251:fq4zEWC1B5A194C1_country-UnitedStates:proxy.packetstream.io:32712
This routes to a United States proxy AND a sticky IP:
mark251:fq4zEWC1B5A194C1_country-UnitedStates_session-M9OtVn9p:proxy.packetstream.io:32712
Additionally, different session IDs are used to map to different sticky IP proxies:
 mark251:fq4zEWC1B5A194C1_country-UnitedStates_session-Pux68O1z:proxy.packetstream.io:32712 mark251:fq4zEWC1B5A194C1_country-UnitedStates_session-SbbaynPQ:proxy.packetstream.io:32712 mark251:fq4zEWC1B5A194C1_country-UnitedStates_session-ybhX9gIf:proxy.packetstream.io:32712 mark251:fq4zEWC1B5A194C1_country-UnitedStates_session-dFgoeQMY:proxy.packetstream.io:32712
So there's definitely a reason to do this.
My question is how does PacketStream do this?
   On Wednesday, September 23, 2020, 9:44:47 PM CDT, Amos Jeffries <squid3 at treenet.co.nz> wrote:  
 
 On 24/09/20 4:14 am, Ajb B wrote:
> 
> Hey Anthony,
> 
> I see you're point. It makes sense to have multiple usernames if I want
> a user to access multiple proxies. But I'm trying to create a "reseller"
> proxy service, so multiple usernames for a single user won't really make
> sense. I can just give users different passwords to access different
> proxies.


I don't see the connection being a reseller service has to do with
routing to specific proxies.

Surely the routing is based on something entirely different - such as
the users credit balance with services, or which packages they have
bought from you, which region(s) they are trying to access etc.

That type of info is traditionally managed via assigning users to
groups. In modern Squid it is more efficiently done with annotations and
"note" ACL as mentioned by Eliezer already.


> 
> Also, I know PacketStream (https://packetstream.io/) does this and I'm
> pretty sure they use Squid.


There is nothing in the PacketStream documentation or FAQ that indicates
routing to specific proxies based on user/password details.

Their on-sellers simply add/remove login accounts and payments to the
main system.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200924/7c67650b/attachment.htm>

From ngtech1ltd at gmail.com  Thu Sep 24 17:26:18 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Thu, 24 Sep 2020 20:26:18 +0300
Subject: [squid-users] How to select parent proxy based on user password
In-Reply-To: <019d3131-5e07-8608-792f-7dac6b8d32be@treenet.co.nz>
References: <145855392.312629.1600806936763.ref@mail.yahoo.com>
 <145855392.312629.1600806936763@mail.yahoo.com>
 <202009222254.56539.Antony.Stone@squid.open.source.it>
 <1015889741.7876186.1600877665397@mail.yahoo.com>
 <019d3131-5e07-8608-792f-7dac6b8d32be@treenet.co.nz>
Message-ID: <001601d69297$d147d0f0$73d772d0$@gmail.com>

Just to add a side note:
Squid is not the most advanced proxy in the Programming world.

It's possible that many use Squid as their proxy servers software however,
in the programming world there are far more simple and efficient ways to write 
a proxy that will serve a service such as PacketStream.
A proxy server with auth, logging and much more  can be written in 200 +- lines of code.
OK OK so it is connected to a K\V or SQL DB...

Haproxy is an OpenSource example for a very efficient proxy service, leaving aside the 
obviates differences between Squid and Haproxy.

All The Bests,
Eliezer

----
Eliezer Croitoru
Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Thursday, September 24, 2020 5:38 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] How to select parent proxy based on user password

On 24/09/20 4:14 am, Ajb B wrote:
> 
> Hey Anthony,
> 
> I see you're point. It makes sense to have multiple usernames if I want
> a user to access multiple proxies. But I'm trying to create a "reseller"
> proxy service, so multiple usernames for a single user won't really make
> sense. I can just give users different passwords to access different
> proxies.


I don't see the connection being a reseller service has to do with
routing to specific proxies.

Surely the routing is based on something entirely different - such as
the users credit balance with services, or which packages they have
bought from you, which region(s) they are trying to access etc.

That type of info is traditionally managed via assigning users to
groups. In modern Squid it is more efficiently done with annotations and
"note" ACL as mentioned by Eliezer already.


> 
> Also, I know PacketStream (https://packetstream.io/) does this and I'm
> pretty sure they use Squid.


There is nothing in the PacketStream documentation or FAQ that indicates
routing to specific proxies based on user/password details.

Their on-sellers simply add/remove login accounts and payments to the
main system.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From ajb23 at ymail.com  Thu Sep 24 23:24:44 2020
From: ajb23 at ymail.com (Ajb B)
Date: Thu, 24 Sep 2020 23:24:44 +0000 (UTC)
Subject: [squid-users] How to select parent proxy based on user password
In-Reply-To: <001601d69297$d147d0f0$73d772d0$@gmail.com>
References: <145855392.312629.1600806936763.ref@mail.yahoo.com>
 <145855392.312629.1600806936763@mail.yahoo.com>
 <202009222254.56539.Antony.Stone@squid.open.source.it>
 <1015889741.7876186.1600877665397@mail.yahoo.com>
 <019d3131-5e07-8608-792f-7dac6b8d32be@treenet.co.nz>
 <001601d69297$d147d0f0$73d772d0$@gmail.com>
Message-ID: <1116487637.455485.1600989884854@mail.yahoo.com>

Hey Eliezer,
Squid contains some very advanced features that would take several weeks to rewrite I'm sure. But you're reply did give me an idea.
I think I can create an additional proxy service on top of Squid to route proxies based on the password. I think I will have to try this approach.

Thanks,Adrian
   On Thursday, September 24, 2020, 12:26:38 PM CDT, Eliezer Croitor <ngtech1ltd at gmail.com> wrote:  
 
 Just to add a side note:
Squid is not the most advanced proxy in the Programming world.

It's possible that many use Squid as their proxy servers software however,
in the programming world there are far more simple and efficient ways to write 
a proxy that will serve a service such as PacketStream.
A proxy server with auth, logging and much more? can be written in 200 +- lines of code.
OK OK so it is connected to a K\V or SQL DB...

Haproxy is an OpenSource example for a very efficient proxy service, leaving aside the 
obviates differences between Squid and Haproxy.

All The Bests,
Eliezer

----
Eliezer Croitoru
Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Thursday, September 24, 2020 5:38 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] How to select parent proxy based on user password

On 24/09/20 4:14 am, Ajb B wrote:
> 
> Hey Anthony,
> 
> I see you're point. It makes sense to have multiple usernames if I want
> a user to access multiple proxies. But I'm trying to create a "reseller"
> proxy service, so multiple usernames for a single user won't really make
> sense. I can just give users different passwords to access different
> proxies.


I don't see the connection being a reseller service has to do with
routing to specific proxies.

Surely the routing is based on something entirely different - such as
the users credit balance with services, or which packages they have
bought from you, which region(s) they are trying to access etc.

That type of info is traditionally managed via assigning users to
groups. In modern Squid it is more efficiently done with annotations and
"note" ACL as mentioned by Eliezer already.


> 
> Also, I know PacketStream (https://packetstream.io/) does this and I'm
> pretty sure they use Squid.


There is nothing in the PacketStream documentation or FAQ that indicates
routing to specific proxies based on user/password details.

Their on-sellers simply add/remove login accounts and payments to the
main system.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200924/cc36f866/attachment.htm>

From ngtech1ltd at gmail.com  Fri Sep 25 04:12:07 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Fri, 25 Sep 2020 07:12:07 +0300
Subject: [squid-users] How to select parent proxy based on user password
In-Reply-To: <1116487637.455485.1600989884854@mail.yahoo.com>
References: <145855392.312629.1600806936763.ref@mail.yahoo.com>
 <145855392.312629.1600806936763@mail.yahoo.com>
 <202009222254.56539.Antony.Stone@squid.open.source.it>
 <1015889741.7876186.1600877665397@mail.yahoo.com>
 <019d3131-5e07-8608-792f-7dac6b8d32be@treenet.co.nz>
 <001601d69297$d147d0f0$73d772d0$@gmail.com>
 <1116487637.455485.1600989884854@mail.yahoo.com>
Message-ID: <001d01d692f2$095821c0$1c086540$@gmail.com>

Hey Adrian,

 

Indeed some advanced features might take some time but, without SSL-BUMP you just to prepare a list of ?requirements? from the proxy.

Squid can enforce HTTP RFC syntax and has couple very nice features but really, what do you need the proxy to do?

Authentication? Via htaccess file, DB, LDAP, AD?
Proxy Peering?

Logging?

Bandwidth control?

Caching?

 

For any project the requirements can be ?quantified? and a developer can give you a price.

Indeed I would agree that a software which is being used by many admins and users can be tested better to some degree.

 

A single username is an identifier and it?s better be unique per client.

You can use realms to differentiate between destination proxies.

Technically speaking there are much better ways to send messages between the client software to the proxy.

For example you can use  a HTTP Header such as ?X-Proxy-Route? with some unique identifiers else then the default.

The main thing with such a setup would be to remove this by-hop\in-transit header(s).

 

If you want to see a 200+- lines proxy I can try next month to look at my list.

 

I posted in 2016 a list of proxies on my web page and you can download the post PDF from:

https://smallpdf.com/shared#st=28c1432b-7248-4a57-9e5b-9d143b6481bd <https://smallpdf.com/shared#st=28c1432b-7248-4a57-9e5b-9d143b6481bd&fn=A+Proxy+for+each+Internet+user+_The+future_2016.pdf&ct=1601007048862&tl=share-document&rf=link> &fn=A+Proxy+for+each+Internet+user+_The+future_2016.pdf&ct=1601007048862&tl=share-document&rf=link

 

All The Bests,

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: Ajb B <ajb23 at ymail.com> 
Sent: Friday, September 25, 2020 2:25 AM
To: squid-users at lists.squid-cache.org; Eliezer Croitor <ngtech1ltd at gmail.com>
Subject: Re: [squid-users] How to select parent proxy based on user password

 

Hey Eliezer,

 

Squid contains some very advanced features that would take several weeks to rewrite I'm sure. But you're reply did give me an idea.

 

I think I can create an additional proxy service on top of Squid to route proxies based on the password. I think I will have to try this approach.

 

 

Thanks,

Adrian

On Thursday, September 24, 2020, 12:26:38 PM CDT, Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > wrote: 

 

 

Just to add a side note:
Squid is not the most advanced proxy in the Programming world.

It's possible that many use Squid as their proxy servers software however,
in the programming world there are far more simple and efficient ways to write 
a proxy that will serve a service such as PacketStream.
A proxy server with auth, logging and much more  can be written in 200 +- lines of code.
OK OK so it is connected to a K\V or SQL DB...

Haproxy is an OpenSource example for a very efficient proxy service, leaving aside the 
obviates differences between Squid and Haproxy.

All The Bests,
Eliezer

----
Eliezer Croitoru
Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org <mailto:squid-users-bounces at lists.squid-cache.org> > On Behalf Of Amos Jeffries
Sent: Thursday, September 24, 2020 5:38 AM
To: squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Subject: Re: [squid-users] How to select parent proxy based on user password

On 24/09/20 4:14 am, Ajb B wrote:
> 
> Hey Anthony,
> 
> I see you're point. It makes sense to have multiple usernames if I want
> a user to access multiple proxies. But I'm trying to create a "reseller"
> proxy service, so multiple usernames for a single user won't really make
> sense. I can just give users different passwords to access different
> proxies.


I don't see the connection being a reseller service has to do with
routing to specific proxies.

Surely the routing is based on something entirely different - such as
the users credit balance with services, or which packages they have
bought from you, which region(s) they are trying to access etc.

That type of info is traditionally managed via assigning users to
groups. In modern Squid it is more efficiently done with annotations and
"note" ACL as mentioned by Eliezer already.


> 
> Also, I know PacketStream (https://packetstream.io/) does this and I'm
> pretty sure they use Squid.


There is nothing in the PacketStream documentation or FAQ that indicates
routing to specific proxies based on user/password details.

Their on-sellers simply add/remove login accounts and payments to the
main system.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200925/7a795679/attachment.htm>

From ajb23 at ymail.com  Fri Sep 25 16:20:48 2020
From: ajb23 at ymail.com (Ajb B)
Date: Fri, 25 Sep 2020 16:20:48 +0000 (UTC)
Subject: [squid-users] How to select parent proxy based on user password
In-Reply-To: <001d01d692f2$095821c0$1c086540$@gmail.com>
References: <145855392.312629.1600806936763.ref@mail.yahoo.com>
 <145855392.312629.1600806936763@mail.yahoo.com>
 <202009222254.56539.Antony.Stone@squid.open.source.it>
 <1015889741.7876186.1600877665397@mail.yahoo.com>
 <019d3131-5e07-8608-792f-7dac6b8d32be@treenet.co.nz>
 <001601d69297$d147d0f0$73d772d0$@gmail.com>
 <1116487637.455485.1600989884854@mail.yahoo.com>
 <001d01d692f2$095821c0$1c086540$@gmail.com>
Message-ID: <1997368238.647877.1601050848112@mail.yahoo.com>

Hey Eliezer,
Thanks for the info.
I do think using HTTP headers is a good idea, but I'm not really seeing that in the Squid documentation. I'll just have to stick with the configuration directives for now.
And that list of proxies looks good. I'll consider using them.

Thanks,Adrian
   On Thursday, September 24, 2020, 11:12:26 PM CDT, Eliezer Croitor <ngtech1ltd at gmail.com> wrote:  
 
 #yiv4063629792 #yiv4063629792 -- _filtered {} _filtered {} _filtered {}#yiv4063629792 #yiv4063629792 p.yiv4063629792MsoNormal, #yiv4063629792 li.yiv4063629792MsoNormal, #yiv4063629792 div.yiv4063629792MsoNormal {margin:0in;font-size:11.0pt;font-family:sans-serif;}#yiv4063629792 a:link, #yiv4063629792 span.yiv4063629792MsoHyperlink {color:blue;text-decoration:underline;}#yiv4063629792 span.yiv4063629792EmailStyle20 {font-family:sans-serif;color:windowtext;}#yiv4063629792 .yiv4063629792MsoChpDefault {font-size:10.0pt;} _filtered {}#yiv4063629792 div.yiv4063629792WordSection1 {}#yiv4063629792 
Hey Adrian,

 ?

Indeed some advanced features might take some time but, without SSL-BUMP you just to prepare a list of ?requirements? from the proxy.

Squid can enforce HTTP RFC syntax and has couple very nice features but really, what do you need the proxy to do?

Authentication? Via htaccess file, DB, LDAP, AD?
Proxy Peering?

Logging?

Bandwidth control?

Caching?

 ?

For any project the requirements can be ?quantified? and a developer can give you a price.

Indeed I would agree that a software which is being used by many admins and users can be tested better to some degree.

 ?

A single username is an identifier and it?s better be unique per client.

You can use realms to differentiate between destination proxies.

Technically speaking there are much better ways to send messages between the client software to the proxy.

For example you can use ?a HTTP Header such as ?X-Proxy-Route? with some unique identifiers else then the default.

The main thing with such a setup would be to remove this by-hop\in-transit header(s).

 ?

If you want to see a 200+- lines proxy I can try next month to look at my list.

 ?

I posted in 2016 a list of proxies on my web page and you can download the post PDF from:

https://smallpdf.com/shared#st=28c1432b-7248-4a57-9e5b-9d143b6481bd&fn=A+Proxy+for+each+Internet+user+_The+future_2016.pdf&ct=1601007048862&tl=share-document&rf=link

 ?

All The Bests,

Eliezer

 ?

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com

 ?

From: Ajb B <ajb23 at ymail.com> 
Sent: Friday, September 25, 2020 2:25 AM
To: squid-users at lists.squid-cache.org; Eliezer Croitor <ngtech1ltd at gmail.com>
Subject: Re: [squid-users] How to select parent proxy based on user password

 ?

Hey Eliezer,

 ?

Squid contains some very advanced features that would take several weeks to rewrite I'm sure. But you're reply did give me an idea.

 ?

I think I can create an additional proxy service on top of Squid to route proxies based on the password. I think I will have to try this approach.

 ?

 ?

Thanks,

Adrian

On Thursday, September 24, 2020, 12:26:38 PM CDT, Eliezer Croitor <ngtech1ltd at gmail.com> wrote: 

 ?

 ?

Just to add a side note:
Squid is not the most advanced proxy in the Programming world.

It's possible that many use Squid as their proxy servers software however,
in the programming world there are far more simple and efficient ways to write 
a proxy that will serve a service such as PacketStream.
A proxy server with auth, logging and much more? can be written in 200 +- lines of code.
OK OK so it is connected to a K\V or SQL DB...

Haproxy is an OpenSource example for a very efficient proxy service, leaving aside the 
obviates differences between Squid and Haproxy.

All The Bests,
Eliezer

----
Eliezer Croitoru
Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Thursday, September 24, 2020 5:38 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] How to select parent proxy based on user password

On 24/09/20 4:14 am, Ajb B wrote:
> 
> Hey Anthony,
> 
> I see you're point. It makes sense to have multiple usernames if I want
> a user to access multiple proxies. But I'm trying to create a "reseller"
> proxy service, so multiple usernames for a single user won't really make
> sense. I can just give users different passwords to access different
> proxies.


I don't see the connection being a reseller service has to do with
routing to specific proxies.

Surely the routing is based on something entirely different - such as
the users credit balance with services, or which packages they have
bought from you, which region(s) they are trying to access etc.

That type of info is traditionally managed via assigning users to
groups. In modern Squid it is more efficiently done with annotations and
"note" ACL as mentioned by Eliezer already.


> 
> Also, I know PacketStream (https://packetstream.io/) does this and I'm
> pretty sure they use Squid.


There is nothing in the PacketStream documentation or FAQ that indicates
routing to specific proxies based on user/password details.

Their on-sellers simply add/remove login accounts and payments to the
main system.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200925/545eabe6/attachment.htm>

From ajb23 at ymail.com  Fri Sep 25 20:28:02 2020
From: ajb23 at ymail.com (Ajb B)
Date: Fri, 25 Sep 2020 20:28:02 +0000 (UTC)
Subject: [squid-users] Squid not sending input into external_acl_type helper
 script
References: <1528687114.724811.1601065682982.ref@mail.yahoo.com>
Message-ID: <1528687114.724811.1601065682982@mail.yahoo.com>

So I have a external_acl_type helper script and it's not reading input from Squid.
Here it is:

redis-cli HSET 'test' data 'SCRIPT DID RUN' >/dev/null
while read -s line; do
? redis-cli HSET 'test' data 'LOOP STARTED ' >/dev/null? printf '%s\n' 'OK'
done
And here are my Squid configuration directives:
external_acl_type ex_parent_proxy %LOGIN /etc/squid/squid-access-control.shacl parent_proxy_1 external ex_parent_proxy http_access allow parent_proxy_1 

When I test it out, the 'SCRIPT DID RUN' value does get set in the database. However, 'LOOP STARTED' does not. Any idea why? I have used helper scripts for the 'auth_param basic program' configuration directive and it works just fine.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200925/132ef85e/attachment.htm>

From service.mv at gmail.com  Fri Sep 25 22:28:14 2020
From: service.mv at gmail.com (Service MV)
Date: Fri, 25 Sep 2020 19:28:14 -0300
Subject: [squid-users] How te deal with proxy authentication bypass
Message-ID: <CA+d==oGFmGqb-BLE+s85FOFkg4OnsJtjW5cqxC+7FaybKVLmvw@mail.gmail.com>

Hello everyone, I am trying to deal unsuccessfully with proxy
authentication bypass.
Even looking at the documentation I can't get it right. The point is that
certain programs such as being a cisco webex client or the google earth pro
client do not know how to speak well with SQUID's kerberos authentication,
so I want them not to authenticate for the domains they use.
For everything else I have no problems in the authentication.
I attach the logs I get and my configuration to see if they can help me.

Thank you very much in advance.
Best regards
Gabriel

squid.conf
visible_hostname s-px4.mydomain.com
#http_port 3128 require-proxy-header
http_port 3128
error_directory /opt/squid-503/share/errors/es-ar
forwarded_for transparent
shutdown_lifetime 0 seconds
quick_abort_min 0 KB
quick_abort_max 0 KB
quick_abort_pct 100
read_timeout 5 minutes
request_timeout 3 minutes
cache_mem 1024 MB
maximum_object_size_in_memory 4 MB
memory_cache_mode always
ipcache_size 2048
fqdncache_size 4096
#cache_mgr
httpd_suppress_version_string on
coredump_dir /opt/squid-503/var/cache/squid

auth_param negotiate program /opt/squid-503/libexec/negotiate_kerberos_auth
-i -r -s GSS_C_NO_NAME
auth_param negotiate children 300 startup=150 idle=10
auth_param negotiate keep_alive on

auth_param basic program /opt/squid-503/libexec/basic_ldap_auth -P -R -b
"dc=mydomain,dc=com" -D "cn=ldap,cn=Users,dc=mydomain,dc=com" -W
/opt/squid-503/etc/ldappass.txt -f sAMAccountName=%s -h s-dc00.mydomain.com
auth_param basic children 30
auth_param basic realm Proxy Authentication
auth_param basic credentialsttl 4 hour

#acl vip_haproxy src 10.10.8.92
#proxy_protocol_access allow vip_haproxy

external_acl_type NO_INTERNET_USERS ttl=3600 negative_ttl=3600 %LOGIN
/opt/squid-503/libexec/ext_kerberos_ldap_group_acl -g INTERNET_OFF -i -D
NUEVENET.MEDIOS
acl NO_INTERNET external NO_INTERNET_USERS

acl SSL_ports port 443
acl SSL_ports port 8543         # LiveU Central
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 81          # coto "yo te conozco" donkey ports
acl Safe_ports port 623         # coto "yo te conozco" donkey ports
acl Safe_ports port 8543        # LiveU Central management
acl Safe_ports port 18255       # LiveU Central files download
acl Safe_ports port 33080       # ddjj
acl Safe_ports port 9090        # asociart
acl Safe_ports port 8713        # handball results
acl Safe_ports port 8080        # cponline.org.ar

# Lists of domains and IPs
acl LS_winupddom dstdomain "/opt/squid-503/acl/winupddom.txt"
acl LS_whitedomains dstdomain "/opt/squid-503/acl/whitedomains.txt"
acl LS_blackdomains dstdomain "/opt/squid-503/acl/blackdomains.txt"
acl LS_porn dstdomain "/opt/squid-503/acl/porn.txt"
acl DOM_Malware dstdomain "/opt/squid-503/acl/DOM_Malware.txt"
acl IP_Malware dst -n "/opt/squid-503/acl/IP_Malware.txt"
acl LS_webex dstdomain "/opt/squid-503/acl/webex.txt"

# Access lists
acl http proto http
acl port_80 port 80
acl port_443 port 443
acl port_9000 port 9000
acl port_5061 port 5061
acl port_5065 port 5065
acl CONNECT method CONNECT

#acl authenticated proxy_auth REQUIRED
# Denied internet to member users of INTERNET_OFF group
http_access deny NO_INTERNET all

# Allow webex without authentication
http_access allow http port_80 LS_webex
http_access allow CONNECT port_443 LS_webex
http_access allow port_9000 LS_webex
http_access allow port_5061 LS_webex
http_access allow port_5065 LS_webex


http_access deny LS_blackdomains
http_access deny LS_porn
http_access deny DOM_Malware
http_access deny IP_Malware

# default SQUID rules
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access deny to_localhost
http_access allow localhost

# Apply 20Mbit/s QoS to members of Active Directory Authenticated Users
group
acl Domain_Users note group AQUAAAAAAAUVAAAA7TIfbORUj8PLQv4YAQIAAA==
delay_pools 1
delay_class 1 1
delay_parameters 1 2500000/2500000
delay_access 1 allow Domain_Users

# Allow authenticated users to use internet and deny to all others
acl authenticated proxy_auth REQUIRED
http_access allow authenticated
http_access deny all


cat /opt/squid-503/acl/webex.txt
.wbx2.com
.ciscospark.com
.webex.com
.quovadisglobal.com
.digicert.com
.accompany.com
.walkme.com
.cisco.com

access.log
1601071522.675      0 10.10.9.250 TCP_DENIED/407 4106 CONNECT
join-test.webex.com:443 - HIER_NONE/- text/html
1601071522.684      0 10.10.9.250 TCP_DENIED/407 4029 CONNECT
msj1mcccl01.webex.com:443 - HIER_NONE/- text/html
1601071524.717      0 10.10.9.250 TCP_DENIED/407 4086 CONNECT
tsa3.webex.com:443 - HIER_NONE/- text/html
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200925/087d9bb6/attachment.htm>

From rousskov at measurement-factory.com  Sat Sep 26 15:17:52 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 26 Sep 2020 11:17:52 -0400
Subject: [squid-users] Squid not sending input into external_acl_type
 helper script
In-Reply-To: <1528687114.724811.1601065682982@mail.yahoo.com>
References: <1528687114.724811.1601065682982.ref@mail.yahoo.com>
 <1528687114.724811.1601065682982@mail.yahoo.com>
Message-ID: <2b4c3c23-2270-6f40-f63e-bfe3b9ae57c1@measurement-factory.com>

On 9/25/20 4:28 PM, Ajb B wrote:
> So I have a external_acl_type helper script and it's not reading input
> from Squid.
> 
> Here it is:
> 
> redis-cli HSET 'test' data 'SCRIPT DID RUN' >/dev/null
> 
> while read -s line; do
> ? redis-cli HSET 'test' data 'LOOP STARTED ' >/dev/null
> ? printf '%s\n' 'OK'
> done
> 
> And here are my Squid configuration directives:
> 
> external_acl_type ex_parent_proxy %LOGIN /etc/squid/squid-access-control.sh
> acl parent_proxy_1 external ex_parent_proxy
> http_access allow parent_proxy_1
> 
> When I test it out, the 'SCRIPT DID RUN' value does get set in the
> database. However, 'LOOP STARTED' does not. Any idea why?

Perhaps access is granted (or denied) by an earlier http_access rule?

If no test transactions are currently denied, then, to test the above
theory, you can add an "http_access deny all" rule immediately
before/above your "http_access allow parent_proxy_1" rule and see
whether Squid starts denying any test transactions. If it does not, the
theory is probably correct.

Alex.


From ajb23 at ymail.com  Sat Sep 26 16:12:47 2020
From: ajb23 at ymail.com (Ajb B)
Date: Sat, 26 Sep 2020 16:12:47 +0000 (UTC)
Subject: [squid-users] How te deal with proxy authentication bypass
In-Reply-To: <CA+d==oGFmGqb-BLE+s85FOFkg4OnsJtjW5cqxC+7FaybKVLmvw@mail.gmail.com>
References: <CA+d==oGFmGqb-BLE+s85FOFkg4OnsJtjW5cqxC+7FaybKVLmvw@mail.gmail.com>
Message-ID: <570566410.878666.1601136767167@mail.yahoo.com>

 I looked this up an it looks like the reason Google does not work with Kerberos authentication (I think) is that Google makes requests to other domains:
https://serverfault.com/a/307605(Please look at the second comment of the first answer.)

The solution would be to create an ACL to allow the Google and Cisco domains, but I don't think it will work because they make requests to other domains. It would be something like:

acl allowed_domains dstdomain google.comhttp_access allow allowed_domains
Please note you would have to place it before your ACL in your lines where you have:
http_access allow authenticated
http_access deny all
I don't really have a solution except to look at your access.log file (in /var/log/squid), see the other domains Google is making a request to, and then add to your ACLs also.

Thanks,Adrian
    On Friday, September 25, 2020, 5:28:36 PM CDT, Service MV <service.mv at gmail.com> wrote:  
 
 Hello everyone, I am trying to deal unsuccessfully with proxy authentication bypass.
Even looking at the documentation I can't get it right. The point is that certain programs such as being a cisco webex client or the google earth pro client do not know how to speak well with SQUID's kerberos authentication, so I want them not to authenticate for the domains they use.
For everything else I have no problems in the authentication. 
I attach the logs I get and my configuration to see if they can help me.

Thank you very much in advance.
Best regardsGabriel
squid.confvisible_hostname s-px4.mydomain.com
#http_port 3128 require-proxy-header
http_port 3128
error_directory /opt/squid-503/share/errors/es-ar
forwarded_for transparent
shutdown_lifetime 0 seconds
quick_abort_min 0 KB
quick_abort_max 0 KB
quick_abort_pct 100
read_timeout 5 minutes
request_timeout 3 minutes
cache_mem 1024 MB
maximum_object_size_in_memory 4 MB
memory_cache_mode always
ipcache_size 2048
fqdncache_size 4096
#cache_mgr?
httpd_suppress_version_string on
coredump_dir /opt/squid-503/var/cache/squid

auth_param negotiate program /opt/squid-503/libexec/negotiate_kerberos_auth -i -r -s GSS_C_NO_NAME
auth_param negotiate children 300 startup=150 idle=10
auth_param negotiate keep_alive on

auth_param basic program /opt/squid-503/libexec/basic_ldap_auth -P -R -b "dc=mydomain,dc=com" -D "cn=ldap,cn=Users,dc=mydomain,dc=com" -W /opt/squid-503/etc/ldappass.txt -f sAMAccountName=%s -h s-dc00.mydomain.com
auth_param basic children 30
auth_param basic realm Proxy Authentication
auth_param basic credentialsttl 4 hour

#acl vip_haproxy src 10.10.8.92
#proxy_protocol_access allow vip_haproxy

external_acl_type NO_INTERNET_USERS ttl=3600 negative_ttl=3600 %LOGIN /opt/squid-503/libexec/ext_kerberos_ldap_group_acl -g INTERNET_OFF -i -D NUEVENET.MEDIOS
acl NO_INTERNET external NO_INTERNET_USERS

acl SSL_ports port 443
acl SSL_ports port 8543 ? ? ? ? # LiveU Central
acl Safe_ports port 80 ? ? ? ? ?# http
acl Safe_ports port 21 ? ? ? ? ?# ftp
acl Safe_ports port 443 ? ? ? ? # https
acl Safe_ports port 70 ? ? ? ? ?# gopher
acl Safe_ports port 210 ? ? ? ? # wais
acl Safe_ports port 280 ? ? ? ? # http-mgmt
acl Safe_ports port 488 ? ? ? ? # gss-http
acl Safe_ports port 591 ? ? ? ? # filemaker
acl Safe_ports port 777 ? ? ? ? # multiling http
acl Safe_ports port 81 ? ? ? ? ?# coto "yo te conozco" donkey ports
acl Safe_ports port 623 ? ? ? ? # coto "yo te conozco" donkey ports
acl Safe_ports port 8543 ? ? ? ?# LiveU Central management
acl Safe_ports port 18255 ? ? ? # LiveU Central files download
acl Safe_ports port 33080 ? ? ? # ddjj
acl Safe_ports port 9090 ? ? ? ?# asociart
acl Safe_ports port 8713 ? ? ? ?# handball results
acl Safe_ports port 8080 ? ? ? ?# cponline.org.ar

# Lists of domains and IPs
acl LS_winupddom dstdomain "/opt/squid-503/acl/winupddom.txt"
acl LS_whitedomains dstdomain "/opt/squid-503/acl/whitedomains.txt"
acl LS_blackdomains dstdomain "/opt/squid-503/acl/blackdomains.txt"
acl LS_porn dstdomain "/opt/squid-503/acl/porn.txt"
acl DOM_Malware dstdomain "/opt/squid-503/acl/DOM_Malware.txt"
acl IP_Malware dst -n "/opt/squid-503/acl/IP_Malware.txt"
acl LS_webex dstdomain "/opt/squid-503/acl/webex.txt"

# Access lists
acl http proto http
acl port_80 port 80
acl port_443 port 443
acl port_9000 port 9000
acl port_5061 port 5061
acl port_5065 port 5065
acl CONNECT method CONNECT

#acl authenticated proxy_auth REQUIRED
# Denied internet to member users of INTERNET_OFF group
http_access deny NO_INTERNET all

# Allow webex without authentication
http_access allow http port_80 LS_webex
http_access allow CONNECT port_443 LS_webex
http_access allow port_9000 LS_webex
http_access allow port_5061 LS_webex
http_access allow port_5065 LS_webex


http_access deny LS_blackdomains
http_access deny LS_porn
http_access deny DOM_Malware
http_access deny IP_Malware

# default SQUID rules
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access deny to_localhost
http_access allow localhost

# Apply 20Mbit/s QoS to members of Active Directory Authenticated Users group
acl Domain_Users note group AQUAAAAAAAUVAAAA7TIfbORUj8PLQv4YAQIAAA==
delay_pools 1
delay_class 1 1
delay_parameters 1 2500000/2500000
delay_access 1 allow Domain_Users

# Allow authenticated users to use internet and deny to all others
acl authenticated proxy_auth REQUIRED
http_access allow authenticated
http_access deny all


cat /opt/squid-503/acl/webex.txt.wbx2.com.ciscospark.com
.webex.com
.quovadisglobal.com
.digicert.com
.accompany.com
.walkme.com
.cisco.com
access.log1601071522.675 ? ? ?0 10.10.9.250 TCP_DENIED/407 4106 CONNECT join-test.webex.com:443 - HIER_NONE/- text/html
1601071522.684 ? ? ?0 10.10.9.250 TCP_DENIED/407 4029 CONNECT msj1mcccl01.webex.com:443 - HIER_NONE/- text/html
1601071524.717 ? ? ?0 10.10.9.250 TCP_DENIED/407 4086 CONNECT tsa3.webex.com:443 - HIER_NONE/- text/html




_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200926/ae61e978/attachment.htm>

From ajb23 at ymail.com  Sat Sep 26 17:52:23 2020
From: ajb23 at ymail.com (Ajb B)
Date: Sat, 26 Sep 2020 17:52:23 +0000 (UTC)
Subject: [squid-users] Squid not sending input into external_acl_type
 helper script
In-Reply-To: <2b4c3c23-2270-6f40-f63e-bfe3b9ae57c1@measurement-factory.com>
References: <1528687114.724811.1601065682982.ref@mail.yahoo.com>
 <1528687114.724811.1601065682982@mail.yahoo.com>
 <2b4c3c23-2270-6f40-f63e-bfe3b9ae57c1@measurement-factory.com>
Message-ID: <816417065.895746.1601142743314@mail.yahoo.com>

Eeehhhh, you were right.
It was a configuration directive. Even though putting 'http_access deny all' didn't fix the issue, I was able to make the loop run by commenting out the following configuration directives:
acl authenticated proxy_auth REQUIRED
http_access allow authenticated
Completely didn't realize they were preventing Squid from passing input into the script.
Thanks Alex!
Adrian
   On Saturday, September 26, 2020, 10:17:53 AM CDT, Alex Rousskov <rousskov at measurement-factory.com> wrote:  
 
 On 9/25/20 4:28 PM, Ajb B wrote:
> So I have a external_acl_type helper script and it's not reading input
> from Squid.
> 
> Here it is:
> 
> redis-cli HSET 'test' data 'SCRIPT DID RUN' >/dev/null
> 
> while read -s line; do
> ? redis-cli HSET 'test' data 'LOOP STARTED ' >/dev/null
> ? printf '%s\n' 'OK'
> done
> 
> And here are my Squid configuration directives:
> 
> external_acl_type ex_parent_proxy %LOGIN /etc/squid/squid-access-control.sh
> acl parent_proxy_1 external ex_parent_proxy
> http_access allow parent_proxy_1
> 
> When I test it out, the 'SCRIPT DID RUN' value does get set in the
> database. However, 'LOOP STARTED' does not. Any idea why?

Perhaps access is granted (or denied) by an earlier http_access rule?

If no test transactions are currently denied, then, to test the above
theory, you can add an "http_access deny all" rule immediately
before/above your "http_access allow parent_proxy_1" rule and see
whether Squid starts denying any test transactions. If it does not, the
theory is probably correct.

Alex.
  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200926/822bf5b6/attachment.htm>

From ngtech1ltd at gmail.com  Sat Sep 26 21:40:47 2020
From: ngtech1ltd at gmail.com (Eliezer Croitor)
Date: Sun, 27 Sep 2020 00:40:47 +0300
Subject: [squid-users] SSL issue on Squid version 4 after blacklisting
In-Reply-To: <DB6PR0102MB27603E5519932014BC566B2593360@DB6PR0102MB2760.eurprd01.prod.exchangelabs.com>
References: <AM5PR0102MB2756FB157CFBE6C65DB56EB693200@AM5PR0102MB2756.eurprd01.prod.exchangelabs.com>
 <DB6PR0102MB27603E5519932014BC566B2593360@DB6PR0102MB2760.eurprd01.prod.exchangelabs.com>
Message-ID: <006701d6944d$b2bbe7e0$1833b7a0$@gmail.com>

Hey,

 

First of all you need to know who is contacting and what is the other end of the connection.

It?s possible that the certificate is invalid.

If you do have the remote service/server name and ip address you can try to resolve this issue by ?creating?
a set of certificates your service can trust and update it using some kind of a git repository.

 

I do not know how important is the order of the certificates since in some cases it does.

An example of dumping a server certificate:

openssl s_client -showcerts -connect google.com:443 </dev/null > 1.pem

or

true | openssl s_client -connect google.com:443 2>/dev/null | openssl x509 > certigicate.pem

 

and to verify against the list of certificates you might try to run this:

openssl verify -CAfile 1.pem certificate.pem

 

should say:

certificate.pem: OK

 

 

Technically speaking, this is how many appliances work.

Either they write their own TLS logic with black/white lists and many which use squid have their
own privately maintained certificates list.

 

It might look like a big thing but once you have your logic/algorithm you would be able to automate the concept.

As a start point you can use the OS ca-certificates package and generate a local one.

 

Some would choose it ignore errors with the certificate  validation and it?s right to do until you will resolve the issue
but this is only for very specific sites.

My assumption is that it will affect only specific services and sites.

 

If you want to resolve issues you can use some list of sites which you might want to override SSL-bump for until
you will find the right solution.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit <Ankit.Dixit at eurostar.com> 
Sent: Friday, September 25, 2020 4:22 PM
To: Eliezer Croitor <ngtech1ltd at gmail.com>; 'Squid Users' <squid-users at lists.squid-cache.org>
Subject: RE: SSL issue on Squid version 4 after blacklisting

 

Elizer/Team,

 

Any help would be appreciated.

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: DIXIT Ankit 
Sent: Tuesday, September 15, 2020 1:24 PM
To: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >; 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: SSL issue on Squid version 4 after blacklisting

 

Subject changed

 

Elizer/Team,

 

Connecting with you again after we upgraded to Squid version 4.

 

We have blacklisted the domain categories  on Squid Proxy, but we are getting below exception in cache.log and due to this internet is not flowing from client servers via squid. 

This blacklist category is having thousands of blacklisted domains.

 

kid1| Error negotiating SSL on FD 33: error:14090086:SSL routines:ssl3_get_server_certificate:certificate verify failed (1/-1/0)

kid1| Error negotiating SSL connection on FD 26: (104) Connection reset by peer

 

Is there any specific ssl certificate, we need to configure? Or any other issue, you see here?

 

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: DIXIT Ankit 
Sent: Monday, July 6, 2020 8:50 AM
To: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >; 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: RE: [squid-users] Squid memory consumption problem

 

Elizer,

 

SSL was failing for few applications but was working fine for other applications. So we reverted back to old version.

I am not sure what ssl certificate dependency was there. 

 

Would be great, if you can suggest memory leak solutions in 3.12 version.

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: Eliezer Croitor <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Sent: Sunday, July 5, 2020 5:58 PM
To: DIXIT Ankit <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com> >; 'Squid Users' <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Cc: SETHI Konica <Konica.Sethi at eurostar.com <mailto:Konica.Sethi at eurostar.com> >
Subject: RE: [squid-users] Squid memory consumption problem

 




 

Hey,

 

What happen with this issue?

I am waiting for any input about this issue to understand with what I can try to help.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit [mailto:Ankit.Dixit at eurostar.com] 
Sent: Tuesday, June 30, 2020 12:35 PM
To: Eliezer Croitoru; Squid Users
Cc: SETHI Konica
Subject: RE: [squid-users] Squid memory consumption problem

 

For your information, we have added below configurations but again same issue.

 

tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

 

tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: DIXIT Ankit 
Sent: Tuesday, June 30, 2020 10:25 AM
To: Eliezer Croitoru <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >; Squid Users <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Cc: SETHI Konica <Konica.Sethi at eurostar.com <mailto:Konica.Sethi at eurostar.com> >
Subject: RE: [squid-users] Squid memory consumption problem

 

Eliezer,

 

Clients are facing some SSL related issues after upgrade. I could see below error. Please suggest, its little urgent.

 

quid[6706]: Error negotiating SSL connection on FD 167: error:00000001:lib(0):func(0):reason(1) (1/0)
Jun 30 09:17:38 squid[6706]: Error parsing SSL Server Hello Message on FD 77
Jun 30 09:17:38 squid[6706]: Error negotiating SSL connection on FD 75: error:00000001:lib(0):func(0):reason(1) (1/0)

 

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

From: Eliezer Croitoru <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Sent: Tuesday, June 30, 2020 9:10 AM
To: Squid Users <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >; DIXIT Ankit <Ankit.Dixit at eurostar.com <mailto:Ankit.Dixit at eurostar.com> >
Subject: RE: [squid-users] Squid memory consumption problem

 




 

The first thing to do is look at:

https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery

 

It should clear couple doubts for you.

 

Eliezer

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: DIXIT Ankit <mailto:Ankit.Dixit at eurostar.com> 
Sent: Tuesday, June 30, 2020 10:46 AM
To: Eliezer Croitoru <mailto:ngtech1ltd at gmail.com> ; Alex Rousskov <mailto:rousskov at measurement-factory.com> ; squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Subject: RE: [squid-users] Squid memory consumption problem

 

Elizer,

 

We installed Squid 4.12 on production server, amazon Linux 2, successfully but I could see below messages in the logs for SECURITY ALERT: Host header forgery detected. These are getting generated very frequently.

Can we ignore this Or is it advised to suppress these alerts?

 

kid2| SECURITY ALERT: on URL: 5-25-3-app.agent.datadoghq.com:443 <http://5-25-3-app.agent.datadoghq.com:443> 

2020/06/30 07:41:29 kid1| SECURITY ALERT: Host header forgery detected on local=IP remote=IP FD 97 flags=33 (local IP does not match any domain IP)

 

Regards,

Ankit Dixit|IS Cloud Team

Eurostar International Ltd

Times House | Bravingtons Walk | London N1 9AW

Office: +44 (0)207 84 35550 (Extension? 35530)

 

 

  _____  

This email (including any attachments) is intended only for the addressee(s), is confidential and may be legally privileged. If you are not the intended recipient, do not use, disclose, copy, or forward this email. Please notify the sender immediately and then delete it. Eurostar International Limited and its affiliates ("EIL") do not accept any liability for action taken in reliance on this email. EIL makes no representation that this email is free of viruses and addressees should check this email for viruses. The comments or statements expressed in this email are not necessarily those of EIL. 

Eurostar International Ltd 
Times House, Bravingtons Walk, London N1 9AW Registered in England and Wales No. 2462001 

  _____  

 

 

  _____  

This email (including any attachments) is intended only for the addressee(s), is confidential and may be legally privileged. If you are not the intended recipient, do not use, disclose, copy, or forward this email. Please notify the sender immediately and then delete it. Eurostar International Limited and its affiliates ("EIL") do not accept any liability for action taken in reliance on this email. EIL makes no representation that this email is free of viruses and addressees should check this email for viruses. The comments or statements expressed in this email are not necessarily those of EIL. 

Eurostar International Ltd 
Times House, Bravingtons Walk, London N1 9AW Registered in England and Wales No. 2462001 

  _____  

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200927/bd059cb4/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.jpg
Type: image/jpeg
Size: 19517 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200927/bd059cb4/attachment.jpg>

From openwrt.jp at gmail.com  Sun Sep 27 16:07:45 2020
From: openwrt.jp at gmail.com (sec)
Date: Mon, 28 Sep 2020 00:07:45 +0800
Subject: [squid-users] squid 5.0.4 cache_peer bug on https outgoing
Message-ID: <CAL4_ukc6P8Ep25PeCBHoQcjuHW8BHfxNr3gySCAEbKH9VocXWA@mail.gmail.com>

X-Squid-Error: ERR_SECURE_CONNECT_FAIL 71
Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

### 0x01 squid version

squid -v

Squid Cache: Version 5.0.4

Service Name: squid


This binary uses OpenSSL 1.0.2g  1 Mar 2016. For legal restrictions on
distribution see https://www.openssl.org/source/license.html


configure options:  '--prefix=/usr' '--exec-prefix=/usr'
'--includedir=/usr/include' '--datadir=/usr/share' '--libdir=/usr/lib64'
'--libexecdir=/usr/lib64/squid' '--localstatedir=/var'
'--sysconfdir=/etc/squid' '--sharedstatedir=/var/lib'
'--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid'
'--with-default-user=squid' '--enable-silent-rules'
'--enable-dependency-tracking' '--with-openssl' '--enable-icmp'
'--enable-delay-pools' '--enable-useragent-log' '--enable-esi'
'--disable-ipv6' '--enable-ssl-crtd' '--enable-follow-x-forwarded-for'
'--enable-auth' --enable-ltdl-convenience

### 0x02  peers.conf

cache_peer 127.0.0.1 parent 3129 0 ssl weighted-round-robin login
=admin:squid name=crawler1

curl http://google.com -x https://admin:squid at localhost:3128 -v  -k

< HTTP/1.1 503 Service Unavailable

< Server: squid/5.0.4

< Mime-Version: 1.0

< Date: Sun, 27 Sep 2020 15:55:05 GMT

< Content-Type: text/html;charset=utf-8

< Content-Length: 1647

< X-Squid-Error: ERR_SECURE_CONNECT_FAIL 71

< Vary: Accept-Language

< Content-Language: en

< X-Cache: MISS from example.com

< Connection: keep-alive

proxy is ok. 3129 is glider
curl http://google.com -x https://admin:squid at localhost:3129 -v  -k

<HTML><HEAD><meta http-equiv="content-type" content=
"text/html;charset=utf-8">

<TITLE>301 Moved</TITLE></HEAD><BODY>

<H1>301 Moved</H1>

The document has moved

<A HREF="http://www.google.com/">here</A>.

</BODY></HTML>


### 0x03 the possible solution. DONT_VERIFY_PEER

So.on squid 4/5,  The DONT_VERIFY_PEER flag is deprecated.
How to get the function on  squid 5.0.4 ?

### 0x04 squid.conf


acl SSL_ports port 443

acl Safe_ports port 1-65535     # unregistered ports

acl CONNECT method CONNECT

acl HEAD method HEAD


http_access deny !Safe_ports

http_access deny manager

http_access allow all




http_port 3128 ssl-bump generate-host-certificates=on \

dynamic_cert_mem_cache_size=100MB \

cert=/etc/squid/server.crt key=/etc/squid/server.key



ssl_bump allow all

#ssl_bump bump all

sslproxy_cert_error allow all



sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
/usr/local/squid/ssl_db -M 400MB



#sslproxy_flags DONT_VERIFY_PEER

tls_outgoing_options options=ALL flags=DONT_VERIFY_PEER,DONT_VERIFY_DOMAIN

sslproxy_cert_error allow all





coredump_dir /var/spool/squid3


# based on
http://code.google.com/p/ghebhes/downloads/detail?name=tunning.conf&can=2&q=


#All File

refresh_pattern -i \.(3gp|7z|ace|asx|avi|bin|cab|dat|deb|rpm|divx|dvr-ms)
    1440 100% 129600 reload-into-ims

refresh_pattern -i \.
(rar|jar|gz|tgz|tar|bz2|iso|m1v|m2(v|p)|mo(d|v)|(x-|)flv) 1440 100% 129600
 reload-into-ims

refresh_pattern -i \.(jp(e?g|e|2)|gif|pn[pg]|bm?|tiff?|ico|swf|css|js)
    1440 100% 129600 reload-into-ims

refresh_pattern -i \.(mp(e?g|a|e|1|2|3|4)|mk(a|v)|ms(i|u|p))
    1440 100% 129600 reload-into-ims

refresh_pattern -i \.(og(x|v|a|g)|rar|rm|r(a|p)m|snd|vob|wav)
    1440 100% 129600 reload-into-ims

refresh_pattern -i \.(pp(s|t)|wax|wm(a|v)|wmx|wpl|zip|cb(r|z|t))
    1440 100% 129600 reload-into-ims


refresh_pattern -i \.(doc|pdf)$           1440   50% 43200 reload-into-ims

refresh_pattern -i \.(html|htm)$          1440   50% 40320 reload-into-ims


refresh_pattern ^ftp:           1440    20%     10080

refresh_pattern ^gopher:        1440    0%      1440

refresh_pattern -i (/cgi-bin/|\?) 0     0%      0

refresh_pattern (Release|Packages(.gz)*)$      0       20%     2880

refresh_pattern .               0       20%     4320





# http options

via off

forwarded_for off

vary_ignore_expire on



# memory cache options

cache_mem 512 MB

maximum_object_size_in_memory 256 KB




forwarded_for delete

ipcache_size 4096

dns_nameservers 8.8.8.8



# error page

cache_mgr admin at example.com

visible_hostname example.com

email_err_data off

err_page_stylesheet none



#include /etc/squid/peers.conf

# use glider to build an http(s)/socks5 proxy on same port 3129

# https://github.com/nadoo/glider

# glider -listen admin:squid at 0.0.0.0:3129


cache_peer 127.0.0.1 parent 3129 0 ssl weighted-round-robin login
=admin:squid name=crawler1



# never_direct: outgoing only by peers

never_direct allow  all


cache_effective_user proxy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200928/0c2d6e38/attachment.htm>

From rousskov at measurement-factory.com  Sun Sep 27 22:48:40 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 27 Sep 2020 18:48:40 -0400
Subject: [squid-users] squid 5.0.4 cache_peer bug on https outgoing
In-Reply-To: <CAL4_ukc6P8Ep25PeCBHoQcjuHW8BHfxNr3gySCAEbKH9VocXWA@mail.gmail.com>
References: <CAL4_ukc6P8Ep25PeCBHoQcjuHW8BHfxNr3gySCAEbKH9VocXWA@mail.gmail.com>
Message-ID: <6da20d4c-2911-e19b-1c3e-c79329820b0b@measurement-factory.com>

On 9/27/20 12:07 PM, sec wrote:

> http_port?3128?ssl-bump ...

> curl http://google.com -x https://admin:squid at localhost:3128 -v  -k

The above two lines do not match AFAICT: You tell curl to use an HTTPS
proxy, but you tell Squid to expect plain HTTP proxy requests.

Also, please note that if you fix the above problem by moving "https"
from "-x" to the origin server URL, then you will probably face another
problem:

curl https://google.com -x http://admin:squid at localhost:3128 -v  -k

> ssl_bump allow all

> cache_peer?127.0.0.1 parent?3129?0?ssl

Squid does not (yet) support "TLS inside TLS": Talking TLS with the
origin server through a cache_peer that also expects a TLS connection.


HTH,

Alex.


From openwrt.jp at gmail.com  Mon Sep 28 05:41:16 2020
From: openwrt.jp at gmail.com (openwrt)
Date: Mon, 28 Sep 2020 13:41:16 +0800
Subject: [squid-users] squid 5.0.4 cache_peer bug on https outgoing
In-Reply-To: <6da20d4c-2911-e19b-1c3e-c79329820b0b@measurement-factory.com>
References: <CAL4_ukc6P8Ep25PeCBHoQcjuHW8BHfxNr3gySCAEbKH9VocXWA@mail.gmail.com>
 <6da20d4c-2911-e19b-1c3e-c79329820b0b@measurement-factory.com>
Message-ID: <CAL4_ukfEuu0ct7td7fuyxRMbmNf_De1WPYLNGavN5JCpdF-Utw@mail.gmail.com>

Yes, I've tried all of these combinations.

### 0x00 cache_peer no ssl

> ssl_bump allow all
> cache_peer 127.0.0.1 parent 3129 0 ?no ssl?

curl http://google.com <https://google.com/> -x http://admin:squid at localhost
:3128 -v  -k   ?it is ok?

curl https://google.com -x https://admin:squid at localhost:3128 -v  -k   ?Get
502?
curl https://google.com -x http://admin:squid at localhost:3128 -v  -k
 ?Get 502?

< HTTP/1.1 502 Bad Gateway
< X-Cache: MISS from example.com
< Transfer-Encoding: chunked
< Connection: keep-alive

log json:

{ "clientip": "127.0.0.1", "ident": "-", "uname": "admin", "timestamp":
"2020-09-28T04:16:28+0000", "verb": "CONNECT", "request": "google.com:443",
"httpversion": "HTTP/1.1", "response": 200, "bytes": 0, "referer": "-",
"agent": "curl/7.47.0", "request_status": "HIER_NONE", "hierarchy_status":
"HIER_NONE" }

{ "clientip": "127.0.0.1", "ident": "-", "uname": "admin", "timestamp":
"2020-09-28T04:16:28+0000", "verb": "GET", "request": "https://google.com/",
"httpversion": "HTTP/1.1", "response": 502, "bytes": 117, "referer": "-",
"agent": "curl/7.47.0", "request_status": "HIER_NONE", "hierarchy_status":
"HIER_NONE" }

### 0x01 cache_peer with ssl

> ssl_bump allow all
> cache_peer 127.0.0.1 parent 3129 0  ssk

curl http://google.com <https://google.com/> -x http://admin:squid at localhost
:3128 -v  -k   ?Get 502?
curl https://google.com -x https://admin:squid at localhost:3128 -v  -k   ?Get
502?

< HTTP/1.1 503 Service Unavailable

< Server: squid/5.0.4

< Mime-Version: 1.0

< Date: Mon, 28 Sep 2020 04:21:00 GMT

< Content-Type: text/html;charset=utf-8

< Content-Length: 1649

< X-Squid-Error: ERR_SECURE_CONNECT_FAIL 71


<p>The system returned:</p>

<blockquote id="data">

<pre>(71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)</pre>

<p>Handshake with SSL server failed: [No Error]</p>

</blockquote>



### 0x02 how to outgoing https request by cache_peer (on squid 5.0.4/Chains
proxy)

Similar features to Charles OR Fiddler. ( open http(s) proxy  on 8080, then
capture the request , outgoing on another http(s)/socks4/5 proxy.)

1. Fiddler gateway:
https://docs.telerik.com/fiddler-everywhere/user-guide/settings/gateway

curl https://google.com -x http://squid:3128 --> outgoing(cache_peer: like
Fiddler gateway) --> google.com:443

The cache_peer should be ignore ssl VERIFY. !!! like other software.

On squid 5.0.4, http is ok, https will get ERR_SECURE_CONNECT_FAIL error.



Alex Rousskov <rousskov at measurement-factory.com> ?2020?9?28??? ??6:48???

> On 9/27/20 12:07 PM, sec wrote:
>
> > http_port 3128 ssl-bump ...
>
> > curl http://google.com -x https://admin:squid at localhost:3128 -v  -k
>
> The above two lines do not match AFAICT: You tell curl to use an HTTPS
> proxy, but you tell Squid to expect plain HTTP proxy requests.
>
> Also, please note that if you fix the above problem by moving "https"
> from "-x" to the origin server URL, then you will probably face another
> problem:
>
> curl https://google.com -x http://admin:squid at localhost:3128 -v  -k
>
> > ssl_bump allow all
>
> > cache_peer 127.0.0.1 parent 3129 0 ssl
>
> Squid does not (yet) support "TLS inside TLS": Talking TLS with the
> origin server through a cache_peer that also expects a TLS connection.
>
>
> HTH,
>
> Alex.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200928/49666ca7/attachment.htm>

From openwrt.jp at gmail.com  Mon Sep 28 09:39:51 2020
From: openwrt.jp at gmail.com (openwrt)
Date: Mon, 28 Sep 2020 17:39:51 +0800
Subject: [squid-users] squid 5.0.4 cache_peer bug on https outgoing
In-Reply-To: <CAL4_ukfEuu0ct7td7fuyxRMbmNf_De1WPYLNGavN5JCpdF-Utw@mail.gmail.com>
References: <CAL4_ukc6P8Ep25PeCBHoQcjuHW8BHfxNr3gySCAEbKH9VocXWA@mail.gmail.com>
 <6da20d4c-2911-e19b-1c3e-c79329820b0b@measurement-factory.com>
 <CAL4_ukfEuu0ct7td7fuyxRMbmNf_De1WPYLNGavN5JCpdF-Utw@mail.gmail.com>
Message-ID: <CAL4_ukdQMq9Z22-=Uvk_0gn9qnfqPShLzhnzo9O1EnCLnm58nA@mail.gmail.com>

I located the bug and found a another way to deal with it.

The bug is that cache_peer https CONNECT drops the port number

If you do the compatibility treatment on the back of the agent software,
you can solve this problem

However, it would be best if it was resolved on squid.

### 0x01 wireshare packet

1) squid cache_peer https CONNECT packet.

CONNECT d.qqq.win  HTTP/1.1 (bad format: without port)

0040   d1 d8 43 4f 4e 4e 45 43 54 20 64 2e 71 71 71 2e   ..CONNECT d.qqq.

0050   77 69 6e 20 48 54 54 50 2f 31 2e 31 0d 0a 55 73   win HTTP/1.1

2) glider verbose log

2020/09/28 17:19:58 forward.go:118: [forwarder] DIRECT recorded 1 failures,
maxfailures: 0

2020/09/28 17:19:58 server.go:98: [http] *.*.*.*:53848 <-> d.qqq.win [c]
via DIRECT, error in dial: dial tcp: address d.qqq.win: missing port in
address

### 0x02 solution

Locate the cache_peer code in squid and add the missing port to the
CONNETCT function.

or, you can do the compatibility treatment on the background proxy soft
(bad idea)



openwrt <openwrt.jp at gmail.com> ?2020?9?28??? ??1:41???

> Yes, I've tried all of these combinations.
>
> ### 0x00 cache_peer no ssl
>
> > ssl_bump allow all
> > cache_peer 127.0.0.1 parent 3129 0 ?no ssl?
>
> curl http://google.com <https://google.com/> -x
> http://admin:squid at localhost:3128 -v  -k   ?it is ok?
>
> curl https://google.com -x https://admin:squid at localhost:3128 -v  -k
>  ?Get 502?
> curl https://google.com -x http://admin:squid at localhost:3128 -v  -k
>  ?Get 502?
>
> < HTTP/1.1 502 Bad Gateway
> < X-Cache: MISS from example.com
> < Transfer-Encoding: chunked
> < Connection: keep-alive
>
> log json:
>
> { "clientip": "127.0.0.1", "ident": "-", "uname": "admin", "timestamp":
> "2020-09-28T04:16:28+0000", "verb": "CONNECT", "request": "google.com:443",
> "httpversion": "HTTP/1.1", "response": 200, "bytes": 0, "referer": "-",
> "agent": "curl/7.47.0", "request_status": "HIER_NONE", "hierarchy_status":
> "HIER_NONE" }
>
> { "clientip": "127.0.0.1", "ident": "-", "uname": "admin", "timestamp":
> "2020-09-28T04:16:28+0000", "verb": "GET", "request": "https://google.com/
> ", "httpversion": "HTTP/1.1", "response": 502, "bytes": 117, "referer":
> "-", "agent": "curl/7.47.0", "request_status": "HIER_NONE",
> "hierarchy_status": "HIER_NONE" }
>
> ### 0x01 cache_peer with ssl
>
> > ssl_bump allow all
> > cache_peer 127.0.0.1 parent 3129 0  ssk
>
> curl http://google.com <https://google.com/> -x
> http://admin:squid at localhost:3128 -v  -k   ?Get 502?
> curl https://google.com -x https://admin:squid at localhost:3128 -v  -k
>  ?Get 502?
>
> < HTTP/1.1 503 Service Unavailable
>
> < Server: squid/5.0.4
>
> < Mime-Version: 1.0
>
> < Date: Mon, 28 Sep 2020 04:21:00 GMT
>
> < Content-Type: text/html;charset=utf-8
>
> < Content-Length: 1649
>
> < X-Squid-Error: ERR_SECURE_CONNECT_FAIL 71
>
>
> <p>The system returned:</p>
>
> <blockquote id="data">
>
> <pre>(71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)</pre>
>
> <p>Handshake with SSL server failed: [No Error]</p>
>
> </blockquote>
>
>
>
> ### 0x02 how to outgoing https request by cache_peer (on squid
> 5.0.4/Chains proxy)
>
> Similar features to Charles OR Fiddler. ( open http(s) proxy  on 8080,
> then capture the request , outgoing on another http(s)/socks4/5 proxy.)
>
> 1. Fiddler gateway:
> https://docs.telerik.com/fiddler-everywhere/user-guide/settings/gateway
>
> curl https://google.com -x http://squid:3128 --> outgoing(cache_peer:
> like Fiddler gateway) --> google.com:443
>
> The cache_peer should be ignore ssl VERIFY. !!! like other software.
>
> On squid 5.0.4, http is ok, https will get ERR_SECURE_CONNECT_FAIL error.
>
>
>
> Alex Rousskov <rousskov at measurement-factory.com> ?2020?9?28??? ??6:48???
>
>> On 9/27/20 12:07 PM, sec wrote:
>>
>> > http_port 3128 ssl-bump ...
>>
>> > curl http://google.com -x https://admin:squid at localhost:3128 -v  -k
>>
>> The above two lines do not match AFAICT: You tell curl to use an HTTPS
>> proxy, but you tell Squid to expect plain HTTP proxy requests.
>>
>> Also, please note that if you fix the above problem by moving "https"
>> from "-x" to the origin server URL, then you will probably face another
>> problem:
>>
>> curl https://google.com -x http://admin:squid at localhost:3128 -v  -k
>>
>> > ssl_bump allow all
>>
>> > cache_peer 127.0.0.1 parent 3129 0 ssl
>>
>> Squid does not (yet) support "TLS inside TLS": Talking TLS with the
>> origin server through a cache_peer that also expects a TLS connection.
>>
>>
>> HTH,
>>
>> Alex.
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200928/788fbfbf/attachment.htm>

From squid3 at treenet.co.nz  Mon Sep 28 10:14:54 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 28 Sep 2020 23:14:54 +1300
Subject: [squid-users] squid 5.0.4 cache_peer bug on https outgoing
In-Reply-To: <CAL4_ukfEuu0ct7td7fuyxRMbmNf_De1WPYLNGavN5JCpdF-Utw@mail.gmail.com>
References: <CAL4_ukc6P8Ep25PeCBHoQcjuHW8BHfxNr3gySCAEbKH9VocXWA@mail.gmail.com>
 <6da20d4c-2911-e19b-1c3e-c79329820b0b@measurement-factory.com>
 <CAL4_ukfEuu0ct7td7fuyxRMbmNf_De1WPYLNGavN5JCpdF-Utw@mail.gmail.com>
Message-ID: <ea659439-020a-1ce7-835a-2c9177e3831e@treenet.co.nz>

On 28/09/20 6:41 pm, openwrt wrote:
> Yes, I've tried all of these combinations.
> 
> ### 0x00?cache_peer no ssl
> 
>> ssl_bump allow all

"allow" is not a SSL-Bump action type for any version of Squid.
<https://wiki.squid-cache.org/Features/SslPeekAndSplice#Actions>

AFAIK, SSL-Bump falls back to default "bump all" as the action performed.


>> cache_peer?127.0.0.1 parent?3129?0 ?no ssl?
> 
> curl?http://google.com <https://google.com/>?-x
> http://admin:squid at localhost:3128 -v? -k? ??it is ok?
> 

This does HTTP(-over-TCP) to Squid asking for HTTP to origin. A
non-TLS/SSL peer is perfectly capable of fetching that.


> curl?https://google.com <https://google.com/>?-x
> https://admin:squid at localhost:3128 -v? -k? ??Get 502?

This does HTTP(-over-TL)S to Squid which told to accept HTTP(-over-TCP).
Expect 502 generated by the frontend Squid.


> curl?https://google.com <https://google.com/>?-x
> http://admin:squid at localhost:3128 -v? -k? ? ??Get 502?
> 

This does HTTP(-over-TCP) to Squid asking for CONNECT tunnel
containing HTTP-over-TLS to origin.

Expect that the tunnel be accepted fro decryption by the frontend Squid
(200 status), then another CONNECT tunnel generated to fetch the
decrypted traffic via the insecure peer.


> 
> log json:
> 
> { "clientip": "127.0.0.1", "ident": "-", "uname": "admin", "timestamp":
> "2020-09-28T04:16:28+0000", "verb": "CONNECT", "request":
> "google.com:443 <http://google.com:443>", "httpversion": "HTTP/1.1",
> "response": 200, "bytes": 0, "referer": "-", "agent": "curl/7.47.0",
> "request_status": "HIER_NONE", "hierarchy_status": "HIER_NONE"}
> 

CONNECT tunnel received and decrypted. This says that you actually
received a 200 status to at least one of your tests. I expect it was for
that third one.


> { "clientip": "127.0.0.1", "ident": "-", "uname": "admin", "timestamp":
> "2020-09-28T04:16:28+0000", "verb": "GET", "request":
> "https://google.com/", "httpversion": "HTTP/1.1", "response": 502,
> "bytes": 117, "referer": "-", "agent": "curl/7.47.0", "request_status":
> "HIER_NONE", "hierarchy_status": "HIER_NONE"}
> 

Decrypted request was not able to be sent anywhere. This is your main
problem - made worse by the ssl_bump misconfiguration. The 502 message
contains a brief description about what went wrong. cache.log may
contain more details - if not, increase the verbosity for
troubleshooting with "debug_options ALL,2 83,7"


> 
> ### 0x01?cache_peer with ssl
> 
>> ssl_bump allow all
>> cache_peer?127.0.0.1 parent?3129?0? ssk
> 
> curl?http://google.com <https://google.com/>?-x
> http://admin:squid at localhost:3128 -v? -k? ??Get 502?
> curl?https://google.com <https://google.com/>?-x
> https://admin:squid at localhost:3128 -v? -k? ??Get 502?
> 
> < HTTP/1.1 503 Service Unavailable
> 

This is 503, not the 502 you mention above.

 * Which of the two different test commands produced it?

 * It says that there is a TLS protocol syntax problem talking TLS/SSL
to the server or peer.

> 
> < X-Squid-Error: ERR_SECURE_CONNECT_FAIL 71
> 
> 
> <p>The system returned:</p>
> 
> <blockquote id="data">
> 
> <pre>(71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)</pre>
> 
> <p>Handshake with SSL server failed: [No Error]</p>
> 
> </blockquote>
> 


> 
> ### 0x02 how to outgoing https request by?cache_peer (on squid
> 5.0.4/Chains proxy)
> 
> Similar features to Charles OR?Fiddler. ( open http(s) proxy? on 8080,
> then capture the request , outgoing on another http(s)/socks4/5 proxy.)
> 
> 1.?Fiddler
> gateway:?https://docs.telerik.com/fiddler-everywhere/user-guide/settings/gateway
> 
> curl https://google.com -x http://squid:3128 --> outgoing(cache_peer:
> like Fiddler gateway) --> google.com:443 <http://google.com:443>
> 
> The?cache_peer should be ignore ssl?VERIFY. !!! like other software.
> 

No. There is no use using TLS if you are going to disable *all* the
security.

What Squid should actually happen is that you configure Squid to know
what CA signed the peer SSL certificate (with cache_peer tls-cafile=
option). So that connections properly going to that peer will verify
successfully. The default you have with just the "ssl "flag (FYI: that
should be "tls" nowdays) uses the operating systems default Global
Trusted CA's to verify.

Allowing interception attacks and transfer corruption on the peer
traffic to be identified if/when any happen is the entire purpose of
using TLS/SSL on peer connections.


Amos


From squid3 at treenet.co.nz  Mon Sep 28 11:53:33 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 29 Sep 2020 00:53:33 +1300
Subject: [squid-users] squid 5.0.4 cache_peer bug on https outgoing
In-Reply-To: <CAL4_ukdQMq9Z22-=Uvk_0gn9qnfqPShLzhnzo9O1EnCLnm58nA@mail.gmail.com>
References: <CAL4_ukc6P8Ep25PeCBHoQcjuHW8BHfxNr3gySCAEbKH9VocXWA@mail.gmail.com>
 <6da20d4c-2911-e19b-1c3e-c79329820b0b@measurement-factory.com>
 <CAL4_ukfEuu0ct7td7fuyxRMbmNf_De1WPYLNGavN5JCpdF-Utw@mail.gmail.com>
 <CAL4_ukdQMq9Z22-=Uvk_0gn9qnfqPShLzhnzo9O1EnCLnm58nA@mail.gmail.com>
Message-ID: <3b3fbf87-f472-5a76-9ad7-50379584afca@treenet.co.nz>

On 28/09/20 10:39 pm, openwrt wrote:
> I located the bug and found a another way to deal with it.
> 
> The bug is that cache_peer https CONNECT drops the port number
> 
> If you do the compatibility treatment on the back of the agent software,
> you can solve this problem
> 
> However, it would be best if it was resolved on squid.
> 
> ### 0x01 wireshare packet
> 
> 1) squid?cache_peer https CONNECT packet.
> 
> CONNECT d.qqq.win? HTTP/1.1 (bad format: without port)
> 

Aha. Thank you for finding this. Can you please open a bug in our
bugzilla with the details so this does not get lost.

Amos


From rst at fomar.com.pl  Mon Sep 28 13:19:05 2020
From: rst at fomar.com.pl (=?UTF-8?Q?Rafa=C5=82_Stanilewicz?=)
Date: Mon, 28 Sep 2020 14:19:05 +0100
Subject: [squid-users] measuring latency of squid in different scenarios
Message-ID: <CAPnyBTPt+3WyVpk25UQ_1v3Jk2bjMv9tdtNESwSQ3a+Q32beOg@mail.gmail.com>

Hello,

I'm planning the deployment of web proxy in my environment. It's not very
big, around 80 typical windows 10 workstations, active directory, plus some
DMZ servers. For now, there is very basic L7 inspection on the edge
firewall.

I plan to use two separate squid instances, one for explicit proxy traffic,
forced by AD GPO settings, and second for traffic still being sent directly
to the Internet (as several applications we use tend to ignore the system
proxy settings). The first instance will use (hopefully) AD authentication,
while the second will use only srcIP-based rules. I will be grateful for
any comments, what should I focus on, or some quirks - I've never deployed
squid from scratch.

But my main point of writing is:

I'd like to get some numbers about squid-introduced latency of getting some
particular web resource. Is there any benchmarking program I could use? I'd
like to see what is the current latency of getting the resource without any
proxying, then of getting the same resource with explicit proxy settings,
then of implicit (intercepting) proxy option, as well as for different
options of caching.

How should I start? Is there any software I can use to measure that,
besides analysis of HAR files?

So far, I used squid only in home environment, and without a need for
granular measurement.

Best regards,

Rafal Stanilewicz
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200928/880e1410/attachment.htm>

From rousskov at measurement-factory.com  Mon Sep 28 13:52:28 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 28 Sep 2020 09:52:28 -0400
Subject: [squid-users] squid 5.0.4 cache_peer bug on https outgoing
In-Reply-To: <CAL4_ukdQMq9Z22-=Uvk_0gn9qnfqPShLzhnzo9O1EnCLnm58nA@mail.gmail.com>
References: <CAL4_ukc6P8Ep25PeCBHoQcjuHW8BHfxNr3gySCAEbKH9VocXWA@mail.gmail.com>
 <6da20d4c-2911-e19b-1c3e-c79329820b0b@measurement-factory.com>
 <CAL4_ukfEuu0ct7td7fuyxRMbmNf_De1WPYLNGavN5JCpdF-Utw@mail.gmail.com>
 <CAL4_ukdQMq9Z22-=Uvk_0gn9qnfqPShLzhnzo9O1EnCLnm58nA@mail.gmail.com>
Message-ID: <42979d1e-7751-bed0-8497-a6dfafb317a4@measurement-factory.com>

On 9/28/20 5:39 AM, openwrt wrote:

> The bug is that cache_peer https CONNECT drops the port number

Please try the attached patch.

Thank you,

Alex.


> squid?cache_peer https CONNECT packet.
> 
> CONNECT d.qqq.win? HTTP/1.1 (bad format: without port)
> 
> 0040 ? d1 d8 43 4f 4e 4e 45 43 54 20 64 2e 71 71 71 2e ? ..CONNECT d.qqq.
> 0050 ? 77 69 6e 20 48 54 54 50 2f 31 2e 31 0d 0a 55 73 ? win HTTP/1.1
-------------- next part --------------
A non-text attachment was scrubbed...
Name: SQUID-111-peer-connect-port-t1.patch
Type: text/x-patch
Size: 635 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200928/7d7184b7/attachment.bin>

From Ralf.Hildebrandt at charite.de  Mon Sep 28 14:03:33 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Mon, 28 Sep 2020 16:03:33 +0200
Subject: [squid-users] [ext] Re: Change of server hardware (?) resulted
 in massive increase of crashes
In-Reply-To: <e9f72fbc-29e2-1dc4-935f-c1170797ddcc@measurement-factory.com>
References: <20200922074737.7twi6ffghibfpqgg@charite.de>
 <e9f72fbc-29e2-1dc4-935f-c1170797ddcc@measurement-factory.com>
Message-ID: <20200928140333.xqaf6qcrel32apsd@charite.de>

> This is still bug #5055. I hope we will post an official pull request
> properly addressing it soon.
> 
> In my environment, Squid v5 is hardly usable without those fixes but, as
> you know, YMMV. Your OS upgrade could trigger different DNS resolution
> timings, the new cluster may have different IPv6 connectivity profile,
> or there can be similar minor/innocent changes that result in slightly
> different Squid state and more exceptions. I would not spend time trying
> to pinpoint the exact trigger.
> 
> I updated bug #5055 with a patch that covers the tunneling case:
> https://bugs.squid-cache.org/show_bug.cgi?id=5055#c5

I applied your renewed patch to squid-6.0.0-20200811-r983fab6e9 -- and
so far the resulting binary seems to be much more stable than with the
previous patch to #5055.

We're currently giving that instance 10% of the connections for
testing (in contrast to the usual 25%)

5.0.2 (running on the other 3 nodes) gives us about 21.7h average
uptime with a median uptime of 28.6h

--
Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From openwrt.jp at gmail.com  Mon Sep 28 14:08:48 2020
From: openwrt.jp at gmail.com (openwrt)
Date: Mon, 28 Sep 2020 22:08:48 +0800
Subject: [squid-users] squid 5.0.4 cache_peer bug on https outgoing
In-Reply-To: <42979d1e-7751-bed0-8497-a6dfafb317a4@measurement-factory.com>
References: <CAL4_ukc6P8Ep25PeCBHoQcjuHW8BHfxNr3gySCAEbKH9VocXWA@mail.gmail.com>
 <6da20d4c-2911-e19b-1c3e-c79329820b0b@measurement-factory.com>
 <CAL4_ukfEuu0ct7td7fuyxRMbmNf_De1WPYLNGavN5JCpdF-Utw@mail.gmail.com>
 <CAL4_ukdQMq9Z22-=Uvk_0gn9qnfqPShLzhnzo9O1EnCLnm58nA@mail.gmail.com>
 <42979d1e-7751-bed0-8497-a6dfafb317a4@measurement-factory.com>
Message-ID: <CAL4_ukcWBgUiHhDJJxrTg+YY8UHhW09BtsApd3mURrDb2dRSMQ@mail.gmail.com>

It worked. thanks.

Alex Rousskov <rousskov at measurement-factory.com> ?2020?9?28??? ??9:52???

> On 9/28/20 5:39 AM, openwrt wrote:
>
> > The bug is that cache_peer https CONNECT drops the port number
>
> Please try the attached patch.
>
> Thank you,
>
> Alex.
>
>
> > squid cache_peer https CONNECT packet.
> >
> > CONNECT d.qqq.win  HTTP/1.1 (bad format: without port)
> >
> > 0040   d1 d8 43 4f 4e 4e 45 43 54 20 64 2e 71 71 71 2e   ..CONNECT d.qqq.
> > 0050   77 69 6e 20 48 54 54 50 2f 31 2e 31 0d 0a 55 73   win HTTP/1.1
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200928/8ae8996d/attachment.htm>

From rousskov at measurement-factory.com  Mon Sep 28 14:12:41 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 28 Sep 2020 10:12:41 -0400
Subject: [squid-users] measuring latency of squid in different scenarios
In-Reply-To: <CAPnyBTPt+3WyVpk25UQ_1v3Jk2bjMv9tdtNESwSQ3a+Q32beOg@mail.gmail.com>
References: <CAPnyBTPt+3WyVpk25UQ_1v3Jk2bjMv9tdtNESwSQ3a+Q32beOg@mail.gmail.com>
Message-ID: <ad1e32a7-12e5-af0c-921c-afc06a946cd5@measurement-factory.com>

On 9/28/20 9:19 AM, Rafa? Stanilewicz wrote:

> I'd like to get some numbers about squid-introduced latency of getting
> some particular web resource. Is there any benchmarking program I could
> use? I'd like to see what is the current latency of getting the resource
> without any proxying, then of getting the same resource with explicit
> proxy settings, then of implicit (intercepting) proxy option, as well as
> for different options of caching.?

What is the primary goal of collecting those measurements? Let's assume
that the measurements show that Squid adds X% to the median response
time in a particular test scenario. Now what?

* If the primary goal is to just record/report _some_ number and forget
about it, then you can use curl, wget, or ab to generate dumb test
traffic and measure overall response times of primary configurations.
This (mostly pointless from a purely technical point of view) exercise
should not take more than a few hours. It is useful, for example, in
cases where one needs to report some measurements to the management, but
everybody just wants to mark some checkbox on some list.

* If the primary goal is to verify some performance guarantees or tune
Squid performance, then you would need to invest a lot more into these
performance tests. You need stable, reproducible results and
representative traffic pattern(s). I use Web Polygraph
(http://www.web-polygraph.org) for such tests, but it has a steep
learning curve, may need some love to compile in your environment, and
it is a biased recommendation.


HTH,

Alex.


From service.mv at gmail.com  Mon Sep 28 14:55:58 2020
From: service.mv at gmail.com (Service MV)
Date: Mon, 28 Sep 2020 11:55:58 -0300
Subject: [squid-users] How te deal with proxy authentication bypass
In-Reply-To: <570566410.878666.1601136767167@mail.yahoo.com>
References: <CA+d==oGFmGqb-BLE+s85FOFkg4OnsJtjW5cqxC+7FaybKVLmvw@mail.gmail.com>
 <570566410.878666.1601136767167@mail.yahoo.com>
Message-ID: <CA+d==oHwkW4__DQaodDUQxmbDx5kQkrvixg-BQDJGGMZBCtoJg@mail.gmail.com>

In my case I have the domains, for example from webex, which I get from
their official support page. It seems that I am doing something wrong or I
am not understanding well.
I base on this documentation
https://wiki.squid-cache.org/ConfigExamples/Authenticate/Bypass

The error I get is 407. I understand I should not request authentication to
those domains with the configuration I have, but apparently it does.

Below I have a bandwidth control configuration with acl note, I don't know
if that will be triggering the webex client authentication request.
Maybe someone with more experience can tell me.

Thank you very much.
Gabriel

El s?b., 26 de sep. de 2020 a la(s) 13:12, Ajb B (ajb23 at ymail.com) escribi?:

> I looked this up an it looks like the reason Google does not work with
> Kerberos authentication (I think) is that Google makes requests to other
> domains:
>
> https://serverfault.com/a/307605
> (Please look at the second comment of the first answer.)
>
> The solution would be to create an ACL to allow the Google and Cisco
> domains, but I don't think it will work because they make requests to other
> domains. It would be something like:
>
> acl allowed_domains dstdomain google.com
> http_access allow allowed_domains
>
> Please note you would have to place it before your ACL in your lines where
> you have:
>
> http_access allow authenticated
> http_access deny all
>
> I don't really have a solution except to look at your access.log file (in
> /var/log/squid), see the other domains Google is making a request to, and
> then add to your ACLs also.
>
>
> Thanks,
> Adrian
> On Friday, September 25, 2020, 5:28:36 PM CDT, Service MV <
> service.mv at gmail.com> wrote:
>
>
> Hello everyone, I am trying to deal unsuccessfully with proxy
> authentication bypass.
> Even looking at the documentation I can't get it right. The point is that
> certain programs such as being a cisco webex client or the google earth pro
> client do not know how to speak well with SQUID's kerberos authentication,
> so I want them not to authenticate for the domains they use.
> For everything else I have no problems in the authentication.
> I attach the logs I get and my configuration to see if they can help me.
>
> Thank you very much in advance.
> Best regards
> Gabriel
>
> squid.conf
> visible_hostname s-px4.mydomain.com
> #http_port 3128 require-proxy-header
> http_port 3128
> error_directory /opt/squid-503/share/errors/es-ar
> forwarded_for transparent
> shutdown_lifetime 0 seconds
> quick_abort_min 0 KB
> quick_abort_max 0 KB
> quick_abort_pct 100
> read_timeout 5 minutes
> request_timeout 3 minutes
> cache_mem 1024 MB
> maximum_object_size_in_memory 4 MB
> memory_cache_mode always
> ipcache_size 2048
> fqdncache_size 4096
> #cache_mgr
> httpd_suppress_version_string on
> coredump_dir /opt/squid-503/var/cache/squid
>
> auth_param negotiate program
> /opt/squid-503/libexec/negotiate_kerberos_auth -i -r -s GSS_C_NO_NAME
> auth_param negotiate children 300 startup=150 idle=10
> auth_param negotiate keep_alive on
>
> auth_param basic program /opt/squid-503/libexec/basic_ldap_auth -P -R -b
> "dc=mydomain,dc=com" -D "cn=ldap,cn=Users,dc=mydomain,dc=com" -W
> /opt/squid-503/etc/ldappass.txt -f sAMAccountName=%s -h
> s-dc00.mydomain.com
> auth_param basic children 30
> auth_param basic realm Proxy Authentication
> auth_param basic credentialsttl 4 hour
>
> #acl vip_haproxy src 10.10.8.92
> #proxy_protocol_access allow vip_haproxy
>
> external_acl_type NO_INTERNET_USERS ttl=3600 negative_ttl=3600 %LOGIN
> /opt/squid-503/libexec/ext_kerberos_ldap_group_acl -g INTERNET_OFF -i -D
> NUEVENET.MEDIOS
> acl NO_INTERNET external NO_INTERNET_USERS
>
> acl SSL_ports port 443
> acl SSL_ports port 8543         # LiveU Central
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl Safe_ports port 81          # coto "yo te conozco" donkey ports
> acl Safe_ports port 623         # coto "yo te conozco" donkey ports
> acl Safe_ports port 8543        # LiveU Central management
> acl Safe_ports port 18255       # LiveU Central files download
> acl Safe_ports port 33080       # ddjj
> acl Safe_ports port 9090        # asociart
> acl Safe_ports port 8713        # handball results
> acl Safe_ports port 8080        # cponline.org.ar
>
> # Lists of domains and IPs
> acl LS_winupddom dstdomain "/opt/squid-503/acl/winupddom.txt"
> acl LS_whitedomains dstdomain "/opt/squid-503/acl/whitedomains.txt"
> acl LS_blackdomains dstdomain "/opt/squid-503/acl/blackdomains.txt"
> acl LS_porn dstdomain "/opt/squid-503/acl/porn.txt"
> acl DOM_Malware dstdomain "/opt/squid-503/acl/DOM_Malware.txt"
> acl IP_Malware dst -n "/opt/squid-503/acl/IP_Malware.txt"
> acl LS_webex dstdomain "/opt/squid-503/acl/webex.txt"
>
> # Access lists
> acl http proto http
> acl port_80 port 80
> acl port_443 port 443
> acl port_9000 port 9000
> acl port_5061 port 5061
> acl port_5065 port 5065
> acl CONNECT method CONNECT
>
> #acl authenticated proxy_auth REQUIRED
> # Denied internet to member users of INTERNET_OFF group
> http_access deny NO_INTERNET all
>
> # Allow webex without authentication
> http_access allow http port_80 LS_webex
> http_access allow CONNECT port_443 LS_webex
> http_access allow port_9000 LS_webex
> http_access allow port_5061 LS_webex
> http_access allow port_5065 LS_webex
>
>
> http_access deny LS_blackdomains
> http_access deny LS_porn
> http_access deny DOM_Malware
> http_access deny IP_Malware
>
> # default SQUID rules
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access deny to_localhost
> http_access allow localhost
>
> # Apply 20Mbit/s QoS to members of Active Directory Authenticated Users
> group
> acl Domain_Users note group AQUAAAAAAAUVAAAA7TIfbORUj8PLQv4YAQIAAA==
> delay_pools 1
> delay_class 1 1
> delay_parameters 1 2500000/2500000
> delay_access 1 allow Domain_Users
>
> # Allow authenticated users to use internet and deny to all others
> acl authenticated proxy_auth REQUIRED
> http_access allow authenticated
> http_access deny all
>
>
> cat /opt/squid-503/acl/webex.txt
> .wbx2.com
> .ciscospark.com
> .webex.com
> .quovadisglobal.com
> .digicert.com
> .accompany.com
> .walkme.com
> .cisco.com
>
> access.log
> 1601071522.675      0 10.10.9.250 TCP_DENIED/407 4106 CONNECT
> join-test.webex.com:443 - HIER_NONE/- text/html
> 1601071522.684      0 10.10.9.250 TCP_DENIED/407 4029 CONNECT
> msj1mcccl01.webex.com:443 - HIER_NONE/- text/html
> 1601071524.717      0 10.10.9.250 TCP_DENIED/407 4086 CONNECT
> tsa3.webex.com:443 - HIER_NONE/- text/html
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200928/88dfc8cd/attachment.htm>

From rentorbuy at yahoo.com  Tue Sep 29 09:34:09 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Tue, 29 Sep 2020 09:34:09 +0000 (UTC)
Subject: [squid-users] acl for urls without regex
References: <433990113.117896.1601372049639.ref@mail.yahoo.com>
Message-ID: <433990113.117896.1601372049639@mail.yahoo.com>

Hi,

Is it possible to create an ACL from a text file containing URLs without treating them as regular expressions?
Otherwise, I get errors of this kind:

?ERROR: invalid regular expression: 'https://whatever.net/auth_hotmail/?user={email}&amp;email={email}': Invalid content of \{\}

Regards,

Vieri


From squid3 at treenet.co.nz  Tue Sep 29 10:40:20 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 29 Sep 2020 23:40:20 +1300
Subject: [squid-users] How te deal with proxy authentication bypass
In-Reply-To: <CA+d==oHwkW4__DQaodDUQxmbDx5kQkrvixg-BQDJGGMZBCtoJg@mail.gmail.com>
References: <CA+d==oGFmGqb-BLE+s85FOFkg4OnsJtjW5cqxC+7FaybKVLmvw@mail.gmail.com>
 <570566410.878666.1601136767167@mail.yahoo.com>
 <CA+d==oHwkW4__DQaodDUQxmbDx5kQkrvixg-BQDJGGMZBCtoJg@mail.gmail.com>
Message-ID: <487c3c40-5f30-e00b-4890-db51d1910021@treenet.co.nz>

On 29/09/20 3:55 am, Service MV wrote:
> In my case I have the domains, for example from webex, which I get from
> their official support page. It seems that I am doing something wrong or
> I am not understanding well.
> I base on this documentation
> https://wiki.squid-cache.org/ConfigExamples/Authenticate/Bypass
> 
> The error I get is 407. I understand I should not request authentication
> to those domains with the configuration I have, but apparently it does.
> 

In the (possibly outdated now) config you showed earlier the
"NO_INTERNET" ACL might produce a 407 if credentials are completely
missing, but not re-auth if they are invalid.
 If you wish to have a free audit please post your current squid.conf
rules and I will comment on useful changes.


> Below I have a bandwidth control configuration with acl note, I don't
> know if that will be triggering the webex client authentication request.
> Maybe someone with more experience can tell me.

"note" ACL will match if the data is available but not trigger
authentication sequences. That is what makes it so useful for fast-group
access checking logins.


Amos


From rentorbuy at yahoo.com  Tue Sep 29 13:27:38 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Tue, 29 Sep 2020 13:27:38 +0000 (UTC)
Subject: [squid-users] ACL matches when it shouldn't
References: <1120165843.178042.1601386058160.ref@mail.yahoo.com>
Message-ID: <1120165843.178042.1601386058160@mail.yahoo.com>

Hi,

I have a url_regex ACL loaded with this file:

https://drive.google.com/file/d/1C5aZqPfMD3qlVP8zvm67c9ZnXUfz-cEW/view?usp=sharing

Then I have an access denial like so:

http_access deny bad_dst_urls

Problem is that I am not expecting to block, eg. https://www.google.com, but I am.
I know it's this ACL because if I remove the htttp_access deny line above, the browser can access? just fine.

I've been? looking around this file for possible matches? for google.com, but there shouldn't be.

Can anyone please let me know if there's a match, or how to enable debugging? to see which record in this ACL is actually triggering the denial?

I'm trying with:
debug_options rotate=1 ALL,1 85,2 88,2

Then I grep the log for bad_dst_urls and DENIED, but I can't seem to find a clear match.

Regards,

Vieri


From squid3 at treenet.co.nz  Tue Sep 29 14:08:38 2020
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 30 Sep 2020 03:08:38 +1300
Subject: [squid-users] ACL matches when it shouldn't
In-Reply-To: <1120165843.178042.1601386058160@mail.yahoo.com>
References: <1120165843.178042.1601386058160.ref@mail.yahoo.com>
 <1120165843.178042.1601386058160@mail.yahoo.com>
Message-ID: <3fe71d34-e37a-2481-0d53-b9548714239c@treenet.co.nz>

On 30/09/20 2:27 am, Vieri wrote:
> Hi,
> 
> I have a url_regex ACL loaded with this file:
> 
> https://drive.google.com/file/d/1C5aZqPfMD3qlVP8zvm67c9ZnXUfz-cEW/view?usp=sharing
> 
> Then I have an access denial like so:
> 
> http_access deny bad_dst_urls
> 
> Problem is that I am not expecting to block, eg. https://www.google.com, but I am.
> I know it's this ACL because if I remove the htttp_access deny line above, the browser can access? just fine.
> 
> I've been? looking around this file for possible matches? for google.com, but there shouldn't be.

None of the file entries are anchored regex. So any one of them could match.


> 
> Can anyone please let me know if there's a match, or how to enable debugging? to see which record in this ACL is actually triggering the denial?

To do that we will need to see the complete and exact URL which is being
blocked incorrectly.


NP: a large number of that files entries can be far more efficiently
blocked using the dstdomain ACL type. For example:

  acl blacklist dstdomain .appspot.com


Amos


From service.mv at gmail.com  Tue Sep 29 20:53:47 2020
From: service.mv at gmail.com (Service MV)
Date: Tue, 29 Sep 2020 17:53:47 -0300
Subject: [squid-users] How te deal with proxy authentication bypass
In-Reply-To: <487c3c40-5f30-e00b-4890-db51d1910021@treenet.co.nz>
References: <CA+d==oGFmGqb-BLE+s85FOFkg4OnsJtjW5cqxC+7FaybKVLmvw@mail.gmail.com>
 <570566410.878666.1601136767167@mail.yahoo.com>
 <CA+d==oHwkW4__DQaodDUQxmbDx5kQkrvixg-BQDJGGMZBCtoJg@mail.gmail.com>
 <487c3c40-5f30-e00b-4890-db51d1910021@treenet.co.nz>
Message-ID: <CA+d==oG0k1pd6pTpikd+YC6vzoS1yxv6EtpD4Q-abbY4=1S1+w@mail.gmail.com>

Thank you Amos as always.
My current configuration has not changed much, it is as follows:

visible_hostname s-px4.mydomain.local
http_port 3128
error_directory /opt/squid-503/share/errors/es-ar
forwarded_for transparent
shutdown_lifetime 0 seconds
quick_abort_min 0 KB
quick_abort_max 0 KB
quick_abort_pct 100
read_timeout 5 minutes
request_timeout 3 minutes
cache_mem 1024 MB
maximum_object_size_in_memory 4 MB
memory_cache_mode always
ipcache_size 2048
fqdncache_size 4096
cache_mgr support at mydomain.local
httpd_suppress_version_string on
coredump_dir /opt/squid-503/var/cache/squid

auth_param negotiate program /opt/squid-503/libexec/negotiate_kerberos_auth
-i -r -s GSS_C_NO_NAME
auth_param negotiate children 300 startup=150 idle=10
auth_param negotiate keep_alive on

auth_param basic program /opt/squid-503/libexec/basic_ldap_auth -P -R -b
"dc=mydomain,dc=local" -D "cn=ldap,cn=Users,dc=mydomain,dc=local" -W
/opt/squid-503/etc/ldappass.txt -f sAMAccountName=%s -h
s-dc00.mydomain.local
auth_param basic children 30
auth_param basic realm Proxy Authentication
auth_param basic credentialsttl 4 hour

external_acl_type NO_INTERNET_USERS ttl=3600 negative_ttl=3600 %LOGIN
/opt/squid-503/libexec/ext_kerberos_ldap_group_acl -g INTERNET_OFF -i -D
MYDOMAIN.LOCAL
acl NO_INTERNET external NO_INTERNET_USERS

acl SSL_ports port 443
acl SSL_ports port 8543         # LiveU Central
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 81          # coto "yo te conozco" donkey ports
acl Safe_ports port 623         # coto "yo te conozco" donkey ports
acl Safe_ports port 8543        # LiveU Central management
acl Safe_ports port 18255       # LiveU Central files download
acl Safe_ports port 33080       # ddjj
acl Safe_ports port 9090        # asociart
acl Safe_ports port 8713        # handball results
acl Safe_ports port 8080        # cponline.org.ar


# Lists of domains and IPs
acl LS_winupddom dstdomain "/opt/squid-503/acl/winupddom.txt"
acl LS_whitedomains dstdomain "/opt/squid-503/acl/whitedomains.txt"
acl LS_blackdomains dstdomain "/opt/squid-503/acl/blackdomains.txt"
acl LS_porn dstdomain "/opt/squid-503/acl/porn.txt"
acl DOM_Malware dstdomain "/opt/squid-503/acl/DOM_Malware.txt"
acl IP_Malware dst -n "/opt/squid-503/acl/IP_Malware.txt"
acl LS_webex dstdomain "/opt/squid-503/acl/webex.txt"

# Access lists
acl http proto http
acl port_80 port 80
acl port_443 port 443
acl port_9000 port 9000
acl port_5061 port 5061
acl port_5065 port 5065
acl CONNECT method CONNECT

# Denied internet to member users of INTERNET_OFF group
http_access deny NO_INTERNET all

# Allow webex without authentication
http_access allow http port_80 LS_webex
http_access allow CONNECT port_443 LS_webex
http_access allow port_9000 LS_webex
http_access allow port_5061 LS_webex
http_access allow port_5065 LS_webex

http_access deny LS_blackdomains
http_access deny LS_porn
http_access deny DOM_Malware
http_access deny IP_Malware

# default SQUID rules
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access deny to_localhost
http_access allow localhost

# Apply 20Mbit/s QoS to members of Active Directory Authenticated Users
group
acl Domain_Users note group AQUAAAAAAAUVAAAA7TIfbORUj8PLQv4YAQIAAA==
delay_pools 1
delay_class 1 1
delay_parameters 1 2500000/2500000
delay_access 1 allow Domain_Users

# Allow authenticated users to use internet and deny to all others
acl authenticated proxy_auth REQUIRED
http_access allow authenticated
http_access deny all


Thank you very much in advance for your valuable help.
Best regards
Gabriel


El mar., 29 de sep. de 2020 a la(s) 07:46, Amos Jeffries (
squid3 at treenet.co.nz) escribi?:

> On 29/09/20 3:55 am, Service MV wrote:
> > In my case I have the domains, for example from webex, which I get from
> > their official support page. It seems that I am doing something wrong or
> > I am not understanding well.
> > I base on this documentation
> > https://wiki.squid-cache.org/ConfigExamples/Authenticate/Bypass
> >
> > The error I get is 407. I understand I should not request authentication
> > to those domains with the configuration I have, but apparently it does.
> >
>
> In the (possibly outdated now) config you showed earlier the
> "NO_INTERNET" ACL might produce a 407 if credentials are completely
> missing, but not re-auth if they are invalid.
>  If you wish to have a free audit please post your current squid.conf
> rules and I will comment on useful changes.
>
>
> > Below I have a bandwidth control configuration with acl note, I don't
> > know if that will be triggering the webex client authentication request.
> > Maybe someone with more experience can tell me.
>
> "note" ACL will match if the data is available but not trigger
> authentication sequences. That is what makes it so useful for fast-group
> access checking logins.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200929/b9125744/attachment.htm>

From rentorbuy at yahoo.com  Tue Sep 29 22:03:33 2020
From: rentorbuy at yahoo.com (Vieri)
Date: Tue, 29 Sep 2020 22:03:33 +0000 (UTC)
Subject: [squid-users] ACL matches when it shouldn't
References: <1105910057.70354.1601417013244.ref@mail.yahoo.com>
Message-ID: <1105910057.70354.1601417013244@mail.yahoo.com>

> None of the file entries are anchored regex. So any one of them could match.

>> Can anyone please let me know if there's a match, or how to enable debugging? to see which record in this ACL is actually triggering the denial?
>
> To do that we will need to see the complete and exact URL which is being blocked incorrectly.

One of them is https://www.google.com/.

> NP: a large number of that files entries can be far more efficiently blocked using the dstdomain ACL type. For example:
>
>? acl blacklist dstdomain .appspot.com

Agreed. However, this file is generated by an external process I don't control (SOC). It's like a "threat feed" I need to load in Squid.
The easiest way for me would be to tell Squid that it's just a list of exact URLs, not a list of regexps. I understand that's not possible.

This list comes with entries such as:

https://domain.org/?something={whatever}&other=(this)

So, if I don't want Squid to complain I process it a little before serving it to it and the above line becomes:

https://domain.org/\?something=\{whatever}&other=\(this)

You mention anchoring them... So now I adjusted the processing and the above becomes:

^https://domain.org/\?something=\{whatever}&other=\(this)$

I'm still getting the same denial when a client tries to access https://www.google.com/.

This is what I can see in cache.log:

client_side_request.cc(751) clientAccessCheckDone: The request GET https://www.google.com/ is DENIED; last ACL checked: bad_dst_urls

I'm also seeing other denials such as:

?client_side_request.cc(751) clientAccessCheckDone: The request GET http://www.microsoft.com/pki/certs/MicRooCerAut2011_2011_03_22.crt is DENIED; last ACL checked: bad_dst_urls

If I grep http://www.microsoft.com/pki/certs in the ACL file I get no results at all.
That's why I'm puzzled.

So here's the new anchored regex file in case you have the chance to test it and reproduce the issue:

https://drive.google.com/file/d/1ZUP9eRAqLzMG162xHfYRV9vx_47kWuXs/view?usp=sharing

Squid doesn't complain about syntax errors so I'm assuming the ACL is as expected.

Thanks,

Vieri


From service.mv at gmail.com  Tue Sep 29 22:06:57 2020
From: service.mv at gmail.com (Service MV)
Date: Tue, 29 Sep 2020 19:06:57 -0300
Subject: [squid-users] measuring latency of squid in different scenarios
In-Reply-To: <CAPnyBTPt+3WyVpk25UQ_1v3Jk2bjMv9tdtNESwSQ3a+Q32beOg@mail.gmail.com>
References: <CAPnyBTPt+3WyVpk25UQ_1v3Jk2bjMv9tdtNESwSQ3a+Q32beOg@mail.gmail.com>
Message-ID: <CA+d==oGjm5BgsCgLV9Hxcaut+hxTxB=_DFG+aEPy=vAH_hvazg@mail.gmail.com>

Hi Rafal, if you wish I've a manual redacted in SPANISH for build a VM whit
Debian 10.5 running SQUID compiled from source, with kerberos and LDAP
authentication, plus AD groups authorizations.

I haven't had time to translate it into English yet.
Let me know if it works for you and I'll share it with you.

Best regards,
Gabriel




El lun., 28 sep. 2020 10:19, Rafa? Stanilewicz <rst at fomar.com.pl> escribi?:

> Hello,
>
> I'm planning the deployment of web proxy in my environment. It's not very
> big, around 80 typical windows 10 workstations, active directory, plus some
> DMZ servers. For now, there is very basic L7 inspection on the edge
> firewall.
>
> I plan to use two separate squid instances, one for explicit proxy
> traffic, forced by AD GPO settings, and second for traffic still being sent
> directly to the Internet (as several applications we use tend to ignore the
> system proxy settings). The first instance will use (hopefully) AD
> authentication, while the second will use only srcIP-based rules. I will be
> grateful for any comments, what should I focus on, or some quirks - I've
> never deployed squid from scratch.
>
> But my main point of writing is:
>
> I'd like to get some numbers about squid-introduced latency of getting
> some particular web resource. Is there any benchmarking program I could
> use? I'd like to see what is the current latency of getting the resource
> without any proxying, then of getting the same resource with explicit proxy
> settings, then of implicit (intercepting) proxy option, as well as for
> different options of caching.
>
> How should I start? Is there any software I can use to measure that,
> besides analysis of HAR files?
>
> So far, I used squid only in home environment, and without a need for
> granular measurement.
>
> Best regards,
>
> Rafal Stanilewicz
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200929/dc6aba25/attachment.htm>

From Ralf.Hildebrandt at charite.de  Wed Sep 30 09:29:16 2020
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Wed, 30 Sep 2020 11:29:16 +0200
Subject: [squid-users] Odd log entries
Message-ID: <20200930092916.mcuh74xwslngnte6@charite.de>

I got quite a lot of those, dunno if they are from 5.0.2 oder 6.HEAD,
though (mixed log):

1601367473.708      0 172.29.138.187 TCP_DENIED/403 3900 CONNECT:35415 - HIER_NONE/- text/html accessRule=notsslports -
1601368555.365      2 172.29.130.245 TCP_DENIED/403 3839 CONNECT:31481 - HIER_NONE/- text/html accessRule=notsslports -
1601383160.341    435 10.47.52.135 TCP_DENIED/403 4057 CONNECT:5001 - HIER_NONE/- text/html accessRule=notsslports -

CONNECT, yes, but why is the host missing?

Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From service.mv at gmail.com  Wed Sep 30 13:22:51 2020
From: service.mv at gmail.com (Service MV)
Date: Wed, 30 Sep 2020 10:22:51 -0300
Subject: [squid-users] measuring latency of squid in different scenarios
In-Reply-To: <CAPnyBTPNOp9UC3iCpzRWCyHYf4qFgW1GFbVpOuHd-T6wQCqPhw@mail.gmail.com>
References: <CAPnyBTPt+3WyVpk25UQ_1v3Jk2bjMv9tdtNESwSQ3a+Q32beOg@mail.gmail.com>
 <CA+d==oGjm5BgsCgLV9Hxcaut+hxTxB=_DFG+aEPy=vAH_hvazg@mail.gmail.com>
 <CAPnyBTPNOp9UC3iCpzRWCyHYf4qFgW1GFbVpOuHd-T6wQCqPhw@mail.gmail.com>
Message-ID: <CA+d==oFHUEnaLOWyCFCpxVYHvPzmHp2+G9KfTkJasF-UF+Upfg@mail.gmail.com>

Below I leave the link. I think that with this you could achieve your goal.
In this project there are more things that you might not want to use or
maybe you do. To begin I believe that it is well.


   - High availability load balancing frontend between users and backend
   proxy nodes.
   - VIP (floating IP) for the load balancers.
   - Automatic configuration script for internal routing.
   - Proxy pool with integrated Kerberos and LDAP authentication in Active
   Directory
   - Domain, IP, and port filtering
   - Active Directory group browsing permissions
   - Navigation reports by cost centers and/or individual users
   - Bandwidth usage control per user.

https://drive.google.com/file/d/1L3HiYs0LXaDZJOEHXVz8WrRFeJXXUBzU/view?usp=sharing

Any question you may have, please reply with a copy to SQUID's mailing list
in order to share with the community of users information that they may
find useful.

Best regards,
Gabriel

El mi?., 30 de sep. de 2020 a la(s) 05:12, Rafa? Stanilewicz (
rst at fomar.com.pl) escribi?:

> Hi Gabriel,
>
> although I do not know Spanish, a few of my friends do. Also, the most
> important pieces will be code samples, which do not need translation. So if
> you would be so kind and share the manual with me, I'd appreciate it very
> much!
>
> Rafal
>
> On Tue, 29 Sep 2020 at 23:07, Service MV <service.mv at gmail.com> wrote:
>
>> Hi Rafal, if you wish I've a manual redacted in SPANISH for build a VM
>> whit Debian 10.5 running SQUID compiled from source, with kerberos and LDAP
>> authentication, plus AD groups authorizations.
>>
>> I haven't had time to translate it into English yet.
>> Let me know if it works for you and I'll share it with you.
>>
>> Best regards,
>> Gabriel
>>
>>
>>
>>
>> El lun., 28 sep. 2020 10:19, Rafa? Stanilewicz <rst at fomar.com.pl>
>> escribi?:
>>
>>> Hello,
>>>
>>> I'm planning the deployment of web proxy in my environment. It's not
>>> very big, around 80 typical windows 10 workstations, active directory, plus
>>> some DMZ servers. For now, there is very basic L7 inspection on the edge
>>> firewall.
>>>
>>> I plan to use two separate squid instances, one for explicit proxy
>>> traffic, forced by AD GPO settings, and second for traffic still being sent
>>> directly to the Internet (as several applications we use tend to ignore the
>>> system proxy settings). The first instance will use (hopefully) AD
>>> authentication, while the second will use only srcIP-based rules. I will be
>>> grateful for any comments, what should I focus on, or some quirks - I've
>>> never deployed squid from scratch.
>>>
>>> But my main point of writing is:
>>>
>>> I'd like to get some numbers about squid-introduced latency of getting
>>> some particular web resource. Is there any benchmarking program I could
>>> use? I'd like to see what is the current latency of getting the resource
>>> without any proxying, then of getting the same resource with explicit proxy
>>> settings, then of implicit (intercepting) proxy option, as well as for
>>> different options of caching.
>>>
>>> How should I start? Is there any software I can use to measure that,
>>> besides analysis of HAR files?
>>>
>>> So far, I used squid only in home environment, and without a need for
>>> granular measurement.
>>>
>>> Best regards,
>>>
>>> Rafal Stanilewicz
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>
>
> --
> Zanim wydrukujesz, pomy?l o ?rodowisku.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200930/08fffc37/attachment.htm>

From rousskov at measurement-factory.com  Wed Sep 30 13:42:21 2020
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 30 Sep 2020 09:42:21 -0400
Subject: [squid-users] Odd log entries
In-Reply-To: <20200930092916.mcuh74xwslngnte6@charite.de>
References: <20200930092916.mcuh74xwslngnte6@charite.de>
Message-ID: <45b3c2c2-ae04-dcb7-e8e9-69d1744d8253@measurement-factory.com>

On 9/30/20 5:29 AM, Ralf Hildebrandt wrote:
> I got quite a lot of those, dunno if they are from 5.0.2 oder 6.HEAD,
> though (mixed log):

> 1601367473.708      0 172.29.138.187 TCP_DENIED/403 3900 CONNECT:35415 - HIER_NONE/- text/html accessRule=notsslports -
> 1601368555.365      2 172.29.130.245 TCP_DENIED/403 3839 CONNECT:31481 - HIER_NONE/- text/html accessRule=notsslports -
> 1601383160.341    435 10.47.52.135 TCP_DENIED/403 4057 CONNECT:5001 - HIER_NONE/- text/html accessRule=notsslports -

> CONNECT, yes, but why is the host missing?

I am even more concerned about the lack of a space character after
"CONNECT". What is your custom logformat definition?

If the problem applies to all denied transactions, then you can probably
tell whether this is v5 or master/v6 problem by sending a manual
to-be-denied request to one or both of the Squid instances in question
and looking for your client address/timestamp in the access log.
Long-term, if you are going to continue mixing access records from
different Squid instances, then I would recommend adding a instance (and
worker) IDs to each access log record.

FWIW, I cannot reproduce this problem using a maser/v6-based branch with
default logformat and CONNECT requests to banned ports, but perhaps the
problem is specific to some CONNECT transactions or some listening port
configurations.


Cheers,

Alex.


From service.mv at gmail.com  Wed Sep 30 14:03:20 2020
From: service.mv at gmail.com (Service MV)
Date: Wed, 30 Sep 2020 11:03:20 -0300
Subject: [squid-users] measuring latency of squid in different scenarios
In-Reply-To: <vmime.5f748ca7.bc5.1bedae91115fb197@ms249-lin-003.rotterdam.bazuin.nl>
References: <CAPnyBTPNOp9UC3iCpzRWCyHYf4qFgW1GFbVpOuHd-T6wQCqPhw@mail.gmail.com>
 <CA+d==oFHUEnaLOWyCFCpxVYHvPzmHp2+G9KfTkJasF-UF+Upfg@mail.gmail.com>
 <vmime.5f748ca7.bc5.1bedae91115fb197@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <CA+d==oEYrEk94wy7gAJevVtfYKzoi-evzRtpU2fTugtjkaGL4w@mail.gmail.com>

Thanks Louis!
I'll be waiting for your configuration.

Along with this I believe that the spirit of the open-source community is
to share. So I hope the information can be useful to the community
(especially in this case to spanish speakers haha ;))

Best regards,
Gabriel

El mi?., 30 sep. 2020 10:48, L.P.H. van Belle <belle at bazuin.nl> escribi?:

> Hai Gabriel,
>
> Only one thing i dont like... Spanish? Portugees? ..  ;-) but google
> translater is my friend.
>
> But this looks great, very nice..  !!!
>
> I have a simular setup here, but i have only samba running, 0 windows
> servers.
> I've seen same parts to simplify this a bit and when im done with that,
> i'l make the english "debianized" version of this..
> Its a nice addition for my (Work in progress) automated Small bussiness
> setup on linux.
>
> When im done, i'll send you/the list a copy of the debianized and english
> version..
>
> Big thanks for sharing this !
>
>
> Greetz,
> Louis
>
>
> ------------------------------
> *Van:* squid-users [mailto:squid-users-bounces at lists.squid-cache.org] *Namens
> *Service MV
> *Verzonden:* woensdag 30 september 2020 15:23
> *Aan:* Rafa?? Stanilewicz; Squid Users
> *Onderwerp:* Re: [squid-users] measuring latency of squid in different
> scenarios
>
> Below I leave the link. I think that with this you could achieve your
> goal. In this project there are more things that you might not want to use
> or maybe you do. To begin I believe that it is well.
>
>
>    - High availability load balancing frontend between users and backend
>    proxy nodes.
>    - VIP (floating IP) for the load balancers.
>    - Automatic configuration script for internal routing.
>    - Proxy pool with integrated Kerberos and LDAP authentication in
>    Active Directory
>    - Domain, IP, and port filtering
>    - Active Directory group browsing permissions
>    - Navigation reports by cost centers and/or individual users
>    - Bandwidth usage control per user.
>
>
> https://drive.google.com/file/d/1L3HiYs0LXaDZJOEHXVz8WrRFeJXXUBzU/view?usp=sharing
>
> Any question you may have, please reply with a copy to SQUID's mailing
> list in order to share with the community of users information that they
> may find useful.
>
> Best regards,
> Gabriel
>
> El mi?., 30 de sep. de 2020 a la(s) 05:12, Rafa? Stanilewicz (
> rst at fomar.com.pl) escribi?:
>
>> Hi Gabriel,
>>
>> although I do not know Spanish, a few of my friends do. Also, the most
>> important pieces will be code samples, which do not need translation. So if
>> you would be so kind and share the manual with me, I'd appreciate it very
>> much!
>>
>> Rafal
>>
>> On Tue, 29 Sep 2020 at 23:07, Service MV <service.mv at gmail.com> wrote:
>>
>>> Hi Rafal, if you wish I've a manual redacted in SPANISH for build a VM
>>> whit Debian 10.5 running SQUID compiled from source, with kerberos and LDAP
>>> authentication, plus AD groups authorizations.
>>>
>>> I haven't had time to translate it into English yet.
>>> Let me know if it works for you and I'll share it with you.
>>>
>>> Best regards,
>>> Gabriel
>>>
>>>
>>>
>>>
>>> El lun., 28 sep. 2020 10:19, Rafa? Stanilewicz <rst at fomar.com.pl>
>>> escribi?:
>>>
>>>> Hello,
>>>>
>>>> I'm planning the deployment of web proxy in my environment. It's not
>>>> very big, around 80 typical windows 10 workstations, active directory, plus
>>>> some DMZ servers. For now, there is very basic L7 inspection on the edge
>>>> firewall.
>>>>
>>>> I plan to use two separate squid instances, one for explicit proxy
>>>> traffic, forced by AD GPO settings, and second for traffic still being sent
>>>> directly to the Internet (as several applications we use tend to ignore the
>>>> system proxy settings). The first instance will use (hopefully) AD
>>>> authentication, while the second will use only srcIP-based rules. I will be
>>>> grateful for any comments, what should I focus on, or some quirks - I've
>>>> never deployed squid from scratch.
>>>>
>>>> But my main point of writing is:
>>>>
>>>> I'd like to get some numbers about squid-introduced latency of getting
>>>> some particular web resource. Is there any benchmarking program I could
>>>> use? I'd like to see what is the current latency of getting the resource
>>>> without any proxying, then of getting the same resource with explicit proxy
>>>> settings, then of implicit (intercepting) proxy option, as well as for
>>>> different options of caching.
>>>>
>>>> How should I start? Is there any software I can use to measure that,
>>>> besides analysis of HAR files?
>>>>
>>>> So far, I used squid only in home environment, and without a need for
>>>> granular measurement.
>>>>
>>>> Best regards,
>>>>
>>>> Rafal Stanilewicz
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>
>>
>> --
>> Zanim wydrukujesz, pomy?l o ?rodowisku.
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20200930/d607750a/attachment.htm>

From m_zouhairy at skno.by  Wed Sep  2 07:46:28 2020
From: m_zouhairy at skno.by (Vacheslav)
Date: Wed, 02 Sep 2020 07:46:28 -0000
Subject: [squid-users] limit bandwidth
In-Reply-To: <a81d28a8d0d2bccbb166af270f1b3315991f21ab.camel@skno.by>
References: <3d7ba9d6-aacb-8907-3440-31c1bd709615@skno.by>
 <7e727b46-dace-eb5f-17ec-dfa705c77ff8@treenet.co.nz>
 <a81d28a8d0d2bccbb166af270f1b3315991f21ab.camel@skno.by>
Message-ID: <6ef4a280-55f4-5fb0-52d2-2c71bcf3ce6b@skno.by>

Well now it works only on http downloads.. thanks mais the problem is 
that most downloads are now through https




From m_zouhairy at skno.by  Fri Sep  4 03:47:45 2020
From: m_zouhairy at skno.by (vacheslav)
Date: Fri, 04 Sep 2020 03:47:45 -0000
Subject: [squid-users] limit bandwidth
In-Reply-To: <a52f4e34-1681-2288-b40c-bb5f8d3dde7c@treenet.co.nz>
References: <3d7ba9d6-aacb-8907-3440-31c1bd709615@skno.by>
 <7e727b46-dace-eb5f-17ec-dfa705c77ff8@treenet.co.nz>
 <a81d28a8d0d2bccbb166af270f1b3315991f21ab.camel@skno.by>
 <a52f4e34-1681-2288-b40c-bb5f8d3dde7c@treenet.co.nz>
Message-ID: <74cae663-e7ad-6059-1c22-3e27d59275be@skno.by>


2.09.20 18:23, Amos Jeffries ?????:
> On 1/09/20 7:50 pm, Majed Zouhairy wrote:
>> On Tue, 2020-09-01 at 05:10 +1200, Amos Jeffries wrote:
>>> On 31/08/20 8:24 pm, Vacheslav wrote:
>>>> Peace,
>>>>
>>>> been suffering for many hours so i'd rather ask for aid..
>>>>
>>>> i'm trying to limit the flow mainly for the most maximize people
>>>>
>>> Okay.
>>>
>>> What Squid version are you using?
>>>
>>>
>> sudo squid -v
>> Squid Cache: Version 4.13
>> Service Name: squid
>>
>>>> acl slower src 10.46.0.74 10.46.0.107
>>> One of the reasons this posting git held up for moderation was that
>>> the
>>> lines which are supposed to contain ASCII tab characters contained
>>> Unicode characters "\c3\82".
>> this is now another email client..so let's confirm that
>>> If those Unicode characters are actually present in your squid.conf
>>> file
>>> then you need to go through and remove them all.
>> i went ahead and typed those added lines in nano and deleted the
>> original ones..still not a trump!
>>> ...
>>>> acl localnet src 10.46.0.0/24		#  local private
>>>> network (LAN)
>>> ...
>>>> acl blockfiles urlpath_regex -i "/etc/squid/blocks.files.acl"
>>>>
>>> ...
>>>
>>>> error_directory /usr/share/squid/errors/en
>>> The above is a default value. Remove that line from your config.
>> this? error_directory /usr/share/squid/errors/en
> Yes, that one.
so it's not the email client even
>
>>>> delay_pools 1
>>>> delay_class 1 3
>>>> delay_access 1 allow slower !localnet
>>> All IPs which match "slower" ACL are also matched by "localnet" ACL.
>>>
>>> It is impossible for an IP to be both part of slower and not part of
>>> localnet. So this line never matches and all traffic is not-delayed.
>>>
>>> To fix, remove the "!localnet" requirement from the above line.
>> i already tried that, i was thinking that there would be an option like
>> acl slower src 10.46.0.74 10.46.0.107
>> acl localnet src !10.46.0.74 10.46.0.0/24
>> so as not type the whole subnet individual addresses
>>
> It is possible to define an ACL like localnet with holes. But that would
> not do what you are wanting.
still that would be very nice to know
>
>
> "delay_access 1 allow slower"  does what you are asking for in terms of
> only the IPs listed in "slower" having their traffic slowed down.
>
> If that is not working, then you may be hitting a bug or something is
> different from what you have told us about the traffic. eg CONNECT
> tunnels do not always have delay pools applied in Squid-4.
>
>
> Amos

it's only working on http downloads,

might it have any relationship with ufdbguard is being used?

the rest of the config

delay_pools 1
delay_class 1 3
delay_access 1 allow slower
delay_access 1 deny all
delay_parameters 1 51200/51200 -1/-1 51200/25600

http_access allow localnet
http_access allow localhost



# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 8080

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/cache/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid

cache_mem 512 MB

netdb_filename none

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:??? ??? 1440??? 20%??? 10080
refresh_pattern ^gopher:??? 1440??? 0%??? 1440
refresh_pattern -i (/cgi-bin/|\?) 0??? 0%??? 0
refresh_pattern .??? ??? 0??? 20%??? 4320

url_rewrite_program /usr/local/ufdbguard/bin/ufdbgclient -m 4 -l 
/var/log/squid/
url_rewrite_children 16 startup=8 idle=2 concurrency=4
#debug_options ALL,1 33,2 28,9

> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



