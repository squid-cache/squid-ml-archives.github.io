From moberger at metanetworks.com  Sun Jul  4 12:44:56 2021
From: moberger at metanetworks.com (Moti Berger)
Date: Sun, 4 Jul 2021 15:44:56 +0300
Subject: [squid-users] Refrain from Cache Manager API requests to reach ICAPs
Message-ID: <CAGSk-42bGKbkD-1q42V8UrmG+W+yhnN9oAWk8GmGw3Kck6AQKg@mail.gmail.com>

Hi

I established an environment with Squid and Datadog.
It periodically calls the endpoint:

/squid-internal-mgr/counters
>

Those requests are also sent to the ICAPs.
Is there a way to make Squid not to pass those requests to the ICAPs?

Thanks,
Moti
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210704/6723c1db/attachment.htm>

From rousskov at measurement-factory.com  Sun Jul  4 16:42:32 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 4 Jul 2021 12:42:32 -0400
Subject: [squid-users] Refrain from Cache Manager API requests to reach
 ICAPs
In-Reply-To: <CAGSk-42bGKbkD-1q42V8UrmG+W+yhnN9oAWk8GmGw3Kck6AQKg@mail.gmail.com>
References: <CAGSk-42bGKbkD-1q42V8UrmG+W+yhnN9oAWk8GmGw3Kck6AQKg@mail.gmail.com>
Message-ID: <6f3d3593-3b4e-17ab-754a-adac995e6a90@measurement-factory.com>

On 7/4/21 8:44 AM, Moti Berger wrote:

> I established?an environment with Squid and Datadog.
> It periodically calls the endpoint:
> 
>     /squid-internal-mgr/counters
> 
> 
> Those requests are also sent to the ICAPs.
> Is there a way to make Squid not to pass those requests to the ICAPs?

Yes, see the adaptation_access directive. Depending on how these cache
manager requests are accepted/authenticated/etc., you may use
urlpath_regex or other ACLs to identify them.


HTH,

Alex.


From squid3 at treenet.co.nz  Mon Jul  5 01:48:17 2021
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Mon, 05 Jul 2021 13:48:17 +1200
Subject: [squid-users] Refrain from Cache Manager API requests to reach
 ICAPs
In-Reply-To: <6f3d3593-3b4e-17ab-754a-adac995e6a90@measurement-factory.com>
References: <CAGSk-42bGKbkD-1q42V8UrmG+W+yhnN9oAWk8GmGw3Kck6AQKg@mail.gmail.com>
 <6f3d3593-3b4e-17ab-754a-adac995e6a90@measurement-factory.com>
Message-ID: <fb21e1f2c8482f011c5ba303931b2a18@treenet.co.nz>

On 2021-07-05 04:42, Alex Rousskov wrote:
> On 7/4/21 8:44 AM, Moti Berger wrote:
> 
>> I established?an environment with Squid and Datadog.
>> It periodically calls the endpoint:
>> 
>>     /squid-internal-mgr/counters
>> 
>> 
>> Those requests are also sent to the ICAPs.
>> Is there a way to make Squid not to pass those requests to the ICAPs?
> 
> Yes, see the adaptation_access directive. Depending on how these cache
> manager requests are accepted/authenticated/etc., you may use
> urlpath_regex or other ACLs to identify them.

Use the built-in "manager" ACL in current Squid versions.

Amos


From ben.goz87 at gmail.com  Mon Jul  5 11:31:09 2021
From: ben.goz87 at gmail.com (Ben Goz)
Date: Mon, 5 Jul 2021 14:31:09 +0300
Subject: [squid-users] TPROXY Error
In-Reply-To: <b75f828b-c3da-8eef-b882-7b0b16fa6f6d@gmail.com>
References: <CADAqQfwR4w-cFidq+8ea7zns=OUwyan6W1wXuLcrge4jSE4B9Q@mail.gmail.com>
 <202106301425.24180.Antony.Stone@squid.open.source.it>
 <b75f828b-c3da-8eef-b882-7b0b16fa6f6d@gmail.com>
Message-ID: <9384bb48-9403-4a7a-e6c7-b42c34efc504@gmail.com>

By the help of God.

Someone have an idea what's wrong with my configuration?

On 30/06/2021 15:55, Ben Goz wrote:
>
> On 30/06/2021 15:25, Antony Stone wrote:
>> On Wednesday 30 June 2021 at 14:16:09, Ben Goz wrote:
>>
>>> I'm trying to configure squid as a transparent proxy using TPROXY.
>>> The machine I'm using has 2 NICs, one for input and the other one for
>>> output traffic.
>>> The TPROXY iptables rules are configured on the input NIC.
>> 1. Which version of Squid are you using?
> # ./squid -v
> Squid Cache: Version 4.15
> Service Name: squid
>
> This binary uses OpenSSL 1.1.1f? 31 Mar 2020. For legal restrictions 
> on distribution see https://www.openssl.org/source/license.html
>
> configure options:? '--with-openssl' '--enable-ssl-crtd' 
> '--enable-ecap' '--enable-linux-netfilter' --enable-ltdl-convenience
>
>>
>> 2. Please show us the TPROXY rules you have.
>
>
> iptables -t mangle -N DIVERT
> iptables -t mangle -A PREROUTING -p tcp -m socket -j DIVERT
> iptables -t mangle -A DIVERT -j MARK --set-mark 1
> iptables -t mangle -A DIVERT -j ACCEPT
>
> iptables -t mangle -A PREROUTING -i bond0.213 -p tcp --dport 80 -j 
> TPROXY --tproxy-mark 0x1/0x1 --on-port 15644
> iptables -t mangle -A PREROUTING -i bond0.213 -p tcp --dport 443 -j 
> TPROXY --tproxy-mark 0x1/0x1 --on-port 15645
>
>
> including:
>
> ip rule add fwmark 1 lookup 100
> ip -f inet route add local default dev lo table 100
>
>>
>> 3. Please show us the relevant lines for intercept proxying from your
>> squid.conf
>
>
> http_port 15644 tproxy
> https_port 15645 ssl-bump tproxy generate-host-certificates=on 
> options=ALL dynamic_cert_mem_cache_size=4MB 
> cert=/usr/local/squid/etc/ssl_cert/myCA.pem 
> dhparams=/usr/local/squid/etc/dhparam.pem
> always_direct allow all
>
>
>
>>
>>
>> Regards,
>>
>>
>> Antony.
>>


From jason.spashett at menlosecurity.com  Mon Jul  5 15:19:30 2021
From: jason.spashett at menlosecurity.com (Jason Spashett)
Date: Mon, 5 Jul 2021 16:19:30 +0100
Subject: [squid-users] SNMP mib data a subset of that available via cache://
 ?
Message-ID: <CANj0NTop=HYx1RRc0+r-nrXC-EsjDDARkLpys=OyLbOBPkRW4w@mail.gmail.com>

Hello,

I saw some anecdotal information on the web that said the SNMP data
available from squid was a restricted subset of that available via the
cache-manager interface. Is this still largely the case? Looking to
use squid4, and 5, shortly.

Regards,
Jason


From rousskov at measurement-factory.com  Mon Jul  5 16:02:36 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 5 Jul 2021 12:02:36 -0400
Subject: [squid-users] SNMP mib data a subset of that available via
 cache:// ?
In-Reply-To: <CANj0NTop=HYx1RRc0+r-nrXC-EsjDDARkLpys=OyLbOBPkRW4w@mail.gmail.com>
References: <CANj0NTop=HYx1RRc0+r-nrXC-EsjDDARkLpys=OyLbOBPkRW4w@mail.gmail.com>
Message-ID: <786e0fa1-5afc-37c6-86a8-ae0a465ad933@measurement-factory.com>

On 7/5/21 11:19 AM, Jason Spashett wrote:

> I saw some anecdotal information on the web that said the SNMP data
> available from squid was a restricted subset of that available via the
> cache-manager interface. Is this still largely the case? Looking to
> use squid4, and 5, shortly.

Yes, it is. Unlike the cache manager, SNMP is one of the neglected areas
that receives very few updates.

Alex.


From jason.spashett at menlosecurity.com  Mon Jul  5 17:51:39 2021
From: jason.spashett at menlosecurity.com (Jason Spashett)
Date: Mon, 5 Jul 2021 18:51:39 +0100
Subject: [squid-users] SNMP mib data a subset of that available via
 cache:// ?
In-Reply-To: <786e0fa1-5afc-37c6-86a8-ae0a465ad933@measurement-factory.com>
References: <CANj0NTop=HYx1RRc0+r-nrXC-EsjDDARkLpys=OyLbOBPkRW4w@mail.gmail.com>
 <786e0fa1-5afc-37c6-86a8-ae0a465ad933@measurement-factory.com>
Message-ID: <CANj0NTpXJ7n8LxE58qLfy7jKHLp2+QKg6sXNsTSeCR0u7JwPsA@mail.gmail.com>

On Mon, 5 Jul 2021 at 17:02, Alex Rousskov
<rousskov at measurement-factory.com> wrote:
>
> On 7/5/21 11:19 AM, Jason Spashett wrote:
>
> > I saw some anecdotal information on the web that said the SNMP data
> > available from squid was a restricted subset of that available via the
> > cache-manager interface. Is this still largely the case? Looking to
> > use squid4, and 5, shortly.
>
> Yes, it is. Unlike the cache manager, SNMP is one of the neglected areas
> that receives very few updates.
>
> Alex.
> _______________________________________________

Thanks Alex,

The cachemgr output is in text form only as far as I can see, and a
little inconsistently formatted. I can imagine that users do sometimes
want to import this data into their monitoring tool of choice. Is
there or has there been any discussion on a direction for providing
this sort of thing for users? Presumably demand for the SNMP interface
is low in the user base.

Jason.


From rousskov at measurement-factory.com  Mon Jul  5 20:09:32 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 5 Jul 2021 16:09:32 -0400
Subject: [squid-users] SNMP mib data a subset of that available via
 cache:// ?
In-Reply-To: <CANj0NTpXJ7n8LxE58qLfy7jKHLp2+QKg6sXNsTSeCR0u7JwPsA@mail.gmail.com>
References: <CANj0NTop=HYx1RRc0+r-nrXC-EsjDDARkLpys=OyLbOBPkRW4w@mail.gmail.com>
 <786e0fa1-5afc-37c6-86a8-ae0a465ad933@measurement-factory.com>
 <CANj0NTpXJ7n8LxE58qLfy7jKHLp2+QKg6sXNsTSeCR0u7JwPsA@mail.gmail.com>
Message-ID: <4f3f2125-b1c5-2276-f61b-c03104cb8dfc@measurement-factory.com>

On 7/5/21 1:51 PM, Jason Spashett wrote:
> On Mon, 5 Jul 2021 at 17:02, Alex Rousskov wrote:
>>
>> On 7/5/21 11:19 AM, Jason Spashett wrote:
>>
>>> I saw some anecdotal information on the web that said the SNMP data
>>> available from squid was a restricted subset of that available via the
>>> cache-manager interface. Is this still largely the case? Looking to
>>> use squid4, and 5, shortly.

>> Yes, it is. Unlike the cache manager, SNMP is one of the neglected areas
>> that receives very few updates.

> The cachemgr output is in text form only as far as I can see, and a
> little inconsistently formatted. I can imagine that users do sometimes
> want to import this data into their monitoring tool of choice. 

Yes, of course. Nearly all serious Squid deployments should
automatically archive and process some of the cache manager reports.


> Is there or has there been any discussion on a direction for providing
> this sort of thing for users?

Yes, there were several lengthy (but reasonably fruitful) discussions on
squid-dev and even a couple of failed initial implementation attempts
predating (and triggering) those necessary discussions.

I believe the long-term goal is a YAML-compliant output with a
stable/published basic structure that would be easy to consume using
modern tools. Properly migrating to that kind of output requires a lot
of basic low-level development work based on serious internal API
changes that I have been unable to find enough free time to implement.

Alex.


From squid3 at treenet.co.nz  Tue Jul  6 07:00:12 2021
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Jul 2021 19:00:12 +1200
Subject: [squid-users] UDP support for squid
In-Reply-To: <CAGU_Ci+LArs4jKGZtVP1eoVmsum3kLh9-KNZXgt1o=RzYNmNiw@mail.gmail.com>
References: <CAGU_Ci+LArs4jKGZtVP1eoVmsum3kLh9-KNZXgt1o=RzYNmNiw@mail.gmail.com>
Message-ID: <ea501134-b5f8-c506-f677-f5d6174e4cc3@treenet.co.nz>

On 23/06/21 9:06 pm, robert k Wild wrote:
> hi all,
> 
> after reading this guide, is this for enabling squid for SOCKSv5 ie UDP -
> 

Well, yes and no.

That is the guide for enabling SOCKS support. But for SOCKS/TCP 
connections, not UDP.


> https://wiki.squid-cache.org/Features/Socks 
> 
> export CFLAGS=" -Dbind=SOCKSbind "
> export CXXFLAGS=" -Dbind=SOCKSbind "
> export LDADD=" -lsocks "
> 
> 
> when building squid from source, do i append it at the end of the 
> "configure options"
> 

You can either run the "export ..." commands before running ./configure 
or put them as KEY="value" parameters on its command line.

Either;

   export CFLAGS=" -Dbind=SOCKSbind "
   export CXXFLAGS=" -Dbind=SOCKSbind "
   export LDADD=" -lsocks "
   ./configure

or,

  ./configure \
	CFLAGS=" -Dbind=SOCKSbind " \
	CXXFLAGS=" -Dbind=SOCKSbind " \
	LDADD=" -lsocks "


Amos


From squid3 at treenet.co.nz  Tue Jul  6 07:09:55 2021
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Jul 2021 19:09:55 +1200
Subject: [squid-users] TPROXY Error
In-Reply-To: <9384bb48-9403-4a7a-e6c7-b42c34efc504@gmail.com>
References: <CADAqQfwR4w-cFidq+8ea7zns=OUwyan6W1wXuLcrge4jSE4B9Q@mail.gmail.com>
 <202106301425.24180.Antony.Stone@squid.open.source.it>
 <b75f828b-c3da-8eef-b882-7b0b16fa6f6d@gmail.com>
 <9384bb48-9403-4a7a-e6c7-b42c34efc504@gmail.com>
Message-ID: <3cf47bfd-99d7-6fb0-4253-208122b83f6c@treenet.co.nz>

On 5/07/21 11:31 pm, Ben Goz wrote:
> By the help of God.
> 
> Someone have an idea what's wrong with my configuration?
> 

The config you have shown does not contain any visible issues.

The feature page has information minimum kernel and library requirements 
for TPROXY to work reasonably well. There are also sections on other 
things to check for in regards to routing table behaviours in various 
kernels, and system security policies (eg SELinux, Apport, systemd)
   <https://wiki.squid-cache.org/Features/Tproxy4>

Amos


From squid3 at treenet.co.nz  Tue Jul  6 07:23:15 2021
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Jul 2021 19:23:15 +1200
Subject: [squid-users] How to use request headers in external_acl_type
In-Reply-To: <7416EB54B03743A4B7B8AFDB52229FDC@OhrSomayach>
References: <F8D8224A429A46F1BD90923F85A56C66@OhrSomayach>
 <ef3618b8b036c03d7d208de91e2daf78@treenet.co.nz>
 <7416EB54B03743A4B7B8AFDB52229FDC@OhrSomayach>
Message-ID: <20291916-696d-f501-cb46-de53448c50b8@treenet.co.nz>

On 1/07/21 5:17 am, Yosi Greenfield wrote:
> Amos,
> 
> As always, thank you for your dedication answering all our questions.
> 
> Ok, turns out, as you noted, the browser is sending the correct request
> headers. However, on https requests the external acl program is not getting
> the custom header we're sending. SSL Bump is set, and works for our
> redirector program, but not for the external acl program.
> 
...>
> Is it possible to get the custom abc_session header on https requests?
> 

It *should* be, but until we know the problem is cause we don't really 
know for certain if it is fixable. Or how long/difficult that will be.

Amos


From robertkwild at gmail.com  Tue Jul  6 08:43:35 2021
From: robertkwild at gmail.com (robert k Wild)
Date: Tue, 6 Jul 2021 09:43:35 +0100
Subject: [squid-users] UDP support for squid
In-Reply-To: <ea501134-b5f8-c506-f677-f5d6174e4cc3@treenet.co.nz>
References: <CAGU_Ci+LArs4jKGZtVP1eoVmsum3kLh9-KNZXgt1o=RzYNmNiw@mail.gmail.com>
 <ea501134-b5f8-c506-f677-f5d6174e4cc3@treenet.co.nz>
Message-ID: <CAGU_Ci+Cj9s1Gba0GqYvq+pdAQ8gePnB1EkFd9nxKRLUC+O5Fg@mail.gmail.com>

Thanks Amos much appreciated

Is there a way of enabling socks udp at all or is this just not the case at
all with squid

Thanks,
Rob

On Tue, 6 Jul 2021, 08:02 Amos Jeffries, <squid3 at treenet.co.nz> wrote:

> On 23/06/21 9:06 pm, robert k Wild wrote:
> > hi all,
> >
> > after reading this guide, is this for enabling squid for SOCKSv5 ie UDP -
> >
>
> Well, yes and no.
>
> That is the guide for enabling SOCKS support. But for SOCKS/TCP
> connections, not UDP.
>
>
> > https://wiki.squid-cache.org/Features/Socks
> >
> > export CFLAGS=" -Dbind=SOCKSbind "
> > export CXXFLAGS=" -Dbind=SOCKSbind "
> > export LDADD=" -lsocks "
> >
> >
> > when building squid from source, do i append it at the end of the
> > "configure options"
> >
>
> You can either run the "export ..." commands before running ./configure
> or put them as KEY="value" parameters on its command line.
>
> Either;
>
>    export CFLAGS=" -Dbind=SOCKSbind "
>    export CXXFLAGS=" -Dbind=SOCKSbind "
>    export LDADD=" -lsocks "
>    ./configure
>
> or,
>
>   ./configure \
>         CFLAGS=" -Dbind=SOCKSbind " \
>         CXXFLAGS=" -Dbind=SOCKSbind " \
>         LDADD=" -lsocks "
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210706/2342e8fa/attachment.htm>

From squid3 at treenet.co.nz  Tue Jul  6 08:49:51 2021
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Jul 2021 20:49:51 +1200
Subject: [squid-users] UDP support for squid
In-Reply-To: <CAGU_Ci+Cj9s1Gba0GqYvq+pdAQ8gePnB1EkFd9nxKRLUC+O5Fg@mail.gmail.com>
References: <CAGU_Ci+LArs4jKGZtVP1eoVmsum3kLh9-KNZXgt1o=RzYNmNiw@mail.gmail.com>
 <ea501134-b5f8-c506-f677-f5d6174e4cc3@treenet.co.nz>
 <CAGU_Ci+Cj9s1Gba0GqYvq+pdAQ8gePnB1EkFd9nxKRLUC+O5Fg@mail.gmail.com>
Message-ID: <9c204ace-72f9-37c5-5692-c0680713a378@treenet.co.nz>

On 6/07/21 8:43 pm, robert k Wild wrote:
> Thanks Amos much appreciated
> 
> Is there a way of enabling socks udp at all or is this just not the case 
> at all with squid
> 

Not until Squid is changed to support HTTP over UDP. That is coming with 
HTTP/3 but nowhere near an ETA on when it will be available.


Amos


From robertkwild at gmail.com  Tue Jul  6 08:55:55 2021
From: robertkwild at gmail.com (robert k Wild)
Date: Tue, 6 Jul 2021 09:55:55 +0100
Subject: [squid-users] UDP support for squid
In-Reply-To: <9c204ace-72f9-37c5-5692-c0680713a378@treenet.co.nz>
References: <CAGU_Ci+LArs4jKGZtVP1eoVmsum3kLh9-KNZXgt1o=RzYNmNiw@mail.gmail.com>
 <ea501134-b5f8-c506-f677-f5d6174e4cc3@treenet.co.nz>
 <CAGU_Ci+Cj9s1Gba0GqYvq+pdAQ8gePnB1EkFd9nxKRLUC+O5Fg@mail.gmail.com>
 <9c204ace-72f9-37c5-5692-c0680713a378@treenet.co.nz>
Message-ID: <CAGU_Ci+3SGrMLW6KCrNr=QxkcuDc9m8ZAKFzZBkzQ33stjqgkA@mail.gmail.com>

Thank you Amos, very much appreciated

On Tue, 6 Jul 2021, 09:51 Amos Jeffries, <squid3 at treenet.co.nz> wrote:

> On 6/07/21 8:43 pm, robert k Wild wrote:
> > Thanks Amos much appreciated
> >
> > Is there a way of enabling socks udp at all or is this just not the case
> > at all with squid
> >
>
> Not until Squid is changed to support HTTP over UDP. That is coming with
> HTTP/3 but nowhere near an ETA on when it will be available.
>
>
> Amos
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210706/3a397a0a/attachment.htm>

From david.mills at acusensus.com  Tue Jul  6 23:25:31 2021
From: david.mills at acusensus.com (David Mills)
Date: Wed, 7 Jul 2021 09:25:31 +1000
Subject: [squid-users] Ubuntu 20.04 "apt update" issues behind a VPN and
 Squid proxy
Message-ID: <CAF28NibkN+CrDDM+2APUKA1rba_6BjZvoDAF11wXCSaFmHSh9Q@mail.gmail.com>

Hi,

We've got a collection of Ubuntu 18.04 boxes out in the field. They connect
to an AWS OpenVPN VPN and use a Squid 3.5 AWS hosted Proxy. They work fine.

We have tried upgrading one to 20.04. Same setup. From the command line
curl or wget can happily download an Ubuntu package from the Ubuntu Mirror
site we use. But "apt update" gets lots of "IGN:" timeouts and errors.

The package we test curl with is
https://mirror.aarnet.edu.au/ubuntu/pool/main/c/curl/curl_7.68.0-1ubuntu2.5_amd64.deb

The Squid log shows a line the doesn't occur for the successful 18.04 "apt
updates":
1625190959.233 81 10.0.11.191 TAG_NONE/200 0 CONNECT
mirror.aarnet.edu.au:443 - HIER_DIRECT/2001:388:30bc:cafe::beef -

The full output of an attempt to update is:

> Ign:1 https://mirror.aarnet.edu.au/ubuntu focal InRelease
>
> Ign:2 https://mirror.aarnet.edu.au/ubuntu focal-updates InRelease
>
> Ign:3 https://mirror.aarnet.edu.au/ubuntu focal-backports InRelease
>
> Ign:4 https://mirror.aarnet.edu.au/ubuntu focal-security InRelease
>
> Err:5 https://mirror.aarnet.edu.au/ubuntu focal Release
>
>   Could not wait for server fd - select (11: Resource temporarily
> unavailable) [IP: 10.0.11.82 3128]
> Err:6 https://mirror.aarnet.edu.au/ubuntu focal-updates Release
>
>   Could not wait for server fd - select (11: Resource temporarily
> unavailable) [IP: 10.0.11.82 3128]
> Err:7 https://mirror.aarnet.edu.au/ubuntu focal-backports Release
>
>   Could not wait for server fd - select (11: Resource temporarily
> unavailable) [IP: 10.0.11.82 3128]
> Err:8 https://mirror.aarnet.edu.au/ubuntu focal-security Release
>
>   Could not wait for server fd - select (11: Resource temporarily
> unavailable) [IP: 10.0.1.26 3128]
> Reading package lists... Done
>
> N: Ignoring file 'microsoft-prod.list-keep' in directory
> '/etc/apt/sources.list.d/' as it has an invalid filename extension
> E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal Release'
> does not have a Release file.
> N: Updating from such a repository can't be done securely, and is
> therefore disabled by default.
> N: See apt-secure(8) manpage for repository creation and user
> configuration details.
> E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal-updates
> Release' does not have a Release file.
> N: Updating from such a repository can't be done securely, and is
> therefore disabled by default.
> N: See apt-secure(8) manpage for repository creation and user
> configuration details.
> E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal-backports
> Release' does not have a Release file.
> N: Updating from such a repository can't be done securely, and is
> therefore disabled by default.
> N: See apt-secure(8) manpage for repository creation and user
> configuration details.
> E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal-security
> Release' does not have a Release file.
> N: Updating from such a repository can't be done securely, and is
> therefore disabled by default.
> N: See apt-secure(8) manpage for repository creation and user
> configuration details.
>

While running, the line

> 0% [Connecting to HTTP proxy (
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128)]
>
appears often and hang for a while.

I've tried upping the squid logging and allowing all, but they didn't offer
any additional information about the issue.

Any advice would be greatly appreciated.

Regards,

David Mills

Senior DevOps Engineer

 E: david.mills at acusensus.com

 M: +61 411 513 404

 W: acusensus.com

-- 
DISCLAIMER: Acusensus puts the privacy and security of its clients, its 
data and information at the core of everything we do. The information 
contained in this email (including attachments) is intended only for the 
use of the person(s) to whom it is addressed to, as it may be confidential 
and contain legally privileged information. If you have received this email 
in error, please delete all copies and notify the sender immediately. Any 
views or opinions presented are
solely those of the author and do not 
necessarily represent the views of Acusensus
Pty Ltd. Please consider the 
environment
before printing this email.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210707/a0516069/attachment.htm>

From ngtech1ltd at gmail.com  Wed Jul  7 10:53:37 2021
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Wed, 7 Jul 2021 13:53:37 +0300
Subject: [squid-users] Ubuntu 20.04 "apt update" issues behind a VPN and
 Squid proxy
In-Reply-To: <CAF28NibkN+CrDDM+2APUKA1rba_6BjZvoDAF11wXCSaFmHSh9Q@mail.gmail.com>
References: <CAF28NibkN+CrDDM+2APUKA1rba_6BjZvoDAF11wXCSaFmHSh9Q@mail.gmail.com>
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAKGjfS9pLRpMrWAgDPs7Rm4BAAAAAA==@gmail.com>

Hey David,

Just wondering if you have seen the apt related docs at:
https://help.ubuntu.com/community/AptGet/Howto/#Setting_up_apt-get_to_use_a_http-proxy

Eliezer

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of David Mills
Sent: Wednesday, July 7, 2021 2:26 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Ubuntu 20.04 "apt update" issues behind a VPN and Squid proxy

Hi,

We've got a collection of Ubuntu 18.04 boxes out in the field. They connect to an AWS OpenVPN VPN and use a Squid 3.5 AWS hosted Proxy. They work fine.

We have tried upgrading one to 20.04. Same setup. From the command line curl or wget can happily download an Ubuntu package from the Ubuntu Mirror site we use. But "apt update" gets lots of "IGN:" timeouts and errors.

The package we test curl with is https://mirror.aarnet.edu.au/ubuntu/pool/main/c/curl/curl_7.68.0-1ubuntu2.5_amd64.deb

The Squid log shows a line the doesn't occur for the successful 18.04 "apt updates":
1625190959.233     81 10.0.11.191 TAG_NONE/200 0 CONNECT http://mirror.aarnet.edu.au:443 - HIER_DIRECT/2001:388:30bc:cafe::beef -

The full output of an attempt to update is:
Ign:1 https://mirror.aarnet.edu.au/ubuntu focal InRelease                                              
Ign:2 https://mirror.aarnet.edu.au/ubuntu focal-updates InRelease                                      
Ign:3 https://mirror.aarnet.edu.au/ubuntu focal-backports InRelease                                    
Ign:4 https://mirror.aarnet.edu.au/ubuntu focal-security InRelease                                     
Err:5 https://mirror.aarnet.edu.au/ubuntu focal Release                                                
  Could not wait for server fd - select (11: Resource temporarily unavailable) [IP: 10.0.11.82 3128]
Err:6 https://mirror.aarnet.edu.au/ubuntu focal-updates Release                                        
  Could not wait for server fd - select (11: Resource temporarily unavailable) [IP: 10.0.11.82 3128]
Err:7 https://mirror.aarnet.edu.au/ubuntu focal-backports Release                                      
  Could not wait for server fd - select (11: Resource temporarily unavailable) [IP: 10.0.11.82 3128]
Err:8 https://mirror.aarnet.edu.au/ubuntu focal-security Release                                       
  Could not wait for server fd - select (11: Resource temporarily unavailable) [IP: 10.0.1.26 3128]
Reading package lists... Done                                                                          
N: Ignoring file 'microsoft-prod.list-keep' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension
E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal Release' does not have a Release file.
N: Updating from such a repository can't be done securely, and is therefore disabled by default.
N: See apt-secure(8) manpage for repository creation and user configuration details.
E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal-updates Release' does not have a Release file.
N: Updating from such a repository can't be done securely, and is therefore disabled by default.
N: See apt-secure(8) manpage for repository creation and user configuration details.
E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal-backports Release' does not have a Release file.
N: Updating from such a repository can't be done securely, and is therefore disabled by default.
N: See apt-secure(8) manpage for repository creation and user configuration details.
E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal-security Release' does not have a Release file.
N: Updating from such a repository can't be done securely, and is therefore disabled by default.
N: See apt-secure(8) manpage for repository creation and user configuration details.

While running, the line
0% [Connecting to HTTP proxy (http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128)]
appears often and hang for a while.

I've tried upping the squid logging and allowing all, but they didn't offer any additional information about the issue.

Any advice would be greatly appreciated.

Regards,


David Mills
Senior DevOps Engineer

 E: mailto:david.mills at acusensus.com
 M: +61 411 513 404
 W:http://acusensus.com/



DISCLAIMER: Acusensus puts the privacy and security of its clients, its data and information at the core of everything we do. The information contained in this email (including attachments) is intended only for the use of the person(s) to whom it is addressed to, as it may be confidential and contain legally privileged information. If you have received this email in error, please delete all copies and notify the sender immediately. Any views or opinions presented are solely those of the author and do not necessarily represent the views of Acusensus Pty Ltd. Please consider the environment before printing this email.



From ngtech1ltd at gmail.com  Wed Jul  7 11:01:36 2021
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Wed, 7 Jul 2021 14:01:36 +0300
Subject: [squid-users] TPROXY Error
In-Reply-To: <CADAqQfwR4w-cFidq+8ea7zns=OUwyan6W1wXuLcrge4jSE4B9Q@mail.gmail.com>
References: <CADAqQfwR4w-cFidq+8ea7zns=OUwyan6W1wXuLcrge4jSE4B9Q@mail.gmail.com>
Message-ID: <000a01d7731f$7550a9c0$5ff1fd40$@gmail.com>

Hey Ben,

I want to try and reset this issue because I am missing some technical
details.

1. What Linux Distro and what version are you using?
2. the output of 'ip address'
3. the output of 'ip rule'
4.  the output of 'ip route show'
5.  the output of 'ip route show table 100'
6. the output of 'iptables-save'
7. the output of 'nft -nn list ruleset' (if exists on the OS)
8. the output of your squid.conf
9. the output of 'squid -v'
10. the output of 'uname -a'

Once we will have all the above details (reducing/modifying any private
details) we can try to maybe help you.

Eliezer

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
Ben Goz
Sent: Wednesday, June 30, 2021 3:16 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] TPROXY Error

 By the help of God.

Hi All,
I'm trying to configure squid as a transparent proxy using TPROXY.
The machine I'm using has 2 NICs, one for input and the other one for
output traffic.
The TPROXY iptables rules are configured on the input NIC.
It looks like iptables TPROXY redirect works but squid prints out the
following error:

ERROR: NAT/TPROXY lookup failed to locate original IPs on
local=xxx:443 remote=xxx:49471 FD 14 flags=17

I think I loaded all TPROXY required kernel modules.

The ip forwarding works fine without the iptables rules. and I don't
see any squid ERROR on getsockopt

Please let me know what I'm missing?

Thanks,
Ben
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From ben.goz87 at gmail.com  Wed Jul  7 12:35:58 2021
From: ben.goz87 at gmail.com (Ben Goz)
Date: Wed, 7 Jul 2021 15:35:58 +0300
Subject: [squid-users] TPROXY Error
In-Reply-To: <000a01d7731f$7550a9c0$5ff1fd40$@gmail.com>
References: <CADAqQfwR4w-cFidq+8ea7zns=OUwyan6W1wXuLcrge4jSE4B9Q@mail.gmail.com>
 <000a01d7731f$7550a9c0$5ff1fd40$@gmail.com>
Message-ID: <68332d40-ba49-f426-21b8-48602608690e@gmail.com>

By the help of God.


Hi Eliezer,

Thanks for your help.

Please let me know if you need more information.


Regards,

Ben

On 07/07/2021 14:01, Eliezer Croitoru wrote:
> Hey Ben,
>
> I want to try and reset this issue because I am missing some technical
> details.
>
> 1. What Linux Distro and what version are you using?'
Ubuntu 20.04
> 2. the output of 'ip address'
$ ip address
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN 
group default qlen 1000
 ??? link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
 ??? inet 127.0.0.1/8 scope host lo
 ?????? valid_lft forever preferred_lft forever
 ??? inet6 ::1/128 scope host
 ?????? valid_lft forever preferred_lft forever
2: ens1f0: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc mq 
master bond0 state UP group default qlen 1000
 ??? link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
3: ens1f1: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc mq 
master bond0 state UP group default qlen 1000
 ??? link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
4: usb0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group 
default qlen 1000
 ??? link/ether ca:13:59:65:c2:56 brd ff:ff:ff:ff:ff:ff
5: enx00e04c3600d3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc 
fq_codel state UP group default qlen 1000
 ??? link/ether 00:e0:4c:36:00:d3 brd ff:ff:ff:ff:ff:ff
 ??? inet 8.11.39.250/30 brd 8.11.39.251 scope global enx00e04c3600d3
 ?????? valid_lft forever preferred_lft forever
 ??? inet6 fe80::2e0:4cff:fe36:d3/64 scope link
 ?????? valid_lft forever preferred_lft forever
6: bond0: <BROADCAST,MULTICAST,MASTER,UP,LOWER_UP> mtu 1500 qdisc 
noqueue state UP group default qlen 1000
 ??? link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
 ??? inet6 fe80::b859:58ff:fe58:232b/64 scope link
 ?????? valid_lft forever preferred_lft forever
7: bond0.212 at bond0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc 
noqueue state UP group default qlen 1000
 ??? link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
 ??? inet 8.13.140.1/28 brd 8.13.140.15 scope global bond0.212
 ?????? valid_lft forever preferred_lft forever
 ??? inet6 fe80::b859:58ff:fe58:232b/64 scope link
 ?????? valid_lft forever preferred_lft forever
8: bond0.213 at bond0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc 
noqueue state UP group default qlen 1000
 ??? link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
 ??? inet 1.21.213.1/24 brd 1.21.213.255 scope global bond0.213
 ?????? valid_lft forever preferred_lft forever
 ??? inet6 fe80::b859:58ff:fe58:232b/64 scope link
 ?????? valid_lft forever preferred_lft forever
> 3. the output of 'ip rule'
$ ip rule
0:??? from all lookup local
32762:??? from all fwmark 0x1 lookup 100
32763:??? from all fwmark 0x1 lookup 100
32764:??? from all fwmark 0x1 lookup 100
32765:??? from all fwmark 0x1 lookup 100
32766:??? from all lookup main
32767:??? from all lookup default

> 4.  the output of 'ip route show'

$ ip route show
default via 8.13.140.14 dev bond0.212 proto static
1.21.213.0/24 dev bond0.213 proto kernel scope link src 1.21.213.1
8.11.39.248/30 dev enx00e04c3600d3 proto kernel scope link src 8.11.39.250
8.13.140.0/28 dev bond0.212 proto kernel scope link src 8.13.140.1
8.13.144.0/20 via 1.21.213.254 dev bond0.213
8.13.148.1 via 1.21.213.254 dev bond0.213

> 5.  the output of 'ip route show table 100'
$ ip route show
default via 8.13.140.14 dev bond0.212 proto static
1.21.213.0/24 dev bond0.213 proto kernel scope link src 1.21.213.1
8.11.39.248/30 dev enx00e04c3600d3 proto kernel scope link src 8.11.39.250
8.13.140.0/28 dev bond0.212 proto kernel scope link src 8.13.140.1
8.13.144.0/20 via 1.21.213.254 dev bond0.213
8.13.148.1 via 1.21.213.254 dev bond0.213
> 6. the output of 'iptables-save'


$ sudo iptables-save
# Generated by iptables-save v1.8.4 on Wed Jul? 7 12:25:05 2021
*mangle
:PREROUTING ACCEPT [72898710:6084386298]
:INPUT ACCEPT [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
:POSTROUTING ACCEPT [0:0]
:DIVERT - [0:0]
-A PREROUTING -p tcp -m socket -j DIVERT
-A PREROUTING -i bond0.213 -p tcp -m tcp --dport 80 -j TPROXY --on-port 
15644 --on-ip 0.0.0.0 --tproxy-mark 0x1/0x1
-A PREROUTING -i bond0.213 -p tcp -m tcp --dport 443 -j TPROXY --on-port 
15645 --on-ip 0.0.0.0 --tproxy-mark 0x1/0x1
-A INPUT -j ACCEPT
-A FORWARD -j ACCEPT
-A OUTPUT -j ACCEPT
-A POSTROUTING -j ACCEPT
-A DIVERT -j MARK --set-xmark 0x1/0xffffffff
-A DIVERT -j ACCEPT
COMMIT
# Completed on Wed Jul? 7 12:25:05 2021
# Generated by iptables-save v1.8.4 on Wed Jul? 7 12:25:05 2021
*nat
:PREROUTING ACCEPT [26338415:1392747531]
:INPUT ACCEPT [820462:44161193]
:OUTPUT ACCEPT [1053:92773]
:POSTROUTING ACCEPT [25514534:1348449899]
-A PREROUTING -i eth1 -p udp -m udp --dport 53 -j REDIRECT --to-ports 53
-A PREROUTING -i eth1 -p tcp -m tcp --dport 53 -j REDIRECT --to-ports 53
COMMIT
# Completed on Wed Jul? 7 12:25:05 2021
# Generated by iptables-save v1.8.4 on Wed Jul? 7 12:25:05 2021
*filter
:INPUT ACCEPT [5045387:2170630036]
:FORWARD ACCEPT [72544426:6194710400]
:OUTPUT ACCEPT [2471930:252759773]
COMMIT
# Completed on Wed Jul? 7 12:25:05 20

> 7. the output of 'nft -nn list ruleset' (if exists on the OS)
Doesn't exists.
> 8. the output of your squid.conf
$ cat squid.conf
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 0.0.0.1-0.255.255.255??? # RFC 1122 "this" network (LAN)
acl localnet src 10.0.0.0/8??? ??? # RFC 1918 local private network (LAN)
acl localnet src 100.64.0.0/10??? ??? # RFC 6598 shared address space (CGN)
acl localnet src 169.254.0.0/16 ??? # RFC 3927 link-local (directly 
plugged) machines
acl localnet src 172.16.0.0/12??? ??? # RFC 1918 local private network (LAN)
acl localnet src 192.168.0.0/16??? ??? # RFC 1918 local private network 
(LAN)
acl localnet src fc00::/7?????? ??? # RFC 4193 local private network range
acl localnet src fe80::/10????? ??? # RFC 4291 link-local (directly 
plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80??? ??? # http
acl Safe_ports port 21??? ??? # ftp
acl Safe_ports port 443??? ??? # https
acl Safe_ports port 70??? ??? # gopher
acl Safe_ports port 210??? ??? # wais
acl Safe_ports port 1025-65535??? # unregistered ports
acl Safe_ports port 280??? ??? # http-mgmt
acl Safe_ports port 488??? ??? # gss-http
acl Safe_ports port 591??? ??? # filemaker
acl Safe_ports port 777??? ??? # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
#http_access deny all

http_access allow all

# Squid normally listens to port 3128
http_port 15643
http_port 15644 tproxy
https_port 15645 ssl-bump tproxy generate-host-certificates=on 
options=ALL dynamic_cert_mem_cache_size=4MB 
cert=/usr/local/squid/etc/ssl_cert/myCA.pem 
dhparams=/usr/local/squid/etc/dhparam.pem
always_direct allow all
acl DiscoverSNIHost at_step SslBump1
acl NoSSLInterceptRegexp_always ssl::server_name_regex -i xxx
acl NoSSLIntercept ssl::server_name? "xxx"
acl NoSSLInterceptRegexp ssl::server_name_regex -i "xxx"
ssl_bump splice NoSSLInterceptRegexp_always
ssl_bump splice NoSSLIntercept
ssl_bump splice NoSSLInterceptRegexp
ssl_bump peek DiscoverSNIHost
ssl_bump bump all
sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s 
/var/lib/ssl_db -M 4MB
sslcrtd_children 32 startup=15 idle=3
#sslproxy_capath /etc/ssl/certs

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /usr/local/squid/var/cache/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /usr/local/squid/var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:??? ??? 1440??? 20%??? 10080
refresh_pattern ^gopher:??? 1440??? 0%??? 1440
refresh_pattern -i (/cgi-bin/|\?) 0??? 0%??? 0
refresh_pattern .??? ??? 0??? 20%??? 4320

range_offset_limit -1

dns_v4_first on
forwarded_for off
cache deny all
> 9. the output of 'squid -v'
$ ./squid -v
Squid Cache: Version 4.15
Service Name: squid

This binary uses OpenSSL 1.1.1f? 31 Mar 2020. For legal restrictions on 
distribution see https://www.openssl.org/source/license.html

configure options:? '--with-openssl' '--enable-ssl-crtd' '--enable-ecap' 
'--enable-linux-netfilter' --enable-ltdl-convenience

> 10. the output of 'uname -a'
uname -a
Linux xxx 5.4.0-77-generic #86-Ubuntu SMP Thu Jun 17 02:35:03 UTC 2021 
x86_64 x86_64 x86_64 GNU/Linux
>
> Once we will have all the above details (reducing/modifying any private
> details) we can try to maybe help you.
>
> Eliezer
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
> Ben Goz
> Sent: Wednesday, June 30, 2021 3:16 PM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] TPROXY Error
>
>   By the help of God.
>
> Hi All,
> I'm trying to configure squid as a transparent proxy using TPROXY.
> The machine I'm using has 2 NICs, one for input and the other one for
> output traffic.
> The TPROXY iptables rules are configured on the input NIC.
> It looks like iptables TPROXY redirect works but squid prints out the
> following error:
>
> ERROR: NAT/TPROXY lookup failed to locate original IPs on
> local=xxx:443 remote=xxx:49471 FD 14 flags=17
>
> I think I loaded all TPROXY required kernel modules.
>
> The ip forwarding works fine without the iptables rules. and I don't
> see any squid ERROR on getsockopt
>
> Please let me know what I'm missing?
>
> Thanks,
> Ben
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From ngtech1ltd at gmail.com  Wed Jul  7 21:03:57 2021
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Thu, 8 Jul 2021 00:03:57 +0300
Subject: [squid-users] TPROXY Error
In-Reply-To: <68332d40-ba49-f426-21b8-48602608690e@gmail.com>
References: <CADAqQfwR4w-cFidq+8ea7zns=OUwyan6W1wXuLcrge4jSE4B9Q@mail.gmail.com>
 <000a01d7731f$7550a9c0$5ff1fd40$@gmail.com>
 <68332d40-ba49-f426-21b8-48602608690e@gmail.com>
Message-ID: <000001d77373$9addf630$d099e290$@gmail.com>

Hey Ben,

You are missing the critical output of the full command:
Ip route show table 100

What you posted was:
> 5.  the output of 'ip route show table 100'
$ ip route show
default via 8.13.140.14 dev bond0.212 proto static
1.21.213.0/24 dev bond0.213 proto kernel scope link src 1.21.213.1
8.11.39.248/30 dev enx00e04c3600d3 proto kernel scope link src 8.11.39.250
8.13.140.0/28 dev bond0.212 proto kernel scope link src 8.13.140.1
8.13.144.0/20 via 1.21.213.254 dev bond0.213
8.13.148.1 via 1.21.213.254 dev bond0.213
##

It's important to see the relevant routing table.
The linux Kernel have couple routing tables which each can contain different routing/forwarding table.
If you want to understand a bit more you might be able to try and lookup for FIB.
( take a peek at: http://linux-ip.net/html/routing-tables.html)

Eliezer

-----Original Message-----
From: Ben Goz <ben.goz87 at gmail.com> 
Sent: Wednesday, July 7, 2021 3:36 PM
To: Eliezer Croitoru <ngtech1ltd at gmail.com>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] TPROXY Error

By the help of God.


Hi Eliezer,

Thanks for your help.

Please let me know if you need more information.


Regards,

Ben

On 07/07/2021 14:01, Eliezer Croitoru wrote:
> Hey Ben,
>
> I want to try and reset this issue because I am missing some technical
> details.
>
> 1. What Linux Distro and what version are you using?'
Ubuntu 20.04
> 2. the output of 'ip address'
$ ip address
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN 
group default qlen 1000
     link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
     inet 127.0.0.1/8 scope host lo
        valid_lft forever preferred_lft forever
     inet6 ::1/128 scope host
        valid_lft forever preferred_lft forever
2: ens1f0: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc mq 
master bond0 state UP group default qlen 1000
     link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
3: ens1f1: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc mq 
master bond0 state UP group default qlen 1000
     link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
4: usb0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group 
default qlen 1000
     link/ether ca:13:59:65:c2:56 brd ff:ff:ff:ff:ff:ff
5: enx00e04c3600d3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc 
fq_codel state UP group default qlen 1000
     link/ether 00:e0:4c:36:00:d3 brd ff:ff:ff:ff:ff:ff
     inet 8.11.39.250/30 brd 8.11.39.251 scope global enx00e04c3600d3
        valid_lft forever preferred_lft forever
     inet6 fe80::2e0:4cff:fe36:d3/64 scope link
        valid_lft forever preferred_lft forever
6: bond0: <BROADCAST,MULTICAST,MASTER,UP,LOWER_UP> mtu 1500 qdisc 
noqueue state UP group default qlen 1000
     link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
     inet6 fe80::b859:58ff:fe58:232b/64 scope link
        valid_lft forever preferred_lft forever
7: bond0.212 at bond0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc 
noqueue state UP group default qlen 1000
     link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
     inet 8.13.140.1/28 brd 8.13.140.15 scope global bond0.212
        valid_lft forever preferred_lft forever
     inet6 fe80::b859:58ff:fe58:232b/64 scope link
        valid_lft forever preferred_lft forever
8: bond0.213 at bond0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc 
noqueue state UP group default qlen 1000
     link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
     inet 1.21.213.1/24 brd 1.21.213.255 scope global bond0.213
        valid_lft forever preferred_lft forever
     inet6 fe80::b859:58ff:fe58:232b/64 scope link
        valid_lft forever preferred_lft forever
> 3. the output of 'ip rule'
$ ip rule
0:    from all lookup local
32762:    from all fwmark 0x1 lookup 100
32763:    from all fwmark 0x1 lookup 100
32764:    from all fwmark 0x1 lookup 100
32765:    from all fwmark 0x1 lookup 100
32766:    from all lookup main
32767:    from all lookup default

> 4.  the output of 'ip route show'

$ ip route show
default via 8.13.140.14 dev bond0.212 proto static
1.21.213.0/24 dev bond0.213 proto kernel scope link src 1.21.213.1
8.11.39.248/30 dev enx00e04c3600d3 proto kernel scope link src 8.11.39.250
8.13.140.0/28 dev bond0.212 proto kernel scope link src 8.13.140.1
8.13.144.0/20 via 1.21.213.254 dev bond0.213
8.13.148.1 via 1.21.213.254 dev bond0.213

> 5.  the output of 'ip route show table 100'
$ ip route show
default via 8.13.140.14 dev bond0.212 proto static
1.21.213.0/24 dev bond0.213 proto kernel scope link src 1.21.213.1
8.11.39.248/30 dev enx00e04c3600d3 proto kernel scope link src 8.11.39.250
8.13.140.0/28 dev bond0.212 proto kernel scope link src 8.13.140.1
8.13.144.0/20 via 1.21.213.254 dev bond0.213
8.13.148.1 via 1.21.213.254 dev bond0.213
> 6. the output of 'iptables-save'


$ sudo iptables-save
# Generated by iptables-save v1.8.4 on Wed Jul  7 12:25:05 2021
*mangle
:PREROUTING ACCEPT [72898710:6084386298]
:INPUT ACCEPT [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
:POSTROUTING ACCEPT [0:0]
:DIVERT - [0:0]
-A PREROUTING -p tcp -m socket -j DIVERT
-A PREROUTING -i bond0.213 -p tcp -m tcp --dport 80 -j TPROXY --on-port 
15644 --on-ip 0.0.0.0 --tproxy-mark 0x1/0x1
-A PREROUTING -i bond0.213 -p tcp -m tcp --dport 443 -j TPROXY --on-port 
15645 --on-ip 0.0.0.0 --tproxy-mark 0x1/0x1
-A INPUT -j ACCEPT
-A FORWARD -j ACCEPT
-A OUTPUT -j ACCEPT
-A POSTROUTING -j ACCEPT
-A DIVERT -j MARK --set-xmark 0x1/0xffffffff
-A DIVERT -j ACCEPT
COMMIT
# Completed on Wed Jul  7 12:25:05 2021
# Generated by iptables-save v1.8.4 on Wed Jul  7 12:25:05 2021
*nat
:PREROUTING ACCEPT [26338415:1392747531]
:INPUT ACCEPT [820462:44161193]
:OUTPUT ACCEPT [1053:92773]
:POSTROUTING ACCEPT [25514534:1348449899]
-A PREROUTING -i eth1 -p udp -m udp --dport 53 -j REDIRECT --to-ports 53
-A PREROUTING -i eth1 -p tcp -m tcp --dport 53 -j REDIRECT --to-ports 53
COMMIT
# Completed on Wed Jul  7 12:25:05 2021
# Generated by iptables-save v1.8.4 on Wed Jul  7 12:25:05 2021
*filter
:INPUT ACCEPT [5045387:2170630036]
:FORWARD ACCEPT [72544426:6194710400]
:OUTPUT ACCEPT [2471930:252759773]
COMMIT
# Completed on Wed Jul  7 12:25:05 20

> 7. the output of 'nft -nn list ruleset' (if exists on the OS)
Doesn't exists.
> 8. the output of your squid.conf
$ cat squid.conf
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 0.0.0.1-0.255.255.255    # RFC 1122 "this" network (LAN)
acl localnet src 10.0.0.0/8        # RFC 1918 local private network (LAN)
acl localnet src 100.64.0.0/10        # RFC 6598 shared address space (CGN)
acl localnet src 169.254.0.0/16     # RFC 3927 link-local (directly 
plugged) machines
acl localnet src 172.16.0.0/12        # RFC 1918 local private network (LAN)
acl localnet src 192.168.0.0/16        # RFC 1918 local private network 
(LAN)
acl localnet src fc00::/7           # RFC 4193 local private network range
acl localnet src fe80::/10          # RFC 4291 link-local (directly 
plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80        # http
acl Safe_ports port 21        # ftp
acl Safe_ports port 443        # https
acl Safe_ports port 70        # gopher
acl Safe_ports port 210        # wais
acl Safe_ports port 1025-65535    # unregistered ports
acl Safe_ports port 280        # http-mgmt
acl Safe_ports port 488        # gss-http
acl Safe_ports port 591        # filemaker
acl Safe_ports port 777        # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
#http_access deny all

http_access allow all

# Squid normally listens to port 3128
http_port 15643
http_port 15644 tproxy
https_port 15645 ssl-bump tproxy generate-host-certificates=on 
options=ALL dynamic_cert_mem_cache_size=4MB 
cert=/usr/local/squid/etc/ssl_cert/myCA.pem 
dhparams=/usr/local/squid/etc/dhparam.pem
always_direct allow all
acl DiscoverSNIHost at_step SslBump1
acl NoSSLInterceptRegexp_always ssl::server_name_regex -i xxx
acl NoSSLIntercept ssl::server_name  "xxx"
acl NoSSLInterceptRegexp ssl::server_name_regex -i "xxx"
ssl_bump splice NoSSLInterceptRegexp_always
ssl_bump splice NoSSLIntercept
ssl_bump splice NoSSLInterceptRegexp
ssl_bump peek DiscoverSNIHost
ssl_bump bump all
sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s 
/var/lib/ssl_db -M 4MB
sslcrtd_children 32 startup=15 idle=3
#sslproxy_capath /etc/ssl/certs

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /usr/local/squid/var/cache/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /usr/local/squid/var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:        1440    20%    10080
refresh_pattern ^gopher:    1440    0%    1440
refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
refresh_pattern .        0    20%    4320

range_offset_limit -1

dns_v4_first on
forwarded_for off
cache deny all
> 9. the output of 'squid -v'
$ ./squid -v
Squid Cache: Version 4.15
Service Name: squid

This binary uses OpenSSL 1.1.1f  31 Mar 2020. For legal restrictions on 
distribution see https://www.openssl.org/source/license.html

configure options:  '--with-openssl' '--enable-ssl-crtd' '--enable-ecap' 
'--enable-linux-netfilter' --enable-ltdl-convenience

> 10. the output of 'uname -a'
uname -a
Linux xxx 5.4.0-77-generic #86-Ubuntu SMP Thu Jun 17 02:35:03 UTC 2021 
x86_64 x86_64 x86_64 GNU/Linux
>
> Once we will have all the above details (reducing/modifying any private
> details) we can try to maybe help you.
>
> Eliezer
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
> Ben Goz
> Sent: Wednesday, June 30, 2021 3:16 PM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] TPROXY Error
>
>   By the help of God.
>
> Hi All,
> I'm trying to configure squid as a transparent proxy using TPROXY.
> The machine I'm using has 2 NICs, one for input and the other one for
> output traffic.
> The TPROXY iptables rules are configured on the input NIC.
> It looks like iptables TPROXY redirect works but squid prints out the
> following error:
>
> ERROR: NAT/TPROXY lookup failed to locate original IPs on
> local=xxx:443 remote=xxx:49471 FD 14 flags=17
>
> I think I loaded all TPROXY required kernel modules.
>
> The ip forwarding works fine without the iptables rules. and I don't
> see any squid ERROR on getsockopt
>
> Please let me know what I'm missing?
>
> Thanks,
> Ben
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



From david.mills at acusensus.com  Wed Jul  7 23:44:32 2021
From: david.mills at acusensus.com (David Mills)
Date: Thu, 8 Jul 2021 09:44:32 +1000
Subject: [squid-users] Ubuntu 20.04 "apt update" issues behind a VPN and
 Squid proxy
In-Reply-To: <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAKGjfS9pLRpMrWAgDPs7Rm4BAAAAAA==@gmail.com>
References: <CAF28NibkN+CrDDM+2APUKA1rba_6BjZvoDAF11wXCSaFmHSh9Q@mail.gmail.com>
 <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAKGjfS9pLRpMrWAgDPs7Rm4BAAAAAA==@gmail.com>
Message-ID: <CAF28NibjRsM8gdcoqMC=X-btNMVswsersd3QZTLurgk-=bLVAA@mail.gmail.com>

Hi Eliezer,

We have:

/etc/apt/apt.conf:

> Acquire::http::proxy "
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128/";
> Acquire::https::proxy "
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128/";
>

/etc/apt/sources.list (comment lines removed for brevity)

> deb https://mirror.aarnet.edu.au/ubuntu/ focal main restricted
> deb https://mirror.aarnet.edu.au/ubuntu/ focal-updates main restricted
> deb https://mirror.aarnet.edu.au/ubuntu/ focal-updates universe
> deb https://mirror.aarnet.edu.au/ubuntu/ focal multiverse
> deb https://mirror.aarnet.edu.au/ubuntu/ focal-updates multiverse
> deb https://mirror.aarnet.edu.au/ubuntu/ focal-backports main restricted
> universe multiverse
> deb https://mirror.aarnet.edu.au/ubuntu focal-security main restricted
> deb https://mirror.aarnet.edu.au/ubuntu focal-security universe
> deb https://mirror.aarnet.edu.au/ubuntu focal-security multiverse
>

squid.conf

> # Debugging for your ACLs
> debug_options ALL,1
>
> # temp option for full debug logs
> #debug_options 28,2
>
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl vpc_cidr src 10.0.0.0/16 # VPC CIDR
> acl vpc_cidr src 127.0.0.1
>
> # technician VPN source cidr
> acl technician_vpn src 10.0.104.0/22
>
>
> acl SSL_ports port 443
> acl Safe_ports port 80 # http
> #acl Safe_ports port 21 # ftp
> acl Safe_ports port 443 # https
> #acl Safe_ports port 70 # gopher
> #acl Safe_ports port 210 # wais
> acl Safe_ports port 1025-65535 # unregistered ports
> #acl Safe_ports port 280 # http-mgmt
> #acl Safe_ports port 488 # gss-http
> #acl Safe_ports port 591 # filemaker
> #acl Safe_ports port 777 # multiling http
> acl CONNECT method CONNECT
>
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
>
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
>
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
>
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
>
> # Redirect HTTP to HTTPS
> acl port_80 port 80
> acl gstatic dstdomain www.gstatic.com
> http_access deny port_80 gstatic
> deny_info 301:https://%H%R gstatic
>
> acl avpc dstdomain crop-assessment.acusensus-vpc
> http_access deny port_80 avpc
> deny_info 302:<company url> avpc
>
>
> # Deny HTTP
> http_access deny port_80
>
> # Whitelist of allowed sites
> acl allowed_http_sites dstdomain "/etc/squid/squid.allowed.sites.txt"
> http_access allow allowed_http_sites vpc_cidr
>
> # And finally deny all other access to this proxy
> http_access deny all
>
> # Squid normally listens to port 3128
> http_port 3128 ssl-bump cert=/etc/squid/cert.pem
> acl allowed_https_sites ssl::server_name
> "/etc/squid/squid.allowed.sites.txt"
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> ssl_bump peek step1 all
> ssl_bump peek step2 allowed_https_sites
> ssl_bump splice step3 allowed_https_sites
> ssl_bump terminate step2 all
>
> # Uncomment and adjust the following to add a disk cache directory.
> #cache_dir ufs /var/spool/squid 100 16 256
>
> # Leave coredumps in the first cache dir
> coredump_dir /var/spool/squid
> #
> # Add any of your own refresh_pattern entries above these.
> #
> refresh_pattern ^ftp: 1440 20% 10080
> refresh_pattern ^gopher: 1440 0% 1440
> refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
> refresh_pattern . 0 20% 4320
>
>
>
Squid 3.5 is running on an EC2 instance running Amazon Linux 2. I'll answer
the questions you asked Ben for extra info.
ip address:

> 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group
> default qlen 1000
>     link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
>     inet 127.0.0.1/8 scope host lo
>        valid_lft forever preferred_lft forever
>     inet6 ::1/128 scope host
>        valid_lft forever preferred_lft forever
> 2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9001 qdisc mq state UP
> group default qlen 1000
>     link/ether 02:1b:15:b8:9a:06 brd ff:ff:ff:ff:ff:ff
>     inet 10.0.12.111/24 brd 10.0.12.255 scope global dynamic eth0
>        valid_lft 2393sec preferred_lft 2393sec
>     inet6 fe80::1b:15ff:feb8:9a06/64 scope link
>        valid_lft forever preferred_lft forever
>

ip rule

> 0: from all lookup local
> 32766: from all lookup main
> 32767: from all lookup default
>

ip route show

> default via 10.0.12.1 dev eth0
> 10.0.12.0/24 dev eth0 proto kernel scope link src 10.0.12.111
> 169.254.169.254 dev eth0
>

ip route show table 100

>
>
iptables-save

>
>
squid -v

> Squid Cache: Version 3.5.20
> Service Name: squid
> configure options:  '--build=x86_64-koji-linux-gnu'
> '--host=x86_64-koji-linux-gnu' '--program-prefix=' '--prefix=/usr'
> '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin'
> '--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include'
> '--libdir=/usr/lib64' '--libexecdir=/usr/libexec'
> '--sharedstatedir=/var/lib' '--mandir=/usr/share/man'
> '--infodir=/usr/share/info' '--disable-strict-error-checking'
> '--exec_prefix=/usr' '--libexecdir=/usr/lib64/squid' '--localstatedir=/var'
> '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
> '--with-logdir=$(localstatedir)/log/squid'
> '--with-pidfile=$(localstatedir)/run/squid.pid'
> '--disable-dependency-tracking' '--enable-eui'
> '--enable-follow-x-forwarded-for' '--enable-auth'
> '--enable-auth-basic=DB,LDAP,MSNT-multi-domain,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,SMB_LM,getpwnam'
> '--enable-auth-ntlm=smb_lm,fake'
> '--enable-auth-digest=file,LDAP,eDirectory'
> '--enable-auth-negotiate=kerberos'
> '--enable-external-acl-helpers=file_userip,LDAP_group,time_quota,session,unix_group,wbinfo_group,kerberos_ldap_group'
> '--enable-cache-digests' '--enable-cachemgr-hostname=localhost'
> '--enable-delay-pools' '--enable-epoll' '--enable-ident-lookups'
> '--enable-linux-netfilter' '--enable-removal-policies=heap,lru'
> '--enable-snmp' '--enable-ssl-crtd' '--enable-storeio=aufs,diskd,rock,ufs'
> '--enable-wccpv2' '--enable-esi' '--enable-ecap' '--with-aio'
> '--with-default-user=squid' '--with-dl' '--with-openssl' '--with-pthreads'
> '--disable-arch-native' 'build_alias=x86_64-koji-linux-gnu'
> 'host_alias=x86_64-koji-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall
> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong
> --param=ssp-buffer-size=4 -grecord-gcc-switches    -m64 -mtune=generic
> -fpie' 'LDFLAGS=-Wl,-z,relro  -pie -Wl,-z,relro -Wl,-z,now' 'CXXFLAGS=-O2
> -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions
> -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches
>  -m64 -mtune=generic -fpie'
> 'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig'
>

uname -a

> Linux ip-10-0-12-111.ap-southeast-2.compute.internal
> 4.14.231-173.361.amzn2.x86_64 #1 SMP Mon Apr 26 20:57:08 UTC 2021 x86_64
> x86_64 x86_64 GNU/Linux
>

Regards,

David Mills

Senior DevOps Engineer

 E: david.mills at acusensus.com

 M: +61 411 513 404

 W: acusensus.com





On Wed, 7 Jul 2021 at 20:53, Eliezer Croitoru <ngtech1ltd at gmail.com> wrote:

> Hey David,
>
> Just wondering if you have seen the apt related docs at:
>
> https://help.ubuntu.com/community/AptGet/Howto/#Setting_up_apt-get_to_use_a_http-proxy
>
> Eliezer
>
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf
> Of David Mills
> Sent: Wednesday, July 7, 2021 2:26 AM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Ubuntu 20.04 "apt update" issues behind a VPN and
> Squid proxy
>
> Hi,
>
> We've got a collection of Ubuntu 18.04 boxes out in the field. They
> connect to an AWS OpenVPN VPN and use a Squid 3.5 AWS hosted Proxy. They
> work fine.
>
> We have tried upgrading one to 20.04. Same setup. From the command line
> curl or wget can happily download an Ubuntu package from the Ubuntu Mirror
> site we use. But "apt update" gets lots of "IGN:" timeouts and errors.
>
> The package we test curl with is
> https://mirror.aarnet.edu.au/ubuntu/pool/main/c/curl/curl_7.68.0-1ubuntu2.5_amd64.deb
>
> The Squid log shows a line the doesn't occur for the successful 18.04 "apt
> updates":
> 1625190959.233     81 10.0.11.191 TAG_NONE/200 0 CONNECT
> http://mirror.aarnet.edu.au:443 - HIER_DIRECT/2001:388:30bc:cafe::beef -
>
> The full output of an attempt to update is:
> Ign:1 https://mirror.aarnet.edu.au/ubuntu focal InRelease
>
> Ign:2 https://mirror.aarnet.edu.au/ubuntu focal-updates InRelease
>
> Ign:3 https://mirror.aarnet.edu.au/ubuntu focal-backports InRelease
>
> Ign:4 https://mirror.aarnet.edu.au/ubuntu focal-security InRelease
>
> Err:5 https://mirror.aarnet.edu.au/ubuntu focal Release
>
>   Could not wait for server fd - select (11: Resource temporarily
> unavailable) [IP: 10.0.11.82 3128]
> Err:6 https://mirror.aarnet.edu.au/ubuntu focal-updates Release
>
>   Could not wait for server fd - select (11: Resource temporarily
> unavailable) [IP: 10.0.11.82 3128]
> Err:7 https://mirror.aarnet.edu.au/ubuntu focal-backports Release
>
>   Could not wait for server fd - select (11: Resource temporarily
> unavailable) [IP: 10.0.11.82 3128]
> Err:8 https://mirror.aarnet.edu.au/ubuntu focal-security Release
>
>   Could not wait for server fd - select (11: Resource temporarily
> unavailable) [IP: 10.0.1.26 3128]
> Reading package lists... Done
>
> N: Ignoring file 'microsoft-prod.list-keep' in directory
> '/etc/apt/sources.list.d/' as it has an invalid filename extension
> E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal Release'
> does not have a Release file.
> N: Updating from such a repository can't be done securely, and is
> therefore disabled by default.
> N: See apt-secure(8) manpage for repository creation and user
> configuration details.
> E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal-updates
> Release' does not have a Release file.
> N: Updating from such a repository can't be done securely, and is
> therefore disabled by default.
> N: See apt-secure(8) manpage for repository creation and user
> configuration details.
> E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal-backports
> Release' does not have a Release file.
> N: Updating from such a repository can't be done securely, and is
> therefore disabled by default.
> N: See apt-secure(8) manpage for repository creation and user
> configuration details.
> E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal-security
> Release' does not have a Release file.
> N: Updating from such a repository can't be done securely, and is
> therefore disabled by default.
> N: See apt-secure(8) manpage for repository creation and user
> configuration details.
>
> While running, the line
> 0% [Connecting to HTTP proxy (
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128)]
> appears often and hang for a while.
>
> I've tried upping the squid logging and allowing all, but they didn't
> offer any additional information about the issue.
>
> Any advice would be greatly appreciated.
>
> Regards,
>
>
> David Mills
> Senior DevOps Engineer
>
>  E: mailto:david.mills at acusensus.com
>  M: +61 411 513 404
>  W:http://acusensus.com/
>
>
>
> DISCLAIMER: Acusensus puts the privacy and security of its clients, its
> data and information at the core of everything we do. The information
> contained in this email (including attachments) is intended only for the
> use of the person(s) to whom it is addressed to, as it may be confidential
> and contain legally privileged information. If you have received this email
> in error, please delete all copies and notify the sender immediately. Any
> views or opinions presented are solely those of the author and do not
> necessarily represent the views of Acusensus Pty Ltd. Please consider the
> environment before printing this email.
>
>

-- 
DISCLAIMER: Acusensus puts the privacy and security of its clients, its 
data and information at the core of everything we do. The information 
contained in this email (including attachments) is intended only for the 
use of the person(s) to whom it is addressed to, as it may be confidential 
and contain legally privileged information. If you have received this email 
in error, please delete all copies and notify the sender immediately. Any 
views or opinions presented are
solely those of the author and do not 
necessarily represent the views of Acusensus
Pty Ltd. Please consider the 
environment
before printing this email.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210708/fcd68076/attachment.htm>

From squid3 at treenet.co.nz  Thu Jul  8 02:17:13 2021
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 8 Jul 2021 14:17:13 +1200
Subject: [squid-users] Ubuntu 20.04 "apt update" issues behind a VPN and
 Squid proxy
In-Reply-To: <CAF28NibjRsM8gdcoqMC=X-btNMVswsersd3QZTLurgk-=bLVAA@mail.gmail.com>
References: <CAF28NibkN+CrDDM+2APUKA1rba_6BjZvoDAF11wXCSaFmHSh9Q@mail.gmail.com>
 <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAKGjfS9pLRpMrWAgDPs7Rm4BAAAAAA==@gmail.com>
 <CAF28NibjRsM8gdcoqMC=X-btNMVswsersd3QZTLurgk-=bLVAA@mail.gmail.com>
Message-ID: <1f5626ce-dea3-bc16-77f8-c9c2fe82b333@treenet.co.nz>



On 8/07/21 11:44 am, David Mills wrote:
> Hi Eliezer,
> 
> We have:
> 
> /etc/apt/apt.conf:
> 
>     Acquire::http::proxy
>     "http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128/
>     <http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128/>";
>     Acquire::https::proxy
>     "http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128/
>     <http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128/>";
> 
> 
> /etc/apt/sources.list (comment lines removed for brevity)
> 
>     deb https://mirror.aarnet.edu.au/ubuntu/
>     <https://mirror.aarnet.edu.au/ubuntu/> focal main restricted
>     deb https://mirror.aarnet.edu.au/ubuntu/
>     <https://mirror.aarnet.edu.au/ubuntu/> focal-updates main restricted
>     deb https://mirror.aarnet.edu.au/ubuntu/
>     <https://mirror.aarnet.edu.au/ubuntu/> focal-updates universe
>     deb https://mirror.aarnet.edu.au/ubuntu/
>     <https://mirror.aarnet.edu.au/ubuntu/> focal multiverse
>     deb https://mirror.aarnet.edu.au/ubuntu/
>     <https://mirror.aarnet.edu.au/ubuntu/> focal-updates multiverse
>     deb https://mirror.aarnet.edu.au/ubuntu/
>     <https://mirror.aarnet.edu.au/ubuntu/> focal-backports main
>     restricted universe multiverse
>     deb https://mirror.aarnet.edu.au/ubuntu
>     <https://mirror.aarnet.edu.au/ubuntu> focal-security main restricted
>     deb https://mirror.aarnet.edu.au/ubuntu
>     <https://mirror.aarnet.edu.au/ubuntu> focal-security universe
>     deb https://mirror.aarnet.edu.au/ubuntu
>     <https://mirror.aarnet.edu.au/ubuntu> focal-security multiverse
> 
> 
> squid.conf
> 
...
>     #
>     # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
>     #
> 
>     # Redirect HTTP to HTTPS
>     acl port_80 port 80
>     acl gstatic dstdomain www.gstatic.com <http://www.gstatic.com>
>     http_access deny port_80 gstatic
>     deny_info 301:https://%H%R gstatic
> 
>     acl avpc dstdomain crop-assessment.acusensus-vpc
>     http_access deny port_80 avpc
>     deny_info 302:<company url> avpc
> 
> 
>     # Deny HTTP
>     http_access deny port_80
> 
>     # Whitelist of allowed sites
>     acl allowed_http_sites dstdomain "/etc/squid/squid.allowed.sites.txt"
>     http_access allow allowed_http_sites vpc_cidr
> 

Is the "mirror.aarnet.edu.au" or a wildcard matching it listed in file 
squid.allowed.sites.txt ?

(I assume so, but checking in case it is that simple).


>     # And finally deny all other access to this proxy
>     http_access deny all
> 
>     # Squid normally listens to port 3128
>     http_port 3128 ssl-bump cert=/etc/squid/cert.pem
>     acl allowed_https_sites ssl::server_name
>     "/etc/squid/squid.allowed.sites.txt"
>     acl step1 at_step SslBump1
>     acl step2 at_step SslBump2
>     acl step3 at_step SslBump3
>     ssl_bump peek step1 all
>     ssl_bump peek step2 allowed_https_sites
>     ssl_bump splice step3 allowed_https_sites
>     ssl_bump terminate step2 all
> 
>     # Uncomment and adjust the following to add a disk cache directory.
>     #cache_dir ufs /var/spool/squid 100 16 256
> 
>     # Leave coredumps in the first cache dir
>     coredump_dir /var/spool/squid
>     #
>     # Add any of your own refresh_pattern entries above these.
>     #
>     refresh_pattern ^ftp: 1440 20% 10080
>     refresh_pattern ^gopher: 1440 0% 1440
>     refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
>     refresh_pattern . 0 20% 4320
> 
> 
> 
> Squid 3.5 is running on an EC2 instance running Amazon Linux 2. I'll 
> answer the questions you asked Ben for extra info.
> ip address:
> 
>     1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN
>     group default qlen 1000
>      ? ? link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
>      ? ? inet 127.0.0.1/8 <http://127.0.0.1/8> scope host lo
>      ? ? ? ?valid_lft forever preferred_lft forever
>      ? ? inet6 ::1/128 scope host
>      ? ? ? ?valid_lft forever preferred_lft forever
>     2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9001 qdisc mq state
>     UP group default qlen 1000
>      ? ? link/ether 02:1b:15:b8:9a:06 brd ff:ff:ff:ff:ff:ff
>      ? ? inet 10.0.12.111/24 <http://10.0.12.111/24> brd 10.0.12.255
>     scope global dynamic eth0
>      ? ? ? ?valid_lft 2393sec preferred_lft 2393sec
>      ? ? inet6 fe80::1b:15ff:feb8:9a06/64 scope link
>      ? ? ? ?valid_lft forever preferred_lft forever
> 
> 
> ip rule
> 
>     0: from all lookup local
>     32766: from all lookup main
>     32767: from all lookup default 
> 
> 
> ip route show
> 
>     default via 10.0.12.1 dev eth0
>     10.0.12.0/24 <http://10.0.12.0/24> dev eth0 proto kernel scope link
>     src 10.0.12.111
>     169.254.169.254 dev eth0
> 
> 


The traffic from Squid to the AArnet server is apparently using IPv6. Is 
that routing setup properly too?


...

>     From: squid-users On Behalf Of David Mills
>     Sent: Wednesday, July 7, 2021 2:26 AM
...
>     We have tried upgrading one to 20.04. Same setup. From the command
>     line curl or wget can happily download an Ubuntu package from the
>     Ubuntu Mirror site we use. But "apt update" gets lots of "IGN:"
>     timeouts and errors.
> 
>     The package we test curl with is
>     https://mirror.aarnet.edu.au/ubuntu/pool/main/c/curl/curl_7.68.0-1ubuntu2.5_amd64.deb
>     <https://mirror.aarnet.edu.au/ubuntu/pool/main/c/curl/curl_7.68.0-1ubuntu2.5_amd64.deb>
> 
>     The Squid log shows a line the doesn't occur for the successful
>     18.04 "apt updates":
>     1625190959.233? ? ?81 10.0.11.191 TAG_NONE/200 0 CONNECT
>     http://mirror.aarnet.edu.au:443 <http://mirror.aarnet.edu.au:443> -
>     HIER_DIRECT/2001:388:30bc:cafe::beef -
> 

With Ubuntu 20.04 you should have received Squid-4 (v4.10 or later). 
Which logs a few things differently from Squid-3.5, particularly for 
SSL-Bump activity and client connections that lack HTTP messages.

The above log line shows SSL-Bump activity. At least step2 was reached, 
possibly also step3. Looking at this a little closer to see if it 
completes fine or has unseen issues would be my next point of approach.

To debug what is happening with SSL-Bump use "debug_options ALL1, 11,2 
83,5" and check the resulting cache.log.



>     The full output of an attempt to update is:
>     Ign:1 https://mirror.aarnet.edu.au/ubuntu
>     <https://mirror.aarnet.edu.au/ubuntu> focal InRelease
>     Ign:2 https://mirror.aarnet.edu.au/ubuntu
>     <https://mirror.aarnet.edu.au/ubuntu> focal-updates InRelease
>     Ign:3 https://mirror.aarnet.edu.au/ubuntu
>     <https://mirror.aarnet.edu.au/ubuntu> focal-backports InRelease
>     Ign:4 https://mirror.aarnet.edu.au/ubuntu
>     <https://mirror.aarnet.edu.au/ubuntu> focal-security InRelease


These "Ign" are fine. They just mean that apt has determined those files 
it has cached are up-to-date and do not need to be re-fetched right now.

The below "Err" are the problem:

>     Err:5 https://mirror.aarnet.edu.au/ubuntu
>     <https://mirror.aarnet.edu.au/ubuntu> focal Release
>      ? Could not wait for server fd - select (11: Resource temporarily
>     unavailable) [IP: 10.0.11.82 3128]...
> 
>     While running, the line
>     0% [Connecting to HTTP proxy
>     (http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128
>     <http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128>)]
>     appears often and hang for a while.
> 
>     I've tried upping the squid logging and allowing all, but they
>     didn't offer any additional information about the issue.
> 

Your squid.conf looks fine, assuming the same http_access rules were 
used in your working version.


I suspect the issue is related to one or more of:

  * IPv6 routing

  * ICMP config issues (maybe outside your network)

  * SSL-Bump issues processing the client or server handshake traffic
    typically seen with OpenSSL library version or config mismatches 
between Squid, client and server.

  * network timeouts affecting Squid


HTH
Amos


From david.mills at acusensus.com  Thu Jul  8 05:01:54 2021
From: david.mills at acusensus.com (David Mills)
Date: Thu, 8 Jul 2021 15:01:54 +1000
Subject: [squid-users] Ubuntu 20.04 "apt update" issues behind a VPN and
 Squid proxy
In-Reply-To: <1f5626ce-dea3-bc16-77f8-c9c2fe82b333@treenet.co.nz>
References: <CAF28NibkN+CrDDM+2APUKA1rba_6BjZvoDAF11wXCSaFmHSh9Q@mail.gmail.com>
 <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAKGjfS9pLRpMrWAgDPs7Rm4BAAAAAA==@gmail.com>
 <CAF28NibjRsM8gdcoqMC=X-btNMVswsersd3QZTLurgk-=bLVAA@mail.gmail.com>
 <1f5626ce-dea3-bc16-77f8-c9c2fe82b333@treenet.co.nz>
Message-ID: <CAF28NiaiPPN7qqH9oY+UtgNQUjmUHyvf4-08nNP83AhnRK6VSw@mail.gmail.com>

Hi Amos,

Thanks for the info.

Yes, "mirror.aarnet.edu.au" is in the whitelist. IPv6 could be an issue as
I believe AWS ELBs may not support.

We'll try the logging you suggest and perhaps an upgrade to 4.0 if we have
no joy with 3.5.

Regards,

David Mills

Senior DevOps Engineer

 E: david.mills at acusensus.com

 M: +61 411 513 404

 W: acusensus.com





On Thu, 8 Jul 2021 at 12:19, Amos Jeffries <squid3 at treenet.co.nz> wrote:

>
>
> On 8/07/21 11:44 am, David Mills wrote:
> > Hi Eliezer,
> >
> > We have:
> >
> > /etc/apt/apt.conf:
> >
> >     Acquire::http::proxy
> >     "
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128/
> >     <
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128/
> >";
> >     Acquire::https::proxy
> >     "
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128/
> >     <
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128/
> >";
> >
> >
> > /etc/apt/sources.list (comment lines removed for brevity)
> >
> >     deb https://mirror.aarnet.edu.au/ubuntu/
> >     <https://mirror.aarnet.edu.au/ubuntu/> focal main restricted
> >     deb https://mirror.aarnet.edu.au/ubuntu/
> >     <https://mirror.aarnet.edu.au/ubuntu/> focal-updates main restricted
> >     deb https://mirror.aarnet.edu.au/ubuntu/
> >     <https://mirror.aarnet.edu.au/ubuntu/> focal-updates universe
> >     deb https://mirror.aarnet.edu.au/ubuntu/
> >     <https://mirror.aarnet.edu.au/ubuntu/> focal multiverse
> >     deb https://mirror.aarnet.edu.au/ubuntu/
> >     <https://mirror.aarnet.edu.au/ubuntu/> focal-updates multiverse
> >     deb https://mirror.aarnet.edu.au/ubuntu/
> >     <https://mirror.aarnet.edu.au/ubuntu/> focal-backports main
> >     restricted universe multiverse
> >     deb https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal-security main restricted
> >     deb https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal-security universe
> >     deb https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal-security multiverse
> >
> >
> > squid.conf
> >
> ...
> >     #
> >     # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> >     #
> >
> >     # Redirect HTTP to HTTPS
> >     acl port_80 port 80
> >     acl gstatic dstdomain www.gstatic.com <http://www.gstatic.com>
> >     http_access deny port_80 gstatic
> >     deny_info 301:https://%H%R gstatic
> >
> >     acl avpc dstdomain crop-assessment.acusensus-vpc
> >     http_access deny port_80 avpc
> >     deny_info 302:<company url> avpc
> >
> >
> >     # Deny HTTP
> >     http_access deny port_80
> >
> >     # Whitelist of allowed sites
> >     acl allowed_http_sites dstdomain "/etc/squid/squid.allowed.sites.txt"
> >     http_access allow allowed_http_sites vpc_cidr
> >
>
> Is the "mirror.aarnet.edu.au" or a wildcard matching it listed in file
> squid.allowed.sites.txt ?
>
> (I assume so, but checking in case it is that simple).
>
>
> >     # And finally deny all other access to this proxy
> >     http_access deny all
> >
> >     # Squid normally listens to port 3128
> >     http_port 3128 ssl-bump cert=/etc/squid/cert.pem
> >     acl allowed_https_sites ssl::server_name
> >     "/etc/squid/squid.allowed.sites.txt"
> >     acl step1 at_step SslBump1
> >     acl step2 at_step SslBump2
> >     acl step3 at_step SslBump3
> >     ssl_bump peek step1 all
> >     ssl_bump peek step2 allowed_https_sites
> >     ssl_bump splice step3 allowed_https_sites
> >     ssl_bump terminate step2 all
> >
> >     # Uncomment and adjust the following to add a disk cache directory.
> >     #cache_dir ufs /var/spool/squid 100 16 256
> >
> >     # Leave coredumps in the first cache dir
> >     coredump_dir /var/spool/squid
> >     #
> >     # Add any of your own refresh_pattern entries above these.
> >     #
> >     refresh_pattern ^ftp: 1440 20% 10080
> >     refresh_pattern ^gopher: 1440 0% 1440
> >     refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
> >     refresh_pattern . 0 20% 4320
> >
> >
> >
> > Squid 3.5 is running on an EC2 instance running Amazon Linux 2. I'll
> > answer the questions you asked Ben for extra info.
> > ip address:
> >
> >     1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN
> >     group default qlen 1000
> >          link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
> >          inet 127.0.0.1/8 <http://127.0.0.1/8> scope host lo
> >             valid_lft forever preferred_lft forever
> >          inet6 ::1/128 scope host
> >             valid_lft forever preferred_lft forever
> >     2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9001 qdisc mq state
> >     UP group default qlen 1000
> >          link/ether 02:1b:15:b8:9a:06 brd ff:ff:ff:ff:ff:ff
> >          inet 10.0.12.111/24 <http://10.0.12.111/24> brd 10.0.12.255
> >     scope global dynamic eth0
> >             valid_lft 2393sec preferred_lft 2393sec
> >          inet6 fe80::1b:15ff:feb8:9a06/64 scope link
> >             valid_lft forever preferred_lft forever
> >
> >
> > ip rule
> >
> >     0: from all lookup local
> >     32766: from all lookup main
> >     32767: from all lookup default
> >
> >
> > ip route show
> >
> >     default via 10.0.12.1 dev eth0
> >     10.0.12.0/24 <http://10.0.12.0/24> dev eth0 proto kernel scope link
> >     src 10.0.12.111
> >     169.254.169.254 dev eth0
> >
> >
>
>
> The traffic from Squid to the AArnet server is apparently using IPv6. Is
> that routing setup properly too?
>
>
> ...
>
> >     From: squid-users On Behalf Of David Mills
> >     Sent: Wednesday, July 7, 2021 2:26 AM
> ...
> >     We have tried upgrading one to 20.04. Same setup. From the command
> >     line curl or wget can happily download an Ubuntu package from the
> >     Ubuntu Mirror site we use. But "apt update" gets lots of "IGN:"
> >     timeouts and errors.
> >
> >     The package we test curl with is
> >
> https://mirror.aarnet.edu.au/ubuntu/pool/main/c/curl/curl_7.68.0-1ubuntu2.5_amd64.deb
> >     <
> https://mirror.aarnet.edu.au/ubuntu/pool/main/c/curl/curl_7.68.0-1ubuntu2.5_amd64.deb
> >
> >
> >     The Squid log shows a line the doesn't occur for the successful
> >     18.04 "apt updates":
> >     1625190959.233     81 10.0.11.191 TAG_NONE/200 0 CONNECT
> >     http://mirror.aarnet.edu.au:443 <http://mirror.aarnet.edu.au:443> -
> >     HIER_DIRECT/2001:388:30bc:cafe::beef -
> >
>
> With Ubuntu 20.04 you should have received Squid-4 (v4.10 or later).
> Which logs a few things differently from Squid-3.5, particularly for
> SSL-Bump activity and client connections that lack HTTP messages.
>
> The above log line shows SSL-Bump activity. At least step2 was reached,
> possibly also step3. Looking at this a little closer to see if it
> completes fine or has unseen issues would be my next point of approach.
>
> To debug what is happening with SSL-Bump use "debug_options ALL1, 11,2
> 83,5" and check the resulting cache.log.
>
>
>
> >     The full output of an attempt to update is:
> >     Ign:1 https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal InRelease
> >     Ign:2 https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal-updates InRelease
> >     Ign:3 https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal-backports InRelease
> >     Ign:4 https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal-security InRelease
>
>
> These "Ign" are fine. They just mean that apt has determined those files
> it has cached are up-to-date and do not need to be re-fetched right now.
>
> The below "Err" are the problem:
>
> >     Err:5 https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal Release
> >        Could not wait for server fd - select (11: Resource temporarily
> >     unavailable) [IP: 10.0.11.82 3128]...
> >
> >     While running, the line
> >     0% [Connecting to HTTP proxy
> >     (
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128
> >     <
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128>)]
> >     appears often and hang for a while.
> >
> >     I've tried upping the squid logging and allowing all, but they
> >     didn't offer any additional information about the issue.
> >
>
> Your squid.conf looks fine, assuming the same http_access rules were
> used in your working version.
>
>
> I suspect the issue is related to one or more of:
>
>   * IPv6 routing
>
>   * ICMP config issues (maybe outside your network)
>
>   * SSL-Bump issues processing the client or server handshake traffic
>     typically seen with OpenSSL library version or config mismatches
> between Squid, client and server.
>
>   * network timeouts affecting Squid
>
>
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

-- 
DISCLAIMER: Acusensus puts the privacy and security of its clients, its 
data and information at the core of everything we do. The information 
contained in this email (including attachments) is intended only for the 
use of the person(s) to whom it is addressed to, as it may be confidential 
and contain legally privileged information. If you have received this email 
in error, please delete all copies and notify the sender immediately. Any 
views or opinions presented are
solely those of the author and do not 
necessarily represent the views of Acusensus
Pty Ltd. Please consider the 
environment
before printing this email.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210708/5be0fa66/attachment.htm>

From david.mills at acusensus.com  Thu Jul  8 05:17:42 2021
From: david.mills at acusensus.com (David Mills)
Date: Thu, 8 Jul 2021 15:17:42 +1000
Subject: [squid-users] Ubuntu 20.04 "apt update" issues behind a VPN and
 Squid proxy
In-Reply-To: <1f5626ce-dea3-bc16-77f8-c9c2fe82b333@treenet.co.nz>
References: <CAF28NibkN+CrDDM+2APUKA1rba_6BjZvoDAF11wXCSaFmHSh9Q@mail.gmail.com>
 <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAKGjfS9pLRpMrWAgDPs7Rm4BAAAAAA==@gmail.com>
 <CAF28NibjRsM8gdcoqMC=X-btNMVswsersd3QZTLurgk-=bLVAA@mail.gmail.com>
 <1f5626ce-dea3-bc16-77f8-c9c2fe82b333@treenet.co.nz>
Message-ID: <CAF28Nia-w-wisTFdkJEW5jVDmJRyspZ=N7Af2Kx2GY4EuNer2w@mail.gmail.com>

Hi Amos,

You said

> The traffic from Squid to the AArnet server is apparently using IPv6. Is
> that routing setup properly too?
>

The output of "ip address" shows both IPv4 and IPv6. What led you to make
the above conclusion?

Regards,

David Mills

Senior DevOps Engineer

 E: david.mills at acusensus.com

 M: +61 411 513 404

 W: acusensus.com





On Thu, 8 Jul 2021 at 12:19, Amos Jeffries <squid3 at treenet.co.nz> wrote:

>
>
> On 8/07/21 11:44 am, David Mills wrote:
> > Hi Eliezer,
> >
> > We have:
> >
> > /etc/apt/apt.conf:
> >
> >     Acquire::http::proxy
> >     "
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128/
> >     <
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128/
> >";
> >     Acquire::https::proxy
> >     "
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128/
> >     <
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128/
> >";
> >
> >
> > /etc/apt/sources.list (comment lines removed for brevity)
> >
> >     deb https://mirror.aarnet.edu.au/ubuntu/
> >     <https://mirror.aarnet.edu.au/ubuntu/> focal main restricted
> >     deb https://mirror.aarnet.edu.au/ubuntu/
> >     <https://mirror.aarnet.edu.au/ubuntu/> focal-updates main restricted
> >     deb https://mirror.aarnet.edu.au/ubuntu/
> >     <https://mirror.aarnet.edu.au/ubuntu/> focal-updates universe
> >     deb https://mirror.aarnet.edu.au/ubuntu/
> >     <https://mirror.aarnet.edu.au/ubuntu/> focal multiverse
> >     deb https://mirror.aarnet.edu.au/ubuntu/
> >     <https://mirror.aarnet.edu.au/ubuntu/> focal-updates multiverse
> >     deb https://mirror.aarnet.edu.au/ubuntu/
> >     <https://mirror.aarnet.edu.au/ubuntu/> focal-backports main
> >     restricted universe multiverse
> >     deb https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal-security main restricted
> >     deb https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal-security universe
> >     deb https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal-security multiverse
> >
> >
> > squid.conf
> >
> ...
> >     #
> >     # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> >     #
> >
> >     # Redirect HTTP to HTTPS
> >     acl port_80 port 80
> >     acl gstatic dstdomain www.gstatic.com <http://www.gstatic.com>
> >     http_access deny port_80 gstatic
> >     deny_info 301:https://%H%R gstatic
> >
> >     acl avpc dstdomain crop-assessment.acusensus-vpc
> >     http_access deny port_80 avpc
> >     deny_info 302:<company url> avpc
> >
> >
> >     # Deny HTTP
> >     http_access deny port_80
> >
> >     # Whitelist of allowed sites
> >     acl allowed_http_sites dstdomain "/etc/squid/squid.allowed.sites.txt"
> >     http_access allow allowed_http_sites vpc_cidr
> >
>
> Is the "mirror.aarnet.edu.au" or a wildcard matching it listed in file
> squid.allowed.sites.txt ?
>
> (I assume so, but checking in case it is that simple).
>
>
> >     # And finally deny all other access to this proxy
> >     http_access deny all
> >
> >     # Squid normally listens to port 3128
> >     http_port 3128 ssl-bump cert=/etc/squid/cert.pem
> >     acl allowed_https_sites ssl::server_name
> >     "/etc/squid/squid.allowed.sites.txt"
> >     acl step1 at_step SslBump1
> >     acl step2 at_step SslBump2
> >     acl step3 at_step SslBump3
> >     ssl_bump peek step1 all
> >     ssl_bump peek step2 allowed_https_sites
> >     ssl_bump splice step3 allowed_https_sites
> >     ssl_bump terminate step2 all
> >
> >     # Uncomment and adjust the following to add a disk cache directory.
> >     #cache_dir ufs /var/spool/squid 100 16 256
> >
> >     # Leave coredumps in the first cache dir
> >     coredump_dir /var/spool/squid
> >     #
> >     # Add any of your own refresh_pattern entries above these.
> >     #
> >     refresh_pattern ^ftp: 1440 20% 10080
> >     refresh_pattern ^gopher: 1440 0% 1440
> >     refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
> >     refresh_pattern . 0 20% 4320
> >
> >
> >
> > Squid 3.5 is running on an EC2 instance running Amazon Linux 2. I'll
> > answer the questions you asked Ben for extra info.
> > ip address:
> >
> >     1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN
> >     group default qlen 1000
> >          link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
> >          inet 127.0.0.1/8 <http://127.0.0.1/8> scope host lo
> >             valid_lft forever preferred_lft forever
> >          inet6 ::1/128 scope host
> >             valid_lft forever preferred_lft forever
> >     2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 9001 qdisc mq state
> >     UP group default qlen 1000
> >          link/ether 02:1b:15:b8:9a:06 brd ff:ff:ff:ff:ff:ff
> >          inet 10.0.12.111/24 <http://10.0.12.111/24> brd 10.0.12.255
> >     scope global dynamic eth0
> >             valid_lft 2393sec preferred_lft 2393sec
> >          inet6 fe80::1b:15ff:feb8:9a06/64 scope link
> >             valid_lft forever preferred_lft forever
> >
> >
> > ip rule
> >
> >     0: from all lookup local
> >     32766: from all lookup main
> >     32767: from all lookup default
> >
> >
> > ip route show
> >
> >     default via 10.0.12.1 dev eth0
> >     10.0.12.0/24 <http://10.0.12.0/24> dev eth0 proto kernel scope link
> >     src 10.0.12.111
> >     169.254.169.254 dev eth0
> >
> >
>
>
> The traffic from Squid to the AArnet server is apparently using IPv6. Is
> that routing setup properly too?
>
>
> ...
>
> >     From: squid-users On Behalf Of David Mills
> >     Sent: Wednesday, July 7, 2021 2:26 AM
> ...
> >     We have tried upgrading one to 20.04. Same setup. From the command
> >     line curl or wget can happily download an Ubuntu package from the
> >     Ubuntu Mirror site we use. But "apt update" gets lots of "IGN:"
> >     timeouts and errors.
> >
> >     The package we test curl with is
> >
> https://mirror.aarnet.edu.au/ubuntu/pool/main/c/curl/curl_7.68.0-1ubuntu2.5_amd64.deb
> >     <
> https://mirror.aarnet.edu.au/ubuntu/pool/main/c/curl/curl_7.68.0-1ubuntu2.5_amd64.deb
> >
> >
> >     The Squid log shows a line the doesn't occur for the successful
> >     18.04 "apt updates":
> >     1625190959.233     81 10.0.11.191 TAG_NONE/200 0 CONNECT
> >     http://mirror.aarnet.edu.au:443 <http://mirror.aarnet.edu.au:443> -
> >     HIER_DIRECT/2001:388:30bc:cafe::beef -
> >
>
> With Ubuntu 20.04 you should have received Squid-4 (v4.10 or later).
> Which logs a few things differently from Squid-3.5, particularly for
> SSL-Bump activity and client connections that lack HTTP messages.
>
> The above log line shows SSL-Bump activity. At least step2 was reached,
> possibly also step3. Looking at this a little closer to see if it
> completes fine or has unseen issues would be my next point of approach.
>
> To debug what is happening with SSL-Bump use "debug_options ALL1, 11,2
> 83,5" and check the resulting cache.log.
>
>
>
> >     The full output of an attempt to update is:
> >     Ign:1 https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal InRelease
> >     Ign:2 https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal-updates InRelease
> >     Ign:3 https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal-backports InRelease
> >     Ign:4 https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal-security InRelease
>
>
> These "Ign" are fine. They just mean that apt has determined those files
> it has cached are up-to-date and do not need to be re-fetched right now.
>
> The below "Err" are the problem:
>
> >     Err:5 https://mirror.aarnet.edu.au/ubuntu
> >     <https://mirror.aarnet.edu.au/ubuntu> focal Release
> >        Could not wait for server fd - select (11: Resource temporarily
> >     unavailable) [IP: 10.0.11.82 3128]...
> >
> >     While running, the line
> >     0% [Connecting to HTTP proxy
> >     (
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128
> >     <
> http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128>)]
> >     appears often and hang for a while.
> >
> >     I've tried upping the squid logging and allowing all, but they
> >     didn't offer any additional information about the issue.
> >
>
> Your squid.conf looks fine, assuming the same http_access rules were
> used in your working version.
>
>
> I suspect the issue is related to one or more of:
>
>   * IPv6 routing
>
>   * ICMP config issues (maybe outside your network)
>
>   * SSL-Bump issues processing the client or server handshake traffic
>     typically seen with OpenSSL library version or config mismatches
> between Squid, client and server.
>
>   * network timeouts affecting Squid
>
>
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

-- 
DISCLAIMER: Acusensus puts the privacy and security of its clients, its 
data and information at the core of everything we do. The information 
contained in this email (including attachments) is intended only for the 
use of the person(s) to whom it is addressed to, as it may be confidential 
and contain legally privileged information. If you have received this email 
in error, please delete all copies and notify the sender immediately. Any 
views or opinions presented are
solely those of the author and do not 
necessarily represent the views of Acusensus
Pty Ltd. Please consider the 
environment
before printing this email.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210708/87866144/attachment.htm>

From squid3 at treenet.co.nz  Thu Jul  8 09:08:22 2021
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 8 Jul 2021 21:08:22 +1200
Subject: [squid-users] Ubuntu 20.04 "apt update" issues behind a VPN and
 Squid proxy
In-Reply-To: <CAF28Nia-w-wisTFdkJEW5jVDmJRyspZ=N7Af2Kx2GY4EuNer2w@mail.gmail.com>
References: <CAF28NibkN+CrDDM+2APUKA1rba_6BjZvoDAF11wXCSaFmHSh9Q@mail.gmail.com>
 <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAKGjfS9pLRpMrWAgDPs7Rm4BAAAAAA==@gmail.com>
 <CAF28NibjRsM8gdcoqMC=X-btNMVswsersd3QZTLurgk-=bLVAA@mail.gmail.com>
 <1f5626ce-dea3-bc16-77f8-c9c2fe82b333@treenet.co.nz>
 <CAF28Nia-w-wisTFdkJEW5jVDmJRyspZ=N7Af2Kx2GY4EuNer2w@mail.gmail.com>
Message-ID: <97b6128c-d2c1-9cf7-1578-44a25fd633da@treenet.co.nz>

On 8/07/21 5:17 pm, David Mills wrote:
> Hi Amos,
> 
> You said
> 
>     The traffic from Squid to the AArnet server is apparently using
>     IPv6. Is
>     that routing setup properly too?
> 
> 
> The output of "ip address" shows both IPv4 and IPv6. What led you to 
> make the above conclusion?
> 

The server IP that Squid logged:

    HIER_DIRECT/2001:388:30bc:cafe::beef

Amos


From ben.goz87 at gmail.com  Thu Jul  8 10:48:15 2021
From: ben.goz87 at gmail.com (Ben Goz)
Date: Thu, 8 Jul 2021 13:48:15 +0300
Subject: [squid-users] TPROXY Error
In-Reply-To: <000001d77373$9addf630$d099e290$@gmail.com>
References: <CADAqQfwR4w-cFidq+8ea7zns=OUwyan6W1wXuLcrge4jSE4B9Q@mail.gmail.com>
 <000a01d7731f$7550a9c0$5ff1fd40$@gmail.com>
 <68332d40-ba49-f426-21b8-48602608690e@gmail.com>
 <000001d77373$9addf630$d099e290$@gmail.com>
Message-ID: <c6fb5b78-a36b-b422-25d8-a50749d37fee@gmail.com>

By the help of God.

It looks like the point of failure (?)

BTW, My kernel already contains the required tproxy drivers by default 
correct?


Regards,

Ben

On 08/07/2021 0:03, Eliezer Croitoru wrote:
> Hey Ben,
>
> You are missing the critical output of the full command:
> Ip route show table 100
>
> What you posted was:
>> 5.  the output of 'ip route show table 100'
$ ip route show table 100
local default dev lo scope host
> $ ip route show
> default via 8.13.140.14 dev bond0.212 proto static
> 1.21.213.0/24 dev bond0.213 proto kernel scope link src 1.21.213.1
> 8.11.39.248/30 dev enx00e04c3600d3 proto kernel scope link src 8.11.39.250
> 8.13.140.0/28 dev bond0.212 proto kernel scope link src 8.13.140.1
> 8.13.144.0/20 via 1.21.213.254 dev bond0.213
> 8.13.148.1 via 1.21.213.254 dev bond0.213
> ##
>
> It's important to see the relevant routing table.
> The linux Kernel have couple routing tables which each can contain different routing/forwarding table.
> If you want to understand a bit more you might be able to try and lookup for FIB.
> ( take a peek at: http://linux-ip.net/html/routing-tables.html)
>
> Eliezer
>
> -----Original Message-----
> From: Ben Goz <ben.goz87 at gmail.com>
> Sent: Wednesday, July 7, 2021 3:36 PM
> To: Eliezer Croitoru <ngtech1ltd at gmail.com>; squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] TPROXY Error
>
> By the help of God.
>
>
> Hi Eliezer,
>
> Thanks for your help.
>
> Please let me know if you need more information.
>
>
> Regards,
>
> Ben
>
> On 07/07/2021 14:01, Eliezer Croitoru wrote:
>> Hey Ben,
>>
>> I want to try and reset this issue because I am missing some technical
>> details.
>>
>> 1. What Linux Distro and what version are you using?'
> Ubuntu 20.04
>> 2. the output of 'ip address'
> $ ip address
> 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN
> group default qlen 1000
>       link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
>       inet 127.0.0.1/8 scope host lo
>          valid_lft forever preferred_lft forever
>       inet6 ::1/128 scope host
>          valid_lft forever preferred_lft forever
> 2: ens1f0: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc mq
> master bond0 state UP group default qlen 1000
>       link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
> 3: ens1f1: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc mq
> master bond0 state UP group default qlen 1000
>       link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
> 4: usb0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group
> default qlen 1000
>       link/ether ca:13:59:65:c2:56 brd ff:ff:ff:ff:ff:ff
> 5: enx00e04c3600d3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc
> fq_codel state UP group default qlen 1000
>       link/ether 00:e0:4c:36:00:d3 brd ff:ff:ff:ff:ff:ff
>       inet 8.11.39.250/30 brd 8.11.39.251 scope global enx00e04c3600d3
>          valid_lft forever preferred_lft forever
>       inet6 fe80::2e0:4cff:fe36:d3/64 scope link
>          valid_lft forever preferred_lft forever
> 6: bond0: <BROADCAST,MULTICAST,MASTER,UP,LOWER_UP> mtu 1500 qdisc
> noqueue state UP group default qlen 1000
>       link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
>       inet6 fe80::b859:58ff:fe58:232b/64 scope link
>          valid_lft forever preferred_lft forever
> 7: bond0.212 at bond0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc
> noqueue state UP group default qlen 1000
>       link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
>       inet 8.13.140.1/28 brd 8.13.140.15 scope global bond0.212
>          valid_lft forever preferred_lft forever
>       inet6 fe80::b859:58ff:fe58:232b/64 scope link
>          valid_lft forever preferred_lft forever
> 8: bond0.213 at bond0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc
> noqueue state UP group default qlen 1000
>       link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
>       inet 1.21.213.1/24 brd 1.21.213.255 scope global bond0.213
>          valid_lft forever preferred_lft forever
>       inet6 fe80::b859:58ff:fe58:232b/64 scope link
>          valid_lft forever preferred_lft forever
>> 3. the output of 'ip rule'
> $ ip rule
> 0:    from all lookup local
> 32762:    from all fwmark 0x1 lookup 100
> 32763:    from all fwmark 0x1 lookup 100
> 32764:    from all fwmark 0x1 lookup 100
> 32765:    from all fwmark 0x1 lookup 100
> 32766:    from all lookup main
> 32767:    from all lookup default
>
>> 4.  the output of 'ip route show'
> $ ip route show
> default via 8.13.140.14 dev bond0.212 proto static
> 1.21.213.0/24 dev bond0.213 proto kernel scope link src 1.21.213.1
> 8.11.39.248/30 dev enx00e04c3600d3 proto kernel scope link src 8.11.39.250
> 8.13.140.0/28 dev bond0.212 proto kernel scope link src 8.13.140.1
> 8.13.144.0/20 via 1.21.213.254 dev bond0.213
> 8.13.148.1 via 1.21.213.254 dev bond0.213
>
>> 5.  the output of 'ip route show table 100'
> $ ip route show
> default via 8.13.140.14 dev bond0.212 proto static
> 1.21.213.0/24 dev bond0.213 proto kernel scope link src 1.21.213.1
> 8.11.39.248/30 dev enx00e04c3600d3 proto kernel scope link src 8.11.39.250
> 8.13.140.0/28 dev bond0.212 proto kernel scope link src 8.13.140.1
> 8.13.144.0/20 via 1.21.213.254 dev bond0.213
> 8.13.148.1 via 1.21.213.254 dev bond0.213
>> 6. the output of 'iptables-save'
>
> $ sudo iptables-save
> # Generated by iptables-save v1.8.4 on Wed Jul  7 12:25:05 2021
> *mangle
> :PREROUTING ACCEPT [72898710:6084386298]
> :INPUT ACCEPT [0:0]
> :FORWARD ACCEPT [0:0]
> :OUTPUT ACCEPT [0:0]
> :POSTROUTING ACCEPT [0:0]
> :DIVERT - [0:0]
> -A PREROUTING -p tcp -m socket -j DIVERT
> -A PREROUTING -i bond0.213 -p tcp -m tcp --dport 80 -j TPROXY --on-port
> 15644 --on-ip 0.0.0.0 --tproxy-mark 0x1/0x1
> -A PREROUTING -i bond0.213 -p tcp -m tcp --dport 443 -j TPROXY --on-port
> 15645 --on-ip 0.0.0.0 --tproxy-mark 0x1/0x1
> -A INPUT -j ACCEPT
> -A FORWARD -j ACCEPT
> -A OUTPUT -j ACCEPT
> -A POSTROUTING -j ACCEPT
> -A DIVERT -j MARK --set-xmark 0x1/0xffffffff
> -A DIVERT -j ACCEPT
> COMMIT
> # Completed on Wed Jul  7 12:25:05 2021
> # Generated by iptables-save v1.8.4 on Wed Jul  7 12:25:05 2021
> *nat
> :PREROUTING ACCEPT [26338415:1392747531]
> :INPUT ACCEPT [820462:44161193]
> :OUTPUT ACCEPT [1053:92773]
> :POSTROUTING ACCEPT [25514534:1348449899]
> -A PREROUTING -i eth1 -p udp -m udp --dport 53 -j REDIRECT --to-ports 53
> -A PREROUTING -i eth1 -p tcp -m tcp --dport 53 -j REDIRECT --to-ports 53
> COMMIT
> # Completed on Wed Jul  7 12:25:05 2021
> # Generated by iptables-save v1.8.4 on Wed Jul  7 12:25:05 2021
> *filter
> :INPUT ACCEPT [5045387:2170630036]
> :FORWARD ACCEPT [72544426:6194710400]
> :OUTPUT ACCEPT [2471930:252759773]
> COMMIT
> # Completed on Wed Jul  7 12:25:05 20
>
>> 7. the output of 'nft -nn list ruleset' (if exists on the OS)
> Doesn't exists.
>> 8. the output of your squid.conf
> $ cat squid.conf
> #
> # Recommended minimum configuration:
> #
>
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 0.0.0.1-0.255.255.255    # RFC 1122 "this" network (LAN)
> acl localnet src 10.0.0.0/8        # RFC 1918 local private network (LAN)
> acl localnet src 100.64.0.0/10        # RFC 6598 shared address space (CGN)
> acl localnet src 169.254.0.0/16     # RFC 3927 link-local (directly
> plugged) machines
> acl localnet src 172.16.0.0/12        # RFC 1918 local private network (LAN)
> acl localnet src 192.168.0.0/16        # RFC 1918 local private network
> (LAN)
> acl localnet src fc00::/7           # RFC 4193 local private network range
> acl localnet src fe80::/10          # RFC 4291 link-local (directly
> plugged) machines
>
> acl SSL_ports port 443
> acl Safe_ports port 80        # http
> acl Safe_ports port 21        # ftp
> acl Safe_ports port 443        # https
> acl Safe_ports port 70        # gopher
> acl Safe_ports port 210        # wais
> acl Safe_ports port 1025-65535    # unregistered ports
> acl Safe_ports port 280        # http-mgmt
> acl Safe_ports port 488        # gss-http
> acl Safe_ports port 591        # filemaker
> acl Safe_ports port 777        # multiling http
> acl CONNECT method CONNECT
>
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
>
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
>
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
>
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
>
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
>
> # And finally deny all other access to this proxy
> #http_access deny all
>
> http_access allow all
>
> # Squid normally listens to port 3128
> http_port 15643
> http_port 15644 tproxy
> https_port 15645 ssl-bump tproxy generate-host-certificates=on
> options=ALL dynamic_cert_mem_cache_size=4MB
> cert=/usr/local/squid/etc/ssl_cert/myCA.pem
> dhparams=/usr/local/squid/etc/dhparam.pem
> always_direct allow all
> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLInterceptRegexp_always ssl::server_name_regex -i xxx
> acl NoSSLIntercept ssl::server_name  "xxx"
> acl NoSSLInterceptRegexp ssl::server_name_regex -i "xxx"
> ssl_bump splice NoSSLInterceptRegexp_always
> ssl_bump splice NoSSLIntercept
> ssl_bump splice NoSSLInterceptRegexp
> ssl_bump peek DiscoverSNIHost
> ssl_bump bump all
> sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
> /var/lib/ssl_db -M 4MB
> sslcrtd_children 32 startup=15 idle=3
> #sslproxy_capath /etc/ssl/certs
>
> # Uncomment and adjust the following to add a disk cache directory.
> #cache_dir ufs /usr/local/squid/var/cache/squid 100 16 256
>
> # Leave coredumps in the first cache dir
> coredump_dir /usr/local/squid/var/cache/squid
>
> #
> # Add any of your own refresh_pattern entries above these.
> #
> refresh_pattern ^ftp:        1440    20%    10080
> refresh_pattern ^gopher:    1440    0%    1440
> refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
> refresh_pattern .        0    20%    4320
>
> range_offset_limit -1
>
> dns_v4_first on
> forwarded_for off
> cache deny all
>> 9. the output of 'squid -v'
> $ ./squid -v
> Squid Cache: Version 4.15
> Service Name: squid
>
> This binary uses OpenSSL 1.1.1f  31 Mar 2020. For legal restrictions on
> distribution see https://www.openssl.org/source/license.html
>
> configure options:  '--with-openssl' '--enable-ssl-crtd' '--enable-ecap'
> '--enable-linux-netfilter' --enable-ltdl-convenience
>
>> 10. the output of 'uname -a'
> uname -a
> Linux xxx 5.4.0-77-generic #86-Ubuntu SMP Thu Jun 17 02:35:03 UTC 2021
> x86_64 x86_64 x86_64 GNU/Linux
>> Once we will have all the above details (reducing/modifying any private
>> details) we can try to maybe help you.
>>
>> Eliezer
>>
>> -----Original Message-----
>> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
>> Ben Goz
>> Sent: Wednesday, June 30, 2021 3:16 PM
>> To: squid-users at lists.squid-cache.org
>> Subject: [squid-users] TPROXY Error
>>
>>    By the help of God.
>>
>> Hi All,
>> I'm trying to configure squid as a transparent proxy using TPROXY.
>> The machine I'm using has 2 NICs, one for input and the other one for
>> output traffic.
>> The TPROXY iptables rules are configured on the input NIC.
>> It looks like iptables TPROXY redirect works but squid prints out the
>> following error:
>>
>> ERROR: NAT/TPROXY lookup failed to locate original IPs on
>> local=xxx:443 remote=xxx:49471 FD 14 flags=17
>>
>> I think I loaded all TPROXY required kernel modules.
>>
>> The ip forwarding works fine without the iptables rules. and I don't
>> see any squid ERROR on getsockopt
>>
>> Please let me know what I'm missing?
>>
>> Thanks,
>> Ben
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>


From ngtech1ltd at gmail.com  Thu Jul  8 19:41:28 2021
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Thu, 8 Jul 2021 22:41:28 +0300
Subject: [squid-users] Ubuntu 20.04 "apt update" issues behind a VPN and
 Squid proxy
In-Reply-To: <CAF28NibkN+CrDDM+2APUKA1rba_6BjZvoDAF11wXCSaFmHSh9Q@mail.gmail.com>
References: <CAF28NibkN+CrDDM+2APUKA1rba_6BjZvoDAF11wXCSaFmHSh9Q@mail.gmail.com>
Message-ID: <001d01d77431$3fe65c40$bfb314c0$@gmail.com>

Hey David,

 

I have just verified that the next guide works as expected:

https://www.serverlab.ca/tutorials/linux/administration-linux/how-to-set-the-proxy-for-apt-for-ubuntu-18-04/

 

on Ubuntu 20.04 you can create the file:

/etc/apt/apt.conf

 

And then add to it the next lines: (replace the domain and port to an ip and port or another domain and port if required)

Acquire::http::proxy "http://prox.srv.world:3128/";
Acquire::https::proxy "http://prox.srv.world:3128/";

##

 

The above works as expected.

 

If for any reason what so ever you experience some issues you can try to add into the proxy hosts  file a static  record of:

202.158.214.106 mirror.aarnet.edu.au

# verify the right host ipv4 address using host/dig/nslookup

 

And then restart the squid proxy.

 

Try again and see if it works as expected.

 

All The Bests,

Eliezer

 

 

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of David Mills
Sent: Wednesday, July 7, 2021 2:26 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Ubuntu 20.04 "apt update" issues behind a VPN and Squid proxy

 

Hi,

 

We've got a collection of Ubuntu 18.04 boxes out in the field. They connect to an AWS OpenVPN VPN and use a Squid 3.5 AWS hosted Proxy. They work fine.

 

We have tried upgrading one to 20.04. Same setup. From the command line curl or wget can happily download an Ubuntu package from the Ubuntu Mirror site we use. But "apt update" gets lots of "IGN:" timeouts and errors.

 

The package we test curl with is https://mirror.aarnet.edu.au/ubuntu/pool/main/c/curl/curl_7.68.0-1ubuntu2.5_amd64.deb

 

The Squid log shows a line the doesn't occur for the successful 18.04 "apt updates":

1625190959.233     81 10.0.11.191 TAG_NONE/200 0 CONNECT mirror.aarnet.edu.au:443 <http://mirror.aarnet.edu.au:443>  - HIER_DIRECT/2001:388:30bc:cafe::beef -

 

The full output of an attempt to update is:

Ign:1 https://mirror.aarnet.edu.au/ubuntu focal InRelease                                              
Ign:2 https://mirror.aarnet.edu.au/ubuntu focal-updates InRelease                                      
Ign:3 https://mirror.aarnet.edu.au/ubuntu focal-backports InRelease                                    
Ign:4 https://mirror.aarnet.edu.au/ubuntu focal-security InRelease                                     
Err:5 https://mirror.aarnet.edu.au/ubuntu focal Release                                                
  Could not wait for server fd - select (11: Resource temporarily unavailable) [IP: 10.0.11.82 3128]
Err:6 https://mirror.aarnet.edu.au/ubuntu focal-updates Release                                        
  Could not wait for server fd - select (11: Resource temporarily unavailable) [IP: 10.0.11.82 3128]
Err:7 https://mirror.aarnet.edu.au/ubuntu focal-backports Release                                      
  Could not wait for server fd - select (11: Resource temporarily unavailable) [IP: 10.0.11.82 3128]
Err:8 https://mirror.aarnet.edu.au/ubuntu focal-security Release                                       
  Could not wait for server fd - select (11: Resource temporarily unavailable) [IP: 10.0.1.26 3128]
Reading package lists... Done                                                                          
N: Ignoring file 'microsoft-prod.list-keep' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension
E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal Release' does not have a Release file.
N: Updating from such a repository can't be done securely, and is therefore disabled by default.
N: See apt-secure(8) manpage for repository creation and user configuration details.
E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal-updates Release' does not have a Release file.
N: Updating from such a repository can't be done securely, and is therefore disabled by default.
N: See apt-secure(8) manpage for repository creation and user configuration details.
E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal-backports Release' does not have a Release file.
N: Updating from such a repository can't be done securely, and is therefore disabled by default.
N: See apt-secure(8) manpage for repository creation and user configuration details.
E: The repository 'https://mirror.aarnet.edu.au/ubuntu focal-security Release' does not have a Release file.
N: Updating from such a repository can't be done securely, and is therefore disabled by default.
N: See apt-secure(8) manpage for repository creation and user configuration details.

 

While running, the line

0% [Connecting to HTTP proxy (http://vpn-proxy-d68aca8a8f7f81d6.elb.ap-southeast-2.amazonaws.com:3128)]

appears often and hang for a while.

 

I've tried upping the squid logging and allowing all, but they didn't offer any additional information about the issue.

 

Any advice would be greatly appreciated.

 

Regards,

 


  <https://lh4.googleusercontent.com/PjzOtuo8wRwonOYtyjVEsTHphPFdwgM8H79UkQ5H--uLWS_Wje0pIvRFGgiiaYF8CohhfacA5LpIBIck7fEou91YR_e95GyEd53ubLzjKbgTVaqvhdESRKKiWZqDxUYAmOApJr47> 

David Mills

Senior DevOps Engineer

 

 E: david.mills at acusensus.com <mailto:david.mills at acusensus.com> 

 M: +61 411 513 404

 W: <http://acusensus.com/>  acusensus.com

 


DISCLAIMER: Acusensus puts the privacy and security of its clients, its data and information at the core of everything we do. The information contained in this email (including attachments) is intended only for the use of the person(s) to whom it is addressed to, as it may be confidential and contain legally privileged information. If you have received this email in error, please delete all copies and notify the sender immediately. Any views or opinions presented are solely those of the author and do not necessarily represent the views of Acusensus Pty Ltd. Please consider the environment before printing this email.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210708/26060a43/attachment.htm>

From alleinerwolf at gmail.com  Mon Jul 12 16:58:43 2021
From: alleinerwolf at gmail.com (Alex Irmel Oviedo Solis)
Date: Mon, 12 Jul 2021 11:58:43 -0500
Subject: [squid-users] issues with old version of TLS/SSL certificate
Message-ID: <CAKZ77-_LtM2Wj6oUW6-R=ceR9Qm8Vc7k1OvVVBCbuAow-ckQhA@mail.gmail.com>

Hello all, I'm trying to download a file from https://prodcont.seace.gob.pe,
it seems have an old  version certificate, the error that shows squid is:
//---Begin of error
The system returned:
    (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
    Handshake with SSL server failed: error:1425F102:SSL
routines:ssl_choose_client_version:unsupported protocol
//---End of error

SSLLabs review shows that server supports only TLS 1.0

I tryed putting this line into my squid.conf without success:
tls_outgoing_options cafile=/etc/squid/cacert.pem min-version=1.0
options=ALL

Any solution please?

-- 
*"Una alegr?a compartida se transforma en doble alegr?a; una pena
compartida, en media pena."*
--> http://www.alexove.me <http://www.alexove.me/>
--> Celular (Movistar): +51-959-625-001
--> Sigueme en Twitter: http://twitter.com/alexove_pe
--> Perfil: http://fedoraproject.org/wiki/user:alexove
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210712/46b90d9c/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Jul 12 17:53:32 2021
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 12 Jul 2021 19:53:32 +0200
Subject: [squid-users] issues with old version of TLS/SSL certificate
In-Reply-To: <CAKZ77-_LtM2Wj6oUW6-R=ceR9Qm8Vc7k1OvVVBCbuAow-ckQhA@mail.gmail.com>
References: <CAKZ77-_LtM2Wj6oUW6-R=ceR9Qm8Vc7k1OvVVBCbuAow-ckQhA@mail.gmail.com>
Message-ID: <202107121953.32350.Antony.Stone@squid.open.source.it>

On Monday 12 July 2021 at 18:58:43, Alex Irmel Oviedo Solis wrote:

> Hello all, I'm trying to download a file from
> https://prodcont.seace.gob.pe

> SSLLabs review shows that server supports only TLS 1.0

> Any solution please?

If you're trying to download a specific file from a specific server, which 
doesn't support current encryption protocols, is it absolutely essential to 
you that you download it via Squid?

In other words, I suggest you just connect to the machine directly, download 
the file, and then either forget about the server's outdated encryption 
capabilities, or inform the website maintainers (if there are any?) and see 
whether they care enough to bring it up to date.

Either way, you have your file, and you don't have to work out how to persuade 
Squid to do somethng that's really not a good idea to start with.


Antony.

-- 
"It is easy to be blinded to the essential uselessness of them by the sense of 
achievement you get from getting them to work at all. In other words - and 
this is the rock solid principle on which the whole of the Corporation's 
Galaxy-wide success is founded - their fundamental design flaws are completely 
hidden by their superficial design flaws."

 - Douglas Noel Adams

                                                   Please reply to the list;
                                                         please *don't* CC me.


From vincent.tamet at exoclick.com  Mon Jul 12 17:59:58 2021
From: vincent.tamet at exoclick.com (Vincent Tamet)
Date: Mon, 12 Jul 2021 19:59:58 +0200
Subject: [squid-users] refresh_pattern and "?"
In-Reply-To: <CAFcUVs2CTWJZSZZgBNKcH8CWKGD6ibU0n_O-0GUb5WWnTzO9NA@mail.gmail.com>
References: <CAFcUVs2CTWJZSZZgBNKcH8CWKGD6ibU0n_O-0GUb5WWnTzO9NA@mail.gmail.com>
Message-ID: <CAFcUVs3YZfGAnFweab3JavrS5oK2prHHf7r7EJhDa6Tu-Q0TrQ@mail.gmail.com>

Hi,

I would like to know how to deactivate the "?" refresh_pattern filter ?
(As most web pages nowaday should use cache-control or expire, I guess the
correct usage of headers should be enough to permit us to cache requests
with "?" !?
Advice are welcome...)

For example for /cgi-bin/:
#refresh_pattern -i (/cgi-bin/)     0      0%        0
1626107114.552    812 192.168.14.224 TCP_MEM_HIT/200 1988993 GET
https://test5vince.titi.com/cgi-bin/201.gif - HIER_NONE/- image/gif

refresh_pattern -i (/cgi-bin/)     0      0%        0
1626107233.336   4729 192.168.14.224 TCP_REFRESH_UNMODIFIED_ABORTED/200
229496 GET https://test5vince.titi.com/cgi-bin/201.gif - FIRSTUP_PARENT/
127.0.0.1 image/gif

But for \?:
#refresh_pattern -i (/cgi-bin/|\?)     0   0%        0
1626107559.200   6441 192.168.14.224 TCP_MISS/200 1988987 GET
https://test5vince.titi.com/201.gif? - FIRSTUP_PARENT/127.0.0.1 image/gif

Best regards
Vince

PS:
< HTTP/2 200
< server: nginx
< date: Mon, 12 Jul 2021 16:42:31 GMT
< content-type: image/gif
< content-length: 1988458
< last-modified: Mon, 12 Jul 2021 16:18:23 GMT
< cache-control: max-age=1800
< strict-transport-security: max-age=60; includeSubDomains
< x-content-type-options: nosniff
< x-frame-options: SAMEORIGIN
< x-xss-protection: 1; mode=block
< accept-ranges: bytes
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210712/3b4fc5c5/attachment.htm>

From marciobacci at gmail.com  Mon Jul 12 18:12:03 2021
From: marciobacci at gmail.com (Marcio B.)
Date: Mon, 12 Jul 2021 15:12:03 -0300
Subject: [squid-users] Problems with HTTPS on Squid
Message-ID: <CA+0TdyqPvJsatX4LHtGGTPuoKCrE6Qe833e_JHFBevf8vMMPJw@mail.gmail.com>

I have the following problem on my Squid 4.6 on Debian 10.

Squid does not redirect the user to the error page when blocking an HTTPS
url. On HTTP it works correctly.

I don't use transparent proxy. The proxy is manually configured in the web
browser.

Here is my squid.conf configuration file:

http_port 3128
cache_mem 256 MB
cache_swap_low 90
cache_swap_high 95

maximum_object_size 512 MB
minimum_object_size 0 KB
maximum_object_size_in_memory 128 KB

access_log /var/log/squid/access.log
cache_log /var/log/squid/cache.log

error_directory /usr/share/squid/errors/pt-br
cache_mgr rede at empresa.com.br

cache_replacement_policy heap LFUDA
memory_replacement_policy heap LFUDA

fqdncache_size 1024

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .                 0     20%     4320

#Prioriza resolucao DNS IPv4
dns_v4_first on

cache_dir aufs /var/spool/squid 600 16 256

visible_hostname "Monitoramento-de-Acesso-a-Internet"

### acls
acl SSL_ports  port 443
acl Safe_ports port 21           # ftp
acl Safe_ports port 70           # gopher
acl Safe_ports port 80           # http
acl Safe_ports port 88           # kerberos
acl Safe_ports port 123          # ntp
acl Safe_ports port 210          # wais
acl Safe_ports port 280          # http-mgmt
acl Safe_ports port 3456         # Siafi
acl Safe_ports port 389          # ldap
acl Safe_ports port 443          # https
acl Safe_ports port 488          # gss-http
acl Safe_ports port 563          # snews
acl Safe_ports port 591          # filemaker
acl Safe_ports port 777          # multiling http
acl Safe_ports port 3001         # imprenssa nacional
acl Safe_ports port 8080         # http
acl Safe_ports port 8443         # http
acl Safe_ports port 1025-65535   # unregistered ports
acl CONNECT method CONNECT

acl sistemas-bloqueados dstdomain "/etc/squid/acls/sistemas-bloqueados"
http_access deny sistemas-bloqueados

## Negotiate kerberos/NTLM module
auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth --ntlm
/usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --use-cached-creds
--kerberos /usr/lib/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME
auth_param negotiate children 200 startup=15 idle=5
auth_param negotiate keep_alive on

## NTLM Auth
auth_param ntlm program /usr/bin/ntlm_auth --use-cached-creds
--helper-protocol=squid-2.5-ntlmssp
auth_param ntlm children 110 startup=5 idle=5
auth_param ntlm keep_alive on
auth_param basic realm "Squid Proxy"

# Incorpora as regras do SquidGuard
#redirect_program /usr/bin/squidGuard
#redirect_children 20
#redirector_bypass on

acl ntlm_users proxy_auth REQUIRED
http_access allow ntlm_users
http_access deny all

### LAN #####
acl rede_usuarios src 192.168.0.0/16

### Regras Padrao do Squid
#http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

http_access allow localhost
#libera a resposta a partir do proxy
http_reply_access allow all
#acl manager proto cache_object

### Allow LAN
http_access allow rede_usuarios

#cache_effective_user proxy
coredump_dir /var/spool/squid

# SquidGuard
url_rewrite_program /usr/bin/squidGuard
redirector_bypass on


As I don't use proxy transparence, is it necessary to create SSL
certificate for my Proxy server?

Can anybody help me?

Regards,

M?rcio Bacci
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210712/e85f90cc/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Jul 12 18:23:02 2021
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 12 Jul 2021 20:23:02 +0200
Subject: [squid-users] Problems with HTTPS on Squid
In-Reply-To: <CA+0TdyqPvJsatX4LHtGGTPuoKCrE6Qe833e_JHFBevf8vMMPJw@mail.gmail.com>
References: <CA+0TdyqPvJsatX4LHtGGTPuoKCrE6Qe833e_JHFBevf8vMMPJw@mail.gmail.com>
Message-ID: <202107122023.02446.Antony.Stone@squid.open.source.it>

On Monday 12 July 2021 at 20:12:03, Marcio B. wrote:

> I have the following problem on my Squid 4.6 on Debian 10.
> 
> Squid does not redirect the user to the error page when blocking an HTTPS
> url. On HTTP it works correctly.

Short answer - it can't.

Longer answer - browser requests https://thing.example.com

Squid won't allow connection to thing.example.com, and wants to send the 
browser to an error page instead.

The error page cannot possibly have the correct certificate for 
https://thing.example.com (because that's signed by some genuine CA), so the 
browser won't accept the error page as being valid.

Squid cannot even send an HTTP 302 redirect back to the browser, because that 
also is HTTPS content, and would need to have the correct certification for the 
browser to accept it and follow the redirect.

So, what you want is understandable, but not possible.

The only option I can think of is to add a CA certificate to all your browsers, 
and get Squid (somehow; sorry, I don't know how) to issue either a redirect or 
a substitute web page, claiming to tbe the original web server, and with a 
certificate signed by that CA that your browsers now trust.

I suspect that involves transparent interception, but someone might know how / 
whether it can be done.


Antony.

-- 
"The future is already here.   It's just not evenly distributed yet."

 - William Gibson

                                                   Please reply to the list;
                                                         please *don't* CC me.


From ngtech1ltd at gmail.com  Tue Jul 13 10:48:21 2021
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Tue, 13 Jul 2021 13:48:21 +0300
Subject: [squid-users] TPROXY Error
References: <CADAqQfwR4w-cFidq+8ea7zns=OUwyan6W1wXuLcrge4jSE4B9Q@mail.gmail.com>
 <000a01d7731f$7550a9c0$5ff1fd40$@gmail.com>
 <68332d40-ba49-f426-21b8-48602608690e@gmail.com> 
Message-ID: <004701d777d4$99ceadb0$cd6c0910$@gmail.com>

Hey Ben,

Still waiting for the relevant output.
Once I will have the relevant details I will probably be able to verify how and what is the issue.

Eliezer

-----Original Message-----
From: Eliezer Croitoru <ngtech1ltd at gmail.com> 
Sent: Thursday, July 8, 2021 12:04 AM
To: 'squid-users at lists.squid-cache.org' <squid-users at lists.squid-cache.org>
Cc: 'Ben Goz' <ben.goz87 at gmail.com>
Subject: RE: [squid-users] TPROXY Error

Hey Ben,

You are missing the critical output of the full command:
Ip route show table 100

What you posted was:
> 5.  the output of 'ip route show table 100'
$ ip route show
default via 8.13.140.14 dev bond0.212 proto static
1.21.213.0/24 dev bond0.213 proto kernel scope link src 1.21.213.1
8.11.39.248/30 dev enx00e04c3600d3 proto kernel scope link src 8.11.39.250
8.13.140.0/28 dev bond0.212 proto kernel scope link src 8.13.140.1
8.13.144.0/20 via 1.21.213.254 dev bond0.213
8.13.148.1 via 1.21.213.254 dev bond0.213
##

It's important to see the relevant routing table.
The linux Kernel have couple routing tables which each can contain different routing/forwarding table.
If you want to understand a bit more you might be able to try and lookup for FIB.
( take a peek at: http://linux-ip.net/html/routing-tables.html)

Eliezer

-----Original Message-----
From: Ben Goz <ben.goz87 at gmail.com> 
Sent: Wednesday, July 7, 2021 3:36 PM
To: Eliezer Croitoru <ngtech1ltd at gmail.com>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] TPROXY Error

By the help of God.


Hi Eliezer,

Thanks for your help.

Please let me know if you need more information.


Regards,

Ben

On 07/07/2021 14:01, Eliezer Croitoru wrote:
> Hey Ben,
>
> I want to try and reset this issue because I am missing some technical
> details.
>
> 1. What Linux Distro and what version are you using?'
Ubuntu 20.04
> 2. the output of 'ip address'
$ ip address
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN 
group default qlen 1000
     link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
     inet 127.0.0.1/8 scope host lo
        valid_lft forever preferred_lft forever
     inet6 ::1/128 scope host
        valid_lft forever preferred_lft forever
2: ens1f0: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc mq 
master bond0 state UP group default qlen 1000
     link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
3: ens1f1: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc mq 
master bond0 state UP group default qlen 1000
     link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
4: usb0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group 
default qlen 1000
     link/ether ca:13:59:65:c2:56 brd ff:ff:ff:ff:ff:ff
5: enx00e04c3600d3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc 
fq_codel state UP group default qlen 1000
     link/ether 00:e0:4c:36:00:d3 brd ff:ff:ff:ff:ff:ff
     inet 8.11.39.250/30 brd 8.11.39.251 scope global enx00e04c3600d3
        valid_lft forever preferred_lft forever
     inet6 fe80::2e0:4cff:fe36:d3/64 scope link
        valid_lft forever preferred_lft forever
6: bond0: <BROADCAST,MULTICAST,MASTER,UP,LOWER_UP> mtu 1500 qdisc 
noqueue state UP group default qlen 1000
     link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
     inet6 fe80::b859:58ff:fe58:232b/64 scope link
        valid_lft forever preferred_lft forever
7: bond0.212 at bond0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc 
noqueue state UP group default qlen 1000
     link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
     inet 8.13.140.1/28 brd 8.13.140.15 scope global bond0.212
        valid_lft forever preferred_lft forever
     inet6 fe80::b859:58ff:fe58:232b/64 scope link
        valid_lft forever preferred_lft forever
8: bond0.213 at bond0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc 
noqueue state UP group default qlen 1000
     link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
     inet 1.21.213.1/24 brd 1.21.213.255 scope global bond0.213
        valid_lft forever preferred_lft forever
     inet6 fe80::b859:58ff:fe58:232b/64 scope link
        valid_lft forever preferred_lft forever
> 3. the output of 'ip rule'
$ ip rule
0:    from all lookup local
32762:    from all fwmark 0x1 lookup 100
32763:    from all fwmark 0x1 lookup 100
32764:    from all fwmark 0x1 lookup 100
32765:    from all fwmark 0x1 lookup 100
32766:    from all lookup main
32767:    from all lookup default

> 4.  the output of 'ip route show'

$ ip route show
default via 8.13.140.14 dev bond0.212 proto static
1.21.213.0/24 dev bond0.213 proto kernel scope link src 1.21.213.1
8.11.39.248/30 dev enx00e04c3600d3 proto kernel scope link src 8.11.39.250
8.13.140.0/28 dev bond0.212 proto kernel scope link src 8.13.140.1
8.13.144.0/20 via 1.21.213.254 dev bond0.213
8.13.148.1 via 1.21.213.254 dev bond0.213

> 5.  the output of 'ip route show table 100'
$ ip route show
default via 8.13.140.14 dev bond0.212 proto static
1.21.213.0/24 dev bond0.213 proto kernel scope link src 1.21.213.1
8.11.39.248/30 dev enx00e04c3600d3 proto kernel scope link src 8.11.39.250
8.13.140.0/28 dev bond0.212 proto kernel scope link src 8.13.140.1
8.13.144.0/20 via 1.21.213.254 dev bond0.213
8.13.148.1 via 1.21.213.254 dev bond0.213
> 6. the output of 'iptables-save'


$ sudo iptables-save
# Generated by iptables-save v1.8.4 on Wed Jul  7 12:25:05 2021
*mangle
:PREROUTING ACCEPT [72898710:6084386298]
:INPUT ACCEPT [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
:POSTROUTING ACCEPT [0:0]
:DIVERT - [0:0]
-A PREROUTING -p tcp -m socket -j DIVERT
-A PREROUTING -i bond0.213 -p tcp -m tcp --dport 80 -j TPROXY --on-port 
15644 --on-ip 0.0.0.0 --tproxy-mark 0x1/0x1
-A PREROUTING -i bond0.213 -p tcp -m tcp --dport 443 -j TPROXY --on-port 
15645 --on-ip 0.0.0.0 --tproxy-mark 0x1/0x1
-A INPUT -j ACCEPT
-A FORWARD -j ACCEPT
-A OUTPUT -j ACCEPT
-A POSTROUTING -j ACCEPT
-A DIVERT -j MARK --set-xmark 0x1/0xffffffff
-A DIVERT -j ACCEPT
COMMIT
# Completed on Wed Jul  7 12:25:05 2021
# Generated by iptables-save v1.8.4 on Wed Jul  7 12:25:05 2021
*nat
:PREROUTING ACCEPT [26338415:1392747531]
:INPUT ACCEPT [820462:44161193]
:OUTPUT ACCEPT [1053:92773]
:POSTROUTING ACCEPT [25514534:1348449899]
-A PREROUTING -i eth1 -p udp -m udp --dport 53 -j REDIRECT --to-ports 53
-A PREROUTING -i eth1 -p tcp -m tcp --dport 53 -j REDIRECT --to-ports 53
COMMIT
# Completed on Wed Jul  7 12:25:05 2021
# Generated by iptables-save v1.8.4 on Wed Jul  7 12:25:05 2021
*filter
:INPUT ACCEPT [5045387:2170630036]
:FORWARD ACCEPT [72544426:6194710400]
:OUTPUT ACCEPT [2471930:252759773]
COMMIT
# Completed on Wed Jul  7 12:25:05 20

> 7. the output of 'nft -nn list ruleset' (if exists on the OS)
Doesn't exists.
> 8. the output of your squid.conf
$ cat squid.conf
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 0.0.0.1-0.255.255.255    # RFC 1122 "this" network (LAN)
acl localnet src 10.0.0.0/8        # RFC 1918 local private network (LAN)
acl localnet src 100.64.0.0/10        # RFC 6598 shared address space (CGN)
acl localnet src 169.254.0.0/16     # RFC 3927 link-local (directly 
plugged) machines
acl localnet src 172.16.0.0/12        # RFC 1918 local private network (LAN)
acl localnet src 192.168.0.0/16        # RFC 1918 local private network 
(LAN)
acl localnet src fc00::/7           # RFC 4193 local private network range
acl localnet src fe80::/10          # RFC 4291 link-local (directly 
plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80        # http
acl Safe_ports port 21        # ftp
acl Safe_ports port 443        # https
acl Safe_ports port 70        # gopher
acl Safe_ports port 210        # wais
acl Safe_ports port 1025-65535    # unregistered ports
acl Safe_ports port 280        # http-mgmt
acl Safe_ports port 488        # gss-http
acl Safe_ports port 591        # filemaker
acl Safe_ports port 777        # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
#http_access deny all

http_access allow all

# Squid normally listens to port 3128
http_port 15643
http_port 15644 tproxy
https_port 15645 ssl-bump tproxy generate-host-certificates=on 
options=ALL dynamic_cert_mem_cache_size=4MB 
cert=/usr/local/squid/etc/ssl_cert/myCA.pem 
dhparams=/usr/local/squid/etc/dhparam.pem
always_direct allow all
acl DiscoverSNIHost at_step SslBump1
acl NoSSLInterceptRegexp_always ssl::server_name_regex -i xxx
acl NoSSLIntercept ssl::server_name  "xxx"
acl NoSSLInterceptRegexp ssl::server_name_regex -i "xxx"
ssl_bump splice NoSSLInterceptRegexp_always
ssl_bump splice NoSSLIntercept
ssl_bump splice NoSSLInterceptRegexp
ssl_bump peek DiscoverSNIHost
ssl_bump bump all
sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s 
/var/lib/ssl_db -M 4MB
sslcrtd_children 32 startup=15 idle=3
#sslproxy_capath /etc/ssl/certs

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /usr/local/squid/var/cache/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /usr/local/squid/var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:        1440    20%    10080
refresh_pattern ^gopher:    1440    0%    1440
refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
refresh_pattern .        0    20%    4320

range_offset_limit -1

dns_v4_first on
forwarded_for off
cache deny all
> 9. the output of 'squid -v'
$ ./squid -v
Squid Cache: Version 4.15
Service Name: squid

This binary uses OpenSSL 1.1.1f  31 Mar 2020. For legal restrictions on 
distribution see https://www.openssl.org/source/license.html

configure options:  '--with-openssl' '--enable-ssl-crtd' '--enable-ecap' 
'--enable-linux-netfilter' --enable-ltdl-convenience

> 10. the output of 'uname -a'
uname -a
Linux xxx 5.4.0-77-generic #86-Ubuntu SMP Thu Jun 17 02:35:03 UTC 2021 
x86_64 x86_64 x86_64 GNU/Linux
>
> Once we will have all the above details (reducing/modifying any private
> details) we can try to maybe help you.
>
> Eliezer
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
> Ben Goz
> Sent: Wednesday, June 30, 2021 3:16 PM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] TPROXY Error
>
>   By the help of God.
>
> Hi All,
> I'm trying to configure squid as a transparent proxy using TPROXY.
> The machine I'm using has 2 NICs, one for input and the other one for
> output traffic.
> The TPROXY iptables rules are configured on the input NIC.
> It looks like iptables TPROXY redirect works but squid prints out the
> following error:
>
> ERROR: NAT/TPROXY lookup failed to locate original IPs on
> local=xxx:443 remote=xxx:49471 FD 14 flags=17
>
> I think I loaded all TPROXY required kernel modules.
>
> The ip forwarding works fine without the iptables rules. and I don't
> see any squid ERROR on getsockopt
>
> Please let me know what I'm missing?
>
> Thanks,
> Ben
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



From ben.goz87 at gmail.com  Tue Jul 13 10:58:06 2021
From: ben.goz87 at gmail.com (Ben Goz)
Date: Tue, 13 Jul 2021 13:58:06 +0300
Subject: [squid-users] TPROXY Error
In-Reply-To: <004701d777d4$99ceadb0$cd6c0910$@gmail.com>
References: <CADAqQfwR4w-cFidq+8ea7zns=OUwyan6W1wXuLcrge4jSE4B9Q@mail.gmail.com>
 <000a01d7731f$7550a9c0$5ff1fd40$@gmail.com>
 <68332d40-ba49-f426-21b8-48602608690e@gmail.com>
 <004701d777d4$99ceadb0$cd6c0910$@gmail.com>
Message-ID: <CADAqQfxVHUfTqdtyPWc6AbBFyM4pNnWAeyrnvrqEJ8NvUJ4SFA@mail.gmail.com>

By the help of God.

Sorry,
I thought I sent it in the last email.
I found out what was the problem, I built squid without libcap. :/

Anyway sorry for the time loss, and thanks for your help.

Regards,
Ben



??????? ??? ??, 13 ????? 2021 ?-13:48 ??? ?Eliezer Croitoru?? <?
ngtech1ltd at gmail.com??>:?

> Hey Ben,
>
> Still waiting for the relevant output.
> Once I will have the relevant details I will probably be able to verify
> how and what is the issue.
>
> Eliezer
>
> -----Original Message-----
> From: Eliezer Croitoru <ngtech1ltd at gmail.com>
> Sent: Thursday, July 8, 2021 12:04 AM
> To: 'squid-users at lists.squid-cache.org' <squid-users at lists.squid-cache.org
> >
> Cc: 'Ben Goz' <ben.goz87 at gmail.com>
> Subject: RE: [squid-users] TPROXY Error
>
> Hey Ben,
>
> You are missing the critical output of the full command:
> Ip route show table 100
>
> What you posted was:
> > 5.  the output of 'ip route show table 100'
> $ ip route show
> default via 8.13.140.14 dev bond0.212 proto static
> 1.21.213.0/24 dev bond0.213 proto kernel scope link src 1.21.213.1
> 8.11.39.248/30 dev enx00e04c3600d3 proto kernel scope link src 8.11.39.250
> 8.13.140.0/28 dev bond0.212 proto kernel scope link src 8.13.140.1
> 8.13.144.0/20 via 1.21.213.254 dev bond0.213
> 8.13.148.1 via 1.21.213.254 dev bond0.213
> ##
>
> It's important to see the relevant routing table.
> The linux Kernel have couple routing tables which each can contain
> different routing/forwarding table.
> If you want to understand a bit more you might be able to try and lookup
> for FIB.
> ( take a peek at: http://linux-ip.net/html/routing-tables.html)
>
> Eliezer
>
> -----Original Message-----
> From: Ben Goz <ben.goz87 at gmail.com>
> Sent: Wednesday, July 7, 2021 3:36 PM
> To: Eliezer Croitoru <ngtech1ltd at gmail.com>;
> squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] TPROXY Error
>
> By the help of God.
>
>
> Hi Eliezer,
>
> Thanks for your help.
>
> Please let me know if you need more information.
>
>
> Regards,
>
> Ben
>
> On 07/07/2021 14:01, Eliezer Croitoru wrote:
> > Hey Ben,
> >
> > I want to try and reset this issue because I am missing some technical
> > details.
> >
> > 1. What Linux Distro and what version are you using?'
> Ubuntu 20.04
> > 2. the output of 'ip address'
> $ ip address
> 1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN
> group default qlen 1000
>      link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
>      inet 127.0.0.1/8 scope host lo
>         valid_lft forever preferred_lft forever
>      inet6 ::1/128 scope host
>         valid_lft forever preferred_lft forever
> 2: ens1f0: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc mq
> master bond0 state UP group default qlen 1000
>      link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
> 3: ens1f1: <BROADCAST,MULTICAST,SLAVE,UP,LOWER_UP> mtu 1500 qdisc mq
> master bond0 state UP group default qlen 1000
>      link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
> 4: usb0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group
> default qlen 1000
>      link/ether ca:13:59:65:c2:56 brd ff:ff:ff:ff:ff:ff
> 5: enx00e04c3600d3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc
> fq_codel state UP group default qlen 1000
>      link/ether 00:e0:4c:36:00:d3 brd ff:ff:ff:ff:ff:ff
>      inet 8.11.39.250/30 brd 8.11.39.251 scope global enx00e04c3600d3
>         valid_lft forever preferred_lft forever
>      inet6 fe80::2e0:4cff:fe36:d3/64 scope link
>         valid_lft forever preferred_lft forever
> 6: bond0: <BROADCAST,MULTICAST,MASTER,UP,LOWER_UP> mtu 1500 qdisc
> noqueue state UP group default qlen 1000
>      link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
>      inet6 fe80::b859:58ff:fe58:232b/64 scope link
>         valid_lft forever preferred_lft forever
> 7: bond0.212 at bond0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc
> noqueue state UP group default qlen 1000
>      link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
>      inet 8.13.140.1/28 brd 8.13.140.15 scope global bond0.212
>         valid_lft forever preferred_lft forever
>      inet6 fe80::b859:58ff:fe58:232b/64 scope link
>         valid_lft forever preferred_lft forever
> 8: bond0.213 at bond0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc
> noqueue state UP group default qlen 1000
>      link/ether ba:59:58:58:23:2b brd ff:ff:ff:ff:ff:ff
>      inet 1.21.213.1/24 brd 1.21.213.255 scope global bond0.213
>         valid_lft forever preferred_lft forever
>      inet6 fe80::b859:58ff:fe58:232b/64 scope link
>         valid_lft forever preferred_lft forever
> > 3. the output of 'ip rule'
> $ ip rule
> 0:    from all lookup local
> 32762:    from all fwmark 0x1 lookup 100
> 32763:    from all fwmark 0x1 lookup 100
> 32764:    from all fwmark 0x1 lookup 100
> 32765:    from all fwmark 0x1 lookup 100
> 32766:    from all lookup main
> 32767:    from all lookup default
>
> > 4.  the output of 'ip route show'
>
> $ ip route show
> default via 8.13.140.14 dev bond0.212 proto static
> 1.21.213.0/24 dev bond0.213 proto kernel scope link src 1.21.213.1
> 8.11.39.248/30 dev enx00e04c3600d3 proto kernel scope link src 8.11.39.250
> 8.13.140.0/28 dev bond0.212 proto kernel scope link src 8.13.140.1
> 8.13.144.0/20 via 1.21.213.254 dev bond0.213
> 8.13.148.1 via 1.21.213.254 dev bond0.213
>
> > 5.  the output of 'ip route show table 100'
> $ ip route show
> default via 8.13.140.14 dev bond0.212 proto static
> 1.21.213.0/24 dev bond0.213 proto kernel scope link src 1.21.213.1
> 8.11.39.248/30 dev enx00e04c3600d3 proto kernel scope link src 8.11.39.250
> 8.13.140.0/28 dev bond0.212 proto kernel scope link src 8.13.140.1
> 8.13.144.0/20 via 1.21.213.254 dev bond0.213
> 8.13.148.1 via 1.21.213.254 dev bond0.213
> > 6. the output of 'iptables-save'
>
>
> $ sudo iptables-save
> # Generated by iptables-save v1.8.4 on Wed Jul  7 12:25:05 2021
> *mangle
> :PREROUTING ACCEPT [72898710:6084386298]
> :INPUT ACCEPT [0:0]
> :FORWARD ACCEPT [0:0]
> :OUTPUT ACCEPT [0:0]
> :POSTROUTING ACCEPT [0:0]
> :DIVERT - [0:0]
> -A PREROUTING -p tcp -m socket -j DIVERT
> -A PREROUTING -i bond0.213 -p tcp -m tcp --dport 80 -j TPROXY --on-port
> 15644 --on-ip 0.0.0.0 --tproxy-mark 0x1/0x1
> -A PREROUTING -i bond0.213 -p tcp -m tcp --dport 443 -j TPROXY --on-port
> 15645 --on-ip 0.0.0.0 --tproxy-mark 0x1/0x1
> -A INPUT -j ACCEPT
> -A FORWARD -j ACCEPT
> -A OUTPUT -j ACCEPT
> -A POSTROUTING -j ACCEPT
> -A DIVERT -j MARK --set-xmark 0x1/0xffffffff
> -A DIVERT -j ACCEPT
> COMMIT
> # Completed on Wed Jul  7 12:25:05 2021
> # Generated by iptables-save v1.8.4 on Wed Jul  7 12:25:05 2021
> *nat
> :PREROUTING ACCEPT [26338415:1392747531]
> :INPUT ACCEPT [820462:44161193]
> :OUTPUT ACCEPT [1053:92773]
> :POSTROUTING ACCEPT [25514534:1348449899]
> -A PREROUTING -i eth1 -p udp -m udp --dport 53 -j REDIRECT --to-ports 53
> -A PREROUTING -i eth1 -p tcp -m tcp --dport 53 -j REDIRECT --to-ports 53
> COMMIT
> # Completed on Wed Jul  7 12:25:05 2021
> # Generated by iptables-save v1.8.4 on Wed Jul  7 12:25:05 2021
> *filter
> :INPUT ACCEPT [5045387:2170630036]
> :FORWARD ACCEPT [72544426:6194710400]
> :OUTPUT ACCEPT [2471930:252759773]
> COMMIT
> # Completed on Wed Jul  7 12:25:05 20
>
> > 7. the output of 'nft -nn list ruleset' (if exists on the OS)
> Doesn't exists.
> > 8. the output of your squid.conf
> $ cat squid.conf
> #
> # Recommended minimum configuration:
> #
>
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 0.0.0.1-0.255.255.255    # RFC 1122 "this" network (LAN)
> acl localnet src 10.0.0.0/8        # RFC 1918 local private network (LAN)
> acl localnet src 100.64.0.0/10        # RFC 6598 shared address space
> (CGN)
> acl localnet src 169.254.0.0/16     # RFC 3927 link-local (directly
> plugged) machines
> acl localnet src 172.16.0.0/12        # RFC 1918 local private network
> (LAN)
> acl localnet src 192.168.0.0/16        # RFC 1918 local private network
> (LAN)
> acl localnet src fc00::/7           # RFC 4193 local private network range
> acl localnet src fe80::/10          # RFC 4291 link-local (directly
> plugged) machines
>
> acl SSL_ports port 443
> acl Safe_ports port 80        # http
> acl Safe_ports port 21        # ftp
> acl Safe_ports port 443        # https
> acl Safe_ports port 70        # gopher
> acl Safe_ports port 210        # wais
> acl Safe_ports port 1025-65535    # unregistered ports
> acl Safe_ports port 280        # http-mgmt
> acl Safe_ports port 488        # gss-http
> acl Safe_ports port 591        # filemaker
> acl Safe_ports port 777        # multiling http
> acl CONNECT method CONNECT
>
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
>
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
>
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
>
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
>
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
>
> # And finally deny all other access to this proxy
> #http_access deny all
>
> http_access allow all
>
> # Squid normally listens to port 3128
> http_port 15643
> http_port 15644 tproxy
> https_port 15645 ssl-bump tproxy generate-host-certificates=on
> options=ALL dynamic_cert_mem_cache_size=4MB
> cert=/usr/local/squid/etc/ssl_cert/myCA.pem
> dhparams=/usr/local/squid/etc/dhparam.pem
> always_direct allow all
> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLInterceptRegexp_always ssl::server_name_regex -i xxx
> acl NoSSLIntercept ssl::server_name  "xxx"
> acl NoSSLInterceptRegexp ssl::server_name_regex -i "xxx"
> ssl_bump splice NoSSLInterceptRegexp_always
> ssl_bump splice NoSSLIntercept
> ssl_bump splice NoSSLInterceptRegexp
> ssl_bump peek DiscoverSNIHost
> ssl_bump bump all
> sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
> /var/lib/ssl_db -M 4MB
> sslcrtd_children 32 startup=15 idle=3
> #sslproxy_capath /etc/ssl/certs
>
> # Uncomment and adjust the following to add a disk cache directory.
> #cache_dir ufs /usr/local/squid/var/cache/squid 100 16 256
>
> # Leave coredumps in the first cache dir
> coredump_dir /usr/local/squid/var/cache/squid
>
> #
> # Add any of your own refresh_pattern entries above these.
> #
> refresh_pattern ^ftp:        1440    20%    10080
> refresh_pattern ^gopher:    1440    0%    1440
> refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
> refresh_pattern .        0    20%    4320
>
> range_offset_limit -1
>
> dns_v4_first on
> forwarded_for off
> cache deny all
> > 9. the output of 'squid -v'
> $ ./squid -v
> Squid Cache: Version 4.15
> Service Name: squid
>
> This binary uses OpenSSL 1.1.1f  31 Mar 2020. For legal restrictions on
> distribution see https://www.openssl.org/source/license.html
>
> configure options:  '--with-openssl' '--enable-ssl-crtd' '--enable-ecap'
> '--enable-linux-netfilter' --enable-ltdl-convenience
>
> > 10. the output of 'uname -a'
> uname -a
> Linux xxx 5.4.0-77-generic #86-Ubuntu SMP Thu Jun 17 02:35:03 UTC 2021
> x86_64 x86_64 x86_64 GNU/Linux
> >
> > Once we will have all the above details (reducing/modifying any private
> > details) we can try to maybe help you.
> >
> > Eliezer
> >
> > -----Original Message-----
> > From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf
> Of
> > Ben Goz
> > Sent: Wednesday, June 30, 2021 3:16 PM
> > To: squid-users at lists.squid-cache.org
> > Subject: [squid-users] TPROXY Error
> >
> >   By the help of God.
> >
> > Hi All,
> > I'm trying to configure squid as a transparent proxy using TPROXY.
> > The machine I'm using has 2 NICs, one for input and the other one for
> > output traffic.
> > The TPROXY iptables rules are configured on the input NIC.
> > It looks like iptables TPROXY redirect works but squid prints out the
> > following error:
> >
> > ERROR: NAT/TPROXY lookup failed to locate original IPs on
> > local=xxx:443 remote=xxx:49471 FD 14 flags=17
> >
> > I think I loaded all TPROXY required kernel modules.
> >
> > The ip forwarding works fine without the iptables rules. and I don't
> > see any squid ERROR on getsockopt
> >
> > Please let me know what I'm missing?
> >
> > Thanks,
> > Ben
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210713/203f7b0e/attachment.htm>

From squid3 at treenet.co.nz  Tue Jul 13 18:23:13 2021
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Wed, 14 Jul 2021 06:23:13 +1200
Subject: [squid-users] refresh_pattern and "?"
In-Reply-To: <CAFcUVs3YZfGAnFweab3JavrS5oK2prHHf7r7EJhDa6Tu-Q0TrQ@mail.gmail.com>
References: <CAFcUVs2CTWJZSZZgBNKcH8CWKGD6ibU0n_O-0GUb5WWnTzO9NA@mail.gmail.com>
 <CAFcUVs3YZfGAnFweab3JavrS5oK2prHHf7r7EJhDa6Tu-Q0TrQ@mail.gmail.com>
Message-ID: <4aea102c6192abfe279bef4c079a1c18@treenet.co.nz>

On 2021-07-13 05:59, Vincent Tamet wrote:
> Hi,
> 
> I would like to know how to deactivate the "?" refresh_pattern filter
> ?

There is no such filter. So "deactivate" has no meaning.

refresh_pattern is a directive that provides default values for the 
caching Freshness heuristics defined by RFC 7234. For messages without a 
necessary cache-control or related header value.


> (As most web pages nowaday should use cache-control or expire, I guess
> the correct usage of headers should be enough to permit us to cache
> requests with "?" !?

Yes. URLs containing '?query-string' are cached by Squid with the 
default squid.conf refresh_pattern settings.

The refresh_pattern line you noticed is to cope with servers that are 
very old and/or broken. You can remove it, but any of your clients 
visiting such a server will see the brokenness and probably blame Squid 
because "it works fine with just Browser X".


Amos


From vincent.tamet at exoclick.com  Wed Jul 14 19:48:16 2021
From: vincent.tamet at exoclick.com (Vincent Tamet)
Date: Wed, 14 Jul 2021 21:48:16 +0200
Subject: [squid-users] refresh_pattern and "?"
In-Reply-To: <4aea102c6192abfe279bef4c079a1c18@treenet.co.nz>
References: <CAFcUVs2CTWJZSZZgBNKcH8CWKGD6ibU0n_O-0GUb5WWnTzO9NA@mail.gmail.com>
 <CAFcUVs3YZfGAnFweab3JavrS5oK2prHHf7r7EJhDa6Tu-Q0TrQ@mail.gmail.com>
 <4aea102c6192abfe279bef4c079a1c18@treenet.co.nz>
Message-ID: <CAFcUVs0yGzPE77cSEkS+s-JTjYatjwvQx1uV+9EW2--6rbY-Vg@mail.gmail.com>

You are totally right !
The problem was on my side with the acl regular expression used to choose
extensions to be cached:
acl images url_regex -i \.(bmp|gif|ico|jpeg|jpg|png|svg|tif|tiff|webp)$
$ was not matching for '?query-string'

* Your answer helps me to find my error.
* And I am now thinking about changing the way of doing the cache
  (a special refresh for my acls or/and a default to 0 0% 0 to use the
TCP_REFRESH_UNMODIFIED).

Thank you very much :)
And sorry for the sound ! :(


On Tue, Jul 13, 2021 at 8:23 PM <squid3 at treenet.co.nz> wrote:

> On 2021-07-13 05:59, Vincent Tamet wrote:
> > Hi,
> >
> > I would like to know how to deactivate the "?" refresh_pattern filter
> > ?
>
> There is no such filter. So "deactivate" has no meaning.
>
> refresh_pattern is a directive that provides default values for the
> caching Freshness heuristics defined by RFC 7234. For messages without a
> necessary cache-control or related header value.
>
>
> > (As most web pages nowaday should use cache-control or expire, I guess
> > the correct usage of headers should be enough to permit us to cache
> > requests with "?" !?
>
> Yes. URLs containing '?query-string' are cached by Squid with the
> default squid.conf refresh_pattern settings.
>
> The refresh_pattern line you noticed is to cope with servers that are
> very old and/or broken. You can remove it, but any of your clients
> visiting such a server will see the brokenness and probably blame Squid
> because "it works fine with just Browser X".
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210714/d2014c82/attachment.htm>

From moberger at metanetworks.com  Wed Jul 14 21:11:42 2021
From: moberger at metanetworks.com (Moti Berger)
Date: Thu, 15 Jul 2021 00:11:42 +0300
Subject: [squid-users] Sharing info from eCAP adapter with other adapters
Message-ID: <CAGSk-42C7LWWzqr_TOUwNg5PORb-uhW+ARmVxWm7+TG=OWPRhQ@mail.gmail.com>

Hi

I have an env with Squid 4 with several ICAPs.
In this env, I set in squid.conf the following:

adaptation_masterx_shared_names X-My-Header
>

and I add an ICAP header X-My-Header with some data in one ICAP and next
ICAPs can use it (I also see it in tcpdump output).

Now I'm writing an eCAP and I did the following (for testing):

static const libecap::Name myHeader("X-My-Header",
> libecap::Name::NextId());

const libecap::Area Adapter::Xaction::option(const libecap::Name &name)
> const
> {
>
>     if (name == myHeader) {

        std::string t = "popo";

        return libecap::Area(t.data(), t.size());
>
    }

    return libecap::Area();
> }
>
>
> void Adapter::Xaction::visitEachOption(libecap::NamedValueVisitor
> &visitor) const
> {
>
>     std::string t = "popo";
>
>     visitor.visit(myHeader, libecap::Area(t.data(), t.size()));
>

}


 It is much like the clamAV eCAP example.
What I see in tcpdump output is the following:

X.....qZREQMOD icap://my.proxy:1234/request ICAP/1.0
> Host: my.proxy:1234
> Date: Wed, 14 Jul 2021 20:37:33 GMT
> X-My-Header: .
> Encapsulated: req-hdr=0, null-body=427
> Preview: 0
> Allow: 204


Meaning, it indeed added the X-My-Header as ICAP header for the benefit of
the ICAP server on the chain but it seems the value is just a dot.
What am I doing wrong?
BTW, I'm struggling to find a decent eCAP interface documentation. Can you
please help me understand what is the difference between 'option' and
'visitEachOption' methods?

Thanks,
Moti
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210715/b923b8a2/attachment.htm>

From squid3 at treenet.co.nz  Thu Jul 15 04:38:25 2021
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Thu, 15 Jul 2021 16:38:25 +1200
Subject: [squid-users] Sharing info from eCAP adapter with other adapters
In-Reply-To: <CAGSk-42C7LWWzqr_TOUwNg5PORb-uhW+ARmVxWm7+TG=OWPRhQ@mail.gmail.com>
References: <CAGSk-42C7LWWzqr_TOUwNg5PORb-uhW+ARmVxWm7+TG=OWPRhQ@mail.gmail.com>
Message-ID: <5418cfb3d0e0cbfd0b705307b514a503@treenet.co.nz>

On 2021-07-15 09:11, Moti Berger wrote:
> 
> Meaning, it indeed added the X-My-Header as ICAP header for the
> benefit of the ICAP server on the chain but it seems the value is just
> a dot.
> What am I doing wrong?

This is best asked via the libecap help channels (see below).


> BTW, I'm struggling to find a decent eCAP interface documentation.

AFAICT, That is still apparently an item on the libecap official TODO 
list.

For now the best documentation I am aware of is Alex responses in the 
Launchpad Answers (<https://answers.launchpad.net/ecap>) and FAQ 
(<https://answers.launchpad.net/ecap/+faqs>).

The clearest (huh!) I've been able to find is at 
<https://answers.launchpad.net/ecap/+question/659846>.


> Can
> you please help me understand what is the difference between 'option'
> and 'visitEachOption' methods?

To quote Alex from the LP Answers discussion:
  "One is of requesting a single known option (i.e., meta header). The 
other is for iterating all options".



Amos


From squid3 at treenet.co.nz  Thu Jul 15 04:59:46 2021
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Thu, 15 Jul 2021 16:59:46 +1200
Subject: [squid-users] refresh_pattern and "?"
In-Reply-To: <CAFcUVs0yGzPE77cSEkS+s-JTjYatjwvQx1uV+9EW2--6rbY-Vg@mail.gmail.com>
References: <CAFcUVs2CTWJZSZZgBNKcH8CWKGD6ibU0n_O-0GUb5WWnTzO9NA@mail.gmail.com>
 <CAFcUVs3YZfGAnFweab3JavrS5oK2prHHf7r7EJhDa6Tu-Q0TrQ@mail.gmail.com>
 <4aea102c6192abfe279bef4c079a1c18@treenet.co.nz>
 <CAFcUVs0yGzPE77cSEkS+s-JTjYatjwvQx1uV+9EW2--6rbY-Vg@mail.gmail.com>
Message-ID: <47565fd9e6b60716b815f7eeb379e094@treenet.co.nz>

On 2021-07-15 07:48, Vincent Tamet wrote:
> You are totally right !
> The problem was on my side with the acl regular expression used to
> choose extensions to be cached:
> acl images url_regex -i
> \.(bmp|gif|ico|jpeg|jpg|png|svg|tif|tiff|webp)$
> $ was not matching for '?query-string'
> 

For this usage my advice is to have (|\?.*)$ as the end of the pattern.
So it looks like this:

   refresh_pattern -i \.(bmp|gif|ico|jpe?g|png|tiff?|webp)(|\?.*)$


> * Your answer helps me to find my error.
> * And I am now thinking about changing the way of doing the cache
>   (a special refresh for my acls or/and a default to 0 0% 0 to use the
> TCP_REFRESH_UNMODIFIED).
> 

FYI: the latest Squid versions have store_miss and send_hit that may 
help you out with the caching ACLs redesign. see 
<http://www.squid-cache.org/Doc/config/cache/>


> Thank you very much :)
> And sorry for the sound ! :(
> 

Welcome. No worries. Helping is what this mailing list is for.

Amos


From robertkwild at gmail.com  Thu Jul 15 10:02:18 2021
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 15 Jul 2021 11:02:18 +0100
Subject: [squid-users] wildcard for numbers in url whitelisting
Message-ID: <CAGU_CiJ2C-G+Tns7prKC0m-LT7LiO0+1fmPvJmSGSh-6DgPYSA@mail.gmail.com>

hi all,

im using the below to do my whitelisting

acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"

in the file contains lines like so

.google.com
.office.com
.microsoft.com

etc etc...

but instead of putting all these urls down in the whitelist

.vsb25.tawk.to
.vsb56.tawk.to
.vsb37.tawk.to
.vsb8.tawk.to
.vsb68.tawk.to
.vsb92.tawk.to
.vsb23.tawk.to
.vsb116.tawk.to

would this work

.vsb[0-9].tawk.to
.vsb[0-9][0-9].tawk.to
.vsb[0-9][0-9][0-9].tawk.to

thanks,
rob

-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210715/32e531f0/attachment.htm>

From squid3 at treenet.co.nz  Thu Jul 15 10:53:15 2021
From: squid3 at treenet.co.nz (=?UTF-8?B?4oCqQW1vcyBKZWZmcmllc+KArA==?=)
Date: Thu, 15 Jul 2021 22:53:15 +1200
Subject: [squid-users] wildcard for numbers in url whitelisting
References: <CAGU_CiJ2C-G+Tns7prKC0m-LT7LiO0+1fmPvJmSGSh-6DgPYSA@mail.gmail.com>
Message-ID: <kpz4sh7hxpr4dlsil4y26mlgops37k8yv2v14hfw3dkdrtgpja8t0ohsncfiwabutipkocl9iu3sjzxvxpnrei8iku-u7qhk2-gq3a2ba7fnm9-a5nt6f9amkz4-orf7q3-2ob0ur8d2v7ncbc6ps.1626346395816@email.android.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210715/4e024f87/attachment.htm>

From robertkwild at gmail.com  Thu Jul 15 10:59:34 2021
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 15 Jul 2021 11:59:34 +0100
Subject: [squid-users] wildcard for numbers in url whitelisting
In-Reply-To: <kpz4sh7hxpr4dlsil4y26mlgops37k8yv2v14hfw3dkdrtgpja8t0ohsncfiwabutipkocl9iu3sjzxvxpnrei8iku-u7qhk2-gq3a2ba7fnm9-a5nt6f9amkz4-orf7q3-2ob0ur8d2v7ncbc6ps.1626346395816@email.android.com>
References: <CAGU_CiJ2C-G+Tns7prKC0m-LT7LiO0+1fmPvJmSGSh-6DgPYSA@mail.gmail.com>
 <kpz4sh7hxpr4dlsil4y26mlgops37k8yv2v14hfw3dkdrtgpja8t0ohsncfiwabutipkocl9iu3sjzxvxpnrei8iku-u7qhk2-gq3a2ba7fnm9-a5nt6f9amkz4-orf7q3-2ob0ur8d2v7ncbc6ps.1626346395816@email.android.com>
Message-ID: <CAGU_CiLPt8iK11T-B=run6X+bm+iM4K9He05hintBzywJfn1jQ@mail.gmail.com>

Thanks Amos, if I change to that acl, I imagine I will need to redo all my
whitelist files

Ie

.Google.com

Will be

.\google\.com

Is that correct?

On Thu, 15 Jul 2021, 11:53 ?Amos Jeffries?, <squid3 at treenet.co.nz> wrote:

> You will need to change to ssl::server_name_regex ACL type to use regex
> patterns.
>
> Also, take care that all values are valid regex pattern and characters
> which are special in regex are properly escaped. Eg the dots.
>
> Amos
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210715/6a6f5649/attachment.htm>

From uhlar at fantomas.sk  Thu Jul 15 11:06:35 2021
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 15 Jul 2021 13:06:35 +0200
Subject: [squid-users] wildcard for numbers in url whitelisting
In-Reply-To: <CAGU_CiLPt8iK11T-B=run6X+bm+iM4K9He05hintBzywJfn1jQ@mail.gmail.com>
References: <CAGU_CiJ2C-G+Tns7prKC0m-LT7LiO0+1fmPvJmSGSh-6DgPYSA@mail.gmail.com>
 <kpz4sh7hxpr4dlsil4y26mlgops37k8yv2v14hfw3dkdrtgpja8t0ohsncfiwabutipkocl9iu3sjzxvxpnrei8iku-u7qhk2-gq3a2ba7fnm9-a5nt6f9amkz4-orf7q3-2ob0ur8d2v7ncbc6ps.1626346395816@email.android.com>
 <CAGU_CiLPt8iK11T-B=run6X+bm+iM4K9He05hintBzywJfn1jQ@mail.gmail.com>
Message-ID: <20210715110635.GB1728@fantomas.sk>

>On Thu, 15 Jul 2021, 11:53 ?Amos Jeffries?, <squid3 at treenet.co.nz> wrote:
>> You will need to change to ssl::server_name_regex ACL type to use regex
>> patterns.
>>
>> Also, take care that all values are valid regex pattern and characters
>> which are special in regex are properly escaped. Eg the dots.

On 15.07.21 11:59, robert k Wild wrote:
>Thanks Amos, if I change to that acl, I imagine I will need to redo all my
>whitelist files
>
>Ie
>
>.Google.com
>
>Will be
>
>.\google\.com
>
>Is that correct?

yes, so I recommend you to avoid regexes as much as possible and better use
two access directives.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
A day without sunshine is like, night.


From robertkwild at gmail.com  Thu Jul 15 11:17:47 2021
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 15 Jul 2021 12:17:47 +0100
Subject: [squid-users] wildcard for numbers in url whitelisting
In-Reply-To: <CAGU_CiLPt8iK11T-B=run6X+bm+iM4K9He05hintBzywJfn1jQ@mail.gmail.com>
References: <CAGU_CiJ2C-G+Tns7prKC0m-LT7LiO0+1fmPvJmSGSh-6DgPYSA@mail.gmail.com>
 <kpz4sh7hxpr4dlsil4y26mlgops37k8yv2v14hfw3dkdrtgpja8t0ohsncfiwabutipkocl9iu3sjzxvxpnrei8iku-u7qhk2-gq3a2ba7fnm9-a5nt6f9amkz4-orf7q3-2ob0ur8d2v7ncbc6ps.1626346395816@email.android.com>
 <CAGU_CiLPt8iK11T-B=run6X+bm+iM4K9He05hintBzywJfn1jQ@mail.gmail.com>
Message-ID: <CAGU_CiLGuXZd7m33dzRs8kQPMdHK5cymsTL=OQE4qwJmEAYxKw@mail.gmail.com>

i think i get you, so have two acl lists, like

acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
acl whitelist ssl::server_name_regex "/usr/local/squid/etc/urlwhitereg.txt"

On Thu, 15 Jul 2021 at 11:59, robert k Wild <robertkwild at gmail.com> wrote:

> Thanks Amos, if I change to that acl, I imagine I will need to redo all my
> whitelist files
>
> Ie
>
> .Google.com
>
> Will be
>
> .\google\.com
>
> Is that correct?
>
> On Thu, 15 Jul 2021, 11:53 ?Amos Jeffries?, <squid3 at treenet.co.nz> wrote:
>
>> You will need to change to ssl::server_name_regex ACL type to use regex
>> patterns.
>>
>> Also, take care that all values are valid regex pattern and characters
>> which are special in regex are properly escaped. Eg the dots.
>>
>> Amos
>>
>

-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210715/9ab591e4/attachment.htm>

From robertkwild at gmail.com  Thu Jul 15 12:08:44 2021
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 15 Jul 2021 13:08:44 +0100
Subject: [squid-users] wildcard for numbers in url whitelisting
In-Reply-To: <CAGU_CiLGuXZd7m33dzRs8kQPMdHK5cymsTL=OQE4qwJmEAYxKw@mail.gmail.com>
References: <CAGU_CiJ2C-G+Tns7prKC0m-LT7LiO0+1fmPvJmSGSh-6DgPYSA@mail.gmail.com>
 <kpz4sh7hxpr4dlsil4y26mlgops37k8yv2v14hfw3dkdrtgpja8t0ohsncfiwabutipkocl9iu3sjzxvxpnrei8iku-u7qhk2-gq3a2ba7fnm9-a5nt6f9amkz4-orf7q3-2ob0ur8d2v7ncbc6ps.1626346395816@email.android.com>
 <CAGU_CiLPt8iK11T-B=run6X+bm+iM4K9He05hintBzywJfn1jQ@mail.gmail.com>
 <CAGU_CiLGuXZd7m33dzRs8kQPMdHK5cymsTL=OQE4qwJmEAYxKw@mail.gmail.com>
Message-ID: <CAGU_Ci+t7G0T_BBGm64UwPnAMOzG9HwBOxPE41DgNTpZit=BOg@mail.gmail.com>

is anything wrong with this as it doesnt work

#HTTP_HTTPS whitelist websites
acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"

#HTTP_HTTPS whitelist websites regex
#acl whitelistreg ssl::server_name_regex
"/usr/local/squid/etc/urlwhitereg.txt"

http_access allow activation whitelist whitelistreg
http_access deny all

time being ive hashed out acl regex and deleted whitelistregon my http
access allow as it doesnt work

can you see anything wrong with it?

On Thu, 15 Jul 2021 at 12:17, robert k Wild <robertkwild at gmail.com> wrote:

> i think i get you, so have two acl lists, like
>
> acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
> acl whitelist ssl::server_name_regex "/usr/local/squid/etc/urlwhitereg.txt"
>
> On Thu, 15 Jul 2021 at 11:59, robert k Wild <robertkwild at gmail.com> wrote:
>
>> Thanks Amos, if I change to that acl, I imagine I will need to redo all
>> my whitelist files
>>
>> Ie
>>
>> .Google.com
>>
>> Will be
>>
>> .\google\.com
>>
>> Is that correct?
>>
>> On Thu, 15 Jul 2021, 11:53 ?Amos Jeffries?, <squid3 at treenet.co.nz> wrote:
>>
>>> You will need to change to ssl::server_name_regex ACL type to use regex
>>> patterns.
>>>
>>> Also, take care that all values are valid regex pattern and characters
>>> which are special in regex are properly escaped. Eg the dots.
>>>
>>> Amos
>>>
>>
>
> --
> Regards,
>
> Robert K Wild.
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210715/685b25ba/attachment.htm>

From belle at bazuin.nl  Thu Jul 15 12:13:19 2021
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Thu, 15 Jul 2021 14:13:19 +0200
Subject: [squid-users] wildcard for numbers in url whitelisting
In-Reply-To: <CAGU_Ci+t7G0T_BBGm64UwPnAMOzG9HwBOxPE41DgNTpZit=BOg@mail.gmail.com>
References: <CAGU_CiLGuXZd7m33dzRs8kQPMdHK5cymsTL=OQE4qwJmEAYxKw@mail.gmail.com>
Message-ID: <vmime.60f0265f.3f04.7622929957c67acf@ms249-lin-003.rotterdam.bazuin.nl>

post a few lines from? "/usr/local/squid/etc/urlwhite.txt"


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens robert k Wild
Verzonden: donderdag 15 juli 2021 14:09
Aan: Amos Jeffries
CC: squid-users at lists.squid-cache.org
Onderwerp: Re: [squid-users] wildcard for numbers in url whitelisting



is anything wrong with this as it doesnt work


#HTTP_HTTPS whitelist websites
acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"

#HTTP_HTTPS whitelist websites regex
#acl whitelistreg ssl::server_name_regex "/usr/local/squid/etc/urlwhitereg.txt"

http_access allow activation whitelist whitelistreg
http_access deny all


time being ive hashed out acl regex and deleted whitelistregon my http access allow as it doesnt work


can you see anything wrong with it?



On Thu, 15 Jul 2021 at 12:17, robert k Wild <robertkwild at gmail.com> wrote:

i think i get you, so have two acl lists, like


acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
acl whitelist ssl::server_name_regex "/usr/local/squid/etc/urlwhitereg.txt"


On Thu, 15 Jul 2021 at 11:59, robert k Wild <robertkwild at gmail.com> wrote:

Thanks Amos, if I change to that acl, I imagine I will need to redo all my whitelist files 

Ie


.Google.com


Will be


.\google\.com


Is that?correct?


On Thu, 15 Jul 2021, 11:53 Amos Jeffries , <squid3 at treenet.co.nz> wrote:

You will need to change to ssl::server_name_regex ACL type to use regex patterns. 

Also, take care that all values are valid regex pattern and characters which are special in regex are properly escaped. Eg the dots. 
Amos






-- 
Regards, 

Robert K Wild.





-- 
Regards, 

Robert K Wild.


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210715/e9d086bd/attachment.htm>

From uhlar at fantomas.sk  Thu Jul 15 12:24:05 2021
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 15 Jul 2021 14:24:05 +0200
Subject: [squid-users] wildcard for numbers in url whitelisting
In-Reply-To: <CAGU_Ci+t7G0T_BBGm64UwPnAMOzG9HwBOxPE41DgNTpZit=BOg@mail.gmail.com>
References: <CAGU_CiJ2C-G+Tns7prKC0m-LT7LiO0+1fmPvJmSGSh-6DgPYSA@mail.gmail.com>
 <kpz4sh7hxpr4dlsil4y26mlgops37k8yv2v14hfw3dkdrtgpja8t0ohsncfiwabutipkocl9iu3sjzxvxpnrei8iku-u7qhk2-gq3a2ba7fnm9-a5nt6f9amkz4-orf7q3-2ob0ur8d2v7ncbc6ps.1626346395816@email.android.com>
 <CAGU_CiLPt8iK11T-B=run6X+bm+iM4K9He05hintBzywJfn1jQ@mail.gmail.com>
 <CAGU_CiLGuXZd7m33dzRs8kQPMdHK5cymsTL=OQE4qwJmEAYxKw@mail.gmail.com>
 <CAGU_Ci+t7G0T_BBGm64UwPnAMOzG9HwBOxPE41DgNTpZit=BOg@mail.gmail.com>
Message-ID: <20210715122405.GA5120@fantomas.sk>

On 15.07.21 13:08, robert k Wild wrote:
>#HTTP_HTTPS whitelist websites
>acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
>
>#HTTP_HTTPS whitelist websites regex
>#acl whitelistreg ssl::server_name_regex
>"/usr/local/squid/etc/urlwhitereg.txt"
>

you must split those to two lines, as all ACLs must match for http_access
line to match:

http_access allow activation whitelist
http_access allow activation whitelistreg
http_access deny all

I only can guess what "activation" means.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Microsoft dick is soft to do no harm


From robertkwild at gmail.com  Thu Jul 15 12:43:12 2021
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 15 Jul 2021 13:43:12 +0100
Subject: [squid-users] wildcard for numbers in url whitelisting
In-Reply-To: <20210715122405.GA5120@fantomas.sk>
References: <CAGU_CiJ2C-G+Tns7prKC0m-LT7LiO0+1fmPvJmSGSh-6DgPYSA@mail.gmail.com>
 <kpz4sh7hxpr4dlsil4y26mlgops37k8yv2v14hfw3dkdrtgpja8t0ohsncfiwabutipkocl9iu3sjzxvxpnrei8iku-u7qhk2-gq3a2ba7fnm9-a5nt6f9amkz4-orf7q3-2ob0ur8d2v7ncbc6ps.1626346395816@email.android.com>
 <CAGU_CiLPt8iK11T-B=run6X+bm+iM4K9He05hintBzywJfn1jQ@mail.gmail.com>
 <CAGU_CiLGuXZd7m33dzRs8kQPMdHK5cymsTL=OQE4qwJmEAYxKw@mail.gmail.com>
 <CAGU_Ci+t7G0T_BBGm64UwPnAMOzG9HwBOxPE41DgNTpZit=BOg@mail.gmail.com>
 <20210715122405.GA5120@fantomas.sk>
Message-ID: <CAGU_Ci+Ls0ATgyCNkOYpzmhtgTE1=y983-TKAV-Ry6gW1AoT0A@mail.gmail.com>

activation is an acl for ports, so

acl activation port 80 443 8090 9251 # office adobe web

On Thu, 15 Jul 2021 at 13:24, Matus UHLAR - fantomas <uhlar at fantomas.sk>
wrote:

> On 15.07.21 13:08, robert k Wild wrote:
> >#HTTP_HTTPS whitelist websites
> >acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
> >
> >#HTTP_HTTPS whitelist websites regex
> >#acl whitelistreg ssl::server_name_regex
> >"/usr/local/squid/etc/urlwhitereg.txt"
> >
>
> you must split those to two lines, as all ACLs must match for http_access
> line to match:
>
> http_access allow activation whitelist
> http_access allow activation whitelistreg
> http_access deny all
>
> I only can guess what "activation" means.
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> Microsoft dick is soft to do no harm
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210715/071dddf9/attachment.htm>

From robertkwild at gmail.com  Thu Jul 15 12:54:56 2021
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 15 Jul 2021 13:54:56 +0100
Subject: [squid-users] wildcard for numbers in url whitelisting
In-Reply-To: <CAGU_Ci+Ls0ATgyCNkOYpzmhtgTE1=y983-TKAV-Ry6gW1AoT0A@mail.gmail.com>
References: <CAGU_CiJ2C-G+Tns7prKC0m-LT7LiO0+1fmPvJmSGSh-6DgPYSA@mail.gmail.com>
 <kpz4sh7hxpr4dlsil4y26mlgops37k8yv2v14hfw3dkdrtgpja8t0ohsncfiwabutipkocl9iu3sjzxvxpnrei8iku-u7qhk2-gq3a2ba7fnm9-a5nt6f9amkz4-orf7q3-2ob0ur8d2v7ncbc6ps.1626346395816@email.android.com>
 <CAGU_CiLPt8iK11T-B=run6X+bm+iM4K9He05hintBzywJfn1jQ@mail.gmail.com>
 <CAGU_CiLGuXZd7m33dzRs8kQPMdHK5cymsTL=OQE4qwJmEAYxKw@mail.gmail.com>
 <CAGU_Ci+t7G0T_BBGm64UwPnAMOzG9HwBOxPE41DgNTpZit=BOg@mail.gmail.com>
 <20210715122405.GA5120@fantomas.sk>
 <CAGU_Ci+Ls0ATgyCNkOYpzmhtgTE1=y983-TKAV-Ry6gW1AoT0A@mail.gmail.com>
Message-ID: <CAGU_CiLdKs4GoO8DRzTSsnag9gH13+5CvjXVu7K+R0qnUVyPNQ@mail.gmail.com>

ok this hasnt worked, its allowing all the internet now ie urls

#HTTP_HTTPS whitelist websites
acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"

#HTTP_HTTPS whitelist websites regex
acl whitelistreg ssl::server_name_regex
"/usr/local/squid/etc/urlwhitereg.txt"

http_access allow activation
http_access allow whitelist
http_access allow whitelistreg
http_access deny all

On Thu, 15 Jul 2021 at 13:43, robert k Wild <robertkwild at gmail.com> wrote:

> activation is an acl for ports, so
>
> acl activation port 80 443 8090 9251 # office adobe web
>
> On Thu, 15 Jul 2021 at 13:24, Matus UHLAR - fantomas <uhlar at fantomas.sk>
> wrote:
>
>> On 15.07.21 13:08, robert k Wild wrote:
>> >#HTTP_HTTPS whitelist websites
>> >acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
>> >
>> >#HTTP_HTTPS whitelist websites regex
>> >#acl whitelistreg ssl::server_name_regex
>> >"/usr/local/squid/etc/urlwhitereg.txt"
>> >
>>
>> you must split those to two lines, as all ACLs must match for http_access
>> line to match:
>>
>> http_access allow activation whitelist
>> http_access allow activation whitelistreg
>> http_access deny all
>>
>> I only can guess what "activation" means.
>>
>> --
>> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
>> Warning: I wish NOT to receive e-mail advertising to this address.
>> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
>> Microsoft dick is soft to do no harm
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
> --
> Regards,
>
> Robert K Wild.
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210715/83742fc9/attachment.htm>

From uhlar at fantomas.sk  Thu Jul 15 13:02:36 2021
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 15 Jul 2021 15:02:36 +0200
Subject: [squid-users] wildcard for numbers in url whitelisting
In-Reply-To: <CAGU_CiLdKs4GoO8DRzTSsnag9gH13+5CvjXVu7K+R0qnUVyPNQ@mail.gmail.com>
References: <CAGU_CiJ2C-G+Tns7prKC0m-LT7LiO0+1fmPvJmSGSh-6DgPYSA@mail.gmail.com>
 <kpz4sh7hxpr4dlsil4y26mlgops37k8yv2v14hfw3dkdrtgpja8t0ohsncfiwabutipkocl9iu3sjzxvxpnrei8iku-u7qhk2-gq3a2ba7fnm9-a5nt6f9amkz4-orf7q3-2ob0ur8d2v7ncbc6ps.1626346395816@email.android.com>
 <CAGU_CiLPt8iK11T-B=run6X+bm+iM4K9He05hintBzywJfn1jQ@mail.gmail.com>
 <CAGU_CiLGuXZd7m33dzRs8kQPMdHK5cymsTL=OQE4qwJmEAYxKw@mail.gmail.com>
 <CAGU_Ci+t7G0T_BBGm64UwPnAMOzG9HwBOxPE41DgNTpZit=BOg@mail.gmail.com>
 <20210715122405.GA5120@fantomas.sk>
 <CAGU_Ci+Ls0ATgyCNkOYpzmhtgTE1=y983-TKAV-Ry6gW1AoT0A@mail.gmail.com>
 <CAGU_CiLdKs4GoO8DRzTSsnag9gH13+5CvjXVu7K+R0qnUVyPNQ@mail.gmail.com>
Message-ID: <20210715130235.GA6095@fantomas.sk>

On 15.07.21 13:54, robert k Wild wrote:
>ok this hasnt worked, its allowing all the internet now ie urls

improper regular expressions probably.
Are you aware that regular expressions can match in the middle of string?
you will need to use $ at the end of line e.g.

\.com$

to match .com domains (which is also reason to avoid regexps when posssible)

>#HTTP_HTTPS whitelist websites
>acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
>
>#HTTP_HTTPS whitelist websites regex
>acl whitelistreg ssl::server_name_regex
>"/usr/local/squid/etc/urlwhitereg.txt"

>http_access allow activation

this one should allow whole internet too.

the standard squid config contains ACLs Safe_ports and SSL_ports along with 
directives to disallow using other ports, perhaps you should use those.

>http_access allow whitelist
>http_access allow whitelistreg
>http_access deny all
>
>On Thu, 15 Jul 2021 at 13:43, robert k Wild <robertkwild at gmail.com> wrote:
>
>> activation is an acl for ports, so
>>
>> acl activation port 80 443 8090 9251 # office adobe web
>>
>> On Thu, 15 Jul 2021 at 13:24, Matus UHLAR - fantomas <uhlar at fantomas.sk>
>> wrote:
>>
>>> On 15.07.21 13:08, robert k Wild wrote:
>>> >#HTTP_HTTPS whitelist websites
>>> >acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
>>> >
>>> >#HTTP_HTTPS whitelist websites regex
>>> >#acl whitelistreg ssl::server_name_regex
>>> >"/usr/local/squid/etc/urlwhitereg.txt"
>>> >
>>>
>>> you must split those to two lines, as all ACLs must match for http_access
>>> line to match:
>>>
>>> http_access allow activation whitelist
>>> http_access allow activation whitelistreg
>>> http_access deny all
>>>
>>> I only can guess what "activation" means.
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
"Two words: Windows survives." - Craig Mundie, Microsoft senior strategist
"So does syphillis. Good thing we have penicillin." - Matthew Alton


From robertkwild at gmail.com  Thu Jul 15 14:13:51 2021
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 15 Jul 2021 15:13:51 +0100
Subject: [squid-users] wildcard for numbers in url whitelisting
In-Reply-To: <20210715130235.GA6095@fantomas.sk>
References: <CAGU_CiJ2C-G+Tns7prKC0m-LT7LiO0+1fmPvJmSGSh-6DgPYSA@mail.gmail.com>
 <kpz4sh7hxpr4dlsil4y26mlgops37k8yv2v14hfw3dkdrtgpja8t0ohsncfiwabutipkocl9iu3sjzxvxpnrei8iku-u7qhk2-gq3a2ba7fnm9-a5nt6f9amkz4-orf7q3-2ob0ur8d2v7ncbc6ps.1626346395816@email.android.com>
 <CAGU_CiLPt8iK11T-B=run6X+bm+iM4K9He05hintBzywJfn1jQ@mail.gmail.com>
 <CAGU_CiLGuXZd7m33dzRs8kQPMdHK5cymsTL=OQE4qwJmEAYxKw@mail.gmail.com>
 <CAGU_Ci+t7G0T_BBGm64UwPnAMOzG9HwBOxPE41DgNTpZit=BOg@mail.gmail.com>
 <20210715122405.GA5120@fantomas.sk>
 <CAGU_Ci+Ls0ATgyCNkOYpzmhtgTE1=y983-TKAV-Ry6gW1AoT0A@mail.gmail.com>
 <CAGU_CiLdKs4GoO8DRzTSsnag9gH13+5CvjXVu7K+R0qnUVyPNQ@mail.gmail.com>
 <20210715130235.GA6095@fantomas.sk>
Message-ID: <CAGU_Ci+5S7FXQO9kFE=ECsiHupgSt+3a72FsusxaOXufhBPw9w@mail.gmail.com>

this is all i have in my urlwhitereg file

\.vsb\.tawk\.to

so i will change it to the below?

\.vsb\.tawk\.to$

also before i made all the changes it was working ie when these lines

http_access allow activation whitelist

it was only allowing those ports and anything in the urlwhite list ie the
non regex ssl one and everything else ie that wasnt in the whitelist it was
blocking

On Thu, 15 Jul 2021 at 14:02, Matus UHLAR - fantomas <uhlar at fantomas.sk>
wrote:

> On 15.07.21 13:54, robert k Wild wrote:
> >ok this hasnt worked, its allowing all the internet now ie urls
>
> improper regular expressions probably.
> Are you aware that regular expressions can match in the middle of string?
> you will need to use $ at the end of line e.g.
>
> \.com$
>
> to match .com domains (which is also reason to avoid regexps when
> posssible)
>
> >#HTTP_HTTPS whitelist websites
> >acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
> >
> >#HTTP_HTTPS whitelist websites regex
> >acl whitelistreg ssl::server_name_regex
> >"/usr/local/squid/etc/urlwhitereg.txt"
>
> >http_access allow activation
>
> this one should allow whole internet too.
>
> the standard squid config contains ACLs Safe_ports and SSL_ports along
> with
> directives to disallow using other ports, perhaps you should use those.
>
> >http_access allow whitelist
> >http_access allow whitelistreg
> >http_access deny all
> >
> >On Thu, 15 Jul 2021 at 13:43, robert k Wild <robertkwild at gmail.com>
> wrote:
> >
> >> activation is an acl for ports, so
> >>
> >> acl activation port 80 443 8090 9251 # office adobe web
> >>
> >> On Thu, 15 Jul 2021 at 13:24, Matus UHLAR - fantomas <uhlar at fantomas.sk
> >
> >> wrote:
> >>
> >>> On 15.07.21 13:08, robert k Wild wrote:
> >>> >#HTTP_HTTPS whitelist websites
> >>> >acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
> >>> >
> >>> >#HTTP_HTTPS whitelist websites regex
> >>> >#acl whitelistreg ssl::server_name_regex
> >>> >"/usr/local/squid/etc/urlwhitereg.txt"
> >>> >
> >>>
> >>> you must split those to two lines, as all ACLs must match for
> http_access
> >>> line to match:
> >>>
> >>> http_access allow activation whitelist
> >>> http_access allow activation whitelistreg
> >>> http_access deny all
> >>>
> >>> I only can guess what "activation" means.
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> "Two words: Windows survives." - Craig Mundie, Microsoft senior strategist
> "So does syphillis. Good thing we have penicillin." - Matthew Alton
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210715/1c62381f/attachment.htm>

From robertkwild at gmail.com  Fri Jul 16 07:08:53 2021
From: robertkwild at gmail.com (robert k Wild)
Date: Fri, 16 Jul 2021 08:08:53 +0100
Subject: [squid-users] wildcard for numbers in url whitelisting
In-Reply-To: <CAGU_Ci+5S7FXQO9kFE=ECsiHupgSt+3a72FsusxaOXufhBPw9w@mail.gmail.com>
References: <CAGU_CiJ2C-G+Tns7prKC0m-LT7LiO0+1fmPvJmSGSh-6DgPYSA@mail.gmail.com>
 <kpz4sh7hxpr4dlsil4y26mlgops37k8yv2v14hfw3dkdrtgpja8t0ohsncfiwabutipkocl9iu3sjzxvxpnrei8iku-u7qhk2-gq3a2ba7fnm9-a5nt6f9amkz4-orf7q3-2ob0ur8d2v7ncbc6ps.1626346395816@email.android.com>
 <CAGU_CiLPt8iK11T-B=run6X+bm+iM4K9He05hintBzywJfn1jQ@mail.gmail.com>
 <CAGU_CiLGuXZd7m33dzRs8kQPMdHK5cymsTL=OQE4qwJmEAYxKw@mail.gmail.com>
 <CAGU_Ci+t7G0T_BBGm64UwPnAMOzG9HwBOxPE41DgNTpZit=BOg@mail.gmail.com>
 <20210715122405.GA5120@fantomas.sk>
 <CAGU_Ci+Ls0ATgyCNkOYpzmhtgTE1=y983-TKAV-Ry6gW1AoT0A@mail.gmail.com>
 <CAGU_CiLdKs4GoO8DRzTSsnag9gH13+5CvjXVu7K+R0qnUVyPNQ@mail.gmail.com>
 <20210715130235.GA6095@fantomas.sk>
 <CAGU_Ci+5S7FXQO9kFE=ECsiHupgSt+3a72FsusxaOXufhBPw9w@mail.gmail.com>
Message-ID: <CAGU_CiKeVHo+3fgJxXS5yw1HZV9Av_QvMb-MqV2tUPJjDC6ORQ@mail.gmail.com>

ok i finally realised for myself why it wasnt working, thanks so much
Matus!!!

http_access allow activation - as this is at the top, allows all internet
on ports 80 443, so the below is totally ignored
http_access allow whitelist
http_access allow whitelistreg
http_access deny all

http_access allow activation  whitelist - only allows ports above only AND
to the certain websites on the whitelist
http_access allow activation  whitelistreg -  only allows ports above only
AND to the certain websites on the whitelistreg
http_access deny all - denies all

thanks Amos aswell for pointing out the ssl server name wouldnt do regex

On Thu, 15 Jul 2021 at 15:13, robert k Wild <robertkwild at gmail.com> wrote:

> this is all i have in my urlwhitereg file
>
> \.vsb\.tawk\.to
>
> so i will change it to the below?
>
> \.vsb\.tawk\.to$
>
> also before i made all the changes it was working ie when these lines
>
> http_access allow activation whitelist
>
> it was only allowing those ports and anything in the urlwhite list ie the
> non regex ssl one and everything else ie that wasnt in the whitelist it was
> blocking
>
> On Thu, 15 Jul 2021 at 14:02, Matus UHLAR - fantomas <uhlar at fantomas.sk>
> wrote:
>
>> On 15.07.21 13:54, robert k Wild wrote:
>> >ok this hasnt worked, its allowing all the internet now ie urls
>>
>> improper regular expressions probably.
>> Are you aware that regular expressions can match in the middle of string?
>> you will need to use $ at the end of line e.g.
>>
>> \.com$
>>
>> to match .com domains (which is also reason to avoid regexps when
>> posssible)
>>
>> >#HTTP_HTTPS whitelist websites
>> >acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
>> >
>> >#HTTP_HTTPS whitelist websites regex
>> >acl whitelistreg ssl::server_name_regex
>> >"/usr/local/squid/etc/urlwhitereg.txt"
>>
>> >http_access allow activation
>>
>> this one should allow whole internet too.
>>
>> the standard squid config contains ACLs Safe_ports and SSL_ports along
>> with
>> directives to disallow using other ports, perhaps you should use those.
>>
>> >http_access allow whitelist
>> >http_access allow whitelistreg
>> >http_access deny all
>> >
>> >On Thu, 15 Jul 2021 at 13:43, robert k Wild <robertkwild at gmail.com>
>> wrote:
>> >
>> >> activation is an acl for ports, so
>> >>
>> >> acl activation port 80 443 8090 9251 # office adobe web
>> >>
>> >> On Thu, 15 Jul 2021 at 13:24, Matus UHLAR - fantomas <
>> uhlar at fantomas.sk>
>> >> wrote:
>> >>
>> >>> On 15.07.21 13:08, robert k Wild wrote:
>> >>> >#HTTP_HTTPS whitelist websites
>> >>> >acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
>> >>> >
>> >>> >#HTTP_HTTPS whitelist websites regex
>> >>> >#acl whitelistreg ssl::server_name_regex
>> >>> >"/usr/local/squid/etc/urlwhitereg.txt"
>> >>> >
>> >>>
>> >>> you must split those to two lines, as all ACLs must match for
>> http_access
>> >>> line to match:
>> >>>
>> >>> http_access allow activation whitelist
>> >>> http_access allow activation whitelistreg
>> >>> http_access deny all
>> >>>
>> >>> I only can guess what "activation" means.
>> --
>> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
>> Warning: I wish NOT to receive e-mail advertising to this address.
>> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
>> "Two words: Windows survives." - Craig Mundie, Microsoft senior strategist
>> "So does syphillis. Good thing we have penicillin." - Matthew Alton
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
> --
> Regards,
>
> Robert K Wild.
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210716/5dac085c/attachment.htm>

From squid3 at treenet.co.nz  Sun Jul 18 06:43:28 2021
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Jul 2021 18:43:28 +1200
Subject: [squid-users] Ubuntu 20.04 "apt update" issues behind a VPN and
 Squid proxy
In-Reply-To: <CAF28NiZ==ceYVCBUSKeh3_AbdQwfgRwpo9mUGvdbbNZegm8Wyg@mail.gmail.com>
References: <CAF28NibkN+CrDDM+2APUKA1rba_6BjZvoDAF11wXCSaFmHSh9Q@mail.gmail.com>
 <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAKGjfS9pLRpMrWAgDPs7Rm4BAAAAAA==@gmail.com>
 <CAF28NibjRsM8gdcoqMC=X-btNMVswsersd3QZTLurgk-=bLVAA@mail.gmail.com>
 <1f5626ce-dea3-bc16-77f8-c9c2fe82b333@treenet.co.nz>
 <CAF28NiZ==ceYVCBUSKeh3_AbdQwfgRwpo9mUGvdbbNZegm8Wyg@mail.gmail.com>
Message-ID: <7613fb7a-220f-6996-1a3c-1c62692d7c79@treenet.co.nz>

On 16/07/21 4:38 pm, David Mills wrote:
> Hi Amos,
> 
> sorry for the big delay here - I've had lots of other things to attend 
> to. It turned on the logging you suggested. For a failed "apt update" 
> attempt on the client I get the following attached access.log and cache.log.
> 
> Are any of the lines
> 
>     2021/07/16 04:28:01.423 kid1| 83,5| bio.cc(396) adjustSSL: Extension
>     13 does not supported!
> 
>     ...
> 
>     20212021/07/16 04:28:32.465 kid1| 83,2| client_side.cc(3749)
>     Squid_SSL_accept: Error negotiating SSL connection on FD 11: Aborted
>     by client: 5
>     ...
> 
>     2021/07/16 04:28:02.452 kid1| Error negotiating SSL on FD 17:
>     error:140920F8:SSL routines:ssl3_get_server_hello:unknown cipher
>     returned (1/-1/0)
> 
>     ...
> 
>     2021/07/16 04:28:01.413 kid1| 83,2| client_side.cc(4293)
>     clientPeekAndSpliceSSL: SSL_accept failed.
> 
> 
> important?
> 

Very. It means the libssl Squid is built with and using is not able to 
understand the TLS the server is sending.

Squid-4 should be more tolerant of this particular issue, or at least 
able to follow the on_unsupported_protocol directive when it is encountered.

Older Squid depend more directly on the library TLS parsing - which 
cannot handle unknown values well.

Amos


From ben.goz87 at gmail.com  Mon Jul 19 12:46:44 2021
From: ben.goz87 at gmail.com (Ben Goz)
Date: Mon, 19 Jul 2021 15:46:44 +0300
Subject: [squid-users] Failed to open file /var/lib/ssl_db/index.txt
Message-ID: <CADAqQfxrQRoLzg4gFGkbXhBt8oiQYPzQMPA2QQpswGJhaWydsA@mail.gmail.com>

By the help of God.

I Managed to configure squid to work transparently using TPROXY configuration.

But randomly I'm observing on cache.log the following errors:

security_file_certgen helper database '/var/lib/ssl_db' failed: Failed
to open file /var/lib/ssl_db/index.txt
security_file_certgen helper database '/var/lib/ssl_db' failed: Failed
to open file /var/lib/ssl_db/index.txt
security_file_certgen helper database 'security_file_certgen helper
database '/var/lib/ssl_db/var/lib/ssl_db' failed: ' failed: Failed to
open file /var/lib/ssl_db/index.txtFailed to open file
/var/lib/ssl_db/index.txt

2021/07/14 21:45:37 kid1| Error negotiating SSL connection on FD 585:
error:00000001:lib(0):func(0):reason(1) (1/-1)
2021/07/14 21:45:37 kid1| Error negotiating SSL connection on FD 569:
error:00000001:lib(0):func(0):reason(1) (1/-1)
2021/07/14 21:45:37 kid1| Error negotiating SSL connection on FD 375:
error:00000001:lib(0):func(0):reason(1) (1/-1)

And the users don't have a connection at all.

How can I resolve this issue?

Thanks,
Ben


From fennex at bk.ru  Tue Jul 20 05:45:49 2021
From: fennex at bk.ru (Fennex)
Date: Tue, 20 Jul 2021 07:45:49 +0200
Subject: [squid-users] Squid domain block feature is at DNS level ?
Message-ID: <160abcf6-454d-c086-ab11-77fb8ac15ca6@bk.ru>

Hello, I'm looking to block some pages. I tried to block domains with a 
feature of my router, but it only works at DNS level. I can bypass it 
using a secure DNS in a browser like Firefox or Brave which accepts this 
"new" feature. I want to know if Squid blocks the domains at DNS level, 
or if it does a DNS lookup and blocks by ip or something similar. Thanks 
you.



From ngtech1ltd at gmail.com  Tue Jul 20 05:57:41 2021
From: ngtech1ltd at gmail.com (NgTech LTD)
Date: Tue, 20 Jul 2021 08:57:41 +0300
Subject: [squid-users] Fwd:  Squid domain block feature is at DNS level ?
In-Reply-To: <CABA8h=QX3QEG_DUhLFWKo-aRR72XtvFF2NWTACQYcKTp1stqcA@mail.gmail.com>
References: <160abcf6-454d-c086-ab11-77fb8ac15ca6@bk.ru>
 <CABA8h=QX3QEG_DUhLFWKo-aRR72XtvFF2NWTACQYcKTp1stqcA@mail.gmail.com>
Message-ID: <CABA8h=TY04GU_A4YVjhWLOtjdcFtexf7jpSzFXNq2RNd0qNFVA@mail.gmail.com>

Hey,

Squid can Intercept both http(port 80) and https(port 443) traffic.
When Squid does these it can enforce on both dns and url level.
Specifically on https there are technical limitations in some cases.
Depends on the setup you can try to test it and make sure it does what you
would expect.

Eliezer

?????? ??? ??, 20 ????? 2021, 8:46, ??? Fennex ?<fennex at bk.ru>:

> Hello, I'm looking to block some pages. I tried to block domains with a
> feature of my router, but it only works at DNS level. I can bypass it
> using a secure DNS in a browser like Firefox or Brave which accepts this
> "new" feature. I want to know if Squid blocks the domains at DNS level,
> or if it does a DNS lookup and blocks by ip or something similar. Thanks
> you.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210720/80eff95e/attachment.htm>

From marcus.kool at urlfilterdb.com  Tue Jul 20 13:38:24 2021
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 20 Jul 2021 14:38:24 +0100
Subject: [squid-users] Squid domain block feature is at DNS level ?
In-Reply-To: <160abcf6-454d-c086-ab11-77fb8ac15ca6@bk.ru>
References: <160abcf6-454d-c086-ab11-77fb8ac15ca6@bk.ru>
Message-ID: <c888853e-6082-61d0-591e-54d8c7c4f20a@urlfilterdb.com>

DNS over HTTPS is used for privacy and also to circumvent filters.

If one wants to filter websites, one must block /all/ filter circumvention techniques as well (or the filter is useless).

shameless plug: the URL database of URLfilterDB has a category dnsoverhttps which can be used to block DNS over HTTPS.

Marcus


On 20/07/2021 06:45, Fennex wrote:
> Hello, I'm looking to block some pages. I tried to block domains with a feature of my router, but it only works at DNS level. I can bypass it using a secure DNS in a browser like Firefox or Brave 
> which accepts this "new" feature. I want to know if Squid blocks the domains at DNS level, or if it does a DNS lookup and blocks by ip or something similar. Thanks you.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210720/814516f3/attachment.htm>

From squid3 at treenet.co.nz  Thu Jul 22 04:24:21 2021
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 22 Jul 2021 16:24:21 +1200
Subject: [squid-users] [squid-announce] Squid 4.16 is available
Message-ID: <860aceb6-9cb4-049f-e683-9d288a876f79@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.16 release!


This release is a bug fix release resolving several issues found in
the prior Squid releases.


The major changes to be aware of since 4.15:

  * Regression Fix: --with-valgrind-debug build

Squid-4.15 changes caused a build failure linking with valgrind
memory tracking tool. This release fixes that to allow memory
leak tracing again.


  * Bug 4528: ICAP transactions quit on async DNS lookups

Squid has never reliably been able to resolve hostnames configured
for ICAP services. They might work most of the time when added to
/etc/hosts, but not always - and would rarely work if relying on
remote DNS servers.

This release adds full support for DNS remote resolution of
service names in icap_service directive. Regardless of where the
hostname is resolved from it can now be expected to resolve and
also properly obey DNS TTL expiry for IP address changes.


  * Bug 5128: Translation: Fix '% i' typo in es/ERR_FORWARDING_DENIED

Spanish translation of the ERR_FORWARDING_DENIED template have
for some time omitted the URL which was having issues being fetched.
The template published with this release and current squid-langpack
downloads will now display the URL identically to other error pages.


   All users of Squid are encouraged to upgrade as soon as possible.


See the ChangeLog for the full list of changes in this and earlier
releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

   http://www.squid-cache.org/Versions/v4/
   ftp://ftp.squid-cache.org/pub/squid/
   ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

   http://www.squid-cache.org/Download/http-mirrors.html
   http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
   http://bugs.squid-cache.org/


Amos Jeffries
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce


From david.mills at acusensus.com  Thu Jul 22 04:51:18 2021
From: david.mills at acusensus.com (David Mills)
Date: Thu, 22 Jul 2021 14:51:18 +1000
Subject: [squid-users] Ubuntu 20.04 "apt update" issues behind a VPN and
 Squid proxy
In-Reply-To: <7613fb7a-220f-6996-1a3c-1c62692d7c79@treenet.co.nz>
References: <CAF28NibkN+CrDDM+2APUKA1rba_6BjZvoDAF11wXCSaFmHSh9Q@mail.gmail.com>
 <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAKGjfS9pLRpMrWAgDPs7Rm4BAAAAAA==@gmail.com>
 <CAF28NibjRsM8gdcoqMC=X-btNMVswsersd3QZTLurgk-=bLVAA@mail.gmail.com>
 <1f5626ce-dea3-bc16-77f8-c9c2fe82b333@treenet.co.nz>
 <CAF28NiZ==ceYVCBUSKeh3_AbdQwfgRwpo9mUGvdbbNZegm8Wyg@mail.gmail.com>
 <7613fb7a-220f-6996-1a3c-1c62692d7c79@treenet.co.nz>
Message-ID: <CAF28NiaJFXNWqSY8=2mAoMuYeqHdDYrQHe2MLFR2Hnf=Wc7ZFA@mail.gmail.com>

Hi Amos,

Upgrading to Squid 4.1 resolved the issue. I had to run

> /usr/lib64/squid/security_file_certgen -c -s /var/spool/squid/ssl_db -M 4MB
>

to get squid to start. But after that all worked well. We'll do a bit more
testing before we roll out to our production servers.

Thanks very much for your help.

Regards,

David Mills

Senior DevOps Engineer

 E: david.mills at acusensus.com

 M: +61 411 513 404

 W: acusensus.com





On Sun, 18 Jul 2021 at 16:45, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 16/07/21 4:38 pm, David Mills wrote:
> > Hi Amos,
> >
> > sorry for the big delay here - I've had lots of other things to attend
> > to. It turned on the logging you suggested. For a failed "apt update"
> > attempt on the client I get the following attached access.log and
> cache.log.
> >
> > Are any of the lines
> >
> >     2021/07/16 04:28:01.423 kid1| 83,5| bio.cc(396) adjustSSL: Extension
> >     13 does not supported!
> >
> >     ...
> >
> >     20212021/07/16 04:28:32.465 kid1| 83,2| client_side.cc(3749)
> >     Squid_SSL_accept: Error negotiating SSL connection on FD 11: Aborted
> >     by client: 5
> >     ...
> >
> >     2021/07/16 04:28:02.452 kid1| Error negotiating SSL on FD 17:
> >     error:140920F8:SSL routines:ssl3_get_server_hello:unknown cipher
> >     returned (1/-1/0)
> >
> >     ...
> >
> >     2021/07/16 04:28:01.413 kid1| 83,2| client_side.cc(4293)
> >     clientPeekAndSpliceSSL: SSL_accept failed.
> >
> >
> > important?
> >
>
> Very. It means the libssl Squid is built with and using is not able to
> understand the TLS the server is sending.
>
> Squid-4 should be more tolerant of this particular issue, or at least
> able to follow the on_unsupported_protocol directive when it is
> encountered.
>
> Older Squid depend more directly on the library TLS parsing - which
> cannot handle unknown values well.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

-- 
DISCLAIMER: Acusensus puts the privacy and security of its clients, its 
data and information at the core of everything we do. The information 
contained in this email (including attachments) is intended only for the 
use of the person(s) to whom it is addressed to, as it may be confidential 
and contain legally privileged information. If you have received this email 
in error, please delete all copies and notify the sender immediately. Any 
views or opinions presented are
solely those of the author and do not 
necessarily represent the views of Acusensus
Pty Ltd. Please consider the 
environment
before printing this email.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210722/4aa51e24/attachment.htm>

From squid.org at bloms.de  Sat Jul 24 07:23:52 2021
From: squid.org at bloms.de (Dieter Bloms)
Date: Sat, 24 Jul 2021 09:23:52 +0200
Subject: [squid-users] Proxy Authentication optional
Message-ID: <20210724072352.4aqn5okksyp7lt2u@bloms.de>

Hello,

I want to implement user authentication (kerberos) on an already existing proxysystem without user authenticaion.
But I know that there are clients, which can't do any authentication.

So is it possible to configure squid, that it ask for proxy
authentication credentials, but if the client can't authenticate skip
this acl and go on with the next acls ?

I tried something like this, but without success:

--snip--
# kerberos authentication 
auth_param negotiate program /usr/sbin/negotiate_kerberos_auth -s HTTP/www-proxy.mydomain -k /etc/squid/HTTP.keytab
auth_param negotiate children 10
auth_param negotiate keep_alive on
acl kerberosauth proxy_auth REQUIRED

acl noauth_port localport 8880

acl give_access any-of kerberosauth noauth_port
http_access allow give_access
--snip--


-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
>From field.


From Antony.Stone at squid.open.source.it  Sat Jul 24 16:14:32 2021
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 24 Jul 2021 18:14:32 +0200
Subject: [squid-users] Proxy Authentication optional
In-Reply-To: <20210724072352.4aqn5okksyp7lt2u@bloms.de>
References: <20210724072352.4aqn5okksyp7lt2u@bloms.de>
Message-ID: <202107241814.32890.Antony.Stone@squid.open.source.it>

On Saturday 24 July 2021 at 09:23:52, Dieter Bloms wrote:

> Hello,
> 
> I want to implement user authentication (kerberos) on an already existing
> proxysystem without user authenticaion. But I know that there are clients,
> which can't do any authentication.

Can you identify these clients in some way, such as IP address, so that they 
can pass an ACL before authentication is requested?

> So is it possible to configure squid, that it ask for proxy
> authentication credentials, but if the client can't authenticate skip
> this acl and go on with the next acls ?

Sounds like a recipe for people bypassing authentication by simply refusing to 
authenticate, and getting allowed through.

What is your purpose in implementing authentication, if you also want some 
clients to get access without authenticating?  What advantage does 
authenticating give the ones who do?


Antony.

-- 
"Linux is going to be part of the future. It's going to be like Unix was."

 - Peter Moore, Asia-Pacific general manager, Microsoft

                                                   Please reply to the list;
                                                         please *don't* CC me.


From jens.altrock at neustadt.eu  Mon Jul 26 11:05:31 2021
From: jens.altrock at neustadt.eu (jens.altrock at neustadt.eu)
Date: Mon, 26 Jul 2021 11:05:31 +0000
Subject: [squid-users] Parent Proxy and direct traffic
Message-ID: <e309d934c9ee48bc8e18364c9755bd6c@sv-mail1.STADT-NW.DE>

Hi!

I got a little Problem:

We have a proxy server that should route special requests to a parent proxy and forward the rest tot he standard gateway. I haven't found any suitable and working configurations, so I'm asking ehre for help. My configuration so far:

acl localnet src 0.0.0.1-0.255.255.255 # RFC 1122 "this" network (LAN)
acl localnet src 10.0.0.0/8 # RFC 1918 local private network (LAN)
acl localnet src 100.64.0.0/10 # RFC 6598 shared address space (CGN)
acl localnet src 169.254.0.0/16 # RFC 3927 link-local (directly plugged) machines
acl localnet src 172.16.0.0/12 # RFC 1918 local private network (LAN)
acl localnet src 192.168.0.0/16 # RFC 1918 local private network (LAN)
acl localnet src fc00::/7 # RFC 4193 local private network range
acl localnet src fe80::/10 # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443 8443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT
acl alwayspeer dstdomain EXAMPLE.COM:777

cache deny all
cache_peer PARENT_PROXY_SRV parent 8080 7 proxy-only no-query
cache_peer_access PARENT_PROXY_SRV allow alwayspeer

#http_access deny !Safe_ports
#http_access deny CONNECT !SSL_ports

http_access allow localhost manager
http_access allow all Safe_ports
http_access allow all SSL_ports
never_direct deny alwayspeer
always_direct allow all
#never_direkt allow all
#always_direct allow all
http_access deny all

include /etc/squid/conf.d/*
http_access allow localhost
http_access deny all

http_port 3128
cache_dir ufs /var/spool/squid 100 16 256
coredump_dir /var/spool/squid
refresh_pattern ^ftp:                           1440       20%        10080
refresh_pattern ^gopher:       1440       0%         1440
refresh_pattern -i (/cgi-bin/|\?) 0           0%         0
refresh_pattern .                  0            20%        4320
cache_effective_user proxy
cache_effective_group proxy
dns_v4_first on

Problem ist hat direct traffic is working, but he doesn't redirect EXAMPLE.COM:777 to the correct Proxy server.

In the access.log I only see:

1627297417.299  31535 CLIENT_IP NONE/503 0 CONNECT EXAMPLE.COM:777 - HIER_NONE/- -

any help and tips appreciated. Thanks so far.

Regards,

Jens

Wichtige Hinweise f?r Mitteilungen an die Stadtverwaltung Neustadt an der Weinstra?e finden Sie unter www.neustadt.eu/kontakt<http://www.neustadt.eu/kontakt>.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210726/d9d773ee/attachment.htm>

From roierachamim at gmail.com  Mon Jul 26 20:15:13 2021
From: roierachamim at gmail.com (roie rachamim)
Date: Mon, 26 Jul 2021 23:15:13 +0300
Subject: [squid-users] ICAP latency information, Bench-marking
Message-ID: <CAD=NrcB0r-6+a_sb0gEOQF-kNrdf_TtMx06m=2vyL0V80dbRCA@mail.gmail.com>

Hi,

Can i get information regarding latency of each ICAP, or even latency added
by processing in squid ?

In addition which tool/method can we use in order to benchmark squid ?

Many Thanks,
Roie
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210726/a2dde164/attachment.htm>

From jason.spashett at menlosecurity.com  Tue Jul 27 09:27:58 2021
From: jason.spashett at menlosecurity.com (Jason Spashett)
Date: Tue, 27 Jul 2021 10:27:58 +0100
Subject: [squid-users] ICAP latency information, Bench-marking
In-Reply-To: <CAD=NrcB0r-6+a_sb0gEOQF-kNrdf_TtMx06m=2vyL0V80dbRCA@mail.gmail.com>
References: <CAD=NrcB0r-6+a_sb0gEOQF-kNrdf_TtMx06m=2vyL0V80dbRCA@mail.gmail.com>
Message-ID: <CANj0NTrx4xvDXeeyhX5mfedf9D0Q4OHqKWVxf90M8iqfi2GF2Q@mail.gmail.com>

If you look at the squid logformat page you can find various
additional logging options available to start with, such as ICAP
processing time. This is a good place to start if you are not using a
custom format already:
http://www.squid-cache.org/Doc/config/logformat/

.e.g.
squid_status=NONE_NONE:HIER_NONE time_response=7
time_icap_processing=6  tls_max=TLS/1.3 tls=TLS/1.3

On Mon, 26 Jul 2021 at 21:15, roie rachamim <roierachamim at gmail.com> wrote:
>
> Hi,
>
> Can i get information regarding latency of each ICAP, or even latency added by processing in squid ?
>
> In addition which tool/method can we use in order to benchmark squid ?
>
> Many Thanks,
> Roie
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Tue Jul 27 10:53:35 2021
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Tue, 27 Jul 2021 22:53:35 +1200
Subject: [squid-users] ICAP latency information, Bench-marking
In-Reply-To: <CANj0NTrx4xvDXeeyhX5mfedf9D0Q4OHqKWVxf90M8iqfi2GF2Q@mail.gmail.com>
References: <CAD=NrcB0r-6+a_sb0gEOQF-kNrdf_TtMx06m=2vyL0V80dbRCA@mail.gmail.com>
 <CANj0NTrx4xvDXeeyhX5mfedf9D0Q4OHqKWVxf90M8iqfi2GF2Q@mail.gmail.com>
Message-ID: <fc5238bcd6a24572f5f15a50e2e8f0c3@treenet.co.nz>

On 2021-07-27 21:27, Jason Spashett wrote:
> If you look at the squid logformat page you can find various
> additional logging options available to start with, such as ICAP
> processing time. This is a good place to start if you are not using a
> custom format already:
> http://www.squid-cache.org/Doc/config/logformat/
> 
> .e.g.
> squid_status=NONE_NONE:HIER_NONE time_response=7
> time_icap_processing=6  tls_max=TLS/1.3 tls=TLS/1.3
> 

Indeed. access_log directive format gives access to the metrics about 
the HTTP transactions.

There is also a specific icap_log directive for recording metrics of the 
ICAP service transactions.

Between those two directives and choice of the metrics you want to see 
you can discover most things about Squid vs external latency.


Amos



> On Mon, 26 Jul 2021 at 21:15, roie rachamim <roierachamim at gmail.com> 
> wrote:
>> 
>> Hi,
>> 
>> Can i get information regarding latency of each ICAP, or even latency 
>> added by processing in squid ?
>> 
>> In addition which tool/method can we use in order to benchmark squid ?
>> 
>> Many Thanks,
>> Roie
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Tue Jul 27 11:38:23 2021
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Tue, 27 Jul 2021 23:38:23 +1200
Subject: [squid-users] Parent Proxy and direct traffic
In-Reply-To: <e309d934c9ee48bc8e18364c9755bd6c@sv-mail1.STADT-NW.DE>
References: <e309d934c9ee48bc8e18364c9755bd6c@sv-mail1.STADT-NW.DE>
Message-ID: <5823cf8e23bc496c0d076bca7e538f6b@treenet.co.nz>

On 2021-07-26 23:05, jens.altrock wrote:
> Hi!
> 
> I got a little Problem:
> 
> We have a proxy server that should route special requests to a parent
> proxy and forward the rest tot he standard gateway. I haven't found
> any suitable and working configurations, so I'm asking ehre for help.

You appear to not understand some of the directives correctly.

As a result your config currently forces Squid to ignore all cache_peer 
lines.



> My configuration so far:
> 


> 
> _acl alwayspeer dstdomain EXAMPLE.COM:777_
> 

":777" is not part of any domain name.

This ACL can never produce a match result.

To check two different properties (domain and port) you need two 
different ACLs.

For example;
  acl example dstdomain example.com
  acl port777 port 777

  cache_peer_access PARENT_PROXY_SRV allow example port777
  never_direct allow example port777


> 
> _cache deny all_
> 
> _cache_peer PARENT_PROXY_SRV parent 8080 7 proxy-only no-query_
> 
> _cache_peer_access PARENT_PROXY_SRV allow alwayspeer_
> 

Since "alwayspeer" is always false this line means the default for 
traffic going to this peer is "deny all".

With the ACL adjustments from above this would be:

  cache_peer_access PARENT_PROXY_SRV allow example port777


> 
> _#http_access deny !Safe_ports_
> 
> _#http_access deny CONNECT !SSL_ports_
> 

Please restore those rules. They are protecting your proxy against being 
abused as a relay for DoS attacks against your network. They have 
nothing to do with routing of valid HTTP messages.


> 
> _http_access allow localhost manager_
> 

> _http_access allow all Safe_ports_
> 
> _http_access allow all SSL_ports_
> 

Remove those two lines **urgently**.


> _never_direct deny alwayspeer_
> 
> _always_direct allow all_
> 

 From the actions chosen I see you misunderstand these two directives.

"DIRECT" means using DNS (or equivalent) to locate and connect to origin 
server(s) from the URL domain name.

always_direct has precedence. So "allow all" means servers will *always* 
be found using URL domain and DNS instead of your config file and 
cache_peer lines.

   -> you need to remove the always_direct line.

never_direct means the URL domain / DNS lookup mechanism is *never* 
used. Only cache_peer have any possibility, and only when 
cache_peer_access rules also say allow.

   -> the 'action' field needs to be "allow" in order to force cache_peer 
to be used.

In both of these directives "deny" is simply a way to stop processing 
the directive lines before any more checks happen. eg, a way to put 
"except" or "unless" clauses into the logic.



> 
> _http_access deny all_
> 

No http_access rules placed below this will be checked. You should 
remove this line.

FYI; the whole point of include directive on the next line is so you can 
put your custom cache_peer and related rules into a file in there and 
not worry about the OS Squid package fiddling with it.

> 
> _include /etc/squid/conf.d/*_
> 
> _http_access allow localhost_
> 
> _http_access deny all_
> 


> 
> Problem ist hat direct traffic is working, but he doesn't redirect
> EXAMPLE.COM:777 to the correct Proxy server.
> 
> In the access.log I only see:
> 
> 1627297417.299  31535 CLIENT_IP NONE/503 0 CONNECT EXAMPLE.COM:777 -
> HIER_NONE/- -
> 


Amos


From robertkwild at gmail.com  Tue Jul 27 12:25:17 2021
From: robertkwild at gmail.com (robert k Wild)
Date: Tue, 27 Jul 2021 13:25:17 +0100
Subject: [squid-users] where to put my own rules
Message-ID: <CAGU_CiLtabA1zLityndyzW-xGYi9+v=CaE7T6MBrF+rVFCDvkQ@mail.gmail.com>

is it best to put my "ssl bump" and "no ssl interception" rules under

# Recommended minimum Access Permission configuration:

or

# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS

#SSL Bump
http_port 3128 ssl-bump cert=/usr/local/squid/etc/ssl_cert/myCA.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
sslcrtd_program /usr/local/squid/libexec/security_file_certgen -s
/var/lib/ssl_db -M 4MB
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all

#NO SSL Interception
acl DiscoverSNIHost at_step SslBump1
acl NoSSLIntercept ssl::server_name "/usr/local/squid/etc/pubkey.txt"
ssl_bump splice NoSSLIntercept
ssl_bump peek DiscoverSNIHost
ssl_bump bump all

thanks,
rob

-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210727/a61a7a19/attachment.htm>

From squid3 at treenet.co.nz  Tue Jul 27 12:57:26 2021
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Wed, 28 Jul 2021 00:57:26 +1200
Subject: [squid-users] where to put my own rules
In-Reply-To: <CAGU_CiLtabA1zLityndyzW-xGYi9+v=CaE7T6MBrF+rVFCDvkQ@mail.gmail.com>
References: <CAGU_CiLtabA1zLityndyzW-xGYi9+v=CaE7T6MBrF+rVFCDvkQ@mail.gmail.com>
Message-ID: <f8cf207b107460df474d05f126fa5f6b@treenet.co.nz>

On 2021-07-28 00:25, robert k Wild wrote:
> is it best to put my "ssl bump" and "no ssl interception" rules under
> 
> # Recommended minimum Access Permission configuration:
> 
> or
> 
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> 

Both of the above comments are about the ordering of http_access lines.
It is just a matter of convenience to put other directives custom config 
there as well.

The rules you are asking about do not (currently) matter where they go 
in regard to *placement*. What matters for them is their *order* is 
correct for what needs to be achieved.

Amos



From robertkwild at gmail.com  Tue Jul 27 13:46:18 2021
From: robertkwild at gmail.com (robert k Wild)
Date: Tue, 27 Jul 2021 14:46:18 +0100
Subject: [squid-users] where to put my own rules
In-Reply-To: <f8cf207b107460df474d05f126fa5f6b@treenet.co.nz>
References: <CAGU_CiLtabA1zLityndyzW-xGYi9+v=CaE7T6MBrF+rVFCDvkQ@mail.gmail.com>
 <f8cf207b107460df474d05f126fa5f6b@treenet.co.nz>
Message-ID: <CAGU_CiJqiU_WuiOPxRhu3sC25dyhP+7TKLDPBpAqp+OVTFKVuw@mail.gmail.com>

Thanks Amos

On Tue, 27 Jul 2021, 13:57 , <squid3 at treenet.co.nz> wrote:

> On 2021-07-28 00:25, robert k Wild wrote:
> > is it best to put my "ssl bump" and "no ssl interception" rules under
> >
> > # Recommended minimum Access Permission configuration:
> >
> > or
> >
> > # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> >
>
> Both of the above comments are about the ordering of http_access lines.
> It is just a matter of convenience to put other directives custom config
> there as well.
>
> The rules you are asking about do not (currently) matter where they go
> in regard to *placement*. What matters for them is their *order* is
> correct for what needs to be achieved.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20210727/19b4f6e0/attachment.htm>

From rentorbuy at yahoo.com  Tue Jul 27 15:45:52 2021
From: rentorbuy at yahoo.com (Vieri)
Date: Tue, 27 Jul 2021 15:45:52 +0000 (UTC)
Subject: [squid-users] SSL handshake
References: <765298140.229491.1627400752633.ref@mail.yahoo.com>
Message-ID: <765298140.229491.1627400752633@mail.yahoo.com>

Hi,

Just recently I've noticed that LAN clients going through Squid with sslbump are all of a sudden unable to access certain HTTPS sites such as login.yahoo.com.
The squid log has lines like:

kid1| 4,3| Error.cc(22) update: recent: ERR_SECURE_CONNECT_FAIL/SQUID_ERR_SSL_HANDSHAKE+TLS_LIB_ERR=1423506E+TLS_IO_ERR=1

and the client error page shows a line like this:

SQUID_TLS_ERR_CONNECT+TLS_LIB_ERR=14094410+TLS_IO_ERR=1

I'm not sure why the lib error code is different. I might not have tracked down the right connection in the log.

I have not changed anything in the OS so it might be because of change in the remote web service.
It might be that my openssl version is already too old (1.1.1g), and that the web site forces the use of an unsupported cypher?

Regards,

Vieri


From rousskov at measurement-factory.com  Tue Jul 27 17:29:58 2021
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 27 Jul 2021 13:29:58 -0400
Subject: [squid-users] SSL handshake
In-Reply-To: <765298140.229491.1627400752633@mail.yahoo.com>
References: <765298140.229491.1627400752633.ref@mail.yahoo.com>
 <765298140.229491.1627400752633@mail.yahoo.com>
Message-ID: <2e93eb79-038b-05c7-c33b-1abfc6ce164b@measurement-factory.com>

On 7/27/21 11:45 AM, Vieri wrote:

> Just recently I've noticed that LAN clients going through Squid with sslbump are all of a sudden unable to access certain HTTPS sites such as login.yahoo.com.
> The squid log has lines like:
> 
> kid1| 4,3| Error.cc(22) update: recent: ERR_SECURE_CONNECT_FAIL/SQUID_ERR_SSL_HANDSHAKE+TLS_LIB_ERR=1423506E+TLS_IO_ERR=1
> 
> and the client error page shows a line like this:
> 
> SQUID_TLS_ERR_CONNECT+TLS_LIB_ERR=14094410+TLS_IO_ERR=1
> 
> I'm not sure why the lib error code is different. I might not have tracked down the right connection in the log.
> 
> I have not changed anything in the OS so it might be because of change in the remote web service.
> It might be that my openssl version is already too old (1.1.1g), and that the web site forces the use of an unsupported cypher?


FWIW, I get the following additional info from my OpenSSL 1.1.1f (your
values may differ -- do check):

$ openssl errstr 1423506E
error:1423506E:SSL routines:ssl_next_proto_validate:bad extension

$ openssl errstr 14094410
error:14094410:SSL routines:ssl3_read_bytes:sslv3 alert handshake failure

The former looks like an NPN negotiation failure. More detailed analysis
is needed to confirm and get to the root cause. I doubt it is an OpenSSL
version issue though.


HTH,

Alex.


From codemarauder at gmail.com  Tue Jul 27 19:21:52 2021
From: codemarauder at gmail.com (Nishant Sharma)
Date: Wed, 28 Jul 2021 00:51:52 +0530
Subject: [squid-users] SSL handshake
In-Reply-To: <765298140.229491.1627400752633@mail.yahoo.com>
References: <765298140.229491.1627400752633.ref@mail.yahoo.com>
 <765298140.229491.1627400752633@mail.yahoo.com>
Message-ID: <8f090d6c-645a-f71f-3c2f-e72a1f33c3ed@gmail.com>

On 27/07/21 9:15 pm, Vieri wrote:
> 
> I have not changed anything in the OS so it might be because of change in the remote web service.
> It might be that my openssl version is already too old (1.1.1g), and that the web site forces the use of an unsupported cypher?

I have also observed it on 2 instances of the squid-4.6.2, starting
25/26th July. The configuration was working fine for more than 9 months now.

OpenSSL versions are 1.0.2q and 1.1.1h.

OS is OpenWrt based custom firmware (hopbox) on x86_64.

If the proxy is explicitly set on the client, SSL-Bump with peek &
splice works fine. If the traffic is intercepted, the HTTPS connection
takes a long to time to establish and times out in the browser. HTTP is
fine with interception.

There is no error in the logs.

I suspected browser updates might have caused this, but it didn't work
on Chrome and Firefox both.

Interception with peek & splice is working fine on squid-4.13 with
OpenSSL 1.1.1i.

Configuration snippet for squid-4.6.2 with openssl 1.0.2q:

=========
http_port 3128
http_port 3127 intercept
https_port 3129 intercept tcpkeepalive=60,30,3 ssl-bump
generate-host-certificates=on dynamic_cert_mem_cache_size=10MB
cert=/etc/squid/ssl_cert/MySSLCA.pem tls-dh=prime256v1:/etc/squid/ssl_
cert/dhparam.pem options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
sslcrtd_children 10
sslcrtd_program /usr/lib/squid/security_file_certgen -s /tmp/squid/ssldb
-M 16MB

acl NoSSLIntercept ssl::server_name "/etc/squid/acls/nobump.txt"
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump splice !NoSSLIntercept
ssl_bump splice all
===========


Configuration snippets for squid-4.6.2 with openssl 1.1.1h:

===========
http_port 3128
http_port 3127 intercept
https_port 3129 intercept tcpkeepalive=60,30,3 ssl-bump
generate-host-certificates=on dynamic_cert_mem_cache_size=10MB
cert=/etc/squid/ssl_cert/citykartSSLCA.pem
sslcrtd_children 15
sslcrtd_program /usr/lib/squid/security_file_certgen -s /tmp/squid/ssldb
-M 10MB

acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump splice all

host_verify_strict off
client_dst_passthru on
===========

Configuration snippet for squid-4.13 with OpenSSL 1.1.1i:

==============
http_port 3128
http_port 3127 intercept
https_port 3129 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=6MB tls-cert=/etc/squid/ssl_cert/MySSLCA.pem
tls-key=/etc/squid/ssl_cert/MySSLCA.pem
tls-dh=prime256v1:/etc/squid/ssl_cert/bump_dhparam.pem'
sslcrtd_children 10

acl intermediate_fetching transaction_initiator certificate-fetching
http_access allow intermediate_fetching

acl DiscoverSNIHost at_step SslBump1
#acl NoSSLIntercept ssl::server_name_regex "/etc/squid/acls/nobump.txt"
ssl_bump peek DiscoverSNIHost
#ssl_bump bump !NoSSLIntercept
ssl_bump splice all

=====================


iptables rules at all the routers:

# iptables-save | grep HTTP

-A zone_lan_prerouting -p tcp -m tcp --dport 80 -m set ! --match-set
direct dst -m comment --comment "!fw3: HTTP Intercept" -j DNAT
--to-destination 10.0.0.1:3127
-A zone_lan_prerouting -p tcp -m tcp --dport 443 -m set ! --match-set
direct dst -m comment --comment "!fw3: HTTPS Intercept" -j DNAT
--to-destination 10.0.0.1:3129

# iptables -nvL -t nat | grep HTTP

DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0
    tcp dpt:80 ! match-set direct dst /* !fw3: HTTP Intercept */
to:10.0.0.1:3127
DNAT       tcp  --  *      *       0.0.0.0/0            0.0.0.0/0
    tcp dpt:443 ! match-set direct dst /* !fw3: HTTPS Intercept */
to:10.0.0.1:3129

I still suspect something has changed either on the browsers / windows
OS or the servers, which has increased the negotiation time and requests
time out.

Any further guidance to debug the issue would be greatly helpful.

Regards,
Nishant


From rentorbuy at yahoo.com  Wed Jul 28 09:54:40 2021
From: rentorbuy at yahoo.com (Vieri)
Date: Wed, 28 Jul 2021 09:54:40 +0000 (UTC)
Subject: [squid-users] SSL handshake
In-Reply-To: <8f090d6c-645a-f71f-3c2f-e72a1f33c3ed@gmail.com>
References: <765298140.229491.1627400752633.ref@mail.yahoo.com>
 <765298140.229491.1627400752633@mail.yahoo.com>
 <8f090d6c-645a-f71f-3c2f-e72a1f33c3ed@gmail.com>
Message-ID: <1801674111.532776.1627466080421@mail.yahoo.com>

Hi,

I don't know if my situation is like Nishant's, but today my issues have gone away without intervention on my behalf.
I'm guessing the cause was on the remote server's side or some?in-between SSL inspection...

Thanks,

Vieri


