From psa at cdot.in  Mon Jan  3 06:45:38 2022
From: psa at cdot.in (Punyasloka Arya)
Date: Mon, 3 Jan 2022 12:15:38 +0530
Subject: [squid-users] Need Urgent Help the CPU load shows 99% for the squid
 process
Message-ID: <61D29B92.6030803@cdot.in>

Dear ALL,

*I need a quick help regarding the squid process occupying 100% CPU 
showing on the top and becomes slow.

*After starting the squid after 2 to 3 hours it is happening.
After stopping the squid process it becomes normal.


Squid installed version

[squid at wcb ~]$  /usr/squid/3.1/sbin/squid -version
Squid Cache: Version 3.3.3
configure options:  '--prefix=/usr/squid/3.1/' 
'--enable-storeio=ufs,aufs,diskd' '--enable-removal-policies=heap,lru' 
'--enable-delay-pools' '--enable-useragent-log' '--enable-referer-log' 
'--enable-icmp' '--enable-cachemgr-hostname=wc.cdotb.ernet.in' 
'--enable-follow-x-forwarded-for' '--disable-ident-lookups' 
'--enable-auth-basic=PAM,NCSA,LDAP' '--sysconfdir=/etc/squid/' 
'--with-default-user=squid' '--with-logdir=/var/log/squid' 
'--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=16384' 
'--with-swapdir=/cache/squid' '--enable-ltdl-convenience'

HARDWARE       : Fujitsu Celsius Xeon Workstation Intel(R) Xeon(R) CPU 
E5-2690 0 @ 2.90GHz 16CPU 8-Core
HARDDISK          : 500GB
RAM                   :24 GB
OS                       : CentOS 6.10(final)


The output of the command  after load is 99% in the CPU

[root at wcb squid]#  tail -n 100000 /var/log/squid/cache.log | grep -i 
descript

2022/01/02 11:49:32 kid1| WARNING! Your cache is running out of 
filedescriptors
2022/01/02 11:49:48 kid1| WARNING! Your cache is running out of 
filedescriptors
2022/01/02 11:50:04 kid1| WARNING! Your cache is running out of 
filedescriptors
2022/01/02 11:50:20 kid1| WARNING! Your cache is running out of 
filedescriptors

Please suggest anything else i should check or missing.

From
Punyasloka Arya

From
Punya
PUNYASLOKA ARYA            ?????????? ?????
Staffno:3880,Netops,TS(B)
Senior Research Engineer   ?????? ???????? ???????
C-DOT                      ??-???
Electronics City,Phase-1 ?????????????? ???? ???? I
Hosur Road,Bangalore       ????? ???, ????????
560100                     560100
### Please consider the environment and print this email only if necessary
.
Go Green ###

Disclaimer :
This email and any files transmitted with it are confidential and intended
solely for the use of the individual or entity to whom they are addressed.
If you are not the intended recipient you are notified that disclosing,
copying, distributing or taking any action in reliance on the contents of
this
information is strictly prohibited. The sender does not accept liability
for any errors or omissions in the contents of this message, which arise
as
a
result.








-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220103/e2b5b3ec/attachment.htm>

From rousskov at measurement-factory.com  Mon Jan  3 16:44:03 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 3 Jan 2022 11:44:03 -0500
Subject: [squid-users] Need Urgent Help the CPU load shows 99% for the
 squid process
In-Reply-To: <61D29B92.6030803@cdot.in>
References: <61D29B92.6030803@cdot.in>
Message-ID: <beb06c58-f3c0-31df-75cd-2fcd16bab107@measurement-factory.com>

On 1/3/22 1:45 AM, Punyasloka Arya wrote:

> I need a quick help regarding the squid process occupying 100% CPU
> showing on the top and becomes slow.
> 
> After starting the squid after 2 to 3 hours it is happening.
> After stopping the squid process it becomes normal.

Your Squid is overloaded (getting too much traffic), misconfigured
(e.g., forwarding loop or insufficient number of descriptors for the
given load), or hitting a bug. Lots of bugs have been fixed since Squid
v3.3 was released, including bugs that could lead to 100% CPU
utilization. Squid v3 has not been officially supported for years.

Your best long-term option is to upgrade, but that may take some
time/effort because your base version is so old.

If you want to troubleshoot this without going through the upgrade, try
figuring out which out of the three cases above you are dealing with.
Here are some hints:

* Grep cache.log for any assertions, errors, warnings, or repeated
messages (other than "running out of filedescriptors" which you already
shared).

* Check whether Squid receives the expected amount of traffic (you may
be able to do that by counting lines in access.log and/or watching
network interface stats).

* Check how many file descriptors Squid actually has. There should be a
message about that in the beginning of cache.log. For example:
2021/12/28 11:58:08| With 1024 file descriptors available

* Think of what has _changed_ in Squid environment since Squid was
running successfully (assuming it was).

* If Squid stops processing new requests, then check whether Squid is
stuck in a loop (using gdb or a similar tool).


HTH,

Alex.




> Squid installed version
> 
> [squid at wcb ~]$? /usr/squid/3.1/sbin/squid -version
> Squid Cache: Version 3.3.3
> configure options:? '--prefix=/usr/squid/3.1/'
> '--enable-storeio=ufs,aufs,diskd'?????????????????
> '--enable-removal-policies=heap,lru' '--enable-delay-pools'
> '--enable-useragent-log' '--enable-referer-log' '--enable-icmp'
> '--enable-cachemgr-hostname=wc.cdotb.ernet.in'
> '--enable-follow-x-forwarded-for' '--disable-ident-lookups'
> '--enable-auth-basic=PAM,NCSA,LDAP' '--sysconfdir=/etc/squid/'
> '--with-default-user=squid' '--with-logdir=/var/log/squid'
> '--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=16384'
> '--with-swapdir=/cache/squid' '--enable-ltdl-convenience'
> 
> HARDWARE?????? : Fujitsu Celsius Xeon Workstation Intel(R) Xeon(R) CPU
> E5-2690 0 @ 2.90GHz 16CPU 8-Core
> HARDDISK????????? : 500GB
> RAM?????????????????? :24 GB
> OS?????????????????????? : CentOS 6.10(final)
> 
> 
> The output of the command? after load is 99% in the CPU
> 
> [root at wcb squid]#? tail -n 100000 /var/log/squid/cache.log | grep -i
> descript
> 
> 2022/01/02 11:49:32 kid1| WARNING! Your cache is running out of
> filedescriptors
> 2022/01/02 11:49:48 kid1| WARNING! Your cache is running out of
> filedescriptors
> 2022/01/02 11:50:04 kid1| WARNING! Your cache is running out of
> filedescriptors
> 2022/01/02 11:50:20 kid1| WARNING! Your cache is running out of
> filedescriptors
> 
> Please suggest anything else i should check or missing.
> 
> From
> Punyasloka Arya
> 
> From
> Punya
> PUNYASLOKA ARYA ? ? ? ? ? ??????????? ?????
> Staffno:3880,Netops,TS(B)
> Senior Research Engineer ? ?????? ???????? ???????
> C-DOT ? ? ? ? ? ? ? ? ? ? ???-??? ? ? ? ? ? ? ? ? ? ?
> Electronics City,Phase-1 ? ?????????????? ???? ???? I ? ? ? ?
> Hosur Road,Bangalore ? ? ? ????? ???, ????????
> 560100 ? ? ? ? ? ? ? ? ? ? 560100
> ### Please consider the environment and print this email only if necessary
> .
> Go Green ###
> 
> Disclaimer :
> This email and any files transmitted with it are confidential and intended
> solely for the use of the individual or entity to whom they are addressed.
> If you are not the intended recipient you are notified that disclosing,
> copying, distributing or taking any action in reliance on the contents of
> this
> information is strictly prohibited. The sender does not accept liability
> for any errors or omissions in the contents of this message, which arise
> as
> a
> result.
> 
> 
> 
> 
> 
> 
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From will at brainmeltdown.net  Tue Jan  4 00:19:28 2022
From: will at brainmeltdown.net (Will BMD)
Date: Tue, 4 Jan 2022 00:19:28 +0000
Subject: [squid-users] MITM the MITM
Message-ID: <e2d9f88c-497f-6a6d-f682-bca17fb4830d@brainmeltdown.net>

Hey all,

I currently have the following network topology, it's emulating a real 
world environment. The proxy is running ssl_bump.

LAN <-> Squid Proxy <-> Firewall <-> Internet

 From the Firewalls perspective all client connections are originating 
as the proxy server. We're wanting to use the https inspect feature of 
the firewall, but according to our firewall documentation it appears due 
to the location of our proxy servers we would be unable to do so.

My question is, if the proxy is behaving as a MITM between itself and 
the client, can't the Firewall do the same thing between itself and the 
proxy? I suspect it is possible, but might potentially involve a lot of 
headaches and a big hit on performance?

Any insight into this would be greatly appreciated.

Thank you,

Will







From Antony.Stone at squid.open.source.it  Tue Jan  4 00:35:48 2022
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 4 Jan 2022 01:35:48 +0100
Subject: [squid-users] MITM the MITM
In-Reply-To: <e2d9f88c-497f-6a6d-f682-bca17fb4830d@brainmeltdown.net>
References: <e2d9f88c-497f-6a6d-f682-bca17fb4830d@brainmeltdown.net>
Message-ID: <202201040135.48476.Antony.Stone@squid.open.source.it>

On Tuesday 04 January 2022 at 01:19:28, Will BMD wrote:

> Hey all,
> 
> I currently have the following network topology, it's emulating a real
> world environment. The proxy is running ssl_bump.
> 
> LAN <-> Squid Proxy <-> Firewall <-> Internet
> 
> From the Firewall's perspective all client connections are originating
> as the proxy server.

Okay, that makes good sense.

> We're wanting to use the https inspect feature of the firewall,

Please give more details?

 - What sort of firewall is this?
 - What does "HTTPS inspect" actually mean?
 - How does the firewall "inspect" HTTPS traffic, which by design is encrypted 
between client and server (neither of which is the firewall)?
 - What does "inspect" mean?  What information is revealed from the inspection 
of the encrypted communication?

> but according to our firewall documentation it appears due to the location of
> our proxy servers we would be unable to do so.

Why?  Where would the proxy servers need to be instead, in order for this 
inspection to work?

Alternatively, how does/would it work if the proxy were not there, and clients 
communicated directly to the Internet through the firewall?

> My question is, if the proxy is behaving as a MITM between itself and
> the client, can't the Firewall do the same thing between itself and the
> proxy?

I agree.  Have you asked the suppliers / authors / vendors of the firewall?

> I suspect it is possible, but might potentially involve a lot of headaches
> and a big hit on performance?

Who knows?

If it's the firewall telling you there's a problem, this doesn't entirely feel 
like a Squid question.


Antony.

-- 
If you can smile when all about you things are going wrong, you must have 
someone in mind to take the blame.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From gtaylor at tnetconsulting.net  Tue Jan  4 04:19:13 2022
From: gtaylor at tnetconsulting.net (Grant Taylor)
Date: Mon, 3 Jan 2022 21:19:13 -0700
Subject: [squid-users] MITM the MITM
In-Reply-To: <e2d9f88c-497f-6a6d-f682-bca17fb4830d@brainmeltdown.net>
References: <e2d9f88c-497f-6a6d-f682-bca17fb4830d@brainmeltdown.net>
Message-ID: <dd1929c6-7f2a-ad41-6a62-6e97d4ed0e83@spamtrap.tnetconsulting.net>

On 1/3/22 5:19 PM, Will BMD wrote:
> Hey all,

Hi,

> From the Firewalls perspective all client connections are originating 
> as the proxy server. We're wanting to use the https inspect feature of 
> the firewall,

I'm taking "HTTPS inspect" to be the firewall's counterpart to ssl_bump.

> but according to our firewall documentation it appears due to the 
> location of our proxy servers we would be unable to do so.

Where does the firewall documentation / vendor want the proxy server to be?

> My question is, if the proxy is behaving as a MITM between itself and 
> the client, can't the Firewall do the same thing between itself and the 
> proxy?

I don't see why it can't.

> I suspect it is possible, but might potentially involve a lot of 
> headaches and a big hit on performance?

Do you are about original client IP addresses?  If not, then I think 
this should be as simple as one proxy (Squid) talking to another proxy 
(firewall).

> Any insight into this would be greatly appreciated.

I would wonder if WCCP /might/ be a viable option in this scenario or 
not.  As in configure clients to use the firewall as a proxy and have 
the firewall do it's thing while leveraging Squid's caching capability 
via WCCP.

There might also be the some room for having Squid view the firewall as 
a parent proxy.



-- 
Grant. . . .
unix || die

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4017 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220103/5a62973b/attachment.bin>

From will at brainmeltdown.net  Tue Jan  4 09:35:35 2022
From: will at brainmeltdown.net (Will BMD)
Date: Tue, 4 Jan 2022 09:35:35 +0000
Subject: [squid-users] MITM the MITM
In-Reply-To: <202201040135.48476.Antony.Stone@squid.open.source.it>
References: <e2d9f88c-497f-6a6d-f682-bca17fb4830d@brainmeltdown.net>
 <202201040135.48476.Antony.Stone@squid.open.source.it>
Message-ID: <1728a695-0a6a-02aa-d312-dd6c595a76c8@brainmeltdown.net>

Hey Antony,

Thanks for the quick response.

> - What sort of firewall is this?

The firewall is a Cisco FTDv 6.6.

>   - What does "HTTPS inspect" actually mean?
>   - How does the firewall "inspect" HTTPS traffic, which by design is encrypted
> between client and server (neither of which is the firewall)?
>   - What does "inspect" mean?  What information is revealed from the inspection
> of the encrypted communication?

It's doing something they call 'decrypt and resign'. Similar to how 
ssl_bump works, so would putting the firewall certificate on the Squid 
server's trusted certificates source be enough?

> Why?  Where would the proxy servers need to be instead, in order for this
> inspection to work?

Good question, their documentation says the following:

    HTTP proxy limitation

    The system cannot decrypt traffic if an HTTP proxy is positioned
    between a client and your managed device, and the client and server
    establish a tunneled TLS/SSL connection using the CONNECT HTTP
    method. The Handshake Errors undecryptable action determines how the
    system handles this traffic.

> Alternatively, how does/would it work if the proxy were not there, and clients
> communicated directly to the Internet through the firewall?

If the proxy wasn't there, it looks like it works the same as ssl_bump.

> Have you asked the suppliers / authors / vendors of the firewall?

Not yet but I will be doing so today.

> If it's the firewall telling you there's a problem, this doesn't entirely feel
> like a Squid question.

Okay, what if we removed the firewall and replaced it with another squid proxy server, where that is also doing ssl_bump. I assume this would work but are there negative implications of doing so?

Appreciate you taking the time.

Thanks,

Will

On 04/01/2022 00:35, Antony Stone wrote:
> On Tuesday 04 January 2022 at 01:19:28, Will BMD wrote:
>
>> Hey all,
>>
>> I currently have the following network topology, it's emulating a real
>> world environment. The proxy is running ssl_bump.
>>
>> LAN <-> Squid Proxy <-> Firewall <-> Internet
>>
>>  From the Firewall's perspective all client connections are originating
>> as the proxy server.
> Okay, that makes good sense.
>
>> We're wanting to use the https inspect feature of the firewall,
> Please give more details?
>
>   - What sort of firewall is this?
>   - What does "HTTPS inspect" actually mean?
>   - How does the firewall "inspect" HTTPS traffic, which by design is encrypted
> between client and server (neither of which is the firewall)?
>   - What does "inspect" mean?  What information is revealed from the inspection
> of the encrypted communication?
>
>> but according to our firewall documentation it appears due to the location of
>> our proxy servers we would be unable to do so.
> Why?  Where would the proxy servers need to be instead, in order for this
> inspection to work?
>
> Alternatively, how does/would it work if the proxy were not there, and clients
> communicated directly to the Internet through the firewall?
>
>> My question is, if the proxy is behaving as a MITM between itself and
>> the client, can't the Firewall do the same thing between itself and the
>> proxy?
> I agree.  Have you asked the suppliers / authors / vendors of the firewall?
>
>> I suspect it is possible, but might potentially involve a lot of headaches
>> and a big hit on performance?
> Who knows?
>
> If it's the firewall telling you there's a problem, this doesn't entirely feel
> like a Squid question.
>
>
> Antony.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220104/f7cca6b4/attachment.htm>

From edv at brand-erbisdorf.de  Tue Jan  4 16:41:04 2022
From: edv at brand-erbisdorf.de (Michael Engelmann)
Date: Tue, 4 Jan 2022 17:41:04 +0100
Subject: [squid-users] squid affected by log4j vulnerability?
Message-ID: <004b01d80189$dd3decc0$97b9c640$@brand-erbisdorf.de>

Hi all,

since I can't find any information on the web about whether the squid proxy
is affected by the log4j vulnerability, I want to ask that question here. We
are running Squid version 4.6 under Debian 4.19.

Thanks

Michael

Mit freundlichen Gr??en
Michael Engelmann

Stadtverwaltung Brand-Erbisdorf
Netzwerk-Administrator

Tel:  037322 32 109
Fax: 037322 32 341
E-Mail: edv at brand-erbisdorf.de

Informationen ?ber die Entgegennahme von elektronisch signierten und/oder
verschl?sselten Nachrichten sind unter www.Brand-Erbisdorf.de in der Rubrik
B?rgerservice -> Kommunikationskan?le zu finden






From will at brainmeltdown.net  Tue Jan  4 16:56:10 2022
From: will at brainmeltdown.net (Will BMD)
Date: Tue, 4 Jan 2022 16:56:10 +0000
Subject: [squid-users] MITM the MITM
In-Reply-To: <dd1929c6-7f2a-ad41-6a62-6e97d4ed0e83@spamtrap.tnetconsulting.net>
References: <e2d9f88c-497f-6a6d-f682-bca17fb4830d@brainmeltdown.net>
 <dd1929c6-7f2a-ad41-6a62-6e97d4ed0e83@spamtrap.tnetconsulting.net>
Message-ID: <25decadd-390b-003e-3b78-e50fb7759571@brainmeltdown.net>


On 04/01/2022 04:19, Grant Taylor wrote:
> On 1/3/22 5:19 PM, Will BMD wrote:
>> Hey all,
>
> Hi,
>
>> From the Firewalls perspective all client connections are originating 
>> as the proxy server. We're wanting to use the https inspect feature 
>> of the firewall,
>
> I'm taking "HTTPS inspect" to be the firewall's counterpart to ssl_bump.
That's correct.
>
>> but according to our firewall documentation it appears due to the 
>> location of our proxy servers we would be unable to do so.
>
> Where does the firewall documentation / vendor want the proxy server 
> to be?
That's a great question, I suspect that this might be an error in their 
documentation.
>
>> My question is, if the proxy is behaving as a MITM between itself and 
>> the client, can't the Firewall do the same thing between itself and 
>> the proxy?
>
> I don't see why it can't.
That's good to hear.
>
>> I suspect it is possible, but might potentially involve a lot of 
>> headaches and a big hit on performance?
>
> Do you are about original client IP addresses?? If not, then I think 
> this should be as simple as one proxy (Squid) talking to another proxy 
> (firewall).
Yea, that's that we're looking to obtain.
>
>> Any insight into this would be greatly appreciated.
>
> I would wonder if WCCP /might/ be a viable option in this scenario or 
> not.? As in configure clients to use the firewall as a proxy and have 
> the firewall do it's thing while leveraging Squid's caching capability 
> via WCCP.
>
> There might also be the some room for having Squid view the firewall 
> as a parent proxy.

I'm not aware of WCCP, but I'll look into it.

Thanks for info Grant.
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Tue Jan  4 17:59:36 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 5 Jan 2022 06:59:36 +1300
Subject: [squid-users] squid affected by log4j vulnerability?
In-Reply-To: <004b01d80189$dd3decc0$97b9c640$@brand-erbisdorf.de>
References: <004b01d80189$dd3decc0$97b9c640$@brand-erbisdorf.de>
Message-ID: <98dba977-5db7-1ac3-5d05-8b542cd8ac42@treenet.co.nz>

On 5/01/22 05:41, Michael Engelmann wrote:
> Hi all,
> 
> since I can't find any information on the web about whether the squid proxy
> is affected by the log4j vulnerability, I want to ask that question here. We
> are running Squid version 4.6 under Debian 4.19.
> 

Squid is not written in Java. So it is not vulnerable to Java API issue.

Amos


From edv at brand-erbisdorf.de  Wed Jan  5 09:33:48 2022
From: edv at brand-erbisdorf.de (Michael Engelmann)
Date: Wed, 5 Jan 2022 10:33:48 +0100
Subject: [squid-users] squid affected by log4j vulnerability?
In-Reply-To: <98dba977-5db7-1ac3-5d05-8b542cd8ac42@treenet.co.nz>
References: <004b01d80189$dd3decc0$97b9c640$@brand-erbisdorf.de>
 <98dba977-5db7-1ac3-5d05-8b542cd8ac42@treenet.co.nz>
Message-ID: <000b01d80217$579007f0$06b017d0$@brand-erbisdorf.de>

Hello Amos,

Thank you for your prompt reply.


Mit freundlichen Gr??en
Michael Engelmann

Stadtverwaltung Brand-Erbisdorf
Netzwerk-Administrator

Tel:  037322 32 109
Fax: 037322 32 341
E-Mail: edv at brand-erbisdorf.de

Informationen ?ber die Entgegennahme von elektronisch signierten und/oder
verschl?sselten Nachrichten sind unter www.Brand-Erbisdorf.de in der Rubrik
B?rgerservice -> Kommunikationskan?le zu finden

-----Urspr?ngliche Nachricht-----
Von: squid-users <squid-users-bounces at lists.squid-cache.org> Im Auftrag von
squid3 at treenet.co.nz (Amos Jeffries)
Gesendet: Dienstag, 4. Januar 2022 19:00
An: squid-users at lists.squid-cache.org
Betreff: Re: [squid-users] squid affected by log4j vulnerability?

On 5/01/22 05:41, Michael Engelmann wrote:
> Hi all,
> 
> since I can't find any information on the web about whether the squid
proxy
> is affected by the log4j vulnerability, I want to ask that question here.
We
> are running Squid version 4.6 under Debian 4.19.
> 

Squid is not written in Java. So it is not vulnerable to Java API issue.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users





From pponakanti at roblox.com  Thu Jan  6 07:50:10 2022
From: pponakanti at roblox.com (Praveen Ponakanti)
Date: Wed, 5 Jan 2022 23:50:10 -0800
Subject: [squid-users] Significant memory leak with version 5.x (not
 with 4.17)
In-Reply-To: <CACabJxNvqBr1=UswwszfDvBjjrFHTDi87bFDuzTtJ8Tc4OM2RQ@mail.gmail.com>
References: <CACabJxOfSqVkN63DN=N=_J=B7CtH-ahRkFaAtM93H67BpQx9eA@mail.gmail.com>
 <f68674bd-1203-062d-9786-7513554fafb4@measurement-factory.com>
 <CACabJxOTJaKcavxx8AwNoETA6OjsLw0OsdLO=d2M05DpHBstGQ@mail.gmail.com>
 <88e5e3e2-5641-883b-fd8c-cf4c3796ea4a@measurement-factory.com>
 <CACabJxN4Vn5HGnoh4b5wVJQm2wRGeBXSH0gcxPwY37cv1wJPmA@mail.gmail.com>
 <80242ed5-4e35-b2e3-80cb-82b78f4303e1@kjj.cz>
 <CACabJxMO-V86qzg9jk0wV=V=Q+j4Gq+4OehxkZkWV284+XaJkg@mail.gmail.com>
 <c06023d4-c97c-7ae5-037f-f20249f87ca3@treenet.co.nz>
 <cc63af40-3aa5-15ef-30ac-2f929b6def8f@kjj.cz>
 <4a1ae799-2d3b-37c8-8d24-d98f95a424fa@kjj.cz>
 <CACabJxNvqBr1=UswwszfDvBjjrFHTDi87bFDuzTtJ8Tc4OM2RQ@mail.gmail.com>
Message-ID: <CACabJxMfkCXtRu=mot_48i148AR29XL0oP8s+5fZdpzo49pnjQ@mail.gmail.com>

Hi Alex/Amos,

Do you still need memory logs from version 5.3 after stopping traffic
through the squid? We have disabled traffic to the 5.3 version squid about
6 hours ago and have not seen any memory being freed up since. This node
has used up ~50G more memory compared with 4.17 squid taking similar
traffic over the last 3+ weeks. I am collecting hourly memory logs on 5.3
after stopping traffic. Let me know and I can attach the
log tomorrow morning.

Thanks
Praveen

On Mon, Dec 27, 2021 at 4:58 PM Praveen Ponakanti <pponakanti at roblox.com>
wrote:

> I cant make any changes to our prod squids this week. I have a squid
> instance (5.3v) in a test env but could not reproduce the leak by starting
> & stopping traffic with a bulk http req generator (wrk). Was able to send
> 175k rps @ 20k concurrent sessions (each doing a get on a 1KB object)
> through the 30-worker squid. This initially caused a 3G increase in memory
> usage and then flattened out after stopping the requests. If I restart the
> bulk reqs, the memory usage only goes up ~0.5GB and then drops back down.
> Live traffic is probably exercising a different code path within squid's
> memory pools.
>
> On Mon, Dec 27, 2021 at 2:26 AM Luk?? Lou?ansk? <loucansky.lukas at kjj.cz>
> wrote:
>
>> After one day of running without clients my squid memory is stable
>>
>> 29345 proxy     20   0  171348 122360  14732 S   0.0   0.7   0:25.96
>> (squid-1) --kid squid-1 -YC -f /etc/squid5/squid.conf
>> 29343 root      20   0  133712  79264   9284 S   0.0   0.5   0:00.00
>> /usr/sbin/squid -YC -f /etc/squid5/squid.conf
>>
>> Storage Mem size:	3944 KB
>> Storage Mem capacity:	 0.2% used, 99.8% free
>> 	
>> Maximum Resident Size: 489440 KB
>> Page faults with physical i/o: 0
>> Memory accounted for:
>> Total accounted:        15741 KB
>> memPoolAlloc calls:   1061495
>> memPoolFree calls:    1071691
>>
>> Total allocated 15741	kB
>>
>> So this does not seem to be the problem...
>> L
>>
>> Dne 26.12.2021 v 10:02 Luk?? Lou?ansk? napsal(a):
>>
>> ok - as it seems my squid quacked on low memory again today -
>>
>> Dec 26 00:04:25 gw (squid-1): FATAL: Too many queued store_id requests;
>> see on-persistent-overload.#012    current master transaction:
>> master4629331
>> Dec 26 00:04:28 gw squid[15485]: Squid Parent: squid-1 process 15487
>> exited with status 1
>> Dec 26 00:04:28 gw squid[15485]: Squid Parent: (squid-1) process 28375
>> started
>>
>> 2021/12/26 00:01:20 kid1| helperOpenServers: Starting 5/64
>> 'storeid_file_rewrite' processes
>> 2021/12/26 00:01:20 kid1| ipcCreate: fork: (12) Cannot allocate memory
>> 2021/12/26 00:01:20 kid1| WARNING: Cannot run
>> '/lib/squid5/storeid_file_rewrite' process.
>> 2021/12/26 00:01:20 kid1| ipcCreate: fork: (12) Cannot allocate memory
>>
>> I'm going to reroute my clients (which are on their days off anyway) to
>> direct connections and run it "dry" - on it's own. But I'm not able to to
>> test it before "lack of memory issues occur" - because my clients are
>> offline. So I'll watch squid for it's own memory consuption. It's all I can
>> do right now - my squid already restarted and it's memory has been freed -
>> so I think just now I have no power to fill it up again :-]
>>
>> L
>>
>> Dne 26.12.2021 v 7:41 Amos Jeffries napsal(a):
>>
>>
>> If possible can one of you run a Squid to get this behaviour, then stop
>> new clients connecting to it before lack of memory issues occur and see if
>> the memory usage disappears or reduces after a 24-48hr wait.
>>
>> A series of regular mempools report dumps from across the test may help
>> Alex or whoever works on the bug eliminate further which cache and client
>> related things are releasing properly.
>>
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>>
>> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient> Bez
>> vir?. www.avast.com
>> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient>
>> <#m_-6622557068709516458_m_9217020348889694418_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220105/aa5adf1b/attachment.htm>

From m_zouhairy at ckta.by  Thu Jan  6 11:53:53 2022
From: m_zouhairy at ckta.by (Majed Zouhairy)
Date: Thu, 6 Jan 2022 14:53:53 +0300
Subject: [squid-users] squid 5.3 frequent crash
Message-ID: <6742bd06-14b6-c43a-71ff-3bd3ebb5fe44@ckta.by>

peace i have squid with ufdb guard, after upgrading today to 5.3 i'm 
getting:

....

2022/01/06 14:47:35| Processing: acl localhet src 169.254.0.0/16 	# RFC 
3927 link-local (directly plugged) machines
2022/01/06 14:47:35| Processing: acl SSL_ports port 443
2022/01/06 14:47:35| Processing: acl Safe_ports port 80		# http
2022/01/06 14:47:35| Processing: acl Safe_ports port 8080	# http
2022/01/06 14:47:35| Processing: acl Safe_ports port 21		# ftp
2022/01/06 14:47:35| Processing: acl Safe_ports port 443		# https
2022/01/06 14:47:35| Processing: acl Safe_ports port 70		# gopher
2022/01/06 14:47:35| Processing: acl Safe_ports port 210		# wais
2022/01/06 14:47:35| Processing: acl Safe_ports port 1025-65535	# 
unregistered ports
2022/01/06 14:47:35| Processing: acl Safe_ports port 280		# http-mgmt
2022/01/06 14:47:35| Processing: acl Safe_ports port 488		# gss-http
2022/01/06 14:47:35| Processing: acl Safe_ports port 591		# filemaker
2022/01/06 14:47:35| Processing: acl Safe_ports port 777		# multiling http
2022/01/06 14:47:35| Processing: acl CONNECT method CONNECT
2022/01/06 14:47:35| Processing: acl blockfiles urlpath_regex -i 
"/etc/squid/blocks.files.acl"
2022/01/06 14:47:35| Processing: http_access deny !Safe_ports
2022/01/06 14:47:35| Processing: http_access deny CONNECT !SSL_ports
2022/01/06 14:47:35| Processing: http_access allow localhost manager
2022/01/06 14:47:35| Processing: http_access deny manager
2022/01/06 14:47:35| Processing: visible_hostname proxy.skko.by
2022/01/06 14:47:35| Processing: forwarded_for delete
2022/01/06 14:47:35| Processing: delay_pools 1
2022/01/06 14:47:35| Processing: delay_class 1 3
2022/01/06 14:47:35| Processing: delay_access 1 allow slower
2022/01/06 14:47:35| Processing: delay_access 1 deny all
2022/01/06 14:47:35| Processing: delay_parameters 1 128000/128000 -1/-1 
128000/64000
2022/01/06 14:47:35| Processing: http_access allow localnet
2022/01/06 14:47:35| Processing: http_access allow localhost
2022/01/06 14:47:35| Processing: http_access deny all
2022/01/06 14:47:35| Processing: http_port 8080 ssl-bump 
cert=/etc/squid/certs/myCA.pem generate-host-certificates=on 
dynamic_cert_mem_cache_size=8MB
2022/01/06 14:47:35| Processing: acl 	tls_s1_connect			at_step SslBump1
2022/01/06 14:47:35| Processing: acl 	tls_s2_client_hello 	at_step SslBump2
2022/01/06 14:47:35| Processing: acl 	tls_s3_server_hello 	at_step SslBump3
2022/01/06 14:47:35| Processing: acl 	tls_allowed_hsts		ssl::server_name 
			.akamaihd.net
2022/01/06 14:47:35| Processing: acl 	tls_allowed_hsts		ssl::server_name 
			.proxy.skko.by
2022/01/06 14:47:35| Processing: acl 	tls_server_is_bank 	 
ssl::server_name		 
"/usr/local/ufdbguard/blacklists/finance/domains.squidsplice"
2022/01/06 14:47:35| Processing: acl 	tls_to_splice 			any-of 					 
tls_allowed_hsts		tls_server_is_bank
2022/01/06 14:47:35| Processing: ssl_bump 		peek				tls_s1_connect 		# 
peek at TLS/SSL connect data
2022/01/06 14:47:35| Processing: ssl_bump 		splice 				tls_to_splice		# 
splice some: no active bump
2022/01/06 14:47:35| Processing: ssl_bump 		stare 				all					# 
stare(peek) at server
2022/01/06 14:47:35| Processing: ssl_bump 		bump									# bump if we 
can (if the stare succeeded)
2022/01/06 14:47:35| Processing: cache_dir ufs /var/cache/squid 3000 16 256
2022/01/06 14:47:35| Processing: coredump_dir /var/cache/squid
2022/01/06 14:47:35| Processing: cache_mem 960 MB
2022/01/06 14:47:35| Processing: netdb_filename none
2022/01/06 14:47:35| Processing: refresh_pattern ^ftp:				1440	20%	10080
2022/01/06 14:47:35| Processing: refresh_pattern ^gopher:			1440	0%	1440
2022/01/06 14:47:35| Processing: refresh_pattern -i (/cgi-bin/|\?) 	0		0%	0
2022/01/06 14:47:35| Processing: refresh_pattern .					0		20%	4320
2022/01/06 14:47:35| Processing: url_rewrite_extras "%>a/%>A %un %>rm 
bump_mode=%ssl::bump_mode sni=\"%ssl::>sni\" referer=\"%{Referer}>h\""
2022/01/06 14:47:35| Processing: url_rewrite_program 
/usr/local/ufdbguard/bin/ufdbgclient -m 4 -l /var/log/squid/
2022/01/06 14:47:35| Processing: url_rewrite_children 16 startup=8 
idle=2 concurrency=4 queue-size=64
2022/01/06 14:47:35| Initializing https:// proxy context
2022/01/06 14:47:35| Requiring client certificates.
2022/01/06 14:47:36| Initializing http_port [::]:8080 TLS contexts
2022/01/06 14:47:36| Using certificate in /etc/squid/certs/myCA.pem
2022/01/06 14:47:36| Using certificate chain in /etc/squid/certs/myCA.pem
2022/01/06 14:47:36| Adding issuer CA: 
/C=BY/ST=Minsk/L=Minsk/O=RUP/OU=COD/CN=proxy.skko.by/emailAddress=v_sedina at skno.by
2022/01/06 14:47:36| Using key in /etc/squid/certs/myCA.pem
2022/01/06 14:47:36| Not requiring any client certificates


in cache.log:

2022/01/06 14:27:14 kid1| ERROR: failure while accepting a TLS 
connection on conn907 local=10.10.10.10:8080 remote=10.14.10.15:54125 FD 
197 flags=1: 0x55e7126a28c0*1
     current master transaction: master95
2022/01/06 14:27:16| Pinger exiting.
2022/01/06 14:27:18 kid1| FATAL: check failed: opening()
     exception location: FwdState.cc(628) noteDestinationsEnd
     current master transaction: master95
2022/01/06 14:27:18 kid1| Closing Pinger socket on FD 46
     current master transaction: master95
2022/01/06 14:27:18| Removing PID file (/run/squid.pid)

systemctl status squid
? squid.service - Squid caching proxy
      Loaded: loaded (/usr/lib/systemd/system/squid.service; enabled; 
vendor preset: disabled)
      Active: failed (Result: exit-code) since Thu 2022-01-06 14:27:18 
+03; 23min ago
        Docs: man:squid(8)
     Process: 12653 
ExecStartPre=/usr/libexec/squid/initialize_cache_if_needed.sh 
(code=exited, status=0/SUCCESS)
     Process: 12657 ExecStart=/usr/sbin/squid -FC (code=exited, 
status=0/SUCCESS)
    Main PID: 12658 (code=exited, status=1/FAILURE)
         CPU: 3min 22.025s

Jan 06 14:27:07 proxy squid[12658]: Squid Parent: squid-1 process 13723 
exited with status 1
Jan 06 14:27:07 proxy squid[12658]: Squid Parent: (squid-1) process 
13773 started
Jan 06 14:27:09 proxy squid[12658]: Squid Parent: squid-1 process 13773 
exited with status 1
Jan 06 14:27:09 proxy squid[12658]: Squid Parent: (squid-1) process 
13823 started
Jan 06 14:27:18 proxy squid[12658]: Squid Parent: squid-1 process 13823 
exited with status 1
Jan 06 14:27:18 proxy squid[12658]: Squid Parent: squid-1 process 13823 
will not be restarted for 3600 seconds due to repeated, frequent failures
Jan 06 14:27:18 proxy squid[12658]: Exiting due to repeated, frequent 
failures
Jan 06 14:27:18 proxy systemd[1]: squid.service: Main process exited, 
code=exited, status=1/FAILURE
Jan 06 14:27:18 proxy systemd[1]: squid.service: Failed with result 
'exit-code'.
Jan 06 14:27:18 proxy systemd[1]: squid.service: Consumed 3min 22.025s 
CPU time.

what is the cause knowing that i changed /var/cache/squid/ssl_db from 
root:root to squid:squid
and /var/cache/squid from root:squid to squid:squid

sudo sysctl -a | grep net.ipv6.conf.all.disable_ipv6
net.ipv6.conf.all.disable_ipv6 = 1


what is the cause?


From rousskov at measurement-factory.com  Thu Jan  6 17:00:14 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 6 Jan 2022 12:00:14 -0500
Subject: [squid-users] squid 5.3 frequent crash
In-Reply-To: <6742bd06-14b6-c43a-71ff-3bd3ebb5fe44@ckta.by>
References: <6742bd06-14b6-c43a-71ff-3bd3ebb5fe44@ckta.by>
Message-ID: <09f185c0-533a-cafe-4e80-57a644449888@measurement-factory.com>

On 1/6/22 6:53 AM, Majed Zouhairy wrote:
> peace i have squid with ufdb guard, after upgrading today to 5.3 i'm
> getting:

> 2022/01/06 14:27:18 kid1| FATAL: check failed: opening()
>     exception location: FwdState.cc(628) noteDestinationsEnd

> what is the cause?

This is most likely bug 5055 fixed in August 2021:
https://bugs.squid-cache.org/show_bug.cgi?id=5055

In many environments, Squid v5 is unusable without that bug fix. I do
not know whether the v5 maintainer plans to officially backport the fix
from master/v6 to v5, but we would be happy to assist with that. FWIW,
Factory has an _unofficial_ backport to v5-based code at:
https://github.com/measurement-factory/squid/commit/22b5f78


HTH,

Alex.


From gtaylor at tnetconsulting.net  Thu Jan  6 17:26:14 2022
From: gtaylor at tnetconsulting.net (Grant Taylor)
Date: Thu, 6 Jan 2022 10:26:14 -0700
Subject: [squid-users] MITM the MITM
In-Reply-To: <25decadd-390b-003e-3b78-e50fb7759571@brainmeltdown.net>
References: <e2d9f88c-497f-6a6d-f682-bca17fb4830d@brainmeltdown.net>
 <dd1929c6-7f2a-ad41-6a62-6e97d4ed0e83@spamtrap.tnetconsulting.net>
 <25decadd-390b-003e-3b78-e50fb7759571@brainmeltdown.net>
Message-ID: <1165ceb8-7b8e-cb0c-1487-f38ff327e207@spamtrap.tnetconsulting.net>

On 1/4/22 9:56 AM, Will BMD wrote:
> I'm not aware of WCCP, but I'll look into it.

In short, the Web Cache Communications Protocol, "... specifies 
interactions between one or more routers (or Layer 3 switches) and one 
or more web-caches ...".

Link - Web Cache Communications Protocol (WCCP)
  - 
https://www.cisco.com/c/en/us/tech/content-networking/web-cache-communications-protocol-wccp/index.html

WCCP can be pressed into service between an in-path device (usually L3) 
and a cache.  As such, I would hope ~> expect that the pseudo L3 
firewall can do it's work while using WCCP to allow a backend proxy do 
the actual caching, et la.

> Thanks for info Grant.

You're welcome.

Sorry for the delayed response.  It's been a busy week.



-- 
Grant. . . .
unix || die

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4017 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220106/a3eca0b4/attachment.bin>

From gtaylor at tnetconsulting.net  Thu Jan  6 17:33:17 2022
From: gtaylor at tnetconsulting.net (Grant Taylor)
Date: Thu, 6 Jan 2022 10:33:17 -0700
Subject: [squid-users] MITM the MITM
In-Reply-To: <1728a695-0a6a-02aa-d312-dd6c595a76c8@brainmeltdown.net>
References: <e2d9f88c-497f-6a6d-f682-bca17fb4830d@brainmeltdown.net>
 <202201040135.48476.Antony.Stone@squid.open.source.it>
 <1728a695-0a6a-02aa-d312-dd6c595a76c8@brainmeltdown.net>
Message-ID: <730f0320-8ec5-db56-13a2-35ebd405f09b@spamtrap.tnetconsulting.net>

On 1/4/22 2:35 AM, Will BMD wrote:
> HTTP proxy limitation
> 
> The system cannot decrypt traffic if an HTTP proxy is positioned 
> between a client and your managed device, and the client and server 
> establish a tunneled TLS/SSL connection using the CONNECT HTTP 
> method. The Handshake Errors undecryptable action determines how the 
> system handles this traffic.

I ... don't know what to make of this.  I would have some questions for 
the vendor (Cisco).

This sort of hints at a technical limitation that the Cisco FTDv /might/ 
have.  It sounds to me like the firewall might be able to pretend to be 
a web server via interception of some sort, but that it can't handle 
HTTP's CONNECT verb which is common to sue on proxies particularly for 
HTTPS connections.

I'm fairly certain that Squid /does/ support bumping such CONNECT requests.

This also hints at /needing/ ~> /requiring/ the downstream client 
devices to /not/ be configured to use the firewall as a proxy.  Because 
if the clients are configured to use the firewall as a proxy, they will 
inherently issue CONNECT requests.

More questions.  This itches like a limitation.

It also /really/ seems to me like Squid /should/ be able to work behind 
this as long as it has the proper public root certificate that is used 
to support the (re)signing.

> Okay, what if we removed the firewall and replaced it with another 
> squid proxy server, where that is also doing ssl_bump. I assume this 
> would work but are there negative implications of doing so?

I would /expect/ that two Squid servers could work in this type of 
configuration.  It's my understanding that Squid has support for parent 
/ child proxy hierarchies that would apply to this.  Even if it did not, 
I think that two simple ssl_bump Squid servers /should/ work with each 
other.  Proper certificate trust configuration not withstanding.



-- 
Grant. . . .
unix || die

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4017 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220106/3bdf1d6b/attachment.bin>

From rousskov at measurement-factory.com  Fri Jan  7 04:16:04 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 6 Jan 2022 23:16:04 -0500
Subject: [squid-users] Significant memory leak with version 5.x (not
 with 4.17)
In-Reply-To: <CACabJxMfkCXtRu=mot_48i148AR29XL0oP8s+5fZdpzo49pnjQ@mail.gmail.com>
References: <CACabJxOfSqVkN63DN=N=_J=B7CtH-ahRkFaAtM93H67BpQx9eA@mail.gmail.com>
 <f68674bd-1203-062d-9786-7513554fafb4@measurement-factory.com>
 <CACabJxOTJaKcavxx8AwNoETA6OjsLw0OsdLO=d2M05DpHBstGQ@mail.gmail.com>
 <88e5e3e2-5641-883b-fd8c-cf4c3796ea4a@measurement-factory.com>
 <CACabJxN4Vn5HGnoh4b5wVJQm2wRGeBXSH0gcxPwY37cv1wJPmA@mail.gmail.com>
 <80242ed5-4e35-b2e3-80cb-82b78f4303e1@kjj.cz>
 <CACabJxMO-V86qzg9jk0wV=V=Q+j4Gq+4OehxkZkWV284+XaJkg@mail.gmail.com>
 <c06023d4-c97c-7ae5-037f-f20249f87ca3@treenet.co.nz>
 <cc63af40-3aa5-15ef-30ac-2f929b6def8f@kjj.cz>
 <4a1ae799-2d3b-37c8-8d24-d98f95a424fa@kjj.cz>
 <CACabJxNvqBr1=UswwszfDvBjjrFHTDi87bFDuzTtJ8Tc4OM2RQ@mail.gmail.com>
 <CACabJxMfkCXtRu=mot_48i148AR29XL0oP8s+5fZdpzo49pnjQ@mail.gmail.com>
Message-ID: <877c1e3f-bd4f-2db2-bb03-49b37d1f0f6b@measurement-factory.com>

On 1/6/22 2:50 AM, Praveen Ponakanti wrote:
> Hi Alex/Amos,
> 
> Do you still need memory logs from version 5.3 after stopping traffic
> through the squid?

I cannot answer for Amos who asked for those logs, but you may want to
try a fix posted at
https://bugs.squid-cache.org/show_bug.cgi?id=5132#c27


HTH,

Alex.


> We have disabled traffic to the 5.3 version squid
> about 6 hours ago and have not seen any memory being freed up since.
> This node has used up ~50G more memory compared with 4.17 squid taking
> similar traffic over the last 3+ weeks. I am collecting hourly memory
> logs on 5.3 after stopping traffic. Let me know and I can attach the
> log?tomorrow?morning.
> 
> Thanks
> Praveen
> 
> On Mon, Dec 27, 2021 at 4:58 PM Praveen Ponakanti <pponakanti at roblox.com
> <mailto:pponakanti at roblox.com>> wrote:
> 
>     I cant?make any changes to our prod squids this week. I have a squid
>     instance (5.3v) in a test env but could not reproduce the leak by
>     starting & stopping traffic with a bulk http req generator (wrk).
>     Was able to send 175k rps @ 20k concurrent sessions (each doing a
>     get on a 1KB object) through?the 30-worker squid. This initially
>     caused a 3G increase in memory usage and then flattened out after
>     stopping the requests. If I restart the bulk reqs, the memory usage
>     only goes up ~0.5GB and then drops back down. Live traffic is
>     probably exercising a different code path within squid's memory pools.
> 
>     On Mon, Dec 27, 2021 at 2:26 AM Luk?? Lou?ansk?
>     <loucansky.lukas at kjj.cz <mailto:loucansky.lukas at kjj.cz>> wrote:
> 
>         After one day of running without clients my squid memory is stable
> 
>         29345 proxy???? 20?? 0? 171348 122360? 14732 S?? 0.0?? 0.7??
>         0:25.96 (squid-1) --kid squid-1 -YC -f /etc/squid5/squid.conf
>         29343 root????? 20?? 0? 133712? 79264?? 9284 S?? 0.0?? 0.5??
>         0:00.00 /usr/sbin/squid -YC -f /etc/squid5/squid.conf
> 
>         Storage Mem size: 3944 KB Storage Mem capacity: 0.2% used, 99.8%
>         free Maximum Resident Size: 489440 KB Page faults with physical
>         i/o: 0 Memory accounted for: Total accounted: 15741 KB
>         memPoolAlloc calls: 1061495 memPoolFree calls: 1071691 Total
>         allocated 15741 kB So this does not seem to be the problem... L
> 
>         Dne 26.12.2021 v 10:02 Luk?? Lou?ansk? napsal(a):
>>         ok - as it seems my squid quacked on low memory again today -
>>
>>         Dec 26 00:04:25 gw (squid-1): FATAL: Too many queued store_id
>>         requests; see on-persistent-overload.#012??? current master
>>         transaction: master4629331
>>         Dec 26 00:04:28 gw squid[15485]: Squid Parent: squid-1 process
>>         15487 exited with status 1
>>         Dec 26 00:04:28 gw squid[15485]: Squid Parent: (squid-1)
>>         process 28375 started
>>
>>         2021/12/26 00:01:20 kid1| helperOpenServers: Starting 5/64
>>         'storeid_file_rewrite' processes
>>         2021/12/26 00:01:20 kid1| ipcCreate: fork: (12) Cannot
>>         allocate memory
>>         2021/12/26 00:01:20 kid1| WARNING: Cannot run
>>         '/lib/squid5/storeid_file_rewrite' process.
>>         2021/12/26 00:01:20 kid1| ipcCreate: fork: (12) Cannot
>>         allocate memory
>>
>>         I'm going to reroute my clients (which are on their days off
>>         anyway) to direct connections and run it "dry" - on it's own.
>>         But I'm not able to to test it before "lack of memory issues
>>         occur" - because my clients are offline. So I'll watch squid
>>         for it's own memory consuption. It's all I can do right now -
>>         my squid already restarted and it's memory has been freed - so
>>         I think just now I have no power to fill it up again :-]
>>
>>         L
>>
>>         Dne 26.12.2021 v 7:41 Amos Jeffries napsal(a):
>>>
>>>         If possible can one of you run a Squid to get this behaviour,
>>>         then stop new clients connecting to it before lack of memory
>>>         issues occur and see if the memory usage disappears or
>>>         reduces after a 24-48hr wait.
>>>
>>>         A series of regular mempools report dumps from across the
>>>         test may help Alex or whoever works on the bug eliminate
>>>         further which cache and client related things are releasing
>>>         properly.
>>>
>>>
>>>         Amos
>>>
>>>         _______________________________________________
>>>         squid-users mailing list
>>>         squid-users at lists.squid-cache.org
>>>         <mailto:squid-users at lists.squid-cache.org>
>>>         http://lists.squid-cache.org/listinfo/squid-users
>>>         <http://lists.squid-cache.org/listinfo/squid-users>
>>
> 
>         <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient>
>         	Bez vir?. www.avast.com
>         <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient>
> 
> 
>         <#m_-6622557068709516458_m_9217020348889694418_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>         _______________________________________________
>         squid-users mailing list
>         squid-users at lists.squid-cache.org
>         <mailto:squid-users at lists.squid-cache.org>
>         http://lists.squid-cache.org/listinfo/squid-users
>         <http://lists.squid-cache.org/listinfo/squid-users>
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From pponakanti at roblox.com  Fri Jan  7 05:12:43 2022
From: pponakanti at roblox.com (Praveen Ponakanti)
Date: Thu, 6 Jan 2022 21:12:43 -0800
Subject: [squid-users] Significant memory leak with version 5.x (not
 with 4.17)
In-Reply-To: <877c1e3f-bd4f-2db2-bb03-49b37d1f0f6b@measurement-factory.com>
References: <CACabJxOfSqVkN63DN=N=_J=B7CtH-ahRkFaAtM93H67BpQx9eA@mail.gmail.com>
 <f68674bd-1203-062d-9786-7513554fafb4@measurement-factory.com>
 <CACabJxOTJaKcavxx8AwNoETA6OjsLw0OsdLO=d2M05DpHBstGQ@mail.gmail.com>
 <88e5e3e2-5641-883b-fd8c-cf4c3796ea4a@measurement-factory.com>
 <CACabJxN4Vn5HGnoh4b5wVJQm2wRGeBXSH0gcxPwY37cv1wJPmA@mail.gmail.com>
 <80242ed5-4e35-b2e3-80cb-82b78f4303e1@kjj.cz>
 <CACabJxMO-V86qzg9jk0wV=V=Q+j4Gq+4OehxkZkWV284+XaJkg@mail.gmail.com>
 <c06023d4-c97c-7ae5-037f-f20249f87ca3@treenet.co.nz>
 <cc63af40-3aa5-15ef-30ac-2f929b6def8f@kjj.cz>
 <4a1ae799-2d3b-37c8-8d24-d98f95a424fa@kjj.cz>
 <CACabJxNvqBr1=UswwszfDvBjjrFHTDi87bFDuzTtJ8Tc4OM2RQ@mail.gmail.com>
 <CACabJxMfkCXtRu=mot_48i148AR29XL0oP8s+5fZdpzo49pnjQ@mail.gmail.com>
 <877c1e3f-bd4f-2db2-bb03-49b37d1f0f6b@measurement-factory.com>
Message-ID: <CACabJxODMUgsN7SA0Y3p-RBrbMaD3uRoHfDJ5Y004WE4PyZOaw@mail.gmail.com>

Hi Alex,

We are fine with version 4.17 as of now. I can try out the fix sometime
next week if you need further data. Is there a build with the fix, or do
you have some recommended steps to manually pull the source, patch the fix
and then recompile?


On Thu, Jan 6, 2022 at 8:16 PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 1/6/22 2:50 AM, Praveen Ponakanti wrote:
> > Hi Alex/Amos,
> >
> > Do you still need memory logs from version 5.3 after stopping traffic
> > through the squid?
>
> I cannot answer for Amos who asked for those logs, but you may want to
> try a fix posted at
> https://bugs.squid-cache.org/show_bug.cgi?id=5132#c27
>
>
> HTH,
>
> Alex.
>
>
> > We have disabled traffic to the 5.3 version squid
> > about 6 hours ago and have not seen any memory being freed up since.
> > This node has used up ~50G more memory compared with 4.17 squid taking
> > similar traffic over the last 3+ weeks. I am collecting hourly memory
> > logs on 5.3 after stopping traffic. Let me know and I can attach the
> > log tomorrow morning.
> >
> > Thanks
> > Praveen
> >
> > On Mon, Dec 27, 2021 at 4:58 PM Praveen Ponakanti <pponakanti at roblox.com
> > <mailto:pponakanti at roblox.com>> wrote:
> >
> >     I cant make any changes to our prod squids this week. I have a squid
> >     instance (5.3v) in a test env but could not reproduce the leak by
> >     starting & stopping traffic with a bulk http req generator (wrk).
> >     Was able to send 175k rps @ 20k concurrent sessions (each doing a
> >     get on a 1KB object) through the 30-worker squid. This initially
> >     caused a 3G increase in memory usage and then flattened out after
> >     stopping the requests. If I restart the bulk reqs, the memory usage
> >     only goes up ~0.5GB and then drops back down. Live traffic is
> >     probably exercising a different code path within squid's memory
> pools.
> >
> >     On Mon, Dec 27, 2021 at 2:26 AM Luk?? Lou?ansk?
> >     <loucansky.lukas at kjj.cz <mailto:loucansky.lukas at kjj.cz>> wrote:
> >
> >         After one day of running without clients my squid memory is
> stable
> >
> >         29345 proxy     20   0  171348 122360  14732 S   0.0   0.7
> >         0:25.96 (squid-1) --kid squid-1 -YC -f /etc/squid5/squid.conf
> >         29343 root      20   0  133712  79264   9284 S   0.0   0.5
> >         0:00.00 /usr/sbin/squid -YC -f /etc/squid5/squid.conf
> >
> >         Storage Mem size: 3944 KB Storage Mem capacity: 0.2% used, 99.8%
> >         free Maximum Resident Size: 489440 KB Page faults with physical
> >         i/o: 0 Memory accounted for: Total accounted: 15741 KB
> >         memPoolAlloc calls: 1061495 memPoolFree calls: 1071691 Total
> >         allocated 15741 kB So this does not seem to be the problem... L
> >
> >         Dne 26.12.2021 v 10:02 Luk?? Lou?ansk? napsal(a):
> >>         ok - as it seems my squid quacked on low memory again today -
> >>
> >>         Dec 26 00:04:25 gw (squid-1): FATAL: Too many queued store_id
> >>         requests; see on-persistent-overload.#012    current master
> >>         transaction: master4629331
> >>         Dec 26 00:04:28 gw squid[15485]: Squid Parent: squid-1 process
> >>         15487 exited with status 1
> >>         Dec 26 00:04:28 gw squid[15485]: Squid Parent: (squid-1)
> >>         process 28375 started
> >>
> >>         2021/12/26 00:01:20 kid1| helperOpenServers: Starting 5/64
> >>         'storeid_file_rewrite' processes
> >>         2021/12/26 00:01:20 kid1| ipcCreate: fork: (12) Cannot
> >>         allocate memory
> >>         2021/12/26 00:01:20 kid1| WARNING: Cannot run
> >>         '/lib/squid5/storeid_file_rewrite' process.
> >>         2021/12/26 00:01:20 kid1| ipcCreate: fork: (12) Cannot
> >>         allocate memory
> >>
> >>         I'm going to reroute my clients (which are on their days off
> >>         anyway) to direct connections and run it "dry" - on it's own.
> >>         But I'm not able to to test it before "lack of memory issues
> >>         occur" - because my clients are offline. So I'll watch squid
> >>         for it's own memory consuption. It's all I can do right now -
> >>         my squid already restarted and it's memory has been freed - so
> >>         I think just now I have no power to fill it up again :-]
> >>
> >>         L
> >>
> >>         Dne 26.12.2021 v 7:41 Amos Jeffries napsal(a):
> >>>
> >>>         If possible can one of you run a Squid to get this behaviour,
> >>>         then stop new clients connecting to it before lack of memory
> >>>         issues occur and see if the memory usage disappears or
> >>>         reduces after a 24-48hr wait.
> >>>
> >>>         A series of regular mempools report dumps from across the
> >>>         test may help Alex or whoever works on the bug eliminate
> >>>         further which cache and client related things are releasing
> >>>         properly.
> >>>
> >>>
> >>>         Amos
> >>>
> >>>         _______________________________________________
> >>>         squid-users mailing list
> >>>         squid-users at lists.squid-cache.org
> >>>         <mailto:squid-users at lists.squid-cache.org>
> >>>         http://lists.squid-cache.org/listinfo/squid-users
> >>>         <http://lists.squid-cache.org/listinfo/squid-users>
> >>
> >
> >         <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient
> >
> >               Bez vir?. www.avast.com
> >         <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient
> >
> >
> >
> >
>  <#m_-6622557068709516458_m_9217020348889694418_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >         _______________________________________________
> >         squid-users mailing list
> >         squid-users at lists.squid-cache.org
> >         <mailto:squid-users at lists.squid-cache.org>
> >         http://lists.squid-cache.org/listinfo/squid-users
> >         <http://lists.squid-cache.org/listinfo/squid-users>
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220106/8e149523/attachment.htm>

From squid3 at treenet.co.nz  Fri Jan  7 08:27:28 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Jan 2022 21:27:28 +1300
Subject: [squid-users] MITM the MITM
In-Reply-To: <730f0320-8ec5-db56-13a2-35ebd405f09b@spamtrap.tnetconsulting.net>
References: <e2d9f88c-497f-6a6d-f682-bca17fb4830d@brainmeltdown.net>
 <202201040135.48476.Antony.Stone@squid.open.source.it>
 <1728a695-0a6a-02aa-d312-dd6c595a76c8@brainmeltdown.net>
 <730f0320-8ec5-db56-13a2-35ebd405f09b@spamtrap.tnetconsulting.net>
Message-ID: <d373f4b6-ad01-49a7-b422-f7a959b03005@treenet.co.nz>

FYI people,

When Squid

On 7/01/22 06:33, Grant Taylor wrote:
> On 1/4/22 2:35 AM, Will BMD wrote:
>> HTTP proxy limitation
>>
>> The system cannot decrypt traffic if an HTTP proxy is positioned 
>> between a client and your managed device, and the client and server 
>> establish a tunneled TLS/SSL connection using the CONNECT HTTP method. 
>> The Handshake Errors undecryptable action determines how the system 
>> handles this traffic.
> 
> I ... don't know what to make of this.? I would have some questions for 
> the vendor (Cisco).
> 

This reads to me like the FTDv supports plain-test HTTP on port 80 and 
HTTPS on port 443, not CONNECT tunnel intercept/decrypt, nor TLS between 
proxies.

So when a proxy like Squid is placed in front:

  * it cannot handle being configured as a peer to Squid. Because those 
peers get HTTPS as CONNECT tunnels, or the TLS is proxy-proxy TLS not 
client-server.

  * it probably can handle Squid terminating CONNECT requests and 
tunneling directly to port 443. Because that TLS is done by client, not 
Squid.

  * it probably can handle Squid SSL-Bump splice or bump traffic with 
*no* peers configured. Because Squid is then just another client talking 
over port 443 to a server. However, you will need Squid to trust the 
FTDv signing certificate, just like client for SSL-Bump need to trust 
Squid's.


HTH
Amos


From squid3 at treenet.co.nz  Fri Jan  7 08:33:06 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Jan 2022 21:33:06 +1300
Subject: [squid-users] MITM the MITM
In-Reply-To: <1165ceb8-7b8e-cb0c-1487-f38ff327e207@spamtrap.tnetconsulting.net>
References: <e2d9f88c-497f-6a6d-f682-bca17fb4830d@brainmeltdown.net>
 <dd1929c6-7f2a-ad41-6a62-6e97d4ed0e83@spamtrap.tnetconsulting.net>
 <25decadd-390b-003e-3b78-e50fb7759571@brainmeltdown.net>
 <1165ceb8-7b8e-cb0c-1487-f38ff327e207@spamtrap.tnetconsulting.net>
Message-ID: <b5d76992-0220-2962-519d-e20b0b536ec7@treenet.co.nz>

On 7/01/22 06:26, Grant Taylor wrote:
> On 1/4/22 9:56 AM, Will BMD wrote:
>> I'm not aware of WCCP, but I'll look into it.
> 
> In short, the Web Cache Communications Protocol, "... specifies 
> interactions between one or more routers (or Layer 3 switches) and one 
> or more web-caches ...".
> 
> Link - Web Cache Communications Protocol (WCCP)
>  ?- 
> https://www.cisco.com/c/en/us/tech/content-networking/web-cache-communications-protocol-wccp/index.html 
> 
> 
> WCCP can be pressed into service between an in-path device (usually L3) 
> and a cache.? As such, I would hope ~> expect that the pseudo L3 
> firewall can do it's work while using WCCP to allow a backend proxy do 
> the actual caching, et la.
> 


FYI, WCCP is one way of routing client traffic to Squid where that Squid 
is doing interception.

The Squid wiki has a whole section on how to setup both router/switch 
and Squid ends of the WCCP. 
<https://wiki.squid-cache.org/ConfigExamples/#Interception>


HTH
Amos


From squid3 at treenet.co.nz  Fri Jan  7 08:39:37 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Jan 2022 21:39:37 +1300
Subject: [squid-users] Significant memory leak with version 5.x (not
 with 4.17)
In-Reply-To: <877c1e3f-bd4f-2db2-bb03-49b37d1f0f6b@measurement-factory.com>
References: <CACabJxOfSqVkN63DN=N=_J=B7CtH-ahRkFaAtM93H67BpQx9eA@mail.gmail.com>
 <f68674bd-1203-062d-9786-7513554fafb4@measurement-factory.com>
 <CACabJxOTJaKcavxx8AwNoETA6OjsLw0OsdLO=d2M05DpHBstGQ@mail.gmail.com>
 <88e5e3e2-5641-883b-fd8c-cf4c3796ea4a@measurement-factory.com>
 <CACabJxN4Vn5HGnoh4b5wVJQm2wRGeBXSH0gcxPwY37cv1wJPmA@mail.gmail.com>
 <80242ed5-4e35-b2e3-80cb-82b78f4303e1@kjj.cz>
 <CACabJxMO-V86qzg9jk0wV=V=Q+j4Gq+4OehxkZkWV284+XaJkg@mail.gmail.com>
 <c06023d4-c97c-7ae5-037f-f20249f87ca3@treenet.co.nz>
 <cc63af40-3aa5-15ef-30ac-2f929b6def8f@kjj.cz>
 <4a1ae799-2d3b-37c8-8d24-d98f95a424fa@kjj.cz>
 <CACabJxNvqBr1=UswwszfDvBjjrFHTDi87bFDuzTtJ8Tc4OM2RQ@mail.gmail.com>
 <CACabJxMfkCXtRu=mot_48i148AR29XL0oP8s+5fZdpzo49pnjQ@mail.gmail.com>
 <877c1e3f-bd4f-2db2-bb03-49b37d1f0f6b@measurement-factory.com>
Message-ID: <f738225f-82ef-e5c6-dfe8-0b78c2600706@treenet.co.nz>

On 7/01/22 17:16, Alex Rousskov wrote:
> On 1/6/22 2:50 AM, Praveen Ponakanti wrote:
>> Hi Alex/Amos,
>>
>> Do you still need memory logs from version 5.3 after stopping traffic
>> through the squid?
> 

I asked so anyone taking on the bug would have data to work with. 3 days 
worth should be plenty to work with, so it is fine for you to stop now. 
If/when someone picks up the issue they may have more detailed info 
requests.


> I cannot answer for Amos who asked for those logs, but you may want to
> try a fix posted at
> https://bugs.squid-cache.org/show_bug.cgi?id=5132#c27
> 
> 

If that does not work the data you have collected may still be useful to 
figure out what exactly is hitting you.

Cheers
Amos


From Ralf.Hildebrandt at charite.de  Fri Jan  7 08:50:04 2022
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Fri, 7 Jan 2022 09:50:04 +0100
Subject: [squid-users] [ext] Re: Significant memory leak with version
 5.x (not with 4.17)
In-Reply-To: <f738225f-82ef-e5c6-dfe8-0b78c2600706@treenet.co.nz>
References: <CACabJxN4Vn5HGnoh4b5wVJQm2wRGeBXSH0gcxPwY37cv1wJPmA@mail.gmail.com>
 <80242ed5-4e35-b2e3-80cb-82b78f4303e1@kjj.cz>
 <CACabJxMO-V86qzg9jk0wV=V=Q+j4Gq+4OehxkZkWV284+XaJkg@mail.gmail.com>
 <c06023d4-c97c-7ae5-037f-f20249f87ca3@treenet.co.nz>
 <cc63af40-3aa5-15ef-30ac-2f929b6def8f@kjj.cz>
 <4a1ae799-2d3b-37c8-8d24-d98f95a424fa@kjj.cz>
 <CACabJxNvqBr1=UswwszfDvBjjrFHTDi87bFDuzTtJ8Tc4OM2RQ@mail.gmail.com>
 <CACabJxMfkCXtRu=mot_48i148AR29XL0oP8s+5fZdpzo49pnjQ@mail.gmail.com>
 <877c1e3f-bd4f-2db2-bb03-49b37d1f0f6b@measurement-factory.com>
 <f738225f-82ef-e5c6-dfe8-0b78c2600706@treenet.co.nz>
Message-ID: <Ydf+vImcboRtYFaM@charite.de>

> > I cannot answer for Amos who asked for those logs, but you may want to
> > try a fix posted at
> > https://bugs.squid-cache.org/show_bug.cgi?id=5132#c27
> > 
> > 
> 
> If that does not work the data you have collected may still be useful to
> figure out what exactly is hitting you.

Update (checked this morning): memory consumption (squid 5.3) seems to be stable.

I'll upgrade to 6.0 with the proposed fix, since bug 5055 becomes the
more pressing issue after the memleak is gone.

Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From squid3 at treenet.co.nz  Fri Jan  7 14:34:57 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 8 Jan 2022 03:34:57 +1300
Subject: [squid-users] squid 5.3 frequent crash
In-Reply-To: <09f185c0-533a-cafe-4e80-57a644449888@measurement-factory.com>
References: <6742bd06-14b6-c43a-71ff-3bd3ebb5fe44@ckta.by>
 <09f185c0-533a-cafe-4e80-57a644449888@measurement-factory.com>
Message-ID: <08060bfb-9502-b112-7dfc-666417a75037@treenet.co.nz>

On 7/01/22 06:00, Alex Rousskov wrote:
> On 1/6/22 6:53 AM, Majed Zouhairy wrote:
>> peace i have squid with ufdb guard, after upgrading today to 5.3 i'm
>> getting:
> 
>> 2022/01/06 14:27:18 kid1| FATAL: check failed: opening()
>>      exception location: FwdState.cc(628) noteDestinationsEnd
> 
>> what is the cause?
> 
> This is most likely bug 5055 fixed in August 2021:
> https://bugs.squid-cache.org/show_bug.cgi?id=5055
> 
> In many environments, Squid v5 is unusable without that bug fix. I do
> not know whether the v5 maintainer plans to officially backport the fix
> from master/v6 to v5, but we would be happy to assist with that. FWIW,
> Factory has an _unofficial_ backport to v5-based code at:
> https://github.com/measurement-factory/squid/commit/22b5f78
> 

The commit message documents that the bug fix is a small part of the 
changes made. Others include altering the fundamental AsyncJob API 
behaviour - affecting every feature in Squid at their most fundamental 
levels. That amount of change is not going into a "stable" release of Squid.

I will consider patches for just the bug 5055 issue though.


HTH
Amos


From rousskov at measurement-factory.com  Fri Jan  7 16:02:54 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 7 Jan 2022 11:02:54 -0500
Subject: [squid-users] squid 5.3 frequent crash
In-Reply-To: <08060bfb-9502-b112-7dfc-666417a75037@treenet.co.nz>
References: <6742bd06-14b6-c43a-71ff-3bd3ebb5fe44@ckta.by>
 <09f185c0-533a-cafe-4e80-57a644449888@measurement-factory.com>
 <08060bfb-9502-b112-7dfc-666417a75037@treenet.co.nz>
Message-ID: <0b2da47a-a862-6f25-5a0b-9b2bb881303b@measurement-factory.com>

On 1/7/22 9:34 AM, Amos Jeffries wrote:
> On 7/01/22 06:00, Alex Rousskov wrote:
>> On 1/6/22 6:53 AM, Majed Zouhairy wrote:
>>> after upgrading today to 5.3 i'm getting:
>>
>>> 2022/01/06 14:27:18 kid1| FATAL: check failed: opening()
>>> ???? exception location: FwdState.cc(628) noteDestinationsEnd
>>
>>> what is the cause?
>>
>> This is most likely bug 5055 fixed in August 2021:
>> https://bugs.squid-cache.org/show_bug.cgi?id=5055
>>
>> In many environments, Squid v5 is unusable without that bug fix. I do
>> not know whether the v5 maintainer plans to officially backport the fix
>> from master/v6 to v5, but we would be happy to assist with that.


> The commit message documents that the bug fix is a small part of the
> changes made.

I am unable to separate many of the bug fixes from most other changes in
that commit. I am a fan of surgical fixes, but, sometimes, significant
code changes are required to address a set of bugs. One could, of
course, ignore most of the bugs fixed by the official commit and just
make sure that v5 does not violate the opening() MUST that triggered
this thread, but I see no point in doing that -- we will end up chasing
one known bug after another, sometimes in circles, and often via painful
triage.


> Others include altering the fundamental AsyncJob API behaviour -
> affecting every feature in Squid at their most fundamental levels.

I disagree with the above summary.


> That amount of change is not going into a "stable" release of
> Squid.

FWIW, IMHO, Squid v5 is much better with those changes than it is
without them. Once tested, the changes do not violate any fundamental
stability principles that I know of. However, I think it is best to let
the maintainer (i.e. you) make v5 admission decisions. I am just
providing feedback to facilitate informed decisions.


> I will consider patches for just the bug 5055 issue though.

To avoid misunderstanding, (the backport of) the official set of fixes
is what I am offering for your consideration. If others can address all
those bugs using smaller patches, great! Otherwise, I recommend
backporting the comprehensive fix and am happy to assist with that.


HTH,

Alex.


From rousskov at measurement-factory.com  Fri Jan  7 16:54:27 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 7 Jan 2022 11:54:27 -0500
Subject: [squid-users] Significant memory leak with version 5.x (not
 with 4.17)
In-Reply-To: <CACabJxODMUgsN7SA0Y3p-RBrbMaD3uRoHfDJ5Y004WE4PyZOaw@mail.gmail.com>
References: <CACabJxOfSqVkN63DN=N=_J=B7CtH-ahRkFaAtM93H67BpQx9eA@mail.gmail.com>
 <f68674bd-1203-062d-9786-7513554fafb4@measurement-factory.com>
 <CACabJxOTJaKcavxx8AwNoETA6OjsLw0OsdLO=d2M05DpHBstGQ@mail.gmail.com>
 <88e5e3e2-5641-883b-fd8c-cf4c3796ea4a@measurement-factory.com>
 <CACabJxN4Vn5HGnoh4b5wVJQm2wRGeBXSH0gcxPwY37cv1wJPmA@mail.gmail.com>
 <80242ed5-4e35-b2e3-80cb-82b78f4303e1@kjj.cz>
 <CACabJxMO-V86qzg9jk0wV=V=Q+j4Gq+4OehxkZkWV284+XaJkg@mail.gmail.com>
 <c06023d4-c97c-7ae5-037f-f20249f87ca3@treenet.co.nz>
 <cc63af40-3aa5-15ef-30ac-2f929b6def8f@kjj.cz>
 <4a1ae799-2d3b-37c8-8d24-d98f95a424fa@kjj.cz>
 <CACabJxNvqBr1=UswwszfDvBjjrFHTDi87bFDuzTtJ8Tc4OM2RQ@mail.gmail.com>
 <CACabJxMfkCXtRu=mot_48i148AR29XL0oP8s+5fZdpzo49pnjQ@mail.gmail.com>
 <877c1e3f-bd4f-2db2-bb03-49b37d1f0f6b@measurement-factory.com>
 <CACabJxODMUgsN7SA0Y3p-RBrbMaD3uRoHfDJ5Y004WE4PyZOaw@mail.gmail.com>
Message-ID: <61f6db02-c221-bf64-df6e-18765d888463@measurement-factory.com>

On 1/7/22 12:12 AM, Praveen Ponakanti wrote:

> Is there a build with the fix, or do you have some recommended steps
> to manually pull the source, patch the fix and then recompile?

Yes, applying the patch to official Squid sources and then bootstrapping
and building from patched sources is what folks using patches usually
have to do. Roughly speaking:

    cd squid-x.y.z/
    patch -p1 < ...
    ./bootstrap.sh
    ./configure
    make
    make check
    sudo make install

The above steps usually require installing a few build-related tools
(and custom options like --prefix and --with-openssl). A capable
sysadmin should be able to get this done in most cases. It is possible
to avoid the bootstrapping step if the patch does not modify
bootstrapping-sensitive files and you can get a bootstrapped version of
the sources from http://www.squid-cache.org/Versions/

I am not aware of anybody providing ready-to-use builds that include the
proposed bug 5132 fix.


HTH,

Alex.


> On Thu, Jan 6, 2022 at 8:16 PM Alex Rousskov wrote:
> 
>     On 1/6/22 2:50 AM, Praveen Ponakanti wrote:
>     > Hi Alex/Amos,
>     >
>     > Do you still need memory logs from version 5.3 after stopping traffic
>     > through the squid?
> 
>     I cannot answer for Amos who asked for those logs, but you may want to
>     try a fix posted at
>     https://bugs.squid-cache.org/show_bug.cgi?id=5132#c27
> 
> 
>     HTH,
> 
>     Alex.
> 
> 
>     > We have disabled traffic to the 5.3 version squid
>     > about 6 hours ago and have not seen any memory being freed up since.
>     > This node has used up ~50G more memory compared with 4.17 squid taking
>     > similar traffic over the last 3+ weeks. I am collecting hourly memory
>     > logs on 5.3 after stopping traffic. Let me know and I can attach the
>     > log?tomorrow?morning.
>     >
>     > Thanks
>     > Praveen
>     >
>     > On Mon, Dec 27, 2021 at 4:58 PM Praveen Ponakanti
>     <pponakanti at roblox.com <mailto:pponakanti at roblox.com>
>     > <mailto:pponakanti at roblox.com <mailto:pponakanti at roblox.com>>> wrote:
>     >
>     >? ? ?I cant?make any changes to our prod squids this week. I have a
>     squid
>     >? ? ?instance (5.3v) in a test env but could not reproduce the leak by
>     >? ? ?starting & stopping traffic with a bulk http req generator (wrk).
>     >? ? ?Was able to send 175k rps @ 20k concurrent sessions (each doing a
>     >? ? ?get on a 1KB object) through?the 30-worker squid. This initially
>     >? ? ?caused a 3G increase in memory usage and then flattened out after
>     >? ? ?stopping the requests. If I restart the bulk reqs, the memory
>     usage
>     >? ? ?only goes up ~0.5GB and then drops back down. Live traffic is
>     >? ? ?probably exercising a different code path within squid's
>     memory pools.
>     >
>     >? ? ?On Mon, Dec 27, 2021 at 2:26 AM Luk?? Lou?ansk?
>     >? ? ?<loucansky.lukas at kjj.cz <mailto:loucansky.lukas at kjj.cz>
>     <mailto:loucansky.lukas at kjj.cz <mailto:loucansky.lukas at kjj.cz>>> wrote:
>     >
>     >? ? ? ? ?After one day of running without clients my squid memory
>     is stable
>     >
>     >? ? ? ? ?29345 proxy???? 20?? 0? 171348 122360? 14732 S?? 0.0?? 0.7??
>     >? ? ? ? ?0:25.96 (squid-1) --kid squid-1 -YC -f /etc/squid5/squid.conf
>     >? ? ? ? ?29343 root????? 20?? 0? 133712? 79264?? 9284 S?? 0.0?? 0.5??
>     >? ? ? ? ?0:00.00 /usr/sbin/squid -YC -f /etc/squid5/squid.conf
>     >
>     >? ? ? ? ?Storage Mem size: 3944 KB Storage Mem capacity: 0.2% used,
>     99.8%
>     >? ? ? ? ?free Maximum Resident Size: 489440 KB Page faults with
>     physical
>     >? ? ? ? ?i/o: 0 Memory accounted for: Total accounted: 15741 KB
>     >? ? ? ? ?memPoolAlloc calls: 1061495 memPoolFree calls: 1071691 Total
>     >? ? ? ? ?allocated 15741 kB So this does not seem to be the
>     problem... L
>     >
>     >? ? ? ? ?Dne 26.12.2021 v 10:02 Luk?? Lou?ansk? napsal(a):
>     >>? ? ? ? ?ok - as it seems my squid quacked on low memory again today -
>     >>
>     >>? ? ? ? ?Dec 26 00:04:25 gw (squid-1): FATAL: Too many queued store_id
>     >>? ? ? ? ?requests; see on-persistent-overload.#012??? current master
>     >>? ? ? ? ?transaction: master4629331
>     >>? ? ? ? ?Dec 26 00:04:28 gw squid[15485]: Squid Parent: squid-1
>     process
>     >>? ? ? ? ?15487 exited with status 1
>     >>? ? ? ? ?Dec 26 00:04:28 gw squid[15485]: Squid Parent: (squid-1)
>     >>? ? ? ? ?process 28375 started
>     >>
>     >>? ? ? ? ?2021/12/26 00:01:20 kid1| helperOpenServers: Starting 5/64
>     >>? ? ? ? ?'storeid_file_rewrite' processes
>     >>? ? ? ? ?2021/12/26 00:01:20 kid1| ipcCreate: fork: (12) Cannot
>     >>? ? ? ? ?allocate memory
>     >>? ? ? ? ?2021/12/26 00:01:20 kid1| WARNING: Cannot run
>     >>? ? ? ? ?'/lib/squid5/storeid_file_rewrite' process.
>     >>? ? ? ? ?2021/12/26 00:01:20 kid1| ipcCreate: fork: (12) Cannot
>     >>? ? ? ? ?allocate memory
>     >>
>     >>? ? ? ? ?I'm going to reroute my clients (which are on their days off
>     >>? ? ? ? ?anyway) to direct connections and run it "dry" - on it's own.
>     >>? ? ? ? ?But I'm not able to to test it before "lack of memory issues
>     >>? ? ? ? ?occur" - because my clients are offline. So I'll watch squid
>     >>? ? ? ? ?for it's own memory consuption. It's all I can do right now -
>     >>? ? ? ? ?my squid already restarted and it's memory has been freed
>     - so
>     >>? ? ? ? ?I think just now I have no power to fill it up again :-]
>     >>
>     >>? ? ? ? ?L
>     >>
>     >>? ? ? ? ?Dne 26.12.2021 v 7:41 Amos Jeffries napsal(a):
>     >>>
>     >>>? ? ? ? ?If possible can one of you run a Squid to get this
>     behaviour,
>     >>>? ? ? ? ?then stop new clients connecting to it before lack of memory
>     >>>? ? ? ? ?issues occur and see if the memory usage disappears or
>     >>>? ? ? ? ?reduces after a 24-48hr wait.
>     >>>
>     >>>? ? ? ? ?A series of regular mempools report dumps from across the
>     >>>? ? ? ? ?test may help Alex or whoever works on the bug eliminate
>     >>>? ? ? ? ?further which cache and client related things are releasing
>     >>>? ? ? ? ?properly.
>     >>>
>     >>>
>     >>>? ? ? ? ?Amos
>     >>>
>     >>>? ? ? ? ?_______________________________________________
>     >>>? ? ? ? ?squid-users mailing list
>     >>>? ? ? ? ?squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     >>>? ? ? ? ?<mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>     >>>? ? ? ? ?http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>
>     >>>? ? ? ? ?<http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>>
>     >>
>     >
>     >? ? ? ?
>     ?<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient
>     <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient>>
>     >? ? ? ? ? ? ? ?Bez vir?. www.avast.com <http://www.avast.com>
>     >? ? ? ?
>     ?<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient
>     <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient>>
>     >
>     >
>     >? ? ? ?
>     ?<#m_-6622557068709516458_m_9217020348889694418_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>     >? ? ? ? ?_______________________________________________
>     >? ? ? ? ?squid-users mailing list
>     >? ? ? ? ?squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     >? ? ? ? ?<mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>     >? ? ? ? ?http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>
>     >? ? ? ? ?<http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>>
>     >
>     >
>     > _______________________________________________
>     > squid-users mailing list
>     > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     > http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>
>     >
> 



From marcelorodrigo at graminsta.com.br  Fri Jan  7 19:11:14 2022
From: marcelorodrigo at graminsta.com.br (Graminsta)
Date: Fri, 7 Jan 2022 16:11:14 -0300
Subject: [squid-users] Squid 4.13 does not access Facebook
Message-ID: <03dd01d803fa$599628b0$0cc27a10$@graminsta.com.br>

Hello :)

 

I have a specific problem with facebook access in squid 4.13 with Ubuntu 20.

It can access all other IPV6 websites but not https://www.facebook.com. Or
any other facebook URL.

 

Outside of squid, the access is working via curl in the same server with the
same IPV6 addresses.

It happens with all IPV6 servers I have.

 

 

Please don't make the following data public from here:

I am a IPV6 proxy provider

You can use the proxy access to test it. Its 181.191.73.174:4000 user
hugoebah pw senhabesta11

I will provide you with a SSH access to avoid you all the trouble to you
make a lab.

SSH 181.191.73.174 user root pw esqueci11@

I am using this server in my Instagram automation but if you have to reboot
it or do testing, you can do it. Its just dummy accounts.

 

Tks a lot ;)

 

Marcelo Rodrigo

Whatsapp 11 9 6854-3878

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220107/917927a8/attachment.htm>

From bruno.larini at riosoft.com.br  Fri Jan  7 20:13:06 2022
From: bruno.larini at riosoft.com.br (Bruno de Paula Larini)
Date: Fri, 7 Jan 2022 17:13:06 -0300
Subject: [squid-users] Squid 4.13 does not access Facebook
In-Reply-To: <03dd01d803fa$599628b0$0cc27a10$@graminsta.com.br>
References: <03dd01d803fa$599628b0$0cc27a10$@graminsta.com.br>
Message-ID: <afc35a6e-a2d6-bd82-c258-b4bf707d95ab@riosoft.com.br>

This is a public mailing list my friend.
Your IP address and password are available on the internet now.

I recommend you to disable that SSH service.

Take care next time.


Em 07/01/2022 16:11, Graminsta escreveu:
>
> Hello J
>
> I have a specific problem with facebook access in squid 4.13 with 
> Ubuntu 20.
>
> It can access all other IPV6 websites but not 
> https://www.facebook.com. Or any other facebook URL.
>
> Outside of squid, the access is working via curl in the same server 
> with the same IPV6 addresses.
>
> It happens with all IPV6 servers I have.
>
> Please don?t make the following data public from here:
>
> I am a IPV6 proxy provider
>
> You can use the proxy access to test it. Its 181.191.73.174:4000 user 
> hugoebah pw senhabesta11
>
> I will provide you with a SSH access to avoid you all the trouble to 
> you make a lab.
>
> SSH 181.191.73.174 user root pw esqueci11@
>
> I am using this server in my Instagram automation but if you have to 
> reboot it or do testing, you can do it. Its just dummy accounts.
>
> Tks a lot ;)
>
> Marcelo Rodrigo
>
> Whatsapp 11 9 6854-3878
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220107/9296a43e/attachment.htm>

From pponakanti at roblox.com  Fri Jan  7 21:16:19 2022
From: pponakanti at roblox.com (Praveen Ponakanti)
Date: Fri, 7 Jan 2022 13:16:19 -0800
Subject: [squid-users] Significant memory leak with version 5.x (not
 with 4.17)
In-Reply-To: <61f6db02-c221-bf64-df6e-18765d888463@measurement-factory.com>
References: <CACabJxOfSqVkN63DN=N=_J=B7CtH-ahRkFaAtM93H67BpQx9eA@mail.gmail.com>
 <f68674bd-1203-062d-9786-7513554fafb4@measurement-factory.com>
 <CACabJxOTJaKcavxx8AwNoETA6OjsLw0OsdLO=d2M05DpHBstGQ@mail.gmail.com>
 <88e5e3e2-5641-883b-fd8c-cf4c3796ea4a@measurement-factory.com>
 <CACabJxN4Vn5HGnoh4b5wVJQm2wRGeBXSH0gcxPwY37cv1wJPmA@mail.gmail.com>
 <80242ed5-4e35-b2e3-80cb-82b78f4303e1@kjj.cz>
 <CACabJxMO-V86qzg9jk0wV=V=Q+j4Gq+4OehxkZkWV284+XaJkg@mail.gmail.com>
 <c06023d4-c97c-7ae5-037f-f20249f87ca3@treenet.co.nz>
 <cc63af40-3aa5-15ef-30ac-2f929b6def8f@kjj.cz>
 <4a1ae799-2d3b-37c8-8d24-d98f95a424fa@kjj.cz>
 <CACabJxNvqBr1=UswwszfDvBjjrFHTDi87bFDuzTtJ8Tc4OM2RQ@mail.gmail.com>
 <CACabJxMfkCXtRu=mot_48i148AR29XL0oP8s+5fZdpzo49pnjQ@mail.gmail.com>
 <877c1e3f-bd4f-2db2-bb03-49b37d1f0f6b@measurement-factory.com>
 <CACabJxODMUgsN7SA0Y3p-RBrbMaD3uRoHfDJ5Y004WE4PyZOaw@mail.gmail.com>
 <61f6db02-c221-bf64-df6e-18765d888463@measurement-factory.com>
Message-ID: <CACabJxPhjinJfsXccMgrxA+ubSB88wv0OEBHdZFGn-gtcDq=3w@mail.gmail.com>

Thanks Alex & Amos. Will try the patch in the next week or 2.

On Fri, Jan 7, 2022 at 8:54 AM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 1/7/22 12:12 AM, Praveen Ponakanti wrote:
>
> > Is there a build with the fix, or do you have some recommended steps
> > to manually pull the source, patch the fix and then recompile?
>
> Yes, applying the patch to official Squid sources and then bootstrapping
> and building from patched sources is what folks using patches usually
> have to do. Roughly speaking:
>
>     cd squid-x.y.z/
>     patch -p1 < ...
>     ./bootstrap.sh
>     ./configure
>     make
>     make check
>     sudo make install
>
> The above steps usually require installing a few build-related tools
> (and custom options like --prefix and --with-openssl). A capable
> sysadmin should be able to get this done in most cases. It is possible
> to avoid the bootstrapping step if the patch does not modify
> bootstrapping-sensitive files and you can get a bootstrapped version of
> the sources from http://www.squid-cache.org/Versions/
>
> I am not aware of anybody providing ready-to-use builds that include the
> proposed bug 5132 fix.
>
>
> HTH,
>
> Alex.
>
>
> > On Thu, Jan 6, 2022 at 8:16 PM Alex Rousskov wrote:
> >
> >     On 1/6/22 2:50 AM, Praveen Ponakanti wrote:
> >     > Hi Alex/Amos,
> >     >
> >     > Do you still need memory logs from version 5.3 after stopping
> traffic
> >     > through the squid?
> >
> >     I cannot answer for Amos who asked for those logs, but you may want
> to
> >     try a fix posted at
> >     https://bugs.squid-cache.org/show_bug.cgi?id=5132#c27
> >
> >
> >     HTH,
> >
> >     Alex.
> >
> >
> >     > We have disabled traffic to the 5.3 version squid
> >     > about 6 hours ago and have not seen any memory being freed up
> since.
> >     > This node has used up ~50G more memory compared with 4.17 squid
> taking
> >     > similar traffic over the last 3+ weeks. I am collecting hourly
> memory
> >     > logs on 5.3 after stopping traffic. Let me know and I can attach
> the
> >     > log tomorrow morning.
> >     >
> >     > Thanks
> >     > Praveen
> >     >
> >     > On Mon, Dec 27, 2021 at 4:58 PM Praveen Ponakanti
> >     <pponakanti at roblox.com <mailto:pponakanti at roblox.com>
> >     > <mailto:pponakanti at roblox.com <mailto:pponakanti at roblox.com>>>
> wrote:
> >     >
> >     >     I cant make any changes to our prod squids this week. I have a
> >     squid
> >     >     instance (5.3v) in a test env but could not reproduce the leak
> by
> >     >     starting & stopping traffic with a bulk http req generator
> (wrk).
> >     >     Was able to send 175k rps @ 20k concurrent sessions (each
> doing a
> >     >     get on a 1KB object) through the 30-worker squid. This
> initially
> >     >     caused a 3G increase in memory usage and then flattened out
> after
> >     >     stopping the requests. If I restart the bulk reqs, the memory
> >     usage
> >     >     only goes up ~0.5GB and then drops back down. Live traffic is
> >     >     probably exercising a different code path within squid's
> >     memory pools.
> >     >
> >     >     On Mon, Dec 27, 2021 at 2:26 AM Luk?? Lou?ansk?
> >     >     <loucansky.lukas at kjj.cz <mailto:loucansky.lukas at kjj.cz>
> >     <mailto:loucansky.lukas at kjj.cz <mailto:loucansky.lukas at kjj.cz>>>
> wrote:
> >     >
> >     >         After one day of running without clients my squid memory
> >     is stable
> >     >
> >     >         29345 proxy     20   0  171348 122360  14732 S   0.0
> 0.7
> >     >         0:25.96 (squid-1) --kid squid-1 -YC -f
> /etc/squid5/squid.conf
> >     >         29343 root      20   0  133712  79264   9284 S   0.0
> 0.5
> >     >         0:00.00 /usr/sbin/squid -YC -f /etc/squid5/squid.conf
> >     >
> >     >         Storage Mem size: 3944 KB Storage Mem capacity: 0.2% used,
> >     99.8%
> >     >         free Maximum Resident Size: 489440 KB Page faults with
> >     physical
> >     >         i/o: 0 Memory accounted for: Total accounted: 15741 KB
> >     >         memPoolAlloc calls: 1061495 memPoolFree calls: 1071691
> Total
> >     >         allocated 15741 kB So this does not seem to be the
> >     problem... L
> >     >
> >     >         Dne 26.12.2021 v 10:02 Luk?? Lou?ansk? napsal(a):
> >     >>         ok - as it seems my squid quacked on low memory again
> today -
> >     >>
> >     >>         Dec 26 00:04:25 gw (squid-1): FATAL: Too many queued
> store_id
> >     >>         requests; see on-persistent-overload.#012    current
> master
> >     >>         transaction: master4629331
> >     >>         Dec 26 00:04:28 gw squid[15485]: Squid Parent: squid-1
> >     process
> >     >>         15487 exited with status 1
> >     >>         Dec 26 00:04:28 gw squid[15485]: Squid Parent: (squid-1)
> >     >>         process 28375 started
> >     >>
> >     >>         2021/12/26 00:01:20 kid1| helperOpenServers: Starting 5/64
> >     >>         'storeid_file_rewrite' processes
> >     >>         2021/12/26 00:01:20 kid1| ipcCreate: fork: (12) Cannot
> >     >>         allocate memory
> >     >>         2021/12/26 00:01:20 kid1| WARNING: Cannot run
> >     >>         '/lib/squid5/storeid_file_rewrite' process.
> >     >>         2021/12/26 00:01:20 kid1| ipcCreate: fork: (12) Cannot
> >     >>         allocate memory
> >     >>
> >     >>         I'm going to reroute my clients (which are on their days
> off
> >     >>         anyway) to direct connections and run it "dry" - on it's
> own.
> >     >>         But I'm not able to to test it before "lack of memory
> issues
> >     >>         occur" - because my clients are offline. So I'll watch
> squid
> >     >>         for it's own memory consuption. It's all I can do right
> now -
> >     >>         my squid already restarted and it's memory has been freed
> >     - so
> >     >>         I think just now I have no power to fill it up again :-]
> >     >>
> >     >>         L
> >     >>
> >     >>         Dne 26.12.2021 v 7:41 Amos Jeffries napsal(a):
> >     >>>
> >     >>>         If possible can one of you run a Squid to get this
> >     behaviour,
> >     >>>         then stop new clients connecting to it before lack of
> memory
> >     >>>         issues occur and see if the memory usage disappears or
> >     >>>         reduces after a 24-48hr wait.
> >     >>>
> >     >>>         A series of regular mempools report dumps from across the
> >     >>>         test may help Alex or whoever works on the bug eliminate
> >     >>>         further which cache and client related things are
> releasing
> >     >>>         properly.
> >     >>>
> >     >>>
> >     >>>         Amos
> >     >>>
> >     >>>         _______________________________________________
> >     >>>         squid-users mailing list
> >     >>>         squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>
> >     >>>         <mailto:squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>>
> >     >>>         http://lists.squid-cache.org/listinfo/squid-users
> >     <http://lists.squid-cache.org/listinfo/squid-users>
> >     >>>         <http://lists.squid-cache.org/listinfo/squid-users
> >     <http://lists.squid-cache.org/listinfo/squid-users>>
> >     >>
> >     >
> >     >
> >      <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient
> >     <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient
> >>
> >     >               Bez vir?. www.avast.com <http://www.avast.com>
> >     >
> >      <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient
> >     <
> https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient
> >>
> >     >
> >     >
> >     >
> >
>   <#m_-6622557068709516458_m_9217020348889694418_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> >     >         _______________________________________________
> >     >         squid-users mailing list
> >     >         squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>
> >     >         <mailto:squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>>
> >     >         http://lists.squid-cache.org/listinfo/squid-users
> >     <http://lists.squid-cache.org/listinfo/squid-users>
> >     >         <http://lists.squid-cache.org/listinfo/squid-users
> >     <http://lists.squid-cache.org/listinfo/squid-users>>
> >     >
> >     >
> >     > _______________________________________________
> >     > squid-users mailing list
> >     > squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>
> >     > http://lists.squid-cache.org/listinfo/squid-users
> >     <http://lists.squid-cache.org/listinfo/squid-users>
> >     >
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220107/a2ed719d/attachment.htm>

From marcelorodrigo at graminsta.com.br  Fri Jan  7 21:39:41 2022
From: marcelorodrigo at graminsta.com.br (Graminsta)
Date: Fri, 7 Jan 2022 18:39:41 -0300
Subject: [squid-users] RES:  Squid 4.13 does not access Facebook
In-Reply-To: <afc35a6e-a2d6-bd82-c258-b4bf707d95ab@riosoft.com.br>
References: <03dd01d803fa$599628b0$0cc27a10$@graminsta.com.br>
 <afc35a6e-a2d6-bd82-c258-b4bf707d95ab@riosoft.com.br>
Message-ID: <03e901d8040f$15fb7050$41f250f0$@graminsta.com.br>

I I thought it was filtered by you guys before make it public.
Other sensitive content I sent was erased before it came in this list.

Its to bad.
Now I have to change the pw of about 200 VPSs, hell.

 

Marcelo Rodrigo

 

De: Bruno de Paula Larini [mailto:bruno.larini at riosoft.com.br] 
Enviada em: sexta-feira, 7 de janeiro de 2022 17:13
Para: Graminsta; squid-users at lists.squid-cache.org
Assunto: Re: [squid-users] Squid 4.13 does not access Facebook

 

This is a public mailing list my friend.
Your IP address and password are available on the internet now.

I recommend you to disable that SSH service.

Take care next time.


Em 07/01/2022 16:11, Graminsta escreveu:



Hello :)

 

I have a specific problem with facebook access in squid 4.13 with Ubuntu 20.

It can access all other IPV6 websites but not https://www.facebook.com. Or any other facebook URL.

 

Outside of squid, the access is working via curl in the same server with the same IPV6 addresses.

It happens with all IPV6 servers I have.

 

 

Please don?t make the following data public from here:

I am a IPV6 proxy provider

You can use the proxy access to test it. Its 181.191.73.174:4000 user hugoebah pw senhabesta11

I will provide you with a SSH access to avoid you all the trouble to you make a lab.

SSH 181.191.73.174 user root pw esqueci11@

I am using this server in my Instagram automation but if you have to reboot it or do testing, you can do it. Its just dummy accounts.

 

Tks a lot ;)

 

Marcelo Rodrigo

Whatsapp 11 9 6854-3878





_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220107/0f450741/attachment.htm>

From Antony.Stone at squid.open.source.it  Fri Jan  7 21:46:35 2022
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 7 Jan 2022 22:46:35 +0100
Subject: [squid-users] RES:  Squid 4.13 does not access Facebook
In-Reply-To: <03e901d8040f$15fb7050$41f250f0$@graminsta.com.br>
References: <03dd01d803fa$599628b0$0cc27a10$@graminsta.com.br>
 <afc35a6e-a2d6-bd82-c258-b4bf707d95ab@riosoft.com.br>
 <03e901d8040f$15fb7050$41f250f0$@graminsta.com.br>
Message-ID: <202201072246.36005.Antony.Stone@squid.open.source.it>

On Friday 07 January 2022 at 22:39:41, Graminsta wrote:

> Now I have to change the pw of about 200 VPSs, hell.

I have to question the wisdom of using the same root PW on multiple servers, 
even when that PW has not been posted on a public mailing list.


Antony.

-- 
I bought a book on memory techniques, but I've forgotten where I put it.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From rousskov at measurement-factory.com  Sat Jan  8 00:26:21 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 7 Jan 2022 19:26:21 -0500
Subject: [squid-users] RES: Squid 4.13 does not access Facebook
In-Reply-To: <03e901d8040f$15fb7050$41f250f0$@graminsta.com.br>
References: <03dd01d803fa$599628b0$0cc27a10$@graminsta.com.br>
 <afc35a6e-a2d6-bd82-c258-b4bf707d95ab@riosoft.com.br>
 <03e901d8040f$15fb7050$41f250f0$@graminsta.com.br>
Message-ID: <c6333f13-5d44-6db7-30f0-5d73cf7886bc@measurement-factory.com>

On 1/7/22 4:39 PM, Graminsta wrote:
> I thought it was filtered by you guys before make it public.
> Other sensitive content I sent was erased before it came in this list.

Just to avoid misunderstanding: squid-users emails from subscribers are
not moderated by default. Content erasure, if any, is essentially
accidental (e.g., a side effect of the message hitting some attachment
size limits). System administration aside, there are no "guys" behind
this Project service -- just Squid users helping Squid users.

Alex.


From ngtech1ltd at gmail.com  Sat Jan  8 18:23:32 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Sat, 8 Jan 2022 20:23:32 +0200
Subject: [squid-users] RES:  Squid 4.13 does not access Facebook
In-Reply-To: <03e901d8040f$15fb7050$41f250f0$@graminsta.com.br>
References: <03dd01d803fa$599628b0$0cc27a10$@graminsta.com.br>
 <afc35a6e-a2d6-bd82-c258-b4bf707d95ab@riosoft.com.br>
 <03e901d8040f$15fb7050$41f250f0$@graminsta.com.br>
Message-ID: <000501d804bc$d868f6f0$893ae4d0$@gmail.com>

Use Ansible to do it?

 

----

Eliezer Croitoru

Tech Support

Mobile: +972-5-28704261

Email:  <mailto:ngtech1ltd at gmail.com> ngtech1ltd at gmail.com

 

 

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Graminsta
Sent: Friday, January 7, 2022 23:40
To: 'Bruno de Paula Larini' <bruno.larini at riosoft.com.br>; squid-users at lists.squid-cache.org
Subject: [squid-users] RES: Squid 4.13 does not access Facebook

 

I I thought it was filtered by you guys before make it public.
Other sensitive content I sent was erased before it came in this list.

Its to bad.
Now I have to change the pw of about 200 VPSs, hell.

 

Marcelo Rodrigo

 

De: Bruno de Paula Larini [mailto:bruno.larini at riosoft.com.br] 
Enviada em: sexta-feira, 7 de janeiro de 2022 17:13
Para: Graminsta; squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Assunto: Re: [squid-users] Squid 4.13 does not access Facebook

 

This is a public mailing list my friend.
Your IP address and password are available on the internet now.

I recommend you to disable that SSH service.

Take care next time.


Em 07/01/2022 16:11, Graminsta escreveu:

Hello :)

 

I have a specific problem with facebook access in squid 4.13 with Ubuntu 20.

It can access all other IPV6 websites but not https://www.facebook.com. Or any other facebook URL.

 

Outside of squid, the access is working via curl in the same server with the same IPV6 addresses.

It happens with all IPV6 servers I have.

 

 

Please don?t make the following data public from here:

I am a IPV6 proxy provider

You can use the proxy access to test it. Its 181.191.73.174:4000 user hugoebah pw senhabesta11

I will provide you with a SSH access to avoid you all the trouble to you make a lab.

SSH 181.191.73.174 user root pw esqueci11@

I am using this server in my Instagram automation but if you have to reboot it or do testing, you can do it. Its just dummy accounts.

 

Tks a lot ;)

 

Marcelo Rodrigo

Whatsapp 11 9 6854-3878

 

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220108/d36e79af/attachment.htm>

From binoyaf at yahoo.com  Tue Jan 11 05:12:20 2022
From: binoyaf at yahoo.com (Binoy Fernandez)
Date: Tue, 11 Jan 2022 05:12:20 +0000 (UTC)
Subject: [squid-users] IPcache and mixed case domain names
In-Reply-To: <23a589a8-f816-af60-a28d-95bd9585793b@treenet.co.nz>
References: <801995541.1556870.1639587368085.ref@mail.yahoo.com>
 <801995541.1556870.1639587368085@mail.yahoo.com>
 <06518943-ff4f-c285-1d74-8eea4d0de86d@measurement-factory.com>
 <23a589a8-f816-af60-a28d-95bd9585793b@treenet.co.nz>
Message-ID: <1139909476.1272974.1641877940718@mail.yahoo.com>

Amos, Alex, thank you for your inputs. I have logged a bug for this issue -?https://bugs.squid-cache.org/show_bug.cgi?id=5185






On Sunday, December 19, 2021, 12:35:13 AM GMT+5:30, Amos Jeffries <squid3 at treenet.co.nz> wrote: 





On 16/12/21 07:08, Alex Rousskov wrote:
> On 12/15/21 11:56 AM, Binoy Fernandez wrote:
> 
>> Assuming the IPcache at all times contains lower case domain names
>> then I think a change might be needed to the ipcache_get function to
>> lower case
> 
> It sounds like you found a bug.


Indeed. Please report it via <https://bugs.squid-cache.org> so this does 
not get forgotten and the fix can make it to stable releases when 
implemented.


Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From uhlar at fantomas.sk  Tue Jan 11 09:49:48 2022
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 11 Jan 2022 10:49:48 +0100
Subject: [squid-users] Squid 4.13 does not access Facebook
In-Reply-To: <03e901d8040f$15fb7050$41f250f0$@graminsta.com.br>
 <afc35a6e-a2d6-bd82-c258-b4bf707d95ab@riosoft.com.br>
Message-ID: <20220111094948.GD6097@fantomas.sk>

On 07.01.22 17:13, Bruno de Paula Larini wrote:
>This is a public mailing list my friend.
>Your IP address and password are available on the internet now.
>
>I recommend you to disable that SSH service.
>
>Take care next time.

still would be nice from you to remove them from your reply.

On 07.01.22 18:39, Graminsta wrote:
>I I thought it was filtered by you guys before make it public.
>Other sensitive content I sent was erased before it came in this list.
>
>Its to bad.
>Now I have to change the pw of about 200 VPSs, hell.

use ssh key authentication.


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Windows found: (R)emove, (E)rase, (D)elete


From dsanchidrian at 2ingenio.com  Wed Jan 12 10:29:15 2022
From: dsanchidrian at 2ingenio.com (Daniel Sanchidrian)
Date: Wed, 12 Jan 2022 11:29:15 +0100
Subject: [squid-users] transparent or intercept keyword stops the service
Message-ID: <775c47f9-2dac-08c2-8b7c-672290bb9aa3@2ingenio.com>

Hi all!


First of all I'm and new to squid, recently installed it to use in my 
company network. I want to configure it as a transparent proxy. I dive 
into the internet and find many tutorials but I'm facing a problem in 
the configuration file for which I can't find a solution.

The issue is with the keyword */transparent/* or */intercept/* (i have 
3.5.4 version installed). When i use one of them (both throws the same 
error) like:

*/http_port 3128 transparent/*

or

*/http_port 3128 intercept/*

and then reload the configuration with /squid -k reconfigure/ or 
reloading the service, it stops (or didn't reload or didn't restart). 
This is the output of /*systemctl squid status*:/

*/squid.service - Squid caching proxy/**/
/**/???? Loaded: loaded (/usr/lib/systemd/system/squid.service; enabled; 
vendor preset: disabled)/**/
/**/???? Active: failed (Result: exit-code) since Wed 2022-01-12 
10:24:10 CET; 13s ago/**/
/**/?????? Docs: man:squid(8)/**/
/**/??? Process: 1716954 ExecStartPre=/usr/libexec/squid/cache_swap.sh 
(code=exited, status=0/SUCCESS)/**/
/**/??? Process: 1716956 ExecStart=/usr/sbin/squid --foreground 
$SQUID_OPTS -f ${SQUID_CONF} (code=exited, status=1/FAILURE)/**/
/**/??? Process: 1717864 ExecReload=/usr/bin/kill -HUP $MAINPID 
(code=exited, status=0/SUCCESS)/**/
/**/?? Main PID: 1716956 (code=exited, status=1/FAILURE)/**/
/**/??????? CPU: 291ms/*


Thanks in advance for your help,

Regards

-- 
Daniel Sanchidrian Herv?s
Dep. Inform?tica
2io Ingenier?a Avanzda S.L.
910336960

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220112/fc8db408/attachment.htm>

From squid3 at treenet.co.nz  Wed Jan 12 11:52:46 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 13 Jan 2022 00:52:46 +1300
Subject: [squid-users] transparent or intercept keyword stops the service
In-Reply-To: <775c47f9-2dac-08c2-8b7c-672290bb9aa3@2ingenio.com>
References: <775c47f9-2dac-08c2-8b7c-672290bb9aa3@2ingenio.com>
Message-ID: <4c6b1725-16d3-33b2-3dd9-f03eb7330a23@treenet.co.nz>

On 12/01/22 23:29, Daniel Sanchidrian wrote:
> Hi all!
> 
> 
> First of all I'm and new to squid, recently installed it to use in my 
> company network.

Welcome.


> I want to configure it as a transparent proxy. I dive 
> into the internet and find many tutorials but I'm facing a problem in 
> the configuration file for which I can't find a solution.
> 

FYI; The most accurate config examples can be found in our wiki
   <https://wiki.squid-cache.org/ConfigExamples/>


> The issue is with the keyword */transparent/* or */intercept/* (i have 
> 3.5.4 version installed). When i use one of them (both throws the same 
> error) like:
> 
> */http_port 3128 transparent/*
> 

This option is obsolete.

> or
> 
> */http_port 3128 intercept/*
> 

This is the current one for NAT interception.


> and then reload the configuration with /squid -k reconfigure/ or 
> reloading the service, it stops (or didn't reload or didn't restart). 
> This is the output of /*systemctl squid status*:/
> 

Please use "squid -k parse" to test configuration changes. That will 
tell you if there are any major problems and usually what to do about it.

When you get more familiar with Squid there is "squid -k check" to do 
the same tests more quietly, then automatically load the changes into a 
running proxy only if they are successful.


Cheers
Amos


From Antony.Stone at squid.open.source.it  Wed Jan 12 12:05:29 2022
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 12 Jan 2022 13:05:29 +0100
Subject: [squid-users] transparent or intercept keyword stops the service
In-Reply-To: <775c47f9-2dac-08c2-8b7c-672290bb9aa3@2ingenio.com>
References: <775c47f9-2dac-08c2-8b7c-672290bb9aa3@2ingenio.com>
Message-ID: <202201121305.29521.Antony.Stone@squid.open.source.it>

On Wednesday 12 January 2022 at 11:29:15, Daniel Sanchidrian wrote:

> First of all I'm and new to squid, recently installed it to use in my
> company network. I want to configure it as a transparent proxy.

Out of interest - why?

What is your objective here - what are you trying to achieve by setting up an 
intercepting proxy for the company?

I'm just curious as to the use case and what you expect to gain from doing 
this, especially given how the world has gone significantly HTTPS in recent 
years.


Antony.

-- 
All matter in the Universe can be placed into one of two categories:

1. Things which need to be fixed.
2. Things which need to be fixed once you've had a few minutes to play with 
them.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From andre.bolinhas at articatech.com  Thu Jan 13 15:00:22 2022
From: andre.bolinhas at articatech.com (=?iso-8859-1?Q?Andr=E9_Bolinhas?=)
Date: Thu, 13 Jan 2022 15:00:22 -0000
Subject: [squid-users] Tune Squid proxy to handle 90k connection
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>

Hi all,

I would like you help to setup my squid server to handle 90k connection.

1 box, with 128GB ram, 1CPU and 1TB SSD.

My question is:

How many squid process need to run (workers, cpu-affinity) ?

Any special configuration that I need to do in squid configuration file?

Any tunning the I need to perform on kernel, sysctl or proc files?

 

Thanks in advance.

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220113/cbd3dc7c/attachment.htm>

From Loucansky.Lukas at kjj.cz  Thu Jan 13 15:37:39 2022
From: Loucansky.Lukas at kjj.cz (=?windows-1250?B?TG916GFuc2v9IEx1a+Ga?=)
Date: Thu, 13 Jan 2022 16:37:39 +0100
Subject: [squid-users] Significant memory leak with version 5.x (not
 with 4.17)
In-Reply-To: <CACabJxPhjinJfsXccMgrxA+ubSB88wv0OEBHdZFGn-gtcDq=3w@mail.gmail.com>
References: <CACabJxOfSqVkN63DN=N=_J=B7CtH-ahRkFaAtM93H67BpQx9eA@mail.gmail.com>
 <f68674bd-1203-062d-9786-7513554fafb4@measurement-factory.com>
 <CACabJxOTJaKcavxx8AwNoETA6OjsLw0OsdLO=d2M05DpHBstGQ@mail.gmail.com>
 <88e5e3e2-5641-883b-fd8c-cf4c3796ea4a@measurement-factory.com>
 <CACabJxN4Vn5HGnoh4b5wVJQm2wRGeBXSH0gcxPwY37cv1wJPmA@mail.gmail.com>
 <80242ed5-4e35-b2e3-80cb-82b78f4303e1@kjj.cz>
 <CACabJxMO-V86qzg9jk0wV=V=Q+j4Gq+4OehxkZkWV284+XaJkg@mail.gmail.com>
 <c06023d4-c97c-7ae5-037f-f20249f87ca3@treenet.co.nz>
 <cc63af40-3aa5-15ef-30ac-2f929b6def8f@kjj.cz>
 <4a1ae799-2d3b-37c8-8d24-d98f95a424fa@kjj.cz>
 <CACabJxNvqBr1=UswwszfDvBjjrFHTDi87bFDuzTtJ8Tc4OM2RQ@mail.gmail.com>
 <CACabJxMfkCXtRu=mot_48i148AR29XL0oP8s+5fZdpzo49pnjQ@mail.gmail.com>
 <877c1e3f-bd4f-2db2-bb03-49b37d1f0f6b@measurement-factory.com>
 <CACabJxODMUgsN7SA0Y3p-RBrbMaD3uRoHfDJ5Y004WE4PyZOaw@mail.gmail.com>
 <61f6db02-c221-bf64-df6e-18765d888463@measurement-factory.com>
 <CACabJxPhjinJfsXccMgrxA+ubSB88wv0OEBHdZFGn-gtcDq=3w@mail.gm
 ail.com>
Message-ID: <72DD5D5CF661B5459DC08A060BF26B53010897EE@kjj-server.KJJ.local>

Hello,
my squid 5.3 with 957 patch runs for 6 days now - so everything seems ok. 

	Maximum Resident Size: 3798688 KB
Memory accounted for:
	Total accounted:       326687 KB

But - I'd like to ask if I'm doing anything wrong. Am I correct when I think, that patch #957 is not backported/merged to tunnel.cc for v5.3 at the git repo v5 branch? Neither in the squid-5.3-20220112-r8ac83ed55 build avaible at the squid cache web page? But tunnel.cc file in the master (v6) branch is patched? As there is a "small" warning not to use v6 in production - I'd like to ask if is it wise to modify tunnel.cc file like I did it in my current 5.3-20211214-r832aa256c. Or it would be better to switch to git master branch. 

But FYI I had a compilation error due -wshadow option:

XactionRep.cc  -fPIC -DPIC -o .libs/libecapsquid_la-XactionRep.o
XactionRep.cc: In member function ?const libecap::Area Adaptation::Ecap::XactionRep::masterxSharedValue(const libecap::Name&) const?:
XactionRep.cc:174:20: error: declaration of ?String name? shadows a parameter [-Werror=shadow]
             String name, value;
                    ^~~~
XactionRep.cc:166:71: note: shadowed declaration is here
 Adaptation::Ecap::XactionRep::masterxSharedValue(const libecap::Name &name) const
                                                  ~~~~~~~~~~~~~~~~~~~~~^~~~
XactionRep.cc: In member function ?void Adaptation::Ecap::XactionRep::updateHistory(Http::Message*)?:
XactionRep.cc:486:33: error: declaration of ?services? shadows a previous local [-Werror=shadow]
         if (const libecap::Area services = theMaster->option(libecap::metaNextServices)) {
                                 ^~~~~~~~
XactionRep.cc:485:16: note: shadowed declaration is here
         String services;
                ^~~~~~~~
At global scope:
cc1plus: error: unrecognized command line option ?-Wno-unused-private-field? [-Werror]


gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/8/lto-wrapper
OFFLOAD_TARGET_NAMES=nvptx-none
OFFLOAD_TARGET_DEFAULT=1
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Debian 8.3.0-6' --with-bugurl=file:///usr/share/doc/gcc-8/README.Bugs --enable-languages=c,ada,c++,go,brig,d,fortran,objc,obj-c++ --prefix=/usr --with-gcc-major-version-only --program-suffix=-8 --program-prefix=x86_64-linux-gnu- --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --enable-bootstrap --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --enable-default-pie --with-system-zlib --with-target-system-zlib --enable-objc-gc=auto --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-offload-targets=nvptx-none --without-cuda-driver --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 8.3.0 (Debian 8.3.0-6)

Description:    Debian GNU/Linux 10 (buster)

I have noticed differences in the configure.ac file between v5 and v6 branches.But the file src/adaptation/ecap/XactionRep.cc is the same. My configure command line is the same for both versions. So I commented out #SQUID_CC_ADD_CXXFLAG_IF_SUPPORTED([-Wshadow]) in the configure.ac and run bootstrap, config, make again.

After that - squid is compiled without any problems:
./squid -v
Squid Cache: Version 6.0.0-VCS
Service Name: squid
v6 master

This binary uses OpenSSL 1.1.1d  10 Sep 2019. For legal restrictions on distribution see https://www.openssl.org/source/license.html

configure options:  '--build=x86_64-linux-gnu' '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc' '--localstatedir=/var' '--libexecdir=/lib/squid5' '--disable-maintainer-mode' '--disable-silent-rules' '--datadir=/usr/share/squid5' '--sysconfdir=/etc/squid5' '--mandir=/usr/share/man' '--enable-build-info=v6 master' '--enable-inline' '--enable-arp-acl' '--disable-wccp' '--disable-wccp2' '--disable-htcp--disable-arch-native' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB' '--enable-auth-digest=file,LDAP' '--enable-auth-negotiate=kerberos,wrapper' '--enable-auth-ntlm=fake,SMB_LM' '--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,time_quota,unix_group,wbinfo_group' '--enable-url-rewrite-helpers=fake' '--enable-security-cert-validators=fake' '--enable-storeid-rewrite-helpers=file' '--enable-eui' '--enable-esi' '--enable-icmp' '--enable-zph-qos' '--enable-ecap' '--enable-snmp' '--disable-ident-lookups' '--disable-translation' '--with-swapdir=/var/spool/squid5' '--with-logdir=/var/log/squid5' '--with-pidfile=/var/run/squid5.pid' '--with-large-files' '--with-default-user=proxy' '--with-openssl' '--with-filedescriptors=8192' '--enable-ssl-crtd' '--enable-security-cert-generators' '--enable-security-cert-validators' '--enable-linux-netfilter' '--enable-stacktraces' 'PKG_CONFIG_PATH=:/usr/local/lib/pkgconfig:/usr/lib64/pkgconfig:/usr/share/pkgconfig' 'CFLAGS=-g -O2 -m64 -fPIE -fstack-protector-strong -Wformat -Werror=format-security -Wall' 'LDFLAGS=-fPIE -pie -Wl,-z,relro -Wl,-z,now' 'CPPFLAGS=-D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -m64 -fPIE -fstack-protector-strong -Wformat -Werror=format-security' 'build_alias=x86_64-linux-gnu'

Sorry for a little thread hijack, but I'd like to confirm that the patch 957 seems to work and ask for advice about v5 brach on the github vs v6/master.

THX
LL


From squid3 at treenet.co.nz  Thu Jan 13 16:26:12 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 14 Jan 2022 05:26:12 +1300
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>
Message-ID: <998139a4-359a-c530-053f-5b96a369d376@treenet.co.nz>

On 14/01/22 04:00, Andr? Bolinhas wrote:
> Hi all,
> 
> I would like you help to setup my squid server to handle 90k connection.
> 
> 1 box, with 128GB ram, 1CPU and 1TB SSD.
> 

Does that means 1 CPU core?
  What speed CPU?


> My question is:
> 
> How many squid process need to run (workers, cpu-affinity) ?
> 
> Any special configuration that I need to do in squid configuration file?
> 

What "mode" of proxy is this Squid operating as?


> Any tunning the I need to perform on kernel, sysctl or proc files?
> 

The number of connections does not matter much unfortunately. What 
matters is how many requests are being made on those connections, and 
how fast they arrive.

90k connections over a day with one request each is trivial. A single 
connection delivering a million requests in one minute is a major 
problem. Your reality will be somewhere in between.

If you are able to gather network statistics to find out the 
request-per-second traffic rates happening in your traffic do that and 
we can use those numbers more helpfully.

If not, then the best thing to do is simply setup Squid how you want to 
use it and see what happens. At the very least it can provide you those 
numbers for fine tuning once it is already operational.

FYI; Tuning is an ongoing process as popularity of websites and the 
technology they are built from changes relatively often. So the "same" 
traffic will change over time and tuning will need irregular updates.


Amos


From andre.bolinhas at articatech.com  Thu Jan 13 16:44:11 2022
From: andre.bolinhas at articatech.com (=?utf-8?Q?Andr=C3=A9_Bolinhas?=)
Date: Thu, 13 Jan 2022 16:44:11 -0000
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <998139a4-359a-c530-053f-5b96a369d376@treenet.co.nz>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>
 <998139a4-359a-c530-053f-5b96a369d376@treenet.co.nz>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABNxsPHehKwSZDzyb36Q4ZsAQAAAAA=@articatech.com>

Hi
~80k request per second  10k users
CPU info:
CPU(s) 16
Threads per code 2
Cores per socket 8
Sockets 1
Inter Xeron Silver 4208  @ 2.10GHz

Squid Mode: Direct mode on port 3128.


-----Mensagem original-----
De: squid-users <squid-users-bounces at lists.squid-cache.org> Em Nome De Amos Jeffries
Enviada: 13 de janeiro de 2022 16:26
Para: squid-users at lists.squid-cache.org
Assunto: Re: [squid-users] Tune Squid proxy to handle 90k connection

On 14/01/22 04:00, Andr? Bolinhas wrote:
> Hi all,
> 
> I would like you help to setup my squid server to handle 90k connection.
> 
> 1 box, with 128GB ram, 1CPU and 1TB SSD.
> 

Does that means 1 CPU core?
  What speed CPU?


> My question is:
> 
> How many squid process need to run (workers, cpu-affinity) ?
> 
> Any special configuration that I need to do in squid configuration file?
> 

What "mode" of proxy is this Squid operating as?


> Any tunning the I need to perform on kernel, sysctl or proc files?
> 

The number of connections does not matter much unfortunately. What matters is how many requests are being made on those connections, and how fast they arrive.

90k connections over a day with one request each is trivial. A single connection delivering a million requests in one minute is a major problem. Your reality will be somewhere in between.

If you are able to gather network statistics to find out the request-per-second traffic rates happening in your traffic do that and we can use those numbers more helpfully.

If not, then the best thing to do is simply setup Squid how you want to use it and see what happens. At the very least it can provide you those numbers for fine tuning once it is already operational.

FYI; Tuning is an ongoing process as popularity of websites and the technology they are built from changes relatively often. So the "same" 
traffic will change over time and tuning will need irregular updates.


Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Thu Jan 13 16:49:29 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 13 Jan 2022 11:49:29 -0500
Subject: [squid-users] Significant memory leak with version 5.x (not
 with 4.17)
In-Reply-To: <72DD5D5CF661B5459DC08A060BF26B53010897EE@kjj-server.KJJ.local>
References: <CACabJxOfSqVkN63DN=N=_J=B7CtH-ahRkFaAtM93H67BpQx9eA@mail.gmail.com>
 <88e5e3e2-5641-883b-fd8c-cf4c3796ea4a@measurement-factory.com>
 <CACabJxN4Vn5HGnoh4b5wVJQm2wRGeBXSH0gcxPwY37cv1wJPmA@mail.gmail.com>
 <80242ed5-4e35-b2e3-80cb-82b78f4303e1@kjj.cz>
 <CACabJxMO-V86qzg9jk0wV=V=Q+j4Gq+4OehxkZkWV284+XaJkg@mail.gmail.com>
 <c06023d4-c97c-7ae5-037f-f20249f87ca3@treenet.co.nz>
 <cc63af40-3aa5-15ef-30ac-2f929b6def8f@kjj.cz>
 <4a1ae799-2d3b-37c8-8d24-d98f95a424fa@kjj.cz>
 <CACabJxNvqBr1=UswwszfDvBjjrFHTDi87bFDuzTtJ8Tc4OM2RQ@mail.gmail.com>
 <CACabJxMfkCXtRu=mot_48i148AR29XL0oP8s+5fZdpzo49pnjQ@mail.gmail.com>
 <877c1e3f-bd4f-2db2-bb03-49b37d1f0f6b@measurement-factory.com>
 <CACabJxODMUgsN7SA0Y3p-RBrbMaD3uRoHfDJ5Y004WE4PyZOaw@mail.gmail.com>
 <61f6db02-c221-bf64-df6e-18765d888463@measurement-factory.com>
 <CACabJxPhjinJfsXccMgrxA+ubSB88wv0OEBHdZFGn-gtcDq=3w@mail.gm ail.com>
 <72DD5D5CF661B5459DC08A060BF26B53010897EE@kjj-server.KJJ.local>
Message-ID: <faf7d318-e411-30af-36a9-0c00ceb27b65@measurement-factory.com>

On 1/13/22 10:37 AM, Lou?ansk? Luk?? wrote:

> I'd like to ask if I'm doing anything wrong. Am I correct when I
> think, that patch #957 is not backported/merged to tunnel.cc for v5.3
> at the git repo v5 branch?

You are correct -- the fix is not in v5 (yet). I cannot speak for Amos,
and the Project does not have a good way to request/track backporting
requests yet, but I bet that #957 fix (or its equivalent) will
eventually be added to v5. Properly evaluating/testing/backporting
changes takes time and effort.


> As there is a "small" warning not to use v6 in production - I'd like
> to ask if is it wise to modify tunnel.cc file like I did it in my
> current 5.3-20211214-r832aa256c. Or it would be better to switch to
> git master branch.

Due to other v5 bugs, it is currently impractical to run unpatched v5 in
many production environments. Many still run v4. Some prefer to risk
patching v5 than to risk running master/v6. Few make the opposite choice
(often because they need a new master/v6-only feature). It is impossible
to give a correct one-size-fits-all advice here: YMMV.


> But FYI I had a compilation error due -wshadow option:
> 
> XactionRep.cc:174:20: error: declaration of ?String name? shadows a parameter [-Werror=shadow]
> XactionRep.cc:486:33: error: declaration of ?services? shadows a previous local [-Werror=shadow]

Fixed at https://github.com/squid-cache/squid/pull/962


HTH,

Alex.


From squid3 at treenet.co.nz  Tue Jan 18 07:51:18 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 18 Jan 2022 20:51:18 +1300
Subject: [squid-users] squid 5.3 frequent crash
In-Reply-To: <0b2da47a-a862-6f25-5a0b-9b2bb881303b@measurement-factory.com>
References: <6742bd06-14b6-c43a-71ff-3bd3ebb5fe44@ckta.by>
 <09f185c0-533a-cafe-4e80-57a644449888@measurement-factory.com>
 <08060bfb-9502-b112-7dfc-666417a75037@treenet.co.nz>
 <0b2da47a-a862-6f25-5a0b-9b2bb881303b@measurement-factory.com>
Message-ID: <07c5174b-ea6f-e5e3-80e3-1f3f4508d16d@treenet.co.nz>

On 8/01/22 05:02, Alex Rousskov wrote:
> On 1/7/22 9:34 AM, Amos Jeffries wrote:
>> On 7/01/22 06:00, Alex Rousskov wrote:
>>> On 1/6/22 6:53 AM, Majed Zouhairy wrote:
>>>> after upgrading today to 5.3 i'm getting:
>>>
>>>> 2022/01/06 14:27:18 kid1| FATAL: check failed: opening()
>>>>  ???? exception location: FwdState.cc(628) noteDestinationsEnd
>>>
>>>> what is the cause?
>>>
>>> This is most likely bug 5055 fixed in August 2021:
>>> https://bugs.squid-cache.org/show_bug.cgi?id=5055
>>>
>>> In many environments, Squid v5 is unusable without that bug fix. I do
>>> not know whether the v5 maintainer plans to officially backport the fix
>>> from master/v6 to v5, but we would be happy to assist with that.
> 
> 
>> The commit message documents that the bug fix is a small part of the
>> changes made.
> 
> I am unable to separate many of the bug fixes from most other changes in
> that commit. I am a fan of surgical fixes, but, sometimes, significant
> code changes are required to address a set of bugs. One could, of
> course, ignore most of the bugs fixed by the official commit and just
> make sure that v5 does not violate the opening() MUST that triggered
> this thread, but I see no point in doing that -- we will end up chasing
> one known bug after another, sometimes in circles, and often via painful
> triage.
> 
> 
>> Others include altering the fundamental AsyncJob API behaviour -
>> affecting every feature in Squid at their most fundamental levels.
> 
> I disagree with the above summary.
> 

This is not an opinion. The patch "part 2" makes logic changes to 
AsyncJob - specifically destructors and swanSong. That touches 
*everything* Squid does. The other parts touch I/O in similarly deep 
ways and we have a history of unexpected weird side effects with I/O 
refactorings.


> 
>> That amount of change is not going into a "stable" release of
>> Squid.
> 
> FWIW, IMHO, Squid v5 is much better with those changes than it is
> without them. Once tested, the changes do not violate any fundamental
> stability principles that I know of. However, I think it is best to let
> the maintainer (i.e. you) make v5 admission decisions. I am just
> providing feedback to facilitate informed decisions.


I do not disagree with the improvement existing. Just that it does not 
fit the criteria for backport into a stable/production release.

I am seriously considering using our exceptional beta release process 
for these changes once v5.4 bug fixes are out.


> 
>> I will consider patches for just the bug 5055 issue though.
> 
> To avoid misunderstanding, (the backport of) the official set of fixes
> is what I am offering for your consideration. If others can address all
> those bugs using smaller patches, great! Otherwise, I recommend
> backporting the comprehensive fix and am happy to assist with that.
> 

I will take you up on this.

FYI; I am clearing the backports queue over the next few days, and again 
just before 1st Feb. With stable v5.4 release scheduled for 6th Feb.

IMO the best code to base your backport PR on would be the v5 HEAD after 
1st Feb when I post the "prep for 5.4" or similar QA for review. With 
intention of a v5.4.1 beta release a few days later on 10th-12th 
containing only the big change.

That gives us 6 weeks for validation before v5.5 release decisions are 
made. I seriously *hope* that is enough testing not to be hit later with 
another one of these.


Amos


From max.toscano at gmail.com  Tue Jan 18 15:02:42 2022
From: max.toscano at gmail.com (Massimiliano Toscano)
Date: Tue, 18 Jan 2022 16:02:42 +0100
Subject: [squid-users] Question about compatibility SQUID 3.5.12 and
 UBUNTU 16.04 or UBUNTU 18.04
In-Reply-To: <CALkXoSzeEKzfOyPQEABR-MOF_-zuyDcjv5Dk=JJatRPF78b-nw@mail.gmail.com>
References: <CALkXoSzeEKzfOyPQEABR-MOF_-zuyDcjv5Dk=JJatRPF78b-nw@mail.gmail.com>
Message-ID: <CALkXoSy=yYiHiNYALjVTWQguSyBtJ=3GjyPrrS+JL5WkW1Vi3Q@mail.gmail.com>

>  Hi ,
>
> i have a Linux UBUNTU 16 to update
>
> and possibly to upgrade and bring to UBUNTU 18.04
>
> root at tortella1:~# cat /etc/issue
> Ubuntu 16.04.4 LTS
>
> root at tortella1:~# squid -v
> Squid Cache: Version 3.5.12
> Service Name: squid
> Ubuntu linux
>
> when we tried the first time SQUID 3.5 doesn't work more.
>
> Could i ask pls, if UBUNTU 18 doesn't work with SQUID 3.5.12 ?
>
> Maybe should i exclude SQUID package fo my upgrade in to UBUNTU 18 ?
>
> and before i have to update other packages of the UBUNTU 16
>
>
> Thanks a lot in advance
>
> Kind Regards
>
> Max
>
> Milan, Italy
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220118/6aa4dec6/attachment.htm>

From rousskov at measurement-factory.com  Tue Jan 18 20:56:23 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 18 Jan 2022 15:56:23 -0500
Subject: [squid-users] squid 5.3 frequent crash
In-Reply-To: <07c5174b-ea6f-e5e3-80e3-1f3f4508d16d@treenet.co.nz>
References: <6742bd06-14b6-c43a-71ff-3bd3ebb5fe44@ckta.by>
 <09f185c0-533a-cafe-4e80-57a644449888@measurement-factory.com>
 <08060bfb-9502-b112-7dfc-666417a75037@treenet.co.nz>
 <0b2da47a-a862-6f25-5a0b-9b2bb881303b@measurement-factory.com>
 <07c5174b-ea6f-e5e3-80e3-1f3f4508d16d@treenet.co.nz>
Message-ID: <d13fc0ef-76ef-5ca7-0693-b0a0bd2161f5@measurement-factory.com>

On 1/18/22 2:51 AM, Amos Jeffries wrote:
> On 8/01/22 05:02, Alex Rousskov wrote:
>> On 1/7/22 9:34 AM, Amos Jeffries wrote:
>>> Others include altering the fundamental AsyncJob API behaviour -
>>> affecting every feature in Squid at their most fundamental levels.

>> I disagree with the above summary.

> This is not an opinion.

It is impossible to tell for sure whether this is an opinion or a fact
because the summary is using undefined terms like "every feature" and
"most fundamental levels". To you, it may sound like a fact. To me, it
sounds like gross exaggeration at best: Clearly, there are Squid
features (for some reasonable definition of a "feature") unaffected by
this change at "most fundamental levels" (for some reasonable definition
of "most fundamental levels").


> The patch "part 2" makes logic changes to
> AsyncJob - specifically destructors and swanSong. That touches
> *everything* Squid does. The other parts touch I/O in similarly deep
> ways and we have a history of unexpected weird side effects with I/O
> refactorings.

I do not think squid-users is the right place to debate complex
development issues. I will just note that the commit in question does
not, IMO, change AsyncJob methods in fundamental ways. It only shrinks
the long-known gray area of what those functions should (not) do. Before
this change, we did not know where certain actions should take place.
Now, we (think we) do, and we have adjusted a few places to follow those
newly discovered rules.

Will this complex change have unexpected side effects? Yes, of course! I
have disclosed that risk when posting the changes. No need to grossly
exaggerate to agree on that point -- nobody is arguing against it.


> I am seriously considering using our exceptional beta release process
> for these changes once v5.4 bug fixes are out.

FWIW, I see no need for a special process here. We have no reasons to
believe that the change is making Squid v5 worse overall. All those who
tested the change in v5 and master reported significant improvement in
Squid stability. Moreover, since the last numbered v5 release was
unstable (for many reasons), the bar for the next numbered v5 release is
pretty low: We are not going from very stable to possibly unstable; we
are going from very unstable to possibly less unstable.

Said that, I am not trying to block the "exceptional beta release
process" you want to use. I am just providing feedback. Most v5 actions
are your call as a v5 maintainer, including special v5.x.y snapshots
that have three numbers instead of the usual two.


> IMO the best code to base your backport PR on would be the v5 HEAD after
> 1st Feb when I post the "prep for 5.4" or similar QA for review.

To avoid misunderstanding, when you have a commit SHA that the backport
should be based on, please let me know that SHA, and I will start
backporting from that point. That commit/SHA does not have to be in the
official branch, of course.


> That gives us 6 weeks for validation before v5.5 release decisions are
> made. I seriously *hope* that is enough testing not to be hit later with
> another one of these.

FWIW, all other factors being equal, I doubt you would see more "beta"
v5 testers than you would see without any special "beta" releases. If
anything, the opposite is probably true. That is one of the several
reasons I do not recommend using special procedures for releasing this
important bug fix in v5. Again, this is your call.


HTH,

Alex.


From squid3 at treenet.co.nz  Wed Jan 19 02:09:17 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 19 Jan 2022 15:09:17 +1300
Subject: [squid-users] Question about compatibility SQUID 3.5.12 and
 UBUNTU 16.04 or UBUNTU 18.04
In-Reply-To: <CALkXoSy=yYiHiNYALjVTWQguSyBtJ=3GjyPrrS+JL5WkW1Vi3Q@mail.gmail.com>
References: <CALkXoSzeEKzfOyPQEABR-MOF_-zuyDcjv5Dk=JJatRPF78b-nw@mail.gmail.com>
 <CALkXoSy=yYiHiNYALjVTWQguSyBtJ=3GjyPrrS+JL5WkW1Vi3Q@mail.gmail.com>
Message-ID: <d42e7ec8-1843-ee39-48a5-0d4cc25884b3@treenet.co.nz>

On 19/01/22 04:02, Massimiliano Toscano wrote:
> 
>      ?Hi ,
> 
>     i have a Linux UBUNTU 16 to update
> 
>     and possibly to upgrade and bring to UBUNTU 18.04
> 
>     root at tortella1:~# cat /etc/issue
>     Ubuntu 16.04.4 LTS
> 
>     root at tortella1:~# squid -v
>     Squid Cache: Version 3.5.12
>     Service Name: squid
>     Ubuntu linux
> 
>     when we tried the first time SQUID 3.5 doesn't work more.
> 
>     Could i ask pls, if UBUNTU 18 doesn't work with SQUID 3.5.12 ?
> 

Major releases of Ubuntu come with entirely different sets of system 
libraries and requirements.

The source code of Squid can usually be said to work for any OS. But the 
compiled binary is specific to that OS version. There is usually a need 
to rebuild if for different OS major versions like Ubuntu 16.04 vs 18.04.


>     Maybe should i exclude SQUID package fo my upgrade in to UBUNTU 18 ?
> 

That depends on why you have been using squid-3.5.12 with Ubuntu 16.04 
which ships squid-3.3.8.

If you simply needed an upgrade and have no special customization. Then 
you should be able to simply install the squid-3.5.26 package from 
Ubuntu 18.04 and stop using the older 3.5.12.

If you have special customization in your Squid build that are not 
included in official Squid. Then you will need to do one of the following:
  * rebuild your 3.5.12 Squid package binaries for the Ubuntu 18.04 
system, or
  * port your customization to the squid-3.5.26 sources provided by 
Ubuntu 18.04.

I advise the later (see below for why). You can find the necessary 
commands on our Debian wiki page 
<https://wiki.squid-cache.org/KnowledgeBase/Debian>. Ubuntu should be 
the same process, except their deb-src URL will be different.


>     and before i have to update other packages of the UBUNTU 16
> 

If your Squid was built as a .deb package and installed you can use 
"aptitude hold X" to prevent upgrades happening for package X. With that 
you can safely use the Ubuntu APT system to upgrade everything unrelated 
to running Squid first. Then build your new .deb package and install it.


If you do have to rebuild from sources. You can prepare your new build 
of Squid. Do test builds before upgrade, upgrade the OS, then re-build 
for the upgraded system.

There are other more complicated methods if neither of those are doable. 
But I shall not go into specifics unless you need them.


HTH
Amos


From hgmi at outlook.com  Thu Jan 20 05:40:28 2022
From: hgmi at outlook.com (Hg Mi)
Date: Thu, 20 Jan 2022 05:40:28 +0000
Subject: [squid-users] How to install squid 5 on ubuntu 18.04
In-Reply-To: <ME3P282MB1617F59BDB1EEB429204AE68D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>
References: <ME3P282MB1617F59BDB1EEB429204AE68D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>
Message-ID: <ME3P282MB1617ECFE537AC599CD3241C9D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>


Dear Support,

As mentioned, is there any method to install the squid 53 on ubuntu using apt?  without compile it.

Thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220120/d94dd857/attachment.htm>

From rafael.akchurin at diladele.com  Thu Jan 20 06:07:04 2022
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 20 Jan 2022 06:07:04 +0000
Subject: [squid-users] How to install squid 5 on ubuntu 18.04
In-Reply-To: <ME3P282MB1617ECFE537AC599CD3241C9D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>
References: <ME3P282MB1617F59BDB1EEB429204AE68D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>
 <ME3P282MB1617ECFE537AC599CD3241C9D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>
Message-ID: <AM8PR04MB774519C3EB6CE8B21784B8648F5A9@AM8PR04MB7745.eurprd04.prod.outlook.com>

Hello Hg,

One way we do it is at https://docs.diladele.com/howtos/build_squid_on_ubuntu_20/repository.html

Best regards,
Rafael

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Hg Mi
Sent: Thursday, January 20, 2022 6:40 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] How to install squid 5 on ubuntu 18.04


Dear Support,

As mentioned, is there any method to install the squid 53 on ubuntu using apt?  without compile it.

Thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220120/77049e13/attachment.htm>

From hgmi at outlook.com  Thu Jan 20 07:04:13 2022
From: hgmi at outlook.com (Hg Mi)
Date: Thu, 20 Jan 2022 07:04:13 +0000
Subject: [squid-users] How to fix the error
 error:transaction-end-before-headers in access log
Message-ID: <ME3P282MB1617D89A730F2A04AB38A4F7D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>

Dear support,

We currently using squid 4.13 on ubuntu 18.04,  the following error generates really frequently in the access.log.

error:transaction-end-before-headers

Is this a bug in squid4?  or it was misconfigured in my environment?

Best regards
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220120/18c825c8/attachment.htm>

From uhlar at fantomas.sk  Thu Jan 20 07:42:43 2022
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 20 Jan 2022 08:42:43 +0100
Subject: [squid-users] How to fix the error
 error:transaction-end-before-headers in access log
In-Reply-To: <ME3P282MB1617D89A730F2A04AB38A4F7D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>
References: <ME3P282MB1617D89A730F2A04AB38A4F7D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>
Message-ID: <20220120074243.GA10312@fantomas.sk>

On 20.01.22 07:04, Hg Mi wrote:
>We currently using squid 4.13 on ubuntu 18.04,  the following error generates really frequently in the access.log.
>
>error:transaction-end-before-headers

it means that either client or server closed connection before 

>Is this a bug in squid4?  or it was misconfigured in my environment?

most likely your environment. don't you have any content filter in front of
your proxy?
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Windows 2000: 640 MB ought to be enough for anybody


From hgmi at outlook.com  Thu Jan 20 08:42:33 2022
From: hgmi at outlook.com (Hg Mi)
Date: Thu, 20 Jan 2022 08:42:33 +0000
Subject: [squid-users] How to fix the error
 error:transaction-end-before-headers in access log
In-Reply-To: <20220120074243.GA10312@fantomas.sk>
References: <ME3P282MB1617D89A730F2A04AB38A4F7D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>
 <20220120074243.GA10312@fantomas.sk>
Message-ID: <ME3P282MB1617428F8B8665E6FCA78287D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>

Hi Fantomas,

There's an L4 load balancer in front of the squid proxy.

Best regards

________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Matus UHLAR - fantomas <uhlar at fantomas.sk>
Sent: Thursday, January 20, 2022 15:42
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] How to fix the error error:transaction-end-before-headers in access log

On 20.01.22 07:04, Hg Mi wrote:
>We currently using squid 4.13 on ubuntu 18.04,  the following error generates really frequently in the access.log.
>
>error:transaction-end-before-headers

it means that either client or server closed connection before

>Is this a bug in squid4?  or it was misconfigured in my environment?

most likely your environment. don't you have any content filter in front of
your proxy?
--
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Windows 2000: 640 MB ought to be enough for anybody
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220120/b0ecd2d4/attachment.htm>

From uhlar at fantomas.sk  Thu Jan 20 08:46:52 2022
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 20 Jan 2022 09:46:52 +0100
Subject: [squid-users] How to fix the error
 error:transaction-end-before-headers in access log
In-Reply-To: <ME3P282MB1617428F8B8665E6FCA78287D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>
References: <ME3P282MB1617D89A730F2A04AB38A4F7D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>
 <20220120074243.GA10312@fantomas.sk>
 <ME3P282MB1617428F8B8665E6FCA78287D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>
Message-ID: <20220120084652.GA11924@fantomas.sk>

On 20.01.22 08:42, Hg Mi wrote:
>There's an L4 load balancer in front of the squid proxy.

if it blocks any connection to the destination site, it's possible that
blocking looks exactly like that.

>On 20.01.22 07:04, Hg Mi wrote:
>>We currently using squid 4.13 on ubuntu 18.04,  the following error generates really frequently in the access.log.
>>
>>error:transaction-end-before-headers
>
>it means that either client or server closed connection before
>
>>Is this a bug in squid4?  or it was misconfigured in my environment?
>
>most likely your environment. don't you have any content filter in front of
>your proxy?


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
My mind is like a steel trap - rusty and illegal in 37 states.


From andre.bolinhas at articatech.com  Thu Jan 20 13:43:31 2022
From: andre.bolinhas at articatech.com (=?iso-8859-1?Q?Andr=E9_Bolinhas?=)
Date: Thu, 20 Jan 2022 13:43:31 -0000
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABtKmQPl2cPSILcdvSaV6u7AQAAAAA=@articatech.com>

Hi

Any update on this please.

 

De: Andr? Bolinhas <andre.bolinhas at articatech.com> 
Enviada: 13 de janeiro de 2022 15:00
Para: squid-users at lists.squid-cache.org
Assunto: Tune Squid proxy to handle 90k connection

 

Hi all,

I would like you help to setup my squid server to handle 90k connection.

1 box, with 128GB ram, 1CPU and 1TB SSD.

My question is:

How many squid process need to run (workers, cpu-affinity) ?

Any special configuration that I need to do in squid configuration file?

Any tunning the I need to perform on kernel, sysctl or proc files?

 

Thanks in advance.

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220120/cd14b932/attachment.htm>

From rousskov at measurement-factory.com  Thu Jan 20 17:39:30 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 20 Jan 2022 12:39:30 -0500
Subject: [squid-users] How to fix the error
 error:transaction-end-before-headers in access log
In-Reply-To: <20220120074243.GA10312@fantomas.sk>
References: <ME3P282MB1617D89A730F2A04AB38A4F7D75A9@ME3P282MB1617.AUSP282.PROD.OUTLOOK.COM>
 <20220120074243.GA10312@fantomas.sk>
Message-ID: <c85a0789-2066-4674-2b80-1f1d2e454e1d@measurement-factory.com>

On 1/20/22 2:42 AM, Matus UHLAR - fantomas wrote:
> On 20.01.22 07:04, Hg Mi wrote:
>> We currently using squid 4.13 on ubuntu 18.04,? the following error
>> generates really frequently in the access.log.
>>
>> error:transaction-end-before-headers
> 
> it means that either client or server closed connection before

In most cases, this means the client opened a TCP connection to a Squid
listening port and then closed it without sending the HTTP headers. To
figure out who is at fault, you need to figure out who is making these
connections to Squid and why they are closing them without sending HTTP
headers (if that is what they are actually doing).

Bugs notwithstanding, server closures should not lead to
transaction-end-before-headers records.

>> Is this a bug in squid4?? or it was misconfigured in my environment?
> 
> most likely your environment. don't you have any content filter in front of
> your proxy?

... or anything that would "probe" or "health check" Squid http_port or
https_port at TCP level.


HTH,

Alex.


From squid3 at treenet.co.nz  Fri Jan 21 16:05:07 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 22 Jan 2022 05:05:07 +1300
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABNxsPHehKwSZDzyb36Q4ZsAQAAAAA=@articatech.com>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>
 <998139a4-359a-c530-053f-5b96a369d376@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABNxsPHehKwSZDzyb36Q4ZsAQAAAAA=@articatech.com>
Message-ID: <438e6a31-1588-5b7d-13eb-8296d792c7d1@treenet.co.nz>

Sorry for the slow reply. Responses inline.


On 14/01/22 05:44, Andr? Bolinhas wrote:
> Hi
> ~80k request per second  10k users


Test this, but you may need a second machine to achieve the full 80k RPS.

Latest Squid do not have any details analysis, but older Squid-3.5 were 
only achieving >15k RPS under lab conditions, more likely expect under 
10k RPS/worker on real traffic.
  That means (IME) this machine is quite likely to hit its capacity 
somewhere under 70k RPS.


> CPU info:
> CPU(s) 16
> Threads per code 2
> Cores per socket 8

With this CPU you will be able to run 7 workers. Setup affinity of one 
core per worker (the "kidN" processes of Squid). Leaving one core to the 
OS and additional processing needs - this matters at peak loading.

CPU "threads" tend not to be useful for Squid. Under high loads Squid 
workers will consume all available cycles on their core, not leaving any 
for the fancy "thread" core sharing features to pretend there is another 
core available. YMMV. One of the tests to try when tuning is to turn off 
the CPU hyperthreading and see what effect it has (if any).


> Sockets 1
> Inter Xeron Silver 4208  @ 2.10GHz
> 

Okay. Doable, but for best performance you want as high GHz rating on 
the cores as your budget can afford. The amount of "lag" Squid adds to 
traffic and RPS performance/parallelism directly correlates with how 
fast the CPU core can run cycles.



HTH
Amos


From andre.bolinhas at articatech.com  Fri Jan 21 16:35:48 2022
From: andre.bolinhas at articatech.com (=?utf-8?Q?Andr=C3=A9_Bolinhas?=)
Date: Fri, 21 Jan 2022 16:35:48 -0000
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <438e6a31-1588-5b7d-13eb-8296d792c7d1@treenet.co.nz>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>
 <998139a4-359a-c530-053f-5b96a369d376@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABNxsPHehKwSZDzyb36Q4ZsAQAAAAA=@articatech.com>
 <438e6a31-1588-5b7d-13eb-8296d792c7d1@treenet.co.nz>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADmeV1yX0SfQK2M6HLGsWqLAQAAAAA=@articatech.com>

Thanks Amos
Yes, you are right, I will put a second box with HaProxy in front to balance the traffic.
About the sockets I can't double it because is a physical machine, do you think disable hyperthreading from bios will help, because we have other services inside the box that works in multi-threading, like unbound DNS?

Just more a few questions:
1? The server have 92Gb of Ram, do you think that is needed that adding swap will help squid performance?
2? Right now we are using squid 4.17 did you recommend upgrade or downgrade to any specific version?
3? We need categorization, for this we are using an external helper to achieve it, do you recommend use this approach with ACL or move to some kind of ufdbguard service?

Best regards
-----Mensagem original-----
De: squid-users <squid-users-bounces at lists.squid-cache.org> Em Nome De Amos Jeffries
Enviada: 21 de janeiro de 2022 16:05
Para: squid-users at lists.squid-cache.org
Assunto: Re: [squid-users] Tune Squid proxy to handle 90k connection

Sorry for the slow reply. Responses inline.


On 14/01/22 05:44, Andr? Bolinhas wrote:
> Hi
> ~80k request per second  10k users


Test this, but you may need a second machine to achieve the full 80k RPS.

Latest Squid do not have any details analysis, but older Squid-3.5 were only achieving >15k RPS under lab conditions, more likely expect under 10k RPS/worker on real traffic.
  That means (IME) this machine is quite likely to hit its capacity somewhere under 70k RPS.


> CPU info:
> CPU(s) 16
> Threads per code 2
> Cores per socket 8

With this CPU you will be able to run 7 workers. Setup affinity of one core per worker (the "kidN" processes of Squid). Leaving one core to the OS and additional processing needs - this matters at peak loading.

CPU "threads" tend not to be useful for Squid. Under high loads Squid workers will consume all available cycles on their core, not leaving any for the fancy "thread" core sharing features to pretend there is another core available. YMMV. One of the tests to try when tuning is to turn off the CPU hyperthreading and see what effect it has (if any).


> Sockets 1
> Inter Xeron Silver 4208  @ 2.10GHz
> 

Okay. Doable, but for best performance you want as high GHz rating on the cores as your budget can afford. The amount of "lag" Squid adds to traffic and RPS performance/parallelism directly correlates with how fast the CPU core can run cycles.



HTH
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Fri Jan 21 18:09:07 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 22 Jan 2022 07:09:07 +1300
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADmeV1yX0SfQK2M6HLGsWqLAQAAAAA=@articatech.com>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>
 <998139a4-359a-c530-053f-5b96a369d376@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABNxsPHehKwSZDzyb36Q4ZsAQAAAAA=@articatech.com>
 <438e6a31-1588-5b7d-13eb-8296d792c7d1@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADmeV1yX0SfQK2M6HLGsWqLAQAAAAA=@articatech.com>
Message-ID: <7ad2938f-27ce-dcab-4579-1b2c49b814a0@treenet.co.nz>

On 22/01/22 05:35, Andr? Bolinhas wrote:
> Thanks Amos
> Yes, you are right, I will put a second box with HaProxy in front to balance the traffic.
> About the sockets I can't double it because is a physical machine, do you think disable hyperthreading from bios will help, because we have other services inside the box that works in multi-threading, like unbound DNS?

CPU hyperthreading and software multi-threading are different things. 
Software can still perform threading without CPU hyperthreading turned on.

Like I said you will have to test its effect, and other services 
reaction will be one of the things to look at carefully there.


Disclaimer: it has been ~5 years since I last had hands-on with any high 
performance Squid system. Others here are likely to have better 
experience when you come to the actual fine tuning.


> 
> Just more a few questions:
> 1? The server have 92Gb of Ram, do you think that is needed that adding swap will help squid performance?

That should be fine. But YMMV.

Swap is an absolute killer of performance for Squid. Avoid it as much as 
you can.


> 2? Right now we are using squid 4.17 did you recommend upgrade or downgrade to any specific version?

I have not seen any good benchmarking since v3.5 so don't have any 
specific version advice in regards to your install.

I would usually advise the latest supported for new setups. Purely to 
ensure maximum length of support time before upgrade. However, there are 
some issues in v5.3 that make me reluctant to promote it for now.


> 3? We need categorization, for this we are using an external helper to achieve it, do you recommend use this approach with ACL or move to some kind of ufdbguard service?
> 

That depends on what and why your categories are.

External ACL helper is usually best for making access control decisions 
and/or marking traffic on arbitrary (but non-payload) properties.

ufdbguard operates primarily on the URI-rewrite/redirect API so best for 
decisions focused around URI modification.

Both are external processes, taking up cycles for their own use and so 
the performance impact should be similar.



Amos


From toma.leopold at outlook.com  Sun Jan 23 16:10:06 2022
From: toma.leopold at outlook.com (toma leopold)
Date: Sun, 23 Jan 2022 16:10:06 +0000
Subject: [squid-users] tls_key_log Configuration
Message-ID: <AM8PR10MB4050AB55178EF878450A112D945D9@AM8PR10MB4050.EURPRD10.PROD.OUTLOOK.COM>

I know squid 6.0 is not out yet but I wanted to try the tls_key_log feature.

Using:

tls_key_log stdio:/logfile

only works partially.
>From client to proxy only TLS 1.2 is negotiated but I get the secret values and the random number.
For proxy to server connections I get the random number from the proxy in the log but no secrets. TLS 1.3 is used for this connection.
Any ideas what could be the issue? Does the config depend to some extend on configure options before compilation or other squid config options? Is it working generally in squid master?

Regards,
Toma
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220123/b46108c5/attachment.htm>

From rousskov at measurement-factory.com  Sun Jan 23 17:40:11 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 23 Jan 2022 12:40:11 -0500
Subject: [squid-users] tls_key_log Configuration
In-Reply-To: <AM8PR10MB4050AB55178EF878450A112D945D9@AM8PR10MB4050.EURPRD10.PROD.OUTLOOK.COM>
References: <AM8PR10MB4050AB55178EF878450A112D945D9@AM8PR10MB4050.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <b0f9dd53-1da4-9edf-b217-cac03664ec83@measurement-factory.com>

On 1/23/22 11:10 AM, toma leopold wrote:
> I know squid 6.0 is not out yet but I wanted to try the tls_key_log
> feature.?
> 
> Using:
> 
> tls_key_log stdio:/logfile
> 
> only works partially.
> From client to proxy only TLS 1.2 is negotiated but I get the secret
> values and the random number.
> For proxy to server connections I get the random number from the proxy
> in the log but no secrets. TLS 1.3 is used for this connection.
> Any ideas what could be the issue?

Squid does not support logging of TLS v1.3 secrets yet.

When tls_key_log was initially implemented, Squid did not support the
OpenSSL version that could extract TLS v1.3 connection secrets - OpenSSL
v1.1.1. There is even a corresponding TODO in the code: "Support
SSL_CTX_set_keylog_callback() available since OpenSSL v1.1.1".

IIRC, Squid supports that OpenSSL version now. Thus, support for logging
TLS v1.3 connection secrets can and should be added. When deciding on
the tls_key_log output format, we tried to anticipate TLS v1.3 needs, so
I hope that adding that support will not require serious format changes.

This whole issue is complicated by the fact that it would be much easier
to just rely on the new OpenSSL SSL_CTX_set_keylog_callback() API for
_all_ TLS secret extraction, but we cannot do that for as long as we
have to support earlier OpenSSL versions that lack that API. One of the
reasons we did not push for TLS v1.3 logging during the initial
tls_key_log implementation is my hope that (by the time we start working
on that additional support) Squid master/v6 would no longer have to
support earlier OpenSSL versions.


HTH,

Alex.


From ngtech1ltd at gmail.com  Mon Jan 24 07:42:29 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Mon, 24 Jan 2022 09:42:29 +0200
Subject: [squid-users] 4.17 and 5.3 SSL BUMP issue:
 SSL_ERROR_RX_RECORD_TOO_LONG
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAO3UOMecORtCkjs2qj/1mFoBAAAAAA==@gmail.com>

Hey,

I have been testing both Squid 4.17 and 5.3 (yet to test 6.x)

The issue I have seen is pretty annoying operationally.
Other products on the market resolve this issue with couple techniques and I
assume it shouldn't be a problem to configure it.
It's a special case that was raised due to the nature of remote working.
I am connection to couple places with a VPN connection which must force the
remote DNS for couple services.
However, not all the traffic is passed via the VPN connection tunnel.
What happens is that the local proxy with ssl bump is using the local
Recursive DNS server while the PC uses the VPN DNS server.
So, I am trying to access http://www.google.com and boom:
I get SSL errors.
I have tried to understand the issue and took a packet capture:
https://cloud1.ngtech.co.il/squid/1.pcapng

I have also seen the cache and access logs which shows the next:
# cache.log
2022/01/24 09:11:20 kid1| SECURITY ALERT: Host header forgery detected on
local=142.250.179.228:443 remote=10.200.191.171:51831 FD 16 flags=33 (local
IP does not match any domain IP)
2022/01/24 09:11:20 kid1| SECURITY ALERT: on URL: www.google.com:443
2022/01/24 09:11:20 kid1| SECURITY ALERT: Host header forgery detected on
local=142.250.179.228:443 remote=10.200.191.171:51832 FD 16 flags=33 (local
IP does not match any domain IP)
2022/01/24 09:11:20 kid1| SECURITY ALERT: on URL: www.google.com:443
2022/01/24 09:11:20 kid1| SECURITY ALERT: Host header forgery detected on
local=142.250.179.228:443 remote=10.200.191.171:51833 FD 16 flags=33 (local
IP does not match any domain IP)
2022/01/24 09:11:20 kid1| SECURITY ALERT: on URL: www.google.com:443
2022/01/24 09:11:20 kid1| SECURITY ALERT: Host header forgery detected on
local=142.250.179.228:443 remote=10.200.191.171:51834 FD 16 flags=33 (local
IP does not match any domain IP)
2022/01/24 09:11:20 kid1| SECURITY ALERT: on URL: www.google.com:443
2022/01/24 09:11:20 kid1| SECURITY ALERT: Host header forgery detected on
local=142.250.179.228:443 remote=10.200.191.171:51835 FD 16 flags=33 (local
IP does not match any domain IP)
2022/01/24 09:11:20 kid1| SECURITY ALERT: on URL: www.google.com:443
2022/01/24 09:11:20 kid1| SECURITY ALERT: Host header forgery detected on
local=142.250.179.228:443 remote=10.200.191.171:51836 FD 16 flags=33 (local
IP does not match any domain IP)
2022/01/24 09:11:20 kid1| SECURITY ALERT: on URL: www.google.com:443
2022/01/24 09:11:20 kid1| SECURITY ALERT: Host header forgery detected on
local=142.250.179.228:443 remote=10.200.191.171:51837 FD 16 flags=33 (local
IP does not match any domain IP)
2022/01/24 09:11:20 kid1| SECURITY ALERT: on URL: www.google.com:443
2022/01/24 09:11:20 kid1| SECURITY ALERT: Host header forgery detected on
local=142.250.179.228:443 remote=10.200.191.171:51838 FD 16 flags=33 (local
IP does not match any domain IP)
2022/01/24 09:11:20 kid1| SECURITY ALERT: on URL: www.google.com:443
2022/01/24 09:11:20 kid1| SECURITY ALERT: Host header forgery detected on
local=142.250.179.228:443 remote=10.200.191.171:51839 FD 16 flags=33 (local
IP does not match any domain IP)
2022/01/24 09:11:20 kid1| SECURITY ALERT: on URL: www.google.com:443
2022/01/24 09:11:20 kid1| SECURITY ALERT: Host header forgery detected on
local=142.250.179.228:443 remote=10.200.191.171:51840 FD 16 flags=33 (local
IP does not match any domain IP)
2022/01/24 09:11:20 kid1| SECURITY ALERT: on URL: www.google.com:443
2022/01/24 09:11:22 kid1| Error negotiating SSL connection on FD 16:
error:00000001:lib(0):func(0):reason(1) (1/-1)
2022/01/24 09:11:26 kid1| SECURITY ALERT: Host header forgery detected on
local=140.82.112.25:443 remote=10.200.191.171:51842 FD 16 flags=33 (local IP
does not match any domain IP)
2022/01/24 09:11:26 kid1| SECURITY ALERT: on URL: alive.github.com:443
## END

# access.log
1643008592.196      4 10.200.191.171 NONE/200 0 CONNECT 142.250.179.228:443
- HIER_NONE/- - www.google.com splice
1643008592.196      0 10.200.191.171 NONE/409 4077 CONNECT
www.google.com:443 - HIER_NONE/- text/html www.google.com -
1643008592.196      0 10.200.191.171 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- - - -
1643008592.217      5 10.200.191.171 NONE/200 0 CONNECT 142.250.179.228:443
- HIER_NONE/- - www.google.com splice
1643008592.217      0 10.200.191.171 NONE/409 4077 CONNECT
www.google.com:443 - HIER_NONE/- text/html www.google.com -
1643008592.217      0 10.200.191.171 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- - - -
1643008592.232      4 10.200.191.171 NONE/200 0 CONNECT 142.250.179.228:443
- HIER_NONE/- - www.google.com splice
1643008592.233      0 10.200.191.171 NONE/409 4077 CONNECT
www.google.com:443 - HIER_NONE/- text/html www.google.com -
1643008592.233      0 10.200.191.171 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- - - -
1643008592.247      4 10.200.191.171 NONE/200 0 CONNECT 142.250.179.228:443
- HIER_NONE/- - www.google.com splice
1643008592.248      0 10.200.191.171 NONE/409 4077 CONNECT
www.google.com:443 - HIER_NONE/- text/html www.google.com -
1643008592.248      0 10.200.191.171 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- - - -
1643008592.265      5 10.200.191.171 NONE/200 0 CONNECT 142.250.179.228:443
- HIER_NONE/- - www.google.com splice
1643008592.266      0 10.200.191.171 NONE/409 4077 CONNECT
www.google.com:443 - HIER_NONE/- text/html www.google.com -
1643008592.266      0 10.200.191.171 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- - - -
1643008592.276      4 10.200.191.171 NONE/200 0 CONNECT 142.250.179.228:443
- HIER_NONE/- - www.google.com splice
1643008592.276      0 10.200.191.171 NONE/409 4077 CONNECT
www.google.com:443 - HIER_NONE/- text/html www.google.com -
1643008592.276      0 10.200.191.171 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- - - -
1643008592.291      4 10.200.191.171 NONE/200 0 CONNECT 142.250.179.228:443
- HIER_NONE/- - www.google.com splice
1643008592.291      0 10.200.191.171 NONE/409 4077 CONNECT
www.google.com:443 - HIER_NONE/- text/html www.google.com -
1643008592.291      0 10.200.191.171 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- - - -
1643008592.306      4 10.200.191.171 NONE/200 0 CONNECT 142.250.179.228:443
- HIER_NONE/- - www.google.com splice
1643008592.306      0 10.200.191.171 NONE/409 4077 CONNECT
www.google.com:443 - HIER_NONE/- text/html www.google.com -
1643008592.306      0 10.200.191.171 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- - - -
1643008592.320      4 10.200.191.171 NONE/200 0 CONNECT 142.250.179.228:443
- HIER_NONE/- - www.google.com splice
1643008592.320      0 10.200.191.171 NONE/409 4077 CONNECT
www.google.com:443 - HIER_NONE/- text/html www.google.com -
1643008592.320      0 10.200.191.171 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- - - -
1643008592.336      5 10.200.191.171 NONE/200 0 CONNECT 142.250.179.228:443
- HIER_NONE/- - www.google.com splice
1643008592.336      0 10.200.191.171 NONE/409 4077 CONNECT
www.google.com:443 - HIER_NONE/- text/html www.google.com -
1643008592.336      0 10.200.191.171 NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- - - -
1643008594.154    145 10.200.191.171 NONE/200 0 CONNECT 104.21.81.98:443 -
ORIGINAL_DST/104.21.81.98 - www.ruby-forum.com bump
## END

Squid returns the response:
HTTP/1.1 409 Conflict
Server: squid/4.17
Mime-Version: 1.0
Date: Mon, 24 Jan 2022 07:13:00 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3680
X-Squid-Error: ERR_CONFLICT_HOST 0
Vary: Accept-Language
Content-Language: en
X-Cache: MISS from px2-043.ngtech.home
X-Cache-Lookup: NONE from px2-043.ngtech.home:3128
Via: 1.1 px2-043.ngtech.home (squid/4.17)
Connection: close
...

And squid is right indeed.
The local DNS has the next DNS resolution for www.google.com
> www.google.com
Server:  [10.200.191.3]
Address:  10.200.191.3

Non-authoritative answer:
Name:    www.google.com
Addresses:  2a00:1450:4009:80a::2004
          216.58.212.196

While the remote resolution is:
> www.google.com
Server:  DC..XX
Address:  192.168.X.X

Non-authoritative answer:
Name:    www.google.com
Addresses:  2a00:1450:4009:81d::2004
          142.250.179.228

So yes, it's a different IP then expected however squid should have the
option(to my understanding) to handle such cases.
Maybe disable caching or anything else.

The whole server config ie: /etc/squid is at:
http://cloud1.ngtech.co.il/squid/support-save-2022-01-24_09:31:10.tar.gz

I have created a setup which uses mysql to store and dump specific acls
files.
It has a nice Makefile with support-save option which dumps many details on
the machine including the HW and OS most relevant details.
I have tried to patch squid to "fix" the issue but didn't had enough time to
resolve it.
I hope it will help to add the ability to handle this situation (which in
the past I haven't seen the real need for a solution and I was wrong).

If any details are missing let me know.
I am pretty sure that there is an open bug for this issue and I am more then
welcome to get a redirection towards it with a link.

Thanks,

----
Eliezer Croitoru
Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com




From rousskov at measurement-factory.com  Mon Jan 24 14:54:13 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 24 Jan 2022 09:54:13 -0500
Subject: [squid-users] 4.17 and 5.3 SSL BUMP issue:
 SSL_ERROR_RX_RECORD_TOO_LONG
In-Reply-To: <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAO3UOMecORtCkjs2qj/1mFoBAAAAAA==@gmail.com>
References: <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAO3UOMecORtCkjs2qj/1mFoBAAAAAA==@gmail.com>
Message-ID: <1ad648ca-ccbf-a1c5-e209-02f520d4c1cd@measurement-factory.com>

On 1/24/22 2:42 AM, Eliezer Croitoru wrote:
> 2022/01/24 09:11:20 kid1| SECURITY ALERT: Host header forgery detected on
> local=142.250.179.228:443 remote=10.200.191.171:51831 FD 16 flags=33 (local
> IP does not match any domain IP)

As you know, Squid improvements related to these messages have been
discussed many times. I bet the ideas summarized in the following old
email remain valid today:

http://lists.squid-cache.org/pipermail/squid-users/2019-July/020764.html


If you would like to address browser's SSL_ERROR_RX_RECORD_TOO_LONG
specifically (the error in your email Subject line), then that is a
somewhat different matter: According to your packet capture, Squid sends
a plain text HTTP 409 response to a TLS client. That is not going to
work with popular browsers (for various technical and policy reasons).

Depending on the SslBump stage where the Host header forgery was
detected, Squid could bump the client connection to deliver that error
response; in that case, the browser may still refuse to show the
response to the user because the browser will not trust the certificate
that Squid would have to fake without sufficient origin server info.
However, the browser error will be different and arguably less confusing
to admins and even users.

https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F


HTH,

Alex.



From ngtech1ltd at gmail.com  Mon Jan 24 18:06:28 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Mon, 24 Jan 2022 20:06:28 +0200
Subject: [squid-users] 4.17 and 5.3 SSL BUMP issue:
 SSL_ERROR_RX_RECORD_TOO_LONG
In-Reply-To: <1ad648ca-ccbf-a1c5-e209-02f520d4c1cd@measurement-factory.com>
References: <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAO3UOMecORtCkjs2qj/1mFoBAAAAAA==@gmail.com>
 <1ad648ca-ccbf-a1c5-e209-02f520d4c1cd@measurement-factory.com>
Message-ID: <002401d8114d$1cb7ef40$5627cdc0$@gmail.com>

I sat for a while thinking what is the best approach to the subject and the
next patch seems to be reasonable enough to me:
https://gist.github.com/elico/630fa57d161b0c0b59ef68786d801589

Let me know if this patch violates anything that I might not took into
account.

Thanks,
Eliezer

* Tested to work in my specific scenario which I really don't care about
caching when I'm in a DOS situation.

----
Eliezer Croitoru
Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
Alex Rousskov
Sent: Monday, January 24, 2022 16:54
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] 4.17 and 5.3 SSL BUMP issue:
SSL_ERROR_RX_RECORD_TOO_LONG

On 1/24/22 2:42 AM, Eliezer Croitoru wrote:
> 2022/01/24 09:11:20 kid1| SECURITY ALERT: Host header forgery detected on
> local=142.250.179.228:443 remote=10.200.191.171:51831 FD 16 flags=33
(local
> IP does not match any domain IP)

As you know, Squid improvements related to these messages have been
discussed many times. I bet the ideas summarized in the following old
email remain valid today:

http://lists.squid-cache.org/pipermail/squid-users/2019-July/020764.html


If you would like to address browser's SSL_ERROR_RX_RECORD_TOO_LONG
specifically (the error in your email Subject line), then that is a
somewhat different matter: According to your packet capture, Squid sends
a plain text HTTP 409 response to a TLS client. That is not going to
work with popular browsers (for various technical and policy reasons).

Depending on the SslBump stage where the Host header forgery was
detected, Squid could bump the client connection to deliver that error
response; in that case, the browser may still refuse to show the
response to the user because the browser will not trust the certificate
that Squid would have to fake without sufficient origin server info.
However, the browser error will be different and arguably less confusing
to admins and even users.

https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feat
ure.2C_enhance.2C_of_fix_something.3F


HTH,

Alex.

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Mon Jan 24 19:53:57 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 24 Jan 2022 14:53:57 -0500
Subject: [squid-users] 4.17 and 5.3 SSL BUMP issue:
 SSL_ERROR_RX_RECORD_TOO_LONG
In-Reply-To: <002401d8114d$1cb7ef40$5627cdc0$@gmail.com>
References: <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAO3UOMecORtCkjs2qj/1mFoBAAAAAA==@gmail.com>
 <1ad648ca-ccbf-a1c5-e209-02f520d4c1cd@measurement-factory.com>
 <002401d8114d$1cb7ef40$5627cdc0$@gmail.com>
Message-ID: <eca4aa31-238e-0d7f-b36c-021cd7629696@measurement-factory.com>

On 1/24/22 1:06 PM, Eliezer Croitoru wrote:
> I sat for a while thinking what is the best approach to the subject and the
> next patch seems to be reasonable enough to me:
> https://gist.github.com/elico/630fa57d161b0c0b59ef68786d801589

> Let me know if this patch violates anything that I might not took into
> account.

The squid-users mailing list is not a good place for code reviews. If
you think your changes should be made official, please submit a pull
request on GitHub: https://wiki.squid-cache.org/MergeProcedure

FWIW, I wonder whether we should reuse and/or extend host_verify_strict
instead of adding a new squid.conf directive to control this behavior.
All other factors being equal, it would be good to have one directive to
control Host validation and its direct effects.


> * Tested to work in my specific scenario which I really don't care about
> caching when I'm in a DOS situation.

When one disables checks, Squid will continue to "work", of course. Did
you verify that the patched Squid:

1. Goes to the intended destination IP address rather than to Host?
2. Does not evict the matching cached responses from the cache?
3. Does not satisfy the forged request from the cache?
4. Does not share responses to requests with the "forged" Host?

There may be other prerequisites, and the above four may need polishing,
but these are the first conditions that come to my mind when dealing
with forgery attacks. Please disclose this information when/if posting
your changes for the Project review on GitHub.


Thank you,

Alex.

> ----
> Eliezer Croitoru
> Tech Support
> Mobile: +972-5-28704261
> Email: ngtech1ltd at gmail.com
> 
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
> Alex Rousskov
> Sent: Monday, January 24, 2022 16:54
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] 4.17 and 5.3 SSL BUMP issue:
> SSL_ERROR_RX_RECORD_TOO_LONG
> 
> On 1/24/22 2:42 AM, Eliezer Croitoru wrote:
>> 2022/01/24 09:11:20 kid1| SECURITY ALERT: Host header forgery detected on
>> local=142.250.179.228:443 remote=10.200.191.171:51831 FD 16 flags=33
> (local
>> IP does not match any domain IP)
> 
> As you know, Squid improvements related to these messages have been
> discussed many times. I bet the ideas summarized in the following old
> email remain valid today:
> 
> http://lists.squid-cache.org/pipermail/squid-users/2019-July/020764.html
> 
> 
> If you would like to address browser's SSL_ERROR_RX_RECORD_TOO_LONG
> specifically (the error in your email Subject line), then that is a
> somewhat different matter: According to your packet capture, Squid sends
> a plain text HTTP 409 response to a TLS client. That is not going to
> work with popular browsers (for various technical and policy reasons).
> 
> Depending on the SslBump stage where the Host header forgery was
> detected, Squid could bump the client connection to deliver that error
> response; in that case, the browser may still refuse to show the
> response to the user because the browser will not trust the certificate
> that Squid would have to fake without sufficient origin server info.
> However, the browser error will be different and arguably less confusing
> to admins and even users.
> 
> https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feat
> ure.2C_enhance.2C_of_fix_something.3F
> 
> 
> HTH,
> 
> Alex.
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From pponakanti at roblox.com  Tue Jan 25 00:24:05 2022
From: pponakanti at roblox.com (Praveen Ponakanti)
Date: Mon, 24 Jan 2022 16:24:05 -0800
Subject: [squid-users] Reverse DNS lookups from squid logging port
Message-ID: <CACabJxODWXv5V99S505uoxPjO32HBjBayF21UzSpSi8LqkQ04w@mail.gmail.com>

Hi,

I am running squid version 4.17 and have not been able to disable the
reverse DNS lookups it does on each client's IP address. Found the thread
below that discusses this; I have attempted adding the following config
knobs, but it still does not disable the reverse lookups. I do not have any
logformat containing ">A" or "<A".

store_id_extras "%>a %un %>rm myip=%la myport=%lp"
url_rewrite_extras "%>a %un %>rm myip=%la myport=%lp"

http://lists.squid-cache.org/pipermail/squid-users/2016-February/009109.html

The proposed solution seems to be to change the following lines and
recompile. If this is still the recommended fix, can it be upstreamed in an
upcoming release?

https://github.com/squid-cache/squid/blob/master/src/cf.data.pre#L6042
https://github.com/squid-cache/squid/blob/master/src/cf.data.pre#L6136

Thanks
Praveen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220124/72870b03/attachment.htm>

From rousskov at measurement-factory.com  Tue Jan 25 04:38:05 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 24 Jan 2022 23:38:05 -0500
Subject: [squid-users] Reverse DNS lookups from squid logging port
In-Reply-To: <CACabJxODWXv5V99S505uoxPjO32HBjBayF21UzSpSi8LqkQ04w@mail.gmail.com>
References: <CACabJxODWXv5V99S505uoxPjO32HBjBayF21UzSpSi8LqkQ04w@mail.gmail.com>
Message-ID: <14c42a20-dfd1-55b0-91c3-51c55a6e2769@measurement-factory.com>

On 1/24/22 7:24 PM, Praveen Ponakanti wrote:
> Hi,
> 
> I am running squid version?4.17 and have not been able to disable the
> reverse DNS lookups it does on each client's IP address. Found the
> thread below that discusses this; I have attempted adding the following
> config knobs, but it still does not disable the reverse lookups. I do
> not have any logformat containing ">A" or "<A".?
> 
> store_id_extras "%>a %un %>rm myip=%la myport=%lp"
> url_rewrite_extras "%>a %un %>rm myip=%la myport=%lp"
> 
> http://lists.squid-cache.org/pipermail/squid-users/2016-February/009109.html
> 
> The proposed solution seems to be to change the following lines and
> recompile. If this is still the recommended fix, can it be upstreamed in
> an upcoming release?
> 
> https://github.com/squid-cache/squid/blob/master/src/cf.data.pre#L6042
> https://github.com/squid-cache/squid/blob/master/src/cf.data.pre#L6136

The above change of squid.conf defaults will probably work for you, but
it will also break some deployments affected by this bug because the
current code implicitly relies on those defaults triggering lookups.
Thus, it is probably not the right solution for upstreaming. The PR
mentioned below discusses specifics (see item #1 in the PR description).


The solution proposed for upstreaming is at
https://github.com/squid-cache/squid/pull/912

It does not require changing squid.conf defaults and has no (known to
me) other serious flaws.


HTH,

Alex.


From pponakanti at roblox.com  Tue Jan 25 06:39:01 2022
From: pponakanti at roblox.com (Praveen Ponakanti)
Date: Mon, 24 Jan 2022 22:39:01 -0800
Subject: [squid-users] Reverse DNS lookups from squid logging port
In-Reply-To: <14c42a20-dfd1-55b0-91c3-51c55a6e2769@measurement-factory.com>
References: <CACabJxODWXv5V99S505uoxPjO32HBjBayF21UzSpSi8LqkQ04w@mail.gmail.com>
 <14c42a20-dfd1-55b0-91c3-51c55a6e2769@measurement-factory.com>
Message-ID: <CACabJxPUTLuy9WD8Ggc78rkE0Hdd1zSFY5TTE90-YjMkjaVk-Q@mail.gmail.com>

Thanks Alex. I will try out the change with the config defaults in
cd.data.pre in a test env for now and wait for the PR with the fix to be
upstreamed.
Praveen

On Mon, Jan 24, 2022 at 8:38 PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 1/24/22 7:24 PM, Praveen Ponakanti wrote:
> > Hi,
> >
> > I am running squid version 4.17 and have not been able to disable the
> > reverse DNS lookups it does on each client's IP address. Found the
> > thread below that discusses this; I have attempted adding the following
> > config knobs, but it still does not disable the reverse lookups. I do
> > not have any logformat containing ">A" or "<A".
> >
> > store_id_extras "%>a %un %>rm myip=%la myport=%lp"
> > url_rewrite_extras "%>a %un %>rm myip=%la myport=%lp"
> >
> >
> http://lists.squid-cache.org/pipermail/squid-users/2016-February/009109.html
> >
> > The proposed solution seems to be to change the following lines and
> > recompile. If this is still the recommended fix, can it be upstreamed in
> > an upcoming release?
> >
> > https://github.com/squid-cache/squid/blob/master/src/cf.data.pre#L6042
> > https://github.com/squid-cache/squid/blob/master/src/cf.data.pre#L6136
>
> The above change of squid.conf defaults will probably work for you, but
> it will also break some deployments affected by this bug because the
> current code implicitly relies on those defaults triggering lookups.
> Thus, it is probably not the right solution for upstreaming. The PR
> mentioned below discusses specifics (see item #1 in the PR description).
>
>
> The solution proposed for upstreaming is at
> https://github.com/squid-cache/squid/pull/912
>
> It does not require changing squid.conf defaults and has no (known to
> me) other serious flaws.
>
>
> HTH,
>
> Alex.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220124/83ea616b/attachment.htm>

From squid3 at treenet.co.nz  Tue Jan 25 09:25:37 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 25 Jan 2022 22:25:37 +1300
Subject: [squid-users] Reverse DNS lookups from squid logging port
In-Reply-To: <14c42a20-dfd1-55b0-91c3-51c55a6e2769@measurement-factory.com>
References: <CACabJxODWXv5V99S505uoxPjO32HBjBayF21UzSpSi8LqkQ04w@mail.gmail.com>
 <14c42a20-dfd1-55b0-91c3-51c55a6e2769@measurement-factory.com>
Message-ID: <6543c10e-17d2-042c-cefb-b8084b09d189@treenet.co.nz>

On 25/01/22 17:38, Alex Rousskov wrote:
> On 1/24/22 7:24 PM, Praveen Ponakanti wrote:
>> The proposed solution seems to be to change the following lines and
>> recompile. If this is still the recommended fix, can it be upstreamed in
>> an upcoming release?
>>
>> https://github.com/squid-cache/squid/blob/master/src/cf.data.pre#L6042
>> https://github.com/squid-cache/squid/blob/master/src/cf.data.pre#L6136
> 
> The above change of squid.conf defaults will probably work for you, but
> it will also break some deployments affected by this bug because the
> current code implicitly relies on those defaults triggering lookups.
> Thus, it is probably not the right solution for upstreaming. The PR
> mentioned below discusses specifics (see item #1 in the PR description).
> 

Alex: FWIW; the above breakage is the same reason for my remaining 
objection to PR #912.


Amos


From Ralf.Hildebrandt at charite.de  Tue Jan 25 12:31:22 2022
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 25 Jan 2022 13:31:22 +0100
Subject: [squid-users] Absolute upper limit for filedescriptors in squid-6?
Message-ID: <Ye/tmgpKefCkWXE1@charite.de>

What is the absolute upper limit for filedescriptor in squid-6?
Am I limited to 64k dues to use of select(), or are larger numbers
possible?

--
Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From rousskov at measurement-factory.com  Tue Jan 25 14:14:15 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 25 Jan 2022 09:14:15 -0500
Subject: [squid-users] Reverse DNS lookups from squid logging port
In-Reply-To: <6543c10e-17d2-042c-cefb-b8084b09d189@treenet.co.nz>
References: <CACabJxODWXv5V99S505uoxPjO32HBjBayF21UzSpSi8LqkQ04w@mail.gmail.com>
 <14c42a20-dfd1-55b0-91c3-51c55a6e2769@measurement-factory.com>
 <6543c10e-17d2-042c-cefb-b8084b09d189@treenet.co.nz>
Message-ID: <b9f0f771-11d2-fcda-b17e-49743f14c7c4@measurement-factory.com>

On 1/25/22 4:25 AM, Amos Jeffries wrote:
> On 25/01/22 17:38, Alex Rousskov wrote:
>> On 1/24/22 7:24 PM, Praveen Ponakanti wrote:
>>> The proposed solution seems to be to change the following lines and
>>> recompile. If this is still the recommended fix, can it be upstreamed in
>>> an upcoming release?
>>>
>>> https://github.com/squid-cache/squid/blob/master/src/cf.data.pre#L6042
>>> https://github.com/squid-cache/squid/blob/master/src/cf.data.pre#L6136
>>
>> The above change of squid.conf defaults will probably work for you, but
>> it will also break some deployments affected by this bug because the
>> current code implicitly relies on those defaults triggering lookups.
>> Thus, it is probably not the right solution for upstreaming. The PR
>> mentioned below discusses specifics (see item #1 in the PR description).
>>
> 
> Alex: FWIW; the above breakage is the same reason for my remaining
> objection to PR #912.

FWIW, PR 912 does not contain the above breakage: PR code does not rely
on %>A in squid.conf defaults to trigger lookups.

This mailing list is not the right place to discuss technical details,
but the PR relies on a getLogClientFqdn() call to trigger lookups. That
approach works well enough for all known %>A use cases, including ICAP
code described in item #1 mentioned above.

Alex.


From gkinkie at gmail.com  Tue Jan 25 14:32:27 2022
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Tue, 25 Jan 2022 14:32:27 +0000
Subject: [squid-users] Absolute upper limit for filedescriptors in
 squid-6?
In-Reply-To: <Ye/tmgpKefCkWXE1@charite.de>
References: <Ye/tmgpKefCkWXE1@charite.de>
Message-ID: <CA+Y8hcPb-5dvucAGCJJLm1hp=_+bLV-_qLjz70kHgc7TJOAfcA@mail.gmail.com>

See configure --max-filedescriptors

It really depends on the OS.
See SQUID_CHECK_MAXFD in
https://github.com/squid-cache/squid/blob/master/acinclude/os-deps.m4#L166

You can see it printed at configure time for your specific OS

On Tue, Jan 25, 2022 at 12:31 PM Ralf Hildebrandt
<Ralf.Hildebrandt at charite.de> wrote:
>
> What is the absolute upper limit for filedescriptor in squid-6?
> Am I limited to 64k dues to use of select(), or are larger numbers
> possible?
>
> --
> Ralf Hildebrandt
> Charit? - Universit?tsmedizin Berlin
> Gesch?ftsbereich IT | Abteilung Netzwerk
>
> Campus Benjamin Franklin (CBF)
> Haus I | 1. OG | Raum 105
> Hindenburgdamm 30 | D-12203 Berlin
>
> Tel. +49 30 450 570 155
> ralf.hildebrandt at charite.de
> https://www.charite.de
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco


From Ralf.Hildebrandt at charite.de  Tue Jan 25 14:55:37 2022
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 25 Jan 2022 15:55:37 +0100
Subject: [squid-users] [ext] Re: Absolute upper limit for
 filedescriptors in squid-6?
In-Reply-To: <CA+Y8hcPb-5dvucAGCJJLm1hp=_+bLV-_qLjz70kHgc7TJOAfcA@mail.gmail.com>
References: <Ye/tmgpKefCkWXE1@charite.de>
 <CA+Y8hcPb-5dvucAGCJJLm1hp=_+bLV-_qLjz70kHgc7TJOAfcA@mail.gmail.com>
Message-ID: <YfAPaR4N1gP9Glya@charite.de>

* Francesco Chemolli <gkinkie at gmail.com>:
> See configure --max-filedescriptors

...
configure: forcing default of 131072 filedescriptors (user-forced)
checking Default FD_SETSIZE value... 1024
checking for getrlimit... yes
checking for setrlimit... yes
checking Maximum number of filedescriptors we can open... 32768
configure: Default number of filedescriptors: 131072
...

Yes, I set "ulimit -n 131072" before running configure

--
Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From andre.bolinhas at articatech.com  Tue Jan 25 16:42:38 2022
From: andre.bolinhas at articatech.com (=?UTF-8?Q?Andr=C3=A9_Bolinhas?=)
Date: Tue, 25 Jan 2022 16:42:38 -0000
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADmeV1yX0SfQK2M6HLGsWqLAQAAAAA=@articatech.com>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>
 <998139a4-359a-c530-053f-5b96a369d376@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABNxsPHehKwSZDzyb36Q4ZsAQAAAAA=@articatech.com>
 <438e6a31-1588-5b7d-13eb-8296d792c7d1@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADmeV1yX0SfQK2M6HLGsWqLAQAAAAA=@articatech.com>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAD3FXIJWgsSQLJz3KxHKB5yAQAAAAA=@articatech.com>

Any tip about my last comment?

-----Mensagem original-----
De: Andr? Bolinhas <andre.bolinhas at articatech.com> 
Enviada: 21 de janeiro de 2022 16:36
Para: 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Assunto: RE: [squid-users] Tune Squid proxy to handle 90k connection

Thanks Amos
Yes, you are right, I will put a second box with HaProxy in front to balance the traffic.
About the sockets I can't double it because is a physical machine, do you think disable hyperthreading from bios will help, because we have other services inside the box that works in multi-threading, like unbound DNS?

Just more a few questions:
1? The server have 92Gb of Ram, do you think that is needed that adding swap will help squid performance?
2? Right now we are using squid 4.17 did you recommend upgrade or downgrade to any specific version?
3? We need categorization, for this we are using an external helper to achieve it, do you recommend use this approach with ACL or move to some kind of ufdbguard service?

Best regards
-----Mensagem original-----
De: squid-users <squid-users-bounces at lists.squid-cache.org> Em Nome De Amos Jeffries
Enviada: 21 de janeiro de 2022 16:05
Para: squid-users at lists.squid-cache.org
Assunto: Re: [squid-users] Tune Squid proxy to handle 90k connection

Sorry for the slow reply. Responses inline.


On 14/01/22 05:44, Andr? Bolinhas wrote:
> Hi
> ~80k request per second  10k users


Test this, but you may need a second machine to achieve the full 80k RPS.

Latest Squid do not have any details analysis, but older Squid-3.5 were only achieving >15k RPS under lab conditions, more likely expect under 10k RPS/worker on real traffic.
  That means (IME) this machine is quite likely to hit its capacity somewhere under 70k RPS.


> CPU info:
> CPU(s) 16
> Threads per code 2
> Cores per socket 8

With this CPU you will be able to run 7 workers. Setup affinity of one core per worker (the "kidN" processes of Squid). Leaving one core to the OS and additional processing needs - this matters at peak loading.

CPU "threads" tend not to be useful for Squid. Under high loads Squid workers will consume all available cycles on their core, not leaving any for the fancy "thread" core sharing features to pretend there is another core available. YMMV. One of the tests to try when tuning is to turn off the CPU hyperthreading and see what effect it has (if any).


> Sockets 1
> Inter Xeron Silver 4208  @ 2.10GHz
>

Okay. Doable, but for best performance you want as high GHz rating on the cores as your budget can afford. The amount of "lag" Squid adds to traffic and RPS performance/parallelism directly correlates with how fast the CPU core can run cycles.



HTH
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From ngtech1ltd at gmail.com  Tue Jan 25 17:12:19 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Tue, 25 Jan 2022 19:12:19 +0200
Subject: [squid-users] The status of AIA ie: TLS code:
 X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY ?
Message-ID: <000001d8120e$b6dabbe0$249033a0$@gmail.com>

Hey,

I have recently seen more then one site that doesn't provide the full CA
bundle chain.
An example:
https://www.ssllabs.com/ssltest/analyze.html?d=www.cloudschool.org
https://www.ssllabs.com/ssltest/analyze.html?d= certificatechain.io 

I wanted to somehow get this issue logged properly.
Currently squid sends the client a customized 503 page and the next line in
cache.log:
2022/01/25 19:01:25 kid1| ERROR: negotiating TLS on FD 26:
error:1416F086:SSL routines:tls_process_server_certificate:certificate
verify failed (1/-1/0)

Were there any improvement in this area in 5.x or 6.x brances?
And also the logging is very uninformative regarding the culprit of the
issue.
I would have expected that the remote host ip:port and sni would be logged
as well in the above mentioned line.

Currently I do not know about a way to identify from the logs these specific
sites.
I was thinking about writing a daemon that will do the trick automatically
for 4.17.
Any ideas about the subject?

Thanks,
Eliezer

----
Eliezer Croitoru
Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com




From squid3 at treenet.co.nz  Tue Jan 25 20:17:20 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Jan 2022 09:17:20 +1300
Subject: [squid-users] [ext] Re: Absolute upper limit for
 filedescriptors in squid-6?
In-Reply-To: <YfAPaR4N1gP9Glya@charite.de>
References: <Ye/tmgpKefCkWXE1@charite.de>
 <CA+Y8hcPb-5dvucAGCJJLm1hp=_+bLV-_qLjz70kHgc7TJOAfcA@mail.gmail.com>
 <YfAPaR4N1gP9Glya@charite.de>
Message-ID: <8f6da3b8-736d-5d5b-5d05-7d492a6c252f@treenet.co.nz>

On 26/01/22 03:55, Ralf Hildebrandt wrote:
> * Francesco Chemolli:
>> See configure --max-filedescriptors
> 
> ...
> configure: forcing default of 131072 filedescriptors (user-forced)
> checking Default FD_SETSIZE value... 1024
> checking for getrlimit... yes
> checking for setrlimit... yes
> checking Maximum number of filedescriptors we can open... 32768
> configure: Default number of filedescriptors: 131072
> ...
> 
> Yes, I set "ulimit -n 131072" before running configure
> 

The ./configure has a 2^15 limit for the _default_ FD number. Runtime 
should allow configuring larger values later (sans bugs).


It also depends on the I/O module selected for runtime. Make sure you 
avoid select(2) and poll(2) for large FD numbers.

  select(2) is limited to 1024.
  poll(2) allows numbers large enough to hit RAM and CPU limits on speed.
  epoll(2) is limited to ~3.5 million.
  kqueue(2) is technically "unlimited" but YMMV regarding bugs etc.


Amos


From andre.bolinhas at articatech.com  Tue Jan 25 23:14:34 2022
From: andre.bolinhas at articatech.com (=?iso-8859-1?Q?Andr=E9_Bolinhas?=)
Date: Tue, 25 Jan 2022 23:14:34 -0000
Subject: [squid-users] [ext] Re: Absolute upper limit for
 filedescriptors in squid-6?
In-Reply-To: <8f6da3b8-736d-5d5b-5d05-7d492a6c252f@treenet.co.nz>
References: <Ye/tmgpKefCkWXE1@charite.de>
 <CA+Y8hcPb-5dvucAGCJJLm1hp=_+bLV-_qLjz70kHgc7TJOAfcA@mail.gmail.com>
 <YfAPaR4N1gP9Glya@charite.de>
 <8f6da3b8-736d-5d5b-5d05-7d492a6c252f@treenet.co.nz>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADBlOEWbBXTSqJUSg07MipBAQAAAAA=@articatech.com>

Hi
I have a question regarding with this topic to, I need about 2M
filedescriptors so my squid is compiled with --enable-poll and
--enable-epoll.
In this case which mechanism Squid will use poll or epoll?
Also, for better performance for large FD, which mechanism did you recommend
poll, epoll or kqueue?
Thanks
Best regards

-----Mensagem original-----
De: squid-users <squid-users-bounces at lists.squid-cache.org> Em Nome De Amos
Jeffries
Enviada: 25 de janeiro de 2022 20:17
Para: squid-users at lists.squid-cache.org
Assunto: Re: [squid-users] [ext] Re: Absolute upper limit for
filedescriptors in squid-6?

On 26/01/22 03:55, Ralf Hildebrandt wrote:
> * Francesco Chemolli:
>> See configure --max-filedescriptors
> 
> ...
> configure: forcing default of 131072 filedescriptors (user-forced) 
> checking Default FD_SETSIZE value... 1024 checking for getrlimit... 
> yes checking for setrlimit... yes checking Maximum number of 
> filedescriptors we can open... 32768
> configure: Default number of filedescriptors: 131072 ...
> 
> Yes, I set "ulimit -n 131072" before running configure
> 

The ./configure has a 2^15 limit for the _default_ FD number. Runtime should
allow configuring larger values later (sans bugs).


It also depends on the I/O module selected for runtime. Make sure you 
avoid select(2) and poll(2) for large FD numbers.

  select(2) is limited to 1024.
  poll(2) allows numbers large enough to hit RAM and CPU limits on speed.
  epoll(2) is limited to ~3.5 million.
  kqueue(2) is technically "unlimited" but YMMV regarding bugs etc.


Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Wed Jan 26 00:06:52 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Jan 2022 13:06:52 +1300
Subject: [squid-users] [ext] Re: Absolute upper limit for
 filedescriptors in squid-6?
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADBlOEWbBXTSqJUSg07MipBAQAAAAA=@articatech.com>
References: <Ye/tmgpKefCkWXE1@charite.de>
 <CA+Y8hcPb-5dvucAGCJJLm1hp=_+bLV-_qLjz70kHgc7TJOAfcA@mail.gmail.com>
 <YfAPaR4N1gP9Glya@charite.de>
 <8f6da3b8-736d-5d5b-5d05-7d492a6c252f@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADBlOEWbBXTSqJUSg07MipBAQAAAAA=@articatech.com>
Message-ID: <b6aa3c4e-1294-751b-d71a-9a73ba5b2879@treenet.co.nz>

On 26/01/22 12:14, Andr? Bolinhas wrote:
> Hi
> I have a question regarding with this topic to, I need about 2M
> filedescriptors so my squid is compiled with --enable-poll and
> --enable-epoll.
> In this case which mechanism Squid will use poll or epoll?


Should be epoll. You can verify with the cachemgr API:

  squidclient mgr:menu | grep comm_incoming

poll(2) has a "comm_poll_incoming" report, and epoll(2) a matching 
"comm_epoll_incoming" report. If you have neither, then your Squid is 
using one of the other modules.


> Also, for better performance for large FD, which mechanism did you recommend
> poll, epoll or kqueue?


Recommended preference order for those is:  epoll, kqueue, poll.

FWIW; with features like this where they are already well-known and 
tested for years the build process and/or squid.conf defaults have 
usually been designed to take care of these decisions automatically.

In this case, at most, you should only need to use ./configure options. 
Squid follow the auto-tools best practice:

  "--enable-foo" *requires* that foo dependencies etc all exist and be 
usable, else configure halts with an error.

  "--disable-foo" forces foo to be omitted from the build.

  not specifying anything will attempt to enable foo as best-effort. But 
with problems it will only log an error and leave 'foo' out of the build.


Cheers
Amos


From andre.bolinhas at articatech.com  Wed Jan 26 00:25:40 2022
From: andre.bolinhas at articatech.com (=?UTF-8?Q?Andr=C3=A9_Bolinhas?=)
Date: Wed, 26 Jan 2022 00:25:40 -0000
Subject: [squid-users] [ext] Re: Absolute upper limit for
 filedescriptors in squid-6?
In-Reply-To: <b6aa3c4e-1294-751b-d71a-9a73ba5b2879@treenet.co.nz>
References: <Ye/tmgpKefCkWXE1@charite.de>
 <CA+Y8hcPb-5dvucAGCJJLm1hp=_+bLV-_qLjz70kHgc7TJOAfcA@mail.gmail.com>
 <YfAPaR4N1gP9Glya@charite.de>
 <8f6da3b8-736d-5d5b-5d05-7d492a6c252f@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADBlOEWbBXTSqJUSg07MipBAQAAAAA=@articatech.com>
 <b6aa3c4e-1294-751b-d71a-9a73ba5b2879@treenet.co.nz>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABiTrkaM2C3TZ1SvnwnqSWrAQAAAAA=@articatech.com>

Thansk Amos,
Is using epoll
root at artica-postfix:~# squidclient -h 127.0.0.1 -p 56500 mgr:menu | grep comm_incoming
stub time| WARNING: BCP 177 violation. Detected non-functional IPv6 loopback.
 comm_epoll_incoming    comm_incoming() stats                   public

-----Mensagem original-----
De: squid-users <squid-users-bounces at lists.squid-cache.org> Em Nome De Amos Jeffries
Enviada: 26 de janeiro de 2022 00:07
Para: squid-users at lists.squid-cache.org
Assunto: Re: [squid-users] [ext] Re: Absolute upper limit for filedescriptors in squid-6?

On 26/01/22 12:14, Andr? Bolinhas wrote:
> Hi
> I have a question regarding with this topic to, I need about 2M 
> filedescriptors so my squid is compiled with --enable-poll and 
> --enable-epoll.
> In this case which mechanism Squid will use poll or epoll?


Should be epoll. You can verify with the cachemgr API:

  squidclient mgr:menu | grep comm_incoming

poll(2) has a "comm_poll_incoming" report, and epoll(2) a matching "comm_epoll_incoming" report. If you have neither, then your Squid is using one of the other modules.


> Also, for better performance for large FD, which mechanism did you 
> recommend poll, epoll or kqueue?


Recommended preference order for those is:  epoll, kqueue, poll.

FWIW; with features like this where they are already well-known and tested for years the build process and/or squid.conf defaults have usually been designed to take care of these decisions automatically.

In this case, at most, you should only need to use ./configure options. 
Squid follow the auto-tools best practice:

  "--enable-foo" *requires* that foo dependencies etc all exist and be usable, else configure halts with an error.

  "--disable-foo" forces foo to be omitted from the build.

  not specifying anything will attempt to enable foo as best-effort. But with problems it will only log an error and leave 'foo' out of the build.


Cheers
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From musamamehboob at gmail.com  Thu Jan 27 03:58:58 2022
From: musamamehboob at gmail.com (Usama Mehboob)
Date: Wed, 26 Jan 2022 22:58:58 -0500
Subject: [squid-users] Getting SSL Connection Reset Randomly but rarely
Message-ID: <CAPjjjyhMtTaW5ObP_C7Qw6iDKGwqVxykByfzV8FaqTZFV6bdpA@mail.gmail.com>

Hi I have squid 3.5 running on amazon linux and it works fine for the most
part but sometime I see the logs of my clients from webapp saying that
connection timeout etc. Upon checking the cache logs, I see these
statements.


2022/01/23 03:10:01| Set Current Directory to /var/spool/squid
2022/01/23 03:10:01| storeDirWriteCleanLogs: Starting...
2022/01/23 03:10:01|   Finished.  Wrote 0 entries.
2022/01/23 03:10:01|   Took 0.00 seconds (  0.00 entries/sec).
2022/01/23 03:10:01| logfileRotate: daemon:/var/log/squid/access.log
2022/01/23 03:10:01| logfileRotate: daemon:/var/log/squid/access.log
2022/01/23 10:45:52| Error negotiating SSL connection on FD 170: (104)
Connection reset by peer
2022/01/23 12:14:07| Error negotiating SSL on FD 139:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2022/01/23 12:14:07| Error negotiating SSL connection on FD 409: (104)
Connection reset by peer
2022/01/25 01:12:04| Error negotiating SSL connection on FD 24: (104)
Connection reset by peer



I am not sure what is causing it, is it because squid is running out of
gas? my instance has 16gb of Ram and 4VCPU. I am using SSL BUMP to use
squid as a transparent proxy within AWS Vpc.

Below is the config file
--------------ConfigFile-----------------------------------------

visible_hostname squid

#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
acl localnet src 172.16.0.0/12 # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines

acl SSL_ports port 443
acl Safe_ports port 80 # http
###acl Safe_ports port 21 # ftp testing after blocking itp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports
#http_access allow CONNECT SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed

# And finally deny all other access to this proxy

# Squid normally listens to port 3128
#http_port 3128
http_port 3129 intercept
https_port 3130 cert=/etc/squid/ssl/squid.pem ssl-bump intercept
http_access allow SSL_ports #-- this allows every https website
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
ssl_bump peek step1 all

# Deny requests to proxy instance metadata
acl instance_metadata dst 169.254.169.254
http_access deny instance_metadata

# Filter HTTP Only requests based on the whitelist
#acl allowed_http_only dstdomain .veevasourcedev.com .google.com .pypi.org .
youtube.com
#acl allowed_http_only dstdomain .amazonaws.com
#acl allowed_http_only dstdomain .veevanetwork.com .veevacrm.com .
veevacrmdi.com .veeva.com .veevavault.com .vaultdev.com .veevacrmqa.com
#acl allowed_http_only dstdomain .documentforce.com  .sforce.com .force.com
.forceusercontent.com .force-user-content.com .lightning.com .salesforce.com
.salesforceliveagent.com .salesforce-communities.com .
salesforce-experience.com .salesforce-hub.com .salesforce-scrt.com .
salesforce-sites.com .site.com .sfdcopens.com .sfdc.sh .trailblazer.me .
trailhead.com .visualforce.com


# Filter HTTPS requests based on the whitelist
acl allowed_https_sites ssl::server_name .pypi.org .pythonhosted.org .
tfhub.dev .gstatic.com .googleapis.com
acl allowed_https_sites ssl::server_name .amazonaws.com
acl allowed_https_sites ssl::server_name .documentforce.com  .sforce.com .
force.com .forceusercontent.com .force-user-content.com .lightning.com .
salesforce.com .salesforceliveagent.com .salesforce-communities.com .
salesforce-experience.com .salesforce-hub.com .salesforce-scrt.com .
salesforce-sites.com .site.com .sfdcopens.com .sfdc.sh .trailblazer.me .
trailhead.com .visualforce.com
ssl_bump peek step2 allowed_https_sites
ssl_bump splice step3 allowed_https_sites
ssl_bump terminate step2 all


connect_timeout 60 minute
read_timeout 60 minute
write_timeout 60 minute
request_timeout 60 minute

## http filtering ###
#http_access allow localnet allowed_http_only
#http_access allow localhost allowed_http_only
http_access allow localnet allowed_https_sites
http_access allow localhost allowed_https_sites
# And finally deny all other access to this proxy
http_access deny all

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/spool/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320
------------------------------------------------------------------------------------
Will appreciate any help, been struggling with it for last week. it is hard
to reproduce and happens randomly and re-running the failed job goes
through to success at times. thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220126/347a9028/attachment.htm>

From rousskov at measurement-factory.com  Thu Jan 27 16:59:30 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 27 Jan 2022 11:59:30 -0500
Subject: [squid-users] [ext] Re: Absolute upper limit for
 filedescriptors in squid-6?
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADBlOEWbBXTSqJUSg07MipBAQAAAAA=@articatech.com>
References: <Ye/tmgpKefCkWXE1@charite.de>
 <CA+Y8hcPb-5dvucAGCJJLm1hp=_+bLV-_qLjz70kHgc7TJOAfcA@mail.gmail.com>
 <YfAPaR4N1gP9Glya@charite.de>
 <8f6da3b8-736d-5d5b-5d05-7d492a6c252f@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADBlOEWbBXTSqJUSg07MipBAQAAAAA=@articatech.com>
Message-ID: <61c8fcc3-5476-9961-e43f-854c759f763a@measurement-factory.com>

On 1/25/22 6:14 PM, Andr? Bolinhas wrote:
> I need about 2M filedescriptors 

File descriptors are local to each Squid process. A single Squid process
(e.g., SMP worker) is unlikely to be able to handle 2 million concurrent
connections or similar resources. Keep that in mind when configuring
Squid and OS.


> so my squid is compiled with --enable-poll and --enable-epoll.
> In this case which mechanism Squid will use poll or epoll?

On Linux, use epoll. In most cases, it will be used by default, but if
you want to be absolutely sure, use --enable-epoll. Do not (explicitly)
enable things you do not need or do not know about, like --enable-poll.


> Also, for better performance for large FD, which mechanism did you recommend
> poll, epoll or kqueue?

On Linux, use epoll. It will be used by default in most Linux cases.


HTH,

Alex.


> -----Mensagem original-----
> De: squid-users <squid-users-bounces at lists.squid-cache.org> Em Nome De Amos
> Jeffries
> Enviada: 25 de janeiro de 2022 20:17
> Para: squid-users at lists.squid-cache.org
> Assunto: Re: [squid-users] [ext] Re: Absolute upper limit for
> filedescriptors in squid-6?
> 
> On 26/01/22 03:55, Ralf Hildebrandt wrote:
>> * Francesco Chemolli:
>>> See configure --max-filedescriptors
>>
>> ...
>> configure: forcing default of 131072 filedescriptors (user-forced) 
>> checking Default FD_SETSIZE value... 1024 checking for getrlimit... 
>> yes checking for setrlimit... yes checking Maximum number of 
>> filedescriptors we can open... 32768
>> configure: Default number of filedescriptors: 131072 ...
>>
>> Yes, I set "ulimit -n 131072" before running configure
>>
> 
> The ./configure has a 2^15 limit for the _default_ FD number. Runtime should
> allow configuring larger values later (sans bugs).
> 
> 
> It also depends on the I/O module selected for runtime. Make sure you 
> avoid select(2) and poll(2) for large FD numbers.
> 
>   select(2) is limited to 1024.
>   poll(2) allows numbers large enough to hit RAM and CPU limits on speed.
>   epoll(2) is limited to ~3.5 million.
>   kqueue(2) is technically "unlimited" but YMMV regarding bugs etc.
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From clark_wfh at hotmail.com  Thu Jan 27 17:32:40 2022
From: clark_wfh at hotmail.com (clark_wfh at hotmail.com)
Date: Thu, 27 Jan 2022 17:32:40 +0000
Subject: [squid-users] Squid and DoT
Message-ID: <SG2PR01MB212881C3AAE9649A1D3A08509E219@SG2PR01MB2128.apcprd01.prod.exchangelabs.com>

Can squid bump TLS connections for DNS over TLS ? I tried TLS interception passively and redirected port 853 to the proxy port. It looks like squid receives the connection but cannot forward it. I think this could be due to lack of headers, at least there was some related error. Should squid work in theory with DoT?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220127/d1f434e2/attachment.htm>

From rousskov at measurement-factory.com  Thu Jan 27 17:51:36 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 27 Jan 2022 12:51:36 -0500
Subject: [squid-users] Squid and DoT
In-Reply-To: <SG2PR01MB212881C3AAE9649A1D3A08509E219@SG2PR01MB2128.apcprd01.prod.exchangelabs.com>
References: <SG2PR01MB212881C3AAE9649A1D3A08509E219@SG2PR01MB2128.apcprd01.prod.exchangelabs.com>
Message-ID: <6be6b48f-9b95-9229-5516-7b4802dc3702@measurement-factory.com>

On 1/27/22 12:32 PM, clark_wfh at hotmail.com wrote:
> Can squid bump TLS connections for DNS over TLS ? I tried TLS
> interception passively and redirected port 853 to the proxy port. It
> looks like squid receives the connection but cannot forward it. I think
> this could be due to lack of headers, at least there was some related
> error. Should squid work in theory with DoT?

When decrypting intercepted TLS, SslBump expects to find HTTP, not DNS
messages. Squid can decrypt DoT but, if you are lucky, will treat what
is inside according to the on_unsupported_protocol settings.

Squid can be enhanced to recognize DNS messages inside DoT connections,
but I doubt it should be.


HTH,

Alex.


From clark_wfh at hotmail.com  Fri Jan 28 13:57:22 2022
From: clark_wfh at hotmail.com (clark_wfh at hotmail.com)
Date: Fri, 28 Jan 2022 13:57:22 +0000
Subject: [squid-users] Per client tls_outgoing_options
Message-ID: <KU1PR01MB211720B59B85CEF8729752869E229@KU1PR01MB2117.apcprd01.prod.exchangelabs.com>

Is there some way to make clients use different outgoing TLS options like ciphers or CA file ?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220128/ac193615/attachment.htm>

From rousskov at measurement-factory.com  Fri Jan 28 14:07:41 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 28 Jan 2022 09:07:41 -0500
Subject: [squid-users] Per client tls_outgoing_options
In-Reply-To: <KU1PR01MB211720B59B85CEF8729752869E229@KU1PR01MB2117.apcprd01.prod.exchangelabs.com>
References: <KU1PR01MB211720B59B85CEF8729752869E229@KU1PR01MB2117.apcprd01.prod.exchangelabs.com>
Message-ID: <5a024e29-1a44-8fc6-bf7e-d6e31bbc3b47@measurement-factory.com>

On 1/28/22 8:57 AM, clark_wfh at hotmail.com wrote:
> Is there some way to make clients use different outgoing TLS options
> like ciphers or CA file ?

The combination of [Squid] "clients" and "outgoing" sounds
self-contradictory, but if you are thinking about from-Squid TLS
connections, then look for tls_outgoing_options.

If you are asking this question in an SslBump context, then please note
that you will have to bump the connection (not splice) at step2 to allow
Squid to honor tls_outgoing_options.

HTH,

Alex.


From rousskov at measurement-factory.com  Fri Jan 28 14:12:33 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 28 Jan 2022 09:12:33 -0500
Subject: [squid-users] Per client tls_outgoing_options
In-Reply-To: <5a024e29-1a44-8fc6-bf7e-d6e31bbc3b47@measurement-factory.com>
References: <KU1PR01MB211720B59B85CEF8729752869E229@KU1PR01MB2117.apcprd01.prod.exchangelabs.com>
 <5a024e29-1a44-8fc6-bf7e-d6e31bbc3b47@measurement-factory.com>
Message-ID: <2299d9b4-cee3-1c4b-ff6d-4069b55fc205@measurement-factory.com>

On 1/28/22 9:07 AM, Alex Rousskov wrote:
> On 1/28/22 8:57 AM, clark_wfh at hotmail.com wrote:
>> Is there some way to make clients use different outgoing TLS options
>> like ciphers or CA file ?
> 
> The combination of [Squid] "clients" and "outgoing" sounds
> self-contradictory, but if you are thinking about from-Squid TLS
> connections, then look for tls_outgoing_options.
> 
> If you are asking this question in an SslBump context, then please note
> that you will have to bump the connection (not splice) at step2 to allow
> Squid to honor tls_outgoing_options.

Sorry, just noticed that you have already mentioned tls_outgoing_options
in the Subject line. That directive does not accept ACLs (yet) so you
cannot customize it on a per-client basis.

If the number of destinations you need this customization for is small,
then you may be able to hack it using cache_peer directives with an
originserver option and custom TLS settings. You can use
cache_peer_access to control which client gets which cache_peer. IIRC,
you can have multiple cache_peers (with different options) that use the
same IP address.


HTH,

Alex.




From david at articatech.com  Mon Jan 31 00:20:49 2022
From: david at articatech.com (David Touzeau)
Date: Mon, 31 Jan 2022 01:20:49 +0100
Subject: [squid-users] squid url_rewrite_program how to return a kind of TCP
 reset
Message-ID: <de6be72f-9ac9-28a0-d1ef-f47aca484ce8@articatech.com>

Hi

I have built my own squid url_rewrite_program

protocol requires answering with

# OK status=301|302 url=
Or
# OK rewrite-url="http://blablaba"

In my case, especially for trackers/ads i would like to say to browsers: 
"Go away !" without need them to redirect.

Sure i can use these methods but...

1) 127.0.0.1 - browser is in charge of getting out
----------------------------------------------------------------
OK status=302 url="http://127.0.0.1" But this ain't clean or polished.


2) 127.0.0.1 - Squid is in charge of getting out
----------------------------------------------------------------
OK rewrite-url="http://127.0.0.1" But this very very ain't clean or 
polished.
Squid claim in logs for an unreachable URL and pollute events


3) Redirect to a dummy page with a deny acl
----------------------------------------------------------------
OK status=302 url="http://dummy.com"
acl dummy dstdomain dummy.com
http_access deny dummy
deny_info TCP_RESET dummy

But it makes 2 connections to the squid for just stopping queries.
It seems not really optimized.

I notice that for several reasons i cannot switch to an external_acl

Is there a way / idea ?


Regards







-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220131/e24beaf6/attachment.htm>

From squid3 at treenet.co.nz  Mon Jan 31 02:52:29 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 31 Jan 2022 15:52:29 +1300
Subject: [squid-users] squid url_rewrite_program how to return a kind of
 TCP reset
In-Reply-To: <de6be72f-9ac9-28a0-d1ef-f47aca484ce8@articatech.com>
References: <de6be72f-9ac9-28a0-d1ef-f47aca484ce8@articatech.com>
Message-ID: <5cf1a9bc-f588-8c07-fefe-5359dda6ffde@treenet.co.nz>

On 31/01/22 13:20, David Touzeau wrote:
> But it makes 2 connections to the squid for just stopping queries.
> It seems not really optimized.
> 

The joys of using URL modification to decide security access.


> I notice that for several reasons i cannot switch to an external_acl
> 

:(


> Is there a way / idea ?
> 

<http://www.squid-cache.org/Doc/config/adapted_http_access/>


Amos


From ngtech1ltd at gmail.com  Mon Jan 31 04:27:34 2022
From: ngtech1ltd at gmail.com (NgTech LTD)
Date: Mon, 31 Jan 2022 06:27:34 +0200
Subject: [squid-users] squid url_rewrite_program how to return a kind of
 TCP reset
In-Reply-To: <de6be72f-9ac9-28a0-d1ef-f47aca484ce8@articatech.com>
References: <de6be72f-9ac9-28a0-d1ef-f47aca484ce8@articatech.com>
Message-ID: <CABA8h=TwEZihPG13TUyOevE0YVHCHU9Ufx+Ptwac1nX6yMaCeA@mail.gmail.com>

You can try to use deny_info with a customized error page template or an
icap service that will respond with a different page.
I think that redirecting to an external website is a good choice.
Many commercial products use this technique.
If you want the traffic of this website to be bypassed from squid you can
also do that with couple iptables lines.

All The Bests,
Eliezer

?????? ??? ??, 31 ????? 2022, 2:21, ??? David Touzeau ?<david at articatech.com
>:

> Hi
>
> I have built my own squid url_rewrite_program
>
> protocol requires answering with
>
> # OK status=301|302 url=
> Or
> # OK rewrite-url="http://blablaba" <http://blablaba>
>
> In my case, especially for trackers/ads i would like to say to browsers:
> "Go away !" without need them to redirect.
>
> Sure i can use these methods but...
>
> 1) 127.0.0.1 - browser is in charge of getting out
> ----------------------------------------------------------------
> OK status=302 url="http://127.0.0.1" <http://127.0.0.1> But this ain't
> clean or polished.
>
>
> 2) 127.0.0.1 - Squid is in charge of getting out
> ----------------------------------------------------------------
> OK rewrite-url="http://127.0.0.1" <http://127.0.0.1> But this very very
> ain't clean or polished.
> Squid claim in logs for an unreachable URL and pollute events
>
>
> 3) Redirect to a dummy page with a deny acl
> ----------------------------------------------------------------
> OK status=302 url="http://dummy.com" <http://dummy.com>
> acl dummy dstdomain dummy.com
> http_access deny dummy
> deny_info TCP_RESET dummy
>
> But it makes 2 connections to the squid for just stopping queries.
> It seems not really optimized.
>
> I notice that for several reasons i cannot switch to an external_acl
>
> Is there a way / idea ?
>
>
> Regards
>
>
>
>
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220131/5c7a6c41/attachment.htm>

From ngtech1ltd at gmail.com  Mon Jan 31 04:34:59 2022
From: ngtech1ltd at gmail.com (NgTech LTD)
Date: Mon, 31 Jan 2022 06:34:59 +0200
Subject: [squid-users] Getting SSL Connection Reset Randomly but rarely
In-Reply-To: <CAPjjjyhMtTaW5ObP_C7Qw6iDKGwqVxykByfzV8FaqTZFV6bdpA@mail.gmail.com>
References: <CAPjjjyhMtTaW5ObP_C7Qw6iDKGwqVxykByfzV8FaqTZFV6bdpA@mail.gmail.com>
Message-ID: <CABA8h=Rm6pqmkSmdbB6B0jXTNmX54HxurJgZNxcDonuMw=3DJQ@mail.gmail.com>

What version of amazon linux are you using? 1 or 2?
2 has support for squid 4.17.
There are couple options regarding these resets and not all of them are
squid side.

Eliezer

?????? ??? ??, 27 ????? 2022, 5:59, ??? Usama Mehboob ?<
musamamehboob at gmail.com>:

> Hi I have squid 3.5 running on amazon linux and it works fine for the most
> part but sometime I see the logs of my clients from webapp saying that
> connection timeout etc. Upon checking the cache logs, I see these
> statements.
>
>
> 2022/01/23 03:10:01| Set Current Directory to /var/spool/squid
> 2022/01/23 03:10:01| storeDirWriteCleanLogs: Starting...
> 2022/01/23 03:10:01|   Finished.  Wrote 0 entries.
> 2022/01/23 03:10:01|   Took 0.00 seconds (  0.00 entries/sec).
> 2022/01/23 03:10:01| logfileRotate: daemon:/var/log/squid/access.log
> 2022/01/23 03:10:01| logfileRotate: daemon:/var/log/squid/access.log
> 2022/01/23 10:45:52| Error negotiating SSL connection on FD 170: (104)
> Connection reset by peer
> 2022/01/23 12:14:07| Error negotiating SSL on FD 139:
> error:00000000:lib(0):func(0):reason(0) (5/-1/104)
> 2022/01/23 12:14:07| Error negotiating SSL connection on FD 409: (104)
> Connection reset by peer
> 2022/01/25 01:12:04| Error negotiating SSL connection on FD 24: (104)
> Connection reset by peer
>
>
>
> I am not sure what is causing it, is it because squid is running out of
> gas? my instance has 16gb of Ram and 4VCPU. I am using SSL BUMP to use
> squid as a transparent proxy within AWS Vpc.
>
> Below is the config file
> --------------ConfigFile-----------------------------------------
>
> visible_hostname squid
>
> #
> # Recommended minimum configuration:
> #
>
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12 # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
> machines
>
> acl SSL_ports port 443
> acl Safe_ports port 80 # http
> ###acl Safe_ports port 21 # ftp testing after blocking itp
> acl Safe_ports port 443 # https
> acl Safe_ports port 70 # gopher
> acl Safe_ports port 210 # wais
> acl Safe_ports port 1025-65535 # unregistered ports
> acl Safe_ports port 280 # http-mgmt
> acl Safe_ports port 488 # gss-http
> acl Safe_ports port 591 # filemaker
> acl Safe_ports port 777 # multiling http
> acl CONNECT method CONNECT
>
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> #http_access allow CONNECT SSL_ports
>
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
>
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
>
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
>
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
>
> # And finally deny all other access to this proxy
>
> # Squid normally listens to port 3128
> #http_port 3128
> http_port 3129 intercept
> https_port 3130 cert=/etc/squid/ssl/squid.pem ssl-bump intercept
> http_access allow SSL_ports #-- this allows every https website
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> ssl_bump peek step1 all
>
> # Deny requests to proxy instance metadata
> acl instance_metadata dst 169.254.169.254
> http_access deny instance_metadata
>
> # Filter HTTP Only requests based on the whitelist
> #acl allowed_http_only dstdomain .veevasourcedev.com .google.com .pypi.org
> .youtube.com
> #acl allowed_http_only dstdomain .amazonaws.com
> #acl allowed_http_only dstdomain .veevanetwork.com .veevacrm.com .
> veevacrmdi.com .veeva.com .veevavault.com .vaultdev.com .veevacrmqa.com
> #acl allowed_http_only dstdomain .documentforce.com  .sforce.com .
> force.com .forceusercontent.com .force-user-content.com .lightning.com .
> salesforce.com .salesforceliveagent.com .salesforce-communities.com .
> salesforce-experience.com .salesforce-hub.com .salesforce-scrt.com .
> salesforce-sites.com .site.com .sfdcopens.com .sfdc.sh .trailblazer.me .
> trailhead.com .visualforce.com
>
>
> # Filter HTTPS requests based on the whitelist
> acl allowed_https_sites ssl::server_name .pypi.org .pythonhosted.org .
> tfhub.dev .gstatic.com .googleapis.com
> acl allowed_https_sites ssl::server_name .amazonaws.com
> acl allowed_https_sites ssl::server_name .documentforce.com  .sforce.com .
> force.com .forceusercontent.com .force-user-content.com .lightning.com .
> salesforce.com .salesforceliveagent.com .salesforce-communities.com .
> salesforce-experience.com .salesforce-hub.com .salesforce-scrt.com .
> salesforce-sites.com .site.com .sfdcopens.com .sfdc.sh .trailblazer.me .
> trailhead.com .visualforce.com
> ssl_bump peek step2 allowed_https_sites
> ssl_bump splice step3 allowed_https_sites
> ssl_bump terminate step2 all
>
>
> connect_timeout 60 minute
> read_timeout 60 minute
> write_timeout 60 minute
> request_timeout 60 minute
>
> ## http filtering ###
> #http_access allow localnet allowed_http_only
> #http_access allow localhost allowed_http_only
> http_access allow localnet allowed_https_sites
> http_access allow localhost allowed_https_sites
> # And finally deny all other access to this proxy
> http_access deny all
>
> # Uncomment and adjust the following to add a disk cache directory.
> #cache_dir ufs /var/spool/squid 100 16 256
>
> # Leave coredumps in the first cache dir
> coredump_dir /var/spool/squid
>
> #
> # Add any of your own refresh_pattern entries above these.
> #
> refresh_pattern ^ftp: 1440 20% 10080
> refresh_pattern ^gopher: 1440 0% 1440
> refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
> refresh_pattern . 0 20% 4320
>
> ------------------------------------------------------------------------------------
> Will appreciate any help, been struggling with it for last week. it is
> hard to reproduce and happens randomly and re-running the failed job goes
> through to success at times. thanks
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220131/d95514e2/attachment.htm>

From ngtech1ltd at gmail.com  Mon Jan 31 04:58:36 2022
From: ngtech1ltd at gmail.com (NgTech LTD)
Date: Mon, 31 Jan 2022 06:58:36 +0200
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAD3FXIJWgsSQLJz3KxHKB5yAQAAAAA=@articatech.com>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>
 <998139a4-359a-c530-053f-5b96a369d376@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABNxsPHehKwSZDzyb36Q4ZsAQAAAAA=@articatech.com>
 <438e6a31-1588-5b7d-13eb-8296d792c7d1@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADmeV1yX0SfQK2M6HLGsWqLAQAAAAA=@articatech.com>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAD3FXIJWgsSQLJz3KxHKB5yAQAAAAA=@articatech.com>
Message-ID: <CABA8h=QBGofnCPuXqd5F_yF_M=mV_G7FVucRtZ7mWJAx_WbiFg@mail.gmail.com>

I would recommend you to start with 0 caching.
However, for choosing the right solution you must give more details.
For example there is an IBM reasearch that prooved that for about 90k
connections you can use vm's ontop of such hardware with apache web server.
If you do have the set of the other requirements from the proxy else then
the 90k requests it would be wise to mention them.

Do you need any specific acls?
Do you need authentication?
etc..

For a simple forward proxy I would suggest to use a simpler solution and if
possible to not log anything as a starter point.
Any local disk i/o will slow down the machine.

About the url categorization, I do not have experience with ufdbguard on
such scale but it would be pretty heavy for any software to handle 90k
rps...
 It's doable to implement such setup but will require testing.
Will you use ssl bump in this setup?

If I will have all the technical and specs/requirements details I might be
able to suggest better then now.
Take into account that each squid worker can handle about 3k rps tops(with
my experience) and it's a juggling between two sides so... 3k is really
3k+3k+external_acls+dns...

I believe that in this case an example of configuration from the squid
developers might be usefull.

Eliezer


?????? ??? ??, 25 ????? 2022, 18:42, ??? Andr? Bolinhas ?<
andre.bolinhas at articatech.com>:

> Any tip about my last comment?
>
> -----Mensagem original-----
> De: Andr? Bolinhas <andre.bolinhas at articatech.com>
> Enviada: 21 de janeiro de 2022 16:36
> Para: 'Amos Jeffries' <squid3 at treenet.co.nz>;
> squid-users at lists.squid-cache.org
> Assunto: RE: [squid-users] Tune Squid proxy to handle 90k connection
>
> Thanks Amos
> Yes, you are right, I will put a second box with HaProxy in front to
> balance the traffic.
> About the sockets I can't double it because is a physical machine, do you
> think disable hyperthreading from bios will help, because we have other
> services inside the box that works in multi-threading, like unbound DNS?
>
> Just more a few questions:
> 1? The server have 92Gb of Ram, do you think that is needed that adding
> swap will help squid performance?
> 2? Right now we are using squid 4.17 did you recommend upgrade or
> downgrade to any specific version?
> 3? We need categorization, for this we are using an external helper to
> achieve it, do you recommend use this approach with ACL or move to some
> kind of ufdbguard service?
>
> Best regards
> -----Mensagem original-----
> De: squid-users <squid-users-bounces at lists.squid-cache.org> Em Nome De
> Amos Jeffries
> Enviada: 21 de janeiro de 2022 16:05
> Para: squid-users at lists.squid-cache.org
> Assunto: Re: [squid-users] Tune Squid proxy to handle 90k connection
>
> Sorry for the slow reply. Responses inline.
>
>
> On 14/01/22 05:44, Andr? Bolinhas wrote:
> > Hi
> > ~80k request per second  10k users
>
>
> Test this, but you may need a second machine to achieve the full 80k RPS.
>
> Latest Squid do not have any details analysis, but older Squid-3.5 were
> only achieving >15k RPS under lab conditions, more likely expect under 10k
> RPS/worker on real traffic.
>   That means (IME) this machine is quite likely to hit its capacity
> somewhere under 70k RPS.
>
>
> > CPU info:
> > CPU(s) 16
> > Threads per code 2
> > Cores per socket 8
>
> With this CPU you will be able to run 7 workers. Setup affinity of one
> core per worker (the "kidN" processes of Squid). Leaving one core to the OS
> and additional processing needs - this matters at peak loading.
>
> CPU "threads" tend not to be useful for Squid. Under high loads Squid
> workers will consume all available cycles on their core, not leaving any
> for the fancy "thread" core sharing features to pretend there is another
> core available. YMMV. One of the tests to try when tuning is to turn off
> the CPU hyperthreading and see what effect it has (if any).
>
>
> > Sockets 1
> > Inter Xeron Silver 4208  @ 2.10GHz
> >
>
> Okay. Doable, but for best performance you want as high GHz rating on the
> cores as your budget can afford. The amount of "lag" Squid adds to traffic
> and RPS performance/parallelism directly correlates with how fast the CPU
> core can run cycles.
>
>
>
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220131/1afac7f9/attachment.htm>

From david at articatech.com  Mon Jan 31 08:53:43 2022
From: david at articatech.com (David Touzeau)
Date: Mon, 31 Jan 2022 09:53:43 +0100
Subject: [squid-users] squid url_rewrite_program how to return a kind of
 TCP reset
In-Reply-To: <5cf1a9bc-f588-8c07-fefe-5359dda6ffde@treenet.co.nz>
References: <de6be72f-9ac9-28a0-d1ef-f47aca484ce8@articatech.com>
 <5cf1a9bc-f588-8c07-fefe-5359dda6ffde@treenet.co.nz>
Message-ID: <6689c956-846a-5452-b931-22abd54712c9@articatech.com>

Is adapted_http_access supporting url_rewrite_program? ? It seems only 
supports ecap/icap

Le 31/01/2022 ? 03:52, Amos Jeffries a ?crit?:
> On 31/01/22 13:20, David Touzeau wrote:
>> But it makes 2 connections to the squid for just stopping queries.
>> It seems not really optimized.
>>
>
> The joys of using URL modification to decide security access.
>
>
>> I notice that for several reasons i cannot switch to an external_acl
>>
>
> :(
>
>
>> Is there a way / idea ?
>>
>
> <http://www.squid-cache.org/Doc/config/adapted_http_access/>
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220131/cc22884a/attachment.htm>

From andre.bolinhas at articatech.com  Mon Jan 31 13:46:51 2022
From: andre.bolinhas at articatech.com (=?UTF-8?Q?Andr=C3=A9_Bolinhas?=)
Date: Mon, 31 Jan 2022 13:46:51 -0000
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <CABA8h=QBGofnCPuXqd5F_yF_M=mV_G7FVucRtZ7mWJAx_WbiFg@mail.gmail.com>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>
 <998139a4-359a-c530-053f-5b96a369d376@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABNxsPHehKwSZDzyb36Q4ZsAQAAAAA=@articatech.com>
 <438e6a31-1588-5b7d-13eb-8296d792c7d1@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADmeV1yX0SfQK2M6HLGsWqLAQAAAAA=@articatech.com>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAD3FXIJWgsSQLJz3KxHKB5yAQAAAAA=@articatech.com>
 <CABA8h=QBGofnCPuXqd5F_yF_M=mV_G7FVucRtZ7mWJAx_WbiFg@mail.gmail.com>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACQee6iB+9UQbA7yyJVYK9FAQAAAAA=@articatech.com>

Hi

I will not use cache in this project.

Yes, I will need

*	ACL (based on Domain, AD user, Headers, User Agent?)
*	Authentication
*	SSL bump just for one domain.
*	DNS resolution (I will use Unbound DNS service for this)

 

Also, I will divide the traffic between two Squid box instead just one.

 

So each box will handle around 50k request.

 

Each box have:

*	CPU(s) 16
*	Threads per code 2
*	Cores per socket 8
*	Sockets 1
*	Inter Xeron Silver 4208  @ 2.10GHz
*	96GB Ram
*	1TB raid-0 SSD

 

At this time I have 5 workers on each Squid box and the Squid version is 4.17, do you recommend more workers or upgrade the squid version to 5?

 

Best regards

 

De: NgTech LTD <ngtech1ltd at gmail.com> 
Enviada: 31 de janeiro de 2022 04:59
Para: Andr? Bolinhas <andre.bolinhas at articatech.com>
Cc: Squid Users <squid-users at lists.squid-cache.org>
Assunto: Re: [squid-users] Tune Squid proxy to handle 90k connection

 

I would recommend you to start with 0 caching.

However, for choosing the right solution you must give more details.

For example there is an IBM reasearch that prooved that for about 90k connections you can use vm's ontop of such hardware with apache web server.

If you do have the set of the other requirements from the proxy else then the 90k requests it would be wise to mention them.

 

Do you need any specific acls?

Do you need authentication?

etc..

 

For a simple forward proxy I would suggest to use a simpler solution and if possible to not log anything as a starter point.

Any local disk i/o will slow down the machine.

 

About the url categorization, I do not have experience with ufdbguard on such scale but it would be pretty heavy for any software to handle 90k rps...

 It's doable to implement such setup but will require testing.

Will you use ssl bump in this setup?

 

If I will have all the technical and specs/requirements details I might be able to suggest better then now.

Take into account that each squid worker can handle about 3k rps tops(with my experience) and it's a juggling between two sides so... 3k is really 3k+3k+external_acls+dns...

 

I believe that in this case an example of configuration from the squid developers might be usefull.

 

Eliezer

 

 

?????? ??? ??, 25 ????? 2022, 18:42, ??? Andr? Bolinhas ?<andre.bolinhas at articatech.com <mailto:andre.bolinhas at articatech.com> >:

Any tip about my last comment?

-----Mensagem original-----
De: Andr? Bolinhas <andre.bolinhas at articatech.com <mailto:andre.bolinhas at articatech.com> > 
Enviada: 21 de janeiro de 2022 16:36
Para: 'Amos Jeffries' <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz> >; squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Assunto: RE: [squid-users] Tune Squid proxy to handle 90k connection

Thanks Amos
Yes, you are right, I will put a second box with HaProxy in front to balance the traffic.
About the sockets I can't double it because is a physical machine, do you think disable hyperthreading from bios will help, because we have other services inside the box that works in multi-threading, like unbound DNS?

Just more a few questions:
1? The server have 92Gb of Ram, do you think that is needed that adding swap will help squid performance?
2? Right now we are using squid 4.17 did you recommend upgrade or downgrade to any specific version?
3? We need categorization, for this we are using an external helper to achieve it, do you recommend use this approach with ACL or move to some kind of ufdbguard service?

Best regards
-----Mensagem original-----
De: squid-users <squid-users-bounces at lists.squid-cache.org <mailto:squid-users-bounces at lists.squid-cache.org> > Em Nome De Amos Jeffries
Enviada: 21 de janeiro de 2022 16:05
Para: squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Assunto: Re: [squid-users] Tune Squid proxy to handle 90k connection

Sorry for the slow reply. Responses inline.


On 14/01/22 05:44, Andr? Bolinhas wrote:
> Hi
> ~80k request per second  10k users


Test this, but you may need a second machine to achieve the full 80k RPS.

Latest Squid do not have any details analysis, but older Squid-3.5 were only achieving >15k RPS under lab conditions, more likely expect under 10k RPS/worker on real traffic.
  That means (IME) this machine is quite likely to hit its capacity somewhere under 70k RPS.


> CPU info:
> CPU(s) 16
> Threads per code 2
> Cores per socket 8

With this CPU you will be able to run 7 workers. Setup affinity of one core per worker (the "kidN" processes of Squid). Leaving one core to the OS and additional processing needs - this matters at peak loading.

CPU "threads" tend not to be useful for Squid. Under high loads Squid workers will consume all available cycles on their core, not leaving any for the fancy "thread" core sharing features to pretend there is another core available. YMMV. One of the tests to try when tuning is to turn off the CPU hyperthreading and see what effect it has (if any).


> Sockets 1
> Inter Xeron Silver 4208  @ 2.10GHz
>

Okay. Doable, but for best performance you want as high GHz rating on the cores as your budget can afford. The amount of "lag" Squid adds to traffic and RPS performance/parallelism directly correlates with how fast the CPU core can run cycles.



HTH
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220131/8886feb3/attachment.htm>

From ngtech1ltd at gmail.com  Mon Jan 31 14:52:30 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Mon, 31 Jan 2022 16:52:30 +0200
Subject: [squid-users] Tune Squid proxy to handle 90k connection
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACQee6iB+9UQbA7yyJVYK9FAQAAAAA=@articatech.com>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAB7SU5pKiptSqMwjCYRtH5DAQAAAAA=@articatech.com>
 <998139a4-359a-c530-053f-5b96a369d376@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABNxsPHehKwSZDzyb36Q4ZsAQAAAAA=@articatech.com>
 <438e6a31-1588-5b7d-13eb-8296d792c7d1@treenet.co.nz>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADmeV1yX0SfQK2M6HLGsWqLAQAAAAA=@articatech.com>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAD3FXIJWgsSQLJz3KxHKB5yAQAAAAA=@articatech.com>
 <CABA8h=QBGofnCPuXqd5F_yF_M=mV_G7FVucRtZ7mWJAx_WbiFg@mail.gmail.com>
 <!&!AAAAAAAAAAAuAAAAAAAAAJJD97gEMN5Ch2HBNn/5W3IBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAACQee6iB+9UQbA7yyJVYK9FAQAAAAA=@articatech.com>
Message-ID: <000901d816b2$2d21cfd0$87656f70$@gmail.com>

Hey Andre,

 

I would not recommend on 5.x yet since there are couple bugs which are blocking it to be used as stable.

I believe that your current setup is pretty good.

The only thing which might affect the system is the authentication and ACLs.

As long these ACL rules are static it should not affect too much on the operation, however,
When adding external authentication and external helpers for other things it?s possible to see some slowdown in specific scenarios.

As long as the credentials and the ACLs will be fast enough it is expected to work fast but only testing will prove how the real world usage
will affect the service.

I believe that 5 workers is enough and also take into account that the external helpers would also require CPU so don?t rush into
changing the workers amount just yet.

 

All The Bests,

Eliezer

 

----

Eliezer Croitoru

NgTech, Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: Andr? Bolinhas <andre.bolinhas at articatech.com> 
Sent: Monday, January 31, 2022 15:47
To: 'NgTech LTD' <ngtech1ltd at gmail.com>
Cc: 'Squid Users' <squid-users at lists.squid-cache.org>
Subject: RE: [squid-users] Tune Squid proxy to handle 90k connection

 

Hi

I will not use cache in this project.

Yes, I will need

*	ACL (based on Domain, AD user, Headers, User Agent?)
*	Authentication
*	SSL bump just for one domain.
*	DNS resolution (I will use Unbound DNS service for this)

 

Also, I will divide the traffic between two Squid box instead just one.

 

So each box will handle around 50k request.

 

Each box have:

*	CPU(s) 16
*	Threads per code 2
*	Cores per socket 8
*	Sockets 1
*	Inter Xeron Silver 4208  @ 2.10GHz
*	96GB Ram
*	1TB raid-0 SSD

 

At this time I have 5 workers on each Squid box and the Squid version is 4.17, do you recommend more workers or upgrade the squid version to 5?

 

Best regards

 

De: NgTech LTD <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Enviada: 31 de janeiro de 2022 04:59
Para: Andr? Bolinhas <andre.bolinhas at articatech.com <mailto:andre.bolinhas at articatech.com> >
Cc: Squid Users <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Assunto: Re: [squid-users] Tune Squid proxy to handle 90k connection

 

I would recommend you to start with 0 caching.

However, for choosing the right solution you must give more details.

For example there is an IBM reasearch that prooved that for about 90k connections you can use vm's ontop of such hardware with apache web server.

If you do have the set of the other requirements from the proxy else then the 90k requests it would be wise to mention them.

 

Do you need any specific acls?

Do you need authentication?

etc..

 

For a simple forward proxy I would suggest to use a simpler solution and if possible to not log anything as a starter point.

Any local disk i/o will slow down the machine.

 

About the url categorization, I do not have experience with ufdbguard on such scale but it would be pretty heavy for any software to handle 90k rps...

 It's doable to implement such setup but will require testing.

Will you use ssl bump in this setup?

 

If I will have all the technical and specs/requirements details I might be able to suggest better then now.

Take into account that each squid worker can handle about 3k rps tops(with my experience) and it's a juggling between two sides so... 3k is really 3k+3k+external_acls+dns...

 

I believe that in this case an example of configuration from the squid developers might be usefull.

 

Eliezer

 

 

?????? ??? ??, 25 ????? 2022, 18:42, ??? Andr? Bolinhas ?<andre.bolinhas at articatech.com <mailto:andre.bolinhas at articatech.com> >:

Any tip about my last comment?

-----Mensagem original-----
De: Andr? Bolinhas <andre.bolinhas at articatech.com <mailto:andre.bolinhas at articatech.com> > 
Enviada: 21 de janeiro de 2022 16:36
Para: 'Amos Jeffries' <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz> >; squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Assunto: RE: [squid-users] Tune Squid proxy to handle 90k connection

Thanks Amos
Yes, you are right, I will put a second box with HaProxy in front to balance the traffic.
About the sockets I can't double it because is a physical machine, do you think disable hyperthreading from bios will help, because we have other services inside the box that works in multi-threading, like unbound DNS?

Just more a few questions:
1? The server have 92Gb of Ram, do you think that is needed that adding swap will help squid performance?
2? Right now we are using squid 4.17 did you recommend upgrade or downgrade to any specific version?
3? We need categorization, for this we are using an external helper to achieve it, do you recommend use this approach with ACL or move to some kind of ufdbguard service?

Best regards
-----Mensagem original-----
De: squid-users <squid-users-bounces at lists.squid-cache.org <mailto:squid-users-bounces at lists.squid-cache.org> > Em Nome De Amos Jeffries
Enviada: 21 de janeiro de 2022 16:05
Para: squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Assunto: Re: [squid-users] Tune Squid proxy to handle 90k connection

Sorry for the slow reply. Responses inline.


On 14/01/22 05:44, Andr? Bolinhas wrote:
> Hi
> ~80k request per second  10k users


Test this, but you may need a second machine to achieve the full 80k RPS.

Latest Squid do not have any details analysis, but older Squid-3.5 were only achieving >15k RPS under lab conditions, more likely expect under 10k RPS/worker on real traffic.
  That means (IME) this machine is quite likely to hit its capacity somewhere under 70k RPS.


> CPU info:
> CPU(s) 16
> Threads per code 2
> Cores per socket 8

With this CPU you will be able to run 7 workers. Setup affinity of one core per worker (the "kidN" processes of Squid). Leaving one core to the OS and additional processing needs - this matters at peak loading.

CPU "threads" tend not to be useful for Squid. Under high loads Squid workers will consume all available cycles on their core, not leaving any for the fancy "thread" core sharing features to pretend there is another core available. YMMV. One of the tests to try when tuning is to turn off the CPU hyperthreading and see what effect it has (if any).


> Sockets 1
> Inter Xeron Silver 4208  @ 2.10GHz
>

Okay. Doable, but for best performance you want as high GHz rating on the cores as your budget can afford. The amount of "lag" Squid adds to traffic and RPS performance/parallelism directly correlates with how fast the CPU core can run cycles.



HTH
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220131/936efc1e/attachment.htm>

From ngtech1ltd at gmail.com  Mon Jan 31 16:20:43 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Mon, 31 Jan 2022 18:20:43 +0200
Subject: [squid-users] squid url_rewrite_program how to return a kind of
 TCP reset
In-Reply-To: <6689c956-846a-5452-b931-22abd54712c9@articatech.com>
References: <de6be72f-9ac9-28a0-d1ef-f47aca484ce8@articatech.com>
 <5cf1a9bc-f588-8c07-fefe-5359dda6ffde@treenet.co.nz>
 <6689c956-846a-5452-b931-22abd54712c9@articatech.com>
Message-ID: <000201d816be$7f8ddaf0$7ea990d0$@gmail.com>

Hey David,

 

It works only with ICAP or ECAP but I was talking about ICAP.

I wrote an example golang service at:

https://github.com/elico/bgu-icap-example

 

It is licensed with 3-clause BSD so you can use it freely.

It?s pretty simple to understand the code and I have used it in more
then one production environment in the past years.

The above is modifying the response of a page while you can just push into the page a template.

Just so you would see that the production is using one that is similar to the next one:

https://github.com/elico/squidblocker-icap-server/blob/master/sb_icap.go

 

Eliezer

----

Eliezer Croitoru

NgTech, Tech Support

Mobile: +972-5-28704261

Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 

 

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of David Touzeau
Sent: Monday, January 31, 2022 10:54
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid url_rewrite_program how to return a kind of TCP reset

 

Is adapted_http_access supporting url_rewrite_program  ? It seems only supports ecap/icap 

Le 31/01/2022 ? 03:52, Amos Jeffries a ?crit :

On 31/01/22 13:20, David Touzeau wrote: 



But it makes 2 connections to the squid for just stopping queries. 
It seems not really optimized. 


The joys of using URL modification to decide security access. 





I notice that for several reasons i cannot switch to an external_acl 


:( 





Is there a way / idea ? 


 <http://www.squid-cache.org/Doc/config/adapted_http_access/> <http://www.squid-cache.org/Doc/config/adapted_http_access/> 


Amos 
_______________________________________________ 
squid-users mailing list 
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>  
http://lists.squid-cache.org/listinfo/squid-users 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220131/0b36a236/attachment.htm>

From squid3 at treenet.co.nz  Mon Jan 31 21:44:48 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 1 Feb 2022 10:44:48 +1300
Subject: [squid-users] squid url_rewrite_program how to return a kind of
 TCP reset
In-Reply-To: <6689c956-846a-5452-b931-22abd54712c9@articatech.com>
References: <de6be72f-9ac9-28a0-d1ef-f47aca484ce8@articatech.com>
 <5cf1a9bc-f588-8c07-fefe-5359dda6ffde@treenet.co.nz>
 <6689c956-846a-5452-b931-22abd54712c9@articatech.com>
Message-ID: <48e558f5-312c-d22e-1f51-4b2225b86166@treenet.co.nz>

On 31/01/22 21:53, David Touzeau wrote:
> Is adapted_http_access supporting url_rewrite_program? ? It seems only 
> supports ecap/icap
> 


All the request adaptors (ICAP, eCAP, rewrite helper) can either respond 
with an adapted request or a response to the client.

  If they respond with a changed request then adapted_http_access is the 
access control to re-do http_access permission for the modified request.

  Otherwise the http_reply_access should be applied to the supplied 
response.


Amos



