From ngtech1ltd at gmail.com  Sun May  1 19:55:07 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Sun, 1 May 2022 22:55:07 +0300
Subject: [squid-users] squid-6.0.0-20220412-rb706999c1 cannot be built
Message-ID: <001701d85d95$5ce8f1b0$16bad510$@gmail.com>

I have tried to build couple RPMs for the V6 beta but found that the current
daily autogenerated releases cannot be built.

Is there any specific git commit I should try to use?

 

These are the last lines of the rpmbuild in CentOS 8 Stream:

## START

loaded-virtual -Werror -pipe -D_REENTRANT -I/usr/include/libxml2 -O2 -g
-pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong
--param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=genb -I../../src
-I../../include -I../../libltdl -I/usr/include/libxml2 -Wextra
-Wno-unused-private-field -Wimplicit-fallthrough=2 -Wpointer-arith
-Wwrite-strings -Wcomments -Wshadow -Wmissing-declarations -Woverlibtool:
compile:  g++ -DHAVE_CONFIG_H
-DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
-DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\"
-DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\" -I../.. -I../../include
-I../../lib -I../../src -I../../include -I../../libltdl
-I/usr/include/libxml2 -Wextra -Wno-unused-private-field
-Wimplicit-fallthrough=2 -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow
-Wmissing-declarations -Woverror.o .libs/SquidErrorData.o .libs/StringData.o
.libs/Tag.o .libs/Time.o .libs/TimeData.o .libs/TransactionInitiator.o
.libs/Url.o .libs/UrlLogin.o .libs/UrlPath.o .libs/UrlPort.o
.libs/UserData.o .libs/Certifg++ -DHAVE_CONFIG_H
-DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
-DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\"
-DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I.. -I../include -I../lib
-I../src -I../include   -I../libltdl -I../src -I../libltdl
-I/usr/include/libxml2  -Wextra -Wno-unused-private-field
-Wimplicit-fallthrough=2 -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow
-Wmissing-declarations -Woverloaded-virtual -Werror -pipe -D_REENTRANT
-I/usr/include/libxml2  -I/usr/include/p11-kit-1   -O2 -g -pipe -Wall
-Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS
-fexceptions -fstack-protector-strong -grecord-gcc-switches
-specs=/usr/lib/rpm/redhat/redhat-hardened-cc1
-specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic
-fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -fPIC
-c -o DelayBucket.o DelayBucket.cc

AclRegs.cc: In lambda function:

AclRegs.cc:165:50: error: unused parameter 'name' [-Werror=unused-parameter]

     RegisterMaker("clientside_mark", [](TypeName name)->ACL* { return new
Acl::ConnMark; });

                                         ~~~~~~~~~^~~~

AclRegs.cc: In lambda function:

AclRegs.cc:166:57: error: unused parameter 'name' [-Werror=unused-parameter]

     RegisterMaker("client_connection_mark", [](TypeName name)->ACL* {
return new Acl::ConnMark; });

                                                ~~~~~~~~~^~~~

g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
-DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\"
-DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I.. -I../include -I../lib
-I../src -I../include   -I../libltdl -I../src -I../libltdl
-I/usr/include/libxml2  -Wextra -Wno-unused-private-field
-Wimplicit-fallthrough=2 -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow
-Wmissing-declarations -Woverloaded-virtual -Werror -pipe -D_REENTRANT
-I/usr/include/libxml2  -I/usr/include/p11-kit-1   -O2 -g -pipe -Wall
-Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS
-fexceptions -fstack-protector-strong -grecord-gcc-switches
-specs=/usr/lib/rpm/redhat/redhat-hardened-cc1
-specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic
-fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -fPIC
-c -o DelayConfig.o DelayConfig.cc

g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
-DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\"
-DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I.. -I../include -I../lib
-I../src -I../include   -I../libltdl -I../src -I../libltdl
-I/usr/include/libxml2  -Wextra -Wno-unused-private-field
-Wimplicit-fallthrough=2 -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow
-Wmissing-declarations -Woverloaded-virtual -Werror -pipe -D_REENTRANT
-I/usr/include/libxml2  -I/usr/include/p11-kit-1   -O2 -g -pipe -Wall
-Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS
-fexceptions -fstack-protector-strong -grecord-gcc-switches
-specs=/usr/lib/rpm/redhat/redhat-hardened-cc1
-specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic
-fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -fPIC
-c -o DelayPool.o DelayPool.cc

g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
-DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\"
-DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I.. -I../include -I../lib
-I../src -I../include   -I../libltdl -I../src -I../libltdl
-I/usr/include/libxml2  -Wextra -Wno-unused-private-field
-Wimplicit-fallthrough=2 -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow
-Wmissing-declarations -Woverloaded-virtual -Werror -pipe -D_REENTRANT
-I/usr/include/libxml2  -I/usr/include/p11-kit-1   -O2 -g -pipe -Wall
-Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS
-fexceptions -fstack-protector-strong -grecord-gcc-switches
-specs=/usr/lib/rpm/redhat/redhat-hardened-cc1
-specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic
-fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -fPIC
-c -o DelaySpec.o DelaySpec.cc

At global scope:

cc1plus: error: unrecognized command line option '-Wno-unused-private-field'
[-Werror]

cc1plus: all warnings being treated as errors

make[3]: *** [Makefile:5929: AclRegs.o] Error 1

make[3]: *** Waiting for unfinished jobs....

make[3]: Leaving directory '/home/builder/BUILD/squid-6.0.1/src'

make[2]: *** [Makefile:6046: all-recursive] Error 1

make[2]: Leaving directory '/home/builder/BUILD/squid-6.0.1/src'

make[1]: *** [Makefile:5037: all] Error 2

make[1]: Leaving directory '/home/builder/BUILD/squid-6.0.1/src'

make: *** [Makefile:591: all-recursive] Error 1

error: Bad exit status from /var/tmp/rpm-tmp.kiBaSw (%build)

 

 

RPM build errors:

    Bad exit status from /var/tmp/rpm-tmp.kiBaSw (%build)

ufdio:       1 reads,    17154 total bytes in 0.000007 secs

ufdio:       1 reads,     5442 total bytes in 0.003573 secs

ufdio:       1 reads,    17154 total bytes in 0.000004 secs 

 

## END

 

Thanks,

 

----

Eliezer Croitoru

NgTech, Tech Support

Mobile: +972-5-28704261

Email:  <mailto:ngtech1ltd at gmail.com> ngtech1ltd at gmail.com

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220501/8a84b918/attachment.htm>

From squid3 at treenet.co.nz  Sun May  1 21:31:30 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 2 May 2022 09:31:30 +1200
Subject: [squid-users] squid-6.0.0-20220412-rb706999c1 cannot be built
In-Reply-To: <001701d85d95$5ce8f1b0$16bad510$@gmail.com>
References: <001701d85d95$5ce8f1b0$16bad510$@gmail.com>
Message-ID: <efa02d28-6ac0-540f-cfc8-c33be2dac546@treenet.co.nz>

On 2/05/22 07:55, Eliezer Croitoru wrote:
> I have tried to build couple RPMs for the V6 beta but found that the 
> current daily autogenerated releases cannot be built.
> 
> Is there any specific git commit I should try to use?
> 

There is a new daily tarball out now. can you try wit that one please?


Also, squid-dev for beta and experimental code issues.


Cheers
Amos


From ngtech1ltd at gmail.com  Sun May  1 22:27:46 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Mon, 2 May 2022 01:27:46 +0300
Subject: [squid-users] squid-6.0.0-20220412-rb706999c1 cannot be built
In-Reply-To: <efa02d28-6ac0-540f-cfc8-c33be2dac546@treenet.co.nz>
References: <001701d85d95$5ce8f1b0$16bad510$@gmail.com>
 <efa02d28-6ac0-540f-cfc8-c33be2dac546@treenet.co.nz>
Message-ID: <001e01d85daa$afd49e00$0f7dda00$@gmail.com>

Moving to Squid-Dev.

>From my tests this issue with the latest daily autogenerated sources package
is the same:
http://master.squid-cache.org/Versions/v6/squid-6.0.0-20220501-re899e0c27.ta
r.bz2
## START
n -fPIC -c -o DelayBucket.o DelayBucket.cc
AclRegs.cc: In lambda function:
AclRegs.cc:165:50: error: unused parameter 'name' [-Werror=unused-parameter]
RegisterMaker("clientside_mark", [](TypeName name)->ACL* { return new
Acl::ConnMark; });
                                         ~~~~~~~~~^~~~
AclRegs.cc: In lambda function:
AclRegs.cc:166:57: error: unused parameter 'name' [-Werror=unused-parameter]
     RegisterMaker("client_connection_mark", [](TypeName name)->ACL* {
return new Acl::ConnMark; });
~~~~~~~~~^~~~
g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
-DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\"
-DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I.. -I../include -I../lib
-I../src -I../include
-I../libltdl -I../src -I../libltdl  -I/usr/include/libxml2  -Wextra
-Wno-unused-private-field -Wimplicit-fallthrough=2 -Wpointer-arith
-Wwrite-strings -Wcomments -Wshadow -Wmissing-declarations
-Woverloaded-virtual -Werror -pipe -D_REENTRANT -I/usr/include/libxml2
-I/usr/include/p11-kit-1   -O2 -g -pipe -Wall -Werror=format-security
-Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions
-fstack-protector-strong -grecord-gcc-switches
-specs=/usr/lib/rpm/redhat/redhat-hardened-cc1
-specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic
-fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -fPIC
-c -o DelayConfig.o DelayConfig.cc
g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
-DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\"
-DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I.. -I../include -I../lib
-I../src -I../include   -I../libltdl -I../src -I../libltdl
-I/usr/include/libxml2  -Wextra -Wno-unused-private-field
-Wimplicit-fallthrough=2 -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow
-Wmissing-declarations -Woverloaded-virtual -Werror -pipe -D_REENTRANT
-I/usr/include/libxml2  -I/usr/include/p11-kit-1   -O2 -g -pipe -Wall
-Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS
-fexceptions -fstack-protector-strong -grecord-gcc-switches
-specs=/usr/lib/rpm/redhat/redhat-hardened-cc1
-specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic
-fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -fPIC
-c -o DelayPool.o DelayPool.cc
g++ -DHAVE_CONFIG_H -DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
-DDEFAULT_SQUID_DATA_DIR=\"/usr/share/squid\"
-DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I.. -I../include -I../lib
-I../src -I../include   -I../libltdl -I../src -I../libltdl
-I/usr/include/libxml2  -Wextra -Wno-unused-private-field
-Wimplicit-fallthrough=2 -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow
-Wmissing-declarations -Woverloaded-virtual -Werror -pipe -D_REENTRANT
-I/usr/include/libxml2  -I/usr/include/p11-kit-1   -O2 -g -pipe -Wall
-Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS
-fexceptions -fstack-protector-strong -grecord-gcc-switches
-specs=/usr/lib/rpm/redhat/redhat-hardened-cc1
-specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic
-fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -fPIC
-c -o DelaySpec.o DelaySpec.cc
At global scope:
cc1plus: error: unrecognized command line option '-Wno-unused-private-field'
[-Werror]
cc1plus: all warnings being treated as errors

## END

I will try to publish my podman build later on.

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
Amos Jeffries
Sent: Monday, May 2, 2022 00:32
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid-6.0.0-20220412-rb706999c1 cannot be built

On 2/05/22 07:55, Eliezer Croitoru wrote:
> I have tried to build couple RPMs for the V6 beta but found that the 
> current daily autogenerated releases cannot be built.
> 
> Is there any specific git commit I should try to use?
> 

There is a new daily tarball out now. can you try wit that one please?


Also, squid-dev for beta and experimental code issues.


Cheers
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From 0xff1f at gmail.com  Mon May  2 03:49:07 2022
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Mon, 2 May 2022 03:49:07 +0000
Subject: [squid-users] squid5 Happy Eyeballs - Is it possible to enable IPV4
 only or IPV6 only ?
Message-ID: <DBBPR09MB45235081C0FC9CCD28D03101F7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>

Hello Team ,

Testing squid5.x .
Still have a question in a case of running multiple instances (IPV4/IPV6) on same machine .
Such as ?  One instance that run as IPV4 only while other instance run as IPV6 only .

I found that squid5.x is ignoring dns_v4_first .
And based on the algorithm and how it works , sometime  the IPV4 instance receive DNS resolution of the destination as IPV6 and the connection fails !!

sometimes the IPV4 instance receive the DNS resolution of the destination as IPV6 and the connection fail .

Is there any option we can do based on the environment above ?
Like maybe we disable eyeballs or preserving it while add an option like DNS A records or DNS AAAA records .

Thanks




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220502/d4ca33f9/attachment.htm>

From rousskov at measurement-factory.com  Mon May  2 15:38:54 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 2 May 2022 11:38:54 -0400
Subject: [squid-users] squid5 Happy Eyeballs - Is it possible to enable
 IPV4 only or IPV6 only ?
In-Reply-To: <DBBPR09MB45235081C0FC9CCD28D03101F7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>
References: <DBBPR09MB45235081C0FC9CCD28D03101F7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>
Message-ID: <ebbbd3ef-1aca-1b25-79d2-4639cbf3dcf0@measurement-factory.com>

On 5/1/22 23:49, Ahmad Alzaeem wrote:

> sometime?the IPV4 
> instance receive DNS resolution of the destination as IPV6 and the 
> connection fails !!
> 
> sometimes the IPV4 instance receive the DNS resolution of the 
> destination as IPV6 and the connection fail .
> 
> Is there any option we can do based on the environment above ?


Without Squid code modifications, your options are:

* Use a custom DNS resolver (configuration) that never sends IPv4 
address records to an IPv6-only Squid. Use a custom DNS resolver 
(configuration) that never sends IPv6 address records to an IPv4-only 
Squid. Configure each Squid to use the right resolver (see dns_nameservers).

* Disable IPv6 support in IPv4-only Squid at ./configure time. This does 
not help with the IPv6-only Squid and has other negative side effects. I 
do not recommend this option.


 > Like maybe we disable eyeballs or preserving it while add an option
 > like DNS A records or DNS AAAA records .

It would be possible to enhance Squid by adding a configuration option 
that disables (certain) A or AAAA queries, but proper modifications are 
not trivial and nobody has done them yet: 
https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F


Cheers,

Alex.



From 0xff1f at gmail.com  Mon May  2 15:44:06 2022
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Mon, 2 May 2022 15:44:06 +0000
Subject: [squid-users] squid5 Happy Eyeballs - Is it possible to enable
 IPV4 only or IPV6 only ?
In-Reply-To: <ebbbd3ef-1aca-1b25-79d2-4639cbf3dcf0@measurement-factory.com>
References: <DBBPR09MB45235081C0FC9CCD28D03101F7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>
 <ebbbd3ef-1aca-1b25-79d2-4639cbf3dcf0@measurement-factory.com>
Message-ID: <DBBPR09MB45231BBEB890F640209F6957F7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>

Hello Alex ,
Thanks for the nice info .
I will consider what you said .


Thanks


From: Alex Rousskov <rousskov at measurement-factory.com>
Date: Monday, May 2, 2022 at 8:38 AM
To: Ahmad Alzaeem <0xff1f at gmail.com>, Squid Users <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] squid5 Happy Eyeballs - Is it possible to enable IPV4 only or IPV6 only ?
On 5/1/22 23:49, Ahmad Alzaeem wrote:

> sometime the IPV4
> instance receive DNS resolution of the destination as IPV6 and the
> connection fails !!
>
> sometimes the IPV4 instance receive the DNS resolution of the
> destination as IPV6 and the connection fail .
>
> Is there any option we can do based on the environment above ?


Without Squid code modifications, your options are:

* Use a custom DNS resolver (configuration) that never sends IPv4
address records to an IPv6-only Squid. Use a custom DNS resolver
(configuration) that never sends IPv6 address records to an IPv4-only
Squid. Configure each Squid to use the right resolver (see dns_nameservers).

* Disable IPv6 support in IPv4-only Squid at ./configure time. This does
not help with the IPv6-only Squid and has other negative side effects. I
do not recommend this option.


 > Like maybe we disable eyeballs or preserving it while add an option
 > like DNS A records or DNS AAAA records .

It would be possible to enhance Squid by adding a configuration option
that disables (certain) A or AAAA queries, but proper modifications are
not trivial and nobody has done them yet:
https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F


Cheers,

Alex.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220502/9846c141/attachment.htm>

From 0xff1f at gmail.com  Mon May  2 18:24:42 2022
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Mon, 2 May 2022 18:24:42 +0000
Subject: [squid-users] squid3/4 compilation error with  Centos8/RH8
Message-ID: <DBBPR09MB4523AAA561BE9E426382044AF7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>




Hello Team ,
I found I only was able to build squid 5.x on Centos8/RH8 ?  (Not able to build 3.x or 4.x )
I was able to build  squid 3.x and 4.x on RH7/Centos7 .

It seems Its libssl error or so based on compilation error below (not sure if need to upgrade or downgrade GCC)

//////
cache_cf.o: In function `parseOneConfigFile(char const*, unsigned int)':
cache_cf.cc:(.text+0x805): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.cc:(.text+0xc2b): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.cc:(.text+0xd78): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.cc:(.text+0x10a4): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.o: In function `parseConfigFileOrThrow(char const*)':
cache_cf.cc:(.text+0x1295): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.o:cache_cf.cc:(.text+0x142e): more undefined references to `Debug::Start[abi:cxx11](int, int)' follow
cache_cf.o: In function `dump_acl(StoreEntry*, char const*, ACL*)':
cache_cf.cc:(.text+0x3bc5): undefined reference to `ACL::dumpOptions[abi:cxx11]()'
cache_cf.o: In function `parse_address(Ip::Address*)':
cache_cf.cc:(.text+0x3f7a): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.o: In function `parse_acl_tos(acl_tos**)':
cache_cf.cc:(.text+0x432e): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.o: In function `parse_http_header_access(HeaderManglers**)':
cache_cf.cc:(.text+0x49d7): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.cc:(.text+0x4a6d): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.o: In function `parse_http_header_replace(HeaderManglers**)':
cache_cf.cc:(.text+0x4cc5): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.o:cache_cf.cc:(.text+0x4d5b): more undefined references to `Debug::Start[abi:cxx11](int, int)' follow
client_side.o: In function `EVP_PKEY_up_ref':
client_side.cc:(.text.EVP_PKEY_up_ref[EVP_PKEY_up_ref]+0x34): undefined reference to `CRYPTO_add_lock'
client_side.o: In function `X509_up_ref':
client_side.cc:(.text.X509_up_ref[X509_up_ref]+0x34): undefined reference to `CRYPTO_add_lock'
anyp/.libs/libanyp.a(PortCfg.o): In function `Security::ServerOptions::sk_X509_NAME_free_wrapper::operator()(stack_st_X509_NAME*)':
PortCfg.cc:(.text._ZN8Security13ServerOptions25sk_X509_NAME_free_wrapperclEP18stack_st_X509_NAME[_ZN8Security13ServerOptions25sk_X509_NAME_free_wrapperclEP18stack_st_X509_NAME]+0x22): undefined reference to `sk_pop_free'
security/.libs/libsecurity.a(PeerOptions.o): In function `Security::PeerOptions::createBlankContext() const':
PeerOptions.cc:(.text+0x1896): undefined reference to `SSLv23_client_method'
security/.libs/libsecurity.a(ServerOptions.o): In function `Security::ServerOptions::createBlankContext() const':
ServerOptions.cc:(.text+0xb4a): undefined reference to `SSLv23_server_method'
security/.libs/libsecurity.a(ServerOptions.o): In function `X509_CRL_up_ref':
ServerOptions.cc:(.text.X509_CRL_up_ref[X509_CRL_up_ref]+0x36): undefined reference to `CRYPTO_add_lock'
security/.libs/libsecurity.a(Session.o): In function `tls_write_method(int, char const*, int)':
Session.cc:(.text+0x677): undefined reference to `SSL_state'
ssl/.libs/libsslsquid.a(support.o): In function `Ssl::MaybeSetupRsaCallback(std::shared_ptr<ssl_ctx_st>&)':
support.cc:(.text+0x6c9): undefined reference to `SSL_CTX_set_tmp_rsa_callback'
ssl/.libs/libsslsquid.a(support.o): In function `Ssl::matchX509CommonNames(x509_st*, void*, int (*)(void*, asn1_string_st*))':
support.cc:(.text+0x855): undefined reference to `sk_num'
support.cc:(.text+0x872): undefined reference to `sk_value'
support.cc:(.text+0x8c2): undefined reference to `sk_pop_free'
support.cc:(.text+0x8eb): undefined reference to `sk_pop_free'
ssl/.libs/libsslsquid.a(support.o): In function `ssl_verify_cb(int, x509_store_ctx_st*)':
support.cc:(.text+0x19be): undefined reference to `sk_pop_free'
ssl/.libs/libsslsquid.a(support.o): In function `ssl_free_CertChain(void*, void*, crypto_ex_data_st*, int, long, void*)':
support.cc:(.text+0x1ead): undefined reference to `sk_pop_free'
ssl/.libs/libsslsquid.a(support.o): In function `Ssl::Initialize()':
support.cc:(.text+0x2084): undefined reference to `SSL_get_ex_new_index'
support.cc:(.text+0x20b0): undefined reference to `SSL_CTX_get_ex_new_index'
support.cc:(.text+0x20df): undefined reference to `SSL_get_ex_new_index'
support.cc:(.text+0x210c): undefined reference to `SSL_get_ex_new_index'
support.cc:(.text+0x2139): undefined reference to `SSL_get_ex_new_index'
support.cc:(.text+0x2166): undefined reference to `SSL_get_ex_new_index'
support.cc:(.text+0x2193): undefined reference to `SSL_get_ex_new_index'
ssl/.libs/libsslsquid.a(support.o):support.cc:(.text+0x21c0): more undefined references to `SSL_get_ex_new_index' follow
ssl/.libs/libsslsquid.a(support.o): In function `sslGetUserCertificateChainPEM(ssl_st*)':
support.cc:(.text+0x2e23): undefined reference to `sk_value'
support.cc:(.text+0x2e4a): undefined reference to `sk_num'
ssl/.libs/libsslsquid.a(support.o): In function `hasAuthorityInfoAccessCaIssuers(x509_st*)':
support.cc:(.text+0x3aed): undefined reference to `sk_value'
support.cc:(.text+0x3b55): undefined reference to `sk_num'
ssl/.libs/libsslsquid.a(support.o): In function `Ssl::SSL_add_untrusted_cert(ssl_st*, x509_st*)':
support.cc:(.text+0x43cc): undefined reference to `sk_new_null'
support.cc:(.text+0x440a): undefined reference to `sk_pop_free'
support.cc:(.text+0x447b): undefined reference to `sk_push'
ssl/.libs/libsslsquid.a(support.o): In function `sk_x509_findIssuer(stack_st_X509*, x509_st*)':
support.cc:(.text+0x44c6): undefined reference to `sk_num'
support.cc:(.text+0x44e3): undefined reference to `sk_value'
ssl/.libs/libsslsquid.a(support.o): In function `completeIssuers(x509_store_ctx_st*, stack_st_X509*)':
support.cc:(.text+0x4604): undefined reference to `sk_num'
support.cc:(.text+0x4713): undefined reference to `sk_push'
ssl/.libs/libsslsquid.a(support.o): In function `untrustedToStoreCtx_cb(x509_store_ctx_st*, void*)':
support.cc:(.text+0x4949): undefined reference to `sk_dup'
support.cc:(.text+0x4967): undefined reference to `sk_value'
support.cc:(.text+0x497e): undefined reference to `sk_push'
support.cc:(.text+0x498e): undefined reference to `sk_num'
support.cc:(.text+0x49d4): undefined reference to `X509_STORE_CTX_set_chain'
support.cc:(.text+0x49f6): undefined reference to `X509_STORE_CTX_set_chain'
support.cc:(.text+0x4a02): undefined reference to `sk_free'
ssl/.libs/libsslsquid.a(support.o): In function `squid_OPENSSL_init_ssl()':
support.cc:(.text._Z24squid_OPENSSL_init_sslv[_Z24squid_OPENSSL_init_sslv]+0x5): undefined reference to `SSL_load_error_strings'
support.cc:(.text._Z24squid_OPENSSL_init_sslv[_Z24squid_OPENSSL_init_sslv]+0xa): undefined reference to `SSL_library_init'
ssl/.libs/libsslsquid.a(cert_validate_message.o): In function `Ssl::CertValidationMsg::composeRequest(Ssl::CertValidationRequest const&)':
cert_validate_message.cc:(.text+0x36a): undefined reference to `sk_value'
cert_validate_message.cc:(.text+0x51d): undefined reference to `sk_num'
cert_validate_message.cc:(.text+0x6e8): undefined reference to `sk_find'
ssl/.libs/libsslsquid.a(cert_validate_message.o): In function `Ssl::CertValidationMsg::parseResponse(Ssl::CertValidationResponse&, std::string&)':
cert_validate_message.cc:(.text+0x1440): undefined reference to `sk_value'
ssl/.libs/libsslutil.a(gadgets.o): In function `mimicAuthorityKeyId(Security::LockingPointer<x509_st, &Security::X509_free_cpp, HardFun<int, x509_st*, &X509_up_ref> >&, Security::LockingPointer<x509_st, &Security::X509_free_cpp, HardFun<int, x509_st*, &X509_up_ref> > const&, Security::LockingPointer<x509_st, &Security::X509_free_cpp, HardFun<int, x509_st*, &X509_up_ref> > const&)':
gadgets.cc:(.text+0x1276): undefined reference to `sk_new_null'
gadgets.cc:(.text+0x12da): undefined reference to `sk_push'
ssl/.libs/libsslutil.a(gadgets.o): In function `buildCertificate(Security::LockingPointer<x509_st, &Security::X509_free_cpp, HardFun<int, x509_st*, &X509_up_ref> >&, Ssl::CertificateProperties const&)':
gadgets.cc:(.text+0x1b24): undefined reference to `X509_set_notBefore'
gadgets.cc:(.text+0x1c30): undefined reference to `X509_set_notAfter'
ssl/.libs/libsslutil.a(gadgets.o): In function `Ssl::certificateMatchesProperties(x509_st*, Ssl::CertificateProperties const&)':
gadgets.cc:(.text+0x2db5): undefined reference to `sk_num'
gadgets.cc:(.text+0x2dd2): undefined reference to `sk_value'
gadgets.cc:(.text+0x2de9): undefined reference to `sk_find'
gadgets.cc:(.text+0x2e26): undefined reference to `sk_pop_free'
gadgets.cc:(.text+0x2e3c): undefined reference to `sk_pop_free'
ssl/.libs/libsslutil.a(gadgets.o): In function `Ssl::sk_GENERAL_NAME_free_wrapper::operator()(stack_st_GENERAL_NAME*)':
gadgets.cc:(.text._ZN3Ssl28sk_GENERAL_NAME_free_wrapperclEP21stack_st_GENERAL_NAME[_ZN3Ssl28sk_GENERAL_NAME_free_wrapperclEP21stack_st_GENERAL_NAME]+0x22): undefined reference to `sk_pop_free'
collect2: error: ld returned 1 exit status
libtool: link: rm -f ".libs/squidS.o"
make[3]: *** [Makefile:6356: squid] Error 1
make[3]: Leaving directory '/root/KrazyNetworks.com/squid-4.8/src'
make[2]: *** [Makefile:7126: all-recursive] Error 1
make[2]: Leaving directory '/root/KrazyNetworks.com/squid-4.8/src'
make[1]: *** [Makefile:6136: all] Error 2
make[1]: Leaving directory '/root/KrazyNetworks.com





gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/8/lto-wrapper
OFFLOAD_TARGET_NAMES=nvptx-none
OFFLOAD_TARGET_DEFAULT=1
Target: x86_64-redhat-linux
Configured with: ../configure --enable-bootstrap --enable-languages=c,c++,fortran,lto --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-shared --enable-threads=posix --enable-checking=release --enable-multilib --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-gcc-major-version-only --with-linker-hash-style=gnu --enable-plugin --enable-initfini-array --with-isl --disable-libmpx --enable-offload-targets=nvptx-none --without-cuda-driver --enable-gnu-indirect-function --enable-cet --with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linux
Thread model: posix
gcc version 8.5.0 20210514 (Red Hat 8.5.0-4) (GCC)








Is there any flag I need to pass for RH8/Centos8 so it compile older version of squid like 3.x and 4.5 ?


Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220502/6b604e27/attachment.htm>

From ngtech1ltd at gmail.com  Mon May  2 18:57:54 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Mon, 2 May 2022 21:57:54 +0300
Subject: [squid-users] squid3/4 compilation error with  Centos8/RH8
In-Reply-To: <DBBPR09MB4523AAA561BE9E426382044AF7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>
References: <DBBPR09MB4523AAA561BE9E426382044AF7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>
Message-ID: <006d01d85e56$88baede0$9a30c9a0$@gmail.com>

Try to use the next SRPM:

https://www.ngtech.co.il/repo/centos/8/SRPMS/squid-4.17-8.el8.src.rpm

 

Good Luck,

 

----

Eliezer Croitoru

NgTech, Tech Support

Mobile: +972-5-28704261

Email:  <mailto:ngtech1ltd at gmail.com> ngtech1ltd at gmail.com

 

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
Ahmad Alzaeem
Sent: Monday, May 2, 2022 21:25
To: squid-users at lists.squid-cache.org
Subject: [squid-users] squid3/4 compilation error with Centos8/RH8

 

 

 

 

Hello Team ,

I found I only was able to build squid 5.x on Centos8/RH8 -  (Not able to
build 3.x or 4.x )

I was able to build  squid 3.x and 4.x on RH7/Centos7 .

 

It seems Its libssl error or so based on compilation error below (not sure
if need to upgrade or downgrade GCC) 

 

////// 

cache_cf.o: In function `parseOneConfigFile(char const*, unsigned int)':

cache_cf.cc:(.text+0x805): undefined reference to
`Debug::Start[abi:cxx11](int, int)'

cache_cf.cc:(.text+0xc2b): undefined reference to
`Debug::Start[abi:cxx11](int, int)'

cache_cf.cc:(.text+0xd78): undefined reference to
`Debug::Start[abi:cxx11](int, int)'

cache_cf.cc:(.text+0x10a4): undefined reference to
`Debug::Start[abi:cxx11](int, int)'

cache_cf.o: In function `parseConfigFileOrThrow(char const*)':

cache_cf.cc:(.text+0x1295): undefined reference to
`Debug::Start[abi:cxx11](int, int)'

cache_cf.o:cache_cf.cc:(.text+0x142e): more undefined references to
`Debug::Start[abi:cxx11](int, int)' follow

cache_cf.o: In function `dump_acl(StoreEntry*, char const*, ACL*)':

cache_cf.cc:(.text+0x3bc5): undefined reference to
`ACL::dumpOptions[abi:cxx11]()'

cache_cf.o: In function `parse_address(Ip::Address*)':

cache_cf.cc:(.text+0x3f7a): undefined reference to
`Debug::Start[abi:cxx11](int, int)'

cache_cf.o: In function `parse_acl_tos(acl_tos**)':

cache_cf.cc:(.text+0x432e): undefined reference to
`Debug::Start[abi:cxx11](int, int)'

cache_cf.o: In function `parse_http_header_access(HeaderManglers**)':

cache_cf.cc:(.text+0x49d7): undefined reference to
`Debug::Start[abi:cxx11](int, int)'

cache_cf.cc:(.text+0x4a6d): undefined reference to
`Debug::Start[abi:cxx11](int, int)'

cache_cf.o: In function `parse_http_header_replace(HeaderManglers**)':

cache_cf.cc:(.text+0x4cc5): undefined reference to
`Debug::Start[abi:cxx11](int, int)'

cache_cf.o:cache_cf.cc:(.text+0x4d5b): more undefined references to
`Debug::Start[abi:cxx11](int, int)' follow

client_side.o: In function `EVP_PKEY_up_ref':

client_side.cc:(.text.EVP_PKEY_up_ref[EVP_PKEY_up_ref]+0x34): undefined
reference to `CRYPTO_add_lock'

client_side.o: In function `X509_up_ref':

client_side.cc:(.text.X509_up_ref[X509_up_ref]+0x34): undefined reference to
`CRYPTO_add_lock'

anyp/.libs/libanyp.a(PortCfg.o): In function
`Security::ServerOptions::sk_X509_NAME_free_wrapper::operator()(stack_st_X50
9_NAME*)':

PortCfg.cc:(.text._ZN8Security13ServerOptions25sk_X509_NAME_free_wrapperclEP
18stack_st_X509_NAME[_ZN8Security13ServerOptions25sk_X509_NAME_free_wrapperc
lEP18stack_st_X509_NAME]+0x22): undefined reference to `sk_pop_free'

security/.libs/libsecurity.a(PeerOptions.o): In function
`Security::PeerOptions::createBlankContext() const':

PeerOptions.cc:(.text+0x1896): undefined reference to `SSLv23_client_method'

security/.libs/libsecurity.a(ServerOptions.o): In function
`Security::ServerOptions::createBlankContext() const':

ServerOptions.cc:(.text+0xb4a): undefined reference to
`SSLv23_server_method'

security/.libs/libsecurity.a(ServerOptions.o): In function
`X509_CRL_up_ref':

ServerOptions.cc:(.text.X509_CRL_up_ref[X509_CRL_up_ref]+0x36): undefined
reference to `CRYPTO_add_lock'

security/.libs/libsecurity.a(Session.o): In function `tls_write_method(int,
char const*, int)':

Session.cc:(.text+0x677): undefined reference to `SSL_state'

ssl/.libs/libsslsquid.a(support.o): In function
`Ssl::MaybeSetupRsaCallback(std::shared_ptr<ssl_ctx_st>&)':

support.cc:(.text+0x6c9): undefined reference to
`SSL_CTX_set_tmp_rsa_callback'

ssl/.libs/libsslsquid.a(support.o): In function
`Ssl::matchX509CommonNames(x509_st*, void*, int (*)(void*,
asn1_string_st*))':

support.cc:(.text+0x855): undefined reference to `sk_num'

support.cc:(.text+0x872): undefined reference to `sk_value'

support.cc:(.text+0x8c2): undefined reference to `sk_pop_free'

support.cc:(.text+0x8eb): undefined reference to `sk_pop_free'

ssl/.libs/libsslsquid.a(support.o): In function `ssl_verify_cb(int,
x509_store_ctx_st*)':

support.cc:(.text+0x19be): undefined reference to `sk_pop_free'

ssl/.libs/libsslsquid.a(support.o): In function `ssl_free_CertChain(void*,
void*, crypto_ex_data_st*, int, long, void*)':

support.cc:(.text+0x1ead): undefined reference to `sk_pop_free'

ssl/.libs/libsslsquid.a(support.o): In function `Ssl::Initialize()':

support.cc:(.text+0x2084): undefined reference to `SSL_get_ex_new_index'

support.cc:(.text+0x20b0): undefined reference to `SSL_CTX_get_ex_new_index'

support.cc:(.text+0x20df): undefined reference to `SSL_get_ex_new_index'

support.cc:(.text+0x210c): undefined reference to `SSL_get_ex_new_index'

support.cc:(.text+0x2139): undefined reference to `SSL_get_ex_new_index'

support.cc:(.text+0x2166): undefined reference to `SSL_get_ex_new_index'

support.cc:(.text+0x2193): undefined reference to `SSL_get_ex_new_index'

ssl/.libs/libsslsquid.a(support.o):support.cc:(.text+0x21c0): more undefined
references to `SSL_get_ex_new_index' follow

ssl/.libs/libsslsquid.a(support.o): In function
`sslGetUserCertificateChainPEM(ssl_st*)':

support.cc:(.text+0x2e23): undefined reference to `sk_value'

support.cc:(.text+0x2e4a): undefined reference to `sk_num'

ssl/.libs/libsslsquid.a(support.o): In function
`hasAuthorityInfoAccessCaIssuers(x509_st*)':

support.cc:(.text+0x3aed): undefined reference to `sk_value'

support.cc:(.text+0x3b55): undefined reference to `sk_num'

ssl/.libs/libsslsquid.a(support.o): In function
`Ssl::SSL_add_untrusted_cert(ssl_st*, x509_st*)':

support.cc:(.text+0x43cc): undefined reference to `sk_new_null'

support.cc:(.text+0x440a): undefined reference to `sk_pop_free'

support.cc:(.text+0x447b): undefined reference to `sk_push'

ssl/.libs/libsslsquid.a(support.o): In function
`sk_x509_findIssuer(stack_st_X509*, x509_st*)':

support.cc:(.text+0x44c6): undefined reference to `sk_num'

support.cc:(.text+0x44e3): undefined reference to `sk_value'

ssl/.libs/libsslsquid.a(support.o): In function
`completeIssuers(x509_store_ctx_st*, stack_st_X509*)':

support.cc:(.text+0x4604): undefined reference to `sk_num'

support.cc:(.text+0x4713): undefined reference to `sk_push'

ssl/.libs/libsslsquid.a(support.o): In function
`untrustedToStoreCtx_cb(x509_store_ctx_st*, void*)':

support.cc:(.text+0x4949): undefined reference to `sk_dup'

support.cc:(.text+0x4967): undefined reference to `sk_value'

support.cc:(.text+0x497e): undefined reference to `sk_push'

support.cc:(.text+0x498e): undefined reference to `sk_num'

support.cc:(.text+0x49d4): undefined reference to `X509_STORE_CTX_set_chain'

support.cc:(.text+0x49f6): undefined reference to `X509_STORE_CTX_set_chain'

support.cc:(.text+0x4a02): undefined reference to `sk_free'

ssl/.libs/libsslsquid.a(support.o): In function `squid_OPENSSL_init_ssl()':

support.cc:(.text._Z24squid_OPENSSL_init_sslv[_Z24squid_OPENSSL_init_sslv]+0
x5): undefined reference to `SSL_load_error_strings'

support.cc:(.text._Z24squid_OPENSSL_init_sslv[_Z24squid_OPENSSL_init_sslv]+0
xa): undefined reference to `SSL_library_init'

ssl/.libs/libsslsquid.a(cert_validate_message.o): In function
`Ssl::CertValidationMsg::composeRequest(Ssl::CertValidationRequest const&)':

cert_validate_message.cc:(.text+0x36a): undefined reference to `sk_value'

cert_validate_message.cc:(.text+0x51d): undefined reference to `sk_num'

cert_validate_message.cc:(.text+0x6e8): undefined reference to `sk_find'

ssl/.libs/libsslsquid.a(cert_validate_message.o): In function
`Ssl::CertValidationMsg::parseResponse(Ssl::CertValidationResponse&,
std::string&)':

cert_validate_message.cc:(.text+0x1440): undefined reference to `sk_value'

ssl/.libs/libsslutil.a(gadgets.o): In function
`mimicAuthorityKeyId(Security::LockingPointer<x509_st,
&Security::X509_free_cpp, HardFun<int, x509_st*, &X509_up_ref> >&,
Security::LockingPointer<x509_st, &Security::X509_free_cpp, HardFun<int,
x509_st*, &X509_up_ref> > const&, Security::LockingPointer<x509_st,
&Security::X509_free_cpp, HardFun<int, x509_st*, &X509_up_ref> > const&)':

gadgets.cc:(.text+0x1276): undefined reference to `sk_new_null'

gadgets.cc:(.text+0x12da): undefined reference to `sk_push'

ssl/.libs/libsslutil.a(gadgets.o): In function
`buildCertificate(Security::LockingPointer<x509_st,
&Security::X509_free_cpp, HardFun<int, x509_st*, &X509_up_ref> >&,
Ssl::CertificateProperties const&)':

gadgets.cc:(.text+0x1b24): undefined reference to `X509_set_notBefore'

gadgets.cc:(.text+0x1c30): undefined reference to `X509_set_notAfter'

ssl/.libs/libsslutil.a(gadgets.o): In function
`Ssl::certificateMatchesProperties(x509_st*, Ssl::CertificateProperties
const&)':

gadgets.cc:(.text+0x2db5): undefined reference to `sk_num'

gadgets.cc:(.text+0x2dd2): undefined reference to `sk_value'

gadgets.cc:(.text+0x2de9): undefined reference to `sk_find'

gadgets.cc:(.text+0x2e26): undefined reference to `sk_pop_free'

gadgets.cc:(.text+0x2e3c): undefined reference to `sk_pop_free'

ssl/.libs/libsslutil.a(gadgets.o): In function
`Ssl::sk_GENERAL_NAME_free_wrapper::operator()(stack_st_GENERAL_NAME*)':

gadgets.cc:(.text._ZN3Ssl28sk_GENERAL_NAME_free_wrapperclEP21stack_st_GENERA
L_NAME[_ZN3Ssl28sk_GENERAL_NAME_free_wrapperclEP21stack_st_GENERAL_NAME]+0x2
2): undefined reference to `sk_pop_free'

collect2: error: ld returned 1 exit status

libtool: link: rm -f ".libs/squidS.o"

make[3]: *** [Makefile:6356: squid] Error 1

make[3]: Leaving directory '/root/KrazyNetworks.com/squid-4.8/src'

make[2]: *** [Makefile:7126: all-recursive] Error 1

make[2]: Leaving directory '/root/KrazyNetworks.com/squid-4.8/src'

make[1]: *** [Makefile:6136: all] Error 2

make[1]: Leaving directory '/root/KrazyNetworks.com

 

 

 

 

 

gcc -v

Using built-in specs.

COLLECT_GCC=gcc

COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/8/lto-wrapper

OFFLOAD_TARGET_NAMES=nvptx-none

OFFLOAD_TARGET_DEFAULT=1

Target: x86_64-redhat-linux

Configured with: ../configure --enable-bootstrap
--enable-languages=c,c++,fortran,lto --prefix=/usr --mandir=/usr/share/man
--infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla
--enable-shared --enable-threads=posix --enable-checking=release
--enable-multilib --with-system-zlib --enable-__cxa_atexit
--disable-libunwind-exceptions --enable-gnu-unique-object
--enable-linker-build-id --with-gcc-major-version-only
--with-linker-hash-style=gnu --enable-plugin --enable-initfini-array
--with-isl --disable-libmpx --enable-offload-targets=nvptx-none
--without-cuda-driver --enable-gnu-indirect-function --enable-cet
--with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linux

Thread model: posix

gcc version 8.5.0 20210514 (Red Hat 8.5.0-4) (GCC)

 

 

 

 

 

 

 

 

Is there any flag I need to pass for RH8/Centos8 so it compile older version
of squid like 3.x and 4.5 ?

 

 

Thanks 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220502/5fc508da/attachment.htm>

From 0xff1f at gmail.com  Mon May  2 19:05:29 2022
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Mon, 2 May 2022 19:05:29 +0000
Subject: [squid-users] squid3/4 compilation error with  Centos8/RH8
In-Reply-To: <006d01d85e56$88baede0$9a30c9a0$@gmail.com>
References: <DBBPR09MB4523AAA561BE9E426382044AF7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>
 <006d01d85e56$88baede0$9a30c9a0$@gmail.com>
Message-ID: <DBBPR09MB4523D1F69057A95715FB765DF7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>

Hello Eliezer Croitoru ,
Thank you for your reply ,

Indeed I need to build it from source with custom compile flags .

Is there anyway to overcome the error I sent earlier ?


Thanks


From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Eliezer Croitoru <ngtech1ltd at gmail.com>
Date: Monday, May 2, 2022 at 11:59 AM
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] squid3/4 compilation error with Centos8/RH8
Try to use the next SRPM:
https://www.ngtech.co.il/repo/centos/8/SRPMS/squid-4.17-8.el8.src.rpm

Good Luck,

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com<mailto:ngtech1ltd at gmail.com>

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Ahmad Alzaeem
Sent: Monday, May 2, 2022 21:25
To: squid-users at lists.squid-cache.org
Subject: [squid-users] squid3/4 compilation error with Centos8/RH8




Hello Team ,
I found I only was able to build squid 5.x on Centos8/RH8 ?  (Not able to build 3.x or 4.x )
I was able to build  squid 3.x and 4.x on RH7/Centos7 .

It seems Its libssl error or so based on compilation error below (not sure if need to upgrade or downgrade GCC)

//////
cache_cf.o: In function `parseOneConfigFile(char const*, unsigned int)':
cache_cf.cc:(.text+0x805): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.cc:(.text+0xc2b): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.cc:(.text+0xd78): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.cc:(.text+0x10a4): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.o: In function `parseConfigFileOrThrow(char const*)':
cache_cf.cc:(.text+0x1295): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.o:cache_cf.cc:(.text+0x142e): more undefined references to `Debug::Start[abi:cxx11](int, int)' follow
cache_cf.o: In function `dump_acl(StoreEntry*, char const*, ACL*)':
cache_cf.cc:(.text+0x3bc5): undefined reference to `ACL::dumpOptions[abi:cxx11]()'
cache_cf.o: In function `parse_address(Ip::Address*)':
cache_cf.cc:(.text+0x3f7a): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.o: In function `parse_acl_tos(acl_tos**)':
cache_cf.cc:(.text+0x432e): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.o: In function `parse_http_header_access(HeaderManglers**)':
cache_cf.cc:(.text+0x49d7): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.cc:(.text+0x4a6d): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.o: In function `parse_http_header_replace(HeaderManglers**)':
cache_cf.cc:(.text+0x4cc5): undefined reference to `Debug::Start[abi:cxx11](int, int)'
cache_cf.o:cache_cf.cc:(.text+0x4d5b): more undefined references to `Debug::Start[abi:cxx11](int, int)' follow
client_side.o: In function `EVP_PKEY_up_ref':
client_side.cc:(.text.EVP_PKEY_up_ref[EVP_PKEY_up_ref]+0x34): undefined reference to `CRYPTO_add_lock'
client_side.o: In function `X509_up_ref':
client_side.cc:(.text.X509_up_ref[X509_up_ref]+0x34): undefined reference to `CRYPTO_add_lock'
anyp/.libs/libanyp.a(PortCfg.o): In function `Security::ServerOptions::sk_X509_NAME_free_wrapper::operator()(stack_st_X509_NAME*)':
PortCfg.cc:(.text._ZN8Security13ServerOptions25sk_X509_NAME_free_wrapperclEP18stack_st_X509_NAME[_ZN8Security13ServerOptions25sk_X509_NAME_free_wrapperclEP18stack_st_X509_NAME]+0x22): undefined reference to `sk_pop_free'
security/.libs/libsecurity.a(PeerOptions.o): In function `Security::PeerOptions::createBlankContext() const':
PeerOptions.cc:(.text+0x1896): undefined reference to `SSLv23_client_method'
security/.libs/libsecurity.a(ServerOptions.o): In function `Security::ServerOptions::createBlankContext() const':
ServerOptions.cc:(.text+0xb4a): undefined reference to `SSLv23_server_method'
security/.libs/libsecurity.a(ServerOptions.o): In function `X509_CRL_up_ref':
ServerOptions.cc:(.text.X509_CRL_up_ref[X509_CRL_up_ref]+0x36): undefined reference to `CRYPTO_add_lock'
security/.libs/libsecurity.a(Session.o): In function `tls_write_method(int, char const*, int)':
Session.cc:(.text+0x677): undefined reference to `SSL_state'
ssl/.libs/libsslsquid.a(support.o): In function `Ssl::MaybeSetupRsaCallback(std::shared_ptr<ssl_ctx_st>&)':
support.cc:(.text+0x6c9): undefined reference to `SSL_CTX_set_tmp_rsa_callback'
ssl/.libs/libsslsquid.a(support.o): In function `Ssl::matchX509CommonNames(x509_st*, void*, int (*)(void*, asn1_string_st*))':
support.cc:(.text+0x855): undefined reference to `sk_num'
support.cc:(.text+0x872): undefined reference to `sk_value'
support.cc:(.text+0x8c2): undefined reference to `sk_pop_free'
support.cc:(.text+0x8eb): undefined reference to `sk_pop_free'
ssl/.libs/libsslsquid.a(support.o): In function `ssl_verify_cb(int, x509_store_ctx_st*)':
support.cc:(.text+0x19be): undefined reference to `sk_pop_free'
ssl/.libs/libsslsquid.a(support.o): In function `ssl_free_CertChain(void*, void*, crypto_ex_data_st*, int, long, void*)':
support.cc:(.text+0x1ead): undefined reference to `sk_pop_free'
ssl/.libs/libsslsquid.a(support.o): In function `Ssl::Initialize()':
support.cc:(.text+0x2084): undefined reference to `SSL_get_ex_new_index'
support.cc:(.text+0x20b0): undefined reference to `SSL_CTX_get_ex_new_index'
support.cc:(.text+0x20df): undefined reference to `SSL_get_ex_new_index'
support.cc:(.text+0x210c): undefined reference to `SSL_get_ex_new_index'
support.cc:(.text+0x2139): undefined reference to `SSL_get_ex_new_index'
support.cc:(.text+0x2166): undefined reference to `SSL_get_ex_new_index'
support.cc:(.text+0x2193): undefined reference to `SSL_get_ex_new_index'
ssl/.libs/libsslsquid.a(support.o):support.cc:(.text+0x21c0): more undefined references to `SSL_get_ex_new_index' follow
ssl/.libs/libsslsquid.a(support.o): In function `sslGetUserCertificateChainPEM(ssl_st*)':
support.cc:(.text+0x2e23): undefined reference to `sk_value'
support.cc:(.text+0x2e4a): undefined reference to `sk_num'
ssl/.libs/libsslsquid.a(support.o): In function `hasAuthorityInfoAccessCaIssuers(x509_st*)':
support.cc:(.text+0x3aed): undefined reference to `sk_value'
support.cc:(.text+0x3b55): undefined reference to `sk_num'
ssl/.libs/libsslsquid.a(support.o): In function `Ssl::SSL_add_untrusted_cert(ssl_st*, x509_st*)':
support.cc:(.text+0x43cc): undefined reference to `sk_new_null'
support.cc:(.text+0x440a): undefined reference to `sk_pop_free'
support.cc:(.text+0x447b): undefined reference to `sk_push'
ssl/.libs/libsslsquid.a(support.o): In function `sk_x509_findIssuer(stack_st_X509*, x509_st*)':
support.cc:(.text+0x44c6): undefined reference to `sk_num'
support.cc:(.text+0x44e3): undefined reference to `sk_value'
ssl/.libs/libsslsquid.a(support.o): In function `completeIssuers(x509_store_ctx_st*, stack_st_X509*)':
support.cc:(.text+0x4604): undefined reference to `sk_num'
support.cc:(.text+0x4713): undefined reference to `sk_push'
ssl/.libs/libsslsquid.a(support.o): In function `untrustedToStoreCtx_cb(x509_store_ctx_st*, void*)':
support.cc:(.text+0x4949): undefined reference to `sk_dup'
support.cc:(.text+0x4967): undefined reference to `sk_value'
support.cc:(.text+0x497e): undefined reference to `sk_push'
support.cc:(.text+0x498e): undefined reference to `sk_num'
support.cc:(.text+0x49d4): undefined reference to `X509_STORE_CTX_set_chain'
support.cc:(.text+0x49f6): undefined reference to `X509_STORE_CTX_set_chain'
support.cc:(.text+0x4a02): undefined reference to `sk_free'
ssl/.libs/libsslsquid.a(support.o): In function `squid_OPENSSL_init_ssl()':
support.cc:(.text._Z24squid_OPENSSL_init_sslv[_Z24squid_OPENSSL_init_sslv]+0x5): undefined reference to `SSL_load_error_strings'
support.cc:(.text._Z24squid_OPENSSL_init_sslv[_Z24squid_OPENSSL_init_sslv]+0xa): undefined reference to `SSL_library_init'
ssl/.libs/libsslsquid.a(cert_validate_message.o): In function `Ssl::CertValidationMsg::composeRequest(Ssl::CertValidationRequest const&)':
cert_validate_message.cc:(.text+0x36a): undefined reference to `sk_value'
cert_validate_message.cc:(.text+0x51d): undefined reference to `sk_num'
cert_validate_message.cc:(.text+0x6e8): undefined reference to `sk_find'
ssl/.libs/libsslsquid.a(cert_validate_message.o): In function `Ssl::CertValidationMsg::parseResponse(Ssl::CertValidationResponse&, std::string&)':
cert_validate_message.cc:(.text+0x1440): undefined reference to `sk_value'
ssl/.libs/libsslutil.a(gadgets.o): In function `mimicAuthorityKeyId(Security::LockingPointer<x509_st, &Security::X509_free_cpp, HardFun<int, x509_st*, &X509_up_ref> >&, Security::LockingPointer<x509_st, &Security::X509_free_cpp, HardFun<int, x509_st*, &X509_up_ref> > const&, Security::LockingPointer<x509_st, &Security::X509_free_cpp, HardFun<int, x509_st*, &X509_up_ref> > const&)':
gadgets.cc:(.text+0x1276): undefined reference to `sk_new_null'
gadgets.cc:(.text+0x12da): undefined reference to `sk_push'
ssl/.libs/libsslutil.a(gadgets.o): In function `buildCertificate(Security::LockingPointer<x509_st, &Security::X509_free_cpp, HardFun<int, x509_st*, &X509_up_ref> >&, Ssl::CertificateProperties const&)':
gadgets.cc:(.text+0x1b24): undefined reference to `X509_set_notBefore'
gadgets.cc:(.text+0x1c30): undefined reference to `X509_set_notAfter'
ssl/.libs/libsslutil.a(gadgets.o): In function `Ssl::certificateMatchesProperties(x509_st*, Ssl::CertificateProperties const&)':
gadgets.cc:(.text+0x2db5): undefined reference to `sk_num'
gadgets.cc:(.text+0x2dd2): undefined reference to `sk_value'
gadgets.cc:(.text+0x2de9): undefined reference to `sk_find'
gadgets.cc:(.text+0x2e26): undefined reference to `sk_pop_free'
gadgets.cc:(.text+0x2e3c): undefined reference to `sk_pop_free'
ssl/.libs/libsslutil.a(gadgets.o): In function `Ssl::sk_GENERAL_NAME_free_wrapper::operator()(stack_st_GENERAL_NAME*)':
gadgets.cc:(.text._ZN3Ssl28sk_GENERAL_NAME_free_wrapperclEP21stack_st_GENERAL_NAME[_ZN3Ssl28sk_GENERAL_NAME_free_wrapperclEP21stack_st_GENERAL_NAME]+0x22): undefined reference to `sk_pop_free'
collect2: error: ld returned 1 exit status
libtool: link: rm -f ".libs/squidS.o"
make[3]: *** [Makefile:6356: squid] Error 1
make[3]: Leaving directory '/root/KrazyNetworks.com/squid-4.8/src'
make[2]: *** [Makefile:7126: all-recursive] Error 1
make[2]: Leaving directory '/root/KrazyNetworks.com/squid-4.8/src'
make[1]: *** [Makefile:6136: all] Error 2
make[1]: Leaving directory '/root/KrazyNetworks.com





gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/8/lto-wrapper
OFFLOAD_TARGET_NAMES=nvptx-none
OFFLOAD_TARGET_DEFAULT=1
Target: x86_64-redhat-linux
Configured with: ../configure --enable-bootstrap --enable-languages=c,c++,fortran,lto --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-shared --enable-threads=posix --enable-checking=release --enable-multilib --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-gcc-major-version-only --with-linker-hash-style=gnu --enable-plugin --enable-initfini-array --with-isl --disable-libmpx --enable-offload-targets=nvptx-none --without-cuda-driver --enable-gnu-indirect-function --enable-cet --with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linux
Thread model: posix
gcc version 8.5.0 20210514 (Red Hat 8.5.0-4) (GCC)








Is there any flag I need to pass for RH8/Centos8 so it compile older version of squid like 3.x and 4.5 ?


Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220502/95b0639f/attachment.htm>

From gkinkie at gmail.com  Mon May  2 21:26:05 2022
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Mon, 2 May 2022 22:26:05 +0100
Subject: [squid-users] squid3/4 compilation error with Centos8/RH8
In-Reply-To: <DBBPR09MB4523D1F69057A95715FB765DF7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>
References: <DBBPR09MB4523AAA561BE9E426382044AF7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>
 <006d01d85e56$88baede0$9a30c9a0$@gmail.com>
 <DBBPR09MB4523D1F69057A95715FB765DF7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>
Message-ID: <CA+Y8hcP3KpS1X9U-mpUeqY5YevUrxXwZC+165zfSxhVzDrGpDw@mail.gmail.com>

Hi,
   are you absolutely sure? Many configure options make no sense in the
context of squid - it doesn't contain any fortran code at all, and most
options would be ignored anyway. I'm also not sure about the nvptx-none
target, it seems related to offloading to GPUs and it's not anything squid
does.
  Assuming everything is mandatory, some of the errors seem to be due to
missing libraries (e.g. openssl). It's strange that it's been detected as
present by configure, it shouldn't have if then the library is missing


On Mon, May 2, 2022 at 8:05 PM Ahmad Alzaeem <0xff1f at gmail.com> wrote:

> Hello Eliezer Croitoru ,
>
> Thank you for your reply ,
>
>
>
> Indeed I need to build it from source with custom compile flags .
>
>
>
> Is there anyway to overcome the error I sent earlier ?
>
>
>
>
>
> Thanks
>
>
>
>
>
> *From: *squid-users <squid-users-bounces at lists.squid-cache.org> on behalf
> of Eliezer Croitoru <ngtech1ltd at gmail.com>
> *Date: *Monday, May 2, 2022 at 11:59 AM
> *To: *squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org
> >
> *Subject: *Re: [squid-users] squid3/4 compilation error with Centos8/RH8
>
> Try to use the next SRPM:
>
> https://www.ngtech.co.il/repo/centos/8/SRPMS/squid-4.17-8.el8.src.rpm
>
>
>
> Good Luck,
>
>
>
> ----
>
> Eliezer Croitoru
>
> NgTech, Tech Support
>
> Mobile: +972-5-28704261
>
> Email: ngtech1ltd at gmail.com
>
>
>
> *From:* squid-users <squid-users-bounces at lists.squid-cache.org> *On
> Behalf Of *Ahmad Alzaeem
> *Sent:* Monday, May 2, 2022 21:25
> *To:* squid-users at lists.squid-cache.org
> *Subject:* [squid-users] squid3/4 compilation error with Centos8/RH8
>
>
>
>
>
>
>
>
>
> Hello Team ,
>
> I found I only was able to build squid 5.x on Centos8/RH8 ?  (Not able to
> build 3.x or 4.x )
>
> I was able to build  squid 3.x and 4.x on RH7/Centos7 .
>
>
>
> It seems Its libssl error or so based on compilation error below (not sure
> if need to upgrade or downgrade GCC)
>
>
>
> //////
>
> cache_cf.o: In function `parseOneConfigFile(char const*, unsigned int)':
>
> cache_cf.cc:(.text+0x805): undefined reference to
> `Debug::Start[abi:cxx11](int, int)'
>
> cache_cf.cc:(.text+0xc2b): undefined reference to
> `Debug::Start[abi:cxx11](int, int)'
>
> cache_cf.cc:(.text+0xd78): undefined reference to
> `Debug::Start[abi:cxx11](int, int)'
>
> cache_cf.cc:(.text+0x10a4): undefined reference to
> `Debug::Start[abi:cxx11](int, int)'
>
> cache_cf.o: In function `parseConfigFileOrThrow(char const*)':
>
> cache_cf.cc:(.text+0x1295): undefined reference to
> `Debug::Start[abi:cxx11](int, int)'
>
> cache_cf.o:cache_cf.cc:(.text+0x142e): more undefined references to
> `Debug::Start[abi:cxx11](int, int)' follow
>
> cache_cf.o: In function `dump_acl(StoreEntry*, char const*, ACL*)':
>
> cache_cf.cc:(.text+0x3bc5): undefined reference to
> `ACL::dumpOptions[abi:cxx11]()'
>
> cache_cf.o: In function `parse_address(Ip::Address*)':
>
> cache_cf.cc:(.text+0x3f7a): undefined reference to
> `Debug::Start[abi:cxx11](int, int)'
>
> cache_cf.o: In function `parse_acl_tos(acl_tos**)':
>
> cache_cf.cc:(.text+0x432e): undefined reference to
> `Debug::Start[abi:cxx11](int, int)'
>
> cache_cf.o: In function `parse_http_header_access(HeaderManglers**)':
>
> cache_cf.cc:(.text+0x49d7): undefined reference to
> `Debug::Start[abi:cxx11](int, int)'
>
> cache_cf.cc:(.text+0x4a6d): undefined reference to
> `Debug::Start[abi:cxx11](int, int)'
>
> cache_cf.o: In function `parse_http_header_replace(HeaderManglers**)':
>
> cache_cf.cc:(.text+0x4cc5): undefined reference to
> `Debug::Start[abi:cxx11](int, int)'
>
> cache_cf.o:cache_cf.cc:(.text+0x4d5b): more undefined references to
> `Debug::Start[abi:cxx11](int, int)' follow
>
> client_side.o: In function `EVP_PKEY_up_ref':
>
> client_side.cc:(.text.EVP_PKEY_up_ref[EVP_PKEY_up_ref]+0x34): undefined
> reference to `CRYPTO_add_lock'
>
> client_side.o: In function `X509_up_ref':
>
> client_side.cc:(.text.X509_up_ref[X509_up_ref]+0x34): undefined reference
> to `CRYPTO_add_lock'
>
> anyp/.libs/libanyp.a(PortCfg.o): In function
> `Security::ServerOptions::sk_X509_NAME_free_wrapper::operator()(stack_st_X509_NAME*)':
>
> PortCfg.cc:(.text._ZN8Security13ServerOptions25sk_X509_NAME_free_wrapperclEP18stack_st_X509_NAME[_ZN8Security13ServerOptions25sk_X509_NAME_free_wrapperclEP18stack_st_X509_NAME]+0x22):
> undefined reference to `sk_pop_free'
>
> security/.libs/libsecurity.a(PeerOptions.o): In function
> `Security::PeerOptions::createBlankContext() const':
>
> PeerOptions.cc:(.text+0x1896): undefined reference to
> `SSLv23_client_method'
>
> security/.libs/libsecurity.a(ServerOptions.o): In function
> `Security::ServerOptions::createBlankContext() const':
>
> ServerOptions.cc:(.text+0xb4a): undefined reference to
> `SSLv23_server_method'
>
> security/.libs/libsecurity.a(ServerOptions.o): In function
> `X509_CRL_up_ref':
>
> ServerOptions.cc:(.text.X509_CRL_up_ref[X509_CRL_up_ref]+0x36): undefined
> reference to `CRYPTO_add_lock'
>
> security/.libs/libsecurity.a(Session.o): In function
> `tls_write_method(int, char const*, int)':
>
> Session.cc:(.text+0x677): undefined reference to `SSL_state'
>
> ssl/.libs/libsslsquid.a(support.o): In function
> `Ssl::MaybeSetupRsaCallback(std::shared_ptr<ssl_ctx_st>&)':
>
> support.cc:(.text+0x6c9): undefined reference to
> `SSL_CTX_set_tmp_rsa_callback'
>
> ssl/.libs/libsslsquid.a(support.o): In function
> `Ssl::matchX509CommonNames(x509_st*, void*, int (*)(void*,
> asn1_string_st*))':
>
> support.cc:(.text+0x855): undefined reference to `sk_num'
>
> support.cc:(.text+0x872): undefined reference to `sk_value'
>
> support.cc:(.text+0x8c2): undefined reference to `sk_pop_free'
>
> support.cc:(.text+0x8eb): undefined reference to `sk_pop_free'
>
> ssl/.libs/libsslsquid.a(support.o): In function `ssl_verify_cb(int,
> x509_store_ctx_st*)':
>
> support.cc:(.text+0x19be): undefined reference to `sk_pop_free'
>
> ssl/.libs/libsslsquid.a(support.o): In function `ssl_free_CertChain(void*,
> void*, crypto_ex_data_st*, int, long, void*)':
>
> support.cc:(.text+0x1ead): undefined reference to `sk_pop_free'
>
> ssl/.libs/libsslsquid.a(support.o): In function `Ssl::Initialize()':
>
> support.cc:(.text+0x2084): undefined reference to `SSL_get_ex_new_index'
>
> support.cc:(.text+0x20b0): undefined reference to
> `SSL_CTX_get_ex_new_index'
>
> support.cc:(.text+0x20df): undefined reference to `SSL_get_ex_new_index'
>
> support.cc:(.text+0x210c): undefined reference to `SSL_get_ex_new_index'
>
> support.cc:(.text+0x2139): undefined reference to `SSL_get_ex_new_index'
>
> support.cc:(.text+0x2166): undefined reference to `SSL_get_ex_new_index'
>
> support.cc:(.text+0x2193): undefined reference to `SSL_get_ex_new_index'
>
> ssl/.libs/libsslsquid.a(support.o):support.cc:(.text+0x21c0): more
> undefined references to `SSL_get_ex_new_index' follow
>
> ssl/.libs/libsslsquid.a(support.o): In function
> `sslGetUserCertificateChainPEM(ssl_st*)':
>
> support.cc:(.text+0x2e23): undefined reference to `sk_value'
>
> support.cc:(.text+0x2e4a): undefined reference to `sk_num'
>
> ssl/.libs/libsslsquid.a(support.o): In function
> `hasAuthorityInfoAccessCaIssuers(x509_st*)':
>
> support.cc:(.text+0x3aed): undefined reference to `sk_value'
>
> support.cc:(.text+0x3b55): undefined reference to `sk_num'
>
> ssl/.libs/libsslsquid.a(support.o): In function
> `Ssl::SSL_add_untrusted_cert(ssl_st*, x509_st*)':
>
> support.cc:(.text+0x43cc): undefined reference to `sk_new_null'
>
> support.cc:(.text+0x440a): undefined reference to `sk_pop_free'
>
> support.cc:(.text+0x447b): undefined reference to `sk_push'
>
> ssl/.libs/libsslsquid.a(support.o): In function
> `sk_x509_findIssuer(stack_st_X509*, x509_st*)':
>
> support.cc:(.text+0x44c6): undefined reference to `sk_num'
>
> support.cc:(.text+0x44e3): undefined reference to `sk_value'
>
> ssl/.libs/libsslsquid.a(support.o): In function
> `completeIssuers(x509_store_ctx_st*, stack_st_X509*)':
>
> support.cc:(.text+0x4604): undefined reference to `sk_num'
>
> support.cc:(.text+0x4713): undefined reference to `sk_push'
>
> ssl/.libs/libsslsquid.a(support.o): In function
> `untrustedToStoreCtx_cb(x509_store_ctx_st*, void*)':
>
> support.cc:(.text+0x4949): undefined reference to `sk_dup'
>
> support.cc:(.text+0x4967): undefined reference to `sk_value'
>
> support.cc:(.text+0x497e): undefined reference to `sk_push'
>
> support.cc:(.text+0x498e): undefined reference to `sk_num'
>
> support.cc:(.text+0x49d4): undefined reference to
> `X509_STORE_CTX_set_chain'
>
> support.cc:(.text+0x49f6): undefined reference to
> `X509_STORE_CTX_set_chain'
>
> support.cc:(.text+0x4a02): undefined reference to `sk_free'
>
> ssl/.libs/libsslsquid.a(support.o): In function `squid_OPENSSL_init_ssl()':
>
> *support.cc:(.text._Z24squid_OPENSSL_init_sslv[_Z24squid_OPENSSL_init_sslv]+0x5):
> undefined reference to `SSL_load_error_strings'*
>
> *support.cc:(.text._Z24squid_OPENSSL_init_sslv[_Z24squid_OPENSSL_init_sslv]+0xa):
> undefined reference to `SSL_library_init'*
>
> *ssl/.libs/libsslsquid.a(cert_validate_message.o): In function
> `Ssl::CertValidationMsg::composeRequest(Ssl::CertValidationRequest
> const&)':*
>
> *cert_validate_message.cc:(.text+0x36a): undefined reference to `sk_value'*
>
> *cert_validate_message.cc:(.text+0x51d): undefined reference to `sk_num'*
>
> *cert_validate_message.cc:(.text+0x6e8): undefined reference to `sk_find'*
>
> *ssl/.libs/libsslsquid.a(cert_validate_message.o): In function
> `Ssl::CertValidationMsg::parseResponse(Ssl::CertValidationResponse&,
> std::string&)':*
>
> *cert_validate_message.cc:(.text+0x1440): undefined reference to
> `sk_value'*
>
> *ssl/.libs/libsslutil.a(gadgets.o): In function
> `mimicAuthorityKeyId(Security::LockingPointer<x509_st,
> &Security::X509_free_cpp, HardFun<int, x509_st*, &X509_up_ref> >&,
> Security::LockingPointer<x509_st, &Security::X509_free_cpp, HardFun<int,
> x509_st*, &X509_up_ref> > const&, Security::LockingPointer<x509_st,
> &Security::X509_free_cpp, HardFun<int, x509_st*, &X509_up_ref> > const&)':*
>
> *gadgets.cc:(.text+0x1276): undefined reference to `sk_new_null'*
>
> *gadgets.cc:(.text+0x12da): undefined reference to `sk_push'*
>
> *ssl/.libs/libsslutil.a(gadgets.o): In function
> `buildCertificate(Security::LockingPointer<x509_st,
> &Security::X509_free_cpp, HardFun<int, x509_st*, &X509_up_ref> >&,
> Ssl::CertificateProperties const&)':*
>
> *gadgets.cc:(.text+0x1b24): undefined reference to `X509_set_notBefore'*
>
> *gadgets.cc:(.text+0x1c30): undefined reference to `X509_set_notAfter'*
>
> *ssl/.libs/libsslutil.a(gadgets.o): In function
> `Ssl::certificateMatchesProperties(x509_st*, Ssl::CertificateProperties
> const&)':*
>
> *gadgets.cc:(.text+0x2db5): undefined reference to `sk_num'*
>
> *gadgets.cc:(.text+0x2dd2): undefined reference to `sk_value'*
>
> *gadgets.cc:(.text+0x2de9): undefined reference to `sk_find'*
>
> *gadgets.cc:(.text+0x2e26): undefined reference to `sk_pop_free'*
>
> *gadgets.cc:(.text+0x2e3c): undefined reference to `sk_pop_free'*
>
> *ssl/.libs/libsslutil.a(gadgets.o): In function
> `Ssl::sk_GENERAL_NAME_free_wrapper::operator()(stack_st_GENERAL_NAME*)':*
>
> *gadgets.cc:(.text._ZN3Ssl28sk_GENERAL_NAME_free_wrapperclEP21stack_st_GENERAL_NAME[_ZN3Ssl28sk_GENERAL_NAME_free_wrapperclEP21stack_st_GENERAL_NAME]+0x22):
> undefined reference to `sk_pop_free'*
>
> collect2: error: ld returned 1 exit status
>
> libtool: link: rm -f ".libs/squidS.o"
>
> make[3]: *** [Makefile:6356: squid] Error 1
>
> make[3]: Leaving directory '/root/KrazyNetworks.com/squid-4.8/src'
>
> make[2]: *** [Makefile:7126: all-recursive] Error 1
>
> make[2]: Leaving directory '/root/KrazyNetworks.com/squid-4.8/src'
>
> make[1]: *** [Makefile:6136: all] Error 2
>
> make[1]: Leaving directory '/root/KrazyNetworks.com
>
>
>
>
>
>
>
>
>
>
>
> gcc -v
>
> Using built-in specs.
>
> COLLECT_GCC=gcc
>
> COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/8/lto-wrapper
>
> OFFLOAD_TARGET_NAMES=nvptx-none
>
> OFFLOAD_TARGET_DEFAULT=1
>
> Target: x86_64-redhat-linux
>
> Configured with: ../configure --enable-bootstrap
> --enable-languages=c,c++,fortran,lto --prefix=/usr --mandir=/usr/share/man
> --infodir=/usr/share/info --with-bugurl=
> http://bugzilla.redhat.com/bugzilla --enable-shared
> --enable-threads=posix --enable-checking=release --enable-multilib
> --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions
> --enable-gnu-unique-object --enable-linker-build-id
> --with-gcc-major-version-only --with-linker-hash-style=gnu --enable-plugin
> --enable-initfini-array --with-isl --disable-libmpx
> --enable-offload-targets=nvptx-none --without-cuda-driver
> --enable-gnu-indirect-function --enable-cet --with-tune=generic
> --with-arch_32=x86-64 --build=x86_64-redhat-linux
>
> Thread model: posix
>
> gcc version 8.5.0 20210514 (Red Hat 8.5.0-4) (GCC)
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> Is there any flag I need to pass for RH8/Centos8 so it compile older
> version of squid like 3.x and 4.5 ?
>
>
>
>
>
> Thanks
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
    Francesco
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220502/ef8a1635/attachment.htm>

From gkinkie at gmail.com  Tue May  3 06:35:55 2022
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Tue, 3 May 2022 07:35:55 +0100
Subject: [squid-users] squid5 Happy Eyeballs - Is it possible to enable
 IPV4 only or IPV6 only ?
In-Reply-To: <ebbbd3ef-1aca-1b25-79d2-4639cbf3dcf0@measurement-factory.com>
References: <DBBPR09MB45235081C0FC9CCD28D03101F7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>
 <ebbbd3ef-1aca-1b25-79d2-4639cbf3dcf0@measurement-factory.com>
Message-ID: <CA+Y8hcNeN_62rrV1bj7-MFHKyHcvi=8w82vN8rUK+DTizJGOWA@mail.gmail.com>

Could tcp_outgoing_address do the deed, forcing a certain source ip or
ipv4-only interface for some or all requests?

On Mon, 2 May 2022 at 16:39, Alex Rousskov <rousskov at measurement-factory.com>
wrote:

> On 5/1/22 23:49, Ahmad Alzaeem wrote:
>
> > sometime the IPV4
> > instance receive DNS resolution of the destination as IPV6 and the
> > connection fails !!
> >
> > sometimes the IPV4 instance receive the DNS resolution of the
> > destination as IPV6 and the connection fail .
> >
> > Is there any option we can do based on the environment above ?
>
>
> Without Squid code modifications, your options are:
>
> * Use a custom DNS resolver (configuration) that never sends IPv4
> address records to an IPv6-only Squid. Use a custom DNS resolver
> (configuration) that never sends IPv6 address records to an IPv4-only
> Squid. Configure each Squid to use the right resolver (see
> dns_nameservers).
>
> * Disable IPv6 support in IPv4-only Squid at ./configure time. This does
> not help with the IPv6-only Squid and has other negative side effects. I
> do not recommend this option.
>
>
>  > Like maybe we disable eyeballs or preserving it while add an option
>  > like DNS A records or DNS AAAA records .
>
> It would be possible to enhance Squid by adding a configuration option
> that disables (certain) A or AAAA queries, but proper modifications are
> not trivial and nobody has done them yet:
>
> https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F
>
>
> Cheers,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-- 
@mobile
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220503/13837c34/attachment.htm>

From roeeklinger60 at gmail.com  Tue May  3 10:12:50 2022
From: roeeklinger60 at gmail.com (roee klinger)
Date: Tue, 3 May 2022 13:12:50 +0300
Subject: [squid-users] Squid CONNECT tunnel
In-Reply-To: <3a49f7e2-528c-4924-a77b-8922719031ff@Spark>
References: <3a49f7e2-528c-4924-a77b-8922719031ff@Spark>
Message-ID: <de153461-f134-4b18-8cb1-6a3e59722bb8@Spark>

Hey,

I am trying to use Squid with FTP server?TCP Port Multiplexing, on the FRP documentation (https://github.com/fatedier/frp#tcp-port-multiplexing), it says:

> quote_type
> frp supports receiving TCP sockets directed to different proxies on a single port on frps, similar to vhost_http_port and vhost_https_port.
>
> The only supported TCP port multiplexing method available at the moment is httpconnect - HTTP CONNECT tunnel.
>
> When setting tcpmux_httpconnect_port to anything other than 0 in frps under [common], frps will listen on this port for HTTP CONNECT requests.
>
> The host of the HTTP CONNECT request will be used to match the proxy in frps. Proxy hosts can be configured in frpc by configuring custom_domain and / or subdomain under type = tcpmux proxies, when multiplexer = httpconnect.
>
> In the above configuration - frps can be contacted on port 1337 with a HTTP CONNECT header such as:
> CONNECT test1 HTTP/1.1\r\n\r\n
>
> and the connection will be routed to proxy1.


I have been struggling to find info about the use of CONNECT tunnels in Squid, the only page that seems to be talking about it is this:?https://wiki.squid-cache.org/Features/HTTPS, and the link it points to is broken.

My question is, how can I use this with Squid? Can I configure Squid to receive traffic and then send it out to FRP with a custom CONNECT header?

I am not sure if this is only good for web servers, or if upstream proxy servers can use this method too.


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220503/19fce61b/attachment.htm>

From rousskov at measurement-factory.com  Tue May  3 13:04:32 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 3 May 2022 09:04:32 -0400
Subject: [squid-users] squid5 Happy Eyeballs - Is it possible to enable
 IPV4 only or IPV6 only ?
In-Reply-To: <CA+Y8hcNeN_62rrV1bj7-MFHKyHcvi=8w82vN8rUK+DTizJGOWA@mail.gmail.com>
References: <DBBPR09MB45235081C0FC9CCD28D03101F7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>
 <ebbbd3ef-1aca-1b25-79d2-4639cbf3dcf0@measurement-factory.com>
 <CA+Y8hcNeN_62rrV1bj7-MFHKyHcvi=8w82vN8rUK+DTizJGOWA@mail.gmail.com>
Message-ID: <0abe197e-5ce5-9b9f-5624-8a5447705680@measurement-factory.com>

On 5/3/22 02:35, Francesco Chemolli wrote:
> Could tcp_outgoing_address do the deed, forcing a certain source ip or 
> ipv4-only interface for some or all requests?

No, not without Squid modifications[1]: Today, tcp_outgoing_address is 
consulted _after_ the address family is already decided for the current 
connection attempt (by the peer selection algorithms selecting a 
specific destination address). We can change that, of course, but 
probably not without some backward compatibility headaches.

[1] Unless, perhaps, one abuses tcp_outgoing_address to select an 
immediately failing source IP address (e.g., the one Squid cannot bind 
to?) as a way to force another attempt (hopefully using another address 
family). I do not know whether this hack would work, and suspect it 
would depend on which socket operation fails when using the special 
"force failure" source IP address.


HTH,

Alex.


> On Mon, 2 May 2022 at 16:39, Alex Rousskov wrote:
> 
>     On 5/1/22 23:49, Ahmad Alzaeem wrote:
> 
>      > sometime?the IPV4
>      > instance receive DNS resolution of the destination as IPV6 and the
>      > connection fails !!
>      >
>      > sometimes the IPV4 instance receive the DNS resolution of the
>      > destination as IPV6 and the connection fail .
>      >
>      > Is there any option we can do based on the environment above ?
> 
> 
>     Without Squid code modifications, your options are:
> 
>     * Use a custom DNS resolver (configuration) that never sends IPv4
>     address records to an IPv6-only Squid. Use a custom DNS resolver
>     (configuration) that never sends IPv6 address records to an IPv4-only
>     Squid. Configure each Squid to use the right resolver (see
>     dns_nameservers).
> 
>     * Disable IPv6 support in IPv4-only Squid at ./configure time. This
>     does
>     not help with the IPv6-only Squid and has other negative side
>     effects. I
>     do not recommend this option.
> 
> 
>      ?> Like maybe we disable eyeballs or preserving it while add an option
>      ?> like DNS A records or DNS AAAA records .
> 
>     It would be possible to enhance Squid by adding a configuration option
>     that disables (certain) A or AAAA queries, but proper modifications are
>     not trivial and nobody has done them yet:
>     https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F
>     <https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F>
> 
> 
>     Cheers,
> 
>     Alex.
> 
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>
> 
> -- 
> @mobile



From rousskov at measurement-factory.com  Tue May  3 13:09:05 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 3 May 2022 09:09:05 -0400
Subject: [squid-users] squid5 Happy Eyeballs - Is it possible to enable
 IPV4 only or IPV6 only ?
In-Reply-To: <0abe197e-5ce5-9b9f-5624-8a5447705680@measurement-factory.com>
References: <DBBPR09MB45235081C0FC9CCD28D03101F7C19@DBBPR09MB4523.eurprd09.prod.outlook.com>
 <ebbbd3ef-1aca-1b25-79d2-4639cbf3dcf0@measurement-factory.com>
 <CA+Y8hcNeN_62rrV1bj7-MFHKyHcvi=8w82vN8rUK+DTizJGOWA@mail.gmail.com>
 <0abe197e-5ce5-9b9f-5624-8a5447705680@measurement-factory.com>
Message-ID: <c7c710bd-097d-00d8-c993-392308a01b36@measurement-factory.com>

On 5/3/22 09:04, Alex Rousskov wrote:
> On 5/3/22 02:35, Francesco Chemolli wrote:
>> Could tcp_outgoing_address do the deed, forcing a certain source ip or 
>> ipv4-only interface for some or all requests?
> 
> No, not without Squid modifications[1]: Today, tcp_outgoing_address is 
> consulted _after_ the address family is already decided for the current 
> connection attempt (by the peer selection algorithms selecting a 
> specific destination address). We can change that, of course, but 
> probably not without some backward compatibility headaches.
> 
> [1] Unless, perhaps, one abuses tcp_outgoing_address to select an 
> immediately failing source IP address (e.g., the one Squid cannot bind 
> to?) as a way to force another attempt (hopefully using another address 
> family). I do not know whether this hack would work, and suspect it 
> would depend on which socket operation fails when using the special 
> "force failure" source IP address.


More ideas along those lines can be found on the following thread:
http://lists.squid-cache.org/pipermail/squid-users/2019-October/021186.html

Alex.



>> On Mon, 2 May 2022 at 16:39, Alex Rousskov wrote:
>>
>> ??? On 5/1/22 23:49, Ahmad Alzaeem wrote:
>>
>> ???? > sometime?the IPV4
>> ???? > instance receive DNS resolution of the destination as IPV6 and the
>> ???? > connection fails !!
>> ???? >
>> ???? > sometimes the IPV4 instance receive the DNS resolution of the
>> ???? > destination as IPV6 and the connection fail .
>> ???? >
>> ???? > Is there any option we can do based on the environment above ?
>>
>>
>> ??? Without Squid code modifications, your options are:
>>
>> ??? * Use a custom DNS resolver (configuration) that never sends IPv4
>> ??? address records to an IPv6-only Squid. Use a custom DNS resolver
>> ??? (configuration) that never sends IPv6 address records to an IPv4-only
>> ??? Squid. Configure each Squid to use the right resolver (see
>> ??? dns_nameservers).
>>
>> ??? * Disable IPv6 support in IPv4-only Squid at ./configure time. This
>> ??? does
>> ??? not help with the IPv6-only Squid and has other negative side
>> ??? effects. I
>> ??? do not recommend this option.
>>
>>
>> ???? ?> Like maybe we disable eyeballs or preserving it while add an 
>> option
>> ???? ?> like DNS A records or DNS AAAA records .
>>
>> ??? It would be possible to enhance Squid by adding a configuration 
>> option
>> ??? that disables (certain) A or AAAA queries, but proper 
>> modifications are
>> ??? not trivial and nobody has done them yet:
>>     
>> https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F 
>>
>>     
>> <https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F> 
>>
>>
>>
>> ??? Cheers,
>>
>> ??? Alex.
>>
>> ??? _______________________________________________
>> ??? squid-users mailing list
>> ??? squid-users at lists.squid-cache.org
>> ??? <mailto:squid-users at lists.squid-cache.org>
>> ??? http://lists.squid-cache.org/listinfo/squid-users
>> ??? <http://lists.squid-cache.org/listinfo/squid-users>
>>
>> -- 
>> @mobile
> 



From rousskov at measurement-factory.com  Tue May  3 13:30:10 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 3 May 2022 09:30:10 -0400
Subject: [squid-users] Squid CONNECT tunnel
In-Reply-To: <de153461-f134-4b18-8cb1-6a3e59722bb8@Spark>
References: <3a49f7e2-528c-4924-a77b-8922719031ff@Spark>
 <de153461-f134-4b18-8cb1-6a3e59722bb8@Spark>
Message-ID: <744812c5-a440-0a80-1b04-c388b7686160@measurement-factory.com>

On 5/3/22 06:12, roee klinger wrote:
> Hey,
> 
> I am trying to use Squid with FTP server TCP Port Multiplexing, on the 
> FRP documentation (https://github.com/fatedier/frp#tcp-port-multiplexing 
> <https://github.com/fatedier/frp#tcp-port-multiplexing>), it says:
> 
>     frp supports receiving TCP sockets directed to different proxies on
>     a single port on frps, similar to vhost_http_port and vhost_https_port.
> 
>     The only supported TCP port multiplexing method available at the
>     moment is httpconnect - HTTP CONNECT tunnel.
> 
>     When setting tcpmux_httpconnect_port to anything other than 0 in
>     frps under [common], frps will listen on this port for HTTP CONNECT
>     requests.
> 
>     The host of the HTTP CONNECT request will be used to match the proxy
>     in frps. Proxy hosts can be configured in frpc by configuring
>     custom_domain and / or subdomain under type = tcpmux proxies, when
>     multiplexer = httpconnect.
> 
>     In the above configuration - frps can be contacted on port 1337 with
>     a HTTP CONNECT header such as:
>     CONNECT test1 HTTP/1.1\r\n\r\n
> 
>     and the connection will be routed to proxy1.
> 
> 
> 
> I have been struggling to find info about the use of CONNECT tunnels in 
> Squid, the only page that seems to be talking about it is this: 
> https://wiki.squid-cache.org/Features/HTTPS 
> <https://wiki.squid-cache.org/Features/HTTPS>, and the link it points to 
> is broken.
> 
> My question is, how can I use this with Squid? Can I configure Squid to 
> receive traffic and then send it out to FRP with a custom CONNECT header?
> 
> I am not sure if this is only good for web servers, or if upstream proxy 
> servers can use this method too.

CONNECT is usually used for opening TCP tunnels through HTTP proxies. 
Squid uses CONNECT (only) when the HTTP protocol requires such use: 
Squid will send a CONNECT request if you configure Squid to talk to a 
configured cache_peer (without an originserver flag), provided Squid 
needs to open a TCP tunnel through that cache_peer.

Squid uses TCP tunnels in several cases. The most common use case is 
when Squid is forwarding a received CONNECT request (or an intercepted 
TLS connection) through a cache_peer.

I have not studied FRP documentation and do not know how it all maps to 
your specific use case, but if you can summarize your use case in basic 
FTP/HTTP/TLS terms (e.g. Squid receives FTP request X and should send 
HTTP request Y), we may be able to help you with Squid configuration.

Alex.


From roeeklinger60 at gmail.com  Wed May  4 16:30:05 2022
From: roeeklinger60 at gmail.com (roee klinger)
Date: Wed, 4 May 2022 19:30:05 +0300
Subject: [squid-users] Squid CONNECT tunnel
In-Reply-To: <744812c5-a440-0a80-1b04-c388b7686160@measurement-factory.com>
References: <3a49f7e2-528c-4924-a77b-8922719031ff@Spark>
 <de153461-f134-4b18-8cb1-6a3e59722bb8@Spark>
 <744812c5-a440-0a80-1b04-c388b7686160@measurement-factory.com>
Message-ID: <59f184fd-83f4-4c31-af87-9798d334f439@Spark>

Hey Alex,

Thanks for the reply.

Basically, I need to set up a cache_peer, and have all traffic to it be sent using CONNECT, and add an?HTTP CONNECT header such as:
CONNECT test1 HTTP/1.1\r\n\r\n .

Is that possible with Squid?

Thanks,

On 3 May 2022, 16:30 +0300, Alex Rousskov <rousskov at measurement-factory.com>, wrote:
> On 5/3/22 06:12, roee klinger wrote:
> > Hey,
> >
> > I am trying to use Squid with FTP server TCP Port Multiplexing, on the
> > FRP documentation (https://github.com/fatedier/frp#tcp-port-multiplexing
> > <https://github.com/fatedier/frp#tcp-port-multiplexing>), it says:
> >
> > frp supports receiving TCP sockets directed to different proxies on
> > a single port on frps, similar to vhost_http_port and vhost_https_port.
> >
> > The only supported TCP port multiplexing method available at the
> > moment is httpconnect - HTTP CONNECT tunnel.
> >
> > When setting tcpmux_httpconnect_port to anything other than 0 in
> > frps under [common], frps will listen on this port for HTTP CONNECT
> > requests.
> >
> > The host of the HTTP CONNECT request will be used to match the proxy
> > in frps. Proxy hosts can be configured in frpc by configuring
> > custom_domain and / or subdomain under type = tcpmux proxies, when
> > multiplexer = httpconnect.
> >
> > In the above configuration - frps can be contacted on port 1337 with
> > a HTTP CONNECT header such as:
> > CONNECT test1 HTTP/1.1\r\n\r\n
> >
> > and the connection will be routed to proxy1.
> >
> >
> >
> > I have been struggling to find info about the use of CONNECT tunnels in
> > Squid, the only page that seems to be talking about it is this:
> > https://wiki.squid-cache.org/Features/HTTPS
> > <https://wiki.squid-cache.org/Features/HTTPS>, and the link it points to
> > is broken.
> >
> > My question is, how can I use this with Squid? Can I configure Squid to
> > receive traffic and then send it out to FRP with a custom CONNECT header?
> >
> > I am not sure if this is only good for web servers, or if upstream proxy
> > servers can use this method too.
>
> CONNECT is usually used for opening TCP tunnels through HTTP proxies.
> Squid uses CONNECT (only) when the HTTP protocol requires such use:
> Squid will send a CONNECT request if you configure Squid to talk to a
> configured cache_peer (without an originserver flag), provided Squid
> needs to open a TCP tunnel through that cache_peer.
>
> Squid uses TCP tunnels in several cases. The most common use case is
> when Squid is forwarding a received CONNECT request (or an intercepted
> TLS connection) through a cache_peer.
>
> I have not studied FRP documentation and do not know how it all maps to
> your specific use case, but if you can summarize your use case in basic
> FTP/HTTP/TLS terms (e.g. Squid receives FTP request X and should send
> HTTP request Y), we may be able to help you with Squid configuration.
>
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220504/bc73bcd8/attachment.htm>

From rousskov at measurement-factory.com  Wed May  4 16:47:03 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 4 May 2022 12:47:03 -0400
Subject: [squid-users] Squid CONNECT tunnel
In-Reply-To: <59f184fd-83f4-4c31-af87-9798d334f439@Spark>
References: <3a49f7e2-528c-4924-a77b-8922719031ff@Spark>
 <de153461-f134-4b18-8cb1-6a3e59722bb8@Spark>
 <744812c5-a440-0a80-1b04-c388b7686160@measurement-factory.com>
 <59f184fd-83f4-4c31-af87-9798d334f439@Spark>
Message-ID: <10874a92-369f-df49-c080-1cb0afd53c7f@measurement-factory.com>

On 5/4/22 12:30, roee klinger wrote:

> Basically, I need to set up a cache_peer, and have all traffic to it be 
> sent using CONNECT, and add an?HTTP CONNECT header such as:
> CONNECT test1 HTTP/1.1\r\n\r\n .

> Is that possible with Squid?

Squid can be configured to forward all http_port and https_port traffic 
to a cache_peer. The same may be true for ftp_port, but I am not sure.

However, Squid cannot be configured to forward "all traffic" (i.e. all 
protocols and all protocol commands) using the CONNECT request method 
specifically. For example, plain HTTP GET requests received on an 
http_port will be forwarded using the GET method, not CONNECT.

Furthermore, it would be difficult (and probably wrong) to rewrite the 
destination of all requests to "test1". In most cases, a request going 
to origin server A should look different than a request going to origin 
server B. However, I am not sure whether "test1" in your template was a 
constant that should not be changed across requests.

Finally, I doubt that you actually need to forward _all_ traffic using 
CONNECT tunnels. You probably need to forward some specific requests. 
For that (unknown to me) subset of requests, Squid may (or may not) use 
CONNECT when talking to a configured cache_peer.

Alex.


> On 3 May 2022, 16:30 +0300, Alex Rousskov wrote:
>> On 5/3/22 06:12, roee klinger wrote:
>>> Hey,
>>>
>>> I am trying to use Squid with FTP server TCP Port Multiplexing, on the
>>> FRP documentation (https://github.com/fatedier/frp#tcp-port-multiplexing
>>> <https://github.com/fatedier/frp#tcp-port-multiplexing>), it says:
>>>
>>> frp supports receiving TCP sockets directed to different proxies on
>>> a single port on frps, similar to vhost_http_port and vhost_https_port.
>>>
>>> The only supported TCP port multiplexing method available at the
>>> moment is httpconnect - HTTP CONNECT tunnel.
>>>
>>> When setting tcpmux_httpconnect_port to anything other than 0 in
>>> frps under [common], frps will listen on this port for HTTP CONNECT
>>> requests.
>>>
>>> The host of the HTTP CONNECT request will be used to match the proxy
>>> in frps. Proxy hosts can be configured in frpc by configuring
>>> custom_domain and / or subdomain under type = tcpmux proxies, when
>>> multiplexer = httpconnect.
>>>
>>> In the above configuration - frps can be contacted on port 1337 with
>>> a HTTP CONNECT header such as:
>>> CONNECT test1 HTTP/1.1\r\n\r\n
>>>
>>> and the connection will be routed to proxy1.
>>>
>>>
>>>
>>> I have been struggling to find info about the use of CONNECT tunnels in
>>> Squid, the only page that seems to be talking about it is this:
>>> https://wiki.squid-cache.org/Features/HTTPS
>>> <https://wiki.squid-cache.org/Features/HTTPS>, and the link it points to
>>> is broken.
>>>
>>> My question is, how can I use this with Squid? Can I configure Squid to
>>> receive traffic and then send it out to FRP with a custom CONNECT header?
>>>
>>> I am not sure if this is only good for web servers, or if upstream proxy
>>> servers can use this method too.
>>
>> CONNECT is usually used for opening TCP tunnels through HTTP proxies.
>> Squid uses CONNECT (only) when the HTTP protocol requires such use:
>> Squid will send a CONNECT request if you configure Squid to talk to a
>> configured cache_peer (without an originserver flag), provided Squid
>> needs to open a TCP tunnel through that cache_peer.
>>
>> Squid uses TCP tunnels in several cases. The most common use case is
>> when Squid is forwarding a received CONNECT request (or an intercepted
>> TLS connection) through a cache_peer.
>>
>> I have not studied FRP documentation and do not know how it all maps to
>> your specific use case, but if you can summarize your use case in basic
>> FTP/HTTP/TLS terms (e.g. Squid receives FTP request X and should send
>> HTTP request Y), we may be able to help you with Squid configuration.
>>
>> Alex.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users



From mail at frank-urban.de  Thu May  5 09:28:13 2022
From: mail at frank-urban.de (Frank Urban)
Date: Thu, 5 May 2022 11:28:13 +0200
Subject: [squid-users] acl question
Message-ID: <CAGmSoH=QfeTbBTv+puSb=a7q0k1mzXrnxdaF4pjgZoFemDdCww@mail.gmail.com>

Hi,

We created an acl list with workstation names instead of IP addresses.

e.g. acl our_networks src workstaion1.

This works as long as the hostname is resolvable over DNS. If it is
not, the restart of squid fails.

Is this the expected result?

Best regards

Frank


From Antony.Stone at squid.open.source.it  Thu May  5 09:34:52 2022
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 5 May 2022 11:34:52 +0200
Subject: [squid-users] acl question
In-Reply-To: <CAGmSoH=QfeTbBTv+puSb=a7q0k1mzXrnxdaF4pjgZoFemDdCww@mail.gmail.com>
References: <CAGmSoH=QfeTbBTv+puSb=a7q0k1mzXrnxdaF4pjgZoFemDdCww@mail.gmail.com>
Message-ID: <202205051134.53456.Antony.Stone@squid.open.source.it>

On Thursday 05 May 2022 at 11:28:13, Frank Urban wrote:

> Hi,
> 
> We created an acl list with workstation names instead of IP addresses.
> 
> e.g. acl our_networks src workstaion1.
> 
> This works as long as the hostname is resolvable over DNS. If it is
> not, the restart of squid fails.
> 
> Is this the expected result?

Yes.  How would Squid be expected to know what RandomWorkstation means if it 
can't look it up in DNS?


Antony.

-- 
The gravitational attraction exerted by a single doctor at a distance of 6 
inches is roughly twice that of Jupiter at its closest point to the Earth.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From Ralf.Hildebrandt at charite.de  Thu May  5 12:24:16 2022
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Thu, 5 May 2022 14:24:16 +0200
Subject: [squid-users] OT: calamaris log parsing...
Message-ID: <YnPB8DYGH0Tll3vL@charite.de>

Bit of an OT question here...I'm using calamaris and was wondering
about the traffic direction:

# Performance in 1 hour steps
                                incomin    hit    miss   direct sibling  fetch  
date             request   Byte kB/sec  kB/sec  kB/sec  kB/sec  kB/sec kB/sec  
--------------- --------- ----- ------- ------- ------- ------- ------- ------- 
30.Apr 22 09:00         9   19G 1451.91     -   1451.91 1451.91     -   -   

Is there a way of seeing both incoming AND outgoing for a client?
I want to know if that client downloaded from the internet or uploaded
to the internet...

Ralf Hildebrandt
Charit? - Universit?tsmedizin Berlin
Gesch?ftsbereich IT | Abteilung Netzwerk

Campus Benjamin Franklin (CBF)
Haus I | 1. OG | Raum 105
Hindenburgdamm 30 | D-12203 Berlin

Tel. +49 30 450 570 155
ralf.hildebrandt at charite.de
https://www.charite.de


From squid3 at treenet.co.nz  Thu May  5 12:33:37 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 6 May 2022 00:33:37 +1200
Subject: [squid-users] OT: calamaris log parsing...
In-Reply-To: <YnPB8DYGH0Tll3vL@charite.de>
References: <YnPB8DYGH0Tll3vL@charite.de>
Message-ID: <b2d1338e-3117-cc3e-35c6-84c71c1a5460@treenet.co.nz>

On 6/05/22 00:24, Ralf Hildebrandt wrote:
> Bit of an OT question here...I'm using calamaris and was wondering
> about the traffic direction:
> 
> # Performance in 1 hour steps
>                                  incomin    hit    miss   direct sibling  fetch
> date             request   Byte kB/sec  kB/sec  kB/sec  kB/sec  kB/sec kB/sec
> --------------- --------- ----- ------- ------- ------- ------- ------- -------
> 30.Apr 22 09:00         9   19G 1451.91     -   1451.91 1451.91     -   -
> 
> Is there a way of seeing both incoming AND outgoing for a client?

Yes. See the '<st' code under "SIZE COUNTERS" at 
<http://www.squid-cache.org/Doc/config/logformat/>


Amos


From manikandan.swaminathan at veeva.com  Fri May  6 01:33:08 2022
From: manikandan.swaminathan at veeva.com (Manikandan Swaminathan)
Date: Thu, 5 May 2022 20:33:08 -0500
Subject: [squid-users] Squid Reconfigure Downtime
Message-ID: <CA+q2tJbGS+2nApm0dcMPo0fer0L9w9kvJRgQJLHUkW6xeTd+FQ@mail.gmail.com>

Hello,

I'm new to Squid and am currently researching the use/effects of running
reconfigurations. I've come across a couple links and forums that talk
about this, but since some of those are a bit dated I wanted to make sure I
have the right info...

We're currently running Squid 4.8, and I want to know, what is the expected
downtime when running "squid -k reconfigure"? How does this affect existing
and incoming connections?

I ran a simple test in my machine where I reconfigure squid, while
separately running multiple proxy requests. As far as I could tell, there
wasn't any disruption, but I'd like to get some input from more experienced
folks.

Thanks,
Mani
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220505/127772bf/attachment.htm>

From chad at chadphillips.org  Fri May  6 03:56:27 2022
From: chad at chadphillips.org (chad phillips)
Date: Thu, 5 May 2022 22:56:27 -0500
Subject: [squid-users] How can I rewrite urls?
Message-ID: <CAFL4EPotR+BbgQNuL-O7QJOKOKmkyy64Opg8o77Pgvn8vTOT5Q@mail.gmail.com>

Hi,

I have squid setup as a proxy.  I would like to rewrite requests that go
through squid.
example:  the browser requests www.example.com, I want to rewrite that to
dev-www.example.com

The idea is the user requests www.example.com, but Squid actually proxies
them to dev-www.example.com.

I believe this is possible, but was hoping someone could point me in the
right direction.  I have looked through the documentation, but guess I am
missing it.

thank you
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220505/5d3f5583/attachment.htm>

From ngtech1ltd at gmail.com  Fri May  6 09:43:55 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Fri, 6 May 2022 12:43:55 +0300
Subject: [squid-users] Squid Reconfigure Downtime
In-Reply-To: <CA+q2tJbGS+2nApm0dcMPo0fer0L9w9kvJRgQJLHUkW6xeTd+FQ@mail.gmail.com>
References: <CA+q2tJbGS+2nApm0dcMPo0fer0L9w9kvJRgQJLHUkW6xeTd+FQ@mail.gmail.com>
Message-ID: <001401d8612d$ce568970$6b039c50$@gmail.com>

Hey Mani,

 

With ?squid -k reconfigure? there shouldn?t be down time.

There are special scenarios which the complexity or the length of the configuration files will result
in a scenario of a slowdown in the overall performance of the service on a reconfiguration.

There is a very far possibility which will cause a drop of connections while running the reconfiguration.

I will define a rule: if ?squid -k parse? doesn?t take too long ( max couple secs..which is a lot for most use cases)
it?s simple to assume that it won?t affect the service at all.

 

Just take into account that the proper ?ratio? of reconfiguration should be no more then once per hour and 
the most widely used reconfiguration is once per day.

 

If you will want to make the service dynamic you can use external_acl and other helpers that will allow you
to prevent and reconfiguration of the service when not really required.

 

All The Bests,

 

----

Eliezer Croitoru

NgTech, Tech Support

Mobile: +972-5-28704261

Email:  <mailto:ngtech1ltd at gmail.com> ngtech1ltd at gmail.com

 

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Manikandan Swaminathan
Sent: Friday, May 6, 2022 04:33
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid Reconfigure Downtime

 

Hello,

 

I'm new to Squid and am currently researching the use/effects of running reconfigurations. I've come across a couple links and forums that talk about this, but since some of those are a bit dated I wanted to make sure I have the right info...

 

We're currently running Squid 4.8, and I want to know, what is the expected downtime when running "squid -k reconfigure"? How does this affect existing and incoming connections?

 

I ran a simple test in my machine where I reconfigure squid, while separately running multiple proxy requests. As far as I could tell, there wasn't any disruption, but I'd like to get some input from more experienced folks.

 

Thanks,

Mani

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220506/69be616b/attachment.htm>

From rousskov at measurement-factory.com  Fri May  6 13:23:02 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 6 May 2022 09:23:02 -0400
Subject: [squid-users] Squid Reconfigure Downtime
In-Reply-To: <CA+q2tJbGS+2nApm0dcMPo0fer0L9w9kvJRgQJLHUkW6xeTd+FQ@mail.gmail.com>
References: <CA+q2tJbGS+2nApm0dcMPo0fer0L9w9kvJRgQJLHUkW6xeTd+FQ@mail.gmail.com>
Message-ID: <86dc5d95-0718-ac21-22a6-e2f80cb6ac50@measurement-factory.com>

On 5/5/22 21:33, Manikandan Swaminathan wrote:

> We're currently running Squid 4.8, and I want to know, what is the 
> expected downtime when running "squid -k reconfigure"? 

The actual delay depends on many variables, including the definition of 
"downtime". Very roughly speaking, reconfiguration today can be almost 
as heavy/slow (or as light/fast) as starting Squid from scratch. Certain 
startup actions (e.g., building an in-memory index of cache_dirs) are 
skipped during reconfigurations, and some optimizations (e.g., various 
internal caches) continue to work through reconfigurations, but a lot of 
heavy startup actions are performed during reconfigurations as well.


> How does this affect existing and incoming connections?

Most existing connections, especially short-lived ones, are usually 
unaffected when the configuration does not change much. IIRC, new 
incoming connections may be rejected during reconfiguration (in some 
cases). The code is not written to guarantee much: Squid does _not_ 
maintain a consistent configuration state during (re)configuration. YMMV.


> I ran a simple test in my machine where I reconfigure squid, while 
> separately running multiple proxy requests. As far as I could tell, 
> there wasn't any disruption, but I'd like to get some input from more 
> experienced folks.

Your test did not expose existing problems. I do not know how much those 
problems are going to affect your deployment environment.


FWIW, we have an ongoing "smooth reconfiguration" project that makes 
Squid reconfigure just the changed configuration directives, without 
disrupting traffic. It will take a while to cover all configuration 
directives, but I hope to see the first pull requests that cover some 
directives soon.


HTH,

Alex.


From psa at cdot.in  Tue May 10 05:33:14 2022
From: psa at cdot.in (Punyasloka Arya)
Date: Tue, 10 May 2022 12:03:14 +0630
Subject: [squid-users] Squid load simulation tools for performance testing
Message-ID: <20220510053206.M8842@cdot.in>


Dear ALL,

We have just installed Squid 5.5 (stable version) from source on ubuntu 
20.0.4.
Before putting in the production network, we want to test the performance of 
squid by monitoring critical parameters like response time,  cache hits, cache 
misses etc
We would like to know tools/software/scripts to simulate load conditions for 
500 users with at least 1K connections.

Any help is greatly appreciated.

From
Punyasloka Arya
PUNYASLOKA ARYA            ?????????? ????? 
Staffno:3880,Netops,TS(B) 
Senior Research Engineer   ?????? ???????? ??????? 
C-DOT                      ??-???                     
Electronics City,Phase-1   ?????????????? ???? ???? I         
Hosur Road,Bangalore       ????? ???, ???????? 
560100                     560100 
### Please consider the environment and print this email only if necessary 
. 
Go Green ###

Disclaimer :
This email and any files transmitted with it are confidential and intended
solely for the use of the individual or entity to whom they are addressed.
If you are not the intended recipient you are notified that disclosing,
copying, distributing or taking any action in reliance on the contents of 
this
information is strictly prohibited. The sender does not accept liability
for any errors or omissions in the contents of this message, which arise 
as 
a
result.

--
Open WebMail Project (http://openwebmail.org)



From ngtech1ltd at gmail.com  Wed May 11 05:14:15 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Wed, 11 May 2022 08:14:15 +0300
Subject: [squid-users] Thinking out loud about "applications" definition
 for squid
In-Reply-To: <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAAdp827zbIBEnsSKBEnN0i4BAAAAAA==@gmail.com>
References: <!&!AAAAAAAAAAAYAAAAAAAAAG15AYh8TcJOh7jZfP/beGvCgAAAEAAAAAdp827zbIBEnsSKBEnN0i4BAAAAAA==@gmail.com>
Message-ID: <000001d864f5$f689c9e0$e39d5da0$@gmail.com>

OK so, an update.
I wrote a basic application that does just the basic features.

I am looking for someone that want's to help me enhance the feature.

Thanks,
Eliezer

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com

-----Original Message-----
From: Eliezer Croitoru <ngtech1ltd at gmail.com> 
Sent: Sunday, March 27, 2022 04:33
To: squid-users at lists.squid-cache.org
Subject: Thinking out loud about "applications" definition for squid

Hey,

I have been thinking about defining a specific way that will tag connections
with an APP ID for simplicity.
For example I have just seen couple support websites of web systems vendors
that provide their domains and ip addresses.
The basic example would be:
https://help.pluralsight.com/help/ip-allowlist

Which provides the next basic info:
*.pluralsight.com
*.typekit.com

# Video CDN
vid.pluralsight.com
vid5.pluralsight.com
vid20.pluralsight.com
vid21.pluralsight.com
vid30.pluralsight.com

# Excertises files
ip-video-course-exercise-files-us-west-2.s3.us-west-2.amazonaws.com

So it means that technically if I have this defined somewhere I can run an
external acl helper that will get all the details of the request and will
tag
the request and/or connection with an APP ID that can be allowed or denied
by the next external acl helper in the pipe line.
The next access log:
https://www.ngtech.co.il/squid/pluralsight-access-log.txt

is a bit redacted but still contains the relevant log lines.

So the relevant ACL options are:
http_access Allow/deny
TLS Splice/bump
Dst_ip - APP ID
Src_ip - Allow/Deny/others
Cache allow/deny
 
I would assume that every request with the dstdomain:
.pluralsight.com
ip-video-course-exercise-files-us-west-2.s3.us-west-2.amazonaws.com

Or SNI regex:
\.pluralsight\.com$
^ip-video-course-exercise-files-us-west-2\.s3\.us-west-2\.amazonaws\.com$

Should 100% be tagged with a pluralsight APP ID tag.

It would be a similar idea with goolge/gmail/Microsoft/AV/others
And since it's a very simple and re-producible APP ID tagging technique it
can be simplified into a set of helpers.

So first, what do you as a squid user think about it?
Can you and others help me work on a simple project that will help with this
specific idea?
A list of applications ID might be a good starter for the first
POC/Development process.

One place I have seen a similar implementation would be:
https://github.com/ntop/nDPI/blob/dev/src/include/ndpi_protocol_ids.h

I think that the goal would be that it would be possible to use an API that
will be able to change a rule or a ruleset per client paired with a
protocol.
Much like in a FW rules the helper would be able to run a query against a
small embedded json/other dbase/base that will contain all the relevant
details of the apps
And another part of it would be to contain the ruleset itself.

So for example a definition of:
Match: client, appID, verdict(allow/deny)
Match: client, appID, verdict(bump/splice)
Match: dst, appID, verdict(allow/deny)..

Would be pretty simple to define by the proxy admin.

Let me know how can you help with this project.

Thanks,
Eliezer

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com




From max.allan at surevine.com  Thu May 12 10:46:48 2022
From: max.allan at surevine.com (Max Allan)
Date: Thu, 12 May 2022 11:46:48 +0100
Subject: [squid-users] WARNING: All 32/32 ssl_crtd processes are busy -
 where next?
Message-ID: <CADNp1BZryxiEfs1UvQbjEWed3RyLvx1KJZfKwebepRhXO30NdQ@mail.gmail.com>

Hi,
I have squid setup to log all requests for security reasons.
When doing an npm install, npm sometimes gets a connection reset error
and fails.
In the cache log, I can see many messages like :

2022/05/12 09:20:00 kid1| helperOpenServers: Starting 1/32 'ssl_crtd' processes
2022/05/12 09:20:00 kid1| WARNING: All 32/32 ssl_crtd processes are busy.
2022/05/12 09:20:00 kid1| WARNING: 32 pending requests queued
2022/05/12 09:20:00 kid1| WARNING: Consider increasing the number of
ssl_crtd processes in your config file.
2022/05/12 09:20:00 kid1| Queue overload, rejecting
2022/05/12 09:20:00 kid1| Queue overload, rejecting
(with 100s of queue overloads)

BUT http://www.squid-cache.org/Versions/v3/3.5/cfgman/sslcrtd_children.html
says the maximum safe value is 32. Later versions don't allow values over 32.
(I'm on 3.5)

So, where do I go from here??

What is the "unsafe" worst case? Packet loss, high server load, squid
crashing out, etc..?

I did increase it to 64 and the idle to 5 so far haven't seen one of
the failures from npm, but my cache log still shows :

2022/05/12 10:14:30 kid1| helperOpenServers: Starting 5/64 'ssl_crtd' processes
2022/05/12 10:14:30 kid1| Starting new ssl_crtd helpers...
2022/05/12 10:14:30 kid1| helperOpenServers: Starting 4/64 'ssl_crtd' processes
2022/05/12 10:14:44 kid1| WARNING: All 64/64 ssl_crtd processes are busy.
2022/05/12 10:14:44 kid1| WARNING: 64 pending requests queued
2022/05/12 10:14:44 kid1| WARNING: Consider increasing the number of
ssl_crtd processes in your config file.
2022/05/12 10:14:44 kid1| Queue overload, rejecting
2022/05/12 10:14:44 kid1| Queue overload, rejecting

Which queue do I increase to prevent the overload? Squid is configured
without any auth, mostly ACL and ssl setup.


Thanks


From 0xff1f at gmail.com  Fri May 13 13:12:46 2022
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Fri, 13 May 2022 13:12:46 +0000
Subject: [squid-users] is there a way to tell squid to write external ip
 even that external ip not attached into the machine ?
Message-ID: <DBBPR09MB452360B6B9D0085134CB738CF7CA9@DBBPR09MB4523.eurprd09.prod.outlook.com>


Hello Guys ,
We are testing squid with a project such as we need squid to write and proceed with tcp_outgoing address address even its not attached to the machine by ifconfig or ip add  ?

After some tests we found that squid wont write the external Ip to be pushed out the network card interface if the ip address is not added to the machine .

Is there anyway to bypass this checkout and let squid ignore checking the external ips if attached or not attached ?
Not sure if from config or may be editing src files .


Many Thanks



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220513/7373c4e3/attachment.htm>

From ngtech1ltd at gmail.com  Fri May 13 15:19:22 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Fri, 13 May 2022 18:19:22 +0300
Subject: [squid-users] is there a way to tell squid to write external ip
 even that external ip not attached into the machine ?
In-Reply-To: <DBBPR09MB452360B6B9D0085134CB738CF7CA9@DBBPR09MB4523.eurprd09.prod.outlook.com>
References: <DBBPR09MB452360B6B9D0085134CB738CF7CA9@DBBPR09MB4523.eurprd09.prod.outlook.com>
Message-ID: <000001d866dc$d38a63d0$7a9f2b70$@gmail.com>

Hey Ahmad,

 

You should use a tproxy port with a PROXY protocol support and acls.

With these you can try to push traffic to the network from a local process
that will write the right details to squid that will generate a fake source
ip.


And since you have asked I assume you are not familiar enough with this kind
of setup so it's crucial you will understand what are doing
before trying and testing it since at might not work as you expect.

 

All The Bests,

Eliezer

 

----

Eliezer Croitoru

NgTech, Tech Support

Mobile: +972-5-28704261

Email:  <mailto:ngtech1ltd at gmail.com> ngtech1ltd at gmail.com

 

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
Ahmad Alzaeem
Sent: Friday, May 13, 2022 16:13
To: squid-users at lists.squid-cache.org; Amos Jeffries <squid3 at treenet.co.nz>
Subject: [squid-users] is there a way to tell squid to write external ip
even that external ip not attached into the machine ?

 

 

Hello Guys ,

We are testing squid with a project such as we need squid to write and
proceed with tcp_outgoing address address even its not attached to the
machine by ifconfig or ip add  ?

 

After some tests we found that squid wont write the external Ip to be pushed
out the network card interface if the ip address is not added to the machine
.

 

Is there anyway to bypass this checkout and let squid ignore checking the
external ips if attached or not attached ?

Not sure if from config or may be editing src files .

 

 

Many Thanks 

 

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220513/4e0d8fdf/attachment.htm>

From 0xff1f at gmail.com  Fri May 13 15:33:35 2022
From: 0xff1f at gmail.com (Ahmad Alzaeem)
Date: Fri, 13 May 2022 15:33:35 +0000
Subject: [squid-users] is there a way to tell squid to write external ip
 even that external ip not attached into the machine ?
In-Reply-To: <000001d866dc$d38a63d0$7a9f2b70$@gmail.com>
References: <DBBPR09MB452360B6B9D0085134CB738CF7CA9@DBBPR09MB4523.eurprd09.prod.outlook.com>
 <000001d866dc$d38a63d0$7a9f2b70$@gmail.com>
Message-ID: <DBBPR09MB4523C855C120CC5551E7EF72F7CA9@DBBPR09MB4523.eurprd09.prod.outlook.com>

Hello Eliezer
I thought it could be done by editing squid src file  like to skip inet address lookup .

Thanks


From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Eliezer Croitoru <ngtech1ltd at gmail.com>
Date: Friday, May 13, 2022 at 8:21 AM
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] is there a way to tell squid to write external ip even that external ip not attached into the machine ?
Hey Ahmad,

You should use a tproxy port with a PROXY protocol support and acls.
With these you can try to push traffic to the network from a local process that will write the right details to squid that will generate a fake source ip.

And since you have asked I assume you are not familiar enough with this kind of setup so it?s crucial you will understand what are doing
before trying and testing it since at might not work as you expect.

All The Bests,
Eliezer

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com<mailto:ngtech1ltd at gmail.com>

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Ahmad Alzaeem
Sent: Friday, May 13, 2022 16:13
To: squid-users at lists.squid-cache.org; Amos Jeffries <squid3 at treenet.co.nz>
Subject: [squid-users] is there a way to tell squid to write external ip even that external ip not attached into the machine ?


Hello Guys ,
We are testing squid with a project such as we need squid to write and proceed with tcp_outgoing address address even its not attached to the machine by ifconfig or ip add  ?

After some tests we found that squid wont write the external Ip to be pushed out the network card interface if the ip address is not added to the machine .

Is there anyway to bypass this checkout and let squid ignore checking the external ips if attached or not attached ?
Not sure if from config or may be editing src files .


Many Thanks



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220513/1d4e45c0/attachment.htm>

From ngtech1ltd at gmail.com  Fri May 13 16:40:31 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Fri, 13 May 2022 19:40:31 +0300
Subject: [squid-users] is there a way to tell squid to write external ip
 even that external ip not attached into the machine ?
In-Reply-To: <DBBPR09MB4523C855C120CC5551E7EF72F7CA9@DBBPR09MB4523.eurprd09.prod.outlook.com>
References: <DBBPR09MB452360B6B9D0085134CB738CF7CA9@DBBPR09MB4523.eurprd09.prod.outlook.com>
 <000001d866dc$d38a63d0$7a9f2b70$@gmail.com>
 <DBBPR09MB4523C855C120CC5551E7EF72F7CA9@DBBPR09MB4523.eurprd09.prod.outlook.com>
Message-ID: <000901d866e8$29e3cb30$7dab6190$@gmail.com>

Hey Ahmad,

 

To be clear, a simple forward proxy that will fake the source IP address is
kind of a simple task with these days libraries.

I do not know your exact scenario and use case but it's possible to write
such a proxy in roughly 200 lines of code in Golang.
Take a peek at:

https://github.com/LiamHaworth/go-tproxy

 

It's a nice library for tproxy alone.

Squid is great but if you will touch any source code it's possible that
you'd better write your own customized proxy.

 

Good Luck,

Eliezer

 

----

Eliezer Croitoru

NgTech, Tech Support

Mobile: +972-5-28704261

Email:  <mailto:ngtech1ltd at gmail.com> ngtech1ltd at gmail.com

 

From: Ahmad Alzaeem <0xff1f at gmail.com> 
Sent: Friday, May 13, 2022 18:34
To: Eliezer Croitoru <ngtech1ltd at gmail.com>;
squid-users at lists.squid-cache.org
Subject: Re: [squid-users] is there a way to tell squid to write external ip
even that external ip not attached into the machine ?

 

Hello Eliezer

I thought it could be done by editing squid src file  like to skip inet
address lookup .

 

Thanks 

 

 

From: squid-users <squid-users-bounces at lists.squid-cache.org
<mailto:squid-users-bounces at lists.squid-cache.org> > on behalf of Eliezer
Croitoru <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >
Date: Friday, May 13, 2022 at 8:21 AM
To: squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
<squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org> >
Subject: Re: [squid-users] is there a way to tell squid to write external ip
even that external ip not attached into the machine ?

Hey Ahmad,

 

You should use a tproxy port with a PROXY protocol support and acls.

With these you can try to push traffic to the network from a local process
that will write the right details to squid that will generate a fake source
ip.


And since you have asked I assume you are not familiar enough with this kind
of setup so it's crucial you will understand what are doing
before trying and testing it since at might not work as you expect.

 

All The Bests,

Eliezer

 

----

Eliezer Croitoru

NgTech, Tech Support

Mobile: +972-5-28704261

Email:  <mailto:ngtech1ltd at gmail.com> ngtech1ltd at gmail.com

 

From: squid-users <squid-users-bounces at lists.squid-cache.org
<mailto:squid-users-bounces at lists.squid-cache.org> > On Behalf Of Ahmad
Alzaeem
Sent: Friday, May 13, 2022 16:13
To: squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org> ; Amos Jeffries
<squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz> >
Subject: [squid-users] is there a way to tell squid to write external ip
even that external ip not attached into the machine ?

 

 

Hello Guys ,

We are testing squid with a project such as we need squid to write and
proceed with tcp_outgoing address address even its not attached to the
machine by ifconfig or ip add  ?

 

After some tests we found that squid wont write the external Ip to be pushed
out the network card interface if the ip address is not added to the machine
.

 

Is there anyway to bypass this checkout and let squid ignore checking the
external ips if attached or not attached ?

Not sure if from config or may be editing src files .

 

 

Many Thanks 

 

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220513/19a5fafe/attachment.htm>

From robertkwild at gmail.com  Wed May 18 15:57:57 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Wed, 18 May 2022 16:57:57 +0100
Subject: [squid-users] disable https inspection for licensing some apps
Message-ID: <CAGU_CiKWmRUVKqQ8rwfR2_huAKXS1Cidn7D1c-KnrWj_vAuR+Q@mail.gmail.com>

hi all,

i have squid proxy configured as ssl bump and i white list some websites
only

but for some websites i dont want to inspect https traffic as it breaks the
cert when i want to license some apps via the url (whitelist url)

how can i disable https inspection for some websites please

many thanks,
rob

-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220518/c6180500/attachment.htm>

From robertkwild at gmail.com  Wed May 18 16:28:49 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Wed, 18 May 2022 17:28:49 +0100
Subject: [squid-users] disable https inspection for licensing some apps
In-Reply-To: <CAGU_CiKWmRUVKqQ8rwfR2_huAKXS1Cidn7D1c-KnrWj_vAuR+Q@mail.gmail.com>
References: <CAGU_CiKWmRUVKqQ8rwfR2_huAKXS1Cidn7D1c-KnrWj_vAuR+Q@mail.gmail.com>
Message-ID: <CAGU_CiK2pnu+hJUNDdOJnfdvZns8SXLGaehQeCdCcZ_4Zq_E4A@mail.gmail.com>

im using this

# SSL bump rulesacl DiscoverSNIHost at_step SslBump1acl NoSSLIntercept
ssl::server_name "/usr/local/squid/etc/nointercept.txt"ssl_bump peek
DiscoverSNIHostssl_bump splice NoSSLInterceptssl_bump bump all

and in the nointercept.txt

i have the url in there, also i have it in the url white list so it
can actually see the url

is there something else i need to add for this to work

or maybe some websites ie license website just dont like it going
through a proxy


On Wed, 18 May 2022 at 16:57, robert k Wild <robertkwild at gmail.com> wrote:

> hi all,
>
> i have squid proxy configured as ssl bump and i white list some websites
> only
>
> but for some websites i dont want to inspect https traffic as it breaks
> the cert when i want to license some apps via the url (whitelist url)
>
> how can i disable https inspection for some websites please
>
> many thanks,
> rob
>
> --
> Regards,
>
> Robert K Wild.
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220518/34b08c12/attachment.htm>

From rousskov at measurement-factory.com  Wed May 18 18:38:47 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 18 May 2022 14:38:47 -0400
Subject: [squid-users] disable https inspection for licensing some apps
In-Reply-To: <CAGU_CiK2pnu+hJUNDdOJnfdvZns8SXLGaehQeCdCcZ_4Zq_E4A@mail.gmail.com>
References: <CAGU_CiKWmRUVKqQ8rwfR2_huAKXS1Cidn7D1c-KnrWj_vAuR+Q@mail.gmail.com>
 <CAGU_CiK2pnu+hJUNDdOJnfdvZns8SXLGaehQeCdCcZ_4Zq_E4A@mail.gmail.com>
Message-ID: <0a024267-6d35-4bc5-ea98-4af9f5866022@measurement-factory.com>

On 5/18/22 12:28, robert k Wild wrote:

> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLIntercept ssl::server_name "/usr/local/squid/etc/nointercept.txt"
> ssl_bump peek DiscoverSNIHost
> ssl_bump splice NoSSLIntercept
> ssl_bump bump all

OK, the above configuration makes the splice/bump decision based on 
plain text information provided by the TLS client.


> and in the nointercept.txt
> i have the url in there

ssl::server_name needs a host/domain name, not a regular URL. No URLs 
are exchanged in plain text between TLS client and the origin server.

Please note that, even after adjusting nointercept.txt to contain domain 
name(s), the above configuration may not always work in modern Squids: 
It will work when the client sends a matching domain name

* in the CONNECT request headers (and sends no TLS SNI at all)
* in the CONNECT request headers and in TLS SNI
* in TLS SNI (the CONNECT request headers should not matter).

It will also work when a CONNECT request is using an IP address that 
reverse-resolves to a matching domain name (which is not overwritten by 
a mismatching SNI).

In all other cases, Squid will bump traffic even if it is ultimately 
going to the server named in nointercept.txt.

There is no configuration that will address all possible cases in 
general. TLS makes that impossible (at least not without probing TLS 
origin servers which is something Squid does not do yet).


HTH,

Alex.


>, also i have it in the url white list so it can actually see the url
> 
> is there something else i need to add for this to work
> 
> or maybe some websites ie license website just dont like it going through a proxy
> 
> 
> On Wed, 18 May 2022 at 16:57, robert k Wild <robertkwild at gmail.com 
> <mailto:robertkwild at gmail.com>> wrote:
> 
>     hi all,
> 
>     i have squid proxy configured as ssl bump and i white list some
>     websites only
> 
>     but for some websites i dont want to inspect https traffic as it
>     breaks the cert when i want to license some apps via the url
>     (whitelist url)
> 
>     how can i disable https inspection for some websites please
> 
>     many thanks,
>     rob
> 
>     -- 
>     Regards,
> 
>     Robert K Wild.
> 
> 
> 
> -- 
> Regards,
> 
> Robert K Wild.
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From ngtech1ltd at gmail.com  Wed May 18 19:19:40 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Wed, 18 May 2022 22:19:40 +0300
Subject: [squid-users] disable https inspection for licensing some apps
In-Reply-To: <0a024267-6d35-4bc5-ea98-4af9f5866022@measurement-factory.com>
References: <CAGU_CiKWmRUVKqQ8rwfR2_huAKXS1Cidn7D1c-KnrWj_vAuR+Q@mail.gmail.com>
 <CAGU_CiK2pnu+hJUNDdOJnfdvZns8SXLGaehQeCdCcZ_4Zq_E4A@mail.gmail.com>
 <0a024267-6d35-4bc5-ea98-4af9f5866022@measurement-factory.com>
Message-ID: <006201d86aec$39a1f0d0$ace5d270$@gmail.com>

 Hey Alex,

I have started working on some external_acl helper that will probe the
server certificate like what ufdbguard does but will be written 
probably in another language then C++ ... ie scripting or GoLang or Rust.
The idea is that there will be some cache or DB that will store information
about an IP+port paired with SNI.
A storage engine like a cache would help to "know" enough about the server
to ultimately decide if there is a risk in splicing this specific
connection.
It's also possible that the first time that the request will pass via thru
the proxy it will be bumped to probe the connection for more information
when possible.

In general for commercial products there is either a CDN service or a
dedicated service.
These usually are not the risk for the proxy users and can be spliced.
The main issue is if one service on a specific IP serves  more then one
domain that contains different content.
The best example is google CDN network that might serve on the same IP and
certificate and SNI(because of HTTP/2.0) different domains.

Eliezer

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
Alex Rousskov
Sent: Wednesday, May 18, 2022 21:39
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] disable https inspection for licensing some apps

On 5/18/22 12:28, robert k Wild wrote:

> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLIntercept ssl::server_name "/usr/local/squid/etc/nointercept.txt"
> ssl_bump peek DiscoverSNIHost
> ssl_bump splice NoSSLIntercept
> ssl_bump bump all

OK, the above configuration makes the splice/bump decision based on 
plain text information provided by the TLS client.


> and in the nointercept.txt
> i have the url in there

ssl::server_name needs a host/domain name, not a regular URL. No URLs 
are exchanged in plain text between TLS client and the origin server.

Please note that, even after adjusting nointercept.txt to contain domain 
name(s), the above configuration may not always work in modern Squids: 
It will work when the client sends a matching domain name

* in the CONNECT request headers (and sends no TLS SNI at all)
* in the CONNECT request headers and in TLS SNI
* in TLS SNI (the CONNECT request headers should not matter).

It will also work when a CONNECT request is using an IP address that 
reverse-resolves to a matching domain name (which is not overwritten by 
a mismatching SNI).

In all other cases, Squid will bump traffic even if it is ultimately 
going to the server named in nointercept.txt.

There is no configuration that will address all possible cases in 
general. TLS makes that impossible (at least not without probing TLS 
origin servers which is something Squid does not do yet).


HTH,

Alex.


>, also i have it in the url white list so it can actually see the url
> 
> is there something else i need to add for this to work
> 
> or maybe some websites ie license website just dont like it going through
a proxy
> 
> 
> On Wed, 18 May 2022 at 16:57, robert k Wild <robertkwild at gmail.com 
> <mailto:robertkwild at gmail.com>> wrote:
> 
>     hi all,
> 
>     i have squid proxy configured as ssl bump and i white list some
>     websites only
> 
>     but for some websites i dont want to inspect https traffic as it
>     breaks the cert when i want to license some apps via the url
>     (whitelist url)
> 
>     how can i disable https inspection for some websites please
> 
>     many thanks,
>     rob
> 
>     -- 
>     Regards,
> 
>     Robert K Wild.
> 
> 
> 
> -- 
> Regards,
> 
> Robert K Wild.
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From ngtech1ltd at gmail.com  Wed May 18 19:35:04 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Wed, 18 May 2022 22:35:04 +0300
Subject: [squid-users] linuxize.com and other sites captcha
Message-ID: <006301d86aee$6070b730$21522590$@gmail.com>

I have seen that many sites are against MITM since they want to be able to
reach the client directly and without any ICAP proxy in the middle.

There are services that gives captcha pages when these pages are being MITM
by squid, for example:

https://linuxize.com

 

@Alex, can we please try to define what cause this and if it is at all
possible to avoid this? (eventually.)

 

Thanks,

Eliezer

 

----

Eliezer Croitoru

NgTech, Tech Support

Mobile: +972-5-28704261

Email:  <mailto:ngtech1ltd at gmail.com> ngtech1ltd at gmail.com

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220518/8f5a33c5/attachment.htm>

From rousskov at measurement-factory.com  Wed May 18 19:55:42 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 18 May 2022 15:55:42 -0400
Subject: [squid-users] linuxize.com and other sites captcha
In-Reply-To: <006301d86aee$6070b730$21522590$@gmail.com>
References: <006301d86aee$6070b730$21522590$@gmail.com>
Message-ID: <b352bbf4-284c-7647-b026-a4c5f7c5a21c@measurement-factory.com>

On 5/18/22 15:35, Eliezer Croitoru wrote:
> I have seen that many sites are against MITM since they want to be able 
> to reach the client directly and without any ICAP proxy in the middle.
> 
> There are services that gives captcha pages when these pages are being 
> MITM by squid, for example: https://linuxize.com
> 
> @Alex, can we please try to define what cause this and if it is at all 
> possible to avoid this? (eventually?)
  There are many known ways to fingerprint a proxy, and Squid is not 
even trying to hide its presence beyond a couple of basic directives 
like "via off". It is possible to make Squid "more stealthy", of course. 
Since needless traffic modification sometimes causes compatibility 
problems, the Squid Project ought to accept quality improvements in this 
area IMO. However, I am not aware of any active efforts in this direction.

Whether a particular Squid change (to remove proxied traffic 
modification) can defeat a particular proxy detection mechanism depends 
on whether that mechanism relies on that traffic modification 
(exclusively), of course. I do not know what linuxize.com is using right 
now. Needless to say, they can change or improve their detection methods 
just like others can change or improve Squid.

Alex.


From robertkwild at gmail.com  Thu May 19 12:47:11 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 19 May 2022 13:47:11 +0100
Subject: [squid-users] disable https inspection for licensing some apps
In-Reply-To: <006201d86aec$39a1f0d0$ace5d270$@gmail.com>
References: <CAGU_CiKWmRUVKqQ8rwfR2_huAKXS1Cidn7D1c-KnrWj_vAuR+Q@mail.gmail.com>
 <CAGU_CiK2pnu+hJUNDdOJnfdvZns8SXLGaehQeCdCcZ_4Zq_E4A@mail.gmail.com>
 <0a024267-6d35-4bc5-ea98-4af9f5866022@measurement-factory.com>
 <006201d86aec$39a1f0d0$ace5d270$@gmail.com>
Message-ID: <CAGU_CiJiYQR_6A0Ogq5hztzNVD-JYX3EvSV_d4EE_r3Kk1hpGg@mail.gmail.com>

I worked it out, my "no Https interception" was working on websites if I
put the URL in that txt file

nointercept.txt

But I needed to make a proxy.ini file as well on the host in question, for
it to point to the proxy

Once it pointed to the proxy I could then monitor the traffic and see what
URL I needed to whitelist and to put in the no SSL interception

Once I did that all good

Thanks guys, much appreciated
On Wed, 18 May 2022, 20:21 Eliezer Croitoru, <ngtech1ltd at gmail.com> wrote:

>  Hey Alex,
>
> I have started working on some external_acl helper that will probe the
> server certificate like what ufdbguard does but will be written
> probably in another language then C++ ... ie scripting or GoLang or Rust.
> The idea is that there will be some cache or DB that will store information
> about an IP+port paired with SNI.
> A storage engine like a cache would help to "know" enough about the server
> to ultimately decide if there is a risk in splicing this specific
> connection.
> It's also possible that the first time that the request will pass via thru
> the proxy it will be bumped to probe the connection for more information
> when possible.
>
> In general for commercial products there is either a CDN service or a
> dedicated service.
> These usually are not the risk for the proxy users and can be spliced.
> The main issue is if one service on a specific IP serves  more then one
> domain that contains different content.
> The best example is google CDN network that might serve on the same IP and
> certificate and SNI(because of HTTP/2.0) different domains.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> NgTech, Tech Support
> Mobile: +972-5-28704261
> Email: ngtech1ltd at gmail.com
>
> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
> Alex Rousskov
> Sent: Wednesday, May 18, 2022 21:39
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] disable https inspection for licensing some apps
>
> On 5/18/22 12:28, robert k Wild wrote:
>
> > acl DiscoverSNIHost at_step SslBump1
> > acl NoSSLIntercept ssl::server_name
> "/usr/local/squid/etc/nointercept.txt"
> > ssl_bump peek DiscoverSNIHost
> > ssl_bump splice NoSSLIntercept
> > ssl_bump bump all
>
> OK, the above configuration makes the splice/bump decision based on
> plain text information provided by the TLS client.
>
>
> > and in the nointercept.txt
> > i have the url in there
>
> ssl::server_name needs a host/domain name, not a regular URL. No URLs
> are exchanged in plain text between TLS client and the origin server.
>
> Please note that, even after adjusting nointercept.txt to contain domain
> name(s), the above configuration may not always work in modern Squids:
> It will work when the client sends a matching domain name
>
> * in the CONNECT request headers (and sends no TLS SNI at all)
> * in the CONNECT request headers and in TLS SNI
> * in TLS SNI (the CONNECT request headers should not matter).
>
> It will also work when a CONNECT request is using an IP address that
> reverse-resolves to a matching domain name (which is not overwritten by
> a mismatching SNI).
>
> In all other cases, Squid will bump traffic even if it is ultimately
> going to the server named in nointercept.txt.
>
> There is no configuration that will address all possible cases in
> general. TLS makes that impossible (at least not without probing TLS
> origin servers which is something Squid does not do yet).
>
>
> HTH,
>
> Alex.
>
>
> >, also i have it in the url white list so it can actually see the url
> >
> > is there something else i need to add for this to work
> >
> > or maybe some websites ie license website just dont like it going through
> a proxy
> >
> >
> > On Wed, 18 May 2022 at 16:57, robert k Wild <robertkwild at gmail.com
> > <mailto:robertkwild at gmail.com>> wrote:
> >
> >     hi all,
> >
> >     i have squid proxy configured as ssl bump and i white list some
> >     websites only
> >
> >     but for some websites i dont want to inspect https traffic as it
> >     breaks the cert when i want to license some apps via the url
> >     (whitelist url)
> >
> >     how can i disable https inspection for some websites please
> >
> >     many thanks,
> >     rob
> >
> >     --
> >     Regards,
> >
> >     Robert K Wild.
> >
> >
> >
> > --
> > Regards,
> >
> > Robert K Wild.
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220519/725618f8/attachment.htm>

From robertkwild at gmail.com  Thu May 19 14:25:21 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 19 May 2022 15:25:21 +0100
Subject: [squid-users] Regex for URL to include numbers special letters
Message-ID: <CAGU_CiLeXLRCJxZudsoRjx0Nz2n+j9D1uPeG6dfOoKsdS627Xg@mail.gmail.com>

hi all,

want to make the below into a regex as after the io..., could be any number
and letter, the - stays in the same position but to make it simple i just
want to make anything a wildcard

http://zzz-iobuckets-io50-1lnk65fe5gm7n.s3.amazonaws.com/

something like this ive done but it doesnt work

"^zzz-iobuckets-io.*.s3.amazonaws.com$"

thanks,

rob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220519/37b334cd/attachment.htm>

From belle at bazuin.nl  Thu May 19 14:40:11 2022
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Thu, 19 May 2022 16:40:11 +0200
Subject: [squid-users] Regex for URL to include numbers special letters
In-Reply-To: <CAGU_CiLeXLRCJxZudsoRjx0Nz2n+j9D1uPeG6dfOoKsdS627Xg@mail.gmail.com>
References: <CAGU_CiLeXLRCJxZudsoRjx0Nz2n+j9D1uPeG6dfOoKsdS627Xg@mail.gmail.com>
Message-ID: <vmime.628656cb.1962.31b65d8d3bb7d3fb@ms249-lin-003.rotterdam.bazuin.nl>

You cant make that certficate.. 
at least, I hope, because, if you can, well then whole amazone has a problem. 

If you want to ?hide? that your an intercepting proxy. 

You need to create a RootCA, IntermediateCA and Certificate + key file for the proxy. 
And you need to publish the RootCA and IntermediateCA to you pc?s. 
?( that?s easy done with a GPO)

If that is what you mean.. 

I use XCA to create certificate. 


Greetz, 



Louis





?

Van: squid-users Namens robert k Wild
Verzonden: donderdag 19 mei 2022 16:25
Aan: Squid Users <squid-users at lists.squid-cache.org>
Onderwerp: [squid-users] Regex for URL to include numbers special letters



?

hi all,

want to make the below into a regex as after the io..., could be any number and letter, the - stays in the same position but to make it simple i just want to make anything a wildcard

http://zzz-iobuckets-io50-1lnk65fe5gm7n.s3.amazonaws.com/

something like this ive done but it doesnt work

"^zzz-iobuckets-io.*.s3.amazonaws.com$"

thanks,

rob



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220519/a3cf0be3/attachment.htm>

From robertkwild at gmail.com  Thu May 19 14:45:24 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 19 May 2022 15:45:24 +0100
Subject: [squid-users] Regex for URL to include numbers special letters
In-Reply-To: <vmime.628656cb.1962.31b65d8d3bb7d3fb@ms249-lin-003.rotterdam.bazuin.nl>
References: <CAGU_CiLeXLRCJxZudsoRjx0Nz2n+j9D1uPeG6dfOoKsdS627Xg@mail.gmail.com>
 <vmime.628656cb.1962.31b65d8d3bb7d3fb@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <CAGU_Ci+Asfr=J_DQQApq6E2Ch_Btb7EebsgdiV=Rf-FbtxNj8w@mail.gmail.com>

No I mean I just want to make the URL into a regex so it can handle any
numbers or letter after the iobuckets-io......S3.amazonaws.com

On Thu, 19 May 2022, 15:40 L.P.H. van Belle, <belle at bazuin.nl> wrote:

> You cant make that certficate..
> at least, I hope, because, if you can, well then whole amazone has a
> problem.
>
> If you want to ?hide? that your an intercepting proxy.
>
> You need to create a RootCA, IntermediateCA and Certificate + key file for
> the proxy.
> And you need to publish the RootCA and IntermediateCA to you pc?s.
>  ( that?s easy done with a GPO)
>
> If that is what you mean..
>
> I use XCA to create certificate.
>
>
> Greetz,
>
> Louis
>
>
>
>
>
> *Van:* squid-users *Namens *robert k Wild
> *Verzonden:* donderdag 19 mei 2022 16:25
> *Aan:* Squid Users <squid-users at lists.squid-cache.org>
> *Onderwerp:* [squid-users] Regex for URL to include numbers special
> letters
>
>
>
> hi all,
>
> want to make the below into a regex as after the io..., could be any
> number and letter, the - stays in the same position but to make it simple i
> just want to make anything a wildcard
>
> http://zzz-iobuckets-io50-1lnk65fe5gm7n.s3.amazonaws.com/
>
> something like this ive done but it doesnt work
>
> "^zzz-iobuckets-io.*.s3.amazonaws.com$"
>
> thanks,
>
> rob
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220519/b0c5d534/attachment.htm>

From belle at bazuin.nl  Thu May 19 14:58:26 2022
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Thu, 19 May 2022 16:58:26 +0200
Subject: [squid-users] Regex for URL to include numbers special letters
In-Reply-To: <CAGU_Ci+Asfr=J_DQQApq6E2Ch_Btb7EebsgdiV=Rf-FbtxNj8w@mail.gmail.com>
References: <vmime.628656cb.1962.31b65d8d3bb7d3fb@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <vmime.62865b12.28c2.196e57771b3045a1@ms249-lin-003.rotterdam.bazuin.nl>

I think you can use *( in case and per example ) 
acl SOMETHING .s3.amazonaws.com

?

Depends bit on what type list your useing. 
https://wiki.squid-cache.org/SquidFaq/SquidAcl 

I suggest have a look there also. 

Greetz, 

Louis

?





?

Van: robert k Wild 
Verzonden: donderdag 19 mei 2022 16:45
Aan: L.P.H. van Belle <belle at bazuin.nl>
CC: Squid Users <squid-users at lists.squid-cache.org>
Onderwerp: Re: [squid-users] Regex for URL to include numbers special letters



?

No I mean I just want to make the URL into a regex so it can handle any numbers or letter after the iobuckets-io......S3.amazonaws.com


?

On Thu, 19 May 2022, 15:40 L.P.H. van Belle, <belle at bazuin.nl> wrote:


You cant make that certficate.. 
at least, I hope, because, if you can, well then whole amazone has a problem. 

If you want to ?hide? that your an intercepting proxy. 

You need to create a RootCA, IntermediateCA and Certificate + key file for the proxy. 
And you need to publish the RootCA and IntermediateCA to you pc?s. 
?( that?s easy done with a GPO)

If that is what you mean.. 

I use XCA to create certificate. 


Greetz, 

Louis

?

?

Van: squid-users Namens robert k Wild
Verzonden: donderdag 19 mei 2022 16:25
Aan: Squid Users <squid-users at lists.squid-cache.org>
Onderwerp: [squid-users] Regex for URL to include numbers special letters



?

hi all,

want to make the below into a regex as after the io..., could be any number and letter, the - stays in the same position but to make it simple i just want to make anything a wildcard

http://zzz-iobuckets-io50-1lnk65fe5gm7n.s3.amazonaws.com/

something like this ive done but it doesnt work

"^zzz-iobuckets-io.*.s3.amazonaws.com$"

thanks,

rob







-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220519/d6c1fb05/attachment.htm>

From robertkwild at gmail.com  Thu May 19 16:45:14 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 19 May 2022 17:45:14 +0100
Subject: [squid-users] Regex for URL to include numbers special letters
In-Reply-To: <vmime.62865b12.28c2.196e57771b3045a1@ms249-lin-003.rotterdam.bazuin.nl>
References: <vmime.628656cb.1962.31b65d8d3bb7d3fb@ms249-lin-003.rotterdam.bazuin.nl>
 <CAGU_Ci+Asfr=J_DQQApq6E2Ch_Btb7EebsgdiV=Rf-FbtxNj8w@mail.gmail.com>
 <vmime.62865b12.28c2.196e57771b3045a1@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <CAGU_CiL969xk=EkdtXu-n4Z2iVcE5wE9U3wPAiF9=Rc42x1j6Q@mail.gmail.com>

Sorted it, deleted the "" and the $ at the end and now it works

On Thu, 19 May 2022, 15:58 L.P.H. van Belle, <belle at bazuin.nl> wrote:

> I think you can use *( in case and per example )
> acl SOMETHING .s3.amazonaws.com
>
>
>
> Depends bit on what type list your useing.
> https://wiki.squid-cache.org/SquidFaq/SquidAcl
>
> I suggest have a look there also.
>
> Greetz,
>
> Louis
>
>
>
>
>
>
>
> *Van:* robert k Wild
> *Verzonden:* donderdag 19 mei 2022 16:45
> *Aan:* L.P.H. van Belle <belle at bazuin.nl>
> *CC:* Squid Users <squid-users at lists.squid-cache.org>
> *Onderwerp:* Re: [squid-users] Regex for URL to include numbers special
> letters
>
>
>
> No I mean I just want to make the URL into a regex so it can handle any
> numbers or letter after the iobuckets-io......S3.amazonaws.com
>
>
>
> On Thu, 19 May 2022, 15:40 L.P.H. van Belle, <belle at bazuin.nl> wrote:
>
> You cant make that certficate..
> at least, I hope, because, if you can, well then whole amazone has a
> problem.
>
> If you want to ?hide? that your an intercepting proxy.
>
> You need to create a RootCA, IntermediateCA and Certificate + key file for
> the proxy.
> And you need to publish the RootCA and IntermediateCA to you pc?s.
>  ( that?s easy done with a GPO)
>
> If that is what you mean..
>
> I use XCA to create certificate.
>
>
> Greetz,
>
> Louis
>
>
>
>
>
> *Van:* squid-users *Namens *robert k Wild
> *Verzonden:* donderdag 19 mei 2022 16:25
> *Aan:* Squid Users <squid-users at lists.squid-cache.org>
> *Onderwerp:* [squid-users] Regex for URL to include numbers special
> letters
>
>
>
> hi all,
>
> want to make the below into a regex as after the io..., could be any
> number and letter, the - stays in the same position but to make it simple i
> just want to make anything a wildcard
>
> http://zzz-iobuckets-io50-1lnk65fe5gm7n.s3.amazonaws.com/
>
> something like this ive done but it doesnt work
>
> "^zzz-iobuckets-io.*.s3.amazonaws.com$"
>
> thanks,
>
> rob
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220519/64642ac5/attachment.htm>

From robertkwild at gmail.com  Thu May 19 18:01:08 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 19 May 2022 19:01:08 +0100
Subject: [squid-users] Put URLs and URL regex in one text file
Message-ID: <CAGU_Ci+gE4K476i2XrKvKxNSRe=QpBLcaLP1jK099+PDFv1nbQ@mail.gmail.com>

Hi all,

ATM in my squid.conf I have two acls, one for normal whitelist urls and one
for whitelist reg ex urls, like so

#HTTP_HTTPS whitelist websites

acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"

#

#HTTP_HTTPS whitelist websites regex

acl whitelistreg ssl::server_name_regex
"/usr/local/squid/etc/urlregwhite.txt"

#

http_access allow activation whitelist

http_access allow activation whitelistreg

http_access deny all


urlwhite.txt



.login.windows.net


urlregwhite.txt



^zzz-iobuckets-io.*.s3.amazonaws.com


How would I be able to combine both together to get rid of the whitelist
and just leave the whitelistreg

Thanks,
Rob
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220519/7e0453d8/attachment.htm>

From robertkwild at gmail.com  Thu May 19 18:29:26 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 19 May 2022 19:29:26 +0100
Subject: [squid-users] Put URLs and URL regex in one text file
In-Reply-To: <CAGU_Ci+gE4K476i2XrKvKxNSRe=QpBLcaLP1jK099+PDFv1nbQ@mail.gmail.com>
References: <CAGU_Ci+gE4K476i2XrKvKxNSRe=QpBLcaLP1jK099+PDFv1nbQ@mail.gmail.com>
Message-ID: <CAGU_CiLyMFjdmFgQMAbzeAwW4f=1KriSCE5b172rQPU1e0smhg@mail.gmail.com>

Think I found it but, what the difference between these two

acl aclname ssl::server_name_regex [-i] \.foo\.com ...

acl aclname dstdom_regex [-n] [-i] \.foo\.com ...


On Thu, 19 May 2022, 19:01 robert k Wild, <robertkwild at gmail.com> wrote:

> Hi all,
>
> ATM in my squid.conf I have two acls, one for normal whitelist urls and
> one for whitelist reg ex urls, like so
>
> #HTTP_HTTPS whitelist websites
>
> acl whitelist ssl::server_name "/usr/local/squid/etc/urlwhite.txt"
>
> #
>
> #HTTP_HTTPS whitelist websites regex
>
> acl whitelistreg ssl::server_name_regex
> "/usr/local/squid/etc/urlregwhite.txt"
>
> #
>
> http_access allow activation whitelist
>
> http_access allow activation whitelistreg
>
> http_access deny all
>
>
> urlwhite.txt
>
>
>
> .login.windows.net
>
>
> urlregwhite.txt
>
>
>
> ^zzz-iobuckets-io.*.s3.amazonaws.com
>
>
> How would I be able to combine both together to get rid of the whitelist
> and just leave the whitelistreg
>
> Thanks,
> Rob
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220519/078cab8b/attachment.htm>

From pponakanti at roblox.com  Fri May 20 00:22:06 2022
From: pponakanti at roblox.com (Praveen Ponakanti)
Date: Thu, 19 May 2022 17:22:06 -0700
Subject: [squid-users] Scaling concurrent TCP sessions beyond ephemeral port
 range
Message-ID: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>

Hi,


Does anyone have recommendations on scaling concurrent connections through
the squid proxy to above the ephemeral port range?


I have squid v5.5 on Ubuntu with about 48K ephemeral ports available with
the ip_local_port_range. The squid is bound to listen on port 3128 and has
a single tcp_outgoing_address configured. We notice that after about 40-45k
concurrent connections through the proxy it is unable to reuse ports and it
severely limits local ports available to other applications running on the
system. The squid is setup to run 30 workers; total CPU is still under 10%
during peak connection rates.


Is any build config flag required to enable SO_REUSEPORT or SO_REUSEADDR on
the outbound TCP sessions opened by squid?

It does not appear that there is an option to use the
IP_BIND_ADDRESS_NO_PORT sockopt flag which can help with ephemeral port
reuse.



We have tried enabling tcp_tw_reuse, ip_autobind_reuse and ip_nonlocal_bind
flags, but unable to get the system reuse the ephemeral ports. The
fs.file-max is set to 4M. Pasted some errors below. Any suggestions are
appreciated!


Thanks

Praveen



2022/05/19 23:35:00 kid12| commBind Cannot bind socket FD 3075 to <*IP*>:
(99) Cannot assign requested address

    current master transaction: master48536607

2022/05/19 23:35:00 kid23| commBind Cannot bind socket FD 1320 to <*IP*>:
(99) Cannot assign requested address

    current master transaction: master26662366


2022/05/19 23:37:30 kid13| commBind Cannot bind socket FD 3346 to <*IP*>:
(98) Address already in use

    current master transaction: master11976056

2022/05/19 23:37:30 kid12| commBind Cannot bind socket FD 6459 to <*IP*>:
(98) Address already in use

    current master transaction: master48561031


While the system is in this state, local curl?s to another endpoint on the
same node are not able to obtain a TCP socket.


curl: (7) Couldn't connect to server
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220519/e79b5df5/attachment.htm>

From rousskov at measurement-factory.com  Fri May 20 02:18:38 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 19 May 2022 22:18:38 -0400
Subject: [squid-users] Scaling concurrent TCP sessions beyond ephemeral
 port range
In-Reply-To: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>
References: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>
Message-ID: <f7f62043-e384-0395-6d0f-ff4d510b0baf@measurement-factory.com>

On 5/19/22 20:22, Praveen Ponakanti wrote:

> Does anyone have recommendations on scaling concurrent connections 
> through the squid proxy to above the ephemeral port range?

I know of several solutions, but not all of them are probably applicable 
to your specific situation:

1. Decrease the amount of time closed TCP connections occupy the port. 
For example, if you have many connections in TIME_WAIT state, and can 
afford to lower that state duration, it may help free ports faster.

2. If outgoing connections are closed faster (i.e. after fewer requests) 
than they should be, then fix that problem to increase connection reuse 
(and, hence, decrease port pressure). This solution is usually 
applicable to environments where you control both ends of the connection 
and see some premature closures.

3. Use more outgoing IP addresses. Without modifications, Squid would 
not automatically pick the next outgoing IP address after using up most 
of the ports on the previous one, but perhaps the OS would do the right 
thing _for_ Squid? Not sure. You can use tcp_outgoing_address with 
random ACLs to force-spread the load across multiple IPs (and, hence, 
multiple port banks). This does not work if you must use a single 
outgoing IP for some reason.

4. Modify Squid to retry port binding errors. This is easy to do but 
(without #5 below) it will not help much once ephemeral ports become 
scarce (in my experience; I have not checked what the latest kernels are 
capable of in this area).

5. If you need, say, 20-30% more concurrency (rather than 100+%) and 
cannot use multiple outbound IP addresses, then would be possible to 
modify Squid to implement a manual port allocation algorithm that 
usually works a lot more reliable under load than ephemeral ports 
administered by the OS (last time I checked, which was a few years ago). 
You will still be bound by the TCP limit of 64K ports (minus whatever 
you want to leave for other applications that open outgoing connections) 
and various TCP-level timeouts, of course, but the number of cases where 
Squid cannot open a port because of OS port mismanagement will go down.

FWIW, we successfully use solutions 3, 4, and 5 in Web Polygraph 
benchmark (that can be configured to create lots of outgoing connections).


> I have squid v5.5 on Ubuntu with about 48K ephemeral ports available 
> with the ip_local_port_range. The squid is bound to listen on port 3128 
> and has a single tcp_outgoing_address configured. We notice that after 
> about 40-45k concurrent connections through the proxy it?is unable to 
> reuse ports and it severely limits local ports available to other 
> applications running on the system. The squid is setup to run 30 
> workers; total CPU is still under 10% during peak connection rates.
> 
> 
> Is any build config flag required to enable SO_REUSEPORT or SO_REUSEADDR 
> on the outbound TCP sessions opened by squid?

Squid can be configured to use SO_REUSEPORT on _incoming_ connections 
(see *_port worker-queues), but that is not what you are asking about. 
Outside of that worker-queues feature, Squid will not set SO_REUSEPORT 
AFAICT.

Squid does set SO_REUSEADDR unless you use the -R command line option 
AFAICT.


> It does not appear that there is an option to use the 
> IP_BIND_ADDRESS_NO_PORT sockopt flag which can help with ephemeral port 
> reuse.

No.


> We have tried enabling tcp_tw_reuse, ip_autobind_reuse and 
> ip_nonlocal_bind flags, but unable to get the system reuse the ephemeral 
> ports. The fs.file-max is set to 4M. Pasted some errors below. Any 
> suggestions are appreciated!


HTH,

Alex.



> 2022/05/19 23:35:00 kid12| commBind Cannot bind socket FD 3075 to 
> </IP/>: (99) Cannot assign requested address
> 
> current master transaction: master48536607
> 
> 2022/05/19 23:35:00 kid23| commBind Cannot bind socket FD 1320 to 
> </IP/>: (99) Cannot assign requested address
> 
> current master transaction: master26662366
> 
> 
> 2022/05/19 23:37:30 kid13| commBind Cannot bind socket FD 3346 to 
> </IP/>: (98) Address already in use
> 
> current master transaction: master11976056
> 
> 2022/05/19 23:37:30 kid12| commBind Cannot bind socket FD 6459 to 
> </IP/>: (98) Address already in use
> 
> current master transaction: master48561031
> 
> 
> While the system is in this state, local curl?s to another endpoint on 
> the same node are not able to obtain a TCP socket.
> 
> 
> curl: (7) Couldn't connect to server
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From pponakanti at roblox.com  Fri May 20 07:44:28 2022
From: pponakanti at roblox.com (Praveen Ponakanti)
Date: Fri, 20 May 2022 00:44:28 -0700
Subject: [squid-users] Scaling concurrent TCP sessions beyond ephemeral
 port range
In-Reply-To: <f7f62043-e384-0395-6d0f-ff4d510b0baf@measurement-factory.com>
References: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>
 <f7f62043-e384-0395-6d0f-ff4d510b0baf@measurement-factory.com>
Message-ID: <CACabJxNv5+o7AiY-tfuJ=_V4ZBNEks=dX4ki2YQBHcPPpUrABg@mail.gmail.com>

Hi Alex,

Thanks for going through several steps to help mitigate src port
exhaustion. We are looking to achieve 400-500% more concurrent connections
if we could :) as there is a significant buffer on the available CPU.
The option to use multiple tcp_outoing_addresses appears to be promising
along with some tweaks to the TCP timeouts. I guess we could use ACLs to
pick a different outbound IP based on the requesting client's prefix. We
had not considered that option as the ephemeral ports were no longer
available to other applications when squid uses most of them with a single
outbound IP configured. We are also looking to modify the code to use the
IP_BIND_ADDRESS_NO_PORT sockopt as that could help delay port assignment
with the bind() call on the outbound TCP sessions (to hopefully allow
access to the 4-tuple on the socket).
Thanks
Praveen


On Thu, May 19, 2022 at 7:18 PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 5/19/22 20:22, Praveen Ponakanti wrote:
>
> > Does anyone have recommendations on scaling concurrent connections
> > through the squid proxy to above the ephemeral port range?
>
> I know of several solutions, but not all of them are probably applicable
> to your specific situation:
>
> 1. Decrease the amount of time closed TCP connections occupy the port.
> For example, if you have many connections in TIME_WAIT state, and can
> afford to lower that state duration, it may help free ports faster.
>
> 2. If outgoing connections are closed faster (i.e. after fewer requests)
> than they should be, then fix that problem to increase connection reuse
> (and, hence, decrease port pressure). This solution is usually
> applicable to environments where you control both ends of the connection
> and see some premature closures.
>
> 3. Use more outgoing IP addresses. Without modifications, Squid would
> not automatically pick the next outgoing IP address after using up most
> of the ports on the previous one, but perhaps the OS would do the right
> thing _for_ Squid? Not sure. You can use tcp_outgoing_address with
> random ACLs to force-spread the load across multiple IPs (and, hence,
> multiple port banks). This does not work if you must use a single
> outgoing IP for some reason.
>
> 4. Modify Squid to retry port binding errors. This is easy to do but
> (without #5 below) it will not help much once ephemeral ports become
> scarce (in my experience; I have not checked what the latest kernels are
> capable of in this area).
>
> 5. If you need, say, 20-30% more concurrency (rather than 100+%) and
> cannot use multiple outbound IP addresses, then would be possible to
> modify Squid to implement a manual port allocation algorithm that
> usually works a lot more reliable under load than ephemeral ports
> administered by the OS (last time I checked, which was a few years ago).
> You will still be bound by the TCP limit of 64K ports (minus whatever
> you want to leave for other applications that open outgoing connections)
> and various TCP-level timeouts, of course, but the number of cases where
> Squid cannot open a port because of OS port mismanagement will go down.
>
> FWIW, we successfully use solutions 3, 4, and 5 in Web Polygraph
> benchmark (that can be configured to create lots of outgoing connections).
>
>
> > I have squid v5.5 on Ubuntu with about 48K ephemeral ports available
> > with the ip_local_port_range. The squid is bound to listen on port 3128
> > and has a single tcp_outgoing_address configured. We notice that after
> > about 40-45k concurrent connections through the proxy it is unable to
> > reuse ports and it severely limits local ports available to other
> > applications running on the system. The squid is setup to run 30
> > workers; total CPU is still under 10% during peak connection rates.
> >
> >
> > Is any build config flag required to enable SO_REUSEPORT or SO_REUSEADDR
> > on the outbound TCP sessions opened by squid?
>
> Squid can be configured to use SO_REUSEPORT on _incoming_ connections
> (see *_port worker-queues), but that is not what you are asking about.
> Outside of that worker-queues feature, Squid will not set SO_REUSEPORT
> AFAICT.
>
> Squid does set SO_REUSEADDR unless you use the -R command line option
> AFAICT.
>
>
> > It does not appear that there is an option to use the
> > IP_BIND_ADDRESS_NO_PORT sockopt flag which can help with ephemeral port
> > reuse.
>
> No.
>
>
> > We have tried enabling tcp_tw_reuse, ip_autobind_reuse and
> > ip_nonlocal_bind flags, but unable to get the system reuse the ephemeral
> > ports. The fs.file-max is set to 4M. Pasted some errors below. Any
> > suggestions are appreciated!
>
>
> HTH,
>
> Alex.
>
>
>
> > 2022/05/19 23:35:00 kid12| commBind Cannot bind socket FD 3075 to
> > </IP/>: (99) Cannot assign requested address
> >
> > current master transaction: master48536607
> >
> > 2022/05/19 23:35:00 kid23| commBind Cannot bind socket FD 1320 to
> > </IP/>: (99) Cannot assign requested address
> >
> > current master transaction: master26662366
> >
> >
> > 2022/05/19 23:37:30 kid13| commBind Cannot bind socket FD 3346 to
> > </IP/>: (98) Address already in use
> >
> > current master transaction: master11976056
> >
> > 2022/05/19 23:37:30 kid12| commBind Cannot bind socket FD 6459 to
> > </IP/>: (98) Address already in use
> >
> > current master transaction: master48561031
> >
> >
> > While the system is in this state, local curl?s to another endpoint on
> > the same node are not able to obtain a TCP socket.
> >
> >
> > curl: (7) Couldn't connect to server
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220520/804da239/attachment.htm>

From uhlar at fantomas.sk  Fri May 20 10:12:42 2022
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 20 May 2022 12:12:42 +0200
Subject: [squid-users] Put URLs and URL regex in one text file
In-Reply-To: <CAGU_CiLyMFjdmFgQMAbzeAwW4f=1KriSCE5b172rQPU1e0smhg@mail.gmail.com>
References: <CAGU_Ci+gE4K476i2XrKvKxNSRe=QpBLcaLP1jK099+PDFv1nbQ@mail.gmail.com>
 <CAGU_CiLyMFjdmFgQMAbzeAwW4f=1KriSCE5b172rQPU1e0smhg@mail.gmail.com>
Message-ID: <YodpmjbBaR5mNSkT@fantomas.sk>

On 19.05.22 19:29, robert k Wild wrote:
>Think I found it but, what the difference between these two
>
>acl aclname ssl::server_name_regex [-i] \.foo\.com ...

this one is taken from SNI option when squid looks at SSL handshake 
parameters.

>acl aclname dstdom_regex [-n] [-i] \.foo\.com ...

this one is the one provided in clients' request, where SSL requests usually 
look like:

CONNECT www.google.com:443 HTTP/1.0

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Chernobyl was an Windows 95 beta test site.


From robertkwild at gmail.com  Fri May 20 10:21:51 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Fri, 20 May 2022 11:21:51 +0100
Subject: [squid-users] Put URLs and URL regex in one text file
In-Reply-To: <YodpmjbBaR5mNSkT@fantomas.sk>
References: <CAGU_Ci+gE4K476i2XrKvKxNSRe=QpBLcaLP1jK099+PDFv1nbQ@mail.gmail.com>
 <CAGU_CiLyMFjdmFgQMAbzeAwW4f=1KriSCE5b172rQPU1e0smhg@mail.gmail.com>
 <YodpmjbBaR5mNSkT@fantomas.sk>
Message-ID: <CAGU_Ci+TQQAv4+BQcUmQ5bkfS3=3++YjXCSz-7ZFr3dyQMsS7A@mail.gmail.com>

So for SSL inspection, for squid to look into the URl headers, what's the
better one

Server name or

DST domain

Thanks,
Rob

On Fri, 20 May 2022, 11:12 Matus UHLAR - fantomas, <uhlar at fantomas.sk>
wrote:

> On 19.05.22 19:29, robert k Wild wrote:
> >Think I found it but, what the difference between these two
> >
> >acl aclname ssl::server_name_regex [-i] \.foo\.com ...
>
> this one is taken from SNI option when squid looks at SSL handshake
> parameters.
>
> >acl aclname dstdom_regex [-n] [-i] \.foo\.com ...
>
> this one is the one provided in clients' request, where SSL requests
> usually
> look like:
>
> CONNECT www.google.com:443 HTTP/1.0
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> Chernobyl was an Windows 95 beta test site.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220520/81a7d8c6/attachment.htm>

From uhlar at fantomas.sk  Fri May 20 11:19:54 2022
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 20 May 2022 13:19:54 +0200
Subject: [squid-users] Put URLs and URL regex in one text file
In-Reply-To: <CAGU_Ci+TQQAv4+BQcUmQ5bkfS3=3++YjXCSz-7ZFr3dyQMsS7A@mail.gmail.com>
References: <CAGU_Ci+gE4K476i2XrKvKxNSRe=QpBLcaLP1jK099+PDFv1nbQ@mail.gmail.com>
 <CAGU_CiLyMFjdmFgQMAbzeAwW4f=1KriSCE5b172rQPU1e0smhg@mail.gmail.com>
 <YodpmjbBaR5mNSkT@fantomas.sk>
 <CAGU_Ci+TQQAv4+BQcUmQ5bkfS3=3++YjXCSz-7ZFr3dyQMsS7A@mail.gmail.com>
Message-ID: <Yod5Wt5Li4RJPIch@fantomas.sk>

On 20.05.22 11:21, robert k Wild wrote:
>So for SSL inspection, for squid to look into the URl headers, what's the
>better one
>
>Server name or
>
>DST domain

I thought I have explained it: 
dstdom_regex is from the request, not from the SSL data.

>On Fri, 20 May 2022, 11:12 Matus UHLAR - fantomas, <uhlar at fantomas.sk>
>wrote:
>
>> On 19.05.22 19:29, robert k Wild wrote:
>> >Think I found it but, what the difference between these two
>> >
>> >acl aclname ssl::server_name_regex [-i] \.foo\.com ...
>>
>> this one is taken from SNI option when squid looks at SSL handshake
>> parameters.
>>
>> >acl aclname dstdom_regex [-n] [-i] \.foo\.com ...
>>
>> this one is the one provided in clients' request, where SSL requests
>> usually
>> look like:
>>
>> CONNECT www.google.com:443 HTTP/1.0

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Posli tento mail 100 svojim znamim - nech vidia aky si idiot
Send this email to 100 your friends - let them see what an idiot you are


From robertkwild at gmail.com  Fri May 20 11:26:40 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Fri, 20 May 2022 12:26:40 +0100
Subject: [squid-users] Put URLs and URL regex in one text file
In-Reply-To: <Yod5Wt5Li4RJPIch@fantomas.sk>
References: <CAGU_Ci+gE4K476i2XrKvKxNSRe=QpBLcaLP1jK099+PDFv1nbQ@mail.gmail.com>
 <CAGU_CiLyMFjdmFgQMAbzeAwW4f=1KriSCE5b172rQPU1e0smhg@mail.gmail.com>
 <YodpmjbBaR5mNSkT@fantomas.sk>
 <CAGU_Ci+TQQAv4+BQcUmQ5bkfS3=3++YjXCSz-7ZFr3dyQMsS7A@mail.gmail.com>
 <Yod5Wt5Li4RJPIch@fantomas.sk>
Message-ID: <CAGU_CiJCUZYhYCdf4Dt0jJ=3MMmg5ybp5=GpxGKa6HhdcSfG9g@mail.gmail.com>

Sorry I'm a bit thick

So I've read SSL::server_name_regex which uses sni is better than
dstdomain_regex

So I think I'm better of using the sni one then ?

On Fri, 20 May 2022, 12:20 Matus UHLAR - fantomas, <uhlar at fantomas.sk>
wrote:

> On 20.05.22 11:21, robert k Wild wrote:
> >So for SSL inspection, for squid to look into the URl headers, what's the
> >better one
> >
> >Server name or
> >
> >DST domain
>
> I thought I have explained it:
> dstdom_regex is from the request, not from the SSL data.
>
> >On Fri, 20 May 2022, 11:12 Matus UHLAR - fantomas, <uhlar at fantomas.sk>
> >wrote:
> >
> >> On 19.05.22 19:29, robert k Wild wrote:
> >> >Think I found it but, what the difference between these two
> >> >
> >> >acl aclname ssl::server_name_regex [-i] \.foo\.com ...
> >>
> >> this one is taken from SNI option when squid looks at SSL handshake
> >> parameters.
> >>
> >> >acl aclname dstdom_regex [-n] [-i] \.foo\.com ...
> >>
> >> this one is the one provided in clients' request, where SSL requests
> >> usually
> >> look like:
> >>
> >> CONNECT www.google.com:443 HTTP/1.0
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> Posli tento mail 100 svojim znamim - nech vidia aky si idiot
> Send this email to 100 your friends - let them see what an idiot you are
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220520/95d5abd3/attachment.htm>

From suporte at konntrol.com.br  Fri May 20 16:51:41 2022
From: suporte at konntrol.com.br (Suporte - Konntrol)
Date: Fri, 20 May 2022 13:51:41 -0300
Subject: [squid-users] Squid 4.15 on FreeBSD 12.2 Stable - Kerberos helper
 issues
Message-ID: <000801d86c69$e3008e60$a901ab20$@konntrol.com.br>

Hello everyone,

Greetings.

 

I got a strange situation with my SQUID 4.1 (FreeBSD 12.2 Stable
environment).

Everything was working fine with Kerberos configuration and suddenly it
stopped with the following error:

 

==> /var/squid/logs/cache.log <==

negotiate_kerberos_auth.cc(182): pid=85679 :2022/05/20 13:35:43|
negotiate_kerberos_auth: ERROR: gss_acquire_cred() failed: No credentials
were supplied, or the credentials were unavailable or inaccessible. No
principal in keytab matches desired name

2022/05/20 13:35:43| negotiate_kerberos_auth: INFO: User not authenticated

 

Judging by the "No principal in keytab matches desired name" message, I went
immediately to the AD object to check if it was really missing the Principal
entry.

To my surprise, everything is there. (talking about the HTTP/fqdn at REALM
entry).

Also, I checked the contents of my keytab, which looks OK, as it contains
the HTTP/server01.mydomain.corp at MYDOMAIN.CORP entry as well.

Additionally, I checked the DNS configuration for the PTR and Reverse
entries. It looks OK as well.

 

I have used "net ads join
createupn=HTTP/server01.mydomain.corp at MYDOMAIN.CORP -k" commands to Join the
Squid machine to Domain, and "net ads keytab create -k" to create a keytab.

Also, used the command "net ads keytab add HTTP" to add the HTTP entry to
the keytab.

 

This is the config used on SQUID for Kerberos:

 

auth_param negotiate program
/usr/local/libexec/squid/negotiate_kerberos_auth -d -i -s
HTTP/server01.mydomain.corp at MYDOMAIN.CORP
<mailto:HTTP/server01.mydomain.corp at MYDOMAIN.CORP>  

auth_param negotiate children 20 startup=10 idle=5

auth_param negotiate keep_alive off

 

As I mentioned, that was working for months, then stopped.

 

Are you guys aware of any Windows Update who may broke the Kerberos
integration?

 

I have "Windows Server 2022 AD" and "WINDOWS 11" clients, working with
"FreeBSD + SQUID + Kerberos Auth helper"

 

Any help is very welcome!

 

Thanks!

 

Fabricio.

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220520/253f7d77/attachment.htm>

From squid3 at treenet.co.nz  Sat May 21 02:39:10 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 May 2022 14:39:10 +1200
Subject: [squid-users] Regex for URL to include numbers special letters
In-Reply-To: <CAGU_CiL969xk=EkdtXu-n4Z2iVcE5wE9U3wPAiF9=Rc42x1j6Q@mail.gmail.com>
References: <vmime.628656cb.1962.31b65d8d3bb7d3fb@ms249-lin-003.rotterdam.bazuin.nl>
 <CAGU_Ci+Asfr=J_DQQApq6E2Ch_Btb7EebsgdiV=Rf-FbtxNj8w@mail.gmail.com>
 <vmime.62865b12.28c2.196e57771b3045a1@ms249-lin-003.rotterdam.bazuin.nl>
 <CAGU_CiL969xk=EkdtXu-n4Z2iVcE5wE9U3wPAiF9=Rc42x1j6Q@mail.gmail.com>
Message-ID: <8639e1b7-d4a1-459f-c3ff-5be8db86c899@treenet.co.nz>


Your solution may "works", but only partial.

Diving back to your original request:

On 20/05/22 02:25, robert k Wild wrote:
 > hi all,
 >
 > want to make the below into a regex as after the io..., could be any
 > number and letter, the - stays in the same position but to make it
 > simple i just want to make anything a wildcard
 >
 > http://zzz-iobuckets-io50-1lnk65fe5gm7n.s3.amazonaws.com/
 > <http://zzz-iobuckets-io50-1lnk65fe5gm7n.s3.amazonaws.com/>
 >
 > something like this ive done but it doesnt work
 >
 > "^zzz-iobuckets-io.*.s3.amazonaws.com <http://s3.amazonaws.com>$"
 >


Please notice that your regex does **not** match any valid "URL".

It explicitly only matches strings that start without a scheme. This is 
matching only URI. Specifically it matches URI-authority which HTTP only 
sees in CONNECT request-target's.


I think what you actually want is this:

   ^zzz-iobuckets-io[0-9]+-[0-9a-z]+\.s3\.amazonaws\.com:[0-9]$


That will limit the successful matches to amazonaws.com sub-domains. 
Preventing things like "zzz-iobuckets-io.s3.amazonaws.com.example.com"


FYI, The regex language supported by Squid is the original GNU regex. 
The operators are ^, $, +, *, ?, |, \x, [^-], and (). No character 
classes, back references, or repetition groups.


HTH
Amos



From squid3 at treenet.co.nz  Sat May 21 04:25:43 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 May 2022 16:25:43 +1200
Subject: [squid-users] Scaling concurrent TCP sessions beyond ephemeral
 port range
In-Reply-To: <CACabJxNv5+o7AiY-tfuJ=_V4ZBNEks=dX4ki2YQBHcPPpUrABg@mail.gmail.com>
References: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>
 <f7f62043-e384-0395-6d0f-ff4d510b0baf@measurement-factory.com>
 <CACabJxNv5+o7AiY-tfuJ=_V4ZBNEks=dX4ki2YQBHcPPpUrABg@mail.gmail.com>
Message-ID: <5856354a-393a-0803-e3e6-da29f8f7d8b1@treenet.co.nz>

On 20/05/22 19:44, Praveen Ponakanti wrote:
> Hi Alex,
> 
> Thanks for going through several steps to help mitigate src port 
> exhaustion. We are looking to achieve 400-500% more 
> concurrent?connections if we could :) as there is a significant?buffer 
> on the available CPU.

Then you require at least 4, maybe 5, IP addresses to handle that many 
concurrent connections with Squid.


> The option to use multiple tcp_outoing_addresses appears to be promising 
> along with some tweaks to the TCP timeouts. I guess we could use ACLs to 
> pick a different outbound IP based on the requesting client's prefix. We 
> had not considered that option as the ephemeral ports were no longer 
> available?to other applications when squid uses most of them with a 
> single outbound IP configured. We are also looking to modify the code to 
> use the IP_BIND_ADDRESS_NO_PORT sockopt as that could help delay port 
> assignment with the bind() call on the outbound TCP sessions (to 
> hopefully allow access to the 4-tuple on the socket).

Patches welcome.

However, please be aware that use of the 4-tuple is often no different 
from the 3-tuple since the dst-port is typically identical for all 
outgoing traffic to a given dst-IP.


Cheers
Amos


From squid3 at treenet.co.nz  Sat May 21 05:04:43 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 May 2022 17:04:43 +1200
Subject: [squid-users] Put URLs and URL regex in one text file
In-Reply-To: <CAGU_CiJCUZYhYCdf4Dt0jJ=3MMmg5ybp5=GpxGKa6HhdcSfG9g@mail.gmail.com>
References: <CAGU_Ci+gE4K476i2XrKvKxNSRe=QpBLcaLP1jK099+PDFv1nbQ@mail.gmail.com>
 <CAGU_CiLyMFjdmFgQMAbzeAwW4f=1KriSCE5b172rQPU1e0smhg@mail.gmail.com>
 <YodpmjbBaR5mNSkT@fantomas.sk>
 <CAGU_Ci+TQQAv4+BQcUmQ5bkfS3=3++YjXCSz-7ZFr3dyQMsS7A@mail.gmail.com>
 <Yod5Wt5Li4RJPIch@fantomas.sk>
 <CAGU_CiJCUZYhYCdf4Dt0jJ=3MMmg5ybp5=GpxGKa6HhdcSfG9g@mail.gmail.com>
Message-ID: <69057966-93e6-c75d-b896-feb6951d6555@treenet.co.nz>

On 20/05/22 23:26, robert k Wild wrote:
> Sorry I'm a bit thick
> 

Don't be. These things beyond plain-text HTTP are unfortunately a bit 
complex.

The key thing to remember is that Squid is dealing with *layers* of 
protocols wrapped around each other.

This wiki page 
<https://wiki.squid-cache.org/Features/SslPeekAndSplice#Terminology> 
documents the process as well as we can.

> So I've read SSL::server_name_regex which uses sni is better than 
> dstdomain_regex
> 
> So I think I'm better of using the sni one then ?
> 

Neither is "better". They check different things.

Usually checking _both_ is useful since "HTTPS" is an HTTP request (with 
domain) wrapped inside TLS (with SNI). The two values there are usually 
supposed to be the same, but may not be.

The ssl_bump access controls should check ssl::server_name* ACLs.

The http_access should check dst* ACLs for HTTP message URL, and may 
also check ssl::* ACLs for TLS details (including the TLS server name).


HTH
Amos


From squid3 at treenet.co.nz  Sat May 21 05:49:42 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 May 2022 17:49:42 +1200
Subject: [squid-users] Squid 4.15 on FreeBSD 12.2 Stable - Kerberos
 helper issues
In-Reply-To: <000801d86c69$e3008e60$a901ab20$@konntrol.com.br>
References: <000801d86c69$e3008e60$a901ab20$@konntrol.com.br>
Message-ID: <7bc76568-afad-ea85-4fa9-72c362e32e4b@treenet.co.nz>

On 21/05/22 04:51, Suporte - Konntrol wrote:
> Hello everyone,
> 
> Greetings.
> 
> I got a strange situation with my SQUID 4.1 (FreeBSD 12.2 Stable 
> environment).
> 
> Everything was working fine with Kerberos configuration and suddenly it 
> stopped with the following error:
> 
> ==> /var/squid/logs/cache.log <==
> 
> negotiate_kerberos_auth.cc(182): pid=85679 :2022/05/20 13:35:43| 
> negotiate_kerberos_auth: ERROR: gss_acquire_cred() failed: No 
> credentials were supplied, or the credentials were unavailable or 
> inaccessible. No principal in keytab matches desired name
> 
> 2022/05/20 13:35:43| negotiate_kerberos_auth: INFO: User not authenticated
> 
> Judging by the ?No principal in keytab matches desired name? message, I 
> went immediately to the AD object to check if it was really missing the 
> Principal entry.
> 
> To my surprise, everything is there. (talking about the HTTP/fqdn at REALM 
> entry).

That error message has a lot of parts.  Check the debug trace to see if 
you can find out what that "desired name" is for that lookup. It may be 
something odd going on there.

Also, notice the character cases. Sometimes it matters, so best to make 
sure they always line up.


> 
> Also, I checked the contents of my keytab, which looks OK, as it 
> contains the HTTP/server01.mydomain.corp at MYDOMAIN.CORP entry as well.
> 
> Additionally, I checked the DNS configuration for the PTR and Reverse 
> entries. It looks OK as well.
> 
> I have used ?net ads join 
> createupn=HTTP/server01.mydomain.corp at MYDOMAIN.CORP -k? commands to Join 
> the Squid machine to Domain, and ?net ads keytab create -k? to create a 
> keytab.
> 
> Also, used the command ?net ads keytab add HTTP? to add the HTTP entry 
> to the keytab.
>
...
> 
> As I mentioned, that was working for months, then stopped.
> 

IME, this type of sudden delayed breakage usually occurs when there is 
some validity period associated with the credentials in the keytab (or 
domain controller which created it). There is a disclaimer in the wiki 
about the "net ads" under some conditions adding an expiry time.

<https://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos#Create_keytab>

Rebuilding the keytab with kinit and msktutil may fix it for you.


HTH
Amos


From robertkwild at gmail.com  Sat May 21 07:08:32 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Sat, 21 May 2022 08:08:32 +0100
Subject: [squid-users] Put URLs and URL regex in one text file
In-Reply-To: <69057966-93e6-c75d-b896-feb6951d6555@treenet.co.nz>
References: <CAGU_Ci+gE4K476i2XrKvKxNSRe=QpBLcaLP1jK099+PDFv1nbQ@mail.gmail.com>
 <CAGU_CiLyMFjdmFgQMAbzeAwW4f=1KriSCE5b172rQPU1e0smhg@mail.gmail.com>
 <YodpmjbBaR5mNSkT@fantomas.sk>
 <CAGU_Ci+TQQAv4+BQcUmQ5bkfS3=3++YjXCSz-7ZFr3dyQMsS7A@mail.gmail.com>
 <Yod5Wt5Li4RJPIch@fantomas.sk>
 <CAGU_CiJCUZYhYCdf4Dt0jJ=3MMmg5ybp5=GpxGKa6HhdcSfG9g@mail.gmail.com>
 <69057966-93e6-c75d-b896-feb6951d6555@treenet.co.nz>
Message-ID: <CAGU_CiJc_G_cBHc+qyPzoMSE4f+L-M7vcg5+uv1Lc1ikp6hF-A@mail.gmail.com>

Thanks Amos,

So does that mean for all my SSL::server_name ACLs, I should be using
SSL_bump and not http_access


On Sat, 21 May 2022, 06:10 Amos Jeffries, <squid3 at treenet.co.nz> wrote:

> On 20/05/22 23:26, robert k Wild wrote:
> > Sorry I'm a bit thick
> >
>
> Don't be. These things beyond plain-text HTTP are unfortunately a bit
> complex.
>
> The key thing to remember is that Squid is dealing with *layers* of
> protocols wrapped around each other.
>
> This wiki page
> <https://wiki.squid-cache.org/Features/SslPeekAndSplice#Terminology>
> documents the process as well as we can.
>
> > So I've read SSL::server_name_regex which uses sni is better than
> > dstdomain_regex
> >
> > So I think I'm better of using the sni one then ?
> >
>
> Neither is "better". They check different things.
>
> Usually checking _both_ is useful since "HTTPS" is an HTTP request (with
> domain) wrapped inside TLS (with SNI). The two values there are usually
> supposed to be the same, but may not be.
>
> The ssl_bump access controls should check ssl::server_name* ACLs.
>
> The http_access should check dst* ACLs for HTTP message URL, and may
> also check ssl::* ACLs for TLS details (including the TLS server name).
>
>
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220521/3714ac3c/attachment.htm>

From robertkwild at gmail.com  Sat May 21 07:20:55 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Sat, 21 May 2022 08:20:55 +0100
Subject: [squid-users] Regex for URL to include numbers special letters
In-Reply-To: <8639e1b7-d4a1-459f-c3ff-5be8db86c899@treenet.co.nz>
References: <vmime.628656cb.1962.31b65d8d3bb7d3fb@ms249-lin-003.rotterdam.bazuin.nl>
 <CAGU_Ci+Asfr=J_DQQApq6E2Ch_Btb7EebsgdiV=Rf-FbtxNj8w@mail.gmail.com>
 <vmime.62865b12.28c2.196e57771b3045a1@ms249-lin-003.rotterdam.bazuin.nl>
 <CAGU_CiL969xk=EkdtXu-n4Z2iVcE5wE9U3wPAiF9=Rc42x1j6Q@mail.gmail.com>
 <8639e1b7-d4a1-459f-c3ff-5be8db86c899@treenet.co.nz>
Message-ID: <CAGU_CiKXMQGNF6dgEMO9mvVENPR0DLnO70_nJ11no5++zLXMyA@mail.gmail.com>

Thanks Amos,

What about if I wanted to put a normal URL in with the URL regex ones like

^zzz-iobuckets-io[0-9]+-[0-9a-z]+\.s3\.amazonaws\.com:[0-9]$
^google\.com$

Would that work


On Sat, 21 May 2022, 03:45 Amos Jeffries, <squid3 at treenet.co.nz> wrote:

>
> Your solution may "works", but only partial.
>
> Diving back to your original request:
>
> On 20/05/22 02:25, robert k Wild wrote:
>  > hi all,
>  >
>  > want to make the below into a regex as after the io..., could be any
>  > number and letter, the - stays in the same position but to make it
>  > simple i just want to make anything a wildcard
>  >
>  > http://zzz-iobuckets-io50-1lnk65fe5gm7n.s3.amazonaws.com/
>  > <http://zzz-iobuckets-io50-1lnk65fe5gm7n.s3.amazonaws.com/>
>  >
>  > something like this ive done but it doesnt work
>  >
>  > "^zzz-iobuckets-io.*.s3.amazonaws.com <http://s3.amazonaws.com>$"
>  >
>
>
> Please notice that your regex does **not** match any valid "URL".
>
> It explicitly only matches strings that start without a scheme. This is
> matching only URI. Specifically it matches URI-authority which HTTP only
> sees in CONNECT request-target's.
>
>
> I think what you actually want is this:
>
>    ^zzz-iobuckets-io[0-9]+-[0-9a-z]+\.s3\.amazonaws\.com:[0-9]$
>
>
> That will limit the successful matches to amazonaws.com sub-domains.
> Preventing things like "zzz-iobuckets-io.s3.amazonaws.com.example.com"
>
>
> FYI, The regex language supported by Squid is the original GNU regex.
> The operators are ^, $, +, *, ?, |, \x, [^-], and (). No character
> classes, back references, or repetition groups.
>
>
> HTH
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220521/df206c9e/attachment.htm>

From squid3 at treenet.co.nz  Sat May 21 08:25:11 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 May 2022 20:25:11 +1200
Subject: [squid-users] Regex for URL to include numbers special letters
In-Reply-To: <CAGU_CiKXMQGNF6dgEMO9mvVENPR0DLnO70_nJ11no5++zLXMyA@mail.gmail.com>
References: <vmime.628656cb.1962.31b65d8d3bb7d3fb@ms249-lin-003.rotterdam.bazuin.nl>
 <CAGU_Ci+Asfr=J_DQQApq6E2Ch_Btb7EebsgdiV=Rf-FbtxNj8w@mail.gmail.com>
 <vmime.62865b12.28c2.196e57771b3045a1@ms249-lin-003.rotterdam.bazuin.nl>
 <CAGU_CiL969xk=EkdtXu-n4Z2iVcE5wE9U3wPAiF9=Rc42x1j6Q@mail.gmail.com>
 <8639e1b7-d4a1-459f-c3ff-5be8db86c899@treenet.co.nz>
 <CAGU_CiKXMQGNF6dgEMO9mvVENPR0DLnO70_nJ11no5++zLXMyA@mail.gmail.com>
Message-ID: <7cb09a3d-8082-7d00-53fa-61aec859c197@treenet.co.nz>

On 21/05/22 19:20, robert k Wild wrote:
> Thanks Amos,
> 
> What about if I wanted to put a normal URL in with the URL regex ones like
> 
> ^zzz-iobuckets-io[0-9]+-[0-9a-z]+\.s3\.amazonaws\.com:[0-9]$
> ^google\.com$
> 
> Would that work
> 

I'm not sure what you mean, neither of those match a URL.

A *normal URL* looks like " https://example.com/ ".

A URI-authority looks like " example.com:80 ".


Amos


From pponakanti at roblox.com  Mon May 23 05:36:43 2022
From: pponakanti at roblox.com (Praveen Ponakanti)
Date: Sun, 22 May 2022 22:36:43 -0700
Subject: [squid-users] Scaling concurrent TCP sessions beyond ephemeral
 port range
In-Reply-To: <5856354a-393a-0803-e3e6-da29f8f7d8b1@treenet.co.nz>
References: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>
 <f7f62043-e384-0395-6d0f-ff4d510b0baf@measurement-factory.com>
 <CACabJxNv5+o7AiY-tfuJ=_V4ZBNEks=dX4ki2YQBHcPPpUrABg@mail.gmail.com>
 <5856354a-393a-0803-e3e6-da29f8f7d8b1@treenet.co.nz>
Message-ID: <CACabJxNaikH2R8rNSy2L=12PNohYWA65QjGRcR__yMLLbeyssA@mail.gmail.com>

Hi Amos,

Thanks will keep you posted if we proceed with the sock option flag and are
able to test it in our environment.
BTW, noticed that using multiple outbound IP's each with their own ACLs,
slows the squid server significantly after about 80k concurrent sessions.
We will test out both solutions and get in touch.

Thanks
Praveen

On Fri, May 20, 2022 at 9:31 PM Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 20/05/22 19:44, Praveen Ponakanti wrote:
> > Hi Alex,
> >
> > Thanks for going through several steps to help mitigate src port
> > exhaustion. We are looking to achieve 400-500% more
> > concurrent connections if we could :) as there is a significant buffer
> > on the available CPU.
>
> Then you require at least 4, maybe 5, IP addresses to handle that many
> concurrent connections with Squid.
>
>
> > The option to use multiple tcp_outoing_addresses appears to be promising
> > along with some tweaks to the TCP timeouts. I guess we could use ACLs to
> > pick a different outbound IP based on the requesting client's prefix. We
> > had not considered that option as the ephemeral ports were no longer
> > available to other applications when squid uses most of them with a
> > single outbound IP configured. We are also looking to modify the code to
> > use the IP_BIND_ADDRESS_NO_PORT sockopt as that could help delay port
> > assignment with the bind() call on the outbound TCP sessions (to
> > hopefully allow access to the 4-tuple on the socket).
>
> Patches welcome.
>
> However, please be aware that use of the 4-tuple is often no different
> from the 3-tuple since the dst-port is typically identical for all
> outgoing traffic to a given dst-IP.
>
>
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220522/4c4a3043/attachment.htm>

From jernej.porenta at 3fs.si  Mon May 23 05:41:32 2022
From: jernej.porenta at 3fs.si (Jernej Porenta)
Date: Mon, 23 May 2022 07:41:32 +0200
Subject: [squid-users] ssl-bump connect issues
Message-ID: <1F75EFFB-9D08-4E33-A429-D6C57D61232D@3fs.si>

Hey,

I am trying to establish a caching squid proxy - 5.5 openssl -  ( to be used with our CI/CD system and cache npm modules (we configure http_proxy in our npm configuration).

I've created a configuration with ssl bump-ing and aggressive npm module caching. When a client starts fetching the modules through proxy, everything works fine however quite soon the connections start stalling and all end up timeouting.

The logs show that clients did issue a CONNECT, however the connections are stuck (and eventually timeout) and netstat is showing exactly 10 connections in SYN_SENT state towards npm registry. I am kinda puzzled, where this number comes from.

I am wondering whether npm registry starts throttling me or I am hitting some networking issue or squid misconfiguration.

Does anyone has any idea what could be the issue? (or if someone is using squid for npm module caching, are you willing to share your working squid.conf ;))?

Big thank you in advance, br, Jernej

The "relevant" parts of my configurations are:

acl intermediate_fetching transaction_initiator certificate-fetching
http_access allow intermediate_fetching
http_port 80 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB tls-cert=/etc/squid/certs/squid-self-signed.crt tls-key=/etc/squid/certs/squid-self-signed.key cipher=HIGH:MEDIUM:!LOW:!RC4:!SEED:!IDEA:!3DES:!MD5:!EXP:!PSK:!DSS options=NO_TLSv1,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE tls-dh=prime256v1:/etc/squid/certs/squid-self-signed_dhparam.pem disable-pmtu-discovery=transparent

sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/spool/squid/ssl_db -M 20MB
sslcrtd_children 8
ssl_bump server-first all
sslproxy_cert_error deny all

forwarded_for delete
via off
request_header_access X-Forwarded-For deny all
request_header_access Via  deny all

# dns
positive_dns_ttl 31 seconds
negative_dns_ttl 30 seconds
httpd_suppress_version_string on
connect_timeout 10 seconds


squid -v: https://pastebin.com/KRywK3rN <https://pastebin.com/KRywK3rN>
Full config: https://pastebin.com/xsgS5J38 <https://pastebin.com/xsgS5J38>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220523/367b7d2b/attachment.htm>

From squid3 at treenet.co.nz  Mon May 23 13:57:23 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 24 May 2022 01:57:23 +1200
Subject: [squid-users] ssl-bump connect issues
In-Reply-To: <1F75EFFB-9D08-4E33-A429-D6C57D61232D@3fs.si>
References: <1F75EFFB-9D08-4E33-A429-D6C57D61232D@3fs.si>
Message-ID: <ab080f2b-b143-bf49-0969-3bafd743274e@treenet.co.nz>

On 23/05/22 17:41, Jernej Porenta wrote:
> 
> The logs show that clients did issue a CONNECT, however the connections 
> are stuck (and eventually timeout) and netstat is showing exactly 10 
> connections in SYN_SENT state towards npm registry. I am kinda puzzled, 
> where this number comes from.
> 

This sounds a bit like other situations where the sslcrtd_program helper 
has hung and stopped generating certificates.



> Big thank you in advance, br, Jernej
> 
> The "relevant" parts of my configurations are:
> 
> acl intermediate_fetching transaction_initiator certificate-fetching
> http_access allow intermediate_fetching

This is not all of the required http_access rules. Please list them all.


> http_port 80 ssl-bump generate-host-certificates=on 
> dynamic_cert_mem_cache_size=20MB 
> tls-cert=/etc/squid/certs/squid-self-signed.crt 
> tls-key=/etc/squid/certs/squid-self-signed.key 
> cipher=HIGH:MEDIUM:!LOW:!RC4:!SEED:!IDEA:!3DES:!MD5:!EXP:!PSK:!DSS 
> options=NO_TLSv1,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE 
> tls-dh=prime256v1:/etc/squid/certs/squid-self-signed_dhparam.pem 
> disable-pmtu-discovery=transparent
> 
> sslcrtd_program /usr/lib/squid/security_file_certgen -s 
> /var/spool/squid/ssl_db -M 20MB
> sslcrtd_children 8
> ssl_bump server-first all


This "server-first" action is outdated. Please upgrade. The modern 
equivalent would be:

   acl step1 at_step SslBump1
   ssl_bump peek step1
   ssl_bump bump cachedSites
   ssl_bump splice all


> sslproxy_cert_error deny all
> 

This may be hiding symptoms you need to figure the problem out. It is 
best to start with everything allowed and only deny the specific errors 
that are not relevant to the client(s).


> 
> # dns
> positive_dns_ttl 31 seconds
> negative_dns_ttl 30 seconds

These also may be the source of problems. They prevent Squid from 
obeying short-TTL on DNS responses typically used by repositories to 
load balance large amounts of traffic and/or server failure recovery.



HTH
Amos


From ngtech1ltd at gmail.com  Tue May 24 07:39:17 2022
From: ngtech1ltd at gmail.com (Eliezer Croitoru)
Date: Tue, 24 May 2022 10:39:17 +0300
Subject: [squid-users] The usage of extended SNMPD commands to monitor squid.
Message-ID: <002e01d86f41$6060e5b0$2122b110$@gmail.com>

Since the Squid-Cache project doesn't maintain the SNMP part of it as far as
I know I was thinking about:

Using extended SNMPD ie in /etc/snmp/snmpd.conf

 

extend squid_x_stats /bin/bash /usr/local/bin/squid_x_stats.sh

 

while the binary itself probably will be a single command/script that will
have symlinks to itself with a different name (like what busybox provides
binaries).

With a set of these commands it would be possible to monitor squid via the
linux SNMPD and the backend would be a script.

To overcome a DOS from the SNMP side I can build a layer of caching in
files.
It would not be like the current squid SNMP tree of-course but as long the
data is there it can be used in any system that supports it.

I have used nagios/cacti/others to create graphs based on this concept.

 

I am currently working on the PHP re-testing project and it seems that PHP
7.4 is not exploding it's memory and crashes compared to older versions.

I still need a more stressed system to test the scripts.

I have created the next scripts for now:

*	Fake helper
*	Session helper based on Redis
*	Session helper based on FS in /var/spool/squid/session_helper_fs

 

Eliezer

 

----

Eliezer Croitoru

NgTech, Tech Support

Mobile: +972-5-28704261

Email:  <mailto:ngtech1ltd at gmail.com> ngtech1ltd at gmail.com

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220524/ec70ce72/attachment.htm>

From suporte at konntrol.com.br  Tue May 24 12:23:19 2022
From: suporte at konntrol.com.br (Suporte - Konntrol)
Date: Tue, 24 May 2022 09:23:19 -0300
Subject: [squid-users] Squid 4.15 on FreeBSD 12.2 Stable - Kerberos
 helper issues
In-Reply-To: <7bc76568-afad-ea85-4fa9-72c362e32e4b@treenet.co.nz>
References: <000801d86c69$e3008e60$a901ab20$@konntrol.com.br>
 <7bc76568-afad-ea85-4fa9-72c362e32e4b@treenet.co.nz>
Message-ID: <001d01d86f69$0fa15470$2ee3fd50$@konntrol.com.br>

Thanks Amos.
I have recreated the keytab and it is back working, although I will need to better investigate the root cause of it.
I will check the expiration time as you mentioned.

Thanks once again!
Fabricio.

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Saturday, May 21, 2022 2:50 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid 4.15 on FreeBSD 12.2 Stable - Kerberos helper issues

On 21/05/22 04:51, Suporte - Konntrol wrote:
> Hello everyone,
> 
> Greetings.
> 
> I got a strange situation with my SQUID 4.1 (FreeBSD 12.2 Stable 
> environment).
> 
> Everything was working fine with Kerberos configuration and suddenly 
> it stopped with the following error:
> 
> ==> /var/squid/logs/cache.log <==
> 
> negotiate_kerberos_auth.cc(182): pid=85679 :2022/05/20 13:35:43|
> negotiate_kerberos_auth: ERROR: gss_acquire_cred() failed: No 
> credentials were supplied, or the credentials were unavailable or 
> inaccessible. No principal in keytab matches desired name
> 
> 2022/05/20 13:35:43| negotiate_kerberos_auth: INFO: User not 
> authenticated
> 
> Judging by the ?No principal in keytab matches desired name? message, 
> I went immediately to the AD object to check if it was really missing 
> the Principal entry.
> 
> To my surprise, everything is there. (talking about the 
> HTTP/fqdn at REALM entry).

That error message has a lot of parts.  Check the debug trace to see if you can find out what that "desired name" is for that lookup. It may be something odd going on there.

Also, notice the character cases. Sometimes it matters, so best to make sure they always line up.


> 
> Also, I checked the contents of my keytab, which looks OK, as it 
> contains the HTTP/server01.mydomain.corp at MYDOMAIN.CORP entry as well.
> 
> Additionally, I checked the DNS configuration for the PTR and Reverse 
> entries. It looks OK as well.
> 
> I have used ?net ads join 
> createupn=HTTP/server01.mydomain.corp at MYDOMAIN.CORP -k? commands to Join 
> the Squid machine to Domain, and ?net ads keytab create -k? to create a 
> keytab.
> 
> Also, used the command ?net ads keytab add HTTP? to add the HTTP entry 
> to the keytab.
>
...
> 
> As I mentioned, that was working for months, then stopped.
> 

IME, this type of sudden delayed breakage usually occurs when there is 
some validity period associated with the credentials in the keytab (or 
domain controller which created it). There is a disclaimer in the wiki 
about the "net ads" under some conditions adding an expiry time.

<https://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos#Create_keytab>

Rebuilding the keytab with kinit and msktutil may fix it for you.


HTH
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From jernej.porenta at 3fs.si  Tue May 24 15:05:41 2022
From: jernej.porenta at 3fs.si (Jernej Porenta)
Date: Tue, 24 May 2022 17:05:41 +0200
Subject: [squid-users] ssl-bump connect issues
In-Reply-To: <ab080f2b-b143-bf49-0969-3bafd743274e@treenet.co.nz>
References: <1F75EFFB-9D08-4E33-A429-D6C57D61232D@3fs.si>
 <ab080f2b-b143-bf49-0969-3bafd743274e@treenet.co.nz>
Message-ID: <58F4366A-B798-47BE-B221-39C3BEF8E2EB@3fs.si>

Hey,

thank you for your response.

>> The logs show that clients did issue a CONNECT, however the connections are stuck (and eventually timeout) and netstat is showing exactly 10 connections in SYN_SENT state towards npm registry. I am kinda puzzled, where this number comes from.
> 
> This sounds a bit like other situations where the sslcrtd_program helper has hung and stopped generating certificates.

I've checked that and it seems this part is working just fine.

> 
>> Big thank you in advance, br, Jernej
>> The "relevant" parts of my configurations are:
>> acl intermediate_fetching transaction_initiator certificate-fetching
>> http_access allow intermediate_fetching
> 
> This is not all of the required http_access rules. Please list them all.

You can check the whole configuration file here: https://pastebin.com/h7ryfArx

> 
>> http_port 80 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB tls-cert=/etc/squid/certs/squid-self-signed.crt tls-key=/etc/squid/certs/squid-self-signed.key cipher=HIGH:MEDIUM:!LOW:!RC4:!SEED:!IDEA:!3DES:!MD5:!EXP:!PSK:!DSS options=NO_TLSv1,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE tls-dh=prime256v1:/etc/squid/certs/squid-self-signed_dhparam.pem disable-pmtu-discovery=transparent
>> sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/spool/squid/ssl_db -M 20MB
>> sslcrtd_children 8
>> ssl_bump server-first all
> 
> 
> This "server-first" action is outdated. Please upgrade. The modern equivalent would be:
> 
>  acl step1 at_step SslBump1
>  ssl_bump peek step1
>  ssl_bump bump cachedSites
>  ssl_bump splice all

Updated it to your recommendation.

> 
>> sslproxy_cert_error deny all
> 
> This may be hiding symptoms you need to figure the problem out. It is best to start with everything allowed and only deny the specific errors that are not relevant to the client(s).

I've tried to comment it out but there was no difference.

>> # dns
>> positive_dns_ttl 31 seconds
>> negative_dns_ttl 30 seconds
> 
> These also may be the source of problems. They prevent Squid from obeying short-TTL on DNS responses typically used by repositories to load balance large amounts of traffic and/or server failure recovery.

Removed.

I've ran some additional test and found out that one of the servers (which is resolved from yarnpkg.com) is not accessible and it seeems that that one is causing all the others to halt. Once the connect_timeout period is over, new batch of requests is processed without a problem.

Is there a way to disable this behaviour? (or maybe it is actually yarn's behaviour that stops requesting if registry is not available?)

Thank you in advance, br, Jernej

From mgresko8 at gmail.com  Wed May 25 05:21:36 2022
From: mgresko8 at gmail.com (=?UTF-8?Q?Marek_Gre=C5=A1ko?=)
Date: Wed, 25 May 2022 07:21:36 +0200
Subject: [squid-users] Squid 4.15 on FreeBSD 12.2 Stable - Kerberos
 helper issues
In-Reply-To: <001d01d86f69$0fa15470$2ee3fd50$@konntrol.com.br>
References: <000801d86c69$e3008e60$a901ab20$@konntrol.com.br>
 <7bc76568-afad-ea85-4fa9-72c362e32e4b@treenet.co.nz>
 <001d01d86f69$0fa15470$2ee3fd50$@konntrol.com.br>
Message-ID: <CAChjPdR8OX5m3449K8jVwvuLCmx5+S1rqxMOikPxs-V_TT_myQ@mail.gmail.com>

Hello,

did not you change the password on the account? If you change password you
should recreate the keytab.

Marek


ut 24. 5. 2022 o 14:23 Suporte - Konntrol <suporte at konntrol.com.br>
nap?sal(a):

> Thanks Amos.
> I have recreated the keytab and it is back working, although I will need
> to better investigate the root cause of it.
> I will check the expiration time as you mentioned.
>
> Thanks once again!
> Fabricio.
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Amos Jeffries
> Sent: Saturday, May 21, 2022 2:50 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid 4.15 on FreeBSD 12.2 Stable - Kerberos
> helper issues
>
> On 21/05/22 04:51, Suporte - Konntrol wrote:
> > Hello everyone,
> >
> > Greetings.
> >
> > I got a strange situation with my SQUID 4.1 (FreeBSD 12.2 Stable
> > environment).
> >
> > Everything was working fine with Kerberos configuration and suddenly
> > it stopped with the following error:
> >
> > ==> /var/squid/logs/cache.log <==
> >
> > negotiate_kerberos_auth.cc(182): pid=85679 :2022/05/20 13:35:43|
> > negotiate_kerberos_auth: ERROR: gss_acquire_cred() failed: No
> > credentials were supplied, or the credentials were unavailable or
> > inaccessible. No principal in keytab matches desired name
> >
> > 2022/05/20 13:35:43| negotiate_kerberos_auth: INFO: User not
> > authenticated
> >
> > Judging by the ?No principal in keytab matches desired name? message,
> > I went immediately to the AD object to check if it was really missing
> > the Principal entry.
> >
> > To my surprise, everything is there. (talking about the
> > HTTP/fqdn at REALM entry).
>
> That error message has a lot of parts.  Check the debug trace to see if
> you can find out what that "desired name" is for that lookup. It may be
> something odd going on there.
>
> Also, notice the character cases. Sometimes it matters, so best to make
> sure they always line up.
>
>
> >
> > Also, I checked the contents of my keytab, which looks OK, as it
> > contains the HTTP/server01.mydomain.corp at MYDOMAIN.CORP entry as well.
> >
> > Additionally, I checked the DNS configuration for the PTR and Reverse
> > entries. It looks OK as well.
> >
> > I have used ?net ads join
> > createupn=HTTP/server01.mydomain.corp at MYDOMAIN.CORP -k? commands to
> Join
> > the Squid machine to Domain, and ?net ads keytab create -k? to create a
> > keytab.
> >
> > Also, used the command ?net ads keytab add HTTP? to add the HTTP entry
> > to the keytab.
> >
> ...
> >
> > As I mentioned, that was working for months, then stopped.
> >
>
> IME, this type of sudden delayed breakage usually occurs when there is
> some validity period associated with the credentials in the keytab (or
> domain controller which created it). There is a disclaimer in the wiki
> about the "net ads" under some conditions adding an expiry time.
>
> <
> https://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos#Create_keytab
> >
>
> Rebuilding the keytab with kinit and msktutil may fix it for you.
>
>
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220525/997fa570/attachment.htm>

From david at articatech.com  Wed May 25 16:31:55 2022
From: david at articatech.com (David Touzeau)
Date: Wed, 25 May 2022 18:31:55 +0200
Subject: [squid-users] Squid load simulation tools for performance
 testing
In-Reply-To: <20220510053206.M8842@cdot.in>
References: <20220510053206.M8842@cdot.in>
Message-ID: <4e94f7ec-161e-c9ea-77a7-7ec6c934d3fc@articatech.com>

Use "siege" it can simulate x users for x urls

You can also use our free of charge appliance that allows you to easily 
use siege.

https://wiki.articatech.com/en/proxy-service/tuning/stress-your-proxy-server



Le 10/05/2022 ? 07:33, Punyasloka Arya a ?crit?:
> Dear ALL,
>
> We have just installed Squid 5.5 (stable version) from source on ubuntu
> 20.0.4.
> Before putting in the production network, we want to test the performance of
> squid by monitoring critical parameters like response time,  cache hits, cache
> misses etc
> We would like to know tools/software/scripts to simulate load conditions for
> 500 users with at least 1K connections.
>
> Any help is greatly appreciated.
>
> From
> Punyasloka Arya
> PUNYASLOKA ARYA            ?????????? ?????
> Staffno:3880,Netops,TS(B)
> Senior Research Engineer   ?????? ???????? ???????
> C-DOT                      ??-???
> Electronics City,Phase-1   ?????????????? ???? ???? I
> Hosur Road,Bangalore       ????? ???, ????????
> 560100                     560100
> ### Please consider the environment and print this email only if necessary
> .
> Go Green ###
>
> Disclaimer :
> This email and any files transmitted with it are confidential and intended
> solely for the use of the individual or entity to whom they are addressed.
> If you are not the intended recipient you are notified that disclosing,
> copying, distributing or taking any action in reliance on the contents of
> this
> information is strictly prohibited. The sender does not accept liability
> for any errors or omissions in the contents of this message, which arise
> as
> a
> result.
>
> --
> Open WebMail Project (http://openwebmail.org)
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-- 
Technical Support
	
	
*David Touzeau*
Orgerus, Yvelines, France
*Artica Tech*

P:?+33 6 58 44 69 46
www: wiki.articatech.com <https://wiki.articatech.com>
www: articatech.net <http://articatech.net>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220525/0bfd02a3/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: xfNSewvHHfFqz86n.jpg
Type: image/jpeg
Size: 6266 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220525/0bfd02a3/attachment.jpg>

From iat at st-andrews.ac.uk  Mon May 30 09:58:07 2022
From: iat at st-andrews.ac.uk (Ian A Taylor)
Date: Mon, 30 May 2022 10:58:07 +0100
Subject: [squid-users] squid only partially working WHY ?
Message-ID: <e5f3e45e-7307-6059-919f-427ad2ef795e@st-andrews.ac.uk>

Good day

I have install ubuntu 22.04 server on 4 machines

The machines are

spark

compute-0-[0,1,2]

spark has an internet connect plus a connection to a restricted 
(10.1.1.0/24) network

compute-0-[0,1,2] are on the restricted network

2 of the three compute-0-[0,1,2] machines install with snap ok

but the third fails

I cannot see why

compute-0-1 - which works has


systemctl show snapd | grep proxy
 ??? Environment=http_proxy=http://10.1.1.1:3128/ 
https_proxy=http://10.1.1.1:3128/
DropInPaths=/etc/systemd/system/snapd.service.d/http-proxy.conf 
/etc/systemd/system/snapd.service.d/https-proxy.conf

snap install test-snapd-tools
 ??? test-snapd-tools 1.0 from Test snaps (test-snaps-canonical) installed

On spark in /var/log/squid/access.log I see

spark:/var/log/squid/access.log
1653903438.774?? 5093 10.1.1.253 TCP_TUNNEL/200 4899 CONNECT 
api.snapcraft.io:443 - HIER_DIRECT/185.125.188.58 -
1653903442.705?? 5107 10.1.1.253 TCP_TUNNEL/200 4909 CONNECT 
api.snapcraft.io:443 - HIER_DIRECT/185.125.188.58 -
1653903442.872?? 9738 10.1.1.253 TCP_TUNNEL/200 25383 CONNECT 
api.snapcraft.io:443 - HIER_DIRECT/185.125.188.58 -

However on compute-0-2

systemctl show snapd | grep proxy
 ??? Environment=http_proxy=http://10.1.1.1:3128/ 
https_proxy=http://10.1.1.1:3128/
DropInPaths=/etc/systemd/system/snapd.service.d/http-proxy.conf 
/etc/systemd/system/snapd.service.d/https-proxy.conf


snap install test-snapd-tools

 ?? generates

 ??? error: cannot install "test-snapd-tools": cannot query the store 
for updates: got unexpected HTTP
 ?????????? status code 500 via POST to 
"http://snaps.spark.internal/v2/snaps/refresh"


spark:/var/log/squid/access.log
1653903468.117????? 1 10.1.1.252 TCP_MISS/500 5394 POST 
http://snaps.spark.internal/v2/snaps/refresh - HIER_NONE/- text/html
1653903468.617????? 0 10.1.1.252 TCP_MISS/500 5394 POST 
http://snaps.spark.internal/v2/snaps/refresh - HIER_NONE/- text/html
1653903469.867????? 0 10.1.1.252 TCP_MISS/500 5394 POST 
http://snaps.spark.internal/v2/snaps/refresh - HIER_NONE/- text/html
1653903472.991????? 0 10.1.1.252 TCP_MISS/500 5394 POST 
http://snaps.spark.internal/v2/snaps/refresh - HIER_NONE/- text/html
1653903480.804????? 0 10.1.1.252 TCP_MISS/500 5394 POST 
http://snaps.spark.internal/v2/snaps/refresh - HIER_NONE/- text/html
1653903485.009? 51235 10.1.1.253 TCP_TUNNEL/200 117316495 CONNECT 
canonical-lgw01.cdn.snapcraftcontent.com:443 - HIER_DIRECT/185.125.190.27 -
1653903487.747? 50040 10.1.1.253 TCP_TUNNEL/200 12970 CONNECT 
canonical-lgw01.cdn.snapcraftcontent.com:443 - HIER_DIRECT/185.125.190.27 -
1653903500.336????? 0 10.1.1.252 TCP_MISS/500 5394 POST 
http://snaps.spark.internal/v2/snaps/refresh - HIER_NONE/- text/html


spark:/etc/squid/squid.conf
acl localnet src 10.1.1.254/32
acl localnet src 10.1.1.253/32
acl localnet src 10.1.1.252/32

If someone could indicate why this is happening I would be sincerely 
appreciative

On compute-0-2 an apt-get install appears to work ok, the problem is 
only on snaps

curl -v api.snapcraft.io
 ??? *?? Trying 185.125.188.54:80...
 ??? * Connected to api.snapcraft.io (185.125.188.54) port 80 (#0)
 ??? > GET / HTTP/1.1
 ??? > Host: api.snapcraft.io
 ??? > User-Agent: curl/7.81.0
 ??? > Accept: */*
 ??? >
 ??? * Mark bundle as not supporting multiuse
 ??? < HTTP/1.1 200 OK
 ??? < server: gunicorn/20.0.4
 ??? < date: Mon, 30 May 2022 09:46:00 GMT
 ??? < content-type: text/html; charset=utf-8
 ??? < content-length: 64
 ??? < snap-store-version: 49
 ??? < x-view-name: snapdevicegw.webapi.root
 ??? < x-vcs-revision: 9abffbb1
 ??? < x-request-id: 8AFB0DA87C990A8325F000506294925814E73D9D
 ??? <
 ??? snapcraft.io store API service - Copyright 2018-2021 Canonical.
 ??? * Connection #0 to host api.snapcraft.io left intact


snap known serial

type: serial
authority-id: generic
brand-id: generic
model: generic-classic
serial: a0f0dea6-d87a-44b1-bb5c-daa40e1787a0
device-key:
AcbBTQRWhcGAARAAlEwUeRrlL215Ouf4CrZKrkGA3YyzqG2G7zVbkYQVeXLyos87OdD21UJVmri4 

hpeqX4lkrjcDS7gCxyOcmUekoM6bNILdlEt8ag1j8if5ZuomhS4xlX1reWkdAjNvMRK9vMpOWDnv 

dFQwfLtvR5K/WHCAXT57U5WXTuDJIGpyf9d3waulpsj1Fr1O5VcJyVXRPOQzizd2U3FAQPk35eKh 

NF68JqHFb6z7CIWIlTxl77D3Z0VMGUx5XYUS3xljC6EMeGeN0d1nen+NWXLw+x56MAbL1gyzRN3f 

pqvWY0vB7zdDNXm72DJ1WDrGwujQJ81OzQ33Ao3N9sSscvrEnjdkN3jfIejJ6TIk8xN679afavTU 

Y6fXEYM8S3LQbix1OELeu8UKWoUxhoNRW2e1rMirIUpeOwt+oPdEcEQGTqfcKQ4tO+AmMSOFS5Lv 

6Je3chdNiao13AYVJXcU7bUeP6IsHLLa3pi+4N00BiqNv3dqjpDQUBAkqaCOVkp8BmEpDdX+pper 

y//VfUyHBAS31+H9cWOSxLfhXdMsBxmtW4tftpm21eylKhFC0q+4IBxqj4P2TWsTmgOHW+1G0F4o 

qPVIGstYV12AO0f3m/8Ql5H7hW+qG2WaQe0P16B55Xb35qtTX0r0nh4a1sdG5qtdZqSRx6yJ4FJ/ 

 ??? dtmrSB3rXGK9LFkAEQEAAQ==
device-key-sha3-384: 
NyBU-b-3_f_Odfthy6vD3cq1hGGzMaulU-AUM8abFgmypUQVkPsJQz_1fmE4dUYW
timestamp: 2022-05-09T10:00:01.908678Z
sign-key-sha3-384: 
wrfougkz3Huq2T_KklfnufCC0HzG7bJ9wP99GV0FF-D3QH3eJtuSRlQc2JhrAoh1

AcLBUgQAAQoABgUCYnjmIQAAKpkQABSLcE/cMlISdOYBmV/te7EqNcIIJfPTAXYfe0/o9Pif9p+u 

Hsl6UDKfe7RS+QQARstsaJhTznSEJwJMvKaCrPKlmTUL1vldRuu70Rz3q3Hf2cdXVXJZutQNNNHa 

sAwzpAkVSXQ5Fjx99xYXjDURriA9+jt6ZXDcCD538M9m7+vNI21ynMlZVz/FmUMYz5z+8XP76faq 

vnvKXqS3uGXF7O6QMo42XIQqUmPiJGrhUl56e66BOhjShsEynpBkQNDbf0SKN1ELFPl7evYT52E4 

aFYs6rGx8Ip6E9xmWfrR4wNgjM/Zimdjs37+591vYyY/k2E7igT8bd3+xhqlkJlghfch2m7IkhWM 

kArg4oXA+I7H9NbGY4wGcgfPLPOujMzbXEgLnh8u1qp0QVxyMNRUCCPrv80uaRkA9tWrtxsOC5gI 

whQ1FOkaavX/ZW9z7XWhBRBPRuxgp6AFgpoQgbN+6DJDDk11/hc1GbGBPdDIFhMAd2/kwfvEQ+nR 

TnnM9JApjdXb/MNmooJVDu3BQvszUuOa6emKP79jvVVP60R0/wNrzjfssseqkyfRizZkdQvJ4IR2 

MTwPlmXIBhAhJsLif6ql8Ht/7X7RFT8ybXHRfB/SDsI1IZGyddV6hjCDMOGj3BfOfOJWhk1r5/WR 

lg589GakIn3XoH43jdqlxknqAKhc

snap list
Name?? Version? Rev??? Tracking?????? Publisher?? Notes
snapd? 2.55.3?? 15534? latest/stable? canonical?? snapd


Thanking you

Regards




-- 
Ian Taylor
University of St.Andrews,
School of Physics & Astronomy,
North Haugh,
St.Andrews,
Fife? KY16 9SS,
Scotland.

e-Mail :- iat at st-and.ac.uk
Tel??? :- (0)1334-463141
Fax??? :- (0)1334-463104

The University of St Andrews
is a charity registered in
Scotland : No SC013532.



