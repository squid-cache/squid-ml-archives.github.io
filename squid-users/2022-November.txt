From ifoolb at gmail.com  Tue Nov  1 01:32:27 2022
From: ifoolb at gmail.com (mingheng wang)
Date: Tue, 1 Nov 2022 09:32:27 +0800
Subject: [squid-users] Does Squid support client ssl termination?
In-Reply-To: <d2f323de-03eb-e828-11ad-fc310fccaad9@spamtrap.tnetconsulting.net>
References: <CAB-cPApGGo1zHR1hVdVUGGLnLA1Ciy3hF1J+9L3a6O1Ap=0r-A@mail.gmail.com>
 <f1a6b704-38c0-321b-486c-1dfa01ed5c3c@spamtrap.tnetconsulting.net>
 <CAB-cPAqzHKh=iLTOVMYGMuV0BX9JKE6gKWUDpFRV=FcUnRTETw@mail.gmail.com>
 <d2f323de-03eb-e828-11ad-fc310fccaad9@spamtrap.tnetconsulting.net>
Message-ID: <CAB-cPArjyq_LpNs+ak8vMk4HJh5X5ce5=MPNwHBWULz7SC1juw@mail.gmail.com>

On Mon, Oct 31, 2022, 11:46 PM Grant Taylor <gtaylor at tnetconsulting.net>
wrote:

> Hi,
>
> Pre-script:  Did you mean to reply directly to me?  Or did you intend
> for your reply to go to the squid-users mailing list?
>
> Sorry about that, don't know why it only went to you.

> On 10/27/22 6:47 PM, mingheng wang wrote:
> > In my experience, many clients, such as Firefox and Chrome, favor
> > HTTPS over HTTP, and some clients even enforce HTTPS. They down right
> > send HTTPS CONNECT to 443.
>
> I think that is a relatively recent change in preference.
>
> > Does this mean Squid does support this:
> >   Client --[HTTPS on self-signed certs]-->Squid--[HTTP]--> site (suppose
> > it doesn't redirect)
>
> Yes, that is entirely likely to happen.
>
> N.B. I'm going to trust that the self-signed vs CA-signed certs are a
> non-issue and that clients have been configured to trust whatever cert
> is being used, no matter who signed it.
>
> I delved into the configuration the last few days, and found that Squid
doesn't officially support
cache_peer when ssl_bump is in use. Actually, I can't find a single tool in
the market that
can just encrypt any HTTP connection, "converting" it to an HTTPS
connection. I'm reading
RFCs and documentation to write my own proxy.


> > My Apache server only listens on 80, but when using Cloudflare in
> > front of it, Cloudflare can add HTTPS support, signed by them, and
> > web browsers say the connection is secured. So I thought Squid could
> > do the same, only with self-signed certs.
>
> Cloudflare is functioning as a /reverse/-proxy in that case.  Forward vs
> reverse proxy is technically different and has different semantics.
>
> I believe that Squid can function as a reverse proxy.
>
> This is what still confuses me. A reverse proxy is supposed to proxy a web
site. At least that's what I learnt from Nginx and Haproxy's documentation.
I'll read more on this when I have time.


> > Because I also want to avoid TLS over TLS, if I chain another HTTPS
> > proxy between the local Squid and the remote Squid. Our company's
> > gateway monitors traffic and forbids tunnels to prevent accessing
> > systems from outside but this is also hurting my internet access. When
> > using HTTPS over a SSL tunnel within our company, it may trigger the
> > IT security policy.
>
> Okay.  This local restriction may complicate things.
>
> Very tough network environment. They can even somehow detect a confidential
file going through the gateway, even with TLS.

> That would mean that unencrypted sites would never be encrypted between
> the two proxies.  If that's okay with you, then fine by me.
>
> > The downstream child Squid is running on the same localhost as with
> > other programs that are going to use it.
>
> Okay.  Thank you for clarifying.
>
> Aside:  I see little benefit, and non-trivial complication, to do HTTPS
> web browser to Squid connections to have Squid do unencrypted traffic out.
>
> > I mean certs signed by well known public CA, like DigiCert, Cloudflare
> > etc.
>
> Okay.  Thank you for clarifying.
>
> > Our company blocks HTTPS connections with self-signed certs. It says
> > they're malicious.  Besides, I want to reuse the public CA signed
> > certs that my website uses. Sorry for not being clearer before,
> > perhaps my use case is too specific.
>
> Re-using CA-signed certificates from a web server on a Squid proxy
> server may not work as well as you hope.  There's a good chance that you
> will run into issues related to CN / SAN mis-match.
>
> If you don't have any CN / SAN mis-match issues, as in the original cert
> includes the proxy's name as a SAN, you'll probably be okay.
>
> I can just negotiate HTTPS using a separate piece of software and send
HTTP data
through the tunnel. I believe the important part is the TLS negotiation.
Eliminating TLS over TLS should be enough to evade our IT's DPI. They even
banned
git from accessing the net outside the company because they can't be sure
what we
are doing with git as it's simultaneously downloading and uploading.

>
>
> --
> Grant. . . .
> unix || die
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221101/c554486a/attachment.htm>

From gtaylor at tnetconsulting.net  Tue Nov  1 16:44:48 2022
From: gtaylor at tnetconsulting.net (Grant Taylor)
Date: Tue, 1 Nov 2022 10:44:48 -0600
Subject: [squid-users] Does Squid support client ssl termination?
In-Reply-To: <CAB-cPArjyq_LpNs+ak8vMk4HJh5X5ce5=MPNwHBWULz7SC1juw@mail.gmail.com>
References: <CAB-cPApGGo1zHR1hVdVUGGLnLA1Ciy3hF1J+9L3a6O1Ap=0r-A@mail.gmail.com>
 <f1a6b704-38c0-321b-486c-1dfa01ed5c3c@spamtrap.tnetconsulting.net>
 <CAB-cPAqzHKh=iLTOVMYGMuV0BX9JKE6gKWUDpFRV=FcUnRTETw@mail.gmail.com>
 <d2f323de-03eb-e828-11ad-fc310fccaad9@spamtrap.tnetconsulting.net>
 <CAB-cPArjyq_LpNs+ak8vMk4HJh5X5ce5=MPNwHBWULz7SC1juw@mail.gmail.com>
Message-ID: <fe883d44-d086-e63a-1ff7-ead23d31ba6c@spamtrap.tnetconsulting.net>

On 10/31/22 7:32 PM, mingheng wang wrote:
> Sorry about that, don't know why it only went to you.

Things happen.  That's why I let people know, in case unwanted things 
did happen.

> I delved into the configuration the last few days, and found that 
> Squid doesn't officially support cache_peer when ssl_bump is in 
> use.

That surprises me.  I wonder if it's a technical limitation or an oversight.

> Actually, I can't find a single tool in the market that can 
> just encrypt any HTTP connection, "converting" it to an HTTPS 
> connection. I'm reading RFCs and documentation to write my own proxy.

That really surprises me.

It's not a general proxy, but this seems like something that stunnel 
will do. (Either direction HTTPS <-> HTTP and HTTP <-> HTTPS.)

> This is what still confuses me. A reverse proxy is supposed to proxy 
> a web site. At least that's what I learnt from Nginx and Haproxy's 
> documentation.  I'll read more on this when I have time.

I think of forward and reverse proxies as doing quite similar things 
with the primary difference being where in the path they are and how 
many sites will be accessed.

Forward:  (C)---(P)---(Big Bad Internet)---------(S)
Reverse:  (C)---------(Big Bad Internet)---(P)---(S)

Both take requests from clients and pass them to (what the proxy thinks 
is) the server.

But with the forward proxy interfacing between relatively few clients 
and significantly more servers.

Conversely the reverse proxy interfaces with significantly more clients 
and relatively few servers.

The reverse proxy tends to be explicitly configured where servers are 
while the forward proxy relies on standard name resolution to find them, 
usually DNS.

So, on one level, what the forward and reverse proxy do is similar, but 
how they do it is subtly different.

Then there's this:

    Both:  (C)---(P)---(Big Bad Internet)---(P)---(S)

Where in both a client side forward proxy /and/ a server side reverse 
proxy are in use.  }:-)  This really is just both technologies being 
independently used at each end.

> Very tough network environment. They can even somehow detect a 
> confidential file going through the gateway, even with TLS.

I'm not going to ask questions.



-- 
Grant. . . .
unix || die

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4017 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221101/9ab61293/attachment.bin>

From squid3 at treenet.co.nz  Tue Nov  1 17:33:59 2022
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Wed, 02 Nov 2022 06:33:59 +1300
Subject: [squid-users] Does Squid support client ssl termination?
In-Reply-To: <fe883d44-d086-e63a-1ff7-ead23d31ba6c@spamtrap.tnetconsulting.net>
References: <CAB-cPApGGo1zHR1hVdVUGGLnLA1Ciy3hF1J+9L3a6O1Ap=0r-A@mail.gmail.com>
 <f1a6b704-38c0-321b-486c-1dfa01ed5c3c@spamtrap.tnetconsulting.net>
 <CAB-cPAqzHKh=iLTOVMYGMuV0BX9JKE6gKWUDpFRV=FcUnRTETw@mail.gmail.com>
 <d2f323de-03eb-e828-11ad-fc310fccaad9@spamtrap.tnetconsulting.net>
 <CAB-cPArjyq_LpNs+ak8vMk4HJh5X5ce5=MPNwHBWULz7SC1juw@mail.gmail.com>
 <fe883d44-d086-e63a-1ff7-ead23d31ba6c@spamtrap.tnetconsulting.net>
Message-ID: <9b11f08b20f9f7f4f4f4fad345161523@treenet.co.nz>

On 2022-11-02 05:44, Grant Taylor wrote:
> On 10/31/22 7:32 PM, mingheng wang wrote:
>> Sorry about that, don't know why it only went to you.
> 
> Things happen.  That's why I let people know, in case unwanted things 
> did happen.
> 
>> I delved into the configuration the last few days, and found that 
>> Squid doesn't officially support cache_peer when ssl_bump is in use.
> 
> That surprises me.  I wonder if it's a technical limitation or an 
> oversight.
> 

That is not true as a blanket statement.

What Squid officially *does not* support is decrypting traffic then 
sending the un-encrypted form to a HTTP-only cache_peer.

All other permutations of inbound TCP/TLS, http:// or https:// URL, and 
outbound TCP/TLS should currently work to some degree. The more recent 
your Squid version the better it is.


Amos


From mandycuba1985 at gmail.com  Tue Nov  1 17:59:29 2022
From: mandycuba1985 at gmail.com (Armando Ramos Roche)
Date: Tue, 1 Nov 2022 13:59:29 -0400
Subject: [squid-users] Problem with wss protocol.
Message-ID: <CACpUbeSioQj=5JiOnVTX6BghvypwtVp+0KTZ0T6RWjx4RVXhnQ@mail.gmail.com>

Hi all.
I was working with squid v3.3 on ubuntu 18.04, after migrating to ubuntu
20.04 a few months ago, squid was updated to version 3.5, currently version
3.5.27.
And I have realized that nothing that uses the wss or ws protocol works for
me, for example whatsapp, messenger etc...
I've searched the logs, but nothing shows up.
I am not doing SSL Bump.
And I've done some searching on the internet and can't find anything to
help me.
It does not even get a response from the server, it does not even leave a
trace in the log
Here the request in firefox:
{
"GET": {
"scheme": "wss",
"host": "web.whatsapp.com",
"filename": "/ws/chat"
}
}
{
"Cabeceras de la petici?n (585 B)": {
"headers": [
{
"name": "Accept",
"value": "*/*"
},
{
"name": "Accept-Encoding",
"value": "gzip, deflate, br"
},
{
"name": "Accept-Language",
"value": "es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3"
},
{
"name": "Cache-Control",
"value": "no-cache"
},
{
"name": "Connection",
"value": "keep-alive, Upgrade"
},
{
"name": "DNT",
"value": "1"
},
{
"name": "Host",
"value": "web.whatsapp.com"
},
{
"name": "Origin",
"value": "https://web.whatsapp.com"
},
{
"name": "Pragma",
"value": "no-cache"
},
{
"name": "Sec-Fetch-Dest",
"value": "websocket"
},
{
"name": "Sec-Fetch-Mode",
"value": "websocket"
},
{
"name": "Sec-Fetch-Site",
"value": "same-origin"
},
{
"name": "Sec-WebSocket-Extensions",
"value": "permessage-deflate"
},
{
"name": "Sec-WebSocket-Key",
"value": "CahSZ7V991nVOR4e+FTLIg=="
},
{
"name": "Sec-WebSocket-Version",
"value": "13"
},
{
"name": "Upgrade",
"value": "websocket"
},
{
"name": "User-Agent",
"value": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:106.0)
Gecko/20100101 Firefox/106.0"
}
]
}
}
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221101/67ce3332/attachment.htm>

From squid3 at treenet.co.nz  Tue Nov  1 18:09:23 2022
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Wed, 02 Nov 2022 07:09:23 +1300
Subject: [squid-users] Problem with wss protocol.
In-Reply-To: <CACpUbeSioQj=5JiOnVTX6BghvypwtVp+0KTZ0T6RWjx4RVXhnQ@mail.gmail.com>
References: <CACpUbeSioQj=5JiOnVTX6BghvypwtVp+0KTZ0T6RWjx4RVXhnQ@mail.gmail.com>
Message-ID: <b4ac3b36edfd213a24b80a2e04f6e17a@treenet.co.nz>

On 2022-11-02 06:59, Armando Ramos Roche wrote:
> Hi all.
> I was working with squid v3.3 on ubuntu 18.04, after migrating to 
> ubuntu
> 20.04 a few months ago, squid was updated to version 3.5, currently 
> version
> 3.5.27.
> And I have realized that nothing that uses the wss or ws protocol works 
> for
> me, for example whatsapp, messenger etc...
> I've searched the logs, but nothing shows up.

Not showing up in logs, even as a failed or rejected transaction is a 
sign that it is not going to Squid.

 From the syntax shown by Firefox it looks to me like HTTP/2 or HTTP/3. 
Which also means it is probably not going to Squid.

Amos


From gtaylor at tnetconsulting.net  Tue Nov  1 18:49:17 2022
From: gtaylor at tnetconsulting.net (Grant Taylor)
Date: Tue, 1 Nov 2022 12:49:17 -0600
Subject: [squid-users] Does Squid support client ssl termination?
In-Reply-To: <9b11f08b20f9f7f4f4f4fad345161523@treenet.co.nz>
References: <CAB-cPApGGo1zHR1hVdVUGGLnLA1Ciy3hF1J+9L3a6O1Ap=0r-A@mail.gmail.com>
 <f1a6b704-38c0-321b-486c-1dfa01ed5c3c@spamtrap.tnetconsulting.net>
 <CAB-cPAqzHKh=iLTOVMYGMuV0BX9JKE6gKWUDpFRV=FcUnRTETw@mail.gmail.com>
 <d2f323de-03eb-e828-11ad-fc310fccaad9@spamtrap.tnetconsulting.net>
 <CAB-cPArjyq_LpNs+ak8vMk4HJh5X5ce5=MPNwHBWULz7SC1juw@mail.gmail.com>
 <fe883d44-d086-e63a-1ff7-ead23d31ba6c@spamtrap.tnetconsulting.net>
 <9b11f08b20f9f7f4f4f4fad345161523@treenet.co.nz>
Message-ID: <c7774050-684e-73fa-69eb-646770ba66a7@spamtrap.tnetconsulting.net>

On 11/1/22 11:33 AM, squid3 at treenet.co.nz wrote:
> That is not true as a blanket statement.

Please clarify which statement / who you are addressing.

It seems as if you're addressing mingheng (copied below for convenience):

On 10/31/22 7:32 PM, mingheng wang wrote:
> I delved into the configuration the last few days, and found that 
> Squid doesn't officially support cache_peer when ssl_bump is in use.

But you may be addressing my statement (...):

On 11/1/22 10:44 AM, Grant Taylor wrote:
> That surprises me.  I wonder if it's a technical limitation or an 
> oversight.


On 11/1/22 11:33 AM, squid3 at treenet.co.nz wrote:
> What Squid officially *does not* support is decrypting traffic then 
> sending the un-encrypted form to a HTTP-only cache_peer.

Please elaborate.  I'm trying to develop a mental model of what is and 
is not supported with regard to client / proxy / server communications. 
I'm unclear on how this applies to the two potential HTTPS streams; 
client-to-proxy and proxy-to-server.  Or if this is more applicable to 
TLS-Bump on implicit / network transparent / intercepting proxies where 
the client thinks that it's talking HTTPS to the origin server and the 
proxy would really be downgrading security by stripping TLS.

Here is my mental model based on my current understanding.  Is the 
following diagram accurate?

             +-------------+-----------+
             |  P2S-HTTP   | P2S-HTTPS |
+-----------+-------------+-----------+
| C2P-HTTP  |  supported  | supported |
+-----------+-------------+-----------+
| C2P-HTTPS | unsupported | supported |
+-----------+-------------+-----------+
   C2P = Client to Proxy communication
   P2S = Proxy to server communication

> All other permutations of inbound TCP/TLS, http:// or https:// URL, and 
> outbound TCP/TLS should currently work to some degree. The more recent 
> your Squid version the better it is.

ACK



-- 
Grant. . . .
unix || die

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4017 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221101/c2a64f5f/attachment.bin>

From rousskov at measurement-factory.com  Tue Nov  1 19:22:27 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 1 Nov 2022 15:22:27 -0400
Subject: [squid-users] Does Squid support client ssl termination?
In-Reply-To: <9b11f08b20f9f7f4f4f4fad345161523@treenet.co.nz>
References: <CAB-cPApGGo1zHR1hVdVUGGLnLA1Ciy3hF1J+9L3a6O1Ap=0r-A@mail.gmail.com>
 <f1a6b704-38c0-321b-486c-1dfa01ed5c3c@spamtrap.tnetconsulting.net>
 <CAB-cPAqzHKh=iLTOVMYGMuV0BX9JKE6gKWUDpFRV=FcUnRTETw@mail.gmail.com>
 <d2f323de-03eb-e828-11ad-fc310fccaad9@spamtrap.tnetconsulting.net>
 <CAB-cPArjyq_LpNs+ak8vMk4HJh5X5ce5=MPNwHBWULz7SC1juw@mail.gmail.com>
 <fe883d44-d086-e63a-1ff7-ead23d31ba6c@spamtrap.tnetconsulting.net>
 <9b11f08b20f9f7f4f4f4fad345161523@treenet.co.nz>
Message-ID: <697d0e35-cfb6-4f7c-5273-6cff2dc88fdd@measurement-factory.com>

On 11/1/22 13:33, squid3 at treenet.co.nz wrote:
> On 2022-11-02 05:44, Grant Taylor wrote:
>> On 10/31/22 7:32 PM, mingheng wang wrote:
>>> I delved into the configuration the last few days, and found that 
>>> Squid doesn't officially support cache_peer when ssl_bump is in use.

>> That surprises me.? I wonder if it's a technical limitation or an 
>> oversight.

> That is not true as a blanket statement.

Agreed.


> What Squid officially *does not* support is decrypting traffic then 
> sending the un-encrypted form to a HTTP-only cache_peer.

Yes, if we are still talking about Squid that does SslBump.

Outside of SslBump, "decrypting traffic then sending the un-encrypted 
form to a HTTP-only cache_peer should be supported": A combination of 
https_port forward proxy (i.e. no SslBump!) and plain text cache_peer 
should work. I have not tested that, but there is no technical reason to 
prohibit that and, arguably, there is no policy reason to prohibit that 
either.


> All other permutations of inbound TCP/TLS, http:// or https:// URL, and 
> outbound TCP/TLS should currently work to some degree. The more recent 
> your Squid version the better it is.

The other thing that is not yet supported is "TLS inside TLS". That is, 
a combination of SslBump and a TLS cache_peer. That is a purely 
technical limitation.


HTH,

Alex.


From squid3 at treenet.co.nz  Tue Nov  1 19:24:03 2022
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Wed, 02 Nov 2022 08:24:03 +1300
Subject: [squid-users] FW: Encrypted browser-Squid connection errors
In-Reply-To: <753b5a29-f2ac-1128-da8b-5c3b7ae7a043@spamtrap.tnetconsulting.net>
References: <DBAPR02MB6149665159D0E233B10A60CFF5249@DBAPR02MB6149.eurprd02.prod.outlook.com>
 <DBAPR02MB6149F46E4378E1069758569EF5289@DBAPR02MB6149.eurprd02.prod.outlook.com>
 <d168d00a-e5e2-1a13-5661-abe33c3397ef@measurement-factory.com>
 <DBAPR02MB6149F7F567889AC742B77519F52B9@DBAPR02MB6149.eurprd02.prod.outlook.com>
 <c76e6f82-f587-c1ab-8f7e-2b22c7badcf6@measurement-factory.com>
 <1a598226-ffe8-f536-6fff-9f1ae7920544@spamtrap.tnetconsulting.net>
 <AM8PR04MB77454AD896CB65626FA54E878F2A9@AM8PR04MB7745.eurprd04.prod.outlook.com>
 <1f0c07d5-74a0-c3b2-ced1-f4334d6dc66a@spamtrap.tnetconsulting.net>
 <Y1FuER/x8qizD34c@fantomas.sk>
 <263997a6-37bd-c9e8-0651-64301048b5af@spamtrap.tnetconsulting.net>
 <17b1bac2-eaa5-775a-95e5-6cc6ffb2692a@suse.de>
 <0dc84627-5af0-78e1-9fe8-9a8329db92e1@spamtrap.tnetconsulting.net>
 <7b177298-2613-9215-2a99-b322e8b7c8e0@treenet.co.nz>
 <2f52e708-b1d8-ad6d-c9ea-62c3c5cf2965@spamtrap.tnetconsulting.net>
 <19fa29f8ddf517b0e38d73a7e6b0ca55@treenet.co.nz>
 <753b5a29-f2ac-1128-da8b-5c3b7ae7a043@spamtrap.tnetconsulting.net>
Message-ID: <a61972fddb4c5661ce60f4ddf47e7068@treenet.co.nz>

On 2022-11-01 11:38, Grant Taylor wrote:
> On 10/30/22 6:59 AM, squid3 at treenet.co.nz wrote:
>> Duane W. would be the best one to ask about the details.
>> 
>> What I know is that some 10-12 years ago I discovered an message by 
>> Duane mentioning that W3C had (given or accepted) port 3128 for Squid 
>> use. I've checked the squid-cache archives and not seeing the message.
>> 
>> Right now it looks like the W3C changed their systems and only track 
>> the standards documents. So I cannot reference their (outdated?) 
>> protocol registry :-{ . Also checked the squid-cache archives and not 
>> finding it email history. Sorry.
> 
> Did you by chance mean IANA?

No I meant W3C. Back in the before times things were a bit messy.

> 
> I looked and 3128 is registered to something other than Squid.
> 

Indeed, thus we cannot register it with IEFT/IANA now. The IANA http-alt 
port would probably be best if we did go official.


> Nor did their search bring anything up for Squid.
> 
>> I mean "authority" as used by HTTP specification, which refers to 
>> https://www.rfc-editor.org/rfc/rfc3986#section-3.2
>> 
>> Yes exactly. That is the source of the problem, perpetuated by the 
>> need to retain on-wire byte/octet backward compatibility until HTTP/2 
>> changed to binary format.
>> 
>> Consider what the proxy has to do when (not if) the IP:port being 
>> connected to are that proxy's (eg localhost:80) and the URL is only a 
>> path ("/") on an origin server somewhere else. Does the "GET / 
>> HTTP/1.0" mean "http://example.com/" or "http://example.net/" ?
> 
> I would hope that it would return an error page, much like Squid does 
> when it can't resolve a domain name or the connection times out.

You see my point I hope. A gateway proxy that returns an error to 
*every* request is not very good.


> 
>> The key point is that the proxy host:port and the origin host:port are 
>> two different authority and only the origin may be passed along in the 
>> URL (or URL+Host header).
> 
> Agreed.
> 
>> When the client uses port 80 and 443 thinking they are origin services 
>> it is *required* (per 
>> https://www.rfc-editor.org/rfc/rfc9112.html#name-origin-form) to omit 
>> the real origins info. Enter problems.
> 
> Why would a client (worth it's disk space) ever conflate the value of 
> it's configured proxy as the origin server?
> 

There is no "configured proxy" for this use-case.


> I can see a potential for confusion when using (network) transparent / 
> intercepting proxies.
> 

Those are the two most/extremely common instances of the problematic 
use-cases. All implicit use of proxy (or gateway) have the same issue.


> 
>> The defaults though are tuned for origin server (or reverse-proxy) 
>> direct contact.
> 
> I don't see how that precludes their use for (forward) proxy servers.
> 

I think you are getting stuck with the subtle difference between "use 
for case X" and "use by default".

ANY port number can be used for *some* use-case(s). "by default" has to 
work for *all* use-cases.


>> No Browser I know supports 
>> "http-alt://proxy.example.com?http://origin.example.net/index.html" 
>> URLs.
> 
> But I bet that many browsers would support:
> 
>    http://proxy.example.com:8080/?http://origin.example.net/index.html
> 

Note that you are now having to add a non-default port "8080" and path 
"/" to the URL to make it valid/accepted by the Browser.

Clients speaking HTTP origin-form (the http:// scheme) are not permitted 
to request tunnels or equivalent gateway services. They can only ask for 
resource representations.


> Also, I'm talking about "http://" and "https://" using their default 
> ports of 80 & 443.
> 

Port is just a number, it can be anything *IF* it is made explicit.
The scheme determines what protocol syntax is being spoken and thus what 
restrictions and/or requirements are.

... and so the protocol for talking to a webcache service is 
http-alt://.
Whose default port is not 80 nor 443 for all the same reasons why Squid 
default listening port is 3128.

If we wanted to we could easily switch Squid default port to 
http-alt/8080 without causing technical issues. But it would be annoying 
to update all the existing documentation around the Internet, so not 
worth the effort changing now.


> 
>> It is based on experience. Squid used to be a lot more lenient and 
>> tried for decades to do the syntax auto-detection. The path from that 
>> to separate ports is littered with CVEs. Most notably the curse that 
>> keeps on giving: CVE-2009-0801, which is just the trigger issue for a 
>> whole nest of bad side effects.
> 
> I wonder how much of that problematic history was related to HTTP/0.9 
> vs HTTP/1.0 vs HTTP/1.1 clients.

Ditto. Though the legacy install base has a long long long tail. 26 
years after HTTP/1.0 came out and HTTP/0.9 still has use-cases alive.

> 
> I similarly wonder how much HTTP/1.0, or even HTTP/0.9, protocol is 
> used these days.

Decreasing, but still a potentially significant amount of traffic seen 
by Squid in general.

> 
> Also, there is the elephant in the room of we're talking about a proxy 
> server which is frequently, but not always, on a dedicated system or 
> IP.  As such, I have no problem predicating the use of the HTTP(80) and 
> HTTPS(443) ports when there is no possible chance of confusion between 
> forward proxy roles and origin server / reverse proxy roles.
> 

Ah, if you have been treating it like an irrelevant elephant that is 
your confusion. The "but not always" is a critical detail in the puzzle 
- its side-effects are the answer to your initial question of *why* 
Squid defaults to X instead of 80/443.

Amos


From gtaylor at tnetconsulting.net  Tue Nov  1 20:03:51 2022
From: gtaylor at tnetconsulting.net (Grant Taylor)
Date: Tue, 1 Nov 2022 14:03:51 -0600
Subject: [squid-users] FW: Encrypted browser-Squid connection errors
In-Reply-To: <a61972fddb4c5661ce60f4ddf47e7068@treenet.co.nz>
References: <DBAPR02MB6149665159D0E233B10A60CFF5249@DBAPR02MB6149.eurprd02.prod.outlook.com>
 <DBAPR02MB6149F7F567889AC742B77519F52B9@DBAPR02MB6149.eurprd02.prod.outlook.com>
 <c76e6f82-f587-c1ab-8f7e-2b22c7badcf6@measurement-factory.com>
 <1a598226-ffe8-f536-6fff-9f1ae7920544@spamtrap.tnetconsulting.net>
 <AM8PR04MB77454AD896CB65626FA54E878F2A9@AM8PR04MB7745.eurprd04.prod.outlook.com>
 <1f0c07d5-74a0-c3b2-ced1-f4334d6dc66a@spamtrap.tnetconsulting.net>
 <Y1FuER/x8qizD34c@fantomas.sk>
 <263997a6-37bd-c9e8-0651-64301048b5af@spamtrap.tnetconsulting.net>
 <17b1bac2-eaa5-775a-95e5-6cc6ffb2692a@suse.de>
 <0dc84627-5af0-78e1-9fe8-9a8329db92e1@spamtrap.tnetconsulting.net>
 <7b177298-2613-9215-2a99-b322e8b7c8e0@treenet.co.nz>
 <2f52e708-b1d8-ad6d-c9ea-62c3c5cf2965@spamtrap.tnetconsulting.net>
 <19fa29f8ddf517b0e38d73a7e6b0ca55@treenet.co.nz>
 <753b5a29-f2ac-1128-da8b-5c3b7ae7a043@spamtrap.tnetconsulting.net>
 <a61972fddb4c5661ce60f4ddf47e7068@treenet.co.nz>
Message-ID: <2b663816-b0ea-03b2-023a-91b3da9bb8d1@spamtrap.tnetconsulting.net>

On 11/1/22 1:24 PM, squid3 at treenet.co.nz wrote:
> No I meant W3C. Back in the before times things were a bit messy.

Hum.  I have more questions than answers.  I'm not aware of W3C ever 
assigning ports.  I thought it was /always/ IANA.

> Indeed, thus we cannot register it with IEFT/IANA now. The IANA http-alt 
> port would probably be best if we did go official.

ACK

> You see my point I hope. A gateway proxy that returns an error to 
> *every* request is not very good.

Except it's not "/ever/ /request/"  It's "/every/ /request/ /of/ /a/ 
/specific/ /type/" where type is an HTTP version.

What does CloudFlare or any of the other big proxy services or even 
other proxy applications do if you send them an HTTP/1.0 or even 
HTTP/0.9 request without the associated Host: header?

> There is no "configured proxy" for this use-case.
> 
> Those are the two most/extremely common instances of the problematic 
> use-cases. All implicit use of proxy (or gateway) have the same issue.

How common is the (network) transparent / intercepting / implicit use of 
Squid (or any proxy for that matter)?

All of the installs that I've worked on (both as a user and as an 
administrator) have been explicit / non-transparent.

> I think you are getting stuck with the subtle difference between "use 
> for case X" and "use by default".
> 
> ANY port number can be used for *some* use-case(s).

Sure.

> "by default" has to work for *all* use-cases.

I disagree.

> Note that you are now having to add a non-default port "8080" and path 
> "/" to the URL to make it valid/accepted by the Browser.

You were already specifying the non-default-http port via the 
"http-alt://" scheme in your example.

> Clients speaking HTTP origin-form (the http:// scheme) are not permitted 
> to request tunnels or equivalent gateway services. They can only ask for 
> resource representations.

I question the veracity of that.  Mostly around said client's use of an 
explicit proxy.

> Port is just a number, it can be anything *IF* it is made explicit.
> The scheme determines what protocol syntax is being spoken and thus what 
> restrictions and/or requirements are.
> 
> ... and so the protocol for talking to a webcache service is http-alt://.
> Whose default port is not 80 nor 443 for all the same reasons why Squid 
> default listening port is 3128.
> 
> If we wanted to we could easily switch Squid default port to 
> http-alt/8080 without causing technical issues. But it would be annoying 
> to update all the existing documentation around the Internet, so not 
> worth the effort changing now.
> 
> Ditto. Though the legacy install base has a long long long tail. 26 
> years after HTTP/1.0 came out and HTTP/0.9 still has use-cases alive.

Where is HTTP/0.9 still being used?

> Decreasing, but still a potentially significant amount of traffic seen 
> by Squid in general.

Can you, or anyone else, quantify what "a potentially significant amount 
of traffic" is?

Do these cases *really* /need/ to be covered by the /default/ 
configuration?  Or can they be addressed by a variation from the default 
configuration?

> Ah, if you have been treating it like an irrelevant elephant that is 
> your confusion. The "but not always" is a critical detail in the puzzle 
> - its side-effects are the answer to your initial question of *why* 
> Squid defaults to X instead of 80/443.

I have no problems using non-default for the "but not always" 
configurations.



-- 
Grant. . . .
unix || die

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4017 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221101/95fc3eb8/attachment.bin>

From squid3 at treenet.co.nz  Tue Nov  1 22:17:35 2022
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Wed, 02 Nov 2022 11:17:35 +1300
Subject: [squid-users] Does Squid support client ssl termination?
In-Reply-To: <c7774050-684e-73fa-69eb-646770ba66a7@spamtrap.tnetconsulting.net>
References: <CAB-cPApGGo1zHR1hVdVUGGLnLA1Ciy3hF1J+9L3a6O1Ap=0r-A@mail.gmail.com>
 <f1a6b704-38c0-321b-486c-1dfa01ed5c3c@spamtrap.tnetconsulting.net>
 <CAB-cPAqzHKh=iLTOVMYGMuV0BX9JKE6gKWUDpFRV=FcUnRTETw@mail.gmail.com>
 <d2f323de-03eb-e828-11ad-fc310fccaad9@spamtrap.tnetconsulting.net>
 <CAB-cPArjyq_LpNs+ak8vMk4HJh5X5ce5=MPNwHBWULz7SC1juw@mail.gmail.com>
 <fe883d44-d086-e63a-1ff7-ead23d31ba6c@spamtrap.tnetconsulting.net>
 <9b11f08b20f9f7f4f4f4fad345161523@treenet.co.nz>
 <c7774050-684e-73fa-69eb-646770ba66a7@spamtrap.tnetconsulting.net>
Message-ID: <4857700226b1763495385cfa23f2bc78@treenet.co.nz>

On 2022-11-02 07:49, Grant Taylor wrote:
> On 11/1/22 11:33 AM, squid3 wrote:
>> That is not true as a blanket statement.
> 
> Please clarify which statement / who you are addressing.
> 
> It seems as if you're addressing mingheng (copied below for 
> convenience):
> 

Yes I was addressing mingheng's statement.


> On 10/31/22 7:32 PM, mingheng wang wrote:
>> I delved into the configuration the last few days, and found that 
>> Squid doesn't officially support cache_peer when ssl_bump is in use.
> 
> But you may be addressing my statement (...):
> 
> On 11/1/22 10:44 AM, Grant Taylor wrote:
>> That surprises me.  I wonder if it's a technical limitation or an 
>> oversight.
> 
> 
> On 11/1/22 11:33 AM, squid3 at treenet.co.nz wrote:
>> What Squid officially *does not* support is decrypting traffic then 
>> sending the un-encrypted form to a HTTP-only cache_peer.
> 
> Please elaborate.  I'm trying to develop a mental model of what is and 
> is not supported with regard to client / proxy / server communications. 
> I'm unclear on how this applies to the two potential HTTPS streams; 
> client-to-proxy and proxy-to-server.

Okay, some info that may help with that mental model...

The first thing you need to do is avoid that "HTTPS" term. It has 
multiple meanings and they cause confusion. Instead decompose it into 
its TLS and HTTP layers.

* A client can use TCP or TLS to connect to a proxy.
  - this is configured with http_port vs https_port

* Independently of the connection type the client can request http:// or 
https:// URLs or CONNECT tunnels.

* Independent of what the client is doing/requesting, a cache_peer may 
be connected to using TCP or TLS.
  - this is configured with cache_peer tls options (or their absence)

* Independent of anything else, a cache_peer MAY be asked to open a 
CONNECT tunnel for opaque uses.
  - this is automatically decided by Squid based on various criteria.


TCP is the foundation layer. On top of that can be HTTP transfer or TLS 
transfer. Transfer layers can be nested infinitely deep in any order.

So "HTTPS" can mean any one of things like:
  1) HTTP-over-TLS (how Browsers handle https:// URLs)
  2) HTTP-over-TLS (sending http:// URLs over a secure connection)
  3) HTTP-over-TLS-over-TLS (relay (1) through a secure cache_peer)
  4) HTTP-over-TLS-over-HTTP (relay (1), (2) or (3) through an insecure 
cache_peer via CONNECT tunnel)

Each agent along the chain can add or remove any number of transfer 
layers to the protocol X-over-Y stack. Although for efficiency most 
prefer to minimize the layering depth.

A typical web request may flow across the Internet through a chain of 
proxies like this:

  client -(1)-> S1 =(4)=> S2 =(1)=> S3 -(2)-> O

  C = origin client
  S1 = forward-proxy
  S2 = insecure relay proxy
  S3 = TLS terminating reverse-proxy
  O = origin server


>  Or if this is more applicable to TLS-Bump on implicit / network 
> transparent / intercepting proxies where the client thinks that it's 
> talking HTTPS to the origin server and the proxy would really be 
> downgrading security by stripping TLS.
> 

It's *more* important with SSL-Bump 'bump' due to the interception 
nature of that operation. But also applies to other cases.

SSL-Bump implies interception of TLS
  * intercept may happen at network level (port 443 redirect or NAT)
  * intercept may be entirely within Squid (CONNECT tunnel unwrapped)

Decryption is independent of interception.
  a) SSL-Bump 'bump' action performs decrypt (the others do not)
  b) a TLS forward/explicit-proxy performs decrypt
  c) a TLS reverse-proxy performs decrypt

Traffic from (a) case requires re-encrypt before sending, even if its 
URL indicates insecure protocols.
Traffic from (b) MUST be re-encrypted when it is for a secure protocol 
eg https://, otherwise optional.
Traffic from (c) SHOULD be encrypted on sending, but always optional.

The "re-encrypt" may take the form of TLS to the secure peer, or a 
CONNECT tunnel through any peer with TLS to whatever is at the other end 
of the tunnel.


> Here is my mental model based on my current understanding.  Is the 
> following diagram accurate?
> 
>             +-------------+-----------+
>             |  P2S-HTTP   | P2S-HTTPS |
> +-----------+-------------+-----------+
> | C2P-HTTP  |  supported  | supported |
> +-----------+-------------+-----------+
> | C2P-HTTPS | unsupported | supported |
> +-----------+-------------+-----------+
>   C2P = Client to Proxy communication
>   P2S = Proxy to server communication
> 

Vaguely yes. There are three dimensions to the matrix, you only have two 
shown here.
The box showing "unsupported" has "supported" in its other dimension.


>> All other permutations of inbound TCP/TLS, http:// or https:// URL, 
>> and outbound TCP/TLS should currently work to some degree. The more 
>> recent your Squid version the better it is.
> 
> ACK
> 
> 


From squid3 at treenet.co.nz  Wed Nov  2 00:27:02 2022
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Wed, 02 Nov 2022 13:27:02 +1300
Subject: [squid-users] FW: Encrypted browser-Squid connection errors
In-Reply-To: <2b663816-b0ea-03b2-023a-91b3da9bb8d1@spamtrap.tnetconsulting.net>
References: <DBAPR02MB6149665159D0E233B10A60CFF5249@DBAPR02MB6149.eurprd02.prod.outlook.com>
 <DBAPR02MB6149F7F567889AC742B77519F52B9@DBAPR02MB6149.eurprd02.prod.outlook.com>
 <c76e6f82-f587-c1ab-8f7e-2b22c7badcf6@measurement-factory.com>
 <1a598226-ffe8-f536-6fff-9f1ae7920544@spamtrap.tnetconsulting.net>
 <AM8PR04MB77454AD896CB65626FA54E878F2A9@AM8PR04MB7745.eurprd04.prod.outlook.com>
 <1f0c07d5-74a0-c3b2-ced1-f4334d6dc66a@spamtrap.tnetconsulting.net>
 <Y1FuER/x8qizD34c@fantomas.sk>
 <263997a6-37bd-c9e8-0651-64301048b5af@spamtrap.tnetconsulting.net>
 <17b1bac2-eaa5-775a-95e5-6cc6ffb2692a@suse.de>
 <0dc84627-5af0-78e1-9fe8-9a8329db92e1@spamtrap.tnetconsulting.net>
 <7b177298-2613-9215-2a99-b322e8b7c8e0@treenet.co.nz>
 <2f52e708-b1d8-ad6d-c9ea-62c3c5cf2965@spamtrap.tnetconsulting.net>
 <19fa29f8ddf517b0e38d73a7e6b0ca55@treenet.co.nz>
 <753b5a29-f2ac-1128-da8b-5c3b7ae7a043@spamtrap.tnetconsulting.net>
 <a61972fddb4c5661ce60f4ddf47e7068@treenet.co.nz>
 <2b663816-b0ea-03b2-023a-91b3da9bb8d1@spamtrap.tnetconsulting.net>
Message-ID: <769fb3cf7a6adafebd98dac5f2981dac@treenet.co.nz>

On 2022-11-02 09:03, Grant Taylor wrote:
> On 11/1/22 1:24 PM, squid3 wrote:
>> No I meant W3C. Back in the before times things were a bit messy.
> 
> Hum.  I have more questions than answers.  I'm not aware of W3C ever 
> assigning ports.  I thought it was /always/ IANA.
> 
>> Indeed, thus we cannot register it with IEFT/IANA now. The IANA 
>> http-alt port would probably be best if we did go official.
> 
> ACK
> 
>> You see my point I hope. A gateway proxy that returns an error to 
>> *every* request is not very good.
> 
> Except it's not "/ever/ /request/"  It's "/every/ /request/ /of/ /a/ 
> /specific/ /type/" where type is an HTTP version.
> 

No, you cropped my use-case description. It specified a client which was 
*unaware* that it was talking to a forward-proxy. Such a client will 
send requests that only a reverse-proxy or origin server can handle 
properly - because they have explicit special configuration to do so.

In all proxying cases there is special configuration somewhere. For 
forward-proxy it is in the client (or its OS so-called "default"), for 
reverse-proxy it is in the proxy, for interception-proxy it is in both 
the network and the proxy.


> What does CloudFlare or any of the other big proxy services or even 
> other proxy applications do if you send them an HTTP/1.0 or even 
> HTTP/0.9 request without the associated Host: header?
> 

The working ones deliver an HTTP/1.1 302 redirect to their companies 
homepage if the request came from outside the company LAN. If the 
request came from an administrators machine it may respond with stats 
data about the node being probed.


>> There is no "configured proxy" for this use-case.
>> 
>> Those are the two most/extremely common instances of the problematic 
>> use-cases. All implicit use of proxy (or gateway) have the same issue.
> 
> How common is the (network) transparent / intercepting / implicit use 
> of Squid (or any proxy for that matter)?
> 
> All of the installs that I've worked on (both as a user and as an 
> administrator) have been explicit / non-transparent.
> 

Almost all the installs I have worked on had interception as part of 
their configuration. It is officially recommended to include 
interception as a backup to explicit forward-proxy for networks needing 
full traffic control and/or monitoring.

I take it from your statement you have not worked on networks like 
web-cafes, airports, schools, hospitals, public shopping malls who all 
use captive portal systems, or high-security institutions capturing 
traffic for personnel activity audits.

There are also at least a half dozen nation states with national 
firewalls doing traffic monitoring and censorship. At least 3 of the 
ones I know of use Squid's for the HTTP portion.


>> I think you are getting stuck with the subtle difference between "use 
>> for case X" and "use by default".
>> 
>> ANY port number can be used for *some* use-case(s).
> 
> Sure.
> 
>> "by default" has to work for *all* use-cases.
> 
> I disagree.
> 

ACK. That is you. I am coming at this from the maintainer viewpoint 
where the entire community's needs have to be balanced.


>> Note that you are now having to add a non-default port "8080" and path 
>> "/" to the URL to make it valid/accepted by the Browser.
> 
> You were already specifying the non-default-http port via the 
> "http-alt://" scheme in your example.
> 

And you were specifying the non-default-'http-alt' port via the 
"http://" scheme in yours.
Either way these are two different HTTP syntax with different "default 
port" values.


An agent supporting the http:// URL treats it as a request for some 
resource at the HTTP origin server indicated by the URL authority part 
or Host header.

An agent supporting the http-alt:// URL treats it as a request to 
forward-proxy the request-target specified in the URL query segment, 
using the upstream proxy indicated by the URL authority part or Host 
header.


>> Clients speaking HTTP origin-form (the http:// scheme) are not 
>> permitted to request tunnels or equivalent gateway services. They can 
>> only ask for resource representations.
> 
> I question the veracity of that.  Mostly around said client's use of an 
> explicit proxy.
> 

It is clear side-effect of the fact that tunnels cannot be opened by 
requesting an origin-form URL (eg "/index.html"). They require an 
authority-form URI (eg "example.com:80").

See https://www.rfc-editor.org/rfc/rfc9110.html#name-intermediaries for 
definitions of intermediary and role scopes.
Note that it explicitly says (requires) absolute-URI for "proxy" (aka 
forward-proxy) intermediaries. Clients do not speak origin-form to 
explicit proxies.

[yes I know the first paragraph says an intermediary may switch 
behaviour based on just the request, that is for HTTP/2+. Squid being 
1.1 is more restricted by the legacy issues].


>> Port is just a number, it can be anything *IF* it is made explicit.
>> The scheme determines what protocol syntax is being spoken and thus 
>> what restrictions and/or requirements are.
>> 
>> ... and so the protocol for talking to a webcache service is 
>> http-alt://.
>> Whose default port is not 80 nor 443 for all the same reasons why 
>> Squid default listening port is 3128.
>> 
>> If we wanted to we could easily switch Squid default port to 
>> http-alt/8080 without causing technical issues. But it would be 
>> annoying to update all the existing documentation around the Internet, 
>> so not worth the effort changing now.
>> 
>> Ditto. Though the legacy install base has a long long long tail. 26 
>> years after HTTP/1.0 came out and HTTP/0.9 still has use-cases alive.
> 
> Where is HTTP/0.9 still being used?

The ones I am aware of are:
  * HTTP software testing and development
  * IoT sensor polling
  * printer network bootstrapping
  * manufacturing controller management
  * network stability monitoring systems


> 
>> Decreasing, but still a potentially significant amount of traffic seen 
>> by Squid in general.
> 
> Can you, or anyone else, quantify what "a potentially significant 
> amount of traffic" is?
> 

I doubt anyone can quantify it accurately. But worldwide use of HTTP/1.1 
is also dropping, and at a faster rate than 0.9/1.0 right now as the 
more efficient HTTP/2+ expand.


> Do these cases *really* /need/ to be covered by the /default/ 
> configuration?  Or can they be addressed by a variation from the 
> default configuration?

HTTP/1.1 specification requires semantic compatibility. So long as 1.1 
is still a thing the older versions are likely to remain as well. 
Undesirable as that may be.

Cheers
Amos


From ifoolb at gmail.com  Wed Nov  2 00:58:25 2022
From: ifoolb at gmail.com (mingheng wang)
Date: Wed, 2 Nov 2022 08:58:25 +0800
Subject: [squid-users] Does Squid support client ssl termination?
In-Reply-To: <4857700226b1763495385cfa23f2bc78@treenet.co.nz>
References: <CAB-cPApGGo1zHR1hVdVUGGLnLA1Ciy3hF1J+9L3a6O1Ap=0r-A@mail.gmail.com>
 <f1a6b704-38c0-321b-486c-1dfa01ed5c3c@spamtrap.tnetconsulting.net>
 <CAB-cPAqzHKh=iLTOVMYGMuV0BX9JKE6gKWUDpFRV=FcUnRTETw@mail.gmail.com>
 <d2f323de-03eb-e828-11ad-fc310fccaad9@spamtrap.tnetconsulting.net>
 <CAB-cPArjyq_LpNs+ak8vMk4HJh5X5ce5=MPNwHBWULz7SC1juw@mail.gmail.com>
 <fe883d44-d086-e63a-1ff7-ead23d31ba6c@spamtrap.tnetconsulting.net>
 <9b11f08b20f9f7f4f4f4fad345161523@treenet.co.nz>
 <c7774050-684e-73fa-69eb-646770ba66a7@spamtrap.tnetconsulting.net>
 <4857700226b1763495385cfa23f2bc78@treenet.co.nz>
Message-ID: <CAB-cPAo2329EEm0cSsZp75M1qh1n4q7YC7BtoQGGuQXdCuSXqA@mail.gmail.com>

On Wed, Nov 2, 2022 at 6:17 AM <squid3 at treenet.co.nz> wrote:

> On 2022-11-02 07:49, Grant Taylor wrote:
> > On 11/1/22 11:33 AM, squid3 wrote:
> >> That is not true as a blanket statement.
> >
> > Please clarify which statement / who you are addressing.
> >
> > It seems as if you're addressing mingheng (copied below for
> > convenience):
> >
>
> Yes I was addressing mingheng's statement.
>
>
> > On 10/31/22 7:32 PM, mingheng wang wrote:
> >> I delved into the configuration the last few days, and found that
> >> Squid doesn't officially support cache_peer when ssl_bump is in use.
> >
> > But you may be addressing my statement (...):
> >
> > On 11/1/22 10:44 AM, Grant Taylor wrote:
> >> That surprises me.  I wonder if it's a technical limitation or an
> >> oversight.
> >
> >
> > On 11/1/22 11:33 AM, squid3 at treenet.co.nz wrote:
> >> What Squid officially *does not* support is decrypting traffic then
> >> sending the un-encrypted form to a HTTP-only cache_peer.
>
Oh sorry, I was meant to say that. I tested setting a sslstrip proxy as
cache_peer
when ssl_bump was in use, and it didn't work. I was too focused on my setup
and
forgot the case of regular proxies.


> >
> > Please elaborate.  I'm trying to develop a mental model of what is and
> > is not supported with regard to client / proxy / server communications.
> > I'm unclear on how this applies to the two potential HTTPS streams;
> > client-to-proxy and proxy-to-server.
>
> Okay, some info that may help with that mental model...
>
> The first thing you need to do is avoid that "HTTPS" term. It has
> multiple meanings and they cause confusion. Instead decompose it into
> its TLS and HTTP layers.
>
> * A client can use TCP or TLS to connect to a proxy.
>   - this is configured with http_port vs https_port
>
> * Independently of the connection type the client can request http:// or
> https:// URLs or CONNECT tunnels.
>
> * Independent of what the client is doing/requesting, a cache_peer may
> be connected to using TCP or TLS.
>   - this is configured with cache_peer tls options (or their absence)
>
> * Independent of anything else, a cache_peer MAY be asked to open a
> CONNECT tunnel for opaque uses.
>   - this is automatically decided by Squid based on various criteria.
>
>
> TCP is the foundation layer. On top of that can be HTTP transfer or TLS
> transfer. Transfer layers can be nested infinitely deep in any order.
>
> So "HTTPS" can mean any one of things like:
>   1) HTTP-over-TLS (how Browsers handle https:// URLs)
>   2) HTTP-over-TLS (sending http:// URLs over a secure connection)
>   3) HTTP-over-TLS-over-TLS (relay (1) through a secure cache_peer)
>   4) HTTP-over-TLS-over-HTTP (relay (1), (2) or (3) through an insecure
> cache_peer via CONNECT tunnel)
>
> Each agent along the chain can add or remove any number of transfer
> layers to the protocol X-over-Y stack. Although for efficiency most
> prefer to minimize the layering depth.
>
> A typical web request may flow across the Internet through a chain of
> proxies like this:
>
>   client -(1)-> S1 =(4)=> S2 =(1)=> S3 -(2)-> O
>
>   C = origin client
>   S1 = forward-proxy
>   S2 = insecure relay proxy
>   S3 = TLS terminating reverse-proxy
>   O = origin server
>
>
> >  Or if this is more applicable to TLS-Bump on implicit / network
> > transparent / intercepting proxies where the client thinks that it's
> > talking HTTPS to the origin server and the proxy would really be
> > downgrading security by stripping TLS.
> >
>
> It's *more* important with SSL-Bump 'bump' due to the interception
> nature of that operation. But also applies to other cases.
>
> SSL-Bump implies interception of TLS
>   * intercept may happen at network level (port 443 redirect or NAT)
>   * intercept may be entirely within Squid (CONNECT tunnel unwrapped)
>
> Decryption is independent of interception.
>   a) SSL-Bump 'bump' action performs decrypt (the others do not)
>   b) a TLS forward/explicit-proxy performs decrypt
>   c) a TLS reverse-proxy performs decrypt
>
> Traffic from (a) case requires re-encrypt before sending, even if its
> URL indicates insecure protocols.
>
  I don't understand. According to the wiki on Squid that I read, there are
several
steps involving "peek", "bump" or "slice" etc, we can already choose to
bump or
slice through SNI at step2. So why does HTTP have to be encrypted too?

  Anyway, essentially what I need is like splitting Squid into two parts:
the client
side part communicate with a client over a connection with dynamically
generated
certificates in order to fool the client when dealing with HSTS; while
forwarding traffic
unencrypted to the "other part" of Squid somewhere, which in turn
establishes a
new connection with the original server to do the bump thing and so on.

  Since Squid doesn't support this, I'll stop fiddling with it. I think
HTTP isn't a very
complicated protocol, and most HTTP libraries can handle TLS as well.
Perhaps it
won't be hard to write a simple proxy for personal use and Squid even has a
tool
called security_file_certgen, maybe I can make use of it.


> Traffic from (b) MUST be re-encrypted when it is for a secure protocol
> eg https://, otherwise optional.
> Traffic from (c) SHOULD be encrypted on sending, but always optional.
>
> The "re-encrypt" may take the form of TLS to the secure peer, or a
> CONNECT tunnel through any peer with TLS to whatever is at the other end
> of the tunnel.
>
>
> > Here is my mental model based on my current understanding.  Is the
> > following diagram accurate?
> >
> >             +-------------+-----------+
> >             |  P2S-HTTP   | P2S-HTTPS |
> > +-----------+-------------+-----------+
> > | C2P-HTTP  |  supported  | supported |
> > +-----------+-------------+-----------+
> > | C2P-HTTPS | unsupported | supported |
> > +-----------+-------------+-----------+
> >   C2P = Client to Proxy communication
> >   P2S = Proxy to server communication
> >
>
> Vaguely yes. There are three dimensions to the matrix, you only have two
> shown here.
> The box showing "unsupported" has "supported" in its other dimension.
>
>
> >> All other permutations of inbound TCP/TLS, http:// or https:// URL,
> >> and outbound TCP/TLS should currently work to some degree. The more
> >> recent your Squid version the better it is.
> >
> > ACK
> >
> >
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
Like a Fool,I'm very foolish.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221102/d2c4e2d9/attachment.htm>

From squid3 at treenet.co.nz  Wed Nov  2 01:48:26 2022
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Wed, 02 Nov 2022 14:48:26 +1300
Subject: [squid-users] Does Squid support client ssl termination?
In-Reply-To: <CAB-cPAo2329EEm0cSsZp75M1qh1n4q7YC7BtoQGGuQXdCuSXqA@mail.gmail.com>
References: <CAB-cPApGGo1zHR1hVdVUGGLnLA1Ciy3hF1J+9L3a6O1Ap=0r-A@mail.gmail.com>
 <f1a6b704-38c0-321b-486c-1dfa01ed5c3c@spamtrap.tnetconsulting.net>
 <CAB-cPAqzHKh=iLTOVMYGMuV0BX9JKE6gKWUDpFRV=FcUnRTETw@mail.gmail.com>
 <d2f323de-03eb-e828-11ad-fc310fccaad9@spamtrap.tnetconsulting.net>
 <CAB-cPArjyq_LpNs+ak8vMk4HJh5X5ce5=MPNwHBWULz7SC1juw@mail.gmail.com>
 <fe883d44-d086-e63a-1ff7-ead23d31ba6c@spamtrap.tnetconsulting.net>
 <9b11f08b20f9f7f4f4f4fad345161523@treenet.co.nz>
 <c7774050-684e-73fa-69eb-646770ba66a7@spamtrap.tnetconsulting.net>
 <4857700226b1763495385cfa23f2bc78@treenet.co.nz>
 <CAB-cPAo2329EEm0cSsZp75M1qh1n4q7YC7BtoQGGuQXdCuSXqA@mail.gmail.com>
Message-ID: <65680eae9b4c0393e71dabfb4da344ef@treenet.co.nz>

On 2022-11-02 13:58, mingheng wang wrote:
> On Wed, Nov 2, 2022 at 6:17 AM squid3 wrote:
>> 
>> SSL-Bump implies interception of TLS
>>   * intercept may happen at network level (port 443 redirect or NAT)
>>   * intercept may be entirely within Squid (CONNECT tunnel unwrapped)
>> 
>> Decryption is independent of interception.
>>   a) SSL-Bump 'bump' action performs decrypt (the others do not)
>>   b) a TLS forward/explicit-proxy performs decrypt
>>   c) a TLS reverse-proxy performs decrypt
>> 
>> Traffic from (a) case requires re-encrypt before sending, even if its
>> URL indicates insecure protocols.
>> 
>   I don't understand. According to the wiki on Squid that I read, there 
> are
> several
> steps involving "peek", "bump" or "slice" etc, we can already choose to
> bump or
> slice through SNI at step2. So why does HTTP have to be encrypted too?

Those "steps" are points along the TLS handshake sequence, the actions 
are things Squid can be asked to do at each step.
The peek/splice/stare/terminate actions do not decrypt, so do not 
matter.

The 'bump' action uses details from origin TLS server certificate and 
maybe initiates a TLS session between client and server. That means a) 
there needs be a TLS server to fetch those details from, and b) the 
decrypted traffic can only be sent to that TLS server. Thus delivery of 
traffic to the server requires re-encryption with the security keys 
'bump' negotiated with the server already (so your split-in-half idea 
breaks).


These limits are all specific to SSL-Bump decrypted traffic. Different 
details/restrictions apply to Squid operating as TLS reverse-proxy or 
TLS explicit forward-proxy. I assume that you have already considered 
those setups before settling on SSL-Bump intercepting TLS.


HTH
Amos


From gtaylor at tnetconsulting.net  Wed Nov  2 02:35:49 2022
From: gtaylor at tnetconsulting.net (Grant Taylor)
Date: Tue, 1 Nov 2022 20:35:49 -0600
Subject: [squid-users] FW: Encrypted browser-Squid connection errors
In-Reply-To: <769fb3cf7a6adafebd98dac5f2981dac@treenet.co.nz>
References: <DBAPR02MB6149665159D0E233B10A60CFF5249@DBAPR02MB6149.eurprd02.prod.outlook.com>
 <c76e6f82-f587-c1ab-8f7e-2b22c7badcf6@measurement-factory.com>
 <1a598226-ffe8-f536-6fff-9f1ae7920544@spamtrap.tnetconsulting.net>
 <AM8PR04MB77454AD896CB65626FA54E878F2A9@AM8PR04MB7745.eurprd04.prod.outlook.com>
 <1f0c07d5-74a0-c3b2-ced1-f4334d6dc66a@spamtrap.tnetconsulting.net>
 <Y1FuER/x8qizD34c@fantomas.sk>
 <263997a6-37bd-c9e8-0651-64301048b5af@spamtrap.tnetconsulting.net>
 <17b1bac2-eaa5-775a-95e5-6cc6ffb2692a@suse.de>
 <0dc84627-5af0-78e1-9fe8-9a8329db92e1@spamtrap.tnetconsulting.net>
 <7b177298-2613-9215-2a99-b322e8b7c8e0@treenet.co.nz>
 <2f52e708-b1d8-ad6d-c9ea-62c3c5cf2965@spamtrap.tnetconsulting.net>
 <19fa29f8ddf517b0e38d73a7e6b0ca55@treenet.co.nz>
 <753b5a29-f2ac-1128-da8b-5c3b7ae7a043@spamtrap.tnetconsulting.net>
 <a61972fddb4c5661ce60f4ddf47e7068@treenet.co.nz>
 <2b663816-b0ea-03b2-023a-91b3da9bb8d1@spamtrap.tnetconsulting.net>
 <769fb3cf7a6adafebd98dac5f2981dac@treenet.co.nz>
Message-ID: <6c3a1684-7c95-48ce-8196-ecf95d793a1f@spamtrap.tnetconsulting.net>

On 11/1/22 6:27 PM, squid3 at treenet.co.nz wrote:
> No, you cropped my use-case description. It specified a client which was 
> *unaware* that it was talking to a forward-proxy.

Sorry, that was unintentional.

> Such a client will send requests that only a reverse-proxy or origin 
> server can handle properly - because they have explicit special 
> configuration to do so.

ACK

> In all proxying cases there is special configuration somewhere. For 
> forward-proxy it is in the client (or its OS so-called "default"), for 
> reverse-proxy it is in the proxy, for interception-proxy it is in both 
> the network and the proxy.

ACK

> The working ones deliver an HTTP/1.1 302 redirect to their companies 
> homepage if the request came from outside the company LAN. If the 
> request came from an administrators machine it may respond with stats 
> data about the node being probed.

I suspect that Squid et al. could do similar.  ;-)

> Almost all the installs I have worked on had interception as part of 
> their configuration.

Fair enough.

> It is officially recommended to include interception as a backup 
> to explicit forward-proxy for networks needing full traffic control 
> and/or monitoring.

I've taken things one step further.  I forego the interception and 
simply have the firewall / router hard block traffic not from the proxy 
server.  }:-)

But short of that, I see and acknowledge the value of interception.

> I take it from your statement you have not worked on networks like 
> web-cafes, airports, schools, hospitals, public shopping malls who all 
> use captive portal systems, or high-security institutions capturing 
> traffic for personnel activity audits.

I have worked in schools, and other public places, some of which had a 
captive portal that intercepted to a web server to process registration 
or flat blocked non-proxied traffic.  The proxy server in those cases 
was explicit.

> There are also at least a half dozen nation states with national 
> firewalls doing traffic monitoring and censorship. At least 3 of the 
> ones I know of use Squid's for the HTTP portion.

I'm aware of a small number of such nation states.  I assume that there 
are many more.  I was not aware that Squid played in that arena.

> ACK. That is you. I am coming at this from the maintainer viewpoint 
> where the entire community's needs have to be balanced.

I maintain that the /default/ does not have to work for /all/ use cases.

I agree that the /default/ should work for /most/ use cases.

The current default doesn't work on servers using NLD Active API Server. 
  Ergo the current default doesn't work on /all/ use cases.  }:-)

> And you were specifying the non-default-'http-alt' port via the 
> "http://" scheme in yours.
> Either way these are two different HTTP syntax with different "default 
> port" values.
> 
> 
> An agent supporting the http:// URL treats it as a request for some 
> resource at the HTTP origin server indicated by the URL authority part 
> or Host header.
> 
> An agent supporting the http-alt:// URL treats it as a request to 
> forward-proxy the request-target specified in the URL query segment, 
> using the upstream proxy indicated by the URL authority part or Host 
> header.

If I'm understanding correctly, this is a case of someone asking Bob to 
connect to Bob.  That's not a thing.  Just talk directly to Bob.

> The ones I am aware of are:
>  ?* HTTP software testing and development
>  ?* IoT sensor polling
>  ?* printer network bootstrapping
>  ?* manufacturing controller management
>  ?* network stability monitoring systems

Why is anything developed in the last two decades green fielding with 
HTTP/0.9?!?!?!

> I doubt anyone can quantify it accurately. But worldwide use of HTTP/1.1 
> is also dropping, and at a faster rate than 0.9/1.0 right now as the 
> more efficient HTTP/2+ expand.

Sure.  There should be three categories of migrations:

HTTP/0.9 to something
HTTP/1.0 to something
HTTP/1.1 to HTTP/2

I sincerely hope that the somethings are going to HTTP/1.1 or HTTP/2.

> HTTP/1.1 specification requires semantic compatibility. So long as 1.1 
> is still a thing the older versions are likely to remain as well. 
> Undesirable as that may be.

ACK



-- 
Grant. . . .
unix || die

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4017 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221101/e1f47e47/attachment.bin>

From squid3 at treenet.co.nz  Wed Nov  2 04:43:55 2022
From: squid3 at treenet.co.nz (squid3 at treenet.co.nz)
Date: Wed, 02 Nov 2022 17:43:55 +1300
Subject: [squid-users] FW: Encrypted browser-Squid connection errors
In-Reply-To: <6c3a1684-7c95-48ce-8196-ecf95d793a1f@spamtrap.tnetconsulting.net>
References: <DBAPR02MB6149665159D0E233B10A60CFF5249@DBAPR02MB6149.eurprd02.prod.outlook.com>
 <c76e6f82-f587-c1ab-8f7e-2b22c7badcf6@measurement-factory.com>
 <1a598226-ffe8-f536-6fff-9f1ae7920544@spamtrap.tnetconsulting.net>
 <AM8PR04MB77454AD896CB65626FA54E878F2A9@AM8PR04MB7745.eurprd04.prod.outlook.com>
 <1f0c07d5-74a0-c3b2-ced1-f4334d6dc66a@spamtrap.tnetconsulting.net>
 <Y1FuER/x8qizD34c@fantomas.sk>
 <263997a6-37bd-c9e8-0651-64301048b5af@spamtrap.tnetconsulting.net>
 <17b1bac2-eaa5-775a-95e5-6cc6ffb2692a@suse.de>
 <0dc84627-5af0-78e1-9fe8-9a8329db92e1@spamtrap.tnetconsulting.net>
 <7b177298-2613-9215-2a99-b322e8b7c8e0@treenet.co.nz>
 <2f52e708-b1d8-ad6d-c9ea-62c3c5cf2965@spamtrap.tnetconsulting.net>
 <19fa29f8ddf517b0e38d73a7e6b0ca55@treenet.co.nz>
 <753b5a29-f2ac-1128-da8b-5c3b7ae7a043@spamtrap.tnetconsulting.net>
 <a61972fddb4c5661ce60f4ddf47e7068@treenet.co.nz>
 <2b663816-b0ea-03b2-023a-91b3da9bb8d1@spamtrap.tnetconsulting.net>
 <769fb3cf7a6adafebd98dac5f2981dac@treenet.co.nz>
 <6c3a1684-7c95-48ce-8196-ecf95d793a1f@spamtrap.tnetconsulting.net>
Message-ID: <0db9747b785fe06efc164543d11526b0@treenet.co.nz>

On 2022-11-02 15:35, Grant Taylor wrote:
> On 11/1/22 6:27 PM, squid3 wrote:
>> The working ones deliver an HTTP/1.1 302 redirect to their companies 
>> homepage if the request came from outside the company LAN. If the 
>> request came from an administrators machine it may respond with stats 
>> data about the node being probed.
> 
> I suspect that Squid et al. could do similar.  ;-)
> 

Yes, they can be configured to do so if you need it.

Neither outcome avoids the problem that the client was trying to 
interact with a resource entirely different on another server whose info 
has been lost implicitly by the protocol syntax.

> 
>> I take it from your statement you have not worked on networks like 
>> web-cafes, airports, schools, hospitals, public shopping malls who all 
>> use captive portal systems, or high-security institutions capturing 
>> traffic for personnel activity audits.
> 
> I have worked in schools, and other public places, some of which had a 
> captive portal that intercepted to a web server to process registration 
> or flat blocked non-proxied traffic.  The proxy server in those cases 
> was explicit.
> 

They missed a trick then. If the registration process is simple, it can 
be done by Squid with a session helper and two listening ports. We even 
ship some ERR_AGENT_* templates for captive portals use.


> 
> The current default doesn't work on servers using NLD Active API 
> Server.


Reference? Google is not providing me with anything HTTP capable by that 
name or the obvious sub-sets.


>> And you were specifying the non-default-'http-alt' port via the 
>> "http://" scheme in yours.
>> Either way these are two different HTTP syntax with different "default 
>> port" values.
>> 
>> 
>> An agent supporting the http:// URL treats it as a request for some 
>> resource at the HTTP origin server indicated by the URL authority part 
>> or Host header.
>> 
>> An agent supporting the http-alt:// URL treats it as a request to 
>> forward-proxy the request-target specified in the URL query segment, 
>> using the upstream proxy indicated by the URL authority part or Host 
>> header.
> 
> If I'm understanding correctly, this is a case of someone asking Bob to 
> connect to Bob.  That's not a thing.  Just talk directly to Bob.

   http-alt://bob?http://alice/some/resource
Is instructing a client to ask proxy (Bob) to fetch /some/resource from 
origin (Alice). All the client "explicit configuration" is in the URL, 
rather than client config files or environment variables.

> 
>> The ones I am aware of are:
>>  ?* HTTP software testing and development
>>  ?* IoT sensor polling
>>  ?* printer network bootstrapping
>>  ?* manufacturing controller management
>>  ?* network stability monitoring systems
> 
> Why is anything developed in the last two decades green fielding with 
> HTTP/0.9?!?!?!
> 

The IoT stuff at least. The others are getting old, but more like 10+ 
years rather than 20+.


Cheers
Amos


From david at articatech.com  Wed Nov  2 10:03:54 2022
From: david at articatech.com (David Touzeau)
Date: Wed, 2 Nov 2022 11:03:54 +0100
Subject: [squid-users] ACL based DNS server list
In-Reply-To: <19aec77d-0dab-0e28-e536-d040b02311e7@spamtrap.tnetconsulting.net>
References: <CAGzU65pSapT51jQb4zbEu3aB7ecqpZ80GhTO0fzy1Zj0+JOiFw@mail.gmail.com>
 <19aec77d-0dab-0e28-e536-d040b02311e7@spamtrap.tnetconsulting.net>
Message-ID: <ab926575-7c72-e58f-2cf3-54b3262da080@articatech.com>

It should be a good feature request that the Squid DNS client supports eDNS
eDNS can be used to send the source client IP address received by Squid 
to a remote DNS.
In this case the DNS will be able to change its behavior depending on 
the source IP address.

Amos, Alex ?

Le 30/10/2022 ? 18:00, Grant Taylor a ?crit?:
> On 10/25/22 7:27 PM, Sneaker Space LTD wrote:
>> Hello,
>
> Hi,
>
>> Is there a way to use specific?DNS servers based on the user or 
>> connecting IP address that is making the connection by using?acls or 
>> any other method? If so, can someone send an example.
>
> "Any other method" covers a LOT of things.? Including things outside 
> of Squid's domain.
>
> You could probably do some things with networking such that different 
> clients connected to different instances of Squid each configured to 
> use different DNS servers.? --? This is a huge hole in the ground and 
> can cover a LOT of things.? All of which are outside of Squid's domain.
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
David Touzeau - Artica Tech France
Development team, level 3 support
----------------------------------
P: +33 6 58 44 69 46
www:https://wiki.articatech.com
www:http://articatech.net  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221102/fcad7410/attachment.htm>

From Antony.Stone at squid.open.source.it  Wed Nov  2 10:07:07 2022
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 2 Nov 2022 11:07:07 +0100
Subject: [squid-users] ACL based DNS server list
In-Reply-To: <CAGzU65pSapT51jQb4zbEu3aB7ecqpZ80GhTO0fzy1Zj0+JOiFw@mail.gmail.com>
References: <CAGzU65pSapT51jQb4zbEu3aB7ecqpZ80GhTO0fzy1Zj0+JOiFw@mail.gmail.com>
Message-ID: <202211021107.07434.Antony.Stone@squid.open.source.it>

On Wednesday 26 October 2022 at 03:27:01, Sneaker Space LTD wrote:

> Hello,
> 
> Is there a way to use specific DNS servers based on the user or connecting
> IP address that is making the connection by using acls or any other method?
> If so, can someone send an example.

What problem are you trying to solve by asking if this is possible?

Antony.

-- 
The truth is rarely pure, and never simple.

 - Oscar Wilde

                                                   Please reply to the list;
                                                         please *don't* CC me.


From gtaylor at tnetconsulting.net  Wed Nov  2 14:52:21 2022
From: gtaylor at tnetconsulting.net (Grant Taylor)
Date: Wed, 2 Nov 2022 08:52:21 -0600
Subject: [squid-users] ACL based DNS server list
In-Reply-To: <ab926575-7c72-e58f-2cf3-54b3262da080@articatech.com>
References: <CAGzU65pSapT51jQb4zbEu3aB7ecqpZ80GhTO0fzy1Zj0+JOiFw@mail.gmail.com>
 <19aec77d-0dab-0e28-e536-d040b02311e7@spamtrap.tnetconsulting.net>
 <ab926575-7c72-e58f-2cf3-54b3262da080@articatech.com>
Message-ID: <6e62ef3c-d842-054a-82a5-78e7236cfdd2@spamtrap.tnetconsulting.net>

On 11/2/22 4:03 AM, David Touzeau wrote:
> It should be a good feature request that the Squid DNS client supports eDNS
> eDNS can be used to send the source client IP address received by Squid 
> to a remote DNS.

Does Squid even have it's own DNS "" / lookup mechanism?

I naively assumed that Squid simply used the system's name resolution 
capabilities, be that DNS, /etc/hosts, or even NIS(+).

As such, I would be shocked if there is any plumbing to pass additional 
information; e.g. down stream proxy client, to influence how the name 
resolution happens.

Maybe I'm wrong.  Hopefully I'll learn something from how others respond.

> In this case the DNS will be able to change its behavior depending on 
> the source IP address.

I take that to mean that DNS will change it's behavior based on the 
EDNS0 Client Subnet information.  Because DNS will still see Squid as 
the client of the DNS query.

Aside:  There's a chance that the -- as I understand it -- suggested /24 
aggregation of E.C.S. will not be granular enough to provide the OP's 
desired result.

N.B. the E.C.S. interactions that I've had have used /24 or larger 
subnets to protect client identity.



-- 
Grant. . . .
unix || die

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4017 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221102/f16414ec/attachment.bin>

From gtaylor at tnetconsulting.net  Wed Nov  2 15:13:52 2022
From: gtaylor at tnetconsulting.net (Grant Taylor)
Date: Wed, 2 Nov 2022 09:13:52 -0600
Subject: [squid-users] Does Squid support client ssl termination?
In-Reply-To: <4857700226b1763495385cfa23f2bc78@treenet.co.nz>
References: <CAB-cPApGGo1zHR1hVdVUGGLnLA1Ciy3hF1J+9L3a6O1Ap=0r-A@mail.gmail.com>
 <f1a6b704-38c0-321b-486c-1dfa01ed5c3c@spamtrap.tnetconsulting.net>
 <CAB-cPAqzHKh=iLTOVMYGMuV0BX9JKE6gKWUDpFRV=FcUnRTETw@mail.gmail.com>
 <d2f323de-03eb-e828-11ad-fc310fccaad9@spamtrap.tnetconsulting.net>
 <CAB-cPArjyq_LpNs+ak8vMk4HJh5X5ce5=MPNwHBWULz7SC1juw@mail.gmail.com>
 <fe883d44-d086-e63a-1ff7-ead23d31ba6c@spamtrap.tnetconsulting.net>
 <9b11f08b20f9f7f4f4f4fad345161523@treenet.co.nz>
 <c7774050-684e-73fa-69eb-646770ba66a7@spamtrap.tnetconsulting.net>
 <4857700226b1763495385cfa23f2bc78@treenet.co.nz>
Message-ID: <a580846c-5341-a3a9-9e71-e83d0181ca35@spamtrap.tnetconsulting.net>

On 11/1/22 4:17 PM, squid3 at treenet.co.nz wrote:
> Yes I was addressing mingheng's statement.

Thank you for clarifying.

> The first thing you need to do is avoid that "HTTPS" term. It has 
> multiple meanings and they cause confusion. Instead decompose it into 
> its TLS and HTTP layers.

Largely okay.

However, a minor nitpick:  TCP, TLS, and HTTP are three distinct things.

TCP is the traditional transport.
TLS is the optional presentation layer that rides on top of TCP.
HTTP is the application layer protocol that's spoken between endpoints 
which rides on top of TLS if present or TCP if TLS is not present.

N.B. I'm eliding UDP / QUIC.

> * A client can use TCP or TLS to connect to a proxy.
>  ?- this is configured with http_port vs https_port
> 
> * Independently of the connection type the client can request http:// or 
> https:// URLs or CONNECT tunnels.

Do you have any recommendation of clarifying / consistent terms for 
using to describe the connection between the client and the proxy with 
the goal of differentiating it from the connection between the proxy and 
the server?

I'll argue, but be open to arguments to the contrary, that both 
connections are using the HTTP application layer protocol on top of 
whatever transport is being used; TCP or TCP+TLS.

> * Independent of what the client is doing/requesting, a cache_peer may 
> be connected to using TCP or TLS.
>  ?- this is configured with cache_peer tls options (or their absence)
> 
> * Independent of anything else, a cache_peer MAY be asked to open a 
> CONNECT tunnel for opaque uses.
>  ?- this is automatically decided by Squid based on various criteria.

Oy vey!

I had forgotten about using HTTP's CONNECT to carry non-HTTP traffic.

> TCP is the foundation layer. On top of that can be HTTP transfer or TLS 
> transfer. Transfer layers can be nested infinitely deep in any order.

I'm avoiding -- what I've seen referenced as -- "chaining" for this 
discussion.

I'm focusing on the what traditional web browsers / clients support out 
of the box; client-to-proxy and proxy-to-server.

After all, even when chaining is in scope, the chained / down stream 
proxy is really functioning as the server that the first / upstream 
proxy connects to.  Thus it's really higher layer traffic as far as the 
first / upstream proxy is concerned.

> So "HTTPS" can mean any one of things like:
>  ?1) HTTP-over-TLS (how Browsers handle https:// URLs)
>  ?2) HTTP-over-TLS (sending http:// URLs over a secure connection)
>  ?3) HTTP-over-TLS-over-TLS (relay (1) through a secure cache_peer)
>  ?4) HTTP-over-TLS-over-HTTP (relay (1), (2) or (3) through an insecure 
> cache_peer via CONNECT tunnel)

Hence my question about nomenclature.

...really big snip...

> Vaguely yes. There are three dimensions to the matrix, you only have two 
> shown here.

Please elaborate.  I'm not following what the 3rd dimension would be 
with the small amount of coffee that I've had.

> The box showing "unsupported" has "supported" in its other dimension.

I'll wait for your elaboration and to finish my coffee before trying to 
understand that.  Also, $WORK beckons.



-- 
Grant. . . .
unix || die

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4017 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221102/bb47b21a/attachment.bin>

From uhlar at fantomas.sk  Wed Nov  2 19:33:07 2022
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 2 Nov 2022 20:33:07 +0100
Subject: [squid-users] ACL based DNS server list
In-Reply-To: <6e62ef3c-d842-054a-82a5-78e7236cfdd2@spamtrap.tnetconsulting.net>
References: <CAGzU65pSapT51jQb4zbEu3aB7ecqpZ80GhTO0fzy1Zj0+JOiFw@mail.gmail.com>
 <19aec77d-0dab-0e28-e536-d040b02311e7@spamtrap.tnetconsulting.net>
 <ab926575-7c72-e58f-2cf3-54b3262da080@articatech.com>
 <6e62ef3c-d842-054a-82a5-78e7236cfdd2@spamtrap.tnetconsulting.net>
Message-ID: <Y2LF8wAfuG5D+qcE@fantomas.sk>

>On 11/2/22 4:03 AM, David Touzeau wrote:
>>It should be a good feature request that the Squid DNS client supports eDNS
>>eDNS can be used to send the source client IP address received by 
>>Squid to a remote DNS.

On 02.11.22 08:52, Grant Taylor wrote:
>Does Squid even have it's own DNS "" / lookup mechanism?

yes.

>I naively assumed that Squid simply used the system's name resolution 
>capabilities, be that DNS, /etc/hosts, or even NIS(+).

afaik these functions don't work asynchronously which would be problem for 
squid.

up to 3.4 squid supported external DNS children. 


>>In this case the DNS will be able to change its behavior depending 
>>on the source IP address.
>
>I take that to mean that DNS will change it's behavior based on the 
>EDNS0 Client Subnet information.  Because DNS will still see Squid as 
>the client of the DNS query.

Since it's always squid who accesses destination servers, providing client 
subnet option by squid is useless here and only squid's IP matters.


>Aside:  There's a chance that the -- as I understand it -- suggested 
>/24 aggregation of E.C.S. will not be granular enough to provide the 
>OP's desired result.
>
>N.B. the E.C.S. interactions that I've had have used /24 or larger 
>subnets to protect client identity.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Save the whales. Collect the whole set.


From m_zouhairy at ckta.by  Thu Nov  3 09:43:22 2022
From: m_zouhairy at ckta.by (Majed Zouhairy)
Date: Thu, 3 Nov 2022 12:43:22 +0300
Subject: [squid-users] site opens only without ssl bump
Message-ID: <0aa508d5-033c-6f41-d751-ec9eee090dc3@ckta.by>

Peace,
i have 2 proxies, one with ssl bump and one without, there is a internal 
site that opens only on the no ssl bump proxy.

on the ssl bump proxy it displays:


?? ??????? ???????? ?????? ? ????????-???????? ?? ?????? (i was unable 
to gain access to website:) 
https://test-auth.ias.ckko.nl/oauth/authorize?response_type=code&client_id=agoh1xHNNwaLZ65uspARyhYj7V8GTWla&state=guest&authentication=usbtoken&redirect_uri=https%3A%2F%2Fais.skko.by%2Foauth2%2Fcallback, 
????????, ???????? ?????????? ??? ????????? ?????????? ?? ?????? ??????. 
(it is possible that it can not bbe reached or it has been permanently 
relocated to a new address)
ERR_TUNNEL_CONNECTION_FAILED

the site needs special configurations to run:
it needs a local proxy to run, avtunproxy.nl
in the internet explorer settings:
the second box in the proxy settings needs to be checked called the "use 
the scenario for automatic configuration"
in it, the proxy address is plugged
http://127.0.0.1:10224/proxy.pac

my bump settings are as follows:


acl 	tls_s1_connect		at_step SslBump1
acl 	tls_s2_client_hello 	at_step SslBump2
acl 	tls_s3_server_hello 	at_step SslBump3

# define acls for sites that must not be actively bumped

acl 	tls_allowed_hsts		ssl::server_name 			.akamaihd.net
acl 	tls_allowed_hsts		ssl::server_name 			.proxy.ckko.nl
acl 	tls_server_is_bank 		ssl::server_name		 
"/usr/local/ufdbguard/blacklists/finance/domains.squidsplice"
acl 	tls_to_splice 	any-of 	tls_allowed_hsts tls_server_is_bank

# TLS/SSL bumping steps

ssl_bump 		peek				tls_s1_connect 		# peek at TLS/SSL connect data
ssl_bump 		splice 				tls_to_splice		# splice some: no active bump
ssl_bump 		stare 				all					# stare(peek) at server
														# properties of the webserver
ssl_bump 		bump

contents of the 
/usr/local/ufdbguard/blacklists/finance/domains.squidsplice file:

.ckko.nl
.ias.ckko.nl
.test-auth.ias.ckko.nl
.config.avtunproxy.nl
.rand.avtunproxy.nl
.avast.nl
.dev.avast.nl
.ncis.nl
.cdn.nlpost.nl

those are all the sites that are logged in on the non ssl bump proxy 
when ias.ckko.nl is accessed

despite all this configuration, the site does not open. in ufdbguard 
every site from the user is a pass.

in avtunproxy log :

2022/11/03 12:22:17.087001 |INF| [UPDATER] [TrustFirmware] fetching 
https://ckko.nl/upload/certificates/8.crl
2022/11/03 12:28:34.634001 |ERR| [rid=ab7a9b1c9f39fb3e] 
[addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
2022/11/03 12:28:34.635001 |INF| [rid=ab7a9b1c9f39fb3e] 
[addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
2022/11/03 12:28:34.663001 |ERR| [rid=47fba344ff078bcf] 
[addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - read 
tcp 192.168.2.5:10527->10.0.0.18:8080: wsarecv: An existing connection 
was forcibly closed by the remote host.
2022/11/03 12:28:34.664001 |INF| [rid=47fba344ff078bcf] 
[addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
test-oauth.ais.ckko.nl:443 -- 500 -- 17.000000 ms
2022/11/03 12:28:35.723001 |ERR| [rid=3f5ccf39ef0ae021] 
[addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
2022/11/03 12:28:35.723001 |INF| [rid=3f5ccf39ef0ae021] 
[addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
2022/11/03 12:28:35.748001 |ERR| [rid=c48d84308d001f59] 
[addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
2022/11/03 12:28:35.748001 |INF| [rid=c48d84308d001f59] 
[addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
test-oauth.ais.ckko.nl:443 -- 500 -- 12.000000 ms
2022/11/03 12:28:35.752001 |ERR| [rid=d181037283b2a34a] 
[addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
2022/11/03 12:28:35.752001 |INF| [rid=d181037283b2a34a] 
[addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
test-oauth.ais.ckko.nl:443 -- 500 -- 15.000000 ms
2022/11/03 12:28:40.775001 |ERR| [rid=27f00eecdbe53178] 
[addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - read 
tcp 192.168.2.5:10538->10.0.0.18:8080: wsarecv: An existing connection 
was forcibly closed by the remote host.
2022/11/03 12:28:40.775001 |INF| [rid=27f00eecdbe53178] 
[addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
2022/11/03 12:28:40.815001 |ERR| [rid=79611bea389d7c9c] 
[addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
2022/11/03 12:28:40.816001 |INF| [rid=79611bea389d7c9c] 
[addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
2022/11/03 12:28:42.188001 |INF| [rid=7a104242baf9a559] 
[addr=127.0.0.1:10541] GET /static/jquery.js - HTTP 200 - OK
2022/11/03 12:28:42.190001 |INF| [rid=27a7baff0fe5d70e] 
[addr=127.0.0.1:10542] GET /static/bootstrap.js - HTTP 200 - OK
2022/11/03 12:28:42.192001 |INF| [rid=dbddaaa3f7759903] 
[addr=127.0.0.1:10459] GET /static/bootstrap.css - HTTP 200 - OK
2022/11/03 12:28:42.287001 |INF| [rid=7e81e98ea9c70d3f] 
[addr=127.0.0.1:10544] GET /api/v2/log


what is the solution?


From rousskov at measurement-factory.com  Thu Nov  3 13:05:24 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 3 Nov 2022 09:05:24 -0400
Subject: [squid-users] site opens only without ssl bump
In-Reply-To: <0aa508d5-033c-6f41-d751-ec9eee090dc3@ckta.by>
References: <0aa508d5-033c-6f41-d751-ec9eee090dc3@ckta.by>
Message-ID: <70311335-8ece-ca90-caea-b78ffeecc69e@measurement-factory.com>

On 11/3/22 05:43, Majed Zouhairy wrote:

> i have 2 proxies, one with ssl bump and one without, there is a internal 
> site that opens only on the no ssl bump proxy.
> 
> on the ssl bump proxy it displays:


What does Squid say in access.log for this problematic request? Please 
configure Squid to log %err_code/%err_detail before answering this 
question. For example:

logformat xsquid ...your regular %codes... %err_code/%err_detail
access_log ... xsquid



Does the site works if you temporary replace your ssl_bump rules with:

ssl_bump peek all
ssl_bump splice all


Does the site works if you temporary replace your ssl_bump rules with:

ssl_bump peek tls_s1_connect
ssl_bump splice all


Alex.




> ?? ??????? ???????? ?????? ? ????????-???????? ?? ?????? (i was unable 
> to gain access to website:) 
> https://test-auth.ias.ckko.nl/oauth/authorize?response_type=code&client_id=agoh1xHNNwaLZ65uspARyhYj7V8GTWla&state=guest&authentication=usbtoken&redirect_uri=https%3A%2F%2Fais.skko.by%2Foauth2%2Fcallback, 
> ????????, ???????? ?????????? ??? ????????? ?????????? ?? ?????? ??????. 
> (it is possible that it can not bbe reached or it has been permanently 
> relocated to a new address)
> ERR_TUNNEL_CONNECTION_FAILED
> 
> the site needs special configurations to run:
> it needs a local proxy to run, avtunproxy.nl
> in the internet explorer settings:
> the second box in the proxy settings needs to be checked called the "use 
> the scenario for automatic configuration"
> in it, the proxy address is plugged
> http://127.0.0.1:10224/proxy.pac
> 
> my bump settings are as follows:
> 
> 
> acl???? tls_s1_connect??????? at_step SslBump1
> acl???? tls_s2_client_hello???? at_step SslBump2
> acl???? tls_s3_server_hello???? at_step SslBump3
> 
> # define acls for sites that must not be actively bumped
> 
> acl???? tls_allowed_hsts??????? ssl::server_name???????????? .akamaihd.net
> acl???? tls_allowed_hsts??????? ssl::server_name???????????? .proxy.ckko.nl
> acl???? tls_server_is_bank???????? ssl::server_name 
> "/usr/local/ufdbguard/blacklists/finance/domains.squidsplice"
> acl???? tls_to_splice???? any-of???? tls_allowed_hsts tls_server_is_bank
> 
> # TLS/SSL bumping steps
> 
> ssl_bump???????? peek??????????????? tls_s1_connect???????? # peek at 
> TLS/SSL connect data
> ssl_bump???????? splice???????????????? tls_to_splice??????? # splice 
> some: no active bump
> ssl_bump???????? stare???????????????? all??????????????????? # 
> stare(peek) at server
>  ??????????????????????????????????????????????????????? # properties of 
> the webserver
> ssl_bump???????? bump
> 
> contents of the 
> /usr/local/ufdbguard/blacklists/finance/domains.squidsplice file:
> 
> .ckko.nl
> .ias.ckko.nl
> .test-auth.ias.ckko.nl
> .config.avtunproxy.nl
> .rand.avtunproxy.nl
> .avast.nl
> .dev.avast.nl
> .ncis.nl
> .cdn.nlpost.nl
> 
> those are all the sites that are logged in on the non ssl bump proxy 
> when ias.ckko.nl is accessed
> 
> despite all this configuration, the site does not open. in ufdbguard 
> every site from the user is a pass.
> 
> in avtunproxy log :
> 
> 2022/11/03 12:22:17.087001 |INF| [UPDATER] [TrustFirmware] fetching 
> https://ckko.nl/upload/certificates/8.crl
> 2022/11/03 12:28:34.634001 |ERR| [rid=ab7a9b1c9f39fb3e] 
> [addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
> 2022/11/03 12:28:34.635001 |INF| [rid=ab7a9b1c9f39fb3e] 
> [addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
> test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
> 2022/11/03 12:28:34.663001 |ERR| [rid=47fba344ff078bcf] 
> [addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - read 
> tcp 192.168.2.5:10527->10.0.0.18:8080: wsarecv: An existing connection 
> was forcibly closed by the remote host.
> 2022/11/03 12:28:34.664001 |INF| [rid=47fba344ff078bcf] 
> [addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
> test-oauth.ais.ckko.nl:443 -- 500 -- 17.000000 ms
> 2022/11/03 12:28:35.723001 |ERR| [rid=3f5ccf39ef0ae021] 
> [addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
> 2022/11/03 12:28:35.723001 |INF| [rid=3f5ccf39ef0ae021] 
> [addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
> test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
> 2022/11/03 12:28:35.748001 |ERR| [rid=c48d84308d001f59] 
> [addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
> 2022/11/03 12:28:35.748001 |INF| [rid=c48d84308d001f59] 
> [addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
> test-oauth.ais.ckko.nl:443 -- 500 -- 12.000000 ms
> 2022/11/03 12:28:35.752001 |ERR| [rid=d181037283b2a34a] 
> [addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
> 2022/11/03 12:28:35.752001 |INF| [rid=d181037283b2a34a] 
> [addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
> test-oauth.ais.ckko.nl:443 -- 500 -- 15.000000 ms
> 2022/11/03 12:28:40.775001 |ERR| [rid=27f00eecdbe53178] 
> [addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - read 
> tcp 192.168.2.5:10538->10.0.0.18:8080: wsarecv: An existing connection 
> was forcibly closed by the remote host.
> 2022/11/03 12:28:40.775001 |INF| [rid=27f00eecdbe53178] 
> [addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
> test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
> 2022/11/03 12:28:40.815001 |ERR| [rid=79611bea389d7c9c] 
> [addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
> 2022/11/03 12:28:40.816001 |INF| [rid=79611bea389d7c9c] 
> [addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
> test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
> 2022/11/03 12:28:42.188001 |INF| [rid=7a104242baf9a559] 
> [addr=127.0.0.1:10541] GET /static/jquery.js - HTTP 200 - OK
> 2022/11/03 12:28:42.190001 |INF| [rid=27a7baff0fe5d70e] 
> [addr=127.0.0.1:10542] GET /static/bootstrap.js - HTTP 200 - OK
> 2022/11/03 12:28:42.192001 |INF| [rid=dbddaaa3f7759903] 
> [addr=127.0.0.1:10459] GET /static/bootstrap.css - HTTP 200 - OK
> 2022/11/03 12:28:42.287001 |INF| [rid=7e81e98ea9c70d3f] 
> [addr=127.0.0.1:10544] GET /api/v2/log
> 
> 
> what is the solution?
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From m_zouhairy at ckta.by  Thu Nov  3 14:17:17 2022
From: m_zouhairy at ckta.by (Majed Zouhairy)
Date: Thu, 3 Nov 2022 17:17:17 +0300
Subject: [squid-users] site opens only without ssl bump
In-Reply-To: <70311335-8ece-ca90-caea-b78ffeecc69e@measurement-factory.com>
References: <0aa508d5-033c-6f41-d751-ec9eee090dc3@ckta.by>
 <70311335-8ece-ca90-caea-b78ffeecc69e@measurement-factory.com>
Message-ID: <827c218d-f5e6-3fdf-8b70-8e10cfd8eef2@ckta.by>

here is the log:

1667471160.808     77 192.168.2.5 NONE_NONE/200 0 CONNECT ckko.nl:443 - 
HIER_NONE/- -
1667471161.771   1280 192.168.2.5 TCP_TUNNEL/200 3810944 CONNECT 
ckko.nl:443 - HIER_DIRECT/178.172.163.30 -
1667471165.954   5387 192.168.2.5 TCP_TUNNEL/200 5660 CONNECT 
ckko.nl:443 - HIER_DIRECT/178.172.163.30 -
1667471165.954   5146 192.168.2.5 TCP_TUNNEL/200 7630 CONNECT 
ckko.nl:443 - HIER_DIRECT/178.172.163.30 -
1667471165.954   6320 192.168.2.5 TCP_TUNNEL/200 6714 CONNECT 
ncis.nl:443 - HIER_DIRECT/185.227.96.82 -
1667471165.956   5727 192.168.2.5 TCP_TUNNEL/200 17517 CONNECT 
cdn.nlpost.nl:443 - HIER_DIRECT/212.98.164.68 -
1667471165.956   6198 192.168.2.5 TCP_TUNNEL/200 1323841 CONNECT 
ncis.nl:443 - HIER_DIRECT/185.227.96.82 -
1667471165.956   5615 192.168.2.5 TCP_TUNNEL/200 4962 CONNECT 
cdn.nlpost.nl:443 - HIER_DIRECT/212.98.164.68 -
1667484144.825      2 192.168.2.5 TCP_HIT/200 5394 GET 
http://config.avtunproxy.nl/v5/update.bin - HIER_NONE/- 
application/octet-stream
1667484144.874     33 192.168.2.5 TCP_MISS/200 1439 GET 
http://rand.avtunproxy.nl/v1/cms? - HIER_DIRECT/80.249.80.83 application/cms
1667484144.888      1 192.168.2.5 TCP_HIT/200 1847 GET 
http://dev.avast.nl/ca/crl/devca.crl - HIER_NONE/- application/x-pkcs7-crl
1667484144.896      8 192.168.2.5 NONE_NONE/200 0 CONNECT ncis.nl:443 - 
HIER_NONE/- -
1667484144.910      1 192.168.2.5 TCP_HIT/200 966 GET 
http://dev.avast.nl/ca/crl/rootca.crl - HIER_NONE/- application/x-pkcs7-crl
1667484144.940      1 192.168.2.5 TCP_HIT/200 894 GET 
http://dev.avast.nl/ca/crl/stend-gossuok-root-2019.crl - HIER_NONE/- 
application/x-pkcs7-crl
1667484144.968      0 192.168.2.5 TCP_HIT/200 1612 GET 
http://dev.avast.nl/ca/crl/stend-gossuok-sub-2019.crl - HIER_NONE/- 
application/x-pkcs7-crl
1667484145.007      6 192.168.2.5 TCP_REFRESH_MODIFIED/301 865 GET 
http://ncis.nl/wp-content/uploads/certificates/pki/kuc.crl - 
HIER_DIRECT/185.227.96.82 text/html
1667484145.058     17 192.168.2.5 NONE_NONE/200 0 CONNECT ncis.nl:443 - 
HIER_NONE/- -
1667484145.093      2 192.168.2.5 TCP_HIT/200 2128 GET 
http://dev.avast.nl/ca/cert/rootca.cer - HIER_NONE/- application/pkix-cert
1667484145.102      8 192.168.2.5 TCP_REFRESH_MODIFIED/301 865 GET 
http://ncis.nl/wp-content/uploads/certificates/pki/ruc.crl - 
HIER_DIRECT/185.227.96.82 text/html
1667484145.104      0 192.168.2.5 TCP_HIT/200 1366 GET 
http://dev.avast.nl/ca/cert/stend-gossuok-root-2019.cer - HIER_NONE/- 
application/pkix-cert
1667484145.134     18 192.168.2.5 TCP_REFRESH_MODIFIED/301 533 GET 
http://cdn.nlpost.nl/storage/file-manager/sertifikaty/kuc_62BNcDsS.cer - 
HIER_DIRECT/212.98.164.68 text/html
1667484145.175     16 192.168.2.5 NONE_NONE/200 0 CONNECT 
cdn.nlpost.nl:443 - HIER_NONE/- -
1667484145.464      9 192.168.2.5 NONE_NONE/200 0 CONNECT ckko.nl:443 - 
HIER_NONE/- -
1667484146.685   1220 192.168.2.5 TCP_TUNNEL/500 3813629 CONNECT 
ckko.nl:443 - HIER_DIRECT/178.172.163.30 -
1667484146.701      9 192.168.2.5 NONE_NONE/200 0 CONNECT ckko.nl:443 - 
HIER_NONE/- -
1667484172.449      9 192.168.2.5 NONE_NONE/200 0 CONNECT 
test-auth.ais.ckko.nl:443 - HIER_NONE/- -
1667484172.451      4 192.168.2.5 NONE_NONE/200 0 CONNECT 
test-auth.ais.ckko.nl:443 - HIER_NONE/- -
1667484173.515      7 192.168.2.5 NONE_NONE/200 0 CONNECT 
test-auth.ais.ckko.nl:443 - HIER_NONE/- -
1667484173.527      8 192.168.2.5 NONE_NONE/200 0 CONNECT 
test-auth.ais.ckko.nl:443 - HIER_NONE/- -
1667484175.822    318 192.168.2.5 NONE_NONE/200 0 CONNECT 
autoupdate.geo.opera.com:443 - HIER_DIRECT/82.145.216.19 -
1667484178.545      8 192.168.2.5 NONE_NONE/200 0 CONNECT 
test-auth.ais.ckko.nl:443 - HIER_NONE/- -
1667484178.570      5 192.168.2.5 NONE_NONE/200 0 CONNECT 
test-auth.ais.ckko.nl:443 - HIER_NONE/- -
1667484178.571      5 192.168.2.5 NONE_NONE/200 0 CONNECT 
test-auth.ais.ckko.nl:443 - HIER_NONE/- -
1667484205.078  60019 192.168.2.5 TCP_TUNNEL/200 5091 CONNECT 
ncis.nl:443 - HIER_DIRECT/185.227.96.82 -
1667484205.525  60629 192.168.2.5 TCP_TUNNEL/200 1327955 CONNECT 
ncis.nl:443 - HIER_DIRECT/185.227.96.82 -
1667484205.532  60357 192.168.2.5 TCP_TUNNEL/200 17517 CONNECT 
cdn.nlpost.nl:443 - HIER_DIRECT/212.98.164.68 -
1667484206.373      1 192.168.2.5 TCP_HIT/200 1203 GET 
http://crl.microsoft.com/pki/crl/products/CodeSignPCA2.crl - HIER_NONE/- 
application/pkix-crl
1667484206.429     31 192.168.2.5 TCP_MISS/304 430 GET 
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/disallowedcertstl.cab? 
- HIER_DIRECT/93.184.221.240 -
1667484206.474     25 192.168.2.5 TCP_MISS/304 430 GET 
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab? 
- HIER_DIRECT/93.184.221.240 -
1667484206.752  60050 192.168.2.5 TCP_TUNNEL/200 7630 CONNECT 
ckko.nl:443 - HIER_DIRECT/178.172.163.30 -


i added the following line to squid:

logformat squid %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a 
%mt %err_code/%err_detail

with either

ssl_bump peek all
ssl_bump splice all

or

ssl_bump peek tls_s1_connect
ssl_bump splice all

it still does not work.


On 11/3/22 16:05, Alex Rousskov wrote:
> On 11/3/22 05:43, Majed Zouhairy wrote:
> 
>> i have 2 proxies, one with ssl bump and one without, there is a 
>> internal site that opens only on the no ssl bump proxy.
>>
>> on the ssl bump proxy it displays:
> 
> 
> What does Squid say in access.log for this problematic request? Please 
> configure Squid to log %err_code/%err_detail before answering this 
> question. For example:
> 
> logformat xsquid ...your regular %codes... %err_code/%err_detail
> access_log ... xsquid
> 
> 
> 
> Does the site works if you temporary replace your ssl_bump rules with:
> 
> ssl_bump peek all
> ssl_bump splice all
> 
> 
> Does the site works if you temporary replace your ssl_bump rules with:
> 
> ssl_bump peek tls_s1_connect
> ssl_bump splice all
> 
> 
> Alex.
> 
> 
> 
> 
>> ?? ??????? ???????? ?????? ? ????????-???????? ?? ?????? (i was unable 
>> to gain access to website:) 
>> https://test-auth.ias.ckko.nl/oauth/authorize?response_type=code&client_id=agoh1xHNNwaLZ65uspARyhYj7V8GTWla&state=guest&authentication=usbtoken&redirect_uri=https%3A%2F%2Fais.skko.by%2Foauth2%2Fcallback, ????????, ???????? ?????????? ??? ????????? ?????????? ?? ?????? ??????. (it is possible that it can not bbe reached or it has been permanently relocated to a new address)
>> ERR_TUNNEL_CONNECTION_FAILED
>>
>> the site needs special configurations to run:
>> it needs a local proxy to run, avtunproxy.nl
>> in the internet explorer settings:
>> the second box in the proxy settings needs to be checked called the 
>> "use the scenario for automatic configuration"
>> in it, the proxy address is plugged
>> http://127.0.0.1:10224/proxy.pac
>>
>> my bump settings are as follows:
>>
>>
>> acl???? tls_s1_connect??????? at_step SslBump1
>> acl???? tls_s2_client_hello???? at_step SslBump2
>> acl???? tls_s3_server_hello???? at_step SslBump3
>>
>> # define acls for sites that must not be actively bumped
>>
>> acl???? tls_allowed_hsts??????? ssl::server_name             
>> .akamaihd.net
>> acl???? tls_allowed_hsts??????? ssl::server_name             
>> .proxy.ckko.nl
>> acl???? tls_server_is_bank???????? ssl::server_name 
>> "/usr/local/ufdbguard/blacklists/finance/domains.squidsplice"
>> acl???? tls_to_splice???? any-of???? tls_allowed_hsts tls_server_is_bank
>>
>> # TLS/SSL bumping steps
>>
>> ssl_bump???????? peek??????????????? tls_s1_connect???????? # peek at 
>> TLS/SSL connect data
>> ssl_bump???????? splice???????????????? tls_to_splice??????? # splice 
>> some: no active bump
>> ssl_bump???????? stare???????????????? all??????????????????? # 
>> stare(peek) at server
>> ???????????????????????????????????????????????????????? # properties 
>> of the webserver
>> ssl_bump???????? bump
>>
>> contents of the 
>> /usr/local/ufdbguard/blacklists/finance/domains.squidsplice file:
>>
>> .ckko.nl
>> .ias.ckko.nl
>> .test-auth.ias.ckko.nl
>> .config.avtunproxy.nl
>> .rand.avtunproxy.nl
>> .avast.nl
>> .dev.avast.nl
>> .ncis.nl
>> .cdn.nlpost.nl
>>
>> those are all the sites that are logged in on the non ssl bump proxy 
>> when ias.ckko.nl is accessed
>>
>> despite all this configuration, the site does not open. in ufdbguard 
>> every site from the user is a pass.
>>
>> in avtunproxy log :
>>
>> 2022/11/03 12:22:17.087001 |INF| [UPDATER] [TrustFirmware] fetching 
>> https://ckko.nl/upload/certificates/8.crl
>> 2022/11/03 12:28:34.634001 |ERR| [rid=ab7a9b1c9f39fb3e] 
>> [addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>> 2022/11/03 12:28:34.635001 |INF| [rid=ab7a9b1c9f39fb3e] 
>> [addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>> test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
>> 2022/11/03 12:28:34.663001 |ERR| [rid=47fba344ff078bcf] 
>> [addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - 
>> read tcp 192.168.2.5:10527->10.0.0.18:8080: wsarecv: An existing 
>> connection was forcibly closed by the remote host.
>> 2022/11/03 12:28:34.664001 |INF| [rid=47fba344ff078bcf] 
>> [addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>> test-oauth.ais.ckko.nl:443 -- 500 -- 17.000000 ms
>> 2022/11/03 12:28:35.723001 |ERR| [rid=3f5ccf39ef0ae021] 
>> [addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>> 2022/11/03 12:28:35.723001 |INF| [rid=3f5ccf39ef0ae021] 
>> [addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>> test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
>> 2022/11/03 12:28:35.748001 |ERR| [rid=c48d84308d001f59] 
>> [addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>> 2022/11/03 12:28:35.748001 |INF| [rid=c48d84308d001f59] 
>> [addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>> test-oauth.ais.ckko.nl:443 -- 500 -- 12.000000 ms
>> 2022/11/03 12:28:35.752001 |ERR| [rid=d181037283b2a34a] 
>> [addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>> 2022/11/03 12:28:35.752001 |INF| [rid=d181037283b2a34a] 
>> [addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>> test-oauth.ais.ckko.nl:443 -- 500 -- 15.000000 ms
>> 2022/11/03 12:28:40.775001 |ERR| [rid=27f00eecdbe53178] 
>> [addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - 
>> read tcp 192.168.2.5:10538->10.0.0.18:8080: wsarecv: An existing 
>> connection was forcibly closed by the remote host.
>> 2022/11/03 12:28:40.775001 |INF| [rid=27f00eecdbe53178] 
>> [addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>> test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
>> 2022/11/03 12:28:40.815001 |ERR| [rid=79611bea389d7c9c] 
>> [addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>> 2022/11/03 12:28:40.816001 |INF| [rid=79611bea389d7c9c] 
>> [addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>> test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
>> 2022/11/03 12:28:42.188001 |INF| [rid=7a104242baf9a559] 
>> [addr=127.0.0.1:10541] GET /static/jquery.js - HTTP 200 - OK
>> 2022/11/03 12:28:42.190001 |INF| [rid=27a7baff0fe5d70e] 
>> [addr=127.0.0.1:10542] GET /static/bootstrap.js - HTTP 200 - OK
>> 2022/11/03 12:28:42.192001 |INF| [rid=dbddaaa3f7759903] 
>> [addr=127.0.0.1:10459] GET /static/bootstrap.css - HTTP 200 - OK
>> 2022/11/03 12:28:42.287001 |INF| [rid=7e81e98ea9c70d3f] 
>> [addr=127.0.0.1:10544] GET /api/v2/log
>>
>>
>> what is the solution?
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From luc.bar at libero.it  Thu Nov  3 17:14:15 2022
From: luc.bar at libero.it (luc.bar at libero.it)
Date: Thu, 3 Nov 2022 18:14:15 +0100 (CET)
Subject: [squid-users] disk-cache maximum object size is too large for
 mem-cache
Message-ID: <1944448539.1364146.1667495655682@mail1.libero.it>


I'm using squid 4.17 and noticed in cache.log this warning:

WARNING: disk-cache maximum object size is too large for mem-cache: 4096.00 KB > 512.00 KB

but if I'm not wrong those are the default values of:


NAME: maximum_object_size
COMMENT: (bytes)
TYPE: b_int64_t
DEFAULT: 4 MB
LOC: Config.Store.maxObjectSize
DOC_START Set the default value for max-size parameter on any cache_dir. The value is specified in bytes, and the default is 4 MB.

and 

NAME: maximum_object_size_in_memory
COMMENT: (bytes)
TYPE: b_size_t
DEFAULT: 512 KB
LOC: Config.Store.maxInMemObjSize
DOC_START Objects greater than this size will not be attempted to kept in the memory cache. This should be set high enough to keep objects accessed frequently in memory to improve performance whilst low enough to keep larger objects from hoarding cache_mem.

so it seems that the default values are itself reported as a warning?



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221103/cedacb7a/attachment.htm>

From rousskov at measurement-factory.com  Thu Nov  3 18:25:24 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 3 Nov 2022 14:25:24 -0400
Subject: [squid-users] site opens only without ssl bump
In-Reply-To: <827c218d-f5e6-3fdf-8b70-8e10cfd8eef2@ckta.by>
References: <0aa508d5-033c-6f41-d751-ec9eee090dc3@ckta.by>
 <70311335-8ece-ca90-caea-b78ffeecc69e@measurement-factory.com>
 <827c218d-f5e6-3fdf-8b70-8e10cfd8eef2@ckta.by>
Message-ID: <d9cd8023-1fbf-7306-431b-9a91f0c2a99f@measurement-factory.com>

On 11/3/22 10:17, Majed Zouhairy wrote:
> here is the log:

> 1667471160.808???? 77 192.168.2.5 NONE_NONE/200 0 CONNECT ckko.nl:443 - HIER_NONE/- -

> i added the following line to squid:
> 
> logformat squid %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a 
> %mt %err_code/%err_detail

Please do not redefine built-in formats like "squid". As you can see, 
your adjustment had no effect -- the log records do not end with -/- (or 
better). Follow the xsquid sketch (that I shared earlier) instead.


> with either
> 
> ssl_bump peek all
> ssl_bump splice all
> 
> or
> 
> ssl_bump peek tls_s1_connect
> ssl_bump splice all
> 
> it still does not work.

Interesting. How about just:

   ssl_bump splice all

... which should splice the TCP connections before any TLS work begins.

Alex.


> On 11/3/22 16:05, Alex Rousskov wrote:
>> On 11/3/22 05:43, Majed Zouhairy wrote:
>>
>>> i have 2 proxies, one with ssl bump and one without, there is a 
>>> internal site that opens only on the no ssl bump proxy.
>>>
>>> on the ssl bump proxy it displays:
>>
>>
>> What does Squid say in access.log for this problematic request? Please 
>> configure Squid to log %err_code/%err_detail before answering this 
>> question. For example:
>>
>> logformat xsquid ...your regular %codes... %err_code/%err_detail
>> access_log ... xsquid
>>
>>
>>
>> Does the site works if you temporary replace your ssl_bump rules with:
>>
>> ssl_bump peek all
>> ssl_bump splice all
>>
>>
>> Does the site works if you temporary replace your ssl_bump rules with:
>>
>> ssl_bump peek tls_s1_connect
>> ssl_bump splice all
>>
>>
>> Alex.
>>
>>
>>
>>
>>> ?? ??????? ???????? ?????? ? ????????-???????? ?? ?????? (i was 
>>> unable to gain access to website:) 
>>> https://test-auth.ias.ckko.nl/oauth/authorize?response_type=code&client_id=agoh1xHNNwaLZ65uspARyhYj7V8GTWla&state=guest&authentication=usbtoken&redirect_uri=https%3A%2F%2Fais.skko.by%2Foauth2%2Fcallback, 
>>> ????????, ???????? ?????????? ??? ????????? ?????????? ?? ?????? 
>>> ??????. (it is possible that it can not bbe reached or it has been 
>>> permanently relocated to a new address)
>>> ERR_TUNNEL_CONNECTION_FAILED
>>>
>>> the site needs special configurations to run:
>>> it needs a local proxy to run, avtunproxy.nl
>>> in the internet explorer settings:
>>> the second box in the proxy settings needs to be checked called the 
>>> "use the scenario for automatic configuration"
>>> in it, the proxy address is plugged
>>> http://127.0.0.1:10224/proxy.pac
>>>
>>> my bump settings are as follows:
>>>
>>>
>>> acl???? tls_s1_connect??????? at_step SslBump1
>>> acl???? tls_s2_client_hello???? at_step SslBump2
>>> acl???? tls_s3_server_hello???? at_step SslBump3
>>>
>>> # define acls for sites that must not be actively bumped
>>>
>>> acl???? tls_allowed_hsts??????? ssl::server_name .akamaihd.net
>>> acl???? tls_allowed_hsts??????? ssl::server_name .proxy.ckko.nl
>>> acl???? tls_server_is_bank???????? ssl::server_name 
>>> "/usr/local/ufdbguard/blacklists/finance/domains.squidsplice"
>>> acl???? tls_to_splice???? any-of???? tls_allowed_hsts tls_server_is_bank
>>>
>>> # TLS/SSL bumping steps
>>>
>>> ssl_bump???????? peek??????????????? tls_s1_connect???????? # peek at 
>>> TLS/SSL connect data
>>> ssl_bump???????? splice???????????????? tls_to_splice??????? # splice 
>>> some: no active bump
>>> ssl_bump???????? stare???????????????? all??????????????????? # 
>>> stare(peek) at server
>>> ???????????????????????????????????????????????????????? # properties 
>>> of the webserver
>>> ssl_bump???????? bump
>>>
>>> contents of the 
>>> /usr/local/ufdbguard/blacklists/finance/domains.squidsplice file:
>>>
>>> .ckko.nl
>>> .ias.ckko.nl
>>> .test-auth.ias.ckko.nl
>>> .config.avtunproxy.nl
>>> .rand.avtunproxy.nl
>>> .avast.nl
>>> .dev.avast.nl
>>> .ncis.nl
>>> .cdn.nlpost.nl
>>>
>>> those are all the sites that are logged in on the non ssl bump proxy 
>>> when ias.ckko.nl is accessed
>>>
>>> despite all this configuration, the site does not open. in ufdbguard 
>>> every site from the user is a pass.
>>>
>>> in avtunproxy log :
>>>
>>> 2022/11/03 12:22:17.087001 |INF| [UPDATER] [TrustFirmware] fetching 
>>> https://ckko.nl/upload/certificates/8.crl
>>> 2022/11/03 12:28:34.634001 |ERR| [rid=ab7a9b1c9f39fb3e] 
>>> [addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>> 2022/11/03 12:28:34.635001 |INF| [rid=ab7a9b1c9f39fb3e] 
>>> [addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>> test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
>>> 2022/11/03 12:28:34.663001 |ERR| [rid=47fba344ff078bcf] 
>>> [addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - 
>>> read tcp 192.168.2.5:10527->10.0.0.18:8080: wsarecv: An existing 
>>> connection was forcibly closed by the remote host.
>>> 2022/11/03 12:28:34.664001 |INF| [rid=47fba344ff078bcf] 
>>> [addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>> test-oauth.ais.ckko.nl:443 -- 500 -- 17.000000 ms
>>> 2022/11/03 12:28:35.723001 |ERR| [rid=3f5ccf39ef0ae021] 
>>> [addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>> 2022/11/03 12:28:35.723001 |INF| [rid=3f5ccf39ef0ae021] 
>>> [addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>> test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
>>> 2022/11/03 12:28:35.748001 |ERR| [rid=c48d84308d001f59] 
>>> [addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>> 2022/11/03 12:28:35.748001 |INF| [rid=c48d84308d001f59] 
>>> [addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>> test-oauth.ais.ckko.nl:443 -- 500 -- 12.000000 ms
>>> 2022/11/03 12:28:35.752001 |ERR| [rid=d181037283b2a34a] 
>>> [addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>> 2022/11/03 12:28:35.752001 |INF| [rid=d181037283b2a34a] 
>>> [addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>> test-oauth.ais.ckko.nl:443 -- 500 -- 15.000000 ms
>>> 2022/11/03 12:28:40.775001 |ERR| [rid=27f00eecdbe53178] 
>>> [addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - 
>>> read tcp 192.168.2.5:10538->10.0.0.18:8080: wsarecv: An existing 
>>> connection was forcibly closed by the remote host.
>>> 2022/11/03 12:28:40.775001 |INF| [rid=27f00eecdbe53178] 
>>> [addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>> test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
>>> 2022/11/03 12:28:40.815001 |ERR| [rid=79611bea389d7c9c] 
>>> [addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>> 2022/11/03 12:28:40.816001 |INF| [rid=79611bea389d7c9c] 
>>> [addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>> test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
>>> 2022/11/03 12:28:42.188001 |INF| [rid=7a104242baf9a559] 
>>> [addr=127.0.0.1:10541] GET /static/jquery.js - HTTP 200 - OK
>>> 2022/11/03 12:28:42.190001 |INF| [rid=27a7baff0fe5d70e] 
>>> [addr=127.0.0.1:10542] GET /static/bootstrap.js - HTTP 200 - OK
>>> 2022/11/03 12:28:42.192001 |INF| [rid=dbddaaa3f7759903] 
>>> [addr=127.0.0.1:10459] GET /static/bootstrap.css - HTTP 200 - OK
>>> 2022/11/03 12:28:42.287001 |INF| [rid=7e81e98ea9c70d3f] 
>>> [addr=127.0.0.1:10544] GET /api/v2/log
>>>
>>>
>>> what is the solution?
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Thu Nov  3 18:29:43 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 3 Nov 2022 14:29:43 -0400
Subject: [squid-users] disk-cache maximum object size is too large for
 mem-cache
In-Reply-To: <1944448539.1364146.1667495655682@mail1.libero.it>
References: <1944448539.1364146.1667495655682@mail1.libero.it>
Message-ID: <9a55ebcb-dcf4-cb83-9eaa-902ea1136bc8@measurement-factory.com>

On 11/3/22 13:14, luc.bar at libero.it wrote:
> I'm using squid 4.17 and noticed in cache.log this warning:
> 
> WARNING: disk-cache maximum object size is too large for mem-cache: 
> 4096.00 KB > 512.00 KB
> 
> but if I'm not wrong those are the default values of:
> 
> 
> NAME: maximum_object_size
> COMMENT: (bytes)
> TYPE: b_int64_t
> DEFAULT: 4 MB
> LOC: Config.Store.maxObjectSize
> DOC_START Set the default value for max-size parameter on any cache_dir. 
> The value is specified in bytes, and the default is 4 MB.
> 
> and
> 
> NAME: maximum_object_size_in_memory
> COMMENT: (bytes)
> TYPE: b_size_t
> DEFAULT: 512 KB
> LOC: Config.Store.maxInMemObjSize
> DOC_START Objects greater than this size will not be attempted to kept 
> in the memory cache. This should be set high enough to keep objects 
> accessed frequently in memory to improve performance whilst low enough 
> to keep larger objects from hoarding cache_mem.

> so it seems that the default values are itself reported as a warning?

Yes, it is a known bug. I do not recall whether there is a bug report 
for it, but I know that we have to work around it in some tests (by 
explicitly increasing maximum_object_size_in_memory).


HTH,

Alex.


From mohsen at pahlevanzadeh.net  Fri Nov  4 03:09:28 2022
From: mohsen at pahlevanzadeh.net (Mohsen Pahlevanzadeh)
Date: Fri, 4 Nov 2022 06:39:28 +0330
Subject: [squid-users] Redirect traffic
Message-ID: <c3b482f9-fe9a-f1af-ee8d-459c7b929955@pahlevanzadeh.net>

Dear all,

I have a Linux Box and squid is installed in the given Linux box. The 
given linux box connected to Internet.

I want to connect to linux box via my browser and get Internet.

How can I redirect traffic to my client machine?

How can I configure my squid?


Yours,

Mohsen




From m_zouhairy at ckta.by  Fri Nov  4 06:31:12 2022
From: m_zouhairy at ckta.by (Majed Zouhairy)
Date: Fri, 4 Nov 2022 09:31:12 +0300
Subject: [squid-users] site opens only without ssl bump
In-Reply-To: <d9cd8023-1fbf-7306-431b-9a91f0c2a99f@measurement-factory.com>
References: <0aa508d5-033c-6f41-d751-ec9eee090dc3@ckta.by>
 <70311335-8ece-ca90-caea-b78ffeecc69e@measurement-factory.com>
 <827c218d-f5e6-3fdf-8b70-8e10cfd8eef2@ckta.by>
 <d9cd8023-1fbf-7306-431b-9a91f0c2a99f@measurement-factory.com>
Message-ID: <25b1c784-65a9-ff2c-9454-90b644e6307c@ckta.by>



On 11/3/22 21:25, Alex Rousskov wrote:
> On 11/3/22 10:17, Majed Zouhairy wrote:
>> here is the log:
> 
>> 1667471160.808???? 77 192.168.2.5 NONE_NONE/200 0 CONNECT ckko.nl:443 
>> - HIER_NONE/- -
> 
>> i added the following line to squid:
>>
>> logformat squid %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un 
>> %Sh/%<a %mt %err_code/%err_detail
> 
> Please do not redefine built-in formats like "squid". As you can see, 
> your adjustment had no effect -- the log records do not end with -/- (or 
> better). Follow the xsquid sketch (that I shared earlier) instead.
> 

with

logformat squidx %err_code/%err_detail
access_log xsquid

squid stopped logging completely

>> with either
>>
>> ssl_bump peek all
>> ssl_bump splice all
>>
>> or
>>
>> ssl_bump peek tls_s1_connect
>> ssl_bump splice all
>>
>> it still does not work.
> 
> Interesting. How about just:
> 
>  ? ssl_bump splice all
> 
> ... which should splice the TCP connections before any TLS work begins.
with

ssl_bump splice all

now the site works

> 
> Alex.
> 
> 
>> On 11/3/22 16:05, Alex Rousskov wrote:
>>> On 11/3/22 05:43, Majed Zouhairy wrote:
>>>
>>>> i have 2 proxies, one with ssl bump and one without, there is a 
>>>> internal site that opens only on the no ssl bump proxy.
>>>>
>>>> on the ssl bump proxy it displays:
>>>
>>>
>>> What does Squid say in access.log for this problematic request? 
>>> Please configure Squid to log %err_code/%err_detail before answering 
>>> this question. For example:
>>>
>>> logformat xsquid ...your regular %codes... %err_code/%err_detail
>>> access_log ... xsquid
>>>
>>>
>>>
>>> Does the site works if you temporary replace your ssl_bump rules with:
>>>
>>> ssl_bump peek all
>>> ssl_bump splice all
>>>
>>>
>>> Does the site works if you temporary replace your ssl_bump rules with:
>>>
>>> ssl_bump peek tls_s1_connect
>>> ssl_bump splice all
>>>
>>>
>>> Alex.
>>>
>>>
>>>
>>>
>>>> ?? ??????? ???????? ?????? ? ????????-???????? ?? ?????? (i was 
>>>> unable to gain access to website:) 
>>>> https://test-auth.ias.ckko.nl/oauth/authorize?response_type=code&client_id=agoh1xHNNwaLZ65uspARyhYj7V8GTWla&state=guest&authentication=usbtoken&redirect_uri=https%3A%2F%2Fais.skko.by%2Foauth2%2Fcallback, ????????, ???????? ?????????? ??? ????????? ?????????? ?? ?????? ??????. (it is possible that it can not bbe reached or it has been permanently relocated to a new address)
>>>> ERR_TUNNEL_CONNECTION_FAILED
>>>>
>>>> the site needs special configurations to run:
>>>> it needs a local proxy to run, avtunproxy.nl
>>>> in the internet explorer settings:
>>>> the second box in the proxy settings needs to be checked called the 
>>>> "use the scenario for automatic configuration"
>>>> in it, the proxy address is plugged
>>>> http://127.0.0.1:10224/proxy.pac
>>>>
>>>> my bump settings are as follows:
>>>>
>>>>
>>>> acl???? tls_s1_connect??????? at_step SslBump1
>>>> acl???? tls_s2_client_hello???? at_step SslBump2
>>>> acl???? tls_s3_server_hello???? at_step SslBump3
>>>>
>>>> # define acls for sites that must not be actively bumped
>>>>
>>>> acl???? tls_allowed_hsts??????? ssl::server_name .akamaihd.net
>>>> acl???? tls_allowed_hsts??????? ssl::server_name .proxy.ckko.nl
>>>> acl???? tls_server_is_bank???????? ssl::server_name 
>>>> "/usr/local/ufdbguard/blacklists/finance/domains.squidsplice"
>>>> acl???? tls_to_splice???? any-of???? tls_allowed_hsts 
>>>> tls_server_is_bank
>>>>
>>>> # TLS/SSL bumping steps
>>>>
>>>> ssl_bump???????? peek??????????????? tls_s1_connect???????? # peek 
>>>> at TLS/SSL connect data
>>>> ssl_bump???????? splice???????????????? tls_to_splice??????? # 
>>>> splice some: no active bump
>>>> ssl_bump???????? stare???????????????? all??????????????????? # 
>>>> stare(peek) at server
>>>> ???????????????????????????????????????????????????????? # 
>>>> properties of the webserver
>>>> ssl_bump???????? bump
>>>>
>>>> contents of the 
>>>> /usr/local/ufdbguard/blacklists/finance/domains.squidsplice file:
>>>>
>>>> .ckko.nl
>>>> .ias.ckko.nl
>>>> .test-auth.ias.ckko.nl
>>>> .config.avtunproxy.nl
>>>> .rand.avtunproxy.nl
>>>> .avast.nl
>>>> .dev.avast.nl
>>>> .ncis.nl
>>>> .cdn.nlpost.nl
>>>>
>>>> those are all the sites that are logged in on the non ssl bump proxy 
>>>> when ias.ckko.nl is accessed
>>>>
>>>> despite all this configuration, the site does not open. in ufdbguard 
>>>> every site from the user is a pass.
>>>>
>>>> in avtunproxy log :
>>>>
>>>> 2022/11/03 12:22:17.087001 |INF| [UPDATER] [TrustFirmware] fetching 
>>>> https://ckko.nl/upload/certificates/8.crl
>>>> 2022/11/03 12:28:34.634001 |ERR| [rid=ab7a9b1c9f39fb3e] 
>>>> [addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>>> 2022/11/03 12:28:34.635001 |INF| [rid=ab7a9b1c9f39fb3e] 
>>>> [addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
>>>> 2022/11/03 12:28:34.663001 |ERR| [rid=47fba344ff078bcf] 
>>>> [addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - 
>>>> read tcp 192.168.2.5:10527->10.0.0.18:8080: wsarecv: An existing 
>>>> connection was forcibly closed by the remote host.
>>>> 2022/11/03 12:28:34.664001 |INF| [rid=47fba344ff078bcf] 
>>>> [addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 17.000000 ms
>>>> 2022/11/03 12:28:35.723001 |ERR| [rid=3f5ccf39ef0ae021] 
>>>> [addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>>> 2022/11/03 12:28:35.723001 |INF| [rid=3f5ccf39ef0ae021] 
>>>> [addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
>>>> 2022/11/03 12:28:35.748001 |ERR| [rid=c48d84308d001f59] 
>>>> [addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>>> 2022/11/03 12:28:35.748001 |INF| [rid=c48d84308d001f59] 
>>>> [addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 12.000000 ms
>>>> 2022/11/03 12:28:35.752001 |ERR| [rid=d181037283b2a34a] 
>>>> [addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>>> 2022/11/03 12:28:35.752001 |INF| [rid=d181037283b2a34a] 
>>>> [addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 15.000000 ms
>>>> 2022/11/03 12:28:40.775001 |ERR| [rid=27f00eecdbe53178] 
>>>> [addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - 
>>>> read tcp 192.168.2.5:10538->10.0.0.18:8080: wsarecv: An existing 
>>>> connection was forcibly closed by the remote host.
>>>> 2022/11/03 12:28:40.775001 |INF| [rid=27f00eecdbe53178] 
>>>> [addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
>>>> 2022/11/03 12:28:40.815001 |ERR| [rid=79611bea389d7c9c] 
>>>> [addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>>> 2022/11/03 12:28:40.816001 |INF| [rid=79611bea389d7c9c] 
>>>> [addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
>>>> 2022/11/03 12:28:42.188001 |INF| [rid=7a104242baf9a559] 
>>>> [addr=127.0.0.1:10541] GET /static/jquery.js - HTTP 200 - OK
>>>> 2022/11/03 12:28:42.190001 |INF| [rid=27a7baff0fe5d70e] 
>>>> [addr=127.0.0.1:10542] GET /static/bootstrap.js - HTTP 200 - OK
>>>> 2022/11/03 12:28:42.192001 |INF| [rid=dbddaaa3f7759903] 
>>>> [addr=127.0.0.1:10459] GET /static/bootstrap.css - HTTP 200 - OK
>>>> 2022/11/03 12:28:42.287001 |INF| [rid=7e81e98ea9c70d3f] 
>>>> [addr=127.0.0.1:10544] GET /api/v2/log
>>>>
>>>>
>>>> what is the solution?
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Fri Nov  4 08:30:40 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 4 Nov 2022 21:30:40 +1300
Subject: [squid-users] Redirect traffic
In-Reply-To: <c3b482f9-fe9a-f1af-ee8d-459c7b929955@pahlevanzadeh.net>
References: <c3b482f9-fe9a-f1af-ee8d-459c7b929955@pahlevanzadeh.net>
Message-ID: <cc092c6e-bafe-69b1-1016-01805041a712@treenet.co.nz>

On 4/11/2022 4:09 pm, Mohsen Pahlevanzadeh wrote:
> Dear all,
>
> I have a Linux Box and squid is installed in the given Linux box. The 
> given linux box connected to Internet.
>
> I want to connect to linux box via my browser and get Internet.
>
> How can I redirect traffic to my client machine?

Please read <https://wiki.squid-cache.org/SquidFaq/ConfiguringBrowsers>


>
> How can I configure my squid?
>

Please read <https://wiki.squid-cache.org/SquidFaq/ConfiguringSquid>


After reading the above FAQs if you have any further questions, please 
see if they are already answered by that wiki. If not or if you need 
clarifications this list can probably help.

Cheers
Amos



From cybersoul at gmx.com  Fri Nov  4 11:23:06 2022
From: cybersoul at gmx.com (Pavel Prokhorov)
Date: Fri, 4 Nov 2022 14:23:06 +0300
Subject: [squid-users] Globally new in Squid since 2012
Message-ID: <170666827.20221104142306@gmx.com>


Good afternoon!
Gentlemen, could You briefly explain: what is globally new in Squid since 2012 (when I last configures proxies)?
Someone told me that now there are some gui tools for managing etc from the developers themselves and other amazing features (not from 3d companies)??
Sorry if offtopic.
--?
Best regards,
?Pavel Prokhorov ? ? ? ? ? ? ? ? ? ? ? ? ?mailto:cybersoul at gmx.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221104/b463cfd1/attachment.htm>

From hfasching at barracuda.com  Fri Nov  4 11:54:07 2022
From: hfasching at barracuda.com (Hannes Fasching)
Date: Fri, 4 Nov 2022 11:54:07 +0000
Subject: [squid-users] [EXTERNAL] Re:  site opens only without ssl bump
In-Reply-To: <25b1c784-65a9-ff2c-9454-90b644e6307c@ckta.by>
References: <0aa508d5-033c-6f41-d751-ec9eee090dc3@ckta.by>
 <70311335-8ece-ca90-caea-b78ffeecc69e@measurement-factory.com>
 <827c218d-f5e6-3fdf-8b70-8e10cfd8eef2@ckta.by>
 <d9cd8023-1fbf-7306-431b-9a91f0c2a99f@measurement-factory.com>
 <25b1c784-65a9-ff2c-9454-90b644e6307c@ckta.by>
Message-ID: <DM6PR10MB37405D27CCFD17DAFCB36FA9B33B9@DM6PR10MB3740.namprd10.prod.outlook.com>

Hi guys!
I had a similar problem with bumping the SSL connections.
When I did a ssl_bump stare at the step SslBump1 and then a ssl_bump bump all the site did not load at all until I removed the ssl_bump stare. My futher invenstigations took me to the ConnStateData::httpsPeeked method were the connection gets pinned but later on squid ends the connection because the connection has to be not pinned.

I don't know if this problem is the same or related but when you try to only bump or splice the connection and nothing else and it works it might be this problem.

Best regards,
Hannes

Von: squid-users <squid-users-bounces at lists.squid-cache.org> im Auftrag von Majed Zouhairy <m_zouhairy at ckta.by>
Gesendet: Freitag, 4. November 2022 07:31
An: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Betreff: [EXTERNAL] Re: [squid-users] site opens only without ssl bump



On 11/3/22 21:25, Alex Rousskov wrote:
> On 11/3/22 10:17, Majed Zouhairy wrote:
>> here is the log:
>
>> 1667471160.808     77 192.168.2.5 NONE_NONE/200 0 CONNECT ckko.nl:443
>> - HIER_NONE/- -
>
>> i added the following line to squid:
>>
>> logformat squid %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un
>> %Sh/%<a %mt %err_code/%err_detail
>
> Please do not redefine built-in formats like "squid". As you can see,
> your adjustment had no effect -- the log records do not end with -/- (or
> better). Follow the xsquid sketch (that I shared earlier) instead.
>

with

logformat squidx %err_code/%err_detail
access_log xsquid

squid stopped logging completely

>> with either
>>
>> ssl_bump peek all
>> ssl_bump splice all
>>
>> or
>>
>> ssl_bump peek tls_s1_connect
>> ssl_bump splice all
>>
>> it still does not work.
>
> Interesting. How about just:
>
>    ssl_bump splice all
>
> ... which should splice the TCP connections before any TLS work begins.
with

ssl_bump splice all

now the site works

>
> Alex.
>
>
>> On 11/3/22 16:05, Alex Rousskov wrote:
>>> On 11/3/22 05:43, Majed Zouhairy wrote:
>>>
>>>> i have 2 proxies, one with ssl bump and one without, there is a
>>>> internal site that opens only on the no ssl bump proxy.
>>>>
>>>> on the ssl bump proxy it displays:
>>>
>>>
>>> What does Squid say in access.log for this problematic request?
>>> Please configure Squid to log %err_code/%err_detail before answering
>>> this question. For example:
>>>
>>> logformat xsquid ...your regular %codes... %err_code/%err_detail
>>> access_log ... xsquid
>>>
>>>
>>>
>>> Does the site works if you temporary replace your ssl_bump rules with:
>>>
>>> ssl_bump peek all
>>> ssl_bump splice all
>>>
>>>
>>> Does the site works if you temporary replace your ssl_bump rules with:
>>>
>>> ssl_bump peek tls_s1_connect
>>> ssl_bump splice all
>>>
>>>
>>> Alex.
>>>
>>>
>>>
>>>
>>>> ?? ??????? ???????? ?????? ? ????????-???????? ?? ?????? (i was
>>>> unable to gain access to website:)
>>>> https://test-auth.ias.ckko.nl/oauth/authorize?response_type=code&client_id=agoh1xHNNwaLZ65uspARyhYj7V8GTWla&state=guest&authentication=usbtoken&redirect_uri=https%3A%2F%2Fais.skko.by%2Foauth2%2Fcallback, ????????, ???????? ?????????? ??? ????????? ?????????? ?? ?????? ??????. (it is possible that it can not bbe reached or it has been permanently relocated to a new address)
>>>> ERR_TUNNEL_CONNECTION_FAILED
>>>>
>>>> the site needs special configurations to run:
>>>> it needs a local proxy to run, avtunproxy.nl
>>>> in the internet explorer settings:
>>>> the second box in the proxy settings needs to be checked called the
>>>> "use the scenario for automatic configuration"
>>>> in it, the proxy address is plugged
>>>> http://127.0.0.1:10224/proxy.pac
>>>>
>>>> my bump settings are as follows:
>>>>
>>>>
>>>> acl     tls_s1_connect        at_step SslBump1
>>>> acl     tls_s2_client_hello     at_step SslBump2
>>>> acl     tls_s3_server_hello     at_step SslBump3
>>>>
>>>> # define acls for sites that must not be actively bumped
>>>>
>>>> acl     tls_allowed_hsts        ssl::server_name .akamaihd.net
>>>> acl     tls_allowed_hsts        ssl::server_name .proxy.ckko.nl
>>>> acl     tls_server_is_bank         ssl::server_name
>>>> "/usr/local/ufdbguard/blacklists/finance/domains.squidsplice"
>>>> acl     tls_to_splice     any-of     tls_allowed_hsts
>>>> tls_server_is_bank
>>>>
>>>> # TLS/SSL bumping steps
>>>>
>>>> ssl_bump         peek                tls_s1_connect         # peek
>>>> at TLS/SSL connect data
>>>> ssl_bump         splice                 tls_to_splice        #
>>>> splice some: no active bump
>>>> ssl_bump         stare                 all                    #
>>>> stare(peek) at server
>>>>                                                          #
>>>> properties of the webserver
>>>> ssl_bump         bump
>>>>
>>>> contents of the
>>>> /usr/local/ufdbguard/blacklists/finance/domains.squidsplice file:
>>>>
>>>> .ckko.nl
>>>> .ias.ckko.nl
>>>> .test-auth.ias.ckko.nl
>>>> .config.avtunproxy.nl
>>>> .rand.avtunproxy.nl
>>>> .avast.nl
>>>> .dev.avast.nl
>>>> .ncis.nl
>>>> .cdn.nlpost.nl
>>>>
>>>> those are all the sites that are logged in on the non ssl bump proxy
>>>> when ias.ckko.nl is accessed
>>>>
>>>> despite all this configuration, the site does not open. in ufdbguard
>>>> every site from the user is a pass.
>>>>
>>>> in avtunproxy log :
>>>>
>>>> 2022/11/03 12:22:17.087001 |INF| [UPDATER] [TrustFirmware] fetching
>>>> https://ckko.nl/upload/certificates/8.crl
>>>> 2022/11/03 12:28:34.634001 |ERR| [rid=ab7a9b1c9f39fb3e]
>>>> [addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>>> 2022/11/03 12:28:34.635001 |INF| [rid=ab7a9b1c9f39fb3e]
>>>> [addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] CONNECT
>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
>>>> 2022/11/03 12:28:34.663001 |ERR| [rid=47fba344ff078bcf]
>>>> [addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 -
>>>> read tcp 192.168.2.5:10527->10.0.0.18:8080: wsarecv: An existing
>>>> connection was forcibly closed by the remote host.
>>>> 2022/11/03 12:28:34.664001 |INF| [rid=47fba344ff078bcf]
>>>> [addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] CONNECT
>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 17.000000 ms
>>>> 2022/11/03 12:28:35.723001 |ERR| [rid=3f5ccf39ef0ae021]
>>>> [addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>>> 2022/11/03 12:28:35.723001 |INF| [rid=3f5ccf39ef0ae021]
>>>> [addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] CONNECT
>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
>>>> 2022/11/03 12:28:35.748001 |ERR| [rid=c48d84308d001f59]
>>>> [addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>>> 2022/11/03 12:28:35.748001 |INF| [rid=c48d84308d001f59]
>>>> [addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] CONNECT
>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 12.000000 ms
>>>> 2022/11/03 12:28:35.752001 |ERR| [rid=d181037283b2a34a]
>>>> [addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>>> 2022/11/03 12:28:35.752001 |INF| [rid=d181037283b2a34a]
>>>> [addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] CONNECT
>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 15.000000 ms
>>>> 2022/11/03 12:28:40.775001 |ERR| [rid=27f00eecdbe53178]
>>>> [addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 -
>>>> read tcp 192.168.2.5:10538->10.0.0.18:8080: wsarecv: An existing
>>>> connection was forcibly closed by the remote host.
>>>> 2022/11/03 12:28:40.775001 |INF| [rid=27f00eecdbe53178]
>>>> [addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] CONNECT
>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
>>>> 2022/11/03 12:28:40.815001 |ERR| [rid=79611bea389d7c9c]
>>>> [addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - EOF
>>>> 2022/11/03 12:28:40.816001 |INF| [rid=79611bea389d7c9c]
>>>> [addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] CONNECT
>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
>>>> 2022/11/03 12:28:42.188001 |INF| [rid=7a104242baf9a559]
>>>> [addr=127.0.0.1:10541] GET /static/jquery.js - HTTP 200 - OK
>>>> 2022/11/03 12:28:42.190001 |INF| [rid=27a7baff0fe5d70e]
>>>> [addr=127.0.0.1:10542] GET /static/bootstrap.js - HTTP 200 - OK
>>>> 2022/11/03 12:28:42.192001 |INF| [rid=dbddaaa3f7759903]
>>>> [addr=127.0.0.1:10459] GET /static/bootstrap.css - HTTP 200 - OK
>>>> 2022/11/03 12:28:42.287001 |INF| [rid=7e81e98ea9c70d3f]
>>>> [addr=127.0.0.1:10544] GET /api/v2/log
>>>>
>>>>
>>>> what is the solution?
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

Get the 13 Email Threat Types eBook

https://www.barracuda.com/

This e-mail and any attachments to it contain confidential and proprietary material of Barracuda, its affiliates or agents, and is solely for the use of the intended recipient. Any review, use, disclosure, distribution or copying of this transmittal is prohibited except by or on behalf of the intended recipient. If you have received this transmittal in error, please notify the sender and destroy this e-mail and any attachments and all copies, whether electronic or printed.

________________________________


From rousskov at measurement-factory.com  Fri Nov  4 12:46:39 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 4 Nov 2022 08:46:39 -0400
Subject: [squid-users] site opens only without ssl bump
In-Reply-To: <25b1c784-65a9-ff2c-9454-90b644e6307c@ckta.by>
References: <0aa508d5-033c-6f41-d751-ec9eee090dc3@ckta.by>
 <70311335-8ece-ca90-caea-b78ffeecc69e@measurement-factory.com>
 <827c218d-f5e6-3fdf-8b70-8e10cfd8eef2@ckta.by>
 <d9cd8023-1fbf-7306-431b-9a91f0c2a99f@measurement-factory.com>
 <25b1c784-65a9-ff2c-9454-90b644e6307c@ckta.by>
Message-ID: <3b8cea8a-a5cf-ee8a-914c-8bf4f76fe279@measurement-factory.com>

On 11/4/22 02:31, Majed Zouhairy wrote:
> with
> 
> logformat squidx %err_code/%err_detail
> access_log xsquid
> 
> squid stopped logging completely

Please try to follow the earlier sketch more closely: Keep your usual 
logformat codes while adding %err_code/%err_detail and keep your usual 
access_log destination when specifying the custom logformat name 
(xsquid). Use squid.conf.documented as a syntax reference for these 
directives. Always monitor cache.log (or equivalent) for important messages.


> with
> 
> ssl_bump splice all
> 
> now the site works

OK, so now we know that something breaks around SslBump step1. The next 
task is (still) getting %err_code/%err_detail working. If that is not 
enough, then you will also need to collect debugging logs.


HTH,

Alex.



>>> On 11/3/22 16:05, Alex Rousskov wrote:
>>>> On 11/3/22 05:43, Majed Zouhairy wrote:
>>>>
>>>>> i have 2 proxies, one with ssl bump and one without, there is a 
>>>>> internal site that opens only on the no ssl bump proxy.
>>>>>
>>>>> on the ssl bump proxy it displays:
>>>>
>>>>
>>>> What does Squid say in access.log for this problematic request? 
>>>> Please configure Squid to log %err_code/%err_detail before answering 
>>>> this question. For example:
>>>>
>>>> logformat xsquid ...your regular %codes... %err_code/%err_detail
>>>> access_log ... xsquid
>>>>
>>>>
>>>>
>>>> Does the site works if you temporary replace your ssl_bump rules with:
>>>>
>>>> ssl_bump peek all
>>>> ssl_bump splice all
>>>>
>>>>
>>>> Does the site works if you temporary replace your ssl_bump rules with:
>>>>
>>>> ssl_bump peek tls_s1_connect
>>>> ssl_bump splice all
>>>>
>>>>
>>>> Alex.
>>>>
>>>>
>>>>
>>>>
>>>>> ?? ??????? ???????? ?????? ? ????????-???????? ?? ?????? (i was 
>>>>> unable to gain access to website:) 
>>>>> https://test-auth.ias.ckko.nl/oauth/authorize?response_type=code&client_id=agoh1xHNNwaLZ65uspARyhYj7V8GTWla&state=guest&authentication=usbtoken&redirect_uri=https%3A%2F%2Fais.skko.by%2Foauth2%2Fcallback, 
>>>>> ????????, ???????? ?????????? ??? ????????? ?????????? ?? ?????? 
>>>>> ??????. (it is possible that it can not bbe reached or it has been 
>>>>> permanently relocated to a new address)
>>>>> ERR_TUNNEL_CONNECTION_FAILED
>>>>>
>>>>> the site needs special configurations to run:
>>>>> it needs a local proxy to run, avtunproxy.nl
>>>>> in the internet explorer settings:
>>>>> the second box in the proxy settings needs to be checked called the 
>>>>> "use the scenario for automatic configuration"
>>>>> in it, the proxy address is plugged
>>>>> http://127.0.0.1:10224/proxy.pac
>>>>>
>>>>> my bump settings are as follows:
>>>>>
>>>>>
>>>>> acl???? tls_s1_connect??????? at_step SslBump1
>>>>> acl???? tls_s2_client_hello???? at_step SslBump2
>>>>> acl???? tls_s3_server_hello???? at_step SslBump3
>>>>>
>>>>> # define acls for sites that must not be actively bumped
>>>>>
>>>>> acl???? tls_allowed_hsts??????? ssl::server_name .akamaihd.net
>>>>> acl???? tls_allowed_hsts??????? ssl::server_name .proxy.ckko.nl
>>>>> acl???? tls_server_is_bank???????? ssl::server_name 
>>>>> "/usr/local/ufdbguard/blacklists/finance/domains.squidsplice"
>>>>> acl???? tls_to_splice???? any-of???? tls_allowed_hsts 
>>>>> tls_server_is_bank
>>>>>
>>>>> # TLS/SSL bumping steps
>>>>>
>>>>> ssl_bump???????? peek??????????????? tls_s1_connect???????? # peek 
>>>>> at TLS/SSL connect data
>>>>> ssl_bump???????? splice???????????????? tls_to_splice??????? # 
>>>>> splice some: no active bump
>>>>> ssl_bump???????? stare???????????????? all??????????????????? # 
>>>>> stare(peek) at server
>>>>> ???????????????????????????????????????????????????????? # 
>>>>> properties of the webserver
>>>>> ssl_bump???????? bump
>>>>>
>>>>> contents of the 
>>>>> /usr/local/ufdbguard/blacklists/finance/domains.squidsplice file:
>>>>>
>>>>> .ckko.nl
>>>>> .ias.ckko.nl
>>>>> .test-auth.ias.ckko.nl
>>>>> .config.avtunproxy.nl
>>>>> .rand.avtunproxy.nl
>>>>> .avast.nl
>>>>> .dev.avast.nl
>>>>> .ncis.nl
>>>>> .cdn.nlpost.nl
>>>>>
>>>>> those are all the sites that are logged in on the non ssl bump 
>>>>> proxy when ias.ckko.nl is accessed
>>>>>
>>>>> despite all this configuration, the site does not open. in 
>>>>> ufdbguard every site from the user is a pass.
>>>>>
>>>>> in avtunproxy log :
>>>>>
>>>>> 2022/11/03 12:22:17.087001 |INF| [UPDATER] [TrustFirmware] fetching 
>>>>> https://ckko.nl/upload/certificates/8.crl
>>>>> 2022/11/03 12:28:34.634001 |ERR| [rid=ab7a9b1c9f39fb3e] 
>>>>> [addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - 
>>>>> EOF
>>>>> 2022/11/03 12:28:34.635001 |INF| [rid=ab7a9b1c9f39fb3e] 
>>>>> [addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
>>>>> 2022/11/03 12:28:34.663001 |ERR| [rid=47fba344ff078bcf] 
>>>>> [addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - 
>>>>> read tcp 192.168.2.5:10527->10.0.0.18:8080: wsarecv: An existing 
>>>>> connection was forcibly closed by the remote host.
>>>>> 2022/11/03 12:28:34.664001 |INF| [rid=47fba344ff078bcf] 
>>>>> [addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 17.000000 ms
>>>>> 2022/11/03 12:28:35.723001 |ERR| [rid=3f5ccf39ef0ae021] 
>>>>> [addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - 
>>>>> EOF
>>>>> 2022/11/03 12:28:35.723001 |INF| [rid=3f5ccf39ef0ae021] 
>>>>> [addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
>>>>> 2022/11/03 12:28:35.748001 |ERR| [rid=c48d84308d001f59] 
>>>>> [addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - 
>>>>> EOF
>>>>> 2022/11/03 12:28:35.748001 |INF| [rid=c48d84308d001f59] 
>>>>> [addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 12.000000 ms
>>>>> 2022/11/03 12:28:35.752001 |ERR| [rid=d181037283b2a34a] 
>>>>> [addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - 
>>>>> EOF
>>>>> 2022/11/03 12:28:35.752001 |INF| [rid=d181037283b2a34a] 
>>>>> [addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 15.000000 ms
>>>>> 2022/11/03 12:28:40.775001 |ERR| [rid=27f00eecdbe53178] 
>>>>> [addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - 
>>>>> read tcp 192.168.2.5:10538->10.0.0.18:8080: wsarecv: An existing 
>>>>> connection was forcibly closed by the remote host.
>>>>> 2022/11/03 12:28:40.775001 |INF| [rid=27f00eecdbe53178] 
>>>>> [addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
>>>>> 2022/11/03 12:28:40.815001 |ERR| [rid=79611bea389d7c9c] 
>>>>> [addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 - 
>>>>> EOF
>>>>> 2022/11/03 12:28:40.816001 |INF| [rid=79611bea389d7c9c] 
>>>>> [addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
>>>>> 2022/11/03 12:28:42.188001 |INF| [rid=7a104242baf9a559] 
>>>>> [addr=127.0.0.1:10541] GET /static/jquery.js - HTTP 200 - OK
>>>>> 2022/11/03 12:28:42.190001 |INF| [rid=27a7baff0fe5d70e] 
>>>>> [addr=127.0.0.1:10542] GET /static/bootstrap.js - HTTP 200 - OK
>>>>> 2022/11/03 12:28:42.192001 |INF| [rid=dbddaaa3f7759903] 
>>>>> [addr=127.0.0.1:10459] GET /static/bootstrap.css - HTTP 200 - OK
>>>>> 2022/11/03 12:28:42.287001 |INF| [rid=7e81e98ea9c70d3f] 
>>>>> [addr=127.0.0.1:10544] GET /api/v2/log
>>>>>
>>>>>
>>>>> what is the solution?
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Fri Nov  4 13:05:19 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 5 Nov 2022 02:05:19 +1300
Subject: [squid-users] Does Squid support client ssl termination?
In-Reply-To: <a580846c-5341-a3a9-9e71-e83d0181ca35@spamtrap.tnetconsulting.net>
References: <CAB-cPApGGo1zHR1hVdVUGGLnLA1Ciy3hF1J+9L3a6O1Ap=0r-A@mail.gmail.com>
 <f1a6b704-38c0-321b-486c-1dfa01ed5c3c@spamtrap.tnetconsulting.net>
 <CAB-cPAqzHKh=iLTOVMYGMuV0BX9JKE6gKWUDpFRV=FcUnRTETw@mail.gmail.com>
 <d2f323de-03eb-e828-11ad-fc310fccaad9@spamtrap.tnetconsulting.net>
 <CAB-cPArjyq_LpNs+ak8vMk4HJh5X5ce5=MPNwHBWULz7SC1juw@mail.gmail.com>
 <fe883d44-d086-e63a-1ff7-ead23d31ba6c@spamtrap.tnetconsulting.net>
 <9b11f08b20f9f7f4f4f4fad345161523@treenet.co.nz>
 <c7774050-684e-73fa-69eb-646770ba66a7@spamtrap.tnetconsulting.net>
 <4857700226b1763495385cfa23f2bc78@treenet.co.nz>
 <a580846c-5341-a3a9-9e71-e83d0181ca35@spamtrap.tnetconsulting.net>
Message-ID: <a39a2395-c924-2561-5fb8-6306fc16f970@treenet.co.nz>

On 3/11/2022 4:13 am, Grant Taylor wrote:
> On 11/1/22 4:17 PM, squid3 wrote:
>> Yes I was addressing mingheng's statement.
>
> Thank you for clarifying.
>
>> The first thing you need to do is avoid that "HTTPS" term. It has 
>> multiple meanings and they cause confusion. Instead decompose it into 
>> its TLS and HTTP layers.
>
> Largely okay.
>
> However, a minor nitpick:? TCP, TLS, and HTTP are three distinct things.
>
> TCP is the traditional transport.
> TLS is the optional presentation layer that rides on top of TCP.
> HTTP is the application layer protocol that's spoken between endpoints 
> which rides on top of TLS if present or TCP if TLS is not present.
>
> N.B. I'm eliding UDP / QUIC.
>

Aye, that is the terminology definitions of them. Which does not clearly 
convey the recursive layer/nesting properties. They way I suggested to 
think of TLS and HTTP as transfer layers helps clarify that property.

>> * A client can use TCP or TLS to connect to a proxy.
>> ??- this is configured with http_port vs https_port
>>
>> * Independently of the connection type the client can request http:// 
>> or https:// URLs or CONNECT tunnels.
>
> Do you have any recommendation of clarifying / consistent terms for 
> using to describe the connection between the client and the proxy with 
> the goal of differentiating it from the connection between the proxy 
> and the server?
>

The best I have found is the rule-of-thumb to avoid abbreviations that 
have multiple meanings and use simple nouns that the reader understands 
already to build a compound noun that they can comprehend. As such you 
will find my wording varies between discussions, and can adjust as I 
learn what terms the others understand already.

> I'll argue, but be open to arguments to the contrary, that both 
> connections are using the HTTP application layer protocol on top of 
> whatever transport is being used; TCP or TCP+TLS.

To Squid the transport is (almost) always TCP. Whether TLS is treated as 
transport layer or application layer depends on the Squid features (eg 
SSL-Bump).

So for your purpose of understanding the possibilities it is best to 
think of it as just another transfer protocol that Squid can receive 
like HTTP. Which can either transfer opaque client information, or 
another type of transfer protocols "nested" inside it.

>> * Independent of what the client is doing/requesting, a cache_peer 
>> may be connected to using TCP or TLS.
>> ??- this is configured with cache_peer tls options (or their absence)
>>
>> * Independent of anything else, a cache_peer MAY be asked to open a 
>> CONNECT tunnel for opaque uses.
>> ??- this is automatically decided by Squid based on various criteria.
>
> Oy vey!
>
> I had forgotten about using HTTP's CONNECT to carry non-HTTP traffic.
>
>> TCP is the foundation layer. On top of that can be HTTP transfer or 
>> TLS transfer. Transfer layers can be nested infinitely deep in any 
>> order.
>
> I'm avoiding -- what I've seen referenced as -- "chaining" for this 
> discussion.
>

Oh, I see (I think). I use nesting or layering (from OSI model 
terminology) because "chain" is used by HTTP in the definition of how 
traffic is routed between multiple agents. For example; 
client->squid->server is a chain.

> I'm focusing on the what traditional web browsers / clients support 
> out of the box; client-to-proxy and proxy-to-server.
>

Browsers are origin-client software. They deal with these layers:
 ?* HTTP (http:// to origin, or http:// to traditional plain-text 
forward-proxy), or
 ?* HTTP-over-TLS (https:// to origin), or
 ?* HTTP-over-TLS-over-HTTP (traditional https:// to plain-text 
forward-proxy).

Recently some started handling HTTP-over-TLS-over-HTTP-over-TLS - which 
is traditional https:// to an secure/encrypted forward-proxy.




> After all, even when chaining is in scope, the chained / down stream 
> proxy is really functioning as the server that the first / upstream 
> proxy connects to.? Thus it's really higher layer traffic as far as 
> the first / upstream proxy is concerned.

There you are running into the ambiguity of "chain". Using both its 
meanings in one sentence.


>
>> So "HTTPS" can mean any one of things like:
>> ??1) HTTP-over-TLS (how Browsers handle https:// URLs)
>> ??2) HTTP-over-TLS (sending http:// URLs over a secure connection)
>> ??3) HTTP-over-TLS-over-TLS (relay (1) through a secure cache_peer)
>> ??4) HTTP-over-TLS-over-HTTP (relay (1), (2) or (3) through an 
>> insecure cache_peer via CONNECT tunnel)
>
> Hence my question about nomenclature.
>
> ...really big snip...
>
>> Vaguely yes. There are three dimensions to the matrix, you only have 
>> two shown here.
>
> Please elaborate.? I'm not following what the 3rd dimension would be 
> with the small amount of coffee that I've had.
>

The three dimensions in play are:
 ?1) protocol X being spoken between client and Squid
 ?2) protocol Y the client is requesting to use with the origin server
 ?3) protocol Z actually being spoken between Squid and next-hop peer/server

protocol Z *could* be the same protocol the client requested, OR it 
could be a CONNECT tunnel (plain-text HTTP) to the origin server.


Amos


From squid3 at treenet.co.nz  Sat Nov  5 00:01:08 2022
From: squid3 at treenet.co.nz (=?UTF-8?B?4oCqQW1vcyBKZWZmcmllc+KArA==?=)
Date: Sat, 05 Nov 2022 13:01:08 +1300
Subject: [squid-users] Globally new in Squid since 2012
References: <170666827.20221104142306@gmx.com>
Message-ID: <-g8g26u-eyj35xpervu0-aq08br-4ezgxa11a1sfsvfvuoovg4v61o5z5vqv7wzipj32hgmoy20fm9wf8j-4jpzfmo0ihw3wdsufye864f-k443yy-ucwb8g-i3d3q8em3sea-pmz9g9-jr8s3b-r1nlo0.1667605925843@email.android.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221105/3303b9a0/attachment.htm>

From gtaylor at tnetconsulting.net  Sat Nov  5 05:59:08 2022
From: gtaylor at tnetconsulting.net (Grant Taylor)
Date: Fri, 4 Nov 2022 23:59:08 -0600
Subject: [squid-users] Does Squid support client ssl termination?
In-Reply-To: <a39a2395-c924-2561-5fb8-6306fc16f970@treenet.co.nz>
References: <CAB-cPApGGo1zHR1hVdVUGGLnLA1Ciy3hF1J+9L3a6O1Ap=0r-A@mail.gmail.com>
 <f1a6b704-38c0-321b-486c-1dfa01ed5c3c@spamtrap.tnetconsulting.net>
 <CAB-cPAqzHKh=iLTOVMYGMuV0BX9JKE6gKWUDpFRV=FcUnRTETw@mail.gmail.com>
 <d2f323de-03eb-e828-11ad-fc310fccaad9@spamtrap.tnetconsulting.net>
 <CAB-cPArjyq_LpNs+ak8vMk4HJh5X5ce5=MPNwHBWULz7SC1juw@mail.gmail.com>
 <fe883d44-d086-e63a-1ff7-ead23d31ba6c@spamtrap.tnetconsulting.net>
 <9b11f08b20f9f7f4f4f4fad345161523@treenet.co.nz>
 <c7774050-684e-73fa-69eb-646770ba66a7@spamtrap.tnetconsulting.net>
 <4857700226b1763495385cfa23f2bc78@treenet.co.nz>
 <a580846c-5341-a3a9-9e71-e83d0181ca35@spamtrap.tnetconsulting.net>
 <a39a2395-c924-2561-5fb8-6306fc16f970@treenet.co.nz>
Message-ID: <35d26595-2d5d-a353-28c4-36d422d74a42@spamtrap.tnetconsulting.net>

On 11/4/22 7:05 AM, Amos Jeffries wrote:
> Aye, that is the terminology definitions of them. Which does not clearly 
> convey the recursive layer/nesting properties. They way I suggested to 
> think of TLS and HTTP as transfer layers helps clarify that property.

I will concede "differentiate", but I don't agree that it "clarifies".

> The best I have found is the rule-of-thumb to avoid abbreviations that 
> have multiple meanings and use simple nouns that the reader understands 
> already to build a compound noun that they can comprehend. As such you 
> will find my wording varies between discussions, and can adjust as I 
> learn what terms the others understand already.

Okay....

How would you describe the following in a green field discussion to 
someone without any prior context to suggest nomenclature?

Client uses an explicit proxy connection with TLS encryption to ask the 
proxy to request a TLS encrypted web page on the client's behalf.

> To Squid the transport is (almost) always TCP. Whether TLS is treated as 
> transport layer or application layer depends on the Squid features (eg 
> SSL-Bump).

Eh....  This isn't a photon, it's can't be both a wave and a particle. 
I feel like it's really one thing and what Squid does with it may be 
different based on if Squid is SSL-Bumping or not.  After all, it's both 
are exactly the same thing to the client, independent of if Squid is 
SSL-Bumping or not.

> So for your purpose of understanding the possibilities it is best to 
> think of it as just another transfer protocol that Squid can receive 
> like HTTP. Which can either transfer opaque client information, or 
> another type of transfer protocols "nested" inside it.

Hum.  So if I understand you correctly, this could be HTTP application 
layer protocol on top of an unencrypted TCP transport /or/ on top of an 
encrypted TCP+TLS transport?

> Oh, I see (I think). I use nesting or layering (from OSI model 
> terminology) because "chain" is used by HTTP in the definition of how 
> traffic is routed between multiple agents. For example; 
> client->squid->server is a chain.

I don't consider client -> squid -> origin to be a chain of proxies.

I do consider client -> squid -> $SOME_OTHER_PROXY -> origin to be a 
chain of proxies.

To me for it to be a chain of proxies, there must be multiple proxies 
involved.

N.B. maybe this is somewhat a problem of nomenclature.  Hence why I have 
explicitly typed out "chain /of/ /proxies/" here.

By the very nature of how proxies work, even for the simplest method of 
an unencrypted TCP transport from client to proxy and then an 
unencrypted TCP transport from the proxy to the origin server, there are 
three parties involved; client, proxy, and origin server.

What's more is that this three party system is baked into many 
contemporary clients.  Conversely, almost everything needs an extremely 
special configuration to add, or chain, an additional intermediate proxy 
in the middle.  Hence why I think that "proxy chaining" is very special. 
  --  After I type that, the nomenclature "/proxy/ chaining" even 
supports that there are multiple proxies.

N.B. "origin server" may be a misnomer as from the client's and Squid's 
point of view, it may not be an origin server and may in fact be an 
additional layer of reverse proxying unbeknownst to the client nor Squid.

> Browsers are origin-client software. They deal with these layers:
>  ?* HTTP (http:// to origin, or http:// to traditional plain-text 
> forward-proxy), or

I believe that's really two different things in an explicitly configured 
proxy use case, because what the client will do is subtly, but 
distinctly different and that difference is important.

>  ?* HTTP-over-TLS (https:// to origin), or
>  ?* HTTP-over-TLS-over-HTTP (traditional https:// to plain-text 
> forward-proxy).
> 
> Recently some started handling HTTP-over-TLS-over-HTTP-over-TLS - which 
> is traditional https:// to an secure/encrypted forward-proxy.

Maybe it's just me, but I don't know that I could extract what is 
happening, without a lot of thought, from these descriptions.

  - HTTP-over-TCP
  - HTTP-over-TLS
  - HTTP-over-TCP-over-HTTP-over-TCP
  - HTTP-over-TLS-over-HTTP-over-TCP
  - HTTP-over-TCP-over-HTTP-over-TLS
  - HTTP-over-TLS-over-HTTP-over-TLS

I don't see a good clean / uniform cut / divide for determining what is 
what, client to origin, client to proxy, or proxy to origin.

> There you are running into the ambiguity of "chain". Using both its 
> meanings in one sentence.

I don't think so.  See above.

I'm fairly certain of what I think to be a proxy chain.  It seems as if 
you are also fairly certain of what you think to be a proxy chain.  But 
it seems like we may be using different definitions of what is a proxy 
chain.

> The three dimensions in play are:
>  ?1) protocol X being spoken between client and Squid
>  ?2) protocol Y the client is requesting to use with the origin server
>  ?3) protocol Z actually being spoken between Squid and next-hop 
> peer/server

Ah.  You're introducing -- what I consider to be -- proxy chaining into 
the mix.

I thought you were instead going to introduce implicit vs explicit 
client configuration.

As indicated elsewhere, I consider proxy chaining to be largely out of 
scope as the (1st) proxy server can't really differentiate between the 
the target of it's traffic being an origin server vs another (2nd) proxy 
server.  This is especially true when TLS encryption is in use and 
SSL-Bump is not in play.



-- 
Grant. . . .
unix || die

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4017 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221104/186df1cf/attachment.bin>

From mohsen at pahlevanzadeh.net  Sat Nov  5 06:46:14 2022
From: mohsen at pahlevanzadeh.net (Mohsen Pahlevanzadeh)
Date: Sat, 5 Nov 2022 10:16:14 +0330
Subject: [squid-users] Redirect traffic
In-Reply-To: <cc092c6e-bafe-69b1-1016-01805041a712@treenet.co.nz>
References: <c3b482f9-fe9a-f1af-ee8d-459c7b929955@pahlevanzadeh.net>
 <cc092c6e-bafe-69b1-1016-01805041a712@treenet.co.nz>
Message-ID: <ecebd630-ef8b-ade8-85e0-3ef1e4c303f7@pahlevanzadeh.net>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221105/29ddf877/attachment.htm>

From squid3 at treenet.co.nz  Sun Nov  6 03:48:43 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 6 Nov 2022 16:48:43 +1300
Subject: [squid-users] Redirect traffic
In-Reply-To: <ecebd630-ef8b-ade8-85e0-3ef1e4c303f7@pahlevanzadeh.net>
References: <c3b482f9-fe9a-f1af-ee8d-459c7b929955@pahlevanzadeh.net>
 <cc092c6e-bafe-69b1-1016-01805041a712@treenet.co.nz>
 <ecebd630-ef8b-ade8-85e0-3ef1e4c303f7@pahlevanzadeh.net>
Message-ID: <297157bb-8827-949f-0eef-d2d77dd0bec2@treenet.co.nz>

On 5/11/2022 7:46 pm, Mohsen Pahlevanzadeh wrote:
>
> I created a squid.conf via default config file from your recommendation.
>

Please show what you came up with.

> When I try via telnet google.com 443 , It's ok, but when I want to 
> receive data from browser I get the following error:
>
>

FYI telnet is plain-text protocol. Port 443 is supposed to be encrypted. 
The behaviour you describe appears to be broken.

> Secure Connection Failed
>
> An error occurred during a connection to www.google.com.
>

What is going on with Squid in all of this testing directly connecting 
to google on port 443 ?

Amos



From admin at sneakerspace.co.uk  Tue Nov  8 06:39:59 2022
From: admin at sneakerspace.co.uk (Sneaker Space LTD)
Date: Tue, 8 Nov 2022 06:39:59 +0000
Subject: [squid-users] Squid Dual HTTP & SOCKS Set-Up
Message-ID: <CAGzU65oL47JgW5V-b=EJKFhJ1_Tf6JgdOY1hxQ1spkWLg=o5NA@mail.gmail.com>

Hello everyone,

Can anyone recommend a good setup for a dual HTTP and SOCKS proxy
configuration?

I want to obviously use Squid as the HTTP proxy and I also see that it may
support SOCKS with the correct install binds, however, from my research,
this would likely mean that I need to run two separate processes at the
same time (Squid HTTP and Squid SOCKS) since apparently, SOCKS Squid can't
handle both connections types at the same time.

I am wondering if there is any better solution to this? And if not, can
these processes run off the same configuration, and will the SOCKS Squid
process have the differences i.e is authentication, and logging the same?

Any insight is appreciated here as I am unfamiliar with this kind of set-up
and there isn't much documentation online about it.

Many Thanks,
James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221108/53bc6c4d/attachment.htm>

From m_zouhairy at ckta.by  Wed Nov  9 14:12:28 2022
From: m_zouhairy at ckta.by (Majed Zouhairy)
Date: Wed, 9 Nov 2022 17:12:28 +0300
Subject: [squid-users] site opens only without ssl bump
In-Reply-To: <3b8cea8a-a5cf-ee8a-914c-8bf4f76fe279@measurement-factory.com>
References: <0aa508d5-033c-6f41-d751-ec9eee090dc3@ckta.by>
 <70311335-8ece-ca90-caea-b78ffeecc69e@measurement-factory.com>
 <827c218d-f5e6-3fdf-8b70-8e10cfd8eef2@ckta.by>
 <d9cd8023-1fbf-7306-431b-9a91f0c2a99f@measurement-factory.com>
 <25b1c784-65a9-ff2c-9454-90b644e6307c@ckta.by>
 <3b8cea8a-a5cf-ee8a-914c-8bf4f76fe279@measurement-factory.com>
Message-ID: <9b9437bf-1c6b-3fd9-146f-715a8a31ad9e@ckta.by>

Peace,

On 11/4/22 15:46, Alex Rousskov wrote:
> On 11/4/22 02:31, Majed Zouhairy wrote:
>> with
>>
>> logformat squidx %err_code/%err_detail
>> access_log xsquid
>>
>> squid stopped logging completely
> 
> Please try to follow the earlier sketch more closely: Keep your usual 
> logformat codes while adding %err_code/%err_detail and keep your usual 
> access_log destination when specifying the custom logformat name 
> (xsquid). Use squid.conf.documented as a syntax reference for these 
> directives. Always monitor cache.log (or equivalent) for important 
> messages.

I think i am becoming Biden, i read the squid documented and didn't get 
it, am i supposed to substitute %err_code/%err_detail with something 
like [http:]>%h for example?
here is what cache.log displayed when i changed config to:

logformat squidx %err_code/%err_detail
access_log daemon:/var/log/squid/accessX.log squidx

acces.log stopped working and again cache.log displayed:

2022/11/09 16:58:36| SendEcho ERROR: sending to ICMPv6 packet to 
[2a00:1450:4010:c02::5f]: (101) Network is unreachable
2022/11/09 16:58:40| SendEcho ERROR: sending to ICMPv6 packet to 
[2a00:1450:4010:c0e::c6]: (101) Network is unreachable
2022/11/09 16:58:48| SendEcho ERROR: sending to ICMPv6 packet to 
[2a00:1450:4010:c0d::66]: (101) Network is unreachable
2022/11/09 16:58:58| SendEcho ERROR: sending to ICMPv6 packet to 
[2a00:1148:db00:0:b0b0::1]: (101) Network is unreachable
2022/11/09 16:59:29 kid1| Preparing for shutdown after 593 requests
2022/11/09 16:59:29 kid1| Waiting 30 seconds for active connections to 
finish
2022/11/09 16:59:29 kid1| Killing master process, pid 22616
2022/11/09 16:59:29 kid1| Closing HTTP(S) port [::]:8080
2022/11/09 16:59:29 kid1| Closing Pinger socket on FD 46
2022/11/09 16:59:29 kid1| Preparing for shutdown after 593 requests
2022/11/09 16:59:29 kid1| Waiting 30 seconds for active connections to 
finish
2022/11/09 16:59:29 kid1| WARNING: sslcrtd_program #Hlpr1 exited
     current master transaction: master85
2022/11/09 16:59:29 kid1| Too few sslcrtd_program processes are running 
(need 1/32)
     current master transaction: master85
2022/11/09 16:59:29 kid1| Starting new helpers
     current master transaction: master85
2022/11/09 16:59:29 kid1| helperOpenServers: Starting 1/32 
'security_file_certgen' processes
     current master transaction: master85
2022/11/09 16:59:29 kid1| WARNING: sslcrtd_program #Hlpr3 exited
2022/11/09 16:59:29 kid1| Too few sslcrtd_program processes are running 
(need 1/32)
2022/11/09 16:59:29 kid1| storeDirWriteCleanLogs: Starting...
2022/11/09 16:59:29 kid1|     65536 entries written so far.
2022/11/09 16:59:29 kid1|   Finished.  Wrote 90620 entries.
2022/11/09 16:59:29 kid1|   Took 0.10 seconds (914392.96 entries/sec).
2022/11/09 16:59:29 kid1| FATAL: The sslcrtd_program helpers are 
crashing too rapidly, need help!


> 
>> with
>>
>> ssl_bump splice all
>>
>> now the site works
> 
> OK, so now we know that something breaks around SslBump step1. The next 
> task is (still) getting %err_code/%err_detail working. If that is not 
> enough, then you will also need to collect debugging logs.
> 
> 
> HTH,
> 
> Alex.
> 
> 
> 
>>>> On 11/3/22 16:05, Alex Rousskov wrote:
>>>>> On 11/3/22 05:43, Majed Zouhairy wrote:
>>>>>
>>>>>> i have 2 proxies, one with ssl bump and one without, there is a 
>>>>>> internal site that opens only on the no ssl bump proxy.
>>>>>>
>>>>>> on the ssl bump proxy it displays:
>>>>>
>>>>>
>>>>> What does Squid say in access.log for this problematic request? 
>>>>> Please configure Squid to log %err_code/%err_detail before 
>>>>> answering this question. For example:
>>>>>
>>>>> logformat xsquid ...your regular %codes... %err_code/%err_detail
>>>>> access_log ... xsquid
>>>>>
>>>>>
>>>>>
>>>>> Does the site works if you temporary replace your ssl_bump rules with:
>>>>>
>>>>> ssl_bump peek all
>>>>> ssl_bump splice all
>>>>>
>>>>>
>>>>> Does the site works if you temporary replace your ssl_bump rules with:
>>>>>
>>>>> ssl_bump peek tls_s1_connect
>>>>> ssl_bump splice all
>>>>>
>>>>>
>>>>> Alex.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>> ?? ??????? ???????? ?????? ? ????????-???????? ?? ?????? (i was 
>>>>>> unable to gain access to website:) 
>>>>>> https://test-auth.ias.ckko.nl/oauth/authorize?response_type=code&client_id=agoh1xHNNwaLZ65uspARyhYj7V8GTWla&state=guest&authentication=usbtoken&redirect_uri=https%3A%2F%2Fais.skko.by%2Foauth2%2Fcallback, ????????, ???????? ?????????? ??? ????????? ?????????? ?? ?????? ??????. (it is possible that it can not bbe reached or it has been permanently relocated to a new address)
>>>>>> ERR_TUNNEL_CONNECTION_FAILED
>>>>>>
>>>>>> the site needs special configurations to run:
>>>>>> it needs a local proxy to run, avtunproxy.nl
>>>>>> in the internet explorer settings:
>>>>>> the second box in the proxy settings needs to be checked called 
>>>>>> the "use the scenario for automatic configuration"
>>>>>> in it, the proxy address is plugged
>>>>>> http://127.0.0.1:10224/proxy.pac
>>>>>>
>>>>>> my bump settings are as follows:
>>>>>>
>>>>>>
>>>>>> acl???? tls_s1_connect??????? at_step SslBump1
>>>>>> acl???? tls_s2_client_hello???? at_step SslBump2
>>>>>> acl???? tls_s3_server_hello???? at_step SslBump3
>>>>>>
>>>>>> # define acls for sites that must not be actively bumped
>>>>>>
>>>>>> acl???? tls_allowed_hsts??????? ssl::server_name .akamaihd.net
>>>>>> acl???? tls_allowed_hsts??????? ssl::server_name .proxy.ckko.nl
>>>>>> acl???? tls_server_is_bank???????? ssl::server_name 
>>>>>> "/usr/local/ufdbguard/blacklists/finance/domains.squidsplice"
>>>>>> acl???? tls_to_splice???? any-of???? tls_allowed_hsts 
>>>>>> tls_server_is_bank
>>>>>>
>>>>>> # TLS/SSL bumping steps
>>>>>>
>>>>>> ssl_bump???????? peek??????????????? tls_s1_connect???????? # peek 
>>>>>> at TLS/SSL connect data
>>>>>> ssl_bump???????? splice???????????????? tls_to_splice??????? # 
>>>>>> splice some: no active bump
>>>>>> ssl_bump???????? stare???????????????? all??????????????????? # 
>>>>>> stare(peek) at server
>>>>>> ???????????????????????????????????????????????????????? # 
>>>>>> properties of the webserver
>>>>>> ssl_bump???????? bump
>>>>>>
>>>>>> contents of the 
>>>>>> /usr/local/ufdbguard/blacklists/finance/domains.squidsplice file:
>>>>>>
>>>>>> .ckko.nl
>>>>>> .ias.ckko.nl
>>>>>> .test-auth.ias.ckko.nl
>>>>>> .config.avtunproxy.nl
>>>>>> .rand.avtunproxy.nl
>>>>>> .avast.nl
>>>>>> .dev.avast.nl
>>>>>> .ncis.nl
>>>>>> .cdn.nlpost.nl
>>>>>>
>>>>>> those are all the sites that are logged in on the non ssl bump 
>>>>>> proxy when ias.ckko.nl is accessed
>>>>>>
>>>>>> despite all this configuration, the site does not open. in 
>>>>>> ufdbguard every site from the user is a pass.
>>>>>>
>>>>>> in avtunproxy log :
>>>>>>
>>>>>> 2022/11/03 12:22:17.087001 |INF| [UPDATER] [TrustFirmware] 
>>>>>> fetching https://ckko.nl/upload/certificates/8.crl
>>>>>> 2022/11/03 12:28:34.634001 |ERR| [rid=ab7a9b1c9f39fb3e] 
>>>>>> [addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 
>>>>>> - EOF
>>>>>> 2022/11/03 12:28:34.635001 |INF| [rid=ab7a9b1c9f39fb3e] 
>>>>>> [addr=127.0.0.1:10523] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
>>>>>> 2022/11/03 12:28:34.663001 |ERR| [rid=47fba344ff078bcf] 
>>>>>> [addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 
>>>>>> - read tcp 192.168.2.5:10527->10.0.0.18:8080: wsarecv: An existing 
>>>>>> connection was forcibly closed by the remote host.
>>>>>> 2022/11/03 12:28:34.664001 |INF| [rid=47fba344ff078bcf] 
>>>>>> [addr=127.0.0.1:10526] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 17.000000 ms
>>>>>> 2022/11/03 12:28:35.723001 |ERR| [rid=3f5ccf39ef0ae021] 
>>>>>> [addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 
>>>>>> - EOF
>>>>>> 2022/11/03 12:28:35.723001 |INF| [rid=3f5ccf39ef0ae021] 
>>>>>> [addr=127.0.0.1:10529] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
>>>>>> 2022/11/03 12:28:35.748001 |ERR| [rid=c48d84308d001f59] 
>>>>>> [addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 
>>>>>> - EOF
>>>>>> 2022/11/03 12:28:35.748001 |INF| [rid=c48d84308d001f59] 
>>>>>> [addr=127.0.0.1:10531] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 12.000000 ms
>>>>>> 2022/11/03 12:28:35.752001 |ERR| [rid=d181037283b2a34a] 
>>>>>> [addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 
>>>>>> - EOF
>>>>>> 2022/11/03 12:28:35.752001 |INF| [rid=d181037283b2a34a] 
>>>>>> [addr=127.0.0.1:10532] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 15.000000 ms
>>>>>> 2022/11/03 12:28:40.775001 |ERR| [rid=27f00eecdbe53178] 
>>>>>> [addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 
>>>>>> - read tcp 192.168.2.5:10538->10.0.0.18:8080: wsarecv: An existing 
>>>>>> connection was forcibly closed by the remote host.
>>>>>> 2022/11/03 12:28:40.775001 |INF| [rid=27f00eecdbe53178] 
>>>>>> [addr=127.0.0.1:10537] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 19.000000 ms
>>>>>> 2022/11/03 12:28:40.815001 |ERR| [rid=79611bea389d7c9c] 
>>>>>> [addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] HTTP 500 
>>>>>> - EOF
>>>>>> 2022/11/03 12:28:40.816001 |INF| [rid=79611bea389d7c9c] 
>>>>>> [addr=127.0.0.1:10539] [PROXY parent=proxy.ckko.nl:8080] CONNECT 
>>>>>> test-oauth.ais.ckko.nl:443 -- 500 -- 14.000000 ms
>>>>>> 2022/11/03 12:28:42.188001 |INF| [rid=7a104242baf9a559] 
>>>>>> [addr=127.0.0.1:10541] GET /static/jquery.js - HTTP 200 - OK
>>>>>> 2022/11/03 12:28:42.190001 |INF| [rid=27a7baff0fe5d70e] 
>>>>>> [addr=127.0.0.1:10542] GET /static/bootstrap.js - HTTP 200 - OK
>>>>>> 2022/11/03 12:28:42.192001 |INF| [rid=dbddaaa3f7759903] 
>>>>>> [addr=127.0.0.1:10459] GET /static/bootstrap.css - HTTP 200 - OK
>>>>>> 2022/11/03 12:28:42.287001 |INF| [rid=7e81e98ea9c70d3f] 
>>>>>> [addr=127.0.0.1:10544] GET /api/v2/log
>>>>>>
>>>>>>
>>>>>> what is the solution?
>>>>>> _______________________________________________
>>>>>> squid-users mailing list
>>>>>> squid-users at lists.squid-cache.org
>>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From bfriconneau at stemarie-aizenay.fr  Wed Nov  9 15:50:05 2022
From: bfriconneau at stemarie-aizenay.fr (Bertrand Friconneau)
Date: Wed, 9 Nov 2022 16:50:05 +0100
Subject: [squid-users] Update from Squid 4 to Squid 5 :
Message-ID: <ff318d21-5e79-aabb-2dc8-7024b94c64b2@stemarie-aizenay.fr>

Hi Everyone,

I've got Squid 4.10 on Ubuntu 20.10 LTS

I try to upgrade my server to Ubuntu 22.04 LTS

But the users couldn't get internet no more.

Here is the log in /var/log/squid/access.log :
1668004454.050????? 0 172.22.200.1 TCP_DENIED/407 3951 CONNECT 
drive.google.com:443 - HIER_NONE/- text/html
1668004454.052????? 0 172.22.200.1 TCP_DENIED/407 3951 CONNECT 
drive.google.com:443 - HIER_NONE/- text/html
1668004454.057????? 0 172.22.200.1 TCP_DENIED/407 3951 CONNECT 
drive.google.com:443 - HIER_NONE/- text/html
1668004454.063????? 1 172.22.200.1 TCP_DENIED/407 4454 CONNECT 
drive.google.com:443 - HIER_NONE/- text/html
1668004454.076???? 10 172.22.200.1 NONE_NONE/500 0 CONNECT 
drive.google.com:443 infoe HIER_NONE/- -

And on the client :
ERR_TUNNEL_CONNECTION_FAILED

According to this page : 
https://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm
The cause is due to challenge-response process of NTLM

How can I solve it ?

Regards

Bertrand Friconneau


-------------------------------------------------------------------------------------------------------------------------------------------------------
Here is my config file of squid :

dns_v4_first on
visible_hostname squid

error_directory /usr/share/squid/errors/French

cache_dir ufs /data/squid/spool 5000 16 256
#cache_mem 256 MB
cache_mem 512 MB
coredump_dir /data/squid/spool
cache_store_log none

auth_param ntlm program /usr/bin/ntlm_auth 
--helper-protocol=squid-2.5-ntlmssp

auth_param ntlm children 250

auth_param ntlm keep_alive off

acl sitebypass dstdomain 
"/var/lib/squidguard/db/exception/bypassite/bypassite.url"
acl tor dst "/etc/squid/tor"

acl administrationzone src 172.21.0.0/16
acl informatiquezone src 172.28.0.0/16
acl secuzone src 172.18.0.0/16
acl srvzone src 172.20.0.0/16
acl url_exe url_regex -i \.[Mm][Ss][Ii]$ \.[Dd][Ll][Ll]$
acl ntlm proxy_auth REQUIRED


acl SSL_ports port 443
acl Safe_ports port 80??? ??? # http
acl Safe_ports port 21??? ??? # ftp
acl Safe_ports port 443??? ??? # https
acl Safe_ports port 70??? ??? # gopher
acl Safe_ports port 210??? ??? # wais
acl Safe_ports port 1025-65535??? # unregistered ports
acl Safe_ports port 280??? ??? # http-mgmt
acl Safe_ports port 488??? ??? # gss-http
acl Safe_ports port 591??? ??? # filemaker
acl Safe_ports port 777??? ??? # multiling http
acl CONNECT method CONNECT

http_access allow sitebypass
http_access deny tor
http_access deny url_exe
http_access allow administrationzone
#http_access allow pedagozone
#http_access allow xibozone
http_access allow informatiquezone
http_access allow secuzone
http_access allow srvzone
http_access allow ntlm

http_access deny !Safe_ports

http_access deny CONNECT !SSL_ports

http_access allow localhost manager
http_access deny manager

http_access allow localhost

http_access deny all
http_port 8080

url_rewrite_program /usr/bin/squidGuard -P -c 
/etc/squidguard/squidGuard.conf

url_rewrite_children 75

coredump_dir /var/spool/squid
refresh_pattern ^gopher:??? 1440??? 0%??? 1440
refresh_pattern -i (/cgi-bin/|\?) 0??? 0%??? 0
refresh_pattern (Release|Packages(.gz)*)$????? 0?????? 20%???? 2880
refresh_pattern .??? ??? 0??? 20%??? 4320

max_filedescriptors 65536

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Here is my config file of samba :

[global]
 ?? workgroup = STEMARIEAIZENAY
 ?? security = ADS
 ?? realm = STEMARIE-AIZENAY.LOCAL
 ?? encrypt passwords = yes
 ?? winbind separator = +
 ?? idmap config *:backend = tdb
 ?? idmap config *:range = 70001-80000
 ?? idmap config STEMARIEAIZENAY:backend? = rid
 ?? idmap config STEMARIEAIZENAY:range? = 10000-70000
 ?? winbind enum users = yes
 ?? winbind enum groups = yes
 ?? vfs objects = acl_xattr
 ?? map acl inherit = Yes
 ?? store dos attributes = Yes
 ?? winbind use default domain = yes
 ?? template homedir = /home/homes/%U

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Here is the krb5.conf file :

[libdefaults]
 ??? default_realm = STEMARIE-AIZENAY.LOCAL
 ??? dns_lookup_kdc = no
 ??? dns_lookup_realm = no
 ??? #ticket_lifetime = 24h
 ??? default_keytab_name = /etc/squid/PROXY.keytab

; for Windows 2003
 ??? default_tgs_enctypes = rc4-hmac des-cbc-crc des-cbc-md5
 ??? default_tkt_enctypes = rc4-hmac des-cbc-crc des-cbc-md5
 ??? permitted_enctypes = rc4-hmac des-cbc-crc des-cbc-md5

; for Windows 2008 with AES
;??? default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc 
des-cbc-md5
;??? default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc 
des-cbc-md5
;??? permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc 
des-cbc-md5

[realms]
 ??? STEMARIE-AIZENAY.LOCAL = {
 ??????? kdc = srv-ad.stemarie-aizenay.local
 ??????? admin_server = srv-ad.stemarie-aizenay.local
 ??????? default_domain = stemarie-aizenay.local
 ??? }

[domain_realm]
 ??? .stemarie-aizenay.local = STEMARIE-AIZENAY.LOCAL
 ??? stemarie-aizenay.local = STEMARIE-AIZENAY.LOCAL


From squid3 at treenet.co.nz  Thu Nov 10 13:10:16 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 11 Nov 2022 02:10:16 +1300
Subject: [squid-users] Update from Squid 4 to Squid 5 :
In-Reply-To: <ff318d21-5e79-aabb-2dc8-7024b94c64b2@stemarie-aizenay.fr>
References: <ff318d21-5e79-aabb-2dc8-7024b94c64b2@stemarie-aizenay.fr>
Message-ID: <56ec5a8c-a171-26bd-6c55-36e75561d971@treenet.co.nz>

On 10/11/2022 4:50 am, Bertrand Friconneau wrote:
> Hi Everyone,
>
> I've got Squid 4.10 on Ubuntu 20.10 LTS
>
> I try to upgrade my server to Ubuntu 22.04 LTS
>
> But the users couldn't get internet no more.
>
> Here is the log in /var/log/squid/access.log :
> 1668004454.050????? 0 172.22.200.1 TCP_DENIED/407 3951 CONNECT 
> drive.google.com:443 - HIER_NONE/- text/html
> 1668004454.052????? 0 172.22.200.1 TCP_DENIED/407 3951 CONNECT 
> drive.google.com:443 - HIER_NONE/- text/html
> 1668004454.057????? 0 172.22.200.1 TCP_DENIED/407 3951 CONNECT 
> drive.google.com:443 - HIER_NONE/- text/html
> 1668004454.063????? 1 172.22.200.1 TCP_DENIED/407 4454 CONNECT 
> drive.google.com:443 - HIER_NONE/- text/html
> 1668004454.076???? 10 172.22.200.1 NONE_NONE/500 0 CONNECT 
> drive.google.com:443 infoe HIER_NONE/- -
>
> And on the client :
> ERR_TUNNEL_CONNECTION_FAILED
>
> According to this page : 
> https://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm
> The cause is due to challenge-response process of NTLM
>
> How can I solve it ?
>
> Regards
>
> Bertrand Friconneau
>
>
> ------------------------------------------------------------------------------------------------------------------------------------------------------- 
>
> Here is my config file of squid :
>
> dns_v4_first on
> visible_hostname squid

Please use an actual FQDN hostname. This is the proxies "visible" 
hostname - eg sent as the domain name for URLs in error pages etc.

>
> error_directory /usr/share/squid/errors/French

These days it would be better to use:

 ? error_default_language fr

or at least
 ? error_directory /usr/share/squid-langpack/fr

>
> auth_param ntlm program /usr/bin/ntlm_auth 
> --helper-protocol=squid-2.5-ntlmssp
> auth_param ntlm children 250
> auth_param ntlm keep_alive off
>
...

> http_access deny !Safe_ports
>
> http_access deny CONNECT !SSL_ports
>
> http_access allow localhost manager

or maybe limit manager access to administrationzone

> http_access deny manager
>

custom access policy rules should be down here:

> http_access allow sitebypass
> http_access deny tor
> http_access deny url_exe

> http_access allow administrationzone
> #http_access allow pedagozone
> #http_access allow xibozone

All these below are of the same ACL type and all "allow" actions.
Therefore you can combine them into one ACL definition.

> http_access allow informatiquezone
> http_access allow secuzone
> http_access allow srvzone

> http_access allow ntlm

What about invalid logins, missing logins etc?
We highly recommend that the line triggering auth is a "deny" policy to 
reject all those.

 ?? http_access deny !ntlm

... then you allow what can be done by logged in accounts.

 ? http_access allow localnet
or
 ?http_access allow all


You may see a behaviour difference with this change to how Squid handles 
the login.
After doing it, of the problem continues try to get some debug 
information from the auth helper to see what it is getting from the 
client and why that is not being accepted.


PS. Since you have Kerberos available, please consider moving away from 
NTLM to using Negotiate/Kerberos auth. It has both better security and 
far better performance for the proxy.

Amos



From wojciech.andralojc at intel.com  Thu Nov 10 16:38:17 2022
From: wojciech.andralojc at intel.com (Andralojc, Wojciech)
Date: Thu, 10 Nov 2022 16:38:17 +0000
Subject: [squid-users] Squid ssl_bump configuration optimized for highest
 CPS?
Message-ID: <PH0PR11MB4966049C5503CE5E4F17594185019@PH0PR11MB4966.namprd11.prod.outlook.com>

Hi,

I'm running squid v4.13 in TLS bump mode.
Trying to configure it to get highest (single core) CPS (new TLS sessions/connections per second) numbers.

I run multiple s_time tests on client side and "plain" nginx on server side.

Example s_time command line:
openssl s_time -connect server:443 -new -cipher AES128-GCM-SHA256 -time 30 -CAfile /opt/proxy_rootCA.pem -tls1_2

Could you please review config below and suggest changes to improve performance?

Assumptions:

  *   SSL bump/transparent SSL proxy;
  *   single core performance;
  *   caching disabled;
  *   persistent connections disabled;
  *   no logs;

Best wishes
Wojciech Andralojc

---

acl localnet src 10.0.8.0/24

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

http_access deny !Safe_ports

http_access deny CONNECT !SSL_ports

http_access allow localhost manager
http_access deny manager

http_access allow localnet
http_access allow localhost

http_access allow all

# Squid normally listens to port 3128
http_port 3128
http_port 3129 intercept
ssl_bump server-first all
https_port 3130 intercept ssl-bump cert=/etc/ssl/certs//rootCA.pem generate-host-certificates=on

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
dns_nameservers 127.0.0.1
visible_hostname "proxy"
tls_outgoing_options cafile=/etc/ssl/certs//nginx.pem
access_log none
cache_store_log none
cache_log /dev/null
workers 1
cache deny all
cache_mem 0
server_persistent_connections off
client_persistent_connections off
--------------------------------------------------------------
Intel Research and Development Ireland Limited
Registered in Ireland
Registered Office: Collinstown Industrial Park, Leixlip, County Kildare
Registered Number: 308263


This e-mail and any attachments may contain confidential material for the sole
use of the intended recipient(s). Any review or distribution by others is
strictly prohibited. If you are not the intended recipient, please contact the
sender and delete all copies.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221110/3392a0b0/attachment.htm>

From squid.org at bloms.de  Fri Nov 11 13:49:34 2022
From: squid.org at bloms.de (Dieter Bloms)
Date: Fri, 11 Nov 2022 14:49:34 +0100
Subject: [squid-users] squid 5.7: can't access
 https://www.ilo.org/global/lang--en/index.htm with enabled sslbump,
 without sslbump it works
Message-ID: <20221111134934.m4gmn2hur7q6gltu@bloms.de>

Hello,

I'm using squid 5.7 with enabled sslbump and can't reach the website https://www.ilo.org/global/lang--en/index.htm
I get an error of type ERR_INVALID_RESP, but when I disable sslbump the
webcontent is shown in the browser.

Can anybody confirm this and can tell me what causes this problem ?


-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
>From field.


From squid3 at treenet.co.nz  Fri Nov 11 15:52:32 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 12 Nov 2022 04:52:32 +1300
Subject: [squid-users] Squid ssl_bump configuration optimized for
 highest CPS?
In-Reply-To: <PH0PR11MB4966049C5503CE5E4F17594185019@PH0PR11MB4966.namprd11.prod.outlook.com>
References: <PH0PR11MB4966049C5503CE5E4F17594185019@PH0PR11MB4966.namprd11.prod.outlook.com>
Message-ID: <76535017-e90e-5baf-3ab7-e2afcb4ff9a7@treenet.co.nz>

On 11/11/2022 5:38 am, Andralojc, Wojciech wrote:
>
> Hi,
>
> I?m running squid v4.13 in TLS bump mode.
>
> Trying to configure it to get highest (single core) CPS (new TLS 
> sessions/connections per second) numbers.
>
> I run multiple s_time tests on client side and ?plain? nginx on server 
> side.
>
> Example s_time command line:
>
> openssl s_time -connect server:443 -new -cipher AES128-GCM-SHA256 
> -time 30 -CAfile /opt/proxy_rootCA.pem -tls1_2
>
> Could you please review config below and suggest changes to improve 
> performance?
>

FYI; If this config you have shown is intended to go into production, 
then I would suggest not using Squid at all.
Without logging, decryption, nor policy rules there is no benefit to 
using Squid.

You would have better efficiency using NAT to redirect the traffic.


> Assumptions:
>
>   * SSL bump/transparent SSL proxy;
>

Which definition of "transparent" do you mean exactly?
 ?* The HTTP definition where it means a proxy does not alter the traffic?
 ?* or the colloquial use where it means intercepting and filtering traffic?

Your provided config looks like it is trying to do both.

>  *
>
>
>   * single core performance;
>   * caching disabled;
>   * persistent connections disabled;
>   * no logs;
>

The last three of those assumptions are debatable.

* the use of a proxy naturally adds some amount of latency to traffic. 
Caching is one of the major mechanisms used in HTTP to counter this cost 
and when possible exceed it for extra performance. Whether it is useful 
depends on how much (if any) of your traffic is cacheable.

* persistence connections are how HTTP (and HTTPS) avoid TCP connection 
setup latency costs. Disabling is generally a loss of performance, but 
some specific situations can benefit from it.
One of the things you should absolutely do is test is what impact 
persistence has on your proxy performance, on each of the client/server 
connection types independently.

* logging is a very minor impact. Processing the HTTP messages is by far 
the largest part of Squid performance costs.
That said;
 ? - store.log is almost always useless so that is OFF by default nowdays.
 ? - access.log is minor work, it can be disabled for a trivial 
reduction in CPU cycles at cost of not being able to see what clients 
are doing with the proxy.


> http_access deny !Safe_ports
>
> http_access deny CONNECT !SSL_ports
>
> http_access allow localhost manager
>
> http_access deny manager
>
> http_access allow localnet
>
> http_access allow localhost
>
> http_access allow all
>

You now have an open-proxy.


> # Squid normally listens to port 3128
>
> http_port 3128
>
> http_port 3129 intercept
>
> ssl_bump server-first all
>

"server-first" is deprecated.
Instead please use the new syntax:

 ? acl step1 at_step SslBump1
 ? ssl_bump peek step1
 ? ssl_bump splice all

> https_port 3130 intercept ssl-bump cert=/etc/ssl/certs//rootCA.pem 
> generate-host-certificates=on
>


> visible_hostname "proxy"
>

This should be an externally resolvable FQDN and not quoted.

> tls_outgoing_options cafile=/etc/ssl/certs//nginx.pem
>
> access_log none
>
> cache_store_log none
>

Not needed, cache_store_log default is disabled anyway.

> cache_log /dev/null
>

cache_log is not optional. If Squid has problems serving traffic that is 
your only source of information about what happened.
To minimize what gets logged use this instead:

 ? debug_options ALL,0

> workers 1
>

If you have a multi-core machine this is not enough. You may also need 
CPU affinity to lock the Squid processes to one core.
see <http://www.squid-cache.org/Doc/config/cpu_affinity_map/>


> cache deny all
>
> cache_mem 0
>

Okay, but if you have any plain-text or decrypted messages handled by 
Squid at least some memory cache can have performance benefits.
This is something you should definitely test, measure, tune to see what 
works best on your specific traffic.

> server_persistent_connections off
>
> client_persistent_connections off
>

See above.


HTH
Amos



From squid3 at treenet.co.nz  Fri Nov 11 16:01:05 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 12 Nov 2022 05:01:05 +1300
Subject: [squid-users] squid 5.7: can't access
 https://www.ilo.org/global/lang--en/index.htm with enabled sslbump,
 without sslbump it works
In-Reply-To: <20221111134934.m4gmn2hur7q6gltu@bloms.de>
References: <20221111134934.m4gmn2hur7q6gltu@bloms.de>
Message-ID: <3b9a64ec-2034-13f0-be8e-e4525c6d9348@treenet.co.nz>

On 12/11/2022 2:49 am, Dieter Bloms wrote:
> Hello,
>
> I'm using squid 5.7 with enabled sslbump and can't reach the website https://www.ilo.org/global/lang--en/index.htm
> I get an error of type ERR_INVALID_RESP, but when I disable sslbump the
> webcontent is shown in the browser.
>
> Can anybody confirm this and can tell me what causes this problem ?

TLS is complicated. SSL-Bump even more so. It is unlikely everyone else 
has exactly the same things occuring, even if they have the same 
squid.conf settings.

You need to look at what the ERR_INVALID_RESP actually says in wrong 
with the server response.
The check Squid cache.log. You may need to set "debug_options 11,2" to 
get a trace of the HTTP messages and see what is going on.

HTH
Amos


From vandita at iitbresearchpark.com  Mon Nov 14 10:33:10 2022
From: vandita at iitbresearchpark.com (Vandita Reddy)
Date: Mon, 14 Nov 2022 16:03:10 +0530
Subject: [squid-users] Upgrade to Squid 5.7
Message-ID: <CAOsFrPJyAmnGeodaDZrX8P=QCr6JRGOaUYrvxtri713FXhRHNw@mail.gmail.com>

Dear Team,

I am currently using Squid 4.10 for proxy but due to some requirements I
want to upgrade the same to Squid 5.7.

I have browsed the internet for a while for some leads but there is no
guidance provided.

Kindly help me upgrade the service. Also, please tell me if there is
vulnerability if I do not set passwords for all user accounts.

Awaiting your reply



Thanks & Regards,
Vandita Reddy
+91 7045281817
Project Assistant
( IT Operations & Maintenance )
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221114/278f176a/attachment.htm>

From squid.org at bloms.de  Mon Nov 14 12:12:53 2022
From: squid.org at bloms.de (Dieter Bloms)
Date: Mon, 14 Nov 2022 13:12:53 +0100
Subject: [squid-users] squid 5.7: can't access
 https://www.ilo.org/global/lang--en/index.htm with enabled sslbump,
 without sslbump it works
In-Reply-To: <3b9a64ec-2034-13f0-be8e-e4525c6d9348@treenet.co.nz>
References: <20221111134934.m4gmn2hur7q6gltu@bloms.de>
 <3b9a64ec-2034-13f0-be8e-e4525c6d9348@treenet.co.nz>
Message-ID: <20221114121253.by2gnmqtdkyxgjdn@bloms.de>

Hello Amos,

On Sat, Nov 12, Amos Jeffries wrote:

> On 12/11/2022 2:49 am, Dieter Bloms wrote:
> > Hello,
> > 
> > I'm using squid 5.7 with enabled sslbump and can't reach the website https://www.ilo.org/global/lang--en/index.htm
> > I get an error of type ERR_INVALID_RESP, but when I disable sslbump the
> > webcontent is shown in the browser.
> > 
> > Can anybody confirm this and can tell me what causes this problem ?
> 
> TLS is complicated. SSL-Bump even more so. It is unlikely everyone else has
> exactly the same things occuring, even if they have the same squid.conf
> settings.
> 
> You need to look at what the ERR_INVALID_RESP actually says in wrong with
> the server response.
> The check Squid cache.log. You may need to set "debug_options 11,2" to get a
> trace of the HTTP messages and see what is going on.

Thank you for your reply!
I've increased the debuglevel, but can't find any reason, why squid
reponds with ERR_INVALID_RESP.

Maybe someone with more knowledge can find the reason in the cache.log.
It can be found here: https://bloms.de/download/cache.log.gz


-- 
Gru?

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
From field.


From rousskov at measurement-factory.com  Mon Nov 14 13:15:31 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 14 Nov 2022 08:15:31 -0500
Subject: [squid-users] squid 5.7: can't access
 https://www.ilo.org/global/lang--en/index.htm with enabled sslbump,
 without sslbump it works
In-Reply-To: <20221114121253.by2gnmqtdkyxgjdn@bloms.de>
References: <20221111134934.m4gmn2hur7q6gltu@bloms.de>
 <3b9a64ec-2034-13f0-be8e-e4525c6d9348@treenet.co.nz>
 <20221114121253.by2gnmqtdkyxgjdn@bloms.de>
Message-ID: <b12a9576-b79c-05f3-bfe4-5beac670db4b@measurement-factory.com>

On 11/14/22 07:12, Dieter Bloms wrote:

> I've increased the debuglevel, but can't find any reason, why squid
> reponds with ERR_INVALID_RESP.


> HTTP/1.1 200 OK
> Server: Oracle-Application-Server-11g
> Transfer-Encoding: chunked
> Via: 1.1 www.ilo.org
> Transfer-Encoding: chunked

The above (abridged) response is malformed because it has two 
Transfer-Encoding headers signalling "chunked, chunked" transfer 
encoding. The proxy and/or the origin server your Squid is talking to is 
broken.

Modern Squids reject such messages because they are known to be used for 
cache poisoning and other security breaches. There is no official 
workaround (yet).


HTH,

Alex.



From andre.bolinhas at articatech.com  Mon Nov 14 16:42:47 2022
From: andre.bolinhas at articatech.com (andre.bolinhas at articatech.com)
Date: Mon, 14 Nov 2022 16:42:47 -0000
Subject: [squid-users] SNMP OID for username
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAIVNjRjcTGZElYgADq7oyvYBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAC0222BfceDTZTy6U2jD+rQAQAAAAA=@articatech.com>

Hi

I have SNMP configured for Squid and I would like to know if there is any
OID to get the information of the username.

Best regards

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221114/2ced3613/attachment.htm>

From andre.bolinhas at articatech.com  Mon Nov 14 16:45:45 2022
From: andre.bolinhas at articatech.com (andre.bolinhas at articatech.com)
Date: Mon, 14 Nov 2022 16:45:45 -0000
Subject: [squid-users] Squid web isolation
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAIVNjRjcTGZElYgADq7oyvYBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAxoVD5dfkrQKVd6Po7Qw+4AQAAAAA=@articatech.com>

Hi

It's possible with Squid + Icap do something like Symantec Web Isolation?
 <https://docs.broadcom.com/doc/web-isolation-en> Symantec Web Isolation
Product Brief (broadcom.com)
 
<https://www.youtube.com/watch?v=_HJdCyCXRc0&ab_channel=WorldInformationTech
nologyCo.%2CLtd.> (744) Symantec Web Isolation - YouTube

 

Best regards

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221114/ed49d897/attachment.htm>

From rousskov at measurement-factory.com  Mon Nov 14 17:08:20 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 14 Nov 2022 12:08:20 -0500
Subject: [squid-users] Squid web isolation
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAIVNjRjcTGZElYgADq7oyvYBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAxoVD5dfkrQKVd6Po7Qw+4AQAAAAA=@articatech.com>
References: <!&!AAAAAAAAAAAuAAAAAAAAAIVNjRjcTGZElYgADq7oyvYBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAxoVD5dfkrQKVd6Po7Qw+4AQAAAAA=@articatech.com>
Message-ID: <52be9ac9-fefd-453a-6817-969b2b2e6dd8@measurement-factory.com>

On 11/14/22 11:45, andre.bolinhas at articatech.com wrote:

> It?s possible with Squid + Icap do something like Symantec Web Isolation?
> Symantec Web Isolation Product Brief (broadcom.com) 
> <https://docs.broadcom.com/doc/web-isolation-en>
> (744) Symantec Web Isolation - YouTube 
> <https://www.youtube.com/watch?v=_HJdCyCXRc0&ab_channel=WorldInformationTechnologyCo.%2CLtd.>

AFAICT, "Web Isolation" requires rewriting HTTP responses. Yes, Squid 
can use an ICAP/eCAP content adaptation service to rewrite HTTP 
responses. However, you would need to find or create a service that 
implements the guts of what Symantec calls "Web Isolation". I doubt you 
will find similar open source services.


HTH,

Alex.



From gtaylor at tnetconsulting.net  Mon Nov 14 17:30:01 2022
From: gtaylor at tnetconsulting.net (Grant Taylor)
Date: Mon, 14 Nov 2022 10:30:01 -0700
Subject: [squid-users] Squid web isolation
In-Reply-To: <52be9ac9-fefd-453a-6817-969b2b2e6dd8@measurement-factory.com>
References: <!&!AAAAAAAAAAAuAAAAAAAAAIVNjRjcTGZElYgADq7oyvYBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAAxoVD5dfkrQKVd6Po7Qw+4AQAAAAA=@articatech.com>
 <52be9ac9-fefd-453a-6817-969b2b2e6dd8@measurement-factory.com>
Message-ID: <7a36c340-baee-a29a-ceed-b6652f8f7d4f@spamtrap.tnetconsulting.net>

On 11/14/22 10:08 AM, Alex Rousskov wrote:
> AFAICT, "Web Isolation" requires rewriting HTTP responses. Yes, Squid 
> can use an ICAP/eCAP content adaptation service to rewrite HTTP 
> responses.

I feel like just saying Web Isolation rewrites HTTP responses is about 
like saying you're going to experience moisture when standing in front 
of a tidal wave.  Is it true?  Yes.  Does it convey scope?  Not even 
remotely.

Aside:  I think the fact that Web Isolation uses JavaScript is ironic.

> However, you would need to find or create a service that implements 
> the guts of what Symantec calls "Web Isolation". I doubt you will 
> find similar open source services.

Ya....  It seems as if Web Isolation does a full render of the requested 
page in a sandbox / custom web browser hostsed on the Web Isolation 
infrastructure  and sends a responsive representation thereof to clients 
for use / interaction with.  This is all done in the context of an HTTP 
reqeust (over HTTP and / or HTTPS?) in a seemingly very transparent way.

This infrastructure to do the rendering and recomposition to generate 
and send the inew faximily to the client is WAY beyond what Squid is 
designed to do.

I agree that this probably could be done through content adaptation. 
But this seems like it is an entire product / industry unto itself.



-- 
Grant. . . .
unix || die

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4017 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221114/a95ac096/attachment.bin>

From squid3 at treenet.co.nz  Mon Nov 14 21:37:07 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 15 Nov 2022 10:37:07 +1300
Subject: [squid-users] SNMP OID for username
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAIVNjRjcTGZElYgADq7oyvYBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAC0222BfceDTZTy6U2jD+rQAQAAAAA=@articatech.com>
References: <!&!AAAAAAAAAAAuAAAAAAAAAIVNjRjcTGZElYgADq7oyvYBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAC0222BfceDTZTy6U2jD+rQAQAAAAA=@articatech.com>
Message-ID: <0d1620cb-63ec-fde3-6ec7-5b21583c32d3@treenet.co.nz>

On 15/11/2022 5:42 am, andre.bolinhas wrote:
>
> Hi
>
> I have SNMP configured for Squid and I would like to know if there is 
> any OID to get the information of the username.
>

No sorry. Credentials are sensitive metrics (even just the username). 
Client info in SNMP is limited to performance metrics by IP address.

The full list of OIDs for Squid can be found at 
<https://wiki.squid-cache.org/Features/Snmp#Squid_OIDs>


Cheers
Amos



From squid3 at treenet.co.nz  Tue Nov 15 03:23:23 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 15 Nov 2022 16:23:23 +1300
Subject: [squid-users] Upgrade to Squid 5.7
In-Reply-To: <CAOsFrPJyAmnGeodaDZrX8P=QCr6JRGOaUYrvxtri713FXhRHNw@mail.gmail.com>
References: <CAOsFrPJyAmnGeodaDZrX8P=QCr6JRGOaUYrvxtri713FXhRHNw@mail.gmail.com>
Message-ID: <f88dfa27-c71d-89bf-897f-4ecfd2adb4c3@treenet.co.nz>

FYI: please use squid-users mailing list for help requests the noc@ list 
is for Squid Software Foundation web/mail/repository administrators.


On 14/11/2022 11:33 pm, Vandita Reddy wrote:
> Dear Team,
>
> I am currently using Squid 4.10 for proxy but due to some requirements 
> I want to upgrade the same to Squid 5.7.
>
> I have browsed the internet for a while for some leads but there is no 
> guidance provided.
>

Requirements depend on what Vendor(s) you are using already for OS and 
to get Squid. If they provide an upgraded version it is "just" a matter 
of installing that.

If that Vendor requires a full OS upgrade to get the new Squid and you 
want to avoid that, then building your own Squid is usually available as 
an alternative.

If you could mention the Vendor/OS you are using, we could probably 
provide some better help that the above.


> Kindly help me upgrade the service. Also, please tell me if there is 
> vulnerability if I do not set passwords for all user accounts.
>

In terms of security username with no password is the same as username 
with a trivial well-known password. Not secure at all.

HTH
Amos



From vandita at iitbresearchpark.com  Tue Nov 15 12:04:42 2022
From: vandita at iitbresearchpark.com (Vandita Reddy)
Date: Tue, 15 Nov 2022 17:34:42 +0530
Subject: [squid-users] squid-users Digest, Vol 99, Issue 19
In-Reply-To: <mailman.3.1668513602.1894377.squid-users@lists.squid-cache.org>
References: <mailman.3.1668513602.1894377.squid-users@lists.squid-cache.org>
Message-ID: <CAOsFrPL0KVzWsoW0kHwnocVaFRt=tQ3-HKuqqjdqobs7n_cBqQ@mail.gmail.com>

Hello,

The OS I am using is Ubuntu 20.4 and the update needed is only for Squid,
not the OS.

Kindly guide me how to upgrade it to 5.7?




Thanks & Regards,
Vandita



On Tue, 15 Nov 2022 at 17:30, <squid-users-request at lists.squid-cache.org>
wrote:

> Send squid-users mailing list submissions to
>         squid-users at lists.squid-cache.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         http://lists.squid-cache.org/listinfo/squid-users
> or, via email, send a message with subject or body 'help' to
>         squid-users-request at lists.squid-cache.org
>
> You can reach the person managing the list at
>         squid-users-owner at lists.squid-cache.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
>
>
> Today's Topics:
>
>    1. Re: SNMP OID for username (Amos Jeffries)
>    2. Re: Upgrade to Squid 5.7 (Amos Jeffries)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Tue, 15 Nov 2022 10:37:07 +1300
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] SNMP OID for username
> Message-ID: <0d1620cb-63ec-fde3-6ec7-5b21583c32d3 at treenet.co.nz>
> Content-Type: text/plain; charset=UTF-8; format=flowed
>
> On 15/11/2022 5:42 am, andre.bolinhas wrote:
> >
> > Hi
> >
> > I have SNMP configured for Squid and I would like to know if there is
> > any OID to get the information of the username.
> >
>
> No sorry. Credentials are sensitive metrics (even just the username).
> Client info in SNMP is limited to performance metrics by IP address.
>
> The full list of OIDs for Squid can be found at
> <https://wiki.squid-cache.org/Features/Snmp#Squid_OIDs>
>
>
> Cheers
> Amos
>
>
>
> ------------------------------
>
> Message: 2
> Date: Tue, 15 Nov 2022 16:23:23 +1300
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Upgrade to Squid 5.7
> Message-ID: <f88dfa27-c71d-89bf-897f-4ecfd2adb4c3 at treenet.co.nz>
> Content-Type: text/plain; charset=UTF-8; format=flowed
>
> FYI: please use squid-users mailing list for help requests the noc@ list
> is for Squid Software Foundation web/mail/repository administrators.
>
>
> On 14/11/2022 11:33 pm, Vandita Reddy wrote:
> > Dear Team,
> >
> > I am currently using Squid 4.10 for proxy but due to some requirements
> > I want to upgrade the same to Squid 5.7.
> >
> > I have browsed the internet for a while for some leads but there is no
> > guidance provided.
> >
>
> Requirements depend on what Vendor(s) you are using already for OS and
> to get Squid. If they provide an upgraded version it is "just" a matter
> of installing that.
>
> If that Vendor requires a full OS upgrade to get the new Squid and you
> want to avoid that, then building your own Squid is usually available as
> an alternative.
>
> If you could mention the Vendor/OS you are using, we could probably
> provide some better help that the above.
>
>
> > Kindly help me upgrade the service. Also, please tell me if there is
> > vulnerability if I do not set passwords for all user accounts.
> >
>
> In terms of security username with no password is the same as username
> with a trivial well-known password. Not secure at all.
>
> HTH
> Amos
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
>
> End of squid-users Digest, Vol 99, Issue 19
> *******************************************
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221115/d98b6697/attachment.htm>

From alex.kimble at viewpointe.com  Tue Nov 15 15:21:05 2022
From: alex.kimble at viewpointe.com (Alex Kimble)
Date: Tue, 15 Nov 2022 15:21:05 +0000
Subject: [squid-users] How to generate daily usage email reports
In-Reply-To: <CY4PR2201MB1543FAEDB0F8D2B66FEFC5458B049@CY4PR2201MB1543.namprd22.prod.outlook.com>
References: <CY4PR2201MB1543FAEDB0F8D2B66FEFC5458B049@CY4PR2201MB1543.namprd22.prod.outlook.com>
Message-ID: <CY4PR2201MB154306967FEE539B3DC10E8E8B049@CY4PR2201MB1543.namprd22.prod.outlook.com>

Greetings Squid users,

I have 2 questions:


  1.  What are some good ways to generate a daily usage report in which I can receive in email format .csv or .html if fine (top users, top URLs, blocked URLs)
  2.  Can daily usage reports be created and emailed from Squidanalyzer or is that just a static dashboard?

Thank you!

Alex
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221115/b0e3375f/attachment.htm>

From robertkwild at gmail.com  Tue Nov 15 17:31:40 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Tue, 15 Nov 2022 17:31:40 +0000
Subject: [squid-users] moving squid from centos 7 to ubuntu 22.04
Message-ID: <CAGU_CiKK5w8+CM+=XLzaUtYS_kqO9iEVKZt2i1i1wES9Cxn-LQ@mail.gmail.com>

hi all,

atm i have written a script, once you have built a centos 7 VM, you just
run the script and after the reboot its a complete running squidclamAV
server

i'm going to be moving the script to a ubuntu server as centos 7 is dead
now (as i run clamAV on it, clamAV will stop getting virus definitions 2024
as i use this for virus scanning of internet packets)

just want to know what lines i need to adjust to work with ubuntu instead
of centos, obviously i know instead of yum install.... its apt install

heres my long script

#!/bin/bash
#
#this script will download/install and configure the following packages
#
#squid - proxy server
#squid ssl bump - intercept HTTPS traffic
#clamAV - antivirus engine inc trojans,viruses,malware
#c-icap - icap server
#squidclamav - that integrates all the above in squid
#whitelist URL's
#deny MIME types
#
#on the PROD host you only need squid
#
#first things first lets disable firewalld and SElinux
#
systemctl stop firewalld
systemctl disable firewalld
sed -i -e 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config
#
#squid packages
#
yum install -y epel-release screen rsync net-tools ethtool swaks sed tar
zip unzip curl telnet openssl openssl-devel bzip2-devel libarchive
libarchive-devel perl perl-Data-Dumper gcc gcc-c++ binutils autoconf
automake make sudo wget libxml2-devel libcap-devel libtool-ltdl-devel
#
#clamAV packages
#
yum install -y clamav-server clamav-data clamav-update clamav-filesystem
clamav clamav-scanner-systemd clamav-devel clamav-lib clamav-server-systemd
#
#download and compile from source
#
cd /tmp
wget http://www.squid-cache.org/Versions/v4/squid-4.17.tar.gz
wget
http://sourceforge.net/projects/c-icap/files/c-icap/0.5.x/c_icap-0.5.10.tar.gz
--no-check-certificate
wget
http://sourceforge.net/projects/c-icap/files/c-icap-modules/0.5.x/c_icap_modules-0.5.5.tar.gz
--no-check-certificate
wget
https://sourceforge.net/projects/squidclamav/files/squidclamav/7.1/squidclamav-7.1.tar.gz
--no-check-certificate
#
for f in *.tar.gz; do tar xf "$f"; done
#
cd /tmp/squid-4.17
./configure --with-openssl --enable-ssl-crtd --enable-icap-client
--enable-http-violations && make && make install
#
cd /tmp/c_icap-0.5.10
./configure 'CXXFLAGS=-O2 -m64 -pipe' 'CFLAGS=-O2 -m64 -pipe' --without-bdb
--prefix=/usr/local && make && make install
#
cd /tmp/squidclamav-7.1
./configure 'CXXFLAGS=-O2 -m64 -pipe' 'CFLAGS=-O2 -m64 -pipe'
--with-c-icap=/usr/local --with-libarchive && make && make install
#
cd /tmp/c_icap_modules-0.5.5
./configure 'CFLAGS=-O3 -m64 -pipe' 'CPPFLAGS=-I/usr/local/clamav/include'
'LDFLAGS=-L/usr/local/lib -L/usr/local/clamav/lib/' && make && make install
#
#creating shortcuts and copying files
#
cp -f /usr/local/squid/etc/squid.conf /usr/local/squid/etc/squid.conf.orig
cp -f /usr/local/etc/c-icap.conf /usr/local/etc/c-icap.conf.orig
cp -f /usr/local/etc/squidclamav.conf /usr/local/etc/squidclamav.conf.orig
cp -f /usr/local/etc/clamav_mod.conf /usr/local/etc/clamav_mod.conf.orig
cp -f /usr/local/etc/virus_scan.conf /usr/local/etc/virus_scan.conf.orig
#
ln -s /usr/local/squid/etc/squid.conf /etc
ln -s /usr/local/etc/c-icap.conf /etc
ln -s /usr/local/etc/squidclamav.conf /etc
ln -s /usr/local/etc/clamav_mod.conf /etc
ln -s /usr/local/etc/virus_scan.conf /etc
#
mkdir -p /usr/local/clamav/share/clamav
ln -s /var/lib/clamav /usr/local/clamav/share/clamav
#
#tmpfiles for run files
#
echo "d /var/run/c-icap 0755 root root -" >> /etc/tmpfiles.d/c-icap.conf
echo "d /var/run/clamav 0755 root root -" >> /etc/tmpfiles.d/clamav.conf
#
#original squid config
#
sed -i '/http_port 3128/d' /usr/local/squid/etc/squid.conf
sed -i -e 's%http_access deny !Safe_ports%#http_access deny !Safe_ports%g'
/usr/local/squid/etc/squid.conf
sed -i -e 's%http_access deny CONNECT !SSL_ports%#http_access deny CONNECT
!SSL_ports%g' /usr/local/squid/etc/squid.conf
#
#create URL, MIME and public key list
#
echo "#eicar" >> /usr/local/squid/etc/urlwhite.txt
echo ".eicar.org" >> /usr/local/squid/etc/urlwhite.txt
#
echo "http://updater.maxon.net/server_test" >>
/usr/local/squid/etc/urlspecial.txt
#
echo "application/octet-stream" >> /usr/local/squid/etc/mimedeny.txt
echo "application/x-msi" >> /usr/local/squid/etc/mimedeny.txt
echo "application/zip" >> /usr/local/squid/etc/mimedeny.txt
echo "application/x-7z-compressed" >> /usr/local/squid/etc/mimedeny.txt
echo "application/vnd.ms-cab-compressed" >>
/usr/local/squid/etc/mimedeny.txt
echo "application/x-msdownload" >> /usr/local/squid/etc/mimedeny.txt
echo "application/x-iso9660-image" >> /usr/local/squid/etc/mimedeny.txt
#
echo ".activation.paceap.com" >> /usr/local/squid/etc/pubkey.txt
#
#ICAP in squid
#
echo "#ICAP" >> /usr/local/squid/etc/squid.conf
echo "icap_enable on" >> /usr/local/squid/etc/squid.conf
echo "adaptation_uses_indirect_client on" >> /usr/local/squid/etc/squid.conf
echo "icap_send_client_ip on" >> /usr/local/squid/etc/squid.conf
echo "icap_send_client_username on" >> /usr/local/squid/etc/squid.conf
echo "icap_client_username_header X-Authenticated-User" >>
/usr/local/squid/etc/squid.conf
echo "icap_service service_req reqmod_precache bypass=0 icap://
127.0.0.1:1344/squidclamav" >> /usr/local/squid/etc/squid.conf
echo "adaptation_access service_req allow all" >>
/usr/local/squid/etc/squid.conf
echo "icap_service service_resp respmod_precache bypass=0 icap://
127.0.0.1:1344/squidclamav" >> /usr/local/squid/etc/squid.conf
echo "adaptation_access service_resp allow all" >>
/usr/local/squid/etc/squid.conf
#
#creating SSL
#
mkdir -p /usr/local/squid/etc/ssl_cert
cd /usr/local/squid/etc/ssl_cert
adduser squid
chown squid:squid /usr/local/squid/etc/ssl_cert
chmod 700 /usr/local/squid/etc/ssl_cert
openssl req -new -newkey rsa:2048 -sha256 -days 365 -nodes -x509
-extensions v3_ca -keyout myCA.pem  -out myCA.pem -batch
#must import the below cert on hosts in trusted root cert ie the .der file
openssl x509 -in myCA.pem -outform DER -out myCA.der
/usr/local/squid/libexec/security_file_certgen -c -s /var/lib/ssl_db -M 4MB
chown squid:squid -R /var/lib/ssl_db
chmod -R 777 /usr/local/squid/var/logs
#
#squid config
#
sed -i '51i#SSL NO Interception' /usr/local/squid/etc/squid.conf
sed -i '52iacl DiscoverSNIHost at_step SslBump1'
/usr/local/squid/etc/squid.conf
sed -i '53iacl NoSSLIntercept ssl::server_name
"/usr/local/squid/etc/pubkey.txt"' /usr/local/squid/etc/squid.conf
sed -i '54issl_bump splice NoSSLIntercept' /usr/local/squid/etc/squid.conf
sed -i '55issl_bump peek DiscoverSNIHost' /usr/local/squid/etc/squid.conf
sed -i '56issl_bump bump all' /usr/local/squid/etc/squid.conf
sed -i '57i#' /usr/local/squid/etc/squid.conf
sed -i '58i#SSL Bump' /usr/local/squid/etc/squid.conf
sed -i '59ihttp_port 3128 ssl-bump
cert=/usr/local/squid/etc/ssl_cert/myCA.pem generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB' /usr/local/squid/etc/squid.conf
sed -i '60isslcrtd_program /usr/local/squid/libexec/security_file_certgen
-s /var/lib/ssl_db -M 4MB' /usr/local/squid/etc/squid.conf
sed -i '61iacl step1 at_step SslBump1' /usr/local/squid/etc/squid.conf
sed -i '62issl_bump peek step1' /usr/local/squid/etc/squid.conf
sed -i '63issl_bump bump all' /usr/local/squid/etc/squid.conf
sed -i '64i#' /usr/local/squid/etc/squid.conf
sed -i '65iacl activation port 80 443 8090 9251 # office adobe web'
/usr/local/squid/etc/squid.conf
sed -i '66i#' /usr/local/squid/etc/squid.conf
sed -i '67i#allow special URL paths' /usr/local/squid/etc/squid.conf
sed -i '68iacl special_url url_regex "/usr/local/squid/etc/urlspecial.txt"'
/usr/local/squid/etc/squid.conf
sed -i '69i#' /usr/local/squid/etc/squid.conf
sed -i '70i#deny MIME types' /usr/local/squid/etc/squid.conf
sed -i '71iacl mimetype rep_mime_type "/usr/local/squid/etc/mimedeny.txt"'
/usr/local/squid/etc/squid.conf
sed -i '72i#' /usr/local/squid/etc/squid.conf
sed -i '73ihttp_reply_access allow special_url'
/usr/local/squid/etc/squid.conf
sed -i '74ihttp_reply_access deny mimetype' /usr/local/squid/etc/squid.conf
sed -i '75i#' /usr/local/squid/etc/squid.conf
sed -i '76i#HTTP_HTTPS whitelist websites' /usr/local/squid/etc/squid.conf
sed -i '77iacl whitelist ssl::server_name
"/usr/local/squid/etc/urlwhite.txt"' /usr/local/squid/etc/squid.conf
sed -i '78i#' /usr/local/squid/etc/squid.conf
sed -i '79i#HTTP_HTTPS whitelist websites regex'
/usr/local/squid/etc/squid.conf
sed -i '80iacl whitelistreg ssl::server_name_regex
"/usr/local/squid/etc/urlregwhite.txt"' /usr/local/squid/etc/squid.conf
sed -i '81i#' /usr/local/squid/etc/squid.conf
sed -i '82ihttp_access allow activation whitelist'
/usr/local/squid/etc/squid.conf
sed -i '83ihttp_access allow activation whitelistreg'
/usr/local/squid/etc/squid.conf
sed -i '84ihttp_access deny all' /usr/local/squid/etc/squid.conf
#
#squidclamav conf
#
sed -i -e 's%redirect http://proxy.domain.dom/cgi-bin/clwarn.cgi%#redirect
http://proxy.domain.dom/cgi-bin/clwarn.cgi%g' /etc/squidclamav.conf
sed -i -e 's%enable_libarchive 0%enable_libarchive 1%g'
/etc/squidclamav.conf
#
#clamav conf
#
sed -i -e 's%#LocalSocket /run/clamd.scan/clamd.sock%LocalSocket
/var/run/clamav/clamd.ctl%g' /etc/clamd.d/scan.conf
sed -i -e 's%Example%#Example%g' /etc/clamd.d/scan.conf
sed -i -e 's%User clamscan%User root%g' /etc/clamd.d/scan.conf
sed -i -e 's%#StreamMaxLength 10M%StreamMaxLength 5M%g'
/etc/clamd.d/scan.conf
freshclam
systemctl enable clamd at scan
#
#crontab
#
echo "00 01,13 * * *  /usr/bin/freshclam --quiet" >> /var/spool/cron/root
echo "@reboot /usr/local/squid/sbin/squid" >> /var/spool/cron/root
echo "*/15 * * * * /usr/local/squid/sbin/squid -k reconfigure" >>
/var/spool/cron/root
echo "0 21 * * 0 /usr/local/squid/sbin/squid -k rotate" >>
/var/spool/cron/root
#
#c-icap and c-icap modules
#
sed -i -e 's%#.*User wwwrun%User root%g' /etc/c-icap.conf
sed -i -e 's%#.*Group nogroup%Group root%g' /etc/c-icap.conf
sed -i -e 's%#.*Service echo_service srv_echo.so%Service squidclamav
squidclamav.so%g' /etc/c-icap.conf
sed -i -e 's%DebugLevel 1%DebugLevel 0%g' /etc/c-icap.conf
sed -i -e 's%StartServers 3%StartServers 1%g' /etc/c-icap.conf
sed -i -e 's%MaxServers 10%MaxServers 20%g' /etc/c-icap.conf
sed -i -e 's%MaxRequestsPerChild  0%MaxRequestsPerChild  100%g'
/etc/c-icap.conf
sed -i '520iacl localhost src 127.0.0.1/255.255.255.255' /etc/c-icap.conf
sed -i '521iacl PERMIT_REQUESTS type REQMOD RESPMOD' /etc/c-icap.conf
sed -i '522iicap_access allow localhost PERMIT_REQUESTS' /etc/c-icap.conf
sed -i '523iicap_access deny all' /etc/c-icap.conf
echo "clamav_mod.TmpDir /var/tmp" >> /etc/clamav_mod.conf
echo "clamav_mod.MaxFilesInArchive 1000" >> /etc/clamav_mod.conf
echo "clamav_mod.MaxScanSize 5M" >> /etc/clamav_mod.conf
echo "clamav_mod.HeuristicScanPrecedence on" >> /etc/clamav_mod.conf
echo "clamav_mod.OLE2BlockMacros on" >> /etc/clamav_mod.conf
echo "virus_scan.ScanFileTypes TEXT DATA EXECUTABLE ARCHIVE DOCUMENT" >>
/etc/virus_scan.conf
echo "virus_scan.SendPercentData 5" >> /etc/virus_scan.conf
echo "virus_scan.PassOnError on" >> /etc/virus_scan.conf
echo "virus_scan.MaxObjectSize  5M" >> /etc/virus_scan.conf
echo "virus_scan.DefaultEngine clamav" >> /etc/virus_scan.conf
echo "Include clamav_mod.conf" >> /etc/virus_scan.conf
echo "Include virus_scan.conf" >> /etc/c-icap.conf
#
#make c-icap service
#
echo "[Unit]" >> /usr/lib/systemd/system/c-icap.service
echo "Description=c-icap service" >> /usr/lib/systemd/system/c-icap.service
echo "After=network.target" >> /usr/lib/systemd/system/c-icap.service
echo "[Service]" >> /usr/lib/systemd/system/c-icap.service
echo "Type=forking" >> /usr/lib/systemd/system/c-icap.service
echo "PIDFile=/var/run/c-icap/c-icap.pid" >>
/usr/lib/systemd/system/c-icap.service
echo "ExecStart=/usr/local/bin/c-icap -f /etc/c-icap.conf" >>
/usr/lib/systemd/system/c-icap.service
echo "KillMode=process" >> /usr/lib/systemd/system/c-icap.service
echo "[Install]" >> /usr/lib/systemd/system/c-icap.service
echo "WantedBy=multi-user.target" >> /usr/lib/systemd/system/c-icap.service
systemctl enable c-icap
reboot

thanks,
rob
-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221115/f8ebf898/attachment.htm>

From makleking at yandex.ru  Wed Nov 16 04:11:46 2022
From: makleking at yandex.ru (=?utf-8?B?0JzQuNGF0LDQuNC7?=)
Date: Wed, 16 Nov 2022 12:11:46 +0800
Subject: [squid-users] Kerberos - Cannot decrypt ticket for HTTP
Message-ID: <1783041668571106@mail.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221116/86787f9f/attachment.htm>

From holitafarolito at gmail.com  Wed Nov 16 20:14:48 2022
From: holitafarolito at gmail.com (Lola Lo)
Date: Wed, 16 Nov 2022 15:14:48 -0500
Subject: [squid-users] transparent mode squid on centos 9 with iptables
 (part 2)
In-Reply-To: <CAKM+x_K5XA0oTvEsGkzwHuYbVVYXe+1UegWCW2b37_pATX7mDQ@mail.gmail.com>
References: <CAKM+x_L67p0YjP3BPwSU=cp8PrQcG-CVH7jzmT80AB=ym3u4Vw@mail.gmail.com>
 <CAKM+x_JRkR2vNgT_zqcQAd3qXTwQMXDa8mJeEY+R6FYXDiFB0g@mail.gmail.com>
 <CAKM+x_K5XA0oTvEsGkzwHuYbVVYXe+1UegWCW2b37_pATX7mDQ@mail.gmail.com>
Message-ID: <CAKM+x_JwQt+4jwVsfzgdj-x-DoWC77TqYROS44+cux0asdAADw@mail.gmail.com>

Hi guys.


Could you please send a tutorial or any good guidance to implement  squid
on transparent mode on centos 9 with iptables.

I have configured squid.conf with this parameters:



ens192: 172.31.168.28, internet interface

ens224: 192.168.1.10, LAN interface (private network)


# Mis ACLs #

acl mi_red src 192.168.1.0/24

acl cliente_linux src 192.168.1.20

acl cliente_windows src 192.168.1.30

acl sitios1 url_regex "/etc/squid/listas/sitios1"

acl sitios2 url_regex "/etc/squid/listas/sitios2"


# Squid normally listens to port 3128

http_port 3128

http_port 8080 transparent


I want the ?deny all? rule get applied to test the client using the proxy


My iptables is configured as follows:


#!/bin/bash


## NAT server configuration ##


sysctl -w net.ipv4.ip_forward=1

sysctl -p

iptables -X

iptables -F

iptables -t nat -X

iptables -t nat -F

iptables -I INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT

iptables -I FORWARD  -m state --state RELATED,ESTABLISHED -j ACCEPT

iptables -t nat -I POSTROUTING -o ens192 -j MASQUERADE




#!/bin/bash


## proxy server configuration ##


### Accepting traffic for the ports: 3128 and 8080##


iptables -A INPUT -s 192.168.1.0/24 -p tcp --dport 3128 -j ACCEPT

iptables -A INPUT -p tcp --dport 3128 -j DROP

iptables -A OUTPUT -d 192.168.1.0/24 -p tcp --sport 3128 -j ACCEPT

iptables -A OUTPUT -p tcp --sport 3128 -j DROP


iptables -A INPUT -s 192.168.1.0/24 -p tcp --dport 8080 -j ACCEPT

iptables -A INPUT -p tcp --dport 8080 -j DROP

iptables -A OUTPUT -d 192.168.1.0/24 -p tcp --sport 8080 -j ACCEPT

iptables -A OUTPUT -p tcp --sport 8080 -j DROP



### Accepting traffic for the ports: 3128 and 8080##


iptables -t nat -A POSTROUTING -o ens192 -j MASQUERADE

iptables -t nat -A PREROUTING -s 192.168.1.0/24 -p tcp --dport 80 -j
REDIRECT --to-port 8080

iptables -t nat -A PREROUTING -s 192.168.1.0/24 -p tcp --dport 443 -j
REDIRECT --to-port 8080




But I got this error:


1668381894.746      0 192.168.1.20 NONE_NONE/000 0 -
error:transaction-end-before-headers - HIER_NONE/- -

1668381967.800      0 192.168.1.20 NONE_NONE/400 3690 -
error:invalid-request - HIER_NONE/- text/html

1668381967.805      0 192.168.1.20 NONE_NONE/400 3690 -
error:invalid-request - HIER_NONE/- text/html

1668381967.809      0 192.168.1.20 NONE_NONE/400 3690 -
error:invalid-request - HIER_NONE/- text/html

1668381967.814      0 192.168.1.20 NONE_NONE/400 3690 -
error:invalid-request - HIER_NONE/- text/html

1668381967.818      0 192.168.1.20 NONE_NONE/400 3690 -
error:invalid-request - HIER_NONE/- text/html

1668381967.823      0 192.168.1.20 NONE_NONE/400 3690 -
error:invalid-request - HIER_NONE/- text/html

1668381967.827      0 192.168.1.20 NONE_NONE/400 3690 -
error:invalid-request - HIER_NONE/- text/html

1668381967.832      0 192.168.1.20 NONE_NONE/400 3690 -
error:invalid-request - HIER_NONE/- text/html

1668381967.836      0 192.168.1.20 NONE_NONE/400 3690 -
error:invalid-request - HIER_NONE/- text/html

1668381967.841      0 192.168.1.20 NONE_NONE/400 3690 -
error:invalid-request - HIER_NONE/- text/html


Could you please help me to solve this; i am completely new using squid and
in Linux?


I was following these sources:


? https://www.xmodulo.com/squid-transparent-web-proxy-centos-rhel.html

? https://www.maravento.com/2015/06/no-forward-proxy-ports-configured.html

? https://www.xmodulo.com/internet-connection-sharing-iptables-linux.html


You can find the logs of squid 5.5 here: squid logs
<https://epnecuador-my.sharepoint.com/:u:/g/personal/mercy_anchundia_epn_edu_ec/EaqrQJFkDfhLnEha14CIfKoBhrKZLaSTIE51t_gw0_iUZw?e=Y8xirv>
I configured the linux client with the ip 192.168.1.20/24, gateway is the
linux server: 192.168.1.10 and DNS: 192.168.1.10 and others of my ISP.

H
Lola Lo <holitafarolito at gmail.com> (sent by marseaplage at gmail.com)
Sun, Nov 13, 8:52 PM (3 days ago)
to squid-users
Hi guys.

You can find the logs of squid 5.5 here: squid logs
<https://epnecuador-my.sharepoint.com/:u:/g/personal/mercy_anchundia_epn_edu_ec/EaqrQJFkDfhLnEha14CIfKoBhrKZLaSTIE51t_gw0_iUZw?e=Y8xirv>
I configured the linux client with the ip 192.168.1.20/24, gateway is the
linux server: 192.168.1.10 and DNS: 192.168.1.10 and others of my ISP.

i gHi guys.

You can find the logs of squid 5.5 here: squid logs
I configured the linux client with the ip 192.168.1.20/24, gateway is the
linux server: 192.168.1.10 and DNS: 192.168.1.10 and others of my ISP.uys.

You can find the logs of squid 5.5 here: squid logs
<https://epnecuador-my.sharepoint.com/:u:/g/personal/mercy_anchundia_epn_edu_ec/EaqrQJFkDfhLnEha14CIfKoBhrKZLaSTIE51t_gw0_iUZw?e=Y8xirv>
I configured the linux client with the ip 192.168.1.20/24, gateway is the
linux server: 192.168.1.10 and DNS: 192.168.1.10 and others of my ISP.
Thank you in advance for your help

---------- Forwarded message ---------
From: Lola Lo <holitafarolito at gmail.com>
Date: Sun, Nov 13, 2022 at 7:32 PM
Subject: transparent mode squid on centos 9 with iptables
To: <squid-users at lists.squid-cache.org>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221116/2f3f2dbd/attachment.htm>

From david at articatech.com  Thu Nov 17 02:06:34 2022
From: david at articatech.com (David Touzeau)
Date: Thu, 17 Nov 2022 03:06:34 +0100
Subject: [squid-users] Kerberos - Cannot decrypt ticket for HTTP
In-Reply-To: <1783041668571106@mail.yandex.ru>
References: <1783041668571106@mail.yandex.ru>
Message-ID: <b9ffb62c-3c84-5380-dbf1-81af6c93e794@articatech.com>

Hi

perhaps this one
https://wiki.articatech.com/en/proxy-service/troubleshooting/gss-cannot-decrypt-ticket


Le 16/11/2022 ? 05:11, ?????? a ?crit?:
> Hi everybody,
> Could you help me to setup my new squid server? I have a problem with 
> keytab authorization.
> 2022/11/16 11:35:39| ERROR: Negotiate Authentication validating user. 
> Result: {result=BH, notes={message: gss_accept_sec_context() failed: 
> Unspecified GSS failure. ?Minor code may provide more information. 
> Cannot decrypt ticket for HTTP/uisproxy-rop.***.***.corp@***.***.CORP 
> using keytab key for HTTP/uisproxy-rop.***.***.corp@***.**.CORP; }}
> Got NTLMSSP neg_flags=0xe2088297
> 2022/11/16 11:35:40| ERROR: Negotiate Authentication validating user. 
> Result: {result=BH, notes={message: gss_accept_sec_context() failed: 
> Unspecified GSS failure. ?Minor code may provide more information. 
> Cannot decrypt ticket for HTTP/uisproxy-rop.***.***.corp@***.***.CORP 
> using keytab key for HTTP/uisproxy-rop.***.***.corp@***.***.CORP; }}
> # kinit -V -k -t /etc/squid/keytab/uisproxy-rop-t.keytab 
> HTTP/uisproxy-rop.***.***.corp
> Using default cache: /tmp/krb5cc_0
> Using principal: HTTP/uisproxy-rop.***.***.corp@***.***.CORP
> Using keytab: /etc/squid/keytab/uisproxy-rop-t.keytab
> Authenticated to Kerberos v5
> # klist -ke /etc/squid/keytab/uisproxy-rop-t.keytab
> Keytab name: FILE:/etc/squid/keytab/uisproxy-rop-t.keytab
> KVNO Principal
> ---- 
> --------------------------------------------------------------------------
> ? ?3 uisproxy-rop-t$@***.***.CORP (arcfour-hmac)
> ? ?3 uisproxy-rop-t$@***.***.CORP (aes128-cts-hmac-sha1-96)
> ? ?3 uisproxy-rop-t$@***.***.CORP (aes256-cts-hmac-sha1-96)
> ? ?3 UISPROXY-ROP-T$@***.***.CORP (arcfour-hmac)
> ? ?3 UISPROXY-ROP-T$@***.***.CORP (aes128-cts-hmac-sha1-96)
> ? ?3 UISPROXY-ROP-T$@***.***.CORP (aes256-cts-hmac-sha1-96)
> ? ?3 HTTP/uisproxy-rop.***.***.corp@***.***.CORP (arcfour-hmac)
> ? ?3 HTTP/uisproxy-rop.***.***.corp@***.***.CORP (aes128-cts-hmac-sha1-96)
> ? ?3 HTTP/uisproxy-rop.***.***.corp@***.***.CORP (aes256-cts-hmac-sha1-96)
> ? ?3 host/uisproxy-rop@***.***.CORP (arcfour-hmac)
> ? ?3 host/uisproxy-rop@***.***.CORP (aes128-cts-hmac-sha1-96)
> ? ?3 host/uisproxy-rop@***.***.CORP (aes256-cts-hmac-sha1-96)
> # klist -kt
> Keytab name: FILE:/etc/squid/keytab/uisproxy-rop-t.keytab
> KVNO Timestamp ? ? ? ? ? Principal
> ---- ------------------- 
> ------------------------------------------------------
> ? ?3 11/16/2022 11:30:50 uisproxy-rop-t$@***.***.CORP
> ? ?3 11/16/2022 11:30:50 uisproxy-rop-t$@***.***.CORP
> ? ?3 11/16/2022 11:30:50 uisproxy-rop-t$@***.***.CORP
> ? ?3 11/16/2022 11:30:50 UISPROXY-ROP-T$@***.***.CORP
> ? ?3 11/16/2022 11:30:50 UISPROXY-ROP-T$@***.***.CORP
> ? ?3 11/16/2022 11:30:50 UISPROXY-ROP-T$@***.***.CORP
> ? ?3 11/16/2022 11:30:50 HTTP/uisproxy-rop.***.***.corp@***.***.CORP
> ? ?3 11/16/2022 11:30:50 HTTP/uisproxy-rop.***.***.corp@***.***.CORP
> ? ?3 11/16/2022 11:30:50 HTTP/uisproxy-rop.***.***.corp@***.***.CORP
> ? ?3 11/16/2022 11:30:50 host/uisproxy-rop@***.***.CORP
> ? ?3 11/16/2022 11:30:50 host/uisproxy-rop@***.***.CORP
> ? ?3 11/16/2022 11:30:50 host/uisproxy-rop@***.***.CORP
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
David Touzeau - Artica Tech France
Development team, level 3 support
----------------------------------
P: +33 6 58 44 69 46
www:https://wiki.articatech.com
www:http://articatech.net  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221117/fa648815/attachment.htm>

From squid3 at treenet.co.nz  Thu Nov 17 04:35:24 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 17 Nov 2022 17:35:24 +1300
Subject: [squid-users] transparent mode squid on centos 9 with iptables
 (part 2)
In-Reply-To: <CAKM+x_JwQt+4jwVsfzgdj-x-DoWC77TqYROS44+cux0asdAADw@mail.gmail.com>
References: <CAKM+x_L67p0YjP3BPwSU=cp8PrQcG-CVH7jzmT80AB=ym3u4Vw@mail.gmail.com>
 <CAKM+x_JRkR2vNgT_zqcQAd3qXTwQMXDa8mJeEY+R6FYXDiFB0g@mail.gmail.com>
 <CAKM+x_K5XA0oTvEsGkzwHuYbVVYXe+1UegWCW2b37_pATX7mDQ@mail.gmail.com>
 <CAKM+x_JwQt+4jwVsfzgdj-x-DoWC77TqYROS44+cux0asdAADw@mail.gmail.com>
Message-ID: <07c330f7-4de8-bc8f-3aab-a00c12baa157@treenet.co.nz>

On 17/11/2022 9:14 am, Lola Lo wrote:
> Hi guys.
>
>
> Could you please send a tutorial or any good guidance to implement? 
> squid on transparent mode on centos 9 with iptables.
>

The configuration details for what you appear to be trying to configure 
are here:
 ?<https://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect>

My comments below relate to how your attempt differs and how to fix.

> I have configured squid.conf with this parameters:
>
>
>
> ens192: 172.31.168.28, internet interface
>
> ens224: 192.168.1.10, LAN interface (private network)
>
>
> # Mis ACLs #
>
> acl mi_red src 192.168.1.0/24 <http://192.168.1.0/24>
>
> acl cliente_linux src 192.168.1.20
>
> acl cliente_windows src 192.168.1.30
>
> acl sitios1 url_regex "/etc/squid/listas/sitios1"
>
> acl sitios2 url_regex "/etc/squid/listas/sitios2"
>
>
> # Squid normally listens to port 3128
>
> http_port 3128
>
> http_port 8080 transparent
>
>

Firstly, use "intercept" instead of "transparent" with modern Squid.

Secondly, remember that only port 8080 is setup to receive intercepted 
traffic. Port 3128 still receives normal forward-proxy traffic.

> I want the ?deny all? rule get applied to test the client using the proxy
>
>

You have not shown any http_access lines from your config. There is a 
clear bug in your NAT which explains the behaviour so I will assume that 
the squid.conf policy does what you want.


> My iptables is configured as follows:
>
>
> #!/bin/bash
>
>
> ## NAT server configuration ##
>
>
> sysctl -w net.ipv4.ip_forward=1
>
> sysctl -p
>
> iptables -X
>
> iptables -F
>
> iptables -t nat -X
>
> iptables -t nat -F
>
> iptables -I INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
>
> iptables -I FORWARD-m state --state RELATED,ESTABLISHED -j ACCEPT
>
> iptables -t nat -I POSTROUTING -o ens192 -j MASQUERADE
>
>
>

Why is this a different script?
Ideally the firewall rules should be as atomic as possible to avoid 
connections being setup with only part of the rules applied.


>
> #!/bin/bash
>
>
> ## proxy server configuration ##
>
>
> ### Accepting traffic for the ports: 3128 and 8080##
>
>
> iptables -A INPUT -s 192.168.1.0/24 <http://192.168.1.0/24> -p tcp 
> --dport 3128 -j ACCEPT
>
> iptables -A INPUT -p tcp --dport 3128 -j DROP
>

Do not accept traffic directly to the port 8080. Also Squid does not 
make outbound connections from its listening ports.
So these ...

> iptables -A OUTPUT -d 192.168.1.0/24 <http://192.168.1.0/24> -p tcp 
> --sport 3128 -j ACCEPT
>
> iptables -A OUTPUT -p tcp --sport 3128 -j DROP
>
>
> iptables -A INPUT -s 192.168.1.0/24 <http://192.168.1.0/24> -p tcp 
> --dport 8080 -j ACCEPT
>
> iptables -A INPUT -p tcp --dport 8080 -j DROP
>
> iptables -A OUTPUT -d 192.168.1.0/24 <http://192.168.1.0/24> -p tcp 
> --sport 8080 -j ACCEPT
>
> iptables -A OUTPUT -p tcp --sport 8080 -j DROP
>
>

... should be replaced with:

   iptables -t mangle -A PREROUTING -p tcp --dport 8080 -j DROP


>
> `### Accepting traffic for the ports: 3128 and 8080##
>
>
> iptables -t nat -A POSTROUTING -o ens192 -j MASQUERADE
>

You are missing a rule to allow Squid outbound traffic to avoid the NAT.

   iptables -t nat -A PREROUTING -s 192.168.1.10 -p tcp --dport 80 -j ACCEPT

> iptables -t nat -A PREROUTING -s 192.168.1.0/24 
> <http://192.168.1.0/24> -p tcp --dport 80 -j REDIRECT --to-port 8080
>
> iptables -t nat -A PREROUTING -s 192.168.1.0/24 
> <http://192.168.1.0/24> -p tcp --dport 443 -j REDIRECT --to-port 8080
>
>

Port 8080 in your squid.conf can only handle port 80 traffic syntax.

Port 443 is a more tricky situation. I recommend removing that until you 
have the port 80 working.


>
> But I got this error:
>
>
> 1668381894.7460 192.168.1.20 NONE_NONE/000 0 - 
> error:transaction-end-before-headers - HIER_NONE/- -
>
> 1668381967.8000 192.168.1.20 NONE_NONE/400 3690 - 
> error:invalid-request - HIER_NONE/- text/html
>

This is likely from the missing NAT rule allowing Squid outbound.

If the above changes do not fix everything make sure that you test 
exactly what the real clients will be doing. Specifically that they are 
making contact to servers on port 80 or directly to Squid port 3128. 
They know *nothing* about port 8080 existence so have no reason to send 
anything that way directly.


HTH
Amos



From squid3 at treenet.co.nz  Thu Nov 17 06:06:58 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 17 Nov 2022 19:06:58 +1300
Subject: [squid-users] moving squid from centos 7 to ubuntu 22.04
In-Reply-To: <CAGU_CiKK5w8+CM+=XLzaUtYS_kqO9iEVKZt2i1i1wES9Cxn-LQ@mail.gmail.com>
References: <CAGU_CiKK5w8+CM+=XLzaUtYS_kqO9iEVKZt2i1i1wES9Cxn-LQ@mail.gmail.com>
Message-ID: <51294f1b-3c4b-73d0-d345-1773bc75cd58@treenet.co.nz>

On 16/11/2022 6:31 am, robert k Wild wrote:
> hi all,
>
> atm i have written a script, once you have built a centos 7 VM, you 
> just run the script and after the reboot its a complete running 
> squidclamAV server
>
> i'm going to be moving the script to a ubuntu server as centos 7 is 
> dead now (as i run clamAV on it, clamAV will stop getting virus 
> definitions 2024 as i use this for virus scanning of internet packets)
>
> just want to know what lines i need to adjust to work with ubuntu 
> instead of centos, obviously i know instead of yum install.... its apt 
> install
>

My comments below assume that you want to keep the exact versions as-is 
and custom build.

Otherwise, if you are okay following Ubuntu's official packages and 
security fixes things could be a lot different (and simpler).


> heres my long script
>
> #!/bin/bash
> #
> #this script will download/install and configure the following packages
> #
> #squid - proxy server
> #squid ssl bump - intercept HTTPS traffic
> #clamAV - antivirus engine inc trojans,viruses,malware
> #c-icap - icap server
> #squidclamav - that integrates all the above in squid

You may not be aware squidclamav has been replaced with eCAP ClamAV module:
<https://www.e-cap.org/downloads/>

Ubuntu provides libecap package and Squid has support auto-enabled for it.
So all you should need to do is build the ecap-clamav adaptor and 
configure it for use.


> #whitelist URL's
> #deny MIME types
> #
> #on the PROD host you only need squid
> #
> #first things first lets disable firewalld and SElinux
> #
> systemctl stop firewalld
> systemctl disable firewalld
> sed -i -e 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config
> #
> #squid packages
> #
> yum install -y epel-release screen rsync net-tools ethtool swaks sed 
> tar zip unzip curl telnet openssl openssl-devel bzip2-devel libarchive 
> libarchive-devel perl perl-Data-Dumper gcc gcc-c++ binutils autoconf 
> automake make sudo wget libxml2-devel libcap-devel libtool-ltdl-devel
> #

Drop "epel-release" as irrelevant on Ubuntu.

Ubuntu developer packages have "-dev" suffix instead of "-devel". So all 
those should change.

To get access to simpler source building I recommend altering the apt 
configuration like so:

 ??? sudo sed --in-place -E 's/# (deb-src.*updates main)/? \1/g' 
/etc/apt/sources.list
 ??? sudo apt-get --quiet=2 update


There are some trivial package naming differences. When apt complains 
about not finding a package you can use
<https://packages.ubuntu.com/search> to search for the Ubuntu naming 
and/or any alternatives.


Many of those are not related to Squid in any way. Perhapse separate 
them into a different install command?

After the above deb-src change the packages needed to build Squid for 
Ubuntu can be installed like so:

 ??? sudo apt-get --quiet=2 build-dep squid

Similar commands also for clamav, c-icap any others which Ubuntu 
provides packages for.

After that build-dep command you only need to install dependencies if 
the Ubuntu package lacks support.
For example, Ubuntu older than 21.10 lack openssl natively, so "apt 
install libssl-dev" may be needed specially.


> #clamAV packages
> #
> yum install -y clamav-server clamav-data clamav-update 
> clamav-filesystem clamav clamav-scanner-systemd clamav-devel 
> clamav-lib clamav-server-systemd
> #


> #download and compile from source
> #
> cd /tmp
> wget http://www.squid-cache.org/Versions/v4/squid-4.17.tar.gz
> wget 
> http://sourceforge.net/projects/c-icap/files/c-icap/0.5.x/c_icap-0.5.10.tar.gz 
> --no-check-certificate
> wget 
> http://sourceforge.net/projects/c-icap/files/c-icap-modules/0.5.x/c_icap_modules-0.5.5.tar.gz 
> --no-check-certificate
> wget 
> https://sourceforge.net/projects/squidclamav/files/squidclamav/7.1/squidclamav-7.1.tar.gz 
> --no-check-certificate
> #
> for f in *.tar.gz; do tar xf "$f"; done
> #
> cd /tmp/squid-4.17
> ./configure --with-openssl --enable-ssl-crtd --enable-icap-client 
> --enable-http-violations && make && make install

The prefix can be a bit different on Debian/Ubuntu. To ensure it is 
right add --prefix=/usr/local to the above options.


> #
> cd /tmp/c_icap-0.5.10
> ./configure 'CXXFLAGS=-O2 -m64 -pipe' 'CFLAGS=-O2 -m64 -pipe' 
> --without-bdb --prefix=/usr/local && make && make install
> #
> cd /tmp/squidclamav-7.1
> ./configure 'CXXFLAGS=-O2 -m64 -pipe' 'CFLAGS=-O2 -m64 -pipe' 
> --with-c-icap=/usr/local --with-libarchive && make && make install
> #
> cd /tmp/c_icap_modules-0.5.5
> ./configure 'CFLAGS=-O3 -m64 -pipe' 
> 'CPPFLAGS=-I/usr/local/clamav/include' 'LDFLAGS=-L/usr/local/lib 
> -L/usr/local/clamav/lib/' && make && make install
> #
> #creating shortcuts and copying files
> #
> cp -f /usr/local/squid/etc/squid.conf /usr/local/squid/etc/squid.conf.orig
> cp -f /usr/local/etc/c-icap.conf /usr/local/etc/c-icap.conf.orig
> cp -f /usr/local/etc/squidclamav.conf /usr/local/etc/squidclamav.conf.orig
> cp -f /usr/local/etc/clamav_mod.conf /usr/local/etc/clamav_mod.conf.orig
> cp -f /usr/local/etc/virus_scan.conf /usr/local/etc/virus_scan.conf.orig
> #
> ln -s /usr/local/squid/etc/squid.conf /etc
> ln -s /usr/local/etc/c-icap.conf /etc
> ln -s /usr/local/etc/squidclamav.conf /etc
> ln -s /usr/local/etc/clamav_mod.conf /etc
> ln -s /usr/local/etc/virus_scan.conf /etc
> #
> mkdir -p /usr/local/clamav/share/clamav
> ln -s /var/lib/clamav /usr/local/clamav/share/clamav
> #
> #tmpfiles for run files
> #
> echo "d /var/run/c-icap 0755 root root -" >> /etc/tmpfiles.d/c-icap.conf
> echo "d /var/run/clamav 0755 root root -" >> /etc/tmpfiles.d/clamav.conf
> #
> #original squid config
> #
> sed -i '/http_port 3128/d' /usr/local/squid/etc/squid.conf
> sed -i -e 's%http_access deny !Safe_ports%#http_access deny 
> !Safe_ports%g' /usr/local/squid/etc/squid.conf
> sed -i -e 's%http_access deny CONNECT !SSL_ports%#http_access deny 
> CONNECT !SSL_ports%g' /usr/local/squid/etc/squid.conf

Reason? this opens a large number of security vulnerabilities.


Modern Squid have an "include" directive to import extra squid.conf 
rules from other files and/or directories.
I recommend adding this one line to squid.conf under where it says 
"|INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS"|:

|include /etc/squid/conf.d/*.conf|

then placing all your custom Squid files in that conf.d directory.


> #
> #create URL, MIME and public key list
> #
> echo "#eicar" >> /usr/local/squid/etc/urlwhite.txt
> echo ".eicar.org <http://eicar.org>" >> /usr/local/squid/etc/urlwhite.txt
> #
> echo "http://updater.maxon.net/server_test" >> 
> /usr/local/squid/etc/urlspecial.txt
> #
> echo "application/octet-stream" >> /usr/local/squid/etc/mimedeny.txt
> echo "application/x-msi" >> /usr/local/squid/etc/mimedeny.txt
> echo "application/zip" >> /usr/local/squid/etc/mimedeny.txt
> echo "application/x-7z-compressed" >> /usr/local/squid/etc/mimedeny.txt
> echo "application/vnd.ms-cab-compressed" >> 
> /usr/local/squid/etc/mimedeny.txt
> echo "application/x-msdownload" >> /usr/local/squid/etc/mimedeny.txt
> echo "application/x-iso9660-image" >> /usr/local/squid/etc/mimedeny.txt

FWIW: squid config files are all agnostic to whitespace indentation. So 
you should be able to improve script readability like this:

 ?echo "
 ?? blah
 ?? blah
 ?? blah
 ?? blah
" >> path/to/file


Also, I see that you are adding systemd integration for the other software.
There is a file in squid tarball at tools/systemd/squid.service that can 
be installed to add that.
You will need to adjust the binary paths inside it to your custom 
/usr/local ones.

Also, consider using logrotate package to manage the log files instead 
of cron.


HTH
Amos



From robertkwild at gmail.com  Thu Nov 17 08:21:07 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 17 Nov 2022 08:21:07 +0000
Subject: [squid-users] moving squid from centos 7 to ubuntu 22.04
In-Reply-To: <51294f1b-3c4b-73d0-d345-1773bc75cd58@treenet.co.nz>
References: <CAGU_CiKK5w8+CM+=XLzaUtYS_kqO9iEVKZt2i1i1wES9Cxn-LQ@mail.gmail.com>
 <51294f1b-3c4b-73d0-d345-1773bc75cd58@treenet.co.nz>
Message-ID: <CAGU_CiJ=gQU+84c4MnWxaN68iE5vri+Q9NmqSyL5ODWA25U3qw@mail.gmail.com>

Wow thanks Amos so much for this,

You think if I build it on rocky Linux, it would be easier?

On Thu, 17 Nov 2022, 06:07 Amos Jeffries, <squid3 at treenet.co.nz> wrote:

> On 16/11/2022 6:31 am, robert k Wild wrote:
> > hi all,
> >
> > atm i have written a script, once you have built a centos 7 VM, you
> > just run the script and after the reboot its a complete running
> > squidclamAV server
> >
> > i'm going to be moving the script to a ubuntu server as centos 7 is
> > dead now (as i run clamAV on it, clamAV will stop getting virus
> > definitions 2024 as i use this for virus scanning of internet packets)
> >
> > just want to know what lines i need to adjust to work with ubuntu
> > instead of centos, obviously i know instead of yum install.... its apt
> > install
> >
>
> My comments below assume that you want to keep the exact versions as-is
> and custom build.
>
> Otherwise, if you are okay following Ubuntu's official packages and
> security fixes things could be a lot different (and simpler).
>
>
> > heres my long script
> >
> > #!/bin/bash
> > #
> > #this script will download/install and configure the following packages
> > #
> > #squid - proxy server
> > #squid ssl bump - intercept HTTPS traffic
> > #clamAV - antivirus engine inc trojans,viruses,malware
> > #c-icap - icap server
> > #squidclamav - that integrates all the above in squid
>
> You may not be aware squidclamav has been replaced with eCAP ClamAV module:
> <https://www.e-cap.org/downloads/>
>
> Ubuntu provides libecap package and Squid has support auto-enabled for it.
> So all you should need to do is build the ecap-clamav adaptor and
> configure it for use.
>
>
> > #whitelist URL's
> > #deny MIME types
> > #
> > #on the PROD host you only need squid
> > #
> > #first things first lets disable firewalld and SElinux
> > #
> > systemctl stop firewalld
> > systemctl disable firewalld
> > sed -i -e 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config
> > #
> > #squid packages
> > #
> > yum install -y epel-release screen rsync net-tools ethtool swaks sed
> > tar zip unzip curl telnet openssl openssl-devel bzip2-devel libarchive
> > libarchive-devel perl perl-Data-Dumper gcc gcc-c++ binutils autoconf
> > automake make sudo wget libxml2-devel libcap-devel libtool-ltdl-devel
> > #
>
> Drop "epel-release" as irrelevant on Ubuntu.
>
> Ubuntu developer packages have "-dev" suffix instead of "-devel". So all
> those should change.
>
> To get access to simpler source building I recommend altering the apt
> configuration like so:
>
>      sudo sed --in-place -E 's/# (deb-src.*updates main)/  \1/g'
> /etc/apt/sources.list
>      sudo apt-get --quiet=2 update
>
>
> There are some trivial package naming differences. When apt complains
> about not finding a package you can use
> <https://packages.ubuntu.com/search> to search for the Ubuntu naming
> and/or any alternatives.
>
>
> Many of those are not related to Squid in any way. Perhapse separate
> them into a different install command?
>
> After the above deb-src change the packages needed to build Squid for
> Ubuntu can be installed like so:
>
>      sudo apt-get --quiet=2 build-dep squid
>
> Similar commands also for clamav, c-icap any others which Ubuntu
> provides packages for.
>
> After that build-dep command you only need to install dependencies if
> the Ubuntu package lacks support.
> For example, Ubuntu older than 21.10 lack openssl natively, so "apt
> install libssl-dev" may be needed specially.
>
>
> > #clamAV packages
> > #
> > yum install -y clamav-server clamav-data clamav-update
> > clamav-filesystem clamav clamav-scanner-systemd clamav-devel
> > clamav-lib clamav-server-systemd
> > #
>
>
> > #download and compile from source
> > #
> > cd /tmp
> > wget http://www.squid-cache.org/Versions/v4/squid-4.17.tar.gz
> > wget
> >
> http://sourceforge.net/projects/c-icap/files/c-icap/0.5.x/c_icap-0.5.10.tar.gz
> > --no-check-certificate
> > wget
> >
> http://sourceforge.net/projects/c-icap/files/c-icap-modules/0.5.x/c_icap_modules-0.5.5.tar.gz
> > --no-check-certificate
> > wget
> >
> https://sourceforge.net/projects/squidclamav/files/squidclamav/7.1/squidclamav-7.1.tar.gz
> > --no-check-certificate
> > #
> > for f in *.tar.gz; do tar xf "$f"; done
> > #
> > cd /tmp/squid-4.17
> > ./configure --with-openssl --enable-ssl-crtd --enable-icap-client
> > --enable-http-violations && make && make install
>
> The prefix can be a bit different on Debian/Ubuntu. To ensure it is
> right add --prefix=/usr/local to the above options.
>
>
> > #
> > cd /tmp/c_icap-0.5.10
> > ./configure 'CXXFLAGS=-O2 -m64 -pipe' 'CFLAGS=-O2 -m64 -pipe'
> > --without-bdb --prefix=/usr/local && make && make install
> > #
> > cd /tmp/squidclamav-7.1
> > ./configure 'CXXFLAGS=-O2 -m64 -pipe' 'CFLAGS=-O2 -m64 -pipe'
> > --with-c-icap=/usr/local --with-libarchive && make && make install
> > #
> > cd /tmp/c_icap_modules-0.5.5
> > ./configure 'CFLAGS=-O3 -m64 -pipe'
> > 'CPPFLAGS=-I/usr/local/clamav/include' 'LDFLAGS=-L/usr/local/lib
> > -L/usr/local/clamav/lib/' && make && make install
> > #
> > #creating shortcuts and copying files
> > #
> > cp -f /usr/local/squid/etc/squid.conf
> /usr/local/squid/etc/squid.conf.orig
> > cp -f /usr/local/etc/c-icap.conf /usr/local/etc/c-icap.conf.orig
> > cp -f /usr/local/etc/squidclamav.conf
> /usr/local/etc/squidclamav.conf.orig
> > cp -f /usr/local/etc/clamav_mod.conf /usr/local/etc/clamav_mod.conf.orig
> > cp -f /usr/local/etc/virus_scan.conf /usr/local/etc/virus_scan.conf.orig
> > #
> > ln -s /usr/local/squid/etc/squid.conf /etc
> > ln -s /usr/local/etc/c-icap.conf /etc
> > ln -s /usr/local/etc/squidclamav.conf /etc
> > ln -s /usr/local/etc/clamav_mod.conf /etc
> > ln -s /usr/local/etc/virus_scan.conf /etc
> > #
> > mkdir -p /usr/local/clamav/share/clamav
> > ln -s /var/lib/clamav /usr/local/clamav/share/clamav
> > #
> > #tmpfiles for run files
> > #
> > echo "d /var/run/c-icap 0755 root root -" >> /etc/tmpfiles.d/c-icap.conf
> > echo "d /var/run/clamav 0755 root root -" >> /etc/tmpfiles.d/clamav.conf
> > #
> > #original squid config
> > #
> > sed -i '/http_port 3128/d' /usr/local/squid/etc/squid.conf
> > sed -i -e 's%http_access deny !Safe_ports%#http_access deny
> > !Safe_ports%g' /usr/local/squid/etc/squid.conf
> > sed -i -e 's%http_access deny CONNECT !SSL_ports%#http_access deny
> > CONNECT !SSL_ports%g' /usr/local/squid/etc/squid.conf
>
> Reason? this opens a large number of security vulnerabilities.
>
>
> Modern Squid have an "include" directive to import extra squid.conf
> rules from other files and/or directories.
> I recommend adding this one line to squid.conf under where it says
> "|INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS"|:
>
> |include /etc/squid/conf.d/*.conf|
>
> then placing all your custom Squid files in that conf.d directory.
>
>
> > #
> > #create URL, MIME and public key list
> > #
> > echo "#eicar" >> /usr/local/squid/etc/urlwhite.txt
> > echo ".eicar.org <http://eicar.org>" >>
> /usr/local/squid/etc/urlwhite.txt
> > #
> > echo "http://updater.maxon.net/server_test" >>
> > /usr/local/squid/etc/urlspecial.txt
> > #
> > echo "application/octet-stream" >> /usr/local/squid/etc/mimedeny.txt
> > echo "application/x-msi" >> /usr/local/squid/etc/mimedeny.txt
> > echo "application/zip" >> /usr/local/squid/etc/mimedeny.txt
> > echo "application/x-7z-compressed" >> /usr/local/squid/etc/mimedeny.txt
> > echo "application/vnd.ms-cab-compressed" >>
> > /usr/local/squid/etc/mimedeny.txt
> > echo "application/x-msdownload" >> /usr/local/squid/etc/mimedeny.txt
> > echo "application/x-iso9660-image" >> /usr/local/squid/etc/mimedeny.txt
>
> FWIW: squid config files are all agnostic to whitespace indentation. So
> you should be able to improve script readability like this:
>
>   echo "
>     blah
>     blah
>     blah
>     blah
> " >> path/to/file
>
>
> Also, I see that you are adding systemd integration for the other software.
> There is a file in squid tarball at tools/systemd/squid.service that can
> be installed to add that.
> You will need to adjust the binary paths inside it to your custom
> /usr/local ones.
>
> Also, consider using logrotate package to manage the log files instead
> of cron.
>
>
> HTH
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221117/150716c6/attachment.htm>

From squid3 at treenet.co.nz  Thu Nov 17 09:29:29 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 17 Nov 2022 22:29:29 +1300
Subject: [squid-users] moving squid from centos 7 to ubuntu 22.04
In-Reply-To: <CAGU_CiJ=gQU+84c4MnWxaN68iE5vri+Q9NmqSyL5ODWA25U3qw@mail.gmail.com>
References: <CAGU_CiKK5w8+CM+=XLzaUtYS_kqO9iEVKZt2i1i1wES9Cxn-LQ@mail.gmail.com>
 <51294f1b-3c4b-73d0-d345-1773bc75cd58@treenet.co.nz>
 <CAGU_CiJ=gQU+84c4MnWxaN68iE5vri+Q9NmqSyL5ODWA25U3qw@mail.gmail.com>
Message-ID: <af0afcba-3518-f576-1ba1-9a2cb3d678ce@treenet.co.nz>

On 17/11/2022 9:21 pm, robert k Wild wrote:
> Wow thanks Amos so much for this,
>
> You think if I build it on rocky Linux, it would be easier?
>

I am not familiar with Rocky Linux beyond its existence.
I expect it would be similar to CentOS since both are in the RHEL family.

Amos



From alex.kimble at viewpointe.com  Thu Nov 17 15:57:03 2022
From: alex.kimble at viewpointe.com (Alex Kimble)
Date: Thu, 17 Nov 2022 15:57:03 +0000
Subject: [squid-users] How to generate daily usage email reports?
In-Reply-To: <CY4PR2201MB154306967FEE539B3DC10E8E8B049@CY4PR2201MB1543.namprd22.prod.outlook.com>
References: <CY4PR2201MB1543FAEDB0F8D2B66FEFC5458B049@CY4PR2201MB1543.namprd22.prod.outlook.com>
 <CY4PR2201MB154306967FEE539B3DC10E8E8B049@CY4PR2201MB1543.namprd22.prod.outlook.com>
Message-ID: <CY4PR2201MB15439DD5E2702AE28A1101B48B069@CY4PR2201MB1543.namprd22.prod.outlook.com>

Greetings Squid users,

I have 2 questions:


  1.  What are some good ways to generate a daily usage report which I can receive in email format .csv or .html is fine (top users, top URLs, blocked URLs)
  2.  Can daily usage reports be created and emailed from Squidanalyzer or is that just eye candy?

Thank you!

Alex
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221117/2845ecd0/attachment.htm>

From rafael.akchurin at diladele.com  Thu Nov 17 16:02:53 2022
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 17 Nov 2022 16:02:53 +0000
Subject: [squid-users] How to generate daily usage email reports?
In-Reply-To: <CY4PR2201MB15439DD5E2702AE28A1101B48B069@CY4PR2201MB1543.namprd22.prod.outlook.com>
References: <CY4PR2201MB1543FAEDB0F8D2B66FEFC5458B049@CY4PR2201MB1543.namprd22.prod.outlook.com>
 <CY4PR2201MB154306967FEE539B3DC10E8E8B049@CY4PR2201MB1543.namprd22.prod.outlook.com>
 <CY4PR2201MB15439DD5E2702AE28A1101B48B069@CY4PR2201MB1543.namprd22.prod.outlook.com>
Message-ID: <AM8PR04MB774539A0B1A57EE8CE3B99B08F069@AM8PR04MB7745.eurprd04.prod.outlook.com>

Hello Alex,

We have something like you seem to be in need of -  https://docs.diladele.com/administrator_guide_stable/traffic_monitoring/reports.html
But these reports are not Squid analyzer :( sorry.

Best regards,
Rafael

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Alex Kimble
Sent: Thursday, November 17, 2022 4:57 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] How to generate daily usage email reports?

Greetings Squid users,

I have 2 questions:


  1.  What are some good ways to generate a daily usage report which I can receive in email format .csv or .html is fine (top users, top URLs, blocked URLs)
  2.  Can daily usage reports be created and emailed from Squidanalyzer or is that just eye candy?

Thank you!

Alex
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221117/155c7798/attachment.htm>

From support at unveiltech.com  Thu Nov 17 16:02:54 2022
From: support at unveiltech.com (UnveilTech - Support)
Date: Thu, 17 Nov 2022 16:02:54 +0000
Subject: [squid-users] Squid 5: server_cert_fingerprint not working
 fine...
In-Reply-To: <3adf99e022084a76b0f18ffb1f3f605f@unveiltech.com>
References: <3adf99e022084a76b0f18ffb1f3f605f@unveiltech.com>
Message-ID: <ab1b5b8d00874760a80cecf61772aeaa@unveiltech.com>

Hello Squid Team,

Can you have a look to this bugzilla case :
https://bugs.squid-cache.org/show_bug.cgi?id=5245

it's about a bug with Squid 5.7 and TLS 1.3.
Critical case created the 2022-10-27 09:59 UTC, it would be nice to have a fix/patch...

Thanks in advance.

Best regards,
Bye Fred

De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de UnveilTech - Support
Envoy? : mardi 25 octobre 2022 18:22
? : squid-users at lists.squid-cache.org
Objet : [squid-users] Squid 5: server_cert_fingerprint not working fine...

Hello,


Here is the part of our squid.conf on Squid 5 :

...

acl my_cf1_list server_cert_fingerprint '/etc/squid5/CF1.txt'

ssl_bump peek all

ssl_bump terminate my_cf1_list

ssl_bump splice all

...



We're not sure about the ssl_bump keys and options to use here, to be honnest we've already spend hours to find the right way to make it working fine.



Here are some samples from the CF1.txt file:

# dayznews.biz

FB:EC:F7:AE:F4:BD:F4:85:68:C0:81:65:99:BA:7D:D3:FA:F8:51:74

# cdeveloper.cn

94:0A:C0:53:A0:E9:74:CE:91:12:6E:FD:06:57:08:58:B2:A5:76:10


1.       Is the server_cert_fingerprint working correctly or are there any bugs with the v5 ?

2.       Are the ssl_bump options/order correct ?

Any tips are welcome, thanks in advance...

Best regards,
Bye Fred
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221117/e6829d22/attachment.htm>

From makleking at yandex.ru  Fri Nov 18 02:54:22 2022
From: makleking at yandex.ru (=?utf-8?B?0JzQuNGF0LDQuNC7?=)
Date: Fri, 18 Nov 2022 10:54:22 +0800
Subject: [squid-users] Kerberos - Cannot decrypt ticket for HTTP
In-Reply-To: <b9ffb62c-3c84-5380-dbf1-81af6c93e794@articatech.com>
References: <1783041668571106@mail.yandex.ru>
 <b9ffb62c-3c84-5380-dbf1-81af6c93e794@articatech.com>
Message-ID: <594301668737598@mail.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221118/fa70840a/attachment.htm>

From squid3 at treenet.co.nz  Fri Nov 18 05:34:01 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 18 Nov 2022 18:34:01 +1300
Subject: [squid-users] Squid 5: server_cert_fingerprint not working
 fine...
In-Reply-To: <ab1b5b8d00874760a80cecf61772aeaa@unveiltech.com>
References: <3adf99e022084a76b0f18ffb1f3f605f@unveiltech.com>
 <ab1b5b8d00874760a80cecf61772aeaa@unveiltech.com>
Message-ID: <67763d66-e264-14a1-f599-224749c18f71@treenet.co.nz>

On 18/11/2022 5:02 am, UnveilTech - Support wrote:
>
> Hello Squid Team,
>
> Can you have a look to this bugzilla case?:
>
> https://bugs.squid-cache.org/show_bug.cgi?id=5245
>
> it?s about a bug with Squid 5.7 and TLS 1.3.
>
> Critical case created the 2022-10-27 09:59 UTC, it would be nice to 
> have a fix/patch?
>
> ? occur)
>

As one can see in the bug report Alex has looked at it in some detail.
The solution may be complex or large change, and thus unlikely to occur 
in Squid-5 if so.

There are three things that come to mind immediately as related problems 
we cannot do anything about:
 ?1) Squid cannot know in advance what server cert will be provided 
(after step2) when it decided to splice (or not) at step2.
 ?2) SHA1 is not the only type of cert fingerprint. The non-working 
certs may be providing newer SHA2/3 etc fingerprints
 ?3) In TLS/1.3 a lot of data can be hidden inside the encryption. Squid 
may simply not be given access to the [real] fingerprint unless bump 
(decrypt) happens.

HTH
Amos



From robertkwild at gmail.com  Fri Nov 18 07:33:32 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Fri, 18 Nov 2022 07:33:32 +0000
Subject: [squid-users] moving squid from centos 7 to ubuntu 22.04
In-Reply-To: <af0afcba-3518-f576-1ba1-9a2cb3d678ce@treenet.co.nz>
References: <CAGU_CiKK5w8+CM+=XLzaUtYS_kqO9iEVKZt2i1i1wES9Cxn-LQ@mail.gmail.com>
 <51294f1b-3c4b-73d0-d345-1773bc75cd58@treenet.co.nz>
 <CAGU_CiJ=gQU+84c4MnWxaN68iE5vri+Q9NmqSyL5ODWA25U3qw@mail.gmail.com>
 <af0afcba-3518-f576-1ba1-9a2cb3d678ce@treenet.co.nz>
Message-ID: <CAGU_CiJ+NZHBvP_5NF7pPddikx+r9=zrTQG9fKqrg+PFRLvpEA@mail.gmail.com>

Hi Amos,

thats fine, youve been more than helpful, thank you

this is where i learnt how to run squid with cicap

https://squidclamav.darold.net/documentation.html

have you got a good how to about running squid with e cap

whats the difference anyway between Icap and Ecap?

On Thu, 17 Nov 2022 at 09:29, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 17/11/2022 9:21 pm, robert k Wild wrote:
> > Wow thanks Amos so much for this,
> >
> > You think if I build it on rocky Linux, it would be easier?
> >
>
> I am not familiar with Rocky Linux beyond its existence.
> I expect it would be similar to CentOS since both are in the RHEL family.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221118/4fe9c78f/attachment.htm>

From support at unveiltech.com  Fri Nov 18 13:55:44 2022
From: support at unveiltech.com (UnveilTech - Support)
Date: Fri, 18 Nov 2022 13:55:44 +0000
Subject: [squid-users] Squid 5: server_cert_fingerprint not working
 fine...
In-Reply-To: <67763d66-e264-14a1-f599-224749c18f71@treenet.co.nz>
References: <3adf99e022084a76b0f18ffb1f3f605f@unveiltech.com>
 <ab1b5b8d00874760a80cecf61772aeaa@unveiltech.com>
 <67763d66-e264-14a1-f599-224749c18f71@treenet.co.nz>
Message-ID: <796a78058b01409f8cd220f3a33a27ae@unveiltech.com>

Hi Amos,

We have tested with a "ssl_bump bump" ("ssl_bump all" and "ssl_bump bump sslstep1"), it does not solve the problem.
According to Alex, we can also confirm it's a bug with Squid 5.x and TLS 1.3.
It seems Squid is only compatible with TLS 1.2, it's not good for the future...

Bye Fred

-----Message d'origine-----
De?: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Amos Jeffries
Envoy??: vendredi 18 novembre 2022 06:34
??: squid-users at lists.squid-cache.org
Objet?: Re: [squid-users] Squid 5: server_cert_fingerprint not working fine...

On 18/11/2022 5:02 am, UnveilTech - Support wrote:
>
> Hello Squid Team,
>
> Can you have a look to this bugzilla case?:
>
> https://bugs.squid-cache.org/show_bug.cgi?id=5245
>
> it?s about a bug with Squid 5.7 and TLS 1.3.
>
> Critical case created the 2022-10-27 09:59 UTC, it would be nice to 
> have a fix/patch?
>
> ? occur)
>

As one can see in the bug report Alex has looked at it in some detail.
The solution may be complex or large change, and thus unlikely to occur in Squid-5 if so.

There are three things that come to mind immediately as related problems we cannot do anything about:
 ?1) Squid cannot know in advance what server cert will be provided (after step2) when it decided to splice (or not) at step2.
 ?2) SHA1 is not the only type of cert fingerprint. The non-working certs may be providing newer SHA2/3 etc fingerprints
 ?3) In TLS/1.3 a lot of data can be hidden inside the encryption. Squid may simply not be given access to the [real] fingerprint unless bump
(decrypt) happens.

HTH
Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From klaus_brandl at genua.de  Fri Nov 18 14:22:35 2022
From: klaus_brandl at genua.de (Klaus Brandl)
Date: Fri, 18 Nov 2022 14:22:35 +0000
Subject: [squid-users] Kerberos - Cannot decrypt ticket for HTTP
In-Reply-To: <594301668737598@mail.yandex.ru>
References: <1783041668571106@mail.yandex.ru>
 <b9ffb62c-3c84-5380-dbf1-81af6c93e794@articatech.com>
 <594301668737598@mail.yandex.ru>
Message-ID: <38e403c49727fa5300d81e1a7cef08066d9d1e72.camel@genua.de>

which options do you have configured for the auth helper?
Something like:

auth_param negotiate program
/usr/local/libexec/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME -i

Best regards

Klaus

Am Freitag, dem 18.11.2022 um 10:54 +0800 schrieb ??????:
> Hi David,
>  
> Thanks for your advice but it doesn't help me. I use AD account which
> haven't set these parameters.
>  
> Misha.
>  
> 17.11.2022, 10:07, "David Touzeau" <david at articatech.com>:
> > Hi
> > 
> > perhaps this one
> > https://wiki.articatech.com/en/proxy-service/troubleshooting/gss-cannot-decrypt-ticket
> > 
> >  
> > Le 16/11/2022 ? 05:11, ?????? a ?crit :
> > > Hi everybody,
> > >  
> > > Could you help me to setup my new squid server? I have a problem
> > > with keytab authorization.
> > >  
> > > 2022/11/16 11:35:39| ERROR: Negotiate Authentication validating
> > > user. Result: {result=BH, notes={message:
> > > gss_accept_sec_context() failed: Unspecified GSS failure.  Minor
> > > code may provide more information. Cannot decrypt ticket for
> > > HTTP/uisproxy-rop.***.***.corp@***.***.CORP using keytab key for
> > > HTTP/uisproxy-rop.***.***.corp@***.**.CORP; }}
> > > Got NTLMSSP neg_flags=0xe2088297
> > > 2022/11/16 11:35:40| ERROR: Negotiate Authentication validating
> > > user. Result: {result=BH, notes={message:
> > > gss_accept_sec_context() failed: Unspecified GSS failure.  Minor
> > > code may provide more information. Cannot decrypt ticket for
> > > HTTP/uisproxy-rop.***.***.corp@***.***.CORP using keytab key for
> > > HTTP/uisproxy-rop.***.***.corp@***.***.CORP; }}
> > >  
> > > # kinit -V -k -t /etc/squid/keytab/uisproxy-rop-t.keytab
> > > HTTP/uisproxy-rop.***.***.corp
> > > Using default cache: /tmp/krb5cc_0
> > > Using principal: HTTP/uisproxy-rop.***.***.corp@***.***.CORP
> > > Using keytab: /etc/squid/keytab/uisproxy-rop-t.keytab
> > > Authenticated to Kerberos v5
> > >  
> > > # klist -ke /etc/squid/keytab/uisproxy-rop-t.keytab
> > > Keytab name: FILE:/etc/squid/keytab/uisproxy-rop-t.keytab
> > > KVNO Principal
> > > ---- ------------------------------------------------------------
> > > --------------
> > >    3 uisproxy-rop-t$@***.***.CORP (arcfour-hmac)
> > >    3 uisproxy-rop-t$@***.***.CORP (aes128-cts-hmac-sha1-96)
> > >    3 uisproxy-rop-t$@***.***.CORP (aes256-cts-hmac-sha1-96)
> > >    3 UISPROXY-ROP-T$@***.***.CORP (arcfour-hmac)
> > >    3 UISPROXY-ROP-T$@***.***.CORP (aes128-cts-hmac-sha1-96)
> > >    3 UISPROXY-ROP-T$@***.***.CORP (aes256-cts-hmac-sha1-96)
> > >    3 HTTP/uisproxy-rop.***.***.corp@***.***.CORP (arcfour-hmac)
> > >    3 HTTP/uisproxy-rop.***.***.corp@***.***.CORP (aes128-cts-
> > > hmac-sha1-96)
> > >    3 HTTP/uisproxy-rop.***.***.corp@***.***.CORP (aes256-cts-
> > > hmac-sha1-96)
> > >    3 host/uisproxy-rop@***.***.CORP (arcfour-hmac)
> > >    3 host/uisproxy-rop@***.***.CORP (aes128-cts-hmac-sha1-96)
> > >    3 host/uisproxy-rop@***.***.CORP (aes256-cts-hmac-sha1-96)
> > >  
> > > # klist -kt
> > > Keytab name: FILE:/etc/squid/keytab/uisproxy-rop-t.keytab
> > > KVNO Timestamp           Principal
> > > ---- ------------------- ----------------------------------------
> > > --------------
> > >    3 11/16/2022 11:30:50 uisproxy-rop-t$@***.***.CORP
> > >    3 11/16/2022 11:30:50 uisproxy-rop-t$@***.***.CORP
> > >    3 11/16/2022 11:30:50 uisproxy-rop-t$@***.***.CORP
> > >    3 11/16/2022 11:30:50 UISPROXY-ROP-T$@***.***.CORP
> > >    3 11/16/2022 11:30:50 UISPROXY-ROP-T$@***.***.CORP
> > >    3 11/16/2022 11:30:50 UISPROXY-ROP-T$@***.***.CORP
> > >    3 11/16/2022 11:30:50 HTTP/uisproxy-
> > > rop.***.***.corp@***.***.CORP
> > >    3 11/16/2022 11:30:50 HTTP/uisproxy-
> > > rop.***.***.corp@***.***.CORP
> > >    3 11/16/2022 11:30:50 HTTP/uisproxy-
> > > rop.***.***.corp@***.***.CORP
> > >    3 11/16/2022 11:30:50 host/uisproxy-rop@***.***.CORP
> > >    3 11/16/2022 11:30:50 host/uisproxy-rop@***.***.CORP
> > >    3 11/16/2022 11:30:50 host/uisproxy-rop@***.***.CORP
> > >  
> > > _______________________________________________
> > > squid-users mailing list
> > > squid-users at lists.squid-cache.org
> > > http://lists.squid-cache.org/listinfo/squid-users
> >  
> > -- 
> > David Touzeau - Artica Tech France
> > Development team, level 3 support
> > ----------------------------------
> > P: +33 6 58 44 69 46
> > www: https://wiki.articatech.com
> > www: http://articatech.net 
> > ,
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> > 
>  NO fileref
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 5361 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221118/20136e6e/attachment.bin>

From squid.org at bloms.de  Fri Nov 18 14:23:28 2022
From: squid.org at bloms.de (Dieter Bloms)
Date: Fri, 18 Nov 2022 15:23:28 +0100
Subject: [squid-users] does squid 5.7 support HTTP/2 protocol
Message-ID: <20221118142328.avrwj672vxvc2nbu@bloms.de>

Hello,

does squid 5.7 support the HTTP/2.0 protocol?
>From https://wiki.squid-cache.org/Features/HTTP2 it seem some work seems
to be done, but not all.
But sometimes the docu is outdated, so I hope it is outdated and squid
does support HTTP/2

-- 
Regdards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
>From field.


From rafael.akchurin at diladele.com  Fri Nov 18 14:53:28 2022
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 18 Nov 2022 14:53:28 +0000
Subject: [squid-users] Kerberos - Cannot decrypt ticket for HTTP
In-Reply-To: <38e403c49727fa5300d81e1a7cef08066d9d1e72.camel@genua.de>
References: <1783041668571106@mail.yandex.ru>
 <b9ffb62c-3c84-5380-dbf1-81af6c93e794@articatech.com>
 <594301668737598@mail.yandex.ru>
 <38e403c49727fa5300d81e1a7cef08066d9d1e72.camel@genua.de>
Message-ID: <AM8PR04MB774599E8571DE2DCA41B16F28F099@AM8PR04MB7745.eurprd04.prod.outlook.com>

Also it might have been related to recent Microsoft Updates.

The following article summarizes our issues with Kerberos (note we use a special user in AD with keytab, not joining of proxy into the domain).

https://docs.diladele.com/faq/squid/authentication/event_14_kerberos_key_distribution_center.html

Best regards,
rafael

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Klaus Brandl
Sent: Friday, November 18, 2022 3:23 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Kerberos - Cannot decrypt ticket for HTTP

which options do you have configured for the auth helper?
Something like:

auth_param negotiate program
/usr/local/libexec/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME -i

Best regards

Klaus

Am Freitag, dem 18.11.2022 um 10:54 +0800 schrieb ??????:
> Hi David,
>  
> Thanks for your advice but it doesn't help me. I use AD account which 
> haven't set these parameters.
>  
> Misha.
>  
> 17.11.2022, 10:07, "David Touzeau" <david at articatech.com>:
> > Hi
> > 
> > perhaps this one
> > https://wiki.articatech.com/en/proxy-service/troubleshooting/gss-can
> > not-decrypt-ticket
> > 
> >  
> > Le 16/11/2022 ? 05:11, ?????? a ?crit :
> > > Hi everybody,
> > >  
> > > Could you help me to setup my new squid server? I have a problem 
> > > with keytab authorization.
> > >  
> > > 2022/11/16 11:35:39| ERROR: Negotiate Authentication validating 
> > > user. Result: {result=BH, notes={message:
> > > gss_accept_sec_context() failed: Unspecified GSS failure.  Minor 
> > > code may provide more information. Cannot decrypt ticket for 
> > > HTTP/uisproxy-rop.***.***.corp@***.***.CORP using keytab key for 
> > > HTTP/uisproxy-rop.***.***.corp@***.**.CORP; }} Got NTLMSSP 
> > > neg_flags=0xe2088297
> > > 2022/11/16 11:35:40| ERROR: Negotiate Authentication validating 
> > > user. Result: {result=BH, notes={message:
> > > gss_accept_sec_context() failed: Unspecified GSS failure.  Minor 
> > > code may provide more information. Cannot decrypt ticket for 
> > > HTTP/uisproxy-rop.***.***.corp@***.***.CORP using keytab key for 
> > > HTTP/uisproxy-rop.***.***.corp@***.***.CORP; }}
> > >  
> > > # kinit -V -k -t /etc/squid/keytab/uisproxy-rop-t.keytab
> > > HTTP/uisproxy-rop.***.***.corp
> > > Using default cache: /tmp/krb5cc_0 Using principal: 
> > > HTTP/uisproxy-rop.***.***.corp@***.***.CORP
> > > Using keytab: /etc/squid/keytab/uisproxy-rop-t.keytab
> > > Authenticated to Kerberos v5
> > >  
> > > # klist -ke /etc/squid/keytab/uisproxy-rop-t.keytab
> > > Keytab name: FILE:/etc/squid/keytab/uisproxy-rop-t.keytab
> > > KVNO Principal
> > > ---- ------------------------------------------------------------
> > > --------------
> > >    3 uisproxy-rop-t$@***.***.CORP (arcfour-hmac)
> > >    3 uisproxy-rop-t$@***.***.CORP (aes128-cts-hmac-sha1-96)
> > >    3 uisproxy-rop-t$@***.***.CORP (aes256-cts-hmac-sha1-96)
> > >    3 UISPROXY-ROP-T$@***.***.CORP (arcfour-hmac)
> > >    3 UISPROXY-ROP-T$@***.***.CORP (aes128-cts-hmac-sha1-96)
> > >    3 UISPROXY-ROP-T$@***.***.CORP (aes256-cts-hmac-sha1-96)
> > >    3 HTTP/uisproxy-rop.***.***.corp@***.***.CORP (arcfour-hmac)
> > >    3 HTTP/uisproxy-rop.***.***.corp@***.***.CORP (aes128-cts-
> > > hmac-sha1-96)
> > >    3 HTTP/uisproxy-rop.***.***.corp@***.***.CORP (aes256-cts-
> > > hmac-sha1-96)
> > >    3 host/uisproxy-rop@***.***.CORP (arcfour-hmac)
> > >    3 host/uisproxy-rop@***.***.CORP (aes128-cts-hmac-sha1-96)
> > >    3 host/uisproxy-rop@***.***.CORP (aes256-cts-hmac-sha1-96)
> > >  
> > > # klist -kt
> > > Keytab name: FILE:/etc/squid/keytab/uisproxy-rop-t.keytab
> > > KVNO Timestamp           Principal
> > > ---- ------------------- ----------------------------------------
> > > --------------
> > >    3 11/16/2022 11:30:50 uisproxy-rop-t$@***.***.CORP
> > >    3 11/16/2022 11:30:50 uisproxy-rop-t$@***.***.CORP
> > >    3 11/16/2022 11:30:50 uisproxy-rop-t$@***.***.CORP
> > >    3 11/16/2022 11:30:50 UISPROXY-ROP-T$@***.***.CORP
> > >    3 11/16/2022 11:30:50 UISPROXY-ROP-T$@***.***.CORP
> > >    3 11/16/2022 11:30:50 UISPROXY-ROP-T$@***.***.CORP
> > >    3 11/16/2022 11:30:50 HTTP/uisproxy- 
> > > rop.***.***.corp@***.***.CORP
> > >    3 11/16/2022 11:30:50 HTTP/uisproxy- 
> > > rop.***.***.corp@***.***.CORP
> > >    3 11/16/2022 11:30:50 HTTP/uisproxy- 
> > > rop.***.***.corp@***.***.CORP
> > >    3 11/16/2022 11:30:50 host/uisproxy-rop@***.***.CORP
> > >    3 11/16/2022 11:30:50 host/uisproxy-rop@***.***.CORP
> > >    3 11/16/2022 11:30:50 host/uisproxy-rop@***.***.CORP
> > >  
> > > _______________________________________________
> > > squid-users mailing list
> > > squid-users at lists.squid-cache.org
> > > http://lists.squid-cache.org/listinfo/squid-users
> >  
> > --
> > David Touzeau - Artica Tech France
> > Development team, level 3 support
> > ----------------------------------
> > P: +33 6 58 44 69 46
> > www: https://wiki.articatech.com
> > www: http://articatech.net
> > ,
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> > 
>  NO fileref
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

From squid3 at treenet.co.nz  Sat Nov 19 06:43:29 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 19 Nov 2022 19:43:29 +1300
Subject: [squid-users] does squid 5.7 support HTTP/2 protocol
In-Reply-To: <20221118142328.avrwj672vxvc2nbu@bloms.de>
References: <20221118142328.avrwj672vxvc2nbu@bloms.de>
Message-ID: <213a5324-8cda-d424-8505-8ace38d4a2fd@treenet.co.nz>

On 19/11/2022 3:23 am, Dieter Bloms wrote:
> Hello,
>
> does squid 5.7 support the HTTP/2.0 protocol?

Short answer is "no".

>  From https://wiki.squid-cache.org/Features/HTTP2 it seem some work seems
> to be done, but not all.
> But sometimes the docu is outdated, so I hope it is outdated and squid
> does support HTTP/2

Squid-5 is able to detect HTTP/2 version being attempted and reject it. 
Further support is stuck in PR review.

PS. with HTTP/3 coming out and becoming so popular in the time it took 
to get the simplest h2c support into Squid I have moved focus to adding 
that first and potentially skipping HTTP/2 entirely. Work to add QUIC 
support underlaying HTTP/3 is also in PR review at present.


HTH
Amos


From support at unveiltech.com  Sat Nov 19 13:43:54 2022
From: support at unveiltech.com (UnveilTech - Support)
Date: Sat, 19 Nov 2022 13:43:54 +0000
Subject: [squid-users] Squid 5: server_cert_fingerprint not working
 fine...
References: <3adf99e022084a76b0f18ffb1f3f605f@unveiltech.com>
 <ab1b5b8d00874760a80cecf61772aeaa@unveiltech.com>
 <67763d66-e264-14a1-f599-224749c18f71@treenet.co.nz> 
Message-ID: <66858c17702a4c27894cd59081ab420d@unveiltech.com>

Hi Amos,

Quick update...
A 10 lines PHP helper is able to catch the SHA1 key with a basis "openssl_x509_fingerprint" function when Squid, a 1 million lines product, could not be able ?

Samples from the helper:
apple.com tls1.3, SHA1: "7B:B1:94:4F:56:5D:7D:64:A1:45:5C:91:E5:BA:0C:EA:D9:FB:91:50"
xforce-cracks.com tls1.3, SHA1: "31:3E:E1:3D:FD:B1:0A:C0:CA:AF:30:47:0A:BA:A1:49:D4:08:42:2A"

I'm sure the Squid team can do better than a PHP function ?

Bye Fred

-----Message d'origine-----
De?: UnveilTech - Support 
Envoy??: vendredi 18 novembre 2022 14:56
??: 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Objet?: RE: [squid-users] Squid 5: server_cert_fingerprint not working fine...

Hi Amos,

We have tested with a "ssl_bump bump" ("ssl_bump all" and "ssl_bump bump sslstep1"), it does not solve the problem.
According to Alex, we can also confirm it's a bug with Squid 5.x and TLS 1.3.
It seems Squid is only compatible with TLS 1.2, it's not good for the future...

Bye Fred

-----Message d'origine-----
De?: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Amos Jeffries Envoy??: vendredi 18 novembre 2022 06:34 ??: squid-users at lists.squid-cache.org Objet?: Re: [squid-users] Squid 5: server_cert_fingerprint not working fine...

On 18/11/2022 5:02 am, UnveilTech - Support wrote:
>
> Hello Squid Team,
>
> Can you have a look to this bugzilla case?:
>
> https://bugs.squid-cache.org/show_bug.cgi?id=5245
>
> it?s about a bug with Squid 5.7 and TLS 1.3.
>
> Critical case created the 2022-10-27 09:59 UTC, it would be nice to 
> have a fix/patch?
>
> ? occur)
>

As one can see in the bug report Alex has looked at it in some detail.
The solution may be complex or large change, and thus unlikely to occur in Squid-5 if so.

There are three things that come to mind immediately as related problems we cannot do anything about:
 ?1) Squid cannot know in advance what server cert will be provided (after step2) when it decided to splice (or not) at step2.
 ?2) SHA1 is not the only type of cert fingerprint. The non-working certs may be providing newer SHA2/3 etc fingerprints
 ?3) In TLS/1.3 a lot of data can be hidden inside the encryption. Squid may simply not be given access to the [real] fingerprint unless bump
(decrypt) happens.

HTH
Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From rousskov at measurement-factory.com  Sat Nov 19 15:07:27 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 19 Nov 2022 10:07:27 -0500
Subject: [squid-users] does squid 5.7 support HTTP/2 protocol
In-Reply-To: <20221118142328.avrwj672vxvc2nbu@bloms.de>
References: <20221118142328.avrwj672vxvc2nbu@bloms.de>
Message-ID: <2a644db6-01c9-9dfb-0a04-17ef8423424e@measurement-factory.com>

On 11/18/22 09:23, Dieter Bloms wrote:

> does squid 5.7 support the HTTP/2.0 protocol?

No, Squid v5 does not. Most likely, Squid v6 will not support HTTP/2+ 
either. I hope to see HTTP/2+ support in v7, but current Squid Project 
deficiencies make that a toll order.

FWIW, last time I checked, very few clients supported talking HTTP/2+ to 
proxies; most clients just send HTTP/1 CONNECT. Thus, in most 
environments, Squid HTTP/2+ support would apply to SslBump setups.


HTH,

Alex.



From squid3 at treenet.co.nz  Sat Nov 19 15:50:26 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 20 Nov 2022 04:50:26 +1300
Subject: [squid-users] Squid 5: server_cert_fingerprint not working
 fine...
In-Reply-To: <796a78058b01409f8cd220f3a33a27ae@unveiltech.com>
References: <3adf99e022084a76b0f18ffb1f3f605f@unveiltech.com>
 <ab1b5b8d00874760a80cecf61772aeaa@unveiltech.com>
 <67763d66-e264-14a1-f599-224749c18f71@treenet.co.nz>
 <796a78058b01409f8cd220f3a33a27ae@unveiltech.com>
Message-ID: <19ae1da5-5d0a-93d6-e91f-3e82b064b1ed@treenet.co.nz>

On 19/11/2022 2:55 am, UnveilTech - Support wrote:
> Hi Amos,
>
> We have tested with a "ssl_bump bump" ("ssl_bump all" and "ssl_bump bump sslstep1"), it does not solve the problem.
> According to Alex, we can also confirm it's a bug with Squid 5.x and TLS 1.3.

Okay.

> It seems Squid is only compatible with TLS 1.2, it's not good for the future...

One bug (or lack of ability) does not make the entire protocol 
"incompatible". It only affects people trying to do the particular buggy 
action.
Unfortunately for you (and others) it happens to be accessing this 
server cert fingerprint.

I/we have been clear from the beginning that *when used properly* 
TLS/SSL cannot be "bump"ed - that is true for all versions of TLS and 
SSL before it. In that same "bump" use-case the server does not provide 
*any* details, it just rejects the proxy attempted connection. In some 
paranoid security environments the server can reject even for "splice" 
when the clientHello is passed on unchanged by the proxy. HTTPS use on 
the web is typically *neither* of those "proper" setups so SSL-Bump 
"bump" in general works and "splice" almost always.

Cheers
Amos



From squid3 at treenet.co.nz  Sat Nov 19 15:58:32 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 20 Nov 2022 04:58:32 +1300
Subject: [squid-users] Squid 5: server_cert_fingerprint not working
 fine...
In-Reply-To: <66858c17702a4c27894cd59081ab420d@unveiltech.com>
References: <3adf99e022084a76b0f18ffb1f3f605f@unveiltech.com>
 <ab1b5b8d00874760a80cecf61772aeaa@unveiltech.com>
 <67763d66-e264-14a1-f599-224749c18f71@treenet.co.nz>
 <66858c17702a4c27894cd59081ab420d@unveiltech.com>
Message-ID: <223b4867-13d6-e46e-2185-759030cd04c7@treenet.co.nz>

On 20/11/2022 2:43 am, UnveilTech - Support wrote:
> Hi Amos,
>
> Quick update...
> A 10 lines PHP helper is able to catch the SHA1 key with a basis "openssl_x509_fingerprint" function when Squid, a 1 million lines product, could not be able ?

The question-conclusion you have reached is ridiculous...
 ?PHP is not just the script itself (that is more akin to *only* the 
squid.conf lines you configured) - it is likely also the Zend engine 
and/or Apache as well.
 ?To compare against the entirely of Squid you would have to compare 
against all their Lines-of-Code, developer teams sizes and funding.
 ?Against which a) Squid falls far short, and b) most said lines of code 
have nothing to do with your TLS problem.



> Samples from the helper:
> apple.com tls1.3, SHA1: "7B:B1:94:4F:56:5D:7D:64:A1:45:5C:91:E5:BA:0C:EA:D9:FB:91:50"
> xforce-cracks.com tls1.3, SHA1: "31:3E:E1:3D:FD:B1:0A:C0:CA:AF:30:47:0A:BA:A1:49:D4:08:42:2A"
>
> I'm sure the Squid team can do better than a PHP function ?

What does said script to *exactly* ?

Cheers
Amos



From ngtech1ltd at gmail.com  Sat Nov 19 17:17:15 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Sat, 19 Nov 2022 19:17:15 +0200
Subject: [squid-users] Squid 5: server_cert_fingerprint not working
 fine...
In-Reply-To: <66858c17702a4c27894cd59081ab420d@unveiltech.com>
References: <3adf99e022084a76b0f18ffb1f3f605f@unveiltech.com>
 <ab1b5b8d00874760a80cecf61772aeaa@unveiltech.com>
 <67763d66-e264-14a1-f599-224749c18f71@treenet.co.nz>
 <66858c17702a4c27894cd59081ab420d@unveiltech.com>
Message-ID: <001001d8fc3a$c5d198a0$5174c9e0$@gmail.com>

Hey Fred,

Just a tiny question, can you share this php script so we can make sense of what is this script doing compared to what squid is doing?

Thanks,
Eliezer

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of UnveilTech - Support
Sent: Saturday, 19 November 2022 15:44
To: Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid 5: server_cert_fingerprint not working fine...

Hi Amos,

Quick update...
A 10 lines PHP helper is able to catch the SHA1 key with a basis "openssl_x509_fingerprint" function when Squid, a 1 million lines product, could not be able ?

Samples from the helper:
apple.com tls1.3, SHA1: "7B:B1:94:4F:56:5D:7D:64:A1:45:5C:91:E5:BA:0C:EA:D9:FB:91:50"
xforce-cracks.com tls1.3, SHA1: "31:3E:E1:3D:FD:B1:0A:C0:CA:AF:30:47:0A:BA:A1:49:D4:08:42:2A"

I'm sure the Squid team can do better than a PHP function ?

Bye Fred

-----Message d'origine-----
De : UnveilTech - Support 
Envoy? : vendredi 18 novembre 2022 14:56
? : 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Objet : RE: [squid-users] Squid 5: server_cert_fingerprint not working fine...

Hi Amos,

We have tested with a "ssl_bump bump" ("ssl_bump all" and "ssl_bump bump sslstep1"), it does not solve the problem.
According to Alex, we can also confirm it's a bug with Squid 5.x and TLS 1.3.
It seems Squid is only compatible with TLS 1.2, it's not good for the future...

Bye Fred

-----Message d'origine-----
De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Amos Jeffries Envoy? : vendredi 18 novembre 2022 06:34 ? : squid-users at lists.squid-cache.org Objet : Re: [squid-users] Squid 5: server_cert_fingerprint not working fine...

On 18/11/2022 5:02 am, UnveilTech - Support wrote:
>
> Hello Squid Team,
>
> Can you have a look to this bugzilla case :
>
> https://bugs.squid-cache.org/show_bug.cgi?id=5245
>
> it?s about a bug with Squid 5.7 and TLS 1.3.
>
> Critical case created the 2022-10-27 09:59 UTC, it would be nice to 
> have a fix/patch?
>
>   occur)
>

As one can see in the bug report Alex has looked at it in some detail.
The solution may be complex or large change, and thus unlikely to occur in Squid-5 if so.

There are three things that come to mind immediately as related problems we cannot do anything about:
  1) Squid cannot know in advance what server cert will be provided (after step2) when it decided to splice (or not) at step2.
  2) SHA1 is not the only type of cert fingerprint. The non-working certs may be providing newer SHA2/3 etc fingerprints
  3) In TLS/1.3 a lot of data can be hidden inside the encryption. Squid may simply not be given access to the [real] fingerprint unless bump
(decrypt) happens.

HTH
Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From david at articatech.com  Sat Nov 19 18:19:20 2022
From: david at articatech.com (David Touzeau)
Date: Sat, 19 Nov 2022 19:19:20 +0100
Subject: [squid-users] Squid 5: server_cert_fingerprint not working
 fine...
In-Reply-To: <19ae1da5-5d0a-93d6-e91f-3e82b064b1ed@treenet.co.nz>
References: <3adf99e022084a76b0f18ffb1f3f605f@unveiltech.com>
 <ab1b5b8d00874760a80cecf61772aeaa@unveiltech.com>
 <67763d66-e264-14a1-f599-224749c18f71@treenet.co.nz>
 <796a78058b01409f8cd220f3a33a27ae@unveiltech.com>
 <19ae1da5-5d0a-93d6-e91f-3e82b064b1ed@treenet.co.nz>
Message-ID: <ba4578b0-1535-c180-c6b5-244859da2d02@articatech.com>

Thanks Amos for this clarification,

We also have the same needs and indeed, we face with the same approach.

It is possible that the structure of Squid could not, in some cases, 
recovering this type of information.
Although the concept of a proxy is neither more nor less than a big 
browser that surfs instead of the client browsers.

The SHA1 and certificate information reception are very valuable because 
it ensures better detection of compromised sites (many malicious sites 
use the same information in their certificates).
This allows detecting "nests" of malicious sites automatically.

Unfortunately, there is madness in the approach to security, there is a 
race to strengthen the security of tunnels (produced by Google and 
browsers vendors).
What is the advantage of encrypting wikipedia and Youtube channels?

On the other hand, it is crucial to look inside these streams to detect 
threats.
This is antinomic...

So TLS 1.3 and soon the use of QUIC with UDP 80/443 will make use of a 
proxy useless as these features are rolled out? (trust Google to 
motivate them)
Unless the proxy manages to follow this protocol madness race...

For this reason, firewall manufacturers propose the use of client 
software that fills the gap of protocol visibility in their gateway 
products or you -can see a growth of workstation protections , such EDR 
concept

Just an ideological and non-technical approach...

Regards

Le 19/11/2022 ? 16:50, Amos Jeffries a ?crit?:
> On 19/11/2022 2:55 am, UnveilTech - Support wrote:
>> Hi Amos,
>>
>> We have tested with a "ssl_bump bump" ("ssl_bump all" and "ssl_bump 
>> bump sslstep1"), it does not solve the problem.
>> According to Alex, we can also confirm it's a bug with Squid 5.x and 
>> TLS 1.3.
>
> Okay.
>
>> It seems Squid is only compatible with TLS 1.2, it's not good for the 
>> future...
>
> One bug (or lack of ability) does not make the entire protocol 
> "incompatible". It only affects people trying to do the particular 
> buggy action.
> Unfortunately for you (and others) it happens to be accessing this 
> server cert fingerprint.
>
> I/we have been clear from the beginning that *when used properly* 
> TLS/SSL cannot be "bump"ed - that is true for all versions of TLS and 
> SSL before it. In that same "bump" use-case the server does not 
> provide *any* details, it just rejects the proxy attempted connection. 
> In some paranoid security environments the server can reject even for 
> "splice" when the clientHello is passed on unchanged by the proxy. 
> HTTPS use on the web is typically *neither* of those "proper" setups 
> so SSL-Bump "bump" in general works and "splice" almost always.
>
> Cheers
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221119/2a4277b6/attachment.htm>

From david at articatech.com  Sat Nov 19 18:19:20 2022
From: david at articatech.com (David Touzeau)
Date: Sat, 19 Nov 2022 19:19:20 +0100
Subject: [squid-users] Squid 5: server_cert_fingerprint not working
 fine...
In-Reply-To: <19ae1da5-5d0a-93d6-e91f-3e82b064b1ed@treenet.co.nz>
References: <3adf99e022084a76b0f18ffb1f3f605f@unveiltech.com>
 <ab1b5b8d00874760a80cecf61772aeaa@unveiltech.com>
 <67763d66-e264-14a1-f599-224749c18f71@treenet.co.nz>
 <796a78058b01409f8cd220f3a33a27ae@unveiltech.com>
 <19ae1da5-5d0a-93d6-e91f-3e82b064b1ed@treenet.co.nz>
Message-ID: <69e50488-3006-0e8b-6b7e-c4b48d76801e@articatech.com>

Thanks Amos for this clarification,

We also have the same needs and indeed, we face with the same approach.

It is possible that the structure of Squid could not, in some cases, 
recovering this type of information.
Although the concept of a proxy is neither more nor less than a big 
browser that surfs instead of the client browsers.

The SHA1 and certificate information reception are very valuable because 
it ensures better detection of compromised sites (many malicious sites 
use the same information in their certificates).
This allows detecting "nests" of malicious sites automatically.

Unfortunately, there is madness in the approach to security, there is a 
race to strengthen the security of tunnels (produced by Google and 
browsers vendors).
What is the advantage of encrypting wikipedia and Youtube channels?

On the other hand, it is crucial to look inside these streams to detect 
threats.
This is antinomic...

So TLS 1.3 and soon the use of QUIC with UDP 80/443 will make use of a 
proxy useless as these features are rolled out? (trust Google to 
motivate them)
Unless the proxy manages to follow this protocol madness race...

For this reason, firewall manufacturers propose the use of client 
software that fills the gap of protocol visibility in their gateway 
products or you -can see a growth of workstation protections , such EDR 
concept

Just an ideological and non-technical approach...

Regards

Le 19/11/2022 ? 16:50, Amos Jeffries a ?crit?:
> On 19/11/2022 2:55 am, UnveilTech - Support wrote:
>> Hi Amos,
>>
>> We have tested with a "ssl_bump bump" ("ssl_bump all" and "ssl_bump 
>> bump sslstep1"), it does not solve the problem.
>> According to Alex, we can also confirm it's a bug with Squid 5.x and 
>> TLS 1.3.
>
> Okay.
>
>> It seems Squid is only compatible with TLS 1.2, it's not good for the 
>> future...
>
> One bug (or lack of ability) does not make the entire protocol 
> "incompatible". It only affects people trying to do the particular 
> buggy action.
> Unfortunately for you (and others) it happens to be accessing this 
> server cert fingerprint.
>
> I/we have been clear from the beginning that *when used properly* 
> TLS/SSL cannot be "bump"ed - that is true for all versions of TLS and 
> SSL before it. In that same "bump" use-case the server does not 
> provide *any* details, it just rejects the proxy attempted connection. 
> In some paranoid security environments the server can reject even for 
> "splice" when the clientHello is passed on unchanged by the proxy. 
> HTTPS use on the web is typically *neither* of those "proper" setups 
> so SSL-Bump "bump" in general works and "splice" almost always.
>
> Cheers
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221119/0d1ebef4/attachment.htm>

From ngtech1ltd at gmail.com  Sat Nov 19 21:10:50 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Sat, 19 Nov 2022 23:10:50 +0200
Subject: [squid-users] transparent mode squid on centos 9 with iptables
 (part 2)
In-Reply-To: <07c330f7-4de8-bc8f-3aab-a00c12baa157@treenet.co.nz>
References: <CAKM+x_L67p0YjP3BPwSU=cp8PrQcG-CVH7jzmT80AB=ym3u4Vw@mail.gmail.com>
 <CAKM+x_JRkR2vNgT_zqcQAd3qXTwQMXDa8mJeEY+R6FYXDiFB0g@mail.gmail.com>
 <CAKM+x_K5XA0oTvEsGkzwHuYbVVYXe+1UegWCW2b37_pATX7mDQ@mail.gmail.com>
 <CAKM+x_JwQt+4jwVsfzgdj-x-DoWC77TqYROS44+cux0asdAADw@mail.gmail.com>
 <07c330f7-4de8-bc8f-3aab-a00c12baa157@treenet.co.nz>
Message-ID: <001b01d8fc5b$675b9bb0$3612d310$@gmail.com>

Hey,

CentOS 9 is mainly uses nftables when possible.
I have not seen any example of squid intercept examples with nftables.
If for any reason the iptables command would not work on CentOS 9 (stream) let me know and I might be able to provide these.

Eliezer

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Amos Jeffries
Sent: Thursday, 17 November 2022 6:35
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] transparent mode squid on centos 9 with iptables (part 2)

On 17/11/2022 9:14 am, Lola Lo wrote:
> Hi guys.
>
>
> Could you please send a tutorial or any good guidance to implement  
> squid on transparent mode on centos 9 with iptables.
>

The configuration details for what you appear to be trying to configure 
are here:
  <https://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect>

My comments below relate to how your attempt differs and how to fix.

> I have configured squid.conf with this parameters:
>
>
>
> ens192: 172.31.168.28, internet interface
>
> ens224: 192.168.1.10, LAN interface (private network)
>
>
> # Mis ACLs #
>
> acl mi_red src 192.168.1.0/24 <http://192.168.1.0/24>
>
> acl cliente_linux src 192.168.1.20
>
> acl cliente_windows src 192.168.1.30
>
> acl sitios1 url_regex "/etc/squid/listas/sitios1"
>
> acl sitios2 url_regex "/etc/squid/listas/sitios2"
>
>
> # Squid normally listens to port 3128
>
> http_port 3128
>
> http_port 8080 transparent
>
>

Firstly, use "intercept" instead of "transparent" with modern Squid.

Secondly, remember that only port 8080 is setup to receive intercepted 
traffic. Port 3128 still receives normal forward-proxy traffic.

> I want the ?deny all? rule get applied to test the client using the proxy
>
>

You have not shown any http_access lines from your config. There is a 
clear bug in your NAT which explains the behaviour so I will assume that 
the squid.conf policy does what you want.


> My iptables is configured as follows:
>
>
> #!/bin/bash
>
>
> ## NAT server configuration ##
>
>
> sysctl -w net.ipv4.ip_forward=1
>
> sysctl -p
>
> iptables -X
>
> iptables -F
>
> iptables -t nat -X
>
> iptables -t nat -F
>
> iptables -I INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
>
> iptables -I FORWARD-m state --state RELATED,ESTABLISHED -j ACCEPT
>
> iptables -t nat -I POSTROUTING -o ens192 -j MASQUERADE
>
>
>

Why is this a different script?
Ideally the firewall rules should be as atomic as possible to avoid 
connections being setup with only part of the rules applied.


>
> #!/bin/bash
>
>
> ## proxy server configuration ##
>
>
> ### Accepting traffic for the ports: 3128 and 8080##
>
>
> iptables -A INPUT -s 192.168.1.0/24 <http://192.168.1.0/24> -p tcp 
> --dport 3128 -j ACCEPT
>
> iptables -A INPUT -p tcp --dport 3128 -j DROP
>

Do not accept traffic directly to the port 8080. Also Squid does not 
make outbound connections from its listening ports.
So these ...

> iptables -A OUTPUT -d 192.168.1.0/24 <http://192.168.1.0/24> -p tcp 
> --sport 3128 -j ACCEPT
>
> iptables -A OUTPUT -p tcp --sport 3128 -j DROP
>
>
> iptables -A INPUT -s 192.168.1.0/24 <http://192.168.1.0/24> -p tcp 
> --dport 8080 -j ACCEPT
>
> iptables -A INPUT -p tcp --dport 8080 -j DROP
>
> iptables -A OUTPUT -d 192.168.1.0/24 <http://192.168.1.0/24> -p tcp 
> --sport 8080 -j ACCEPT
>
> iptables -A OUTPUT -p tcp --sport 8080 -j DROP
>
>

... should be replaced with:

   iptables -t mangle -A PREROUTING -p tcp --dport 8080 -j DROP


>
> `### Accepting traffic for the ports: 3128 and 8080##
>
>
> iptables -t nat -A POSTROUTING -o ens192 -j MASQUERADE
>

You are missing a rule to allow Squid outbound traffic to avoid the NAT.

   iptables -t nat -A PREROUTING -s 192.168.1.10 -p tcp --dport 80 -j ACCEPT

> iptables -t nat -A PREROUTING -s 192.168.1.0/24 
> <http://192.168.1.0/24> -p tcp --dport 80 -j REDIRECT --to-port 8080
>
> iptables -t nat -A PREROUTING -s 192.168.1.0/24 
> <http://192.168.1.0/24> -p tcp --dport 443 -j REDIRECT --to-port 8080
>
>

Port 8080 in your squid.conf can only handle port 80 traffic syntax.

Port 443 is a more tricky situation. I recommend removing that until you 
have the port 80 working.


>
> But I got this error:
>
>
> 1668381894.7460 192.168.1.20 NONE_NONE/000 0 - 
> error:transaction-end-before-headers - HIER_NONE/- -
>
> 1668381967.8000 192.168.1.20 NONE_NONE/400 3690 - 
> error:invalid-request - HIER_NONE/- text/html
>

This is likely from the missing NAT rule allowing Squid outbound.

If the above changes do not fix everything make sure that you test 
exactly what the real clients will be doing. Specifically that they are 
making contact to servers on port 80 or directly to Squid port 3128. 
They know *nothing* about port 8080 existence so have no reason to send 
anything that way directly.


HTH
Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Sat Nov 19 23:04:04 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 20 Nov 2022 12:04:04 +1300
Subject: [squid-users] transparent mode squid on centos 9 with iptables
 (part 2)
In-Reply-To: <001b01d8fc5b$675b9bb0$3612d310$@gmail.com>
References: <CAKM+x_L67p0YjP3BPwSU=cp8PrQcG-CVH7jzmT80AB=ym3u4Vw@mail.gmail.com>
 <CAKM+x_JRkR2vNgT_zqcQAd3qXTwQMXDa8mJeEY+R6FYXDiFB0g@mail.gmail.com>
 <CAKM+x_K5XA0oTvEsGkzwHuYbVVYXe+1UegWCW2b37_pATX7mDQ@mail.gmail.com>
 <CAKM+x_JwQt+4jwVsfzgdj-x-DoWC77TqYROS44+cux0asdAADw@mail.gmail.com>
 <07c330f7-4de8-bc8f-3aab-a00c12baa157@treenet.co.nz>
 <001b01d8fc5b$675b9bb0$3612d310$@gmail.com>
Message-ID: <f649b1fb-a8fa-4502-df96-5ed5679a6f34@treenet.co.nz>

On 20/11/2022 10:10 am, ngtech1ltd wrote:
> Hey,
>
> CentOS 9 is mainly uses nftables when possible.
> I have not seen any example of squid intercept examples with nftables.

iptables has for many years been a wrapper converting its command-line 
into nftables messages internally.
So all Squid config examples mentioning iptables will work with the 
equivalent nftables commands.


Cheers
Amos



From robertkwild at gmail.com  Mon Nov 21 13:55:46 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Mon, 21 Nov 2022 13:55:46 +0000
Subject: [squid-users] moving squid from centos 7 to ubuntu 22.04
In-Reply-To: <CAGU_CiJ+NZHBvP_5NF7pPddikx+r9=zrTQG9fKqrg+PFRLvpEA@mail.gmail.com>
References: <CAGU_CiKK5w8+CM+=XLzaUtYS_kqO9iEVKZt2i1i1wES9Cxn-LQ@mail.gmail.com>
 <51294f1b-3c4b-73d0-d345-1773bc75cd58@treenet.co.nz>
 <CAGU_CiJ=gQU+84c4MnWxaN68iE5vri+Q9NmqSyL5ODWA25U3qw@mail.gmail.com>
 <af0afcba-3518-f576-1ba1-9a2cb3d678ce@treenet.co.nz>
 <CAGU_CiJ+NZHBvP_5NF7pPddikx+r9=zrTQG9fKqrg+PFRLvpEA@mail.gmail.com>
Message-ID: <CAGU_CiKZ=ykiGgHYLR0MhRc5i2yUK-zkQnfJ3JfE887e_Zgj+A@mail.gmail.com>

so to get ecap working instead if icap

from this

wget http://www.squid-cache.org/Versions/v4/squid-4.17.tar.gz
wget
http://sourceforge.net/projects/c-icap/files/c-icap/0.5.x/c_icap-0.5.10.tar.gz
--no-check-certificate
wget
http://sourceforge.net/projects/c-icap/files/c-icap-modules/0.5.x/c_icap_modules-0.5.5.tar.gz
--no-check-certificate
wget
https://sourceforge.net/projects/squidclamav/files/squidclamav/7.1/squidclamav-7.1.tar.gz
--no-check-certificate

to this

wget http://www.squid-cache.org/Versions/v4/squid-4.17.tar.gz
wget https://www.e-cap.org/archive/libecap-1.0.0.tar.gz
wget https://www.e-cap.org/archive/ecap_clamav_adapter-2.0.0.tar.gz

what guide is best to follow for ecap as theres two

https://wiki.squid-cache.org/Features/eCAP

https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/eCAP



On Fri, 18 Nov 2022 at 07:33, robert k Wild <robertkwild at gmail.com> wrote:

> Hi Amos,
>
> thats fine, youve been more than helpful, thank you
>
> this is where i learnt how to run squid with cicap
>
> https://squidclamav.darold.net/documentation.html
>
> have you got a good how to about running squid with e cap
>
> whats the difference anyway between Icap and Ecap?
>
> On Thu, 17 Nov 2022 at 09:29, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
>> On 17/11/2022 9:21 pm, robert k Wild wrote:
>> > Wow thanks Amos so much for this,
>> >
>> > You think if I build it on rocky Linux, it would be easier?
>> >
>>
>> I am not familiar with Rocky Linux beyond its existence.
>> I expect it would be similar to CentOS since both are in the RHEL family.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
> --
> Regards,
>
> Robert K Wild.
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221121/7fe0da07/attachment.htm>

From uhlar at fantomas.sk  Mon Nov 21 14:07:55 2022
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 21 Nov 2022 15:07:55 +0100
Subject: [squid-users] moving squid from centos 7 to ubuntu 22.04
In-Reply-To: <CAGU_CiKZ=ykiGgHYLR0MhRc5i2yUK-zkQnfJ3JfE887e_Zgj+A@mail.gmail.com>
References: <CAGU_CiKK5w8+CM+=XLzaUtYS_kqO9iEVKZt2i1i1wES9Cxn-LQ@mail.gmail.com>
 <51294f1b-3c4b-73d0-d345-1773bc75cd58@treenet.co.nz>
 <CAGU_CiJ=gQU+84c4MnWxaN68iE5vri+Q9NmqSyL5ODWA25U3qw@mail.gmail.com>
 <af0afcba-3518-f576-1ba1-9a2cb3d678ce@treenet.co.nz>
 <CAGU_CiJ+NZHBvP_5NF7pPddikx+r9=zrTQG9fKqrg+PFRLvpEA@mail.gmail.com>
 <CAGU_CiKZ=ykiGgHYLR0MhRc5i2yUK-zkQnfJ3JfE887e_Zgj+A@mail.gmail.com>
Message-ID: <Y3uGO1+gjqpFmlbo@fantomas.sk>

On 21.11.22 13:55, robert k Wild wrote:
>so to get ecap working instead if icap
>
>from this
>
>wget http://www.squid-cache.org/Versions/v4/squid-4.17.tar.gz
>wget
>http://sourceforge.net/projects/c-icap/files/c-icap/0.5.x/c_icap-0.5.10.tar.gz
>--no-check-certificate
>wget
>http://sourceforge.net/projects/c-icap/files/c-icap-modules/0.5.x/c_icap_modules-0.5.5.tar.gz
>--no-check-certificate
>wget
>https://sourceforge.net/projects/squidclamav/files/squidclamav/7.1/squidclamav-7.1.tar.gz
>--no-check-certificate
>
>to this
>
>wget http://www.squid-cache.org/Versions/v4/squid-4.17.tar.gz
>wget https://www.e-cap.org/archive/libecap-1.0.0.tar.gz
>wget https://www.e-cap.org/archive/ecap_clamav_adapter-2.0.0.tar.gz
>
>what guide is best to follow for ecap as theres two
>
>https://wiki.squid-cache.org/Features/eCAP
>
>https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/eCAP

if you are moving to ubuntu, shouldn't you check if squid package in ubuntu 
doesn't already support it?

https://packages.ubuntu.com/jammy/squid
seems to support icap/ecap and is newer version

https://packages.ubuntu.com/jammy/libc-icap-mod-virus-scan
seems to support clamav and icap



>On Fri, 18 Nov 2022 at 07:33, robert k Wild <robertkwild at gmail.com> wrote:
>> thats fine, youve been more than helpful, thank you
>> this is where i learnt how to run squid with cicap
>> https://squidclamav.darold.net/documentation.html
>> have you got a good how to about running squid with e cap
>> whats the difference anyway between Icap and Ecap?

>>> On 17/11/2022 9:21 pm, robert k Wild wrote:
>>> > Wow thanks Amos so much for this,
>>> >
>>> > You think if I build it on rocky Linux, it would be easier?

>> On Thu, 17 Nov 2022 at 09:29, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>> I am not familiar with Rocky Linux beyond its existence.
>>> I expect it would be similar to CentOS since both are in the RHEL family.


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Micro$oft random number generator: 0, 0, 0, 4.33e+67, 0, 0, 0...


From robertkwild at gmail.com  Mon Nov 21 14:21:08 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Mon, 21 Nov 2022 14:21:08 +0000
Subject: [squid-users] moving squid from centos 7 to ubuntu 22.04
In-Reply-To: <Y3uGO1+gjqpFmlbo@fantomas.sk>
References: <CAGU_CiKK5w8+CM+=XLzaUtYS_kqO9iEVKZt2i1i1wES9Cxn-LQ@mail.gmail.com>
 <51294f1b-3c4b-73d0-d345-1773bc75cd58@treenet.co.nz>
 <CAGU_CiJ=gQU+84c4MnWxaN68iE5vri+Q9NmqSyL5ODWA25U3qw@mail.gmail.com>
 <af0afcba-3518-f576-1ba1-9a2cb3d678ce@treenet.co.nz>
 <CAGU_CiJ+NZHBvP_5NF7pPddikx+r9=zrTQG9fKqrg+PFRLvpEA@mail.gmail.com>
 <CAGU_CiKZ=ykiGgHYLR0MhRc5i2yUK-zkQnfJ3JfE887e_Zgj+A@mail.gmail.com>
 <Y3uGO1+gjqpFmlbo@fantomas.sk>
Message-ID: <CAGU_Ci+eGouw91Yd2ZZAEVQnPW+rs4j9qGovDCTL0V2XBjxONg@mail.gmail.com>

thanks Amos, sorry im so used to downloading and compiling packages as
centos never comes with the latest packages

but i still need to download/install package clamAV as i imagine the clamAV
adapter needs the clamAV package still

On Mon, 21 Nov 2022 at 14:08, Matus UHLAR - fantomas <uhlar at fantomas.sk>
wrote:

> On 21.11.22 13:55, robert k Wild wrote:
> >so to get ecap working instead if icap
> >
> >from this
> >
> >wget http://www.squid-cache.org/Versions/v4/squid-4.17.tar.gz
> >wget
> >
> http://sourceforge.net/projects/c-icap/files/c-icap/0.5.x/c_icap-0.5.10.tar.gz
> >--no-check-certificate
> >wget
> >
> http://sourceforge.net/projects/c-icap/files/c-icap-modules/0.5.x/c_icap_modules-0.5.5.tar.gz
> >--no-check-certificate
> >wget
> >
> https://sourceforge.net/projects/squidclamav/files/squidclamav/7.1/squidclamav-7.1.tar.gz
> >--no-check-certificate
> >
> >to this
> >
> >wget http://www.squid-cache.org/Versions/v4/squid-4.17.tar.gz
> >wget https://www.e-cap.org/archive/libecap-1.0.0.tar.gz
> >wget https://www.e-cap.org/archive/ecap_clamav_adapter-2.0.0.tar.gz
> >
> >what guide is best to follow for ecap as theres two
> >
> >https://wiki.squid-cache.org/Features/eCAP
> >
> >https://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/eCAP
>
> if you are moving to ubuntu, shouldn't you check if squid package in
> ubuntu
> doesn't already support it?
>
> https://packages.ubuntu.com/jammy/squid
> seems to support icap/ecap and is newer version
>
> https://packages.ubuntu.com/jammy/libc-icap-mod-virus-scan
> seems to support clamav and icap
>
>
>
> >On Fri, 18 Nov 2022 at 07:33, robert k Wild <robertkwild at gmail.com>
> wrote:
> >> thats fine, youve been more than helpful, thank you
> >> this is where i learnt how to run squid with cicap
> >> https://squidclamav.darold.net/documentation.html
> >> have you got a good how to about running squid with e cap
> >> whats the difference anyway between Icap and Ecap?
>
> >>> On 17/11/2022 9:21 pm, robert k Wild wrote:
> >>> > Wow thanks Amos so much for this,
> >>> >
> >>> > You think if I build it on rocky Linux, it would be easier?
>
> >> On Thu, 17 Nov 2022 at 09:29, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
> >>> I am not familiar with Rocky Linux beyond its existence.
> >>> I expect it would be similar to CentOS since both are in the RHEL
> family.
>
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> Micro$oft random number generator: 0, 0, 0, 4.33e+67, 0, 0, 0...
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221121/93cdcd97/attachment.htm>

From pponakanti at roblox.com  Wed Nov 23 02:06:19 2022
From: pponakanti at roblox.com (Praveen Ponakanti)
Date: Tue, 22 Nov 2022 18:06:19 -0800
Subject: [squid-users] Scaling concurrent TCP sessions beyond ephemeral
 port range
In-Reply-To: <a8746396-a00d-65d3-ed60-7f20e10c9bed@measurement-factory.com>
References: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>
 <f7f62043-e384-0395-6d0f-ff4d510b0baf@measurement-factory.com>
 <CACabJxNv5+o7AiY-tfuJ=_V4ZBNEks=dX4ki2YQBHcPPpUrABg@mail.gmail.com>
 <5856354a-393a-0803-e3e6-da29f8f7d8b1@treenet.co.nz>
 <CACabJxMt1wkt7cUJH00WpbVK9wA2-8odhS8QrMGPhe8w4SUQpw@mail.gmail.com>
 <97b1c32d-2172-d2fa-bfde-dd8c850c799a@measurement-factory.com>
 <CACabJxP1f8YhngBG6WzkRZ4W+RzcM4cc0HoXo2=5bGsQCFUsBQ@mail.gmail.com>
 <40a11002-0925-c791-683b-8fee212224e8@measurement-factory.com>
 <CACabJxMXendT2FFn5u9dFqYhWNrBab=E1k-JbWUAWV=qrCPW2w@mail.gmail.com>
 <a8746396-a00d-65d3-ed60-7f20e10c9bed@measurement-factory.com>
Message-ID: <CACabJxP4bXq5X-U360NL2v65RQ7o=--_h-NxT=P6DCygvC87Hg@mail.gmail.com>

Hi Alex,

Do we have a recent squid ver 6 snapshot build available for testing?
Looking for something that includes the patch from the PR to introduce the
ip_bind_address_noport socket option on outbound TCP connections, I dont
see any new builds after Sep 6th.

http://www.squid-cache.org/Versions/v6/


We have been using the last commit (prior to merge) from my branch on a few
canary instances and have observed a memory leak with squid 6.0.0.  The
memory usage by squid with that code has grown by almost 20G over the last
2+ months, while other v5.5 squids (with a local patch for adding that
socket option) have not had that significant of an increase.


Thanks for your insights below, apologies for not being able to try your
suggestions until recently. I hadn't looked at the coordinator in depth and
forgotten that squid workers are not threads.
The following config knobs were tried and did not make much of a difference
with respect to concurrent outbound TLS sessions across the workers. The
docs say the default sslproxy_session_cache_size is 2 MB, how high can we
go? Are there any other knobs we can try to improve session reuse for HTTPS
reqs ? (without enabling squid cache)

sslproxy_session_cache_size 10 MB
tls_outgoing_options options=NO_TICKET


> Agree, it might not make sense to increase the complexity with sharing
> > socket among the workers. Was thinking more on the lines of a hashmap
> > that the coordinator could use to pick workers that already have a TCP
> > connection to the destination being requested, instead of having the
> > workers themselves share connection details.


> Coordinator does not receive/see regular HTTP traffic. If we start
> routing HTTP transactions through that process, it may become the
> bottleneck itself _and_ will introduce additional overheads for passing
> descriptors to workers. From performance point of view, the model with
> one "routing" task doling work to workers works best (and is commonly
> used) in threaded applications, but Squid is not threaded at that level.
>
>

> > Most of the TCP connections are for HTTPS reqs, w/o TLS termination at
> > the squid. Does squid currently support a TLS session cache ?
>
> Yes, there is some support for worker-specific TLS session caching, with
> directives like sslproxy_session_cache_size, tls_outgoing_options
> options=NO_TICKET (for outgoing sessions IIRC) and https_port
> sslflags=NO_SESSION_REUSE and https_port sslcontext (for incoming
> sessions).
>

> HTH,
>
> Alex.
>
>
> >     If you are dealing with TLS sessions as well, then we should add a
> >     shared memory TLS session cache that all workers can tap into.
> >
> >
> >     Cheers,
> >
> >     Alex.
> >
> >      > On Tue, Jun 21, 2022 at 2:11 PM Alex Rousskov wrote:
> >      >
> >      >     On 6/19/22 12:48, Praveen Ponakanti wrote:
> >      >
> >      >      > What is the process to have this code patch upstreamed for
> >     future
> >      >     squid
> >      >      > versions?
> >      >
> >      >     In short, just post a quality pull request on GitHub (or find
> >     somebody
> >      >     who can guide your code towards official acceptance for you).
> For
> >      >     details, please see
> >     https://wiki.squid-cache.org/MergeProcedure
> >     <https://wiki.squid-cache.org/MergeProcedure>
> >      >     <https://wiki.squid-cache.org/MergeProcedure
> >     <https://wiki.squid-cache.org/MergeProcedure>>
> >      >
> >      >
> >      >     Thank you,
> >      >
> >      >     Alex.
> >      >
> >      >
> >      >      > On Fri, May 20, 2022 at 9:31 PM Amos Jeffries
> >      >     <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>
> >     <mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>
> >      >      > wrote:
> >      >      >
> >      >      >     On 20/05/22 19:44, Praveen Ponakanti wrote:
> >      >      >      > Hi Alex,
> >      >      >      >
> >      >      >      > Thanks for going through several steps to help
> mitigate
> >      >     src port
> >      >      >      > exhaustion. We are looking to achieve 400-500% more
> >      >      >      > concurrent connections if we could :) as there is a
> >      >      >     significant buffer
> >      >      >      > on the available CPU.
> >      >      >
> >      >      >     Then you require at least 4, maybe 5, IP addresses to
> >     handle
> >      >     that many
> >      >      >     concurrent connections with Squid.
> >      >      >
> >      >      >
> >      >      > We would like to investigate going beyond the ephemeral
> port
> >      >     range for
> >      >      > some specific destination IP:PORT addresses. For that it
> >     appears
> >      >     squid
> >      >      > does not round-robin requests if we use multiple
> >      >     tcp_outgoing_addresses.
> >      >      > We could use ACL?s to pick a different outbound IP based
> >     on the
> >      >     clients
> >      >      > source IP, however that is not very ideal in our
> >     environment as our
> >      >      > clients aren?t always equally split by subnet. However, if
> >     we could
> >      >      > split by the client?s source port that might help achieve
> >     this. For
> >      >      > example something like:
> >      >      >
> >      >      >
> >      >      > acl pool1 clientport 0-32768
> >      >      >
> >      >      > acl pool2 clientport 32769-65536
> >      >      >
> >      >      >
> >      >      > tcp_outgoing_address 10.1.0.1 pool1
> >      >      >
> >      >      > tcp_outgoing_address 10.1.0.2 pool2
> >      >      >
> >      >      >
> >      >      > Squid's ACLs currently do not allow filtering by the
> >     client's source
> >      >      > port. We could look into a separate patch to add this
> >      >     functionality to
> >      >      > squid?s ACL code if that makes sense. Or is there a better
> >     way to
> >      >      > achieve this?
> >      >      >
> >      >      >
> >      >      > Thanks
> >      >      >
> >      >      > Praveen
> >      >      >
> >      >      >
> >      >      >      > The option to use multiple tcp_outoing_addresses
> >     appears to be
> >      >      >     promising
> >      >      >      > along with some tweaks to the TCP timeouts. I guess
> we
> >      >     could use
> >      >      >     ACLs to
> >      >      >      > pick a different outbound IP based on the
> >     requesting client's
> >      >      >     prefix. We
> >      >      >      > had not considered that option as the ephemeral
> >     ports were
> >      >     no longer
> >      >      >      > available to other applications when squid uses
> most of
> >      >     them with a
> >      >      >      > single outbound IP configured. We are also looking
> to
> >      >     modify the
> >      >      >     code to
> >      >      >      > use the IP_BIND_ADDRESS_NO_PORT sockopt as that
> >     could help
> >      >     delay
> >      >      >     port
> >      >      >      > assignment with the bind() call on the outbound TCP
> >      >     sessions (to
> >      >      >      > hopefully allow access to the 4-tuple on the
> socket).
> >      >      >
> >      >      >     Patches welcome.
> >      >      >
> >      >      >     However, please be aware that use of the 4-tuple is
> >     often no
> >      >     different
> >      >      >     from the 3-tuple since the dst-port is typically
> identical
> >      >     for all
> >      >      >     outgoing traffic to a given dst-IP.
> >      >      >
> >      >      >
> >      >      >     Cheers
> >      >      >     Amos
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221122/4a00f4a8/attachment.htm>

From rousskov at measurement-factory.com  Wed Nov 23 03:58:31 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 22 Nov 2022 22:58:31 -0500
Subject: [squid-users] Scaling concurrent TCP sessions beyond ephemeral
 port range
In-Reply-To: <CACabJxP4bXq5X-U360NL2v65RQ7o=--_h-NxT=P6DCygvC87Hg@mail.gmail.com>
References: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>
 <f7f62043-e384-0395-6d0f-ff4d510b0baf@measurement-factory.com>
 <CACabJxNv5+o7AiY-tfuJ=_V4ZBNEks=dX4ki2YQBHcPPpUrABg@mail.gmail.com>
 <5856354a-393a-0803-e3e6-da29f8f7d8b1@treenet.co.nz>
 <CACabJxMt1wkt7cUJH00WpbVK9wA2-8odhS8QrMGPhe8w4SUQpw@mail.gmail.com>
 <97b1c32d-2172-d2fa-bfde-dd8c850c799a@measurement-factory.com>
 <CACabJxP1f8YhngBG6WzkRZ4W+RzcM4cc0HoXo2=5bGsQCFUsBQ@mail.gmail.com>
 <40a11002-0925-c791-683b-8fee212224e8@measurement-factory.com>
 <CACabJxMXendT2FFn5u9dFqYhWNrBab=E1k-JbWUAWV=qrCPW2w@mail.gmail.com>
 <a8746396-a00d-65d3-ed60-7f20e10c9bed@measurement-factory.com>
 <CACabJxP4bXq5X-U360NL2v65RQ7o=--_h-NxT=P6DCygvC87Hg@mail.gmail.com>
Message-ID: <984bcb90-05cd-fb2b-5955-59593219c10e@measurement-factory.com>

On 11/22/22 21:06, Praveen Ponakanti wrote:

> Do we have a recent squid ver 6 snapshot build available for testing? 

Sorry, I do not know the exact answer to your question. One can 
certainly build master/v6 from git sources, of course.


> The following config knobs were tried and did not make much of a 
> difference with respect to concurrent outbound TLS sessions across the 
> workers.

I can only speculate that there is a Squid bug that prevents workers 
from using (or sharing) the TLS session cache OR your traffic patterns 
do not allow (much) sharing OR your TLS session cache is too small for 
those traffic patterns. Lot's of possibilities here!


> The docs say the default sslproxy_session_cache_size is 2 MB, 
> how high can we go?

I have not tested this, but, bugs notwithstanding, I would expect you to 
be able to go as high as the maximum shared memory segment size in your 
environment (e.g., see sysctl kernel.shmax). The entire cache must fit 
into a single shared memory segment IIRC. It certainly does not hurt to 
try 100 MB if you already tried 10 MB. Squid should complain if it 
cannot allocate a segment of the specified size.


> Are there any other knobs we can try to improve 
> session reuse for HTTPS reqs ? (without enabling squid cache)

FWIW, I would try to understand _why_ sessions are not shared (enough) 
in the first place, especially if increasing sslproxy_session_cache_size 
value does not result in session cache hit ratio increase while there 
are still many false cache misses. I do not know whether anybody is 
paying a lot of attention to that cache in production, but the 
corresponding Squid code is not tested by the Squid Project CI (yet?).

Also, there are different kinds of TLS session reuse. It is possible 
that the sessions you want to reuse are not supported by the Squid 
session cache. Unfortunately, I do not remember enough details to tell 
you more, but one can set up a controlled test and see what is actually 
going on.


HTH,

Alex.


> sslproxy_session_cache_size 10 MB
> tls_outgoing_options options=NO_TICKET
> 
> 
>     > Agree, it might not make sense to increase the complexity with sharing
>     > socket among the workers. Was thinking more on the lines of a hashmap
>     > that the coordinator could use to pick workers that already have a TCP
>     > connection to the destination being requested, instead of having the
>     > workers themselves share connection details.
> 
> 
>     Coordinator does not receive/see regular HTTP traffic. If we start
>     routing HTTP transactions through that process, it may become the
>     bottleneck itself _and_ will introduce additional overheads for passing
>     descriptors to workers. From performance point of view, the model with
>     one "routing" task doling work to workers works best (and is commonly
>     used) in threaded applications, but Squid is not threaded at that level.
> 
> 
>      > Most of the TCP connections are for HTTPS reqs, w/o TLS
>     termination at
>      > the squid. Does squid currently support a TLS session cache ?
> 
>     Yes, there is some support for worker-specific TLS session caching,
>     with
>     directives like sslproxy_session_cache_size, tls_outgoing_options
>     options=NO_TICKET (for outgoing sessions IIRC) and https_port
>     sslflags=NO_SESSION_REUSE and https_port sslcontext (for incoming
>     sessions).
> 
> 
>     HTH,
> 
>     Alex.
> 
> 
>      >? ? ?If you are dealing with TLS sessions as well, then we should
>     add a
>      >? ? ?shared memory TLS session cache that all workers can tap into.
>      >
>      >
>      >? ? ?Cheers,
>      >
>      >? ? ?Alex.
>      >
>      >? ? ? > On Tue, Jun 21, 2022 at 2:11 PM Alex Rousskov wrote:
>      >? ? ? >
>      >? ? ? >? ? ?On 6/19/22 12:48, Praveen Ponakanti wrote:
>      >? ? ? >
>      >? ? ? >? ? ? > What is the process to have this code patch
>     upstreamed for
>      >? ? ?future
>      >? ? ? >? ? ?squid
>      >? ? ? >? ? ? > versions?
>      >? ? ? >
>      >? ? ? >? ? ?In short, just post a quality pull request on GitHub
>     (or find
>      >? ? ?somebody
>      >? ? ? >? ? ?who can guide your code towards official acceptance
>     for you). For
>      >? ? ? >? ? ?details, please see
>      > https://wiki.squid-cache.org/MergeProcedure
>     <https://wiki.squid-cache.org/MergeProcedure>
>      >? ? ?<https://wiki.squid-cache.org/MergeProcedure
>     <https://wiki.squid-cache.org/MergeProcedure>>
>      >? ? ? >? ? ?<https://wiki.squid-cache.org/MergeProcedure
>     <https://wiki.squid-cache.org/MergeProcedure>
>      >? ? ?<https://wiki.squid-cache.org/MergeProcedure
>     <https://wiki.squid-cache.org/MergeProcedure>>>
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >? ? ?Thank you,
>      >? ? ? >
>      >? ? ? >? ? ?Alex.
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >? ? ? > On Fri, May 20, 2022 at 9:31 PM Amos Jeffries
>      >? ? ? >? ? ?<squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>
>     <mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>
>      >? ? ?<mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>
>     <mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>>
>      >? ? ? >? ? ? > wrote:
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?On 20/05/22 19:44, Praveen Ponakanti wrote:
>      >? ? ? >? ? ? >? ? ? > Hi Alex,
>      >? ? ? >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? > Thanks for going through several steps to
>     help mitigate
>      >? ? ? >? ? ?src port
>      >? ? ? >? ? ? >? ? ? > exhaustion. We are looking to achieve
>     400-500% more
>      >? ? ? >? ? ? >? ? ? > concurrent?connections if we could :) as
>     there is a
>      >? ? ? >? ? ? >? ? ?significant?buffer
>      >? ? ? >? ? ? >? ? ? > on the available CPU.
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?Then you require at least 4, maybe 5, IP
>     addresses to
>      >? ? ?handle
>      >? ? ? >? ? ?that many
>      >? ? ? >? ? ? >? ? ?concurrent connections with Squid.
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > We would like to investigate going beyond the
>     ephemeral port
>      >? ? ? >? ? ?range for
>      >? ? ? >? ? ? > some specific destination IP:PORT addresses. For
>     that it
>      >? ? ?appears
>      >? ? ? >? ? ?squid
>      >? ? ? >? ? ? > does not round-robin requests if we use multiple
>      >? ? ? >? ? ?tcp_outgoing_addresses.
>      >? ? ? >? ? ? > We could use ACL?s to pick a different outbound IP
>     based
>      >? ? ?on the
>      >? ? ? >? ? ?clients
>      >? ? ? >? ? ? > source IP, however that is not very ideal in our
>      >? ? ?environment as our
>      >? ? ? >? ? ? > clients aren?t always equally split by subnet.
>     However, if
>      >? ? ?we could
>      >? ? ? >? ? ? > split by the client?s source port that might help
>     achieve
>      >? ? ?this. For
>      >? ? ? >? ? ? > example something like:
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > acl pool1 clientport 0-32768
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > acl pool2 clientport 32769-65536
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > tcp_outgoing_address 10.1.0.1 pool1
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > tcp_outgoing_address 10.1.0.2 pool2
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Squid's ACLs currently do not allow filtering by the
>      >? ? ?client's source
>      >? ? ? >? ? ? > port. We could look into a separate patch to add this
>      >? ? ? >? ? ?functionality to
>      >? ? ? >? ? ? > squid?s ACL code if that makes sense. Or is there a
>     better
>      >? ? ?way to
>      >? ? ? >? ? ? > achieve this?
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Thanks
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Praveen
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ? > The option to use multiple tcp_outoing_addresses
>      >? ? ?appears to be
>      >? ? ? >? ? ? >? ? ?promising
>      >? ? ? >? ? ? >? ? ? > along with some tweaks to the TCP timeouts.
>     I guess we
>      >? ? ? >? ? ?could use
>      >? ? ? >? ? ? >? ? ?ACLs to
>      >? ? ? >? ? ? >? ? ? > pick a different outbound IP based on the
>      >? ? ?requesting client's
>      >? ? ? >? ? ? >? ? ?prefix. We
>      >? ? ? >? ? ? >? ? ? > had not considered that option as the ephemeral
>      >? ? ?ports were
>      >? ? ? >? ? ?no longer
>      >? ? ? >? ? ? >? ? ? > available?to other applications when squid
>     uses most of
>      >? ? ? >? ? ?them with a
>      >? ? ? >? ? ? >? ? ? > single outbound IP configured. We are also
>     looking to
>      >? ? ? >? ? ?modify the
>      >? ? ? >? ? ? >? ? ?code to
>      >? ? ? >? ? ? >? ? ? > use the IP_BIND_ADDRESS_NO_PORT sockopt as that
>      >? ? ?could help
>      >? ? ? >? ? ?delay
>      >? ? ? >? ? ? >? ? ?port
>      >? ? ? >? ? ? >? ? ? > assignment with the bind() call on the
>     outbound TCP
>      >? ? ? >? ? ?sessions (to
>      >? ? ? >? ? ? >? ? ? > hopefully allow access to the 4-tuple on the
>     socket).
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?Patches welcome.
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?However, please be aware that use of the 4-tuple is
>      >? ? ?often no
>      >? ? ? >? ? ?different
>      >? ? ? >? ? ? >? ? ?from the 3-tuple since the dst-port is
>     typically identical
>      >? ? ? >? ? ?for all
>      >? ? ? >? ? ? >? ? ?outgoing traffic to a given dst-IP.
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? >? ? ?Cheers
>      >? ? ? >? ? ? >? ? ?Amos
> 



From support at unveiltech.com  Wed Nov 23 12:59:25 2022
From: support at unveiltech.com (UnveilTech - Support)
Date: Wed, 23 Nov 2022 12:59:25 +0000
Subject: [squid-users] [SPAM] Re: Squid 5: server_cert_fingerprint not
 working fine...
In-Reply-To: <69e50488-3006-0e8b-6b7e-c4b48d76801e@articatech.com>
References: <3adf99e022084a76b0f18ffb1f3f605f@unveiltech.com>
 <ab1b5b8d00874760a80cecf61772aeaa@unveiltech.com>
 <67763d66-e264-14a1-f599-224749c18f71@treenet.co.nz>
 <796a78058b01409f8cd220f3a33a27ae@unveiltech.com>
 <19ae1da5-5d0a-93d6-e91f-3e82b064b1ed@treenet.co.nz>
 <69e50488-3006-0e8b-6b7e-c4b48d76801e@articatech.com>
Message-ID: <f1adf0a84faa4585a7f4ed8ffdf18669@unveiltech.com>

Amos,

For your information, sslcrtvalidator_program is also not compatible with TLS1.3.
We have done dozen of tests and we only get TLS1.2 information with sslcrtvalidator_program.

My ? question-conclusion ? ?  could be ridiculous but the imcompability is here a fact, sorry for that.
Instead a PHP helper we have build a C++ helper (300 lines including comments) and we can also work with TLS1.3 by using basis OpenSSL functions, we suppose the same the Squid uses?

PS : OpenSSL is the same we use to compile Squid 5.7.

Ye Fred

De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de David Touzeau
Envoy? : samedi 19 novembre 2022 19:19
? : squid-users at lists.squid-cache.org
Objet : [SPAM] Re: [squid-users] Squid 5: server_cert_fingerprint not working fine...

Thanks Amos for this clarification,

We also have the same needs and indeed, we face with the same approach.

It is possible that the structure of Squid could not, in some cases, recovering this type of information.
Although the concept of a proxy is neither more nor less than a big browser that surfs instead of the client browsers.

The SHA1 and certificate information reception are very valuable because it ensures better detection of compromised sites (many malicious sites use the same information in their certificates).
This allows detecting "nests" of malicious sites automatically.

Unfortunately, there is madness in the approach to security, there is a race to strengthen the security of tunnels (produced by Google and browsers vendors).
What is the advantage of encrypting wikipedia and Youtube channels?

On the other hand, it is crucial to look inside these streams to detect threats.
This is antinomic...

So TLS 1.3 and soon the use of QUIC with UDP 80/443 will make use of a proxy useless as these features are rolled out  (trust Google to motivate them)
Unless the proxy manages to follow this protocol madness race...

For this reason, firewall manufacturers propose the use of client software that fills the gap of protocol visibility in their gateway products or you -can see a growth of workstation protections , such EDR concept

Just an ideological and non-technical approach...

Regards
Le 19/11/2022 ? 16:50, Amos Jeffries a ?crit :
On 19/11/2022 2:55 am, UnveilTech - Support wrote:

Hi Amos,

We have tested with a "ssl_bump bump" ("ssl_bump all" and "ssl_bump bump sslstep1"), it does not solve the problem.
According to Alex, we can also confirm it's a bug with Squid 5.x and TLS 1.3.

Okay.


It seems Squid is only compatible with TLS 1.2, it's not good for the future...

One bug (or lack of ability) does not make the entire protocol "incompatible". It only affects people trying to do the particular buggy action.
Unfortunately for you (and others) it happens to be accessing this server cert fingerprint.

I/we have been clear from the beginning that *when used properly* TLS/SSL cannot be "bump"ed - that is true for all versions of TLS and SSL before it. In that same "bump" use-case the server does not provide *any* details, it just rejects the proxy attempted connection. In some paranoid security environments the server can reject even for "splice" when the clientHello is passed on unchanged by the proxy. HTTPS use on the web is typically *neither* of those "proper" setups so SSL-Bump "bump" in general works and "splice" almost always.

Cheers
Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221123/fd528bb1/attachment.htm>

From ngtech1ltd at gmail.com  Wed Nov 23 21:58:31 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Wed, 23 Nov 2022 23:58:31 +0200
Subject: [squid-users] Squid 5: server_cert_fingerprint not working
 fine...
Message-ID: <001201d8ff86$ba7267b0$2f573710$@gmail.com>

Hey Fred,
 
First take into account that to the Squid-Users no question is ridicules at any time!!!!
There are couple sides for a forum/list and only one of them is the technical one.
I was told by a good mentor of me the next sentence:
Think about the other side of the conversation on the line like your own son or daughter.
Sometimes a father or a friend are saying things because they truly love you. The only reason you might not understand the comparison you are doing is probably since you are not used to do specific tasks.
And I will try to make sense of both sides.
Think about squid about the ?nice? kid in the neighborhood.
Squid is almost the only proxy software out there that is trying to give a solution for everything and every use case for a very long time.
It is more complicated to support everyone then writing a proxy that does one specific thing very good.
 
Squid is here since 1985~ and will not be taken down easily and will kick in the web a long ahead compared to others.
This is despite it not being the most advertised software out there.
The original goal of Squid-Cache was achieved and not just in a standard way but with a really good success and every piece of the Internet was and is still affected by it.
 
Sometimes I would answer my kid with a really rough answer (compared to what I believe should have been a softer one) but my intent is good.
 
This is a place where we would like you Fred to get a grasp of what is happening and to help you become better and only one of the tools to get there is coding.
The Squid-Cache project tried and tries to make the proxy smart as possible and to not harm while doing it?s job/purpose.
 
For example, ufdbguard (which is a great piece of code which deserves honor and respect) does destination tls probing.
The overhead for that is that eventually (if there is no caching involved) per CONNECT request there is another tls/tcp request that is going to hit the hosting service.
For a single connection of a home user it?s fine.
For a single connection of a home user doubles an ISP it?s not fine?
I will call this as it is, an ?amplification attack?.
Which means that every single action hits in power of 2 or more.
Squid tries to avoid this as much as possible.
 
I would try to give you a sense of the issue in a human level.
Assume that there is a shop in the street that sell .. let say fruits.
One customer comes and asks to taste something small from the store before buying. As a good and nice shop owner he lets him do so.
Then a bunch of clients comes and take each a fruit to ?taste? and goes off without buying anything.
The end result is that the whole sector of this specific fruit is gone and the owner left with an open mouth shocked and.. robbed.
 
Take into account that every single TLS connection consumes more CPU then a single linux kernel ?sendfile? operation.
To make more sense of it, a CPU is merely some form of programmable electrical resistor.
If you would know something in electronics(these days called electricity engineering) there is a specific life span to a resistor and by definition to any electrical component.
 
I believe that you don?t want to harm every CPU in every site your clients are visiting.
Every HIT costs and one of the goals of Squid-Cache is to reduce these HITs on the origin service and to offload some of the HIT rate from the origin server and to allow the local or regional ISP take the HIT on itself since it?s more reasonable for a group of clients to take the HIT for their demand for any communication consumption.
 
For some reason else then maybe Microsoft the Gaming industry and couple other big players nobody wants to be a part of this.
And it?s not that I don?t understand why many goes after the TLS everywhere and couple other communication trends but it?s mostly because of an un-justified fear.
TLS is not security but rather it?s a burden on the service providers and shop owners, it?s actually a ?protection? mechanism.
So I would just say that to protect the data you don?t need to protect every piece of the shop but rather make an effort to block the ?escape? routes or ?leak? routes.
 
What you want to achieve is good but what I am trying to say is that you must have both brains and sensitivity to others on the Internet and if you are probing the services on the Internet you should write a good caching layer that will lower the power of your amplification attack from power of 2 to a lower ratio since probably the signature of a SNI+ip+port or NO-SNI+ip+port would stay the same for at-least 12 hours and with let-encrypt around the cert is valid and fresh for 30~ days for a domain star certificate.
 
So to summarize:
I didn?t touch every piece of technical aspect of the SNI+IP+PORT TLS probing solution but I hope it?s enough to make some sense into caching with redis(for example) the results of this probing.
 
And if you would ask any standard and non-greedy client if they would prefer to get good security without harming the service provider, they would surly answer they would be ok waiting an extra couple milliseconds for the caching layer to get a good answer like from a MariaDB table(layer 2) compared to a Redis(layer 1).
 
And I just must tell you something:
I am religious person and we have a very old story about a person who wanted to get to Jerusalem. (in the old days)
He got to a place near Jerusalem where you cannot see the city because of the hills and also because Jerusalem(old one) is actually a very low mountain compared to couple others in the area.
In this place the kids of Jerusalem were playing and wondering around and he have seen one kid (the kids of Jerusalem are known for their wisdom).
He then asked him for directions to Jerusalem and the kid told him the next:
You have from here two ways to Jerusalem, the short long and the long short.
He assumed that the short long is the shorter? but..
He started walking this short long way and it was a nice and smooth route but as he started seeing Jerusalem, he started to stumble thorns and bushes. After fighting the ? lost cause to reach Jerusalem he got back to the intersection of roads where he met the boy.
He then asked him: Why did you told me that this is the short way? It?s the worst way to get to Jerusalem!!!!
The kid then answered him: I told you there are two ways.
There is a short and long while the other is long but short.
He then tried the other way understanding the basic wisdom of the kids of Jerusalem.
Indeed the ?long short? way started rough but not as rough as the other rough part of the ?short long? way.
After a while when he was a bit exhausted from the road he saw Jerusalem so close he felt he was already there and as he saw this he gets a relief since from this point the terrain became smooth.
At this point he got to grasp how smart are the kids of Jerusalem and threw a blessing to the air ?If this smart are the kids of Jerusalem, I wish their wisdom would spread in the world?.
 
I have known your name for a very long time and I believe you are on the right track, just make sure that the architecture of your helper is smart enough so that the amplification attack it causes will try to get to the result with less then the power of 2 HIT ratio on the services it?s probing.
 
Yours,
Eliezer  
 
----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/
 
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of UnveilTech - Support
Sent: Wednesday, 23 November 2022 14:59
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] [SPAM] Re: Squid 5: server_cert_fingerprint not working fine...
 
Amos,
 
For your information, sslcrtvalidator_program is also not compatible with TLS1.3.
We have done dozen of tests and we only get TLS1.2 information with sslcrtvalidator_program.
 
My ? question-conclusion ? ?  could be ridiculous but the imcompability is here a fact, sorry for that.
Instead a PHP helper we have build a C++ helper (300 lines including comments) and we can also work with TLS1.3 by using basis OpenSSL functions, we suppose the same the Squid uses?
 
PS : OpenSSL is the same we use to compile Squid 5.7.
 
Ye Fred
 
De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de David Touzeau
Envoy? : samedi 19 novembre 2022 19:19
? : squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Objet : [SPAM] Re: [squid-users] Squid 5: server_cert_fingerprint not working fine...
 
Thanks Amos for this clarification,

We also have the same needs and indeed, we face with the same approach.

It is possible that the structure of Squid could not, in some cases, recovering this type of information.
Although the concept of a proxy is neither more nor less than a big browser that surfs instead of the client browsers.

The SHA1 and certificate information reception are very valuable because it ensures better detection of compromised sites (many malicious sites use the same information in their certificates).
This allows detecting "nests" of malicious sites automatically.

Unfortunately, there is madness in the approach to security, there is a race to strengthen the security of tunnels (produced by Google and browsers vendors).
What is the advantage of encrypting wikipedia and Youtube channels?

On the other hand, it is crucial to look inside these streams to detect threats.
This is antinomic...

So TLS 1.3 and soon the use of QUIC with UDP 80/443 will make use of a proxy useless as these features are rolled out  (trust Google to motivate them)
Unless the proxy manages to follow this protocol madness race...

For this reason, firewall manufacturers propose the use of client software that fills the gap of protocol visibility in their gateway products or you -can see a growth of workstation protections , such EDR concept

Just an ideological and non-technical approach...

Regards
Le 19/11/2022 ? 16:50, Amos Jeffries a ?crit :
On 19/11/2022 2:55 am, UnveilTech - Support wrote: 
Hi Amos, 

We have tested with a "ssl_bump bump" ("ssl_bump all" and "ssl_bump bump sslstep1"), it does not solve the problem. 
According to Alex, we can also confirm it's a bug with Squid 5.x and TLS 1.3. 

Okay. 


It seems Squid is only compatible with TLS 1.2, it's not good for the future... 

One bug (or lack of ability) does not make the entire protocol "incompatible". It only affects people trying to do the particular buggy action. 
Unfortunately for you (and others) it happens to be accessing this server cert fingerprint. 

I/we have been clear from the beginning that *when used properly* TLS/SSL cannot be "bump"ed - that is true for all versions of TLS and SSL before it. In that same "bump" use-case the server does not provide *any* details, it just rejects the proxy attempted connection. In some paranoid security environments the server can reject even for "splice" when the clientHello is passed on unchanged by the proxy. HTTPS use on the web is typically *neither* of those "proper" setups so SSL-Bump "bump" in general works and "splice" almost always. 

Cheers 
Amos 

_______________________________________________ 
squid-users mailing list 
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>  
http://lists.squid-cache.org/listinfo/squid-users 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221123/d830bfa9/attachment.htm>

From pponakanti at roblox.com  Wed Nov 23 23:07:01 2022
From: pponakanti at roblox.com (Praveen Ponakanti)
Date: Wed, 23 Nov 2022 15:07:01 -0800
Subject: [squid-users] Scaling concurrent TCP sessions beyond ephemeral
 port range
In-Reply-To: <984bcb90-05cd-fb2b-5955-59593219c10e@measurement-factory.com>
References: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>
 <f7f62043-e384-0395-6d0f-ff4d510b0baf@measurement-factory.com>
 <CACabJxNv5+o7AiY-tfuJ=_V4ZBNEks=dX4ki2YQBHcPPpUrABg@mail.gmail.com>
 <5856354a-393a-0803-e3e6-da29f8f7d8b1@treenet.co.nz>
 <CACabJxMt1wkt7cUJH00WpbVK9wA2-8odhS8QrMGPhe8w4SUQpw@mail.gmail.com>
 <97b1c32d-2172-d2fa-bfde-dd8c850c799a@measurement-factory.com>
 <CACabJxP1f8YhngBG6WzkRZ4W+RzcM4cc0HoXo2=5bGsQCFUsBQ@mail.gmail.com>
 <40a11002-0925-c791-683b-8fee212224e8@measurement-factory.com>
 <CACabJxMXendT2FFn5u9dFqYhWNrBab=E1k-JbWUAWV=qrCPW2w@mail.gmail.com>
 <a8746396-a00d-65d3-ed60-7f20e10c9bed@measurement-factory.com>
 <CACabJxP4bXq5X-U360NL2v65RQ7o=--_h-NxT=P6DCygvC87Hg@mail.gmail.com>
 <984bcb90-05cd-fb2b-5955-59593219c10e@measurement-factory.com>
Message-ID: <CACabJxP_wdxvBqpZPQ1ccqJQKKA9NctOWxZZwzCx2ZXKBh5tYQ@mail.gmail.com>

Hi Alex,

Thanks for all the details. I will build a new squid image off master/v6 to
check for the memory leak with test traffic.
Regarding the TLS session cache, I will try setting it to 100MB. Are there
any stats exposed from the tls session cache that can be monitored to study
the session cache usage with our traffic patterns? Would those be
accessible via the squid-internal-mgr endpoint?
Thanks
Praveen

On Tue, Nov 22, 2022 at 7:58 PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 11/22/22 21:06, Praveen Ponakanti wrote:
>
> > Do we have a recent squid ver 6 snapshot build available for testing?
>
> Sorry, I do not know the exact answer to your question. One can
> certainly build master/v6 from git sources, of course.
>
>
> > The following config knobs were tried and did not make much of a
> > difference with respect to concurrent outbound TLS sessions across the
> > workers.
>
> I can only speculate that there is a Squid bug that prevents workers
> from using (or sharing) the TLS session cache OR your traffic patterns
> do not allow (much) sharing OR your TLS session cache is too small for
> those traffic patterns. Lot's of possibilities here!
>
>
> > The docs say the default sslproxy_session_cache_size is 2 MB,
> > how high can we go?
>
> I have not tested this, but, bugs notwithstanding, I would expect you to
> be able to go as high as the maximum shared memory segment size in your
> environment (e.g., see sysctl kernel.shmax). The entire cache must fit
> into a single shared memory segment IIRC. It certainly does not hurt to
> try 100 MB if you already tried 10 MB. Squid should complain if it
> cannot allocate a segment of the specified size.
>
>
> > Are there any other knobs we can try to improve
> > session reuse for HTTPS reqs ? (without enabling squid cache)
>
> FWIW, I would try to understand _why_ sessions are not shared (enough)
> in the first place, especially if increasing sslproxy_session_cache_size
> value does not result in session cache hit ratio increase while there
> are still many false cache misses. I do not know whether anybody is
> paying a lot of attention to that cache in production, but the
> corresponding Squid code is not tested by the Squid Project CI (yet?).
>
> Also, there are different kinds of TLS session reuse. It is possible
> that the sessions you want to reuse are not supported by the Squid
> session cache. Unfortunately, I do not remember enough details to tell
> you more, but one can set up a controlled test and see what is actually
> going on.
>
>
> HTH,
>
> Alex.
>
>
> > sslproxy_session_cache_size 10 MB
> > tls_outgoing_options options=NO_TICKET
> >
> >
> >     > Agree, it might not make sense to increase the complexity with
> sharing
> >     > socket among the workers. Was thinking more on the lines of a
> hashmap
> >     > that the coordinator could use to pick workers that already have a
> TCP
> >     > connection to the destination being requested, instead of having
> the
> >     > workers themselves share connection details.
> >
> >
> >     Coordinator does not receive/see regular HTTP traffic. If we start
> >     routing HTTP transactions through that process, it may become the
> >     bottleneck itself _and_ will introduce additional overheads for
> passing
> >     descriptors to workers. From performance point of view, the model
> with
> >     one "routing" task doling work to workers works best (and is commonly
> >     used) in threaded applications, but Squid is not threaded at that
> level.
> >
> >
> >      > Most of the TCP connections are for HTTPS reqs, w/o TLS
> >     termination at
> >      > the squid. Does squid currently support a TLS session cache ?
> >
> >     Yes, there is some support for worker-specific TLS session caching,
> >     with
> >     directives like sslproxy_session_cache_size, tls_outgoing_options
> >     options=NO_TICKET (for outgoing sessions IIRC) and https_port
> >     sslflags=NO_SESSION_REUSE and https_port sslcontext (for incoming
> >     sessions).
> >
> >
> >     HTH,
> >
> >     Alex.
> >
> >
> >      >     If you are dealing with TLS sessions as well, then we should
> >     add a
> >      >     shared memory TLS session cache that all workers can tap into.
> >      >
> >      >
> >      >     Cheers,
> >      >
> >      >     Alex.
> >      >
> >      >      > On Tue, Jun 21, 2022 at 2:11 PM Alex Rousskov wrote:
> >      >      >
> >      >      >     On 6/19/22 12:48, Praveen Ponakanti wrote:
> >      >      >
> >      >      >      > What is the process to have this code patch
> >     upstreamed for
> >      >     future
> >      >      >     squid
> >      >      >      > versions?
> >      >      >
> >      >      >     In short, just post a quality pull request on GitHub
> >     (or find
> >      >     somebody
> >      >      >     who can guide your code towards official acceptance
> >     for you). For
> >      >      >     details, please see
> >      > https://wiki.squid-cache.org/MergeProcedure
> >     <https://wiki.squid-cache.org/MergeProcedure>
> >      >     <https://wiki.squid-cache.org/MergeProcedure
> >     <https://wiki.squid-cache.org/MergeProcedure>>
> >      >      >     <https://wiki.squid-cache.org/MergeProcedure
> >     <https://wiki.squid-cache.org/MergeProcedure>
> >      >     <https://wiki.squid-cache.org/MergeProcedure
> >     <https://wiki.squid-cache.org/MergeProcedure>>>
> >      >      >
> >      >      >
> >      >      >     Thank you,
> >      >      >
> >      >      >     Alex.
> >      >      >
> >      >      >
> >      >      >      > On Fri, May 20, 2022 at 9:31 PM Amos Jeffries
> >      >      >     <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>
> >     <mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>
> >      >     <mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>
> >     <mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>>
> >      >      >      > wrote:
> >      >      >      >
> >      >      >      >     On 20/05/22 19:44, Praveen Ponakanti wrote:
> >      >      >      >      > Hi Alex,
> >      >      >      >      >
> >      >      >      >      > Thanks for going through several steps to
> >     help mitigate
> >      >      >     src port
> >      >      >      >      > exhaustion. We are looking to achieve
> >     400-500% more
> >      >      >      >      > concurrent connections if we could :) as
> >     there is a
> >      >      >      >     significant buffer
> >      >      >      >      > on the available CPU.
> >      >      >      >
> >      >      >      >     Then you require at least 4, maybe 5, IP
> >     addresses to
> >      >     handle
> >      >      >     that many
> >      >      >      >     concurrent connections with Squid.
> >      >      >      >
> >      >      >      >
> >      >      >      > We would like to investigate going beyond the
> >     ephemeral port
> >      >      >     range for
> >      >      >      > some specific destination IP:PORT addresses. For
> >     that it
> >      >     appears
> >      >      >     squid
> >      >      >      > does not round-robin requests if we use multiple
> >      >      >     tcp_outgoing_addresses.
> >      >      >      > We could use ACL?s to pick a different outbound IP
> >     based
> >      >     on the
> >      >      >     clients
> >      >      >      > source IP, however that is not very ideal in our
> >      >     environment as our
> >      >      >      > clients aren?t always equally split by subnet.
> >     However, if
> >      >     we could
> >      >      >      > split by the client?s source port that might help
> >     achieve
> >      >     this. For
> >      >      >      > example something like:
> >      >      >      >
> >      >      >      >
> >      >      >      > acl pool1 clientport 0-32768
> >      >      >      >
> >      >      >      > acl pool2 clientport 32769-65536
> >      >      >      >
> >      >      >      >
> >      >      >      > tcp_outgoing_address 10.1.0.1 pool1
> >      >      >      >
> >      >      >      > tcp_outgoing_address 10.1.0.2 pool2
> >      >      >      >
> >      >      >      >
> >      >      >      > Squid's ACLs currently do not allow filtering by the
> >      >     client's source
> >      >      >      > port. We could look into a separate patch to add
> this
> >      >      >     functionality to
> >      >      >      > squid?s ACL code if that makes sense. Or is there a
> >     better
> >      >     way to
> >      >      >      > achieve this?
> >      >      >      >
> >      >      >      >
> >      >      >      > Thanks
> >      >      >      >
> >      >      >      > Praveen
> >      >      >      >
> >      >      >      >
> >      >      >      >      > The option to use multiple
> tcp_outoing_addresses
> >      >     appears to be
> >      >      >      >     promising
> >      >      >      >      > along with some tweaks to the TCP timeouts.
> >     I guess we
> >      >      >     could use
> >      >      >      >     ACLs to
> >      >      >      >      > pick a different outbound IP based on the
> >      >     requesting client's
> >      >      >      >     prefix. We
> >      >      >      >      > had not considered that option as the
> ephemeral
> >      >     ports were
> >      >      >     no longer
> >      >      >      >      > available to other applications when squid
> >     uses most of
> >      >      >     them with a
> >      >      >      >      > single outbound IP configured. We are also
> >     looking to
> >      >      >     modify the
> >      >      >      >     code to
> >      >      >      >      > use the IP_BIND_ADDRESS_NO_PORT sockopt as
> that
> >      >     could help
> >      >      >     delay
> >      >      >      >     port
> >      >      >      >      > assignment with the bind() call on the
> >     outbound TCP
> >      >      >     sessions (to
> >      >      >      >      > hopefully allow access to the 4-tuple on the
> >     socket).
> >      >      >      >
> >      >      >      >     Patches welcome.
> >      >      >      >
> >      >      >      >     However, please be aware that use of the
> 4-tuple is
> >      >     often no
> >      >      >     different
> >      >      >      >     from the 3-tuple since the dst-port is
> >     typically identical
> >      >      >     for all
> >      >      >      >     outgoing traffic to a given dst-IP.
> >      >      >      >
> >      >      >      >
> >      >      >      >     Cheers
> >      >      >      >     Amos
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221123/7d1bc55e/attachment.htm>

From robertkwild at gmail.com  Thu Nov 24 17:40:43 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 24 Nov 2022 17:40:43 +0000
Subject: [squid-users] ubuntu squid - proxy refusing
Message-ID: <CAGU_CiJMsvC9rL11q7smibeZ=t+aqqR+Lw8WkoGE_KAB5KOqMg@mail.gmail.com>

hi all,

so i have installed squid on ubuntu 22.04 and i havnt made any changes, all
i have done is

apt install squid
systemctl start squid

its obviously not like centos 7 where out the box it just works ie
doesnt block anything

on certain websites i get the squid access is denied

but most of the time i get

The proxy server is refusing connections

why is this please?

thanks,
rob

-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221124/127cc4db/attachment.htm>

From robertkwild at gmail.com  Thu Nov 24 17:48:42 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 24 Nov 2022 17:48:42 +0000
Subject: [squid-users] ubuntu squid - proxy refusing
In-Reply-To: <CAGU_CiJMsvC9rL11q7smibeZ=t+aqqR+Lw8WkoGE_KAB5KOqMg@mail.gmail.com>
References: <CAGU_CiJMsvC9rL11q7smibeZ=t+aqqR+Lw8WkoGE_KAB5KOqMg@mail.gmail.com>
Message-ID: <CAGU_Ci+eLxp-PkJ4dQ1huGVjNtH=o-yj+Ha0E7MbJLjzfowFZw@mail.gmail.com>

LOL ok sorted

i uncommented out

http_access allow localnet

and reloaded the service and job done

On Thu, 24 Nov 2022 at 17:40, robert k Wild <robertkwild at gmail.com> wrote:

> hi all,
>
> so i have installed squid on ubuntu 22.04 and i havnt made any changes,
> all i have done is
>
> apt install squid
> systemctl start squid
>
> its obviously not like centos 7 where out the box it just works ie
> doesnt block anything
>
> on certain websites i get the squid access is denied
>
> but most of the time i get
>
> The proxy server is refusing connections
>
> why is this please?
>
> thanks,
> rob
>
> --
> Regards,
>
> Robert K Wild.
>


-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221124/7572b13d/attachment.htm>

From robertkwild at gmail.com  Thu Nov 24 18:22:36 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 24 Nov 2022 18:22:36 +0000
Subject: [squid-users] ubuntu ecap clamAV adapter
Message-ID: <CAGU_CiK02Ce6dX8WwC79ChpYmBpVhQT9AAcgGpWf-X+AfO2vUA@mail.gmail.com>

hi all,

so im trying to install squid, ecap with the clamAV adapter

i noticed when i install squid it comes already with libecap, so all i need
to do is install the clamAV adapter

so do i just need to do this

wget https://www.e-cap.org/archive/ecap_clamav_adapter-2.0.0.tar.gz

but when i do

./configure

i get this error

configure: error: in `/root/ecap_clamav_adapter-2.0.0':
configure: error: The pkg-config script could not be found or is too old.
Make sure it
is in your PATH or set the PKG_CONFIG environment variable to the full
path to pkg-config.

Alternatively, you may set the environment variables LIBECAP_CFLAGS
and LIBECAP_LIBS to avoid the need to call pkg-config.
See the pkg-config man page for more details.

To get pkg-config, see <http://pkg-config.freedesktop.org/>.
See `config.log' for more details

ive looked at there website but its for the sample adapter

any help would be great

thanks,
rob

-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221124/e1b24be3/attachment.htm>

From rafael.akchurin at diladele.com  Thu Nov 24 18:35:31 2022
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 24 Nov 2022 18:35:31 +0000
Subject: [squid-users] ubuntu ecap clamAV adapter
In-Reply-To: <CAGU_CiK02Ce6dX8WwC79ChpYmBpVhQT9AAcgGpWf-X+AfO2vUA@mail.gmail.com>
References: <CAGU_CiK02Ce6dX8WwC79ChpYmBpVhQT9AAcgGpWf-X+AfO2vUA@mail.gmail.com>
Message-ID: <AM8PR04MB7745999FACE1DEC66569F25B8F0F9@AM8PR04MB7745.eurprd04.prod.outlook.com>

Hello Robert,

May be this will be of any help ? this is how we compile the eCAP for Squid - https://github.com/diladele/websafety/blob/master/core.ubuntu20/03_clamav.sh
If you need to compile the Squid too ? also look at https://github.com/diladele/squid-ubuntu

Best regards,
Rafael

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of robert k Wild
Sent: Thursday, November 24, 2022 7:23 PM
To: Squid Users <squid-users at lists.squid-cache.org>
Subject: [squid-users] ubuntu ecap clamAV adapter

hi all,

so im trying to install squid, ecap with the clamAV adapter

i noticed when i install squid it comes already with libecap, so all i need to do is install the clamAV adapter

so do i just need to do this

wget https://www.e-cap.org/archive/ecap_clamav_adapter-2.0.0.tar.gz

but when i do

./configure

i get this error

configure: error: in `/root/ecap_clamav_adapter-2.0.0':
configure: error: The pkg-config script could not be found or is too old.  Make sure it
is in your PATH or set the PKG_CONFIG environment variable to the full
path to pkg-config.

Alternatively, you may set the environment variables LIBECAP_CFLAGS
and LIBECAP_LIBS to avoid the need to call pkg-config.
See the pkg-config man page for more details.

To get pkg-config, see <http://pkg-config.freedesktop.org/>.
See `config.log' for more details

ive looked at there website but its for the sample adapter

any help would be great

thanks,
rob

--
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221124/97ba90cb/attachment.htm>

From robertkwild at gmail.com  Thu Nov 24 20:26:11 2022
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 24 Nov 2022 20:26:11 +0000
Subject: [squid-users] ubuntu ecap clamAV adapter
In-Reply-To: <AM8PR04MB7745999FACE1DEC66569F25B8F0F9@AM8PR04MB7745.eurprd04.prod.outlook.com>
References: <CAGU_CiK02Ce6dX8WwC79ChpYmBpVhQT9AAcgGpWf-X+AfO2vUA@mail.gmail.com>
 <AM8PR04MB7745999FACE1DEC66569F25B8F0F9@AM8PR04MB7745.eurprd04.prod.outlook.com>
Message-ID: <CAGU_CiJ2de9edgsqf5ehV1kG9fSGm6im9jKj2jmyUNHUxdm_9A@mail.gmail.com>

Thanks Rafael,

Do you think I should compile all packages from source IE squid, ecap and
ecap clamAV module or just download the first 2 via apt and just compile
the last one

Also I imagine I need to also install from apt clamAV

Thanks, rob

On Thu, 24 Nov 2022, 18:35 Rafael Akchurin, <rafael.akchurin at diladele.com>
wrote:

> Hello Robert,
>
>
>
> May be this will be of any help ? this is how we compile the eCAP for
> Squid -
> https://github.com/diladele/websafety/blob/master/core.ubuntu20/03_clamav.sh
>
> If you need to compile the Squid too ? also look at
> https://github.com/diladele/squid-ubuntu
>
>
>
> Best regards,
>
> Rafael
>
>
>
> *From:* squid-users <squid-users-bounces at lists.squid-cache.org> *On
> Behalf Of *robert k Wild
> *Sent:* Thursday, November 24, 2022 7:23 PM
> *To:* Squid Users <squid-users at lists.squid-cache.org>
> *Subject:* [squid-users] ubuntu ecap clamAV adapter
>
>
>
> hi all,
>
>
>
> so im trying to install squid, ecap with the clamAV adapter
>
>
>
> i noticed when i install squid it comes already with libecap, so all i
> need to do is install the clamAV adapter
>
>
>
> so do i just need to do this
>
>
>
> wget https://www.e-cap.org/archive/ecap_clamav_adapter-2.0.0.tar.gz
>
>
>
> but when i do
>
>
>
> ./configure
>
>
>
> i get this error
>
>
>
> configure: error: in `/root/ecap_clamav_adapter-2.0.0':
> configure: error: The pkg-config script could not be found or is too old.
> Make sure it
> is in your PATH or set the PKG_CONFIG environment variable to the full
> path to pkg-config.
>
> Alternatively, you may set the environment variables LIBECAP_CFLAGS
> and LIBECAP_LIBS to avoid the need to call pkg-config.
> See the pkg-config man page for more details.
>
> To get pkg-config, see <http://pkg-config.freedesktop.org/>.
> See `config.log' for more details
>
>
>
> ive looked at there website but its for the sample adapter
>
>
>
> any help would be great
>
>
>
> thanks,
>
> rob
>
>
>
> --
>
> Regards,
>
> Robert K Wild.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221124/ad14a917/attachment.htm>

From jointdogg at gmail.com  Sat Nov 26 10:49:34 2022
From: jointdogg at gmail.com (N)
Date: Sat, 26 Nov 2022 12:49:34 +0200
Subject: [squid-users] tcp_outgoing_address directive ignored,
 data goes out on default gateway
Message-ID: <CAOB-uc=0+a_SVn+-fNKe=N-3yt-_z1-jrnESJJ6dkhfSC3qWzA@mail.gmail.com>

Hi,
I'm trying to use tcp_outgoing_address to forward traffic from specific
users to a specific interface.

running squid 5.7 (on openwrt).
have a few interfaces on my machine, two of which are VPN interfaces with
IPs (internal) 10.200.0.70  and 10.102.237.50.
trying to forward user "uk" to the interface with IP 10.200.0.70 is
"ignored" - I can see that the default WAN interface is used. I see it by
using a simple "what is my ip" test when using the proxy, and checking the
traffic of the interfaces when sending requests.

the relevant excerpt from the squid conf:
acl auth_users proxy_auth REQUIRED
acl wg_uk proxy_auth uk
tcp_outgoing_address 10.200.0.70 wg_uk

I can see that the IP and config are not wrong because the requests don't
get 503 errors (if I change the IP to a non existing one, e.g. 10.200.0.71
I do get 503 errors).

small excerpt from the squid_cache.log (proxy server is 192.168.1.1, proxy
client is 192.168.1.149)
2022/11/26 11:28:48.286| 17,3| FwdState.cc(394) Start: '
http://detectportal.firefox.com/canonical.html'
2022/11/26 11:28:48.286| 17,2| FwdState.cc(157) FwdState: Forwarding client
request conn157 local=192.168.1.1:3128 remote=192.168.1.149:64723 FD 13
flags=1, url=http://detectportal.firefox.com/canonical.html
2022/11/26 11:28:48.287| 44,2| peer_select.cc(460) resolveSelected: Find IP
destination for: http://detectportal.firefox.com/canonical.html' via
detectportal.firefox.com
2022/11/26 11:28:48.287| 14,4| ipcache.cc(607) nbgethostbyname:
detectportal.firefox.com
2022/11/26 11:28:48.287| 14,3| Address.cc(389) lookupHostIP: Given Non-IP '
detectportal.firefox.com': Name does not resolve
2022/11/26 11:28:48.287| 14,4| ipcache.cc(647) ipcache_nbgethostbyname_:
ipcache_nbgethostbyname: HIT for 'detectportal.firefox.com'
2022/11/26 11:28:48.287| 14,7| ipcache.cc(250) forwardIp: 34.107.221.82
2022/11/26 11:28:48.287| 28,3| Checklist.cc(70) preCheck: 0x7ffd71e3d440
checking fast ACLs
2022/11/26 11:28:48.287| 28,5| Acl.cc(124) matches: checking
tcp_outgoing_address 10.200.0.70
2022/11/26 11:28:48.287| 28,5| Acl.cc(124) matches: checking
(tcp_outgoing_address 10.200.0.70 line)
2022/11/26 11:28:48.287| 28,5| Acl.cc(124) matches: checking wg_uk
2022/11/26 11:28:48.287| 29,5| UserRequest.cc(75) valid: Validated.
Auth::UserRequest '0x1bad2e0'.
2022/11/26 11:28:48.287| 28,4| Acl.cc(346) cacheMatchAcl:
ACL::cacheMatchAcl: cache hit on acl 'wg_uk' (0x1551ca0)
2022/11/26 11:28:48.287| 28,3| Acl.cc(151) matches: checked: wg_uk = 1
2022/11/26 11:28:48.287| 28,3| Acl.cc(151) matches: checked:
(tcp_outgoing_address 10.200.0.70 line) = 1
2022/11/26 11:28:48.287| 28,3| Acl.cc(151) matches: checked:
tcp_outgoing_address 10.200.0.70 = 1
2022/11/26 11:28:48.287| 28,3| Checklist.cc(63) markFinished:
0x7ffd71e3d440 answer ALLOWED for match
2022/11/26 11:28:48.287| 28,4| FilledChecklist.cc(67) ~ACLFilledChecklist:
ACLFilledChecklist destroyed 0x7ffd71e3d440
2022/11/26 11:28:48.287| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0x7ffd71e3d440
2022/11/26 11:28:48.287| 24,7| SBuf.cc(209) append: from c-string to id
SBuf10501
2022/11/26 11:28:48.287| 24,7| SBuf.cc(160) rawSpace: reserving 46 for
SBuf10501
2022/11/26 11:28:48.287| 24,7| SBuf.cc(866) reAlloc: SBuf10501 new store
capacity: 128
2022/11/26 11:28:48.287| 44,2| peer_select.cc(1171) handlePath:
PeerSelector27 found conn167 local=10.200.0.70 remote=34.107.221.82:80
HIER_DIRECT flags=1, destination #1 for
http://detectportal.firefox.com/canonical.html
2022/11/26 11:28:48.288| 44,2| peer_select.cc(1177) handlePath:
always_direct = DENIED
2022/11/26 11:28:48.288| 44,2| peer_select.cc(1178) handlePath:
 never_direct = DENIED
2022/11/26 11:28:48.288| 44,2| peer_select.cc(1179) handlePath:
 timedout = 0
2022/11/26 11:28:48.288| 44,7| peer_select.cc(1149) interestedInitiator:
PeerSelector27
2022/11/26 11:28:48.288| 17,3| FwdState.cc(631) noteDestination: conn167
local=10.200.0.70 remote=34.107.221.82:80 HIER_DIRECT flags=1
2022/11/26 11:28:48.288| 17,3| FwdState.cc(1135) connectStart: 1+ paths to
http://detectportal.firefox.com/canonical.html
2022/11/26 11:28:48.288| 11,7| HttpRequest.cc(468) clearError: old: ERR_NONE
2022/11/26 11:28:48.288| 17,5| AsyncCall.cc(30) AsyncCall: The AsyncCall
FwdState::noteConnection constructed, this=0x1b97100 [call1887]
2022/11/26 11:28:48.288| 93,5| AsyncJob.cc(34) AsyncJob: AsyncJob
constructed, this=0x1b86e18 type=HappyConnOpener [job99]
2022/11/26 11:28:48.288| 93,5| AsyncCall.cc(30) AsyncCall: The AsyncCall
AsyncJob::start constructed, this=0x1b09300 [call1888]
2022/11/26 11:28:48.288| 93,5| AsyncCall.cc(97) ScheduleCall:
AsyncJob.cc(26) will call AsyncJob::start() [call1888]
2022/11/26 11:28:48.288| 14,7| ipcache.cc(250) forwardIp:
[2600:1901:0:38d7::]
2022/11/26 11:28:48.288| 44,7| peer_select.cc(1149) interestedInitiator:
PeerSelector27
2022/11/26 11:28:48.288| 24,6| SBuf.cc(99) assign: SBuf10502 from c-string,
n=4294967295)
2022/11/26 11:28:48.288| 28,4| FilledChecklist.cc(67) ~ACLFilledChecklist:
ACLFilledChecklist destroyed 0x7ffd71e3d440
2022/11/26 11:28:48.288| 28,4| Checklist.cc(197) ~ACLChecklist:
ACLChecklist::~ACLChecklist: destroyed 0x7ffd71e3d440
2022/11/26 11:28:48.288| 24,7| SBuf.cc(209) append: from c-string to id
SBuf10503
2022/11/26 11:28:48.288| 24,7| SBuf.cc(160) rawSpace: reserving 46 for
SBuf10503
2022/11/26 11:28:48.288| 24,7| SBuf.cc(866) reAlloc: SBuf10503 new store
capacity: 128
2022/11/26 11:28:48.288| 44,2| peer_select.cc(1171) handlePath:
PeerSelector27 found conn168 local=[::] remote=[2600:1901:0:38d7::]:80
HIER_DIRECT flags=1, destination #2 for
http://detectportal.firefox.com/canonical.html
2022/11/26 11:28:48.288| 44,2| peer_select.cc(1177) handlePath:
always_direct = DENIED
2022/11/26 11:28:48.288| 44,2| peer_select.cc(1178) handlePath:
 never_direct = DENIED
2022/11/26 11:28:48.288| 44,2| peer_select.cc(1179) handlePath:
 timedout = 0
2022/11/26 11:28:48.288| 44,7| peer_select.cc(1149) interestedInitiator:
PeerSelector27
2022/11/26 11:28:48.288| 17,3| FwdState.cc(631) noteDestination: conn168
local=[::] remote=[2600:1901:0:38d7::]:80 HIER_DIRECT flags=1
2022/11/26 11:28:48.288| 17,7| FwdState.cc(690) notifyConnOpener: reusing
pending notification about 2+ paths
2022/11/26 11:28:48.288| 14,7| ipcache.cc(231) finalCallback: 0x1af12b8
2022/11/26 11:28:48.288| 44,7| peer_select.cc(1149) interestedInitiator:
PeerSelector27
2022/11/26 11:28:48.288| 44,7| peer_select.cc(1149) interestedInitiator:
PeerSelector27
2022/11/26 11:28:48.288| 24,7| SBuf.cc(209) append: from c-string to id
SBuf10504
2022/11/26 11:28:48.288| 24,7| SBuf.cc(160) rawSpace: reserving 46 for
SBuf10504
2022/11/26 11:28:48.288| 24,7| SBuf.cc(866) reAlloc: SBuf10504 new store
capacity: 128
2022/11/26 11:28:48.288| 44,2| peer_select.cc(479) resolveSelected:
PeerSelector27 found all 2 destinations for
http://detectportal.firefox.com/canonical.html
2022/11/26 11:28:48.288| 44,2| peer_select.cc(480) resolveSelected:
always_direct = DENIED
2022/11/26 11:28:48.288| 44,2| peer_select.cc(481) resolveSelected:
 never_direct = DENIED
2022/11/26 11:28:48.288| 44,2| peer_select.cc(482) resolveSelected:
 timedout = 0

can anyone help me understand what I'm missing?
thanks!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221126/35d8b5fe/attachment.htm>

From lpereira at blockbit.com  Sat Nov 26 16:37:08 2022
From: lpereira at blockbit.com (Lucas Vicente Pereira)
Date: Sat, 26 Nov 2022 16:37:08 +0000
Subject: [squid-users] Network appliance Sizing for Squid transparent proxy
Message-ID: <RO2P215MB1866C0FFF45756090A14D2A3B7119@RO2P215MB1866.LAMP215.PROD.OUTLOOK.COM>

Dear,


I have a project and would like to use Squid for WebProxy with Full SSL inspection, external acl to control urls access.

Environment information:

~2500 users
3 x Internet links 1 Gbps each
Average HTTP requests per minute since start: 65956.1
ClamAv integration
Snort Integration
Iptables REDIRECT for squid

Please, can you please help me with appliance sizing for this environment?



Sincerely,

Lucas Pereira
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221126/a7d74f08/attachment.htm>

From squid3 at treenet.co.nz  Sun Nov 27 13:55:45 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 28 Nov 2022 02:55:45 +1300
Subject: [squid-users] tcp_outgoing_address directive ignored,
 data goes out on default gateway
In-Reply-To: <CAOB-uc=0+a_SVn+-fNKe=N-3yt-_z1-jrnESJJ6dkhfSC3qWzA@mail.gmail.com>
References: <CAOB-uc=0+a_SVn+-fNKe=N-3yt-_z1-jrnESJJ6dkhfSC3qWzA@mail.gmail.com>
Message-ID: <499c9974-1089-37b0-fcc0-b1376b1ffb8a@treenet.co.nz>

On 26/11/2022 11:49 pm, N wrote:
> Hi,
> I'm trying to use tcp_outgoing_address to forward traffic from 
> specific users to a specific interface.
>
> running squid 5.7 (on openwrt).
> have a few interfaces on my machine, two of which are VPN interfaces 
> with IPs (internal) 10.200.0.70 ?and10.102.237.50.
> trying to forward user "uk" to the interface with IP 10.200.0.70 is 
> "ignored" - I can see that the default WAN interface is used. I see it 
> by using a simple "what is my ip" test when using the proxy, and 
> checking the traffic of the interfaces when sending requests.
>
> the relevant excerpt from the squid conf:
> acl auth_users proxy_auth REQUIRED

First possibility:

 ?Authentication is a VERY slow process. It is definitely not reliable 
to trigger during a 'fast' type ACL check like tcp_outgoing_* directives.

To fix this you need to ensure authentication is performed in 
http_access or similar early 'slow' access control directive. eg.

 ?? http_access deny !auth_users


Squid can then access the username with a 'note' type ACL check like so:

 ? acl wg_uk note user uk


> acl wg_uk proxy_auth uk
> tcp_outgoing_address 10.200.0.70 wg_uk
>
> I can see that the IP and config are not wrong because the requests 
> don't get 503 errors (if I change the IP to a non existing one, e.g. 
> 10.200.0.71 I do get 503 errors).
>

The log snippet looks like Squid is correctly obeying your configuration:

> small excerpt from the squid_cache.log (proxy server is 192.168.1.1, 
> proxy client is?192.168.1.149)
> 2022/11/26 11:28:48.286| 17,3| FwdState.cc(394) Start: 
> 'http://detectportal.firefox.com/canonical.html'
> 2022/11/26 11:28:48.286| 17,2| FwdState.cc(157) FwdState: Forwarding 
> client request conn157 local=192.168.1.1:3128 
> <http://192.168.1.1:3128> remote=192.168.1.149:64723 
> <http://192.168.1.149:64723> FD 13 flags=1, 
> url=http://detectportal.firefox.com/canonical.html

To be clear, the above are about the client<->Squid connection which 
triggered this outbound request.

...
> 2022/11/26 11:28:48.287| 14,4| ipcache.cc(647) 
> ipcache_nbgethostbyname_: ipcache_nbgethostbyname: HIT for 
> 'detectportal.firefox.com <http://detectportal.firefox.com>'
> 2022/11/26 11:28:48.287| 14,7| ipcache.cc(250) forwardIp: 34.107.221.82
> 2022/11/26 11:28:48.287| 28,5| Acl.cc(124) matches: checking wg_uk
> 2022/11/26 11:28:48.287| 28,3| Acl.cc(151) matches: checked: 
> tcp_outgoing_address 10.200.0.70 = 1
> 2022/11/26 11:28:48.287| 28,3| Checklist.cc(63) markFinished: 
> 0x7ffd71e3d440 answer ALLOWED for match
> 2022/11/26 11:28:48.287| 44,2| peer_select.cc(1171) handlePath: 
> PeerSelector27 found conn167 local=10.200.0.70 remote=34.107.221.82:80 
> <http://34.107.221.82:80> HIER_DIRECT flags=1, destination #1 for 
> http://detectportal.firefox.com/canonical.html

As you can see Squid MAY select to use a connection where the local= IP 
is your configured tcp_outgoing_address ...

...
> 2022/11/26 11:28:48.288| 14,7| ipcache.cc(250) forwardIp: 
> [2600:1901:0:38d7::]
> 2022/11/26 11:28:48.288| 44,7| peer_select.cc(1149) 
> interestedInitiator: PeerSelector27
> 2022/11/26 11:28:48.288| 44,2| peer_select.cc(1171) handlePath: 
> PeerSelector27 found conn168 local=[::] remote=[2600:1901:0:38d7::]:80 
> HIER_DIRECT flags=1, destination #2 for 
> http://detectportal.firefox.com/canonical.html

... or it also MAY select IPv6 which you did not configure any 
particular address for.
In accordance with with BCP 177 specifications Squid prefers IPv6 when 
possible setting up new connections.
This can also be impacted by "happy eyeballs" timing and whether there 
is an existing open connection on either of those two routes to the server.

So it is most likely that the IPv6 was chosen when you see the "not 
working" behaviour with 10.200.0.70 address, and the IPv4 is chosen when 
you saw the 503 errors in the 10.200.0.71 tests.


Try adding tcp_outgoing_address for IPv6 first and see if the problems 
disappear completely.

The log shown stops before showing which of the two connections were 
actually used, so there may be additional problems later. If they remain 
we will need more log info to tell what is going on. Including the debug 
11,2 trace of a non-working transaction would help.


Cheers
Amos



From squid3 at treenet.co.nz  Sun Nov 27 15:28:03 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 28 Nov 2022 04:28:03 +1300
Subject: [squid-users] Network appliance Sizing for Squid transparent
 proxy
In-Reply-To: <RO2P215MB1866C0FFF45756090A14D2A3B7119@RO2P215MB1866.LAMP215.PROD.OUTLOOK.COM>
References: <RO2P215MB1866C0FFF45756090A14D2A3B7119@RO2P215MB1866.LAMP215.PROD.OUTLOOK.COM>
Message-ID: <c59c8163-e1cc-12d2-1299-1388dc576d29@treenet.co.nz>

On 27/11/2022 5:37 am, Lucas Vicente Pereira wrote:
> Dear,
>
>
> I have a project and would like to use Squid for WebProxy with Full 
> SSL inspection, external acl to control urls access.
>

Firstly, be aware that TLS when used properly *cannot* be decrypted 
transparently.
So do not expect 100% inspection rates. Even though typical web HTTPS 
can still be inspected, service security levels vary a lot.


> Environment information:
>
> ~2500 users
> 3 x Internet links 1 Gbps each
> Average HTTP requests per minute since start: 65956.1
> ClamAv integration
> Snort Integration
> Iptables REDIRECT for squid
>
> Please, can you please help me with appliance sizing for this environment?
>

Disclaimer:? I do not have any numbers for Squid when ClamAv is added. 
Someone else here may be able to supply or correct my below numbers from 
their actual experience when that tool is used.

AFAIK Snort and iptables are so much more efficient than Squid that they 
are essentially not relevant.


Your 1.1k RPS is well within Squid's capabilities for HTTP (15k-20k RPS 
limit), but the "SSL inspection" will add much overhead so YMMV.

Squid places heavy loads on CPU and I/O systems. The key things to look 
for when you are pushing performance boundaries are (in order of 
impact/gains IMO):

 ?* as much RAM as you can afford. Within reason, ~128GB is probably 
enough for most Squid.
 ? - I/O is a major point of performance loss. Network I/O is implicitly 
minimized by Squid defaults.
 ? - Now that RAM comes by the GB I typically recommend a memory cache 
over disk cache.

 ?* prefer CPU with higher GHz rating than more cores,
 ? - the GHz translates directly into faster transaction times + more 
clients, cores translates only to parallel capacity/clients.

 ?* real/physical cores better than hyper-threading,
 ?? - Squid workers are single-threaded and can push their CPU hard. In 
this case hyper-threading just slows the CPU down.

 ?* bare-metal better than container;? container better than VM.
 ? - under load Squid will just keep squeezing the machine until it has 
nothing left to give - then traffic speed takes a nosedive at the worst 
possible time to do so.

The rest is down to configuration and making the whole system as simple 
as possible at every level.


HTH
Amos



From holitafarolito at gmail.com  Mon Nov 28 04:33:11 2022
From: holitafarolito at gmail.com (Lola Lo)
Date: Sun, 27 Nov 2022 23:33:11 -0500
Subject: [squid-users] transparent mode squid on centos 9 with iptables
 (part 2)
In-Reply-To: <07c330f7-4de8-bc8f-3aab-a00c12baa157@treenet.co.nz>
References: <CAKM+x_L67p0YjP3BPwSU=cp8PrQcG-CVH7jzmT80AB=ym3u4Vw@mail.gmail.com>
 <CAKM+x_JRkR2vNgT_zqcQAd3qXTwQMXDa8mJeEY+R6FYXDiFB0g@mail.gmail.com>
 <CAKM+x_K5XA0oTvEsGkzwHuYbVVYXe+1UegWCW2b37_pATX7mDQ@mail.gmail.com>
 <CAKM+x_JwQt+4jwVsfzgdj-x-DoWC77TqYROS44+cux0asdAADw@mail.gmail.com>
 <07c330f7-4de8-bc8f-3aab-a00c12baa157@treenet.co.nz>
Message-ID: <CAKM+x_JGMXB9eVe66Z8+2wTBr6qpmOCa3a_b=Psn07pxELjjjw@mail.gmail.com>

Hi Amos.

Thank you for your advice. I applied the instructionts that you have sent
it to me in this link:
https://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect and the
https://wiki.squid-cache.org/ConfigExamples/Intercept/IptablesPolicyRoute,
the case of: "When Squid is Internal amongst clients" and the section:  Routing
Setup. Now I can see the squid is intercepting the traffic however, it is
not applying my policies:

http_access deny cliente_linux sitios2
http_access deny cliente_windows sitios1
http_access allow mi_red

"sitios2"=facebook
"sitios1"=youtube
 these policies work when I set up manually the proxy. Do you have any idea
of how to troubleshoot this?
Thank you for your help



On Wed, Nov 16, 2022 at 11:35 PM Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 17/11/2022 9:14 am, Lola Lo wrote:
> > Hi guys.
> >
> >
> > Could you please send a tutorial or any good guidance to implement
> > squid on transparent mode on centos 9 with iptables.
> >
>
> The configuration details for what you appear to be trying to configure
> are here:
>   <https://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect>
>
> My comments below relate to how your attempt differs and how to fix.
>
> > I have configured squid.conf with this parameters:
> >
> >
> >
> > ens192: 172.31.168.28, internet interface
> >
> > ens224: 192.168.1.10, LAN interface (private network)
> >
> >
> > # Mis ACLs #
> >
> > acl mi_red src 192.168.1.0/24 <http://192.168.1.0/24>
> >
> > acl cliente_linux src 192.168.1.20
> >
> > acl cliente_windows src 192.168.1.30
> >
> > acl sitios1 url_regex "/etc/squid/listas/sitios1"
> >
> > acl sitios2 url_regex "/etc/squid/listas/sitios2"
> >
> >
> > # Squid normally listens to port 3128
> >
> > http_port 3128
> >
> > http_port 8080 transparent
> >
> >
>
> Firstly, use "intercept" instead of "transparent" with modern Squid.
>
> Secondly, remember that only port 8080 is setup to receive intercepted
> traffic. Port 3128 still receives normal forward-proxy traffic.
>
> > I want the ?deny all? rule get applied to test the client using the proxy
> >
> >
>
> You have not shown any http_access lines from your config. There is a
> clear bug in your NAT which explains the behaviour so I will assume that
> the squid.conf policy does what you want.
>
>
> > My iptables is configured as follows:
> >
> >
> > #!/bin/bash
> >
> >
> > ## NAT server configuration ##
> >
> >
> > sysctl -w net.ipv4.ip_forward=1
> >
> > sysctl -p
> >
> > iptables -X
> >
> > iptables -F
> >
> > iptables -t nat -X
> >
> > iptables -t nat -F
> >
> > iptables -I INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
> >
> > iptables -I FORWARD-m state --state RELATED,ESTABLISHED -j ACCEPT
> >
> > iptables -t nat -I POSTROUTING -o ens192 -j MASQUERADE
> >
> >
> >
>
> Why is this a different script?
> Ideally the firewall rules should be as atomic as possible to avoid
> connections being setup with only part of the rules applied.
>
>
> >
> > #!/bin/bash
> >
> >
> > ## proxy server configuration ##
> >
> >
> > ### Accepting traffic for the ports: 3128 and 8080##
> >
> >
> > iptables -A INPUT -s 192.168.1.0/24 <http://192.168.1.0/24> -p tcp
> > --dport 3128 -j ACCEPT
> >
> > iptables -A INPUT -p tcp --dport 3128 -j DROP
> >
>
> Do not accept traffic directly to the port 8080. Also Squid does not
> make outbound connections from its listening ports.
> So these ...
>
> > iptables -A OUTPUT -d 192.168.1.0/24 <http://192.168.1.0/24> -p tcp
> > --sport 3128 -j ACCEPT
> >
> > iptables -A OUTPUT -p tcp --sport 3128 -j DROP
> >
> >
> > iptables -A INPUT -s 192.168.1.0/24 <http://192.168.1.0/24> -p tcp
> > --dport 8080 -j ACCEPT
> >
> > iptables -A INPUT -p tcp --dport 8080 -j DROP
> >
> > iptables -A OUTPUT -d 192.168.1.0/24 <http://192.168.1.0/24> -p tcp
> > --sport 8080 -j ACCEPT
> >
> > iptables -A OUTPUT -p tcp --sport 8080 -j DROP
> >
> >
>
> ... should be replaced with:
>
>    iptables -t mangle -A PREROUTING -p tcp --dport 8080 -j DROP
>
>
> >
> > `### Accepting traffic for the ports: 3128 and 8080##
> >
> >
> > iptables -t nat -A POSTROUTING -o ens192 -j MASQUERADE
> >
>
> You are missing a rule to allow Squid outbound traffic to avoid the NAT.
>
>    iptables -t nat -A PREROUTING -s 192.168.1.10 -p tcp --dport 80 -j
> ACCEPT
>
> > iptables -t nat -A PREROUTING -s 192.168.1.0/24
> > <http://192.168.1.0/24> -p tcp --dport 80 -j REDIRECT --to-port 8080
> >
> > iptables -t nat -A PREROUTING -s 192.168.1.0/24
> > <http://192.168.1.0/24> -p tcp --dport 443 -j REDIRECT --to-port 8080
> >
> >
>
> Port 8080 in your squid.conf can only handle port 80 traffic syntax.
>
> Port 443 is a more tricky situation. I recommend removing that until you
> have the port 80 working.
>
>
> >
> > But I got this error:
> >
> >
> > 1668381894.7460 192.168.1.20 NONE_NONE/000 0 -
> > error:transaction-end-before-headers - HIER_NONE/- -
> >
> > 1668381967.8000 192.168.1.20 NONE_NONE/400 3690 -
> > error:invalid-request - HIER_NONE/- text/html
> >
>
> This is likely from the missing NAT rule allowing Squid outbound.
>
> If the above changes do not fix everything make sure that you test
> exactly what the real clients will be doing. Specifically that they are
> making contact to servers on port 80 or directly to Squid port 3128.
> They know *nothing* about port 8080 existence so have no reason to send
> anything that way directly.
>
>
> HTH
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221127/6affe651/attachment.htm>

From alex.kimble at viewpointe.com  Mon Nov 28 13:37:16 2022
From: alex.kimble at viewpointe.com (Alex Kimble)
Date: Mon, 28 Nov 2022 13:37:16 +0000
Subject: [squid-users] daily usage email reports for hostnames/users/top
 URLs/blocked URLs
Message-ID: <DS7PR22MB3670FDF3685F6F2F0F92650A8B139@DS7PR22MB3670.namprd22.prod.outlook.com>

What is everyone using for generating and emailing daily reports in either .csv/.pdf/.html format for which machines/users? Looking for a simple report that shows top URLs & blocked URLs.

Thanks,

[A picture containing text  Description automatically generated]
Alex Kimble
Senior Security Analyst

317.869.6708 pc
317.617.0812 wc
alex.kimble at viewpointe.com<mailto:josh.samples at viewpointe.com>

227 West Trade Street, Suite 2000
Charlotte, NC 28202

www.viewpointe.com<http://www.viewpointe.com/>

[Title: LinkedIn - Description: image of LinkedIn icon]<https://www.linkedin.com/company/viewpointe/>[Title: Twitter - Description: image of Twitter icon]<https://twitter.com/viewpointellc>

Notice: This email message (including any attachments) may contain confidential, proprietary, privileged and/or private information. The information is intended solely for the use of the individual or entity to which it is addressed. If you are not the intended recipient of this message, please notify the sender immediately and delete the message and any attachments from your system. Any disclosure, reproduction, distribution or other use of this message or any attachments by an individual or entity other than the intended recipient is strictly prohibited.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221128/a47a7d31/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 10619 bytes
Desc: image001.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221128/a47a7d31/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.png
Type: image/png
Size: 1437 bytes
Desc: image002.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221128/a47a7d31/attachment-0001.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image003.png
Type: image/png
Size: 1413 bytes
Desc: image003.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221128/a47a7d31/attachment-0002.png>

From rafael.akchurin at diladele.com  Mon Nov 28 13:48:20 2022
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Mon, 28 Nov 2022 13:48:20 +0000
Subject: [squid-users] daily usage email reports for hostnames/users/top
 URLs/blocked URLs
In-Reply-To: <DS7PR22MB3670FDF3685F6F2F0F92650A8B139@DS7PR22MB3670.namprd22.prod.outlook.com>
References: <DS7PR22MB3670FDF3685F6F2F0F92650A8B139@DS7PR22MB3670.namprd22.prod.outlook.com>
Message-ID: <AM8PR04MB77457DB497A641D3F9E6529B8F139@AM8PR04MB7745.eurprd04.prod.outlook.com>

Hello Alex,

We use our own reporter like in https://docs.diladele.com/administrator_guide_stable/traffic_monitoring/reports.html
Disclosure ? it requires a license key ?.

Best regards,
Rafael

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Alex Kimble
Sent: Monday, November 28, 2022 2:37 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] daily usage email reports for hostnames/users/top URLs/blocked URLs

What is everyone using for generating and emailing daily reports in either .csv/.pdf/.html format for which machines/users? Looking for a simple report that shows top URLs & blocked URLs.

Thanks,

[A picture containing text  Description automatically generated]
Alex Kimble
Senior Security Analyst

317.869.6708 pc
317.617.0812 wc
alex.kimble at viewpointe.com<mailto:josh.samples at viewpointe.com>

227 West Trade Street, Suite 2000
Charlotte, NC 28202

www.viewpointe.com<http://www.viewpointe.com/>

[Title: LinkedIn - Description: image of LinkedIn icon]<https://www.linkedin.com/company/viewpointe/>[Title: Twitter - Description: image of Twitter icon]<https://twitter.com/viewpointellc>

Notice: This email message (including any attachments) may contain confidential, proprietary, privileged and/or private information. The information is intended solely for the use of the individual or entity to which it is addressed. If you are not the intended recipient of this message, please notify the sender immediately and delete the message and any attachments from your system. Any disclosure, reproduction, distribution or other use of this message or any attachments by an individual or entity other than the intended recipient is strictly prohibited.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221128/efe0cf75/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 23096 bytes
Desc: image001.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221128/efe0cf75/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.png
Type: image/png
Size: 3438 bytes
Desc: image002.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221128/efe0cf75/attachment-0001.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image003.png
Type: image/png
Size: 3302 bytes
Desc: image003.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221128/efe0cf75/attachment-0002.png>

From lpereira at blockbit.com  Mon Nov 28 17:03:05 2022
From: lpereira at blockbit.com (Lucas Vicente Pereira)
Date: Mon, 28 Nov 2022 17:03:05 +0000
Subject: [squid-users] Network appliance Sizing for Squid transparent
 proxy
Message-ID: <RO2P215MB1866D5C25D893DF238F54A61B7139@RO2P215MB1866.LAMP215.PROD.OUTLOOK.COM>

Thanks, Amos

Beet regards,

Lucas Pereira
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221128/8be56aae/attachment.htm>

From gvilarino6 at gmail.com  Tue Nov 29 12:16:38 2022
From: gvilarino6 at gmail.com (=?UTF-8?Q?Gabriel_Vilari=C3=B1o?=)
Date: Tue, 29 Nov 2022 13:16:38 +0100
Subject: [squid-users] Logs not showing ssl::servername
Message-ID: <CAGSQug=Ri2iZV+DVD45xCcVh2viP8d0ocs1u+yetZB3QPoXqKA@mail.gmail.com>

Hi there,

I am setting up an HTTP/HTTPS transparent proxy, meaning the clients not
need any certificates for using the proxy. This works fine on version 3.5
of Squid, however after upgrading to 5.7 the behavior of the logs change:

1669723133.174   8037 10.184.19.220 TCP_TUNNEL/500 6207 CONNECT
54.240.253.128:443 - ORIGINAL_DST/54.240.253.128 -

Directive: logformat squid %ts.%03tu %>a %Ss/%03>Hs %ssl::>sni
%ssl::bump_mode ssl::>cert_subject %<ru

On version 3.5 we were obtaining the domain name (an aws service) in the
place of ORIGINAL_DST. Also now we are not seeing any information about the
bump_mode in no one of the connections while before we were seeing it. One
could trough that it could be because of the /500 message, however on a 200
one to docs.ansble.com it also don?t show any data on the sni field:

1669723513.363    332 10.184.19.220 TCP_TUNNEL/200 38192 CONNECT
104.26.0.234:443 - ORIGINAL_DST/104.26.0.234 -

Also the 500 looks to come from the squid not understanding something on
the SSL negotiation:

2022/11/29 10:32:38.943 kid1| 83,4| support.cc(248) check_domain: Verifying
server domain arsenal.us-west-2.amazonaws.com to certificate
name/subjectAltName arsenal.us-west-2.amazonaws.com 2022/11/29 10:32:38.943
kid1| 83,5| bio.cc(136) read: FD 28 read 347 <= 65535 2022/11/29
10:32:38.943 kid1| 83,5| Io.cc(91) Handshake: -1/0 for TLS connection
0x558453168970 over conn99 local=SQUID-INTERNAL-IP:44264 remote=
54.240.251.223:443 ORIGINAL_DST FD 28 flags=1 2022/11/29 10:32:38.943 kid1|
83,2| PeerConnector.cc(256) handleNegotiationResult: ERROR: failure while
establishing TLS connection on FD: 280x558452b68980*1 2022/11/29
10:32:38.943 kid1| 83,5| NegotiationHistory.cc(85) retrieveNegotiatedInfo:
SSL connection info on FD 28 SSL version NONE/0.0 negotiated cipher 2022/11/29
10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(84)
checkForPeekAndSpliceMatched: Will check for peek and splice on FD 28
2022/11/29
10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(395)
serverCertificateVerified: HTTPS server CN: arsenal.us-west-2.amazonaws.com
bumped: conn99 local=SQUID-INTERNAL-IP:44264 remote=54.240.251.223:443
ORIGINAL_DST FD 28 flags=1
2022/11/29 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(273)
startTunneling: will tunnel instead of negotiating TLS

It is clear that in creates the tunnel so the 500 probably is that error?
Why the bump/sni messages never log anything (according to
https://wiki.squid-cache.org/Features/SslPeekAndSplice they should log
splice not -). This is the config for bumping:



acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
ssl_bump peek step1 all

.... http rules ...

acl allowed_https_sites ssl::server_name_regex "/etc/squid/whitelist.txt"
ssl_bump peek step2 allowed_https_sites
ssl_bump splice step3 allowed_https_sites
ssl_bump terminate step2 all




Ip tables simply redirect:

iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 3129
iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-port 3130
# https port on squid: https_port 3130 intercept ssl-bump
cert=/etc/squid/ssl/dummy.pem

Thanks in advance, i have been trying this for a week now reading a lot of
posts but not luck...
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221129/9a5d4372/attachment.htm>

From gvilarino6 at gmail.com  Tue Nov 29 13:06:14 2022
From: gvilarino6 at gmail.com (=?UTF-8?Q?Gabriel_Vilari=C3=B1o?=)
Date: Tue, 29 Nov 2022 14:06:14 +0100
Subject: [squid-users] Logs not showing ssl::servername
In-Reply-To: <CAGSQug=Ri2iZV+DVD45xCcVh2viP8d0ocs1u+yetZB3QPoXqKA@mail.gmail.com>
References: <CAGSQug=Ri2iZV+DVD45xCcVh2viP8d0ocs1u+yetZB3QPoXqKA@mail.gmail.com>
Message-ID: <CAGSQugn9D=XvcX7V8nNji5fFTe-ddKEVtRLdc_aTqqfnDaGgjw@mail.gmail.com>

Just got it solved. Was caused because of checking default access.log.
Using a new file solves all the problems.

However, in this context, what means TCP_TUNNEL/500? is it because the TLS
handshake? I would like to know if it is tunneling correctly or is having
some trouble (not easy to test right now).

Thanks!

El mar, 29 nov 2022 a las 13:16, Gabriel Vilari?o (<gvilarino6 at gmail.com>)
escribi?:

> Hi there,
>
> I am setting up an HTTP/HTTPS transparent proxy, meaning the clients not
> need any certificates for using the proxy. This works fine on version 3.5
> of Squid, however after upgrading to 5.7 the behavior of the logs change:
>
> 1669723133.174   8037 10.184.19.220 TCP_TUNNEL/500 6207 CONNECT
> 54.240.253.128:443 - ORIGINAL_DST/54.240.253.128 -
>
> Directive: logformat squid %ts.%03tu %>a %Ss/%03>Hs %ssl::>sni
> %ssl::bump_mode ssl::>cert_subject %<ru
>
> On version 3.5 we were obtaining the domain name (an aws service) in the
> place of ORIGINAL_DST. Also now we are not seeing any information about the
> bump_mode in no one of the connections while before we were seeing it. One
> could trough that it could be because of the /500 message, however on a 200
> one to docs.ansble.com it also don?t show any data on the sni field:
>
> 1669723513.363    332 10.184.19.220 TCP_TUNNEL/200 38192 CONNECT
> 104.26.0.234:443 - ORIGINAL_DST/104.26.0.234 -
>
> Also the 500 looks to come from the squid not understanding something on
> the SSL negotiation:
>
> 2022/11/29 10:32:38.943 kid1| 83,4| support.cc(248) check_domain:
> Verifying server domain arsenal.us-west-2.amazonaws.com to certificate
> name/subjectAltName arsenal.us-west-2.amazonaws.com 2022/11/29
> 10:32:38.943 kid1| 83,5| bio.cc(136) read: FD 28 read 347 <= 65535 2022/11/29
> 10:32:38.943 kid1| 83,5| Io.cc(91) Handshake: -1/0 for TLS connection
> 0x558453168970 over conn99 local=SQUID-INTERNAL-IP:44264 remote=
> 54.240.251.223:443 ORIGINAL_DST FD 28 flags=1 2022/11/29 10:32:38.943
> kid1| 83,2| PeerConnector.cc(256) handleNegotiationResult: ERROR: failure
> while establishing TLS connection on FD: 280x558452b68980*1 2022/11/29
> 10:32:38.943 kid1| 83,5| NegotiationHistory.cc(85) retrieveNegotiatedInfo:
> SSL connection info on FD 28 SSL version NONE/0.0 negotiated cipher 2022/11/29
> 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(84)
> checkForPeekAndSpliceMatched: Will check for peek and splice on FD 28 2022/11/29
> 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(395)
> serverCertificateVerified: HTTPS server CN:
> arsenal.us-west-2.amazonaws.com bumped: conn99
> local=SQUID-INTERNAL-IP:44264 remote=54.240.251.223:443 ORIGINAL_DST FD
> 28 flags=1
> 2022/11/29 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(273)
> startTunneling: will tunnel instead of negotiating TLS
>
> It is clear that in creates the tunnel so the 500 probably is that error?
> Why the bump/sni messages never log anything (according to
> https://wiki.squid-cache.org/Features/SslPeekAndSplice they should log
> splice not -). This is the config for bumping:
>
>
>
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> ssl_bump peek step1 all
>
> .... http rules ...
>
> acl allowed_https_sites ssl::server_name_regex "/etc/squid/whitelist.txt"
> ssl_bump peek step2 allowed_https_sites
> ssl_bump splice step3 allowed_https_sites
> ssl_bump terminate step2 all
>
>
>
>
> Ip tables simply redirect:
>
> iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 3129
> iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-port
> 3130 # https port on squid: https_port 3130 intercept ssl-bump
> cert=/etc/squid/ssl/dummy.pem
>
> Thanks in advance, i have been trying this for a week now reading a lot of
> posts but not luck...
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221129/9379d222/attachment.htm>

From rousskov at measurement-factory.com  Tue Nov 29 14:18:15 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 29 Nov 2022 09:18:15 -0500
Subject: [squid-users] Logs not showing ssl::servername
In-Reply-To: <CAGSQugn9D=XvcX7V8nNji5fFTe-ddKEVtRLdc_aTqqfnDaGgjw@mail.gmail.com>
References: <CAGSQug=Ri2iZV+DVD45xCcVh2viP8d0ocs1u+yetZB3QPoXqKA@mail.gmail.com>
 <CAGSQugn9D=XvcX7V8nNji5fFTe-ddKEVtRLdc_aTqqfnDaGgjw@mail.gmail.com>
Message-ID: <5afe9c32-c979-4b64-5193-b96d975fd05f@measurement-factory.com>

On 11/29/22 08:06, Gabriel Vilari?o wrote:

> However, in this context, what means TCP_TUNNEL/500? is it because the 
> TLS handshake? I would like to know if it is tunneling correctly or is 
> having some trouble (not easy to test right now).

Squid bugs notwithstanding, TCP_TUNNEL/500 means that Squid refused to 
tunnel the corresponding TCP connection and responded with an HTTP 500 
error to the corresponding HTTP CONNECT request. That client request is 
faked in your TLS interception case, so the response is also a fake -- 
Squid does not really send it to the client.

In most SslBump cases, if Squid cannot successfully peek-and-splice, 
then it will try to bump the client connection and, if the client then 
sends a GET request on the bumped client-Squid connection, Squid will 
respond with a real HTTP 500 error.

AFAICT, the logs you have shared do not detail the TLS error that 
triggers that TCP_TUNNEL/500 outcome.


HTH,

Alex.


> 
> Thanks!
> 
> El mar, 29 nov 2022 a las 13:16, Gabriel Vilari?o (<gvilarino6 at gmail.com 
> <mailto:gvilarino6 at gmail.com>>) escribi?:
> 
>     Hi there,
> 
>     I am setting up an HTTP/HTTPS transparent proxy, meaning the clients
>     not need any certificates for using the proxy. This works fine on
>     version 3.5 of Squid, however after upgrading to 5.7 the behavior of
>     the logs change:
> 
>     1669723133.174 ? 8037 10.184.19.220 TCP_TUNNEL/500 6207 CONNECT
>     54.240.253.128:443 <http://54.240.253.128:443> -
>     ORIGINAL_DST/54.240.253.128 <http://54.240.253.128> -
> 
>     Directive: logformat squid %ts.%03tu %>a %Ss/%03>Hs %ssl::>sni
>     %ssl::bump_mode ssl::>cert_subject %<ru
> 
>     On version 3.5 we were obtaining the domain name (an aws service) in
>     the place of ORIGINAL_DST. Also now we are not seeing any
>     information about the bump_mode in no one of the connections while
>     before we were seeing it. One could trough that it could be because
>     of the /500 message, however on a 200 one to docs.ansble.com
>     <http://docs.ansble.com> it also don?t show any data on the sni field:
> 
>     1669723513.363 ? ?332 10.184.19.220 TCP_TUNNEL/200 38192 CONNECT
>     104.26.0.234:443 <http://104.26.0.234:443> -
>     ORIGINAL_DST/104.26.0.234 <http://104.26.0.234> -
> 
>     Also the 500 looks to come from the squid not understanding
>     something on the SSL negotiation:
> 
>     |2022/11/29 10:32:38.943 kid1| 83,4| support.cc(248) check_domain:
>     Verifying server domain arsenal.us-west-2.amazonaws.com
>     <http://arsenal.us-west-2.amazonaws.com> to certificate
>     name/subjectAltName arsenal.us-west-2.amazonaws.com
>     <http://arsenal.us-west-2.amazonaws.com> ||2022/11/29 10:32:38.943
>     kid1| 83,5| bio.cc(136) read: FD 28 read 347 <= 65535 ||2022/11/29
>     10:32:38.943 kid1| 83,5| Io.cc(91) Handshake: -1/0 for TLS
>     connection 0x558453168970 over conn99 local=SQUID-INTERNAL-IP:44264
>     remote=54.240.251.223:443 <http://54.240.251.223:443> ORIGINAL_DST
>     FD 28 flags=1 ||2022/11/29 10:32:38.943 kid1| 83,2|
>     PeerConnector.cc(256) handleNegotiationResult: ERROR: failure while
>     establishing TLS connection on FD: 280x558452b68980*1 ||2022/11/29
>     10:32:38.943 kid1| 83,5| NegotiationHistory.cc(85)
>     retrieveNegotiatedInfo: SSL connection info on FD 28 SSL version
>     NONE/0.0 negotiated cipher ||2022/11/29 10:32:38.943 kid1| 83,5|
>     PeekingPeerConnector.cc(84) checkForPeekAndSpliceMatched: Will check
>     for peek and splice on FD 28 ||2022/11/29 10:32:38.943 kid1| 83,5|
>     PeekingPeerConnector.cc(395) serverCertificateVerified: HTTPS server
>     CN: arsenal.us-west-2.amazonaws.com
>     <http://arsenal.us-west-2.amazonaws.com> bumped: conn99
>     local=SQUID-INTERNAL-IP:44264 remote=54.240.251.223:443
>     <http://54.240.251.223:443> ORIGINAL_DST FD 28 flags=1 |
>     |2022/11/29 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(273)
>     startTunneling: will tunnel instead of negotiating TLS|
> 
>     It is clear that in creates the tunnel so the 500 probably is that
>     error? Why the bump/sni messages never log anything (according to
>     https://wiki.squid-cache.org/Features/SslPeekAndSplice
>     <https://wiki.squid-cache.org/Features/SslPeekAndSplice> they should
>     log splice not -). This is the config for bumping:
> 
> 
> 
>     acl step1 at_step SslBump1
>     acl step2 at_step SslBump2
>     acl step3 at_step SslBump3
>     ssl_bump peek step1 all
> 
>     .... http rules ...
> 
>     acl allowed_https_sites ssl::server_name_regex
>     "/etc/squid/whitelist.txt"
>     ssl_bump peek step2 allowed_https_sites
>     ssl_bump splice step3 allowed_https_sites
>     ssl_bump terminate step2 all
> 
> 
> 
> 
>     Ip tables simply redirect:
> 
>     iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT
>     --to-port 3129
>     iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT
>     --to-port 3130 # https port on squid: https_port 3130 intercept
>     ssl-bump cert=/etc/squid/ssl/dummy.pem
> 
>     Thanks in advance, i have been trying this for a week now reading a
>     lot of posts but not luck...
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From gvilarino6 at gmail.com  Tue Nov 29 20:52:53 2022
From: gvilarino6 at gmail.com (=?UTF-8?Q?Gabriel_Vilari=C3=B1o?=)
Date: Tue, 29 Nov 2022 21:52:53 +0100
Subject: [squid-users] Logs not showing ssl::servername
In-Reply-To: <CAGSQugn9D=XvcX7V8nNji5fFTe-ddKEVtRLdc_aTqqfnDaGgjw@mail.gmail.com>
References: <CAGSQug=Ri2iZV+DVD45xCcVh2viP8d0ocs1u+yetZB3QPoXqKA@mail.gmail.com>
 <CAGSQugn9D=XvcX7V8nNji5fFTe-ddKEVtRLdc_aTqqfnDaGgjw@mail.gmail.com>
Message-ID: <CAGSQugk-aQHNXZ9JC__S-XLxJ97-Xr6+A5rQ4KDdG-jkSswgRQ@mail.gmail.com>

Thanks Alex!

Here are the fixed logs:
1669726977.734 INTERNAL_CLIENT_IP TCP_TUNNEL/500
arsenal.us-west-2.amazonaws.com splice /CN=arsenal.us-west-2.amazonaws.com
54.240.251.223

As you can see, the destination is an aws service, more interesting, it
effectively *logs the splice* action! That?s why I though it was letting
the traffic go trough. Also the debug logs from SSL show this:
2022/11/29 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(273)
*startTunneling:
will tunnel instead of negotiating TLS* # Last line from previously
attached logs

As far as I know this means *is getting to the TCP_TUNNEL, at that point it
can not know anything about the internal status on the connection between
client and host*. If not, *where I should be looking for this error? *Should
try to review further the debug ssl logs to se if I fend something more
useful? Maybe tcpdump? This could be just the end service failing on the
request? Or is an error between Squid and the end sever?

If I understand right the request that fails is the fake connect and I need
to understand why. Also note almost same config logged this as
TCP_TUNNEL/200 on version 3.5. But as said before, I really not sure how to
check, since that service is just an agent installed on some aws machines
and don?t know how to reproduce this behavior.




Thanks again! Hope I answered fine since I didn?t get the answer email.


El mar, 29 nov 2022 a las 14:06, Gabriel Vilari?o (<gvilarino6 at gmail.com>)
escribi?:

> Just got it solved. Was caused because of checking default access.log.
> Using a new file solves all the problems.
>
> However, in this context, what means TCP_TUNNEL/500? is it because the TLS
> handshake? I would like to know if it is tunneling correctly or is having
> some trouble (not easy to test right now).
>
> Thanks!
>
> El mar, 29 nov 2022 a las 13:16, Gabriel Vilari?o (<gvilarino6 at gmail.com>)
> escribi?:
>
>> Hi there,
>>
>> I am setting up an HTTP/HTTPS transparent proxy, meaning the clients not
>> need any certificates for using the proxy. This works fine on version 3.5
>> of Squid, however after upgrading to 5.7 the behavior of the logs change:
>>
>> 1669723133.174   8037 10.184.19.220 TCP_TUNNEL/500 6207 CONNECT
>> 54.240.253.128:443 - ORIGINAL_DST/54.240.253.128 -
>>
>> Directive: logformat squid %ts.%03tu %>a %Ss/%03>Hs %ssl::>sni
>> %ssl::bump_mode ssl::>cert_subject %<ru
>>
>> On version 3.5 we were obtaining the domain name (an aws service) in the
>> place of ORIGINAL_DST. Also now we are not seeing any information about the
>> bump_mode in no one of the connections while before we were seeing it. One
>> could trough that it could be because of the /500 message, however on a 200
>> one to docs.ansble.com it also don?t show any data on the sni field:
>>
>> 1669723513.363    332 10.184.19.220 TCP_TUNNEL/200 38192 CONNECT
>> 104.26.0.234:443 - ORIGINAL_DST/104.26.0.234 -
>>
>> Also the 500 looks to come from the squid not understanding something on
>> the SSL negotiation:
>>
>> 2022/11/29 10:32:38.943 kid1| 83,4| support.cc(248) check_domain:
>> Verifying server domain arsenal.us-west-2.amazonaws.com to certificate
>> name/subjectAltName arsenal.us-west-2.amazonaws.com 2022/11/29
>> 10:32:38.943 kid1| 83,5| bio.cc(136) read: FD 28 read 347 <= 65535 2022/11/29
>> 10:32:38.943 kid1| 83,5| Io.cc(91) Handshake: -1/0 for TLS connection
>> 0x558453168970 over conn99 local=SQUID-INTERNAL-IP:44264 remote=
>> 54.240.251.223:443 ORIGINAL_DST FD 28 flags=1 2022/11/29 10:32:38.943
>> kid1| 83,2| PeerConnector.cc(256) handleNegotiationResult: ERROR: failure
>> while establishing TLS connection on FD: 280x558452b68980*1 2022/11/29
>> 10:32:38.943 kid1| 83,5| NegotiationHistory.cc(85) retrieveNegotiatedInfo:
>> SSL connection info on FD 28 SSL version NONE/0.0 negotiated cipher 2022/11/29
>> 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(84)
>> checkForPeekAndSpliceMatched: Will check for peek and splice on FD 28 2022/11/29
>> 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(395)
>> serverCertificateVerified: HTTPS server CN:
>> arsenal.us-west-2.amazonaws.com bumped: conn99
>> local=SQUID-INTERNAL-IP:44264 remote=54.240.251.223:443 ORIGINAL_DST FD
>> 28 flags=1
>> 2022/11/29 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(273)
>> startTunneling: will tunnel instead of negotiating TLS
>>
>> It is clear that in creates the tunnel so the 500 probably is that error?
>> Why the bump/sni messages never log anything (according to
>> https://wiki.squid-cache.org/Features/SslPeekAndSplice they should log
>> splice not -). This is the config for bumping:
>>
>>
>>
>> acl step1 at_step SslBump1
>> acl step2 at_step SslBump2
>> acl step3 at_step SslBump3
>> ssl_bump peek step1 all
>>
>> .... http rules ...
>>
>> acl allowed_https_sites ssl::server_name_regex "/etc/squid/whitelist.txt"
>> ssl_bump peek step2 allowed_https_sites
>> ssl_bump splice step3 allowed_https_sites
>> ssl_bump terminate step2 all
>>
>>
>>
>>
>> Ip tables simply redirect:
>>
>> iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 3129
>> iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-port
>> 3130 # https port on squid: https_port 3130 intercept ssl-bump
>> cert=/etc/squid/ssl/dummy.pem
>>
>> Thanks in advance, i have been trying this for a week now reading a lot
>> of posts but not luck...
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221129/8cabd548/attachment.htm>

From rousskov at measurement-factory.com  Tue Nov 29 21:15:36 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 29 Nov 2022 16:15:36 -0500
Subject: [squid-users] Logs not showing ssl::servername
In-Reply-To: <CAGSQugk-aQHNXZ9JC__S-XLxJ97-Xr6+A5rQ4KDdG-jkSswgRQ@mail.gmail.com>
References: <CAGSQug=Ri2iZV+DVD45xCcVh2viP8d0ocs1u+yetZB3QPoXqKA@mail.gmail.com>
 <CAGSQugn9D=XvcX7V8nNji5fFTe-ddKEVtRLdc_aTqqfnDaGgjw@mail.gmail.com>
 <CAGSQugk-aQHNXZ9JC__S-XLxJ97-Xr6+A5rQ4KDdG-jkSswgRQ@mail.gmail.com>
Message-ID: <1dccba7c-f6bc-57c8-a672-9981d228092e@measurement-factory.com>

On 11/29/22 15:52, Gabriel Vilari?o wrote:
> Here are the fixed logs:
> |1669726977.734 INTERNAL_CLIENT_IP TCP_TUNNEL/500 
> arsenal.us-west-2.amazonaws.com splice /CN=arsenal.us-west-2.amazonaws.com 54.240.251.223|


> |As you can see, the destination is an aws service, more interesting, it 
> effectively *logs the splice* action! That?s why I though it was letting 
> the traffic go trough.

Yeah. Without more information, I cannot tell whether Squid logs the 
wrong "500" status code or the wrong "splice" action in this case.


> Also the debug logs from SSL show this:|
> ||2022/11/29 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(273) 
> *startTunneling: will tunnel instead of negotiating TLS* # Last line 
> from previously attached logs||
> ||
> ||
> ||As far as I know this means *is getting to the TCP_TUNNEL, at that 
> point it can not know anything about the internal status on the 
> connection between client and host*. 

Correct.


> If not, *where I should be looking for this error?

My current bet is that either

* there is no error at all (but Squid logs the wrong 500 status code) OR
* there is an error (but you are looking at the wrong cache.log lines 
that are not about the transaction that ended with an error).


FWIW, IMHO, you should not be looking for information in debugging 
cache.log (ALL,3 or higher) because the latter is not designed for admin 
use. Instead, you should:

* log %err_code/%err_detail to access.log and share that info (along 
with any associated level-0/1 messages in cache.log).

* If that information is not sufficient, then you should share debugging 
cache.log, so that folks who know "where to look for this error" can 
look for it. 
https://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction


Said that, the answer to your question is: The misleading "will tunnel 
instead of negotiating" line in an ALL,5+ debugging cache.log is 
associated with a no-error successful-splicing-at-step3 transaction 
outcome. If the same transaction ends with an error from client or 
origin point of view, then that error usually happens _after_ Squid 
splices the connections. In that case, Squid will not "see" that error.


HTH,

Alex.



> El mar, 29 nov 2022 a las 14:06, Gabriel Vilari?o (<gvilarino6 at gmail.com>) escribi?:
> 
>     Just got it solved. Was caused because of checking default
>     access.log. Using a new file solves all the problems.
> 
>     However, in this context, what means TCP_TUNNEL/500? is it because
>     the TLS handshake? I would like to know if it is tunneling correctly
>     or is having some trouble (not easy to test right now).
> 
>     Thanks!
> 
>     El mar, 29 nov 2022 a las 13:16, Gabriel Vilari?o
>     (<gvilarino6 at gmail.com <mailto:gvilarino6 at gmail.com>>) escribi?:
> 
>         Hi there,
> 
>         I am setting up an HTTP/HTTPS transparent proxy, meaning the
>         clients not need any certificates for using the proxy. This
>         works fine on version 3.5 of Squid, however after upgrading to
>         5.7 the behavior of the logs change:
> 
>         1669723133.174 ? 8037 10.184.19.220 TCP_TUNNEL/500 6207 CONNECT
>         54.240.253.128:443 <http://54.240.253.128:443> -
>         ORIGINAL_DST/54.240.253.128 <http://54.240.253.128> -
> 
>         Directive: logformat squid %ts.%03tu %>a %Ss/%03>Hs %ssl::>sni
>         %ssl::bump_mode ssl::>cert_subject %<ru
> 
>         On version 3.5 we were obtaining the domain name (an aws
>         service) in the place of ORIGINAL_DST. Also now we are not
>         seeing any information about the bump_mode in no one of the
>         connections while before we were seeing it. One could trough
>         that it could be because of the /500 message, however on a 200
>         one to docs.ansble.com <http://docs.ansble.com> it also don?t
>         show any data on the sni field:
> 
>         1669723513.363 ? ?332 10.184.19.220 TCP_TUNNEL/200 38192 CONNECT
>         104.26.0.234:443 <http://104.26.0.234:443> -
>         ORIGINAL_DST/104.26.0.234 <http://104.26.0.234> -
> 
>         Also the 500 looks to come from the squid not understanding
>         something on the SSL negotiation:
> 
>         |2022/11/29 10:32:38.943 kid1| 83,4| support.cc(248)
>         check_domain: Verifying server domain
>         arsenal.us-west-2.amazonaws.com
>         <http://arsenal.us-west-2.amazonaws.com> to certificate
>         name/subjectAltName arsenal.us-west-2.amazonaws.com
>         <http://arsenal.us-west-2.amazonaws.com> ||2022/11/29
>         10:32:38.943 kid1| 83,5| bio.cc(136) read: FD 28 read 347 <=
>         65535 ||2022/11/29 10:32:38.943 kid1| 83,5| Io.cc(91) Handshake:
>         -1/0 for TLS connection 0x558453168970 over conn99
>         local=SQUID-INTERNAL-IP:44264 remote=54.240.251.223:443
>         <http://54.240.251.223:443> ORIGINAL_DST FD 28 flags=1
>         ||2022/11/29 10:32:38.943 kid1| 83,2| PeerConnector.cc(256)
>         handleNegotiationResult: ERROR: failure while establishing TLS
>         connection on FD: 280x558452b68980*1 ||2022/11/29 10:32:38.943
>         kid1| 83,5| NegotiationHistory.cc(85) retrieveNegotiatedInfo:
>         SSL connection info on FD 28 SSL version NONE/0.0 negotiated
>         cipher ||2022/11/29 10:32:38.943 kid1| 83,5|
>         PeekingPeerConnector.cc(84) checkForPeekAndSpliceMatched: Will
>         check for peek and splice on FD 28 ||2022/11/29 10:32:38.943
>         kid1| 83,5| PeekingPeerConnector.cc(395)
>         serverCertificateVerified: HTTPS server CN:
>         arsenal.us-west-2.amazonaws.com
>         <http://arsenal.us-west-2.amazonaws.com> bumped: conn99
>         local=SQUID-INTERNAL-IP:44264 remote=54.240.251.223:443
>         <http://54.240.251.223:443> ORIGINAL_DST FD 28 flags=1 |
>         |2022/11/29 10:32:38.943 kid1| 83,5|
>         PeekingPeerConnector.cc(273) startTunneling: will tunnel instead
>         of negotiating TLS|
> 
>         It is clear that in creates the tunnel so the 500 probably is
>         that error? Why the bump/sni messages never log anything
>         (according to
>         https://wiki.squid-cache.org/Features/SslPeekAndSplice
>         <https://wiki.squid-cache.org/Features/SslPeekAndSplice> they
>         should log splice not -). This is the config for bumping:
> 
> 
> 
>         acl step1 at_step SslBump1
>         acl step2 at_step SslBump2
>         acl step3 at_step SslBump3
>         ssl_bump peek step1 all
> 
>         .... http rules ...
> 
>         acl allowed_https_sites ssl::server_name_regex
>         "/etc/squid/whitelist.txt"
>         ssl_bump peek step2 allowed_https_sites
>         ssl_bump splice step3 allowed_https_sites
>         ssl_bump terminate step2 all
> 
> 
> 
> 
>         Ip tables simply redirect:
> 
>         iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT
>         --to-port 3129
>         iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT
>         --to-port 3130 # https port on squid: https_port 3130 intercept
>         ssl-bump cert=/etc/squid/ssl/dummy.pem
> 
>         Thanks in advance, i have been trying this for a week now
>         reading a lot of posts but not luck...
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Wed Nov 30 01:00:42 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 30 Nov 2022 14:00:42 +1300
Subject: [squid-users] tcp_outgoing_address directive ignored,
 data goes out on default gateway
In-Reply-To: <CAOB-ucngBrY8o1zGhitWzmwOackfXmWifCTCz1yoPS9VK-9igQ@mail.gmail.com>
References: <CAOB-uc=0+a_SVn+-fNKe=N-3yt-_z1-jrnESJJ6dkhfSC3qWzA@mail.gmail.com>
 <499c9974-1089-37b0-fcc0-b1376b1ffb8a@treenet.co.nz>
 <CAOB-ucngBrY8o1zGhitWzmwOackfXmWifCTCz1yoPS9VK-9igQ@mail.gmail.com>
Message-ID: <7f975b7a-e34e-41c6-96df-ef7fe03845f7@treenet.co.nz>

On 29/11/2022 9:07 pm, N wrote:
> Hi Amos,
> thanks for the quick response.
>
> following your comments, my configuration now looks like this:
> acl auth_users proxy_auth REQUIRED
> http_access deny !auth_users
> acl wg_uk note user uk
> tcp_outgoing_address 10.200.0.70 wg_uk
> tcp_outgoing_address fe80::bd02:7fd9:3f4b:4a22 wg_uk
>
> still, the traffic is not going through the wg_uk interface.
>
> the logs are huge when using squid -k debug, so I wasn't sure what I 
> should clip.
> I decided to add the full log of the few requests that were tested, 
> hope it's ok, and that you can understand something from it.

Log is great. It confirms a bug happening. The wg_uk ACL produces a 
non-matches on the first time it scans the tcp_outgoing_address list, 
then matches on the second IP tested. It should be always matching or 
always non-matching.

Please report this to the project bugzilla 
(<http://bugs.squid-cache.org>) for tracking.
I am about to try to replicate the issue here and will update the report 
with my findings in the next day or so.


Cheers
Amos



From gvilarino6 at gmail.com  Wed Nov 30 08:16:43 2022
From: gvilarino6 at gmail.com (=?UTF-8?Q?Gabriel_Vilari=C3=B1o?=)
Date: Wed, 30 Nov 2022 09:16:43 +0100
Subject: [squid-users] Logs not showing ssl::servername
In-Reply-To: <CAGSQugk-aQHNXZ9JC__S-XLxJ97-Xr6+A5rQ4KDdG-jkSswgRQ@mail.gmail.com>
References: <CAGSQug=Ri2iZV+DVD45xCcVh2viP8d0ocs1u+yetZB3QPoXqKA@mail.gmail.com>
 <CAGSQugn9D=XvcX7V8nNji5fFTe-ddKEVtRLdc_aTqqfnDaGgjw@mail.gmail.com>
 <CAGSQugk-aQHNXZ9JC__S-XLxJ97-Xr6+A5rQ4KDdG-jkSswgRQ@mail.gmail.com>
Message-ID: <CAGSQugkYf5S80F4p8suW-w6SoXy208GQs3g1_fRqcxA5205dnQ@mail.gmail.com>

Hi again!

Thanks for the info!

Log with error code and error detail at the end, both "-":
1669794718.051 INTERNAL_IP *TCP_TUNNEL/500* arsenal.us-west-2.amazonaws.com
splice /CN=arsenal.us-west-2.amazonaws.com 54.240.254.131* - -*

The cache.log with ALL,1 does not look to share a lot, in fact I don?t see
any messages referencing this transaction:

22/11/30 07:51:39 kid1| Current Directory is /
2022/11/30 07:51:39 kid1| Creating missing swap directories
2022/11/30 07:51:39 kid1| No cache_dir stores are configured.
2022/11/30 07:51:39| Removing PID file (/run/squid.pid)
2022/11/30 07:51:39 kid1| Current Directory is /
2022/11/30 07:51:39 kid1| Starting Squid Cache version 5.7 for
x86_64-pc-linux-gnu...
2022/11/30 07:51:39 kid1| Service Name: squid
2022/11/30 07:51:39 kid1| Process ID 64694
2022/11/30 07:51:39 kid1| Process Roles: worker
2022/11/30 07:51:39 kid1| With 1024 file descriptors available
2022/11/30 07:51:39 kid1| Initializing IP Cache...
2022/11/30 07:51:39 kid1| DNS Socket created at [::], FD 9
2022/11/30 07:51:39 kid1| DNS Socket created at 0.0.0.0, FD 10
2022/11/30 07:51:39 kid1| Adding nameserver 127.0.0.53 from /etc/resolv.conf
2022/11/30 07:51:39 kid1| Adding domain dev.ops.mitekcloud.local from
/etc/resolv.conf
2022/11/30 07:51:39 kid1| helperOpenServers: Starting 5/32
'security_file_certgen' processes
2022/11/30 07:51:39 kid1| Logfile: opening log
daemon:/var/log/squid/custom.log
2022/11/30 07:51:39 kid1| Logfile Daemon: opening log
/var/log/squid/custom.log
2022/11/30 07:51:40 kid1| Local cache digest enabled; rebuild/rewrite every
3600/3600 sec
2022/11/30 07:51:40 kid1| Store logging disabled
2022/11/30 07:51:40 kid1| Swap maxSize 0 + 262144 KB, estimated 20164
objects
2022/11/30 07:51:40 kid1| Target number of buckets: 1008
2022/11/30 07:51:40 kid1| Using 8192 Store buckets
2022/11/30 07:51:40 kid1| Max Mem  size: 262144 KB
2022/11/30 07:51:40 kid1| Max Swap size: 0 KB
2022/11/30 07:51:40 kid1| Using Least Load store dir selection
2022/11/30 07:51:40 kid1| Current Directory is /
2022/11/30 07:51:40 kid1| Finished loading MIME types and icons.
2022/11/30 07:51:40 kid1| HTCP Disabled.
2022/11/30 07:51:40 kid1| Pinger socket opened on FD 27
2022/11/30 07:51:40 kid1| Squid plugin modules loaded: 0
2022/11/30 07:51:40 kid1| Adaptation support is off.
2022/11/30 07:51:40 kid1| Accepting HTTP Socket connections at conn13
local=[::]:3128 remote=[::] FD 23 flags=9
2022/11/30 07:51:40 kid1| Accepting NAT intercepted HTTP Socket connections
at conn15 local=[::]:3129 remote=[::] FD 24 flags=41
2022/11/30 07:51:40 kid1| Accepting NAT intercepted SSL bumped HTTPS Socket
connections at conn17 local=[::]:3130 remote=[::] FD 25 flags=41
2022/11/30 07:51:40| pinger: Initialising ICMP pinger ...
2022/11/30 07:51:40| pinger: ICMP socket opened.
2022/11/30 07:51:40| pinger: ICMPv6 socket opened
2022/11/30 07:51:41 kid1| storeLateRelease: released 0 objects
2022/11/30 07:52:09 kid1| Preparing for shutdown after 3 requests
... Starts ending the connections for shutdown, ends with next message...
*2022/11/30 07:52:40 kid1| Squid Cache (Version 5.7): Exiting normally.*

I checked with further log levels but it outputs a lot of data (I know this
one is not for admins, I wanted to try to sent only the relevant logs since
those aws agents do several calls and I was not to only record one
transaction). Also if I needed, this is shared as an attachment?

Thanks in advance!


El mar, 29 nov 2022 a las 21:52, Gabriel Vilari?o (<gvilarino6 at gmail.com>)
escribi?:

> Thanks Alex!
>
> Here are the fixed logs:
> 1669726977.734 INTERNAL_CLIENT_IP TCP_TUNNEL/500
> arsenal.us-west-2.amazonaws.com splice /CN=arsenal.us-west-2.amazonaws.com
> 54.240.251.223
>
> As you can see, the destination is an aws service, more interesting, it
> effectively *logs the splice* action! That?s why I though it was letting
> the traffic go trough. Also the debug logs from SSL show this:
> 2022/11/29 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(273) *startTunneling:
> will tunnel instead of negotiating TLS* # Last line from previously
> attached logs
>
> As far as I know this means *is getting to the TCP_TUNNEL, at that point
> it can not know anything about the internal status on the connection
> between client and host*. If not, *where I should be looking for this
> error? *Should try to review further the debug ssl logs to se if I fend
> something more useful? Maybe tcpdump? This could be just the end service
> failing on the request? Or is an error between Squid and the end sever?
>
> If I understand right the request that fails is the fake connect and I
> need to understand why. Also note almost same config logged this as
> TCP_TUNNEL/200 on version 3.5. But as said before, I really not sure how
> to check, since that service is just an agent installed on some aws
> machines and don?t know how to reproduce this behavior.
>
>
>
>
> Thanks again! Hope I answered fine since I didn?t get the answer email.
>
>
> El mar, 29 nov 2022 a las 14:06, Gabriel Vilari?o (<gvilarino6 at gmail.com>)
> escribi?:
>
>> Just got it solved. Was caused because of checking default access.log.
>> Using a new file solves all the problems.
>>
>> However, in this context, what means TCP_TUNNEL/500? is it because the
>> TLS handshake? I would like to know if it is tunneling correctly or is
>> having some trouble (not easy to test right now).
>>
>> Thanks!
>>
>> El mar, 29 nov 2022 a las 13:16, Gabriel Vilari?o (<gvilarino6 at gmail.com>)
>> escribi?:
>>
>>> Hi there,
>>>
>>> I am setting up an HTTP/HTTPS transparent proxy, meaning the clients not
>>> need any certificates for using the proxy. This works fine on version 3.5
>>> of Squid, however after upgrading to 5.7 the behavior of the logs change:
>>>
>>> 1669723133.174   8037 10.184.19.220 TCP_TUNNEL/500 6207 CONNECT
>>> 54.240.253.128:443 - ORIGINAL_DST/54.240.253.128 -
>>>
>>> Directive: logformat squid %ts.%03tu %>a %Ss/%03>Hs %ssl::>sni
>>> %ssl::bump_mode ssl::>cert_subject %<ru
>>>
>>> On version 3.5 we were obtaining the domain name (an aws service) in the
>>> place of ORIGINAL_DST. Also now we are not seeing any information about the
>>> bump_mode in no one of the connections while before we were seeing it. One
>>> could trough that it could be because of the /500 message, however on a 200
>>> one to docs.ansble.com it also don?t show any data on the sni field:
>>>
>>> 1669723513.363    332 10.184.19.220 TCP_TUNNEL/200 38192 CONNECT
>>> 104.26.0.234:443 - ORIGINAL_DST/104.26.0.234 -
>>>
>>> Also the 500 looks to come from the squid not understanding something on
>>> the SSL negotiation:
>>>
>>> 2022/11/29 10:32:38.943 kid1| 83,4| support.cc(248) check_domain:
>>> Verifying server domain arsenal.us-west-2.amazonaws.com to certificate
>>> name/subjectAltName arsenal.us-west-2.amazonaws.com 2022/11/29
>>> 10:32:38.943 kid1| 83,5| bio.cc(136) read: FD 28 read 347 <= 65535 2022/11/29
>>> 10:32:38.943 kid1| 83,5| Io.cc(91) Handshake: -1/0 for TLS connection
>>> 0x558453168970 over conn99 local=SQUID-INTERNAL-IP:44264 remote=
>>> 54.240.251.223:443 ORIGINAL_DST FD 28 flags=1 2022/11/29 10:32:38.943
>>> kid1| 83,2| PeerConnector.cc(256) handleNegotiationResult: ERROR: failure
>>> while establishing TLS connection on FD: 280x558452b68980*1 2022/11/29
>>> 10:32:38.943 kid1| 83,5| NegotiationHistory.cc(85) retrieveNegotiatedInfo:
>>> SSL connection info on FD 28 SSL version NONE/0.0 negotiated cipher 2022/11/29
>>> 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(84)
>>> checkForPeekAndSpliceMatched: Will check for peek and splice on FD 28 2022/11/29
>>> 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(395)
>>> serverCertificateVerified: HTTPS server CN:
>>> arsenal.us-west-2.amazonaws.com bumped: conn99
>>> local=SQUID-INTERNAL-IP:44264 remote=54.240.251.223:443 ORIGINAL_DST FD
>>> 28 flags=1
>>> 2022/11/29 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(273)
>>> startTunneling: will tunnel instead of negotiating TLS
>>>
>>> It is clear that in creates the tunnel so the 500 probably is that
>>> error? Why the bump/sni messages never log anything (according to
>>> https://wiki.squid-cache.org/Features/SslPeekAndSplice they should log
>>> splice not -). This is the config for bumping:
>>>
>>>
>>>
>>> acl step1 at_step SslBump1
>>> acl step2 at_step SslBump2
>>> acl step3 at_step SslBump3
>>> ssl_bump peek step1 all
>>>
>>> .... http rules ...
>>>
>>> acl allowed_https_sites ssl::server_name_regex "/etc/squid/whitelist.txt"
>>> ssl_bump peek step2 allowed_https_sites
>>> ssl_bump splice step3 allowed_https_sites
>>> ssl_bump terminate step2 all
>>>
>>>
>>>
>>>
>>> Ip tables simply redirect:
>>>
>>> iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port
>>> 3129
>>> iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-port
>>> 3130 # https port on squid: https_port 3130 intercept ssl-bump
>>> cert=/etc/squid/ssl/dummy.pem
>>>
>>> Thanks in advance, i have been trying this for a week now reading a lot
>>> of posts but not luck...
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221130/ec207dd3/attachment.htm>

From gkinkie at gmail.com  Wed Nov 30 10:21:50 2022
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Wed, 30 Nov 2022 11:21:50 +0100
Subject: [squid-users] Help wanted to clean up and update the wiki
Message-ID: <CA+Y8hcMqUQ2BkSKQ=niqoCO02BxVJ+d-dgsZ+9TBuHomCuWy8A@mail.gmail.com>

Hi all!
  In the last weeks I have started the process to clean up the squid wiki
and port it to a faster and more effective platform - the goal is to be
able to host it onsite or on github pages.

I have done the heavy lifting of collecting and auto-transcoding the
contents from MoinMon to Markdown, but as it always happens there's a lot
of cleanup to do, and at 500 pages it's a lot of work. You can find the
work in progress at https://kinkie.github.io/ and the underlying dataset at
https://github.com/kinkie/kinkie.github.io .

THE ASK
Is anyone willing to help, clean and migrate pages over?


HOW TO HELP
I am currently focusing on the ConfigExamples section of the wiki. Pages to
be cleaned up are in old/ConfigExamples. For each page in that subtree, the
"example as-is" content needs to be removed (it's now added by the
template engine), markdown needs to be cleaned up, and the page can be
moved to the docs/ subtree (in the same relative location); then send me a
PR with the changes.
Changes can be tested locally if you have jekyll installed on your system
along with the plugins listed in docs/_config.yml, by the running bin/serve
script

Thanks for any contributions, and please ask questions if something is
unclear, they will help me develop a more comprehensive how-to-help guide

-- 
    Francesco
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221130/959d67d5/attachment.htm>

From ngtech1ltd at gmail.com  Wed Nov 30 10:56:50 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Wed, 30 Nov 2022 12:56:50 +0200
Subject: [squid-users] transparent mode squid on centos 9 with iptables
 (part 2)
In-Reply-To: <CAKM+x_JGMXB9eVe66Z8+2wTBr6qpmOCa3a_b=Psn07pxELjjjw@mail.gmail.com>
References: <CAKM+x_L67p0YjP3BPwSU=cp8PrQcG-CVH7jzmT80AB=ym3u4Vw@mail.gmail.com>
 <CAKM+x_JRkR2vNgT_zqcQAd3qXTwQMXDa8mJeEY+R6FYXDiFB0g@mail.gmail.com>
 <CAKM+x_K5XA0oTvEsGkzwHuYbVVYXe+1UegWCW2b37_pATX7mDQ@mail.gmail.com>
 <CAKM+x_JwQt+4jwVsfzgdj-x-DoWC77TqYROS44+cux0asdAADw@mail.gmail.com>
 <07c330f7-4de8-bc8f-3aab-a00c12baa157@treenet.co.nz>
 <CAKM+x_JGMXB9eVe66Z8+2wTBr6qpmOCa3a_b=Psn07pxELjjjw@mail.gmail.com>
Message-ID: <001101d904aa$73a03190$5ae094b0$@gmail.com>

Hey,
 
There are no technical details about the relevant subject which is the iptables, iproute and squid.conf
I will try to give a demo for such a setup later on.
 
Eliezer
 
----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/
 
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Lola Lo
Sent: Monday, 28 November 2022 6:33
To: Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] transparent mode squid on centos 9 with iptables (part 2)
 
Hi Amos.
 
Thank you for your advice. I applied the instructionts that you have sent it to me in this link: https://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect and the https://wiki.squid-cache.org/ConfigExamples/Intercept/IptablesPolicyRoute, the case of: "When Squid is Internal amongst clients" and the section:  Routing Setup. Now I can see the squid is intercepting the traffic however, it is not applying my policies:
 
http_access deny cliente_linux sitios2
http_access deny cliente_windows sitios1
http_access allow mi_red
 
"sitios2"=facebook
"sitios1"=youtube
 these policies work when I set up manually the proxy. Do you have any idea of how to troubleshoot this?
Thank you for your help
 
 
 
On Wed, Nov 16, 2022 at 11:35 PM Amos Jeffries <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz> > wrote:
On 17/11/2022 9:14 am, Lola Lo wrote:
> Hi guys.
>
>
> Could you please send a tutorial or any good guidance to implement  
> squid on transparent mode on centos 9 with iptables.
>

The configuration details for what you appear to be trying to configure 
are here:
  <https://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect>

My comments below relate to how your attempt differs and how to fix.

> I have configured squid.conf with this parameters:
>
>
>
> ens192: 172.31.168.28, internet interface
>
> ens224: 192.168.1.10, LAN interface (private network)
>
>
> # Mis ACLs #
>
> acl mi_red src 192.168.1.0/24 <http://192.168.1.0/24>  <http://192.168.1.0/24>
>
> acl cliente_linux src 192.168.1.20
>
> acl cliente_windows src 192.168.1.30
>
> acl sitios1 url_regex "/etc/squid/listas/sitios1"
>
> acl sitios2 url_regex "/etc/squid/listas/sitios2"
>
>
> # Squid normally listens to port 3128
>
> http_port 3128
>
> http_port 8080 transparent
>
>

Firstly, use "intercept" instead of "transparent" with modern Squid.

Secondly, remember that only port 8080 is setup to receive intercepted 
traffic. Port 3128 still receives normal forward-proxy traffic.

> I want the ?deny all? rule get applied to test the client using the proxy
>
>

You have not shown any http_access lines from your config. There is a 
clear bug in your NAT which explains the behaviour so I will assume that 
the squid.conf policy does what you want.


> My iptables is configured as follows:
>
>
> #!/bin/bash
>
>
> ## NAT server configuration ##
>
>
> sysctl -w net.ipv4.ip_forward=1
>
> sysctl -p
>
> iptables -X
>
> iptables -F
>
> iptables -t nat -X
>
> iptables -t nat -F
>
> iptables -I INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
>
> iptables -I FORWARD-m state --state RELATED,ESTABLISHED -j ACCEPT
>
> iptables -t nat -I POSTROUTING -o ens192 -j MASQUERADE
>
>
>

Why is this a different script?
Ideally the firewall rules should be as atomic as possible to avoid 
connections being setup with only part of the rules applied.


>
> #!/bin/bash
>
>
> ## proxy server configuration ##
>
>
> ### Accepting traffic for the ports: 3128 and 8080##
>
>
> iptables -A INPUT -s 192.168.1.0/24 <http://192.168.1.0/24>  <http://192.168.1.0/24> -p tcp 
> --dport 3128 -j ACCEPT
>
> iptables -A INPUT -p tcp --dport 3128 -j DROP
>

Do not accept traffic directly to the port 8080. Also Squid does not 
make outbound connections from its listening ports.
So these ...

> iptables -A OUTPUT -d 192.168.1.0/24 <http://192.168.1.0/24>  <http://192.168.1.0/24> -p tcp 
> --sport 3128 -j ACCEPT
>
> iptables -A OUTPUT -p tcp --sport 3128 -j DROP
>
>
> iptables -A INPUT -s 192.168.1.0/24 <http://192.168.1.0/24>  <http://192.168.1.0/24> -p tcp 
> --dport 8080 -j ACCEPT
>
> iptables -A INPUT -p tcp --dport 8080 -j DROP
>
> iptables -A OUTPUT -d 192.168.1.0/24 <http://192.168.1.0/24>  <http://192.168.1.0/24> -p tcp 
> --sport 8080 -j ACCEPT
>
> iptables -A OUTPUT -p tcp --sport 8080 -j DROP
>
>

... should be replaced with:

   iptables -t mangle -A PREROUTING -p tcp --dport 8080 -j DROP


>
> `### Accepting traffic for the ports: 3128 and 8080##
>
>
> iptables -t nat -A POSTROUTING -o ens192 -j MASQUERADE
>

You are missing a rule to allow Squid outbound traffic to avoid the NAT.

   iptables -t nat -A PREROUTING -s 192.168.1.10 -p tcp --dport 80 -j ACCEPT

> iptables -t nat -A PREROUTING -s 192.168.1.0/24 <http://192.168.1.0/24>  
> <http://192.168.1.0/24> -p tcp --dport 80 -j REDIRECT --to-port 8080
>
> iptables -t nat -A PREROUTING -s 192.168.1.0/24 <http://192.168.1.0/24>  
> <http://192.168.1.0/24> -p tcp --dport 443 -j REDIRECT --to-port 8080
>
>

Port 8080 in your squid.conf can only handle port 80 traffic syntax.

Port 443 is a more tricky situation. I recommend removing that until you 
have the port 80 working.


>
> But I got this error:
>
>
> 1668381894.7460 192.168.1.20 NONE_NONE/000 0 - 
> error:transaction-end-before-headers - HIER_NONE/- -
>
> 1668381967.8000 192.168.1.20 NONE_NONE/400 3690 - 
> error:invalid-request - HIER_NONE/- text/html
>

This is likely from the missing NAT rule allowing Squid outbound.

If the above changes do not fix everything make sure that you test 
exactly what the real clients will be doing. Specifically that they are 
making contact to servers on port 80 or directly to Squid port 3128. 
They know *nothing* about port 8080 existence so have no reason to send 
anything that way directly.


HTH
Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221130/d5f4e551/attachment.htm>

From rousskov at measurement-factory.com  Wed Nov 30 15:48:03 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 30 Nov 2022 10:48:03 -0500
Subject: [squid-users] Logs not showing ssl::servername
In-Reply-To: <CAGSQugkYf5S80F4p8suW-w6SoXy208GQs3g1_fRqcxA5205dnQ@mail.gmail.com>
References: <CAGSQug=Ri2iZV+DVD45xCcVh2viP8d0ocs1u+yetZB3QPoXqKA@mail.gmail.com>
 <CAGSQugn9D=XvcX7V8nNji5fFTe-ddKEVtRLdc_aTqqfnDaGgjw@mail.gmail.com>
 <CAGSQugk-aQHNXZ9JC__S-XLxJ97-Xr6+A5rQ4KDdG-jkSswgRQ@mail.gmail.com>
 <CAGSQugkYf5S80F4p8suW-w6SoXy208GQs3g1_fRqcxA5205dnQ@mail.gmail.com>
Message-ID: <cd09bb60-23ef-b7d7-b80e-dbfd0f51ff01@measurement-factory.com>

On 11/30/22 03:16, Gabriel Vilari?o wrote:

> Log with error code and error detail at the end, both "-":
> 1669794718.051 INTERNAL_IP TCP_TUNNEL/500
> arsenal.us-west-2.amazonaws.com splice /CN=arsenal.us-west-2.amazonaws.com 
> 54.240.254.131 - -
> 
> The cache.log with ALL,1 does not look to share a lot, in fact I don?t 
> see any messages referencing this transaction

Looks good, thank you. All of the above indirectly supports (but does 
not yet prove) my working theory that there is no TLS failure here (that 
Squid is aware of).


> I checked with further log levels but it outputs a lot of data (I know 
> this one is not for admins, I wanted to try to sent only the relevant 
> logs since those aws agents do several calls and I was not to only 
> record one transaction).

Do not worry about the volume of data as long as you do your best to 
reproduce the problem using as few transactions as possible (and 
compress logs before sharing a pointer to them). As you know, there are 
some hints for doing this at 
https://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction

Also, it would be nice if, when sharing the logs, you restate what the 
current reproduced/observed problem is. Thank you.


> Also if I needed, this is shared as an attachment?

Most likely, this mailing list software will not let you share large 
archives. Posting a (temporary) link to them usually works best.


Cheers,

Alex.


> El mar, 29 nov 2022 a las 21:52, Gabriel Vilari?o (<gvilarino6 at gmail.com>) escribi?:
> 
>     Thanks Alex!
> 
>     Here are the fixed logs:
>     |1669726977.734 INTERNAL_CLIENT_IP TCP_TUNNEL/500
>     arsenal.us-west-2.amazonaws.com
>     <http://arsenal.us-west-2.amazonaws.com> splice
>     /CN=arsenal.us-west-2.amazonaws.com
>     <http://arsenal.us-west-2.amazonaws.com> 54.240.251.223|
>     |
>     |
>     |As you can see, the destination is an aws service, more
>     interesting, it effectively *logs the splice* action! That?s why I
>     though it was letting the traffic go trough. Also the debug logs
>     from SSL show this:|
>     ||2022/11/29 10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(273)
>     *startTunneling: will tunnel instead of negotiating TLS* # Last line
>     from previously attached logs||
>     ||
>     ||
>     ||As far as I know this means *is getting to the TCP_TUNNEL, at that
>     point it can not know anything about the internal status on the
>     connection between client and host*. If not, *where I should be
>     looking for this error? *Should try to review further the debug ssl
>     logs to se if I fend something more useful? Maybe tcpdump? This
>     could be just the end service failing on the request? Or is an error
>     between Squid and the end sever?||
>     ||
>     ||
>     ||If I understand right the request that fails is the fake connect
>     and I need to understand why. Also note almost same config logged
>     this as TCP_TUNNEL/200 on version 3.5. But as said before, I really
>     not sure how to check, since that service is just an agent installed
>     on some aws machines and don?t know how to reproduce this behavior.
>     ||
>     |
>     |
>     |
>     |
>     |
>     |
>     |
>     |
>     |Thanks again! Hope I answered fine since I didn?t get the answer email.
>     |
> 
> 
>     El mar, 29 nov 2022 a las 14:06, Gabriel Vilari?o
>     (<gvilarino6 at gmail.com <mailto:gvilarino6 at gmail.com>>) escribi?:
> 
>         Just got it solved. Was caused because of checking default
>         access.log. Using a new file solves all the problems.
> 
>         However, in this context, what means TCP_TUNNEL/500? is it
>         because the TLS handshake? I would like to know if it is
>         tunneling correctly or is having some trouble (not easy to test
>         right now).
> 
>         Thanks!
> 
>         El mar, 29 nov 2022 a las 13:16, Gabriel Vilari?o
>         (<gvilarino6 at gmail.com <mailto:gvilarino6 at gmail.com>>) escribi?:
> 
>             Hi there,
> 
>             I am setting up an HTTP/HTTPS transparent proxy, meaning the
>             clients not need any certificates for using the proxy. This
>             works fine on version 3.5 of Squid, however after upgrading
>             to 5.7 the behavior of the logs change:
> 
>             1669723133.174 ? 8037 10.184.19.220 TCP_TUNNEL/500 6207
>             CONNECT 54.240.253.128:443 <http://54.240.253.128:443> -
>             ORIGINAL_DST/54.240.253.128 <http://54.240.253.128> -
> 
>             Directive: logformat squid %ts.%03tu %>a %Ss/%03>Hs
>             %ssl::>sni %ssl::bump_mode ssl::>cert_subject %<ru
> 
>             On version 3.5 we were obtaining the domain name (an aws
>             service) in the place of ORIGINAL_DST. Also now we are not
>             seeing any information about the bump_mode in no one of the
>             connections while before we were seeing it. One could trough
>             that it could be because of the /500 message, however on a
>             200 one to docs.ansble.com <http://docs.ansble.com> it also
>             don?t show any data on the sni field:
> 
>             1669723513.363 ? ?332 10.184.19.220 TCP_TUNNEL/200 38192
>             CONNECT 104.26.0.234:443 <http://104.26.0.234:443> -
>             ORIGINAL_DST/104.26.0.234 <http://104.26.0.234> -
> 
>             Also the 500 looks to come from the squid not understanding
>             something on the SSL negotiation:
> 
>             |2022/11/29 10:32:38.943 kid1| 83,4| support.cc(248)
>             check_domain: Verifying server domain
>             arsenal.us-west-2.amazonaws.com
>             <http://arsenal.us-west-2.amazonaws.com> to certificate
>             name/subjectAltName arsenal.us-west-2.amazonaws.com
>             <http://arsenal.us-west-2.amazonaws.com> ||2022/11/29
>             10:32:38.943 kid1| 83,5| bio.cc(136) read: FD 28 read 347 <=
>             65535 ||2022/11/29 10:32:38.943 kid1| 83,5| Io.cc(91)
>             Handshake: -1/0 for TLS connection 0x558453168970 over
>             conn99 local=SQUID-INTERNAL-IP:44264
>             remote=54.240.251.223:443 <http://54.240.251.223:443>
>             ORIGINAL_DST FD 28 flags=1 ||2022/11/29 10:32:38.943 kid1|
>             83,2| PeerConnector.cc(256) handleNegotiationResult: ERROR:
>             failure while establishing TLS connection on FD:
>             280x558452b68980*1 ||2022/11/29 10:32:38.943 kid1| 83,5|
>             NegotiationHistory.cc(85) retrieveNegotiatedInfo: SSL
>             connection info on FD 28 SSL version NONE/0.0 negotiated
>             cipher ||2022/11/29 10:32:38.943 kid1| 83,5|
>             PeekingPeerConnector.cc(84) checkForPeekAndSpliceMatched:
>             Will check for peek and splice on FD 28 ||2022/11/29
>             10:32:38.943 kid1| 83,5| PeekingPeerConnector.cc(395)
>             serverCertificateVerified: HTTPS server CN:
>             arsenal.us-west-2.amazonaws.com
>             <http://arsenal.us-west-2.amazonaws.com> bumped: conn99
>             local=SQUID-INTERNAL-IP:44264 remote=54.240.251.223:443
>             <http://54.240.251.223:443> ORIGINAL_DST FD 28 flags=1 |
>             |2022/11/29 10:32:38.943 kid1| 83,5|
>             PeekingPeerConnector.cc(273) startTunneling: will tunnel
>             instead of negotiating TLS|
> 
>             It is clear that in creates the tunnel so the 500 probably
>             is that error? Why the bump/sni messages never log anything
>             (according to
>             https://wiki.squid-cache.org/Features/SslPeekAndSplice
>             <https://wiki.squid-cache.org/Features/SslPeekAndSplice>
>             they should log splice not -). This is the config for bumping:
> 
> 
> 
>             acl step1 at_step SslBump1
>             acl step2 at_step SslBump2
>             acl step3 at_step SslBump3
>             ssl_bump peek step1 all
> 
>             .... http rules ...
> 
>             acl allowed_https_sites ssl::server_name_regex
>             "/etc/squid/whitelist.txt"
>             ssl_bump peek step2 allowed_https_sites
>             ssl_bump splice step3 allowed_https_sites
>             ssl_bump terminate step2 all
> 
> 
> 
> 
>             Ip tables simply redirect:
> 
>             iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT
>             --to-port 3129
>             iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT
>             --to-port 3130 # https port on squid: https_port 3130
>             intercept ssl-bump cert=/etc/squid/ssl/dummy.pem
> 
>             Thanks in advance, i have been trying this for a week now
>             reading a lot of posts but not luck...
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From utbtrialuser at gmail.com  Wed Nov 30 21:57:41 2022
From: utbtrialuser at gmail.com (utb trialuser)
Date: Wed, 30 Nov 2022 16:57:41 -0500
Subject: [squid-users] Squid Degrading
Message-ID: <CAFuFF_K9SOttfwtfgAjQhfZ-Jz_31=cVuY-TXM5FnMboQ7ij2w@mail.gmail.com>

Hello, I'm running a basic Squid setup on the latest version of Ubuntu.
Could you help me figure out why when 15 people connect to my proxy it
starts degrading and websites start to take really long to load? According
to the log file, connections take up to 300000ms to load when this happens.
And via other networking tools I was able to realize that packets were
being dropped. Bandwidth usage tops at 6MB/s according to another
networking tool. Thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20221130/9496a300/attachment.htm>

From ngtech1ltd at gmail.com  Wed Nov 30 23:07:22 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Thu, 1 Dec 2022 01:07:22 +0200
Subject: [squid-users] transparent mode squid on centos 9 with iptables
 (part 2)
In-Reply-To: <CAKM+x_JwQt+4jwVsfzgdj-x-DoWC77TqYROS44+cux0asdAADw@mail.gmail.com>
References: <CAKM+x_L67p0YjP3BPwSU=cp8PrQcG-CVH7jzmT80AB=ym3u4Vw@mail.gmail.com>
 <CAKM+x_JRkR2vNgT_zqcQAd3qXTwQMXDa8mJeEY+R6FYXDiFB0g@mail.gmail.com>
 <CAKM+x_K5XA0oTvEsGkzwHuYbVVYXe+1UegWCW2b37_pATX7mDQ@mail.gmail.com>
 <CAKM+x_JwQt+4jwVsfzgdj-x-DoWC77TqYROS44+cux0asdAADw@mail.gmail.com>
Message-ID: <001701d90510$82126700$86373500$@gmail.com>

Hey Lola,

I have created a demo video at:
https://cloud1.ngtech.co.il/static/squid-data/CentOS%209%20-%20Intercept%20Demo.mp4

This gives a demo on how to configure squid in intercept (transparent)  mode for both port 80 HTTP and port 443 HTTPS.
It?s not in a tutorial, it?s a demo.

The client is a Windows Server 2022 and the proxy server is a CentOS 9 with the default Squid 5.5 package.
it?s recommended by the Squid-Cache project to use the latest stable but from my tests the latest 5 cannot be compiled on CentOS 9
and all other RHEL 9 based distributions.
Pay attention for the OpenSSL version that is being used  on CentOS 9 and others.

For now I do recommend to use the RHEL / Oracle 8 and not CentOS 9 Stream.
If you do feel comfortable with CentOS 8 Stream then use that instead of CentOS 9 Stream for now.


# CentOS 9 squid 5.5 complication flags
# squid -v
Squid Cache: Version 5.5
Service Name: squid

This binary uses OpenSSL 3.0.1 14 Dec 2021. For legal restrictions on distribution see https://www.openssl.org/source/license.html

configure options:  '--build=x86_64-redhat-linux-gnu' '--host=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' '--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include' '--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--localstatedir=/var' '--sharedstatedir=/var/lib' '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--libexecdir=/usr/lib64/squid' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--with-logdir=/var/log/squid' '--with-pidfile=/run/squid.pid' '--disable-dependency-tracking' '--enable-eui' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,PAM,POP3,RADIUS,SASL,SMB,SMB_LM' '--enable-auth-ntlm=SMB_LM,fake' '--enable-auth-digest=file,LDAP' '--enable-auth-negotiate=kerberos' '--enable-external-acl-helpers=LDAP_group,time_quota,session,unix_group,wbinfo_group,kerberos_ldap_group' '--enable-storeid-rewrite-helpers=file' '--enable-cache-digests' '--enable-cachemgr-hostname=localhost' '--enable-delay-pools' '--enable-epoll' '--enable-icap-client' '--enable-ident-lookups' '--enable-linux-netfilter' '--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-ssl' '--enable-ssl-crtd' '--enable-storeio=aufs,diskd,ufs,rock' '--enable-diskio' '--enable-wccpv2' '--enable-esi' '--enable-ecap' '--with-aio' '--with-default-user=squid' '--with-dl' '--with-openssl' '--with-pthreads' '--disable-arch-native' '--disable-security-cert-validators' '--disable-strict-error-checking' '--with-swapdir=/var/spool/squid' 'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu' 'CC=gcc' 'CFLAGS=-O2 -flto=auto -ffat-lto-objects -fexceptions -g -grecord-gcc-switches -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -fstack-protector-strong -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1  -m64 -march=x86-64-v2 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection' 'LDFLAGS=-Wl,-z,relro -Wl,--as-needed  -Wl,-z,now -specs=/usr/lib/rpm/redhat/redhat-hardened-ld -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 ' 'CXX=g++' 'CXXFLAGS=-O2 -flto=auto -ffat-lto-objects -fexceptions -g -grecord-gcc-switches -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -fstack-protector-strong -specs=/usr/lib/rpm/redhat/redhat-annobin-cc1  -m64 -march=x86-64-v2 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection' 'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig' 'LT_SYS_LIBRARY_PATH=/usr/lib64:'


All The Bests,
Eliezer

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: mailto:ngtech1ltd at gmail.com
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Lola Lo
Sent: Wednesday, 16 November 2022 22:15
To: squid-users at lists.squid-cache.org
Subject: [squid-users] transparent mode squid on centos 9 with iptables (part 2)

Hi guys.

Could you please send a tutorial or any good guidance to implement  squid on transparent mode on centos 9 with iptables.  
I have configured squid.conf with this parameters:


ens192: 172.31.168.28, internet interface
ens224: 192.168.1.10, LAN interface (private network)

# Mis ACLs #
acl mi_red src http://192.168.1.0/24
acl cliente_linux src 192.168.1.20
acl cliente_windows src 192.168.1.30
acl sitios1 url_regex "/etc/squid/listas/sitios1"
acl sitios2 url_regex "/etc/squid/listas/sitios2"

# Squid normally listens to port 3128
http_port 3128
http_port 8080 transparent

I want the ?deny all? rule get applied to test the client using the proxy

My iptables is configured as follows:

#!/bin/bash

## NAT server configuration ##

sysctl -w net.ipv4.ip_forward=1
sysctl -p
iptables -X
iptables -F
iptables -t nat -X
iptables -t nat -F
iptables -I INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
iptables -I FORWARD  -m state --state RELATED,ESTABLISHED -j ACCEPT
iptables -t nat -I POSTROUTING -o ens192 -j MASQUERADE



#!/bin/bash

## proxy server configuration ##

### Accepting traffic for the ports: 3128 and 8080##

iptables -A INPUT -s http://192.168.1.0/24 -p tcp --dport 3128 -j ACCEPT
iptables -A INPUT -p tcp --dport 3128 -j DROP
iptables -A OUTPUT -d http://192.168.1.0/24 -p tcp --sport 3128 -j ACCEPT
iptables -A OUTPUT -p tcp --sport 3128 -j DROP

iptables -A INPUT -s http://192.168.1.0/24 -p tcp --dport 8080 -j ACCEPT
iptables -A INPUT -p tcp --dport 8080 -j DROP
iptables -A OUTPUT -d http://192.168.1.0/24 -p tcp --sport 8080 -j ACCEPT
iptables -A OUTPUT -p tcp --sport 8080 -j DROP


### Accepting traffic for the ports: 3128 and 8080##

iptables -t nat -A POSTROUTING -o ens192 -j MASQUERADE
iptables -t nat -A PREROUTING -s http://192.168.1.0/24 -p tcp --dport 80 -j REDIRECT --to-port 8080
iptables -t nat -A PREROUTING -s http://192.168.1.0/24 -p tcp --dport 443 -j REDIRECT --to-port 8080



But I got this error:

1668381894.746      0 192.168.1.20 NONE_NONE/000 0 - error:transaction-end-before-headers - HIER_NONE/- -
1668381967.800      0 192.168.1.20 NONE_NONE/400 3690 - error:invalid-request - HIER_NONE/- text/html
1668381967.805      0 192.168.1.20 NONE_NONE/400 3690 - error:invalid-request - HIER_NONE/- text/html
1668381967.809      0 192.168.1.20 NONE_NONE/400 3690 - error:invalid-request - HIER_NONE/- text/html
1668381967.814      0 192.168.1.20 NONE_NONE/400 3690 - error:invalid-request - HIER_NONE/- text/html
1668381967.818      0 192.168.1.20 NONE_NONE/400 3690 - error:invalid-request - HIER_NONE/- text/html
1668381967.823      0 192.168.1.20 NONE_NONE/400 3690 - error:invalid-request - HIER_NONE/- text/html
1668381967.827      0 192.168.1.20 NONE_NONE/400 3690 - error:invalid-request - HIER_NONE/- text/html
1668381967.832      0 192.168.1.20 NONE_NONE/400 3690 - error:invalid-request - HIER_NONE/- text/html
1668381967.836      0 192.168.1.20 NONE_NONE/400 3690 - error:invalid-request - HIER_NONE/- text/html
1668381967.841      0 192.168.1.20 NONE_NONE/400 3690 - error:invalid-request - HIER_NONE/- text/html

Could you please help me to solve this; i am completely new using squid and in Linux?

I was following these sources:

? https://www.xmodulo.com/squid-transparent-web-proxy-centos-rhel.html 
? https://www.maravento.com/2015/06/no-forward-proxy-ports-configured.html 
? https://www.xmodulo.com/internet-connection-sharing-iptables-linux.html 

You can find the logs of squid 5.5 here: https://epnecuador-my.sharepoint.com/:u:/g/personal/mercy_anchundia_epn_edu_ec/EaqrQJFkDfhLnEha14CIfKoBhrKZLaSTIE51t_gw0_iUZw?e=Y8xirv
I configured the linux client with the ip http://192.168.1.20/24, gateway is the linux server: 192.168.1.10 and DNS: 192.168.1.10 and others of my ISP.

....



From rousskov at measurement-factory.com  Wed Nov 30 23:12:04 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 30 Nov 2022 18:12:04 -0500
Subject: [squid-users] Squid Degrading
In-Reply-To: <CAFuFF_K9SOttfwtfgAjQhfZ-Jz_31=cVuY-TXM5FnMboQ7ij2w@mail.gmail.com>
References: <CAFuFF_K9SOttfwtfgAjQhfZ-Jz_31=cVuY-TXM5FnMboQ7ij2w@mail.gmail.com>
Message-ID: <3ffc1451-7515-da0a-ac7f-be5463018279@measurement-factory.com>

On 11/30/22 16:57, utb trialuser wrote:
> Hello, I'm running a basic Squid setup on the latest version of Ubuntu. 
> Could you help?me figure out why when 15 people connect to my proxy it 
> starts degrading and websites start to take really long to load? 
> According to the log file, connections take up to 300000ms to load when 
> this happens. And via other networking tools I was able to realize?that 
> packets were being dropped. Bandwidth usage tops at 6MB/s according to 
> another networking tool. Thanks.

What is your Squid version (squid --version)?

Any errors or warnings in cache.log?

Do you have a cache_dir and/or cache_mem configured in squid.conf? Do 
you have "workers" configured?

How much free RAM is left on the box when "websites start to take really 
long to load"?

Alex.



