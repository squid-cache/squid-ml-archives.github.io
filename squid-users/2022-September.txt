From mca2rahulbit at gmail.com  Sat Sep  3 09:41:08 2022
From: mca2rahulbit at gmail.com (rahul gupta)
Date: Sat, 3 Sep 2022 17:41:08 +0800
Subject: [squid-users] Squid container stopped with exit 1 recursively
In-Reply-To: <mailman.1.1658836801.2754623.squid-users@lists.squid-cache.org>
References: <mailman.1.1658836801.2754623.squid-users@lists.squid-cache.org>
Message-ID: <CAA50s+AK85rJ4VsJPbOx7Jn-NARpERuADH=vsyopB5NVQ934JQ@mail.gmail.com>

Hi Team,
I?m running squid in container and running in aws ECS.

It?s working fine but in every few hours container got stopped with exit 1.
I see cpu and memory usage for container are not too high.

Any pointers .? What May be the potential cause.?or the start point for
troubleshooting.?

Regards
Rahul

-- 
Sent from iPhone
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220903/6795e53e/attachment.htm>

From gkinkie at gmail.com  Sat Sep  3 11:39:55 2022
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Sat, 3 Sep 2022 13:39:55 +0200
Subject: [squid-users] Squid container stopped with exit 1 recursively
In-Reply-To: <CAA50s+AK85rJ4VsJPbOx7Jn-NARpERuADH=vsyopB5NVQ934JQ@mail.gmail.com>
References: <mailman.1.1658836801.2754623.squid-users@lists.squid-cache.org>
 <CAA50s+AK85rJ4VsJPbOx7Jn-NARpERuADH=vsyopB5NVQ934JQ@mail.gmail.com>
Message-ID: <CA+Y8hcM8JdtjnFGhmwA5eULX1UH6LcAvj8j9oD3DfMA-T3-6yA@mail.gmail.com>

Hi,
  Anything in the logs?
What version of squid are you using?

On Sat, 3 Sep 2022 at 11:41, rahul gupta <mca2rahulbit at gmail.com> wrote:

> Hi Team,
> I?m running squid in container and running in aws ECS.
>
> It?s working fine but in every few hours container got stopped with exit
> 1. I see cpu and memory usage for container are not too high.
>
> Any pointers .? What May be the potential cause.?or the start point for
> troubleshooting.?
>
> Regards
> Rahul
>
> --
> Sent from iPhone
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-- 
@mobile
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220903/3737f9b9/attachment.htm>

From mca2rahulbit at gmail.com  Sat Sep  3 11:42:58 2022
From: mca2rahulbit at gmail.com (rahul gupta)
Date: Sat, 3 Sep 2022 19:42:58 +0800
Subject: [squid-users] Squid container stopped with exit 1 recursively
In-Reply-To: <CA+Y8hcM8JdtjnFGhmwA5eULX1UH6LcAvj8j9oD3DfMA-T3-6yA@mail.gmail.com>
References: <mailman.1.1658836801.2754623.squid-users@lists.squid-cache.org>
 <CAA50s+AK85rJ4VsJPbOx7Jn-NARpERuADH=vsyopB5NVQ934JQ@mail.gmail.com>
 <CA+Y8hcM8JdtjnFGhmwA5eULX1UH6LcAvj8j9oD3DfMA-T3-6yA@mail.gmail.com>
Message-ID: <CAA50s+D_5Qmy2Wjjc+Bxez0jSEsDEWiATRC2ybL6PzPd4b77xQ@mail.gmail.com>

Thanks Francesco for offering help, in error logs its 104 and message is
?terminated abnormally?.

Squid version is 5.0.4.

Regards
Rahul



On Sat, 3 Sep 2022 at 7:40 PM, Francesco Chemolli <gkinkie at gmail.com> wrote:

> Hi,
>   Anything in the logs?
> What version of squid are you using?
>
> On Sat, 3 Sep 2022 at 11:41, rahul gupta <mca2rahulbit at gmail.com> wrote:
>
>> Hi Team,
>> I?m running squid in container and running in aws ECS.
>>
>> It?s working fine but in every few hours container got stopped with exit
>> 1. I see cpu and memory usage for container are not too high.
>>
>> Any pointers .? What May be the potential cause.?or the start point for
>> troubleshooting.?
>>
>> Regards
>> Rahul
>>
>> --
>> Sent from iPhone
>>
> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>> --
> @mobile
>
-- 
Sent from iPhone
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220903/890f841e/attachment.htm>

From ngtech1ltd at gmail.com  Sun Sep  4 12:27:45 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Sun, 4 Sep 2022 15:27:45 +0300
Subject: [squid-users] Squid container stopped with exit 1 recursively
In-Reply-To: <CAA50s+D_5Qmy2Wjjc+Bxez0jSEsDEWiATRC2ybL6PzPd4b77xQ@mail.gmail.com>
References: <mailman.1.1658836801.2754623.squid-users@lists.squid-cache.org>
 <CAA50s+AK85rJ4VsJPbOx7Jn-NARpERuADH=vsyopB5NVQ934JQ@mail.gmail.com>
 <CA+Y8hcM8JdtjnFGhmwA5eULX1UH6LcAvj8j9oD3DfMA-T3-6yA@mail.gmail.com>
 <CAA50s+D_5Qmy2Wjjc+Bxez0jSEsDEWiATRC2ybL6PzPd4b77xQ@mail.gmail.com>
Message-ID: <002401d8c059$bd518bd0$37f4a370$@gmail.com>

Hey Rahul,
 
You should use the latest squid stable version 5.6.
Depends on the container you are running but you might be able to use the latest RPMs of:
CentOS, Oracle, Fedora, Alma, Rocky, AMZN
 
>From my repository at:
https://www.ngtech.co.il/repo/
 
To know the error with squid you will need more then ?terminated abnormally?
You will need access to the cache.log and as much details as possible.
 
Eliezer
 
----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/
 
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of rahul gupta
Sent: Saturday, 3 September 2022 14:43
To: Francesco Chemolli <gkinkie at gmail.com>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid container stopped with exit 1 recursively
 
Thanks Francesco for offering help, in error logs its 104 and message is ?terminated abnormally?.
 
Squid version is 5.0.4.
 
Regards 
Rahul 
 
 
 
On Sat, 3 Sep 2022 at 7:40 PM, Francesco Chemolli <gkinkie at gmail.com <mailto:gkinkie at gmail.com> > wrote:
Hi,
  Anything in the logs?
What version of squid are you using?
 
On Sat, 3 Sep 2022 at 11:41, rahul gupta <mca2rahulbit at gmail.com <mailto:mca2rahulbit at gmail.com> > wrote:
Hi Team,
I?m running squid in container and running in aws ECS.
 
It?s working fine but in every few hours container got stopped with exit 1. I see cpu and memory usage for container are not too high.
 
Any pointers .? What May be the potential cause.?or the start point for troubleshooting.?
 
Regards
Rahul
 
-- 
Sent from iPhone
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users
 
-- 
@mobile
-- 
Sent from iPhone
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220904/4b0260be/attachment.htm>

From mca2rahulbit at gmail.com  Mon Sep  5 05:55:22 2022
From: mca2rahulbit at gmail.com (rahul gupta)
Date: Mon, 5 Sep 2022 13:55:22 +0800
Subject: [squid-users] squid-users Digest, Vol 97, Issue 2
In-Reply-To: <mailman.1434.1662294467.1112.squid-users@lists.squid-cache.org>
References: <mailman.1434.1662294467.1112.squid-users@lists.squid-cache.org>
Message-ID: <CAA50s+Db3NhEEZ7a5sk5=UtHUkfV7Y6rWoUhaMFdY4iOsiGQBg@mail.gmail.com>

Hi  Eliezer,
As it's in ECS-serverless, hence can't log in into the VM to debug more.

Currently debug level set is:
debug_options: ALL,9
which says terminated abnormally.

Current cpu usage is 2 CPU, memory 4 GB.

i see at startup it shows

Target number of buckets:1008
Using 8192 Stroe buckets
Max Mem size: 262144 KB
Max Swap size: 0 KB

any inputs?

thanks.
Rahul


On Sun, Sep 4, 2022 at 8:27 PM <squid-users-request at lists.squid-cache.org>
wrote:

> Send squid-users mailing list submissions to
>         squid-users at lists.squid-cache.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         http://lists.squid-cache.org/listinfo/squid-users
> or, via email, send a message with subject or body 'help' to
>         squid-users-request at lists.squid-cache.org
>
> You can reach the person managing the list at
>         squid-users-owner at lists.squid-cache.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
>
>
> Today's Topics:
>
>    1. Re: Squid container stopped with exit 1 recursively
>       (ngtech1ltd at gmail.com)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sun, 4 Sep 2022 15:27:45 +0300
> From: <ngtech1ltd at gmail.com>
> To: <squid-users at lists.squid-cache.org>
> Subject: Re: [squid-users] Squid container stopped with exit 1
>         recursively
> Message-ID: <002401d8c059$bd518bd0$37f4a370$@gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Hey Rahul,
>
> You should use the latest squid stable version 5.6.
> Depends on the container you are running but you might be able to use the
> latest RPMs of:
> CentOS, Oracle, Fedora, Alma, Rocky, AMZN
>
> >From my repository at:
> https://www.ngtech.co.il/repo/
>
> To know the error with squid you will need more then ?terminated
> abnormally?
> You will need access to the cache.log and as much details as possible.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> NgTech, Tech Support
> Mobile: +972-5-28704261
> Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com>
> Web: https://ngtech.co.il/
> My-Tube: https://tube.ngtech.co.il/
>
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf
> Of rahul gupta
> Sent: Saturday, 3 September 2022 14:43
> To: Francesco Chemolli <gkinkie at gmail.com>
> Cc: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid container stopped with exit 1 recursively
>
> Thanks Francesco for offering help, in error logs its 104 and message is
> ?terminated abnormally?.
>
> Squid version is 5.0.4.
>
> Regards
> Rahul
>
>
>
> On Sat, 3 Sep 2022 at 7:40 PM, Francesco Chemolli <gkinkie at gmail.com
> <mailto:gkinkie at gmail.com> > wrote:
> Hi,
>   Anything in the logs?
> What version of squid are you using?
>
> On Sat, 3 Sep 2022 at 11:41, rahul gupta <mca2rahulbit at gmail.com <mailto:
> mca2rahulbit at gmail.com> > wrote:
> Hi Team,
> I?m running squid in container and running in aws ECS.
>
> It?s working fine but in every few hours container got stopped with exit
> 1. I see cpu and memory usage for container are not too high.
>
> Any pointers .? What May be the potential cause.?or the start point for
> troubleshooting.?
>
> Regards
> Rahul
>
> --
> Sent from iPhone
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org <mailto:
> squid-users at lists.squid-cache.org>
> http://lists.squid-cache.org/listinfo/squid-users
>
> --
> @mobile
> --
> Sent from iPhone
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <
> http://lists.squid-cache.org/pipermail/squid-users/attachments/20220904/4b0260be/attachment.htm
> >
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
>
> End of squid-users Digest, Vol 97, Issue 2
> ******************************************
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220905/27765e48/attachment.htm>

From ngtech1ltd at gmail.com  Mon Sep  5 08:16:00 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Mon, 5 Sep 2022 11:16:00 +0300
Subject: [squid-users] squid-users Digest, Vol 97, Issue 2
In-Reply-To: <CAA50s+Db3NhEEZ7a5sk5=UtHUkfV7Y6rWoUhaMFdY4iOsiGQBg@mail.gmail.com>
References: <mailman.1434.1662294467.1112.squid-users@lists.squid-cache.org>
 <CAA50s+Db3NhEEZ7a5sk5=UtHUkfV7Y6rWoUhaMFdY4iOsiGQBg@mail.gmail.com>
Message-ID: <000501d8c0ff$bc6bbb40$354331c0$@gmail.com>

Hey Rahul,
 
You can create a customized container like described in the official document at:
https://docs.aws.amazon.com/AmazonECS/latest/userguide/create-container-image.html
 
It?s pretty simple and is doable.
You shouldn?t run Squid 5.0.4 since it?s very old and there for would not get support?
 
I am probably not ?The Master Of Containers? but I know it?s doable.
You can use either Alpine linux or another RPM based OS and use my RPMs.
 
If you have the  Dockerfile or spec of the container so I can see what can be done, send it to me.
 
Eliezer
 
----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/
 
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of rahul gupta
Sent: Monday, 5 September 2022 8:55
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid-users Digest, Vol 97, Issue 2
 
Hi  Eliezer,
As it's in ECS-serverless, hence can't log in into the VM to debug more.
 
Currently debug level set is:  
debug_options: ALL,9
which says terminated abnormally.
 
Current cpu usage is 2 CPU, memory 4 GB. 
 
i see at startup it shows 
 
Target number of buckets:1008
Using 8192 Stroe buckets
Max Mem size: 262144 KB
Max Swap size: 0 KB
 
any inputs?
 
thanks.
Rahul
 
 
On Sun, Sep 4, 2022 at 8:27 PM <squid-users-request at lists.squid-cache.org <mailto:squid-users-request at lists.squid-cache.org> > wrote:
Send squid-users mailing list submissions to
        squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 

To subscribe or unsubscribe via the World Wide Web, visit
        http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
        squid-users-request at lists.squid-cache.org <mailto:squid-users-request at lists.squid-cache.org> 

You can reach the person managing the list at
        squid-users-owner at lists.squid-cache.org <mailto:squid-users-owner at lists.squid-cache.org> 

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. Re: Squid container stopped with exit 1 recursively
      (ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> )


----------------------------------------------------------------------

Message: 1
Date: Sun, 4 Sep 2022 15:27:45 +0300
From: <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >
To: <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: Re: [squid-users] Squid container stopped with exit 1
        recursively
Message-ID: <002401d8c059$bd518bd0$37f4a370$@gmail.com <http://gmail.com> >
Content-Type: text/plain; charset="utf-8"

Hey Rahul,

You should use the latest squid stable version 5.6.
Depends on the container you are running but you might be able to use the latest RPMs of:
CentOS, Oracle, Fedora, Alma, Rocky, AMZN

>From my repository at:
https://www.ngtech.co.il/repo/

To know the error with squid you will need more then ?terminated abnormally?
You will need access to the cache.log and as much details as possible.

Eliezer

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com>  <mailto:ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/

From: squid-users <squid-users-bounces at lists.squid-cache.org <mailto:squid-users-bounces at lists.squid-cache.org> > On Behalf Of rahul gupta
Sent: Saturday, 3 September 2022 14:43
To: Francesco Chemolli <gkinkie at gmail.com <mailto:gkinkie at gmail.com> >
Cc: squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Subject: Re: [squid-users] Squid container stopped with exit 1 recursively

Thanks Francesco for offering help, in error logs its 104 and message is ?terminated abnormally?.

Squid version is 5.0.4.

Regards 
Rahul 



On Sat, 3 Sep 2022 at 7:40 PM, Francesco Chemolli <gkinkie at gmail.com <mailto:gkinkie at gmail.com>  <mailto:gkinkie at gmail.com <mailto:gkinkie at gmail.com> > > wrote:
Hi,
  Anything in the logs?
What version of squid are you using?

On Sat, 3 Sep 2022 at 11:41, rahul gupta <mca2rahulbit at gmail.com <mailto:mca2rahulbit at gmail.com>  <mailto:mca2rahulbit at gmail.com <mailto:mca2rahulbit at gmail.com> > > wrote:
Hi Team,
I?m running squid in container and running in aws ECS.

It?s working fine but in every few hours container got stopped with exit 1. I see cpu and memory usage for container are not too high.

Any pointers .? What May be the potential cause.?or the start point for troubleshooting.?

Regards
Rahul

-- 
Sent from iPhone
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>  <mailto:squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> > 
http://lists.squid-cache.org/listinfo/squid-users

-- 
@mobile
-- 
Sent from iPhone
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220904/4b0260be/attachment.htm>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 97, Issue 2
******************************************
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220905/69d4eb08/attachment.htm>

From ngtech1ltd at gmail.com  Mon Sep  5 09:22:54 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Mon, 5 Sep 2022 12:22:54 +0300
Subject: [squid-users] squid-users Digest, Vol 97, Issue 2
In-Reply-To: <CAA50s+Db3NhEEZ7a5sk5=UtHUkfV7Y6rWoUhaMFdY4iOsiGQBg@mail.gmail.com>
References: <mailman.1434.1662294467.1112.squid-users@lists.squid-cache.org>
 <CAA50s+Db3NhEEZ7a5sk5=UtHUkfV7Y6rWoUhaMFdY4iOsiGQBg@mail.gmail.com>
Message-ID: <000a01d8c109$156a15d0$403e4170$@gmail.com>

I have a container specification at:
https://github.com/elico/squid-container
 
if it?s helping you and others.
It?s a simple forward proxy with RAM cache only.
If you want to use CentOS stream 8 you can modify the Dockerfile a bit and it should work in a similar way.
 
Eliezer
 
----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/
 
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of rahul gupta
Sent: Monday, 5 September 2022 8:55
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid-users Digest, Vol 97, Issue 2
 
Hi  Eliezer,
As it's in ECS-serverless, hence can't log in into the VM to debug more.
 
Currently debug level set is:  
debug_options: ALL,9
which says terminated abnormally.
 
Current cpu usage is 2 CPU, memory 4 GB. 
 
i see at startup it shows 
 
Target number of buckets:1008
Using 8192 Stroe buckets
Max Mem size: 262144 KB
Max Swap size: 0 KB
 
any inputs?
 
thanks.
Rahul
 
 
On Sun, Sep 4, 2022 at 8:27 PM <squid-users-request at lists.squid-cache.org <mailto:squid-users-request at lists.squid-cache.org> > wrote:
Send squid-users mailing list submissions to
        squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 

To subscribe or unsubscribe via the World Wide Web, visit
        http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
        squid-users-request at lists.squid-cache.org <mailto:squid-users-request at lists.squid-cache.org> 

You can reach the person managing the list at
        squid-users-owner at lists.squid-cache.org <mailto:squid-users-owner at lists.squid-cache.org> 

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. Re: Squid container stopped with exit 1 recursively
      (ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> )


----------------------------------------------------------------------

Message: 1
Date: Sun, 4 Sep 2022 15:27:45 +0300
From: <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >
To: <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: Re: [squid-users] Squid container stopped with exit 1
        recursively
Message-ID: <002401d8c059$bd518bd0$37f4a370$@gmail.com <http://gmail.com> >
Content-Type: text/plain; charset="utf-8"

Hey Rahul,

You should use the latest squid stable version 5.6.
Depends on the container you are running but you might be able to use the latest RPMs of:
CentOS, Oracle, Fedora, Alma, Rocky, AMZN

>From my repository at:
https://www.ngtech.co.il/repo/

To know the error with squid you will need more then ?terminated abnormally?
You will need access to the cache.log and as much details as possible.

Eliezer

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com>  <mailto:ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/

From: squid-users <squid-users-bounces at lists.squid-cache.org <mailto:squid-users-bounces at lists.squid-cache.org> > On Behalf Of rahul gupta
Sent: Saturday, 3 September 2022 14:43
To: Francesco Chemolli <gkinkie at gmail.com <mailto:gkinkie at gmail.com> >
Cc: squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Subject: Re: [squid-users] Squid container stopped with exit 1 recursively

Thanks Francesco for offering help, in error logs its 104 and message is ?terminated abnormally?.

Squid version is 5.0.4.

Regards 
Rahul 



On Sat, 3 Sep 2022 at 7:40 PM, Francesco Chemolli <gkinkie at gmail.com <mailto:gkinkie at gmail.com>  <mailto:gkinkie at gmail.com <mailto:gkinkie at gmail.com> > > wrote:
Hi,
  Anything in the logs?
What version of squid are you using?

On Sat, 3 Sep 2022 at 11:41, rahul gupta <mca2rahulbit at gmail.com <mailto:mca2rahulbit at gmail.com>  <mailto:mca2rahulbit at gmail.com <mailto:mca2rahulbit at gmail.com> > > wrote:
Hi Team,
I?m running squid in container and running in aws ECS.

It?s working fine but in every few hours container got stopped with exit 1. I see cpu and memory usage for container are not too high.

Any pointers .? What May be the potential cause.?or the start point for troubleshooting.?

Regards
Rahul

-- 
Sent from iPhone
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>  <mailto:squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> > 
http://lists.squid-cache.org/listinfo/squid-users

-- 
@mobile
-- 
Sent from iPhone
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220904/4b0260be/attachment.htm>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 97, Issue 2
******************************************
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220905/e838d67e/attachment.htm>

From eric.perrot at interieur.gouv.fr  Mon Sep  5 12:56:29 2022
From: eric.perrot at interieur.gouv.fr (PERROT Eric DNUM SDCAST BST SSAIM)
Date: Mon, 05 Sep 2022 14:56:29 +0200
Subject: [squid-users] [squid][v5.6] : problem with "slow" or "fast" acl
In-Reply-To: <6315EC88.6050505@interieur.gouv.fr>
References: <6315EC88.6050505@interieur.gouv.fr>
Message-ID: <6315F1FD.5010501@interieur.gouv.fr>

Hello,

We use directives "reply_body_max_size", "request_body_max_size" and 
"delay_access" to limit upload, download and passband in our infra.

This configuration existes since a while, but we have noticed that with 
squid v4.16, our delay pool didn't react as we wanted anymore. We were 
excpeting improvment upgrading squid to v5.6. But it got worth :
- restriction still didn't work
- and squid had a segmentation fault each time some acl where used

Thanks to Alex Rousskov (bug 5231), after some investigation, it appears 
that we used "slow" acl (proxy_auth an time acl) where only "fast" acl 
where authorized...). The bug is still open as squid has not flagged the 
problem in cache logs,

My email, is to show you our configuration and the behaviour we espect, 
and the behaviour we finally have.
1 - squd v4.12 : we expect to limit downlod/upload and passband during 
working time for all login except those starting with cg_*
"
|###### Gestion de bande passante ##########
acl bureau time 09:00-12:00
acl bureau time 14:00-17:00
# Comptes generiques
|||acl my_ldap_auth proxy_auth REQUIRED
|acl cgen proxy_auth_regex cg_
reply_body_max_size 800 MB *bureau !cgen*
request_body_max_size 5 MB
# La limite de bande passante ne fonctionne plus avec le BUMP
# A tester ...
delay_pools 1
# Pendant time sauf cgen, emeraude
delay_class 1 4
delay_access 1 allow**||*||my_ldap_auth !cgen||***!emeraude
delay_access 1 deny all
# 512000 = 5120 kbits/user 640 ko
# 307200 = 3072 kbits/user 384 ko
delay_parameters 1 -1/-1 -1/-1 -1/-1 107200/107200
##################################################|
"
=> with this configuration, the delay pool seemed not to work anymore, 
so we upgraded squid to v5.6. Which caused the squid segmentation fault...

2 - squid v5.6 : to solve the segmentation fault, we had to take off 
my_ldap_auth/cgen (proxy_auth acl) and bureau (time acl). The limitation 
work again, but we are no more able to limit restriction during working 
time, or for sp?cific login...
"
|###### Gestion de bande passante ##########
acl bureau time 09:00-12:00
acl bureau time 14:00-17:00
# Comptes generiques
acl userrgt src 10.0.0.0/8
|||acl my_ldap_auth proxy_auth REQUIRED
|acl cgen proxy_auth_regex cg_
reply_body_max_size 800 MB *userrgt*
request_body_max_size 5 MB
# La limite de bande passante ne fonctionne plus avec le BUMP
# A tester ...
delay_pools 1
# Pendant time sauf cgen, emeraude
delay_class 1 4
delay_access 1 allow||*||||***!emeraude
delay_access 1 deny all
# 512000 = 5120 kbits/user 640 ko
# 307200 = 3072 kbits/user 384 ko
delay_parameters 1 -1/-1 -1/-1 -1/-1 107200/107200
##################################################|
"

Can you tell me if what we want to do is still possible? Limiting 
upload/download/passband for all logged user except those starting by 
cg_*..?.

Thank you for the time reading, and thank you for your answers.

Regards,

Eric Perrot




Pour une administration exemplaire, pr?servons l'environnement.
N'imprimons que si n?cessaire.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220905/d5c31230/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature-perroter.png
Type: image/png
Size: 10699 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220905/d5c31230/attachment.png>

From mca2rahulbit at gmail.com  Mon Sep  5 23:49:20 2022
From: mca2rahulbit at gmail.com (rahul gupta)
Date: Tue, 6 Sep 2022 07:49:20 +0800
Subject: [squid-users] squid-users Digest, Vol 97, Issue 4
In-Reply-To: <mailman.1458.1662369774.1112.squid-users@lists.squid-cache.org>
References: <mailman.1458.1662369774.1112.squid-users@lists.squid-cache.org>
Message-ID: <CAA50s+CrGCNaym=quE8F6HidnCcox7y3=Qp=KeTeppyktLGEgQ@mail.gmail.com>

Hi ,

I have debug options set to 9, assuming it?s increasing cache.log so fast.
That might be crashing the container.

I?ve set debug level 0 and found from last 13 hours container is running.
Earlier it got restarted in every 4 hours.

Monitoring for week, should be ok.

Thanks everyone for pointers. Cheers.


Regards
Rahul

On Mon, 5 Sep 2022 at 5:23 PM, <squid-users-request at lists.squid-cache.org>
wrote:

> Send squid-users mailing list submissions to
>         squid-users at lists.squid-cache.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         http://lists.squid-cache.org/listinfo/squid-users
> or, via email, send a message with subject or body 'help' to
>         squid-users-request at lists.squid-cache.org
>
> You can reach the person managing the list at
>         squid-users-owner at lists.squid-cache.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
>
>
> Today's Topics:
>
>    1. Re: squid-users Digest, Vol 97, Issue 2 (ngtech1ltd at gmail.com)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Mon, 5 Sep 2022 12:22:54 +0300
> From: <ngtech1ltd at gmail.com>
> To: <squid-users at lists.squid-cache.org>
> Subject: Re: [squid-users] squid-users Digest, Vol 97, Issue 2
> Message-ID: <000a01d8c109$156a15d0$403e4170$@gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> I have a container specification at:
> https://github.com/elico/squid-container
>
> if it?s helping you and others.
> It?s a simple forward proxy with RAM cache only.
> If you want to use CentOS stream 8 you can modify the Dockerfile a bit and
> it should work in a similar way.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> NgTech, Tech Support
> Mobile: +972-5-28704261
> Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com>
> Web: https://ngtech.co.il/
> My-Tube: https://tube.ngtech.co.il/
>
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf
> Of rahul gupta
> Sent: Monday, 5 September 2022 8:55
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] squid-users Digest, Vol 97, Issue 2
>
> Hi  Eliezer,
> As it's in ECS-serverless, hence can't log in into the VM to debug more.
>
> Currently debug level set is:
> debug_options: ALL,9
> which says terminated abnormally.
>
> Current cpu usage is 2 CPU, memory 4 GB.
>
> i see at startup it shows
>
> Target number of buckets:1008
> Using 8192 Stroe buckets
> Max Mem size: 262144 KB
> Max Swap size: 0 KB
>
> any inputs?
>
> thanks.
> Rahul
>
>
> On Sun, Sep 4, 2022 at 8:27 PM <squid-users-request at lists.squid-cache.org
> <mailto:squid-users-request at lists.squid-cache.org> > wrote:
> Send squid-users mailing list submissions to
>         squid-users at lists.squid-cache.org <mailto:
> squid-users at lists.squid-cache.org>
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         http://lists.squid-cache.org/listinfo/squid-users
> or, via email, send a message with subject or body 'help' to
>         squid-users-request at lists.squid-cache.org <mailto:
> squid-users-request at lists.squid-cache.org>
>
> You can reach the person managing the list at
>         squid-users-owner at lists.squid-cache.org <mailto:
> squid-users-owner at lists.squid-cache.org>
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
>
>
> Today's Topics:
>
>    1. Re: Squid container stopped with exit 1 recursively
>       (ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> )
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sun, 4 Sep 2022 15:27:45 +0300
> From: <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >
> To: <squid-users at lists.squid-cache.org <mailto:
> squid-users at lists.squid-cache.org> >
> Subject: Re: [squid-users] Squid container stopped with exit 1
>         recursively
> Message-ID: <002401d8c059$bd518bd0$37f4a370$@gmail.com <http://gmail.com>
> >
> Content-Type: text/plain; charset="utf-8"
>
> Hey Rahul,
>
> You should use the latest squid stable version 5.6.
> Depends on the container you are running but you might be able to use the
> latest RPMs of:
> CentOS, Oracle, Fedora, Alma, Rocky, AMZN
>
> >From my repository at:
> https://www.ngtech.co.il/repo/
>
> To know the error with squid you will need more then ?terminated
> abnormally?
> You will need access to the cache.log and as much details as possible.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> NgTech, Tech Support
> Mobile: +972-5-28704261
> Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com>  <mailto:
> ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >
> Web: https://ngtech.co.il/
> My-Tube: https://tube.ngtech.co.il/
>
> From: squid-users <squid-users-bounces at lists.squid-cache.org <mailto:
> squid-users-bounces at lists.squid-cache.org> > On Behalf Of rahul gupta
> Sent: Saturday, 3 September 2022 14:43
> To: Francesco Chemolli <gkinkie at gmail.com <mailto:gkinkie at gmail.com> >
> Cc: squid-users at lists.squid-cache.org <mailto:
> squid-users at lists.squid-cache.org>
> Subject: Re: [squid-users] Squid container stopped with exit 1 recursively
>
> Thanks Francesco for offering help, in error logs its 104 and message is
> ?terminated abnormally?.
>
> Squid version is 5.0.4.
>
> Regards
> Rahul
>
>
>
> On Sat, 3 Sep 2022 at 7:40 PM, Francesco Chemolli <gkinkie at gmail.com
> <mailto:gkinkie at gmail.com>  <mailto:gkinkie at gmail.com <mailto:
> gkinkie at gmail.com> > > wrote:
> Hi,
>   Anything in the logs?
> What version of squid are you using?
>
> On Sat, 3 Sep 2022 at 11:41, rahul gupta <mca2rahulbit at gmail.com <mailto:
> mca2rahulbit at gmail.com>  <mailto:mca2rahulbit at gmail.com <mailto:
> mca2rahulbit at gmail.com> > > wrote:
> Hi Team,
> I?m running squid in container and running in aws ECS.
>
> It?s working fine but in every few hours container got stopped with exit
> 1. I see cpu and memory usage for container are not too high.
>
> Any pointers .? What May be the potential cause.?or the start point for
> troubleshooting.?
>
> Regards
> Rahul
>
> --
> Sent from iPhone
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org <mailto:
> squid-users at lists.squid-cache.org>  <mailto:
> squid-users at lists.squid-cache.org <mailto:
> squid-users at lists.squid-cache.org> >
> http://lists.squid-cache.org/listinfo/squid-users
>
> --
> @mobile
> --
> Sent from iPhone
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <
> http://lists.squid-cache.org/pipermail/squid-users/attachments/20220904/4b0260be/attachment.htm
> >
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org <mailto:
> squid-users at lists.squid-cache.org>
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
>
> End of squid-users Digest, Vol 97, Issue 2
> ******************************************
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <
> http://lists.squid-cache.org/pipermail/squid-users/attachments/20220905/e838d67e/attachment.htm
> >
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
>
> End of squid-users Digest, Vol 97, Issue 4
> ******************************************
>
-- 
Sent from iPhone
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220906/b3e9cdcd/attachment.htm>

From ngtech1ltd at gmail.com  Tue Sep  6 08:43:53 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Tue, 6 Sep 2022 11:43:53 +0300
Subject: [squid-users] squid-users Digest, Vol 97, Issue 4
In-Reply-To: <CAA50s+CrGCNaym=quE8F6HidnCcox7y3=Qp=KeTeppyktLGEgQ@mail.gmail.com>
References: <mailman.1458.1662369774.1112.squid-users@lists.squid-cache.org>
 <CAA50s+CrGCNaym=quE8F6HidnCcox7y3=Qp=KeTeppyktLGEgQ@mail.gmail.com>
Message-ID: <000001d8c1cc$cc255f00$64701d00$@gmail.com>

Hey Rahul,
 
I?m trying to understand:
Did you turned on the debug in level 9 since you turned spined the container?
If so it?s pretty reasonable that it will run out of space pretty fast.
 
Eliezer
 
----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/
 
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of rahul gupta
Sent: Tuesday, 6 September 2022 2:49
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid-users Digest, Vol 97, Issue 4
 
Hi ,
 
I have debug options set to 9, assuming it?s increasing cache.log so fast. That might be crashing the container.
 
I?ve set debug level 0 and found from last 13 hours container is running. Earlier it got restarted in every 4 hours.
 
Monitoring for week, should be ok.
 
Thanks everyone for pointers. Cheers.
 
 
Regards
Rahul 
 
On Mon, 5 Sep 2022 at 5:23 PM, <squid-users-request at lists.squid-cache.org <mailto:squid-users-request at lists.squid-cache.org> > wrote:
Send squid-users mailing list submissions to
        squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 

To subscribe or unsubscribe via the World Wide Web, visit
        http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
        squid-users-request at lists.squid-cache.org <mailto:squid-users-request at lists.squid-cache.org> 

You can reach the person managing the list at
        squid-users-owner at lists.squid-cache.org <mailto:squid-users-owner at lists.squid-cache.org> 

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. Re: squid-users Digest, Vol 97, Issue 2 (ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> )


----------------------------------------------------------------------

Message: 1
Date: Mon, 5 Sep 2022 12:22:54 +0300
From: <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >
To: <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >
Subject: Re: [squid-users] squid-users Digest, Vol 97, Issue 2
Message-ID: <000a01d8c109$156a15d0$403e4170$@gmail.com <http://gmail.com> >
Content-Type: text/plain; charset="utf-8"

I have a container specification at:
https://github.com/elico/squid-container

if it?s helping you and others.
It?s a simple forward proxy with RAM cache only.
If you want to use CentOS stream 8 you can modify the Dockerfile a bit and it should work in a similar way.

Eliezer

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com>  <mailto:ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > 
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/

From: squid-users <squid-users-bounces at lists.squid-cache.org <mailto:squid-users-bounces at lists.squid-cache.org> > On Behalf Of rahul gupta
Sent: Monday, 5 September 2022 8:55
To: squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Subject: Re: [squid-users] squid-users Digest, Vol 97, Issue 2

Hi  Eliezer,
As it's in ECS-serverless, hence can't log in into the VM to debug more.

Currently debug level set is:  
debug_options: ALL,9
which says terminated abnormally.

Current cpu usage is 2 CPU, memory 4 GB. 

i see at startup it shows 

Target number of buckets:1008
Using 8192 Stroe buckets
Max Mem size: 262144 KB
Max Swap size: 0 KB

any inputs?

thanks.
Rahul


On Sun, Sep 4, 2022 at 8:27 PM <squid-users-request at lists.squid-cache.org <mailto:squid-users-request at lists.squid-cache.org>  <mailto:squid-users-request at lists.squid-cache.org <mailto:squid-users-request at lists.squid-cache.org> > > wrote:
Send squid-users mailing list submissions to
        squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>  <mailto:squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> > 

To subscribe or unsubscribe via the World Wide Web, visit
        http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
        squid-users-request at lists.squid-cache.org <mailto:squid-users-request at lists.squid-cache.org>  <mailto:squid-users-request at lists.squid-cache.org <mailto:squid-users-request at lists.squid-cache.org> > 

You can reach the person managing the list at
        squid-users-owner at lists.squid-cache.org <mailto:squid-users-owner at lists.squid-cache.org>  <mailto:squid-users-owner at lists.squid-cache.org <mailto:squid-users-owner at lists.squid-cache.org> > 

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. Re: Squid container stopped with exit 1 recursively
      (ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com>  <mailto:ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > )


----------------------------------------------------------------------

Message: 1
Date: Sun, 4 Sep 2022 15:27:45 +0300
From: <ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com>  <mailto:ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > >
To: <squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>  <mailto:squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> > >
Subject: Re: [squid-users] Squid container stopped with exit 1
        recursively
Message-ID: <002401d8c059$bd518bd0$37f4a370$@gmail.com <http://gmail.com>  <http://gmail.com> >
Content-Type: text/plain; charset="utf-8"

Hey Rahul,

You should use the latest squid stable version 5.6.
Depends on the container you are running but you might be able to use the latest RPMs of:
CentOS, Oracle, Fedora, Alma, Rocky, AMZN

>From my repository at:
https://www.ngtech.co.il/repo/

To know the error with squid you will need more then ?terminated abnormally?
You will need access to the cache.log and as much details as possible.

Eliezer

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com>  <mailto:ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> >  <mailto:ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com>  <mailto:ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> > > 
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/

From: squid-users <squid-users-bounces at lists.squid-cache.org <mailto:squid-users-bounces at lists.squid-cache.org>  <mailto:squid-users-bounces at lists.squid-cache.org <mailto:squid-users-bounces at lists.squid-cache.org> > > On Behalf Of rahul gupta
Sent: Saturday, 3 September 2022 14:43
To: Francesco Chemolli <gkinkie at gmail.com <mailto:gkinkie at gmail.com>  <mailto:gkinkie at gmail.com <mailto:gkinkie at gmail.com> > >
Cc: squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>  <mailto:squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> > 
Subject: Re: [squid-users] Squid container stopped with exit 1 recursively

Thanks Francesco for offering help, in error logs its 104 and message is ?terminated abnormally?.

Squid version is 5.0.4.

Regards 
Rahul 



On Sat, 3 Sep 2022 at 7:40 PM, Francesco Chemolli <gkinkie at gmail.com <mailto:gkinkie at gmail.com>  <mailto:gkinkie at gmail.com <mailto:gkinkie at gmail.com> >  <mailto:gkinkie at gmail.com <mailto:gkinkie at gmail.com>  <mailto:gkinkie at gmail.com <mailto:gkinkie at gmail.com> > > > wrote:
Hi,
  Anything in the logs?
What version of squid are you using?

On Sat, 3 Sep 2022 at 11:41, rahul gupta <mca2rahulbit at gmail.com <mailto:mca2rahulbit at gmail.com>  <mailto:mca2rahulbit at gmail.com <mailto:mca2rahulbit at gmail.com> >  <mailto:mca2rahulbit at gmail.com <mailto:mca2rahulbit at gmail.com>  <mailto:mca2rahulbit at gmail.com <mailto:mca2rahulbit at gmail.com> > > > wrote:
Hi Team,
I?m running squid in container and running in aws ECS.

It?s working fine but in every few hours container got stopped with exit 1. I see cpu and memory usage for container are not too high.

Any pointers .? What May be the potential cause.?or the start point for troubleshooting.?

Regards
Rahul

-- 
Sent from iPhone
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>  <mailto:squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> >  <mailto:squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>  <mailto:squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> > > 
http://lists.squid-cache.org/listinfo/squid-users

-- 
@mobile
-- 
Sent from iPhone
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220904/4b0260be/attachment.htm>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>  <mailto:squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> > 
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 97, Issue 2
******************************************
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220905/e838d67e/attachment.htm>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 97, Issue 4
******************************************
-- 
Sent from iPhone
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220906/ee36d762/attachment.htm>

From roeeklinger60 at gmail.com  Tue Sep  6 11:41:21 2022
From: roeeklinger60 at gmail.com (roee klinger)
Date: Tue, 6 Sep 2022 14:41:21 +0300
Subject: [squid-users] logfileHandleWrite: daemon:/var/log/squid/access.log:
 error writing ((32) Broken pipe)
Message-ID: <CAGCa14q9QeX_fqH0bFPW5C8=Cpssbx8zgw0CWE-MLAEivkTSyw@mail.gmail.com>

Hello,

I know this is a common issue, and I found many instances of people
complaining about it online, but I have not found a working fix yet.

It is also important to know that I am running multiple Squid instances on
the same machine, they are all getting the error at the same time, and I
have plenty of RAM and CPU available, some more info below.

Is a possible workaround that might be just replacing the line with this?
or will this cause a problem?

access_log /var/log/squid/access2.log




INFO -
Versions:

Squid Cache: Version 4.10
Ubuntu 20.04.4 LTS


Example squid.conf:

visible_hostname squid2

access_log daemon:/var/log/squid/access2.log squid

cache_log /var/log/squid/cache2.log

pid_filename /var/run/squid2.pid


acl localnet src 0.0.0.1-0.255.255.255  # RFC 1122 "this" network (LAN)

acl localnet src 10.0.0.0/8             # RFC 1918 local private network
(LAN)

acl localnet src 100.64.0.0/10          # RFC 6598 shared address space
(CGN)

acl localnet src 169.254.0.0/16         # RFC 3927 link-local (directly
plugged) machines

acl localnet src 172.16.0.0/12          # RFC 1918 local private network
(LAN)

acl localnet src 192.168.0.0/16         # RFC 1918 local private network
(LAN)

acl localnet src fc00::/7               # RFC 4193 local private network
range

acl localnet src fe80::/10              # RFC 4291 link-local (directly
plugged) machines

acl SSL_ports port 443

acl Safe_ports port 80          # http

acl Safe_ports port 21          # ftp

acl Safe_ports port 443         # https

acl Safe_ports port 70          # gopher

acl Safe_ports port 210         # wais

acl Safe_ports port 1025-65535  # unregistered ports

acl Safe_ports port 280         # http-mgmt

acl Safe_ports port 488         # gss-http

acl Safe_ports port 591         # filemaker

acl Safe_ports port 777         # multiling http

acl CONNECT method CONNECT

http_access deny !Safe_ports

http_access deny CONNECT !SSL_ports

http_access allow localhost manager

http_access deny manager

# include /etc/squid/conf.d/*

http_access allow localhost

acl aws src *censored*

http_access allow aws

# http_access deny all

tcp_outgoing_address *censored*

http_port 10002

coredump_dir /var/spool/squid

refresh_pattern ^ftp:           1440    20%     10080

refresh_pattern ^gopher:        1440    0%      1440

refresh_pattern -i (/cgi-bin/|\?) 0     0%      0

refresh_pattern \/(Packages|Sources)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims

refresh_pattern \/Release(|\.gpg)$ 0 0% 0 refresh-ims

refresh_pattern \/InRelease$ 0 0% 0 refresh-ims

refresh_pattern \/(Translation-.*)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims

refresh_pattern .               0       20%     4320


shutdown_lifetime 1 seconds

logfile_rotate 0

max_filedescriptors 16384

dns_nameservers 8.8.8.8 8.8.4.4 1.1.1.1

cache deny all

cache_dir null /tmp

via off

forwarded_for off

request_header_access From deny all

request_header_access Server deny all

request_header_access WWW-Authenticate deny all

request_header_access Link deny all

request_header_access Cache-Control deny all

request_header_access Proxy-Connection deny all

request_header_access X-Cache deny all

request_header_access X-Cache-Lookup deny all

request_header_access Via deny all

request_header_access X-Forwarded-For deny all

request_header_access Pragma deny all

request_header_access Keep-Alive deny all

dns_v4_first on


Example service file:

## Copyright (C) 1996-2020 The Squid Software Foundation and contributors

##

## Squid software is distributed under GPLv2+ license and includes

## contributions from numerous individuals and organizations.

## Please see the COPYING and CONTRIBUTORS files for details.

##


[Unit]

Description=Squid Web Proxy Server

Documentation=man:squid(8)

After=network.target network-online.target nss-lookup.target


[Service]

Type=forking

PIDFile=/var/run/squid2.pid

ExecStartPre=/usr/sbin/squid --foreground -z -f /etc/squid/squid2.conf

ExecStart=/usr/sbin/squid -sYC -f /etc/squid/squid2.conf

ExecReload=/bin/kill -HUP $MAINPID

KillMode=mixed


[Install]

WantedBy=multi-user.target



Permissions:

?  ls -alt /etc/squid/
total 128
drwxr-xr-x   2 root root 4096 Sep  6 11:33 .
-rw-r--r--   1 root root 2831 Sep  6 11:33 squid7.conf
drwxr-xr-x 116 root root 4096 Sep  6 11:33 ..
-rw-r--r--   1 root root 2830 Sep  6 11:33 squid2.conf
-rw-r--r--   1 root root 2836 Sep  6 11:33 squid13.conf
-rw-r--r--   1 root root 2836 Sep  6 11:32 squid23.conf
-rw-r--r--   1 root root 2836 Sep  6 11:32 squid19.conf
-rw-r--r--   1 root root 2832 Sep  6 11:32 squid1.conf
-rw-r--r--   1 root root 2836 Sep  6 11:32 squid17.conf
-rw-r--r--   1 root root 2832 Sep  6 11:31 squid4.conf
-rw-r--r--   1 root root 2834 Sep  6 11:31 squid21.conf
-rw-r--r--   1 root root 2833 Sep  6 11:31 squid25.conf
-rw-r--r--   1 root root 2834 Sep  6 11:31 squid12.conf
-rw-r--r--   1 root root 2832 Sep  6 11:31 squid3.conf
-rw-r--r--   1 root root 2836 Sep  6 11:30 squid10.conf
-rw-r--r--   1 root root 2835 Sep  6 11:30 squid11.conf
-rw-r--r--   1 root root 2833 Sep  6 11:30 squid18.conf
-rw-r--r--   1 root root 2830 Sep  6 11:30 squid8.conf
-rw-r--r--   1 root root 2830 Sep  6 11:30 squid6.conf
-rw-r--r--   1 root root 2833 Sep  6 11:30 squid28.conf
-rw-r--r--   1 root root 2830 Sep  6 11:25 squid9.conf
-rw-r--r--   1 root root 2836 Sep  6 11:25 squid24.conf
-rw-r--r--   1 root root 2835 Sep  6 11:25 squid22.conf
-rw-r--r--   1 root root 2837 Sep  6 11:25 squid20.conf
-rw-r--r--   1 root root 2836 Sep  6 11:25 squid16.conf
-rw-r--r--   1 root root 2835 Sep  6 11:25 squid15.conf
-rw-r--r--   1 root root 2836 Sep  6 11:25 squid14.conf
-rw-r--r--   1 root root 2831 Sep  6 11:25 squid5.conf
-rw-r--r--   1 root root 2833 Sep  6 11:25 squid27.conf
-rw-r--r--   1 root root 2835 Sep  6 11:25 squid26.conf
-rw-r--r--   1 root root 2835 Sep  6 11:25 squid30.conf
-rw-r--r--   1 root root 2835 Sep  6 11:25 squid29.conf
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220906/8bbbc7af/attachment.htm>

From rousskov at measurement-factory.com  Tue Sep  6 13:28:39 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 6 Sep 2022 09:28:39 -0400
Subject: [squid-users] logfileHandleWrite:
 daemon:/var/log/squid/access.log: error writing ((32) Broken pipe)
In-Reply-To: <CAGCa14q9QeX_fqH0bFPW5C8=Cpssbx8zgw0CWE-MLAEivkTSyw@mail.gmail.com>
References: <CAGCa14q9QeX_fqH0bFPW5C8=Cpssbx8zgw0CWE-MLAEivkTSyw@mail.gmail.com>
Message-ID: <171b0b23-7a59-b420-ac05-fcbdb02a213d@measurement-factory.com>

On 9/6/22 07:41, roee klinger wrote:

> It is also important to know that I am running multiple Squid instances 
> on the same machine, they are all getting the error at the same time

What external event(s) happen at that time? Something is probably 
sending a signal to the logging daemon process. It would be good to know 
what that something (and that signal) is. Your syslog or cache.log might 
contain more info. Analyzing the timing/schedule of these problems may 
also be helpful in identifying the trigger.


> Is a possible workaround that might be just replacing the line with 
> this? 

 > access_log /var/log/squid/access2.log

As you know, this configuration (in this deprecated spelling or with and 
explicit "stdio:" prefix) will result in Squid workers writing to the 
log file directly instead of asking the logging daemon. This will, 
naturally, get rid of the pipe between workers and their daemons, and 
the associated broken pipe error.

> or will this cause a problem?

Impossible to say for sure without knowing whether your workers benefit 
from the anticipated performance advantages of avoiding blocking file 
I/O _and_ whether those advantages are real (in your environment). Too 
many variables and too many unknowns. I would treat this as an important 
(and potentially disruptive) configuration change and carefully test the 
outcome.


HTH,

Alex.


> INFO -
> Versions:
> 
>     Squid Cache: Version 4.10
>     Ubuntu 20.04.4 LTS
> 
> 
> Example squid.conf:
> 
>     visible_hostname squid2
> 
>     access_log daemon:/var/log/squid/access2.log squid
> 
>     cache_log /var/log/squid/cache2.log
> 
>     pid_filename /var/run/squid2.pid
> 
> 
>     acl localnet src 0.0.0.1-0.255.255.255# RFC 1122 "this" network (LAN)
> 
>     acl localnet src 10.0.0.0/8 <http://10.0.0.0/8> # RFC 1918 local
>     private network (LAN)
> 
>     acl localnet src 100.64.0.0/10 <http://100.64.0.0/10># RFC 6598
>     shared address space (CGN)
> 
>     acl localnet src 169.254.0.0/16 <http://169.254.0.0/16> # RFC 3927
>     link-local (directly plugged) machines
> 
>     acl localnet src 172.16.0.0/12 <http://172.16.0.0/12># RFC 1918
>     local private network (LAN)
> 
>     acl localnet src 192.168.0.0/16 <http://192.168.0.0/16> # RFC 1918
>     local private network (LAN)
> 
>     acl localnet src fc00::/7 # RFC 4193 local private network range
> 
>     acl localnet src fe80::/10# RFC 4291 link-local (directly plugged)
>     machines
> 
>     acl SSL_ports port 443
> 
>     acl Safe_ports port 80# http
> 
>     acl Safe_ports port 21# ftp
> 
>     acl Safe_ports port 443 # https
> 
>     acl Safe_ports port 70# gopher
> 
>     acl Safe_ports port 210 # wais
> 
>     acl Safe_ports port 1025-65535# unregistered ports
> 
>     acl Safe_ports port 280 # http-mgmt
> 
>     acl Safe_ports port 488 # gss-http
> 
>     acl Safe_ports port 591 # filemaker
> 
>     acl Safe_ports port 777 # multiling http
> 
>     acl CONNECT method CONNECT
> 
>     http_access deny !Safe_ports
> 
>     http_access deny CONNECT !SSL_ports
> 
>     http_access allow localhost manager
> 
>     http_access deny manager
> 
>     # include /etc/squid/conf.d/*
> 
>     http_access allow localhost
> 
>     acl aws src *censored*
> 
>     http_access allow aws
> 
>     # http_access deny all
> 
>     tcp_outgoing_address *censored*
> 
>     http_port 10002
> 
>     coredump_dir /var/spool/squid
> 
>     refresh_pattern ^ftp: 144020% 10080
> 
>     refresh_pattern ^gopher:14400%1440
> 
>     refresh_pattern -i (/cgi-bin/|\?) 0 0%0
> 
>     refresh_pattern \/(Packages|Sources)(|\.bz2|\.gz|\.xz)$ 0 0% 0
>     refresh-ims
> 
>     refresh_pattern \/Release(|\.gpg)$ 0 0% 0 refresh-ims
> 
>     refresh_pattern \/InRelease$ 0 0% 0 refresh-ims
> 
>     refresh_pattern \/(Translation-.*)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims
> 
>     refresh_pattern . 0 20% 4320
> 
> 
>     shutdown_lifetime 1 seconds
> 
>     logfile_rotate 0
> 
>     max_filedescriptors 16384
> 
>     dns_nameservers 8.8.8.8 8.8.4.4 1.1.1.1
> 
>     cache deny all
> 
>     cache_dir null /tmp
> 
>     via off
> 
>     forwarded_for off
> 
>     request_header_access From deny all
> 
>     request_header_access Server deny all
> 
>     request_header_access WWW-Authenticate deny all
> 
>     request_header_access Link deny all
> 
>     request_header_access Cache-Control deny all
> 
>     request_header_access Proxy-Connection deny all
> 
>     request_header_access X-Cache deny all
> 
>     request_header_access X-Cache-Lookup deny all
> 
>     request_header_access Via deny all
> 
>     request_header_access X-Forwarded-For deny all
> 
>     request_header_access Pragma deny all
> 
>     request_header_access Keep-Alive deny all
> 
>     dns_v4_first on
> 
> 
> Example?service file:
> 
>     ## Copyright (C) 1996-2020 The Squid Software Foundation and
>     contributors
> 
>     ##
> 
>     ## Squid software is distributed under GPLv2+ license and includes
> 
>     ## contributions from numerous individuals and organizations.
> 
>     ## Please see the COPYING and CONTRIBUTORS files for details.
> 
>     ##
> 
> 
>     [Unit]
> 
>     Description=Squid Web Proxy Server
> 
>     Documentation=man:squid(8)
> 
>     After=network.target network-online.target nss-lookup.target
> 
> 
>     [Service]
> 
>     Type=forking
> 
>     PIDFile=/var/run/squid2.pid
> 
>     ExecStartPre=/usr/sbin/squid --foreground -z -f /etc/squid/squid2.conf
> 
>     ExecStart=/usr/sbin/squid -sYC -f /etc/squid/squid2.conf
> 
>     ExecReload=/bin/kill -HUP $MAINPID
> 
>     KillMode=mixed
> 
> 
>     [Install]
> 
>     WantedBy=multi-user.target
> 
> 
> 
> Permissions:
> 
>     ?? ls -alt /etc/squid/
>     total 128
>     drwxr-xr-x ? 2 root root 4096 Sep ?6 11:33 .
>     -rw-r--r-- ? 1 root root 2831 Sep ?6 11:33 squid7.conf
>     drwxr-xr-x 116 root root 4096 Sep ?6 11:33 ..
>     -rw-r--r-- ? 1 root root 2830 Sep ?6 11:33 squid2.conf
>     -rw-r--r-- ? 1 root root 2836 Sep ?6 11:33 squid13.conf
>     -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid23.conf
>     -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid19.conf
>     -rw-r--r-- ? 1 root root 2832 Sep ?6 11:32 squid1.conf
>     -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid17.conf
>     -rw-r--r-- ? 1 root root 2832 Sep ?6 11:31 squid4.conf
>     -rw-r--r-- ? 1 root root 2834 Sep ?6 11:31 squid21.conf
>     -rw-r--r-- ? 1 root root 2833 Sep ?6 11:31 squid25.conf
>     -rw-r--r-- ? 1 root root 2834 Sep ?6 11:31 squid12.conf
>     -rw-r--r-- ? 1 root root 2832 Sep ?6 11:31 squid3.conf
>     -rw-r--r-- ? 1 root root 2836 Sep ?6 11:30 squid10.conf
>     -rw-r--r-- ? 1 root root 2835 Sep ?6 11:30 squid11.conf
>     -rw-r--r-- ? 1 root root 2833 Sep ?6 11:30 squid18.conf
>     -rw-r--r-- ? 1 root root 2830 Sep ?6 11:30 squid8.conf
>     -rw-r--r-- ? 1 root root 2830 Sep ?6 11:30 squid6.conf
>     -rw-r--r-- ? 1 root root 2833 Sep ?6 11:30 squid28.conf
>     -rw-r--r-- ? 1 root root 2830 Sep ?6 11:25 squid9.conf
>     -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid24.conf
>     -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid22.conf
>     -rw-r--r-- ? 1 root root 2837 Sep ?6 11:25 squid20.conf
>     -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid16.conf
>     -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid15.conf
>     -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid14.conf
>     -rw-r--r-- ? 1 root root 2831 Sep ?6 11:25 squid5.conf
>     -rw-r--r-- ? 1 root root 2833 Sep ?6 11:25 squid27.conf
>     -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid26.conf
>     -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid30.conf
>     -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid29.conf
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From david at articatech.com  Tue Sep  6 15:45:08 2022
From: david at articatech.com (David Touzeau)
Date: Tue, 6 Sep 2022 17:45:08 +0200
Subject: [squid-users] [squid][v5.6] : problem with "slow" or "fast" acl
In-Reply-To: <6315F1FD.5010501@interieur.gouv.fr>
References: <6315EC88.6050505@interieur.gouv.fr>
 <6315F1FD.5010501@interieur.gouv.fr>
Message-ID: <33020e46-99dc-d860-324b-30da97991049@articatech.com>

Hi Eric.

We had the same restrictions with the fast or slow ACLs.
Have you thought about creating a squid helper that calculates your needs?
So maybe you can get around this by using the acl "note" acl note xxx 
xxx which turns your helper results (slow) into "fast".



Le 05/09/2022 ? 14:56, PERROT Eric DNUM SDCAST BST SSAIM a ?crit?:
> Hello,
>
> We use directives "reply_body_max_size", "request_body_max_size" and 
> "delay_access" to limit upload, download and passband in our infra.
>
> This configuration existes since a while, but we have noticed that 
> with squid v4.16, our delay pool didn't react as we wanted anymore. We 
> were excpeting improvment upgrading squid to v5.6. But it got worth :
> - restriction still didn't work
> - and squid had a segmentation fault each time some acl where used
>
> Thanks to Alex Rousskov (bug 5231), after some investigation, it 
> appears that we used "slow" acl (proxy_auth an time acl) where only 
> "fast" acl where authorized...). The bug is still open as squid has 
> not flagged the problem in cache logs,
>
> My email, is to show you our configuration and the behaviour we 
> espect, and the behaviour we finally have.
> 1 - squd v4.12 : we expect to limit downlod/upload and passband during 
> working time for all login except those starting with cg_*
> "
> |###### Gestion de bande passante ##########
> acl bureau time 09:00-12:00
> acl bureau time 14:00-17:00
> # Comptes generiques
> |||acl my_ldap_auth proxy_auth REQUIRED
> |acl cgen proxy_auth_regex cg_
> reply_body_max_size 800 MB *bureau !cgen*
> request_body_max_size 5 MB
> # La limite de bande passante ne fonctionne plus avec le BUMP
> # A tester ...
> delay_pools 1
> # Pendant time sauf cgen, emeraude
> delay_class 1 4
> delay_access 1 allow**||*||my_ldap_auth !cgen||***!emeraude
> delay_access 1 deny all
> # 512000 = 5120 kbits/user 640 ko
> # 307200 = 3072 kbits/user 384 ko
> delay_parameters 1 -1/-1 -1/-1 -1/-1 107200/107200
> ##################################################|
> "
> => with this configuration, the delay pool seemed not to work anymore, 
> so we upgraded squid to v5.6. Which caused the squid segmentation 
> fault...
>
> 2 - squid v5.6 : to solve the segmentation fault, we had to take off 
> my_ldap_auth/cgen (proxy_auth acl) and bureau (time acl). The 
> limitation work again, but we are no more able to limit restriction 
> during working time, or for sp?cific login...
> "
> |###### Gestion de bande passante ##########
> acl bureau time 09:00-12:00
> acl bureau time 14:00-17:00
> # Comptes generiques
> acl userrgt src 10.0.0.0/8
> |||acl my_ldap_auth proxy_auth REQUIRED
> |acl cgen proxy_auth_regex cg_
> reply_body_max_size 800 MB *userrgt*
> request_body_max_size 5 MB
> # La limite de bande passante ne fonctionne plus avec le BUMP
> # A tester ...
> delay_pools 1
> # Pendant time sauf cgen, emeraude
> delay_class 1 4
> delay_access 1 allow||*||||***!emeraude
> delay_access 1 deny all
> # 512000 = 5120 kbits/user 640 ko
> # 307200 = 3072 kbits/user 384 ko
> delay_parameters 1 -1/-1 -1/-1 -1/-1 107200/107200
> ##################################################|
> "
>
> Can you tell me if what we want to do is still possible? Limiting 
> upload/download/passband for all logged user except those starting by 
> cg_*..?.
>
> Thank you for the time reading, and thank you for your answers.
>
> Regards,
>
> Eric Perrot
>
>
>
>
> Pour une administration exemplaire, pr?servons l'environnement.
> N'imprimons que si n?cessaire.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-- 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220906/0c569514/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature-perroter.png
Type: image/png
Size: 10699 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220906/0c569514/attachment.png>

From ngtech1ltd at gmail.com  Tue Sep  6 18:10:08 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Tue, 6 Sep 2022 21:10:08 +0300
Subject: [squid-users] [squid][v5.6] : problem with "slow" or "fast" acl
In-Reply-To: <33020e46-99dc-d860-324b-30da97991049@articatech.com>
References: <6315EC88.6050505@interieur.gouv.fr>
 <6315F1FD.5010501@interieur.gouv.fr>
 <33020e46-99dc-d860-324b-30da97991049@articatech.com>
Message-ID: <000001d8c21b$ece0a340$c6a1e9c0$@gmail.com>

Hey Eric and David,
 
I am thinking about the best place to put a note acl.
 
What is the actual requirement?
Do you want to limit a specific client or all of them?
I have not used delay pools for a very long time so I am not sure about what you want these to do.
 
Eliezer
 
----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/
 
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of David Touzeau
Sent: Tuesday, 6 September 2022 18:45
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] [squid][v5.6] : problem with "slow" or "fast" acl
 
Hi Eric.
We had the same restrictions with the fast or slow ACLs. 
Have you thought about creating a squid helper that calculates your needs? 
So maybe you can get around this by using the acl "note" acl note xxx xxx which turns your helper results (slow) into "fast".
 
 
Le 05/09/2022 ? 14:56, PERROT Eric DNUM SDCAST BST SSAIM a ?crit :
Hello,

We use directives "reply_body_max_size", "request_body_max_size" and "delay_access" to limit upload, download and passband in our infra.

This configuration existes since a while, but we have noticed that with squid v4.16, our delay pool didn't react as we wanted anymore. We were excpeting improvment upgrading squid to v5.6. But it got worth :
- restriction still didn't work
- and squid had a segmentation fault each time some acl where used

Thanks to Alex Rousskov (bug 5231), after some investigation, it appears that we used "slow" acl (proxy_auth an time acl) where only "fast" acl where authorized...). The bug is still open as squid has not flagged the problem in cache logs, 

My email, is to show you our configuration and the behaviour we espect, and the behaviour we finally have.
1 - squd v4.12 : we expect to limit downlod/upload and passband during working time for all login except those starting with cg_*
"
###### Gestion de bande passante ##########
acl bureau time 09:00-12:00
acl bureau time 14:00-17:00
# Comptes generiques
acl my_ldap_auth proxy_auth REQUIRED
acl cgen proxy_auth_regex cg_
reply_body_max_size 800 MB bureau !cgen
request_body_max_size 5 MB 
# La limite de bande passante ne fonctionne plus avec le BUMP
# A tester ...
delay_pools 1
# Pendant time sauf cgen, emeraude 
delay_class 1 4
delay_access 1 allow my_ldap_auth !cgen !emeraude
delay_access 1 deny all
# 512000 = 5120 kbits/user 640 ko
# 307200 = 3072 kbits/user 384 ko
delay_parameters 1 -1/-1 -1/-1 -1/-1 107200/107200
##################################################
"
=> with this configuration, the delay pool seemed not to work anymore, so we upgraded squid to v5.6. Which caused the squid segmentation fault... 

2 - squid v5.6 : to solve the segmentation fault, we had to take off my_ldap_auth/cgen (proxy_auth acl) and bureau (time acl). The limitation work again, but we are no more able to limit restriction during working time, or for sp?cific login...
"
###### Gestion de bande passante ##########
acl bureau time 09:00-12:00
acl bureau time 14:00-17:00
# Comptes generiques
acl userrgt src 10.0.0.0/8
acl my_ldap_auth proxy_auth REQUIRED
acl cgen proxy_auth_regex cg_
reply_body_max_size 800 MB userrgt
request_body_max_size 5 MB 
# La limite de bande passante ne fonctionne plus avec le BUMP
# A tester ...
delay_pools 1
# Pendant time sauf cgen, emeraude 
delay_class 1 4
delay_access 1 allow !emeraude
delay_access 1 deny all
# 512000 = 5120 kbits/user 640 ko
# 307200 = 3072 kbits/user 384 ko
delay_parameters 1 -1/-1 -1/-1 -1/-1 107200/107200
##################################################
"

Can you tell me if what we want to do is still possible? Limiting upload/download/passband for all logged user except those starting by cg_*..?.

Thank you for the time reading, and thank you for your answers.

Regards,

Eric Perrot





Pour une administration exemplaire, pr?servons l'environnement. 
N'imprimons que si n?cessaire. 



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users
-- 
 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220906/fbe63deb/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 10699 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220906/fbe63deb/attachment.png>

From ngtech1ltd at gmail.com  Tue Sep  6 18:21:55 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Tue, 6 Sep 2022 21:21:55 +0300
Subject: [squid-users] MySQL backend for time restrictions of clients
Message-ID: <000601d8c21d$8c646720$a52d3560$@gmail.com>

Hey Everyone,
 
I have seen a very nice to restrict internet access by hours.
The concept is pretty simple.
Per client you have a time table which contains the day and the hour in the day as integers.
For example the next table:
##
user_id, day, hour, allow
1, 0, 8, 0
1, 0, 9, 1
?
1, 0, 20, 1
1, 0, 21, 0
##
 
So the client with user_id 1 which is being resolved in another table can use the Internet at 09:00 until 21:00 on Sunday (day 0)
 
I wrote a helper that runs a query against the DB and resolve the right user_id for the IP and decides whether  to allow or deny internet access.
 
There are other ideas on how to implement a similar solution and if someone implemented any other solution with a DB backend please share.
 
Thanks,
Eliezer
 
----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email:  <mailto:ngtech1ltd at gmail.com> ngtech1ltd at gmail.com
Web:  <https://ngtech.co.il/> https://ngtech.co.il/
My-Tube:  <https://tube.ngtech.co.il/> https://tube.ngtech.co.il/
 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220906/845617ea/attachment.htm>

From squid3 at treenet.co.nz  Tue Sep  6 18:46:29 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 7 Sep 2022 06:46:29 +1200
Subject: [squid-users] [squid][v5.6] : problem with "slow" or "fast" acl
In-Reply-To: <6315F1FD.5010501@interieur.gouv.fr>
References: <6315EC88.6050505@interieur.gouv.fr>
 <6315F1FD.5010501@interieur.gouv.fr>
Message-ID: <25aa58ab-a20f-8b50-eb1a-12d1656b797f@treenet.co.nz>

On 6/09/22 00:56, PERROT Eric DNUM SDCAST BST SSAIM wrote:
> Hello,
> 
> We use directives "reply_body_max_size", "request_body_max_size" and 
> "delay_access" to limit upload, download and passband in our infra.
> 

All of which are "fast" type.


> This configuration existes since a while, but we have noticed that with 
> squid v4.16, our delay pool didn't react as we wanted anymore.


FYI, use of "slow" type ACLs in "fast" type checks is subject to what 
Squid happens to have in its processing state information and available 
in caches from previous traffic.

Even if a config like this *appears* to work, it may not be actually 
working for all transactions. The delicate balance may change at any time.


> Can you tell me if what we want to do is still possible? Limiting 
> upload/download/passband for all logged user except those starting by 
> cg_*..?.

You need to:

  1) do authentication checks to http_access.



  2) make the cg_* accounts part of a "group".

  The usual way to do that is with the authentication systems "group" 
functionality and a helper to fetch that.

  However, in Squid-4+ you can also add a temporary "group" label as 
needed based on other ACL checks (eg the username regex matching) like so:

    acl userCgPrefix proxy_auth_regex ^cg_
    acl markCgGroup annotate_transaction group=cgUsers
    http_access allow userCgPrefix markCgGroup !all


3) check the 'group' annotation in fast type controls, not the username:

   acl userrgt note group cgUsers

   reply_body_max_size 800 MB userrgt
   deny_access 1 deny userrgt

FTR; the above should work on any Squid-4 or later. So you can revert to 
the v4 Squid install which was otherwise working for you.


HTH
Amos


From roeeklinger60 at gmail.com  Tue Sep  6 22:02:53 2022
From: roeeklinger60 at gmail.com (roee klinger)
Date: Wed, 7 Sep 2022 01:02:53 +0300
Subject: [squid-users] logfileHandleWrite:
 daemon:/var/log/squid/access.log: error writing ((32) Broken pipe)
In-Reply-To: <171b0b23-7a59-b420-ac05-fcbdb02a213d@measurement-factory.com>
References: <CAGCa14q9QeX_fqH0bFPW5C8=Cpssbx8zgw0CWE-MLAEivkTSyw@mail.gmail.com>
 <171b0b23-7a59-b420-ac05-fcbdb02a213d@measurement-factory.com>
Message-ID: <3dce10cb-9ed3-4176-bc70-5763ff9f7c67@Spark>

Hey Alex,

Thank you for your reply.
> Your syslog or cache.log might
> contain more info. Analyzing the timing/schedule of these problems may
> also be helpful in identifying the trigger.

After following this advice, I could easily see that this happens due to disk space running out on my server,
it seems that the logs has filled over 100GB of log data, since I made a configuration mistake (I think?) by setting this:
> quote_type
> logfile_rotate 0
>
If I remember and read correctly, this means that the rotation of the files is disabled and they will just keeping increasing
in size if left unchecked.

I have now gone ahead and changed all the configuration file to this setting:
> quote_type
> logfile_rotate 1
>
So now it should rotate once daily, and on the next rotation it should be deleted, and this is all handled by logrotate on Debian-based machines?

This is my / cat /etc/logrotate.d/squid:
? / cat /etc/logrotate.d/squid
#
# Logrotate fragment for squid.
#
/var/log/squid/*.log {
?daily
?compress
?delaycompress
?rotate 2
?missingok
?nocreate
?sharedscripts
?prerotate
?test ! -x /usr/sbin/sarg-reports || /usr/sbin/sarg-reports daily
?endscript
?postrotate
?test ! -e /var/run/squid.pid || test ! -x /usr/sbin/squid || /usr/sbin/squid -k rotate
?endscript
}

Is there a way for me to set it so it just get deleted every 24 or 12 hours without the archive first?

Thanks,
Roee
On 6 Sep 2022, 16:28 +0300, Alex Rousskov <rousskov at measurement-factory.com>, wrote:
> On 9/6/22 07:41, roee klinger wrote:
>
> > It is also important to know that I am running multiple Squid instances
> > on the same machine, they are all getting the error at the same time
>
> What external event(s) happen at that time? Something is probably
> sending a signal to the logging daemon process. It would be good to know
> what that something (and that signal) is. Your syslog or cache.log might
> contain more info. Analyzing the timing/schedule of these problems may
> also be helpful in identifying the trigger.
>
>
> > Is a possible workaround that might be just replacing the line with
> > this?
>
> > access_log /var/log/squid/access2.log
>
> As you know, this configuration (in this deprecated spelling or with and
> explicit "stdio:" prefix) will result in Squid workers writing to the
> log file directly instead of asking the logging daemon. This will,
> naturally, get rid of the pipe between workers and their daemons, and
> the associated broken pipe error.
>
> > or will this cause a problem?
>
> Impossible to say for sure without knowing whether your workers benefit
> from the anticipated performance advantages of avoiding blocking file
> I/O _and_ whether those advantages are real (in your environment). Too
> many variables and too many unknowns. I would treat this as an important
> (and potentially disruptive) configuration change and carefully test the
> outcome.
>
>
> HTH,
>
> Alex.
>
>
> > INFO -
> > Versions:
> >
> > Squid Cache: Version 4.10
> > Ubuntu 20.04.4 LTS
> >
> >
> > Example squid.conf:
> >
> > visible_hostname squid2
> >
> > access_log daemon:/var/log/squid/access2.log squid
> >
> > cache_log /var/log/squid/cache2.log
> >
> > pid_filename /var/run/squid2.pid
> >
> >
> > acl localnet src 0.0.0.1-0.255.255.255# RFC 1122 "this" network (LAN)
> >
> > acl localnet src 10.0.0.0/8 <http://10.0.0.0/8> # RFC 1918 local
> > private network (LAN)
> >
> > acl localnet src 100.64.0.0/10 <http://100.64.0.0/10># RFC 6598
> > shared address space (CGN)
> >
> > acl localnet src 169.254.0.0/16 <http://169.254.0.0/16> # RFC 3927
> > link-local (directly plugged) machines
> >
> > acl localnet src 172.16.0.0/12 <http://172.16.0.0/12># RFC 1918
> > local private network (LAN)
> >
> > acl localnet src 192.168.0.0/16 <http://192.168.0.0/16> # RFC 1918
> > local private network (LAN)
> >
> > acl localnet src fc00::/7 # RFC 4193 local private network range
> >
> > acl localnet src fe80::/10# RFC 4291 link-local (directly plugged)
> > machines
> >
> > acl SSL_ports port 443
> >
> > acl Safe_ports port 80# http
> >
> > acl Safe_ports port 21# ftp
> >
> > acl Safe_ports port 443 # https
> >
> > acl Safe_ports port 70# gopher
> >
> > acl Safe_ports port 210 # wais
> >
> > acl Safe_ports port 1025-65535# unregistered ports
> >
> > acl Safe_ports port 280 # http-mgmt
> >
> > acl Safe_ports port 488 # gss-http
> >
> > acl Safe_ports port 591 # filemaker
> >
> > acl Safe_ports port 777 # multiling http
> >
> > acl CONNECT method CONNECT
> >
> > http_access deny !Safe_ports
> >
> > http_access deny CONNECT !SSL_ports
> >
> > http_access allow localhost manager
> >
> > http_access deny manager
> >
> > # include /etc/squid/conf.d/*
> >
> > http_access allow localhost
> >
> > acl aws src *censored*
> >
> > http_access allow aws
> >
> > # http_access deny all
> >
> > tcp_outgoing_address *censored*
> >
> > http_port 10002
> >
> > coredump_dir /var/spool/squid
> >
> > refresh_pattern ^ftp: 144020% 10080
> >
> > refresh_pattern ^gopher:14400%1440
> >
> > refresh_pattern -i (/cgi-bin/|\?) 0 0%0
> >
> > refresh_pattern \/(Packages|Sources)(|\.bz2|\.gz|\.xz)$ 0 0% 0
> > refresh-ims
> >
> > refresh_pattern \/Release(|\.gpg)$ 0 0% 0 refresh-ims
> >
> > refresh_pattern \/InRelease$ 0 0% 0 refresh-ims
> >
> > refresh_pattern \/(Translation-.*)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims
> >
> > refresh_pattern . 0 20% 4320
> >
> >
> > shutdown_lifetime 1 seconds
> >
> > logfile_rotate 0
> >
> > max_filedescriptors 16384
> >
> > dns_nameservers 8.8.8.8 8.8.4.4 1.1.1.1
> >
> > cache deny all
> >
> > cache_dir null /tmp
> >
> > via off
> >
> > forwarded_for off
> >
> > request_header_access From deny all
> >
> > request_header_access Server deny all
> >
> > request_header_access WWW-Authenticate deny all
> >
> > request_header_access Link deny all
> >
> > request_header_access Cache-Control deny all
> >
> > request_header_access Proxy-Connection deny all
> >
> > request_header_access X-Cache deny all
> >
> > request_header_access X-Cache-Lookup deny all
> >
> > request_header_access Via deny all
> >
> > request_header_access X-Forwarded-For deny all
> >
> > request_header_access Pragma deny all
> >
> > request_header_access Keep-Alive deny all
> >
> > dns_v4_first on
> >
> >
> > Example?service file:
> >
> > ## Copyright (C) 1996-2020 The Squid Software Foundation and
> > contributors
> >
> > ##
> >
> > ## Squid software is distributed under GPLv2+ license and includes
> >
> > ## contributions from numerous individuals and organizations.
> >
> > ## Please see the COPYING and CONTRIBUTORS files for details.
> >
> > ##
> >
> >
> > [Unit]
> >
> > Description=Squid Web Proxy Server
> >
> > Documentation=man:squid(8)
> >
> > After=network.target network-online.target nss-lookup.target
> >
> >
> > [Service]
> >
> > Type=forking
> >
> > PIDFile=/var/run/squid2.pid
> >
> > ExecStartPre=/usr/sbin/squid --foreground -z -f /etc/squid/squid2.conf
> >
> > ExecStart=/usr/sbin/squid -sYC -f /etc/squid/squid2.conf
> >
> > ExecReload=/bin/kill -HUP $MAINPID
> >
> > KillMode=mixed
> >
> >
> > [Install]
> >
> > WantedBy=multi-user.target
> >
> >
> >
> > Permissions:
> >
> > ?? ls -alt /etc/squid/
> > total 128
> > drwxr-xr-x ? 2 root root 4096 Sep ?6 11:33 .
> > -rw-r--r-- ? 1 root root 2831 Sep ?6 11:33 squid7.conf
> > drwxr-xr-x 116 root root 4096 Sep ?6 11:33 ..
> > -rw-r--r-- ? 1 root root 2830 Sep ?6 11:33 squid2.conf
> > -rw-r--r-- ? 1 root root 2836 Sep ?6 11:33 squid13.conf
> > -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid23.conf
> > -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid19.conf
> > -rw-r--r-- ? 1 root root 2832 Sep ?6 11:32 squid1.conf
> > -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid17.conf
> > -rw-r--r-- ? 1 root root 2832 Sep ?6 11:31 squid4.conf
> > -rw-r--r-- ? 1 root root 2834 Sep ?6 11:31 squid21.conf
> > -rw-r--r-- ? 1 root root 2833 Sep ?6 11:31 squid25.conf
> > -rw-r--r-- ? 1 root root 2834 Sep ?6 11:31 squid12.conf
> > -rw-r--r-- ? 1 root root 2832 Sep ?6 11:31 squid3.conf
> > -rw-r--r-- ? 1 root root 2836 Sep ?6 11:30 squid10.conf
> > -rw-r--r-- ? 1 root root 2835 Sep ?6 11:30 squid11.conf
> > -rw-r--r-- ? 1 root root 2833 Sep ?6 11:30 squid18.conf
> > -rw-r--r-- ? 1 root root 2830 Sep ?6 11:30 squid8.conf
> > -rw-r--r-- ? 1 root root 2830 Sep ?6 11:30 squid6.conf
> > -rw-r--r-- ? 1 root root 2833 Sep ?6 11:30 squid28.conf
> > -rw-r--r-- ? 1 root root 2830 Sep ?6 11:25 squid9.conf
> > -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid24.conf
> > -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid22.conf
> > -rw-r--r-- ? 1 root root 2837 Sep ?6 11:25 squid20.conf
> > -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid16.conf
> > -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid15.conf
> > -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid14.conf
> > -rw-r--r-- ? 1 root root 2831 Sep ?6 11:25 squid5.conf
> > -rw-r--r-- ? 1 root root 2833 Sep ?6 11:25 squid27.conf
> > -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid26.conf
> > -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid30.conf
> > -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid29.conf
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220907/a07dbea2/attachment.htm>

From rousskov at measurement-factory.com  Wed Sep  7 00:45:13 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 6 Sep 2022 20:45:13 -0400
Subject: [squid-users] logfileHandleWrite:
 daemon:/var/log/squid/access.log: error writing ((32) Broken pipe)
In-Reply-To: <3dce10cb-9ed3-4176-bc70-5763ff9f7c67@Spark>
References: <CAGCa14q9QeX_fqH0bFPW5C8=Cpssbx8zgw0CWE-MLAEivkTSyw@mail.gmail.com>
 <171b0b23-7a59-b420-ac05-fcbdb02a213d@measurement-factory.com>
 <3dce10cb-9ed3-4176-bc70-5763ff9f7c67@Spark>
Message-ID: <95f8b8d3-c23e-93dd-f772-ae11133ed4b9@measurement-factory.com>

On 9/6/22 18:02, roee klinger wrote:
> it seems that the logs has filled over 100GB of log data, since I made a 
> configuration mistake (I think?) by setting this:
> 
>     logfile_rotate 0

This is correct setting when using an external log rotation tool like 
the logrotate daemon. More on that below.


> If I remember and read correctly, this means that the rotation of the 
> files is disabled and they will just keeping increasing
> in size if left unchecked.

To be more precise, this means that you are relying on an external tool 
to rename the log files. With this setting, Squid rotate command closes 
the access log and opens a new one (under the same name). While that 
might sound useless, it is the right (and necessary) thing for Squid to 
do when combined with the correct external log rotation setup.


> I have now gone ahead and changed all the configuration file to this 
> setting:
> 
>     logfile_rotate 1
> 
> So now it should rotate once daily, and on the next rotation it should 
> be deleted, and this is all handled by logrotate on Debian-based machines?

AFAIK, if you are using an external (to Squid) tool like logrotate, you 
should be setting logfile_rotate to zero.


> This is my / cat /etc/logrotate.d/squid:
> ? / cat /etc/logrotate.d/squid
> #
> # Logrotate fragment for squid.
> #
> /var/log/squid/*.log {
>  ?daily
>  ?compress
>  ?delaycompress
>  ?rotate 2
>  ?missingok
>  ?nocreate
>  ?sharedscripts
>  ?prerotate
>  ?test ! -x /usr/sbin/sarg-reports || /usr/sbin/sarg-reports daily
>  ?endscript
>  ?postrotate
>  ?test ! -e /var/run/squid.pid || test ! -x /usr/sbin/squid || 
> /usr/sbin/squid -k rotate
>  ?endscript
> }

This is not my area of expertise, but the above configuration does not 
look 100% correct to me: sarg-reports execution failures should have no 
effect on log rotation but does (AFAICT). There may be other problems 
(e.g., I do not know whether your /usr/sbin/squid finds the right Squid 
configuration file). I hope sysadmin experts on this mailing list will 
help you polish this.

You should be able to test whether the above is working (e.g., by asking 
logrotate to rotate). Testing is critical even if you do end up getting 
expert log rotation help on this list (this email is not it!).


HTH,

Alex.


> Is there a way for me to set it so it just get deleted every 24 or 12 
> hours without the archive first?
> 
> Thanks,
> Roee
> On 6 Sep 2022, 16:28 +0300, Alex Rousskov 
> <rousskov at measurement-factory.com>, wrote:
>> On 9/6/22 07:41, roee klinger wrote:
>>
>>> It is also important to know that I am running multiple Squid instances
>>> on the same machine, they are all getting the error at the same time
>>
>> What external event(s) happen at that time? Something is probably
>> sending a signal to the logging daemon process. It would be good to know
>> what that something (and that signal) is. Your syslog or cache.log might
>> contain more info. Analyzing the timing/schedule of these problems may
>> also be helpful in identifying the trigger.
>>
>>
>>> Is a possible workaround that might be just replacing the line with
>>> this?
>>
>>> access_log /var/log/squid/access2.log
>>
>> As you know, this configuration (in this deprecated spelling or with and
>> explicit "stdio:" prefix) will result in Squid workers writing to the
>> log file directly instead of asking the logging daemon. This will,
>> naturally, get rid of the pipe between workers and their daemons, and
>> the associated broken pipe error.
>>
>>> or will this cause a problem?
>>
>> Impossible to say for sure without knowing whether your workers benefit
>> from the anticipated performance advantages of avoiding blocking file
>> I/O _and_ whether those advantages are real (in your environment). Too
>> many variables and too many unknowns. I would treat this as an important
>> (and potentially disruptive) configuration change and carefully test the
>> outcome.
>>
>>
>> HTH,
>>
>> Alex.
>>
>>
>>> INFO -
>>> Versions:
>>>
>>> Squid Cache: Version 4.10
>>> Ubuntu 20.04.4 LTS
>>>
>>>
>>> Example squid.conf:
>>>
>>> visible_hostname squid2
>>>
>>> access_log daemon:/var/log/squid/access2.log squid
>>>
>>> cache_log /var/log/squid/cache2.log
>>>
>>> pid_filename /var/run/squid2.pid
>>>
>>>
>>> acl localnet src 0.0.0.1-0.255.255.255# RFC 1122 "this" network (LAN)
>>>
>>> acl localnet src 10.0.0.0/8 <http://10.0.0.0/8> # RFC 1918 local
>>> private network (LAN)
>>>
>>> acl localnet src 100.64.0.0/10 <http://100.64.0.0/10># RFC 6598
>>> shared address space (CGN)
>>>
>>> acl localnet src 169.254.0.0/16 <http://169.254.0.0/16> # RFC 3927
>>> link-local (directly plugged) machines
>>>
>>> acl localnet src 172.16.0.0/12 <http://172.16.0.0/12># RFC 1918
>>> local private network (LAN)
>>>
>>> acl localnet src 192.168.0.0/16 <http://192.168.0.0/16> # RFC 1918
>>> local private network (LAN)
>>>
>>> acl localnet src fc00::/7 # RFC 4193 local private network range
>>>
>>> acl localnet src fe80::/10# RFC 4291 link-local (directly plugged)
>>> machines
>>>
>>> acl SSL_ports port 443
>>>
>>> acl Safe_ports port 80# http
>>>
>>> acl Safe_ports port 21# ftp
>>>
>>> acl Safe_ports port 443 # https
>>>
>>> acl Safe_ports port 70# gopher
>>>
>>> acl Safe_ports port 210 # wais
>>>
>>> acl Safe_ports port 1025-65535# unregistered ports
>>>
>>> acl Safe_ports port 280 # http-mgmt
>>>
>>> acl Safe_ports port 488 # gss-http
>>>
>>> acl Safe_ports port 591 # filemaker
>>>
>>> acl Safe_ports port 777 # multiling http
>>>
>>> acl CONNECT method CONNECT
>>>
>>> http_access deny !Safe_ports
>>>
>>> http_access deny CONNECT !SSL_ports
>>>
>>> http_access allow localhost manager
>>>
>>> http_access deny manager
>>>
>>> # include /etc/squid/conf.d/*
>>>
>>> http_access allow localhost
>>>
>>> acl aws src *censored*
>>>
>>> http_access allow aws
>>>
>>> # http_access deny all
>>>
>>> tcp_outgoing_address *censored*
>>>
>>> http_port 10002
>>>
>>> coredump_dir /var/spool/squid
>>>
>>> refresh_pattern ^ftp: 144020% 10080
>>>
>>> refresh_pattern ^gopher:14400%1440
>>>
>>> refresh_pattern -i (/cgi-bin/|\?) 0 0%0
>>>
>>> refresh_pattern \/(Packages|Sources)(|\.bz2|\.gz|\.xz)$ 0 0% 0
>>> refresh-ims
>>>
>>> refresh_pattern \/Release(|\.gpg)$ 0 0% 0 refresh-ims
>>>
>>> refresh_pattern \/InRelease$ 0 0% 0 refresh-ims
>>>
>>> refresh_pattern \/(Translation-.*)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims
>>>
>>> refresh_pattern . 0 20% 4320
>>>
>>>
>>> shutdown_lifetime 1 seconds
>>>
>>> logfile_rotate 0
>>>
>>> max_filedescriptors 16384
>>>
>>> dns_nameservers 8.8.8.8 8.8.4.4 1.1.1.1
>>>
>>> cache deny all
>>>
>>> cache_dir null /tmp
>>>
>>> via off
>>>
>>> forwarded_for off
>>>
>>> request_header_access From deny all
>>>
>>> request_header_access Server deny all
>>>
>>> request_header_access WWW-Authenticate deny all
>>>
>>> request_header_access Link deny all
>>>
>>> request_header_access Cache-Control deny all
>>>
>>> request_header_access Proxy-Connection deny all
>>>
>>> request_header_access X-Cache deny all
>>>
>>> request_header_access X-Cache-Lookup deny all
>>>
>>> request_header_access Via deny all
>>>
>>> request_header_access X-Forwarded-For deny all
>>>
>>> request_header_access Pragma deny all
>>>
>>> request_header_access Keep-Alive deny all
>>>
>>> dns_v4_first on
>>>
>>>
>>> Example?service file:
>>>
>>> ## Copyright (C) 1996-2020 The Squid Software Foundation and
>>> contributors
>>>
>>> ##
>>>
>>> ## Squid software is distributed under GPLv2+ license and includes
>>>
>>> ## contributions from numerous individuals and organizations.
>>>
>>> ## Please see the COPYING and CONTRIBUTORS files for details.
>>>
>>> ##
>>>
>>>
>>> [Unit]
>>>
>>> Description=Squid Web Proxy Server
>>>
>>> Documentation=man:squid(8)
>>>
>>> After=network.target network-online.target nss-lookup.target
>>>
>>>
>>> [Service]
>>>
>>> Type=forking
>>>
>>> PIDFile=/var/run/squid2.pid
>>>
>>> ExecStartPre=/usr/sbin/squid --foreground -z -f /etc/squid/squid2.conf
>>>
>>> ExecStart=/usr/sbin/squid -sYC -f /etc/squid/squid2.conf
>>>
>>> ExecReload=/bin/kill -HUP $MAINPID
>>>
>>> KillMode=mixed
>>>
>>>
>>> [Install]
>>>
>>> WantedBy=multi-user.target
>>>
>>>
>>>
>>> Permissions:
>>>
>>> ?? ls -alt /etc/squid/
>>> total 128
>>> drwxr-xr-x ? 2 root root 4096 Sep ?6 11:33 .
>>> -rw-r--r-- ? 1 root root 2831 Sep ?6 11:33 squid7.conf
>>> drwxr-xr-x 116 root root 4096 Sep ?6 11:33 ..
>>> -rw-r--r-- ? 1 root root 2830 Sep ?6 11:33 squid2.conf
>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:33 squid13.conf
>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid23.conf
>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid19.conf
>>> -rw-r--r-- ? 1 root root 2832 Sep ?6 11:32 squid1.conf
>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid17.conf
>>> -rw-r--r-- ? 1 root root 2832 Sep ?6 11:31 squid4.conf
>>> -rw-r--r-- ? 1 root root 2834 Sep ?6 11:31 squid21.conf
>>> -rw-r--r-- ? 1 root root 2833 Sep ?6 11:31 squid25.conf
>>> -rw-r--r-- ? 1 root root 2834 Sep ?6 11:31 squid12.conf
>>> -rw-r--r-- ? 1 root root 2832 Sep ?6 11:31 squid3.conf
>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:30 squid10.conf
>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:30 squid11.conf
>>> -rw-r--r-- ? 1 root root 2833 Sep ?6 11:30 squid18.conf
>>> -rw-r--r-- ? 1 root root 2830 Sep ?6 11:30 squid8.conf
>>> -rw-r--r-- ? 1 root root 2830 Sep ?6 11:30 squid6.conf
>>> -rw-r--r-- ? 1 root root 2833 Sep ?6 11:30 squid28.conf
>>> -rw-r--r-- ? 1 root root 2830 Sep ?6 11:25 squid9.conf
>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid24.conf
>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid22.conf
>>> -rw-r--r-- ? 1 root root 2837 Sep ?6 11:25 squid20.conf
>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid16.conf
>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid15.conf
>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid14.conf
>>> -rw-r--r-- ? 1 root root 2831 Sep ?6 11:25 squid5.conf
>>> -rw-r--r-- ? 1 root root 2833 Sep ?6 11:25 squid27.conf
>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid26.conf
>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid30.conf
>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid29.conf
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Wed Sep  7 00:53:48 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 6 Sep 2022 20:53:48 -0400
Subject: [squid-users] logfileHandleWrite:
 daemon:/var/log/squid/access.log: error writing ((32) Broken pipe)
In-Reply-To: <95f8b8d3-c23e-93dd-f772-ae11133ed4b9@measurement-factory.com>
References: <CAGCa14q9QeX_fqH0bFPW5C8=Cpssbx8zgw0CWE-MLAEivkTSyw@mail.gmail.com>
 <171b0b23-7a59-b420-ac05-fcbdb02a213d@measurement-factory.com>
 <3dce10cb-9ed3-4176-bc70-5763ff9f7c67@Spark>
 <95f8b8d3-c23e-93dd-f772-ae11133ed4b9@measurement-factory.com>
Message-ID: <80a8a3e2-6650-dd9e-e147-e19a43606d40@measurement-factory.com>

 > pid_filename /var/run/squid2.pid

 >   postrotate
 >   test ! -e /var/run/squid.pid || ... /usr/sbin/squid -k rotate
 >   endscript

I spotted one more (potentially critical) problem: Your Squid 
configuration sets pid_filename to /var/run/squid2.pid but your 
logrotate configuration assumes Squid uses /var/run/squid.pid.

IMHO, in general, it is best not to guess where Squid has its PID if you 
are using "squid -k ...". If you want to test whether Squid is currently 
running, try using "squid -k check" instead.


HTH,

Alex.



On 9/6/22 20:45, Alex Rousskov wrote:
> On 9/6/22 18:02, roee klinger wrote:
>> it seems that the logs has filled over 100GB of log data, since I made 
>> a configuration mistake (I think?) by setting this:
>>
>> ??? logfile_rotate 0
> 
> This is correct setting when using an external log rotation tool like 
> the logrotate daemon. More on that below.
> 
> 
>> If I remember and read correctly, this means that the rotation of the 
>> files is disabled and they will just keeping increasing
>> in size if left unchecked.
> 
> To be more precise, this means that you are relying on an external tool 
> to rename the log files. With this setting, Squid rotate command closes 
> the access log and opens a new one (under the same name). While that 
> might sound useless, it is the right (and necessary) thing for Squid to 
> do when combined with the correct external log rotation setup.
> 
> 
>> I have now gone ahead and changed all the configuration file to this 
>> setting:
>>
>> ??? logfile_rotate 1
>>
>> So now it should rotate once daily, and on the next rotation it should 
>> be deleted, and this is all handled by logrotate on Debian-based 
>> machines?
> 
> AFAIK, if you are using an external (to Squid) tool like logrotate, you 
> should be setting logfile_rotate to zero.
> 
> 
>> This is my / cat /etc/logrotate.d/squid:
>> ? / cat /etc/logrotate.d/squid
>> #
>> # Logrotate fragment for squid.
>> #
>> /var/log/squid/*.log {
>> ??daily
>> ??compress
>> ??delaycompress
>> ??rotate 2
>> ??missingok
>> ??nocreate
>> ??sharedscripts
>> ??prerotate
>> ??test ! -x /usr/sbin/sarg-reports || /usr/sbin/sarg-reports daily
>> ??endscript
>> ??postrotate
>> ??test ! -e /var/run/squid.pid || test ! -x /usr/sbin/squid || 
>> /usr/sbin/squid -k rotate
>> ??endscript
>> }
> 
> This is not my area of expertise, but the above configuration does not 
> look 100% correct to me: sarg-reports execution failures should have no 
> effect on log rotation but does (AFAICT). There may be other problems 
> (e.g., I do not know whether your /usr/sbin/squid finds the right Squid 
> configuration file). I hope sysadmin experts on this mailing list will 
> help you polish this.
> 
> You should be able to test whether the above is working (e.g., by asking 
> logrotate to rotate). Testing is critical even if you do end up getting 
> expert log rotation help on this list (this email is not it!).
> 
> 
> HTH,
> 
> Alex.
> 
> 
>> Is there a way for me to set it so it just get deleted every 24 or 12 
>> hours without the archive first?
>>
>> Thanks,
>> Roee
>> On 6 Sep 2022, 16:28 +0300, Alex Rousskov 
>> <rousskov at measurement-factory.com>, wrote:
>>> On 9/6/22 07:41, roee klinger wrote:
>>>
>>>> It is also important to know that I am running multiple Squid instances
>>>> on the same machine, they are all getting the error at the same time
>>>
>>> What external event(s) happen at that time? Something is probably
>>> sending a signal to the logging daemon process. It would be good to know
>>> what that something (and that signal) is. Your syslog or cache.log might
>>> contain more info. Analyzing the timing/schedule of these problems may
>>> also be helpful in identifying the trigger.
>>>
>>>
>>>> Is a possible workaround that might be just replacing the line with
>>>> this?
>>>
>>>> access_log /var/log/squid/access2.log
>>>
>>> As you know, this configuration (in this deprecated spelling or with and
>>> explicit "stdio:" prefix) will result in Squid workers writing to the
>>> log file directly instead of asking the logging daemon. This will,
>>> naturally, get rid of the pipe between workers and their daemons, and
>>> the associated broken pipe error.
>>>
>>>> or will this cause a problem?
>>>
>>> Impossible to say for sure without knowing whether your workers benefit
>>> from the anticipated performance advantages of avoiding blocking file
>>> I/O _and_ whether those advantages are real (in your environment). Too
>>> many variables and too many unknowns. I would treat this as an important
>>> (and potentially disruptive) configuration change and carefully test the
>>> outcome.
>>>
>>>
>>> HTH,
>>>
>>> Alex.
>>>
>>>
>>>> INFO -
>>>> Versions:
>>>>
>>>> Squid Cache: Version 4.10
>>>> Ubuntu 20.04.4 LTS
>>>>
>>>>
>>>> Example squid.conf:
>>>>
>>>> visible_hostname squid2
>>>>
>>>> access_log daemon:/var/log/squid/access2.log squid
>>>>
>>>> cache_log /var/log/squid/cache2.log
>>>>
>>>> pid_filename /var/run/squid2.pid
>>>>
>>>>
>>>> acl localnet src 0.0.0.1-0.255.255.255# RFC 1122 "this" network (LAN)
>>>>
>>>> acl localnet src 10.0.0.0/8 <http://10.0.0.0/8> # RFC 1918 local
>>>> private network (LAN)
>>>>
>>>> acl localnet src 100.64.0.0/10 <http://100.64.0.0/10># RFC 6598
>>>> shared address space (CGN)
>>>>
>>>> acl localnet src 169.254.0.0/16 <http://169.254.0.0/16> # RFC 3927
>>>> link-local (directly plugged) machines
>>>>
>>>> acl localnet src 172.16.0.0/12 <http://172.16.0.0/12># RFC 1918
>>>> local private network (LAN)
>>>>
>>>> acl localnet src 192.168.0.0/16 <http://192.168.0.0/16> # RFC 1918
>>>> local private network (LAN)
>>>>
>>>> acl localnet src fc00::/7 # RFC 4193 local private network range
>>>>
>>>> acl localnet src fe80::/10# RFC 4291 link-local (directly plugged)
>>>> machines
>>>>
>>>> acl SSL_ports port 443
>>>>
>>>> acl Safe_ports port 80# http
>>>>
>>>> acl Safe_ports port 21# ftp
>>>>
>>>> acl Safe_ports port 443 # https
>>>>
>>>> acl Safe_ports port 70# gopher
>>>>
>>>> acl Safe_ports port 210 # wais
>>>>
>>>> acl Safe_ports port 1025-65535# unregistered ports
>>>>
>>>> acl Safe_ports port 280 # http-mgmt
>>>>
>>>> acl Safe_ports port 488 # gss-http
>>>>
>>>> acl Safe_ports port 591 # filemaker
>>>>
>>>> acl Safe_ports port 777 # multiling http
>>>>
>>>> acl CONNECT method CONNECT
>>>>
>>>> http_access deny !Safe_ports
>>>>
>>>> http_access deny CONNECT !SSL_ports
>>>>
>>>> http_access allow localhost manager
>>>>
>>>> http_access deny manager
>>>>
>>>> # include /etc/squid/conf.d/*
>>>>
>>>> http_access allow localhost
>>>>
>>>> acl aws src *censored*
>>>>
>>>> http_access allow aws
>>>>
>>>> # http_access deny all
>>>>
>>>> tcp_outgoing_address *censored*
>>>>
>>>> http_port 10002
>>>>
>>>> coredump_dir /var/spool/squid
>>>>
>>>> refresh_pattern ^ftp: 144020% 10080
>>>>
>>>> refresh_pattern ^gopher:14400%1440
>>>>
>>>> refresh_pattern -i (/cgi-bin/|\?) 0 0%0
>>>>
>>>> refresh_pattern \/(Packages|Sources)(|\.bz2|\.gz|\.xz)$ 0 0% 0
>>>> refresh-ims
>>>>
>>>> refresh_pattern \/Release(|\.gpg)$ 0 0% 0 refresh-ims
>>>>
>>>> refresh_pattern \/InRelease$ 0 0% 0 refresh-ims
>>>>
>>>> refresh_pattern \/(Translation-.*)(|\.bz2|\.gz|\.xz)$ 0 0% 0 
>>>> refresh-ims
>>>>
>>>> refresh_pattern . 0 20% 4320
>>>>
>>>>
>>>> shutdown_lifetime 1 seconds
>>>>
>>>> logfile_rotate 0
>>>>
>>>> max_filedescriptors 16384
>>>>
>>>> dns_nameservers 8.8.8.8 8.8.4.4 1.1.1.1
>>>>
>>>> cache deny all
>>>>
>>>> cache_dir null /tmp
>>>>
>>>> via off
>>>>
>>>> forwarded_for off
>>>>
>>>> request_header_access From deny all
>>>>
>>>> request_header_access Server deny all
>>>>
>>>> request_header_access WWW-Authenticate deny all
>>>>
>>>> request_header_access Link deny all
>>>>
>>>> request_header_access Cache-Control deny all
>>>>
>>>> request_header_access Proxy-Connection deny all
>>>>
>>>> request_header_access X-Cache deny all
>>>>
>>>> request_header_access X-Cache-Lookup deny all
>>>>
>>>> request_header_access Via deny all
>>>>
>>>> request_header_access X-Forwarded-For deny all
>>>>
>>>> request_header_access Pragma deny all
>>>>
>>>> request_header_access Keep-Alive deny all
>>>>
>>>> dns_v4_first on
>>>>
>>>>
>>>> Example?service file:
>>>>
>>>> ## Copyright (C) 1996-2020 The Squid Software Foundation and
>>>> contributors
>>>>
>>>> ##
>>>>
>>>> ## Squid software is distributed under GPLv2+ license and includes
>>>>
>>>> ## contributions from numerous individuals and organizations.
>>>>
>>>> ## Please see the COPYING and CONTRIBUTORS files for details.
>>>>
>>>> ##
>>>>
>>>>
>>>> [Unit]
>>>>
>>>> Description=Squid Web Proxy Server
>>>>
>>>> Documentation=man:squid(8)
>>>>
>>>> After=network.target network-online.target nss-lookup.target
>>>>
>>>>
>>>> [Service]
>>>>
>>>> Type=forking
>>>>
>>>> PIDFile=/var/run/squid2.pid
>>>>
>>>> ExecStartPre=/usr/sbin/squid --foreground -z -f /etc/squid/squid2.conf
>>>>
>>>> ExecStart=/usr/sbin/squid -sYC -f /etc/squid/squid2.conf
>>>>
>>>> ExecReload=/bin/kill -HUP $MAINPID
>>>>
>>>> KillMode=mixed
>>>>
>>>>
>>>> [Install]
>>>>
>>>> WantedBy=multi-user.target
>>>>
>>>>
>>>>
>>>> Permissions:
>>>>
>>>> ?? ls -alt /etc/squid/
>>>> total 128
>>>> drwxr-xr-x ? 2 root root 4096 Sep ?6 11:33 .
>>>> -rw-r--r-- ? 1 root root 2831 Sep ?6 11:33 squid7.conf
>>>> drwxr-xr-x 116 root root 4096 Sep ?6 11:33 ..
>>>> -rw-r--r-- ? 1 root root 2830 Sep ?6 11:33 squid2.conf
>>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:33 squid13.conf
>>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid23.conf
>>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid19.conf
>>>> -rw-r--r-- ? 1 root root 2832 Sep ?6 11:32 squid1.conf
>>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid17.conf
>>>> -rw-r--r-- ? 1 root root 2832 Sep ?6 11:31 squid4.conf
>>>> -rw-r--r-- ? 1 root root 2834 Sep ?6 11:31 squid21.conf
>>>> -rw-r--r-- ? 1 root root 2833 Sep ?6 11:31 squid25.conf
>>>> -rw-r--r-- ? 1 root root 2834 Sep ?6 11:31 squid12.conf
>>>> -rw-r--r-- ? 1 root root 2832 Sep ?6 11:31 squid3.conf
>>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:30 squid10.conf
>>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:30 squid11.conf
>>>> -rw-r--r-- ? 1 root root 2833 Sep ?6 11:30 squid18.conf
>>>> -rw-r--r-- ? 1 root root 2830 Sep ?6 11:30 squid8.conf
>>>> -rw-r--r-- ? 1 root root 2830 Sep ?6 11:30 squid6.conf
>>>> -rw-r--r-- ? 1 root root 2833 Sep ?6 11:30 squid28.conf
>>>> -rw-r--r-- ? 1 root root 2830 Sep ?6 11:25 squid9.conf
>>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid24.conf
>>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid22.conf
>>>> -rw-r--r-- ? 1 root root 2837 Sep ?6 11:25 squid20.conf
>>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid16.conf
>>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid15.conf
>>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid14.conf
>>>> -rw-r--r-- ? 1 root root 2831 Sep ?6 11:25 squid5.conf
>>>> -rw-r--r-- ? 1 root root 2833 Sep ?6 11:25 squid27.conf
>>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid26.conf
>>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid30.conf
>>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid29.conf
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From ngtech1ltd at gmail.com  Wed Sep  7 16:26:40 2022
From: ngtech1ltd at gmail.com (NgTech LTD)
Date: Wed, 7 Sep 2022 19:26:40 +0300
Subject: [squid-users] logfileHandleWrite:
 daemon:/var/log/squid/access.log: error writing ((32) Broken pipe)
In-Reply-To: <80a8a3e2-6650-dd9e-e147-e19a43606d40@measurement-factory.com>
References: <CAGCa14q9QeX_fqH0bFPW5C8=Cpssbx8zgw0CWE-MLAEivkTSyw@mail.gmail.com>
 <171b0b23-7a59-b420-ac05-fcbdb02a213d@measurement-factory.com>
 <3dce10cb-9ed3-4176-bc70-5763ff9f7c67@Spark>
 <95f8b8d3-c23e-93dd-f772-ae11133ed4b9@measurement-factory.com>
 <80a8a3e2-6650-dd9e-e147-e19a43606d40@measurement-factory.com>
Message-ID: <CABA8h=SqKQeNvp4By1dyNX+MDq3qz4ShbW=2Ur+DvN5pMjp=Uw@mail.gmail.com>

Good one, Alex.

For this specific use case you need a special rotate script which will know
the confs file and will loop over them.
Later on I will try to see if yave one of these on my servers.
Basically you will need an array of config files and loop on them.

The pid shouldn't be relevevant for a rotate operation but it depends on
the nature of the system.(on a 24/7 system you should know about a service
that is down way before the logrotate happpens)
If you have a set of config files you can generate a set of postrotate
commands compared to a special script.

Let me know if this solution might fit for your use case.

Eliezer

?????? ??? ??, 7 ????? 2022, 3:53, ??? Alex Rousskov ?<
rousskov at measurement-factory.com>:

>  > pid_filename /var/run/squid2.pid
>
>  >   postrotate
>  >   test ! -e /var/run/squid.pid || ... /usr/sbin/squid -k rotate
>  >   endscript
>
> I spotted one more (potentially critical) problem: Your Squid
> configuration sets pid_filename to /var/run/squid2.pid but your
> logrotate configuration assumes Squid uses /var/run/squid.pid.
>
> IMHO, in general, it is best not to guess where Squid has its PID if you
> are using "squid -k ...". If you want to test whether Squid is currently
> running, try using "squid -k check" instead.
>
>
> HTH,
>
> Alex.
>
>
>
> On 9/6/22 20:45, Alex Rousskov wrote:
> > On 9/6/22 18:02, roee klinger wrote:
> >> it seems that the logs has filled over 100GB of log data, since I made
> >> a configuration mistake (I think?) by setting this:
> >>
> >>     logfile_rotate 0
> >
> > This is correct setting when using an external log rotation tool like
> > the logrotate daemon. More on that below.
> >
> >
> >> If I remember and read correctly, this means that the rotation of the
> >> files is disabled and they will just keeping increasing
> >> in size if left unchecked.
> >
> > To be more precise, this means that you are relying on an external tool
> > to rename the log files. With this setting, Squid rotate command closes
> > the access log and opens a new one (under the same name). While that
> > might sound useless, it is the right (and necessary) thing for Squid to
> > do when combined with the correct external log rotation setup.
> >
> >
> >> I have now gone ahead and changed all the configuration file to this
> >> setting:
> >>
> >>     logfile_rotate 1
> >>
> >> So now it should rotate once daily, and on the next rotation it should
> >> be deleted, and this is all handled by logrotate on Debian-based
> >> machines?
> >
> > AFAIK, if you are using an external (to Squid) tool like logrotate, you
> > should be setting logfile_rotate to zero.
> >
> >
> >> This is my / cat /etc/logrotate.d/squid:
> >> ? / cat /etc/logrotate.d/squid
> >> #
> >> # Logrotate fragment for squid.
> >> #
> >> /var/log/squid/*.log {
> >>   daily
> >>   compress
> >>   delaycompress
> >>   rotate 2
> >>   missingok
> >>   nocreate
> >>   sharedscripts
> >>   prerotate
> >>   test ! -x /usr/sbin/sarg-reports || /usr/sbin/sarg-reports daily
> >>   endscript
> >>   postrotate
> >>   test ! -e /var/run/squid.pid || test ! -x /usr/sbin/squid ||
> >> /usr/sbin/squid -k rotate
> >>   endscript
> >> }
> >
> > This is not my area of expertise, but the above configuration does not
> > look 100% correct to me: sarg-reports execution failures should have no
> > effect on log rotation but does (AFAICT). There may be other problems
> > (e.g., I do not know whether your /usr/sbin/squid finds the right Squid
> > configuration file). I hope sysadmin experts on this mailing list will
> > help you polish this.
> >
> > You should be able to test whether the above is working (e.g., by asking
> > logrotate to rotate). Testing is critical even if you do end up getting
> > expert log rotation help on this list (this email is not it!).
> >
> >
> > HTH,
> >
> > Alex.
> >
> >
> >> Is there a way for me to set it so it just get deleted every 24 or 12
> >> hours without the archive first?
> >>
> >> Thanks,
> >> Roee
> >> On 6 Sep 2022, 16:28 +0300, Alex Rousskov
> >> <rousskov at measurement-factory.com>, wrote:
> >>> On 9/6/22 07:41, roee klinger wrote:
> >>>
> >>>> It is also important to know that I am running multiple Squid
> instances
> >>>> on the same machine, they are all getting the error at the same time
> >>>
> >>> What external event(s) happen at that time? Something is probably
> >>> sending a signal to the logging daemon process. It would be good to
> know
> >>> what that something (and that signal) is. Your syslog or cache.log
> might
> >>> contain more info. Analyzing the timing/schedule of these problems may
> >>> also be helpful in identifying the trigger.
> >>>
> >>>
> >>>> Is a possible workaround that might be just replacing the line with
> >>>> this?
> >>>
> >>>> access_log /var/log/squid/access2.log
> >>>
> >>> As you know, this configuration (in this deprecated spelling or with
> and
> >>> explicit "stdio:" prefix) will result in Squid workers writing to the
> >>> log file directly instead of asking the logging daemon. This will,
> >>> naturally, get rid of the pipe between workers and their daemons, and
> >>> the associated broken pipe error.
> >>>
> >>>> or will this cause a problem?
> >>>
> >>> Impossible to say for sure without knowing whether your workers benefit
> >>> from the anticipated performance advantages of avoiding blocking file
> >>> I/O _and_ whether those advantages are real (in your environment). Too
> >>> many variables and too many unknowns. I would treat this as an
> important
> >>> (and potentially disruptive) configuration change and carefully test
> the
> >>> outcome.
> >>>
> >>>
> >>> HTH,
> >>>
> >>> Alex.
> >>>
> >>>
> >>>> INFO -
> >>>> Versions:
> >>>>
> >>>> Squid Cache: Version 4.10
> >>>> Ubuntu 20.04.4 LTS
> >>>>
> >>>>
> >>>> Example squid.conf:
> >>>>
> >>>> visible_hostname squid2
> >>>>
> >>>> access_log daemon:/var/log/squid/access2.log squid
> >>>>
> >>>> cache_log /var/log/squid/cache2.log
> >>>>
> >>>> pid_filename /var/run/squid2.pid
> >>>>
> >>>>
> >>>> acl localnet src 0.0.0.1-0.255.255.255# RFC 1122 "this" network (LAN)
> >>>>
> >>>> acl localnet src 10.0.0.0/8 <http://10.0.0.0/8> # RFC 1918 local
> >>>> private network (LAN)
> >>>>
> >>>> acl localnet src 100.64.0.0/10 <http://100.64.0.0/10># RFC 6598
> >>>> shared address space (CGN)
> >>>>
> >>>> acl localnet src 169.254.0.0/16 <http://169.254.0.0/16> # RFC 3927
> >>>> link-local (directly plugged) machines
> >>>>
> >>>> acl localnet src 172.16.0.0/12 <http://172.16.0.0/12># RFC 1918
> >>>> local private network (LAN)
> >>>>
> >>>> acl localnet src 192.168.0.0/16 <http://192.168.0.0/16> # RFC 1918
> >>>> local private network (LAN)
> >>>>
> >>>> acl localnet src fc00::/7 # RFC 4193 local private network range
> >>>>
> >>>> acl localnet src fe80::/10# RFC 4291 link-local (directly plugged)
> >>>> machines
> >>>>
> >>>> acl SSL_ports port 443
> >>>>
> >>>> acl Safe_ports port 80# http
> >>>>
> >>>> acl Safe_ports port 21# ftp
> >>>>
> >>>> acl Safe_ports port 443 # https
> >>>>
> >>>> acl Safe_ports port 70# gopher
> >>>>
> >>>> acl Safe_ports port 210 # wais
> >>>>
> >>>> acl Safe_ports port 1025-65535# unregistered ports
> >>>>
> >>>> acl Safe_ports port 280 # http-mgmt
> >>>>
> >>>> acl Safe_ports port 488 # gss-http
> >>>>
> >>>> acl Safe_ports port 591 # filemaker
> >>>>
> >>>> acl Safe_ports port 777 # multiling http
> >>>>
> >>>> acl CONNECT method CONNECT
> >>>>
> >>>> http_access deny !Safe_ports
> >>>>
> >>>> http_access deny CONNECT !SSL_ports
> >>>>
> >>>> http_access allow localhost manager
> >>>>
> >>>> http_access deny manager
> >>>>
> >>>> # include /etc/squid/conf.d/*
> >>>>
> >>>> http_access allow localhost
> >>>>
> >>>> acl aws src *censored*
> >>>>
> >>>> http_access allow aws
> >>>>
> >>>> # http_access deny all
> >>>>
> >>>> tcp_outgoing_address *censored*
> >>>>
> >>>> http_port 10002
> >>>>
> >>>> coredump_dir /var/spool/squid
> >>>>
> >>>> refresh_pattern ^ftp: 144020% 10080
> >>>>
> >>>> refresh_pattern ^gopher:14400%1440
> >>>>
> >>>> refresh_pattern -i (/cgi-bin/|\?) 0 0%0
> >>>>
> >>>> refresh_pattern \/(Packages|Sources)(|\.bz2|\.gz|\.xz)$ 0 0% 0
> >>>> refresh-ims
> >>>>
> >>>> refresh_pattern \/Release(|\.gpg)$ 0 0% 0 refresh-ims
> >>>>
> >>>> refresh_pattern \/InRelease$ 0 0% 0 refresh-ims
> >>>>
> >>>> refresh_pattern \/(Translation-.*)(|\.bz2|\.gz|\.xz)$ 0 0% 0
> >>>> refresh-ims
> >>>>
> >>>> refresh_pattern . 0 20% 4320
> >>>>
> >>>>
> >>>> shutdown_lifetime 1 seconds
> >>>>
> >>>> logfile_rotate 0
> >>>>
> >>>> max_filedescriptors 16384
> >>>>
> >>>> dns_nameservers 8.8.8.8 8.8.4.4 1.1.1.1
> >>>>
> >>>> cache deny all
> >>>>
> >>>> cache_dir null /tmp
> >>>>
> >>>> via off
> >>>>
> >>>> forwarded_for off
> >>>>
> >>>> request_header_access From deny all
> >>>>
> >>>> request_header_access Server deny all
> >>>>
> >>>> request_header_access WWW-Authenticate deny all
> >>>>
> >>>> request_header_access Link deny all
> >>>>
> >>>> request_header_access Cache-Control deny all
> >>>>
> >>>> request_header_access Proxy-Connection deny all
> >>>>
> >>>> request_header_access X-Cache deny all
> >>>>
> >>>> request_header_access X-Cache-Lookup deny all
> >>>>
> >>>> request_header_access Via deny all
> >>>>
> >>>> request_header_access X-Forwarded-For deny all
> >>>>
> >>>> request_header_access Pragma deny all
> >>>>
> >>>> request_header_access Keep-Alive deny all
> >>>>
> >>>> dns_v4_first on
> >>>>
> >>>>
> >>>> Example service file:
> >>>>
> >>>> ## Copyright (C) 1996-2020 The Squid Software Foundation and
> >>>> contributors
> >>>>
> >>>> ##
> >>>>
> >>>> ## Squid software is distributed under GPLv2+ license and includes
> >>>>
> >>>> ## contributions from numerous individuals and organizations.
> >>>>
> >>>> ## Please see the COPYING and CONTRIBUTORS files for details.
> >>>>
> >>>> ##
> >>>>
> >>>>
> >>>> [Unit]
> >>>>
> >>>> Description=Squid Web Proxy Server
> >>>>
> >>>> Documentation=man:squid(8)
> >>>>
> >>>> After=network.target network-online.target nss-lookup.target
> >>>>
> >>>>
> >>>> [Service]
> >>>>
> >>>> Type=forking
> >>>>
> >>>> PIDFile=/var/run/squid2.pid
> >>>>
> >>>> ExecStartPre=/usr/sbin/squid --foreground -z -f /etc/squid/squid2.conf
> >>>>
> >>>> ExecStart=/usr/sbin/squid -sYC -f /etc/squid/squid2.conf
> >>>>
> >>>> ExecReload=/bin/kill -HUP $MAINPID
> >>>>
> >>>> KillMode=mixed
> >>>>
> >>>>
> >>>> [Install]
> >>>>
> >>>> WantedBy=multi-user.target
> >>>>
> >>>>
> >>>>
> >>>> Permissions:
> >>>>
> >>>> ?  ls -alt /etc/squid/
> >>>> total 128
> >>>> drwxr-xr-x   2 root root 4096 Sep  6 11:33 .
> >>>> -rw-r--r--   1 root root 2831 Sep  6 11:33 squid7.conf
> >>>> drwxr-xr-x 116 root root 4096 Sep  6 11:33 ..
> >>>> -rw-r--r--   1 root root 2830 Sep  6 11:33 squid2.conf
> >>>> -rw-r--r--   1 root root 2836 Sep  6 11:33 squid13.conf
> >>>> -rw-r--r--   1 root root 2836 Sep  6 11:32 squid23.conf
> >>>> -rw-r--r--   1 root root 2836 Sep  6 11:32 squid19.conf
> >>>> -rw-r--r--   1 root root 2832 Sep  6 11:32 squid1.conf
> >>>> -rw-r--r--   1 root root 2836 Sep  6 11:32 squid17.conf
> >>>> -rw-r--r--   1 root root 2832 Sep  6 11:31 squid4.conf
> >>>> -rw-r--r--   1 root root 2834 Sep  6 11:31 squid21.conf
> >>>> -rw-r--r--   1 root root 2833 Sep  6 11:31 squid25.conf
> >>>> -rw-r--r--   1 root root 2834 Sep  6 11:31 squid12.conf
> >>>> -rw-r--r--   1 root root 2832 Sep  6 11:31 squid3.conf
> >>>> -rw-r--r--   1 root root 2836 Sep  6 11:30 squid10.conf
> >>>> -rw-r--r--   1 root root 2835 Sep  6 11:30 squid11.conf
> >>>> -rw-r--r--   1 root root 2833 Sep  6 11:30 squid18.conf
> >>>> -rw-r--r--   1 root root 2830 Sep  6 11:30 squid8.conf
> >>>> -rw-r--r--   1 root root 2830 Sep  6 11:30 squid6.conf
> >>>> -rw-r--r--   1 root root 2833 Sep  6 11:30 squid28.conf
> >>>> -rw-r--r--   1 root root 2830 Sep  6 11:25 squid9.conf
> >>>> -rw-r--r--   1 root root 2836 Sep  6 11:25 squid24.conf
> >>>> -rw-r--r--   1 root root 2835 Sep  6 11:25 squid22.conf
> >>>> -rw-r--r--   1 root root 2837 Sep  6 11:25 squid20.conf
> >>>> -rw-r--r--   1 root root 2836 Sep  6 11:25 squid16.conf
> >>>> -rw-r--r--   1 root root 2835 Sep  6 11:25 squid15.conf
> >>>> -rw-r--r--   1 root root 2836 Sep  6 11:25 squid14.conf
> >>>> -rw-r--r--   1 root root 2831 Sep  6 11:25 squid5.conf
> >>>> -rw-r--r--   1 root root 2833 Sep  6 11:25 squid27.conf
> >>>> -rw-r--r--   1 root root 2835 Sep  6 11:25 squid26.conf
> >>>> -rw-r--r--   1 root root 2835 Sep  6 11:25 squid30.conf
> >>>> -rw-r--r--   1 root root 2835 Sep  6 11:25 squid29.conf
> >>>>
> >>>>
> >>>> _______________________________________________
> >>>> squid-users mailing list
> >>>> squid-users at lists.squid-cache.org
> >>>> http://lists.squid-cache.org/listinfo/squid-users
> >>>
> >>> _______________________________________________
> >>> squid-users mailing list
> >>> squid-users at lists.squid-cache.org
> >>> http://lists.squid-cache.org/listinfo/squid-users
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220907/bcae7f38/attachment.htm>

From marcelorodrigo at graminsta.com.br  Wed Sep  7 21:28:47 2022
From: marcelorodrigo at graminsta.com.br (Marcelo)
Date: Wed, 7 Sep 2022 18:28:47 -0300
Subject: [squid-users] Failover using Cache Peer feature.
Message-ID: <003901d8c300$d3007af0$790170d0$@graminsta.com.br>

Hi,

 

Is there a way to use Cache Peer feature to send traffic to Squid number 2
if Squid number 1 does not respond in N seconds?

 

Best Regards,

 

Marcelo.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220907/01ece9ca/attachment.htm>

From rousskov at measurement-factory.com  Thu Sep  8 02:25:59 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 7 Sep 2022 22:25:59 -0400
Subject: [squid-users] Failover using Cache Peer feature.
In-Reply-To: <003901d8c300$d3007af0$790170d0$@graminsta.com.br>
References: <003901d8c300$d3007af0$790170d0$@graminsta.com.br>
Message-ID: <1d611f32-e3d0-9d5c-1b42-301e72261739@measurement-factory.com>

On 9/7/22 17:28, Marcelo wrote:

> Is there a way to use Cache Peer feature to send traffic to Squid number 
> 2 if Squid number 1 does not respond in N seconds?

The correct answer probably depends on your definition of "respond" but 
see if the cache_peer connect-timeout option[1] is what you are looking 
for. That option defines "respond" as "establish a TCP connection with 
that peer known IP address". You probably want to mark those peers as 
parents and use the "first-up" peer selection algorithm[2] (which is the 
default).

[1] http://www.squid-cache.org/Doc/config/cache_peer/
[2] https://wiki.squid-cache.org/Features/LoadBalance#First-Up_Parent


HTH,

Alex.


From marek.gresko at protonmail.com  Thu Sep  8 07:13:04 2022
From: marek.gresko at protonmail.com (=?utf-8?Q?Marek_Gre=C5=A1ko?=)
Date: Thu, 08 Sep 2022 07:13:04 +0000
Subject: [squid-users] Unwanted authentication requests
Message-ID: <qcRVW_0gtCSQwAm3fLUNjgjDDMwYp_G96UV5aQvJ60Nc18sC2P1aZwYJY_Xzn_EMc1Av6l9sAjIOY7bZ5c0AO0kNW_TXeWXf8lS1SsXOgSE=@protonmail.com>

Hello,

I have a setup that users in one vlan use kerberos authentication to the squid and users in second vlan are not kerberos aware. They are either allowed by ip address or use basic authentication. This setup was working quite well for a long time. Time to time users on the kerberos aware vlan got basic auth request which after pressing cancel disappeared. This happened maybe once a month without apparent reason.

But nowadays I observe the basic auth on the kerberos aware vlan very often without any change to policy. When looking into the logs it seems it is related to these logs:

NONE_NONE/000 0 - error:transaction-end-before-headers - HIER_NONE/- -

It seems the after connection crash brower receives another auth request and it thinks the kerberos was not successful and tries basic auth.

Is there some way to limit the use of basic auth only to the users on the second vlan and not present it to the users on the first vlan and vice versa? Or am I doing something wrong? Or do you have some suggestion what could happen that it appears so frequently now? Squid proxy update? Browser update (firefox)? I am using Fedora 36 with latest updates on both server and client when this happens.

I worked with Bluecoat proxies in the past and if I remember well there was separate policy layer for authentication. I cannot find such a thing in the squid proxy.

Thanks for suggestions.

Marek
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220908/acfb35ce/attachment.htm>

From hfasching at barracuda.com  Thu Sep  8 07:40:09 2022
From: hfasching at barracuda.com (Hannes Fasching)
Date: Thu, 8 Sep 2022 07:40:09 +0000
Subject: [squid-users] Exchange server authentication via squid reverse
 proxy not working after upgrade from squid 4.15 to 5.6
Message-ID: <DM6PR10MB3740189C7803EC2C750365E6B3409@DM6PR10MB3740.namprd10.prod.outlook.com>

Hello,
A customer have an issue that after upgrading from squid 4.15 to actual 5.6 with reverse proxy mode for an exchange server.
The authentication is not working anymore when the integrated Windows authentication is enabled (needed for SSO). When disabled, the authentication via squid is then working.
The difference is that Windows with integrated authentication is trying several authentication schemes otherwise only Basic authentication is used.
Please follow the link to see the squid.conf and the cache log file starting with the attempt when it fails and afterwards, with the time stamp 19:15, the attempt when it is working.

https://barracudacorp-my.sharepoint.com/:u:/g/personal/hfasching_barracuda_com/EZBjHnJqCaFLlArPb8a_-FwB-7FIzvK0e21ow1Qec-MVhw?e=5149sA (squid.conf)
https://barracudacorp-my.sharepoint.com/:u:/g/personal/hfasching_barracuda_com/EcPpd3DeeoFLs4_9Dn6JWAYBbHrwenOEJ3SZ0IW8_ED1-A?e=Ff9BZc (squid_cache.log)

It would be great if you could help me finding out what is wrong with Windows integrated authentication as our customer needs the SSO feature.


Thanks in advance and Kind regards,
Hannes Fasching

PS: All public/relevant IP's and domain names where replaced with text that should give a meaning e.g. IP of the proxy -> proxyip, IP of the client -> clientip, etc.
Also the Basic authentication string was replaced by '*'s














Get the 13 Email Threat Types eBook

https://www.barracuda.com/

This e-mail and any attachments to it contain confidential and proprietary material of Barracuda, its affiliates or agents, and is solely for the use of the intended recipient. Any review, use, disclosure, distribution or copying of this transmittal is prohibited except by or on behalf of the intended recipient. If you have received this transmittal in error, please notify the sender and destroy this e-mail and any attachments and all copies, whether electronic or printed.

________________________________


From rousskov at measurement-factory.com  Thu Sep  8 13:19:58 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 8 Sep 2022 09:19:58 -0400
Subject: [squid-users] Unwanted authentication requests
In-Reply-To: <qcRVW_0gtCSQwAm3fLUNjgjDDMwYp_G96UV5aQvJ60Nc18sC2P1aZwYJY_Xzn_EMc1Av6l9sAjIOY7bZ5c0AO0kNW_TXeWXf8lS1SsXOgSE=@protonmail.com>
References: <qcRVW_0gtCSQwAm3fLUNjgjDDMwYp_G96UV5aQvJ60Nc18sC2P1aZwYJY_Xzn_EMc1Av6l9sAjIOY7bZ5c0AO0kNW_TXeWXf8lS1SsXOgSE=@protonmail.com>
Message-ID: <b97eef54-4ad0-b53f-136a-9e4addfb7d97@measurement-factory.com>

On 9/8/22 03:13, Marek Gre?ko wrote:

> Is there some way to limit the use of basic auth only to the users on 
> the second vlan and not present it to the users on the first vlan and 
> vice versa?

This is not my area of expertise, but the auth_schemes directive does 
support ACLs, so you can tell Squid what schemes to use for what 
incoming traffic: http://www.squid-cache.org/Doc/config/auth_schemes/


> NONE_NONE/000 0 - error:transaction-end-before-headers - HIER_NONE/- -

FWIW, older Squids did not access-log many requestless TCP connections. 
Their presence in Squid v5 logs does not necessarily indicate a change 
in traffic patterns.


HTH,

Alex.


From zebu14 at free.fr  Thu Sep  8 14:15:04 2022
From: zebu14 at free.fr (Xavier Lecluse)
Date: Thu, 8 Sep 2022 16:15:04 +0200 (CEST)
Subject: [squid-users] [Troubleshoot] Squid 3.3 - Lots of 403 erros when
 reducing the workers number
In-Reply-To: <1692985167.1551895942.1662645051690.JavaMail.root@zimbra17-e3.priv.proxad.net>
Message-ID: <259615787.1552035307.1662646504051.JavaMail.root@zimbra17-e3.priv.proxad.net>

Hello everybody,
I am new to this list so feel free to react if my request is incorrect in any way (missing topic, tag, ....)

We are using two squid proxies (Squid 3.3) behind a load balancer, to handle our users requests (http/https).

The "hardware" of our VMs is :
2 vCPU @ 4.0GHz
4 Go Ram
iSCSI disks


In order to address some issues with Java clients, we tried to lower the worker directive from 8 to 1, because of the relative low number of simultaneous connections on our SSquid servers (about 100rq/s)
After reducing the worker value to 1, and restarting the proxies, we observed a great number of 403 errors, so we decided to rollback to 8 workers.


My questions are :
- How the number of workers and these 403 errors can be correlated ?
- Is there any "recommandations" about the number of workers to use, for a given number of request/s ?


The inital problem is from some java clients, which are using two TCP sessions, one for the authentication, and another one for the HTTP(s) requests.
The fact is that the "second" session is not always opened on the same worker, so ot considers that the authentication step has not already been done.

Is there a way to address this issue ?

Thank you.
Xavier


From rousskov at measurement-factory.com  Thu Sep  8 15:19:19 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 8 Sep 2022 11:19:19 -0400
Subject: [squid-users] [Troubleshoot] Squid 3.3 - Lots of 403 erros when
 reducing the workers number
In-Reply-To: <259615787.1552035307.1662646504051.JavaMail.root@zimbra17-e3.priv.proxad.net>
References: <259615787.1552035307.1662646504051.JavaMail.root@zimbra17-e3.priv.proxad.net>
Message-ID: <d911ce4e-41c2-58b4-cb20-4a94c5d60e59@measurement-factory.com>

On 9/8/22 10:15, Xavier Lecluse wrote:

> We are using two squid proxies (Squid 3.3)

Squid v3 is not officially supported. My answers below may apply to 
Squid v3, but they are based on Squid v5+.


> In order to address some issues with Java clients, we tried to lower
> the worker directive from 8 to 1, because of the relative low number
> of simultaneous connections on our SSquid servers (about 100rq/s) 
> After reducing the worker value to 1, and restarting the proxies, we
> observed a great number of 403 errors, so we decided to rollback to 8
> workers.

> - How the number of workers and these 403 errors can be correlated ?

I do not know the exact correlation vector in your environment, but 
fewer workers means, among other things, smaller _aggregate_ 
authentication cache size and higher load on individual authentication 
helpers. To pinpoint the correlation, we would need to know _why_ Squid 
is generating 403 (Forbidden) errors.


> - Is there any "recommandations" about the number of workers to use,
> for a given number of request/s ?

Workers are primarily a performance optimization. For related tuning 
suggestions, please see 
https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F


> The inital problem is from some java clients, which are using two TCP
> sessions, one for the authentication, and another one for the HTTP(s)
> requests. The fact is that the "second" session is not always opened
> on the same worker, so ot considers that the authentication step has
> not already been done.

> Is there a way to address this issue ?

If (a request on) the second connection has enough information to link 
it to the first/authenticated request/connection, then it may be 
possible to configure Squid and write authentication helpers in such a 
way that the "other" worker knows that the client of the second 
connection has already authenticated. The details would depend on the 
authentication scheme and that "linking" mechanism.


HTH,

Alex.



From marek.gresko at protonmail.com  Thu Sep  8 19:22:43 2022
From: marek.gresko at protonmail.com (=?utf-8?Q?Marek_Gre=C5=A1ko?=)
Date: Thu, 08 Sep 2022 19:22:43 +0000
Subject: [squid-users] Unwanted authentication requests
In-Reply-To: <b97eef54-4ad0-b53f-136a-9e4addfb7d97@measurement-factory.com>
References: <qcRVW_0gtCSQwAm3fLUNjgjDDMwYp_G96UV5aQvJ60Nc18sC2P1aZwYJY_Xzn_EMc1Av6l9sAjIOY7bZ5c0AO0kNW_TXeWXf8lS1SsXOgSE=@protonmail.com>
 <b97eef54-4ad0-b53f-136a-9e4addfb7d97@measurement-factory.com>
Message-ID: <Y_KbSIAaQwYjaqlA3hHf-V2FapySKoTmZ5NnSQWGbp9UHpAxXBhml8wZnM4PUyEjqsY27dx2-VMPV9F8dIsTAkatoCLmoCNk0B_KRlaok74=@protonmail.com>

Hello Alex,

thanks for tip. I did not know about that directive. Is it possible to specify no method for others? I tried none, but squid complained. Not necessarily needed now, but I tried to specify no method for other vlans without success. I left basic for others now.

Regarding the logs, I am not sure whether they were logged before, but before I did not get the basic login requests. Well, sometimes yes, but definitely not several a day, but one for months. Maybe it is some firefox update problem?

Marek





Sent with Proton Mail secure email.

------- Original Message -------
On Thursday, September 8th, 2022 at 15:19, Alex Rousskov <rousskov at measurement-factory.com> wrote:


> On 9/8/22 03:13, Marek Gre?ko wrote:
> 
> > Is there some way to limit the use of basic auth only to the users on
> > the second vlan and not present it to the users on the first vlan and
> > vice versa?
> 
> 
> This is not my area of expertise, but the auth_schemes directive does
> support ACLs, so you can tell Squid what schemes to use for what
> incoming traffic: http://www.squid-cache.org/Doc/config/auth_schemes/
> 
> > NONE_NONE/000 0 - error:transaction-end-before-headers - HIER_NONE/- -
> 
> 
> FWIW, older Squids did not access-log many requestless TCP connections.
> Their presence in Squid v5 logs does not necessarily indicate a change
> in traffic patterns.
> 
> 
> HTH,
> 
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Thu Sep  8 21:08:42 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 8 Sep 2022 17:08:42 -0400
Subject: [squid-users] Unwanted authentication requests
In-Reply-To: <Y_KbSIAaQwYjaqlA3hHf-V2FapySKoTmZ5NnSQWGbp9UHpAxXBhml8wZnM4PUyEjqsY27dx2-VMPV9F8dIsTAkatoCLmoCNk0B_KRlaok74=@protonmail.com>
References: <qcRVW_0gtCSQwAm3fLUNjgjDDMwYp_G96UV5aQvJ60Nc18sC2P1aZwYJY_Xzn_EMc1Av6l9sAjIOY7bZ5c0AO0kNW_TXeWXf8lS1SsXOgSE=@protonmail.com>
 <b97eef54-4ad0-b53f-136a-9e4addfb7d97@measurement-factory.com>
 <Y_KbSIAaQwYjaqlA3hHf-V2FapySKoTmZ5NnSQWGbp9UHpAxXBhml8wZnM4PUyEjqsY27dx2-VMPV9F8dIsTAkatoCLmoCNk0B_KRlaok74=@protonmail.com>
Message-ID: <8ba9e84f-f3ee-cccc-44e1-ae5f8f2119b1@measurement-factory.com>

On 9/8/22 15:22, Marek Gre?ko wrote:

> thanks for tip. I did not know about that directive. Is it possible
> to specify no method for others?

Hi Marek,

     If you do not want authentication for others, adjust your 
http_access rules (that trigger authentication). The auth_schemes 
directive controls how to authenticate, not whether to authenticate.


HTH,

Alex.


> Regarding the logs, I am not sure whether they were logged before,
> but before I did not get the basic login requests. Well, sometimes
> yes, but definitely not several a day, but one for months. Maybe it
> is some firefox update problem?


> ------- Original Message -------
> On Thursday, September 8th, 2022 at 15:19, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> 
>> On 9/8/22 03:13, Marek Gre?ko wrote:
>>
>>> Is there some way to limit the use of basic auth only to the users on
>>> the second vlan and not present it to the users on the first vlan and
>>> vice versa?
>>
>>
>> This is not my area of expertise, but the auth_schemes directive does
>> support ACLs, so you can tell Squid what schemes to use for what
>> incoming traffic: http://www.squid-cache.org/Doc/config/auth_schemes/
>>
>>> NONE_NONE/000 0 - error:transaction-end-before-headers - HIER_NONE/- -
>>
>>
>> FWIW, older Squids did not access-log many requestless TCP connections.
>> Their presence in Squid v5 logs does not necessarily indicate a change
>> in traffic patterns.
>>
>>
>> HTH,
>>
>> Alex.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users



From pponakanti at roblox.com  Thu Sep  8 23:41:25 2022
From: pponakanti at roblox.com (Praveen Ponakanti)
Date: Thu, 8 Sep 2022 16:41:25 -0700
Subject: [squid-users] Scaling concurrent TCP sessions beyond ephemeral
 port range
In-Reply-To: <97b1c32d-2172-d2fa-bfde-dd8c850c799a@measurement-factory.com>
References: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>
 <f7f62043-e384-0395-6d0f-ff4d510b0baf@measurement-factory.com>
 <CACabJxNv5+o7AiY-tfuJ=_V4ZBNEks=dX4ki2YQBHcPPpUrABg@mail.gmail.com>
 <5856354a-393a-0803-e3e6-da29f8f7d8b1@treenet.co.nz>
 <CACabJxMt1wkt7cUJH00WpbVK9wA2-8odhS8QrMGPhe8w4SUQpw@mail.gmail.com>
 <97b1c32d-2172-d2fa-bfde-dd8c850c799a@measurement-factory.com>
Message-ID: <CACabJxP1f8YhngBG6WzkRZ4W+RzcM4cc0HoXo2=5bGsQCFUsBQ@mail.gmail.com>

Hi Alex,


Thanks for all the help from the squid dev group with upstreaming the
enhancement to scale up outbound TCP sessions on Linux with the
IP_BIND_ADDRESS_NO_PORT sockopt flag. Our canary instances have been doing
great the last few weeks with the code patch prior to merge.


A few followup questions (not urgent) :

   - Do we know which 5.x version will include the patch? I do not see it
   listed in the change log for squid-5.7.
   - We have a large number of workers (30) to help with handling a
   high RPS. However, TCP session reuse does not seem to be optimal even with
   server_persistent_connections enabled as a new outbound session would have
   to be opened up if the request is proxied by a kid worker that doesn?t
   already have a connection to that destination. Is there something that can
   be done to improve this with later versions of squid? Would be glad to help
   out if anyone has some suggestions.

Thanks
Praveen

On Tue, Jun 21, 2022 at 2:11 PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 6/19/22 12:48, Praveen Ponakanti wrote:
>
> > What is the process to have this code patch upstreamed for future squid
> > versions?
>
> In short, just post a quality pull request on GitHub (or find somebody
> who can guide your code towards official acceptance for you). For
> details, please see https://wiki.squid-cache.org/MergeProcedure
>
>
> Thank you,
>
> Alex.
>
>
> > On Fri, May 20, 2022 at 9:31 PM Amos Jeffries <squid3 at treenet.co.nz
> > wrote:
> >
> >     On 20/05/22 19:44, Praveen Ponakanti wrote:
> >      > Hi Alex,
> >      >
> >      > Thanks for going through several steps to help mitigate src port
> >      > exhaustion. We are looking to achieve 400-500% more
> >      > concurrent connections if we could :) as there is a
> >     significant buffer
> >      > on the available CPU.
> >
> >     Then you require at least 4, maybe 5, IP addresses to handle that
> many
> >     concurrent connections with Squid.
> >
> >
> > We would like to investigate going beyond the ephemeral port range for
> > some specific destination IP:PORT addresses. For that it appears squid
> > does not round-robin requests if we use multiple tcp_outgoing_addresses.
> > We could use ACL?s to pick a different outbound IP based on the clients
> > source IP, however that is not very ideal in our environment as our
> > clients aren?t always equally split by subnet. However, if we could
> > split by the client?s source port that might help achieve this. For
> > example something like:
> >
> >
> > acl pool1 clientport 0-32768
> >
> > acl pool2 clientport 32769-65536
> >
> >
> > tcp_outgoing_address 10.1.0.1 pool1
> >
> > tcp_outgoing_address 10.1.0.2 pool2
> >
> >
> > Squid's ACLs currently do not allow filtering by the client's source
> > port. We could look into a separate patch to add this functionality to
> > squid?s ACL code if that makes sense. Or is there a better way to
> > achieve this?
> >
> >
> > Thanks
> >
> > Praveen
> >
> >
> >      > The option to use multiple tcp_outoing_addresses appears to be
> >     promising
> >      > along with some tweaks to the TCP timeouts. I guess we could use
> >     ACLs to
> >      > pick a different outbound IP based on the requesting client's
> >     prefix. We
> >      > had not considered that option as the ephemeral ports were no
> longer
> >      > available to other applications when squid uses most of them with
> a
> >      > single outbound IP configured. We are also looking to modify the
> >     code to
> >      > use the IP_BIND_ADDRESS_NO_PORT sockopt as that could help delay
> >     port
> >      > assignment with the bind() call on the outbound TCP sessions (to
> >      > hopefully allow access to the 4-tuple on the socket).
> >
> >     Patches welcome.
> >
> >     However, please be aware that use of the 4-tuple is often no
> different
> >     from the 3-tuple since the dst-port is typically identical for all
> >     outgoing traffic to a given dst-IP.
> >
> >
> >     Cheers
> >     Amos
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>
> >     http://lists.squid-cache.org/listinfo/squid-users
> >     <http://lists.squid-cache.org/listinfo/squid-users>
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220908/75a4db90/attachment.htm>

From squid3 at treenet.co.nz  Fri Sep  9 02:48:49 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 9 Sep 2022 14:48:49 +1200
Subject: [squid-users] Scaling concurrent TCP sessions beyond ephemeral
 port range
In-Reply-To: <CACabJxP1f8YhngBG6WzkRZ4W+RzcM4cc0HoXo2=5bGsQCFUsBQ@mail.gmail.com>
References: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>
 <f7f62043-e384-0395-6d0f-ff4d510b0baf@measurement-factory.com>
 <CACabJxNv5+o7AiY-tfuJ=_V4ZBNEks=dX4ki2YQBHcPPpUrABg@mail.gmail.com>
 <5856354a-393a-0803-e3e6-da29f8f7d8b1@treenet.co.nz>
 <CACabJxMt1wkt7cUJH00WpbVK9wA2-8odhS8QrMGPhe8w4SUQpw@mail.gmail.com>
 <97b1c32d-2172-d2fa-bfde-dd8c850c799a@measurement-factory.com>
 <CACabJxP1f8YhngBG6WzkRZ4W+RzcM4cc0HoXo2=5bGsQCFUsBQ@mail.gmail.com>
Message-ID: <d9d728ee-fe16-c947-bc92-2397ae2dcdd3@treenet.co.nz>

On 9/09/22 11:41, Praveen Ponakanti wrote:
> Hi Alex,
> 
> 
> Thanks for all the help from the squid dev group with upstreaming the 
> enhancement to scale up outbound TCP sessions on Linux with the 
> IP_BIND_ADDRESS_NO_PORT sockopt flag. Our canary instances have been 
> doing great the last few weeks with the code patch prior to merge.
> 
> 
> A few followup questions (not urgent) :
> 
>   * Do we know which 5.x version will include the patch? I do not see it
>     listed in the change log for squid-5.7.

Squid-5 is in "stable" release cycle already which means the changes 
applied to it are quite restricted.

IMO this change is more of a performance optimization than a bug fix, so 
this is being left for Squid-6 which is supposed to start releasing in a 
few months (Feb 2023).



>   * We have a large number of workers (30) to help with handling a
>     high?RPS. However, TCP session reuse does not seem to be optimal
>     even with server_persistent_connections enabled as a new outbound
>     session would have to be opened up if the request is proxied by a
>     kid worker that doesn?t already have a connection to that
>     destination. Is there something that can be done to improve this
>     with later versions of squid? Would be glad to help out if anyone
>     has some suggestions.

It sounds to me like your situation is one that this system architecture 
was designed to service: 
<https://wiki.squid-cache.org/ConfigExamples/ExtremeCarpFrontend>



Cheers
Amos


From squid3 at treenet.co.nz  Fri Sep  9 02:57:18 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 9 Sep 2022 14:57:18 +1200
Subject: [squid-users] Unwanted authentication requests
In-Reply-To: <Y_KbSIAaQwYjaqlA3hHf-V2FapySKoTmZ5NnSQWGbp9UHpAxXBhml8wZnM4PUyEjqsY27dx2-VMPV9F8dIsTAkatoCLmoCNk0B_KRlaok74=@protonmail.com>
References: <qcRVW_0gtCSQwAm3fLUNjgjDDMwYp_G96UV5aQvJ60Nc18sC2P1aZwYJY_Xzn_EMc1Av6l9sAjIOY7bZ5c0AO0kNW_TXeWXf8lS1SsXOgSE=@protonmail.com>
 <b97eef54-4ad0-b53f-136a-9e4addfb7d97@measurement-factory.com>
 <Y_KbSIAaQwYjaqlA3hHf-V2FapySKoTmZ5NnSQWGbp9UHpAxXBhml8wZnM4PUyEjqsY27dx2-VMPV9F8dIsTAkatoCLmoCNk0B_KRlaok74=@protonmail.com>
Message-ID: <157a9b0c-b68b-06f2-6bbf-5ae85387e6bc@treenet.co.nz>

On 9/09/22 07:22, Marek Gre?ko wrote:
> Hello Alex,
> 
> thanks for tip. I did not know about that directive. Is it possible to specify no method for others? I tried none, but squid complained. Not necessarily needed now, but I tried to specify no method for other vlans without success. I left basic for others now.
> 
> Regarding the logs, I am not sure whether they were logged before, but before I did not get the basic login requests. Well, sometimes yes, but definitely not several a day, but one for months. Maybe it is some firefox update problem?

I think some change in the Browser(s) is likely the cause, assuming you 
did not alter the auth configuration and/or how http_access policies 
used authentication ACLs.

FYI, unless you specify the auth_schemes policy Alex mentioned Squid 
will always inform the client of *all* auth types you configured for 
use. Which auth scheme(s) to try is entirely a Browser/client choice.

Regarding the popup box. That is an internal Browser choice to ask the 
user to supply credentials instead of locating them by other means (eg 
SSO, machine account, or a credentials store). It has nothing to do with 
Squid.


HTH
Amos


From rousskov at measurement-factory.com  Fri Sep  9 03:31:18 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 8 Sep 2022 23:31:18 -0400
Subject: [squid-users] Scaling concurrent TCP sessions beyond ephemeral
 port range
In-Reply-To: <CACabJxP1f8YhngBG6WzkRZ4W+RzcM4cc0HoXo2=5bGsQCFUsBQ@mail.gmail.com>
References: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>
 <f7f62043-e384-0395-6d0f-ff4d510b0baf@measurement-factory.com>
 <CACabJxNv5+o7AiY-tfuJ=_V4ZBNEks=dX4ki2YQBHcPPpUrABg@mail.gmail.com>
 <5856354a-393a-0803-e3e6-da29f8f7d8b1@treenet.co.nz>
 <CACabJxMt1wkt7cUJH00WpbVK9wA2-8odhS8QrMGPhe8w4SUQpw@mail.gmail.com>
 <97b1c32d-2172-d2fa-bfde-dd8c850c799a@measurement-factory.com>
 <CACabJxP1f8YhngBG6WzkRZ4W+RzcM4cc0HoXo2=5bGsQCFUsBQ@mail.gmail.com>
Message-ID: <40a11002-0925-c791-683b-8fee212224e8@measurement-factory.com>

On 9/8/22 19:41, Praveen Ponakanti wrote:
>   * We have a large number of workers (30) to help with handling a
>     high?RPS. However, TCP session reuse does not seem to be optimal
>     even with server_persistent_connections enabled as a new outbound
>     session would have to be opened up if the request is proxied by a
>     kid worker that doesn?t already have a connection to that
>     destination. Is there something that can be done to improve this
>     with later versions of squid? Would be glad to help out if anyone
>     has some suggestions.

If your only concern is TCP, and the number of servers is large, then it 
would be possible to share open Squid-server connections among workers 
by adding code that would exchange open TCP socket descriptors using UDS 
messages, but I doubt it is worth doing (a lot of complexity but not 
enough gain). There may also be some advanced/modern kernel tricks that 
we can teach Squid to use for sharing connections, but, again, I doubt 
the complexity would be worth the benefits from such reuse.

If most TCP servers are known a priori, and there are few of them, then 
cache_peer standby=N feature for them might be useful.

If you are dealing with TLS sessions as well, then we should add a 
shared memory TLS session cache that all workers can tap into.


Cheers,

Alex.

> On Tue, Jun 21, 2022 at 2:11 PM Alex Rousskov wrote:
> 
>     On 6/19/22 12:48, Praveen Ponakanti wrote:
> 
>      > What is the process to have this code patch upstreamed for future
>     squid
>      > versions?
> 
>     In short, just post a quality pull request on GitHub (or find somebody
>     who can guide your code towards official acceptance for you). For
>     details, please see https://wiki.squid-cache.org/MergeProcedure
>     <https://wiki.squid-cache.org/MergeProcedure>
> 
> 
>     Thank you,
> 
>     Alex.
> 
> 
>      > On Fri, May 20, 2022 at 9:31 PM Amos Jeffries
>     <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>
>      > wrote:
>      >
>      >? ? ?On 20/05/22 19:44, Praveen Ponakanti wrote:
>      >? ? ? > Hi Alex,
>      >? ? ? >
>      >? ? ? > Thanks for going through several steps to help mitigate
>     src port
>      >? ? ? > exhaustion. We are looking to achieve 400-500% more
>      >? ? ? > concurrent?connections if we could :) as there is a
>      >? ? ?significant?buffer
>      >? ? ? > on the available CPU.
>      >
>      >? ? ?Then you require at least 4, maybe 5, IP addresses to handle
>     that many
>      >? ? ?concurrent connections with Squid.
>      >
>      >
>      > We would like to investigate going beyond the ephemeral port
>     range for
>      > some specific destination IP:PORT addresses. For that it appears
>     squid
>      > does not round-robin requests if we use multiple
>     tcp_outgoing_addresses.
>      > We could use ACL?s to pick a different outbound IP based on the
>     clients
>      > source IP, however that is not very ideal in our environment as our
>      > clients aren?t always equally split by subnet. However, if we could
>      > split by the client?s source port that might help achieve this. For
>      > example something like:
>      >
>      >
>      > acl pool1 clientport 0-32768
>      >
>      > acl pool2 clientport 32769-65536
>      >
>      >
>      > tcp_outgoing_address 10.1.0.1 pool1
>      >
>      > tcp_outgoing_address 10.1.0.2 pool2
>      >
>      >
>      > Squid's ACLs currently do not allow filtering by the client's source
>      > port. We could look into a separate patch to add this
>     functionality to
>      > squid?s ACL code if that makes sense. Or is there a better way to
>      > achieve this?
>      >
>      >
>      > Thanks
>      >
>      > Praveen
>      >
>      >
>      >? ? ? > The option to use multiple tcp_outoing_addresses appears to be
>      >? ? ?promising
>      >? ? ? > along with some tweaks to the TCP timeouts. I guess we
>     could use
>      >? ? ?ACLs to
>      >? ? ? > pick a different outbound IP based on the requesting client's
>      >? ? ?prefix. We
>      >? ? ? > had not considered that option as the ephemeral ports were
>     no longer
>      >? ? ? > available?to other applications when squid uses most of
>     them with a
>      >? ? ? > single outbound IP configured. We are also looking to
>     modify the
>      >? ? ?code to
>      >? ? ? > use the IP_BIND_ADDRESS_NO_PORT sockopt as that could help
>     delay
>      >? ? ?port
>      >? ? ? > assignment with the bind() call on the outbound TCP
>     sessions (to
>      >? ? ? > hopefully allow access to the 4-tuple on the socket).
>      >
>      >? ? ?Patches welcome.
>      >
>      >? ? ?However, please be aware that use of the 4-tuple is often no
>     different
>      >? ? ?from the 3-tuple since the dst-port is typically identical
>     for all
>      >? ? ?outgoing traffic to a given dst-IP.
>      >
>      >
>      >? ? ?Cheers
>      >? ? ?Amos
>      >? ? ?_______________________________________________
>      >? ? ?squid-users mailing list
>      > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >? ? ?<mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>      > http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>
>      >? ? ?<http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>>
>      >
>      >
>      > _______________________________________________
>      > squid-users mailing list
>      > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      > http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>
> 
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>
> 



From squid3 at treenet.co.nz  Fri Sep  9 04:45:38 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 9 Sep 2022 16:45:38 +1200
Subject: [squid-users] Exchange server authentication via squid reverse
 proxy not working after upgrade from squid 4.15 to 5.6
In-Reply-To: <DM6PR10MB3740189C7803EC2C750365E6B3409@DM6PR10MB3740.namprd10.prod.outlook.com>
References: <DM6PR10MB3740189C7803EC2C750365E6B3409@DM6PR10MB3740.namprd10.prod.outlook.com>
Message-ID: <bd2a3a0f-b210-8f83-c70a-a506ca172cdc@treenet.co.nz>

On 8/09/22 19:40, Hannes Fasching wrote:
> Hello,
> A customer have an issue that after upgrading from squid 4.15 to actual 5.6 with reverse proxy mode for an exchange server.
> The authentication is not working anymore when the integrated Windows authentication is enabled (needed for SSO). When disabled, the authentication via squid is then working.


The squid.conf you link to below does not perform any authentication. 
Squid is configured just to relay any auth headers as-is to the Exchange 
server / peer.

To clarify some details here:

* "SSO" means simply that all services on a network are supposed to 
accept the same credentials.
  - Microsoft making a big noise about this terminology is purely 
marketing hype. SSO can be performed with any auth scheme and any 
credentials - it is entirely a matter of what the service doing the 
authentication accepts as valid credentials. So this can be ignored for 
troubleshooting purposes.


* "integrated Windows authentication" means simply that the Browser is 
supposed to have access to the users Windows account to send their 
machine login credentials when auth is needed.
  - So the thing to be looking at is whether the Browser (or other 
client software) is able to access and send the user login when 
authenticating.
  - If it is sending some other credentials that is a problem. Look at 
where they are coming from and why.


* authentication _scheme_ is simply a way to deliver the credentials 
from some client to some server.
  - these are dictated by the server doing the authentication. As long 
as the client software is using a scheme the service indicated as 
available things should work correctly.
  - this is where Squid comes in.
   ** If Squid is participating in the authentication the scheme is 
limited to one where three agents can share it (eg Basic).
   ** If Squid is blindly relaying then only the client and server need 
to agree on the scheme. But Squid needs to avoid breaking the scheme 
requirements (eg NTLM/Negotiate restrict TCP connection multiplexing, 
Digest restricts server load balancing).


> The difference is that Windows with integrated authentication is trying several authentication schemes otherwise only Basic authentication is used.
> Please follow the link to see the squid.conf and the cache log file starting with the attempt when it fails and afterwards, with the time stamp 19:15, the attempt when it is working.
> 
> https://barracudacorp-my.sharepoint.com/:u:/g/personal/hfasching_barracuda_com/EZBjHnJqCaFLlArPb8a_-FwB-7FIzvK0e21ow1Qec-MVhw?e=5149sA (squid.conf)
> https://barracudacorp-my.sharepoint.com/:u:/g/personal/hfasching_barracuda_com/EcPpd3DeeoFLs4_9Dn6JWAYBbHrwenOEJ3SZ0IW8_ED1-A?e=Ff9BZc (squid_cache.log)
> 
> It would be great if you could help me finding out what is wrong with Windows integrated authentication as our customer needs the SSO feature.


What I would be looking at here is the HTTP(S) message flows and headers 
to see what type of credentials the user/client is trying to send 
through Squid to Exchange. What auth scheme they are being sent with. 
And what TCP connections ("FD") they are being sent on when leaving Squid.


What I see in the log you posted is two client connections doing the 
following:

Client connection #1:
  * sends POST with Basic auth
  * server accepts
  * sends OPTIONS with Basic auth
  * server accepts

That looks good. Check that the credentials sent were the users Windows 
login and were sent automatically. If so then "SSO" is working.


Client connection #2:
  * sends POST with Bearer auth
  * server rejects (401)
  * sends POST with no credentials
  * server rejects (401)
  * sends POST with no credentials
  * server rejects (401)

   - I think this client software is broken. It should absolutely *not* 
be sending any requests without authentication after having received 
that first 401 status. It should be trying alternative schemes, or 
alternative credentials with each scheme, or going away.


Client connection #2 (after a short delay):

  * sends POST with Negotiate/NTLMv2 client capabilities token
  * server responds per NTLMv2 (401 status)
    - I assume it also produces the nonce token though I don't see the 
header logged
  * sends POST with Negotiate/NTLMv2 proof of identity token
  * server rejects (401)

That looks like Squid is correctly relaying the NTLMv2 handshake 
messages. But the Exchange server does not like the login for some reason.
  I would at this point be checking whether the credentials used here 
were actually the users Windows login, and whether Exchange server is 
validating properly.
  I am not familiar with Exchange but this may be something to do with 
NTLMv2 credentials using Negotiate scheme instead of NTLM scheme. 
Negotiate scheme typically means Kerberos handshake expected since NTLM 
was formally deprecated by Microsoft in April 2006.


HTH
Amos


From marek.gresko at protonmail.com  Fri Sep  9 05:09:43 2022
From: marek.gresko at protonmail.com (=?utf-8?Q?Marek_Gre=C5=A1ko?=)
Date: Fri, 09 Sep 2022 05:09:43 +0000
Subject: [squid-users] Unwanted authentication requests
In-Reply-To: <157a9b0c-b68b-06f2-6bbf-5ae85387e6bc@treenet.co.nz>
References: <qcRVW_0gtCSQwAm3fLUNjgjDDMwYp_G96UV5aQvJ60Nc18sC2P1aZwYJY_Xzn_EMc1Av6l9sAjIOY7bZ5c0AO0kNW_TXeWXf8lS1SsXOgSE=@protonmail.com>
 <b97eef54-4ad0-b53f-136a-9e4addfb7d97@measurement-factory.com>
 <Y_KbSIAaQwYjaqlA3hHf-V2FapySKoTmZ5NnSQWGbp9UHpAxXBhml8wZnM4PUyEjqsY27dx2-VMPV9F8dIsTAkatoCLmoCNk0B_KRlaok74=@protonmail.com>
 <157a9b0c-b68b-06f2-6bbf-5ae85387e6bc@treenet.co.nz>
Message-ID: <efSr1eqdwOs6PrnNYY4gLYhXB4ZpDVbIRmuaD9HCYP0rRwrmL2n_upLdW4ZbVNfEGUtbsjfCecXaq3RsJweeisb-ECpiBS5EpHhqmdiV2Kg=@protonmail.com>

OK, thanks.

Marek





Sent with Proton Mail secure email.

------- Original Message -------
On Friday, September 9th, 2022 at 4:57, Amos Jeffries <squid3 at treenet.co.nz> wrote:


> On 9/09/22 07:22, Marek Gre?ko wrote:
> 
> > Hello Alex,
> > 
> > thanks for tip. I did not know about that directive. Is it possible to specify no method for others? I tried none, but squid complained. Not necessarily needed now, but I tried to specify no method for other vlans without success. I left basic for others now.
> > 
> > Regarding the logs, I am not sure whether they were logged before, but before I did not get the basic login requests. Well, sometimes yes, but definitely not several a day, but one for months. Maybe it is some firefox update problem?
> 
> 
> I think some change in the Browser(s) is likely the cause, assuming you
> did not alter the auth configuration and/or how http_access policies
> used authentication ACLs.
> 
> FYI, unless you specify the auth_schemes policy Alex mentioned Squid
> will always inform the client of all auth types you configured for
> use. Which auth scheme(s) to try is entirely a Browser/client choice.
> 
> Regarding the popup box. That is an internal Browser choice to ask the
> user to supply credentials instead of locating them by other means (eg
> SSO, machine account, or a credentials store). It has nothing to do with
> Squid.
> 
> 
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From zebu14 at free.fr  Fri Sep  9 08:20:42 2022
From: zebu14 at free.fr (Xavier Lecluse)
Date: Fri, 9 Sep 2022 10:20:42 +0200 (CEST)
Subject: [squid-users] [Troubleshoot] Squid 3.3 - Lots of 403 erros when
 reducing the workers number
In-Reply-To: <d911ce4e-41c2-58b4-cb20-4a94c5d60e59@measurement-factory.com>
Message-ID: <117109620.1554863650.1662711642360.JavaMail.root@zimbra17-e3.priv.proxad.net>

Hello Alex,

Thanks for your answer.

>> We are using two squid proxies (Squid 3.3)

>Squid v3 is not officially supported. My answers below may apply to 
>Squid v3, but they are based on Squid v5+.


>> In order to address some issues with Java clients, we tried to lower
>> the worker directive from 8 to 1, because of the relative low number
>> of simultaneous connections on our SSquid servers (about 100rq/s) 
>> After reducing the worker value to 1, and restarting the proxies, we
>> observed a great number of 403 errors, so we decided to rollback to 8
>> workers.

>> - How the number of workers and these 403 errors can be correlated ?

>I do not know the exact correlation vector in your environment, but 
>fewer workers means, among other things, smaller _aggregate_ 
>authentication cache size and higher load on individual authentication 
>helpers. To pinpoint the correlation, we would need to know _why_ Squid 
>is generating 403 (Forbidden) errors.

Is there a specific way to find the reason ? Do I need to activate a certain logging level to see these traces ?
I will check in the actual logs and I'll come back if I don't find anything


>> - Is there any "recommandations" about the number of workers to use,
>> for a given number of request/s ?

>Workers are primarily a performance optimization. For related tuning 
>suggestions, please see 
>https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F

Yes, I saw and read this thread on the Wiki.
We were already using some of these recommandations.
I think we are quite far from a "top performance" but we didn't observed any performance issue when we used 8 workers.
I understand that an individual worker should be able to handle our actual load, but we have to find what is provoking the 403 errors first.

>> The inital problem is from some java clients, which are using two TCP
>> sessions, one for the authentication, and another one for the HTTP(s)
>> requests. The fact is that the "second" session is not always opened
>> on the same worker, so ot considers that the authentication step has
>> not already been done.

>> Is there a way to address this issue ?

>If (a request on) the second connection has enough information to link 
>it to the first/authenticated request/connection, then it may be 
>possible to configure Squid and write authentication helpers in such a 
>way that the "other" worker knows that the client of the second 
>connection has already authenticated. The details would depend on the 
>authentication scheme and that "linking" mechanism.

Do you have any example of an authentication helper I can start with ? or an example on how to "link" events between workers ?
I was thinking that workers were quite "individuals" and did not exchange anything (or verry little) with each other.
Any start point would be welcome.

Regards,
Xavier

>HTH,

>Alex.




----- Mail original -----
De: "Alex Rousskov" <rousskov at measurement-factory.com>
?: squid-users at lists.squid-cache.org
Envoy?: Jeudi 8 Septembre 2022 17:19:19
Objet: Re: [squid-users] [Troubleshoot] Squid 3.3 - Lots of 403 erros when reducing the workers number

On 9/8/22 10:15, Xavier Lecluse wrote:

> We are using two squid proxies (Squid 3.3)

Squid v3 is not officially supported. My answers below may apply to 
Squid v3, but they are based on Squid v5+.


> In order to address some issues with Java clients, we tried to lower
> the worker directive from 8 to 1, because of the relative low number
> of simultaneous connections on our SSquid servers (about 100rq/s) 
> After reducing the worker value to 1, and restarting the proxies, we
> observed a great number of 403 errors, so we decided to rollback to 8
> workers.

> - How the number of workers and these 403 errors can be correlated ?

I do not know the exact correlation vector in your environment, but 
fewer workers means, among other things, smaller _aggregate_ 
authentication cache size and higher load on individual authentication 
helpers. To pinpoint the correlation, we would need to know _why_ Squid 
is generating 403 (Forbidden) errors.


> - Is there any "recommandations" about the number of workers to use,
> for a given number of request/s ?

Workers are primarily a performance optimization. For related tuning 
suggestions, please see 
https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F


> The inital problem is from some java clients, which are using two TCP
> sessions, one for the authentication, and another one for the HTTP(s)
> requests. The fact is that the "second" session is not always opened
> on the same worker, so ot considers that the authentication step has
> not already been done.

> Is there a way to address this issue ?

If (a request on) the second connection has enough information to link 
it to the first/authenticated request/connection, then it may be 
possible to configure Squid and write authentication helpers in such a 
way that the "other" worker knows that the client of the second 
connection has already authenticated. The details would depend on the 
authentication scheme and that "linking" mechanism.


HTH,

Alex.

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From roeeklinger60 at gmail.com  Fri Sep  9 12:40:32 2022
From: roeeklinger60 at gmail.com (roee klinger)
Date: Fri, 9 Sep 2022 15:40:32 +0300
Subject: [squid-users] logfileHandleWrite:
 daemon:/var/log/squid/access.log: error writing ((32) Broken pipe)
In-Reply-To: <CABA8h=SqKQeNvp4By1dyNX+MDq3qz4ShbW=2Ur+DvN5pMjp=Uw@mail.gmail.com>
References: <CAGCa14q9QeX_fqH0bFPW5C8=Cpssbx8zgw0CWE-MLAEivkTSyw@mail.gmail.com>
 <171b0b23-7a59-b420-ac05-fcbdb02a213d@measurement-factory.com>
 <3dce10cb-9ed3-4176-bc70-5763ff9f7c67@Spark>
 <95f8b8d3-c23e-93dd-f772-ae11133ed4b9@measurement-factory.com>
 <80a8a3e2-6650-dd9e-e147-e19a43606d40@measurement-factory.com>
 <CABA8h=SqKQeNvp4By1dyNX+MDq3qz4ShbW=2Ur+DvN5pMjp=Uw@mail.gmail.com>
Message-ID: <47359982-dafd-4a65-b916-4ff02510f979@Spark>

Thank you, Alex and Eli,

Just wanted to update that I was able to solve the problem in case someone runs into it in the future,
based on Eliezers suggestion, I disabled logrotate (although it can be tweaked to work), and just wrote
a custom cron job to run daily and rotate the logs for each squid instance using something like this:
> quote_type
> squid -f /etc/squid/squid12.conf -k rotate
> ..
> ..
> ..
>
Now everything seems to be working properly, logfile_rotate is set to 1, so the files move over once
and then they get deleted, just as I wanted.
On 7 Sep 2022, 19:27 +0300, NgTech LTD <ngtech1ltd at gmail.com>, wrote:
> Good one, Alex.
>
> For this specific use case you need a special rotate script which will know the confs file and will loop over them.
> Later on I will try to see if yave one of these on my servers.
> Basically you will need an array of config files and loop on them.
>
> The pid shouldn't be relevevant for a rotate operation but it depends on the nature of the system.(on a 24/7 system you should know about a service that is down way before the logrotate happpens)
> If you have a set of config files you can generate a set of postrotate commands compared to a special script.
>
> Let me know if this solution might fit for your use case.
>
> Eliezer
>
> > ?????? ??? ??, 7 ????? 2022, 3:53, ??? Alex Rousskov ?<rousskov at measurement-factory.com>:
> > > ?> pid_filename /var/run/squid2.pid
> > >
> > > ?>? ?postrotate
> > > ?>? ?test ! -e /var/run/squid.pid || ... /usr/sbin/squid -k rotate
> > > ?>? ?endscript
> > >
> > > I spotted one more (potentially critical) problem: Your Squid
> > > configuration sets pid_filename to /var/run/squid2.pid but your
> > > logrotate configuration assumes Squid uses /var/run/squid.pid.
> > >
> > > IMHO, in general, it is best not to guess where Squid has its PID if you
> > > are using "squid -k ...". If you want to test whether Squid is currently
> > > running, try using "squid -k check" instead.
> > >
> > >
> > > HTH,
> > >
> > > Alex.
> > >
> > >
> > >
> > > On 9/6/22 20:45, Alex Rousskov wrote:
> > > > On 9/6/22 18:02, roee klinger wrote:
> > > >> it seems that the logs has filled over 100GB of log data, since I made
> > > >> a configuration mistake (I think?) by setting this:
> > > >>
> > > >> ??? logfile_rotate 0
> > > >
> > > > This is correct setting when using an external log rotation tool like
> > > > the logrotate daemon. More on that below.
> > > >
> > > >
> > > >> If I remember and read correctly, this means that the rotation of the
> > > >> files is disabled and they will just keeping increasing
> > > >> in size if left unchecked.
> > > >
> > > > To be more precise, this means that you are relying on an external tool
> > > > to rename the log files. With this setting, Squid rotate command closes
> > > > the access log and opens a new one (under the same name). While that
> > > > might sound useless, it is the right (and necessary) thing for Squid to
> > > > do when combined with the correct external log rotation setup.
> > > >
> > > >
> > > >> I have now gone ahead and changed all the configuration file to this
> > > >> setting:
> > > >>
> > > >> ??? logfile_rotate 1
> > > >>
> > > >> So now it should rotate once daily, and on the next rotation it should
> > > >> be deleted, and this is all handled by logrotate on Debian-based
> > > >> machines?
> > > >
> > > > AFAIK, if you are using an external (to Squid) tool like logrotate, you
> > > > should be setting logfile_rotate to zero.
> > > >
> > > >
> > > >> This is my / cat /etc/logrotate.d/squid:
> > > >> ? / cat /etc/logrotate.d/squid
> > > >> #
> > > >> # Logrotate fragment for squid.
> > > >> #
> > > >> /var/log/squid/*.log {
> > > >> ??daily
> > > >> ??compress
> > > >> ??delaycompress
> > > >> ??rotate 2
> > > >> ??missingok
> > > >> ??nocreate
> > > >> ??sharedscripts
> > > >> ??prerotate
> > > >> ??test ! -x /usr/sbin/sarg-reports || /usr/sbin/sarg-reports daily
> > > >> ??endscript
> > > >> ??postrotate
> > > >> ??test ! -e /var/run/squid.pid || test ! -x /usr/sbin/squid ||
> > > >> /usr/sbin/squid -k rotate
> > > >> ??endscript
> > > >> }
> > > >
> > > > This is not my area of expertise, but the above configuration does not
> > > > look 100% correct to me: sarg-reports execution failures should have no
> > > > effect on log rotation but does (AFAICT). There may be other problems
> > > > (e.g., I do not know whether your /usr/sbin/squid finds the right Squid
> > > > configuration file). I hope sysadmin experts on this mailing list will
> > > > help you polish this.
> > > >
> > > > You should be able to test whether the above is working (e.g., by asking
> > > > logrotate to rotate). Testing is critical even if you do end up getting
> > > > expert log rotation help on this list (this email is not it!).
> > > >
> > > >
> > > > HTH,
> > > >
> > > > Alex.
> > > >
> > > >
> > > >> Is there a way for me to set it so it just get deleted every 24 or 12
> > > >> hours without the archive first?
> > > >>
> > > >> Thanks,
> > > >> Roee
> > > >> On 6 Sep 2022, 16:28 +0300, Alex Rousskov
> > > >> <rousskov at measurement-factory.com>, wrote:
> > > >>> On 9/6/22 07:41, roee klinger wrote:
> > > >>>
> > > >>>> It is also important to know that I am running multiple Squid instances
> > > >>>> on the same machine, they are all getting the error at the same time
> > > >>>
> > > >>> What external event(s) happen at that time? Something is probably
> > > >>> sending a signal to the logging daemon process. It would be good to know
> > > >>> what that something (and that signal) is. Your syslog or cache.log might
> > > >>> contain more info. Analyzing the timing/schedule of these problems may
> > > >>> also be helpful in identifying the trigger.
> > > >>>
> > > >>>
> > > >>>> Is a possible workaround that might be just replacing the line with
> > > >>>> this?
> > > >>>
> > > >>>> access_log /var/log/squid/access2.log
> > > >>>
> > > >>> As you know, this configuration (in this deprecated spelling or with and
> > > >>> explicit "stdio:" prefix) will result in Squid workers writing to the
> > > >>> log file directly instead of asking the logging daemon. This will,
> > > >>> naturally, get rid of the pipe between workers and their daemons, and
> > > >>> the associated broken pipe error.
> > > >>>
> > > >>>> or will this cause a problem?
> > > >>>
> > > >>> Impossible to say for sure without knowing whether your workers benefit
> > > >>> from the anticipated performance advantages of avoiding blocking file
> > > >>> I/O _and_ whether those advantages are real (in your environment). Too
> > > >>> many variables and too many unknowns. I would treat this as an important
> > > >>> (and potentially disruptive) configuration change and carefully test the
> > > >>> outcome.
> > > >>>
> > > >>>
> > > >>> HTH,
> > > >>>
> > > >>> Alex.
> > > >>>
> > > >>>
> > > >>>> INFO -
> > > >>>> Versions:
> > > >>>>
> > > >>>> Squid Cache: Version 4.10
> > > >>>> Ubuntu 20.04.4 LTS
> > > >>>>
> > > >>>>
> > > >>>> Example squid.conf:
> > > >>>>
> > > >>>> visible_hostname squid2
> > > >>>>
> > > >>>> access_log daemon:/var/log/squid/access2.log squid
> > > >>>>
> > > >>>> cache_log /var/log/squid/cache2.log
> > > >>>>
> > > >>>> pid_filename /var/run/squid2.pid
> > > >>>>
> > > >>>>
> > > >>>> acl localnet src 0.0.0.1-0.255.255.255# RFC 1122 "this" network (LAN)
> > > >>>>
> > > >>>> acl localnet src 10.0.0.0/8 <http://10.0.0.0/8> # RFC 1918 local
> > > >>>> private network (LAN)
> > > >>>>
> > > >>>> acl localnet src 100.64.0.0/10 <http://100.64.0.0/10># RFC 6598
> > > >>>> shared address space (CGN)
> > > >>>>
> > > >>>> acl localnet src 169.254.0.0/16 <http://169.254.0.0/16> # RFC 3927
> > > >>>> link-local (directly plugged) machines
> > > >>>>
> > > >>>> acl localnet src 172.16.0.0/12 <http://172.16.0.0/12># RFC 1918
> > > >>>> local private network (LAN)
> > > >>>>
> > > >>>> acl localnet src 192.168.0.0/16 <http://192.168.0.0/16> # RFC 1918
> > > >>>> local private network (LAN)
> > > >>>>
> > > >>>> acl localnet src fc00::/7 # RFC 4193 local private network range
> > > >>>>
> > > >>>> acl localnet src fe80::/10# RFC 4291 link-local (directly plugged)
> > > >>>> machines
> > > >>>>
> > > >>>> acl SSL_ports port 443
> > > >>>>
> > > >>>> acl Safe_ports port 80# http
> > > >>>>
> > > >>>> acl Safe_ports port 21# ftp
> > > >>>>
> > > >>>> acl Safe_ports port 443 # https
> > > >>>>
> > > >>>> acl Safe_ports port 70# gopher
> > > >>>>
> > > >>>> acl Safe_ports port 210 # wais
> > > >>>>
> > > >>>> acl Safe_ports port 1025-65535# unregistered ports
> > > >>>>
> > > >>>> acl Safe_ports port 280 # http-mgmt
> > > >>>>
> > > >>>> acl Safe_ports port 488 # gss-http
> > > >>>>
> > > >>>> acl Safe_ports port 591 # filemaker
> > > >>>>
> > > >>>> acl Safe_ports port 777 # multiling http
> > > >>>>
> > > >>>> acl CONNECT method CONNECT
> > > >>>>
> > > >>>> http_access deny !Safe_ports
> > > >>>>
> > > >>>> http_access deny CONNECT !SSL_ports
> > > >>>>
> > > >>>> http_access allow localhost manager
> > > >>>>
> > > >>>> http_access deny manager
> > > >>>>
> > > >>>> # include /etc/squid/conf.d/*
> > > >>>>
> > > >>>> http_access allow localhost
> > > >>>>
> > > >>>> acl aws src *censored*
> > > >>>>
> > > >>>> http_access allow aws
> > > >>>>
> > > >>>> # http_access deny all
> > > >>>>
> > > >>>> tcp_outgoing_address *censored*
> > > >>>>
> > > >>>> http_port 10002
> > > >>>>
> > > >>>> coredump_dir /var/spool/squid
> > > >>>>
> > > >>>> refresh_pattern ^ftp: 144020% 10080
> > > >>>>
> > > >>>> refresh_pattern ^gopher:14400%1440
> > > >>>>
> > > >>>> refresh_pattern -i (/cgi-bin/|\?) 0 0%0
> > > >>>>
> > > >>>> refresh_pattern \/(Packages|Sources)(|\.bz2|\.gz|\.xz)$ 0 0% 0
> > > >>>> refresh-ims
> > > >>>>
> > > >>>> refresh_pattern \/Release(|\.gpg)$ 0 0% 0 refresh-ims
> > > >>>>
> > > >>>> refresh_pattern \/InRelease$ 0 0% 0 refresh-ims
> > > >>>>
> > > >>>> refresh_pattern \/(Translation-.*)(|\.bz2|\.gz|\.xz)$ 0 0% 0
> > > >>>> refresh-ims
> > > >>>>
> > > >>>> refresh_pattern . 0 20% 4320
> > > >>>>
> > > >>>>
> > > >>>> shutdown_lifetime 1 seconds
> > > >>>>
> > > >>>> logfile_rotate 0
> > > >>>>
> > > >>>> max_filedescriptors 16384
> > > >>>>
> > > >>>> dns_nameservers 8.8.8.8 8.8.4.4 1.1.1.1
> > > >>>>
> > > >>>> cache deny all
> > > >>>>
> > > >>>> cache_dir null /tmp
> > > >>>>
> > > >>>> via off
> > > >>>>
> > > >>>> forwarded_for off
> > > >>>>
> > > >>>> request_header_access From deny all
> > > >>>>
> > > >>>> request_header_access Server deny all
> > > >>>>
> > > >>>> request_header_access WWW-Authenticate deny all
> > > >>>>
> > > >>>> request_header_access Link deny all
> > > >>>>
> > > >>>> request_header_access Cache-Control deny all
> > > >>>>
> > > >>>> request_header_access Proxy-Connection deny all
> > > >>>>
> > > >>>> request_header_access X-Cache deny all
> > > >>>>
> > > >>>> request_header_access X-Cache-Lookup deny all
> > > >>>>
> > > >>>> request_header_access Via deny all
> > > >>>>
> > > >>>> request_header_access X-Forwarded-For deny all
> > > >>>>
> > > >>>> request_header_access Pragma deny all
> > > >>>>
> > > >>>> request_header_access Keep-Alive deny all
> > > >>>>
> > > >>>> dns_v4_first on
> > > >>>>
> > > >>>>
> > > >>>> Example?service file:
> > > >>>>
> > > >>>> ## Copyright (C) 1996-2020 The Squid Software Foundation and
> > > >>>> contributors
> > > >>>>
> > > >>>> ##
> > > >>>>
> > > >>>> ## Squid software is distributed under GPLv2+ license and includes
> > > >>>>
> > > >>>> ## contributions from numerous individuals and organizations.
> > > >>>>
> > > >>>> ## Please see the COPYING and CONTRIBUTORS files for details.
> > > >>>>
> > > >>>> ##
> > > >>>>
> > > >>>>
> > > >>>> [Unit]
> > > >>>>
> > > >>>> Description=Squid Web Proxy Server
> > > >>>>
> > > >>>> Documentation=man:squid(8)
> > > >>>>
> > > >>>> After=network.target network-online.target nss-lookup.target
> > > >>>>
> > > >>>>
> > > >>>> [Service]
> > > >>>>
> > > >>>> Type=forking
> > > >>>>
> > > >>>> PIDFile=/var/run/squid2.pid
> > > >>>>
> > > >>>> ExecStartPre=/usr/sbin/squid --foreground -z -f /etc/squid/squid2.conf
> > > >>>>
> > > >>>> ExecStart=/usr/sbin/squid -sYC -f /etc/squid/squid2.conf
> > > >>>>
> > > >>>> ExecReload=/bin/kill -HUP $MAINPID
> > > >>>>
> > > >>>> KillMode=mixed
> > > >>>>
> > > >>>>
> > > >>>> [Install]
> > > >>>>
> > > >>>> WantedBy=multi-user.target
> > > >>>>
> > > >>>>
> > > >>>>
> > > >>>> Permissions:
> > > >>>>
> > > >>>> ?? ls -alt /etc/squid/
> > > >>>> total 128
> > > >>>> drwxr-xr-x ? 2 root root 4096 Sep ?6 11:33 .
> > > >>>> -rw-r--r-- ? 1 root root 2831 Sep ?6 11:33 squid7.conf
> > > >>>> drwxr-xr-x 116 root root 4096 Sep ?6 11:33 ..
> > > >>>> -rw-r--r-- ? 1 root root 2830 Sep ?6 11:33 squid2.conf
> > > >>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:33 squid13.conf
> > > >>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid23.conf
> > > >>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid19.conf
> > > >>>> -rw-r--r-- ? 1 root root 2832 Sep ?6 11:32 squid1.conf
> > > >>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:32 squid17.conf
> > > >>>> -rw-r--r-- ? 1 root root 2832 Sep ?6 11:31 squid4.conf
> > > >>>> -rw-r--r-- ? 1 root root 2834 Sep ?6 11:31 squid21.conf
> > > >>>> -rw-r--r-- ? 1 root root 2833 Sep ?6 11:31 squid25.conf
> > > >>>> -rw-r--r-- ? 1 root root 2834 Sep ?6 11:31 squid12.conf
> > > >>>> -rw-r--r-- ? 1 root root 2832 Sep ?6 11:31 squid3.conf
> > > >>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:30 squid10.conf
> > > >>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:30 squid11.conf
> > > >>>> -rw-r--r-- ? 1 root root 2833 Sep ?6 11:30 squid18.conf
> > > >>>> -rw-r--r-- ? 1 root root 2830 Sep ?6 11:30 squid8.conf
> > > >>>> -rw-r--r-- ? 1 root root 2830 Sep ?6 11:30 squid6.conf
> > > >>>> -rw-r--r-- ? 1 root root 2833 Sep ?6 11:30 squid28.conf
> > > >>>> -rw-r--r-- ? 1 root root 2830 Sep ?6 11:25 squid9.conf
> > > >>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid24.conf
> > > >>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid22.conf
> > > >>>> -rw-r--r-- ? 1 root root 2837 Sep ?6 11:25 squid20.conf
> > > >>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid16.conf
> > > >>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid15.conf
> > > >>>> -rw-r--r-- ? 1 root root 2836 Sep ?6 11:25 squid14.conf
> > > >>>> -rw-r--r-- ? 1 root root 2831 Sep ?6 11:25 squid5.conf
> > > >>>> -rw-r--r-- ? 1 root root 2833 Sep ?6 11:25 squid27.conf
> > > >>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid26.conf
> > > >>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid30.conf
> > > >>>> -rw-r--r-- ? 1 root root 2835 Sep ?6 11:25 squid29.conf
> > > >>>>
> > > >>>>
> > > >>>> _______________________________________________
> > > >>>> squid-users mailing list
> > > >>>> squid-users at lists.squid-cache.org
> > > >>>> http://lists.squid-cache.org/listinfo/squid-users
> > > >>>
> > > >>> _______________________________________________
> > > >>> squid-users mailing list
> > > >>> squid-users at lists.squid-cache.org
> > > >>> http://lists.squid-cache.org/listinfo/squid-users
> > > >
> > > > _______________________________________________
> > > > squid-users mailing list
> > > > squid-users at lists.squid-cache.org
> > > > http://lists.squid-cache.org/listinfo/squid-users
> > >
> > > _______________________________________________
> > > squid-users mailing list
> > > squid-users at lists.squid-cache.org
> > > http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220909/dcdba5fc/attachment.htm>

From roeeklinger60 at gmail.com  Fri Sep  9 12:49:33 2022
From: roeeklinger60 at gmail.com (roee klinger)
Date: Fri, 9 Sep 2022 15:49:33 +0300
Subject: [squid-users] Do squid logs performence affect general request
 performece?
In-Reply-To: <190bd8ec-0724-44dd-96b2-3f9e6505d92e@Spark>
References: <190bd8ec-0724-44dd-96b2-3f9e6505d92e@Spark>
Message-ID: <5ac180f3-41c7-463b-8266-4fef7ee0fee4@Spark>

Hello,

I have just recently started exploring ingesting logs from Squid via Logstash (TCP log ingestion)

I now have to make the decision of how to deploy Logstash, it seems to me that I have two options:

1. Deploy a Logstash instance for every region where I have a Squid instance running, resulting in the lowest latency possible between Squid and Logstash.
2. Deploy a central Logstash instance for all Squid instance worldwide, which is the cheapest and easiest option, but will have high latency for some of the Squid instance which are located far away geographically from the Logstash instance.

I already know that if the log server crashes in Squid, then Squid will crash with a fatal error, so Squid takes logging very seriously, so my question is: does TCP logging performance in Squid effect the total request performance, or are they independent from each other? based on that, I can decide if I go with option #1 or #2.

What would be you recommendations, if request performance is crucial (and log performance is not)?

Thanks,
Roee
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220909/7e78ef26/attachment.htm>

From rousskov at measurement-factory.com  Fri Sep  9 14:43:28 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 9 Sep 2022 10:43:28 -0400
Subject: [squid-users] [Troubleshoot] Squid 3.3 - Lots of 403 erros when
 reducing the workers number
In-Reply-To: <117109620.1554863650.1662711642360.JavaMail.root@zimbra17-e3.priv.proxad.net>
References: <117109620.1554863650.1662711642360.JavaMail.root@zimbra17-e3.priv.proxad.net>
Message-ID: <8b84cbd6-5de6-3151-1eee-d9cb1c144e8d@measurement-factory.com>

On 9/9/22 04:20, Xavier Lecluse wrote:
>>> In order to address some issues with Java clients, we tried to lower
>>> the worker directive from 8 to 1, because of the relative low number
>>> of simultaneous connections on our SSquid servers (about 100rq/s)
>>> After reducing the worker value to 1, and restarting the proxies, we
>>> observed a great number of 403 errors, so we decided to rollback to 8
>>> workers.

>>> - How the number of workers and these 403 errors can be correlated ?

>> I do not know the exact correlation vector in your environment, but
>> fewer workers means, among other things, smaller _aggregate_
>> authentication cache size and higher load on individual authentication
>> helpers. To pinpoint the correlation, we would need to know _why_ Squid
>> is generating 403 (Forbidden) errors.

> Is there a specific way to find the reason ? Do I need to activate a certain logging level to see these traces ?
> I will check in the actual logs and I'll come back if I don't find anything

There are many ways to investigate this. If you cannot figure it out, I 
hope that others on this mailing list can guide you.



>>> The inital problem is from some java clients, which are using two TCP
>>> sessions, one for the authentication, and another one for the HTTP(s)
>>> requests. The fact is that the "second" session is not always opened
>>> on the same worker, so ot considers that the authentication step has
>>> not already been done.

>>> Is there a way to address this issue ?

>> If (a request on) the second connection has enough information to link
>> it to the first/authenticated request/connection, then it may be
>> possible to configure Squid and write authentication helpers in such a
>> way that the "other" worker knows that the client of the second
>> connection has already authenticated. The details would depend on the
>> authentication scheme and that "linking" mechanism.

> Do you have any example of an authentication helper I can start with
> ? or an example on how to "link" events between workers ?

Sorry, I do not.


> I was thinking that workers were quite "individuals" and did not
> exchange anything (or verry little) with each other.

In this case, the exchange of information would be performed by your 
authentication helpers, not workers. A helper is a custom program that 
can do nearly anything as long as it obeys the helper API[1]. For 
example, helpers from different workers can share a custom 
authentication database. Squid workers will just read annotations sent 
to Squid by your helpers (e.g., already_authenticated_=yes). Your 
configuration can act on those annotations via the note ACL.

[1] https://wiki.squid-cache.org/Features/AddonHelpers


HTH,

Alex.


> ----- Mail original -----
> De: "Alex Rousskov" <rousskov at measurement-factory.com>
> ?: squid-users at lists.squid-cache.org
> Envoy?: Jeudi 8 Septembre 2022 17:19:19
> Objet: Re: [squid-users] [Troubleshoot] Squid 3.3 - Lots of 403 erros when reducing the workers number
> 
> On 9/8/22 10:15, Xavier Lecluse wrote:
> 
>> We are using two squid proxies (Squid 3.3)
> 
> Squid v3 is not officially supported. My answers below may apply to
> Squid v3, but they are based on Squid v5+.
> 
> 
>> In order to address some issues with Java clients, we tried to lower
>> the worker directive from 8 to 1, because of the relative low number
>> of simultaneous connections on our SSquid servers (about 100rq/s)
>> After reducing the worker value to 1, and restarting the proxies, we
>> observed a great number of 403 errors, so we decided to rollback to 8
>> workers.
> 
>> - How the number of workers and these 403 errors can be correlated ?
> 
> I do not know the exact correlation vector in your environment, but
> fewer workers means, among other things, smaller _aggregate_
> authentication cache size and higher load on individual authentication
> helpers. To pinpoint the correlation, we would need to know _why_ Squid
> is generating 403 (Forbidden) errors.
> 
> 
>> - Is there any "recommandations" about the number of workers to use,
>> for a given number of request/s ?
> 
> Workers are primarily a performance optimization. For related tuning
> suggestions, please see
> https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F
> 
> 
>> The inital problem is from some java clients, which are using two TCP
>> sessions, one for the authentication, and another one for the HTTP(s)
>> requests. The fact is that the "second" session is not always opened
>> on the same worker, so ot considers that the authentication step has
>> not already been done.
> 
>> Is there a way to address this issue ?
> 
> If (a request on) the second connection has enough information to link
> it to the first/authenticated request/connection, then it may be
> possible to configure Squid and write authentication helpers in such a
> way that the "other" worker knows that the client of the second
> connection has already authenticated. The details would depend on the
> authentication scheme and that "linking" mechanism.
> 
> 
> HTH,
> 
> Alex.
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Fri Sep  9 16:56:48 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 9 Sep 2022 12:56:48 -0400
Subject: [squid-users] Do squid logs performence affect general request
 performece?
In-Reply-To: <5ac180f3-41c7-463b-8266-4fef7ee0fee4@Spark>
References: <190bd8ec-0724-44dd-96b2-3f9e6505d92e@Spark>
 <5ac180f3-41c7-463b-8266-4fef7ee0fee4@Spark>
Message-ID: <9e76568b-a203-fe03-3025-8ff0a47fc2c5@measurement-factory.com>

On 9/9/22 08:49, roee klinger wrote:
> Hello,
> 
> I have just recently started exploring ingesting logs from Squid via 
> Logstash (TCP log ingestion)
> 
> I now have to make the decision of how to deploy Logstash, it seems to 
> me that I have two options:
> 
>  1. Deploy a Logstash instance for every region where I have a Squid
>     instance running, resulting in the lowest latency possible between
>     Squid and Logstash.
>  2. Deploy a central Logstash instance for all Squid instance worldwide,
>     which is the cheapest and easiest option, but will have high latency
>     for some of the Squid instance which are located far away
>     geographically from the Logstash instance.
> 
> I already know that if the log server crashes in Squid, then Squid will 
> crash with a fatal error,

FYI: Logging error handling is configurable via "access_log on-error".


> so Squid takes logging very seriously, so my 
> question is: does TCP logging performance in Squid effect the total 
> request performance, or are they independent from each other?

TCP logger uses asynchronous non-blocking I/O. Individual HTTP 
transactions do not wait for individual log records to be sent. Needless 
to say, logging does consume resources and, hence, may affect overall 
HTTP transaction performance. And if the log record recipient is too 
slow, then Squid will die and/or log records will be dropped.


> What would be you recommendations, if request performance is crucial 
> (and log performance is not)?

I would not be surprised if you would not be able to measure meaningful 
performance difference among these modules. From general performance 
point of view, and module-specific bugs and limitations notwithstanding, 
I would expect "daemon" and "udp" modules to have smaller performance 
overhead/cost for Squid workers than the "tcp" module because I expect 
that TCP has to "do more" than stdout I/O and UDP. However, I would not 
base this decision on such high-level speculations and test various 
options instead.


HTH,

Alex.


From pponakanti at roblox.com  Fri Sep  9 22:02:19 2022
From: pponakanti at roblox.com (Praveen Ponakanti)
Date: Fri, 9 Sep 2022 15:02:19 -0700
Subject: [squid-users] Scaling concurrent TCP sessions beyond ephemeral
 port range
In-Reply-To: <d9d728ee-fe16-c947-bc92-2397ae2dcdd3@treenet.co.nz>
References: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>
 <f7f62043-e384-0395-6d0f-ff4d510b0baf@measurement-factory.com>
 <CACabJxNv5+o7AiY-tfuJ=_V4ZBNEks=dX4ki2YQBHcPPpUrABg@mail.gmail.com>
 <5856354a-393a-0803-e3e6-da29f8f7d8b1@treenet.co.nz>
 <CACabJxMt1wkt7cUJH00WpbVK9wA2-8odhS8QrMGPhe8w4SUQpw@mail.gmail.com>
 <97b1c32d-2172-d2fa-bfde-dd8c850c799a@measurement-factory.com>
 <CACabJxP1f8YhngBG6WzkRZ4W+RzcM4cc0HoXo2=5bGsQCFUsBQ@mail.gmail.com>
 <d9d728ee-fe16-c947-bc92-2397ae2dcdd3@treenet.co.nz>
Message-ID: <CACabJxNkWSPMfMLzOzruujZpv4SjV90fwDKxFG1KDUzGBpdX2g@mail.gmail.com>

Amos,

Thanks, will wait for the feature on the squid-6 release.
Praveen

On Thu, Sep 8, 2022 at 7:50 PM Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 9/09/22 11:41, Praveen Ponakanti wrote:
> > Hi Alex,
> >
> >
> > Thanks for all the help from the squid dev group with upstreaming the
> > enhancement to scale up outbound TCP sessions on Linux with the
> > IP_BIND_ADDRESS_NO_PORT sockopt flag. Our canary instances have been
> > doing great the last few weeks with the code patch prior to merge.
> >
> >
> > A few followup questions (not urgent) :
> >
> >   * Do we know which 5.x version will include the patch? I do not see it
> >     listed in the change log for squid-5.7.
>
> Squid-5 is in "stable" release cycle already which means the changes
> applied to it are quite restricted.
>
> IMO this change is more of a performance optimization than a bug fix, so
> this is being left for Squid-6 which is supposed to start releasing in a
> few months (Feb 2023).
>
>
>
> >   * We have a large number of workers (30) to help with handling a
> >     high RPS. However, TCP session reuse does not seem to be optimal
> >     even with server_persistent_connections enabled as a new outbound
> >     session would have to be opened up if the request is proxied by a
> >     kid worker that doesn?t already have a connection to that
> >     destination. Is there something that can be done to improve this
> >     with later versions of squid? Would be glad to help out if anyone
> >     has some suggestions.
>
> It sounds to me like your situation is one that this system architecture
> was designed to service:
> <https://wiki.squid-cache.org/ConfigExamples/ExtremeCarpFrontend>
>
>
>
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220909/f8277a3e/attachment.htm>

From pponakanti at roblox.com  Fri Sep  9 22:29:07 2022
From: pponakanti at roblox.com (Praveen Ponakanti)
Date: Fri, 9 Sep 2022 15:29:07 -0700
Subject: [squid-users] Scaling concurrent TCP sessions beyond ephemeral
 port range
In-Reply-To: <40a11002-0925-c791-683b-8fee212224e8@measurement-factory.com>
References: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>
 <f7f62043-e384-0395-6d0f-ff4d510b0baf@measurement-factory.com>
 <CACabJxNv5+o7AiY-tfuJ=_V4ZBNEks=dX4ki2YQBHcPPpUrABg@mail.gmail.com>
 <5856354a-393a-0803-e3e6-da29f8f7d8b1@treenet.co.nz>
 <CACabJxMt1wkt7cUJH00WpbVK9wA2-8odhS8QrMGPhe8w4SUQpw@mail.gmail.com>
 <97b1c32d-2172-d2fa-bfde-dd8c850c799a@measurement-factory.com>
 <CACabJxP1f8YhngBG6WzkRZ4W+RzcM4cc0HoXo2=5bGsQCFUsBQ@mail.gmail.com>
 <40a11002-0925-c791-683b-8fee212224e8@measurement-factory.com>
Message-ID: <CACabJxMXendT2FFn5u9dFqYhWNrBab=E1k-JbWUAWV=qrCPW2w@mail.gmail.com>

On Thu, Sep 8, 2022 at 8:31 PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 9/8/22 19:41, Praveen Ponakanti wrote:
> >   * We have a large number of workers (30) to help with handling a
> >     high RPS. However, TCP session reuse does not seem to be optimal
> >     even with server_persistent_connections enabled as a new outbound
> >     session would have to be opened up if the request is proxied by a
> >     kid worker that doesn?t already have a connection to that
> >     destination. Is there something that can be done to improve this
> >     with later versions of squid? Would be glad to help out if anyone
> >     has some suggestions.
>
> If your only concern is TCP, and the number of servers is large, then it
> would be possible to share open Squid-server connections among workers
> by adding code that would exchange open TCP socket descriptors using UDS
> messages, but I doubt it is worth doing (a lot of complexity but not
> enough gain). There may also be some advanced/modern kernel tricks that
> we can teach Squid to use for sharing connections, but, again, I doubt
> the complexity would be worth the benefits from such reuse.
>

Agree, it might not make sense to increase the complexity with sharing
socket among the workers. Was thinking more on the lines of a hashmap that
the coordinator could use to pick workers that already have a TCP
connection to the destination being requested, instead of having the
workers themselves share connection details. This might introduce
significant complexity as well, so please ignore if there are better
solutions when large counts of workers are in use.


>
> If most TCP servers are known a priori, and there are few of them, then
> cache_peer standby=N feature for them might be useful.
>
>
The TCP destinations are not always known beforehand and can run into the
thousands. However only the top 4-5 destinations have a large number of
concurrent sessions. Which are each limited to the ip_local_port_range size
in concurrent sessions now after the enhancement to add the
IP_BIND_ADDRESS_NO_PORT flag. BTW, we do not run caching on squid or have
peer caches in our deployment.

Most of the TCP connections are for HTTPS reqs, w/o TLS termination at the
squid. Does squid currently support a TLS session cache ?

Thanks
Praveen


> If you are dealing with TLS sessions as well, then we should add a
> shared memory TLS session cache that all workers can tap into.
>
>
> Cheers,
>
> Alex.
>
> > On Tue, Jun 21, 2022 at 2:11 PM Alex Rousskov wrote:
> >
> >     On 6/19/22 12:48, Praveen Ponakanti wrote:
> >
> >      > What is the process to have this code patch upstreamed for future
> >     squid
> >      > versions?
> >
> >     In short, just post a quality pull request on GitHub (or find
> somebody
> >     who can guide your code towards official acceptance for you). For
> >     details, please see https://wiki.squid-cache.org/MergeProcedure
> >     <https://wiki.squid-cache.org/MergeProcedure>
> >
> >
> >     Thank you,
> >
> >     Alex.
> >
> >
> >      > On Fri, May 20, 2022 at 9:31 PM Amos Jeffries
> >     <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>
> >      > wrote:
> >      >
> >      >     On 20/05/22 19:44, Praveen Ponakanti wrote:
> >      >      > Hi Alex,
> >      >      >
> >      >      > Thanks for going through several steps to help mitigate
> >     src port
> >      >      > exhaustion. We are looking to achieve 400-500% more
> >      >      > concurrent connections if we could :) as there is a
> >      >     significant buffer
> >      >      > on the available CPU.
> >      >
> >      >     Then you require at least 4, maybe 5, IP addresses to handle
> >     that many
> >      >     concurrent connections with Squid.
> >      >
> >      >
> >      > We would like to investigate going beyond the ephemeral port
> >     range for
> >      > some specific destination IP:PORT addresses. For that it appears
> >     squid
> >      > does not round-robin requests if we use multiple
> >     tcp_outgoing_addresses.
> >      > We could use ACL?s to pick a different outbound IP based on the
> >     clients
> >      > source IP, however that is not very ideal in our environment as
> our
> >      > clients aren?t always equally split by subnet. However, if we
> could
> >      > split by the client?s source port that might help achieve this.
> For
> >      > example something like:
> >      >
> >      >
> >      > acl pool1 clientport 0-32768
> >      >
> >      > acl pool2 clientport 32769-65536
> >      >
> >      >
> >      > tcp_outgoing_address 10.1.0.1 pool1
> >      >
> >      > tcp_outgoing_address 10.1.0.2 pool2
> >      >
> >      >
> >      > Squid's ACLs currently do not allow filtering by the client's
> source
> >      > port. We could look into a separate patch to add this
> >     functionality to
> >      > squid?s ACL code if that makes sense. Or is there a better way to
> >      > achieve this?
> >      >
> >      >
> >      > Thanks
> >      >
> >      > Praveen
> >      >
> >      >
> >      >      > The option to use multiple tcp_outoing_addresses appears
> to be
> >      >     promising
> >      >      > along with some tweaks to the TCP timeouts. I guess we
> >     could use
> >      >     ACLs to
> >      >      > pick a different outbound IP based on the requesting
> client's
> >      >     prefix. We
> >      >      > had not considered that option as the ephemeral ports were
> >     no longer
> >      >      > available to other applications when squid uses most of
> >     them with a
> >      >      > single outbound IP configured. We are also looking to
> >     modify the
> >      >     code to
> >      >      > use the IP_BIND_ADDRESS_NO_PORT sockopt as that could help
> >     delay
> >      >     port
> >      >      > assignment with the bind() call on the outbound TCP
> >     sessions (to
> >      >      > hopefully allow access to the 4-tuple on the socket).
> >      >
> >      >     Patches welcome.
> >      >
> >      >     However, please be aware that use of the 4-tuple is often no
> >     different
> >      >     from the 3-tuple since the dst-port is typically identical
> >     for all
> >      >     outgoing traffic to a given dst-IP.
> >      >
> >      >
> >      >     Cheers
> >      >     Amos
> >      >     _______________________________________________
> >      >     squid-users mailing list
> >      > squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>
> >      >     <mailto:squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>>
> >      > http://lists.squid-cache.org/listinfo/squid-users
> >     <http://lists.squid-cache.org/listinfo/squid-users>
> >      >     <http://lists.squid-cache.org/listinfo/squid-users
> >     <http://lists.squid-cache.org/listinfo/squid-users>>
> >      >
> >      >
> >      > _______________________________________________
> >      > squid-users mailing list
> >      > squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>
> >      > http://lists.squid-cache.org/listinfo/squid-users
> >     <http://lists.squid-cache.org/listinfo/squid-users>
> >
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>
> >     http://lists.squid-cache.org/listinfo/squid-users
> >     <http://lists.squid-cache.org/listinfo/squid-users>
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220909/cb812047/attachment.htm>

From rousskov at measurement-factory.com  Sat Sep 10 02:22:02 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 9 Sep 2022 22:22:02 -0400
Subject: [squid-users] Scaling concurrent TCP sessions beyond ephemeral
 port range
In-Reply-To: <CACabJxMXendT2FFn5u9dFqYhWNrBab=E1k-JbWUAWV=qrCPW2w@mail.gmail.com>
References: <CACabJxP86UGm_dm+PbyckMWoxiis2fc87jwyQq+uXHXAKm=AfA@mail.gmail.com>
 <f7f62043-e384-0395-6d0f-ff4d510b0baf@measurement-factory.com>
 <CACabJxNv5+o7AiY-tfuJ=_V4ZBNEks=dX4ki2YQBHcPPpUrABg@mail.gmail.com>
 <5856354a-393a-0803-e3e6-da29f8f7d8b1@treenet.co.nz>
 <CACabJxMt1wkt7cUJH00WpbVK9wA2-8odhS8QrMGPhe8w4SUQpw@mail.gmail.com>
 <97b1c32d-2172-d2fa-bfde-dd8c850c799a@measurement-factory.com>
 <CACabJxP1f8YhngBG6WzkRZ4W+RzcM4cc0HoXo2=5bGsQCFUsBQ@mail.gmail.com>
 <40a11002-0925-c791-683b-8fee212224e8@measurement-factory.com>
 <CACabJxMXendT2FFn5u9dFqYhWNrBab=E1k-JbWUAWV=qrCPW2w@mail.gmail.com>
Message-ID: <a8746396-a00d-65d3-ed60-7f20e10c9bed@measurement-factory.com>

On 9/9/22 18:29, Praveen Ponakanti wrote:
> 
> On Thu, Sep 8, 2022 at 8:31 PM Alex Rousskov wrote:
> 
>     On 9/8/22 19:41, Praveen Ponakanti wrote:
>      >? ?* We have a large number of workers (30) to help with handling a
>      >? ? ?high?RPS. However, TCP session reuse does not seem to be optimal
>      >? ? ?even with server_persistent_connections enabled as a new outbound
>      >? ? ?session would have to be opened up if the request is proxied by a
>      >? ? ?kid worker that doesn?t already have a connection to that
>      >? ? ?destination. Is there something that can be done to improve this
>      >? ? ?with later versions of squid? Would be glad to help out if anyone
>      >? ? ?has some suggestions.
> 
>     If your only concern is TCP, and the number of servers is large,
>     then it
>     would be possible to share open Squid-server connections among workers
>     by adding code that would exchange open TCP socket descriptors using
>     UDS
>     messages, but I doubt it is worth doing (a lot of complexity but not
>     enough gain). There may also be some advanced/modern kernel tricks that
>     we can teach Squid to use for sharing connections, but, again, I doubt
>     the complexity would be worth the benefits from such reuse.

> Agree, it might not make sense to increase the complexity with sharing 
> socket among the workers. Was thinking more on the lines of a hashmap 
> that the coordinator could use to pick workers that already have a TCP 
> connection to the destination being requested, instead of having the 
> workers themselves share connection details.

Coordinator does not receive/see regular HTTP traffic. If we start 
routing HTTP transactions through that process, it may become the 
bottleneck itself _and_ will introduce additional overheads for passing 
descriptors to workers. From performance point of view, the model with 
one "routing" task doling work to workers works best (and is commonly 
used) in threaded applications, but Squid is not threaded at that level.



> Most of the TCP connections are for HTTPS reqs, w/o TLS termination at 
> the squid. Does squid currently support a TLS session cache ?

Yes, there is some support for worker-specific TLS session caching, with 
directives like sslproxy_session_cache_size, tls_outgoing_options 
options=NO_TICKET (for outgoing sessions IIRC) and https_port 
sslflags=NO_SESSION_REUSE and https_port sslcontext (for incoming sessions).


HTH,

Alex.


>     If you are dealing with TLS sessions as well, then we should add a
>     shared memory TLS session cache that all workers can tap into.
> 
> 
>     Cheers,
> 
>     Alex.
> 
>      > On Tue, Jun 21, 2022 at 2:11 PM Alex Rousskov wrote:
>      >
>      >? ? ?On 6/19/22 12:48, Praveen Ponakanti wrote:
>      >
>      >? ? ? > What is the process to have this code patch upstreamed for
>     future
>      >? ? ?squid
>      >? ? ? > versions?
>      >
>      >? ? ?In short, just post a quality pull request on GitHub (or find
>     somebody
>      >? ? ?who can guide your code towards official acceptance for you). For
>      >? ? ?details, please see
>     https://wiki.squid-cache.org/MergeProcedure
>     <https://wiki.squid-cache.org/MergeProcedure>
>      >? ? ?<https://wiki.squid-cache.org/MergeProcedure
>     <https://wiki.squid-cache.org/MergeProcedure>>
>      >
>      >
>      >? ? ?Thank you,
>      >
>      >? ? ?Alex.
>      >
>      >
>      >? ? ? > On Fri, May 20, 2022 at 9:31 PM Amos Jeffries
>      >? ? ?<squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>
>     <mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>
>      >? ? ? > wrote:
>      >? ? ? >
>      >? ? ? >? ? ?On 20/05/22 19:44, Praveen Ponakanti wrote:
>      >? ? ? >? ? ? > Hi Alex,
>      >? ? ? >? ? ? >
>      >? ? ? >? ? ? > Thanks for going through several steps to help mitigate
>      >? ? ?src port
>      >? ? ? >? ? ? > exhaustion. We are looking to achieve 400-500% more
>      >? ? ? >? ? ? > concurrent?connections if we could :) as there is a
>      >? ? ? >? ? ?significant?buffer
>      >? ? ? >? ? ? > on the available CPU.
>      >? ? ? >
>      >? ? ? >? ? ?Then you require at least 4, maybe 5, IP addresses to
>     handle
>      >? ? ?that many
>      >? ? ? >? ? ?concurrent connections with Squid.
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > We would like to investigate going beyond the ephemeral port
>      >? ? ?range for
>      >? ? ? > some specific destination IP:PORT addresses. For that it
>     appears
>      >? ? ?squid
>      >? ? ? > does not round-robin requests if we use multiple
>      >? ? ?tcp_outgoing_addresses.
>      >? ? ? > We could use ACL?s to pick a different outbound IP based
>     on the
>      >? ? ?clients
>      >? ? ? > source IP, however that is not very ideal in our
>     environment as our
>      >? ? ? > clients aren?t always equally split by subnet. However, if
>     we could
>      >? ? ? > split by the client?s source port that might help achieve
>     this. For
>      >? ? ? > example something like:
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > acl pool1 clientport 0-32768
>      >? ? ? >
>      >? ? ? > acl pool2 clientport 32769-65536
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > tcp_outgoing_address 10.1.0.1 pool1
>      >? ? ? >
>      >? ? ? > tcp_outgoing_address 10.1.0.2 pool2
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > Squid's ACLs currently do not allow filtering by the
>     client's source
>      >? ? ? > port. We could look into a separate patch to add this
>      >? ? ?functionality to
>      >? ? ? > squid?s ACL code if that makes sense. Or is there a better
>     way to
>      >? ? ? > achieve this?
>      >? ? ? >
>      >? ? ? >
>      >? ? ? > Thanks
>      >? ? ? >
>      >? ? ? > Praveen
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >? ? ? > The option to use multiple tcp_outoing_addresses
>     appears to be
>      >? ? ? >? ? ?promising
>      >? ? ? >? ? ? > along with some tweaks to the TCP timeouts. I guess we
>      >? ? ?could use
>      >? ? ? >? ? ?ACLs to
>      >? ? ? >? ? ? > pick a different outbound IP based on the
>     requesting client's
>      >? ? ? >? ? ?prefix. We
>      >? ? ? >? ? ? > had not considered that option as the ephemeral
>     ports were
>      >? ? ?no longer
>      >? ? ? >? ? ? > available?to other applications when squid uses most of
>      >? ? ?them with a
>      >? ? ? >? ? ? > single outbound IP configured. We are also looking to
>      >? ? ?modify the
>      >? ? ? >? ? ?code to
>      >? ? ? >? ? ? > use the IP_BIND_ADDRESS_NO_PORT sockopt as that
>     could help
>      >? ? ?delay
>      >? ? ? >? ? ?port
>      >? ? ? >? ? ? > assignment with the bind() call on the outbound TCP
>      >? ? ?sessions (to
>      >? ? ? >? ? ? > hopefully allow access to the 4-tuple on the socket).
>      >? ? ? >
>      >? ? ? >? ? ?Patches welcome.
>      >? ? ? >
>      >? ? ? >? ? ?However, please be aware that use of the 4-tuple is
>     often no
>      >? ? ?different
>      >? ? ? >? ? ?from the 3-tuple since the dst-port is typically identical
>      >? ? ?for all
>      >? ? ? >? ? ?outgoing traffic to a given dst-IP.
>      >? ? ? >
>      >? ? ? >
>      >? ? ? >? ? ?Cheers
>      >? ? ? >? ? ?Amos



From csadi at hotmail.com  Sat Sep 10 18:19:23 2022
From: csadi at hotmail.com (Adiseshu Channasamudhram)
Date: Sat, 10 Sep 2022 18:19:23 +0000
Subject: [squid-users] https on frontend
Message-ID: <PH0PR14MB530976D868BCFACDF5BF6F20B3429@PH0PR14MB5309.namprd14.prod.outlook.com>

Hello Squid experts

I'm running in to an issue with the below setup

frontend -----------TLS-------------Squid-------------------------2WayTLS--------------------------Backend

When frontend is sending the http request, i see the tls exchange is successful but then on the access log of squid, i see the below error

w.x.y.z is the IP of the frontend server.

10/Sep/2022:00:13:34 +0000      0 w.x.y.z - - - TAG_NONE/400 4476 NONE error:invalid-request - HIER_NONE/- text/html - - -
10/Sep/2022:00:13:34 +0000      0 w.x.y.z - - - TAG_NONE/400 4476 NONE error:invalid-request - HIER_NONE/- text/html - - -
10/Sep/2022:00:13:34 +0000      0 w.x.y.z - - - TAG_NONE/400 4476 NONE error:invalid-request - HIER_NONE/- text/html - - -
10/Sep/2022:00:13:34 +0000      0 w.x.y.z - - - TAG_NONE/400 4016 %16%03%03 %A1%DFXl%A1%90yf%1C - HIER_NONE/- text/html - - -
10/Sep/2022:00:13:37 +0000      0 w.x.y.z - - - TAG_NONE/400 4476 NONE error:invalid-request - HIER_NONE/- text/html - - -
10/Sep/2022:00:13:37 +0000      0 w.x.y.z - - - TAG_NONE/400 4476 NONE error:invalid-request - HIER_NONE/- text/html - - -
10/Sep/2022:00:13:38 +0000      0 w.x.y.z - - - TAG_NONE/400 4476 NONE error:invalid-request - HIER_NONE/- text/html - - -
10/Sep/2022:00:13:38 +0000      0 w.x.y.z - - - TAG_NONE/400 4476 NONE error:invalid-request - HIER_NONE/- text/html - - -

On the squid interface listening to the frontend, I have pointed it to a self signed cert ...

Any help/suggestion would be greatly appreciated

Regards

Adi
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220910/a27bfffa/attachment.htm>

From squid3 at treenet.co.nz  Sat Sep 10 21:11:35 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 11 Sep 2022 09:11:35 +1200
Subject: [squid-users] https on frontend
In-Reply-To: <PH0PR14MB530976D868BCFACDF5BF6F20B3429@PH0PR14MB5309.namprd14.prod.outlook.com>
References: <PH0PR14MB530976D868BCFACDF5BF6F20B3429@PH0PR14MB5309.namprd14.prod.outlook.com>
Message-ID: <ef33deaf-3c02-8cba-c8df-12a20fbfa258@treenet.co.nz>

On 11/09/22 06:19, Adiseshu Channasamudhram wrote:
> Hello Squid experts
> 
> I'm running in to an issue with the below setup
> 
> frontend 
> -----------TLS-------------Squid-------------------------2WayTLS--------------------------Backend
> 
> When frontend is sending the http request, i see the tls exchange is 
> successful but then on the access log of squid, i see the below error
> 
> w.x.y.z is the IP of the frontend server.
> 
> 10/Sep/2022:00:13:34 +0000 ? ? ?0 w.x.y.z - - - TAG_NONE/400 4476 NONE 
> error:invalid-request - HIER_NONE/- text/html - - -
...
> On the squid interface listening to the frontend, I have pointed it to a 
> self signed cert ...
> 
> Any help/suggestion would be greatly appreciated
> 

Either the HTTP request messages received from the frontend inside the 
TLS are invalid, or your frontend<->Squid is misconfigured.

We will need to see your squid.conf details. Specifically these 
directives, though all settings (no comments or empty lines) would be 
useful for a full check:
  http_port, https_port, cache_peer, tls_outgoing_options

Also a cache/log trace made with "debug_options ALL,0 11,2" will be helpful.


Amos


From ngtech1ltd at gmail.com  Mon Sep 12 11:29:22 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Mon, 12 Sep 2022 14:29:22 +0300
Subject: [squid-users] [Troubleshoot] Squid 3.3 - Lots of 403 erros when
 reducing the workers number
In-Reply-To: <117109620.1554863650.1662711642360.JavaMail.root@zimbra17-e3.priv.proxad.net>
References: <d911ce4e-41c2-58b4-cb20-4a94c5d60e59@measurement-factory.com>
 <117109620.1554863650.1662711642360.JavaMail.root@zimbra17-e3.priv.proxad.net>
Message-ID: <000c01d8c69a$e896a680$b9c3f380$@gmail.com>

He Xavier,

I believe that there are couple logformat options that you should add to understand better this issue.
The first thing in this scenario is to have the squid.conf and access.log output.

If you have a load of about 100 rps you shouldn't be required to have more then 1-2 workers tops.
To know the actual load you can dump the cache manager details.
With the next script:
https://gist.github.com/elico/8790bdc835d8e9ecbc57e72fc31effc0

it would be possible to probably dump all the relevant sections and much more.
Just be advised to review them and the squid.conf and the access.log before send a link to a compressed archive
on the public list.

If you prefer you can send the link to there in a private email so I can try to review them.
Depends on the proxy network access it would be pretty simple to understand where this 403 is coming from.
It's also possible that it's from the origin server and not from the proxy.

I assume this 403 is not based on the authentication level but it might be possible to use a special deny_info to
"mark" the culprit deny acl in your squid.conf.
Ie we can set a special response code in the ranges of 40x or 50x to make sure if it's from the proxy side.

If I remember you are using basic authentication so it's pretty simple to write a threaded helper that will 
be responsible on all requests but I still need to see the squid.conf and access.log

Eliezer

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Xavier Lecluse
Sent: Friday, 9 September 2022 11:21
To: Alex Rousskov <rousskov at measurement-factory.com>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] [Troubleshoot] Squid 3.3 - Lots of 403 erros when reducing the workers number

Hello Alex,

Thanks for your answer.

>> We are using two squid proxies (Squid 3.3)

>Squid v3 is not officially supported. My answers below may apply to 
>Squid v3, but they are based on Squid v5+.


>> In order to address some issues with Java clients, we tried to lower
>> the worker directive from 8 to 1, because of the relative low number
>> of simultaneous connections on our SSquid servers (about 100rq/s) 
>> After reducing the worker value to 1, and restarting the proxies, we
>> observed a great number of 403 errors, so we decided to rollback to 8
>> workers.

>> - How the number of workers and these 403 errors can be correlated ?

>I do not know the exact correlation vector in your environment, but 
>fewer workers means, among other things, smaller _aggregate_ 
>authentication cache size and higher load on individual authentication 
>helpers. To pinpoint the correlation, we would need to know _why_ Squid 
>is generating 403 (Forbidden) errors.

Is there a specific way to find the reason ? Do I need to activate a certain logging level to see these traces ?
I will check in the actual logs and I'll come back if I don't find anything


>> - Is there any "recommandations" about the number of workers to use,
>> for a given number of request/s ?

>Workers are primarily a performance optimization. For related tuning 
>suggestions, please see 
>https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F

Yes, I saw and read this thread on the Wiki.
We were already using some of these recommandations.
I think we are quite far from a "top performance" but we didn't observed any performance issue when we used 8 workers.
I understand that an individual worker should be able to handle our actual load, but we have to find what is provoking the 403 errors first.

>> The inital problem is from some java clients, which are using two TCP
>> sessions, one for the authentication, and another one for the HTTP(s)
>> requests. The fact is that the "second" session is not always opened
>> on the same worker, so ot considers that the authentication step has
>> not already been done.

>> Is there a way to address this issue ?

>If (a request on) the second connection has enough information to link 
>it to the first/authenticated request/connection, then it may be 
>possible to configure Squid and write authentication helpers in such a 
>way that the "other" worker knows that the client of the second 
>connection has already authenticated. The details would depend on the 
>authentication scheme and that "linking" mechanism.

Do you have any example of an authentication helper I can start with ? or an example on how to "link" events between workers ?
I was thinking that workers were quite "individuals" and did not exchange anything (or verry little) with each other.
Any start point would be welcome.

Regards,
Xavier

>HTH,

>Alex.




----- Mail original -----
De: "Alex Rousskov" <rousskov at measurement-factory.com>
?: squid-users at lists.squid-cache.org
Envoy?: Jeudi 8 Septembre 2022 17:19:19
Objet: Re: [squid-users] [Troubleshoot] Squid 3.3 - Lots of 403 erros when reducing the workers number

On 9/8/22 10:15, Xavier Lecluse wrote:

> We are using two squid proxies (Squid 3.3)

Squid v3 is not officially supported. My answers below may apply to 
Squid v3, but they are based on Squid v5+.


> In order to address some issues with Java clients, we tried to lower
> the worker directive from 8 to 1, because of the relative low number
> of simultaneous connections on our SSquid servers (about 100rq/s) 
> After reducing the worker value to 1, and restarting the proxies, we
> observed a great number of 403 errors, so we decided to rollback to 8
> workers.

> - How the number of workers and these 403 errors can be correlated ?

I do not know the exact correlation vector in your environment, but 
fewer workers means, among other things, smaller _aggregate_ 
authentication cache size and higher load on individual authentication 
helpers. To pinpoint the correlation, we would need to know _why_ Squid 
is generating 403 (Forbidden) errors.


> - Is there any "recommandations" about the number of workers to use,
> for a given number of request/s ?

Workers are primarily a performance optimization. For related tuning 
suggestions, please see 
https://wiki.squid-cache.org/Features/SmpScale#How_to_configure_SMP_Squid_for_top_performance.3F


> The inital problem is from some java clients, which are using two TCP
> sessions, one for the authentication, and another one for the HTTP(s)
> requests. The fact is that the "second" session is not always opened
> on the same worker, so ot considers that the authentication step has
> not already been done.

> Is there a way to address this issue ?

If (a request on) the second connection has enough information to link 
it to the first/authenticated request/connection, then it may be 
possible to configure Squid and write authentication helpers in such a 
way that the "other" worker knows that the client of the second 
connection has already authenticated. The details would depend on the 
authentication scheme and that "linking" mechanism.


HTH,

Alex.

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From csadi at hotmail.com  Mon Sep 12 12:39:59 2022
From: csadi at hotmail.com (Adiseshu Channasamudhram)
Date: Mon, 12 Sep 2022 12:39:59 +0000
Subject: [squid-users] squid-users Digest, Vol 97, Issue 20
In-Reply-To: <mailman.3.1662897601.3540902.squid-users@lists.squid-cache.org>
References: <mailman.3.1662897601.3540902.squid-users@lists.squid-cache.org>
Message-ID: <PH0PR14MB53092FB919E55E07EC1C9EE0B3449@PH0PR14MB5309.namprd14.prod.outlook.com>

Hello Amos

Thank you for looking in to this. Below is the configuration ...


###########################
logformat squid %tl %6tr %>a %<a %dt %<rd %Ss/%>Hs %<st %rm %ru %un %Sh/%<A %mt %<tt %<pt %{Nuance-Session-ID}>h

cache_access_log /var/log/squid/access.log  squid
pid_filename /var/run/squid.pid

visible_hostname nuance-ak-client-test2

acl Safe_ports port 80
acl Safe_ports port 443
acl SSL_ports port 443
acl SSL method CONNECT
acl CONNECT method CONNECT

cache deny all
dns_v4_first on
http_port 443 tcpkeepalive=60,30,3 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/etc/squid/squidCA.pem  cipher=HIGH:MEDIUM:!LOW:!RC4:!SEED:!IDEA:!3DES:!MD5:!EXP:!PSK:!DSS options=NO_TLSv1,NO_SSLv3,NO_SSLv2,SINGLE_DH_USE,SINGLE_ECDH_USE tls-dh=prime256v1:/etc/squid/bump_dhparam.pem

# Below, a.b.c.d is the backend IP
cache_peer a.b.c.d parent 443 0 no-query proxy-only no-digest originserver ssl sslcert=/etc/certs/abc.crt sslkey=/etc/certs/key.pem sslcapath=/etc/certs/ sslflags=DONT_VERIFY_PEER name=dev
acl dev myport 443
acl dev myport 80
acl dev myport 3129

http_access allow all

cache_peer_access dev allow dev
#cache_peer_access dev deny all
#URL_REWRITE_PROGRAM /etc/squid/rewrite-http.pl
sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB
sslcrtd_children 5
ssl_bump server-first all
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER


________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of squid-users-request at lists.squid-cache.org <squid-users-request at lists.squid-cache.org>
Sent: Sunday, September 11, 2022 8:00 AM
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: squid-users Digest, Vol 97, Issue 20

Send squid-users mailing list submissions to
        squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
        http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
        squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
        squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. https on frontend (Adiseshu Channasamudhram)
   2. Re: https on frontend (Amos Jeffries)


----------------------------------------------------------------------

Message: 1
Date: Sat, 10 Sep 2022 18:19:23 +0000
From: Adiseshu Channasamudhram <csadi at hotmail.com>
To: "squid-users at lists.squid-cache.org"
        <squid-users at lists.squid-cache.org>
Subject: [squid-users] https on frontend
Message-ID:
        <PH0PR14MB530976D868BCFACDF5BF6F20B3429 at PH0PR14MB5309.namprd14.prod.outlook.com>

Content-Type: text/plain; charset="iso-8859-1"

Hello Squid experts

I'm running in to an issue with the below setup

frontend -----------TLS-------------Squid-------------------------2WayTLS--------------------------Backend

When frontend is sending the http request, i see the tls exchange is successful but then on the access log of squid, i see the below error

w.x.y.z is the IP of the frontend server.

10/Sep/2022:00:13:34 +0000      0 w.x.y.z - - - TAG_NONE/400 4476 NONE error:invalid-request - HIER_NONE/- text/html - - -
10/Sep/2022:00:13:34 +0000      0 w.x.y.z - - - TAG_NONE/400 4476 NONE error:invalid-request - HIER_NONE/- text/html - - -
10/Sep/2022:00:13:34 +0000      0 w.x.y.z - - - TAG_NONE/400 4476 NONE error:invalid-request - HIER_NONE/- text/html - - -
10/Sep/2022:00:13:34 +0000      0 w.x.y.z - - - TAG_NONE/400 4016 %16%03%03 %A1%DFXl%A1%90yf%1C - HIER_NONE/- text/html - - -
10/Sep/2022:00:13:37 +0000      0 w.x.y.z - - - TAG_NONE/400 4476 NONE error:invalid-request - HIER_NONE/- text/html - - -
10/Sep/2022:00:13:37 +0000      0 w.x.y.z - - - TAG_NONE/400 4476 NONE error:invalid-request - HIER_NONE/- text/html - - -
10/Sep/2022:00:13:38 +0000      0 w.x.y.z - - - TAG_NONE/400 4476 NONE error:invalid-request - HIER_NONE/- text/html - - -
10/Sep/2022:00:13:38 +0000      0 w.x.y.z - - - TAG_NONE/400 4476 NONE error:invalid-request - HIER_NONE/- text/html - - -

On the squid interface listening to the frontend, I have pointed it to a self signed cert ...

Any help/suggestion would be greatly appreciated

Regards

Adi
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220910/a27bfffa/attachment-0001.htm>

------------------------------

Message: 2
Date: Sun, 11 Sep 2022 09:11:35 +1200
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] https on frontend
Message-ID: <ef33deaf-3c02-8cba-c8df-12a20fbfa258 at treenet.co.nz>
Content-Type: text/plain; charset=UTF-8; format=flowed

On 11/09/22 06:19, Adiseshu Channasamudhram wrote:
> Hello Squid experts
>
> I'm running in to an issue with the below setup
>
> frontend
> -----------TLS-------------Squid-------------------------2WayTLS--------------------------Backend
>
> When frontend is sending the http request, i see the tls exchange is
> successful but then on the access log of squid, i see the below error
>
> w.x.y.z is the IP of the frontend server.
>
> 10/Sep/2022:00:13:34 +0000 ? ? ?0 w.x.y.z - - - TAG_NONE/400 4476 NONE
> error:invalid-request - HIER_NONE/- text/html - - -
...
> On the squid interface listening to the frontend, I have pointed it to a
> self signed cert ...
>
> Any help/suggestion would be greatly appreciated
>

Either the HTTP request messages received from the frontend inside the
TLS are invalid, or your frontend<->Squid is misconfigured.

We will need to see your squid.conf details. Specifically these
directives, though all settings (no comments or empty lines) would be
useful for a full check:
  http_port, https_port, cache_peer, tls_outgoing_options

Also a cache/log trace made with "debug_options ALL,0 11,2" will be helpful.


Amos


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 97, Issue 20
*******************************************
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220912/58c01b39/attachment.htm>

From hfasching at barracuda.com  Mon Sep 12 13:06:04 2022
From: hfasching at barracuda.com (Hannes Fasching)
Date: Mon, 12 Sep 2022 13:06:04 +0000
Subject: [squid-users] [EXTERNAL] Re: Exchange server authentication via
 squid reverse proxy not working after upgrade from squid 4.15 to 5.6
In-Reply-To: <bd2a3a0f-b210-8f83-c70a-a506ca172cdc@treenet.co.nz>
References: <DM6PR10MB3740189C7803EC2C750365E6B3409@DM6PR10MB3740.namprd10.prod.outlook.com>
 <bd2a3a0f-b210-8f83-c70a-a506ca172cdc@treenet.co.nz>
Message-ID: <DM6PR10MB3740208B6C31955ACA904C53B3449@DM6PR10MB3740.namprd10.prod.outlook.com>

Hi Amos,
thanks for your answer. It's a new point to look at and brings me one step further.

Kind regards,
Hannes





Von: squid-users <squid-users-bounces at lists.squid-cache.org> im Auftrag von Amos Jeffries <squid3 at treenet.co.nz>
Gesendet: Freitag, 9. September 2022 06:45
An: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Betreff: [EXTERNAL] Re: [squid-users] Exchange server authentication via squid reverse proxy not working after upgrade from squid 4.15 to 5.6

On 8/09/22 19:40, Hannes Fasching wrote:
> Hello,
> A customer have an issue that after upgrading from squid 4.15 to actual 5.6 with reverse proxy mode for an exchange server.
> The authentication is not working anymore when the integrated Windows authentication is enabled (needed for SSO). When disabled, the authentication via squid is then working.


The squid.conf you link to below does not perform any authentication.
Squid is configured just to relay any auth headers as-is to the Exchange
server / peer.

To clarify some details here:

* "SSO" means simply that all services on a network are supposed to
accept the same credentials.
  - Microsoft making a big noise about this terminology is purely
marketing hype. SSO can be performed with any auth scheme and any
credentials - it is entirely a matter of what the service doing the
authentication accepts as valid credentials. So this can be ignored for
troubleshooting purposes.


* "integrated Windows authentication" means simply that the Browser is
supposed to have access to the users Windows account to send their
machine login credentials when auth is needed.
  - So the thing to be looking at is whether the Browser (or other
client software) is able to access and send the user login when
authenticating.
  - If it is sending some other credentials that is a problem. Look at
where they are coming from and why.


* authentication _scheme_ is simply a way to deliver the credentials
from some client to some server.
  - these are dictated by the server doing the authentication. As long
as the client software is using a scheme the service indicated as
available things should work correctly.
  - this is where Squid comes in.
   ** If Squid is participating in the authentication the scheme is
limited to one where three agents can share it (eg Basic).
   ** If Squid is blindly relaying then only the client and server need
to agree on the scheme. But Squid needs to avoid breaking the scheme
requirements (eg NTLM/Negotiate restrict TCP connection multiplexing,
Digest restricts server load balancing).


> The difference is that Windows with integrated authentication is trying several authentication schemes otherwise only Basic authentication is used.
> Please follow the link to see the squid.conf and the cache log file starting with the attempt when it fails and afterwards, with the time stamp 19:15, the attempt when it is working.
>
> https://barracudacorp-my.sharepoint.com/:u:/g/personal/hfasching_barracuda_com/EZBjHnJqCaFLlArPb8a_-FwB-7FIzvK0e21ow1Qec-MVhw?e=5149sA (squid.conf)
> https://barracudacorp-my.sharepoint.com/:u:/g/personal/hfasching_barracuda_com/EcPpd3DeeoFLs4_9Dn6JWAYBbHrwenOEJ3SZ0IW8_ED1-A?e=Ff9BZc (squid_cache.log)
>
> It would be great if you could help me finding out what is wrong with Windows integrated authentication as our customer needs the SSO feature.


What I would be looking at here is the HTTP(S) message flows and headers
to see what type of credentials the user/client is trying to send
through Squid to Exchange. What auth scheme they are being sent with.
And what TCP connections ("FD") they are being sent on when leaving Squid.


What I see in the log you posted is two client connections doing the
following:

Client connection #1:
  * sends POST with Basic auth
  * server accepts
  * sends OPTIONS with Basic auth
  * server accepts

That looks good. Check that the credentials sent were the users Windows
login and were sent automatically. If so then "SSO" is working.


Client connection #2:
  * sends POST with Bearer auth
  * server rejects (401)
  * sends POST with no credentials
  * server rejects (401)
  * sends POST with no credentials
  * server rejects (401)

   - I think this client software is broken. It should absolutely *not*
be sending any requests without authentication after having received
that first 401 status. It should be trying alternative schemes, or
alternative credentials with each scheme, or going away.


Client connection #2 (after a short delay):

  * sends POST with Negotiate/NTLMv2 client capabilities token
  * server responds per NTLMv2 (401 status)
    - I assume it also produces the nonce token though I don't see the
header logged
  * sends POST with Negotiate/NTLMv2 proof of identity token
  * server rejects (401)

That looks like Squid is correctly relaying the NTLMv2 handshake
messages. But the Exchange server does not like the login for some reason.
  I would at this point be checking whether the credentials used here
were actually the users Windows login, and whether Exchange server is
validating properly.
  I am not familiar with Exchange but this may be something to do with
NTLMv2 credentials using Negotiate scheme instead of NTLM scheme.
Negotiate scheme typically means Kerberos handshake expected since NTLM
was formally deprecated by Microsoft in April 2006.


HTH
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

Get the 13 Email Threat Types eBook

https://www.barracuda.com/

This e-mail and any attachments to it contain confidential and proprietary material of Barracuda, its affiliates or agents, and is solely for the use of the intended recipient. Any review, use, disclosure, distribution or copying of this transmittal is prohibited except by or on behalf of the intended recipient. If you have received this transmittal in error, please notify the sender and destroy this e-mail and any attachments and all copies, whether electronic or printed.

________________________________


From roeeklinger60 at gmail.com  Mon Sep 12 22:20:10 2022
From: roeeklinger60 at gmail.com (roee klinger)
Date: Tue, 13 Sep 2022 01:20:10 +0300
Subject: [squid-users] Do squid logs performence affect general request
 performece?
In-Reply-To: <9e76568b-a203-fe03-3025-8ff0a47fc2c5@measurement-factory.com>
References: <190bd8ec-0724-44dd-96b2-3f9e6505d92e@Spark>
 <5ac180f3-41c7-463b-8266-4fef7ee0fee4@Spark>
 <9e76568b-a203-fe03-3025-8ff0a47fc2c5@measurement-factory.com>
Message-ID: <9b254c79-ed34-4464-a767-a9863e4e2ab4@Spark>

Hello,

Thank you for your advice, as suggested I tested a both TCP and UDP, and found TCP to be so slow
that is it practically unusable, UDP however works fine, but has the normal disadvantages of UDP.

It seems that TCP sends each message by itself, and UDP sends them in bulk (10-20 at a time),
which seems to be a big part of the performance difference, in fact TCP is so slow that it causes
Squid to crash after a while.

After carefully reading the logs, I tried to get TCP to send in bulk as well by configuring:
> quote_type
> logformat logstash %ts.%03tu %6tr %>a %<la %>lp %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a %mt %{Client-Tags}>h
> access_log tcp://127.0.0.1:5400 logformat=logstash buffer-size=64KB
> buffered_logs on
>
But it seems to still be sending the logs line by line, am I missing something?

Thanks,
Roee
On 9 Sep 2022, 19:57 +0300, Alex Rousskov <rousskov at measurement-factory.com>, wrote:
> On 9/9/22 08:49, roee klinger wrote:
> > Hello,
> >
> > I have just recently started exploring ingesting logs from Squid via
> > Logstash (TCP log ingestion)
> >
> > I now have to make the decision of how to deploy Logstash, it seems to
> > me that I have two options:
> >
> > 1. Deploy a Logstash instance for every region where I have a Squid
> > instance running, resulting in the lowest latency possible between
> > Squid and Logstash.
> > 2. Deploy a central Logstash instance for all Squid instance worldwide,
> > which is the cheapest and easiest option, but will have high latency
> > for some of the Squid instance which are located far away
> > geographically from the Logstash instance.
> >
> > I already know that if the log server crashes in Squid, then Squid will
> > crash with a fatal error,
>
> FYI: Logging error handling is configurable via "access_log on-error".
>
>
> > so Squid takes logging very seriously, so my
> > question is: does TCP logging performance in Squid effect the total
> > request performance, or are they independent from each other?
>
> TCP logger uses asynchronous non-blocking I/O. Individual HTTP
> transactions do not wait for individual log records to be sent. Needless
> to say, logging does consume resources and, hence, may affect overall
> HTTP transaction performance. And if the log record recipient is too
> slow, then Squid will die and/or log records will be dropped.
>
>
> > What would be you recommendations, if request performance is crucial
> > (and log performance is not)?
>
> I would not be surprised if you would not be able to measure meaningful
> performance difference among these modules. From general performance
> point of view, and module-specific bugs and limitations notwithstanding,
> I would expect "daemon" and "udp" modules to have smaller performance
> overhead/cost for Squid workers than the "tcp" module because I expect
> that TCP has to "do more" than stdout I/O and UDP. However, I would not
> base this decision on such high-level speculations and test various
> options instead.
>
>
> HTH,
>
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220913/9020f0a6/attachment.htm>

From rousskov at measurement-factory.com  Tue Sep 13 03:30:39 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 12 Sep 2022 23:30:39 -0400
Subject: [squid-users] Do squid logs performence affect general request
 performece?
In-Reply-To: <9b254c79-ed34-4464-a767-a9863e4e2ab4@Spark>
References: <190bd8ec-0724-44dd-96b2-3f9e6505d92e@Spark>
 <5ac180f3-41c7-463b-8266-4fef7ee0fee4@Spark>
 <9e76568b-a203-fe03-3025-8ff0a47fc2c5@measurement-factory.com>
 <9b254c79-ed34-4464-a767-a9863e4e2ab4@Spark>
Message-ID: <b7f407f8-5902-75f5-532c-8afa5401e7be@measurement-factory.com>

On 9/12/22 18:20, roee klinger wrote:

> Thank you for your advice, as suggested I tested a both TCP and UDP, and 
> found TCP to be so slow
> that is it practically unusable, UDP however works fine, but has the 
> normal disadvantages of UDP.

Glad that test yielded useful results in your environment!


> It seems that TCP sends each message by itself, and UDP sends them in 
> bulk (10-20 at a time),
> which seems to be a big part of the performance difference, in fact TCP 
> is so slow that it causes Squid to crash after a while.
> 
> After carefully reading the logs, I tried to get TCP to send in bulk as 
> well by configuring:
> 
>     logformat logstash %ts.%03tu %6tr %>a %<la %>lp %Ss/%03>Hs %<st %rm
>     %ru %[un %Sh/%<a %mt %{Client-Tags}>h
>     access_log tcp://127.0.0.1:5400 logformat=logstash buffer-size=64KB
>     buffered_logs on
> 
> But it seems to still be sending the logs line by line, am I missing 
> something?


I have not tested this, but if my interpretation of the underlying code 
is correct, then the TCP logging module code does not flush the buffer 
when it accumulates (close to) buffer-size bytes. Instead, the module 
starts writing its buffer after accumulating more than 16KB (2*MAX_URL). 
How long are your typical access.log records?

Each write(2) call of a buffering TCP logging module during normal Squid 
operation should be 16KB, regardless of the buffer-size setting.

FWIW, the official access_log buffer-size documentation hints at 
module-specific flushing algorithms. I cannot describe the exact 
algorithm used by the TCP logging module in a few words, but it is not 
as simple as "accumulate buffer-size bytes and then write the 
accumulated bytes".


HTH,

Alex.


> On 9 Sep 2022, 19:57 +0300, Alex Rousskov wrote:
>> On 9/9/22 08:49, roee klinger wrote:
>>> Hello,
>>>
>>> I have just recently started exploring ingesting logs from Squid via
>>> Logstash (TCP log ingestion)
>>>
>>> I now have to make the decision of how to deploy Logstash, it seems to
>>> me that I have two options:
>>>
>>> 1. Deploy a Logstash instance for every region where I have a Squid
>>> instance running, resulting in the lowest latency possible between
>>> Squid and Logstash.
>>> 2. Deploy a central Logstash instance for all Squid instance worldwide,
>>> which is the cheapest and easiest option, but will have high latency
>>> for some of the Squid instance which are located far away
>>> geographically from the Logstash instance.
>>>
>>> I already know that if the log server crashes in Squid, then Squid will
>>> crash with a fatal error,
>>
>> FYI: Logging error handling is configurable via "access_log on-error".
>>
>>
>>> so Squid takes logging very seriously, so my
>>> question is: does TCP logging performance in Squid effect the total
>>> request performance, or are they independent from each other?
>>
>> TCP logger uses asynchronous non-blocking I/O. Individual HTTP
>> transactions do not wait for individual log records to be sent. Needless
>> to say, logging does consume resources and, hence, may affect overall
>> HTTP transaction performance. And if the log record recipient is too
>> slow, then Squid will die and/or log records will be dropped.
>>
>>
>>> What would be you recommendations, if request performance is crucial
>>> (and log performance is not)?
>>
>> I would not be surprised if you would not be able to measure meaningful
>> performance difference among these modules. From general performance
>> point of view, and module-specific bugs and limitations notwithstanding,
>> I would expect "daemon" and "udp" modules to have smaller performance
>> overhead/cost for Squid workers than the "tcp" module because I expect
>> that TCP has to "do more" than stdout I/O and UDP. However, I would not
>> base this decision on such high-level speculations and test various
>> options instead.
>>
>>
>> HTH,
>>
>> Alex.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users



From dwd at fnal.gov  Wed Sep 14 11:30:40 2022
From: dwd at fnal.gov (Dave Dykstra)
Date: Wed, 14 Sep 2022 11:30:40 +0000
Subject: [squid-users] Is there a way to ignore incoming If-Modified-Since
 request?
Message-ID: <YyG7YF9I7r9dlQMx@fnal.gov>

I have tried playing around with reply_header_access and
request_header_access, and looking for other options having to do
with "ims" or "revalid" but have not had any luck finding an option
to ignore If-Modified-Since headers in requests from clients.  Is
there a way to do it?  Alternatively it would work for me to ignore
Last-Modified headers from the upstream server.

The reason I am asking is for a squid instance using rock cache where I
want to make sure that this bug (or I guess you could call it a feature
since it is documented behavior) related to collapsed forwarding is
avoided:
    https://bugs.squid-cache.org/show_bug.cgi?id=4890
Collapsed forwarding is very important for my applications but in this
case If-Modified-Since is not important.

Thanks,

Dave

From daku8938 at gmx.de  Thu Sep 15 14:29:31 2022
From: daku8938 at gmx.de (Hildegard Meier)
Date: Thu, 15 Sep 2022 16:29:31 +0200
Subject: [squid-users] Howto make Squid config dependent on hostname?
Message-ID: <trinity-a2935dc4-afa5-44ae-95e9-02f034d48a30-1663252171595@3c-app-gmx-bs05>

Hello,

we have two Squid servers (Linux hosts) and each shall have the very same config file /etc/squid/squid.conf
which is versioned and deployed from a central deployment server.
So each host shall have deployed the same files.

Each of the two shall have the other configured as sibling cache peer.

So node1 shall have
cache_peer node2.examlpe.com sibling 3128 3130

and node2 shalle have
cache_peer node1.examlpe.com sibling 3128 3130

I guess it is not so nice to have both configured with both lines together, no?

cache_peer node1.examlpe.com sibling 3128 3130
cache_peer node2.examlpe.com sibling 3128 3130

With above, each node would not only have the othe node as sibling, but also itself configured as sibling, that's ugly and I do not know how squid will handle that.
I tested that, and config parser does say ok, and squid starts with that, but I find that ugly.

Does squif offer a hostname conditional if clause ?
In the docu is mentioned the squid config if-else-condition, but I did not find any example about it and what macros/variables/values one could use with it.

I think about something like this:

if $MY_HOSTNAME == 'node1' then
    cache_peer node2.examlpe.com sibling 3128 3130
fi

if $MY_HOSTNAME == 'node2' then
    cache_peer node1.examlpe.com sibling 3128 3130
fi

Best regards


From rousskov at measurement-factory.com  Thu Sep 15 18:06:37 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 15 Sep 2022 14:06:37 -0400
Subject: [squid-users] Howto make Squid config dependent on hostname?
In-Reply-To: <trinity-a2935dc4-afa5-44ae-95e9-02f034d48a30-1663252171595@3c-app-gmx-bs05>
References: <trinity-a2935dc4-afa5-44ae-95e9-02f034d48a30-1663252171595@3c-app-gmx-bs05>
Message-ID: <7eac75df-a0e6-3195-850f-715da132f3fb@measurement-factory.com>

On 9/15/22 10:29, Hildegard Meier wrote:

> we have two Squid servers (Linux hosts) and each shall have the very same config file /etc/squid/squid.conf
> which is versioned and deployed from a central deployment server.
> So each host shall have deployed the same files.
> 
> Each of the two shall have the other configured as sibling cache peer.
> 
> So node1 shall have
> cache_peer node2.examlpe.com sibling 3128 3130
> 
> and node2 shalle have
> cache_peer node1.examlpe.com sibling 3128 3130
> 
> I guess it is not so nice to have both configured with both lines together, no?
> 
> cache_peer node1.examlpe.com sibling 3128 3130
> cache_peer node2.examlpe.com sibling 3128 3130

 > I find that ugly.

I agree.

Squid does not support being its own peer (yet?): Upon startup, Squid 
validates connectivity to peers. If that validation happens before Squid 
starts listening for requests, the validation will (silently) fail. 
There are several race conditions here, but that failure is likely in a 
self-peering case.

In your particular use case, such self-peering also does not reflect 
reality. You do not want to lie to Squid about it being its own peer 
because Squid will try to use both configured peers, creating problems 
that you do not want to solve. It also duplicates peer configurations.


> Does squif offer a hostname conditional if clause ?

Not yet. Squid currently only supports three kinds of conditions: true, 
false, and integer equality comparison (as documented).

The only build-in macro that always yields an integer is the 
${process_number} macro.

Depending on your setup, you may also be able to use the ${service_name} 
macro if your service name is an integer, but that is kind of hacky, and 
I have not tested it.

For now, your best option is probably to post-process the versioned 
configuration to substitute your own custom macro(s). For example, your 
Squid startup (or deployment) stript can substitute a 
${mynamespace:PeerName} macro in squid.conf.template with either true or 
false, depending on the node, producing squid.conf that Squid can use:

cache_peer ${mynamespace:PeerName} sibling 3128 3130


If you need to hard-code peer names or substantially different 
configurations for individual cache peers, then you can do something 
like this in the template configuration file:

if ${mynamespace:AtNode1()}
     cache_peer node2.example.com sibling 3128 3130
endif

if ${mynamespace:AtNode2()}
     cache_peer node1.example.com sibling 3128 3130
endif


FWIW, quality PRs introducing the following related features should be 
welcomed IMO:

* a macro function evaluating a named environment variable
* a macro function evaluating a given shell command
* string comparison in squid.conf conditionals


HTH,

Alex.


> I think about something like this:
> 
> if $MY_HOSTNAME == 'node1' then
>      cache_peer node2.examlpe.com sibling 3128 3130
> fi
> 
> if $MY_HOSTNAME == 'node2' then
>      cache_peer node1.examlpe.com sibling 3128 3130
> fi


From ngtech1ltd at gmail.com  Thu Sep 15 22:23:18 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Fri, 16 Sep 2022 01:23:18 +0300
Subject: [squid-users] Seems like the 5.7 was picked automatically at the git
Message-ID: <000001d8c951$c2861250$479236f0$@gmail.com>

Hey,
 
Per the request for an updated version of squid for automation, it seems that the repo is working file at:
https://github.com/elico/squid-latest
 
and is being updated automatically and the 5.7 was just released?
 
It will be built in the next hour and will be deployed.
 
I have not received any mail message about it.
 
Eliezer
 
----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email:  <mailto:ngtech1ltd at gmail.com> ngtech1ltd at gmail.com
Web:  <https://ngtech.co.il/> https://ngtech.co.il/
My-Tube:  <https://tube.ngtech.co.il/> https://tube.ngtech.co.il/
 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220916/9edb21e0/attachment.htm>

From gtaylor at tnetconsulting.net  Fri Sep 16 03:26:04 2022
From: gtaylor at tnetconsulting.net (Grant Taylor)
Date: Thu, 15 Sep 2022 21:26:04 -0600
Subject: [squid-users] Howto make Squid config dependent on hostname?
In-Reply-To: <trinity-a2935dc4-afa5-44ae-95e9-02f034d48a30-1663252171595@3c-app-gmx-bs05>
References: <trinity-a2935dc4-afa5-44ae-95e9-02f034d48a30-1663252171595@3c-app-gmx-bs05>
Message-ID: <e4e937ac-222d-f5a0-f292-4e1fc0aa6f03@spamtrap.tnetconsulting.net>

On 9/15/22 8:29 AM, Hildegard Meier wrote:
> Hello,

Hi,

> we have two Squid servers (Linux hosts) and each shall have the very 
> same config file /etc/squid/squid.conf which is versioned and deployed 
> from a central deployment server.  So each host shall have deployed 
> the same files.
> 
> Each of the two shall have the other configured as sibling cache peer.
> 
> So node1 shall have
> cache_peer node2.examlpe.com sibling 3128 3130
> 
> and node2 shalle have
> cache_peer node1.examlpe.com sibling 3128 3130

I have no idea if it will work or not, but I might be tempted to try -- 
what I first saw as -- Solaris's "mailhost" or "losthost" name overloading.

Meaning that you would have a single identical entry in the config file 
on both systems:

    cache_peer peer-cache-node.example.com sibling 3128 3130

And then each host would use /etc/hosts to resolve the 
peer-cache-node.example.com name to it's neighbor's IP.  E.g.

node1:/etc/hosts
    ...
    192.0.2.1	node1.example.com
    192.0.2.2	node2.example.com peer-cache-node.example.com
    ...

node2:/etc/hosts
    ...
    192.0.2.1	node1.example.com peer-cache-node.example.com
    192.0.2.2	node2.example.com
    ...

I sort of suspect that the nodes already have a per-node /etc/hosts file.

This is untested and wild speculation on my part.  Can / will someone 
with more experience comment on the viability of such "mailhost" or 
"loghost" use?

Aside:  Solaris 8 / 9 / 10 used to ship with a lot of files configured 
with <something>host used in various configuration files and rely on the 
name resolution to resolve that to the proper IP address for the 
environment, be it the hosts file, NIS(+), or DNS.



-- 
Grant. . . .
unix || die

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4017 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220915/d5954aff/attachment.bin>

From eric.perrot at interieur.gouv.fr  Fri Sep 16 07:11:58 2022
From: eric.perrot at interieur.gouv.fr (PERROT Eric DNUM SDCAST BST SSAIM)
Date: Fri, 16 Sep 2022 09:11:58 +0200
Subject: [squid-users] [squid][v5.6] : problem with "slow" or "fast" acl
In-Reply-To: <000001d8c21b$ece0a340$c6a1e9c0$@gmail.com>
References: <6315EC88.6050505@interieur.gouv.fr>
 <6315F1FD.5010501@interieur.gouv.fr>
 <33020e46-99dc-d860-324b-30da97991049@articatech.com>
 <000001d8c21b$ece0a340$c6a1e9c0$@gmail.com>
Message-ID: <134aba14e66bb9d58b5999d733a64627@interieur.gouv.fr>

 

Hello Elizer and David, 

Sorry for the delay, I have been monopolized by another subject... 

I am not sur to understand how note acl could help me. If the idear of
"note acl" is similar to the one proposed by Amos (creating a group with
annotate acl). 

My requirement is to have special limitation for logged users, except
for those with a login starting by cg_*.

I have been using proxy_auth acl to identify my users, but this acl is
slow and is not recommended with limitation directive
("reply_body_max_size", "request_body_max_size" and "delay_access"). 

I am testing to create groups today and I'll come back to you

Thank you for your thinking, 

Eric 

Le 06/09/2022 20:10, ngtech1ltd at gmail.com a ?crit : 

> Hey Eric and David, 
> 
> I am thinking about the best place to put a note acl. 
> 
> What is the actual requirement?
> Do you want to limit a specific client or all of them?
> I have not used delay pools for a very long time so I am not sure about what you want these to do. 
> 
> Eliezer 
> 
> ---- 
> 
> Eliezer Croitoru 
> 
> NgTech, Tech Support 
> 
> Mobile: +972-5-28704261 
> 
> Email: ngtech1ltd at gmail.com 
> 
> Web: https://ngtech.co.il/ [2] 
> 
> My-Tube: https://tube.ngtech.co.il/ [3] 
> 
> FROM: squid-users <squid-users-bounces at lists.squid-cache.org> ON BEHALF OF David Touzeau
> SENT: Tuesday, 6 September 2022 18:45
> TO: squid-users at lists.squid-cache.org
> SUBJECT: Re: [squid-users] [squid][v5.6] : problem with "slow" or "fast" acl 
> 
> Hi Eric. 
> 
> We had the same restrictions with the fast or slow ACLs. 
> Have you thought about creating a squid helper that calculates your needs? 
> So maybe you can get around this by using the acl "note" acl note xxx xxx which turns your helper results (slow) into "fast". 
> 
> Le 05/09/2022 ? 14:56, PERROT Eric DNUM SDCAST BST SSAIM a ?crit : 
> 
>> Hello,
>> 
>> We use directives "reply_body_max_size", "request_body_max_size" and "delay_access" to limit upload, download and passband in our infra.
>> 
>> This configuration existes since a while, but we have noticed that with squid v4.16, our delay pool didn't react as we wanted anymore. We were excpeting improvment upgrading squid to v5.6. But it got worth :
>> - restriction still didn't work
>> - and squid had a segmentation fault each time some acl where used
>> 
>> Thanks to Alex Rousskov (bug 5231), after some investigation, it appears that we used "slow" acl (proxy_auth an time acl) where only "fast" acl where authorized...). The bug is still open as squid has not flagged the problem in cache logs, 
>> 
>> My email, is to show you our configuration and the behaviour we espect, and the behaviour we finally have.
>> 1 - squd v4.12 : we expect to limit downlod/upload and passband during working time for all login except those starting with cg_*
>> "
>> ###### Gestion de bande passante ##########
>> acl bureau time 09:00-12:00
>> acl bureau time 14:00-17:00
>> # Comptes generiques
>> acl my_ldap_auth proxy_auth REQUIRED
>> acl cgen proxy_auth_regex cg_
>> reply_body_max_size 800 MB BUREAU !CGEN
>> request_body_max_size 5 MB 
>> # La limite de bande passante ne fonctionne plus avec le BUMP
>> # A tester ...
>> delay_pools 1
>> # Pendant time sauf cgen, emeraude 
>> delay_class 1 4
>> delay_access 1 allow MY_LDAP_AUTH !CGEN !emeraude
>> delay_access 1 deny all
>> # 512000 = 5120 kbits/user 640 ko
>> # 307200 = 3072 kbits/user 384 ko
>> delay_parameters 1 -1/-1 -1/-1 -1/-1 107200/107200
>> ##################################################
>> "
>> => with this configuration, the delay pool seemed not to work anymore, so we upgraded squid to v5.6. Which caused the squid segmentation fault... 
>> 
>> 2 - squid v5.6 : to solve the segmentation fault, we had to take off my_ldap_auth/cgen (proxy_auth acl) and bureau (time acl). The limitation work again, but we are no more able to limit restriction during working time, or for sp?cific login...
>> "
>> ###### Gestion de bande passante ##########
>> acl bureau time 09:00-12:00
>> acl bureau time 14:00-17:00
>> # Comptes generiques
>> acl userrgt src 10.0.0.0/8
>> acl my_ldap_auth proxy_auth REQUIRED
>> acl cgen proxy_auth_regex cg_
>> reply_body_max_size 800 MB USERRGT
>> request_body_max_size 5 MB 
>> # La limite de bande passante ne fonctionne plus avec le BUMP
>> # A tester ...
>> delay_pools 1
>> # Pendant time sauf cgen, emeraude 
>> delay_class 1 4
>> delay_access 1 allow!emeraude
>> delay_access 1 deny all
>> # 512000 = 5120 kbits/user 640 ko
>> # 307200 = 3072 kbits/user 384 ko
>> delay_parameters 1 -1/-1 -1/-1 -1/-1 107200/107200
>> ##################################################
>> "
>> 
>> Can you tell me if what we want to do is still possible? Limiting upload/download/passband for all logged user except those starting by cg_*..?.
>> 
>> Thank you for the time reading, and thank you for your answers.
>> 
>> Regards,
>> 
>> Eric Perrot 
>> 
>> Pour une administration exemplaire, pr?servons l'environnement. 
>> 
>> N'imprimons que si n?cessaire. 
>> 
>> _______________________________________________
>> 
>> squid-users mailing list
>> 
>> squid-users at lists.squid-cache.org
>> 
>> http://lists.squid-cache.org/listinfo/squid-users [1]
> 
> -- 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users [1]
 

Links:
------
[1] http://lists.squid-cache.org/listinfo/squid-users
[2] https://ngtech.co.il/
[3] https://tube.ngtech.co.il/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220916/aa07da5d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 10699 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220916/aa07da5d/attachment.png>

From squid3 at treenet.co.nz  Fri Sep 16 07:50:37 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 16 Sep 2022 19:50:37 +1200
Subject: [squid-users] Howto make Squid config dependent on hostname?
In-Reply-To: <e4e937ac-222d-f5a0-f292-4e1fc0aa6f03@spamtrap.tnetconsulting.net>
References: <trinity-a2935dc4-afa5-44ae-95e9-02f034d48a30-1663252171595@3c-app-gmx-bs05>
 <e4e937ac-222d-f5a0-f292-4e1fc0aa6f03@spamtrap.tnetconsulting.net>
Message-ID: <70c37ede-be61-eabf-2304-9debf928e807@treenet.co.nz>

On 16/09/22 15:26, Grant Taylor wrote:
> On 9/15/22 8:29 AM, Hildegard Meier wrote:
>> Hello,
> 
> Hi,
> 
>> we have two Squid servers (Linux hosts) and each shall have the very 
>> same config file /etc/squid/squid.conf which is versioned and deployed 
>> from a central deployment server.? So each host shall have deployed 
>> the same files.
>>
>> Each of the two shall have the other configured as sibling cache peer.
>>
>> So node1 shall have
>> cache_peer node2.examlpe.com sibling 3128 3130
>>
>> and node2 shalle have
>> cache_peer node1.examlpe.com sibling 3128 3130
> 
> I have no idea if it will work or not, but I might be tempted to try -- 
> what I first saw as -- Solaris's "mailhost" or "losthost" name overloading.
> 
> Meaning that you would have a single identical entry in the config file 
> on both systems:
> 
>  ?? cache_peer peer-cache-node.example.com sibling 3128 3130
> 
> And then each host would use /etc/hosts to resolve the 
> peer-cache-node.example.com name to it's neighbor's IP.? E.g.
> 
> node1:/etc/hosts
>  ?? ...
>  ?? 192.0.2.1??? node1.example.com
>  ?? 192.0.2.2??? node2.example.com peer-cache-node.example.com
>  ?? ...
> 
> node2:/etc/hosts
>  ?? ...
>  ?? 192.0.2.1??? node1.example.com peer-cache-node.example.com
>  ?? 192.0.2.2??? node2.example.com
>  ?? ...
> 
> I sort of suspect that the nodes already have a per-node /etc/hosts file.
> 
> This is untested and wild speculation on my part.? Can / will someone 
> with more experience comment on the viability of such "mailhost" or 
> "loghost" use?

This config does work.


Although, I personally would first look at the system being used to 
distribute the config files. All the ones I am aware of some sort of 
macro substitution in files as they are pushed out for exactly this purpose.


Alternatively the cache_peer config settings can be pushed as a separate 
file in /etc/squid/conf.d/cache_peer.conf and the main config file use 
'include' directive to load it.


Cheers
Amos


From squid3 at treenet.co.nz  Fri Sep 16 07:55:44 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 16 Sep 2022 19:55:44 +1200
Subject: [squid-users] [squid][v5.6] : problem with "slow" or "fast" acl
In-Reply-To: <134aba14e66bb9d58b5999d733a64627@interieur.gouv.fr>
References: <6315EC88.6050505@interieur.gouv.fr>
 <6315F1FD.5010501@interieur.gouv.fr>
 <33020e46-99dc-d860-324b-30da97991049@articatech.com>
 <000001d8c21b$ece0a340$c6a1e9c0$@gmail.com>
 <134aba14e66bb9d58b5999d733a64627@interieur.gouv.fr>
Message-ID: <6c0e0c15-1fd3-6993-c8d7-33ad2e3492b2@treenet.co.nz>

On 16/09/22 19:11, PERROT Eric DNUM SDCAST BST SSAIM wrote:
> Hello Elizer and David,
> 
> Sorry for the delay, I have been monopolized by another subject...
> 
> I am not sur to understand how note acl could help me.?If the idear of 
> "note acl" is similar to the one proposed by Amos (creating a group with 
> annotate acl).
> 

FWIW, the idea is the same. The "note" ACL is a fast-type ACL that 
checks annotations linked to the transaction happening. So it works on 
the fast-type checks you are trying to use.

Where all our advice has been different it is about how you set the 
annotation. There are many way to do that.


Amos


From squid3 at treenet.co.nz  Fri Sep 16 08:16:19 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 16 Sep 2022 20:16:19 +1200
Subject: [squid-users] Is there a way to ignore incoming
 If-Modified-Since request?
In-Reply-To: <YyG7YF9I7r9dlQMx@fnal.gov>
References: <YyG7YF9I7r9dlQMx@fnal.gov>
Message-ID: <80dcc9a0-f39e-b21a-fe9a-60150eefdb50@treenet.co.nz>


Sorry, No there is no option to ignore revalidations on incoming traffic.


Cheers
Amos


From squid3 at treenet.co.nz  Fri Sep 16 09:28:54 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 16 Sep 2022 21:28:54 +1200
Subject: [squid-users] squid-users Digest, Vol 97, Issue 20
In-Reply-To: <PH0PR14MB53092FB919E55E07EC1C9EE0B3449@PH0PR14MB5309.namprd14.prod.outlook.com>
References: <mailman.3.1662897601.3540902.squid-users@lists.squid-cache.org>
 <PH0PR14MB53092FB919E55E07EC1C9EE0B3449@PH0PR14MB5309.namprd14.prod.outlook.com>
Message-ID: <7c4a2e62-9b38-5c42-5ecd-dcc0a576adca@treenet.co.nz>

On 13/09/22 00:39, Adiseshu Channasamudhram wrote:
> Hello Amos
> 
> Thank you for looking in to this. Below is the configuration ...
> 


FYI, below is advice for Squid-4+, if you have an older version then 
please upgrade ASAP. Current stable Squid is v5.7.


> 
> ###########################
> logformat squid %tl %6tr %>a %<a %dt %<rd %Ss/%>Hs %<st %rm %ru %un 
> %Sh/%<A %mt %<tt %<pt %{Nuance-Session-ID}>h
> 

"squid" is the registered name for Squid native log format. Some Squid 
versions will silently use the built-in format instead of yours. Recent 
versions will complain about this.

Please use a custom name for custom formats:

   logformat nuance ...


> cache_access_log /var/log/squid/access.log ?squid

This directive is called "access_log". Remove the "cache_" part.

   access_Log daemon:/var/log/squid/access.log logformat=nuance


> pid_filename /var/run/squid.pid
> 

This should not need configuring in any modern Squid.


> visible_hostname nuance-ak-client-test2
> 

The above should be a FQDN resolvable in DNS. It will be used in URLs 
presented to clients in error pages etc.


> acl Safe_ports port 80
> acl Safe_ports port 443
> acl SSL_ports port 443
> acl SSL method CONNECT
> acl CONNECT method CONNECT
> 
> cache deny all

To fully disable caching you should also add:
   cache_mem 0 KB


> dns_v4_first on

> http_port 443 tcpkeepalive=60,30,3 ssl-bump 

This may be your problem.

  - Port 443 is for encrypted TLS traffic.
  - "http_port" requires plain-text HTTP traffic. Encrypted TLS arriving 
here directly will guaranteed result in your log "error:invalid-request" 
entries.

A working configuration for port 443 would be:

   https_port 443 \
     tls-cert=/etc/squid/squidCA.pem \
     cipher=HIGH:MEDIUM:!LOW:!RC4:!SEED:!IDEA:!3DES:!MD5:!EXP:!PSK:!DSS \
     options=NO_TLSv1,NO_SSLv3,NO_SSLv2,SINGLE_DH_USE,SINGLE_ECDH_USE \
     tls-dh=prime256v1:/etc/squid/bump_dhparam.pem \
     tcpkeepalive=60,30,3


FYI, NO_SSLv2 is no longer supported with latest Squid. All SSLv2 
related features are fully prohibited by default. Including these 
disable options.


> # Below, a.b.c.d is the backend IP
> cache_peer a.b.c.d parent 443 0 no-query proxy-only no-digest 
> originserver ssl sslcert=/etc/certs/abc.crt sslkey=/etc/certs/key.pem 
> sslcapath=/etc/certs/ sslflags=DONT_VERIFY_PEER name=dev


FYI: DONT_VERIFY_PEER disables the 2-way security on these backend 
connections.

Please *actually* setup 2-way TLS validation. Like so:

  * Check that /etc/certs/abc.crt contains the *Client Certificate* 
Squid is supposed to send in 2-way TLS to this backend.

  * Check that /etc/certs/key.pem is the private key matching the 
content of /etc/certs/abc.crt.

  * Add the sslcafile= option with the specific PEM file containing the 
root CA which signed the Server Certificate of a.b.c.d.

  * Remove both sslcapath= and sslflags=DONT_VERIFY_PEER


FWIW, you could merge /etc/certs/abc.crt and /etc/certs/key.pem into one 
PEM file and load it with "sslcert=/etc/certs/squid.pem". In modern 
Squid that file can also contain any necessary chained CA intermediary 
certificates.


> acl dev myport 443
> acl dev myport 80
> acl dev myport 3129
> 

Use "myportname" ACL type instead.

   acl dev myportname 443 80 3129


FWIW, you have not shown any port 80 or 3129 settings. Without 
http(s)_port lines using those as names the values are pointless in this 
ACL.


> http_access allow all
> 

Your network description specified there is a "frontend" receiving 
traffic before relaying it to Squid. You should configure these 
http_access to deny traffic arriving without going through those 
frontend(s). The default squid.conf defines an ACL called "localnet" for 
things like this.


> cache_peer_access dev allow dev
> #cache_peer_access dev deny all

There are no rules specifying what to do with traffic that does not go 
through the peer. That means Squid will currently try to go directly to 
the Internet for all that.

Your network topology description specified that there was a backend 
receiving all traffic. To enforce that you need the following rule:

   never_direct allow all


> #URL_REWRITE_PROGRAM /etc/squid/rewrite-http.pl
> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB
> sslcrtd_children 5
> ssl_bump server-first all

With the port 443 configuration fixed your Squid is no longer performing 
SSL-Bump. You can remove all these above settings.


> sslproxy_cert_error allow all
> sslproxy_flags DONT_VERIFY_PEER

These settings should never be configured like this. All it does is hide 
log entries informing you about security issues. The issues themselves 
still occur.

You should remove them and resolve any issues that are then visible.
FWIW, once never_direct is used and the cache_peer is fixed these should 
not be necessary configuring at all.


HTH
Amos


From eric.perrot at interieur.gouv.fr  Fri Sep 16 09:45:32 2022
From: eric.perrot at interieur.gouv.fr (PERROT Eric DNUM SDCAST BST SSAIM)
Date: Fri, 16 Sep 2022 11:45:32 +0200
Subject: [squid-users] [squid][v5.6] : problem with "slow" or "fast" acl
In-Reply-To: <25aa58ab-a20f-8b50-eb1a-12d1656b797f@treenet.co.nz>
References: <6315EC88.6050505@interieur.gouv.fr>
 <6315F1FD.5010501@interieur.gouv.fr>
 <25aa58ab-a20f-8b50-eb1a-12d1656b797f@treenet.co.nz>
Message-ID: <ceddcff4922c627df60784d7eafaf487@interieur.gouv.fr>

 

Hello Amos, 

This seems to be a solved issue. With your advices, I have manage to
limit all my user except those who had a login starting by cg_*. 

1 - annotation of the "cg_*" 's flow :
_# Comptes generiques_
acl userCgPrefix proxy_auth_regex ^cg_
acl markCgGroup annotate_transaction cgUsers=true 

_http_access allow userCgPrefix markCgGroup !all_
_http_access allow my_ldap_auth !emeraude_ 

 2 - fixed limits for all except "cg_*" users 

_acl cgen note cgUsers true_
acl userrgt src 10.0.0.0/8
reply_body_max_size 800 MB bureau !cgen userrgt
request_body_max_size 5 MB
delay_pools 1
delay_class 1 4
delay_access 1 allow bureau !cgen !emeraude
_delay_parameters 1 -1/-1 -1/-1 -1/-1 512000/512000_ 

I will make some other tests later on with the "usual way" you also
preconised :
"The usual way to do that is with the authentication systems "group"
functionality and a helper to fetch that." 

Thanks very much to you, David and Eliezer 
Regards, 

Eric Perrot 

Le 06/09/2022 20:46, Amos Jeffries a ?crit : 

> On 6/09/22 00:56, PERROT Eric DNUM SDCAST BST SSAIM wrote:
> 
>> Hello, We use directives "reply_body_max_size", "request_body_max_size" and "delay_access" to limit upload, download and passband in our infra.
> 
> All of which are "fast" type.
> 
>> This configuration existes since a while, but we have noticed that with squid v4.16, our delay pool didn't react as we wanted anymore.
> 
> FYI, use of "slow" type ACLs in "fast" type checks is subject to what Squid happens to have in its processing state information and available in caches from previous traffic.
> 
> Even if a config like this *appears* to work, it may not be actually working for all transactions. The delicate balance may change at any time.
> 
>> Can you tell me if what we want to do is still possible? Limiting upload/download/passband for all logged user except those starting by cg_*..?.
> 
> You need to:
> 
> 1) do authentication checks to http_access.
> 
> 2) make the cg_* accounts part of a "group".
> 
> The usual way to do that is with the authentication systems "group" functionality and a helper to fetch that.
> 
> However, in Squid-4+ you can also add a temporary "group" label as needed based on other ACL checks (eg the username regex matching) like so:
> 
> acl userCgPrefix proxy_auth_regex ^cg_
> acl markCgGroup annotate_transaction group=cgUsers
> http_access allow userCgPrefix markCgGroup !all
> 
> 3) check the 'group' annotation in fast type controls, not the username:
> 
> acl userrgt note group cgUsers
> 
> reply_body_max_size 800 MB userrgt
> deny_access 1 deny userrgt
> 
> FTR; the above should work on any Squid-4 or later. So you can revert to the v4 Squid install which was otherwise working for you.
> 
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users [1]
 

Links:
------
[1] http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220916/964db83d/attachment.htm>

From daku8938 at gmx.de  Fri Sep 16 10:30:33 2022
From: daku8938 at gmx.de (Hildegard Meier)
Date: Fri, 16 Sep 2022 12:30:33 +0200
Subject: [squid-users] Howto make Squid config dependent on hostname?
In-Reply-To: <7eac75df-a0e6-3195-850f-715da132f3fb@measurement-factory.com>
References: <trinity-a2935dc4-afa5-44ae-95e9-02f034d48a30-1663252171595@3c-app-gmx-bs05>
 <7eac75df-a0e6-3195-850f-715da132f3fb@measurement-factory.com>
Message-ID: <trinity-de55c871-dc3d-4667-9f85-85eff3fb5170-1663324233075@3c-app-gmx-bs10>

> Squid currently only supports three kinds of conditions: true,
> false, and integer equality comparison (as documented).

I think it would be very good to give some concrete examples of how one can use the if-condition. The current abstract and vague "documentation" is totally unclear to me.

> For now, your best option is probably to post-process the versioned
> configuration to substitute your own custom macro(s). For example, your
> Squid startup (or deployment) stript can substitute a
> ${mynamespace:PeerName} macro in squid.conf.template with either true or
> false, depending on the node, producing squid.conf that Squid can use:
>
> cache_peer ${mynamespace:PeerName} sibling 3128 3130
>
>
> If you need to hard-code peer names or substantially different
> configurations for individual cache peers, then you can do something
> like this in the template configuration file:
>
> if ${mynamespace:AtNode1()}
>      cache_peer node2.example.com sibling 3128 3130
> endif
>
> if ${mynamespace:AtNode2()}
>      cache_peer node1.example.com sibling 3128 3130
> endif
>

Sorry, I do not understand what you write.


From daku8938 at gmx.de  Fri Sep 16 10:32:55 2022
From: daku8938 at gmx.de (Hildegard Meier)
Date: Fri, 16 Sep 2022 12:32:55 +0200
Subject: [squid-users] Howto make Squid config dependent on hostname?
In-Reply-To: <e4e937ac-222d-f5a0-f292-4e1fc0aa6f03@spamtrap.tnetconsulting.net>
References: <trinity-a2935dc4-afa5-44ae-95e9-02f034d48a30-1663252171595@3c-app-gmx-bs05>
 <e4e937ac-222d-f5a0-f292-4e1fc0aa6f03@spamtrap.tnetconsulting.net>
Message-ID: <trinity-ad4228d8-8923-492c-84b8-d46f72a626d9-1663324375417@3c-app-gmx-bs10>

>
> node1:/etc/hosts
>     ...
>     192.0.2.1	node1.example.com
>     192.0.2.2	node2.example.com peer-cache-node.example.com
>     ...
>
> node2:/etc/hosts
>     ...
>     192.0.2.1	node1.example.com peer-cache-node.example.com
>     192.0.2.2	node2.example.com
>     ...

Thanks, but having individual /etc/hosts file is not feasable as we deploy all files centrally (with rsync) and do not touch files on the hosts themself.


From rousskov at measurement-factory.com  Fri Sep 16 12:31:55 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 16 Sep 2022 08:31:55 -0400
Subject: [squid-users] Howto make Squid config dependent on hostname?
In-Reply-To: <trinity-de55c871-dc3d-4667-9f85-85eff3fb5170-1663324233075@3c-app-gmx-bs10>
References: <trinity-a2935dc4-afa5-44ae-95e9-02f034d48a30-1663252171595@3c-app-gmx-bs05>
 <7eac75df-a0e6-3195-850f-715da132f3fb@measurement-factory.com>
 <trinity-de55c871-dc3d-4667-9f85-85eff3fb5170-1663324233075@3c-app-gmx-bs10>
Message-ID: <9a673df5-c914-9066-b595-ec8f97ba9cb8@measurement-factory.com>

On 9/16/22 06:30, Hildegard Meier wrote:
>> Squid currently only supports three kinds of conditions: true,
>> false, and integer equality comparison (as documented).


> I think it would be very good to give some concrete examples of how
> one can use the if-condition.

I agree.


>> For now, your best option is probably to post-process the versioned
>> configuration to substitute your own custom macro(s). For example, your
>> Squid startup (or deployment) stript can substitute a
>> ${mynamespace:PeerName} macro in squid.conf.template with either true or
>> false, depending on the node, producing squid.conf that Squid can use:
>>
>> cache_peer ${mynamespace:PeerName} sibling 3128 3130
>>
>>
>> If you need to hard-code peer names or substantially different
>> configurations for individual cache peers, then you can do something
>> like this in the template configuration file:
>>
>> if ${mynamespace:AtNode1()}
>>       cache_peer node2.example.com sibling 3128 3130
>> endif
>>
>> if ${mynamespace:AtNode2()}
>>       cache_peer node1.example.com sibling 3128 3130
>> endif

> Sorry, I do not understand what you write.

It is difficult for me to improve the above without knowing which parts 
are unclear to you, but I will try: The above snippets are concrete 
examples of how one can use conditional statements (with custom macros) 
in a squid.conf template. Your custom program will take a 
squid.conf.template containing one of the above snippet and substitute 
the above ${...} custom macros with appropriate values.

On node1, the first template snippet will be replaced with

   cache_peer node2.example.com sibling 3128 3130

On node2, the first template snippet will be replaced with

   cache_peer node1.example.com sibling 3128 3130


On node1, the second template snippet will be replaced with

   if true
        cache_peer node2.example.com sibling 3128 3130
   endif

   if false
        cache_peer node1.example.com sibling 3128 3130
   endif


HTH,

Alex.


From daku8938 at gmx.de  Fri Sep 16 14:22:40 2022
From: daku8938 at gmx.de (Hildegard Meier)
Date: Fri, 16 Sep 2022 16:22:40 +0200
Subject: [squid-users] Howto make Squid config dependent on hostname?
In-Reply-To: <trinity-a2935dc4-afa5-44ae-95e9-02f034d48a30-1663252171595@3c-app-gmx-bs05>
References: <trinity-a2935dc4-afa5-44ae-95e9-02f034d48a30-1663252171595@3c-app-gmx-bs05>
Message-ID: <trinity-9a073eae-d1de-47e0-8d9a-1af4ec01f3b3-1663338160778@3c-app-gmx-bs10>

I found about

man squid

-f file     Use the given config-file instead of /etc/squid/squid.conf .  If the file name starts with a !  or | then it is assumed  to  be
                   an  external  command  or  command  line.   Can for example be used to pre-process the configuration before it is being read by
                   Squid.  To facilitate this Squid also understands the common #line notion to indicate the real source file.

While I dnot know what "common #line notion" should be (searching on internet matches only the squid man page),

I found the following solution for Ubuntu 18.04 server (Squid 3.5.27):

Create a script
--------------------
/usr/local/script/squid/pre_process_squid_config_file.sh

#!/bin/bash

readonly SQUID_CONFIG_TEMPLATE_FILE='/etc/squid/squid.conf.TEMPLATE'

case "${HOSTNAME}" in
    'node1')  readonly HOSTNAME_PEER='node2' ;;
    'node2')  readonly HOSTNAME_PEER='node1' ;;
    *)
        echo "invalid hostname in script ${0}. Exit"
        exit 1
        ;;
esac

sed \
-e "s@{HOSTNAME}@${HOSTNAME}@g" \
-e "s@{HOSTNAME_PEER}@${HOSTNAME_PEER}@g" \
"${SQUID_CONFIG_TEMPLATE_FILE}"
--------------------

Create file /etc/default/squid with content
CONFIG='|/usr/local/script/squid/pre_process_squid_config_file.sh'
SQUID_ARGS="-YC -f $CONFIG"

Now you can use the Macros {HOSTNAME} (which will give the actual hosts name) and {HOSTNAME_PEER} (name of the other host)

I have only one problem with it, is that a bug?

/usr/sbin/squid -k parse -f '|/usr/local/script/squid/pre_process_squid_config_file.sh'

works, but

/usr/sbin/squid -k reconfigure -f '|/usr/local/script/squid/pre_process_squid_config_file.sh'

gives the following line in /var/log/squid/cache.log

2022/09/16 16:20:55 kid1| storeDirWriteCleanLogs: Starting...
2022/09/16 16:20:55 kid1|   Finished.  Wrote 0 entries.
2022/09/16 16:20:55 kid1|   Took 0.00 seconds (  0.00 entries/sec).
FATAL: parseConfigFile: '|/usr/local/script/squid/pre_process_squid_config_file.sh' failed with exit code -1

Squid Cache (Version 3.5.27): Terminated abnormally.
CPU Usage: 1.267 seconds = 0.760 user + 0.507 sys
Maximum Resident Size: 107296 KB
Page faults with physical i/o: 7
2022/09/16 16:20:58 kid1| Current Directory is /



From rousskov at measurement-factory.com  Fri Sep 16 18:03:19 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 16 Sep 2022 14:03:19 -0400
Subject: [squid-users] Howto make Squid config dependent on hostname?
In-Reply-To: <trinity-9a073eae-d1de-47e0-8d9a-1af4ec01f3b3-1663338160778@3c-app-gmx-bs10>
References: <trinity-a2935dc4-afa5-44ae-95e9-02f034d48a30-1663252171595@3c-app-gmx-bs05>
 <trinity-9a073eae-d1de-47e0-8d9a-1af4ec01f3b3-1663338160778@3c-app-gmx-bs10>
Message-ID: <4162e00d-90a4-bd94-c2eb-6fe4bf78d01b@measurement-factory.com>

On 9/16/22 10:22, Hildegard Meier wrote:

> I dnot know what "common #line notion" should be (searching on internet matches only the squid man page)

It is a poorly worded reference to "#line" directives used by some 
programming languages for documenting the original location of lines in 
preprocessed files. Here are the corresponding C++ preprocessor docs, 
for example: https://en.cppreference.com/w/cpp/preprocessor/line

Your template preprocessing script may (but does not have to) insert 
#line directives so that Squid can attribute configuration lines to the 
original configuration template rather than its processed result.


> /usr/sbin/squid -k parse -f '|/usr/local/script/squid/pre_process_squid_config_file.sh'
> 
> works, but
> 
> /usr/sbin/squid -k reconfigure -f '|/usr/local/script/squid/pre_process_squid_config_file.sh'
> 
> gives the following line in /var/log/squid/cache.log

> 2022/09/16 16:20:55 kid1| storeDirWriteCleanLogs: Starting...
> 2022/09/16 16:20:55 kid1|   Finished.  Wrote 0 entries.
> 2022/09/16 16:20:55 kid1|   Took 0.00 seconds (  0.00 entries/sec).
> FATAL: parseConfigFile: '|/usr/local/script/squid/pre_process_squid_config_file.sh' failed with exit code -1

 > is that a bug?

I am not sure. I cannot reproduce this problem with a modern/supported 
Squid version, but my test environment may be too different from yours. 
If you are willing to try this with Squid v5, I can help with triaging 
this further, but it may take a few iterations to get to the bottom of 
this (e.g., using "bash -x" and adding some no-output command at the 
very end of the script might provide more clues). Others on this mailing 
list may have better ideas/suspects.


> /usr/local/script/squid/pre_process_squid_config_file.sh
> 
> #!/bin/bash
> 
> readonly SQUID_CONFIG_TEMPLATE_FILE='/etc/squid/squid.conf.TEMPLATE'
> 
> case "${HOSTNAME}" in
>     'node1')  readonly HOSTNAME_PEER='node2' ;;
>     'node2')  readonly HOSTNAME_PEER='node1' ;;
>     *)
>         echo "invalid hostname in script ${0}. Exit"
>         exit 1
>         ;;
> esac
> 
> sed \
> -e "s@{HOSTNAME}@${HOSTNAME}@g" \
> -e "s@{HOSTNAME_PEER}@${HOSTNAME_PEER}@g" \
> "${SQUID_CONFIG_TEMPLATE_FILE}"
> --------------------


FWIW, the "invalid hostname" error should be reported to stderr rather 
than stdout. Otherwise, the error text will be interpreted as Squid 
configuration file contents, producing a somewhat confusing output:

> 2022/09/16 13:49:27| Processing Configuration File: |/tmp/t.sh (depth 0)

> 2022/09/16 13:49:27| /tmp/t.sh(1): unrecognized: 'invalid'



HTH,

Alex.


From daku8938 at gmx.de  Sat Sep 17 09:37:13 2022
From: daku8938 at gmx.de (Hildegard Meier)
Date: Sat, 17 Sep 2022 11:37:13 +0200
Subject: [squid-users] Howto make Squid config dependent on hostname?
In-Reply-To: <4162e00d-90a4-bd94-c2eb-6fe4bf78d01b@measurement-factory.com>
References: <trinity-a2935dc4-afa5-44ae-95e9-02f034d48a30-1663252171595@3c-app-gmx-bs05>
 <trinity-9a073eae-d1de-47e0-8d9a-1af4ec01f3b3-1663338160778@3c-app-gmx-bs10>
 <4162e00d-90a4-bd94-c2eb-6fe4bf78d01b@measurement-factory.com>
Message-ID: <trinity-c5a46f14-a444-484a-8d94-b0678956b88d-1663407433463@3c-app-gmx-bs62>

> It is a poorly worded reference to "#line" directives used by some
> programming languages for documenting the original location of lines in
> preprocessed files. Here are the corresponding C++ preprocessor docs,
> for example: https://en.cppreference.com/w/cpp/preprocessor/line

I guess it would be helpful to add this explanation to the doc.

> > /usr/sbin/squid -k reconfigure -f '|/usr/local/script/squid/pre_process_squid_config_file.sh'
> >
> > gives the following line in /var/log/squid/cache.log
> > FATAL: parseConfigFile: '|/usr/local/script/squid/pre_process_squid_config_file.sh' failed with exit code -1
> > Squid Cache (Version 3.5.27): Terminated abnormally.
>
>  > is that a bug?

I found out that has nothing to do with the -f "|pre_processing_script.sh" syntax, it happens with the standard -f "/etc/squid/squid.conf" syntax the same.

We have IPv6 disabled on the host and Squid says "ERROR: Failed to create helper child read FD: UDP[::1]", so that let me to suspicion the "Terminated abnormally" could be an IPv6 issue.

Solution was to set http_port to the specific IPv4 host addresses.

Now, Squid still says "ERROR: Failed to create helper child read FD: UDP[::1]",
but squid -k reconfigure does work now without the above "parseConfigFile failed with exit code -1" and "Terminated abnormally" message.

(I understand that IPv6 should be availabe on node ("IPv6 Support Required for All IP-Capable Nodes" https://www.rfc-editor.org/rfc/rfc6540), but we have still disabled it on Ubuntu 18, maybe we will not disable it it anymore as of Ubuntu 22)

Regarding the initial question of how to use Macros, I made it now simpler.

We use now /etc/squid/squid.conf.TEMPLATE as config template file, having custom (non-squid, self defined) Macros available.
After the template file has been deployed with rsync to a host, a Bash script is executed locally on the host that replaces (with sed) the Macros with the values (e.g. Hostname, Peer hostname etc.)
and writes the result to /etc/squid/squid.conf
With that, there is no need to use the -f '|pre_processing_script.sh' tweak. That's simpler and more standard, no need for custom /etc/default/squid anymore.

With that we can now deploy host-specific "unique_hostname", "cache_peer" etc. using uniform files on all hosts.

So issue should be solved now.

Thanks and best regards.



From rousskov at measurement-factory.com  Sat Sep 17 16:05:33 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 17 Sep 2022 12:05:33 -0400
Subject: [squid-users] Howto make Squid config dependent on hostname?
In-Reply-To: <trinity-c5a46f14-a444-484a-8d94-b0678956b88d-1663407433463@3c-app-gmx-bs62>
References: <trinity-a2935dc4-afa5-44ae-95e9-02f034d48a30-1663252171595@3c-app-gmx-bs05>
 <trinity-9a073eae-d1de-47e0-8d9a-1af4ec01f3b3-1663338160778@3c-app-gmx-bs10>
 <4162e00d-90a4-bd94-c2eb-6fe4bf78d01b@measurement-factory.com>
 <trinity-c5a46f14-a444-484a-8d94-b0678956b88d-1663407433463@3c-app-gmx-bs62>
Message-ID: <e76d61e7-6a9a-23c1-e28e-cc10aacea7f5@measurement-factory.com>

On 9/17/22 05:37, Hildegard Meier wrote:
>> It is a poorly worded reference to "#line" directives used by some
>> programming languages for documenting the original location of lines in
>> preprocessed files. Here are the corresponding C++ preprocessor docs,
>> for example: https://en.cppreference.com/w/cpp/preprocessor/line
> 
> I guess it would be helpful to add this explanation to the doc.

Agreed.


>>> /usr/sbin/squid -k reconfigure -f '|/usr/local/script/squid/pre_process_squid_config_file.sh'
>>>
>>> gives the following line in /var/log/squid/cache.log
>>> FATAL: parseConfigFile: '|/usr/local/script/squid/pre_process_squid_config_file.sh' failed with exit code -1
>>> Squid Cache (Version 3.5.27): Terminated abnormally.
>>
>>  > is that a bug?

> I found out that has nothing to do with the -f
> "|pre_processing_script.sh" syntax, it happens with the standard -f
> "/etc/squid/squid.conf" syntax the same.

The "terminated abnormally" message is a generic message common to many 
fatal problems. However, the "FATAL: parseConfigFile: ... failed with 
exit code..." error is specific to the pipeline configuration syntax. I 
realize that you do not care about the latter anymore, but wanted to add 
this clarification in case somebody else does.

Glad you found a solution that works well for you.

Alex.


From rousskov at measurement-factory.com  Sat Sep 17 16:25:45 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 17 Sep 2022 12:25:45 -0400
Subject: [squid-users] Is there a way to ignore incoming
 If-Modified-Since request?
In-Reply-To: <YyG7YF9I7r9dlQMx@fnal.gov>
References: <YyG7YF9I7r9dlQMx@fnal.gov>
Message-ID: <1bfd5df6-bf3d-2a61-b8d9-b9dcd50069cf@measurement-factory.com>

On 9/14/22 07:30, Dave Dykstra wrote:
> I have tried playing around with reply_header_access and
> request_header_access, and looking for other options having to do
> with "ims" or "revalid" but have not had any luck finding an option
> to ignore If-Modified-Since headers in requests from clients.  Is
> there a way to do it?

Today, an ICAP/eCAP REQMOD service can edit or remove an incoming 
request header field. However, if you just want to ignore 
If-Modified-Since headers in all client requests, I would probably 
modify Squid sources instead of building a whole adaptation service for 
that task. See the attached untested unofficial unsupported patch.

We are also working on a built-in feature that can be (ab)used for your 
use case, but it is not ready for production use or the official review 
yet. I am only mentioning it here to say that the source code 
modifications suggested above may not be permanent/long-term...


HTH,

Alex.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ignore-all-ims-fields-in-received-requests.patch
Type: text/x-patch
Size: 531 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220917/65d6755e/attachment.bin>

From roeeklinger60 at gmail.com  Sun Sep 18 16:51:40 2022
From: roeeklinger60 at gmail.com (roee klinger)
Date: Sun, 18 Sep 2022 19:51:40 +0300
Subject: [squid-users] Do squid logs performence affect general request
 performece?
In-Reply-To: <b7f407f8-5902-75f5-532c-8afa5401e7be@measurement-factory.com>
References: <190bd8ec-0724-44dd-96b2-3f9e6505d92e@Spark>
 <5ac180f3-41c7-463b-8266-4fef7ee0fee4@Spark>
 <9e76568b-a203-fe03-3025-8ff0a47fc2c5@measurement-factory.com>
 <9b254c79-ed34-4464-a767-a9863e4e2ab4@Spark>
 <b7f407f8-5902-75f5-532c-8afa5401e7be@measurement-factory.com>
Message-ID: <b9487dcc-1874-42b6-9830-be9290cbf7e0@Spark>

Thank you for the advice, Alex.

I just wanted to update anyone following or who might follow that the problem ended up being in
my Logstash server, not in Squid, it performed too slow due to a miss configuration, so Squid kept
sending logs but the slow server got over flooded.

After fixing the server I simply set these configuration normally:
access_log tcp://server:port logformat=logs

and everything seems to be working fine by default.

I did however notice that UDP does aggregate logs before sending them, and TCP does not,
even when set explicitly.

If anybody runs into this issue in the future it might be worth to follow Alex advice on how to get
this to work.

Thanks,
Roee


On 13 Sep 2022, 6:30 +0300, Alex Rousskov <rousskov at measurement-factory.com>, wrote:
> On 9/12/22 18:20, roee klinger wrote:
>
> > Thank you for your advice, as suggested I tested a both TCP and UDP, and
> > found TCP to be so slow
> > that is it practically unusable, UDP however works fine, but has the
> > normal disadvantages of UDP.
>
> Glad that test yielded useful results in your environment!
>
>
> > It seems that TCP sends each message by itself, and UDP sends them in
> > bulk (10-20 at a time),
> > which seems to be a big part of the performance difference, in fact TCP
> > is so slow that it causes Squid to crash after a while.
> >
> > After carefully reading the logs, I tried to get TCP to send in bulk as
> > well by configuring:
> >
> > logformat logstash %ts.%03tu %6tr %>a %<la %>lp %Ss/%03>Hs %<st %rm
> > %ru %[un %Sh/%<a %mt %{Client-Tags}>h
> > access_log tcp://127.0.0.1:5400 logformat=logstash buffer-size=64KB
> > buffered_logs on
> >
> > But it seems to still be sending the logs line by line, am I missing
> > something?
>
>
> I have not tested this, but if my interpretation of the underlying code
> is correct, then the TCP logging module code does not flush the buffer
> when it accumulates (close to) buffer-size bytes. Instead, the module
> starts writing its buffer after accumulating more than 16KB (2*MAX_URL).
> How long are your typical access.log records?
>
> Each write(2) call of a buffering TCP logging module during normal Squid
> operation should be 16KB, regardless of the buffer-size setting.
>
> FWIW, the official access_log buffer-size documentation hints at
> module-specific flushing algorithms. I cannot describe the exact
> algorithm used by the TCP logging module in a few words, but it is not
> as simple as "accumulate buffer-size bytes and then write the
> accumulated bytes".
>
>
> HTH,
>
> Alex.
>
>
> > On 9 Sep 2022, 19:57 +0300, Alex Rousskov wrote:
> > > On 9/9/22 08:49, roee klinger wrote:
> > > > Hello,
> > > >
> > > > I have just recently started exploring ingesting logs from Squid via
> > > > Logstash (TCP log ingestion)
> > > >
> > > > I now have to make the decision of how to deploy Logstash, it seems to
> > > > me that I have two options:
> > > >
> > > > 1. Deploy a Logstash instance for every region where I have a Squid
> > > > instance running, resulting in the lowest latency possible between
> > > > Squid and Logstash.
> > > > 2. Deploy a central Logstash instance for all Squid instance worldwide,
> > > > which is the cheapest and easiest option, but will have high latency
> > > > for some of the Squid instance which are located far away
> > > > geographically from the Logstash instance.
> > > >
> > > > I already know that if the log server crashes in Squid, then Squid will
> > > > crash with a fatal error,
> > >
> > > FYI: Logging error handling is configurable via "access_log on-error".
> > >
> > >
> > > > so Squid takes logging very seriously, so my
> > > > question is: does TCP logging performance in Squid effect the total
> > > > request performance, or are they independent from each other?
> > >
> > > TCP logger uses asynchronous non-blocking I/O. Individual HTTP
> > > transactions do not wait for individual log records to be sent. Needless
> > > to say, logging does consume resources and, hence, may affect overall
> > > HTTP transaction performance. And if the log record recipient is too
> > > slow, then Squid will die and/or log records will be dropped.
> > >
> > >
> > > > What would be you recommendations, if request performance is crucial
> > > > (and log performance is not)?
> > >
> > > I would not be surprised if you would not be able to measure meaningful
> > > performance difference among these modules. From general performance
> > > point of view, and module-specific bugs and limitations notwithstanding,
> > > I would expect "daemon" and "udp" modules to have smaller performance
> > > overhead/cost for Squid workers than the "tcp" module because I expect
> > > that TCP has to "do more" than stdout I/O and UDP. However, I would not
> > > base this decision on such high-level speculations and test various
> > > options instead.
> > >
> > >
> > > HTH,
> > >
> > > Alex.
> > > _______________________________________________
> > > squid-users mailing list
> > > squid-users at lists.squid-cache.org
> > > http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220918/ca9a3fc9/attachment.htm>

From uhlar at fantomas.sk  Mon Sep 19 16:06:22 2022
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 19 Sep 2022 18:06:22 +0200
Subject: [squid-users] bandwidth statistics
Message-ID: <YyiTfuu10KD5vTNo@fantomas.sk>

Hi guys,

I am searching for tool that could produce detailed statistics of bandwidth 
usage globally or for particular domains, e.g.  microsoft.com and webex.com 
within day.

I have some experience with calamaris and lightsquid, neither of those does 
that.

I've looked at tools at:
http://www.squid-cache.org/Misc/log-analysis.html
but neither seems to support what I want.

I'm thinking about making statistics for each second within a day
(lukily there's only 86400 seconds in day)

- each log provides start, duration and bytes transferred
- while not 100% accurate, it could at least give hint which sites take how 
   much of bandwidth at which time.

does anyone know a hint which tool could do that, or perhaps which tools 
could produce similat output?

I'm quite familiar with perl

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Emacs is a complicated operating system without good text editor.


From jose.rodriguez at cenpalab.cu  Mon Sep 19 16:43:03 2022
From: jose.rodriguez at cenpalab.cu (jose.rodriguez at cenpalab.cu)
Date: Mon, 19 Sep 2022 12:43:03 -0400
Subject: [squid-users] bandwidth statistics
In-Reply-To: <YyiTfuu10KD5vTNo@fantomas.sk>
References: <YyiTfuu10KD5vTNo@fantomas.sk>
Message-ID: <51bf62e1bc3d408aff3bb7455a7bf9e6@cenpalab.cu>

On 2022-09-19 12:06, Matus UHLAR - fantomas wrote:
> Hi guys,
> 
> I am searching for tool that could produce detailed statistics of
> bandwidth usage globally or for particular domains, e.g.
> microsoft.com and webex.com within day.
> 
> I have some experience with calamaris and lightsquid, neither of those
> does that.
> 

Have a look at squidanalyzer:

https://squidanalyzer.darold.net/

Regards,
Joe1962



From zebu14 at free.fr  Mon Sep 19 16:46:21 2022
From: zebu14 at free.fr (Xavier Lecluse)
Date: Mon, 19 Sep 2022 18:46:21 +0200 (CEST)
Subject: [squid-users] bandwidth statistics
In-Reply-To: <YyiTfuu10KD5vTNo@fantomas.sk>
Message-ID: <740908755.1593385122.1663605981139.JavaMail.root@zimbra17-e3.priv.proxad.net>

Hello,

You may use Cacti for example if you need to monitor your bandwith globally.
I found that sqstat or SquidView may help you on this task.

If you want to monitor for specific targets, then maybe an ELK stack with metricbeat on your server will do the job for sure, but it could be overkill.

My two cents
Xavier

----- Mail original -----
De: "Matus UHLAR - fantomas" <uhlar at fantomas.sk>
?: squid-users at lists.squid-cache.org
Envoy?: Lundi 19 Septembre 2022 18:06:22
Objet: [squid-users] bandwidth statistics

Hi guys,

I am searching for tool that could produce detailed statistics of bandwidth 
usage globally or for particular domains, e.g.  microsoft.com and webex.com 
within day.

I have some experience with calamaris and lightsquid, neither of those does 
that.

I've looked at tools at:
http://www.squid-cache.org/Misc/log-analysis.html
but neither seems to support what I want.

I'm thinking about making statistics for each second within a day
(lukily there's only 86400 seconds in day)

- each log provides start, duration and bytes transferred
- while not 100% accurate, it could at least give hint which sites take how 
   much of bandwidth at which time.

does anyone know a hint which tool could do that, or perhaps which tools 
could produce similat output?

I'm quite familiar with perl

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Emacs is a complicated operating system without good text editor.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From uhlar at fantomas.sk  Mon Sep 19 17:22:21 2022
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 19 Sep 2022 19:22:21 +0200
Subject: [squid-users] bandwidth statistics
In-Reply-To: <740908755.1593385122.1663605981139.JavaMail.root@zimbra17-e3.priv.proxad.net>
References: <YyiTfuu10KD5vTNo@fantomas.sk>
 <740908755.1593385122.1663605981139.JavaMail.root@zimbra17-e3.priv.proxad.net>
Message-ID: <YyilTaDrwcq2MakA@fantomas.sk>

On 19.09.22 18:46, Xavier Lecluse wrote:
>You may use Cacti for example if you need to monitor your bandwith globally.

I do already, however this is only for global traffic.


>I found that sqstat or SquidView may help you on this task.
>
>If you want to monitor for specific targets, then maybe an ELK stack with metricbeat on your server will do the job for sure, but it could be overkill.
>
>My two cents
>Xavier
>
>----- Mail original -----
>De: "Matus UHLAR - fantomas" <uhlar at fantomas.sk>
>?: squid-users at lists.squid-cache.org
>Envoy?: Lundi 19 Septembre 2022 18:06:22
>Objet: [squid-users] bandwidth statistics
>
>Hi guys,
>
>I am searching for tool that could produce detailed statistics of bandwidth
>usage globally or for particular domains, e.g.  microsoft.com and webex.com
>within day.
>
>I have some experience with calamaris and lightsquid, neither of those does
>that.
>
>I've looked at tools at:
>http://www.squid-cache.org/Misc/log-analysis.html
>but neither seems to support what I want.
>
>I'm thinking about making statistics for each second within a day
>(lukily there's only 86400 seconds in day)
>
>- each log provides start, duration and bytes transferred
>- while not 100% accurate, it could at least give hint which sites take how
>   much of bandwidth at which time.
>
>does anyone know a hint which tool could do that, or perhaps which tools
>could produce similat output?
>
>I'm quite familiar with perl

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Boost your system's speed by 500% - DEL C:\WINDOWS\*.*


From bruno.larini at riosoft.com.br  Mon Sep 19 17:56:24 2022
From: bruno.larini at riosoft.com.br (Bruno de Paula Larini)
Date: Mon, 19 Sep 2022 14:56:24 -0300
Subject: [squid-users] bandwidth statistics
In-Reply-To: <YyiTfuu10KD5vTNo@fantomas.sk>
References: <YyiTfuu10KD5vTNo@fantomas.sk>
Message-ID: <3b1d2b4d-9851-65d6-4d6c-c93149d8524c@riosoft.com.br>

Spam detection software, running on the system "master.squid-cache.org",
has identified this incoming email as possible spam.  The original
message has been attached to this so you can view it or label
similar future email.  If you have any questions, see
the administrator of that system for details.

Content preview:  Em 19/09/2022 13:06, Matus UHLAR - fantomas escreveu: > >
  I'm thinking about making statistics for each second within a day > (lukily
   there's only 86400 seconds in day) Some time ago I was looking for [...] 

Content analysis details:   (5.6 points, 5.0 required)

 pts rule name              description
---- ---------------------- --------------------------------------------------
 3.6 RCVD_IN_PBL            RBL: Received via a relay in Spamhaus PBL
                            [171.171.0.181 listed in zen.spamhaus.org]
 1.0 SPF_SOFTFAIL           SPF: sender does not match SPF record (softfail)
 0.0 HTML_MESSAGE           BODY: HTML included in message
-0.1 DKIM_VALID_AU          Message has a valid DKIM or DK signature from
                            author's domain
-0.1 DKIM_VALID             Message has at least one valid DKIM or DK signature
 0.1 DKIM_SIGNED            Message has a DKIM or DK signature, not necessarily
                            valid
-0.1 DKIM_VALID_EF          Message has a valid DKIM or DK signature from
                            envelope-from domain
-0.0 T_SCC_BODY_TEXT_LINE   No description available.
 0.0 UNPARSEABLE_RELAY      Informational: message has unparseable relay
                            lines
 1.3 RDNS_NONE              Delivered to internal network by a host with no rDNS
-0.0 NICE_REPLY_A           Looks like a legit reply (A)
 0.0 NO_FM_NAME_IP_HOSTN    No From name + hostname using IP address

The original message was not completely plain text, and may be unsafe to
open with some email clients; in particular, it may contain a virus,
or confirm that your address can receive spam.  If you wish to view
it, it may be safer to save it to a file and open it with an editor.

-------------- next part --------------
An embedded message was scrubbed...
From: Bruno de Paula Larini <bruno.larini at riosoft.com.br>
Subject: Re: [squid-users] bandwidth statistics
Date: Mon, 19 Sep 2022 14:56:24 -0300
Size: 4155
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220919/d654b4c4/attachment.eml>

From mark.schenk at vayapay.com  Tue Sep 20 04:53:25 2022
From: mark.schenk at vayapay.com (Mark Schenk)
Date: Tue, 20 Sep 2022 06:53:25 +0200
Subject: [squid-users] Squid proxy as outgoing gateway
Message-ID: <CALWMwDxhH4m4e9+zqCPwUuAT=C1e=pNrA6NL=VgHQBDJ4-wufw@mail.gmail.com>

Hi squid community,

We have a use case in which we need to do mutual TLS with an upstream
server. Our internal services are using their own certificates, and we
would like to use the SQUID proxy as a kind of gateway to which we send
requests for the upstream server. The squid proxy will verify the incoming
certificate and if correct, replace it by a certificate that is appropriate
for the upstream server. I'm wondering whether this is possible with squid.
I have been looking into ssl-bump of squid but couldn't get it working.

Has anybody any experience with mutual authentication and squid ?


Cheers,

Mark
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220920/88c21bf5/attachment.htm>

From ngtech1ltd at gmail.com  Tue Sep 20 11:12:20 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Tue, 20 Sep 2022 14:12:20 +0300
Subject: [squid-users] Squid alpine latest(5.5) container
Message-ID: <000a01d8cce1$db58d6d0$920a8470$@gmail.com>

Since I have tried to find a decent and tiny squid container and yet to find one I took the time to push one int docker hub.
At:
https://hub.docker.com/r/hack2003/squid-alpine
 
I will push later on an RPM based squid container, which will be an overkill for many but will not be based on ulibc 
which is an embedded lib c library.
 
Eliezer
 
----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email:  <mailto:ngtech1ltd at gmail.com> ngtech1ltd at gmail.com
Web:  <https://ngtech.co.il/> https://ngtech.co.il/
My-Tube:  <https://tube.ngtech.co.il/> https://tube.ngtech.co.il/
 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220920/883c505e/attachment.htm>

From rousskov at measurement-factory.com  Tue Sep 20 14:11:43 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 20 Sep 2022 10:11:43 -0400
Subject: [squid-users] Squid proxy as outgoing gateway
In-Reply-To: <CALWMwDxhH4m4e9+zqCPwUuAT=C1e=pNrA6NL=VgHQBDJ4-wufw@mail.gmail.com>
References: <CALWMwDxhH4m4e9+zqCPwUuAT=C1e=pNrA6NL=VgHQBDJ4-wufw@mail.gmail.com>
Message-ID: <a1b0d56d-ae51-9a37-8f4b-6da57282b48c@measurement-factory.com>

On 9/20/22 00:53, Mark Schenk wrote:

> We have a use case in which we need to do mutual TLS with an upstream 
> server. Our internal services are using their own certificates, and we 
> would like to use the SQUID proxy as a kind of gateway to which we send 
> requests for the upstream server. The squid proxy will verify the 
> incoming certificate and if correct, replace it by a certificate that is 
> appropriate for the upstream server. I'm wondering whether this is 
> possible with squid. I have been looking into ssl-bump of squid but 
> couldn't get it working.

I see nothing in your description that would require SslBump. You seem 
to be describing a reverse proxy for an HTTPS service with 
certificate-based authentication. The certificates you are talking about 
sound like client certificates. Squid supports those.


> Has anybody any experience with mutual authentication and squid ?

I would start with a basic https_port and TLS cache_peer combo:

   # Squid pretends to be an HTTPS service listening on port 443
   # and requiring client certificates
   https_port 443 accel cert=... tls-cafile=... ...

   # Squid forwards (all? some?) requests to the real HTTPS service
   # that requires client certificates
   cache_peer ... parent 443 0 no-query originserver tls sslcert=... ...
   hierarchical_direct off
   never_direct allow ...


HTH,

Alex.


From spinter at npsh.hu  Tue Sep 20 19:52:28 2022
From: spinter at npsh.hu (=?UTF-8?Q?Pint=c3=a9r_Szabolcs?=)
Date: Tue, 20 Sep 2022 21:52:28 +0200
Subject: [squid-users] Squid performance recommendation
Message-ID: <cf862fec-8e93-46c0-9254-f95dbd2b5c03@npsh.hu>

Hi squid community,

I need to find most best and sustainable way to build a stable High 
Availability squid cluster/solution for abou 40k user.

Parameters: I need HA, caching(little objects only not like big windows 
updates), scaling(It is just secondly), and I want to use and modify(in 
production,in working hours) complex black- and whitelists

I have some idea:

1. A huge kubernetes cluster

pro: Easy to scale, change the config and update.

contra: I'm afraid of the network latency.(because of the most plus 
layers e.g. vm network stack, kubernetes network stack ith vxlan and etc.).

2. Simple VM-s with a HAProxy in tcp mode

pro: less network latency(I think)

contra: More time to Administration


Has anybody any experience with squid in kubernetes(or similar 
technology) with a large number of useres?

What do you think which is the most perfect solution or do you have 
other idea for the implementation?

Thanks!

Best, Szabolcs

-- 
*Pint?r Szabolcs P?ter*
H-1117 Budapest, Neumann J?nos u. 1. A ?p?let 2. emelet
+36 1 489-4600
+36 30 471-3827
spinter at npsh.hu
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220920/1e67ff4b/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: OpfuJ7aWrZr5hlc2.png
Type: image/png
Size: 3869 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220920/1e67ff4b/attachment.png>

From dwd at fnal.gov  Tue Sep 20 22:33:37 2022
From: dwd at fnal.gov (Dave Dykstra)
Date: Tue, 20 Sep 2022 22:33:37 +0000
Subject: [squid-users] Missing squid 5.6 & 5.7 announcements
Message-ID: <Yyo/wOTzT9EietDQ@fnal.gov>

I tried sending this directly to Amos twice over the last week or so but
it bounced each time.

I noticed that 5.7 is on the website since 5 September, but I have not
see a release announcement for that or for 5.6 from June.  I would like
to know if it is considered to be in a stable enough state that all
squid 4 users are encouraged to upgrade, or not.  The release notes
don't tell me that.

Dave

From marcelorodrigo at graminsta.com.br  Wed Sep 21 03:22:39 2022
From: marcelorodrigo at graminsta.com.br (Marcelo)
Date: Wed, 21 Sep 2022 00:22:39 -0300
Subject: [squid-users] Different routes for domains in dstdomains list
Message-ID: <002d01d8cd69$6abf4610$403dd230$@graminsta.com.br>

Hello,

 

I am trying to implement a rule in squid.conf, but I cant find enough
examples on google to do it.

 

Rule:

User try to access an URL THAT IS IN a dstdomain list so he will be routed
to route X

User try to access an URL THAT IS NOT IN the same dstdomain list so he will
be routed to route Y

 

All examples I can find is always denying or allowing access to the same
just one route.

 

It would be great if I could implement something like an IF argument in
squid.conf.

Like, if url is in the dstdomain list do like this, if not do like that.

 

Any ideias?

 

Marcelo Rodrigo

+55 11 9 6854 -3878

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220921/a5a36dd9/attachment.htm>

From rousskov at measurement-factory.com  Wed Sep 21 03:58:34 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 20 Sep 2022 23:58:34 -0400
Subject: [squid-users] Different routes for domains in dstdomains list
In-Reply-To: <002d01d8cd69$6abf4610$403dd230$@graminsta.com.br>
References: <002d01d8cd69$6abf4610$403dd230$@graminsta.com.br>
Message-ID: <5d32a184-7956-6403-2a1e-27d13ce6d8fe@measurement-factory.com>

On 9/20/22 23:22, Marcelo wrote:

> I am trying to implement a rule in squid.conf, but I cant find enough 
> examples on google to do it.
> 
> Rule:
> 
> User try to access an URL THAT IS IN a dstdomain list so he will be 
> routed to route X
> 
> User try to access an URL THAT IS NOT IN the same dstdomain list so he 
> will be routed to route Y
> 
> All examples I can find is always denying or allowing access to the same 
> just one route.

How do you define "route"?

* If you want a request to go out on a connection that uses a particular 
source IP address then use the tcp_outgoing_address directives.

* If you want to direct a request to different cache_peers, then use 
cache_peer_access and related directives.

* If you want to change the request itself (e.g., change its URL or 
target) then see url_rewrite_program and 
https://wiki.squid-cache.org/SquidFaq/ContentAdaptation . In some cases, 
an originserver cache_peer can work for this as well.


> It would be great if I could implement something like an IF argument in 
> squid.conf.
> 
> Like, if url is in the dstdomain list do like this, if not do like that.
> 
> Any ideias?


Many Squid built-in actions can be configured/tuned based on conditions 
(i.e. ACLs). Some actions can be outsourced to helpers and services. 
However, you cannot easily import custom "do this" code directly into 
Squid. Usually, one does not really have to do that though; if you 
detail your needs (i.e. what "do like this" means in your use case), 
then somebody may be able to suggest a specific solution.


HTH,

Alex.


From squid3 at treenet.co.nz  Wed Sep 21 11:27:21 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 21 Sep 2022 23:27:21 +1200
Subject: [squid-users] Squid performance recommendation
In-Reply-To: <cf862fec-8e93-46c0-9254-f95dbd2b5c03@npsh.hu>
References: <cf862fec-8e93-46c0-9254-f95dbd2b5c03@npsh.hu>
Message-ID: <773afd34-6f0d-5887-d220-cb056a6a7b36@treenet.co.nz>

On 21/09/22 07:52, Pint?r Szabolcs wrote:
> Hi squid community,
> 
> I need to find most best and sustainable way to build a stable High 
> Availability squid cluster/solution for abou 40k user.
> 

Number of users is of low relevance to Squid. What matters is the rate 
of requests they are sending to Squid.

For example; each of your 40k users sending one request per hour to 
Squid is not a problem, but if they send one per second will need 
multiple Squid instances.


> Parameters: I need HA,

Assuming you do mean "high availability" instead of something unusual.
Squid is designed to maximize availability - whether it meets this 
criteria will depend on several factors:

  * what measure(s) you consider necessary for this requirement.
    Proxy uptime? Response time?
    How much outage is acceptable for each?

  * the complexity of features and policy Squid is configured with.
   - impacts reconfigure/restart times, and response times.

  * consistency of client compliance to HTTP
   - impacts response times


> caching(little objects only not like big windows 
> updates),

No problem for Squid.

> scaling(It is just secondly), and

Not a problem for Squid.

> I want to use and modify(in 
> production,in working hours) complex black- and whitelists
> 

Should not be a problem. Details of course depend on your specific 
policy and update needs.



> I have some idea:
> 
> 1. A huge kubernetes cluster
> 
> pro: Easy to scale, change the config and update.
> 
> contra: I'm afraid of the network latency.(because of the most plus 
> layers e.g. vm network stack, kubernetes network stack ith vxlan and etc.).
> 

Sorry I have no experience here. So the remainder of your questions I 
cannot answer.


HTH
Amos


From squid3 at treenet.co.nz  Wed Sep 21 11:43:41 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 21 Sep 2022 23:43:41 +1200
Subject: [squid-users] Missing squid 5.6 & 5.7 announcements
In-Reply-To: <Yyo/wOTzT9EietDQ@fnal.gov>
References: <Yyo/wOTzT9EietDQ@fnal.gov>
Message-ID: <77b706ec-03d4-f075-5573-b4643c4d98f7@treenet.co.nz>

On 21/09/22 10:33, Dave Dykstra wrote:
> I tried sending this directly to Amos twice over the last week or so but
> it bounced each time.
> 
> I noticed that 5.7 is on the website since 5 September, but I have not
> see a release announcement for that or for 5.6 from June.


Mea culpa sorry. I am a bit behind on security paperwork needed for those.


>  I would like
> to know if it is considered to be in a stable enough state that all
> squid 4 users are encouraged to upgrade, or not.  The release notes
> don't tell me that.

Basically yes we are back at "encourage to upgrade".

To be specific:
  * The initial big troubles were resolved in 5.5.
  * We have two reports of Delay Pools having weird behaviours, but that 
is shared with v4.

  * WCCP regression (YMMV) in latest security patches has not fully been 
resolved in the official code. Experimental patches are available if 
necessary.


HTH
Amos


From marcus.kool at urlfilterdb.com  Wed Sep 21 15:58:45 2022
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 21 Sep 2022 16:58:45 +0100
Subject: [squid-users] Squid performance recommendation
In-Reply-To: <cf862fec-8e93-46c0-9254-f95dbd2b5c03@npsh.hu>
References: <cf862fec-8e93-46c0-9254-f95dbd2b5c03@npsh.hu>
Message-ID: <3887afdf-2156-5151-7c48-948fee782689@urlfilterdb.com>


On 20/09/2022 20:52, Pint?r Szabolcs wrote:
>
> Hi squid community,
>
> I need to find most best and sustainable way to build a stable High Availability squid cluster/solution for abou 40k user.
>
> Parameters: I need HA, caching(little objects only not like big windows updates), scaling(It is just secondly), and I want to use and modify(in production,in working hours) complex black- and whitelists
>
> [snip]

To modify the Squid config in production during working hours is a requirement that needs careful thought since the web proxy is unavailable when it reloads its configuration.

HA can resolved this with
1. change config squid node 1
2. load balancer stops new connections to node 1
3. wait X minutes, maybe 15 minutes, for most connections to node 1 to disappear
4. reload the config on node 1 - existing connections are closed
5. wait until Squid on node 1 is operational again
6. load balancer allows new connections to node 1 and stops new connections to node 2
7. change config squid node 2
8. wait X minutes, maybe 15 minutes, for most connections to node 2 to disappear
9. reload the config on node 2 - existing connections are closed
10. wait until Squid on node 2 is operational again
11. load balancer allows new connections to node 2

Depending on what your requirements are, you may consider using ufdbGuard for Squid since ufdbGuard can reload its configuration without interrupting clients of the web proxy.

Marcus



From ngtech1ltd at gmail.com  Wed Sep 21 16:58:31 2022
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Wed, 21 Sep 2022 19:58:31 +0300
Subject: [squid-users] Squid performance recommendation
In-Reply-To: <cf862fec-8e93-46c0-9254-f95dbd2b5c03@npsh.hu>
References: <cf862fec-8e93-46c0-9254-f95dbd2b5c03@npsh.hu>
Message-ID: <004a01d8cddb$622c6c40$268544c0$@gmail.com>

Hey Szabolcs,
 
Since Amos answered your question regarding a simple VM I would like to refer to the k8s part.
 
A huge Kubernetes cluster is good for very specific use cases.
It?s not ?easy? to scale and or change the config and update out of the box,
you will need to work on that since there aren?t any ready to use solutions for these on k8s.
?kubectl apply -f x.yaml? is not really a good solution for every scaling problem.
Also take into account that you will probably will have issues with cache HITS if the distribution
algorithm is unable to inflict the same requests to the same proxy.
 
With k8s since the *big* clusters usually is on BareMetal it?s possible to get up to 30 percent more
performance then a VMs. Also, the network latency is not so high in a k8s cluster for the same reason.
Basically, in most k8s clusters the traffic is almost like inside a shared memory.
 
It?s possible to define the specs of the project and to asses from there.
HAproxy will be able to handle 40k clients without any issues and to allow full HA you might need 2 HAproxy machines.
The real issue with such a setup is how the config is applied.
For example, a big list of black and whitelist domains might be better stored outside of squid.
Depends on your requirements you might be able to use either ufdbGuard or another solution.
 
There aren?t many differences between containerized squid to VM?s is not a lot. Actually, in the case of a simple forward proxy
it might be pretty simple to run a containerized squid on-top of a VM (which how k8s is most runs like these days).
 
As for autoscaling squid containers on-top of k8s, you will probably need to invest a lot more then a VM to make this fit your needs.
 
Since you mentioned more Administration time on a VM, it?s not true (to my opinion and experience).
There isn?t much of a difference between a VM and a container for a simple forward squid setup.
(it will be different if you need interception of connections)
 
If you do have more details on the required setup itself it would be pretty simple to find the right way for a good solution.
 
I really recommend you to read the next article:
https://ably.com/blog/no-we-dont-use-kubernetes
 
which touch many aspects of k8s vs VM?s.
 
I can try to give you an idea for implementation on VM?s but I am still missing couple pieces to understand the best.
 
Yours,
Eliezer
 
----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com <mailto:ngtech1ltd at gmail.com> 
Web: https://ngtech.co.il/
My-Tube: https://tube.ngtech.co.il/
 
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Pint?r Szabolcs
Sent: Tuesday, 20 September 2022 22:52
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid performance recommendation
 
Hi squid community,
I need to find most best and sustainable way to build a stable High Availability squid cluster/solution for abou 40k user.
Parameters: I need HA, caching(little objects only not like big windows updates), scaling(It is just secondly), and I want to use and modify(in production,in working hours) complex black- and whitelists
I have some idea:

1. A huge kubernetes cluster 
pro: Easy to scale, change the config and update.
contra: I'm afraid of the network latency.(because of the most plus layers e.g. vm network stack, kubernetes network stack ith vxlan and etc.).
2. Simple VM-s with a HAProxy in tcp mode
pro: less network latency(I think)
contra: More time to Administration 


Has anybody any experience with squid in kubernetes(or similar technology) with a large number of useres?

What do you think which is the most perfect solution or do you have other idea for the implementation?

Thanks!

Best, Szabolcs
-- 
Pint?r Szabolcs P?ter
H-1117 Budapest, Neumann J?nos u. 1. A ?p?let 2. emelet
+36 1 489-4600 
+36 30 471-3827 
spinter at npsh.hu <mailto:spinter at npsh.hu> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220921/e7daa420/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 3869 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220921/e7daa420/attachment.png>

From uhlar at fantomas.sk  Thu Sep 22 14:10:52 2022
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 22 Sep 2022 16:10:52 +0200
Subject: [squid-users] bandwidth statistics
In-Reply-To: <740908755.1593385122.1663605981139.JavaMail.root@zimbra17-e3.priv.proxad.net>
References: <YyiTfuu10KD5vTNo@fantomas.sk>
 <740908755.1593385122.1663605981139.JavaMail.root@zimbra17-e3.priv.proxad.net>
Message-ID: <Yyxs7LCB/ta085kI@fantomas.sk>

On 19.09.22 18:46, Xavier Lecluse wrote:
>You may use Cacti for example if you need to monitor your bandwith globally.

BTW

another problem came to my mind:

squid doesn't support 64-bis MIBs by now and looks it won't for some time:
http://lists.squid-cache.org/pipermail/squid-users/2022-June/024893.html
http://lists.squid-cache.org/pipermail/squid-users/2022-June/024896.html

with traffic over ~114mbps, 32-bit counters overflow within 5 minutes which 
makes it impossible to monitor counters reliably.

with such limitation, and traffic I notice on server I was asking about, 
it's impossible to find out real numbers. 
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Posli tento mail 100 svojim znamim - nech vidia aky si idiot
Send this email to 100 your friends - let them see what an idiot you are


From frizquierdo87 at gmail.com  Thu Sep 22 22:07:01 2022
From: frizquierdo87 at gmail.com (Francisco)
Date: Thu, 22 Sep 2022 18:07:01 -0400
Subject: [squid-users] Fwd: Squid shutdown on web request of type
 http://ftp.domain.country
In-Reply-To: <CAJXDObYOED1-utdptCTLq1Ahw8v8683bzDpPue+eWiVBQCEhAg@mail.gmail.com>
References: <CAJXDObYOED1-utdptCTLq1Ahw8v8683bzDpPue+eWiVBQCEhAg@mail.gmail.com>
Message-ID: <CAJXDObaAeZCQEbTtVntu4RVrQT-ZZaY9E89YgGNQi2zQLXcvaA@mail.gmail.com>

I have compiled and installed Squid proxy (version 5.6) on Debian 11. When
I enable certain response size control rules (*reply_body_max_size*), Squid
stops instantly when making a web request to web-serving FTPs (for example:
http://ftp.sld.cu it?s a FTP site served as HTTP), only happen with this
kind of site.

I have the following acl:

acl usuarios_nav_basica proxy_auth "/etc/squid/usuarios/nav-basica"
acl usuarios_internet proxy_auth "/etc/squid/usuarios/nav-internet"
acl usuarios_admins proxy_auth "/etc/squid/usuarios/admins"

acl dominio_cuba dstdomain .cu
acl dominio_infomed dstdomain .sld.cu
acl dominio_bandec dstdomain  .bandec.cu
#thousands of domains
acl dominios dstdomain "/etc/squid/infomed/dominios"
acl dominios_parciales dstdomain "/etc/squid/infomed/dominios_parciales"
#thousands of sites
acl sitios url_regex -i "/etc/squid/infomed/sitios"

acl horario_manhana time MTWHFA 00:00-11:59

acl extensiones_media urlpath_regex -i
\.(mpg|mp3|avi|mp4|mov|m4v|mkv|flv)(\?.*)?$
acl extensiones_limitadas urlpath_regex -i \.(exe|cab|msi|iso)(\?.*)?$

cache_peer XXX.XXX.XXX.XXX parent 3128 0 no-query default
cache_peer_access XXX.XXX.XXX.XXX allow !dominio_infomed

always_direct allow dominio_infomed
never_direct allow !dominio_infomed

When I activate these rules, Squid shuts down:

reply_body_max_size 5 MB extensiones_media usuarios_internet
horario_manhana !dominio_cuba !dominios !dominios_parciales !sitios
reply_body_max_size 5 MB extensiones_limitadas usuarios_internet
horario_manhana !dominio_cuba !dominios !dominios_parciales !sitios

## Usuarios de navegacion basica
reply_body_max_size 50 MB usuarios_nav_basica horario_manhana
!dominio_infomed dominio_cuba
reply_body_max_size 50 MB usuarios_nav_basica horario_manhana dominios
!dominio_infomed
reply_body_max_size 50 MB usuarios_nav_basica horario_manhana
!dominio_infomed dominios_parciales
reply_body_max_size 50 MB usuarios_nav_basica horario_manhana
!dominio_infomed sitios

reply_body_max_size 100 MB usuarios_nav_basica !horario_manhana
!dominio_infomed dominio_cuba
reply_body_max_size 100 MB usuarios_nav_basica !horario_manhana
!dominio_infomed dominios
reply_body_max_size 100 MB usuarios_nav_basica !horario_manhana
!dominio_infomed dominios_parciales
reply_body_max_size 100 MB usuarios_nav_basica !horario_manhana
!dominio_infomed sitios

## Usuarios con acceso a internet
reply_body_max_size 50 MB usuarios_internet horario_manhana
!dominio_infomed dominio_cuba
reply_body_max_size 50 MB usuarios_internet horario_manhana
!dominio_infomed dominios
reply_body_max_size 50 MB usuarios_internet horario_manhana
!dominio_infomed dominios_parciales
reply_body_max_size 50 MB usuarios_internet horario_manhana
!dominio_infomed sitios

reply_body_max_size 100 MB usuarios_internet horario_manhana !dominio_cuba
reply_body_max_size 100 MB usuarios_internet horario_manhana !dominios
reply_body_max_size 100 MB usuarios_internet horario_manhana !dominios_parciales
reply_body_max_size 100 MB usuarios_internet horario_manhana !sitios

reply_body_max_size 1024 MB usuarios_internet !horario_manhana !dominio_cuba
reply_body_max_size 1024 MB usuarios_internet !horario_manhana !dominios
reply_body_max_size 1024 MB usuarios_internet !horario_manhana
!dominios_parciales
reply_body_max_size 1024 MB usuarios_internet !horario_manhana !sitios

reply_body_max_size 200 KB all

When I make systemctl status squid, it show Exiting due to repeated,
frequent failures. In /var/log/squid/cache.log I don?t found any about the
error.

 In /var/log/kernel.log I founded: [squid][500]: segfault at 448 ip
00005653d5ec933a sp 0000fffdf9374730 error 4 in squid [5653d5c950000+4c0000]

*Note*: If I leave the two first reply_body_max_size rules declarations,
it?s work ok!!!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220922/53ae5cb8/attachment.htm>

From rousskov at measurement-factory.com  Thu Sep 22 22:31:59 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 22 Sep 2022 18:31:59 -0400
Subject: [squid-users] Fwd: Squid shutdown on web request of type
 http://ftp.domain.country
In-Reply-To: <CAJXDObaAeZCQEbTtVntu4RVrQT-ZZaY9E89YgGNQi2zQLXcvaA@mail.gmail.com>
References: <CAJXDObYOED1-utdptCTLq1Ahw8v8683bzDpPue+eWiVBQCEhAg@mail.gmail.com>
 <CAJXDObaAeZCQEbTtVntu4RVrQT-ZZaY9E89YgGNQi2zQLXcvaA@mail.gmail.com>
Message-ID: <ae505ff6-7b26-55f2-8198-e60ca826601d@measurement-factory.com>

On 9/22/22 18:07, Francisco wrote:
> I have compiled and installed Squid proxy (version 5.6) on Debian 11. 
> When I enable certain response size control rules 
> (/*reply_body_max_size*/), Squid stops instantly when making a web 
> request to web-serving FTPs (for example: http://ftp.sld.cu 
> it?s a FTP site served as HTTP), only happen with this kind of site.

> In /var/log/kernel.log I founded: [squid][500]: segfault at 448 ip 

Squid segmentation faults are usually Squid bugs. Please consider filing 
a bug report with Squid bugzilla and attaching a backtrace from the 
coredump file there. Please keep the coredump file for further analysis.

There is some old information about enabling and examining coredumps at 
the FAQ URL below, but you can use your OS documentation as well:
https://wiki.squid-cache.org/SquidFaq/BugReporting#crashes_and_core_dumps

Upgrading to Squid v5.7 first is a good idea, but it may not address 
this specific bug.


Thank you,

Alex.


> I have the following acl:
> 
> |acl usuarios_nav_basica proxy_auth "/etc/squid/usuarios/nav-basica" acl 
> usuarios_internet proxy_auth "/etc/squid/usuarios/nav-internet" acl 
> usuarios_admins proxy_auth "/etc/squid/usuarios/admins" acl dominio_cuba 
> dstdomain .cu acl dominio_infomed dstdomain .sld.cu <http://sld.cu> acl 
> dominio_bandec dstdomain .bandec.cu <http://bandec.cu> #thousands of 
> domains acl dominios dstdomain "/etc/squid/infomed/dominios" acl 
> dominios_parciales dstdomain "/etc/squid/infomed/dominios_parciales" 
> #thousands of sites acl sitios url_regex -i "/etc/squid/infomed/sitios" 
> acl horario_manhana time MTWHFA 00:00-11:59 acl extensiones_media 
> urlpath_regex -i \.(mpg|mp3|avi|mp4|mov|m4v|mkv|flv)(\?.*)?$ acl 
> extensiones_limitadas urlpath_regex -i \.(exe|cab|msi|iso)(\?.*)?$ 
> cache_peer XXX.XXX.XXX.XXX parent 3128 0 no-query default 
> cache_peer_access XXX.XXX.XXX.XXX allow !dominio_infomed always_direct 
> allow dominio_infomed never_direct allow !dominio_infomed |
> 
> When I activate these rules, Squid shuts down:
> 
> |reply_body_max_size 5 MB extensiones_media usuarios_internet 
> horario_manhana !dominio_cuba !dominios !dominios_parciales !sitios 
> reply_body_max_size 5 MB extensiones_limitadas usuarios_internet 
> horario_manhana !dominio_cuba !dominios !dominios_parciales !sitios ## 
> Usuarios de navegacion basica reply_body_max_size 50 MB 
> usuarios_nav_basica horario_manhana !dominio_infomed dominio_cuba 
> reply_body_max_size 50 MB usuarios_nav_basica horario_manhana dominios 
> !dominio_infomed reply_body_max_size 50 MB usuarios_nav_basica 
> horario_manhana !dominio_infomed dominios_parciales reply_body_max_size 
> 50 MB usuarios_nav_basica horario_manhana !dominio_infomed sitios 
> reply_body_max_size 100 MB usuarios_nav_basica !horario_manhana 
> !dominio_infomed dominio_cuba reply_body_max_size 100 MB 
> usuarios_nav_basica !horario_manhana !dominio_infomed dominios 
> reply_body_max_size 100 MB usuarios_nav_basica !horario_manhana 
> !dominio_infomed dominios_parciales reply_body_max_size 100 MB 
> usuarios_nav_basica !horario_manhana !dominio_infomed sitios ## Usuarios 
> con acceso a internet reply_body_max_size 50 MB usuarios_internet 
> horario_manhana !dominio_infomed dominio_cuba reply_body_max_size 50 MB 
> usuarios_internet horario_manhana !dominio_infomed dominios 
> reply_body_max_size 50 MB usuarios_internet horario_manhana 
> !dominio_infomed dominios_parciales reply_body_max_size 50 MB 
> usuarios_internet horario_manhana !dominio_infomed sitios 
> reply_body_max_size 100 MB usuarios_internet horario_manhana 
> !dominio_cuba reply_body_max_size 100 MB usuarios_internet 
> horario_manhana !dominios reply_body_max_size 100 MB usuarios_internet 
> horario_manhana !dominios_parciales reply_body_max_size 100 MB 
> usuarios_internet horario_manhana !sitios reply_body_max_size 1024 MB 
> usuarios_internet !horario_manhana !dominio_cuba reply_body_max_size 
> 1024 MB usuarios_internet !horario_manhana !dominios reply_body_max_size 
> 1024 MB usuarios_internet !horario_manhana !dominios_parciales 
> reply_body_max_size 1024 MB usuarios_internet !horario_manhana !sitios 
> reply_body_max_size 200 KB all |
> 
> When I make |systemctl status squid|, it show Exiting due to repeated, 
> frequent failures. In /var/log/squid/cache.log I don?t found any about 
> the error.
> 
>  ?In /var/log/kernel.log I founded: [squid][500]: segfault at 448 ip 
> 00005653d5ec933a sp 0000fffdf9374730 error 4 in squid [5653d5c950000+4c0000]
> 
> *Note*: If I leave the two first |reply_body_max_size|?rules 
> declarations, it?s work ok!!!
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From Theo.BARRAGUE.ext at boursorama.fr  Fri Sep 23 14:30:35 2022
From: Theo.BARRAGUE.ext at boursorama.fr (=?iso-8859-1?Q?Th=E9o_BARRAGUE?=)
Date: Fri, 23 Sep 2022 14:30:35 +0000
Subject: [squid-users] Use ICP RTT with HTTPS request
Message-ID: <PAYP264MB4127C935A9422AAC1868EE9BA3519@PAYP264MB4127.FRAP264.PROD.OUTLOOK.COM>

Hello,

I'm trying to setup ICP exchange with HTTPS request.
With my current setup (no ssl bumping) I can't use ICP for cache but it may be possible for RTT.
My goal is to use the closest parent to establish the connection.

My configuration look like :

cache_peer 127.0.0.1 parent 3129 3131 no-digest proxy-only name=same-server
cache_peer_access same-server allow all

cache_peer w.x.y.z parent 3129 3131 no-digest proxy-only name=pair-server
cache_peer_access pair-server allow all

query_icmp on
never_direct allow all

It works great for http, when I curl for the first time i got that :

same-server
Network                                        recv/sent     RTT  Hops Hostnames
142.251.40.0                                      1/   1   121.0  14.0 www.google.fr

pair-server
Network                                        recv/sent     RTT  Hops Hostnames
172.253.122.0                                     1/   1    94.0  23.0 www.google.fr<http://www.google.fr>

Next requests will go through pair-server, example :

same-server
Network                                        recv/sent     RTT  Hops Hostnames
142.251.40.0                                      1/   1   121.0  14.0 www.google.fr

pair-server
Network                                        recv/sent     RTT  Hops Hostnames
172.253.122.0                                    10/  10    93.1  23.0 www.google.fr<http://www.google.fr>

But for HTTPS, squid is able to determine hostname and network but doesn't care about RTT sharing :

same-server
Network                                        recv/sent     RTT  Hops Hostnames
149.202.190.0                                    10/   1     6.0  15.0 api.gouv.fr

pair-server
Network                                        recv/sent     RTT  Hops Hostnames

Even if I force a request though the pair-server to initiate NetDB, ICP not used.

How can I say "please, use ICP for RTT sharing like you did with HTTP" ?

Best regards
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220923/b65ed6e9/attachment.htm>

From rousskov at measurement-factory.com  Fri Sep 23 14:52:38 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 23 Sep 2022 10:52:38 -0400
Subject: [squid-users] Use ICP RTT with HTTPS request
In-Reply-To: <PAYP264MB4127C935A9422AAC1868EE9BA3519@PAYP264MB4127.FRAP264.PROD.OUTLOOK.COM>
References: <PAYP264MB4127C935A9422AAC1868EE9BA3519@PAYP264MB4127.FRAP264.PROD.OUTLOOK.COM>
Message-ID: <44da60ba-d691-06ba-22c6-4e95ad6b9fc5@measurement-factory.com>


On 9/23/22 10:30, Th?o BARRAGUE wrote:

> How can I say "please, use ICP for RTT sharing like you did with
> HTTP" ?

AFAICT, Squid tries to use NetDB on both HTTP and HTTPS paths, but 
something probably goes wrong somewhere. The easiest way to figure this 
out may be to analyze debugging cache.log while reproducing the problem 
with a single transaction.

https://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction

Beyond that, I do not have any good triage ideas. You may want to share 
Cache Manager mgr:server_list page for additional clues. Does changing 
the order of cache_peer lines in squid.conf change the outcome?


Cheers,

Alex.



> I'm trying to setup ICP exchange with HTTPS request.
> With my current setup (no ssl bumping) I can't use ICP for cache but it 
> may be possible for RTT.
> My goal is to use the closest parent to establish the connection.
> 
> My configuration look like :
> 
>     cache_peer 127.0.0.1 parent 3129 3131 no-digest proxy-only
>     name=same-server
>     cache_peer_access same-server allow all
> 
>     cache_peer w.x.y.z parent 3129 3131 no-digest proxy-only
>     name=pair-server
>     cache_peer_access pair-server allow all
> 
>     query_icmp on
>     never_direct allow all
> 
> 
> It works great for http, when I curl for the first time i got that :
> 
>     same-server
>     Network ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?recv/sent ? ? RTT
>      ?Hops Hostnames
>     142.251.40.0 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?1/ ? 1 ? 121.0
>      ?14.0 www.google.fr
> 
>     pair-server
>     Network ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?recv/sent ? ? RTT
>      ?Hops Hostnames
>     172.253.122.0 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1/ ? 1 ? ?94.0
>      ?23.0 www.google.fr <http://www.google.fr>
> 
> 
> Next requests will go through pair-server, example :
> 
>     same-server
>     Network ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?recv/sent ? ? RTT
>      ?Hops Hostnames
>     142.251.40.0 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?1/ ? 1 ? 121.0
>      ?14.0 www.google.fr
> 
>     pair-server
>     Network ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?recv/sent ? ? RTT
>      ?Hops Hostnames
>     172.253.122.0 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?10/ ?10 ? ?93.1
>      ?23.0 www.google.fr <http://www.google.fr>
> 
> 
> But for HTTPS, squid is able to determine hostname and network but 
> doesn't care about RTT sharing :
> 
>     same-server
>     Network ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?recv/sent ? ? RTT
>      ?Hops Hostnames
>     149.202.190.0? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 10/ ? 1 ? ? 6.0
>      ?15.0 api.gouv.fr
> 
>     pair-server
>     Network ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?recv/sent ? ? RTT
>      ?Hops Hostnames
> 
> 
> Even if I force a request though the pair-server to initiate NetDB, ICP 
> not used.



From david at articatech.com  Sat Sep 24 10:35:29 2022
From: david at articatech.com (David Touzeau)
Date: Sat, 24 Sep 2022 12:35:29 +0200
Subject: [squid-users] Squid performance recommendation
In-Reply-To: <cf862fec-8e93-46c0-9254-f95dbd2b5c03@npsh.hu>
References: <cf862fec-8e93-46c0-9254-f95dbd2b5c03@npsh.hu>
Message-ID: <b5b50046-f5c3-16ba-9827-95c8341a577e@articatech.com>

Hi

We have some experience on cluster configuration.

https://wiki.articatech.com/en/proxy-service/hacluster

As using Kubernetes for Squid and for 40K users is a very "risky adventure".

Squid requires a very high disk performance (I/O) which means both a 
good hard disk drive and a decent controller card.

You will reach a functional limit of kubernete which by structure is not 
adapted to this type of service

Of course you can continue in this way....

But we see this a lot from experience:

"To take on the load you're going to install a lot of instances on 
multiple virtualization servers.
Whereas 2 or 3 physical machines could handle it all."


Le 20/09/2022 ? 21:52, Pint?r Szabolcs a ?crit?:
>
> Hi squid community,
>
> I need to find most best and sustainable way to build a stable High 
> Availability squid cluster/solution for abou 40k user.
>
> Parameters: I need HA, caching(little objects only not like big 
> windows updates), scaling(It is just secondly), and I want to use and 
> modify(in production,in working hours) complex black- and whitelists
>
> I have some idea:
>
> 1. A huge kubernetes cluster
>
> pro: Easy to scale, change the config and update.
>
> contra: I'm afraid of the network latency.(because of the most plus 
> layers e.g. vm network stack, kubernetes network stack ith vxlan and 
> etc.).
>
> 2. Simple VM-s with a HAProxy in tcp mode
>
> pro: less network latency(I think)
>
> contra: More time to Administration
>
>
> Has anybody any experience with squid in kubernetes(or similar 
> technology) with a large number of useres?
>
> What do you think which is the most perfect solution or do you have 
> other idea for the implementation?
>
> Thanks!
>
> Best, Szabolcs
>
> -- 
> *Pint?r Szabolcs P?ter*
> H-1117 Budapest, Neumann J?nos u. 1. A ?p?let 2. emelet
> +36 1 489-4600
> +36 30 471-3827
> spinter at npsh.hu
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-- 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220924/7e43b0f9/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: OpfuJ7aWrZr5hlc2.png
Type: image/png
Size: 3869 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220924/7e43b0f9/attachment.png>

From Theo.BARRAGUE.ext at boursorama.fr  Mon Sep 26 09:51:40 2022
From: Theo.BARRAGUE.ext at boursorama.fr (=?iso-8859-1?Q?Th=E9o_BARRAGUE?=)
Date: Mon, 26 Sep 2022 09:51:40 +0000
Subject: [squid-users] Use ICP RTT with HTTPS request
Message-ID: <PAYP264MB412768F98833F4A4878EC042A3529@PAYP264MB4127.FRAP264.PROD.OUTLOOK.COM>

Hello,

Thank's for answer. I increased output level and get this :


2022/09/26 09:07:52.381| 44,3| peer_select.cc(163) peerSelect: CONNECT
2022/09/26 09:07:52.381| 44,3| peer_select.cc(472) peerSelectFoo: CONNECT api.gouv.fr
2022/09/26 09:07:52.381| 44,3| peer_select.cc(485) peerSelectFoo: peerSelectFoo: direct = DIRECT_UNKNOWN (never_direct to be checked)
2022/09/26 09:07:52.381| 28,3| Checklist.cc(70) preCheck: 0x5653abfc4b68 checking slow rules
2022/09/26 09:07:52.381| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.25.41.21:34896' found
2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked: all = 1
2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked: never_direct#1 = 1
2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked: never_direct = 1
2022/09/26 09:07:52.381| 28,3| Checklist.cc(63) markFinished: 0x5653abfc4b68 answer ALLOWED for match
2022/09/26 09:07:52.381| 28,3| Checklist.cc(163) checkCallback: ACLChecklist::checkCallback: 0x5653abfc4b68 answer=ALLOWED
2022/09/26 09:07:52.381| 44,3| peer_select.cc(195) peerCheckNeverDirectDone: peerCheckNeverDirectDone: ALLOWED
2022/09/26 09:07:52.381| 44,3| peer_select.cc(201) peerCheckNeverDirectDone: direct = DIRECT_NO (never_direct allow)
2022/09/26 09:07:52.381| 44,3| peer_select.cc(472) peerSelectFoo: CONNECT api.gouv.fr
2022/09/26 09:07:52.381| 44,3| peer_select.cc(712) peerGetSomeParent: CONNECT api.gouv.fr
2022/09/26 09:07:52.381| 15,3| neighbors.cc(332) getRoundRobinParent: returning NULL
2022/09/26 09:07:52.381| 15,3| neighbors.cc(382) getWeightedRoundRobinParent: getWeightedRoundRobinParent: returning NULL
2022/09/26 09:07:52.381| 28,3| Checklist.cc(70) preCheck: 0x7ffd6220f030 checking fast rules
2022/09/26 09:07:52.381| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.25.41.21:34896' found
2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked: all = 1
2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked: peer_access squid-2.inf-proxy03-d01.dc02#1 = 1
2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked: peer_access squid-2.inf-proxy03-d01.dc02 = 1
2022/09/26 09:07:52.381| 28,3| Checklist.cc(63) markFinished: 0x7ffd6220f030 answer ALLOWED for match
2022/09/26 09:07:52.381| 15,3| neighbors.cc(294) getFirstUpParent: getFirstUpParent: returning 10.26.8.10
2022/09/26 09:07:52.381| 44,3| peer_select.cc(978) peerAddFwdServer: adding FIRSTUP_PARENT/10.26.8.10
2022/09/26 09:07:52.381| 28,3| Checklist.cc(70) preCheck: 0x7ffd6220f0d0 checking fast rules
2022/09/26 09:07:52.381| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.25.41.21:34896' found
2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked: all = 1
2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked: peer_access squid-2.inf-proxy03-d01.dc02#1 = 1
2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked: peer_access squid-2.inf-proxy03-d01.dc02 = 1
2022/09/26 09:07:52.382| 28,3| Checklist.cc(63) markFinished: 0x7ffd6220f0d0 answer ALLOWED for match
2022/09/26 09:07:52.382| 44,3| peer_select.cc(971) peerAddFwdServer: skipping ANY_OLD_PARENT/10.26.8.10; have FIRSTUP_PARENT/10.26.8.10
2022/09/26 09:07:52.382| 28,3| Checklist.cc(70) preCheck: 0x7ffd6220f0d0 checking fast rules
2022/09/26 09:07:52.382| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.25.41.21:34896' found
2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked: all = 1
2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked: peer_access squid-2.inf-proxy03-d01.dc01#1 = 1
2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked: peer_access squid-2.inf-proxy03-d01.dc01 = 1
2022/09/26 09:07:52.382| 28,3| Checklist.cc(63) markFinished: 0x7ffd6220f0d0 answer ALLOWED for match
2022/09/26 09:07:52.382| 44,3| peer_select.cc(978) peerAddFwdServer: adding ANY_OLD_PARENT/127.0.0.1
2022/09/26 09:07:52.382| 15,3| neighbors.cc(472) getDefaultParent: getDefaultParent: returning NULL
2022/09/26 09:07:52.382| 44,2| peer_select.cc(295) peerSelectDnsPaths: Find IP destination for: api.gouv.fr:443' via 10.26.8.10
2022/09/26 09:07:52.382| 44,2| peer_select.cc(295) peerSelectDnsPaths: Find IP destination for: api.gouv.fr:443' via 127.0.0.1
2022/09/26 09:07:52.382| 44,2| peer_select.cc(316) peerSelectDnsPaths: Found sources for 'api.gouv.fr:443'
2022/09/26 09:07:52.382| 44,2| peer_select.cc(317) peerSelectDnsPaths:   always_direct = DENIED
2022/09/26 09:07:52.382| 44,2| peer_select.cc(318) peerSelectDnsPaths:    never_direct = ALLOWED
2022/09/26 09:07:52.382| 44,2| peer_select.cc(328) peerSelectDnsPaths:      cache_peer = local=0.0.0.0 remote=10.26.8.10:3129 flags=1
2022/09/26 09:07:52.382| 44,2| peer_select.cc(328) peerSelectDnsPaths:      cache_peer = local=0.0.0.0 remote=127.0.0.1:3129 flags=1
2022/09/26 09:07:52.382| 44,2| peer_select.cc(331) peerSelectDnsPaths:        timedout = 0
2022/09/26 09:07:52.382| 26,3| tunnel.cc(1249) tunnelPeerSelectComplete: paths=2, p[0]={local=0.0.0.0 remote=10.26.8.10:3129 flags=1}, serverDest[0]={local=0.0.0.0 remote=10.26.8.10:3129 flags=1}
2022/09/26 09:07:52.382| 17,3| FwdState.cc(1369) GetMarkingsToServer: from 0.0.0.0 netfilter mark 0
2022/09/26 09:07:52.382| 26,3| AsyncCall.cc(25) AsyncCall: The AsyncCall tunnelConnectDone constructed, this=0x5653abf924a0 [call164]
2022/09/26 09:07:52.382| 5,3| ConnOpener.cc(43) ConnOpener: will connect to local=0.0.0.0 remote=10.26.8.10:3129 flags=1 with 30 timeout
2022/09/26 09:07:52.382| 50,3| comm.cc(350) comm_openex: comm_openex: Attempt open socket for: 0.0.0.0
2022/09/26 09:07:52.382| 50,3| comm.cc(393) comm_openex: comm_openex: Opened socket local=0.0.0.0 remote=[::] FD 14 flags=1 : family=2, type=1, protocol=6
2022/09/26 09:07:52.382| 51,3| fd.cc(198) fd_open: fd_open() FD 14 api.gouv.fr:443
2022/09/26 09:07:52.382| 5,3| ConnOpener.cc(291) createFd: local=0.0.0.0 remote=10.26.8.10:3129 flags=1 will timeout in 30
2022/09/26 09:07:52.393| 26,3| AsyncCall.cc(92) ScheduleCall: ConnOpener.cc(139) will call tunnelConnectDone(local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1, data=0x5653abfa3598) [call164]
2022/09/26 09:07:52.393| 26,3| AsyncCallQueue.cc(55) fireNext: entering tunnelConnectDone(local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1, data=0x5653abfa3598)
2022/09/26 09:07:52.393| 26,3| AsyncCall.cc(37) make: make call tunnelConnectDone [call164]
2022/09/26 09:07:52.393| 14,3| Address.cc(382) lookupHostIP: Given Non-IP 'api.gouv.fr': Name or service not known
2022/09/26 09:07:52.393| 38,3| net_db.cc(355) netdbSendPing: netdbSendPing: pinging api.gouv.fr
2022/09/26 09:07:52.393| 37,2| IcmpSquid.cc(59) SendEcho:  Socket Closed. Aborted send to 10.26.8.10, opcode 3, len 10
2022/09/26 09:07:52.393| 26,3| tunnel.cc(1163) tunnelRelayConnectRequest: local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1, tunnelState=0x5653abfa3598
2022/09/26 09:07:52.393| 22,3| refresh.cc(648) getMaxAge: getMaxAge: 'api.gouv.fr:443'
2022/09/26 09:07:52.393| 11,2| tunnel.cc(1177) tunnelRelayConnectRequest: Tunnel Server REQUEST: local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1:
----------
CONNECT api.gouv.fr:443 HTTP/1.1
User-Agent: curl/7.52.1
Host: api.gouv.fr:443
X-Forwarded-For: unknown
Cache-Control: max-age=259200
Connection: close


----------
2022/09/26 09:07:52.393| 5,3| comm.cc(559) commSetConnTimeout: local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1 timeout 900
2022/09/26 09:07:52.393| 5,3| comm.cc(559) commSetConnTimeout: local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1 timeout 900
2022/09/26 09:07:52.393| 26,3| AsyncCallQueue.cc(57) fireNext: leaving tunnelConnectDone(local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1, data=0x5653abfa3598)
2022/09/26 09:07:52.393| 5,3| IoCallback.cc(116) finish: called for local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1 (0, 0)
2022/09/26 09:07:52.393| 26,3| tunnel.cc(929) tunnelConnectReqWriteDone: local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1, flag=0


It seems peerGetSomeParent is called and this method never issue an ICP :


static void
peerGetSomeParent(ps_state * ps)
{
    CachePeer *p;
    HttpRequest *request = ps->request;
    hier_code code = HIER_NONE;
    debugs(44, 3, request->method << ' ' << request->url.host());

    if (ps->direct == DIRECT_YES)
        return;

    if ((p = peerSourceHashSelectParent(request))) {
        code = SOURCEHASH_PARENT;
#if USE_AUTH
    } else if ((p = peerUserHashSelectParent(request))) {
        code = USERHASH_PARENT;
#endif
    } else if ((p = carpSelectParent(request))) {
        code = CARP;
    } else if ((p = getRoundRobinParent(request))) {
        code = ROUNDROBIN_PARENT;
    } else if ((p = getWeightedRoundRobinParent(request))) {
        code = ROUNDROBIN_PARENT;
    } else if ((p = getFirstUpParent(request))) {
        code = FIRSTUP_PARENT;
    } else if ((p = getDefaultParent(request))) {
        code = DEFAULT_PARENT;
    }

    if (code != HIER_NONE) {
        peerAddFwdServer(ps, p, code);
    }
}


Instead of peerGetSomeNeighbor :


/**
 * peerGetSomeNeighbor
 *
 * Selects a neighbor (parent or sibling) based on one of the
 * following methods:
 *      Cache Digests
 *      CARP
 *      ICMP Netdb RTT estimates
 *      ICP/HTCP queries
 */
static void
peerGetSomeNeighbor(ps_state * ps)
{
    StoreEntry *entry = ps->entry;
    HttpRequest *request = ps->request;
    CachePeer *p;
    hier_code code = HIER_NONE;
    assert(entry->ping_status == PING_NONE);

    if (ps->direct == DIRECT_YES) {
        entry->ping_status = PING_DONE;
        return;
    }

#if USE_CACHE_DIGESTS
    if ((p = neighborsDigestSelect(request))) {
        if (neighborType(p, request->url) == PEER_PARENT)
            code = CD_PARENT_HIT;
        else
            code = CD_SIBLING_HIT;
    } else
#endif
        if ((p = netdbClosestParent(request))) {
            code = CLOSEST_PARENT;
        } else if (peerSelectIcpPing(request, ps->direct, entry)) {
            debugs(44, 3, "peerSelect: Doing ICP pings");
            ps->ping.start = current_time;
            ps->ping.n_sent = neighborsUdpPing(request,
                                               entry,
                                               peerHandlePingReply,
                                               ps,
                                               &ps->ping.n_replies_expected,
                                               &ps->ping.timeout);

            if (ps->ping.n_sent == 0)
                debugs(44, DBG_CRITICAL, "WARNING: neighborsUdpPing returned 0");
            debugs(44, 3, "peerSelect: " << ps->ping.n_replies_expected <<
                   " ICP replies expected, RTT " << ps->ping.timeout <<
                   " msec");

            if (ps->ping.n_replies_expected > 0) {
                entry->ping_status = PING_WAITING;
                eventAdd("peerPingTimeout",
                         peerPingTimeout,
                         ps,
                         0.001 * ps->ping.timeout,
                         0);
                return;
            }
        }

    if (code != HIER_NONE) {
        assert(p);
        peerAddFwdServer(ps, p, code);
    }

    entry->ping_status = PING_DONE;
}


These functions are called from peerSelectFoo :


static void
peerSelectFoo(ps_state * ps)
{
    if (!cbdataReferenceValid(ps->callback_data)) {
        debugs(44, 3, "Aborting peer selection. Parent Job went away.");
        delete ps;
        return;
    }

    StoreEntry *entry = ps->entry;
    HttpRequest *request = ps->request;
    debugs(44, 3, request->method << ' ' << request->url.host());

    /** If we don't know whether DIRECT is permitted ... */
    if (ps->direct == DIRECT_UNKNOWN) {
        if (ps->always_direct == ACCESS_DUNNO) {
            debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] << " (always_direct to be checked)");
            /** check always_direct; */
            ACLFilledChecklist *ch = new ACLFilledChecklist(Config.accessList.AlwaysDirect, request, NULL);
            ch->al = ps->al;
            ps->acl_checklist = ch;
            ps->acl_checklist->nonBlockingCheck(peerCheckAlwaysDirectDone, ps);
            return;
        } else if (ps->never_direct == ACCESS_DUNNO) {
            debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] << " (never_direct to be checked)");
            /** check never_direct; */
            ACLFilledChecklist *ch = new ACLFilledChecklist(Config.accessList.NeverDirect, request, NULL);
            ch->al = ps->al;
            ps->acl_checklist = ch;
            ps->acl_checklist->nonBlockingCheck(peerCheckNeverDirectDone, ps);
            return;
        } else if (request->flags.noDirect) {
            /** if we are accelerating, direct is not an option. */
            ps->direct = DIRECT_NO;
            debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] << " (forced non-direct)");
        } else if (request->flags.loopDetected) {
            /** if we are in a forwarding-loop, direct is not an option. */
            ps->direct = DIRECT_YES;
            debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] << " (forwarding loop detected)");
        } else if (peerCheckNetdbDirect(ps)) {
            ps->direct = DIRECT_YES;
            debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] << " (checkNetdbDirect)");
        } else {
            ps->direct = DIRECT_MAYBE;
            debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] << " (default)");
        }

        debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct]);
    }

    if (!entry || entry->ping_status == PING_NONE)
        peerSelectPinned(ps);
    if (entry == NULL) {
        (void) 0;
    } else if (entry->ping_status == PING_NONE) {
        peerGetSomeNeighbor(ps);

        if (entry->ping_status == PING_WAITING)
            return;
    } else if (entry->ping_status == PING_WAITING) {
        peerGetSomeNeighborReplies(ps);
        entry->ping_status = PING_DONE;
    }

    switch (ps->direct) {

    case DIRECT_YES:
        peerGetSomeDirect(ps);
        break;

    case DIRECT_NO:
        peerGetSomeParent(ps);
        peerGetAllParents(ps);
        break;

    default:

        if (Config.onoff.prefer_direct)
            peerGetSomeDirect(ps);

        if (request->flags.hierarchical || !Config.onoff.nonhierarchical_direct) {
            peerGetSomeParent(ps);
            peerGetAllParents(ps);
        }

        if (!Config.onoff.prefer_direct)
            peerGetSomeDirect(ps);

        break;
    }

    // resolve the possible peers
    peerSelectDnsPaths(ps);
}


entry is null so peerGetSomeNeighbor is never called :


    if (entry == NULL) {
        (void) 0;
    } else if (entry->ping_status == PING_NONE) {
        peerGetSomeNeighbor(ps);

        if (entry->ping_status == PING_WAITING)
            return;
    } else if (entry->ping_status == PING_WAITING) {
        peerGetSomeNeighborReplies(ps);
        entry->ping_status = PING_DONE;
    }


Because of tunnelStart method :


void
tunnelStart(ClientHttpRequest * http)
{
    debugs(26, 3, HERE);
    /* Create state structure. */
    TunnelStateData *tunnelState = NULL;
    ErrorState *err = NULL;
    HttpRequest *request = http->request;
    char *url = http->uri;

    /*
     * client_addr.isNoAddr()  indicates this is an "internal" request
     * from peer_digest.c, asn.c, netdb.c, etc and should always
     * be allowed.  yuck, I know.
     */

    if (Config.accessList.miss && !request->client_addr.isNoAddr()) {
        /*
         * Check if this host is allowed to fetch MISSES from us (miss_access)
         * default is to allow.
         */
        ACLFilledChecklist ch(Config.accessList.miss, request, NULL);
        ch.al = http->al;
        ch.src_addr = request->client_addr;
        ch.my_addr = request->my_addr;
        ch.syncAle(request, http->log_uri);
        if (ch.fastCheck().denied()) {
            debugs(26, 4, HERE << "MISS access forbidden.");
            err = new ErrorState(ERR_FORWARDING_DENIED, Http::scForbidden, request);
            http->al->http.code = Http::scForbidden;
            errorSend(http->getConn()->clientConnection, err);
            return;
        }
    }

    debugs(26, 3, request->method << ' ' << url << ' ' << request->http_ver);
    ++statCounter.server.all.requests;
    ++statCounter.server.other.requests;

    tunnelState = new TunnelStateData(http);
#if USE_DELAY_POOLS
    //server.setDelayId called from tunnelConnectDone after server side connection established
#endif

    peerSelect(&(tunnelState->serverDestinations), request, http->al,
               NULL,
               tunnelPeerSelectComplete,
               tunnelState);
}


Any ideas ?

Regards,
Th?o BARRAGU?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220926/cccf5fd1/attachment.htm>

From rousskov at measurement-factory.com  Mon Sep 26 13:25:58 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Sep 2022 09:25:58 -0400
Subject: [squid-users] Use ICP RTT with HTTPS request
In-Reply-To: <PAYP264MB412768F98833F4A4878EC042A3529@PAYP264MB4127.FRAP264.PROD.OUTLOOK.COM>
References: <PAYP264MB412768F98833F4A4878EC042A3529@PAYP264MB4127.FRAP264.PROD.OUTLOOK.COM>
Message-ID: <80b149d8-87fc-8055-2314-ef36e10277f0@measurement-factory.com>

On 9/26/22 05:51, Th?o BARRAGUE wrote:

>  entry is null so peerGetSomeNeighbor is never called

I did not check all the details, but it looks like Squid ICMP code 
(ab)uses StoreEntry-linked metadata. Basic CONNECT tunnels lack 
StoreEntry because they are not reading/writing data from/to Store. The 
combination is essentially a Squid bug -- basic CONNECT tunnels cannot 
use ICMP features.

Most likely, the correct long-term solution here is to remove StoreEntry 
use from ICMP code -- I bet that code does not have a genuine need for 
Store access and should store its essential metadata elsewhere. That 
proper solution will require non-trivial development. For a possibly 
simpler workaround, one could consider creating a temporary StoreEntry 
object for ICMP use (instead of disabling ICMP for entry-less use cases).

https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F


HTH,

Alex.

>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(163) peerSelect: CONNECT
>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(472) peerSelectFoo:
>     CONNECT api.gouv.fr
>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(485) peerSelectFoo:
>     peerSelectFoo: direct?= DIRECT_UNKNOWN (never_direct to be checked)
>     2022/09/26 09:07:52.381| 28,3| Checklist.cc(70) preCheck:
>     0x5653abfc4b68 checking slow rules
>     2022/09/26 09:07:52.381| 28,3| Ip.cc(538) match: aclIpMatchIp:
>     '10.25.41.21:34896'?found
>     2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked: all?= 1
>     2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked:
>     never_direct#1 = 1
>     2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked:
>     never_direct?= 1
>     2022/09/26 09:07:52.381| 28,3| Checklist.cc(63) markFinished:
>     0x5653abfc4b68 answer ALLOWED for match
>     2022/09/26 09:07:52.381| 28,3| Checklist.cc(163) checkCallback:
>     ACLChecklist::checkCallback: 0x5653abfc4b68 answer=ALLOWED
>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(195)
>     peerCheckNeverDirectDone: peerCheckNeverDirectDone: ALLOWED
>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(201)
>     peerCheckNeverDirectDone: direct?= DIRECT_NO (never_direct allow)
>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(472) peerSelectFoo:
>     CONNECT api.gouv.fr
>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(712)
>     peerGetSomeParent: CONNECT api.gouv.fr
>     2022/09/26 09:07:52.381| 15,3| neighbors.cc(332)
>     getRoundRobinParent: returning NULL
>     2022/09/26 09:07:52.381| 15,3| neighbors.cc(382)
>     getWeightedRoundRobinParent: getWeightedRoundRobinParent: returning NULL
>     2022/09/26 09:07:52.381| 28,3| Checklist.cc(70) preCheck:
>     0x7ffd6220f030 checking fast rules
>     2022/09/26 09:07:52.381| 28,3| Ip.cc(538) match: aclIpMatchIp:
>     '10.25.41.21:34896'?found
>     2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked: all?= 1
>     2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked:
>     peer_access squid-2.inf-proxy03-d01.dc02#1 = 1
>     2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked:
>     peer_access squid-2.inf-proxy03-d01.dc02?= 1
>     2022/09/26 09:07:52.381| 28,3| Checklist.cc(63) markFinished:
>     0x7ffd6220f030 answer ALLOWED for match
>     2022/09/26 09:07:52.381| 15,3| neighbors.cc(294) getFirstUpParent:
>     getFirstUpParent: returning 10.26.8.10
>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(978) peerAddFwdServer:
>     adding FIRSTUP_PARENT/10.26.8.10
>     2022/09/26 09:07:52.381| 28,3| Checklist.cc(70) preCheck:
>     0x7ffd6220f0d0 checking fast rules
>     2022/09/26 09:07:52.381| 28,3| Ip.cc(538) match: aclIpMatchIp:
>     '10.25.41.21:34896'?found
>     2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked: all?= 1
>     2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked:
>     peer_access squid-2.inf-proxy03-d01.dc02#1 = 1
>     2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked:
>     peer_access squid-2.inf-proxy03-d01.dc02?= 1
>     2022/09/26 09:07:52.382| 28,3| Checklist.cc(63) markFinished:
>     0x7ffd6220f0d0 answer ALLOWED for match
>     2022/09/26 09:07:52.382| 44,3| peer_select.cc(971) peerAddFwdServer:
>     skipping ANY_OLD_PARENT/10.26.8.10; have FIRSTUP_PARENT/10.26.8.10
>     2022/09/26 09:07:52.382| 28,3| Checklist.cc(70) preCheck:
>     0x7ffd6220f0d0 checking fast rules
>     2022/09/26 09:07:52.382| 28,3| Ip.cc(538) match: aclIpMatchIp:
>     '10.25.41.21:34896'?found
>     2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked: all?= 1
>     2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked:
>     peer_access squid-2.inf-proxy03-d01.dc01#1 = 1
>     2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked:
>     peer_access squid-2.inf-proxy03-d01.dc01?= 1
>     2022/09/26 09:07:52.382| 28,3| Checklist.cc(63) markFinished:
>     0x7ffd6220f0d0 answer ALLOWED for match
>     2022/09/26 09:07:52.382| 44,3| peer_select.cc(978) peerAddFwdServer:
>     adding ANY_OLD_PARENT/127.0.0.1
>     2022/09/26 09:07:52.382| 15,3| neighbors.cc(472) getDefaultParent:
>     getDefaultParent: returning NULL
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(295)
>     peerSelectDnsPaths: Find IP destination for: api.gouv.fr:443' via
>     10.26.8.10
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(295)
>     peerSelectDnsPaths: Find IP destination for: api.gouv.fr:443'?via
>     127.0.0.1
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(316)
>     peerSelectDnsPaths: Found sources for 'api.gouv.fr:443'
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(317)
>     peerSelectDnsPaths: always_direct?= DENIED
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(318)
>     peerSelectDnsPaths: never_direct?= ALLOWED
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(328)
>     peerSelectDnsPaths: cache_peer?= local=0.0.0.0
>     remote=10.26.8.10:3129 flags=1
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(328)
>     peerSelectDnsPaths: cache_peer?= local=0.0.0.0 remote=127.0.0.1:3129
>     flags=1
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(331)
>     peerSelectDnsPaths: timedout?= 0
>     2022/09/26 09:07:52.382| 26,3| tunnel.cc(1249)
>     tunnelPeerSelectComplete: paths=2, p[0]={local=0.0.0.0
>     remote=10.26.8.10:3129 flags=1}, serverDest[0]={local=0.0.0.0
>     remote=10.26.8.10:3129 flags=1}
>     2022/09/26 09:07:52.382| 17,3| FwdState.cc(1369)
>     GetMarkingsToServer: from 0.0.0.0 netfilter mark 0
>     2022/09/26 09:07:52.382| 26,3| AsyncCall.cc(25) AsyncCall: The
>     AsyncCall tunnelConnectDone constructed, this=0x5653abf924a0 [call164]
>     2022/09/26 09:07:52.382| 5,3| ConnOpener.cc(43) ConnOpener: will
>     connect to local=0.0.0.0 remote=10.26.8.10:3129 flags=1 with 30 timeout
>     2022/09/26 09:07:52.382| 50,3| comm.cc(350) comm_openex:
>     comm_openex: Attempt open socket for: 0.0.0.0
>     2022/09/26 09:07:52.382| 50,3| comm.cc(393) comm_openex:
>     comm_openex: Opened socket local=0.0.0.0 remote=[::] FD 14 flags=1 :
>     family=2, type=1, protocol=6
>     2022/09/26 09:07:52.382| 51,3| fd.cc(198) fd_open: fd_open() FD 14
>     api.gouv.fr:443
>     2022/09/26 09:07:52.382| 5,3| ConnOpener.cc(291) createFd:
>     local=0.0.0.0 remote=10.26.8.10:3129 flags=1 will timeout in 30
>     2022/09/26 09:07:52.393| 26,3| AsyncCall.cc(92) ScheduleCall:
>     ConnOpener.cc(139) will call
>     tunnelConnectDone(local=10.25.8.10:58500 remote=10.26.8.10:3129 FD
>     14 flags=1, data=0x5653abfa3598) [call164]
>     2022/09/26 09:07:52.393| 26,3| AsyncCallQueue.cc(55) fireNext:
>     entering tunnelConnectDone(local=10.25.8.10:58500
>     remote=10.26.8.10:3129 FD 14 flags=1, data=0x5653abfa3598)
>     2022/09/26 09:07:52.393| 26,3| AsyncCall.cc(37) make: make call
>     tunnelConnectDone [call164]
>     2022/09/26 09:07:52.393| 14,3| Address.cc(382) lookupHostIP: Given
>     Non-IP 'api.gouv.fr': Name or service not known
>     2022/09/26 09:07:52.393| 38,3| net_db.cc(355) netdbSendPing:
>     netdbSendPing: pinging api.gouv.fr
>     2022/09/26 09:07:52.393| 37,2| IcmpSquid.cc(59) SendEcho: ?Socket
>     Closed. Aborted send to 10.26.8.10, opcode 3, len 10
>     2022/09/26 09:07:52.393| 26,3| tunnel.cc(1163)
>     tunnelRelayConnectRequest: local=10.25.8.10:58500
>     remote=10.26.8.10:3129 FD 14 flags=1, tunnelState=0x5653abfa3598
>     2022/09/26 09:07:52.393| 22,3| refresh.cc(648) getMaxAge: getMaxAge:
>     'api.gouv.fr:443'
>     2022/09/26 09:07:52.393| 11,2| tunnel.cc(1177)
>     tunnelRelayConnectRequest: Tunnel Server REQUEST:
>     local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1:
>     ----------
>     CONNECT api.gouv.fr:443 HTTP/1.1
>     User-Agent: curl/7.52.1
>     Host: api.gouv.fr:443
>     X-Forwarded-For: unknown
>     Cache-Control: max-age=259200
>     Connection: close
> 
> 
>     ----------
>     2022/09/26 09:07:52.393| 5,3| comm.cc(559) commSetConnTimeout:
>     local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1 timeout 900
>     2022/09/26 09:07:52.393| 5,3| comm.cc(559) commSetConnTimeout:
>     local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1 timeout 900
>     2022/09/26 09:07:52.393| 26,3| AsyncCallQueue.cc(57) fireNext:
>     leaving tunnelConnectDone(local=10.25.8.10:58500
>     remote=10.26.8.10:3129 FD 14 flags=1, data=0x5653abfa3598)
>     2022/09/26 09:07:52.393| 5,3| IoCallback.cc(116) finish: called for
>     local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1 (0, 0)
>     2022/09/26 09:07:52.393| 26,3| tunnel.cc(929)
>     tunnelConnectReqWriteDone: local=10.25.8.10:58500
>     remote=10.26.8.10:3129 FD 14 flags=1, flag=0
> 
> 
> It seems /peerGetSomeParent/ is called and this method never issue an ICP :
> 
> 
>     staticvoid
>     peerGetSomeParent(ps_state * ps)
>     {
>      ? ? CachePeer *p;
>      ? ? HttpRequest *request = ps->request;
>      ? ? hier_code code = HIER_NONE;
>     debugs(44, 3, request->method?<< ' '?<< request->url.host());
>     if?(ps->direct?== DIRECT_YES)
>     return;
>     if?((p = peerSourceHashSelectParent(request))) {
>      ? ? ? ? code = SOURCEHASH_PARENT;
>     #if?USE_AUTH
>      ? ? } elseif?((p = peerUserHashSelectParent(request))) {
>      ? ? ? ? code = USERHASH_PARENT;
>     #endif
>      ? ? } elseif?((p = carpSelectParent(request))) {
>      ? ? ? ? code = CARP;
>      ? ? } elseif?((p = getRoundRobinParent(request))) {
>      ? ? ? ? code = ROUNDROBIN_PARENT;
>      ? ? } elseif?((p = getWeightedRoundRobinParent(request))) {
>      ? ? ? ? code = ROUNDROBIN_PARENT;
>      ? ? } elseif?((p = getFirstUpParent(request))) {
>      ? ? ? ? code = FIRSTUP_PARENT;
>      ? ? } elseif?((p = getDefaultParent(request))) {
>      ? ? ? ? code = DEFAULT_PARENT;
>      ? ? }
> 
>     if?(code != HIER_NONE) {
>     peerAddFwdServer(ps, p, code);
>      ? ? }
>     }
> 
> 
> Instead of /peerGetSomeNeighbor/ :
> 
> 
>     /**
>      ?* peerGetSomeNeighbor
>      ?*
>      ?* Selects a neighbor (parent or sibling) based on one of the
>      ?* following methods:
>      ?* ? ? ?Cache Digests
>      ?* ? ? ?CARP
>      ?* ? ? ?ICMP Netdb RTT estimates
>      ?* ? ? ?ICP/HTCP queries
>      ?*/
>     staticvoid
>     peerGetSomeNeighbor(ps_state * ps)
>     {
>      ? ? StoreEntry *entry = ps->entry;
>      ? ? HttpRequest *request = ps->request;
>      ? ? CachePeer *p;
>      ? ? hier_code code = HIER_NONE;
>     assert(entry->ping_status?== PING_NONE);
> 
>     if?(ps->direct?== DIRECT_YES) {
>     entry->ping_status?= PING_DONE;
>     return;
>      ? ? }
> 
>     #if?USE_CACHE_DIGESTS
>     if?((p = neighborsDigestSelect(request))) {
>     if?(neighborType(p, request->url) == PEER_PARENT)
>      ? ? ? ? ? ? code = CD_PARENT_HIT;
>     else
>      ? ? ? ? ? ? code = CD_SIBLING_HIT;
>      ? ? } else
>     #endif
>     if?((p = netdbClosestParent(request))) {
>      ? ? ? ? ? ? code = CLOSEST_PARENT;
>      ? ? ? ? } elseif?(peerSelectIcpPing(request, ps->direct, entry)) {
>     debugs(44, 3, "peerSelect: Doing ICP pings");
>     ps->ping.start?= current_time;
>     ps->ping.n_sent?= neighborsUdpPing(request,
>      ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?entry,
>      ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?peerHandlePingReply,
>      ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?ps,
>                                                   
>      ?&ps->ping.n_replies_expected,
>      ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?&ps->ping.timeout);
> 
>     if?(ps->ping.n_sent?== 0)
>     debugs(44, DBG_CRITICAL, "WARNING: neighborsUdpPing returned 0");
>     debugs(44, 3, "peerSelect: "?<< ps->ping.n_replies_expected?<<
>     " ICP replies expected, RTT "?<< ps->ping.timeout?<<
>     " msec");
> 
>     if?(ps->ping.n_replies_expected?> 0) {
>     entry->ping_status?= PING_WAITING;
>     eventAdd("peerPingTimeout",
>      ? ? ? ? ? ? ? ? ? ? ? ? ?peerPingTimeout,
>      ? ? ? ? ? ? ? ? ? ? ? ? ?ps,
>     0.001?* ps->ping.timeout,
>     0);
>     return;
>      ? ? ? ? ? ? }
>      ? ? ? ? }
> 
>     if?(code != HIER_NONE) {
>     assert(p);
>     peerAddFwdServer(ps, p, code);
>      ? ? }
> 
>     entry->ping_status?= PING_DONE;
>     }
> 
> 
> These functions are called from /peerSelectFoo/?:
> 
> 
>     staticvoid
>     peerSelectFoo(ps_state * ps)
>     {
>     if?(!cbdataReferenceValid(ps->callback_data)) {
>     debugs(44, 3, "Aborting peer selection. Parent Job went away.");
>     delete?ps;
>     return;
>      ? ? }
>      ? ? StoreEntry *entry = ps->entry;
>      ? ? HttpRequest *request = ps->request;
>     debugs(44, 3, request->method?<< ' '?<< request->url.host());
>      ? ? /** If we don't know whether DIRECT is permitted ... */
>     if?(ps->direct?== DIRECT_UNKNOWN) {
>     if?(ps->always_direct?== ACCESS_DUNNO) {
>     debugs(44, 3, "peerSelectFoo: direct = "?<< DirectStr[ps->direct] <<
>     " (always_direct to be checked)");
>      ? ? ? ? ? ? /** check always_direct; */
>      ? ? ? ? ? ? ACLFilledChecklist *ch =
>     newACLFilledChecklist(Config.accessList.AlwaysDirect, request, NULL);
>     ch->al?= ps->al;
>     ps->acl_checklist?= ch;
>     ps->acl_checklist->nonBlockingCheck(peerCheckAlwaysDirectDone, ps);
>     return;
>      ? ? ? ? } elseif?(ps->never_direct?== ACCESS_DUNNO) {
>     debugs(44, 3, "peerSelectFoo: direct = "?<< DirectStr[ps->direct] <<
>     " (never_direct to be checked)");
>      ? ? ? ? ? ? /** check never_direct; */
>      ? ? ? ? ? ? ACLFilledChecklist *ch =
>     newACLFilledChecklist(Config.accessList.NeverDirect, request, NULL);
>     ch->al?= ps->al;
>     ps->acl_checklist?= ch;
>     ps->acl_checklist->nonBlockingCheck(peerCheckNeverDirectDone, ps);
>     return;
>      ? ? ? ? } elseif?(request->flags.noDirect) {
>      ? ? ? ? ? ? /** if we are accelerating, direct is not an option. */
>     ps->direct?= DIRECT_NO;
>     debugs(44, 3, "peerSelectFoo: direct = "?<< DirectStr[ps->direct] <<
>     " (forced non-direct)");
>      ? ? ? ? } elseif?(request->flags.loopDetected) {
>      ? ? ? ? ? ? /** if we are in a forwarding-loop, direct is not an
>     option. */
>     ps->direct?= DIRECT_YES;
>     debugs(44, 3, "peerSelectFoo: direct = "?<< DirectStr[ps->direct] <<
>     " (forwarding loop detected)");
>      ? ? ? ? } elseif?(peerCheckNetdbDirect(ps)) {
>     ps->direct?= DIRECT_YES;
>     debugs(44, 3, "peerSelectFoo: direct = "?<< DirectStr[ps->direct] <<
>     " (checkNetdbDirect)");
>      ? ? ? ? } else?{
>     ps->direct?= DIRECT_MAYBE;
>     debugs(44, 3, "peerSelectFoo: direct = "?<< DirectStr[ps->direct] <<
>     " (default)");
>      ? ? ? ? }
> 
>     debugs(44, 3, "peerSelectFoo: direct = "?<< DirectStr[ps->direct]);
>      ? ? }
> 
>     if?(!entry || entry->ping_status?== PING_NONE)
>     peerSelectPinned(ps);
>     if?(entry == NULL) {
>      ? ? ? ? (void) 0;
>      ? ? } elseif?(entry->ping_status?== PING_NONE) {
>     peerGetSomeNeighbor(ps);
> 
>     if?(entry->ping_status?== PING_WAITING)
>     return;
>      ? ? } elseif?(entry->ping_status?== PING_WAITING) {
>     peerGetSomeNeighborReplies(ps);
>     entry->ping_status?= PING_DONE;
>      ? ? }
> 
>     switch?(ps->direct) {
> 
>     case?DIRECT_YES:
>     peerGetSomeDirect(ps);
>     break;
> 
>     case?DIRECT_NO:
>     peerGetSomeParent(ps);
>     peerGetAllParents(ps);
>     break;
> 
>     default:
> 
>     if?(Config.onoff.prefer_direct)
>     peerGetSomeDirect(ps);
> 
>     if?(request->flags.hierarchical?||
>     !Config.onoff.nonhierarchical_direct) {
>     peerGetSomeParent(ps);
>     peerGetAllParents(ps);
>      ? ? ? ? }
> 
>     if?(!Config.onoff.prefer_direct)
>     peerGetSomeDirect(ps);
> 
>     break;
>      ? ? }
> 
>      ? ? // resolve the possible peers
>     peerSelectDnsPaths(ps);
>     }
> 
> 
> /entry/ is /null/?so /peerGetSomeNeighbor/?is never called :
> 
> if?(entry == NULL) {
>  ? ? ? ? (void) 0;
>  ? ? } elseif?(entry->ping_status?== PING_NONE) {
> peerGetSomeNeighbor(ps);
> 
> if?(entry->ping_status?== PING_WAITING)
> return;
>  ? ? } elseif?(entry->ping_status?== PING_WAITING) {
> peerGetSomeNeighborReplies(ps);
> entry->ping_status?= PING_DONE;
>  ? ? }
> 
> 
> Because of /tunnelStart/?method :
> 
> 
>     void
>     tunnelStart(ClientHttpRequest * http)
>     {
>     debugs(26, 3, HERE);
>      ? ? /* Create state structure. */
>      ? ? TunnelStateData *tunnelState = NULL;
>      ? ? ErrorState *err = NULL;
>      ? ? HttpRequest *request = http->request;
>     char?*url = http->uri;
> 
>      ? ? /*
>      ? ? ?* client_addr.isNoAddr() ?indicates this is an "internal" request
>      ? ? ?* from peer_digest.c, asn.c, netdb.c, etc and should always
>      ? ? ?* be allowed. ?yuck, I know.
>      ? ? ?*/
> 
>     if?(Config.accessList.miss?&& !request->client_addr.isNoAddr()) {
>      ? ? ? ? /*
>      ? ? ? ? ?* Check if this host is allowed to fetch MISSES from us
>     (miss_access)
>      ? ? ? ? ?* default is to allow.
>      ? ? ? ? ?*/
>      ? ? ? ? ACLFilledChecklist ch(Config.accessList.miss, request, NULL);
>     ch.al?= http->al;
>     ch.src_addr?= request->client_addr;
>     ch.my_addr?= request->my_addr;
>     ch.syncAle(request, http->log_uri);
>     if?(ch.fastCheck().denied()) {
>     debugs(26, 4, HERE << "MISS access forbidden.");
>      ? ? ? ? ? ? err = newErrorState(ERR_FORWARDING_DENIED,
>     Http::scForbidden, request);
>     http->al->http.code?= Http::scForbidden;
>     errorSend(http->getConn()->clientConnection, err);
>     return;
>      ? ? ? ? }
>      ? ? }
>     debugs(26, 3, request->method?<< ' '?<< url << ' '?<<
>     request->http_ver);
>      ? ? ++statCounter.server.all.requests;
>      ? ? ++statCounter.server.other.requests;
> 
>      ? ? tunnelState = newTunnelStateData(http);
>     #if?USE_DELAY_POOLS
>      ? ? //server.setDelayId called from tunnelConnectDone after server
>     side connection established
>     #endif
> 
>     peerSelect(&(tunnelState->serverDestinations), request, http->al,
>     NULL,
>      ? ? ? ? ? ? ? ?tunnelPeerSelectComplete,
>      ? ? ? ? ? ? ? ?tunnelState);
>     }
> 
> 
> Any ideas ?
> 
> Regards,
> Th?o BARRAGU?



From andy.armstrong at uk.ibm.com  Mon Sep 26 19:27:03 2022
From: andy.armstrong at uk.ibm.com (Andy Armstrong)
Date: Mon, 26 Sep 2022 19:27:03 +0000
Subject: [squid-users] TCP_MISS only
Message-ID: <SA0PR15MB375725E2BCE8978659B9BE0CB2529@SA0PR15MB3757.namprd15.prod.outlook.com>

Hi all,

I am trying to use Squid Cache for the first time. My aim ? is that for any HTTP response from 192.168.0.2:3001 is cached and served from the cache.

My config is as follows:

http_port 3128

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 1025-65535  # unregistered ports

acl CONNECT method CONNECT

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager

http_access allow localnet
http_access allow localhost
http_access deny all

coredump_dir /squid/var/cache/squid

cache_dir ufs /var/spool/squid 1024 16 256

refresh_pattern -i http:\/\/192.168.0.2:3001\/.* 10080 100% 43200  override-lastmod
refresh_pattern ^ftp:                      1440      20%        10080
refresh_pattern ^gopher:             1440      0%          1440
refresh_pattern -i (/cgi-bin/|\?) 0             0%          0
refresh_pattern .                              0              20%        4320


The problem I am finding is that each time my client makes a call via the proxy, I see this in the logs:


1664219486.836  10098 10.1.1.70 TCP_MISS/201 492 POST http://192.168.0.2:3001/InternalCommunicationServices/message/email - HIER_DIRECT/192.168.0.2 application/json

I see the ?TCP_MISS?,  the client receives the response from the remote server, but on subsequent calls, it continues to trigger TCP_MISS and I never manage to cache the response.

Please help me understand what I am missing from the configuration for my intended use case.

Kind regards,

Andy Armstrong
?? ?????
Principal Specialist for Z Technologies
EMEA Squad Leader for Hybrid Cloud
Worldwide Community Leader for Hybrid Cloud
Member of the CTO Office Server & Storage EMEA
Distinguished Technical Specialist ? The Open Group
IBM Master Inventor

Mobile: +447500103874



Unless otherwise stated above:

IBM United Kingdom Limited
Registered in England and Wales with number 741598
Registered office: PO Box 41, North Harbour, Portsmouth, Hants. PO6 3AU
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220926/68111b2e/attachment.htm>

From rousskov at measurement-factory.com  Mon Sep 26 20:07:09 2022
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Sep 2022 16:07:09 -0400
Subject: [squid-users] TCP_MISS only
In-Reply-To: <SA0PR15MB375725E2BCE8978659B9BE0CB2529@SA0PR15MB3757.namprd15.prod.outlook.com>
References: <SA0PR15MB375725E2BCE8978659B9BE0CB2529@SA0PR15MB3757.namprd15.prod.outlook.com>
Message-ID: <da33fd71-420c-cc4a-47e9-e057626d4e4f@measurement-factory.com>

On 9/26/22 15:27, Andy Armstrong wrote:

> My aim ? is that for any HTTP response from 192.168.0.2:3001 is
> cached and served from the cache.

> 1664219486.83610098 10.1.1.70 TCP_MISS/201 492 POST 
> http://192.168.0.2:3001/InternalCommunicationServices/message/email - 
> HIER_DIRECT/192.168.0.2 application/json

Squid does not cache responses with HTTP status code 201 (Created). Per 
HTTP protocol, such responses are not cachable "by default" and Squid is 
not smart enough to check whether a particular 201 response has headers 
that would allow Squid to overwrite that default. The specific response 
in question probably does not have those headers, but I am mentioning 
them here for completeness sake.

Furthermore, a "Created" response to a POST request probably does not 
contain anything you would want to cache -- things will probably break 
if that "create something" POST request is satisfied from the cache the 
next time around. You may need to study the HTTP server in question and 
adjust your goals from "cache any 192.168.0.2:3001 response" to 
something more nuanced, based on what that server does.


HTH,

Alex.




> My config is as follows:
> 
> http_port 3128
> 
> acl localnet src 10.0.0.0/8???? # RFC1918 possible internal network
> 
> acl localnet src 172.16.0.0/12? # RFC1918 possible internal network
> 
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> 
> acl localnet src fc00::/7?????? # RFC 4193 local private network range
> 
> acl localnet src fe80::/10????? # RFC 4291 link-local (directly plugged) 
> machines
> 
> acl SSL_ports port 443
> 
> acl Safe_ports port 80????????? # http
> 
> acl Safe_ports port 21????????? # ftp
> 
> acl Safe_ports port 443???????? # https
> 
> acl Safe_ports port 70????????? # gopher
> 
> acl Safe_ports port 210???????? # wais
> 
> acl Safe_ports port 280???????? # http-mgmt
> 
> acl Safe_ports port 488???????? # gss-http
> 
> acl Safe_ports port 591???????? # filemaker
> 
> acl Safe_ports port 777???????? # multiling http
> 
> acl Safe_ports port 1025-65535? # unregistered ports
> 
> acl CONNECT method CONNECT
> 
> http_access deny !Safe_ports
> 
> http_access deny CONNECT !SSL_ports
> 
> http_access allow localhost manager
> 
> http_access deny manager
> 
> http_access allow localnet
> 
> http_access allow localhost
> 
> http_access deny all
> 
> coredump_dir /squid/var/cache/squid
> 
> cache_dir ufs /var/spool/squid 1024 16 256
> 
> refresh_pattern -i http:\/\/192.168.0.2:3001\/.* 10080 100% 43200  
> override-lastmod
> 
> refresh_pattern ^ftp:????????????????????? 1440????? 20%??????? 10080
> 
> refresh_pattern ^gopher:???????????? 1440????? 0%????????? 1440
> 
> refresh_pattern -i (/cgi-bin/|\?) 0???????????? 0%????????? 0
> 
> refresh_pattern .????????????????????????????? 0????????????? 20%        
> 4320
> 
> The problem I am finding is that each time my client makes a call via 
> the proxy, I see this in the logs:
> 
> 1664219486.83610098 10.1.1.70 TCP_MISS/201 492 POST 
> http://192.168.0.2:3001/InternalCommunicationServices/message/email - 
> HIER_DIRECT/192.168.0.2 application/json
> 
> I see the ?TCP_MISS?, ?the client receives the response from the remote 
> server, but on subsequent calls, it continues to trigger TCP_MISS and I 
> never manage to cache the response.
> 
> Please help me understand what I am missing from the configuration for 
> my intended use case.
> 
> Kind regards,
> 
> Andy Armstrong
> 
> ???????
> 
> Principal Specialist for Z Technologies
> 
> EMEA Squad Leader for Hybrid Cloud
> 
> Worldwide Community Leader for Hybrid Cloud
> 
> Member of the CTO Office Server & Storage EMEA
> 
> Distinguished Technical Specialist ? The Open Group
> 
> IBM Master Inventor
> 
> 
> Mobile: +447500103874
> 
> Unless otherwise stated above:
> 
> IBM United Kingdom Limited
> Registered in England and Wales with number 741598
> Registered office: PO Box 41, North Harbour, Portsmouth, Hants. PO6 3AU
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From marcelorodrigo at graminsta.com.br  Tue Sep 27 04:27:43 2022
From: marcelorodrigo at graminsta.com.br (Marcelo)
Date: Tue, 27 Sep 2022 01:27:43 -0300
Subject: [squid-users] Prevent squid user to go out through server's IP
Message-ID: <003a01d8d229$7ed5c2e0$7c8148a0$@graminsta.com.br>

Hi,

 

Even after Squid fulfill ACLs and Cache Peer rules, the client connection
keeps going out through squid server's IP.

How can I prevent it to happen?

 

For instance, some rule ends with a IPv6 address on tcp_outgoing_address,
but when a proxy client connects, he can see this IPv6 address plus the
squid server IPv4 address in a ipleak.net and other kinds of proxy detect
website.

 

How can I create a rule to say in squid.conf that is forbidden to going out
through server's IP?

 

Thanks.

 

Marcelo Rodrigo

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220927/a587411e/attachment.htm>

From andy.armstrong at uk.ibm.com  Tue Sep 27 10:01:24 2022
From: andy.armstrong at uk.ibm.com (Andy Armstrong)
Date: Tue, 27 Sep 2022 10:01:24 +0000
Subject: [squid-users] TCP_MISS only
In-Reply-To: <da33fd71-420c-cc4a-47e9-e057626d4e4f@measurement-factory.com>
References: <SA0PR15MB375725E2BCE8978659B9BE0CB2529@SA0PR15MB3757.namprd15.prod.outlook.com>
 <da33fd71-420c-cc4a-47e9-e057626d4e4f@measurement-factory.com>
Message-ID: <SA0PR15MB3757DD79FA92D3C545F26938B2559@SA0PR15MB3757.namprd15.prod.outlook.com>

Hi Alex,

That makes a lot of sense, I don?t know how I overlooked that ? thank you. I also agree, logically caching a 201 response makes little sense, and it was just an example I had that was easy to try so I used that.

I just altered the HTTP Return code so it sent 200 instead of 201, and the result is sadly the same, I get many, many lines like this:


1664272638.443  10107 10.1.1.70 TCP_MISS/200 275 POST http://192.168.0.2:3001/InternalCommunicationServices/message/email - HIER_DIRECT/192.168.0.2 application/json

My suspicion is still that my refresh_pattern is wrong:

refresh_pattern -i http:\/\/129.168.0.2:3001\/.* 10080 100% 43200 override-lastmod

Kind regards,

Andy Armstrong
?? ?????
Principal Specialist for Z Technologies
EMEA Squad Leader for Hybrid Cloud
Worldwide Community Leader for Hybrid Cloud
Member of the CTO Office Server & Storage EMEA
Distinguished Technical Specialist ? The Open Group
IBM Master Inventor

Mobile: +447500103874



From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Alex Rousskov <rousskov at measurement-factory.com>
Date: Monday, 26 September 2022 at 21:07
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: [EXTERNAL] Re: [squid-users] TCP_MISS only
On 9/26/22 15:27, Andy Armstrong wrote:

> My aim ? is that for any HTTP response from 192.168.0.2:3001 is
> cached and served from the cache.

> 1664219486.83610098 10.1.1.70 TCP_MISS/201 492 POST
> http://192.168.0.2:3001/InternalCommunicationServices/message/email   -
> HIER_DIRECT/192.168.0.2 application/json

Squid does not cache responses with HTTP status code 201 (Created). Per
HTTP protocol, such responses are not cachable "by default" and Squid is
not smart enough to check whether a particular 201 response has headers
that would allow Squid to overwrite that default. The specific response
in question probably does not have those headers, but I am mentioning
them here for completeness sake.

Furthermore, a "Created" response to a POST request probably does not
contain anything you would want to cache -- things will probably break
if that "create something" POST request is satisfied from the cache the
next time around. You may need to study the HTTP server in question and
adjust your goals from "cache any 192.168.0.2:3001 response" to
something more nuanced, based on what that server does.


HTH,

Alex.




> My config is as follows:
>
> http_port 3128
>
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
>
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
>
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
>
> acl localnet src fc00::/7       # RFC 4193 local private network range
>
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
> machines
>
> acl SSL_ports port 443
>
> acl Safe_ports port 80          # http
>
> acl Safe_ports port 21          # ftp
>
> acl Safe_ports port 443         # https
>
> acl Safe_ports port 70          # gopher
>
> acl Safe_ports port 210         # wais
>
> acl Safe_ports port 280         # http-mgmt
>
> acl Safe_ports port 488         # gss-http
>
> acl Safe_ports port 591         # filemaker
>
> acl Safe_ports port 777         # multiling http
>
> acl Safe_ports port 1025-65535  # unregistered ports
>
> acl CONNECT method CONNECT
>
> http_access deny !Safe_ports
>
> http_access deny CONNECT !SSL_ports
>
> http_access allow localhost manager
>
> http_access deny manager
>
> http_access allow localnet
>
> http_access allow localhost
>
> http_access deny all
>
> coredump_dir /squid/var/cache/squid
>
> cache_dir ufs /var/spool/squid 1024 16 256
>
> refresh_pattern -i http://192.168.0.2:3001%5C/.*   10080 100% 43200
> override-lastmod
>
> refresh_pattern ^ftp:                      1440      20%        10080
>
> refresh_pattern ^gopher:             1440      0%          1440
>
> refresh_pattern -i (/cgi-bin/|\?) 0             0%          0
>
> refresh_pattern .                              0              20%
> 4320
>
> The problem I am finding is that each time my client makes a call via
> the proxy, I see this in the logs:
>
> 1664219486.83610098 10.1.1.70 TCP_MISS/201 492 POST
> http://192.168.0.2:3001/InternalCommunicationServices/message/email   -
> HIER_DIRECT/192.168.0.2 application/json
>
> I see the ?TCP_MISS?,  the client receives the response from the remote
> server, but on subsequent calls, it continues to trigger TCP_MISS and I
> never manage to cache the response.
>
> Please help me understand what I am missing from the configuration for
> my intended use case.
>
> Kind regards,
>
> Andy Armstrong
>
> ???????
>
> Principal Specialist for Z Technologies
>
> EMEA Squad Leader for Hybrid Cloud
>
> Worldwide Community Leader for Hybrid Cloud
>
> Member of the CTO Office Server & Storage EMEA
>
> Distinguished Technical Specialist ? The Open Group
>
> IBM Master Inventor
>
>
> Mobile: +447500103874
>
> Unless otherwise stated above:
>
> IBM United Kingdom Limited
> Registered in England and Wales with number 741598
> Registered office: PO Box 41, North Harbour, Portsmouth, Hants. PO6 3AU
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

Unless otherwise stated above:

IBM United Kingdom Limited
Registered in England and Wales with number 741598
Registered office: PO Box 41, North Harbour, Portsmouth, Hants. PO6 3AU
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220927/91e5f3fd/attachment.htm>

From Theo.BARRAGUE.ext at boursorama.fr  Tue Sep 27 11:38:22 2022
From: Theo.BARRAGUE.ext at boursorama.fr (=?utf-8?B?VGjDqW8gQkFSUkFHVUU=?=)
Date: Tue, 27 Sep 2022 11:38:22 +0000
Subject: [squid-users] Use ICP RTT with HTTPS request
In-Reply-To: <80b149d8-87fc-8055-2314-ef36e10277f0@measurement-factory.com>
References: <PAYP264MB412768F98833F4A4878EC042A3529@PAYP264MB4127.FRAP264.PROD.OUTLOOK.COM>
 <80b149d8-87fc-8055-2314-ef36e10277f0@measurement-factory.com>
Message-ID: <PAYP264MB4127A3E55A31C4D5305CCFCAA3559@PAYP264MB4127.FRAP264.PROD.OUTLOOK.COM>

I will take a look, thank's for help ?

Regards,
Th?o BARRAGU?

________________________________
From: Alex Rousskov <rousskov at measurement-factory.com>
Sent: Monday, September 26, 2022 3:25 PM
To: Th?o BARRAGUE <Theo.BARRAGUE.ext at boursorama.fr>; squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Cc: Olivier HANESSE <Olivier.HANESSE at boursorama.fr>
Subject: Re: [squid-users] Use ICP RTT with HTTPS request

On 9/26/22 05:51, Th?o BARRAGUE wrote:

>  entry is null so peerGetSomeNeighbor is never called

I did not check all the details, but it looks like Squid ICMP code
(ab)uses StoreEntry-linked metadata. Basic CONNECT tunnels lack
StoreEntry because they are not reading/writing data from/to Store. The
combination is essentially a Squid bug -- basic CONNECT tunnels cannot
use ICMP features.

Most likely, the correct long-term solution here is to remove StoreEntry
use from ICMP code -- I bet that code does not have a genuine need for
Store access and should store its essential metadata elsewhere. That
proper solution will require non-trivial development. For a possibly
simpler workaround, one could consider creating a temporary StoreEntry
object for ICMP use (instead of disabling ICMP for entry-less use cases).

https://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F


HTH,

Alex.

>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(163) peerSelect: CONNECT
>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(472) peerSelectFoo:
>     CONNECT api.gouv.fr
>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(485) peerSelectFoo:
>     peerSelectFoo: direct = DIRECT_UNKNOWN (never_direct to be checked)
>     2022/09/26 09:07:52.381| 28,3| Checklist.cc(70) preCheck:
>     0x5653abfc4b68 checking slow rules
>     2022/09/26 09:07:52.381| 28,3| Ip.cc(538) match: aclIpMatchIp:
>     '10.25.41.21:34896' found
>     2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked: all = 1
>     2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked:
>     never_direct#1 = 1
>     2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked:
>     never_direct = 1
>     2022/09/26 09:07:52.381| 28,3| Checklist.cc(63) markFinished:
>     0x5653abfc4b68 answer ALLOWED for match
>     2022/09/26 09:07:52.381| 28,3| Checklist.cc(163) checkCallback:
>     ACLChecklist::checkCallback: 0x5653abfc4b68 answer=ALLOWED
>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(195)
>     peerCheckNeverDirectDone: peerCheckNeverDirectDone: ALLOWED
>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(201)
>     peerCheckNeverDirectDone: direct = DIRECT_NO (never_direct allow)
>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(472) peerSelectFoo:
>     CONNECT api.gouv.fr
>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(712)
>     peerGetSomeParent: CONNECT api.gouv.fr
>     2022/09/26 09:07:52.381| 15,3| neighbors.cc(332)
>     getRoundRobinParent: returning NULL
>     2022/09/26 09:07:52.381| 15,3| neighbors.cc(382)
>     getWeightedRoundRobinParent: getWeightedRoundRobinParent: returning NULL
>     2022/09/26 09:07:52.381| 28,3| Checklist.cc(70) preCheck:
>     0x7ffd6220f030 checking fast rules
>     2022/09/26 09:07:52.381| 28,3| Ip.cc(538) match: aclIpMatchIp:
>     '10.25.41.21:34896' found
>     2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked: all = 1
>     2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked:
>     peer_access squid-2.inf-proxy03-d01.dc02#1 = 1
>     2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked:
>     peer_access squid-2.inf-proxy03-d01.dc02 = 1
>     2022/09/26 09:07:52.381| 28,3| Checklist.cc(63) markFinished:
>     0x7ffd6220f030 answer ALLOWED for match
>     2022/09/26 09:07:52.381| 15,3| neighbors.cc(294) getFirstUpParent:
>     getFirstUpParent: returning 10.26.8.10
>     2022/09/26 09:07:52.381| 44,3| peer_select.cc(978) peerAddFwdServer:
>     adding FIRSTUP_PARENT/10.26.8.10
>     2022/09/26 09:07:52.381| 28,3| Checklist.cc(70) preCheck:
>     0x7ffd6220f0d0 checking fast rules
>     2022/09/26 09:07:52.381| 28,3| Ip.cc(538) match: aclIpMatchIp:
>     '10.25.41.21:34896' found
>     2022/09/26 09:07:52.381| 28,3| Acl.cc(151) matches: checked: all = 1
>     2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked:
>     peer_access squid-2.inf-proxy03-d01.dc02#1 = 1
>     2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked:
>     peer_access squid-2.inf-proxy03-d01.dc02 = 1
>     2022/09/26 09:07:52.382| 28,3| Checklist.cc(63) markFinished:
>     0x7ffd6220f0d0 answer ALLOWED for match
>     2022/09/26 09:07:52.382| 44,3| peer_select.cc(971) peerAddFwdServer:
>     skipping ANY_OLD_PARENT/10.26.8.10; have FIRSTUP_PARENT/10.26.8.10
>     2022/09/26 09:07:52.382| 28,3| Checklist.cc(70) preCheck:
>     0x7ffd6220f0d0 checking fast rules
>     2022/09/26 09:07:52.382| 28,3| Ip.cc(538) match: aclIpMatchIp:
>     '10.25.41.21:34896' found
>     2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked: all = 1
>     2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked:
>     peer_access squid-2.inf-proxy03-d01.dc01#1 = 1
>     2022/09/26 09:07:52.382| 28,3| Acl.cc(151) matches: checked:
>     peer_access squid-2.inf-proxy03-d01.dc01 = 1
>     2022/09/26 09:07:52.382| 28,3| Checklist.cc(63) markFinished:
>     0x7ffd6220f0d0 answer ALLOWED for match
>     2022/09/26 09:07:52.382| 44,3| peer_select.cc(978) peerAddFwdServer:
>     adding ANY_OLD_PARENT/127.0.0.1
>     2022/09/26 09:07:52.382| 15,3| neighbors.cc(472) getDefaultParent:
>     getDefaultParent: returning NULL
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(295)
>     peerSelectDnsPaths: Find IP destination for: api.gouv.fr:443' via
>     10.26.8.10
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(295)
>     peerSelectDnsPaths: Find IP destination for: api.gouv.fr:443' via
>     127.0.0.1
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(316)
>     peerSelectDnsPaths: Found sources for 'api.gouv.fr:443'
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(317)
>     peerSelectDnsPaths: always_direct = DENIED
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(318)
>     peerSelectDnsPaths: never_direct = ALLOWED
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(328)
>     peerSelectDnsPaths: cache_peer = local=0.0.0.0
>     remote=10.26.8.10:3129 flags=1
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(328)
>     peerSelectDnsPaths: cache_peer = local=0.0.0.0 remote=127.0.0.1:3129
>     flags=1
>     2022/09/26 09:07:52.382| 44,2| peer_select.cc(331)
>     peerSelectDnsPaths: timedout = 0
>     2022/09/26 09:07:52.382| 26,3| tunnel.cc(1249)
>     tunnelPeerSelectComplete: paths=2, p[0]={local=0.0.0.0
>     remote=10.26.8.10:3129 flags=1}, serverDest[0]={local=0.0.0.0
>     remote=10.26.8.10:3129 flags=1}
>     2022/09/26 09:07:52.382| 17,3| FwdState.cc(1369)
>     GetMarkingsToServer: from 0.0.0.0 netfilter mark 0
>     2022/09/26 09:07:52.382| 26,3| AsyncCall.cc(25) AsyncCall: The
>     AsyncCall tunnelConnectDone constructed, this=0x5653abf924a0 [call164]
>     2022/09/26 09:07:52.382| 5,3| ConnOpener.cc(43) ConnOpener: will
>     connect to local=0.0.0.0 remote=10.26.8.10:3129 flags=1 with 30 timeout
>     2022/09/26 09:07:52.382| 50,3| comm.cc(350) comm_openex:
>     comm_openex: Attempt open socket for: 0.0.0.0
>     2022/09/26 09:07:52.382| 50,3| comm.cc(393) comm_openex:
>     comm_openex: Opened socket local=0.0.0.0 remote=[::] FD 14 flags=1 :
>     family=2, type=1, protocol=6
>     2022/09/26 09:07:52.382| 51,3| fd.cc(198) fd_open: fd_open() FD 14
>     api.gouv.fr:443
>     2022/09/26 09:07:52.382| 5,3| ConnOpener.cc(291) createFd:
>     local=0.0.0.0 remote=10.26.8.10:3129 flags=1 will timeout in 30
>     2022/09/26 09:07:52.393| 26,3| AsyncCall.cc(92) ScheduleCall:
>     ConnOpener.cc(139) will call
>     tunnelConnectDone(local=10.25.8.10:58500 remote=10.26.8.10:3129 FD
>     14 flags=1, data=0x5653abfa3598) [call164]
>     2022/09/26 09:07:52.393| 26,3| AsyncCallQueue.cc(55) fireNext:
>     entering tunnelConnectDone(local=10.25.8.10:58500
>     remote=10.26.8.10:3129 FD 14 flags=1, data=0x5653abfa3598)
>     2022/09/26 09:07:52.393| 26,3| AsyncCall.cc(37) make: make call
>     tunnelConnectDone [call164]
>     2022/09/26 09:07:52.393| 14,3| Address.cc(382) lookupHostIP: Given
>     Non-IP 'api.gouv.fr': Name or service not known
>     2022/09/26 09:07:52.393| 38,3| net_db.cc(355) netdbSendPing:
>     netdbSendPing: pinging api.gouv.fr
>     2022/09/26 09:07:52.393| 37,2| IcmpSquid.cc(59) SendEcho:  Socket
>     Closed. Aborted send to 10.26.8.10, opcode 3, len 10
>     2022/09/26 09:07:52.393| 26,3| tunnel.cc(1163)
>     tunnelRelayConnectRequest: local=10.25.8.10:58500
>     remote=10.26.8.10:3129 FD 14 flags=1, tunnelState=0x5653abfa3598
>     2022/09/26 09:07:52.393| 22,3| refresh.cc(648) getMaxAge: getMaxAge:
>     'api.gouv.fr:443'
>     2022/09/26 09:07:52.393| 11,2| tunnel.cc(1177)
>     tunnelRelayConnectRequest: Tunnel Server REQUEST:
>     local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1:
>     ----------
>     CONNECT api.gouv.fr:443 HTTP/1.1
>     User-Agent: curl/7.52.1
>     Host: api.gouv.fr:443
>     X-Forwarded-For: unknown
>     Cache-Control: max-age=259200
>     Connection: close
>
>
>     ----------
>     2022/09/26 09:07:52.393| 5,3| comm.cc(559) commSetConnTimeout:
>     local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1 timeout 900
>     2022/09/26 09:07:52.393| 5,3| comm.cc(559) commSetConnTimeout:
>     local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1 timeout 900
>     2022/09/26 09:07:52.393| 26,3| AsyncCallQueue.cc(57) fireNext:
>     leaving tunnelConnectDone(local=10.25.8.10:58500
>     remote=10.26.8.10:3129 FD 14 flags=1, data=0x5653abfa3598)
>     2022/09/26 09:07:52.393| 5,3| IoCallback.cc(116) finish: called for
>     local=10.25.8.10:58500 remote=10.26.8.10:3129 FD 14 flags=1 (0, 0)
>     2022/09/26 09:07:52.393| 26,3| tunnel.cc(929)
>     tunnelConnectReqWriteDone: local=10.25.8.10:58500
>     remote=10.26.8.10:3129 FD 14 flags=1, flag=0
>
>
> It seems /peerGetSomeParent/ is called and this method never issue an ICP :
>
>
>     staticvoid
>     peerGetSomeParent(ps_state * ps)
>     {
>          CachePeer *p;
>          HttpRequest *request = ps->request;
>          hier_code code = HIER_NONE;
>     debugs(44, 3, request->method << ' ' << request->url.host());
>     if (ps->direct == DIRECT_YES)
>     return;
>     if ((p = peerSourceHashSelectParent(request))) {
>              code = SOURCEHASH_PARENT;
>     #if USE_AUTH
>          } elseif ((p = peerUserHashSelectParent(request))) {
>              code = USERHASH_PARENT;
>     #endif
>          } elseif ((p = carpSelectParent(request))) {
>              code = CARP;
>          } elseif ((p = getRoundRobinParent(request))) {
>              code = ROUNDROBIN_PARENT;
>          } elseif ((p = getWeightedRoundRobinParent(request))) {
>              code = ROUNDROBIN_PARENT;
>          } elseif ((p = getFirstUpParent(request))) {
>              code = FIRSTUP_PARENT;
>          } elseif ((p = getDefaultParent(request))) {
>              code = DEFAULT_PARENT;
>          }
>
>     if (code != HIER_NONE) {
>     peerAddFwdServer(ps, p, code);
>          }
>     }
>
>
> Instead of /peerGetSomeNeighbor/ :
>
>
>     /**
>       * peerGetSomeNeighbor
>       *
>       * Selects a neighbor (parent or sibling) based on one of the
>       * following methods:
>       *      Cache Digests
>       *      CARP
>       *      ICMP Netdb RTT estimates
>       *      ICP/HTCP queries
>       */
>     staticvoid
>     peerGetSomeNeighbor(ps_state * ps)
>     {
>          StoreEntry *entry = ps->entry;
>          HttpRequest *request = ps->request;
>          CachePeer *p;
>          hier_code code = HIER_NONE;
>     assert(entry->ping_status == PING_NONE);
>
>     if (ps->direct == DIRECT_YES) {
>     entry->ping_status = PING_DONE;
>     return;
>          }
>
>     #if USE_CACHE_DIGESTS
>     if ((p = neighborsDigestSelect(request))) {
>     if (neighborType(p, request->url) == PEER_PARENT)
>                  code = CD_PARENT_HIT;
>     else
>                  code = CD_SIBLING_HIT;
>          } else
>     #endif
>     if ((p = netdbClosestParent(request))) {
>                  code = CLOSEST_PARENT;
>              } elseif (peerSelectIcpPing(request, ps->direct, entry)) {
>     debugs(44, 3, "peerSelect: Doing ICP pings");
>     ps->ping.start = current_time;
>     ps->ping.n_sent = neighborsUdpPing(request,
>                                                     entry,
>                                                     peerHandlePingReply,
>                                                     ps,
>
>       &ps->ping.n_replies_expected,
>                                                     &ps->ping.timeout);
>
>     if (ps->ping.n_sent == 0)
>     debugs(44, DBG_CRITICAL, "WARNING: neighborsUdpPing returned 0");
>     debugs(44, 3, "peerSelect: " << ps->ping.n_replies_expected <<
>     " ICP replies expected, RTT " << ps->ping.timeout <<
>     " msec");
>
>     if (ps->ping.n_replies_expected > 0) {
>     entry->ping_status = PING_WAITING;
>     eventAdd("peerPingTimeout",
>                               peerPingTimeout,
>                               ps,
>     0.001 * ps->ping.timeout,
>     0);
>     return;
>                  }
>              }
>
>     if (code != HIER_NONE) {
>     assert(p);
>     peerAddFwdServer(ps, p, code);
>          }
>
>     entry->ping_status = PING_DONE;
>     }
>
>
> These functions are called from /peerSelectFoo/ :
>
>
>     staticvoid
>     peerSelectFoo(ps_state * ps)
>     {
>     if (!cbdataReferenceValid(ps->callback_data)) {
>     debugs(44, 3, "Aborting peer selection. Parent Job went away.");
>     delete ps;
>     return;
>          }
>          StoreEntry *entry = ps->entry;
>          HttpRequest *request = ps->request;
>     debugs(44, 3, request->method << ' ' << request->url.host());
>          /** If we don't know whether DIRECT is permitted ... */
>     if (ps->direct == DIRECT_UNKNOWN) {
>     if (ps->always_direct == ACCESS_DUNNO) {
>     debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] <<
>     " (always_direct to be checked)");
>                  /** check always_direct; */
>                  ACLFilledChecklist *ch =
>     newACLFilledChecklist(Config.accessList.AlwaysDirect, request, NULL);
>     ch->al = ps->al;
>     ps->acl_checklist = ch;
>     ps->acl_checklist->nonBlockingCheck(peerCheckAlwaysDirectDone, ps);
>     return;
>              } elseif (ps->never_direct == ACCESS_DUNNO) {
>     debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] <<
>     " (never_direct to be checked)");
>                  /** check never_direct; */
>                  ACLFilledChecklist *ch =
>     newACLFilledChecklist(Config.accessList.NeverDirect, request, NULL);
>     ch->al = ps->al;
>     ps->acl_checklist = ch;
>     ps->acl_checklist->nonBlockingCheck(peerCheckNeverDirectDone, ps);
>     return;
>              } elseif (request->flags.noDirect) {
>                  /** if we are accelerating, direct is not an option. */
>     ps->direct = DIRECT_NO;
>     debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] <<
>     " (forced non-direct)");
>              } elseif (request->flags.loopDetected) {
>                  /** if we are in a forwarding-loop, direct is not an
>     option. */
>     ps->direct = DIRECT_YES;
>     debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] <<
>     " (forwarding loop detected)");
>              } elseif (peerCheckNetdbDirect(ps)) {
>     ps->direct = DIRECT_YES;
>     debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] <<
>     " (checkNetdbDirect)");
>              } else {
>     ps->direct = DIRECT_MAYBE;
>     debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct] <<
>     " (default)");
>              }
>
>     debugs(44, 3, "peerSelectFoo: direct = " << DirectStr[ps->direct]);
>          }
>
>     if (!entry || entry->ping_status == PING_NONE)
>     peerSelectPinned(ps);
>     if (entry == NULL) {
>              (void) 0;
>          } elseif (entry->ping_status == PING_NONE) {
>     peerGetSomeNeighbor(ps);
>
>     if (entry->ping_status == PING_WAITING)
>     return;
>          } elseif (entry->ping_status == PING_WAITING) {
>     peerGetSomeNeighborReplies(ps);
>     entry->ping_status = PING_DONE;
>          }
>
>     switch (ps->direct) {
>
>     case DIRECT_YES:
>     peerGetSomeDirect(ps);
>     break;
>
>     case DIRECT_NO:
>     peerGetSomeParent(ps);
>     peerGetAllParents(ps);
>     break;
>
>     default:
>
>     if (Config.onoff.prefer_direct)
>     peerGetSomeDirect(ps);
>
>     if (request->flags.hierarchical ||
>     !Config.onoff.nonhierarchical_direct) {
>     peerGetSomeParent(ps);
>     peerGetAllParents(ps);
>              }
>
>     if (!Config.onoff.prefer_direct)
>     peerGetSomeDirect(ps);
>
>     break;
>          }
>
>          // resolve the possible peers
>     peerSelectDnsPaths(ps);
>     }
>
>
> /entry/ is /null/ so /peerGetSomeNeighbor/ is never called :
>
> if (entry == NULL) {
>          (void) 0;
>      } elseif (entry->ping_status == PING_NONE) {
> peerGetSomeNeighbor(ps);
>
> if (entry->ping_status == PING_WAITING)
> return;
>      } elseif (entry->ping_status == PING_WAITING) {
> peerGetSomeNeighborReplies(ps);
> entry->ping_status = PING_DONE;
>      }
>
>
> Because of /tunnelStart/ method :
>
>
>     void
>     tunnelStart(ClientHttpRequest * http)
>     {
>     debugs(26, 3, HERE);
>          /* Create state structure. */
>          TunnelStateData *tunnelState = NULL;
>          ErrorState *err = NULL;
>          HttpRequest *request = http->request;
>     char *url = http->uri;
>
>          /*
>           * client_addr.isNoAddr()  indicates this is an "internal" request
>           * from peer_digest.c, asn.c, netdb.c, etc and should always
>           * be allowed.  yuck, I know.
>           */
>
>     if (Config.accessList.miss && !request->client_addr.isNoAddr()) {
>              /*
>               * Check if this host is allowed to fetch MISSES from us
>     (miss_access)
>               * default is to allow.
>               */
>              ACLFilledChecklist ch(Config.accessList.miss, request, NULL);
>     ch.al = http->al;
>     ch.src_addr = request->client_addr;
>     ch.my_addr = request->my_addr;
>     ch.syncAle(request, http->log_uri);
>     if (ch.fastCheck().denied()) {
>     debugs(26, 4, HERE << "MISS access forbidden.");
>                  err = newErrorState(ERR_FORWARDING_DENIED,
>     Http::scForbidden, request);
>     http->al->http.code = Http::scForbidden;
>     errorSend(http->getConn()->clientConnection, err);
>     return;
>              }
>          }
>     debugs(26, 3, request->method << ' ' << url << ' ' <<
>     request->http_ver);
>          ++statCounter.server.all.requests;
>          ++statCounter.server.other.requests;
>
>          tunnelState = newTunnelStateData(http);
>     #if USE_DELAY_POOLS
>          //server.setDelayId called from tunnelConnectDone after server
>     side connection established
>     #endif
>
>     peerSelect(&(tunnelState->serverDestinations), request, http->al,
>     NULL,
>                     tunnelPeerSelectComplete,
>                     tunnelState);
>     }
>
>
> Any ideas ?
>
> Regards,
> Th?o BARRAGU?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220927/fee3ba0f/attachment.htm>

From squid3 at treenet.co.nz  Tue Sep 27 18:43:35 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 28 Sep 2022 07:43:35 +1300
Subject: [squid-users] TCP_MISS only
In-Reply-To: <SA0PR15MB3757DD79FA92D3C545F26938B2559@SA0PR15MB3757.namprd15.prod.outlook.com>
References: <SA0PR15MB375725E2BCE8978659B9BE0CB2529@SA0PR15MB3757.namprd15.prod.outlook.com>
 <da33fd71-420c-cc4a-47e9-e057626d4e4f@measurement-factory.com>
 <SA0PR15MB3757DD79FA92D3C545F26938B2559@SA0PR15MB3757.namprd15.prod.outlook.com>
Message-ID: <4395563c-d41b-c3ca-97a6-a5588a51bfc9@treenet.co.nz>

On 27/09/22 23:01, Andy Armstrong wrote:
> Hi Alex,
> 
> That makes a lot of sense, I don?t know how I overlooked that ? thank 
> you. I also agree, logically caching a 201 response makes little sense, 
> and it was just an example I had that was easy to try so I used that.
> 
> I just altered the HTTP Return code so it sent 200 instead of 201, and 
> the result is sadly the same, I get many, many lines like this:
> 

Unfortunately that is not enough. POST method is also not cacheable by 
default. See <https://www.rfc-editor.org/rfc/rfc9110#section-9.3.3>

Consider what would happen when two clients POST different sets of data 
to the same URL.  Which one should the cache handle *instead* of letting 
it be delivered to a server?


> 1664272638.44310107 10.1.1.70 TCP_MISS/200 275 POST 
> http://192.168.0.2:3001/InternalCommunicationServices/message/email - 
> HIER_DIRECT/192.168.0.2 application/json
> 
> My suspicion is still that my refresh_pattern is wrong:
> 
> refresh_pattern -i http:\/\/129.168.0.2:3001\/.* 10080 100% 43200 
> override-lastmod
> 

refresh_pattern directive does not make things cacheable when they are 
not. It can only extend or shrink cacheability times.


HTH
Amos


From andy.armstrong at uk.ibm.com  Tue Sep 27 18:56:44 2022
From: andy.armstrong at uk.ibm.com (Andy Armstrong)
Date: Tue, 27 Sep 2022 18:56:44 +0000
Subject: [squid-users] TCP_MISS only
In-Reply-To: <4395563c-d41b-c3ca-97a6-a5588a51bfc9@treenet.co.nz>
References: <SA0PR15MB375725E2BCE8978659B9BE0CB2529@SA0PR15MB3757.namprd15.prod.outlook.com>
 <da33fd71-420c-cc4a-47e9-e057626d4e4f@measurement-factory.com>
 <SA0PR15MB3757DD79FA92D3C545F26938B2559@SA0PR15MB3757.namprd15.prod.outlook.com>
 <4395563c-d41b-c3ca-97a6-a5588a51bfc9@treenet.co.nz>
Message-ID: <SA0PR15MB3757FF0BD73163E637A119F8B2559@SA0PR15MB3757.namprd15.prod.outlook.com>

Hi,

Okay ? but what happens if you are communicating with a non REST endpoint. Consider a Web services endpoint for example where a request is only interacted with via POST but the operation for example may frequently be a read based function akin to a HTTP GET? Is Squid just simply not going to help cache those requests? It is only helpful for more strict alignment to REST principles?

Kind regards,

Andy Armstrong
?? ?????
Principal Specialist for Z Technologies
EMEA Squad Leader for Hybrid Cloud
Worldwide Community Leader for Hybrid Cloud
Member of the CTO Office Server & Storage EMEA
Distinguished Technical Specialist ? The Open Group
IBM Master Inventor

Mobile: +447500103874



From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Amos Jeffries <squid3 at treenet.co.nz>
Date: Tuesday, 27 September 2022 at 19:45
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: [EXTERNAL] Re: [squid-users] TCP_MISS only
On 27/09/22 23:01, Andy Armstrong wrote:
> Hi Alex,
>
> That makes a lot of sense, I don?t know how I overlooked that ? thank
> you. I also agree, logically caching a 201 response makes little sense,
> and it was just an example I had that was easy to try so I used that.
>
> I just altered the HTTP Return code so it sent 200 instead of 201, and
> the result is sadly the same, I get many, many lines like this:
>

Unfortunately that is not enough. POST method is also not cacheable by
default. See <https://www.rfc-editor.org/rfc/rfc9110#section-9.3.3  >

Consider what would happen when two clients POST different sets of data
to the same URL.  Which one should the cache handle *instead* of letting
it be delivered to a server?


> 1664272638.44310107 10.1.1.70 TCP_MISS/200 275 POST
> http://192.168.0.2:3001/InternalCommunicationServices/message/email   -
> HIER_DIRECT/192.168.0.2 application/json
>
> My suspicion is still that my refresh_pattern is wrong:
>
> refresh_pattern -i http://129.168.0.2:3001%5C/.*   10080 100% 43200
> override-lastmod
>

refresh_pattern directive does not make things cacheable when they are
not. It can only extend or shrink cacheability times.


HTH
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

Unless otherwise stated above:

IBM United Kingdom Limited
Registered in England and Wales with number 741598
Registered office: PO Box 41, North Harbour, Portsmouth, Hants. PO6 3AU
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220927/46e3bae8/attachment.htm>

From psa at cdot.in  Wed Sep 28 10:11:11 2022
From: psa at cdot.in (Punyasloka Arya)
Date: Wed, 28 Sep 2022 16:41:11 +0630
Subject: [squid-users] Frequent disruption of Microsoft Teams and other
 online VC applications through Squid Proxy
Message-ID: <20220928101111.M34365@cdot.in>

We have our squid 3.5 proxy running on centos 6 for 500 users
Desktop video conference application Microsoft Team Meetings sessions and
other VC apps often get disconnected. Audio goes off and reconnects 
automatically.
At the same time browsing and other applications  work fine.
At the same time SQUID load is normal. we are clueless where to look into the 
system

Any clues to fine tune the underlying parameters like File desriptors, cahce 
parameters etc.

Any help is greatly appreciated

Thanks in advance
Punyasloka Arya
PUNYASLOKA ARYA            ?????????? ????? 
Staffno:3880,Netops,TS(B) 
Senior Research Engineer   ?????? ???????? ??????? 
C-DOT                      ??-???                     
Electronics City,Phase-1   ?????????????? ???? ???? I         
Hosur Road,Bangalore       ????? ???, ???????? 
560100                     560100 
### Please consider the environment and print this email only if necessary 
. 
Go Green ###

Disclaimer :
This email and any files transmitted with it are confidential and intended
solely for the use of the individual or entity to whom they are addressed.
If you are not the intended recipient you are notified that disclosing,
copying, distributing or taking any action in reliance on the contents of 
this
information is strictly prohibited. The sender does not accept liability
for any errors or omissions in the contents of this message, which arise 
as 
a
result.

--
Open WebMail Project (http://openwebmail.org)



From squid3 at treenet.co.nz  Thu Sep 29 12:03:46 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2022 01:03:46 +1300
Subject: [squid-users] TCP_MISS only
In-Reply-To: <SA0PR15MB3757FF0BD73163E637A119F8B2559@SA0PR15MB3757.namprd15.prod.outlook.com>
References: <SA0PR15MB375725E2BCE8978659B9BE0CB2529@SA0PR15MB3757.namprd15.prod.outlook.com>
 <da33fd71-420c-cc4a-47e9-e057626d4e4f@measurement-factory.com>
 <SA0PR15MB3757DD79FA92D3C545F26938B2559@SA0PR15MB3757.namprd15.prod.outlook.com>
 <4395563c-d41b-c3ca-97a6-a5588a51bfc9@treenet.co.nz>
 <SA0PR15MB3757FF0BD73163E637A119F8B2559@SA0PR15MB3757.namprd15.prod.outlook.com>
Message-ID: <5d36de4a-715d-4910-c235-2c7d777867b9@treenet.co.nz>

On 28/09/22 07:56, Andy Armstrong wrote:
> Okay ? but what happens if you are communicating with a non REST 
> endpoint.

You are still communicating over HTTP. To interact with and benefit from 
HTTP agents like caches you need to comply to the HTTP semantics they use.

IMO, REST is just a useful tool to define (in abstract) an API's 
operation when considering what/how it needs to be implemented.


> Consider a Web services endpoint for example where a request 
> is only interacted with via POST but the operation for example may 
> frequently be a read based function akin to a HTTP GET?

That is by definition a broken implementation of HTTP. The agent is 
using a *delivery* API (POST) for retrieval (GET).

If you can separate the delivery and fetch operations HTTP becomes much 
easier to use.


> Is Squid just 
> simply not going to help cache those requests?

Not *by default*, no.

POST implies changing some arbitrary resource *other* than the URL 
presented. Based on data and logic which may not be provided in the 
request message URL+headers.

To use POST with caching both the client *and* the server have to 
explicitly tell the HTTP cache agent(s) what to do on every single HTTP 
message.

  - The client has to tell the cache whether a stored response is able 
to be produced as reply, what object-ID it is trying to retrieve, what 
object-ID's it already knows about (if any), and how old the stored 
object is allowed to be.

  - The server has to tell the cache whether the response can be stored, 
what to use for a unique-ID of the reply object, how old it already is, 
how long it can be stored for, how and when to update it when it becomes 
stale.

The Squid refresh_pattern can provide defaults for the storage times 
when they are omitted. But all the ID related things and whether to use 
cache at all can only come from the client/server.


As you can see by limiting yourself to POST-only you have imposed a huge 
amount of complexity. Using GET instead for fetches makes all the above 
*optional* where now it is mandatory.


> It is only helpful for 
> more strict alignment to REST principles?
> 

You lost me here. Squid implements HTTP.

REST is a very abstract simplification of basic HTTP/1.0 semantics. So 
the closer ones code aligns to REST the *easier* it is to implement HTTP 
properly. But HTTP/1.1+ are vastly more than REST.

HTH
Amos


From squid3 at treenet.co.nz  Thu Sep 29 12:32:48 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2022 01:32:48 +1300
Subject: [squid-users] Frequent disruption of Microsoft Teams and other
 online VC applications through Squid Proxy
In-Reply-To: <20220928101111.M34365@cdot.in>
References: <20220928101111.M34365@cdot.in>
Message-ID: <f46c93c7-b2d7-cd64-4a06-9f2116c7e7df@treenet.co.nz>

On 28/09/22 23:11, Punyasloka Arya wrote:
> We have our squid 3.5 proxy running on centos 6 for 500 users
> Desktop video conference application Microsoft Team Meetings sessions and
> other VC apps often get disconnected. Audio goes off and reconnects
> automatically.
> At the same time browsing and other applications  work fine.
> At the same time SQUID load is normal. we are clueless where to look into the
> system
> 
> Any clues to fine tune the underlying parameters like File desriptors, cahce
> parameters etc.
> 

Please first check whether Squid is actually involved with those 
software transactions. Typically those type of communications should be 
using RTSP/RTMP or VoIP protocols which Squid-3 does not support.


When Squid-3 does handle CONNECT for non-HTTP protocols (including 
encrypted HTTPS) its involvement is purely that of shuffling bytes 
between client and server. So the things to look for there are TCP level 
network issues (eg TCP, NAT, or router cache timeouts) closing 
connections unexpectedly.

If you have Squid Delay Pools configured that may also be interfering 
with connections that need high traffic flow rates.


Check how much traffic Squid is handling at the time(s) these issues 
occur. Squid-3.5 has upper limits of around 19K requests/second and ~63K 
concurrent client connections (on Linux/BSD, much lower on Windows). If 
either of these limits are encountered traffic speeds *will* drastically 
reduce speed until the clients adjust to a lower level.
  - The fix for these if you actually hit the upper limits is to use 
more Squid instances (on different hardware, not VMs on same HW) to 
share the traffic load.
  - If the speed drop occurs before hitting the limits you can try 
optimizing squid.conf settings (ACL sequence in particular), TCP stack 
settings (ie. ephemeral ports use and/or TCP flow controls) for performance.


Also check cache.log to see if Squid, workers, or helpers are 
halting/crashing at all. These are not very consistent in Squid-3 but 
should show up as one or more "FATAL", "ERROR", "assertion failed", or 
"unhandled exception", or "halted" messages.
  - The fix here is obviously to figure out and prevent the crashes 
occuring. Each log message and ones above it should provide some hints 
to help with troubleshooting.



FWIW, Squid-3.5 is long out of support and AFAIK CentOS 6 is also.


HTH
Amos


From squid3 at treenet.co.nz  Thu Sep 29 12:58:17 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2022 01:58:17 +1300
Subject: [squid-users] Use ICP RTT with HTTPS request
In-Reply-To: <80b149d8-87fc-8055-2314-ef36e10277f0@measurement-factory.com>
References: <PAYP264MB412768F98833F4A4878EC042A3529@PAYP264MB4127.FRAP264.PROD.OUTLOOK.COM>
 <80b149d8-87fc-8055-2314-ef36e10277f0@measurement-factory.com>
Message-ID: <9bc3a5d5-df50-9e99-38a7-7462db449f29@treenet.co.nz>

On 27/09/22 02:25, Alex Rousskov wrote:
> On 9/26/22 05:51, Th?o BARRAGUE wrote:
> 
>> ?entry is null so peerGetSomeNeighbor is never called
> 
> I did not check all the details, but it looks like Squid ICMP code 
> (ab)uses StoreEntry-linked metadata. Basic CONNECT tunnels lack 
> StoreEntry because they are not reading/writing data from/to Store. The 
> combination is essentially a Squid bug -- basic CONNECT tunnels cannot 
> use ICMP features.
> 

CONNECT tunnel should be able to use data from ICMP like other code 
doing peer selection.


I see several bugs here:

  1) ICMP relying on StoreEntry as a data source. The server (if not a 
cache_peer) being ping'ed should come from the CONNECT request object URI.

  2) peer selection initiating ICMP directly. It should be retrieving 
RTT values from NetDB, which indirectly uses ICMP to get updates.


Cheers
Amos


From squid3 at treenet.co.nz  Thu Sep 29 13:37:53 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2022 02:37:53 +1300
Subject: [squid-users] Prevent squid user to go out through server's IP
In-Reply-To: <003a01d8d229$7ed5c2e0$7c8148a0$@graminsta.com.br>
References: <003a01d8d229$7ed5c2e0$7c8148a0$@graminsta.com.br>
Message-ID: <a8e7ce5a-e3b9-b003-9e3b-8ef519ff4f1e@treenet.co.nz>

On 27/09/22 17:27, Marcelo wrote:
> Hi,
> 
> Even after Squid fulfill ACLs and Cache Peer rules, the client 
> connection keeps going out through squid server?s IP.
> 
> How can I prevent it to happen?
> 
> For instance, some rule ends with a IPv6 address on 
> tcp_outgoing_address, but when a proxy client connects, he can see this 
> IPv6 address plus the squid server IPv4 address in a ipleak.net and 
> other kinds of proxy detect website.
> 

You cannot trust external websites like these to show Squid behaviour. 
They employ a number of tricks to uncover IP details regardless of what 
Squid is doing.


> How can I create a rule to say in squid.conf that is forbidden to going 
> out through server?s IP?
> 


What you need to look at is:

  a) what HTTP message headers the client is sending to Squid, and

    - specifically whether any hostname or IPs are being mentioned.

  b) what Squid is sending to the server based on those, and

    - specifically whether any hostname or IPs are being mentioned.

  c) what IP address is used on the TCP layer for Squid's server message.

    - specifically whether your tcp_outgoing_address are being used by 
Squid.

Check the above for connections to an IPv6-only server and to an 
IPv4-only server, and also to a dual-stack server.


Be aware that tcp_outgoing_address with an IPv6 can only be used on 
connections to IPv6 servers. It cannot be used for IPv4 connections.


Be aware that HTTP Via header allows the client and Squid to both inform 
origin servers about network topology using hostnames. These can be used 
by the origin to identify Squid's public IP(s) even if those IPs are not 
used for the traffic.
  Disable with "via off" in squid.conf


Be aware that HTTP Forwarded (and X-Forwarded-For, X-Forwarded-By, 
Client-IP, X-Client-IP, X-Origin-IP + maybe others) headers allow the 
client and Squid to both inform origin servers about network topology 
using IP addresses. These can be used to identify client and/or Squid 
internal IPs used for the actually traffic regardless of the publicly 
available name info.
  Disable X-Forwarded-For and Forwarded with "forwarded_for delete" in 
squid.conf
  Disable others with request_header_access directives as-needed.


HTH
Amos


From andy.armstrong at uk.ibm.com  Thu Sep 29 13:59:57 2022
From: andy.armstrong at uk.ibm.com (Andy Armstrong)
Date: Thu, 29 Sep 2022 13:59:57 +0000
Subject: [squid-users] TCP_MISS only
In-Reply-To: <5d36de4a-715d-4910-c235-2c7d777867b9@treenet.co.nz>
References: <SA0PR15MB375725E2BCE8978659B9BE0CB2529@SA0PR15MB3757.namprd15.prod.outlook.com>
 <da33fd71-420c-cc4a-47e9-e057626d4e4f@measurement-factory.com>
 <SA0PR15MB3757DD79FA92D3C545F26938B2559@SA0PR15MB3757.namprd15.prod.outlook.com>
 <4395563c-d41b-c3ca-97a6-a5588a51bfc9@treenet.co.nz>
 <SA0PR15MB3757FF0BD73163E637A119F8B2559@SA0PR15MB3757.namprd15.prod.outlook.com>
 <5d36de4a-715d-4910-c235-2c7d777867b9@treenet.co.nz>
Message-ID: <SA0PR15MB37577549B07B7CF9F5295413B2579@SA0PR15MB3757.namprd15.prod.outlook.com>

Hi,

Excellent I understand and agree with what you are saying. Is this behaviour documented within the Squid documentation anywhere, or is this more ?how does the HTTP specification handle caching??

I am moving forward with a HTTP GET to see if that works per my use case. I assume therefore that any other verb is simply not going to work out the box?

Kind regards,

Andy Armstrong
?? ?????
Principal Specialist for Z Technologies
EMEA Squad Leader for Hybrid Cloud
Worldwide Community Leader for Hybrid Cloud
Member of the CTO Office Server & Storage EMEA
Distinguished Technical Specialist ? The Open Group
IBM Master Inventor

Mobile: +447500103874



From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Amos Jeffries <squid3 at treenet.co.nz>
Date: Thursday, 29 September 2022 at 13:06
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: [EXTERNAL] Re: [squid-users] TCP_MISS only
On 28/09/22 07:56, Andy Armstrong wrote:
> Okay ? but what happens if you are communicating with a non REST
> endpoint.

You are still communicating over HTTP. To interact with and benefit from
HTTP agents like caches you need to comply to the HTTP semantics they use.

IMO, REST is just a useful tool to define (in abstract) an API's
operation when considering what/how it needs to be implemented.


> Consider a Web services endpoint for example where a request
> is only interacted with via POST but the operation for example may
> frequently be a read based function akin to a HTTP GET?

That is by definition a broken implementation of HTTP. The agent is
using a *delivery* API (POST) for retrieval (GET).

If you can separate the delivery and fetch operations HTTP becomes much
easier to use.


> Is Squid just
> simply not going to help cache those requests?

Not *by default*, no.

POST implies changing some arbitrary resource *other* than the URL
presented. Based on data and logic which may not be provided in the
request message URL+headers.

To use POST with caching both the client *and* the server have to
explicitly tell the HTTP cache agent(s) what to do on every single HTTP
message.

  - The client has to tell the cache whether a stored response is able
to be produced as reply, what object-ID it is trying to retrieve, what
object-ID's it already knows about (if any), and how old the stored
object is allowed to be.

  - The server has to tell the cache whether the response can be stored,
what to use for a unique-ID of the reply object, how old it already is,
how long it can be stored for, how and when to update it when it becomes
stale.

The Squid refresh_pattern can provide defaults for the storage times
when they are omitted. But all the ID related things and whether to use
cache at all can only come from the client/server.


As you can see by limiting yourself to POST-only you have imposed a huge
amount of complexity. Using GET instead for fetches makes all the above
*optional* where now it is mandatory.


> It is only helpful for
> more strict alignment to REST principles?
>

You lost me here. Squid implements HTTP.

REST is a very abstract simplification of basic HTTP/1.0 semantics. So
the closer ones code aligns to REST the *easier* it is to implement HTTP
properly. But HTTP/1.1+ are vastly more than REST.

HTH
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

Unless otherwise stated above:

IBM United Kingdom Limited
Registered in England and Wales with number 741598
Registered office: PO Box 41, North Harbour, Portsmouth, Hants. PO6 3AU
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220929/ca0601a8/attachment.htm>

From m_zouhairy at ckta.by  Thu Sep 29 14:45:27 2022
From: m_zouhairy at ckta.by (Majed Zouhairy)
Date: Thu, 29 Sep 2022 17:45:27 +0300
Subject: [squid-users] sarg error in squid 5.7
Message-ID: <9a1ca752-16bc-72e3-ffcd-5827040aa43e@ckta.by>

Peace, does squid still not support long urls?

sudo sarg -x -z
SARG: Init
SARG: Loading configuration file "/usr/share/sarg/sarg.conf"
SARG: TAG: access_log /var/log/squid/access.log
SARG: TAG: title "Squid User Access Reports"
SARG: TAG: font_face Tahoma,Verdana,Arial
SARG: TAG: font_size 18px
SARG: TAG: header_font_size 12px
SARG: TAG: temporary_dir /tmp
SARG: TAG: output_dir /srv/www/sarg
SARG: TAG: resolve_ip yes
SARG: Chaining IP resolving module "dns"
SARG: TAG: date_format e
SARG: TAG: lastlog 25
SARG: TAG: remove_temp_files yes
SARG: TAG: index yes
SARG: TAG: index_tree file
SARG: TAG: overwrite_report yes
SARG: TAG: topsites_num 180
SARG: TAG: exclude_codes /usr/share/sarg/exclude_codes
SARG: TAG: max_elapsed 28800000
SARG: TAG: report_type topusers topsites denied sites_users users_sites 
date_time denied auth_failures site_user_time_date downloads
SARG: TAG: long_url no
SARG: TAG: privacy no
SARG: TAG: show_successful_message yes
SARG: TAG: show_read_statistics yes
SARG: TAG: www_document_root /srv/www/htdocs
SARG: TAG: download_suffix 
"zip,arj,bzip,gz,ace,doc,iso,adt,bin,cab,com,dot,drv$,lha,lzh,mdb,mso,ppt,rtf,src,shs,sys,exe,dll,mp3,avi,mpg,mpeg"
SARG: Purging temporary directory "/tmp/sargnX2FZX"
SARG: Parameters:
SARG:           Hostname or IP address (-a) =
SARG:                     Exclude file (-c) =
SARG:                  Date from-until (-d) =
SARG:    Email address to send reports (-e) =
SARG:                      Config file (-f) = /usr/share/sarg/sarg.conf
SARG:                      Date format (-g) = Europe (dd/mm/yyyy)
SARG:                        IP report (-i) = No
SARG:             Keep temporary files (-k) = No
SARG:                        Input log (-l) = /var/log/squid/access.log
SARG:               Resolve IP Address (-n) = Yes
SARG:                       Output dir (-o) = /srv/www/sarg/
SARG: Use Ip Address instead of userid (-p) = No
SARG:                    Accessed site (-s) =
SARG:                             Time (-t) =
SARG:                             User (-u) =
SARG:                    Temporary dir (-w) = /tmp/sargnX2FZX
SARG:                   Debug messages (-x) = Yes
SARG:                 Process messages (-z) = 1
SARG:  Previous reports to keep (--lastlog) = 25
SARG:
SARG: sarg version: 2.4.0 Jan-16-2020
SARG: Reading access log file: /var/log/squid/access.log
SARG: Log format identified as "squid log format" for 
/var/log/squid/access.log
SARG: The following line read from /var/log/squid/access.log could not 
be parsed and is ignored
1664429404.809     12 10.32.0.2 NONE_NONE/400 23894 POST 
https://yandex.by/clck/safeclick/data=AiuY0DBWFJ5Hyx_fyvalFLOD-Yhiku6D0pBKde9dUC5JtQWHFepEIISjW65MNM0MbWwwbD826Q6PbhmH8wOygGEGZrEbAD17l5ZxdNR-cdjO5PX6BPXQlCuhboWrsuvOUWLzCF5DolY3QBpPflNk0GmYurtACNOj7wBvT5DBkWS6Bceio12NXfa8_IXI5oBhrJfhfaLy5st7wUykxNAvNbUHEnwTieLfdmpWv04zCFacPnnvLUqOdGAbFXQPEbyGKDhVsb12swdUr4_IwTWnXwp1t0lXq_Cm415e6rMpeCdg8vTFFT-D0k0UQ39arRjMuSDzE_8MtoDT6M3q7UB3qA8i-DQ4QupIf-bI_8lhs0d1gtj3wWUrmNrATp6i_Xjf6leJ-IJ_gsU7hxp1BhpvQxPiBPbdz63vO8xdfmupx6dQMbYcoSywDppIGo1X80S4dK9_ZpoKlMP_Onn8Flh8s6Dl4aqqh1AOvNaWnEirAtxtHbtfvUBAQz8N-SYAaN2sQJKUnjJGewpawVeLOZ1qQQ,,/sign=214e4bac6a7f5b6913d67e7a333db887/keyno=0/ref=orjY4mGPRjkHVRqRT7scnl9k3ZfzgjFj0NXM8QCXJ87Lp4yaofJuZIGyAcDCDs-Qxz1NDGQsk0PYaiHTlBS-kNrrDW1IyfUgrvoaMQQfJjvAaeeXw0yAWiEPHr2ZWCcw2tYm73H8gZ89Y5jlFWYscV9f6rVDBKocPyT7JEQI25xWZJZvkh_O-JV9DU8JbHJ5_cwFb_FmjJRcNITbQwr24MQ3UrFCfWmBzhTmAoRmzxtZN3RIbSvTFJQccXH-nU0Awm8IViyObMOih6WKmYmDFq_lMhfJi21t9kshE1JzTbLXdJIck-bAmjvX_VZn2cVPXKt10hpVpsTpMICr52rGzA,,/installation_info=eyJnZW8iOiJ2bGEiLCJjdHlwZSI6InByb2QiLCJ2ZXJ0aWNhbCI6IldFQiJ9/events=%5B%7B%22event%22%3A%22append%22%2C%22tree%22%3A%7B%22id%22%3A%2265olw0e-0-115%22%2C%22name%22%3A%22%24subresult%22%2C%22attrs%22%3A%7B%22schema-ver%22%3A0%2C%22ui%22%3A%22desktop%22%2C%22parent-id%22%3A%2265olw0e-0-10%22%2C%22trigger-event-trusted%22%3Afalse%2C%22main-search%22%3Afalse%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-114%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A0%2C%22docid%22%3A%22ZA4F90CD9CBA93F43%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3De9a6a5515c67cae851b07b9f229b5e83-5220043-images-thumbs%26n%3D13%22%2C%22width%22%3A90%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-116%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A0%7D%7D%5D%7D%2C%7B%22id%22%3A%2265olw0e-0-117%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A1%2C%22docid%22%3A%22Z9DDC9719A5955EEE%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D8c9f9e5b8aa88bf86eb6f6fe517f085c-4032520-images-thumbs%26n%3D13%22%2C%22width%22%3A165%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-118%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A1%7D%7D%5D%7D%2C%7B%22id%22%3A%2265olw0e-0-119%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A2%2C%22docid%22%3A%22ZFD084F8C7957DDCA%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D10c47a55e47708dc60761a03fe0849dc-4076784-images-thumbs%26n%3D13%22%2C%22width%22%3A204%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-11a%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A2%7D%7D%5D%7D%2C%7B%22id%22%3A%2265olw0e-0-11b%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A3%2C%22docid%22%3A%22Z60007453A7465610%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Dc986517c0f5146c8342c58aaf3847352-7015747-images-thumbs%26n%3D13%22%2C%22width%22%3A201%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-11c%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A3%7D%7D%5D%7D%2C%7B%22id%22%3A%2265olw0e-0-11d%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A4%2C%22docid%22%3A%22Z16DA39CF11FDB87D%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Df67d58c0daca68608182d977a6b067dc-5291412-images-thumbs%26n%3D13%22%2C%22width%22%3A233%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-11e%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A4%7D%7D%5D%7D%2C%7B%22id%22%3A%2265olw0e-0-11f%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A0%2C%22docid%22%3A%22ZA973A30BF4AB45AB%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Dedf206c2a87d351f288bd65471868e39-5233360-images-thumbs%26n%3D13%22%2C%22width%22%3A172%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-11g%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A0%7D%7D%5D%7D%2C%7B%22id%22%3A%2265olw0e-0-11h%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A1%2C%22docid%22%3A%22Z57CF2D370EF093EB%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Dba532f52222edfbd2180e043203c80be-4396079-images-thumbs%26n%3D13%22%2C%22width%22%3A312%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-11i%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A1%7D%7D%5D%7D%2C%7B%22id%22%3A%2265olw0e-0-11j%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A2%2C%22docid%22%3A%22Z349D7049DB916BE6%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D82adb561ab8fae18fc006ccfeb408252-5582168-images-thumbs%26n%3D13%22%2C%22width%22%3A198%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-11k%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A2%7D%7D%5D%7D%2C%7B%22id%22%3A%2265olw0e-0-11l%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A3%2C%22docid%22%3A%22Z12EDDFC23892CBC3%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Df947321a2ac89bbb7dd8e14fcd95134c-4985678-images-thumbs%26n%3D13%22%2C%22width%22%3A215%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-11m%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A3%7D%7D%5D%7D%2C%7B%22id%22%3A%2265olw0e-0-11n%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A0%2C%22docid%22%3A%22Z8673BC7B52FEA8AA%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D1acb1ab66905da2923eeacac172096e6-5220621-images-thumbs%26n%3D13%22%2C%22width%22%3A170%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-11o%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A0%7D%7D%5D%7D%2C%7B%22id%22%3A%2265olw0e-0-11p%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A1%2C%22docid%22%3A%22ZA2C4135B25BBF43C%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D14d97a69a2d4ef904f5c81e22c0e1443-5882930-images-thumbs%26n%3D13%22%2C%22width%22%3A166%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-11q%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A1%7D%7D%5D%7D%2C%7B%22id%22%3A%2265olw0e-0-11r%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A2%2C%22docid%22%3A%22Z1E0BBF2AD5BFBBF4%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D57484608e91156299f9e644d083cc246-3735052-images-thumbs%26n%3D13%22%2C%22width%22%3A167%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-11s%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A2%7D%7D%5D%7D%2C%7B%22id%22%3A%2265olw0e-0-11t%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A3%2C%22docid%22%3A%22ZD193DFCF82B23864%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D04047c08be02085d53dcc34aee8d176b-5665620-images-thumbs%26n%3D13%22%2C%22width%22%3A234%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-11u%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A3%7D%7D%5D%7D%2C%7B%22id%22%3A%2265olw0e-0-11v%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A4%2C%22docid%22%3A%22Z444104B5A42D4382%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D5de2ec12cdbc04eac5fa202034bbd021-5364864-images-thumbs%26n%3D13%22%2C%22width%22%3A156%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%2265olw0e-0-11w%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A4%7D%7D%5D%7D%2C%7B%22id%22%3A%2265olw0e-0-11x%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A3%2C%22item%22%3A0%2C%22docid%22%3A%22ZD8EEAC966D07DC7A%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D2f9a1664429404.809 
    121 10.32.0.2 TCP_MISS/200 817 GET 
https://suggest.yandex.by/suggest-ff.cgi? - HIER_DIRECT/213.180.204.63 
application/json
SARG: The following line read from /var/log/squid/access.log could not 
be parsed and is ignored
1664437564.327     28 10.96.0.38 NONE_NONE/400 25171 POST 
https://yandex.by/clck/safeclick/data=AiuY0DBWFJ5Hyx_fyvalFKIC5aGqSbat1LNhkXt7ooCG21jgMNymxw6joxn6UJ1XyFibz5ffYw7Z2hRcM6i7rO0_Dn2x-IhM4sIXJMagiM7qGdLPPXP8iNkAY8QprX3AibkqTZiYYXar4wryTL_Si4TeAxQz2X6gDDX9BTLoVGP8D4vjNwbgjXkwlTKSlyYSDNDJB95zg8pMoe8rV2mxmcAmolNmLA4yhIDh_fagLITPTTqIHrbf7yc09XPFI93KqY61FJMoV1kNFYlrCSPu56YNoV_vBHsO-BlNosXtm_uKRA1fgtxxYNeGrsTWaTnaStLP5W4achxUJIpH1W5ysKxlMQMILEHnAaoR4AEeHRw8_EJ3-PQzBUwePXpinM7lNJWpJjV64wz0qyERfzv-UzTPSAYwU3vTJ_AgpM7zbMeaB050WZN1Pb5ZKLpOj_Ksaj18-Lq1Q9c,/sign=ef862190acf6e6a91d1a778642e6c749/keyno=0/ref=orjY4mGPRjkHVRqRT7scnl9k3ZfzgjFj_7m3biO8ndaTDFyOnqu_OxXiPWitj-41FumWLaWkTCv_EuOFrYGTG5jgCE-AxdMW92L8zyzX_9CpEVZU9TZzQg,,/installation_info=eyJnZW8iOiJ2bGEiLCJjdHlwZSI6InByb2QiLCJ2ZXJ0aWNhbCI6IldFQiJ9/events=%5B%7B%22event%22%3A%22append%22%2C%22tree%22%3A%7B%22id%22%3A%22h0c5w0g-0-119%22%2C%22name%22%3A%22%24subresult%22%2C%22attrs%22%3A%7B%22schema-ver%22%3A0%2C%22ui%22%3A%22desktop%22%2C%22parent-id%22%3A%22h0c5w0g-0-10%22%2C%22trigger-event-trusted%22%3Afalse%2C%22main-search%22%3Afalse%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-118%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A0%2C%22docid%22%3A%22Z5B7AFF3433F0E7A0%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D4fab8df162501c3598f16002a562a59b-5906268-images-thumbs%26n%3D13%22%2C%22width%22%3A165%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-11a%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A0%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-11b%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A1%2C%22docid%22%3A%22ZF625E879835213D6%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Db9e67cba7b2ff4ccc4d993b65604f340-5136262-images-thumbs%26n%3D13%22%2C%22width%22%3A165%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-11c%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A1%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-11d%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A2%2C%22docid%22%3A%22Z1740E8C36FB3ED99%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Dfe099c4bcd6fa587daa5719847cdc53d-4298968-images-thumbs%26n%3D13%22%2C%22width%22%3A165%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-11e%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A2%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-11f%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A3%2C%22docid%22%3A%22Z8AB6D69166EF320E%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D17b11a5aa1405d8f10a131337c367b7b-5280252-images-thumbs%26n%3D13%22%2C%22width%22%3A166%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-11g%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A3%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-11h%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A4%2C%22docid%22%3A%22Z289F6750EFFFDF00%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Db74f7ca5a3e2063710673c668a017828-5233198-images-thumbs%26n%3D13%22%2C%22width%22%3A233%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-11i%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A4%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-11j%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A0%2C%22docid%22%3A%22Z38066DF5C4E2E5B2%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D0d4c39c08a83c639b4f3f637049b8636-4575769-images-thumbs%26n%3D13%22%2C%22width%22%3A201%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-11k%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A0%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-11l%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A1%2C%22docid%22%3A%22Z93A88202EDEE4D0A%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Df1235ac0e77ab9390f3b7c3e16944ef3-5234162-images-thumbs%26n%3D13%22%2C%22width%22%3A173%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-11m%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A1%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-11n%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A2%2C%22docid%22%3A%22Z3D70A5DA8C435D74%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D5bada371b19c5a47f5c17f4d2795b806-3719197-images-thumbs%26n%3D13%22%2C%22width%22%3A173%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-11o%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A2%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-11p%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A3%2C%22docid%22%3A%22Z97D9064ECD929023%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D9294b463a835c82f511f556cc39e5492-5221577-images-thumbs%26n%3D13%22%2C%22width%22%3A173%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-11q%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A3%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-11r%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A4%2C%22docid%22%3A%22Z76D6B81BBF3E30BF%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Df0300d0371f9cff29b0c7dbf3d52baab-4229373-images-thumbs%26n%3D13%22%2C%22width%22%3A174%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-11s%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A4%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-11t%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A0%2C%22docid%22%3A%22Z581A4319B5F4B73D%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Deac4bb4ce0334ba98e2d982c758f10c9-5213641-images-thumbs%26n%3D13%22%2C%22width%22%3A193%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-11u%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A0%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-11v%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A1%2C%22docid%22%3A%22Z47FE2B535F66C6D9%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D99bac48a4102bcef53b04578c65f42ff-4964214-images-thumbs%26n%3D13%22%2C%22width%22%3A194%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-11w%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A1%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-11x%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A2%2C%22docid%22%3A%22Z3A706D3C8E96BB29%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D8eda03ca33f057460b8465c07f950cd0-4592836-images-thumbs%26n%3D13%22%2C%22width%22%3A169%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-11y%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A2%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-11z%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A3%2C%22docid%22%3A%22Z1A5DCB0487E6CA3E%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D33d849e780f36791c985fe31d440f580-5285663-images-thumbs%26n%3D13%22%2C%22width%22%3A169%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-120%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A3%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-121%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A4%2C%22docid%22%3A%22Z40190374FDCFA9C8%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D3c73e2ec5aa90a77cb3a2bd0ecc2265b-5275568-images-thumbs%26n%3D13%22%2C%22width%22%3A169%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22h0c5w0g-0-122%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A4%7D%7D%5D%7D%2C%7B%22id%22%3A%22h0c5w0g-0-123%22%2C%22name%1664437564.330 
    186 10.80.0.85 NONE_NONE/200 0 CONNECT 
core-nmaps-mrc-browser.maps.yandex.ru:443 - HIER_DIRECT/213.180.193.151 -
SARG: The following line read from /var/log/squid/access.log could not 
be parsed and is ignored
1664437704.474     32 10.96.0.38 NONE_NONE/400 25125 POST 
https://yandex.by/clck/safeclick/data=AiuY0DBWFJ5Hyx_fyvalFKIC5aGqSbat1LNhkXt7ooCG21jgMNymxw6joxn6UJ1XyFibz5ffYw7Z2hRcM6i7rO0_Dn2x-IhM4sIXJMagiM7qGdLPPXP8iNkAY8QprX3AibkqTZiYYXar4wryTL_Si4TeAxQz2X6gDDX9BTLoVGP8D4vjNwbgjXkwlTKSlyYSDNDJB95zg8pMoe8rV2mxmcAmolNmLA4yhIDh_fagLITPTTqIHrbf7yc09XPFI93KqY61FJMoV1kNFYlrCSPu56YNoV_vBHsO-BlNosXtm_uKRA1fgtxxYNeGrsTWaTnaStLP5W4achxUJIpH1W5ysKxlMQMILEHnUcI9JlLp7fMBCzZHgKn-u1lA2N5d1Y_Djz_ph8EZ7ume6N4la_mT2foauSFt_4wP9LVr-vhIeVkgTVs_WFpB2wDNN4Kpe7rSwKiHbz-c6eM,/sign=dc79aa8b62a7068ac021289f948dde38/keyno=0/ref=orjY4mGPRjkHVRqRT7scnl9k3ZfzgjFj_7m3biO8ndaTDFyOnqu_OxXiPWitj-415Qr16iHrowwQqz_9Ezm1PubA8Y9s1h-5/installation_info=eyJnZW8iOiJ2bGEiLCJjdHlwZSI6InByb2QiLCJ2ZXJ0aWNhbCI6IldFQiJ9/events=%5B%7B%22event%22%3A%22append%22%2C%22tree%22%3A%7B%22id%22%3A%22jpx6w0g-0-119%22%2C%22name%22%3A%22%24subresult%22%2C%22attrs%22%3A%7B%22schema-ver%22%3A0%2C%22ui%22%3A%22desktop%22%2C%22parent-id%22%3A%22jpx6w0g-0-10%22%2C%22trigger-event-trusted%22%3Afalse%2C%22main-search%22%3Afalse%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-118%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A0%2C%22docid%22%3A%22Z5B7AFF3433F0E7A0%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D4fab8df162501c3598f16002a562a59b-5906268-images-thumbs%26n%3D13%22%2C%22width%22%3A165%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-11a%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A0%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-11b%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A1%2C%22docid%22%3A%22ZF625E879835213D6%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Db9e67cba7b2ff4ccc4d993b65604f340-5136262-images-thumbs%26n%3D13%22%2C%22width%22%3A165%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-11c%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A1%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-11d%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A2%2C%22docid%22%3A%22Z1740E8C36FB3ED99%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Dfe099c4bcd6fa587daa5719847cdc53d-4298968-images-thumbs%26n%3D13%22%2C%22width%22%3A165%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-11e%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A2%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-11f%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A3%2C%22docid%22%3A%22Z8AB6D69166EF320E%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D17b11a5aa1405d8f10a131337c367b7b-5280252-images-thumbs%26n%3D13%22%2C%22width%22%3A166%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-11g%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A3%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-11h%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A4%2C%22docid%22%3A%22Z289F6750EFFFDF00%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Db74f7ca5a3e2063710673c668a017828-5233198-images-thumbs%26n%3D13%22%2C%22width%22%3A233%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-11i%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A0%2C%22item%22%3A4%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-11j%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A0%2C%22docid%22%3A%22Z38066DF5C4E2E5B2%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D0d4c39c08a83c639b4f3f637049b8636-4575769-images-thumbs%26n%3D13%22%2C%22width%22%3A201%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-11k%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A0%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-11l%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A1%2C%22docid%22%3A%22Z93A88202EDEE4D0A%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Df1235ac0e77ab9390f3b7c3e16944ef3-5234162-images-thumbs%26n%3D13%22%2C%22width%22%3A173%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-11m%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A1%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-11n%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A2%2C%22docid%22%3A%22Z3D70A5DA8C435D74%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D5bada371b19c5a47f5c17f4d2795b806-3719197-images-thumbs%26n%3D13%22%2C%22width%22%3A173%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-11o%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A2%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-11p%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A3%2C%22docid%22%3A%22Z97D9064ECD929023%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D9294b463a835c82f511f556cc39e5492-5221577-images-thumbs%26n%3D13%22%2C%22width%22%3A173%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-11q%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A3%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-11r%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A4%2C%22docid%22%3A%22Z76D6B81BBF3E30BF%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Df0300d0371f9cff29b0c7dbf3d52baab-4229373-images-thumbs%26n%3D13%22%2C%22width%22%3A174%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-11s%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A1%2C%22item%22%3A4%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-11t%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A0%2C%22docid%22%3A%22Z581A4319B5F4B73D%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3Deac4bb4ce0334ba98e2d982c758f10c9-5213641-images-thumbs%26n%3D13%22%2C%22width%22%3A193%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-11u%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A0%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-11v%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A1%2C%22docid%22%3A%22Z47FE2B535F66C6D9%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D99bac48a4102bcef53b04578c65f42ff-4964214-images-thumbs%26n%3D13%22%2C%22width%22%3A194%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-11w%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A1%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-11x%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A2%2C%22docid%22%3A%22Z3A706D3C8E96BB29%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D8eda03ca33f057460b8465c07f950cd0-4592836-images-thumbs%26n%3D13%22%2C%22width%22%3A169%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-11y%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A2%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-11z%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A3%2C%22docid%22%3A%22Z1A5DCB0487E6CA3E%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D33d849e780f36791c985fe31d440f580-5285663-images-thumbs%26n%3D13%22%2C%22width%22%3A169%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-120%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A3%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-121%22%2C%22name%22%3A%22image%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A4%2C%22docid%22%3A%22Z40190374FDCFA9C8%22%2C%22image%22%3A%22%2F%2Favatars.mds.yandex.net%2Fi%3Fid%3D3c73e2ec5aa90a77cb3a2bd0ecc2265b-5275568-images-thumbs%26n%3D13%22%2C%22width%22%3A169%2C%22height%22%3A150%7D%2C%22children%22%3A%5B%7B%22id%22%3A%22jpx6w0g-0-122%22%2C%22name%22%3A%22thumb%22%2C%22attrs%22%3A%7B%22row%22%3A2%2C%22item%22%3A4%7D%7D%5D%7D%2C%7B%22id%22%3A%22jpx6w0g-0-123%22%2C%22name%22%3A%22image%22%2C%22at1664437704.480 
     40 10.48.0.3 TCP_REFRESH_UNMODIFIED/200 7952 GET 
https://core-nmaps-mrc-browser.maps.yandex.ru/feature/280258523/image? - 
HIER_DIRECT/213.180.193.151 text/plain
SARG: 4 consecutive errors found in the input log file 
/var/log/squid/access.log

From squid3 at treenet.co.nz  Thu Sep 29 15:15:48 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2022 04:15:48 +1300
Subject: [squid-users] TCP_MISS only
In-Reply-To: <SA0PR15MB37577549B07B7CF9F5295413B2579@SA0PR15MB3757.namprd15.prod.outlook.com>
References: <SA0PR15MB375725E2BCE8978659B9BE0CB2529@SA0PR15MB3757.namprd15.prod.outlook.com>
 <da33fd71-420c-cc4a-47e9-e057626d4e4f@measurement-factory.com>
 <SA0PR15MB3757DD79FA92D3C545F26938B2559@SA0PR15MB3757.namprd15.prod.outlook.com>
 <4395563c-d41b-c3ca-97a6-a5588a51bfc9@treenet.co.nz>
 <SA0PR15MB3757FF0BD73163E637A119F8B2559@SA0PR15MB3757.namprd15.prod.outlook.com>
 <5d36de4a-715d-4910-c235-2c7d777867b9@treenet.co.nz>
 <SA0PR15MB37577549B07B7CF9F5295413B2579@SA0PR15MB3757.namprd15.prod.outlook.com>
Message-ID: <9cf8a74a-8088-a80b-e04c-0c5342d975f1@treenet.co.nz>

On 30/09/22 02:59, Andy Armstrong wrote:
> Hi,
> 
> Excellent I understand and agree with what you are saying. Is this 
> behaviour documented within the Squid documentation anywhere, or is this 
> more ?how does the HTTP specification handle caching??
> 

It is HTTP basics. I have just re-phrased details from RFC 9110 and RFC 
9111 to make them clearer in context of this conversation.

The details about methods can be found in 
https://www.rfc-editor.org/rfc/rfc9110#name-methods

The requirements on caches are covered in 
https://www.rfc-editor.org/rfc/rfc9111#name-overview-of-cache-operation.



> I am moving forward with a HTTP GET to see if that works per my use 
> case. I assume therefore that any other verb is simply not going to work 
> out the box?
> 

Without knowing the details of your service API it is hard to answer 
that question. From what you have mentioned so far I believe so. Or at 
least it is the method most easily altered when you want non-default 
behaviour to occur.


HTH
Amos


From squid3 at treenet.co.nz  Thu Sep 29 16:04:06 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2022 05:04:06 +1300
Subject: [squid-users] sarg error in squid 5.7
In-Reply-To: <9a1ca752-16bc-72e3-ffcd-5827040aa43e@ckta.by>
References: <9a1ca752-16bc-72e3-ffcd-5827040aa43e@ckta.by>
Message-ID: <7b8cfcc9-bb7e-c0c0-722f-e6e7d05b98c8@treenet.co.nz>

On 30/09/22 03:45, Majed Zouhairy wrote:
> Peace, does squid still not support long urls?
> 

Squid supports long URLs. If it did not those log entries would be 
shorter and indicate clients being rejected with "414 URI Too Long".

Your problem is the length of the log line. The logging modules have 
limits which may be shorter than what you have configured the acceptible 
URL / request size to be.

I suggest trying TCP logging instead of the default stdio or daemon.

Sarg itself may also have problems with such long URLs.


HTH
Amos


From krb at informatica.com  Thu Sep 29 17:28:28 2022
From: krb at informatica.com (K R, Bharath)
Date: Thu, 29 Sep 2022 17:28:28 +0000
Subject: [squid-users] NTLM V2 Set up for Squid issue
In-Reply-To: <CO1PR03MB574862C02D2334B3194AB6D9A1579@CO1PR03MB5748.namprd03.prod.outlook.com>
References: <CO1PR03MB574862C02D2334B3194AB6D9A1579@CO1PR03MB5748.namprd03.prod.outlook.com>
Message-ID: <CO1PR03MB574802487F2F9CC24EDC2F10A1579@CO1PR03MB5748.namprd03.prod.outlook.com>

From: K R, Bharath
Sent: Thursday, September 29, 2022 10:31 PM
To: squid-users at lists.squid-cache.org
Cc: Kasat, Puneeth Kumar <pkasat at informatica.com>; Boddupalli, Vikram <vboddupalli at informatica.com>; Uppal, Tanjot Singh <tuppal at informatica.com>
Subject: NTLM V2 Set up for Squid issue

Hi Team,

We see the below error while configuring Squid for NTLM V2.

1664469456.486     73 10.65.140.107 TCP_DENIED/407 4408 GET http://detectportal.firefox.com/canonical.html - HIER_NONE/- text/html
1664469461.446     67 10.65.140.107 TCP_DENIED/407 4408 GET http://detectportal.firefox.com/canonical.html - HIER_NONE/- text/html
1664469466.478     96 10.65.140.107 TCP_DENIED/407 4408 GET http://detectportal.firefox.com/canonical.html - HIER_NONE/- text/html
1664469471.497    102 10.65.140.107 TCP_DENIED/407 4408 GET http://detectportal.firefox.com/canonical.html - HIER_NONE/- text/html
1664469476.478     88 10.65.140.107 TCP_DENIED/407 4408 GET http://detectportal.firefox.com/canonical.html - HIER_NONE/- text/html
1664469481.454     46 10.65.140.107 TCP_DENIED/407 4408 GET http://detectportal.firefox.com/canonical.html - HIER_NONE/- text/html
1664469612.625     34 10.65.140.107 TCP_DENIED/407 4326 CONNECT push.services.mozilla.com:443 - HIER_NONE/- text/html



auth_param ntlm program /usr/bin/ntlm_auth --diagnostics --helper-protocol=squid-2.5-ntlmssp --domain=xxxxx.com
auth_param ntlm children 10
auth_param ntlm keep_alive off


auth_param ntlm program /usr/lib/squid/ntlm_auth xxxx.com/xxxxx.informatica.com
auth_param ntlm children 5
auth_param ntlm max_challenge_reuses 0
auth_param ntlm max_challenge_lifetime 2 minutes


acl ntlm_users proxy_auth REQUIRED
http_access allow ntlm_users
#http_access deny all

NOTE: Our wbinfo component is working as expected.

We made use of https://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm for doc.

Regards,
Bharath

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220929/f262eb7f/attachment.htm>

From marcelorodrigo at graminsta.com.br  Thu Sep 29 18:38:24 2022
From: marcelorodrigo at graminsta.com.br (Marcelo)
Date: Thu, 29 Sep 2022 15:38:24 -0300
Subject: [squid-users] Prevent squid user to go out through
Message-ID: <005f01d8d432$abce58b0$036b0a10$@graminsta.com.br>

ANSWERS BELOW.

On 27/09/22 17:27, Marcelo wrote:
> Hi,
> 
> Even after Squid fulfill ACLs and Cache Peer rules, the client 
> connection keeps going out through squid server?s IP.
> 
> How can I prevent it to happen?
> 
> For instance, some rule ends with a IPv6 address on 
> tcp_outgoing_address, but when a proxy client connects, he can see this 
> IPv6 address plus the squid server IPv4 address in a ipleak.net and 
> other kinds of proxy detect website.
> 

You cannot trust external websites like these to show Squid behaviour. 
They employ a number of tricks to uncover IP details regardless of what 
Squid is doing.

==> MARCELO'S ANWWER:
I know it, but I use the same APIs to identify proxies that the social
network I have to mimic.
So the data I get is what I need.

> How can I create a rule to say in squid.conf that is forbidden to going 
> out through server?s IP?
> 


What you need to look at is:

  a) what HTTP message headers the client is sending to Squid, and

    - specifically whether any hostname or IPs are being mentioned.

  b) what Squid is sending to the server based on those, and

    - specifically whether any hostname or IPs are being mentioned.

  c) what IP address is used on the TCP layer for Squid's server message.

==> MARCELO'S ANWWER:
Sure, that I already did, and the result is ok.

    - specifically whether your tcp_outgoing_address are being used by 
Squid.

Check the above for connections to an IPv6-only server and to an 
IPv4-only server, and also to a dual-stack server.


Be aware that tcp_outgoing_address with an IPv6 can only be used on 
connections to IPv6 servers. It cannot be used for IPv4 connections.


Be aware that HTTP Via header allows the client and Squid to both inform 
origin servers about network topology using hostnames. These can be used 
by the origin to identify Squid's public IP(s) even if those IPs are not 
used for the traffic.
  Disable with "via off" in squid.conf


Be aware that HTTP Forwarded (and X-Forwarded-For, X-Forwarded-By, 
Client-IP, X-Client-IP, X-Origin-IP + maybe others) headers allow the 
client and Squid to both inform origin servers about network topology 
using IP addresses. These can be used to identify client and/or Squid 
internal IPs used for the actually traffic regardless of the publicly 
available name info.
  Disable X-Forwarded-For and Forwarded with "forwarded_for delete" in 
squid.conf
  Disable others with request_header_access directives as-needed.

==> MARCELO'S ANWWER:
I already do all of this and I have tested it for some years. Its working
fine and this is not the issue.

The real problem is that Squid are "leaking" the IPv4 server IP. It is going
out via server IP.
It's as if squid server's IP was in a TCP_OUTGOING_ADDRESS, but it does not.

If for instance I put a TCP_OUTGOING_ADDRESS with some invalid IPv4 address
in the beginning of the squid.conf, the problem is solved because all my
outgoing addresses are IPv6.
But I can't do it because it would kill the CACHE PEER rules that uses IPv4
between Squid servers.

That is why my original question is how to suppress the IPv4 server's IP in
Squid.conf?
Is there any kind of ACL (I have tested MYIP, SRS and DST ones) that I could
use to deny the connections to goes out via server's IP?

Something like:
ACL server_IP "typeN" 192.168.12.1
HTTP_ACCESS deny server_IP

Thanks a lot for all the help.



From marcelorodrigo at graminsta.com.br  Thu Sep 29 18:42:26 2022
From: marcelorodrigo at graminsta.com.br (Marcelo)
Date: Thu, 29 Sep 2022 15:42:26 -0300
Subject: [squid-users] RES:  Prevent squid user to go out through
Message-ID: <006101d8d433$3a70ef10$af52cd30$@graminsta.com.br>

Adittional information.

I don't have problem with client's IP. It's not "leaking".
Main problem is, that after squid.conf accomplish all the rules correctly,
it "leaks" squid server's IP.

Marcelo Rodrigo

-----Mensagem original-----
De: Marcelo [mailto:marcelorodrigo at graminsta.com.br] 
Enviada em: quinta-feira, 29 de setembro de 2022 15:38
Para: 'squid-users at lists.squid-cache.org'
Assunto: Re: [squid-users] Prevent squid user to go out through

ANSWERS BELOW.

On 27/09/22 17:27, Marcelo wrote:
> Hi,
> 
> Even after Squid fulfill ACLs and Cache Peer rules, the client 
> connection keeps going out through squid server?s IP.
> 
> How can I prevent it to happen?
> 
> For instance, some rule ends with a IPv6 address on 
> tcp_outgoing_address, but when a proxy client connects, he can see 
> this
> IPv6 address plus the squid server IPv4 address in a ipleak.net and 
> other kinds of proxy detect website.
> 

You cannot trust external websites like these to show Squid behaviour. 
They employ a number of tricks to uncover IP details regardless of what
Squid is doing.

==> MARCELO'S ANWWER:
I know it, but I use the same APIs to identify proxies that the social
network I have to mimic.
So the data I get is what I need.

> How can I create a rule to say in squid.conf that is forbidden to 
> going out through server?s IP?
> 


What you need to look at is:

  a) what HTTP message headers the client is sending to Squid, and

    - specifically whether any hostname or IPs are being mentioned.

  b) what Squid is sending to the server based on those, and

    - specifically whether any hostname or IPs are being mentioned.

  c) what IP address is used on the TCP layer for Squid's server message.

==> MARCELO'S ANWWER:
Sure, that I already did, and the result is ok.

    - specifically whether your tcp_outgoing_address are being used by
Squid.

Check the above for connections to an IPv6-only server and to an IPv4-only
server, and also to a dual-stack server.


Be aware that tcp_outgoing_address with an IPv6 can only be used on 
connections to IPv6 servers. It cannot be used for IPv4 connections.


Be aware that HTTP Via header allows the client and Squid to both inform 
origin servers about network topology using hostnames. These can be used 
by the origin to identify Squid's public IP(s) even if those IPs are not 
used for the traffic.
  Disable with "via off" in squid.conf


Be aware that HTTP Forwarded (and X-Forwarded-For, X-Forwarded-By, 
Client-IP, X-Client-IP, X-Origin-IP + maybe others) headers allow the 
client and Squid to both inform origin servers about network topology 
using IP addresses. These can be used to identify client and/or Squid 
internal IPs used for the actually traffic regardless of the publicly 
available name info.
  Disable X-Forwarded-For and Forwarded with "forwarded_for delete" in 
squid.conf
  Disable others with request_header_access directives as-needed.

==> MARCELO'S ANWWER:
I already do all of this and I have tested it for some years. Its working
fine and this is not the issue.

The real problem is that Squid are "leaking" the IPv4 server IP. It is going
out via server IP.
It's as if squid server's IP was in a TCP_OUTGOING_ADDRESS, but it does not.

If for instance I put a TCP_OUTGOING_ADDRESS with some invalid IPv4 address
in the beginning of the squid.conf, the problem is solved because all my
outgoing addresses are IPv6.
But I can't do it because it would kill the CACHE PEER rules that uses IPv4
between Squid servers.

That is why my original question is how to suppress the IPv4 server's IP in
Squid.conf?
Is there any kind of ACL (I have tested MYIP, SRS and DST ones) that I could
use to deny the connections to goes out via server's IP?

Something like:
ACL server_IP "typeN" 192.168.12.1
HTTP_ACCESS deny server_IP

Thanks a lot for all the help.



From gtaylor at tnetconsulting.net  Fri Sep 30 01:51:02 2022
From: gtaylor at tnetconsulting.net (Grant Taylor)
Date: Thu, 29 Sep 2022 19:51:02 -0600
Subject: [squid-users] Different routes for domains in dstdomains list
In-Reply-To: <5d32a184-7956-6403-2a1e-27d13ce6d8fe@measurement-factory.com>
References: <002d01d8cd69$6abf4610$403dd230$@graminsta.com.br>
 <5d32a184-7956-6403-2a1e-27d13ce6d8fe@measurement-factory.com>
Message-ID: <e05c2ecc-371c-82a7-8e55-dd77ead48d4b@spamtrap.tnetconsulting.net>

On 9/20/22 9:58 PM, Alex Rousskov wrote:
> * If you want a request to go out on a connection that uses a particular 
> source IP address then use the tcp_outgoing_address directives.

I don't know if the OP is wanting to use a different IP default gateway 
or not; e.g. things in the dstdomain list would use ISP1 while things 
not in dstdomain list would use ISP2.  At least that's what my 
understanding of their message was.

On Linux, I don't know about other OSs, it's possible to configure 
routing rules so that different source IPs are routed differently.  E.g. 
IP1 uses ISP1 while IP2 used ISP2.

> * If you want to direct a request to different cache_peers, then use 
> cache_peer_access and related directives.

I was originally thinking about targeting different cache_peers as a way 
to cause traffic to be more easily identifiable from the routing layer. 
But the tcp_outgoing_address seems to simplify this to the point that an 
iproute2 rule can match based on the source IP.



-- 
Grant. . . .
unix || die

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4017 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20220929/ab8ae4a2/attachment.bin>

From squid3 at treenet.co.nz  Fri Sep 30 07:31:26 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2022 20:31:26 +1300
Subject: [squid-users] Prevent squid user to go out through
In-Reply-To: <005f01d8d432$abce58b0$036b0a10$@graminsta.com.br>
References: <005f01d8d432$abce58b0$036b0a10$@graminsta.com.br>
Message-ID: <4848d533-d7a5-8661-4a22-6c3dd7219432@treenet.co.nz>

On 30/09/22 07:38, Marcelo wrote:
> ANSWERS BELOW.
> 
> On 27/09/22 17:27, Marcelo wrote:
>> Hi,
>>
>> Even after Squid fulfill ACLs and Cache Peer rules, the client
>> connection keeps going out through squid server?s IP.
>>
>> How can I prevent it to happen?
>>
>> For instance, some rule ends with a IPv6 address on
>> tcp_outgoing_address, but when a proxy client connects, he can see this
>> IPv6 address plus the squid server IPv4 address in a ipleak.net and
>> other kinds of proxy detect website.
>>
> 
> You cannot trust external websites like these to show Squid behaviour.
> They employ a number of tricks to uncover IP details regardless of what
> Squid is doing.
> 
> ==> MARCELO'S ANWWER:
> I know it, but I use the same APIs to identify proxies that the social
> network I have to mimic.
> So the data I get is what I need.
> 

What I mean is that they can do things like use javascript to have the 
client Browser report its knowledge of the network and/or scan for 
information. So the source of the leak may be something outside of 
Squid's ability to prevent.

Squid can only control details in the HTTP message headers and tell the 
OS what TCP details it would *like* to use. The OS can decide otherwise, 
for example with outgoing NAT.


>> How can I create a rule to say in squid.conf that is forbidden to going
>> out through server?s IP?
>>
> 
> 
> What you need to look at is:
> 
>    a) what HTTP message headers the client is sending to Squid, and
> 
>      - specifically whether any hostname or IPs are being mentioned.
> 
>    b) what Squid is sending to the server based on those, and
> 
>      - specifically whether any hostname or IPs are being mentioned.
> 
>    c) what IP address is used on the TCP layer for Squid's server message.
> 
> ==> MARCELO'S ANWWER:
> Sure, that I already did, and the result is ok.
> 
>      - specifically whether your tcp_outgoing_address are being used by
> Squid.
> 

... the only way your two statements (above) and (below) can be true at 
the same time is when a NAT system is changing the correct IP (from 
tcp_outgoing_address) to the wrong one (what you call "'leaked' IPv4 
server IP").

> 
> The real problem is that Squid are "leaking" the IPv4 server IP. It is going
> out via server IP.
> It's as if squid server's IP was in a TCP_OUTGOING_ADDRESS, but it does not.
> 

... OR, you have ACLs limiting use of that tcp_outgoing_address to some 
traffic. Leaving Squids default machine IP to be used on the rest.

... OR, you have traffic interception that requires Squid to use 
identical dst-IP used by the client on its request connection (eg for 
TLS decryption).

Eliminating those possibilities is why I had you check TCP layer was 
acting as you want.

... OR, you have a NAT somewhere screwing things ups.


> 
> That is why my original question is how to suppress the IPv4 server's IP in
> Squid.conf?

You are apparently doing everything that can be done in squid.conf. Time 
to look outside Squid at what the routing system is doing. NAT's on the 
IPv4 traffic being the prime suspect for causing this behaviour.


> Is there any kind of ACL (I have tested MYIP, SRS and DST ones) that I could
> use to deny the connections to goes out via server's IP?
> 
> Something like:
> ACL server_IP "typeN" 192.168.12.1
> HTTP_ACCESS deny server_IP
> 

If you cannot find what is doing the odd behaviour only for IPv4 (it is 
not normal AFAICT). Then you can setup a rule like that in the Squid 
machines firewall.

Squid does not have any control that can do what you ask.


HTH
Amos


From squid3 at treenet.co.nz  Fri Sep 30 08:05:25 2022
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2022 21:05:25 +1300
Subject: [squid-users] NTLM V2 Set up for Squid issue
In-Reply-To: <CO1PR03MB574802487F2F9CC24EDC2F10A1579@CO1PR03MB5748.namprd03.prod.outlook.com>
References: <CO1PR03MB574862C02D2334B3194AB6D9A1579@CO1PR03MB5748.namprd03.prod.outlook.com>
 <CO1PR03MB574802487F2F9CC24EDC2F10A1579@CO1PR03MB5748.namprd03.prod.outlook.com>
Message-ID: <8cf8bba2-9475-2992-5616-d46811f41ca9@treenet.co.nz>

On 30/09/22 06:28, K R, Bharath wrote:
> 
> Hi Team,
> 
> We see the below error while configuring Squid for NTLM V2.
> 

FYI: NTLM was formally deprecated by Microsoft on April 2006. It should 
not be used except as a last resort for supporting ancient client software.

Please consider implementing its replacement, Negotiate/Kerberos 
authentication instead.



> 1664469456.486???? 73 10.65.140.107 *TCP_DENIED/407* 4408 GET 
> http://detectportal.firefox.com/canonical.html 
> <http://detectportal.firefox.com/canonical.html> - HIER_NONE/- text/html
> 

Please be aware that NTLM authentication has the following properties:

  1) each TCP connection needs its own unique handshake.

  2) auth handshake is split over multiple HTTP requests. The first 
several of which *will* receive a 407 response status.

  2) it does not work outside LAN environments


The log provided does not make it clear whether these 407 are the result 
of auth rejection, or just the proxy receiving a lot of new TCP 
connections suddenly.


FWIW, From behaviour seen elsewhere with non-NTLM auth I suspect the 
pattern of detectportal.firefox.com and push.services.mozilla.com 
requests are Firefox automation that runs on opening, but does not try 
to complete auth handshakes initially.
  If you are only seeing these excess of 407 for those domains I would 
ignore as normal.



> 1664469612.625???? 34 10.65.140.107 TCP_DENIED/407 4326 CONNECT 
> push.services.mozilla.com:443 - HIER_NONE/- text/html
> 
> auth_param ntlm program /usr/bin/ntlm_auth --diagnostics 
> --helper-protocol=squid-2.5-ntlmssp --domain=xxxxx.com
> 
> auth_param ntlm children 10
> 
> auth_param ntlm keep_alive off
> 
> auth_param ntlm program /usr/lib/squid/ntlm_auth 
> xxxx.com/xxxxx.informatica.com
> 
> auth_param ntlm children 5
> 
> auth_param ntlm max_challenge_reuses 0
> 
> auth_param ntlm max_challenge_lifetime 2 minutes
> 

FYI, these max_challenge_* parameters have not been supported since 
Squid-2.6.

If you are still using that version or older *PLEASE* upgrade. Current 
supported versions are the Squid-4 and Squid-5 series.



> acl ntlm_users proxy_auth REQUIRED
> 
> http_access allow ntlm_users
> 

This will permit anyone to supply bad credentials and still use the proxy.

I suggest replacing the above line with:

  http_access deny !ntlm_users

... then followup with any policy rules for allowing users.


> #http_access deny all
> 
> NOTE: Our wbinfo component is working as expected.
> 
> We made use of 
> https://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm 
> <https://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm> for doc.
> 
> Regards,
> 
> Bharath
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


