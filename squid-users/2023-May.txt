From amajer at suse.de  Tue May  2 10:31:38 2023
From: amajer at suse.de (Adam Majer)
Date: Tue, 2 May 2023 12:31:38 +0200
Subject: [squid-users] Squid ntlm_authenticator #Hlpr254332 exited
In-Reply-To: <MW5PR14MB5289C3F3E4652D23BF218DE7B06B9@MW5PR14MB5289.namprd14.prod.outlook.com>
References: <MW5PR14MB5289C3F3E4652D23BF218DE7B06B9@MW5PR14MB5289.namprd14.prod.outlook.com>
Message-ID: <3fcc9e52-f4f7-8a8c-6fd9-840b1b09a486@suse.de>

On 4/28/23 21:05, Bobby Matznick wrote:
> Upgraded to Debian 11 and all that comes with that (updated all 

Debian 12 is coming out in a month or so, so please try to upgrade sooner ;)

> Any help would be greatly appreciated. Thanks!!
> 
> Squid cache log entries:
> ipcCreate:? //usr/bin/ntlm_auth:? (13) Permission denied
> WARNING: ntlmauthenticator #Hlpr253452 exited

/usr/bin/ntlm_auth doesn't exist in squid and didn't exist in the last 
Debian version (buster) either. If it's your own script, it says that 
it's simply not executable

I've found now that this file comes from package `winbind`. Do you have 
it installed?

https://packages.debian.org/bullseye/winbind

Squid is not looking anywhere except what you have in squid.conf.

- Adam


From bmatznick at pbandt.bank  Tue May  2 14:20:13 2023
From: bmatznick at pbandt.bank (Bobby Matznick)
Date: Tue, 2 May 2023 14:20:13 +0000
Subject: [squid-users] [External] squid-users Digest, Vol 105, Issue 1
In-Reply-To: <mailman.3.1683028802.2652431.squid-users@lists.squid-cache.org>
References: <mailman.3.1683028802.2652431.squid-users@lists.squid-cache.org>
Message-ID: <MW5PR14MB52895B4796956DC39443E7A2B06F9@MW5PR14MB5289.namprd14.prod.outlook.com>

Hello Adam, thanks for your reply. Yes, I am aware the executable is from Winbind, it is installed, and it does exist in the location where squid is looking for it. It doesn't seem to be able to access it though. I checked the Debian server I am running on currently while trying to upgrade this one and ntlm_auth is in the exact same location, /usr/bin/ntlm_auth. I did find that apparmor was turned on with the upgrade, I disable that but still see the same message.
Here is what I have in squid.conf
auth_param ntlm program /usr/bin/ntlm_auth -helper-protocol=squid-2.5-ntlmssp -require-membership-of="domain\\domain group"
auth_param ntlm children 250

ntlm_auth does exist at /usr/bin/ntlm_auth

log messages from /var/log/squid/cache.log

ipcCreate:? //usr/bin/ntlm_auth:? (13) Permission denied
WARNING: ntlmauthenticator #Hlpr253452 exited
ipcCreate:? //usr/bin/ntlm_auth:? (13) Permission denied
WARNING: ntlmauthenticator #Hlpr253452 exited
ipcCreate:? //usr/bin/ntlm_auth:? (13) Permission denied
WARNING: ntlmauthenticator #Hlpr253452 exited


Bobby


From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of squid-users-request at lists.squid-cache.org
Sent: Tuesday, May 2, 2023 6:00 AM
To: squid-users at lists.squid-cache.org
Subject: [External] squid-users Digest, Vol 105, Issue 1

Caution: This is an external email and has a suspicious subject or content. Please take care when clicking links or opening attachments. When in doubt, contact your IT Department
Send squid-users mailing list submissions to
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

To subscribe or unsubscribe via the World Wide Web, visit
http://lists.squid-cache.org/listinfo/squid-users<http://lists.squid-cache.org/listinfo/squid-users>
or, via email, send a message with subject or body 'help' to
squid-users-request at lists.squid-cache.org<mailto:squid-users-request at lists.squid-cache.org>

You can reach the person managing the list at
squid-users-owner at lists.squid-cache.org<mailto:squid-users-owner at lists.squid-cache.org>

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

1. Re: Squid ntlm_authenticator #Hlpr254332 exited (Adam Majer)


----------------------------------------------------------------------

Message: 1
Date: Tue, 2 May 2023 12:31:38 +0200
From: Adam Majer <amajer at suse.de<mailto:amajer at suse.de>>
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Squid ntlm_authenticator #Hlpr254332 exited
Message-ID: <3fcc9e52-f4f7-8a8c-6fd9-840b1b09a486 at suse.de<mailto:3fcc9e52-f4f7-8a8c-6fd9-840b1b09a486 at suse.de>>
Content-Type: text/plain; charset=UTF-8; format=flowed

On 4/28/23 21:05, Bobby Matznick wrote:
> Upgraded to Debian 11 and all that comes with that (updated all

Debian 12 is coming out in a month or so, so please try to upgrade sooner ;)

> Any help would be greatly appreciated. Thanks!!
>
> Squid cache log entries:
> ipcCreate:? //usr/bin/ntlm_auth:? (13) Permission denied
> WARNING: ntlmauthenticator #Hlpr253452 exited

/usr/bin/ntlm_auth doesn't exist in squid and didn't exist in the last
Debian version (buster) either. If it's your own script, it says that
it's simply not executable

I've found now that this file comes from package `winbind`. Do you have
it installed?

https://packages.debian.org/bullseye/winbind<https://packages.debian.org/bullseye/winbind>

Squid is not looking anywhere except what you have in squid.conf.

- Adam


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users<http://lists.squid-cache.org/listinfo/squid-users>


------------------------------

End of squid-users Digest, Vol 105, Issue 1
*******************************************
CONFIDENTIALITY NOTICE: The information contained in and attached to this email is intended only for the confidential use of the person or entity to which the email is addressed. This email and any attachments may contain privileged and confidential information. If you are not the intended recipient, you are notified that you received this email in error and that any reading, retention, use or distribution of this email and attachments is strictly prohibited. If you received this email in error, you are requested to immediately notify us by calling 888-728-3550 or by return email and immediately and permanently delete the email and any attachments. Thank you.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230502/c253ed9b/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0.jpg
Type: image/jpeg
Size: 6398 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230502/c253ed9b/attachment.jpg>

From jinshu_zhang at fanniemae.com  Thu May  4 17:56:39 2023
From: jinshu_zhang at fanniemae.com (Zhang, Jinshu)
Date: Thu, 4 May 2023 17:56:39 +0000
Subject: [squid-users] Bearer authentication released?
Message-ID: <DM6PR06MB44253A77FB170ACE07D3381FF16D9@DM6PR06MB4425.namprd06.prod.outlook.com>

Hi There, I saw a feature page for bearer authentication. But seems to me that is never merge into a release. Can any body update on that? If it is
released? If not, nay plan it will be? Thank you so much.

Thanks and Regards,
Jinshu Zhang
Flex Gateway
Fannie Mae
703-833-3413

fanniemae.com

This e-mail and its attachments are confidential and solely for the intended addressee(s). Do not share or use them without Fannie Mae's approval. If received in error, delete them and contact the sender.




Fannie Mae Confidential
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230504/0ac29e08/attachment.htm>

From service.mv at gmail.com  Thu May  4 17:57:25 2023
From: service.mv at gmail.com (Service MV)
Date: Thu, 4 May 2023 14:57:25 -0300
Subject: [squid-users] PROXY client not permited by ACLs...
Message-ID: <CA+d==oE1QCkAeGCQLy350tbi4ie5ni4-V5KB=jbmTtdiBufaBQ@mail.gmail.com>

Hello everyone.
I'm monitoring by SNMP my SQUID nodes using Zabbix 5.2 without problems.
The monitoring is working fine. I clarify that in front of my proxies I
have a HAproxy with proxy protocol enabled.
However in cache.log I have many messages like the following:
PROXY client not permitted by ACLs from local=10.10.8.53:3128 remote=
10.10.8.66:54568 FD 888 flags=1

This is the relevant configuration:

# SNMP monitoring with Zabbix
acl zabbix snmp_community zabbix_public
acl zabbix_proxy src 10.10.8.66
snmp_port 3401
snmp_access allow zabbix zabbix_proxy
snmp_access allow zabbix localhost
snmp_access deny all
snmp_incoming_address 0.0.0.0
snmp_outgoing_address 0.0.0.0
access_log none zabbix_proxy
access_log daemon:/var/log/squid/4.14/access.log

http_port 3128 require-proxy-header
forwarded_for transparent

acl vip_haproxy src 10.10.8.92
proxy_protocol_access allow vip_haproxy


Could someone tell me what configuration I could do to avoid these messages?

Thank you very much
Gabriel
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230504/bc07e01b/attachment.htm>

From rousskov at measurement-factory.com  Thu May  4 20:30:36 2023
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 4 May 2023 16:30:36 -0400
Subject: [squid-users] PROXY client not permited by ACLs...
In-Reply-To: <CA+d==oE1QCkAeGCQLy350tbi4ie5ni4-V5KB=jbmTtdiBufaBQ@mail.gmail.com>
References: <CA+d==oE1QCkAeGCQLy350tbi4ie5ni4-V5KB=jbmTtdiBufaBQ@mail.gmail.com>
Message-ID: <0b92a4f3-d92a-f7a9-0d68-7daaa7ea9a26@measurement-factory.com>

On 5/4/23 13:57, Service MV wrote:

> I'm monitoring by SNMP my SQUID nodes using Zabbix 5.2 without problems. 
> The monitoring is working fine. I clarify that in front of my proxies I 
> have a HAproxy with proxy protocol enabled.


> However in cache.log I have many messages like the following:
> PROXY client not permitted by ACLs from local=10.10.8.53:3128 
> remote=10.10.8.66:54568 
> FD 888 flags=1


> This is the relevant configuration:
> 
> # SNMP monitoring with Zabbix
> acl zabbix snmp_community zabbix_public
> acl zabbix_proxy src 10.10.8.66
> snmp_port 3401
> snmp_access allow zabbix zabbix_proxy
> snmp_access allow zabbix localhost
> snmp_access deny all
> snmp_incoming_address 0.0.0.0
> snmp_outgoing_address 0.0.0.0
> access_log none zabbix_proxy
> access_log daemon:/var/log/squid/4.14/access.log
> 
> http_port 3128 require-proxy-header
> forwarded_for transparent
> 
> acl vip_haproxy src 10.10.8.92
> proxy_protocol_access allow vip_haproxy


> Could someone tell me what configuration I could do to avoid these messages?


Bugs notwithstanding, something running on 10.10.8.66 is opening TCP 
connections to your Squid http_port 3128. That port is configured to 
require PROXY protocol connection prefixes. Your Squid is also 
configured to only accept such connections from vip_haproxy which does 
not match 10.10.8.66. Squid denies http_port connections from 
10.10.8.66, and you see the above cache.log messages.

Does this give you enough information to fix the problem?

Alex.



From service.mv at gmail.com  Fri May  5 15:13:00 2023
From: service.mv at gmail.com (Service MV)
Date: Fri, 5 May 2023 12:13:00 -0300
Subject: [squid-users] PROXY client not permited by ACLs...
In-Reply-To: <0b92a4f3-d92a-f7a9-0d68-7daaa7ea9a26@measurement-factory.com>
References: <CA+d==oE1QCkAeGCQLy350tbi4ie5ni4-V5KB=jbmTtdiBufaBQ@mail.gmail.com>
 <0b92a4f3-d92a-f7a9-0d68-7daaa7ea9a26@measurement-factory.com>
Message-ID: <CA+d==oEyYCXDr8Cdw7aPwdado-43jEMa0dThmtKOc=+R-nYXzw@mail.gmail.com>

Thanks Alex, with this information I was able to solve the problem.

Best regards.

El jue, 4 de may de 2023, 17:31, Alex Rousskov <
rousskov at measurement-factory.com> escribi?:

> On 5/4/23 13:57, Service MV wrote:
>
> > I'm monitoring by SNMP my SQUID nodes using Zabbix 5.2 without problems.
> > The monitoring is working fine. I clarify that in front of my proxies I
> > have a HAproxy with proxy protocol enabled.
>
>
> > However in cache.log I have many messages like the following:
> > PROXY client not permitted by ACLs from local=10.10.8.53:3128
> > remote=10.10.8.66:54568
> > FD 888 flags=1
>
>
> > This is the relevant configuration:
> >
> > # SNMP monitoring with Zabbix
> > acl zabbix snmp_community zabbix_public
> > acl zabbix_proxy src 10.10.8.66
> > snmp_port 3401
> > snmp_access allow zabbix zabbix_proxy
> > snmp_access allow zabbix localhost
> > snmp_access deny all
> > snmp_incoming_address 0.0.0.0
> > snmp_outgoing_address 0.0.0.0
> > access_log none zabbix_proxy
> > access_log daemon:/var/log/squid/4.14/access.log
> >
> > http_port 3128 require-proxy-header
> > forwarded_for transparent
> >
> > acl vip_haproxy src 10.10.8.92
> > proxy_protocol_access allow vip_haproxy
>
>
> > Could someone tell me what configuration I could do to avoid these
> messages?
>
>
> Bugs notwithstanding, something running on 10.10.8.66 is opening TCP
> connections to your Squid http_port 3128. That port is configured to
> require PROXY protocol connection prefixes. Your Squid is also
> configured to only accept such connections from vip_haproxy which does
> not match 10.10.8.66. Squid denies http_port connections from
> 10.10.8.66, and you see the above cache.log messages.
>
> Does this give you enough information to fix the problem?
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230505/caea2e16/attachment.htm>

From marcelorodrigo at graminsta.com.br  Tue May  9 19:54:20 2023
From: marcelorodrigo at graminsta.com.br (Marcelo Rodrigo - ProxyADS)
Date: Tue, 9 May 2023 16:54:20 -0300
Subject: [squid-users] Squid Server on Android Devices?
Message-ID: <00da01d982b0$0bd69ed0$2383dc70$@graminsta.com.br>

 

Hello.

 

Is it possible to run squid on Android devices?
I was thinking about using an android device as a peer.

I would like to run some tests. I got a Samsung S10 with Android 12 that
already works with Ethernet Theatering and the USB-c/Ethernet cable.

Which Squid package should I use for that? This hardware is an ARM64.

 

I am thinking about root this device in order to run a SSH access to begin.

 

Any advices for this journey?

 

Marcelo

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230509/68e74f79/attachment.htm>

From Antony.Stone at squid.open.source.it  Tue May  9 21:36:16 2023
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 9 May 2023 22:36:16 +0100
Subject: [squid-users] Squid Server on Android Devices?
In-Reply-To: <00da01d982b0$0bd69ed0$2383dc70$@graminsta.com.br>
References: <00da01d982b0$0bd69ed0$2383dc70$@graminsta.com.br>
Message-ID: <202305092236.16446.Antony.Stone@squid.open.source.it>

On Tuesday 09 May 2023 at 20:54:20, Marcelo Rodrigo - ProxyADS wrote:

> Hello.
> 
> Is it possible to run squid on Android devices?
> I was thinking about using an android device as a peer.

Why?  What's the purpose, and what Android device would you use that is either 
cheaper or more appropriate than, for example, a Raspberry Pi (on which Squid 
runs for certain)?

Antony.

-- 
Pavlov is in the pub enjoying a pint.
The barman rings for last orders, and Pavlov jumps up exclaiming "Damn!  I 
forgot to feed the dog!"

                                                   Please reply to the list;
                                                         please *don't* CC me.


From stu.lists at spacehopper.org  Tue May  9 22:28:31 2023
From: stu.lists at spacehopper.org (Stuart Henderson)
Date: Tue, 9 May 2023 22:28:31 -0000 (UTC)
Subject: [squid-users] Squid Server on Android Devices?
References: <00da01d982b0$0bd69ed0$2383dc70$@graminsta.com.br>
Message-ID: <slrnu5li8f.2j29.stu.lists@naiad.spacehopper.org>

On 2023-05-09, Marcelo Rodrigo - ProxyADS <marcelorodrigo at graminsta.com.br> wrote:
> Is it possible to run squid on Android devices?

> I am thinking about root this device in order to run a SSH access to begin.

There's a squid package available in Termux. You shouldn't need root
but will need to allow unsigned installs either to install Termux (either
directly from apk or via F-Droid).

Not sure it really makes much sense to do this but there's a reasonable
chance it will work.




From robertocarna36 at gmail.com  Wed May 10 16:51:31 2023
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Wed, 10 May 2023 13:51:31 -0300
Subject: [squid-users] Define Squid max connections limit
Message-ID: <CAG2Qp6u09jfFhUcDgEWq_S7ZTc=MQN6cV32C2sFR0YDfSyNSLA@mail.gmail.com>

Dear all, is there any directive to define Squid max connections
limit, or do I have to increase the RAM and CPU instead?

Thanks a lot, regards!


From krystian.sikora77 at interia.pl  Wed May 10 17:30:04 2023
From: krystian.sikora77 at interia.pl (Krystian Sikora)
Date: Wed, 10 May 2023 19:30:04 +0200
Subject: [squid-users] How to increase the number of ports supported by
 Squid?
Message-ID: <xbnehwqubagaxnpnflja@dctx>

Spam detection software, running on the system "master.squid-cache.org",
has identified this incoming email as possible spam.  The original
message has been attached to this so you can view it or label
similar future email.  If you have any questions, see
the administrator of that system for details.

Content preview:  Dear Squid developers,I am writing to inquire about how to
   increase the number of ports supported by Squid. I have recently set up a
   proxy server using Squid and have encountered an issue where Squid [...] 

Content analysis details:   (5.8 points, 5.0 required)

 pts rule name              description
---- ---------------------- --------------------------------------------------
 3.6 RCVD_IN_PBL            RBL: Received via a relay in Spamhaus PBL
                            [79.184.244.40 listed in zen.spamhaus.org]
 0.0 FREEMAIL_FROM          Sender email is commonly abused enduser mail
                            provider
                            [krystian.sikora77[at]interia.pl]
 0.2 FREEMAIL_ENVFROM_END_DIGIT Envelope-from freemail username ends
                            in digit
                            [krystian.sikora77[at]interia.pl]
 0.9 SPF_FAIL               SPF: sender does not match SPF record (fail)
[SPF failed: Please see http://www.openspf.org/Why?s=mfrom;id=krystian.sikora77%40interia.pl;ip=79.184.244.40;r=master.squid-cache.org]
 0.0 HTML_MESSAGE           BODY: HTML included in message
-0.1 DKIM_VALID             Message has at least one valid DKIM or DK signature
-0.1 DKIM_VALID_EF          Message has a valid DKIM or DK signature from
                            envelope-from domain
-0.1 DKIM_VALID_AU          Message has a valid DKIM or DK signature from
                            author's domain
 0.1 DKIM_SIGNED            Message has a DKIM or DK signature, not necessarily
                            valid
 0.0 HELO_NO_DOMAIN         Relay reports its domain incorrectly
-0.0 T_SCC_BODY_TEXT_LINE   No description available.
 0.0 UNPARSEABLE_RELAY      Informational: message has unparseable relay
                            lines
 1.3 RDNS_NONE              Delivered to internal network by a host with no rDNS

The original message was not completely plain text, and may be unsafe to
open with some email clients; in particular, it may contain a virus,
or confirm that your address can receive spam.  If you wish to view
it, it may be safer to save it to a file and open it with an editor.

-------------- next part --------------
An embedded message was scrubbed...
From: Krystian  Sikora <krystian.sikora77 at interia.pl>
Subject: How to increase the number of ports supported by Squid?
Date: Wed, 10 May 2023 19:30:04 +0200
Size: 5607
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230510/d29fd003/attachment.eml>

From ben.goz87 at gmail.com  Thu May 11 10:26:12 2023
From: ben.goz87 at gmail.com (Ben Goz)
Date: Thu, 11 May 2023 13:26:12 +0300
Subject: [squid-users] Bind specific squid instance (port) to specific icap
 service
Message-ID: <CADAqQfx7mkJF3a+qwPtHnSMOcSJHCHx7VRjJtYu0z8uyEqTg=w@mail.gmail.com>

By the help of God.

I have a machine with N (while N is always bigger than 1) different ip
addresses and for each ip address I have a different squid instance. And I
also have N icap servers. What is the best configuration that each squid
will be attached to a different icap service?

Thanks,
Ben
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230511/b3c723f3/attachment.htm>

From rousskov at measurement-factory.com  Thu May 11 12:58:53 2023
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 11 May 2023 08:58:53 -0400
Subject: [squid-users] Bind specific squid instance (port) to specific
 icap service
In-Reply-To: <CADAqQfx7mkJF3a+qwPtHnSMOcSJHCHx7VRjJtYu0z8uyEqTg=w@mail.gmail.com>
References: <CADAqQfx7mkJF3a+qwPtHnSMOcSJHCHx7VRjJtYu0z8uyEqTg=w@mail.gmail.com>
Message-ID: <515fe69a-6d00-6eda-514c-0e663eb51d4d@measurement-factory.com>

On 5/11/23 06:26, Ben Goz wrote:

> I have a machine with N (while N is always bigger than 1) different ip 
> addresses and for each ip address?I have a different squid instance. And 
> I also have N icap servers. What is the best configuration that each 
> squid will be attached?to a different icap service?

Can you configure each Squid to use a different ICAP service (i.e. Squid 
instance #i would use ICAP service #i)? If the answer to that question 
is "no", then please detail what prevents you from using that 
(natural/obvious) solution.


Thank you,

Alex.



From ben.goz87 at gmail.com  Thu May 11 13:08:13 2023
From: ben.goz87 at gmail.com (Ben Goz)
Date: Thu, 11 May 2023 16:08:13 +0300
Subject: [squid-users] Bind specific squid instance (port) to specific
 icap service
In-Reply-To: <515fe69a-6d00-6eda-514c-0e663eb51d4d@measurement-factory.com>
References: <CADAqQfx7mkJF3a+qwPtHnSMOcSJHCHx7VRjJtYu0z8uyEqTg=w@mail.gmail.com>
 <515fe69a-6d00-6eda-514c-0e663eb51d4d@measurement-factory.com>
Message-ID: <d0a02b01-2579-6ab9-a3a5-a50b38a0c199@gmail.com>


On 11/05/2023 15:58, Alex Rousskov wrote:
> On 5/11/23 06:26, Ben Goz wrote:
>
>> I have a machine with N (while N is always bigger than 1) different 
>> ip addresses and for each ip address?I have a different squid 
>> instance. And I also have N icap servers. What is the best 
>> configuration that each squid will be attached?to a different icap 
>> service?
>
> Can you configure each Squid to use a different ICAP service (i.e. 
> Squid instance #i would use ICAP service #i)? If the answer to that 
> question is "no", then please detail what prevents you from using that 
> (natural/obvious) solution.

It should be used with different pidfile correct?

>
>
> Thank you,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Thu May 11 13:39:13 2023
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 11 May 2023 09:39:13 -0400
Subject: [squid-users] Bind specific squid instance (port) to specific
 icap service
In-Reply-To: <d0a02b01-2579-6ab9-a3a5-a50b38a0c199@gmail.com>
References: <CADAqQfx7mkJF3a+qwPtHnSMOcSJHCHx7VRjJtYu0z8uyEqTg=w@mail.gmail.com>
 <515fe69a-6d00-6eda-514c-0e663eb51d4d@measurement-factory.com>
 <d0a02b01-2579-6ab9-a3a5-a50b38a0c199@gmail.com>
Message-ID: <b41eb609-eafd-7941-2f81-5f6478cfc9e9@measurement-factory.com>

On 5/11/23 09:08, Ben Goz wrote:
> 
> On 11/05/2023 15:58, Alex Rousskov wrote:
>> On 5/11/23 06:26, Ben Goz wrote:
>>
>>> I have a machine with N (while N is always bigger than 1) different 
>>> ip addresses and for each ip address?I have a different squid 
>>> instance. And I also have N icap servers. What is the best 
>>> configuration that each squid will be attached?to a different icap 
>>> service?
>>
>> Can you configure each Squid to use a different ICAP service (i.e. 
>> Squid instance #i would use ICAP service #i)? If the answer to that 
>> question is "no", then please detail what prevents you from using that 
>> (natural/obvious) solution.

> It should be used with different pidfile correct?

What do you mean by "it"? The opening of your question states that you 
already have a machine with N Squid instances so, I assume, you already 
know how to run multiple Squid instances on the same machine. It does 
require instance-specific PID files (pid_filename in squid.conf). It is 
usually best to make that multi-Squid setup work well _before_ you add 
ICAP into the mix.

If you are asking about ICAP server configuration, then you should 
direct your question to ICAP server support. Each ICAP server has its 
own configuration language and caveats...

In squid.conf for Squid instance #i, you will use an icap_service 
directive to point that Squid instance #i to ICAP service #i (i.e. the 
ICAP service dedicated to Squid instance #i). There are more complicated 
ways to set this up, but this simple setup already addresses the 
requirements you have shared so far.


HTH,

Alex.



From my.shellac at gmail.com  Fri May 12 11:28:07 2023
From: my.shellac at gmail.com (=?UTF-8?B?QWxleGV50Y/RgCBHcnV6ZG92?=)
Date: Fri, 12 May 2023 16:28:07 +0500
Subject: [squid-users] cache_peer selection
Message-ID: <CAFqyDwB1Kp+9dwCSuSZFg3oYUBaLg0P_29XX8xzOHCW6pGBHVw@mail.gmail.com>

Hello Guys!

Thank you for your help that was before!

Could you explain somethings - For example I have a five cache_peer servers

peer1
peer2
peer3
peer4


And users like:

User-100
User-101

For forwarding requests over  existed cache_peer I use an external ACL and
"note" option - all works well.

Now I'd like to implement the next logic:
This is something like a failover of specified cache_peers for specified
user.

For example:
We send User-100 over peer1, if peer1 is failed - that User-100 must to go
over peer2.

For User-101 - something like - primary will be peer4, if its failed
User-101 must to go over peer3.

its something like primary and multiple of backup of cache_peer

etc....


Thank you !

Alexg
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230512/09d45359/attachment.htm>

From rousskov at measurement-factory.com  Fri May 12 14:53:03 2023
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 12 May 2023 10:53:03 -0400
Subject: [squid-users] cache_peer selection
In-Reply-To: <CAFqyDwB1Kp+9dwCSuSZFg3oYUBaLg0P_29XX8xzOHCW6pGBHVw@mail.gmail.com>
References: <CAFqyDwB1Kp+9dwCSuSZFg3oYUBaLg0P_29XX8xzOHCW6pGBHVw@mail.gmail.com>
Message-ID: <42979f46-868c-4b29-7456-73a1765ce2d6@measurement-factory.com>

On 5/12/23 07:28, Alexey?? Gruzdov wrote:
> Hello Guys!
> 
> Thank you for your help that was?before!
> 
> Could you explain somethings - For example I have a five cache_peer servers
> 
> peer1
> peer2
> peer3
> peer4
> 
> 
> And users like:
> 
> User-100
> User-101
> 
> For forwarding requests over? existed cache_peer I use an external ACL 
> and "note" option - all works well.
> 
> Now I'd like to implement the next logic:
> This is something like a failover of specified?cache_peers for specified 
> user.

If your external ACL can tell whether the peer has "failed", then the 
external ACL can annotate the transaction not to use that failed peer.

Otherwise, what you want may be possible using complex ACL tricks, but I 
am not sure, and do not have the time to explain/test those tricks. In 
short, you would need to create ACLs that detect peer selection stage[1] 
and select a different peer during different stages.

[1] https://wiki.squid-cache.org/Features/LoadBalance#go-through-a-peer


FWIW, dynamic peer selection with failover preference support is a known 
missing feature. Factory has implemented that feature[2], but we need 
more time to polish and submit our implementation for the official Squid 
Project consideration. With that feature, there is no need for the 
complex ACLs mentioned above because the ACL script simply tells Squid 
which peers to use for the transaction, in which failover order.

[2] https://github.com/measurement-factory/squid/pull/169


> For example:
> We send User-100 over peer1, if peer1 is failed - that User-100 must to 
> go over peer2.

Without code modifications, the above example will work because Squid 
will prefer peer1 to peer2, assuming that, in squid.conf, the cache_peer 
directive for peer1 is listed higher/earlier than that for peer2.


> For User-101 - something like - primary?will be peer4, if its?failed 
> User-101 must to go over peer3.

However, this example will _not_ work by default, for the same reason: 
When both peers are alive, Squid will prefer peer3 over peer4.


HTH,

Alex.


> its something like primary and multiple of backup of cache_peer
> 
> etc....
> 
> 
> Thank you !
> 
> Alexg
> 
> 
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Sun May 14 04:32:45 2023
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 14 May 2023 16:32:45 +1200
Subject: [squid-users] cache_peer selection
In-Reply-To: <42979f46-868c-4b29-7456-73a1765ce2d6@measurement-factory.com>
References: <CAFqyDwB1Kp+9dwCSuSZFg3oYUBaLg0P_29XX8xzOHCW6pGBHVw@mail.gmail.com>
 <42979f46-868c-4b29-7456-73a1765ce2d6@measurement-factory.com>
Message-ID: <89b02830-c8aa-cb9a-3b0a-6df5e824d3b1@treenet.co.nz>

On 13/05/2023 2:53 am, Alex Rousskov wrote:
> On 5/12/23 07:28, Alexey?? Gruzdov wrote:
>> Hello Guys!
>>
>> Thank you for your help that was?before!
>>
>> Could you explain somethings - For example I have a five cache_peer 
>> servers
>>
>> peer1
>> peer2
>> peer3
>> peer4
>>
>>
>> And users like:
>>
>> User-100
>> User-101
>>
>> For forwarding requests over? existed cache_peer I use an external 
>> ACL and "note" option - all works well.
>>
>> Now I'd like to implement the next logic:
>> This is something like a failover of specified?cache_peers for 
>> specified user.

One trick I use is to list each cache_peer twice (like: A1, B1, C1, A2 , 
B2, C2). Just use a different name= parameter for each cache_peer line.

That way I can "loop" the order when I want A,B to be a failover from C. 
Like this:? C1, A2, B2.

HTH
Amos



From squid3 at treenet.co.nz  Tue May 16 05:16:08 2023
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 16 May 2023 17:16:08 +1200
Subject: [squid-users] Bearer authentication released?
In-Reply-To: <DM6PR06MB44253A77FB170ACE07D3381FF16D9@DM6PR06MB4425.namprd06.prod.outlook.com>
References: <DM6PR06MB44253A77FB170ACE07D3381FF16D9@DM6PR06MB4425.namprd06.prod.outlook.com>
Message-ID: <35586180-e45b-6ea1-0c45-d91b34b688f3@treenet.co.nz>

On 5/05/2023 5:56 am, Zhang, Jinshu wrote:
>
> Hi There, I saw a feature page for bearer authentication. But seems to 
> me that is never merge into a release. Can any body update on that? If 
> it is
>
> released? If not, nay plan it will be? Thank you so much.
>

We use the Feature pages to indicate both existing and planned features 
under development.

As for OAuth Bearer authentication. Other than being a fair bit outdated 
the branch in my repository linked from that wiki page should be usable. 
You will need to write your own helper though.
I do have some plans for future updates, but those are going very slowly.


Cheers
Amos



From sachin1.g at gmail.com  Tue May 16 06:52:40 2023
From: sachin1.g at gmail.com (sachin gupta)
Date: Tue, 16 May 2023 12:22:40 +0530
Subject: [squid-users] host_verify_check behaviour in intercept mode for
 domain behind Loadbalancer ( multiple IPs )
Message-ID: <CALpWAcoujkPumOsVHfQhKYbPtMzfVttVycS-n7DFMxPXfWoOAQ@mail.gmail.com>

Hi

We recently shifted to squid 5.9 and started seeing errors in Transparent mode

SECURITY ALERT: Host header forgery detected on conn3615903
local=44.242.184.237:443 remote=10.109.176.240:8990 FD 28029 flags=17
(local IP does not match any domain IP)

Previously we were using
https://github.com/NethServer/dev/issues/5348. In addition we are
using client_dst_passthru off. When building 5.9, the patch was not
applied cleanly and we wanted to check if things worked without this
patch. They did not work.

I did check the forum responses
https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery. and
https://docs.diladele.com/faq/squid/host_header_forgery.html. We
already support explicit proxy but that is not always an option. We
can create another patch to circumvent issues like  in
https://github.com/NethServer/dev/issues/5348. But I wanted to know if
there is a plan to make this check optional or there is some way we
can workaround this problem without changing the code. Without this
support, how can intercept mode work for any website which is behind a
loadbalancer with multiple IPs.

Regards
Sachin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230516/504013a2/attachment.htm>

From squid3 at treenet.co.nz  Tue May 16 14:03:15 2023
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 17 May 2023 02:03:15 +1200
Subject: [squid-users] host_verify_check behaviour in intercept mode for
 domain behind Loadbalancer ( multiple IPs )
In-Reply-To: <CALpWAcoujkPumOsVHfQhKYbPtMzfVttVycS-n7DFMxPXfWoOAQ@mail.gmail.com>
References: <CALpWAcoujkPumOsVHfQhKYbPtMzfVttVycS-n7DFMxPXfWoOAQ@mail.gmail.com>
Message-ID: <69b3c42c-8a9a-24e3-737a-ac4bd5b48bad@treenet.co.nz>

On 16/05/2023 6:52 pm, sachin gupta wrote:
> Hi
> We recently shifted to squid 5.9 and started seeing errors in 
> Transparent mode SECURITY ALERT: Host header forgery detected on 
> conn3615903 local=44.242.184.237:443 <http://44.242.184.237:443> 
> remote=10.109.176.240:8990 <http://10.109.176.240:8990> FD 28029 
> flags=17 (local IP does not match any domain IP)

This is not a error, it is a alert to what is going on. The client 
10.109.176.240 is trying to connect to 44.242.184.237 requesting a 
domain which DNS says is **not** hosted there.

What happens next depends on what Squid is able to do given the 
transaction type.
Some are rejected as unable to continue, some are allowed to complete 
under restricted handling.

> Previously we were using 
> https://github.com/NethServer/dev/issues/5348. In addition we are 
> using client_dst_passthru off. When building 5.9, the patch was not 
> applied cleanly and we wanted to check if things worked without this 
> patch. They did not work.

Please clarify "things" and "did not work".

> I did check the forum responses 
> https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery. and 
> https://docs.diladele.com/faq/squid/host_header_forgery.html. We 
> already support explicit proxy but that is not always an option. We 
> can create another patch to circumvent issues like ***. But I wanted 
> to know if there is a plan to make this check optional or there is 
> some way we can workaround this problem without changing the code. 
> Without this support, how can intercept mode work for any website 
> which is behind a loadbalancer with multiple IPs.

More recent version of Squid allow some more CONNECT traffic cases be 
handled instead of rejected.
There are also some ideas on further improvements, but those are a long 
way off.

Cheers
Amos



From my.shellac at gmail.com  Thu May 18 06:58:48 2023
From: my.shellac at gmail.com (=?UTF-8?B?QWxleGV50Y/RgCBHcnV6ZG92?=)
Date: Thu, 18 May 2023 11:58:48 +0500
Subject: [squid-users] cache_peer round robin
Message-ID: <CAFqyDwDH=ndGepsHnCcCSX8iuM17LcQDa-i5AfGYLzexgqT6oA@mail.gmail.com>

Hello guys !


*1. Question Number 1: *

A day ago I met with strange things of squid working.

I have twenty of cache_peer and these all works in round-robin mode
that means each new requests will operated by new cache_peer.

For example the five  from these twenty cache_peer is down. But others is
OK and live ( this is fifteet)

When I run my tests script for check - that I can see the first around 10 -
30 seconds all looks OK and each new requests is going over next one
cache_peer.
But after these 10 - 30 seconds the round-robin mechanism stops to operate
and all new requests are going over one cache_peer (look like this is
FIRSTUP_PARENT but not the ROUNDROBIN_PARENT )


*2. Question Number 2:*

Is there some mechanism to use some external script based on the events of
squid?
for example - squid generates a log message like
    "Detected DEAD Parent: proxy_42662"    ( that means some one cache_peer
unavailable ) and will be great to listens these message and doing some
actions ( the easiest its notification )
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230518/ea8bc24c/attachment.htm>

From squid3 at treenet.co.nz  Sat May 20 11:58:04 2023
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 20 May 2023 23:58:04 +1200
Subject: [squid-users] cache_peer round robin
In-Reply-To: <CAFqyDwDH=ndGepsHnCcCSX8iuM17LcQDa-i5AfGYLzexgqT6oA@mail.gmail.com>
References: <CAFqyDwDH=ndGepsHnCcCSX8iuM17LcQDa-i5AfGYLzexgqT6oA@mail.gmail.com>
Message-ID: <948b50b3-dc49-c911-6324-246cd31f8d28@treenet.co.nz>

On 18/05/2023 6:58 pm, Alexey?? Gruzdov wrote:
> Hello guys !
>
>
> *1. Question Number 1: *
>
> A day ago I met with strange things of squid?working.
>
> I have twenty of cache_peer and these all works?in round-robin mode
> that means each new requests will operated by new cache_peer.
>
> For example the five? from these twenty?cache_peer is down. But others 
> is OK and live ( this is fifteet)
>
> When I run my tests script for check - that I can see the first around 
> 10 - 30 seconds all looks OK and each new requests?is going over next 
> one cache_peer.
> But after these 10 - 30 seconds the round-robin mechanism?stops to 
> operate and all new requests are going over one cache_peer (look like 
> this is FIRSTUP_PARENT but not the ROUNDROBIN_PARENT )

Which mechanism is your Squid using to detect the peer recovery?
Have you perhapse used "default" selection option on any of the peers?

What cache_peer lines are you using exactly? (IP/port can be obscured)



>
>
> *2. Question Number 2:*
>
> Is there some mechanism?to use some external script based on the 
> events of squid?
> for example - squid generates a log message like
> ? ? "Detected DEAD Parent: proxy_42662"? ? ( that means some one 
> cache_peer unavailable ) and will be great to listens these message 
> and doing some actions ( the easiest its notification )


Yes, but not for that particular event.

HTH
Amos



From my.shellac at gmail.com  Sat May 20 17:26:12 2023
From: my.shellac at gmail.com (=?UTF-8?B?QWxleGV50Y/RgCBHcnV6ZG92?=)
Date: Sat, 20 May 2023 22:26:12 +0500
Subject: [squid-users] cache_peer round robin
In-Reply-To: <948b50b3-dc49-c911-6324-246cd31f8d28@treenet.co.nz>
References: <CAFqyDwDH=ndGepsHnCcCSX8iuM17LcQDa-i5AfGYLzexgqT6oA@mail.gmail.com>
 <948b50b3-dc49-c911-6324-246cd31f8d28@treenet.co.nz>
Message-ID: <CAFqyDwA_-vgqM4p0uX3aM8GZze6kSjq-VNQU8QVUTCTPR2Z2ig@mail.gmail.com>

Hello !

About cache_peer section:
cache_peer 1.2.3.1 parent 40001 0 no-query no-digest proxy-only
name=proxy_1.2.3.1 round-robin
....
....
cache_peer 1.2.3.20 parent 40001 0 no-query no-digest proxy-only
name=proxy_1.2.3.20 round-robin



??, 20 ??? 2023??. ? 16:58, Amos Jeffries <squid3 at treenet.co.nz>:

> On 18/05/2023 6:58 pm, Alexey?? Gruzdov wrote:
> > Hello guys !
> >
> >
> > *1. Question Number 1: *
> >
> > A day ago I met with strange things of squid working.
> >
> > I have twenty of cache_peer and these all works in round-robin mode
> > that means each new requests will operated by new cache_peer.
> >
> > For example the five  from these twenty cache_peer is down. But others
> > is OK and live ( this is fifteet)
> >
> > When I run my tests script for check - that I can see the first around
> > 10 - 30 seconds all looks OK and each new requests is going over next
> > one cache_peer.
> > But after these 10 - 30 seconds the round-robin mechanism stops to
> > operate and all new requests are going over one cache_peer (look like
> > this is FIRSTUP_PARENT but not the ROUNDROBIN_PARENT )
>
> Which mechanism is your Squid using to detect the peer recovery?
> Have you perhapse used "default" selection option on any of the peers?
>
> What cache_peer lines are you using exactly? (IP/port can be obscured)
>
>
>
> >
> >
> > *2. Question Number 2:*
> >
> > Is there some mechanism to use some external script based on the
> > events of squid?
> > for example - squid generates a log message like
> >     "Detected DEAD Parent: proxy_42662"    ( that means some one
> > cache_peer unavailable ) and will be great to listens these message
> > and doing some actions ( the easiest its notification )
>
>
> Yes, but not for that particular event.
>
> HTH
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230520/f401b5b2/attachment.htm>

From squid3 at treenet.co.nz  Sat May 20 21:24:43 2023
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 21 May 2023 09:24:43 +1200
Subject: [squid-users] cache_peer round robin
In-Reply-To: <CAFqyDwA_-vgqM4p0uX3aM8GZze6kSjq-VNQU8QVUTCTPR2Z2ig@mail.gmail.com>
References: <CAFqyDwDH=ndGepsHnCcCSX8iuM17LcQDa-i5AfGYLzexgqT6oA@mail.gmail.com>
 <948b50b3-dc49-c911-6324-246cd31f8d28@treenet.co.nz>
 <CAFqyDwA_-vgqM4p0uX3aM8GZze6kSjq-VNQU8QVUTCTPR2Z2ig@mail.gmail.com>
Message-ID: <c7d3de8b-4a21-9864-c1bb-91aae26a50fd@treenet.co.nz>

On 21/05/2023 5:26 am, Alexey?? Gruzdov wrote:
> Hello !
>
> About cache_peer section:
> cache_peer 1.2.3.1 parent 40001 0 no-query no-digest proxy-only 
> name=proxy_1.2.3.1?round-robin
> ....
> ....
> cache_peer 1.2.3.20 parent 40001 0 no-query no-digest proxy-only 
> name=proxy_1.2.3.20?round-robin
>

Try removing the no-query options.

HTH
Amos



From my.shellac at gmail.com  Sat May 20 22:03:42 2023
From: my.shellac at gmail.com (=?UTF-8?B?QWxleGV50Y/RgCBHcnV6ZG92?=)
Date: Sun, 21 May 2023 03:03:42 +0500
Subject: [squid-users] cache_peer round robin
In-Reply-To: <c7d3de8b-4a21-9864-c1bb-91aae26a50fd@treenet.co.nz>
References: <CAFqyDwDH=ndGepsHnCcCSX8iuM17LcQDa-i5AfGYLzexgqT6oA@mail.gmail.com>
 <948b50b3-dc49-c911-6324-246cd31f8d28@treenet.co.nz>
 <CAFqyDwA_-vgqM4p0uX3aM8GZze6kSjq-VNQU8QVUTCTPR2Z2ig@mail.gmail.com>
 <c7d3de8b-4a21-9864-c1bb-91aae26a50fd@treenet.co.nz>
Message-ID: <CAFqyDwAJRf79sb=b49Ckoym3ES_XAmSjqcteghRKdFdt46_oqQ@mail.gmail.com>

Ok! Will try !
Thanks !
On Sun, 21 May 2023 at 02:25, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 21/05/2023 5:26 am, Alexey?? Gruzdov wrote:
> > Hello !
> >
> > About cache_peer section:
> > cache_peer 1.2.3.1 parent 40001 0 no-query no-digest proxy-only
> > name=proxy_1.2.3.1 round-robin
> > ....
> > ....
> > cache_peer 1.2.3.20 parent 40001 0 no-query no-digest proxy-only
> > name=proxy_1.2.3.20 round-robin
> >
>
> Try removing the no-query options.
>
> HTH
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230521/14b9895f/attachment.htm>

From my.shellac at gmail.com  Tue May 23 05:29:11 2023
From: my.shellac at gmail.com (=?UTF-8?B?QWxleGV50Y/RgCBHcnV6ZG92?=)
Date: Tue, 23 May 2023 10:29:11 +0500
Subject: [squid-users] cache_peer round robin
In-Reply-To: <CAFqyDwAJRf79sb=b49Ckoym3ES_XAmSjqcteghRKdFdt46_oqQ@mail.gmail.com>
References: <CAFqyDwDH=ndGepsHnCcCSX8iuM17LcQDa-i5AfGYLzexgqT6oA@mail.gmail.com>
 <948b50b3-dc49-c911-6324-246cd31f8d28@treenet.co.nz>
 <CAFqyDwA_-vgqM4p0uX3aM8GZze6kSjq-VNQU8QVUTCTPR2Z2ig@mail.gmail.com>
 <c7d3de8b-4a21-9864-c1bb-91aae26a50fd@treenet.co.nz>
 <CAFqyDwAJRf79sb=b49Ckoym3ES_XAmSjqcteghRKdFdt46_oqQ@mail.gmail.com>
Message-ID: <CAFqyDwDsQrjRYoqUD6YsqUYszSwSvGKA0XR8Bc_73_7QiS0fDg@mail.gmail.com>

Hello!

Looks like this doesn't help. And this affect is more pronounced if you add
more cache_peers and a lot of these doesn't alive.

For example:  If to have 50 whole of parent proxy, and ten of these is
alive  -  the squid hangs on the first UP parent and looks like it make
checking all other and looks like some timer expired and squid still
working with one first up parent, after some time (30 sec or 40 sec) the
round-robin works again for just one two next parent proxy, and then again
hangs on one parent
May be we could to change some response timer in cache_peer checking
procedure ?

Thank you.
Alexg

??, 21 ??? 2023??. ? 03:03, Alexey?? Gruzdov <my.shellac at gmail.com>:

>
> Ok! Will try !
> Thanks !
> On Sun, 21 May 2023 at 02:25, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
>> On 21/05/2023 5:26 am, Alexey?? Gruzdov wrote:
>> > Hello !
>> >
>> > About cache_peer section:
>> > cache_peer 1.2.3.1 parent 40001 0 no-query no-digest proxy-only
>> > name=proxy_1.2.3.1 round-robin
>> > ....
>> > ....
>> > cache_peer 1.2.3.20 parent 40001 0 no-query no-digest proxy-only
>> > name=proxy_1.2.3.20 round-robin
>> >
>>
>> Try removing the no-query options.
>>
>> HTH
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230523/947c37da/attachment.htm>

From ngtech1ltd at gmail.com  Tue May 23 15:35:54 2023
From: ngtech1ltd at gmail.com (NgTech LTD)
Date: Tue, 23 May 2023 18:35:54 +0300
Subject: [squid-users] maintenance period for ngtech www services
Message-ID: <CABA8h=TSJzHZBoxJ=iAQbn_bS9sNbzudR5wnJ_3k87FEaNAG0g@mail.gmail.com>

Hey List,

I have started working on couple things in my web services.
The services will be reachable only locally (IL) and later on this week
will be available again for the rest of the world.

Sorry for the in-convience (it's a surprise for me too).
If you need something just email me.

Eliezer
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230523/0a7d921d/attachment.htm>

From sachin1.g at gmail.com  Thu May 25 15:20:31 2023
From: sachin1.g at gmail.com (sachin gupta)
Date: Thu, 25 May 2023 20:50:31 +0530
Subject: [squid-users] TCP_TUNNEL/500 in squid logs in squid 5.9
Message-ID: <CALpWAcoD4NdJL78yU2o_9KvrKTc_jVLH0npDa-rE=j_BdDyOcg@mail.gmail.com>

Hi All

We are migrating for squid 4.15 to squid 5.9. We are running our existing
test suite to check if we pass our sanity testing.

For requests in transparent mode, though request passes and client get 200,
in squid logs we are getting TCP_TUNNEL/500. We were not getting this issue
with squid 4.15.

*Client logs*

curl -v https://origin/cache/0

*   Trying 10.80.96.68:443...

* TCP_NODELAY set

* Connected to origin (10.80.96.68) port 443 (#0)

* ALPN, offering h2

* ALPN, offering http/1.1

* Cipher selection:
ALL:!EXPORT:!EXPORT40:!EXPORT56:!aNULL:!LOW:!RC4:@STRENGTH

* successfully set certificate verify locations:

*   CAfile: /etc/pki/tls/certs/ca-bundle.crt

  CApath: none

* TLSv1.2 (OUT), TLS header, Certificate Status (22):

* TLSv1.2 (OUT), TLS handshake, Client hello (1):

* TLSv1.2 (IN), TLS handshake, Server hello (2):

* TLSv1.2 (IN), TLS handshake, Certificate (11):

* TLSv1.2 (IN), TLS handshake, Server key exchange (12):

* TLSv1.2 (IN), TLS handshake, Server finished (14):

* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):

* TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1):

* TLSv1.2 (OUT), TLS handshake, Finished (20):

* TLSv1.2 (IN), TLS change cipher, Change cipher spec (1):

* TLSv1.2 (IN), TLS handshake, Finished (20):

* SSL connection using TLSv1.2 / ECDHE-RSA-AES256-SHA

* ALPN, server did not agree to a protocol

* Server certificate:

*  subject: C=US; ST=CA; L=SF; O=SFDC;
OU=0:ns.tester;1:mvp;2:mist51;3:na44;4:dev1; CN=origin

*  start date: Jul 26 06:59:41 2022 GMT

*  expire date: Jul 26 06:59:41 2023 GMT

*  subjectAltName: host "origin" matched cert's "origin"

*  issuer: C=US; ST=CA; L=SF; O=SFDC; OU=Edge; CN=ca

*  SSL certificate verify ok.

> GET /cache/0 HTTP/1.1

> Host: origin

> User-Agent: curl/7.67.0

> Accept: */*

>

* Mark bundle as not supporting multiuse

< HTTP/1.1 200 OK

< Server: origin

< Date: Thu, 25 May 2023 15:08:57 GMT

< Connection: close

< Content-Type: application/json

< Content-Length: 162

< Cache-Control: public, max-age=0

< Access-Control-Allow-Origin: *

< Access-Control-Allow-Credentials: true

<

{"args":{},"headers":{"Accept":"*/*","Host":"origin","User-Agent":"curl/7.67.0","X-Origin-Server":"origin"},"origin":"10.80.96.3","url":"
https://origin/cache/0"}

* Closing connection 0

* TLSv1.2 (OUT), TLS alert, close notify (256):


Squid access logs


[25/May/2023:15:08:57]      31 10.80.96.6:51028 - NONE_NONE/000 0 CONNECT
10.80.96.68:443 tester HIER_NONE/- - - tester 746573746572 dagobah [-] -
[-] - [-] - 0 0 - - [origin]

[25/May/2023:15:08:57]     40 10.80.96.6:51028 - *TCP_TUNNEL/500* 800
CONNECT origin:443 tester HIER_DIRECT/origin 10.80.96.68 - tester
746573746572 dagobah [-] - [-] - [-] - 1969 2769 4 33 [origin]


Can someone please help in this.


Regards

Sachin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230525/7d8f166a/attachment.htm>

From sachin1.g at gmail.com  Fri May 26 12:22:50 2023
From: sachin1.g at gmail.com (sachin gupta)
Date: Fri, 26 May 2023 17:52:50 +0530
Subject: [squid-users] TCP_TUNNEL/500 in squid logs in squid 5.9
In-Reply-To: <CALpWAcoD4NdJL78yU2o_9KvrKTc_jVLH0npDa-rE=j_BdDyOcg@mail.gmail.com>
References: <CALpWAcoD4NdJL78yU2o_9KvrKTc_jVLH0npDa-rE=j_BdDyOcg@mail.gmail.com>
Message-ID: <CALpWAcqnEhk=dMsUkm8rcSEeigjAZXktkYT+4imU8PiosYH5qA@mail.gmail.com>

Hi

I also added some prints in ClientHttpRequest::logRequest  to see if it is
getting 500 from response.

 398     if (const auto reply = findReply()) {

 399

 400         debugs(33, 8, "SACHIN clientLogRequest: status='" <<
reply->sline.status() << "'");

 401         debugs(33, 8, "SACHIN clientLogRequest: body='" <<
reply->body.content() << "'");

 402         al->http.code = reply->sline.status();

 403         al->http.content_type = reply->content_type.termedBuf();

 404     }

 405

 406     debugs(33, 9, "clientLogRequest: http.code='" << al->http.code <<
"'");



The lines inside if ( 400-401 ) did not get printed but 406 got printed
with status code as 500. I also collected cache.log with debug level as 5
but mailing list is not allowing me to send that in mail.


Any suggestion for this behavior


Regards

Sachin

On Thu, May 25, 2023 at 8:50?PM sachin gupta <sachin1.g at gmail.com> wrote:

> Hi All
>
> We are migrating for squid 4.15 to squid 5.9. We are running our existing
> test suite to check if we pass our sanity testing.
>
> For requests in transparent mode, though request passes and client get
> 200, in squid logs we are getting TCP_TUNNEL/500. We were not getting this
> issue with squid 4.15.
>
> *Client logs*
>
> curl -v https://origin/cache/0
>
> *   Trying 10.80.96.68:443...
>
> * TCP_NODELAY set
>
> * Connected to origin (10.80.96.68) port 443 (#0)
>
> * ALPN, offering h2
>
> * ALPN, offering http/1.1
>
> * Cipher selection:
> ALL:!EXPORT:!EXPORT40:!EXPORT56:!aNULL:!LOW:!RC4:@STRENGTH
>
> * successfully set certificate verify locations:
>
> *   CAfile: /etc/pki/tls/certs/ca-bundle.crt
>
>   CApath: none
>
> * TLSv1.2 (OUT), TLS header, Certificate Status (22):
>
> * TLSv1.2 (OUT), TLS handshake, Client hello (1):
>
> * TLSv1.2 (IN), TLS handshake, Server hello (2):
>
> * TLSv1.2 (IN), TLS handshake, Certificate (11):
>
> * TLSv1.2 (IN), TLS handshake, Server key exchange (12):
>
> * TLSv1.2 (IN), TLS handshake, Server finished (14):
>
> * TLSv1.2 (OUT), TLS handshake, Client key exchange (16):
>
> * TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1):
>
> * TLSv1.2 (OUT), TLS handshake, Finished (20):
>
> * TLSv1.2 (IN), TLS change cipher, Change cipher spec (1):
>
> * TLSv1.2 (IN), TLS handshake, Finished (20):
>
> * SSL connection using TLSv1.2 / ECDHE-RSA-AES256-SHA
>
> * ALPN, server did not agree to a protocol
>
> * Server certificate:
>
> *  subject: C=US; ST=CA; L=SF; O=SFDC;
> OU=0:ns.tester;1:mvp;2:mist51;3:na44;4:dev1; CN=origin
>
> *  start date: Jul 26 06:59:41 2022 GMT
>
> *  expire date: Jul 26 06:59:41 2023 GMT
>
> *  subjectAltName: host "origin" matched cert's "origin"
>
> *  issuer: C=US; ST=CA; L=SF; O=SFDC; OU=Edge; CN=ca
>
> *  SSL certificate verify ok.
>
> > GET /cache/0 HTTP/1.1
>
> > Host: origin
>
> > User-Agent: curl/7.67.0
>
> > Accept: */*
>
> >
>
> * Mark bundle as not supporting multiuse
>
> < HTTP/1.1 200 OK
>
> < Server: origin
>
> < Date: Thu, 25 May 2023 15:08:57 GMT
>
> < Connection: close
>
> < Content-Type: application/json
>
> < Content-Length: 162
>
> < Cache-Control: public, max-age=0
>
> < Access-Control-Allow-Origin: *
>
> < Access-Control-Allow-Credentials: true
>
> <
>
>
> {"args":{},"headers":{"Accept":"*/*","Host":"origin","User-Agent":"curl/7.67.0","X-Origin-Server":"origin"},"origin":"10.80.96.3","url":"
> https://origin/cache/0"}
>
> * Closing connection 0
>
> * TLSv1.2 (OUT), TLS alert, close notify (256):
>
>
> Squid access logs
>
>
> [25/May/2023:15:08:57]      31 10.80.96.6:51028 - NONE_NONE/000 0 CONNECT
> 10.80.96.68:443 tester HIER_NONE/- - - tester 746573746572 dagobah [-] -
> [-] - [-] - 0 0 - - [origin]
>
> [25/May/2023:15:08:57]     40 10.80.96.6:51028 - *TCP_TUNNEL/500* 800
> CONNECT origin:443 tester HIER_DIRECT/origin 10.80.96.68 - tester
> 746573746572 dagobah [-] - [-] - [-] - 1969 2769 4 33 [origin]
>
>
> Can someone please help in this.
>
>
> Regards
>
> Sachin
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230526/a875903b/attachment.htm>

From ankor2023 at gmail.com  Mon May 29 14:43:03 2023
From: ankor2023 at gmail.com (Andrey K)
Date: Mon, 29 May 2023 17:43:03 +0300
Subject: [squid-users] Proxy server to support a large number of
 simultaneous requests
Message-ID: <CADJd0Y3ofecE0XsFBX+YG2P1HuMT9CCHoRQVE1=K8risZLhmkA@mail.gmail.com>

Hello,

We need to configure a dedicated proxy server to provide caching of online
video broadcasts in order to reduce the load on the uplink proxy.
Hundreds of users will access the same video-chunks simultaneously.

I developed a simple configuration for the test purposes (it is shown
below).
The *collapsed_forwarding* option is on.
I selected a couple of cacheable resources in the internet for testing:
 - small size (~400 KB):
https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf
 - large (~8 MB):
https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf
To test simultaneous connections I am forking curl using a simple script
(it is also shown below).

When I run a test (500 curl threads to
https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf)
I see lots of TCP_MISS/200 with FIRSTUP_PARENT/parent_proxy records in the
logs.

A simple analysis shows a low percentage of cache hits:
cat /var/log/squid.user/access.log| grep '2023-05-29 14' | grep pdf  | awk
'{print $5" " $10}' | sort | uniq -c
     24 TCP_CF_MISS/200/- HIER_NONE/-
    457 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
     10 TCP_MISS/200/- HIER_NONE/-
      9 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy

So the Hit ratio is about (500-457-9)*100/500=6.8%

Almost the same situation we see when run 200 threads:
cat /var/log/squid.user/access.log| grep '2023-05-29 15:45' | grep pdf  |
awk '{print $5" " $10}' | sort | uniq -c
      4 TCP_CF_MISS/200/- HIER_NONE/-
    140 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
     40 TCP_MISS/200/- HIER_NONE/-
     16 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy

This time the Hit ratio is about (200-140-16)*100/500=21%

With 50 threads the Hit ratio is 90%:
cat /var/log/squid.user/access.log| grep '2023-05-29 15:50' | grep pdf  |
awk '{print $5" " $10}' | sort | uniq -c
     27 TCP_CF_MISS/200/- HIER_NONE/-
      1 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
     18 TCP_MISS/200/- HIER_NONE/-
      4 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy

I thought that it should always be near 99% - only the first request to an
URL should be forwarded to the parent proxy and all subsequent requests
should be served from the cache.

The situation is even worse with downloading a large file:
500 threads (0.4%):
cat /var/log/squid.user/access.log| grep '2023-05-29 17:2' | grep pdf  |
awk '{print $5" " $10}' | sort | uniq -c
     10 TCP_CF_MISS/200/200 FIRSTUP_PARENT/parent_proxy
      2 TCP_CF_MISS/200/- HIER_NONE/-
    488 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy

200 threads (3%):
cat /var/log/squid.user/access.log| grep '2023-05-29 17:3' | grep pdf  |
awk '{print $5" " $10}' | sort | uniq -c
      9 TCP_CF_MISS/200/200 FIRSTUP_PARENT/parent_proxy
      6 TCP_CF_MISS/200/- HIER_NONE/-
    180 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
      5 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy

50 threads (98%):
 cat /var/log/squid.user/access.log| grep '2023-05-29 17:36' | grep pdf  |
awk '{print $5" " $10}' | sort | uniq -c
     25 TCP_CF_HIT/200/- HIER_NONE/-
     12 TCP_CF_MISS/200/- HIER_NONE/-
     12 TCP_HIT/200/- HIER_NONE/-
      1 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy

Could you clarify if this behavior of my squid is a bug/misconfiguration,
or if I'm running into server performance limitations (squid is running on
a VM with 22 cores)?

Kind regards,
     Ankor



*squid.conf:*
workers 21

sslcrtd_program /data/squid.user/usr/lib/squid/security_file_certgen -s
/data/squid.user/var/lib/squid/ssl_db -M 20MB
sslcrtd_children 21

logformat extended-squid %{%Y-%m-%d %H:%M:%S}tl| %6tr %>a %Ss/%03>Hs/%<Hs
%<st %rm %ru %un %Sh/%<A %mt %ea

logfile_rotate 0
access_log daemon:/var/log/squid.user/access.log logformat=extended-squid
on-error=drop

cache_peer parent_proxy  parent 3128 0
never_direct allow all

cachemgr_passwd pass config

acl PURGE method PURGE
http_access allow PURGE

http_access allow all

http_port 3131 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=20MB tls-cert=/etc/squid.user/sslbump/bump.crt
tls-key=/etc/squid.user/sslbump/bump.key
sslproxy_cert_error allow all

acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3

ssl_bump peek step1
ssl_bump bump step2
ssl_bump bump step3

cache_dir rock /data/squid.user/cache 20000 max-size=12000000
cache_swap_low 85
cache_swap_high 90

*collapsed_forwarding on*

pinger_enable off
max_filedesc 8192
shutdown_lifetime 5 seconds
netdb_filename none
log_icp_queries off
client_request_buffer_max_size 100 MB

via off
forwarded_for delete

coredump_dir /data/squid.user/var/cache/squid

*curl_forker.sh:*
#!/bin/sh
N=100
URL=
https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf

if [[  -n $1 &&  $1 =~ help$  ]];
then
   echo "Usage: $0 [<cnt>] [<url>]"
   echo
   echo "Example: $0 10
https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf
";
   echo
   exit;
fi

while [[ $# -gt 0 ]]
do
  if [[ $1 =~ ^[0-9]+$ ]]
  then
     N=$1
  else
     URL=$1
  fi
  shift
done

echo $URL
echo $N threads

for i in `seq $N`
do
  nohup curl --tlsv1.2 -k   --proxy 0001vsg01:3131  -v $URL  >/dev/null
 2>&1 &
done
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230529/289f1cca/attachment.htm>

From rousskov at measurement-factory.com  Mon May 29 20:16:35 2023
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 29 May 2023 16:16:35 -0400
Subject: [squid-users] Proxy server to support a large number of
 simultaneous requests
In-Reply-To: <CADJd0Y3ofecE0XsFBX+YG2P1HuMT9CCHoRQVE1=K8risZLhmkA@mail.gmail.com>
References: <CADJd0Y3ofecE0XsFBX+YG2P1HuMT9CCHoRQVE1=K8risZLhmkA@mail.gmail.com>
Message-ID: <4f506ba3-c1aa-feab-8cbd-8b86861364c9@measurement-factory.com>

On 5/29/23 10:43, Andrey K wrote:

> We need to configure a dedicated proxy server to provide caching of 
> online video broadcasts in order to reduce the load on the uplink proxy.
> Hundreds of users will access the same video-chunks simultaneously.
> 
> I developed a simple configuration for the test purposes (it is shown 
> below).
> The *collapsed_forwarding*?option is on.

Do you get close to 100% hit ratio if clients access these URLs 
sequentially rather than concurrently? If not, then focus on that 
problem before you open the collapsed forwarding Pandora box.

What is your Squid version? Older Squids have more collapsed forwarding 
bugs than newer ones. I recommend testing with Squid v6 or master/v7, at 
least to confirm that the problem is still present in the latest 
official code.

How much RAM does your server have? You are using default 256MB memory 
cache (cache_mem). If you have spare memory, make your memory cache much 
larger: A rock cache_dir cannot (yet) share the response _while_ the 
response is being written to disk, so relying on cache_dir too much will 
decrease your hit ratio, especially in a collapsed forwarding environment.

Is your Squid built with --enable-delay-pools? If yes, TCP_MISS does not 
necessarily mean a cache miss (an old Squid bug), even if you do not use 
any delay pools.

Since you are trying to cache objects lager than 512KB, see 
maximum_object_size_in_memory.

Consider making your test much longer (more sequential requests per 
client/curl worker), to see whether the cache becomes "stable" after one 
of the first transactions manages to fully cache the response. This may 
not help with older Squids, but might help with newer ones. However, you 
should not test using real origin servers (that you do not control)!


> Could you clarify if this behavior of my squid is 
> a bug/misconfiguration, or if I'm running into server performance
> limitations (squid is running on a VM with 22 cores)?

Most likely, reduction of hit ratio with increase of concurrency is 
_not_ a performance limitation.


HTH,

Alex.


> I selected a couple of cacheable resources in the internet for testing:
>  ?- small size (~400 KB): 
> https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf <https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf>
>  ?- large (~8 MB): 
> https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf <https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf>
> To test simultaneous connections I am forking curl using a simple script 
> (it is also shown below).
> 
> When I run a test (500 curl threads to 
> https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf <https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf>) I see lots of?TCP_MISS/200 with?FIRSTUP_PARENT/parent_proxy records in the logs.
> 
> A simple analysis shows?a low percentage of cache hits:
> cat /var/log/squid.user/access.log| grep '2023-05-29 14' | grep pdf ?| 
> awk '{print $5" " $10}' | sort | uniq -c
>  ? ? ?24 TCP_CF_MISS/200/- HIER_NONE/-
>  ? ? 457 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>  ? ? ?10 TCP_MISS/200/- HIER_NONE/-
>  ? ? ? 9 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> 
> So the Hit ratio is about (500-457-9)*100/500=6.8%
> 
> Almost the same situation we see when run 200 threads:
> cat /var/log/squid.user/access.log| grep '2023-05-29 15:45' | grep pdf 
>  ?| awk '{print $5" " $10}' | sort | uniq -c
>  ? ? ? 4 TCP_CF_MISS/200/- HIER_NONE/-
>  ? ? 140 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>  ? ? ?40 TCP_MISS/200/- HIER_NONE/-
>  ? ? ?16 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> 
> This time the Hit ratio is about (200-140-16)*100/500=21%
> 
> With 50 threads the Hit ratio is 90%:
> cat /var/log/squid.user/access.log| grep '2023-05-29 15:50' | grep pdf 
>  ?| awk '{print $5" " $10}' | sort | uniq -c
>  ? ? ?27 TCP_CF_MISS/200/- HIER_NONE/-
>  ? ? ? 1 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>  ? ? ?18 TCP_MISS/200/- HIER_NONE/-
>  ? ? ? 4 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> 
> I thought that it should always be near 99% - only the first request to 
> an URL should be forwarded to the parent proxy and all subsequent 
> requests should be served from the cache.
> 
> The situation is even worse with downloading a large file:
> 500 threads (0.4%):
> cat /var/log/squid.user/access.log| grep '2023-05-29 17:2' | grep pdf ?| 
> awk '{print $5" " $10}' | sort | uniq -c
>  ? ? ?10 TCP_CF_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>  ? ? ? 2 TCP_CF_MISS/200/- HIER_NONE/-
>  ? ? 488 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> 
> 200 threads (3%):
> cat /var/log/squid.user/access.log| grep '2023-05-29 17:3' | grep pdf ?| 
> awk '{print $5" " $10}' | sort | uniq -c
>  ? ? ? 9 TCP_CF_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>  ? ? ? 6 TCP_CF_MISS/200/- HIER_NONE/-
>  ? ? 180 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>  ? ? ? 5 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> 
> 50 threads (98%):
> cat /var/log/squid.user/access.log| grep '2023-05-29 17:36' | grep pdf 
>  ?| awk '{print $5" " $10}' | sort | uniq -c
>  ? ? ?25 TCP_CF_HIT/200/- HIER_NONE/-
>  ? ? ?12 TCP_CF_MISS/200/- HIER_NONE/-
>  ? ? ?12 TCP_HIT/200/- HIER_NONE/-
>  ? ? ? 1 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> 
> Could you clarify if this behavior of my squid is a 
> bug/misconfiguration, or if I'm running into server performance 
> limitations (squid is running on a VM with 22 cores)?
> 
> Kind regards,
>  ? ? ?Ankor
> 
> 
> 
> *squid.conf:*
> workers 21
> 
> sslcrtd_program /data/squid.user/usr/lib/squid/security_file_certgen -s 
> /data/squid.user/var/lib/squid/ssl_db -M 20MB
> sslcrtd_children 21
> 
> logformat extended-squid %{%Y-%m-%d %H:%M:%S}tl| %6tr %>a 
> %Ss/%03>Hs/%<Hs %<st %rm %ru %un %Sh/%<A %mt %ea
> 
> logfile_rotate 0
> access_log daemon:/var/log/squid.user/access.log 
> logformat=extended-squid on-error=drop
> 
> cache_peer parent_proxy ?parent 3128 0
> never_direct allow all
> 
> cachemgr_passwd pass config
> 
> acl PURGE method PURGE
> http_access allow PURGE
> 
> http_access allow all
> 
> http_port 3131 ssl-bump generate-host-certificates=on 
> dynamic_cert_mem_cache_size=20MB 
> tls-cert=/etc/squid.user/sslbump/bump.crt 
> tls-key=/etc/squid.user/sslbump/bump.key
> sslproxy_cert_error allow all
> 
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> 
> ssl_bump peek step1
> ssl_bump bump step2
> ssl_bump bump step3
> 
> cache_dir rock /data/squid.user/cache 20000 max-size=12000000
> cache_swap_low 85
> cache_swap_high 90
> 
> *collapsed_forwarding on*
> 
> pinger_enable off
> max_filedesc 8192
> shutdown_lifetime 5 seconds
> netdb_filename none
> log_icp_queries off
> client_request_buffer_max_size 100 MB
> 
> via off
> forwarded_for delete
> 
> coredump_dir /data/squid.user/var/cache/squid
> 
> *curl_forker.sh:*
> #!/bin/sh
> N=100
> URL=https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf <https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf>
> 
> if [[ ?-n $1 && ?$1 =~ help$ ?]];
> then
>  ? ?echo "Usage: $0 [<cnt>] [<url>]"
>  ? ?echo
>  ? ?echo "Example: $0 10 
> https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf <https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf>";
>  ? ?echo
>  ? ?exit;
> fi
> 
> while [[ $# -gt 0 ]]
> do
>  ? if [[ $1 =~ ^[0-9]+$ ]]
>  ? then
>  ? ? ?N=$1
>  ? else
>  ? ? ?URL=$1
>  ? fi
>  ? shift
> done
> 
> echo $URL
> echo $N threads
> 
> for i in `seq $N`
> do
>  ? nohup curl --tlsv1.2 -k ? --proxy 0001vsg01:3131 ?-v $URL ?>/dev/null 
>  ?2>&1 &
> done
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From sachin1.g at gmail.com  Tue May 30 11:22:23 2023
From: sachin1.g at gmail.com (sachin gupta)
Date: Tue, 30 May 2023 16:52:23 +0530
Subject: [squid-users] host_verify_check behaviour in intercept mode for
 domain behind Loadbalancer ( multiple IPs )
In-Reply-To: <69b3c42c-8a9a-24e3-737a-ac4bd5b48bad@treenet.co.nz>
References: <CALpWAcoujkPumOsVHfQhKYbPtMzfVttVycS-n7DFMxPXfWoOAQ@mail.gmail.com>
 <69b3c42c-8a9a-24e3-737a-ac4bd5b48bad@treenet.co.nz>
Message-ID: <CALpWAcqK0VzXvJ5J8606hy70MJc944jt22H=To5S=kFXkPAAYg@mail.gmail.com>

Hi

I am sorry to come back late on it. I had applied patch and my previous
logs were overwritten. Reproduced it today with amazon url (
monitoring.us-west-2.amazonaws.com:443 )


>> Please clarify "things" and "did not work".

We are getting 409. For example this if or one on amazon url cache.log
output

2023/05/30 10:38:04.703 kid5| 78,8| dns_internal.cc(1126)
idnsCallbackAllCallersWithNewAnswer: last 1 records

2023/05/30 10:38:04.703 kid5| 1,5| CodeContext.cc(60) Entering: master203

2023/05/30 10:38:04.703 kid5| 78,6| dns_internal.cc(1104)
idnsCallbackOneWithAnswer: last 1 records for 0x556b994c6f68

2023/05/30 10:38:04.704 kid5| 14,3| ipcache.cc(477) ipcacheParse: 1 answers
for monitoring.us-west-2.amazonaws.com

2023/05/30 10:38:04.704 kid5| 14,7| ipcache.cc(985) have:  no 52.94.176.210
in [no cached IPs]

2023/05/30 10:38:04.704 kid5| 14,7| ipcache.cc(985) have:  no 52.94.176.210
in [no cached IPs]

2023/05/30 10:38:04.704 kid5| 14,3| ipcache.cc(532) addGood:
monitoring.us-west-2.amazonaws.com #1 52.94.176.210

2023/05/30 10:38:04.704 kid5| 14,7| ipcache.cc(250) forwardIp: 52.94.176.210

2023/05/30 10:38:04.704 kid5| 14,3| ipcache.cc(576) ipcacheHandleReply:
done with monitoring.us-west-2.amazonaws.com: 52.94.176.210 #1/1-0

2023/05/30 10:38:04.704 kid5| 14,7| ipcache.cc(231) finalCallback:
0x556b994c6f88 lookup_wait=1

2023/05/30 10:38:04.704 kid5| 78,7| HttpRequest.cc(595) recordLookup:
0x556b994c6570 lookup_wait=1

2023/05/30 10:38:04.704 kid5| 14,7| ipcache.cc(985) have:  no
52.94.184.173:443 in 52.94.176.210 #1/1-0

2023/05/30 10:38:04.704 kid5| 85,3| client_side_request.cc(538)
hostHeaderIpVerify: FAIL: validate IP 52.94.184.173:443 possible from Host:

2023/05/30 10:38:04.704 kid5| SECURITY ALERT: Host header forgery detected
on conn616 local=52.94.184.173:443 remote=10.32.79.33:58260 FD 28 flags=17
(local IP does not match any domain IP)

    current master transaction: master203

2023/05/30 10:38:04.704 kid5| SECURITY ALERT: on URL:
monitoring.us-west-2.amazonaws.com:443

    current master transaction: master203

2023/05/30 10:38:04.704 kid5| 20,3| store.cc(769) storeCreatePureEntry:
storeCreateEntry: 'monitoring.us-west-2.amazonaws.com:443'

2023/05/30 10:38:04.704 kid5| 20,5| store.cc(349) StoreEntry: StoreEntry
constructed, this=0x556b994f0200

2023/05/30 10:38:04.704 kid5| 19,9| stmem.cc(376) mem_hdr: 0x556b994ef648
hi: 0

2023/05/30 10:38:04.704 kid5| 20,3| MemObject.cc(100) MemObject: MemObject
constructed, this=0x556b994ef620

2023/05/30 10:38:04.704 kid5| 55,7| HttpHeader.cc(155) HttpHeader: init-ing
hdr: 0x556b994ef788 owner: 3

2023/05/30 10:38:04.704 kid5| 55,9| HttpHeader.cc(829) getList:
0x556b994ef788 joining for id Connection[12]

2023/05/30 10:38:04.704 kid5| 55,9| HttpHeader.cc(829) getList:
0x556b994ef788 joining for id Proxy-Connection[50]

2023/05/30 10:38:04.704 kid5| 55,9| HttpHeader.cc(1009) has: 0x556b994ef788
lookup for Expires[27]

2023/05/30 10:38:04.704 kid5| 88,3| MemObject.cc(83) setUris:
0x556b994ef620 storeId: monitoring.us-west-2.amazonaws.com:443

2023/05/30 10:38:04.704 kid5| 20,3| store.cc(443) lock: storeCreateEntry
locked key [null_store_key] e:=V/0x556b994f0200*1

2023/05/30 10:38:04.704 kid5| 20,3| store.cc(569) setPrivateKey: 01
e:=V/0x556b994f0200*1

2023/05/30 10:38:04.704 kid5| 20,3| store.cc(421) hashInsert:
StoreEntry::hashInsert: Inserting Entry e:=XIV/0x556b994f0200*1 key
'0C000000000000003400000005000000'

2023/05/30 10:38:04.704 kid5| 4,4| errorpage.cc(717) errorAppendEntry:
storing ERR_CONFLICT_HOST in e:=XIV/0x556b994f0200*1

2023/05/30 10:38:04.704 kid5| 55,7| HttpHeader.cc(155) HttpHeader: init-ing
hdr: 0x556b994ef8b8 owner: 3

2023/05/30 10:38:04.704 kid5| 55,9| HttpHeader.cc(829) getList:
0x556b994ef8b8 joining for id Connection[12]

2023/05/30 10:38:04.704 kid5| 55,9| HttpHeader.cc(829) getList:
0x556b994ef8b8 joining for id Proxy-Connection[50]

2023/05/30 10:38:04.704 kid5| 55,9| HttpHeader.cc(1009) has: 0x556b994ef8b8
lookup for Expires[27]

2023/05/30 10:38:04.704 kid5| 55,9| HttpHeader.cc(829) getList:
0x556b994c6588 joining for id Accept-Language[3]

2023/05/30 10:38:04.704 kid5| 4,2| errorpage.cc(1386) buildBody: No
existing error page language negotiated for ERR_CONFLICT_HOST. Using
default error file.


Regards
Sachin


On Tue, May 16, 2023 at 7:33?PM Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 16/05/2023 6:52 pm, sachin gupta wrote:
> > Hi
> > We recently shifted to squid 5.9 and started seeing errors in
> > Transparent mode SECURITY ALERT: Host header forgery detected on
> > conn3615903 local=44.242.184.237:443 <http://44.242.184.237:443>
> > remote=10.109.176.240:8990 <http://10.109.176.240:8990> FD 28029
> > flags=17 (local IP does not match any domain IP)
>
> This is not a error, it is a alert to what is going on. The client
> 10.109.176.240 is trying to connect to 44.242.184.237 requesting a
> domain which DNS says is **not** hosted there.
>
> What happens next depends on what Squid is able to do given the
> transaction type.
> Some are rejected as unable to continue, some are allowed to complete
> under restricted handling.
>
> > Previously we were using
> > https://github.com/NethServer/dev/issues/5348. In addition we are
> > using client_dst_passthru off. When building 5.9, the patch was not
> > applied cleanly and we wanted to check if things worked without this
> > patch. They did not work.
>
> Please clarify "things" and "did not work".
>
> > I did check the forum responses
> > https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery. and
> > https://docs.diladele.com/faq/squid/host_header_forgery.html. We
> > already support explicit proxy but that is not always an option. We
> > can create another patch to circumvent issues like ***. But I wanted
> > to know if there is a plan to make this check optional or there is
> > some way we can workaround this problem without changing the code.
> > Without this support, how can intercept mode work for any website
> > which is behind a loadbalancer with multiple IPs.
>
> More recent version of Squid allow some more CONNECT traffic cases be
> handled instead of rejected.
> There are also some ideas on further improvements, but those are a long
> way off.
>
> Cheers
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230530/95d4ce92/attachment.htm>

From ankor2023 at gmail.com  Wed May 31 06:56:28 2023
From: ankor2023 at gmail.com (Andrey K)
Date: Wed, 31 May 2023 09:56:28 +0300
Subject: [squid-users] Proxy server to support a large number of
 simultaneous requests
In-Reply-To: <4f506ba3-c1aa-feab-8cbd-8b86861364c9@measurement-factory.com>
References: <CADJd0Y3ofecE0XsFBX+YG2P1HuMT9CCHoRQVE1=K8risZLhmkA@mail.gmail.com>
 <4f506ba3-c1aa-feab-8cbd-8b86861364c9@measurement-factory.com>
Message-ID: <CADJd0Y16ZsmBCFzeKM4RSCDs0hi+AuJRu=iqgayfe4FEBmqQEA@mail.gmail.com>

Hello, Alex,

Thank you for the recommendations.

> Do you get close to 100% hit ratio if clients access these URLs
> sequentially rather than concurrently? If not, then focus on that
> problem before you open the collapsed forwarding Pandora box.
When I run curl sequentially like this:
for i in `seq 500`; do curl --tlsv1.2 -k   --proxy 0001vsg01:3131  -v
$URL  >/dev/null 2>&1; done
I get only the first request with a status TCP_MISS and all others with
TCP_MEM_HIT:
    Cnt Status            Parent
    499 TCP_MEM_HIT/200/- HIER_NONE/-
      1 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy


> What is your Squid version? Older Squids have more collapsed forwarding
> bugs than newer ones. I recommend testing with Squid v6 or master/v7, at
> least to confirm that the problem is still present in the latest
> official code.
I run tests on SQUID 5.9.
We compiled 6.0.2 (with disabled delay-pools) and increased memory
parameters:
  cache_mem 2048 MB
  maximum_object_size_in_memory 10 MB
The complete configuration is shown below.

Now on the version 6.0.2 we have the next results:
500 threads -  Hit ratio 3.8%:
      3 TCP_CF_HIT/200/- HIER_NONE/-
      2 TCP_CF_MISS/200/200 FIRSTUP_PARENT/parent_proxy
     16 TCP_HIT/200/- HIER_NONE/-
    467 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
     12 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy

200 threads - 6%
      6 TCP_CF_HIT/200/- HIER_NONE/-
     10 TCP_HIT/200/- HIER_NONE/-
    176 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
      8 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy

50 threads - 82%
     30 TCP_CF_HIT/200/- HIER_NONE/-
     11 TCP_HIT/200/- HIER_NONE/-
      1 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
      8 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy

The results are slightly worse than they were on the version 5.9.
It is interesting to note that on both squid versions if I run a separate
curl after processing 500 or 200 concurrent threads, I get a result with
the status  TCP_MISS/200, although the requested URL is already in the rock
cache (I can see it in the contents of the cache using the utility I
developed rock_cache_dump.pl:
$VAR1 = {
          '1' => {
                   'VERSION' => 'Wed May 31 09:18:05 2023',
                   'KEY_MD5' => 'e5eb10f0ab7d84ff9d3fd1e5a6d3eb9c',
                   'OBJSIZE' => 446985,
                   'STD_LFS' => {
                                  'lastref' => 'Wed May 31 09:18:05 2023',
                                  'flags' => '0x4004',
                                  'expires' => 'Wed May 31 15:18:05 2023',
                                  'swap_file_sz' => 0,
                                  'refcount' => 1,
                                  'lastmod' => 'Wed Jun 29 16:09:14 2016',
                                  'timestamp' => 'Wed May 31 09:18:05 2023'
                                },
                   'URL' => '
https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf
'
                 }
        };

).

> How much RAM does your server have? You are using default 256MB memory
> cache (cache_mem). If you have spare memory, make your memory cache much
> larger: A rock cache_dir cannot (yet) share the response _while_ the
> response is being written to disk, so relying on cache_dir too much will
> decrease your hit ratio, especially in a collapsed forwarding environment.
The VM has 32 GB RAM. I configured cache_mem 2048 MB on the 6.0.2 version.

> Is your Squid built with --enable-delay-pools? If yes, TCP_MISS does not
> necessarily mean a cache miss (an old Squid bug), even if you do not use
> any delay pools.
Yes, delay pools on the version 5.9 were enabled though we don't use them.
I disabled this feature on the 6.0.2 version.


> Since you are trying to cache objects lager than 512KB, see
> maximum_object_size_in_memory.
I configured  maximum_object_size_in_memory 10 MB on the 6.0.2 version (as
video chunks are less than 7 MB).

> Consider making your test much longer (more sequential requests per
> client/curl worker), to see whether the cache becomes "stable" after one
> of the first transactions manages to fully cache the response. This may
> not help with older Squids, but might help with newer ones. However, you
> should not test using real origin servers (that you do not control)!
I don't have any of my own web servers for tests, so I choose some
resources on the public internet that have a robust infrastructure.
I will conduct the longer tests next week.

Kind regards,
      Ankor.

*squid.conf*
workers 21

sslcrtd_program /data/squid.user/usr/lib/squid/security_file_certgen -s
/data/squid.user/var/lib/squid/ssl_db -M 20MB
sslcrtd_children 21

logformat extended-squid %{%Y-%m-%d %H:%M:%S}tl| %6tr %>a %Ss/%03>Hs/%<Hs
%<st %rm %ru %un %Sh/%<A %mt %ea

logfile_rotate 0
access_log daemon:/var/log/squid.user/access.log logformat=extended-squid
on-error=drop

cache_peer parent_proxy  parent 3128 0
never_direct allow all

cachemgr_passwd pass config

acl PURGE method PURGE
http_access allow PURGE

http_access allow all

http_port 3131 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=20MB tls-cert=/etc/squid.user/sslbump/bump.crt
tls-key=/etc/squid.user/sslbump/bump.key
sslproxy_cert_error allow all

acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3

ssl_bump peek step1
ssl_bump bump step2
ssl_bump bump step3

cache_dir rock /data/squid.user/cache 20000 max-size=12000000
cache_swap_low 85
cache_swap_high 90

collapsed_forwarding on
cache_mem 2048 MB
maximum_object_size_in_memory 10 MB

pinger_enable off
max_filedesc 8192
shutdown_lifetime 5 seconds
netdb_filename none
log_icp_queries off

via off
forwarded_for delete

client_request_buffer_max_size 100 MB

coredump_dir /data/squid.user/var/cache/squid




??, 29 ??? 2023??. ? 23:17, Alex Rousskov <rousskov at measurement-factory.com
>:

> On 5/29/23 10:43, Andrey K wrote:
>
> > We need to configure a dedicated proxy server to provide caching of
> > online video broadcasts in order to reduce the load on the uplink proxy.
> > Hundreds of users will access the same video-chunks simultaneously.
> >
> > I developed a simple configuration for the test purposes (it is shown
> > below).
> > The *collapsed_forwarding* option is on.
>
> Do you get close to 100% hit ratio if clients access these URLs
> sequentially rather than concurrently? If not, then focus on that
> problem before you open the collapsed forwarding Pandora box.
>
> What is your Squid version? Older Squids have more collapsed forwarding
> bugs than newer ones. I recommend testing with Squid v6 or master/v7, at
> least to confirm that the problem is still present in the latest
> official code.
>
> How much RAM does your server have? You are using default 256MB memory
> cache (cache_mem). If you have spare memory, make your memory cache much
> larger: A rock cache_dir cannot (yet) share the response _while_ the
> response is being written to disk, so relying on cache_dir too much will
> decrease your hit ratio, especially in a collapsed forwarding environment.
>
> Is your Squid built with --enable-delay-pools? If yes, TCP_MISS does not
> necessarily mean a cache miss (an old Squid bug), even if you do not use
> any delay pools.
>
> Since you are trying to cache objects lager than 512KB, see
> maximum_object_size_in_memory.
>
> Consider making your test much longer (more sequential requests per
> client/curl worker), to see whether the cache becomes "stable" after one
> of the first transactions manages to fully cache the response. This may
> not help with older Squids, but might help with newer ones. However, you
> should not test using real origin servers (that you do not control)!
>
>
> > Could you clarify if this behavior of my squid is
> > a bug/misconfiguration, or if I'm running into server performance
> > limitations (squid is running on a VM with 22 cores)?
>
> Most likely, reduction of hit ratio with increase of concurrency is
> _not_ a performance limitation.
>
>
> HTH,
>
> Alex.
>
>
> > I selected a couple of cacheable resources in the internet for testing:
> >   - small size (~400 KB):
> >
> https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf
> <
> https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf
> >
> >   - large (~8 MB):
> >
> https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf
> <
> https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf
> >
> > To test simultaneous connections I am forking curl using a simple script
> > (it is also shown below).
> >
> > When I run a test (500 curl threads to
> >
> https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf
> <
> https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf>)
> I see lots of TCP_MISS/200 with FIRSTUP_PARENT/parent_proxy records in the
> logs.
> >
> > A simple analysis shows a low percentage of cache hits:
> > cat /var/log/squid.user/access.log| grep '2023-05-29 14' | grep pdf  |
> > awk '{print $5" " $10}' | sort | uniq -c
> >       24 TCP_CF_MISS/200/- HIER_NONE/-
> >      457 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> >       10 TCP_MISS/200/- HIER_NONE/-
> >        9 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> >
> > So the Hit ratio is about (500-457-9)*100/500=6.8%
> >
> > Almost the same situation we see when run 200 threads:
> > cat /var/log/squid.user/access.log| grep '2023-05-29 15:45' | grep pdf
> >   | awk '{print $5" " $10}' | sort | uniq -c
> >        4 TCP_CF_MISS/200/- HIER_NONE/-
> >      140 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> >       40 TCP_MISS/200/- HIER_NONE/-
> >       16 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> >
> > This time the Hit ratio is about (200-140-16)*100/500=21%
> >
> > With 50 threads the Hit ratio is 90%:
> > cat /var/log/squid.user/access.log| grep '2023-05-29 15:50' | grep pdf
> >   | awk '{print $5" " $10}' | sort | uniq -c
> >       27 TCP_CF_MISS/200/- HIER_NONE/-
> >        1 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> >       18 TCP_MISS/200/- HIER_NONE/-
> >        4 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> >
> > I thought that it should always be near 99% - only the first request to
> > an URL should be forwarded to the parent proxy and all subsequent
> > requests should be served from the cache.
> >
> > The situation is even worse with downloading a large file:
> > 500 threads (0.4%):
> > cat /var/log/squid.user/access.log| grep '2023-05-29 17:2' | grep pdf  |
> > awk '{print $5" " $10}' | sort | uniq -c
> >       10 TCP_CF_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> >        2 TCP_CF_MISS/200/- HIER_NONE/-
> >      488 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> >
> > 200 threads (3%):
> > cat /var/log/squid.user/access.log| grep '2023-05-29 17:3' | grep pdf  |
> > awk '{print $5" " $10}' | sort | uniq -c
> >        9 TCP_CF_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> >        6 TCP_CF_MISS/200/- HIER_NONE/-
> >      180 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> >        5 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> >
> > 50 threads (98%):
> > cat /var/log/squid.user/access.log| grep '2023-05-29 17:36' | grep pdf
> >   | awk '{print $5" " $10}' | sort | uniq -c
> >       25 TCP_CF_HIT/200/- HIER_NONE/-
> >       12 TCP_CF_MISS/200/- HIER_NONE/-
> >       12 TCP_HIT/200/- HIER_NONE/-
> >        1 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> >
> > Could you clarify if this behavior of my squid is a
> > bug/misconfiguration, or if I'm running into server performance
> > limitations (squid is running on a VM with 22 cores)?
> >
> > Kind regards,
> >       Ankor
> >
> >
> >
> > *squid.conf:*
> > workers 21
> >
> > sslcrtd_program /data/squid.user/usr/lib/squid/security_file_certgen -s
> > /data/squid.user/var/lib/squid/ssl_db -M 20MB
> > sslcrtd_children 21
> >
> > logformat extended-squid %{%Y-%m-%d %H:%M:%S}tl| %6tr %>a
> > %Ss/%03>Hs/%<Hs %<st %rm %ru %un %Sh/%<A %mt %ea
> >
> > logfile_rotate 0
> > access_log daemon:/var/log/squid.user/access.log
> > logformat=extended-squid on-error=drop
> >
> > cache_peer parent_proxy  parent 3128 0
> > never_direct allow all
> >
> > cachemgr_passwd pass config
> >
> > acl PURGE method PURGE
> > http_access allow PURGE
> >
> > http_access allow all
> >
> > http_port 3131 ssl-bump generate-host-certificates=on
> > dynamic_cert_mem_cache_size=20MB
> > tls-cert=/etc/squid.user/sslbump/bump.crt
> > tls-key=/etc/squid.user/sslbump/bump.key
> > sslproxy_cert_error allow all
> >
> > acl step1 at_step SslBump1
> > acl step2 at_step SslBump2
> > acl step3 at_step SslBump3
> >
> > ssl_bump peek step1
> > ssl_bump bump step2
> > ssl_bump bump step3
> >
> > cache_dir rock /data/squid.user/cache 20000 max-size=12000000
> > cache_swap_low 85
> > cache_swap_high 90
> >
> > *collapsed_forwarding on*
> >
> > pinger_enable off
> > max_filedesc 8192
> > shutdown_lifetime 5 seconds
> > netdb_filename none
> > log_icp_queries off
> > client_request_buffer_max_size 100 MB
> >
> > via off
> > forwarded_for delete
> >
> > coredump_dir /data/squid.user/var/cache/squid
> >
> > *curl_forker.sh:*
> > #!/bin/sh
> > N=100
> > URL=
> https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf
> <
> https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf
> >
> >
> > if [[  -n $1 &&  $1 =~ help$  ]];
> > then
> >     echo "Usage: $0 [<cnt>] [<url>]"
> >     echo
> >     echo "Example: $0 10
> >
> https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf
> <
> https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf
> >";
> >     echo
> >     exit;
> > fi
> >
> > while [[ $# -gt 0 ]]
> > do
> >    if [[ $1 =~ ^[0-9]+$ ]]
> >    then
> >       N=$1
> >    else
> >       URL=$1
> >    fi
> >    shift
> > done
> >
> > echo $URL
> > echo $N threads
> >
> > for i in `seq $N`
> > do
> >    nohup curl --tlsv1.2 -k   --proxy 0001vsg01:3131  -v $URL  >/dev/null
> >   2>&1 &
> > done
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20230531/fa233276/attachment.htm>

From rousskov at measurement-factory.com  Wed May 31 13:43:01 2023
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 31 May 2023 09:43:01 -0400
Subject: [squid-users] Proxy server to support a large number of
 simultaneous requests
In-Reply-To: <CADJd0Y16ZsmBCFzeKM4RSCDs0hi+AuJRu=iqgayfe4FEBmqQEA@mail.gmail.com>
References: <CADJd0Y3ofecE0XsFBX+YG2P1HuMT9CCHoRQVE1=K8risZLhmkA@mail.gmail.com>
 <4f506ba3-c1aa-feab-8cbd-8b86861364c9@measurement-factory.com>
 <CADJd0Y16ZsmBCFzeKM4RSCDs0hi+AuJRu=iqgayfe4FEBmqQEA@mail.gmail.com>
Message-ID: <509b99ce-346e-441f-2fa0-cd6cd1c915ef@measurement-factory.com>

On 5/31/23 02:56, Andrey K wrote:

>  > Do you get close to 100% hit ratio if clients access these URLs
>  > sequentially rather than concurrently? If not, then focus on that
>  > problem before you open the collapsed forwarding Pandora box.
> When I run curl sequentially?like this:
> for i in `seq 500`; do curl --tlsv1.2 -k ? --proxy 0001vsg01:3131 ?-v 
> $URL??>/dev/null 2>&1; done
> I get only the first request with a status TCP_MISS?and all others with 
> TCP_MEM_HIT:
>  ? ? Cnt Status? ? ? ? ? ? Parent
>  ? 499 TCP_MEM_HIT/200/- HIER_NONE/-
>  ? ? ? 1 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy

Excellent. This confirms that your Squid can successfully cache this 
object (in memory).


> It is interesting to note that on both squid versions if I run a 
> separate curl after processing 500 or 200 concurrent threads, I get a 
> result with the status TCP_MISS/200

The next step I would recommend is to study the very first cache miss 
_after_ the 500 or 200 concurrent threads test. Doing so may shed light 
on why Squid is refusing to serve that (presumably cached) object from 
the cache. I suspect that the object was marked for deletion earlier, 
but we should check before spending more time on more complex triage of 
concurrent cases. If you can share a (link to) compressed ALL,9 
cache.log from that single transaction against Squid v6, I may be able 
to help you with that step.


Cheers,

Alex.


>  > What is your Squid version? Older Squids have more collapsed forwarding
>  > bugs than newer ones. I recommend testing with Squid v6 or master/v7, at
>  > least to confirm that the problem is still present in the latest
>  > official code.
> I run tests on SQUID 5.9.
> We compiled?6.0.2 (with disabled delay-pools) and increased memory 
> parameters:
>  ? cache_mem 2048 MB
>  ? maximum_object_size_in_memory 10 MB
> The complete configuration is shown below.
> 
> Now on the version 6.0.2 we have the next results:
> 500 threads -? Hit ratio 3.8%:
>  ? ? ? 3 TCP_CF_HIT/200/- HIER_NONE/-
>  ? ? ? 2 TCP_CF_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>  ? ? ?16 TCP_HIT/200/- HIER_NONE/-
>  ? ? 467 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>  ? ? ?12 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> 
> 200 threads - 6%
>  ? ? ? 6 TCP_CF_HIT/200/- HIER_NONE/-
>  ? ? ?10 TCP_HIT/200/- HIER_NONE/-
>  ? ? 176 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>  ? ? ? 8 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> 
> 50 threads - 82%
>  ? ? ?30 TCP_CF_HIT/200/- HIER_NONE/-
>  ? ? ?11 TCP_HIT/200/- HIER_NONE/-
>  ? ? ? 1 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>  ? ? ? 8 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
> 
> The results are slightly worse than they were on the version 5.9.
> It is interesting to note that on both squid versions if I run a 
> separate curl after processing 500 or 200 concurrent threads, I get a 
> result with the status TCP_MISS/200, although the requested URL is 
> already in the rock cache (I can see it in the contents of the cache 
> using the utility I developed rock_cache_dump.pl 
> <http://rock_cache_dump.pl>:
> $VAR1 = {
>  ? ? ? ? ? '1' => {
>  ? ? ? ? ? ? ? ? ? ?'VERSION' => 'Wed May 31 09:18:05 2023',
>  ? ? ? ? ? ? ? ? ? ?'KEY_MD5' => 'e5eb10f0ab7d84ff9d3fd1e5a6d3eb9c',
>  ? ? ? ? ? ? ? ? ? ?'OBJSIZE' => 446985,
>  ? ? ? ? ? ? ? ? ? ?'STD_LFS' => {
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 'lastref' => 'Wed May 31 09:18:05 2023',
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 'flags' => '0x4004',
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 'expires' => 'Wed May 31 15:18:05 2023',
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 'swap_file_sz' => 0,
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 'refcount' => 1,
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 'lastmod' => 'Wed Jun 29 16:09:14 2016',
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 'timestamp' => 'Wed May 31 09:18:05 2023'
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? },
>  ? ? ? ? ? ? ? ? ? ?'URL' => 
> 'https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf <https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf>'
>  ? ? ? ? ? ? ? ? ?}
>  ? ? ? ? };
> 
> ).
> 
>  > How much RAM does your server have? You are using default 256MB memory
>  > cache (cache_mem). If you have spare memory, make your memory cache much
>  > larger: A rock cache_dir cannot (yet) share the response _while_ the
>  > response is being written to disk, so relying on cache_dir too much will
>  > decrease your hit ratio, especially in a collapsed forwarding 
> environment.
> The VM has 32 GB RAM. I configured cache_mem 2048 MB on the 6.0.2 version.
> 
>  > Is your Squid built with --enable-delay-pools? If yes, TCP_MISS does not
>  > necessarily mean a cache miss (an old Squid bug), even if you do not use
>  > any delay pools.
> Yes, delay pools on the version 5.9 were enabled though?we don't use 
> them. I disabled this feature on the 6.0.2 version.
> 
> 
>  > Since you are trying to cache objects lager than 512KB, see
>  > maximum_object_size_in_memory.
> I configured maximum_object_size_in_memory 10 MB?on the 6.0.2 version 
> (as videochunks are less than 7 MB).
> 
>  > Consider making your test much longer (more sequential requests per
>  > client/curl worker), to see whether the cache becomes "stable" after one
>  > of the first transactions manages to fully cache the response. This may
>  > not help with older Squids, but might help with newer ones. However, you
>  > should not test using real origin servers (that you do not control)!
> I don't have any of my own web servers for tests, so I choose some 
> resources on the public internet that have a robust infrastructure.
> I will conduct the longer tests next week.
> 
> Kind regards,
>  ? ? ? Ankor.
> 
> *squid.conf*
> workers 21
> 
> sslcrtd_program /data/squid.user/usr/lib/squid/security_file_certgen -s 
> /data/squid.user/var/lib/squid/ssl_db -M 20MB
> sslcrtd_children 21
> 
> logformat extended-squid %{%Y-%m-%d %H:%M:%S}tl| %6tr %>a 
> %Ss/%03>Hs/%<Hs %<st %rm %ru %un %Sh/%<A %mt %ea
> 
> logfile_rotate 0
> access_log daemon:/var/log/squid.user/access.log 
> logformat=extended-squid on-error=drop
> 
> cache_peer parent_proxy ?parent 3128 0
> never_direct allow all
> 
> cachemgr_passwd pass config
> 
> acl PURGE method PURGE
> http_access allow PURGE
> 
> http_access allow all
> 
> http_port 3131 ssl-bump generate-host-certificates=on 
> dynamic_cert_mem_cache_size=20MB 
> tls-cert=/etc/squid.user/sslbump/bump.crt 
> tls-key=/etc/squid.user/sslbump/bump.key
> sslproxy_cert_error allow all
> 
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> 
> ssl_bump peek step1
> ssl_bump bump step2
> ssl_bump bump step3
> 
> cache_dir rock /data/squid.user/cache 20000 max-size=12000000
> cache_swap_low 85
> cache_swap_high 90
> 
> collapsed_forwarding on
> cache_mem 2048 MB
> maximum_object_size_in_memory 10 MB
> 
> pinger_enable off
> max_filedesc 8192
> shutdown_lifetime 5 seconds
> netdb_filename none
> log_icp_queries off
> 
> via off
> forwarded_for delete
> 
> client_request_buffer_max_size 100 MB
> 
> coredump_dir /data/squid.user/var/cache/squid
> 
> 
> 
> 
> ??, 29 ??? 2023??. ? 23:17, Alex Rousskov 
> <rousskov at measurement-factory.com 
> <mailto:rousskov at measurement-factory.com>>:
> 
>     On 5/29/23 10:43, Andrey K wrote:
> 
>      > We need to configure a dedicated proxy server to provide caching of
>      > online video broadcasts in order to reduce the load on the uplink
>     proxy.
>      > Hundreds of users will access the same video-chunks simultaneously.
>      >
>      > I developed a simple configuration for the test purposes (it is
>     shown
>      > below).
>      > The *collapsed_forwarding*?option is on.
> 
>     Do you get close to 100% hit ratio if clients access these URLs
>     sequentially rather than concurrently? If not, then focus on that
>     problem before you open the collapsed forwarding Pandora box.
> 
>     What is your Squid version? Older Squids have more collapsed forwarding
>     bugs than newer ones. I recommend testing with Squid v6 or
>     master/v7, at
>     least to confirm that the problem is still present in the latest
>     official code.
> 
>     How much RAM does your server have? You are using default 256MB memory
>     cache (cache_mem). If you have spare memory, make your memory cache
>     much
>     larger: A rock cache_dir cannot (yet) share the response _while_ the
>     response is being written to disk, so relying on cache_dir too much
>     will
>     decrease your hit ratio, especially in a collapsed forwarding
>     environment.
> 
>     Is your Squid built with --enable-delay-pools? If yes, TCP_MISS does
>     not
>     necessarily mean a cache miss (an old Squid bug), even if you do not
>     use
>     any delay pools.
> 
>     Since you are trying to cache objects lager than 512KB, see
>     maximum_object_size_in_memory.
> 
>     Consider making your test much longer (more sequential requests per
>     client/curl worker), to see whether the cache becomes "stable" after
>     one
>     of the first transactions manages to fully cache the response. This may
>     not help with older Squids, but might help with newer ones. However,
>     you
>     should not test using real origin servers (that you do not control)!
> 
> 
>      > Could you clarify if this behavior of my squid is
>      > a bug/misconfiguration, or if I'm running into server performance
>      > limitations (squid is running on a VM with 22 cores)?
> 
>     Most likely, reduction of hit ratio with increase of concurrency is
>     _not_ a performance limitation.
> 
> 
>     HTH,
> 
>     Alex.
> 
> 
>      > I selected a couple of cacheable resources in the internet for
>     testing:
>      >? ?- small size (~400 KB):
>      >
>     https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf <https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf> <https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf <https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf>>
>      >? ?- large (~8 MB):
>      >
>     https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf <https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf> <https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf <https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf>>
>      > To test simultaneous connections I am forking curl using a simple
>     script
>      > (it is also shown below).
>      >
>      > When I run a test (500 curl threads to
>      >
>     https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf <https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf> <https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf <https://ia800406.us.archive.org/13/items/romeo-y-julieta-texto-completo/Romeo%20y%20Julieta%20-%20William%20Shakespeare.pdf>>) I see lots of?TCP_MISS/200 with?FIRSTUP_PARENT/parent_proxy records in the logs.
>      >
>      > A simple analysis shows?a low percentage of cache hits:
>      > cat /var/log/squid.user/access.log| grep '2023-05-29 14' | grep
>     pdf ?|
>      > awk '{print $5" " $10}' | sort | uniq -c
>      >? ? ? ?24 TCP_CF_MISS/200/- HIER_NONE/-
>      >? ? ? 457 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>      >? ? ? ?10 TCP_MISS/200/- HIER_NONE/-
>      >? ? ? ? 9 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>      >
>      > So the Hit ratio is about (500-457-9)*100/500=6.8%
>      >
>      > Almost the same situation we see when run 200 threads:
>      > cat /var/log/squid.user/access.log| grep '2023-05-29 15:45' |
>     grep pdf
>      >? ?| awk '{print $5" " $10}' | sort | uniq -c
>      >? ? ? ? 4 TCP_CF_MISS/200/- HIER_NONE/-
>      >? ? ? 140 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>      >? ? ? ?40 TCP_MISS/200/- HIER_NONE/-
>      >? ? ? ?16 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>      >
>      > This time the Hit ratio is about (200-140-16)*100/500=21%
>      >
>      > With 50 threads the Hit ratio is 90%:
>      > cat /var/log/squid.user/access.log| grep '2023-05-29 15:50' |
>     grep pdf
>      >? ?| awk '{print $5" " $10}' | sort | uniq -c
>      >? ? ? ?27 TCP_CF_MISS/200/- HIER_NONE/-
>      >? ? ? ? 1 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>      >? ? ? ?18 TCP_MISS/200/- HIER_NONE/-
>      >? ? ? ? 4 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>      >
>      > I thought that it should always be near 99% - only the first
>     request to
>      > an URL should be forwarded to the parent proxy and all subsequent
>      > requests should be served from the cache.
>      >
>      > The situation is even worse with downloading a large file:
>      > 500 threads (0.4%):
>      > cat /var/log/squid.user/access.log| grep '2023-05-29 17:2' | grep
>     pdf ?|
>      > awk '{print $5" " $10}' | sort | uniq -c
>      >? ? ? ?10 TCP_CF_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>      >? ? ? ? 2 TCP_CF_MISS/200/- HIER_NONE/-
>      >? ? ? 488 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>      >
>      > 200 threads (3%):
>      > cat /var/log/squid.user/access.log| grep '2023-05-29 17:3' | grep
>     pdf ?|
>      > awk '{print $5" " $10}' | sort | uniq -c
>      >? ? ? ? 9 TCP_CF_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>      >? ? ? ? 6 TCP_CF_MISS/200/- HIER_NONE/-
>      >? ? ? 180 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>      >? ? ? ? 5 TCP_SWAPFAIL_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>      >
>      > 50 threads (98%):
>      > cat /var/log/squid.user/access.log| grep '2023-05-29 17:36' |
>     grep pdf
>      >? ?| awk '{print $5" " $10}' | sort | uniq -c
>      >? ? ? ?25 TCP_CF_HIT/200/- HIER_NONE/-
>      >? ? ? ?12 TCP_CF_MISS/200/- HIER_NONE/-
>      >? ? ? ?12 TCP_HIT/200/- HIER_NONE/-
>      >? ? ? ? 1 TCP_MISS/200/200 FIRSTUP_PARENT/parent_proxy
>      >
>      > Could you clarify if this behavior of my squid is a
>      > bug/misconfiguration, or if I'm running into server performance
>      > limitations (squid is running on a VM with 22 cores)?
>      >
>      > Kind regards,
>      >? ? ? ?Ankor
>      >
>      >
>      >
>      > *squid.conf:*
>      > workers 21
>      >
>      > sslcrtd_program
>     /data/squid.user/usr/lib/squid/security_file_certgen -s
>      > /data/squid.user/var/lib/squid/ssl_db -M 20MB
>      > sslcrtd_children 21
>      >
>      > logformat extended-squid %{%Y-%m-%d %H:%M:%S}tl| %6tr %>a
>      > %Ss/%03>Hs/%<Hs %<st %rm %ru %un %Sh/%<A %mt %ea
>      >
>      > logfile_rotate 0
>      > access_log daemon:/var/log/squid.user/access.log
>      > logformat=extended-squid on-error=drop
>      >
>      > cache_peer parent_proxy ?parent 3128 0
>      > never_direct allow all
>      >
>      > cachemgr_passwd pass config
>      >
>      > acl PURGE method PURGE
>      > http_access allow PURGE
>      >
>      > http_access allow all
>      >
>      > http_port 3131 ssl-bump generate-host-certificates=on
>      > dynamic_cert_mem_cache_size=20MB
>      > tls-cert=/etc/squid.user/sslbump/bump.crt
>      > tls-key=/etc/squid.user/sslbump/bump.key
>      > sslproxy_cert_error allow all
>      >
>      > acl step1 at_step SslBump1
>      > acl step2 at_step SslBump2
>      > acl step3 at_step SslBump3
>      >
>      > ssl_bump peek step1
>      > ssl_bump bump step2
>      > ssl_bump bump step3
>      >
>      > cache_dir rock /data/squid.user/cache 20000 max-size=12000000
>      > cache_swap_low 85
>      > cache_swap_high 90
>      >
>      > *collapsed_forwarding on*
>      >
>      > pinger_enable off
>      > max_filedesc 8192
>      > shutdown_lifetime 5 seconds
>      > netdb_filename none
>      > log_icp_queries off
>      > client_request_buffer_max_size 100 MB
>      >
>      > via off
>      > forwarded_for delete
>      >
>      > coredump_dir /data/squid.user/var/cache/squid
>      >
>      > *curl_forker.sh:*
>      > #!/bin/sh
>      > N=100
>      >
>     URL=https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf <https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf> <https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf <https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf>>
>      >
>      > if [[ ?-n $1 && ?$1 =~ help$ ?]];
>      > then
>      >? ? ?echo "Usage: $0 [<cnt>] [<url>]"
>      >? ? ?echo
>      >? ? ?echo "Example: $0 10
>      >
>     https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf <https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf> <https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf <https://ia600601.us.archive.org/10/items/Linux-Journal-2015-01/Linux-Journal-2015-01.pdf>>";
>      >? ? ?echo
>      >? ? ?exit;
>      > fi
>      >
>      > while [[ $# -gt 0 ]]
>      > do
>      >? ? if [[ $1 =~ ^[0-9]+$ ]]
>      >? ? then
>      >? ? ? ?N=$1
>      >? ? else
>      >? ? ? ?URL=$1
>      >? ? fi
>      >? ? shift
>      > done
>      >
>      > echo $URL
>      > echo $N threads
>      >
>      > for i in `seq $N`
>      > do
>      >? ? nohup curl --tlsv1.2 -k ? --proxy 0001vsg01:3131 ?-v $URL
>      ?>/dev/null
>      >? ?2>&1 &
>      > done
>      >
>      >
>      >
>      >
>      >
>      >
>      >
>      >
>      >
>      >
>      >
>      > _______________________________________________
>      > squid-users mailing list
>      > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      > http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>
> 
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>
> 



