From andre.bolinhas at articatech.com  Mon Apr  1 10:53:54 2024
From: andre.bolinhas at articatech.com (Andre Bolinhas)
Date: Mon, 1 Apr 2024 11:53:54 +0100
Subject: [squid-users] ACL / http_access rules stop work using Squid 6+
In-Reply-To: <9cd03f00-a87e-4c48-8a9c-61eb6751c0d9@measurement-factory.com>
References: <zarafa.6601cce9.6f7a.695ad7ca298a924d@ns413437.ip-37-187-142.eu>
 <9cd03f00-a87e-4c48-8a9c-61eb6751c0d9@measurement-factory.com>
Message-ID: <ad81a226-e4dd-4748-a15f-746e2bf9a75b@articatech.com>

Hi Alex

Thanks for your help on the matter.


> The logs archive you shared previously has expired, so I cannot double 
> check, but from what I remember, the shared logs did not support the 
> above assertion, so there may be more to the story here. However, to 
> make progress, let's assume that v5 configuration files are identical 
> to v6 configuration files. 
If you want, I can run the same test with in a different debug 
parameters, just tell which ones.

I have re-uploaded the cache.log files.
https://we.tl/t-AB4XuUwuf7

> One way to answer all of the above questions is to look at the 
> following output:
>
> ??? squid -k parse ... |& grep Processing:.http_access 
There is no diff between both squid version, you can check it here
DiffNow - Compare Files, URLs, and Clipboard Contents Online 
<https://www.diffnow.com/report/jsrva>

> The logs archive you shared previously has expired, so I cannot double 
> check, but from what I remember, the shared logs did not support the 
> above assertion, so there may be more to the story here. However, to 
> make progress, let's assume that v5 configuration files are identical 
> to v6 configuration files.
The configuration files / folder are the same, the server is the same, 
the only thing that changes is the Squid version

On 29/03/2024 17:40, Alex Rousskov wrote:
> On 2024-03-25 15:13, Bolinhas Andr? wrote:
>
>> Yes, the configuration is the same for both versions.
>
> The logs archive you shared previously has expired, so I cannot double 
> check, but from what I remember, the shared logs did not support the 
> above assertion, so there may be more to the story here. However, to 
> make progress, let's assume that v5 configuration files are identical 
> to v6 configuration files.
>
> 1. Is there an "http_access allow all AnnotateFinalAllow" rule?
>
> 2. Is there an "http_access deny HTTP Group38 AnnotateRule28" rule?
>
> 3. Assuming the answers are "yes" and "yes", which rule comes first? 
> If you use include files, this question applies to the imaginary 
> preprocessed squid.conf file with all the include files inlined 
> (recursively if needed). That kind of preprocessed configuration is 
> what Squid effectively sees when compiling http_access rules, one by 
> one. Which of the two rules will Squid see first?
>
> One way to answer all of the above questions is to look at the 
> following output:
>
> ??? squid -k parse ... |& grep Processing:.http_access
>
> Replace "..." with your regular squid startup command line options and 
> adjust standard error redirection (|&) as needed for your shell. Run 
> the above command for both Squid v5 and v6 binaries. You should see 
> output like this:
>
>
>> 2024/03/29 13:31:05| Processing: http_access allow manager
>> 2024/03/29 13:31:05| Processing: http_access deny all
>
>
> HTH,
>
> Alex.
>
>
>> ------------------------------------------------------------------------
>> *De:* Alex Rousskov <rousskov at measurement-factory.com>
>> *Enviado:* segunda-feira, 25 de mar?o de 2024 19:12
>> *Para:* squid-users at lists.squid-cache.org
>> *Assunto* Re: [squid-users] ACL / http_access rules stop work using 
>> Squid 6+
>>
>>
>>
>> On 2024-03-22 09:38, Andre Bolinhas wrote:
>>
>> ?> In previous versions of squid, from 3 to 5.9, I use this kind of deny
>> ?> rules and they work like charm
>> ?>
>> ?> acl AnnotateRule28 annotate_transaction accessrule=Rule28
>> ?> http_access deny HTTP Group38 AnnotateRule28
>> ?>
>> ?> This allows me to deny objects without bump / show the error page
>> ?> (deny_info)
>> ?>
>> ?> But using squid 6+ this rules stop to work and everything is allowed.
>> ?>
>> ?> Example:
>> ?> Squid 5.9 (OK)
>> ?> https://ibb.co/YdKgL1Y
>> ?>
>> ?> Squid 6.8 (NOK)
>> ?> https://ibb.co/tbyY2GV
>> ?>
>> ?> Sample of both cache.log in debug mode
>> ?>
>> ?> https://we.tl/t-T7Nz1rVbVu
>>
>>
>> In you v6 logs, most logged transactions are allowed because a rule
>> similar to the one reconstructed below is matching:
>>
>> ????? http_access allow all AnnotateFinalAllow
>>
>>
>> There are similar cases in v5 logs as well, but most denied v5
>> transactions match the following rule instead (i.e. the one you shared
>> above):
>>
>> ????? http_access deny HTTP Group38 AnnotateRule28
>>
>>
>> In your Squid configuration, v6 allow rule is listed much higher than v5
>> deny rule (#43 vs #149). I do not see any signs of Group38 or
>> AnnotateRule28 ACL evaluation in v6 logs, as if the rule sets are
>> different for two different Squid instances. Are you using the same set
>> of http_access rules for both Squid versions?
>>
>> Alex.
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240401/fd88909f/attachment.htm>

From root at ohmuro.net  Tue Apr  2 03:03:02 2024
From: root at ohmuro.net (root at ohmuro.net)
Date: Tue, 2 Apr 2024 12:03:02 +0900
Subject: [squid-users] BWS after chunk-size
Message-ID: <CAH1GxxT1roKE2mD3HutA3o_EhTpvkH-Jc6P1P0+jNLee9=FsfA@mail.gmail.com>

Hi Team,

after an upgrade from squid 5.4.1 to squid 5.9, unable to parse HTTP
chunked response containing whitespace after chunk size.

I think the following bugs were fixed and worked fine in squid 5.9 and
earlier.
 https://bugs.squid-cache.org/show_bug.cgi?id=4492

However, after the fix for SQUID2023:1 in 5.9, it seems that it does not
work properly.

https://github.com/squid-cache/squid/security/advisories/GHSA-j83v-w3p4-5cqh

I could be wrong, but Can you please advise me know if there is a way or
patch to fix this issue.

Best regards,
Mitsumasa Ohmuro
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240402/5553af04/attachment.htm>

From technik at kjj.cz  Wed Apr  3 06:14:42 2024
From: technik at kjj.cz (=?UTF-8?B?TG91xI1hbnNrw70gTHVrw6HFoQ==?=)
Date: Wed, 3 Apr 2024 08:14:42 +0200
Subject: [squid-users] Chrome auto-HTTPS-upgrade - not falling to http
Message-ID: <82ae59b8-c835-4715-a836-418e8d44d33f@kjj.cz>

Hello,

this has recently started me up more then let it go. For a while chrome 
is upgrading in-page links to https. It is supposed to work something 
like 
https://www.bleepingcomputer.com/news/google/google-chrome-now-auto-upgrades-to-secure-connections-for-all-users/

But there is a catch for me - my squid returns something like:

(104) Connection reset by peer (TLS code: 
SQUID_TLS_ERR_CONNECT+TLS_IO_ERR=5+errno=104)
Failed to establish a secure connection: [No Error]

or

[No Error] (TLS code: 
SQUID_TLS_ERR_CONNECT+TLS_LIB_ERR=1408F10B+TLS_IO_ERR=1)
Failed to establish a secure connection: error:1408F10B:SSL 
routines:ssl3_get_record:wrong version number

to the user - via error page

Log file:

1712122364.809?? 1172 10.0.0.1 NONE_NONE_ABORTED/000 0 CONNECT 
46.255.231.158:443 - HIER_NONE/- - SNI redir.netcentrum.cz BumpMode peek 
- - - ServerNegoTLS - ServerRecTLS - ServerRecVer - ServerNegCiph - 
Error: ERR_SECURE_CONNECT_FAIL | 
SQUID_TLS_ERR_CONNECT+TLS_IO_ERR=5+errno=104
1712122366.296???? 23 10.0.0.1 NONE_NONE_ABORTED/000 0 CONNECT 
46.255.231.158:443 - HIER_NONE/- - SNI redir.netcentrum.cz BumpMode peek 
- - - ServerNegoTLS - ServerRecTLS - ServerRecVer - ServerNegCiph - 
Error: ERR_SECURE_CONNECT_FAIL | 
SQUID_TLS_ERR_CONNECT+TLS_IO_ERR=5+errno=104
1712122366.293???? 21 10.0.0.1 NONE_NONE_ABORTED/000 0 CONNECT 
46.255.231.158:443 - HIER_NONE/- - SNI redir.netcentrum.cz BumpMode peek 
- - - ServerNegoTLS - ServerRecTLS - ServerRecVer - ServerNegCiph - 
Error: ERR_SECURE_CONNECT_FAIL | 
SQUID_TLS_ERR_CONNECT+TLS_IO_ERR=5+errno=104
1712122367.111???? 20 10.0.0.1 NONE_NONE_ABORTED/000 0 CONNECT 
46.255.231.158:443 - HIER_NONE/- - SNI redir.netcentrum.cz BumpMode peek 
- - - ServerNegoTLS - ServerRecTLS - ServerRecVer - ServerNegCiph - 
Error: ERR_SECURE_CONNECT_FAIL | 
SQUID_TLS_ERR_CONNECT+TLS_IO_ERR=5+errno=104
1712122367.114???? 21 10.0.0.1 NONE_NONE_ABORTED/000 0 CONNECT 
46.255.231.158:443 - HIER_NONE/- - SNI redir.netcentrum.cz BumpMode peek 
- - - ServerNegoTLS - ServerRecTLS - ServerRecVer - ServerNegCiph - 
Error: ERR_SECURE_CONNECT_FAIL | 
SQUID_TLS_ERR_CONNECT+TLS_IO_ERR=5+errno=104

In fact - this seems to be http only sites like - 
https://www.ssllabs.com/ssltest/analyze.html?d=www.jarovnet.org or 
https://www.ssllabs.com/ssltest/analyze.html?d=redir.netcentrum.cz&s=46.255.231.158&latest. 
See this snapshot from centrum web mail page source code "V?ce informac? 
o tomto zapezpe?en? naleznete v <a 
href="http://napoveda.centrum.cz/index.php?/Knowledgebase/Article/View/18/1/" 
"

So - what is supposed to be happening is chrome should fallback to http 
if there is a problem with https - i think the most obvious reason to 
fall back would be no output at all. So I think my effort should target 
the situation when squid says? ERR_SECURE_CONNECT_FAIL | 
SQUID_TLS_ERR_CONNECT+TLS_IO_ERR=5+errno=104 and to remain silent to the 
client.

Is there a way to do it - ie. do not show error page for not able to 
connect to server at all? I'd like every other problems (ie. 
bad/selfsigned/not matched certificate etc.) pushed to the client's 
eyes. I have implemented 
https://www.squid-cache.org/Doc/config/on_unsupported_protocol/ like in 
the example - but it is for an accepted TCP connections. I'd like to 
handle SSL errors - such as not being able to connect at all. - could it 
be done with https://www.squid-cache.org/Doc/config/sslproxy_cert_error/?

LL

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240403/5b47ea4a/attachment.htm>

From technik at kjj.cz  Wed Apr  3 07:59:03 2024
From: technik at kjj.cz (=?UTF-8?B?TG91xI1hbnNrw70gTHVrw6HFoQ==?=)
Date: Wed, 3 Apr 2024 09:59:03 +0200
Subject: [squid-users] Chrome auto-HTTPS-upgrade - not falling to http
In-Reply-To: <82ae59b8-c835-4715-a836-418e8d44d33f@kjj.cz>
References: <82ae59b8-c835-4715-a836-418e8d44d33f@kjj.cz>
Message-ID: <e774283f-ad56-4872-a402-78a75c207a26@kjj.cz>

My effort so far:


acl SquidTLSErrorConnect ssl_error SQUID_TLS_ERR_CONNECT

##############################
#unsupported protocol definice
##############################
# define what Squid errors indicate receiving non-HTTP traffic:
acl foreignProtocol squid_error ERR_PROTOCOL_UNKNOWN ERR_TOO_BIG

# define what Squid errors indicate receiving nothing:
acl serverTalksFirstProtocol squid_error ERR_REQUEST_START_TIMEOUT

acl SquidSecureConnectFail squid_error ERR_SECURE_CONNECT_FAIL

# tunnel everything that does not look like HTTP:
on_unsupported_protocol tunnel foreignProtocol

# tunnel if we think the client waits for the server to talk first:
on_unsupported_protocol tunnel serverTalksFirstProtocol

#tunnel all for connection errors
on_unsupported_protocol tunnel SquidTLSErrorConnect
on_unsupported_protocol tunnel SquidSecureConnectFail


# in all other error cases, just send an HTTP "error page" response:
on_unsupported_protocol respond all

This is how it changed the behaviour (checked only with 
redir.netcentrum.cz so far)


1712126917.823????? 0 10.0.0.1 NONE_NONE/503 13605 GET 
https://redir.netcentrum.cz/favicon.ico - HIER_NONE/- text/html 
redir.netcentrum.cz
1712126918.842???? 23 10.0.0.1 NONE_NONE_ABORTED/000 0 CONNECT 
46.255.231.158:443 - HIER_NONE/- - redir.netcentrum.cz
1712126918.881????? 0 10.0.0.1 NONE_NONE/503 13605 GET 
https://redir.netcentrum.cz/favicon.ico - HIER_NONE/- text/html 
redir.netcentrum.cz
1712126919.116???? 21 10.0.0.1 NONE_NONE_ABORTED/000 0 CONNECT 
46.255.231.158:443 - HIER_NONE/- - redir.netcentrum.cz
1712126919.156????? 0 10.0.0.1 NONE_NONE/503 13605 GET 
https://redir.netcentrum.cz/favicon.ico - HIER_NONE/- text/html 
redir.netcentrum.cz
1712126918.839???? 19 10.0.0.1 NONE_NONE_ABORTED/000 0 CONNECT 
46.255.231.158:443 - HIER_NONE/- - redir.netcentrum.cz
1712126918.845????? 0 10.0.0.1 NONE_NONE/503 13605 GET 
https://redir.netcentrum.cz/? - HIER_NONE/- text/html redir.netcentrum.cz
1712126919.113???? 19 10.0.0.1 NONE_NONE_ABORTED/000 0 CONNECT 
46.255.231.158:443 - HIER_NONE/- - redir.netcentrum.cz
1712126919.119????? 0 10.0.0.1 NONE_NONE/503 13605 GET 
https://redir.netcentrum.cz/? - HIER_NONE/- text/html redir.netcentrum.cz
1712127729.466???? 66 10.0.0.1 TCP_MISS/200 719 GET 
http://redir.netcentrum.cz/? - ORIGINAL_DST/46.255.231.158 text/html -
1712127729.516????? 9 10.0.0.1 TCP_MISS/403 424 GET 
http://redir.netcentrum.cz/favicon.ico - ORIGINAL_DST/46.255.231.158 
text/plain -
1712127768.494????? 8 10.0.0.1 TCP_MISS/200 794 GET 
http://redir.netcentrum.cz/? - ORIGINAL_DST/46.255.231.158 text/html -
1712127768.544????? 7 10.0.0.1 TCP_MISS/403 424 GET 
http://redir.netcentrum.cz/favicon.ico - ORIGINAL_DST/46.255.231.158 
text/plain -
1712127833.348????? 9 10.0.0.1 TCP_MISS/200 794 GET 
http://redir.netcentrum.cz/? - ORIGINAL_DST/46.255.231.158 text/html -
1712127833.486???? 15 10.0.0.1 TCP_MISS/403 424 GET 
http://redir.netcentrum.cz/favicon.ico - ORIGINAL_DST/46.255.231.158 
text/plain -
1712129450.601???? 27 10.0.0.1 TCP_MISS/200 851 GET 
http://redir.netcentrum.cz/? - ORIGINAL_DST/46.255.231.158 text/html -
1712129450.688????? 8 10.0.0.1 TCP_MISS/403 424 GET 
http://redir.netcentrum.cz/favicon.ico - ORIGINAL_DST/46.255.231.158 
text/plain -
1712130278.514???? 54 10.0.0.1 TCP_MISS/200 795 GET 
http://redir.netcentrum.cz/? - ORIGINAL_DST/46.255.231.158 text/html -
1712130278.565????? 9 10.0.0.1 TCP_MISS/403 422 GET 
http://redir.netcentrum.cz/favicon.ico - ORIGINAL_DST/46.255.231.158 
text/plain -
1712130282.165????? 9 10.0.0.1 TCP_MISS/200 815 GET 
http://redir.netcentrum.cz/? - ORIGINAL_DST/46.255.231.158 text/html -
1712130282.222????? 8 10.0.0.1 TCP_MISS/403 424 GET 
http://redir.netcentrum.cz/favicon.ico - ORIGINAL_DST/46.255.231.158 
text/plain -

I can see clear change from GET https to GET http only. I have to check 
what else does not work and why. (for example many users complained 
about heureka.cz subdomains not openning right with https.) I have to 
say - there many less competent admins in the wild with selfsigned or 
unmatched certificates on their websites, thinking they did the homework 
right. It is tough to explaing to my users that the error page they are 
getting is not a result of a faulty local gear - nor an attempt of the 
admin to spy on them or to block some sites etc.

LL

Dne 03.04.2024 v 8:14 Lou?ansk? Luk?? napsal(a):
>
> Hello,
>
> this has recently started me up more then let it go. For a while 
> chrome is upgrading in-page links to https. It is supposed to work 
> something like 
> https://www.bleepingcomputer.com/news/google/google-chrome-now-auto-upgrades-to-secure-connections-fo 
> r-all-users/
>
> But there is a catch for me - my squid returns something like:
>
> (104) Connection reset by peer (TLS code: 
> SQUID_TLS_ERR_CONNECT+TLS_IO_ERR=5+errno=104)
> Failed to establish a secure connection: [No Error]
>
> or
>
> [No Error] (TLS code: 
> SQUID_TLS_ERR_CONNECT+TLS_LIB_ERR=1408F10B+TLS_IO_ERR=1)
> Failed to establish a secure connection: error:1408F10B:SSL 
> routines:ssl3_get_record:wrong version number
>
> to the user - via error page
>
> Log file:
>
> 1712122364.809?? 1172 10.0.0.1 NONE_NONE_ABORTED/000 0 CONNECT 
> 46.255.231.158:443 - HIER_NONE/- - SNI redir.netcentrum.cz BumpMode 
> peek - - - ServerNegoTLS - ServerRecTLS - ServerRecVer - ServerNegCiph 
> - Error: ERR_SECURE_CONNECT_FAIL | 
> SQUID_TLS_ERR_CONNECT+TLS_IO_ERR=5+errno=104
> 1712122366.296???? 23 10.0.0.1 NONE_NONE_ABORTED/000 0 CONNECT 
> 46.255.231.158:443 - HIER_NONE/- - SNI redir.netcentrum.cz BumpMode 
> peek - - - ServerNegoTLS - ServerRecTLS - ServerRecVer - ServerNegCiph 
> - Error: ERR_SECURE_CONNECT_FAIL | 
> SQUID_TLS_ERR_CONNECT+TLS_IO_ERR=5+errno=104
> 1712122366.293???? 21 10.0.0.1 NONE_NONE_ABORTED/000 0 CONNECT 
> 46.255.231.158:443 - HIER_NONE/- - SNI redir.netcentrum.cz BumpMode 
> peek - - - ServerNegoTLS - ServerRecTLS - ServerRecVer - ServerNegCiph 
> - Error: ERR_SECURE_CONNECT_FAIL | 
> SQUID_TLS_ERR_CONNECT+TLS_IO_ERR=5+errno=104
> 1712122367.111???? 20 10.0.0.1 NONE_NONE_ABORTED/000 0 CONNECT 
> 46.255.231.158:443 - HIER_NONE/- - SNI redir.netcentrum.cz BumpMode 
> peek - - - ServerNegoTLS - ServerRecTLS - ServerRecVer - ServerNegCiph 
> - Error: ERR_SECURE_CONNECT_FAIL | 
> SQUID_TLS_ERR_CONNECT+TLS_IO_ERR=5+errno=104
> 1712122367.114???? 21 10.0.0.1 NONE_NONE_ABORTED/000 0 CONNECT 
> 46.255.231.158:443 - HIER_NONE/- - SNI redir.netcentrum.cz BumpMode 
> peek - - - ServerNegoTLS - ServerRecTLS - ServerRecVer - ServerNegCiph 
> - Error: ERR_SECURE_CONNECT_FAIL | 
> SQUID_TLS_ERR_CONNECT+TLS_IO_ERR=5+errno=104
>
> In fact - this seems to be http only sites like - 
> https://www.ssllabs.com/ssltest/analyze.html?d=www.jarovnet.org or 
> https://www.ssllabs.com/ssltest/analyze.html?d=redir.netcentrum.cz&s=46.255.231.158&latest. 
> See this snapshot from centrum web mail page source code "V?ce 
> informac? o tomto zapezpe?en? naleznete v <a 
> href="http://napoveda.centrum.cz/index.php?/Knowledgebase/Article/View/18/1/" 
> "
>
> So - what is supposed to be happening is chrome should fallback to 
> http if there is a problem with https - i think the most obvious 
> reason to fall back would be no output at all. So I think my effort 
> should target the situation when squid says? ERR_SECURE_CONNECT_FAIL | 
> SQUID_TLS_ERR_CONNECT+TLS_IO_ERR=5+errno=104 and to remain silent to 
> the client.
>
> Is there a way to do it - ie. do not show error page for not able to 
> connect to server at all? I'd like every other problems (ie. 
> bad/selfsigned/not matched certificate etc.) pushed to the client's 
> eyes. I have implemented 
> https://www.squid-cache.org/Doc/config/on_unsupported_protocol/ like 
> in the example - but it is for an accepted TCP connections. I'd like 
> to handle SSL errors - such as not being able to connect at all. - 
> could it be done with 
> https://www.squid-cache.org/Doc/config/sslproxy_cert_error/?
>
> LL
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240403/2250e3e4/attachment.htm>

From squid3 at treenet.co.nz  Wed Apr  3 08:28:32 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 3 Apr 2024 21:28:32 +1300
Subject: [squid-users] BWS after chunk-size
In-Reply-To: <CAH1GxxT1roKE2mD3HutA3o_EhTpvkH-Jc6P1P0+jNLee9=FsfA@mail.gmail.com>
References: <CAH1GxxT1roKE2mD3HutA3o_EhTpvkH-Jc6P1P0+jNLee9=FsfA@mail.gmail.com>
Message-ID: <76add099-ff7f-4c5d-aa2d-fb6afc1b33e8@treenet.co.nz>

On 2/04/24 16:03, root wrote:
> Hi Team,
> 
> after an upgrade from squid 5.4.1 to squid 5.9, unable to parse HTTP 
> chunked response containing whitespace after chunk size. >
> I think the following bugs were fixed and worked fine in squid 5.9 and 
> earlier.
> https://bugs.squid-cache.org/show_bug.cgi?id=4492 
> <https://bugs.squid-cache.org/show_bug.cgi?id=4492>
> 

There was no bug. We caved to user pressure and relaxed the protocol 
validation to tolerate and "fix" known-bad syntax. That change is what 
opened the security issue...


> However, after the fix for SQUID2023:1 in 5.9, it seems that it does not 
> work properly.
> <https://github.com/squid-cache/squid/security/advisories/GHSA-j83v-w3p4-5cqh>
> 

Indeed. That particular broken syntax is being intentionally rejected as 
a security attack.


> I could be wrong, but Can you please advise me know if there is a way or 
> patch to fix this issue.
> 

You need to fix or stop using the software which is adding BWS (bad 
whitespace) to the protocol syntax fixed.


Amos


From squid3 at treenet.co.nz  Wed Apr  3 08:49:55 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 3 Apr 2024 21:49:55 +1300
Subject: [squid-users] Chrome auto-HTTPS-upgrade - not falling to http
In-Reply-To: <e774283f-ad56-4872-a402-78a75c207a26@kjj.cz>
References: <82ae59b8-c835-4715-a836-418e8d44d33f@kjj.cz>
 <e774283f-ad56-4872-a402-78a75c207a26@kjj.cz>
Message-ID: <0eff858d-31ce-4107-bce1-d314f55b3b79@treenet.co.nz>

There is no way to configure around this. The error produced by Squid is 
a hard-coded reaction to TLS level errors in the SSL-Bump process.

Squid needs some significant code redesign to do a better job of 
handling the situation. Which I understand is already underway, but 
still some way off usable.


Amos


From rousskov at measurement-factory.com  Wed Apr  3 15:05:02 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 3 Apr 2024 11:05:02 -0400
Subject: [squid-users] Chrome auto-HTTPS-upgrade - not falling to http
In-Reply-To: <0eff858d-31ce-4107-bce1-d314f55b3b79@treenet.co.nz>
References: <82ae59b8-c835-4715-a836-418e8d44d33f@kjj.cz>
 <e774283f-ad56-4872-a402-78a75c207a26@kjj.cz>
 <0eff858d-31ce-4107-bce1-d314f55b3b79@treenet.co.nz>
Message-ID: <e8845677-fe34-439a-9bfe-4a0b2aa3461a@measurement-factory.com>

On 2024-04-03 02:14, Lou?ansk? Luk?? wrote:

> this has recently started me up more then let it go. For a while
> chrome is upgrading in-page links to https.
Just to add two more pieces of related information to this thread:

Some Squid admins report that their v6-based code does not suffer from 
this issue while their v5-based code does. I have not verified those 
reports, but there may be more to the story here. What Squid version are 
_you_ using?

One way to track progress with this annoying and complex issue is to 
follow the following pull request. The current code cannot be officially 
merged as is, and I would not recommend using it in production (because 
of low-level bugs that will probably crash Squid in some cases), but 
testing it in the lab and providing feedback to authors may be useful:

https://github.com/squid-cache/squid/pull/1668

HTH,

Alex.



From rousskov at measurement-factory.com  Wed Apr  3 15:48:15 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 3 Apr 2024 11:48:15 -0400
Subject: [squid-users] BWS after chunk-size
In-Reply-To: <CAH1GxxT1roKE2mD3HutA3o_EhTpvkH-Jc6P1P0+jNLee9=FsfA@mail.gmail.com>
References: <CAH1GxxT1roKE2mD3HutA3o_EhTpvkH-Jc6P1P0+jNLee9=FsfA@mail.gmail.com>
Message-ID: <cb449840-0da1-44db-80d3-b077ad82424b@measurement-factory.com>

On 2024-04-01 23:03, root at ohmuro.net wrote:

> after an upgrade from squid 5.4.1 to squid 5.9, unable to parse HTTP 
> chunked response containing whitespace after chunk size.

> I could be wrong, but Can you please advise me know if there is a way or 
> patch to fix this issue.

The sender of these malformed chunks is at fault. If you can reach out 
to them, they may be able to upgrade or fix their software.

Senders with similar behavior were used for attacks on clients or 
network infrastructure. Squid cannot tell whether an attack is going on 
and, hence, rejects traffic with such serious message framing-related 
violations. This is the right default that will never change.

It is, of course, possible to modify Squid code to resume accepting this 
dangerous whitespace again. However, such changes will not be officially 
accepted, and running your Squid with such changes does elevate security 
risks of your Squid deployment or those around it. FWIW, we work in the 
background to better address this issue, but we are currently too busy 
with more important Squid problems to make good progress with that work.

Alex.



From jonathanlee571 at gmail.com  Thu Apr  4 04:48:08 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 3 Apr 2024 21:48:08 -0700
Subject: [squid-users] Squid cache questions
Message-ID: <F23BE06C-985E-4F47-BE09-B16EB7BCC2C7@gmail.com>

Is there any particular order to squid configuration??

Does this look correct?

I actually get allot of hits and it functions amazing, so I wanted to share this in case I could improve something. Is there any issues with security? I am concerned that an invasive container could become installed in the cache and data marshal the network card.

Here is my config 

# This file is automatically generated by pfSense
# Do not edit manually !

http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

icp_port 0
digest_generation off
dns_v4_first on
pid_filename /var/run/squid/squid.pid
cache_effective_user squid
cache_effective_group proxy
error_default_language en
icon_directory /usr/local/etc/squid/icons
visible_hostname Lee_Family.home.arpa
cache_mgr jonathanlee571 at gmail.com
access_log /var/squid/logs/access.log
cache_log /var/squid/logs/cache.log
cache_store_log none
netdb_filename /var/squid/logs/netdb.state
pinger_enable on
pinger_program /usr/local/libexec/squid/pinger
sslcrtd_program /usr/local/libexec/squid/security_file_certgen -s /var/squid/lib/ssl_db -M 4MB -b 2048
tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
tls_outgoing_options capath=/usr/local/share/certs/
tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
tls_outgoing_options flags=DONT_VERIFY_PEER
sslcrtd_children 10

logfile_rotate 0
debug_options rotate=0
shutdown_lifetime 3 seconds
# Allow local network(s) on interface(s)
acl localnet src  192.168.1.0/27
forwarded_for transparent
httpd_suppress_version_string on
uri_whitespace strip

acl getmethod method GET

acl windowsupdate dstdomain windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain download.windowsupdate.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain www.download.windowsupdate.com
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com
acl windowsupdate dstdomain dc1-st.ksn.kaspersky-labs.com
acl windowsupdate dstdomain dc1-file.ksn.kaspersky-labs.com
acl windowsupdate dstdomain dc1.ksn.kaspersky-labs.com

acl rewritedoms dstdomain .facebook.com .akamaihd.net .fbcdn.net .google.com .static.com .apple.com .oracle.com .sun.com .java.com .adobe.com .steamstatic.com .steampowered.com .steamcontent.com .google.com

store_id_program /usr/local/libexec/squid/storeid_file_rewrite /var/squid/storeid/storeid_rewrite.txt
store_id_children 10 startup=5 idle=1 concurrency=0
always_direct allow !getmethod
store_id_access deny connect
store_id_access deny !getmethod
store_id_access allow rewritedoms
reload_into_ims on
max_stale 20 years
minimum_expiry_time 0


refresh_pattern -i squid.internal 10080 80% 79900 override-lastmod override-expire ignore-reload ignore-no-store ignore-must-revalidate ignore-private ignore-auth

#APPLE STUFF
refresh_pattern -i apple.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip|dist)$ 0 80% 43200  refresh-ims

#apple update
refresh_pattern -i (download|adcdownload).apple.com/.*.(pkg|dmg) 4320 100% 43200 
refresh_pattern -i appldnld.apple.com 129600 100% 129600     
refresh_pattern -i phobos.apple.com 129600 100% 129600     
refresh_pattern -i iosapps.itunes.apple.com 129600 100% 129600     

# Updates: Windows
refresh_pattern -i microsoft.com/..(cab|exe|msi|msu|msf|asf|wma|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i windowsupdate.com/..(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i windows.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i windows.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i .*windowsupdate.com/.*.(cab|exe) 259200 100% 259200   
refresh_pattern -i .*update.microsoft.com/.*.(cab|exe|dll|msi|psf) 259200 100% 259200   
refresh_pattern windowsupdate.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern download.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern www.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern au.download.windowsupdate.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200 
refresh_pattern bg.v4.pr.dl.ws.microsoft.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
#windows update NEW UPDATE 0.04
refresh_pattern update.microsoft.com/.*.(cab|exe) 43200 100% 129600    
refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200  
refresh_pattern update.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern -i .update.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .download.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .ws.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       

refresh_pattern ([^.]+.)?(cs|content[1-9]|hsar|content-origin|client-download).[steampowered|steamcontent].com/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern ([^.]+.)?.akamai.steamstatic.com/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod

refresh_pattern -i ([^.]+.)?.adobe.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern -i ([^.]+.)?.java.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern -i ([^.]+.)?.sun.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern -i ([^.]+.)?.oracle.com/.*.(zip|exe|tar.gz) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod

refresh_pattern -i appldnld.apple.com 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern -i ([^.]+.)?apple.com/.*.(ipa) 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
 
refresh_pattern -i ([^.]+.)?.google.com/.*.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
refresh_pattern -i ([^.]+.)?g.static.com/.*.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private

#FACEBOOK
refresh_pattern ^http?://*.facebook.com/*  10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private

#FACEBOOK IMAGES  
refresh_pattern -i pixel.facebook.com..(jpg|png|gif|ico|css|js)  10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
refresh_pattern -i .akamaihd.net..(jpg|png|gif|ico|css|js) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private   
refresh_pattern -i (facebook.com).(jpg|png|gif) 10080 80% 43200 store-stale override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private 
refresh_pattern static.(xx|ak).fbcdn.net.(jpg|gif|png) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
refresh_pattern ^https?://profile.ak.fbcdn.net*.(jpg|gif|png) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private

#FACEBOOK VIDEO
refresh_pattern -i .video.ak.fbcdn.net.*.(mp4|flv|mp3|amf) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private   
refresh_pattern (audio|video)/(webm|mp4) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private


range_offset_limit 512 MB windowsupdate
maximum_object_size 512 MB windowsupdate
range_offset_limit 0
quick_abort_min -1 KB

cache_mem 64 MB
maximum_object_size_in_memory 256 KB
memory_replacement_policy heap LFUDA
cache_replacement_policy heap LFUDA
minimum_object_size 0 KB
maximum_object_size 4 MB
cache_dir diskd /var/squid/cache 64000 256 256
offline_mode off
cache_swap_low 90
cache_swap_high 95
acl donotcache dstdomain '/var/squid/acl/donotcache.acl'
cache deny donotcache
cache allow all
# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:    1440  20%  10080
refresh_pattern ^gopher:  1440  0%  1440
refresh_pattern -i (/cgi-bin/|?) 0  0%  0
refresh_pattern .    0  20%  4320


#Remote proxies


# Setup some default acls
# ACLs all, manager, localhost, and to_localhost are predefined.
acl allsrc src all
acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080 3128 3129 1025-65535 
acl sslports port 443 563 8080 5223 2197

acl purge method PURGE
acl connect method CONNECT

# Define protocols used for redirects
acl HTTP proto HTTP
acl HTTPS proto HTTPS

# SslBump Peek and Splice
# http://wiki.squid-cache.org/Features/SslPeekAndSplice
# http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
# Match against the current step during ssl_bump evaluation [fast]
# Never matches and should not be used outside the ssl_bump context.
#
# At each SslBump step, Squid evaluates ssl_bump directives to find
# the next bumping action (e.g., peek or splice). Valid SslBump step
# values and the corresponding ssl_bump evaluation moments are:
#   SslBump1: After getting TCP-level and HTTP CONNECT info.
#   SslBump2: After getting TLS Client Hello info.
#   SslBump3: After getting TLS Server Hello info.
# These ACLs exist even when 'SSL/MITM Mode' is set to 'Custom' so that
# they can be used there for custom configuration.
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
acl banned_hosts src '/var/squid/acl/banned_hosts.acl'
acl whitelist dstdom_regex -i '/var/squid/acl/whitelist.acl'
acl blacklist dstdom_regex -i '/var/squid/acl/blacklist.acl'
http_access allow manager localhost

# Allow external cache managers
acl ext_manager src 192.168.1.1
acl ext_manager src 127.0.0.1
http_access allow manager ext_manager

http_access deny manager
http_access allow purge localhost
http_access deny purge
http_access deny !safeports
http_access deny CONNECT !sslports

# Always allow localhost connections
http_access allow localhost

quick_abort_min 0 KB
quick_abort_max 0 KB
quick_abort_pct 95
request_body_max_size 0 KB
delay_pools 1
delay_class 1 2
delay_parameters 1 -1/-1 -1/-1
delay_initial_bucket_level 100
delay_access 1 allow allsrc

# Reverse Proxy settings

deny_info TCP_RESET allsrc

# Package Integration
url_rewrite_program /usr/local/bin/squidGuard -c /usr/local/etc/squidGuard/squidGuard.conf
url_rewrite_bypass off
url_rewrite_children 32 startup=8 idle=4 concurrency=0

# Custom options before auth
#host_verify_strict on

# These hosts are banned
http_access deny banned_hosts
# Always allow access to whitelist domains
http_access allow whitelist
# Block access to blacklist domains
http_access deny blacklist
# List of domains allowed to logging in to Google services
request_header_access X-GoogApps-Allowed-Domains deny all
request_header_add X-GoogApps-Allowed-Domains consumer_accounts
# Set YouTube safesearch restriction
acl youtubedst dstdomain -n www.youtube.com m.youtube.com youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com
request_header_access YouTube-Restrict deny all
request_header_add YouTube-Restrict none youtubedst
acl sglog url_regex -i sgr=ACCESSDENIED
http_access deny sglog
# Custom SSL/MITM options before auth
acl manager proto cache_object
acl localhost src 192.168.1.1/32
#cachemgr_passwd disable offline_toggle reconfigure shutdown
#cachemgr_passwd secret all
acl https_login url_regex -i ^https.*(login|Login).*
acl no_miss url_regex -i ^.*gateway.facebook.com/ws/realtime?
acl no_miss url_regex -i ^.*web-chat-e2ee.facebook.com/ws/chat	
acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com
http_access allow CONNECT wuCONNECT localnet
http_access allow CONNECT wuCONNECT localhost
http_access allow windowsupdate localnet
http_access allow windowsupdate localhost
http_access deny manager

acl BrokenButTrustedServers dstdomain '/usr/local/pkg/dstdom.broken'
acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
sslproxy_cert_error deny all

acl splice_only src 192.168.1.8 #Tasha iPhone
acl splice_only src 192.168.1.10 #Jon iPhone
acl splice_only src 192.168.1.11 #Amazon Fire
acl splice_only src 192.168.1.15 #Tasha HP
acl splice_only src 192.168.1.16 #iPad

acl NoSSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.nobump'

acl markBumped annotate_client bumped=true
acl bump_only src 192.168.1.3 #webtv
acl bump_only src 192.168.1.4 #toshiba
acl bump_only src 192.168.1.5 #imac
acl bump_only src 192.168.1.9 #macbook
acl bump_only src 192.168.1.13 #dell

cache deny https_login

ssl_bump peek step1
miss_access deny no_miss 
ssl_bump splice https_login
ssl_bump splice splice_only
ssl_bump splice NoSSLIntercept
ssl_bump bump bump_only markBumped
ssl_bump stare all

acl markedBumped note bumped true
url_rewrite_access deny markedBumped

http_access deny all
read_ahead_gap 32 KB
negative_ttl 1 second
connect_timeout 30 seconds
request_timeout 60 seconds
half_closed_clients off
shutdown_lifetime 10 seconds
negative_dns_ttl 1 seconds
ignore_unknown_nameservers on
pipeline_prefetch 100

#acl SSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.bump'
#ssl_bump bump SSLIntercept

# Setup allowed ACLs
# Allow local network(s) on interface(s)
http_access allow localnet
# Default block all to be sure
http_access deny allsrc

Sent from my iPhone
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240403/a691dd44/attachment.htm>

From david.komanek at natur.cuni.cz  Thu Apr  4 07:01:42 2024
From: david.komanek at natur.cuni.cz (David Komanek)
Date: Thu, 4 Apr 2024 09:01:42 +0200
Subject: [squid-users] Chrome auto-HTTPS-upgrade - not falling to http
In-Reply-To: <mailman.984.1712206107.1200.squid-users@lists.squid-cache.org>
References: <mailman.984.1712206107.1200.squid-users@lists.squid-cache.org>
Message-ID: <ba1742ee-2a97-466e-a739-84380e8512e9@natur.cuni.cz>


> Date: Wed, 3 Apr 2024 11:05:02 -0400
> From: Alex Rousskov<rousskov at measurement-factory.com>
> To:squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Chrome auto-HTTPS-upgrade - not falling to
> 	http
> Message-ID:
> 	<e8845677-fe34-439a-9bfe-4a0b2aa3461a at measurement-factory.com>
> Content-Type: text/plain; charset=UTF-8; format=flowed
>
> On 2024-04-03 02:14, Lou?ansk? Luk?? wrote:
>
>> this has recently started me up more then let it go. For a while
>> chrome is upgrading in-page links to https.
> Just to add two more pieces of related information to this thread:
>
> Some Squid admins report that their v6-based code does not suffer from
> this issue while their v5-based code does. I have not verified those
> reports, but there may be more to the story here. What Squid version are
> _you_ using?
>
> One way to track progress with this annoying and complex issue is to
> follow the following pull request. The current code cannot be officially
> merged as is, and I would not recommend using it in production (because
> of low-level bugs that will probably crash Squid in some cases), but
> testing it in the lab and providing feedback to authors may be useful:
>
> https://github.com/squid-cache/squid/pull/1668
>
> HTH,
>
> Alex.
>
>
>

Hello,

fortunately, I do not observe this problem accessing sites running only 
on port 80 (no 443 at all), but my configuration is simple:

squid 6.6 as FreeBSD binary package

not much about ssl in the config file though, just passing it through, 
no ssl juggling

acl SSL_ports port
acl Safe_ports port 80
acl Safe_ports port 443
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny to_localhost
http_access allow ....
http_access allow ....
http_access allow ....
http_access allow ....
http_access allow ....
http_access deny all

I don't think it was different with squid 5.9, which I used till 
November 2023.

Occasionally, I see another problem, which may or may not be related to 
squid ssl handling configuration: PR_END_OF_FILE_ERROR (Firefox) / 
ERR_CONNECTION_CLOSED (Chrome), typically accessing samba.org. But they 
use permanent redirect from http to https, so it another situation than 
http-only site.

David

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240404/288c2b56/attachment.htm>

From ohmuro at iij.ad.jp  Thu Apr  4 07:47:02 2024
From: ohmuro at iij.ad.jp (ohmuro)
Date: Thu, 4 Apr 2024 16:47:02 +0900
Subject: [squid-users] BWS after chunk-size
In-Reply-To: <76add099-ff7f-4c5d-aa2d-fb6afc1b33e8@treenet.co.nz>
References: <CAH1GxxT1roKE2mD3HutA3o_EhTpvkH-Jc6P1P0+jNLee9=FsfA@mail.gmail.com>
 <76add099-ff7f-4c5d-aa2d-fb6afc1b33e8@treenet.co.nz>
Message-ID: <8aeb3493-66a1-46f3-abfd-b83cbdf316ac@iij.ad.jp>

Hi Amos

Thank you for your reply.

I would like the behavior to be aligned with major browsers, but I 
understand why it was fixed.
and agree that software that adds bad whitespace to protocol syntax is a 
problem.


 >> However, after the fix for SQUID2023:1 in 5.9, it seems that it does 
not work properly.
 >> 
<https://github.com/squid-cache/squid/security/advisories/GHSA-j83v-w3p4-5cqh>
 >>

 > Indeed. That particular broken syntax is being intentionally rejected 
as a security attack.
 >

I would like to report that in my Squid 5.9, accessing a website that 
has BWS added, a blank screen appears instead of an error message.


Best regards,
Mitsumasa Ohmuro




From squid3 at treenet.co.nz  Fri Apr  5 01:17:16 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 5 Apr 2024 14:17:16 +1300
Subject: [squid-users] Squid cache questions
In-Reply-To: <F23BE06C-985E-4F47-BE09-B16EB7BCC2C7@gmail.com>
References: <F23BE06C-985E-4F47-BE09-B16EB7BCC2C7@gmail.com>
Message-ID: <bef43696-be7f-463b-b82e-d4346abba2a5@treenet.co.nz>

On 4/04/24 17:48, Jonathan Lee wrote:
> Is there any particular order to squid configuration??
> 

Yes. <https://wiki.squid-cache.org/SquidFaq/OrderIsImportant>


> Does this look correct?
> 

Best way to find out is to run "squid -k parse", which should be done 
after upgrades as well to identify and fix changes between versions as 
we improve the output.


> I actually get allot of hits and it functions amazing, so I wanted to 
> share this in case I could improve something. Is there any issues with 
> security?

Yes, the obvious one is "DONT_VERIFY_PEER" disabling TLS security 
entirely on outbound connections. That particular option will prevent 
you even being told about suspicious activity regarding TLS.

Also there are a few weird things in your TLS cipher settings, such as 
this sequence "  EECDH+aRSA+RC4:...:!RC4 "
  Which as I understand, enables the EECDH with RC4 hash, but also 
forbids all uses of RC4.


> I am concerned that an invasive container could become 
> installed in the cache and data marshal the network card.
> 

You have a limit of 4 MB for objects allowed to pass through this proxy, 
exception being objects from domains listed in the "windowsupdate" ACL 
(not all Windows related) which are allowed up to 512 MB.

For the general case, any type of file which can store an image of some 
system is a risk for that type of vulnerability can be cached.

The place to fix that vulnerability properly is not the cache or Squid. 
It is the OS permissions allowing non-Squid software access to the cache 
files and/or directory.



> Here is my config
> 
> # This file is automatically generated by pfSense
> # Do not edit manually !

Since this file is generated by pfsense there is little that can be done 
about ordering issues and very hard to tell which of the problems below 
are due to pfsense and which due toy your settings.

FWIW, there are no major issues, just some lines not being necessary due 
to setting things to their default values, or just some blocks already 
denyign things that are blocked previously.


> 
> http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 
> http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 
> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 
> icp_port 0
> digest_generation off
> dns_v4_first on
> pid_filename /var/run/squid/squid.pid
> cache_effective_user squid
> cache_effective_group proxy
> error_default_language en
> icon_directory /usr/local/etc/squid/icons
> visible_hostname ****
> cache_mgr ****
> access_log /var/squid/logs/access.log
> cache_log /var/squid/logs/cache.log
> cache_store_log none
> netdb_filename /var/squid/logs/netdb.state
> pinger_enable on
> pinger_program /usr/local/libexec/squid/pinger
> sslcrtd_program /usr/local/libexec/squid/security_file_certgen -s /var/squid/lib/ssl_db -M 4MB -b 2048
> tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
> tls_outgoing_options capath=/usr/local/share/certs/
> tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> tls_outgoing_options flags=DONT_VERIFY_PEER
> sslcrtd_children 10
> 
> logfile_rotate 0
> debug_options rotate=0
> shutdown_lifetime 3 seconds
> # Allow local network(s) on interface(s)
> acl localnet src  192.168.1.0/27
> forwarded_for transparent
> httpd_suppress_version_string on
> uri_whitespace strip
> 
> acl getmethod method GET
> 
> acl windowsupdate dstdomain windowsupdate.microsoft.com
> acl windowsupdate dstdomain .update.microsoft.com
> acl windowsupdate dstdomain download.windowsupdate.com
> acl windowsupdate dstdomain redir.metaservices.microsoft.com
> acl windowsupdate dstdomain images.metaservices.microsoft.com
> acl windowsupdate dstdomain c.microsoft.com
> acl windowsupdate dstdomain www.download.windowsupdate.com
> acl windowsupdate dstdomain wustat.windows.com
> acl windowsupdate dstdomain crl.microsoft.com
> acl windowsupdate dstdomain sls.microsoft.com
> acl windowsupdate dstdomain productactivation.one.microsoft.com
> acl windowsupdate dstdomain ntservicepack.microsoft.com
> acl windowsupdate dstdomain dc1-st.ksn.kaspersky-labs.com
> acl windowsupdate dstdomain dc1-file.ksn.kaspersky-labs.com
> acl windowsupdate dstdomain dc1.ksn.kaspersky-labs.com
> 
> acl rewritedoms dstdomain .facebook.com .akamaihd.net .fbcdn.net .google.com .static.com .apple.com .oracle.com .sun.com .java.com .adobe.com .steamstatic.com .steampowered.com .steamcontent.com .google.com
> 
> store_id_program /usr/local/libexec/squid/storeid_file_rewrite /var/squid/storeid/storeid_rewrite.txt
> store_id_children 10 startup=5 idle=1 concurrency=0
> always_direct allow !getmethod
> store_id_access deny connect
> store_id_access deny !getmethod
> store_id_access allow rewritedoms
> reload_into_ims on
> max_stale 20 years
> minimum_expiry_time 0
> 


I am not sure how many of these refresh_pattern rules below are written 
by you, copy-pasted from elsewhere, or added automatically by pfsense. 
So how you need to fix the problems here is uncertain.

That said, please consider removing all these override-* and ignore-*.
<http://www.squid-cache.org/Doc/config/refresh_pattern/>


> 
> refresh_pattern -i squid.internal 10080 80% 79900 override-lastmod override-expire ignore-reload ignore-no-store ignore-must-revalidate ignore-private ignore-auth
> 
> #APPLE STUFF
> refresh_pattern -i apple.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip|dist)$ 0 80% 43200  refresh-ims
> 
> #apple update
> refresh_pattern -i (download|adcdownload).apple.com/.*.(pkg|dmg) 4320 100% 43200
> refresh_pattern -i appldnld.apple.com 129600 100% 129600
> refresh_pattern -i phobos.apple.com 129600 100% 129600
> refresh_pattern -i iosapps.itunes.apple.com 129600 100% 129600
> 
> # Updates: Windows
> refresh_pattern -i microsoft.com/..(cab|exe|msi|msu|msf|asf|wma|dat|zip)$ 4320 80% 43200  refresh-ims
> refresh_pattern -i windowsupdate.com/..(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$ 4320 80% 43200  refresh-ims
> refresh_pattern -i windows.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip)$ 4320 80% 43200  refresh-ims
> refresh_pattern -i microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
> refresh_pattern -i windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
> refresh_pattern -i windows.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
> refresh_pattern -i .*windowsupdate.com/.*.(cab|exe) 259200 100% 259200
> refresh_pattern -i .*update.microsoft.com/.*.(cab|exe|dll|msi|psf) 259200 100% 259200
> refresh_pattern windowsupdate.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
> refresh_pattern download.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
> refresh_pattern www.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
> refresh_pattern au.download.windowsupdate.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
> refresh_pattern bg.v4.pr.dl.ws.microsoft.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
> #windows update NEW UPDATE 0.04
> refresh_pattern update.microsoft.com/.*.(cab|exe) 43200 100% 129600
> refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200
> refresh_pattern update.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
> refresh_pattern -i .update.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
> refresh_pattern -i .windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
> refresh_pattern -i .download.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
> refresh_pattern -i .ws.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
> 
> refresh_pattern ([^.]+.)?(cs|content[1-9]|hsar|content-origin|client-download).[steampowered|steamcontent].com/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern ([^.]+.)?.akamai.steamstatic.com/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> 
> refresh_pattern -i ([^.]+.)?.adobe.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?.java.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?.sun.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?.oracle.com/.*.(zip|exe|tar.gz) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> 
> refresh_pattern -i appldnld.apple.com 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?apple.com/.*.(ipa) 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
>   
> refresh_pattern -i ([^.]+.)?.google.com/.*.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern -i ([^.]+.)?g.static.com/.*.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> 
> #FACEBOOK
> refresh_pattern ^http?://*.facebook.com/*  10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> 
> #FACEBOOK IMAGES
> refresh_pattern -i pixel.facebook.com..(jpg|png|gif|ico|css|js)  10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern -i .akamaihd.net..(jpg|png|gif|ico|css|js) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern -i (facebook.com).(jpg|png|gif) 10080 80% 43200 store-stale override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern static.(xx|ak).fbcdn.net.(jpg|gif|png) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern ^https?://profile.ak.fbcdn.net*.(jpg|gif|png) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> 
> #FACEBOOK VIDEO
> refresh_pattern -i .video.ak.fbcdn.net.*.(mp4|flv|mp3|amf) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern (audio|video)/(webm|mp4) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> 
> 
> range_offset_limit 512 MB windowsupdate
> maximum_object_size 512 MB windowsupdate
> range_offset_limit 0
> quick_abort_min -1 KB
> 
> cache_mem 64 MB
> maximum_object_size_in_memory 256 KB
> memory_replacement_policy heap LFUDA
> cache_replacement_policy heap LFUDA
> minimum_object_size 0 KB
> maximum_object_size 4 MB
> cache_dir diskd /var/squid/cache 64000 256 256
> offline_mode off
> cache_swap_low 90
> cache_swap_high 95
> acl donotcache dstdomain '/var/squid/acl/donotcache.acl'
> cache deny donotcache
> cache allow all
> # Add any of your own refresh_pattern entries above these.
> refresh_pattern ^ftp:    1440  20%  10080
> refresh_pattern ^gopher:  1440  0%  1440
> refresh_pattern -i (/cgi-bin/|?) 0  0%  0
> refresh_pattern .    0  20%  4320
> 
> 
> #Remote proxies
> 
> 
> # Setup some default acls
> # ACLs all, manager, localhost, and to_localhost are predefined.
> acl allsrc src all
> acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080 3128 3129 1025-65535
> acl sslports port 443 563 8080 5223 2197
> 
> acl purge method PURGE
> acl connect method CONNECT
> 
> # Define protocols used for redirects
> acl HTTP proto HTTP
> acl HTTPS proto HTTPS
> 
> # SslBump Peek and Splice
> # http://wiki.squid-cache.org/Features/SslPeekAndSplice
> # http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
> # Match against the current step during ssl_bump evaluation [fast]
> # Never matches and should not be used outside the ssl_bump context.
> #
> # At each SslBump step, Squid evaluates ssl_bump directives to find
> # the next bumping action (e.g., peek or splice). Valid SslBump step
> # values and the corresponding ssl_bump evaluation moments are:
> #   SslBump1: After getting TCP-level and HTTP CONNECT info.
> #   SslBump2: After getting TLS Client Hello info.
> #   SslBump3: After getting TLS Server Hello info.
> # These ACLs exist even when 'SSL/MITM Mode' is set to 'Custom' so that
> # they can be used there for custom configuration.
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> acl banned_hosts src '/var/squid/acl/banned_hosts.acl'
> acl whitelist dstdom_regex -i '/var/squid/acl/whitelist.acl'
> acl blacklist dstdom_regex -i '/var/squid/acl/blacklist.acl'
> http_access allow manager localhost
> 
> # Allow external cache managers
> acl ext_manager src 192.168.1.1
> acl ext_manager src 127.0.0.1
> http_access allow manager ext_manager
> 
> http_access deny manager
> http_access allow purge localhost
> http_access deny purge
> http_access deny !safeports
> http_access deny CONNECT !sslports
> 
> # Always allow localhost connections
> http_access allow localhost
> 
> quick_abort_min 0 KB
> quick_abort_max 0 KB
> quick_abort_pct 95
> request_body_max_size 0 KB
> delay_pools 1
> delay_class 1 2
> delay_parameters 1 -1/-1 -1/-1
> delay_initial_bucket_level 100
> delay_access 1 allow allsrc
> 
> # Reverse Proxy settings
> 
> deny_info TCP_RESET allsrc
> 
> # Package Integration
> url_rewrite_program /usr/local/bin/squidGuard -c /usr/local/etc/squidGuard/squidGuard.conf
> url_rewrite_bypass off
> url_rewrite_children 32 startup=8 idle=4 concurrency=0
> 

Squidguard is very outdated. You should upgrade to its successor 
ufdbguard if possible.



> # Custom options before auth
> #host_verify_strict on
> 
> # These hosts are banned
> http_access deny banned_hosts
> # Always allow access to whitelist domains
> http_access allow whitelist
> # Block access to blacklist domains
> http_access deny blacklist
> # List of domains allowed to logging in to Google services
> request_header_access X-GoogApps-Allowed-Domains deny all
> request_header_add X-GoogApps-Allowed-Domains consumer_accounts
> # Set YouTube safesearch restriction
> acl youtubedst dstdomain -n www.youtube.com m.youtube.com youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com
> request_header_access YouTube-Restrict deny all
> request_header_add YouTube-Restrict none youtubedst
> acl sglog url_regex -i sgr=ACCESSDENIED
> http_access deny sglog
> # Custom SSL/MITM options before auth
> acl manager proto cache_object
> acl localhost src 192.168.1.1/32
> #cachemgr_passwd disable offline_toggle reconfigure shutdown
> #cachemgr_passwd secret all
> acl https_login url_regex -i ^https.*(login|Login).*
> acl no_miss url_regex -i ^.*gateway.facebook.com/ws/realtime?
> acl no_miss url_regex -i ^.*web-chat-e2ee.facebook.com/ws/chat	
> acl CONNECT method CONNECT
> acl wuCONNECT dstdomain www.update.microsoft.com
> acl wuCONNECT dstdomain sls.microsoft.com
> http_access allow CONNECT wuCONNECT localnet
> http_access allow CONNECT wuCONNECT localhost
> http_access allow windowsupdate localnet
> http_access allow windowsupdate localhost
> http_access deny manager
> 
> acl BrokenButTrustedServers dstdomain '/usr/local/pkg/dstdom.broken'
> acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
> sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
> sslproxy_cert_error deny all
> 
> acl splice_only src 192.168.1.8 #Tasha iPhone
> acl splice_only src 192.168.1.10 #Jon iPhone
> acl splice_only src 192.168.1.11 #Amazon Fire
> acl splice_only src 192.168.1.15 #Tasha HP
> acl splice_only src 192.168.1.16 #iPad
> 
> acl NoSSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.nobump'
> 
> acl markBumped annotate_client bumped=true
> acl bump_only src 192.168.1.3 #webtv
> acl bump_only src 192.168.1.4 #toshiba
> acl bump_only src 192.168.1.5 #imac
> acl bump_only src 192.168.1.9 #macbook
> acl bump_only src 192.168.1.13 #dell
> 

You have a previous "cache allow all". This below rule does nothing.

> cache deny https_login
> 
> ssl_bump peek step1
> miss_access deny no_miss
> ssl_bump splice https_login
> ssl_bump splice splice_only
> ssl_bump splice NoSSLIntercept
> ssl_bump bump bump_only markBumped
> ssl_bump stare all
> 
> acl markedBumped note bumped true
> url_rewrite_access deny markedBumped
> 
> http_access deny all
> read_ahead_gap 32 KB
> negative_ttl 1 second
> connect_timeout 30 seconds
> request_timeout 60 seconds
> half_closed_clients off
> shutdown_lifetime 10 seconds
> negative_dns_ttl 1 seconds
> ignore_unknown_nameservers on
> pipeline_prefetch 100
> 
> #acl SSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.bump'
> #ssl_bump bump SSLIntercept
> 

You already have an earlier "http_access deny all". The below lines do 
nothing.

> # Setup allowed ACLs
> # Allow local network(s) on interface(s)
> http_access allow localnet
> # Default block all to be sure
> http_access deny allsrc
> 


HTH
Amos


From technik at kjj.cz  Fri Apr  5 12:16:09 2024
From: technik at kjj.cz (=?UTF-8?B?TG91xI1hbnNrw70gTHVrw6HFoQ==?=)
Date: Fri, 5 Apr 2024 14:16:09 +0200
Subject: [squid-users] Chrome auto-HTTPS-upgrade - not falling to http
In-Reply-To: <e8845677-fe34-439a-9bfe-4a0b2aa3461a@measurement-factory.com>
References: <82ae59b8-c835-4715-a836-418e8d44d33f@kjj.cz>
 <e774283f-ad56-4872-a402-78a75c207a26@kjj.cz>
 <0eff858d-31ce-4107-bce1-d314f55b3b79@treenet.co.nz>
 <e8845677-fe34-439a-9bfe-4a0b2aa3461a@measurement-factory.com>
Message-ID: <bfe54f01-41e6-4fe1-be93-220a383c56c2@kjj.cz>

FYI

Squid Object Cache: Version 6.8-VCS
Build Info: GIT V6.8 commit 4bee0c8

Could you please somehow elaborate how this seems to be working?

acl SquidSecureConnectFail squid_error ERR_SECURE_CONNECT_FAIL
acl SquidTLSErrorConnect ssl_error SQUID_TLS_ERR_CONNECT

#tunnel all for connection errors
on_unsupported_protocol tunnel SquidTLSErrorConnect
on_unsupported_protocol tunnel SquidSecureConnectFail

Is it a good or bad attempt? As I put redir.netcentrum.cz as an example 
in my first post - now it seems to just request TCP_MISS/200 815 GET 
http://redir.netcentrum.cz/? - ORIGINAL_DST/46.255.231.158 text/html -. 
I do not think my chrome just decided this site is http only and call it 
like this forever. I just did not see more SSL errors till yesterday . I 
do not say I haven't seen any (during some fairly short period) - such 
as SSL version errors, TLS inappropiate fallbacks, broken certs, no 
common ciphers etc. - but now I could not find a site that does not work 
(for me) - I have to ask my users. Anyway - squid seemed to have slight 
problems downloading intermediate certificates - to work properly - so I 
had to create a collection of several ones for myself (and some root 
certificates too - for example from MS WU site etc.) - but this could be 
just trouble with my Debian underlaying distro. (BTW I've alerady 
implemented transaction_initiator certificate-fetching acl and have 
http_access line for it)

L

Dne 03.04.2024 v 17:05 Alex Rousskov napsal(a):
> On 2024-04-03 02:14, Lou?ansk? Luk?? wrote:
>
>> this has recently started me up more then let it go. For a while
>> chrome is upgrading in-page links to https.
> Just to add two more pieces of related information to this thread:
>
> Some Squid admins report that their v6-based code does not suffer from 
> this issue while their v5-based code does. I have not verified those 
> reports, but there may be more to the story here. What Squid version 
> are _you_ using?
>
> One way to track progress with this annoying and complex issue is to 
> follow the following pull request. The current code cannot be 
> officially merged as is, and I would not recommend using it in 
> production (because of low-level bugs that will probably crash Squid 
> in some cases), but testing it in the lab and providing feedback to 
> authors may be useful:
>
> https://github.com/squid-cache/squid/pull/1668
>
> HTH,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240405/b9e23490/attachment.htm>

From rousskov at measurement-factory.com  Fri Apr  5 17:56:20 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 5 Apr 2024 13:56:20 -0400
Subject: [squid-users] Chrome auto-HTTPS-upgrade - not falling to http
In-Reply-To: <bfe54f01-41e6-4fe1-be93-220a383c56c2@kjj.cz>
References: <82ae59b8-c835-4715-a836-418e8d44d33f@kjj.cz>
 <e774283f-ad56-4872-a402-78a75c207a26@kjj.cz>
 <0eff858d-31ce-4107-bce1-d314f55b3b79@treenet.co.nz>
 <e8845677-fe34-439a-9bfe-4a0b2aa3461a@measurement-factory.com>
 <bfe54f01-41e6-4fe1-be93-220a383c56c2@kjj.cz>
Message-ID: <9ea93946-f050-471a-862b-b7cd39c0a92f@measurement-factory.com>

On 2024-04-05 08:16, Lou?ansk? Luk?? wrote:

> Build Info: GIT V6.8 commit 4bee0c8
> 
> Could you please somehow elaborate how this seems to be working?
> 
> acl SquidSecureConnectFail squid_error ERR_SECURE_CONNECT_FAIL
> acl SquidTLSErrorConnect ssl_error SQUID_TLS_ERR_CONNECT
> 
> #tunnel all for connection errors
> on_unsupported_protocol tunnel SquidTLSErrorConnect
> on_unsupported_protocol tunnel SquidSecureConnectFail

Assuming the above rules have the desired effect, I speculate that, in 
your particular test cases (where these rules have the desired effect), 
the tested non-https origin servers result in those two Squid TLS 
errors, those errors happen where on_unsupported_protocol still applies, 
and the selected "tunnel" action tickles the right Chrome behavior. I 
also speculate that not all non-https origin servers exhibit similar 
behavior because other errors were alleged to (also) matter during PR 
#1668 work (e.g., ERR_ZERO_SIZE_OBJECT).

Sorry, I currently do not have enough free time to verify any of the 
above assumptions and speculations. Some of them do surprise me, but 
that does not mean they have to be wrong/false.


> Is it a good or bad attempt? As I put redir.netcentrum.cz as an example 
> in my first post - now it seems to just request TCP_MISS/200 815 GET 
> http://redir.netcentrum.cz/? - ORIGINAL_DST/46.255.231.158 text/html -.

If there is no corresponding TLS connection attempt (through Squid) 
before that, then Chrome has changed its behavior in your tests (or your 
network has stopped delivering that attempt to Squid if your Squid is 
intercepting Chrome TLS connections rather than receiving plain CONNECT 
requests from Chrome). Without such an attempt, you are not really 
testing what this thread calls "Chrome auto-HTTPS-upgrade"...


> I do not think my chrome just decided this site is http only and call it 
> like this forever. I just did not see more SSL errors till yesterday . I 
> do not say I haven't seen any (during some fairly short period) - such 
> as SSL version errors, TLS inappropiate fallbacks, broken certs, no 
> common ciphers etc. - but now I could not find a site that does not work 
> (for me) - I have to ask my users.

Same "If there is no..." comment applies.


> Anyway - squid seemed to have slight 
> problems downloading intermediate certificates - to work properly - so I 
> had to create a collection of several ones for myself (and some root 
> certificates too - for example from MS WU site etc.) - but this could be 
> just trouble with my Debian underlaying distro. (BTW I've alerady 
> implemented transaction_initiator certificate-fetching acl and have 
> http_access line for it)

This sounds like a completely separate issue. If you are suspecting that 
Squid should get certain intermediate certificates but does not, check 
Bugzilla, and, if there is no corresponding bug report, file a new one.


HTH,

Alex.


> Dne 03.04.2024 v 17:05 Alex Rousskov napsal(a):
>> On 2024-04-03 02:14, Lou?ansk? Luk?? wrote:
>>
>>> this has recently started me up more then let it go. For a while
>>> chrome is upgrading in-page links to https.
>> Just to add two more pieces of related information to this thread:
>>
>> Some Squid admins report that their v6-based code does not suffer from 
>> this issue while their v5-based code does. I have not verified those 
>> reports, but there may be more to the story here. What Squid version 
>> are _you_ using?
>>
>> One way to track progress with this annoying and complex issue is to 
>> follow the following pull request. The current code cannot be 
>> officially merged as is, and I would not recommend using it in 
>> production (because of low-level bugs that will probably crash Squid 
>> in some cases), but testing it in the lab and providing feedback to 
>> authors may be useful:
>>
>> https://github.com/squid-cache/squid/pull/1668
>>
>> HTH,
>>
>> Alex.
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Fri Apr  5 20:33:32 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 5 Apr 2024 16:33:32 -0400
Subject: [squid-users] Chrome auto-HTTPS-upgrade - not falling to http
In-Reply-To: <ba1742ee-2a97-466e-a739-84380e8512e9@natur.cuni.cz>
References: <mailman.984.1712206107.1200.squid-users@lists.squid-cache.org>
 <ba1742ee-2a97-466e-a739-84380e8512e9@natur.cuni.cz>
Message-ID: <673414ff-4e52-4fbd-b54b-c9681590986b@measurement-factory.com>

On 2024-04-04 03:01, David Komanek wrote:
> I do not observe this problem accessing sites running only 
> on port 80 (no 443 at all), but my configuration is simple:
> 
> squid 6.6 as FreeBSD binary package
> 
> not much about ssl in the config file though, just passing it through, 
> no ssl juggling

Your use case is not applicable to this problem because your Squid is 
not using SslBump. It is SslBump actions that confuse Chrome (in some 
cases).

Alex.


> acl SSL_ports port
> acl Safe_ports port 80
> acl Safe_ports port 443
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access deny to_localhost
> http_access allow ....
> http_access allow ....
> http_access allow ....
> http_access allow ....
> http_access allow ....
> http_access deny all
> 
> I don't think it was different with squid 5.9, which I used till 
> November 2023.
> 
> Occasionally, I see another problem, which may or may not be related to 
> squid ssl handling configuration: PR_END_OF_FILE_ERROR (Firefox) / 
> ERR_CONNECTION_CLOSED (Chrome), typically accessing samba.org. But they 
> use permanent redirect from http to https, so it another situation than 
> http-only site.
> 
> David
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From jonathanlee571 at gmail.com  Fri Apr  5 22:34:54 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Apr 2024 15:34:54 -0700
Subject: [squid-users] Squid cache questions
In-Reply-To: <bef43696-be7f-463b-b82e-d4346abba2a5@treenet.co.nz>
References: <F23BE06C-985E-4F47-BE09-B16EB7BCC2C7@gmail.com>
 <bef43696-be7f-463b-b82e-d4346abba2a5@treenet.co.nz>
Message-ID: <A0DD0E1A-A9F5-4258-9AF9-8A46FCDF3427@gmail.com>

if (empty($settings['sslproxy_compatibility_mode']) || ($settings['sslproxy_compatibility_mode'] == 'modern')) {
					// Modern cipher suites
					$sslproxy_cipher = "EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS";
					$sslproxy_options .= ",NO_TLSv1";
				} else {
					$sslproxy_cipher = "EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS";
				}

Should the RC4  be removed or allowed?

https://github.com/pfsense/FreeBSD-ports/pull/1365



> On Apr 4, 2024, at 18:17, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 4/04/24 17:48, Jonathan Lee wrote:
>> Is there any particular order to squid configuration??
> 
> Yes. <https://wiki.squid-cache.org/SquidFaq/OrderIsImportant>
> 
> 
>> Does this look correct?
> 
> Best way to find out is to run "squid -k parse", which should be done after upgrades as well to identify and fix changes between versions as we improve the output.
> 
> 
>> I actually get allot of hits and it functions amazing, so I wanted to share this in case I could improve something. Is there any issues with security?
> 
> Yes, the obvious one is "DONT_VERIFY_PEER" disabling TLS security entirely on outbound connections. That particular option will prevent you even being told about suspicious activity regarding TLS.
> 
> Also there are a few weird things in your TLS cipher settings, such as this sequence "  EECDH+aRSA+RC4:...:!RC4 "
> Which as I understand, enables the EECDH with RC4 hash, but also forbids all uses of RC4.
> 
> 
>> I am concerned that an invasive container could become installed in the cache and data marshal the network card.
> 
> You have a limit of 4 MB for objects allowed to pass through this proxy, exception being objects from domains listed in the "windowsupdate" ACL (not all Windows related) which are allowed up to 512 MB.
> 
> For the general case, any type of file which can store an image of some system is a risk for that type of vulnerability can be cached.
> 
> The place to fix that vulnerability properly is not the cache or Squid. It is the OS permissions allowing non-Squid software access to the cache files and/or directory.
> 
> 
> 
>> Here is my config
>> # This file is automatically generated by pfSense
>> # Do not edit manually !
> 
> Since this file is generated by pfsense there is little that can be done about ordering issues and very hard to tell which of the problems below are due to pfsense and which due toy your settings.
> 
> FWIW, there are no major issues, just some lines not being necessary due to setting things to their default values, or just some blocks already denyign things that are blocked previously.
> 
> 
>> http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>> http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>> icp_port 0
>> digest_generation off
>> dns_v4_first on
>> pid_filename /var/run/squid/squid.pid
>> cache_effective_user squid
>> cache_effective_group proxy
>> error_default_language en
>> icon_directory /usr/local/etc/squid/icons
>> visible_hostname ****
>> cache_mgr ****
>> access_log /var/squid/logs/access.log
>> cache_log /var/squid/logs/cache.log
>> cache_store_log none
>> netdb_filename /var/squid/logs/netdb.state
>> pinger_enable on
>> pinger_program /usr/local/libexec/squid/pinger
>> sslcrtd_program /usr/local/libexec/squid/security_file_certgen -s /var/squid/lib/ssl_db -M 4MB -b 2048
>> tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
>> tls_outgoing_options capath=/usr/local/share/certs/
>> tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>> tls_outgoing_options flags=DONT_VERIFY_PEER
>> sslcrtd_children 10
>> logfile_rotate 0
>> debug_options rotate=0
>> shutdown_lifetime 3 seconds
>> # Allow local network(s) on interface(s)
>> acl localnet src  192.168.1.0/27
>> forwarded_for transparent
>> httpd_suppress_version_string on
>> uri_whitespace strip
>> acl getmethod method GET
>> acl windowsupdate dstdomain windowsupdate.microsoft.com <http://windowsupdate.microsoft.com/>
>> acl windowsupdate dstdomain .update.microsoft.com <http://update.microsoft.com/>
>> acl windowsupdate dstdomain download.windowsupdate.com <http://download.windowsupdate.com/>
>> acl windowsupdate dstdomain redir.metaservices.microsoft.com <http://redir.metaservices.microsoft.com/>
>> acl windowsupdate dstdomain images.metaservices.microsoft.com <http://images.metaservices.microsoft.com/>
>> acl windowsupdate dstdomain c.microsoft.com <http://c.microsoft.com/>
>> acl windowsupdate dstdomain www.download.windowsupdate.com <http://www.download.windowsupdate.com/>
>> acl windowsupdate dstdomain wustat.windows.com <http://wustat.windows.com/>
>> acl windowsupdate dstdomain crl.microsoft.com <http://crl.microsoft.com/>
>> acl windowsupdate dstdomain sls.microsoft.com <http://sls.microsoft.com/>
>> acl windowsupdate dstdomain productactivation.one.microsoft.com <http://productactivation.one.microsoft.com/>
>> acl windowsupdate dstdomain ntservicepack.microsoft.com <http://ntservicepack.microsoft.com/>
>> acl windowsupdate dstdomain dc1-st.ksn.kaspersky-labs.com <http://dc1-st.ksn.kaspersky-labs.com/>
>> acl windowsupdate dstdomain dc1-file.ksn.kaspersky-labs.com <http://dc1-file.ksn.kaspersky-labs.com/>
>> acl windowsupdate dstdomain dc1.ksn.kaspersky-labs.com <http://dc1.ksn.kaspersky-labs.com/>
>> acl rewritedoms dstdomain .facebook.com <http://facebook.com/> .akamaihd.net <http://akamaihd.net/> .fbcdn.net <http://fbcdn.net/> .google.com <http://google.com/> .static.com <http://static.com/> .apple.com <http://apple.com/> .oracle.com <http://oracle.com/> .sun.com <http://sun.com/> .java.com <http://java.com/> .adobe.com <http://adobe.com/> .steamstatic.com <http://steamstatic.com/>.steampowered.com <http://steampowered.com/> .steamcontent.com <http://steamcontent.com/> .google.com <http://google.com/>
>> store_id_program /usr/local/libexec/squid/storeid_file_rewrite /var/squid/storeid/storeid_rewrite.txt
>> store_id_children 10 startup=5 idle=1 concurrency=0
>> always_direct allow !getmethod
>> store_id_access deny connect
>> store_id_access deny !getmethod
>> store_id_access allow rewritedoms
>> reload_into_ims on
>> max_stale 20 years
>> minimum_expiry_time 0
> 
> 
> I am not sure how many of these refresh_pattern rules below are written by you, copy-pasted from elsewhere, or added automatically by pfsense. So how you need to fix the problems here is uncertain.
> 
> That said, please consider removing all these override-* and ignore-*.
> <http://www.squid-cache.org/Doc/config/refresh_pattern/>
> 
> 
>> refresh_pattern -i squid.internal 10080 80% 79900 override-lastmod override-expire ignore-reload ignore-no-store ignore-must-revalidate ignore-private ignore-auth
>> #APPLE STUFF
>> refresh_pattern -i apple.com/ <http://apple.com/>..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip|dist)$ 0 80% 43200  refresh-ims
>> #apple update
>> refresh_pattern -i (download|adcdownload).apple.com <http://apple.com/>/.*.(pkg|dmg) 4320 100% 43200
>> refresh_pattern -i appldnld.apple.com <http://appldnld.apple.com/> 129600 100% 129600
>> refresh_pattern -i phobos.apple.com <http://phobos.apple.com/> 129600 100% 129600
>> refresh_pattern -i iosapps.itunes.apple.com <http://iosapps.itunes.apple.com/> 129600 100% 129600
>> # Updates: Windows
>> refresh_pattern -i microsoft.com/ <http://microsoft.com/>..(cab|exe|msi|msu|msf|asf|wma|dat|zip)$ 4320 80% 43200  refresh-ims
>> refresh_pattern -i windowsupdate.com/ <http://windowsupdate.com/>..(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$ 4320 80% 43200  refresh-ims
>> refresh_pattern -i windows.com/ <http://windows.com/>..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip)$ 4320 80% 43200  refresh-ims
>> refresh_pattern -i microsoft.com <http://microsoft.com/>/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
>> refresh_pattern -i windowsupdate.com <http://windowsupdate.com/>/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
>> refresh_pattern -i windows.com <http://windows.com/>/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
>> refresh_pattern -i .*windowsupdate.com <http://windowsupdate.com/>/.*.(cab|exe) 259200 100% 259200
>> refresh_pattern -i .*update.microsoft.com <http://update.microsoft.com/>/.*.(cab|exe|dll|msi|psf) 259200 100% 259200
>> refresh_pattern windowsupdate.com <http://windowsupdate.com/>/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
>> refresh_pattern download.microsoft.com <http://download.microsoft.com/>/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
>> refresh_pattern www.microsoft.com <http://www.microsoft.com/>/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
>> refresh_pattern au.download.windowsupdate.com <http://au.download.windowsupdate.com/>/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
>> refresh_pattern bg.v4.pr.dl.ws.microsoft.com <http://pr.dl.ws.microsoft.com/>/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
>> #windows update NEW UPDATE 0.04
>> refresh_pattern update.microsoft.com <http://update.microsoft.com/>/.*.(cab|exe) 43200 100% 129600
>> refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200
>> refresh_pattern update.microsoft.com <http://update.microsoft.com/>/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
>> refresh_pattern -i .update.microsoft.com <http://update.microsoft.com/>/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
>> refresh_pattern -i .windowsupdate.com <http://windowsupdate.com/>/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
>> refresh_pattern -i .download.microsoft.com <http://download.microsoft.com/>/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
>> refresh_pattern -i .ws.microsoft.com <http://ws.microsoft.com/>/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
>> refresh_pattern ([^.]+.)?(cs|content[1-9]|hsar|content-origin|client-download).[steampowered|steamcontent].com/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
>> refresh_pattern ([^.]+.)?.akamai.steamstatic.com <http://akamai.steamstatic.com/>/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
>> refresh_pattern -i ([^.]+.)?.adobe.com <http://adobe.com/>/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
>> refresh_pattern -i ([^.]+.)?.java.com <http://java.com/>/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
>> refresh_pattern -i ([^.]+.)?.sun.com <http://sun.com/>/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
>> refresh_pattern -i ([^.]+.)?.oracle.com <http://oracle.com/>/.*.(zip|exe|tar.gz) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
>> refresh_pattern -i appldnld.apple.com <http://appldnld.apple.com/> 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
>> refresh_pattern -i ([^.]+.)?apple.com <http://apple.com/>/.*.(ipa) 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
>>  refresh_pattern -i ([^.]+.)?.google.com <http://google.com/>/.*.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
>> refresh_pattern -i ([^.]+.)?g.static.com <http://g.static.com/>/.*.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
>> #FACEBOOK
>> refresh_pattern ^http?://*.facebook.com/* <http://facebook.com/*>  10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
>> #FACEBOOK IMAGES
>> refresh_pattern -i pixel.facebook.com <http://pixel.facebook.com/>..(jpg|png|gif|ico|css|js)  10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
>> refresh_pattern -i .akamaihd.net <http://akamaihd.net/>..(jpg|png|gif|ico|css|js) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
>> refresh_pattern -i (facebook.com <http://facebook.com/>).(jpg|png|gif) 10080 80% 43200 store-stale override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
>> refresh_pattern static.(xx|ak).fbcdn.net <http://fbcdn.net/>.(jpg|gif|png) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
>> refresh_pattern ^https?://profile.ak.fbcdn.net <http://profile.ak.fbcdn.net/>*.(jpg|gif|png) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
>> #FACEBOOK VIDEO
>> refresh_pattern -i .video.ak.fbcdn.net <http://video.ak.fbcdn.net/>.*.(mp4|flv|mp3|amf) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
>> refresh_pattern (audio|video)/(webm|mp4) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
>> range_offset_limit 512 MB windowsupdate
>> maximum_object_size 512 MB windowsupdate
>> range_offset_limit 0
>> quick_abort_min -1 KB
>> cache_mem 64 MB
>> maximum_object_size_in_memory 256 KB
>> memory_replacement_policy heap LFUDA
>> cache_replacement_policy heap LFUDA
>> minimum_object_size 0 KB
>> maximum_object_size 4 MB
>> cache_dir diskd /var/squid/cache 64000 256 256
>> offline_mode off
>> cache_swap_low 90
>> cache_swap_high 95
>> acl donotcache dstdomain '/var/squid/acl/donotcache.acl'
>> cache deny donotcache
>> cache allow all
>> # Add any of your own refresh_pattern entries above these.
>> refresh_pattern ^ftp:    1440  20%  10080
>> refresh_pattern ^gopher:  1440  0%  1440
>> refresh_pattern -i (/cgi-bin/|?) 0  0%  0
>> refresh_pattern .    0  20%  4320
>> #Remote proxies
>> # Setup some default acls
>> # ACLs all, manager, localhost, and to_localhost are predefined.
>> acl allsrc src all
>> acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080 3128 3129 1025-65535
>> acl sslports port 443 563 8080 5223 2197
>> acl purge method PURGE
>> acl connect method CONNECT
>> # Define protocols used for redirects
>> acl HTTP proto HTTP
>> acl HTTPS proto HTTPS
>> # SslBump Peek and Splice
>> # http://wiki.squid-cache.org/Features/SslPeekAndSplice
>> # http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>> # Match against the current step during ssl_bump evaluation [fast]
>> # Never matches and should not be used outside the ssl_bump context.
>> #
>> # At each SslBump step, Squid evaluates ssl_bump directives to find
>> # the next bumping action (e.g., peek or splice). Valid SslBump step
>> # values and the corresponding ssl_bump evaluation moments are:
>> #   SslBump1: After getting TCP-level and HTTP CONNECT info.
>> #   SslBump2: After getting TLS Client Hello info.
>> #   SslBump3: After getting TLS Server Hello info.
>> # These ACLs exist even when 'SSL/MITM Mode' is set to 'Custom' so that
>> # they can be used there for custom configuration.
>> acl step1 at_step SslBump1
>> acl step2 at_step SslBump2
>> acl step3 at_step SslBump3
>> acl banned_hosts src '/var/squid/acl/banned_hosts.acl'
>> acl whitelist dstdom_regex -i '/var/squid/acl/whitelist.acl'
>> acl blacklist dstdom_regex -i '/var/squid/acl/blacklist.acl'
>> http_access allow manager localhost
>> # Allow external cache managers
>> acl ext_manager src 192.168.1.1
>> acl ext_manager src 127.0.0.1
>> http_access allow manager ext_manager
>> http_access deny manager
>> http_access allow purge localhost
>> http_access deny purge
>> http_access deny !safeports
>> http_access deny CONNECT !sslports
>> # Always allow localhost connections
>> http_access allow localhost
>> quick_abort_min 0 KB
>> quick_abort_max 0 KB
>> quick_abort_pct 95
>> request_body_max_size 0 KB
>> delay_pools 1
>> delay_class 1 2
>> delay_parameters 1 -1/-1 -1/-1
>> delay_initial_bucket_level 100
>> delay_access 1 allow allsrc
>> # Reverse Proxy settings
>> deny_info TCP_RESET allsrc
>> # Package Integration
>> url_rewrite_program /usr/local/bin/squidGuard -c /usr/local/etc/squidGuard/squidGuard.conf
>> url_rewrite_bypass off
>> url_rewrite_children 32 startup=8 idle=4 concurrency=0
> 
> Squidguard is very outdated. You should upgrade to its successor ufdbguard if possible.
> 
> 
> 
>> # Custom options before auth
>> #host_verify_strict on
>> # These hosts are banned
>> http_access deny banned_hosts
>> # Always allow access to whitelist domains
>> http_access allow whitelist
>> # Block access to blacklist domains
>> http_access deny blacklist
>> # List of domains allowed to logging in to Google services
>> request_header_access X-GoogApps-Allowed-Domains deny all
>> request_header_add X-GoogApps-Allowed-Domains consumer_accounts
>> # Set YouTube safesearch restriction
>> acl youtubedst dstdomain -n www.youtube.com <http://www.youtube.com/> m.youtube.com <http://m.youtube.com/> youtubei.googleapis.com <http://youtubei.googleapis.com/> youtube.googleapis.com <http://youtube.googleapis.com/> www.youtube-nocookie.com <http://www.youtube-nocookie.com/>
>> request_header_access YouTube-Restrict deny all
>> request_header_add YouTube-Restrict none youtubedst
>> acl sglog url_regex -i sgr=ACCESSDENIED
>> http_access deny sglog
>> # Custom SSL/MITM options before auth
>> acl manager proto cache_object
>> acl localhost src 192.168.1.1/32
>> #cachemgr_passwd disable offline_toggle reconfigure shutdown
>> #cachemgr_passwd secret all
>> acl https_login url_regex -i ^https.*(login|Login).*
>> acl no_miss url_regex -i ^.*gateway.facebook.com/ws/realtime? <http://gateway.facebook.com/ws/realtime?>
>> acl no_miss url_regex -i ^.*web-chat-e2ee.facebook.com/ws/chat <http://web-chat-e2ee.facebook.com/ws/chat>	
>> acl CONNECT method CONNECT
>> acl wuCONNECT dstdomain www.update.microsoft.com <http://www.update.microsoft.com/>
>> acl wuCONNECT dstdomain sls.microsoft.com <http://sls.microsoft.com/>
>> http_access allow CONNECT wuCONNECT localnet
>> http_access allow CONNECT wuCONNECT localhost
>> http_access allow windowsupdate localnet
>> http_access allow windowsupdate localhost
>> http_access deny manager
>> acl BrokenButTrustedServers dstdomain '/usr/local/pkg/dstdom.broken'
>> acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
>> sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
>> sslproxy_cert_error deny all
>> acl splice_only src 192.168.1.8 #Tasha iPhone
>> acl splice_only src 192.168.1.10 #Jon iPhone
>> acl splice_only src 192.168.1.11 #Amazon Fire
>> acl splice_only src 192.168.1.15 #Tasha HP
>> acl splice_only src 192.168.1.16 #iPad
>> acl NoSSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.nobump'
>> acl markBumped annotate_client bumped=true
>> acl bump_only src 192.168.1.3 #webtv
>> acl bump_only src 192.168.1.4 #toshiba
>> acl bump_only src 192.168.1.5 #imac
>> acl bump_only src 192.168.1.9 #macbook
>> acl bump_only src 192.168.1.13 #dell
> 
> You have a previous "cache allow all". This below rule does nothing.
> 
>> cache deny https_login
>> ssl_bump peek step1
>> miss_access deny no_miss
>> ssl_bump splice https_login
>> ssl_bump splice splice_only
>> ssl_bump splice NoSSLIntercept
>> ssl_bump bump bump_only markBumped
>> ssl_bump stare all
>> acl markedBumped note bumped true
>> url_rewrite_access deny markedBumped
>> http_access deny all
>> read_ahead_gap 32 KB
>> negative_ttl 1 second
>> connect_timeout 30 seconds
>> request_timeout 60 seconds
>> half_closed_clients off
>> shutdown_lifetime 10 seconds
>> negative_dns_ttl 1 seconds
>> ignore_unknown_nameservers on
>> pipeline_prefetch 100
>> #acl SSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.bump'
>> #ssl_bump bump SSLIntercept
> 
> You already have an earlier "http_access deny all". The below lines do nothing.
> 
>> # Setup allowed ACLs
>> # Allow local network(s) on interface(s)
>> http_access allow localnet
>> # Default block all to be sure
>> http_access deny allsrc
> 
> 
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240405/41b0d7a6/attachment.htm>

From jonathanlee571 at gmail.com  Sat Apr  6 05:40:13 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Apr 2024 22:40:13 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
Message-ID: <FC75961E-4CB1-480F-A190-9915F0472FA4@gmail.com>

Can you please help I moved from 5.8 to 6.6 I am getting access denied for mgr info.

Http manager is built in now right?
I can access it from the loopback
Sent from my iPhone

From jonathanlee571 at gmail.com  Sat Apr  6 05:48:30 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Apr 2024 22:48:30 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <FC75961E-4CB1-480F-A190-9915F0472FA4@gmail.com>
References: <FC75961E-4CB1-480F-A190-9915F0472FA4@gmail.com>
Message-ID: <DA266AA1-8B27-44EF-B72C-BF7DF6AE3637@gmail.com>

Correction I can?t access it from the loop back
Sent from my iPhone

> On Apr 5, 2024, at 22:40, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> ?Can you please help I moved from 5.8 to 6.6 I am getting access denied for mgr info.
> 
> Http manager is built in now right?
> I can access it from the loopback
> Sent from my iPhone


From gkinkie at gmail.com  Sat Apr  6 11:08:37 2024
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Sat, 6 Apr 2024 18:08:37 +0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <DA266AA1-8B27-44EF-B72C-BF7DF6AE3637@gmail.com>
References: <FC75961E-4CB1-480F-A190-9915F0472FA4@gmail.com>
 <DA266AA1-8B27-44EF-B72C-BF7DF6AE3637@gmail.com>
Message-ID: <CA+Y8hcNp=CwfQnfZLveb+ywrRgeSSFaQ1KJVo=-i74CtCamXhQ@mail.gmail.com>

Hi Jonathan,
  could you share the parts of your squid configuration that relate to the
cache manager?
It's hard to help you with so little information.

On Sat, Apr 6, 2024 at 12:48?PM Jonathan Lee <jonathanlee571 at gmail.com>
wrote:

> Correction I can?t access it from the loop back
> Sent from my iPhone
>
> > On Apr 5, 2024, at 22:40, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> >
> > ?Can you please help I moved from 5.8 to 6.6 I am getting access denied
> for mgr info.
> >
> > Http manager is built in now right?
> > I can access it from the loopback
> > Sent from my iPhone
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>


-- 
    Francesco
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240406/249d7b5b/attachment.htm>

From rousskov at measurement-factory.com  Sat Apr  6 19:22:10 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 6 Apr 2024 15:22:10 -0400
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <FC75961E-4CB1-480F-A190-9915F0472FA4@gmail.com>
References: <FC75961E-4CB1-480F-A190-9915F0472FA4@gmail.com>
Message-ID: <63549005-cbb8-483e-a5b7-9b2d7d469233@measurement-factory.com>

On 2024-04-06 01:40, Jonathan Lee wrote:
> Can you please help I moved from 5.8 to 6.6 I am getting access denied for mgr info.

> Http manager is built in now right?

Yes, it is and it was. No changes there.


> I can access it from the loopback


Currently, you may need to figure out what hostname Squid considers to 
self-identify as and use that hostname in cache manager requests. The 
following bug report may help, but there are several overlapping 
problems here, and that makes it difficult to triage without more 
information: https://bugs.squid-cache.org/show_bug.cgi?id=5283

I second Francesco's suggestion for sharing more information (privately 
if needed). A pointer to compressed ALL,9 cache.log for the problematic 
transaction would be best IMO[1], but you can start with sharing the 
output of your squidclient command with "-v" option added, your 
http_port configuration for port(s) 3128, and your visible_hostname 
setting in squid.conf (if any).


HTH,

Alex.

[1]: 
https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction



From squid3 at treenet.co.nz  Sun Apr  7 03:00:31 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 7 Apr 2024 15:00:31 +1200
Subject: [squid-users] Squid cache questions
In-Reply-To: <51DAB933-283B-4806-A9AC-6653359ED0A1@gmail.com>
References: <F23BE06C-985E-4F47-BE09-B16EB7BCC2C7@gmail.com>
 <bef43696-be7f-463b-b82e-d4346abba2a5@treenet.co.nz>
 <9206F516-EB66-449F-9751-89748F94E8D0@gmail.com>
 <51DAB933-283B-4806-A9AC-6653359ED0A1@gmail.com>
Message-ID: <0c69cd0c-a6af-4040-8934-8f508da248fa@treenet.co.nz>

On 5/04/24 17:25, Jonathan Lee wrote:
>> ssl_bump splice https_login
>> ssl_bump splice splice_only
>> ssl_bump splice NoSSLIntercept
>> ssl_bump bump bump_only markBumped
>> ssl_bump stare all
>> acl markedBumped note bumped true
>> url_rewrite_access deny markedBumped
> 
> for good hits should the url_rewirte_access deny be splice not bumped 
> connections ?
> 
> I feel I mixed this up
> 

Depends on what the re-write program is doing.

Ideally no traffic should be re-written by your proxy at all. Every 
change you make to the protocol(s) as they go throug adds problems to 
traffic behaviour.

Since you have squidguard..
  * if it only does ACL checks, that is fine. But ideally those checks 
would be done by http_access rules instead.
  * if it is actually changing URLs, that is where the problems start 
and caching is risky.

If you are re-writing URLs just to improve caching, I recommend using 
Store-ID feature instead for those URLs. It does a better job of 
balancing the caching risk vs ratio gains, even though outwardly it can 
appear to have less HITs.


HTH
Amos


From squid3 at treenet.co.nz  Sun Apr  7 03:09:55 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 7 Apr 2024 15:09:55 +1200
Subject: [squid-users] Squid cache questions
In-Reply-To: <A0DD0E1A-A9F5-4258-9AF9-8A46FCDF3427@gmail.com>
References: <F23BE06C-985E-4F47-BE09-B16EB7BCC2C7@gmail.com>
 <bef43696-be7f-463b-b82e-d4346abba2a5@treenet.co.nz>
 <A0DD0E1A-A9F5-4258-9AF9-8A46FCDF3427@gmail.com>
Message-ID: <6385ede4-cea3-4567-9e19-bd67278c4920@treenet.co.nz>


On 6/04/24 11:34, Jonathan Lee wrote:
> if (empty($settings['sslproxy_compatibility_mode']) || 
> ($settings['sslproxy_compatibility_mode'] == 'modern')) {
> // Modern cipher suites
> $sslproxy_cipher = 
> "EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS";
> $sslproxy_options .= ",NO_TLSv1";
> } else {
> $sslproxy_cipher = 
> "EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS";
> }
> 
> Should the RC4 ?be removed or allowed?
> 
> https://github.com/pfsense/FreeBSD-ports/pull/1365 
> <https://github.com/pfsense/FreeBSD-ports/pull/1365>
> 


AFAIK it should be removed. What I was intending to point out was that 
its removal via "!RC4" is likely making the prior "EECDH+aRSA+RC4" 
addition pointless. Sorry if that was not clear.

If you check the TLS handshake and find Squid is working fine without 
advertising "EECDH+aRSA+RC4" it would be a bit simpler/easier to read 
the config by removing that cipher and just relying on the "!RC4".


HTH
Amos


From squid3 at treenet.co.nz  Sun Apr  7 03:18:46 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 7 Apr 2024 15:18:46 +1200
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <DA266AA1-8B27-44EF-B72C-BF7DF6AE3637@gmail.com>
References: <FC75961E-4CB1-480F-A190-9915F0472FA4@gmail.com>
 <DA266AA1-8B27-44EF-B72C-BF7DF6AE3637@gmail.com>
Message-ID: <d018d560-acb2-406e-895d-8446759f41e5@treenet.co.nz>

On 6/04/24 18:48, Jonathan Lee wrote:
> Correction I can?t access it from the loop back

 From the config in the other "Squid cache questions" thread you are 
only intercepting traffic on the loopback 127.0.0.1:3128 port. You 
cannot access it directly on "localhost".

You do have direct proxy (and thus manager) access via the 
192.168.1.1:3128 so this URL should work:
   http://192.168.1.1:3128/squid-internal-mgr/menu


.. or substitute the raw-IP for the visible_hostname setting **if** that 
hostname actually resolves to that IP.


HTH
Amos


From jonathanlee571 at gmail.com  Sun Apr  7 04:29:53 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sat, 6 Apr 2024 21:29:53 -0700
Subject: [squid-users] Squid cache questions
In-Reply-To: <0c69cd0c-a6af-4040-8934-8f508da248fa@treenet.co.nz>
References: <F23BE06C-985E-4F47-BE09-B16EB7BCC2C7@gmail.com>
 <bef43696-be7f-463b-b82e-d4346abba2a5@treenet.co.nz>
 <9206F516-EB66-449F-9751-89748F94E8D0@gmail.com>
 <51DAB933-283B-4806-A9AC-6653359ED0A1@gmail.com>
 <0c69cd0c-a6af-4040-8934-8f508da248fa@treenet.co.nz>
Message-ID: <A86EB07C-C869-4B42-96BD-F5892C99D9A7@gmail.com>

Thanks for the reply I am using the built in StoreID program however it requires the database file so I have it only set to the items in the dynamic cache settings custom refresh areas. 

The rewrite program should redirect to pull from the cache right? Only for bumped connections and or cab files from Windows that come over as http. Squidguard only does URL checks and blocks some items that cause me issues mainly doubleclick.net and a couple other invasive sites and or different profiles for different devices. 

Everything works however I started to wonder if I am bumping connections for some I still would want the Windows refresh patterns to work so I thought if I url_rewrite_access deny them that would block the cache from being used also right? Of course the splice items I just want them spliced and checked with Squirdguard again the error page itself is that not considered a url_rewrite?

That?s what got me confused as I was thinking at the time an invasive container could redirect from the cache so I thought that?s why I would set up blocks for it however I am now wondering about the refresh items.

Thanks for the reply. Are you the guy that invented phone mail for Amos OS on Semens PBX systems and ROLM phones? I did training with you in Texas if that is you.

Thanks agin for your reply

Jonathan Lee
Adult Student 

> On Apr 6, 2024, at 20:00, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 5/04/24 17:25, Jonathan Lee wrote:
>>> ssl_bump splice https_login
>>> ssl_bump splice splice_only
>>> ssl_bump splice NoSSLIntercept
>>> ssl_bump bump bump_only markBumped
>>> ssl_bump stare all
>>> acl markedBumped note bumped true
>>> url_rewrite_access deny markedBumped
>> for good hits should the url_rewirte_access deny be splice not bumped connections ?
>> I feel I mixed this up
> 
> Depends on what the re-write program is doing.
> 
> Ideally no traffic should be re-written by your proxy at all. Every change you make to the protocol(s) as they go throug adds problems to traffic behaviour.
> 
> Since you have squidguard..
> * if it only does ACL checks, that is fine. But ideally those checks would be done by http_access rules instead.
> * if it is actually changing URLs, that is where the problems start and caching is risky.
> 
> If you are re-writing URLs just to improve caching, I recommend using Store-ID feature instead for those URLs. It does a better job of balancing the caching risk vs ratio gains, even though outwardly it can appear to have less HITs.
> 
> 
> HTH
> Amos



From jonathanlee571 at gmail.com  Wed Apr 10 14:50:51 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 10 Apr 2024 07:50:51 -0700
Subject: [squid-users] SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
Message-ID: <5A46B30E-D553-4681-9A18-50EEED90847C@gmail.com>

Hello fellow Squid Proxy Users can you please help

I am getting the following error in 6.6 after a upgrade from 5.8 does anyone know what this is caused by?

SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR

After it says kick abandoned this if for bumped clients with certificates 


Jonathan Lee

From bmatznick at pbandt.bank  Wed Apr 10 15:15:30 2024
From: bmatznick at pbandt.bank (Bobby Matznick)
Date: Wed, 10 Apr 2024 15:15:30 +0000
Subject: [squid-users] [External] squid-users Digest, Vol 116, Issue 7
In-Reply-To: <mailman.3.1712318402.3798964.squid-users@lists.squid-cache.org>
References: <mailman.3.1712318402.3798964.squid-users@lists.squid-cache.org>
Message-ID: <MW5PR14MB5289E10FE67E3888C772A2E6B0062@MW5PR14MB5289.namprd14.prod.outlook.com>

Question about squid, Debian version 4.13. Looking for a way to log referer's. I see the way that worked up until version 4, seems this does not work anymore. I'm having some trouble finding if anything replaced it or if there's another way to go about this? Here is the old way.
referrer_log /pathname

Thanks for any help you can provide!

Bobby

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of squid-users-request at lists.squid-cache.org
Sent: Friday, April 5, 2024 6:00 AM
To: squid-users at lists.squid-cache.org
Subject: [External] squid-users Digest, Vol 116, Issue 7

Caution: This is an external email and has a suspicious subject or content. Please take care when clicking links or opening attachments. When in doubt, contact your IT Department
Send squid-users mailing list submissions to
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

To subscribe or unsubscribe via the World Wide Web, visit
https://lists.squid-cache.org/listinfo/squid-users<https://lists.squid-cache.org/listinfo/squid-users>
or, via email, send a message with subject or body 'help' to
squid-users-request at lists.squid-cache.org<mailto:squid-users-request at lists.squid-cache.org>

You can reach the person managing the list at
squid-users-owner at lists.squid-cache.org<mailto:squid-users-owner at lists.squid-cache.org>

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

1. Re: Squid cache questions (Amos Jeffries)


----------------------------------------------------------------------

Message: 1
Date: Fri, 5 Apr 2024 14:17:16 +1300
From: Amos Jeffries <squid3 at treenet.co.nz<mailto:squid3 at treenet.co.nz>>
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Squid cache questions
Message-ID: <bef43696-be7f-463b-b82e-d4346abba2a5 at treenet.co.nz<mailto:bef43696-be7f-463b-b82e-d4346abba2a5 at treenet.co.nz>>
Content-Type: text/plain; charset=UTF-8; format=flowed

On 4/04/24 17:48, Jonathan Lee wrote:
> Is there any particular order to squid configuration??
>

Yes. <https://wiki.squid-cache.org/SquidFaq/OrderIsImportant<https://wiki.squid-cache.org/SquidFaq/OrderIsImportant>>


> Does this look correct?
>

Best way to find out is to run "squid -k parse", which should be done
after upgrades as well to identify and fix changes between versions as
we improve the output.


> I actually get allot of hits and it functions amazing, so I wanted to
> share this in case I could improve something. Is there any issues with
> security?

Yes, the obvious one is "DONT_VERIFY_PEER" disabling TLS security
entirely on outbound connections. That particular option will prevent
you even being told about suspicious activity regarding TLS.

Also there are a few weird things in your TLS cipher settings, such as
this sequence " EECDH+aRSA+RC4:...:!RC4 "
Which as I understand, enables the EECDH with RC4 hash, but also
forbids all uses of RC4.


> I am concerned that an invasive container could become
> installed in the cache and data marshal the network card.
>

You have a limit of 4 MB for objects allowed to pass through this proxy,
exception being objects from domains listed in the "windowsupdate" ACL
(not all Windows related) which are allowed up to 512 MB.

For the general case, any type of file which can store an image of some
system is a risk for that type of vulnerability can be cached.

The place to fix that vulnerability properly is not the cache or Squid.
It is the OS permissions allowing non-Squid software access to the cache
files and/or directory.



> Here is my config
>
> # This file is automatically generated by pfSense
> # Do not edit manually !

Since this file is generated by pfsense there is little that can be done
about ordering issues and very hard to tell which of the problems below
are due to pfsense and which due toy your settings.

FWIW, there are no major issues, just some lines not being necessary due
to setting things to their default values, or just some blocks already
denyign things that are blocked previously.


>
> http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>
> http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>
> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>
> icp_port 0
> digest_generation off
> dns_v4_first on
> pid_filename /var/run/squid/squid.pid
> cache_effective_user squid
> cache_effective_group proxy
> error_default_language en
> icon_directory /usr/local/etc/squid/icons
> visible_hostname ****
> cache_mgr ****
> access_log /var/squid/logs/access.log
> cache_log /var/squid/logs/cache.log
> cache_store_log none
> netdb_filename /var/squid/logs/netdb.state
> pinger_enable on
> pinger_program /usr/local/libexec/squid/pinger
> sslcrtd_program /usr/local/libexec/squid/security_file_certgen -s /var/squid/lib/ssl_db -M 4MB -b 2048
> tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
> tls_outgoing_options capath=/usr/local/share/certs/
> tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> tls_outgoing_options flags=DONT_VERIFY_PEER
> sslcrtd_children 10
>
> logfile_rotate 0
> debug_options rotate=0
> shutdown_lifetime 3 seconds
> # Allow local network(s) on interface(s)
> acl localnet src 192.168.1.0/27<http://192.168.1.0/27>
> forwarded_for transparent
> httpd_suppress_version_string on
> uri_whitespace strip
>
> acl getmethod method GET
>
> acl windowsupdate dstdomain windowsupdate.microsoft.com
> acl windowsupdate dstdomain .update.microsoft.com
> acl windowsupdate dstdomain download.windowsupdate.com
> acl windowsupdate dstdomain redir.metaservices.microsoft.com
> acl windowsupdate dstdomain images.metaservices.microsoft.com
> acl windowsupdate dstdomain c.microsoft.com
> acl windowsupdate dstdomain www.download.windowsupdate.com<http://www.download.windowsupdate.com>
> acl windowsupdate dstdomain wustat.windows.com
> acl windowsupdate dstdomain crl.microsoft.com
> acl windowsupdate dstdomain sls.microsoft.com
> acl windowsupdate dstdomain productactivation.one.microsoft.com
> acl windowsupdate dstdomain ntservicepack.microsoft.com
> acl windowsupdate dstdomain dc1-st.ksn.kaspersky-labs.com
> acl windowsupdate dstdomain dc1-file.ksn.kaspersky-labs.com
> acl windowsupdate dstdomain dc1.ksn.kaspersky-labs.com
>
> acl rewritedoms dstdomain .facebook.com .akamaihd.net .fbcdn.net .google.com .static.com .apple.com .oracle.com .sun.com .java.com .adobe.com .steamstatic.com .steampowered.com .steamcontent.com .google.com
>
> store_id_program /usr/local/libexec/squid/storeid_file_rewrite /var/squid/storeid/storeid_rewrite.txt
> store_id_children 10 startup=5 idle=1 concurrency=0
> always_direct allow !getmethod
> store_id_access deny connect
> store_id_access deny !getmethod
> store_id_access allow rewritedoms
> reload_into_ims on
> max_stale 20 years
> minimum_expiry_time 0
>


I am not sure how many of these refresh_pattern rules below are written
by you, copy-pasted from elsewhere, or added automatically by pfsense.
So how you need to fix the problems here is uncertain.

That said, please consider removing all these override-* and ignore-*.
<http://www.squid-cache.org/Doc/config/refresh_pattern/<http://www.squid-cache.org/Doc/config/refresh_pattern>>


>
> refresh_pattern -i squid.internal 10080 80% 79900 override-lastmod override-expire ignore-reload ignore-no-store ignore-must-revalidate ignore-private ignore-auth
>
> #APPLE STUFF
> refresh_pattern -i apple.com/.<http://apple.com/.>.(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip|dist)$ 0 80% 43200 refresh-ims
>
> #apple update
> refresh_pattern -i (download|adcdownload)apple.com/.*<http://apple.com/.*>.(pkg|dmg) 4320 100% 43200
> refresh_pattern -i appldnld.apple.com 129600 100% 129600
> refresh_pattern -i phobos.apple.com 129600 100% 129600
> refresh_pattern -i iosapps.itunes.apple.com 129600 100% 129600
>
> # Updates: Windows
> refresh_pattern -i microsoft.com/.<http://microsoft.com/.>.(cab|exe|msi|msu|msf|asf|wma|dat|zip)$ 4320 80% 43200 refresh-ims
> refresh_pattern -i windowsupdate.com/.<http://windowsupdate.com/.>.(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$ 4320 80% 43200 refresh-ims
> refresh_pattern -i windows.com/.<http://windows.com/.>.(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip)$ 4320 80% 43200 refresh-ims
> refresh_pattern -i microsoft.com/.*<http://microsoft.com/.*>.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
> refresh_pattern -i windowsupdate.com/.*<http://windowsupdate.com/.*>.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
> refresh_pattern -i windows.com/.*<http://windows.com/.*>.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
> refresh_pattern -i .*windowsupdate.com/.*<http://windowsupdate.com/.*>.(cab|exe) 259200 100% 259200
> refresh_pattern -i .*update.microsoft.com/.*<http://update.microsoft.com/.*>.(cab|exe|dll|msi|psf) 259200 100% 259200
> refresh_pattern windowsupdate.com/.*<http://windowsupdate.com/.*>.(cab|exe|dll|msi|psf) 10080 100% 43200
> refresh_pattern download.microsoft.com/.*<http://download.microsoft.com/.*>.(cab|exe|dll|msi|psf) 10080 100% 43200
> refresh_pattern www.microsoft.com/.*<http://www.microsoft.com/.*>.(cab|exe|dll|msi|psf) 10080 100% 43200
> refresh_pattern au.download.windowsupdate.com/.*<http://au.download.windowsupdate.com/.*>.(cab|exe|dll|msi|psf) 4320 100% 43200
> refresh_pattern bg.v4.pr.dl.ws.microsoft.com/.*<http://bg.v4.pr.dl.ws.microsoft.com/.*>.(cab|exe|dll|msi|psf) 4320 100% 43200
> #windows update NEW UPDATE 0.04
> refresh_pattern update.microsoft.com/.*<http://update.microsoft.com/.*>.(cab|exe) 43200 100% 129600
> refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200
> refresh_pattern update.microsoft.com/.*<http://update.microsoft.com/.*>.(cab|exe|dll|msi|psf) 10080 100% 43200
> refresh_pattern -i update.microsoft.com/.*<http://update.microsoft.com/.*>.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
> refresh_pattern -i windowsupdate.com/.*<http://windowsupdate.com/.*>.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
> refresh_pattern -i download.microsoft.com/.*<http://download.microsoft.com/.*>.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
> refresh_pattern -i ws.microsoft.com/.*<http://ws.microsoft.com/.*>.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
>
> refresh_pattern ([^.]+.)?(cs|content[1-9]|hsar|content-origin|client-download).[steampowered|steamcontent].com/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern ([^.]+.)?akamai.steamstatic.com/.*.*<http://akamai.steamstatic.com/.*.*> 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
>
> refresh_pattern -i ([^.]+.)?adobe.com/.*<http://adobe.com/.*>.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?java.com/.*<http://java.com/.*>.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?sun.com/.*<http://sun.com/.*>.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?oracle.com/.*<http://oracle.com/.*>.(zip|exe|tar.gz) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
>
> refresh_pattern -i appldnld.apple.com 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?apple.com/.*.(ipa)<http://apple.com/.*.(ipa)> 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
>
> refresh_pattern -i ([^.]+.)?google.com/.*<http://google.com/.*>.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern -i ([^.]+.)?g.static.com/.*<http://g.static.com/.*>.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
>
> #FACEBOOK
> refresh_pattern ^http?://*facebook.com/*<http://facebook.com/*> 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
>
> #FACEBOOK IMAGES
> refresh_pattern -i pixel.facebook.com..(jpg|png|gif|ico|css|js) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern -i .akamaihd.net..(jpg|png|gif|ico|css|js) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern -i (facebook.com).(jpg|png|gif) 10080 80% 43200 store-stale override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern static.(xx|ak).fbcdn.net.(jpg|gif|png) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern ^https?://profile.ak.fbcdn.net*.(jpg|gif|png) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
>
> #FACEBOOK VIDEO
> refresh_pattern -i .video.ak.fbcdn.net.*.(mp4|flv|mp3|amf) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern (audio|video)/(webm|mp4) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
>
>
> range_offset_limit 512 MB windowsupdate
> maximum_object_size 512 MB windowsupdate
> range_offset_limit 0
> quick_abort_min -1 KB
>
> cache_mem 64 MB
> maximum_object_size_in_memory 256 KB
> memory_replacement_policy heap LFUDA
> cache_replacement_policy heap LFUDA
> minimum_object_size 0 KB
> maximum_object_size 4 MB
> cache_dir diskd /var/squid/cache 64000 256 256
> offline_mode off
> cache_swap_low 90
> cache_swap_high 95
> acl donotcache dstdomain '/var/squid/acl/donotcache.acl'
> cache deny donotcache
> cache allow all
> # Add any of your own refresh_pattern entries above these.
> refresh_pattern ^ftp: 1440 20% 10080
> refresh_pattern ^gopher: 1440 0% 1440
> refresh_pattern -i (/cgi-bin/|?) 0 0% 0
> refresh_pattern . 0 20% 4320
>
>
> #Remote proxies
>
>
> # Setup some default acls
> # ACLs all, manager, localhost, and to_localhost are predefined.
> acl allsrc src all
> acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080 3128 3129 1025-65535
> acl sslports port 443 563 8080 5223 2197
>
> acl purge method PURGE
> acl connect method CONNECT
>
> # Define protocols used for redirects
> acl HTTP proto HTTP
> acl HTTPS proto HTTPS
>
> # SslBump Peek and Splice
> # http://wiki.squid-cache.org/Features/SslPeekAndSplice<http://wiki.squid-cache.org/Features/SslPeekAndSplice>
> # http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit<http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit>
> # Match against the current step during ssl_bump evaluation [fast]
> # Never matches and should not be used outside the ssl_bump context.
> #
> # At each SslBump step, Squid evaluates ssl_bump directives to find
> # the next bumping action (e.g., peek or splice). Valid SslBump step
> # values and the corresponding ssl_bump evaluation moments are:
> # SslBump1: After getting TCP-level and HTTP CONNECT info.
> # SslBump2: After getting TLS Client Hello info.
> # SslBump3: After getting TLS Server Hello info.
> # These ACLs exist even when 'SSL/MITM Mode' is set to 'Custom' so that
> # they can be used there for custom configuration.
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> acl banned_hosts src '/var/squid/acl/banned_hosts.acl'
> acl whitelist dstdom_regex -i '/var/squid/acl/whitelist.acl'
> acl blacklist dstdom_regex -i '/var/squid/acl/blacklist.acl'
> http_access allow manager localhost
>
> # Allow external cache managers
> acl ext_manager src 192.168.1.1
> acl ext_manager src 127.0.0.1<http://127.0.0.1>
> http_access allow manager ext_manager
>
> http_access deny manager
> http_access allow purge localhost
> http_access deny purge
> http_access deny !safeports
> http_access deny CONNECT !sslports
>
> # Always allow localhost connections
> http_access allow localhost
>
> quick_abort_min 0 KB
> quick_abort_max 0 KB
> quick_abort_pct 95
> request_body_max_size 0 KB
> delay_pools 1
> delay_class 1 2
> delay_parameters 1 -1/-1 -1/-1
> delay_initial_bucket_level 100
> delay_access 1 allow allsrc
>
> # Reverse Proxy settings
>
> deny_info TCP_RESET allsrc
>
> # Package Integration
> url_rewrite_program /usr/local/bin/squidGuard -c /usr/local/etc/squidGuard/squidGuard.conf
> url_rewrite_bypass off
> url_rewrite_children 32 startup=8 idle=4 concurrency=0
>

Squidguard is very outdated. You should upgrade to its successor
ufdbguard if possible.



> # Custom options before auth
> #host_verify_strict on
>
> # These hosts are banned
> http_access deny banned_hosts
> # Always allow access to whitelist domains
> http_access allow whitelist
> # Block access to blacklist domains
> http_access deny blacklist
> # List of domains allowed to logging in to Google services
> request_header_access X-GoogApps-Allowed-Domains deny all
> request_header_add X-GoogApps-Allowed-Domains consumer_accounts
> # Set YouTube safesearch restriction
> acl youtubedst dstdomain -n www.youtube.com<http://www.youtube.com> m.youtube.com youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com<http://www.youtube-nocookie.com>
> request_header_access YouTube-Restrict deny all
> request_header_add YouTube-Restrict none youtubedst
> acl sglog url_regex -i sgr=ACCESSDENIED
> http_access deny sglog
> # Custom SSL/MITM options before auth
> acl manager proto cache_object
> acl localhost src 192.168.1.1/32<http://192.168.1.1/32>
> #cachemgr_passwd disable offline_toggle reconfigure shutdown
> #cachemgr_passwd secret all
> acl https_login url_regex -i ^https.*(login|Login).*
> acl no_miss url_regex -i ^.*gateway.facebook.com/ws/realtime?<http://gateway.facebook.com/ws/realtime?>
> acl no_miss url_regex -i ^.*web-chat-e2ee.facebook.com/ws/chat<http://web-chat-e2ee.facebook.com/ws/chat>
> acl CONNECT method CONNECT
> acl wuCONNECT dstdomain www.update.microsoft.com<http://www.update.microsoft.com>
> acl wuCONNECT dstdomain sls.microsoft.com
> http_access allow CONNECT wuCONNECT localnet
> http_access allow CONNECT wuCONNECT localhost
> http_access allow windowsupdate localnet
> http_access allow windowsupdate localhost
> http_access deny manager
>
> acl BrokenButTrustedServers dstdomain '/usr/local/pkg/dstdom.broken'
> acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
> sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
> sslproxy_cert_error deny all
>
> acl splice_only src 192.168.1.8 #Tasha iPhone
> acl splice_only src 192.168.1.10 #Jon iPhone
> acl splice_only src 192.168.1.11 #Amazon Fire
> acl splice_only src 192.168.1.15 #Tasha HP
> acl splice_only src 192.168.1.16 #iPad
>
> acl NoSSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.nobump'
>
> acl markBumped annotate_client bumped=true
> acl bump_only src 192.168.1.3 #webtv
> acl bump_only src 192.168.1.4 #toshiba
> acl bump_only src 192.168.1.5 #imac
> acl bump_only src 192.168.1.9 #macbook
> acl bump_only src 192.168.1.13 #dell
>

You have a previous "cache allow all". This below rule does nothing.

> cache deny https_login
>
> ssl_bump peek step1
> miss_access deny no_miss
> ssl_bump splice https_login
> ssl_bump splice splice_only
> ssl_bump splice NoSSLIntercept
> ssl_bump bump bump_only markBumped
> ssl_bump stare all
>
> acl markedBumped note bumped true
> url_rewrite_access deny markedBumped
>
> http_access deny all
> read_ahead_gap 32 KB
> negative_ttl 1 second
> connect_timeout 30 seconds
> request_timeout 60 seconds
> half_closed_clients off
> shutdown_lifetime 10 seconds
> negative_dns_ttl 1 seconds
> ignore_unknown_nameservers on
> pipeline_prefetch 100
>
> #acl SSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.bump'
> #ssl_bump bump SSLIntercept
>

You already have an earlier "http_access deny all". The below lines do
nothing.

> # Setup allowed ACLs
> # Allow local network(s) on interface(s)
> http_access allow localnet
> # Default block all to be sure
> http_access deny allsrc
>


HTH
Amos


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
https://lists.squid-cache.org/listinfo/squid-users<https://lists.squid-cache.org/listinfo/squid-users>


------------------------------

End of squid-users Digest, Vol 116, Issue 7
*******************************************
CONFIDENTIALITY NOTICE: The information contained in and attached to this email is intended only for the confidential use of the person or entity to which the email is addressed. This email and any attachments may contain privileged and confidential information. If you are not the intended recipient, you are notified that you received this email in error and that any reading, retention, use or distribution of this email and attachments is strictly prohibited. If you received this email in error, you are requested to immediately notify us by calling 888-728-3550 or by return email and immediately and permanently delete the email and any attachments. Thank you.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240410/80de5108/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0.jpg
Type: image/jpeg
Size: 6398 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240410/80de5108/attachment.jpg>

From rousskov at measurement-factory.com  Wed Apr 10 15:38:57 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 10 Apr 2024 11:38:57 -0400
Subject: [squid-users]
 SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
In-Reply-To: <5A46B30E-D553-4681-9A18-50EEED90847C@gmail.com>
References: <5A46B30E-D553-4681-9A18-50EEED90847C@gmail.com>
Message-ID: <f10251e7-6c09-4657-80bc-e1d4a3267c91@measurement-factory.com>

On 2024-04-10 10:50, Jonathan Lee wrote:

> I am getting the following error in 6.6 after a upgrade from 5.8 does anyone know what this is caused by?
> 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR

     $ openssl errstr A000417
     error:0A000417:SSL routines::sslv3 alert illegal parameter

I think I have seen that error code before, but I do not recall the 
exact circumstances. Sorry! The error happens when Squid tries to accept 
(or peek at) a TLS connection from the client. Might be prohibited TLS 
version/feature, TLS greasing, or non-TLS traffic? Try examining client 
TLS Hello packet(s) in Wireshark.

Alex.



From gkinkie at gmail.com  Wed Apr 10 15:43:12 2024
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Wed, 10 Apr 2024 22:43:12 +0700
Subject: [squid-users] [External] squid-users Digest, Vol 116, Issue 7
In-Reply-To: <MW5PR14MB5289E10FE67E3888C772A2E6B0062@MW5PR14MB5289.namprd14.prod.outlook.com>
References: <mailman.3.1712318402.3798964.squid-users@lists.squid-cache.org>
 <MW5PR14MB5289E10FE67E3888C772A2E6B0062@MW5PR14MB5289.namprd14.prod.outlook.com>
Message-ID: <CA+Y8hcOnLRP2orJeTf8v_9YdX8iswVunWc1PZ3SAV+XjLquy3g@mail.gmail.com>

Have you checked https://www.squid-cache.org/Doc/config/logformat/ ?
There is a note about "logformat referrer", it should be what you are
looking for

On Wed, Apr 10, 2024 at 10:16?PM Bobby Matznick <bmatznick at pbandt.bank>
wrote:

> Question about squid, Debian version 4.13. Looking for a way to log
> referer?s. I see the way that worked up until version 4, seems this does
> not work anymore. I?m having some trouble finding if anything replaced it
> or if there?s another way to go about this? Here is the old way.
>
> referrer_log /pathname
>
>
>
> Thanks for any help you can provide!
>
>
>
> Bobby
>
>
>
> *From:* squid-users <squid-users-bounces at lists.squid-cache.org> *On
> Behalf Of *squid-users-request at lists.squid-cache.org
> *Sent:* Friday, April 5, 2024 6:00 AM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* [External] squid-users Digest, Vol 116, Issue 7
>
>
>
> *Caution:* This is an external email and has a suspicious subject or
> content. Please take care when clicking links or opening attachments. When
> in doubt, contact your IT Department
>
> Send squid-users mailing list submissions to
> squid-users at lists.squid-cache.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> https://lists.squid-cache.org/listinfo/squid-users
> or, via email, send a message with subject or body 'help' to
> squid-users-request at lists.squid-cache.org
>
> You can reach the person managing the list at
> squid-users-owner at lists.squid-cache.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
>
>
> Today's Topics:
>
> 1. Re: Squid cache questions (Amos Jeffries)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Fri, 5 Apr 2024 14:17:16 +1300
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid cache questions
> Message-ID: <bef43696-be7f-463b-b82e-d4346abba2a5 at treenet.co.nz>
> Content-Type: text/plain; charset=UTF-8; format=flowed
>
> On 4/04/24 17:48, Jonathan Lee wrote:
> > Is there any particular order to squid configuration??
> >
>
> Yes. <https://wiki.squid-cache.org/SquidFaq/OrderIsImportant>
>
>
> > Does this look correct?
> >
>
> Best way to find out is to run "squid -k parse", which should be done
> after upgrades as well to identify and fix changes between versions as
> we improve the output.
>
>
> > I actually get allot of hits and it functions amazing, so I wanted to
> > share this in case I could improve something. Is there any issues with
> > security?
>
> Yes, the obvious one is "DONT_VERIFY_PEER" disabling TLS security
> entirely on outbound connections. That particular option will prevent
> you even being told about suspicious activity regarding TLS.
>
> Also there are a few weird things in your TLS cipher settings, such as
> this sequence " EECDH+aRSA+RC4:...:!RC4 "
> Which as I understand, enables the EECDH with RC4 hash, but also
> forbids all uses of RC4.
>
>
> > I am concerned that an invasive container could become
> > installed in the cache and data marshal the network card.
> >
>
> You have a limit of 4 MB for objects allowed to pass through this proxy,
> exception being objects from domains listed in the "windowsupdate" ACL
> (not all Windows related) which are allowed up to 512 MB.
>
> For the general case, any type of file which can store an image of some
> system is a risk for that type of vulnerability can be cached.
>
> The place to fix that vulnerability properly is not the cache or Squid.
> It is the OS permissions allowing non-Squid software access to the cache
> files and/or directory.
>
>
>
> > Here is my config
> >
> > # This file is automatically generated by pfSense
> > # Do not edit manually !
>
> Since this file is generated by pfsense there is little that can be done
> about ordering issues and very hard to tell which of the problems below
> are due to pfsense and which due toy your settings.
>
> FWIW, there are no major issues, just some lines not being necessary due
> to setting things to their default values, or just some blocks already
> denyign things that are blocked previously.
>
>
> >
> > http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem
> cafile=/usr/local/share/certs/ca-root-nss.crt
> capath=/usr/local/share/certs/
> cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> tls-dh=prime256v1:/etc/dh-parameters.2048
> options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> >
> > http_port 127.0.0.1:3128 intercept ssl-bump
> generate-host-certificates=on dynamic_cert_mem_cache_size=20MB
> cert=/usr/local/etc/squid/serverkey.pem
> cafile=/usr/local/share/certs/ca-root-nss.crt
> capath=/usr/local/share/certs/
> cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> tls-dh=prime256v1:/etc/dh-parameters.2048
> options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> >
> > https_port 127.0.0.1:3129 intercept ssl-bump
> generate-host-certificates=on dynamic_cert_mem_cache_size=20MB
> cert=/usr/local/etc/squid/serverkey.pem
> cafile=/usr/local/share/certs/ca-root-nss.crt
> capath=/usr/local/share/certs/
> cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> tls-dh=prime256v1:/etc/dh-parameters.2048
> options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> >
> > icp_port 0
> > digest_generation off
> > dns_v4_first on
> > pid_filename /var/run/squid/squid.pid
> > cache_effective_user squid
> > cache_effective_group proxy
> > error_default_language en
> > icon_directory /usr/local/etc/squid/icons
> > visible_hostname ****
> > cache_mgr ****
> > access_log /var/squid/logs/access.log
> > cache_log /var/squid/logs/cache.log
> > cache_store_log none
> > netdb_filename /var/squid/logs/netdb.state
> > pinger_enable on
> > pinger_program /usr/local/libexec/squid/pinger
> > sslcrtd_program /usr/local/libexec/squid/security_file_certgen -s
> /var/squid/lib/ssl_db -M 4MB -b 2048
> > tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
> > tls_outgoing_options capath=/usr/local/share/certs/
> > tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> > tls_outgoing_options
> cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> > tls_outgoing_options flags=DONT_VERIFY_PEER
> > sslcrtd_children 10
> >
> > logfile_rotate 0
> > debug_options rotate=0
> > shutdown_lifetime 3 seconds
> > # Allow local network(s) on interface(s)
> > acl localnet src 192.168.1.0/27
> > forwarded_for transparent
> > httpd_suppress_version_string on
> > uri_whitespace strip
> >
> > acl getmethod method GET
> >
> > acl windowsupdate dstdomain windowsupdate.microsoft.com
> > acl windowsupdate dstdomain .update.microsoft.com
> > acl windowsupdate dstdomain download.windowsupdate.com
> > acl windowsupdate dstdomain redir.metaservices.microsoft.com
> > acl windowsupdate dstdomain images.metaservices.microsoft.com
> > acl windowsupdate dstdomain c.microsoft.com
> > acl windowsupdate dstdomain www.download.windowsupdate.com
> > acl windowsupdate dstdomain wustat.windows.com
> > acl windowsupdate dstdomain crl.microsoft.com
> > acl windowsupdate dstdomain sls.microsoft.com
> > acl windowsupdate dstdomain productactivation.one.microsoft.com
> > acl windowsupdate dstdomain ntservicepack.microsoft.com
> > acl windowsupdate dstdomain dc1-st.ksn.kaspersky-labs.com
> > acl windowsupdate dstdomain dc1-file.ksn.kaspersky-labs.com
> > acl windowsupdate dstdomain dc1.ksn.kaspersky-labs.com
> >
> > acl rewritedoms dstdomain .facebook.com .akamaihd.net .fbcdn.net .
> google.com .static.com .apple.com .oracle.com .sun.com .java.com .
> adobe.com .steamstatic.com .steampowered.com .steamcontent.com .google.com
> >
> > store_id_program /usr/local/libexec/squid/storeid_file_rewrite
> /var/squid/storeid/storeid_rewrite.txt
> > store_id_children 10 startup=5 idle=1 concurrency=0
> > always_direct allow !getmethod
> > store_id_access deny connect
> > store_id_access deny !getmethod
> > store_id_access allow rewritedoms
> > reload_into_ims on
> > max_stale 20 years
> > minimum_expiry_time 0
> >
>
>
> I am not sure how many of these refresh_pattern rules below are written
> by you, copy-pasted from elsewhere, or added automatically by pfsense.
> So how you need to fix the problems here is uncertain.
>
> That said, please consider removing all these override-* and ignore-*.
> <http://www.squid-cache.org/Doc/config/refresh_pattern/>
>
>
> >
> > refresh_pattern -i squid.internal 10080 80% 79900 override-lastmod
> override-expire ignore-reload ignore-no-store ignore-must-revalidate
> ignore-private ignore-auth
> >
> > #APPLE STUFF
> > refresh_pattern -i apple.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip|dist)$
> 0 80% 43200 refresh-ims
> >
> > #apple update
> > refresh_pattern -i (download|adcdownload)apple.com/.*.(pkg|dmg) 4320
> 100% 43200
> > refresh_pattern -i appldnld.apple.com 129600 100% 129600
> > refresh_pattern -i phobos.apple.com 129600 100% 129600
> > refresh_pattern -i iosapps.itunes.apple.com 129600 100% 129600
> >
> > # Updates: Windows
> > refresh_pattern -i microsoft.com/..(cab|exe|msi|msu|msf|asf|wma|dat|zip)$
> 4320 80% 43200 refresh-ims
> > refresh_pattern -i windowsupdate.com/..(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$
> 4320 80% 43200 refresh-ims
> > refresh_pattern -i windows.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip)$
> 4320 80% 43200 refresh-ims
> > refresh_pattern -i microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
> 4320 80% 43200
> > refresh_pattern -i windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
> 4320 80% 43200
> > refresh_pattern -i windows.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
> 4320 80% 43200
> > refresh_pattern -i .*windowsupdate.com/.*.(cab|exe) 259200 100% 259200
> > refresh_pattern -i .*update.microsoft.com/.*.(cab|exe|dll|msi|psf)
> 259200 100% 259200
> > refresh_pattern windowsupdate.com/.*.(cab|exe|dll|msi|psf) 10080 100%
> 43200
> > refresh_pattern download.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080
> 100% 43200
> > refresh_pattern www.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100%
> 43200
> > refresh_pattern au.download.windowsupdate.com/.*.(cab|exe|dll|msi|psf)
> 4320 100% 43200
> > refresh_pattern bg.v4.pr.dl.ws.microsoft.com/.*.(cab|exe|dll|msi|psf)
> 4320 100% 43200
> > #windows update NEW UPDATE 0.04
> > refresh_pattern update.microsoft.com/.*.(cab|exe) 43200 100% 129600
> > refresh_pattern
> ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf)
> 4320 100% 43200
> > refresh_pattern update.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080
> 100% 43200
> > refresh_pattern -i update.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
> 525600 100% 525600
> > refresh_pattern -i windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
> 525600 100% 525600
> > refresh_pattern -i download.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
> 525600 100% 525600
> > refresh_pattern -i ws.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
> 525600 100% 525600
> >
> > refresh_pattern
> ([^.]+.)?(cs|content[1-9]|hsar|content-origin|client-download).[steampowered|steamcontent].com/.*.*
> 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store
> override-expire override-lastmod
> > refresh_pattern ([^.]+.)?akamai.steamstatic.com/.*.* 43200 100% 43200
> reload-into-ims ignore-reload ignore-no-store override-expire
> override-lastmod
> >
> > refresh_pattern -i ([^.]+.)?adobe.com/.*.(zip|exe) 43200 100% 43200
> reload-into-ims ignore-reload ignore-no-store override-expire
> override-lastmod
> > refresh_pattern -i ([^.]+.)?java.com/.*.(zip|exe) 43200 100% 43200
> reload-into-ims ignore-reload ignore-no-store override-expire
> override-lastmod
> > refresh_pattern -i ([^.]+.)?sun.com/.*.(zip|exe) 43200 100% 43200
> reload-into-ims ignore-reload ignore-no-store override-expire
> override-lastmod
> > refresh_pattern -i ([^.]+.)?oracle.com/.*.(zip|exe|tar.gz) 43200 100%
> 43200 reload-into-ims ignore-reload ignore-no-store override-expire
> override-lastmod
> >
> > refresh_pattern -i appldnld.apple.com 43200 100% 43200 ignore-reload
> ignore-no-store override-expire override-lastmod
> > refresh_pattern -i ([^.]+.)?apple.com/.*.(ipa) 43200 100% 43200
> ignore-reload ignore-no-store override-expire override-lastmod
> >
> > refresh_pattern -i ([^.]+.)?google.com/.*.(exe|crx) 10080 80% 43200
> override-expire override-lastmod ignore-no-cache ignore-reload
> reload-into-ims ignore-private
> > refresh_pattern -i ([^.]+.)?g.static.com/.*.(exe|crx) 10080 80% 43200
> override-expire override-lastmod ignore-no-cache ignore-reload
> reload-into-ims ignore-private
> >
> > #FACEBOOK
> > refresh_pattern ^http?://*facebook.com/* 10080 80% 43200
> override-expire override-lastmod ignore-no-cache ignore-reload
> reload-into-ims ignore-private
> >
> > #FACEBOOK IMAGES
> > refresh_pattern -i pixel.facebook.com..(jpg|png|gif|ico|css|js) 10080
> 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload
> reload-into-ims ignore-private
> > refresh_pattern -i .akamaihd.net..(jpg|png|gif|ico|css|js) 10080 80%
> 43200 override-expire override-lastmod ignore-no-cache ignore-reload
> reload-into-ims ignore-private
> > refresh_pattern -i (facebook.com).(jpg|png|gif) 10080 80% 43200
> store-stale override-expire override-lastmod ignore-no-cache ignore-reload
> reload-into-ims ignore-private
> > refresh_pattern static.(xx|ak).fbcdn.net.(jpg|gif|png) 10080 80% 43200
> override-expire override-lastmod ignore-no-cache ignore-reload
> reload-into-ims ignore-private
> > refresh_pattern ^https?://profile.ak.fbcdn.net*.(jpg|gif|png) 10080 80%
> 43200 override-expire override-lastmod ignore-no-cache ignore-reload
> reload-into-ims ignore-private
> >
> > #FACEBOOK VIDEO
> > refresh_pattern -i .video.ak.fbcdn.net.*.(mp4|flv|mp3|amf) 10080 80%
> 43200 override-expire override-lastmod ignore-no-cache ignore-reload
> reload-into-ims ignore-private
> > refresh_pattern (audio|video)/(webm|mp4) 10080 80% 43200 override-expire
> override-lastmod ignore-no-cache ignore-reload reload-into-ims
> ignore-private
> >
> >
> > range_offset_limit 512 MB windowsupdate
> > maximum_object_size 512 MB windowsupdate
> > range_offset_limit 0
> > quick_abort_min -1 KB
> >
> > cache_mem 64 MB
> > maximum_object_size_in_memory 256 KB
> > memory_replacement_policy heap LFUDA
> > cache_replacement_policy heap LFUDA
> > minimum_object_size 0 KB
> > maximum_object_size 4 MB
> > cache_dir diskd /var/squid/cache 64000 256 256
> > offline_mode off
> > cache_swap_low 90
> > cache_swap_high 95
> > acl donotcache dstdomain '/var/squid/acl/donotcache.acl'
> > cache deny donotcache
> > cache allow all
> > # Add any of your own refresh_pattern entries above these.
> > refresh_pattern ^ftp: 1440 20% 10080
> > refresh_pattern ^gopher: 1440 0% 1440
> > refresh_pattern -i (/cgi-bin/|?) 0 0% 0
> > refresh_pattern . 0 20% 4320
> >
> >
> > #Remote proxies
> >
> >
> > # Setup some default acls
> > # ACLs all, manager, localhost, and to_localhost are predefined.
> > acl allsrc src all
> > acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080
> 3128 3129 1025-65535
> > acl sslports port 443 563 8080 5223 2197
> >
> > acl purge method PURGE
> > acl connect method CONNECT
> >
> > # Define protocols used for redirects
> > acl HTTP proto HTTP
> > acl HTTPS proto HTTPS
> >
> > # SslBump Peek and Splice
> > # http://wiki.squid-cache.org/Features/SslPeekAndSplice
> > # http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
> > # Match against the current step during ssl_bump evaluation [fast]
> > # Never matches and should not be used outside the ssl_bump context.
> > #
> > # At each SslBump step, Squid evaluates ssl_bump directives to find
> > # the next bumping action (e.g., peek or splice). Valid SslBump step
> > # values and the corresponding ssl_bump evaluation moments are:
> > # SslBump1: After getting TCP-level and HTTP CONNECT info.
> > # SslBump2: After getting TLS Client Hello info.
> > # SslBump3: After getting TLS Server Hello info.
> > # These ACLs exist even when 'SSL/MITM Mode' is set to 'Custom' so that
> > # they can be used there for custom configuration.
> > acl step1 at_step SslBump1
> > acl step2 at_step SslBump2
> > acl step3 at_step SslBump3
> > acl banned_hosts src '/var/squid/acl/banned_hosts.acl'
> > acl whitelist dstdom_regex -i '/var/squid/acl/whitelist.acl'
> > acl blacklist dstdom_regex -i '/var/squid/acl/blacklist.acl'
> > http_access allow manager localhost
> >
> > # Allow external cache managers
> > acl ext_manager src 192.168.1.1
> > acl ext_manager src 127.0.0.1
> > http_access allow manager ext_manager
> >
> > http_access deny manager
> > http_access allow purge localhost
> > http_access deny purge
> > http_access deny !safeports
> > http_access deny CONNECT !sslports
> >
> > # Always allow localhost connections
> > http_access allow localhost
> >
> > quick_abort_min 0 KB
> > quick_abort_max 0 KB
> > quick_abort_pct 95
> > request_body_max_size 0 KB
> > delay_pools 1
> > delay_class 1 2
> > delay_parameters 1 -1/-1 -1/-1
> > delay_initial_bucket_level 100
> > delay_access 1 allow allsrc
> >
> > # Reverse Proxy settings
> >
> > deny_info TCP_RESET allsrc
> >
> > # Package Integration
> > url_rewrite_program /usr/local/bin/squidGuard -c
> /usr/local/etc/squidGuard/squidGuard.conf
> > url_rewrite_bypass off
> > url_rewrite_children 32 startup=8 idle=4 concurrency=0
> >
>
> Squidguard is very outdated. You should upgrade to its successor
> ufdbguard if possible.
>
>
>
> > # Custom options before auth
> > #host_verify_strict on
> >
> > # These hosts are banned
> > http_access deny banned_hosts
> > # Always allow access to whitelist domains
> > http_access allow whitelist
> > # Block access to blacklist domains
> > http_access deny blacklist
> > # List of domains allowed to logging in to Google services
> > request_header_access X-GoogApps-Allowed-Domains deny all
> > request_header_add X-GoogApps-Allowed-Domains consumer_accounts
> > # Set YouTube safesearch restriction
> > acl youtubedst dstdomain -n www.youtube.com m.youtube.com
> youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com
> > request_header_access YouTube-Restrict deny all
> > request_header_add YouTube-Restrict none youtubedst
> > acl sglog url_regex -i sgr=ACCESSDENIED
> > http_access deny sglog
> > # Custom SSL/MITM options before auth
> > acl manager proto cache_object
> > acl localhost src 192.168.1.1/32
> > #cachemgr_passwd disable offline_toggle reconfigure shutdown
> > #cachemgr_passwd secret all
> > acl https_login url_regex -i ^https.*(login|Login).*
> > acl no_miss url_regex -i ^.*gateway.facebook.com/ws/realtime?
> > acl no_miss url_regex -i ^.*web-chat-e2ee.facebook.com/ws/chat
> > acl CONNECT method CONNECT
> > acl wuCONNECT dstdomain www.update.microsoft.com
> > acl wuCONNECT dstdomain sls.microsoft.com
> > http_access allow CONNECT wuCONNECT localnet
> > http_access allow CONNECT wuCONNECT localhost
> > http_access allow windowsupdate localnet
> > http_access allow windowsupdate localhost
> > http_access deny manager
> >
> > acl BrokenButTrustedServers dstdomain '/usr/local/pkg/dstdom.broken'
> > acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
> > sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
> > sslproxy_cert_error deny all
> >
> > acl splice_only src 192.168.1.8 #Tasha iPhone
> > acl splice_only src 192.168.1.10 #Jon iPhone
> > acl splice_only src 192.168.1.11 #Amazon Fire
> > acl splice_only src 192.168.1.15 #Tasha HP
> > acl splice_only src 192.168.1.16 #iPad
> >
> > acl NoSSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.nobump'
> >
> > acl markBumped annotate_client bumped=true
> > acl bump_only src 192.168.1.3 #webtv
> > acl bump_only src 192.168.1.4 #toshiba
> > acl bump_only src 192.168.1.5 #imac
> > acl bump_only src 192.168.1.9 #macbook
> > acl bump_only src 192.168.1.13 #dell
> >
>
> You have a previous "cache allow all". This below rule does nothing.
>
> > cache deny https_login
> >
> > ssl_bump peek step1
> > miss_access deny no_miss
> > ssl_bump splice https_login
> > ssl_bump splice splice_only
> > ssl_bump splice NoSSLIntercept
> > ssl_bump bump bump_only markBumped
> > ssl_bump stare all
> >
> > acl markedBumped note bumped true
> > url_rewrite_access deny markedBumped
> >
> > http_access deny all
> > read_ahead_gap 32 KB
> > negative_ttl 1 second
> > connect_timeout 30 seconds
> > request_timeout 60 seconds
> > half_closed_clients off
> > shutdown_lifetime 10 seconds
> > negative_dns_ttl 1 seconds
> > ignore_unknown_nameservers on
> > pipeline_prefetch 100
> >
> > #acl SSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.bump'
> > #ssl_bump bump SSLIntercept
> >
>
> You already have an earlier "http_access deny all". The below lines do
> nothing.
>
> > # Setup allowed ACLs
> > # Allow local network(s) on interface(s)
> > http_access allow localnet
> > # Default block all to be sure
> > http_access deny allsrc
> >
>
>
> HTH
> Amos
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
>
> End of squid-users Digest, Vol 116, Issue 7
> *******************************************
>
> <http://www.pbandt.bank>* CONFIDENTIALITY NOTICE: The information
> contained in and attached to this email is intended only for the
> confidential use of the person or entity to which the email is addressed.
> This email and any attachments may contain privileged and confidential
> information. If you are not the intended recipient, you are notified that
> you received this email in error and that any reading, retention, use or
> distribution of this email and attachments is strictly prohibited. If you
> received this email in error, you are requested to immediately notify us by
> calling 888-728-3550 or by return email and immediately and permanently
> delete the email and any attachments. Thank you. *
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>


-- 
    Francesco
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240410/c1c898fb/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0.jpg
Type: image/jpeg
Size: 6398 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240410/c1c898fb/attachment.jpg>

From jonathanlee571 at gmail.com  Wed Apr 10 20:22:15 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 10 Apr 2024 13:22:15 -0700
Subject: [squid-users]
 SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
In-Reply-To: <f10251e7-6c09-4657-80bc-e1d4a3267c91@measurement-factory.com>
References: <5A46B30E-D553-4681-9A18-50EEED90847C@gmail.com>
 <f10251e7-6c09-4657-80bc-e1d4a3267c91@measurement-factory.com>
Message-ID: <07A70FC2-D089-4090-9A83-656BADE0064A@gmail.com>

Could it be related to this ??

"WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'. error:1E08010C:DECODER routines::unsupported?


> On Apr 10, 2024, at 08:38, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> On 2024-04-10 10:50, Jonathan Lee wrote:
> 
>> I am getting the following error in 6.6 after a upgrade from 5.8 does anyone know what this is caused by?
>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
> 
>    $ openssl errstr A000417
>    error:0A000417:SSL routines::sslv3 alert illegal parameter
> 
> I think I have seen that error code before, but I do not recall the exact circumstances. Sorry! The error happens when Squid tries to accept (or peek at) a TLS connection from the client. Might be prohibited TLS version/feature, TLS greasing, or non-TLS traffic? Try examining client TLS Hello packet(s) in Wireshark.
> 
> Alex.
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240410/be554d57/attachment.htm>

From rousskov at measurement-factory.com  Wed Apr 10 21:13:22 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 10 Apr 2024 17:13:22 -0400
Subject: [squid-users]
 SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
In-Reply-To: <07A70FC2-D089-4090-9A83-656BADE0064A@gmail.com>
References: <5A46B30E-D553-4681-9A18-50EEED90847C@gmail.com>
 <f10251e7-6c09-4657-80bc-e1d4a3267c91@measurement-factory.com>
 <07A70FC2-D089-4090-9A83-656BADE0064A@gmail.com>
Message-ID: <cc452541-7e19-400a-99ba-ffabfe58c21c@measurement-factory.com>

On 2024-04-10 16:22, Jonathan Lee wrote:
> Could it be related to this ??
> 
> "WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'. 
> error:1E08010C:DECODER routines::unsupported?

I do not know the answer to your question. I speculate that it could be 
related: Depending on various factors, without those DH parameters, 
Squid may not be able to communicate with clients. See WARNING in tls-dh 
description in squid.conf.documented.

I know that others are reporting similar WARNINGs during v6 upgrades and 
dislike the letters "EC" those messages use. I am not going to debate 
the best choice of letters for this message, but I can tell you that, in 
the cases I investigated, the message was caused by a mismatch between 
squid.conf tls-dh=... option value and DH parameter file contents:

* To Squid, tls-dh=curve:filename format implies that the keytype is 
"EC". These two letters are then fed to an OpenSSL function that 
configures related TLS state. OpenSSL then fails if tls-dh filename 
contains DH parameters produced with "openssl dhparam" command. I have 
seen these failures in tests.

* To Squid, tls-dh=filename format (i.e. format without the curve name 
prefix) implies that the keytype is "DC". These two letters are then fed 
to an OpenSSL function that configured related TLS state. OpenSSL then 
probably fails if tls-dh filename contains DH parameters produced with 
"openssl ecparam" command. I have not tested this use case.

* The failing checks and their messages are specific to Squids built 
with OpenSSL v3. It is possible that Squids built with OpenSSL v1 just 
silently fail (at runtime), but I have not checked that theory.


FWIW, this poorly categorized message indicates a configuration _error_. 
AFAICT, Squid code should be adjusted to _quit_ (i.e. reject bad 
configuration) after discovering this error instead of continuing as if 
nothing bad happened.

I recommend addressing the underlying cause, even if this message is 
unrelated to SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417.


HTH,

Alex.


>> On Apr 10, 2024, at 08:38, Alex Rousskov 
>> <rousskov at measurement-factory.com> wrote:
>>
>> On 2024-04-10 10:50, Jonathan Lee wrote:
>>
>>> I am getting the following error in 6.6 after a upgrade from 5.8 does 
>>> anyone know what this is caused by?
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
>>
>> ???$ openssl errstr A000417
>> ???error:0A000417:SSL routines::sslv3 alert illegal parameter
>>
>> I think I have seen that error code before, but I do not recall the 
>> exact circumstances. Sorry! The error happens when Squid tries to 
>> accept (or peek at) a TLS connection from the client. Might be 
>> prohibited TLS version/feature, TLS greasing, or non-TLS traffic? Try 
>> examining client TLS Hello packet(s) in Wireshark.
>>
>> Alex.
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 



From jonathanlee571 at gmail.com  Wed Apr 10 21:26:17 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 10 Apr 2024 14:26:17 -0700
Subject: [squid-users]
 SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
In-Reply-To: <cc452541-7e19-400a-99ba-ffabfe58c21c@measurement-factory.com>
References: <5A46B30E-D553-4681-9A18-50EEED90847C@gmail.com>
 <f10251e7-6c09-4657-80bc-e1d4a3267c91@measurement-factory.com>
 <07A70FC2-D089-4090-9A83-656BADE0064A@gmail.com>
 <cc452541-7e19-400a-99ba-ffabfe58c21c@measurement-factory.com>
Message-ID: <DBCEC9C5-E27E-4807-B6CF-39CF5B32B56F@gmail.com>

I think they also did fail silently in the older version because the error logs were not present for previous packages that I used. At one point all error logs were removed in a package and I had to create a linker file to see the basic errors. Squid 6.6 comes with the error logs I could not see, previously 5.8 and prior it would create many blank logs that had no information.  

In 5.8 the squid -k parse did not show the 
WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'. error:1E08010C:DECODER routines::unsupported
However it did show this in 5.8, 5.9,  and now in 6.6 if I delete the options it no longer lists the error.

2024/04/10 14:21:48| ERROR: Unsupported TLS option SINGLE_DH_USE
2024/04/10 14:21:48| ERROR: Unsupported TLS option SINGLE_ECDH_USE
It works I can block URLS that is what I am confused about it shows hit 304 and refreshes in 5.9 however 6.6 it kick abandons my connections 

5.8 is my everything bagel version it just works however like you said is the errors not showing as it is slow at times 


> On Apr 10, 2024, at 14:13, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> On 2024-04-10 16:22, Jonathan Lee wrote:
>> Could it be related to this ??
>> "WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'. error:1E08010C:DECODER routines::unsupported?
> 
> I do not know the answer to your question. I speculate that it could be related: Depending on various factors, without those DH parameters, Squid may not be able to communicate with clients. See WARNING in tls-dh description in squid.conf.documented.
> 
> I know that others are reporting similar WARNINGs during v6 upgrades and dislike the letters "EC" those messages use. I am not going to debate the best choice of letters for this message, but I can tell you that, in the cases I investigated, the message was caused by a mismatch between squid.conf tls-dh=... option value and DH parameter file contents:
> 
> * To Squid, tls-dh=curve:filename format implies that the keytype is "EC". These two letters are then fed to an OpenSSL function that configures related TLS state. OpenSSL then fails if tls-dh filename contains DH parameters produced with "openssl dhparam" command. I have seen these failures in tests.
> 
> * To Squid, tls-dh=filename format (i.e. format without the curve name prefix) implies that the keytype is "DC". These two letters are then fed to an OpenSSL function that configured related TLS state. OpenSSL then probably fails if tls-dh filename contains DH parameters produced with "openssl ecparam" command. I have not tested this use case.
> 
> * The failing checks and their messages are specific to Squids built with OpenSSL v3. It is possible that Squids built with OpenSSL v1 just silently fail (at runtime), but I have not checked that theory.
> 
> 
> FWIW, this poorly categorized message indicates a configuration _error_. AFAICT, Squid code should be adjusted to _quit_ (i.e. reject bad configuration) after discovering this error instead of continuing as if nothing bad happened.
> 
> I recommend addressing the underlying cause, even if this message is unrelated to SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417.
> 
> 
> HTH,
> 
> Alex.
> 
> 
>>> On Apr 10, 2024, at 08:38, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>> 
>>> On 2024-04-10 10:50, Jonathan Lee wrote:
>>> 
>>>> I am getting the following error in 6.6 after a upgrade from 5.8 does anyone know what this is caused by?
>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
>>> 
>>>    $ openssl errstr A000417
>>>    error:0A000417:SSL routines::sslv3 alert illegal parameter
>>> 
>>> I think I have seen that error code before, but I do not recall the exact circumstances. Sorry! The error happens when Squid tries to accept (or peek at) a TLS connection from the client. Might be prohibited TLS version/feature, TLS greasing, or non-TLS traffic? Try examining client TLS Hello packet(s) in Wireshark.
>>> 
>>> Alex.
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240410/e664f688/attachment.htm>

From jonathanlee571 at gmail.com  Wed Apr 10 21:27:23 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 10 Apr 2024 14:27:23 -0700
Subject: [squid-users]
 SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
In-Reply-To: <cc452541-7e19-400a-99ba-ffabfe58c21c@measurement-factory.com>
References: <5A46B30E-D553-4681-9A18-50EEED90847C@gmail.com>
 <f10251e7-6c09-4657-80bc-e1d4a3267c91@measurement-factory.com>
 <07A70FC2-D089-4090-9A83-656BADE0064A@gmail.com>
 <cc452541-7e19-400a-99ba-ffabfe58c21c@measurement-factory.com>
Message-ID: <75DA748B-04E7-4CB6-8F33-F23A8D527C3C@gmail.com>

Copy of config I am using 

# This file is automatically generated by pfSense
# Do not edit manually !

http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

icp_port 0
digest_generation off
dns_v4_first on
pid_filename /var/run/squid/squid.pid
cache_effective_user squid
cache_effective_group proxy
error_default_language en
icon_directory /usr/local/etc/squid/icons
visible_hostname Lee_Family.home.arpa
cache_mgr jonathanlee571 at gmail.com
access_log /var/squid/logs/access.log
cache_log /var/squid/logs/cache.log
cache_store_log none
netdb_filename /var/squid/logs/netdb.state
pinger_enable on
pinger_program /usr/local/libexec/squid/pinger
sslcrtd_program /usr/local/libexec/squid/security_file_certgen -s /var/squid/lib/ssl_db -M 4MB -b 2048
tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
tls_outgoing_options capath=/usr/local/share/certs/
tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
sslcrtd_children 10

logfile_rotate 0
debug_options rotate=0
shutdown_lifetime 3 seconds
# Allow local network(s) on interface(s)
acl localnet src  192.168.1.0/27
forwarded_for transparent
httpd_suppress_version_string on
uri_whitespace strip

acl getmethod method GET

tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

acl windowsupdate dstdomain windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain download.windowsupdate.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain www.download.windowsupdate.com
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com
acl windowsupdate dstdomain dc1-st.ksn.kaspersky-labs.com
acl windowsupdate dstdomain dc1-file.ksn.kaspersky-labs.com
acl windowsupdate dstdomain dc1.ksn.kaspersky-labs.com

acl rewritedoms dstdomain .facebook.com .akamaihd.net .fbcdn.net .google.com .static.com .apple.com .oracle.com .sun.com .java.com .adobe.com .steamstatic.com .steampowered.com .steamcontent.com .google.com

store_id_program /usr/local/libexec/squid/storeid_file_rewrite /var/squid/storeid/storeid_rewrite.txt
store_id_children 10 startup=5 idle=1 concurrency=0
always_direct allow !getmethod
store_id_access deny connect
store_id_access deny !getmethod
store_id_access allow rewritedoms
reload_into_ims on
max_stale 20 years
minimum_expiry_time 0


refresh_pattern -i squid.internal 10080 80% 79900 override-lastmod override-expire ignore-reload ignore-no-store ignore-private

#APPLE STUFF
refresh_pattern -i apple.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip|dist)$ 0 80% 43200  refresh-ims

#apple update
refresh_pattern -i (download|adcdownload).apple.com/.*.(pkg|dmg) 4320 100% 43200 
refresh_pattern -i appldnld.apple.com 129600 100% 129600     
refresh_pattern -i phobos.apple.com 129600 100% 129600     
refresh_pattern -i iosapps.itunes.apple.com 129600 100% 129600     

# Updates: Windows
refresh_pattern -i microsoft.com/..(cab|exe|msi|msu|msf|asf|wma|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i windowsupdate.com/..(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i windows.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i windows.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i .*windowsupdate.com/.*.(cab|exe) 259200 100% 259200   
refresh_pattern -i .*update.microsoft.com/.*.(cab|exe|dll|msi|psf) 259200 100% 259200   
refresh_pattern windowsupdate.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern download.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern www.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern au.download.windowsupdate.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200 
refresh_pattern bg.v4.pr.dl.ws.microsoft.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
#windows update NEW UPDATE 0.04
refresh_pattern update.microsoft.com/.*.(cab|exe) 43200 100% 129600    
refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200  
refresh_pattern update.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern -i .update.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .download.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .ws.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       

refresh_pattern ([^.]+.)?(cs|content[1-9]|hsar|content-origin|client-download).[steampowered|steamcontent].com/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern ([^.]+.)?.akamai.steamstatic.com/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod

refresh_pattern -i ([^.]+.)?.adobe.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern -i ([^.]+.)?.java.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern -i ([^.]+.)?.sun.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern -i ([^.]+.)?.oracle.com/.*.(zip|exe|tar.gz) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod

refresh_pattern -i appldnld.apple.com 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern -i ([^.]+.)?apple.com/.*.(ipa) 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
 
refresh_pattern -i ([^.]+.)?.google.com/.*.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
refresh_pattern -i ([^.]+.)?g.static.com/.*.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private

#FACEBOOK
refresh_pattern ^http?://*.facebook.com/*  10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private

#FACEBOOK IMAGES  
refresh_pattern -i pixel.facebook.com..(jpg|png|gif|ico|css|js)  10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
refresh_pattern -i .akamaihd.net..(jpg|png|gif|ico|css|js) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private   
refresh_pattern -i (facebook.com).(jpg|png|gif) 10080 80% 43200 store-stale override-expire override-lastmod ignore-reload reload-into-ims ignore-private 
refresh_pattern static.(xx|ak).fbcdn.net.(jpg|gif|png) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
refresh_pattern (scontent-lax[0-9]-[0-9].xx|.ak).fbcdn.net.*(jpg|gif|png) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private

refresh_pattern ^https?://profile.ak.fbcdn.net*.(jpg|gif|png) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private

#FACEBOOK VIDEO
refresh_pattern -i .(video-lax[0-9]-[0-9].xx|video.ak).fbcdn.net.*.(mp4|flv|mp3|amf) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
refresh_pattern (audio|video)/(webm|mp4) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
acl https_login url_regex -i ^https.*(login|Login).*
cache deny https_login

range_offset_limit 512 MB windowsupdate
range_offset_limit 4 MB
range_offset_limit 0
quick_abort_min -1 KB

cache_mem 64 MB
maximum_object_size_in_memory 256 KB
memory_replacement_policy heap LFUDA
cache_replacement_policy heap LFUDA
minimum_object_size 0 KB
maximum_object_size 512 MB
cache_dir diskd /var/squid/cache 64000 256 256
offline_mode off
cache_swap_low 90
cache_swap_high 95
acl donotcache dstdomain '/var/squid/acl/donotcache.acl'
cache deny donotcache
cache allow all
# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:    1440  20%  10080
refresh_pattern ^gopher:  1440  0%  1440
refresh_pattern -i (/cgi-bin/|?) 0  0%  0
refresh_pattern .    0  20%  4320


#Remote proxies


# Setup some default acls
# ACLs all, manager, localhost, and to_localhost are predefined.
acl allsrc src all
acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080 3128 3129 1025-65535 
acl sslports port 443 563 8080 5223 2197

acl purge method PURGE
acl connect method CONNECT

# Define protocols used for redirects
acl HTTP proto HTTP
acl HTTPS proto HTTPS

# SslBump Peek and Splice
# http://wiki.squid-cache.org/Features/SslPeekAndSplice
# http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
# Match against the current step during ssl_bump evaluation [fast]
# Never matches and should not be used outside the ssl_bump context.
#
# At each SslBump step, Squid evaluates ssl_bump directives to find
# the next bumping action (e.g., peek or splice). Valid SslBump step
# values and the corresponding ssl_bump evaluation moments are:
#   SslBump1: After getting TCP-level and HTTP CONNECT info.
#   SslBump2: After getting TLS Client Hello info.
#   SslBump3: After getting TLS Server Hello info.
# These ACLs exist even when 'SSL/MITM Mode' is set to 'Custom' so that
# they can be used there for custom configuration.
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
acl banned_hosts src '/var/squid/acl/banned_hosts.acl'
acl whitelist dstdom_regex -i '/var/squid/acl/whitelist.acl'
acl blacklist dstdom_regex -i '/var/squid/acl/blacklist.acl'
http_access allow manager localhost

# Allow external cache managers
acl ext_manager src 192.168.1.1
acl ext_manager src 127.0.0.1
http_access allow manager ext_manager

http_access deny manager
http_access allow purge localhost
http_access deny purge
http_access deny !safeports
http_access deny CONNECT !sslports

# Always allow localhost connections
http_access allow localhost

quick_abort_min 0 KB
quick_abort_max 0 KB
quick_abort_pct 95
request_body_max_size 0 KB
delay_pools 1
delay_class 1 2
delay_parameters 1 -1/-1 -1/-1
delay_initial_bucket_level 100
delay_access 1 allow allsrc

# Reverse Proxy settings

deny_info TCP_RESET allsrc

# Package Integration
url_rewrite_program /usr/local/bin/squidGuard -c /usr/local/etc/squidGuard/squidGuard.conf
url_rewrite_bypass off
url_rewrite_children 32 startup=8 idle=4 concurrency=0

# Custom options before auth
#host_verify_strict on

# These hosts are banned
http_access deny banned_hosts
# Always allow access to whitelist domains
http_access allow whitelist
# Block access to blacklist domains
http_access deny blacklist
# List of domains allowed to logging in to Google services
request_header_access X-GoogApps-Allowed-Domains deny all
request_header_add X-GoogApps-Allowed-Domains consumer_accounts
# Set YouTube safesearch restriction
acl youtubedst dstdomain -n www.youtube.com m.youtube.com youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com
request_header_access YouTube-Restrict deny all
request_header_add YouTube-Restrict none youtubedst
acl sglog url_regex -i sgr=ACCESSDENIED
http_access deny sglog
# Custom SSL/MITM options before auth
acl localhost src 192.168.1.1/32
#cachemgr_passwd disable offline_toggle reconfigure shutdown
#cachemgr_passwd REDACTED123! all
acl no_miss url_regex -i gateway.facebook.com/ws/realtime?
acl no_miss url_regex -i web-chat-e2ee.facebook.com/ws/chat	
acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com
http_access allow CONNECT wuCONNECT localnet
http_access allow CONNECT wuCONNECT localhost
http_access allow windowsupdate localnet
http_access allow windowsupdate localhost
http_access deny manager

acl BrokenButTrustedServers dstdomain '/usr/local/pkg/dstdom.broken'
acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
sslproxy_cert_error deny all

acl splice_only src 192.168.1.8 #Tasha iPhone
acl splice_only src 192.168.1.10 #Jon iPhone
acl splice_only src 192.168.1.11 #Amazon Fire
acl splice_only src 192.168.1.15 #Tasha HP
acl splice_only src 192.168.1.16 #iPad

acl NoSSLIntercept ssl::server_name_regex -i '/usr/local/pkg/reg.url.nobump'
acl NoBumpDNS dstdomain '/usr/local/pkg/dns.nobump'

acl markBumped annotate_client bumped=true
acl bump_only src 192.168.1.3 #webtv
acl bump_only src 192.168.1.4 #toshiba
acl bump_only src 192.168.1.5 #imac
acl bump_only src 192.168.1.9 #macbook
acl bump_only src 192.168.1.13 #dell

ssl_bump peek step1
miss_access deny no_miss 
ssl_bump splice https_login
ssl_bump splice splice_only
ssl_bump splice NoBumpDNS
ssl_bump splice NoSSLIntercept
ssl_bump bump bump_only markBumped
ssl_bump stare all

acl markedBumped note bumped true
url_rewrite_access deny markedBumped

read_ahead_gap 64 KB
negative_ttl 1 second
connect_timeout 30 seconds
request_timeout 60 seconds
half_closed_clients off
shutdown_lifetime 10 seconds
negative_dns_ttl 1 seconds
ignore_unknown_nameservers on
pipeline_prefetch 100

#acl SSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.bump'
#ssl_bump bump SSLIntercept

# Setup allowed ACLs
# Allow local network(s) on interface(s)
http_access allow localnet
# Default block all to be sure
http_access deny allsrc

> On Apr 10, 2024, at 14:13, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> On 2024-04-10 16:22, Jonathan Lee wrote:
>> Could it be related to this ??
>> "WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'. error:1E08010C:DECODER routines::unsupported?
> 
> I do not know the answer to your question. I speculate that it could be related: Depending on various factors, without those DH parameters, Squid may not be able to communicate with clients. See WARNING in tls-dh description in squid.conf.documented.
> 
> I know that others are reporting similar WARNINGs during v6 upgrades and dislike the letters "EC" those messages use. I am not going to debate the best choice of letters for this message, but I can tell you that, in the cases I investigated, the message was caused by a mismatch between squid.conf tls-dh=... option value and DH parameter file contents:
> 
> * To Squid, tls-dh=curve:filename format implies that the keytype is "EC". These two letters are then fed to an OpenSSL function that configures related TLS state. OpenSSL then fails if tls-dh filename contains DH parameters produced with "openssl dhparam" command. I have seen these failures in tests.
> 
> * To Squid, tls-dh=filename format (i.e. format without the curve name prefix) implies that the keytype is "DC". These two letters are then fed to an OpenSSL function that configured related TLS state. OpenSSL then probably fails if tls-dh filename contains DH parameters produced with "openssl ecparam" command. I have not tested this use case.
> 
> * The failing checks and their messages are specific to Squids built with OpenSSL v3. It is possible that Squids built with OpenSSL v1 just silently fail (at runtime), but I have not checked that theory.
> 
> 
> FWIW, this poorly categorized message indicates a configuration _error_. AFAICT, Squid code should be adjusted to _quit_ (i.e. reject bad configuration) after discovering this error instead of continuing as if nothing bad happened.
> 
> I recommend addressing the underlying cause, even if this message is unrelated to SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417.
> 
> 
> HTH,
> 
> Alex.
> 
> 
>>> On Apr 10, 2024, at 08:38, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>> 
>>> On 2024-04-10 10:50, Jonathan Lee wrote:
>>> 
>>>> I am getting the following error in 6.6 after a upgrade from 5.8 does anyone know what this is caused by?
>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
>>> 
>>>    $ openssl errstr A000417
>>>    error:0A000417:SSL routines::sslv3 alert illegal parameter
>>> 
>>> I think I have seen that error code before, but I do not recall the exact circumstances. Sorry! The error happens when Squid tries to accept (or peek at) a TLS connection from the client. Might be prohibited TLS version/feature, TLS greasing, or non-TLS traffic? Try examining client TLS Hello packet(s) in Wireshark.
>>> 
>>> Alex.
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240410/a395f90d/attachment.htm>

From jonathanlee571 at gmail.com  Wed Apr 10 21:48:22 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 10 Apr 2024 14:48:22 -0700
Subject: [squid-users]
 SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
In-Reply-To: <75DA748B-04E7-4CB6-8F33-F23A8D527C3C@gmail.com>
References: <5A46B30E-D553-4681-9A18-50EEED90847C@gmail.com>
 <f10251e7-6c09-4657-80bc-e1d4a3267c91@measurement-factory.com>
 <07A70FC2-D089-4090-9A83-656BADE0064A@gmail.com>
 <cc452541-7e19-400a-99ba-ffabfe58c21c@measurement-factory.com>
 <75DA748B-04E7-4CB6-8F33-F23A8D527C3C@gmail.com>
Message-ID: <8961D36D-C6B5-4F7A-A93E-0A2D80D68BC7@gmail.com>

It works in 5.8 with no errors however in 6.6 I can see indexing and other information that I have never seen before realted to my cache and this new TLS error that follows your thought process you listed before with OpenSSL

ERROR: failure while accepting a TLS connection on conn367 local=192.168.1.1:3128 remote=192.168.1.5:55067 FD 46 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1


And 

Squid - Cache Logs
Date-Time	Message
10.04.2024 14:46:31	ERROR: failure while accepting a TLS connection on conn2404 local=192.168.1.1:3128 remote=192.168.1.5:55534 FD 20 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
10.04.2024 14:45:20	ERROR: failure while accepting a TLS connection on conn2355 local=192.168.1.1:3128 remote=192.168.1.5:55527 FD 16 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
10.04.2024 14:44:23	ERROR: failure while accepting a TLS connection on conn2011 local=192.168.1.1:3128 remote=192.168.1.5:55496 FD 81 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
10.04.2024 14:43:33	ERROR: failure while accepting a TLS connection on conn1824 local=192.168.1.1:3128 remote=192.168.1.5:55465 FD 33 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
10.04.2024 14:43:17	ERROR: failure while accepting a TLS connection on conn1813 local=192.168.1.1:3128 remote=192.168.1.5:55461 FD 33 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
31.12.1969 16:00:00	
10.04.2024 14:43:03	kick abandoning conn1780 local=192.168.1.1:3128 remote=192.168.1.5:55457 FD 26 flags=1
10.04.2024 14:42:36	storeLateRelease: released 110 objects

I would love to learn more I am a Computer science student with a AA in cyber security I have worked in the IT field for the past 15 years, I have some open pull requests in for Squid here

This proxy technology fascinates me so much. It is amazing code. 

https://github.com/pfsense/FreeBSD-ports/pull/1365
And 

https://github.com/pfsense/FreeBSD-ports/pull/1366

Fix for non support

2024/04/05 07:58:24| ERROR: Unsupported TLS option SINGLE_DH_USE
2024/04/05 07:58:24| ERROR: Unsupported TLS option SINGLE_ECDH_USE



Again I do not think many development team members review any of the GitHub pulls for Squid or I am working on something else

if anyone wants to let me know what part of the cipher should be removed please let me know so I can fix the RC4 issue.

https://github.com/pfsense/FreeBSD-ports/pull/1365

Working on this also Per Squid support Amos Jeffries

"Also there are a few weird things in your TLS cipher settings, such as this sequence " EECDH+aRSA+RC4:...:!RC4 "
Which as I understand, enables the EECDH with RC4 hash, but also forbids all uses of RC4."

Are we to disable RC4 because of the security issues? Or are we leaving it it has both listed.

if (empty($settings['sslproxy_compatibility_mode']) || ($settings['sslproxy_compatibility_mode'] == 'modern')) {
					// Modern cipher suites
					$sslproxy_cipher = "EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS";
					$sslproxy_options .= ",NO_TLSv1";
				} else {
					$sslproxy_cipher = "EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS";
				}

Anything else you need I think you requested a pcap file I will create one with 2000 entries of facebook or something also 



> On Apr 10, 2024, at 14:27, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Copy of config I am using 
> 
> # This file is automatically generated by pfSense
> # Do not edit manually !
> 
> http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 
> http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 
> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 
> icp_port 0
> digest_generation off
> dns_v4_first on
> pid_filename /var/run/squid/squid.pid
> cache_effective_user squid
> cache_effective_group proxy
> error_default_language en
> icon_directory /usr/local/etc/squid/icons
> visible_hostname Lee_Family.home.arpa
> cache_mgr jonathanlee571 at gmail.com
> access_log /var/squid/logs/access.log
> cache_log /var/squid/logs/cache.log
> cache_store_log none
> netdb_filename /var/squid/logs/netdb.state
> pinger_enable on
> pinger_program /usr/local/libexec/squid/pinger
> sslcrtd_program /usr/local/libexec/squid/security_file_certgen -s /var/squid/lib/ssl_db -M 4MB -b 2048
> tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
> tls_outgoing_options capath=/usr/local/share/certs/
> tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> sslcrtd_children 10
> 
> logfile_rotate 0
> debug_options rotate=0
> shutdown_lifetime 3 seconds
> # Allow local network(s) on interface(s)
> acl localnet src  192.168.1.0/27
> forwarded_for transparent
> httpd_suppress_version_string on
> uri_whitespace strip
> 
> acl getmethod method GET
> 
> tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> 
> acl windowsupdate dstdomain windowsupdate.microsoft.com
> acl windowsupdate dstdomain .update.microsoft.com
> acl windowsupdate dstdomain download.windowsupdate.com
> acl windowsupdate dstdomain redir.metaservices.microsoft.com
> acl windowsupdate dstdomain images.metaservices.microsoft.com
> acl windowsupdate dstdomain c.microsoft.com
> acl windowsupdate dstdomain www.download.windowsupdate.com
> acl windowsupdate dstdomain wustat.windows.com
> acl windowsupdate dstdomain crl.microsoft.com
> acl windowsupdate dstdomain sls.microsoft.com
> acl windowsupdate dstdomain productactivation.one.microsoft.com
> acl windowsupdate dstdomain ntservicepack.microsoft.com
> acl windowsupdate dstdomain dc1-st.ksn.kaspersky-labs.com
> acl windowsupdate dstdomain dc1-file.ksn.kaspersky-labs.com
> acl windowsupdate dstdomain dc1.ksn.kaspersky-labs.com
> 
> acl rewritedoms dstdomain .facebook.com .akamaihd.net .fbcdn.net .google.com .static.com .apple.com .oracle.com .sun.com .java.com .adobe.com .steamstatic.com .steampowered.com .steamcontent.com .google.com
> 
> store_id_program /usr/local/libexec/squid/storeid_file_rewrite /var/squid/storeid/storeid_rewrite.txt
> store_id_children 10 startup=5 idle=1 concurrency=0
> always_direct allow !getmethod
> store_id_access deny connect
> store_id_access deny !getmethod
> store_id_access allow rewritedoms
> reload_into_ims on
> max_stale 20 years
> minimum_expiry_time 0
> 
> 
> refresh_pattern -i squid.internal 10080 80% 79900 override-lastmod override-expire ignore-reload ignore-no-store ignore-private
> 
> #APPLE STUFF
> refresh_pattern -i apple.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip|dist)$ 0 80% 43200  refresh-ims
> 
> #apple update
> refresh_pattern -i (download|adcdownload).apple.com/.*.(pkg|dmg) 4320 100% 43200 
> refresh_pattern -i appldnld.apple.com 129600 100% 129600     
> refresh_pattern -i phobos.apple.com 129600 100% 129600     
> refresh_pattern -i iosapps.itunes.apple.com 129600 100% 129600     
> 
> # Updates: Windows
> refresh_pattern -i microsoft.com/..(cab|exe|msi|msu|msf|asf|wma|dat|zip)$ 4320 80% 43200  refresh-ims
> refresh_pattern -i windowsupdate.com/..(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$ 4320 80% 43200  refresh-ims
> refresh_pattern -i windows.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip)$ 4320 80% 43200  refresh-ims
> refresh_pattern -i microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
> refresh_pattern -i windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
> refresh_pattern -i windows.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
> refresh_pattern -i .*windowsupdate.com/.*.(cab|exe) 259200 100% 259200   
> refresh_pattern -i .*update.microsoft.com/.*.(cab|exe|dll|msi|psf) 259200 100% 259200   
> refresh_pattern windowsupdate.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
> refresh_pattern download.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
> refresh_pattern www.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
> refresh_pattern au.download.windowsupdate.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200 
> refresh_pattern bg.v4.pr.dl.ws.microsoft.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
> #windows update NEW UPDATE 0.04
> refresh_pattern update.microsoft.com/.*.(cab|exe) 43200 100% 129600    
> refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200  
> refresh_pattern update.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
> refresh_pattern -i .update.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
> refresh_pattern -i .windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
> refresh_pattern -i .download.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
> refresh_pattern -i .ws.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
> 
> refresh_pattern ([^.]+.)?(cs|content[1-9]|hsar|content-origin|client-download).[steampowered|steamcontent].com/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern ([^.]+.)?.akamai.steamstatic.com/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> 
> refresh_pattern -i ([^.]+.)?.adobe.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?.java.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?.sun.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?.oracle.com/.*.(zip|exe|tar.gz) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> 
> refresh_pattern -i appldnld.apple.com 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?apple.com/.*.(ipa) 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
>  
> refresh_pattern -i ([^.]+.)?.google.com/.*.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
> refresh_pattern -i ([^.]+.)?g.static.com/.*.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
> 
> #FACEBOOK
> refresh_pattern ^http?://*.facebook.com/*  10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
> 
> #FACEBOOK IMAGES  
> refresh_pattern -i pixel.facebook.com..(jpg|png|gif|ico|css|js)  10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
> refresh_pattern -i .akamaihd.net..(jpg|png|gif|ico|css|js) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private   
> refresh_pattern -i (facebook.com).(jpg|png|gif) 10080 80% 43200 store-stale override-expire override-lastmod ignore-reload reload-into-ims ignore-private 
> refresh_pattern static.(xx|ak).fbcdn.net.(jpg|gif|png) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
> refresh_pattern (scontent-lax[0-9]-[0-9].xx|.ak).fbcdn.net.*(jpg|gif|png) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
> 
> refresh_pattern ^https?://profile.ak.fbcdn.net*.(jpg|gif|png) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
> 
> #FACEBOOK VIDEO
> refresh_pattern -i .(video-lax[0-9]-[0-9].xx|video.ak).fbcdn.net.*.(mp4|flv|mp3|amf) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
> refresh_pattern (audio|video)/(webm|mp4) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
> acl https_login url_regex -i ^https.*(login|Login).*
> cache deny https_login
> 
> range_offset_limit 512 MB windowsupdate
> range_offset_limit 4 MB
> range_offset_limit 0
> quick_abort_min -1 KB
> 
> cache_mem 64 MB
> maximum_object_size_in_memory 256 KB
> memory_replacement_policy heap LFUDA
> cache_replacement_policy heap LFUDA
> minimum_object_size 0 KB
> maximum_object_size 512 MB
> cache_dir diskd /var/squid/cache 64000 256 256
> offline_mode off
> cache_swap_low 90
> cache_swap_high 95
> acl donotcache dstdomain '/var/squid/acl/donotcache.acl'
> cache deny donotcache
> cache allow all
> # Add any of your own refresh_pattern entries above these.
> refresh_pattern ^ftp:    1440  20%  10080
> refresh_pattern ^gopher:  1440  0%  1440
> refresh_pattern -i (/cgi-bin/|?) 0  0%  0
> refresh_pattern .    0  20%  4320
> 
> 
> #Remote proxies
> 
> 
> # Setup some default acls
> # ACLs all, manager, localhost, and to_localhost are predefined.
> acl allsrc src all
> acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080 3128 3129 1025-65535 
> acl sslports port 443 563 8080 5223 2197
> 
> acl purge method PURGE
> acl connect method CONNECT
> 
> # Define protocols used for redirects
> acl HTTP proto HTTP
> acl HTTPS proto HTTPS
> 
> # SslBump Peek and Splice
> # http://wiki.squid-cache.org/Features/SslPeekAndSplice
> # http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
> # Match against the current step during ssl_bump evaluation [fast]
> # Never matches and should not be used outside the ssl_bump context.
> #
> # At each SslBump step, Squid evaluates ssl_bump directives to find
> # the next bumping action (e.g., peek or splice). Valid SslBump step
> # values and the corresponding ssl_bump evaluation moments are:
> #   SslBump1: After getting TCP-level and HTTP CONNECT info.
> #   SslBump2: After getting TLS Client Hello info.
> #   SslBump3: After getting TLS Server Hello info.
> # These ACLs exist even when 'SSL/MITM Mode' is set to 'Custom' so that
> # they can be used there for custom configuration.
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> acl banned_hosts src '/var/squid/acl/banned_hosts.acl'
> acl whitelist dstdom_regex -i '/var/squid/acl/whitelist.acl'
> acl blacklist dstdom_regex -i '/var/squid/acl/blacklist.acl'
> http_access allow manager localhost
> 
> # Allow external cache managers
> acl ext_manager src 192.168.1.1
> acl ext_manager src 127.0.0.1
> http_access allow manager ext_manager
> 
> http_access deny manager
> http_access allow purge localhost
> http_access deny purge
> http_access deny !safeports
> http_access deny CONNECT !sslports
> 
> # Always allow localhost connections
> http_access allow localhost
> 
> quick_abort_min 0 KB
> quick_abort_max 0 KB
> quick_abort_pct 95
> request_body_max_size 0 KB
> delay_pools 1
> delay_class 1 2
> delay_parameters 1 -1/-1 -1/-1
> delay_initial_bucket_level 100
> delay_access 1 allow allsrc
> 
> # Reverse Proxy settings
> 
> deny_info TCP_RESET allsrc
> 
> # Package Integration
> url_rewrite_program /usr/local/bin/squidGuard -c /usr/local/etc/squidGuard/squidGuard.conf
> url_rewrite_bypass off
> url_rewrite_children 32 startup=8 idle=4 concurrency=0
> 
> # Custom options before auth
> #host_verify_strict on
> 
> # These hosts are banned
> http_access deny banned_hosts
> # Always allow access to whitelist domains
> http_access allow whitelist
> # Block access to blacklist domains
> http_access deny blacklist
> # List of domains allowed to logging in to Google services
> request_header_access X-GoogApps-Allowed-Domains deny all
> request_header_add X-GoogApps-Allowed-Domains consumer_accounts
> # Set YouTube safesearch restriction
> acl youtubedst dstdomain -n www.youtube.com m.youtube.com youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com
> request_header_access YouTube-Restrict deny all
> request_header_add YouTube-Restrict none youtubedst
> acl sglog url_regex -i sgr=ACCESSDENIED
> http_access deny sglog
> # Custom SSL/MITM options before auth
> acl localhost src 192.168.1.1/32
> #cachemgr_passwd disable offline_toggle reconfigure shutdown
> #cachemgr_passwd REDACTED123! all
> acl no_miss url_regex -i gateway.facebook.com/ws/realtime?
> acl no_miss url_regex -i web-chat-e2ee.facebook.com/ws/chat	
> acl CONNECT method CONNECT
> acl wuCONNECT dstdomain www.update.microsoft.com
> acl wuCONNECT dstdomain sls.microsoft.com
> http_access allow CONNECT wuCONNECT localnet
> http_access allow CONNECT wuCONNECT localhost
> http_access allow windowsupdate localnet
> http_access allow windowsupdate localhost
> http_access deny manager
> 
> acl BrokenButTrustedServers dstdomain '/usr/local/pkg/dstdom.broken'
> acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
> sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
> sslproxy_cert_error deny all
> 
> acl splice_only src 192.168.1.8 #Tasha iPhone
> acl splice_only src 192.168.1.10 #Jon iPhone
> acl splice_only src 192.168.1.11 #Amazon Fire
> acl splice_only src 192.168.1.15 #Tasha HP
> acl splice_only src 192.168.1.16 #iPad
> 
> acl NoSSLIntercept ssl::server_name_regex -i '/usr/local/pkg/reg.url.nobump'
> acl NoBumpDNS dstdomain '/usr/local/pkg/dns.nobump'
> 
> acl markBumped annotate_client bumped=true
> acl bump_only src 192.168.1.3 #webtv
> acl bump_only src 192.168.1.4 #toshiba
> acl bump_only src 192.168.1.5 #imac
> acl bump_only src 192.168.1.9 #macbook
> acl bump_only src 192.168.1.13 #dell
> 
> ssl_bump peek step1
> miss_access deny no_miss 
> ssl_bump splice https_login
> ssl_bump splice splice_only
> ssl_bump splice NoBumpDNS
> ssl_bump splice NoSSLIntercept
> ssl_bump bump bump_only markBumped
> ssl_bump stare all
> 
> acl markedBumped note bumped true
> url_rewrite_access deny markedBumped
> 
> read_ahead_gap 64 KB
> negative_ttl 1 second
> connect_timeout 30 seconds
> request_timeout 60 seconds
> half_closed_clients off
> shutdown_lifetime 10 seconds
> negative_dns_ttl 1 seconds
> ignore_unknown_nameservers on
> pipeline_prefetch 100
> 
> #acl SSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.bump'
> #ssl_bump bump SSLIntercept
> 
> # Setup allowed ACLs
> # Allow local network(s) on interface(s)
> http_access allow localnet
> # Default block all to be sure
> http_access deny allsrc
> 
>> On Apr 10, 2024, at 14:13, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>> 
>> On 2024-04-10 16:22, Jonathan Lee wrote:
>>> Could it be related to this ??
>>> "WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'. error:1E08010C:DECODER routines::unsupported?
>> 
>> I do not know the answer to your question. I speculate that it could be related: Depending on various factors, without those DH parameters, Squid may not be able to communicate with clients. See WARNING in tls-dh description in squid.conf.documented.
>> 
>> I know that others are reporting similar WARNINGs during v6 upgrades and dislike the letters "EC" those messages use. I am not going to debate the best choice of letters for this message, but I can tell you that, in the cases I investigated, the message was caused by a mismatch between squid.conf tls-dh=... option value and DH parameter file contents:
>> 
>> * To Squid, tls-dh=curve:filename format implies that the keytype is "EC". These two letters are then fed to an OpenSSL function that configures related TLS state. OpenSSL then fails if tls-dh filename contains DH parameters produced with "openssl dhparam" command. I have seen these failures in tests.
>> 
>> * To Squid, tls-dh=filename format (i.e. format without the curve name prefix) implies that the keytype is "DC". These two letters are then fed to an OpenSSL function that configured related TLS state. OpenSSL then probably fails if tls-dh filename contains DH parameters produced with "openssl ecparam" command. I have not tested this use case.
>> 
>> * The failing checks and their messages are specific to Squids built with OpenSSL v3. It is possible that Squids built with OpenSSL v1 just silently fail (at runtime), but I have not checked that theory.
>> 
>> 
>> FWIW, this poorly categorized message indicates a configuration _error_. AFAICT, Squid code should be adjusted to _quit_ (i.e. reject bad configuration) after discovering this error instead of continuing as if nothing bad happened.
>> 
>> I recommend addressing the underlying cause, even if this message is unrelated to SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417.
>> 
>> 
>> HTH,
>> 
>> Alex.
>> 
>> 
>>>> On Apr 10, 2024, at 08:38, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>> 
>>>> On 2024-04-10 10:50, Jonathan Lee wrote:
>>>> 
>>>>> I am getting the following error in 6.6 after a upgrade from 5.8 does anyone know what this is caused by?
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
>>>> 
>>>>    $ openssl errstr A000417
>>>>    error:0A000417:SSL routines::sslv3 alert illegal parameter
>>>> 
>>>> I think I have seen that error code before, but I do not recall the exact circumstances. Sorry! The error happens when Squid tries to accept (or peek at) a TLS connection from the client. Might be prohibited TLS version/feature, TLS greasing, or non-TLS traffic? Try examining client TLS Hello packet(s) in Wireshark.
>>>> 
>>>> Alex.
>>>> 
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240410/376cff3b/attachment.htm>

From robertkwild at gmail.com  Thu Apr 11 08:47:36 2024
From: robertkwild at gmail.com (robert k Wild)
Date: Thu, 11 Apr 2024 09:47:36 +0100
Subject: [squid-users] bye from me for now
Message-ID: <CAGU_CiJ56LNAnHpw1poSzKX2grchFK2ZXUdTojqc8J16u2E5DA@mail.gmail.com>

hi all,

just want to say bye from me for now as the company i work for have stopped
using squid i implemented for them, they made good use out of it (since
march 2020) but they found an alternative which is called Ericom ZTedge
which went live Q4 2023

in a way im sad/upset/happy as i worked so hard to research/learn/implement
it and then they finally realise what i have done is so good that they get
a third party company to offer there alternative services

there using ZTEdge for app call home activations (like what i did with
squid) and also for end users to browse the web (they didnt want me to
implement this but i could had done)

i attach my script if interested

thanks,
rob

-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240411/4dafa9bd/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.sh
Type: application/octet-stream
Size: 14130 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240411/4dafa9bd/attachment.obj>

From rafael.akchurin at diladele.com  Thu Apr 11 09:30:26 2024
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 11 Apr 2024 09:30:26 +0000
Subject: [squid-users] Ubuntu 22.04 LTS repository for Squid 6.9 (rebuilt
 from sources in Debian)
Message-ID: <AS5PR04MB9826006005B028F7214FF5BC8F052@AS5PR04MB9826.eurprd04.prod.outlook.com>

Hello everyone,

Online repository with latest Squid 6.9 (rebuilt from sources in Debian) for Ubuntu 22.04 LTS 64-bit is available at https://squid69.diladele.com/.
Github repo https://github.com/diladele/squid-ubuntu/tree/master/src/ubuntu22 contains all the scripts we used to make this compilation.

Here are simple instructions how to use the repo. For more information see readme at https://github.com/diladele/squid-ubuntu .

# add diladele apt key
wget -qO - https://packages.diladele.com/diladele_pub.asc | sudo apt-key add -

# add new repo
echo "deb https://squid69.diladele.com/ubuntu/ jammy main" \
    > /etc/apt/sources.list.d/squid69.diladele.com.list

# and install
apt-get update && apt-get install -y \
    squid-common \
    squid-openssl \
    squidclient \
    libecap3 libecap3-dev

This version of Squid will now be part of Web Safety 9.2 coming out in summer of 2024.  If you have some spare time and are interested in Admin UI for Squid and ICAP web filtering, consider downloading an appliance for VMware ESXi/vSphere<https://packages.diladele.com/websafety-va/9.0/websafety.zip> or Microsoft Hyper-V<https://packages.diladele.com/websafety-va/9.0/websafety-hyperv.zip> or even deploy directly on Microsoft Azure<https://azuremarketplace.microsoft.com/en-us/marketplace/apps/diladele.websafety> and Amazon AWS<https://aws.amazon.com/marketplace/pp/prodview-ixvbzugrltcqq>.

Hope you will find this useful.

Best regards,
Rafael Akchurin
Diladele B.V.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240411/862d038b/attachment.htm>

From dm at belkam.com  Thu Apr 11 09:41:36 2024
From: dm at belkam.com (Dmitry Melekhov)
Date: Thu, 11 Apr 2024 13:41:36 +0400
Subject: [squid-users] Ubuntu 22.04 LTS repository for Squid 6.9
 (rebuilt from sources in Debian)
In-Reply-To: <AS5PR04MB9826006005B028F7214FF5BC8F052@AS5PR04MB9826.eurprd04.prod.outlook.com>
References: <AS5PR04MB9826006005B028F7214FF5BC8F052@AS5PR04MB9826.eurprd04.prod.outlook.com>
Message-ID: <0e3eb5f9-0a94-4369-b583-cfafef6d35ab@belkam.com>

11.04.2024 13:30, Rafael Akchurin ?????:
>
> Hello everyone,
>
> Online repository with latest Squid 6.9
>

why not 6.10?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240411/c3beba9b/attachment.htm>

From pinpinpoola at hotmail.com  Thu Apr 11 09:55:14 2024
From: pinpinpoola at hotmail.com (PinPin Poola)
Date: Thu, 11 Apr 2024 09:55:14 +0000
Subject: [squid-users] Squid as a http/https transparent web proxy in
 2024.... do I still have to build from source?
Message-ID: <CWLP123MB6315CFE4C893F5D1AD2A885DB2052@CWLP123MB6315.GBRP123.PROD.OUTLOOK.COM>

I have put this off for a while, as I find everything about squid very intimidating. The fact you still use an email mailing list and not a web forum site amazes & scares me in equal part.

I am probably using the wrong terminology here, but I now desperately need to build a http/https transparent web proxy with two interfaces, so that clients on a isolated/non-Internet routable subnet can download some large (25GB+) packages.

I don't care which Linux distro tbh; but would prefer Ubuntu as I have most familiarity with it.

I have watched a few old YouTube videos of people explaining that at the time to do this you had to build from source and add switches like "--enable-ssl --enable-ssl-crtd --with-openssl \" before compiling the code.

Is this still that case that I cannot download and use a pre-compiled binary from your site?

Many Thanks
Pin


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240411/a824775a/attachment.htm>

From rafael.akchurin at diladele.com  Thu Apr 11 10:03:43 2024
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 11 Apr 2024 10:03:43 +0000
Subject: [squid-users] Ubuntu 22.04 LTS repository for Squid 6.9
 (rebuilt from sources in Debian)
In-Reply-To: <0e3eb5f9-0a94-4369-b583-cfafef6d35ab@belkam.com>
References: <AS5PR04MB9826006005B028F7214FF5BC8F052@AS5PR04MB9826.eurprd04.prod.outlook.com>
 <0e3eb5f9-0a94-4369-b583-cfafef6d35ab@belkam.com>
Message-ID: <AS5PR04MB98264B321D0AF601F650992E8F052@AS5PR04MB9826.eurprd04.prod.outlook.com>

Only 6.9 is now in Debian; once 6.10 will be there, I will republish.

Best regards,
Rafael



From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Dmitry Melekhov
Sent: Thursday, April 11, 2024 11:42 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Ubuntu 22.04 LTS repository for Squid 6.9 (rebuilt from sources in Debian)

11.04.2024 13:30, Rafael Akchurin ?????:
Hello everyone,

Online repository with latest Squid 6.9



why not 6.10?


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240411/9db03326/attachment.htm>

From uhlar at fantomas.sk  Thu Apr 11 11:08:12 2024
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 11 Apr 2024 13:08:12 +0200
Subject: [squid-users] Squid as a http/https transparent web proxy in
 2024.... do I still have to build from source?
In-Reply-To: <CWLP123MB6315CFE4C893F5D1AD2A885DB2052@CWLP123MB6315.GBRP123.PROD.OUTLOOK.COM>
References: <CWLP123MB6315CFE4C893F5D1AD2A885DB2052@CWLP123MB6315.GBRP123.PROD.OUTLOOK.COM>
Message-ID: <ZhfEnBYe1a3oF8r3@fantomas.sk>

On 11.04.24 09:55, PinPin Poola wrote:
> I have put this off for a while, as I find everything about squid very 
> intimidating.  The fact you still use an email mailing list and not a web 
> forum site amazes & scares me in equal part.

> I am probably using the wrong terminology here, but I now desperately need 
> to build a http/https transparent web proxy with two interfaces, so that 
> clients on a isolated/non-Internet routable subnet can download some large 
> (25GB+) packages.

> I don't care which Linux distro tbh; but would prefer Ubuntu as I have most 
> familiarity with it.

> I have watched a few old YouTube videos of people explaining that at the 
> time to do this you had to build from source and add switches like 
> "--enable-ssl --enable-ssl-crtd --with-openssl \" before compiling the 
> code.

> Is this still that case that I cannot download and use a pre-compiled 
> binary from your site?

Ubuntu includes squid packages, and provides security support for them.
It's rarely needed to rebuild packages on your own, you should not need it.

I prefer Debian which is similat to ubuntu and it comes with certgen, so it 
might wor for you.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
M$ Win's are shit, do not use it !


From david.komanek at natur.cuni.cz  Thu Apr 11 12:34:25 2024
From: david.komanek at natur.cuni.cz (David Komanek)
Date: Thu, 11 Apr 2024 14:34:25 +0200
Subject: [squid-users] Squid as a http/https transparent web proxy in
 2024.... do I still have to build from source?
In-Reply-To: <mailman.1282.1712829828.1200.squid-users@lists.squid-cache.org>
References: <mailman.1282.1712829828.1200.squid-users@lists.squid-cache.org>
Message-ID: <409e64e6-ac88-4d45-a12c-9f4dce3640e8@natur.cuni.cz>

> Date: Thu, 11 Apr 2024 09:55:14 +0000
> From: PinPin Poola<pinpinpoola at hotmail.com>
> To:"squid-users at lists.squid-cache.org"
> 	<squid-users at lists.squid-cache.org>
> Subject: [squid-users] Squid as a http/https transparent web proxy in
> 	2024.... do I still have to build from source?
> Message-ID:
> 	<CWLP123MB6315CFE4C893F5D1AD2A885DB2052 at CWLP123MB6315.GBRP123.PROD.OUTLOOK.COM>
> 	
> Content-Type: text/plain; charset="iso-8859-1"
>
> I have put this off for a while, as I find everything about squid very intimidating. The fact you still use an email mailing list and not a web forum site amazes & scares me in equal part.
>
> I am probably using the wrong terminology here, but I now desperately need to build a http/https transparent web proxy with two interfaces, so that clients on a isolated/non-Internet routable subnet can download some large (25GB+) packages.
>
> I don't care which Linux distro tbh; but would prefer Ubuntu as I have most familiarity with it.
>
> I have watched a few old YouTube videos of people explaining that at the time to do this you had to build from source and add switches like "--enable-ssl --enable-ssl-crtd --with-openssl \" before compiling the code.

At least for FreeBSD binary-packaged squid these three switches should 
be on, but I don't know if they are sufficient.

# uname -vm
FreeBSD 13.3-RELEASE-p1 GENERIC amd64

# squid -v
Squid Cache: Version 6.6
Service Name: squid

This binary uses OpenSSL 1.1.1w-freebsd? 11 Sep 2023. For legal 
restrictions on distribution see https://www.openssl.org/source/license.html

configure options:? '--with-default-user=squid' 
'--bindir=/usr/local/sbin' '--sbindir=/usr/local/sbin' 
'--datadir=/usr/local/etc/squid' '--libexecdir=/usr/local/libexec/squid' 
'--localstatedir=/var' '--sysconfdir=/usr/local/etc/squid' 
'--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid/squid.pid' 
'--with-swapdir=/var/squid/cache' '--without-gnutls' 
'--with-included-ltdl' '--enable-build-info' 
'--enable-removal-policies=lru heap' '--disable-epoll' 
'--disable-arch-native' '--disable-strict-error-checking' 
'--without-systemd' '--without-netfilter-conntrack' '--without-cap' 
'--enable-eui' '--without-ldap' '--enable-cache-digests' 
'--enable-delay-pools' '--disable-ecap' '--disable-esi' 
'--without-expat' '--without-xml2' '--enable-follow-x-forwarded-for' 
'--with-pthreads' '--with-heimdal-krb5=/usr' 'CFLAGS=-I/usr/include -O2 
-pipe -fstack-protector-strong -isystem /usr/local/include 
-fno-strict-aliasing ' 'LDFLAGS=? -pthread -fstack-protector-strong 
-L/usr/local/lib ' 'LIBS=-lkrb5 -lgssapi -lgssapi_krb5 ' 
'KRB5CONFIG=/usr/bin/krb5-config' 'krb5_config=/usr/bin/krb5-config' 
'--enable-htcp' '--enable-icap-client' '--enable-icmp' 
'--enable-ident-lookups' '--enable-ipv6' '--enable-kqueue' 
'--with-large-files' '--enable-http-violations' '--without-nettle' 
'--enable-snmp' '--*enable-ssl*' '--*with-openssl*' 
'--enable-security-cert-generators=file' 
'LIBOPENSSL_CFLAGS=-I/usr/include' 'LIBOPENSSL_LIBS=-lcrypto -lssl' 
'--*enable-ssl-crtd*' '--disable-stacktraces' '--without-tdb' 
'--disable-ipf-transparent' '--enable-ipfw-transparent' 
'--disable-pf-transparent' '--without-nat-devpf' '--enable-forw-via-db' 
'--enable-wccp' '--enable-wccpv2' '--enable-auth-basic=DB NCSA PAM POP3 
RADIUS SMB_LM fake getpwnam NIS' '--enable-auth-digest=file' 
'--enable-auth-negotiate=kerberos wrapper' '--enable-auth-ntlm=fake 
SMB_LM' '--enable-log-daemon-helpers=file DB' 
'--enable-external-acl-helpers=file_userip unix_group delayer' 
'--enable-url-rewrite-helpers=fake LFS' 
'--enable-security-cert-validators=fake' 
'--enable-storeid-rewrite-helpers=file' '--enable-storeio=aufs diskd 
rock ufs' '--enable-disk-io=DiskThreads DiskDaemon AIO Blocking IpcIo 
Mmapped' '--prefix=/usr/local' '--mandir=/usr/local/man' 
'--disable-silent-rules' '--infodir=/usr/local/share/info/' 
'--build=amd64-portbld-freebsd13.2' 
'build_alias=amd64-portbld-freebsd13.2' 'CC=cc' 'CPPFLAGS=-isystem 
/usr/local/include' 'CXX=c++' 'CXXFLAGS=-O2 -pipe 
-fstack-protector-strong -isystem /usr/local/include 
-fno-strict-aliasing? -isystem /usr/local/include ' 'CPP=cpp' 
'PKG_CONFIG_LIBDIR=/wrkdirs/usr/ports/www/squid/work/.pkgconfig:/usr/local/libdata/pkgconfig:/usr/local/share/pkgconfig:/usr/libdata/pkgconfig' 
--enable-ltdl-convenience

# pkg info squid
squid-6.6
Name?????????? : squid
Version??????? : 6.6
Installed on?? : Thu Feb 22 10:57:12 2024 CET
Origin???????? : www/squid
Architecture?? : FreeBSD:13:amd64
Prefix???????? : /usr/local
Categories???? : www
Licenses?????? : GPLv2
Maintainer???? : timp87 at gmail.com
WWW??????????? : http://www.squid-cache.org/
Comment??????? : HTTP Caching Proxy
Options??????? :
 ?? ?ARP_ACL??????? : on
 ?? ?AUTH_LDAP????? : off
 ?? ?AUTH_NIS?????? : on
 ?? ?AUTH_SASL????? : off
 ?? ?AUTH_SMB?????? : off
 ?? ?AUTH_SQL?????? : off
 ?? ?CACHE_DIGESTS? : on
 ?? ?DEBUG????????? : off
 ?? ?DELAY_POOLS??? : on
 ?? ?DOCS?????????? : on
 ?? ?ECAP?????????? : off
 ?? ?ESI??????????? : off
 ?? ?EXAMPLES?????? : on
 ?? ?FOLLOW_XFF???? : on
 ?? ?FS_AUFS??????? : on
 ?? ?FS_DISKD?????? : on
 ?? ?FS_ROCK??????? : on
 ?? ?GSSAPI_BASE??? : on
 ?? ?GSSAPI_HEIMDAL : off
 ?? ?GSSAPI_MIT???? : off
 ?? ?GSSAPI_NONE??? : off
 ?? ?HTCP?????????? : on
 ?? ?ICAP?????????? : on
 ?? ?ICMP?????????? : on
 ?? ?IDENT????????? : on
 ?? ?IPV6?????????? : on
 ?? ?KQUEUE???????? : on
 ?? ?LARGEFILE????? : on
 ?? ?LAX_HTTP?????? : on
 ?? ?NETTLE???????? : off
 ?? ?SNMP?????????? : on
 ?? ?SSL??????????? : on
 ?? ?SSL_CRTD?????? : on
 ?? ?STACKTRACES??? : off
 ?? ?TDB??????????? : off
 ?? ?TP_IPF???????? : off
 ?? ?TP_IPFW??????? : on
 ?? ?TP_PF????????? : off
 ?? ?VIA_DB???????? : on
 ?? ?WCCP?????????? : on
 ?? ?WCCPV2???????? : on
Annotations??? :
 ?? ?FreeBSD_version: 1302001
 ?? ?build_timestamp: 2024-02-16T15:01:11+0000
 ?? ?built_by?????? : poudriere-git-3.4.1
 ?? ?cpe??????????? : cpe:2.3:a:squid-cache:squid:6.6:::::freebsd13:x64
 ?? ?port_checkout_unclean: no
 ?? ?port_git_hash? : 756e18783
 ?? ?ports_top_checkout_unclean: no
 ?? ?ports_top_git_hash: b3e528239
 ?? ?repo_type????? : binary
 ?? ?repository???? : FreeBSD
Flat size????? : 7.99MiB
Description??? :
Squid is a fully-featured HTTP/1.0 proxy which is almost (but not quite)
HTTP/1.1 compliant. Squid offers a rich access control, authorization and
logging environment to develop web proxy and content serving applications.



>
> Is this still that case that I cannot download and use a pre-compiled binary from your site?
>
> Many Thanks
> Pin
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240411/6679f5a8/attachment.htm>

From rousskov at measurement-factory.com  Thu Apr 11 16:26:00 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 11 Apr 2024 12:26:00 -0400
Subject: [squid-users]
 SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
In-Reply-To: <8961D36D-C6B5-4F7A-A93E-0A2D80D68BC7@gmail.com>
References: <5A46B30E-D553-4681-9A18-50EEED90847C@gmail.com>
 <f10251e7-6c09-4657-80bc-e1d4a3267c91@measurement-factory.com>
 <07A70FC2-D089-4090-9A83-656BADE0064A@gmail.com>
 <cc452541-7e19-400a-99ba-ffabfe58c21c@measurement-factory.com>
 <75DA748B-04E7-4CB6-8F33-F23A8D527C3C@gmail.com>
 <8961D36D-C6B5-4F7A-A93E-0A2D80D68BC7@gmail.com>
Message-ID: <1386fe99-ffbd-4598-a656-e6e987606e4a@measurement-factory.com>

On 2024-04-10 17:48, Jonathan Lee wrote:
> It works in 5.8 with no errors however in 6.6 I can see indexing and 
> other information that I have never seen before

Unfortunately, I am unable to make progress with this email thread 
because there are just too many different problems being introduced and 
discussed. I am aware that the problems may be related, but it does not 
change the outcome for me. I hope somebody else can sort through this 
collection of concerns and data. If not, I recommend restarting from 
scratch while focusing on a single issue (of your choice).


> I have some open pull requests in for Squid here
> https://github.com/pfsense/FreeBSD-ports/pull/

I am not familiar with PFSense development practices, but PFSense PRs 
should be discussed with PFSense folks, using PFSense support channels 
(rather than this mailing list). If you want your code changes to be 
accepted into _official_ Squid releases, then please follow
https://wiki.squid-cache.org/MergeProcedure

Alex.



From squid3 at treenet.co.nz  Thu Apr 11 16:47:05 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Apr 2024 04:47:05 +1200
Subject: [squid-users] Squid as a http/https transparent web proxy in
 2024.... do I still have to build from source?
In-Reply-To: <CWLP123MB6315CFE4C893F5D1AD2A885DB2052@CWLP123MB6315.GBRP123.PROD.OUTLOOK.COM>
References: <CWLP123MB6315CFE4C893F5D1AD2A885DB2052@CWLP123MB6315.GBRP123.PROD.OUTLOOK.COM>
Message-ID: <32a1d686-c7a4-4042-bca4-c97ca2987cd5@treenet.co.nz>

On 11/04/24 21:55, PinPin Poola wrote:
> I don't care which Linux distro tbh; but would prefer Ubuntu as I have 
> most familiarity with it.
> 

Latest Ubuntu provide the "squid-openssl" package, which contains the 
SSL-Bump and other OpenSSL-exclusive features.

Just install that package as you would the "squid" package. It can also 
be installed as a drop-in upgrade for the "squid" package.

One thing to be aware of in both cases, is that the SELinux security 
system does not allow Squid by default to access the /etc/ssl/* config 
area. So you may need to allow that depending on what your desired 
TLS/SSL settings in squid.conf are.



Cheers
Amos


From squid3 at treenet.co.nz  Thu Apr 11 18:25:09 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Apr 2024 06:25:09 +1200
Subject: [squid-users]
 SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
In-Reply-To: <07A70FC2-D089-4090-9A83-656BADE0064A@gmail.com>
References: <5A46B30E-D553-4681-9A18-50EEED90847C@gmail.com>
 <f10251e7-6c09-4657-80bc-e1d4a3267c91@measurement-factory.com>
 <07A70FC2-D089-4090-9A83-656BADE0064A@gmail.com>
Message-ID: <9f7a5a21-1b17-4ba2-a4a2-be83bd640c34@treenet.co.nz>

On 11/04/24 08:22, Jonathan Lee wrote:
> Could it be related to this ??
> 
> "WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'. 
> error:1E08010C:DECODER routines::unsupported?
> 

That would certainly make Squid unable to use EC (Elliptic Curve) ciphers.


Unfortunately OpenSSL is not verbose enough to explain the actual 
problem in an easily understood way.


HTH
Amos


From jonathanlee571 at gmail.com  Thu Apr 11 20:22:24 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 11 Apr 2024 13:22:24 -0700
Subject: [squid-users]
 SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR
In-Reply-To: <9f7a5a21-1b17-4ba2-a4a2-be83bd640c34@treenet.co.nz>
References: <5A46B30E-D553-4681-9A18-50EEED90847C@gmail.com>
 <f10251e7-6c09-4657-80bc-e1d4a3267c91@measurement-factory.com>
 <07A70FC2-D089-4090-9A83-656BADE0064A@gmail.com>
 <9f7a5a21-1b17-4ba2-a4a2-be83bd640c34@treenet.co.nz>
Message-ID: <03C2A83E-95FB-4475-A990-7DA4237DC363@gmail.com>

Is there anyway to correct this I am a bit confused as it works perfectly in 5.8 I even used the dynamic cache to reuse a full Windows 11 update yesterday over my DSL it took 30 mins to originally download and on the next system took 2 mins to download and install I had hits all day with it. But on 6.6 same config same certificates I get this weird error, and it is very sluggish too. 

> On Apr 11, 2024, at 11:25, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 11/04/24 08:22, Jonathan Lee wrote:
>> Could it be related to this ??
>> "WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'. error:1E08010C:DECODER routines::unsupported?
> 
> That would certainly make Squid unable to use EC (Elliptic Curve) ciphers.
> 
> 
> Unfortunately OpenSSL is not verbose enough to explain the actual problem in an easily understood way.
> 
> 
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From pinpinpoola at hotmail.com  Fri Apr 12 13:12:42 2024
From: pinpinpoola at hotmail.com (PinPin Poola)
Date: Fri, 12 Apr 2024 13:12:42 +0000
Subject: [squid-users] Squid Cache 6.9 on Ubuntu 22.04.3 LTS. Not caching
 large files to disk.
Message-ID: <CWLP123MB63158C816C3DCC4D7D036365B2042@CWLP123MB6315.GBRP123.PROD.OUTLOOK.COM>

I have moved on a pace since my first message yesterday - thank you all who helped. I can now happily download files from clients on my isolated network, through my new proxy. #fanfare!!!!

However, I would really like to cache any file over 1 GB in size to disk, as the same file could get downloaded 100's of time a day by many different clients.  The cache can purge/age out after a week or so, or when getting close to the 150 GB limit.

I have configured cache_dir as below, but when I download a large 2 GB ISO file, I do not see it being cached within the /var/spool/squid directory structure and a subsequent download of the same file is no faster; so it is coming from Internet source.

My full /etc/squid/squid.conf file looks like this:

acl localnet src 0.0.0.1-0.255.255.255  # RFC 1122 "this" network (LAN)
acl localnet src 10.0.0.0/8             # RFC 1918 local private network (LAN)
acl localnet src 100.64.0.0/10          # RFC 6598 shared address space (CGN)
acl localnet src 169.254.0.0/16         # RFC 3927 link-local (directly plugged) machines
acl localnet src 172.16.0.0/12          # RFC 1918 local private network (LAN)
acl localnet src 192.168.0.0/16         # RFC 1918 local private network (LAN)
acl localnet src fc00::/7               # RFC 4193 local private network range
acl localnet src fe80::/10              # RFC 4291 link-local (directly plugged) machines
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localhost
http_access allow localnet
http_access deny to_localhost
http_access deny to_linklocal
include /etc/squid/conf.d/*.conf
http_access deny all
http_port 3128
coredump_dir /var/spool/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
shutdown_lifetime 10 seconds
maximum_object_size 35 GB
cache_dir aufs /var/spool/squid 150000 16 256 min-size=1073741824
cache_mem 256 MB
maximum_object_size_in_memory 512 KB
cache_replacement_policy heap LFUDA
range_offset_limit -1
quick_abort_min -1 KB


I have plenty of disk space on my root partition:

Filesystem                         Size  Used Avail Use% Mounted on
tmpfs                              2.4G  1.2M  2.4G   1% /run
/dev/mapper/ubuntu--vg-ubuntu--lv  364G  8.3G  341G   3% /
tmpfs                               12G   12K   12G   1% /dev/shm
tmpfs                              5.0M     0  5.0M   0% /run/lock
/dev/sda2                          974M  252M  656M  28% /boot
tmpfs                              2.4G  4.0K  2.4G   1% /run/user/1000


I would really appreciate any pointers on what I am doing wrong?

This is a test setup for now; so if there are security/best practice concerns about my config, I would like to be aware; but I need to get it working for now.

Many Thanks
Pin


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240412/a6eedaa5/attachment.htm>

From pinpinpoola at hotmail.com  Fri Apr 12 16:30:46 2024
From: pinpinpoola at hotmail.com (PinPin Poola)
Date: Fri, 12 Apr 2024 16:30:46 +0000
Subject: [squid-users] Squid Cache 6.9 on Ubuntu 22.04.3 LTS. Not
 caching large files to disk.
In-Reply-To: <3478E213-8C85-4932-AFC8-D0917D7DF18D@gmail.com>
References: <CWLP123MB63158C816C3DCC4D7D036365B2042@CWLP123MB6315.GBRP123.PROD.OUTLOOK.COM>
 <3478E213-8C85-4932-AFC8-D0917D7DF18D@gmail.com>
Message-ID: <CWLP123MB6315CD16A832EBF129178850B2042@CWLP123MB6315.GBRP123.PROD.OUTLOOK.COM>

Hi Jonathan,

No, I didn't have a refresh_pattern for .ISO/etc, so thank you. BTW, what are the "43800 100% 129600" values?

I realised that I had not actually configured "SSL Bump" in that last /etc/squid/squid.conf file I posted, as the access.log showed my https connections as being tunnelled. ?

I have tried to enable SSL Bump as best I understand how to and my squid.conf now looks like:

acl localnet src 0.0.0.1-0.255.255.255  # RFC 1122 "this" network (LAN)
acl localnet src 10.0.0.0/8             # RFC 1918 local private network (LAN)
acl localnet src 100.64.0.0/10          # RFC 6598 shared address space (CGN)
acl localnet src 169.254.0.0/16         # RFC 3927 link-local (directly plugged) machines
acl localnet src 172.16.0.0/12          # RFC 1918 local private network (LAN)
acl localnet src 192.168.0.0/16         # RFC 1918 local private network (LAN)
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localhost
http_access allow localnet
http_access deny to_localhost
http_access deny to_linklocal
include /etc/squid/conf.d/*.conf
http_access deny all
http_port 3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myCA.pem
sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/lib/ssl_db -M 4MB
ssl_bump peek all
ssl_bump splice all
coredump_dir /var/spool/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
refresh_pattern -i \.(rar|jar|gz|tgz|tar|bz2|iso)(\?|$)?????43800 100% 129600
shutdown_lifetime 10 seconds
maximum_object_size 35 GB
cache_mem 256 MB
maximum_object_size_in_memory 512 KB
cache_replacement_policy heap LFUDA
range_offset_limit -1
quick_abort_min -1 KB
cache_dir aufs /var/spool/squid 150000 16 256 min-size=1048576

I read in one blog that the cache_dir had to be listed after maximum_object_size so I moved it.

I also reduced the cache_dir / min-size value from 1 GB to 1 MB for testing and switched to a smaller .ISO file as I was getting bored wating for the big one to download repeatedly.

So now:

1) A https download works, but is still tunnelled as mentioned above:

root at client1 [ /tmp ]# wget -e https_proxy=10.40.1.250:3128 --ca-certificate ~/myCA.pem https://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso
--2024-04-12 15:42:44--  https://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso
Connecting to 10.40.1.250:3128... connected.
Proxy request sent, awaiting response... 200 OK
Length: 1016070144 (969M) [application/x-iso9660-image]
Saving to: ?ubuntu-18.04.6-live-server-amd64.iso?

ubuntu-18.04.6-live-server-amd64.iso            100%[=======================================================================================================>] 969.00M  20.0MB/s    in 53s

2024-04-12 15:43:37 (18.4 MB/s) - ?ubuntu-18.04.6-live-server-amd64.iso? saved [1016070144/1016070144]

and the access.log entry looks like this:

1712936617.285  52629 10.40.1.2 TCP_TUNNEL/200 1017438604 CONNECT releases.ubuntu.com:443 - HIER_DIRECT/185.125.190.40 -


2) A new http download works and is cached to disk now:

root at client1 [ /tmp ]# wget -e http_proxy=10.40.1.250:3128 http://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso
--2024-04-12 15:44:15--  http://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso
Connecting to 10.40.1.250:3128... connected.
Proxy request sent, awaiting response... 200 OK
Length: 1016070144 (969M) [application/x-iso9660-image]
Saving to: ?ubuntu-18.04.6-live-server-amd64.iso.1?

ubuntu-18.04.6-live-server-amd64.iso.1          100%[=======================================================================================================>] 969.00M  16.0MB/s    in 52s

2024-04-12 15:45:07 (18.6 MB/s) - ?ubuntu-18.04.6-live-server-amd64.iso.1? saved [1016070144/1016070144]

and the access.log entry looks like this:

1712936707.689  52198 10.40.1.2 TCP_MISS/200 1016070508 GET http://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso - HIER_DIRECT/185.125.190.40 application/x-iso9660-image


3) A subsequent http download of the same file does pull it from cache:

root at client1 [ /tmp ]# wget -e http_proxy=10.40.1.250:3128 http://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso
--2024-04-12 15:45:23--  http://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso
Connecting to 10.40.1.250:3128... connected.
Proxy request sent, awaiting response... 200 OK
Length: 1016070144 (969M) [application/x-iso9660-image]
Saving to: ?ubuntu-18.04.6-live-server-amd64.iso.2?

ubuntu-18.04.6-live-server-amd64.iso.2          100%[=======================================================================================================>] 969.00M  30.4MB/s    in 36s

2024-04-12 15:45:58 (27.0 MB/s) - ?ubuntu-18.04.6-live-server-amd64.iso.2? saved [1016070144/1016070144]

and the access.log entry looks like this:

1712936758.943  35825 10.40.1.2 TCP_HIT/200 1016070518 GET http://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso - HIER_NONE/- application/x-iso9660-image


I am making progress, I just need to understand where I am going wrong with SSL Bump for https connections. Why it is still tunnelling? If I fix that I think it will cache/pull from cache the https downloads too. #fingerscrossed

Any suggestions or decent web blogs/etc on how to configure it?

Have a great weekend,

Many Thanks
Pin

________________________________
From: Jonathan Lee <jonathanlee571 at gmail.com>
Sent: 12 April 2024 15:10
To: PinPin Poola <pinpinpoola at hotmail.com>
Cc: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Squid Cache 6.9 on Ubuntu 22.04.3 LTS. Not caching large files to disk.

Do you have a refresh pattern for .ISO to do this. The defaults for the cache does not cache .ISO files, you have to add a custom refresh pattern for it

Something like this

refresh_pattern -i \.(rar|jar|gz|tgz|tar|bz2|iso)(\?|$)                         43800 100% 129600        # RAR | JAR | GZ | TGZ | TAR | BZ2 | ISO

~~~~~
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240412/1d3944f0/attachment.htm>

From jonathanlee571 at gmail.com  Fri Apr 12 19:33:16 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 12 Apr 2024 12:33:16 -0700
Subject: [squid-users] Squid Cache 6.9 on Ubuntu 22.04.3 LTS. Not
 caching large files to disk.
In-Reply-To: <CWLP123MB6315CD16A832EBF129178850B2042@CWLP123MB6315.GBRP123.PROD.OUTLOOK.COM>
References: <CWLP123MB6315CD16A832EBF129178850B2042@CWLP123MB6315.GBRP123.PROD.OUTLOOK.COM>
Message-ID: <F980FFE1-D933-485F-969F-386DE5ECDF0C@gmail.com>

You need to install certificates as well as on your clients. I don?t normally catch ISO. I only catch updates regarding windows. I have issues where I have to reserve the updates rather than download them over and over again it saves on bandwidth and costs. I wish you the best of luck, however you do need certificates for the ability to catch HTTPS. without certificates, it will not function so you must own the devices as well for this function. Windows is a different story as the updates come over just HTTPtherefore they can be caught without intercepting. I hope that helps if you?re using a transparent proxy.
Sent from my iPhone

> On Apr 12, 2024, at 09:30, PinPin Poola <pinpinpoola at hotmail.com> wrote:
> 
> ?
> Hi Jonathan,
> 
> No, I didn't have a refresh_pattern for .ISO/etc, so thank you. BTW, what are the "43800 100% 129600" values?
> 
> I realised that I had not actually configured "SSL Bump" in that last /etc/squid/squid.conf file I posted, as the access.log showed my https connections as being tunnelled. ?
> 
> I have tried to enable SSL Bump as best I understand how to and my squid.conf now looks like:
> 
> acl localnet src 0.0.0.1-0.255.255.255  # RFC 1122 "this" network (LAN)
> acl localnet src 10.0.0.0/8             # RFC 1918 local private network (LAN)
> acl localnet src 100.64.0.0/10          # RFC 6598 shared address space (CGN)
> acl localnet src 169.254.0.0/16         # RFC 3927 link-local (directly plugged) machines
> acl localnet src 172.16.0.0/12          # RFC 1918 local private network (LAN)
> acl localnet src 192.168.0.0/16         # RFC 1918 local private network (LAN)
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access allow localhost
> http_access allow localnet
> http_access deny to_localhost
> http_access deny to_linklocal
> include /etc/squid/conf.d/*.conf
> http_access deny all
> http_port 3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myCA.pem
> sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/lib/ssl_db -M 4MB
> ssl_bump peek all
> ssl_bump splice all
> coredump_dir /var/spool/squid
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> refresh_pattern -i \.(rar|jar|gz|tgz|tar|bz2|iso)(\?|$)?????43800 100% 129600
> shutdown_lifetime 10 seconds
> maximum_object_size 35 GB
> cache_mem 256 MB
> maximum_object_size_in_memory 512 KB
> cache_replacement_policy heap LFUDA
> range_offset_limit -1
> quick_abort_min -1 KB
> cache_dir aufs /var/spool/squid 150000 16 256 min-size=1048576
> 
> I read in one blog that the cache_dir had to be listed after maximum_object_size so I moved it. 
> 
> I also reduced the cache_dir / min-size value from 1 GB to 1 MB for testing and switched to a smaller .ISO file as I was getting bored wating for the big one to download repeatedly.
> 
> So now:
> 
> 1) A https download works, but is still tunnelled as mentioned above:
> 
> root at client1 [ /tmp ]# wget -e https_proxy=10.40.1.250:3128 --ca-certificate ~/myCA.pem https://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso
> --2024-04-12 15:42:44--  https://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso
> Connecting to 10.40.1.250:3128... connected.
> Proxy request sent, awaiting response... 200 OK
> Length: 1016070144 (969M) [application/x-iso9660-image]
> Saving to: ?ubuntu-18.04.6-live-server-amd64.iso?
> 
> ubuntu-18.04.6-live-server-amd64.iso            100%[=======================================================================================================>] 969.00M  20.0MB/s    in 53s
> 
> 2024-04-12 15:43:37 (18.4 MB/s) - ?ubuntu-18.04.6-live-server-amd64.iso? saved [1016070144/1016070144]
> 
> and the access.log entry looks like this:
> 
> 1712936617.285  52629 10.40.1.2 TCP_TUNNEL/200 1017438604 CONNECT releases.ubuntu.com:443 - HIER_DIRECT/185.125.190.40 -
> 
> 
> 2) A new http download works and is cached to disk now:
> 
> root at client1 [ /tmp ]# wget -e http_proxy=10.40.1.250:3128 http://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso
> --2024-04-12 15:44:15--  http://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso
> Connecting to 10.40.1.250:3128... connected.
> Proxy request sent, awaiting response... 200 OK
> Length: 1016070144 (969M) [application/x-iso9660-image]
> Saving to: ?ubuntu-18.04.6-live-server-amd64.iso.1?
> 
> ubuntu-18.04.6-live-server-amd64.iso.1          100%[=======================================================================================================>] 969.00M  16.0MB/s    in 52s
> 
> 2024-04-12 15:45:07 (18.6 MB/s) - ?ubuntu-18.04.6-live-server-amd64.iso.1? saved [1016070144/1016070144]
> 
> and the access.log entry looks like this:
> 
> 1712936707.689  52198 10.40.1.2 TCP_MISS/200 1016070508 GET http://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso - HIER_DIRECT/185.125.190.40 application/x-iso9660-image
> 
> 
> 3) A subsequent http download of the same file does pull it from cache:
> 
> root at client1 [ /tmp ]# wget -e http_proxy=10.40.1.250:3128 http://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso
> --2024-04-12 15:45:23--  http://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso
> Connecting to 10.40.1.250:3128... connected.
> Proxy request sent, awaiting response... 200 OK
> Length: 1016070144 (969M) [application/x-iso9660-image]
> Saving to: ?ubuntu-18.04.6-live-server-amd64.iso.2?
> 
> ubuntu-18.04.6-live-server-amd64.iso.2          100%[=======================================================================================================>] 969.00M  30.4MB/s    in 36s
> 
> 2024-04-12 15:45:58 (27.0 MB/s) - ?ubuntu-18.04.6-live-server-amd64.iso.2? saved [1016070144/1016070144]
> 
> and the access.log entry looks like this:
> 
> 1712936758.943  35825 10.40.1.2 TCP_HIT/200 1016070518 GET http://releases.ubuntu.com/18.04.6/ubuntu-18.04.6-live-server-amd64.iso - HIER_NONE/- application/x-iso9660-image
> 
> 
> I am making progress, I just need to understand where I am going wrong with SSL Bump for https connections. Why it is still tunnelling? If I fix that I think it will cache/pull from cache the https downloads too. #fingerscrossed
> 
> Any suggestions or decent web blogs/etc on how to configure it?
> 
> Have a great weekend,
> 
> Many Thanks
> Pin
> 
> From: Jonathan Lee <jonathanlee571 at gmail.com>
> Sent: 12 April 2024 15:10
> To: PinPin Poola <pinpinpoola at hotmail.com>
> Cc: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
> Subject: Re: [squid-users] Squid Cache 6.9 on Ubuntu 22.04.3 LTS. Not caching large files to disk.
>  
> Do you have a refresh pattern for .ISO to do this. The defaults for the cache does not cache .ISO files, you have to add a custom refresh pattern for it
> 
> Something like this 
> 
> refresh_pattern -i \.(rar|jar|gz|tgz|tar|bz2|iso)(\?|$)                         43800 100% 129600        # RAR | JAR | GZ | TGZ | TAR | BZ2 | ISO
> 
> ~~~~~
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240412/40d09edd/attachment.htm>

From yvong at gmx.net  Sun Apr 14 13:03:49 2024
From: yvong at gmx.net (=?UTF-8?Q?Yvon_Gro=C3=9F?=)
Date: Sun, 14 Apr 2024 15:03:49 +0200
Subject: [squid-users] Install-Problems under WSL2 / Unbuntu 22.04 LTS with
 squid v6.9
Message-ID: <44310f77-a473-4cb3-85a6-47f006ac8d09@gmx.net>

Hello,

after a few attempts and tests with Squid (version 5.7) under Windows
Server 2022 - "Windows Subsystem for Linux" with Ubuntu 22.04 LTS, I
decided to install newer versions of Squid (e.g. v6.9) on the system in
question. In doing so, I encountered problems that I did not expect and
had not yet found a solution to. First of all, I am not a Linux expert
and therefore hope to get some valuable tips and advice from the community.
So, what is it all about?
I want to compile, install and run the latest version of Squid (v6.9)
under WSL2 (I'm running Ubuntu 22.04 LTS).
What exactly have I done ?
- downloaded the latest squid_6.9.tar.gz and put it in the /opt directory
- unpacked tar with tar xzf
- ./configure as specified on the squid-cache-faq page for Ubuntu:
--prefix=/usr \
--localstatedir=/var \
--libexecdir=${prefix}/lib/squid \
--datadir=${prefix}/share/squid \
--sysconfdir=/etc/squid \
--with-default-user=administrator \ ### a deviation here
--with-logdir=/var/log/squid \
--with-pidfile=/var/run/squid.pid
- Missing dependencies like
gcc
c++
g++
clang
perl
libssl-dev
as packages via apt-get install and installed
- executed ./configure again and checked for any missing dependencies
- after Ok, then executed the following steps
- make executed (completed successfully)
- make check (completed successfully)
- make install (completed successfully)
After the installation, however, I notice that squid cannot be started.
The error message says that squid cannot find the squid.service.
Obviously not everything was installed correctly or completely during
the installation. When I search for the file in question in the folder,
this file is nowhere to be found (except of course in the compressed
squid.tar file). Strange.
When setting up WSL2 for the first time, you are asked for the main
user: the main user is "administrator" --> hence a change when calling
the ./configure command (default-user). I think this is correct.
However, I also carried out the installation as "root". The behavior is
the same.
I have already carried out 4 or 5 compilations and installations with
slight differences. Unfortunately, I am not successful. Squid cannot be
started.
I hope there is someone in the community who has already had experience
with WSL2 (Windows Subsystem for Linux) and can give me a little help to
get the whole thing working after all. Is it perhaps an access problem
that occurred during installation? (I have read that Ubuntu is partly
different from the "original" Linux). Or is my configuration
(./configure) insufficient or incomplete.
Since the Squid project is very interesting and I would like to follow
it and gain experience, I would be happy to receive your tips.

Have a nice Sunday and greetings from Germany
Yvon

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240414/51711aab/attachment.htm>

From gkinkie at gmail.com  Sun Apr 14 14:03:06 2024
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Sun, 14 Apr 2024 21:03:06 +0700
Subject: [squid-users] Install-Problems under WSL2 / Unbuntu 22.04 LTS
 with squid v6.9
In-Reply-To: <44310f77-a473-4cb3-85a6-47f006ac8d09@gmx.net>
References: <44310f77-a473-4cb3-85a6-47f006ac8d09@gmx.net>
Message-ID: <CA+Y8hcMnj5VLPnTTmNhPrsS35o_Up=aiAdp2Dz5D98XuRWkwhw@mail.gmail.com>

On Sun, 14 Apr 2024 at 20:04, Yvon Gro? <yvong at gmx.net> wrote:

[...]


> After the installation, however, I notice that squid cannot be started.
> The error message says that squid cannot find the squid.service. Obviously
> not everything was installed correctly or completely during the
> installation. When I search for the file in question in the folder, this
> file is nowhere to be found (except of course in the compressed squid.tar
> file). Strange.
>

In order to understand what is happening, a crucial piece of information is
missing: how are you trying to start squid?
Have you tried running /usr/sbin/squid ? Does it work when you do that?

  Francesco
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240414/e1924199/attachment.htm>

From andre.bolinhas at articatech.com  Sun Apr 14 21:23:39 2024
From: andre.bolinhas at articatech.com (Andre Bolinhas)
Date: Sun, 14 Apr 2024 22:23:39 +0100
Subject: [squid-users] ACL / http_access rules stop work using Squid 6+
In-Reply-To: <ad81a226-e4dd-4748-a15f-746e2bf9a75b@articatech.com>
References: <zarafa.6601cce9.6f7a.695ad7ca298a924d@ns413437.ip-37-187-142.eu>
 <9cd03f00-a87e-4c48-8a9c-61eb6751c0d9@measurement-factory.com>
 <ad81a226-e4dd-4748-a15f-746e2bf9a75b@articatech.com>
Message-ID: <7e2d2ece-d58a-46af-890d-bb3801f392e8@articatech.com>

Hi All

Any tip on this matter? I want to upgrade to squid 6.9 but due to this 
issue, i'm stuck.

Best regards

On 01/04/2024 11:53, Andre Bolinhas wrote:
>
> Hi Alex
>
> Thanks for your help on the matter.
>
>
>> The logs archive you shared previously has expired, so I cannot 
>> double check, but from what I remember, the shared logs did not 
>> support the above assertion, so there may be more to the story here. 
>> However, to make progress, let's assume that v5 configuration files 
>> are identical to v6 configuration files. 
> If you want, I can run the same test with in a different debug 
> parameters, just tell which ones.
>
> I have re-uploaded the cache.log files.
> https://we.tl/t-AB4XuUwuf7
>
>> One way to answer all of the above questions is to look at the 
>> following output:
>>
>> ??? squid -k parse ... |& grep Processing:.http_access 
> There is no diff between both squid version, you can check it here
> DiffNow - Compare Files, URLs, and Clipboard Contents Online 
> <https://www.diffnow.com/report/jsrva>
>
>> The logs archive you shared previously has expired, so I cannot 
>> double check, but from what I remember, the shared logs did not 
>> support the above assertion, so there may be more to the story here. 
>> However, to make progress, let's assume that v5 configuration files 
>> are identical to v6 configuration files.
> The configuration files / folder are the same, the server is the same, 
> the only thing that changes is the Squid version
>
> On 29/03/2024 17:40, Alex Rousskov wrote:
>> On 2024-03-25 15:13, Bolinhas Andr? wrote:
>>
>>> Yes, the configuration is the same for both versions.
>>
>> The logs archive you shared previously has expired, so I cannot 
>> double check, but from what I remember, the shared logs did not 
>> support the above assertion, so there may be more to the story here. 
>> However, to make progress, let's assume that v5 configuration files 
>> are identical to v6 configuration files.
>>
>> 1. Is there an "http_access allow all AnnotateFinalAllow" rule?
>>
>> 2. Is there an "http_access deny HTTP Group38 AnnotateRule28" rule?
>>
>> 3. Assuming the answers are "yes" and "yes", which rule comes first? 
>> If you use include files, this question applies to the imaginary 
>> preprocessed squid.conf file with all the include files inlined 
>> (recursively if needed). That kind of preprocessed configuration is 
>> what Squid effectively sees when compiling http_access rules, one by 
>> one. Which of the two rules will Squid see first?
>>
>> One way to answer all of the above questions is to look at the 
>> following output:
>>
>> ??? squid -k parse ... |& grep Processing:.http_access
>>
>> Replace "..." with your regular squid startup command line options 
>> and adjust standard error redirection (|&) as needed for your shell. 
>> Run the above command for both Squid v5 and v6 binaries. You should 
>> see output like this:
>>
>>
>>> 2024/03/29 13:31:05| Processing: http_access allow manager
>>> 2024/03/29 13:31:05| Processing: http_access deny all
>>
>>
>> HTH,
>>
>> Alex.
>>
>>
>>> ------------------------------------------------------------------------ 
>>>
>>> *De:* Alex Rousskov <rousskov at measurement-factory.com>
>>> *Enviado:* segunda-feira, 25 de mar?o de 2024 19:12
>>> *Para:* squid-users at lists.squid-cache.org
>>> *Assunto* Re: [squid-users] ACL / http_access rules stop work using 
>>> Squid 6+
>>>
>>>
>>>
>>> On 2024-03-22 09:38, Andre Bolinhas wrote:
>>>
>>> ?> In previous versions of squid, from 3 to 5.9, I use this kind of 
>>> deny
>>> ?> rules and they work like charm
>>> ?>
>>> ?> acl AnnotateRule28 annotate_transaction accessrule=Rule28
>>> ?> http_access deny HTTP Group38 AnnotateRule28
>>> ?>
>>> ?> This allows me to deny objects without bump / show the error page
>>> ?> (deny_info)
>>> ?>
>>> ?> But using squid 6+ this rules stop to work and everything is 
>>> allowed.
>>> ?>
>>> ?> Example:
>>> ?> Squid 5.9 (OK)
>>> ?> https://ibb.co/YdKgL1Y
>>> ?>
>>> ?> Squid 6.8 (NOK)
>>> ?> https://ibb.co/tbyY2GV
>>> ?>
>>> ?> Sample of both cache.log in debug mode
>>> ?>
>>> ?> https://we.tl/t-T7Nz1rVbVu
>>>
>>>
>>> In you v6 logs, most logged transactions are allowed because a rule
>>> similar to the one reconstructed below is matching:
>>>
>>> ????? http_access allow all AnnotateFinalAllow
>>>
>>>
>>> There are similar cases in v5 logs as well, but most denied v5
>>> transactions match the following rule instead (i.e. the one you shared
>>> above):
>>>
>>> ????? http_access deny HTTP Group38 AnnotateRule28
>>>
>>>
>>> In your Squid configuration, v6 allow rule is listed much higher 
>>> than v5
>>> deny rule (#43 vs #149). I do not see any signs of Group38 or
>>> AnnotateRule28 ACL evaluation in v6 logs, as if the rule sets are
>>> different for two different Squid instances. Are you using the same set
>>> of http_access rules for both Squid versions?
>>>
>>> Alex.
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>>>
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240414/180bcfb7/attachment.htm>

From rousskov at measurement-factory.com  Mon Apr 15 13:12:33 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 15 Apr 2024 09:12:33 -0400
Subject: [squid-users] ACL / http_access rules stop work using Squid 6+
In-Reply-To: <7e2d2ece-d58a-46af-890d-bb3801f392e8@articatech.com>
References: <zarafa.6601cce9.6f7a.695ad7ca298a924d@ns413437.ip-37-187-142.eu>
 <9cd03f00-a87e-4c48-8a9c-61eb6751c0d9@measurement-factory.com>
 <ad81a226-e4dd-4748-a15f-746e2bf9a75b@articatech.com>
 <7e2d2ece-d58a-46af-890d-bb3801f392e8@articatech.com>
Message-ID: <01c18e16-e7f2-462e-9c55-3cf6adc33e84@measurement-factory.com>

On 2024-04-14 17:23, Andre Bolinhas wrote:

> Any tip on this matter? I want to upgrade to squid 6.9 but due to this 
> issue, i'm stuck.


Hi Andre,

     Please note that I did _not_ receive your email quoted below. It is 
in the email archive, so the problem is not on your end, but I just 
wanted to mention that I was not (knowingly) ignoring you.

 > I have re-uploaded the cache.log files.

The files have expired again. I have reviewed the diff you shared, but 
cannot make further progress without those test logs. Hopefully, your 
next list post reaches me.

Alex.


> On 01/04/2024 11:53, Andre Bolinhas wrote:
>>
>> Hi Alex
>>
>> Thanks for your help on the matter.
>>
>>
>>> The logs archive you shared previously has expired, so I cannot 
>>> double check, but from what I remember, the shared logs did not 
>>> support the above assertion, so there may be more to the story here. 
>>> However, to make progress, let's assume that v5 configuration files 
>>> are identical to v6 configuration files. 
>> If you want, I can run the same test with in a different debug 
>> parameters, just tell which ones.
>>
>> I have re-uploaded the cache.log files.
>> https://we.tl/t-AB4XuUwuf7
>>
>>> One way to answer all of the above questions is to look at the 
>>> following output:
>>>
>>> ??? squid -k parse ... |& grep Processing:.http_access 
>> There is no diff between both squid version, you can check it here
>> DiffNow - Compare Files, URLs, and Clipboard Contents Online 
>> <https://www.diffnow.com/report/jsrva>
>>
>>> The logs archive you shared previously has expired, so I cannot 
>>> double check, but from what I remember, the shared logs did not 
>>> support the above assertion, so there may be more to the story here. 
>>> However, to make progress, let's assume that v5 configuration files 
>>> are identical to v6 configuration files.
>> The configuration files / folder are the same, the server is the same, 
>> the only thing that changes is the Squid version
>>
>> On 29/03/2024 17:40, Alex Rousskov wrote:
>>> On 2024-03-25 15:13, Bolinhas Andr? wrote:
>>>
>>>> Yes, the configuration is the same for both versions.
>>>
>>> The logs archive you shared previously has expired, so I cannot 
>>> double check, but from what I remember, the shared logs did not 
>>> support the above assertion, so there may be more to the story here. 
>>> However, to make progress, let's assume that v5 configuration files 
>>> are identical to v6 configuration files.
>>>
>>> 1. Is there an "http_access allow all AnnotateFinalAllow" rule?
>>>
>>> 2. Is there an "http_access deny HTTP Group38 AnnotateRule28" rule?
>>>
>>> 3. Assuming the answers are "yes" and "yes", which rule comes first? 
>>> If you use include files, this question applies to the imaginary 
>>> preprocessed squid.conf file with all the include files inlined 
>>> (recursively if needed). That kind of preprocessed configuration is 
>>> what Squid effectively sees when compiling http_access rules, one by 
>>> one. Which of the two rules will Squid see first?
>>>
>>> One way to answer all of the above questions is to look at the 
>>> following output:
>>>
>>> ??? squid -k parse ... |& grep Processing:.http_access
>>>
>>> Replace "..." with your regular squid startup command line options 
>>> and adjust standard error redirection (|&) as needed for your shell. 
>>> Run the above command for both Squid v5 and v6 binaries. You should 
>>> see output like this:
>>>
>>>
>>>> 2024/03/29 13:31:05| Processing: http_access allow manager
>>>> 2024/03/29 13:31:05| Processing: http_access deny all
>>>
>>>
>>> HTH,
>>>
>>> Alex.
>>>
>>>
>>>> ------------------------------------------------------------------------
>>>> *De:* Alex Rousskov <rousskov at measurement-factory.com>
>>>> *Enviado:* segunda-feira, 25 de mar?o de 2024 19:12
>>>> *Para:* squid-users at lists.squid-cache.org
>>>> *Assunto* Re: [squid-users] ACL / http_access rules stop work using 
>>>> Squid 6+
>>>>
>>>>
>>>>
>>>> On 2024-03-22 09:38, Andre Bolinhas wrote:
>>>>
>>>> ?> In previous versions of squid, from 3 to 5.9, I use this kind of 
>>>> deny
>>>> ?> rules and they work like charm
>>>> ?>
>>>> ?> acl AnnotateRule28 annotate_transaction accessrule=Rule28
>>>> ?> http_access deny HTTP Group38 AnnotateRule28
>>>> ?>
>>>> ?> This allows me to deny objects without bump / show the error page
>>>> ?> (deny_info)
>>>> ?>
>>>> ?> But using squid 6+ this rules stop to work and everything is 
>>>> allowed.
>>>> ?>
>>>> ?> Example:
>>>> ?> Squid 5.9 (OK)
>>>> ?> https://ibb.co/YdKgL1Y
>>>> ?>
>>>> ?> Squid 6.8 (NOK)
>>>> ?> https://ibb.co/tbyY2GV
>>>> ?>
>>>> ?> Sample of both cache.log in debug mode
>>>> ?>
>>>> ?> https://we.tl/t-T7Nz1rVbVu
>>>>
>>>>
>>>> In you v6 logs, most logged transactions are allowed because a rule
>>>> similar to the one reconstructed below is matching:
>>>>
>>>> ????? http_access allow all AnnotateFinalAllow
>>>>
>>>>
>>>> There are similar cases in v5 logs as well, but most denied v5
>>>> transactions match the following rule instead (i.e. the one you shared
>>>> above):
>>>>
>>>> ????? http_access deny HTTP Group38 AnnotateRule28
>>>>
>>>>
>>>> In your Squid configuration, v6 allow rule is listed much higher 
>>>> than v5
>>>> deny rule (#43 vs #149). I do not see any signs of Group38 or
>>>> AnnotateRule28 ACL evaluation in v6 logs, as if the rule sets are
>>>> different for two different Squid instances. Are you using the same set
>>>> of http_access rules for both Squid versions?
>>>>
>>>> Alex.
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From andre.bolinhas at articatech.com  Mon Apr 15 23:49:51 2024
From: andre.bolinhas at articatech.com (Andre Bolinhas)
Date: Tue, 16 Apr 2024 00:49:51 +0100
Subject: [squid-users] ACL / http_access rules stop work using Squid 6+
In-Reply-To: <01c18e16-e7f2-462e-9c55-3cf6adc33e84@measurement-factory.com>
References: <zarafa.6601cce9.6f7a.695ad7ca298a924d@ns413437.ip-37-187-142.eu>
 <9cd03f00-a87e-4c48-8a9c-61eb6751c0d9@measurement-factory.com>
 <ad81a226-e4dd-4748-a15f-746e2bf9a75b@articatech.com>
 <7e2d2ece-d58a-46af-890d-bb3801f392e8@articatech.com>
 <01c18e16-e7f2-462e-9c55-3cf6adc33e84@measurement-factory.com>
Message-ID: <5d0f2d73-e7c2-49b1-9550-2b89c78ac824@articatech.com>

Hi Alex,
Thnks for your reply.

Logs uploaded again, you can find it here.

https://we.tl/t-QiSKMgclOb

Best regards

On 15/04/2024 14:12, Alex Rousskov wrote:
> On 2024-04-14 17:23, Andre Bolinhas wrote:
>
>> Any tip on this matter? I want to upgrade to squid 6.9 but due to 
>> this issue, i'm stuck.
>
>
> Hi Andre,
>
> ??? Please note that I did _not_ receive your email quoted below. It 
> is in the email archive, so the problem is not on your end, but I just 
> wanted to mention that I was not (knowingly) ignoring you.
>
> > I have re-uploaded the cache.log files.
>
> The files have expired again. I have reviewed the diff you shared, but 
> cannot make further progress without those test logs. Hopefully, your 
> next list post reaches me.
>
> Alex.
>
>
>> On 01/04/2024 11:53, Andre Bolinhas wrote:
>>>
>>> Hi Alex
>>>
>>> Thanks for your help on the matter.
>>>
>>>
>>>> The logs archive you shared previously has expired, so I cannot 
>>>> double check, but from what I remember, the shared logs did not 
>>>> support the above assertion, so there may be more to the story 
>>>> here. However, to make progress, let's assume that v5 configuration 
>>>> files are identical to v6 configuration files. 
>>> If you want, I can run the same test with in a different debug 
>>> parameters, just tell which ones.
>>>
>>> I have re-uploaded the cache.log files.
>>> https://we.tl/t-AB4XuUwuf7
>>>
>>>> One way to answer all of the above questions is to look at the 
>>>> following output:
>>>>
>>>> ??? squid -k parse ... |& grep Processing:.http_access 
>>> There is no diff between both squid version, you can check it here
>>> DiffNow - Compare Files, URLs, and Clipboard Contents Online 
>>> <https://www.diffnow.com/report/jsrva>
>>>
>>>> The logs archive you shared previously has expired, so I cannot 
>>>> double check, but from what I remember, the shared logs did not 
>>>> support the above assertion, so there may be more to the story 
>>>> here. However, to make progress, let's assume that v5 configuration 
>>>> files are identical to v6 configuration files.
>>> The configuration files / folder are the same, the server is the 
>>> same, the only thing that changes is the Squid version
>>>
>>> On 29/03/2024 17:40, Alex Rousskov wrote:
>>>> On 2024-03-25 15:13, Bolinhas Andr? wrote:
>>>>
>>>>> Yes, the configuration is the same for both versions.
>>>>
>>>> The logs archive you shared previously has expired, so I cannot 
>>>> double check, but from what I remember, the shared logs did not 
>>>> support the above assertion, so there may be more to the story 
>>>> here. However, to make progress, let's assume that v5 configuration 
>>>> files are identical to v6 configuration files.
>>>>
>>>> 1. Is there an "http_access allow all AnnotateFinalAllow" rule?
>>>>
>>>> 2. Is there an "http_access deny HTTP Group38 AnnotateRule28" rule?
>>>>
>>>> 3. Assuming the answers are "yes" and "yes", which rule comes 
>>>> first? If you use include files, this question applies to the 
>>>> imaginary preprocessed squid.conf file with all the include files 
>>>> inlined (recursively if needed). That kind of preprocessed 
>>>> configuration is what Squid effectively sees when compiling 
>>>> http_access rules, one by one. Which of the two rules will Squid 
>>>> see first?
>>>>
>>>> One way to answer all of the above questions is to look at the 
>>>> following output:
>>>>
>>>> ??? squid -k parse ... |& grep Processing:.http_access
>>>>
>>>> Replace "..." with your regular squid startup command line options 
>>>> and adjust standard error redirection (|&) as needed for your 
>>>> shell. Run the above command for both Squid v5 and v6 binaries. You 
>>>> should see output like this:
>>>>
>>>>
>>>>> 2024/03/29 13:31:05| Processing: http_access allow manager
>>>>> 2024/03/29 13:31:05| Processing: http_access deny all
>>>>
>>>>
>>>> HTH,
>>>>
>>>> Alex.
>>>>
>>>>
>>>>> ------------------------------------------------------------------------ 
>>>>>
>>>>> *De:* Alex Rousskov <rousskov at measurement-factory.com>
>>>>> *Enviado:* segunda-feira, 25 de mar?o de 2024 19:12
>>>>> *Para:* squid-users at lists.squid-cache.org
>>>>> *Assunto* Re: [squid-users] ACL / http_access rules stop work 
>>>>> using Squid 6+
>>>>>
>>>>>
>>>>>
>>>>> On 2024-03-22 09:38, Andre Bolinhas wrote:
>>>>>
>>>>> ?> In previous versions of squid, from 3 to 5.9, I use this kind 
>>>>> of deny
>>>>> ?> rules and they work like charm
>>>>> ?>
>>>>> ?> acl AnnotateRule28 annotate_transaction accessrule=Rule28
>>>>> ?> http_access deny HTTP Group38 AnnotateRule28
>>>>> ?>
>>>>> ?> This allows me to deny objects without bump / show the error page
>>>>> ?> (deny_info)
>>>>> ?>
>>>>> ?> But using squid 6+ this rules stop to work and everything is 
>>>>> allowed.
>>>>> ?>
>>>>> ?> Example:
>>>>> ?> Squid 5.9 (OK)
>>>>> ?> https://ibb.co/YdKgL1Y
>>>>> ?>
>>>>> ?> Squid 6.8 (NOK)
>>>>> ?> https://ibb.co/tbyY2GV
>>>>> ?>
>>>>> ?> Sample of both cache.log in debug mode
>>>>> ?>
>>>>> ?> https://we.tl/t-T7Nz1rVbVu
>>>>>
>>>>>
>>>>> In you v6 logs, most logged transactions are allowed because a rule
>>>>> similar to the one reconstructed below is matching:
>>>>>
>>>>> ????? http_access allow all AnnotateFinalAllow
>>>>>
>>>>>
>>>>> There are similar cases in v5 logs as well, but most denied v5
>>>>> transactions match the following rule instead (i.e. the one you 
>>>>> shared
>>>>> above):
>>>>>
>>>>> ????? http_access deny HTTP Group38 AnnotateRule28
>>>>>
>>>>>
>>>>> In your Squid configuration, v6 allow rule is listed much higher 
>>>>> than v5
>>>>> deny rule (#43 vs #149). I do not see any signs of Group38 or
>>>>> AnnotateRule28 ACL evaluation in v6 logs, as if the rule sets are
>>>>> different for two different Squid instances. Are you using the 
>>>>> same set
>>>>> of http_access rules for both Squid versions?
>>>>>
>>>>> Alex.
>>>>>
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240416/4e85ae8b/attachment.htm>

From jonathanlee571 at gmail.com  Tue Apr 16 01:19:41 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 15 Apr 2024 18:19:41 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <d018d560-acb2-406e-895d-8446759f41e5@treenet.co.nz>
References: <FC75961E-4CB1-480F-A190-9915F0472FA4@gmail.com>
 <DA266AA1-8B27-44EF-B72C-BF7DF6AE3637@gmail.com>
 <d018d560-acb2-406e-895d-8446759f41e5@treenet.co.nz>
Message-ID: <2AC48652-519C-45A5-A66B-AD393B34C8B9@gmail.com>

Just to confirm

the cache_object://url scheme was removed in Squid 6.6 was it replaced with just squid-internal-mgr???

so squidclient mgr:info

can we still use this or no?

> On Apr 6, 2024, at 20:18, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 6/04/24 18:48, Jonathan Lee wrote:
>> Correction I can?t access it from the loop back
> 
> From the config in the other "Squid cache questions" thread you are only intercepting traffic on the loopback 127.0.0.1:3128 port. You cannot access it directly on "localhost".
> 
> You do have direct proxy (and thus manager) access via the 192.168.1.1:3128 so this URL should work:
>  http://192.168.1.1:3128/squid-internal-mgr/menu
> 
> 
> .. or substitute the raw-IP for the visible_hostname setting **if** that hostname actually resolves to that IP.
> 
> 
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240415/18d5950d/attachment.htm>

From gkinkie at gmail.com  Tue Apr 16 06:46:23 2024
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Tue, 16 Apr 2024 07:46:23 +0100
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <2AC48652-519C-45A5-A66B-AD393B34C8B9@gmail.com>
References: <FC75961E-4CB1-480F-A190-9915F0472FA4@gmail.com>
 <DA266AA1-8B27-44EF-B72C-BF7DF6AE3637@gmail.com>
 <d018d560-acb2-406e-895d-8446759f41e5@treenet.co.nz>
 <2AC48652-519C-45A5-A66B-AD393B34C8B9@gmail.com>
Message-ID: <CA+Y8hcNMmynwq2J9pi=jfFRi-LiQrcUHfxfHCLTady957xjpUg@mail.gmail.com>

On Tue, Apr 16, 2024 at 2:20?AM Jonathan Lee <jonathanlee571 at gmail.com>
wrote:

> Just to confirm
>
> the cache_object://url scheme was removed in Squid 6.6 was it replaced
> with just squid-internal-mgr???
>

Hi,
  yes, that's it. In addition, squidclient is no longer built or
distributed with Squid, since any web browser can do the
job just as well if not better.
For Squid 7, I am in the process of converting the output of cache manager
reports to yaml, to allow using even more widely available tools.


>
> so squidclient mgr:info
>
> can we still use this or no?
>
> On Apr 6, 2024, at 20:18, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>
> On 6/04/24 18:48, Jonathan Lee wrote:
>
> Correction I can?t access it from the loop back
>
>
> From the config in the other "Squid cache questions" thread you are only
> intercepting traffic on the loopback 127.0.0.1:3128 port. You cannot
> access it directly on "localhost".
>
> You do have direct proxy (and thus manager) access via the
> 192.168.1.1:3128 so this URL should work:
>  http://192.168.1.1:3128/squid-internal-mgr/menu
>
>
> .. or substitute the raw-IP for the visible_hostname setting **if** that
> hostname actually resolves to that IP.
>
>
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>


-- 
    Francesco
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240416/eb310df7/attachment.htm>

From numsys at free.fr  Tue Apr 16 07:20:39 2024
From: numsys at free.fr (FredB)
Date: Tue, 16 Apr 2024 09:20:39 +0200
Subject: [squid-users] Rock store limit
Message-ID: <538c3378-645a-4a1e-9dcb-bf6f1aa750c5@free.fr>

Hello,

I'm trying to use rock store with 6.9, there is a limitation about the 
size of cache ? I tried 15000 but there is no rock db created with squid 
-z but it works with 1000
My goal is using a 200G SSD disk

cache_dir rock /cache 1000 max-swap-rate=250 swap-timeout=350


Thanks



From rousskov at measurement-factory.com  Tue Apr 16 16:07:59 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 16 Apr 2024 12:07:59 -0400
Subject: [squid-users] Rock store limit
In-Reply-To: <538c3378-645a-4a1e-9dcb-bf6f1aa750c5@free.fr>
References: <538c3378-645a-4a1e-9dcb-bf6f1aa750c5@free.fr>
Message-ID: <0e93c156-c721-4476-baf1-4e3fc567b26f@measurement-factory.com>

On 2024-04-16 03:20, FredB wrote:

> I'm trying to use rock store with 6.9, there is a limitation about the 
> size of cache ?

If my calculations are correct, all cache_dirs share the same byte-size 
limit: A single cache_dir cannot store more than ~2048 terabytes (i.e. 
2^51 bytes).

However, all cache_dir types are also limited by factors other than the 
total size. For example, each cache_dir cannot store more than 
16'777'215 entries (2^24-1).

IIRC, rock cache_dirs also cannot have more than 2'147'483'648 slots 
(2^31). See cache_dir rock ... slot-size=bytes documentation for more 
info regarding rock slots.

Rock cache_dirs are also limited by the maximum shared memory segment 
size. A cache_dir index maintains an index in shared memory. That index 
has three components. Each component must fit into a dedicated shared 
memory segment (your OS configuration limits the size of that segment):

* index component A:  4 bytes per cache_dir entry
* index component B: 96 bytes per cache_dir entry
* index component C:  8 bytes per cache_dir slot


> I tried 15000 but there is no rock db created with squid -z

What error do you get from Squid? Please note that Squid may be limited 
by the maximum shared memory segment size or some other limit.


> My goal is using a 200G SSD disk

With default store_avg_object_size of 13KB, the 16'777'215 entry limit 
implies the maximum cache_dir size of ~208G, but, again, there are other 
limits.


Please also note that large rock cache_dirs will take a long time to be 
indexed on Squid startup. Rock indexing is usually done in background, 
but it is still a significant performance expense. Optimizing indexing 
is an old item on our to-do list.


HTH,

Alex.


> cache_dir rock /cache 1000 max-swap-rate=250 swap-timeout=350



From Mario.Rauch at dieboldnixdorf.com  Wed Apr 17 13:07:03 2024
From: Mario.Rauch at dieboldnixdorf.com (Rauch, Mario)
Date: Wed, 17 Apr 2024 13:07:03 +0000
Subject: [squid-users] Squid 6.8 SSL_BUMP TLS Error
In-Reply-To: <GV1PR10MB61001028A9E7DFD57691E95583342@GV1PR10MB6100.EURPRD10.PROD.OUTLOOK.COM>
References: <GV1PR10MB61001028A9E7DFD57691E95583342@GV1PR10MB6100.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <GV1PR10MB61007F6BA3DD2209734EDAE4830F2@GV1PR10MB6100.EURPRD10.PROD.OUTLOOK.COM>

Hi,
hope somebody has a hint. We are receiving following errors when clients want to connect to specific website using ssl bump feature and self signed certificate:

2024/04/17 14:55:15 kid1| ERROR: failure while accepting a TLS connection on conn275 local=185.229.91.169:3128 remote=81.217.86.125:63673 FD 16 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
    current master transaction: master53

Does somebody know what the problem could be?

With old Squid 3.5 it worked with almost same config and certificate.

Regards,
Mario
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240417/2d862ab4/attachment.htm>

From rousskov at measurement-factory.com  Wed Apr 17 17:52:36 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 17 Apr 2024 13:52:36 -0400
Subject: [squid-users] Squid 6.8 SSL_BUMP TLS Error
In-Reply-To: <GV1PR10MB61007F6BA3DD2209734EDAE4830F2@GV1PR10MB6100.EURPRD10.PROD.OUTLOOK.COM>
References: <GV1PR10MB61001028A9E7DFD57691E95583342@GV1PR10MB6100.EURPRD10.PROD.OUTLOOK.COM>
 <GV1PR10MB61007F6BA3DD2209734EDAE4830F2@GV1PR10MB6100.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <c7a42ced-0598-40f9-8530-c6b85c3c3905@measurement-factory.com>

On 2024-04-17 09:07, Rauch, Mario wrote:

> We are receiving following errors when clients 
> want to connect to specific website using ssl bump feature and self 
> signed certificate:
> 
> 2024/04/17 14:55:15 kid1| ERROR: failure while accepting a TLS 
> connection on conn275 local=185.229.91.169:3128 
> remote=81.217.86.125:63673 FD 16 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 
> Does somebody know what the problem could be?

$ openssl errstr A000418
error:0A000418:SSL routines::tlsv1 alert unknown ca

Looks like the client does not trust Squid certificate and tells Squid 
about that lack of trust via a TLS alert. Did you configure the client 
to trust the certificate your Squid is using for bumping client connections?


HTH,

Alex.


> With old Squid 3.5 it worked with almost same config and certificate.




From mogi at oce.co.jp  Wed Apr 17 23:45:15 2024
From: mogi at oce.co.jp (=?iso-2022-jp?B?GyRCTFBMWhsoQiAgGyRCTklKPxsoQg==?=)
Date: Wed, 17 Apr 2024 23:45:15 +0000
Subject: [squid-users] "No buffer space available" is output to cache.log
Message-ID: <3997db5d82d14c8d93264d40fc27b2ff@oce.co.jp>

Hello everyone



Iam using Squid on Windows Server 2019.

There are times when I cannot connect to the internet, and upon checking the cache.log file, I found the following error:

"comm_openex socket failure: (105) No buffer space available"

While searching the internet, I found a few potential solutions:

  1.  Modify the cache settings in squid.conf: cache_dir ufs c:/squid/var/cache 100 16 256
  2.  Registry modification: Create a DWORD key named TcpNumConnections under HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters and set the value to 800.
  3.  Add the following lines to the squid.conf to apply bandwidth limiting:

delay_pools 1

delay_class 1 1

delay_access 1

allow all delay_parameters 1 500000/500000

Is this an issue with the operating system or with Squid?

If anyone has more information, please let me know.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240417/5cf2362e/attachment.htm>

From Mario.Rauch at dieboldnixdorf.com  Thu Apr 18 08:13:37 2024
From: Mario.Rauch at dieboldnixdorf.com (Rauch, Mario)
Date: Thu, 18 Apr 2024 08:13:37 +0000
Subject: [squid-users] Squid 6.8 SSL_BUMP TLS Error
In-Reply-To: <c7a42ced-0598-40f9-8530-c6b85c3c3905@measurement-factory.com>
References: <GV1PR10MB61001028A9E7DFD57691E95583342@GV1PR10MB6100.EURPRD10.PROD.OUTLOOK.COM>
 <GV1PR10MB61007F6BA3DD2209734EDAE4830F2@GV1PR10MB6100.EURPRD10.PROD.OUTLOOK.COM>
 <c7a42ced-0598-40f9-8530-c6b85c3c3905@measurement-factory.com>
Message-ID: <GV1PR10MB6100F04F28BCE1B10D82827E830E2@GV1PR10MB6100.EURPRD10.PROD.OUTLOOK.COM>

Hello,
We have created a DER version of the PEM certificate which Squid uses and imported this into client certificate store using script like this:
certmgr /add DN_SIGNATOR_CA.der /r localMachine /s root

DN_SIGNATOR_CA.der is the self signed certificate

Maybe there must be some additional or changed setting in config from 3.5 > 6.8 Squid version?
As I wrote on old server with Squid 3.5 and same certificate it worked. Should I attach both config files?

Regards,
Mario

Von: squid-users <squid-users-bounces at lists.squid-cache.org> Im Auftrag von Alex Rousskov
Gesendet: Mittwoch, 17. April 2024 19:53
An: squid-users at lists.squid-cache.org
Betreff: Re: [squid-users] Squid 6.8 SSL_BUMP TLS Error

On 2024-04-17 09:?07, Rauch, Mario wrote: > We are receiving following errors when clients > want to connect to specific website using ssl bump feature and self > signed certificate: > > 2024/04/17 14:?55:?15 kid1| ERROR: failure


On 2024-04-17 09:07, Rauch, Mario wrote:



> We are receiving following errors when clients

> want to connect to specific website using ssl bump feature and self

> signed certificate:

>

> 2024/04/17 14:55:15 kid1| ERROR: failure while accepting a TLS

> connection on conn275 local=185.229.91.169:3128

> remote=81.217.86.125:63673 FD 16 flags=1:

> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1

>

> Does somebody know what the problem could be?



$ openssl errstr A000418

error:0A000418:SSL routines::tlsv1 alert unknown ca



Looks like the client does not trust Squid certificate and tells Squid

about that lack of trust via a TLS alert. Did you configure the client

to trust the certificate your Squid is using for bumping client connections?





HTH,



Alex.





> With old Squid 3.5 it worked with almost same config and certificate.





_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

https://urldefense.com/v3/__https://lists.squid-cache.org/listinfo/squid-users__;!!Gb9UCRAl!8v8DHhzXtUPSxAheCy_Rh2E-Sywz_Z-_afBDDwJUCCJ0ojG5KeBK_73nBnc3Uo6bz9cIuzHlHwrxDZNznVMO1E0k3oPcDpH5ysNH$<https://urldefense.com/v3/__https:/lists.squid-cache.org/listinfo/squid-users__;!!Gb9UCRAl!8v8DHhzXtUPSxAheCy_Rh2E-Sywz_Z-_afBDDwJUCCJ0ojG5KeBK_73nBnc3Uo6bz9cIuzHlHwrxDZNznVMO1E0k3oPcDpH5ysNH$>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240418/e726b780/attachment.htm>

From Albert.Shih at obspm.fr  Thu Apr 18 17:08:46 2024
From: Albert.Shih at obspm.fr (Albert Shih)
Date: Thu, 18 Apr 2024 19:08:46 +0200
Subject: [squid-users] squid acl + user through ssh
Message-ID: <ZiFTngw1s4amUIul@io.chezmoi.fr>

Hi everyone

If a user use a ssh tunnel to access to squid like

  ssh -L 3128:squid_server:3128 ssh-portal 

then configure his browser to use 127.0.0.1:3128 to access the squid proxy
is they are a way to use ?acl by user? in the squid configuration ? 

Thanks

-- 
Albert SHIH ? ?
France
Heure locale/Local time:
jeu. 18 avril 2024 19:06:02 CEST


From gkinkie at gmail.com  Thu Apr 18 17:13:41 2024
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Thu, 18 Apr 2024 18:13:41 +0100
Subject: [squid-users] squid acl + user through ssh
In-Reply-To: <ZiFTngw1s4amUIul@io.chezmoi.fr>
References: <ZiFTngw1s4amUIul@io.chezmoi.fr>
Message-ID: <CA+Y8hcP1Ew=iLpM_60QpNPJdotC9RDQAfWTAa=JTrVPM1c6YjQ@mail.gmail.com>

Sure, of course. It will work just as normal.
The only type of ACLs that would need to be considered is source-based


@mobile


On Thu, 18 Apr 2024 at 18:09, Albert Shih <Albert.Shih at obspm.fr> wrote:

> Hi everyone
>
> If a user use a ssh tunnel to access to squid like
>
>   ssh -L 3128:squid_server:3128 ssh-portal
>
> then configure his browser to use 127.0.0.1:3128 to access the squid proxy
> is they are a way to use ?acl by user? in the squid configuration ?
>
> Thanks
>
> --
> Albert SHIH ? ?
> France
> Heure locale/Local time:
> jeu. 18 avril 2024 19:06:02 CEST
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240418/9f5eff67/attachment.htm>

From Albert.Shih at obspm.fr  Thu Apr 18 19:46:13 2024
From: Albert.Shih at obspm.fr (Albert Shih)
Date: Thu, 18 Apr 2024 21:46:13 +0200
Subject: [squid-users] squid acl + user through ssh
In-Reply-To: <CA+Y8hcP1Ew=iLpM_60QpNPJdotC9RDQAfWTAa=JTrVPM1c6YjQ@mail.gmail.com>
References: <ZiFTngw1s4amUIul@io.chezmoi.fr>
 <CA+Y8hcP1Ew=iLpM_60QpNPJdotC9RDQAfWTAa=JTrVPM1c6YjQ@mail.gmail.com>
Message-ID: <ZiF4hYvFddrhvNCi@io.chezmoi.fr>

Le 18/04/2024 ? 18:13:41+0100, Francesco Chemolli a ?crit
Hi, 

> Sure, of course. It will work just as normal.
> The only type of ACLs that would need to be considered is source-based

Ok, thanks, but just to be sure, because re-reading myself I was not very clear
about my question. 

So what I'm trying to do is to use ACL according to the user who make the
ssh connection, I don't want ?another? authentication. 

So let's say 

  ssh -L 3128:squid_server:3128 user1 at ssh-portal 

the squid will match

    acl aclforuser1 ident user1

and

  ssh -L 3128:squid_server:3128 user2 at ssh-portal

the squid will match

    acl aclforuser2 ident user2


Thanks. 

-- 
Albert SHIH ? ?
France
Heure locale/Local time:
jeu. 18 avril 2024 21:40:33 CEST


From rousskov at measurement-factory.com  Thu Apr 18 21:16:39 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 18 Apr 2024 17:16:39 -0400
Subject: [squid-users] Squid 6.8 SSL_BUMP TLS Error
In-Reply-To: <GV1PR10MB6100F04F28BCE1B10D82827E830E2@GV1PR10MB6100.EURPRD10.PROD.OUTLOOK.COM>
References: <GV1PR10MB61001028A9E7DFD57691E95583342@GV1PR10MB6100.EURPRD10.PROD.OUTLOOK.COM>
 <GV1PR10MB61007F6BA3DD2209734EDAE4830F2@GV1PR10MB6100.EURPRD10.PROD.OUTLOOK.COM>
 <c7a42ced-0598-40f9-8530-c6b85c3c3905@measurement-factory.com>
 <GV1PR10MB6100F04F28BCE1B10D82827E830E2@GV1PR10MB6100.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <915a220d-d7eb-49b3-8247-12f5966e3c77@measurement-factory.com>

On 2024-04-18 04:13, Rauch, Mario wrote:

> We have created a DER version of the PEM certificate which Squid uses 
> and imported this into client certificate store using script like this:
> 
> certmgr /add DN_SIGNATOR_CA.der /r localMachine /s root
> 
> DN_SIGNATOR_CA.der is the self signed certificate

There is no practical way for me to verify that the above steps have the 
desired result. However, _you_ can verify that by, for example, using 
OpenSSL s_server configured with a certificate signed by DN_SIGNATOR_CA. 
Does the client trust that test server?

Can you verify that your client is getting a certificate signed by 
DN_SIGNATOR_CA? Depending on TLS version, it may be possible to do that 
using Wireshark or a similar packet capture analysis tool. If you can 
run OpenSSL s_client or a similar test client, it can also tell you what 
certificate(s) it is getting from Squid.


> Maybe there must be some additional or changed setting in config from 
> 3.5 > 6.8 Squid version?

Lots of things changed since Squid v3. Others may be able to guide you 
through those changes, but I cannot. That is why I am focusing on 
solving your problem in v6 (rather than trying to figure out what change 
triggered that problem).


> As I wrote on old server with Squid 3.5 and same certificate it worked. 
> Should I attach both config files?

Personally, I am not interested in Squid v3 configuration. Seeing your 
ssl_bump rules for v6 may be useful (especially if you know for sure 
which rules have matched for the test transaction), but I would _start_ 
by checking that Squid is sending the certificate(s) you think it is 
sending.


HTH,

Alex.


> *Von:*squid-users <squid-users-bounces at lists.squid-cache.org> *Im 
> Auftrag von *Alex Rousskov
> *Gesendet:* Mittwoch, 17. April 2024 19:53
> *An:* squid-users at lists.squid-cache.org
> *Betreff:* Re: [squid-users] Squid 6.8 SSL_BUMP TLS Error
> 
> On 2024-04-17 09:?07, Rauch, Mario wrote: > We are receiving following 
> errors when clients > want to connect to specific website using ssl bump 
> feature and self > signed certificate: > > 2024/04/17 14:?55:?15 kid1| 
> ERROR: failure
> 
> On 2024-04-17 09:07, Rauch, Mario wrote:
> 
>> We are receiving following errors when clients 
> 
>> want to connect to specific website using ssl bump feature and self 
> 
>> signed certificate:
> 
>> 
> 
>> 2024/04/17 14:55:15 kid1| ERROR: failure while accepting a TLS 
> 
>> connection on conn275 local=185.229.91.169:3128 
> 
>> remote=81.217.86.125:63673 FD 16 flags=1: 
> 
>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 
>> 
> 
>> Does somebody know what the problem could be?
> 
> $ openssl errstr A000418
> 
> error:0A000418:SSL routines::tlsv1 alert unknown ca
> 
> Looks like the client does not trust Squid certificate and tells Squid
> 
> about that lack of trust via a TLS alert. Did you configure the client
> 
> to trust the certificate your Squid is using for bumping client connections?
> 
> HTH,
> 
> Alex.
> 
>> With old Squid 3.5 it worked with almost same config and certificate.
> 
> _______________________________________________
> 
> squid-users mailing list
> 
> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
> 
> https://urldefense.com/v3/__https://lists.squid-cache.org/listinfo/squid-users__;!!Gb9UCRAl!8v8DHhzXtUPSxAheCy_Rh2E-Sywz_Z-_afBDDwJUCCJ0ojG5KeBK_73nBnc3Uo6bz9cIuzHlHwrxDZNznVMO1E0k3oPcDpH5ysNH$ <https://urldefense.com/v3/__https:/lists.squid-cache.org/listinfo/squid-users__;!!Gb9UCRAl!8v8DHhzXtUPSxAheCy_Rh2E-Sywz_Z-_afBDDwJUCCJ0ojG5KeBK_73nBnc3Uo6bz9cIuzHlHwrxDZNznVMO1E0k3oPcDpH5ysNH$>
> 



From gtaylor at tnetconsulting.net  Thu Apr 18 23:42:57 2024
From: gtaylor at tnetconsulting.net (Grant Taylor)
Date: Thu, 18 Apr 2024 18:42:57 -0500
Subject: [squid-users] squid acl + user through ssh
In-Reply-To: <ZiF4hYvFddrhvNCi@io.chezmoi.fr>
References: <ZiFTngw1s4amUIul@io.chezmoi.fr>
 <CA+Y8hcP1Ew=iLpM_60QpNPJdotC9RDQAfWTAa=JTrVPM1c6YjQ@mail.gmail.com>
 <ZiF4hYvFddrhvNCi@io.chezmoi.fr>
Message-ID: <cb61ade0-24d5-700e-a10c-ca7513f32b77@tnetconsulting.net>

On 4/18/24 2:46?PM, Albert Shih wrote:
> So what I'm trying to do is to use ACL according to the user who make 
> the ssh connection, I don't want ?another? authentication.

About the only thing that comes to mind is RFC 931 (?) ident (might be 
okay on the same system) or something that matches the process owner. 
(I'm thinking iptables process owner match extension.)

But my testing seems to show that such port forwarding is done by the 
ssh daemon owner process not the connecting user.

If it wasn't for your "don't want another authentication" I'd wonder 
about username and password creds to authenticate to Squid.



-- 
Grant. . . .
unix || die



From rousskov at measurement-factory.com  Fri Apr 19 04:04:41 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 19 Apr 2024 00:04:41 -0400
Subject: [squid-users] ACL / http_access rules stop work using Squid 6+
In-Reply-To: <5d0f2d73-e7c2-49b1-9550-2b89c78ac824@articatech.com>
References: <zarafa.6601cce9.6f7a.695ad7ca298a924d@ns413437.ip-37-187-142.eu>
 <9cd03f00-a87e-4c48-8a9c-61eb6751c0d9@measurement-factory.com>
 <ad81a226-e4dd-4748-a15f-746e2bf9a75b@articatech.com>
 <7e2d2ece-d58a-46af-890d-bb3801f392e8@articatech.com>
 <01c18e16-e7f2-462e-9c55-3cf6adc33e84@measurement-factory.com>
 <5d0f2d73-e7c2-49b1-9550-2b89c78ac824@articatech.com>
Message-ID: <a5256abe-70d9-4380-ac68-c48e5087e91a@measurement-factory.com>

Hi Andre,

     I did not receive your new reply, but I did find it in the mailing 
list archives in time to download the logs. Thank you for sharing them! 
FWIW, you may want to CC me in future emails (but I do not know whether 
that will help).


Something really strange is going on. Squid runtime logs (both versions) 
do not match the two identical "squid -k parse" logs you have shared 
earlier. For example, at runtime, Squid v5 checks the following rules, 
in this order:

1. http_access ... ArticaTSTSite ...
2. http_access ... NoCacheMGR ...
3. http_access ... LocalClient ...
4. http_access ... MyIPSrc ...
5. http_access ... internal_icons ...
6. http_access ... MgrInfoUri ...

The first 10 rules in "squid -k parse" output are different! I pasted 
them below and marked those that are missing in runtime output:

1. http_access deny ArticaTSTSite ArticaTSTSiteAll
2. http_access allow NoCacheMGR ToArticaWWW
3. http_access allow LocalClient NoCacheMGR
4. http_access allow MyIPSrc NoCacheMGR
5. http_access allow internal_icons
6. Missing: http_access allow internal_icons
7. Missing: http_access deny NormalPorts to_localhost  CVEFix all
8. Missing: http_access deny NormalPorts manager  ManagerDeny all
9. Missing: http_access allow MgRPort manager all
10. http_access allow MgRPort MgrInfoUri all

The differences continue...

N.B. Rules 5 and 6 in parsing logs are the same, but Squid does not know 
that (yet?). Squid will parse, consume, and evaluate both (if they are 
reached and do not match). In runtime logs, Squid v5 only evaluates the 
first one (#5) and then goes to a MgrInfoUri rule that is listed as #6 
in Squid v5 runtime logs and as #10 in parse logs, skipping four rules.

Runtime logs do not contain just the ACL names. They also contain rule 
numbers assigned at parsing time. The number should be incremented for 
every http_access rule Squid parses. Those numbers do not match "squid 
-k parse" output, reflecting the same "missing rules" problem, and 
elevating my confidence that other rules are missing at runtime.


Squid v6 runtime logs show the same problem, but the differences start 
later (and are more profound). For example, Squid v6 logs do not show 
Group212 ACL being evaluated (rule #151 in parse logs) but do show 
AnnotateFinalAllow ACL evaluated (rule #168 in parse logs and rule #43 
in v6 runtime logs). Group98 (rule #116 in parse logs) is also missing 
from v6 runtime logs.


Parsing logs show 168 http_access rules.
Running Squid v5 appears to have 163 http_access rules.
Running Squid v6 appears to have 43 http_access rules!

Bugs notwithstanding, Squid does not "skip" http_access rules that it 
successfully parsed/consumed at startup or reconfiguration. Squid does 
not evaluate higher-numbered rules after a rule matches, but that is not 
what it happening here: For example, I see sequences where Squid v6 
checks 43 rules from the first (in all logs) ArticaTSTSite rule to the 
last (in all logs) AnnotateFinalAllow rule; the other 125 rules (seen in 
"squid -k parse" logs) appear to be "missing" from v6 runtime logs.


I speculate that one of these things have happened (in no particular order):

A. I am confused by these partial logs.


B. Squid failed to parse/consume some http_access rules in your 
configuration files. The set of rules Squid failed to parse differs 
across v5 and v6. The logs do not detail parsing, so I cannot validate 
this theory, but it would explain the missing rules. In the vast 
majority of cases, there ought to be at least some level-0/1 cache.log 
errors or warnings about failing to parse/consume an http_access rule!

One way to validate this theory is to compare "squid -k parse" output 
with http_access lines in mgr:config cache manager report received from 
a running Squid instance. You may need to modify squid.conf to allow 
that cache manager query (see cachemgr_passwd). Squids, especially older 
ones, have various bugs in mgr:config output so a manual comparison may 
be needed.

Another way is to study "squid -k parse -X -d9" output that should have 
more details for Squid v6. This is similar to the trick in (D) below, 
but without runtime debugging.


C. Your "squid -k parse" commands do not match the actual configurations 
that Squids are parsing and then using at runtime. The same mgr:config 
trick from (B) above can be used to validate this theory.


D. Both Squids are suffering from some serious bug. The effects of that 
bug result in different actual/used http_access rule sets in each version.

One way to confirm theory D is to study ALL,9 logs collected from Squid 
v6 with "squid ... -X -d9" command line option (or a similar trick that 
will include initial parsing in the log). The logs should detail at 
least one transaction that should evaluate most http_access rules. Such 
logs will address concern (A) as well, but you will probably have to 
share them privately if you are using production configuration/instance.


HTH,

Alex.


On 2024-04-15 19:49, Andre Bolinhas wrote:
> Hi Alex,
> Thnks for your reply.
> 
> Logs uploaded again, you can find it here.
> 
> https://we.tl/t-QiSKMgclOb
> 
> Best regards
> 
> On 15/04/2024 14:12, Alex Rousskov wrote:
>> On 2024-04-14 17:23, Andre Bolinhas wrote:
>>
>>> Any tip on this matter? I want to upgrade to squid 6.9 but due to 
>>> this issue, i'm stuck.
>>
>>
>> Hi Andre,
>>
>> ??? Please note that I did _not_ receive your email quoted below. It 
>> is in the email archive, so the problem is not on your end, but I just 
>> wanted to mention that I was not (knowingly) ignoring you.
>>
>> > I have re-uploaded the cache.log files.
>>
>> The files have expired again. I have reviewed the diff you shared, but 
>> cannot make further progress without those test logs. Hopefully, your 
>> next list post reaches me.
>>
>> Alex.
>>
>>
>>> On 01/04/2024 11:53, Andre Bolinhas wrote:
>>>>
>>>> Hi Alex
>>>>
>>>> Thanks for your help on the matter.
>>>>
>>>>
>>>>> The logs archive you shared previously has expired, so I cannot 
>>>>> double check, but from what I remember, the shared logs did not 
>>>>> support the above assertion, so there may be more to the story 
>>>>> here. However, to make progress, let's assume that v5 configuration 
>>>>> files are identical to v6 configuration files. 
>>>> If you want, I can run the same test with in a different debug 
>>>> parameters, just tell which ones.
>>>>
>>>> I have re-uploaded the cache.log files.
>>>> https://we.tl/t-AB4XuUwuf7
>>>>
>>>>> One way to answer all of the above questions is to look at the 
>>>>> following output:
>>>>>
>>>>> ??? squid -k parse ... |& grep Processing:.http_access 
>>>> There is no diff between both squid version, you can check it here
>>>> DiffNow - Compare Files, URLs, and Clipboard Contents Online 
>>>> <https://www.diffnow.com/report/jsrva>
>>>>
>>>>> The logs archive you shared previously has expired, so I cannot 
>>>>> double check, but from what I remember, the shared logs did not 
>>>>> support the above assertion, so there may be more to the story 
>>>>> here. However, to make progress, let's assume that v5 configuration 
>>>>> files are identical to v6 configuration files.
>>>> The configuration files / folder are the same, the server is the 
>>>> same, the only thing that changes is the Squid version
>>>>
>>>> On 29/03/2024 17:40, Alex Rousskov wrote:
>>>>> On 2024-03-25 15:13, Bolinhas Andr? wrote:
>>>>>
>>>>>> Yes, the configuration is the same for both versions.
>>>>>
>>>>> The logs archive you shared previously has expired, so I cannot 
>>>>> double check, but from what I remember, the shared logs did not 
>>>>> support the above assertion, so there may be more to the story 
>>>>> here. However, to make progress, let's assume that v5 configuration 
>>>>> files are identical to v6 configuration files.
>>>>>
>>>>> 1. Is there an "http_access allow all AnnotateFinalAllow" rule?
>>>>>
>>>>> 2. Is there an "http_access deny HTTP Group38 AnnotateRule28" rule?
>>>>>
>>>>> 3. Assuming the answers are "yes" and "yes", which rule comes 
>>>>> first? If you use include files, this question applies to the 
>>>>> imaginary preprocessed squid.conf file with all the include files 
>>>>> inlined (recursively if needed). That kind of preprocessed 
>>>>> configuration is what Squid effectively sees when compiling 
>>>>> http_access rules, one by one. Which of the two rules will Squid 
>>>>> see first?
>>>>>
>>>>> One way to answer all of the above questions is to look at the 
>>>>> following output:
>>>>>
>>>>> ??? squid -k parse ... |& grep Processing:.http_access
>>>>>
>>>>> Replace "..." with your regular squid startup command line options 
>>>>> and adjust standard error redirection (|&) as needed for your 
>>>>> shell. Run the above command for both Squid v5 and v6 binaries. You 
>>>>> should see output like this:
>>>>>
>>>>>
>>>>>> 2024/03/29 13:31:05| Processing: http_access allow manager
>>>>>> 2024/03/29 13:31:05| Processing: http_access deny all
>>>>>
>>>>>
>>>>> HTH,
>>>>>
>>>>> Alex.
>>>>>
>>>>>
>>>>>> ------------------------------------------------------------------------
>>>>>> *De:* Alex Rousskov <rousskov at measurement-factory.com>
>>>>>> *Enviado:* segunda-feira, 25 de mar?o de 2024 19:12
>>>>>> *Para:* squid-users at lists.squid-cache.org
>>>>>> *Assunto* Re: [squid-users] ACL / http_access rules stop work 
>>>>>> using Squid 6+
>>>>>>
>>>>>>
>>>>>>
>>>>>> On 2024-03-22 09:38, Andre Bolinhas wrote:
>>>>>>
>>>>>> ?> In previous versions of squid, from 3 to 5.9, I use this kind 
>>>>>> of deny
>>>>>> ?> rules and they work like charm
>>>>>> ?>
>>>>>> ?> acl AnnotateRule28 annotate_transaction accessrule=Rule28
>>>>>> ?> http_access deny HTTP Group38 AnnotateRule28
>>>>>> ?>
>>>>>> ?> This allows me to deny objects without bump / show the error page
>>>>>> ?> (deny_info)
>>>>>> ?>
>>>>>> ?> But using squid 6+ this rules stop to work and everything is 
>>>>>> allowed.
>>>>>> ?>
>>>>>> ?> Example:
>>>>>> ?> Squid 5.9 (OK)
>>>>>> ?> https://ibb.co/YdKgL1Y
>>>>>> ?>
>>>>>> ?> Squid 6.8 (NOK)
>>>>>> ?> https://ibb.co/tbyY2GV
>>>>>> ?>
>>>>>> ?> Sample of both cache.log in debug mode
>>>>>> ?>
>>>>>> ?> https://we.tl/t-T7Nz1rVbVu
>>>>>>
>>>>>>
>>>>>> In you v6 logs, most logged transactions are allowed because a rule
>>>>>> similar to the one reconstructed below is matching:
>>>>>>
>>>>>> ????? http_access allow all AnnotateFinalAllow
>>>>>>
>>>>>>
>>>>>> There are similar cases in v5 logs as well, but most denied v5
>>>>>> transactions match the following rule instead (i.e. the one you 
>>>>>> shared
>>>>>> above):
>>>>>>
>>>>>> ????? http_access deny HTTP Group38 AnnotateRule28
>>>>>>
>>>>>>
>>>>>> In your Squid configuration, v6 allow rule is listed much higher 
>>>>>> than v5
>>>>>> deny rule (#43 vs #149). I do not see any signs of Group38 or
>>>>>> AnnotateRule28 ACL evaluation in v6 logs, as if the rule sets are
>>>>>> different for two different Squid instances. Are you using the 
>>>>>> same set
>>>>>> of http_access rules for both Squid versions?
>>>>>>
>>>>>> Alex.
>>>>>>
>>>>>> _______________________________________________
>>>>>> squid-users mailing list
>>>>>> squid-users at lists.squid-cache.org
>>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>>>
>>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>>



From Albert.Shih at obspm.fr  Fri Apr 19 06:06:08 2024
From: Albert.Shih at obspm.fr (Albert Shih)
Date: Fri, 19 Apr 2024 08:06:08 +0200
Subject: [squid-users] squid acl + user through ssh
In-Reply-To: <cb61ade0-24d5-700e-a10c-ca7513f32b77@tnetconsulting.net>
References: <ZiFTngw1s4amUIul@io.chezmoi.fr>
 <CA+Y8hcP1Ew=iLpM_60QpNPJdotC9RDQAfWTAa=JTrVPM1c6YjQ@mail.gmail.com>
 <ZiF4hYvFddrhvNCi@io.chezmoi.fr>
 <cb61ade0-24d5-700e-a10c-ca7513f32b77@tnetconsulting.net>
Message-ID: <ZiIJ0AD19yCNUKJr@io.chezmoi.fr>

Le 18/04/2024 ? 18:42:57-0500, Grant Taylor a ?crit
> On 4/18/24 2:46?PM, Albert Shih wrote:
> > So what I'm trying to do is to use ACL according to the user who make
> > the ssh connection, I don't want ?another? authentication.
> 
> About the only thing that comes to mind is RFC 931 (?) ident (might be okay
> on the same system) or something that matches the process owner. (I'm
> thinking iptables process owner match extension.)
> 
> But my testing seems to show that such port forwarding is done by the ssh
> daemon owner process not the connecting user.

Yes. Indeed. 
> 
> If it wasn't for your "don't want another authentication" I'd wonder about
> username and password creds to authenticate to Squid.

Well....It's not me who don't want another authentication, it's the
application (not a web browser) who only know (and I'm not sure of that
yet) how to do a basic http authentication. 

Regards

-- 
Albert SHIH ? ?
France
Heure locale/Local time:
ven. 19 avril 2024 07:58:44 CEST


From jonathanlee571 at gmail.com  Fri Apr 19 06:55:28 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 18 Apr 2024 23:55:28 -0700
Subject: [squid-users] Warm cold times
Message-ID: <BF45E7F5-706B-400C-9654-A2FEE721163D@gmail.com>

Does anyone know the current warm cold download times for dynamic cache of windows updates?

I can say my experience was a massive increase in the warm download it was delivered in under a couple mins versus 30 or so to download it cold. The warm download was almost instant on the second device. Very green energy efficient. 


Does squid 5.8 or 6 work better on warm delivery? Is there a way to make 100 percent sure a docker container can?t get inside the cache? I have this fear it could be sitting on any cache and actually data marshal the system from inside the cache. Again with use of software fingerprinting we should know if that occurs right? 

As a kid in the early days of the internet I was fascinated with content accelerators. Today they can be used to cache invasive containers and block them essentially this could be a massive tool in cyber security defenses. Again how can we fingerprint invasive docker images containers, non approved bsd jails etc??

Amazing stuff thanks for all you do it was amazing to see acceleration technology still functional and working like a dream in 2024. With the green energy push maybe more of it will be used.
Sent from my iPhone

From jonathanlee571 at gmail.com  Mon Apr 22 05:42:26 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sun, 21 Apr 2024 22:42:26 -0700
Subject: [squid-users] Warm cold times
In-Reply-To: <BF45E7F5-706B-400C-9654-A2FEE721163D@gmail.com>
References: <BF45E7F5-706B-400C-9654-A2FEE721163D@gmail.com>
Message-ID: <52393E38-5763-486F-A680-D4F9B3BF7E10@gmail.com>

Has anyone else taken up the fun challenge of doing windows update caching. It is amazing when it works right. It is a complex configuration, but it is worth it to see a warm download come down that originally took 30 mins instantly to a second client. I didn?t know how much of the updates are the same across different vendor laptops. 

Amazing stuff Squid team.
I wish I could get some of the Roblox Xbox stuff to cache but it?s a night to get running with squid in the first place, I had to splice a bunch of stuff and also wpad the Xbox system. 
Sent from my iPhone

> On Apr 18, 2024, at 23:55, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> ?Does anyone know the current warm cold download times for dynamic cache of windows updates?
> 
> I can say my experience was a massive increase in the warm download it was delivered in under a couple mins versus 30 or so to download it cold. The warm download was almost instant on the second device. Very green energy efficient.
> 
> 
> Does squid 5.8 or 6 work better on warm delivery? Is there a way to make 100 percent sure a docker container can?t get inside the cache? I have this fear it could be sitting on any cache and actually data marshal the system from inside the cache. Again with use of software fingerprinting we should know if that occurs right?
> 
> As a kid in the early days of the internet I was fascinated with content accelerators. Today they can be used to cache invasive containers and block them essentially this could be a massive tool in cyber security defenses. Again how can we fingerprint invasive docker images containers, non approved bsd jails etc??
> 
> Amazing stuff thanks for all you do it was amazing to see acceleration technology still functional and working like a dream in 2024. With the green energy push maybe more of it will be used.
> Sent from my iPhone


From jonathanlee571 at gmail.com  Mon Apr 22 23:52:56 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 22 Apr 2024 16:52:56 -0700
Subject: [squid-users] Container Based Issues Lock Down Password and
 Terminate SSL
Message-ID: <FB29CA6C-BC7A-481C-BE04-4B0AB42D9EE4@gmail.com>

Hello fellow Squid Accelerator/Dynamic Cache/Web Cache Users/PfSense users

I think this might resolve any container based issues/fears if they happened to get into the cache. Ie a Docker Proxy got installed and tried to data marshal the network card inside of a freeBSD jail or something like that. Biggest fear with my cache it is a big cache now

Please yet me know what you think or if it is wrong.

Here is my configuration. I wanted to share it as it might help to secure some of this.

Keep in mine I use cachemgr.cgi within Squidlight so I had to set the password and I have to also adapt the php status file to include the password and also the sqlight php file. 

After that the status and gui pages work still with the new password. Only issues area that it shows up in clear text when it goes over the proxy I can see my password clear as day again that was an issue listed inside the Squid O?REILLY book also. 


I am amazed at the warm updates that was the original goal I was tired of slow updates over and over again. 

# This file is automatically generated by pfSense
# Do not edit manually !

http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

icp_port 0
digest_generation off
dns_v4_first on
pid_filename /var/run/squid/squid.pid
cache_effective_user squid
cache_effective_group proxy
error_default_language en
icon_directory /usr/local/etc/squid/icons
visible_hostname Lee_Family.home.arpa
cache_mgr jonathanlee571 at gmail.com
access_log /var/squid/logs/access.log
cache_log /var/squid/logs/cache.log
cache_store_log none
netdb_filename /var/squid/logs/netdb.state
pinger_enable on
pinger_program /usr/local/libexec/squid/pinger
sslcrtd_program /usr/local/libexec/squid/security_file_certgen -s /var/squid/lib/ssl_db -M 4MB -b 2048
tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
tls_outgoing_options capath=/usr/local/share/certs/
tls_outgoing_options options=NO_SSLv3
tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
sslcrtd_children 10

logfile_rotate 0
debug_options rotate=0
shutdown_lifetime 3 seconds
# Allow local network(s) on interface(s)
acl localnet src  192.168.1.0/27
forwarded_for transparent
httpd_suppress_version_string on
uri_whitespace strip
dns_nameservers 127.0.0.1 
acl getmethod method GET
acl to_ipv6 dst ipv6
acl from_ipv6 src ipv6

tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

acl HttpAccess dstdomain '/usr/local/pkg/http.access'
acl windowsupdate dstdomain '/usr/local/pkg/windowsupdate'

acl rewritedoms dstdomain .facebook.com .akamaihd.net .fbcdn.net .google.com .static.com .apple.com .oracle.com .sun.com .java.com .adobe.com .steamstatic.com .steampowered.com .steamcontent.com .google.com

store_id_program /usr/local/libexec/squid/storeid_file_rewrite /var/squid/storeid/storeid_rewrite.txt
store_id_children 10 startup=5 idle=1 concurrency=0
always_direct allow !getmethod
store_id_access deny connect
store_id_access deny !getmethod
store_id_access allow rewritedoms
reload_into_ims on
max_stale 20 years
minimum_expiry_time 0


refresh_pattern -i squid.internal 10080 80% 79900 override-lastmod override-expire ignore-reload ignore-no-store ignore-private

#FACEBOOK
refresh_pattern ^https.*.facebook.com/* 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private

#FACEBOOK IMAGES  
refresh_pattern -i pixel.facebook.com..(jpg|png|gif|ico|css|js|jpg?) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
refresh_pattern -i .akamaihd.net..(jpg|png|gif|ico|css|js|jpg?) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private   
refresh_pattern -i facebook.com.(jpg|png|gif|jpg?) 10080 80% 43200 store-stale override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private 
refresh_pattern static.(xx|ak).fbcdn.net.(jpg|gif|png|jpg?) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
refresh_pattern ^https.*profile.ak.fbcdn.net.*(jpg|gif|png|jpg?) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
refresh_pattern ^https.*fbcdn.net.*(jpg|gif|png|jpg?) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private

#FACEBOOK VIDEO
refresh_pattern -i .video.ak.fbcdn.net.*.(mp4|flv|mp3|amf) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private   
refresh_pattern (audio|video)/(webm|mp4) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private

#APPLE STUFF
refresh_pattern -i apple.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip|dist)$ 0 80% 43200  refresh-ims

#apple update
refresh_pattern -i (download|adcdownload).apple.com/.*.(pkg|dmg) 4320 100% 43200 
refresh_pattern -i appldnld.apple.com 129600 100% 129600     
refresh_pattern -i phobos.apple.com 129600 100% 129600     
refresh_pattern -i iosapps.itunes.apple.com 129600 100% 129600     

# Updates: Windows
refresh_pattern -i microsoft.com/..(cab|exe|msi|msu|msf|asf|wma|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i windowsupdate.com/..(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i windows.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i windows.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i .*windowsupdate.com/.*.(cab|exe) 259200 100% 259200   
refresh_pattern -i .*update.microsoft.com/.*.(cab|exe|dll|msi|psf) 259200 100% 259200   
refresh_pattern windowsupdate.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern download.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern www.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern au.download.windowsupdate.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200 
refresh_pattern bg.v4.pr.dl.ws.microsoft.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
#windows update NEW UPDATE 0.04
refresh_pattern update.microsoft.com/.*.(cab|exe) 43200 100% 129600    
refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200  
refresh_pattern update.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern -i .update.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .download.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .ws.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       

refresh_pattern ([^.]+.)?(cs|content[1-9]|hsar|content-origin|client-download).[steampowered|steamcontent].com/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern ([^.]+.)?.akamai.steamstatic.com/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod

refresh_pattern -i ([^.]+.)?.adobe.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern -i ([^.]+.)?.java.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern -i ([^.]+.)?.sun.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern -i ([^.]+.)?.oracle.com/.*.(zip|exe|tar.gz) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod

refresh_pattern -i appldnld.apple.com 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern -i ([^.]+.)?apple.com/.*.(ipa) 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
 
refresh_pattern -i ([^.]+.)?.google.com/.*.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
refresh_pattern -i ([^.]+.)?g.static.com/.*.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private

acl https_login url_regex -i ^https.*(login|Login).*
cache deny https_login

range_offset_limit 512 MB windowsupdate
range_offset_limit 4 MB
range_offset_limit 0
quick_abort_min -1 KB

cache_mem 64 MB
maximum_object_size_in_memory 256 KB
memory_replacement_policy heap LFUDA
cache_replacement_policy heap LFUDA
minimum_object_size 0 KB
maximum_object_size 512 MB
cache_dir diskd /var/squid/cache 64000 256 256
offline_mode off
cache_swap_low 90
cache_swap_high 95
acl donotcache dstdomain '/var/squid/acl/donotcache.acl'
cache deny donotcache
cache allow all
# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:    1440  20%  10080
refresh_pattern ^gopher:  1440  0%  1440
refresh_pattern -i (/cgi-bin/|?) 0  0%  0
refresh_pattern .    0  20%  4320


#Remote proxies


# Setup some default acls
# ACLs all, manager, localhost, and to_localhost are predefined.
acl allsrc src all
acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080 3128 3129 1025-65535 
acl sslports port 443 563 8080 5223 2197

acl purge method PURGE
acl connect method CONNECT

# Define protocols used for redirects
acl HTTP proto HTTP
acl HTTPS proto HTTPS

# SslBump Peek and Splice
# http://wiki.squid-cache.org/Features/SslPeekAndSplice
# http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
# Match against the current step during ssl_bump evaluation [fast]
# Never matches and should not be used outside the ssl_bump context.
#
# At each SslBump step, Squid evaluates ssl_bump directives to find
# the next bumping action (e.g., peek or splice). Valid SslBump step
# values and the corresponding ssl_bump evaluation moments are:
#   SslBump1: After getting TCP-level and HTTP CONNECT info.
#   SslBump2: After getting TLS Client Hello info.
#   SslBump3: After getting TLS Server Hello info.
# These ACLs exist even when 'SSL/MITM Mode' is set to 'Custom' so that
# they can be used there for custom configuration.
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
acl banned_hosts src '/var/squid/acl/banned_hosts.acl'
acl whitelist dstdom_regex -i '/var/squid/acl/whitelist.acl'
acl blacklist dstdom_regex -i '/var/squid/acl/blacklist.acl'
http_access allow manager localhost

http_access deny manager
http_access allow purge localhost
http_access deny purge
http_access deny !safeports
http_access deny CONNECT !sslports

# Always allow localhost connections
http_access allow localhost

quick_abort_min 0 KB
quick_abort_max 0 KB
quick_abort_pct 95
request_body_max_size 0 KB
delay_pools 1
delay_class 1 2
delay_parameters 1 -1/-1 -1/-1
delay_initial_bucket_level 100
delay_access 1 allow allsrc

# Reverse Proxy settings

deny_info TCP_RESET allsrc

# Package Integration
url_rewrite_program /usr/local/bin/squidGuard -c /usr/local/etc/squidGuard/squidGuard.conf
url_rewrite_bypass off
url_rewrite_children 32 startup=8 idle=4 concurrency=0

# Custom options before auth
#host_verify_strict on

# These hosts are banned
http_access deny banned_hosts
# Always allow access to whitelist domains
http_access allow whitelist
# Block access to blacklist domains
http_access deny blacklist
# List of domains allowed to logging in to Google services
request_header_access X-GoogApps-Allowed-Domains deny all
request_header_add X-GoogApps-Allowed-Domains consumer_accounts
# Set YouTube safesearch restriction
acl youtubedst dstdomain -n www.youtube.com m.youtube.com youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com
request_header_access YouTube-Restrict deny all
request_header_add YouTube-Restrict none youtubedst
acl sglog url_regex -i sgr=ACCESSDENIED
http_access deny sglog
# Custom SSL/MITM options before auth
cachemgr_passwd disable offline_toggle reconfigure shutdown
cachemgr_passwd REDACTED_CLASSIFIED all
eui_lookup on
acl no_miss url_regex -i gateway.facebook.com/ws/realtime?
acl no_miss url_regex -i web-chat-e2ee.facebook.com/ws/chat
acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com
http_access allow CONNECT wuCONNECT localnet
http_access allow CONNECT wuCONNECT localhost
http_access allow windowsupdate localnet
http_access allow windowsupdate localhost
http_access allow HttpAccess localnet
http_access allow HttpAccess localhost
http_access deny manager
http_access deny to_ipv6
http_access deny from_ipv6

acl BrokenButTrustedServers dstdomain '/usr/local/pkg/dstdom.broken'
acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
sslproxy_cert_error deny all

acl splice_only src 192.168.1.8 #Tasha iPhone
acl splice_only src 192.168.1.10 #Jon iPhone
acl splice_only src 192.168.1.11 #Amazon Fire
acl splice_only src 192.168.1.15 #Tasha HP
acl splice_only src 192.168.1.16 #iPad

acl splice_only_mac arp REDACTED
acl splice_only_mac arp REDACTED
acl splice_only_mac arp REDACTED
acl splice_only_mac arp REDACTED
acl splice_only_mac arp REDACTED

acl NoSSLIntercept ssl::server_name_regex -i '/usr/local/pkg/reg.url.nobump'
acl NoBumpDNS dstdomain '/usr/local/pkg/dns.nobump'

acl markBumped annotate_client bumped=true
acl bump_only src 192.168.1.3 #webtv
acl bump_only src 192.168.1.4 #toshiba
acl bump_only src 192.168.1.5 #imac
acl bump_only src 192.168.1.9 #macbook
acl bump_only src 192.168.1.13 #dell

acl bump_only_mac arp REDACTED
acl bump_only_mac arp REDACTED
acl bump_only_mac arp REDACTED
acl bump_only_mac arp REDACTED
acl bump_only_mac arp REDACTED


ssl_bump peek step1
miss_access deny no_miss 
ssl_bump splice https_login
ssl_bump splice splice_only_mac
ssl_bump splice NoBumpDNS
ssl_bump splice NoSSLIntercept
ssl_bump bump bump_only_mac
ssl_bump terminate all # if its not on the list kill the connection

acl markedBumped note bumped true
url_rewrite_access deny markedBumped

read_ahead_gap 64 KB
negative_ttl 1 second
connect_timeout 30 seconds
request_timeout 60 seconds
half_closed_clients off
shutdown_lifetime 10 seconds
negative_dns_ttl 1 seconds
ignore_unknown_nameservers on
pipeline_prefetch 100

#acl SSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.bump'
#ssl_bump bump SSLIntercept

# Setup allowed ACLs
# Allow local network(s) on interface(s)
http_access allow localnet
# Default block all to be sure
http_access deny allsrc
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240422/fc600191/attachment.htm>

From jonathanlee571 at gmail.com  Tue Apr 23 03:51:04 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 22 Apr 2024 20:51:04 -0700
Subject: [squid-users] Container Based Issues Lock Down Password and
 Terminate SSL
In-Reply-To: <FB29CA6C-BC7A-481C-BE04-4B0AB42D9EE4@gmail.com>
References: <FB29CA6C-BC7A-481C-BE04-4B0AB42D9EE4@gmail.com>
Message-ID: <5DC11288-5137-4C62-A1A5-E25EBA3A842C@gmail.com>

correction use both acl for and use 

> ssl_bump peek step1
> miss_access deny no_miss 
> ssl_bump splice https_login
> ssl_bump splice splice_only_mac splice_only
> ssl_bump splice NoBumpDNS
> ssl_bump splice NoSSLIntercept
> ssl_bump bump bump_only_mac bump_only
> ssl_bump terminate all # if its not on the list kill the connection

I did not know it could also check Layer 2 and Layer 3 addresses this way seems more secure 

Have a good day everyone

> On Apr 22, 2024, at 16:52, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Hello fellow Squid Accelerator/Dynamic Cache/Web Cache Users/PfSense users
> 
> I think this might resolve any container based issues/fears if they happened to get into the cache. Ie a Docker Proxy got installed and tried to data marshal the network card inside of a freeBSD jail or something like that. Biggest fear with my cache it is a big cache now
> 
> Please yet me know what you think or if it is wrong.
> 
> Here is my configuration. I wanted to share it as it might help to secure some of this.
> 
> Keep in mine I use cachemgr.cgi within Squidlight so I had to set the password and I have to also adapt the php status file to include the password and also the sqlight php file. 
> 
> After that the status and gui pages work still with the new password. Only issues area that it shows up in clear text when it goes over the proxy I can see my password clear as day again that was an issue listed inside the Squid O?REILLY book also. 
> 
> 
> I am amazed at the warm updates that was the original goal I was tired of slow updates over and over again. 
> 
> # This file is automatically generated by pfSense
> # Do not edit manually !
> 
> http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3
> 
> http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3
> 
> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3
> 
> icp_port 0
> digest_generation off
> dns_v4_first on
> pid_filename /var/run/squid/squid.pid
> cache_effective_user squid
> cache_effective_group proxy
> error_default_language en
> icon_directory /usr/local/etc/squid/icons
> visible_hostname Lee_Family.home.arpa
> cache_mgr jonathanlee571 at gmail.com
> access_log /var/squid/logs/access.log
> cache_log /var/squid/logs/cache.log
> cache_store_log none
> netdb_filename /var/squid/logs/netdb.state
> pinger_enable on
> pinger_program /usr/local/libexec/squid/pinger
> sslcrtd_program /usr/local/libexec/squid/security_file_certgen -s /var/squid/lib/ssl_db -M 4MB -b 2048
> tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
> tls_outgoing_options capath=/usr/local/share/certs/
> tls_outgoing_options options=NO_SSLv3
> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> sslcrtd_children 10
> 
> logfile_rotate 0
> debug_options rotate=0
> shutdown_lifetime 3 seconds
> # Allow local network(s) on interface(s)
> acl localnet src  192.168.1.0/27
> forwarded_for transparent
> httpd_suppress_version_string on
> uri_whitespace strip
> dns_nameservers 127.0.0.1 
> acl getmethod method GET
> acl to_ipv6 dst ipv6
> acl from_ipv6 src ipv6
> 
> tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 
> acl HttpAccess dstdomain '/usr/local/pkg/http.access'
> acl windowsupdate dstdomain '/usr/local/pkg/windowsupdate'
> 
> acl rewritedoms dstdomain .facebook.com .akamaihd.net .fbcdn.net .google.com .static.com .apple.com .oracle.com .sun.com .java.com .adobe.com .steamstatic.com .steampowered.com .steamcontent.com .google.com
> 
> store_id_program /usr/local/libexec/squid/storeid_file_rewrite /var/squid/storeid/storeid_rewrite.txt
> store_id_children 10 startup=5 idle=1 concurrency=0
> always_direct allow !getmethod
> store_id_access deny connect
> store_id_access deny !getmethod
> store_id_access allow rewritedoms
> reload_into_ims on
> max_stale 20 years
> minimum_expiry_time 0
> 
> 
> refresh_pattern -i squid.internal 10080 80% 79900 override-lastmod override-expire ignore-reload ignore-no-store ignore-private
> 
> #FACEBOOK
> refresh_pattern ^https.*.facebook.com/* 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> 
> #FACEBOOK IMAGES  
> refresh_pattern -i pixel.facebook.com..(jpg|png|gif|ico|css|js|jpg?) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern -i .akamaihd.net..(jpg|png|gif|ico|css|js|jpg?) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private   
> refresh_pattern -i facebook.com.(jpg|png|gif|jpg?) 10080 80% 43200 store-stale override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private 
> refresh_pattern static.(xx|ak).fbcdn.net.(jpg|gif|png|jpg?) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern ^https.*profile.ak.fbcdn.net.*(jpg|gif|png|jpg?) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> refresh_pattern ^https.*fbcdn.net.*(jpg|gif|png|jpg?) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> 
> #FACEBOOK VIDEO
> refresh_pattern -i .video.ak.fbcdn.net.*.(mp4|flv|mp3|amf) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private   
> refresh_pattern (audio|video)/(webm|mp4) 10080 80% 43200 override-expire override-lastmod ignore-no-cache ignore-reload reload-into-ims ignore-private
> 
> #APPLE STUFF
> refresh_pattern -i apple.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip|dist)$ 0 80% 43200  refresh-ims
> 
> #apple update
> refresh_pattern -i (download|adcdownload).apple.com/.*.(pkg|dmg) 4320 100% 43200 
> refresh_pattern -i appldnld.apple.com 129600 100% 129600     
> refresh_pattern -i phobos.apple.com 129600 100% 129600     
> refresh_pattern -i iosapps.itunes.apple.com 129600 100% 129600     
> 
> # Updates: Windows
> refresh_pattern -i microsoft.com/..(cab|exe|msi|msu|msf|asf|wma|dat|zip)$ 4320 80% 43200  refresh-ims
> refresh_pattern -i windowsupdate.com/..(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$ 4320 80% 43200  refresh-ims
> refresh_pattern -i windows.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip)$ 4320 80% 43200  refresh-ims
> refresh_pattern -i microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
> refresh_pattern -i windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
> refresh_pattern -i windows.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
> refresh_pattern -i .*windowsupdate.com/.*.(cab|exe) 259200 100% 259200   
> refresh_pattern -i .*update.microsoft.com/.*.(cab|exe|dll|msi|psf) 259200 100% 259200   
> refresh_pattern windowsupdate.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
> refresh_pattern download.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
> refresh_pattern www.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
> refresh_pattern au.download.windowsupdate.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200 
> refresh_pattern bg.v4.pr.dl.ws.microsoft.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
> #windows update NEW UPDATE 0.04
> refresh_pattern update.microsoft.com/.*.(cab|exe) 43200 100% 129600    
> refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200  
> refresh_pattern update.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
> refresh_pattern -i .update.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
> refresh_pattern -i .windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
> refresh_pattern -i .download.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
> refresh_pattern -i .ws.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
> 
> refresh_pattern ([^.]+.)?(cs|content[1-9]|hsar|content-origin|client-download).[steampowered|steamcontent].com/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern ([^.]+.)?.akamai.steamstatic.com/.*.* 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> 
> refresh_pattern -i ([^.]+.)?.adobe.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?.java.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?.sun.com/.*.(zip|exe) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?.oracle.com/.*.(zip|exe|tar.gz) 43200 100% 43200 reload-into-ims ignore-reload ignore-no-store override-expire override-lastmod
> 
> refresh_pattern -i appldnld.apple.com 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
> refresh_pattern -i ([^.]+.)?apple.com/.*.(ipa) 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
>  
> refresh_pattern -i ([^.]+.)?.google.com/.*.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
> refresh_pattern -i ([^.]+.)?g.static.com/.*.(exe|crx) 10080 80% 43200 override-expire override-lastmod ignore-reload reload-into-ims ignore-private
> 
> acl https_login url_regex -i ^https.*(login|Login).*
> cache deny https_login
> 
> range_offset_limit 512 MB windowsupdate
> range_offset_limit 4 MB
> range_offset_limit 0
> quick_abort_min -1 KB
> 
> cache_mem 64 MB
> maximum_object_size_in_memory 256 KB
> memory_replacement_policy heap LFUDA
> cache_replacement_policy heap LFUDA
> minimum_object_size 0 KB
> maximum_object_size 512 MB
> cache_dir diskd /var/squid/cache 64000 256 256
> offline_mode off
> cache_swap_low 90
> cache_swap_high 95
> acl donotcache dstdomain '/var/squid/acl/donotcache.acl'
> cache deny donotcache
> cache allow all
> # Add any of your own refresh_pattern entries above these.
> refresh_pattern ^ftp:    1440  20%  10080
> refresh_pattern ^gopher:  1440  0%  1440
> refresh_pattern -i (/cgi-bin/|?) 0  0%  0
> refresh_pattern .    0  20%  4320
> 
> 
> #Remote proxies
> 
> 
> # Setup some default acls
> # ACLs all, manager, localhost, and to_localhost are predefined.
> acl allsrc src all
> acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080 3128 3129 1025-65535 
> acl sslports port 443 563 8080 5223 2197
> 
> acl purge method PURGE
> acl connect method CONNECT
> 
> # Define protocols used for redirects
> acl HTTP proto HTTP
> acl HTTPS proto HTTPS
> 
> # SslBump Peek and Splice
> # http://wiki.squid-cache.org/Features/SslPeekAndSplice
> # http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
> # Match against the current step during ssl_bump evaluation [fast]
> # Never matches and should not be used outside the ssl_bump context.
> #
> # At each SslBump step, Squid evaluates ssl_bump directives to find
> # the next bumping action (e.g., peek or splice). Valid SslBump step
> # values and the corresponding ssl_bump evaluation moments are:
> #   SslBump1: After getting TCP-level and HTTP CONNECT info.
> #   SslBump2: After getting TLS Client Hello info.
> #   SslBump3: After getting TLS Server Hello info.
> # These ACLs exist even when 'SSL/MITM Mode' is set to 'Custom' so that
> # they can be used there for custom configuration.
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> acl banned_hosts src '/var/squid/acl/banned_hosts.acl'
> acl whitelist dstdom_regex -i '/var/squid/acl/whitelist.acl'
> acl blacklist dstdom_regex -i '/var/squid/acl/blacklist.acl'
> http_access allow manager localhost
> 
> http_access deny manager
> http_access allow purge localhost
> http_access deny purge
> http_access deny !safeports
> http_access deny CONNECT !sslports
> 
> # Always allow localhost connections
> http_access allow localhost
> 
> quick_abort_min 0 KB
> quick_abort_max 0 KB
> quick_abort_pct 95
> request_body_max_size 0 KB
> delay_pools 1
> delay_class 1 2
> delay_parameters 1 -1/-1 -1/-1
> delay_initial_bucket_level 100
> delay_access 1 allow allsrc
> 
> # Reverse Proxy settings
> 
> deny_info TCP_RESET allsrc
> 
> # Package Integration
> url_rewrite_program /usr/local/bin/squidGuard -c /usr/local/etc/squidGuard/squidGuard.conf
> url_rewrite_bypass off
> url_rewrite_children 32 startup=8 idle=4 concurrency=0
> 
> # Custom options before auth
> #host_verify_strict on
> 
> # These hosts are banned
> http_access deny banned_hosts
> # Always allow access to whitelist domains
> http_access allow whitelist
> # Block access to blacklist domains
> http_access deny blacklist
> # List of domains allowed to logging in to Google services
> request_header_access X-GoogApps-Allowed-Domains deny all
> request_header_add X-GoogApps-Allowed-Domains consumer_accounts
> # Set YouTube safesearch restriction
> acl youtubedst dstdomain -n www.youtube.com m.youtube.com youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com
> request_header_access YouTube-Restrict deny all
> request_header_add YouTube-Restrict none youtubedst
> acl sglog url_regex -i sgr=ACCESSDENIED
> http_access deny sglog
> # Custom SSL/MITM options before auth
> cachemgr_passwd disable offline_toggle reconfigure shutdown
> cachemgr_passwd REDACTED_CLASSIFIED all
> eui_lookup on
> acl no_miss url_regex -i gateway.facebook.com/ws/realtime?
> acl no_miss url_regex -i web-chat-e2ee.facebook.com/ws/chat
> acl CONNECT method CONNECT
> acl wuCONNECT dstdomain www.update.microsoft.com
> acl wuCONNECT dstdomain sls.microsoft.com
> http_access allow CONNECT wuCONNECT localnet
> http_access allow CONNECT wuCONNECT localhost
> http_access allow windowsupdate localnet
> http_access allow windowsupdate localhost
> http_access allow HttpAccess localnet
> http_access allow HttpAccess localhost
> http_access deny manager
> http_access deny to_ipv6
> http_access deny from_ipv6
> 
> acl BrokenButTrustedServers dstdomain '/usr/local/pkg/dstdom.broken'
> acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
> sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
> sslproxy_cert_error deny all
> 
> acl splice_only src 192.168.1.8 #Tasha iPhone
> acl splice_only src 192.168.1.10 #Jon iPhone
> acl splice_only src 192.168.1.11 #Amazon Fire
> acl splice_only src 192.168.1.15 #Tasha HP
> acl splice_only src 192.168.1.16 #iPad
> 
> acl splice_only_mac arp REDACTED
> acl splice_only_mac arp REDACTED
> acl splice_only_mac arp REDACTED
> acl splice_only_mac arp REDACTED
> acl splice_only_mac arp REDACTED
> 
> acl NoSSLIntercept ssl::server_name_regex -i '/usr/local/pkg/reg.url.nobump'
> acl NoBumpDNS dstdomain '/usr/local/pkg/dns.nobump'
> 
> acl markBumped annotate_client bumped=true
> acl bump_only src 192.168.1.3 #webtv
> acl bump_only src 192.168.1.4 #toshiba
> acl bump_only src 192.168.1.5 #imac
> acl bump_only src 192.168.1.9 #macbook
> acl bump_only src 192.168.1.13 #dell
> 
> acl bump_only_mac arp REDACTED
> acl bump_only_mac arp REDACTED
> acl bump_only_mac arp REDACTED
> acl bump_only_mac arp REDACTED
> acl bump_only_mac arp REDACTED
> 
> 
> ssl_bump peek step1
> miss_access deny no_miss 
> ssl_bump splice https_login
> ssl_bump splice splice_only_mac
> ssl_bump splice NoBumpDNS
> ssl_bump splice NoSSLIntercept
> ssl_bump bump bump_only_mac
> ssl_bump terminate all # if its not on the list kill the connection
> 
> acl markedBumped note bumped true
> url_rewrite_access deny markedBumped
> 
> read_ahead_gap 64 KB
> negative_ttl 1 second
> connect_timeout 30 seconds
> request_timeout 60 seconds
> half_closed_clients off
> shutdown_lifetime 10 seconds
> negative_dns_ttl 1 seconds
> ignore_unknown_nameservers on
> pipeline_prefetch 100
> 
> #acl SSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.bump'
> #ssl_bump bump SSLIntercept
> 
> # Setup allowed ACLs
> # Allow local network(s) on interface(s)
> http_access allow localnet
> # Default block all to be sure
> http_access deny allsrc

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240422/3190fbed/attachment.htm>

From squid3 at treenet.co.nz  Tue Apr 23 07:41:37 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 23 Apr 2024 19:41:37 +1200
Subject: [squid-users] Warm cold times
In-Reply-To: <52393E38-5763-486F-A680-D4F9B3BF7E10@gmail.com>
References: <BF45E7F5-706B-400C-9654-A2FEE721163D@gmail.com>
 <52393E38-5763-486F-A680-D4F9B3BF7E10@gmail.com>
Message-ID: <9d8f4de6-c797-4e70-aaf5-c073f45c3390@treenet.co.nz>

On 22/04/24 17:42, Jonathan Lee wrote:
> Has anyone else taken up the fun challenge of doing windows update caching. It is amazing when it works right. It is a complex configuration, but it is worth it to see a warm download come down that originally took 30 mins instantly to a second client. I didn?t know how much of the updates are the same across different vendor laptops.
> 

There have been several people over the years.
The collected information is being gathered at 
<https://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates>

If you would like to check and update the information for the current 
Windows 11 and Squid 6, etc. that would be useful.

Wiki updates are now made using github PRs against the repository at 
<https://github.com/squid-cache/squid-cache.github.io>.




> Amazing stuff Squid team.
> I wish I could get some of the Roblox Xbox stuff to cache but it?s a night to get running with squid in the first place, I had to splice a bunch of stuff and also wpad the Xbox system.

FWIW, what I have seen from routing perspective is that Roblox likes to 
use custom ports and P2P connections for a lot of things. So no high 
expectations there, but anything cacheable is great news.



>> On Apr 18, 2024, at 23:55, Jonathan Lee wrote:
>>
>> ?Does anyone know the current warm cold download times for dynamic cache of windows updates?
>>
>> I can say my experience was a massive increase in the warm download it was delivered in under a couple mins versus 30 or so to download it cold. The warm download was almost instant on the second device. Very green energy efficient.
>>
>>
>> Does squid 5.8 or 6 work better on warm delivery?

There is no significant differences AFAIK. They both come down to what 
you have configured. That said, the ongoing improvements may make v6 
some amount of "better" - even if only trivial.



>> Is there a way to make 100 percent sure a docker container can?t get inside the cache?

For Windows I would expect the only "100% sure" way is to completely 
forbid access to the disk where the cache is stored.


The rest of your questions are about container management and Windows 
configuration. Which are kind of off-topic.


Cheers
Amos


From squid3 at treenet.co.nz  Tue Apr 23 08:03:42 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 23 Apr 2024 20:03:42 +1200
Subject: [squid-users] Container Based Issues Lock Down Password and
 Terminate SSL
In-Reply-To: <FB29CA6C-BC7A-481C-BE04-4B0AB42D9EE4@gmail.com>
References: <FB29CA6C-BC7A-481C-BE04-4B0AB42D9EE4@gmail.com>
Message-ID: <58c41ee7-b88c-4d5a-bd12-220d44465067@treenet.co.nz>

On 23/04/24 11:52, Jonathan Lee wrote:
> Hello fellow Squid Accelerator/Dynamic Cache/Web Cache Users/PfSense users
> 
> I think this might resolve any container based issues/fears if they 
> happened to get into the cache. Ie a Docker Proxy got installed and 
> tried to data marshal the network card inside of a freeBSD jail or 
> something like that. Biggest fear with my cache it is a big cache now
> 
> Please yet me know what you think or if it is wrong.
> 
> Here is my configuration. I wanted to share it as it might help to 
> secure some of this.

FTR, this config was auto-generated by pfsense. A number of things which 
that tool forces into the config could be done much better in the latest 
Squid, but the tool does not do due to needing to support older Squid 
version.


> 
> Keep in mine I use cachemgr.cgi within Squidlight so I had to set the 
> password and I have to also adapt the php status file to include the 
> password and also the sqlight php file.
> 
> After that the status and gui pages work still with the new password. 
> Only issues area that it shows up in clear text when it goes over the 
> proxy I can see my password clear as day again that was an issue listed 
> inside the Squid O?REILLY book also.


Please ensure you are using the latest Squid v6 release. That release 
has both a number of security fixes, and working https:// URL access to 
the manager reports.

The cachemgr.cgi tool is deprecated fro a number of issues including 
that style of embedding passwords in the URLs.

Francesco and I have created a tool that can be found at 
<https://github.com/yadij/cachemgr.js/blob/master/README.md> for basic 
access to the reports directly from Browser.
That tool uses HTTP authentication configured via the well-documented 
proxy_auth ACLs and http_access for more secure access than the old URL 
based mechanism (which still exists, just deprecated).



Cheers
Amos


From jonathanlee571 at gmail.com  Tue Apr 23 14:07:15 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Tue, 23 Apr 2024 07:07:15 -0700
Subject: [squid-users] Warm cold times
In-Reply-To: <9d8f4de6-c797-4e70-aaf5-c073f45c3390@treenet.co.nz>
References: <9d8f4de6-c797-4e70-aaf5-c073f45c3390@treenet.co.nz>
Message-ID: <5CF7681E-C5E1-45FB-948D-A888EAE36135@gmail.com>

Thanks
Sent from my iPhone

> On Apr 23, 2024, at 00:41, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> ?On 22/04/24 17:42, Jonathan Lee wrote:
>> Has anyone else taken up the fun challenge of doing windows update caching. It is amazing when it works right. It is a complex configuration, but it is worth it to see a warm download come down that originally took 30 mins instantly to a second client. I didn?t know how much of the updates are the same across different vendor laptops.
> 
> There have been several people over the years.
> The collected information is being gathered at <https://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates>
> 
> If you would like to check and update the information for the current Windows 11 and Squid 6, etc. that would be useful.
> 
> Wiki updates are now made using github PRs against the repository at <https://github.com/squid-cache/squid-cache.github.io>.
> 
> 
> 
> 
>> Amazing stuff Squid team.
>> I wish I could get some of the Roblox Xbox stuff to cache but it?s a night to get running with squid in the first place, I had to splice a bunch of stuff and also wpad the Xbox system.
> 
> FWIW, what I have seen from routing perspective is that Roblox likes to use custom ports and P2P connections for a lot of things. So no high expectations there, but anything cacheable is great news.
> 
> 
> 
>>>> On Apr 18, 2024, at 23:55, Jonathan Lee wrote:
>>> 
>>> ?Does anyone know the current warm cold download times for dynamic cache of windows updates?
>>> 
>>> I can say my experience was a massive increase in the warm download it was delivered in under a couple mins versus 30 or so to download it cold. The warm download was almost instant on the second device. Very green energy efficient.
>>> 
>>> 
>>> Does squid 5.8 or 6 work better on warm delivery?
> 
> There is no significant differences AFAIK. They both come down to what you have configured. That said, the ongoing improvements may make v6 some amount of "better" - even if only trivial.
> 
> 
> 
>>> Is there a way to make 100 percent sure a docker container can?t get inside the cache?
> 
> For Windows I would expect the only "100% sure" way is to completely forbid access to the disk where the cache is stored.
> 
> 
> The rest of your questions are about container management and Windows configuration. Which are kind of off-topic.
> 
> 
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From jonathanlee571 at gmail.com  Wed Apr 24 05:27:20 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Tue, 23 Apr 2024 22:27:20 -0700
Subject: [squid-users] Container Based Issues Lock Down Password and
 Terminate SSL
In-Reply-To: <58c41ee7-b88c-4d5a-bd12-220d44465067@treenet.co.nz>
References: <58c41ee7-b88c-4d5a-bd12-220d44465067@treenet.co.nz>
Message-ID: <EDB6E1EB-C9AD-4ACB-9ACD-8CFB8D5F8E41@gmail.com>

Hello fellow Squid users I wanted to ask a quick question for use with termination would http access for cache still work with this type of setup and custom refresh patterns?

I think it would terminate all but the clients and if they use the cache it would be ok.

But I think an invasive container would be blocked my goal here. 

acl markBumped annotate_client bumped=true
acl active_use annotate_client active=true
acl bump_only src 192.168.1.3 #webtv
acl bump_only src 192.168.1.4 #toshiba
acl bump_only src 192.168.1.5 #imac
acl bump_only src 192.168.1.9 #macbook
acl bump_only src 192.168.1.13 #dell

acl bump_only_mac arp macaddresshere
acl bump_only_mac arp macaddresshere
acl bump_only_mac arp macaddresshere
acl bump_only_mac arp macaddresshere
acl bump_only_mac arp macaddresshere

ssl_bump peek step1
miss_access deny no_miss active_use
ssl_bump splice https_login active_use
ssl_bump splice splice_only_mac splice_only active_use
ssl_bump splice NoBumpDNS active_use
ssl_bump splice NoSSLIntercept active_use
ssl_bump bump bump_only_mac bump_only active_use
acl activated note active_use true
ssl_bump terminate !activated



Sent from my iPhone

> On Apr 23, 2024, at 01:03, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> ?On 23/04/24 11:52, Jonathan Lee wrote:
>> Hello fellow Squid Accelerator/Dynamic Cache/Web Cache Users/PfSense users
>> I think this might resolve any container based issues/fears if they happened to get into the cache. Ie a Docker Proxy got installed and tried to data marshal the network card inside of a freeBSD jail or something like that. Biggest fear with my cache it is a big cache now
>> Please yet me know what you think or if it is wrong.
>> Here is my configuration. I wanted to share it as it might help to secure some of this.
> 
> FTR, this config was auto-generated by pfsense. A number of things which that tool forces into the config could be done much better in the latest Squid, but the tool does not do due to needing to support older Squid version.
> 
> 
>> Keep in mine I use cachemgr.cgi within Squidlight so I had to set the password and I have to also adapt the php status file to include the password and also the sqlight php file.
>> After that the status and gui pages work still with the new password. Only issues area that it shows up in clear text when it goes over the proxy I can see my password clear as day again that was an issue listed inside the Squid O?REILLY book also.
> 
> 
> Please ensure you are using the latest Squid v6 release. That release has both a number of security fixes, and working https:// URL access to the manager reports.
> 
> The cachemgr.cgi tool is deprecated fro a number of issues including that style of embedding passwords in the URLs.
> 
> Francesco and I have created a tool that can be found at <https://github.com/yadij/cachemgr.js/blob/master/README.md> for basic access to the reports directly from Browser.
> That tool uses HTTP authentication configured via the well-documented proxy_auth ACLs and http_access for more secure access than the old URL based mechanism (which still exists, just deprecated).
> 
> 
> 
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From chgakiivc at gmail.com  Wed Apr 24 05:31:01 2024
From: chgakiivc at gmail.com (ivc chgaki)
Date: Wed, 24 Apr 2024 10:31:01 +0500
Subject: [squid-users] enctype aes256-cts found in keytab but cannot decrypt
 ticket
Message-ID: <CABFnWrRvSfsUMjYpJ96UZ-A2DL-d9wjEPqHs77T-BVu6SsQkJg@mail.gmail.com>

 hello. i hve Samba DC and squid. i created user, then SPN, and then
exported keytab and imported him to squid. im using kerberos negotiate
helper but when i try go to internet i have popup window with
login/password and in cace.log log error


2024/04/21 21:41:58 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: gss_accept_sec_context() failed:
Unspecified GSS failure.  Minor code may provide more information. Request
ticket server HTTP/srv-proxy.mydomain.com at MYADOMAIN.COM kvno 2 enctype
aes256-cts found in keytab but cannot decrypt ticket; }}


why this happen? i can see using klist that in keytab aes256 on place, but
why squid cant decrypt?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240424/18b52ff7/attachment.htm>

From hima at withforge.com  Wed Apr 24 19:21:13 2024
From: hima at withforge.com (Hima Tammineedi)
Date: Wed, 24 Apr 2024 12:21:13 -0700
Subject: [squid-users] Squid macOS homebrew package doesn't put squid files
 in a neat folder
Message-ID: <CAPjdNQqEEk99HS-2UTvYcZ4TeSMmsguxaAT-=FSGDtDDiYJZ2A@mail.gmail.com>

Hi,

It seems that on macOS with homebrew, that the squid files are not
installed in a proper subdirectory like they are on linux.

I installed squid on macOS with `brew install squid`
I then noticed that the conf file is found at `/opt/homebrew/etc/squid.conf`
And then after some digging and searching, found that the access.log and
cache.log are at `/opt/homebrew/var/logs/{access,cache}.log`.

But the part that doesn't seem good here is that these files are not being
put into folders.
In `/opt/homebrew/etc/` for example, it would be better if the three files
that squid created: squid.conf, squid.conf.default,
and squid.conf.documented were put into a subdir like
`/opt/homebrew/etc/squid/squid.conf` etc.
That would be better organization.

It's worse for the log files because they are just in the root logs folder
with generic names "access" and "cache", and so some other program could
use the same file names and they might overwrite each other!

In linux installs, there is a subdir.

Can this be fixed?

Thanks,
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240424/ef4ed3c0/attachment.htm>

From s_p_arun at yahoo.com  Thu Apr 25 01:16:23 2024
From: s_p_arun at yahoo.com (Arun Kumar)
Date: Thu, 25 Apr 2024 01:16:23 +0000 (UTC)
Subject: [squid-users] Error during ICAP RESPMOD
In-Reply-To: <9d34831b-1f9c-41d0-b123-e022c872ecc9@measurement-factory.com>
References: <334246463.6454176.1710802007981.ref@mail.yahoo.com>
 <334246463.6454176.1710802007981@mail.yahoo.com>
 <400fe870-9742-4fd8-a66e-22a9b281c932@measurement-factory.com>
 <283160880.349514.1711127497866@mail.yahoo.com>
 <9d34831b-1f9c-41d0-b123-e022c872ecc9@measurement-factory.com>
Message-ID: <2101931183.3556436.1714007783880@mail.yahoo.com>

 I managed to reproduce the problem in my personal setup. Please find the cache logs when the problem is reproduced. Squid version is 5.8
cache.zip


|  | 
cache.zip
 |




    On Friday, March 22, 2024 at 11:02:51 PM EDT, Alex Rousskov <rousskov at measurement-factory.com> wrote:  
 
 On 2024-03-22 13:11, Arun Kumar wrote:
> The lines above are. The content-length is 138 (8a in hex), but the 
> bytes are 144. Could this be the reason?
> 
> parseMore: have 144 bytes to parse [FD 14;RBG/Comm(14)wr job24]
> parseMore:
> 8a^M
> {"activity":"Make a simple musical 
> instrument","type":"music","participants":1,"price:0.4,"link":"","key":"7091374","accessibility":0.25}^M
> parseHeaders: parse ICAP headers
> parsePart: have 144 head bytes to parse; state: 0
> parsePart: head parsing result: 0 detail: 600


I cannot be sure based on the tiny snippets shared so far, but it 
_looks_ like Squid expected an ICAP response header and got an ICAP 
response body chunk instead. It is also possible that we are looking at 
log lines from two unrelated ICAP transactions, or I am simply 
misinterpreting the snippets.

If you want a more reliable diagnosis, then my earlier recommendation 
regarding sharing (privately if needed) the following information still 
stands:

* compressed ALL,9 cache.log and
* the problematic ICAP response in a raw packet capture format.


HTH,

Alex.


> On Monday, March 18, 2024 at 11:21:02 PM EDT, Alex Rousskov 
> <rousskov at measurement-factory.com> wrote:
> 
> 
> On 2024-03-18 18:46, Arun Kumar wrote:
> 
>? > Any idea, the reason for error in ModXact.cc parsePart fuction.
>? > Happening during parsing the response from ICAP
>? >
>? >
>? > parsePart: have 144 head bytes to parse; state: 0
>? > parsePart: head parsing result: 0 detail: 600
> 
> 
> AFAICT, Squid considers received ICAP response header malformed. More
> than five possible problems/cases may match the above lines. The answer
> to your question (or an additional clue!) is in different debugging
> output, possibly logged somewhere between the two lines quoted above.
> The right debugging lines may be visible in "debug_options ALL,2 58,5,
> 93,5" output, but it is usually best to share compressed ALL,9 logs
> (privately if needed).
> 
> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>
> 
> 
> Sharing the problematic ICAP response (header) in a raw packet capture
> format (to preserve important details) may also be very useful.
> 
> 
> HTH,
> 
> Alex.
> 
> 

  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240425/de42131a/attachment.htm>

From s_p_arun at yahoo.com  Thu Apr 25 01:23:34 2024
From: s_p_arun at yahoo.com (Arun Kumar)
Date: Thu, 25 Apr 2024 01:23:34 +0000 (UTC)
Subject: [squid-users] Error during ICAP RESPMOD
In-Reply-To: <2101931183.3556436.1714007783880@mail.yahoo.com>
References: <334246463.6454176.1710802007981.ref@mail.yahoo.com>
 <334246463.6454176.1710802007981@mail.yahoo.com>
 <400fe870-9742-4fd8-a66e-22a9b281c932@measurement-factory.com>
 <283160880.349514.1711127497866@mail.yahoo.com>
 <9d34831b-1f9c-41d0-b123-e022c872ecc9@measurement-factory.com>
 <2101931183.3556436.1714007783880@mail.yahoo.com>
Message-ID: <37699563.3545988.1714008214587@mail.yahoo.com>

 I managed to reproduce the problem in my personal setup. Please find the cache logs when the problem is reproduced. Squid version is 5.8
https://drive.google.com/file/d/19yirXfxKli7NXon4ewiy-v3GpLvECT1i/view?usp=sharing

    On Wednesday, April 24, 2024 at 09:16:23 PM EDT, Arun Kumar <s_p_arun at yahoo.com> wrote:  
 
  I managed to reproduce the problem in my personal setup. Please find the cache logs when the problem is reproduced. Squid version is 5.8
cache.zip


|  | 
cache.zip
 |



| 
| 
|  | 
cache.zip


 |

 |

 |






    On Friday, March 22, 2024 at 11:02:51 PM EDT, Alex Rousskov <rousskov at measurement-factory.com> wrote:  
 
 On 2024-03-22 13:11, Arun Kumar wrote:
> The lines above are. The content-length is 138 (8a in hex), but the 
> bytes are 144. Could this be the reason?
> 
> parseMore: have 144 bytes to parse [FD 14;RBG/Comm(14)wr job24]
> parseMore:
> 8a^M
> {"activity":"Make a simple musical 
> instrument","type":"music","participants":1,"price:0.4,"link":"","key":"7091374","accessibility":0.25}^M
> parseHeaders: parse ICAP headers
> parsePart: have 144 head bytes to parse; state: 0
> parsePart: head parsing result: 0 detail: 600


I cannot be sure based on the tiny snippets shared so far, but it 
_looks_ like Squid expected an ICAP response header and got an ICAP 
response body chunk instead. It is also possible that we are looking at 
log lines from two unrelated ICAP transactions, or I am simply 
misinterpreting the snippets.

If you want a more reliable diagnosis, then my earlier recommendation 
regarding sharing (privately if needed) the following information still 
stands:

* compressed ALL,9 cache.log and
* the problematic ICAP response in a raw packet capture format.


HTH,

Alex.


> On Monday, March 18, 2024 at 11:21:02 PM EDT, Alex Rousskov 
> <rousskov at measurement-factory.com> wrote:
> 
> 
> On 2024-03-18 18:46, Arun Kumar wrote:
> 
>? > Any idea, the reason for error in ModXact.cc parsePart fuction.
>? > Happening during parsing the response from ICAP
>? >
>? >
>? > parsePart: have 144 head bytes to parse; state: 0
>? > parsePart: head parsing result: 0 detail: 600
> 
> 
> AFAICT, Squid considers received ICAP response header malformed. More
> than five possible problems/cases may match the above lines. The answer
> to your question (or an additional clue!) is in different debugging
> output, possibly logged somewhere between the two lines quoted above.
> The right debugging lines may be visible in "debug_options ALL,2 58,5,
> 93,5" output, but it is usually best to share compressed ALL,9 logs
> (privately if needed).
> 
> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>
> 
> 
> Sharing the problematic ICAP response (header) in a raw packet capture
> format (to preserve important details) may also be very useful.
> 
> 
> HTH,
> 
> Alex.
> 
> 

    
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240425/dce138fc/attachment.htm>

From ankor2023 at gmail.com  Thu Apr 25 07:57:06 2024
From: ankor2023 at gmail.com (Andrey K)
Date: Thu, 25 Apr 2024 10:57:06 +0300
Subject: [squid-users] tls_key_log
Message-ID: <CADJd0Y3NTvhknTmOPNcWGRmrgBuRuz7h4JxDv1oY+qHxzfXbdQ@mail.gmail.com>

Hello,

Does squid 6.9 allow you to log TLS 1.3 keys so that you can then decrypt
traffic using Wireshark?
I found that there was an issue earlier with using tls_key_log to decrypt
TLS 1.3:
https://lists.squid-cache.org/pipermail/squid-users/2022-January/024424.html

I tried using tls_key_log on Squid 6.9 to decrypt TLS 1.3, but
without success.
Is work on TLS 1.3 logging support still ongoing?

Kind regards,
      Ankor.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240425/e86b52e5/attachment.htm>

From gkinkie at gmail.com  Thu Apr 25 12:48:36 2024
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Thu, 25 Apr 2024 13:48:36 +0100
Subject: [squid-users] Squid macOS homebrew package doesn't put squid
 files in a neat folder
In-Reply-To: <CAPjdNQqEEk99HS-2UTvYcZ4TeSMmsguxaAT-=FSGDtDDiYJZ2A@mail.gmail.com>
References: <CAPjdNQqEEk99HS-2UTvYcZ4TeSMmsguxaAT-=FSGDtDDiYJZ2A@mail.gmail.com>
Message-ID: <CA+Y8hcMXz66a+=Ou6RnKw-pCcEG9HMqgMuHjNxP3UKSsBBzxQA@mail.gmail.com>

Hello Hima,
   you raise valid points, but to the wrong audience: default locations for
homebrew
installs are determined by the maintainers of the homebrew package, so the
best thing
to do is to reach out to them to see if they're willing to change them.

All paths can be controlled from squid.conf, and the location for
squid.conf itself can be specified
as a command line argument, so you always have the option to adopt the file
structure that works
best for you.

Hope this helps,
  Francesco

On Wed, Apr 24, 2024 at 8:21?PM Hima Tammineedi <hima at withforge.com> wrote:

> Hi,
>
> It seems that on macOS with homebrew, that the squid files are not
> installed in a proper subdirectory like they are on linux.
>
> I installed squid on macOS with `brew install squid`
> I then noticed that the conf file is found at
> `/opt/homebrew/etc/squid.conf`
> And then after some digging and searching, found that the access.log and
> cache.log are at `/opt/homebrew/var/logs/{access,cache}.log`.
>
> But the part that doesn't seem good here is that these files are not being
> put into folders.
> In `/opt/homebrew/etc/` for example, it would be better if the three files
> that squid created: squid.conf, squid.conf.default,
> and squid.conf.documented were put into a subdir like
> `/opt/homebrew/etc/squid/squid.conf` etc.
> That would be better organization.
>
> It's worse for the log files because they are just in the root logs folder
> with generic names "access" and "cache", and so some other program could
> use the same file names and they might overwrite each other!
>
> In linux installs, there is a subdir.
>
> Can this be fixed?
>
> Thanks,
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>


-- 
    Francesco
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240425/23585556/attachment.htm>

From jonathanlee571 at gmail.com  Fri Apr 26 05:15:19 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 25 Apr 2024 22:15:19 -0700
Subject: [squid-users] Best way to utilize time constraints with squid?
Message-ID: <538DBFBB-5CD0-4620-A55E-2A6AF8026EE6@gmail.com>


acl block_hours time 01:30-05:00
ssl_bump terminate all block_hours
http_access deny all block_hours

In this a good way to time lock squid with times lock down?

My goal is to secure non use hours and just lock down squid when it is not being used. Is this the best way to secure the system during 1am to 5am ?

To essentially terminate all connections and block http access.

Sent from my iPhone
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240425/58bbd3e1/attachment.htm>

From squid3 at treenet.co.nz  Sat Apr 27 07:40:50 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 27 Apr 2024 19:40:50 +1200
Subject: [squid-users] Best way to utilize time constraints with squid?
In-Reply-To: <538DBFBB-5CD0-4620-A55E-2A6AF8026EE6@gmail.com>
References: <538DBFBB-5CD0-4620-A55E-2A6AF8026EE6@gmail.com>
Message-ID: <50c94dfb-7c26-4d4e-85f5-975d5fe47f5d@treenet.co.nz>

On 26/04/24 17:15, Jonathan Lee wrote:
> 
> aclblock_hourstime01:30-05:00ssl_bumpterminateallblock_hourshttp_accessdenyallblock_hours
> 
> In this a good way to time lock squid with times lock down?
> 

That depends on your criteria/definition of "good".

Be aware that http_access only checks *new* transactions. Large 
downloads, and long-running transactions such as CONNECT tunnel which 
start during an allowed time will continue running across the disallowed 
time(s).


> 
> To essentially terminate all connections and block http access.
> 

The "terminate all connections" is not enforced by 'time` ACL. Once a 
transaction is allowed to start, it can continue until completion - be 
that milliseconds or days later.


HTH
Amos


From squid3 at treenet.co.nz  Sat Apr 27 07:52:13 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 27 Apr 2024 19:52:13 +1200
Subject: [squid-users] tls_key_log
In-Reply-To: <CADJd0Y3NTvhknTmOPNcWGRmrgBuRuz7h4JxDv1oY+qHxzfXbdQ@mail.gmail.com>
References: <CADJd0Y3NTvhknTmOPNcWGRmrgBuRuz7h4JxDv1oY+qHxzfXbdQ@mail.gmail.com>
Message-ID: <ac63f280-9b4e-4d94-9641-d36a63acc0f1@treenet.co.nz>

On 25/04/24 19:57, Andrey K wrote:
> Hello,
> 
> Does squid 6.9 allow you to log TLS 1.3 keys so that you can then 
> decrypt traffic using Wireshark?
> I found that there was an issue earlier with using tls_key_log to 
> decrypt TLS 1.3: 
> https://lists.squid-cache.org/pipermail/squid-users/2022-January/024424.html <https://lists.squid-cache.org/pipermail/squid-users/2022-January/024424.html>
> 
> I tried using tls_key_log on Squid 6.9 to decrypt TLS 1.3, but 
> without?success.

You answer your own question here.


> Is work on TLS 1.3 logging support still ongoing?
> 

Not specifically. As I understand it logging is not the issue - Squid 
cannot log something it cannot see. TLS support has quieted down in 
recent times, but not stopped.


Cheers
Amos


From ankor2023 at gmail.com  Sat Apr 27 08:38:01 2024
From: ankor2023 at gmail.com (Andrey K)
Date: Sat, 27 Apr 2024 11:38:01 +0300
Subject: [squid-users] tls_key_log
In-Reply-To: <ac63f280-9b4e-4d94-9641-d36a63acc0f1@treenet.co.nz>
References: <CADJd0Y3NTvhknTmOPNcWGRmrgBuRuz7h4JxDv1oY+qHxzfXbdQ@mail.gmail.com>
 <ac63f280-9b4e-4d94-9641-d36a63acc0f1@treenet.co.nz>
Message-ID: <CADJd0Y1ka0SAqiSBPfLTJ28OvUDzW_Ra_1=JbxsGL_iK4+J57A@mail.gmail.com>

Amos, thanks for the answer,

We will be waiting for full support of the TLS key logging.

Kind regards,
       Ankor


??, 27 ???. 2024??. ? 10:52, Amos Jeffries <squid3 at treenet.co.nz>:

> On 25/04/24 19:57, Andrey K wrote:
> > Hello,
> >
> > Does squid 6.9 allow you to log TLS 1.3 keys so that you can then
> > decrypt traffic using Wireshark?
> > I found that there was an issue earlier with using tls_key_log to
> > decrypt TLS 1.3:
> >
> https://lists.squid-cache.org/pipermail/squid-users/2022-January/024424.html
> <
> https://lists.squid-cache.org/pipermail/squid-users/2022-January/024424.html
> >
> >
> > I tried using tls_key_log on Squid 6.9 to decrypt TLS 1.3, but
> > without success.
>
> You answer your own question here.
>
>
> > Is work on TLS 1.3 logging support still ongoing?
> >
>
> Not specifically. As I understand it logging is not the issue - Squid
> cannot log something it cannot see. TLS support has quieted down in
> recent times, but not stopped.
>
>
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240427/b5cf07b7/attachment.htm>

From squid3 at treenet.co.nz  Sat Apr 27 08:52:24 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 27 Apr 2024 20:52:24 +1200
Subject: [squid-users] enctype aes256-cts found in keytab but cannot
 decrypt ticket
In-Reply-To: <CABFnWrRvSfsUMjYpJ96UZ-A2DL-d9wjEPqHs77T-BVu6SsQkJg@mail.gmail.com>
References: <CABFnWrRvSfsUMjYpJ96UZ-A2DL-d9wjEPqHs77T-BVu6SsQkJg@mail.gmail.com>
Message-ID: <d344d297-fcea-4ee4-8d40-3c844366bddb@treenet.co.nz>

On 24/04/24 17:31, ivc chgaki wrote:
> hello. i hve Samba DC and squid. i created user, then SPN, and then 
> exported keytab and imported him to squid. im using kerberos negotiate 
> helper but when i try go to internet i have popup window with 
> login/password and in cace.log log error
> 
> 
> 2024/04/21 21:41:58 kid1| ERROR: Negotiate Authentication validating 
> user. Result: {result=BH, notes={message: gss_accept_sec_context() 
> failed: Unspecified GSS failure.? Minor code may provide more 
> information. Request ticket server 
> HTTP/srv-proxy.mydomain.com at MYADOMAIN.COM kvno 2 enctype aes256-cts 
> found in keytab but cannot decrypt ticket; }}
> 
> 

<https://wiki.articatech.com/proxy-service/troubleshooting/gss-cannot-decrypt-ticket>


HTH
Amos


From squid3 at treenet.co.nz  Sat Apr 27 10:07:30 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 27 Apr 2024 22:07:30 +1200
Subject: [squid-users] Container Based Issues Lock Down Password and
 Terminate SSL
In-Reply-To: <EDB6E1EB-C9AD-4ACB-9ACD-8CFB8D5F8E41@gmail.com>
References: <58c41ee7-b88c-4d5a-bd12-220d44465067@treenet.co.nz>
 <EDB6E1EB-C9AD-4ACB-9ACD-8CFB8D5F8E41@gmail.com>
Message-ID: <bfa1bfec-fda0-48f2-8e05-7c04f9bb60e2@treenet.co.nz>

On 24/04/24 17:27, Jonathan Lee wrote:
> Hello fellow Squid users I wanted to ask a quick question for use with termination would http access for cache still work with this type of setup and custom refresh patterns?
> 
> I think it would terminate all but the clients and if they use the cache it would be ok.
> 

These things are sequential, but otherwise not directly related.

SSL-Bump is about TLS handshake opening a connection from a client.

The "ssl_bump splice" action allows the client connection to go through 
Squid in the form of a blind tunnel. Caching (and thus refresh of cached 
objects) is not applicable to tunneled traffic.


The "ssl_bump terminate" action closes the client connection 
immediately. It should be obvious that nothing can be done in that 
connection once it is closed. HTTP(S) and/or caching are irrelevant - 
they can never happen on a terminated connection.



> But I think an invasive container would be blocked my goal here.
> 
> acl markBumped annotate_client bumped=true
> acl active_use annotate_client active=true
> acl bump_only src 192.168.1.3 #webtv
> acl bump_only src 192.168.1.4 #toshiba
> acl bump_only src 192.168.1.5 #imac
> acl bump_only src 192.168.1.9 #macbook
> acl bump_only src 192.168.1.13 #dell
> 
> acl bump_only_mac arp macaddresshere
> acl bump_only_mac arp macaddresshere
> acl bump_only_mac arp macaddresshere
> acl bump_only_mac arp macaddresshere
> acl bump_only_mac arp macaddresshere
> 
> ssl_bump peek step1
> miss_access deny no_miss active_use
> ssl_bump splice https_login active_use
> ssl_bump splice splice_only_mac splice_only active_use
> ssl_bump splice NoBumpDNS active_use
> ssl_bump splice NoSSLIntercept active_use
> ssl_bump bump bump_only_mac bump_only active_use
> acl activated note active_use true
> ssl_bump terminate !activated
> 
> 


From jonathanlee571 at gmail.com  Sat Apr 27 14:48:17 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sat, 27 Apr 2024 07:48:17 -0700
Subject: [squid-users] Best way to utilize time constraints with squid?
In-Reply-To: <50c94dfb-7c26-4d4e-85f5-975d5fe47f5d@treenet.co.nz>
References: <50c94dfb-7c26-4d4e-85f5-975d5fe47f5d@treenet.co.nz>
Message-ID: <D2550F6D-B0A6-4D9C-A9B3-17B6189ACA6B@gmail.com>

The time constraints for termination do appear to lock out all new connections until that timeframe has elapsed. My devices have connection errors during this duration.

Just to confirm ssl_bump can not be used with time ? Because my connections don?t work during the timeframe so that is a plus. 


Sent from my iPhone

> On Apr 27, 2024, at 00:41, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> ?On 26/04/24 17:15, Jonathan Lee wrote:
>> aclblock_hourstime01:30-05:00ssl_bumpterminateallblock_hourshttp_accessdenyallblock_hours
>> In this a good way to time lock squid with times lock down?
> 
> That depends on your criteria/definition of "good".
> 
> Be aware that http_access only checks *new* transactions. Large downloads, and long-running transactions such as CONNECT tunnel which start during an allowed time will continue running across the disallowed time(s).
> 
> 
>> To essentially terminate all connections and block http access.
> 
> The "terminate all connections" is not enforced by 'time` ACL. Once a transaction is allowed to start, it can continue until completion - be that milliseconds or days later.
> 
> 
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From jonathanlee571 at gmail.com  Sat Apr 27 14:51:48 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sat, 27 Apr 2024 07:51:48 -0700
Subject: [squid-users] Container Based Issues Lock Down Password and
 Terminate SSL
In-Reply-To: <bfa1bfec-fda0-48f2-8e05-7c04f9bb60e2@treenet.co.nz>
References: <bfa1bfec-fda0-48f2-8e05-7c04f9bb60e2@treenet.co.nz>
Message-ID: <7967D268-040A-47FF-9230-CF7B64A5E02D@gmail.com>

Thank you for the reply. Thank you for confirming that the connections that are started are not effected by the last ACL, thus clients not on acls prior would be blocked and not allowed to access the cache. However ones that are would be able to use the cache. 


Jonathan Lee
Adult Student
Sent from my iPhone

> On Apr 27, 2024, at 03:07, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> ?On 24/04/24 17:27, Jonathan Lee wrote:
>> Hello fellow Squid users I wanted to ask a quick question for use with termination would http access for cache still work with this type of setup and custom refresh patterns?
>> I think it would terminate all but the clients and if they use the cache it would be ok.
> 
> These things are sequential, but otherwise not directly related.
> 
> SSL-Bump is about TLS handshake opening a connection from a client.
> 
> The "ssl_bump splice" action allows the client connection to go through Squid in the form of a blind tunnel. Caching (and thus refresh of cached objects) is not applicable to tunneled traffic.
> 
> 
> The "ssl_bump terminate" action closes the client connection immediately. It should be obvious that nothing can be done in that connection once it is closed. HTTP(S) and/or caching are irrelevant - they can never happen on a terminated connection.
> 
> 
> 
>> But I think an invasive container would be blocked my goal here.
>> acl markBumped annotate_client bumped=true
>> acl active_use annotate_client active=true
>> acl bump_only src 192.168.1.3 #webtv
>> acl bump_only src 192.168.1.4 #toshiba
>> acl bump_only src 192.168.1.5 #imac
>> acl bump_only src 192.168.1.9 #macbook
>> acl bump_only src 192.168.1.13 #dell
>> acl bump_only_mac arp macaddresshere
>> acl bump_only_mac arp macaddresshere
>> acl bump_only_mac arp macaddresshere
>> acl bump_only_mac arp macaddresshere
>> acl bump_only_mac arp macaddresshere
>> ssl_bump peek step1
>> miss_access deny no_miss active_use
>> ssl_bump splice https_login active_use
>> ssl_bump splice splice_only_mac splice_only active_use
>> ssl_bump splice NoBumpDNS active_use
>> ssl_bump splice NoSSLIntercept active_use
>> ssl_bump bump bump_only_mac bump_only active_use
>> acl activated note active_use true
>> ssl_bump terminate !activated
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From jonathanlee571 at gmail.com  Mon Apr 29 16:54:26 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 29 Apr 2024 09:54:26 -0700
Subject: [squid-users] Best way to utilize time constraints with squid?
In-Reply-To: <D2550F6D-B0A6-4D9C-A9B3-17B6189ACA6B@gmail.com>
References: <D2550F6D-B0A6-4D9C-A9B3-17B6189ACA6B@gmail.com>
Message-ID: <D8D0997C-83B8-4707-B770-BBC76FE167AB@gmail.com>

Squid -k parse also does not fail with use of the time ACL 
Sent from my iPhone

> On Apr 27, 2024, at 07:49, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> ?The time constraints for termination do appear to lock out all new connections until that timeframe has elapsed. My devices have connection errors during this duration.
> 
> Just to confirm ssl_bump can not be used with time ? Because my connections don?t work during the timeframe so that is a plus.
> 
> 
> Sent from my iPhone
> 
>>> On Apr 27, 2024, at 00:41, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>> 
>>> ?On 26/04/24 17:15, Jonathan Lee wrote:
>>> aclblock_hourstime01:30-05:00ssl_bumpterminateallblock_hourshttp_accessdenyallblock_hours
>>> In this a good way to time lock squid with times lock down?
>> 
>> That depends on your criteria/definition of "good".
>> 
>> Be aware that http_access only checks *new* transactions. Large downloads, and long-running transactions such as CONNECT tunnel which start during an allowed time will continue running across the disallowed time(s).
>> 
>> 
>>> To essentially terminate all connections and block http access.
>> 
>> The "terminate all connections" is not enforced by 'time` ACL. Once a transaction is allowed to start, it can continue until completion - be that milliseconds or days later.
>> 
>> 
>> HTH
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users


From s_p_arun at yahoo.com  Mon Apr 29 17:06:40 2024
From: s_p_arun at yahoo.com (Arun Kumar)
Date: Mon, 29 Apr 2024 17:06:40 +0000 (UTC)
Subject: [squid-users] Error from icap during respmod
References: <166088187.5074521.1714410400274.ref@mail.yahoo.com>
Message-ID: <166088187.5074521.1714410400274@mail.yahoo.com>

Configured python based icap server (pyicap) and getting 500 Internal Server error during respmod.https://drive.google.com/file/d/19yirXfxKli7NXon4ewiy-v3GpLvECT1i/view?usp=sharing

Squid configuration:icap_enable onicap_send_client_ip onicap_send_client_username onicap_client_username_encode officap_client_username_header X-Authenticated-Usericap_preview_enable onicap_preview_size 1024
icap_service service_req reqmod_precache bypass=0 icap://127.0.0.1:13440/exampleicap_service service_resp respmod_precache bypass=0 icap://127.0.0.1:13441/example

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240429/37c90e8b/attachment.htm>

