From codemarauder at gmail.com  Wed Jul  3 13:27:10 2024
From: codemarauder at gmail.com (Nishant Sharma)
Date: Wed, 3 Jul 2024 18:57:10 +0530
Subject: [squid-users] FATAL: assertion failed: mem/PageStack.cc:159:
 "StoredNode().is_lock_free()"
In-Reply-To: <c9cda733-0838-4cd6-a269-11efcaff80e9@gmail.com>
References: <f399b9c1-9b62-4de2-81d3-893d5eb22fa7@gmail.com>
 <f07dddcd-8f6e-422e-b21b-9b9d9a60c718@measurement-factory.com>
 <91526e3e-39cf-4ba5-9aac-a90729170993@gmail.com>
 <6deef121-649e-4d70-b5fb-92dbc4ec05db@measurement-factory.com>
 <c9cda733-0838-4cd6-a269-11efcaff80e9@gmail.com>
Message-ID: <1cde8458-00c3-4c01-af34-361402283feb@gmail.com>

Hello,

On 28/06/24 20:01, Nishant Sharma wrote:
> On 28/06/24 19:44, Alex Rousskov wrote:
>> I do not know the answer to your question. SMP performance penalties 
>> are often smaller for smaller cache sizes, but cache size is not the 
>> only performance-affecting locking-sensitive parameter, so YMMV.
> 
> I was able to compile after commenting the specific line of code. Squid 
> workers start and I am able to bind them to specific CPU cores.

I had reported the issue to Openwrt project as well and I understood 
that in order to save space, squid was being compiled for mips16 instead 
of mips32.

Even after compiling it for mips32 (by adding a flag for the build 
system), the error is still occuring as in the code in 
`ipc/mem/PageStack.h` `uint64_t` is specified.

I was able to compile by replacing `uint64_t` to `uint32_t` and squid 
worked with workers > 1.

Further discussion on Openwrt issue tracker suggested [1] the following:

<quote>
The posix definition is that lock ID is native integer. It should be 
some conditional in ./configure style portability of squid to run on 
(most) 32bit platforms.
</quote>

Is there any change that we need to do in the configure script to check 
for the availability of 64 bit atomic lock and use 32 bit lock if not 
available?

Or may be document the fact that it is not advisable / possible to run 
squid in SMP mode on such platforms that are not able to provide 64 bit 
lock ID.

I tried to go through config.log and could see the following messages 
which might or might not be related to this:

<config.log>
...
...
...

configure:46036: checking for uint64_t
configure:46036: $? = 0
configure:46036: result: yes

AND

configure:46027: checking for int64_t

configure:46027: mipsel-openwrt-linux-musl-g++ -std=c++17 -c 
-I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include 
-I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include 
  -Os -pipe -mno-branch-likely -mips32r2 -mtune=24kc -fno-caller-saves 
-fno-plt -fhonour-copts -msoft-float 
-fmacro-prefix-map=/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/build_dir/target-mipsel_24kc_musl/squid-6.10=squid-6.10 
-Wformat -Werror=format-security -fstack-protector -D_FORTIFY_SOURCE=1 
-Wl,-z,now -Wl,-z,relro -Wno-error 
-I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include 
-I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include/libxml2 
-I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/toolchain-mipsel_24kc_gcc-12.3.0_musl/usr/include 
-I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/toolchain-mipsel_24kc_gcc-12.3.0_musl/include/fortify 
-I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/toolchain-mipsel_24kc_gcc-12.3.0_musl/include 
  conftest.cpp >&5
configure:46027: $? = 0

configure:46027: mipsel-openwrt-linux-musl-g++ -std=c++17 -c 
-I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include 
-I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include 
  -Os -pipe -mno-branch-likely -mips32r2 -mtune=24kc -fno-caller-saves 
-fno-plt -fhonour-copts -msoft-float 
-fmacro-prefix-map=/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/build_dir/target-mipsel_24kc_musl/squid-6.10=squid-6.10 
-Wformat -Werror=format-security -fstack-protector -D_FORTIFY_SOURCE=1 
-Wl,-z,now -Wl,-z,relro -Wno-error 
-I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include 
-I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include/libxml2 
-I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/toolchain-mipsel_24kc_gcc-12.3.0_musl/usr/include 
-I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/toolchain-mipsel_24kc_gcc-12.3.0_musl/include/fortify 
-I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/toolchain-mipsel_24kc_gcc-12.3.0_musl/include 
  conftest.cpp >&5

conftest.cpp: In function 'int main()':
conftest.cpp:324:67: warning: integer overflow in expression of type 
'int64_t' {aka 'long long int'} results in '-9223372036854775808' 
[-Woverflow]
   324 |                  < (int64_t) (((((int64_t) 1 << N) << N) - 1) * 
2 + 2))];
       | 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~
conftest.cpp:323:26: error: size '-1' of array 'test_array' is negative
   323 | static int test_array [1 - 2 * !((int64_t) (((((int64_t) 1 << 
N) << N) - 1) * 2 + 1)
       | 
~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   324 |                  < (int64_t) (((((int64_t) 1 << N) << N) - 1) * 
2 + 2))];
       | 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
configure:46027: $? = 1

configure: failed program was:
| /* confdefs.h */
| #define PACKAGE_NAME "Squid Web Proxy"
| #define PACKAGE_TARNAME "squid"
| #define PACKAGE_VERSION "6.10"
| #define PACKAGE_STRING "Squid Web Proxy 6.10"
| #define PACKAGE_BUGREPORT "https://bugs.squid-cache.org/"
| #define PACKAGE_URL ""
...
...
...
...
</config.log>

Regards,
Nishant

* [1] 
https://github.com/openwrt/packages/issues/24469#issuecomment-2203033868


From jonathanlee571 at gmail.com  Wed Jul  3 15:28:07 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 3 Jul 2024 08:28:07 -0700
Subject: [squid-users] Speed issues
Message-ID: <85D48B01-F0F4-4C8F-AFE3-4D39D3AA51AB@gmail.com>

Does anyone have tips for getting the proxy to run faster when SSL intercept is enabled along side splice lists with dynamic cache and ClamAV running?


I just seems to have slow traffic on the interception side. 
Sent from my iPhone

From rousskov at measurement-factory.com  Wed Jul  3 15:57:31 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 3 Jul 2024 11:57:31 -0400
Subject: [squid-users] FATAL: assertion failed: mem/PageStack.cc:159:
 "StoredNode().is_lock_free()"
In-Reply-To: <1cde8458-00c3-4c01-af34-361402283feb@gmail.com>
References: <f399b9c1-9b62-4de2-81d3-893d5eb22fa7@gmail.com>
 <f07dddcd-8f6e-422e-b21b-9b9d9a60c718@measurement-factory.com>
 <91526e3e-39cf-4ba5-9aac-a90729170993@gmail.com>
 <6deef121-649e-4d70-b5fb-92dbc4ec05db@measurement-factory.com>
 <c9cda733-0838-4cd6-a269-11efcaff80e9@gmail.com>
 <1cde8458-00c3-4c01-af34-361402283feb@gmail.com>
Message-ID: <d11426f0-a401-4900-8e2c-e08544a388df@measurement-factory.com>

On 2024-07-03 09:27, Nishant Sharma wrote:

> I had reported the issue to Openwrt project as well and I understood 
> that in order to save space, squid was being compiled for mips16 instead 
> of mips32.

Sorry, I do not know why/how that fact is relevant to this discussion, 
but thank you for sharing it as it may be useful for others.


> Even after compiling it for mips32 (by adding a flag for the build 
> system), the error is still occuring as in the code in 
> `ipc/mem/PageStack.h` `uint64_t` is specified.

Glad to hear that: That assertion should not depend on those build flags 
AFAICT.


> I was able to compile by replacing `uint64_t` to `uint32_t` and squid 
> worked with workers > 1.

Where did you replace uint64_t with uint32_t? In IdSet::Node typedef? 
Any other changes? AFAICT, changing just IdSet::Node badly breaks the 
corresponding binary tree code because we hard-code the number of bits 
per leaf node (at least!) to be 64. I did not audit code for other 
dependencies.


> Further discussion on Openwrt issue tracker suggested [1] the following:
> 
> <quote>
> The posix definition is that lock ID is native integer. It should be 
> some conditional in ./configure style portability of squid to run on 
> (most) 32bit platforms.
> </quote>

It is possible that the above comment was negatively influenced by the 
previous misleading statement about Squid v4 having no uint64_t: "In 
code for version 4.x, there is no mention of uint64_t. It was introduced 
with 5.x." In reality, Squid has been using 64-bit integers since before 
Squid v3. It is neither practical nor necessary to remove uint64_t from 
Squid so there will be no corresponding conditionals in ./configure.

The shared binary tree (that contains the assertion) did not exist in 
v4, as we discussed earlier.


> Is there any change that we need to do in the configure script to check 
> for the availability of 64 bit atomic lock and use 32 bit lock if not 
> available?

It is technically possible (perhaps even without ./configure checks), 
but it would require adjusting complex shared tree code in the abcense 
of comprehensive ready-to-use tests. It is trivial to break that code. 
It is difficult to detect bugs. IMO, we should not expose ourselves to 
such risks in this case, especially since Squid uses 64-bit atomics in 
many other places: Supporting 32 bits in shared binary tree nodes is not 
going to remove the last frequently used 64-bit lock.


> Or may be document the fact that it is not advisable / possible to run 
> squid in SMP mode on such platforms that are not able to provide 64 bit 
> lock ID.

I believe your experiments with removing the assertion point in a rather 
different direction: If your tests do not suggest otherwise, we should 
downgrade that assertion to a startup warning. Let folks run Squid on 
platforms without 64-bit atomic locks (if they wish to do so), but warn 
them about an uncertain impact. Perhaps we can even convince ourselves 
that the impact can only be on performance (i.e., there can be no 
deadlocks due to mutexes).

Disclaimer: I do not know what "lock ID" is in this context.


HTH,

Alex.


> I tried to go through config.log and could see the following messages 
> which might or might not be related to this:
> 
> <config.log>
> ...
> ...
> ...
> 
> configure:46036: checking for uint64_t
> configure:46036: $? = 0
> configure:46036: result: yes
> 
> AND
> 
> configure:46027: checking for int64_t
> 
> configure:46027: mipsel-openwrt-linux-musl-g++ -std=c++17 -c 
> -I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include -I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include ?-Os -pipe -mno-branch-likely -mips32r2 -mtune=24kc -fno-caller-saves -fno-plt -fhonour-copts -msoft-float -fmacro-prefix-map=/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/build_dir/target-mipsel_24kc_musl/squid-6.10=squid-6.10 -Wformat -Werror=format-security -fstack-protector -D_FORTIFY_SOURCE=1 -Wl,-z,now -Wl,-z,relro -Wno-error -I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include -I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include/libxml2 -I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/toolchain-mipsel_24kc_gcc-12.3.0_musl/usr/include -I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/toolchain-mipsel_24kc_gcc-12.3.0_musl/include/fortify -I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/toolchain-mipsel_24kc_gcc-12.3.0_musl/include ?conftest.cpp >&5
> configure:46027: $? = 0
> 
> configure:46027: mipsel-openwrt-linux-musl-g++ -std=c++17 -c 
> -I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include -I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include ?-Os -pipe -mno-branch-likely -mips32r2 -mtune=24kc -fno-caller-saves -fno-plt -fhonour-copts -msoft-float -fmacro-prefix-map=/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/build_dir/target-mipsel_24kc_musl/squid-6.10=squid-6.10 -Wformat -Werror=format-security -fstack-protector -D_FORTIFY_SOURCE=1 -Wl,-z,now -Wl,-z,relro -Wno-error -I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include -I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/target-mipsel_24kc_musl/usr/include/libxml2 -I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/toolchain-mipsel_24kc_gcc-12.3.0_musl/usr/include -I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/toolchain-mipsel_24kc_gcc-12.3.0_musl/include/fortify -I/home/devuser/openwrt-23.05/arthur/mt7621/openwrt/staging_dir/toolchain-mipsel_24kc_gcc-12.3.0_musl/include ?conftest.cpp >&5
> 
> conftest.cpp: In function 'int main()':
> conftest.cpp:324:67: warning: integer overflow in expression of type 
> 'int64_t' {aka 'long long int'} results in '-9223372036854775808' 
> [-Woverflow]
>  ? 324 |????????????????? < (int64_t) (((((int64_t) 1 << N) << N) - 1) * 
> 2 + 2))];
>  ????? | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~
> conftest.cpp:323:26: error: size '-1' of array 'test_array' is negative
>  ? 323 | static int test_array [1 - 2 * !((int64_t) (((((int64_t) 1 << 
> N) << N) - 1) * 2 + 1)
>  ????? | ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>  ? 324 |????????????????? < (int64_t) (((((int64_t) 1 << N) << N) - 1) * 
> 2 + 2))];
>  ????? | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> configure:46027: $? = 1
> 
> configure: failed program was:
> | /* confdefs.h */
> | #define PACKAGE_NAME "Squid Web Proxy"
> | #define PACKAGE_TARNAME "squid"
> | #define PACKAGE_VERSION "6.10"
> | #define PACKAGE_STRING "Squid Web Proxy 6.10"
> | #define PACKAGE_BUGREPORT "https://bugs.squid-cache.org/"
> | #define PACKAGE_URL ""
> ...
> ...
> ...
> ...
> </config.log>
> 
> Regards,
> Nishant
> 
> * [1] 
> https://github.com/openwrt/packages/issues/24469#issuecomment-2203033868


From jonathanlee571 at gmail.com  Wed Jul  3 17:56:38 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 3 Jul 2024 10:56:38 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
Message-ID: <3E8A3F50-0BD8-407D-9860-06F5BCB255A2@gmail.com>

Hello fellow Squid users does anyone know how to fix this issue?

Squid - Cache Logs
Date-Time	Message
31.12.1969 16:00:00	
03.07.2024 10:54:34	kick abandoning conn7853 local=192.168.1.1:3128 remote=192.168.1.5:49710 FD 89 flags=1
31.12.1969 16:00:00	
03.07.2024 10:54:29	kick abandoning conn7844 local=192.168.1.1:3128 remote=192.168.1.5:49702 FD 81 flags=1
03.07.2024 10:54:09	ERROR: failure while accepting a TLS connection on conn7648 local=192.168.1.1:3128 remote=192.168.1.5:49672 FD 44 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
03.07.2024 10:54:09	ERROR: failure while accepting a TLS connection on conn7647 local=192.168.1.1:3128 remote=192.168.1.5:49670 FD 43 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
03.07.2024 10:54:09	ERROR: failure while accepting a TLS connection on conn7646 local=192.168.1.1:3128 remote=192.168.1.5:49668 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
03.07.2024 10:53:04	ERROR: failure while accepting a TLS connection on conn7367 local=192.168.1.1:3128 remote=192.168.1.5:49627 FD 22 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
03.07.2024 10:52:47	ERROR: failure while accepting a TLS connection on conn7345 local=192.168.1.1:3128 remote=192.168.1.5:49618 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
03.07.2024 10:52:38	ERROR: failure while accepting a TLS connection on conn7340 local=192.168.1.1:3128 remote=192.168.1.5:49616 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
03.07.2024 10:52:34	ERROR: failure while accepting a TLS connection on conn7316 local=192.168.1.1:3128 remote=192.168.1.5:49609 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
31.12.1969 16:00:00	
03.07.2024 10:51:55	WARNING: Error Pages Missing Language: en-us
31.12.1969 16:00:00	
03.07.2024 10:51:55	ERROR: loading file 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': (2) No such file or directory
03.07.2024 10:51:44	ERROR: failure while accepting a TLS connection on conn7102 local=192.168.1.1:3128 remote=192.168.1.5:49574 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
03.07.2024 10:51:28	ERROR: failure while accepting a TLS connection on conn7071 local=192.168.1.1:3128 remote=192.168.1.5:49568 FD 92 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
03.07.2024 10:50:29	ERROR: failure while accepting a TLS connection on conn6944 local=192.168.1.1:3128 remote=192.168.1.5:49534 FD 101 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
03.07.2024 10:49:54	ERROR: failure while accepting a TLS connection on conn6866 local=192.168.1.1:3128 remote=192.168.1.5:49519 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
03.07.2024 10:49:38	ERROR: failure while accepting a TLS connection on conn6809 local=192.168.1.1:3128 remote=192.168.1.5:49503 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
31.12.1969 16:00:00	
03.07.2024 10:49:32	ERROR: system call failure while accepting a TLS connection on conn6794 local=192.168.1.1:3128 remote=192.168.1.5:49496 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
03.07.2024 10:49:24	ERROR: failure while accepting a TLS connection on conn6776 local=192.168.1.1:3128 remote=192.168.1.5:49481 FD 137 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
03.07.2024 10:48:49	ERROR: failure while accepting a TLS connection on conn6440 local=192.168.1.1:3128 remote=192.168.1.5:49424 FD 16 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
03.07.2024 10:48:49	ERROR: failure while accepting a TLS connection on conn6445 local=192.168.1.1:3128 remote=192.168.1.5:49426 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
03.07.2024 10:48:22	ERROR: failure while accepting a TLS connection on conn6035 local=192.168.1.1:3128 remote=192.168.1.5:49355 FD 226 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
03.07.2024 10:48:09	ERROR: failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128 remote=192.168.1.5:49318 FD 33 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
03.07.2024 10:48:09	ERROR: failure while accepting a TLS connection on conn5875 local=192.168.1.1:3128 remote=192.168.1.5:49312 FD 216 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
03.07.2024 10:48:09	ERROR: failure while accepting a TLS connection on conn5876 local=192.168.1.1:3128 remote=192.168.1.5:49314 FD 217 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
03.07.2024 10:47:57	ERROR: failure while accepting a TLS connection on conn5815 local=192.168.1.1:3128 remote=192.168.1.5:49297 FD 201 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
03.07.2024 10:47:54	ERROR: failure while accepting a TLS connection on conn5760 local=192.168.1.1:3128 remote=192.168.1.5:49289 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
03.07.2024 10:47:52	ERROR: failure while accepting a TLS connection on conn5717 local=192.168.1.1:3128 remote=192.168.1.5:49284 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
03.07.2024 10:47:50	ERROR: failure while accepting a TLS connection on conn5552 local=192.168.1.1:3128 remote=192.168.1.5:49268 FD 142 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
31.12.1969 16:00:00	
03.07.2024 10:47:34	kick abandoning conn5254 local=192.168.1.1:3128 remote=192.168.1.5:49209 FD 100 flags=1
31.12.1969 16:00:00	
03.07.2024 10:47:21	kick abandoning conn5022 local=192.168.1.1:3128 remote=192.168.1.5:49167 FD 37 flags=1
31.12.1969 16:00:00	
03.07.2024 10:47:21	kick abandoning conn5020 local=192.168.1.1:3128 remote=192.168.1.5:49165 FD 36 flags=1
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00	
03.07.2024 10:42:22	WARNING: Forwarding loop detected for:
03.07.2024 10:40:08	ERROR: failure while accepting a TLS connection on conn4955 local=192.168.1.1:3128 remote=192.168.1.5:52339 FD 98 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
31.12.1969 16:00:00	
03.07.2024 10:39:52	kick abandoning conn4927 local=192.168.1.1:3128 remote=192.168.1.5:52331 FD 105 flags=1
03.07.2024 10:39:09	ERROR: failure while accepting a TLS connection on conn4846 local=192.168.1.1:3128 remote=192.168.1.5:52314 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
03.07.2024 10:38:14	ERROR: failure while accepting a TLS connection on conn4650 local=192.168.1.1:3128 remote=192.168.1.5:52274 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
03.07.2024 10:38:08	ERROR: failure while accepting a TLS connection on conn4645 local=192.168.1.1:3128 remote=192.168.1.5:52272 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
03.07.2024 10:38:04	ERROR: Unsupported TLS option SINGLE_ECDH_USE
03.07.2024 10:38:04	ERROR: Unsupported TLS option SINGLE_DH_USE
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240703/ec5f7907/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jul  4 02:34:11 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 3 Jul 2024 19:34:11 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <3E8A3F50-0BD8-407D-9860-06F5BCB255A2@gmail.com>
References: <3E8A3F50-0BD8-407D-9860-06F5BCB255A2@gmail.com>
Message-ID: <9FB6F87F-E550-4594-81C8-832D28EBDE27@gmail.com>

I forgot to mention my certificates I use on squid was generated from this method 

openssl req -x509 -new -nodes -key myProxykey.key -sha256 -days 365 -out myProxyca.pem


Sent from my iPhone

> On Jul 3, 2024, at 10:56, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> ?Hello fellow Squid users does anyone know how to fix this issue?
> 
> Squid - Cache Logs
> Date-Time	Message
> 31.12.1969 16:00:00	
> 03.07.2024 10:54:34	kick abandoning conn7853 local=192.168.1.1:3128 remote=192.168.1.5:49710 FD 89 flags=1
> 31.12.1969 16:00:00	
> 03.07.2024 10:54:29	kick abandoning conn7844 local=192.168.1.1:3128 remote=192.168.1.5:49702 FD 81 flags=1
> 03.07.2024 10:54:09	ERROR: failure while accepting a TLS connection on conn7648 local=192.168.1.1:3128 remote=192.168.1.5:49672 FD 44 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:54:09	ERROR: failure while accepting a TLS connection on conn7647 local=192.168.1.1:3128 remote=192.168.1.5:49670 FD 43 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:54:09	ERROR: failure while accepting a TLS connection on conn7646 local=192.168.1.1:3128 remote=192.168.1.5:49668 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:53:04	ERROR: failure while accepting a TLS connection on conn7367 local=192.168.1.1:3128 remote=192.168.1.5:49627 FD 22 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:52:47	ERROR: failure while accepting a TLS connection on conn7345 local=192.168.1.1:3128 remote=192.168.1.5:49618 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:52:38	ERROR: failure while accepting a TLS connection on conn7340 local=192.168.1.1:3128 remote=192.168.1.5:49616 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:52:34	ERROR: failure while accepting a TLS connection on conn7316 local=192.168.1.1:3128 remote=192.168.1.5:49609 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 31.12.1969 16:00:00	
> 03.07.2024 10:51:55	WARNING: Error Pages Missing Language: en-us
> 31.12.1969 16:00:00	
> 03.07.2024 10:51:55	ERROR: loading file 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': (2) No such file or directory
> 03.07.2024 10:51:44	ERROR: failure while accepting a TLS connection on conn7102 local=192.168.1.1:3128 remote=192.168.1.5:49574 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:51:28	ERROR: failure while accepting a TLS connection on conn7071 local=192.168.1.1:3128 remote=192.168.1.5:49568 FD 92 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:50:29	ERROR: failure while accepting a TLS connection on conn6944 local=192.168.1.1:3128 remote=192.168.1.5:49534 FD 101 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:49:54	ERROR: failure while accepting a TLS connection on conn6866 local=192.168.1.1:3128 remote=192.168.1.5:49519 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:49:38	ERROR: failure while accepting a TLS connection on conn6809 local=192.168.1.1:3128 remote=192.168.1.5:49503 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 31.12.1969 16:00:00	
> 03.07.2024 10:49:32	ERROR: system call failure while accepting a TLS connection on conn6794 local=192.168.1.1:3128 remote=192.168.1.5:49496 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
> 03.07.2024 10:49:24	ERROR: failure while accepting a TLS connection on conn6776 local=192.168.1.1:3128 remote=192.168.1.5:49481 FD 137 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:48:49	ERROR: failure while accepting a TLS connection on conn6440 local=192.168.1.1:3128 remote=192.168.1.5:49424 FD 16 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:48:49	ERROR: failure while accepting a TLS connection on conn6445 local=192.168.1.1:3128 remote=192.168.1.5:49426 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:48:22	ERROR: failure while accepting a TLS connection on conn6035 local=192.168.1.1:3128 remote=192.168.1.5:49355 FD 226 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:48:09	ERROR: failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128 remote=192.168.1.5:49318 FD 33 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:48:09	ERROR: failure while accepting a TLS connection on conn5875 local=192.168.1.1:3128 remote=192.168.1.5:49312 FD 216 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:48:09	ERROR: failure while accepting a TLS connection on conn5876 local=192.168.1.1:3128 remote=192.168.1.5:49314 FD 217 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:47:57	ERROR: failure while accepting a TLS connection on conn5815 local=192.168.1.1:3128 remote=192.168.1.5:49297 FD 201 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:47:54	ERROR: failure while accepting a TLS connection on conn5760 local=192.168.1.1:3128 remote=192.168.1.5:49289 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:47:52	ERROR: failure while accepting a TLS connection on conn5717 local=192.168.1.1:3128 remote=192.168.1.5:49284 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:47:50	ERROR: failure while accepting a TLS connection on conn5552 local=192.168.1.1:3128 remote=192.168.1.5:49268 FD 142 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 31.12.1969 16:00:00	
> 03.07.2024 10:47:34	kick abandoning conn5254 local=192.168.1.1:3128 remote=192.168.1.5:49209 FD 100 flags=1
> 31.12.1969 16:00:00	
> 03.07.2024 10:47:21	kick abandoning conn5022 local=192.168.1.1:3128 remote=192.168.1.5:49167 FD 37 flags=1
> 31.12.1969 16:00:00	
> 03.07.2024 10:47:21	kick abandoning conn5020 local=192.168.1.1:3128 remote=192.168.1.5:49165 FD 36 flags=1
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 03.07.2024 10:42:22	WARNING: Forwarding loop detected for:
> 03.07.2024 10:40:08	ERROR: failure while accepting a TLS connection on conn4955 local=192.168.1.1:3128 remote=192.168.1.5:52339 FD 98 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 31.12.1969 16:00:00	
> 03.07.2024 10:39:52	kick abandoning conn4927 local=192.168.1.1:3128 remote=192.168.1.5:52331 FD 105 flags=1
> 03.07.2024 10:39:09	ERROR: failure while accepting a TLS connection on conn4846 local=192.168.1.1:3128 remote=192.168.1.5:52314 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:38:14	ERROR: failure while accepting a TLS connection on conn4650 local=192.168.1.1:3128 remote=192.168.1.5:52274 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:38:08	ERROR: failure while accepting a TLS connection on conn4645 local=192.168.1.1:3128 remote=192.168.1.5:52272 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:38:04	ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 03.07.2024 10:38:04	ERROR: Unsupported TLS option SINGLE_DH_USE
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240703/0cd876bb/attachment.htm>

From codemarauder at gmail.com  Thu Jul  4 08:57:51 2024
From: codemarauder at gmail.com (Nishant Sharma)
Date: Thu, 4 Jul 2024 14:27:51 +0530
Subject: [squid-users] FATAL: assertion failed: mem/PageStack.cc:159:
 "StoredNode().is_lock_free()"
In-Reply-To: <d11426f0-a401-4900-8e2c-e08544a388df@measurement-factory.com>
References: <f399b9c1-9b62-4de2-81d3-893d5eb22fa7@gmail.com>
 <f07dddcd-8f6e-422e-b21b-9b9d9a60c718@measurement-factory.com>
 <91526e3e-39cf-4ba5-9aac-a90729170993@gmail.com>
 <6deef121-649e-4d70-b5fb-92dbc4ec05db@measurement-factory.com>
 <c9cda733-0838-4cd6-a269-11efcaff80e9@gmail.com>
 <1cde8458-00c3-4c01-af34-361402283feb@gmail.com>
 <d11426f0-a401-4900-8e2c-e08544a388df@measurement-factory.com>
Message-ID: <19461178-4d1c-49e6-b9d7-611596689f8a@gmail.com>

On 03/07/24 21:27, Alex Rousskov wrote:
> On 2024-07-03 09:27, Nishant Sharma wrote:
>> I was able to compile by replacing `uint64_t` to `uint32_t` and squid 
>> worked with workers > 1.
> 
> Where did you replace uint64_t with uint32_t? In IdSet::Node typedef? 
> Any other changes? AFAICT, changing just IdSet::Node badly breaks the 
> corresponding binary tree code because we hard-code the number of bits 
> per leaf node (at least!) to be 64. I did not audit code for other 
> dependencies.

In the code for squid-6.10, in ipc/mem/PageStack.h there is just one 
occurrence of `uint64_t` at line 79 inside class IdSet. I had changed 
that. But now I understand that I don't have to, rolled it back.

class IdSet
{
public:
    using size_type = IdSetMeasurement::size_type;
    using Position = IdSetPosition;
...
...
...
private:
    typedef uint64_t Node; ///< either leaf or intermediate node
    typedef std::atomic<Node> StoredNode; ///< a Node stored in shared 
memory
...
...
    // No more data members should follow! See FlexibleArray<> for details.
};

>> Further discussion on Openwrt issue tracker suggested [1] the following:
>>
> 
> It is possible that the above comment was negatively influenced by the 
> previous misleading statement about Squid v4 having no uint64_t: "In 
> code for version 4.x, there is no mention of uint64_t. It was introduced 
> with 5.x." In reality, Squid has been using 64-bit integers since before 
> Squid v3. It is neither practical nor necessary to remove uint64_t from 
> Squid so there will be no corresponding conditionals in ./configure.

That was due to my comment there. I actually meant to convey that I 
couldn't find a reference to `uint64_t` in the PageStack.cc file as I 
simply knew that the assert error message is being generated from the 
code in this file.

> The shared binary tree (that contains the assertion) did not exist in 
> v4, as we discussed earlier.

Ack. This is the correct statement that I should have used while 
replying on Openwrt issue tracker.

>> Is there any change that we need to do in the configure script to 
>> check for the availability of 64 bit atomic lock and use 32 bit lock 
>> if not available?
> 
> It is technically possible (perhaps even without ./configure checks), 
> but it would require adjusting complex shared tree code in the abcense 
> of comprehensive ready-to-use tests. It is trivial to break that code. 
> It is difficult to detect bugs. IMO, we should not expose ourselves to 
> such risks in this case, especially since Squid uses 64-bit atomics in 
> many other places: Supporting 32 bits in shared binary tree nodes is not 
> going to remove the last frequently used 64-bit lock.

Just being curious here, if a certain platform (mips32 in this case) is 
unable to guarantee a 64 bit atomic lock, other functions except SMP 
mode might get affected as well?

>> Or may be document the fact that it is not advisable / possible to run 
>> squid in SMP mode on such platforms that are not able to provide 64 
>> bit lock ID.
> 
> I believe your experiments with removing the assertion point in a rather 
> different direction: If your tests do not suggest otherwise, we should 
> downgrade that assertion to a startup warning. Let folks run Squid on 
> platforms without 64-bit atomic locks (if they wish to do so), but warn 
> them about an uncertain impact. Perhaps we can even convince ourselves 
> that the impact can only be on performance (i.e., there can be no 
> deadlocks due to mutexes).
> 
> Disclaimer: I do not know what "lock ID" is in this context.

I am not a programmer and not very well versed with a lot of these 
terms, so I have mixed / messed up while passing messages between the 
two forums.

"lock ID" term was used on Openwrt issue tracker where it was suggested 
that "The assertion assumes 64bit lock id.". [1]

Let me experiment with squid-6.x on these devices and also use them in 
the live environment.

The only change being commenting out the following line from 
ipc/mem/PageStack.c:

`assertion(StoredNode().is_lock_free());`

I will report back with success or any failures encountered.

Regards,
Nishant

[1] 
"https://github.com/openwrt/packages/issues/24469#issuecomment-2202322703"


From juergen.3.wagner at continental-corporation.com  Thu Jul  4 13:20:23 2024
From: juergen.3.wagner at continental-corporation.com (Wagner, Juergen03)
Date: Thu, 4 Jul 2024 13:20:23 +0000
Subject: [squid-users] Squid as http to https forward proxy
Message-ID: <AS8PR03MB8072C9DC3302D4535EBC5C28CADE2@AS8PR03MB8072.eurprd03.prod.outlook.com>

Hello forum,
we are evaluating Squid to be used as a http to https forward proxy.

So Squid would need to support the following setup:

    http (client)    ---->   Squid  --->  https ( server )

I have searched the mailing list and didn?t find a proper answer.

Could someone please confirm if the given setup is in principle possible with Squid?
If yes, which configuration needs to be done?

Currently we do a rewrite-url only and we do get a ?Bad Gateway error?

Output of the rewriter:
OK rewrite-url=https://www.example.com


Thanks in advance for a response,
Juergen


Internal
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240704/bcd11d30/attachment.htm>

From rousskov at measurement-factory.com  Thu Jul  4 14:24:57 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 4 Jul 2024 10:24:57 -0400
Subject: [squid-users] FATAL: assertion failed: mem/PageStack.cc:159:
 "StoredNode().is_lock_free()"
In-Reply-To: <19461178-4d1c-49e6-b9d7-611596689f8a@gmail.com>
References: <f399b9c1-9b62-4de2-81d3-893d5eb22fa7@gmail.com>
 <f07dddcd-8f6e-422e-b21b-9b9d9a60c718@measurement-factory.com>
 <91526e3e-39cf-4ba5-9aac-a90729170993@gmail.com>
 <6deef121-649e-4d70-b5fb-92dbc4ec05db@measurement-factory.com>
 <c9cda733-0838-4cd6-a269-11efcaff80e9@gmail.com>
 <1cde8458-00c3-4c01-af34-361402283feb@gmail.com>
 <d11426f0-a401-4900-8e2c-e08544a388df@measurement-factory.com>
 <19461178-4d1c-49e6-b9d7-611596689f8a@gmail.com>
Message-ID: <2da068bc-851f-4cd5-b14c-fdf220efdc93@measurement-factory.com>

On 2024-07-04 04:57, Nishant Sharma wrote:
> On 03/07/24 21:27, Alex Rousskov wrote:
>> On 2024-07-03 09:27, Nishant Sharma wrote:
>>> Is there any change that we need to do in the configure script to 
>>> check for the availability of 64 bit atomic lock and use 32 bit lock 
>>> if not available?

>> It is technically possible (perhaps even without ./configure checks), 
>> but it would require adjusting complex shared tree code in the abcense 
>> of comprehensive ready-to-use tests. It is trivial to break that code. 
>> It is difficult to detect bugs. IMO, we should not expose ourselves to 
>> such risks in this case, especially since Squid uses 64-bit atomics in 
>> many other places: Supporting 32 bits in shared binary tree nodes is 
>> not going to remove the last frequently used 64-bit lock.

> Just being curious here, if a certain platform (mips32 in this case) is 
> unable to guarantee a 64 bit atomic lock, other functions except SMP 
> mode might get affected as well?

The answer depends on where one draws "SMP mode" boundaries: The locks 
in question should have no effect on non-SMP Squid (i.e. Squids with 
only one worker process, no cache_dir diskers, and memory_cache_shared 
not turned on). Beyond that, it is very difficult to isolate "other 
functions" from "SMP mode" because a lot of Squid "functions" ought to 
be (and are becoming) SMP-aware and, hence, use shared memory locking.

>> Disclaimer: I do not know what "lock ID" is in this context.

> "lock ID" term was used on Openwrt issue tracker where it was suggested 
> that "The assertion assumes 64bit lock id.". [1]

Yes, I am aware. I wrote the disclaimer _after_ reading that thread :-).


> Let me experiment with squid-6.x on these devices and also use them in 
> the live environment.
> 
> The only change being commenting out the following line from 
> ipc/mem/PageStack.c:
> 
> `assertion(StoredNode().is_lock_free());`
> 
> I will report back with success or any failures encountered.


Thank you,

Alex.


> [1] 
> "https://github.com/openwrt/packages/issues/24469#issuecomment-2202322703"



From rousskov at measurement-factory.com  Thu Jul  4 14:36:05 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 4 Jul 2024 10:36:05 -0400
Subject: [squid-users] Squid as http to https forward proxy
In-Reply-To: <AS8PR03MB8072C9DC3302D4535EBC5C28CADE2@AS8PR03MB8072.eurprd03.prod.outlook.com>
References: <AS8PR03MB8072C9DC3302D4535EBC5C28CADE2@AS8PR03MB8072.eurprd03.prod.outlook.com>
Message-ID: <fd866f62-ad88-4fe8-9903-e8c1c2578d9c@measurement-factory.com>

On 2024-07-04 09:20, Wagner, Juergen03 wrote:

> we are evaluating Squid to be used as a http to https forward proxy.
> 
> So Squid would need to support the following setup:
> 
>  ??? http (client) ???---->?? Squid? --->? https ( server )
> 
> Could someone please confirm if the given setup is in principle possible 
> with Squid?
> 
> If yes, which configuration needs to be done?


Hello Juergen,

     Yes, Squid should be able to forward plain text HTTP requests to a 
secure server. Use cache_peer directive with "tls" and "originserver" 
flags. Here is an untested sketch:

     # routing all traffic to one HTTPS origin server
     cache_peer 127.0.0.1 parent 443 0 tls originserver \
         name=MySecureOrigin \
         no-query no-digest
     cache_peer_access MySecureOrigin allow all
     always_direct deny all
     never_direct allow all
     nonhierarchical_direct off


HTH,

Alex.



From rousskov at measurement-factory.com  Thu Jul  4 14:41:08 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 4 Jul 2024 10:41:08 -0400
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <3E8A3F50-0BD8-407D-9860-06F5BCB255A2@gmail.com>
References: <3E8A3F50-0BD8-407D-9860-06F5BCB255A2@gmail.com>
Message-ID: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>

On 2024-07-03 13:56, Jonathan Lee wrote:
> Hello fellow Squid users does anyone know how to fix this issue?

I counted about eight different "issues" in your cache.log sample. Most 
of them are probably independent. I recommend that you explicitly pick 
_one_, search mailing list archives for previous discussions about it, 
and then provide as many details about it as you can (e.g., what traffic 
causes it and/or matching access.log records).


HTH,

Alex.


> Squid - Cache Logs
> Date-Time	Message
> 31.12.1969 16:00:00	
> 03.07.2024 10:54:34	kick abandoning conn7853?local=192.168.1.1:3128 
> remote=192.168.1.5:49710 FD 89 flags=1
> 31.12.1969 16:00:00	
> 03.07.2024 10:54:29	kick abandoning conn7844?local=192.168.1.1:3128 
> remote=192.168.1.5:49702 FD 81 flags=1
> 03.07.2024 10:54:09	ERROR: failure while accepting a TLS connection on 
> conn7648 local=192.168.1.1:3128 remote=192.168.1.5:49672 FD 44 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:54:09	ERROR: failure while accepting a TLS connection on 
> conn7647 local=192.168.1.1:3128 remote=192.168.1.5:49670 FD 43 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:54:09	ERROR: failure while accepting a TLS connection on 
> conn7646 local=192.168.1.1:3128 remote=192.168.1.5:49668 FD 34 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:53:04	ERROR: failure while accepting a TLS connection on 
> conn7367 local=192.168.1.1:3128 remote=192.168.1.5:49627 FD 22 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:52:47	ERROR: failure while accepting a TLS connection on 
> conn7345 local=192.168.1.1:3128 remote=192.168.1.5:49618 FD 31 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:52:38	ERROR: failure while accepting a TLS connection on 
> conn7340 local=192.168.1.1:3128 remote=192.168.1.5:49616 FD 45 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:52:34	ERROR: failure while accepting a TLS connection on 
> conn7316 local=192.168.1.1:3128 remote=192.168.1.5:49609 FD 45 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 31.12.1969 16:00:00	
> 03.07.2024 10:51:55	WARNING: Error Pages Missing Language: en-us
> 31.12.1969 16:00:00	
> 03.07.2024 10:51:55	ERROR: loading file 
> 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': (2) No 
> such?file or directory
> 03.07.2024 10:51:44	ERROR: failure while accepting a TLS connection on 
> conn7102 local=192.168.1.1:3128 remote=192.168.1.5:49574 FD 34 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:51:28	ERROR: failure while accepting a TLS connection on 
> conn7071 local=192.168.1.1:3128 remote=192.168.1.5:49568 FD 92 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:50:29	ERROR: failure while accepting a TLS connection on 
> conn6944 local=192.168.1.1:3128 remote=192.168.1.5:49534 FD 101 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:49:54	ERROR: failure while accepting a TLS connection on 
> conn6866 local=192.168.1.1:3128 remote=192.168.1.5:49519 FD 31 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:49:38	ERROR: failure while accepting a TLS connection on 
> conn6809 local=192.168.1.1:3128 remote=192.168.1.5:49503 FD 31 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 31.12.1969 16:00:00	
> 03.07.2024 10:49:32	ERROR: system call failure while accepting a TLS 
> connection on conn6794 local=192.168.1.1:3128 remote=192.168.1.5:49496 
> FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
> 03.07.2024 10:49:24	ERROR: failure while accepting a TLS connection on 
> conn6776 local=192.168.1.1:3128 remote=192.168.1.5:49481 FD 137 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:48:49	ERROR: failure while accepting a TLS connection on 
> conn6440 local=192.168.1.1:3128 remote=192.168.1.5:49424 FD 16 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:48:49	ERROR: failure while accepting a TLS connection on 
> conn6445 local=192.168.1.1:3128 remote=192.168.1.5:49426 FD 34 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:48:22	ERROR: failure while accepting a TLS connection on 
> conn6035 local=192.168.1.1:3128 remote=192.168.1.5:49355 FD 226 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:48:09	ERROR: failure while accepting a TLS connection on 
> conn5887 local=192.168.1.1:3128 remote=192.168.1.5:49318 FD 33 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:48:09	ERROR: failure while accepting a TLS connection on 
> conn5875 local=192.168.1.1:3128 remote=192.168.1.5:49312 FD 216 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:48:09	ERROR: failure while accepting a TLS connection on 
> conn5876 local=192.168.1.1:3128 remote=192.168.1.5:49314 FD 217 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:47:57	ERROR: failure while accepting a TLS connection on 
> conn5815 local=192.168.1.1:3128 remote=192.168.1.5:49297 FD 201 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:47:54	ERROR: failure while accepting a TLS connection on 
> conn5760 local=192.168.1.1:3128 remote=192.168.1.5:49289 FD 195 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:47:52	ERROR: failure while accepting a TLS connection on 
> conn5717 local=192.168.1.1:3128 remote=192.168.1.5:49284 FD 195 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:47:50	ERROR: failure while accepting a TLS connection on 
> conn5552 local=192.168.1.1:3128 remote=192.168.1.5:49268 FD 142 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 31.12.1969 16:00:00	
> 03.07.2024 10:47:34	kick abandoning conn5254?local=192.168.1.1:3128 
> remote=192.168.1.5:49209 FD 100 flags=1
> 31.12.1969 16:00:00	
> 03.07.2024 10:47:21	kick abandoning conn5022?local=192.168.1.1:3128 
> remote=192.168.1.5:49167 FD 37 flags=1
> 31.12.1969 16:00:00	
> 03.07.2024 10:47:21	kick abandoning conn5020?local=192.168.1.1:3128 
> remote=192.168.1.5:49165 FD 36 flags=1
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 03.07.2024 10:42:22	WARNING: Forwarding loop?detected for:
> 03.07.2024 10:40:08	ERROR: failure while accepting a TLS connection on 
> conn4955 local=192.168.1.1:3128 remote=192.168.1.5:52339 FD 98 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 31.12.1969 16:00:00	
> 03.07.2024 10:39:52	kick abandoning conn4927?local=192.168.1.1:3128 
> remote=192.168.1.5:52331 FD 105 flags=1
> 03.07.2024 10:39:09	ERROR: failure while accepting a TLS connection on 
> conn4846 local=192.168.1.1:3128 remote=192.168.1.5:52314 FD 19 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:38:14	ERROR: failure while accepting a TLS connection on 
> conn4650 local=192.168.1.1:3128 remote=192.168.1.5:52274 FD 35 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
> 03.07.2024 10:38:08	ERROR: failure while accepting a TLS connection on 
> conn4645 local=192.168.1.1:3128 remote=192.168.1.5:52272 FD 35 flags=1: 
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 03.07.2024 10:38:04	ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 03.07.2024 10:38:04	ERROR: Unsupported TLS option SINGLE_DH_USE
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From uhlar at fantomas.sk  Thu Jul  4 14:58:48 2024
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 4 Jul 2024 16:58:48 +0200
Subject: [squid-users] Squid as http to https forward proxy
In-Reply-To: <fd866f62-ad88-4fe8-9903-e8c1c2578d9c@measurement-factory.com>
References: <AS8PR03MB8072C9DC3302D4535EBC5C28CADE2@AS8PR03MB8072.eurprd03.prod.outlook.com>
 <fd866f62-ad88-4fe8-9903-e8c1c2578d9c@measurement-factory.com>
Message-ID: <Zoa4qPkq5ckD3V4E@fantomas.sk>

>On 2024-07-04 09:20, Wagner, Juergen03 wrote:
>>we are evaluating Squid to be used as a http to https forward proxy.
>>
>>So Squid would need to support the following setup:
>>
>> ??? http (client) ???---->?? Squid? --->? https ( server )
>>
>>Could someone please confirm if the given setup is in principle 
>>possible with Squid?
>>
>>If yes, which configuration needs to be done?

On 04.07.24 10:36, Alex Rousskov wrote:
>    Yes, Squid should be able to forward plain text HTTP requests to a 
>secure server. Use cache_peer directive with "tls" and "originserver" 
>flags. Here is an untested sketch:
>
>    # routing all traffic to one HTTPS origin server
>    cache_peer 127.0.0.1 parent 443 0 tls originserver \
>        name=MySecureOrigin \
>        no-query no-digest
>    cache_peer_access MySecureOrigin allow all
>    always_direct deny all
>    never_direct allow all
>    nonhierarchical_direct off

Afaik this means that it is not possible with any remote server, because all 
servers you want to access this way must be explicitly set up in squid.conf, 
correct?


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Silvester Stallone: Father of the RISC concept.


From rousskov at measurement-factory.com  Thu Jul  4 16:36:35 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 4 Jul 2024 12:36:35 -0400
Subject: [squid-users] Squid as http to https forward proxy
In-Reply-To: <Zoa4qPkq5ckD3V4E@fantomas.sk>
References: <AS8PR03MB8072C9DC3302D4535EBC5C28CADE2@AS8PR03MB8072.eurprd03.prod.outlook.com>
 <fd866f62-ad88-4fe8-9903-e8c1c2578d9c@measurement-factory.com>
 <Zoa4qPkq5ckD3V4E@fantomas.sk>
Message-ID: <97c63622-762a-431f-a00e-bdae2bd8442b@measurement-factory.com>

On 2024-07-04 10:58, Matus UHLAR - fantomas wrote:
>> On 2024-07-04 09:20, Wagner, Juergen03 wrote:
>>> we are evaluating Squid to be used as a http to https forward proxy.
>>>
>>> So Squid would need to support the following setup:
>>>
>>> ??? http (client) ???---->?? Squid? --->? https ( server )
>>>
>>> Could someone please confirm if the given setup is in principle 
>>> possible with Squid?
>>>
>>> If yes, which configuration needs to be done?
> 
> On 04.07.24 10:36, Alex Rousskov wrote:
>> ?? Yes, Squid should be able to forward plain text HTTP requests to a 
>> secure server. Use cache_peer directive with "tls" and "originserver" 
>> flags. Here is an untested sketch:
>>
>> ?? # routing all traffic to one HTTPS origin server
>> ?? cache_peer 127.0.0.1 parent 443 0 tls originserver \
>> ?????? name=MySecureOrigin \
>> ?????? no-query no-digest
>> ?? cache_peer_access MySecureOrigin allow all
>> ?? always_direct deny all
>> ?? never_direct allow all
>> ?? nonhierarchical_direct off
> 
> Afaik this means that it is not possible with any remote server, because 
> all servers you want to access this way must be explicitly set up in 
> squid.conf, correct?

I assumed (possibly incorrectly) that Juergen was asking about a single 
"true origin server" (e.g., example.com). The above example was written 
with a single "true origin server" in mind. However, exactly the same 
Squid configuration may work to forward traffic to a reverse proxy 
(running at 127.0.0.1 on port 443) that "represents" multiple/different 
"true origin servers".

That reverse proxy will need to shovel TLS bytes received from Squid to 
the right "true origin server", but I am guessing that it can do that 
based on TLS SNI supplied by Squid. Some Squid code modifications may be 
necessary to make this work correctly with persistent Squid-to-peer 
connections and such, but nothing major AFAICT (and they can be turned 
off using server_persistent_connections if they are in the way).

AFAICT, with either SslBump or some Squid code modifications, that 
reverse proxy can be a Squid proxy. With even more Squid enhancements, 
that reverse proxy can also become an https_port on the same Squid proxy 
instance where the http_port receives plain HTTP requests!

Does this answer your question?

Alex.



From rousskov at measurement-factory.com  Thu Jul  4 16:43:27 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 4 Jul 2024 12:43:27 -0400
Subject: [squid-users] Squid as http to https forward proxy
In-Reply-To: <97c63622-762a-431f-a00e-bdae2bd8442b@measurement-factory.com>
References: <AS8PR03MB8072C9DC3302D4535EBC5C28CADE2@AS8PR03MB8072.eurprd03.prod.outlook.com>
 <fd866f62-ad88-4fe8-9903-e8c1c2578d9c@measurement-factory.com>
 <Zoa4qPkq5ckD3V4E@fantomas.sk>
 <97c63622-762a-431f-a00e-bdae2bd8442b@measurement-factory.com>
Message-ID: <7a1c7920-567b-491e-8302-49154c01e9f8@measurement-factory.com>

On 2024-07-04 12:36, Alex Rousskov wrote:
> On 2024-07-04 10:58, Matus UHLAR - fantomas wrote:
>>> On 2024-07-04 09:20, Wagner, Juergen03 wrote:
>>>> we are evaluating Squid to be used as a http to https forward proxy.
>>>>
>>>> So Squid would need to support the following setup:
>>>>
>>>> ??? http (client) ???---->?? Squid? --->? https ( server )
>>>>
>>>> Could someone please confirm if the given setup is in principle 
>>>> possible with Squid?
>>>>
>>>> If yes, which configuration needs to be done?
>>
>> On 04.07.24 10:36, Alex Rousskov wrote:
>>> ?? Yes, Squid should be able to forward plain text HTTP requests to a 
>>> secure server. Use cache_peer directive with "tls" and "originserver" 
>>> flags. Here is an untested sketch:
>>>
>>> ?? # routing all traffic to one HTTPS origin server
>>> ?? cache_peer 127.0.0.1 parent 443 0 tls originserver \
>>> ?????? name=MySecureOrigin \
>>> ?????? no-query no-digest
>>> ?? cache_peer_access MySecureOrigin allow all
>>> ?? always_direct deny all
>>> ?? never_direct allow all
>>> ?? nonhierarchical_direct off
>>
>> Afaik this means that it is not possible with any remote server, 
>> because all servers you want to access this way must be explicitly set 
>> up in squid.conf, correct?
> 
> I assumed (possibly incorrectly) that Juergen was asking about a single 
> "true origin server" (e.g., example.com). The above example was written 
> with a single "true origin server" in mind. However, exactly the same 
> Squid configuration may work to forward traffic to a reverse proxy 
> (running at 127.0.0.1 on port 443) that "represents" multiple/different 
> "true origin servers".
> 
> That reverse proxy will need to shovel TLS bytes received from Squid to 
> the right "true origin server", but I am guessing that it can do that 
> based on TLS SNI supplied by Squid. Some Squid code modifications may be 
> necessary to make this work correctly with persistent Squid-to-peer 
> connections and such, but nothing major AFAICT (and they can be turned 
> off using server_persistent_connections if they are in the way).
> 
> AFAICT, with either SslBump or some Squid code modifications, that 
> reverse proxy can be a Squid proxy. With even more Squid enhancements, 
> that reverse proxy can also become an https_port on the same Squid proxy 
> instance where the http_port receives plain HTTP requests!

At some point, depending on the use case, it will be easier to enhance 
Squid to encrypt plain HTTP requests without using this TLS cache_peer 
hack, of course.

Alex.



From rousskov at measurement-factory.com  Thu Jul  4 16:56:04 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 4 Jul 2024 12:56:04 -0400
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
Message-ID: <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>

On 2024-07-04 12:11, Jonathan Lee wrote:
> failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128
> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417

A000417 is an "unknown CA" alert sent by client to Squid while the 
client is trying to establish a TLS connection to/through Squid. The 
client does not trust the Certificate Authority that signed the 
certificate that was used for that TLS connection.

As the next step in triage, I recommend determining what that CA is in 
these cases (e.g., by capturing raw TLS packets and matching them with 
connection information from A000417 error messages in cache.log or 
%err_detail in access.log).

If you use SslBump for port 3128 traffic, then one of the possibilities 
here is that Squid is using an unknown-to-client CA to report an origin 
server that Squid itself does not trust (see signUntrusted in 
squid.conf.documented). In those cases, logging a level-1 ERROR is a 
Squid bug because that expected/desirable outcome should be treated as 
success (and a successful TLS accept treated as an error!).


HTH,

Alex.
P.S. For free Squid support, please keep the discussion on the mailing list.


> Is my main concern however I use the squid guard URL blocker
> Sent from my iPhone
> 
>> On Jul 4, 2024, at 07:41, Alex Rousskov 
>> <rousskov at measurement-factory.com> wrote:
>>
>> ?On 2024-07-03 13:56, Jonathan Lee wrote:
>>> Hello fellow Squid users does anyone know how to fix this issue?
>>
>> I counted about eight different "issues" in your cache.log sample. 
>> Most of them are probably independent. I recommend that you explicitly 
>> pick _one_, search mailing list archives for previous discussions 
>> about it, and then provide as many details about it as you can (e.g., 
>> what traffic causes it and/or matching access.log records).
>>
>>
>> HTH,
>>
>> Alex.
>>
>>
>>> Squid - Cache Logs
>>> Date-Time ? ?Message
>>> 31.12.1969 16:00:00
>>> 03.07.2024 10:54:34 ? ?kick abandoning 
>>> conn7853?local=192.168.1.1:3128 remote=192.168.1.5:49710 FD 89 flags=1
>>> 31.12.1969 16:00:00
>>> 03.07.2024 10:54:29 ? ?kick abandoning 
>>> conn7844?local=192.168.1.1:3128 remote=192.168.1.5:49702 FD 81 flags=1
>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn7648 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49672 FD 44 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn7647 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49670 FD 43 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn7646 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49668 FD 34 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 03.07.2024 10:53:04 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn7367 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49627 FD 22 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 03.07.2024 10:52:47 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn7345 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49618 FD 31 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 03.07.2024 10:52:38 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn7340 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49616 FD 45 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>> 03.07.2024 10:52:34 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn7316 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49609 FD 45 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 31.12.1969 16:00:00
>>> 03.07.2024 10:51:55 ? ?WARNING: Error Pages Missing Language: en-us
>>> 31.12.1969 16:00:00
>>> 03.07.2024 10:51:55 ? ?ERROR: loading file 
>>> 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': (2) No 
>>> such?file or directory
>>> 03.07.2024 10:51:44 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn7102 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49574 FD 34 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 03.07.2024 10:51:28 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn7071 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49568 FD 92 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 03.07.2024 10:50:29 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn6944 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49534 FD 101 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>> 03.07.2024 10:49:54 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn6866 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49519 FD 31 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 03.07.2024 10:49:38 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn6809 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49503 FD 31 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 31.12.1969 16:00:00
>>> 03.07.2024 10:49:32 ? ?ERROR: system call failure while accepting a 
>>> TLS connection on conn6794 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49496 FD 19 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
>>> 03.07.2024 10:49:24 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn6776 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49481 FD 137 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>> 03.07.2024 10:48:49 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn6440 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49424 FD 16 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>> 03.07.2024 10:48:49 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn6445 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49426 FD 34 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 03.07.2024 10:48:22 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn6035 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49355 FD 226 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn5887 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49318 FD 33 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn5875 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49312 FD 216 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn5876 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49314 FD 217 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 03.07.2024 10:47:57 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn5815 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49297 FD 201 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>> 03.07.2024 10:47:54 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn5760 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49289 FD 195 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>> 03.07.2024 10:47:52 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn5717 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49284 FD 195 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>> 03.07.2024 10:47:50 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn5552 local=192.168.1.1:3128 
>>> remote=192.168.1.5:49268 FD 142 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>> 31.12.1969 16:00:00
>>> 03.07.2024 10:47:34 ? ?kick abandoning 
>>> conn5254?local=192.168.1.1:3128 remote=192.168.1.5:49209 FD 100 flags=1
>>> 31.12.1969 16:00:00
>>> 03.07.2024 10:47:21 ? ?kick abandoning 
>>> conn5022?local=192.168.1.1:3128 remote=192.168.1.5:49167 FD 37 flags=1
>>> 31.12.1969 16:00:00
>>> 03.07.2024 10:47:21 ? ?kick abandoning 
>>> conn5020?local=192.168.1.1:3128 remote=192.168.1.5:49165 FD 36 flags=1
>>> 31.12.1969 16:00:00
>>> 31.12.1969 16:00:00
>>> 31.12.1969 16:00:00
>>> 31.12.1969 16:00:00
>>> 31.12.1969 16:00:00
>>> 31.12.1969 16:00:00
>>> 31.12.1969 16:00:00
>>> 31.12.1969 16:00:00
>>> 31.12.1969 16:00:00
>>> 31.12.1969 16:00:00
>>> 03.07.2024 10:42:22 ? ?WARNING: Forwarding loop?detected for:
>>> 03.07.2024 10:40:08 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn4955 local=192.168.1.1:3128 
>>> remote=192.168.1.5:52339 FD 98 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 31.12.1969 16:00:00
>>> 03.07.2024 10:39:52 ? ?kick abandoning 
>>> conn4927?local=192.168.1.1:3128 remote=192.168.1.5:52331 FD 105 flags=1
>>> 03.07.2024 10:39:09 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn4846 local=192.168.1.1:3128 
>>> remote=192.168.1.5:52314 FD 19 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 03.07.2024 10:38:14 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn4650 local=192.168.1.1:3128 
>>> remote=192.168.1.5:52274 FD 35 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>> 03.07.2024 10:38:08 ? ?ERROR: failure while accepting a TLS 
>>> connection on conn4645 local=192.168.1.1:3128 
>>> remote=192.168.1.5:52272 FD 35 flags=1: 
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>> 03.07.2024 10:38:04 ? ?ERROR: Unsupported TLS option SINGLE_ECDH_USE
>>> 03.07.2024 10:38:04 ? ?ERROR: Unsupported TLS option SINGLE_DH_USE
>>> 31.12.1969 16:00:00
>>> 31.12.1969 16:00:00
>>> 31.12.1969 16:00:00
>>> 31.12.1969 16:00:00
>>> 31.12.1969 16:00:00
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>>



From jonathanlee571 at gmail.com  Thu Jul  4 19:37:01 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 4 Jul 2024 12:37:01 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
 <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
Message-ID: <DA771A75-5CF4-4CB1-B63A-AD2937C07604@gmail.com>

I found it 

#  TAG: sslproxy_cert_sign
#
#        sslproxy_cert_sign <signing algorithm> acl ...
#
#        The following certificate signing algorithms are supported:
#
#	   signTrusted
#		Sign using the configured CA certificate which is usually
#		placed in and trusted by end-user browsers. This is the
#		default for trusted origin server certificates.
#
#	   signUntrusted
#		Sign to guarantee an X509_V_ERR_CERT_UNTRUSTED browser error.
#		This is the default for untrusted origin server certificates
#		that are not self-signed (see ssl::certUntrusted).
#
#	   signSelf
#		Sign using a self-signed certificate with the right CN to
#		generate a X509_V_ERR_DEPTH_ZERO_SELF_SIGNED_CERT error in the
#		browser. This is the default for self-signed origin server
#		certificates (see ssl::certSelfSigned).
#
#	This clause only supports fast acl types.
#
#	When sslproxy_cert_sign acl(s) match, Squid uses the corresponding
#	signing algorithm to generate the certificate and ignores all
#	subsequent sslproxy_cert_sign options (the first match wins). If no
#	acl(s) match, the default signing algorithm is determined by errors
#	detected when obtaining and validating the origin server certificate.
#
#	WARNING: SQUID_X509_V_ERR_DOMAIN_MISMATCH and ssl:certDomainMismatch can
#	be used with sslproxy_cert_adapt, but if and only if Squid is bumping a
#	CONNECT request that carries a domain name. In all other cases (CONNECT
#	to an IP address or an intercepted SSL connection), Squid cannot detect
#	the domain mismatch at certificate generation time when
#	bump-server-first is used.
#Default:
# none

in Squid.conf I have nothing with that detective. 

Yes I am using SSL bump with this configuration..


# This file is automatically generated by pfSense
# Do not edit manually !

http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

icp_port 0
digest_generation off
dns_v4_first on
pid_filename /var/run/squid/squid.pid
cache_effective_user squid
cache_effective_group proxy
error_default_language en
icon_directory /usr/local/etc/squid/icons
visible_hostname Lee_Family.home.arpa
cache_mgr jonathanlee571 at gmail.com
access_log /var/squid/logs/access.log
cache_log /var/squid/logs/cache.log
cache_store_log none
netdb_filename /var/squid/logs/netdb.state
pinger_enable on
pinger_program /usr/local/libexec/squid/pinger
sslcrtd_program /usr/local/libexec/squid/security_file_certgen -s /var/squid/lib/ssl_db -M 4MB -b 2048
tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
tls_outgoing_options capath=/usr/local/share/certs/
tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
sslcrtd_children 10

logfile_rotate 7
debug_options rotate=7
shutdown_lifetime 3 seconds
# Allow local network(s) on interface(s)
acl localnet src  192.168.1.0/27
forwarded_for transparent
httpd_suppress_version_string on
uri_whitespace strip
dns_nameservers 127.0.0.1 
acl block_hours time 00:30-05:00
ssl_bump terminate all block_hours
http_access deny all block_hours
acl getmethod method GET
acl to_ipv6 dst ipv6
acl from_ipv6 src ipv6

#tls_outgoing_options options=0x40000
#request_header_access Accept-Ranges deny all
#reply_header_access Accept-Ranges deny all
#request_header_replace Accept-Ranges none
#reply_header_replace Accept-Ranges none


tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

acl HttpAccess dstdomain "/usr/local/pkg/http.access"
acl windowsupdate dstdomain "/usr/local/pkg/windowsupdate"
acl rewritedoms dstdomain "/usr/local/pkg/desdom"

#store_id_program /usr/local/libexec/squid/storeid_file_rewrite /var/squid/storeid/storeid_rewrite.txt
#store_id_children 10 startup=5 idle=1 concurrency=0
#always_direct allow all
#store_id_access deny connect
#store_id_access deny !getmethod
#store_id_access allow rewritedoms
#store_id_access deny all

refresh_all_ims on
reload_into_ims on
max_stale 20 years
minimum_expiry_time 0

refresh_pattern -i ^http.*squid\.internal.* 43200 100% 79900 override-expire override-lastmod ignore-reload ignore-no-store ignore-must-revalidate ignore-private ignore-auth

#FACEBOOK
#refresh_pattern ^https.*.facebook.com/* 10080 80% 43200

#FACEBOOK IMAGES  
#refresh_pattern -i pixel.facebook.com..(jpg|png|gif|ico|css|js|jpg?) 10080 80% 43200
#refresh_pattern -i .akamaihd.net..(jpg|png|gif|ico|css|js|jpg?) 10080 80% 43200 
#refresh_pattern -i facebook.com.(jpg|png|gif|jpg?) 10080 80% 43200 store-stale
#refresh_pattern static.(xx|ak).fbcdn.net.(jpg|gif|png|jpg?) 10080 80% 43200
#refresh_pattern ^https.*profile.ak.fbcdn.net.*(jpg|gif|png|jpg?) 10080 80% 43200
#refresh_pattern ^https.*fbcdn.net.*(jpg|gif|png|jpg?) 10080 80% 43200

#FACEBOOK VIDEO
#refresh_pattern -i .video.ak.fbcdn.net.*.(mp4|flv|mp3|amf) 10080 80% 43200
#refresh_pattern (audio|video)/(webm|mp4) 10080 80% 43200

#APPLE STUFF
refresh_pattern -i apple.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip|dist)$ 0 80% 43200  refresh-ims

#apple update
refresh_pattern -i (download|adcdownload).apple.com/.*\.(pkg|dmg) 4320 100% 43200
refresh_pattern -i appldnld\.apple\.com 129600 100% 129600
refresh_pattern -i phobos\.apple\.com 129600 100% 129600
refresh_pattern -i iosapps\.itunes\.apple\.com 129600 100% 129600

# Updates: Windows
refresh_pattern -i microsoft.com/..(cab|exe|msi|msu|msf|asf|wma|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i windowsupdate.com/..(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i windows.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i .*windowsupdate.com/.*\.(cab|exe) 259200 100% 259200   
refresh_pattern -i .*update.microsoft.com/.*\.(cab|exe|dll|msi|psf) 259200 100% 259200   
refresh_pattern windowsupdate.com/.*\.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern download.microsoft.com/.*\.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern www.microsoft.com/.*\.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern au.download.windowsupdate.com/.*\.(cab|exe|dll|msi|psf) 4320 100% 43200 
refresh_pattern bg.v4.pr.dl.ws.microsoft.com/.*\.(cab|exe|dll|msi|psf) 4320 100% 43200
#windows update NEW UPDATE 0.04
refresh_pattern update.microsoft.com/.*\.(cab|exe) 43200 100% 129600    
refresh_pattern ([^.]+\.)?(download|(windows)?update)\.(microsoft\.)?com/.*\.(cab|exe|msi|msp|psf) 4320 100% 43200  
refresh_pattern update.microsoft.com/.*\.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern -i \.update.microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i \.windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i \.download.microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i \.ws.microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
    
#refresh_pattern ([^.]+\.)?(cs|content[1-9]|hsar|content-origin|client-download).[steampowered|steamcontent].com/.*\.* 43200 100% 43200     
#refresh_pattern ([^.]+\.)?.akamai.steamstatic.com/.*\.* 43200 100% 43200

#refresh_pattern -i ([^.]+\.)?.adobe.com/.*\.(zip|exe) 43200 100% 43200
#refresh_pattern -i ([^.]+\.)?.java.com/.*\.(zip|exe) 43200 100% 43200
#refresh_pattern -i ([^.]+\.)?.sun.com/.*\.(zip|exe) 43200 100% 43200
#refresh_pattern -i ([^.]+\.)?.oracle.com/.*\.(zip|exe|tar.gz) 43200 100% 43200

refresh_pattern -i appldnld\.apple\.com 43200 100% 43200
refresh_pattern -i ([^.]+\.)?apple.com/.*\.(ipa) 43200 100% 43200
 
refresh_pattern -i ([^.]+\.)?.google.com/.*\.(exe|crx) 10080 80% 43200
refresh_pattern -i ([^.]+\.)?g.static.com/.*\.(exe|crx) 10080 80% 43200

acl https_login url_regex -i ^https.*(login|Login).*
cache deny https_login

range_offset_limit 512 MB windowsupdate
range_offset_limit 4 MB
range_offset_limit 0
quick_abort_min -1 KB

cache_mem 64 MB
maximum_object_size_in_memory 256 KB
memory_replacement_policy heap GDSF
cache_replacement_policy heap LFUDA
minimum_object_size 0 KB
maximum_object_size 512 MB
cache_dir diskd /var/squid/cache 64000 256 256
offline_mode off
cache_swap_low 90
cache_swap_high 95
acl donotcache dstdomain "/var/squid/acl/donotcache.acl"
cache deny donotcache
cache allow all
# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:    1440  20%  10080
refresh_pattern ^gopher:  1440  0%  1440
refresh_pattern -i (/cgi-bin/|\?) 0  0%  0
refresh_pattern .    0  20%  4320


#Remote proxies


# Setup some default acls
# ACLs all, manager, localhost, and to_localhost are predefined.
acl allsrc src all
acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080 3128 3129 1025-65535 
acl sslports port 443 563 8080 5223 2197

acl purge method PURGE
acl connect method CONNECT

# Define protocols used for redirects
acl HTTP proto HTTP
acl HTTPS proto HTTPS

# SslBump Peek and Splice
# http://wiki.squid-cache.org/Features/SslPeekAndSplice
# http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
# Match against the current step during ssl_bump evaluation [fast]
# Never matches and should not be used outside the ssl_bump context.
#
# At each SslBump step, Squid evaluates ssl_bump directives to find
# the next bumping action (e.g., peek or splice). Valid SslBump step
# values and the corresponding ssl_bump evaluation moments are:
#   SslBump1: After getting TCP-level and HTTP CONNECT info.
#   SslBump2: After getting TLS Client Hello info.
#   SslBump3: After getting TLS Server Hello info.
# These ACLs exist even when 'SSL/MITM Mode' is set to 'Custom' so that
# they can be used there for custom configuration.
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
acl banned_hosts src "/var/squid/acl/banned_hosts.acl"
acl whitelist dstdom_regex -i "/var/squid/acl/whitelist.acl"
acl blacklist dstdom_regex -i "/var/squid/acl/blacklist.acl"
http_access allow manager localhost

http_access deny manager
http_access allow purge localhost
http_access deny purge
http_access deny !safeports
http_access deny CONNECT !sslports

# Always allow localhost connections
http_access allow localhost

quick_abort_min 0 KB
quick_abort_max 0 KB
quick_abort_pct 95
request_body_max_size 0 KB
delay_pools 1
delay_class 1 2
delay_parameters 1 -1/-1 -1/-1
delay_initial_bucket_level 100
delay_access 1 allow allsrc

# Reverse Proxy settings

deny_info TCP_RESET allsrc

# Package Integration
url_rewrite_program /usr/local/bin/squidGuard -c /usr/local/etc/squidGuard/squidGuard.conf
url_rewrite_bypass off
url_rewrite_children 32 startup=8 idle=4 concurrency=0

# Custom options before auth
#host_verify_strict on

# These hosts are banned
http_access deny banned_hosts
# Always allow access to whitelist domains
http_access allow whitelist
# Block access to blacklist domains
http_access deny blacklist
# List of domains allowed to logging in to Google services
request_header_access X-GoogApps-Allowed-Domains deny all
request_header_add X-GoogApps-Allowed-Domains consumer_accounts
# Set YouTube safesearch restriction
acl youtubedst dstdomain -n www.youtube.com m.youtube.com youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com
request_header_access YouTube-Restrict deny all
request_header_add YouTube-Restrict none youtubedst
acl sglog url_regex -i sgr=ACCESSDENIED
http_access deny sglog
# Custom SSL/MITM options before auth
cachemgr_passwd disable offline_toggle reconfigure shutdown
cachemgr_passwd redacted all
eui_lookup on
acl no_miss url_regex -i gateway\.facebook\.com\/ws\/realtime\?
acl no_miss url_regex -i web-chat-e2ee\.facebook\.com\/ws\/chat
acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com
http_access allow CONNECT wuCONNECT localnet
http_access allow CONNECT wuCONNECT localhost
http_access allow windowsupdate localnet
http_access allow windowsupdate localhost
http_access allow HttpAccess localnet
http_access allow HttpAccess localhost
http_access deny manager
http_access deny to_ipv6
http_access deny from_ipv6

acl BrokenButTrustedServers dstdomain "/usr/local/pkg/dstdom.broken"
acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
sslproxy_cert_error deny all

acl splice_only src 192.168.1.8 #Tasha iPhone
acl splice_only src 192.168.1.10 #Jon iPhone
acl splice_only src 192.168.1.11 #Amazon Fire
acl splice_only src 192.168.1.15 #Tasha HP
acl splice_only src 192.168.1.16 #iPad

acl splice_only_mac arp redacted
acl splice_only_mac arp redacted
acl splice_only_mac arp redacted
acl splice_only_mac arp redacted
acl splice_only_mac arp redacted

acl NoSSLIntercept ssl::server_name_regex -i "/usr/local/pkg/reg.url.nobump"
acl NoBumpDNS dstdomain "/usr/local/pkg/dns.nobump"

acl markBumped annotate_client bumped=true
acl active_use annotate_client active=true
acl bump_only src 192.168.1.3 #webtv
acl bump_only src 192.168.1.4 #toshiba
acl bump_only src 192.168.1.5 #imac
acl bump_only src 192.168.1.9 #macbook
acl bump_only src 192.168.1.13 #dell

acl bump_only_mac arp redacted redacted redacted
acl bump_only_mac arp 
acl bump_only_mac arp 
acl bump_only_mac arp 
acl bump_only_mac arp 

ssl_bump peek step1
miss_access deny no_miss active_use
ssl_bump splice https_login active_use
ssl_bump splice splice_only_mac splice_only active_use
ssl_bump splice NoBumpDNS active_use
ssl_bump splice NoSSLIntercept active_use
ssl_bump bump bump_only_mac bump_only active_use
acl activated note active_use true
ssl_bump terminate !activated

acl markedBumped note bumped true
url_rewrite_access deny markedBumped

#workers 3
read_ahead_gap 32 KB
#negative_ttl 1 second
#connect_timeout 30 seconds
#request_timeout 60 seconds
#half_closed_clients off
#shutdown_lifetime 10 seconds
#negative_dns_ttl 1 seconds
#ignore_unknown_nameservers on
#client_persistent_connections off
#server_persistent_connections off
#pipeline_prefetch 100

#acl SSLIntercept ssl::server_name_regex -i "/usr/local/pkg/url.bump"
#ssl_bump bump SSLIntercept

# Setup allowed ACLs
# Allow local network(s) on interface(s)
http_access allow localnet
# Default block all to be sure
http_access deny allsrc

icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_encode off
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024

icap_service service_avi_req reqmod_precache icap://127.0.0.1:1344/squid_clamav bypass=off
adaptation_access service_avi_req allow all
icap_service service_avi_resp respmod_precache icap://127.0.0.1:1344/squid_clamav bypass=on
adaptation_access service_avi_resp allow all


I see nothing with that derivative I also added my firewalls cert a bit ago as an extra cert but it had no affect on the errors..

So would I use this directive like this

 sslproxy_cert_sign signTrusted bump_only_mac

with bump only mac as my ACL? the reference does not really show a good example of use it explains it well 

 sslproxy_cert_sign <signing algorithm> acl ...

        The following certificate signing algorithms are supported:

	   signTrusted
		Sign using the configured CA certificate which is usually
		placed in and trusted by end-user browsers. This is the
		default for trusted origin server certificates.

	   signUntrusted
		Sign to guarantee an X509_V_ERR_CERT_UNTRUSTED browser error.
		This is the default for untrusted origin server certificates
		that are not self-signed (see ssl::certUntrusted).

	   signSelf
		Sign using a self-signed certificate with the right CN to
		generate a X509_V_ERR_DEPTH_ZERO_SELF_SIGNED_CERT error in the
		browser. This is the default for self-signed origin server
		certificates (see ssl::certSelfSigned).

	This clause only supports fast acl types.

	When sslproxy_cert_sign acl(s) match, Squid uses the corresponding
	signing algorithm to generate the certificate and ignores all
	subsequent sslproxy_cert_sign options (the first match wins). If no
	acl(s) match, the default signing algorithm is determined by errors
	detected when obtaining and validating the origin server certificate.

	WARNING: SQUID_X509_V_ERR_DOMAIN_MISMATCH and ssl:certDomainMismatch can
	be used with sslproxy_cert_adapt, but if and only if Squid is bumping a
	CONNECT request that carries a domain name. In all other cases (CONNECT
	to an IP address or an intercepted SSL connection), Squid cannot detect
	the domain mismatch at certificate generation time when
	bump-server-first is used.




> On Jul 4, 2024, at 09:56, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> On 2024-07-04 12:11, Jonathan Lee wrote:
>> failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128
>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417
> 
> A000417 is an "unknown CA" alert sent by client to Squid while the client is trying to establish a TLS connection to/through Squid. The client does not trust the Certificate Authority that signed the certificate that was used for that TLS connection.
> 
> As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).
> 
> If you use SslBump for port 3128 traffic, then one of the possibilities here is that Squid is using an unknown-to-client CA to report an origin server that Squid itself does not trust (see signUntrusted in squid.conf.documented). In those cases, logging a level-1 ERROR is a Squid bug because that expected/desirable outcome should be treated as success (and a successful TLS accept treated as an error!).
> 
> 
> HTH,
> 
> Alex.
> P.S. For free Squid support, please keep the discussion on the mailing list.
> 
> 
>> Is my main concern however I use the squid guard URL blocker
>> Sent from my iPhone
>>> On Jul 4, 2024, at 07:41, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>> 
>>> ?On 2024-07-03 13:56, Jonathan Lee wrote:
>>>> Hello fellow Squid users does anyone know how to fix this issue?
>>> 
>>> I counted about eight different "issues" in your cache.log sample. Most of them are probably independent. I recommend that you explicitly pick _one_, search mailing list archives for previous discussions about it, and then provide as many details about it as you can (e.g., what traffic causes it and/or matching access.log records).
>>> 
>>> 
>>> HTH,
>>> 
>>> Alex.
>>> 
>>> 
>>>> Squid - Cache Logs
>>>> Date-Time    Message
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:54:34    kick abandoning conn7853 local=192.168.1.1:3128 remote=192.168.1.5:49710 FD 89 flags=1
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:54:29    kick abandoning conn7844 local=192.168.1.1:3128 remote=192.168.1.5:49702 FD 81 flags=1
>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7648 local=192.168.1.1:3128 remote=192.168.1.5:49672 FD 44 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7647 local=192.168.1.1:3128 remote=192.168.1.5:49670 FD 43 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7646 local=192.168.1.1:3128 remote=192.168.1.5:49668 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:53:04    ERROR: failure while accepting a TLS connection on conn7367 local=192.168.1.1:3128 remote=192.168.1.5:49627 FD 22 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:52:47    ERROR: failure while accepting a TLS connection on conn7345 local=192.168.1.1:3128 remote=192.168.1.5:49618 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:52:38    ERROR: failure while accepting a TLS connection on conn7340 local=192.168.1.1:3128 remote=192.168.1.5:49616 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:52:34    ERROR: failure while accepting a TLS connection on conn7316 local=192.168.1.1:3128 remote=192.168.1.5:49609 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:51:55    WARNING: Error Pages Missing Language: en-us
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:51:55    ERROR: loading file 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': (2) No such file or directory
>>>> 03.07.2024 10:51:44    ERROR: failure while accepting a TLS connection on conn7102 local=192.168.1.1:3128 remote=192.168.1.5:49574 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:51:28    ERROR: failure while accepting a TLS connection on conn7071 local=192.168.1.1:3128 remote=192.168.1.5:49568 FD 92 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:50:29    ERROR: failure while accepting a TLS connection on conn6944 local=192.168.1.1:3128 remote=192.168.1.5:49534 FD 101 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:49:54    ERROR: failure while accepting a TLS connection on conn6866 local=192.168.1.1:3128 remote=192.168.1.5:49519 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:49:38    ERROR: failure while accepting a TLS connection on conn6809 local=192.168.1.1:3128 remote=192.168.1.5:49503 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:49:32    ERROR: system call failure while accepting a TLS connection on conn6794 local=192.168.1.1:3128 remote=192.168.1.5:49496 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
>>>> 03.07.2024 10:49:24    ERROR: failure while accepting a TLS connection on conn6776 local=192.168.1.1:3128 remote=192.168.1.5:49481 FD 137 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:48:49    ERROR: failure while accepting a TLS connection on conn6440 local=192.168.1.1:3128 remote=192.168.1.5:49424 FD 16 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:48:49    ERROR: failure while accepting a TLS connection on conn6445 local=192.168.1.1:3128 remote=192.168.1.5:49426 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:48:22    ERROR: failure while accepting a TLS connection on conn6035 local=192.168.1.1:3128 remote=192.168.1.5:49355 FD 226 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128 remote=192.168.1.5:49318 FD 33 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5875 local=192.168.1.1:3128 remote=192.168.1.5:49312 FD 216 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5876 local=192.168.1.1:3128 remote=192.168.1.5:49314 FD 217 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:47:57    ERROR: failure while accepting a TLS connection on conn5815 local=192.168.1.1:3128 remote=192.168.1.5:49297 FD 201 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:47:54    ERROR: failure while accepting a TLS connection on conn5760 local=192.168.1.1:3128 remote=192.168.1.5:49289 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:47:52    ERROR: failure while accepting a TLS connection on conn5717 local=192.168.1.1:3128 remote=192.168.1.5:49284 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:47:50    ERROR: failure while accepting a TLS connection on conn5552 local=192.168.1.1:3128 remote=192.168.1.5:49268 FD 142 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:47:34    kick abandoning conn5254 local=192.168.1.1:3128 remote=192.168.1.5:49209 FD 100 flags=1
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:47:21    kick abandoning conn5022 local=192.168.1.1:3128 remote=192.168.1.5:49167 FD 37 flags=1
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:47:21    kick abandoning conn5020 local=192.168.1.1:3128 remote=192.168.1.5:49165 FD 36 flags=1
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:42:22    WARNING: Forwarding loop detected for:
>>>> 03.07.2024 10:40:08    ERROR: failure while accepting a TLS connection on conn4955 local=192.168.1.1:3128 remote=192.168.1.5:52339 FD 98 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:39:52    kick abandoning conn4927 local=192.168.1.1:3128 remote=192.168.1.5:52331 FD 105 flags=1
>>>> 03.07.2024 10:39:09    ERROR: failure while accepting a TLS connection on conn4846 local=192.168.1.1:3128 remote=192.168.1.5:52314 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:38:14    ERROR: failure while accepting a TLS connection on conn4650 local=192.168.1.1:3128 remote=192.168.1.5:52274 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:38:08    ERROR: failure while accepting a TLS connection on conn4645 local=192.168.1.1:3128 remote=192.168.1.5:52272 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:38:04    ERROR: Unsupported TLS option SINGLE_ECDH_USE
>>>> 03.07.2024 10:38:04    ERROR: Unsupported TLS option SINGLE_DH_USE
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240704/54f35b1a/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jul  4 19:50:09 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 4 Jul 2024 12:50:09 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
 <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
Message-ID: <65FE63DD-8A84-4517-99BC-DECBA524A685@gmail.com>

Maybe adding it like this ?

sslproxy_cert_sign signTrusted bump_only_mac https_login splice_only_mac NoBumpDNS NoSSLIntercept
ssl_bump peek step1
miss_access deny no_miss active_use
ssl_bump splice https_login active_use
ssl_bump splice splice_only_mac splice_only active_use
ssl_bump splice NoBumpDNS active_use
ssl_bump splice NoSSLIntercept active_use
ssl_bump bump bump_only_mac bump_only active_use
acl activated note active_use true
ssl_bump terminate !activated

acl markedBumped note bumped true
url_rewrite_access deny markedBumped


> On Jul 4, 2024, at 09:56, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> On 2024-07-04 12:11, Jonathan Lee wrote:
>> failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128
>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417
> 
> A000417 is an "unknown CA" alert sent by client to Squid while the client is trying to establish a TLS connection to/through Squid. The client does not trust the Certificate Authority that signed the certificate that was used for that TLS connection.
> 
> As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).
> 
> If you use SslBump for port 3128 traffic, then one of the possibilities here is that Squid is using an unknown-to-client CA to report an origin server that Squid itself does not trust (see signUntrusted in squid.conf.documented). In those cases, logging a level-1 ERROR is a Squid bug because that expected/desirable outcome should be treated as success (and a successful TLS accept treated as an error!).
> 
> 
> HTH,
> 
> Alex.
> P.S. For free Squid support, please keep the discussion on the mailing list.
> 
> 
>> Is my main concern however I use the squid guard URL blocker
>> Sent from my iPhone
>>> On Jul 4, 2024, at 07:41, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>> 
>>> ?On 2024-07-03 13:56, Jonathan Lee wrote:
>>>> Hello fellow Squid users does anyone know how to fix this issue?
>>> 
>>> I counted about eight different "issues" in your cache.log sample. Most of them are probably independent. I recommend that you explicitly pick _one_, search mailing list archives for previous discussions about it, and then provide as many details about it as you can (e.g., what traffic causes it and/or matching access.log records).
>>> 
>>> 
>>> HTH,
>>> 
>>> Alex.
>>> 
>>> 
>>>> Squid - Cache Logs
>>>> Date-Time    Message
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:54:34    kick abandoning conn7853 local=192.168.1.1:3128 remote=192.168.1.5:49710 FD 89 flags=1
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:54:29    kick abandoning conn7844 local=192.168.1.1:3128 remote=192.168.1.5:49702 FD 81 flags=1
>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7648 local=192.168.1.1:3128 remote=192.168.1.5:49672 FD 44 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7647 local=192.168.1.1:3128 remote=192.168.1.5:49670 FD 43 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7646 local=192.168.1.1:3128 remote=192.168.1.5:49668 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:53:04    ERROR: failure while accepting a TLS connection on conn7367 local=192.168.1.1:3128 remote=192.168.1.5:49627 FD 22 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:52:47    ERROR: failure while accepting a TLS connection on conn7345 local=192.168.1.1:3128 remote=192.168.1.5:49618 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:52:38    ERROR: failure while accepting a TLS connection on conn7340 local=192.168.1.1:3128 remote=192.168.1.5:49616 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:52:34    ERROR: failure while accepting a TLS connection on conn7316 local=192.168.1.1:3128 remote=192.168.1.5:49609 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:51:55    WARNING: Error Pages Missing Language: en-us
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:51:55    ERROR: loading file 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': (2) No such file or directory
>>>> 03.07.2024 10:51:44    ERROR: failure while accepting a TLS connection on conn7102 local=192.168.1.1:3128 remote=192.168.1.5:49574 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:51:28    ERROR: failure while accepting a TLS connection on conn7071 local=192.168.1.1:3128 remote=192.168.1.5:49568 FD 92 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:50:29    ERROR: failure while accepting a TLS connection on conn6944 local=192.168.1.1:3128 remote=192.168.1.5:49534 FD 101 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:49:54    ERROR: failure while accepting a TLS connection on conn6866 local=192.168.1.1:3128 remote=192.168.1.5:49519 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:49:38    ERROR: failure while accepting a TLS connection on conn6809 local=192.168.1.1:3128 remote=192.168.1.5:49503 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:49:32    ERROR: system call failure while accepting a TLS connection on conn6794 local=192.168.1.1:3128 remote=192.168.1.5:49496 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
>>>> 03.07.2024 10:49:24    ERROR: failure while accepting a TLS connection on conn6776 local=192.168.1.1:3128 remote=192.168.1.5:49481 FD 137 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:48:49    ERROR: failure while accepting a TLS connection on conn6440 local=192.168.1.1:3128 remote=192.168.1.5:49424 FD 16 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:48:49    ERROR: failure while accepting a TLS connection on conn6445 local=192.168.1.1:3128 remote=192.168.1.5:49426 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:48:22    ERROR: failure while accepting a TLS connection on conn6035 local=192.168.1.1:3128 remote=192.168.1.5:49355 FD 226 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128 remote=192.168.1.5:49318 FD 33 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5875 local=192.168.1.1:3128 remote=192.168.1.5:49312 FD 216 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5876 local=192.168.1.1:3128 remote=192.168.1.5:49314 FD 217 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:47:57    ERROR: failure while accepting a TLS connection on conn5815 local=192.168.1.1:3128 remote=192.168.1.5:49297 FD 201 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:47:54    ERROR: failure while accepting a TLS connection on conn5760 local=192.168.1.1:3128 remote=192.168.1.5:49289 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:47:52    ERROR: failure while accepting a TLS connection on conn5717 local=192.168.1.1:3128 remote=192.168.1.5:49284 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:47:50    ERROR: failure while accepting a TLS connection on conn5552 local=192.168.1.1:3128 remote=192.168.1.5:49268 FD 142 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:47:34    kick abandoning conn5254 local=192.168.1.1:3128 remote=192.168.1.5:49209 FD 100 flags=1
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:47:21    kick abandoning conn5022 local=192.168.1.1:3128 remote=192.168.1.5:49167 FD 37 flags=1
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:47:21    kick abandoning conn5020 local=192.168.1.1:3128 remote=192.168.1.5:49165 FD 36 flags=1
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:42:22    WARNING: Forwarding loop detected for:
>>>> 03.07.2024 10:40:08    ERROR: failure while accepting a TLS connection on conn4955 local=192.168.1.1:3128 remote=192.168.1.5:52339 FD 98 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 31.12.1969 16:00:00
>>>> 03.07.2024 10:39:52    kick abandoning conn4927 local=192.168.1.1:3128 remote=192.168.1.5:52331 FD 105 flags=1
>>>> 03.07.2024 10:39:09    ERROR: failure while accepting a TLS connection on conn4846 local=192.168.1.1:3128 remote=192.168.1.5:52314 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:38:14    ERROR: failure while accepting a TLS connection on conn4650 local=192.168.1.1:3128 remote=192.168.1.5:52274 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>> 03.07.2024 10:38:08    ERROR: failure while accepting a TLS connection on conn4645 local=192.168.1.1:3128 remote=192.168.1.5:52272 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>> 03.07.2024 10:38:04    ERROR: Unsupported TLS option SINGLE_ECDH_USE
>>>> 03.07.2024 10:38:04    ERROR: Unsupported TLS option SINGLE_DH_USE
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> 31.12.1969 16:00:00
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>>> 
> 



From rousskov at measurement-factory.com  Thu Jul  4 21:45:29 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 4 Jul 2024 17:45:29 -0400
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <DA771A75-5CF4-4CB1-B63A-AD2937C07604@gmail.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
 <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
 <DA771A75-5CF4-4CB1-B63A-AD2937C07604@gmail.com>
Message-ID: <f4b44f1a-e817-407c-8045-26af617b6cd4@measurement-factory.com>

On 2024-07-04 15:37, Jonathan Lee wrote:

> in Squid.conf I have nothing with that detective.

Sounds good; sslproxy_cert_sign default should work OK in most cases. I 
mentioned signUntrusted algorithm so that you can discover (from the 
corresponding sslproxy_cert_sign documentation) which CA/certificate 
Squid uses in which SslBump use case. Triage is often easier if folks 
share the same working theory, and my current working theory suggests 
that we are looking at a (default) signUntrusted use case.

The solution here probably does _not_ involve changing 
sslproxy_cert_sign configuration, but, to make progress, I need more 
info to confirm this working theory and describe next steps.


> Yes I am using SSL bump with this configuration..

Noted, thank you.


> So would I use this directive 

I do not recommend changing your configuration at this time. I recommend 
rereading my earlier recommendation and following that instead: "As the 
next step in triage, I recommend determining what that CA is in these 
cases (e.g., by capturing raw TLS packets and matching them with 
connection information from A000417 error messages in cache.log or 
%err_detail in access.log)."


HTH,

Alex.


>> On Jul 4, 2024, at 09:56, Alex Rousskov wrote:
>>
>> On 2024-07-04 12:11, Jonathan Lee wrote:
>>> failure while accepting a TLS connection on conn5887 
>>> local=192.168.1.1:3128
>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417
>>
>> A000417 is an "unknown CA" alert sent by client to Squid while the 
>> client is trying to establish a TLS connection to/through Squid. The 
>> client does not trust the Certificate Authority that signed the 
>> certificate that was used for that TLS connection.
>>
>> As the next step in triage, I recommend determining what that CA is in 
>> these cases (e.g., by capturing raw TLS packets and matching them with 
>> connection information from A000417 error messages in cache.log or 
>> %err_detail in access.log).
>>
>> If you use SslBump for port 3128 traffic, then one of the 
>> possibilities here is that Squid is using an unknown-to-client CA to 
>> report an origin server that Squid itself does not trust (see 
>> signUntrusted in squid.conf.documented). In those cases, logging a 
>> level-1 ERROR is a Squid bug because that expected/desirable outcome 
>> should be treated as success (and a successful TLS accept treated as 
>> an error!).
>>
>>
>> HTH,
>>
>> Alex.


>>> Is my main concern however I use the squid guard URL blocker
>>> Sent from my iPhone
>>>> On Jul 4, 2024, at 07:41, Alex Rousskov 
>>>> <rousskov at measurement-factory.com> wrote:
>>>>
>>>> ?On 2024-07-03 13:56, Jonathan Lee wrote:
>>>>> Hello fellow Squid users does anyone know how to fix this issue?
>>>>
>>>> I counted about eight different "issues" in your cache.log sample. 
>>>> Most of them are probably independent. I recommend that you 
>>>> explicitly pick _one_, search mailing list archives for previous 
>>>> discussions about it, and then provide as many details about it as 
>>>> you can (e.g., what traffic causes it and/or matching access.log 
>>>> records).
>>>>
>>>>
>>>> HTH,
>>>>
>>>> Alex.
>>>>
>>>>
>>>>> Squid - Cache Logs
>>>>> Date-Time ? ?Message
>>>>> 31.12.1969 16:00:00
>>>>> 03.07.2024 10:54:34 ? ?kick abandoning 
>>>>> conn7853?local=192.168.1.1:3128 remote=192.168.1.5:49710 FD 89 flags=1
>>>>> 31.12.1969 16:00:00
>>>>> 03.07.2024 10:54:29 ? ?kick abandoning 
>>>>> conn7844?local=192.168.1.1:3128 remote=192.168.1.5:49702 FD 81 flags=1
>>>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn7648 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49672 FD 44 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn7647 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49670 FD 43 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn7646 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49668 FD 34 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 03.07.2024 10:53:04 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn7367 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49627 FD 22 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 03.07.2024 10:52:47 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn7345 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49618 FD 31 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 03.07.2024 10:52:38 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn7340 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49616 FD 45 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>> 03.07.2024 10:52:34 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn7316 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49609 FD 45 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 31.12.1969 16:00:00
>>>>> 03.07.2024 10:51:55 ? ?WARNING: Error Pages Missing Language: en-us
>>>>> 31.12.1969 16:00:00
>>>>> 03.07.2024 10:51:55 ? ?ERROR: loading file 
>>>>> 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': (2) No 
>>>>> such?file or directory
>>>>> 03.07.2024 10:51:44 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn7102 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49574 FD 34 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 03.07.2024 10:51:28 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn7071 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49568 FD 92 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 03.07.2024 10:50:29 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn6944 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49534 FD 101 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>> 03.07.2024 10:49:54 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn6866 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49519 FD 31 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 03.07.2024 10:49:38 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn6809 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49503 FD 31 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 31.12.1969 16:00:00
>>>>> 03.07.2024 10:49:32 ? ?ERROR: system call failure while accepting a 
>>>>> TLS connection on conn6794 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49496 FD 19 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
>>>>> 03.07.2024 10:49:24 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn6776 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49481 FD 137 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>> 03.07.2024 10:48:49 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn6440 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49424 FD 16 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>> 03.07.2024 10:48:49 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn6445 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49426 FD 34 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 03.07.2024 10:48:22 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn6035 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49355 FD 226 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn5887 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49318 FD 33 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn5875 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49312 FD 216 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn5876 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49314 FD 217 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 03.07.2024 10:47:57 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn5815 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49297 FD 201 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>> 03.07.2024 10:47:54 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn5760 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49289 FD 195 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>> 03.07.2024 10:47:52 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn5717 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49284 FD 195 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>> 03.07.2024 10:47:50 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn5552 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:49268 FD 142 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>> 31.12.1969 16:00:00
>>>>> 03.07.2024 10:47:34 ? ?kick abandoning 
>>>>> conn5254?local=192.168.1.1:3128 remote=192.168.1.5:49209 FD 100 flags=1
>>>>> 31.12.1969 16:00:00
>>>>> 03.07.2024 10:47:21 ? ?kick abandoning 
>>>>> conn5022?local=192.168.1.1:3128 remote=192.168.1.5:49167 FD 37 flags=1
>>>>> 31.12.1969 16:00:00
>>>>> 03.07.2024 10:47:21 ? ?kick abandoning 
>>>>> conn5020?local=192.168.1.1:3128 remote=192.168.1.5:49165 FD 36 flags=1
>>>>> 31.12.1969 16:00:00
>>>>> 31.12.1969 16:00:00
>>>>> 31.12.1969 16:00:00
>>>>> 31.12.1969 16:00:00
>>>>> 31.12.1969 16:00:00
>>>>> 31.12.1969 16:00:00
>>>>> 31.12.1969 16:00:00
>>>>> 31.12.1969 16:00:00
>>>>> 31.12.1969 16:00:00
>>>>> 31.12.1969 16:00:00
>>>>> 03.07.2024 10:42:22 ? ?WARNING: Forwarding loop?detected for:
>>>>> 03.07.2024 10:40:08 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn4955 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:52339 FD 98 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 31.12.1969 16:00:00
>>>>> 03.07.2024 10:39:52 ? ?kick abandoning 
>>>>> conn4927?local=192.168.1.1:3128 remote=192.168.1.5:52331 FD 105 flags=1
>>>>> 03.07.2024 10:39:09 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn4846 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:52314 FD 19 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 03.07.2024 10:38:14 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn4650 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:52274 FD 35 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>> 03.07.2024 10:38:08 ? ?ERROR: failure while accepting a TLS 
>>>>> connection on conn4645 local=192.168.1.1:3128 
>>>>> remote=192.168.1.5:52272 FD 35 flags=1: 
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>> 03.07.2024 10:38:04 ? ?ERROR: Unsupported TLS option SINGLE_ECDH_USE
>>>>> 03.07.2024 10:38:04 ? ?ERROR: Unsupported TLS option SINGLE_DH_USE
>>>>> 31.12.1969 16:00:00
>>>>> 31.12.1969 16:00:00
>>>>> 31.12.1969 16:00:00
>>>>> 31.12.1969 16:00:00
>>>>> 31.12.1969 16:00:00
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>
>>
> 



From jonathanlee571 at gmail.com  Thu Jul  4 22:12:24 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 4 Jul 2024 15:12:24 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <f4b44f1a-e817-407c-8045-26af617b6cd4@measurement-factory.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
 <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
 <DA771A75-5CF4-4CB1-B63A-AD2937C07604@gmail.com>
 <f4b44f1a-e817-407c-8045-26af617b6cd4@measurement-factory.com>
Message-ID: <88441F2A-5A7F-469B-8AD3-B27CF1ED7B28@gmail.com>

I know before I could use 

tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

However with the update I am seeing 

ERROR: Unsupported TLS option SINGLE_ECDH_USE

I found researching in lists-squid-cache.org <http://lists-squid-cache.org/> that someone solved this with appending TLS13-AES-256-CGM-SHA384 to the ciphers. 

I am thinking this is my issue also.

I see that error over and over when I run "squid -k parse?

Do I append this to the options cipher list?

Jonathan Lee

> On Jul 4, 2024, at 14:45, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> On 2024-07-04 15:37, Jonathan Lee wrote:
> 
>> in Squid.conf I have nothing with that detective.
> 
> Sounds good; sslproxy_cert_sign default should work OK in most cases. I mentioned signUntrusted algorithm so that you can discover (from the corresponding sslproxy_cert_sign documentation) which CA/certificate Squid uses in which SslBump use case. Triage is often easier if folks share the same working theory, and my current working theory suggests that we are looking at a (default) signUntrusted use case.
> 
> The solution here probably does _not_ involve changing sslproxy_cert_sign configuration, but, to make progress, I need more info to confirm this working theory and describe next steps.
> 
> 
>> Yes I am using SSL bump with this configuration..
> 
> Noted, thank you.
> 
> 
>> So would I use this directive
> 
> I do not recommend changing your configuration at this time. I recommend rereading my earlier recommendation and following that instead: "As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log)."
> 
> 
> HTH,
> 
> Alex.
> 
> 
>>> On Jul 4, 2024, at 09:56, Alex Rousskov wrote:
>>> 
>>> On 2024-07-04 12:11, Jonathan Lee wrote:
>>>> failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128
>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417
>>> 
>>> A000417 is an "unknown CA" alert sent by client to Squid while the client is trying to establish a TLS connection to/through Squid. The client does not trust the Certificate Authority that signed the certificate that was used for that TLS connection.
>>> 
>>> As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).
>>> 
>>> If you use SslBump for port 3128 traffic, then one of the possibilities here is that Squid is using an unknown-to-client CA to report an origin server that Squid itself does not trust (see signUntrusted in squid.conf.documented). In those cases, logging a level-1 ERROR is a Squid bug because that expected/desirable outcome should be treated as success (and a successful TLS accept treated as an error!).
>>> 
>>> 
>>> HTH,
>>> 
>>> Alex.
> 
> 
>>>> Is my main concern however I use the squid guard URL blocker
>>>> Sent from my iPhone
>>>>> On Jul 4, 2024, at 07:41, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>>> 
>>>>> ?On 2024-07-03 13:56, Jonathan Lee wrote:
>>>>>> Hello fellow Squid users does anyone know how to fix this issue?
>>>>> 
>>>>> I counted about eight different "issues" in your cache.log sample. Most of them are probably independent. I recommend that you explicitly pick _one_, search mailing list archives for previous discussions about it, and then provide as many details about it as you can (e.g., what traffic causes it and/or matching access.log records).
>>>>> 
>>>>> 
>>>>> HTH,
>>>>> 
>>>>> Alex.
>>>>> 
>>>>> 
>>>>>> Squid - Cache Logs
>>>>>> Date-Time    Message
>>>>>> 31.12.1969 16:00:00
>>>>>> 03.07.2024 10:54:34    kick abandoning conn7853 local=192.168.1.1:3128 remote=192.168.1.5:49710 FD 89 flags=1
>>>>>> 31.12.1969 16:00:00
>>>>>> 03.07.2024 10:54:29    kick abandoning conn7844 local=192.168.1.1:3128 remote=192.168.1.5:49702 FD 81 flags=1
>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7648 local=192.168.1.1:3128 remote=192.168.1.5:49672 FD 44 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7647 local=192.168.1.1:3128 remote=192.168.1.5:49670 FD 43 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7646 local=192.168.1.1:3128 remote=192.168.1.5:49668 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:53:04    ERROR: failure while accepting a TLS connection on conn7367 local=192.168.1.1:3128 remote=192.168.1.5:49627 FD 22 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:52:47    ERROR: failure while accepting a TLS connection on conn7345 local=192.168.1.1:3128 remote=192.168.1.5:49618 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:52:38    ERROR: failure while accepting a TLS connection on conn7340 local=192.168.1.1:3128 remote=192.168.1.5:49616 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:52:34    ERROR: failure while accepting a TLS connection on conn7316 local=192.168.1.1:3128 remote=192.168.1.5:49609 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 31.12.1969 16:00:00
>>>>>> 03.07.2024 10:51:55    WARNING: Error Pages Missing Language: en-us
>>>>>> 31.12.1969 16:00:00
>>>>>> 03.07.2024 10:51:55    ERROR: loading file 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': (2) No such file or directory
>>>>>> 03.07.2024 10:51:44    ERROR: failure while accepting a TLS connection on conn7102 local=192.168.1.1:3128 remote=192.168.1.5:49574 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:51:28    ERROR: failure while accepting a TLS connection on conn7071 local=192.168.1.1:3128 remote=192.168.1.5:49568 FD 92 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:50:29    ERROR: failure while accepting a TLS connection on conn6944 local=192.168.1.1:3128 remote=192.168.1.5:49534 FD 101 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:49:54    ERROR: failure while accepting a TLS connection on conn6866 local=192.168.1.1:3128 remote=192.168.1.5:49519 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:49:38    ERROR: failure while accepting a TLS connection on conn6809 local=192.168.1.1:3128 remote=192.168.1.5:49503 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 31.12.1969 16:00:00
>>>>>> 03.07.2024 10:49:32    ERROR: system call failure while accepting a TLS connection on conn6794 local=192.168.1.1:3128 remote=192.168.1.5:49496 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
>>>>>> 03.07.2024 10:49:24    ERROR: failure while accepting a TLS connection on conn6776 local=192.168.1.1:3128 remote=192.168.1.5:49481 FD 137 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:48:49    ERROR: failure while accepting a TLS connection on conn6440 local=192.168.1.1:3128 remote=192.168.1.5:49424 FD 16 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:48:49    ERROR: failure while accepting a TLS connection on conn6445 local=192.168.1.1:3128 remote=192.168.1.5:49426 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:48:22    ERROR: failure while accepting a TLS connection on conn6035 local=192.168.1.1:3128 remote=192.168.1.5:49355 FD 226 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128 remote=192.168.1.5:49318 FD 33 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5875 local=192.168.1.1:3128 remote=192.168.1.5:49312 FD 216 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5876 local=192.168.1.1:3128 remote=192.168.1.5:49314 FD 217 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:47:57    ERROR: failure while accepting a TLS connection on conn5815 local=192.168.1.1:3128 remote=192.168.1.5:49297 FD 201 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:47:54    ERROR: failure while accepting a TLS connection on conn5760 local=192.168.1.1:3128 remote=192.168.1.5:49289 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:47:52    ERROR: failure while accepting a TLS connection on conn5717 local=192.168.1.1:3128 remote=192.168.1.5:49284 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:47:50    ERROR: failure while accepting a TLS connection on conn5552 local=192.168.1.1:3128 remote=192.168.1.5:49268 FD 142 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>> 31.12.1969 16:00:00
>>>>>> 03.07.2024 10:47:34    kick abandoning conn5254 local=192.168.1.1:3128 remote=192.168.1.5:49209 FD 100 flags=1
>>>>>> 31.12.1969 16:00:00
>>>>>> 03.07.2024 10:47:21    kick abandoning conn5022 local=192.168.1.1:3128 remote=192.168.1.5:49167 FD 37 flags=1
>>>>>> 31.12.1969 16:00:00
>>>>>> 03.07.2024 10:47:21    kick abandoning conn5020 local=192.168.1.1:3128 remote=192.168.1.5:49165 FD 36 flags=1
>>>>>> 31.12.1969 16:00:00
>>>>>> 31.12.1969 16:00:00
>>>>>> 31.12.1969 16:00:00
>>>>>> 31.12.1969 16:00:00
>>>>>> 31.12.1969 16:00:00
>>>>>> 31.12.1969 16:00:00
>>>>>> 31.12.1969 16:00:00
>>>>>> 31.12.1969 16:00:00
>>>>>> 31.12.1969 16:00:00
>>>>>> 31.12.1969 16:00:00
>>>>>> 03.07.2024 10:42:22    WARNING: Forwarding loop detected for:
>>>>>> 03.07.2024 10:40:08    ERROR: failure while accepting a TLS connection on conn4955 local=192.168.1.1:3128 remote=192.168.1.5:52339 FD 98 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 31.12.1969 16:00:00
>>>>>> 03.07.2024 10:39:52    kick abandoning conn4927 local=192.168.1.1:3128 remote=192.168.1.5:52331 FD 105 flags=1
>>>>>> 03.07.2024 10:39:09    ERROR: failure while accepting a TLS connection on conn4846 local=192.168.1.1:3128 remote=192.168.1.5:52314 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:38:14    ERROR: failure while accepting a TLS connection on conn4650 local=192.168.1.1:3128 remote=192.168.1.5:52274 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:38:08    ERROR: failure while accepting a TLS connection on conn4645 local=192.168.1.1:3128 remote=192.168.1.5:52272 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>> 03.07.2024 10:38:04    ERROR: Unsupported TLS option SINGLE_ECDH_USE
>>>>>> 03.07.2024 10:38:04    ERROR: Unsupported TLS option SINGLE_DH_USE
>>>>>> 31.12.1969 16:00:00
>>>>>> 31.12.1969 16:00:00
>>>>>> 31.12.1969 16:00:00
>>>>>> 31.12.1969 16:00:00
>>>>>> 31.12.1969 16:00:00
>>>>>> _______________________________________________
>>>>>> squid-users mailing list
>>>>>> squid-users at lists.squid-cache.org
>>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>> 
>>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240704/8d784417/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jul  4 22:13:47 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 4 Jul 2024 15:13:47 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <88441F2A-5A7F-469B-8AD3-B27CF1ED7B28@gmail.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
 <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
 <DA771A75-5CF4-4CB1-B63A-AD2937C07604@gmail.com>
 <f4b44f1a-e817-407c-8045-26af617b6cd4@measurement-factory.com>
 <88441F2A-5A7F-469B-8AD3-B27CF1ED7B28@gmail.com>
Message-ID: <E733FB66-E104-43B6-BFDD-1C255C20816A@gmail.com>

Sorry 

tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

Would I add this here?

> On Jul 4, 2024, at 15:12, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> I know before I could use 
> 
> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> 
> However with the update I am seeing 
> 
> ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 
> I found researching in lists-squid-cache.org <http://lists-squid-cache.org/> that someone solved this with appending TLS13-AES-256-CGM-SHA384 to the ciphers. 
> 
> I am thinking this is my issue also.
> 
> I see that error over and over when I run "squid -k parse?
> 
> Do I append this to the options cipher list?
> 
> Jonathan Lee
> 
>> On Jul 4, 2024, at 14:45, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>> 
>> On 2024-07-04 15:37, Jonathan Lee wrote:
>> 
>>> in Squid.conf I have nothing with that detective.
>> 
>> Sounds good; sslproxy_cert_sign default should work OK in most cases. I mentioned signUntrusted algorithm so that you can discover (from the corresponding sslproxy_cert_sign documentation) which CA/certificate Squid uses in which SslBump use case. Triage is often easier if folks share the same working theory, and my current working theory suggests that we are looking at a (default) signUntrusted use case.
>> 
>> The solution here probably does _not_ involve changing sslproxy_cert_sign configuration, but, to make progress, I need more info to confirm this working theory and describe next steps.
>> 
>> 
>>> Yes I am using SSL bump with this configuration..
>> 
>> Noted, thank you.
>> 
>> 
>>> So would I use this directive
>> 
>> I do not recommend changing your configuration at this time. I recommend rereading my earlier recommendation and following that instead: "As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log)."
>> 
>> 
>> HTH,
>> 
>> Alex.
>> 
>> 
>>>> On Jul 4, 2024, at 09:56, Alex Rousskov wrote:
>>>> 
>>>> On 2024-07-04 12:11, Jonathan Lee wrote:
>>>>> failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417
>>>> 
>>>> A000417 is an "unknown CA" alert sent by client to Squid while the client is trying to establish a TLS connection to/through Squid. The client does not trust the Certificate Authority that signed the certificate that was used for that TLS connection.
>>>> 
>>>> As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).
>>>> 
>>>> If you use SslBump for port 3128 traffic, then one of the possibilities here is that Squid is using an unknown-to-client CA to report an origin server that Squid itself does not trust (see signUntrusted in squid.conf.documented). In those cases, logging a level-1 ERROR is a Squid bug because that expected/desirable outcome should be treated as success (and a successful TLS accept treated as an error!).
>>>> 
>>>> 
>>>> HTH,
>>>> 
>>>> Alex.
>> 
>> 
>>>>> Is my main concern however I use the squid guard URL blocker
>>>>> Sent from my iPhone
>>>>>> On Jul 4, 2024, at 07:41, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>>>> 
>>>>>> ?On 2024-07-03 13:56, Jonathan Lee wrote:
>>>>>>> Hello fellow Squid users does anyone know how to fix this issue?
>>>>>> 
>>>>>> I counted about eight different "issues" in your cache.log sample. Most of them are probably independent. I recommend that you explicitly pick _one_, search mailing list archives for previous discussions about it, and then provide as many details about it as you can (e.g., what traffic causes it and/or matching access.log records).
>>>>>> 
>>>>>> 
>>>>>> HTH,
>>>>>> 
>>>>>> Alex.
>>>>>> 
>>>>>> 
>>>>>>> Squid - Cache Logs
>>>>>>> Date-Time    Message
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:54:34    kick abandoning conn7853 local=192.168.1.1:3128 remote=192.168.1.5:49710 FD 89 flags=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:54:29    kick abandoning conn7844 local=192.168.1.1:3128 remote=192.168.1.5:49702 FD 81 flags=1
>>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7648 local=192.168.1.1:3128 remote=192.168.1.5:49672 FD 44 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7647 local=192.168.1.1:3128 remote=192.168.1.5:49670 FD 43 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7646 local=192.168.1.1:3128 remote=192.168.1.5:49668 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:53:04    ERROR: failure while accepting a TLS connection on conn7367 local=192.168.1.1:3128 remote=192.168.1.5:49627 FD 22 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:52:47    ERROR: failure while accepting a TLS connection on conn7345 local=192.168.1.1:3128 remote=192.168.1.5:49618 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:52:38    ERROR: failure while accepting a TLS connection on conn7340 local=192.168.1.1:3128 remote=192.168.1.5:49616 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:52:34    ERROR: failure while accepting a TLS connection on conn7316 local=192.168.1.1:3128 remote=192.168.1.5:49609 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:51:55    WARNING: Error Pages Missing Language: en-us
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:51:55    ERROR: loading file 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': (2) No such file or directory
>>>>>>> 03.07.2024 10:51:44    ERROR: failure while accepting a TLS connection on conn7102 local=192.168.1.1:3128 remote=192.168.1.5:49574 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:51:28    ERROR: failure while accepting a TLS connection on conn7071 local=192.168.1.1:3128 remote=192.168.1.5:49568 FD 92 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:50:29    ERROR: failure while accepting a TLS connection on conn6944 local=192.168.1.1:3128 remote=192.168.1.5:49534 FD 101 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:49:54    ERROR: failure while accepting a TLS connection on conn6866 local=192.168.1.1:3128 remote=192.168.1.5:49519 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:49:38    ERROR: failure while accepting a TLS connection on conn6809 local=192.168.1.1:3128 remote=192.168.1.5:49503 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:49:32    ERROR: system call failure while accepting a TLS connection on conn6794 local=192.168.1.1:3128 remote=192.168.1.5:49496 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
>>>>>>> 03.07.2024 10:49:24    ERROR: failure while accepting a TLS connection on conn6776 local=192.168.1.1:3128 remote=192.168.1.5:49481 FD 137 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:48:49    ERROR: failure while accepting a TLS connection on conn6440 local=192.168.1.1:3128 remote=192.168.1.5:49424 FD 16 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:48:49    ERROR: failure while accepting a TLS connection on conn6445 local=192.168.1.1:3128 remote=192.168.1.5:49426 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:48:22    ERROR: failure while accepting a TLS connection on conn6035 local=192.168.1.1:3128 remote=192.168.1.5:49355 FD 226 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128 remote=192.168.1.5:49318 FD 33 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5875 local=192.168.1.1:3128 remote=192.168.1.5:49312 FD 216 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5876 local=192.168.1.1:3128 remote=192.168.1.5:49314 FD 217 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:47:57    ERROR: failure while accepting a TLS connection on conn5815 local=192.168.1.1:3128 remote=192.168.1.5:49297 FD 201 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:47:54    ERROR: failure while accepting a TLS connection on conn5760 local=192.168.1.1:3128 remote=192.168.1.5:49289 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:47:52    ERROR: failure while accepting a TLS connection on conn5717 local=192.168.1.1:3128 remote=192.168.1.5:49284 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:47:50    ERROR: failure while accepting a TLS connection on conn5552 local=192.168.1.1:3128 remote=192.168.1.5:49268 FD 142 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:47:34    kick abandoning conn5254 local=192.168.1.1:3128 remote=192.168.1.5:49209 FD 100 flags=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:47:21    kick abandoning conn5022 local=192.168.1.1:3128 remote=192.168.1.5:49167 FD 37 flags=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:47:21    kick abandoning conn5020 local=192.168.1.1:3128 remote=192.168.1.5:49165 FD 36 flags=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:42:22    WARNING: Forwarding loop detected for:
>>>>>>> 03.07.2024 10:40:08    ERROR: failure while accepting a TLS connection on conn4955 local=192.168.1.1:3128 remote=192.168.1.5:52339 FD 98 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:39:52    kick abandoning conn4927 local=192.168.1.1:3128 remote=192.168.1.5:52331 FD 105 flags=1
>>>>>>> 03.07.2024 10:39:09    ERROR: failure while accepting a TLS connection on conn4846 local=192.168.1.1:3128 remote=192.168.1.5:52314 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:38:14    ERROR: failure while accepting a TLS connection on conn4650 local=192.168.1.1:3128 remote=192.168.1.5:52274 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:38:08    ERROR: failure while accepting a TLS connection on conn4645 local=192.168.1.1:3128 remote=192.168.1.5:52272 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:38:04    ERROR: Unsupported TLS option SINGLE_ECDH_USE
>>>>>>> 03.07.2024 10:38:04    ERROR: Unsupported TLS option SINGLE_DH_USE
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> _______________________________________________
>>>>>>> squid-users mailing list
>>>>>>> squid-users at lists.squid-cache.org
>>>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>>> 
>>>> 
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240704/4b84bb5f/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jul  4 23:02:52 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 4 Jul 2024 16:02:52 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <E733FB66-E104-43B6-BFDD-1C255C20816A@gmail.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
 <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
 <DA771A75-5CF4-4CB1-B63A-AD2937C07604@gmail.com>
 <f4b44f1a-e817-407c-8045-26af617b6cd4@measurement-factory.com>
 <88441F2A-5A7F-469B-8AD3-B27CF1ED7B28@gmail.com>
 <E733FB66-E104-43B6-BFDD-1C255C20816A@gmail.com>
Message-ID: <BCA3C955-2899-4C9E-B82B-65BF268579C0@gmail.com>

>>> I do not recommend changing your configuration at this time. I recommend rereading my earlier recommendation and following that instead: "As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log)."


Ok I went back to 5.8 and ran the following command after I removed the changes I used does this help this is ran on the firewall side itself. 

 openssl s_client -connect foxnews.com:443 <http://foxnews.com:443/>

depth=2 C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert Global Root CA
verify return:1
depth=1 C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
verify return:1
depth=0 C = US, ST = New York, L = New York, O = "Fox News Network, LLC", CN = wildcard.foxnews.com
verify return:1
CONNECTED(00000004)
---
Certificate chain
 0 s:C = US, ST = New York, L = New York, O = "Fox News Network, LLC", CN = wildcard.foxnews.com
   i:C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
 1 s:C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
   i:C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert Global Root CA

-----END CERTIFICATE-----
subject=C = US, ST = New York, L = New York, O = "Fox News Network, LLC", CN = wildcard.foxnews.com

issuer=C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1

---
No client certificate CA names sent
Peer signing digest: SHA256
Peer signature type: ECDSA
Server Temp Key: X25519, 253 bits
---
SSL handshake has read 4198 bytes and written 393 bytes
Verification: OK
---
New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384
Server public key is 256 bit
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
Early data was not sent
Verify return code: 0 (ok)
---
DONE

Does that help I am not going to pretend I understand TLS options I do understand how the SSL ciphers work and certificates but all the different options and kinds are what is confusing me. I did not seem to have this error before.


Should I regenerate a new certificate for the new version of Squid and redeploy them all to hosts again? I used this method in the past and it worked for a long time after I imported it. I am wondering if this is outdated now

openssl req -x509 -new -nodes -key myProxykey.key -sha256 -days 365 -out myProxyca.pem


> On Jul 4, 2024, at 15:13, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Sorry 
> 
> tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 
> Would I add this here?
> 
>> On Jul 4, 2024, at 15:12, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> I know before I could use 
>> 
>> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>> 
>> However with the update I am seeing 
>> 
>> ERROR: Unsupported TLS option SINGLE_ECDH_USE
>> 
>> I found researching in lists-squid-cache.org <http://lists-squid-cache.org/> that someone solved this with appending TLS13-AES-256-CGM-SHA384 to the ciphers. 
>> 
>> I am thinking this is my issue also.
>> 
>> I see that error over and over when I run "squid -k parse?
>> 
>> Do I append this to the options cipher list?
>> 
>> Jonathan Lee
>> 
>>> On Jul 4, 2024, at 14:45, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>> 
>>> On 2024-07-04 15:37, Jonathan Lee wrote:
>>> 
>>>> in Squid.conf I have nothing with that detective.
>>> 
>>> Sounds good; sslproxy_cert_sign default should work OK in most cases. I mentioned signUntrusted algorithm so that you can discover (from the corresponding sslproxy_cert_sign documentation) which CA/certificate Squid uses in which SslBump use case. Triage is often easier if folks share the same working theory, and my current working theory suggests that we are looking at a (default) signUntrusted use case.
>>> 
>>> The solution here probably does _not_ involve changing sslproxy_cert_sign configuration, but, to make progress, I need more info to confirm this working theory and describe next steps.
>>> 
>>> 
>>>> Yes I am using SSL bump with this configuration..
>>> 
>>> Noted, thank you.
>>> 
>>> 
>>>> So would I use this directive
>>> 
>>> I do not recommend changing your configuration at this time. I recommend rereading my earlier recommendation and following that instead: "As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log)."
>>> 
>>> 
>>> HTH,
>>> 
>>> Alex.
>>> 
>>> 
>>>>> On Jul 4, 2024, at 09:56, Alex Rousskov wrote:
>>>>> 
>>>>> On 2024-07-04 12:11, Jonathan Lee wrote:
>>>>>> failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128
>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417
>>>>> 
>>>>> A000417 is an "unknown CA" alert sent by client to Squid while the client is trying to establish a TLS connection to/through Squid. The client does not trust the Certificate Authority that signed the certificate that was used for that TLS connection.
>>>>> 
>>>>> As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).
>>>>> 
>>>>> If you use SslBump for port 3128 traffic, then one of the possibilities here is that Squid is using an unknown-to-client CA to report an origin server that Squid itself does not trust (see signUntrusted in squid.conf.documented). In those cases, logging a level-1 ERROR is a Squid bug because that expected/desirable outcome should be treated as success (and a successful TLS accept treated as an error!).
>>>>> 
>>>>> 
>>>>> HTH,
>>>>> 
>>>>> Alex.
>>> 
>>> 
>>>>>> Is my main concern however I use the squid guard URL blocker
>>>>>> Sent from my iPhone
>>>>>>> On Jul 4, 2024, at 07:41, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>>>>> 
>>>>>>> ?On 2024-07-03 13:56, Jonathan Lee wrote:
>>>>>>>> Hello fellow Squid users does anyone know how to fix this issue?
>>>>>>> 
>>>>>>> I counted about eight different "issues" in your cache.log sample. Most of them are probably independent. I recommend that you explicitly pick _one_, search mailing list archives for previous discussions about it, and then provide as many details about it as you can (e.g., what traffic causes it and/or matching access.log records).
>>>>>>> 
>>>>>>> 
>>>>>>> HTH,
>>>>>>> 
>>>>>>> Alex.
>>>>>>> 
>>>>>>> 
>>>>>>>> Squid - Cache Logs
>>>>>>>> Date-Time    Message
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 03.07.2024 10:54:34    kick abandoning conn7853 local=192.168.1.1:3128 remote=192.168.1.5:49710 FD 89 flags=1
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 03.07.2024 10:54:29    kick abandoning conn7844 local=192.168.1.1:3128 remote=192.168.1.5:49702 FD 81 flags=1
>>>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7648 local=192.168.1.1:3128 remote=192.168.1.5:49672 FD 44 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7647 local=192.168.1.1:3128 remote=192.168.1.5:49670 FD 43 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7646 local=192.168.1.1:3128 remote=192.168.1.5:49668 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:53:04    ERROR: failure while accepting a TLS connection on conn7367 local=192.168.1.1:3128 remote=192.168.1.5:49627 FD 22 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:52:47    ERROR: failure while accepting a TLS connection on conn7345 local=192.168.1.1:3128 remote=192.168.1.5:49618 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:52:38    ERROR: failure while accepting a TLS connection on conn7340 local=192.168.1.1:3128 remote=192.168.1.5:49616 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:52:34    ERROR: failure while accepting a TLS connection on conn7316 local=192.168.1.1:3128 remote=192.168.1.5:49609 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 03.07.2024 10:51:55    WARNING: Error Pages Missing Language: en-us
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 03.07.2024 10:51:55    ERROR: loading file 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': (2) No such file or directory
>>>>>>>> 03.07.2024 10:51:44    ERROR: failure while accepting a TLS connection on conn7102 local=192.168.1.1:3128 remote=192.168.1.5:49574 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:51:28    ERROR: failure while accepting a TLS connection on conn7071 local=192.168.1.1:3128 remote=192.168.1.5:49568 FD 92 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:50:29    ERROR: failure while accepting a TLS connection on conn6944 local=192.168.1.1:3128 remote=192.168.1.5:49534 FD 101 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:49:54    ERROR: failure while accepting a TLS connection on conn6866 local=192.168.1.1:3128 remote=192.168.1.5:49519 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:49:38    ERROR: failure while accepting a TLS connection on conn6809 local=192.168.1.1:3128 remote=192.168.1.5:49503 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 03.07.2024 10:49:32    ERROR: system call failure while accepting a TLS connection on conn6794 local=192.168.1.1:3128 remote=192.168.1.5:49496 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
>>>>>>>> 03.07.2024 10:49:24    ERROR: failure while accepting a TLS connection on conn6776 local=192.168.1.1:3128 remote=192.168.1.5:49481 FD 137 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:48:49    ERROR: failure while accepting a TLS connection on conn6440 local=192.168.1.1:3128 remote=192.168.1.5:49424 FD 16 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:48:49    ERROR: failure while accepting a TLS connection on conn6445 local=192.168.1.1:3128 remote=192.168.1.5:49426 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:48:22    ERROR: failure while accepting a TLS connection on conn6035 local=192.168.1.1:3128 remote=192.168.1.5:49355 FD 226 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128 remote=192.168.1.5:49318 FD 33 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5875 local=192.168.1.1:3128 remote=192.168.1.5:49312 FD 216 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5876 local=192.168.1.1:3128 remote=192.168.1.5:49314 FD 217 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:47:57    ERROR: failure while accepting a TLS connection on conn5815 local=192.168.1.1:3128 remote=192.168.1.5:49297 FD 201 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:47:54    ERROR: failure while accepting a TLS connection on conn5760 local=192.168.1.1:3128 remote=192.168.1.5:49289 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:47:52    ERROR: failure while accepting a TLS connection on conn5717 local=192.168.1.1:3128 remote=192.168.1.5:49284 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:47:50    ERROR: failure while accepting a TLS connection on conn5552 local=192.168.1.1:3128 remote=192.168.1.5:49268 FD 142 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 03.07.2024 10:47:34    kick abandoning conn5254 local=192.168.1.1:3128 remote=192.168.1.5:49209 FD 100 flags=1
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 03.07.2024 10:47:21    kick abandoning conn5022 local=192.168.1.1:3128 remote=192.168.1.5:49167 FD 37 flags=1
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 03.07.2024 10:47:21    kick abandoning conn5020 local=192.168.1.1:3128 remote=192.168.1.5:49165 FD 36 flags=1
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 03.07.2024 10:42:22    WARNING: Forwarding loop detected for:
>>>>>>>> 03.07.2024 10:40:08    ERROR: failure while accepting a TLS connection on conn4955 local=192.168.1.1:3128 remote=192.168.1.5:52339 FD 98 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 03.07.2024 10:39:52    kick abandoning conn4927 local=192.168.1.1:3128 remote=192.168.1.5:52331 FD 105 flags=1
>>>>>>>> 03.07.2024 10:39:09    ERROR: failure while accepting a TLS connection on conn4846 local=192.168.1.1:3128 remote=192.168.1.5:52314 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:38:14    ERROR: failure while accepting a TLS connection on conn4650 local=192.168.1.1:3128 remote=192.168.1.5:52274 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:38:08    ERROR: failure while accepting a TLS connection on conn4645 local=192.168.1.1:3128 remote=192.168.1.5:52272 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>> 03.07.2024 10:38:04    ERROR: Unsupported TLS option SINGLE_ECDH_USE
>>>>>>>> 03.07.2024 10:38:04    ERROR: Unsupported TLS option SINGLE_DH_USE
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> 31.12.1969 16:00:00
>>>>>>>> _______________________________________________
>>>>>>>> squid-users mailing list
>>>>>>>> squid-users at lists.squid-cache.org
>>>>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>>>> 
>>>>> 
>>> 
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240704/345c44b1/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jul  4 23:12:27 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 4 Jul 2024 16:12:27 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <f4b44f1a-e817-407c-8045-26af617b6cd4@measurement-factory.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
 <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
 <DA771A75-5CF4-4CB1-B63A-AD2937C07604@gmail.com>
 <f4b44f1a-e817-407c-8045-26af617b6cd4@measurement-factory.com>
Message-ID: <CA4A251D-C14E-4E7A-B380-EF9F8C15088D@gmail.com>

You also stated .. " my current working theory suggests that we are looking at a (default) signUntrusted use case.?

I noticed for Squid documents that default is now set to off ..

http://www.squid-cache.org/Versions/v5/cfgman/http_port.html?

http://www.squid-cache.org/Versions/v6/cfgman/http_port.html?
  tls-default-ca[=off]
			Whether to use the system Trusted CAs. Default is OFF.
Would enabling this resolve the problem in Squid 6.6 for error. In theory if default is auto off and it is attempting to use one it would be untrusted automagically after migration

> On Jul 4, 2024, at 14:45, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
>  my current working theory suggests that we are looking at a (default) signUntrusted use case.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240704/6c32b603/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: favicon.ico
Type: image/vnd.microsoft.icon
Size: 1406 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240704/6c32b603/attachment.ico>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: favicon.ico
Type: image/vnd.microsoft.icon
Size: 1406 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240704/6c32b603/attachment-0001.ico>

From jonathanlee571 at gmail.com  Thu Jul  4 23:17:53 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 4 Jul 2024 16:17:53 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <CA4A251D-C14E-4E7A-B380-EF9F8C15088D@gmail.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
 <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
 <DA771A75-5CF4-4CB1-B63A-AD2937C07604@gmail.com>
 <f4b44f1a-e817-407c-8045-26af617b6cd4@measurement-factory.com>
 <CA4A251D-C14E-4E7A-B380-EF9F8C15088D@gmail.com>
Message-ID: <F61CD646-4C7E-4CD5-9B23-C84692F42869@gmail.com>

It does not recognize this directive 

2024/07/04 16:16:46| Processing: url_rewrite_children 32 startup=8 idle=4 concurrency=0
2024/07/04 16:16:46| Processing: tls-default-ca on
2024/07/04 16:16:46| /usr/local/etc/squid/squid.conf(235): unrecognized: 'tls-default-ca?

Or with use of =

> On Jul 4, 2024, at 16:12, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> You also stated .. " my current working theory suggests that we are looking at a (default) signUntrusted use case.?
> 
> I noticed for Squid documents that default is now set to off ..
> 
> http://www.squid-cache.org/Versions/v5/cfgman/http_port.html
> 
> http://www.squid-cache.org/Versions/v6/cfgman/http_port.html
>   tls-default-ca[=off]
> 			Whether to use the system Trusted CAs. Default is OFF.
> Would enabling this resolve the problem in Squid 6.6 for error. In theory if default is auto off and it is attempting to use one it would be untrusted automagically after migration
> 
>> On Jul 4, 2024, at 14:45, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>> 
>>  my current working theory suggests that we are looking at a (default) signUntrusted use case.
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240704/96755169/attachment.htm>

From rousskov at measurement-factory.com  Fri Jul  5 13:00:26 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 5 Jul 2024 09:00:26 -0400
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <88441F2A-5A7F-469B-8AD3-B27CF1ED7B28@gmail.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
 <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
 <DA771A75-5CF4-4CB1-B63A-AD2937C07604@gmail.com>
 <f4b44f1a-e817-407c-8045-26af617b6cd4@measurement-factory.com>
 <88441F2A-5A7F-469B-8AD3-B27CF1ED7B28@gmail.com>
Message-ID: <5fc8a77b-7b0d-4c69-b449-374b8657c79b@measurement-factory.com>

On 2024-07-04 18:12, Jonathan Lee wrote:
> I know before I could use
> 
> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> 
> 
> However with the update I am seeing
> 
> ERROR: Unsupported TLS option SINGLE_ECDH_USE

FWIW, I can only (try to) help with one problem at this time. If you 
really want to attack two problems concurrently, I recommend starting 
another/new thread dedicated to the above problem. Others may be able to 
help you on that other thread.

Alex.

> I found researching in lists-squid-cache.org 
> <http://lists-squid-cache.org>?that someone solved this with appending 
> TLS13-AES-256-CGM-SHA384 to the ciphers.
> 
> I am thinking this is my issue also.
> 
> I see that error over and over when I run "squid -k parse?
> 
> Do I append this to the options cipher list?
> 
> Jonathan Lee
> 
>> On Jul 4, 2024, at 14:45, Alex Rousskov 
>> <rousskov at measurement-factory.com> wrote:
>>
>> On 2024-07-04 15:37, Jonathan Lee wrote:
>>
>>> in Squid.conf I have nothing with that detective.
>>
>> Sounds good; sslproxy_cert_sign default should work OK in most cases. 
>> I mentioned signUntrusted algorithm so that you can discover (from the 
>> corresponding sslproxy_cert_sign documentation) which CA/certificate 
>> Squid uses in which SslBump use case. Triage is often easier if folks 
>> share the same working theory, and my current working theory suggests 
>> that we are looking at a (default) signUntrusted use case.
>>
>> The solution here probably does _not_ involve changing 
>> sslproxy_cert_sign configuration, but, to make progress, I need more 
>> info to confirm this working theory and describe next steps.
>>
>>
>>> Yes I am using SSL bump with this configuration..
>>
>> Noted, thank you.
>>
>>
>>> So would I use this directive
>>
>> I do not recommend changing your configuration at this time. I 
>> recommend rereading my earlier recommendation and following that 
>> instead: "As the next step in triage, I recommend determining what 
>> that CA is in these cases (e.g., by capturing raw TLS packets and 
>> matching them with connection information from A000417 error messages 
>> in cache.log or %err_detail in access.log)."
>>
>>
>> HTH,
>>
>> Alex.
>>
>>
>>>> On Jul 4, 2024, at 09:56, Alex Rousskov wrote:
>>>>
>>>> On 2024-07-04 12:11, Jonathan Lee wrote:
>>>>> failure while accepting a TLS connection on conn5887 
>>>>> local=192.168.1.1:3128
>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417
>>>>
>>>> A000417 is an "unknown CA" alert sent by client to Squid while the 
>>>> client is trying to establish a TLS connection to/through Squid. The 
>>>> client does not trust the Certificate Authority that signed the 
>>>> certificate that was used for that TLS connection.
>>>>
>>>> As the next step in triage, I recommend determining what that CA is 
>>>> in these cases (e.g., by capturing raw TLS packets and matching them 
>>>> with connection information from A000417 error messages in cache.log 
>>>> or %err_detail in access.log).
>>>>
>>>> If you use SslBump for port 3128 traffic, then one of the 
>>>> possibilities here is that Squid is using an unknown-to-client CA to 
>>>> report an origin server that Squid itself does not trust (see 
>>>> signUntrusted in squid.conf.documented). In those cases, logging a 
>>>> level-1 ERROR is a Squid bug because that expected/desirable outcome 
>>>> should be treated as success (and a successful TLS accept treated as 
>>>> an error!).
>>>>
>>>>
>>>> HTH,
>>>>
>>>> Alex.
>>
>>
>>>>> Is my main concern however I use the squid guard URL blocker
>>>>> Sent from my iPhone
>>>>>> On Jul 4, 2024, at 07:41, Alex Rousskov 
>>>>>> <rousskov at measurement-factory.com> wrote:
>>>>>>
>>>>>> ?On 2024-07-03 13:56, Jonathan Lee wrote:
>>>>>>> Hello fellow Squid users does anyone know how to fix this issue?
>>>>>>
>>>>>> I counted about eight different "issues" in your cache.log sample. 
>>>>>> Most of them are probably independent. I recommend that you 
>>>>>> explicitly pick _one_, search mailing list archives for previous 
>>>>>> discussions about it, and then provide as many details about it as 
>>>>>> you can (e.g., what traffic causes it and/or matching access.log 
>>>>>> records).
>>>>>>
>>>>>>
>>>>>> HTH,
>>>>>>
>>>>>> Alex.
>>>>>>
>>>>>>
>>>>>>> Squid - Cache Logs
>>>>>>> Date-Time ? ?Message
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:54:34 ? ?kick abandoning 
>>>>>>> conn7853?local=192.168.1.1:3128 remote=192.168.1.5:49710 FD 89 
>>>>>>> flags=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:54:29 ? ?kick abandoning 
>>>>>>> conn7844?local=192.168.1.1:3128 remote=192.168.1.5:49702 FD 81 
>>>>>>> flags=1
>>>>>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn7648 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49672 FD 44 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn7647 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49670 FD 43 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn7646 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49668 FD 34 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:53:04 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn7367 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49627 FD 22 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:52:47 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn7345 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49618 FD 31 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:52:38 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn7340 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49616 FD 45 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:52:34 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn7316 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49609 FD 45 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:51:55 ? ?WARNING: Error Pages Missing Language: en-us
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:51:55 ? ?ERROR: loading file 
>>>>>>> 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': (2) 
>>>>>>> No such?file or directory
>>>>>>> 03.07.2024 10:51:44 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn7102 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49574 FD 34 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:51:28 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn7071 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49568 FD 92 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:50:29 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn6944 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49534 FD 101 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:49:54 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn6866 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49519 FD 31 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:49:38 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn6809 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49503 FD 31 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:49:32 ? ?ERROR: system call failure while accepting 
>>>>>>> a TLS connection on conn6794 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49496 FD 19 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
>>>>>>> 03.07.2024 10:49:24 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn6776 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49481 FD 137 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:48:49 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn6440 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49424 FD 16 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:48:49 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn6445 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49426 FD 34 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:48:22 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn6035 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49355 FD 226 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn5887 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49318 FD 33 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn5875 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49312 FD 216 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn5876 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49314 FD 217 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:47:57 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn5815 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49297 FD 201 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:47:54 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn5760 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49289 FD 195 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:47:52 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn5717 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49284 FD 195 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:47:50 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn5552 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:49268 FD 142 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:47:34 ? ?kick abandoning 
>>>>>>> conn5254?local=192.168.1.1:3128 remote=192.168.1.5:49209 FD 100 
>>>>>>> flags=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:47:21 ? ?kick abandoning 
>>>>>>> conn5022?local=192.168.1.1:3128 remote=192.168.1.5:49167 FD 37 
>>>>>>> flags=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:47:21 ? ?kick abandoning 
>>>>>>> conn5020?local=192.168.1.1:3128 remote=192.168.1.5:49165 FD 36 
>>>>>>> flags=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:42:22 ? ?WARNING: Forwarding loop?detected for:
>>>>>>> 03.07.2024 10:40:08 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn4955 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:52339 FD 98 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 03.07.2024 10:39:52 ? ?kick abandoning 
>>>>>>> conn4927?local=192.168.1.1:3128 remote=192.168.1.5:52331 FD 105 
>>>>>>> flags=1
>>>>>>> 03.07.2024 10:39:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn4846 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:52314 FD 19 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:38:14 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn4650 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:52274 FD 35 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:38:08 ? ?ERROR: failure while accepting a TLS 
>>>>>>> connection on conn4645 local=192.168.1.1:3128 
>>>>>>> remote=192.168.1.5:52272 FD 35 flags=1: 
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>> 03.07.2024 10:38:04 ? ?ERROR: Unsupported TLS option SINGLE_ECDH_USE
>>>>>>> 03.07.2024 10:38:04 ? ?ERROR: Unsupported TLS option SINGLE_DH_USE
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> 31.12.1969 16:00:00
>>>>>>> _______________________________________________
>>>>>>> squid-users mailing list
>>>>>>> squid-users at lists.squid-cache.org
>>>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>>>
>>>>
>>
> 



From rousskov at measurement-factory.com  Fri Jul  5 13:10:54 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 5 Jul 2024 09:10:54 -0400
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <BCA3C955-2899-4C9E-B82B-65BF268579C0@gmail.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
 <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
 <DA771A75-5CF4-4CB1-B63A-AD2937C07604@gmail.com>
 <f4b44f1a-e817-407c-8045-26af617b6cd4@measurement-factory.com>
 <88441F2A-5A7F-469B-8AD3-B27CF1ED7B28@gmail.com>
 <E733FB66-E104-43B6-BFDD-1C255C20816A@gmail.com>
 <BCA3C955-2899-4C9E-B82B-65BF268579C0@gmail.com>
Message-ID: <93557255-907e-49a3-b610-189ead21a128@measurement-factory.com>

On 2024-07-04 19:02, Jonathan Lee wrote:
>>>> I do not recommend changing your configuration at this time. I 
>>>> recommend rereading my earlier recommendation and following that 
>>>> instead: "As the next step in triage, I recommend determining what 
>>>> that CA is in these cases (e.g., by capturing raw TLS packets and 
>>>> matching them with connection information from A000417 error 
>>>> messages in cache.log or %err_detail in access.log)."
> 
> Ok I went back to 5.8 and ran the following command after I removed the 
> changes I used does this help this is ran on the firewall side itself.
> 
>  ?openssl s_client -connect foxnews.com:443
> 
> depth=2 C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert Global Root CA

Did the above connection go through Squid? Sorry, I do not know whether 
"on the firewall side itself" implies a "yes" or "no" answer in this 
test case.


> Does that help

It does not hurt, but it is not the information I have requested for the 
next triage step: I asked about the certificate corresponding to the 
A000417 error message in Squid v6.6. You are sharing the certificate 
corresponding to either a direct connection to the origin server or the 
certificate corresponding to a problem-free connection through Squid v5.8.


> Should I regenerate a new certificate for the new version of Squid and 
> redeploy them all to hosts again?

IMHO, on this thread, you should follow the recommended triage steps. If 
those recommendations are problematic, please discuss.

Alex.


>>>> On Jul 4, 2024, at 14:45, Alex Rousskov 
>>>> <rousskov at measurement-factory.com> wrote:
>>>>
>>>> On 2024-07-04 15:37, Jonathan Lee wrote:
>>>>
>>>>> in Squid.conf I have nothing with that detective.
>>>>
>>>> Sounds good; sslproxy_cert_sign default should work OK in most 
>>>> cases. I mentioned signUntrusted algorithm so that you can discover 
>>>> (from the corresponding sslproxy_cert_sign documentation) which 
>>>> CA/certificate Squid uses in which SslBump use case. Triage is often 
>>>> easier if folks share the same working theory, and my current 
>>>> working theory suggests that we are looking at a (default) 
>>>> signUntrusted use case.
>>>>
>>>> The solution here probably does _not_ involve changing 
>>>> sslproxy_cert_sign configuration, but, to make progress, I need more 
>>>> info to confirm this working theory and describe next steps.
>>>>
>>>>
>>>>> Yes I am using SSL bump with this configuration..
>>>>
>>>> Noted, thank you.
>>>>
>>>>
>>>>> So would I use this directive
>>>>
>>>> I do not recommend changing your configuration at this time. I 
>>>> recommend rereading my earlier recommendation and following that 
>>>> instead: "As the next step in triage, I recommend determining what 
>>>> that CA is in these cases (e.g., by capturing raw TLS packets and 
>>>> matching them with connection information from A000417 error 
>>>> messages in cache.log or %err_detail in access.log)."
>>>>
>>>>
>>>> HTH,
>>>>
>>>> Alex.
>>>>
>>>>
>>>>>> On Jul 4, 2024, at 09:56, Alex Rousskov wrote:
>>>>>>
>>>>>> On 2024-07-04 12:11, Jonathan Lee wrote:
>>>>>>> failure while accepting a TLS connection on conn5887 
>>>>>>> local=192.168.1.1:3128
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417
>>>>>>
>>>>>> A000417 is an "unknown CA" alert sent by client to Squid while the 
>>>>>> client is trying to establish a TLS connection to/through Squid. 
>>>>>> The client does not trust the Certificate Authority that signed 
>>>>>> the certificate that was used for that TLS connection.
>>>>>>
>>>>>> As the next step in triage, I recommend determining what that CA 
>>>>>> is in these cases (e.g., by capturing raw TLS packets and matching 
>>>>>> them with connection information from A000417 error messages in 
>>>>>> cache.log or %err_detail in access.log).
>>>>>>
>>>>>> If you use SslBump for port 3128 traffic, then one of the 
>>>>>> possibilities here is that Squid is using an unknown-to-client CA 
>>>>>> to report an origin server that Squid itself does not trust (see 
>>>>>> signUntrusted in squid.conf.documented). In those cases, logging a 
>>>>>> level-1 ERROR is a Squid bug because that expected/desirable 
>>>>>> outcome should be treated as success (and a successful TLS accept 
>>>>>> treated as an error!).
>>>>>>
>>>>>>
>>>>>> HTH,
>>>>>>
>>>>>> Alex.
>>>>
>>>>
>>>>>>> Is my main concern however I use the squid guard URL blocker
>>>>>>> Sent from my iPhone
>>>>>>>> On Jul 4, 2024, at 07:41, Alex Rousskov 
>>>>>>>> <rousskov at measurement-factory.com> wrote:
>>>>>>>>
>>>>>>>> ?On 2024-07-03 13:56, Jonathan Lee wrote:
>>>>>>>>> Hello fellow Squid users does anyone know how to fix this issue?
>>>>>>>>
>>>>>>>> I counted about eight different "issues" in your cache.log 
>>>>>>>> sample. Most of them are probably independent. I recommend that 
>>>>>>>> you explicitly pick _one_, search mailing list archives for 
>>>>>>>> previous discussions about it, and then provide as many details 
>>>>>>>> about it as you can (e.g., what traffic causes it and/or 
>>>>>>>> matching access.log records).
>>>>>>>>
>>>>>>>>
>>>>>>>> HTH,
>>>>>>>>
>>>>>>>> Alex.
>>>>>>>>
>>>>>>>>
>>>>>>>>> Squid - Cache Logs
>>>>>>>>> Date-Time ? ?Message
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:54:34 ? ?kick abandoning 
>>>>>>>>> conn7853?local=192.168.1.1:3128 remote=192.168.1.5:49710 FD 89 
>>>>>>>>> flags=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:54:29 ? ?kick abandoning 
>>>>>>>>> conn7844?local=192.168.1.1:3128 remote=192.168.1.5:49702 FD 81 
>>>>>>>>> flags=1
>>>>>>>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn7648 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49672 FD 44 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn7647 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49670 FD 43 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn7646 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49668 FD 34 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:53:04 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn7367 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49627 FD 22 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:52:47 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn7345 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49618 FD 31 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:52:38 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn7340 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49616 FD 45 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:52:34 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn7316 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49609 FD 45 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:51:55 ? ?WARNING: Error Pages Missing Language: en-us
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:51:55 ? ?ERROR: loading file 
>>>>>>>>> 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': (2) 
>>>>>>>>> No such?file or directory
>>>>>>>>> 03.07.2024 10:51:44 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn7102 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49574 FD 34 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:51:28 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn7071 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49568 FD 92 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:50:29 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn6944 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49534 FD 101 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:49:54 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn6866 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49519 FD 31 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:49:38 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn6809 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49503 FD 31 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:49:32 ? ?ERROR: system call failure while 
>>>>>>>>> accepting a TLS connection on conn6794 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49496 FD 19 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
>>>>>>>>> 03.07.2024 10:49:24 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn6776 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49481 FD 137 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:48:49 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn6440 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49424 FD 16 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:48:49 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn6445 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49426 FD 34 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:48:22 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn6035 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49355 FD 226 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn5887 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49318 FD 33 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn5875 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49312 FD 216 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn5876 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49314 FD 217 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:47:57 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn5815 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49297 FD 201 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:47:54 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn5760 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49289 FD 195 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:47:52 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn5717 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49284 FD 195 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:47:50 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn5552 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:49268 FD 142 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:47:34 ? ?kick abandoning 
>>>>>>>>> conn5254?local=192.168.1.1:3128 remote=192.168.1.5:49209 FD 100 
>>>>>>>>> flags=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:47:21 ? ?kick abandoning 
>>>>>>>>> conn5022?local=192.168.1.1:3128 remote=192.168.1.5:49167 FD 37 
>>>>>>>>> flags=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:47:21 ? ?kick abandoning 
>>>>>>>>> conn5020?local=192.168.1.1:3128 remote=192.168.1.5:49165 FD 36 
>>>>>>>>> flags=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:42:22 ? ?WARNING: Forwarding loop?detected for:
>>>>>>>>> 03.07.2024 10:40:08 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn4955 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:52339 FD 98 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:39:52 ? ?kick abandoning 
>>>>>>>>> conn4927?local=192.168.1.1:3128 remote=192.168.1.5:52331 FD 105 
>>>>>>>>> flags=1
>>>>>>>>> 03.07.2024 10:39:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn4846 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:52314 FD 19 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:38:14 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn4650 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:52274 FD 35 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:38:08 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>> connection on conn4645 local=192.168.1.1:3128 
>>>>>>>>> remote=192.168.1.5:52272 FD 35 flags=1: 
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:38:04 ? ?ERROR: Unsupported TLS option 
>>>>>>>>> SINGLE_ECDH_USE
>>>>>>>>> 03.07.2024 10:38:04 ? ?ERROR: Unsupported TLS option SINGLE_DH_USE
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> _______________________________________________
>>>>>>>>> squid-users mailing list
>>>>>>>>> squid-users at lists.squid-cache.org
>>>>>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>>>>>
>>>>>>
>>>>
>>>
>>
> 



From juergen.3.wagner at continental-corporation.com  Fri Jul  5 13:16:52 2024
From: juergen.3.wagner at continental-corporation.com (Wagner, Juergen03)
Date: Fri, 5 Jul 2024 13:16:52 +0000
Subject: [squid-users] Squid as http to https forward proxy
In-Reply-To: <7a1c7920-567b-491e-8302-49154c01e9f8@measurement-factory.com>
References: <AS8PR03MB8072C9DC3302D4535EBC5C28CADE2@AS8PR03MB8072.eurprd03.prod.outlook.com>
 <fd866f62-ad88-4fe8-9903-e8c1c2578d9c@measurement-factory.com>
 <Zoa4qPkq5ckD3V4E@fantomas.sk>
 <97c63622-762a-431f-a00e-bdae2bd8442b@measurement-factory.com>
 <7a1c7920-567b-491e-8302-49154c01e9f8@measurement-factory.com>
Message-ID: <AS8PR03MB80729B98975E22E33A73D87ECADF2@AS8PR03MB8072.eurprd03.prod.outlook.com>

Hello,
thanks a lot for the fast responses.
Actually we want to be able to connect to any remote server.
So we are not looking for a solution with a "single true origin server".

My current understanding from your response is,
that a simple url-rewrite only, as we tried, is not working to forward http requests form a client to any https server.

Just to be clear, is the usage of Squid as a forward http proxy for a client while using https for external communication possible without any Squid code changes?
Could the Squid configuration directive "http_port" in combination with the mode "accel" be used to support that use case?

Maybe Alex' last statement is the solution:
<<
At some point, depending on the use case,
it will be easier to enhance Squid to encrypt plain HTTP requests without using this TLS cache_peer hack, of course
>>

Regards,
Juergen



Internal
-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Alex Rousskov
Sent: Donnerstag, 4. Juli 2024 18:43
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid as http to https forward proxy

CAUTION: This is an external email. Do not click or open any attachments unless you recognize the sender and know that the content is safe. (http://links.conti.de/mailcheck)


On 2024-07-04 12:36, Alex Rousskov wrote:
> On 2024-07-04 10:58, Matus UHLAR - fantomas wrote:
>>> On 2024-07-04 09:20, Wagner, Juergen03 wrote:
>>>> we are evaluating Squid to be used as a http to https forward proxy.
>>>>
>>>> So Squid would need to support the following setup:
>>>>
>>>>     http (client)    ---->   Squid  --->  https ( server )
>>>>
>>>> Could someone please confirm if the given setup is in principle
>>>> possible with Squid?
>>>>
>>>> If yes, which configuration needs to be done?
>>
>> On 04.07.24 10:36, Alex Rousskov wrote:
>>>    Yes, Squid should be able to forward plain text HTTP requests to
>>> a secure server. Use cache_peer directive with "tls" and "originserver"
>>> flags. Here is an untested sketch:
>>>
>>>    # routing all traffic to one HTTPS origin server
>>>    cache_peer 127.0.0.1 parent 443 0 tls originserver \
>>>        name=MySecureOrigin \
>>>        no-query no-digest
>>>    cache_peer_access MySecureOrigin allow all
>>>    always_direct deny all
>>>    never_direct allow all
>>>    nonhierarchical_direct off
>>
>> Afaik this means that it is not possible with any remote server,
>> because all servers you want to access this way must be explicitly
>> set up in squid.conf, correct?
>
> I assumed (possibly incorrectly) that Juergen was asking about a
> single "true origin server" (e.g., example.com). The above example was
> written with a single "true origin server" in mind. However, exactly
> the same Squid configuration may work to forward traffic to a reverse
> proxy (running at 127.0.0.1 on port 443) that "represents"
> multiple/different "true origin servers".
>
> That reverse proxy will need to shovel TLS bytes received from Squid
> to the right "true origin server", but I am guessing that it can do
> that based on TLS SNI supplied by Squid. Some Squid code modifications
> may be necessary to make this work correctly with persistent
> Squid-to-peer connections and such, but nothing major AFAICT (and they
> can be turned off using server_persistent_connections if they are in the way).
>
> AFAICT, with either SslBump or some Squid code modifications, that
> reverse proxy can be a Squid proxy. With even more Squid enhancements,
> that reverse proxy can also become an https_port on the same Squid
> proxy instance where the http_port receives plain HTTP requests!

At some point, depending on the use case, it will be easier to enhance Squid to encrypt plain HTTP requests without using this TLS cache_peer hack, of course.

Alex.

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
https://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Fri Jul  5 13:33:26 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 5 Jul 2024 09:33:26 -0400
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <CA4A251D-C14E-4E7A-B380-EF9F8C15088D@gmail.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
 <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
 <DA771A75-5CF4-4CB1-B63A-AD2937C07604@gmail.com>
 <f4b44f1a-e817-407c-8045-26af617b6cd4@measurement-factory.com>
 <CA4A251D-C14E-4E7A-B380-EF9F8C15088D@gmail.com>
Message-ID: <3b237f87-7b8d-4db7-9b8e-b42233a9a288@measurement-factory.com>

On 2024-07-04 19:12, Jonathan Lee wrote:
> You also stated .. "?my current working theory suggests that we are 
> looking at a (default) signUntrusted use case.?
> 
> I noticed for Squid documents that default is now set to off ..

The http_port option you are looking at now is not the directive I was 
talking about earlier.

 > http_port
>    tls-default-ca[=off]
> 			Whether to use the system Trusted CAs. Default is OFF.
> 
> Would enabling this resolve the problem in Squid 6.6 for error.


No, the above poorly documented http_port option is for validating 
_client_ certificates. It has been off since Squid v4 AFAICT. Your 
clients are not sending client certificates to Squid.

According to the working theory, the problem we are solving is related 
to server certificates. http_port tls-default-ca option does not affect 
server certificate validation. Server certificate validation should use 
default CAs by default.

Outside of SslBump, server certificate validation is controlled by 
tls_outgoing_options default-ca option. That option defaults to "on". I 
am not sure whether SslBump honors that directive/option though. There 
are known related bugs in that area. However, we are jumping ahead of 
ourselves. We should confirm the working theory first.

 > The squid.conf.documented lists it incorrectly

Squid has many directives and a directive may have many options. One 
should not use an directive option name instead of a directive name. One 
should not use an option from one directive with another directive. 
Squid naming is often inconsistent; be careful.

* http_port is a directive. tls-default-ca is an option for that 
directive. It is used for client certificate validation. It defaults to 
"off" (because client certificates are rarely signed by well-known 
(a.k.a. "default") CAs preinstalled in many deployment environments).

* tls_outgoing_options is a directive. default-ca is an option for that 
directive. It is used for server certificate validation outside of 
SslBump contexts (at least!). It defaults to "on" (because server 
certificates are usually signed by well-known (a.k.a. "default") CAs 
preinstalled in many deployment environments).

AFAICT, the documentation in question is not wrong (but is insufficient).

Again, I do not recommend changing any Squid configuration 
directives/options at this triage state.

Alex.



From rousskov at measurement-factory.com  Fri Jul  5 13:52:21 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 5 Jul 2024 09:52:21 -0400
Subject: [squid-users] Squid as http to https forward proxy
In-Reply-To: <AS8PR03MB80729B98975E22E33A73D87ECADF2@AS8PR03MB8072.eurprd03.prod.outlook.com>
References: <AS8PR03MB8072C9DC3302D4535EBC5C28CADE2@AS8PR03MB8072.eurprd03.prod.outlook.com>
 <fd866f62-ad88-4fe8-9903-e8c1c2578d9c@measurement-factory.com>
 <Zoa4qPkq5ckD3V4E@fantomas.sk>
 <97c63622-762a-431f-a00e-bdae2bd8442b@measurement-factory.com>
 <7a1c7920-567b-491e-8302-49154c01e9f8@measurement-factory.com>
 <AS8PR03MB80729B98975E22E33A73D87ECADF2@AS8PR03MB8072.eurprd03.prod.outlook.com>
Message-ID: <fe25c303-6335-4256-90d8-1e202d2b29e6@measurement-factory.com>

On 2024-07-05 09:16, Wagner, Juergen03 wrote:

> Actually we want to be able to connect to any remote server.
> So we are not looking for a solution with a "single true origin server".

Thank you for clarifying that.


> My current understanding from your response is, that a simple
> url-rewrite only, as we tried, is not working to forward http
> requests form a client to any https server.

FWIW, I do not know why URL scheme rewriting does not work in your use 
case. In principle, bugs notwithstanding, I would expect URL scheme 
rewriting to work. In my original response, I was focusing on avoiding 
rewrites for a case where they should not be needed because they should 
not be needed (in that use case) and because they did not work (in your 
specific tests), but _not_ because they should not work in principle or 
on some fundamental level.


> Just to be clear, is the usage of Squid as a forward http proxy for a
> client while using https for external communication possible without
> any Squid code changes?

That particular question covers several different scenarios. Your use 
case is one of them. The answer for your specific use case is unknown 
(to me) -- I would expect URL scheme rewrites to work but they do not in 
your test. I do not know why.


> Alex: At some point, depending on the use case, it will be easier to
> enhance Squid to encrypt plain HTTP requests

That comment still applies. However, if you would prefer to avoid (or at 
least reduce) Squid code modifications, it may be useful to triage why 
scheme rewrites do not work in your tests. In other words, why Squid 
generates a "Bad Gateway" error when the rewriter changes request URL 
scheme from "http" to "https". Sharing a pointer to compressed cache.log 
collected with debug_options set to ALL,9 while reproducing the problem 
with a single test transaction may be the best next step.


HTH,

Alex.


> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Alex Rousskov
> Sent: Donnerstag, 4. Juli 2024 18:43
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid as http to https forward proxy
> 
> CAUTION: This is an external email. Do not click or open any attachments unless you recognize the sender and know that the content is safe. (http://links.conti.de/mailcheck)
> 
> 
> On 2024-07-04 12:36, Alex Rousskov wrote:
>> On 2024-07-04 10:58, Matus UHLAR - fantomas wrote:
>>>> On 2024-07-04 09:20, Wagner, Juergen03 wrote:
>>>>> we are evaluating Squid to be used as a http to https forward proxy.
>>>>>
>>>>> So Squid would need to support the following setup:
>>>>>
>>>>>      http (client)    ---->   Squid  --->  https ( server )
>>>>>
>>>>> Could someone please confirm if the given setup is in principle
>>>>> possible with Squid?
>>>>>
>>>>> If yes, which configuration needs to be done?
>>>
>>> On 04.07.24 10:36, Alex Rousskov wrote:
>>>>     Yes, Squid should be able to forward plain text HTTP requests to
>>>> a secure server. Use cache_peer directive with "tls" and "originserver"
>>>> flags. Here is an untested sketch:
>>>>
>>>>     # routing all traffic to one HTTPS origin server
>>>>     cache_peer 127.0.0.1 parent 443 0 tls originserver \
>>>>         name=MySecureOrigin \
>>>>         no-query no-digest
>>>>     cache_peer_access MySecureOrigin allow all
>>>>     always_direct deny all
>>>>     never_direct allow all
>>>>     nonhierarchical_direct off
>>>
>>> Afaik this means that it is not possible with any remote server,
>>> because all servers you want to access this way must be explicitly
>>> set up in squid.conf, correct?
>>
>> I assumed (possibly incorrectly) that Juergen was asking about a
>> single "true origin server" (e.g., example.com). The above example was
>> written with a single "true origin server" in mind. However, exactly
>> the same Squid configuration may work to forward traffic to a reverse
>> proxy (running at 127.0.0.1 on port 443) that "represents"
>> multiple/different "true origin servers".
>>
>> That reverse proxy will need to shovel TLS bytes received from Squid
>> to the right "true origin server", but I am guessing that it can do
>> that based on TLS SNI supplied by Squid. Some Squid code modifications
>> may be necessary to make this work correctly with persistent
>> Squid-to-peer connections and such, but nothing major AFAICT (and they
>> can be turned off using server_persistent_connections if they are in the way).
>>
>> AFAICT, with either SslBump or some Squid code modifications, that
>> reverse proxy can be a Squid proxy. With even more Squid enhancements,
>> that reverse proxy can also become an https_port on the same Squid
>> proxy instance where the http_port receives plain HTTP requests!
> 
> At some point, depending on the use case, it will be easier to enhance Squid to encrypt plain HTTP requests without using this TLS cache_peer hack, of course.
> 
> Alex.
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From juergen.3.wagner at continental-corporation.com  Fri Jul  5 14:15:23 2024
From: juergen.3.wagner at continental-corporation.com (Wagner, Juergen03)
Date: Fri, 5 Jul 2024 14:15:23 +0000
Subject: [squid-users] Squid as http to https forward proxy
In-Reply-To: <fe25c303-6335-4256-90d8-1e202d2b29e6@measurement-factory.com>
References: <AS8PR03MB8072C9DC3302D4535EBC5C28CADE2@AS8PR03MB8072.eurprd03.prod.outlook.com>
 <fd866f62-ad88-4fe8-9903-e8c1c2578d9c@measurement-factory.com>
 <Zoa4qPkq5ckD3V4E@fantomas.sk>
 <97c63622-762a-431f-a00e-bdae2bd8442b@measurement-factory.com>
 <7a1c7920-567b-491e-8302-49154c01e9f8@measurement-factory.com>
 <AS8PR03MB80729B98975E22E33A73D87ECADF2@AS8PR03MB8072.eurprd03.prod.outlook.com>
 <fe25c303-6335-4256-90d8-1e202d2b29e6@measurement-factory.com>
Message-ID: <AS8PR03MB80722567BECF91E9C0CFEE23CADF2@AS8PR03MB8072.eurprd03.prod.outlook.com>


>FWIW, I do not know why URL scheme rewriting does not work in your use case. In principle, bugs notwithstanding, I would expect URL scheme rewriting to work. In my original response, I was focusing on avoiding rewrites for a case where they should not be >needed because they should not be needed (in that use case) and because they did not work (in your specific tests), but _not_ because they should not work in principle or on some fundamental level.

Do you expect that by just changing the URL scheme from http to https Squid is doing the encryption and decryption of the data?
My suspicion was or is, that Squid is just forwarding the unencrypted data form the http client to the https server.

How can I check this when generating the Squid logs with "debug_options ALL, 9"

Regards,
Juergen


<<
FWIW, I do not know why URL scheme rewriting does not work in your use case. In principle, bugs notwithstanding, I would expect URL scheme rewriting to work. In my original response, I was focusing on avoiding rewrites for a case where they should not be needed because they should not be needed (in that use case) and because they did not work (in your specific tests), but _not_ because they should not work in principle or on some fundamental level.
>>

Internal
-----Original Message-----
From: Alex Rousskov <rousskov at measurement-factory.com>
Sent: Freitag, 5. Juli 2024 15:52
To: Wagner, Juergen03 <juergen.3.wagner at continental-corporation.com>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid as http to https forward proxy

CAUTION: This is an external email. Do not click or open any attachments unless you recognize the sender and know that the content is safe. (http://links.conti.de/mailcheck)


On 2024-07-05 09:16, Wagner, Juergen03 wrote:

> Actually we want to be able to connect to any remote server.
> So we are not looking for a solution with a "single true origin server".

Thank you for clarifying that.


> My current understanding from your response is, that a simple
> url-rewrite only, as we tried, is not working to forward http requests
> form a client to any https server.

FWIW, I do not know why URL scheme rewriting does not work in your use case. In principle, bugs notwithstanding, I would expect URL scheme rewriting to work. In my original response, I was focusing on avoiding rewrites for a case where they should not be needed because they should not be needed (in that use case) and because they did not work (in your specific tests), but _not_ because they should not work in principle or on some fundamental level.


> Just to be clear, is the usage of Squid as a forward http proxy for a
> client while using https for external communication possible without
> any Squid code changes?

That particular question covers several different scenarios. Your use case is one of them. The answer for your specific use case is unknown (to me) -- I would expect URL scheme rewrites to work but they do not in your test. I do not know why.


> Alex: At some point, depending on the use case, it will be easier to
> enhance Squid to encrypt plain HTTP requests

That comment still applies. However, if you would prefer to avoid (or at least reduce) Squid code modifications, it may be useful to triage why scheme rewrites do not work in your tests. In other words, why Squid generates a "Bad Gateway" error when the rewriter changes request URL scheme from "http" to "https". Sharing a pointer to compressed cache.log collected with debug_options set to ALL,9 while reproducing the problem with a single test transaction may be the best next step.


HTH,

Alex.


> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On
> Behalf Of Alex Rousskov
> Sent: Donnerstag, 4. Juli 2024 18:43
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid as http to https forward proxy
>
> CAUTION: This is an external email. Do not click or open any
> attachments unless you recognize the sender and know that the content
> is safe. (http://links.conti.de/mailcheck)
>
>
> On 2024-07-04 12:36, Alex Rousskov wrote:
>> On 2024-07-04 10:58, Matus UHLAR - fantomas wrote:
>>>> On 2024-07-04 09:20, Wagner, Juergen03 wrote:
>>>>> we are evaluating Squid to be used as a http to https forward proxy.
>>>>>
>>>>> So Squid would need to support the following setup:
>>>>>
>>>>>      http (client)    ---->   Squid  --->  https ( server )
>>>>>
>>>>> Could someone please confirm if the given setup is in principle
>>>>> possible with Squid?
>>>>>
>>>>> If yes, which configuration needs to be done?
>>>
>>> On 04.07.24 10:36, Alex Rousskov wrote:
>>>>     Yes, Squid should be able to forward plain text HTTP requests
>>>> to a secure server. Use cache_peer directive with "tls" and "originserver"
>>>> flags. Here is an untested sketch:
>>>>
>>>>     # routing all traffic to one HTTPS origin server
>>>>     cache_peer 127.0.0.1 parent 443 0 tls originserver \
>>>>         name=MySecureOrigin \
>>>>         no-query no-digest
>>>>     cache_peer_access MySecureOrigin allow all
>>>>     always_direct deny all
>>>>     never_direct allow all
>>>>     nonhierarchical_direct off
>>>
>>> Afaik this means that it is not possible with any remote server,
>>> because all servers you want to access this way must be explicitly
>>> set up in squid.conf, correct?
>>
>> I assumed (possibly incorrectly) that Juergen was asking about a
>> single "true origin server" (e.g., example.com). The above example
>> was written with a single "true origin server" in mind. However,
>> exactly the same Squid configuration may work to forward traffic to a
>> reverse proxy (running at 127.0.0.1 on port 443) that "represents"
>> multiple/different "true origin servers".
>>
>> That reverse proxy will need to shovel TLS bytes received from Squid
>> to the right "true origin server", but I am guessing that it can do
>> that based on TLS SNI supplied by Squid. Some Squid code
>> modifications may be necessary to make this work correctly with
>> persistent Squid-to-peer connections and such, but nothing major
>> AFAICT (and they can be turned off using server_persistent_connections if they are in the way).
>>
>> AFAICT, with either SslBump or some Squid code modifications, that
>> reverse proxy can be a Squid proxy. With even more Squid
>> enhancements, that reverse proxy can also become an https_port on the
>> same Squid proxy instance where the http_port receives plain HTTP requests!
>
> At some point, depending on the use case, it will be easier to enhance Squid to encrypt plain HTTP requests without using this TLS cache_peer hack, of course.
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From jonathanlee571 at gmail.com  Fri Jul  5 15:23:42 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Jul 2024 08:23:42 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <3b237f87-7b8d-4db7-9b8e-b42233a9a288@measurement-factory.com>
References: <3b237f87-7b8d-4db7-9b8e-b42233a9a288@measurement-factory.com>
Message-ID: <33A2A946-B618-46C2-92C6-1302D6ED0BDC@gmail.com>

Thanks for the email and support with this. I will get wireshark running on the client and get the info required. Yes the information prior is from the firewall side outside of the proxy testing from the demilitarized zone area. I wanted to test this first to rule that out as it?s coming in from that first and hits the proxy next
Sent from my iPhone

> On Jul 5, 2024, at 06:33, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> ?On 2024-07-04 19:12, Jonathan Lee wrote:
>> You also stated .. " my current working theory suggests that we are looking at a (default) signUntrusted use case.?
>> I noticed for Squid documents that default is now set to off ..
> 
> The http_port option you are looking at now is not the directive I was talking about earlier.
> 
> > http_port
>>   tls-default-ca[=off]
>>            Whether to use the system Trusted CAs. Default is OFF.
>> Would enabling this resolve the problem in Squid 6.6 for error.
> 
> 
> No, the above poorly documented http_port option is for validating _client_ certificates. It has been off since Squid v4 AFAICT. Your clients are not sending client certificates to Squid.
> 
> According to the working theory, the problem we are solving is related to server certificates. http_port tls-default-ca option does not affect server certificate validation. Server certificate validation should use default CAs by default.
> 
> Outside of SslBump, server certificate validation is controlled by tls_outgoing_options default-ca option. That option defaults to "on". I am not sure whether SslBump honors that directive/option though. There are known related bugs in that area. However, we are jumping ahead of ourselves. We should confirm the working theory first.
> 
> > The squid.conf.documented lists it incorrectly
> 
> Squid has many directives and a directive may have many options. One should not use an directive option name instead of a directive name. One should not use an option from one directive with another directive. Squid naming is often inconsistent; be careful.
> 
> * http_port is a directive. tls-default-ca is an option for that directive. It is used for client certificate validation. It defaults to "off" (because client certificates are rarely signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
> 
> * tls_outgoing_options is a directive. default-ca is an option for that directive. It is used for server certificate validation outside of SslBump contexts (at least!). It defaults to "on" (because server certificates are usually signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
> 
> AFAICT, the documentation in question is not wrong (but is insufficient).
> 
> Again, I do not recommend changing any Squid configuration directives/options at this triage state.
> 
> Alex.
> 


From rousskov at measurement-factory.com  Fri Jul  5 15:24:09 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 5 Jul 2024 11:24:09 -0400
Subject: [squid-users] Squid as http to https forward proxy
In-Reply-To: <AS8PR03MB80722567BECF91E9C0CFEE23CADF2@AS8PR03MB8072.eurprd03.prod.outlook.com>
References: <AS8PR03MB8072C9DC3302D4535EBC5C28CADE2@AS8PR03MB8072.eurprd03.prod.outlook.com>
 <fd866f62-ad88-4fe8-9903-e8c1c2578d9c@measurement-factory.com>
 <Zoa4qPkq5ckD3V4E@fantomas.sk>
 <97c63622-762a-431f-a00e-bdae2bd8442b@measurement-factory.com>
 <7a1c7920-567b-491e-8302-49154c01e9f8@measurement-factory.com>
 <AS8PR03MB80729B98975E22E33A73D87ECADF2@AS8PR03MB8072.eurprd03.prod.outlook.com>
 <fe25c303-6335-4256-90d8-1e202d2b29e6@measurement-factory.com>
 <AS8PR03MB80722567BECF91E9C0CFEE23CADF2@AS8PR03MB8072.eurprd03.prod.outlook.com>
Message-ID: <e4b17471-6335-4a1f-ae01-4596cb1f0b15@measurement-factory.com>

On 2024-07-05 10:15, Wagner, Juergen03 wrote:

>> FWIW, I do not know why URL scheme rewriting does not work in your use case. In principle, bugs notwithstanding, I would expect URL scheme rewriting to work. In my original response, I was focusing on avoiding rewrites for a case where they should not be >needed because they should not be needed (in that use case) and because they did not work (in your specific tests), but _not_ because they should not work in principle or on some fundamental level.

> Do you expect that by just changing the URL scheme from http to https Squid is doing the encryption and decryption of the data?

Yes, I do expect Squid to honor the new URL scheme. Honoring rewriter 
instructions is natural, but there is more to the story here: Bugs 
notwithstanding, Squid is already capable for receiving a plain text 
"GET https://..." request on http_port and doing the encryption when 
talking to the requested TLS origin server. What your rewriter is doing 
feels very similar to that GET-https use case!


> My suspicion was or is, that Squid is just forwarding the unencrypted data form the http client to the https server.

IMO, that would be a Squid bug in this case.


> How can I check this when generating the Squid logs with "debug_options ALL,9"

You should not. Debugging logs are for Squid developers. Me or others 
will check if you share the logs. Share privately if needed and/or use 
fake/temporary keys/passwords/etc. to avoid leaking something sensitive. 
There are a few relevant hints at

https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction


HTH,

Alex.


> <<
> FWIW, I do not know why URL scheme rewriting does not work in your use case. In principle, bugs notwithstanding, I would expect URL scheme rewriting to work. In my original response, I was focusing on avoiding rewrites for a case where they should not be needed because they should not be needed (in that use case) and because they did not work (in your specific tests), but _not_ because they should not work in principle or on some fundamental level.
>>>
> 
> Internal
> -----Original Message-----
> From: Alex Rousskov <rousskov at measurement-factory.com>
> Sent: Freitag, 5. Juli 2024 15:52
> To: Wagner, Juergen03 <juergen.3.wagner at continental-corporation.com>; squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid as http to https forward proxy
> 
> CAUTION: This is an external email. Do not click or open any attachments unless you recognize the sender and know that the content is safe. (http://links.conti.de/mailcheck)
> 
> 
> On 2024-07-05 09:16, Wagner, Juergen03 wrote:
> 
>> Actually we want to be able to connect to any remote server.
>> So we are not looking for a solution with a "single true origin server".
> 
> Thank you for clarifying that.
> 
> 
>> My current understanding from your response is, that a simple
>> url-rewrite only, as we tried, is not working to forward http requests
>> form a client to any https server.
> 
> FWIW, I do not know why URL scheme rewriting does not work in your use case. In principle, bugs notwithstanding, I would expect URL scheme rewriting to work. In my original response, I was focusing on avoiding rewrites for a case where they should not be needed because they should not be needed (in that use case) and because they did not work (in your specific tests), but _not_ because they should not work in principle or on some fundamental level.
> 
> 
>> Just to be clear, is the usage of Squid as a forward http proxy for a
>> client while using https for external communication possible without
>> any Squid code changes?
> 
> That particular question covers several different scenarios. Your use case is one of them. The answer for your specific use case is unknown (to me) -- I would expect URL scheme rewrites to work but they do not in your test. I do not know why.
> 
> 
>> Alex: At some point, depending on the use case, it will be easier to
>> enhance Squid to encrypt plain HTTP requests
> 
> That comment still applies. However, if you would prefer to avoid (or at least reduce) Squid code modifications, it may be useful to triage why scheme rewrites do not work in your tests. In other words, why Squid generates a "Bad Gateway" error when the rewriter changes request URL scheme from "http" to "https". Sharing a pointer to compressed cache.log collected with debug_options set to ALL,9 while reproducing the problem with a single test transaction may be the best next step.
> 
> 
> HTH,
> 
> Alex.
> 
> 
>> -----Original Message-----
>> From: squid-users <squid-users-bounces at lists.squid-cache.org> On
>> Behalf Of Alex Rousskov
>> Sent: Donnerstag, 4. Juli 2024 18:43
>> To: squid-users at lists.squid-cache.org
>> Subject: Re: [squid-users] Squid as http to https forward proxy
>>
>> CAUTION: This is an external email. Do not click or open any
>> attachments unless you recognize the sender and know that the content
>> is safe. (http://links.conti.de/mailcheck)
>>
>>
>> On 2024-07-04 12:36, Alex Rousskov wrote:
>>> On 2024-07-04 10:58, Matus UHLAR - fantomas wrote:
>>>>> On 2024-07-04 09:20, Wagner, Juergen03 wrote:
>>>>>> we are evaluating Squid to be used as a http to https forward proxy.
>>>>>>
>>>>>> So Squid would need to support the following setup:
>>>>>>
>>>>>>       http (client)    ---->   Squid  --->  https ( server )
>>>>>>
>>>>>> Could someone please confirm if the given setup is in principle
>>>>>> possible with Squid?
>>>>>>
>>>>>> If yes, which configuration needs to be done?
>>>>
>>>> On 04.07.24 10:36, Alex Rousskov wrote:
>>>>>      Yes, Squid should be able to forward plain text HTTP requests
>>>>> to a secure server. Use cache_peer directive with "tls" and "originserver"
>>>>> flags. Here is an untested sketch:
>>>>>
>>>>>      # routing all traffic to one HTTPS origin server
>>>>>      cache_peer 127.0.0.1 parent 443 0 tls originserver \
>>>>>          name=MySecureOrigin \
>>>>>          no-query no-digest
>>>>>      cache_peer_access MySecureOrigin allow all
>>>>>      always_direct deny all
>>>>>      never_direct allow all
>>>>>      nonhierarchical_direct off
>>>>
>>>> Afaik this means that it is not possible with any remote server,
>>>> because all servers you want to access this way must be explicitly
>>>> set up in squid.conf, correct?
>>>
>>> I assumed (possibly incorrectly) that Juergen was asking about a
>>> single "true origin server" (e.g., example.com). The above example
>>> was written with a single "true origin server" in mind. However,
>>> exactly the same Squid configuration may work to forward traffic to a
>>> reverse proxy (running at 127.0.0.1 on port 443) that "represents"
>>> multiple/different "true origin servers".
>>>
>>> That reverse proxy will need to shovel TLS bytes received from Squid
>>> to the right "true origin server", but I am guessing that it can do
>>> that based on TLS SNI supplied by Squid. Some Squid code
>>> modifications may be necessary to make this work correctly with
>>> persistent Squid-to-peer connections and such, but nothing major
>>> AFAICT (and they can be turned off using server_persistent_connections if they are in the way).
>>>
>>> AFAICT, with either SslBump or some Squid code modifications, that
>>> reverse proxy can be a Squid proxy. With even more Squid
>>> enhancements, that reverse proxy can also become an https_port on the
>>> same Squid proxy instance where the http_port receives plain HTTP requests!
>>
>> At some point, depending on the use case, it will be easier to enhance Squid to encrypt plain HTTP requests without using this TLS cache_peer hack, of course.
>>
>> Alex.
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From jonathanlee571 at gmail.com  Fri Jul  5 15:35:59 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Jul 2024 08:35:59 -0700
Subject: [squid-users] ERROR: Unsupported TLS option SINGLE_ECDH_USE
Message-ID: <5F03ED6B-DD48-4184-B1C0-EC184D25FC24@gmail.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240705/af102e51/attachment.htm>

From jonathanlee571 at gmail.com  Fri Jul  5 15:46:23 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Jul 2024 08:46:23 -0700
Subject: [squid-users] ERROR: Unsupported TLS option SINGLE_ECDH_USE
In-Reply-To: <5F03ED6B-DD48-4184-B1C0-EC184D25FC24@gmail.com>
References: <5F03ED6B-DD48-4184-B1C0-EC184D25FC24@gmail.com>
Message-ID: <5DCD4237-204B-4B17-B868-A391A5EC5E1B@gmail.com>

More details for Unsupported TLS option

When running squid -k parse

2024/07/05 08:40:43| Processing: http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
2024/07/05 08:40:43| UPGRADE WARNING: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
2024/07/05 08:40:47| ERROR: Unsupported TLS option SINGLE_DH_USE
2024/07/05 08:40:47| ERROR: Unsupported TLS option SINGLE_ECDH_USE
2024/07/05 08:40:47| Processing: http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
2024/07/05 08:40:47| Starting Authentication on port 127.0.0.1:3128
2024/07/05 08:40:47| Disabling Authentication on port 127.0.0.1:3128 (interception enabled)
2024/07/05 08:40:47| UPGRADE WARNING: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
2024/07/05 08:40:51| ERROR: Unsupported TLS option SINGLE_DH_USE
2024/07/05 08:40:51| ERROR: Unsupported TLS option SINGLE_ECDH_USE
2024/07/05 08:40:51| Processing: https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
2024/07/05 08:40:51| Starting Authentication on port 127.0.0.1:3129
2024/07/05 08:40:51| Disabling Authentication on port 127.0.0.1:3129 (interception enabled)
2024/07/05 08:40:51| UPGRADE WARNING: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in https_port. Use 'tls-cafile=' instead.
2024/07/05 08:40:55| ERROR: Unsupported TLS option SINGLE_DH_USE
2024/07/05 08:40:55| ERROR: Unsupported TLS option SINGLE_ECDH_USE
elliptic curve options are set below and I have inspected the file it is present. 

 tls-dh=prime256v1:/etc/dh-parameters.2048 

> On Jul 5, 2024, at 08:35, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> Different thread for ciphers issues
> 
> ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 
> I found researching in lists-squid-cache.org <http://lists-squid-cache.org/> that someone solved this error with appending TLS13-AES-256-CGM-SHA384 to the ciphers. 
> 
> I am thinking this is my issue also.
> 
> I see that error over and over when I run "squid -k parse?
> 
> Do I append this to the options cipher list?
> 
> Does anyone know how to fix the 2 diffie-hellman key exchange algorithm errors?
> 
> 
> 
> Jonathan Lee

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240705/cbd71495/attachment.htm>

From jonathanlee571 at gmail.com  Fri Jul  5 16:02:24 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Jul 2024 09:02:24 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <33A2A946-B618-46C2-92C6-1302D6ED0BDC@gmail.com>
References: <3b237f87-7b8d-4db7-9b8e-b42233a9a288@measurement-factory.com>
 <33A2A946-B618-46C2-92C6-1302D6ED0BDC@gmail.com>
Message-ID: <0E99748B-F081-44B6-B3FB-DA611AA5AB26@gmail.com>

per 

As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).


I have Wireshark running do I just look for information with ssl.handshake.type == 1

Or is there a wireshark particular filter you would like ran to help with isolation?



> On Jul 5, 2024, at 08:23, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Thanks for the email and support with this. I will get wireshark running on the client and get the info required. Yes the information prior is from the firewall side outside of the proxy testing from the demilitarized zone area. I wanted to test this first to rule that out as it?s coming in from that first and hits the proxy next
> Sent from my iPhone
> 
>> On Jul 5, 2024, at 06:33, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>> 
>> ?On 2024-07-04 19:12, Jonathan Lee wrote:
>>> You also stated .. " my current working theory suggests that we are looking at a (default) signUntrusted use case.?
>>> I noticed for Squid documents that default is now set to off ..
>> 
>> The http_port option you are looking at now is not the directive I was talking about earlier.
>> 
>>> http_port
>>> tls-default-ca[=off]
>>>   Whether to use the system Trusted CAs. Default is OFF.
>>> Would enabling this resolve the problem in Squid 6.6 for error.
>> 
>> 
>> No, the above poorly documented http_port option is for validating _client_ certificates. It has been off since Squid v4 AFAICT. Your clients are not sending client certificates to Squid.
>> 
>> According to the working theory, the problem we are solving is related to server certificates. http_port tls-default-ca option does not affect server certificate validation. Server certificate validation should use default CAs by default.
>> 
>> Outside of SslBump, server certificate validation is controlled by tls_outgoing_options default-ca option. That option defaults to "on". I am not sure whether SslBump honors that directive/option though. There are known related bugs in that area. However, we are jumping ahead of ourselves. We should confirm the working theory first.
>> 
>>> The squid.conf.documented lists it incorrectly
>> 
>> Squid has many directives and a directive may have many options. One should not use an directive option name instead of a directive name. One should not use an option from one directive with another directive. Squid naming is often inconsistent; be careful.
>> 
>> * http_port is a directive. tls-default-ca is an option for that directive. It is used for client certificate validation. It defaults to "off" (because client certificates are rarely signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>> 
>> * tls_outgoing_options is a directive. default-ca is an option for that directive. It is used for server certificate validation outside of SslBump contexts (at least!). It defaults to "on" (because server certificates are usually signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>> 
>> AFAICT, the documentation in question is not wrong (but is insufficient).
>> 
>> Again, I do not recommend changing any Squid configuration directives/options at this triage state.
>> 
>> Alex.
>> 



From jonathanlee571 at gmail.com  Fri Jul  5 16:11:36 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Jul 2024 09:11:36 -0700
Subject: [squid-users] ERROR: Unsupported TLS option SINGLE_ECDH_USE
In-Reply-To: <5DCD4237-204B-4B17-B868-A391A5EC5E1B@gmail.com>
References: <5F03ED6B-DD48-4184-B1C0-EC184D25FC24@gmail.com>
 <5DCD4237-204B-4B17-B868-A391A5EC5E1B@gmail.com>
Message-ID: <2E3550AC-2E15-484F-B1BD-417E09158651@gmail.com>

Wireshark shows Cipher Suite: TLS_AES_128_GCM_SHA256 is being used
How would I append the TLS13-AES-256-CGM-SHA384 cipher suite for use with TLSv1.3 as it states change cipher spec on wireshark

> On Jul 5, 2024, at 08:46, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> More details for Unsupported TLS option
> 
> When running squid -k parse
> 
> 2024/07/05 08:40:43| Processing: http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2024/07/05 08:40:43| UPGRADE WARNING: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
> 2024/07/05 08:40:47| ERROR: Unsupported TLS option SINGLE_DH_USE
> 2024/07/05 08:40:47| ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 2024/07/05 08:40:47| Processing: http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2024/07/05 08:40:47| Starting Authentication on port 127.0.0.1:3128
> 2024/07/05 08:40:47| Disabling Authentication on port 127.0.0.1:3128 (interception enabled)
> 2024/07/05 08:40:47| UPGRADE WARNING: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
> 2024/07/05 08:40:51| ERROR: Unsupported TLS option SINGLE_DH_USE
> 2024/07/05 08:40:51| ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 2024/07/05 08:40:51| Processing: https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2024/07/05 08:40:51| Starting Authentication on port 127.0.0.1:3129
> 2024/07/05 08:40:51| Disabling Authentication on port 127.0.0.1:3129 (interception enabled)
> 2024/07/05 08:40:51| UPGRADE WARNING: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in https_port. Use 'tls-cafile=' instead.
> 2024/07/05 08:40:55| ERROR: Unsupported TLS option SINGLE_DH_USE
> 2024/07/05 08:40:55| ERROR: Unsupported TLS option SINGLE_ECDH_USE
> elliptic curve options are set below and I have inspected the file it is present. 
> 
>  tls-dh=prime256v1:/etc/dh-parameters.2048 
> 
>> On Jul 5, 2024, at 08:35, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>> tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>> Different thread for ciphers issues
>> 
>> ERROR: Unsupported TLS option SINGLE_ECDH_USE
>> 
>> I found researching in lists-squid-cache.org <http://lists-squid-cache.org/> that someone solved this error with appending TLS13-AES-256-CGM-SHA384 to the ciphers. 
>> 
>> I am thinking this is my issue also.
>> 
>> I see that error over and over when I run "squid -k parse?
>> 
>> Do I append this to the options cipher list?
>> 
>> Does anyone know how to fix the 2 diffie-hellman key exchange algorithm errors?
>> 
>> 
>> 
>> Jonathan Lee
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240705/32360cfb/attachment.htm>

From jonathanlee571 at gmail.com  Fri Jul  5 17:16:50 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Jul 2024 10:16:50 -0700
Subject: [squid-users] ERROR: Unsupported TLS option SINGLE_ECDH_USE
In-Reply-To: <2E3550AC-2E15-484F-B1BD-417E09158651@gmail.com>
References: <5F03ED6B-DD48-4184-B1C0-EC184D25FC24@gmail.com>
 <5DCD4237-204B-4B17-B868-A391A5EC5E1B@gmail.com>
 <2E3550AC-2E15-484F-B1BD-417E09158651@gmail.com>
Message-ID: <80B55CB8-3259-476C-86B9-4E6C1B6DFF88@gmail.com>

Does anyone know how to activate the TLS1.3 ciphers?

Per lists.squid-cache.org <http://lists.squid-cache.org/>

Ref:
https://lists.squid-cache.org/pipermail/squid-users/2018-February/017640.html
https://openssl.org/blog/blog/2017/05/04/tlsv1.3/

And CVE-2016-0701

"Yes. Due to CVE-2016-0701 the SSL_OP_SINGLE_DH_USE option was deprecated?

It is depreciated and the new pfSense package still shows it as a default option, however how does one append 

ppending
> "TLS13-AES-256-GCM-SHA384" to the ciphers.
> 
> But the log shows the use of "ECDHE-ECDSA-AES256-GCM-SHA384?


> On Jul 5, 2024, at 09:11, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Wireshark shows Cipher Suite: TLS_AES_128_GCM_SHA256 is being used
> How would I append the TLS13-AES-256-CGM-SHA384 cipher suite for use with TLSv1.3 as it states change cipher spec on wireshark
> 
>> On Jul 5, 2024, at 08:46, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> More details for Unsupported TLS option
>> 
>> When running squid -k parse
>> 
>> 2024/07/05 08:40:43| Processing: http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>> 2024/07/05 08:40:43| UPGRADE WARNING: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
>> 2024/07/05 08:40:47| ERROR: Unsupported TLS option SINGLE_DH_USE
>> 2024/07/05 08:40:47| ERROR: Unsupported TLS option SINGLE_ECDH_USE
>> 2024/07/05 08:40:47| Processing: http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>> 2024/07/05 08:40:47| Starting Authentication on port 127.0.0.1:3128
>> 2024/07/05 08:40:47| Disabling Authentication on port 127.0.0.1:3128 (interception enabled)
>> 2024/07/05 08:40:47| UPGRADE WARNING: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
>> 2024/07/05 08:40:51| ERROR: Unsupported TLS option SINGLE_DH_USE
>> 2024/07/05 08:40:51| ERROR: Unsupported TLS option SINGLE_ECDH_USE
>> 2024/07/05 08:40:51| Processing: https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>> 2024/07/05 08:40:51| Starting Authentication on port 127.0.0.1:3129
>> 2024/07/05 08:40:51| Disabling Authentication on port 127.0.0.1:3129 (interception enabled)
>> 2024/07/05 08:40:51| UPGRADE WARNING: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in https_port. Use 'tls-cafile=' instead.
>> 2024/07/05 08:40:55| ERROR: Unsupported TLS option SINGLE_DH_USE
>> 2024/07/05 08:40:55| ERROR: Unsupported TLS option SINGLE_ECDH_USE
>> elliptic curve options are set below and I have inspected the file it is present. 
>> 
>>  tls-dh=prime256v1:/etc/dh-parameters.2048 
>> 
>>> On Jul 5, 2024, at 08:35, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>> 
>>> tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>>> tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>>> Different thread for ciphers issues
>>> 
>>> ERROR: Unsupported TLS option SINGLE_ECDH_USE
>>> 
>>> I found researching in lists-squid-cache.org <http://lists-squid-cache.org/> that someone solved this error with appending TLS13-AES-256-CGM-SHA384 to the ciphers. 
>>> 
>>> I am thinking this is my issue also.
>>> 
>>> I see that error over and over when I run "squid -k parse?
>>> 
>>> Do I append this to the options cipher list?
>>> 
>>> Does anyone know how to fix the 2 diffie-hellman key exchange algorithm errors?
>>> 
>>> 
>>> 
>>> Jonathan Lee
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240705/ce8f7404/attachment.htm>

From jonathanlee571 at gmail.com  Fri Jul  5 17:35:17 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Jul 2024 10:35:17 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <0E99748B-F081-44B6-B3FB-DA611AA5AB26@gmail.com>
References: <3b237f87-7b8d-4db7-9b8e-b42233a9a288@measurement-factory.com>
 <33A2A946-B618-46C2-92C6-1302D6ED0BDC@gmail.com>
 <0E99748B-F081-44B6-B3FB-DA611AA5AB26@gmail.com>
Message-ID: <6C06354C-7CC0-47D9-A50F-66192916AD4D@gmail.com>

Side note: I have just found while analyzing Wireshark packets that this A000417 error only occurs with use of the iMac and the Safari browser, this does not occur on Windows 10 with the Edge browser. 

> On Jul 5, 2024, at 09:02, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> per 
> 
> As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).
> 
> 
> I have Wireshark running do I just look for information with ssl.handshake.type == 1
> 
> Or is there a wireshark particular filter you would like ran to help with isolation?
> 
> 
> 
>> On Jul 5, 2024, at 08:23, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> Thanks for the email and support with this. I will get wireshark running on the client and get the info required. Yes the information prior is from the firewall side outside of the proxy testing from the demilitarized zone area. I wanted to test this first to rule that out as it?s coming in from that first and hits the proxy next
>> Sent from my iPhone
>> 
>>> On Jul 5, 2024, at 06:33, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>> 
>>> ?On 2024-07-04 19:12, Jonathan Lee wrote:
>>>> You also stated .. " my current working theory suggests that we are looking at a (default) signUntrusted use case.?
>>>> I noticed for Squid documents that default is now set to off ..
>>> 
>>> The http_port option you are looking at now is not the directive I was talking about earlier.
>>> 
>>>> http_port
>>>> tls-default-ca[=off]
>>>>  Whether to use the system Trusted CAs. Default is OFF.
>>>> Would enabling this resolve the problem in Squid 6.6 for error.
>>> 
>>> 
>>> No, the above poorly documented http_port option is for validating _client_ certificates. It has been off since Squid v4 AFAICT. Your clients are not sending client certificates to Squid.
>>> 
>>> According to the working theory, the problem we are solving is related to server certificates. http_port tls-default-ca option does not affect server certificate validation. Server certificate validation should use default CAs by default.
>>> 
>>> Outside of SslBump, server certificate validation is controlled by tls_outgoing_options default-ca option. That option defaults to "on". I am not sure whether SslBump honors that directive/option though. There are known related bugs in that area. However, we are jumping ahead of ourselves. We should confirm the working theory first.
>>> 
>>>> The squid.conf.documented lists it incorrectly
>>> 
>>> Squid has many directives and a directive may have many options. One should not use an directive option name instead of a directive name. One should not use an option from one directive with another directive. Squid naming is often inconsistent; be careful.
>>> 
>>> * http_port is a directive. tls-default-ca is an option for that directive. It is used for client certificate validation. It defaults to "off" (because client certificates are rarely signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>>> 
>>> * tls_outgoing_options is a directive. default-ca is an option for that directive. It is used for server certificate validation outside of SslBump contexts (at least!). It defaults to "on" (because server certificates are usually signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>>> 
>>> AFAICT, the documentation in question is not wrong (but is insufficient).
>>> 
>>> Again, I do not recommend changing any Squid configuration directives/options at this triage state.
>>> 
>>> Alex.
>>> 
> 



From rousskov at measurement-factory.com  Fri Jul  5 17:52:43 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 5 Jul 2024 13:52:43 -0400
Subject: [squid-users] ERROR: Unsupported TLS option SINGLE_ECDH_USE
In-Reply-To: <5F03ED6B-DD48-4184-B1C0-EC184D25FC24@gmail.com>
References: <5F03ED6B-DD48-4184-B1C0-EC184D25FC24@gmail.com>
Message-ID: <2c535c72-2b4d-4ad2-984c-dfa59bdfabb2@measurement-factory.com>

On 2024-07-05 11:35, Jonathan Lee wrote:

> tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 
> ERROR: Unsupported TLS option SINGLE_ECDH_USE

Your OpenSSL version defines SSL_OP_SINGLE_ECDH_USE name but otherwise 
ignores SSL_OP_SINGLE_ECDH_USE. OpenSSL behavior that was triggered by 
using this option in old OpenSSL releases is now default behavior, so 
using this option is no longer needed to trigger single-DH key use[1].

Adding SINGLE_ECDH_USE to your configuration achieves/changes nothing 
(with modern OpenSSL versions) as far as traffic on the wire is 
concerned. AFAICT, you should not use that option in squid.conf.

HTH,

Alex.

[1]: 
https://wiki.openssl.org/index.php/List_of_SSL_OP_Flags#SSL_OP_SINGLE_DH_USE



From rousskov at measurement-factory.com  Fri Jul  5 18:01:58 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 5 Jul 2024 14:01:58 -0400
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <0E99748B-F081-44B6-B3FB-DA611AA5AB26@gmail.com>
References: <3b237f87-7b8d-4db7-9b8e-b42233a9a288@measurement-factory.com>
 <33A2A946-B618-46C2-92C6-1302D6ED0BDC@gmail.com>
 <0E99748B-F081-44B6-B3FB-DA611AA5AB26@gmail.com>
Message-ID: <4db94c80-c96c-4739-b0d4-4c207d17905e@measurement-factory.com>

On 2024-07-05 12:02, Jonathan Lee wrote:

> > Alex: I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).


> I have Wireshark running do I just look for information with ssl.handshake.type == 1

> Or is there a wireshark particular filter you would like ran to help with isolation?


Please use Wireshark to determine the name of CA that issued the 
certificate that Squid sent to the client in the failing test case. If 
you are not sure, feel free to share issuer and subject fields of all 
certificates that Squid sent to the client in that test case (there may 
be two of each if Squid sent two certificates). Or even share a pointer 
to the entire (compressed) raw test case packet capture in pcap format!

These certificates are a part of standard TLS handshake, and Wireshark 
usually displays their fields when one studies TLS handshake bytes using 
Wireshark UI.

I do not know what filter would work best, but there should be just a 
handful of TLS handshake packets to examine for the test case, so no 
filter should be necessary.


HTH,

Alex.



>> On Jul 5, 2024, at 08:23, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>
>> Thanks for the email and support with this. I will get wireshark running on the client and get the info required. Yes the information prior is from the firewall side outside of the proxy testing from the demilitarized zone area. I wanted to test this first to rule that out as it?s coming in from that first and hits the proxy next
>> Sent from my iPhone
>>
>>> On Jul 5, 2024, at 06:33, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>
>>> ?On 2024-07-04 19:12, Jonathan Lee wrote:
>>>> You also stated .. " my current working theory suggests that we are looking at a (default) signUntrusted use case.?
>>>> I noticed for Squid documents that default is now set to off ..
>>>
>>> The http_port option you are looking at now is not the directive I was talking about earlier.
>>>
>>>> http_port
>>>> tls-default-ca[=off]
>>>>    Whether to use the system Trusted CAs. Default is OFF.
>>>> Would enabling this resolve the problem in Squid 6.6 for error.
>>>
>>>
>>> No, the above poorly documented http_port option is for validating _client_ certificates. It has been off since Squid v4 AFAICT. Your clients are not sending client certificates to Squid.
>>>
>>> According to the working theory, the problem we are solving is related to server certificates. http_port tls-default-ca option does not affect server certificate validation. Server certificate validation should use default CAs by default.
>>>
>>> Outside of SslBump, server certificate validation is controlled by tls_outgoing_options default-ca option. That option defaults to "on". I am not sure whether SslBump honors that directive/option though. There are known related bugs in that area. However, we are jumping ahead of ourselves. We should confirm the working theory first.
>>>
>>>> The squid.conf.documented lists it incorrectly
>>>
>>> Squid has many directives and a directive may have many options. One should not use an directive option name instead of a directive name. One should not use an option from one directive with another directive. Squid naming is often inconsistent; be careful.
>>>
>>> * http_port is a directive. tls-default-ca is an option for that directive. It is used for client certificate validation. It defaults to "off" (because client certificates are rarely signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>>>
>>> * tls_outgoing_options is a directive. default-ca is an option for that directive. It is used for server certificate validation outside of SslBump contexts (at least!). It defaults to "on" (because server certificates are usually signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>>>
>>> AFAICT, the documentation in question is not wrong (but is insufficient).
>>>
>>> Again, I do not recommend changing any Squid configuration directives/options at this triage state.
>>>
>>> Alex.
>>>



From jonathanlee571 at gmail.com  Fri Jul  5 18:28:54 2024
From: jonathanlee571 at gmail.com (jonathanlee571 at gmail.com)
Date: Fri, 5 Jul 2024 11:28:54 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <4db94c80-c96c-4739-b0d4-4c207d17905e@measurement-factory.com>
References: <3b237f87-7b8d-4db7-9b8e-b42233a9a288@measurement-factory.com>
 <33A2A946-B618-46C2-92C6-1302D6ED0BDC@gmail.com>
 <0E99748B-F081-44B6-B3FB-DA611AA5AB26@gmail.com>
 <4db94c80-c96c-4739-b0d4-4c207d17905e@measurement-factory.com>
Message-ID: <6df201dacf09$31b71bb0$95255310$@gmail.com>

The only one I got a certificate from was the non iMac

The iMac keeps sending change cipher requests and wants TLS1.3 over and over as soon as a TLS1.2 pops up it works 

That one has the certificate however that system the Toshiba does not have any issues with this error. I highly suspect that I need to enable TLS1.3 would you agree?

-----Original Message-----
From: Alex Rousskov <rousskov at measurement-factory.com> 
Sent: Friday, July 5, 2024 11:02 AM
To: squid-users <squid-users at lists.squid-cache.org>
Cc: Jonathan Lee <jonathanlee571 at gmail.com>
Subject: Re: [squid-users] Squid Cache Issues migration from 5.8 to 6.6

On 2024-07-05 12:02, Jonathan Lee wrote:

> > Alex: I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).


> I have Wireshark running do I just look for information with 
> ssl.handshake.type == 1

> Or is there a wireshark particular filter you would like ran to help with isolation?


Please use Wireshark to determine the name of CA that issued the certificate that Squid sent to the client in the failing test case. If you are not sure, feel free to share issuer and subject fields of all certificates that Squid sent to the client in that test case (there may be two of each if Squid sent two certificates). Or even share a pointer to the entire (compressed) raw test case packet capture in pcap format!

These certificates are a part of standard TLS handshake, and Wireshark usually displays their fields when one studies TLS handshake bytes using Wireshark UI.

I do not know what filter would work best, but there should be just a handful of TLS handshake packets to examine for the test case, so no filter should be necessary.


HTH,

Alex.



>> On Jul 5, 2024, at 08:23, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>
>> Thanks for the email and support with this. I will get wireshark 
>> running on the client and get the info required. Yes the information 
>> prior is from the firewall side outside of the proxy testing from the 
>> demilitarized zone area. I wanted to test this first to rule that out 
>> as it?s coming in from that first and hits the proxy next Sent from 
>> my iPhone
>>
>>> On Jul 5, 2024, at 06:33, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>
>>> ?On 2024-07-04 19:12, Jonathan Lee wrote:
>>>> You also stated .. " my current working theory suggests that we are looking at a (default) signUntrusted use case.?
>>>> I noticed for Squid documents that default is now set to off ..
>>>
>>> The http_port option you are looking at now is not the directive I was talking about earlier.
>>>
>>>> http_port
>>>> tls-default-ca[=off]
>>>>    Whether to use the system Trusted CAs. Default is OFF.
>>>> Would enabling this resolve the problem in Squid 6.6 for error.
>>>
>>>
>>> No, the above poorly documented http_port option is for validating _client_ certificates. It has been off since Squid v4 AFAICT. Your clients are not sending client certificates to Squid.
>>>
>>> According to the working theory, the problem we are solving is related to server certificates. http_port tls-default-ca option does not affect server certificate validation. Server certificate validation should use default CAs by default.
>>>
>>> Outside of SslBump, server certificate validation is controlled by tls_outgoing_options default-ca option. That option defaults to "on". I am not sure whether SslBump honors that directive/option though. There are known related bugs in that area. However, we are jumping ahead of ourselves. We should confirm the working theory first.
>>>
>>>> The squid.conf.documented lists it incorrectly
>>>
>>> Squid has many directives and a directive may have many options. One should not use an directive option name instead of a directive name. One should not use an option from one directive with another directive. Squid naming is often inconsistent; be careful.
>>>
>>> * http_port is a directive. tls-default-ca is an option for that directive. It is used for client certificate validation. It defaults to "off" (because client certificates are rarely signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>>>
>>> * tls_outgoing_options is a directive. default-ca is an option for that directive. It is used for server certificate validation outside of SslBump contexts (at least!). It defaults to "on" (because server certificates are usually signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>>>
>>> AFAICT, the documentation in question is not wrong (but is insufficient).
>>>
>>> Again, I do not recommend changing any Squid configuration directives/options at this triage state.
>>>
>>> Alex.
>>>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: tlschange.PNG
Type: image/png
Size: 61751 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240705/bf8e5dbf/attachment.png>

From jonathanlee571 at gmail.com  Fri Jul  5 18:51:59 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Jul 2024 11:51:59 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <6df201dacf09$31b71bb0$95255310$@gmail.com>
References: <3b237f87-7b8d-4db7-9b8e-b42233a9a288@measurement-factory.com>
 <33A2A946-B618-46C2-92C6-1302D6ED0BDC@gmail.com>
 <0E99748B-F081-44B6-B3FB-DA611AA5AB26@gmail.com>
 <4db94c80-c96c-4739-b0d4-4c207d17905e@measurement-factory.com>
 <6df201dacf09$31b71bb0$95255310$@gmail.com>
Message-ID: <B599C9DC-3E0F-46C6-B7FB-DB88C44EDD2E@gmail.com>

If it?s encrypted at TLS1.3 it should still work with the approved certificate authority as it is imported to my devices I own. I just enable TLS1.3 right?

> On Jul 5, 2024, at 11:28, <jonathanlee571 at gmail.com> <jonathanlee571 at gmail.com> wrote:
> 
> The only one I got a certificate from was the non iMac
> 
> The iMac keeps sending change cipher requests and wants TLS1.3 over and over as soon as a TLS1.2 pops up it works 
> 
> That one has the certificate however that system the Toshiba does not have any issues with this error. I highly suspect that I need to enable TLS1.3 would you agree?
> 
> -----Original Message-----
> From: Alex Rousskov <rousskov at measurement-factory.com> 
> Sent: Friday, July 5, 2024 11:02 AM
> To: squid-users <squid-users at lists.squid-cache.org>
> Cc: Jonathan Lee <jonathanlee571 at gmail.com>
> Subject: Re: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
> 
> On 2024-07-05 12:02, Jonathan Lee wrote:
> 
>>> Alex: I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).
> 
> 
>> I have Wireshark running do I just look for information with 
>> ssl.handshake.type == 1
> 
>> Or is there a wireshark particular filter you would like ran to help with isolation?
> 
> 
> Please use Wireshark to determine the name of CA that issued the certificate that Squid sent to the client in the failing test case. If you are not sure, feel free to share issuer and subject fields of all certificates that Squid sent to the client in that test case (there may be two of each if Squid sent two certificates). Or even share a pointer to the entire (compressed) raw test case packet capture in pcap format!
> 
> These certificates are a part of standard TLS handshake, and Wireshark usually displays their fields when one studies TLS handshake bytes using Wireshark UI.
> 
> I do not know what filter would work best, but there should be just a handful of TLS handshake packets to examine for the test case, so no filter should be necessary.
> 
> 
> HTH,
> 
> Alex.
> 
> 
> 
>>> On Jul 5, 2024, at 08:23, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>> 
>>> Thanks for the email and support with this. I will get wireshark 
>>> running on the client and get the info required. Yes the information 
>>> prior is from the firewall side outside of the proxy testing from the 
>>> demilitarized zone area. I wanted to test this first to rule that out 
>>> as it?s coming in from that first and hits the proxy next Sent from 
>>> my iPhone
>>> 
>>>> On Jul 5, 2024, at 06:33, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>> 
>>>> ?On 2024-07-04 19:12, Jonathan Lee wrote:
>>>>> You also stated .. " my current working theory suggests that we are looking at a (default) signUntrusted use case.?
>>>>> I noticed for Squid documents that default is now set to off ..
>>>> 
>>>> The http_port option you are looking at now is not the directive I was talking about earlier.
>>>> 
>>>>> http_port
>>>>> tls-default-ca[=off]
>>>>>   Whether to use the system Trusted CAs. Default is OFF.
>>>>> Would enabling this resolve the problem in Squid 6.6 for error.
>>>> 
>>>> 
>>>> No, the above poorly documented http_port option is for validating _client_ certificates. It has been off since Squid v4 AFAICT. Your clients are not sending client certificates to Squid.
>>>> 
>>>> According to the working theory, the problem we are solving is related to server certificates. http_port tls-default-ca option does not affect server certificate validation. Server certificate validation should use default CAs by default.
>>>> 
>>>> Outside of SslBump, server certificate validation is controlled by tls_outgoing_options default-ca option. That option defaults to "on". I am not sure whether SslBump honors that directive/option though. There are known related bugs in that area. However, we are jumping ahead of ourselves. We should confirm the working theory first.
>>>> 
>>>>> The squid.conf.documented lists it incorrectly
>>>> 
>>>> Squid has many directives and a directive may have many options. One should not use an directive option name instead of a directive name. One should not use an option from one directive with another directive. Squid naming is often inconsistent; be careful.
>>>> 
>>>> * http_port is a directive. tls-default-ca is an option for that directive. It is used for client certificate validation. It defaults to "off" (because client certificates are rarely signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>>>> 
>>>> * tls_outgoing_options is a directive. default-ca is an option for that directive. It is used for server certificate validation outside of SslBump contexts (at least!). It defaults to "on" (because server certificates are usually signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>>>> 
>>>> AFAICT, the documentation in question is not wrong (but is insufficient).
>>>> 
>>>> Again, I do not recommend changing any Squid configuration directives/options at this triage state.
>>>> 
>>>> Alex.
>>>> 
> 
> <tlschange.PNG>



From jonathanlee571 at gmail.com  Fri Jul  5 20:54:47 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Jul 2024 13:54:47 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <B599C9DC-3E0F-46C6-B7FB-DB88C44EDD2E@gmail.com>
References: <B599C9DC-3E0F-46C6-B7FB-DB88C44EDD2E@gmail.com>
Message-ID: <07453F3F-96E7-491F-ABC5-D9BB8AF1FA33@gmail.com>

I have also tested in 5.8 and 6.6 both show the same condition, 6.6 shows errors for it however. I have also imported my certificates into wireshark. 

Just to confirm this is the firewall 192.168.1.1 port 3128 is squid going to iMac that is attempting TSL1.3 I have nosslv3 set also. The firewall is where I grabbed the pcap from 
Sent from my iPhone

> On Jul 5, 2024, at 11:52, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> ?If it?s encrypted at TLS1.3 it should still work with the approved certificate authority as it is imported to my devices I own. I just enable TLS1.3 right?
> 
>> On Jul 5, 2024, at 11:28, <jonathanlee571 at gmail.com> <jonathanlee571 at gmail.com> wrote:
>> 
>> The only one I got a certificate from was the non iMac
>> 
>> The iMac keeps sending change cipher requests and wants TLS1.3 over and over as soon as a TLS1.2 pops up it works
>> 
>> That one has the certificate however that system the Toshiba does not have any issues with this error. I highly suspect that I need to enable TLS1.3 would you agree?
>> 
>> -----Original Message-----
>> From: Alex Rousskov <rousskov at measurement-factory.com>
>> Sent: Friday, July 5, 2024 11:02 AM
>> To: squid-users <squid-users at lists.squid-cache.org>
>> Cc: Jonathan Lee <jonathanlee571 at gmail.com>
>> Subject: Re: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
>> 
>> On 2024-07-05 12:02, Jonathan Lee wrote:
>> 
>>>> Alex: I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).
>> 
>> 
>>> I have Wireshark running do I just look for information with
>>> ssl.handshake.type == 1
>> 
>>> Or is there a wireshark particular filter you would like ran to help with isolation?
>> 
>> 
>> Please use Wireshark to determine the name of CA that issued the certificate that Squid sent to the client in the failing test case. If you are not sure, feel free to share issuer and subject fields of all certificates that Squid sent to the client in that test case (there may be two of each if Squid sent two certificates). Or even share a pointer to the entire (compressed) raw test case packet capture in pcap format!
>> 
>> These certificates are a part of standard TLS handshake, and Wireshark usually displays their fields when one studies TLS handshake bytes using Wireshark UI.
>> 
>> I do not know what filter would work best, but there should be just a handful of TLS handshake packets to examine for the test case, so no filter should be necessary.
>> 
>> 
>> HTH,
>> 
>> Alex.
>> 
>> 
>> 
>>>> On Jul 5, 2024, at 08:23, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>> 
>>>> Thanks for the email and support with this. I will get wireshark
>>>> running on the client and get the info required. Yes the information
>>>> prior is from the firewall side outside of the proxy testing from the
>>>> demilitarized zone area. I wanted to test this first to rule that out
>>>> as it?s coming in from that first and hits the proxy next Sent from
>>>> my iPhone
>>>> 
>>>>> On Jul 5, 2024, at 06:33, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>>> 
>>>>> ?On 2024-07-04 19:12, Jonathan Lee wrote:
>>>>>> You also stated .. " my current working theory suggests that we are looking at a (default) signUntrusted use case.?
>>>>>> I noticed for Squid documents that default is now set to off ..
>>>>> 
>>>>> The http_port option you are looking at now is not the directive I was talking about earlier.
>>>>> 
>>>>>> http_port
>>>>>> tls-default-ca[=off]
>>>>>>  Whether to use the system Trusted CAs. Default is OFF.
>>>>>> Would enabling this resolve the problem in Squid 6.6 for error.
>>>>> 
>>>>> 
>>>>> No, the above poorly documented http_port option is for validating _client_ certificates. It has been off since Squid v4 AFAICT. Your clients are not sending client certificates to Squid.
>>>>> 
>>>>> According to the working theory, the problem we are solving is related to server certificates. http_port tls-default-ca option does not affect server certificate validation. Server certificate validation should use default CAs by default.
>>>>> 
>>>>> Outside of SslBump, server certificate validation is controlled by tls_outgoing_options default-ca option. That option defaults to "on". I am not sure whether SslBump honors that directive/option though. There are known related bugs in that area. However, we are jumping ahead of ourselves. We should confirm the working theory first.
>>>>> 
>>>>>> The squid.conf.documented lists it incorrectly
>>>>> 
>>>>> Squid has many directives and a directive may have many options. One should not use an directive option name instead of a directive name. One should not use an option from one directive with another directive. Squid naming is often inconsistent; be careful.
>>>>> 
>>>>> * http_port is a directive. tls-default-ca is an option for that directive. It is used for client certificate validation. It defaults to "off" (because client certificates are rarely signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>>>>> 
>>>>> * tls_outgoing_options is a directive. default-ca is an option for that directive. It is used for server certificate validation outside of SslBump contexts (at least!). It defaults to "on" (because server certificates are usually signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>>>>> 
>>>>> AFAICT, the documentation in question is not wrong (but is insufficient).
>>>>> 
>>>>> Again, I do not recommend changing any Squid configuration directives/options at this triage state.
>>>>> 
>>>>> Alex.
>>>>> 
>> 
>> <tlschange.PNG>
> 


From jonathanlee571 at gmail.com  Fri Jul  5 21:21:39 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Jul 2024 14:21:39 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <07453F3F-96E7-491F-ABC5-D9BB8AF1FA33@gmail.com>
References: <B599C9DC-3E0F-46C6-B7FB-DB88C44EDD2E@gmail.com>
 <07453F3F-96E7-491F-ABC5-D9BB8AF1FA33@gmail.com>
Message-ID: <2EEDA700-23AA-4CA0-97D6-AA60122AA0DE@gmail.com>

output of versions 

Shell Output - openssl ciphers -s -v ECDHE
TLS_AES_256_GCM_SHA384         TLSv1.3 Kx=any      Au=any   Enc=AESGCM(256)            Mac=AEAD
TLS_CHACHA20_POLY1305_SHA256   TLSv1.3 Kx=any      Au=any   Enc=CHACHA20/POLY1305(256) Mac=AEAD
TLS_AES_128_GCM_SHA256         TLSv1.3 Kx=any      Au=any   Enc=AESGCM(128)            Mac=AEAD
ECDHE-ECDSA-AES256-GCM-SHA384  TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESGCM(256)            Mac=AEAD
ECDHE-RSA-AES256-GCM-SHA384    TLSv1.2 Kx=ECDH     Au=RSA   Enc=AESGCM(256)            Mac=AEAD
ECDHE-ECDSA-CHACHA20-POLY1305  TLSv1.2 Kx=ECDH     Au=ECDSA Enc=CHACHA20/POLY1305(256) Mac=AEAD
ECDHE-RSA-CHACHA20-POLY1305    TLSv1.2 Kx=ECDH     Au=RSA   Enc=CHACHA20/POLY1305(256) Mac=AEAD
ECDHE-ECDSA-AES256-CCM8        TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESCCM8(256)           Mac=AEAD
ECDHE-ECDSA-AES256-CCM         TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESCCM(256)            Mac=AEAD
ECDHE-ECDSA-AES128-GCM-SHA256  TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESGCM(128)            Mac=AEAD
ECDHE-RSA-AES128-GCM-SHA256    TLSv1.2 Kx=ECDH     Au=RSA   Enc=AESGCM(128)            Mac=AEAD
ECDHE-ECDSA-AES128-CCM8        TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESCCM8(128)           Mac=AEAD
ECDHE-ECDSA-AES128-CCM         TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESCCM(128)            Mac=AEAD
ECDHE-ECDSA-AES256-SHA384      TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AES(256)               Mac=SHA384
ECDHE-RSA-AES256-SHA384        TLSv1.2 Kx=ECDH     Au=RSA   Enc=AES(256)               Mac=SHA384
ECDHE-ECDSA-CAMELLIA256-SHA384 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=Camellia(256)          Mac=SHA384
ECDHE-RSA-CAMELLIA256-SHA384   TLSv1.2 Kx=ECDH     Au=RSA   Enc=Camellia(256)          Mac=SHA384
ECDHE-ECDSA-AES128-SHA256      TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AES(128)               Mac=SHA256
ECDHE-RSA-AES128-SHA256        TLSv1.2 Kx=ECDH     Au=RSA   Enc=AES(128)               Mac=SHA256
ECDHE-ECDSA-CAMELLIA128-SHA256 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=Camellia(128)          Mac=SHA256
ECDHE-RSA-CAMELLIA128-SHA256   TLSv1.2 Kx=ECDH     Au=RSA   Enc=Camellia(128)          Mac=SHA256
ECDHE-ECDSA-AES256-SHA         TLSv1   Kx=ECDH     Au=ECDSA Enc=AES(256)               Mac=SHA1
ECDHE-RSA-AES256-SHA           TLSv1   Kx=ECDH     Au=RSA   Enc=AES(256)               Mac=SHA1
ECDHE-ECDSA-AES128-SHA         TLSv1   Kx=ECDH     Au=ECDSA Enc=AES(128)               Mac=SHA1
ECDHE-RSA-AES128-SHA           TLSv1   Kx=ECDH     Au=RSA   Enc=AES(128)               Mac=SHA1
So it does support TLSv1.3 Could it be because my certificate authority is type RSA? Disabling TLSv1.3 would fix it again that doesn?t help me in the future 

openssl req -x509 -new -nodes -key myProxykey.key -sha256 -days 365 -out myProxyca.pem



> On Jul 5, 2024, at 13:54, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> I have also tested in 5.8 and 6.6 both show the same condition, 6.6 shows errors for it however. I have also imported my certificates into wireshark. 
> 
> Just to confirm this is the firewall 192.168.1.1 port 3128 is squid going to iMac that is attempting TSL1.3 I have nosslv3 set also. The firewall is where I grabbed the pcap from 
> Sent from my iPhone
> 
>> On Jul 5, 2024, at 11:52, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> ?If it?s encrypted at TLS1.3 it should still work with the approved certificate authority as it is imported to my devices I own. I just enable TLS1.3 right?
>> 
>>> On Jul 5, 2024, at 11:28, <jonathanlee571 at gmail.com> <jonathanlee571 at gmail.com> wrote:
>>> 
>>> The only one I got a certificate from was the non iMac
>>> 
>>> The iMac keeps sending change cipher requests and wants TLS1.3 over and over as soon as a TLS1.2 pops up it works
>>> 
>>> That one has the certificate however that system the Toshiba does not have any issues with this error. I highly suspect that I need to enable TLS1.3 would you agree?
>>> 
>>> -----Original Message-----
>>> From: Alex Rousskov <rousskov at measurement-factory.com>
>>> Sent: Friday, July 5, 2024 11:02 AM
>>> To: squid-users <squid-users at lists.squid-cache.org>
>>> Cc: Jonathan Lee <jonathanlee571 at gmail.com>
>>> Subject: Re: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
>>> 
>>> On 2024-07-05 12:02, Jonathan Lee wrote:
>>> 
>>>>> Alex: I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).
>>> 
>>> 
>>>> I have Wireshark running do I just look for information with
>>>> ssl.handshake.type == 1
>>> 
>>>> Or is there a wireshark particular filter you would like ran to help with isolation?
>>> 
>>> 
>>> Please use Wireshark to determine the name of CA that issued the certificate that Squid sent to the client in the failing test case. If you are not sure, feel free to share issuer and subject fields of all certificates that Squid sent to the client in that test case (there may be two of each if Squid sent two certificates). Or even share a pointer to the entire (compressed) raw test case packet capture in pcap format!
>>> 
>>> These certificates are a part of standard TLS handshake, and Wireshark usually displays their fields when one studies TLS handshake bytes using Wireshark UI.
>>> 
>>> I do not know what filter would work best, but there should be just a handful of TLS handshake packets to examine for the test case, so no filter should be necessary.
>>> 
>>> 
>>> HTH,
>>> 
>>> Alex.
>>> 
>>> 
>>> 
>>>>> On Jul 5, 2024, at 08:23, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>>> 
>>>>> Thanks for the email and support with this. I will get wireshark
>>>>> running on the client and get the info required. Yes the information
>>>>> prior is from the firewall side outside of the proxy testing from the
>>>>> demilitarized zone area. I wanted to test this first to rule that out
>>>>> as it?s coming in from that first and hits the proxy next Sent from
>>>>> my iPhone
>>>>> 
>>>>>> On Jul 5, 2024, at 06:33, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>>>> 
>>>>>> ?On 2024-07-04 19:12, Jonathan Lee wrote:
>>>>>>> You also stated .. " my current working theory suggests that we are looking at a (default) signUntrusted use case.?
>>>>>>> I noticed for Squid documents that default is now set to off ..
>>>>>> 
>>>>>> The http_port option you are looking at now is not the directive I was talking about earlier.
>>>>>> 
>>>>>>> http_port
>>>>>>> tls-default-ca[=off]
>>>>>>> Whether to use the system Trusted CAs. Default is OFF.
>>>>>>> Would enabling this resolve the problem in Squid 6.6 for error.
>>>>>> 
>>>>>> 
>>>>>> No, the above poorly documented http_port option is for validating _client_ certificates. It has been off since Squid v4 AFAICT. Your clients are not sending client certificates to Squid.
>>>>>> 
>>>>>> According to the working theory, the problem we are solving is related to server certificates. http_port tls-default-ca option does not affect server certificate validation. Server certificate validation should use default CAs by default.
>>>>>> 
>>>>>> Outside of SslBump, server certificate validation is controlled by tls_outgoing_options default-ca option. That option defaults to "on". I am not sure whether SslBump honors that directive/option though. There are known related bugs in that area. However, we are jumping ahead of ourselves. We should confirm the working theory first.
>>>>>> 
>>>>>>> The squid.conf.documented lists it incorrectly
>>>>>> 
>>>>>> Squid has many directives and a directive may have many options. One should not use an directive option name instead of a directive name. One should not use an option from one directive with another directive. Squid naming is often inconsistent; be careful.
>>>>>> 
>>>>>> * http_port is a directive. tls-default-ca is an option for that directive. It is used for client certificate validation. It defaults to "off" (because client certificates are rarely signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>>>>>> 
>>>>>> * tls_outgoing_options is a directive. default-ca is an option for that directive. It is used for server certificate validation outside of SslBump contexts (at least!). It defaults to "on" (because server certificates are usually signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>>>>>> 
>>>>>> AFAICT, the documentation in question is not wrong (but is insufficient).
>>>>>> 
>>>>>> Again, I do not recommend changing any Squid configuration directives/options at this triage state.
>>>>>> 
>>>>>> Alex.
>>>>>> 
>>> 
>>> <tlschange.PNG>
>> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240705/0f6f10a5/attachment.htm>

From jonathanlee571 at gmail.com  Fri Jul  5 21:30:06 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Jul 2024 14:30:06 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <2EEDA700-23AA-4CA0-97D6-AA60122AA0DE@gmail.com>
References: <B599C9DC-3E0F-46C6-B7FB-DB88C44EDD2E@gmail.com>
 <07453F3F-96E7-491F-ABC5-D9BB8AF1FA33@gmail.com>
 <2EEDA700-23AA-4CA0-97D6-AA60122AA0DE@gmail.com>
Message-ID: <49E443EC-B7A9-4D97-8C50-2636071CF080@gmail.com>

tls_outgoing_options options=NO_SSLv3,NO_TLSv1_3
NO_TLSv1_3 is the directive if you need to disable this I have found for all other users with this problem 

> On Jul 5, 2024, at 14:21, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> output of versions 
> 
> Shell Output - openssl ciphers -s -v ECDHE
> TLS_AES_256_GCM_SHA384         TLSv1.3 Kx=any      Au=any   Enc=AESGCM(256)            Mac=AEAD
> TLS_CHACHA20_POLY1305_SHA256   TLSv1.3 Kx=any      Au=any   Enc=CHACHA20/POLY1305(256) Mac=AEAD
> TLS_AES_128_GCM_SHA256         TLSv1.3 Kx=any      Au=any   Enc=AESGCM(128)            Mac=AEAD
> ECDHE-ECDSA-AES256-GCM-SHA384  TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESGCM(256)            Mac=AEAD
> ECDHE-RSA-AES256-GCM-SHA384    TLSv1.2 Kx=ECDH     Au=RSA   Enc=AESGCM(256)            Mac=AEAD
> ECDHE-ECDSA-CHACHA20-POLY1305  TLSv1.2 Kx=ECDH     Au=ECDSA Enc=CHACHA20/POLY1305(256) Mac=AEAD
> ECDHE-RSA-CHACHA20-POLY1305    TLSv1.2 Kx=ECDH     Au=RSA   Enc=CHACHA20/POLY1305(256) Mac=AEAD
> ECDHE-ECDSA-AES256-CCM8        TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESCCM8(256)           Mac=AEAD
> ECDHE-ECDSA-AES256-CCM         TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESCCM(256)            Mac=AEAD
> ECDHE-ECDSA-AES128-GCM-SHA256  TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESGCM(128)            Mac=AEAD
> ECDHE-RSA-AES128-GCM-SHA256    TLSv1.2 Kx=ECDH     Au=RSA   Enc=AESGCM(128)            Mac=AEAD
> ECDHE-ECDSA-AES128-CCM8        TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESCCM8(128)           Mac=AEAD
> ECDHE-ECDSA-AES128-CCM         TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AESCCM(128)            Mac=AEAD
> ECDHE-ECDSA-AES256-SHA384      TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AES(256)               Mac=SHA384
> ECDHE-RSA-AES256-SHA384        TLSv1.2 Kx=ECDH     Au=RSA   Enc=AES(256)               Mac=SHA384
> ECDHE-ECDSA-CAMELLIA256-SHA384 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=Camellia(256)          Mac=SHA384
> ECDHE-RSA-CAMELLIA256-SHA384   TLSv1.2 Kx=ECDH     Au=RSA   Enc=Camellia(256)          Mac=SHA384
> ECDHE-ECDSA-AES128-SHA256      TLSv1.2 Kx=ECDH     Au=ECDSA Enc=AES(128)               Mac=SHA256
> ECDHE-RSA-AES128-SHA256        TLSv1.2 Kx=ECDH     Au=RSA   Enc=AES(128)               Mac=SHA256
> ECDHE-ECDSA-CAMELLIA128-SHA256 TLSv1.2 Kx=ECDH     Au=ECDSA Enc=Camellia(128)          Mac=SHA256
> ECDHE-RSA-CAMELLIA128-SHA256   TLSv1.2 Kx=ECDH     Au=RSA   Enc=Camellia(128)          Mac=SHA256
> ECDHE-ECDSA-AES256-SHA         TLSv1   Kx=ECDH     Au=ECDSA Enc=AES(256)               Mac=SHA1
> ECDHE-RSA-AES256-SHA           TLSv1   Kx=ECDH     Au=RSA   Enc=AES(256)               Mac=SHA1
> ECDHE-ECDSA-AES128-SHA         TLSv1   Kx=ECDH     Au=ECDSA Enc=AES(128)               Mac=SHA1
> ECDHE-RSA-AES128-SHA           TLSv1   Kx=ECDH     Au=RSA   Enc=AES(128)               Mac=SHA1
> So it does support TLSv1.3 Could it be because my certificate authority is type RSA? Disabling TLSv1.3 would fix it again that doesn?t help me in the future 
> 
> openssl req -x509 -new -nodes -key myProxykey.key -sha256 -days 365 -out myProxyca.pem
> 
> 
> 
>> On Jul 5, 2024, at 13:54, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> I have also tested in 5.8 and 6.6 both show the same condition, 6.6 shows errors for it however. I have also imported my certificates into wireshark. 
>> 
>> Just to confirm this is the firewall 192.168.1.1 port 3128 is squid going to iMac that is attempting TSL1.3 I have nosslv3 set also. The firewall is where I grabbed the pcap from 
>> Sent from my iPhone
>> 
>>> On Jul 5, 2024, at 11:52, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>> 
>>> ?If it?s encrypted at TLS1.3 it should still work with the approved certificate authority as it is imported to my devices I own. I just enable TLS1.3 right?
>>> 
>>>> On Jul 5, 2024, at 11:28, <jonathanlee571 at gmail.com> <jonathanlee571 at gmail.com> wrote:
>>>> 
>>>> The only one I got a certificate from was the non iMac
>>>> 
>>>> The iMac keeps sending change cipher requests and wants TLS1.3 over and over as soon as a TLS1.2 pops up it works
>>>> 
>>>> That one has the certificate however that system the Toshiba does not have any issues with this error. I highly suspect that I need to enable TLS1.3 would you agree?
>>>> 
>>>> -----Original Message-----
>>>> From: Alex Rousskov <rousskov at measurement-factory.com>
>>>> Sent: Friday, July 5, 2024 11:02 AM
>>>> To: squid-users <squid-users at lists.squid-cache.org>
>>>> Cc: Jonathan Lee <jonathanlee571 at gmail.com>
>>>> Subject: Re: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
>>>> 
>>>> On 2024-07-05 12:02, Jonathan Lee wrote:
>>>> 
>>>>>> Alex: I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).
>>>> 
>>>> 
>>>>> I have Wireshark running do I just look for information with
>>>>> ssl.handshake.type == 1
>>>> 
>>>>> Or is there a wireshark particular filter you would like ran to help with isolation?
>>>> 
>>>> 
>>>> Please use Wireshark to determine the name of CA that issued the certificate that Squid sent to the client in the failing test case. If you are not sure, feel free to share issuer and subject fields of all certificates that Squid sent to the client in that test case (there may be two of each if Squid sent two certificates). Or even share a pointer to the entire (compressed) raw test case packet capture in pcap format!
>>>> 
>>>> These certificates are a part of standard TLS handshake, and Wireshark usually displays their fields when one studies TLS handshake bytes using Wireshark UI.
>>>> 
>>>> I do not know what filter would work best, but there should be just a handful of TLS handshake packets to examine for the test case, so no filter should be necessary.
>>>> 
>>>> 
>>>> HTH,
>>>> 
>>>> Alex.
>>>> 
>>>> 
>>>> 
>>>>>> On Jul 5, 2024, at 08:23, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>>>> 
>>>>>> Thanks for the email and support with this. I will get wireshark
>>>>>> running on the client and get the info required. Yes the information
>>>>>> prior is from the firewall side outside of the proxy testing from the
>>>>>> demilitarized zone area. I wanted to test this first to rule that out
>>>>>> as it?s coming in from that first and hits the proxy next Sent from
>>>>>> my iPhone
>>>>>> 
>>>>>>> On Jul 5, 2024, at 06:33, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>>>>> 
>>>>>>> ?On 2024-07-04 19:12, Jonathan Lee wrote:
>>>>>>>> You also stated .. " my current working theory suggests that we are looking at a (default) signUntrusted use case.?
>>>>>>>> I noticed for Squid documents that default is now set to off ..
>>>>>>> 
>>>>>>> The http_port option you are looking at now is not the directive I was talking about earlier.
>>>>>>> 
>>>>>>>> http_port
>>>>>>>> tls-default-ca[=off]
>>>>>>>> Whether to use the system Trusted CAs. Default is OFF.
>>>>>>>> Would enabling this resolve the problem in Squid 6.6 for error.
>>>>>>> 
>>>>>>> 
>>>>>>> No, the above poorly documented http_port option is for validating _client_ certificates. It has been off since Squid v4 AFAICT. Your clients are not sending client certificates to Squid.
>>>>>>> 
>>>>>>> According to the working theory, the problem we are solving is related to server certificates. http_port tls-default-ca option does not affect server certificate validation. Server certificate validation should use default CAs by default.
>>>>>>> 
>>>>>>> Outside of SslBump, server certificate validation is controlled by tls_outgoing_options default-ca option. That option defaults to "on". I am not sure whether SslBump honors that directive/option though. There are known related bugs in that area. However, we are jumping ahead of ourselves. We should confirm the working theory first.
>>>>>>> 
>>>>>>>> The squid.conf.documented lists it incorrectly
>>>>>>> 
>>>>>>> Squid has many directives and a directive may have many options. One should not use an directive option name instead of a directive name. One should not use an option from one directive with another directive. Squid naming is often inconsistent; be careful.
>>>>>>> 
>>>>>>> * http_port is a directive. tls-default-ca is an option for that directive. It is used for client certificate validation. It defaults to "off" (because client certificates are rarely signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>>>>>>> 
>>>>>>> * tls_outgoing_options is a directive. default-ca is an option for that directive. It is used for server certificate validation outside of SslBump contexts (at least!). It defaults to "on" (because server certificates are usually signed by well-known (a.k.a. "default") CAs preinstalled in many deployment environments).
>>>>>>> 
>>>>>>> AFAICT, the documentation in question is not wrong (but is insufficient).
>>>>>>> 
>>>>>>> Again, I do not recommend changing any Squid configuration directives/options at this triage state.
>>>>>>> 
>>>>>>> Alex.
>>>>>>> 
>>>> 
>>>> <tlschange.PNG>
>>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240705/448f285e/attachment.htm>

From jonathanlee571 at gmail.com  Fri Jul  5 21:33:06 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Jul 2024 14:33:06 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <BCA3C955-2899-4C9E-B82B-65BF268579C0@gmail.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
 <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
 <DA771A75-5CF4-4CB1-B63A-AD2937C07604@gmail.com>
 <f4b44f1a-e817-407c-8045-26af617b6cd4@measurement-factory.com>
 <88441F2A-5A7F-469B-8AD3-B27CF1ED7B28@gmail.com>
 <E733FB66-E104-43B6-BFDD-1C255C20816A@gmail.com>
 <BCA3C955-2899-4C9E-B82B-65BF268579C0@gmail.com>
Message-ID: <097DDBD3-0C2C-47FB-8721-A7FF2E1A4664@gmail.com>

However even with it marked as no 

05.07.2024 14:30:46	ERROR: failure while accepting a TLS connection on conn4633 local=192.168.1.1:3128 remote=192.168.1.5:49721 FD 30 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1



continues

I am going to take a break please if anyone know how to resolve this or wants me to try something else let me know. I was originally looking for the certificate when this error occurs however the error comes from the TLS_v1.3 as seen in the pcap files below. 


Thanks again everyone  

> On Jul 4, 2024, at 16:02, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
>>>> I do not recommend changing your configuration at this time. I recommend rereading my earlier recommendation and following that instead: "As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log)."
> 
> 
> Ok I went back to 5.8 and ran the following command after I removed the changes I used does this help this is ran on the firewall side itself. 
> 
>  openssl s_client -connect foxnews.com:443 <http://foxnews.com:443/>
> 
> depth=2 C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert Global Root CA
> verify return:1
> depth=1 C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
> verify return:1
> depth=0 C = US, ST = New York, L = New York, O = "Fox News Network, LLC", CN = wildcard.foxnews.com
> verify return:1
> CONNECTED(00000004)
> ---
> Certificate chain
>  0 s:C = US, ST = New York, L = New York, O = "Fox News Network, LLC", CN = wildcard.foxnews.com
>    i:C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
>  1 s:C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
>    i:C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert Global Root CA
> 
> -----END CERTIFICATE-----
> subject=C = US, ST = New York, L = New York, O = "Fox News Network, LLC", CN = wildcard.foxnews.com
> 
> issuer=C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
> 
> ---
> No client certificate CA names sent
> Peer signing digest: SHA256
> Peer signature type: ECDSA
> Server Temp Key: X25519, 253 bits
> ---
> SSL handshake has read 4198 bytes and written 393 bytes
> Verification: OK
> ---
> New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384
> Server public key is 256 bit
> Secure Renegotiation IS NOT supported
> Compression: NONE
> Expansion: NONE
> No ALPN negotiated
> Early data was not sent
> Verify return code: 0 (ok)
> ---
> DONE
> 
> Does that help I am not going to pretend I understand TLS options I do understand how the SSL ciphers work and certificates but all the different options and kinds are what is confusing me. I did not seem to have this error before.
> 
> 
> Should I regenerate a new certificate for the new version of Squid and redeploy them all to hosts again? I used this method in the past and it worked for a long time after I imported it. I am wondering if this is outdated now
> 
> openssl req -x509 -new -nodes -key myProxykey.key -sha256 -days 365 -out myProxyca.pem
> 
> 
>> On Jul 4, 2024, at 15:13, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> Sorry 
>> 
>> tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>> tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>> 
>> Would I add this here?
>> 
>>> On Jul 4, 2024, at 15:12, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>> 
>>> I know before I could use 
>>> 
>>> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>>> 
>>> However with the update I am seeing 
>>> 
>>> ERROR: Unsupported TLS option SINGLE_ECDH_USE
>>> 
>>> I found researching in lists-squid-cache.org <http://lists-squid-cache.org/> that someone solved this with appending TLS13-AES-256-CGM-SHA384 to the ciphers. 
>>> 
>>> I am thinking this is my issue also.
>>> 
>>> I see that error over and over when I run "squid -k parse?
>>> 
>>> Do I append this to the options cipher list?
>>> 
>>> Jonathan Lee
>>> 
>>>> On Jul 4, 2024, at 14:45, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>> 
>>>> On 2024-07-04 15:37, Jonathan Lee wrote:
>>>> 
>>>>> in Squid.conf I have nothing with that detective.
>>>> 
>>>> Sounds good; sslproxy_cert_sign default should work OK in most cases. I mentioned signUntrusted algorithm so that you can discover (from the corresponding sslproxy_cert_sign documentation) which CA/certificate Squid uses in which SslBump use case. Triage is often easier if folks share the same working theory, and my current working theory suggests that we are looking at a (default) signUntrusted use case.
>>>> 
>>>> The solution here probably does _not_ involve changing sslproxy_cert_sign configuration, but, to make progress, I need more info to confirm this working theory and describe next steps.
>>>> 
>>>> 
>>>>> Yes I am using SSL bump with this configuration..
>>>> 
>>>> Noted, thank you.
>>>> 
>>>> 
>>>>> So would I use this directive
>>>> 
>>>> I do not recommend changing your configuration at this time. I recommend rereading my earlier recommendation and following that instead: "As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log)."
>>>> 
>>>> 
>>>> HTH,
>>>> 
>>>> Alex.
>>>> 
>>>> 
>>>>>> On Jul 4, 2024, at 09:56, Alex Rousskov wrote:
>>>>>> 
>>>>>> On 2024-07-04 12:11, Jonathan Lee wrote:
>>>>>>> failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128
>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417
>>>>>> 
>>>>>> A000417 is an "unknown CA" alert sent by client to Squid while the client is trying to establish a TLS connection to/through Squid. The client does not trust the Certificate Authority that signed the certificate that was used for that TLS connection.
>>>>>> 
>>>>>> As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).
>>>>>> 
>>>>>> If you use SslBump for port 3128 traffic, then one of the possibilities here is that Squid is using an unknown-to-client CA to report an origin server that Squid itself does not trust (see signUntrusted in squid.conf.documented). In those cases, logging a level-1 ERROR is a Squid bug because that expected/desirable outcome should be treated as success (and a successful TLS accept treated as an error!).
>>>>>> 
>>>>>> 
>>>>>> HTH,
>>>>>> 
>>>>>> Alex.
>>>> 
>>>> 
>>>>>>> Is my main concern however I use the squid guard URL blocker
>>>>>>> Sent from my iPhone
>>>>>>>> On Jul 4, 2024, at 07:41, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>>>>>> 
>>>>>>>> ?On 2024-07-03 13:56, Jonathan Lee wrote:
>>>>>>>>> Hello fellow Squid users does anyone know how to fix this issue?
>>>>>>>> 
>>>>>>>> I counted about eight different "issues" in your cache.log sample. Most of them are probably independent. I recommend that you explicitly pick _one_, search mailing list archives for previous discussions about it, and then provide as many details about it as you can (e.g., what traffic causes it and/or matching access.log records).
>>>>>>>> 
>>>>>>>> 
>>>>>>>> HTH,
>>>>>>>> 
>>>>>>>> Alex.
>>>>>>>> 
>>>>>>>> 
>>>>>>>>> Squid - Cache Logs
>>>>>>>>> Date-Time    Message
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:54:34    kick abandoning conn7853 local=192.168.1.1:3128 remote=192.168.1.5:49710 FD 89 flags=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:54:29    kick abandoning conn7844 local=192.168.1.1:3128 remote=192.168.1.5:49702 FD 81 flags=1
>>>>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7648 local=192.168.1.1:3128 remote=192.168.1.5:49672 FD 44 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7647 local=192.168.1.1:3128 remote=192.168.1.5:49670 FD 43 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7646 local=192.168.1.1:3128 remote=192.168.1.5:49668 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:53:04    ERROR: failure while accepting a TLS connection on conn7367 local=192.168.1.1:3128 remote=192.168.1.5:49627 FD 22 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:52:47    ERROR: failure while accepting a TLS connection on conn7345 local=192.168.1.1:3128 remote=192.168.1.5:49618 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:52:38    ERROR: failure while accepting a TLS connection on conn7340 local=192.168.1.1:3128 remote=192.168.1.5:49616 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:52:34    ERROR: failure while accepting a TLS connection on conn7316 local=192.168.1.1:3128 remote=192.168.1.5:49609 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:51:55    WARNING: Error Pages Missing Language: en-us
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:51:55    ERROR: loading file 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': (2) No such file or directory
>>>>>>>>> 03.07.2024 10:51:44    ERROR: failure while accepting a TLS connection on conn7102 local=192.168.1.1:3128 remote=192.168.1.5:49574 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:51:28    ERROR: failure while accepting a TLS connection on conn7071 local=192.168.1.1:3128 remote=192.168.1.5:49568 FD 92 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:50:29    ERROR: failure while accepting a TLS connection on conn6944 local=192.168.1.1:3128 remote=192.168.1.5:49534 FD 101 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:49:54    ERROR: failure while accepting a TLS connection on conn6866 local=192.168.1.1:3128 remote=192.168.1.5:49519 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:49:38    ERROR: failure while accepting a TLS connection on conn6809 local=192.168.1.1:3128 remote=192.168.1.5:49503 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:49:32    ERROR: system call failure while accepting a TLS connection on conn6794 local=192.168.1.1:3128 remote=192.168.1.5:49496 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
>>>>>>>>> 03.07.2024 10:49:24    ERROR: failure while accepting a TLS connection on conn6776 local=192.168.1.1:3128 remote=192.168.1.5:49481 FD 137 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:48:49    ERROR: failure while accepting a TLS connection on conn6440 local=192.168.1.1:3128 remote=192.168.1.5:49424 FD 16 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:48:49    ERROR: failure while accepting a TLS connection on conn6445 local=192.168.1.1:3128 remote=192.168.1.5:49426 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:48:22    ERROR: failure while accepting a TLS connection on conn6035 local=192.168.1.1:3128 remote=192.168.1.5:49355 FD 226 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128 remote=192.168.1.5:49318 FD 33 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5875 local=192.168.1.1:3128 remote=192.168.1.5:49312 FD 216 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5876 local=192.168.1.1:3128 remote=192.168.1.5:49314 FD 217 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:47:57    ERROR: failure while accepting a TLS connection on conn5815 local=192.168.1.1:3128 remote=192.168.1.5:49297 FD 201 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:47:54    ERROR: failure while accepting a TLS connection on conn5760 local=192.168.1.1:3128 remote=192.168.1.5:49289 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:47:52    ERROR: failure while accepting a TLS connection on conn5717 local=192.168.1.1:3128 remote=192.168.1.5:49284 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:47:50    ERROR: failure while accepting a TLS connection on conn5552 local=192.168.1.1:3128 remote=192.168.1.5:49268 FD 142 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:47:34    kick abandoning conn5254 local=192.168.1.1:3128 remote=192.168.1.5:49209 FD 100 flags=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:47:21    kick abandoning conn5022 local=192.168.1.1:3128 remote=192.168.1.5:49167 FD 37 flags=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:47:21    kick abandoning conn5020 local=192.168.1.1:3128 remote=192.168.1.5:49165 FD 36 flags=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:42:22    WARNING: Forwarding loop detected for:
>>>>>>>>> 03.07.2024 10:40:08    ERROR: failure while accepting a TLS connection on conn4955 local=192.168.1.1:3128 remote=192.168.1.5:52339 FD 98 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 03.07.2024 10:39:52    kick abandoning conn4927 local=192.168.1.1:3128 remote=192.168.1.5:52331 FD 105 flags=1
>>>>>>>>> 03.07.2024 10:39:09    ERROR: failure while accepting a TLS connection on conn4846 local=192.168.1.1:3128 remote=192.168.1.5:52314 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:38:14    ERROR: failure while accepting a TLS connection on conn4650 local=192.168.1.1:3128 remote=192.168.1.5:52274 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:38:08    ERROR: failure while accepting a TLS connection on conn4645 local=192.168.1.1:3128 remote=192.168.1.5:52272 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>> 03.07.2024 10:38:04    ERROR: Unsupported TLS option SINGLE_ECDH_USE
>>>>>>>>> 03.07.2024 10:38:04    ERROR: Unsupported TLS option SINGLE_DH_USE
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>> _______________________________________________
>>>>>>>>> squid-users mailing list
>>>>>>>>> squid-users at lists.squid-cache.org
>>>>>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>>>>> 
>>>>>> 
>>>> 
>>> 
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240705/334f6603/attachment.htm>

From jonathanlee571 at gmail.com  Sat Jul  6 00:55:48 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Jul 2024 17:55:48 -0700
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <097DDBD3-0C2C-47FB-8721-A7FF2E1A4664@gmail.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
 <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
 <DA771A75-5CF4-4CB1-B63A-AD2937C07604@gmail.com>
 <f4b44f1a-e817-407c-8045-26af617b6cd4@measurement-factory.com>
 <88441F2A-5A7F-469B-8AD3-B27CF1ED7B28@gmail.com>
 <E733FB66-E104-43B6-BFDD-1C255C20816A@gmail.com>
 <BCA3C955-2899-4C9E-B82B-65BF268579C0@gmail.com>
 <097DDBD3-0C2C-47FB-8721-A7FF2E1A4664@gmail.com>
Message-ID: <CD9F95A0-B083-4089-B846-DE4B0C501D1D@gmail.com>

FIXED 

I think it wanted a new certificate generated mine became to weak I needed one that ECDSA with prime256v sha256 and not RSA anymore that solved my errors


The error is gone when this cert is used :) 

> On Jul 5, 2024, at 14:33, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> However even with it marked as no 
> 
> 05.07.2024 14:30:46	ERROR: failure while accepting a TLS connection on conn4633 local=192.168.1.1:3128 remote=192.168.1.5:49721 FD 30 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
> 
> 
> 
> continues
> 
> I am going to take a break please if anyone know how to resolve this or wants me to try something else let me know. I was originally looking for the certificate when this error occurs however the error comes from the TLS_v1.3 as seen in the pcap files below. 
> 
> 
> Thanks again everyone  
> 
>> On Jul 4, 2024, at 16:02, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>>>>> I do not recommend changing your configuration at this time. I recommend rereading my earlier recommendation and following that instead: "As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log)."
>> 
>> 
>> Ok I went back to 5.8 and ran the following command after I removed the changes I used does this help this is ran on the firewall side itself. 
>> 
>>  openssl s_client -connect foxnews.com:443 <http://foxnews.com:443/>
>> 
>> depth=2 C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert Global Root CA
>> verify return:1
>> depth=1 C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
>> verify return:1
>> depth=0 C = US, ST = New York, L = New York, O = "Fox News Network, LLC", CN = wildcard.foxnews.com
>> verify return:1
>> CONNECTED(00000004)
>> ---
>> Certificate chain
>>  0 s:C = US, ST = New York, L = New York, O = "Fox News Network, LLC", CN = wildcard.foxnews.com
>>    i:C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
>>  1 s:C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
>>    i:C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert Global Root CA
>> 
>> -----END CERTIFICATE-----
>> subject=C = US, ST = New York, L = New York, O = "Fox News Network, LLC", CN = wildcard.foxnews.com
>> 
>> issuer=C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
>> 
>> ---
>> No client certificate CA names sent
>> Peer signing digest: SHA256
>> Peer signature type: ECDSA
>> Server Temp Key: X25519, 253 bits
>> ---
>> SSL handshake has read 4198 bytes and written 393 bytes
>> Verification: OK
>> ---
>> New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384
>> Server public key is 256 bit
>> Secure Renegotiation IS NOT supported
>> Compression: NONE
>> Expansion: NONE
>> No ALPN negotiated
>> Early data was not sent
>> Verify return code: 0 (ok)
>> ---
>> DONE
>> 
>> Does that help I am not going to pretend I understand TLS options I do understand how the SSL ciphers work and certificates but all the different options and kinds are what is confusing me. I did not seem to have this error before.
>> 
>> 
>> Should I regenerate a new certificate for the new version of Squid and redeploy them all to hosts again? I used this method in the past and it worked for a long time after I imported it. I am wondering if this is outdated now
>> 
>> openssl req -x509 -new -nodes -key myProxykey.key -sha256 -days 365 -out myProxyca.pem
>> 
>> 
>>> On Jul 4, 2024, at 15:13, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>> 
>>> Sorry 
>>> 
>>> tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>>> tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>>> 
>>> Would I add this here?
>>> 
>>>> On Jul 4, 2024, at 15:12, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>> 
>>>> I know before I could use 
>>>> 
>>>> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>>>> 
>>>> However with the update I am seeing 
>>>> 
>>>> ERROR: Unsupported TLS option SINGLE_ECDH_USE
>>>> 
>>>> I found researching in lists-squid-cache.org <http://lists-squid-cache.org/> that someone solved this with appending TLS13-AES-256-CGM-SHA384 to the ciphers. 
>>>> 
>>>> I am thinking this is my issue also.
>>>> 
>>>> I see that error over and over when I run "squid -k parse?
>>>> 
>>>> Do I append this to the options cipher list?
>>>> 
>>>> Jonathan Lee
>>>> 
>>>>> On Jul 4, 2024, at 14:45, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>>> 
>>>>> On 2024-07-04 15:37, Jonathan Lee wrote:
>>>>> 
>>>>>> in Squid.conf I have nothing with that detective.
>>>>> 
>>>>> Sounds good; sslproxy_cert_sign default should work OK in most cases. I mentioned signUntrusted algorithm so that you can discover (from the corresponding sslproxy_cert_sign documentation) which CA/certificate Squid uses in which SslBump use case. Triage is often easier if folks share the same working theory, and my current working theory suggests that we are looking at a (default) signUntrusted use case.
>>>>> 
>>>>> The solution here probably does _not_ involve changing sslproxy_cert_sign configuration, but, to make progress, I need more info to confirm this working theory and describe next steps.
>>>>> 
>>>>> 
>>>>>> Yes I am using SSL bump with this configuration..
>>>>> 
>>>>> Noted, thank you.
>>>>> 
>>>>> 
>>>>>> So would I use this directive
>>>>> 
>>>>> I do not recommend changing your configuration at this time. I recommend rereading my earlier recommendation and following that instead: "As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log)."
>>>>> 
>>>>> 
>>>>> HTH,
>>>>> 
>>>>> Alex.
>>>>> 
>>>>> 
>>>>>>> On Jul 4, 2024, at 09:56, Alex Rousskov wrote:
>>>>>>> 
>>>>>>> On 2024-07-04 12:11, Jonathan Lee wrote:
>>>>>>>> failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128
>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417
>>>>>>> 
>>>>>>> A000417 is an "unknown CA" alert sent by client to Squid while the client is trying to establish a TLS connection to/through Squid. The client does not trust the Certificate Authority that signed the certificate that was used for that TLS connection.
>>>>>>> 
>>>>>>> As the next step in triage, I recommend determining what that CA is in these cases (e.g., by capturing raw TLS packets and matching them with connection information from A000417 error messages in cache.log or %err_detail in access.log).
>>>>>>> 
>>>>>>> If you use SslBump for port 3128 traffic, then one of the possibilities here is that Squid is using an unknown-to-client CA to report an origin server that Squid itself does not trust (see signUntrusted in squid.conf.documented). In those cases, logging a level-1 ERROR is a Squid bug because that expected/desirable outcome should be treated as success (and a successful TLS accept treated as an error!).
>>>>>>> 
>>>>>>> 
>>>>>>> HTH,
>>>>>>> 
>>>>>>> Alex.
>>>>> 
>>>>> 
>>>>>>>> Is my main concern however I use the squid guard URL blocker
>>>>>>>> Sent from my iPhone
>>>>>>>>> On Jul 4, 2024, at 07:41, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>>>>>>> 
>>>>>>>>> ?On 2024-07-03 13:56, Jonathan Lee wrote:
>>>>>>>>>> Hello fellow Squid users does anyone know how to fix this issue?
>>>>>>>>> 
>>>>>>>>> I counted about eight different "issues" in your cache.log sample. Most of them are probably independent. I recommend that you explicitly pick _one_, search mailing list archives for previous discussions about it, and then provide as many details about it as you can (e.g., what traffic causes it and/or matching access.log records).
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> HTH,
>>>>>>>>> 
>>>>>>>>> Alex.
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>>> Squid - Cache Logs
>>>>>>>>>> Date-Time    Message
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 03.07.2024 10:54:34    kick abandoning conn7853 local=192.168.1.1:3128 remote=192.168.1.5:49710 FD 89 flags=1
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 03.07.2024 10:54:29    kick abandoning conn7844 local=192.168.1.1:3128 remote=192.168.1.5:49702 FD 81 flags=1
>>>>>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7648 local=192.168.1.1:3128 remote=192.168.1.5:49672 FD 44 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7647 local=192.168.1.1:3128 remote=192.168.1.5:49670 FD 43 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:54:09    ERROR: failure while accepting a TLS connection on conn7646 local=192.168.1.1:3128 remote=192.168.1.5:49668 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:53:04    ERROR: failure while accepting a TLS connection on conn7367 local=192.168.1.1:3128 remote=192.168.1.5:49627 FD 22 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:52:47    ERROR: failure while accepting a TLS connection on conn7345 local=192.168.1.1:3128 remote=192.168.1.5:49618 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:52:38    ERROR: failure while accepting a TLS connection on conn7340 local=192.168.1.1:3128 remote=192.168.1.5:49616 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:52:34    ERROR: failure while accepting a TLS connection on conn7316 local=192.168.1.1:3128 remote=192.168.1.5:49609 FD 45 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 03.07.2024 10:51:55    WARNING: Error Pages Missing Language: en-us
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 03.07.2024 10:51:55    ERROR: loading file 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': (2) No such file or directory
>>>>>>>>>> 03.07.2024 10:51:44    ERROR: failure while accepting a TLS connection on conn7102 local=192.168.1.1:3128 remote=192.168.1.5:49574 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:51:28    ERROR: failure while accepting a TLS connection on conn7071 local=192.168.1.1:3128 remote=192.168.1.5:49568 FD 92 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:50:29    ERROR: failure while accepting a TLS connection on conn6944 local=192.168.1.1:3128 remote=192.168.1.5:49534 FD 101 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:49:54    ERROR: failure while accepting a TLS connection on conn6866 local=192.168.1.1:3128 remote=192.168.1.5:49519 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:49:38    ERROR: failure while accepting a TLS connection on conn6809 local=192.168.1.1:3128 remote=192.168.1.5:49503 FD 31 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 03.07.2024 10:49:32    ERROR: system call failure while accepting a TLS connection on conn6794 local=192.168.1.1:3128 remote=192.168.1.5:49496 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
>>>>>>>>>> 03.07.2024 10:49:24    ERROR: failure while accepting a TLS connection on conn6776 local=192.168.1.1:3128 remote=192.168.1.5:49481 FD 137 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:48:49    ERROR: failure while accepting a TLS connection on conn6440 local=192.168.1.1:3128 remote=192.168.1.5:49424 FD 16 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:48:49    ERROR: failure while accepting a TLS connection on conn6445 local=192.168.1.1:3128 remote=192.168.1.5:49426 FD 34 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:48:22    ERROR: failure while accepting a TLS connection on conn6035 local=192.168.1.1:3128 remote=192.168.1.5:49355 FD 226 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5887 local=192.168.1.1:3128 remote=192.168.1.5:49318 FD 33 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5875 local=192.168.1.1:3128 remote=192.168.1.5:49312 FD 216 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:48:09    ERROR: failure while accepting a TLS connection on conn5876 local=192.168.1.1:3128 remote=192.168.1.5:49314 FD 217 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:47:57    ERROR: failure while accepting a TLS connection on conn5815 local=192.168.1.1:3128 remote=192.168.1.5:49297 FD 201 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:47:54    ERROR: failure while accepting a TLS connection on conn5760 local=192.168.1.1:3128 remote=192.168.1.5:49289 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:47:52    ERROR: failure while accepting a TLS connection on conn5717 local=192.168.1.1:3128 remote=192.168.1.5:49284 FD 195 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:47:50    ERROR: failure while accepting a TLS connection on conn5552 local=192.168.1.1:3128 remote=192.168.1.5:49268 FD 142 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 03.07.2024 10:47:34    kick abandoning conn5254 local=192.168.1.1:3128 remote=192.168.1.5:49209 FD 100 flags=1
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 03.07.2024 10:47:21    kick abandoning conn5022 local=192.168.1.1:3128 remote=192.168.1.5:49167 FD 37 flags=1
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 03.07.2024 10:47:21    kick abandoning conn5020 local=192.168.1.1:3128 remote=192.168.1.5:49165 FD 36 flags=1
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 03.07.2024 10:42:22    WARNING: Forwarding loop detected for:
>>>>>>>>>> 03.07.2024 10:40:08    ERROR: failure while accepting a TLS connection on conn4955 local=192.168.1.1:3128 remote=192.168.1.5:52339 FD 98 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 03.07.2024 10:39:52    kick abandoning conn4927 local=192.168.1.1:3128 remote=192.168.1.5:52331 FD 105 flags=1
>>>>>>>>>> 03.07.2024 10:39:09    ERROR: failure while accepting a TLS connection on conn4846 local=192.168.1.1:3128 remote=192.168.1.5:52314 FD 19 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:38:14    ERROR: failure while accepting a TLS connection on conn4650 local=192.168.1.1:3128 remote=192.168.1.5:52274 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:38:08    ERROR: failure while accepting a TLS connection on conn4645 local=192.168.1.1:3128 remote=192.168.1.5:52272 FD 35 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>> 03.07.2024 10:38:04    ERROR: Unsupported TLS option SINGLE_ECDH_USE
>>>>>>>>>> 03.07.2024 10:38:04    ERROR: Unsupported TLS option SINGLE_DH_USE
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>> _______________________________________________
>>>>>>>>>> squid-users mailing list
>>>>>>>>>> squid-users at lists.squid-cache.org
>>>>>>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>>>>>> 
>>>>>>> 
>>>>> 
>>>> 
>>> 
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240705/a96b7bb0/attachment.htm>

From jonathanlee571 at gmail.com  Sat Jul  6 01:07:42 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 5 Jul 2024 18:07:42 -0700
Subject: [squid-users] Squid 6.6 kick abandoning connections
Message-ID: <D1191274-D08F-4F03-A353-535A3679516D@gmail.com>

Hello fellow Squid Users 

I am using Bump with certificates installed on devices does anyone know what this error is...

kick abandoning conn43723 local=192.168.1.1:3128 remote=192.168.1.5:52129 FD 178 flags=1

Does anyone know how to fix my last weird error I have with Squid 6.6 

This is my last weird error I am trying to pinpoint?

I really appreciate the new error codes that I can see the older versions did not have any information it was blank for 
issues like this?

thanks 




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240705/9a710e51/attachment.htm>

From jonathanlee571 at gmail.com  Sun Jul  7 21:13:02 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sun, 7 Jul 2024 14:13:02 -0700
Subject: [squid-users] Speed issues
In-Reply-To: <85D48B01-F0F4-4C8F-AFE3-4D39D3AA51AB@gmail.com>
References: <85D48B01-F0F4-4C8F-AFE3-4D39D3AA51AB@gmail.com>
Message-ID: <F6679295-BEB5-40A7-8B93-C982C22AC696@gmail.com>

This change seems to help

http_upgrade_request_protocols websocket allow all 
accept_filter httpready
accept_filter dataready
collapsed_forwarding on
half_closed_clients off
pipeline_prefetch 6

also enabling UDP on port 3128 

and disabling pinger now that the system is set up and running?



> On Jul 3, 2024, at 08:28, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Does anyone have tips for getting the proxy to run faster when SSL intercept is enabled along side splice lists with dynamic cache and ClamAV running?
> 
> 
> I just seems to have slow traffic on the interception side. 
> Sent from my iPhone



From jonathanlee571 at gmail.com  Mon Jul  8 04:06:56 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sun, 7 Jul 2024 21:06:56 -0700
Subject: [squid-users] ICMP and QUIC
Message-ID: <C44CC8A7-84A3-49AB-AD49-8B43BB7FA2DB@gmail.com>

Hello fellow Squid Users,

When watching facebook reels everything works as expected after about 15 minutes the system starts to attempt to use QUIC and after my iMac fan goes crazy and the website locks up..

HTTPS was reserved for 443. QUIC is also using UDP 443 and not following proper protocol rules. 

I do understand that QUIC is HTTP3 and uses UDP over 443 only. Again from a cybersecurity perspective how do you set up this protocol in the proxy ?

Here is the photo of the pcap showing the issue..

Does anyone know what to do to fix this?


-------------- next part --------------
A non-text attachment was scrubbed...
Name: QUIC.PNG
Type: image/png
Size: 71684 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240707/9d345cd1/attachment.png>

From jonathanlee571 at gmail.com  Mon Jul  8 04:10:14 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sun, 7 Jul 2024 21:10:14 -0700
Subject: [squid-users] ICMP and QUIC
Message-ID: <D2139A5D-AE5E-404E-A0B3-AF22DFA95665@gmail.com>

Hello fellow Squid Users,

When watching facebook reels everything works as expected after about 15 minutes the system starts to attempt to use QUIC and after my iMac fan goes crazy and the website locks up..

HTTPS was reserved for 443. QUIC is also using UDP 443 and not following proper protocol rules. 

I do understand that QUIC is HTTP3 and uses UDP over 443 only. Again from a cybersecurity perspective how do you set up this protocol in the proxy ?

Here is the photo of the pcap showing the issue..

Does anyone know what to do to fix this?


-------------- next part --------------
A non-text attachment was scrubbed...
Name: QUIC.PNG
Type: image/png
Size: 71684 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240707/a3c4225a/attachment.png>

From jonathanlee571 at gmail.com  Mon Jul  8 04:42:18 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sun, 7 Jul 2024 21:42:18 -0700
Subject: [squid-users] ICMP and QUIC
In-Reply-To: <5E1F18CC-07BA-407D-8A4D-0DB261FAD355@gmail.com>
References: <D2139A5D-AE5E-404E-A0B3-AF22DFA95665@gmail.com>
 <5E1F18CC-07BA-407D-8A4D-0DB261FAD355@gmail.com>
Message-ID: <D20611C4-07CD-4141-AB13-39F184D19B4C@gmail.com>

Does anyone use this directive for QUIC in the mean time? what?s weird is that IP address is Apple when Facebook is running

on_unsupported_protocol <>


> On Jul 7, 2024, at 21:24, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> I have just found... YEAH!!! has anyone tested this? Does Squid 6.6 have it? 
> https://github.com/squid-cache/squid/pull/919
>> On Jul 7, 2024, at 21:10, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> Hello fellow Squid Users,
>> 
>> When watching facebook reels everything works as expected after about 15 minutes the system starts to attempt to use QUIC and after my iMac fan goes crazy and the website locks up..
>> 
>> HTTPS was reserved for 443. QUIC is also using UDP 443 and not following proper protocol rules. 
>> 
>> I do understand that QUIC is HTTP3 and uses UDP over 443 only. Again from a cybersecurity perspective how do you set up this protocol in the proxy ?
>> 
>> Here is the photo of the pcap showing the issue..
>> 
>> Does anyone know what to do to fix this?
>> 
>> 
>> <QUIC.PNG>
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240707/70c316ca/attachment.htm>

From rousskov at measurement-factory.com  Mon Jul  8 12:35:50 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 8 Jul 2024 08:35:50 -0400
Subject: [squid-users] ICMP and QUIC
In-Reply-To: <C44CC8A7-84A3-49AB-AD49-8B43BB7FA2DB@gmail.com>
References: <C44CC8A7-84A3-49AB-AD49-8B43BB7FA2DB@gmail.com>
Message-ID: <63e6479a-b16b-485e-9612-6c0da5124608@measurement-factory.com>

On 2024-07-08 00:06, Jonathan Lee wrote:

> When watching facebook reels everything works as expected after about
> 15 minutes the system starts to attempt to use QUIC and after my iMac
> fan goes crazy and the website locks up..

Squid does not proxy UDP traffic (including QUIC). UDP traffic should 
not be forwarded/redirected/intercepted/etc. to Squid primary TCP 
listening ports (i.e. http_port, https_port, and ftp_port).

If you see signs of UDP traffic getting to Squid primary TCP ports, then 
something is misconfigured outside of Squid. In either case, the 
solution probably lies outside of Squid.


HTH,

Alex.


> HTTPS was reserved for 443. QUIC is also using UDP 443 and not following proper protocol rules.
> 
> I do understand that QUIC is HTTP3 and uses UDP over 443 only. Again from a cybersecurity perspective how do you set up this protocol in the proxy ?
> 
> Here is the photo of the pcap showing the issue..
> 
> Does anyone know what to do to fix this?
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From tribosmde at gmail.com  Mon Jul  8 14:39:58 2024
From: tribosmde at gmail.com (Random Dude)
Date: Mon, 8 Jul 2024 15:39:58 +0100
Subject: [squid-users] Unable to explain 407 Proxy Authentication Required
Message-ID: <CAFgeZO7tDom+YK6CDYzFkyGUqkGWLrtjA2+2MaW2Pj1+6LBi=w@mail.gmail.com>

Hey everyone.

I'm trying to get a minimal forward proxy with authentication set up. I
have the following config (purposely kept as minimal as possible) and have
followed these steps -
https://wiki.squid-cache.org/ConfigExamples/Authenticate/

squid.conf ---
auth_param basic program /usr/lib/squid/basic_ncsa_auth
/etc/squid/passwords auth_param basic children 5 auth_param basic
credentialsttl 1 minute acl CONNECT method CONNECT acl auth proxy_auth
REQUIRED http_port 3128 http_access deny !auth http_access allow auth
http_access deny all
---

However, no matter what I do I always get a 407 Proxy Authentication
Required response from the proxy. I've been testing with "curl -v -U
<usernamen>:<password> -x localhost:3128 <url>" I must be missing something
very simple so what am I doing wrong?

Thank you.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240708/90ba1911/attachment.htm>

From rousskov at measurement-factory.com  Mon Jul  8 15:47:05 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 8 Jul 2024 11:47:05 -0400
Subject: [squid-users] Squid Cache Issues migration from 5.8 to 6.6
In-Reply-To: <CD9F95A0-B083-4089-B846-DE4B0C501D1D@gmail.com>
References: <39d67422-bb1c-4b5d-8990-aa052cc1e1b2@measurement-factory.com>
 <0492F11B-AFF3-49CD-B4F5-C3369C4B1CD1@gmail.com>
 <30150677-cf8d-4d44-ad2a-66437dfa71f2@measurement-factory.com>
 <DA771A75-5CF4-4CB1-B63A-AD2937C07604@gmail.com>
 <f4b44f1a-e817-407c-8045-26af617b6cd4@measurement-factory.com>
 <88441F2A-5A7F-469B-8AD3-B27CF1ED7B28@gmail.com>
 <E733FB66-E104-43B6-BFDD-1C255C20816A@gmail.com>
 <BCA3C955-2899-4C9E-B82B-65BF268579C0@gmail.com>
 <097DDBD3-0C2C-47FB-8721-A7FF2E1A4664@gmail.com>
 <CD9F95A0-B083-4089-B846-DE4B0C501D1D@gmail.com>
Message-ID: <e891f017-68b9-4ec6-965a-7d641cbee658@measurement-factory.com>

On 2024-07-05 20:55, Jonathan Lee wrote:
> FIXED
> 
> I think it wanted a new certificate generated mine became to weak I 
> needed one that ECDSA with prime256v sha256 and not RSA anymore that 
> solved my errors

Glad you found a solution! And if these errors resurface, you now have a 
blueprint for their initial triage.

Alex.


> The error is gone when this cert is used :)
> 
>> On Jul 5, 2024, at 14:33, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>
>> However even with it marked as no
>>
>> 05.07.2024 14:30:46	ERROR: failure while accepting a TLS connection on 
>> conn4633 local=192.168.1.1:3128 remote=192.168.1.5:49721 FD 30 
>> flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>
>>
>>
>> continues
>>
>> I am going to take a break please if anyone know how to resolve this 
>> or wants me to try something else let me know. I was originally 
>> looking for the certificate when this error occurs however the error 
>> comes from the TLS_v1.3 as seen in the pcap files below.
>>
>>
>> Thanks again everyone
>>
>>> On Jul 4, 2024, at 16:02, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>
>>>>>> I do not recommend changing your configuration at this time. I 
>>>>>> recommend rereading my earlier recommendation and following that 
>>>>>> instead: "As the next step in triage, I recommend determining what 
>>>>>> that CA is in these cases (e.g., by capturing raw TLS packets and 
>>>>>> matching them with connection information from A000417 error 
>>>>>> messages in cache.log or %err_detail in access.log)."
>>>
>>> Ok I went back to 5.8 and ran the following command after I removed 
>>> the changes I used does this help this is ran on the firewall side 
>>> itself.
>>>
>>> ?openssl s_client -connect foxnews.com:443 <http://foxnews.com:443/>
>>>
>>> depth=2 C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert Global Root CA
>>> verify return:1
>>> depth=1 C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
>>> verify return:1
>>> depth=0 C = US, ST = New York, L = New York, O = "Fox News Network, LLC", CN = wildcard.foxnews.com
>>> verify return:1
>>> CONNECTED(00000004)
>>> ---
>>> Certificate chain
>>>   0 s:C = US, ST = New York, L = New York, O = "Fox News Network, LLC", CN = wildcard.foxnews.com
>>>     i:C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
>>>   1 s:C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
>>>     i:C = US, O = DigiCert Inc, OU = www.digicert.com, CN = DigiCert Global Root CA
>>>
>>> -----END CERTIFICATE-----
>>> subject=C = US, ST = New York, L = New York, O = "Fox News Network, LLC", CN = wildcard.foxnews.com
>>>
>>> issuer=C = US, O = DigiCert Inc, CN = DigiCert TLS RSA SHA256 2020 CA1
>>>
>>> ---
>>> No client certificate CA names sent
>>> Peer signing digest: SHA256
>>> Peer signature type: ECDSA
>>> Server Temp Key: X25519, 253 bits
>>> ---
>>> SSL handshake has read 4198 bytes and written 393 bytes
>>> Verification: OK
>>> ---
>>> New, TLSv1.3, Cipher is TLS_AES_256_GCM_SHA384
>>> Server public key is 256 bit
>>> Secure Renegotiation IS NOT supported
>>> Compression: NONE
>>> Expansion: NONE
>>> No ALPN negotiated
>>> Early data was not sent
>>> Verify return code: 0 (ok)
>>> ---
>>> DONE
>>>
>>> Does that help I am not going to pretend I understand TLS options I 
>>> do understand how the SSL ciphers work and certificates but all the 
>>> different options and kinds are what is confusing me. I did not seem 
>>> to have this error before.
>>>
>>>
>>> Should I regenerate a new certificate for the new version of Squid 
>>> and redeploy them all to hosts again? I used this method in the past 
>>> and it worked for a long time after I imported it. I am wondering if 
>>> this is outdated now
>>>
>>> *openssl req -x509 -new -nodes -key myProxykey.key -sha256 -days 365 
>>> -out myProxyca.pem*
>>>
>>>
>>>> On Jul 4, 2024, at 15:13, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>>
>>>> Sorry
>>>>
>>>> tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>>>> tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>>>>
>>>> Would I add this here?
>>>>
>>>>> On Jul 4, 2024, at 15:12, Jonathan Lee <jonathanlee571 at gmail.com> 
>>>>> wrote:
>>>>>
>>>>> I know before I could use
>>>>>
>>>>> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>>>>>
>>>>> However with the update I am seeing
>>>>>
>>>>> ERROR: Unsupported TLS option SINGLE_ECDH_USE
>>>>>
>>>>> I found researching in lists-squid-cache.org 
>>>>> <http://lists-squid-cache.org/>?that someone solved this with 
>>>>> appending TLS13-AES-256-CGM-SHA384 to the ciphers.
>>>>>
>>>>> I am thinking this is my issue also.
>>>>>
>>>>> I see that error over and over when I run "squid -k parse?
>>>>>
>>>>> Do I append this to the options cipher list?
>>>>>
>>>>> Jonathan Lee
>>>>>
>>>>>> On Jul 4, 2024, at 14:45, Alex Rousskov 
>>>>>> <rousskov at measurement-factory.com> wrote:
>>>>>>
>>>>>> On 2024-07-04 15:37, Jonathan Lee wrote:
>>>>>>
>>>>>>> in Squid.conf I have nothing with that detective.
>>>>>>
>>>>>> Sounds good; sslproxy_cert_sign default should work OK in most 
>>>>>> cases. I mentioned signUntrusted algorithm so that you can 
>>>>>> discover (from the corresponding sslproxy_cert_sign documentation) 
>>>>>> which CA/certificate Squid uses in which SslBump use case. Triage 
>>>>>> is often easier if folks share the same working theory, and my 
>>>>>> current working theory suggests that we are looking at a (default) 
>>>>>> signUntrusted use case.
>>>>>>
>>>>>> The solution here probably does _not_ involve changing 
>>>>>> sslproxy_cert_sign configuration, but, to make progress, I need 
>>>>>> more info to confirm this working theory and describe next steps.
>>>>>>
>>>>>>
>>>>>>> Yes I am using SSL bump with this configuration..
>>>>>>
>>>>>> Noted, thank you.
>>>>>>
>>>>>>
>>>>>>> So would I use this directive
>>>>>>
>>>>>> I do not recommend changing your configuration at this time. I 
>>>>>> recommend rereading my earlier recommendation and following that 
>>>>>> instead: "As the next step in triage, I recommend determining what 
>>>>>> that CA is in these cases (e.g., by capturing raw TLS packets and 
>>>>>> matching them with connection information from A000417 error 
>>>>>> messages in cache.log or %err_detail in access.log)."
>>>>>>
>>>>>>
>>>>>> HTH,
>>>>>>
>>>>>> Alex.
>>>>>>
>>>>>>
>>>>>>>> On Jul 4, 2024, at 09:56, Alex Rousskov wrote:
>>>>>>>>
>>>>>>>> On 2024-07-04 12:11, Jonathan Lee wrote:
>>>>>>>>> failure while accepting a TLS connection on conn5887 
>>>>>>>>> local=192.168.1.1:3128
>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417
>>>>>>>>
>>>>>>>> A000417 is an "unknown CA" alert sent by client to Squid while 
>>>>>>>> the client is trying to establish a TLS connection to/through 
>>>>>>>> Squid. The client does not trust the Certificate Authority that 
>>>>>>>> signed the certificate that was used for that TLS connection.
>>>>>>>>
>>>>>>>> As the next step in triage, I recommend determining what that CA 
>>>>>>>> is in these cases (e.g., by capturing raw TLS packets and 
>>>>>>>> matching them with connection information from A000417 error 
>>>>>>>> messages in cache.log or %err_detail in access.log).
>>>>>>>>
>>>>>>>> If you use SslBump for port 3128 traffic, then one of the 
>>>>>>>> possibilities here is that Squid is using an unknown-to-client 
>>>>>>>> CA to report an origin server that Squid itself does not trust 
>>>>>>>> (see signUntrusted in squid.conf.documented). In those cases, 
>>>>>>>> logging a level-1 ERROR is a Squid bug because that 
>>>>>>>> expected/desirable outcome should be treated as success (and a 
>>>>>>>> successful TLS accept treated as an error!).
>>>>>>>>
>>>>>>>>
>>>>>>>> HTH,
>>>>>>>>
>>>>>>>> Alex.
>>>>>>
>>>>>>
>>>>>>>>> Is my main concern however I use the squid guard URL blocker
>>>>>>>>> Sent from my iPhone
>>>>>>>>>> On Jul 4, 2024, at 07:41, Alex Rousskov 
>>>>>>>>>> <rousskov at measurement-factory.com> wrote:
>>>>>>>>>>
>>>>>>>>>> ?On 2024-07-03 13:56, Jonathan Lee wrote:
>>>>>>>>>>> Hello fellow Squid users does anyone know how to fix this issue?
>>>>>>>>>>
>>>>>>>>>> I counted about eight different "issues" in your cache.log 
>>>>>>>>>> sample. Most of them are probably independent. I recommend 
>>>>>>>>>> that you explicitly pick _one_, search mailing list archives 
>>>>>>>>>> for previous discussions about it, and then provide as many 
>>>>>>>>>> details about it as you can (e.g., what traffic causes it 
>>>>>>>>>> and/or matching access.log records).
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> HTH,
>>>>>>>>>>
>>>>>>>>>> Alex.
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>> Squid - Cache Logs
>>>>>>>>>>> Date-Time ? ?Message
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 03.07.2024 10:54:34 ? ?kick abandoning 
>>>>>>>>>>> conn7853?local=192.168.1.1:3128 remote=192.168.1.5:49710 FD 
>>>>>>>>>>> 89 flags=1
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 03.07.2024 10:54:29 ? ?kick abandoning 
>>>>>>>>>>> conn7844?local=192.168.1.1:3128 remote=192.168.1.5:49702 FD 
>>>>>>>>>>> 81 flags=1
>>>>>>>>>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn7648 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49672 FD 44 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn7647 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49670 FD 43 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:54:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn7646 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49668 FD 34 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:53:04 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn7367 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49627 FD 22 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:52:47 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn7345 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49618 FD 31 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:52:38 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn7340 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49616 FD 45 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:52:34 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn7316 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49609 FD 45 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 03.07.2024 10:51:55 ? ?WARNING: Error Pages Missing Language: 
>>>>>>>>>>> en-us
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 03.07.2024 10:51:55 ? ?ERROR: loading file 
>>>>>>>>>>> 9;/usr/local/etc/squid/errors/en-us/ERR_ZERO_SIZE_OBJECT': 
>>>>>>>>>>> (2) No such?file or directory
>>>>>>>>>>> 03.07.2024 10:51:44 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn7102 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49574 FD 34 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:51:28 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn7071 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49568 FD 92 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:50:29 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn6944 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49534 FD 101 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:49:54 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn6866 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49519 FD 31 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:49:38 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn6809 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49503 FD 31 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 03.07.2024 10:49:32 ? ?ERROR: system call failure while 
>>>>>>>>>>> accepting a TLS connection on conn6794 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49496 FD 19 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_IO_ERR=5+errno=54
>>>>>>>>>>> 03.07.2024 10:49:24 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn6776 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49481 FD 137 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:48:49 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn6440 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49424 FD 16 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:48:49 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn6445 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49426 FD 34 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:48:22 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn6035 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49355 FD 226 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn5887 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49318 FD 33 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn5875 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49312 FD 216 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:48:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn5876 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49314 FD 217 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:47:57 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn5815 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49297 FD 201 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:47:54 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn5760 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49289 FD 195 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:47:52 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn5717 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49284 FD 195 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:47:50 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn5552 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:49268 FD 142 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 03.07.2024 10:47:34 ? ?kick abandoning 
>>>>>>>>>>> conn5254?local=192.168.1.1:3128 remote=192.168.1.5:49209 FD 
>>>>>>>>>>> 100 flags=1
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 03.07.2024 10:47:21 ? ?kick abandoning 
>>>>>>>>>>> conn5022?local=192.168.1.1:3128 remote=192.168.1.5:49167 FD 
>>>>>>>>>>> 37 flags=1
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 03.07.2024 10:47:21 ? ?kick abandoning 
>>>>>>>>>>> conn5020?local=192.168.1.1:3128 remote=192.168.1.5:49165 FD 
>>>>>>>>>>> 36 flags=1
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 03.07.2024 10:42:22 ? ?WARNING: Forwarding loop?detected for:
>>>>>>>>>>> 03.07.2024 10:40:08 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn4955 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:52339 FD 98 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 03.07.2024 10:39:52 ? ?kick abandoning 
>>>>>>>>>>> conn4927?local=192.168.1.1:3128 remote=192.168.1.5:52331 FD 
>>>>>>>>>>> 105 flags=1
>>>>>>>>>>> 03.07.2024 10:39:09 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn4846 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:52314 FD 19 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:38:14 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn4650 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:52274 FD 35 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000418+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:38:08 ? ?ERROR: failure while accepting a TLS 
>>>>>>>>>>> connection on conn4645 local=192.168.1.1:3128 
>>>>>>>>>>> remote=192.168.1.5:52272 FD 35 flags=1: 
>>>>>>>>>>> SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
>>>>>>>>>>> 03.07.2024 10:38:04 ? ?ERROR: Unsupported TLS option 
>>>>>>>>>>> SINGLE_ECDH_USE
>>>>>>>>>>> 03.07.2024 10:38:04 ? ?ERROR: Unsupported TLS option 
>>>>>>>>>>> SINGLE_DH_USE
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> 31.12.1969 16:00:00
>>>>>>>>>>> _______________________________________________
>>>>>>>>>>> squid-users mailing list
>>>>>>>>>>> squid-users at lists.squid-cache.org
>>>>>>>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>>>>>>>
>>>>>>>>
>>>>>>
>>>>>
>>>>
>>>
>>
> 



From rousskov at measurement-factory.com  Mon Jul  8 16:15:38 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 8 Jul 2024 12:15:38 -0400
Subject: [squid-users] Squid 6.6 kick abandoning connections
In-Reply-To: <D1191274-D08F-4F03-A353-535A3679516D@gmail.com>
References: <D1191274-D08F-4F03-A353-535A3679516D@gmail.com>
Message-ID: <4f5375c8-75d6-413f-90fe-7f3fd94647d3@measurement-factory.com>

On 2024-07-05 21:07, Jonathan Lee wrote:

> I am using Bump with certificates installed on devices does anyone know 
> what this error is...
> 
> kick abandoning conn43723 local=192.168.1.1:3128 
> remote=192.168.1.5:52129 FD 178 flags=1


This "kick abandoning" message marks a Squid problem or bug: Squid 
enters a seemingly impossible state. In some (but probably not all) 
cases, the client connection might become stuck (hopefully until some 
timeout closes it). In some (and possibly all) cases, Squid might 
immediately close the connection and nobody gets hurt. Code reporting 
this problem does not know how we got here and what will happen next.

There were several incomplete/unfinished attempts to fix this problem, 
including two different patches posted at Bug 3715. I do not know 
whether either of them is safe and applies to Squid v6. Neither is a 
comprehensive solution.
https://bugs.squid-cache.org/show_bug.cgi?id=3715


> Does anyone know how to fix my last weird error I have with Squid 6.6

I do not know of a good configuration-based workaround. Squid code 
modifications are required to properly address this problem. Other 
errors may trigger this bug, so addressing those other errors may hide 
(and reduce the pressure to fix) this bug. Besides fixing those other 
errors (if any -- I am aware that you have said that there are no other 
errors left, but perhaps you found other problems since then), these 
basic options apply:

https://wiki.squid-cache.org/SquidFaq/AboutSquid#how-to-add-a-new-squid-feature-enhance-of-fix-something

Alex.



From jonathanlee571 at gmail.com  Mon Jul  8 16:31:48 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 8 Jul 2024 09:31:48 -0700
Subject: [squid-users] Squid 6.6 kick abandoning connections
In-Reply-To: <4f5375c8-75d6-413f-90fe-7f3fd94647d3@measurement-factory.com>
References: <4f5375c8-75d6-413f-90fe-7f3fd94647d3@measurement-factory.com>
Message-ID: <0F6548E6-C076-42B4-AFE0-062C3621F1F3@gmail.com>

I can confirm I have no ipv6 our isp is ipv4 only and I have IPv6 disabled on the firewall and with layer 2 and 3 traffic 
Sent from my iPhone

> On Jul 8, 2024, at 09:15, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> ?On 2024-07-05 21:07, Jonathan Lee wrote:
> 
>> I am using Bump with certificates installed on devices does anyone know what this error is...
>> kick abandoning conn43723 local=192.168.1.1:3128 remote=192.168.1.5:52129 FD 178 flags=1
> 
> 
> This "kick abandoning" message marks a Squid problem or bug: Squid enters a seemingly impossible state. In some (but probably not all) cases, the client connection might become stuck (hopefully until some timeout closes it). In some (and possibly all) cases, Squid might immediately close the connection and nobody gets hurt. Code reporting this problem does not know how we got here and what will happen next.
> 
> There were several incomplete/unfinished attempts to fix this problem, including two different patches posted at Bug 3715. I do not know whether either of them is safe and applies to Squid v6. Neither is a comprehensive solution.
> https://bugs.squid-cache.org/show_bug.cgi?id=3715
> 
> 
>> Does anyone know how to fix my last weird error I have with Squid 6.6
> 
> I do not know of a good configuration-based workaround. Squid code modifications are required to properly address this problem. Other errors may trigger this bug, so addressing those other errors may hide (and reduce the pressure to fix) this bug. Besides fixing those other errors (if any -- I am aware that you have said that there are no other errors left, but perhaps you found other problems since then), these basic options apply:
> 
> https://wiki.squid-cache.org/SquidFaq/AboutSquid#how-to-add-a-new-squid-feature-enhance-of-fix-something
> 
> Alex.
> 


From rousskov at measurement-factory.com  Mon Jul  8 17:40:53 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 8 Jul 2024 13:40:53 -0400
Subject: [squid-users] Squid 6.6 kick abandoning connections
In-Reply-To: <0F6548E6-C076-42B4-AFE0-062C3621F1F3@gmail.com>
References: <4f5375c8-75d6-413f-90fe-7f3fd94647d3@measurement-factory.com>
 <0F6548E6-C076-42B4-AFE0-062C3621F1F3@gmail.com>
Message-ID: <0bb9752d-8d30-433d-86cb-017961302abd@measurement-factory.com>

On 2024-07-08 12:31, Jonathan Lee wrote:

> I can confirm I have no ipv6 our isp is ipv4 only and I have IPv6
> disabled on the firewall and with layer 2 and 3 traffic

This problem is not specific to any IP family/version.

Alex.


>> On Jul 8, 2024, at 09:15, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>
>> ?On 2024-07-05 21:07, Jonathan Lee wrote:
>>
>>> I am using Bump with certificates installed on devices does anyone know what this error is...
>>> kick abandoning conn43723 local=192.168.1.1:3128 remote=192.168.1.5:52129 FD 178 flags=1
>>
>>
>> This "kick abandoning" message marks a Squid problem or bug: Squid enters a seemingly impossible state. In some (but probably not all) cases, the client connection might become stuck (hopefully until some timeout closes it). In some (and possibly all) cases, Squid might immediately close the connection and nobody gets hurt. Code reporting this problem does not know how we got here and what will happen next.
>>
>> There were several incomplete/unfinished attempts to fix this problem, including two different patches posted at Bug 3715. I do not know whether either of them is safe and applies to Squid v6. Neither is a comprehensive solution.
>> https://bugs.squid-cache.org/show_bug.cgi?id=3715
>>
>>
>>> Does anyone know how to fix my last weird error I have with Squid 6.6
>>
>> I do not know of a good configuration-based workaround. Squid code modifications are required to properly address this problem. Other errors may trigger this bug, so addressing those other errors may hide (and reduce the pressure to fix) this bug. Besides fixing those other errors (if any -- I am aware that you have said that there are no other errors left, but perhaps you found other problems since then), these basic options apply:
>>
>> https://wiki.squid-cache.org/SquidFaq/AboutSquid#how-to-add-a-new-squid-feature-enhance-of-fix-something
>>
>> Alex.
>>



From squid3 at treenet.co.nz  Mon Jul  8 17:44:25 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 9 Jul 2024 05:44:25 +1200
Subject: [squid-users] ICMP and QUIC
In-Reply-To: <D20611C4-07CD-4141-AB13-39F184D19B4C@gmail.com>
References: <D2139A5D-AE5E-404E-A0B3-AF22DFA95665@gmail.com>
 <5E1F18CC-07BA-407D-8A4D-0DB261FAD355@gmail.com>
 <D20611C4-07CD-4141-AB13-39F184D19B4C@gmail.com>
Message-ID: <ed829f5f-63bf-4ea8-bea6-a000fb20cdab@treenet.co.nz>

On 8/07/24 16:42, Jonathan Lee wrote:
> Does anyone use this directive for QUIC in the mean time? what?s weird 
> is that IP address is Apple when Facebook is running
> 
> on_unsupported_protocol
> 

This directive is only relevant to protocols Squid receives over TCP 
connections. For SSL-Bumped CONNECT tunnels or intercepted ports.

Squid does not support QUIC at all yet.

> 
>> On Jul 7, 2024, at 21:24, Jonathan Lee wrote:
>>
>> I have just found... YEAH!!! has anyone tested this? Does Squid 6.6 
>> have it?

>> QUIC foundations for HTTP/3 by yadij ? Pull Request #919 ? 
>> squid-cache/squid <https://github.com/squid-cache/squid/pull/919>
>> github.com <https://github.com/squid-cache/squid/pull/919>

As of this writing, that work is a Draft for design review. It still 
needs a lot of protocol support added before it can be used for more 
than debugging experiments.

HTH
Amos


From jonathanlee571 at gmail.com  Mon Jul  8 21:34:31 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 8 Jul 2024 14:34:31 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <d018d560-acb2-406e-895d-8446759f41e5@treenet.co.nz>
References: <FC75961E-4CB1-480F-A190-9915F0472FA4@gmail.com>
 <DA266AA1-8B27-44EF-B72C-BF7DF6AE3637@gmail.com>
 <d018d560-acb2-406e-895d-8446759f41e5@treenet.co.nz>
Message-ID: <5F898811-4C5D-4477-A6E4-83D456A8790A@gmail.com>

This shows access denied in 6.6 I have a password for cache_manager does that cause any issues with accessing this new mgr directive ?

> On Apr 6, 2024, at 20:18, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 6/04/24 18:48, Jonathan Lee wrote:
>> Correction I can?t access it from the loop back
> 
> From the config in the other "Squid cache questions" thread you are only intercepting traffic on the loopback 127.0.0.1:3128 port. You cannot access it directly on "localhost".
> 
> You do have direct proxy (and thus manager) access via the 192.168.1.1:3128 so this URL should work:
>  http://192.168.1.1:3128/squid-internal-mgr/menu
> 
> 
> .. or substitute the raw-IP for the visible_hostname setting **if** that hostname actually resolves to that IP.
> 
> 
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From jonathanlee571 at gmail.com  Mon Jul  8 23:12:54 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 8 Jul 2024 16:12:54 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <96F3E89F-ED67-491E-BD50-FA5307464FE7@gmail.com>
References: <FC75961E-4CB1-480F-A190-9915F0472FA4@gmail.com>
 <DA266AA1-8B27-44EF-B72C-BF7DF6AE3637@gmail.com>
 <d018d560-acb2-406e-895d-8446759f41e5@treenet.co.nz>
 <5F898811-4C5D-4477-A6E4-83D456A8790A@gmail.com>
 <96F3E89F-ED67-491E-BD50-FA5307464FE7@gmail.com>
Message-ID: <9BF3DE5B-149B-475D-940E-8F21118C7E8E@gmail.com>

Also 
squidclient -h 192.168.1.1:3128 mgr:info at PASSWORD
squidclient -h 1287.0.0.1 mgr:info at PASSWORD

Gives the following error

Embedding a password in a cache manager command requires providing a username with -U: mgr:info at PASSWORDHERE


> On Jul 8, 2024, at 15:13, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> cachemgr_passwd disable offline_toggle reconfigure shutdown
> cachemgr_passwd REDACTED all
> 
> http_access allow CONNECT wuCONNECT localnet
> http_access allow CONNECT wuCONNECT localhost
> http_access allow windowsupdate localnet
> http_access allow windowsupdate localhost
> 
> http_access allow localhost manager with or without
> http_access allow 192.168.1.1:3128 manager  with or without
> http_access allow lee.family.home.arpa:3128 manager with or without
> http_access deny manager
> 
> I have tried all of this also
> 
> is cache_manager.cc <http://cache_manager.cc/> missing? does anyone know the filesystem path for this squid-internals-mgr?
> 
> <Screenshot 2024-07-08 at 15.06.40.png>
> 
> Miss 403 shows for them I have http_access localhost
> 
>> On Jul 8, 2024, at 14:34, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> This shows access denied in 6.6 I have a password for cache_manager does that cause any issues with accessing this new mgr directive ?
>> 
>>> On Apr 6, 2024, at 20:18, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>> 
>>> On 6/04/24 18:48, Jonathan Lee wrote:
>>>> Correction I can?t access it from the loop back
>>> 
>>> From the config in the other "Squid cache questions" thread you are only intercepting traffic on the loopback 127.0.0.1:3128 port. You cannot access it directly on "localhost".
>>> 
>>> You do have direct proxy (and thus manager) access via the 192.168.1.1:3128 so this URL should work:
>>> http://192.168.1.1:3128/squid-internal-mgr/menu
>>> 
>>> 
>>> .. or substitute the raw-IP for the visible_hostname setting **if** that hostname actually resolves to that IP.
>>> 
>>> 
>>> HTH
>>> Amos
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240708/047007d1/attachment.htm>

From stu.lists at spacehopper.org  Tue Jul  9 12:40:07 2024
From: stu.lists at spacehopper.org (Stuart Henderson)
Date: Tue, 9 Jul 2024 12:40:07 -0000 (UTC)
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
References: <FC75961E-4CB1-480F-A190-9915F0472FA4@gmail.com>
 <DA266AA1-8B27-44EF-B72C-BF7DF6AE3637@gmail.com>
 <d018d560-acb2-406e-895d-8446759f41e5@treenet.co.nz>
 <5F898811-4C5D-4477-A6E4-83D456A8790A@gmail.com>
 <96F3E89F-ED67-491E-BD50-FA5307464FE7@gmail.com>
 <9BF3DE5B-149B-475D-940E-8F21118C7E8E@gmail.com>
Message-ID: <slrnv8qbt7.h8a.stu.lists@naiad.spacehopper.org>

On 2024-07-08, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>
> Also=20
> squidclient -h 192.168.1.1:3128 mgr:info at PASSWORD
> squidclient -h 1287.0.0.1 mgr:info at PASSWORD
>
> Gives the following error
>
> Embedding a password in a cache manager command requires providing a =
> username with -U: mgr:info at PASSWORDHERE

Try "/squid-internal-mgr/info" where you have "mgr:info".




From jonathanlee571 at gmail.com  Tue Jul  9 16:12:38 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Tue, 9 Jul 2024 09:12:38 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <slrnv8qbt7.h8a.stu.lists@naiad.spacehopper.org>
References: <slrnv8qbt7.h8a.stu.lists@naiad.spacehopper.org>
Message-ID: <E2D620E0-64BE-4454-94B3-99F0167FCBFC@gmail.com>

Thanks do I still append the cache manager password ?
Sent from my iPhone

> On Jul 9, 2024, at 05:47, Stuart Henderson <stu.lists at spacehopper.org> wrote:
> 
> ?On 2024-07-08, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> Also=20
>> squidclient -h 192.168.1.1:3128 mgr:info at PASSWORD
>> squidclient -h 1287.0.0.1 mgr:info at PASSWORD
>> 
>> Gives the following error
>> 
>> Embedding a password in a cache manager command requires providing a =
>> username with -U: mgr:info at PASSWORDHERE
> 
> Try "/squid-internal-mgr/info" where you have "mgr:info".
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From c.fiehe at eurodata.de  Tue Jul  9 22:25:30 2024
From: c.fiehe at eurodata.de (Fiehe, Christoph)
Date: Tue, 9 Jul 2024 22:25:30 +0000
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
Message-ID: <cbc168a71735481aaddc99c6cba92155@eurodata.de>

Hallo,

I hope that somebody has an idea, what I am doing wrong. I try to build a generic package proxy with Squid and need the feature to rewrite (not redirect) a HTTP request to a package repository transparently to a HTTPS-based package source. I was able to get Jesred working and defined the following rewrite rule:

regex ^http:\/\/download\.docker\.com(.*)$ https://download.docker.com\1

I had to use a parent upstream proxy. In my test case the rule gets applied successfully:

1720558404.106 10.2.59.102/molecule-ubuntu-jammy.lx.mycompany.de http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/linux/ubuntu/dists/jammy/InRelease] https://download.docker.com/linux/ubuntu/dists/jammy/InRelease 2

I have validated that the returned URL is correct and that the resource is accessible via my upstream proxy.

But at the very end, the client receives a 503 error code. I have set "debug_options ALL,3" and this gives the log:

[...]
2024/07/09 23:35:40.115 kid1| 11,2| client_side.cc(1333) parseHttpRequest: HTTP Client REQUEST:
---------
HEAD http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/linux/ubuntu/dists/jammy/InRelease] HTTP/1.1
Host: download.docker.com
User-Agent: curl/7.81.0
Accept: */*
Proxy-Connection: Keep-Alive


----------
2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(1364) parseHttpRequest: complete request received. prefix_sz = 174, request-line-size=77, mime-header-size=97, mime header block:
Host: download.docker.com
User-Agent: curl/7.81.0
Accept: */*
Proxy-Connection: Keep-Alive


----------
2024/07/09 23:35:40.115 kid1| 87,3| clientStream.cc(139) clientStreamInsertHead: clientStreamInsertHead: Inserted node 0x5c3ba4154308 with data 0x5c3ba4152950 after head
2024/07/09 23:35:40.115 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn9 local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1 timeout 86400
2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(1767) add: 0x5c3ba41518e0*3 to 0/0
2024/07/09 23:35:40.115 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x5c3ba41501f0 add request 1 0x5c3ba41518e0*4
2024/07/09 23:35:40.115 kid1| 23,3| Uri.cc(446) parse: Split URL 'http://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[http://download.docker.com/linux/ubuntu/dists/jammy/InRelease'] into proto='http', host='download.docker.com', port='80', path='/linux/ubuntu/dists/jammy/InRelease'
2024/07/09 23:35:40.115 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(702) clientSetKeepaliveFlag: http_ver = HTTP/1.1
2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(703) clientSetKeepaliveFlag: method = HEAD
2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(122) ClientRequestContext: ClientRequestContext constructed, this=0x5c3ba4154e78
2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1708) doCallouts: Doing calloutContext->hostHeaderVerify()
2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(606) hostHeaderVerify: validate host=download.docker.com, port=0, portStr=NULL
2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(620) hostHeaderVerify: validate skipped.
2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1715) doCallouts: Doing calloutContext->clientAccessCheck()
2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba41552d8 checking slow rules
2024/07/09 23:35:40.115 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.102:56466' found
2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: http_access#1 = 1
2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: http_access = 1
2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba41552d8 answer ALLOWED for match
2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(162) checkCallback: ACLChecklist::checkCallback: 0x5c3ba41552d8 answer=ALLOWED
2024/07/09 23:35:40.115 kid1| 85,2| client_side_request.cc(714) clientAccessCheckDone: The request HEAD http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/linux/ubuntu/dists/jammy/InRelease] is ALLOWED; last ACL checked: all
2024/07/09 23:35:40.115 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1735) doCallouts: Doing calloutContext->clientRedirectStart()
2024/07/09 23:35:40.115 kid1| 78,3| dns_internal.cc(1836) idnsPTRLookup: idnsPTRLookup: buf is 42 bytes for 10.2.59.102, id = 0x8d95
2024/07/09 23:35:40.115 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
2024/07/09 23:35:40 kid1| Starting new redirector helpers...
current master transaction: master54
2024/07/09 23:35:40 kid1| helperOpenServers: Starting 1/3 'jesred' processes
current master transaction: master54
2024/07/09 23:35:40.115 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 17 IPC UNIX STREAM Parent
2024/07/09 23:35:40.115 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 19 IPC UNIX STREAM Parent
2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(212) ipcCreate: ipcCreate: prfd FD 17
2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(213) ipcCreate: ipcCreate: pwfd FD 17
2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(214) ipcCreate: ipcCreate: crfd FD 19
2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(215) ipcCreate: ipcCreate: cwfd FD 19
2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(850) _comm_close: start closing FD 19 by ipc.cc:271
2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(586) commUnsetFdTimeout: Remove timeout for FD 19
2024/07/09 23:35:40.116 kid1| 21,3| tools.cc(561) leave_suid: leave_suid: PID 503746 called
2024/07/09 23:35:40.116 kid1| 21,3| tools.cc(651) no_suid: no_suid: PID 503746 giving up root privileges forever
2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(586) commUnsetFdTimeout: Remove timeout for FD 17
2024/07/09 23:35:40.117 kid1| 84,3| helper.cc(1310) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is fully loaded!
2024/07/09 23:35:40.117 kid1| 51,3| fd.cc(93) fd_close: fd_close FD 19 IPC UNIX STREAM Parent
2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting with FD 11
2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11: received 92 bytes from 127.0.0.53:53
2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply: QID 0x8d95, 1 answers
2024/07/09 23:35:40.117 kid1| 35,3| fqdncache.cc(336) fqdncacheParse: fqdncacheParse: 1 answers for '10.2.59.102'
2024/07/09 23:35:40.117 kid1| 5,3| IoCallback.cc(112) finish: called for conn11 local=[::] remote=[::] FD 17 flags=1 (0, 0)
2024/07/09 23:35:40.125 kid1| 5,3| Read.cc(148) HandleRead: FD 17, size 32767, retval 80, errno 0
2024/07/09 23:35:40.125 kid1| 5,3| IoCallback.cc(112) finish: called for conn10 local=[::] remote=[::] FD 17 flags=1 (0, 0)
2024/07/09 23:35:40.125 kid1| 84,3| helper.cc(1022) helperHandleRead: helperHandleRead: end of reply found
2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(41) finalize: Parsing helper buffer
2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(59) finalize: Buff length is larger than 2
2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(63) finalize: helper Result = OK
2024/07/09 23:35:40.125 kid1| 23,3| Uri.cc(446) parse: Split URL 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'] into proto='https', host='download.docker.com', port='443', path='/linux/ubuntu/dists/jammy/InRelease'
2024/07/09 23:35:40.125 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
2024/07/09 23:35:40.125 kid1| 61,2| client_side_request.cc(1235) clientRedirectDone: URL-rewriter diverts URL from http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/linux/ubuntu/dists/jammy/InRelease] to https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
2024/07/09 23:35:40.125 kid1| 83,3| client_side_request.cc(1743) doCallouts: Doing calloutContext->clientAccessCheck2()
2024/07/09 23:35:40.125 kid1| 85,2| client_side_request.cc(692) clientAccessCheck2: No adapted_http_access configuration. default: ALLOW
2024/07/09 23:35:40.125 kid1| 85,2| client_side_request.cc(714) clientAccessCheckDone: The request HEAD https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease] is ALLOWED; last ACL checked: all
2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1761) doCallouts: Doing clientInterpretRequestHeaders()
2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1770) doCallouts: Doing calloutContext->checkNoCache()
2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba41552d8 checking slow rules
2024/07/09 23:35:40.126 kid1| 28,3| RegexData.cc(50) match: checking 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease']
2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: no_cache = 0
2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache#1 = 0
2024/07/09 23:35:40.126 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.102:56466' found
2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache#2 = 1
2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache = 1
2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba41552d8 answer ALLOWED for match
2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(162) checkCallback: ACLChecklist::checkCallback: 0x5c3ba41552d8 answer=ALLOWED
2024/07/09 23:35:40.126 kid1| 85,3| client_side_request.cc(116) ~ClientRequestContext: ClientRequestContext destructed, this=0x5c3ba4154e78
2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1855) doCallouts: calling processRequest()
2024/07/09 23:35:40.126 kid1| 87,3| clientStream.cc(178) clientStreamRead: clientStreamRead: Calling 1 with cbdata 0x5c3ba4153e70 from node 0x5c3ba4154308
2024/07/09 23:35:40.126 kid1| 73,3| HttpRequest.cc(742) storeId: sent back effectiveRequestUrl: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
2024/07/09 23:35:40.126 kid1| 20,3| Controller.cc(429) peek: DE850794EBC405A27A7718F51795E32A
2024/07/09 23:35:40.126 kid1| 73,3| HttpRequest.cc(742) storeId: sent back effectiveRequestUrl: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
2024/07/09 23:35:40.126 kid1| 20,3| Controller.cc(429) peek: D3522EE27FB0ED7004DD594AF7674667
2024/07/09 23:35:40.126 kid1| 85,3| client_side_reply.cc(1523) identifyFoundObject: StoreEntry is NULL - MISS
2024/07/09 23:35:40.126 kid1| 20,3| store.cc(730) storeCreatePureEntry: storeCreateEntry: 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease']
2024/07/09 23:35:40.126 kid1| 20,3| MemObject.cc(99) MemObject: MemObject constructed, this=0x5c3ba416ef10
2024/07/09 23:35:40.126 kid1| 88,3| MemObject.cc(82) setUris: 0x5c3ba416ef10 storeId: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: storeCreateEntry locked key [null_store_key] e:=V/0x5c3ba416ee90*1
2024/07/09 23:35:40.126 kid1| 20,3| store.cc(536) setPrivateKey: 00 e:=V/0x5c3ba416ee90*1
2024/07/09 23:35:40.126 kid1| 20,3| store.cc(412) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x5c3ba416ee90*1 key '020000000000000061AF070001000000'
2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: store_client locked key 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*2
2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(243) copy: store_client::copy: 020000000000000061AF070001000000, from 0, for length 4096, cb 1, cbdata 0x5c3ba4152dd8
2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: store_client::copy locked key 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(343) storeClientCopy2: storeClientCopy2: 020000000000000061AF070001000000
2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(390) doCopy: store_client::doCopy: Waiting for more
2024/07/09 23:35:40.126 kid1| 20,3| store.cc(457) unlock: store_client::copy unlocking key 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(373) Start: 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease']
2024/07/09 23:35:40.126 kid1| 17,2| FwdState.cc(133) FwdState: Forwarding client request conn9 local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1, url=https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: FwdState locked key 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(140) FwdState: FwdState constructed, this=0x5c3ba416fa18
2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(309) peerSelect: e:=IV/0x5c3ba416ee90*3 https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: peerSelect locked key 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*4
2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(612) selectMore: HEAD download.docker.com
2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(626) selectMore: direct = DIRECT_UNKNOWN (never_direct to be checked)
2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba4170638 checking slow rules
2024/07/09 23:35:40.126 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.102:56466' found
2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: never_direct#1 = 1
2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: never_direct = 1
2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba4170638 answer ALLOWED for match
2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(162) checkCallback: ACLChecklist::checkCallback: 0x5c3ba4170638 answer=ALLOWED
2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(345) checkNeverDirectDone: ALLOWED
2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(351) checkNeverDirectDone: direct = DIRECT_NO (never_direct allow)
2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(612) selectMore: HEAD download.docker.com
2024/07/09 23:35:40.126 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname: ipcache_gethostbyname: 'download.docker.com', flags=0
2024/07/09 23:35:40.126 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(286) peerSelectIcpPing: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(283) neighborsCount: neighborsCount: 0
2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(297) peerSelectIcpPing: counted 0 neighbors
2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(833) selectSomeParent: HEAD download.docker.com
2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(350) getRoundRobinParent: returning [nil]
2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(403) getWeightedRoundRobinParent: returning [nil]
2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(309) getFirstUpParent: returning 212.89.128.96
2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1102) addSelection: adding FIRSTUP_PARENT/212.89.128.96
2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1095) addSelection: skipping ANY_OLD_PARENT/212.89.128.96; have FIRSTUP_PARENT/212.89.128.96
2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(493) getDefaultParent: returning 212.89.128.96
2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1095) addSelection: skipping DEFAULT_PARENT/212.89.128.96; have FIRSTUP_PARENT/212.89.128.96
2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(460) resolveSelected: Find IP destination for: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'] via 212.89.128.96
2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector1 found conn12 local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1, destination #1 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = ALLOWED
2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(610) noteDestination: conn12 local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1
2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(1124) connectStart: 1+ paths to https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(479) resolveSelected: PeerSelector1 found all 1 destinations for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(480) resolveSelected: always_direct = DENIED
2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(481) resolveSelected: never_direct = ALLOWED
2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(482) resolveSelected: timedout = 0
2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(241) ~PeerSelector: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
2024/07/09 23:35:40.126 kid1| 20,3| store.cc(457) unlock: peerSelect unlocking key 020000000000000061AF070001000000 e:=p2IV/0x5c3ba416ee90*4
2024/07/09 23:35:40.126 kid1| 48,3| pconn.cc(474) popStored: lookup for key {212.89.128.96:3128} failed.
2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(1568) GetMarkingsToServer: from 0.0.0.0 tos 0 netfilter mark 0
2024/07/09 23:35:40.126 kid1| 5,3| ConnOpener.cc(42) ConnOpener: will connect to conn14 local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1 with 30 timeout
2024/07/09 23:35:40.126 kid1| 50,3| comm.cc(378) comm_openex: comm_openex: Attempt open socket for: 0.0.0.0
2024/07/09 23:35:40.126 kid1| 50,3| comm.cc(420) comm_openex: comm_openex: Opened socket conn15 local=0.0.0.0 remote=[::] FD 19 flags=1 : family=2, type=1, protocol=6
2024/07/09 23:35:40.126 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 19
2024/07/09 23:35:40.126 kid1| 5,3| ConnOpener.cc(312) createFd: conn14 local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1 will timeout in 30
2024/07/09 23:35:40.127 kid1| 17,3| FwdState.cc(1197) dispatch: conn9 local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1: Fetching HEAD https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
2024/07/09 23:35:40.127 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
2024/07/09 23:35:40.127 kid1| 78,3| dns_internal.cc(1793) idnsALookup: idnsALookup: buf is 37 bytes for download.docker.com, id = 0xe779
2024/07/09 23:35:40.127 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
2024/07/09 23:35:40.127 kid1| 78,3| dns_internal.cc(1729) idnsSendSlaveAAAAQuery: buf is 37 bytes for download.docker.com, id = 0x8aee
2024/07/09 23:35:40.127 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
2024/07/09 23:35:40.127 kid1| 11,3| http.cc(2516) httpStart: HEAD https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
2024/07/09 23:35:40.127 kid1| 20,3| store.cc(434) lock: Client locked key 020000000000000061AF070001000000 e:=p2IV/0x5c3ba416ee90*4
2024/07/09 23:35:40.127 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn14 local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 timeout 86400
2024/07/09 23:35:40.127 kid1| 22,3| refresh.cc(636) getMaxAge: getMaxAge: 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease']
2024/07/09 23:35:40.127 kid1| 11,2| http.cc(2472) sendRequest: HTTP Server conn14 local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1
2024/07/09 23:35:40.127 kid1| 11,2| http.cc(2473) sendRequest: HTTP Server REQUEST:
---------
HEAD https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease] HTTP/1.1
Host: download.docker.com
User-Agent: curl/7.81.0
Accept: */*
Via: 1.1 pkg-proxy (squid/6.6)
X-Forwarded-For: 10.2.59.102
Cache-Control: max-age=0
Connection: keep-alive


----------
2024/07/09 23:35:40.127 kid1| 5,3| IoCallback.cc(112) finish: called for conn14 local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 (0, 0)
2024/07/09 23:35:40.127 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn14 local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 timeout 900
2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting with FD 11
2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11: received 304 bytes from 127.0.0.53:53
2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply: QID 0x8aee, 9 answers
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(480) ipcacheParse: 9 answers for download.docker.com
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #1 [2600:9000:2490:6c00:3:db06:4200:93a1]
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #2 [2600:9000:2490:a600:3:db06:4200:93a1]
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #3 [2600:9000:2490:9c00:3:db06:4200:93a1]
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #4 [2600:9000:2490:6000:3:db06:4200:93a1]
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #5 [2600:9000:2490:c00:3:db06:4200:93a1]
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #6 [2600:9000:2490:5200:3:db06:4200:93a1]
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #7 [2600:9000:2490:9a00:3:db06:4200:93a1]
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #8 [2600:9000:2490:2c00:3:db06:4200:93a1]
2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting with FD 11
2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11: received 144 bytes from 127.0.0.53:53
2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply: QID 0xe779, 5 answers
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(480) ipcacheParse: 5 answers for download.docker.com
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #9 108.138.7.33
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #10 108.138.7.18
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #11 108.138.7.88
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #12 108.138.7.48
2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(586) ipcacheHandleReply: done with download.docker.com: [2600:9000:2490:6c00:3:db06:4200:93a1] #1/12-0
2024/07/09 23:35:40.137 kid1| 38,3| net_db.cc(337) netdbSendPing: netdbSendPing: pinging download.docker.com
2024/07/09 23:35:40.137 kid1| 37,2| IcmpSquid.cc(88) SendEcho: to [2600:9000:2490:6c00:3:db06:4200:93a1], opcode 3, len 19
2024/07/09 23:35:40.137 pinger| 42,2| IcmpPinger.cc(198) Recv: Pass [2600:9000:2490:6c00:3:db06:4200:93a1] off to ICMPv6 module.
2024/07/09 23:35:40 pinger| SendEcho ERROR: sending to ICMPv6 packet to [2600:9000:2490:6c00:3:db06:4200:93a1]: (101) Network is unreachable
2024/07/09 23:35:40.138 pinger| 42,2| Icmp.cc(90) Log: pingerLog: 1720560940.138021 [2600:9000:2490:6c00:3:db06:4200:93a1] 0
2024/07/09 23:35:40.323 kid1| 5,3| IoCallback.cc(112) finish: called for conn14 local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 (0, 0)
2024/07/09 23:35:40.324 kid1| 5,3| Read.cc(93) ReadNow: conn14 local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1, size 65536, retval 348, errno 0
2024/07/09 23:35:40.324 kid1| 11,3| http.cc(649) processReplyHeader: processReplyHeader: key '020000000000000061AF070001000000'
2024/07/09 23:35:40.324 kid1| 11,2| http.cc(696) processReplyHeader: HTTP Server conn14 local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1
2024/07/09 23:35:40.324 kid1| 11,2| http.cc(697) processReplyHeader: HTTP Server RESPONSE:
---------
HTTP/1.1 503 Service Unavailable
Server: squid/4.10
Mime-Version: 1.0
Date: Tue, 09 Jul 2024 21:35:40 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3879
X-Squid-Error: ERR_SECURE_CONNECT_FAIL 71
X-Cache: MISS from proxy-srv2
X-Cache-Lookup: MISS from proxy-srv2:3128
Via: 1.1 proxy-srv2 (squid/4.10)
Connection: keep-alive

----------
2024/07/09 23:35:40.324 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
2024/07/09 23:35:40.324 kid1| 20,3| store.cc(1693) replaceHttpReply: StoreEntry::replaceHttpReply: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
2024/07/09 23:35:40.324 kid1| 11,3| http.cc(949) haveParsedReplyHeaders: HTTP CODE: 503

Has anybody an idea what I can do to solve the issue?

This is my configuration borrowed from squid-deb-proxy:

# this file contains private networks (10.0.0.0/8, 172.16.0.0/12,
# 192.168.0.0/16) by default, you can add/remove additional allowed
# source networks in it to customize it for your setup
acl src_networks src "/etc/squid/acl/src-networks.acl"

# this file contains the archive mirrors by default,
# if you use a different mirror, add it there
acl to_archive_mirrors dstdomain "/etc/squid/acl/archive-mirrors.acl"

# Disable Cache for defined domains
acl no_cache url_regex "/etc/squid/acl/no-cache.acl"

# this contains the package blacklist
acl blockedpkgs urlpath_regex "/etc/squid/pkg-blacklist-regexp.acl"

# default to a different port than stock squid
http_port 8000

# -------------------------------------------------
# settings below probably do not need customization

# user visible name
visible_hostname pkg-proxy

# we need a big cache, some debs are huge
maximum_object_size 512 MB

# use a different dir than stock squid and default to 40G
cache_dir aufs /var/cache/squid 40000 16 256

cache_peer 212.89.128.96 parent 3128 0 no-query default
never_direct allow all

# use different logs
cache_access_log /var/log/squid/access.log
cache_log /var/log/squid/cache.log
cache_store_log /var/log/squid/store.log

# tweaks to speed things up
cache_mem 200 MB
maximum_object_size_in_memory 10240 KB

# pid
pid_filename /var/run/squid.pid

# refresh pattern for debs and udebs
refresh_pattern deb$ 129600 100% 129600
refresh_pattern udeb$ 129600 100% 129600
refresh_pattern tar.gz$ 129600 100% 129600
refresh_pattern tar.xz$ 129600 100% 129600
refresh_pattern tar.bz2$ 129600 100% 129600

# always refresh Packages and Release files
refresh_pattern \/(Packages|Sources)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims
refresh_pattern \/Release(|\.gpg)$ 0 0% 0 refresh-ims
refresh_pattern \/InRelease$ 0 0% 0 refresh-ims
refresh_pattern \/(Translation-.*)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims

# handle meta-release and changelogs.ubuntu.com special
# (fine to have this on debian too)
refresh_pattern changelogs.ubuntu.com\/.* 0 1% 1

# only allow connects to ports for http, https
acl SSL_ports port 443 563
acl Safe_ports port 80
acl Safe_ports port 443 563

# only allow ports we trust
http_access deny !Safe_ports

# do not allow to download from the pkg blacklist
http_access deny blockedpkgs

# allow access only to official archive mirrors
# uncomment the third and fouth line to permit any unlisted domain
http_access deny !to_archive_mirrors

# allow access from our network and localhost
http_access allow src_networks

# And finally deny all other access to this proxy
http_access deny all

# don't cache domains not listed in the mirrors file
# uncomment the third and fourth line to cache any unlisted domains
cache deny no_cache

# And finally cache everything else
cache allow all

url_rewrite_children 3 startup=0 idle=1 concurrency=1
url_rewrite_program /usr/lib/squid/jesred

debug_options ALL,3

Thanks a lot.

Regards,
Christoph


From jonathanlee571 at gmail.com  Tue Jul  9 23:30:16 2024
From: jonathanlee571 at gmail.com (jonathanlee571 at gmail.com)
Date: Tue, 9 Jul 2024 16:30:16 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <slrnv8qbt7.h8a.stu.lists@naiad.spacehopper.org>
References: <FC75961E-4CB1-480F-A190-9915F0472FA4@gmail.com>
 <DA266AA1-8B27-44EF-B72C-BF7DF6AE3637@gmail.com>
 <d018d560-acb2-406e-895d-8446759f41e5@treenet.co.nz>
 <5F898811-4C5D-4477-A6E4-83D456A8790A@gmail.com>
 <96F3E89F-ED67-491E-BD50-FA5307464FE7@gmail.com>
 <9BF3DE5B-149B-475D-940E-8F21118C7E8E@gmail.com>
 <slrnv8qbt7.h8a.stu.lists@naiad.spacehopper.org>
Message-ID: <01d201dad257$f4eab0a0$dec011e0$@gmail.com>

Thanks that also gave the error access denied 

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
Stuart Henderson
Sent: Tuesday, July 9, 2024 5:40 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
access denined

On 2024-07-08, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>
> Also=20
> squidclient -h 192.168.1.1:3128 mgr:info at PASSWORD squidclient -h 
> 1287.0.0.1 mgr:info at PASSWORD
>
> Gives the following error
>
> Embedding a password in a cache manager command requires providing a = 
> username with -U: mgr:info at PASSWORDHERE

Try "/squid-internal-mgr/info" where you have "mgr:info".


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
https://lists.squid-cache.org/listinfo/squid-users



From jonathanlee571 at gmail.com  Wed Jul 10 00:31:18 2024
From: jonathanlee571 at gmail.com (jonathanlee571 at gmail.com)
Date: Tue, 9 Jul 2024 17:31:18 -0700
Subject: [squid-users] Squid 6.6 kick abandoning connections
In-Reply-To: <0bb9752d-8d30-433d-86cb-017961302abd@measurement-factory.com>
References: <4f5375c8-75d6-413f-90fe-7f3fd94647d3@measurement-factory.com>
 <0F6548E6-C076-42B4-AFE0-062C3621F1F3@gmail.com>
 <0bb9752d-8d30-433d-86cb-017961302abd@measurement-factory.com>
Message-ID: <000201dad260$7bfe07b0$73fa1710$@gmail.com>

I found the older patch from 2017 I cant find the path to client_sid_request.cc in the pfsense filesystem 

Does anyone know the path to this file "modified file 'src/client_side_request.cc" so I can test it with the patches application if it doesn?t work no big deal I can just restore it to to prior and or use an older boot environment




kick abandoning [connection]" message in cache.log

This patch call quitAfterError() to force Squid to close the connection after
writing a "Host header forgery" error response  instead of just logging a
[misleading] "kick abandoning [connection]" message in cache.log.

This is a Measurement Factory project

=== modified file 'src/client_side_request.cc'
--- src/client_side_request.cc	2017-02-07 23:11:33 +0000
+++ src/client_side_request.cc	2017-03-31 08:00:01 +0000
@@ -564,40 +564,41 @@
         debugs(85, 3, "SECURITY ALERT: Host header forgery detected on " << http->getConn()->clientConnection <<
                " (" << A << " does not match " << B << ") on URL: " << http->request->effectiveRequestUri());
 
         // NP: it is tempting to use 'flags.noCache' but that is all about READing cache data.
         // The problems here are about WRITE for new cache content, which means flags.cachable
         http->request->flags.cachable = false; // MUST NOT cache (for now)
         // XXX: when we have updated the cache key to base on raw-IP + URI this cacheable limit can go.
         http->request->flags.hierarchical = false; // MUST NOT pass to peers (for now)
         // XXX: when we have sorted out the best way to relay requests properly to peers this hierarchical limit can go.
         http->doCallouts();
         return;
     }
 
     debugs(85, DBG_IMPORTANT, "SECURITY ALERT: Host header forgery detected on " <<
            http->getConn()->clientConnection << " (" << A << " does not match " << B << ")");
     if (const char *ua = http->request->header.getStr(Http::HdrType::USER_AGENT))
         debugs(85, DBG_IMPORTANT, "SECURITY ALERT: By user agent: " << ua);
     debugs(85, DBG_IMPORTANT, "SECURITY ALERT: on URL: " << http->request->effectiveRequestUri());
 
     // IP address validation for Host: failed. reject the connection.
+    http->getConn()->quitAfterError(http->request);
     clientStreamNode *node = (clientStreamNode *)http->client_stream.tail->prev->data;
     clientReplyContext *repContext = dynamic_cast<clientReplyContext *>(node->data.getRaw());
     assert (repContext);
     repContext->setReplyToError(ERR_CONFLICT_HOST, Http::scConflict,
                                 http->request->method, NULL,
                                 http->getConn()->clientConnection->remote,
                                 http->request,
                                 NULL,
 #if USE_AUTH
                                 http->getConn() != NULL && http->getConn()->getAuth() != NULL ?
                                 http->getConn()->getAuth() : http->request->auth_user_request);
 #else
                                 NULL);
 #endif
     node = (clientStreamNode *)http->client_stream.tail->data;
     clientStreamRead(node, http, node->readBuffer);
 }
 
 void
 ClientRequestContext::hostHeaderVerify()



-----Original Message-----
From: Alex Rousskov <rousskov at measurement-factory.com> 
Sent: Monday, July 8, 2024 10:41 AM
To: squid-users <squid-users at lists.squid-cache.org>
Cc: Jonathan Lee <jonathanlee571 at gmail.com>
Subject: Re: [squid-users] Squid 6.6 kick abandoning connections

On 2024-07-08 12:31, Jonathan Lee wrote:

> I can confirm I have no ipv6 our isp is ipv4 only and I have IPv6 
> disabled on the firewall and with layer 2 and 3 traffic

This problem is not specific to any IP family/version.

Alex.


>> On Jul 8, 2024, at 09:15, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>
>> ?On 2024-07-05 21:07, Jonathan Lee wrote:
>>
>>> I am using Bump with certificates installed on devices does anyone know what this error is...
>>> kick abandoning conn43723 local=192.168.1.1:3128 
>>> remote=192.168.1.5:52129 FD 178 flags=1
>>
>>
>> This "kick abandoning" message marks a Squid problem or bug: Squid enters a seemingly impossible state. In some (but probably not all) cases, the client connection might become stuck (hopefully until some timeout closes it). In some (and possibly all) cases, Squid might immediately close the connection and nobody gets hurt. Code reporting this problem does not know how we got here and what will happen next.
>>
>> There were several incomplete/unfinished attempts to fix this problem, including two different patches posted at Bug 3715. I do not know whether either of them is safe and applies to Squid v6. Neither is a comprehensive solution.
>> https://bugs.squid-cache.org/show_bug.cgi?id=3715
>>
>>
>>> Does anyone know how to fix my last weird error I have with Squid 
>>> 6.6
>>
>> I do not know of a good configuration-based workaround. Squid code modifications are required to properly address this problem. Other errors may trigger this bug, so addressing those other errors may hide (and reduce the pressure to fix) this bug. Besides fixing those other errors (if any -- I am aware that you have said that there are no other errors left, but perhaps you found other problems since then), these basic options apply:
>>
>> https://wiki.squid-cache.org/SquidFaq/AboutSquid#how-to-add-a-new-squ
>> id-feature-enhance-of-fix-something
>>
>> Alex.
>>




From squid3 at treenet.co.nz  Wed Jul 10 09:41:37 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 10 Jul 2024 21:41:37 +1200
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
Message-ID: <075ae288-b3af-49ef-a4ca-f47bfd30a2fc@treenet.co.nz>

On 10/07/24 10:25, Fiehe, Christoph wrote:
> Hallo,
> 
> I hope that somebody has an idea, what I am doing wrong. I try to build a generic package proxy with Squid and need the feature to rewrite (not redirect) a HTTP request to a package repository transparently to a HTTPS-based package source.

The "Wrong" starts with the very idea you have that re-writing a URL 
scheme is even useful.


While it mas *seem* like an okay idea, what you are actually doing is 
exposing the HTTPS secured Response message to transmission over 
insecure connections from Squid to client. That is prohibited by HTTPS 
which assumes/requires encryption negotiated between the origin client 
and the origin server.


The best you can do for a regular proxy. Is *redirect* the http:// 
requests with a 302 message telling the client to use https:// instead.


   ...
   http_access deny !to_archive_mirrors

   acl HTTP proto HTTP
   deny_info 302:https://%>rd%rp HTTP
   http_access deny HTTP

   http_access allow src_networks
   ...



HTH
Amos



From squid3 at treenet.co.nz  Wed Jul 10 10:45:18 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 10 Jul 2024 22:45:18 +1200
Subject: [squid-users] Unable to explain 407 Proxy Authentication
 Required
In-Reply-To: <CAFgeZO7tDom+YK6CDYzFkyGUqkGWLrtjA2+2MaW2Pj1+6LBi=w@mail.gmail.com>
References: <CAFgeZO7tDom+YK6CDYzFkyGUqkGWLrtjA2+2MaW2Pj1+6LBi=w@mail.gmail.com>
Message-ID: <c38ee699-a6f3-48fc-bd55-041bda7e11bc@treenet.co.nz>

On 9/07/24 02:39, Random Dude wrote:
> Hey everyone.
> 
> I'm trying to get a minimal forward proxy with authentication set up. I 
> have the following config (purposely kept as minimal as possible) and 
> have followed these steps - 
> https://wiki.squid-cache.org/ConfigExamples/Authenticate/ 
> <https://wiki.squid-cache.org/ConfigExamples/Authenticate/>
> 
> squid.conf ---
> auth_param basic program /usr/lib/squid/basic_ncsa_auth 
> /etc/squid/passwords auth_param basic children 5 auth_param basic 
> credentialsttl 1 minute acl CONNECT method CONNECT acl auth proxy_auth 
> REQUIRED http_port 3128 http_access deny !auth http_access allow auth 
> http_access deny all
> ---
> 
> However, no matter what I do I always get a 407 Proxy Authentication 
> Required response from the proxy. I've been testing with "curl -v -U 
> <usernamen>:<password> -x localhost:3128 <url>" I must be missing 
> something very simple so what am I doing wrong?
> 

The config above is correct. So whatever the issue, it is not Squid.

I would start with a check to see if the login you are testing with is 
correctly encoded in the passwords file.

This command line should tell you that:

  echo "username password" | \
  /usr/lib/squid/basic_ncsa_auth /etc/squid/passwords


HTH
Amos


From c.fiehe at eurodata.de  Wed Jul 10 10:57:57 2024
From: c.fiehe at eurodata.de (Fiehe, Christoph)
Date: Wed, 10 Jul 2024 10:57:57 +0000
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <075ae288-b3af-49ef-a4ca-f47bfd30a2fc@treenet.co.nz>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <075ae288-b3af-49ef-a4ca-f47bfd30a2fc@treenet.co.nz>
Message-ID: <6727429ee289454dbfde22ccf092ffd2@eurodata.de>

The idea behind was to find a way to cache packages from a repository that only provides HTTPS-based connections. It would work, when the HTTPS connection terminates at the Squid Proxy and not at the client, so that the proxy can forward the message payload to the client using normal HTTP. Apt-Cacher-NG implements the behavior, but it seems to be too buggy to use in a productive environment.

There is no way to achieve that with standard Squid mechanisms?

Regards,
Christoph


>-----Urspr?ngliche Nachricht-----
>Von: squid-users <squid-users-bounces at lists.squid-cache.org> Im Auftrag von Amos Jeffries
>Gesendet: Mittwoch, 10. Juli 2024 11:42
>An: squid-users at lists.squid-cache.org
>Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>
>On 10/07/24 10:25, Fiehe, Christoph wrote:
>> Hallo,
>>
>> I hope that somebody has an idea, what I am doing wrong. I try to build a generic
>package proxy with Squid and need the feature to rewrite (not redirect) a HTTP request to
>a package repository transparently to a HTTPS-based package source.
>
>The "Wrong" starts with the very idea you have that re-writing a URL
>scheme is even useful.
>
>
>While it mas *seem* like an okay idea, what you are actually doing is
>exposing the HTTPS secured Response message to transmission over
>insecure connections from Squid to client. That is prohibited by HTTPS
>which assumes/requires encryption negotiated between the origin client
>and the origin server.
>
>
>The best you can do for a regular proxy. Is *redirect* the http://
>requests with a 302 message telling the client to use https:// instead.
>
>
>   ...
>   http_access deny !to_archive_mirrors
>
>   acl HTTP proto HTTP
>   deny_info 302:https://%>rd%rp HTTP
>   http_access deny HTTP
>
>   http_access allow src_networks
>   ...
>
>
>
>HTH
>Amos
>
>_______________________________________________
>squid-users mailing list
>squid-users at lists.squid-cache.org
>https://lists.squid-cache.org/listinfo/squid-users


From uhlar at fantomas.sk  Wed Jul 10 11:29:46 2024
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 10 Jul 2024 13:29:46 +0200
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <01d201dad257$f4eab0a0$dec011e0$@gmail.com>
References: <FC75961E-4CB1-480F-A190-9915F0472FA4@gmail.com>
 <DA266AA1-8B27-44EF-B72C-BF7DF6AE3637@gmail.com>
 <d018d560-acb2-406e-895d-8446759f41e5@treenet.co.nz>
 <5F898811-4C5D-4477-A6E4-83D456A8790A@gmail.com>
 <96F3E89F-ED67-491E-BD50-FA5307464FE7@gmail.com>
 <9BF3DE5B-149B-475D-940E-8F21118C7E8E@gmail.com>
 <slrnv8qbt7.h8a.stu.lists@naiad.spacehopper.org>
 <01d201dad257$f4eab0a0$dec011e0$@gmail.com>
Message-ID: <Zo5wquYhxhqqAJQW@fantomas.sk>

>On 2024-07-08, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> squidclient -h 192.168.1.1:3128 mgr:info at PASSWORD squidclient -h
>> 1287.0.0.1 mgr:info at PASSWORD
>>
>> Gives the following error
>>
>> Embedding a password in a cache manager command requires providing a =
>> username with -U: mgr:info at PASSWORDHERE

>Try "/squid-internal-mgr/info" where you have "mgr:info".

On 09.07.24 16:30, jonathanlee571 at gmail.com wrote:
>Thanks that also gave the error access denied

have you tried providing -U (and maybe -W) options to squidclient?
Because that one looks like squidclient error to me.

in previous versions username was not important for manager queries, just 
the password, which should be either part of user or provided by -W option

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Christian Science Programming: "Let God Debug It!".


From squid3 at treenet.co.nz  Wed Jul 10 11:34:45 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 10 Jul 2024 23:34:45 +1200
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <6727429ee289454dbfde22ccf092ffd2@eurodata.de>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <075ae288-b3af-49ef-a4ca-f47bfd30a2fc@treenet.co.nz>
 <6727429ee289454dbfde22ccf092ffd2@eurodata.de>
Message-ID: <27460936-0e09-4f78-965a-3db38bb68101@treenet.co.nz>

On 10/07/24 22:57, Fiehe, Christoph wrote:
> The idea behind was to find a way to cache packages from a repository that only provides HTTPS-based connections. It would work, when the HTTPS connection terminates at the Squid Proxy and not at the client, so that the proxy can forward the message payload to the client using normal HTTP. Apt-Cacher-NG implements the behavior, but it seems to be too buggy to use in a productive environment.
> 
> There is no way to achieve that with standard Squid mechanisms?
> 

At risk of allowing bad actors to install arbitrary software on all of 
your clients: You can direct all the archive traffic to a cache_peer 
with port 443 and "originserver tls" flags.

YMMV, caveat emptor.


Cheers
Amos


From rousskov at measurement-factory.com  Wed Jul 10 12:49:35 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 10 Jul 2024 08:49:35 -0400
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
Message-ID: <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>

On 2024-07-09 18:25, Fiehe, Christoph wrote:

> I hope that somebody has an idea, what I am doing wrong. 

AFAICT from the debugging log, it is your parent proxy that returns an 
ERR_SECURE_CONNECT_FAIL error page in response to a seemingly valid 
"HEAD https://..." request. Can you ask their admin to investigate? You 
may also recommend that they upgrade from Squid v4 that has many known 
security vulnerabiities.

If parent is uncooperative, you can try to reproduce the problem by 
temporary installing your own parent Squid instance and configuring your 
child Squid to use that instead.

HTH,

Alex.
P.S. Unlike Amos, I do not see serious conceptual problems with 
rewriting request target scheme (as a temporary compatibility measure). 
It may not always work, for various reasons, but it does not necessarily 
make things worse (and may make things better).




I try to build a generic package proxy with Squid and need the feature 
to rewrite (not redirect) a HTTP request to a package repository 
transparently to a HTTPS-based package source. I was able to get Jesred 
working and defined the following rewrite rule:
> 
> regex ^http:\/\/download\.docker\.com(.*)$ https://download.docker.com\1
> 
> I had to use a parent upstream proxy. In my test case the rule gets applied successfully:
> 
> 1720558404.106 10.2.59.102/molecule-ubuntu-jammy.lx.mycompany.de http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/linux/ubuntu/dists/jammy/InRelease] https://download.docker.com/linux/ubuntu/dists/jammy/InRelease 2
> 
> I have validated that the returned URL is correct and that the resource is accessible via my upstream proxy.
> 
> But at the very end, the client receives a 503 error code. I have set "debug_options ALL,3" and this gives the log:
> 
> [...]
> 2024/07/09 23:35:40.115 kid1| 11,2| client_side.cc(1333) parseHttpRequest: HTTP Client REQUEST:
> ---------
> HEAD http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/linux/ubuntu/dists/jammy/InRelease] HTTP/1.1
> Host: download.docker.com
> User-Agent: curl/7.81.0
> Accept: */*
> Proxy-Connection: Keep-Alive
> 
> 
> ----------
> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(1364) parseHttpRequest: complete request received. prefix_sz = 174, request-line-size=77, mime-header-size=97, mime header block:
> Host: download.docker.com
> User-Agent: curl/7.81.0
> Accept: */*
> Proxy-Connection: Keep-Alive
> 
> 
> ----------
> 2024/07/09 23:35:40.115 kid1| 87,3| clientStream.cc(139) clientStreamInsertHead: clientStreamInsertHead: Inserted node 0x5c3ba4154308 with data 0x5c3ba4152950 after head
> 2024/07/09 23:35:40.115 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn9 local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1 timeout 86400
> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(1767) add: 0x5c3ba41518e0*3 to 0/0
> 2024/07/09 23:35:40.115 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x5c3ba41501f0 add request 1 0x5c3ba41518e0*4
> 2024/07/09 23:35:40.115 kid1| 23,3| Uri.cc(446) parse: Split URL 'http://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[http://download.docker.com/linux/ubuntu/dists/jammy/InRelease'] into proto='http', host='download.docker.com', port='80', path='/linux/ubuntu/dists/jammy/InRelease'
> 2024/07/09 23:35:40.115 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(702) clientSetKeepaliveFlag: http_ver = HTTP/1.1
> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(703) clientSetKeepaliveFlag: method = HEAD
> 2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(122) ClientRequestContext: ClientRequestContext constructed, this=0x5c3ba4154e78
> 2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1708) doCallouts: Doing calloutContext->hostHeaderVerify()
> 2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(606) hostHeaderVerify: validate host=download.docker.com, port=0, portStr=NULL
> 2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(620) hostHeaderVerify: validate skipped.
> 2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1715) doCallouts: Doing calloutContext->clientAccessCheck()
> 2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba41552d8 checking slow rules
> 2024/07/09 23:35:40.115 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.102:56466' found
> 2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
> 2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: http_access#1 = 1
> 2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: http_access = 1
> 2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba41552d8 answer ALLOWED for match
> 2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(162) checkCallback: ACLChecklist::checkCallback: 0x5c3ba41552d8 answer=ALLOWED
> 2024/07/09 23:35:40.115 kid1| 85,2| client_side_request.cc(714) clientAccessCheckDone: The request HEAD http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/linux/ubuntu/dists/jammy/InRelease] is ALLOWED; last ACL checked: all
> 2024/07/09 23:35:40.115 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
> 2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1735) doCallouts: Doing calloutContext->clientRedirectStart()
> 2024/07/09 23:35:40.115 kid1| 78,3| dns_internal.cc(1836) idnsPTRLookup: idnsPTRLookup: buf is 42 bytes for 10.2.59.102, id = 0x8d95
> 2024/07/09 23:35:40.115 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
> 2024/07/09 23:35:40 kid1| Starting new redirector helpers...
> current master transaction: master54
> 2024/07/09 23:35:40 kid1| helperOpenServers: Starting 1/3 'jesred' processes
> current master transaction: master54
> 2024/07/09 23:35:40.115 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 17 IPC UNIX STREAM Parent
> 2024/07/09 23:35:40.115 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 19 IPC UNIX STREAM Parent
> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(212) ipcCreate: ipcCreate: prfd FD 17
> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(213) ipcCreate: ipcCreate: pwfd FD 17
> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(214) ipcCreate: ipcCreate: crfd FD 19
> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(215) ipcCreate: ipcCreate: cwfd FD 19
> 2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(850) _comm_close: start closing FD 19 by ipc.cc:271
> 2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(586) commUnsetFdTimeout: Remove timeout for FD 19
> 2024/07/09 23:35:40.116 kid1| 21,3| tools.cc(561) leave_suid: leave_suid: PID 503746 called
> 2024/07/09 23:35:40.116 kid1| 21,3| tools.cc(651) no_suid: no_suid: PID 503746 giving up root privileges forever
> 2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(586) commUnsetFdTimeout: Remove timeout for FD 17
> 2024/07/09 23:35:40.117 kid1| 84,3| helper.cc(1310) GetFirstAvailable: GetFirstAvailable: Least-loaded helper is fully loaded!
> 2024/07/09 23:35:40.117 kid1| 51,3| fd.cc(93) fd_close: fd_close FD 19 IPC UNIX STREAM Parent
> 2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting with FD 11
> 2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11: received 92 bytes from 127.0.0.53:53
> 2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply: QID 0x8d95, 1 answers
> 2024/07/09 23:35:40.117 kid1| 35,3| fqdncache.cc(336) fqdncacheParse: fqdncacheParse: 1 answers for '10.2.59.102'
> 2024/07/09 23:35:40.117 kid1| 5,3| IoCallback.cc(112) finish: called for conn11 local=[::] remote=[::] FD 17 flags=1 (0, 0)
> 2024/07/09 23:35:40.125 kid1| 5,3| Read.cc(148) HandleRead: FD 17, size 32767, retval 80, errno 0
> 2024/07/09 23:35:40.125 kid1| 5,3| IoCallback.cc(112) finish: called for conn10 local=[::] remote=[::] FD 17 flags=1 (0, 0)
> 2024/07/09 23:35:40.125 kid1| 84,3| helper.cc(1022) helperHandleRead: helperHandleRead: end of reply found
> 2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(41) finalize: Parsing helper buffer
> 2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(59) finalize: Buff length is larger than 2
> 2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(63) finalize: helper Result = OK
> 2024/07/09 23:35:40.125 kid1| 23,3| Uri.cc(446) parse: Split URL 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'] into proto='https', host='download.docker.com', port='443', path='/linux/ubuntu/dists/jammy/InRelease'
> 2024/07/09 23:35:40.125 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
> 2024/07/09 23:35:40.125 kid1| 61,2| client_side_request.cc(1235) clientRedirectDone: URL-rewriter diverts URL from http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/linux/ubuntu/dists/jammy/InRelease] to https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
> 2024/07/09 23:35:40.125 kid1| 83,3| client_side_request.cc(1743) doCallouts: Doing calloutContext->clientAccessCheck2()
> 2024/07/09 23:35:40.125 kid1| 85,2| client_side_request.cc(692) clientAccessCheck2: No adapted_http_access configuration. default: ALLOW
> 2024/07/09 23:35:40.125 kid1| 85,2| client_side_request.cc(714) clientAccessCheckDone: The request HEAD https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease] is ALLOWED; last ACL checked: all
> 2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1761) doCallouts: Doing clientInterpretRequestHeaders()
> 2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1770) doCallouts: Doing calloutContext->checkNoCache()
> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba41552d8 checking slow rules
> 2024/07/09 23:35:40.126 kid1| 28,3| RegexData.cc(50) match: checking 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease']
> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: no_cache = 0
> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache#1 = 0
> 2024/07/09 23:35:40.126 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.102:56466' found
> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache#2 = 1
> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache = 1
> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba41552d8 answer ALLOWED for match
> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(162) checkCallback: ACLChecklist::checkCallback: 0x5c3ba41552d8 answer=ALLOWED
> 2024/07/09 23:35:40.126 kid1| 85,3| client_side_request.cc(116) ~ClientRequestContext: ClientRequestContext destructed, this=0x5c3ba4154e78
> 2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1855) doCallouts: calling processRequest()
> 2024/07/09 23:35:40.126 kid1| 87,3| clientStream.cc(178) clientStreamRead: clientStreamRead: Calling 1 with cbdata 0x5c3ba4153e70 from node 0x5c3ba4154308
> 2024/07/09 23:35:40.126 kid1| 73,3| HttpRequest.cc(742) storeId: sent back effectiveRequestUrl: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
> 2024/07/09 23:35:40.126 kid1| 20,3| Controller.cc(429) peek: DE850794EBC405A27A7718F51795E32A
> 2024/07/09 23:35:40.126 kid1| 73,3| HttpRequest.cc(742) storeId: sent back effectiveRequestUrl: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
> 2024/07/09 23:35:40.126 kid1| 20,3| Controller.cc(429) peek: D3522EE27FB0ED7004DD594AF7674667
> 2024/07/09 23:35:40.126 kid1| 85,3| client_side_reply.cc(1523) identifyFoundObject: StoreEntry is NULL - MISS
> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(730) storeCreatePureEntry: storeCreateEntry: 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease']
> 2024/07/09 23:35:40.126 kid1| 20,3| MemObject.cc(99) MemObject: MemObject constructed, this=0x5c3ba416ef10
> 2024/07/09 23:35:40.126 kid1| 88,3| MemObject.cc(82) setUris: 0x5c3ba416ef10 storeId: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: storeCreateEntry locked key [null_store_key] e:=V/0x5c3ba416ee90*1
> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(536) setPrivateKey: 00 e:=V/0x5c3ba416ee90*1
> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(412) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x5c3ba416ee90*1 key '020000000000000061AF070001000000'
> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: store_client locked key 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*2
> 2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(243) copy: store_client::copy: 020000000000000061AF070001000000, from 0, for length 4096, cb 1, cbdata 0x5c3ba4152dd8
> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: store_client::copy locked key 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
> 2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(343) storeClientCopy2: storeClientCopy2: 020000000000000061AF070001000000
> 2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(390) doCopy: store_client::doCopy: Waiting for more
> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(457) unlock: store_client::copy unlocking key 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(373) Start: 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease']
> 2024/07/09 23:35:40.126 kid1| 17,2| FwdState.cc(133) FwdState: Forwarding client request conn9 local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1, url=https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: FwdState locked key 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(140) FwdState: FwdState constructed, this=0x5c3ba416fa18
> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(309) peerSelect: e:=IV/0x5c3ba416ee90*3 https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: peerSelect locked key 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*4
> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(612) selectMore: HEAD download.docker.com
> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(626) selectMore: direct = DIRECT_UNKNOWN (never_direct to be checked)
> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba4170638 checking slow rules
> 2024/07/09 23:35:40.126 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.102:56466' found
> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: never_direct#1 = 1
> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: never_direct = 1
> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba4170638 answer ALLOWED for match
> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(162) checkCallback: ACLChecklist::checkCallback: 0x5c3ba4170638 answer=ALLOWED
> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(345) checkNeverDirectDone: ALLOWED
> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(351) checkNeverDirectDone: direct = DIRECT_NO (never_direct allow)
> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(612) selectMore: HEAD download.docker.com
> 2024/07/09 23:35:40.126 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname: ipcache_gethostbyname: 'download.docker.com', flags=0
> 2024/07/09 23:35:40.126 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(286) peerSelectIcpPing: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(283) neighborsCount: neighborsCount: 0
> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(297) peerSelectIcpPing: counted 0 neighbors
> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(833) selectSomeParent: HEAD download.docker.com
> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(350) getRoundRobinParent: returning [nil]
> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(403) getWeightedRoundRobinParent: returning [nil]
> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(309) getFirstUpParent: returning 212.89.128.96
> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1102) addSelection: adding FIRSTUP_PARENT/212.89.128.96
> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1095) addSelection: skipping ANY_OLD_PARENT/212.89.128.96; have FIRSTUP_PARENT/212.89.128.96
> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(493) getDefaultParent: returning 212.89.128.96
> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1095) addSelection: skipping DEFAULT_PARENT/212.89.128.96; have FIRSTUP_PARENT/212.89.128.96
> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(460) resolveSelected: Find IP destination for: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'] via 212.89.128.96
> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector1 found conn12 local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1, destination #1 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = ALLOWED
> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(610) noteDestination: conn12 local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1
> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(1124) connectStart: 1+ paths to https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(479) resolveSelected: PeerSelector1 found all 1 destinations for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(480) resolveSelected: always_direct = DENIED
> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(481) resolveSelected: never_direct = ALLOWED
> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(482) resolveSelected: timedout = 0
> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(241) ~PeerSelector: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(457) unlock: peerSelect unlocking key 020000000000000061AF070001000000 e:=p2IV/0x5c3ba416ee90*4
> 2024/07/09 23:35:40.126 kid1| 48,3| pconn.cc(474) popStored: lookup for key {212.89.128.96:3128} failed.
> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(1568) GetMarkingsToServer: from 0.0.0.0 tos 0 netfilter mark 0
> 2024/07/09 23:35:40.126 kid1| 5,3| ConnOpener.cc(42) ConnOpener: will connect to conn14 local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1 with 30 timeout
> 2024/07/09 23:35:40.126 kid1| 50,3| comm.cc(378) comm_openex: comm_openex: Attempt open socket for: 0.0.0.0
> 2024/07/09 23:35:40.126 kid1| 50,3| comm.cc(420) comm_openex: comm_openex: Opened socket conn15 local=0.0.0.0 remote=[::] FD 19 flags=1 : family=2, type=1, protocol=6
> 2024/07/09 23:35:40.126 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 19
> 2024/07/09 23:35:40.126 kid1| 5,3| ConnOpener.cc(312) createFd: conn14 local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1 will timeout in 30
> 2024/07/09 23:35:40.127 kid1| 17,3| FwdState.cc(1197) dispatch: conn9 local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1: Fetching HEAD https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
> 2024/07/09 23:35:40.127 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
> 2024/07/09 23:35:40.127 kid1| 78,3| dns_internal.cc(1793) idnsALookup: idnsALookup: buf is 37 bytes for download.docker.com, id = 0xe779
> 2024/07/09 23:35:40.127 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
> 2024/07/09 23:35:40.127 kid1| 78,3| dns_internal.cc(1729) idnsSendSlaveAAAAQuery: buf is 37 bytes for download.docker.com, id = 0x8aee
> 2024/07/09 23:35:40.127 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
> 2024/07/09 23:35:40.127 kid1| 11,3| http.cc(2516) httpStart: HEAD https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
> 2024/07/09 23:35:40.127 kid1| 20,3| store.cc(434) lock: Client locked key 020000000000000061AF070001000000 e:=p2IV/0x5c3ba416ee90*4
> 2024/07/09 23:35:40.127 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn14 local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 timeout 86400
> 2024/07/09 23:35:40.127 kid1| 22,3| refresh.cc(636) getMaxAge: getMaxAge: 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease']
> 2024/07/09 23:35:40.127 kid1| 11,2| http.cc(2472) sendRequest: HTTP Server conn14 local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1
> 2024/07/09 23:35:40.127 kid1| 11,2| http.cc(2473) sendRequest: HTTP Server REQUEST:
> ---------
> HEAD https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease] HTTP/1.1
> Host: download.docker.com
> User-Agent: curl/7.81.0
> Accept: */*
> Via: 1.1 pkg-proxy (squid/6.6)
> X-Forwarded-For: 10.2.59.102
> Cache-Control: max-age=0
> Connection: keep-alive
> 
> 
> ----------
> 2024/07/09 23:35:40.127 kid1| 5,3| IoCallback.cc(112) finish: called for conn14 local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 (0, 0)
> 2024/07/09 23:35:40.127 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn14 local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 timeout 900
> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting with FD 11
> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11: received 304 bytes from 127.0.0.53:53
> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply: QID 0x8aee, 9 answers
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(480) ipcacheParse: 9 answers for download.docker.com
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #1 [2600:9000:2490:6c00:3:db06:4200:93a1]
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #2 [2600:9000:2490:a600:3:db06:4200:93a1]
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #3 [2600:9000:2490:9c00:3:db06:4200:93a1]
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #4 [2600:9000:2490:6000:3:db06:4200:93a1]
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #5 [2600:9000:2490:c00:3:db06:4200:93a1]
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #6 [2600:9000:2490:5200:3:db06:4200:93a1]
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #7 [2600:9000:2490:9a00:3:db06:4200:93a1]
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #8 [2600:9000:2490:2c00:3:db06:4200:93a1]
> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting with FD 11
> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11: received 144 bytes from 127.0.0.53:53
> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply: QID 0xe779, 5 answers
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(480) ipcacheParse: 5 answers for download.docker.com
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #9 108.138.7.33
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #10 108.138.7.18
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #11 108.138.7.88
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #12 108.138.7.48
> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(586) ipcacheHandleReply: done with download.docker.com: [2600:9000:2490:6c00:3:db06:4200:93a1] #1/12-0
> 2024/07/09 23:35:40.137 kid1| 38,3| net_db.cc(337) netdbSendPing: netdbSendPing: pinging download.docker.com
> 2024/07/09 23:35:40.137 kid1| 37,2| IcmpSquid.cc(88) SendEcho: to [2600:9000:2490:6c00:3:db06:4200:93a1], opcode 3, len 19
> 2024/07/09 23:35:40.137 pinger| 42,2| IcmpPinger.cc(198) Recv: Pass [2600:9000:2490:6c00:3:db06:4200:93a1] off to ICMPv6 module.
> 2024/07/09 23:35:40 pinger| SendEcho ERROR: sending to ICMPv6 packet to [2600:9000:2490:6c00:3:db06:4200:93a1]: (101) Network is unreachable
> 2024/07/09 23:35:40.138 pinger| 42,2| Icmp.cc(90) Log: pingerLog: 1720560940.138021 [2600:9000:2490:6c00:3:db06:4200:93a1] 0
> 2024/07/09 23:35:40.323 kid1| 5,3| IoCallback.cc(112) finish: called for conn14 local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 (0, 0)
> 2024/07/09 23:35:40.324 kid1| 5,3| Read.cc(93) ReadNow: conn14 local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1, size 65536, retval 348, errno 0
> 2024/07/09 23:35:40.324 kid1| 11,3| http.cc(649) processReplyHeader: processReplyHeader: key '020000000000000061AF070001000000'
> 2024/07/09 23:35:40.324 kid1| 11,2| http.cc(696) processReplyHeader: HTTP Server conn14 local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1
> 2024/07/09 23:35:40.324 kid1| 11,2| http.cc(697) processReplyHeader: HTTP Server RESPONSE:
> ---------
> HTTP/1.1 503 Service Unavailable
> Server: squid/4.10
> Mime-Version: 1.0
> Date: Tue, 09 Jul 2024 21:35:40 GMT
> Content-Type: text/html;charset=utf-8
> Content-Length: 3879
> X-Squid-Error: ERR_SECURE_CONNECT_FAIL 71
> X-Cache: MISS from proxy-srv2
> X-Cache-Lookup: MISS from proxy-srv2:3128
> Via: 1.1 proxy-srv2 (squid/4.10)
> Connection: keep-alive
> 
> ----------
> 2024/07/09 23:35:40.324 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
> 2024/07/09 23:35:40.324 kid1| 20,3| store.cc(1693) replaceHttpReply: StoreEntry::replaceHttpReply: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com/linux/ubuntu/dists/jammy/InRelease]
> 2024/07/09 23:35:40.324 kid1| 11,3| http.cc(949) haveParsedReplyHeaders: HTTP CODE: 503
> 
> Has anybody an idea what I can do to solve the issue?
> 
> This is my configuration borrowed from squid-deb-proxy:
> 
> # this file contains private networks (10.0.0.0/8, 172.16.0.0/12,
> # 192.168.0.0/16) by default, you can add/remove additional allowed
> # source networks in it to customize it for your setup
> acl src_networks src "/etc/squid/acl/src-networks.acl"
> 
> # this file contains the archive mirrors by default,
> # if you use a different mirror, add it there
> acl to_archive_mirrors dstdomain "/etc/squid/acl/archive-mirrors.acl"
> 
> # Disable Cache for defined domains
> acl no_cache url_regex "/etc/squid/acl/no-cache.acl"
> 
> # this contains the package blacklist
> acl blockedpkgs urlpath_regex "/etc/squid/pkg-blacklist-regexp.acl"
> 
> # default to a different port than stock squid
> http_port 8000
> 
> # -------------------------------------------------
> # settings below probably do not need customization
> 
> # user visible name
> visible_hostname pkg-proxy
> 
> # we need a big cache, some debs are huge
> maximum_object_size 512 MB
> 
> # use a different dir than stock squid and default to 40G
> cache_dir aufs /var/cache/squid 40000 16 256
> 
> cache_peer 212.89.128.96 parent 3128 0 no-query default
> never_direct allow all
> 
> # use different logs
> cache_access_log /var/log/squid/access.log
> cache_log /var/log/squid/cache.log
> cache_store_log /var/log/squid/store.log
> 
> # tweaks to speed things up
> cache_mem 200 MB
> maximum_object_size_in_memory 10240 KB
> 
> # pid
> pid_filename /var/run/squid.pid
> 
> # refresh pattern for debs and udebs
> refresh_pattern deb$ 129600 100% 129600
> refresh_pattern udeb$ 129600 100% 129600
> refresh_pattern tar.gz$ 129600 100% 129600
> refresh_pattern tar.xz$ 129600 100% 129600
> refresh_pattern tar.bz2$ 129600 100% 129600
> 
> # always refresh Packages and Release files
> refresh_pattern \/(Packages|Sources)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims
> refresh_pattern \/Release(|\.gpg)$ 0 0% 0 refresh-ims
> refresh_pattern \/InRelease$ 0 0% 0 refresh-ims
> refresh_pattern \/(Translation-.*)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims
> 
> # handle meta-release and changelogs.ubuntu.com special
> # (fine to have this on debian too)
> refresh_pattern changelogs.ubuntu.com\/.* 0 1% 1
> 
> # only allow connects to ports for http, https
> acl SSL_ports port 443 563
> acl Safe_ports port 80
> acl Safe_ports port 443 563
> 
> # only allow ports we trust
> http_access deny !Safe_ports
> 
> # do not allow to download from the pkg blacklist
> http_access deny blockedpkgs
> 
> # allow access only to official archive mirrors
> # uncomment the third and fouth line to permit any unlisted domain
> http_access deny !to_archive_mirrors
> 
> # allow access from our network and localhost
> http_access allow src_networks
> 
> # And finally deny all other access to this proxy
> http_access deny all
> 
> # don't cache domains not listed in the mirrors file
> # uncomment the third and fourth line to cache any unlisted domains
> cache deny no_cache
> 
> # And finally cache everything else
> cache allow all
> 
> url_rewrite_children 3 startup=0 idle=1 concurrency=1
> url_rewrite_program /usr/lib/squid/jesred
> 
> debug_options ALL,3
> 
> Thanks a lot.
> 
> Regards,
> Christoph
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From jonathanlee571 at gmail.com  Wed Jul 10 15:52:44 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 10 Jul 2024 08:52:44 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <Zo5wquYhxhqqAJQW@fantomas.sk>
References: <Zo5wquYhxhqqAJQW@fantomas.sk>
Message-ID: <99DC3EC1-4A9C-4DC1-A531-EE2723A27845@gmail.com>

That makes sense, I only had a password in the previous version, how do I add username admin for cachemgr? I don?t have a username configured yet, I can?t find the directive for cachemgr username
Sent from my iPhone

> On Jul 10, 2024, at 04:29, Matus UHLAR - fantomas <uhlar at fantomas.sk> wrote:
> 
> ?
>> 
>>> On 2024-07-08, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>> squidclient -h 192.168.1.1:3128 mgr:info at PASSWORD squidclient -h
>>> 1287.0.0.1 mgr:info at PASSWORD
>>> 
>>> Gives the following error
>>> 
>>> Embedding a password in a cache manager command requires providing a =
>>> username with -U: mgr:info at PASSWORDHERE
> 
>> Try "/squid-internal-mgr/info" where you have "mgr:info".
> 
>> On 09.07.24 16:30, jonathanlee571 at gmail.com wrote:
>> Thanks that also gave the error access denied
> 
> have you tried providing -U (and maybe -W) options to squidclient?
> Because that one looks like squidclient error to me.
> 
> in previous versions username was not important for manager queries, just the password, which should be either part of user or provided by -W option
> 
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> Christian Science Programming: "Let God Debug It!".
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From uhlar at fantomas.sk  Wed Jul 10 16:20:55 2024
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 10 Jul 2024 18:20:55 +0200
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <99DC3EC1-4A9C-4DC1-A531-EE2723A27845@gmail.com>
References: <Zo5wquYhxhqqAJQW@fantomas.sk>
 <99DC3EC1-4A9C-4DC1-A531-EE2723A27845@gmail.com>
Message-ID: <Zo605zQA1vz_lEZX@fantomas.sk>

On 10.07.24 08:52, Jonathan Lee wrote:
> That makes sense, I only had a password in the previous version, how do I 
> add username admin for cachemgr?  

you don't, that's why I said "username was not important"
simply try random username

>> On Jul 10, 2024, at 04:29, Matus UHLAR - fantomas <uhlar at fantomas.sk> wrote:
>>
>>>> On 2024-07-08, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>> squidclient -h 192.168.1.1:3128 mgr:info at PASSWORD squidclient -h
>>>> 1287.0.0.1 mgr:info at PASSWORD
>>>>
>>>> Gives the following error
>>>>
>>>> Embedding a password in a cache manager command requires providing a =
>>>> username with -U: mgr:info at PASSWORDHERE
>>
>>> Try "/squid-internal-mgr/info" where you have "mgr:info".
>>
>>> On 09.07.24 16:30, jonathanlee571 at gmail.com wrote:
>>> Thanks that also gave the error access denied
>>
>> have you tried providing -U (and maybe -W) options to squidclient?
>> Because that one looks like squidclient error to me.
>>
>> in previous versions username was not important for manager queries, just the password, which should be either part of user or provided by -W option

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Boost your system's speed by 500% - DEL C:\WINDOWS$\*.*


From jonathanlee571 at gmail.com  Wed Jul 10 16:33:02 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 10 Jul 2024 09:33:02 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <Zo605zQA1vz_lEZX@fantomas.sk>
References: <Zo605zQA1vz_lEZX@fantomas.sk>
Message-ID: <B445DDAF-6DCD-4B1F-AA53-FD51C62B99B2@gmail.com>

I have it says denied as if it requires an entry for one to use password, again if I remove the password the same thing happens. Weird right? Could WPAD cause this? 
Sent from my iPhone

> On Jul 10, 2024, at 09:21, Matus UHLAR - fantomas <uhlar at fantomas.sk> wrote:
> 
> ?On 10.07.24 08:52, Jonathan Lee wrote:
>> That makes sense, I only had a password in the previous version, how do I add username admin for cachemgr?  
> 
> you don't, that's why I said "username was not important"
> simply try random username
> 
>>>> On Jul 10, 2024, at 04:29, Matus UHLAR - fantomas <uhlar at fantomas.sk> wrote:
>>> 
>>>>> On 2024-07-08, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>>> squidclient -h 192.168.1.1:3128 mgr:info at PASSWORD squidclient -h
>>>>> 1287.0.0.1 mgr:info at PASSWORD
>>>>> 
>>>>> Gives the following error
>>>>> 
>>>>> Embedding a password in a cache manager command requires providing a =
>>>>> username with -U: mgr:info at PASSWORDHERE
>>> 
>>>> Try "/squid-internal-mgr/info" where you have "mgr:info".
>>> 
>>>> On 09.07.24 16:30, jonathanlee571 at gmail.com wrote:
>>>> Thanks that also gave the error access denied
>>> 
>>> have you tried providing -U (and maybe -W) options to squidclient?
>>> Because that one looks like squidclient error to me.
>>> 
>>> in previous versions username was not important for manager queries, just the password, which should be either part of user or provided by -W option
> 
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> Boost your system's speed by 500% - DEL C:\WINDOWS$\*.*
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From uhlar at fantomas.sk  Wed Jul 10 16:35:04 2024
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 10 Jul 2024 18:35:04 +0200
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <B445DDAF-6DCD-4B1F-AA53-FD51C62B99B2@gmail.com>
References: <Zo605zQA1vz_lEZX@fantomas.sk>
 <B445DDAF-6DCD-4B1F-AA53-FD51C62B99B2@gmail.com>
Message-ID: <Zo64OEswTGHYcl9x@fantomas.sk>

On 10.07.24 09:33, Jonathan Lee wrote:
>To: Matus UHLAR - fantomas <uhlar at fantomas.sk>

please avoid personal copies.

>I have it says denied as if it requires an entry for one to use password, again if I remove the password the same thing happens. Weird right? Could WPAD cause this?

what exactly did you run?
show us complete command line, just replace password with "redacted"

And note that I'm guessing as well, since I dont run squid 6 (yet).

>> On Jul 10, 2024, at 09:21, Matus UHLAR - fantomas <uhlar at fantomas.sk> wrote:
>>
>> ?On 10.07.24 08:52, Jonathan Lee wrote:
>>> That makes sense, I only had a password in the previous version, how do I add username admin for cachemgr?
>>
>> you don't, that's why I said "username was not important"
>> simply try random username
>>
>>>>> On Jul 10, 2024, at 04:29, Matus UHLAR - fantomas <uhlar at fantomas.sk> wrote:
>>>>
>>>>>> On 2024-07-08, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>>>> squidclient -h 192.168.1.1:3128 mgr:info at PASSWORD squidclient -h
>>>>>> 1287.0.0.1 mgr:info at PASSWORD
>>>>>>
>>>>>> Gives the following error
>>>>>>
>>>>>> Embedding a password in a cache manager command requires providing a =
>>>>>> username with -U: mgr:info at PASSWORDHERE
>>>>
>>>>> Try "/squid-internal-mgr/info" where you have "mgr:info".
>>>>
>>>>> On 09.07.24 16:30, jonathanlee571 at gmail.com wrote:
>>>>> Thanks that also gave the error access denied
>>>>
>>>> have you tried providing -U (and maybe -W) options to squidclient?
>>>> Because that one looks like squidclient error to me.
>>>>
>>>> in previous versions username was not important for manager queries, just the password, which should be either part of user or provided by -W option

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Support bacteria - they're the only culture some people have.


From c.fiehe at eurodata.de  Wed Jul 10 16:42:09 2024
From: c.fiehe at eurodata.de (Fiehe, Christoph)
Date: Wed, 10 Jul 2024 16:42:09 +0000
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
Message-ID: <6bb89d7c58e34320b1eb15c1447e99d7@eurodata.de>

Thanks a lot. That was a good advice. For test purposes, I have deconfigured the upstream proxy and used an internal server. I changed the scheme from HTTP to HTTPS via a Jesred rule. The translation is working as expected without any issues and the client receives the requested packages.

In the next test case, I used a more modern upstream proxy server based von Squid 6.8 and enabled debugging.

The log shows the error SQUID_TLS_ERR_CONNECT+GNUTLS_E_FATAL_ALERT_RECEIVED. I am not sure, what I can do to prevent it from occurring:

2024/07/10 18:24:44.031 kid1| 5,2| TcpAcceptor.cc(214) doAccept: New connection on FD 12
2024/07/10 18:24:44.031 kid1| 5,2| TcpAcceptor.cc(316) acceptNext: connection on conn482169 local=[::]:3128 remote=[::] FD 12 flags=9
2024/07/10 18:24:44.031 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 16 HTTP Request
2024/07/10 18:24:44.031 kid1| 28,3| Eui48.cc(511) lookup: id=0x5651b3e6d558 10.2.59.181 NOT found
2024/07/10 18:24:44.031 kid1| 17,2| QosConfig.cc(162) getNfConnmark: QOS: Failed to retrieve connection mark: (-1) (2) No such file or directory (Destination 212.89.134.12:3128, source 10.2.59.181:59100)
2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 300
2024/07/10 18:24:44.031 kid1| 5,3| IoCallback.cc(112) finish: called for conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 (0, 0)
2024/07/10 18:24:44.031 kid1| 5,3| Read.cc(93) ReadNow: conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1, size 4096, retval 293, errno 0
2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 300
2024/07/10 18:24:44.031 kid1| 33,3| Pipeline.cc(43) back: Pipeline 0x5651b328cb80 empty
2024/07/10 18:24:44.031 kid1| 11,2| client_side.cc(1332) parseHttpRequest: HTTP Client conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1
2024/07/10 18:24:44.031 kid1| 11,2| client_side.cc(1333) parseHttpRequest: HTTP Client REQUEST:
---------
GET https://download.docker.com/linux/ubuntu/dists/jammy/InRelease HTTP/1.1
Host: download.docker.com
Accept: text/*
User-Agent: Debian APT-HTTP/1.3 (2.4.12) non-interactive
Via: 1.1 pkg-proxy (squid/6.10)
X-Forwarded-For: 10.2.59.102
Cache-Control: max-age=0
Connection: keep-alive


----------
2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(1364) parseHttpRequest: complete request received. prefix_sz = 293, request-line-size=77, mime-header-size=216, mime header block:
Host: download.docker.com
Accept: text/*
User-Agent: Debian APT-HTTP/1.3 (2.4.12) non-interactive
Via: 1.1 pkg-proxy (squid/6.10)
X-Forwarded-For: 10.2.59.102
Cache-Control: max-age=0
Connection: keep-alive


----------
2024/07/10 18:24:44.031 kid1| 87,3| clientStream.cc(139) clientStreamInsertHead: clientStreamInsertHead: Inserted node 0x5651b6c14538 with data 0x5651b379ecb0 after head
2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 86400
2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(1767) add: 0x5651b379dc40*3 to 0/0
2024/07/10 18:24:44.031 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x5651b328cb80 add request 1 0x5651b379dc40*4
2024/07/10 18:24:44.031 kid1| 23,3| Uri.cc(446) parse: Split URL 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease' into proto='https', host='download.docker.com', port='443', path='/linux/ubuntu/dists/jammy/InRelease'
2024/07/10 18:24:44.031 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(702) clientSetKeepaliveFlag: http_ver = HTTP/1.1
2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(703) clientSetKeepaliveFlag: method = GET
2024/07/10 18:24:44.031 kid1| 85,3| client_side_request.cc(123) ClientRequestContext: ClientRequestContext constructed, this=0x5651b667b8b8
2024/07/10 18:24:44.031 kid1| 83,3| client_side_request.cc(1709) doCallouts: Doing calloutContext->hostHeaderVerify()
2024/07/10 18:24:44.031 kid1| 85,3| client_side_request.cc(607) hostHeaderVerify: validate host=download.docker.com, port=0, portStr=NULL
2024/07/10 18:24:44.031 kid1| 85,3| client_side_request.cc(621) hostHeaderVerify: validate skipped.
2024/07/10 18:24:44.031 kid1| 83,3| client_side_request.cc(1716) doCallouts: Doing calloutContext->clientAccessCheck()
2024/07/10 18:24:44.031 kid1| 28,3| Checklist.cc(69) preCheck: 0x5651b56d0d38 checking slow rules
2024/07/10 18:24:44.032 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' found
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: follow_x_forwarded_for#1 = 1
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: follow_x_forwarded_for = 1
2024/07/10 18:24:44.032 kid1| 28,3| Checklist.cc(62) markFinished: 0x5651b56d0d38 answer DENIED for match
2024/07/10 18:24:44.032 kid1| 28,3| Checklist.cc(162) checkCallback: ACLChecklist::checkCallback: 0x5651b56d0d38 answer=DENIED
2024/07/10 18:24:44.032 kid1| 28,3| Checklist.cc(69) preCheck: 0x5651b5f334e8 checking slow rules
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: Safe_ports = 1
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: !Safe_ports = 0
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#1 = 0
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#2 = 0
2024/07/10 18:24:44.032 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: localhost = 0
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#3 = 0
2024/07/10 18:24:44.032 kid1| 28,3| RegexData.cc(50) match: checking 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: manager = 0
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#4 = 0
2024/07/10 18:24:44.032 kid1| 14,3| ipcache.cc(733) ipcache_gethostbyname: 'download.docker.com', flags=1
2024/07/10 18:24:44.032 kid1| 14,3| ipcache.cc(314) ipcacheRelease: ipcacheRelease: Releasing entry for 'download.docker.com'
2024/07/10 18:24:44.032 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
2024/07/10 18:24:44.032 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
2024/07/10 18:24:44.032 kid1| 78,3| dns_internal.cc(1793) idnsALookup: idnsALookup: buf is 37 bytes for download.docker.com, id = 0xc228
2024/07/10 18:24:44.032 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to X.X.X.X:53 using FD 10 using Port 52871
2024/07/10 18:24:44.032 kid1| 78,3| dns_internal.cc(1729) idnsSendSlaveAAAAQuery: buf is 48 bytes for download.docker.com, id = 0x798c
2024/07/10 18:24:44.032 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to X.X.X.X:53 using FD 10 using Port 52871
2024/07/10 18:24:44.032 kid1| 28,3| DestinationIp.cc(78) match: can't yet compare 'to_localhost' ACL for download.docker.com
2024/07/10 18:24:44.032 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: to_localhost = -1 async
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#5 = -1 async
2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access = -1 async
2024/07/10 18:24:44.048 kid1| 78,3| dns_internal.cc(1320) idnsRead: idnsRead: starting with FD 10
2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1366) idnsRead: idnsRead: FD 10: received 144 bytes from X.X.X.X:53
2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1173) idnsGrokReply: idnsGrokReply: QID 0xc228, 5 answers
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 5 answers for download.docker.com
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #1 108.138.7.18
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #2 108.138.7.33
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #3 108.138.7.48
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #4 108.138.7.88
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 5 answers for download.docker.com
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #1 108.138.7.18
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #2 108.138.7.33
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #3 108.138.7.48
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #4 108.138.7.88
2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1320) idnsRead: idnsRead: starting with FD 10
2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1366) idnsRead: idnsRead: FD 10: received 315 bytes from X.X.X.X:53
2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1173) idnsGrokReply: idnsGrokReply: QID 0x798c, 9 answers
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 9 answers for download.docker.com
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #5 [2600:9000:2490:2200:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #6 [2600:9000:2490:3600:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #7 [2600:9000:2490:7000:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #8 [2600:9000:2490:d600:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #9 [2600:9000:2490:5a00:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #10 [2600:9000:2490:6600:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #11 [2600:9000:2490:b600:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #12 [2600:9000:2490:aa00:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(587) ipcacheHandleReply: done with download.docker.com: 108.138.7.18 #1/12-0
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 9 answers for download.docker.com
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #5 [2600:9000:2490:2200:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #6 [2600:9000:2490:3600:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #7 [2600:9000:2490:7000:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #8 [2600:9000:2490:d600:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #9 [2600:9000:2490:5a00:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #10 [2600:9000:2490:6600:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #11 [2600:9000:2490:b600:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #12 [2600:9000:2490:aa00:3:db06:4200:93a1]
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(587) ipcacheHandleReply: done with download.docker.com: 108.138.7.18 #1/12-0
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(314) ipcacheRelease: ipcacheRelease: Releasing entry for 'download.docker.com'
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(733) ipcache_gethostbyname: 'download.docker.com', flags=1
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.18' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.33' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.48' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.88' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:2200:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:3600:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:7000:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:d600:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:5a00:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:6600:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:b600:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:aa00:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: to_localhost = 0
2024/07/10 18:24:44.049 kid1| 28,3| InnerNode.cc(100) resumeMatchingAt: checked: http_access#5 = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: PURGE = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#6 = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: PURGE = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#7 = 0
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: localhost = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#8 = 0
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: nocnet = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#9 = 0
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: EXTERNAL_DEV_CLIENTS = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#10 = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#11 = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#12 = 0
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#13 = 0
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#14 = 0
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#15 = 0
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#16 = 0
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#17 = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: Safe_ports = 1
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: !Safe_ports = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#18 = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#19 = 0
2024/07/10 18:24:44.049 kid1| 28,3| RegexData.cc(50) match: checking '/linux/ubuntu/dists/jammy/InRelease'
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: worm = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#20 = 0
2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(733) ipcache_gethostbyname: 'download.docker.com', flags=1
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.18' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.33' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.48' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.88' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:2200:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:3600:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:7000:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:d600:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:5a00:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:6600:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:b600:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:aa00:3:db06:4200:93a1]' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: SEUCHEN_IPS = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#21 = 0
2024/07/10 18:24:44.049 kid1| 28,3| DomainData.cc(110) match: aclMatchDomainList: checking 'download.docker.com'
2024/07/10 18:24:44.049 kid1| 28,3| DomainData.cc(115) match: aclMatchDomainList: 'download.docker.com' NOT found
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: SEUCHEN_DOMAINS = 0
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#22 = 0
2024/07/10 18:24:44.049 kid1| 28,3| RegexData.cc(50) match: checking 'download.docker.com'
2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: SEUCHEN_DOMAINS_REGEX = 0
2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: http_access#23 = 0
2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: http_access#24 = 0
2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' found
2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: REPOSITORY-CLIENTS = 1
2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(110) match: aclMatchDomainList: checking 'download.docker.com'
2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(115) match: aclMatchDomainList: 'download.docker.com' found
2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: REPOSITORY-ZIELE = 1
2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: http_access#25 = 1
2024/07/10 18:24:44.050 kid1| 28,3| InnerNode.cc(100) resumeMatchingAt: checked: http_access = 1
2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(62) markFinished: 0x5651b5f334e8 answer ALLOWED for match
2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(162) checkCallback: ACLChecklist::checkCallback: 0x5651b5f334e8 answer=ALLOWED
2024/07/10 18:24:44.050 kid1| 85,2| client_side_request.cc(715) clientAccessCheckDone: The request GET https://download.docker.com/linux/ubuntu/dists/jammy/InRelease is ALLOWED; last ACL checked: REPOSITORY-ZIELE
2024/07/10 18:24:44.050 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
2024/07/10 18:24:44.050 kid1| 83,3| client_side_request.cc(1744) doCallouts: Doing calloutContext->clientAccessCheck2()
2024/07/10 18:24:44.050 kid1| 85,2| client_side_request.cc(693) clientAccessCheck2: No adapted_http_access configuration. default: ALLOW
2024/07/10 18:24:44.050 kid1| 85,2| client_side_request.cc(715) clientAccessCheckDone: The request GET https://download.docker.com/linux/ubuntu/dists/jammy/InRelease is ALLOWED; last ACL checked: REPOSITORY-ZIELE
2024/07/10 18:24:44.050 kid1| 83,3| client_side_request.cc(1762) doCallouts: Doing clientInterpretRequestHeaders()
2024/07/10 18:24:44.050 kid1| 85,3| client_side_request.cc(117) ~ClientRequestContext: ClientRequestContext destructed, this=0x5651b667b8b8
2024/07/10 18:24:44.050 kid1| 83,3| client_side_request.cc(1856) doCallouts: calling processRequest()
2024/07/10 18:24:44.050 kid1| 87,3| clientStream.cc(178) clientStreamRead: clientStreamRead: Calling 1 with cbdata 0x5651b379fd80 from node 0x5651b6c14538
2024/07/10 18:24:44.050 kid1| 73,3| HttpRequest.cc(742) storeId: sent back effectiveRequestUrl: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 20,3| Controller.cc(429) peek: D3522EE27FB0ED7004DD594AF7674667
2024/07/10 18:24:44.050 kid1| 85,3| client_side_reply.cc(1523) identifyFoundObject: StoreEntry is NULL -  MISS
2024/07/10 18:24:44.050 kid1| 20,3| store.cc(731) storeCreatePureEntry: storeCreateEntry: 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'
2024/07/10 18:24:44.050 kid1| 20,3| MemObject.cc(99) MemObject: MemObject constructed, this=0x5651b3ae4fc0
2024/07/10 18:24:44.050 kid1| 88,3| MemObject.cc(82) setUris: 0x5651b3ae4fc0 storeId: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: storeCreateEntry locked key [null_store_key] e:=V/0x5651b365e210*1
2024/07/10 18:24:44.050 kid1| 20,3| store.cc(537) setPrivateKey: 00 e:=V/0x5651b365e210*1
2024/07/10 18:24:44.050 kid1| 20,3| store.cc(413) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x5651b365e210*1 key '8349000000000000D107000001000000'
2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: store_client locked key 8349000000000000D107000001000000 e:=IV/0x5651b365e210*2
2024/07/10 18:24:44.050 kid1| 90,3| store_client.cc(243) copy: store_client::copy: 8349000000000000D107000001000000, from 0, for length 4096, cb 1, cbdata 0x5651b379ece8
2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: store_client::copy locked key 8349000000000000D107000001000000 e:=IV/0x5651b365e210*3
2024/07/10 18:24:44.050 kid1| 90,3| store_client.cc(343) storeClientCopy2: storeClientCopy2: 8349000000000000D107000001000000
2024/07/10 18:24:44.050 kid1| 90,3| store_client.cc(390) doCopy: store_client::doCopy: Waiting for more
2024/07/10 18:24:44.050 kid1| 20,3| store.cc(458) unlock: store_client::copy unlocking key 8349000000000000D107000001000000 e:=IV/0x5651b365e210*3
2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(69) preCheck: 0x7ffef6c09e30 checking fast rules
2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181:59100' found
2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: miss_access#1 = 1
2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: miss_access = 1
2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(62) markFinished: 0x7ffef6c09e30 answer ALLOWED for match
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(373) Start: 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'
2024/07/10 18:24:44.050 kid1| 17,2| FwdState.cc(133) FwdState: Forwarding client request conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1, url=https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: FwdState locked key 8349000000000000D107000001000000 e:=IV/0x5651b365e210*3
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(140) FwdState: FwdState constructed, this=0x5651b695faf8
2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(309) peerSelect: e:=IV/0x5651b365e210*3 https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: peerSelect locked key 8349000000000000D107000001000000 e:=IV/0x5651b365e210*4
2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(612) selectMore: GET download.docker.com
2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(617) selectMore: direct = DIRECT_UNKNOWN (always_direct to be checked)
2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(69) preCheck: 0x5651b56d0d38 checking slow rules
2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' found
2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: always_direct#1 = 1
2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: always_direct = 1
2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(62) markFinished: 0x5651b56d0d38 answer ALLOWED for match
2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(162) checkCallback: ACLChecklist::checkCallback: 0x5651b56d0d38 answer=ALLOWED
2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(373) checkAlwaysDirectDone: ALLOWED
2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(379) checkAlwaysDirectDone: direct = DIRECT_YES (always_direct allow)
2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(612) selectMore: GET download.docker.com
2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(1102) addSelection: adding HIER_DIRECT#download.docker.com
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(460) resolveSelected: Find IP destination for: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease' via download.docker.com
2024/07/10 18:24:44.050 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482176 local=0.0.0.0 remote=108.138.7.18:443 HIER_DIRECT flags=1, destination #1 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482176 local=0.0.0.0 remote=108.138.7.18:443 HIER_DIRECT flags=1
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(1124) connectStart: 1+ paths to https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482177 local=0.0.0.0 remote=108.138.7.33:443 HIER_DIRECT flags=1, destination #2 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482177 local=0.0.0.0 remote=108.138.7.33:443 HIER_DIRECT flags=1
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482178 local=0.0.0.0 remote=108.138.7.48:443 HIER_DIRECT flags=1, destination #3 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482178 local=0.0.0.0 remote=108.138.7.48:443 HIER_DIRECT flags=1
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482179 local=0.0.0.0 remote=108.138.7.88:443 HIER_DIRECT flags=1, destination #4 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482179 local=0.0.0.0 remote=108.138.7.88:443 HIER_DIRECT flags=1
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482180 local=[::] remote=[2600:9000:2490:2200:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #5 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482180 local=[::] remote=[2600:9000:2490:2200:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482181 local=[::] remote=[2600:9000:2490:3600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #6 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482181 local=[::] remote=[2600:9000:2490:3600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482182 local=[::] remote=[2600:9000:2490:7000:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #7 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482182 local=[::] remote=[2600:9000:2490:7000:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482183 local=[::] remote=[2600:9000:2490:d600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #8 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482183 local=[::] remote=[2600:9000:2490:d600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482184 local=[::] remote=[2600:9000:2490:5a00:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #9 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482184 local=[::] remote=[2600:9000:2490:5a00:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482185 local=[::] remote=[2600:9000:2490:6600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #10 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482185 local=[::] remote=[2600:9000:2490:6600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482186 local=[::] remote=[2600:9000:2490:b600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #11 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482186 local=[::] remote=[2600:9000:2490:b600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482187 local=[::] remote=[2600:9000:2490:aa00:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #12 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482187 local=[::] remote=[2600:9000:2490:aa00:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(479) resolveSelected: PeerSelector64364 found all 12 destinations for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(480) resolveSelected:   always_direct = ALLOWED
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(481) resolveSelected:    never_direct = DUNNO
2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(482) resolveSelected:        timedout = 0
2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(241) ~PeerSelector: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.050 kid1| 20,3| store.cc(458) unlock: peerSelect unlocking key 8349000000000000D107000001000000 e:=p2IV/0x5651b365e210*4
2024/07/10 18:24:44.050 kid1| 48,3| pconn.cc(474) popStored: lookup for key {108.138.7.18:443/download.docker.com} failed.
2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(69) preCheck: 0x7ffef6c0a460 checking fast ACLs
2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(110) match: aclMatchDomainList: checking 'download.docker.com'
2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(115) match: aclMatchDomainList: 'download.docker.com' NOT found
2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: SKIP_PALO_DOMAINS_FAST = 0
2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: !SKIP_PALO_DOMAINS_FAST = 1
2024/07/10 18:24:44.051 kid1| 28,3| Acl.cc(175) matches: checked: (tcp_outgoing_mark 0x14 line) = 1
2024/07/10 18:24:44.051 kid1| 28,3| Acl.cc(175) matches: checked: tcp_outgoing_mark 0x14 = 1
2024/07/10 18:24:44.051 kid1| 28,3| Checklist.cc(62) markFinished: 0x7ffef6c0a460 answer ALLOWED for match
2024/07/10 18:24:44.051 kid1| 17,3| FwdState.cc(1568) GetMarkingsToServer: from 0.0.0.0 tos 0 netfilter mark 20
2024/07/10 18:24:44.051 kid1| 5,3| ConnOpener.cc(42) ConnOpener: will connect to conn482189 local=0.0.0.0 remote=108.138.7.18:443 HIER_DIRECT flags=1 with 60 timeout
2024/07/10 18:24:44.051 kid1| 50,3| comm.cc(378) comm_openex: comm_openex: Attempt open socket for: 0.0.0.0
2024/07/10 18:24:44.051 kid1| 50,3| comm.cc(420) comm_openex: comm_openex: Opened socket conn482190 local=0.0.0.0 remote=[::] FD 19 flags=1 : family=2, type=1, protocol=6
2024/07/10 18:24:44.051 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 19 download.docker.com
2024/07/10 18:24:44.051 kid1| 50,3| QosConfig.cc(581) setSockNfmark: for FD 19 to 20
2024/07/10 18:24:44.051 kid1| 5,3| ConnOpener.cc(312) createFd: conn482189 local=0.0.0.0 remote=108.138.7.18:443 HIER_DIRECT flags=1 will timeout in 60
2024/07/10 18:24:44.058 kid1| 83,2| Io.cc(161) Handshake: handshake IN: Unknown Handshake packet
2024/07/10 18:24:44.058 kid1| 83,2| Io.cc(163) Handshake: handshake OUT: CLIENT HELLO
2024/07/10 18:24:44.058 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482189 local=X.X.X.X:36718 remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1 timeout 60
2024/07/10 18:24:44.064 kid1| 83,2| Io.cc(161) Handshake: handshake IN: Unknown Handshake packet
2024/07/10 18:24:44.064 kid1| 83,2| Io.cc(163) Handshake: handshake OUT: CLIENT HELLO
2024/07/10 18:24:44.064 kid1| 83,2| PeerConnector.cc(279) handleNegotiationResult: ERROR: Cannot establish a TLS connection to conn482189 local=X.X.X.X:36718 remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1:
    problem: failure
    detail: SQUID_TLS_ERR_CONNECT+GNUTLS_E_FATAL_ALERT_RECEIVED
2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(625) commUnsetConnTimeout: Remove timeout for conn482189 local=X.X.X.X:36718 remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1
2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482189 local=X.X.X.X:36718 remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1 timeout -1
2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(850) _comm_close: start closing FD 19 by Connection.cc:108
2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(586) commUnsetFdTimeout: Remove timeout for FD 19
2024/07/10 18:24:44.064 kid1| 83,3| Session.cc(36) tls_read_method: started for session=0x5651b404d2c0
2024/07/10 18:24:44.064 kid1| 51,3| fd.cc(93) fd_close: fd_close FD 19 server https start
2024/07/10 18:24:44.064 kid1| 17,3| FwdState.cc(471) fail: ERR_SECURE_CONNECT_FAIL "Service Unavailable"
	https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
2024/07/10 18:24:44.064 kid1| 17,3| FwdState.cc(781) retryOrBail: re-forwarding (1 tries, 0 secs)


>-----Urspr?ngliche Nachricht-----
>Von: Alex Rousskov <rousskov at measurement-factory.com>
>Gesendet: Mittwoch, 10. Juli 2024 14:50
>An: squid-users at lists.squid-cache.org
>Cc: Fiehe, Christoph <c.fiehe at eurodata.de>
>Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>
>On 2024-07-09 18:25, Fiehe, Christoph wrote:
>
>> I hope that somebody has an idea, what I am doing wrong.
>
>AFAICT from the debugging log, it is your parent proxy that returns an
>ERR_SECURE_CONNECT_FAIL error page in response to a seemingly valid
>"HEAD https://..." request. Can you ask their admin to investigate? You
>may also recommend that they upgrade from Squid v4 that has many known
>security vulnerabiities.
>
>If parent is uncooperative, you can try to reproduce the problem by
>temporary installing your own parent Squid instance and configuring your
>child Squid to use that instead.
>
>HTH,
>
>Alex.
>P.S. Unlike Amos, I do not see serious conceptual problems with
>rewriting request target scheme (as a temporary compatibility measure).
>It may not always work, for various reasons, but it does not necessarily
>make things worse (and may make things better).
>
>
>
>
>I try to build a generic package proxy with Squid and need the feature
>to rewrite (not redirect) a HTTP request to a package repository
>transparently to a HTTPS-based package source. I was able to get Jesred
>working and defined the following rewrite rule:
>>
>> regex ^http:\/\/download\.docker\.com(.*)$ https://download.docker.com\1
>>
>> I had to use a parent upstream proxy. In my test case the rule gets applied
>successfully:
>>
>> 1720558404.106 10.2.59.102/molecule-ubuntu-jammy.lx.mycompany.de
>http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/l
>inux/ubuntu/dists/jammy/InRelease]
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease 2
>>
>> I have validated that the returned URL is correct and that the resource is accessible
>via my upstream proxy.
>>
>> But at the very end, the client receives a 503 error code. I have set "debug_options
>ALL,3" and this gives the log:
>>
>> [...]
>> 2024/07/09 23:35:40.115 kid1| 11,2| client_side.cc(1333) parseHttpRequest: HTTP Client
>REQUEST:
>> ---------
>> HEAD
>http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/l
>inux/ubuntu/dists/jammy/InRelease] HTTP/1.1
>> Host: download.docker.com
>> User-Agent: curl/7.81.0
>> Accept: */*
>> Proxy-Connection: Keep-Alive
>>
>>
>> ----------
>> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(1364) parseHttpRequest: complete
>request received. prefix_sz = 174, request-line-size=77, mime-header-size=97, mime header
>block:
>> Host: download.docker.com
>> User-Agent: curl/7.81.0
>> Accept: */*
>> Proxy-Connection: Keep-Alive
>>
>>
>> ----------
>> 2024/07/09 23:35:40.115 kid1| 87,3| clientStream.cc(139) clientStreamInsertHead:
>clientStreamInsertHead: Inserted node 0x5c3ba4154308 with data 0x5c3ba4152950 after head
>> 2024/07/09 23:35:40.115 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn9
>local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1 timeout 86400
>> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(1767) add: 0x5c3ba41518e0*3 to 0/0
>> 2024/07/09 23:35:40.115 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x5c3ba41501f0 add
>request 1 0x5c3ba41518e0*4
>> 2024/07/09 23:35:40.115 kid1| 23,3| Uri.cc(446) parse: Split URL
>'http://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[http://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease'] into proto='http', host='download.docker.com',
>port='80', path='/linux/ubuntu/dists/jammy/InRelease'
>> 2024/07/09 23:35:40.115 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>'download.docker.com': Name or service not known
>> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(702) clientSetKeepaliveFlag: http_ver
>= HTTP/1.1
>> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(703) clientSetKeepaliveFlag: method =
>HEAD
>> 2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(122) ClientRequestContext:
>ClientRequestContext constructed, this=0x5c3ba4154e78
>> 2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1708) doCallouts: Doing
>calloutContext->hostHeaderVerify()
>> 2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(606) hostHeaderVerify:
>validate host=download.docker.com, port=0, portStr=NULL
>> 2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(620) hostHeaderVerify:
>validate skipped.
>> 2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1715) doCallouts: Doing
>calloutContext->clientAccessCheck()
>> 2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba41552d8 checking
>slow rules
>> 2024/07/09 23:35:40.115 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.102:56466'
>found
>> 2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>> 2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: http_access#1 = 1
>> 2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: http_access = 1
>> 2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba41552d8 answer
>ALLOWED for match
>> 2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(162) checkCallback:
>ACLChecklist::checkCallback: 0x5c3ba41552d8 answer=ALLOWED
>> 2024/07/09 23:35:40.115 kid1| 85,2| client_side_request.cc(714) clientAccessCheckDone:
>The request HEAD
>http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/l
>inux/ubuntu/dists/jammy/InRelease] is ALLOWED; last ACL checked: all
>> 2024/07/09 23:35:40.115 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
>> 2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1735) doCallouts: Doing
>calloutContext->clientRedirectStart()
>> 2024/07/09 23:35:40.115 kid1| 78,3| dns_internal.cc(1836) idnsPTRLookup: idnsPTRLookup:
>buf is 42 bytes for 10.2.59.102, id = 0x8d95
>> 2024/07/09 23:35:40.115 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto:
>Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
>> 2024/07/09 23:35:40 kid1| Starting new redirector helpers...
>> current master transaction: master54
>> 2024/07/09 23:35:40 kid1| helperOpenServers: Starting 1/3 'jesred' processes
>> current master transaction: master54
>> 2024/07/09 23:35:40.115 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 17 IPC UNIX STREAM
>Parent
>> 2024/07/09 23:35:40.115 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 19 IPC UNIX STREAM
>Parent
>> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(212) ipcCreate: ipcCreate: prfd FD 17
>> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(213) ipcCreate: ipcCreate: pwfd FD 17
>> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(214) ipcCreate: ipcCreate: crfd FD 19
>> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(215) ipcCreate: ipcCreate: cwfd FD 19
>> 2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(850) _comm_close: start closing FD 19 by
>ipc.cc:271
>> 2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(586) commUnsetFdTimeout: Remove timeout for
>FD 19
>> 2024/07/09 23:35:40.116 kid1| 21,3| tools.cc(561) leave_suid: leave_suid: PID 503746
>called
>> 2024/07/09 23:35:40.116 kid1| 21,3| tools.cc(651) no_suid: no_suid: PID 503746 giving up
>root privileges forever
>> 2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(586) commUnsetFdTimeout: Remove timeout for
>FD 17
>> 2024/07/09 23:35:40.117 kid1| 84,3| helper.cc(1310) GetFirstAvailable:
>GetFirstAvailable: Least-loaded helper is fully loaded!
>> 2024/07/09 23:35:40.117 kid1| 51,3| fd.cc(93) fd_close: fd_close FD 19 IPC UNIX STREAM
>Parent
>> 2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting
>with FD 11
>> 2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11:
>received 92 bytes from 127.0.0.53:53
>> 2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply:
>QID 0x8d95, 1 answers
>> 2024/07/09 23:35:40.117 kid1| 35,3| fqdncache.cc(336) fqdncacheParse: fqdncacheParse: 1
>answers for '10.2.59.102'
>> 2024/07/09 23:35:40.117 kid1| 5,3| IoCallback.cc(112) finish: called for conn11
>local=[::] remote=[::] FD 17 flags=1 (0, 0)
>> 2024/07/09 23:35:40.125 kid1| 5,3| Read.cc(148) HandleRead: FD 17, size 32767, retval
>80, errno 0
>> 2024/07/09 23:35:40.125 kid1| 5,3| IoCallback.cc(112) finish: called for conn10
>local=[::] remote=[::] FD 17 flags=1 (0, 0)
>> 2024/07/09 23:35:40.125 kid1| 84,3| helper.cc(1022) helperHandleRead: helperHandleRead:
>end of reply found
>> 2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(41) finalize: Parsing helper buffer
>> 2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(59) finalize: Buff length is larger than 2
>> 2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(63) finalize: helper Result = OK
>> 2024/07/09 23:35:40.125 kid1| 23,3| Uri.cc(446) parse: Split URL
>'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>om/linux/ubuntu/dists/jammy/InRelease'] into proto='https', host='download.docker.com',
>port='443', path='/linux/ubuntu/dists/jammy/InRelease'
>> 2024/07/09 23:35:40.125 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>'download.docker.com': Name or service not known
>> 2024/07/09 23:35:40.125 kid1| 61,2| client_side_request.cc(1235) clientRedirectDone:
>URL-rewriter diverts URL from
>http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/l
>inux/ubuntu/dists/jammy/InRelease] to
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease]
>> 2024/07/09 23:35:40.125 kid1| 83,3| client_side_request.cc(1743) doCallouts: Doing
>calloutContext->clientAccessCheck2()
>> 2024/07/09 23:35:40.125 kid1| 85,2| client_side_request.cc(692) clientAccessCheck2: No
>adapted_http_access configuration. default: ALLOW
>> 2024/07/09 23:35:40.125 kid1| 85,2| client_side_request.cc(714) clientAccessCheckDone:
>The request HEAD
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease] is ALLOWED; last ACL checked: all
>> 2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1761) doCallouts: Doing
>clientInterpretRequestHeaders()
>> 2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1770) doCallouts: Doing
>calloutContext->checkNoCache()
>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba41552d8 checking
>slow rules
>> 2024/07/09 23:35:40.126 kid1| 28,3| RegexData.cc(50) match: checking
>'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>om/linux/ubuntu/dists/jammy/InRelease']
>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: no_cache = 0
>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache#1 = 0
>> 2024/07/09 23:35:40.126 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.102:56466'
>found
>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache#2 = 1
>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache = 1
>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba41552d8 answer
>ALLOWED for match
>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(162) checkCallback:
>ACLChecklist::checkCallback: 0x5c3ba41552d8 answer=ALLOWED
>> 2024/07/09 23:35:40.126 kid1| 85,3| client_side_request.cc(116) ~ClientRequestContext:
>ClientRequestContext destructed, this=0x5c3ba4154e78
>> 2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1855) doCallouts: calling
>processRequest()
>> 2024/07/09 23:35:40.126 kid1| 87,3| clientStream.cc(178) clientStreamRead:
>clientStreamRead: Calling 1 with cbdata 0x5c3ba4153e70 from node 0x5c3ba4154308
>> 2024/07/09 23:35:40.126 kid1| 73,3| HttpRequest.cc(742) storeId: sent back
>effectiveRequestUrl:
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease]
>> 2024/07/09 23:35:40.126 kid1| 20,3| Controller.cc(429) peek:
>DE850794EBC405A27A7718F51795E32A
>> 2024/07/09 23:35:40.126 kid1| 73,3| HttpRequest.cc(742) storeId: sent back
>effectiveRequestUrl:
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease]
>> 2024/07/09 23:35:40.126 kid1| 20,3| Controller.cc(429) peek:
>D3522EE27FB0ED7004DD594AF7674667
>> 2024/07/09 23:35:40.126 kid1| 85,3| client_side_reply.cc(1523) identifyFoundObject:
>StoreEntry is NULL - MISS
>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(730) storeCreatePureEntry:
>storeCreateEntry:
>'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>om/linux/ubuntu/dists/jammy/InRelease']
>> 2024/07/09 23:35:40.126 kid1| 20,3| MemObject.cc(99) MemObject: MemObject constructed,
>this=0x5c3ba416ef10
>> 2024/07/09 23:35:40.126 kid1| 88,3| MemObject.cc(82) setUris: 0x5c3ba416ef10 storeId:
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease]
>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: storeCreateEntry locked key
>[null_store_key] e:=V/0x5c3ba416ee90*1
>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(536) setPrivateKey: 00
>e:=V/0x5c3ba416ee90*1
>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(412) hashInsert: StoreEntry::hashInsert:
>Inserting Entry e:=IV/0x5c3ba416ee90*1 key '020000000000000061AF070001000000'
>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: store_client locked key
>020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*2
>> 2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(243) copy: store_client::copy:
>020000000000000061AF070001000000, from 0, for length 4096, cb 1, cbdata 0x5c3ba4152dd8
>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: store_client::copy locked key
>020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
>> 2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(343) storeClientCopy2:
>storeClientCopy2: 020000000000000061AF070001000000
>> 2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(390) doCopy: store_client::doCopy:
>Waiting for more
>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(457) unlock: store_client::copy unlocking
>key 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(373) Start:
>'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>om/linux/ubuntu/dists/jammy/InRelease']
>> 2024/07/09 23:35:40.126 kid1| 17,2| FwdState.cc(133) FwdState: Forwarding client request
>conn9 local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1,
>url=https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker
>.com/linux/ubuntu/dists/jammy/InRelease]
>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: FwdState locked key
>020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(140) FwdState: FwdState constructed,
>this=0x5c3ba416fa18
>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(309) peerSelect:
>e:=IV/0x5c3ba416ee90*3
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease]
>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: peerSelect locked key
>020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*4
>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(612) selectMore: HEAD
>download.docker.com
>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(626) selectMore: direct =
>DIRECT_UNKNOWN (never_direct to be checked)
>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba4170638 checking
>slow rules
>> 2024/07/09 23:35:40.126 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.102:56466'
>found
>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: never_direct#1 = 1
>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: never_direct = 1
>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba4170638 answer
>ALLOWED for match
>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(162) checkCallback:
>ACLChecklist::checkCallback: 0x5c3ba4170638 answer=ALLOWED
>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(345) checkNeverDirectDone: ALLOWED
>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(351) checkNeverDirectDone: direct =
>DIRECT_NO (never_direct allow)
>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(612) selectMore: HEAD
>download.docker.com
>> 2024/07/09 23:35:40.126 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname:
>ipcache_gethostbyname: 'download.docker.com', flags=0
>> 2024/07/09 23:35:40.126 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>'download.docker.com': Name or service not known
>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(286) peerSelectIcpPing:
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease]
>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(283) neighborsCount: neighborsCount: 0
>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(297) peerSelectIcpPing: counted 0
>neighbors
>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(833) selectSomeParent: HEAD
>download.docker.com
>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(350) getRoundRobinParent: returning
>[nil]
>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(403) getWeightedRoundRobinParent:
>returning [nil]
>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(309) getFirstUpParent: returning
>212.89.128.96
>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1102) addSelection: adding
>FIRSTUP_PARENT/212.89.128.96
>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1095) addSelection: skipping
>ANY_OLD_PARENT/212.89.128.96; have FIRSTUP_PARENT/212.89.128.96
>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(493) getDefaultParent: returning
>212.89.128.96
>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1095) addSelection: skipping
>DEFAULT_PARENT/212.89.128.96; have FIRSTUP_PARENT/212.89.128.96
>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(460) resolveSelected: Find IP
>destination for:
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.co
>m/linux/ubuntu/dists/jammy/InRelease'] via 212.89.128.96
>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector1 found
>conn12 local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1, destination #1 for
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease]
>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct =
>DENIED
>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct =
>ALLOWED
>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(610) noteDestination: conn12
>local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1
>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(1124) connectStart: 1+ paths to
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease]
>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(479) resolveSelected: PeerSelector1
>found all 1 destinations for
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease]
>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(480) resolveSelected: always_direct =
>DENIED
>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(481) resolveSelected: never_direct =
>ALLOWED
>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(482) resolveSelected: timedout = 0
>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(241) ~PeerSelector:
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease]
>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(457) unlock: peerSelect unlocking key
>020000000000000061AF070001000000 e:=p2IV/0x5c3ba416ee90*4
>> 2024/07/09 23:35:40.126 kid1| 48,3| pconn.cc(474) popStored: lookup for key
>{212.89.128.96:3128} failed.
>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(1568) GetMarkingsToServer: from 0.0.0.0
>tos 0 netfilter mark 0
>> 2024/07/09 23:35:40.126 kid1| 5,3| ConnOpener.cc(42) ConnOpener: will connect to conn14
>local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1 with 30 timeout
>> 2024/07/09 23:35:40.126 kid1| 50,3| comm.cc(378) comm_openex: comm_openex: Attempt open
>socket for: 0.0.0.0
>> 2024/07/09 23:35:40.126 kid1| 50,3| comm.cc(420) comm_openex: comm_openex: Opened socket
>conn15 local=0.0.0.0 remote=[::] FD 19 flags=1 : family=2, type=1, protocol=6
>> 2024/07/09 23:35:40.126 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 19
>> 2024/07/09 23:35:40.126 kid1| 5,3| ConnOpener.cc(312) createFd: conn14 local=0.0.0.0
>remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1 will timeout in 30
>> 2024/07/09 23:35:40.127 kid1| 17,3| FwdState.cc(1197) dispatch: conn9
>local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1: Fetching HEAD
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease]
>> 2024/07/09 23:35:40.127 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>'download.docker.com': Name or service not known
>> 2024/07/09 23:35:40.127 kid1| 78,3| dns_internal.cc(1793) idnsALookup: idnsALookup: buf
>is 37 bytes for download.docker.com, id = 0xe779
>> 2024/07/09 23:35:40.127 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto:
>Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
>> 2024/07/09 23:35:40.127 kid1| 78,3| dns_internal.cc(1729) idnsSendSlaveAAAAQuery: buf is
>37 bytes for download.docker.com, id = 0x8aee
>> 2024/07/09 23:35:40.127 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto:
>Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
>> 2024/07/09 23:35:40.127 kid1| 11,3| http.cc(2516) httpStart: HEAD
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease]
>> 2024/07/09 23:35:40.127 kid1| 20,3| store.cc(434) lock: Client locked key
>020000000000000061AF070001000000 e:=p2IV/0x5c3ba416ee90*4
>> 2024/07/09 23:35:40.127 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn14
>local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 timeout
>86400
>> 2024/07/09 23:35:40.127 kid1| 22,3| refresh.cc(636) getMaxAge: getMaxAge:
>'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>om/linux/ubuntu/dists/jammy/InRelease']
>> 2024/07/09 23:35:40.127 kid1| 11,2| http.cc(2472) sendRequest: HTTP Server conn14
>local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1
>> 2024/07/09 23:35:40.127 kid1| 11,2| http.cc(2473) sendRequest: HTTP Server REQUEST:
>> ---------
>> HEAD
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease] HTTP/1.1
>> Host: download.docker.com
>> User-Agent: curl/7.81.0
>> Accept: */*
>> Via: 1.1 pkg-proxy (squid/6.6)
>> X-Forwarded-For: 10.2.59.102
>> Cache-Control: max-age=0
>> Connection: keep-alive
>>
>>
>> ----------
>> 2024/07/09 23:35:40.127 kid1| 5,3| IoCallback.cc(112) finish: called for conn14
>local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 (0, 0)
>> 2024/07/09 23:35:40.127 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn14
>local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 timeout 900
>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting
>with FD 11
>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11:
>received 304 bytes from 127.0.0.53:53
>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply:
>QID 0x8aee, 9 answers
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(480) ipcacheParse: 9 answers for
>download.docker.com
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #1
>[2600:9000:2490:6c00:3:db06:4200:93a1]
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #2
>[2600:9000:2490:a600:3:db06:4200:93a1]
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #3
>[2600:9000:2490:9c00:3:db06:4200:93a1]
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #4
>[2600:9000:2490:6000:3:db06:4200:93a1]
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #5
>[2600:9000:2490:c00:3:db06:4200:93a1]
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #6
>[2600:9000:2490:5200:3:db06:4200:93a1]
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #7
>[2600:9000:2490:9a00:3:db06:4200:93a1]
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #8
>[2600:9000:2490:2c00:3:db06:4200:93a1]
>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting
>with FD 11
>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11:
>received 144 bytes from 127.0.0.53:53
>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply:
>QID 0xe779, 5 answers
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(480) ipcacheParse: 5 answers for
>download.docker.com
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #9
>108.138.7.33
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #10
>108.138.7.18
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #11
>108.138.7.88
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #12
>108.138.7.48
>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(586) ipcacheHandleReply: done with
>download.docker.com: [2600:9000:2490:6c00:3:db06:4200:93a1] #1/12-0
>> 2024/07/09 23:35:40.137 kid1| 38,3| net_db.cc(337) netdbSendPing: netdbSendPing: pinging
>download.docker.com
>> 2024/07/09 23:35:40.137 kid1| 37,2| IcmpSquid.cc(88) SendEcho: to
>[2600:9000:2490:6c00:3:db06:4200:93a1], opcode 3, len 19
>> 2024/07/09 23:35:40.137 pinger| 42,2| IcmpPinger.cc(198) Recv: Pass
>[2600:9000:2490:6c00:3:db06:4200:93a1] off to ICMPv6 module.
>> 2024/07/09 23:35:40 pinger| SendEcho ERROR: sending to ICMPv6 packet to
>[2600:9000:2490:6c00:3:db06:4200:93a1]: (101) Network is unreachable
>> 2024/07/09 23:35:40.138 pinger| 42,2| Icmp.cc(90) Log: pingerLog: 1720560940.138021
>[2600:9000:2490:6c00:3:db06:4200:93a1] 0
>> 2024/07/09 23:35:40.323 kid1| 5,3| IoCallback.cc(112) finish: called for conn14
>local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 (0, 0)
>> 2024/07/09 23:35:40.324 kid1| 5,3| Read.cc(93) ReadNow: conn14 local=10.2.59.103:39370
>remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1, size 65536, retval 348, errno 0
>> 2024/07/09 23:35:40.324 kid1| 11,3| http.cc(649) processReplyHeader: processReplyHeader:
>key '020000000000000061AF070001000000'
>> 2024/07/09 23:35:40.324 kid1| 11,2| http.cc(696) processReplyHeader: HTTP Server conn14
>local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1
>> 2024/07/09 23:35:40.324 kid1| 11,2| http.cc(697) processReplyHeader: HTTP Server
>RESPONSE:
>> ---------
>> HTTP/1.1 503 Service Unavailable
>> Server: squid/4.10
>> Mime-Version: 1.0
>> Date: Tue, 09 Jul 2024 21:35:40 GMT
>> Content-Type: text/html;charset=utf-8
>> Content-Length: 3879
>> X-Squid-Error: ERR_SECURE_CONNECT_FAIL 71
>> X-Cache: MISS from proxy-srv2
>> X-Cache-Lookup: MISS from proxy-srv2:3128
>> Via: 1.1 proxy-srv2 (squid/4.10)
>> Connection: keep-alive
>>
>> ----------
>> 2024/07/09 23:35:40.324 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
>> 2024/07/09 23:35:40.324 kid1| 20,3| store.cc(1693) replaceHttpReply:
>StoreEntry::replaceHttpReply:
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>/linux/ubuntu/dists/jammy/InRelease]
>> 2024/07/09 23:35:40.324 kid1| 11,3| http.cc(949) haveParsedReplyHeaders: HTTP CODE: 503
>>
>> Has anybody an idea what I can do to solve the issue?
>>
>> This is my configuration borrowed from squid-deb-proxy:
>>
>> # this file contains private networks (10.0.0.0/8, 172.16.0.0/12,
>> # 192.168.0.0/16) by default, you can add/remove additional allowed
>> # source networks in it to customize it for your setup
>> acl src_networks src "/etc/squid/acl/src-networks.acl"
>>
>> # this file contains the archive mirrors by default,
>> # if you use a different mirror, add it there
>> acl to_archive_mirrors dstdomain "/etc/squid/acl/archive-mirrors.acl"
>>
>> # Disable Cache for defined domains
>> acl no_cache url_regex "/etc/squid/acl/no-cache.acl"
>>
>> # this contains the package blacklist
>> acl blockedpkgs urlpath_regex "/etc/squid/pkg-blacklist-regexp.acl"
>>
>> # default to a different port than stock squid
>> http_port 8000
>>
>> # -------------------------------------------------
>> # settings below probably do not need customization
>>
>> # user visible name
>> visible_hostname pkg-proxy
>>
>> # we need a big cache, some debs are huge
>> maximum_object_size 512 MB
>>
>> # use a different dir than stock squid and default to 40G
>> cache_dir aufs /var/cache/squid 40000 16 256
>>
>> cache_peer 212.89.128.96 parent 3128 0 no-query default
>> never_direct allow all
>>
>> # use different logs
>> cache_access_log /var/log/squid/access.log
>> cache_log /var/log/squid/cache.log
>> cache_store_log /var/log/squid/store.log
>>
>> # tweaks to speed things up
>> cache_mem 200 MB
>> maximum_object_size_in_memory 10240 KB
>>
>> # pid
>> pid_filename /var/run/squid.pid
>>
>> # refresh pattern for debs and udebs
>> refresh_pattern deb$ 129600 100% 129600
>> refresh_pattern udeb$ 129600 100% 129600
>> refresh_pattern tar.gz$ 129600 100% 129600
>> refresh_pattern tar.xz$ 129600 100% 129600
>> refresh_pattern tar.bz2$ 129600 100% 129600
>>
>> # always refresh Packages and Release files
>> refresh_pattern \/(Packages|Sources)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims
>> refresh_pattern \/Release(|\.gpg)$ 0 0% 0 refresh-ims
>> refresh_pattern \/InRelease$ 0 0% 0 refresh-ims
>> refresh_pattern \/(Translation-.*)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims
>>
>> # handle meta-release and changelogs.ubuntu.com special
>> # (fine to have this on debian too)
>> refresh_pattern changelogs.ubuntu.com\/.* 0 1% 1
>>
>> # only allow connects to ports for http, https
>> acl SSL_ports port 443 563
>> acl Safe_ports port 80
>> acl Safe_ports port 443 563
>>
>> # only allow ports we trust
>> http_access deny !Safe_ports
>>
>> # do not allow to download from the pkg blacklist
>> http_access deny blockedpkgs
>>
>> # allow access only to official archive mirrors
>> # uncomment the third and fouth line to permit any unlisted domain
>> http_access deny !to_archive_mirrors
>>
>> # allow access from our network and localhost
>> http_access allow src_networks
>>
>> # And finally deny all other access to this proxy
>> http_access deny all
>>
>> # don't cache domains not listed in the mirrors file
>> # uncomment the third and fourth line to cache any unlisted domains
>> cache deny no_cache
>>
>> # And finally cache everything else
>> cache allow all
>>
>> url_rewrite_children 3 startup=0 idle=1 concurrency=1
>> url_rewrite_program /usr/lib/squid/jesred
>>
>> debug_options ALL,3
>>
>> Thanks a lot.
>>
>> Regards,
>> Christoph
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Wed Jul 10 16:55:34 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 10 Jul 2024 12:55:34 -0400
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <6bb89d7c58e34320b1eb15c1447e99d7@eurodata.de>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
 <6bb89d7c58e34320b1eb15c1447e99d7@eurodata.de>
Message-ID: <ca32f7f1-9123-47d4-a7ba-dfc40d0c6937@measurement-factory.com>

On 2024-07-10 12:42, Fiehe, Christoph wrote:

> In the next test case, I used a more modern upstream proxy server based von Squid 6.8 and enabled debugging.
> 
> The log shows the error SQUID_TLS_ERR_CONNECT+GNUTLS_E_FATAL_ALERT_RECEIVED. I am not sure, what I can do to prevent it from occurring

I cannot help with GnuTLS, but I can recommend using Squid built with 
OpenSSL libraries (./configure --with-openssl) instead of Squid built 
with GnuTLS.


HTH,

Alex.



> 2024/07/10 18:24:44.031 kid1| 5,2| TcpAcceptor.cc(214) doAccept: New connection on FD 12
> 2024/07/10 18:24:44.031 kid1| 5,2| TcpAcceptor.cc(316) acceptNext: connection on conn482169 local=[::]:3128 remote=[::] FD 12 flags=9
> 2024/07/10 18:24:44.031 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 16 HTTP Request
> 2024/07/10 18:24:44.031 kid1| 28,3| Eui48.cc(511) lookup: id=0x5651b3e6d558 10.2.59.181 NOT found
> 2024/07/10 18:24:44.031 kid1| 17,2| QosConfig.cc(162) getNfConnmark: QOS: Failed to retrieve connection mark: (-1) (2) No such file or directory (Destination 212.89.134.12:3128, source 10.2.59.181:59100)
> 2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 300
> 2024/07/10 18:24:44.031 kid1| 5,3| IoCallback.cc(112) finish: called for conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 (0, 0)
> 2024/07/10 18:24:44.031 kid1| 5,3| Read.cc(93) ReadNow: conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1, size 4096, retval 293, errno 0
> 2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 300
> 2024/07/10 18:24:44.031 kid1| 33,3| Pipeline.cc(43) back: Pipeline 0x5651b328cb80 empty
> 2024/07/10 18:24:44.031 kid1| 11,2| client_side.cc(1332) parseHttpRequest: HTTP Client conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1
> 2024/07/10 18:24:44.031 kid1| 11,2| client_side.cc(1333) parseHttpRequest: HTTP Client REQUEST:
> ---------
> GET https://download.docker.com/linux/ubuntu/dists/jammy/InRelease HTTP/1.1
> Host: download.docker.com
> Accept: text/*
> User-Agent: Debian APT-HTTP/1.3 (2.4.12) non-interactive
> Via: 1.1 pkg-proxy (squid/6.10)
> X-Forwarded-For: 10.2.59.102
> Cache-Control: max-age=0
> Connection: keep-alive
> 
> 
> ----------
> 2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(1364) parseHttpRequest: complete request received. prefix_sz = 293, request-line-size=77, mime-header-size=216, mime header block:
> Host: download.docker.com
> Accept: text/*
> User-Agent: Debian APT-HTTP/1.3 (2.4.12) non-interactive
> Via: 1.1 pkg-proxy (squid/6.10)
> X-Forwarded-For: 10.2.59.102
> Cache-Control: max-age=0
> Connection: keep-alive
> 
> 
> ----------
> 2024/07/10 18:24:44.031 kid1| 87,3| clientStream.cc(139) clientStreamInsertHead: clientStreamInsertHead: Inserted node 0x5651b6c14538 with data 0x5651b379ecb0 after head
> 2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 86400
> 2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(1767) add: 0x5651b379dc40*3 to 0/0
> 2024/07/10 18:24:44.031 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x5651b328cb80 add request 1 0x5651b379dc40*4
> 2024/07/10 18:24:44.031 kid1| 23,3| Uri.cc(446) parse: Split URL 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease' into proto='https', host='download.docker.com', port='443', path='/linux/ubuntu/dists/jammy/InRelease'
> 2024/07/10 18:24:44.031 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
> 2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(702) clientSetKeepaliveFlag: http_ver = HTTP/1.1
> 2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(703) clientSetKeepaliveFlag: method = GET
> 2024/07/10 18:24:44.031 kid1| 85,3| client_side_request.cc(123) ClientRequestContext: ClientRequestContext constructed, this=0x5651b667b8b8
> 2024/07/10 18:24:44.031 kid1| 83,3| client_side_request.cc(1709) doCallouts: Doing calloutContext->hostHeaderVerify()
> 2024/07/10 18:24:44.031 kid1| 85,3| client_side_request.cc(607) hostHeaderVerify: validate host=download.docker.com, port=0, portStr=NULL
> 2024/07/10 18:24:44.031 kid1| 85,3| client_side_request.cc(621) hostHeaderVerify: validate skipped.
> 2024/07/10 18:24:44.031 kid1| 83,3| client_side_request.cc(1716) doCallouts: Doing calloutContext->clientAccessCheck()
> 2024/07/10 18:24:44.031 kid1| 28,3| Checklist.cc(69) preCheck: 0x5651b56d0d38 checking slow rules
> 2024/07/10 18:24:44.032 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' found
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: follow_x_forwarded_for#1 = 1
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: follow_x_forwarded_for = 1
> 2024/07/10 18:24:44.032 kid1| 28,3| Checklist.cc(62) markFinished: 0x5651b56d0d38 answer DENIED for match
> 2024/07/10 18:24:44.032 kid1| 28,3| Checklist.cc(162) checkCallback: ACLChecklist::checkCallback: 0x5651b56d0d38 answer=DENIED
> 2024/07/10 18:24:44.032 kid1| 28,3| Checklist.cc(69) preCheck: 0x5651b5f334e8 checking slow rules
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: Safe_ports = 1
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: !Safe_ports = 0
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#1 = 0
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#2 = 0
> 2024/07/10 18:24:44.032 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: localhost = 0
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#3 = 0
> 2024/07/10 18:24:44.032 kid1| 28,3| RegexData.cc(50) match: checking 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: manager = 0
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#4 = 0
> 2024/07/10 18:24:44.032 kid1| 14,3| ipcache.cc(733) ipcache_gethostbyname: 'download.docker.com', flags=1
> 2024/07/10 18:24:44.032 kid1| 14,3| ipcache.cc(314) ipcacheRelease: ipcacheRelease: Releasing entry for 'download.docker.com'
> 2024/07/10 18:24:44.032 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
> 2024/07/10 18:24:44.032 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
> 2024/07/10 18:24:44.032 kid1| 78,3| dns_internal.cc(1793) idnsALookup: idnsALookup: buf is 37 bytes for download.docker.com, id = 0xc228
> 2024/07/10 18:24:44.032 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to X.X.X.X:53 using FD 10 using Port 52871
> 2024/07/10 18:24:44.032 kid1| 78,3| dns_internal.cc(1729) idnsSendSlaveAAAAQuery: buf is 48 bytes for download.docker.com, id = 0x798c
> 2024/07/10 18:24:44.032 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto: Attempt to send UDP packet to X.X.X.X:53 using FD 10 using Port 52871
> 2024/07/10 18:24:44.032 kid1| 28,3| DestinationIp.cc(78) match: can't yet compare 'to_localhost' ACL for download.docker.com
> 2024/07/10 18:24:44.032 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: to_localhost = -1 async
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#5 = -1 async
> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access = -1 async
> 2024/07/10 18:24:44.048 kid1| 78,3| dns_internal.cc(1320) idnsRead: idnsRead: starting with FD 10
> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1366) idnsRead: idnsRead: FD 10: received 144 bytes from X.X.X.X:53
> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1173) idnsGrokReply: idnsGrokReply: QID 0xc228, 5 answers
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 5 answers for download.docker.com
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #1 108.138.7.18
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #2 108.138.7.33
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #3 108.138.7.48
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #4 108.138.7.88
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 5 answers for download.docker.com
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #1 108.138.7.18
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #2 108.138.7.33
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #3 108.138.7.48
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #4 108.138.7.88
> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1320) idnsRead: idnsRead: starting with FD 10
> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1366) idnsRead: idnsRead: FD 10: received 315 bytes from X.X.X.X:53
> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1173) idnsGrokReply: idnsGrokReply: QID 0x798c, 9 answers
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 9 answers for download.docker.com
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #5 [2600:9000:2490:2200:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #6 [2600:9000:2490:3600:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #7 [2600:9000:2490:7000:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #8 [2600:9000:2490:d600:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #9 [2600:9000:2490:5a00:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #10 [2600:9000:2490:6600:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #11 [2600:9000:2490:b600:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #12 [2600:9000:2490:aa00:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(587) ipcacheHandleReply: done with download.docker.com: 108.138.7.18 #1/12-0
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 9 answers for download.docker.com
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #5 [2600:9000:2490:2200:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #6 [2600:9000:2490:3600:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #7 [2600:9000:2490:7000:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #8 [2600:9000:2490:d600:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #9 [2600:9000:2490:5a00:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #10 [2600:9000:2490:6600:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #11 [2600:9000:2490:b600:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #12 [2600:9000:2490:aa00:3:db06:4200:93a1]
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(587) ipcacheHandleReply: done with download.docker.com: 108.138.7.18 #1/12-0
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(314) ipcacheRelease: ipcacheRelease: Releasing entry for 'download.docker.com'
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(733) ipcache_gethostbyname: 'download.docker.com', flags=1
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.18' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.33' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.48' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.88' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:2200:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:3600:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:7000:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:d600:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:5a00:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:6600:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:b600:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:aa00:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: to_localhost = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| InnerNode.cc(100) resumeMatchingAt: checked: http_access#5 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: PURGE = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#6 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: PURGE = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#7 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: localhost = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#8 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: nocnet = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#9 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: EXTERNAL_DEV_CLIENTS = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#10 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#11 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#12 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#13 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#14 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#15 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#16 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#17 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: Safe_ports = 1
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: !Safe_ports = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#18 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#19 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| RegexData.cc(50) match: checking '/linux/ubuntu/dists/jammy/InRelease'
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: worm = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#20 = 0
> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(733) ipcache_gethostbyname: 'download.docker.com', flags=1
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.18' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.33' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.48' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.88' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:2200:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:3600:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:7000:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:d600:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:5a00:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:6600:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:b600:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '[2600:9000:2490:aa00:3:db06:4200:93a1]' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: SEUCHEN_IPS = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#21 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| DomainData.cc(110) match: aclMatchDomainList: checking 'download.docker.com'
> 2024/07/10 18:24:44.049 kid1| 28,3| DomainData.cc(115) match: aclMatchDomainList: 'download.docker.com' NOT found
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: SEUCHEN_DOMAINS = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#22 = 0
> 2024/07/10 18:24:44.049 kid1| 28,3| RegexData.cc(50) match: checking 'download.docker.com'
> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: SEUCHEN_DOMAINS_REGEX = 0
> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: http_access#23 = 0
> 2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT found
> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: http_access#24 = 0
> 2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' found
> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: REPOSITORY-CLIENTS = 1
> 2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(110) match: aclMatchDomainList: checking 'download.docker.com'
> 2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(115) match: aclMatchDomainList: 'download.docker.com' found
> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: REPOSITORY-ZIELE = 1
> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: http_access#25 = 1
> 2024/07/10 18:24:44.050 kid1| 28,3| InnerNode.cc(100) resumeMatchingAt: checked: http_access = 1
> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(62) markFinished: 0x5651b5f334e8 answer ALLOWED for match
> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(162) checkCallback: ACLChecklist::checkCallback: 0x5651b5f334e8 answer=ALLOWED
> 2024/07/10 18:24:44.050 kid1| 85,2| client_side_request.cc(715) clientAccessCheckDone: The request GET https://download.docker.com/linux/ubuntu/dists/jammy/InRelease is ALLOWED; last ACL checked: REPOSITORY-ZIELE
> 2024/07/10 18:24:44.050 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
> 2024/07/10 18:24:44.050 kid1| 83,3| client_side_request.cc(1744) doCallouts: Doing calloutContext->clientAccessCheck2()
> 2024/07/10 18:24:44.050 kid1| 85,2| client_side_request.cc(693) clientAccessCheck2: No adapted_http_access configuration. default: ALLOW
> 2024/07/10 18:24:44.050 kid1| 85,2| client_side_request.cc(715) clientAccessCheckDone: The request GET https://download.docker.com/linux/ubuntu/dists/jammy/InRelease is ALLOWED; last ACL checked: REPOSITORY-ZIELE
> 2024/07/10 18:24:44.050 kid1| 83,3| client_side_request.cc(1762) doCallouts: Doing clientInterpretRequestHeaders()
> 2024/07/10 18:24:44.050 kid1| 85,3| client_side_request.cc(117) ~ClientRequestContext: ClientRequestContext destructed, this=0x5651b667b8b8
> 2024/07/10 18:24:44.050 kid1| 83,3| client_side_request.cc(1856) doCallouts: calling processRequest()
> 2024/07/10 18:24:44.050 kid1| 87,3| clientStream.cc(178) clientStreamRead: clientStreamRead: Calling 1 with cbdata 0x5651b379fd80 from node 0x5651b6c14538
> 2024/07/10 18:24:44.050 kid1| 73,3| HttpRequest.cc(742) storeId: sent back effectiveRequestUrl: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 20,3| Controller.cc(429) peek: D3522EE27FB0ED7004DD594AF7674667
> 2024/07/10 18:24:44.050 kid1| 85,3| client_side_reply.cc(1523) identifyFoundObject: StoreEntry is NULL -  MISS
> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(731) storeCreatePureEntry: storeCreateEntry: 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'
> 2024/07/10 18:24:44.050 kid1| 20,3| MemObject.cc(99) MemObject: MemObject constructed, this=0x5651b3ae4fc0
> 2024/07/10 18:24:44.050 kid1| 88,3| MemObject.cc(82) setUris: 0x5651b3ae4fc0 storeId: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: storeCreateEntry locked key [null_store_key] e:=V/0x5651b365e210*1
> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(537) setPrivateKey: 00 e:=V/0x5651b365e210*1
> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(413) hashInsert: StoreEntry::hashInsert: Inserting Entry e:=IV/0x5651b365e210*1 key '8349000000000000D107000001000000'
> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: store_client locked key 8349000000000000D107000001000000 e:=IV/0x5651b365e210*2
> 2024/07/10 18:24:44.050 kid1| 90,3| store_client.cc(243) copy: store_client::copy: 8349000000000000D107000001000000, from 0, for length 4096, cb 1, cbdata 0x5651b379ece8
> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: store_client::copy locked key 8349000000000000D107000001000000 e:=IV/0x5651b365e210*3
> 2024/07/10 18:24:44.050 kid1| 90,3| store_client.cc(343) storeClientCopy2: storeClientCopy2: 8349000000000000D107000001000000
> 2024/07/10 18:24:44.050 kid1| 90,3| store_client.cc(390) doCopy: store_client::doCopy: Waiting for more
> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(458) unlock: store_client::copy unlocking key 8349000000000000D107000001000000 e:=IV/0x5651b365e210*3
> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(69) preCheck: 0x7ffef6c09e30 checking fast rules
> 2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181:59100' found
> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: miss_access#1 = 1
> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: miss_access = 1
> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(62) markFinished: 0x7ffef6c09e30 answer ALLOWED for match
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(373) Start: 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'
> 2024/07/10 18:24:44.050 kid1| 17,2| FwdState.cc(133) FwdState: Forwarding client request conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1, url=https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: FwdState locked key 8349000000000000D107000001000000 e:=IV/0x5651b365e210*3
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(140) FwdState: FwdState constructed, this=0x5651b695faf8
> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(309) peerSelect: e:=IV/0x5651b365e210*3 https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: peerSelect locked key 8349000000000000D107000001000000 e:=IV/0x5651b365e210*4
> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(612) selectMore: GET download.docker.com
> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(617) selectMore: direct = DIRECT_UNKNOWN (always_direct to be checked)
> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(69) preCheck: 0x5651b56d0d38 checking slow rules
> 2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' found
> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: always_direct#1 = 1
> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: always_direct = 1
> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(62) markFinished: 0x5651b56d0d38 answer ALLOWED for match
> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(162) checkCallback: ACLChecklist::checkCallback: 0x5651b56d0d38 answer=ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(373) checkAlwaysDirectDone: ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(379) checkAlwaysDirectDone: direct = DIRECT_YES (always_direct allow)
> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(612) selectMore: GET download.docker.com
> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(1102) addSelection: adding HIER_DIRECT#download.docker.com
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(460) resolveSelected: Find IP destination for: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease' via download.docker.com
> 2024/07/10 18:24:44.050 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'download.docker.com': Name or service not known
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482176 local=0.0.0.0 remote=108.138.7.18:443 HIER_DIRECT flags=1, destination #1 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482176 local=0.0.0.0 remote=108.138.7.18:443 HIER_DIRECT flags=1
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(1124) connectStart: 1+ paths to https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482177 local=0.0.0.0 remote=108.138.7.33:443 HIER_DIRECT flags=1, destination #2 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482177 local=0.0.0.0 remote=108.138.7.33:443 HIER_DIRECT flags=1
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482178 local=0.0.0.0 remote=108.138.7.48:443 HIER_DIRECT flags=1, destination #3 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482178 local=0.0.0.0 remote=108.138.7.48:443 HIER_DIRECT flags=1
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482179 local=0.0.0.0 remote=108.138.7.88:443 HIER_DIRECT flags=1, destination #4 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482179 local=0.0.0.0 remote=108.138.7.88:443 HIER_DIRECT flags=1
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482180 local=[::] remote=[2600:9000:2490:2200:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #5 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482180 local=[::] remote=[2600:9000:2490:2200:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482181 local=[::] remote=[2600:9000:2490:3600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #6 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482181 local=[::] remote=[2600:9000:2490:3600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482182 local=[::] remote=[2600:9000:2490:7000:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #7 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482182 local=[::] remote=[2600:9000:2490:7000:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482183 local=[::] remote=[2600:9000:2490:d600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #8 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482183 local=[::] remote=[2600:9000:2490:d600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482184 local=[::] remote=[2600:9000:2490:5a00:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #9 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482184 local=[::] remote=[2600:9000:2490:5a00:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482185 local=[::] remote=[2600:9000:2490:6600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #10 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482185 local=[::] remote=[2600:9000:2490:6600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482186 local=[::] remote=[2600:9000:2490:b600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #11 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482186 local=[::] remote=[2600:9000:2490:b600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364 found conn482187 local=[::] remote=[2600:9000:2490:aa00:3:db06:4200:93a1]:443 HIER_DIRECT flags=1, destination #12 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct = ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct = DUNNO
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482187 local=[::] remote=[2600:9000:2490:aa00:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(479) resolveSelected: PeerSelector64364 found all 12 destinations for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(480) resolveSelected:   always_direct = ALLOWED
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(481) resolveSelected:    never_direct = DUNNO
> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(482) resolveSelected:        timedout = 0
> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(241) ~PeerSelector: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(458) unlock: peerSelect unlocking key 8349000000000000D107000001000000 e:=p2IV/0x5651b365e210*4
> 2024/07/10 18:24:44.050 kid1| 48,3| pconn.cc(474) popStored: lookup for key {108.138.7.18:443/download.docker.com} failed.
> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(69) preCheck: 0x7ffef6c0a460 checking fast ACLs
> 2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(110) match: aclMatchDomainList: checking 'download.docker.com'
> 2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(115) match: aclMatchDomainList: 'download.docker.com' NOT found
> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: SKIP_PALO_DOMAINS_FAST = 0
> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: !SKIP_PALO_DOMAINS_FAST = 1
> 2024/07/10 18:24:44.051 kid1| 28,3| Acl.cc(175) matches: checked: (tcp_outgoing_mark 0x14 line) = 1
> 2024/07/10 18:24:44.051 kid1| 28,3| Acl.cc(175) matches: checked: tcp_outgoing_mark 0x14 = 1
> 2024/07/10 18:24:44.051 kid1| 28,3| Checklist.cc(62) markFinished: 0x7ffef6c0a460 answer ALLOWED for match
> 2024/07/10 18:24:44.051 kid1| 17,3| FwdState.cc(1568) GetMarkingsToServer: from 0.0.0.0 tos 0 netfilter mark 20
> 2024/07/10 18:24:44.051 kid1| 5,3| ConnOpener.cc(42) ConnOpener: will connect to conn482189 local=0.0.0.0 remote=108.138.7.18:443 HIER_DIRECT flags=1 with 60 timeout
> 2024/07/10 18:24:44.051 kid1| 50,3| comm.cc(378) comm_openex: comm_openex: Attempt open socket for: 0.0.0.0
> 2024/07/10 18:24:44.051 kid1| 50,3| comm.cc(420) comm_openex: comm_openex: Opened socket conn482190 local=0.0.0.0 remote=[::] FD 19 flags=1 : family=2, type=1, protocol=6
> 2024/07/10 18:24:44.051 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 19 download.docker.com
> 2024/07/10 18:24:44.051 kid1| 50,3| QosConfig.cc(581) setSockNfmark: for FD 19 to 20
> 2024/07/10 18:24:44.051 kid1| 5,3| ConnOpener.cc(312) createFd: conn482189 local=0.0.0.0 remote=108.138.7.18:443 HIER_DIRECT flags=1 will timeout in 60
> 2024/07/10 18:24:44.058 kid1| 83,2| Io.cc(161) Handshake: handshake IN: Unknown Handshake packet
> 2024/07/10 18:24:44.058 kid1| 83,2| Io.cc(163) Handshake: handshake OUT: CLIENT HELLO
> 2024/07/10 18:24:44.058 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482189 local=X.X.X.X:36718 remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1 timeout 60
> 2024/07/10 18:24:44.064 kid1| 83,2| Io.cc(161) Handshake: handshake IN: Unknown Handshake packet
> 2024/07/10 18:24:44.064 kid1| 83,2| Io.cc(163) Handshake: handshake OUT: CLIENT HELLO
> 2024/07/10 18:24:44.064 kid1| 83,2| PeerConnector.cc(279) handleNegotiationResult: ERROR: Cannot establish a TLS connection to conn482189 local=X.X.X.X:36718 remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1:
>      problem: failure
>      detail: SQUID_TLS_ERR_CONNECT+GNUTLS_E_FATAL_ALERT_RECEIVED
> 2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(625) commUnsetConnTimeout: Remove timeout for conn482189 local=X.X.X.X:36718 remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1
> 2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482189 local=X.X.X.X:36718 remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1 timeout -1
> 2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(850) _comm_close: start closing FD 19 by Connection.cc:108
> 2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(586) commUnsetFdTimeout: Remove timeout for FD 19
> 2024/07/10 18:24:44.064 kid1| 83,3| Session.cc(36) tls_read_method: started for session=0x5651b404d2c0
> 2024/07/10 18:24:44.064 kid1| 51,3| fd.cc(93) fd_close: fd_close FD 19 server https start
> 2024/07/10 18:24:44.064 kid1| 17,3| FwdState.cc(471) fail: ERR_SECURE_CONNECT_FAIL "Service Unavailable"
> 	https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
> 2024/07/10 18:24:44.064 kid1| 17,3| FwdState.cc(781) retryOrBail: re-forwarding (1 tries, 0 secs)
> 
> 
>> -----Urspr?ngliche Nachricht-----
>> Von: Alex Rousskov <rousskov at measurement-factory.com>
>> Gesendet: Mittwoch, 10. Juli 2024 14:50
>> An: squid-users at lists.squid-cache.org
>> Cc: Fiehe, Christoph <c.fiehe at eurodata.de>
>> Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>>
>> On 2024-07-09 18:25, Fiehe, Christoph wrote:
>>
>>> I hope that somebody has an idea, what I am doing wrong.
>>
>> AFAICT from the debugging log, it is your parent proxy that returns an
>> ERR_SECURE_CONNECT_FAIL error page in response to a seemingly valid
>> "HEAD https://..." request. Can you ask their admin to investigate? You
>> may also recommend that they upgrade from Squid v4 that has many known
>> security vulnerabiities.
>>
>> If parent is uncooperative, you can try to reproduce the problem by
>> temporary installing your own parent Squid instance and configuring your
>> child Squid to use that instead.
>>
>> HTH,
>>
>> Alex.
>> P.S. Unlike Amos, I do not see serious conceptual problems with
>> rewriting request target scheme (as a temporary compatibility measure).
>> It may not always work, for various reasons, but it does not necessarily
>> make things worse (and may make things better).
>>
>>
>>
>>
>> I try to build a generic package proxy with Squid and need the feature
>> to rewrite (not redirect) a HTTP request to a package repository
>> transparently to a HTTPS-based package source. I was able to get Jesred
>> working and defined the following rewrite rule:
>>>
>>> regex ^http:\/\/download\.docker\.com(.*)$ https://download.docker.com\1
>>>
>>> I had to use a parent upstream proxy. In my test case the rule gets applied
>> successfully:
>>>
>>> 1720558404.106 10.2.59.102/molecule-ubuntu-jammy.lx.mycompany.de
>> http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/l
>> inux/ubuntu/dists/jammy/InRelease]
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease 2
>>>
>>> I have validated that the returned URL is correct and that the resource is accessible
>> via my upstream proxy.
>>>
>>> But at the very end, the client receives a 503 error code. I have set "debug_options
>> ALL,3" and this gives the log:
>>>
>>> [...]
>>> 2024/07/09 23:35:40.115 kid1| 11,2| client_side.cc(1333) parseHttpRequest: HTTP Client
>> REQUEST:
>>> ---------
>>> HEAD
>> http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/l
>> inux/ubuntu/dists/jammy/InRelease] HTTP/1.1
>>> Host: download.docker.com
>>> User-Agent: curl/7.81.0
>>> Accept: */*
>>> Proxy-Connection: Keep-Alive
>>>
>>>
>>> ----------
>>> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(1364) parseHttpRequest: complete
>> request received. prefix_sz = 174, request-line-size=77, mime-header-size=97, mime header
>> block:
>>> Host: download.docker.com
>>> User-Agent: curl/7.81.0
>>> Accept: */*
>>> Proxy-Connection: Keep-Alive
>>>
>>>
>>> ----------
>>> 2024/07/09 23:35:40.115 kid1| 87,3| clientStream.cc(139) clientStreamInsertHead:
>> clientStreamInsertHead: Inserted node 0x5c3ba4154308 with data 0x5c3ba4152950 after head
>>> 2024/07/09 23:35:40.115 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn9
>> local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1 timeout 86400
>>> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(1767) add: 0x5c3ba41518e0*3 to 0/0
>>> 2024/07/09 23:35:40.115 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x5c3ba41501f0 add
>> request 1 0x5c3ba41518e0*4
>>> 2024/07/09 23:35:40.115 kid1| 23,3| Uri.cc(446) parse: Split URL
>> 'http://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[http://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease'] into proto='http', host='download.docker.com',
>> port='80', path='/linux/ubuntu/dists/jammy/InRelease'
>>> 2024/07/09 23:35:40.115 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>> 'download.docker.com': Name or service not known
>>> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(702) clientSetKeepaliveFlag: http_ver
>> = HTTP/1.1
>>> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(703) clientSetKeepaliveFlag: method =
>> HEAD
>>> 2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(122) ClientRequestContext:
>> ClientRequestContext constructed, this=0x5c3ba4154e78
>>> 2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1708) doCallouts: Doing
>> calloutContext->hostHeaderVerify()
>>> 2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(606) hostHeaderVerify:
>> validate host=download.docker.com, port=0, portStr=NULL
>>> 2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(620) hostHeaderVerify:
>> validate skipped.
>>> 2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1715) doCallouts: Doing
>> calloutContext->clientAccessCheck()
>>> 2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba41552d8 checking
>> slow rules
>>> 2024/07/09 23:35:40.115 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.102:56466'
>> found
>>> 2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>>> 2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: http_access#1 = 1
>>> 2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: http_access = 1
>>> 2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba41552d8 answer
>> ALLOWED for match
>>> 2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(162) checkCallback:
>> ACLChecklist::checkCallback: 0x5c3ba41552d8 answer=ALLOWED
>>> 2024/07/09 23:35:40.115 kid1| 85,2| client_side_request.cc(714) clientAccessCheckDone:
>> The request HEAD
>> http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/l
>> inux/ubuntu/dists/jammy/InRelease] is ALLOWED; last ACL checked: all
>>> 2024/07/09 23:35:40.115 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
>>> 2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1735) doCallouts: Doing
>> calloutContext->clientRedirectStart()
>>> 2024/07/09 23:35:40.115 kid1| 78,3| dns_internal.cc(1836) idnsPTRLookup: idnsPTRLookup:
>> buf is 42 bytes for 10.2.59.102, id = 0x8d95
>>> 2024/07/09 23:35:40.115 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto:
>> Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
>>> 2024/07/09 23:35:40 kid1| Starting new redirector helpers...
>>> current master transaction: master54
>>> 2024/07/09 23:35:40 kid1| helperOpenServers: Starting 1/3 'jesred' processes
>>> current master transaction: master54
>>> 2024/07/09 23:35:40.115 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 17 IPC UNIX STREAM
>> Parent
>>> 2024/07/09 23:35:40.115 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 19 IPC UNIX STREAM
>> Parent
>>> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(212) ipcCreate: ipcCreate: prfd FD 17
>>> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(213) ipcCreate: ipcCreate: pwfd FD 17
>>> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(214) ipcCreate: ipcCreate: crfd FD 19
>>> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(215) ipcCreate: ipcCreate: cwfd FD 19
>>> 2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(850) _comm_close: start closing FD 19 by
>> ipc.cc:271
>>> 2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(586) commUnsetFdTimeout: Remove timeout for
>> FD 19
>>> 2024/07/09 23:35:40.116 kid1| 21,3| tools.cc(561) leave_suid: leave_suid: PID 503746
>> called
>>> 2024/07/09 23:35:40.116 kid1| 21,3| tools.cc(651) no_suid: no_suid: PID 503746 giving up
>> root privileges forever
>>> 2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(586) commUnsetFdTimeout: Remove timeout for
>> FD 17
>>> 2024/07/09 23:35:40.117 kid1| 84,3| helper.cc(1310) GetFirstAvailable:
>> GetFirstAvailable: Least-loaded helper is fully loaded!
>>> 2024/07/09 23:35:40.117 kid1| 51,3| fd.cc(93) fd_close: fd_close FD 19 IPC UNIX STREAM
>> Parent
>>> 2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting
>> with FD 11
>>> 2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11:
>> received 92 bytes from 127.0.0.53:53
>>> 2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply:
>> QID 0x8d95, 1 answers
>>> 2024/07/09 23:35:40.117 kid1| 35,3| fqdncache.cc(336) fqdncacheParse: fqdncacheParse: 1
>> answers for '10.2.59.102'
>>> 2024/07/09 23:35:40.117 kid1| 5,3| IoCallback.cc(112) finish: called for conn11
>> local=[::] remote=[::] FD 17 flags=1 (0, 0)
>>> 2024/07/09 23:35:40.125 kid1| 5,3| Read.cc(148) HandleRead: FD 17, size 32767, retval
>> 80, errno 0
>>> 2024/07/09 23:35:40.125 kid1| 5,3| IoCallback.cc(112) finish: called for conn10
>> local=[::] remote=[::] FD 17 flags=1 (0, 0)
>>> 2024/07/09 23:35:40.125 kid1| 84,3| helper.cc(1022) helperHandleRead: helperHandleRead:
>> end of reply found
>>> 2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(41) finalize: Parsing helper buffer
>>> 2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(59) finalize: Buff length is larger than 2
>>> 2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(63) finalize: helper Result = OK
>>> 2024/07/09 23:35:40.125 kid1| 23,3| Uri.cc(446) parse: Split URL
>> 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>> om/linux/ubuntu/dists/jammy/InRelease'] into proto='https', host='download.docker.com',
>> port='443', path='/linux/ubuntu/dists/jammy/InRelease'
>>> 2024/07/09 23:35:40.125 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>> 'download.docker.com': Name or service not known
>>> 2024/07/09 23:35:40.125 kid1| 61,2| client_side_request.cc(1235) clientRedirectDone:
>> URL-rewriter diverts URL from
>> http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/l
>> inux/ubuntu/dists/jammy/InRelease] to
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease]
>>> 2024/07/09 23:35:40.125 kid1| 83,3| client_side_request.cc(1743) doCallouts: Doing
>> calloutContext->clientAccessCheck2()
>>> 2024/07/09 23:35:40.125 kid1| 85,2| client_side_request.cc(692) clientAccessCheck2: No
>> adapted_http_access configuration. default: ALLOW
>>> 2024/07/09 23:35:40.125 kid1| 85,2| client_side_request.cc(714) clientAccessCheckDone:
>> The request HEAD
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease] is ALLOWED; last ACL checked: all
>>> 2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1761) doCallouts: Doing
>> clientInterpretRequestHeaders()
>>> 2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1770) doCallouts: Doing
>> calloutContext->checkNoCache()
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba41552d8 checking
>> slow rules
>>> 2024/07/09 23:35:40.126 kid1| 28,3| RegexData.cc(50) match: checking
>> 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>> om/linux/ubuntu/dists/jammy/InRelease']
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: no_cache = 0
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache#1 = 0
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.102:56466'
>> found
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache#2 = 1
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache = 1
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba41552d8 answer
>> ALLOWED for match
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(162) checkCallback:
>> ACLChecklist::checkCallback: 0x5c3ba41552d8 answer=ALLOWED
>>> 2024/07/09 23:35:40.126 kid1| 85,3| client_side_request.cc(116) ~ClientRequestContext:
>> ClientRequestContext destructed, this=0x5c3ba4154e78
>>> 2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1855) doCallouts: calling
>> processRequest()
>>> 2024/07/09 23:35:40.126 kid1| 87,3| clientStream.cc(178) clientStreamRead:
>> clientStreamRead: Calling 1 with cbdata 0x5c3ba4153e70 from node 0x5c3ba4154308
>>> 2024/07/09 23:35:40.126 kid1| 73,3| HttpRequest.cc(742) storeId: sent back
>> effectiveRequestUrl:
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease]
>>> 2024/07/09 23:35:40.126 kid1| 20,3| Controller.cc(429) peek:
>> DE850794EBC405A27A7718F51795E32A
>>> 2024/07/09 23:35:40.126 kid1| 73,3| HttpRequest.cc(742) storeId: sent back
>> effectiveRequestUrl:
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease]
>>> 2024/07/09 23:35:40.126 kid1| 20,3| Controller.cc(429) peek:
>> D3522EE27FB0ED7004DD594AF7674667
>>> 2024/07/09 23:35:40.126 kid1| 85,3| client_side_reply.cc(1523) identifyFoundObject:
>> StoreEntry is NULL - MISS
>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(730) storeCreatePureEntry:
>> storeCreateEntry:
>> 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>> om/linux/ubuntu/dists/jammy/InRelease']
>>> 2024/07/09 23:35:40.126 kid1| 20,3| MemObject.cc(99) MemObject: MemObject constructed,
>> this=0x5c3ba416ef10
>>> 2024/07/09 23:35:40.126 kid1| 88,3| MemObject.cc(82) setUris: 0x5c3ba416ef10 storeId:
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease]
>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: storeCreateEntry locked key
>> [null_store_key] e:=V/0x5c3ba416ee90*1
>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(536) setPrivateKey: 00
>> e:=V/0x5c3ba416ee90*1
>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(412) hashInsert: StoreEntry::hashInsert:
>> Inserting Entry e:=IV/0x5c3ba416ee90*1 key '020000000000000061AF070001000000'
>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: store_client locked key
>> 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*2
>>> 2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(243) copy: store_client::copy:
>> 020000000000000061AF070001000000, from 0, for length 4096, cb 1, cbdata 0x5c3ba4152dd8
>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: store_client::copy locked key
>> 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
>>> 2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(343) storeClientCopy2:
>> storeClientCopy2: 020000000000000061AF070001000000
>>> 2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(390) doCopy: store_client::doCopy:
>> Waiting for more
>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(457) unlock: store_client::copy unlocking
>> key 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
>>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(373) Start:
>> 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>> om/linux/ubuntu/dists/jammy/InRelease']
>>> 2024/07/09 23:35:40.126 kid1| 17,2| FwdState.cc(133) FwdState: Forwarding client request
>> conn9 local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1,
>> url=https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker
>> .com/linux/ubuntu/dists/jammy/InRelease]
>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: FwdState locked key
>> 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
>>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(140) FwdState: FwdState constructed,
>> this=0x5c3ba416fa18
>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(309) peerSelect:
>> e:=IV/0x5c3ba416ee90*3
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease]
>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: peerSelect locked key
>> 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*4
>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(612) selectMore: HEAD
>> download.docker.com
>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(626) selectMore: direct =
>> DIRECT_UNKNOWN (never_direct to be checked)
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba4170638 checking
>> slow rules
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.102:56466'
>> found
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: never_direct#1 = 1
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: never_direct = 1
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba4170638 answer
>> ALLOWED for match
>>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(162) checkCallback:
>> ACLChecklist::checkCallback: 0x5c3ba4170638 answer=ALLOWED
>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(345) checkNeverDirectDone: ALLOWED
>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(351) checkNeverDirectDone: direct =
>> DIRECT_NO (never_direct allow)
>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(612) selectMore: HEAD
>> download.docker.com
>>> 2024/07/09 23:35:40.126 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname:
>> ipcache_gethostbyname: 'download.docker.com', flags=0
>>> 2024/07/09 23:35:40.126 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>> 'download.docker.com': Name or service not known
>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(286) peerSelectIcpPing:
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease]
>>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(283) neighborsCount: neighborsCount: 0
>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(297) peerSelectIcpPing: counted 0
>> neighbors
>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(833) selectSomeParent: HEAD
>> download.docker.com
>>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(350) getRoundRobinParent: returning
>> [nil]
>>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(403) getWeightedRoundRobinParent:
>> returning [nil]
>>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(309) getFirstUpParent: returning
>> 212.89.128.96
>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1102) addSelection: adding
>> FIRSTUP_PARENT/212.89.128.96
>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1095) addSelection: skipping
>> ANY_OLD_PARENT/212.89.128.96; have FIRSTUP_PARENT/212.89.128.96
>>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(493) getDefaultParent: returning
>> 212.89.128.96
>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1095) addSelection: skipping
>> DEFAULT_PARENT/212.89.128.96; have FIRSTUP_PARENT/212.89.128.96
>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(460) resolveSelected: Find IP
>> destination for:
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.co
>> m/linux/ubuntu/dists/jammy/InRelease'] via 212.89.128.96
>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector1 found
>> conn12 local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1, destination #1 for
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease]
>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct =
>> DENIED
>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct =
>> ALLOWED
>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
>>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(610) noteDestination: conn12
>> local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1
>>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(1124) connectStart: 1+ paths to
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease]
>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(479) resolveSelected: PeerSelector1
>> found all 1 destinations for
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease]
>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(480) resolveSelected: always_direct =
>> DENIED
>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(481) resolveSelected: never_direct =
>> ALLOWED
>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(482) resolveSelected: timedout = 0
>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(241) ~PeerSelector:
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease]
>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(457) unlock: peerSelect unlocking key
>> 020000000000000061AF070001000000 e:=p2IV/0x5c3ba416ee90*4
>>> 2024/07/09 23:35:40.126 kid1| 48,3| pconn.cc(474) popStored: lookup for key
>> {212.89.128.96:3128} failed.
>>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(1568) GetMarkingsToServer: from 0.0.0.0
>> tos 0 netfilter mark 0
>>> 2024/07/09 23:35:40.126 kid1| 5,3| ConnOpener.cc(42) ConnOpener: will connect to conn14
>> local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1 with 30 timeout
>>> 2024/07/09 23:35:40.126 kid1| 50,3| comm.cc(378) comm_openex: comm_openex: Attempt open
>> socket for: 0.0.0.0
>>> 2024/07/09 23:35:40.126 kid1| 50,3| comm.cc(420) comm_openex: comm_openex: Opened socket
>> conn15 local=0.0.0.0 remote=[::] FD 19 flags=1 : family=2, type=1, protocol=6
>>> 2024/07/09 23:35:40.126 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 19
>>> 2024/07/09 23:35:40.126 kid1| 5,3| ConnOpener.cc(312) createFd: conn14 local=0.0.0.0
>> remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1 will timeout in 30
>>> 2024/07/09 23:35:40.127 kid1| 17,3| FwdState.cc(1197) dispatch: conn9
>> local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1: Fetching HEAD
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease]
>>> 2024/07/09 23:35:40.127 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>> 'download.docker.com': Name or service not known
>>> 2024/07/09 23:35:40.127 kid1| 78,3| dns_internal.cc(1793) idnsALookup: idnsALookup: buf
>> is 37 bytes for download.docker.com, id = 0xe779
>>> 2024/07/09 23:35:40.127 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto:
>> Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
>>> 2024/07/09 23:35:40.127 kid1| 78,3| dns_internal.cc(1729) idnsSendSlaveAAAAQuery: buf is
>> 37 bytes for download.docker.com, id = 0x8aee
>>> 2024/07/09 23:35:40.127 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto:
>> Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
>>> 2024/07/09 23:35:40.127 kid1| 11,3| http.cc(2516) httpStart: HEAD
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease]
>>> 2024/07/09 23:35:40.127 kid1| 20,3| store.cc(434) lock: Client locked key
>> 020000000000000061AF070001000000 e:=p2IV/0x5c3ba416ee90*4
>>> 2024/07/09 23:35:40.127 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn14
>> local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 timeout
>> 86400
>>> 2024/07/09 23:35:40.127 kid1| 22,3| refresh.cc(636) getMaxAge: getMaxAge:
>> 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>> om/linux/ubuntu/dists/jammy/InRelease']
>>> 2024/07/09 23:35:40.127 kid1| 11,2| http.cc(2472) sendRequest: HTTP Server conn14
>> local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1
>>> 2024/07/09 23:35:40.127 kid1| 11,2| http.cc(2473) sendRequest: HTTP Server REQUEST:
>>> ---------
>>> HEAD
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease] HTTP/1.1
>>> Host: download.docker.com
>>> User-Agent: curl/7.81.0
>>> Accept: */*
>>> Via: 1.1 pkg-proxy (squid/6.6)
>>> X-Forwarded-For: 10.2.59.102
>>> Cache-Control: max-age=0
>>> Connection: keep-alive
>>>
>>>
>>> ----------
>>> 2024/07/09 23:35:40.127 kid1| 5,3| IoCallback.cc(112) finish: called for conn14
>> local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 (0, 0)
>>> 2024/07/09 23:35:40.127 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn14
>> local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 timeout 900
>>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting
>> with FD 11
>>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11:
>> received 304 bytes from 127.0.0.53:53
>>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply:
>> QID 0x8aee, 9 answers
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(480) ipcacheParse: 9 answers for
>> download.docker.com
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #1
>> [2600:9000:2490:6c00:3:db06:4200:93a1]
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #2
>> [2600:9000:2490:a600:3:db06:4200:93a1]
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #3
>> [2600:9000:2490:9c00:3:db06:4200:93a1]
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #4
>> [2600:9000:2490:6000:3:db06:4200:93a1]
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #5
>> [2600:9000:2490:c00:3:db06:4200:93a1]
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #6
>> [2600:9000:2490:5200:3:db06:4200:93a1]
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #7
>> [2600:9000:2490:9a00:3:db06:4200:93a1]
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #8
>> [2600:9000:2490:2c00:3:db06:4200:93a1]
>>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting
>> with FD 11
>>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11:
>> received 144 bytes from 127.0.0.53:53
>>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply:
>> QID 0xe779, 5 answers
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(480) ipcacheParse: 5 answers for
>> download.docker.com
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #9
>> 108.138.7.33
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #10
>> 108.138.7.18
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #11
>> 108.138.7.88
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #12
>> 108.138.7.48
>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(586) ipcacheHandleReply: done with
>> download.docker.com: [2600:9000:2490:6c00:3:db06:4200:93a1] #1/12-0
>>> 2024/07/09 23:35:40.137 kid1| 38,3| net_db.cc(337) netdbSendPing: netdbSendPing: pinging
>> download.docker.com
>>> 2024/07/09 23:35:40.137 kid1| 37,2| IcmpSquid.cc(88) SendEcho: to
>> [2600:9000:2490:6c00:3:db06:4200:93a1], opcode 3, len 19
>>> 2024/07/09 23:35:40.137 pinger| 42,2| IcmpPinger.cc(198) Recv: Pass
>> [2600:9000:2490:6c00:3:db06:4200:93a1] off to ICMPv6 module.
>>> 2024/07/09 23:35:40 pinger| SendEcho ERROR: sending to ICMPv6 packet to
>> [2600:9000:2490:6c00:3:db06:4200:93a1]: (101) Network is unreachable
>>> 2024/07/09 23:35:40.138 pinger| 42,2| Icmp.cc(90) Log: pingerLog: 1720560940.138021
>> [2600:9000:2490:6c00:3:db06:4200:93a1] 0
>>> 2024/07/09 23:35:40.323 kid1| 5,3| IoCallback.cc(112) finish: called for conn14
>> local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 (0, 0)
>>> 2024/07/09 23:35:40.324 kid1| 5,3| Read.cc(93) ReadNow: conn14 local=10.2.59.103:39370
>> remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1, size 65536, retval 348, errno 0
>>> 2024/07/09 23:35:40.324 kid1| 11,3| http.cc(649) processReplyHeader: processReplyHeader:
>> key '020000000000000061AF070001000000'
>>> 2024/07/09 23:35:40.324 kid1| 11,2| http.cc(696) processReplyHeader: HTTP Server conn14
>> local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1
>>> 2024/07/09 23:35:40.324 kid1| 11,2| http.cc(697) processReplyHeader: HTTP Server
>> RESPONSE:
>>> ---------
>>> HTTP/1.1 503 Service Unavailable
>>> Server: squid/4.10
>>> Mime-Version: 1.0
>>> Date: Tue, 09 Jul 2024 21:35:40 GMT
>>> Content-Type: text/html;charset=utf-8
>>> Content-Length: 3879
>>> X-Squid-Error: ERR_SECURE_CONNECT_FAIL 71
>>> X-Cache: MISS from proxy-srv2
>>> X-Cache-Lookup: MISS from proxy-srv2:3128
>>> Via: 1.1 proxy-srv2 (squid/4.10)
>>> Connection: keep-alive
>>>
>>> ----------
>>> 2024/07/09 23:35:40.324 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
>>> 2024/07/09 23:35:40.324 kid1| 20,3| store.cc(1693) replaceHttpReply:
>> StoreEntry::replaceHttpReply:
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>> /linux/ubuntu/dists/jammy/InRelease]
>>> 2024/07/09 23:35:40.324 kid1| 11,3| http.cc(949) haveParsedReplyHeaders: HTTP CODE: 503
>>>
>>> Has anybody an idea what I can do to solve the issue?
>>>
>>> This is my configuration borrowed from squid-deb-proxy:
>>>
>>> # this file contains private networks (10.0.0.0/8, 172.16.0.0/12,
>>> # 192.168.0.0/16) by default, you can add/remove additional allowed
>>> # source networks in it to customize it for your setup
>>> acl src_networks src "/etc/squid/acl/src-networks.acl"
>>>
>>> # this file contains the archive mirrors by default,
>>> # if you use a different mirror, add it there
>>> acl to_archive_mirrors dstdomain "/etc/squid/acl/archive-mirrors.acl"
>>>
>>> # Disable Cache for defined domains
>>> acl no_cache url_regex "/etc/squid/acl/no-cache.acl"
>>>
>>> # this contains the package blacklist
>>> acl blockedpkgs urlpath_regex "/etc/squid/pkg-blacklist-regexp.acl"
>>>
>>> # default to a different port than stock squid
>>> http_port 8000
>>>
>>> # -------------------------------------------------
>>> # settings below probably do not need customization
>>>
>>> # user visible name
>>> visible_hostname pkg-proxy
>>>
>>> # we need a big cache, some debs are huge
>>> maximum_object_size 512 MB
>>>
>>> # use a different dir than stock squid and default to 40G
>>> cache_dir aufs /var/cache/squid 40000 16 256
>>>
>>> cache_peer 212.89.128.96 parent 3128 0 no-query default
>>> never_direct allow all
>>>
>>> # use different logs
>>> cache_access_log /var/log/squid/access.log
>>> cache_log /var/log/squid/cache.log
>>> cache_store_log /var/log/squid/store.log
>>>
>>> # tweaks to speed things up
>>> cache_mem 200 MB
>>> maximum_object_size_in_memory 10240 KB
>>>
>>> # pid
>>> pid_filename /var/run/squid.pid
>>>
>>> # refresh pattern for debs and udebs
>>> refresh_pattern deb$ 129600 100% 129600
>>> refresh_pattern udeb$ 129600 100% 129600
>>> refresh_pattern tar.gz$ 129600 100% 129600
>>> refresh_pattern tar.xz$ 129600 100% 129600
>>> refresh_pattern tar.bz2$ 129600 100% 129600
>>>
>>> # always refresh Packages and Release files
>>> refresh_pattern \/(Packages|Sources)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims
>>> refresh_pattern \/Release(|\.gpg)$ 0 0% 0 refresh-ims
>>> refresh_pattern \/InRelease$ 0 0% 0 refresh-ims
>>> refresh_pattern \/(Translation-.*)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims
>>>
>>> # handle meta-release and changelogs.ubuntu.com special
>>> # (fine to have this on debian too)
>>> refresh_pattern changelogs.ubuntu.com\/.* 0 1% 1
>>>
>>> # only allow connects to ports for http, https
>>> acl SSL_ports port 443 563
>>> acl Safe_ports port 80
>>> acl Safe_ports port 443 563
>>>
>>> # only allow ports we trust
>>> http_access deny !Safe_ports
>>>
>>> # do not allow to download from the pkg blacklist
>>> http_access deny blockedpkgs
>>>
>>> # allow access only to official archive mirrors
>>> # uncomment the third and fouth line to permit any unlisted domain
>>> http_access deny !to_archive_mirrors
>>>
>>> # allow access from our network and localhost
>>> http_access allow src_networks
>>>
>>> # And finally deny all other access to this proxy
>>> http_access deny all
>>>
>>> # don't cache domains not listed in the mirrors file
>>> # uncomment the third and fourth line to cache any unlisted domains
>>> cache deny no_cache
>>>
>>> # And finally cache everything else
>>> cache allow all
>>>
>>> url_rewrite_children 3 startup=0 idle=1 concurrency=1
>>> url_rewrite_program /usr/lib/squid/jesred
>>>
>>> debug_options ALL,3
>>>
>>> Thanks a lot.
>>>
>>> Regards,
>>> Christoph
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From jonathanlee571 at gmail.com  Wed Jul 10 16:55:49 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 10 Jul 2024 09:55:49 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <Zo64OEswTGHYcl9x@fantomas.sk>
References: <Zo605zQA1vz_lEZX@fantomas.sk>
 <B445DDAF-6DCD-4B1F-AA53-FD51C62B99B2@gmail.com>
 <Zo64OEswTGHYcl9x@fantomas.sk>
Message-ID: <BC3294F8-E402-4C22-AC91-C604FC64456A@gmail.com>

squidclient -w /squid-internal-mgr/info -u admin
squidclient -w /squid-internal-mgr/info at redacted -u admin
squidclient -w http://192.168.1.1:3128/squid-internal-mgr/info at redacted -u admin
squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info at redacted -u admin
squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info
squidclient http://127.0.0.1:3128/squid-internal-mgr/info
squidclient -h 127.0.0.1:3128/squid-internal-mgr/info
squidclient -h 127.0.0.1 /squid-internal-mgr/info
squidclient -h 127.0.0.1 /squid-internal-mgr/info at redcated
squidclient -w 127.0.0.1 /squid-internal-mgr/info at redacted
squidclient -w 127.0.0.1 /squid-internal-mgr/info at redcated -u admin
squidclient -h 192.168.1.1:3128  /squid-internal-mgr/info at redacted
squidclient -h 192.168.1.1  /squid-internal-mgr/info at redacted
squidclient -h 192.168.1.1  /squid-internal-mgr/info

with -w -u -h http spaces I can?t get it to show me stats 

Squid 6.6


> On Jul 10, 2024, at 09:35, Matus UHLAR - fantomas <uhlar at fantomas.sk> wrote:
> 
>>>>>> "/squid-internal-mgr/info"

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240710/d8965909/attachment.htm>

From jonathanlee571 at gmail.com  Wed Jul 10 16:57:51 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 10 Jul 2024 09:57:51 -0700
Subject: [squid-users] Squid 6.6 error clientProcessHit: Vary object loop!
Message-ID: <A9316505-DD38-433A-8C06-9C6599A02A65@gmail.com>

Has anyone seen this before? on hits?


10.07.2024 09:56:30	clientProcessHit: Vary object loop!
10.07.2024 09:56:30	varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'https://zagent20.h-cdn.com/cmd/get_thumb_info?customer=foxnews&ver=1.165.67&amp;url=https%3A%2F%2F247preview.foxnews.com%2Fhls%2Flive%2F2020027%2Ffncv3preview%2Findex.m3u8' 'origin="https%3A%2F%2Fstatic.foxnews.com", accept-encoding="gzip,%20deflate,%20br,%20zstd"'
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00	
31.12.1969 16:00:00
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240710/52577638/attachment.htm>

From rousskov at measurement-factory.com  Wed Jul 10 18:08:28 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 10 Jul 2024 14:08:28 -0400
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <BC3294F8-E402-4C22-AC91-C604FC64456A@gmail.com>
References: <Zo605zQA1vz_lEZX@fantomas.sk>
 <B445DDAF-6DCD-4B1F-AA53-FD51C62B99B2@gmail.com>
 <Zo64OEswTGHYcl9x@fantomas.sk>
 <BC3294F8-E402-4C22-AC91-C604FC64456A@gmail.com>
Message-ID: <04d4fbde-1ad0-4b02-bf60-5c2bee2bab09@measurement-factory.com>

On 2024-07-10 12:55, Jonathan Lee wrote:

>> Embedding a password in a cache manager command requires providing a
>> username with -U

> squidclient -w /squid-internal-mgr/info -u admin
> squidclient -w /squid-internal-mgr/info at redacted -u admin
> squidclient -w http://192.168.1.1:3128/squid-internal-mgr/info at redacted 
> -u admin
> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info at redacted -u 
> admin
> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info
> squidclient http://127.0.0.1:3128/squid-internal-mgr/info
> squidclient -h 127.0.0.1:3128/squid-internal-mgr/info
> squidclient -h 127.0.0.1 /squid-internal-mgr/info
> squidclient -h 127.0.0.1 /squid-internal-mgr/info at redcated
> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redacted
> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redcated -u admin
> squidclient -h 192.168.1.1:3128 ?/squid-internal-mgr/info at redacted
> squidclient -h 192.168.1.1 ?/squid-internal-mgr/info at redacted
> squidclient -h 192.168.1.1 ?/squid-internal-mgr/info
> 
> with -w -u -h http spaces I can?t get it to show me stats
> 
> Squid 6.6

I do not know whether this mistake is relevant, but squidclient 
documentation and error message imply that you should be using "-U" 
(capital letter U) while you are using "-u" (small letter u).

FWIW, I recommend using curl instead of deprecated squidclient. If 
nothing else, you would be dealing with a well-known tool with extensive 
documentation and wide-spread knowledge that will continue to work when 
you upgrade to Squid v7. Using curl is not going to solve Squid Bug 5283 
and similar Squid-specific problems[1], but it may reduce the number of 
"external" problems you have to deal with (e.g., guessing what 
squidclient command line options actually do).

[1]: https://bugs.squid-cache.org/show_bug.cgi?id=5283


HTH,

Alex.



From jonathanlee571 at gmail.com  Wed Jul 10 18:32:15 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 10 Jul 2024 11:32:15 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <04d4fbde-1ad0-4b02-bf60-5c2bee2bab09@measurement-factory.com>
References: <04d4fbde-1ad0-4b02-bf60-5c2bee2bab09@measurement-factory.com>
Message-ID: <1B312E07-2FA6-48DB-B309-6559C8205D6D@gmail.com>

Thanks
Sent from my iPhone

> On Jul 10, 2024, at 11:08, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> ?On 2024-07-10 12:55, Jonathan Lee wrote:
> 
>>> Embedding a password in a cache manager command requires providing a
>>> username with -U
> 
>> squidclient -w /squid-internal-mgr/info -u admin
>> squidclient -w /squid-internal-mgr/info at redacted -u admin
>> squidclient -w http://192.168.1.1:3128/squid-internal-mgr/info at redacted -u admin
>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info at redacted -u admin
>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info
>> squidclient http://127.0.0.1:3128/squid-internal-mgr/info
>> squidclient -h 127.0.0.1:3128/squid-internal-mgr/info
>> squidclient -h 127.0.0.1 /squid-internal-mgr/info
>> squidclient -h 127.0.0.1 /squid-internal-mgr/info at redcated
>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redacted
>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redcated -u admin
>> squidclient -h 192.168.1.1:3128  /squid-internal-mgr/info at redacted
>> squidclient -h 192.168.1.1  /squid-internal-mgr/info at redacted
>> squidclient -h 192.168.1.1  /squid-internal-mgr/info
>> with -w -u -h http spaces I can?t get it to show me stats
>> Squid 6.6
> 
> I do not know whether this mistake is relevant, but squidclient documentation and error message imply that you should be using "-U" (capital letter U) while you are using "-u" (small letter u).
> 
> FWIW, I recommend using curl instead of deprecated squidclient. If nothing else, you would be dealing with a well-known tool with extensive documentation and wide-spread knowledge that will continue to work when you upgrade to Squid v7. Using curl is not going to solve Squid Bug 5283 and similar Squid-specific problems[1], but it may reduce the number of "external" problems you have to deal with (e.g., guessing what squidclient command line options actually do).
> 
> [1]: https://bugs.squid-cache.org/show_bug.cgi?id=5283
> 
> 
> HTH,
> 
> Alex.
> 


From c.fiehe at eurodata.de  Wed Jul 10 20:06:49 2024
From: c.fiehe at eurodata.de (Fiehe, Christoph)
Date: Wed, 10 Jul 2024 20:06:49 +0000
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <ca32f7f1-9123-47d4-a7ba-dfc40d0c6937@measurement-factory.com>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
 <6bb89d7c58e34320b1eb15c1447e99d7@eurodata.de>
 <ca32f7f1-9123-47d4-a7ba-dfc40d0c6937@measurement-factory.com>
Message-ID: <570c3639c78749eda872556538f43f27@eurodata.de>

No problem. Thank you very much for your help.

I checked the difference between a working call when the URL is not being rewritten and the not working call with a schema rewrite. The problem is that the proxy just forwards the client GET request to the upstream proxy, but in that case a CONNECT is required. I suppose that Squid does not consider the protocol change initiated by the url_rewrite_program. Is there any opportunity to add something to the code that handles the protocol change requested by url_rewrite_program in case of a rewrite?

Working case: Upstream proxy receives a CONNECT from the downstream proxy

2024/07/10 21:06:05.355 kid1| 5,2| TcpAcceptor.cc(214) doAccept: New connection on FD 12
2024/07/10 21:06:05.355 kid1| 5,2| TcpAcceptor.cc(316) acceptNext: connection on conn482169 local=[::]:3128 remote=[::] FD 12 flags=9
2024/07/10 21:06:05.355 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 16 HTTP Request
2024/07/10 21:06:05.355 kid1| 28,3| Eui48.cc(511) lookup: id=0x5651b3e6d558 10.2.59.181 NOT found
2024/07/10 21:06:05.355 kid1| 17,2| QosConfig.cc(162) getNfConnmark: QOS: Failed to retrieve connection mark: (-1) (2) No such file or directory (Destination X.X.X.X:3128, source 10.2.59.181:40122)
2024/07/10 21:06:05.355 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482750 local=X.X.X.X:3128 remote=10.2.59.181:40122 FD 16 flags=1 timeout 300
2024/07/10 21:06:05.355 kid1| 5,3| IoCallback.cc(112) finish: called for conn482750 local=X.X.X.X:3128 remote=10.2.59.181:40122 FD 16 flags=1 (0, 0)
2024/07/10 21:06:05.355 kid1| 5,3| Read.cc(93) ReadNow: conn482750 local=X.X.X.X:3128 remote=10.2.59.181:40122 FD 16 flags=1, size 4096, retval 213, errno 0
2024/07/10 21:06:05.355 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482750 local=X.X.X.X:3128 remote=10.2.59.181:40122 FD 16 flags=1 timeout 300
2024/07/10 21:06:05.355 kid1| 33,3| Pipeline.cc(43) back: Pipeline 0x5651b328cb80 empty
2024/07/10 21:06:05.355 kid1| 11,2| client_side.cc(1332) parseHttpRequest: HTTP Client conn482750 local=X.X.X.X:3128 remote=10.2.59.181:40122 FD 16 flags=1
2024/07/10 21:06:05.355 kid1| 11,2| client_side.cc(1333) parseHttpRequest: HTTP Client REQUEST:
---------
CONNECT download.docker.com:443 HTTP/1.1
Host: download.docker.com:443
User-Agent: curl/7.81.0
Via: 1.1 pkg-proxy (squid/6.10)
X-Forwarded-For: 10.2.59.102
Cache-Control: max-age=259200
Connection: close

Not working after schema rewrite: Upstream proxy receives a GET from the proxy

2024/07/10 18:24:44.031 kid1| 5,2| TcpAcceptor.cc(214) doAccept: New connection on FD 12
2024/07/10 18:24:44.031 kid1| 5,2| TcpAcceptor.cc(316) acceptNext: connection on conn482169 local=[::]:3128 remote=[::] FD 12 flags=9
2024/07/10 18:24:44.031 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 16 HTTP Request
2024/07/10 18:24:44.031 kid1| 28,3| Eui48.cc(511) lookup: id=0x5651b3e6d558 10.2.59.181 NOT found
2024/07/10 18:24:44.031 kid1| 17,2| QosConfig.cc(162) getNfConnmark: QOS: Failed to retrieve connection mark: (-1) (2) No such file or directory (Destination X.X.X.X:3128, source 10.2.59.181:59100)
2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175 local=X.X.X.X:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 300
2024/07/10 18:24:44.031 kid1| 5,3| IoCallback.cc(112) finish: called for conn482175 local=X.X.X.X:3128 remote=10.2.59.181:59100 FD 16 flags=1 (0, 0)
2024/07/10 18:24:44.031 kid1| 5,3| Read.cc(93) ReadNow: conn482175 local=X.X.X.X:3128 remote=10.2.59.181:59100 FD 16 flags=1, size 4096, retval 293, errno 0
2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175 local=X.X.X.X:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 300
2024/07/10 18:24:44.031 kid1| 33,3| Pipeline.cc(43) back: Pipeline 0x5651b328cb80 empty
2024/07/10 18:24:44.031 kid1| 11,2| client_side.cc(1332) parseHttpRequest: HTTP Client conn482175 local=X.X.X.X:3128 remote=10.2.59.181:59100 FD 16 flags=1
2024/07/10 18:24:44.031 kid1| 11,2| client_side.cc(1333) parseHttpRequest: HTTP Client REQUEST:
---------
GET https://download.docker.com/linux/ubuntu/dists/jammy/InRelease HTTP/1.1
Host: download.docker.com
Accept: text/*
User-Agent: Debian APT-HTTP/1.3 (2.4.12) non-interactive
Via: 1.1 pkg-proxy (squid/6.10)
X-Forwarded-For: 10.2.59.102
Cache-Control: max-age=0
Connection: keep-alive


>-----Urspr?ngliche Nachricht-----
>Von: Alex Rousskov <rousskov at measurement-factory.com>
>Gesendet: Mittwoch, 10. Juli 2024 18:56
>An: squid-users at lists.squid-cache.org
>Cc: Fiehe, Christoph <c.fiehe at eurodata.de>
>Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>
>On 2024-07-10 12:42, Fiehe, Christoph wrote:
>
>> In the next test case, I used a more modern upstream proxy server based von Squid 6.8
>and enabled debugging.
>>
>> The log shows the error SQUID_TLS_ERR_CONNECT+GNUTLS_E_FATAL_ALERT_RECEIVED. I am not
>sure, what I can do to prevent it from occurring
>
>I cannot help with GnuTLS, but I can recommend using Squid built with
>OpenSSL libraries (./configure --with-openssl) instead of Squid built
>with GnuTLS.
>
>
>HTH,
>
>Alex.
>
>
>
>> 2024/07/10 18:24:44.031 kid1| 5,2| TcpAcceptor.cc(214) doAccept: New connection on FD 12
>> 2024/07/10 18:24:44.031 kid1| 5,2| TcpAcceptor.cc(316) acceptNext: connection on
>conn482169 local=[::]:3128 remote=[::] FD 12 flags=9
>> 2024/07/10 18:24:44.031 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 16 HTTP Request
>> 2024/07/10 18:24:44.031 kid1| 28,3| Eui48.cc(511) lookup: id=0x5651b3e6d558 10.2.59.181
>NOT found
>> 2024/07/10 18:24:44.031 kid1| 17,2| QosConfig.cc(162) getNfConnmark: QOS: Failed to
>retrieve connection mark: (-1) (2) No such file or directory (Destination
>212.89.134.12:3128, source 10.2.59.181:59100)
>> 2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175
>local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 300
>> 2024/07/10 18:24:44.031 kid1| 5,3| IoCallback.cc(112) finish: called for conn482175
>local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 (0, 0)
>> 2024/07/10 18:24:44.031 kid1| 5,3| Read.cc(93) ReadNow: conn482175
>local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1, size 4096, retval 293,
>errno 0
>> 2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175
>local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 300
>> 2024/07/10 18:24:44.031 kid1| 33,3| Pipeline.cc(43) back: Pipeline 0x5651b328cb80 empty
>> 2024/07/10 18:24:44.031 kid1| 11,2| client_side.cc(1332) parseHttpRequest: HTTP Client
>conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1
>> 2024/07/10 18:24:44.031 kid1| 11,2| client_side.cc(1333) parseHttpRequest: HTTP Client
>REQUEST:
>> ---------
>> GET https://download.docker.com/linux/ubuntu/dists/jammy/InRelease HTTP/1.1
>> Host: download.docker.com
>> Accept: text/*
>> User-Agent: Debian APT-HTTP/1.3 (2.4.12) non-interactive
>> Via: 1.1 pkg-proxy (squid/6.10)
>> X-Forwarded-For: 10.2.59.102
>> Cache-Control: max-age=0
>> Connection: keep-alive
>>
>>
>> ----------
>> 2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(1364) parseHttpRequest: complete
>request received. prefix_sz = 293, request-line-size=77, mime-header-size=216, mime header
>block:
>> Host: download.docker.com
>> Accept: text/*
>> User-Agent: Debian APT-HTTP/1.3 (2.4.12) non-interactive
>> Via: 1.1 pkg-proxy (squid/6.10)
>> X-Forwarded-For: 10.2.59.102
>> Cache-Control: max-age=0
>> Connection: keep-alive
>>
>>
>> ----------
>> 2024/07/10 18:24:44.031 kid1| 87,3| clientStream.cc(139) clientStreamInsertHead:
>clientStreamInsertHead: Inserted node 0x5651b6c14538 with data 0x5651b379ecb0 after head
>> 2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175
>local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 86400
>> 2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(1767) add: 0x5651b379dc40*3 to 0/0
>> 2024/07/10 18:24:44.031 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x5651b328cb80 add
>request 1 0x5651b379dc40*4
>> 2024/07/10 18:24:44.031 kid1| 23,3| Uri.cc(446) parse: Split URL
>'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease' into proto='https',
>host='download.docker.com', port='443', path='/linux/ubuntu/dists/jammy/InRelease'
>> 2024/07/10 18:24:44.031 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>'download.docker.com': Name or service not known
>> 2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(702) clientSetKeepaliveFlag: http_ver
>= HTTP/1.1
>> 2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(703) clientSetKeepaliveFlag: method =
>GET
>> 2024/07/10 18:24:44.031 kid1| 85,3| client_side_request.cc(123) ClientRequestContext:
>ClientRequestContext constructed, this=0x5651b667b8b8
>> 2024/07/10 18:24:44.031 kid1| 83,3| client_side_request.cc(1709) doCallouts: Doing
>calloutContext->hostHeaderVerify()
>> 2024/07/10 18:24:44.031 kid1| 85,3| client_side_request.cc(607) hostHeaderVerify:
>validate host=download.docker.com, port=0, portStr=NULL
>> 2024/07/10 18:24:44.031 kid1| 85,3| client_side_request.cc(621) hostHeaderVerify:
>validate skipped.
>> 2024/07/10 18:24:44.031 kid1| 83,3| client_side_request.cc(1716) doCallouts: Doing
>calloutContext->clientAccessCheck()
>> 2024/07/10 18:24:44.031 kid1| 28,3| Checklist.cc(69) preCheck: 0x5651b56d0d38 checking
>slow rules
>> 2024/07/10 18:24:44.032 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' found
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked:
>follow_x_forwarded_for#1 = 1
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: follow_x_forwarded_for
>= 1
>> 2024/07/10 18:24:44.032 kid1| 28,3| Checklist.cc(62) markFinished: 0x5651b56d0d38 answer
>DENIED for match
>> 2024/07/10 18:24:44.032 kid1| 28,3| Checklist.cc(162) checkCallback:
>ACLChecklist::checkCallback: 0x5651b56d0d38 answer=DENIED
>> 2024/07/10 18:24:44.032 kid1| 28,3| Checklist.cc(69) preCheck: 0x5651b5f334e8 checking
>slow rules
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: Safe_ports = 1
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: !Safe_ports = 0
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#1 = 0
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#2 = 0
>> 2024/07/10 18:24:44.032 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>found
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: localhost = 0
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#3 = 0
>> 2024/07/10 18:24:44.032 kid1| 28,3| RegexData.cc(50) match: checking
>'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: manager = 0
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#4 = 0
>> 2024/07/10 18:24:44.032 kid1| 14,3| ipcache.cc(733) ipcache_gethostbyname:
>'download.docker.com', flags=1
>> 2024/07/10 18:24:44.032 kid1| 14,3| ipcache.cc(314) ipcacheRelease: ipcacheRelease:
>Releasing entry for 'download.docker.com'
>> 2024/07/10 18:24:44.032 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>'download.docker.com': Name or service not known
>> 2024/07/10 18:24:44.032 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>'download.docker.com': Name or service not known
>> 2024/07/10 18:24:44.032 kid1| 78,3| dns_internal.cc(1793) idnsALookup: idnsALookup: buf
>is 37 bytes for download.docker.com, id = 0xc228
>> 2024/07/10 18:24:44.032 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto:
>Attempt to send UDP packet to X.X.X.X:53 using FD 10 using Port 52871
>> 2024/07/10 18:24:44.032 kid1| 78,3| dns_internal.cc(1729) idnsSendSlaveAAAAQuery: buf is
>48 bytes for download.docker.com, id = 0x798c
>> 2024/07/10 18:24:44.032 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto:
>Attempt to send UDP packet to X.X.X.X:53 using FD 10 using Port 52871
>> 2024/07/10 18:24:44.032 kid1| 28,3| DestinationIp.cc(78) match: can't yet compare
>'to_localhost' ACL for download.docker.com
>> 2024/07/10 18:24:44.032 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>'download.docker.com': Name or service not known
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: to_localhost = -1
>async
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#5 = -1
>async
>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access = -1 async
>> 2024/07/10 18:24:44.048 kid1| 78,3| dns_internal.cc(1320) idnsRead: idnsRead: starting
>with FD 10
>> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1366) idnsRead: idnsRead: FD 10:
>received 144 bytes from X.X.X.X:53
>> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1173) idnsGrokReply: idnsGrokReply:
>QID 0xc228, 5 answers
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 5 answers for
>download.docker.com
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #1
>108.138.7.18
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #2
>108.138.7.33
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #3
>108.138.7.48
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #4
>108.138.7.88
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 5 answers for
>download.docker.com
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #1
>108.138.7.18
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #2
>108.138.7.33
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #3
>108.138.7.48
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #4
>108.138.7.88
>> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1320) idnsRead: idnsRead: starting
>with FD 10
>> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1366) idnsRead: idnsRead: FD 10:
>received 315 bytes from X.X.X.X:53
>> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1173) idnsGrokReply: idnsGrokReply:
>QID 0x798c, 9 answers
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 9 answers for
>download.docker.com
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #5
>[2600:9000:2490:2200:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #6
>[2600:9000:2490:3600:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #7
>[2600:9000:2490:7000:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #8
>[2600:9000:2490:d600:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #9
>[2600:9000:2490:5a00:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #10
>[2600:9000:2490:6600:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #11
>[2600:9000:2490:b600:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #12
>[2600:9000:2490:aa00:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(587) ipcacheHandleReply: done with
>download.docker.com: 108.138.7.18 #1/12-0
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 9 answers for
>download.docker.com
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #5
>[2600:9000:2490:2200:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #6
>[2600:9000:2490:3600:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #7
>[2600:9000:2490:7000:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #8
>[2600:9000:2490:d600:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #9
>[2600:9000:2490:5a00:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #10
>[2600:9000:2490:6600:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #11
>[2600:9000:2490:b600:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #12
>[2600:9000:2490:aa00:3:db06:4200:93a1]
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(587) ipcacheHandleReply: done with
>download.docker.com: 108.138.7.18 #1/12-0
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(314) ipcacheRelease: ipcacheRelease:
>Releasing entry for 'download.docker.com'
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(733) ipcache_gethostbyname:
>'download.docker.com', flags=1
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.18' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.33' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.48' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.88' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:2200:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:3600:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:7000:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:d600:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:5a00:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:6600:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:b600:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:aa00:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: to_localhost = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| InnerNode.cc(100) resumeMatchingAt: checked:
>http_access#5 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: PURGE = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#6 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: PURGE = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#7 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: localhost = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#8 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: nocnet = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#9 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: EXTERNAL_DEV_CLIENTS =
>0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#10 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#11 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#12 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#13 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#14 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#15 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#16 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#17 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: Safe_ports = 1
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: !Safe_ports = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#18 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#19 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| RegexData.cc(50) match: checking
>'/linux/ubuntu/dists/jammy/InRelease'
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: worm = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#20 = 0
>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(733) ipcache_gethostbyname:
>'download.docker.com', flags=1
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.18' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.33' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.48' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.88' NOT
>found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:2200:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:3600:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:7000:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:d600:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:5a00:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:6600:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:b600:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>'[2600:9000:2490:aa00:3:db06:4200:93a1]' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: SEUCHEN_IPS = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#21 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| DomainData.cc(110) match: aclMatchDomainList:
>checking 'download.docker.com'
>> 2024/07/10 18:24:44.049 kid1| 28,3| DomainData.cc(115) match: aclMatchDomainList:
>'download.docker.com' NOT found
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: SEUCHEN_DOMAINS = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#22 = 0
>> 2024/07/10 18:24:44.049 kid1| 28,3| RegexData.cc(50) match: checking
>'download.docker.com'
>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: SEUCHEN_DOMAINS_REGEX
>= 0
>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: http_access#23 = 0
>> 2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>found
>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: http_access#24 = 0
>> 2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' found
>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: REPOSITORY-CLIENTS = 1
>> 2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(110) match: aclMatchDomainList:
>checking 'download.docker.com'
>> 2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(115) match: aclMatchDomainList:
>'download.docker.com' found
>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: REPOSITORY-ZIELE = 1
>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: http_access#25 = 1
>> 2024/07/10 18:24:44.050 kid1| 28,3| InnerNode.cc(100) resumeMatchingAt: checked:
>http_access = 1
>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(62) markFinished: 0x5651b5f334e8 answer
>ALLOWED for match
>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(162) checkCallback:
>ACLChecklist::checkCallback: 0x5651b5f334e8 answer=ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 85,2| client_side_request.cc(715) clientAccessCheckDone:
>The request GET https://download.docker.com/linux/ubuntu/dists/jammy/InRelease is ALLOWED;
>last ACL checked: REPOSITORY-ZIELE
>> 2024/07/10 18:24:44.050 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
>> 2024/07/10 18:24:44.050 kid1| 83,3| client_side_request.cc(1744) doCallouts: Doing
>calloutContext->clientAccessCheck2()
>> 2024/07/10 18:24:44.050 kid1| 85,2| client_side_request.cc(693) clientAccessCheck2: No
>adapted_http_access configuration. default: ALLOW
>> 2024/07/10 18:24:44.050 kid1| 85,2| client_side_request.cc(715) clientAccessCheckDone:
>The request GET https://download.docker.com/linux/ubuntu/dists/jammy/InRelease is ALLOWED;
>last ACL checked: REPOSITORY-ZIELE
>> 2024/07/10 18:24:44.050 kid1| 83,3| client_side_request.cc(1762) doCallouts: Doing
>clientInterpretRequestHeaders()
>> 2024/07/10 18:24:44.050 kid1| 85,3| client_side_request.cc(117) ~ClientRequestContext:
>ClientRequestContext destructed, this=0x5651b667b8b8
>> 2024/07/10 18:24:44.050 kid1| 83,3| client_side_request.cc(1856) doCallouts: calling
>processRequest()
>> 2024/07/10 18:24:44.050 kid1| 87,3| clientStream.cc(178) clientStreamRead:
>clientStreamRead: Calling 1 with cbdata 0x5651b379fd80 from node 0x5651b6c14538
>> 2024/07/10 18:24:44.050 kid1| 73,3| HttpRequest.cc(742) storeId: sent back
>effectiveRequestUrl: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 20,3| Controller.cc(429) peek:
>D3522EE27FB0ED7004DD594AF7674667
>> 2024/07/10 18:24:44.050 kid1| 85,3| client_side_reply.cc(1523) identifyFoundObject:
>StoreEntry is NULL -  MISS
>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(731) storeCreatePureEntry:
>storeCreateEntry: 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'
>> 2024/07/10 18:24:44.050 kid1| 20,3| MemObject.cc(99) MemObject: MemObject constructed,
>this=0x5651b3ae4fc0
>> 2024/07/10 18:24:44.050 kid1| 88,3| MemObject.cc(82) setUris: 0x5651b3ae4fc0 storeId:
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: storeCreateEntry locked key
>[null_store_key] e:=V/0x5651b365e210*1
>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(537) setPrivateKey: 00
>e:=V/0x5651b365e210*1
>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(413) hashInsert: StoreEntry::hashInsert:
>Inserting Entry e:=IV/0x5651b365e210*1 key '8349000000000000D107000001000000'
>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: store_client locked key
>8349000000000000D107000001000000 e:=IV/0x5651b365e210*2
>> 2024/07/10 18:24:44.050 kid1| 90,3| store_client.cc(243) copy: store_client::copy:
>8349000000000000D107000001000000, from 0, for length 4096, cb 1, cbdata 0x5651b379ece8
>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: store_client::copy locked key
>8349000000000000D107000001000000 e:=IV/0x5651b365e210*3
>> 2024/07/10 18:24:44.050 kid1| 90,3| store_client.cc(343) storeClientCopy2:
>storeClientCopy2: 8349000000000000D107000001000000
>> 2024/07/10 18:24:44.050 kid1| 90,3| store_client.cc(390) doCopy: store_client::doCopy:
>Waiting for more
>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(458) unlock: store_client::copy unlocking
>key 8349000000000000D107000001000000 e:=IV/0x5651b365e210*3
>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(69) preCheck: 0x7ffef6c09e30 checking
>fast rules
>> 2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181:59100'
>found
>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: miss_access#1 = 1
>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: miss_access = 1
>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(62) markFinished: 0x7ffef6c09e30 answer
>ALLOWED for match
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(373) Start:
>'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'
>> 2024/07/10 18:24:44.050 kid1| 17,2| FwdState.cc(133) FwdState: Forwarding client request
>conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1,
>url=https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: FwdState locked key
>8349000000000000D107000001000000 e:=IV/0x5651b365e210*3
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(140) FwdState: FwdState constructed,
>this=0x5651b695faf8
>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(309) peerSelect:
>e:=IV/0x5651b365e210*3 https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: peerSelect locked key
>8349000000000000D107000001000000 e:=IV/0x5651b365e210*4
>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(612) selectMore: GET
>download.docker.com
>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(617) selectMore: direct =
>DIRECT_UNKNOWN (always_direct to be checked)
>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(69) preCheck: 0x5651b56d0d38 checking
>slow rules
>> 2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' found
>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: always_direct#1 = 1
>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: always_direct = 1
>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(62) markFinished: 0x5651b56d0d38 answer
>ALLOWED for match
>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(162) checkCallback:
>ACLChecklist::checkCallback: 0x5651b56d0d38 answer=ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(373) checkAlwaysDirectDone: ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(379) checkAlwaysDirectDone: direct =
>DIRECT_YES (always_direct allow)
>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(612) selectMore: GET
>download.docker.com
>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(1102) addSelection: adding
>HIER_DIRECT#download.docker.com
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(460) resolveSelected: Find IP
>destination for: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease' via
>download.docker.com
>> 2024/07/10 18:24:44.050 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>'download.docker.com': Name or service not known
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>found conn482176 local=0.0.0.0 remote=108.138.7.18:443 HIER_DIRECT flags=1, destination #1
>for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>DUNNO
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482176
>local=0.0.0.0 remote=108.138.7.18:443 HIER_DIRECT flags=1
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(1124) connectStart: 1+ paths to
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>found conn482177 local=0.0.0.0 remote=108.138.7.33:443 HIER_DIRECT flags=1, destination #2
>for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>DUNNO
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482177
>local=0.0.0.0 remote=108.138.7.33:443 HIER_DIRECT flags=1
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>found conn482178 local=0.0.0.0 remote=108.138.7.48:443 HIER_DIRECT flags=1, destination #3
>for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>DUNNO
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482178
>local=0.0.0.0 remote=108.138.7.48:443 HIER_DIRECT flags=1
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>found conn482179 local=0.0.0.0 remote=108.138.7.88:443 HIER_DIRECT flags=1, destination #4
>for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>DUNNO
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482179
>local=0.0.0.0 remote=108.138.7.88:443 HIER_DIRECT flags=1
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>found conn482180 local=[::] remote=[2600:9000:2490:2200:3:db06:4200:93a1]:443 HIER_DIRECT
>flags=1, destination #5 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>DUNNO
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482180
>local=[::] remote=[2600:9000:2490:2200:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>found conn482181 local=[::] remote=[2600:9000:2490:3600:3:db06:4200:93a1]:443 HIER_DIRECT
>flags=1, destination #6 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>DUNNO
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482181
>local=[::] remote=[2600:9000:2490:3600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>found conn482182 local=[::] remote=[2600:9000:2490:7000:3:db06:4200:93a1]:443 HIER_DIRECT
>flags=1, destination #7 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>DUNNO
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482182
>local=[::] remote=[2600:9000:2490:7000:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>found conn482183 local=[::] remote=[2600:9000:2490:d600:3:db06:4200:93a1]:443 HIER_DIRECT
>flags=1, destination #8 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>DUNNO
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482183
>local=[::] remote=[2600:9000:2490:d600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>found conn482184 local=[::] remote=[2600:9000:2490:5a00:3:db06:4200:93a1]:443 HIER_DIRECT
>flags=1, destination #9 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>DUNNO
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482184
>local=[::] remote=[2600:9000:2490:5a00:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>found conn482185 local=[::] remote=[2600:9000:2490:6600:3:db06:4200:93a1]:443 HIER_DIRECT
>flags=1, destination #10 for
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>DUNNO
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482185
>local=[::] remote=[2600:9000:2490:6600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>found conn482186 local=[::] remote=[2600:9000:2490:b600:3:db06:4200:93a1]:443 HIER_DIRECT
>flags=1, destination #11 for
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>DUNNO
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482186
>local=[::] remote=[2600:9000:2490:b600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>found conn482187 local=[::] remote=[2600:9000:2490:aa00:3:db06:4200:93a1]:443 HIER_DIRECT
>flags=1, destination #12 for
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>DUNNO
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482187
>local=[::] remote=[2600:9000:2490:aa00:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(479) resolveSelected:
>PeerSelector64364 found all 12 destinations for
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(480) resolveSelected:   always_direct
>= ALLOWED
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(481) resolveSelected:    never_direct
>= DUNNO
>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(482) resolveSelected:        timedout
>= 0
>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(241) ~PeerSelector:
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(458) unlock: peerSelect unlocking key
>8349000000000000D107000001000000 e:=p2IV/0x5651b365e210*4
>> 2024/07/10 18:24:44.050 kid1| 48,3| pconn.cc(474) popStored: lookup for key
>{108.138.7.18:443/download.docker.com} failed.
>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(69) preCheck: 0x7ffef6c0a460 checking
>fast ACLs
>> 2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(110) match: aclMatchDomainList:
>checking 'download.docker.com'
>> 2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(115) match: aclMatchDomainList:
>'download.docker.com' NOT found
>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: SKIP_PALO_DOMAINS_FAST
>= 0
>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked:
>!SKIP_PALO_DOMAINS_FAST = 1
>> 2024/07/10 18:24:44.051 kid1| 28,3| Acl.cc(175) matches: checked: (tcp_outgoing_mark
>0x14 line) = 1
>> 2024/07/10 18:24:44.051 kid1| 28,3| Acl.cc(175) matches: checked: tcp_outgoing_mark 0x14
>= 1
>> 2024/07/10 18:24:44.051 kid1| 28,3| Checklist.cc(62) markFinished: 0x7ffef6c0a460 answer
>ALLOWED for match
>> 2024/07/10 18:24:44.051 kid1| 17,3| FwdState.cc(1568) GetMarkingsToServer: from 0.0.0.0
>tos 0 netfilter mark 20
>> 2024/07/10 18:24:44.051 kid1| 5,3| ConnOpener.cc(42) ConnOpener: will connect to
>conn482189 local=0.0.0.0 remote=108.138.7.18:443 HIER_DIRECT flags=1 with 60 timeout
>> 2024/07/10 18:24:44.051 kid1| 50,3| comm.cc(378) comm_openex: comm_openex: Attempt open
>socket for: 0.0.0.0
>> 2024/07/10 18:24:44.051 kid1| 50,3| comm.cc(420) comm_openex: comm_openex: Opened socket
>conn482190 local=0.0.0.0 remote=[::] FD 19 flags=1 : family=2, type=1, protocol=6
>> 2024/07/10 18:24:44.051 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 19
>download.docker.com
>> 2024/07/10 18:24:44.051 kid1| 50,3| QosConfig.cc(581) setSockNfmark: for FD 19 to 20
>> 2024/07/10 18:24:44.051 kid1| 5,3| ConnOpener.cc(312) createFd: conn482189 local=0.0.0.0
>remote=108.138.7.18:443 HIER_DIRECT flags=1 will timeout in 60
>> 2024/07/10 18:24:44.058 kid1| 83,2| Io.cc(161) Handshake: handshake IN: Unknown
>Handshake packet
>> 2024/07/10 18:24:44.058 kid1| 83,2| Io.cc(163) Handshake: handshake OUT: CLIENT HELLO
>> 2024/07/10 18:24:44.058 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482189
>local=X.X.X.X:36718 remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1 timeout 60
>> 2024/07/10 18:24:44.064 kid1| 83,2| Io.cc(161) Handshake: handshake IN: Unknown
>Handshake packet
>> 2024/07/10 18:24:44.064 kid1| 83,2| Io.cc(163) Handshake: handshake OUT: CLIENT HELLO
>> 2024/07/10 18:24:44.064 kid1| 83,2| PeerConnector.cc(279) handleNegotiationResult:
>ERROR: Cannot establish a TLS connection to conn482189 local=X.X.X.X:36718
>remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1:
>>      problem: failure
>>      detail: SQUID_TLS_ERR_CONNECT+GNUTLS_E_FATAL_ALERT_RECEIVED
>> 2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(625) commUnsetConnTimeout: Remove timeout for
>conn482189 local=X.X.X.X:36718 remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1
>> 2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482189
>local=X.X.X.X:36718 remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1 timeout -1
>> 2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(850) _comm_close: start closing FD 19 by
>Connection.cc:108
>> 2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(586) commUnsetFdTimeout: Remove timeout for
>FD 19
>> 2024/07/10 18:24:44.064 kid1| 83,3| Session.cc(36) tls_read_method: started for
>session=0x5651b404d2c0
>> 2024/07/10 18:24:44.064 kid1| 51,3| fd.cc(93) fd_close: fd_close FD 19 server https
>start
>> 2024/07/10 18:24:44.064 kid1| 17,3| FwdState.cc(471) fail: ERR_SECURE_CONNECT_FAIL
>"Service Unavailable"
>> 	https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>> 2024/07/10 18:24:44.064 kid1| 17,3| FwdState.cc(781) retryOrBail: re-forwarding (1
>tries, 0 secs)

From rousskov at measurement-factory.com  Wed Jul 10 20:15:10 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 10 Jul 2024 16:15:10 -0400
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <867452bfd4ff482bb60b90d4482265a7@eurodata.de>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
 <6bb89d7c58e34320b1eb15c1447e99d7@eurodata.de>
 <ca32f7f1-9123-47d4-a7ba-dfc40d0c6937@measurement-factory.com>
 <867452bfd4ff482bb60b90d4482265a7@eurodata.de>
Message-ID: <cda7c451-72eb-4be5-bc10-a7db7ea1ba64@measurement-factory.com>

On 2024-07-10 15:31, Fiehe, Christoph wrote:
> The problem is that the proxy just forwards the client GET request to the upstream proxy

Why does sending a GET request to the upstream proxy represent a problem 
in your use case? I cannot find anything in your prior messages on this 
thread that would preclude sending a GET request to the upstream proxy.


> but in that case a CONNECT is required.

Why?

Please do not interpret my response as implying that this "must send 
CONNECT" requirement is wrong (or correct). At this point, I am just 
trying to understand what problem(s) you are trying to solve beyond the 
one you have originally described.


Thank you,

Alex.


> Working case: Upstream proxy receives a CONNECT from the downstream proxy
> 
> 2024/07/10 21:06:05.355 kid1| 5,2| TcpAcceptor.cc(214) doAccept: New connection on FD 12
> 2024/07/10 21:06:05.355 kid1| 5,2| TcpAcceptor.cc(316) acceptNext: connection on conn482169 local=[::]:3128 remote=[::] FD 12 flags=9
> 2024/07/10 21:06:05.355 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 16 HTTP Request
> 2024/07/10 21:06:05.355 kid1| 28,3| Eui48.cc(511) lookup: id=0x5651b3e6d558 10.2.59.181 NOT found
> 2024/07/10 21:06:05.355 kid1| 17,2| QosConfig.cc(162) getNfConnmark: QOS: Failed to retrieve connection mark: (-1) (2) No such file or directory (Destination X.X.X.X:3128, source 10.2.59.181:40122)
> 2024/07/10 21:06:05.355 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482750 local=X.X.X.X:3128 remote=10.2.59.181:40122 FD 16 flags=1 timeout 300
> 2024/07/10 21:06:05.355 kid1| 5,3| IoCallback.cc(112) finish: called for conn482750 local=X.X.X.X:3128 remote=10.2.59.181:40122 FD 16 flags=1 (0, 0)
> 2024/07/10 21:06:05.355 kid1| 5,3| Read.cc(93) ReadNow: conn482750 local=X.X.X.X:3128 remote=10.2.59.181:40122 FD 16 flags=1, size 4096, retval 213, errno 0
> 2024/07/10 21:06:05.355 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482750 local=X.X.X.X:3128 remote=10.2.59.181:40122 FD 16 flags=1 timeout 300
> 2024/07/10 21:06:05.355 kid1| 33,3| Pipeline.cc(43) back: Pipeline 0x5651b328cb80 empty
> 2024/07/10 21:06:05.355 kid1| 11,2| client_side.cc(1332) parseHttpRequest: HTTP Client conn482750 local=X.X.X.X:3128 remote=10.2.59.181:40122 FD 16 flags=1
> 2024/07/10 21:06:05.355 kid1| 11,2| client_side.cc(1333) parseHttpRequest: HTTP Client REQUEST:
> ---------
> CONNECT download.docker.com:443 HTTP/1.1
> Host: download.docker.com:443
> User-Agent: curl/7.81.0
> Via: 1.1 pkg-proxy (squid/6.10)
> X-Forwarded-For: 10.2.59.102
> Cache-Control: max-age=259200
> Connection: close
> 
> Not working after schema rewrite: Upstream proxy receives a GET from the proxy
> 
> 2024/07/10 18:24:44.031 kid1| 5,2| TcpAcceptor.cc(214) doAccept: New connection on FD 12
> 2024/07/10 18:24:44.031 kid1| 5,2| TcpAcceptor.cc(316) acceptNext: connection on conn482169 local=[::]:3128 remote=[::] FD 12 flags=9
> 2024/07/10 18:24:44.031 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 16 HTTP Request
> 2024/07/10 18:24:44.031 kid1| 28,3| Eui48.cc(511) lookup: id=0x5651b3e6d558 10.2.59.181 NOT found
> 2024/07/10 18:24:44.031 kid1| 17,2| QosConfig.cc(162) getNfConnmark: QOS: Failed to retrieve connection mark: (-1) (2) No such file or directory (Destination X.X.X.X:3128, source 10.2.59.181:59100)
> 2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175 local=X.X.X.X:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 300
> 2024/07/10 18:24:44.031 kid1| 5,3| IoCallback.cc(112) finish: called for conn482175 local=X.X.X.X:3128 remote=10.2.59.181:59100 FD 16 flags=1 (0, 0)
> 2024/07/10 18:24:44.031 kid1| 5,3| Read.cc(93) ReadNow: conn482175 local=X.X.X.X:3128 remote=10.2.59.181:59100 FD 16 flags=1, size 4096, retval 293, errno 0
> 2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175 local=X.X.X.X:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 300
> 2024/07/10 18:24:44.031 kid1| 33,3| Pipeline.cc(43) back: Pipeline 0x5651b328cb80 empty
> 2024/07/10 18:24:44.031 kid1| 11,2| client_side.cc(1332) parseHttpRequest: HTTP Client conn482175 local=X.X.X.X:3128 remote=10.2.59.181:59100 FD 16 flags=1
> 2024/07/10 18:24:44.031 kid1| 11,2| client_side.cc(1333) parseHttpRequest: HTTP Client REQUEST:
> ---------
> GET https://download.docker.com/linux/ubuntu/dists/jammy/InRelease HTTP/1.1
> Host: download.docker.com
> Accept: text/*
> User-Agent: Debian APT-HTTP/1.3 (2.4.12) non-interactive
> Via: 1.1 pkg-proxy (squid/6.10)
> X-Forwarded-For: 10.2.59.102
> Cache-Control: max-age=0
> Connection: keep-alive
> 
> 
> 
>> -----Urspr?ngliche Nachricht-----
>> Von: Alex Rousskov <rousskov at measurement-factory.com>
>> Gesendet: Mittwoch, 10. Juli 2024 18:56
>> An: squid-users at lists.squid-cache.org
>> Cc: Fiehe, Christoph <c.fiehe at eurodata.de>
>> Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>>
>> On 2024-07-10 12:42, Fiehe, Christoph wrote:
>>
>>> In the next test case, I used a more modern upstream proxy server based von Squid 6.8
>> and enabled debugging.
>>>
>>> The log shows the error SQUID_TLS_ERR_CONNECT+GNUTLS_E_FATAL_ALERT_RECEIVED. I am not
>> sure, what I can do to prevent it from occurring
>>
>> I cannot help with GnuTLS, but I can recommend using Squid built with
>> OpenSSL libraries (./configure --with-openssl) instead of Squid built
>> with GnuTLS.
>>
>>
>> HTH,
>>
>> Alex.
>>
>>
>>
>>> 2024/07/10 18:24:44.031 kid1| 5,2| TcpAcceptor.cc(214) doAccept: New connection on FD 12
>>> 2024/07/10 18:24:44.031 kid1| 5,2| TcpAcceptor.cc(316) acceptNext: connection on
>> conn482169 local=[::]:3128 remote=[::] FD 12 flags=9
>>> 2024/07/10 18:24:44.031 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 16 HTTP Request
>>> 2024/07/10 18:24:44.031 kid1| 28,3| Eui48.cc(511) lookup: id=0x5651b3e6d558 10.2.59.181
>> NOT found
>>> 2024/07/10 18:24:44.031 kid1| 17,2| QosConfig.cc(162) getNfConnmark: QOS: Failed to
>> retrieve connection mark: (-1) (2) No such file or directory (Destination
>> 212.89.134.12:3128, source 10.2.59.181:59100)
>>> 2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175
>> local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 300
>>> 2024/07/10 18:24:44.031 kid1| 5,3| IoCallback.cc(112) finish: called for conn482175
>> local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 (0, 0)
>>> 2024/07/10 18:24:44.031 kid1| 5,3| Read.cc(93) ReadNow: conn482175
>> local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1, size 4096, retval 293,
>> errno 0
>>> 2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175
>> local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 300
>>> 2024/07/10 18:24:44.031 kid1| 33,3| Pipeline.cc(43) back: Pipeline 0x5651b328cb80 empty
>>> 2024/07/10 18:24:44.031 kid1| 11,2| client_side.cc(1332) parseHttpRequest: HTTP Client
>> conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1
>>> 2024/07/10 18:24:44.031 kid1| 11,2| client_side.cc(1333) parseHttpRequest: HTTP Client
>> REQUEST:
>>> ---------
>>> GET https://download.docker.com/linux/ubuntu/dists/jammy/InRelease HTTP/1.1
>>> Host: download.docker.com
>>> Accept: text/*
>>> User-Agent: Debian APT-HTTP/1.3 (2.4.12) non-interactive
>>> Via: 1.1 pkg-proxy (squid/6.10)
>>> X-Forwarded-For: 10.2.59.102
>>> Cache-Control: max-age=0
>>> Connection: keep-alive
>>>
>>>
>>> ----------
>>> 2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(1364) parseHttpRequest: complete
>> request received. prefix_sz = 293, request-line-size=77, mime-header-size=216, mime header
>> block:
>>> Host: download.docker.com
>>> Accept: text/*
>>> User-Agent: Debian APT-HTTP/1.3 (2.4.12) non-interactive
>>> Via: 1.1 pkg-proxy (squid/6.10)
>>> X-Forwarded-For: 10.2.59.102
>>> Cache-Control: max-age=0
>>> Connection: keep-alive
>>>
>>>
>>> ----------
>>> 2024/07/10 18:24:44.031 kid1| 87,3| clientStream.cc(139) clientStreamInsertHead:
>> clientStreamInsertHead: Inserted node 0x5651b6c14538 with data 0x5651b379ecb0 after head
>>> 2024/07/10 18:24:44.031 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482175
>> local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1 timeout 86400
>>> 2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(1767) add: 0x5651b379dc40*3 to 0/0
>>> 2024/07/10 18:24:44.031 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x5651b328cb80 add
>> request 1 0x5651b379dc40*4
>>> 2024/07/10 18:24:44.031 kid1| 23,3| Uri.cc(446) parse: Split URL
>> 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease' into proto='https',
>> host='download.docker.com', port='443', path='/linux/ubuntu/dists/jammy/InRelease'
>>> 2024/07/10 18:24:44.031 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>> 'download.docker.com': Name or service not known
>>> 2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(702) clientSetKeepaliveFlag: http_ver
>> = HTTP/1.1
>>> 2024/07/10 18:24:44.031 kid1| 33,3| client_side.cc(703) clientSetKeepaliveFlag: method =
>> GET
>>> 2024/07/10 18:24:44.031 kid1| 85,3| client_side_request.cc(123) ClientRequestContext:
>> ClientRequestContext constructed, this=0x5651b667b8b8
>>> 2024/07/10 18:24:44.031 kid1| 83,3| client_side_request.cc(1709) doCallouts: Doing
>> calloutContext->hostHeaderVerify()
>>> 2024/07/10 18:24:44.031 kid1| 85,3| client_side_request.cc(607) hostHeaderVerify:
>> validate host=download.docker.com, port=0, portStr=NULL
>>> 2024/07/10 18:24:44.031 kid1| 85,3| client_side_request.cc(621) hostHeaderVerify:
>> validate skipped.
>>> 2024/07/10 18:24:44.031 kid1| 83,3| client_side_request.cc(1716) doCallouts: Doing
>> calloutContext->clientAccessCheck()
>>> 2024/07/10 18:24:44.031 kid1| 28,3| Checklist.cc(69) preCheck: 0x5651b56d0d38 checking
>> slow rules
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' found
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked:
>> follow_x_forwarded_for#1 = 1
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: follow_x_forwarded_for
>> = 1
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Checklist.cc(62) markFinished: 0x5651b56d0d38 answer
>> DENIED for match
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Checklist.cc(162) checkCallback:
>> ACLChecklist::checkCallback: 0x5651b56d0d38 answer=DENIED
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Checklist.cc(69) preCheck: 0x5651b5f334e8 checking
>> slow rules
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: Safe_ports = 1
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: !Safe_ports = 0
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#1 = 0
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#2 = 0
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>> found
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: localhost = 0
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#3 = 0
>>> 2024/07/10 18:24:44.032 kid1| 28,3| RegexData.cc(50) match: checking
>> 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: manager = 0
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#4 = 0
>>> 2024/07/10 18:24:44.032 kid1| 14,3| ipcache.cc(733) ipcache_gethostbyname:
>> 'download.docker.com', flags=1
>>> 2024/07/10 18:24:44.032 kid1| 14,3| ipcache.cc(314) ipcacheRelease: ipcacheRelease:
>> Releasing entry for 'download.docker.com'
>>> 2024/07/10 18:24:44.032 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>> 'download.docker.com': Name or service not known
>>> 2024/07/10 18:24:44.032 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>> 'download.docker.com': Name or service not known
>>> 2024/07/10 18:24:44.032 kid1| 78,3| dns_internal.cc(1793) idnsALookup: idnsALookup: buf
>> is 37 bytes for download.docker.com, id = 0xc228
>>> 2024/07/10 18:24:44.032 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto:
>> Attempt to send UDP packet to X.X.X.X:53 using FD 10 using Port 52871
>>> 2024/07/10 18:24:44.032 kid1| 78,3| dns_internal.cc(1729) idnsSendSlaveAAAAQuery: buf is
>> 48 bytes for download.docker.com, id = 0x798c
>>> 2024/07/10 18:24:44.032 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto:
>> Attempt to send UDP packet to X.X.X.X:53 using FD 10 using Port 52871
>>> 2024/07/10 18:24:44.032 kid1| 28,3| DestinationIp.cc(78) match: can't yet compare
>> 'to_localhost' ACL for download.docker.com
>>> 2024/07/10 18:24:44.032 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>> 'download.docker.com': Name or service not known
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: to_localhost = -1
>> async
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access#5 = -1
>> async
>>> 2024/07/10 18:24:44.032 kid1| 28,3| Acl.cc(175) matches: checked: http_access = -1 async
>>> 2024/07/10 18:24:44.048 kid1| 78,3| dns_internal.cc(1320) idnsRead: idnsRead: starting
>> with FD 10
>>> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1366) idnsRead: idnsRead: FD 10:
>> received 144 bytes from X.X.X.X:53
>>> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1173) idnsGrokReply: idnsGrokReply:
>> QID 0xc228, 5 answers
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 5 answers for
>> download.docker.com
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #1
>> 108.138.7.18
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #2
>> 108.138.7.33
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #3
>> 108.138.7.48
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #4
>> 108.138.7.88
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 5 answers for
>> download.docker.com
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #1
>> 108.138.7.18
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #2
>> 108.138.7.33
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #3
>> 108.138.7.48
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #4
>> 108.138.7.88
>>> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1320) idnsRead: idnsRead: starting
>> with FD 10
>>> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1366) idnsRead: idnsRead: FD 10:
>> received 315 bytes from X.X.X.X:53
>>> 2024/07/10 18:24:44.049 kid1| 78,3| dns_internal.cc(1173) idnsGrokReply: idnsGrokReply:
>> QID 0x798c, 9 answers
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 9 answers for
>> download.docker.com
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #5
>> [2600:9000:2490:2200:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #6
>> [2600:9000:2490:3600:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #7
>> [2600:9000:2490:7000:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #8
>> [2600:9000:2490:d600:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #9
>> [2600:9000:2490:5a00:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #10
>> [2600:9000:2490:6600:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #11
>> [2600:9000:2490:b600:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #12
>> [2600:9000:2490:aa00:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(587) ipcacheHandleReply: done with
>> download.docker.com: 108.138.7.18 #1/12-0
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(481) ipcacheParse: 9 answers for
>> download.docker.com
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #5
>> [2600:9000:2490:2200:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #6
>> [2600:9000:2490:3600:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #7
>> [2600:9000:2490:7000:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #8
>> [2600:9000:2490:d600:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #9
>> [2600:9000:2490:5a00:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #10
>> [2600:9000:2490:6600:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #11
>> [2600:9000:2490:b600:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(536) addGood: download.docker.com #12
>> [2600:9000:2490:aa00:3:db06:4200:93a1]
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(587) ipcacheHandleReply: done with
>> download.docker.com: 108.138.7.18 #1/12-0
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(314) ipcacheRelease: ipcacheRelease:
>> Releasing entry for 'download.docker.com'
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(733) ipcache_gethostbyname:
>> 'download.docker.com', flags=1
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.18' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.33' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.48' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.88' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:2200:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:3600:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:7000:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:d600:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:5a00:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:6600:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:b600:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:aa00:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: to_localhost = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| InnerNode.cc(100) resumeMatchingAt: checked:
>> http_access#5 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: PURGE = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#6 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: PURGE = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#7 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: localhost = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#8 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: nocnet = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#9 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: EXTERNAL_DEV_CLIENTS =
>> 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#10 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#11 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#12 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#13 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#14 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#15 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#16 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#17 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: Safe_ports = 1
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: !Safe_ports = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#18 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: CONNECT = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#19 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| RegexData.cc(50) match: checking
>> '/linux/ubuntu/dists/jammy/InRelease'
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: worm = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#20 = 0
>>> 2024/07/10 18:24:44.049 kid1| 14,3| ipcache.cc(733) ipcache_gethostbyname:
>> 'download.docker.com', flags=1
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.18' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.33' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.48' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '108.138.7.88' NOT
>> found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:2200:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:3600:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:7000:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:d600:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:5a00:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:6600:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:b600:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '[2600:9000:2490:aa00:3:db06:4200:93a1]' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: SEUCHEN_IPS = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#21 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| DomainData.cc(110) match: aclMatchDomainList:
>> checking 'download.docker.com'
>>> 2024/07/10 18:24:44.049 kid1| 28,3| DomainData.cc(115) match: aclMatchDomainList:
>> 'download.docker.com' NOT found
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: SEUCHEN_DOMAINS = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: http_access#22 = 0
>>> 2024/07/10 18:24:44.049 kid1| 28,3| RegexData.cc(50) match: checking
>> 'download.docker.com'
>>> 2024/07/10 18:24:44.049 kid1| 28,3| Acl.cc(175) matches: checked: SEUCHEN_DOMAINS_REGEX
>> = 0
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: http_access#23 = 0
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' NOT
>> found
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: GERMANIA_PROXY = 0
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: http_access#24 = 0
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' found
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: REPOSITORY-CLIENTS = 1
>>> 2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(110) match: aclMatchDomainList:
>> checking 'download.docker.com'
>>> 2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(115) match: aclMatchDomainList:
>> 'download.docker.com' found
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: REPOSITORY-ZIELE = 1
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: http_access#25 = 1
>>> 2024/07/10 18:24:44.050 kid1| 28,3| InnerNode.cc(100) resumeMatchingAt: checked:
>> http_access = 1
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(62) markFinished: 0x5651b5f334e8 answer
>> ALLOWED for match
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(162) checkCallback:
>> ACLChecklist::checkCallback: 0x5651b5f334e8 answer=ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 85,2| client_side_request.cc(715) clientAccessCheckDone:
>> The request GET https://download.docker.com/linux/ubuntu/dists/jammy/InRelease is ALLOWED;
>> last ACL checked: REPOSITORY-ZIELE
>>> 2024/07/10 18:24:44.050 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
>>> 2024/07/10 18:24:44.050 kid1| 83,3| client_side_request.cc(1744) doCallouts: Doing
>> calloutContext->clientAccessCheck2()
>>> 2024/07/10 18:24:44.050 kid1| 85,2| client_side_request.cc(693) clientAccessCheck2: No
>> adapted_http_access configuration. default: ALLOW
>>> 2024/07/10 18:24:44.050 kid1| 85,2| client_side_request.cc(715) clientAccessCheckDone:
>> The request GET https://download.docker.com/linux/ubuntu/dists/jammy/InRelease is ALLOWED;
>> last ACL checked: REPOSITORY-ZIELE
>>> 2024/07/10 18:24:44.050 kid1| 83,3| client_side_request.cc(1762) doCallouts: Doing
>> clientInterpretRequestHeaders()
>>> 2024/07/10 18:24:44.050 kid1| 85,3| client_side_request.cc(117) ~ClientRequestContext:
>> ClientRequestContext destructed, this=0x5651b667b8b8
>>> 2024/07/10 18:24:44.050 kid1| 83,3| client_side_request.cc(1856) doCallouts: calling
>> processRequest()
>>> 2024/07/10 18:24:44.050 kid1| 87,3| clientStream.cc(178) clientStreamRead:
>> clientStreamRead: Calling 1 with cbdata 0x5651b379fd80 from node 0x5651b6c14538
>>> 2024/07/10 18:24:44.050 kid1| 73,3| HttpRequest.cc(742) storeId: sent back
>> effectiveRequestUrl: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 20,3| Controller.cc(429) peek:
>> D3522EE27FB0ED7004DD594AF7674667
>>> 2024/07/10 18:24:44.050 kid1| 85,3| client_side_reply.cc(1523) identifyFoundObject:
>> StoreEntry is NULL -  MISS
>>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(731) storeCreatePureEntry:
>> storeCreateEntry: 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'
>>> 2024/07/10 18:24:44.050 kid1| 20,3| MemObject.cc(99) MemObject: MemObject constructed,
>> this=0x5651b3ae4fc0
>>> 2024/07/10 18:24:44.050 kid1| 88,3| MemObject.cc(82) setUris: 0x5651b3ae4fc0 storeId:
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: storeCreateEntry locked key
>> [null_store_key] e:=V/0x5651b365e210*1
>>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(537) setPrivateKey: 00
>> e:=V/0x5651b365e210*1
>>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(413) hashInsert: StoreEntry::hashInsert:
>> Inserting Entry e:=IV/0x5651b365e210*1 key '8349000000000000D107000001000000'
>>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: store_client locked key
>> 8349000000000000D107000001000000 e:=IV/0x5651b365e210*2
>>> 2024/07/10 18:24:44.050 kid1| 90,3| store_client.cc(243) copy: store_client::copy:
>> 8349000000000000D107000001000000, from 0, for length 4096, cb 1, cbdata 0x5651b379ece8
>>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: store_client::copy locked key
>> 8349000000000000D107000001000000 e:=IV/0x5651b365e210*3
>>> 2024/07/10 18:24:44.050 kid1| 90,3| store_client.cc(343) storeClientCopy2:
>> storeClientCopy2: 8349000000000000D107000001000000
>>> 2024/07/10 18:24:44.050 kid1| 90,3| store_client.cc(390) doCopy: store_client::doCopy:
>> Waiting for more
>>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(458) unlock: store_client::copy unlocking
>> key 8349000000000000D107000001000000 e:=IV/0x5651b365e210*3
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(69) preCheck: 0x7ffef6c09e30 checking
>> fast rules
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181:59100'
>> found
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: miss_access#1 = 1
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: miss_access = 1
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(62) markFinished: 0x7ffef6c09e30 answer
>> ALLOWED for match
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(373) Start:
>> 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'
>>> 2024/07/10 18:24:44.050 kid1| 17,2| FwdState.cc(133) FwdState: Forwarding client request
>> conn482175 local=212.89.134.12:3128 remote=10.2.59.181:59100 FD 16 flags=1,
>> url=https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: FwdState locked key
>> 8349000000000000D107000001000000 e:=IV/0x5651b365e210*3
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(140) FwdState: FwdState constructed,
>> this=0x5651b695faf8
>>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(309) peerSelect:
>> e:=IV/0x5651b365e210*3 https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(435) lock: peerSelect locked key
>> 8349000000000000D107000001000000 e:=IV/0x5651b365e210*4
>>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(612) selectMore: GET
>> download.docker.com
>>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(617) selectMore: direct =
>> DIRECT_UNKNOWN (always_direct to be checked)
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(69) preCheck: 0x5651b56d0d38 checking
>> slow rules
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp: '10.2.59.181' found
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: always_direct#1 = 1
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: always_direct = 1
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(62) markFinished: 0x5651b56d0d38 answer
>> ALLOWED for match
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(162) checkCallback:
>> ACLChecklist::checkCallback: 0x5651b56d0d38 answer=ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(373) checkAlwaysDirectDone: ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(379) checkAlwaysDirectDone: direct =
>> DIRECT_YES (always_direct allow)
>>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(612) selectMore: GET
>> download.docker.com
>>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(1102) addSelection: adding
>> HIER_DIRECT#download.docker.com
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(460) resolveSelected: Find IP
>> destination for: https://download.docker.com/linux/ubuntu/dists/jammy/InRelease' via
>> download.docker.com
>>> 2024/07/10 18:24:44.050 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>> 'download.docker.com': Name or service not known
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>> found conn482176 local=0.0.0.0 remote=108.138.7.18:443 HIER_DIRECT flags=1, destination #1
>> for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>> ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>> DUNNO
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482176
>> local=0.0.0.0 remote=108.138.7.18:443 HIER_DIRECT flags=1
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(1124) connectStart: 1+ paths to
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>> found conn482177 local=0.0.0.0 remote=108.138.7.33:443 HIER_DIRECT flags=1, destination #2
>> for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>> ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>> DUNNO
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482177
>> local=0.0.0.0 remote=108.138.7.33:443 HIER_DIRECT flags=1
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>> found conn482178 local=0.0.0.0 remote=108.138.7.48:443 HIER_DIRECT flags=1, destination #3
>> for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>> ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>> DUNNO
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482178
>> local=0.0.0.0 remote=108.138.7.48:443 HIER_DIRECT flags=1
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>> found conn482179 local=0.0.0.0 remote=108.138.7.88:443 HIER_DIRECT flags=1, destination #4
>> for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>> ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>> DUNNO
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482179
>> local=0.0.0.0 remote=108.138.7.88:443 HIER_DIRECT flags=1
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>> found conn482180 local=[::] remote=[2600:9000:2490:2200:3:db06:4200:93a1]:443 HIER_DIRECT
>> flags=1, destination #5 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>> ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>> DUNNO
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482180
>> local=[::] remote=[2600:9000:2490:2200:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>> found conn482181 local=[::] remote=[2600:9000:2490:3600:3:db06:4200:93a1]:443 HIER_DIRECT
>> flags=1, destination #6 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>> ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>> DUNNO
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482181
>> local=[::] remote=[2600:9000:2490:3600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>> found conn482182 local=[::] remote=[2600:9000:2490:7000:3:db06:4200:93a1]:443 HIER_DIRECT
>> flags=1, destination #7 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>> ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>> DUNNO
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482182
>> local=[::] remote=[2600:9000:2490:7000:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>> found conn482183 local=[::] remote=[2600:9000:2490:d600:3:db06:4200:93a1]:443 HIER_DIRECT
>> flags=1, destination #8 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>> ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>> DUNNO
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482183
>> local=[::] remote=[2600:9000:2490:d600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>> found conn482184 local=[::] remote=[2600:9000:2490:5a00:3:db06:4200:93a1]:443 HIER_DIRECT
>> flags=1, destination #9 for https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>> ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>> DUNNO
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482184
>> local=[::] remote=[2600:9000:2490:5a00:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>> found conn482185 local=[::] remote=[2600:9000:2490:6600:3:db06:4200:93a1]:443 HIER_DIRECT
>> flags=1, destination #10 for
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>> ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>> DUNNO
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482185
>> local=[::] remote=[2600:9000:2490:6600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>> found conn482186 local=[::] remote=[2600:9000:2490:b600:3:db06:4200:93a1]:443 HIER_DIRECT
>> flags=1, destination #11 for
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>> ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>> DUNNO
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482186
>> local=[::] remote=[2600:9000:2490:b600:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector64364
>> found conn482187 local=[::] remote=[2600:9000:2490:aa00:3:db06:4200:93a1]:443 HIER_DIRECT
>> flags=1, destination #12 for
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1180) handlePath:   always_direct =
>> ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1181) handlePath:    never_direct =
>> DUNNO
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(1182) handlePath:        timedout = 0
>>> 2024/07/10 18:24:44.050 kid1| 17,3| FwdState.cc(610) noteDestination: conn482187
>> local=[::] remote=[2600:9000:2490:aa00:3:db06:4200:93a1]:443 HIER_DIRECT flags=1
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(479) resolveSelected:
>> PeerSelector64364 found all 12 destinations for
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(480) resolveSelected:   always_direct
>> = ALLOWED
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(481) resolveSelected:    never_direct
>> = DUNNO
>>> 2024/07/10 18:24:44.050 kid1| 44,2| peer_select.cc(482) resolveSelected:        timedout
>> = 0
>>> 2024/07/10 18:24:44.050 kid1| 44,3| peer_select.cc(241) ~PeerSelector:
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.050 kid1| 20,3| store.cc(458) unlock: peerSelect unlocking key
>> 8349000000000000D107000001000000 e:=p2IV/0x5651b365e210*4
>>> 2024/07/10 18:24:44.050 kid1| 48,3| pconn.cc(474) popStored: lookup for key
>> {108.138.7.18:443/download.docker.com} failed.
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Checklist.cc(69) preCheck: 0x7ffef6c0a460 checking
>> fast ACLs
>>> 2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(110) match: aclMatchDomainList:
>> checking 'download.docker.com'
>>> 2024/07/10 18:24:44.050 kid1| 28,3| DomainData.cc(115) match: aclMatchDomainList:
>> 'download.docker.com' NOT found
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked: SKIP_PALO_DOMAINS_FAST
>> = 0
>>> 2024/07/10 18:24:44.050 kid1| 28,3| Acl.cc(175) matches: checked:
>> !SKIP_PALO_DOMAINS_FAST = 1
>>> 2024/07/10 18:24:44.051 kid1| 28,3| Acl.cc(175) matches: checked: (tcp_outgoing_mark
>> 0x14 line) = 1
>>> 2024/07/10 18:24:44.051 kid1| 28,3| Acl.cc(175) matches: checked: tcp_outgoing_mark 0x14
>> = 1
>>> 2024/07/10 18:24:44.051 kid1| 28,3| Checklist.cc(62) markFinished: 0x7ffef6c0a460 answer
>> ALLOWED for match
>>> 2024/07/10 18:24:44.051 kid1| 17,3| FwdState.cc(1568) GetMarkingsToServer: from 0.0.0.0
>> tos 0 netfilter mark 20
>>> 2024/07/10 18:24:44.051 kid1| 5,3| ConnOpener.cc(42) ConnOpener: will connect to
>> conn482189 local=0.0.0.0 remote=108.138.7.18:443 HIER_DIRECT flags=1 with 60 timeout
>>> 2024/07/10 18:24:44.051 kid1| 50,3| comm.cc(378) comm_openex: comm_openex: Attempt open
>> socket for: 0.0.0.0
>>> 2024/07/10 18:24:44.051 kid1| 50,3| comm.cc(420) comm_openex: comm_openex: Opened socket
>> conn482190 local=0.0.0.0 remote=[::] FD 19 flags=1 : family=2, type=1, protocol=6
>>> 2024/07/10 18:24:44.051 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 19
>> download.docker.com
>>> 2024/07/10 18:24:44.051 kid1| 50,3| QosConfig.cc(581) setSockNfmark: for FD 19 to 20
>>> 2024/07/10 18:24:44.051 kid1| 5,3| ConnOpener.cc(312) createFd: conn482189 local=0.0.0.0
>> remote=108.138.7.18:443 HIER_DIRECT flags=1 will timeout in 60
>>> 2024/07/10 18:24:44.058 kid1| 83,2| Io.cc(161) Handshake: handshake IN: Unknown
>> Handshake packet
>>> 2024/07/10 18:24:44.058 kid1| 83,2| Io.cc(163) Handshake: handshake OUT: CLIENT HELLO
>>> 2024/07/10 18:24:44.058 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482189
>> local=X.X.X.X:36718 remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1 timeout 60
>>> 2024/07/10 18:24:44.064 kid1| 83,2| Io.cc(161) Handshake: handshake IN: Unknown
>> Handshake packet
>>> 2024/07/10 18:24:44.064 kid1| 83,2| Io.cc(163) Handshake: handshake OUT: CLIENT HELLO
>>> 2024/07/10 18:24:44.064 kid1| 83,2| PeerConnector.cc(279) handleNegotiationResult:
>> ERROR: Cannot establish a TLS connection to conn482189 local=X.X.X.X:36718
>> remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1:
>>>       problem: failure
>>>       detail: SQUID_TLS_ERR_CONNECT+GNUTLS_E_FATAL_ALERT_RECEIVED
>>> 2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(625) commUnsetConnTimeout: Remove timeout for
>> conn482189 local=X.X.X.X:36718 remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1
>>> 2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn482189
>> local=X.X.X.X:36718 remote=108.138.7.18:443 HIER_DIRECT FD 19 flags=1 timeout -1
>>> 2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(850) _comm_close: start closing FD 19 by
>> Connection.cc:108
>>> 2024/07/10 18:24:44.064 kid1| 5,3| comm.cc(586) commUnsetFdTimeout: Remove timeout for
>> FD 19
>>> 2024/07/10 18:24:44.064 kid1| 83,3| Session.cc(36) tls_read_method: started for
>> session=0x5651b404d2c0
>>> 2024/07/10 18:24:44.064 kid1| 51,3| fd.cc(93) fd_close: fd_close FD 19 server https
>> start
>>> 2024/07/10 18:24:44.064 kid1| 17,3| FwdState.cc(471) fail: ERR_SECURE_CONNECT_FAIL
>> "Service Unavailable"
>>> 	https://download.docker.com/linux/ubuntu/dists/jammy/InRelease
>>> 2024/07/10 18:24:44.064 kid1| 17,3| FwdState.cc(781) retryOrBail: re-forwarding (1
>> tries, 0 secs)
>>>
>>>
>>>> -----Urspr?ngliche Nachricht-----
>>>> Von: Alex Rousskov <rousskov at measurement-factory.com>
>>>> Gesendet: Mittwoch, 10. Juli 2024 14:50
>>>> An: squid-users at lists.squid-cache.org
>>>> Cc: Fiehe, Christoph <c.fiehe at eurodata.de>
>>>> Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>>>>
>>>> On 2024-07-09 18:25, Fiehe, Christoph wrote:
>>>>
>>>>> I hope that somebody has an idea, what I am doing wrong.
>>>>
>>>> AFAICT from the debugging log, it is your parent proxy that returns an
>>>> ERR_SECURE_CONNECT_FAIL error page in response to a seemingly valid
>>>> "HEAD https://..." request. Can you ask their admin to investigate? You
>>>> may also recommend that they upgrade from Squid v4 that has many known
>>>> security vulnerabiities.
>>>>
>>>> If parent is uncooperative, you can try to reproduce the problem by
>>>> temporary installing your own parent Squid instance and configuring your
>>>> child Squid to use that instead.
>>>>
>>>> HTH,
>>>>
>>>> Alex.
>>>> P.S. Unlike Amos, I do not see serious conceptual problems with
>>>> rewriting request target scheme (as a temporary compatibility measure).
>>>> It may not always work, for various reasons, but it does not necessarily
>>>> make things worse (and may make things better).
>>>>
>>>>
>>>>
>>>>
>>>> I try to build a generic package proxy with Squid and need the feature
>>>> to rewrite (not redirect) a HTTP request to a package repository
>>>> transparently to a HTTPS-based package source. I was able to get Jesred
>>>> working and defined the following rewrite rule:
>>>>>
>>>>> regex ^http:\/\/download\.docker\.com(.*)$ https://download.docker.com\1
>>>>>
>>>>> I had to use a parent upstream proxy. In my test case the rule gets applied
>>>> successfully:
>>>>>
>>>>> 1720558404.106 10.2.59.102/molecule-ubuntu-jammy.lx.mycompany.de
>>>>
>> http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/l
>>>> inux/ubuntu/dists/jammy/InRelease]
>>>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease 2
>>>>>
>>>>> I have validated that the returned URL is correct and that the resource is accessible
>>>> via my upstream proxy.
>>>>>
>>>>> But at the very end, the client receives a 503 error code. I have set "debug_options
>>>> ALL,3" and this gives the log:
>>>>>
>>>>> [...]
>>>>> 2024/07/09 23:35:40.115 kid1| 11,2| client_side.cc(1333) parseHttpRequest: HTTP Client
>>>> REQUEST:
>>>>> ---------
>>>>> HEAD
>>>>
>> http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/l
>>>> inux/ubuntu/dists/jammy/InRelease] HTTP/1.1
>>>>> Host: download.docker.com
>>>>> User-Agent: curl/7.81.0
>>>>> Accept: */*
>>>>> Proxy-Connection: Keep-Alive
>>>>>
>>>>>
>>>>> ----------
>>>>> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(1364) parseHttpRequest: complete
>>>> request received. prefix_sz = 174, request-line-size=77, mime-header-size=97, mime
>> header
>>>> block:
>>>>> Host: download.docker.com
>>>>> User-Agent: curl/7.81.0
>>>>> Accept: */*
>>>>> Proxy-Connection: Keep-Alive
>>>>>
>>>>>
>>>>> ----------
>>>>> 2024/07/09 23:35:40.115 kid1| 87,3| clientStream.cc(139) clientStreamInsertHead:
>>>> clientStreamInsertHead: Inserted node 0x5c3ba4154308 with data 0x5c3ba4152950 after
>> head
>>>>> 2024/07/09 23:35:40.115 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn9
>>>> local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1 timeout 86400
>>>>> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(1767) add: 0x5c3ba41518e0*3 to 0/0
>>>>> 2024/07/09 23:35:40.115 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x5c3ba41501f0 add
>>>> request 1 0x5c3ba41518e0*4
>>>>> 2024/07/09 23:35:40.115 kid1| 23,3| Uri.cc(446) parse: Split URL
>>>>
>> 'http://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[http://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease'] into proto='http', host='download.docker.com',
>>>> port='80', path='/linux/ubuntu/dists/jammy/InRelease'
>>>>> 2024/07/09 23:35:40.115 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>>>> 'download.docker.com': Name or service not known
>>>>> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(702) clientSetKeepaliveFlag:
>> http_ver
>>>> = HTTP/1.1
>>>>> 2024/07/09 23:35:40.115 kid1| 33,3| client_side.cc(703) clientSetKeepaliveFlag: method
>> =
>>>> HEAD
>>>>> 2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(122) ClientRequestContext:
>>>> ClientRequestContext constructed, this=0x5c3ba4154e78
>>>>> 2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1708) doCallouts: Doing
>>>> calloutContext->hostHeaderVerify()
>>>>> 2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(606) hostHeaderVerify:
>>>> validate host=download.docker.com, port=0, portStr=NULL
>>>>> 2024/07/09 23:35:40.115 kid1| 85,3| client_side_request.cc(620) hostHeaderVerify:
>>>> validate skipped.
>>>>> 2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1715) doCallouts: Doing
>>>> calloutContext->clientAccessCheck()
>>>>> 2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba41552d8 checking
>>>> slow rules
>>>>> 2024/07/09 23:35:40.115 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '10.2.59.102:56466'
>>>> found
>>>>> 2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>>>>> 2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: http_access#1 = 1
>>>>> 2024/07/09 23:35:40.115 kid1| 28,3| Acl.cc(175) matches: checked: http_access = 1
>>>>> 2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba41552d8
>> answer
>>>> ALLOWED for match
>>>>> 2024/07/09 23:35:40.115 kid1| 28,3| Checklist.cc(162) checkCallback:
>>>> ACLChecklist::checkCallback: 0x5c3ba41552d8 answer=ALLOWED
>>>>> 2024/07/09 23:35:40.115 kid1| 85,2| client_side_request.cc(714) clientAccessCheckDone:
>>>> The request HEAD
>>>>
>> http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/l
>>>> inux/ubuntu/dists/jammy/InRelease] is ALLOWED; last ACL checked: all
>>>>> 2024/07/09 23:35:40.115 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
>>>>> 2024/07/09 23:35:40.115 kid1| 83,3| client_side_request.cc(1735) doCallouts: Doing
>>>> calloutContext->clientRedirectStart()
>>>>> 2024/07/09 23:35:40.115 kid1| 78,3| dns_internal.cc(1836) idnsPTRLookup:
>> idnsPTRLookup:
>>>> buf is 42 bytes for 10.2.59.102, id = 0x8d95
>>>>> 2024/07/09 23:35:40.115 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto:
>>>> Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
>>>>> 2024/07/09 23:35:40 kid1| Starting new redirector helpers...
>>>>> current master transaction: master54
>>>>> 2024/07/09 23:35:40 kid1| helperOpenServers: Starting 1/3 'jesred' processes
>>>>> current master transaction: master54
>>>>> 2024/07/09 23:35:40.115 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 17 IPC UNIX
>> STREAM
>>>> Parent
>>>>> 2024/07/09 23:35:40.115 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 19 IPC UNIX
>> STREAM
>>>> Parent
>>>>> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(212) ipcCreate: ipcCreate: prfd FD 17
>>>>> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(213) ipcCreate: ipcCreate: pwfd FD 17
>>>>> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(214) ipcCreate: ipcCreate: crfd FD 19
>>>>> 2024/07/09 23:35:40.115 kid1| 54,3| ipc.cc(215) ipcCreate: ipcCreate: cwfd FD 19
>>>>> 2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(850) _comm_close: start closing FD 19 by
>>>> ipc.cc:271
>>>>> 2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(586) commUnsetFdTimeout: Remove timeout for
>>>> FD 19
>>>>> 2024/07/09 23:35:40.116 kid1| 21,3| tools.cc(561) leave_suid: leave_suid: PID 503746
>>>> called
>>>>> 2024/07/09 23:35:40.116 kid1| 21,3| tools.cc(651) no_suid: no_suid: PID 503746 giving
>> up
>>>> root privileges forever
>>>>> 2024/07/09 23:35:40.116 kid1| 5,3| comm.cc(586) commUnsetFdTimeout: Remove timeout for
>>>> FD 17
>>>>> 2024/07/09 23:35:40.117 kid1| 84,3| helper.cc(1310) GetFirstAvailable:
>>>> GetFirstAvailable: Least-loaded helper is fully loaded!
>>>>> 2024/07/09 23:35:40.117 kid1| 51,3| fd.cc(93) fd_close: fd_close FD 19 IPC UNIX STREAM
>>>> Parent
>>>>> 2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting
>>>> with FD 11
>>>>> 2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11:
>>>> received 92 bytes from 127.0.0.53:53
>>>>> 2024/07/09 23:35:40.117 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply:
>> idnsGrokReply:
>>>> QID 0x8d95, 1 answers
>>>>> 2024/07/09 23:35:40.117 kid1| 35,3| fqdncache.cc(336) fqdncacheParse: fqdncacheParse:
>> 1
>>>> answers for '10.2.59.102'
>>>>> 2024/07/09 23:35:40.117 kid1| 5,3| IoCallback.cc(112) finish: called for conn11
>>>> local=[::] remote=[::] FD 17 flags=1 (0, 0)
>>>>> 2024/07/09 23:35:40.125 kid1| 5,3| Read.cc(148) HandleRead: FD 17, size 32767, retval
>>>> 80, errno 0
>>>>> 2024/07/09 23:35:40.125 kid1| 5,3| IoCallback.cc(112) finish: called for conn10
>>>> local=[::] remote=[::] FD 17 flags=1 (0, 0)
>>>>> 2024/07/09 23:35:40.125 kid1| 84,3| helper.cc(1022) helperHandleRead:
>> helperHandleRead:
>>>> end of reply found
>>>>> 2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(41) finalize: Parsing helper buffer
>>>>> 2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(59) finalize: Buff length is larger than
>> 2
>>>>> 2024/07/09 23:35:40.125 kid1| 84,3| Reply.cc(63) finalize: helper Result = OK
>>>>> 2024/07/09 23:35:40.125 kid1| 23,3| Uri.cc(446) parse: Split URL
>>>>
>> 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>>>> om/linux/ubuntu/dists/jammy/InRelease'] into proto='https', host='download.docker.com',
>>>> port='443', path='/linux/ubuntu/dists/jammy/InRelease'
>>>>> 2024/07/09 23:35:40.125 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>>>> 'download.docker.com': Name or service not known
>>>>> 2024/07/09 23:35:40.125 kid1| 61,2| client_side_request.cc(1235) clientRedirectDone:
>>>> URL-rewriter diverts URL from
>>>>
>> http://download.docker.com/linux/ubuntu/dists/jammy/InRelease[http://download.docker.com/l
>>>> inux/ubuntu/dists/jammy/InRelease] to
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease]
>>>>> 2024/07/09 23:35:40.125 kid1| 83,3| client_side_request.cc(1743) doCallouts: Doing
>>>> calloutContext->clientAccessCheck2()
>>>>> 2024/07/09 23:35:40.125 kid1| 85,2| client_side_request.cc(692) clientAccessCheck2: No
>>>> adapted_http_access configuration. default: ALLOW
>>>>> 2024/07/09 23:35:40.125 kid1| 85,2| client_side_request.cc(714) clientAccessCheckDone:
>>>> The request HEAD
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease] is ALLOWED; last ACL checked: all
>>>>> 2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1761) doCallouts: Doing
>>>> clientInterpretRequestHeaders()
>>>>> 2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1770) doCallouts: Doing
>>>> calloutContext->checkNoCache()
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba41552d8 checking
>>>> slow rules
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| RegexData.cc(50) match: checking
>>>>
>> 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>>>> om/linux/ubuntu/dists/jammy/InRelease']
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: no_cache = 0
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache#1 = 0
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '10.2.59.102:56466'
>>>> found
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache#2 = 1
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: cache = 1
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba41552d8
>> answer
>>>> ALLOWED for match
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(162) checkCallback:
>>>> ACLChecklist::checkCallback: 0x5c3ba41552d8 answer=ALLOWED
>>>>> 2024/07/09 23:35:40.126 kid1| 85,3| client_side_request.cc(116) ~ClientRequestContext:
>>>> ClientRequestContext destructed, this=0x5c3ba4154e78
>>>>> 2024/07/09 23:35:40.126 kid1| 83,3| client_side_request.cc(1855) doCallouts: calling
>>>> processRequest()
>>>>> 2024/07/09 23:35:40.126 kid1| 87,3| clientStream.cc(178) clientStreamRead:
>>>> clientStreamRead: Calling 1 with cbdata 0x5c3ba4153e70 from node 0x5c3ba4154308
>>>>> 2024/07/09 23:35:40.126 kid1| 73,3| HttpRequest.cc(742) storeId: sent back
>>>> effectiveRequestUrl:
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease]
>>>>> 2024/07/09 23:35:40.126 kid1| 20,3| Controller.cc(429) peek:
>>>> DE850794EBC405A27A7718F51795E32A
>>>>> 2024/07/09 23:35:40.126 kid1| 73,3| HttpRequest.cc(742) storeId: sent back
>>>> effectiveRequestUrl:
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease]
>>>>> 2024/07/09 23:35:40.126 kid1| 20,3| Controller.cc(429) peek:
>>>> D3522EE27FB0ED7004DD594AF7674667
>>>>> 2024/07/09 23:35:40.126 kid1| 85,3| client_side_reply.cc(1523) identifyFoundObject:
>>>> StoreEntry is NULL - MISS
>>>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(730) storeCreatePureEntry:
>>>> storeCreateEntry:
>>>>
>> 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>>>> om/linux/ubuntu/dists/jammy/InRelease']
>>>>> 2024/07/09 23:35:40.126 kid1| 20,3| MemObject.cc(99) MemObject: MemObject constructed,
>>>> this=0x5c3ba416ef10
>>>>> 2024/07/09 23:35:40.126 kid1| 88,3| MemObject.cc(82) setUris: 0x5c3ba416ef10 storeId:
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease]
>>>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: storeCreateEntry locked key
>>>> [null_store_key] e:=V/0x5c3ba416ee90*1
>>>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(536) setPrivateKey: 00
>>>> e:=V/0x5c3ba416ee90*1
>>>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(412) hashInsert: StoreEntry::hashInsert:
>>>> Inserting Entry e:=IV/0x5c3ba416ee90*1 key '020000000000000061AF070001000000'
>>>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: store_client locked key
>>>> 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*2
>>>>> 2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(243) copy: store_client::copy:
>>>> 020000000000000061AF070001000000, from 0, for length 4096, cb 1, cbdata 0x5c3ba4152dd8
>>>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: store_client::copy locked key
>>>> 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
>>>>> 2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(343) storeClientCopy2:
>>>> storeClientCopy2: 020000000000000061AF070001000000
>>>>> 2024/07/09 23:35:40.126 kid1| 90,3| store_client.cc(390) doCopy: store_client::doCopy:
>>>> Waiting for more
>>>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(457) unlock: store_client::copy unlocking
>>>> key 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
>>>>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(373) Start:
>>>>
>> 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>>>> om/linux/ubuntu/dists/jammy/InRelease']
>>>>> 2024/07/09 23:35:40.126 kid1| 17,2| FwdState.cc(133) FwdState: Forwarding client
>> request
>>>> conn9 local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1,
>>>>
>> url=https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker
>>>> .com/linux/ubuntu/dists/jammy/InRelease]
>>>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: FwdState locked key
>>>> 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*3
>>>>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(140) FwdState: FwdState constructed,
>>>> this=0x5c3ba416fa18
>>>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(309) peerSelect:
>>>> e:=IV/0x5c3ba416ee90*3
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease]
>>>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(434) lock: peerSelect locked key
>>>> 020000000000000061AF070001000000 e:=IV/0x5c3ba416ee90*4
>>>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(612) selectMore: HEAD
>>>> download.docker.com
>>>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(626) selectMore: direct =
>>>> DIRECT_UNKNOWN (never_direct to be checked)
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(69) preCheck: 0x5c3ba4170638 checking
>>>> slow rules
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Ip.cc(538) match: aclIpMatchIp:
>> '10.2.59.102:56466'
>>>> found
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: all = 1
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: never_direct#1 = 1
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Acl.cc(175) matches: checked: never_direct = 1
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(62) markFinished: 0x5c3ba4170638
>> answer
>>>> ALLOWED for match
>>>>> 2024/07/09 23:35:40.126 kid1| 28,3| Checklist.cc(162) checkCallback:
>>>> ACLChecklist::checkCallback: 0x5c3ba4170638 answer=ALLOWED
>>>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(345) checkNeverDirectDone: ALLOWED
>>>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(351) checkNeverDirectDone: direct =
>>>> DIRECT_NO (never_direct allow)
>>>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(612) selectMore: HEAD
>>>> download.docker.com
>>>>> 2024/07/09 23:35:40.126 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname:
>>>> ipcache_gethostbyname: 'download.docker.com', flags=0
>>>>> 2024/07/09 23:35:40.126 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>>>> 'download.docker.com': Name or service not known
>>>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(286) peerSelectIcpPing:
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease]
>>>>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(283) neighborsCount: neighborsCount:
>> 0
>>>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(297) peerSelectIcpPing: counted 0
>>>> neighbors
>>>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(833) selectSomeParent: HEAD
>>>> download.docker.com
>>>>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(350) getRoundRobinParent: returning
>>>> [nil]
>>>>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(403) getWeightedRoundRobinParent:
>>>> returning [nil]
>>>>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(309) getFirstUpParent: returning
>>>> 212.89.128.96
>>>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1102) addSelection: adding
>>>> FIRSTUP_PARENT/212.89.128.96
>>>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1095) addSelection: skipping
>>>> ANY_OLD_PARENT/212.89.128.96; have FIRSTUP_PARENT/212.89.128.96
>>>>> 2024/07/09 23:35:40.126 kid1| 15,3| neighbors.cc(493) getDefaultParent: returning
>>>> 212.89.128.96
>>>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(1095) addSelection: skipping
>>>> DEFAULT_PARENT/212.89.128.96; have FIRSTUP_PARENT/212.89.128.96
>>>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(460) resolveSelected: Find IP
>>>> destination for:
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.co
>>>> m/linux/ubuntu/dists/jammy/InRelease'] via 212.89.128.96
>>>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector1
>> found
>>>> conn12 local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1, destination #1
>> for
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease]
>>>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct =
>>>> DENIED
>>>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct =
>>>> ALLOWED
>>>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
>>>>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(610) noteDestination: conn12
>>>> local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1
>>>>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(1124) connectStart: 1+ paths to
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease]
>>>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(479) resolveSelected: PeerSelector1
>>>> found all 1 destinations for
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease]
>>>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(480) resolveSelected: always_direct
>> =
>>>> DENIED
>>>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(481) resolveSelected: never_direct
>> =
>>>> ALLOWED
>>>>> 2024/07/09 23:35:40.126 kid1| 44,2| peer_select.cc(482) resolveSelected: timedout = 0
>>>>> 2024/07/09 23:35:40.126 kid1| 44,3| peer_select.cc(241) ~PeerSelector:
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease]
>>>>> 2024/07/09 23:35:40.126 kid1| 20,3| store.cc(457) unlock: peerSelect unlocking key
>>>> 020000000000000061AF070001000000 e:=p2IV/0x5c3ba416ee90*4
>>>>> 2024/07/09 23:35:40.126 kid1| 48,3| pconn.cc(474) popStored: lookup for key
>>>> {212.89.128.96:3128} failed.
>>>>> 2024/07/09 23:35:40.126 kid1| 17,3| FwdState.cc(1568) GetMarkingsToServer: from
>> 0.0.0.0
>>>> tos 0 netfilter mark 0
>>>>> 2024/07/09 23:35:40.126 kid1| 5,3| ConnOpener.cc(42) ConnOpener: will connect to
>> conn14
>>>> local=0.0.0.0 remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1 with 30 timeout
>>>>> 2024/07/09 23:35:40.126 kid1| 50,3| comm.cc(378) comm_openex: comm_openex: Attempt
>> open
>>>> socket for: 0.0.0.0
>>>>> 2024/07/09 23:35:40.126 kid1| 50,3| comm.cc(420) comm_openex: comm_openex: Opened
>> socket
>>>> conn15 local=0.0.0.0 remote=[::] FD 19 flags=1 : family=2, type=1, protocol=6
>>>>> 2024/07/09 23:35:40.126 kid1| 51,3| fd.cc(168) fd_open: fd_open() FD 19
>>>>> 2024/07/09 23:35:40.126 kid1| 5,3| ConnOpener.cc(312) createFd: conn14 local=0.0.0.0
>>>> remote=212.89.128.96:3128 FIRSTUP_PARENT flags=1 will timeout in 30
>>>>> 2024/07/09 23:35:40.127 kid1| 17,3| FwdState.cc(1197) dispatch: conn9
>>>> local=10.2.59.103:8000 remote=10.2.59.102:56466 FD 15 flags=1: Fetching HEAD
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease]
>>>>> 2024/07/09 23:35:40.127 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP
>>>> 'download.docker.com': Name or service not known
>>>>> 2024/07/09 23:35:40.127 kid1| 78,3| dns_internal.cc(1793) idnsALookup: idnsALookup:
>> buf
>>>> is 37 bytes for download.docker.com, id = 0xe779
>>>>> 2024/07/09 23:35:40.127 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto:
>>>> Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
>>>>> 2024/07/09 23:35:40.127 kid1| 78,3| dns_internal.cc(1729) idnsSendSlaveAAAAQuery: buf
>> is
>>>> 37 bytes for download.docker.com, id = 0x8aee
>>>>> 2024/07/09 23:35:40.127 kid1| 50,3| comm.cc(927) comm_udp_sendto: comm_udp_sendto:
>>>> Attempt to send UDP packet to 127.0.0.53:53 using FD 11 using Port 54280
>>>>> 2024/07/09 23:35:40.127 kid1| 11,3| http.cc(2516) httpStart: HEAD
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease]
>>>>> 2024/07/09 23:35:40.127 kid1| 20,3| store.cc(434) lock: Client locked key
>>>> 020000000000000061AF070001000000 e:=p2IV/0x5c3ba416ee90*4
>>>>> 2024/07/09 23:35:40.127 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn14
>>>> local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 timeout
>>>> 86400
>>>>> 2024/07/09 23:35:40.127 kid1| 22,3| refresh.cc(636) getMaxAge: getMaxAge:
>>>>
>> 'https://download.docker.com/linux/ubuntu/dists/jammy/InRelease'[https://download.docker.c
>>>> om/linux/ubuntu/dists/jammy/InRelease']
>>>>> 2024/07/09 23:35:40.127 kid1| 11,2| http.cc(2472) sendRequest: HTTP Server conn14
>>>> local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1
>>>>> 2024/07/09 23:35:40.127 kid1| 11,2| http.cc(2473) sendRequest: HTTP Server REQUEST:
>>>>> ---------
>>>>> HEAD
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease] HTTP/1.1
>>>>> Host: download.docker.com
>>>>> User-Agent: curl/7.81.0
>>>>> Accept: */*
>>>>> Via: 1.1 pkg-proxy (squid/6.6)
>>>>> X-Forwarded-For: 10.2.59.102
>>>>> Cache-Control: max-age=0
>>>>> Connection: keep-alive
>>>>>
>>>>>
>>>>> ----------
>>>>> 2024/07/09 23:35:40.127 kid1| 5,3| IoCallback.cc(112) finish: called for conn14
>>>> local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 (0, 0)
>>>>> 2024/07/09 23:35:40.127 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn14
>>>> local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 timeout
>> 900
>>>>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting
>>>> with FD 11
>>>>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11:
>>>> received 304 bytes from 127.0.0.53:53
>>>>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply:
>> idnsGrokReply:
>>>> QID 0x8aee, 9 answers
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(480) ipcacheParse: 9 answers for
>>>> download.docker.com
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #1
>>>> [2600:9000:2490:6c00:3:db06:4200:93a1]
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #2
>>>> [2600:9000:2490:a600:3:db06:4200:93a1]
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #3
>>>> [2600:9000:2490:9c00:3:db06:4200:93a1]
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #4
>>>> [2600:9000:2490:6000:3:db06:4200:93a1]
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #5
>>>> [2600:9000:2490:c00:3:db06:4200:93a1]
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #6
>>>> [2600:9000:2490:5200:3:db06:4200:93a1]
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #7
>>>> [2600:9000:2490:9a00:3:db06:4200:93a1]
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #8
>>>> [2600:9000:2490:2c00:3:db06:4200:93a1]
>>>>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting
>>>> with FD 11
>>>>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 11:
>>>> received 144 bytes from 127.0.0.53:53
>>>>> 2024/07/09 23:35:40.137 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply:
>> idnsGrokReply:
>>>> QID 0xe779, 5 answers
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(480) ipcacheParse: 5 answers for
>>>> download.docker.com
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #9
>>>> 108.138.7.33
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #10
>>>> 108.138.7.18
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #11
>>>> 108.138.7.88
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(535) addGood: download.docker.com #12
>>>> 108.138.7.48
>>>>> 2024/07/09 23:35:40.137 kid1| 14,3| ipcache.cc(586) ipcacheHandleReply: done with
>>>> download.docker.com: [2600:9000:2490:6c00:3:db06:4200:93a1] #1/12-0
>>>>> 2024/07/09 23:35:40.137 kid1| 38,3| net_db.cc(337) netdbSendPing: netdbSendPing:
>> pinging
>>>> download.docker.com
>>>>> 2024/07/09 23:35:40.137 kid1| 37,2| IcmpSquid.cc(88) SendEcho: to
>>>> [2600:9000:2490:6c00:3:db06:4200:93a1], opcode 3, len 19
>>>>> 2024/07/09 23:35:40.137 pinger| 42,2| IcmpPinger.cc(198) Recv: Pass
>>>> [2600:9000:2490:6c00:3:db06:4200:93a1] off to ICMPv6 module.
>>>>> 2024/07/09 23:35:40 pinger| SendEcho ERROR: sending to ICMPv6 packet to
>>>> [2600:9000:2490:6c00:3:db06:4200:93a1]: (101) Network is unreachable
>>>>> 2024/07/09 23:35:40.138 pinger| 42,2| Icmp.cc(90) Log: pingerLog: 1720560940.138021
>>>> [2600:9000:2490:6c00:3:db06:4200:93a1] 0
>>>>> 2024/07/09 23:35:40.323 kid1| 5,3| IoCallback.cc(112) finish: called for conn14
>>>> local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1 (0, 0)
>>>>> 2024/07/09 23:35:40.324 kid1| 5,3| Read.cc(93) ReadNow: conn14 local=10.2.59.103:39370
>>>> remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1, size 65536, retval 348, errno 0
>>>>> 2024/07/09 23:35:40.324 kid1| 11,3| http.cc(649) processReplyHeader:
>> processReplyHeader:
>>>> key '020000000000000061AF070001000000'
>>>>> 2024/07/09 23:35:40.324 kid1| 11,2| http.cc(696) processReplyHeader: HTTP Server
>> conn14
>>>> local=10.2.59.103:39370 remote=212.89.128.96:3128 FIRSTUP_PARENT FD 19 flags=1
>>>>> 2024/07/09 23:35:40.324 kid1| 11,2| http.cc(697) processReplyHeader: HTTP Server
>>>> RESPONSE:
>>>>> ---------
>>>>> HTTP/1.1 503 Service Unavailable
>>>>> Server: squid/4.10
>>>>> Mime-Version: 1.0
>>>>> Date: Tue, 09 Jul 2024 21:35:40 GMT
>>>>> Content-Type: text/html;charset=utf-8
>>>>> Content-Length: 3879
>>>>> X-Squid-Error: ERR_SECURE_CONNECT_FAIL 71
>>>>> X-Cache: MISS from proxy-srv2
>>>>> X-Cache-Lookup: MISS from proxy-srv2:3128
>>>>> Via: 1.1 proxy-srv2 (squid/4.10)
>>>>> Connection: keep-alive
>>>>>
>>>>> ----------
>>>>> 2024/07/09 23:35:40.324 kid1| 83,3| AccessCheck.cc(42) Start: adaptation off, skipping
>>>>> 2024/07/09 23:35:40.324 kid1| 20,3| store.cc(1693) replaceHttpReply:
>>>> StoreEntry::replaceHttpReply:
>>>>
>> https://download.docker.com/linux/ubuntu/dists/jammy/InRelease[https://download.docker.com
>>>> /linux/ubuntu/dists/jammy/InRelease]
>>>>> 2024/07/09 23:35:40.324 kid1| 11,3| http.cc(949) haveParsedReplyHeaders: HTTP CODE:
>> 503
>>>>>
>>>>> Has anybody an idea what I can do to solve the issue?
>>>>>
>>>>> This is my configuration borrowed from squid-deb-proxy:
>>>>>
>>>>> # this file contains private networks (10.0.0.0/8, 172.16.0.0/12,
>>>>> # 192.168.0.0/16) by default, you can add/remove additional allowed
>>>>> # source networks in it to customize it for your setup
>>>>> acl src_networks src "/etc/squid/acl/src-networks.acl"
>>>>>
>>>>> # this file contains the archive mirrors by default,
>>>>> # if you use a different mirror, add it there
>>>>> acl to_archive_mirrors dstdomain "/etc/squid/acl/archive-mirrors.acl"
>>>>>
>>>>> # Disable Cache for defined domains
>>>>> acl no_cache url_regex "/etc/squid/acl/no-cache.acl"
>>>>>
>>>>> # this contains the package blacklist
>>>>> acl blockedpkgs urlpath_regex "/etc/squid/pkg-blacklist-regexp.acl"
>>>>>
>>>>> # default to a different port than stock squid
>>>>> http_port 8000
>>>>>
>>>>> # -------------------------------------------------
>>>>> # settings below probably do not need customization
>>>>>
>>>>> # user visible name
>>>>> visible_hostname pkg-proxy
>>>>>
>>>>> # we need a big cache, some debs are huge
>>>>> maximum_object_size 512 MB
>>>>>
>>>>> # use a different dir than stock squid and default to 40G
>>>>> cache_dir aufs /var/cache/squid 40000 16 256
>>>>>
>>>>> cache_peer 212.89.128.96 parent 3128 0 no-query default
>>>>> never_direct allow all
>>>>>
>>>>> # use different logs
>>>>> cache_access_log /var/log/squid/access.log
>>>>> cache_log /var/log/squid/cache.log
>>>>> cache_store_log /var/log/squid/store.log
>>>>>
>>>>> # tweaks to speed things up
>>>>> cache_mem 200 MB
>>>>> maximum_object_size_in_memory 10240 KB
>>>>>
>>>>> # pid
>>>>> pid_filename /var/run/squid.pid
>>>>>
>>>>> # refresh pattern for debs and udebs
>>>>> refresh_pattern deb$ 129600 100% 129600
>>>>> refresh_pattern udeb$ 129600 100% 129600
>>>>> refresh_pattern tar.gz$ 129600 100% 129600
>>>>> refresh_pattern tar.xz$ 129600 100% 129600
>>>>> refresh_pattern tar.bz2$ 129600 100% 129600
>>>>>
>>>>> # always refresh Packages and Release files
>>>>> refresh_pattern \/(Packages|Sources)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims
>>>>> refresh_pattern \/Release(|\.gpg)$ 0 0% 0 refresh-ims
>>>>> refresh_pattern \/InRelease$ 0 0% 0 refresh-ims
>>>>> refresh_pattern \/(Translation-.*)(|\.bz2|\.gz|\.xz)$ 0 0% 0 refresh-ims
>>>>>
>>>>> # handle meta-release and changelogs.ubuntu.com special
>>>>> # (fine to have this on debian too)
>>>>> refresh_pattern changelogs.ubuntu.com\/.* 0 1% 1
>>>>>
>>>>> # only allow connects to ports for http, https
>>>>> acl SSL_ports port 443 563
>>>>> acl Safe_ports port 80
>>>>> acl Safe_ports port 443 563
>>>>>
>>>>> # only allow ports we trust
>>>>> http_access deny !Safe_ports
>>>>>
>>>>> # do not allow to download from the pkg blacklist
>>>>> http_access deny blockedpkgs
>>>>>
>>>>> # allow access only to official archive mirrors
>>>>> # uncomment the third and fouth line to permit any unlisted domain
>>>>> http_access deny !to_archive_mirrors
>>>>>
>>>>> # allow access from our network and localhost
>>>>> http_access allow src_networks
>>>>>
>>>>> # And finally deny all other access to this proxy
>>>>> http_access deny all
>>>>>
>>>>> # don't cache domains not listed in the mirrors file
>>>>> # uncomment the third and fourth line to cache any unlisted domains
>>>>> cache deny no_cache
>>>>>
>>>>> # And finally cache everything else
>>>>> cache allow all
>>>>>
>>>>> url_rewrite_children 3 startup=0 idle=1 concurrency=1
>>>>> url_rewrite_program /usr/lib/squid/jesred
>>>>>
>>>>> debug_options ALL,3
>>>>>
>>>>> Thanks a lot.
>>>>>
>>>>> Regards,
>>>>> Christoph
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
> 



From c.fiehe at eurodata.de  Wed Jul 10 20:57:43 2024
From: c.fiehe at eurodata.de (Fiehe, Christoph)
Date: Wed, 10 Jul 2024 20:57:43 +0000
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <cda7c451-72eb-4be5-bc10-a7db7ea1ba64@measurement-factory.com>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
 <6bb89d7c58e34320b1eb15c1447e99d7@eurodata.de>
 <ca32f7f1-9123-47d4-a7ba-dfc40d0c6937@measurement-factory.com>
 <867452bfd4ff482bb60b90d4482265a7@eurodata.de>
 <cda7c451-72eb-4be5-bc10-a7db7ea1ba64@measurement-factory.com>
Message-ID: <2d18e96ef2be492f9deea0b5c07688f5@eurodata.de>

No problem. I am just trying to find something that helps to narrow down the problem. What I want to achieve is, that a client can use HTTP in the LAN, so that Squid can cache distribution packages without making use of SSL intercepting when repos are only accessible via HTTPS. In that case the secure connection must start at the proxy and end on the target server with or without any upstream proxies in betweem. When the proxy has received the payload, it can cache it and send it back to the client via plain HTTP. When a new request for this package arrives, the server can just return the resource from the cache.

We have the following setup:

client -> downstream proxy -> upstream proxy -> https://download.docker.com

Now let us assume the client wants to retrieve the following resource http://download.docker.com/linux/ubuntu/dists/jammy/InRelease from the upstream proxy.

The client initiates a HTTP GET request and sends it to the downstream proxy. Now, the URL gets rewritten. It indicates to use a HTTPS connection instead in order to talk to the target server, in our case the result is https://download.docker.com/linux/ubuntu/dists/jammy/InRelease. Now comes the critical point: From my understanding ? it may be wrong of course - the downstream server now has to send a CONNECT request to the upstream server to advise him to establish a secure connection to the target server. After creation, the downstream proxy can retrieve the resource and send it back to the client via plain HTTP.

I suppose, that the GnuTLS occurs because of a missing SSL handshake between downstream proxy and download.docker.com.

Do I get something wrong?

Regards,
Christoph


>-----Urspr?ngliche Nachricht-----
>Von: Alex Rousskov <rousskov at measurement-factory.com>
>Gesendet: Mittwoch, 10. Juli 2024 22:15
>An: squid-users at lists.squid-cache.org
>Cc: Fiehe, Christoph <c.fiehe at eurodata.de>
>Betreff: AW: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>
>On 2024-07-10 15:31, Fiehe, Christoph wrote:
>> The problem is that the proxy just forwards the client GET request to the upstream proxy
>
>Why does sending a GET request to the upstream proxy represent a problem
>in your use case? I cannot find anything in your prior messages on this
>thread that would preclude sending a GET request to the upstream proxy.
>
>
>> but in that case a CONNECT is required.
>
>Why?
>
>Please do not interpret my response as implying that this "must send
>CONNECT" requirement is wrong (or correct). At this point, I am just
>trying to understand what problem(s) you are trying to solve beyond the
>one you have originally described.
>
>
>Thank you,
>
>Alex.


From c.fiehe at eurodata.de  Wed Jul 10 21:09:00 2024
From: c.fiehe at eurodata.de (Fiehe, Christoph)
Date: Wed, 10 Jul 2024 21:09:00 +0000
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <2d18e96ef2be492f9deea0b5c07688f5@eurodata.de>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
 <6bb89d7c58e34320b1eb15c1447e99d7@eurodata.de>
 <ca32f7f1-9123-47d4-a7ba-dfc40d0c6937@measurement-factory.com>
 <867452bfd4ff482bb60b90d4482265a7@eurodata.de>
 <cda7c451-72eb-4be5-bc10-a7db7ea1ba64@measurement-factory.com>
 <2d18e96ef2be492f9deea0b5c07688f5@eurodata.de>
Message-ID: <1c91f7425a8c45cb80970de7f484a4d6@eurodata.de>

The caching feature is implemented by Apt-Cacher-NG, but the proxy only works sporadically. Squid seems to be a better choice. The remapping feature, for what I try to find a solution in Squid, is e.g. described at https://blog.packagecloud.io/using-apt-cacher-ng-with-ssl-tls/ in section "Caching objects.


>-----Urspr?ngliche Nachricht-----
>Von: squid-users <squid-users-bounces at lists.squid-cache.org> Im Auftrag von Fiehe,
>Christoph
>Gesendet: Mittwoch, 10. Juli 2024 22:58
>An: squid-users at lists.squid-cache.org
>Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>
>No problem. I am just trying to find something that helps to narrow down the problem. What
>I want to achieve is, that a client can use HTTP in the LAN, so that Squid can cache
>distribution packages without making use of SSL intercepting when repos are only
>accessible via HTTPS. In that case the secure connection must start at the proxy and end
>on the target server with or without any upstream proxies in betweem. When the proxy has
>received the payload, it can cache it and send it back to the client via plain HTTP. When
>a new request for this package arrives, the server can just return the resource from the
>cache.
>
>We have the following setup:
>
>client -> downstream proxy -> upstream proxy -> https://download.docker.com
>
>Now let us assume the client wants to retrieve the following resource
>http://download.docker.com/linux/ubuntu/dists/jammy/InRelease from the upstream proxy.
>
>The client initiates a HTTP GET request and sends it to the downstream proxy. Now, the URL
>gets rewritten. It indicates to use a HTTPS connection instead in order to talk to the
>target server, in our case the result is
>https://download.docker.com/linux/ubuntu/dists/jammy/InRelease. Now comes the critical
>point: From my understanding ? it may be wrong of course - the downstream server now has
>to send a CONNECT request to the upstream server to advise him to establish a secure
>connection to the target server. After creation, the downstream proxy can retrieve the
>resource and send it back to the client via plain HTTP.
>
>I suppose, that the GnuTLS occurs because of a missing SSL handshake between downstream
>proxy and download.docker.com.
>
>Do I get something wrong?
>
>Regards,
>Christoph
>
>
>>-----Urspr?ngliche Nachricht-----
>>Von: Alex Rousskov <rousskov at measurement-factory.com>
>>Gesendet: Mittwoch, 10. Juli 2024 22:15
>>An: squid-users at lists.squid-cache.org
>>Cc: Fiehe, Christoph <c.fiehe at eurodata.de>
>>Betreff: AW: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>>
>>On 2024-07-10 15:31, Fiehe, Christoph wrote:
>>> The problem is that the proxy just forwards the client GET request to the upstream
>proxy
>>
>>Why does sending a GET request to the upstream proxy represent a problem
>>in your use case? I cannot find anything in your prior messages on this
>>thread that would preclude sending a GET request to the upstream proxy.
>>
>>
>>> but in that case a CONNECT is required.
>>
>>Why?
>>
>>Please do not interpret my response as implying that this "must send
>>CONNECT" requirement is wrong (or correct). At this point, I am just
>>trying to understand what problem(s) you are trying to solve beyond the
>>one you have originally described.
>>
>>
>>Thank you,
>>
>>Alex.
>
>_______________________________________________
>squid-users mailing list
>squid-users at lists.squid-cache.org
>https://lists.squid-cache.org/listinfo/squid-users

From alan.long at vesta.io  Thu Jul 11 14:23:14 2024
From: alan.long at vesta.io (Alan Long)
Date: Thu, 11 Jul 2024 14:23:14 +0000
Subject: [squid-users] After upgrade from 5.7 to 5.9 the whitelists were
 not listed , we had to readd them.
In-Reply-To: <SJ2PR02MB9414DE2F284EA30B97C2C06981A52@SJ2PR02MB9414.namprd02.prod.outlook.com>
References: <SJ2PR02MB9414DE2F284EA30B97C2C06981A52@SJ2PR02MB9414.namprd02.prod.outlook.com>
Message-ID: <SJ2PR02MB9414ADE532760A6E1DB10B1181A52@SJ2PR02MB9414.namprd02.prod.outlook.com>

We did an upgrade from 5.7 to 5.9 and after the upgrade the whitelists we had were gone. We had to recreate them and set them up under the access control section.
Anyone seen this? I have another one in queue for upgrade, and will get more info once we run the upgrade, but wanted to ask if this is a known issue.
Also our delay pool had to be recreated as well.


Alan Long | Senior Network Engineer I

[A blue and white logo  Description automatically generated with medium confidence]
Web www.vesta.io<http://www.vesta.io/>

Notice: This e-mail message and any attachments are the property of Vesta, are confidential, and may contain Vesta proprietary information. If you have received this message in error, please notify the sender and delete this message immediately. Any other use of this message is strictly prohibited.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240711/ddff7361/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 14195 bytes
Desc: image001.png
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240711/ddff7361/attachment.png>

From rousskov at measurement-factory.com  Thu Jul 11 14:52:11 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 11 Jul 2024 10:52:11 -0400
Subject: [squid-users] After upgrade from 5.7 to 5.9 the whitelists were
 not listed , we had to readd them.
In-Reply-To: <SJ2PR02MB9414ADE532760A6E1DB10B1181A52@SJ2PR02MB9414.namprd02.prod.outlook.com>
References: <SJ2PR02MB9414DE2F284EA30B97C2C06981A52@SJ2PR02MB9414.namprd02.prod.outlook.com>
 <SJ2PR02MB9414ADE532760A6E1DB10B1181A52@SJ2PR02MB9414.namprd02.prod.outlook.com>
Message-ID: <6b6a0e13-1a8d-43c9-bcca-20ad59664a3e@measurement-factory.com>

On 2024-07-11 10:23, Alan Long wrote:
> We did an upgrade from 5.7 to 5.9 and after the upgrade the whitelists 
> we had were gone. We had to recreate them and set them up under the 
> access control section.
> 
> Anyone seen this? I have another one in queue for upgrade, and will get 
> more info once we run the upgrade, but wanted to ask if this is a known 
> issue.
> 
> Also our delay pool had to be recreated as well.

What do you use to upgrade/install Squid? Do you build Squid from 
sources and then run "make install"? Or do you use some packaging 
software provided by a third party?

Do you put your access rules (a.k.a. whitelists) into squid.conf? Was 
you squid.conf overwritten? With some default configuration??


FWIW, native Squid "make install" does not install or update squid.conf 
file AFAICT. It installs squid.cond.documented and squid.conf.default.


HTH,

Alex.



From alan.long at vesta.io  Thu Jul 11 15:24:50 2024
From: alan.long at vesta.io (Alan Long)
Date: Thu, 11 Jul 2024 15:24:50 +0000
Subject: [squid-users] After upgrade from 5.7 to 5.9 the whitelists were
 not listed , we had to readd them.
In-Reply-To: <6b6a0e13-1a8d-43c9-bcca-20ad59664a3e@measurement-factory.com>
References: <SJ2PR02MB9414DE2F284EA30B97C2C06981A52@SJ2PR02MB9414.namprd02.prod.outlook.com>
 <SJ2PR02MB9414ADE532760A6E1DB10B1181A52@SJ2PR02MB9414.namprd02.prod.outlook.com>
 <6b6a0e13-1a8d-43c9-bcca-20ad59664a3e@measurement-factory.com>
Message-ID: <SJ2PR02MB941494022DBF578D0119B43D81A52@SJ2PR02MB9414.namprd02.prod.outlook.com>

Our whitelists are separate files. The files were still in the /etc/squid directory, but the configs were gone.
We actually go old school and use webmin to manage the squid server and it showed an upgrade.
I am thinking the squid.conf got overwritten, which caused our issue.

Alan Long | Senior Network Engineer I


 Web www.vesta.io

-----Original Message-----
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Alex Rousskov
Sent: Thursday, July 11, 2024 9:52 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] After upgrade from 5.7 to 5.9 the whitelists were not listed , we had to readd them.

** WARNING: This email originated from outside of the organization. Do not click links or open attachments unless you recognize the sender and know the content is safe. **


On 2024-07-11 10:23, Alan Long wrote:
> We did an upgrade from 5.7 to 5.9 and after the upgrade the whitelists
> we had were gone. We had to recreate them and set them up under the
> access control section.
>
> Anyone seen this? I have another one in queue for upgrade, and will
> get more info once we run the upgrade, but wanted to ask if this is a
> known issue.
>
> Also our delay pool had to be recreated as well.

What do you use to upgrade/install Squid? Do you build Squid from sources and then run "make install"? Or do you use some packaging software provided by a third party?

Do you put your access rules (a.k.a. whitelists) into squid.conf? Was you squid.conf overwritten? With some default configuration??


FWIW, native Squid "make install" does not install or update squid.conf file AFAICT. It installs squid.cond.documented and squid.conf.default.


HTH,

Alex.

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
https://protect.checkpoint.com/v2/___https://lists.squid-cache.org/listinfo/squid-users___.YzJ1OnZlc3RhY29ycG9yYXRpb246YzpvOjU5ODI0ZTdkN2QwZTBkN2RkMjVjYTEwYzhmYjRjOWVlOjY6YTk0MTpmMWUzNjA2ZjY4ZDVmYmNlYTc3OTNhNTUyMjg5Njc0YmU2NDgyZTBjNjIzMzRhMjQ0ZTRiZmNlY2MyNWIxOWZmOnA6VDpO
Notice: This e-mail message and any attachments are the property of Vesta, are confidential, and may contain Vesta proprietary information. If you have received this message in error, please notify the sender and delete this message immediately. Any other use of this message is strictly prohibited.


From ben at macmule.com  Thu Jul 11 15:37:27 2024
From: ben at macmule.com (Ben Toms)
Date: Thu, 11 Jul 2024 15:37:27 +0000
Subject: [squid-users] TCP_MISS_ABORTED/502
Message-ID: <LO2P265MB3165D0078E70D946E38DE9AFFEA52@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>

Hi folks,

We?re looking to leverage squid-cache as an accelerator, but for large content. For example, a local cache of macOS installers so that the internet line isn?t swamped when updating Photoshop etc across devices.

Below is an example of the conf I?ve been using (and have been going backwards and forwards trying different things):

https_port 443 accel protocol=HTTPS tls-cert=/usr/local/squid/client.pem tls-key=/usr/local/squid/client.key
cache_peer public.server.fqdn parent 443 0 no-query originserver no-digest no-netdb-exchange tls login=PASSTHRU name=myAccel
acl our_sites dstdomain local.server.fqdn
http_access allow our_sites
cache_peer_access myAccel allow our_sites
cache_peer_access myAccel deny all
refresh_pattern -i public.server.fqdn/.* 3600    80%     14400
cache_dir ufs /usr/local/squid/var/cache 100000 16 256

When I attempt to curl a file from local.server.fqdn, I can see that there has been a request made to public.server.fqdn and that the authentication has been passed through and all is well (it returns a 200 code and needs authentication), but I?m seeing TCP_MISS_ABORTED/502 in /var/log/squid/access.log as per the below:

1720711470.297     84 192.168.0.156 TCP_MISS_ABORTED/502 3974 GET https://local.server.fqdn/some/file/path - FIRSTUP_PARENT/public.ip.of.public.server text/html

Seems like the client to squid-cache HTTPS conection is fine, and squid-cache can contact public.server.fqdn.. but nothing is cached.

Help appreciated.

Regards,
Ben.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240711/6df4e651/attachment.htm>

From rousskov at measurement-factory.com  Thu Jul 11 15:47:57 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 11 Jul 2024 11:47:57 -0400
Subject: [squid-users] After upgrade from 5.7 to 5.9 the whitelists were
 not listed , we had to readd them.
In-Reply-To: <SJ2PR02MB941494022DBF578D0119B43D81A52@SJ2PR02MB9414.namprd02.prod.outlook.com>
References: <SJ2PR02MB9414DE2F284EA30B97C2C06981A52@SJ2PR02MB9414.namprd02.prod.outlook.com>
 <SJ2PR02MB9414ADE532760A6E1DB10B1181A52@SJ2PR02MB9414.namprd02.prod.outlook.com>
 <6b6a0e13-1a8d-43c9-bcca-20ad59664a3e@measurement-factory.com>
 <SJ2PR02MB941494022DBF578D0119B43D81A52@SJ2PR02MB9414.namprd02.prod.outlook.com>
Message-ID: <29f9a00e-3bef-4192-b599-605748eab4dc@measurement-factory.com>

On 2024-07-11 11:24, Alan Long wrote:

> We actually go old school and use webmin to manage the squid server
> and it showed an upgrade.

It sounds like this is a webmin issue rather than a Squid issue. I do 
not know much about webmin. I hope somebody else here can help you with 
webmin integration, but please consider contacting webmin folks for support.


> I am thinking the squid.conf got overwritten, which caused our issue.

If it was overwritten, it was not overwritten by Squid (i.e. by anything 
shipped by the Squid Project).


HTH,

Alex.


> -----Original Message-----
> From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Alex Rousskov
> Sent: Thursday, July 11, 2024 9:52 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] After upgrade from 5.7 to 5.9 the whitelists were not listed , we had to readd them.
> 
> ** WARNING: This email originated from outside of the organization. Do not click links or open attachments unless you recognize the sender and know the content is safe. **
> 
> 
> On 2024-07-11 10:23, Alan Long wrote:
>> We did an upgrade from 5.7 to 5.9 and after the upgrade the whitelists
>> we had were gone. We had to recreate them and set them up under the
>> access control section.
>>
>> Anyone seen this? I have another one in queue for upgrade, and will
>> get more info once we run the upgrade, but wanted to ask if this is a
>> known issue.
>>
>> Also our delay pool had to be recreated as well.
> 
> What do you use to upgrade/install Squid? Do you build Squid from sources and then run "make install"? Or do you use some packaging software provided by a third party?
> 
> Do you put your access rules (a.k.a. whitelists) into squid.conf? Was you squid.conf overwritten? With some default configuration??
> 
> 
> FWIW, native Squid "make install" does not install or update squid.conf file AFAICT. It installs squid.cond.documented and squid.conf.default.
> 
> 
> HTH,
> 
> Alex.
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://protect.checkpoint.com/v2/___https://lists.squid-cache.org/listinfo/squid-users___.YzJ1OnZlc3RhY29ycG9yYXRpb246YzpvOjU5ODI0ZTdkN2QwZTBkN2RkMjVjYTEwYzhmYjRjOWVlOjY6YTk0MTpmMWUzNjA2ZjY4ZDVmYmNlYTc3OTNhNTUyMjg5Njc0YmU2NDgyZTBjNjIzMzRhMjQ0ZTRiZmNlY2MyNWIxOWZmOnA6VDpO
> Notice: This e-mail message and any attachments are the property of Vesta, are confidential, and may contain Vesta proprietary information. If you have received this message in error, please notify the sender and delete this message immediately. Any other use of this message is strictly prohibited.



From rousskov at measurement-factory.com  Thu Jul 11 16:15:07 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 11 Jul 2024 12:15:07 -0400
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <2d18e96ef2be492f9deea0b5c07688f5@eurodata.de>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
 <6bb89d7c58e34320b1eb15c1447e99d7@eurodata.de>
 <ca32f7f1-9123-47d4-a7ba-dfc40d0c6937@measurement-factory.com>
 <867452bfd4ff482bb60b90d4482265a7@eurodata.de>
 <cda7c451-72eb-4be5-bc10-a7db7ea1ba64@measurement-factory.com>
 <2d18e96ef2be492f9deea0b5c07688f5@eurodata.de>
Message-ID: <b44b830f-3ec4-4464-adf3-5695fe280ad5@measurement-factory.com>

On 2024-07-10 16:57, Fiehe, Christoph wrote:

> I am just trying to find something that helps to narrow down the
> problem. What I want to achieve is, that a client can use HTTP in the
> LAN, so that Squid can cache distribution packages without making use
> of SSL intercepting when repos are only accessible via HTTPS.

OK.


> In that case the secure connection must start at the proxy and end on
> the target server with or without any upstream proxies in betweem.

It depends on whether you trust the parent proxy:

If you trust the parent proxy, then you can use two secure connections:

1.1. child - parent (TLS; no CONNECT)
1.2. parent - origin (TLS; no CONNECT)

If you do not trust the parent proxy, then, yes, you will need a tunnel:

2.1. child - parent (CONNECT)
2.2. child - origin (TLS inside the CONNECT tunnel)

N.B. CONNECT request in 2.1 may be plain text (common) or encrypted 
(rare); I am ignoring the difference between those two subcases for now.


> We have the following setup:
> 
> client -> downstream proxy -> upstream proxy -> https://download.docker.com
> 
> Now let us assume the client wants to retrieve the following resource http://download.docker.com/linux/ubuntu/dists/jammy/InRelease from the upstream proxy.
> 
> The client initiates a HTTP GET request and sends it to the downstream proxy. Now, the URL gets rewritten.

OK.


> It indicates to use a HTTPS connection instead in order to talk to the target server, in our case the result is https://download.docker.com/linux/ubuntu/dists/jammy/InRelease.

Yes, but HTTPS scheme does not imply that the child Squid has to use 
CONNECT. There are two possible scenarios detailed above. I do not know 
which of them applies to your use case.


> Now comes the critical point: From my understanding ? it may be 
> wrongof course - the downstream server now has to send a CONNECT 
> request to the upstream server

Yes, provided the child (downstream) proxy does not trust that parent 
(upstream) proxy. That is scenario 2. Scenario 1 is different.


> to advise him to establish a secure connection to the target server.

No, the CONNECT tunnel itself is just a pair of TCP connections. The 
parent proxy "secures" nothing but basic TCP connectivity. It is the 
child proxy that negotiates TLS (over/inside that tunnel) with the 
origin server.


> After creation, the downstream proxy can retrieve the resource and
> send it back to the client via plain HTTP.

Yes.



> I suppose, that the GnuTLS occurs because of a missing SSL handshake
> between downstream proxy and download.docker.com.

At this time, I can only say that a TLS negotiation error occurs (while 
child Squid is using the encryption library it probably should not be 
using for this). It is not yet clear to me whether child Squid is 
negotiating with the wrong hop or something goes wrong during 
negotiation with the right hop.

As the next steps, I recommend switching to OpenSSL and, if that alone 
does not help, sharing new errors and determining whether you want to 
use scenario 1 (no CONNECT), scenario 2 (CONNECT), or either (whichever 
works): Do you trust the parent Squid?


HTH,

Alex.


>> -----Urspr?ngliche Nachricht-----
>> Von: Alex Rousskov <rousskov at measurement-factory.com>
>> Gesendet: Mittwoch, 10. Juli 2024 22:15
>> An: squid-users at lists.squid-cache.org
>> Cc: Fiehe, Christoph <c.fiehe at eurodata.de>
>> Betreff: AW: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>>
>> On 2024-07-10 15:31, Fiehe, Christoph wrote:
>>> The problem is that the proxy just forwards the client GET request to the upstream proxy
>>
>> Why does sending a GET request to the upstream proxy represent a problem
>> in your use case? I cannot find anything in your prior messages on this
>> thread that would preclude sending a GET request to the upstream proxy.
>>
>>
>>> but in that case a CONNECT is required.
>>
>> Why?
>>
>> Please do not interpret my response as implying that this "must send
>> CONNECT" requirement is wrong (or correct). At this point, I am just
>> trying to understand what problem(s) you are trying to solve beyond the
>> one you have originally described.
>>
>>
>> Thank you,
>>
>> Alex.
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Thu Jul 11 17:17:01 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Jul 2024 05:17:01 +1200
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <04d4fbde-1ad0-4b02-bf60-5c2bee2bab09@measurement-factory.com>
References: <Zo605zQA1vz_lEZX@fantomas.sk>
 <B445DDAF-6DCD-4B1F-AA53-FD51C62B99B2@gmail.com>
 <Zo64OEswTGHYcl9x@fantomas.sk>
 <BC3294F8-E402-4C22-AC91-C604FC64456A@gmail.com>
 <04d4fbde-1ad0-4b02-bf60-5c2bee2bab09@measurement-factory.com>
Message-ID: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>


On 11/07/24 06:08, Alex Rousskov wrote:
> On 2024-07-10 12:55, Jonathan Lee wrote:
> 
>>> Embedding a password in a cache manager command requires providing a
>>> username with -U
> 
>> squidclient -w /squid-internal-mgr/info -u admin
>> squidclient -w /squid-internal-mgr/info at redacted -u admin
>> squidclient -w 
>> http://192.168.1.1:3128/squid-internal-mgr/info at redacted -u admin
>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info at redacted 
>> -u admin
>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info
>> squidclient http://127.0.0.1:3128/squid-internal-mgr/info
>> squidclient -h 127.0.0.1:3128/squid-internal-mgr/info
>> squidclient -h 127.0.0.1 /squid-internal-mgr/info
>> squidclient -h 127.0.0.1 /squid-internal-mgr/info at redcated
>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redacted
>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redcated -u admin
>> squidclient -h 192.168.1.1:3128 ?/squid-internal-mgr/info at redacted
>> squidclient -h 192.168.1.1 ?/squid-internal-mgr/info at redacted
>> squidclient -h 192.168.1.1 ?/squid-internal-mgr/info
>>
>> with -w -u -h http spaces I can?t get it to show me stats
>>
>> Squid 6.6
> 
> I do not know whether this mistake is relevant, but squidclient 
> documentation and error message imply that you should be using "-U" 
> (capital letter U) while you are using "-u" (small letter u).


It is very relevant. As Matus already mentioned, both -U and -W.


squidclient -v -U admin -W cachemgr_password mgr:info
Request:
GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
Host: localhost:3128
User-Agent: squidclient/6.10
Accept: */*
Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
Connection: close


squidclient -v -U admin -W cachemgr_password /squid-internal-mgr/info
Request:
GET /squid-internal-mgr/info HTTP/1.0
Host: localhost:3128
User-Agent: squidclient/6.10
Accept: */*
Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
Connection: close


Cheers
Amos


From jonathanlee571 at gmail.com  Thu Jul 11 17:27:11 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 11 Jul 2024 10:27:11 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
References: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
Message-ID: <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>

Thanks what about the password is it set with@ or -p where would I place that?
Sent from my iPhone

> On Jul 11, 2024, at 10:17, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> ?
>> On 11/07/24 06:08, Alex Rousskov wrote:
>> On 2024-07-10 12:55, Jonathan Lee wrote:
>>>> Embedding a password in a cache manager command requires providing a
>>>> username with -U
>>> squidclient -w /squid-internal-mgr/info -u admin
>>> squidclient -w /squid-internal-mgr/info at redacted -u admin
>>> squidclient -w http://192.168.1.1:3128/squid-internal-mgr/info at redacted -u admin
>>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info at redacted -u admin
>>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info
>>> squidclient http://127.0.0.1:3128/squid-internal-mgr/info
>>> squidclient -h 127.0.0.1:3128/squid-internal-mgr/info
>>> squidclient -h 127.0.0.1 /squid-internal-mgr/info
>>> squidclient -h 127.0.0.1 /squid-internal-mgr/info at redcated
>>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redacted
>>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redcated -u admin
>>> squidclient -h 192.168.1.1:3128  /squid-internal-mgr/info at redacted
>>> squidclient -h 192.168.1.1  /squid-internal-mgr/info at redacted
>>> squidclient -h 192.168.1.1  /squid-internal-mgr/info
>>> 
>>> with -w -u -h http spaces I can?t get it to show me stats
>>> 
>>> Squid 6.6
>> I do not know whether this mistake is relevant, but squidclient documentation and error message imply that you should be using "-U" (capital letter U) while you are using "-u" (small letter u).
> 
> 
> It is very relevant. As Matus already mentioned, both -U and -W.
> 
> 
> squidclient -v -U admin -W cachemgr_password mgr:info
> Request:
> GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
> Host: localhost:3128
> User-Agent: squidclient/6.10
> Accept: */*
> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
> Connection: close
> 
> 
> squidclient -v -U admin -W cachemgr_password /squid-internal-mgr/info
> Request:
> GET /squid-internal-mgr/info HTTP/1.0
> Host: localhost:3128
> User-Agent: squidclient/6.10
> Accept: */*
> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
> Connection: close
> 
> 
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From c.fiehe at eurodata.de  Thu Jul 11 17:37:17 2024
From: c.fiehe at eurodata.de (Fiehe, Christoph)
Date: Thu, 11 Jul 2024 17:37:17 +0000
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <b44b830f-3ec4-4464-adf3-5695fe280ad5@measurement-factory.com>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
 <6bb89d7c58e34320b1eb15c1447e99d7@eurodata.de>
 <ca32f7f1-9123-47d4-a7ba-dfc40d0c6937@measurement-factory.com>
 <867452bfd4ff482bb60b90d4482265a7@eurodata.de>
 <cda7c451-72eb-4be5-bc10-a7db7ea1ba64@measurement-factory.com>
 <2d18e96ef2be492f9deea0b5c07688f5@eurodata.de>
 <b44b830f-3ec4-4464-adf3-5695fe280ad5@measurement-factory.com>
Message-ID: <93949ac76c724384b62d5e6332c7c1ab@eurodata.de>

My proxy (the child proxy) already uses the OpenSSL library:

$ squid --version
Squid Cache: Version 6.10
Service Name: squid

This binary uses OpenSSL 3.3.1 4 Jun 2024. configure options:  '--build=x86_64' '--host=x86_64' '--prefix=/usr' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--libexecdir=/usr/lib/squid' '--localstatedir=/var' '--with-logdir=/var/log/squid' '--disable-strict-error-checking' '--disable-arch-native' '--enable-removal-policies=lru,heap' '--enable-auth-digest' '--enable-auth-basic=getpwnam,NCSA,DB,RADIUS' '--enable-basic-auth-helpers=DB' '--enable-external-acl-helpers=file_userip,unix_group,wbinfo_group' '--enable-auth-ntlm=fake' '--enable-auth-negotiate=kerberos,wrapper' '--enable-silent-rules' '--disable-mit' '--enable-heimdal' '--enable-delay-pools' '--enable-openssl' '--enable-ssl-crtd' '--enable-security-cert-generators=file' '--enable-ident-lookups' '--enable-useragent-log' '--enable-cache-digests' '--enable-referer-log' '--enable-async-io' '--enable-truncate' '--enable-arp-acl' '--enable-htcp' '--enable-carp' '--enable-epoll' '--enable-follow-x-forwarded-for' '--enable-storeio=diskd rock' '--enable-ipv6' '--enable-translation' '--enable-snmp' '--disable-dependency-tracking' '--with-large-files' '--with-default-user=squid' '--with-openssl' '--with-pidfile=/var/run/squid/squid.pid' 'build_alias=x86_64' 'host_alias=x86_64' 'CFLAGS=-g0 -O2' 'LDFLAGS=-s' 'CXXFLAGS=-g0 -O2

The parent proxy was compiled with:

squid --version
Squid Cache: Version 6.8
Service Name: squid
Ubuntu linux
configure options:  '--build=x86_64-linux-gnu' '--prefix=/usr' '--includedir=${prefix}/include' '--mandir=${prefix}/share/man' '--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var' '--disable-option-checking' '--disable-silent-rules' '--libdir=${prefix}/lib/x86_64-linux-gnu' '--runstatedir=/run' '--disable-maintainer-mode' '--disable-dependency-tracking' 'BUILDCXXFLAGS=-g -O2 -ffile-prefix-map=/home/builder/ubuntu22/build/squid/squid-6.8=. -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -Wno-error=deprecated-declarations -Wdate-time -D_FORTIFY_SOURCE=2 -Wl,-Bsymbolic-functions -flto=auto -ffat-lto-objects -flto=auto -Wl,-z,relro -Wl,-z,now ' 'BUILDCXX=g++' '--with-build-environment=default' '--enable-build-info=Ubuntu linux' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--libexecdir=/usr/lib/squid' '--mandir=/usr/share/man' '--enable-inline' '--disable-arch-native' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,PAM,POP3,RADIUS,SASL,SMB' '--enable-auth-digest=file,LDAP' '--enable-auth-negotiate=kerberos,wrapper' '--enable-auth-ntlm=fake,SMB_LM' '--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,time_quota,unix_group,wbinfo_group' '--enable-security-cert-validators=fake' '--enable-storeid-rewrite-helpers=file' '--enable-url-rewrite-helpers=fake' '--enable-eui' '--enable-esi' '--enable-icmp' '--enable-zph-qos' '--enable-ecap' '--disable-translation' '--with-swapdir=/var/spool/squid' '--with-logdir=/var/log/squid' '--with-pidfile=/run/squid.pid' '--with-filedescriptors=65536' '--with-large-files' '--with-default-user=proxy' '--enable-linux-netfilter' '--with-systemd' '--with-gnutls' 'build_alias=x86_64-linux-gnu' 'CFLAGS=-g -O2 -ffile-prefix-map=/home/builder/ubuntu22/build/squid/squid-6.8=. -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -Wno-error=deprecated-declarations' 'LDFLAGS=-Wl,-Bsymbolic-functions -flto=auto -ffat-lto-objects -flto=auto -Wl,-z,relro -Wl,-z,now ' 'CPPFLAGS=-Wdate-time -D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -ffile-prefix-map=/home/builder/ubuntu22/build/squid/squid-6.8=. -flto=auto -ffat-lto-objects -flto=auto -ffat-lto-objects -fstack-protector-strong -Wformat -Werror=format-security -Wno-error=deprecated-declarations'

The GnuTLS exception is thrown at my parent proxy. Unfortunately, I cannot make any changes here. So yes, I trust my parent proxy, but not using a tunnel between child and parent does not seem to work and results in the TLS exception on the parent proxy.

I have not find a way to tell my child proxy to always setup a tunnel through the parent proxy, when the target server talks HTTPS. Do you know, how to achieve that? It would be a promising approach.

Thank you very much help and your patience, Alex.

Regards,
Christoph


>-----Urspr?ngliche Nachricht-----
>Von: squid-users <squid-users-bounces at lists.squid-cache.org> Im Auftrag von Alex Rousskov
>Gesendet: Donnerstag, 11. Juli 2024 18:15
>An: squid-users at lists.squid-cache.org
>Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>
>On 2024-07-10 16:57, Fiehe, Christoph wrote:
>
>> I am just trying to find something that helps to narrow down the
>> problem. What I want to achieve is, that a client can use HTTP in the
>> LAN, so that Squid can cache distribution packages without making use
>> of SSL intercepting when repos are only accessible via HTTPS.
>
>OK.
>
>
>> In that case the secure connection must start at the proxy and end on
>> the target server with or without any upstream proxies in betweem.
>
>It depends on whether you trust the parent proxy:
>
>If you trust the parent proxy, then you can use two secure connections:
>
>1.1. child - parent (TLS; no CONNECT)
>1.2. parent - origin (TLS; no CONNECT)
>
>If you do not trust the parent proxy, then, yes, you will need a tunnel:
>
>2.1. child - parent (CONNECT)
>2.2. child - origin (TLS inside the CONNECT tunnel)
>
>N.B. CONNECT request in 2.1 may be plain text (common) or encrypted
>(rare); I am ignoring the difference between those two subcases for now.
>
>
>> We have the following setup:
>>
>> client -> downstream proxy -> upstream proxy -> https://download.docker.com
>>
>> Now let us assume the client wants to retrieve the following resource
>http://download.docker.com/linux/ubuntu/dists/jammy/InRelease from the upstream proxy.
>>
>> The client initiates a HTTP GET request and sends it to the downstream proxy. Now, the
>URL gets rewritten.
>
>OK.
>
>
>> It indicates to use a HTTPS connection instead in order to talk to the target server, in
>our case the result is https://download.docker.com/linux/ubuntu/dists/jammy/InRelease.
>
>Yes, but HTTPS scheme does not imply that the child Squid has to use
>CONNECT. There are two possible scenarios detailed above. I do not know
>which of them applies to your use case.
>
>
>> Now comes the critical point: From my understanding ? it may be
>> wrongof course - the downstream server now has to send a CONNECT
>> request to the upstream server
>
>Yes, provided the child (downstream) proxy does not trust that parent
>(upstream) proxy. That is scenario 2. Scenario 1 is different.
>
>
>> to advise him to establish a secure connection to the target server.
>
>No, the CONNECT tunnel itself is just a pair of TCP connections. The
>parent proxy "secures" nothing but basic TCP connectivity. It is the
>child proxy that negotiates TLS (over/inside that tunnel) with the
>origin server.
>
>
>> After creation, the downstream proxy can retrieve the resource and
>> send it back to the client via plain HTTP.
>
>Yes.
>
>
>
>> I suppose, that the GnuTLS occurs because of a missing SSL handshake
>> between downstream proxy and download.docker.com.
>
>At this time, I can only say that a TLS negotiation error occurs (while
>child Squid is using the encryption library it probably should not be
>using for this). It is not yet clear to me whether child Squid is
>negotiating with the wrong hop or something goes wrong during
>negotiation with the right hop.
>
>As the next steps, I recommend switching to OpenSSL and, if that alone
>does not help, sharing new errors and determining whether you want to
>use scenario 1 (no CONNECT), scenario 2 (CONNECT), or either (whichever
>works): Do you trust the parent Squid?
>
>
>HTH,
>
>Alex.
>
>
>>> -----Urspr?ngliche Nachricht-----
>>> Von: Alex Rousskov <rousskov at measurement-factory.com>
>>> Gesendet: Mittwoch, 10. Juli 2024 22:15
>>> An: squid-users at lists.squid-cache.org
>>> Cc: Fiehe, Christoph <c.fiehe at eurodata.de>
>>> Betreff: AW: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>>>
>>> On 2024-07-10 15:31, Fiehe, Christoph wrote:
>>>> The problem is that the proxy just forwards the client GET request to the upstream
>proxy
>>>
>>> Why does sending a GET request to the upstream proxy represent a problem
>>> in your use case? I cannot find anything in your prior messages on this
>>> thread that would preclude sending a GET request to the upstream proxy.
>>>
>>>
>>>> but in that case a CONNECT is required.
>>>
>>> Why?
>>>
>>> Please do not interpret my response as implying that this "must send
>>> CONNECT" requirement is wrong (or correct). At this point, I am just
>>> trying to understand what problem(s) you are trying to solve beyond the
>>> one you have originally described.
>>>
>>>
>>> Thank you,
>>>
>>> Alex.
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>
>_______________________________________________
>squid-users mailing list
>squid-users at lists.squid-cache.org
>https://lists.squid-cache.org/listinfo/squid-users

From jonathanlee571 at gmail.com  Thu Jul 11 17:57:28 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 11 Jul 2024 10:57:28 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
References: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
 <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
Message-ID: <F19657D2-D16C-4D37-8EDE-A0F7D2A5A64E@gmail.com>

Shell Output - squidclient -v -U admin -W REDACTED mgr:info
Request:
GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
Host: localhost:3128
User-Agent: squidclient/6.6
Accept: */*
Authorization: Basic YWRtaW46R09Qc3lzdGVtYWRtaW4xIQ==
Connection: close


.
HTTP/1.1 403 Forbidden
Server: squid
Mime-Version: 1.0
Date: Thu, 11 Jul 2024 17:55:05 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3788
X-Squid-Error: ERR_ACCESS_DENIED 0
Vary: Accept-Language
Content-Language: en
Cache-Status: Lee_Family.home.arpa
Cache-Status: Lee_Family.home.arpa;detail=no-cache
Connection: close

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
<meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>ERROR: The requested URL could not be retrieved</title>
<style type="text/css"><!--
 /*
 * Copyright (C) 1996-2023 The Squid Software Foundation and contributor

Shell Output - squidclient -v -U admin -W REDACTED /squid-internal-mgr/info
Request:
GET /squid-internal-mgr/info HTTP/1.0
User-Agent: squidclient/6.6
Accept: */*
Authorization: Basic YWRtaW46R09Qc3lzdGVtYWRtaW4xIQ==
Connection: close


.
HTTP/1.1 403 Forbidden
Server: squid
Mime-Version: 1.0
Date: Thu, 11 Jul 2024 17:56:48 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3788
X-Squid-Error: ERR_ACCESS_DENIED 0
Vary: Accept-Language
Content-Language: en
Cache-Status: Lee_Family.home.arpa
Cache-Status: Lee_Family.home.arpa;detail=no-cache
Connection: close

<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
<meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>ERROR: The requested URL could not be retrieved</title>
<style type="text/css"><!--
 /*
 * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
Tested both and they also failed 

> On Jul 11, 2024, at 10:27, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Thanks what about the password is it set with@ or -p where would I place that?
> Sent from my iPhone
> 
>> On Jul 11, 2024, at 10:17, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>> 
>> ?
>>> On 11/07/24 06:08, Alex Rousskov wrote:
>>> On 2024-07-10 12:55, Jonathan Lee wrote:
>>>>> Embedding a password in a cache manager command requires providing a
>>>>> username with -U
>>>> squidclient -w /squid-internal-mgr/info -u admin
>>>> squidclient -w /squid-internal-mgr/info at redacted -u admin
>>>> squidclient -w http://192.168.1.1:3128/squid-internal-mgr/info at redacted -u admin
>>>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info at redacted -u admin
>>>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info
>>>> squidclient http://127.0.0.1:3128/squid-internal-mgr/info
>>>> squidclient -h 127.0.0.1:3128/squid-internal-mgr/info
>>>> squidclient -h 127.0.0.1 /squid-internal-mgr/info
>>>> squidclient -h 127.0.0.1 /squid-internal-mgr/info at redcated
>>>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redacted
>>>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redcated -u admin
>>>> squidclient -h 192.168.1.1:3128  /squid-internal-mgr/info at redacted
>>>> squidclient -h 192.168.1.1  /squid-internal-mgr/info at redacted
>>>> squidclient -h 192.168.1.1  /squid-internal-mgr/info
>>>> 
>>>> with -w -u -h http spaces I can?t get it to show me stats
>>>> 
>>>> Squid 6.6
>>> I do not know whether this mistake is relevant, but squidclient documentation and error message imply that you should be using "-U" (capital letter U) while you are using "-u" (small letter u).
>> 
>> 
>> It is very relevant. As Matus already mentioned, both -U and -W.
>> 
>> 
>> squidclient -v -U admin -W cachemgr_password mgr:info
>> Request:
>> GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
>> Host: localhost:3128
>> User-Agent: squidclient/6.10
>> Accept: */*
>> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
>> Connection: close
>> 
>> 
>> squidclient -v -U admin -W cachemgr_password /squid-internal-mgr/info
>> Request:
>> GET /squid-internal-mgr/info HTTP/1.0
>> Host: localhost:3128
>> User-Agent: squidclient/6.10
>> Accept: */*
>> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
>> Connection: close
>> 
>> 
>> Cheers
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240711/0462ad9f/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jul 11 18:02:21 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 11 Jul 2024 11:02:21 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <F19657D2-D16C-4D37-8EDE-A0F7D2A5A64E@gmail.com>
References: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
 <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
 <F19657D2-D16C-4D37-8EDE-A0F7D2A5A64E@gmail.com>
Message-ID: <AC4A93C3-F77B-414A-A408-39391584B388@gmail.com>

also 

Shell Output - squidclient -h 127.0.0.1 -v -U admin -W redacted mgr:info
Request:
GET http://127.0.0.1:3128/squid-internal-mgr/info HTTP/1.0
Host: 127.0.0.1:3128
User-Agent: squidclient/6.6
Accept: */*
Authorization: Basic YWRtaW46R09Qc3lzdGVtYWRtaW4xIQ==
Connection: close


.
HTTP/1.1 403 Forbidden
Server: squid
Mime-Version: 1.0
Date: Thu, 11 Jul 2024 18:01:46 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3788
X-Squid-Error: ERR_ACCESS_DENIED 0
Vary: Accept-Language
Content-Language: en
Cache-Status: Lee_Family.home.arpa
Cache-Status: Lee_Family.home.arpa;detail=no-cache
Connection: close

> On Jul 11, 2024, at 10:57, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Shell Output - squidclient -v -U admin -W REDACTED mgr:info
> Request:
> GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
> Host: localhost:3128
> User-Agent: squidclient/6.6
> Accept: */*
> Authorization: Basic YWRtaW46R09Qc3lzdGVtYWRtaW4xIQ==
> Connection: close
> 
> 
> .
> HTTP/1.1 403 Forbidden
> Server: squid
> Mime-Version: 1.0
> Date: Thu, 11 Jul 2024 17:55:05 GMT
> Content-Type: text/html;charset=utf-8
> Content-Length: 3788
> X-Squid-Error: ERR_ACCESS_DENIED 0
> Vary: Accept-Language
> Content-Language: en
> Cache-Status: Lee_Family.home.arpa
> Cache-Status: Lee_Family.home.arpa;detail=no-cache
> Connection: close
> 
> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
> <html><head>
> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
> <title>ERROR: The requested URL could not be retrieved</title>
> <style type="text/css"><!--
>  /*
>  * Copyright (C) 1996-2023 The Squid Software Foundation and contributor
> 
> Shell Output - squidclient -v -U admin -W REDACTED /squid-internal-mgr/info
> Request:
> GET /squid-internal-mgr/info HTTP/1.0
> User-Agent: squidclient/6.6
> Accept: */*
> Authorization: Basic YWRtaW46R09Qc3lzdGVtYWRtaW4xIQ==
> Connection: close
> 
> 
> .
> HTTP/1.1 403 Forbidden
> Server: squid
> Mime-Version: 1.0
> Date: Thu, 11 Jul 2024 17:56:48 GMT
> Content-Type: text/html;charset=utf-8
> Content-Length: 3788
> X-Squid-Error: ERR_ACCESS_DENIED 0
> Vary: Accept-Language
> Content-Language: en
> Cache-Status: Lee_Family.home.arpa
> Cache-Status: Lee_Family.home.arpa;detail=no-cache
> Connection: close
> 
> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
> <html><head>
> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
> <title>ERROR: The requested URL could not be retrieved</title>
> <style type="text/css"><!--
>  /*
>  * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
> Tested both and they also failed 
> 
>> On Jul 11, 2024, at 10:27, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> Thanks what about the password is it set with@ or -p where would I place that?
>> Sent from my iPhone
>> 
>>> On Jul 11, 2024, at 10:17, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>> 
>>> ?
>>>> On 11/07/24 06:08, Alex Rousskov wrote:
>>>> On 2024-07-10 12:55, Jonathan Lee wrote:
>>>>>> Embedding a password in a cache manager command requires providing a
>>>>>> username with -U
>>>>> squidclient -w /squid-internal-mgr/info -u admin
>>>>> squidclient -w /squid-internal-mgr/info at redacted -u admin
>>>>> squidclient -w http://192.168.1.1:3128/squid-internal-mgr/info at redacted -u admin
>>>>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info at redacted -u admin
>>>>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info
>>>>> squidclient http://127.0.0.1:3128/squid-internal-mgr/info
>>>>> squidclient -h 127.0.0.1:3128/squid-internal-mgr/info
>>>>> squidclient -h 127.0.0.1 /squid-internal-mgr/info
>>>>> squidclient -h 127.0.0.1 /squid-internal-mgr/info at redcated
>>>>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redacted
>>>>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redcated -u admin
>>>>> squidclient -h 192.168.1.1:3128  /squid-internal-mgr/info at redacted
>>>>> squidclient -h 192.168.1.1  /squid-internal-mgr/info at redacted
>>>>> squidclient -h 192.168.1.1  /squid-internal-mgr/info
>>>>> 
>>>>> with -w -u -h http spaces I can?t get it to show me stats
>>>>> 
>>>>> Squid 6.6
>>>> I do not know whether this mistake is relevant, but squidclient documentation and error message imply that you should be using "-U" (capital letter U) while you are using "-u" (small letter u).
>>> 
>>> 
>>> It is very relevant. As Matus already mentioned, both -U and -W.
>>> 
>>> 
>>> squidclient -v -U admin -W cachemgr_password mgr:info
>>> Request:
>>> GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
>>> Host: localhost:3128
>>> User-Agent: squidclient/6.10
>>> Accept: */*
>>> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
>>> Connection: close
>>> 
>>> 
>>> squidclient -v -U admin -W cachemgr_password /squid-internal-mgr/info
>>> Request:
>>> GET /squid-internal-mgr/info HTTP/1.0
>>> Host: localhost:3128
>>> User-Agent: squidclient/6.10
>>> Accept: */*
>>> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
>>> Connection: close
>>> 
>>> 
>>> Cheers
>>> Amos
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240711/bbb74694/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jul 11 18:08:29 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 11 Jul 2024 11:08:29 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <AC4A93C3-F77B-414A-A408-39391584B388@gmail.com>
References: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
 <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
 <F19657D2-D16C-4D37-8EDE-A0F7D2A5A64E@gmail.com>
 <AC4A93C3-F77B-414A-A408-39391584B388@gmail.com>
Message-ID: <D97540C8-E366-4753-BB39-053208E373CB@gmail.com>

I use http access acl set as followed 

acl getmethod method GET
acl to_ipv6 dst ipv6
acl from_ipv6 src ipv6
acl HttpAccess dstdomain "/usr/local/pkg/http.access?


/usr/local/pkg/http.access
contains:
office.com
data.microsoft.com
windowsupdate.com
dc1-st.ksn.kaspersky-labs.com
dc1-file.ksn.kaspersky-labs.com
dc1.ksn.kaspersky-labs.com
gsa.apple.com
apps.apple.com
certs.apple.com
crl.apple.com
entrust.net
digicert.com
ocsp.apple.com
ocsp2.apple.com
valid.apple.com
push.apple.com
itunes.apple.com
appldnld.apple.com
gg.apple.com
gs.apple.com
mesu.apple.com
oscdn.apple.com
osrecovery.apple.com
swcdn.apple.com
swdownload.apple.com
updates-http.cdn-apple.com
appldnld.apple.com.edgesuite.net
suconfig.apple.com
audiocontentdownload.apple.com
devimages-cdn.apple.com
download.developer.apple.com
sylvan.apple.com
static.ips.apple.com


http_access allow CONNECT wuCONNECT localnet
http_access allow CONNECT wuCONNECT localhost
http_access allow windowsupdate localnet
http_access allow windowsupdate localhost
http_access allow HttpAccess localnet
http_access allow HttpAccess localhost
http_access deny manager
http_access deny to_ipv6
http_access deny from_ipv6 

> On Jul 11, 2024, at 11:02, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> also 
> 
> Shell Output - squidclient -h 127.0.0.1 -v -U admin -W redacted mgr:info
> Request:
> GET http://127.0.0.1:3128/squid-internal-mgr/info HTTP/1.0
> Host: 127.0.0.1:3128
> User-Agent: squidclient/6.6
> Accept: */*
> Authorization: Basic YWRtaW46R09Qc3lzdGVtYWRtaW4xIQ==
> Connection: close
> 
> 
> .
> HTTP/1.1 403 Forbidden
> Server: squid
> Mime-Version: 1.0
> Date: Thu, 11 Jul 2024 18:01:46 GMT
> Content-Type: text/html;charset=utf-8
> Content-Length: 3788
> X-Squid-Error: ERR_ACCESS_DENIED 0
> Vary: Accept-Language
> Content-Language: en
> Cache-Status: Lee_Family.home.arpa
> Cache-Status: Lee_Family.home.arpa;detail=no-cache
> Connection: close
> 
>> On Jul 11, 2024, at 10:57, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> Shell Output - squidclient -v -U admin -W REDACTED mgr:info
>> Request:
>> GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
>> Host: localhost:3128
>> User-Agent: squidclient/6.6
>> Accept: */*
>> Authorization: Basic YWRtaW46R09Qc3lzdGVtYWRtaW4xIQ==
>> Connection: close
>> 
>> 
>> .
>> HTTP/1.1 403 Forbidden
>> Server: squid
>> Mime-Version: 1.0
>> Date: Thu, 11 Jul 2024 17:55:05 GMT
>> Content-Type: text/html;charset=utf-8
>> Content-Length: 3788
>> X-Squid-Error: ERR_ACCESS_DENIED 0
>> Vary: Accept-Language
>> Content-Language: en
>> Cache-Status: Lee_Family.home.arpa
>> Cache-Status: Lee_Family.home.arpa;detail=no-cache
>> Connection: close
>> 
>> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
>> <html><head>
>> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
>> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
>> <title>ERROR: The requested URL could not be retrieved</title>
>> <style type="text/css"><!--
>>  /*
>>  * Copyright (C) 1996-2023 The Squid Software Foundation and contributor
>> 
>> Shell Output - squidclient -v -U admin -W REDACTED /squid-internal-mgr/info
>> Request:
>> GET /squid-internal-mgr/info HTTP/1.0
>> User-Agent: squidclient/6.6
>> Accept: */*
>> Authorization: Basic YWRtaW46R09Qc3lzdGVtYWRtaW4xIQ==
>> Connection: close
>> 
>> 
>> .
>> HTTP/1.1 403 Forbidden
>> Server: squid
>> Mime-Version: 1.0
>> Date: Thu, 11 Jul 2024 17:56:48 GMT
>> Content-Type: text/html;charset=utf-8
>> Content-Length: 3788
>> X-Squid-Error: ERR_ACCESS_DENIED 0
>> Vary: Accept-Language
>> Content-Language: en
>> Cache-Status: Lee_Family.home.arpa
>> Cache-Status: Lee_Family.home.arpa;detail=no-cache
>> Connection: close
>> 
>> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
>> <html><head>
>> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
>> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
>> <title>ERROR: The requested URL could not be retrieved</title>
>> <style type="text/css"><!--
>>  /*
>>  * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
>> Tested both and they also failed 
>> 
>>> On Jul 11, 2024, at 10:27, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>> 
>>> Thanks what about the password is it set with@ or -p where would I place that?
>>> Sent from my iPhone
>>> 
>>>> On Jul 11, 2024, at 10:17, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>>> 
>>>> ?
>>>>> On 11/07/24 06:08, Alex Rousskov wrote:
>>>>> On 2024-07-10 12:55, Jonathan Lee wrote:
>>>>>>> Embedding a password in a cache manager command requires providing a
>>>>>>> username with -U
>>>>>> squidclient -w /squid-internal-mgr/info -u admin
>>>>>> squidclient -w /squid-internal-mgr/info at redacted -u admin
>>>>>> squidclient -w http://192.168.1.1:3128/squid-internal-mgr/info at redacted -u admin
>>>>>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info at redacted -u admin
>>>>>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info
>>>>>> squidclient http://127.0.0.1:3128/squid-internal-mgr/info
>>>>>> squidclient -h 127.0.0.1:3128/squid-internal-mgr/info
>>>>>> squidclient -h 127.0.0.1 /squid-internal-mgr/info
>>>>>> squidclient -h 127.0.0.1 /squid-internal-mgr/info at redcated
>>>>>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redacted
>>>>>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redcated -u admin
>>>>>> squidclient -h 192.168.1.1:3128  /squid-internal-mgr/info at redacted
>>>>>> squidclient -h 192.168.1.1  /squid-internal-mgr/info at redacted
>>>>>> squidclient -h 192.168.1.1  /squid-internal-mgr/info
>>>>>> 
>>>>>> with -w -u -h http spaces I can?t get it to show me stats
>>>>>> 
>>>>>> Squid 6.6
>>>>> I do not know whether this mistake is relevant, but squidclient documentation and error message imply that you should be using "-U" (capital letter U) while you are using "-u" (small letter u).
>>>> 
>>>> 
>>>> It is very relevant. As Matus already mentioned, both -U and -W.
>>>> 
>>>> 
>>>> squidclient -v -U admin -W cachemgr_password mgr:info
>>>> Request:
>>>> GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
>>>> Host: localhost:3128
>>>> User-Agent: squidclient/6.10
>>>> Accept: */*
>>>> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
>>>> Connection: close
>>>> 
>>>> 
>>>> squidclient -v -U admin -W cachemgr_password /squid-internal-mgr/info
>>>> Request:
>>>> GET /squid-internal-mgr/info HTTP/1.0
>>>> Host: localhost:3128
>>>> User-Agent: squidclient/6.10
>>>> Accept: */*
>>>> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
>>>> Connection: close
>>>> 
>>>> 
>>>> Cheers
>>>> Amos
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240711/da580aa4/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jul 11 18:12:22 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 11 Jul 2024 11:12:22 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <D97540C8-E366-4753-BB39-053208E373CB@gmail.com>
References: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
 <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
 <F19657D2-D16C-4D37-8EDE-A0F7D2A5A64E@gmail.com>
 <AC4A93C3-F77B-414A-A408-39391584B388@gmail.com>
 <D97540C8-E366-4753-BB39-053208E373CB@gmail.com>
Message-ID: <FDB03E03-1FEE-44A7-A427-8CC3435EFB91@gmail.com>

cachemgr_passwd disable offline_toggle reconfigure shutdown
cachemgr_passwd PASSWORDREDCATED all
eui_lookup on
acl no_miss url_regex -i gateway\.facebook\.com\/ws\/realtime\?
acl no_miss url_regex -i web-chat-e2ee\.facebook\.com\/ws\/chat
acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com
http_access allow CONNECT wuCONNECT localnet
http_access allow CONNECT wuCONNECT localhost
http_access allow windowsupdate localnet
http_access allow windowsupdate localhost
http_access allow HttpAccess localnet
http_access allow HttpAccess localhost
http_access deny manager
http_access deny to_ipv6
http_access deny from_ipv6

acl BrokenButTrustedServers dstdomain "/usr/local/pkg/dstdom.broken"
acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
sslproxy_cert_error deny all

acl splice_only src 192.168.1.8 #Tasha iPhone
acl splice_only src 192.168.1.10 #Jon iPhone
acl splice_only src 192.168.1.11 #Amazon Fire
acl splice_only src 192.168.1.15 #Tasha HP
acl splice_only src 192.168.1.16 #iPad

acl splice_only_mac arp MACADDRESSREDACTED
acl splice_only_mac arp MACADDRESSREDACTED
acl splice_only_mac arp MACADDRESSREDACTED
acl splice_only_mac arp MACADDRESSREDACTED
acl splice_only_mac arp MACADDRESSREDACTED

acl NoSSLIntercept ssl::server_name_regex -i "/usr/local/pkg/reg.url.nobump"
acl NoBumpDNS dstdomain "/usr/local/pkg/dns.nobump"

acl markBumped annotate_client bumped=true
acl active_use annotate_client active=true
acl bump_only src 192.168.1.3 #webtv
acl bump_only src 192.168.1.4 #toshiba
acl bump_only src 192.168.1.5 #imac
acl bump_only src 192.168.1.9 #macbook
acl bump_only src 192.168.1.13 #dell

acl bump_only_mac arp MACADDRESSREDACTED
acl bump_only_mac arp MACADDRESSREDACTED
acl bump_only_mac arp MACADDRESSREDACTED
acl bump_only_mac arp MACADDRESSREDACTED
acl bump_only_mac arp MACADDRESSREDACTED
sslproxy_cert_sign signTrusted bump_only_mac

ssl_bump peek step1
miss_access deny no_miss active_use
ssl_bump splice https_login active_use
ssl_bump splice splice_only_mac splice_only active_use
ssl_bump splice NoBumpDNS active_use
ssl_bump splice NoSSLIntercept active_use
ssl_bump bump bump_only_mac bump_only active_use
acl activated note active_use true
ssl_bump terminate !activated

shutdown_lifetime 1 seconds
negative_dns_ttl 5 minutes


Does the MAC address and bump have anything to do with it? This worked in the older versions without having to input a MAC for the loopback

> On Jul 11, 2024, at 11:08, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> I use http access acl set as followed 
> 
> acl getmethod method GET
> acl to_ipv6 dst ipv6
> acl from_ipv6 src ipv6
> acl HttpAccess dstdomain "/usr/local/pkg/http.access?
> 
> 
> /usr/local/pkg/http.access
> contains:
> office.com
> data.microsoft.com
> windowsupdate.com
> dc1-st.ksn.kaspersky-labs.com
> dc1-file.ksn.kaspersky-labs.com
> dc1.ksn.kaspersky-labs.com
> gsa.apple.com
> apps.apple.com
> certs.apple.com
> crl.apple.com
> entrust.net
> digicert.com
> ocsp.apple.com
> ocsp2.apple.com
> valid.apple.com
> push.apple.com
> itunes.apple.com
> appldnld.apple.com
> gg.apple.com
> gs.apple.com
> mesu.apple.com
> oscdn.apple.com
> osrecovery.apple.com
> swcdn.apple.com
> swdownload.apple.com
> updates-http.cdn-apple.com
> appldnld.apple.com.edgesuite.net
> suconfig.apple.com
> audiocontentdownload.apple.com
> devimages-cdn.apple.com
> download.developer.apple.com
> sylvan.apple.com
> static.ips.apple.com
> 
> 
> http_access allow CONNECT wuCONNECT localnet
> http_access allow CONNECT wuCONNECT localhost
> http_access allow windowsupdate localnet
> http_access allow windowsupdate localhost
> http_access allow HttpAccess localnet
> http_access allow HttpAccess localhost
> http_access deny manager
> http_access deny to_ipv6
> http_access deny from_ipv6 
> 
>> On Jul 11, 2024, at 11:02, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> also 
>> 
>> Shell Output - squidclient -h 127.0.0.1 -v -U admin -W redacted mgr:info
>> Request:
>> GET http://127.0.0.1:3128/squid-internal-mgr/info HTTP/1.0
>> Host: 127.0.0.1:3128
>> User-Agent: squidclient/6.6
>> Accept: */*
>> Authorization: Basic YWRtaW46R09Qc3lzdGVtYWRtaW4xIQ==
>> Connection: close
>> 
>> 
>> .
>> HTTP/1.1 403 Forbidden
>> Server: squid
>> Mime-Version: 1.0
>> Date: Thu, 11 Jul 2024 18:01:46 GMT
>> Content-Type: text/html;charset=utf-8
>> Content-Length: 3788
>> X-Squid-Error: ERR_ACCESS_DENIED 0
>> Vary: Accept-Language
>> Content-Language: en
>> Cache-Status: Lee_Family.home.arpa
>> Cache-Status: Lee_Family.home.arpa;detail=no-cache
>> Connection: close
>> 
>>> On Jul 11, 2024, at 10:57, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>> 
>>> Shell Output - squidclient -v -U admin -W REDACTED mgr:info
>>> Request:
>>> GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
>>> Host: localhost:3128
>>> User-Agent: squidclient/6.6
>>> Accept: */*
>>> Authorization: Basic YWRtaW46R09Qc3lzdGVtYWRtaW4xIQ==
>>> Connection: close
>>> 
>>> 
>>> .
>>> HTTP/1.1 403 Forbidden
>>> Server: squid
>>> Mime-Version: 1.0
>>> Date: Thu, 11 Jul 2024 17:55:05 GMT
>>> Content-Type: text/html;charset=utf-8
>>> Content-Length: 3788
>>> X-Squid-Error: ERR_ACCESS_DENIED 0
>>> Vary: Accept-Language
>>> Content-Language: en
>>> Cache-Status: Lee_Family.home.arpa
>>> Cache-Status: Lee_Family.home.arpa;detail=no-cache
>>> Connection: close
>>> 
>>> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
>>> <html><head>
>>> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
>>> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
>>> <title>ERROR: The requested URL could not be retrieved</title>
>>> <style type="text/css"><!--
>>>  /*
>>>  * Copyright (C) 1996-2023 The Squid Software Foundation and contributor
>>> 
>>> Shell Output - squidclient -v -U admin -W REDACTED /squid-internal-mgr/info
>>> Request:
>>> GET /squid-internal-mgr/info HTTP/1.0
>>> User-Agent: squidclient/6.6
>>> Accept: */*
>>> Authorization: Basic YWRtaW46R09Qc3lzdGVtYWRtaW4xIQ==
>>> Connection: close
>>> 
>>> 
>>> .
>>> HTTP/1.1 403 Forbidden
>>> Server: squid
>>> Mime-Version: 1.0
>>> Date: Thu, 11 Jul 2024 17:56:48 GMT
>>> Content-Type: text/html;charset=utf-8
>>> Content-Length: 3788
>>> X-Squid-Error: ERR_ACCESS_DENIED 0
>>> Vary: Accept-Language
>>> Content-Language: en
>>> Cache-Status: Lee_Family.home.arpa
>>> Cache-Status: Lee_Family.home.arpa;detail=no-cache
>>> Connection: close
>>> 
>>> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
>>> <html><head>
>>> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
>>> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
>>> <title>ERROR: The requested URL could not be retrieved</title>
>>> <style type="text/css"><!--
>>>  /*
>>>  * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
>>> Tested both and they also failed 
>>> 
>>>> On Jul 11, 2024, at 10:27, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>> 
>>>> Thanks what about the password is it set with@ or -p where would I place that?
>>>> Sent from my iPhone
>>>> 
>>>>> On Jul 11, 2024, at 10:17, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>>>> 
>>>>> ?
>>>>>> On 11/07/24 06:08, Alex Rousskov wrote:
>>>>>> On 2024-07-10 12:55, Jonathan Lee wrote:
>>>>>>>> Embedding a password in a cache manager command requires providing a
>>>>>>>> username with -U
>>>>>>> squidclient -w /squid-internal-mgr/info -u admin
>>>>>>> squidclient -w /squid-internal-mgr/info at redacted -u admin
>>>>>>> squidclient -w http://192.168.1.1:3128/squid-internal-mgr/info at redacted -u admin
>>>>>>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info at redacted -u admin
>>>>>>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info
>>>>>>> squidclient http://127.0.0.1:3128/squid-internal-mgr/info
>>>>>>> squidclient -h 127.0.0.1:3128/squid-internal-mgr/info
>>>>>>> squidclient -h 127.0.0.1 /squid-internal-mgr/info
>>>>>>> squidclient -h 127.0.0.1 /squid-internal-mgr/info at redcated
>>>>>>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redacted
>>>>>>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redcated -u admin
>>>>>>> squidclient -h 192.168.1.1:3128  /squid-internal-mgr/info at redacted
>>>>>>> squidclient -h 192.168.1.1  /squid-internal-mgr/info at redacted
>>>>>>> squidclient -h 192.168.1.1  /squid-internal-mgr/info
>>>>>>> 
>>>>>>> with -w -u -h http spaces I can?t get it to show me stats
>>>>>>> 
>>>>>>> Squid 6.6
>>>>>> I do not know whether this mistake is relevant, but squidclient documentation and error message imply that you should be using "-U" (capital letter U) while you are using "-u" (small letter u).
>>>>> 
>>>>> 
>>>>> It is very relevant. As Matus already mentioned, both -U and -W.
>>>>> 
>>>>> 
>>>>> squidclient -v -U admin -W cachemgr_password mgr:info
>>>>> Request:
>>>>> GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
>>>>> Host: localhost:3128
>>>>> User-Agent: squidclient/6.10
>>>>> Accept: */*
>>>>> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
>>>>> Connection: close
>>>>> 
>>>>> 
>>>>> squidclient -v -U admin -W cachemgr_password /squid-internal-mgr/info
>>>>> Request:
>>>>> GET /squid-internal-mgr/info HTTP/1.0
>>>>> Host: localhost:3128
>>>>> User-Agent: squidclient/6.10
>>>>> Accept: */*
>>>>> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
>>>>> Connection: close
>>>>> 
>>>>> 
>>>>> Cheers
>>>>> Amos
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>> 
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240711/a1fc65c6/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jul 11 18:13:44 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 11 Jul 2024 11:13:44 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <FDB03E03-1FEE-44A7-A427-8CC3435EFB91@gmail.com>
References: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
 <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
 <F19657D2-D16C-4D37-8EDE-A0F7D2A5A64E@gmail.com>
 <AC4A93C3-F77B-414A-A408-39391584B388@gmail.com>
 <D97540C8-E366-4753-BB39-053208E373CB@gmail.com>
 <FDB03E03-1FEE-44A7-A427-8CC3435EFB91@gmail.com>
Message-ID: <3874DD06-8843-4ECC-AAC0-D6C8F8737589@gmail.com>

Could this cause the issue?

acl https_login url_regex -i ^https.*(login|Login).*
cache deny https_login


> On Jul 11, 2024, at 11:12, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> cachemgr_passwd disable offline_toggle reconfigure shutdown
> cachemgr_passwd PASSWORDREDCATED all
> eui_lookup on
> acl no_miss url_regex -i gateway\.facebook\.com\/ws\/realtime\?
> acl no_miss url_regex -i web-chat-e2ee\.facebook\.com\/ws\/chat
> acl CONNECT method CONNECT
> acl wuCONNECT dstdomain www.update.microsoft.com
> acl wuCONNECT dstdomain sls.microsoft.com
> http_access allow CONNECT wuCONNECT localnet
> http_access allow CONNECT wuCONNECT localhost
> http_access allow windowsupdate localnet
> http_access allow windowsupdate localhost
> http_access allow HttpAccess localnet
> http_access allow HttpAccess localhost
> http_access deny manager
> http_access deny to_ipv6
> http_access deny from_ipv6
> 
> acl BrokenButTrustedServers dstdomain "/usr/local/pkg/dstdom.broken"
> acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
> sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
> sslproxy_cert_error deny all
> 
> acl splice_only src 192.168.1.8 #Tasha iPhone
> acl splice_only src 192.168.1.10 #Jon iPhone
> acl splice_only src 192.168.1.11 #Amazon Fire
> acl splice_only src 192.168.1.15 #Tasha HP
> acl splice_only src 192.168.1.16 #iPad
> 
> acl splice_only_mac arp MACADDRESSREDACTED
> acl splice_only_mac arp MACADDRESSREDACTED
> acl splice_only_mac arp MACADDRESSREDACTED
> acl splice_only_mac arp MACADDRESSREDACTED
> acl splice_only_mac arp MACADDRESSREDACTED
> 
> acl NoSSLIntercept ssl::server_name_regex -i "/usr/local/pkg/reg.url.nobump"
> acl NoBumpDNS dstdomain "/usr/local/pkg/dns.nobump"
> 
> acl markBumped annotate_client bumped=true
> acl active_use annotate_client active=true
> acl bump_only src 192.168.1.3 #webtv
> acl bump_only src 192.168.1.4 #toshiba
> acl bump_only src 192.168.1.5 #imac
> acl bump_only src 192.168.1.9 #macbook
> acl bump_only src 192.168.1.13 #dell
> 
> acl bump_only_mac arp MACADDRESSREDACTED
> acl bump_only_mac arp MACADDRESSREDACTED
> acl bump_only_mac arp MACADDRESSREDACTED
> acl bump_only_mac arp MACADDRESSREDACTED
> acl bump_only_mac arp MACADDRESSREDACTED
> sslproxy_cert_sign signTrusted bump_only_mac
> 
> ssl_bump peek step1
> miss_access deny no_miss active_use
> ssl_bump splice https_login active_use
> ssl_bump splice splice_only_mac splice_only active_use
> ssl_bump splice NoBumpDNS active_use
> ssl_bump splice NoSSLIntercept active_use
> ssl_bump bump bump_only_mac bump_only active_use
> acl activated note active_use true
> ssl_bump terminate !activated
> 
> shutdown_lifetime 1 seconds
> negative_dns_ttl 5 minutes
> 
> 
> Does the MAC address and bump have anything to do with it? This worked in the older versions without having to input a MAC for the loopback
> 
>> On Jul 11, 2024, at 11:08, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> I use http access acl set as followed 
>> 
>> acl getmethod method GET
>> acl to_ipv6 dst ipv6
>> acl from_ipv6 src ipv6
>> acl HttpAccess dstdomain "/usr/local/pkg/http.access?
>> 
>> 
>> /usr/local/pkg/http.access
>> contains:
>> office.com
>> data.microsoft.com
>> windowsupdate.com
>> dc1-st.ksn.kaspersky-labs.com
>> dc1-file.ksn.kaspersky-labs.com
>> dc1.ksn.kaspersky-labs.com
>> gsa.apple.com
>> apps.apple.com
>> certs.apple.com
>> crl.apple.com
>> entrust.net
>> digicert.com
>> ocsp.apple.com
>> ocsp2.apple.com
>> valid.apple.com
>> push.apple.com
>> itunes.apple.com
>> appldnld.apple.com
>> gg.apple.com
>> gs.apple.com
>> mesu.apple.com
>> oscdn.apple.com
>> osrecovery.apple.com
>> swcdn.apple.com
>> swdownload.apple.com
>> updates-http.cdn-apple.com
>> appldnld.apple.com.edgesuite.net
>> suconfig.apple.com
>> audiocontentdownload.apple.com
>> devimages-cdn.apple.com
>> download.developer.apple.com
>> sylvan.apple.com
>> static.ips.apple.com
>> 
>> 
>> http_access allow CONNECT wuCONNECT localnet
>> http_access allow CONNECT wuCONNECT localhost
>> http_access allow windowsupdate localnet
>> http_access allow windowsupdate localhost
>> http_access allow HttpAccess localnet
>> http_access allow HttpAccess localhost
>> http_access deny manager
>> http_access deny to_ipv6
>> http_access deny from_ipv6 
>> 
>>> On Jul 11, 2024, at 11:02, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>> 
>>> also 
>>> 
>>> Shell Output - squidclient -h 127.0.0.1 -v -U admin -W redacted mgr:info
>>> Request:
>>> GET http://127.0.0.1:3128/squid-internal-mgr/info HTTP/1.0
>>> Host: 127.0.0.1:3128
>>> User-Agent: squidclient/6.6
>>> Accept: */*
>>> Authorization: Basic YWRtaW46R09Qc3lzdGVtYWRtaW4xIQ==
>>> Connection: close
>>> 
>>> 
>>> .
>>> HTTP/1.1 403 Forbidden
>>> Server: squid
>>> Mime-Version: 1.0
>>> Date: Thu, 11 Jul 2024 18:01:46 GMT
>>> Content-Type: text/html;charset=utf-8
>>> Content-Length: 3788
>>> X-Squid-Error: ERR_ACCESS_DENIED 0
>>> Vary: Accept-Language
>>> Content-Language: en
>>> Cache-Status: Lee_Family.home.arpa
>>> Cache-Status: Lee_Family.home.arpa;detail=no-cache
>>> Connection: close
>>> 
>>>> On Jul 11, 2024, at 10:57, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>> 
>>>> Shell Output - squidclient -v -U admin -W REDACTED mgr:info
>>>> Request:
>>>> GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
>>>> Host: localhost:3128
>>>> User-Agent: squidclient/6.6
>>>> Accept: */*
>>>> Authorization: Basic YWRtaW46R09Qc3lzdGVtYWRtaW4xIQ==
>>>> Connection: close
>>>> 
>>>> 
>>>> .
>>>> HTTP/1.1 403 Forbidden
>>>> Server: squid
>>>> Mime-Version: 1.0
>>>> Date: Thu, 11 Jul 2024 17:55:05 GMT
>>>> Content-Type: text/html;charset=utf-8
>>>> Content-Length: 3788
>>>> X-Squid-Error: ERR_ACCESS_DENIED 0
>>>> Vary: Accept-Language
>>>> Content-Language: en
>>>> Cache-Status: Lee_Family.home.arpa
>>>> Cache-Status: Lee_Family.home.arpa;detail=no-cache
>>>> Connection: close
>>>> 
>>>> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
>>>> <html><head>
>>>> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
>>>> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
>>>> <title>ERROR: The requested URL could not be retrieved</title>
>>>> <style type="text/css"><!--
>>>>  /*
>>>>  * Copyright (C) 1996-2023 The Squid Software Foundation and contributor
>>>> 
>>>> Shell Output - squidclient -v -U admin -W REDACTED /squid-internal-mgr/info
>>>> Request:
>>>> GET /squid-internal-mgr/info HTTP/1.0
>>>> User-Agent: squidclient/6.6
>>>> Accept: */*
>>>> Authorization: Basic YWRtaW46R09Qc3lzdGVtYWRtaW4xIQ==
>>>> Connection: close
>>>> 
>>>> 
>>>> .
>>>> HTTP/1.1 403 Forbidden
>>>> Server: squid
>>>> Mime-Version: 1.0
>>>> Date: Thu, 11 Jul 2024 17:56:48 GMT
>>>> Content-Type: text/html;charset=utf-8
>>>> Content-Length: 3788
>>>> X-Squid-Error: ERR_ACCESS_DENIED 0
>>>> Vary: Accept-Language
>>>> Content-Language: en
>>>> Cache-Status: Lee_Family.home.arpa
>>>> Cache-Status: Lee_Family.home.arpa;detail=no-cache
>>>> Connection: close
>>>> 
>>>> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
>>>> <html><head>
>>>> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
>>>> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
>>>> <title>ERROR: The requested URL could not be retrieved</title>
>>>> <style type="text/css"><!--
>>>>  /*
>>>>  * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
>>>> Tested both and they also failed 
>>>> 
>>>>> On Jul 11, 2024, at 10:27, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>>> 
>>>>> Thanks what about the password is it set with@ or -p where would I place that?
>>>>> Sent from my iPhone
>>>>> 
>>>>>> On Jul 11, 2024, at 10:17, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>>>>> 
>>>>>> ?
>>>>>>> On 11/07/24 06:08, Alex Rousskov wrote:
>>>>>>> On 2024-07-10 12:55, Jonathan Lee wrote:
>>>>>>>>> Embedding a password in a cache manager command requires providing a
>>>>>>>>> username with -U
>>>>>>>> squidclient -w /squid-internal-mgr/info -u admin
>>>>>>>> squidclient -w /squid-internal-mgr/info at redacted -u admin
>>>>>>>> squidclient -w http://192.168.1.1:3128/squid-internal-mgr/info at redacted -u admin
>>>>>>>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info at redacted -u admin
>>>>>>>> squidclient -w http://127.0.0.1:3128/squid-internal-mgr/info
>>>>>>>> squidclient http://127.0.0.1:3128/squid-internal-mgr/info
>>>>>>>> squidclient -h 127.0.0.1:3128/squid-internal-mgr/info
>>>>>>>> squidclient -h 127.0.0.1 /squid-internal-mgr/info
>>>>>>>> squidclient -h 127.0.0.1 /squid-internal-mgr/info at redcated
>>>>>>>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redacted
>>>>>>>> squidclient -w 127.0.0.1 /squid-internal-mgr/info at redcated -u admin
>>>>>>>> squidclient -h 192.168.1.1:3128  /squid-internal-mgr/info at redacted
>>>>>>>> squidclient -h 192.168.1.1  /squid-internal-mgr/info at redacted
>>>>>>>> squidclient -h 192.168.1.1  /squid-internal-mgr/info
>>>>>>>> 
>>>>>>>> with -w -u -h http spaces I can?t get it to show me stats
>>>>>>>> 
>>>>>>>> Squid 6.6
>>>>>>> I do not know whether this mistake is relevant, but squidclient documentation and error message imply that you should be using "-U" (capital letter U) while you are using "-u" (small letter u).
>>>>>> 
>>>>>> 
>>>>>> It is very relevant. As Matus already mentioned, both -U and -W.
>>>>>> 
>>>>>> 
>>>>>> squidclient -v -U admin -W cachemgr_password mgr:info
>>>>>> Request:
>>>>>> GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
>>>>>> Host: localhost:3128
>>>>>> User-Agent: squidclient/6.10
>>>>>> Accept: */*
>>>>>> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
>>>>>> Connection: close
>>>>>> 
>>>>>> 
>>>>>> squidclient -v -U admin -W cachemgr_password /squid-internal-mgr/info
>>>>>> Request:
>>>>>> GET /squid-internal-mgr/info HTTP/1.0
>>>>>> Host: localhost:3128
>>>>>> User-Agent: squidclient/6.10
>>>>>> Accept: */*
>>>>>> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
>>>>>> Connection: close
>>>>>> 
>>>>>> 
>>>>>> Cheers
>>>>>> Amos
>>>>>> _______________________________________________
>>>>>> squid-users mailing list
>>>>>> squid-users at lists.squid-cache.org
>>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>> 
>>> 
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240711/bb94374e/attachment.htm>

From rousskov at measurement-factory.com  Thu Jul 11 18:27:20 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 11 Jul 2024 14:27:20 -0400
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <93949ac76c724384b62d5e6332c7c1ab@eurodata.de>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
 <6bb89d7c58e34320b1eb15c1447e99d7@eurodata.de>
 <ca32f7f1-9123-47d4-a7ba-dfc40d0c6937@measurement-factory.com>
 <867452bfd4ff482bb60b90d4482265a7@eurodata.de>
 <cda7c451-72eb-4be5-bc10-a7db7ea1ba64@measurement-factory.com>
 <2d18e96ef2be492f9deea0b5c07688f5@eurodata.de>
 <b44b830f-3ec4-4464-adf3-5695fe280ad5@measurement-factory.com>
 <93949ac76c724384b62d5e6332c7c1ab@eurodata.de>
Message-ID: <41737fa0-ab1a-4d94-a355-eb77a1fabc21@measurement-factory.com>

On 2024-07-11 13:37, Fiehe, Christoph wrote:
> My proxy (the child proxy) already uses the OpenSSL library:

Good.


> The parent proxy was compiled ... '--with-gnutls'

> The GnuTLS exception is thrown at my parent proxy. 

Thank you for reminding me of that fact; I did not notice or have 
forgotten about it. I assume you cannot rebuild your parent proxy to use 
OpenSSL.

I see the following choice:

A) Continue with the current no-CONNECT setup: Find somebody who can 
help you get Squid+GnuTLS code path working on the parent proxy. It 
might be impossible to get this working without making build or 
configuration changes at the parent proxy. Moreover, please note that 
your current no-CONNECT setup lacks encryption on the child-parent 
segment. If that was not intentional, then fixing that will increase 
TLS-related work for the parent, potentially triggering more problems there.

B) Switch to a CONNECT-based setup: Find somebody who can enhance Squid 
code to establish a CONNECT tunnel through parent proxy when dealing 
with a GET-https request. Today, Squid will not do that AFAICT[^1].

https://wiki.squid-cache.org/SquidFaq/AboutSquid#how-to-add-a-new-squid-feature-enhance-of-fix-something


[^1]: AFAICT: Today, there are two primary Squid code conditions for 
establishing a CONNECT tunnel on a caching code path: Request method is 
CONNECT or SslBump is in use. Neither matches your GET-https request 
scenario. Squid current behavior is not "wrong" (as detailed in my 
earlier email about CONNECT and no-CONNECT scenarios), so, to make these 
changes official, the author will need to add a configuration option to 
let admins enable this behavior. The corresponding code changes feel 
straightforward to me, but I have not studied any details.


HTH,

Alex.



> Unfortunately, I cannot make any changes here. So yes, I trust my parent proxy, but not using a tunnel between child and parent does not seem to work and results in the TLS exception on the parent proxy.
> 
> I have not find a way to tell my child proxy to always setup a tunnel through the parent proxy, when the target server talks HTTPS. Do you know, how to achieve that? It would be a promising approach.
> 
> Thank you very much help and your patience, Alex.
> 
> Regards,
> Christoph
> 
> 
>> -----Urspr?ngliche Nachricht-----
>> Von: squid-users <squid-users-bounces at lists.squid-cache.org> Im Auftrag von Alex Rousskov
>> Gesendet: Donnerstag, 11. Juli 2024 18:15
>> An: squid-users at lists.squid-cache.org
>> Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>>
>> On 2024-07-10 16:57, Fiehe, Christoph wrote:
>>
>>> I am just trying to find something that helps to narrow down the
>>> problem. What I want to achieve is, that a client can use HTTP in the
>>> LAN, so that Squid can cache distribution packages without making use
>>> of SSL intercepting when repos are only accessible via HTTPS.
>>
>> OK.
>>
>>
>>> In that case the secure connection must start at the proxy and end on
>>> the target server with or without any upstream proxies in betweem.
>>
>> It depends on whether you trust the parent proxy:
>>
>> If you trust the parent proxy, then you can use two secure connections:
>>
>> 1.1. child - parent (TLS; no CONNECT)
>> 1.2. parent - origin (TLS; no CONNECT)
>>
>> If you do not trust the parent proxy, then, yes, you will need a tunnel:
>>
>> 2.1. child - parent (CONNECT)
>> 2.2. child - origin (TLS inside the CONNECT tunnel)
>>
>> N.B. CONNECT request in 2.1 may be plain text (common) or encrypted
>> (rare); I am ignoring the difference between those two subcases for now.
>>
>>
>>> We have the following setup:
>>>
>>> client -> downstream proxy -> upstream proxy -> https://download.docker.com
>>>
>>> Now let us assume the client wants to retrieve the following resource
>> http://download.docker.com/linux/ubuntu/dists/jammy/InRelease from the upstream proxy.
>>>
>>> The client initiates a HTTP GET request and sends it to the downstream proxy. Now, the
>> URL gets rewritten.
>>
>> OK.
>>
>>
>>> It indicates to use a HTTPS connection instead in order to talk to the target server, in
>> our case the result is https://download.docker.com/linux/ubuntu/dists/jammy/InRelease.
>>
>> Yes, but HTTPS scheme does not imply that the child Squid has to use
>> CONNECT. There are two possible scenarios detailed above. I do not know
>> which of them applies to your use case.
>>
>>
>>> Now comes the critical point: From my understanding ? it may be
>>> wrongof course - the downstream server now has to send a CONNECT
>>> request to the upstream server
>>
>> Yes, provided the child (downstream) proxy does not trust that parent
>> (upstream) proxy. That is scenario 2. Scenario 1 is different.
>>
>>
>>> to advise him to establish a secure connection to the target server.
>>
>> No, the CONNECT tunnel itself is just a pair of TCP connections. The
>> parent proxy "secures" nothing but basic TCP connectivity. It is the
>> child proxy that negotiates TLS (over/inside that tunnel) with the
>> origin server.
>>
>>
>>> After creation, the downstream proxy can retrieve the resource and
>>> send it back to the client via plain HTTP.
>>
>> Yes.
>>
>>
>>
>>> I suppose, that the GnuTLS occurs because of a missing SSL handshake
>>> between downstream proxy and download.docker.com.
>>
>> At this time, I can only say that a TLS negotiation error occurs (while
>> child Squid is using the encryption library it probably should not be
>> using for this). It is not yet clear to me whether child Squid is
>> negotiating with the wrong hop or something goes wrong during
>> negotiation with the right hop.
>>
>> As the next steps, I recommend switching to OpenSSL and, if that alone
>> does not help, sharing new errors and determining whether you want to
>> use scenario 1 (no CONNECT), scenario 2 (CONNECT), or either (whichever
>> works): Do you trust the parent Squid?
>>
>>
>> HTH,
>>
>> Alex.
>>
>>
>>>> -----Urspr?ngliche Nachricht-----
>>>> Von: Alex Rousskov <rousskov at measurement-factory.com>
>>>> Gesendet: Mittwoch, 10. Juli 2024 22:15
>>>> An: squid-users at lists.squid-cache.org
>>>> Cc: Fiehe, Christoph <c.fiehe at eurodata.de>
>>>> Betreff: AW: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>>>>
>>>> On 2024-07-10 15:31, Fiehe, Christoph wrote:
>>>>> The problem is that the proxy just forwards the client GET request to the upstream
>> proxy
>>>>
>>>> Why does sending a GET request to the upstream proxy represent a problem
>>>> in your use case? I cannot find anything in your prior messages on this
>>>> thread that would preclude sending a GET request to the upstream proxy.
>>>>
>>>>
>>>>> but in that case a CONNECT is required.
>>>>
>>>> Why?
>>>>
>>>> Please do not interpret my response as implying that this "must send
>>>> CONNECT" requirement is wrong (or correct). At this point, I am just
>>>> trying to understand what problem(s) you are trying to solve beyond the
>>>> one you have originally described.
>>>>
>>>>
>>>> Thank you,
>>>>
>>>> Alex.
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From jonathanlee571 at gmail.com  Thu Jul 11 18:43:23 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 11 Jul 2024 11:43:23 -0700
Subject: [squid-users] Squid 6.6 error clientProcessHit: Vary object
 loop!
In-Reply-To: <A9316505-DD38-433A-8C06-9C6599A02A65@gmail.com>
References: <A9316505-DD38-433A-8C06-9C6599A02A65@gmail.com>
Message-ID: <432BDA5F-563A-44FC-AD56-DD1238B9BD1F@gmail.com>

What is Vary Object loop??

Does that  mean clear my cache? Or is that something I am missing has anyone else seen this?

11.07.2024 11:36:49	clientProcessHit: Vary object loop!
11.07.2024 11:36:49	varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'https://static.foxnews.com/static/orion/styles/css/fox-news/article-new.rs.css9; 'accept-encoding="gzip,%20deflate,%20br,%20zstd"'
11.07.2024 11:36:49	clientProcessHit: Vary object loop!
11.07.2024 11:36:49	varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'https://static.foxnews.com/static/strike/ver/foxnews/loader.global.js' 'accept-encoding="gzip,%20deflate,%20br,%20zstd"'
31.12.1969 16:00:00	
11.07.2024 11:36:40	SECURITY ALERT: on URL: mask.icloud.com:443
31.12.1969 16:00:00	
11.07.2024 11:36:40	SECURITY ALERT: Host header forgery detected on conn10283 local=17.248.245.233:443 remote=192.168.1.10:55733 FD 37 flags=33 (local IP does not match any domain IP)
31.12.1969 16:00:00	
11.07.2024 11:36:37	SECURITY ALERT: on URL: mask.icloud.com:443
31.12.1969 16:00:00	
11.07.2024 11:36:37	SECURITY ALERT: Host header forgery detected on conn10215 local=17.248.245.132:443 remote=192.168.1.10:55730 FD 26 flags=33 (local IP does not match any domain IP)
31.12.1969 16:00:00	
11.07.2024 11:36:36	ERROR: failure while accepting a TLS connection on conn10136 local=17.248.245.36:443 remote=192.168.1.5:50800 FD 61 flags=33: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000417+TLS_IO_ERR=1
11.07.2024 11:36:36	clientProcessHit: Vary object loop!
11.07.2024 11:36:36	varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'https://www.foxnews.com/_wzln/59f1c12.js' 'accept-encoding="gzip,%20deflate,%20br,%20zstd&quot;'
11.07.2024 11:36:34	clientProcessHit: Vary object loop!
11.07.2024 11:36:34	varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'https://www.foxnews.com/_wzln/77963e9.js' 'accept-encoding="gzip,%20deflate,%20br,%20zstd&quot;'
31.12.1969 16:00:00	
11.07.2024 11:36:30	SECURITY ALERT: on URL: mask.icloud.com:443
31.12.1969 16:00:00	
11.07.2024 11:36:30	SECURITY ALERT: Host header forgery detected on conn10151 local=17.248.245.132:443 remote=192.168.1.10:55728 FD 84 flags=33 (local IP does not match any domain IP)
11.07.2024 11:36:28	clientProcessHit: Vary object loop!
11.07.2024 11:36:28	varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'https://www.foxnews.com/_wzln/bb8a19f.js' 'accept-encoding="gzip,%20deflate,%20br,%20zstd&quot;'
31.12.1969 16:00:00	
11.07.2024 11:36:27	SECURITY ALERT: on URL: mask.icloud.com:443
31.12.1969 16:00:00	
11.07.2024 11:36:27	SECURITY ALERT: Host header forgery detected on conn10117 local=17.248.245.229:443 remote=192.168.1.10:55726 FD 32 flags=33 (local IP does not match any domain IP)
31.12.1969 16:00:00	
11.07.2024 11:36:19	SECURITY ALERT: on URL: mask-h2.icloud.com:443
31.12.1969 16:00:00	
11.07.2024 11:36:19	SECURITY ALERT: Host header forgery detected on conn10000 local=17.248.245.233:443 remote=192.168.1.10:55724 FD 93 flags=33 (local IP does not match any domain IP)
31.12.1969 16:00:00	
11.07.2024 11:36:16	SECURITY ALERT: on URL: mask-h2.icloud.com:443
31.12.1969 16:00:00	
11.07.2024 11:36:16	SECURITY ALERT: Host header forgery detected on conn9981 local=17.248.245.132:443 remote=192.168.1.10:55722 FD 107 flags=33 (local IP does not match any domain IP)
31.12.1969 16:00:00	
11.07.2024 11:36:16	SECURITY ALERT: on URL: mask-h2.icloud.com:443
31.12.1969 16:00:00	
11.07.2024 11:36:16	SECURITY ALERT: Host header forgery detected on conn9975 local=17.248.245.229:443 remote=192.168.1.10:55721 FD 102 flags=33 (local IP does not match any domain IP)
31.12.1969 16:00:00


> On Jul 10, 2024, at 09:57, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Has anyone seen this before? on hits?
> 
> 
> 10.07.2024 09:56:30	clientProcessHit: Vary object loop!
> 10.07.2024 09:56:30	varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'https://zagent20.h-cdn.com/cmd/get_thumb_info?customer=foxnews&ver=1.165.67&amp;url=https%3A%2F%2F247preview.foxnews.com%2Fhls%2Flive%2F2020027%2Ffncv3preview%2Findex.m3u8' 'origin="https%3A%2F%2Fstatic.foxnews.com", accept-encoding="gzip,%20deflate,%20br,%20zstd"'
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00	
> 31.12.1969 16:00:00

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240711/354c68fe/attachment.htm>

From squid3 at treenet.co.nz  Thu Jul 11 19:59:14 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Jul 2024 07:59:14 +1200
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
References: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
 <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
Message-ID: <de84e4f1-ff61-4e78-a7b8-6c266c6257fe@treenet.co.nz>

On 12/07/24 05:27, Jonathan Lee wrote:
> Thanks what about the password is it set with@ or -p where would I place that?

Neither. It is set with -W .

Amos


> Sent from my iPhone
> 
>> On Jul 11, 2024, at 10:17, Amos Jeffries wrote:
>>
>> It is very relevant. As Matus already mentioned, both -U and -W.
>>
>>
>> squidclient -v -U admin -W cachemgr_password mgr:info
>> Request:
>> GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
>> Host: localhost:3128
>> User-Agent: squidclient/6.10
>> Accept: */*
>> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
>> Connection: close
>>
>>
>> squidclient -v -U admin -W cachemgr_password /squid-internal-mgr/info
>> Request:
>> GET /squid-internal-mgr/info HTTP/1.0
>> Host: localhost:3128
>> User-Agent: squidclient/6.10
>> Accept: */*
>> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
>> Connection: close
>>
>>
>> Cheers
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users


From jonathanlee571 at gmail.com  Thu Jul 11 20:00:37 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 11 Jul 2024 13:00:37 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <de84e4f1-ff61-4e78-a7b8-6c266c6257fe@treenet.co.nz>
References: <de84e4f1-ff61-4e78-a7b8-6c266c6257fe@treenet.co.nz>
Message-ID: <28D5F9C6-991A-41E1-B4A8-B870D376899F@gmail.com>

Ok I sent output prior email that shows the right path but says access denied 
Sent from my iPhone

> On Jul 11, 2024, at 12:59, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> ?On 12/07/24 05:27, Jonathan Lee wrote:
>> Thanks what about the password is it set with@ or -p where would I place that?
> 
> Neither. It is set with -W .
> 
> Amos
> 
> 
>> Sent from my iPhone
>>>> On Jul 11, 2024, at 10:17, Amos Jeffries wrote:
>>> 
>>> It is very relevant. As Matus already mentioned, both -U and -W.
>>> 
>>> 
>>> squidclient -v -U admin -W cachemgr_password mgr:info
>>> Request:
>>> GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
>>> Host: localhost:3128
>>> User-Agent: squidclient/6.10
>>> Accept: */*
>>> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
>>> Connection: close
>>> 
>>> 
>>> squidclient -v -U admin -W cachemgr_password /squid-internal-mgr/info
>>> Request:
>>> GET /squid-internal-mgr/info HTTP/1.0
>>> Host: localhost:3128
>>> User-Agent: squidclient/6.10
>>> Accept: */*
>>> Authorization: Basic YWRtaW46Y2FjaGVtZ3JfcGFzc3dvcmQ=
>>> Connection: close
>>> 
>>> 
>>> Cheers
>>> Amos
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Thu Jul 11 20:16:46 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Jul 2024 08:16:46 +1200
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <FDB03E03-1FEE-44A7-A427-8CC3435EFB91@gmail.com>
References: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
 <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
 <F19657D2-D16C-4D37-8EDE-A0F7D2A5A64E@gmail.com>
 <AC4A93C3-F77B-414A-A408-39391584B388@gmail.com>
 <D97540C8-E366-4753-BB39-053208E373CB@gmail.com>
 <FDB03E03-1FEE-44A7-A427-8CC3435EFB91@gmail.com>
Message-ID: <ec61944c-6420-41b7-8737-05230761eac2@treenet.co.nz>


Lets see ...

 >>> On Jul 11, 2024, at 11:02, Jonathan Lee wrote:
 >>>     Shell Output - squidclient -h 127.0.0.1 -v -U admin -W redacted
 >>>     mgr:info
 >>>
 >>> Request:
 >>> GET http://127.0.0.1:3128/squid-internal-mgr/info HTTP/1.0
 >>> Host: 127.0.0.1:3128
 >>> User-Agent: squidclient/6.6
 >>> Accept: */*
 >>> Authorization: Basic YWRtaW4..REDACTED..Q==
 >>> Connection: close


On 12/07/24 06:12, Jonathan Lee wrote:
> http_access allow CONNECT wuCONNECT localnet
> http_access allow CONNECT wuCONNECT localhost


  ... GET is not CONNECT. Skip the above.


> http_access allow windowsupdate localnet
> http_access allow windowsupdate localhost


  ... 127.0.0.1 is not in *.microsoft.com. Skip the above.


> http_access allow HttpAccess localnet
> http_access allow HttpAccess localhost


  ... 127.0.0.1 is not listed in /usr/local/pkg/http.access. Skip the above.


> http_access deny manager


  ... /squid-internal-mgr/ matches.  DENY the request.


Problem solved.

What you should do is restore the default security settings which we 
ship with Squid.

Place these above your custom http_access lines:

   http_access deny !Safe_ports
   http_access deny CONNECT !SSL_ports
   http_access allow localhost manager
   http_access deny manager


see <https://wiki.squid-cache.org/Releases/Squid-5> for the ACL details 
if you need them too.



Amos


From squid3 at treenet.co.nz  Thu Jul 11 20:43:51 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Jul 2024 08:43:51 +1200
Subject: [squid-users] Squid 6.6 error clientProcessHit: Vary object
 loop!
In-Reply-To: <432BDA5F-563A-44FC-AD56-DD1238B9BD1F@gmail.com>
References: <A9316505-DD38-433A-8C06-9C6599A02A65@gmail.com>
 <432BDA5F-563A-44FC-AD56-DD1238B9BD1F@gmail.com>
Message-ID: <150ee779-d0b8-42e2-a44d-55700ef81b2c@treenet.co.nz>

On 12/07/24 06:43, Jonathan Lee wrote:
> What is Vary Object loop??
> 

In HTTP URLs can point at a set or "variants" of a resource.

Squid "Vary Object" is an entry in the cache that is used to represent 
these types of resource.
  When the URL-only is looked up, the "Vary Object" is found and tells 
Squid to perform a second lookup appending certain details to the hash 
key to find the actual object that client needs.

A "Vary Object loop" is when this second lookup finds an object which is 
not the desired variant of that original URL.


You can see this in your first message ...


 >> 10.07.2024 09:56:30	clientProcessHit: Vary object loop!
 >> 10.07.2024 09:56:30	varyEvaluateMatch: Oops. Not a Vary match on
 >> second attempt,

Original request came in for "https%3A%2F%2Fstatic.foxnews.com"

That URL had a cached "Vary Object" saying there were different 
responses to provide depending on the Accept-Encoding header:

Squdi performed a second lookup for:

 >> 'origin="https%3A%2F%2Fstatic.foxnews.com", 
accept-encoding="gzip,%20deflate,%20br,%20zstd"'


... which found a cache entry for this URL:

 >> 
'https://zagent20.h-cdn.com/cmd/get_thumb_info?customer=foxnews&ver=1.165.67&amp;url=https%3A%2F%2F247preview.foxnews.com%2Fhls%2Flive%2F2020027%2Ffncv3preview%2Findex.m3u8'


which is not the same URL.



> Does that ?mean clear my cache?

No. But yes.

A quick check of the URLs from your log message with the tool at 
<https://redbot.org/?uri=https://static.foxnews.com/static/orion/styles/css/fox-news/article-new.rs.css> 


We can see that:

"
     The resource doesn't send Vary consistently.
     The ETag doesn't change between negotiated representations.
"


You can ignore these log messages.

Or, you can configure Squid not to cache content from this server. If 
you do this, then clearing the cache would stop the log entries continuing.


> Or is that something I am missing has 
> anyone else seen this?
> 

That origin server is broken. So likely everyone is seeing the same 
problem with that website.


> 11.07.2024 11:36:49	clientProcessHit: Vary object loop!
> 11.07.2024 11:36:49	varyEvaluateMatch: Oops.?Not a Vary match on second 
> attempt, 
> 'https://static.foxnews.com/static/orion/styles/css/fox-news/article-new.rs.css9; 'accept-encoding="gzip,%20deflate,%20br,%20zstd"'
> 11.07.2024 11:36:49	clientProcessHit: Vary object loop!
> 11.07.2024 11:36:49	varyEvaluateMatch: Oops.?Not a Vary match on second 
> attempt, 
> 'https://static.foxnews.com/static/strike/ver/foxnews/loader.global.js' 
> 'accept-encoding="gzip,%20deflate,%20br,%20zstd"'
> 31.12.1969 16:00:00	
<snip>


Cheers
Amos


From squid3 at treenet.co.nz  Thu Jul 11 21:03:42 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Jul 2024 09:03:42 +1200
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
Message-ID: <60d138f7-0c05-48d0-8d9d-959526e40499@treenet.co.nz>

On 11/07/24 00:49, Alex Rousskov wrote:
> On 2024-07-09 18:25, Fiehe, Christoph wrote:
> 
>> I hope that somebody has an idea, what I am doing wrong. 
> 
> AFAICT from the debugging log, it is your parent proxy that returns an 
> ERR_SECURE_CONNECT_FAIL error page in response to a seemingly valid 
> "HEAD https://..." request. Can you ask their admin to investigate? You 
> may also recommend that they upgrade from Squid v4 that has many known 
> security vulnerabiities.
> 
> If parent is uncooperative, you can try to reproduce the problem by 
> temporary installing your own parent Squid instance and configuring your 
> child Squid to use that instead.
> 
> HTH,
> 
> Alex.
> P.S. Unlike Amos, I do not see serious conceptual problems with 
> rewriting request target scheme (as a temporary compatibility measure). 
> It may not always work, for various reasons, but it does not necessarily 
> make things worse (and may make things better).
> 

To which I refer you to:
  <https://cwe.mitre.org/data/definitions/311.html>
  <https://cwe.mitre.org/data/definitions/312.html>
  <https://cwe.mitre.org/data/definitions/319.html>

Cheers
Amos


From jonathanlee571 at gmail.com  Thu Jul 11 21:19:48 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 11 Jul 2024 14:19:48 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <ec61944c-6420-41b7-8737-05230761eac2@treenet.co.nz>
References: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
 <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
 <F19657D2-D16C-4D37-8EDE-A0F7D2A5A64E@gmail.com>
 <AC4A93C3-F77B-414A-A408-39391584B388@gmail.com>
 <D97540C8-E366-4753-BB39-053208E373CB@gmail.com>
 <FDB03E03-1FEE-44A7-A427-8CC3435EFB91@gmail.com>
 <ec61944c-6420-41b7-8737-05230761eac2@treenet.co.nz>
Message-ID: <3A753A42-FAEE-42F1-87D7-93EB45EF2D9E@gmail.com>

Tested same thing..

I noticed it does have the default when I ran squid -k parse see below


I restored lines:
http_access deny !safeports
http_access deny CONNECT !sslports
http_access allow localhost manager
http_access deny manager
cachemgr_passwd disable offline_toggle reconfigure shutdown
cachemgr_passwd redacted password all
eui_lookup on
acl no_miss url_regex -i gateway\.facebook\.com\/ws\/realtime\?
acl no_miss url_regex -i web-chat-e2ee\.facebook\.com\/ws\/chat
acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com
http_access allow CONNECT wuCONNECT localnet
http_access allow CONNECT wuCONNECT localhost
http_access allow windowsupdate localnet
http_access allow windowsupdate localhost
http_access allow HttpAccess localnet
http_access allow HttpAccess localhost
http_access deny manager
http_access deny to_ipv6
http_access deny from_ipv6

acl BrokenButTrustedServers dstdomain "/usr/local/pkg/dstdom.broken"
acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
sslproxy_cert_error deny all

acl splice_only src 192.168.1.8 #Tasha iPhone
acl splice_only src 192.168.1.10 #Jon iPhone
acl splice_only src 192.168.1.11 #Amazon Fire
acl splice_only src 192.168.1.15 #Tasha HP
acl splice_only src 192.168.1.16 #iPad

acl splice_only_mac arp redactedmac
acl splice_only_mac arp redactedmac
acl splice_only_mac arp redactedmac
acl splice_only_mac arp redactedmac
acl splice_only_mac arp redactedmac

acl NoSSLIntercept ssl::server_name_regex -i "/usr/local/pkg/reg.url.nobump"
acl NoBumpDNS dstdomain "/usr/local/pkg/dns.nobump"

acl markBumped annotate_client bumped=true
acl active_use annotate_client active=true
acl bump_only src 192.168.1.3 #webtv
acl bump_only src 192.168.1.4 #toshiba
acl bump_only src 192.168.1.5 #imac
acl bump_only src 192.168.1.9 #macbook
acl bump_only src 192.168.1.13 #dell

acl bump_only_mac arp redactedmac
acl bump_only_mac arp redactedmac
acl bump_only_mac arp redactedmac
acl bump_only_mac arp redactedmac
acl bump_only_mac arp redactedmac
sslproxy_cert_sign signTrusted bump_only_mac

ssl_bump peek step1
miss_access deny no_miss active_use
ssl_bump splice https_login active_use
ssl_bump splice splice_only_mac splice_only active_use
ssl_bump splice NoBumpDNS active_use
ssl_bump splice NoSSLIntercept active_use
ssl_bump bump bump_only_mac bump_only active_use
acl activated note active_use true
ssl_bump terminate !activated

shutdown_lifetime 1 seconds
negative_dns_ttl 5 minutes

Output same

Shell Output - squidclient -v -U admin -W redactedpassword mgr:info
Request:
GET http://localhost:3128/squid-internal-mgr/info HTTP/1.0
Host: localhost:3128
User-Agent: squidclient/6.6
Accept: */*
Authorization: Basic redactedQ==
Connection: close


.
HTTP/1.1 403 Forbidden
Server: squid
Mime-Version: 1.0
Date: Thu, 11 Jul 2024 21:06:49 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3788
X-Squid-Error: ERR_ACCESS_DENIED 0
Vary: Accept-Language
Content-Language: en
Cache-Status: Lee_Family.home.arpa
Cache-Status: Lee_Family.home.arpa;detail=no-cache
Connection: close
same thing tested with -h 127.0.0.1
Request:
GET http://127.0.0.1:3128/squid-internal-mgr/info HTTP/1.0
Host: 127.0.0.1:3128
User-Agent: squidclient/6.6
Accept: */*
Authorization: Basic redacted==
Connection: close


.
HTTP/1.1 403 Forbidden
Server: squid
Mime-Version: 1.0
Date: Thu, 11 Jul 2024 21:18:48 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3788
X-Squid-Error: ERR_ACCESS_DENIED 0
Vary: Accept-Language
Content-Language: en
Cache-Status: Lee_Family.home.arpa
Cache-Status: Lee_Family.home.arpa;detail=no-cache
Connection: close

squid -k parse shows 
2024/07/11 14:09:27| Processing Configuration File: /usr/local/etc/squid/squid.conf (depth 0)
2024/07/11 14:09:27| Processing: http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
2024/07/11 14:09:27| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
2024/07/11 14:09:27| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
    OpenSSL-saved error #1: 0x1e08010c
2024/07/11 14:09:27| ERROR: Unsupported TLS option SINGLE_DH_USE
2024/07/11 14:09:27| ERROR: Unsupported TLS option SINGLE_ECDH_USE
2024/07/11 14:09:27| Processing: http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
2024/07/11 14:09:27| Starting Authentication on port 127.0.0.1:3128
2024/07/11 14:09:27| Disabling Authentication on port 127.0.0.1:3128 (interception enabled)
2024/07/11 14:09:27| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
2024/07/11 14:09:27| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
    OpenSSL-saved error #1: 0x1e08010c
2024/07/11 14:09:27| ERROR: Unsupported TLS option SINGLE_DH_USE
2024/07/11 14:09:27| ERROR: Unsupported TLS option SINGLE_ECDH_USE
2024/07/11 14:09:27| Processing: https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
2024/07/11 14:09:27| Starting Authentication on port 127.0.0.1:3129
2024/07/11 14:09:27| Disabling Authentication on port 127.0.0.1:3129 (interception enabled)
2024/07/11 14:09:27| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in https_port. Use 'tls-cafile=' instead.
2024/07/11 14:09:27| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
    OpenSSL-saved error #1: 0x1e08010c
2024/07/11 14:09:27| ERROR: Unsupported TLS option SINGLE_DH_USE
2024/07/11 14:09:27| ERROR: Unsupported TLS option SINGLE_ECDH_USE
2024/07/11 14:09:27| Processing: tcp_outgoing_address 207.231.82.182
2024/07/11 14:09:27| Processing: icp_port 0
2024/07/11 14:09:27| Processing: digest_generation off
2024/07/11 14:09:27| Processing: dns_v4_first on
2024/07/11 14:09:27| ERROR: Directive 'dns_v4_first' is obsolete.
2024/07/11 14:09:27| dns_v4_first : Remove this line. Squid no longer supports preferential treatment of DNS A records.
2024/07/11 14:09:27| Processing: pid_filename /var/run/squid/squid.pid
2024/07/11 14:09:27| Processing: cache_effective_user squid
2024/07/11 14:09:27| Processing: cache_effective_group proxy
2024/07/11 14:09:27| Processing: error_default_language en
2024/07/11 14:09:27| Processing: icon_directory /usr/local/etc/squid/icons
2024/07/11 14:09:27| Processing: visible_hostname Lee_Family.home.arpa
2024/07/11 14:09:27| Processing: cache_mgr jonathanlee571 at gmail.com
2024/07/11 14:09:27| Processing: access_log /var/squid/logs/access.log
2024/07/11 14:09:27| Processing: cache_log /var/squid/logs/cache.log
2024/07/11 14:09:27| Processing: cache_store_log none
2024/07/11 14:09:27| Processing: netdb_filename /var/squid/logs/netdb.state
2024/07/11 14:09:27| Processing: pinger_enable on
2024/07/11 14:09:27| Processing: pinger_program /usr/local/libexec/squid/pinger
2024/07/11 14:09:27| Processing: sslcrtd_program /usr/local/libexec/squid/security_file_certgen -s /var/squid/lib/ssl_db -M 4MB -b 2048
2024/07/11 14:09:27| Processing: tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
2024/07/11 14:09:27| Processing: tls_outgoing_options capath=/usr/local/share/certs/
2024/07/11 14:09:27| Processing: tls_outgoing_options options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
2024/07/11 14:09:27| ERROR: Unsupported TLS option SINGLE_DH_USE
2024/07/11 14:09:27| ERROR: Unsupported TLS option SINGLE_ECDH_USE
2024/07/11 14:09:27| Processing: tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS
2024/07/11 14:09:27| Processing: sslcrtd_children 10
2024/07/11 14:09:27| Processing: logfile_rotate 7
2024/07/11 14:09:27| Processing: debug_options rotate=7
2024/07/11 14:09:27| Processing: shutdown_lifetime 3 seconds
2024/07/11 14:09:27| Processing: acl localnet src  192.168.1.0/27
2024/07/11 14:09:27| Processing: forwarded_for delete
2024/07/11 14:09:27| Processing: via off
2024/07/11 14:09:27| Processing: httpd_suppress_version_string on
2024/07/11 14:09:27| Processing: uri_whitespace strip
2024/07/11 14:09:27| Processing: acl block_hours time 00:30-05:00
2024/07/11 14:09:27| Processing: ssl_bump terminate all block_hours
2024/07/11 14:09:27| Processing: http_access deny all block_hours
2024/07/11 14:09:27| Processing: acl getmethod method GET
2024/07/11 14:09:27| Processing: acl to_ipv6 dst ipv6
2024/07/11 14:09:27| Processing: acl from_ipv6 src ipv6
2024/07/11 14:09:27| Processing: acl HttpAccess dstdomain "/usr/local/pkg/http.access"
2024/07/11 14:09:27| Processing: acl windowsupdate dstdomain "/usr/local/pkg/windowsupdate"
2024/07/11 14:09:27| Processing: acl rewritedoms dstdomain "/usr/local/pkg/desdom"
2024/07/11 14:09:27| Processing: always_direct allow all
2024/07/11 14:09:27| Processing: refresh_all_ims on
2024/07/11 14:09:27| Processing: reload_into_ims on
2024/07/11 14:09:27| Processing: max_stale 20 years
2024/07/11 14:09:27| Processing: minimum_expiry_time 0
2024/07/11 14:09:27| Processing: refresh_pattern -i ^http.*squid\.internal.* 43200 100% 79900 override-expire override-lastmod ignore-reload ignore-no-store ignore-must-revalidate ignore-private ignore-auth
2024/07/11 14:09:27| UPGRADE: refresh_pattern option 'ignore-must-revalidate' is obsolete. Remove it.
2024/07/11 14:09:27| UPGRADE: refresh_pattern option 'ignore-auth' is obsolete. Remove it.
2024/07/11 14:09:27| Processing: refresh_pattern -i windowsupdate.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
2024/07/11 14:09:27| Processing: refresh_pattern -i microsoft.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
2024/07/11 14:09:27| Processing: refresh_pattern -i windows.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
2024/07/11 14:09:27| Processing: refresh_pattern -i microsoft.com.akadns.net/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
2024/07/11 14:09:27| Processing: refresh_pattern -i deploy.akamaitechnologies.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
2024/07/11 14:09:27| Processing: refresh_pattern -i windowsupdate.com/..(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$ 4320 80% 43200  refresh-ims
2024/07/11 14:09:27| Processing: acl https_login url_regex -i ^https.*(login|Login).*
2024/07/11 14:09:27| Processing: cache deny https_login
2024/07/11 14:09:27| Processing: range_offset_limit 512 MB windowsupdate
2024/07/11 14:09:27| Processing: range_offset_limit 4 MB
2024/07/11 14:09:27| Processing: quick_abort_min -1 KB
2024/07/11 14:09:27| Processing: cache_mem 64 MB
2024/07/11 14:09:27| Processing: maximum_object_size_in_memory 256 KB
2024/07/11 14:09:27| Processing: memory_replacement_policy heap GDSF
2024/07/11 14:09:27| Processing: cache_replacement_policy heap LFUDA
2024/07/11 14:09:27| Processing: minimum_object_size 0 KB
2024/07/11 14:09:27| Processing: maximum_object_size 512 MB
2024/07/11 14:09:27| Processing: cache_dir diskd /var/squid/cache 64000 256 256
2024/07/11 14:09:27| Processing: offline_mode off
2024/07/11 14:09:27| Processing: cache_swap_low 90
2024/07/11 14:09:27| Processing: cache_swap_high 95
2024/07/11 14:09:27| Processing: acl donotcache dstdomain "/var/squid/acl/donotcache.acl"
2024/07/11 14:09:27| Processing: cache deny donotcache
2024/07/11 14:09:27| Processing: cache allow all
2024/07/11 14:09:27| Processing: refresh_pattern ^ftp:    1440  20%  10080
2024/07/11 14:09:27| Processing: refresh_pattern ^gopher:  1440  0%  1440
2024/07/11 14:09:27| Processing: refresh_pattern -i (/cgi-bin/|\?) 0  0%  0
2024/07/11 14:09:27| Processing: refresh_pattern .    0  20%  4320
2024/07/11 14:09:27| Processing: acl allsrc src all
2024/07/11 14:09:27| Processing: acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080 3128 3129 1025-65535
2024/07/11 14:09:27| Processing: acl sslports port 443 563 8080 5223 2197
2024/07/11 14:09:27| Processing: acl purge method PURGE
2024/07/11 14:09:27| Processing: acl connect method CONNECT
2024/07/11 14:09:27| Processing: acl HTTP proto HTTP
2024/07/11 14:09:27| Processing: acl HTTPS proto HTTPS
2024/07/11 14:09:27| Processing: acl step1 at_step SslBump1
2024/07/11 14:09:27| Processing: acl step2 at_step SslBump2
2024/07/11 14:09:27| Processing: acl step3 at_step SslBump3
2024/07/11 14:09:27| Processing: acl banned_hosts src "/var/squid/acl/banned_hosts.acl"
2024/07/11 14:09:27| Processing: acl whitelist dstdom_regex -i "/var/squid/acl/whitelist.acl"
2024/07/11 14:09:27| Processing: acl blacklist dstdom_regex -i "/var/squid/acl/blacklist.acl"
2024/07/11 14:09:27| Processing: http_access allow manager localhost
2024/07/11 14:09:27| Processing: http_access deny manager
2024/07/11 14:09:27| Processing: http_access allow purge localhost
2024/07/11 14:09:27| Processing: http_access deny purge
2024/07/11 14:09:27| Processing: http_access deny !safeports
2024/07/11 14:09:27| Processing: http_access deny CONNECT !sslports
2024/07/11 14:09:27| Processing: http_access allow localhost
2024/07/11 14:09:27| Processing: quick_abort_min 0 KB
2024/07/11 14:09:27| Processing: quick_abort_max 0 KB
2024/07/11 14:09:27| Processing: quick_abort_pct 95
2024/07/11 14:09:27| Processing: request_body_max_size 0 KB
2024/07/11 14:09:27| Processing: delay_pools 1
2024/07/11 14:09:27| Processing: delay_class 1 2
2024/07/11 14:09:27| Processing: delay_parameters 1 -1/-1 -1/-1
2024/07/11 14:09:27| Processing: delay_initial_bucket_level 100
2024/07/11 14:09:27| Processing: delay_access 1 allow allsrc
2024/07/11 14:09:27| Processing: deny_info TCP_RESET allsrc
2024/07/11 14:09:27| Processing: url_rewrite_program /usr/local/bin/squidGuard -c /usr/local/etc/squidGuard/squidGuard.conf
2024/07/11 14:09:27| Processing: url_rewrite_bypass off
2024/07/11 14:09:27| Processing: url_rewrite_children 32 startup=8 idle=4 concurrency=0
2024/07/11 14:09:27| Processing: http_access deny banned_hosts
2024/07/11 14:09:27| Processing: http_access allow whitelist
2024/07/11 14:09:27| Processing: http_access deny blacklist
2024/07/11 14:09:27| Processing: request_header_access X-GoogApps-Allowed-Domains deny all
2024/07/11 14:09:27| Processing: request_header_add X-GoogApps-Allowed-Domains consumer_accounts
2024/07/11 14:09:27| Processing: acl youtubedst dstdomain -n www.youtube.com m.youtube.com youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com
2024/07/11 14:09:27| Processing: request_header_access YouTube-Restrict deny all
2024/07/11 14:09:27| Processing: request_header_add YouTube-Restrict none youtubedst
2024/07/11 14:09:27| Processing: acl sglog url_regex -i sgr=ACCESSDENIED
2024/07/11 14:09:27| Processing: http_access deny sglog
2024/07/11 14:09:27| Processing: http_access deny !safeports
2024/07/11 14:09:27| Processing: http_access deny CONNECT !sslports
2024/07/11 14:09:27| Processing: http_access allow localhost manager
2024/07/11 14:09:27| Processing: http_access deny manager
2024/07/11 14:09:27| Processing: cachemgr_passwd disable offline_toggle reconfigure shutdown
2024/07/11 14:09:27| Processing: cachemgr_passwd redacted all
2024/07/11 14:09:27| Processing: eui_lookup on
2024/07/11 14:09:27| Processing: acl no_miss url_regex -i gateway\.facebook\.com\/ws\/realtime\?
2024/07/11 14:09:27| Processing: acl no_miss url_regex -i web-chat-e2ee\.facebook\.com\/ws\/chat
2024/07/11 14:09:27| Processing: acl CONNECT method CONNECT
2024/07/11 14:09:27| Processing: acl wuCONNECT dstdomain www.update.microsoft.com
2024/07/11 14:09:27| Processing: acl wuCONNECT dstdomain sls.microsoft.com
2024/07/11 14:09:27| Processing: http_access allow CONNECT wuCONNECT localnet
2024/07/11 14:09:27| Processing: http_access allow CONNECT wuCONNECT localhost
2024/07/11 14:09:27| Processing: http_access allow windowsupdate localnet
2024/07/11 14:09:27| Processing: http_access allow windowsupdate localhost
2024/07/11 14:09:27| Processing: http_access allow HttpAccess localnet
2024/07/11 14:09:27| Processing: http_access allow HttpAccess localhost
2024/07/11 14:09:27| Processing: http_access deny manager
2024/07/11 14:09:27| Processing: http_access deny to_ipv6
2024/07/11 14:09:27| Processing: http_access deny from_ipv6
2024/07/11 14:09:27| Processing: acl BrokenButTrustedServers dstdomain "/usr/local/pkg/dstdom.broken"
2024/07/11 14:09:27| Processing: acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
2024/07/11 14:09:27| Processing: sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
2024/07/11 14:09:27| Processing: sslproxy_cert_error deny all
2024/07/11 14:09:27| Processing: acl splice_only src 192.168.1.8 #Tasha iPhone
2024/07/11 14:09:27| Processing: acl splice_only src 192.168.1.10 #Jon iPhone
2024/07/11 14:09:27| Processing: acl splice_only src 192.168.1.11 #Amazon Fire
2024/07/11 14:09:27| Processing: acl splice_only src 192.168.1.15 #Tasha HP
2024/07/11 14:09:27| Processing: acl splice_only src 192.168.1.16 #iPad
2024/07/11 14:09:27| Processing: acl splice_only_mac arp 
2024/07/11 14:09:27| Processing: acl splice_only_mac arp 
2024/07/11 14:09:27| Processing: acl splice_only_mac arp 
2024/07/11 14:09:27| Processing: acl splice_only_mac arp 
2024/07/11 14:09:27| Processing: acl splice_only_mac arp 
2024/07/11 14:09:27| Processing: acl NoSSLIntercept ssl::server_name_regex -i "/usr/local/pkg/reg.url.nobump"
2024/07/11 14:09:27| Processing: acl NoBumpDNS dstdomain "/usr/local/pkg/dns.nobump"
2024/07/11 14:09:27| Processing: acl markBumped annotate_client bumped=true
2024/07/11 14:09:27| Processing: acl active_use annotate_client active=true
2024/07/11 14:09:27| Processing: acl bump_only src 192.168.1.3 #webtv
2024/07/11 14:09:27| Processing: acl bump_only src 192.168.1.4 #toshiba
2024/07/11 14:09:27| Processing: acl bump_only src 192.168.1.5 #imac
2024/07/11 14:09:27| Processing: acl bump_only src 192.168.1.9 #macbook
2024/07/11 14:09:27| Processing: acl bump_only src 192.168.1.13 #dell
2024/07/11 14:09:27| Processing: acl bump_only_mac arp 
2024/07/11 14:09:27| Processing: acl bump_only_mac arp 
2024/07/11 14:09:27| Processing: acl bump_only_mac arp 
2024/07/11 14:09:27| Processing: acl bump_only_mac arp 
2024/07/11 14:09:27| Processing: acl bump_only_mac arp 
2024/07/11 14:09:27| Processing: sslproxy_cert_sign signTrusted bump_only_mac
2024/07/11 14:09:27| Processing: ssl_bump peek step1
2024/07/11 14:09:27| Processing: miss_access deny no_miss active_use
2024/07/11 14:09:27| Processing: ssl_bump splice https_login active_use
2024/07/11 14:09:27| Processing: ssl_bump splice splice_only_mac splice_only active_use
2024/07/11 14:09:27| Processing: ssl_bump splice NoBumpDNS active_use
2024/07/11 14:09:27| Processing: ssl_bump splice NoSSLIntercept active_use
2024/07/11 14:09:27| Processing: ssl_bump bump bump_only_mac bump_only active_use
2024/07/11 14:09:27| Processing: acl activated note active_use true
2024/07/11 14:09:27| Processing: ssl_bump terminate !activated
2024/07/11 14:09:27| Processing: shutdown_lifetime 1 seconds
2024/07/11 14:09:27| Processing: negative_dns_ttl 5 minutes
2024/07/11 14:09:27| Processing: http_access allow localnet
2024/07/11 14:09:27| Processing: http_access deny allsrc
2024/07/11 14:09:27| WARNING: use of 'override-expire' in 'refresh_pattern' violates HTTP
2024/07/11 14:09:27| WARNING: use of 'override-lastmod' in 'refresh_pattern' violates HTTP
2024/07/11 14:09:27| WARNING: use of 'reload-into-ims' in 'refresh_pattern' violates HTTP
2024/07/11 14:09:27| WARNING: use of 'ignore-reload' in 'refresh_pattern' violates HTTP
2024/07/11 14:09:27| WARNING: use of 'ignore-no-store' in 'refresh_pattern' violates HTTP
2024/07/11 14:09:27| WARNING: use of 'ignore-private' in 'refresh_pattern' violates HTTP
2024/07/11 14:09:27| WARNING: HTTP requires the use of Via
2024/07/11 14:09:27| Requiring client certificates.
2024/07/11 14:09:28| Loaded signing certificate: /CN=internal-ca/C=US/ST=California/L=Roseville/O=Homeuse
2024/07/11 14:09:29| Not requiring any client certificates
2024/07/11 14:09:29| Loaded signing certificate: /CN=internal-ca/C=US/ST=California/L=Roseville/O=Homeuse
2024/07/11 14:09:30| Not requiring any client certificates
2024/07/11 14:09:30| Loaded signing certificate: /CN=internal-ca/C=US/ST=California/L=Roseville/O=Homeuse
2024/07/11 14:09:30| Not requiring any client certificates

> On Jul 11, 2024, at 13:16, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> 
> Lets see ...
> 
> >>> On Jul 11, 2024, at 11:02, Jonathan Lee wrote:
> >>>     Shell Output - squidclient -h 127.0.0.1 -v -U admin -W redacted
> >>>     mgr:info
> >>>
> >>> Request:
> >>> GET http://127.0.0.1:3128/squid-internal-mgr/info HTTP/1.0
> >>> Host: 127.0.0.1:3128
> >>> User-Agent: squidclient/6.6
> >>> Accept: */*
> >>> Authorization: Basic YWRtaW4..REDACTED..Q==
> >>> Connection: close
> 
> 
> On 12/07/24 06:12, Jonathan Lee wrote:
>> http_access allow CONNECT wuCONNECT localnet
>> http_access allow CONNECT wuCONNECT localhost
> 
> 
> ... GET is not CONNECT. Skip the above.
> 
> 
>> http_access allow windowsupdate localnet
>> http_access allow windowsupdate localhost
> 
> 
> ... 127.0.0.1 is not in *.microsoft.com. Skip the above.
> 
> 
>> http_access allow HttpAccess localnet
>> http_access allow HttpAccess localhost
> 
> 
> ... 127.0.0.1 is not listed in /usr/local/pkg/http.access. Skip the above.
> 
> 
>> http_access deny manager
> 
> 
> ... /squid-internal-mgr/ matches.  DENY the request.
> 
> 
> Problem solved.
> 
> What you should do is restore the default security settings which we ship with Squid.
> 
> Place these above your custom http_access lines:
> 
>  http_access deny !Safe_ports
>  http_access deny CONNECT !SSL_ports
>  http_access allow localhost manager
>  http_access deny manager
> 
> 
> see <https://wiki.squid-cache.org/Releases/Squid-5> for the ACL details if you need them too.
> 
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240711/8fdb7590/attachment.htm>

From squid3 at treenet.co.nz  Thu Jul 11 21:28:20 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Jul 2024 09:28:20 +1200
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <LO2P265MB3165D0078E70D946E38DE9AFFEA52@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
References: <LO2P265MB3165D0078E70D946E38DE9AFFEA52@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <1c43deb5-20d0-44fa-ba24-b44a676d436a@treenet.co.nz>

On 12/07/24 03:37, Ben Toms wrote:
> Hi folks,
> 
> We?re looking to leverage squid-cache as an accelerator, but for large 
> content. For example, a local cache of macOS installers so that the 
> internet line isn?t swamped when updating Photoshop etc across devices.
> 
> Below is an example of the conf I?ve been using (and have been going 
> backwards and forwards trying different things):
> 
> https_port 443 accel protocol=HTTPS tls-cert=/usr/local/squid/client.pem 
> tls-key=/usr/local/squid/client.key
> 
> cache_peer public.server.fqdn parent 443 0 no-query originserver 
> no-digest no-netdb-exchange tls login=PASSTHRU name=myAccel
> 

I suggest also adding the option to this cache_peer line:
    forceddomain=public.server.fqdn


> acl our_sites dstdomain local.server.fqdn
> 
> http_access allow our_sites
> 
> cache_peer_access myAccel allow our_sites
> 
> cache_peer_access myAccel deny all
> 
> refresh_pattern -i public.server.fqdn/.* 3600??? 80%???? 14400

Note: you do not need to put ".*" at either end of a regex. It is implicit.


> 
> cache_dir ufs /usr/local/squid/var/cache 100000 16 256
> 
> When I attempt to curl a file from local.server.fqdn, I can see that 
> there has been a request made to public.server.fqdn and that the 
> authentication has been passed through and all is well (it returns a 200 
> code and needs authentication),


That does not make sense. "needs authentication" in HTTP is a 4xx status 
code.

A response cannot be 200 "OK, successful complete" and "needs 
authentication" at the same time.


> but I?m seeing TCP_MISS_ABORTED/502 in 
> /var/log/squid/access.log as per the below:
> 
> 1720711470.297???? 84 192.168.0.156 TCP_MISS_ABORTED/502 3974 GET 
> https://local.server.fqdn/some/file/path 
> <https://local.server.fqdn/some/file/path> - 
> FIRSTUP_PARENT/public.ip.of.public.server text/html
> 
> Seems like the client to squid-cache HTTPS conection is fine, and 
> squid-cache can contact public.server.fqdn.. but nothing is cached.
> 

There is nothing in the above which indicates a problem caching.

There is a client doing unexpected abort - which may (or not) have 
side-effects on storage of the response. But still no problem exactly - 
clients can do what they want.


Cheers
Amos


From squid3 at treenet.co.nz  Thu Jul 11 21:49:35 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Jul 2024 09:49:35 +1200
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <3A753A42-FAEE-42F1-87D7-93EB45EF2D9E@gmail.com>
References: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
 <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
 <F19657D2-D16C-4D37-8EDE-A0F7D2A5A64E@gmail.com>
 <AC4A93C3-F77B-414A-A408-39391584B388@gmail.com>
 <D97540C8-E366-4753-BB39-053208E373CB@gmail.com>
 <FDB03E03-1FEE-44A7-A427-8CC3435EFB91@gmail.com>
 <ec61944c-6420-41b7-8737-05230761eac2@treenet.co.nz>
 <3A753A42-FAEE-42F1-87D7-93EB45EF2D9E@gmail.com>
Message-ID: <706d830e-f42e-4585-b5a3-79bd3fe5f831@treenet.co.nz>

Oh, I see the problem:

   http_port 127.0.0.1:3128 intercept ...

  (which also means you lack a firewall rule preventing external 
software like squidclient from sending traffic directly to your 
intercept port.)


Please **do not** use port 3128 to receive intercepted traffic.


I recommend changing your main port to this:

    http_port 3128 ssl-bump ....

and receiving the intercepted traffic on:

   http_port 3129 intercept ssl-bump ...


and check your firewall has all the rules listed at 
<https://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect>.
One to note in particular is the "mangle" table rule.


Cheers
Amos


From rousskov at measurement-factory.com  Thu Jul 11 22:10:46 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 11 Jul 2024 18:10:46 -0400
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <60d138f7-0c05-48d0-8d9d-959526e40499@treenet.co.nz>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
 <60d138f7-0c05-48d0-8d9d-959526e40499@treenet.co.nz>
Message-ID: <5eba3547-b303-402f-93ec-507a91690e0d@measurement-factory.com>

On 2024-07-11 17:03, Amos Jeffries wrote:
> On 11/07/24 00:49, Alex Rousskov wrote:
>> On 2024-07-09 18:25, Fiehe, Christoph wrote:
>>
>>> I hope that somebody has an idea, what I am doing wrong. 
>>
>> AFAICT from the debugging log, it is your parent proxy that returns an 
>> ERR_SECURE_CONNECT_FAIL error page in response to a seemingly valid 
>> "HEAD https://..." request. Can you ask their admin to investigate? 
>> You may also recommend that they upgrade from Squid v4 that has many 
>> known security vulnerabiities.
>>
>> If parent is uncooperative, you can try to reproduce the problem by 
>> temporary installing your own parent Squid instance and configuring 
>> your child Squid to use that instead.
>>
>> HTH,
>>
>> Alex.
>> P.S. Unlike Amos, I do not see serious conceptual problems with 
>> rewriting request target scheme (as a temporary compatibility 
>> measure). It may not always work, for various reasons, but it does not 
>> necessarily make things worse (and may make things better).


> To which I refer you to:

None of the weaknesses below are applicable to request target scheme 
rewriting (assuming both proxies in question are implemented/configured 
correctly, of course). Specific non-applicability reasons are given 
below for each weakness URL:

> https://cwe.mitre.org/data/definitions/311.html

The above "The product does not encrypt sensitive or critical 
information before storage or transmission" case is not applicable: All 
connections can be encrypted as needed after the scheme rewrite.


> https://cwe.mitre.org/data/definitions/312.html

The above "The product stores sensitive information in cleartext within 
a resource that might be accessible to another control sphere." case is 
not applicable: Squid does not store information in such an accessible 
resource.


> https://cwe.mitre.org/data/definitions/319.html

The above "The product transmits sensitive or security-critical data in 
cleartext in a communication channel that can be sniffed by unauthorized 
actors." case is not applicable: All connections can be encrypted as 
needed after the scheme rewrite.

Alex.



From jonathanlee571 at gmail.com  Thu Jul 11 23:50:11 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 11 Jul 2024 16:50:11 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <706d830e-f42e-4585-b5a3-79bd3fe5f831@treenet.co.nz>
References: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
 <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
 <F19657D2-D16C-4D37-8EDE-A0F7D2A5A64E@gmail.com>
 <AC4A93C3-F77B-414A-A408-39391584B388@gmail.com>
 <D97540C8-E366-4753-BB39-053208E373CB@gmail.com>
 <FDB03E03-1FEE-44A7-A427-8CC3435EFB91@gmail.com>
 <ec61944c-6420-41b7-8737-05230761eac2@treenet.co.nz>
 <3A753A42-FAEE-42F1-87D7-93EB45EF2D9E@gmail.com>
 <706d830e-f42e-4585-b5a3-79bd3fe5f831@treenet.co.nz>
Message-ID: <5CEDCC1C-0840-4DD5-B45A-8DB67635E6B3@gmail.com>

> I recommend changing your main port to this:
> 
>   http_port 3128 ssl-bump ....

This is set to this when it processes

http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE

> and receiving the intercepted traffic on:
> 
>  http_port 3129 intercept ssl-bump ?

Do you mean https?

https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
Https uses that port 3129

What should I adapt 

http_port 
https_port?



> On Jul 11, 2024, at 14:49, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> Oh, I see the problem:
> 
>  http_port 127.0.0.1:3128 intercept ...
> 
> (which also means you lack a firewall rule preventing external software like squidclient from sending traffic directly to your intercept port.)
> 
> 
> Please **do not** use port 3128 to receive intercepted traffic.
> 
> 
> I recommend changing your main port to this:
> 
>   http_port 3128 ssl-bump ....
> 
> and receiving the intercepted traffic on:
> 
>  http_port 3129 intercept ssl-bump ...
> 
> 
> and check your firewall has all the rules listed at <https://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect>.
> One to note in particular is the "mangle" table rule.
> 
> 
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240711/c50b1c78/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jul 11 23:54:29 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 11 Jul 2024 16:54:29 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <706d830e-f42e-4585-b5a3-79bd3fe5f831@treenet.co.nz>
References: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
 <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
 <F19657D2-D16C-4D37-8EDE-A0F7D2A5A64E@gmail.com>
 <AC4A93C3-F77B-414A-A408-39391584B388@gmail.com>
 <D97540C8-E366-4753-BB39-053208E373CB@gmail.com>
 <FDB03E03-1FEE-44A7-A427-8CC3435EFB91@gmail.com>
 <ec61944c-6420-41b7-8737-05230761eac2@treenet.co.nz>
 <3A753A42-FAEE-42F1-87D7-93EB45EF2D9E@gmail.com>
 <706d830e-f42e-4585-b5a3-79bd3fe5f831@treenet.co.nz>
Message-ID: <F35F1E08-97CD-4FA7-B0B6-2AB46B3E23DE@gmail.com>

Here is how it is set

http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE

http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE

https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE

Should be???

http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE

http_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE

https_port 127.0.0.1:3129? intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE


> On Jul 11, 2024, at 14:49, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> Oh, I see the problem:
> 
>  http_port 127.0.0.1:3128 intercept ...
> 
> (which also means you lack a firewall rule preventing external software like squidclient from sending traffic directly to your intercept port.)
> 
> 
> Please **do not** use port 3128 to receive intercepted traffic.
> 
> 
> I recommend changing your main port to this:
> 
>   http_port 3128 ssl-bump ....
> 
> and receiving the intercepted traffic on:
> 
>  http_port 3129 intercept ssl-bump ...
> 
> 
> and check your firewall has all the rules listed at <https://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect>.
> One to note in particular is the "mangle" table rule.
> 
> 
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240711/4de9dbae/attachment.htm>

From jonathanlee571 at gmail.com  Fri Jul 12 05:43:33 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 11 Jul 2024 22:43:33 -0700
Subject: [squid-users] Squid 6.6 error clientProcessHit: Vary object
 loop!
In-Reply-To: <150ee779-d0b8-42e2-a44d-55700ef81b2c@treenet.co.nz>
References: <150ee779-d0b8-42e2-a44d-55700ef81b2c@treenet.co.nz>
Message-ID: <153AB5F4-859B-4748-A999-03E0DB294CE2@gmail.com>

Thanks for the reply.

Proxy technology amazes me as I am a computer science student. I feel generation 2 proxy technology is key to stopping invasive containers within a cybersecurity perspective. Again to spot them you need to cache them and scan for fingerprints, thus my fascination with Squid. 

Thanks again 
Sent from my iPhone

> On Jul 11, 2024, at 22:02, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> ?On 12/07/24 06:43, Jonathan Lee wrote:
>> What is Vary Object loop??
> 
> In HTTP URLs can point at a set or "variants" of a resource.
> 
> Squid "Vary Object" is an entry in the cache that is used to represent these types of resource.
> When the URL-only is looked up, the "Vary Object" is found and tells Squid to perform a second lookup appending certain details to the hash key to find the actual object that client needs.
> 
> A "Vary Object loop" is when this second lookup finds an object which is not the desired variant of that original URL.
> 
> 
> You can see this in your first message ...
> 
> 
> >> 10.07.2024 09:56:30    clientProcessHit: Vary object loop!
> >> 10.07.2024 09:56:30    varyEvaluateMatch: Oops. Not a Vary match on
> >> second attempt,
> 
> Original request came in for "https%3A%2F%2Fstatic.foxnews.com"
> 
> That URL had a cached "Vary Object" saying there were different responses to provide depending on the Accept-Encoding header:
> 
> Squdi performed a second lookup for:
> 
> >> 'origin="https%3A%2F%2Fstatic.foxnews.com", accept-encoding="gzip,%20deflate,%20br,%20zstd"'
> 
> 
> ... which found a cache entry for this URL:
> 
> >> 'https://zagent20.h-cdn.com/cmd/get_thumb_info?customer=foxnews&ver=1.165.67&amp;url=https%3A%2F%2F247preview.foxnews.com%2Fhls%2Flive%2F2020027%2Ffncv3preview%2Findex.m3u8'
> 
> 
> which is not the same URL.
> 
> 
> 
>> Does that  mean clear my cache?
> 
> No. But yes.
> 
> A quick check of the URLs from your log message with the tool at <https://redbot.org/?uri=https://static.foxnews.com/static/orion/styles/css/fox-news/article-new.rs.css>
> 
> We can see that:
> 
> "
>    The resource doesn't send Vary consistently.
>    The ETag doesn't change between negotiated representations.
> "
> 
> 
> You can ignore these log messages.
> 
> Or, you can configure Squid not to cache content from this server. If you do this, then clearing the cache would stop the log entries continuing.
> 
> 
>> Or is that something I am missing has anyone else seen this?
> 
> That origin server is broken. So likely everyone is seeing the same problem with that website.
> 
> 
>> 11.07.2024 11:36:49    clientProcessHit: Vary object loop!
>> 11.07.2024 11:36:49    varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'https://static.foxnews.com/static/orion/styles/css/fox-news/article-new.rs.css9; 'accept-encoding="gzip,%20deflate,%20br,%20zstd"'
>> 11.07.2024 11:36:49    clientProcessHit: Vary object loop!
>> 11.07.2024 11:36:49    varyEvaluateMatch: Oops. Not a Vary match on second attempt, 'https://static.foxnews.com/static/strike/ver/foxnews/loader.global.js' 'accept-encoding="gzip,%20deflate,%20br,%20zstd"'
>> 31.12.1969 16:00:00    
> <snip>
> 
> 
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From ben at macmule.com  Fri Jul 12 09:29:14 2024
From: ben at macmule.com (Ben Toms)
Date: Fri, 12 Jul 2024 09:29:14 +0000
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
Message-ID: <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>

Hi Amos,

I made the changes suggested, biut still getting TCP_MISS_ABORTED/502.

The test I?m performing is via a simple curl:

curl https://local.server.fqdn/some/file/path -H "Authorization: Basic base64_auth" -o ~/Downloads/test

The Apache logs for the parent (public.server.fqdn), show:

[12/Jul/2024:10:16:09 +0100] "GET /some/file/path HTTP/1.1" 200 10465 "-" "curl/8.7.1"

So, Apache on the parent is responding with a 200.. and if I mess around with the curl commands base64_auth I get 401?s as expected in the parents Apache logs.

However, squids access.log still shows:

1720775769.417     49 192.168.0.156 TCP_MISS_ABORTED/502 3974 GET https://local.server.fqdn/some/file/path - FIRSTUP_PARENT/public.ip.of.public.server text/html

Squid.conf is now:

https_port 443 accel protocol=HTTPS tls-cert=/usr/local/squid/client.pem tls-key=/usr/local/squid/client.key
cache_peer public.server.fqdn parent 443 0 no-query originserver no-digest no-netdb-exchange tls login=PASSTHRU name=myAccel forceddomain=uk-dist-a.datajar.mobi
acl our_sites dstdomain local.server.fqdn
http_access allow our_sites
cache_peer_access myAccel allow our_sites
cache_peer_access myAccel deny all
refresh_pattern -i public.server.fqdn/* 3600    80%     14400
cache_dir ufs /usr/local/squid/var/cache 100000 16 256

The file I?m attempting to cache with the above curl command is 6.5kb only.. have tried others to no avail.

It seems like squid doesn?t want to cache, and it?s not advising the client to wait as it caches.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/fcf21602/attachment.htm>

From paolo.prinx at gmail.com  Fri Jul 12 10:58:08 2024
From: paolo.prinx at gmail.com (paolo.prinx at gmail.com)
Date: Fri, 12 Jul 2024 10:58:08 +0000 (UTC)
Subject: [squid-users] Socket handle leak?
References: <1026668535.2215882.1720781888145.ref@mail.yahoo.com>
Message-ID: <1026668535.2215882.1720781888145@mail.yahoo.com>

Hello,? ?apologies in advance for the silly question.
We are having some stability issues with our squid farms after a recent upgrade from Centos/Squid 3.5.x to Ubuntu/Squid 5.7/6.9. I wonder if anyone here has seen something similar, and might have some suggestion about what we are obviously missing?

In short, after running for a certain period the servers run out of file descriptors. We see a slowly growing number of TCP or TCPv6 socket handles, that eventually hits the configured maximum. The handles do not get released until after squid is restarted (-k restart)

It is somewhat similar to what reported under?https://access.redhat.com/solutions/3362211?. They state that??   
   - If an application fails to?close()?it's socket descriptors and continues to allocate new sockets then it can use up all the system memory on TCP(v6) slab objects.
   - Note some of these sockets will not show up in?/proc/net/sockstat(6). Sockets that still have a file descriptor but are in the?TCP_CLOSE?state will consume a slab object. But will not be accounted for in?/proc/net/sockstat(6)?or "ss" or "netstat".
   - It can be determined whether this is an application sockets leak, by stopping the application processes that are consuming sockets. If the slab objects in?/proc/slabinfo?are freed then the application is responsible. As that means that destructor routines have found open file descriptors to sockets in the process.

"This is most likely to be a case of the application not handling error conditions correctly and not calling?close()?to free the FD and socket."


For example, on a server with squid 5.7, unmodified package:

list of open files;
lsof |wc -l56963
 
of which 35K in TCPv6:
lsof |grep proxy |grep TCPv6 |wc -l
????35301
under /proc I see less objects
? ? cat? /proc/net/tcp6 |wc -l
????3095
but the number of objects in the slabs is high????cat /proc/slabinfo |grep TCPv6 ????MPTCPv6? ? ? ? ? ? ? ? 0? ? ? 0? ?2048? ?16? ? 8 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0????tw_sock_TCPv6? ? ? ?1155? ?1155? ? 248? ?33? ? 2 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ?35? ? ?35? ? ? 0????request_sock_TCPv6? ? ? 0? ? ? 0? ? 304? ?26? ? 2 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0????TCPv6? ? ? ? ? ? ? 38519? 38519? ?2432? ?13? ? 8 : tunables? ? 0? ? 0? ? 0 : slabdata? ?2963? ?2963? ? ? 0
I have 35K of lines like this????lsof |grep proxy |grep TCPv6 |more????squid? ? ? ? 1049? ? ? ? ? ? ? proxy? ?13u? ? ?sock? ? ? ? ? ? ? ? 0,8? ? ? ? 0t0? ? 5428173 protocol: TCPv6????squid? ? ? ? 1049? ? ? ? ? ? ? proxy? ?14u? ? ?sock? ? ? ? ? ? ? ? 0,8? ? ? ? 0t0? ?27941608 protocol: TCPv6????squid? ? ? ? 1049? ? ? ? ? ? ? proxy? ?24u? ? ?sock? ? ? ? ? ? ? ? 0,8? ? ? ? 0t0? ?45124047 protocol: TCPv6????squid? ? ? ? 1049? ? ? ? ? ? ? proxy? ?25u? ? ?sock? ? ? ? ? ? ? ? 0,8? ? ? ? 0t0? ?50689821 protocol: TCPv6...

We thought maybe this is a weird IPv6 thing, as we only route IPv4, so we compiled a more recent version of squid with no v6 support. The thing just moved to TCP4..
lsof |wc -l120313
cat /proc/slabinfo |grep TCPMPTCPv6? ? ? ? ? ? ? ? 0? ? ? 0? ?2048? ?16? ? 8 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0tw_sock_TCPv6? ? ? ? ? 0? ? ? 0? ? 248? ?33? ? 2 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0request_sock_TCPv6? ? ? 0? ? ? 0? ? 304? ?26? ? 2 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0TCPv6? ? ? ? ? ? ? ? 208? ? 208? ?2432? ?13? ? 8 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ?16? ? ?16? ? ? 0MPTCP? ? ? ? ? ? ? ? ? 0? ? ? 0? ?1856? ?17? ? 8 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0tw_sock_TCP? ? ? ? ?5577? ?5577? ? 248? ?33? ? 2 : tunables? ? 0? ? 0? ? 0 : slabdata? ? 169? ? 169? ? ? 0request_sock_TCP? ? 1898? ?2002? ? 304? ?26? ? 2 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ?77? ? ?77? ? ? 0TCP? ? ? ? ? ? ? ?102452 113274? ?2240? ?14? ? 8 : tunables? ? 0? ? 0? ? 0 : slabdata? ?8091? ?8091? ? ? 0

cat /proc/net/tcp |wc -l255
After restarting squid the slab objects are released and the open file descriptors drop to a reasonable value. This further suggests it is squid hanging on to these FDs.

lsof |grep proxy |wc -l1221

Any suggestion? I guess it's something blatantly obvious, but it's a couple of days we look at this and we're not going anywhere...
Thanks again

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/185d00e9/attachment.htm>

From ben at macmule.com  Fri Jul 12 11:07:47 2024
From: ben at macmule.com (Ben Toms)
Date: Fri, 12 Jul 2024 11:07:47 +0000
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <LO2P265MB3165DBB8AF9A1068155EE38EFEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>

To test, I changed the parent url to my blog.. and was able to download an item there via squid-cache.. so the issue seems to be when downloading from a parent which requires authentication.


Regards,
Ben.

From: Ben Toms <ben at macmule.com>
Date: Friday, 12 July 2024 at 10:29
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: TCP_MISS_ABORTED/502
Hi Amos,

I made the changes suggested, biut still getting TCP_MISS_ABORTED/502.

The test I?m performing is via a simple curl:

curl https://local.server.fqdn/some/file/path -H "Authorization: Basic base64_auth" -o ~/Downloads/test

The Apache logs for the parent (public.server.fqdn), show:

[12/Jul/2024:10:16:09 +0100] "GET /some/file/path HTTP/1.1" 200 10465 "-" "curl/8.7.1"

So, Apache on the parent is responding with a 200.. and if I mess around with the curl commands base64_auth I get 401?s as expected in the parents Apache logs.

However, squids access.log still shows:

1720775769.417     49 192.168.0.156 TCP_MISS_ABORTED/502 3974 GET https://local.server.fqdn/some/file/path - FIRSTUP_PARENT/public.ip.of.public.server text/html

Squid.conf is now:

https_port 443 accel protocol=HTTPS tls-cert=/usr/local/squid/client.pem tls-key=/usr/local/squid/client.key
cache_peer public.server.fqdn parent 443 0 no-query originserver no-digest no-netdb-exchange tls login=PASSTHRU name=myAccel forceddomain=uk-dist-a.datajar.mobi
acl our_sites dstdomain local.server.fqdn
http_access allow our_sites
cache_peer_access myAccel allow our_sites
cache_peer_access myAccel deny all
refresh_pattern -i public.server.fqdn/* 3600    80%     14400
cache_dir ufs /usr/local/squid/var/cache 100000 16 256

The file I?m attempting to cache with the above curl command is 6.5kb only.. have tried others to no avail.

It seems like squid doesn?t want to cache, and it?s not advising the client to wait as it caches.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/5f027e2d/attachment.htm>

From squid3 at treenet.co.nz  Fri Jul 12 11:57:12 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 12 Jul 2024 23:57:12 +1200
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <5CEDCC1C-0840-4DD5-B45A-8DB67635E6B3@gmail.com>
References: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
 <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
 <F19657D2-D16C-4D37-8EDE-A0F7D2A5A64E@gmail.com>
 <AC4A93C3-F77B-414A-A408-39391584B388@gmail.com>
 <D97540C8-E366-4753-BB39-053208E373CB@gmail.com>
 <FDB03E03-1FEE-44A7-A427-8CC3435EFB91@gmail.com>
 <ec61944c-6420-41b7-8737-05230761eac2@treenet.co.nz>
 <3A753A42-FAEE-42F1-87D7-93EB45EF2D9E@gmail.com>
 <706d830e-f42e-4585-b5a3-79bd3fe5f831@treenet.co.nz>
 <5CEDCC1C-0840-4DD5-B45A-8DB67635E6B3@gmail.com>
Message-ID: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>

On 12/07/24 11:50, Jonathan Lee wrote:
>> I recommend changing your main port to this:
>>
>> ??http_port 3128 ssl-bump ....
> 
> This is set to this when it processes
> 
> http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
> 

The key thing here was the removal of the IP address. So that Squid 
received both the 192.168.*.* and the 127.0.0.* traffic without needing 
separate http_port lines.



> 
>> and receiving the intercepted traffic on:
>>
>> ?http_port 3129 intercept ssl-bump ?
> 
> Do you mean https?
> 

Sorry. I missed that you had an https_port using 3129 already.



> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
> 
> Https uses that port 3129
> 
> What should I adapt
> 
> http_port
> https_port?
> 

Both.

FYI, there are two issues:

1) listening on IP 127.0.0.1. Inside the OS there are different devices 
for localhost (lo) and WAN (eg. eth0). NAT is problematic already 
without introducing any tricky behaviours from bridging those "private" 
(lo) and "public" WAN devices.

The simplest solution is just not to put any IP address on the 
squid.conf *port line(s) with intercept options. The OS will select one 
appropriate for whatever device and tell Squid on a per-connection basis.

The more difficult way is to put one of the machines "global" (WAN or 
LAN) IP addresses. In your case 192.168.1.1. With most connections being 
from the LAN that minimizes the possible problems.


2) listening on a well-known proxy port 3128 for intercepted traffic.

There is malware in existence that scans for at least port 3128 (likely 
1080, 8080 etc common proxy ports) being used by proxies like yours and 
abuses them. As a result at least one popular antivirus network scanner 
(from Trend) does the same scan to detect insecure proxies.

The worst thing about this situation is that the NAT very effectively 
hides the malware. So it is extremely hard to see whether it is 
happening to you.


I am not sure what UI you are using to show those firewall rules in your 
other email. However the one that had ALLOW for the port range 3128-3129 
worries me. AFAIK that should only be for 3128 and a separate rule 
somewhere else to drop the intercepted port 3129 traffic pre-NAT.


HTH
Amos


From yvain.payen at tessi.fr  Fri Jul 12 12:05:11 2024
From: yvain.payen at tessi.fr (Yvain PAYEN)
Date: Fri, 12 Jul 2024 12:05:11 +0000
Subject: [squid-users] Socket handle leak?
In-Reply-To: <1026668535.2215882.1720781888145@mail.yahoo.com>
References: <1026668535.2215882.1720781888145.ref@mail.yahoo.com>
 <1026668535.2215882.1720781888145@mail.yahoo.com>
Message-ID: <DB9PR07MB98095EDADCE2A6EB11A8C9519CA62@DB9PR07MB9809.eurprd07.prod.outlook.com>

Hi,

I my setup (also ubuntu) I have made these changes :

root at proxy: # cat /etc/security/limits.d/squid.conf
squid        soft    nofile  64000
squid        hard    nofile  65500

root at proxy: # cat /etc/squid/squid.conf | grep max_file
max_filedesc 64000

This force the system limits for squid process and tell squid how much FD it can consume.

Regards,

Yvain PAYEN

De : squid-users <squid-users-bounces at lists.squid-cache.org> De la part de paolo.prinx at gmail.com
Envoy? : vendredi 12 juillet 2024 12:58
? : squid-users at lists.squid-cache.org
Objet : [squid-users] Socket handle leak?

? FR : Ce message provient de l'ext?rieur de l'organisation. N'ouvrez pas de liens ou de pi?ces jointes ? moins que vous ne sachiez que le contenu est fiable.  ?

Hello,
   apologies in advance for the silly question.

We are having some stability issues with our squid farms after a recent upgrade from Centos/Squid 3.5.x to Ubuntu/Squid 5.7/6.9. I wonder if anyone here has seen something similar, and might have some suggestion about what we are obviously missing?


In short, after running for a certain period the servers run out of file descriptors. We see a slowly growing number of TCP or TCPv6 socket handles, that eventually hits the configured maximum. The handles do not get released until after squid is restarted (-k restart)


It is somewhat similar to what reported under https://access.redhat.com/solutions/3362211 . They state that

  *   If an application fails to close() it's socket descriptors and continues to allocate new sockets then it can use up all the system memory on TCP(v6) slab objects.
  *   Note some of these sockets will not show up in /proc/net/sockstat(6). Sockets that still have a file descriptor but are in the TCP_CLOSE state will consume a slab object. But will not be accounted for in /proc/net/sockstat(6) or "ss" or "netstat".
  *   It can be determined whether this is an application sockets leak, by stopping the application processes that are consuming sockets. If the slab objects in /proc/slabinfo are freed then the application is responsible. As that means that destructor routines have found open file descriptors to sockets in the process.

"This is most likely to be a case of the application not handling error conditions correctly and not calling close() to free the FD and socket."


For example, on a server with squid 5.7, unmodified package:

list of open files;
lsof |wc -l
56963

of which 35K in TCPv6:
lsof |grep proxy |grep TCPv6 |wc -l
    35301

under /proc I see less objects
    cat  /proc/net/tcp6 |wc -l
    3095

but the number of objects in the slabs is high
    cat /proc/slabinfo |grep TCPv6
    MPTCPv6                0      0   2048   16    8 : tunables    0    0    0 : slabdata      0      0      0
    tw_sock_TCPv6       1155   1155    248   33    2 : tunables    0    0    0 : slabdata     35     35      0
    request_sock_TCPv6      0      0    304   26    2 : tunables    0    0    0 : slabdata      0      0      0
    TCPv6              38519  38519   2432   13    8 : tunables    0    0    0 : slabdata   2963   2963      0

I have 35K of lines like this
    lsof |grep proxy |grep TCPv6 |more
    squid        1049              proxy   13u     sock                0,8        0t0    5428173 protocol: TCPv6
    squid        1049              proxy   14u     sock                0,8        0t0   27941608 protocol: TCPv6
    squid        1049              proxy   24u     sock                0,8        0t0   45124047 protocol: TCPv6
    squid        1049              proxy   25u     sock                0,8        0t0   50689821 protocol: TCPv6
...


We thought maybe this is a weird IPv6 thing, as we only route IPv4, so we compiled a more recent version of squid with no v6 support. The thing just moved to TCP4..

lsof |wc -l
120313

cat /proc/slabinfo |grep TCP
MPTCPv6                0      0   2048   16    8 : tunables    0    0    0 : slabdata      0      0      0
tw_sock_TCPv6          0      0    248   33    2 : tunables    0    0    0 : slabdata      0      0      0
request_sock_TCPv6      0      0    304   26    2 : tunables    0    0    0 : slabdata      0      0      0
TCPv6                208    208   2432   13    8 : tunables    0    0    0 : slabdata     16     16      0
MPTCP                  0      0   1856   17    8 : tunables    0    0    0 : slabdata      0      0      0
tw_sock_TCP         5577   5577    248   33    2 : tunables    0    0    0 : slabdata    169    169      0
request_sock_TCP    1898   2002    304   26    2 : tunables    0    0    0 : slabdata     77     77      0
TCP               102452 113274   2240   14    8 : tunables    0    0    0 : slabdata   8091   8091      0


cat /proc/net/tcp |wc -l
255

After restarting squid the slab objects are released and the open file descriptors drop to a reasonable value. This further suggests it is squid hanging on to these FDs.
lsof |grep proxy |wc -l
1221


Any suggestion? I guess it's something blatantly obvious, but it's a couple of days we look at this and we're not going anywhere...

Thanks again


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/7c3f1e7d/attachment.htm>

From ben at macmule.com  Fri Jul 12 12:06:47 2024
From: ben at macmule.com (Ben Toms)
Date: Fri, 12 Jul 2024 12:06:47 +0000
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <LO2P265MB3165DBB8AF9A1068155EE38EFEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165DBB8AF9A1068155EE38EFEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <LO2P265MB316510765BD02C033497EC99FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>

Seems that my issue is similar to - https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication

Regards,
Ben.

From: Ben Toms <ben at macmule.com>
Date: Friday, 12 July 2024 at 12:07
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: TCP_MISS_ABORTED/502
To test, I changed the parent url to my blog.. and was able to download an item there via squid-cache.. so the issue seems to be when downloading from a parent which requires authentication.


Regards,
Ben.

From: Ben Toms <ben at macmule.com>
Date: Friday, 12 July 2024 at 10:29
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: TCP_MISS_ABORTED/502
Hi Amos,

I made the changes suggested, biut still getting TCP_MISS_ABORTED/502.

The test I?m performing is via a simple curl:

curl https://local.server.fqdn/some/file/path -H "Authorization: Basic base64_auth" -o ~/Downloads/test

The Apache logs for the parent (public.server.fqdn), show:

[12/Jul/2024:10:16:09 +0100] "GET /some/file/path HTTP/1.1" 200 10465 "-" "curl/8.7.1"

So, Apache on the parent is responding with a 200.. and if I mess around with the curl commands base64_auth I get 401?s as expected in the parents Apache logs.

However, squids access.log still shows:

1720775769.417     49 192.168.0.156 TCP_MISS_ABORTED/502 3974 GET https://local.server.fqdn/some/file/path - FIRSTUP_PARENT/public.ip.of.public.server text/html

Squid.conf is now:

https_port 443 accel protocol=HTTPS tls-cert=/usr/local/squid/client.pem tls-key=/usr/local/squid/client.key
cache_peer public.server.fqdn parent 443 0 no-query originserver no-digest no-netdb-exchange tls login=PASSTHRU name=myAccel forceddomain=uk-dist-a.datajar.mobi
acl our_sites dstdomain local.server.fqdn
http_access allow our_sites
cache_peer_access myAccel allow our_sites
cache_peer_access myAccel deny all
refresh_pattern -i public.server.fqdn/* 3600    80%     14400
cache_dir ufs /usr/local/squid/var/cache 100000 16 256

The file I?m attempting to cache with the above curl command is 6.5kb only.. have tried others to no avail.

It seems like squid doesn?t want to cache, and it?s not advising the client to wait as it caches.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/26d53b0d/attachment.htm>

From paolo.prinx at gmail.com  Fri Jul 12 13:04:32 2024
From: paolo.prinx at gmail.com (Paolo Prinsecchi)
Date: Fri, 12 Jul 2024 13:04:32 +0000 (UTC)
Subject: [squid-users] Socket handle leak?
In-Reply-To: <DB9PR07MB98095EDADCE2A6EB11A8C9519CA62@DB9PR07MB9809.eurprd07.prod.outlook.com>
References: <1026668535.2215882.1720781888145.ref@mail.yahoo.com>
 <1026668535.2215882.1720781888145@mail.yahoo.com>
 <DB9PR07MB98095EDADCE2A6EB11A8C9519CA62@DB9PR07MB9809.eurprd07.prod.outlook.com>
Message-ID: <782252282.537183.1720789472761@mail.yahoo.com>

Thanks. We have limits set?at 100K, squid can easily reach that. The problem is that the number of FD in use?keeps increasing. A workaround is to restart squid every time it goes over a certain value,?but it?s not really a solution.?In the same situation, with centos and squid 3.5, we seldom went over 20k FD in use.?
Thanks for your reply.?

Panem et circenses

On Friday, July 12, 2024, 7:05 PM, Yvain PAYEN <yvain.payen at tessi.fr> wrote:

#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 p.yiv4238416288MsoNormal, #yiv4238416288 li.yiv4238416288MsoNormal, #yiv4238416288 div.yiv4238416288MsoNormal {margin:0cm;font-size:11.0pt;font-family:sans-serif;}#yiv4238416288 a:link, #yiv4238416288 span.yiv4238416288MsoHyperlink {color:blue;text-decoration:underline;}#yiv4238416288 code {}#yiv4238416288 span.yiv4238416288EmailStyle19 {font-family:sans-serif;color:windowtext;}#yiv4238416288 .yiv4238416288MsoChpDefault {font-size:10.0pt;}#yiv4238416288 filtered {}#yiv4238416288 div.yiv4238416288WordSection1 {}#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 filtered {}#yiv4238416288 ol {margin-bottom:0cm;}#yiv4238416288 ul {margin-bottom:0cm;}
Hi,
 
 ?
 
I my setup (also ubuntu) I have made these changes :
 
 ?
 
root at proxy: # cat /etc/security/limits.d/squid.conf
 
squid??????? soft??? nofile? 64000
 
squid??????? hard??? nofile? 65500
 
 ?
 
root at proxy: # cat /etc/squid/squid.conf | grep max_file
 
max_filedesc 64000
 
 ?
 
This force the system limits for squid process and tell squid how much FD it can consume.
 
 ?
 
Regards,
 
 ?
 
Yvain PAYEN
 
 ?
 
De?: squid-users <squid-users-bounces at lists.squid-cache.org>De la part de paolo.prinx at gmail.com
Envoy??: vendredi 12 juillet 2024 12:58
??: squid-users at lists.squid-cache.org
Objet?: [squid-users] Socket handle leak?
 
 ?
 
? FR : Ce message provient de l'ext?rieur de l'organisation. N'ouvrez pas de liens ou de pi?ces jointes ? moins que vous ne sachiez que le contenu est fiable. ??

 ?
 
Hello,
 
? ?apologies in advance for the silly question.
 
 ?
 
We are having some stability issues with our squid farms after a recent upgrade from Centos/Squid 3.5.x to Ubuntu/Squid 5.7/6.9. I wonder if anyone here has seen something similar, and might have some suggestion about what we are obviously missing?
 
 ?
 
 ?
 
In short, after running for a certain period the servers run out of file descriptors. We see a slowly growing number of TCP or TCPv6 socket handles, that eventually hits the configured maximum. The handles do not get released until after squid is restarted (-k restart)
 
 ?
 
 ?
 
It is somewhat similar to what reported under?https://access.redhat.com/solutions/3362211?. They state that??
    
   - If an application fails to?close()?it's socket descriptors and continues to allocate new sockets then it can use up all the system memory on TCP(v6) slab objects.
   - Note some of these sockets will not show up in?/proc/net/sockstat(6). Sockets that still have a file descriptor but are in the?TCP_CLOSE?state will consume a slab object. But will not be accounted for in?/proc/net/sockstat(6)?or "ss" or "netstat".
   - It can be determined whether this is an application sockets leak, by stopping the application processes that are consuming sockets. If the slab objects in?/proc/slabinfo?are freed then the application is responsible. As that means that destructor routines have found open file descriptors to sockets in the process.
 
 ?
 
"This is most likely to be a case of the application not handling error conditions correctly and not calling?close()?to free the FD and socket."
 
 ?
 
 ?
 
For example, on a server with squid 5.7, unmodified package:
 
 ?
 
list of open files;
 

lsof |wc -l
 
56963
 

 ?
 
of which 35K in TCPv6:
 

lsof |grep proxy |grep TCPv6 |wc -l
 

????35301
 
 ?
 
under /proc I see less objects
? ? cat? /proc/net/tcp6 |wc -l
 
????3095
 
 ?
 
but the number of objects in the slabs is high
 
????cat /proc/slabinfo |grep TCPv6
 
????MPTCPv6? ? ? ? ? ? ? ? 0? ? ? 0? ?2048? ?16? ? 8 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0
 
????tw_sock_TCPv6? ? ? ?1155? ?1155? ? 248? ?33? ? 2 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ?35? ? ?35? ? ? 0
 
????request_sock_TCPv6? ? ? 0? ? ? 0? ? 304? ?26? ? 2 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0
 
????TCPv6? ? ? ? ? ? ?38519? 38519? ?2432? ?13? ? 8 : tunables? ? 0? ? 0? ? 0 : slabdata? ?2963? ?2963? ? ? 0
 
 ?
 
I have 35K of lines like this
 
????lsof |grep proxy |grep TCPv6 |more
 
????squid? ? ? ? 1049? ? ? ? ? ? ? proxy? ?13u? ? ?sock? ? ? ? ? ? ? ? 0,8? ? ? ? 0t0? ? 5428173 protocol: TCPv6
 
????squid? ? ? ? 1049? ? ? ? ? ? ? proxy? ?14u? ? ?sock? ? ? ? ? ? ? ? 0,8? ? ? ? 0t0? ?27941608 protocol: TCPv6
 
????squid? ? ? ? 1049? ? ? ? ? ? ? proxy? ?24u? ? ?sock? ? ? ? ? ? ? ? 0,8? ? ? ? 0t0? ?45124047 protocol: TCPv6
 
????squid? ? ? ? 1049? ? ? ? ? ? ? proxy? ?25u? ? ?sock? ? ? ? ? ? ? ? 0,8? ? ? ? 0t0? ?50689821 protocol: TCPv6
 
...
 
 ?
 
 ?
 
We thought maybe this is a weird IPv6 thing, as we only route IPv4, so we compiled a more recent version of squid with no v6 support. The thing just moved to TCP4..
 
 ?
 
lsof |wc -l
 
120313
 
 ?
 
cat /proc/slabinfo |grep TCP
 
MPTCPv6? ? ? ? ? ? ? ? 0? ? ? 0? ?2048? ?16? ? 8 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0
 
tw_sock_TCPv6? ? ? ? ? 0? ? ? 0? ? 248? ?33? ? 2 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0
 
request_sock_TCPv6? ? ? 0? ? ? 0? ? 304? ?26? ? 2 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0
 
TCPv6? ? ? ? ? ? ? ? 208? ? 208? ?2432? ?13? ? 8 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ?16? ? ?16? ? ? 0
 
MPTCP? ? ? ? ? ? ? ? ? 0? ? ? 0? ?1856? ?17? ? 8 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0
 
tw_sock_TCP? ? ? ? ?5577? ?5577? ? 248? ?33? ? 2 : tunables? ? 0? ? 0? ? 0 : slabdata? ? 169? ? 169? ? ? 0
 
request_sock_TCP? ? 1898? ?2002? ? 304? ?26? ? 2 : tunables? ? 0? ? 0? ? 0 : slabdata? ? ?77? ? ?77? ? ? 0
 
TCP? ? ? ? ? ? ? ?102452 113274??2240? ?14? ? 8 : tunables? ? 0? ? 0? ? 0 : slabdata? ?8091? ?8091? ? ? 0
 
 ?
 
 ?
 
cat /proc/net/tcp |wc -l
 
255
 
 ?
 
After restarting squid the slab objects are released and the open file descriptors drop to a reasonable value. This further suggests it is squid hanging on to these FDs.
 
lsof |grep proxy |wc -l
 
1221
 
 ?
 
 ?
 
Any suggestion? I guess it's something blatantly obvious, but it's a couple of days we look at this and we're not going anywhere...
 
 ?
 
Thanks again
 
 ?
 
 ?
 


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/e8fa01c6/attachment.htm>

From rousskov at measurement-factory.com  Fri Jul 12 13:42:53 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 12 Jul 2024 09:42:53 -0400
Subject: [squid-users] Socket handle leak?
In-Reply-To: <1026668535.2215882.1720781888145@mail.yahoo.com>
References: <1026668535.2215882.1720781888145.ref@mail.yahoo.com>
 <1026668535.2215882.1720781888145@mail.yahoo.com>
Message-ID: <83789855-5dff-49c4-80ed-0d35120aa8c2@measurement-factory.com>

On 2024-07-12 06:58, paolo.prinx at gmail.com wrote:

> We are having some stability issues with our squid farms after a recent 
> upgrade from Centos/Squid 3.5.x to Ubuntu/Squid 5.7/6.9.

> In short, after running for a certain period the servers run out of file 
> descriptors. We see a slowly growing number of TCP or TCPv6 socket 
> handles

Assuming that your Squids are not under an ever-increasing load, what 
you describe sounds like a Squid bug. I do not see any obviously related 
fixes in the latest official code, so it is possible that this bug is 
unknown to Squid developers and is still present in v6+. I recommend the 
following steps:

1. Forget about Squid v5. Aim to upgrade to Squid v6.

2. Collect a few mgr:filedescriptors cache manager snapshots from a 
problematic Squid in hope to discover a common theme among leaked 
descriptors metadata. Share your findings (and/or a pointer to 
compressed snapshots).

3. Check cache.log for frequent (or at least persistent) ERROR and 
WARNING messages and report your findings.

4. Does your Squid grow its resident memory usage as well? Descriptor 
leaks are often (but not always!) accompanied by memory leaks. The 
latter are sometimes easier to pinpoint. If (and only if) your Squid is 
leaking a lot of memory, then collect a few dozen mgr:mem snapshots 
(e.g., one every busy hour) and share a pointer to a compressed snapshot 
  archive for analysis by Squid developers. There is at least one v6 
memory leak fixed in master/v7 (Bug 5322), but, hopefully, you are not 
suffering from that memory leak (otherwise the noise from that leak may 
obscure what we are looking for).


You may continue this triage on this mailing list or file a bug report 
at https://bugs.squid-cache.org/enter_bug.cgi?product=Squid


Thank you,

Alex.



> It is somewhat similar to what reported under 
> https://access.redhat.com/solutions/3362211 
> <https://access.redhat.com/solutions/3362211>?. They state that
> 
>   * /If an application fails to |close()|?it's socket descriptors and
>     continues to allocate new sockets then it can use up all the system
>     memory on TCP(v6) slab objects./
>   * /Note some of these sockets will not show up in
>     |/proc/net/sockstat(6)|. Sockets that still have a file descriptor
>     but are in the |TCP_CLOSE|?state will consume a slab object. But
>     will not be accounted for in |/proc/net/sockstat(6)|?or "ss" or
>     "netstat"./
>   * It can be determined whether this is an application sockets leak, by
>     stopping the application processes that are consuming sockets. If
>     the slab objects in |/proc/slabinfo|?are freed then the application
>     is responsible. As that means that destructor routines have found
>     open file descriptors to sockets in the process.
> 
> /
> /
> /"/This is most likely to be a case of the application not handling 
> error conditions correctly and not calling |close()|?to free the FD and 
> socket."/
> /
> 
> 
> For example, on a server with squid 5.7, unmodified package:
> 
> list of open files;
> 
>     lsof |wc -l
>     56963
> 
> 
> of which 35K in TCPv6:
> 
>     lsof |grep proxy |grep TCPv6 |wc -l
> 
>  ????35301
> 
> under /proc I see less objects
>  ? ? cat? /proc/net/tcp6 |wc -l
>  ????3095
> 
> but the number of objects in the slabs is high
>  ????cat /proc/slabinfo |grep TCPv6
>  ????MPTCPv6? ? ? ? ? ? ? ? 0? ? ? 0? ?2048? ?16? ? 8 : tunables? ? 0    
> 0? ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0
>  ????tw_sock_TCPv6? ? ? ?1155? ?1155? ? 248? ?33? ? 2 : tunables? ? 0    
> 0? ? 0 : slabdata? ? ?35? ? ?35? ? ? 0
>  ????request_sock_TCPv6? ? ? 0? ? ? 0? ? 304? ?26? ? 2 : tunables? ? 0  
>  ? 0? ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0
>  ????TCPv6 *38519? 38519*? ?2432? ?13? ? 8 : tunables? ? 0? ? 0? ? 0 : 
> slabdata? ?2963? ?2963? ? ? 0
> 
> I have 35K of lines like this
>  ????lsof |grep proxy |grep TCPv6 |more
>  ????squid? ? ? ? 1049? ? ? ? ? ? ? proxy? ?13u? ? ?sock                
> 0,8? ? ? ? 0t0? ? 5428173 protocol: TCPv6
>  ????squid? ? ? ? 1049? ? ? ? ? ? ? proxy? ?14u? ? ?sock                
> 0,8? ? ? ? 0t0? ?27941608 protocol: TCPv6
>  ????squid? ? ? ? 1049? ? ? ? ? ? ? proxy? ?24u? ? ?sock                
> 0,8? ? ? ? 0t0? ?45124047 protocol: TCPv6
>  ????squid? ? ? ? 1049? ? ? ? ? ? ? proxy? ?25u? ? ?sock                
> 0,8? ? ? ? 0t0? ?50689821 protocol: TCPv6
> ...
> 
> 
> We thought maybe this is a weird IPv6 thing, as we only route IPv4, so 
> we compiled a more recent version of squid with no v6 support. The thing 
> just moved to TCP4..
> 
> lsof |wc -l
> 120313
> 
> cat /proc/slabinfo |grep TCP
> MPTCPv6? ? ? ? ? ? ? ? 0? ? ? 0? ?2048? ?16? ? 8 : tunables? ? 0? ? 0    
> 0 : slabdata? ? ? 0? ? ? 0? ? ? 0
> tw_sock_TCPv6? ? ? ? ? 0? ? ? 0? ? 248? ?33? ? 2 : tunables? ? 0? ? 0    
> 0 : slabdata? ? ? 0? ? ? 0? ? ? 0
> request_sock_TCPv6? ? ? 0? ? ? 0? ? 304? ?26? ? 2 : tunables? ? 0? ? 0  
>  ? 0 : slabdata? ? ? 0? ? ? 0? ? ? 0
> TCPv6? ? ? ? ? ? ? ? 208? ? 208? ?2432? ?13? ? 8 : tunables? ? 0? ? 0    
> 0 : slabdata? ? ?16? ? ?16? ? ? 0
> MPTCP? ? ? ? ? ? ? ? ? 0? ? ? 0? ?1856? ?17? ? 8 : tunables? ? 0? ? 0    
> 0 : slabdata? ? ? 0? ? ? 0? ? ? 0
> tw_sock_TCP? ? ? ? ?5577? ?5577? ? 248? ?33? ? 2 : tunables? ? 0? ? 0    
> 0 : slabdata? ? 169? ? 169? ? ? 0
> request_sock_TCP? ? 1898? ?2002? ? 304? ?26? ? 2 : tunables? ? 0? ? 0    
> 0 : slabdata? ? ?77? ? ?77? ? ? 0
> TCP *102452 113274 *?2240? ?14? ? 8 : tunables? ? 0? ? 0? ? 0 : 
> slabdata? ?8091? ?8091? ? ? 0
> 
> 
> cat /proc/net/tcp |wc -l
> 255
> 
> After restarting squid the slab objects are released and the open file 
> descriptors drop to a reasonable value. This further suggests it is 
> squid hanging on to these FDs.
> 
> lsof |grep proxy |wc -l
> 1221
> 
> 
> Any suggestion? I guess it's something blatantly obvious, but it's a 
> couple of days we look at this and we're not going anywhere...
> 
> Thanks again
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Fri Jul 12 13:52:29 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 12 Jul 2024 09:52:29 -0400
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <LO2P265MB316510765BD02C033497EC99FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165DBB8AF9A1068155EE38EFEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316510765BD02C033497EC99FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <23084e58-c287-435a-9106-9ee12e81605a@measurement-factory.com>

On 2024-07-12 08:06, Ben Toms wrote:
> Seems that my issue is similar to - 
> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication 

You are facing up to two problems:

1. Some authenticated responses are not cachable by Squid. Please share 
HTTP headers of the response in question.

2. TCP_MISS_ABORTED/502 errors may delete a being-cached response. These 
can be bogus errors (essentially Squid logging bugs) or real ones (e.g., 
due to communication bugs, misconfiguration, or compatibility problems). 
I recommend adding %err_code/%err_detail to your logformat and sharing 
the corresponding access.log lines (obfuscated as needed).

Sharing (privately if needed) a pointer to compressed ALL,9 cache.log 
while reproducing the issue using a single transaction may help us 
resolve all the unknowns:

https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction


HTH,

Alex.


> *From: *Ben Toms <ben at macmule.com>
> *Date: *Friday, 12 July 2024 at 12:07
> *To: *squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
> *Subject: *Re: TCP_MISS_ABORTED/502
> 
> To test, I changed the parent url to my blog.. and was able to download 
> an item there via squid-cache.. so the issue seems to be when 
> downloading from a parent which requires authentication.
> 
> Regards,
> 
> Ben.
> 
> *From: *Ben Toms <ben at macmule.com>
> *Date: *Friday, 12 July 2024 at 10:29
> *To: *squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
> *Subject: *TCP_MISS_ABORTED/502
> 
> Hi Amos,
> 
> I made the changes suggested, biut still getting TCP_MISS_ABORTED/502.
> 
> The test I?m performing is via a simple curl:
> 
> curl https://local.server.fqdn/some/file/path 
> <https://local.server.fqdn/some/file/path> -H "Authorization: Basic 
> base64_auth" -o ~/Downloads/test
> 
> The Apache logs for the parent (public.server.fqdn), show:
> 
> [12/Jul/2024:10:16:09 +0100] "GET /some/file/path HTTP/1.1" 200 10465 
> "-" "curl/8.7.1"
> 
> So, Apache on the parent is responding with a 200.. and if I mess around 
> with the curl commands base64_auth I get 401?s as expected in the 
> parents Apache logs.
> 
> However, squids access.log still shows:
> 
> 1720775769.417???? 49 192.168.0.156 TCP_MISS_ABORTED/502 3974 GET 
> https://local.server.fqdn/some/file/path 
> <https://local.server.fqdn/some/file/path> - 
> FIRSTUP_PARENT/public.ip.of.public.server text/html
> 
> Squid.conf is now:
> 
> https_port 443 accel protocol=HTTPS tls-cert=/usr/local/squid/client.pem 
> tls-key=/usr/local/squid/client.key
> 
> cache_peer public.server.fqdn parent 443 0 no-query originserver 
> no-digest no-netdb-exchange tls login=PASSTHRU name=myAccel 
> forceddomain=uk-dist-a.datajar.mobi
> 
> acl our_sites dstdomain local.server.fqdn
> 
> http_access allow our_sites
> 
> cache_peer_access myAccel allow our_sites
> 
> cache_peer_access myAccel deny all
> 
> refresh_pattern -i public.server.fqdn/* 3600??? 80%???? 14400
> 
> cache_dir ufs /usr/local/squid/var/cache 100000 16 256
> 
> The file I?m attempting to cache with the above curl command is 6.5kb 
> only.. have tried others to no avail.
> 
> It seems like squid doesn?t want to cache, and it?s not advising the 
> client to wait as it caches.
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Fri Jul 12 14:22:25 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 Jul 2024 02:22:25 +1200
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <23084e58-c287-435a-9106-9ee12e81605a@measurement-factory.com>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165DBB8AF9A1068155EE38EFEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316510765BD02C033497EC99FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <23084e58-c287-435a-9106-9ee12e81605a@measurement-factory.com>
Message-ID: <af509e63-7d63-4e3a-8991-8961e65aaa4c@treenet.co.nz>


On 13/07/24 01:52, Alex Rousskov wrote:
> On 2024-07-12 08:06, Ben Toms wrote:
>> Seems that my issue is similar to - 
>> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication 
> 
> You are facing up to two problems:
> 
> 1. Some authenticated responses are not cachable by Squid. Please share 
> HTTP headers of the response in question.
> 

FYI, those can be obtained by configuring squid.conf with

   debug_options 11,2


Cheers
Amos


> 2. TCP_MISS_ABORTED/502 errors may delete a being-cached response. These 
> can be bogus errors (essentially Squid logging bugs) or real ones (e.g., 
> due to communication bugs, misconfiguration, or compatibility problems). 
> I recommend adding %err_code/%err_detail to your logformat and sharing 
> the corresponding access.log lines (obfuscated as needed).
> 
> Sharing (privately if needed) a pointer to compressed ALL,9 cache.log 
> while reproducing the issue using a single transaction may help us 
> resolve all the unknowns:
> 
> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction
> 
> 
> HTH,
> 
> Alex.
> 
> 




From ben at macmule.com  Fri Jul 12 15:03:02 2024
From: ben at macmule.com (Ben Toms)
Date: Fri, 12 Jul 2024 15:03:02 +0000
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <af509e63-7d63-4e3a-8991-8961e65aaa4c@treenet.co.nz>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165DBB8AF9A1068155EE38EFEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316510765BD02C033497EC99FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <23084e58-c287-435a-9106-9ee12e81605a@measurement-factory.com>
 <af509e63-7d63-4e3a-8991-8961e65aaa4c@treenet.co.nz>
Message-ID: <LO2P265MB3165A2095FB83CD85137D8A4FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>

Logs below:

----------
2024/07/12 14:57:08.678 kid1| 11,2| http.cc(1263) readReply: conn17 local=squid.cache.ip:42848 remote=public.ip.of.public.server:443 FIRSTUP_PARENT FD 14 flags=1: read failure: (0) No error.
2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(273) sendStartOfMessage: HTTP Client conn14 local=squid.cache.ip:443 remote=client.ip:56517 FD 13 flags=1
2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(274) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 502 Bad Gateway
Server: squid/6.6
Mime-Version: 1.0
Date: Fri, 12 Jul 2024 14:57:08 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3629
X-Squid-Error: ERR_READ_ERROR 0
Vary: Accept-Language
Content-Language: en
Cache-Status: squid.host;detail=mismatch
Via: 1.1 squid.host (squid/6.6)
Connection: keep-alive


----------


Regards,
Ben.

From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Amos Jeffries <squid3 at treenet.co.nz>
Date: Friday, 12 July 2024 at 15:22
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] TCP_MISS_ABORTED/502

On 13/07/24 01:52, Alex Rousskov wrote:
> On 2024-07-12 08:06, Ben Toms wrote:
>> Seems that my issue is similar to -
>> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication
>
> You are facing up to two problems:
>
> 1. Some authenticated responses are not cachable by Squid. Please share
> HTTP headers of the response in question.
>

FYI, those can be obtained by configuring squid.conf with

   debug_options 11,2


Cheers
Amos


> 2. TCP_MISS_ABORTED/502 errors may delete a being-cached response. These
> can be bogus errors (essentially Squid logging bugs) or real ones (e.g.,
> due to communication bugs, misconfiguration, or compatibility problems).
> I recommend adding %err_code/%err_detail to your logformat and sharing
> the corresponding access.log lines (obfuscated as needed).
>
> Sharing (privately if needed) a pointer to compressed ALL,9 cache.log
> while reproducing the issue using a single transaction may help us
> resolve all the unknowns:
>
> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction
>
>
> HTH,
>
> Alex.
>
>


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/9e437a9f/attachment.htm>

From bcook at poughkeepsieschools.org  Fri Jul 12 15:18:48 2024
From: bcook at poughkeepsieschools.org (Brian Cook)
Date: Fri, 12 Jul 2024 11:18:48 -0400
Subject: [squid-users] cachemgr.cgi isn't mgr:info ?
Message-ID: <CAOyb_Ew4XT2JyPHxFXR06KbjeQ5DXH4S0bnOrX7pqphmEJFRgQ@mail.gmail.com>

Picking up squid again and trying to look at what's going on inside..

Squid on OpenWRT.. wanted to look at mgr:info for file desc, etc..

trying to access the cachemgr.cgi.. as this looks like the new squidclient

Wasn't working etc..

..
debug_options ALL,2
cache_log /tmp/squid_cache.log
..

----------
2024/07/12 10:57:08.388| 33,2| client_side.cc(1646) clientProcessRequest:
internal URL found: http://10.20.245.10:3128
2024/07/12 10:57:08.388| 85,2| client_side_request.cc(715)
clientAccessCheckDone: The request GET
http://10.20.245.10:3128/squid-internal-mgr/menu is DENIED; last ACL
checked: Safe_ports
# EOF
---------

Q: So I added 3128 to the Safe_ports.. and then it works..

[image: image.png]

Q: no password set for cachemgr_passwd.. cachemgr.cgi just open to the
world? unsecured?

and is Process Filedescriptor Allocation the closest thing?

I (think) I remember something like max, in use, and something else.. being
in mgr:info

fwiw openwrt starts squid with like 4096 max files..

needed something like this:

..
        procd_set_param file $CONFIGFILE
        procd_set_param limits nofile="262140 262140"
        procd_set_param respawn
..

to set the hard and soft limits..

any better practice than adding 3128 to the 'Safe_ports'? (can't keep that
in place..)

and setting a cachemgr_passwd would be the only thing to secure the cgi?

(am I missing something else?)

Thank you in advance.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/8749b532/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 23732 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/8749b532/attachment.png>

From ben at macmule.com  Fri Jul 12 15:38:28 2024
From: ben at macmule.com (Ben Toms)
Date: Fri, 12 Jul 2024 15:38:28 +0000
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <LO2P265MB3165A2095FB83CD85137D8A4FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165DBB8AF9A1068155EE38EFEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316510765BD02C033497EC99FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <23084e58-c287-435a-9106-9ee12e81605a@measurement-factory.com>
 <af509e63-7d63-4e3a-8991-8961e65aaa4c@treenet.co.nz>
 <LO2P265MB3165A2095FB83CD85137D8A4FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <LO2P265MB3165E5F9F32931620EE1F794FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>

Think I made the changes Alex requested:

12/Jul/2024:15:36:31 +0000.640 local.server.ip TCP_MISS_ABORTED/502 3974 GET https://local.server.fqdn/path/to/file - FIRSTUP_PARENT/public.ip.of.public.server text/html ERR_READ_ERROR/WITH_SERVER


Regards,
Ben.

From: Ben Toms <ben at macmule.com>
Date: Friday, 12 July 2024 at 16:03
To: Amos Jeffries <squid3 at treenet.co.nz>, squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] TCP_MISS_ABORTED/502
Logs below:

----------
2024/07/12 14:57:08.678 kid1| 11,2| http.cc(1263) readReply: conn17 local=squid.cache.ip:42848 remote=public.ip.of.public.server:443 FIRSTUP_PARENT FD 14 flags=1: read failure: (0) No error.
2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(273) sendStartOfMessage: HTTP Client conn14 local=squid.cache.ip:443 remote=client.ip:56517 FD 13 flags=1
2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(274) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 502 Bad Gateway
Server: squid/6.6
Mime-Version: 1.0
Date: Fri, 12 Jul 2024 14:57:08 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3629
X-Squid-Error: ERR_READ_ERROR 0
Vary: Accept-Language
Content-Language: en
Cache-Status: squid.host;detail=mismatch
Via: 1.1 squid.host (squid/6.6)
Connection: keep-alive


----------


Regards,
Ben.

From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Amos Jeffries <squid3 at treenet.co.nz>
Date: Friday, 12 July 2024 at 15:22
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] TCP_MISS_ABORTED/502

On 13/07/24 01:52, Alex Rousskov wrote:
> On 2024-07-12 08:06, Ben Toms wrote:
>> Seems that my issue is similar to -
>> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication
>
> You are facing up to two problems:
>
> 1. Some authenticated responses are not cachable by Squid. Please share
> HTTP headers of the response in question.
>

FYI, those can be obtained by configuring squid.conf with

   debug_options 11,2


Cheers
Amos


> 2. TCP_MISS_ABORTED/502 errors may delete a being-cached response. These
> can be bogus errors (essentially Squid logging bugs) or real ones (e.g.,
> due to communication bugs, misconfiguration, or compatibility problems).
> I recommend adding %err_code/%err_detail to your logformat and sharing
> the corresponding access.log lines (obfuscated as needed).
>
> Sharing (privately if needed) a pointer to compressed ALL,9 cache.log
> while reproducing the issue using a single transaction may help us
> resolve all the unknowns:
>
> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction
>
>
> HTH,
>
> Alex.
>
>


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/a815dace/attachment.htm>

From jonathanlee571 at gmail.com  Fri Jul 12 16:09:12 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 12 Jul 2024 09:09:12 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
Message-ID: <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>

Thanks I fixed the firewall rules, I am trying tproxy and it seems to help with speed right now. 
Sent from my iPhone

> On Jul 12, 2024, at 04:57, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> ?On 12/07/24 11:50, Jonathan Lee wrote:
>>> I recommend changing your main port to this:
>>> 
>>>   http_port 3128 ssl-bump ....
>> This is set to this when it processes
>> http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
> 
> The key thing here was the removal of the IP address. So that Squid received both the 192.168.*.* and the 127.0.0.* traffic without needing separate http_port lines.
> 
> 
> 
>>> and receiving the intercepted traffic on:
>>> 
>>>  http_port 3129 intercept ssl-bump ?
>> Do you mean https?
> 
> Sorry. I missed that you had an https_port using 3129 already.
> 
> 
> 
>> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
>> Https uses that port 3129
>> What should I adapt
>> http_port
>> https_port?
> 
> Both.
> 
> FYI, there are two issues:
> 
> 1) listening on IP 127.0.0.1. Inside the OS there are different devices for localhost (lo) and WAN (eg. eth0). NAT is problematic already without introducing any tricky behaviours from bridging those "private" (lo) and "public" WAN devices.
> 
> The simplest solution is just not to put any IP address on the squid.conf *port line(s) with intercept options. The OS will select one appropriate for whatever device and tell Squid on a per-connection basis.
> 
> The more difficult way is to put one of the machines "global" (WAN or LAN) IP addresses. In your case 192.168.1.1. With most connections being from the LAN that minimizes the possible problems.
> 
> 
> 2) listening on a well-known proxy port 3128 for intercepted traffic.
> 
> There is malware in existence that scans for at least port 3128 (likely 1080, 8080 etc common proxy ports) being used by proxies like yours and abuses them. As a result at least one popular antivirus network scanner (from Trend) does the same scan to detect insecure proxies.
> 
> The worst thing about this situation is that the NAT very effectively hides the malware. So it is extremely hard to see whether it is happening to you.
> 
> 
> I am not sure what UI you are using to show those firewall rules in your other email. However the one that had ALLOW for the port range 3128-3129 worries me. AFAIK that should only be for 3128 and a separate rule somewhere else to drop the intercepted port 3129 traffic pre-NAT.
> 
> 
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Fri Jul 12 16:10:54 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 12 Jul 2024 12:10:54 -0400
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <LO2P265MB3165E5F9F32931620EE1F794FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165DBB8AF9A1068155EE38EFEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316510765BD02C033497EC99FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <23084e58-c287-435a-9106-9ee12e81605a@measurement-factory.com>
 <af509e63-7d63-4e3a-8991-8961e65aaa4c@treenet.co.nz>
 <LO2P265MB3165A2095FB83CD85137D8A4FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165E5F9F32931620EE1F794FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <1ee387d1-732e-4504-8d00-2d8a0c243d8a@measurement-factory.com>

On 2024-07-12 11:38, Ben Toms wrote:
> Think I made the changes Alex requested:
> 
> 12/Jul/2024:15:36:31 +0000.640 local.server.ip TCP_MISS_ABORTED/502 3974 
> GET https://local.server.fqdn/path/to/file - 
> FIRSTUP_PARENT/public.ip.of.public.server text/html 
> ERR_READ_ERROR/WITH_SERVER

Thank you for using Squid v6 for this test.

Unfortunately, due to Squid logging bugs, ERR_READ_ERROR/WITH_SERVER 
does not always mean what it says. For example, parent Squid could have 
closed the child-parent connection prematurely, but there could be other 
reasons. A full debugging log should give us more information.


> 2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(274) sendStartOfMessage: 
> HTTP Client REPLY:

This is a child proxy response to the client. We need parent response to 
the child proxy. Look for "HTTP Server RESPONSE" lines instead.


HTH,

Alex.



> ---------
> 
> HTTP/1.1 502 Bad Gateway
> 
> Server: squid/6.6
> 
> Mime-Version: 1.0
> 
> Date: Fri, 12 Jul 2024 14:57:08 GMT
> 
> Content-Type: text/html;charset=utf-8
> 
> Content-Length: 3629
> 
> X-Squid-Error: ERR_READ_ERROR 0
> 
> Vary: Accept-Language
> 
> Content-Language: en
> 
> Cache-Status: squid.host;detail=mismatch
> 
> Via: 1.1 squid.host (squid/6.6)
> 
> Connection: keep-alive
> 
> ----------
> 
> Regards,
> 
> Ben.
> 
> *From: *squid-users <squid-users-bounces at lists.squid-cache.org> on 
> behalf of Amos Jeffries <squid3 at treenet.co.nz>
> *Date: *Friday, 12 July 2024 at 15:22
> *To: *squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
> 
> 
> On 13/07/24 01:52, Alex Rousskov wrote:
>> On 2024-07-12 08:06, Ben Toms wrote:
>>> Seems that my issue is similar to - 
>>> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>
>> 
>> You are facing up to two problems:
>> 
>> 1. Some authenticated responses are not cachable by Squid. Please share 
>> HTTP headers of the response in question.
>> 
> 
> FYI, those can be obtained by configuring squid.conf with
> 
>  ?? debug_options 11,2
> 
> 
> Cheers
> Amos
> 
> 
>> 2. TCP_MISS_ABORTED/502 errors may delete a being-cached response. These 
>> can be bogus errors (essentially Squid logging bugs) or real ones (e.g., 
>> due to communication bugs, misconfiguration, or compatibility problems). 
>> I recommend adding %err_code/%err_detail to your logformat and sharing 
>> the corresponding access.log lines (obfuscated as needed).
>> 
>> Sharing (privately if needed) a pointer to compressed ALL,9 cache.log 
>> while reproducing the issue using a single transaction may help us 
>> resolve all the unknowns:
>> 
>> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>
>> 
>> 
>> HTH,
>> 
>> Alex.
>> 
>> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From ben at macmule.com  Fri Jul 12 16:14:30 2024
From: ben at macmule.com (Ben Toms)
Date: Fri, 12 Jul 2024 16:14:30 +0000
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <1ee387d1-732e-4504-8d00-2d8a0c243d8a@measurement-factory.com>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165DBB8AF9A1068155EE38EFEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316510765BD02C033497EC99FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <23084e58-c287-435a-9106-9ee12e81605a@measurement-factory.com>
 <af509e63-7d63-4e3a-8991-8961e65aaa4c@treenet.co.nz>
 <LO2P265MB3165A2095FB83CD85137D8A4FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165E5F9F32931620EE1F794FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <1ee387d1-732e-4504-8d00-2d8a0c243d8a@measurement-factory.com>
Message-ID: <LO2P265MB31651D6F080E7EF06AD34E21FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>

Hi Alex,

Which log should those be found?

Can?t see ?HTTP Server RESPONSE? in the access.log or cache.log.

Regards,
Ben.

From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Alex Rousskov <rousskov at measurement-factory.com>
Date: Friday, 12 July 2024 at 17:11
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] TCP_MISS_ABORTED/502
On 2024-07-12 11:38, Ben Toms wrote:
> Think I made the changes Alex requested:
>
> 12/Jul/2024:15:36:31 +0000.640 local.server.ip TCP_MISS_ABORTED/502 3974
> GET https://local.server.fqdn/path/to/file -
> FIRSTUP_PARENT/public.ip.of.public.server text/html
> ERR_READ_ERROR/WITH_SERVER

Thank you for using Squid v6 for this test.

Unfortunately, due to Squid logging bugs, ERR_READ_ERROR/WITH_SERVER
does not always mean what it says. For example, parent Squid could have
closed the child-parent connection prematurely, but there could be other
reasons. A full debugging log should give us more information.


> 2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(274) sendStartOfMessage:
> HTTP Client REPLY:

This is a child proxy response to the client. We need parent response to
the child proxy. Look for "HTTP Server RESPONSE" lines instead.


HTH,

Alex.



> ---------
>
> HTTP/1.1 502 Bad Gateway
>
> Server: squid/6.6
>
> Mime-Version: 1.0
>
> Date: Fri, 12 Jul 2024 14:57:08 GMT
>
> Content-Type: text/html;charset=utf-8
>
> Content-Length: 3629
>
> X-Squid-Error: ERR_READ_ERROR 0
>
> Vary: Accept-Language
>
> Content-Language: en
>
> Cache-Status: squid.host;detail=mismatch
>
> Via: 1.1 squid.host (squid/6.6)
>
> Connection: keep-alive
>
> ----------
>
> Regards,
>
> Ben.
>
> *From: *squid-users <squid-users-bounces at lists.squid-cache.org> on
> behalf of Amos Jeffries <squid3 at treenet.co.nz>
> *Date: *Friday, 12 July 2024 at 15:22
> *To: *squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>
>
> On 13/07/24 01:52, Alex Rousskov wrote:
>> On 2024-07-12 08:06, Ben Toms wrote:
>>> Seems that my issue is similar to -
>>> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>
>>
>> You are facing up to two problems:
>>
>> 1. Some authenticated responses are not cachable by Squid. Please share
>> HTTP headers of the response in question.
>>
>
> FYI, those can be obtained by configuring squid.conf with
>
>     debug_options 11,2
>
>
> Cheers
> Amos
>
>
>> 2. TCP_MISS_ABORTED/502 errors may delete a being-cached response. These
>> can be bogus errors (essentially Squid logging bugs) or real ones (e.g.,
>> due to communication bugs, misconfiguration, or compatibility problems).
>> I recommend adding %err_code/%err_detail to your logformat and sharing
>> the corresponding access.log lines (obfuscated as needed).
>>
>> Sharing (privately if needed) a pointer to compressed ALL,9 cache.log
>> while reproducing the issue using a single transaction may help us
>> resolve all the unknowns:
>>
>> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>
>>
>>
>> HTH,
>>
>> Alex.
>>
>>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
> <https://lists.squid-cache.org/listinfo/squid-users>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/8edf4f12/attachment.htm>

From jonathanlee571 at gmail.com  Fri Jul 12 16:16:17 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 12 Jul 2024 09:16:17 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
Message-ID: <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>

tested with removal of IP and port failed If I leave port I get this

2024/07/12 09:15:17| Processing: http_port :3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
2024/07/12 09:15:17| FATAL: http_port: failed to resolve Host/IP:
2024/07/12 09:15:17| Not currently OK to rewrite swap log.
2024/07/12 09:15:17| storeDirWriteCleanLogs: Operation aborted.
2024/07/12 09:15:17| FATAL: Bungled /usr/local/etc/squid/squid.conf line 6: http_port :3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
2024/07/12 09:15:17| Squid Cache (Version 5.8): Terminated abnormally.

> On Jul 12, 2024, at 09:09, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Thanks I fixed the firewall rules, I am trying tproxy and it seems to help with speed right now. 
> Sent from my iPhone
> 
>> On Jul 12, 2024, at 04:57, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>> 
>> ?On 12/07/24 11:50, Jonathan Lee wrote:
>>>> I recommend changing your main port to this:
>>>> 
>>>>  http_port 3128 ssl-bump ....
>>> This is set to this when it processes
>>> http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
>> 
>> The key thing here was the removal of the IP address. So that Squid received both the 192.168.*.* and the 127.0.0.* traffic without needing separate http_port lines.
>> 
>> 
>> 
>>>> and receiving the intercepted traffic on:
>>>> 
>>>> http_port 3129 intercept ssl-bump ?
>>> Do you mean https?
>> 
>> Sorry. I missed that you had an https_port using 3129 already.
>> 
>> 
>> 
>>> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
>>> Https uses that port 3129
>>> What should I adapt
>>> http_port
>>> https_port?
>> 
>> Both.
>> 
>> FYI, there are two issues:
>> 
>> 1) listening on IP 127.0.0.1. Inside the OS there are different devices for localhost (lo) and WAN (eg. eth0). NAT is problematic already without introducing any tricky behaviours from bridging those "private" (lo) and "public" WAN devices.
>> 
>> The simplest solution is just not to put any IP address on the squid.conf *port line(s) with intercept options. The OS will select one appropriate for whatever device and tell Squid on a per-connection basis.
>> 
>> The more difficult way is to put one of the machines "global" (WAN or LAN) IP addresses. In your case 192.168.1.1. With most connections being from the LAN that minimizes the possible problems.
>> 
>> 
>> 2) listening on a well-known proxy port 3128 for intercepted traffic.
>> 
>> There is malware in existence that scans for at least port 3128 (likely 1080, 8080 etc common proxy ports) being used by proxies like yours and abuses them. As a result at least one popular antivirus network scanner (from Trend) does the same scan to detect insecure proxies.
>> 
>> The worst thing about this situation is that the NAT very effectively hides the malware. So it is extremely hard to see whether it is happening to you.
>> 
>> 
>> I am not sure what UI you are using to show those firewall rules in your other email. However the one that had ALLOW for the port range 3128-3129 worries me. AFAIK that should only be for 3128 and a separate rule somewhere else to drop the intercepted port 3129 traffic pre-NAT.
>> 
>> 
>> HTH
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/cb2a7892/attachment.htm>

From squid3 at treenet.co.nz  Fri Jul 12 16:17:53 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 Jul 2024 04:17:53 +1200
Subject: [squid-users] cachemgr.cgi isn't mgr:info ?
In-Reply-To: <CAOyb_Ew4XT2JyPHxFXR06KbjeQ5DXH4S0bnOrX7pqphmEJFRgQ@mail.gmail.com>
References: <CAOyb_Ew4XT2JyPHxFXR06KbjeQ5DXH4S0bnOrX7pqphmEJFRgQ@mail.gmail.com>
Message-ID: <2d89bf45-cfb8-424d-b8c9-ef37b1f2c7a6@treenet.co.nz>

Per your subject question "cachemgr.cgi isn't mgr:info ?"

Correct.

  cachemgr.cgi is an old tool to access multiple proxies manager reports.

  "mgr:info" is a command line parameter for the squidclient tool to 
access a proxies "info" manager report.
   Also, commonly used shorthand in Squid community to refer to the 
"info" report, regardless of how it is accessed.


Responses to your other queries inline...


On 13/07/24 03:18, Brian Cook wrote:
> Picking up squid again and trying to look at what's going on inside..
> 
> Squid on OpenWRT.. wanted to look at mgr:info for file desc, etc..
> 
> trying to access the cachemgr.cgi.. as this looks like the new squidclient
> 
> Wasn't working etc..
> 

FYI, both squidclient and cachemgr.cgi are deprecated. It depends on the 
tool version vs Squid version whether you will encounter an issue.

Current recommendation for current supported Squid is to use a tool like 
this one: <https://github.com/yadij/cachemgr.js>.
(I may be a bit biased there as its author, but also not yet aware of 
any others to reference.)


> ..
> debug_options ALL,2
> cache_log /tmp/squid_cache.log
> ..
> 
> ----------
> 2024/07/12 10:57:08.388| 33,2| client_side.cc(1646) 
> clientProcessRequest: internal URL found: http://10.20.245.10:3128 
> 2024/07/12 10:57:08.388| 85,2| client_side_request.cc(715) 
> clientAccessCheckDone: The request GET 
> http://10.20.245.10:3128/squid-internal-mgr/menu is DENIED; last ACL 
> checked: Safe_ports
> # EOF
> ---------
> 
> Q: So I added 3128 to the Safe_ports.. and then it works..
> 
> image.png
> 
> Q: no password set for cachemgr_passwd.. cachemgr.cgi just open to the 
> world? unsecured?
> 

Apparently so in your setup. Unless your Browser etc did some implicit 
authentication that you overlooked.


> and is Process Filedescriptor Allocation the closest thing?
> 

That report is a list of what each filedescriptor is currently being 
used for.


> I (think) I remember something like max, in use, and something else.. 
> being in mgr:info
> 

Yes.


> fwiw openwrt starts squid with like 4096 max files..
> 
> needed something like this:
> 
> ..
>  ? ? ? ? procd_set_param file $CONFIGFILE
>  ? ? ? ? procd_set_param limits nofile="262140 262140"
>  ? ? ? ? procd_set_param respawn
> ..
> 
> to set the hard and soft limits..
> 
> any better practice than adding 3128 to the 'Safe_ports'? (can't keep 
> that in place..)


Ports 1025 to 65535 should already be listed as "Safe_ports". That ACL 
is supposed to be used to pinhole a denial of the known **non-safe** ports.


> 
> and setting a cachemgr_passwd would be the only thing to secure the cgi?
> 

No.

  The CGI tool is restricted by any configuration of the web server 
running it. And,

  Then tool requests to Squid are restricted by your http_access rules 
for what requests can be made of the proxy. And,

  Then the access to individual manager reports is controlled by 
cachemgr_passwd directive in Squid.


Cheers
Amos


From jonathanlee571 at gmail.com  Fri Jul 12 16:25:39 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 12 Jul 2024 09:25:39 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
References: <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
Message-ID: <86F3A59A-FF13-49B3-BB1E-F51B3A757B23@gmail.com>

Sorry that test was on the 5.8 version I am using that boot environment right now. All others were on 6.6 does 6.6 support no IP port combo?
Sent from my iPhone

> On Jul 12, 2024, at 09:16, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> ?tested with removal of IP and port failed If I leave port I get this
> 
> 2024/07/12 09:15:17| Processing: http_port :3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2024/07/12 09:15:17| FATAL: http_port: failed to resolve Host/IP:
> 2024/07/12 09:15:17| Not currently OK to rewrite swap log.
> 2024/07/12 09:15:17| storeDirWriteCleanLogs: Operation aborted.
> 2024/07/12 09:15:17| FATAL: Bungled /usr/local/etc/squid/squid.conf line 6: http_port :3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2024/07/12 09:15:17| Squid Cache (Version 5.8): Terminated abnormally.
> 
>> On Jul 12, 2024, at 09:09, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> Thanks I fixed the firewall rules, I am trying tproxy and it seems to help with speed right now.
>> Sent from my iPhone
>> 
>>> On Jul 12, 2024, at 04:57, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>> 
>>> ?On 12/07/24 11:50, Jonathan Lee wrote:
>>>>> I recommend changing your main port to this:
>>>>> 
>>>>>  http_port 3128 ssl-bump ....
>>>> This is set to this when it processes
>>>> http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
>>> 
>>> The key thing here was the removal of the IP address. So that Squid received both the 192.168.*.* and the 127.0.0.* traffic without needing separate http_port lines.
>>> 
>>> 
>>> 
>>>>> and receiving the intercepted traffic on:
>>>>> 
>>>>> http_port 3129 intercept ssl-bump ?
>>>> Do you mean https?
>>> 
>>> Sorry. I missed that you had an https_port using 3129 already.
>>> 
>>> 
>>> 
>>>> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
>>>> Https uses that port 3129
>>>> What should I adapt
>>>> http_port
>>>> https_port?
>>> 
>>> Both.
>>> 
>>> FYI, there are two issues:
>>> 
>>> 1) listening on IP 127.0.0.1. Inside the OS there are different devices for localhost (lo) and WAN (eg. eth0). NAT is problematic already without introducing any tricky behaviours from bridging those "private" (lo) and "public" WAN devices.
>>> 
>>> The simplest solution is just not to put any IP address on the squid.conf *port line(s) with intercept options. The OS will select one appropriate for whatever device and tell Squid on a per-connection basis.
>>> 
>>> The more difficult way is to put one of the machines "global" (WAN or LAN) IP addresses. In your case 192.168.1.1. With most connections being from the LAN that minimizes the possible problems.
>>> 
>>> 
>>> 2) listening on a well-known proxy port 3128 for intercepted traffic.
>>> 
>>> There is malware in existence that scans for at least port 3128 (likely 1080, 8080 etc common proxy ports) being used by proxies like yours and abuses them. As a result at least one popular antivirus network scanner (from Trend) does the same scan to detect insecure proxies.
>>> 
>>> The worst thing about this situation is that the NAT very effectively hides the malware. So it is extremely hard to see whether it is happening to you.
>>> 
>>> 
>>> I am not sure what UI you are using to show those firewall rules in your other email. However the one that had ALLOW for the port range 3128-3129 worries me. AFAIK that should only be for 3128 and a separate rule somewhere else to drop the intercepted port 3129 traffic pre-NAT.
>>> 
>>> 
>>> HTH
>>> Amos
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/3e98c748/attachment.htm>

From rousskov at measurement-factory.com  Fri Jul 12 16:32:42 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 12 Jul 2024 12:32:42 -0400
Subject: [squid-users] cachemgr.cgi isn't mgr:info ?
In-Reply-To: <CAOyb_Ew4XT2JyPHxFXR06KbjeQ5DXH4S0bnOrX7pqphmEJFRgQ@mail.gmail.com>
References: <CAOyb_Ew4XT2JyPHxFXR06KbjeQ5DXH4S0bnOrX7pqphmEJFRgQ@mail.gmail.com>
Message-ID: <c513c2aa-8c6d-477a-a560-cfee995a2d7c@measurement-factory.com>

On 2024-07-12 11:18, Brian Cook wrote:
> Picking up squid again and trying to look at what's going on inside..
> 
> Squid on OpenWRT.. wanted to look at mgr:info for file desc, etc..
> 
> trying to access the cachemgr.cgi.. as this looks like the new squidclient

FWIW, I do not recommend using cachemgr.cgi and squidclient. For various 
reasons, both were recently removed from Squid master/v7. Squidclient 
can be replaced with curl or wget. The best cachemgr.cgi replacement 
depends on many factors; a static HTML file may be the best solution in 
some cases!

Without squidclient, you will need to use absolute URLs like this one:

     http://correct-host-name-or-ip:port/squid-internal-mgr/info

See recent discussions on this mailing list or Bug 5283 for discussions 
about what correct-host-name-or-ip:port to use for these URLs. And if 
you got it working with squidclient, you can see what your squidclient 
was sending, of course.
https://bugs.squid-cache.org/show_bug.cgi?id=5283


> Wasn't working etc..

> Q: So I added 3128 to the Safe_ports.. and then it works..

That solution is probably wrong, even if it works. If you share your 
http_access rules, others may be able to suggest a better solution.


> Q: no password set for cachemgr_passwd.. cachemgr.cgi just open to the 
> world? unsecured?

I cannot help you with cachemgr.cgi (see above). Openness of cache 
manager interface itself depends on your http_access rules (and 
cachemgr_passwd).


> and is Process Filedescriptor Allocation the closest thing?

If you want to know more about a subset of file and socket descriptors 
used by Squid, with per-descriptor information, then, yes, 
mgr:filedescriptors is the right cache manager report.


> I (think) I remember something like max, in use, and something else.. 
> being in mgr:info

Yes, it is still there:

> File descriptor usage for squid:
>         Maximum number of file descriptors:   16000
>         Largest file desc currently in use:     41
>         Number of file desc currently in use:   24
>         Files queued for open:                   0
>         Available number of file descriptors: 15976
>         Reserved number of file descriptors:   100
>         Store Disk files open:                   0


HTH,

Alex.



> fwiw openwrt starts squid with like 4096 max files..
> 
> needed something like this:
> 
> ..
>  ? ? ? ? procd_set_param file $CONFIGFILE
>  ? ? ? ? procd_set_param limits nofile="262140 262140"
>  ? ? ? ? procd_set_param respawn
> ..
> 
> to set the hard and soft limits..
> 
> any better practice than adding 3128 to the 'Safe_ports'? (can't keep 
> that in place..)
> 
> and setting a cachemgr_passwd would be the only thing to secure the cgi?
> 
> (am I missing something else?)
> 
> Thank you in advance.
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Fri Jul 12 16:36:41 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 12 Jul 2024 12:36:41 -0400
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <LO2P265MB31651D6F080E7EF06AD34E21FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165DBB8AF9A1068155EE38EFEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316510765BD02C033497EC99FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <23084e58-c287-435a-9106-9ee12e81605a@measurement-factory.com>
 <af509e63-7d63-4e3a-8991-8961e65aaa4c@treenet.co.nz>
 <LO2P265MB3165A2095FB83CD85137D8A4FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165E5F9F32931620EE1F794FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <1ee387d1-732e-4504-8d00-2d8a0c243d8a@measurement-factory.com>
 <LO2P265MB31651D6F080E7EF06AD34E21FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <0377b31b-4ec0-4b29-8651-a7984210e446@measurement-factory.com>

On 2024-07-12 12:14, Ben Toms wrote:

> Which log should those be found?

cache.log (if they are present)


> Can?t see ?HTTP Server RESPONSE? in the access.log or cache.log.

Sigh. This is one of the reasons I avoid asking folks to study logs 
themselves, even ALL,2 logs...

If that line is not in cache.log, then child Squid probably did not 
receive a response from parent Squid, or could not parse that response. 
A full debugging log should give us more information.

Alex.


> *From: *squid-users <squid-users-bounces at lists.squid-cache.org> on 
> behalf of Alex Rousskov <rousskov at measurement-factory.com>
> *Date: *Friday, 12 July 2024 at 17:11
> *To: *squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
> 
> On 2024-07-12 11:38, Ben Toms wrote:
>> Think I made the changes Alex requested:
>> 
>> 12/Jul/2024:15:36:31 +0000.640 local.server.ip TCP_MISS_ABORTED/502 3974 
>> GET https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file> -
>> FIRSTUP_PARENT/public.ip.of.public.server text/html 
>> ERR_READ_ERROR/WITH_SERVER
> 
> Thank you for using Squid v6 for this test.
> 
> Unfortunately, due to Squid logging bugs, ERR_READ_ERROR/WITH_SERVER
> does not always mean what it says. For example, parent Squid could have
> closed the child-parent connection prematurely, but there could be other
> reasons. A full debugging log should give us more information.
> 
> 
>> 2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(274) sendStartOfMessage: 
>> HTTP Client REPLY:
> 
> This is a child proxy response to the client. We need parent response to
> the child proxy. Look for "HTTP Server RESPONSE" lines instead.
> 
> 
> HTH,
> 
> Alex.
> 
> 
> 
>> ---------
>> 
>> HTTP/1.1 502 Bad Gateway
>> 
>> Server: squid/6.6
>> 
>> Mime-Version: 1.0
>> 
>> Date: Fri, 12 Jul 2024 14:57:08 GMT
>> 
>> Content-Type: text/html;charset=utf-8
>> 
>> Content-Length: 3629
>> 
>> X-Squid-Error: ERR_READ_ERROR 0
>> 
>> Vary: Accept-Language
>> 
>> Content-Language: en
>> 
>> Cache-Status: squid.host;detail=mismatch
>> 
>> Via: 1.1 squid.host (squid/6.6)
>> 
>> Connection: keep-alive
>> 
>> ----------
>> 
>> Regards,
>> 
>> Ben.
>> 
>> *From: *squid-users <squid-users-bounces at lists.squid-cache.org> on 
>> behalf of Amos Jeffries <squid3 at treenet.co.nz>
>> *Date: *Friday, 12 July 2024 at 15:22
>> *To: *squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
>> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>> 
>> 
>> On 13/07/24 01:52, Alex Rousskov wrote:
>>> On 2024-07-12 08:06, Ben Toms wrote:
>>>> Seems that my issue is similar to - 
>>>> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>
>>> 
>>> You are facing up to two problems:
>>> 
>>> 1. Some authenticated responses are not cachable by Squid. Please share 
>>> HTTP headers of the response in question.
>>> 
>> 
>> FYI, those can be obtained by configuring squid.conf with
>> 
>>? ?? debug_options 11,2
>> 
>> 
>> Cheers
>> Amos
>> 
>> 
>>> 2. TCP_MISS_ABORTED/502 errors may delete a being-cached response. These 
>>> can be bogus errors (essentially Squid logging bugs) or real ones (e.g., 
>>> due to communication bugs, misconfiguration, or compatibility problems). 
>>> I recommend adding %err_code/%err_detail to your logformat and sharing 
>>> the corresponding access.log lines (obfuscated as needed).
>>> 
>>> Sharing (privately if needed) a pointer to compressed ALL,9 cache.log 
>>> while reproducing the issue using a single transaction may help us 
>>> resolve all the unknowns:
>>> 
>>> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>>
>>> 
>>> 
>>> HTH,
>>> 
>>> Alex.
>>> 
>>> 
>> 
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>
>> <https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>>
>> 
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>
> 



From squid3 at treenet.co.nz  Fri Jul 12 16:52:27 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 13 Jul 2024 04:52:27 +1200
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
Message-ID: <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>

On 13/07/24 04:16, Jonathan Lee wrote:
> tested with removal of IP and port failed If I leave port I get this
> 
> 2024/07/12 09:15:17| Processing: http_port :3128 intercept

No  ":" before thr port number.


Amos


From ben at macmule.com  Fri Jul 12 16:56:34 2024
From: ben at macmule.com (Ben Toms)
Date: Fri, 12 Jul 2024 16:56:34 +0000
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <0377b31b-4ec0-4b29-8651-a7984210e446@measurement-factory.com>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165DBB8AF9A1068155EE38EFEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316510765BD02C033497EC99FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <23084e58-c287-435a-9106-9ee12e81605a@measurement-factory.com>
 <af509e63-7d63-4e3a-8991-8961e65aaa4c@treenet.co.nz>
 <LO2P265MB3165A2095FB83CD85137D8A4FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165E5F9F32931620EE1F794FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <1ee387d1-732e-4504-8d00-2d8a0c243d8a@measurement-factory.com>
 <LO2P265MB31651D6F080E7EF06AD34E21FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <0377b31b-4ec0-4b29-8651-a7984210e446@measurement-factory.com>
Message-ID: <LO2P265MB3165A66218D288B5873339B6FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>

So, with the below config:

https_port 443 accel protocol=HTTPS tls-cert=/usr/local/squid/client.pem tls-key=/usr/local/squid/client.key
cache_peer public.server.fqdn parent 443 0 no-query originserver no-digest no-netdb-exchange tls login=PASSTHRU name=myAccel forceddomain=public.server.fqdn
acl our_sites dstdomain local.server.fqdn
http_access allow our_sites
cache_peer_access myAccel allow our_sites
cache_peer_access myAccel deny all
cache_dir ufs /usr/local/squid/var/cache 100000 16 256
cache_mem 500 MB
maximum_object_size_in_memory 50000 KB
refresh_pattern .               0       20%     4320
debug_options 11,2

I can see the below in /var/log/squid/cache.log
----------
2024/07/12 16:49:57.056 kid1| 11,2| http.cc(1263) readReply: conn12 local=client.ip:56670 remote=public.ip.of.public.server:443 FIRSTUP_PARENT FD 14 flags=1: read failure: (0) No error.
2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(273) sendStartOfMessage: HTTP Client conn9 local=client.ip:443 remote=local.server.ip:59158 FD 13 flags=1
2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(274) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 502 Bad Gateway
Server: squid/6.6
Mime-Version: 1.0
Date: Fri, 12 Jul 2024 16:49:57 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3629
X-Squid-Error: ERR_READ_ERROR 0
Vary: Accept-Language
Content-Language: en
Cache-Status: local.server;detail=mismatch
Via: 1.1 local.server (squid/6.6)
Connection: keep-alive


----------

The apache server still shows a 200 for the request:
[12/Jul/2024:17:49:57 +0100] "GET /path/to/file HTTP/1.1" 200 10465 "-" "curl/8.7.1"

And this is when testing via:
curl -D - https://local.server.fqdn/path/to/file -H "Authorization: Basic base64auth" -o /dev/null

Regards,
Ben.

From: Alex Rousskov <rousskov at measurement-factory.com>
Date: Friday, 12 July 2024 at 17:36
To: Ben Toms <ben at macmule.com>, squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] TCP_MISS_ABORTED/502
On 2024-07-12 12:14, Ben Toms wrote:

> Which log should those be found?

cache.log (if they are present)


> Can?t see ?HTTP Server RESPONSE? in the access.log or cache.log.

Sigh. This is one of the reasons I avoid asking folks to study logs
themselves, even ALL,2 logs...

If that line is not in cache.log, then child Squid probably did not
receive a response from parent Squid, or could not parse that response.
A full debugging log should give us more information.

Alex.


> *From: *squid-users <squid-users-bounces at lists.squid-cache.org> on
> behalf of Alex Rousskov <rousskov at measurement-factory.com>
> *Date: *Friday, 12 July 2024 at 17:11
> *To: *squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>
> On 2024-07-12 11:38, Ben Toms wrote:
>> Think I made the changes Alex requested:
>>
>> 12/Jul/2024:15:36:31 +0000.640 local.server.ip TCP_MISS_ABORTED/502 3974
>> GET https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file> -
>> FIRSTUP_PARENT/public.ip.of.public.server text/html
>> ERR_READ_ERROR/WITH_SERVER
>
> Thank you for using Squid v6 for this test.
>
> Unfortunately, due to Squid logging bugs, ERR_READ_ERROR/WITH_SERVER
> does not always mean what it says. For example, parent Squid could have
> closed the child-parent connection prematurely, but there could be other
> reasons. A full debugging log should give us more information.
>
>
>> 2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(274) sendStartOfMessage:
>> HTTP Client REPLY:
>
> This is a child proxy response to the client. We need parent response to
> the child proxy. Look for "HTTP Server RESPONSE" lines instead.
>
>
> HTH,
>
> Alex.
>
>
>
>> ---------
>>
>> HTTP/1.1 502 Bad Gateway
>>
>> Server: squid/6.6
>>
>> Mime-Version: 1.0
>>
>> Date: Fri, 12 Jul 2024 14:57:08 GMT
>>
>> Content-Type: text/html;charset=utf-8
>>
>> Content-Length: 3629
>>
>> X-Squid-Error: ERR_READ_ERROR 0
>>
>> Vary: Accept-Language
>>
>> Content-Language: en
>>
>> Cache-Status: squid.host;detail=mismatch
>>
>> Via: 1.1 squid.host (squid/6.6)
>>
>> Connection: keep-alive
>>
>> ----------
>>
>> Regards,
>>
>> Ben.
>>
>> *From: *squid-users <squid-users-bounces at lists.squid-cache.org> on
>> behalf of Amos Jeffries <squid3 at treenet.co.nz>
>> *Date: *Friday, 12 July 2024 at 15:22
>> *To: *squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
>> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>>
>>
>> On 13/07/24 01:52, Alex Rousskov wrote:
>>> On 2024-07-12 08:06, Ben Toms wrote:
>>>> Seems that my issue is similar to -
>>>> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>
>>>
>>> You are facing up to two problems:
>>>
>>> 1. Some authenticated responses are not cachable by Squid. Please share
>>> HTTP headers of the response in question.
>>>
>>
>> FYI, those can be obtained by configuring squid.conf with
>>
>>     debug_options 11,2
>>
>>
>> Cheers
>> Amos
>>
>>
>>> 2. TCP_MISS_ABORTED/502 errors may delete a being-cached response. These
>>> can be bogus errors (essentially Squid logging bugs) or real ones (e.g.,
>>> due to communication bugs, misconfiguration, or compatibility problems).
>>> I recommend adding %err_code/%err_detail to your logformat and sharing
>>> the corresponding access.log lines (obfuscated as needed).
>>>
>>> Sharing (privately if needed) a pointer to compressed ALL,9 cache.log
>>> while reproducing the issue using a single transaction may help us
>>> resolve all the unknowns:
>>>
>>> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>>
>>>
>>>
>>> HTH,
>>>
>>> Alex.
>>>
>>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> <https://lists.squid-cache.org/listinfo/squid-users>
>> <https://lists.squid-cache.org/listinfo/squid-users
> <https://lists.squid-cache.org/listinfo/squid-users>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> <https://lists.squid-cache.org/listinfo/squid-users>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
> <https://lists.squid-cache.org/listinfo/squid-users>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/14b5216a/attachment.htm>

From ben at macmule.com  Fri Jul 12 17:03:21 2024
From: ben at macmule.com (Ben Toms)
Date: Fri, 12 Jul 2024 17:03:21 +0000
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <LO2P265MB3165A66218D288B5873339B6FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165DBB8AF9A1068155EE38EFEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316510765BD02C033497EC99FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <23084e58-c287-435a-9106-9ee12e81605a@measurement-factory.com>
 <af509e63-7d63-4e3a-8991-8961e65aaa4c@treenet.co.nz>
 <LO2P265MB3165A2095FB83CD85137D8A4FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165E5F9F32931620EE1F794FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <1ee387d1-732e-4504-8d00-2d8a0c243d8a@measurement-factory.com>
 <LO2P265MB31651D6F080E7EF06AD34E21FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <0377b31b-4ec0-4b29-8651-a7984210e446@measurement-factory.com>
 <LO2P265MB3165A66218D288B5873339B6FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <LO2P265MB316511FB262897B4C5F4AC69FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>

And, just to confirm.. if I change public.server.fqdn to that my blog (macmule.com).. I can curl down a file from that via squid-cache fine:

curl -D - https://local.server.fqdn/AutoCasperNBI-AppCast.xml -o /dev/null
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0HTTP/1.1 200 OK
Date: Fri, 12 Jul 2024 11:04:24 GMT
Server: Apache
Last-Modified: Sat, 04 May 2019 13:21:20 GMT
ETag: "69d9d-75b7-5880fbe2c1400"
Accept-Ranges: bytes
Content-Length: 30135
Vary: Accept-Encoding
Content-Type: application/xml
Age: 21285
Cache-Status: local.server;hit;detail=match
Via: 1.1 local.server (squid/6.6)
Connection: keep-alive

100 30135  100 30135    0     0  96335      0 --:--:-- --:--:-- --:--:-- 96277

So the issue seems to be caching content that requires authentication, hence saying the issues seems to be what is stated at: https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication

The question here is, can squid cache items that require authentication to access?

Regards,
Ben.

From: Ben Toms <ben at macmule.com>
Date: Friday, 12 July 2024 at 17:56
To: Alex Rousskov <rousskov at measurement-factory.com>, squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] TCP_MISS_ABORTED/502
So, with the below config:

https_port 443 accel protocol=HTTPS tls-cert=/usr/local/squid/client.pem tls-key=/usr/local/squid/client.key
cache_peer public.server.fqdn parent 443 0 no-query originserver no-digest no-netdb-exchange tls login=PASSTHRU name=myAccel forceddomain=public.server.fqdn
acl our_sites dstdomain local.server.fqdn
http_access allow our_sites
cache_peer_access myAccel allow our_sites
cache_peer_access myAccel deny all
cache_dir ufs /usr/local/squid/var/cache 100000 16 256
cache_mem 500 MB
maximum_object_size_in_memory 50000 KB
refresh_pattern .               0       20%     4320
debug_options 11,2

I can see the below in /var/log/squid/cache.log
----------
2024/07/12 16:49:57.056 kid1| 11,2| http.cc(1263) readReply: conn12 local=client.ip:56670 remote=public.ip.of.public.server:443 FIRSTUP_PARENT FD 14 flags=1: read failure: (0) No error.
2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(273) sendStartOfMessage: HTTP Client conn9 local=client.ip:443 remote=local.server.ip:59158 FD 13 flags=1
2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(274) sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 502 Bad Gateway
Server: squid/6.6
Mime-Version: 1.0
Date: Fri, 12 Jul 2024 16:49:57 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3629
X-Squid-Error: ERR_READ_ERROR 0
Vary: Accept-Language
Content-Language: en
Cache-Status: local.server;detail=mismatch
Via: 1.1 local.server (squid/6.6)
Connection: keep-alive


----------

The apache server still shows a 200 for the request:
[12/Jul/2024:17:49:57 +0100] "GET /path/to/file HTTP/1.1" 200 10465 "-" "curl/8.7.1"

And this is when testing via:
curl -D - https://local.server.fqdn/path/to/file -H "Authorization: Basic base64auth" -o /dev/null

Regards,
Ben.

From: Alex Rousskov <rousskov at measurement-factory.com>
Date: Friday, 12 July 2024 at 17:36
To: Ben Toms <ben at macmule.com>, squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] TCP_MISS_ABORTED/502
On 2024-07-12 12:14, Ben Toms wrote:

> Which log should those be found?

cache.log (if they are present)


> Can?t see ?HTTP Server RESPONSE? in the access.log or cache.log.

Sigh. This is one of the reasons I avoid asking folks to study logs
themselves, even ALL,2 logs...

If that line is not in cache.log, then child Squid probably did not
receive a response from parent Squid, or could not parse that response.
A full debugging log should give us more information.

Alex.


> *From: *squid-users <squid-users-bounces at lists.squid-cache.org> on
> behalf of Alex Rousskov <rousskov at measurement-factory.com>
> *Date: *Friday, 12 July 2024 at 17:11
> *To: *squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>
> On 2024-07-12 11:38, Ben Toms wrote:
>> Think I made the changes Alex requested:
>>
>> 12/Jul/2024:15:36:31 +0000.640 local.server.ip TCP_MISS_ABORTED/502 3974
>> GET https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file> -
>> FIRSTUP_PARENT/public.ip.of.public.server text/html
>> ERR_READ_ERROR/WITH_SERVER
>
> Thank you for using Squid v6 for this test.
>
> Unfortunately, due to Squid logging bugs, ERR_READ_ERROR/WITH_SERVER
> does not always mean what it says. For example, parent Squid could have
> closed the child-parent connection prematurely, but there could be other
> reasons. A full debugging log should give us more information.
>
>
>> 2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(274) sendStartOfMessage:
>> HTTP Client REPLY:
>
> This is a child proxy response to the client. We need parent response to
> the child proxy. Look for "HTTP Server RESPONSE" lines instead.
>
>
> HTH,
>
> Alex.
>
>
>
>> ---------
>>
>> HTTP/1.1 502 Bad Gateway
>>
>> Server: squid/6.6
>>
>> Mime-Version: 1.0
>>
>> Date: Fri, 12 Jul 2024 14:57:08 GMT
>>
>> Content-Type: text/html;charset=utf-8
>>
>> Content-Length: 3629
>>
>> X-Squid-Error: ERR_READ_ERROR 0
>>
>> Vary: Accept-Language
>>
>> Content-Language: en
>>
>> Cache-Status: squid.host;detail=mismatch
>>
>> Via: 1.1 squid.host (squid/6.6)
>>
>> Connection: keep-alive
>>
>> ----------
>>
>> Regards,
>>
>> Ben.
>>
>> *From: *squid-users <squid-users-bounces at lists.squid-cache.org> on
>> behalf of Amos Jeffries <squid3 at treenet.co.nz>
>> *Date: *Friday, 12 July 2024 at 15:22
>> *To: *squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
>> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>>
>>
>> On 13/07/24 01:52, Alex Rousskov wrote:
>>> On 2024-07-12 08:06, Ben Toms wrote:
>>>> Seems that my issue is similar to -
>>>> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>
>>>
>>> You are facing up to two problems:
>>>
>>> 1. Some authenticated responses are not cachable by Squid. Please share
>>> HTTP headers of the response in question.
>>>
>>
>> FYI, those can be obtained by configuring squid.conf with
>>
>>     debug_options 11,2
>>
>>
>> Cheers
>> Amos
>>
>>
>>> 2. TCP_MISS_ABORTED/502 errors may delete a being-cached response. These
>>> can be bogus errors (essentially Squid logging bugs) or real ones (e.g.,
>>> due to communication bugs, misconfiguration, or compatibility problems).
>>> I recommend adding %err_code/%err_detail to your logformat and sharing
>>> the corresponding access.log lines (obfuscated as needed).
>>>
>>> Sharing (privately if needed) a pointer to compressed ALL,9 cache.log
>>> while reproducing the issue using a single transaction may help us
>>> resolve all the unknowns:
>>>
>>> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>>
>>>
>>>
>>> HTH,
>>>
>>> Alex.
>>>
>>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> <https://lists.squid-cache.org/listinfo/squid-users>
>> <https://lists.squid-cache.org/listinfo/squid-users
> <https://lists.squid-cache.org/listinfo/squid-users>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> <https://lists.squid-cache.org/listinfo/squid-users>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
> <https://lists.squid-cache.org/listinfo/squid-users>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/b56ac9a9/attachment.htm>

From rousskov at measurement-factory.com  Fri Jul 12 17:26:53 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 12 Jul 2024 13:26:53 -0400
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <LO2P265MB316511FB262897B4C5F4AC69FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165DBB8AF9A1068155EE38EFEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316510765BD02C033497EC99FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <23084e58-c287-435a-9106-9ee12e81605a@measurement-factory.com>
 <af509e63-7d63-4e3a-8991-8961e65aaa4c@treenet.co.nz>
 <LO2P265MB3165A2095FB83CD85137D8A4FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165E5F9F32931620EE1F794FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <1ee387d1-732e-4504-8d00-2d8a0c243d8a@measurement-factory.com>
 <LO2P265MB31651D6F080E7EF06AD34E21FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <0377b31b-4ec0-4b29-8651-a7984210e446@measurement-factory.com>
 <LO2P265MB3165A66218D288B5873339B6FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316511FB262897B4C5F4AC69FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <73240ae0-6bc0-4094-8d23-435d2c21913c@measurement-factory.com>

On 2024-07-12 13:03, Ben Toms wrote:

> So the issue seems to be caching content that requires authentication

The client is getting an error response from Squid. That error is 
probably not related to caching decisions. I do not recommend focusing 
on caching at this stage of triage. I recommend addressing that error first.


> The question here is, can squid cache items that require authentication 
> to access?

Yes, in some cases. To know whether your case qualifies, I asked for the 
response headers. That led to the discovery that there are none (from 
child Squid point of view). If you really want to investigate the 
caching angle in parallel with solving ERR_READ_ERROR/WITH_SERVER, then 
try to obtain HTTP response headers that the origin server responds (to 
the parent cache) with.


HTH,

Alex.


> *From: *Ben Toms <ben at macmule.com>
> *Date: *Friday, 12 July 2024 at 17:56
> *To: *Alex Rousskov <rousskov at measurement-factory.com>, 
> squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
> 
> So, with the below config:
> 
> https_port 443 accel protocol=HTTPS tls-cert=/usr/local/squid/client.pem 
> tls-key=/usr/local/squid/client.key
> 
> cache_peer public.server.fqdn parent 443 0 no-query originserver 
> no-digest no-netdb-exchange tls login=PASSTHRU name=myAccel 
> forceddomain=public.server.fqdn
> 
> acl our_sites dstdomain local.server.fqdn
> 
> http_access allow our_sites
> 
> cache_peer_access myAccel allow our_sites
> 
> cache_peer_access myAccel deny all
> 
> cache_dir ufs /usr/local/squid/var/cache 100000 16 256
> 
> cache_mem 500 MB
> 
> maximum_object_size_in_memory 50000 KB
> 
> refresh_pattern .?????????????? 0?????? 20%???? 4320
> 
> debug_options 11,2
> 
> I can see the below in /var/log/squid/cache.log
> 
> ----------
> 
> 2024/07/12 16:49:57.056 kid1| 11,2| http.cc(1263) readReply: conn12 
> local=client.ip:56670 remote=public.ip.of.public.server:443 
> FIRSTUP_PARENT FD 14 flags=1: read failure: (0) No error.
> 
> 2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(273) sendStartOfMessage: 
> HTTP Client conn9 local=client.ip:443 remote=local.server.ip:59158 FD 13 
> flags=1
> 
> 2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(274) sendStartOfMessage: 
> HTTP Client REPLY:
> 
> ---------
> 
> HTTP/1.1 502 Bad Gateway
> 
> Server: squid/6.6
> 
> Mime-Version: 1.0
> 
> Date: Fri, 12 Jul 2024 16:49:57 GMT
> 
> Content-Type: text/html;charset=utf-8
> 
> Content-Length: 3629
> 
> X-Squid-Error: ERR_READ_ERROR 0
> 
> Vary: Accept-Language
> 
> Content-Language: en
> 
> Cache-Status: local.server;detail=mismatch
> 
> Via: 1.1 local.server (squid/6.6)
> 
> Connection: keep-alive
> 
> ----------
> 
> The apache server still shows a 200 for the request:
> 
> [12/Jul/2024:17:49:57 +0100] "GET /path/to/file HTTP/1.1" 200 10465 "-" 
> "curl/8.7.1"
> 
> And this is when testing via:
> 
> curl -D - https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file> -H "Authorization: Basic 
> base64auth" -o /dev/null
> 
> Regards,
> 
> Ben.
> 
> *From: *Alex Rousskov <rousskov at measurement-factory.com>
> *Date: *Friday, 12 July 2024 at 17:36
> *To: *Ben Toms <ben at macmule.com>, squid-users at lists.squid-cache.org 
> <squid-users at lists.squid-cache.org>
> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
> 
> On 2024-07-12 12:14, Ben Toms wrote:
> 
>> Which log should those be found?
> 
> cache.log (if they are present)
> 
> 
>> Can?t see ?HTTP Server RESPONSE? in the access.log or cache.log.
> 
> Sigh. This is one of the reasons I avoid asking folks to study logs
> themselves, even ALL,2 logs...
> 
> If that line is not in cache.log, then child Squid probably did not
> receive a response from parent Squid, or could not parse that response.
> A full debugging log should give us more information.
> 
> Alex.
> 
> 
>> *From: *squid-users <squid-users-bounces at lists.squid-cache.org> on 
>> behalf of Alex Rousskov <rousskov at measurement-factory.com>
>> *Date: *Friday, 12 July 2024 at 17:11
>> *To: *squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
>> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>> 
>> On 2024-07-12 11:38, Ben Toms wrote:
>>> Think I made the changes Alex requested:
>>> 
>>> 12/Jul/2024:15:36:31 +0000.640 local.server.ip TCP_MISS_ABORTED/502 3974 
>>> GET https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>
>> <https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>> -
>>> FIRSTUP_PARENT/public.ip.of.public.server text/html 
>>> ERR_READ_ERROR/WITH_SERVER
>> 
>> Thank you for using Squid v6 for this test.
>> 
>> Unfortunately, due to Squid logging bugs, ERR_READ_ERROR/WITH_SERVER
>> does not always mean what it says. For example, parent Squid could have
>> closed the child-parent connection prematurely, but there could be other
>> reasons. A full debugging log should give us more information.
>> 
>> 
>>> 2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(274) sendStartOfMessage: 
>>> HTTP Client REPLY:
>> 
>> This is a child proxy response to the client. We need parent response to
>> the child proxy. Look for "HTTP Server RESPONSE" lines instead.
>> 
>> 
>> HTH,
>> 
>> Alex.
>> 
>> 
>> 
>>> ---------
>>> 
>>> HTTP/1.1 502 Bad Gateway
>>> 
>>> Server: squid/6.6
>>> 
>>> Mime-Version: 1.0
>>> 
>>> Date: Fri, 12 Jul 2024 14:57:08 GMT
>>> 
>>> Content-Type: text/html;charset=utf-8
>>> 
>>> Content-Length: 3629
>>> 
>>> X-Squid-Error: ERR_READ_ERROR 0
>>> 
>>> Vary: Accept-Language
>>> 
>>> Content-Language: en
>>> 
>>> Cache-Status: squid.host;detail=mismatch
>>> 
>>> Via: 1.1 squid.host (squid/6.6)
>>> 
>>> Connection: keep-alive
>>> 
>>> ----------
>>> 
>>> Regards,
>>> 
>>> Ben.
>>> 
>>> *From: *squid-users <squid-users-bounces at lists.squid-cache.org> on 
>>> behalf of Amos Jeffries <squid3 at treenet.co.nz>
>>> *Date: *Friday, 12 July 2024 at 15:22
>>> *To: *squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
>>> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>>> 
>>> 
>>> On 13/07/24 01:52, Alex Rousskov wrote:
>>>> On 2024-07-12 08:06, Ben Toms wrote:
>>>>> Seems that my issue is similar to - 
>>>>> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>>
>>>> 
>>>> You are facing up to two problems:
>>>> 
>>>> 1. Some authenticated responses are not cachable by Squid. Please share 
>>>> HTTP headers of the response in question.
>>>> 
>>> 
>>> FYI, those can be obtained by configuring squid.conf with
>>> 
>>>? ?? debug_options 11,2
>>> 
>>> 
>>> Cheers
>>> Amos
>>> 
>>> 
>>>> 2. TCP_MISS_ABORTED/502 errors may delete a being-cached response. These 
>>>> can be bogus errors (essentially Squid logging bugs) or real ones (e.g., 
>>>> due to communication bugs, misconfiguration, or compatibility problems). 
>>>> I recommend adding %err_code/%err_detail to your logformat and sharing 
>>>> the corresponding access.log lines (obfuscated as needed).
>>>> 
>>>> Sharing (privately if needed) a pointer to compressed ALL,9 cache.log 
>>>> while reproducing the issue using a single transaction may help us 
>>>> resolve all the unknowns:
>>>> 
>>>> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>>>
>>>> 
>>>> 
>>>> HTH,
>>>> 
>>>> Alex.
>>>> 
>>>> 
>>> 
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>
>> <https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>>
>>> <https://lists.squid-cache.org/listinfo/squid-users 
>> <https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>>>
>>> 
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>
>> <https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>>
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>
>> <https://lists.squid-cache.org/listinfo/squid-users 
> <https://lists.squid-cache.org/listinfo/squid-users>>
>> 
> 



From ben at macmule.com  Fri Jul 12 17:38:43 2024
From: ben at macmule.com (Ben Toms)
Date: Fri, 12 Jul 2024 18:38:43 +0100
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <73240ae0-6bc0-4094-8d23-435d2c21913c@measurement-factory.com>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <LO2P265MB31654E5CF00152BDAA416E43FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165DBB8AF9A1068155EE38EFEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316510765BD02C033497EC99FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <23084e58-c287-435a-9106-9ee12e81605a@measurement-factory.com>
 <af509e63-7d63-4e3a-8991-8961e65aaa4c@treenet.co.nz>
 <LO2P265MB3165A2095FB83CD85137D8A4FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165E5F9F32931620EE1F794FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <1ee387d1-732e-4504-8d00-2d8a0c243d8a@measurement-factory.com>
 <LO2P265MB31651D6F080E7EF06AD34E21FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <0377b31b-4ec0-4b29-8651-a7984210e446@measurement-factory.com>
 <LO2P265MB3165A66218D288B5873339B6FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316511FB262897B4C5F4AC69FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <73240ae0-6bc0-4094-8d23-435d2c21913c@measurement-factory.com>
Message-ID: <CADjniur4VwfGPReOWMGjnxkgWHcDfCsSjsj+NMNkvpD=82ai7g@mail.gmail.com>

Thanks, Alex.

Where would I find those headers?

Looking at the origin servers apache logs.. it?s sending a 200 response.


Regards,

Ben


On Fri, 12 Jul 2024 at 18:26, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 2024-07-12 13:03, Ben Toms wrote:
>
> > So the issue seems to be caching content that requires authentication
>
> The client is getting an error response from Squid. That error is
> probably not related to caching decisions. I do not recommend focusing
> on caching at this stage of triage. I recommend addressing that error
> first.
>
>
> > The question here is, can squid cache items that require authentication
> > to access?
>
> Yes, in some cases. To know whether your case qualifies, I asked for the
> response headers. That led to the discovery that there are none (from
> child Squid point of view). If you really want to investigate the
> caching angle in parallel with solving ERR_READ_ERROR/WITH_SERVER, then
> try to obtain HTTP response headers that the origin server responds (to
> the parent cache) with.
>
>
> HTH,
>
> Alex.
>
>
> > *From: *Ben Toms <ben at macmule.com>
> > *Date: *Friday, 12 July 2024 at 17:56
> > *To: *Alex Rousskov <rousskov at measurement-factory.com>,
> > squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
> > *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
> >
> > So, with the below config:
> >
> > https_port 443 accel protocol=HTTPS tls-cert=/usr/local/squid/client.pem
> > tls-key=/usr/local/squid/client.key
> >
> > cache_peer public.server.fqdn parent 443 0 no-query originserver
> > no-digest no-netdb-exchange tls login=PASSTHRU name=myAccel
> > forceddomain=public.server.fqdn
> >
> > acl our_sites dstdomain local.server.fqdn
> >
> > http_access allow our_sites
> >
> > cache_peer_access myAccel allow our_sites
> >
> > cache_peer_access myAccel deny all
> >
> > cache_dir ufs /usr/local/squid/var/cache 100000 16 256
> >
> > cache_mem 500 MB
> >
> > maximum_object_size_in_memory 50000 KB
> >
> > refresh_pattern .               0       20%     4320
> >
> > debug_options 11,2
> >
> > I can see the below in /var/log/squid/cache.log
> >
> > ----------
> >
> > 2024/07/12 16:49:57.056 kid1| 11,2| http.cc(1263) readReply: conn12
> > local=client.ip:56670 remote=public.ip.of.public.server:443
> > FIRSTUP_PARENT FD 14 flags=1: read failure: (0) No error.
> >
> > 2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(273) sendStartOfMessage:
> > HTTP Client conn9 local=client.ip:443 remote=local.server.ip:59158 FD 13
> > flags=1
> >
> > 2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(274) sendStartOfMessage:
> > HTTP Client REPLY:
> >
> > ---------
> >
> > HTTP/1.1 502 Bad Gateway
> >
> > Server: squid/6.6
> >
> > Mime-Version: 1.0
> >
> > Date: Fri, 12 Jul 2024 16:49:57 GMT
> >
> > Content-Type: text/html;charset=utf-8
> >
> > Content-Length: 3629
> >
> > X-Squid-Error: ERR_READ_ERROR 0
> >
> > Vary: Accept-Language
> >
> > Content-Language: en
> >
> > Cache-Status: local.server;detail=mismatch
> >
> > Via: 1.1 local.server (squid/6.6)
> >
> > Connection: keep-alive
> >
> > ----------
> >
> > The apache server still shows a 200 for the request:
> >
> > [12/Jul/2024:17:49:57 +0100] "GET /path/to/file HTTP/1.1" 200 10465 "-"
> > "curl/8.7.1"
> >
> > And this is when testing via:
> >
> > curl -D - https://local.server.fqdn/path/to/file
> > <https://local.server.fqdn/path/to/file> -H "Authorization: Basic
> > base64auth" -o /dev/null
> >
> > Regards,
> >
> > Ben.
> >
> > *From: *Alex Rousskov <rousskov at measurement-factory.com>
> > *Date: *Friday, 12 July 2024 at 17:36
> > *To: *Ben Toms <ben at macmule.com>, squid-users at lists.squid-cache.org
> > <squid-users at lists.squid-cache.org>
> > *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
> >
> > On 2024-07-12 12:14, Ben Toms wrote:
> >
> >> Which log should those be found?
> >
> > cache.log (if they are present)
> >
> >
> >> Can?t see ?HTTP Server RESPONSE? in the access.log or cache.log.
> >
> > Sigh. This is one of the reasons I avoid asking folks to study logs
> > themselves, even ALL,2 logs...
> >
> > If that line is not in cache.log, then child Squid probably did not
> > receive a response from parent Squid, or could not parse that response.
> > A full debugging log should give us more information.
> >
> > Alex.
> >
> >
> >> *From: *squid-users <squid-users-bounces at lists.squid-cache.org> on
> >> behalf of Alex Rousskov <rousskov at measurement-factory.com>
> >> *Date: *Friday, 12 July 2024 at 17:11
> >> *To: *squid-users at lists.squid-cache.org <
> squid-users at lists.squid-cache.org>
> >> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
> >>
> >> On 2024-07-12 11:38, Ben Toms wrote:
> >>> Think I made the changes Alex requested:
> >>>
> >>> 12/Jul/2024:15:36:31 +0000.640 local.server.ip TCP_MISS_ABORTED/502
> 3974
> >>> GET https://local.server.fqdn/path/to/file
> > <https://local.server.fqdn/path/to/file>
> >> <https://local.server.fqdn/path/to/file
> > <https://local.server.fqdn/path/to/file>> -
> >>> FIRSTUP_PARENT/public.ip.of.public.server text/html
> >>> ERR_READ_ERROR/WITH_SERVER
> >>
> >> Thank you for using Squid v6 for this test.
> >>
> >> Unfortunately, due to Squid logging bugs, ERR_READ_ERROR/WITH_SERVER
> >> does not always mean what it says. For example, parent Squid could have
> >> closed the child-parent connection prematurely, but there could be other
> >> reasons. A full debugging log should give us more information.
> >>
> >>
> >>> 2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(274) sendStartOfMessage:
> >>> HTTP Client REPLY:
> >>
> >> This is a child proxy response to the client. We need parent response to
> >> the child proxy. Look for "HTTP Server RESPONSE" lines instead.
> >>
> >>
> >> HTH,
> >>
> >> Alex.
> >>
> >>
> >>
> >>> ---------
> >>>
> >>> HTTP/1.1 502 Bad Gateway
> >>>
> >>> Server: squid/6.6
> >>>
> >>> Mime-Version: 1.0
> >>>
> >>> Date: Fri, 12 Jul 2024 14:57:08 GMT
> >>>
> >>> Content-Type: text/html;charset=utf-8
> >>>
> >>> Content-Length: 3629
> >>>
> >>> X-Squid-Error: ERR_READ_ERROR 0
> >>>
> >>> Vary: Accept-Language
> >>>
> >>> Content-Language: en
> >>>
> >>> Cache-Status: squid.host;detail=mismatch
> >>>
> >>> Via: 1.1 squid.host (squid/6.6)
> >>>
> >>> Connection: keep-alive
> >>>
> >>> ----------
> >>>
> >>> Regards,
> >>>
> >>> Ben.
> >>>
> >>> *From: *squid-users <squid-users-bounces at lists.squid-cache.org> on
> >>> behalf of Amos Jeffries <squid3 at treenet.co.nz>
> >>> *Date: *Friday, 12 July 2024 at 15:22
> >>> *To: *squid-users at lists.squid-cache.org <
> squid-users at lists.squid-cache.org>
> >>> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
> >>>
> >>>
> >>> On 13/07/24 01:52, Alex Rousskov wrote:
> >>>> On 2024-07-12 08:06, Ben Toms wrote:
> >>>>> Seems that my issue is similar to -
> >>>>>
> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication
> <
> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>
> <
> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication
> <
> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>
> <
> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication
> <
> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication
> <
> https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication
> >>>
> >>>>
> >>>> You are facing up to two problems:
> >>>>
> >>>> 1. Some authenticated responses are not cachable by Squid. Please
> share
> >>>> HTTP headers of the response in question.
> >>>>
> >>>
> >>> FYI, those can be obtained by configuring squid.conf with
> >>>
> >>>     debug_options 11,2
> >>>
> >>>
> >>> Cheers
> >>> Amos
> >>>
> >>>
> >>>> 2. TCP_MISS_ABORTED/502 errors may delete a being-cached response.
> These
> >>>> can be bogus errors (essentially Squid logging bugs) or real ones
> (e.g.,
> >>>> due to communication bugs, misconfiguration, or compatibility
> problems).
> >>>> I recommend adding %err_code/%err_detail to your logformat and
> sharing
> >>>> the corresponding access.log lines (obfuscated as needed).
> >>>>
> >>>> Sharing (privately if needed) a pointer to compressed ALL,9 cache.log
> >>>> while reproducing the issue using a single transaction may help us
> >>>> resolve all the unknowns:
> >>>>
> >>>>
> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction
> <
> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>
> <
> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction
> <
> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>>
> <
> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction
> <
> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction
> <
> https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction
> >>>
> >>>>
> >>>>
> >>>> HTH,
> >>>>
> >>>> Alex.
> >>>>
> >>>>
> >>>
> >>>
> >>> _______________________________________________
> >>> squid-users mailing list
> >>> squid-users at lists.squid-cache.org
> >>> https://lists.squid-cache.org/listinfo/squid-users
> > <https://lists.squid-cache.org/listinfo/squid-users>
> >> <https://lists.squid-cache.org/listinfo/squid-users
> > <https://lists.squid-cache.org/listinfo/squid-users>>
> >>> <https://lists.squid-cache.org/listinfo/squid-users
> >> <https://lists.squid-cache.org/listinfo/squid-users
> > <https://lists.squid-cache.org/listinfo/squid-users>>>
> >>>
> >>>
> >>> _______________________________________________
> >>> squid-users mailing list
> >>> squid-users at lists.squid-cache.org
> >>> https://lists.squid-cache.org/listinfo/squid-users
> > <https://lists.squid-cache.org/listinfo/squid-users>
> >> <https://lists.squid-cache.org/listinfo/squid-users
> > <https://lists.squid-cache.org/listinfo/squid-users>>
> >>
> >> _______________________________________________
> >> squid-users mailing list
> >> squid-users at lists.squid-cache.org
> >> https://lists.squid-cache.org/listinfo/squid-users
> > <https://lists.squid-cache.org/listinfo/squid-users>
> >> <https://lists.squid-cache.org/listinfo/squid-users
> > <https://lists.squid-cache.org/listinfo/squid-users>>
> >>
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240712/0ae7aa47/attachment.htm>

From rousskov at measurement-factory.com  Fri Jul 12 18:15:08 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 12 Jul 2024 14:15:08 -0400
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <CADjniur4VwfGPReOWMGjnxkgWHcDfCsSjsj+NMNkvpD=82ai7g@mail.gmail.com>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <LO2P265MB316510765BD02C033497EC99FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <23084e58-c287-435a-9106-9ee12e81605a@measurement-factory.com>
 <af509e63-7d63-4e3a-8991-8961e65aaa4c@treenet.co.nz>
 <LO2P265MB3165A2095FB83CD85137D8A4FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165E5F9F32931620EE1F794FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <1ee387d1-732e-4504-8d00-2d8a0c243d8a@measurement-factory.com>
 <LO2P265MB31651D6F080E7EF06AD34E21FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <0377b31b-4ec0-4b29-8651-a7984210e446@measurement-factory.com>
 <LO2P265MB3165A66218D288B5873339B6FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316511FB262897B4C5F4AC69FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <73240ae0-6bc0-4094-8d23-435d2c21913c@measurement-factory.com>
 <CADjniur4VwfGPReOWMGjnxkgWHcDfCsSjsj+NMNkvpD=82ai7g@mail.gmail.com>
Message-ID: <6712bade-d307-4568-8eb4-14cee7fa997e@measurement-factory.com>

On 2024-07-12 13:38, Ben Toms wrote:

> Where would I find those headers?

If you have access to the parent Squid proxy, they will be in its 
debugging cache.log. You can also get them by capturing network packets 
between the parent Squid and origin, but for HTTPS traffic that requires 
giving Wireshark the associated master keys, which may be possible with 
Squid v6, but not trivial (see tls_key_log in Squid; Apache may have 
better support for this). Finally, one can configure Apache to log them 
(sorry, I do not remember the details).

Again, the child Squid does not see these headers yet (AFAICT), so they 
are not the reason things do not currently "work" in your tests.


> Looking at the origin servers apache logs.. it?s sending a 200 response.

I am aware. We need the headers that go with that 200 OK response. For 
example, if it has Cache-Control:public, then Squid may be able to cache 
it despite authentication.


HTH,

Alex.


> On Fri, 12 Jul 2024 at 18:26, Alex Rousskov wrote:
> 
>     On 2024-07-12 13:03, Ben Toms wrote:
> 
>      > So the issue seems to be caching content that requires authentication
> 
>     The client is getting an error response from Squid. That error is
>     probably not related to caching decisions. I do not recommend focusing
>     on caching at this stage of triage. I recommend addressing that
>     error first.
> 
> 
>      > The question here is, can squid cache items that require
>     authentication
>      > to access?
> 
>     Yes, in some cases. To know whether your case qualifies, I asked for
>     the
>     response headers. That led to the discovery that there are none (from
>     child Squid point of view). If you really want to investigate the
>     caching angle in parallel with solving ERR_READ_ERROR/WITH_SERVER, then
>     try to obtain HTTP response headers that the origin server responds (to
>     the parent cache) with.
> 
> 
>     HTH,
> 
>     Alex.
> 
> 
>      > *From: *Ben Toms <ben at macmule.com <mailto:ben at macmule.com>>
>      > *Date: *Friday, 12 July 2024 at 17:56
>      > *To: *Alex Rousskov <rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>>,
>      > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     <squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>      > *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>      >
>      > So, with the below config:
>      >
>      > https_port 443 accel protocol=HTTPS
>     tls-cert=/usr/local/squid/client.pem
>      > tls-key=/usr/local/squid/client.key
>      >
>      > cache_peer public.server.fqdn parent 443 0 no-query originserver
>      > no-digest no-netdb-exchange tls login=PASSTHRU name=myAccel
>      > forceddomain=public.server.fqdn
>      >
>      > acl our_sites dstdomain local.server.fqdn
>      >
>      > http_access allow our_sites
>      >
>      > cache_peer_access myAccel allow our_sites
>      >
>      > cache_peer_access myAccel deny all
>      >
>      > cache_dir ufs /usr/local/squid/var/cache 100000 16 256
>      >
>      > cache_mem 500 MB
>      >
>      > maximum_object_size_in_memory 50000 KB
>      >
>      > refresh_pattern .?????????????? 0?????? 20%???? 4320
>      >
>      > debug_options 11,2
>      >
>      > I can see the below in /var/log/squid/cache.log
>      >
>      > ----------
>      >
>      > 2024/07/12 16:49:57.056 kid1| 11,2| http.cc(1263) readReply: conn12
>      > local=client.ip:56670 remote=public.ip.of.public.server:443
>      > FIRSTUP_PARENT FD 14 flags=1: read failure: (0) No error.
>      >
>      > 2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(273)
>     sendStartOfMessage:
>      > HTTP Client conn9 local=client.ip:443
>     remote=local.server.ip:59158 FD 13
>      > flags=1
>      >
>      > 2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(274)
>     sendStartOfMessage:
>      > HTTP Client REPLY:
>      >
>      > ---------
>      >
>      > HTTP/1.1 502 Bad Gateway
>      >
>      > Server: squid/6.6
>      >
>      > Mime-Version: 1.0
>      >
>      > Date: Fri, 12 Jul 2024 16:49:57 GMT
>      >
>      > Content-Type: text/html;charset=utf-8
>      >
>      > Content-Length: 3629
>      >
>      > X-Squid-Error: ERR_READ_ERROR 0
>      >
>      > Vary: Accept-Language
>      >
>      > Content-Language: en
>      >
>      > Cache-Status: local.server;detail=mismatch
>      >
>      > Via: 1.1 local.server (squid/6.6)
>      >
>      > Connection: keep-alive
>      >
>      > ----------
>      >
>      > The apache server still shows a 200 for the request:
>      >
>      > [12/Jul/2024:17:49:57 +0100] "GET /path/to/file HTTP/1.1" 200
>     10465 "-"
>      > "curl/8.7.1"
>      >
>      > And this is when testing via:
>      >
>      > curl -D - https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>
>      > <https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>> -H "Authorization: Basic
>      > base64auth" -o /dev/null
>      >
>      > Regards,
>      >
>      > Ben.
>      >
>      > *From: *Alex Rousskov <rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>>
>      > *Date: *Friday, 12 July 2024 at 17:36
>      > *To: *Ben Toms <ben at macmule.com <mailto:ben at macmule.com>>,
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      > <squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>      > *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>      >
>      > On 2024-07-12 12:14, Ben Toms wrote:
>      >
>      >> Which log should those be found?
>      >
>      > cache.log (if they are present)
>      >
>      >
>      >> Can?t see ?HTTP Server RESPONSE? in the access.log or cache.log.
>      >
>      > Sigh. This is one of the reasons I avoid asking folks to study logs
>      > themselves, even ALL,2 logs...
>      >
>      > If that line is not in cache.log, then child Squid probably did not
>      > receive a response from parent Squid, or could not parse that
>     response.
>      > A full debugging log should give us more information.
>      >
>      > Alex.
>      >
>      >
>      >> *From: *squid-users <squid-users-bounces at lists.squid-cache.org
>     <mailto:squid-users-bounces at lists.squid-cache.org>> on
>      >> behalf of Alex Rousskov <rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>>
>      >> *Date: *Friday, 12 July 2024 at 17:11
>      >> *To: *squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     <squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>      >> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>      >>
>      >> On 2024-07-12 11:38, Ben Toms wrote:
>      >>> Think I made the changes Alex requested:
>      >>>
>      >>> 12/Jul/2024:15:36:31 +0000.640 local.server.ip
>     TCP_MISS_ABORTED/502 3974
>      >>> GET https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>
>      > <https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>>
>      >> <https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>
>      > <https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>>> -
>      >>> FIRSTUP_PARENT/public.ip.of.public.server text/html
>      >>> ERR_READ_ERROR/WITH_SERVER
>      >>
>      >> Thank you for using Squid v6 for this test.
>      >>
>      >> Unfortunately, due to Squid logging bugs, ERR_READ_ERROR/WITH_SERVER
>      >> does not always mean what it says. For example, parent Squid
>     could have
>      >> closed the child-parent connection prematurely, but there could
>     be other
>      >> reasons. A full debugging log should give us more information.
>      >>
>      >>
>      >>> 2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(274)
>     sendStartOfMessage:
>      >>> HTTP Client REPLY:
>      >>
>      >> This is a child proxy response to the client. We need parent
>     response to
>      >> the child proxy. Look for "HTTP Server RESPONSE" lines instead.
>      >>
>      >>
>      >> HTH,
>      >>
>      >> Alex.
>      >>
>      >>
>      >>
>      >>> ---------
>      >>>
>      >>> HTTP/1.1 502 Bad Gateway
>      >>>
>      >>> Server: squid/6.6
>      >>>
>      >>> Mime-Version: 1.0
>      >>>
>      >>> Date: Fri, 12 Jul 2024 14:57:08 GMT
>      >>>
>      >>> Content-Type: text/html;charset=utf-8
>      >>>
>      >>> Content-Length: 3629
>      >>>
>      >>> X-Squid-Error: ERR_READ_ERROR 0
>      >>>
>      >>> Vary: Accept-Language
>      >>>
>      >>> Content-Language: en
>      >>>
>      >>> Cache-Status: squid.host;detail=mismatch
>      >>>
>      >>> Via: 1.1 squid.host (squid/6.6)
>      >>>
>      >>> Connection: keep-alive
>      >>>
>      >>> ----------
>      >>>
>      >>> Regards,
>      >>>
>      >>> Ben.
>      >>>
>      >>> *From: *squid-users <squid-users-bounces at lists.squid-cache.org
>     <mailto:squid-users-bounces at lists.squid-cache.org>> on
>      >>> behalf of Amos Jeffries <squid3 at treenet.co.nz
>     <mailto:squid3 at treenet.co.nz>>
>      >>> *Date: *Friday, 12 July 2024 at 15:22
>      >>> *To: *squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     <squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>      >>> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>      >>>
>      >>>
>      >>> On 13/07/24 01:52, Alex Rousskov wrote:
>      >>>> On 2024-07-12 08:06, Ben Toms wrote:
>      >>>>> Seems that my issue is similar to -
>      >>>>>
>     https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>>>
>      >>>>
>      >>>> You are facing up to two problems:
>      >>>>
>      >>>> 1. Some authenticated responses are not cachable by Squid.
>     Please share
>      >>>> HTTP headers of the response in question.
>      >>>>
>      >>>
>      >>> FYI, those can be obtained by configuring squid.conf with
>      >>>
>      >>>? ?? debug_options 11,2
>      >>>
>      >>>
>      >>> Cheers
>      >>> Amos
>      >>>
>      >>>
>      >>>> 2. TCP_MISS_ABORTED/502 errors may delete a being-cached
>     response. These
>      >>>> can be bogus errors (essentially Squid logging bugs) or real
>     ones (e.g.,
>      >>>> due to communication bugs, misconfiguration, or compatibility
>     problems).
>      >>>> I recommend adding %err_code/%err_detail to your logformat and
>     sharing
>      >>>> the corresponding access.log lines (obfuscated as needed).
>      >>>>
>      >>>> Sharing (privately if needed) a pointer to compressed ALL,9
>     cache.log
>      >>>> while reproducing the issue using a single transaction may
>     help us
>      >>>> resolve all the unknowns:
>      >>>>
>      >>>>
>     https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>>> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>>>>
>      >>>>
>      >>>>
>      >>>> HTH,
>      >>>>
>      >>>> Alex.
>      >>>>
>      >>>>
>      >>>
>      >>>
>      >>> _______________________________________________
>      >>> squid-users mailing list
>      >>> squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >>> https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      > <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>
>      >> <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      > <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>>
>      >>> <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >> <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      > <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>>>
>      >>>
>      >>>
>      >>> _______________________________________________
>      >>> squid-users mailing list
>      >>> squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >>> https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      > <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>
>      >> <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      > <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>>
>      >>
>      >> _______________________________________________
>      >> squid-users mailing list
>      >> squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >> https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      > <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>
>      >> <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      > <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>>
>      >>
>      >
> 


From jonathanlee571 at gmail.com  Fri Jul 12 22:28:58 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 12 Jul 2024 15:28:58 -0700
Subject: [squid-users] Tproxy or intercept
Message-ID: <D6683741-0D14-4C9F-A155-370876E4A30C@gmail.com>

For the HTTP and https derivative is it better to use tproxy or intercept on FreeBSD? 
Sent from my iPhone

From ankor2023 at gmail.com  Sat Jul 13 03:57:32 2024
From: ankor2023 at gmail.com (Andrey K)
Date: Sat, 13 Jul 2024 06:57:32 +0300
Subject: [squid-users] Squid 6.6 kick abandoning connections
In-Reply-To: <000201dad260$7bfe07b0$73fa1710$@gmail.com>
References: <4f5375c8-75d6-413f-90fe-7f3fd94647d3@measurement-factory.com>
 <0F6548E6-C076-42B4-AFE0-062C3621F1F3@gmail.com>
 <0bb9752d-8d30-433d-86cb-017961302abd@measurement-factory.com>
 <000201dad260$7bfe07b0$73fa1710$@gmail.com>
Message-ID: <CADJd0Y3LOrRDEzHHBgzdxVkD6VgxB16dB8HSLYtDt74bO+gj9g@mail.gmail.com>

Hello, Jonathan,

>> Does anyone know the path to this file "modified file
'src/client_side_request.cc" so I can test it with the patches application
if it doesn?t work no big deal I can just restore it to to prior and or use
an older boot environment

You can find it in the squid sources:
tar -tvzf squid-6.10.tar.gz | grep src/client_side_request.cc
-rw-rw-r-- kinkie/kinkie  77063 2024-06-08 16:28
squid-6.10/src/client_side_request.cc

Kind regards,
      Ankor

??, 10 ???. 2024??. ? 03:31, <jonathanlee571 at gmail.com>:

> I found the older patch from 2017 I cant find the path to
> client_sid_request.cc in the pfsense filesystem
>
> Does anyone know the path to this file "modified file
> 'src/client_side_request.cc" so I can test it with the patches application
> if it doesn?t work no big deal I can just restore it to to prior and or use
> an older boot environment
>
>
>
>
> kick abandoning [connection]" message in cache.log
>
> This patch call quitAfterError() to force Squid to close the connection
> after
> writing a "Host header forgery" error response  instead of just logging a
> [misleading] "kick abandoning [connection]" message in cache.log.
>
> This is a Measurement Factory project
>
> === modified file 'src/client_side_request.cc'
> --- src/client_side_request.cc  2017-02-07 23:11:33 +0000
> +++ src/client_side_request.cc  2017-03-31 08:00:01 +0000
> @@ -564,40 +564,41 @@
>          debugs(85, 3, "SECURITY ALERT: Host header forgery detected on "
> << http->getConn()->clientConnection <<
>                 " (" << A << " does not match " << B << ") on URL: " <<
> http->request->effectiveRequestUri());
>
>          // NP: it is tempting to use 'flags.noCache' but that is all
> about READing cache data.
>          // The problems here are about WRITE for new cache content, which
> means flags.cachable
>          http->request->flags.cachable = false; // MUST NOT cache (for now)
>          // XXX: when we have updated the cache key to base on raw-IP +
> URI this cacheable limit can go.
>          http->request->flags.hierarchical = false; // MUST NOT pass to
> peers (for now)
>          // XXX: when we have sorted out the best way to relay requests
> properly to peers this hierarchical limit can go.
>          http->doCallouts();
>          return;
>      }
>
>      debugs(85, DBG_IMPORTANT, "SECURITY ALERT: Host header forgery
> detected on " <<
>             http->getConn()->clientConnection << " (" << A << " does not
> match " << B << ")");
>      if (const char *ua =
> http->request->header.getStr(Http::HdrType::USER_AGENT))
>          debugs(85, DBG_IMPORTANT, "SECURITY ALERT: By user agent: " <<
> ua);
>      debugs(85, DBG_IMPORTANT, "SECURITY ALERT: on URL: " <<
> http->request->effectiveRequestUri());
>
>      // IP address validation for Host: failed. reject the connection.
> +    http->getConn()->quitAfterError(http->request);
>      clientStreamNode *node = (clientStreamNode
> *)http->client_stream.tail->prev->data;
>      clientReplyContext *repContext = dynamic_cast<clientReplyContext
> *>(node->data.getRaw());
>      assert (repContext);
>      repContext->setReplyToError(ERR_CONFLICT_HOST, Http::scConflict,
>                                  http->request->method, NULL,
>                                  http->getConn()->clientConnection->remote,
>                                  http->request,
>                                  NULL,
>  #if USE_AUTH
>                                  http->getConn() != NULL &&
> http->getConn()->getAuth() != NULL ?
>                                  http->getConn()->getAuth() :
> http->request->auth_user_request);
>  #else
>                                  NULL);
>  #endif
>      node = (clientStreamNode *)http->client_stream.tail->data;
>      clientStreamRead(node, http, node->readBuffer);
>  }
>
>  void
>  ClientRequestContext::hostHeaderVerify()
>
>
>
> -----Original Message-----
> From: Alex Rousskov <rousskov at measurement-factory.com>
> Sent: Monday, July 8, 2024 10:41 AM
> To: squid-users <squid-users at lists.squid-cache.org>
> Cc: Jonathan Lee <jonathanlee571 at gmail.com>
> Subject: Re: [squid-users] Squid 6.6 kick abandoning connections
>
> On 2024-07-08 12:31, Jonathan Lee wrote:
>
> > I can confirm I have no ipv6 our isp is ipv4 only and I have IPv6
> > disabled on the firewall and with layer 2 and 3 traffic
>
> This problem is not specific to any IP family/version.
>
> Alex.
>
>
> >> On Jul 8, 2024, at 09:15, Alex Rousskov <
> rousskov at measurement-factory.com> wrote:
> >>
> >> ?On 2024-07-05 21:07, Jonathan Lee wrote:
> >>
> >>> I am using Bump with certificates installed on devices does anyone
> know what this error is...
> >>> kick abandoning conn43723 local=192.168.1.1:3128
> >>> remote=192.168.1.5:52129 FD 178 flags=1
> >>
> >>
> >> This "kick abandoning" message marks a Squid problem or bug: Squid
> enters a seemingly impossible state. In some (but probably not all) cases,
> the client connection might become stuck (hopefully until some timeout
> closes it). In some (and possibly all) cases, Squid might immediately close
> the connection and nobody gets hurt. Code reporting this problem does not
> know how we got here and what will happen next.
> >>
> >> There were several incomplete/unfinished attempts to fix this problem,
> including two different patches posted at Bug 3715. I do not know whether
> either of them is safe and applies to Squid v6. Neither is a comprehensive
> solution.
> >> https://bugs.squid-cache.org/show_bug.cgi?id=3715
> >>
> >>
> >>> Does anyone know how to fix my last weird error I have with Squid
> >>> 6.6
> >>
> >> I do not know of a good configuration-based workaround. Squid code
> modifications are required to properly address this problem. Other errors
> may trigger this bug, so addressing those other errors may hide (and reduce
> the pressure to fix) this bug. Besides fixing those other errors (if any --
> I am aware that you have said that there are no other errors left, but
> perhaps you found other problems since then), these basic options apply:
> >>
> >> https://wiki.squid-cache.org/SquidFaq/AboutSquid#how-to-add-a-new-squ
> >> id-feature-enhance-of-fix-something
> >>
> >> Alex.
> >>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240713/77f64bfa/attachment.htm>

From ml at netfence.it  Sat Jul 13 07:46:15 2024
From: ml at netfence.it (Andrea Venturoli)
Date: Sat, 13 Jul 2024 09:46:15 +0200
Subject: [squid-users] Tproxy or intercept
In-Reply-To: <D6683741-0D14-4C9F-A155-370876E4A30C@gmail.com>
References: <D6683741-0D14-4C9F-A155-370876E4A30C@gmail.com>
Message-ID: <02d98d80-be51-42d6-9ee6-3f0c55ab46b1@netfence.it>

On 7/13/24 00:28, Jonathan Lee wrote:
> For the HTTP and https derivative is it better to use tproxy or intercept on FreeBSD?

AFAIK TProxy does not work on FreeBSD, but I'd be glad to be proven wrong.

  bye
	av.



From jonathanlee571 at gmail.com  Sat Jul 13 15:04:33 2024
From: jonathanlee571 at gmail.com (Jonathan David Lee FreeBSD Alpine)
Date: Sat, 13 Jul 2024 08:04:33 -0700 (PDT)
Subject: [squid-users] Tproxy or intercept
In-Reply-To: <02d98d80-be51-42d6-9ee6-3f0c55ab46b1@netfence.it>
References: <D6683741-0D14-4C9F-A155-370876E4A30C@gmail.com>
 <02d98d80-be51-42d6-9ee6-3f0c55ab46b1@netfence.it>
Message-ID: <bb5b1f39-19fa-1ebc-0ea0-ad57020219f8@freeBSDJailsTestVM.mshome.net>

Do you consider pfsense freebsd or openbsd based, becaause it does work, 
it does not in squid 6.6 requires a different ./ command in squid 5.8 you 
can just enable it


On Sat, 13 Jul 2024, Andrea Venturoli wrote:

> On 7/13/24 00:28, Jonathan Lee wrote:
>> For the HTTP and https derivative is it better to use tproxy or intercept 
>> on FreeBSD?
>
> AFAIK TProxy does not work on FreeBSD, but I'd be glad to be proven wrong.
>
> bye
> 	av.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>


From ml at netfence.it  Sat Jul 13 17:52:15 2024
From: ml at netfence.it (Andrea Venturoli)
Date: Sat, 13 Jul 2024 19:52:15 +0200
Subject: [squid-users] Tproxy or intercept
In-Reply-To: <bb5b1f39-19fa-1ebc-0ea0-ad57020219f8@freeBSDJailsTestVM.mshome.net>
References: <D6683741-0D14-4C9F-A155-370876E4A30C@gmail.com>
 <02d98d80-be51-42d6-9ee6-3f0c55ab46b1@netfence.it>
 <bb5b1f39-19fa-1ebc-0ea0-ad57020219f8@freeBSDJailsTestVM.mshome.net>
Message-ID: <fe7f2b64-848f-47ed-95fc-7a964f4e2b87@netfence.it>

On 7/13/24 17:04, Jonathan David Lee FreeBSD Alpine wrote:
> Do you consider pfsense freebsd or openbsd based

I know nothing about pfsense.

> becaause it does work, 

Good to know.
What kind of firewall do you use? ipfw? pf? other?

> it does not in squid 6.6 requires a different ./ command in squid 5.8 
> you can just enable it

Then again, if it doesn't work with 6.6, it's useless to me.

What would be the benefit of using tproxy instead of intercept, anyway?

  bye & Thanks
	av.


From jonathanlee571 at gmail.com  Sat Jul 13 18:48:48 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sat, 13 Jul 2024 11:48:48 -0700
Subject: [squid-users] Tproxy or intercept
In-Reply-To: <fe7f2b64-848f-47ed-95fc-7a964f4e2b87@netfence.it>
References: <fe7f2b64-848f-47ed-95fc-7a964f4e2b87@netfence.it>
Message-ID: <946CAF07-163C-443D-BC2C-10018DFC2215@gmail.com>

It works 6.6 it just have a different requirement to enable it. I am using a Netgate 2100 with pfSense. The difference is that it spoofs the IP of the client so the host doesn?t see the IP of the firewall when using intercept I am told. So transparent with more of a hidden layer 
Sent from my iPhone

> On Jul 13, 2024, at 10:52, Andrea Venturoli <ml at netfence.it> wrote:
> 
> ?On 7/13/24 17:04, Jonathan David Lee FreeBSD Alpine wrote:
>> Do you consider pfsense freebsd or openbsd based
> 
> I know nothing about pfsense.
> 
>> becaause it does work,
> 
> Good to know.
> What kind of firewall do you use? ipfw? pf? other?
> 
>> it does not in squid 6.6 requires a different ./ command in squid 5.8 you can just enable it
> 
> Then again, if it doesn't work with 6.6, it's useless to me.
> 
> What would be the benefit of using tproxy instead of intercept, anyway?
> 
> bye & Thanks
>    av.


From jonathanlee571 at gmail.com  Sat Jul 13 18:53:24 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sat, 13 Jul 2024 11:53:24 -0700
Subject: [squid-users] Tproxy or intercept
In-Reply-To: <946CAF07-163C-443D-BC2C-10018DFC2215@gmail.com>
References: <946CAF07-163C-443D-BC2C-10018DFC2215@gmail.com>
Message-ID: <ACFC3847-BA3E-4F6A-B547-222BFDE18C3E@gmail.com>

Best way to describe it is transparent intercept maybe? tproxy takes place of intercept on the http_port directive 
Sent from my iPhone

> On Jul 13, 2024, at 11:49, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> ?It works 6.6 it just have a different requirement to enable it. I am using a Netgate 2100 with pfSense. The difference is that it spoofs the IP of the client so the host doesn?t see the IP of the firewall when using intercept I am told. So transparent with more of a hidden layer
> Sent from my iPhone
> 
>>> On Jul 13, 2024, at 10:52, Andrea Venturoli <ml at netfence.it> wrote:
>>> 
>>> ?On 7/13/24 17:04, Jonathan David Lee FreeBSD Alpine wrote:
>>> Do you consider pfsense freebsd or openbsd based
>> 
>> I know nothing about pfsense.
>> 
>>> becaause it does work,
>> 
>> Good to know.
>> What kind of firewall do you use? ipfw? pf? other?
>> 
>>> it does not in squid 6.6 requires a different ./ command in squid 5.8 you can just enable it
>> 
>> Then again, if it doesn't work with 6.6, it's useless to me.
>> 
>> What would be the benefit of using tproxy instead of intercept, anyway?
>> 
>> bye & Thanks
>>   av.


From ben at macmule.com  Sat Jul 13 20:02:45 2024
From: ben at macmule.com (Ben Toms)
Date: Sat, 13 Jul 2024 20:02:45 +0000
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <LO2P265MB316592733FD0BB2B08E3B3D8FEA72@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <23084e58-c287-435a-9106-9ee12e81605a@measurement-factory.com>
 <af509e63-7d63-4e3a-8991-8961e65aaa4c@treenet.co.nz>
 <LO2P265MB3165A2095FB83CD85137D8A4FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB3165E5F9F32931620EE1F794FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <1ee387d1-732e-4504-8d00-2d8a0c243d8a@measurement-factory.com>
 <LO2P265MB31651D6F080E7EF06AD34E21FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <0377b31b-4ec0-4b29-8651-a7984210e446@measurement-factory.com>
 <LO2P265MB3165A66218D288B5873339B6FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316511FB262897B4C5F4AC69FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <73240ae0-6bc0-4094-8d23-435d2c21913c@measurement-factory.com>
 <CADjniur4VwfGPReOWMGjnxkgWHcDfCsSjsj+NMNkvpD=82ai7g@mail.gmail.com>
 <6712bade-d307-4568-8eb4-14cee7fa997e@measurement-factory.com>
 <CADjniuoqjKHrXctmOQZLqpTrdquY_4ASFxTc=7H9qCh8WO=x-w@mail.gmail.com>
 <eb142f40-cf47-4a66-8245-d739a0196951@measurement-factory.com>
 <LO2P265MB316592733FD0BB2B08E3B3D8FEA72@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CWLP265MB3156BA85ADAF926FEF663D73FEA72@CWLP265MB3156.GBRP265.PROD.OUTLOOK.COM>

Apologies, Alex. Hadn?t realised that somewhere in my replies things went direct to you and not the list.

Anyways.. with debug_options ALL,4 set.. the cache.log shows:

2024/07/13 18:55:03.581 kid1| 11,2| http.cc(2472) sendRequest: HTTP Server conn17 local=squid.cache.ip:37046 remote=origin.server.ip:443 FIRSTUP_PARENT FD 14 flags=1
2024/07/13 18:55:03.581 kid1| 11,2| http.cc(2473) sendRequest: HTTP Server REQUEST:
---------
GET /path/to/file HTTP/1.1
Host: origin.server.fqdn
User-Agent: curl/8.7.1
Accept: */*
Authorization: Basic base64auth
Via: 1.1 squid.cache.hostname (squid/6.6)
Surrogate-Capability: squid.cache.hostname="Surrogate/1.0 ESI/1.0"
X-Forwarded-For: 192.168.0.132
Cache-Control: max-age=259200
Connection: keep-alive


----------
2024/07/13 18:55:03.581 kid1| 83,3| Session.cc(66) tls_write_method: started for session=0x6496ea7430c0
2024/07/13 18:55:03.581 kid1| 5,3| IoCallback.cc(112) finish: called for conn17 local=squid.cache.ip:37046 remote=origin.server.ip:443 FIRSTUP_PARENT FD 14 flags=1 (0, 0)
2024/07/13 18:55:03.581 kid1| 5,3| comm.cc(599) commSetConnTimeout: conn17 local=squid.cache.ip:37046 remote=origin.server.ip:443 FIRSTUP_PARENT FD 14 flags=1 timeout 900
2024/07/13 18:55:03.595 kid1| 5,3| IoCallback.cc(112) finish: called for conn17 local=squid.cache.ip:37046 remote=origin.server.ip:443 FIRSTUP_PARENT FD 14 flags=1 (0, 0)
2024/07/13 18:55:03.595 kid1| 83,3| Session.cc(36) tls_read_method: started for session=0x6496ea7430c0
2024/07/13 18:55:03.595 kid1| 5,3| Read.cc(93) ReadNow: conn17 local=squid.cache.ip:37046 remote=origin.server.ip:443 FIRSTUP_PARENT FD 14 flags=1, size 65536, retval -28, errno 0
2024/07/13 18:55:03.595 kid1| 5,3| Read.cc(107) ReadNow: conn17 local=squid.cache.ip:37046 remote=origin.server.ip:443 FIRSTUP_PARENT FD 14 flags=1 Comm::COMM_ERROR: (0) No error.
2024/07/13 18:55:03.595 kid1| 11,2| http.cc(1263) readReply: conn17 local=squid.cache.ip:37046 remote=origin.server.ip:443 FIRSTUP_PARENT FD 14 flags=1: read failure: (0) No error.
2024/07/13 18:55:03.595 kid1| 17,3| FwdState.cc(471) fail: ERR_READ_ERROR "Bad Gateway"
                https://origin.server.fqdn/path/to/file
2024/07/13 18:55:03.595 kid1| 17,3| FwdState.cc(512) unregister: https://origin.server.fqdn/path/to/file
2024/07/13 18:55:03.595 kid1| 5,4| AsyncCall.cc(58) cancel: will not call SomeCloseHandler [call252] because comm_remove_close_handler


Still need to dig in more.. but the true error seems to be: ERR_READ_ERROR "Bad Gateway"

Regards,
Ben.

From: Ben Toms <ben at macmule.com>
Date: Saturday, 13 July 2024 at 13:04
To: Alex Rousskov <rousskov at measurement-factory.com>
Subject: Re: [squid-users] TCP_MISS_ABORTED/502
Well.. tried with cache-control headers added to the apache servers responses.. and still no luck (header response below).

Date: Sat, 13 Jul 2024 12:00:02 GMT
Server: Apache
Last-Modified: Thu, 20 Jun 2024 13:57:21 GMT
ETag: "152c-61b52b19bbd2a"
Accept-Ranges: bytes
Content-Length: 5420
Cache-Control: max-age=84600, public
Connection: close

I?ve tried a few other sites and the issue seems to be when attempting to cache an item which requires authentication. Which is bizarre, as the apache server is showing files are being downloaded.. yet squid-cache is still erroring with TCP_MISS_ABORTED/502.

Regards,
Ben.

From: Alex Rousskov <rousskov at measurement-factory.com>
Date: Friday, 12 July 2024 at 22:54
To: Ben Toms <ben at macmule.com>
Subject: Re: [squid-users] TCP_MISS_ABORTED/502
On 2024-07-12 14:31, Ben Toms wrote:

> So this squid cache is the parent (which might speak to me
> misconfiguring squid).
>
> It?s setup as an accelerator for the public server.

Ah, I see. Sorry I forgot or misinterpreted that part. Too many balls in
the air.

Right now, it sounds like origin sent 200 OK, but Squid could not even
parse that response header, which is rather unusual/rare. However, that
theory is based on your interpretation of ALL,2 logs, so there may be
more to the story here.


> When I curl the public server direct, there are no cache control headers.

Understood. I suspect Squid will not cache such authenticated responses
by default (even after Squid starts to receive them), but I have not
checked all the relevant details.


Cheers,

Alex.


> On Fri, 12 Jul 2024 at 19:15, Alex Rousskov  wrote:
>
>     On 2024-07-12 13:38, Ben Toms wrote:
>
>      > Where would I find those headers?
>
>     If you have access to the parent Squid proxy, they will be in its
>     debugging cache.log. You can also get them by capturing network packets
>     between the parent Squid and origin, but for HTTPS traffic that
>     requires
>     giving Wireshark the associated master keys, which may be possible with
>     Squid v6, but not trivial (see tls_key_log in Squid; Apache may have
>     better support for this). Finally, one can configure Apache to log them
>     (sorry, I do not remember the details).
>
>     Again, the child Squid does not see these headers yet (AFAICT), so they
>     are not the reason things do not currently "work" in your tests.
>
>
>      > Looking at the origin servers apache logs.. it?s sending a 200
>     response.
>
>     I am aware. We need the headers that go with that 200 OK response. For
>     example, if it has Cache-Control:public, then Squid may be able to
>     cache
>     it despite authentication.
>
>
>     HTH,
>
>     Alex.
>
>
>      > On Fri, 12 Jul 2024 at 18:26, Alex Rousskov wrote:
>      >
>      >     On 2024-07-12 13:03, Ben Toms wrote:
>      >
>      >      > So the issue seems to be caching content that requires
>     authentication
>      >
>      >     The client is getting an error response from Squid. That error is
>      >     probably not related to caching decisions. I do not recommend
>     focusing
>      >     on caching at this stage of triage. I recommend addressing that
>      >     error first.
>      >
>      >
>      >      > The question here is, can squid cache items that require
>      >     authentication
>      >      > to access?
>      >
>      >     Yes, in some cases. To know whether your case qualifies, I
>     asked for
>      >     the
>      >     response headers. That led to the discovery that there are
>     none (from
>      >     child Squid point of view). If you really want to investigate the
>      >     caching angle in parallel with solving
>     ERR_READ_ERROR/WITH_SERVER, then
>      >     try to obtain HTTP response headers that the origin server
>     responds (to
>      >     the parent cache) with.
>      >
>      >
>      >     HTH,
>      >
>      >     Alex.
>      >
>      >
>      >      > *From: *Ben Toms <ben at macmule.com <mailto:ben at macmule.com>
>     <mailto:ben at macmule.com <mailto:ben at macmule.com>>>
>      >      > *Date: *Friday, 12 July 2024 at 17:56
>      >      > *To: *Alex Rousskov <rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>
>      >     <mailto:rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>>>,
>      >      > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >     <mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>      >     <squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >     <mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>>
>      >      > *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>      >      >
>      >      > So, with the below config:
>      >      >
>      >      > https_port 443 accel protocol=HTTPS
>      >     tls-cert=/usr/local/squid/client.pem
>      >      > tls-key=/usr/local/squid/client.key
>      >      >
>      >      > cache_peer public.server.fqdn parent 443 0 no-query
>     originserver
>      >      > no-digest no-netdb-exchange tls login=PASSTHRU name=myAccel
>      >      > forceddomain=public.server.fqdn
>      >      >
>      >      > acl our_sites dstdomain local.server.fqdn
>      >      >
>      >      > http_access allow our_sites
>      >      >
>      >      > cache_peer_access myAccel allow our_sites
>      >      >
>      >      > cache_peer_access myAccel deny all
>      >      >
>      >      > cache_dir ufs /usr/local/squid/var/cache 100000 16 256
>      >      >
>      >      > cache_mem 500 MB
>      >      >
>      >      > maximum_object_size_in_memory 50000 KB
>      >      >
>      >      > refresh_pattern .               0       20%     4320
>      >      >
>      >      > debug_options 11,2
>      >      >
>      >      > I can see the below in /var/log/squid/cache.log
>      >      >
>      >      > ----------
>      >      >
>      >      > 2024/07/12 16:49:57.056 kid1| 11,2| http.cc(1263)
>     readReply: conn12
>      >      > local=client.ip:56670 remote=public.ip.of.public.server:443
>      >      > FIRSTUP_PARENT FD 14 flags=1: read failure: (0) No error.
>      >      >
>      >      > 2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(273)
>      >     sendStartOfMessage:
>      >      > HTTP Client conn9 local=client.ip:443
>      >     remote=local.server.ip:59158 FD 13
>      >      > flags=1
>      >      >
>      >      > 2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(274)
>      >     sendStartOfMessage:
>      >      > HTTP Client REPLY:
>      >      >
>      >      > ---------
>      >      >
>      >      > HTTP/1.1 502 Bad Gateway
>      >      >
>      >      > Server: squid/6.6
>      >      >
>      >      > Mime-Version: 1.0
>      >      >
>      >      > Date: Fri, 12 Jul 2024 16:49:57 GMT
>      >      >
>      >      > Content-Type: text/html;charset=utf-8
>      >      >
>      >      > Content-Length: 3629
>      >      >
>      >      > X-Squid-Error: ERR_READ_ERROR 0
>      >      >
>      >      > Vary: Accept-Language
>      >      >
>      >      > Content-Language: en
>      >      >
>      >      > Cache-Status: local.server;detail=mismatch
>      >      >
>      >      > Via: 1.1 local.server (squid/6.6)
>      >      >
>      >      > Connection: keep-alive
>      >      >
>      >      > ----------
>      >      >
>      >      > The apache server still shows a 200 for the request:
>      >      >
>      >      > [12/Jul/2024:17:49:57 +0100] "GET /path/to/file HTTP/1.1" 200
>      >     10465 "-"
>      >      > "curl/8.7.1"
>      >      >
>      >      > And this is when testing via:
>      >      >
>      >      > curl -D - https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>
>      >     <https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>>
>      >      > <https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>
>      >     <https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>>> -H "Authorization: Basic
>      >      > base64auth" -o /dev/null
>      >      >
>      >      > Regards,
>      >      >
>      >      > Ben.
>      >      >
>      >      > *From: *Alex Rousskov <rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>
>      >     <mailto:rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>>>
>      >      > *Date: *Friday, 12 July 2024 at 17:36
>      >      > *To: *Ben Toms <ben at macmule.com <mailto:ben at macmule.com>
>     <mailto:ben at macmule.com <mailto:ben at macmule.com>>>,
>      > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >     <mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>      >      > <squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >     <mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>>
>      >      > *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>      >      >
>      >      > On 2024-07-12 12:14, Ben Toms wrote:
>      >      >
>      >      >> Which log should those be found?
>      >      >
>      >      > cache.log (if they are present)
>      >      >
>      >      >
>      >      >> Can?t see ?HTTP Server RESPONSE? in the access.log or
>     cache.log.
>      >      >
>      >      > Sigh. This is one of the reasons I avoid asking folks to
>     study logs
>      >      > themselves, even ALL,2 logs...
>      >      >
>      >      > If that line is not in cache.log, then child Squid
>     probably did not
>      >      > receive a response from parent Squid, or could not parse that
>      >     response.
>      >      > A full debugging log should give us more information.
>      >      >
>      >      > Alex.
>      >      >
>      >      >
>      >      >> *From: *squid-users
>     <squid-users-bounces at lists.squid-cache.org
>     <mailto:squid-users-bounces at lists.squid-cache.org>
>      >     <mailto:squid-users-bounces at lists.squid-cache.org
>     <mailto:squid-users-bounces at lists.squid-cache.org>>> on
>      >      >> behalf of Alex Rousskov <rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>
>      >     <mailto:rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>>>
>      >      >> *Date: *Friday, 12 July 2024 at 17:11
>      >      >> *To: *squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >     <mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>      >     <squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >     <mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>>
>      >      >> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>      >      >>
>      >      >> On 2024-07-12 11:38, Ben Toms wrote:
>      >      >>> Think I made the changes Alex requested:
>      >      >>>
>      >      >>> 12/Jul/2024:15:36:31 +0000.640 local.server.ip
>      >     TCP_MISS_ABORTED/502 3974
>      >      >>> GET https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>
>      >     <https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>>
>      >      > <https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>
>      >     <https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>>>
>      >      >> <https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>
>      >     <https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>>
>      >      > <https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>
>      >     <https://local.server.fqdn/path/to/file
>     <https://local.server.fqdn/path/to/file>>>> -
>      >      >>> FIRSTUP_PARENT/public.ip.of.public.server text/html
>      >      >>> ERR_READ_ERROR/WITH_SERVER
>      >      >>
>      >      >> Thank you for using Squid v6 for this test.
>      >      >>
>      >      >> Unfortunately, due to Squid logging bugs,
>     ERR_READ_ERROR/WITH_SERVER
>      >      >> does not always mean what it says. For example, parent Squid
>      >     could have
>      >      >> closed the child-parent connection prematurely, but there
>     could
>      >     be other
>      >      >> reasons. A full debugging log should give us more
>     information.
>      >      >>
>      >      >>
>      >      >>> 2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(274)
>      >     sendStartOfMessage:
>      >      >>> HTTP Client REPLY:
>      >      >>
>      >      >> This is a child proxy response to the client. We need parent
>      >     response to
>      >      >> the child proxy. Look for "HTTP Server RESPONSE" lines
>     instead.
>      >      >>
>      >      >>
>      >      >> HTH,
>      >      >>
>      >      >> Alex.
>      >      >>
>      >      >>
>      >      >>
>      >      >>> ---------
>      >      >>>
>      >      >>> HTTP/1.1 502 Bad Gateway
>      >      >>>
>      >      >>> Server: squid/6.6
>      >      >>>
>      >      >>> Mime-Version: 1.0
>      >      >>>
>      >      >>> Date: Fri, 12 Jul 2024 14:57:08 GMT
>      >      >>>
>      >      >>> Content-Type: text/html;charset=utf-8
>      >      >>>
>      >      >>> Content-Length: 3629
>      >      >>>
>      >      >>> X-Squid-Error: ERR_READ_ERROR 0
>      >      >>>
>      >      >>> Vary: Accept-Language
>      >      >>>
>      >      >>> Content-Language: en
>      >      >>>
>      >      >>> Cache-Status: squid.host;detail=mismatch
>      >      >>>
>      >      >>> Via: 1.1 squid.host (squid/6.6)
>      >      >>>
>      >      >>> Connection: keep-alive
>      >      >>>
>      >      >>> ----------
>      >      >>>
>      >      >>> Regards,
>      >      >>>
>      >      >>> Ben.
>      >      >>>
>      >      >>> *From: *squid-users
>     <squid-users-bounces at lists.squid-cache.org
>     <mailto:squid-users-bounces at lists.squid-cache.org>
>      >     <mailto:squid-users-bounces at lists.squid-cache.org
>     <mailto:squid-users-bounces at lists.squid-cache.org>>> on
>      >      >>> behalf of Amos Jeffries <squid3 at treenet.co.nz
>     <mailto:squid3 at treenet.co.nz>
>      >     <mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>>
>      >      >>> *Date: *Friday, 12 July 2024 at 15:22
>      >      >>> *To: *squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >     <mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>      >     <squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >     <mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>>
>      >      >>> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>      >      >>>
>      >      >>>
>      >      >>> On 13/07/24 01:52, Alex Rousskov wrote:
>      >      >>>> On 2024-07-12 08:06, Ben Toms wrote:
>      >      >>>>> Seems that my issue is similar to -
>      >      >>>>>
>      >
>     https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>>>>
>      >      >>>>
>      >      >>>> You are facing up to two problems:
>      >      >>>>
>      >      >>>> 1. Some authenticated responses are not cachable by Squid.
>      >     Please share
>      >      >>>> HTTP headers of the response in question.
>      >      >>>>
>      >      >>>
>      >      >>> FYI, those can be obtained by configuring squid.conf with
>      >      >>>
>      >      >>>     debug_options 11,2
>      >      >>>
>      >      >>>
>      >      >>> Cheers
>      >      >>> Amos
>      >      >>>
>      >      >>>
>      >      >>>> 2. TCP_MISS_ABORTED/502 errors may delete a being-cached
>      >     response. These
>      >      >>>> can be bogus errors (essentially Squid logging bugs) or
>     real
>      >     ones (e.g.,
>      >      >>>> due to communication bugs, misconfiguration, or
>     compatibility
>      >     problems).
>      >      >>>> I recommend adding %err_code/%err_detail to your
>     logformat and
>      >     sharing
>      >      >>>> the corresponding access.log lines (obfuscated as needed).
>      >      >>>>
>      >      >>>> Sharing (privately if needed) a pointer to compressed ALL,9
>      >     cache.log
>      >      >>>> while reproducing the issue using a single transaction may
>      >     help us
>      >      >>>> resolve all the unknowns:
>      >      >>>>
>      >      >>>>
>      >
>     https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>>> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>>>> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction> <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction <https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction>>>>>
>      >      >>>>
>      >      >>>>
>      >      >>>> HTH,
>      >      >>>>
>      >      >>>> Alex.
>      >      >>>>
>      >      >>>>
>      >      >>>
>      >      >>>
>      >      >>> _______________________________________________
>      >      >>> squid-users mailing list
>      >      >>> squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >     <mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>      >      >>> https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>
>      >      > <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>>
>      >      >> <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>
>      >      > <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>>>
>      >      >>> <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>
>      >      >> <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>
>      >      > <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>>>>
>      >      >>>
>      >      >>>
>      >      >>> _______________________________________________
>      >      >>> squid-users mailing list
>      >      >>> squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >     <mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>      >      >>> https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>
>      >      > <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>>
>      >      >> <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>
>      >      > <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>>>
>      >      >>
>      >      >> _______________________________________________
>      >      >> squid-users mailing list
>      >      >> squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >     <mailto:squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>>
>      >      >> https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>
>      >      > <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>>
>      >      >> <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>
>      >      > <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>      >     <https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>>>>
>      >      >>
>      >      >
>      >
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240713/9614756d/attachment.htm>

From c.fiehe at eurodata.de  Sun Jul 14 16:35:47 2024
From: c.fiehe at eurodata.de (Fiehe, Christoph)
Date: Sun, 14 Jul 2024 16:35:47 +0000
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <5eba3547-b303-402f-93ec-507a91690e0d@measurement-factory.com>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
 <60d138f7-0c05-48d0-8d9d-959526e40499@treenet.co.nz>
 <5eba3547-b303-402f-93ec-507a91690e0d@measurement-factory.com>
Message-ID: <456eb9f4cf1746a7b749217b1f8262cc@eurodata.de>

The only solution I was currently able to get working, was to make use of an Apache server installed locally beside Squid. It acts as a reverse proxy and gets queried by Squid when the client requests an external resource via HTTP, but that resource must be accessed transparently for the client via HTTPS using an upstream proxy. The Apache is able to initiate the required CONNECT request to the upstream proxy and to fetch that resource from the specified source via the established tunnel.

I do not like the solution. It would be nice to get rid of the Apache, but I have not found a way to use URL rewriting in combination with Squid's reverse proxy capabilities to fetch that resource in case of HTTPS via a CONNECT to the upstream proxy.

If someone has a better idea to achieve that behavior, please do not hesitate to send a response.

This is just an experimental configuration and should not be used in production:

jesred.rules:

regex ^(http://download\.docker\.com.*)$ http://localhost:9090?uri=\1

vhost.conf:

Listen 9090
<VirtualHost 127.0.0.1:9090>
    ServerName  localhost
    ServerAlias 127.0.0.1

    ErrorLog ${APACHE_LOG_DIR}/error.log
    CustomLog ${APACHE_LOG_DIR}/access.log combined

    SSLProxyEngine On

    ProxyRemoteMatch ^(?!.*internaldomain\.com).*$ http://<PROXY-FQDN>:<PROXY-PORT>

    RewriteCond %{QUERY_STRING} uri=https?:\/\/([^&]*)$
    RewriteRule ^ https://%1 [P,L]
</VirtualHost>

squid.conf:

http_port 8000
visible_hostname pkg-proxy

cache_peer <PROXY-FQDN> parent <PROXY-PORT> 0 no-query default

always_direct allow to_localhost

never_direct allow all

http_access allow all

cache deny all

url_rewrite_children 3 startup=0 idle=1 concurrency=1
url_rewrite_program /usr/lib/squid/jesred

Regards,
Christoph

>-----Urspr?ngliche Nachricht-----
>Von: squid-users <squid-users-bounces at lists.squid-cache.org> Im Auftrag von Alex Rousskov
>Gesendet: Freitag, 12. Juli 2024 00:11
>An: squid-users at lists.squid-cache.org
>Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>
>On 2024-07-11 17:03, Amos Jeffries wrote:
>> On 11/07/24 00:49, Alex Rousskov wrote:
>>> On 2024-07-09 18:25, Fiehe, Christoph wrote:
>>>
>>>> I hope that somebody has an idea, what I am doing wrong.
>>>
>>> AFAICT from the debugging log, it is your parent proxy that returns an
>>> ERR_SECURE_CONNECT_FAIL error page in response to a seemingly valid
>>> "HEAD https://..." request. Can you ask their admin to investigate?
>>> You may also recommend that they upgrade from Squid v4 that has many
>>> known security vulnerabiities.
>>>
>>> If parent is uncooperative, you can try to reproduce the problem by
>>> temporary installing your own parent Squid instance and configuring
>>> your child Squid to use that instead.
>>>
>>> HTH,
>>>
>>> Alex.
>>> P.S. Unlike Amos, I do not see serious conceptual problems with
>>> rewriting request target scheme (as a temporary compatibility
>>> measure). It may not always work, for various reasons, but it does not
>>> necessarily make things worse (and may make things better).
>
>
>> To which I refer you to:
>
>None of the weaknesses below are applicable to request target scheme
>rewriting (assuming both proxies in question are implemented/configured
>correctly, of course). Specific non-applicability reasons are given
>below for each weakness URL:
>
>> https://cwe.mitre.org/data/definitions/311.html
>
>The above "The product does not encrypt sensitive or critical
>information before storage or transmission" case is not applicable: All
>connections can be encrypted as needed after the scheme rewrite.
>
>
>> https://cwe.mitre.org/data/definitions/312.html
>
>The above "The product stores sensitive information in cleartext within
>a resource that might be accessible to another control sphere." case is
>not applicable: Squid does not store information in such an accessible
>resource.
>
>
>> https://cwe.mitre.org/data/definitions/319.html
>
>The above "The product transmits sensitive or security-critical data in
>cleartext in a communication channel that can be sniffed by unauthorized
>actors." case is not applicable: All connections can be encrypted as
>needed after the scheme rewrite.
>
>Alex.
>
>_______________________________________________
>squid-users mailing list
>squid-users at lists.squid-cache.org
>https://lists.squid-cache.org/listinfo/squid-users


From c.fiehe at eurodata.de  Sun Jul 14 16:59:16 2024
From: c.fiehe at eurodata.de (Fiehe, Christoph)
Date: Sun, 14 Jul 2024 16:59:16 +0000
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <41737fa0-ab1a-4d94-a355-eb77a1fabc21@measurement-factory.com>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
 <6bb89d7c58e34320b1eb15c1447e99d7@eurodata.de>
 <ca32f7f1-9123-47d4-a7ba-dfc40d0c6937@measurement-factory.com>
 <867452bfd4ff482bb60b90d4482265a7@eurodata.de>
 <cda7c451-72eb-4be5-bc10-a7db7ea1ba64@measurement-factory.com>
 <2d18e96ef2be492f9deea0b5c07688f5@eurodata.de>
 <b44b830f-3ec4-4464-adf3-5695fe280ad5@measurement-factory.com>
 <93949ac76c724384b62d5e6332c7c1ab@eurodata.de>
 <41737fa0-ab1a-4d94-a355-eb77a1fabc21@measurement-factory.com>
Message-ID: <02050efa5cfb4b338677934a5e1178bc@eurodata.de>

Hi Alex,

sorry, I have not seen your message, yet. Thank you very much for your helping support.

(A) I will try to find a way to test, how a new Squid build based on OpenSSL behaves under those circumstances. It will take some time.

(B) Yes, Squid does nothing wrong, it is a very specific use case. I would prefer to utilize a dedicated package caching solution, but there are only a few available. It's a pity that Apt-Cacher-NG is in such a bad state. Unfortunately, I lack the required C/C++ skills to do the code extensions in Squid by myself.

Have a nice weekend.

Regards,
Christoph


>-----Urspr?ngliche Nachricht-----
>Von: squid-users <squid-users-bounces at lists.squid-cache.org> Im Auftrag von Alex Rousskov
>Gesendet: Donnerstag, 11. Juli 2024 20:27
>An: squid-users at lists.squid-cache.org
>Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>
>On 2024-07-11 13:37, Fiehe, Christoph wrote:
>> My proxy (the child proxy) already uses the OpenSSL library:
>
>Good.
>
>
>> The parent proxy was compiled ... '--with-gnutls'
>
>> The GnuTLS exception is thrown at my parent proxy.
>
>Thank you for reminding me of that fact; I did not notice or have
>forgotten about it. I assume you cannot rebuild your parent proxy to use
>OpenSSL.
>
>I see the following choice:
>
>A) Continue with the current no-CONNECT setup: Find somebody who can
>help you get Squid+GnuTLS code path working on the parent proxy. It
>might be impossible to get this working without making build or
>configuration changes at the parent proxy. Moreover, please note that
>your current no-CONNECT setup lacks encryption on the child-parent
>segment. If that was not intentional, then fixing that will increase
>TLS-related work for the parent, potentially triggering more problems there.
>
>B) Switch to a CONNECT-based setup: Find somebody who can enhance Squid
>code to establish a CONNECT tunnel through parent proxy when dealing
>with a GET-https request. Today, Squid will not do that AFAICT[^1].
>
>https://wiki.squid-cache.org/SquidFaq/AboutSquid#how-to-add-a-new-squid-feature-enhance-
>of-fix-something
>
>
>[^1]: AFAICT: Today, there are two primary Squid code conditions for
>establishing a CONNECT tunnel on a caching code path: Request method is
>CONNECT or SslBump is in use. Neither matches your GET-https request
>scenario. Squid current behavior is not "wrong" (as detailed in my
>earlier email about CONNECT and no-CONNECT scenarios), so, to make these
>changes official, the author will need to add a configuration option to
>let admins enable this behavior. The corresponding code changes feel
>straightforward to me, but I have not studied any details.
>
>
>HTH,
>
>Alex.
>
>
>
>> Unfortunately, I cannot make any changes here. So yes, I trust my parent proxy, but not
>using a tunnel between child and parent does not seem to work and results in the TLS
>exception on the parent proxy.
>>
>> I have not find a way to tell my child proxy to always setup a tunnel through the parent
>proxy, when the target server talks HTTPS. Do you know, how to achieve that? It would be a
>promising approach.
>>
>> Thank you very much help and your patience, Alex.
>>
>> Regards,
>> Christoph
>>
>>
>>> -----Urspr?ngliche Nachricht-----
>>> Von: squid-users <squid-users-bounces at lists.squid-cache.org> Im Auftrag von Alex
>Rousskov
>>> Gesendet: Donnerstag, 11. Juli 2024 18:15
>>> An: squid-users at lists.squid-cache.org
>>> Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>>>
>>> On 2024-07-10 16:57, Fiehe, Christoph wrote:
>>>
>>>> I am just trying to find something that helps to narrow down the
>>>> problem. What I want to achieve is, that a client can use HTTP in the
>>>> LAN, so that Squid can cache distribution packages without making use
>>>> of SSL intercepting when repos are only accessible via HTTPS.
>>>
>>> OK.
>>>
>>>
>>>> In that case the secure connection must start at the proxy and end on
>>>> the target server with or without any upstream proxies in betweem.
>>>
>>> It depends on whether you trust the parent proxy:
>>>
>>> If you trust the parent proxy, then you can use two secure connections:
>>>
>>> 1.1. child - parent (TLS; no CONNECT)
>>> 1.2. parent - origin (TLS; no CONNECT)
>>>
>>> If you do not trust the parent proxy, then, yes, you will need a tunnel:
>>>
>>> 2.1. child - parent (CONNECT)
>>> 2.2. child - origin (TLS inside the CONNECT tunnel)
>>>
>>> N.B. CONNECT request in 2.1 may be plain text (common) or encrypted
>>> (rare); I am ignoring the difference between those two subcases for now.
>>>
>>>
>>>> We have the following setup:
>>>>
>>>> client -> downstream proxy -> upstream proxy -> https://download.docker.com
>>>>
>>>> Now let us assume the client wants to retrieve the following resource
>>> http://download.docker.com/linux/ubuntu/dists/jammy/InRelease from the upstream proxy.
>>>>
>>>> The client initiates a HTTP GET request and sends it to the downstream proxy. Now, the
>>> URL gets rewritten.
>>>
>>> OK.
>>>
>>>
>>>> It indicates to use a HTTPS connection instead in order to talk to the target server,
>in
>>> our case the result is https://download.docker.com/linux/ubuntu/dists/jammy/InRelease.
>>>
>>> Yes, but HTTPS scheme does not imply that the child Squid has to use
>>> CONNECT. There are two possible scenarios detailed above. I do not know
>>> which of them applies to your use case.
>>>
>>>
>>>> Now comes the critical point: From my understanding ? it may be
>>>> wrongof course - the downstream server now has to send a CONNECT
>>>> request to the upstream server
>>>
>>> Yes, provided the child (downstream) proxy does not trust that parent
>>> (upstream) proxy. That is scenario 2. Scenario 1 is different.
>>>
>>>
>>>> to advise him to establish a secure connection to the target server.
>>>
>>> No, the CONNECT tunnel itself is just a pair of TCP connections. The
>>> parent proxy "secures" nothing but basic TCP connectivity. It is the
>>> child proxy that negotiates TLS (over/inside that tunnel) with the
>>> origin server.
>>>
>>>
>>>> After creation, the downstream proxy can retrieve the resource and
>>>> send it back to the client via plain HTTP.
>>>
>>> Yes.
>>>
>>>
>>>
>>>> I suppose, that the GnuTLS occurs because of a missing SSL handshake
>>>> between downstream proxy and download.docker.com.
>>>
>>> At this time, I can only say that a TLS negotiation error occurs (while
>>> child Squid is using the encryption library it probably should not be
>>> using for this). It is not yet clear to me whether child Squid is
>>> negotiating with the wrong hop or something goes wrong during
>>> negotiation with the right hop.
>>>
>>> As the next steps, I recommend switching to OpenSSL and, if that alone
>>> does not help, sharing new errors and determining whether you want to
>>> use scenario 1 (no CONNECT), scenario 2 (CONNECT), or either (whichever
>>> works): Do you trust the parent Squid?
>>>
>>>
>>> HTH,
>>>
>>> Alex.
>>>
>>>
>>>>> -----Urspr?ngliche Nachricht-----
>>>>> Von: Alex Rousskov <rousskov at measurement-factory.com>
>>>>> Gesendet: Mittwoch, 10. Juli 2024 22:15
>>>>> An: squid-users at lists.squid-cache.org
>>>>> Cc: Fiehe, Christoph <c.fiehe at eurodata.de>
>>>>> Betreff: AW: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>>>>>
>>>>> On 2024-07-10 15:31, Fiehe, Christoph wrote:
>>>>>> The problem is that the proxy just forwards the client GET request to the upstream
>>> proxy
>>>>>
>>>>> Why does sending a GET request to the upstream proxy represent a problem
>>>>> in your use case? I cannot find anything in your prior messages on this
>>>>> thread that would preclude sending a GET request to the upstream proxy.
>>>>>
>>>>>
>>>>>> but in that case a CONNECT is required.
>>>>>
>>>>> Why?
>>>>>
>>>>> Please do not interpret my response as implying that this "must send
>>>>> CONNECT" requirement is wrong (or correct). At this point, I am just
>>>>> trying to understand what problem(s) you are trying to solve beyond the
>>>>> one you have originally described.
>>>>>
>>>>>
>>>>> Thank you,
>>>>>
>>>>> Alex.
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>
>_______________________________________________
>squid-users mailing list
>squid-users at lists.squid-cache.org
>https://lists.squid-cache.org/listinfo/squid-users

From c.fiehe at eurodata.de  Sun Jul 14 21:02:43 2024
From: c.fiehe at eurodata.de (Fiehe, Christoph)
Date: Sun, 14 Jul 2024 21:02:43 +0000
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <02050efa5cfb4b338677934a5e1178bc@eurodata.de>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
 <6bb89d7c58e34320b1eb15c1447e99d7@eurodata.de>
 <ca32f7f1-9123-47d4-a7ba-dfc40d0c6937@measurement-factory.com>
 <867452bfd4ff482bb60b90d4482265a7@eurodata.de>
 <cda7c451-72eb-4be5-bc10-a7db7ea1ba64@measurement-factory.com>
 <2d18e96ef2be492f9deea0b5c07688f5@eurodata.de>
 <b44b830f-3ec4-4464-adf3-5695fe280ad5@measurement-factory.com>
 <93949ac76c724384b62d5e6332c7c1ab@eurodata.de>
 <41737fa0-ab1a-4d94-a355-eb77a1fabc21@measurement-factory.com>
 <02050efa5cfb4b338677934a5e1178bc@eurodata.de>
Message-ID: <a44693f404854d0ab48d35020794b0cc@eurodata.de>

I did some more debugging and I think that I have found the cause why the issue occurs in case (A). As Alex already explained, in case (A) the child proxy forwards the rewritten request e.g. a GET request containing a HTTPS URL, to the parent proxy. Now the parent proxy is in charge to establish a connection with the target server. This action fails with:

TLS code: SQUID_TLS_ERR_CONNECT+GNUTLS_E_FATAL_ALERT_RECEIVED
SSL handshake error (SQUID_TLS_ERR_CONNECT)

The problem is when you use Squid in combination with GnuTLS, the client HELLO message does not contain the server name in the SNI extension. This causes the server to send a FATAL ALERT - Handshake Failure to the client. That is the reason why the parent server cannot establish a secure connection to the target server. I checked the code and it looks promising that Squid with the OpenSSL library will work. In the class support.cc the server name is added when the SNI extension is enabled in the OpenSSL library.

I hope that it is possible for us to switch to the squid-openssl package.

Regards,
Christoph


>-----Urspr?ngliche Nachricht-----
>Von: squid-users <squid-users-bounces at lists.squid-cache.org> Im Auftrag von Fiehe,
>Christoph
>Gesendet: Sonntag, 14. Juli 2024 18:59
>An: squid-users at lists.squid-cache.org
>Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>
>Hi Alex,
>
>sorry, I have not seen your message, yet. Thank you very much for your helping support.
>
>(A) I will try to find a way to test, how a new Squid build based on OpenSSL behaves under
>those circumstances. It will take some time.
>
>(B) Yes, Squid does nothing wrong, it is a very specific use case. I would prefer to
>utilize a dedicated package caching solution, but there are only a few available. It's a
>pity that Apt-Cacher-NG is in such a bad state. Unfortunately, I lack the required C/C++
>skills to do the code extensions in Squid by myself.
>
>Have a nice weekend.
>
>Regards,
>Christoph
>
>
>>-----Urspr?ngliche Nachricht-----
>>Von: squid-users <squid-users-bounces at lists.squid-cache.org> Im Auftrag von Alex Rousskov
>>Gesendet: Donnerstag, 11. Juli 2024 20:27
>>An: squid-users at lists.squid-cache.org
>>Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>>
>>On 2024-07-11 13:37, Fiehe, Christoph wrote:
>>> My proxy (the child proxy) already uses the OpenSSL library:
>>
>>Good.
>>
>>
>>> The parent proxy was compiled ... '--with-gnutls'
>>
>>> The GnuTLS exception is thrown at my parent proxy.
>>
>>Thank you for reminding me of that fact; I did not notice or have
>>forgotten about it. I assume you cannot rebuild your parent proxy to use
>>OpenSSL.
>>
>>I see the following choice:
>>
>>A) Continue with the current no-CONNECT setup: Find somebody who can
>>help you get Squid+GnuTLS code path working on the parent proxy. It
>>might be impossible to get this working without making build or
>>configuration changes at the parent proxy. Moreover, please note that
>>your current no-CONNECT setup lacks encryption on the child-parent
>>segment. If that was not intentional, then fixing that will increase
>>TLS-related work for the parent, potentially triggering more problems there.
>>
>>B) Switch to a CONNECT-based setup: Find somebody who can enhance Squid
>>code to establish a CONNECT tunnel through parent proxy when dealing
>>with a GET-https request. Today, Squid will not do that AFAICT[^1].
>>
>>https://wiki.squid-cache.org/SquidFaq/AboutSquid#how-to-add-a-new-squid-feature-enhance-
>>of-fix-something
>>
>>
>>[^1]: AFAICT: Today, there are two primary Squid code conditions for
>>establishing a CONNECT tunnel on a caching code path: Request method is
>>CONNECT or SslBump is in use. Neither matches your GET-https request
>>scenario. Squid current behavior is not "wrong" (as detailed in my
>>earlier email about CONNECT and no-CONNECT scenarios), so, to make these
>>changes official, the author will need to add a configuration option to
>>let admins enable this behavior. The corresponding code changes feel
>>straightforward to me, but I have not studied any details.
>>
>>
>>HTH,
>>
>>Alex.
>>
>>
>>
>>> Unfortunately, I cannot make any changes here. So yes, I trust my parent proxy, but not
>>using a tunnel between child and parent does not seem to work and results in the TLS
>>exception on the parent proxy.
>>>
>>> I have not find a way to tell my child proxy to always setup a tunnel through the
>parent
>>proxy, when the target server talks HTTPS. Do you know, how to achieve that? It would be
>a
>>promising approach.
>>>
>>> Thank you very much help and your patience, Alex.
>>>
>>> Regards,
>>> Christoph
>>>
>>>
>>>> -----Urspr?ngliche Nachricht-----
>>>> Von: squid-users <squid-users-bounces at lists.squid-cache.org> Im Auftrag von Alex
>>Rousskov
>>>> Gesendet: Donnerstag, 11. Juli 2024 18:15
>>>> An: squid-users at lists.squid-cache.org
>>>> Betreff: Re: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>>>>
>>>> On 2024-07-10 16:57, Fiehe, Christoph wrote:
>>>>
>>>>> I am just trying to find something that helps to narrow down the
>>>>> problem. What I want to achieve is, that a client can use HTTP in the
>>>>> LAN, so that Squid can cache distribution packages without making use
>>>>> of SSL intercepting when repos are only accessible via HTTPS.
>>>>
>>>> OK.
>>>>
>>>>
>>>>> In that case the secure connection must start at the proxy and end on
>>>>> the target server with or without any upstream proxies in betweem.
>>>>
>>>> It depends on whether you trust the parent proxy:
>>>>
>>>> If you trust the parent proxy, then you can use two secure connections:
>>>>
>>>> 1.1. child - parent (TLS; no CONNECT)
>>>> 1.2. parent - origin (TLS; no CONNECT)
>>>>
>>>> If you do not trust the parent proxy, then, yes, you will need a tunnel:
>>>>
>>>> 2.1. child - parent (CONNECT)
>>>> 2.2. child - origin (TLS inside the CONNECT tunnel)
>>>>
>>>> N.B. CONNECT request in 2.1 may be plain text (common) or encrypted
>>>> (rare); I am ignoring the difference between those two subcases for now.
>>>>
>>>>
>>>>> We have the following setup:
>>>>>
>>>>> client -> downstream proxy -> upstream proxy -> https://download.docker.com
>>>>>
>>>>> Now let us assume the client wants to retrieve the following resource
>>>> http://download.docker.com/linux/ubuntu/dists/jammy/InRelease from the upstream proxy.
>>>>>
>>>>> The client initiates a HTTP GET request and sends it to the downstream proxy. Now,
>the
>>>> URL gets rewritten.
>>>>
>>>> OK.
>>>>
>>>>
>>>>> It indicates to use a HTTPS connection instead in order to talk to the target server,
>>in
>>>> our case the result is https://download.docker.com/linux/ubuntu/dists/jammy/InRelease.
>>>>
>>>> Yes, but HTTPS scheme does not imply that the child Squid has to use
>>>> CONNECT. There are two possible scenarios detailed above. I do not know
>>>> which of them applies to your use case.
>>>>
>>>>
>>>>> Now comes the critical point: From my understanding ? it may be
>>>>> wrongof course - the downstream server now has to send a CONNECT
>>>>> request to the upstream server
>>>>
>>>> Yes, provided the child (downstream) proxy does not trust that parent
>>>> (upstream) proxy. That is scenario 2. Scenario 1 is different.
>>>>
>>>>
>>>>> to advise him to establish a secure connection to the target server.
>>>>
>>>> No, the CONNECT tunnel itself is just a pair of TCP connections. The
>>>> parent proxy "secures" nothing but basic TCP connectivity. It is the
>>>> child proxy that negotiates TLS (over/inside that tunnel) with the
>>>> origin server.
>>>>
>>>>
>>>>> After creation, the downstream proxy can retrieve the resource and
>>>>> send it back to the client via plain HTTP.
>>>>
>>>> Yes.
>>>>
>>>>
>>>>
>>>>> I suppose, that the GnuTLS occurs because of a missing SSL handshake
>>>>> between downstream proxy and download.docker.com.
>>>>
>>>> At this time, I can only say that a TLS negotiation error occurs (while
>>>> child Squid is using the encryption library it probably should not be
>>>> using for this). It is not yet clear to me whether child Squid is
>>>> negotiating with the wrong hop or something goes wrong during
>>>> negotiation with the right hop.
>>>>
>>>> As the next steps, I recommend switching to OpenSSL and, if that alone
>>>> does not help, sharing new errors and determining whether you want to
>>>> use scenario 1 (no CONNECT), scenario 2 (CONNECT), or either (whichever
>>>> works): Do you trust the parent Squid?
>>>>
>>>>
>>>> HTH,
>>>>
>>>> Alex.
>>>>
>>>>
>>>>>> -----Urspr?ngliche Nachricht-----
>>>>>> Von: Alex Rousskov <rousskov at measurement-factory.com>
>>>>>> Gesendet: Mittwoch, 10. Juli 2024 22:15
>>>>>> An: squid-users at lists.squid-cache.org
>>>>>> Cc: Fiehe, Christoph <c.fiehe at eurodata.de>
>>>>>> Betreff: AW: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
>>>>>>
>>>>>> On 2024-07-10 15:31, Fiehe, Christoph wrote:
>>>>>>> The problem is that the proxy just forwards the client GET request to the upstream
>>>> proxy
>>>>>>
>>>>>> Why does sending a GET request to the upstream proxy represent a problem
>>>>>> in your use case? I cannot find anything in your prior messages on this
>>>>>> thread that would preclude sending a GET request to the upstream proxy.
>>>>>>
>>>>>>
>>>>>>> but in that case a CONNECT is required.
>>>>>>
>>>>>> Why?
>>>>>>
>>>>>> Please do not interpret my response as implying that this "must send
>>>>>> CONNECT" requirement is wrong (or correct). At this point, I am just
>>>>>> trying to understand what problem(s) you are trying to solve beyond the
>>>>>> one you have originally described.
>>>>>>
>>>>>>
>>>>>> Thank you,
>>>>>>
>>>>>> Alex.
>>>>>
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>>
>>_______________________________________________
>>squid-users mailing list
>>squid-users at lists.squid-cache.org
>>https://lists.squid-cache.org/listinfo/squid-users
>_______________________________________________
>squid-users mailing list
>squid-users at lists.squid-cache.org
>https://lists.squid-cache.org/listinfo/squid-users

From ml at netfence.it  Mon Jul 15 05:49:47 2024
From: ml at netfence.it (Andrea Venturoli)
Date: Mon, 15 Jul 2024 07:49:47 +0200
Subject: [squid-users] Tproxy or intercept
In-Reply-To: <946CAF07-163C-443D-BC2C-10018DFC2215@gmail.com>
References: <fe7f2b64-848f-47ed-95fc-7a964f4e2b87@netfence.it>
 <946CAF07-163C-443D-BC2C-10018DFC2215@gmail.com>
Message-ID: <920017a5-439a-4b11-9efc-2a852aa4b3af@netfence.it>

On 7/13/24 20:48, Jonathan Lee wrote:
> It works 6.6 it just have a different requirement to enable it. I am using a Netgate 2100 with pfSense. The difference is that it spoofs the IP of the client so the host doesn?t see the IP of the firewall when using intercept I am told. So transparent with more of a hidden layer

Well, in my case the client IP is everywhere a private one, so the host 
(the public web server?) will always see the IP of the firewall.
Are you using IPv6?

  bye & Thanks
	av.


From jonathanlee571 at gmail.com  Mon Jul 15 06:13:14 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sun, 14 Jul 2024 23:13:14 -0700
Subject: [squid-users] Tproxy or intercept
In-Reply-To: <920017a5-439a-4b11-9efc-2a852aa4b3af@netfence.it>
References: <920017a5-439a-4b11-9efc-2a852aa4b3af@netfence.it>
Message-ID: <9B0C474A-CD35-4856-AFCA-0E50B2AFC16D@gmail.com>

IPv4 only ips, I have a BE with tunnel broker that I test out but my IPS IDS can?t inspect the tunnel 
Sent from my iPhone

> On Jul 14, 2024, at 22:49, Andrea Venturoli <ml at netfence.it> wrote:
> 
> ?On 7/13/24 20:48, Jonathan Lee wrote:
>> It works 6.6 it just have a different requirement to enable it. I am using a Netgate 2100 with pfSense. The difference is that it spoofs the IP of the client so the host doesn?t see the IP of the firewall when using intercept I am told. So transparent with more of a hidden layer
> 
> Well, in my case the client IP is everywhere a private one, so the host (the public web server?) will always see the IP of the firewall.
> Are you using IPv6?
> 
> bye & Thanks
>    av.


From rousskov at measurement-factory.com  Mon Jul 15 18:38:41 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 15 Jul 2024 14:38:41 -0400
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <CWLP265MB3156BA85ADAF926FEF663D73FEA72@CWLP265MB3156.GBRP265.PROD.OUTLOOK.COM>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <1ee387d1-732e-4504-8d00-2d8a0c243d8a@measurement-factory.com>
 <LO2P265MB31651D6F080E7EF06AD34E21FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <0377b31b-4ec0-4b29-8651-a7984210e446@measurement-factory.com>
 <LO2P265MB3165A66218D288B5873339B6FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316511FB262897B4C5F4AC69FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <73240ae0-6bc0-4094-8d23-435d2c21913c@measurement-factory.com>
 <CADjniur4VwfGPReOWMGjnxkgWHcDfCsSjsj+NMNkvpD=82ai7g@mail.gmail.com>
 <6712bade-d307-4568-8eb4-14cee7fa997e@measurement-factory.com>
 <CADjniuoqjKHrXctmOQZLqpTrdquY_4ASFxTc=7H9qCh8WO=x-w@mail.gmail.com>
 <eb142f40-cf47-4a66-8245-d739a0196951@measurement-factory.com>
 <LO2P265MB316592733FD0BB2B08E3B3D8FEA72@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <CWLP265MB3156BA85ADAF926FEF663D73FEA72@CWLP265MB3156.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <3790aa46-a25c-4030-a5b7-0732824bee3f@measurement-factory.com>

On 2024-07-13 16:02, Ben Toms wrote:

> with debug_options ALL,4 set.. the cache.log shows:

> 2024/07/13 18:55:03.595 kid1| 5,3| Read.cc(93) ReadNow: conn17 
> local=squid.cache.ip:37046 remote=origin.server.ip:443 FIRSTUP_PARENT FD 
> 14 flags=1, size 65536, retval -28, errno 0

> 2024/07/13 18:55:03.595 kid1| 17,3| FwdState.cc(471) fail: 
> ERR_READ_ERROR "Bad Gateway"


> Still need to dig in more.. but the true error seems to be: 
> ERR_READ_ERROR "Bad Gateway"

AFAICT, the underlying error happens a bit earlier (probably at TLS 
layer), just before the "retval -28" line above. Official high-level 
Squid code that produced the above log lines does not detail those TLS 
errors. I do not know what went wrong between Squid and Apache.

Going forward, I see four options:

A) Examine origin logs. It is likely that Apache logs what is going 
wrong with that TLS session from httpd point of view.

B) (Privately) examine Squid ALL,9 logs. Squid OpenSSL integration code 
might log something relevant to this context.

C) Examine Squid-origin packet capture. If you supply TLS master keys to 
Wireshark or a similar tool, you may be able to see a relevant TLS alert 
in that TLS stream.

D) Find somebody to patch Squid source code to add more debugging info 
if (B) did not produce enough new/usable hints.


HTH,

Alex.

> *From: *Ben Toms <ben at macmule.com>
> *Date: *Saturday, 13 July 2024 at 13:04
> *To: *Alex Rousskov <rousskov at measurement-factory.com>
> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
> 
> Well.. tried with cache-control headers added to the apache servers 
> responses.. and still no luck (header response below).
> 
> Date: Sat, 13 Jul 2024 12:00:02 GMT
> 
> Server: Apache
> 
> Last-Modified: Thu, 20 Jun 2024 13:57:21 GMT
> 
> ETag: "152c-61b52b19bbd2a"
> 
> Accept-Ranges: bytes
> 
> Content-Length: 5420
> 
> Cache-Control: max-age=84600, public
> 
> Connection: close
> 
> I?ve tried a few other sites and the issue seems to be when attempting 
> to cache an item which requires authentication. Which is bizarre, as the 
> apache server is showing files are being downloaded.. yet squid-cache is 
> still erroring with TCP_MISS_ABORTED/502.
> 
> Regards,
> 
> Ben.
> 
> *From: *Alex Rousskov <rousskov at measurement-factory.com>
> *Date: *Friday, 12 July 2024 at 22:54
> *To: *Ben Toms <ben at macmule.com>
> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
> 
> On 2024-07-12 14:31, Ben Toms wrote:
> 
>> So this squid cache is the parent (which might speak to me 
>> misconfiguring squid).
>> 
>> It?s setup as an accelerator for the public server.
> 
> Ah, I see. Sorry I forgot or misinterpreted that part. Too many balls in
> the air.
> 
> Right now, it sounds like origin sent 200 OK, but Squid could not even
> parse that response header, which is rather unusual/rare. However, that
> theory is based on your interpretation of ALL,2 logs, so there may be
> more to the story here.
> 
> 
>> When I curl the public server direct, there are no cache control headers.
> 
> Understood. I suspect Squid will not cache such authenticated responses
> by default (even after Squid starts to receive them), but I have not
> checked all the relevant details.
> 
> 
> Cheers,
> 
> Alex.
> 
> 
>> On Fri, 12 Jul 2024 at 19:15, Alex Rousskov? wrote:
>> 
>>???? On 2024-07-12 13:38, Ben Toms wrote:
>> 
>>????? > Where would I find those headers?
>> 
>>???? If you have access to the parent Squid proxy, they will be in its
>>???? debugging cache.log. You can also get them by capturing network packets
>>???? between the parent Squid and origin, but for HTTPS traffic that
>>???? requires
>>???? giving Wireshark the associated master keys, which may be possible with
>>???? Squid v6, but not trivial (see tls_key_log in Squid; Apache may have
>>???? better support for this). Finally, one can configure Apache to log them
>>???? (sorry, I do not remember the details).
>> 
>>???? Again, the child Squid does not see these headers yet (AFAICT), so they
>>???? are not the reason things do not currently "work" in your tests.
>> 
>> 
>>????? > Looking at the origin servers apache logs.. it?s sending a 200
>>???? response.
>> 
>>???? I am aware. We need the headers that go with that 200 OK response. For
>>???? example, if it has Cache-Control:public, then Squid may be able to
>>???? cache
>>???? it despite authentication.
>> 
>> 
>>???? HTH,
>> 
>>???? Alex.
>> 
>> 
>>????? > On Fri, 12 Jul 2024 at 18:26, Alex Rousskov wrote:
>>????? >
>>????? >? ? ?On 2024-07-12 13:03, Ben Toms wrote:
>>????? >
>>????? >? ? ? > So the issue seems to be caching content that requires
>>???? authentication
>>????? >
>>????? >? ? ?The client is getting an error response from Squid. That error is
>>????? >? ? ?probably not related to caching decisions. I do not recommend
>>???? focusing
>>????? >? ? ?on caching at this stage of triage. I recommend addressing that
>>????? >? ? ?error first.
>>????? >
>>????? >
>>????? >? ? ? > The question here is, can squid cache items that require
>>????? >? ? ?authentication
>>????? >? ? ? > to access?
>>????? >
>>????? >? ? ?Yes, in some cases. To know whether your case qualifies, I
>>???? asked for
>>????? >? ? ?the
>>????? >? ? ?response headers. That led to the discovery that there are
>>???? none (from
>>????? >? ? ?child Squid point of view). If you really want to investigate the
>>????? >? ? ?caching angle in parallel with solving
>>???? ERR_READ_ERROR/WITH_SERVER, then
>>????? >? ? ?try to obtain HTTP response headers that the origin server
>>???? responds (to
>>????? >? ? ?the parent cache) with.
>>????? >
>>????? >
>>????? >? ? ?HTH,
>>????? >
>>????? >? ? ?Alex.
>>????? >
>>????? >
>>????? >? ? ? > *From: *Ben Toms <ben at macmule.com <mailto:ben at macmule.com <mailto:ben at macmule.com>>
>>???? <mailto:ben at macmule.com <mailto:ben at macmule.com <mailto:ben at macmule.com>>>>
>>????? >? ? ? > *Date: *Friday, 12 July 2024 at 17:56
>>????? >? ? ? > *To: *Alex Rousskov <rousskov at measurement-factory.com
>>???? <mailto:rousskov at measurement-factory.com 
> <mailto:rousskov at measurement-factory.com>>
>>????? >? ? ?<mailto:rousskov at measurement-factory.com
>>???? <mailto:rousskov at measurement-factory.com 
> <mailto:rousskov at measurement-factory.com>>>>,
>>????? >? ? ? > squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>
>>????? >? ? ?<mailto:squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>>
>>????? >? ? ?<squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>
>>????? >? ? ?<mailto:squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>>>
>>????? >? ? ? > *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>>????? >? ? ? >
>>????? >? ? ? > So, with the below config:
>>????? >? ? ? >
>>????? >? ? ? > https_port 443 accel protocol=HTTPS
>>????? >? ? ?tls-cert=/usr/local/squid/client.pem
>>????? >? ? ? > tls-key=/usr/local/squid/client.key
>>????? >? ? ? >
>>????? >? ? ? > cache_peer public.server.fqdn parent 443 0 no-query
>>???? originserver
>>????? >? ? ? > no-digest no-netdb-exchange tls login=PASSTHRU name=myAccel
>>????? >? ? ? > forceddomain=public.server.fqdn
>>????? >? ? ? >
>>????? >? ? ? > acl our_sites dstdomain local.server.fqdn
>>????? >? ? ? >
>>????? >? ? ? > http_access allow our_sites
>>????? >? ? ? >
>>????? >? ? ? > cache_peer_access myAccel allow our_sites
>>????? >? ? ? >
>>????? >? ? ? > cache_peer_access myAccel deny all
>>????? >? ? ? >
>>????? >? ? ? > cache_dir ufs /usr/local/squid/var/cache 100000 16 256
>>????? >? ? ? >
>>????? >? ? ? > cache_mem 500 MB
>>????? >? ? ? >
>>????? >? ? ? > maximum_object_size_in_memory 50000 KB
>>????? >? ? ? >
>>????? >? ? ? > refresh_pattern .?????????????? 0?????? 20%???? 4320
>>????? >? ? ? >
>>????? >? ? ? > debug_options 11,2
>>????? >? ? ? >
>>????? >? ? ? > I can see the below in /var/log/squid/cache.log
>>????? >? ? ? >
>>????? >? ? ? > ----------
>>????? >? ? ? >
>>????? >? ? ? > 2024/07/12 16:49:57.056 kid1| 11,2| http.cc(1263)
>>???? readReply: conn12
>>????? >? ? ? > local=client.ip:56670 remote=public.ip.of.public.server:443
>>????? >? ? ? > FIRSTUP_PARENT FD 14 flags=1: read failure: (0) No error.
>>????? >? ? ? >
>>????? >? ? ? > 2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(273)
>>????? >? ? ?sendStartOfMessage:
>>????? >? ? ? > HTTP Client conn9 local=client.ip:443
>>????? >? ? ?remote=local.server.ip:59158 FD 13
>>????? >? ? ? > flags=1
>>????? >? ? ? >
>>????? >? ? ? > 2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(274)
>>????? >? ? ?sendStartOfMessage:
>>????? >? ? ? > HTTP Client REPLY:
>>????? >? ? ? >
>>????? >? ? ? > ---------
>>????? >? ? ? >
>>????? >? ? ? > HTTP/1.1 502 Bad Gateway
>>????? >? ? ? >
>>????? >? ? ? > Server: squid/6.6
>>????? >? ? ? >
>>????? >? ? ? > Mime-Version: 1.0
>>????? >? ? ? >
>>????? >? ? ? > Date: Fri, 12 Jul 2024 16:49:57 GMT
>>????? >? ? ? >
>>????? >? ? ? > Content-Type: text/html;charset=utf-8
>>????? >? ? ? >
>>????? >? ? ? > Content-Length: 3629
>>????? >? ? ? >
>>????? >? ? ? > X-Squid-Error: ERR_READ_ERROR 0
>>????? >? ? ? >
>>????? >? ? ? > Vary: Accept-Language
>>????? >? ? ? >
>>????? >? ? ? > Content-Language: en
>>????? >? ? ? >
>>????? >? ? ? > Cache-Status: local.server;detail=mismatch
>>????? >? ? ? >
>>????? >? ? ? > Via: 1.1 local.server (squid/6.6)
>>????? >? ? ? >
>>????? >? ? ? > Connection: keep-alive
>>????? >? ? ? >
>>????? >? ? ? > ----------
>>????? >? ? ? >
>>????? >? ? ? > The apache server still shows a 200 for the request:
>>????? >? ? ? >
>>????? >? ? ? > [12/Jul/2024:17:49:57 +0100] "GET /path/to/file HTTP/1.1" 200
>>????? >? ? ?10465 "-"
>>????? >? ? ? > "curl/8.7.1"
>>????? >? ? ? >
>>????? >? ? ? > And this is when testing via:
>>????? >? ? ? >
>>????? >? ? ? > curl -D - https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>
>>???? <https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>>
>>????? >? ? ?<https://local.server.fqdn/path/to/file
>>???? <https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>>>
>>????? >? ? ? > <https://local.server.fqdn/path/to/file
>>???? <https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>>
>>????? >? ? ?<https://local.server.fqdn/path/to/file
>>???? <https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>>>> -H "Authorization: Basic
>>????? >? ? ? > base64auth" -o /dev/null
>>????? >? ? ? >
>>????? >? ? ? > Regards,
>>????? >? ? ? >
>>????? >? ? ? > Ben.
>>????? >? ? ? >
>>????? >? ? ? > *From: *Alex Rousskov <rousskov at measurement-factory.com
>>???? <mailto:rousskov at measurement-factory.com 
> <mailto:rousskov at measurement-factory.com>>
>>????? >? ? ?<mailto:rousskov at measurement-factory.com
>>???? <mailto:rousskov at measurement-factory.com 
> <mailto:rousskov at measurement-factory.com>>>>
>>????? >? ? ? > *Date: *Friday, 12 July 2024 at 17:36
>>????? >? ? ? > *To: *Ben Toms <ben at macmule.com <mailto:ben at macmule.com <mailto:ben at macmule.com>>
>>???? <mailto:ben at macmule.com <mailto:ben at macmule.com <mailto:ben at macmule.com>>>>,
>>????? > squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>
>>????? >? ? ?<mailto:squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>>
>>????? >? ? ? > <squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>
>>????? >? ? ?<mailto:squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>>>
>>????? >? ? ? > *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>>????? >? ? ? >
>>????? >? ? ? > On 2024-07-12 12:14, Ben Toms wrote:
>>????? >? ? ? >
>>????? >? ? ? >> Which log should those be found?
>>????? >? ? ? >
>>????? >? ? ? > cache.log (if they are present)
>>????? >? ? ? >
>>????? >? ? ? >
>>????? >? ? ? >> Can?t see ?HTTP Server RESPONSE? in the access.log or
>>???? cache.log.
>>????? >? ? ? >
>>????? >? ? ? > Sigh. This is one of the reasons I avoid asking folks to
>>???? study logs
>>????? >? ? ? > themselves, even ALL,2 logs...
>>????? >? ? ? >
>>????? >? ? ? > If that line is not in cache.log, then child Squid
>>???? probably did not
>>????? >? ? ? > receive a response from parent Squid, or could not parse that
>>????? >? ? ?response.
>>????? >? ? ? > A full debugging log should give us more information.
>>????? >? ? ? >
>>????? >? ? ? > Alex.
>>????? >? ? ? >
>>????? >? ? ? >
>>????? >? ? ? >> *From: *squid-users
>>???? <squid-users-bounces at lists.squid-cache.org
>>???? <mailto:squid-users-bounces at lists.squid-cache.org 
> <mailto:squid-users-bounces at lists.squid-cache.org>>
>>????? >? ? ?<mailto:squid-users-bounces at lists.squid-cache.org
>>???? <mailto:squid-users-bounces at lists.squid-cache.org 
> <mailto:squid-users-bounces at lists.squid-cache.org>>>> on
>>????? >? ? ? >> behalf of Alex Rousskov <rousskov at measurement-factory.com
>>???? <mailto:rousskov at measurement-factory.com 
> <mailto:rousskov at measurement-factory.com>>
>>????? >? ? ?<mailto:rousskov at measurement-factory.com
>>???? <mailto:rousskov at measurement-factory.com 
> <mailto:rousskov at measurement-factory.com>>>>
>>????? >? ? ? >> *Date: *Friday, 12 July 2024 at 17:11
>>????? >? ? ? >> *To: *squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>
>>????? >? ? ?<mailto:squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>>
>>????? >? ? ?<squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>
>>????? >? ? ?<mailto:squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>>>
>>????? >? ? ? >> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>>????? >? ? ? >>
>>????? >? ? ? >> On 2024-07-12 11:38, Ben Toms wrote:
>>????? >? ? ? >>> Think I made the changes Alex requested:
>>????? >? ? ? >>>
>>????? >? ? ? >>> 12/Jul/2024:15:36:31 +0000.640 local.server.ip
>>????? >? ? ?TCP_MISS_ABORTED/502 3974
>>????? >? ? ? >>> GET https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>
>>???? <https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>>
>>????? >? ? ?<https://local.server.fqdn/path/to/file
>>???? <https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>>>
>>????? >? ? ? > <https://local.server.fqdn/path/to/file
>>???? <https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>>
>>????? >? ? ?<https://local.server.fqdn/path/to/file
>>???? <https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>>>>
>>????? >? ? ? >> <https://local.server.fqdn/path/to/file
>>???? <https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>>
>>????? >? ? ?<https://local.server.fqdn/path/to/file
>>???? <https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>>>
>>????? >? ? ? > <https://local.server.fqdn/path/to/file
>>???? <https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>>
>>????? >? ? ?<https://local.server.fqdn/path/to/file
>>???? <https://local.server.fqdn/path/to/file 
> <https://local.server.fqdn/path/to/file>>>>> -
>>????? >? ? ? >>> FIRSTUP_PARENT/public.ip.of.public.server text/html
>>????? >? ? ? >>> ERR_READ_ERROR/WITH_SERVER
>>????? >? ? ? >>
>>????? >? ? ? >> Thank you for using Squid v6 for this test.
>>????? >? ? ? >>
>>????? >? ? ? >> Unfortunately, due to Squid logging bugs,
>>???? ERR_READ_ERROR/WITH_SERVER
>>????? >? ? ? >> does not always mean what it says. For example, parent Squid
>>????? >? ? ?could have
>>????? >? ? ? >> closed the child-parent connection prematurely, but there
>>???? could
>>????? >? ? ?be other
>>????? >? ? ? >> reasons. A full debugging log should give us more
>>???? information.
>>????? >? ? ? >>
>>????? >? ? ? >>
>>????? >? ? ? >>> 2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(274)
>>????? >? ? ?sendStartOfMessage:
>>????? >? ? ? >>> HTTP Client REPLY:
>>????? >? ? ? >>
>>????? >? ? ? >> This is a child proxy response to the client. We need parent
>>????? >? ? ?response to
>>????? >? ? ? >> the child proxy. Look for "HTTP Server RESPONSE" lines
>>???? instead.
>>????? >? ? ? >>
>>????? >? ? ? >>
>>????? >? ? ? >> HTH,
>>????? >? ? ? >>
>>????? >? ? ? >> Alex.
>>????? >? ? ? >>
>>????? >? ? ? >>
>>????? >? ? ? >>
>>????? >? ? ? >>> ---------
>>????? >? ? ? >>>
>>????? >? ? ? >>> HTTP/1.1 502 Bad Gateway
>>????? >? ? ? >>>
>>????? >? ? ? >>> Server: squid/6.6
>>????? >? ? ? >>>
>>????? >? ? ? >>> Mime-Version: 1.0
>>????? >? ? ? >>>
>>????? >? ? ? >>> Date: Fri, 12 Jul 2024 14:57:08 GMT
>>????? >? ? ? >>>
>>????? >? ? ? >>> Content-Type: text/html;charset=utf-8
>>????? >? ? ? >>>
>>????? >? ? ? >>> Content-Length: 3629
>>????? >? ? ? >>>
>>????? >? ? ? >>> X-Squid-Error: ERR_READ_ERROR 0
>>????? >? ? ? >>>
>>????? >? ? ? >>> Vary: Accept-Language
>>????? >? ? ? >>>
>>????? >? ? ? >>> Content-Language: en
>>????? >? ? ? >>>
>>????? >? ? ? >>> Cache-Status: squid.host;detail=mismatch
>>????? >? ? ? >>>
>>????? >? ? ? >>> Via: 1.1 squid.host (squid/6.6)
>>????? >? ? ? >>>
>>????? >? ? ? >>> Connection: keep-alive
>>????? >? ? ? >>>
>>????? >? ? ? >>> ----------
>>????? >? ? ? >>>
>>????? >? ? ? >>> Regards,
>>????? >? ? ? >>>
>>????? >? ? ? >>> Ben.
>>????? >? ? ? >>>
>>????? >? ? ? >>> *From: *squid-users
>>???? <squid-users-bounces at lists.squid-cache.org
>>???? <mailto:squid-users-bounces at lists.squid-cache.org 
> <mailto:squid-users-bounces at lists.squid-cache.org>>
>>????? >? ? ?<mailto:squid-users-bounces at lists.squid-cache.org
>>???? <mailto:squid-users-bounces at lists.squid-cache.org 
> <mailto:squid-users-bounces at lists.squid-cache.org>>>> on
>>????? >? ? ? >>> behalf of Amos Jeffries <squid3 at treenet.co.nz
>>???? <mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>
>>????? >? ? ?<mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>>>
>>????? >? ? ? >>> *Date: *Friday, 12 July 2024 at 15:22
>>????? >? ? ? >>> *To: *squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>
>>????? >? ? ?<mailto:squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>>
>>????? >? ? ?<squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>
>>????? >? ? ?<mailto:squid-users at lists.squid-cache.org
>>???? <mailto:squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>>>
>>????? >? ? ? >>> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>>????? >? ? ? >>>
>>????? >? ? ? >>>
>>????? >? ? ? >>> On 13/07/24 01:52, Alex Rousskov wrote:
>>????? >? ? ? >>>> On 2024-07-12 08:06, Ben Toms wrote:
>>????? >? ? ? >>>>> Seems that my issue is similar to -
>>????? >? ? ? >>>>>
>>????? >
>>     https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>>>>>
>>????? >? ? ? >>>>
>>????? >? ? ? >>>> You are facing up to two problems:
>>????? >? ? ? >>>>
>>????? >? ? ? >>>> 1. Some authenticated responses are not cachable by Squid.
>>????? >? ? ?Please share
>>????? >? ? ? >>>> HTTP headers of the response in question.
>>????? >? ? ? >>>>
>>????? >? ? ? >>>
>>????? >? ? ? >>> FYI, those can be obtained by configuring squid.conf with
>>????? >? ? ? >>>
>>????? >? ? ? >>>? ?? debug_options 11,2
>>????? >? ? ? >>>
>>????? >? ? ? >>>
>>????? >? ? ? >>> Cheers
>>????? >? ? ? >>> Amos
>>????? >? ? ? >>>
>>????? >? ? ? >>>
>>????? >? ? ? >>>> 2. TCP_MISS_ABORTED/502 errors may delete a being-cached
>>????? >? ? ?response. These
>>????? >? ? ? >>>> can be bogus errors (essentially Squid logging bugs) or
>>???? real
>>????? >? ? ?ones (e.g.,
>>????? >? ? ? >>>> due to communication bugs, misconfiguration, or
>>???? compatibility
>>????? >? ? ?problems).
>>????? >? ? ? >>>> I recommend adding %err_code/%err_detail to your
>>???? logformat and
>>????? >? ? ?sharing
>>????? >? ? ? >>>> the corresponding access.log lines (obfuscated as needed).
>>????? >? ? ? >>>>
>>????? >? ? ? >>>> Sharing (privately if needed) a pointer to compressed ALL,9
>>????? >? ? ?cache.log
>>????? >? ? ? >>>> while reproducing the issue using a single transaction may
>>????? >? ? ?help us
>>????? >? ? ? >>>> resolve all the unknowns:
>>????? >? ? ? >>>>
>>????? >? ? ? >>>>
>>????? >
>>     https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction



From squid3 at treenet.co.nz  Mon Jul 15 21:19:36 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 16 Jul 2024 09:19:36 +1200
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <5eba3547-b303-402f-93ec-507a91690e0d@measurement-factory.com>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
 <60d138f7-0c05-48d0-8d9d-959526e40499@treenet.co.nz>
 <5eba3547-b303-402f-93ec-507a91690e0d@measurement-factory.com>
Message-ID: <6cdba96f-327b-41fd-be08-2a51bd6e5047@treenet.co.nz>

On 12/07/24 10:10, Alex Rousskov wrote:
> On 2024-07-11 17:03, Amos Jeffries wrote:
>> On 11/07/24 00:49, Alex Rousskov wrote:
>>> On 2024-07-09 18:25, Fiehe, Christoph wrote:
>>>
>>>> I hope that somebody has an idea, what I am doing wrong. 
>>>
>>> AFAICT from the debugging log, it is your parent proxy that returns 
>>> an ERR_SECURE_CONNECT_FAIL error page in response to a seemingly 
>>> valid "HEAD https://..." request. Can you ask their admin to 
>>> investigate? You may also recommend that they upgrade from Squid v4 
>>> that has many known security vulnerabiities.
>>>
>>> If parent is uncooperative, you can try to reproduce the problem by 
>>> temporary installing your own parent Squid instance and configuring 
>>> your child Squid to use that instead.
>>>
>>> HTH,
>>>
>>> Alex.
>>> P.S. Unlike Amos, I do not see serious conceptual problems with 
>>> rewriting request target scheme (as a temporary compatibility 
>>> measure). It may not always work, for various reasons, but it does 
>>> not necessarily make things worse (and may make things better).
> 
> 
>> To which I refer you to:
> 
> None of the weaknesses below are applicable to request target scheme 
> rewriting (assuming both proxies in question are implemented/configured 
> correctly, of course). Specific non-applicability reasons are given 
> below for each weakness URL:
> 
>> https://cwe.mitre.org/data/definitions/311.html
> 
> The above "The product does not encrypt sensitive or critical 
> information before storage or transmission" case is not applicable: All 
> connections can be encrypted as needed after the scheme rewrite.
> 

Reminder, OP requirement is to cache the responses and send un-encrypted.

"can be" is not a safety measure.


> 
>> https://cwe.mitre.org/data/definitions/312.html
> 
> The above "The product stores sensitive information in cleartext within 
> a resource that might be accessible to another control sphere." case is 
> not applicable: Squid does not store information in such an accessible 
> resource.
> 

Reminder, Squid does cache both https:// and http:// traffic.


> 
>> https://cwe.mitre.org/data/definitions/319.html
> 
> The above "The product transmits sensitive or security-critical data in 
> cleartext in a communication channel that can be sniffed by unauthorized 
> actors." case is not applicable: All connections can be encrypted as 
> needed after the scheme rewrite.

The relevant sensitive data is in the Responses, which are absolutely 
transmitted un-encrypted per the OP requirements.


Cheers
Amos


From rousskov at measurement-factory.com  Mon Jul 15 22:35:41 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 15 Jul 2024 18:35:41 -0400
Subject: [squid-users] Rewriting HTTP to HTTPS for generic package proxy
In-Reply-To: <6cdba96f-327b-41fd-be08-2a51bd6e5047@treenet.co.nz>
References: <cbc168a71735481aaddc99c6cba92155@eurodata.de>
 <3ea0b87c-fe4a-40c7-8512-369a1299cfad@measurement-factory.com>
 <60d138f7-0c05-48d0-8d9d-959526e40499@treenet.co.nz>
 <5eba3547-b303-402f-93ec-507a91690e0d@measurement-factory.com>
 <6cdba96f-327b-41fd-be08-2a51bd6e5047@treenet.co.nz>
Message-ID: <279f92b6-b0ed-4f3a-a38a-eeae4c5c1422@measurement-factory.com>

On 2024-07-15 17:19, Amos Jeffries wrote:
> On 12/07/24 10:10, Alex Rousskov wrote:
>> On 2024-07-11 17:03, Amos Jeffries wrote:
>>> On 11/07/24 00:49, Alex Rousskov wrote:
>>>> On 2024-07-09 18:25, Fiehe, Christoph wrote:
>>>>
>>>>> I hope that somebody has an idea, what I am doing wrong. 
>>>>
>>>> AFAICT from the debugging log, it is your parent proxy that returns 
>>>> an ERR_SECURE_CONNECT_FAIL error page in response to a seemingly 
>>>> valid "HEAD https://..." request. Can you ask their admin to 
>>>> investigate? You may also recommend that they upgrade from Squid v4 
>>>> that has many known security vulnerabiities.
>>>>
>>>> If parent is uncooperative, you can try to reproduce the problem by 
>>>> temporary installing your own parent Squid instance and configuring 
>>>> your child Squid to use that instead.
>>>>
>>>> HTH,
>>>>
>>>> Alex.
>>>> P.S. Unlike Amos, I do not see serious conceptual problems with 
>>>> rewriting request target scheme (as a temporary compatibility 
>>>> measure). It may not always work, for various reasons, but it does 
>>>> not necessarily make things worse (and may make things better).
>>
>>
>>> To which I refer you to:
>>
>> None of the weaknesses below are applicable to request target scheme 
>> rewriting (assuming both proxies in question are 
>> implemented/configured correctly, of course). Specific 
>> non-applicability reasons are given below for each weakness URL:
>>
>>> https://cwe.mitre.org/data/definitions/311.html
>>
>> The above "The product does not encrypt sensitive or critical 
>> information before storage or transmission" case is not applicable: 
>> All connections can be encrypted as needed after the scheme rewrite.
>>
> 
> Reminder, OP requirement is to cache the responses and send un-encrypted.

The client does not support TLS so what happens between the client and 
Squid is irrelevant to this discussion -- a correctly 
configured/implemented Squid is not going to make things worse there. 
Squid is a part of the "product" in the above definition; client is not. 
The only relevant communication part is between Squid and origin server 
(possibly via a parent). All those network segments can be configured to 
be encrypted "before storage or transmission", avoiding the above weakness.


>>> https://cwe.mitre.org/data/definitions/312.html
>>
>> The above "The product stores sensitive information in cleartext 
>> within a resource that might be accessible to another control sphere." 
>> case is not applicable: Squid does not store information in such an 
>> accessible resource.

> Reminder, Squid does cache both https:// and http:// traffic.

I do not see how that assertion is relevant. Everything Squid caches is 
_not_ stored in an "accessible resource" described in that weakness.


>>> https://cwe.mitre.org/data/definitions/319.html
>>
>> The above "The product transmits sensitive or security-critical data 
>> in cleartext in a communication channel that can be sniffed by 
>> unauthorized actors." case is not applicable: All connections can be 
>> encrypted as needed after the scheme rewrite.
> 
> The relevant sensitive data is in the Responses, which are absolutely 
> transmitted un-encrypted per the OP requirements.

See 311.html case above: Responses are encrypted on the relevant network 
segments.

Alex.




From ben at macmule.com  Tue Jul 16 09:22:43 2024
From: ben at macmule.com (Ben Toms)
Date: Tue, 16 Jul 2024 09:22:43 +0000
Subject: [squid-users] TCP_MISS_ABORTED/502
In-Reply-To: <3790aa46-a25c-4030-a5b7-0732824bee3f@measurement-factory.com>
References: <mailman.4070.1720742085.1200.squid-users@lists.squid-cache.org>
 <1ee387d1-732e-4504-8d00-2d8a0c243d8a@measurement-factory.com>
 <LO2P265MB31651D6F080E7EF06AD34E21FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <0377b31b-4ec0-4b29-8651-a7984210e446@measurement-factory.com>
 <LO2P265MB3165A66218D288B5873339B6FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <LO2P265MB316511FB262897B4C5F4AC69FEA62@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <73240ae0-6bc0-4094-8d23-435d2c21913c@measurement-factory.com>
 <CADjniur4VwfGPReOWMGjnxkgWHcDfCsSjsj+NMNkvpD=82ai7g@mail.gmail.com>
 <6712bade-d307-4568-8eb4-14cee7fa997e@measurement-factory.com>
 <CADjniuoqjKHrXctmOQZLqpTrdquY_4ASFxTc=7H9qCh8WO=x-w@mail.gmail.com>
 <eb142f40-cf47-4a66-8245-d739a0196951@measurement-factory.com>
 <LO2P265MB316592733FD0BB2B08E3B3D8FEA72@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>
 <CWLP265MB3156BA85ADAF926FEF663D73FEA72@CWLP265MB3156.GBRP265.PROD.OUTLOOK.COM>
 <3790aa46-a25c-4030-a5b7-0732824bee3f@measurement-factory.com>
Message-ID: <LO2P265MB3165511255CE01D1E9053450FEA22@LO2P265MB3165.GBRP265.PROD.OUTLOOK.COM>

Thanks, Alex.

Nothing jumps out in the logs when set to ALL, 9.. redacted snippet below:

2024/07/16 09:13:18.072 kid1| 11,5| http.cc(1181) readReply: conn12 local=squid.cache.ip:57824 remote=origin.server.ip:443 FIRSTUP_PARENT FD 14 flags=1
2024/07/16 09:13:18.072 kid1| 11,7| http.cc(1674) canBufferMoreReplyBytes: yes, may read up to 65536 into 0/23
2024/07/16 09:13:18.072 kid1| 24,8| SBuf.cc(880) cow: SBuf5269 new size:65536
2024/07/16 09:13:18.072 kid1| 24,8| SBuf.cc(847) reAlloc: SBuf5269 new size: 65536
2024/07/16 09:13:18.072 kid1| 24,9| MemBlob.cc(54) MemBlob: constructed, this=0x568b12912270 id=blob1461 reserveSize=65536
2024/07/16 09:13:18.073 kid1| 24,8| MemBlob.cc(99) memAlloc: blob1461 memAlloc: requested=65536, received=65536
2024/07/16 09:13:18.073 kid1| 24,7| SBuf.cc(859) reAlloc: SBuf5269 new store capacity: 65536
2024/07/16 09:13:18.073 kid1| 11,7| http.cc(1694) maybeMakeSpaceAvailable: may read up to 65536 bytes info buffer (0/65536) from conn12 local=squid.cache.ip:57824 remote=origin.server.ip:443 FIRSTUP_PARENT FD 14 flags=1
2024/07/16 09:13:18.073 kid1| 45,9| cbdata.cc(228) cbdataInternalLock: 0x568b1291d588=9
2024/07/16 09:13:18.073 kid1| 24,7| SBuf.cc(160) rawSpace: reserving 65536 for SBuf5269
2024/07/16 09:13:18.073 kid1| 24,7| SBuf.cc(167) rawSpace: SBuf5269 not growing
2024/07/16 09:13:18.073 kid1| 24,8| SBuf.cc(139) rawAppendStart: SBuf5269 start appending up to 65536 bytes
2024/07/16 09:13:18.073 kid1| 83,3| Session.cc(36) tls_read_method: started for session=0x568b1290d5e0
2024/07/16 09:13:18.073 kid1| 5,3| Read.cc(93) ReadNow: conn12 local=squid.cache.ip:57824 remote=origin.server.ip:443 FIRSTUP_PARENT FD 14 flags=1, size 65536, retval -28, errno 0
2024/07/16 09:13:18.073 kid1| 5,3| Read.cc(107) ReadNow: conn12 local=squid.cache.ip:57824 remote=origin.server.ip:443 FIRSTUP_PARENT FD 14 flags=1 Comm::COMM_ERROR: (0) No error.
2024/07/16 09:13:18.073 kid1| 11,2| http.cc(1263) readReply: conn12 local=squid.cache.ip:57824 remote=origin.server.ip:443 FIRSTUP_PARENT FD 14 flags=1: read failure: (0) No error.
2024/07/16 09:13:18.073 kid1| 45,9| cbdata.cc(168) cbdataInternalAlloc: Allocating 0x568b1291cc18
2024/07/16 09:13:18.073 kid1| 24,8| SBuf.cc(30) SBuf: SBuf5291 created
2024/07/16 09:13:18.073 kid1| 17,3| FwdState.cc(471) fail: ERR_READ_ERROR "Bad Gateway"
                https://origin.server.fqdn/path/to/file

As we?re sadly not progressing.. I think we?ll pivot to building our own thing to more closely match our requirements.

Thanks to yourself and Amos for responding.

Regards,
Ben.

From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Alex Rousskov <rousskov at measurement-factory.com>
Date: Monday, 15 July 2024 at 19:38
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] TCP_MISS_ABORTED/502
On 2024-07-13 16:02, Ben Toms wrote:

> with debug_options ALL,4 set.. the cache.log shows:

> 2024/07/13 18:55:03.595 kid1| 5,3| Read.cc(93) ReadNow: conn17
> local=squid.cache.ip:37046 remote=origin.server.ip:443 FIRSTUP_PARENT FD
> 14 flags=1, size 65536, retval -28, errno 0

> 2024/07/13 18:55:03.595 kid1| 17,3| FwdState.cc(471) fail:
> ERR_READ_ERROR "Bad Gateway"


> Still need to dig in more.. but the true error seems to be:
> ERR_READ_ERROR "Bad Gateway"

AFAICT, the underlying error happens a bit earlier (probably at TLS
layer), just before the "retval -28" line above. Official high-level
Squid code that produced the above log lines does not detail those TLS
errors. I do not know what went wrong between Squid and Apache.

Going forward, I see four options:

A) Examine origin logs. It is likely that Apache logs what is going
wrong with that TLS session from httpd point of view.

B) (Privately) examine Squid ALL,9 logs. Squid OpenSSL integration code
might log something relevant to this context.

C) Examine Squid-origin packet capture. If you supply TLS master keys to
Wireshark or a similar tool, you may be able to see a relevant TLS alert
in that TLS stream.

D) Find somebody to patch Squid source code to add more debugging info
if (B) did not produce enough new/usable hints.


HTH,

Alex.

> *From: *Ben Toms <ben at macmule.com>
> *Date: *Saturday, 13 July 2024 at 13:04
> *To: *Alex Rousskov <rousskov at measurement-factory.com>
> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>
> Well.. tried with cache-control headers added to the apache servers
> responses.. and still no luck (header response below).
>
> Date: Sat, 13 Jul 2024 12:00:02 GMT
>
> Server: Apache
>
> Last-Modified: Thu, 20 Jun 2024 13:57:21 GMT
>
> ETag: "152c-61b52b19bbd2a"
>
> Accept-Ranges: bytes
>
> Content-Length: 5420
>
> Cache-Control: max-age=84600, public
>
> Connection: close
>
> I?ve tried a few other sites and the issue seems to be when attempting
> to cache an item which requires authentication. Which is bizarre, as the
> apache server is showing files are being downloaded.. yet squid-cache is
> still erroring with TCP_MISS_ABORTED/502.
>
> Regards,
>
> Ben.
>
> *From: *Alex Rousskov <rousskov at measurement-factory.com>
> *Date: *Friday, 12 July 2024 at 22:54
> *To: *Ben Toms <ben at macmule.com>
> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>
> On 2024-07-12 14:31, Ben Toms wrote:
>
>> So this squid cache is the parent (which might speak to me
>> misconfiguring squid).
>>
>> It?s setup as an accelerator for the public server.
>
> Ah, I see. Sorry I forgot or misinterpreted that part. Too many balls in
> the air.
>
> Right now, it sounds like origin sent 200 OK, but Squid could not even
> parse that response header, which is rather unusual/rare. However, that
> theory is based on your interpretation of ALL,2 logs, so there may be
> more to the story here.
>
>
>> When I curl the public server direct, there are no cache control headers.
>
> Understood. I suspect Squid will not cache such authenticated responses
> by default (even after Squid starts to receive them), but I have not
> checked all the relevant details.
>
>
> Cheers,
>
> Alex.
>
>
>> On Fri, 12 Jul 2024 at 19:15, Alex Rousskov  wrote:
>>
>>     On 2024-07-12 13:38, Ben Toms wrote:
>>
>>      > Where would I find those headers?
>>
>>     If you have access to the parent Squid proxy, they will be in its
>>     debugging cache.log. You can also get them by capturing network packets
>>     between the parent Squid and origin, but for HTTPS traffic that
>>     requires
>>     giving Wireshark the associated master keys, which may be possible with
>>     Squid v6, but not trivial (see tls_key_log in Squid; Apache may have
>>     better support for this). Finally, one can configure Apache to log them
>>     (sorry, I do not remember the details).
>>
>>     Again, the child Squid does not see these headers yet (AFAICT), so they
>>     are not the reason things do not currently "work" in your tests.
>>
>>
>>      > Looking at the origin servers apache logs.. it?s sending a 200
>>     response.
>>
>>     I am aware. We need the headers that go with that 200 OK response. For
>>     example, if it has Cache-Control:public, then Squid may be able to
>>     cache
>>     it despite authentication.
>>
>>
>>     HTH,
>>
>>     Alex.
>>
>>
>>      > On Fri, 12 Jul 2024 at 18:26, Alex Rousskov wrote:
>>      >
>>      >     On 2024-07-12 13:03, Ben Toms wrote:
>>      >
>>      >      > So the issue seems to be caching content that requires
>>     authentication
>>      >
>>      >     The client is getting an error response from Squid. That error is
>>      >     probably not related to caching decisions. I do not recommend
>>     focusing
>>      >     on caching at this stage of triage. I recommend addressing that
>>      >     error first.
>>      >
>>      >
>>      >      > The question here is, can squid cache items that require
>>      >     authentication
>>      >      > to access?
>>      >
>>      >     Yes, in some cases. To know whether your case qualifies, I
>>     asked for
>>      >     the
>>      >     response headers. That led to the discovery that there are
>>     none (from
>>      >     child Squid point of view). If you really want to investigate the
>>      >     caching angle in parallel with solving
>>     ERR_READ_ERROR/WITH_SERVER, then
>>      >     try to obtain HTTP response headers that the origin server
>>     responds (to
>>      >     the parent cache) with.
>>      >
>>      >
>>      >     HTH,
>>      >
>>      >     Alex.
>>      >
>>      >
>>      >      > *From: *Ben Toms <ben at macmule.com <mailto:ben at macmule.com <mailto:ben at macmule.com>>
>>     <mailto:ben at macmule.com <mailto:ben at macmule.com <mailto:ben at macmule.com>>>>
>>      >      > *Date: *Friday, 12 July 2024 at 17:56
>>      >      > *To: *Alex Rousskov <rousskov at measurement-factory.com
>>     <mailto:rousskov at measurement-factory.com
> <mailto:rousskov at measurement-factory.com>>
>>      >     <mailto:rousskov at measurement-factory.com
>>     <mailto:rousskov at measurement-factory.com
> <mailto:rousskov at measurement-factory.com>>>>,
>>      >      > squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>
>>      >     <mailto:squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>>
>>      >     <squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>
>>      >     <mailto:squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>>>
>>      >      > *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>>      >      >
>>      >      > So, with the below config:
>>      >      >
>>      >      > https_port 443 accel protocol=HTTPS
>>      >     tls-cert=/usr/local/squid/client.pem
>>      >      > tls-key=/usr/local/squid/client.key
>>      >      >
>>      >      > cache_peer public.server.fqdn parent 443 0 no-query
>>     originserver
>>      >      > no-digest no-netdb-exchange tls login=PASSTHRU name=myAccel
>>      >      > forceddomain=public.server.fqdn
>>      >      >
>>      >      > acl our_sites dstdomain local.server.fqdn
>>      >      >
>>      >      > http_access allow our_sites
>>      >      >
>>      >      > cache_peer_access myAccel allow our_sites
>>      >      >
>>      >      > cache_peer_access myAccel deny all
>>      >      >
>>      >      > cache_dir ufs /usr/local/squid/var/cache 100000 16 256
>>      >      >
>>      >      > cache_mem 500 MB
>>      >      >
>>      >      > maximum_object_size_in_memory 50000 KB
>>      >      >
>>      >      > refresh_pattern .               0       20%     4320
>>      >      >
>>      >      > debug_options 11,2
>>      >      >
>>      >      > I can see the below in /var/log/squid/cache.log
>>      >      >
>>      >      > ----------
>>      >      >
>>      >      > 2024/07/12 16:49:57.056 kid1| 11,2| http.cc(1263)
>>     readReply: conn12
>>      >      > local=client.ip:56670 remote=public.ip.of.public.server:443
>>      >      > FIRSTUP_PARENT FD 14 flags=1: read failure: (0) No error.
>>      >      >
>>      >      > 2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(273)
>>      >     sendStartOfMessage:
>>      >      > HTTP Client conn9 local=client.ip:443
>>      >     remote=local.server.ip:59158 FD 13
>>      >      > flags=1
>>      >      >
>>      >      > 2024/07/12 16:49:57.056 kid1| 11,2| Stream.cc(274)
>>      >     sendStartOfMessage:
>>      >      > HTTP Client REPLY:
>>      >      >
>>      >      > ---------
>>      >      >
>>      >      > HTTP/1.1 502 Bad Gateway
>>      >      >
>>      >      > Server: squid/6.6
>>      >      >
>>      >      > Mime-Version: 1.0
>>      >      >
>>      >      > Date: Fri, 12 Jul 2024 16:49:57 GMT
>>      >      >
>>      >      > Content-Type: text/html;charset=utf-8
>>      >      >
>>      >      > Content-Length: 3629
>>      >      >
>>      >      > X-Squid-Error: ERR_READ_ERROR 0
>>      >      >
>>      >      > Vary: Accept-Language
>>      >      >
>>      >      > Content-Language: en
>>      >      >
>>      >      > Cache-Status: local.server;detail=mismatch
>>      >      >
>>      >      > Via: 1.1 local.server (squid/6.6)
>>      >      >
>>      >      > Connection: keep-alive
>>      >      >
>>      >      > ----------
>>      >      >
>>      >      > The apache server still shows a 200 for the request:
>>      >      >
>>      >      > [12/Jul/2024:17:49:57 +0100] "GET /path/to/file HTTP/1.1" 200
>>      >     10465 "-"
>>      >      > "curl/8.7.1"
>>      >      >
>>      >      > And this is when testing via:
>>      >      >
>>      >      > curl -D - https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file>
>>     <https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file>>
>>      >     <https://local.server.fqdn/path/to/file
>>     <https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file>>>
>>      >      > <https://local.server.fqdn/path/to/file
>>     <https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file>>
>>      >     <https://local.server.fqdn/path/to/file
>>     <https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file>>>> -H "Authorization: Basic
>>      >      > base64auth" -o /dev/null
>>      >      >
>>      >      > Regards,
>>      >      >
>>      >      > Ben.
>>      >      >
>>      >      > *From: *Alex Rousskov <rousskov at measurement-factory.com
>>     <mailto:rousskov at measurement-factory.com
> <mailto:rousskov at measurement-factory.com>>
>>      >     <mailto:rousskov at measurement-factory.com
>>     <mailto:rousskov at measurement-factory.com
> <mailto:rousskov at measurement-factory.com>>>>
>>      >      > *Date: *Friday, 12 July 2024 at 17:36
>>      >      > *To: *Ben Toms <ben at macmule.com <mailto:ben at macmule.com <mailto:ben at macmule.com>>
>>     <mailto:ben at macmule.com <mailto:ben at macmule.com <mailto:ben at macmule.com>>>>,
>>      > squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>
>>      >     <mailto:squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>>
>>      >      > <squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>
>>      >     <mailto:squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>>>
>>      >      > *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>>      >      >
>>      >      > On 2024-07-12 12:14, Ben Toms wrote:
>>      >      >
>>      >      >> Which log should those be found?
>>      >      >
>>      >      > cache.log (if they are present)
>>      >      >
>>      >      >
>>      >      >> Can?t see ?HTTP Server RESPONSE? in the access.log or
>>     cache.log.
>>      >      >
>>      >      > Sigh. This is one of the reasons I avoid asking folks to
>>     study logs
>>      >      > themselves, even ALL,2 logs...
>>      >      >
>>      >      > If that line is not in cache.log, then child Squid
>>     probably did not
>>      >      > receive a response from parent Squid, or could not parse that
>>      >     response.
>>      >      > A full debugging log should give us more information.
>>      >      >
>>      >      > Alex.
>>      >      >
>>      >      >
>>      >      >> *From: *squid-users
>>     <squid-users-bounces at lists.squid-cache.org
>>     <mailto:squid-users-bounces at lists.squid-cache.org
> <mailto:squid-users-bounces at lists.squid-cache.org>>
>>      >     <mailto:squid-users-bounces at lists.squid-cache.org
>>     <mailto:squid-users-bounces at lists.squid-cache.org
> <mailto:squid-users-bounces at lists.squid-cache.org>>>> on
>>      >      >> behalf of Alex Rousskov <rousskov at measurement-factory.com
>>     <mailto:rousskov at measurement-factory.com
> <mailto:rousskov at measurement-factory.com>>
>>      >     <mailto:rousskov at measurement-factory.com
>>     <mailto:rousskov at measurement-factory.com
> <mailto:rousskov at measurement-factory.com>>>>
>>      >      >> *Date: *Friday, 12 July 2024 at 17:11
>>      >      >> *To: *squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>
>>      >     <mailto:squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>>
>>      >     <squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>
>>      >     <mailto:squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>>>
>>      >      >> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>>      >      >>
>>      >      >> On 2024-07-12 11:38, Ben Toms wrote:
>>      >      >>> Think I made the changes Alex requested:
>>      >      >>>
>>      >      >>> 12/Jul/2024:15:36:31 +0000.640 local.server.ip
>>      >     TCP_MISS_ABORTED/502 3974
>>      >      >>> GET https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file>
>>     <https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file>>
>>      >     <https://local.server.fqdn/path/to/file
>>     <https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file>>>
>>      >      > <https://local.server.fqdn/path/to/file
>>     <https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file>>
>>      >     <https://local.server.fqdn/path/to/file
>>     <https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file>>>>
>>      >      >> <https://local.server.fqdn/path/to/file
>>     <https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file>>
>>      >     <https://local.server.fqdn/path/to/file
>>     <https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file>>>
>>      >      > <https://local.server.fqdn/path/to/file
>>     <https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file>>
>>      >     <https://local.server.fqdn/path/to/file
>>     <https://local.server.fqdn/path/to/file
> <https://local.server.fqdn/path/to/file>>>>> -
>>      >      >>> FIRSTUP_PARENT/public.ip.of.public.server text/html
>>      >      >>> ERR_READ_ERROR/WITH_SERVER
>>      >      >>
>>      >      >> Thank you for using Squid v6 for this test.
>>      >      >>
>>      >      >> Unfortunately, due to Squid logging bugs,
>>     ERR_READ_ERROR/WITH_SERVER
>>      >      >> does not always mean what it says. For example, parent Squid
>>      >     could have
>>      >      >> closed the child-parent connection prematurely, but there
>>     could
>>      >     be other
>>      >      >> reasons. A full debugging log should give us more
>>     information.
>>      >      >>
>>      >      >>
>>      >      >>> 2024/07/12 14:57:08.678 kid1| 11,2| Stream.cc(274)
>>      >     sendStartOfMessage:
>>      >      >>> HTTP Client REPLY:
>>      >      >>
>>      >      >> This is a child proxy response to the client. We need parent
>>      >     response to
>>      >      >> the child proxy. Look for "HTTP Server RESPONSE" lines
>>     instead.
>>      >      >>
>>      >      >>
>>      >      >> HTH,
>>      >      >>
>>      >      >> Alex.
>>      >      >>
>>      >      >>
>>      >      >>
>>      >      >>> ---------
>>      >      >>>
>>      >      >>> HTTP/1.1 502 Bad Gateway
>>      >      >>>
>>      >      >>> Server: squid/6.6
>>      >      >>>
>>      >      >>> Mime-Version: 1.0
>>      >      >>>
>>      >      >>> Date: Fri, 12 Jul 2024 14:57:08 GMT
>>      >      >>>
>>      >      >>> Content-Type: text/html;charset=utf-8
>>      >      >>>
>>      >      >>> Content-Length: 3629
>>      >      >>>
>>      >      >>> X-Squid-Error: ERR_READ_ERROR 0
>>      >      >>>
>>      >      >>> Vary: Accept-Language
>>      >      >>>
>>      >      >>> Content-Language: en
>>      >      >>>
>>      >      >>> Cache-Status: squid.host;detail=mismatch
>>      >      >>>
>>      >      >>> Via: 1.1 squid.host (squid/6.6)
>>      >      >>>
>>      >      >>> Connection: keep-alive
>>      >      >>>
>>      >      >>> ----------
>>      >      >>>
>>      >      >>> Regards,
>>      >      >>>
>>      >      >>> Ben.
>>      >      >>>
>>      >      >>> *From: *squid-users
>>     <squid-users-bounces at lists.squid-cache.org
>>     <mailto:squid-users-bounces at lists.squid-cache.org
> <mailto:squid-users-bounces at lists.squid-cache.org>>
>>      >     <mailto:squid-users-bounces at lists.squid-cache.org
>>     <mailto:squid-users-bounces at lists.squid-cache.org
> <mailto:squid-users-bounces at lists.squid-cache.org>>>> on
>>      >      >>> behalf of Amos Jeffries <squid3 at treenet.co.nz
>>     <mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>
>>      >     <mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>>>
>>      >      >>> *Date: *Friday, 12 July 2024 at 15:22
>>      >      >>> *To: *squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>
>>      >     <mailto:squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>>
>>      >     <squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>
>>      >     <mailto:squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>>>>
>>      >      >>> *Subject: *Re: [squid-users] TCP_MISS_ABORTED/502
>>      >      >>>
>>      >      >>>
>>      >      >>> On 13/07/24 01:52, Alex Rousskov wrote:
>>      >      >>>> On 2024-07-12 08:06, Ben Toms wrote:
>>      >      >>>>> Seems that my issue is similar to -
>>      >      >>>>>
>>      >
>>     https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>> <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication <https://serverfault.com/questions/1104330/squid-cache-items-behind-basic-authentication>>>>>>
>>      >      >>>>
>>      >      >>>> You are facing up to two problems:
>>      >      >>>>
>>      >      >>>> 1. Some authenticated responses are not cachable by Squid.
>>      >     Please share
>>      >      >>>> HTTP headers of the response in question.
>>      >      >>>>
>>      >      >>>
>>      >      >>> FYI, those can be obtained by configuring squid.conf with
>>      >      >>>
>>      >      >>>     debug_options 11,2
>>      >      >>>
>>      >      >>>
>>      >      >>> Cheers
>>      >      >>> Amos
>>      >      >>>
>>      >      >>>
>>      >      >>>> 2. TCP_MISS_ABORTED/502 errors may delete a being-cached
>>      >     response. These
>>      >      >>>> can be bogus errors (essentially Squid logging bugs) or
>>     real
>>      >     ones (e.g.,
>>      >      >>>> due to communication bugs, misconfiguration, or
>>     compatibility
>>      >     problems).
>>      >      >>>> I recommend adding %err_code/%err_detail to your
>>     logformat and
>>      >     sharing
>>      >      >>>> the corresponding access.log lines (obfuscated as needed).
>>      >      >>>>
>>      >      >>>> Sharing (privately if needed) a pointer to compressed ALL,9
>>      >     cache.log
>>      >      >>>> while reproducing the issue using a single transaction may
>>      >     help us
>>      >      >>>> resolve all the unknowns:
>>      >      >>>>
>>      >      >>>>
>>      >
>>     https://wiki.squid-cache.org/SquidFaq/BugReporting#debugging-a-single-transaction


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240716/06a6cc80/attachment.htm>

From raho at priceshape.dk  Tue Jul 16 13:31:24 2024
From: raho at priceshape.dk (Rasmus Horndrup)
Date: Tue, 16 Jul 2024 15:31:24 +0200
Subject: [squid-users] Prefer or force ipv6 usage on dual stack interface
Message-ID: <AFCF2E50-BC23-41C2-900F-CD9575FC5741@priceshape.dk>

Hi,
On a dual stack network interface I?m interested in using squid as a ipv6 only forward proxy.
My general understanding was that squid will prefer to use ipv6 whenever available, but I?m having issues with squid seemingly preferring ipv4 in some cases.

I have two examples, where it proceeds using IPv6 for the first and IPv4 for the second.

From the looks of it, they both successfully receive A and AAAA records, but how can I basically force squid to use IPv6? 

Resolves to IPv6:
---------
CONNECT www.google.com:443 HTTP/1.1
Host: www.google.com:443
Proxy-Authorization: Basic cHJpY2VzaGFwZTpwcmljZXNoYXBlMTIz
User-Agent: curl/8.6.0
Proxy-Connection: Keep-Alive


----------
2024/07/16 14:08:58.089 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
2024/07/16 14:08:58.089 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname: ipcache_gethostbyname: 'www.google.com', flags=1
2024/07/16 14:08:58.090 kid1| 14,3| ipcache.cc(313) ipcacheRelease: ipcacheRelease: Releasing entry for 'www.google.com'
2024/07/16 14:08:58.090 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
2024/07/16 14:08:58.090 kid1| 14,4| ipcache.cc(610) ipcache_nbgethostbyname: www.google.com
2024/07/16 14:08:58.090 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
2024/07/16 14:08:58.090 kid1| 14,5| ipcache.cc(670) ipcache_nbgethostbyname_: ipcache_nbgethostbyname: MISS for 'www.google.com'
2024/07/16 14:08:58.090 kid1| 78,3| dns_internal.cc(1793) idnsALookup: idnsALookup: buf is 32 bytes for www.google.com, id = 0xfc67
2024/07/16 14:08:58.090 kid1| 78,3| dns_internal.cc(1729) idnsSendSlaveAAAAQuery: buf is 32 bytes for www.google.com, id = 0x147d
2024/07/16 14:08:58.090 kid1| 14,4| ipcache.cc(610) ipcache_nbgethostbyname: www.google.com
2024/07/16 14:08:58.090 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
2024/07/16 14:08:58.090 kid1| 14,5| ipcache.cc(670) ipcache_nbgethostbyname_: ipcache_nbgethostbyname: MISS for 'www.google.com'
2024/07/16 14:08:58 pinger| Pinger exiting.
2024/07/16 14:08:58.117 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting with FD 10
2024/07/16 14:08:58.117 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 10: received 144 bytes from [2001:4860:4860::8888]:53
2024/07/16 14:08:58.117 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply: QID 0x147d, 4 answers
2024/07/16 14:08:58.117 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: 4 records for 0x648c0dbd80d8
2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(480) ipcacheParse: 4 answers for www.google.com
2024/07/16 14:08:58.117 kid1| 14,5| ipcache.cc(549) updateTtl: use first 300 from RR TTL 300
2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #1 [2607:f8b0:4004:c07::93]
2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #2 [2607:f8b0:4004:c07::6a]
2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #3 [2607:f8b0:4004:c07::67]
2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #4 [2607:f8b0:4004:c07::68]
2024/07/16 14:08:58.117 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: 4 records for 0x648c0dbdca68
2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(480) ipcacheParse: 4 answers for www.google.com
2024/07/16 14:08:58.117 kid1| 14,5| ipcache.cc(549) updateTtl: use first 300 from RR TTL 300
2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #1 [2607:f8b0:4004:c07::93]
2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #2 [2607:f8b0:4004:c07::6a]
2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #3 [2607:f8b0:4004:c07::67]
2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #4 [2607:f8b0:4004:c07::68]
2024/07/16 14:08:58.129 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting with FD 10
2024/07/16 14:08:58.129 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 10: received 128 bytes from [2001:4860:4860::8888]:53
2024/07/16 14:08:58.129 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply: QID 0xfc67, 6 answers
2024/07/16 14:08:58.129 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: last 6 records for 0x648c0dbd80d8
2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(480) ipcacheParse: 6 answers for www.google.com
2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #5 172.253.62.106
2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #6 172.253.62.104
2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #7 172.253.62.99
2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #8 172.253.62.103
2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #9 172.253.62.105
2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #10 172.253.62.147
2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(586) ipcacheHandleReply: done with www.google.com: [2607:f8b0:4004:c07::93] #1/10-0
2024/07/16 14:08:58.129 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: last 6 records for 0x648c0dbdca68
2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(480) ipcacheParse: 6 answers for www.google.com
2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #5 172.253.62.106
2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #6 172.253.62.104
2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #7 172.253.62.99
2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #8 172.253.62.103
2024/07/16 14:08:58.130 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #9 172.253.62.105
2024/07/16 14:08:58.130 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #10 172.253.62.147
2024/07/16 14:08:58.130 kid1| 14,3| ipcache.cc(586) ipcacheHandleReply: done with www.google.com: [2607:f8b0:4004:c07::93] #1/10-0
2024/07/16 14:08:58.130 kid1| 14,3| ipcache.cc(313) ipcacheRelease: ipcacheRelease: Releasing entry for 'www.google.com'
2024/07/16 14:08:58.130 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname: ipcache_gethostbyname: 'www.google.com', flags=1
2024/07/16 14:08:58.130 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname: ipcache_gethostbyname: 'www.google.com', flags=1
2024/07/16 14:08:58.130 kid1| 26,3| tunnel.cc(1141) tunnelStart: tunnelStart 
2024/07/16 14:08:58.130 kid1| 26,3| tunnel.cc(1174) tunnelStart: CONNECT www.google.com:443 HTTP/1.1
2024/07/16 14:08:58.130 kid1| 26,3| tunnel.cc(359) TunnelStateData: TunnelStateData constructed this=0x648c0e047388
2024/07/16 14:08:58.130 kid1| 14,4| ipcache.cc(617) nbgethostbyname: www.google.com
2024/07/16 14:08:58.131 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
2024/07/16 14:08:58.131 kid1| 14,4| ipcache.cc(657) ipcache_nbgethostbyname_: ipcache_nbgethostbyname: HIT for 'www.google.com'
2024/07/16 14:08:58.227 kid1| 26,5| tunnel.cc(508) updateAttempts: 1
2024/07/16 14:08:58.227 kid1| 14,4| ipcache.cc(610) ipcache_nbgethostbyname: www.google.com
2024/07/16 14:08:58.227 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
2024/07/16 14:08:58.227 kid1| 14,4| ipcache.cc(657) ipcache_nbgethostbyname_: ipcache_nbgethostbyname: HIT for 'www.google.com'
2024/07/16 14:08:58.227 kid1| 14,5| net_db.cc(357) networkFromInaddr: networkFromInaddr : Masked IPv6 Address to [2607:f8b0:4004:c07::93]/64 routing part.



Resolves to IPv4:
---------
CONNECT www.google.com:443 HTTP/1.1
Host: www.google.com:443
Proxy-Authorization: Basic cHJpY2VzaGFwZTpwcmljZXNoYXBlMTIz
User-Agent: curl/8.6.0
Proxy-Connection: Keep-Alive


----------
2024/07/16 14:29:01.280 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
2024/07/16 14:29:01.280 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname: ipcache_gethostbyname: 'www.google.com', flags=1
2024/07/16 14:29:01.280 kid1| 14,3| ipcache.cc(313) ipcacheRelease: ipcacheRelease: Releasing entry for 'www.google.com'
2024/07/16 14:29:01.280 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
2024/07/16 14:29:01.280 kid1| 14,4| ipcache.cc(610) ipcache_nbgethostbyname: www.google.com
2024/07/16 14:29:01.280 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
2024/07/16 14:29:01.280 kid1| 14,5| ipcache.cc(670) ipcache_nbgethostbyname_: ipcache_nbgethostbyname: MISS for 'www.google.com'
2024/07/16 14:29:01.280 kid1| 78,3| dns_internal.cc(1793) idnsALookup: idnsALookup: buf is 32 bytes for www.google.com, id = 0xd80b
2024/07/16 14:29:01.280 kid1| 78,3| dns_internal.cc(1729) idnsSendSlaveAAAAQuery: buf is 32 bytes for www.google.com, id = 0xacdf
2024/07/16 14:29:01.280 kid1| 14,4| ipcache.cc(610) ipcache_nbgethostbyname: www.google.com
2024/07/16 14:29:01.280 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
2024/07/16 14:29:01.280 kid1| 14,5| ipcache.cc(670) ipcache_nbgethostbyname_: ipcache_nbgethostbyname: MISS for 'www.google.com'
2024/07/16 14:29:01.300 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting with FD 8
2024/07/16 14:29:01.300 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 8: received 128 bytes from [2001:4860:4860::8888]:53
2024/07/16 14:29:01.300 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply: QID 0xd80b, 6 answers
2024/07/16 14:29:01.300 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: 6 records for 0x5a939a3a4e08
2024/07/16 14:29:01.300 kid1| 14,3| ipcache.cc(480) ipcacheParse: 6 answers for www.google.com
2024/07/16 14:29:01.300 kid1| 14,5| ipcache.cc(549) updateTtl: use first 300 from RR TTL 300
2024/07/16 14:29:01.300 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #1 172.253.62.104
2024/07/16 14:29:01.300 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #2 172.253.62.103
2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #3 172.253.62.105
2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #4 172.253.62.147
2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #5 172.253.62.106
2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #6 172.253.62.99
2024/07/16 14:29:01.301 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: 6 records for 0x5a939a3a0438
2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(480) ipcacheParse: 6 answers for www.google.com
2024/07/16 14:29:01.301 kid1| 14,5| ipcache.cc(549) updateTtl: use first 300 from RR TTL 300
2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #1 172.253.62.104
2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #2 172.253.62.103
2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #3 172.253.62.105
2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #4 172.253.62.147
2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #5 172.253.62.106
2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #6 172.253.62.99
2024/07/16 14:29:01.311 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting with FD 8
2024/07/16 14:29:01.311 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 8: received 144 bytes from [2001:4860:4860::8888]:53
2024/07/16 14:29:01.311 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply: QID 0xacdf, 4 answers
2024/07/16 14:29:01.311 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: last 4 records for 0x5a939a3a4e08
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(480) ipcacheParse: 4 answers for www.google.com
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #7 [2607:f8b0:4004:c07::6a]
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #8 [2607:f8b0:4004:c07::93]
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #9 [2607:f8b0:4004:c07::63]
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #10 [2607:f8b0:4004:c07::69]
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(586) ipcacheHandleReply: done with www.google.com: 172.253.62.104 #1/10-0
2024/07/16 14:29:01.311 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: last 4 records for 0x5a939a3a0438
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(480) ipcacheParse: 4 answers for www.google.com
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #7 [2607:f8b0:4004:c07::6a]
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #8 [2607:f8b0:4004:c07::93]
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #9 [2607:f8b0:4004:c07::63]
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #10 [2607:f8b0:4004:c07::69]
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(586) ipcacheHandleReply: done with www.google.com: 172.253.62.104 #1/10-0
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(313) ipcacheRelease: ipcacheRelease: Releasing entry for 'www.google.com'
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname: ipcache_gethostbyname: 'www.google.com', flags=1
2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname: ipcache_gethostbyname: 'www.google.com', flags=1
2024/07/16 14:29:01.311 kid1| 26,3| tunnel.cc(1141) tunnelStart: tunnelStart 
2024/07/16 14:29:01.312 kid1| 26,3| tunnel.cc(1174) tunnelStart: CONNECT www.google.com:443 HTTP/1.1
2024/07/16 14:29:01.312 kid1| 26,3| tunnel.cc(359) TunnelStateData: TunnelStateData constructed this=0x5a939a80e858
2024/07/16 14:29:01.312 kid1| 44,3| peer_select.cc(311) peerSelect: CONNECT
2024/07/16 14:29:01.312 kid1| 44,3| peer_select.cc(612) selectMore: CONNECT www.google.com
2024/07/16 14:29:01.312 kid1| 44,3| peer_select.cc(577) checkNetdbDirect: MY RTT = 95 msec
2024/07/16 14:29:01.312 kid1| 44,3| peer_select.cc(578) checkNetdbDirect: minimum_direct_rtt = 400 msec
2024/07/16 14:29:01.312 kid1| 44,3| peer_select.cc(644) selectMore: direct = DIRECT_YES (checkNetdbDirect)
2024/07/16 14:29:01.312 kid1| 44,3| peer_select.cc(650) selectMore: direct = DIRECT_YES
2024/07/16 14:29:01.312 kid1| 44,3| peer_select.cc(1102) addSelection: adding HIER_DIRECT#www.google.com
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(460) resolveSelected: Find IP destination for: www.google.com:443' via www.google.com
2024/07/16 14:29:01.312 kid1| 14,4| ipcache.cc(617) nbgethostbyname: www.google.com
2024/07/16 14:29:01.312 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
2024/07/16 14:29:01.312 kid1| 14,4| ipcache.cc(657) ipcache_nbgethostbyname_: ipcache_nbgethostbyname: HIT for 'www.google.com'
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn24 local=0.0.0.0 remote=172.253.62.104:443 HIER_DIRECT flags=1, destination #1 for www.google.com:443
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
2024/07/16 14:29:01.312 kid1| 17,5| AsyncCall.cc(29) AsyncCall: The AsyncCall TunnelStateData::noteConnection constructed, this=0x5a939a8009c0 [call2215]
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn25 local=0.0.0.0 remote=172.253.62.103:443 HIER_DIRECT flags=1, destination #2 for www.google.com:443
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn26 local=0.0.0.0 remote=172.253.62.105:443 HIER_DIRECT flags=1, destination #3 for www.google.com:443
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn27 local=0.0.0.0 remote=172.253.62.147:443 HIER_DIRECT flags=1, destination #4 for www.google.com:443
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn28 local=0.0.0.0 remote=172.253.62.106:443 HIER_DIRECT flags=1, destination #5 for www.google.com:443
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn29 local=0.0.0.0 remote=172.253.62.99:443 HIER_DIRECT flags=1, destination #6 for www.google.com:443
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn30 local=[::] remote=[2607:f8b0:4004:c07::6a]:443 HIER_DIRECT flags=1, destination #7 for www.google.com:443
2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn31 local=[::] remote=[2607:f8b0:4004:c07::93]:443 HIER_DIRECT flags=1, destination #8 for www.google.com:443
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn32 local=[::] remote=[2607:f8b0:4004:c07::63]:443 HIER_DIRECT flags=1, destination #9 for www.google.com:443
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn33 local=[::] remote=[2607:f8b0:4004:c07::69]:443 HIER_DIRECT flags=1, destination #10 for www.google.com:443
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(479) resolveSelected: PeerSelector2 found all 10 destinations for www.google.com:443
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(480) resolveSelected: always_direct = DENIED
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(481) resolveSelected: never_direct = DENIED
2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(482) resolveSelected: timedout = 0
2024/07/16 14:29:01.313 kid1| 17,3| FwdState.cc(1568) GetMarkingsToServer: from 0.0.0.0 tos 0 netfilter mark 0
2024/07/16 14:29:01.409 kid1| 17,4| HappyConnOpener.cc(501) sendSuccess: new prime connection: conn35 local=HIDDEN:38852 remote=172.253.62.104:443 HIER_DIRECT FD 15 flags=1 @0
2024/07/16 14:29:01.409 kid1| 17,5| AsyncCall.cc(96) ScheduleCall: HappyConnOpener.cc(505) will call TunnelStateData::noteConnection(new conn35 local=HIDDEN remote=172.253.62.104:443 HIER_DIRECT FD 15 flags=1 @0) [call2215]



Best regards

Rasmus


From squid.org at bloms.de  Tue Jul 16 15:11:57 2024
From: squid.org at bloms.de (Dieter Bloms)
Date: Tue, 16 Jul 2024 17:11:57 +0200
Subject: [squid-users] Prefer or force ipv6 usage on dual stack interface
In-Reply-To: <AFCF2E50-BC23-41C2-900F-CD9575FC5741@priceshape.dk>
References: <AFCF2E50-BC23-41C2-900F-CD9575FC5741@priceshape.dk>
Message-ID: <20240716151144.2sr6th4vm65lfulz@bloms.de>

Hello Rasmus,

squid has implemented the happy eyeballs algorithm, so squid uses the
best protocol to reach the server.

More infos about happy eyeball can be found here: https://datatracker.ietf.org/doc/html/rfc8305

On Tue, Jul 16, Rasmus Horndrup wrote:

> Hi,
> On a dual stack network interface I?m interested in using squid as a ipv6 only forward proxy.
> My general understanding was that squid will prefer to use ipv6 whenever available, but I?m having issues with squid seemingly preferring ipv4 in some cases.
> 
> I have two examples, where it proceeds using IPv6 for the first and IPv4 for the second.
> 
> From the looks of it, they both successfully receive A and AAAA records, but how can I basically force squid to use IPv6? 
> 
> Resolves to IPv6:
> ---------
> CONNECT www.google.com:443 HTTP/1.1
> Host: www.google.com:443
> Proxy-Authorization: Basic cHJpY2VzaGFwZTpwcmljZXNoYXBlMTIz
> User-Agent: curl/8.6.0
> Proxy-Connection: Keep-Alive
> 
> 
> ----------
> 2024/07/16 14:08:58.089 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
> 2024/07/16 14:08:58.089 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname: ipcache_gethostbyname: 'www.google.com', flags=1
> 2024/07/16 14:08:58.090 kid1| 14,3| ipcache.cc(313) ipcacheRelease: ipcacheRelease: Releasing entry for 'www.google.com'
> 2024/07/16 14:08:58.090 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
> 2024/07/16 14:08:58.090 kid1| 14,4| ipcache.cc(610) ipcache_nbgethostbyname: www.google.com
> 2024/07/16 14:08:58.090 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
> 2024/07/16 14:08:58.090 kid1| 14,5| ipcache.cc(670) ipcache_nbgethostbyname_: ipcache_nbgethostbyname: MISS for 'www.google.com'
> 2024/07/16 14:08:58.090 kid1| 78,3| dns_internal.cc(1793) idnsALookup: idnsALookup: buf is 32 bytes for www.google.com, id = 0xfc67
> 2024/07/16 14:08:58.090 kid1| 78,3| dns_internal.cc(1729) idnsSendSlaveAAAAQuery: buf is 32 bytes for www.google.com, id = 0x147d
> 2024/07/16 14:08:58.090 kid1| 14,4| ipcache.cc(610) ipcache_nbgethostbyname: www.google.com
> 2024/07/16 14:08:58.090 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
> 2024/07/16 14:08:58.090 kid1| 14,5| ipcache.cc(670) ipcache_nbgethostbyname_: ipcache_nbgethostbyname: MISS for 'www.google.com'
> 2024/07/16 14:08:58 pinger| Pinger exiting.
> 2024/07/16 14:08:58.117 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting with FD 10
> 2024/07/16 14:08:58.117 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 10: received 144 bytes from [2001:4860:4860::8888]:53
> 2024/07/16 14:08:58.117 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply: QID 0x147d, 4 answers
> 2024/07/16 14:08:58.117 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: 4 records for 0x648c0dbd80d8
> 2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(480) ipcacheParse: 4 answers for www.google.com
> 2024/07/16 14:08:58.117 kid1| 14,5| ipcache.cc(549) updateTtl: use first 300 from RR TTL 300
> 2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #1 [2607:f8b0:4004:c07::93]
> 2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #2 [2607:f8b0:4004:c07::6a]
> 2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #3 [2607:f8b0:4004:c07::67]
> 2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #4 [2607:f8b0:4004:c07::68]
> 2024/07/16 14:08:58.117 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: 4 records for 0x648c0dbdca68
> 2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(480) ipcacheParse: 4 answers for www.google.com
> 2024/07/16 14:08:58.117 kid1| 14,5| ipcache.cc(549) updateTtl: use first 300 from RR TTL 300
> 2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #1 [2607:f8b0:4004:c07::93]
> 2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #2 [2607:f8b0:4004:c07::6a]
> 2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #3 [2607:f8b0:4004:c07::67]
> 2024/07/16 14:08:58.117 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #4 [2607:f8b0:4004:c07::68]
> 2024/07/16 14:08:58.129 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting with FD 10
> 2024/07/16 14:08:58.129 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 10: received 128 bytes from [2001:4860:4860::8888]:53
> 2024/07/16 14:08:58.129 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply: QID 0xfc67, 6 answers
> 2024/07/16 14:08:58.129 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: last 6 records for 0x648c0dbd80d8
> 2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(480) ipcacheParse: 6 answers for www.google.com
> 2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #5 172.253.62.106
> 2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #6 172.253.62.104
> 2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #7 172.253.62.99
> 2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #8 172.253.62.103
> 2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #9 172.253.62.105
> 2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #10 172.253.62.147
> 2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(586) ipcacheHandleReply: done with www.google.com: [2607:f8b0:4004:c07::93] #1/10-0
> 2024/07/16 14:08:58.129 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: last 6 records for 0x648c0dbdca68
> 2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(480) ipcacheParse: 6 answers for www.google.com
> 2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #5 172.253.62.106
> 2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #6 172.253.62.104
> 2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #7 172.253.62.99
> 2024/07/16 14:08:58.129 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #8 172.253.62.103
> 2024/07/16 14:08:58.130 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #9 172.253.62.105
> 2024/07/16 14:08:58.130 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #10 172.253.62.147
> 2024/07/16 14:08:58.130 kid1| 14,3| ipcache.cc(586) ipcacheHandleReply: done with www.google.com: [2607:f8b0:4004:c07::93] #1/10-0
> 2024/07/16 14:08:58.130 kid1| 14,3| ipcache.cc(313) ipcacheRelease: ipcacheRelease: Releasing entry for 'www.google.com'
> 2024/07/16 14:08:58.130 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname: ipcache_gethostbyname: 'www.google.com', flags=1
> 2024/07/16 14:08:58.130 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname: ipcache_gethostbyname: 'www.google.com', flags=1
> 2024/07/16 14:08:58.130 kid1| 26,3| tunnel.cc(1141) tunnelStart: tunnelStart 
> 2024/07/16 14:08:58.130 kid1| 26,3| tunnel.cc(1174) tunnelStart: CONNECT www.google.com:443 HTTP/1.1
> 2024/07/16 14:08:58.130 kid1| 26,3| tunnel.cc(359) TunnelStateData: TunnelStateData constructed this=0x648c0e047388
> 2024/07/16 14:08:58.130 kid1| 14,4| ipcache.cc(617) nbgethostbyname: www.google.com
> 2024/07/16 14:08:58.131 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
> 2024/07/16 14:08:58.131 kid1| 14,4| ipcache.cc(657) ipcache_nbgethostbyname_: ipcache_nbgethostbyname: HIT for 'www.google.com'
> 2024/07/16 14:08:58.227 kid1| 26,5| tunnel.cc(508) updateAttempts: 1
> 2024/07/16 14:08:58.227 kid1| 14,4| ipcache.cc(610) ipcache_nbgethostbyname: www.google.com
> 2024/07/16 14:08:58.227 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
> 2024/07/16 14:08:58.227 kid1| 14,4| ipcache.cc(657) ipcache_nbgethostbyname_: ipcache_nbgethostbyname: HIT for 'www.google.com'
> 2024/07/16 14:08:58.227 kid1| 14,5| net_db.cc(357) networkFromInaddr: networkFromInaddr : Masked IPv6 Address to [2607:f8b0:4004:c07::93]/64 routing part.
> 
> 
> 
> Resolves to IPv4:
> ---------
> CONNECT www.google.com:443 HTTP/1.1
> Host: www.google.com:443
> Proxy-Authorization: Basic cHJpY2VzaGFwZTpwcmljZXNoYXBlMTIz
> User-Agent: curl/8.6.0
> Proxy-Connection: Keep-Alive
> 
> 
> ----------
> 2024/07/16 14:29:01.280 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
> 2024/07/16 14:29:01.280 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname: ipcache_gethostbyname: 'www.google.com', flags=1
> 2024/07/16 14:29:01.280 kid1| 14,3| ipcache.cc(313) ipcacheRelease: ipcacheRelease: Releasing entry for 'www.google.com'
> 2024/07/16 14:29:01.280 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
> 2024/07/16 14:29:01.280 kid1| 14,4| ipcache.cc(610) ipcache_nbgethostbyname: www.google.com
> 2024/07/16 14:29:01.280 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
> 2024/07/16 14:29:01.280 kid1| 14,5| ipcache.cc(670) ipcache_nbgethostbyname_: ipcache_nbgethostbyname: MISS for 'www.google.com'
> 2024/07/16 14:29:01.280 kid1| 78,3| dns_internal.cc(1793) idnsALookup: idnsALookup: buf is 32 bytes for www.google.com, id = 0xd80b
> 2024/07/16 14:29:01.280 kid1| 78,3| dns_internal.cc(1729) idnsSendSlaveAAAAQuery: buf is 32 bytes for www.google.com, id = 0xacdf
> 2024/07/16 14:29:01.280 kid1| 14,4| ipcache.cc(610) ipcache_nbgethostbyname: www.google.com
> 2024/07/16 14:29:01.280 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
> 2024/07/16 14:29:01.280 kid1| 14,5| ipcache.cc(670) ipcache_nbgethostbyname_: ipcache_nbgethostbyname: MISS for 'www.google.com'
> 2024/07/16 14:29:01.300 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting with FD 8
> 2024/07/16 14:29:01.300 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 8: received 128 bytes from [2001:4860:4860::8888]:53
> 2024/07/16 14:29:01.300 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply: QID 0xd80b, 6 answers
> 2024/07/16 14:29:01.300 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: 6 records for 0x5a939a3a4e08
> 2024/07/16 14:29:01.300 kid1| 14,3| ipcache.cc(480) ipcacheParse: 6 answers for www.google.com
> 2024/07/16 14:29:01.300 kid1| 14,5| ipcache.cc(549) updateTtl: use first 300 from RR TTL 300
> 2024/07/16 14:29:01.300 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #1 172.253.62.104
> 2024/07/16 14:29:01.300 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #2 172.253.62.103
> 2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #3 172.253.62.105
> 2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #4 172.253.62.147
> 2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #5 172.253.62.106
> 2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #6 172.253.62.99
> 2024/07/16 14:29:01.301 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: 6 records for 0x5a939a3a0438
> 2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(480) ipcacheParse: 6 answers for www.google.com
> 2024/07/16 14:29:01.301 kid1| 14,5| ipcache.cc(549) updateTtl: use first 300 from RR TTL 300
> 2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #1 172.253.62.104
> 2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #2 172.253.62.103
> 2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #3 172.253.62.105
> 2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #4 172.253.62.147
> 2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #5 172.253.62.106
> 2024/07/16 14:29:01.301 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #6 172.253.62.99
> 2024/07/16 14:29:01.311 kid1| 78,3| dns_internal.cc(1319) idnsRead: idnsRead: starting with FD 8
> 2024/07/16 14:29:01.311 kid1| 78,3| dns_internal.cc(1365) idnsRead: idnsRead: FD 8: received 144 bytes from [2001:4860:4860::8888]:53
> 2024/07/16 14:29:01.311 kid1| 78,3| dns_internal.cc(1172) idnsGrokReply: idnsGrokReply: QID 0xacdf, 4 answers
> 2024/07/16 14:29:01.311 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: last 4 records for 0x5a939a3a4e08
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(480) ipcacheParse: 4 answers for www.google.com
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #7 [2607:f8b0:4004:c07::6a]
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #8 [2607:f8b0:4004:c07::93]
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #9 [2607:f8b0:4004:c07::63]
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #10 [2607:f8b0:4004:c07::69]
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(586) ipcacheHandleReply: done with www.google.com: 172.253.62.104 #1/10-0
> 2024/07/16 14:29:01.311 kid1| 78,6| dns_internal.cc(1105) idnsCallbackOneWithAnswer: last 4 records for 0x5a939a3a0438
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(480) ipcacheParse: 4 answers for www.google.com
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #7 [2607:f8b0:4004:c07::6a]
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #8 [2607:f8b0:4004:c07::93]
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #9 [2607:f8b0:4004:c07::63]
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(535) addGood: www.google.com #10 [2607:f8b0:4004:c07::69]
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(586) ipcacheHandleReply: done with www.google.com: 172.253.62.104 #1/10-0
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(313) ipcacheRelease: ipcacheRelease: Releasing entry for 'www.google.com'
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname: ipcache_gethostbyname: 'www.google.com', flags=1
> 2024/07/16 14:29:01.311 kid1| 14,3| ipcache.cc(732) ipcache_gethostbyname: ipcache_gethostbyname: 'www.google.com', flags=1
> 2024/07/16 14:29:01.311 kid1| 26,3| tunnel.cc(1141) tunnelStart: tunnelStart 
> 2024/07/16 14:29:01.312 kid1| 26,3| tunnel.cc(1174) tunnelStart: CONNECT www.google.com:443 HTTP/1.1
> 2024/07/16 14:29:01.312 kid1| 26,3| tunnel.cc(359) TunnelStateData: TunnelStateData constructed this=0x5a939a80e858
> 2024/07/16 14:29:01.312 kid1| 44,3| peer_select.cc(311) peerSelect: CONNECT
> 2024/07/16 14:29:01.312 kid1| 44,3| peer_select.cc(612) selectMore: CONNECT www.google.com
> 2024/07/16 14:29:01.312 kid1| 44,3| peer_select.cc(577) checkNetdbDirect: MY RTT = 95 msec
> 2024/07/16 14:29:01.312 kid1| 44,3| peer_select.cc(578) checkNetdbDirect: minimum_direct_rtt = 400 msec
> 2024/07/16 14:29:01.312 kid1| 44,3| peer_select.cc(644) selectMore: direct = DIRECT_YES (checkNetdbDirect)
> 2024/07/16 14:29:01.312 kid1| 44,3| peer_select.cc(650) selectMore: direct = DIRECT_YES
> 2024/07/16 14:29:01.312 kid1| 44,3| peer_select.cc(1102) addSelection: adding HIER_DIRECT#www.google.com
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(460) resolveSelected: Find IP destination for: www.google.com:443' via www.google.com
> 2024/07/16 14:29:01.312 kid1| 14,4| ipcache.cc(617) nbgethostbyname: www.google.com
> 2024/07/16 14:29:01.312 kid1| 14,3| Address.cc(389) lookupHostIP: Given Non-IP 'www.google.com': Name or service not known
> 2024/07/16 14:29:01.312 kid1| 14,4| ipcache.cc(657) ipcache_nbgethostbyname_: ipcache_nbgethostbyname: HIT for 'www.google.com'
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn24 local=0.0.0.0 remote=172.253.62.104:443 HIER_DIRECT flags=1, destination #1 for www.google.com:443
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
> 2024/07/16 14:29:01.312 kid1| 17,5| AsyncCall.cc(29) AsyncCall: The AsyncCall TunnelStateData::noteConnection constructed, this=0x5a939a8009c0 [call2215]
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn25 local=0.0.0.0 remote=172.253.62.103:443 HIER_DIRECT flags=1, destination #2 for www.google.com:443
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn26 local=0.0.0.0 remote=172.253.62.105:443 HIER_DIRECT flags=1, destination #3 for www.google.com:443
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn27 local=0.0.0.0 remote=172.253.62.147:443 HIER_DIRECT flags=1, destination #4 for www.google.com:443
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn28 local=0.0.0.0 remote=172.253.62.106:443 HIER_DIRECT flags=1, destination #5 for www.google.com:443
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn29 local=0.0.0.0 remote=172.253.62.99:443 HIER_DIRECT flags=1, destination #6 for www.google.com:443
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn30 local=[::] remote=[2607:f8b0:4004:c07::6a]:443 HIER_DIRECT flags=1, destination #7 for www.google.com:443
> 2024/07/16 14:29:01.312 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn31 local=[::] remote=[2607:f8b0:4004:c07::93]:443 HIER_DIRECT flags=1, destination #8 for www.google.com:443
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn32 local=[::] remote=[2607:f8b0:4004:c07::63]:443 HIER_DIRECT flags=1, destination #9 for www.google.com:443
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1174) handlePath: PeerSelector2 found conn33 local=[::] remote=[2607:f8b0:4004:c07::69]:443 HIER_DIRECT flags=1, destination #10 for www.google.com:443
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1180) handlePath: always_direct = DENIED
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1181) handlePath: never_direct = DENIED
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(1182) handlePath: timedout = 0
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(479) resolveSelected: PeerSelector2 found all 10 destinations for www.google.com:443
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(480) resolveSelected: always_direct = DENIED
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(481) resolveSelected: never_direct = DENIED
> 2024/07/16 14:29:01.313 kid1| 44,2| peer_select.cc(482) resolveSelected: timedout = 0
> 2024/07/16 14:29:01.313 kid1| 17,3| FwdState.cc(1568) GetMarkingsToServer: from 0.0.0.0 tos 0 netfilter mark 0
> 2024/07/16 14:29:01.409 kid1| 17,4| HappyConnOpener.cc(501) sendSuccess: new prime connection: conn35 local=HIDDEN:38852 remote=172.253.62.104:443 HIER_DIRECT FD 15 flags=1 @0
> 2024/07/16 14:29:01.409 kid1| 17,5| AsyncCall.cc(96) ScheduleCall: HappyConnOpener.cc(505) will call TunnelStateData::noteConnection(new conn35 local=HIDDEN remote=172.253.62.104:443 HIER_DIRECT FD 15 flags=1 @0) [call2215]
> 
> 
> 
> Best regards
> 
> Rasmus
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-- 
Gru?

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
From field.


From squid3 at treenet.co.nz  Tue Jul 16 16:00:04 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 17 Jul 2024 04:00:04 +1200
Subject: [squid-users] Prefer or force ipv6 usage on dual stack interface
In-Reply-To: <AFCF2E50-BC23-41C2-900F-CD9575FC5741@priceshape.dk>
References: <AFCF2E50-BC23-41C2-900F-CD9575FC5741@priceshape.dk>
Message-ID: <09fa9f72-a731-4be7-96c5-d09b86c93387@treenet.co.nz>

On 17/07/24 01:31, Rasmus Horndrup wrote:
> Hi,
> On a dual stack network interface I?m interested in using squid as a ipv6 only forward proxy.
> My general understanding was that squid will prefer to use ipv6 whenever available, but I?m having issues with squid seemingly preferring ipv4 in some cases.
> 
> I have two examples, where it proceeds using IPv6 for the first and IPv4 for the second.
> 
>  From the looks of it, they both successfully receive A and AAAA records, but how can I basically force squid to use IPv6?
> 

Squid obeys the IPv6 specifications which still require IPv4 transition 
capabilities. Including whether you are on an IPv4-only or IPv6-only or 
Dual-Stack network.

The best way to make Squid IPv6-only is to make the machine it is 
running on IPv6-only.

Alternatively, to setup a firewall rule matching the proxy by PID/UID to 
reject TCPv4 connections with an ICMP "(3) Destination Unreachable" packet.


Cheers
Amos


From rousskov at measurement-factory.com  Tue Jul 16 18:46:59 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 16 Jul 2024 14:46:59 -0400
Subject: [squid-users] Prefer or force ipv6 usage on dual stack interface
In-Reply-To: <AFCF2E50-BC23-41C2-900F-CD9575FC5741@priceshape.dk>
References: <AFCF2E50-BC23-41C2-900F-CD9575FC5741@priceshape.dk>
Message-ID: <ab2440cc-5b6e-4392-a51c-f75107eea40f@measurement-factory.com>

On 2024-07-16 09:31, Rasmus Horndrup wrote:
> how can I basically force squid to use IPv6?

One can modify Squid source code to enforce that rule OR

* ban requests targeting raw IPv4 addresses _and_
* ensure your /etc/hosts is not in the way _and_
* use a DNS resolver that never sends IPv4 addresses to Squid.


HTH,

Alex.



From raho at priceshape.dk  Wed Jul 17 06:22:59 2024
From: raho at priceshape.dk (Rasmus Horndrup)
Date: Wed, 17 Jul 2024 08:22:59 +0200
Subject: [squid-users] Prefer or force ipv6 usage on dual stack interface
In-Reply-To: <ab2440cc-5b6e-4392-a51c-f75107eea40f@measurement-factory.com>
References: <AFCF2E50-BC23-41C2-900F-CD9575FC5741@priceshape.dk>
 <ab2440cc-5b6e-4392-a51c-f75107eea40f@measurement-factory.com>
Message-ID: <8CBEB80F-80DF-436A-A159-91DAF3DFB7BE@priceshape.dk>

Thank you. I?ll look into that.
But is there anything from the logs I?m missing, for an indication as to why it went with the ipv4 conn over ipv6 in the second case. As I understood, it should prefer ipv6?



> On 16 Jul 2024, at 20.46, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> On 2024-07-16 09:31, Rasmus Horndrup wrote:
>> how can I basically force squid to use IPv6?
> 
> One can modify Squid source code to enforce that rule OR
> 
> * ban requests targeting raw IPv4 addresses _and_
> * ensure your /etc/hosts is not in the way _and_
> * use a DNS resolver that never sends IPv4 addresses to Squid.
> 
> 
> HTH,
> 
> Alex.
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Wed Jul 17 14:26:23 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 17 Jul 2024 10:26:23 -0400
Subject: [squid-users] Prefer or force ipv6 usage on dual stack interface
In-Reply-To: <8CBEB80F-80DF-436A-A159-91DAF3DFB7BE@priceshape.dk>
References: <AFCF2E50-BC23-41C2-900F-CD9575FC5741@priceshape.dk>
 <ab2440cc-5b6e-4392-a51c-f75107eea40f@measurement-factory.com>
 <8CBEB80F-80DF-436A-A159-91DAF3DFB7BE@priceshape.dk>
Message-ID: <8f4601dc-951e-40e2-8d67-30898a29a293@measurement-factory.com>

On 2024-07-17 02:22, Rasmus Horndrup wrote:

> why it went with the ipv4 conn over ipv6 in the second case.

Squid went with IPv4 because Squid established the corresponding 
TCP/IPv4 connection before it could establish the corresponding TCP/IPv6 
connection. Squid started with an IPv4 connection establishment attempt 
because DNS A query (QID 0xd80b) was answered before DNS AAAA query (QID 
0xacdf) was.

The logs are not detailed enough for me to be sure, but I suspect that 
Squid did not even try to establish an TCP/IPv6 connection in this 
particular case (see happy_eyeballs_connect_timeout).


> As I understood, it should prefer ipv6?

Squid does not prefer IPv6. Whether it _should_ is a complicated 
question I would rather not answer until it becomes really necessary.


N.B. Squid still sends DNS A (IPv4) queries just before sending DNS AAAA 
(IPv6) queries. The two queries are sent one after another, without any 
wait or artificial delays between them, but this hard-coded query 
sending order does give IPv4 an advantage over IPv6 (with all other 
factors being equal).


HTH,

Alex.


>> On 16 Jul 2024, at 20.46, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>
>> On 2024-07-16 09:31, Rasmus Horndrup wrote:
>>> how can I basically force squid to use IPv6?
>>
>> One can modify Squid source code to enforce that rule OR
>>
>> * ban requests targeting raw IPv4 addresses _and_
>> * ensure your /etc/hosts is not in the way _and_
>> * use a DNS resolver that never sends IPv4 addresses to Squid.
>>
>>
>> HTH,
>>
>> Alex.



From jonathanlee571 at gmail.com  Thu Jul 18 04:08:32 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 17 Jul 2024 21:08:32 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
Message-ID: <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>

2024/07/17 21:07:37| Processing Configuration File: /usr/local/etc/squid/squid.conf (depth 0)
2024/07/17 21:07:37| Processing: http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
    OpenSSL-saved error #1: 0x1e08010c
2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE
2024/07/17 21:07:37| Processing: http_port 3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
2024/07/17 21:07:37| Starting Authentication on port [::]:3128
2024/07/17 21:07:37| Disabling Authentication on port [::]:3128 (interception enabled)
2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
    OpenSSL-saved error #1: 0x1e08010c
2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE
2024/07/17 21:07:37| Processing: https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
2024/07/17 21:07:37| Starting Authentication on port [::]:3129
2024/07/17 21:07:37| Disabling Authentication on port [::]:3129 (interception enabled)
2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in https_port. Use 'tls-cafile=' instead.
2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
    OpenSSL-saved error #1: 0x1e08010c
2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE

I removed the : and it processed 


> On Jul 12, 2024, at 09:52, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 13/07/24 04:16, Jonathan Lee wrote:
>> tested with removal of IP and port failed If I leave port I get this
>> 2024/07/12 09:15:17| Processing: http_port :3128 intercept
> 
> No  ":" before thr port number.
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240717/747b99ae/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jul 18 04:12:55 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 17 Jul 2024 21:12:55 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
Message-ID: <4A7948E9-6C30-4E07-84C5-1D85B3C2C4FC@gmail.com>

Same result 


Shell Output - squidclient -v -h 127.0.0.1 -p 3128 -U cachemgr -W REDACTED mgr:info
Request:
GET http://127.0.0.1:3128/squid-internal-mgr/info HTTP/1.0
Host: 127.0.0.1:3128
User-Agent: squidclient/6.6
Accept: */*
Authorization: Basic redacted==
Connection: close


.
HTTP/1.1 403 Forbidden
Server: squid
Mime-Version: 1.0
Date: Thu, 18 Jul 2024 04:09:35 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 3792
X-Squid-Error: ERR_ACCESS_DENIED 0
Vary: Accept-Language
Content-Language: en
Cache-Status: Lee_Family.home.arpa
Cache-Status: Lee_Family.home.arpa;detail=no-cache
Connection: close
I also tested this 

squidclient -l 127.0.0.1 -h localhost mgr:info

Per pfSense Netgate community this seemed to work for users that do not use a password directive 

cachemgr_passwd disable offline_toggle reconfigure shutdown
cachemgr_passwd REDACTED_PASSWORD_HERE all

Any other recommendations to try to get the password to work?

> On Jul 17, 2024, at 21:08, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> 2024/07/17 21:07:37| Processing Configuration File: /usr/local/etc/squid/squid.conf (depth 0)
> 2024/07/17 21:07:37| Processing: http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
> 2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
>     OpenSSL-saved error #1: 0x1e08010c
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 2024/07/17 21:07:37| Processing: http_port 3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2024/07/17 21:07:37| Starting Authentication on port [::]:3128
> 2024/07/17 21:07:37| Disabling Authentication on port [::]:3128 (interception enabled)
> 2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
> 2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
>     OpenSSL-saved error #1: 0x1e08010c
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 2024/07/17 21:07:37| Processing: https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2024/07/17 21:07:37| Starting Authentication on port [::]:3129
> 2024/07/17 21:07:37| Disabling Authentication on port [::]:3129 (interception enabled)
> 2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in https_port. Use 'tls-cafile=' instead.
> 2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
>     OpenSSL-saved error #1: 0x1e08010c
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 
> I removed the : and it processed 
> 
> 
>> On Jul 12, 2024, at 09:52, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>> 
>> On 13/07/24 04:16, Jonathan Lee wrote:
>>> tested with removal of IP and port failed If I leave port I get this
>>> 2024/07/12 09:15:17| Processing: http_port :3128 intercept
>> 
>> No  ":" before thr port number.
>> 
>> 
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240717/ca19dac7/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jul 18 04:25:51 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 17 Jul 2024 21:25:51 -0700
Subject: [squid-users] Squid 6.6 shows configuration failure: requires
 TPROXY feature to be enabled by ./configure
Message-ID: <2819F388-B4F3-47C7-80C9-33CFDD602B25@gmail.com>

How do we enable tproxy in Squid 6.6 in 5.8 we could just adapt the Squid.conf and it would enable tproxy 


2024/07/17 21:22:41| Processing Configuration File: /usr/local/etc/squid/squid.conf (depth 0)
2024/07/17 21:22:41| Processing: http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
2024/07/17 21:22:41| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
2024/07/17 21:22:41| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
    OpenSSL-saved error #1: 0x1e08010c
2024/07/17 21:22:41| ERROR: Unsupported TLS option SINGLE_DH_USE
2024/07/17 21:22:41| ERROR: Unsupported TLS option SINGLE_ECDH_USE
2024/07/17 21:22:41| Processing: http_port 127.0.0.1:3128 tproxy ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

This error never occurred for 5.8
**---->2024/07/17 21:22:41| ERROR: configuration failure: requires TPROXY feature to be enabled by ./configure**


    exception location: Intercept.cc(163) StartTransparency
2024/07/17 21:22:41| Not currently OK to rewrite swap log.
2024/07/17 21:22:41| storeDirWriteCleanLogs: Operation aborted.
2024/07/17 21:22:41| FATAL: Bungled /usr/local/etc/squid/squid.conf line 6: http_port 127.0.0.1:3128 tproxy ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
2024/07/17 21:22:41| Squid Cache (Version 6.6): Terminated abnormally.
CPU Usage: 0.073 seconds = 0.049 user + 0.024 sys
Maximum Resident Size: 62512 KB
Page faults with physical i/o: 0



From jonathanlee571 at gmail.com  Thu Jul 18 04:33:52 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 17 Jul 2024 21:33:52 -0700
Subject: [squid-users] Squid 6.6 cache_dir rock questions
Message-ID: <973D49C2-725C-4409-86F7-F6AC988390CB@gmail.com>

Squid 6.6 

Hello fellow Squid users,

What would be the correct way to convert cache_dir disks to rock?

cache_dir diskd /var/squid/cache 64000 256 256

Would it be as simple as..

cache_dir rock /var/squid/cache 64000 256 256?








From jonathanlee571 at gmail.com  Thu Jul 18 04:46:26 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 17 Jul 2024 21:46:26 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
Message-ID: <332D00C6-BF8E-461E-B604-C1714C21310B@gmail.com>

Again still no status page

This is the active php code used

function squid_status() {
	if (is_service_running('squid')) {
		init_config_arr(array('installedpackages', 'squidcache','config'));
		$proxy_ifaces = explode(",", config_get_path('installedpackages/squid/config/0/active_interface', ''));
		foreach ($proxy_ifaces as $iface) {
			if (get_interface_ip($iface)) {
				$ip = get_interface_ip($iface);
				$lip = '127.0.0.1';
			} else {
				$ip = get_interface_ipv6($iface);
				$lip = '::1';
			}
			exec("/usr/local/sbin/squidclient -l " . escapeshellarg($lip) .
				" -h " . escapeshellarg($ip) . " mgr:info", $result);
		}
	} else {
		return(gettext('Squid Proxy is not running.'));


I use to just append the password after mgr:info at password and it worked however now nothing?.

Also 

squidclient -l 127.0.0.1 -h localhost mgr:info 

I get nothing with password removed  

> On Jul 17, 2024, at 21:08, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> 2024/07/17 21:07:37| Processing Configuration File: /usr/local/etc/squid/squid.conf (depth 0)
> 2024/07/17 21:07:37| Processing: http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
> 2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
>     OpenSSL-saved error #1: 0x1e08010c
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 2024/07/17 21:07:37| Processing: http_port 3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2024/07/17 21:07:37| Starting Authentication on port [::]:3128
> 2024/07/17 21:07:37| Disabling Authentication on port [::]:3128 (interception enabled)
> 2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
> 2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
>     OpenSSL-saved error #1: 0x1e08010c
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 2024/07/17 21:07:37| Processing: https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2024/07/17 21:07:37| Starting Authentication on port [::]:3129
> 2024/07/17 21:07:37| Disabling Authentication on port [::]:3129 (interception enabled)
> 2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in https_port. Use 'tls-cafile=' instead.
> 2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
>     OpenSSL-saved error #1: 0x1e08010c
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 
> I removed the : and it processed 
> 
> 
>> On Jul 12, 2024, at 09:52, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>> 
>> On 13/07/24 04:16, Jonathan Lee wrote:
>>> tested with removal of IP and port failed If I leave port I get this
>>> 2024/07/12 09:15:17| Processing: http_port :3128 intercept
>> 
>> No  ":" before thr port number.
>> 
>> 
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240717/00effeda/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jul 18 04:55:59 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 17 Jul 2024 21:55:59 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
Message-ID: <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>

Do I use 

curl http://localhost:3128/squid-internal-mgr/info 

Where would I place the password?

> On Jul 17, 2024, at 21:08, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> 2024/07/17 21:07:37| Processing Configuration File: /usr/local/etc/squid/squid.conf (depth 0)
> 2024/07/17 21:07:37| Processing: http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
> 2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
>     OpenSSL-saved error #1: 0x1e08010c
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 2024/07/17 21:07:37| Processing: http_port 3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2024/07/17 21:07:37| Starting Authentication on port [::]:3128
> 2024/07/17 21:07:37| Disabling Authentication on port [::]:3128 (interception enabled)
> 2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
> 2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
>     OpenSSL-saved error #1: 0x1e08010c
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 2024/07/17 21:07:37| Processing: https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2024/07/17 21:07:37| Starting Authentication on port [::]:3129
> 2024/07/17 21:07:37| Disabling Authentication on port [::]:3129 (interception enabled)
> 2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in https_port. Use 'tls-cafile=' instead.
> 2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
>     OpenSSL-saved error #1: 0x1e08010c
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE
> 
> I removed the : and it processed 
> 
> 
>> On Jul 12, 2024, at 09:52, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>> 
>> On 13/07/24 04:16, Jonathan Lee wrote:
>>> tested with removal of IP and port failed If I leave port I get this
>>> 2024/07/12 09:15:17| Processing: http_port :3128 intercept
>> 
>> No  ":" before thr port number.
>> 
>> 
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240717/cddc82a2/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jul 18 05:05:52 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 17 Jul 2024 22:05:52 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
 <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
Message-ID: <540C5C85-9D5F-40A2-AE65-E08D2FCA02DE@gmail.com>

without password enabled 

Shell Output - curl http://127.0.0.1:3128/squid-internal-mgr/info
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100  3714  100  3714    0     0  12258      0 --:--:-- --:--:-- --:--:-- 12298
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
<meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>ERROR: The requested URL could not be retrieved</title>
<style type="text/css"><!--
 /*
 * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
 *
 * Squid software is distributed under GPLv2+ license and includes
 * contributions from numerous individuals and organizations.
 * Please see the COPYING and CONTRIBUTORS files for details.
 */

/*
 Stylesheet for Squid Error pages
 Adapted from design by Free CSS Templates
 http://www.freecsstemplates.org
 Released for free under a Creative Commons Attribution 2.5 License
*/

/* Page basics */
* {
	font-family: verdana, sans-serif;
? more 

> On Jul 17, 2024, at 21:55, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Do I use 
> 
> curl http://localhost:3128/squid-internal-mgr/info 
> 
> Where would I place the password?
> 
>> On Jul 17, 2024, at 21:08, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> 2024/07/17 21:07:37| Processing Configuration File: /usr/local/etc/squid/squid.conf (depth 0)
>> 2024/07/17 21:07:37| Processing: http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>> 2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
>> 2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
>>     OpenSSL-saved error #1: 0x1e08010c
>> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
>> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE
>> 2024/07/17 21:07:37| Processing: http_port 3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>> 2024/07/17 21:07:37| Starting Authentication on port [::]:3128
>> 2024/07/17 21:07:37| Disabling Authentication on port [::]:3128 (interception enabled)
>> 2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in http_port. Use 'tls-cafile=' instead.
>> 2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
>>     OpenSSL-saved error #1: 0x1e08010c
>> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
>> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE
>> 2024/07/17 21:07:37| Processing: https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>> 2024/07/17 21:07:37| Starting Authentication on port [::]:3129
>> 2024/07/17 21:07:37| Disabling Authentication on port [::]:3129 (interception enabled)
>> 2024/07/17 21:07:37| WARNING: UPGRADE: 'cafile=/usr/local/share/certs/ca-root-nss.crt' is deprecated in https_port. Use 'tls-cafile=' instead.
>> 2024/07/17 21:07:37| WARNING: Failed to decode EC parameters '/etc/dh-parameters.2048'
>>     OpenSSL-saved error #1: 0x1e08010c
>> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_DH_USE
>> 2024/07/17 21:07:37| ERROR: Unsupported TLS option SINGLE_ECDH_USE
>> 
>> I removed the : and it processed 
>> 
>> 
>>> On Jul 12, 2024, at 09:52, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>> 
>>> On 13/07/24 04:16, Jonathan Lee wrote:
>>>> tested with removal of IP and port failed If I leave port I get this
>>>> 2024/07/12 09:15:17| Processing: http_port :3128 intercept
>>> 
>>> No  ":" before thr port number.
>>> 
>>> 
>>> Amos
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>> 
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240717/b0066108/attachment.htm>

From uhlar at fantomas.sk  Thu Jul 18 08:04:44 2024
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 18 Jul 2024 10:04:44 +0200
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <4A7948E9-6C30-4E07-84C5-1D85B3C2C4FC@gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
 <4A7948E9-6C30-4E07-84C5-1D85B3C2C4FC@gmail.com>
Message-ID: <ZpjMnEgFeqsvcDHh@fantomas.sk>

On 17.07.24 21:12, Jonathan Lee wrote:
>Shell Output - squidclient -v -h 127.0.0.1 -p 3128 -U cachemgr -W REDACTED mgr:info
>Request:
>GET http://127.0.0.1:3128/squid-internal-mgr/info HTTP/1.0
>Host: 127.0.0.1:3128
>User-Agent: squidclient/6.6
>Accept: */*
>Authorization: Basic redacted==
>Connection: close
>
>
>.
>HTTP/1.1 403 Forbidden

I think it's time to look at squid config again, to see if you don't deny 
manager access in squid configuration before allowing it.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
He who laughs last thinks slowest.


From rousskov at measurement-factory.com  Thu Jul 18 13:14:44 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 18 Jul 2024 09:14:44 -0400
Subject: [squid-users] Squid 6.6 shows configuration failure: requires
 TPROXY feature to be enabled by ./configure
In-Reply-To: <2819F388-B4F3-47C7-80C9-33CFDD602B25@gmail.com>
References: <2819F388-B4F3-47C7-80C9-33CFDD602B25@gmail.com>
Message-ID: <7b152e12-e1b9-4966-a079-9ec82c269e43@measurement-factory.com>

On 2024-07-18 00:25, Jonathan Lee wrote:
> How do we enable tproxy in Squid 

> 2024/07/17 21:22:41| Processing: http_port 127.0.0.1:3128 tproxy ...
> ...
> 2024/07/17 21:22:41| ERROR: configuration failure: requires TPROXY feature to be enabled by ./configure

As strongly implied by the error message, TPROXY support has to be 
enabled by using Squid ./configure parameters (among other things). 
Running ./configure --help does not, unfortunately, contain the word 
"TPROXY", but searching for "proxy" reveals the following relevant 
./configure options:


>   --enable-ipfw-transparent
>                           Enable Transparent Proxy support for systems using
>                           FreeBSD IPFW-style firewalling.
>   --enable-ipf-transparent
>                           Enable Transparent Proxy support using
>                           IPFilter-style firewalling
>   --enable-pf-transparent Enable Transparent Proxy support for systems using
>                           PF network address redirection.
>   --enable-linux-netfilter
>                           Enable Transparent Proxy support for Linux
>                           (Netfilter)

Pick the one matching your environment and check ./configure output for 
relevant lines, while keeping in mind that Squid still has a lot of text 
inconsistencies (e.g., "TPROXY" vs. "tproxy" vs. "Transparent Proxy" vs. 
"transparent proxying") that require relaxed searching rules. For example:

> FreeBSD IPFW-based transparent proxying enabled: no
> IPF-based transparent proxying requested: no
> PF-based transparent proxying requested: no
> IPF-based transparent proxying enabled: no


Searching squid.conf.documented for similar terms may be useful as well.


HTH,

Alex.



From rousskov at measurement-factory.com  Thu Jul 18 13:24:28 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 18 Jul 2024 09:24:28 -0400
Subject: [squid-users] Squid 6.6 cache_dir rock questions
In-Reply-To: <973D49C2-725C-4409-86F7-F6AC988390CB@gmail.com>
References: <973D49C2-725C-4409-86F7-F6AC988390CB@gmail.com>
Message-ID: <d40900b1-5150-4903-bc44-df251bbcd7ed@measurement-factory.com>

On 2024-07-18 00:33, Jonathan Lee wrote:

> What would be the correct way to convert cache_dir disks to rock?

One cannot convert a cache_dir of another type to rock cache_dir. You 
will need to start from scratch, using a rock-dedicated cache_dir path 
(initialized by running "squid -z" after updating squid.conf). If you 
want to reuse the same path, then move or remove the old/diskd contents 
first.


> cache_dir diskd /var/squid/cache 64000 256 256
> 
> Would it be as simple as..
> 
> cache_dir rock /var/squid/cache 64000 256 256?

See cache_dir directive in squid.conf.documented; diskd and rock 
cache_dirs have _different_ configuration syntax because rock cache_dirs 
do not have/need L1 and L2 parameters required for diskd cache_dirs:

     cache_dir diskd Directory-Name Mbytes L1 L2 [options]
     cache_dir rock Directory-Name Mbytes [options]

HTH,

Alex.



From rousskov at measurement-factory.com  Thu Jul 18 13:58:01 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 18 Jul 2024 09:58:01 -0400
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
 <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
Message-ID: <d18f0034-1f3b-4b51-9927-06aa5e7f01ca@measurement-factory.com>

On 2024-07-18 00:55, Jonathan Lee wrote:

> curl http://localhost:3128/squid-internal-mgr/info 
> 
> Where would I place the password?

See "man curl" or online manual pages for curl. They will point you to 
two relevant options: --user and --proxy-user. AFAICT, your particular 
cache manager requests are sent _to_ the proxy (as if it were an origin 
server) rather than _through_ the proxy. Thus, you should use --user.

As I keep saying on this thread, due to Squid complications related to 
Bug 5283, specifying seemingly correct client parameters may not be 
enough to convince Squid to accept the cache manager request. I 
recommend the following procedure:

1. List the corresponding http_port directive first, before any other 
http_port, https_port, and ftp_port directives. Do not use interception 
of any kind for this cache manager port.

2. Use curl with absolute squid-internal-mgr URLs with http scheme (like 
you show above). Do _not_ use "curl --proxy" or similar. Do not use 
https scheme.

3. In that absolute mgr URL, use the host name that matches 
visible_hostname in squid.conf. If you do not have visible_hostname in 
squid.conf, add it. This is not required, but, due to Squid bugs, it is 
often much easier to get this to work with visible_hostname than without it.

4. Make (passwordless) mgr:info use case working first, before trying to 
get password-protected pages working.

5. When you do specify a username and a password, remember that you are 
sending this request to an (equivalent of) a service running on an 
origin server, _not_ a proxy (hence --user rather than --proxy-user).


If you cannot figure it out despite carefully going through the above 
steps, share (privately if needed) a pointer to compressed ALL,9 
cache.log while reproducing the problem with throw-away credentials on 
an idle Squid with a single curl request. Mention which step you got 
stuck on.


HTH,

Alex.



From anitha.m at hpe.com  Thu Jul 18 16:23:51 2024
From: anitha.m at hpe.com (M, Anitha (CSS))
Date: Thu, 18 Jul 2024 16:23:51 +0000
Subject: [squid-users] Squid Version squid-5.7-150400.3.6.1.x86_64 -- Squid
 is crashing continusly
Message-ID: <DM4PR84MB303207E0D29872FC555138A990AC2@DM4PR84MB3032.NAMPRD84.PROD.OUTLOOK.COM>

Hi Team,

We are seeing squid is continuously crashing with signal 6. Any known issues with this version? Pls help.  Attached is the squid.conf file we are using it.

regards,
Anitha
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240718/1a512c55/attachment.htm>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: squidproxy1.txt
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240718/1a512c55/attachment.txt>

From squid3 at treenet.co.nz  Thu Jul 18 18:31:47 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 19 Jul 2024 06:31:47 +1200
Subject: [squid-users] Squid Version squid-5.7-150400.3.6.1.x86_64 --
 Squid is crashing continusly
In-Reply-To: <DM4PR84MB303207E0D29872FC555138A990AC2@DM4PR84MB3032.NAMPRD84.PROD.OUTLOOK.COM>
References: <DM4PR84MB303207E0D29872FC555138A990AC2@DM4PR84MB3032.NAMPRD84.PROD.OUTLOOK.COM>
Message-ID: <55d57b16-e059-443b-a3cf-8b5084b77044@treenet.co.nz>

On 19/07/24 04:23, M, Anitha (CSS) wrote:
> Hi Team,
> 
> We are seeing squid is continuously crashing with signal 6.

"signal 6" in system log means there should be an "assertion" error 
message in the cache.log. Please look for that.


> Any known 
> issues with this version?

Many. It is not clear which (or another) is happening for you.

Please be aware that Squid-5 are no longer supported and has quite a 
number of security issues that have been fixed in later releases.
Current Squid release is v6.10. If you are able to upgrade, please do so.


Cheers
Amos


From ngtech1ltd at gmail.com  Thu Jul 18 19:21:30 2024
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Thu, 18 Jul 2024 22:21:30 +0300
Subject: [squid-users] Squid Version squid-5.7-150400.3.6.1.x86_64 --
 Squid is crashing continusly
In-Reply-To: <DM4PR84MB303207E0D29872FC555138A990AC2@DM4PR84MB3032.NAMPRD84.PROD.OUTLOOK.COM>
References: <DM4PR84MB303207E0D29872FC555138A990AC2@DM4PR84MB3032.NAMPRD84.PROD.OUTLOOK.COM>
Message-ID: <1885901dad947$b25b1530$17113f90$@gmail.com>

Hey Anitha,

There are couple missing details.
Is it a brand new proxy? What OS are you using? What Distro?
It looks like a very simple forward proxy setup.
When is the proxy crashing? At startup? After a while?

Thanks,
Eliezer

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
M, Anitha (CSS)
Sent: Thursday, July 18, 2024 7:24 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid Version squid-5.7-150400.3.6.1.x86_64 -- Squid
is crashing continusly

Hi Team,?

We are seeing squid is continuously crashing with signal 6. Any known issues
with this version? Pls help.? Attached?is the squid.conf file we are using
it.?

regards,
Anitha



From anitha.m at hpe.com  Thu Jul 18 21:08:05 2024
From: anitha.m at hpe.com (M, Anitha (CSS))
Date: Thu, 18 Jul 2024 21:08:05 +0000
Subject: [squid-users] Squid Version squid-5.7-150400.3.6.1.x86_64 --
 Squid is crashing continusly
In-Reply-To: <1885901dad947$b25b1530$17113f90$@gmail.com>
References: <DM4PR84MB303207E0D29872FC555138A990AC2@DM4PR84MB3032.NAMPRD84.PROD.OUTLOOK.COM>
 <1885901dad947$b25b1530$17113f90$@gmail.com>
Message-ID: <DM4PR84MB30321E29D1F35A517A9A8AEB90AC2@DM4PR84MB3032.NAMPRD84.PROD.OUTLOOK.COM>

Hi Eliezer,

Pls find my comments inline.

________________________________
From: ngtech1ltd at gmail.com <ngtech1ltd at gmail.com>
Sent: Friday, July 19, 2024 12:51 AM
To: squid-users at lists.squid-cache.org <squid-users at lists.squid-cache.org>
Cc: M, Anitha (CSS) <anitha.m at hpe.com>
Subject: RE: [squid-users] Squid Version squid-5.7-150400.3.6.1.x86_64 -- Squid is crashing continusly

Hey Anitha,

There are couple missing details.
Is it a brand new proxy? What OS are you using? What Distro?
>>No. It's not a brand new. We are using SLES SP4
gl-mh-dca-zav-squidproxy02:~ # cat /etc/os-release
NAME="SLES"
VERSION="15-SP4"
VERSION_ID="15.4"
PRETTY_NAME="SUSE Linux Enterprise Server 15 SP4"
ID="sles"
ID_LIKE="suse"
ANSI_COLOR="0;32"
CPE_NAME="cpe:/o:suse:sles:15:sp4"
DOCUMENTATION_URL="https://documentation.suse.com/"

It looks like a very simple forward proxy setup.

When is the proxy crashing? At startup? After a while?
One the squid starts within 5 mins it will be keep on crashing.


Thanks,
Eliezer

From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of
M, Anitha (CSS)
Sent: Thursday, July 18, 2024 7:24 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid Version squid-5.7-150400.3.6.1.x86_64 -- Squid
is crashing continusly

Hi Team,

We are seeing squid is continuously crashing with signal 6. Any known issues
with this version? Pls help.  Attached is the squid.conf file we are using
it.

regards,
Anitha

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240718/bc7eee3a/attachment.htm>

From rst at fomar.com.pl  Fri Jul 19 09:04:35 2024
From: rst at fomar.com.pl (=?UTF-8?Q?Rafa=C5=82_Stanilewicz?=)
Date: Fri, 19 Jul 2024 10:04:35 +0100
Subject: [squid-users] squid "make check" error
Message-ID: <CAPnyBTN-Yy4NqraDKTbPDnOmzohVyHmp2jpQ4fxJ_UAy9MYMJA@mail.gmail.com>

Good morning Gentlemen,

that's my first time here, so please forgive me for any mistakes.
I decided to make a test run of Squid 7 on our test server, running Ubuntu
24.04, but stumbled upon some issue during the "make check" step

I downloaded the squid-7.0.0-20240706-r314e430471.tar.bz2,
(BTW - I wanted to verify the signature, but I was not able to find it on
vhttp://www.squid-cache.org/Versions/v7/sig.dyn#SHA1 ),

As a preparation, I ran

apt update && apt upgrade
aptitude build-dep squid
apt install debhelper-compat libcap2-dev libssl-dev

I configured it with
./configure  --enable-ssl-crtd --with-openssl --prefix=/usr
--localstatedir=/var     --libexecdir=${prefix}/lib/squid
--datadir=${prefix}/share/squid     --sysconfdir=/etc/squid
--with-default-user=proxy     --with-logdir=/var/log/squid
--with-pidfile=/var/run/squid.pid

The process was completed successfully. Then
make
and it finished completely. The last lines of make process:
make[1]: Leaving directory '/root/squid-7.0.0-VCS/tools'
Making all in test-suite
make[1]: Entering directory '/root/squid-7.0.0-VCS/test-suite'
make[1]: Nothing to be done for 'all'.
make[1]: Leaving directory '/root/squid-7.0.0-VCS/test-suite'
make[1]: Entering directory '/root/squid-7.0.0-VCS'
make[1]: Nothing to be done for 'all-am'.

Next step was make check, and it failed with this error:

make[3]: Leaving directory '/root/squid-7.0.0-VCS/lib/ntlmauth'
make[2]: Leaving directory '/root/squid-7.0.0-VCS/lib/ntlmauth'
make[2]: Entering directory '/root/squid-7.0.0-VCS/lib'
make  tests/testRFC1738
make[3]: Entering directory '/root/squid-7.0.0-VCS/lib'
depbase=`echo tests/testRFC1738.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
g++ -std=c++17 -DHAVE_CONFIG_H
-DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
-DDEFAULT_SQUID_DATA_DIR=\"/share/squid\"
-DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I.. -I../include -I../lib
-I../src -I../include    -Wall -Wextra -Wimplicit-fallthrough=5
-Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Wmissing-declarations
-Woverloaded-virtual -Werror -pipe -D_REENTRANT -g -O2 -march=native -MT
tests/testRFC1738.o -MD -MP -MF $depbase.Tpo -c -o tests/testRFC1738.o
tests/testRFC1738.cc &&\
mv -f $depbase.Tpo $depbase.Po
In file included from tests/testRFC1738.cc:10:
../include/unitTestMain.h:16:10: fatal error:
cppunit/BriefTestProgressListener.h: No such file or directory
   16 | #include <cppunit/BriefTestProgressListener.h>
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated.
make[3]: *** [Makefile:990: tests/testRFC1738.o] Error 1
make[3]: Leaving directory '/root/squid-7.0.0-VCS/lib'
make[2]: *** [Makefile:1347: check-am] Error 2
make[2]: Leaving directory '/root/squid-7.0.0-VCS/lib'
make[1]: *** [Makefile:1027: check-recursive] Error 1
make[1]: Leaving directory '/root/squid-7.0.0-VCS/lib'
make: *** [Makefile:606: check-recursive] Error 1

I found out that I need to do
apt install libcppunit-dev
So i did it.

I re-ran "make check" , but then things went south completely:
...
make  tests/testRFC1738
make[3]: Entering directory '/root/squid-7.0.0-VCS/lib'
depbase=`echo tests/testRFC1738.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`;\
g++ -std=c++17 -DHAVE_CONFIG_H
-DDEFAULT_CONFIG_FILE=\"/etc/squid/squid.conf\"
-DDEFAULT_SQUID_DATA_DIR=\"/share/squid\"
-DDEFAULT_SQUID_CONFIG_DIR=\"/etc/squid\"   -I.. -I../include -I../lib
-I../src -I../include    -Wall -Wextra -Wimplicit-fallthrough=5
-Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Wmissing-declarations
-Woverloaded-virtual -Werror -pipe -D_REENTRANT -g -O2 -march=native -MT
tests/testRFC1738.o -MD -MP -MF $depbase.Tpo -c -o tests/testRFC1738.o
tests/testRFC1738.cc &&\
mv -f $depbase.Tpo $depbase.Po
/bin/bash ../libtool  --tag=CXX   --mode=link g++ -std=c++17 -Wall -Wextra
-Wimplicit-fallthrough=5 -Wpointer-arith -Wwrite-strings -Wcomments
-Wshadow -Wmissing-declarations -Woverloaded-virtual -Werror -pipe
-D_REENTRANT -g -O2 -march=native  -g -o tests/testRFC1738
tests/testRFC1738.o ../lib/libmiscencoding.la ../lib/libmiscutil.la
 ../compat/libcompatsquid.la
libtool: link: g++ -std=c++17 -Wall -Wextra -Wimplicit-fallthrough=5
-Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Wmissing-declarations
-Woverloaded-virtual -Werror -pipe -D_REENTRANT -g -O2 -march=native -g -o
tests/testRFC1738 tests/testRFC1738.o  ../lib/.libs/libmiscencoding.a
../lib/.libs/libmiscutil.a ../compat/.libs/libcompatsquid.a
/usr/bin/ld: tests/testRFC1738.o: warning: relocation against
`_ZTVN7CppUnit27TestSuiteBuilderContextBaseE' in read-only section
`.text._ZN11TestRfc173815addTestsToSuiteERN7CppUnit27TestSuiteBuilderContextBaseE[_ZN11TestRfc173815addTestsToSuiteERN7CppUnit27TestSuiteBuilderContextBaseE]'
/usr/bin/ld: tests/testRFC1738.o: in function `TestProgram::runTests()':
/root/squid-7.0.0-VCS/lib/../include/unitTestMain.h:61:(.text+0x42b):
undefined reference to
`CppUnit::TestResult::TestResult(CppUnit::SynchronizedObject::SynchronizationObject*)'
/usr/bin/ld:
/root/squid-7.0.0-VCS/lib/../include/unitTestMain.h:64:(.text+0x435):
undefined reference to
`CppUnit::TestResultCollector::TestResultCollector(CppUnit::SynchronizedObject::SynchronizationObject*)'
/usr/bin/ld:
/root/squid-7.0.0-VCS/lib/../include/unitTestMain.h:65:(.text+0x440):
undefined reference to
`CppUnit::TestResult::addListener(CppUnit::TestListener*)'
/usr/bin/ld:
/root/squid-7.0.0-VCS/lib/../include/unitTestMain.h:71:(.text+0x44d):
undefined reference to
`CppUnit::TextTestProgressListener::TextTestProgressListener()'
/usr/bin/ld:
/root/squid-7.0.0-VCS/lib/../include/unitTestMain.h:72:(.text+0x458):
undefined reference to
`CppUnit::TestResult::addListener(CppUnit::TestListener*)'
...
/usr/bin/ld:
tests/testRFC1738.o:(.data.rel.ro._ZTVN7CppUnit10TestCallerI11TestRfc1738EE[_ZTVN7CppUnit10TestCallerI11TestRfc1738EE]+0x68):
undefined reference to `CppUnit::Test::checkIsValidIndex(int) const'
/usr/bin/ld:
tests/testRFC1738.o:(.data.rel.ro._ZTVN7CppUnit10TestCallerI11TestRfc1738EE[_ZTVN7CppUnit10TestCallerI11TestRfc1738EE]+0x70):
undefined reference to `CppUnit::TestLeaf::doGetChildTestAt(int) const'
/usr/bin/ld: warning: creating DT_TEXTREL in a PIE
collect2: error: ld returned 1 exit status
make[3]: *** [Makefile:936: tests/testRFC1738] Error 1
make[3]: Leaving directory '/root/squid-7.0.0-VCS/lib'
make[2]: *** [Makefile:1347: check-am] Error 2
make[2]: Leaving directory '/root/squid-7.0.0-VCS/lib'
make[1]: *** [Makefile:1027: check-recursive] Error 1
make[1]: Leaving directory '/root/squid-7.0.0-VCS/lib'
make: *** [Makefile:606: check-recursive] Error 1

Before I re-compile the whole package and drill down to the configuration
process, let me ask if there is something obvious that I missed, or that
you can see in the process.

I can provide all the logs needed.

Thank you in advance.

Rafal Stanilewicz
-- 
Zanim wydrukujesz, pomy?l o drukarce..
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240719/82d8b45a/attachment.htm>

From rousskov at measurement-factory.com  Fri Jul 19 12:59:04 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 19 Jul 2024 08:59:04 -0400
Subject: [squid-users] squid "make check" error
In-Reply-To: <CAPnyBTN-Yy4NqraDKTbPDnOmzohVyHmp2jpQ4fxJ_UAy9MYMJA@mail.gmail.com>
References: <CAPnyBTN-Yy4NqraDKTbPDnOmzohVyHmp2jpQ4fxJ_UAy9MYMJA@mail.gmail.com>
Message-ID: <807cf936-1616-44ac-9e8b-0aa4efb323e4@measurement-factory.com>

On 2024-07-19 05:04, Rafa? Stanilewicz wrote:

> Next step was make check, and it failed with this error:
> ../include/unitTestMain.h:16:10: fatal error: 
> cppunit/BriefTestProgressListener.h: No such file or directory


> I found out that I need to do
> apt install libcppunit-dev
> So i did it.
> 
> I re-ran "make check" , but then things went south completely:
> /root/squid-7.0.0-VCS/lib/../include/unitTestMain.h:61:(.text+0x42b): 
> undefined reference to 
> `CppUnit::TestResult::TestResult(CppUnit::SynchronizedObject::SynchronizationObject*)'


If you have not run ./configure after installing libcppunit-dev, then go 
back to that step _before_ running "make" and "make check" again:

     ./configure ... && make && make check

BTW, if you are building Squid v7+ on a system with N CPU cores, run 
"make -jN" instead of just "make" to speed things up.


HTH,

Alex.



From rousskov at measurement-factory.com  Fri Jul 19 15:19:34 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 19 Jul 2024 11:19:34 -0400
Subject: [squid-users] squid "make check" error
In-Reply-To: <CAPnyBTOKgTE3StJUqu2T4JKWSzX0BMeUuxhpAGaaxKgbM87BdA@mail.gmail.com>
References: <CAPnyBTN-Yy4NqraDKTbPDnOmzohVyHmp2jpQ4fxJ_UAy9MYMJA@mail.gmail.com>
 <807cf936-1616-44ac-9e8b-0aa4efb323e4@measurement-factory.com>
 <CAPnyBTOKgTE3StJUqu2T4JKWSzX0BMeUuxhpAGaaxKgbM87BdA@mail.gmail.com>
Message-ID: <7e8bbd55-2997-4e2a-89c7-fab75a8f4bdc@measurement-factory.com>

On 2024-07-19 09:20, Rafa? Stanilewicz wrote:
> Thank you. It worked.

Glad to hear that!


> I incorrectly assumed all dependencies would be captured by aptitude 
> build-dep squid and ./configure.

Your assumption is not wrong for dependencies that are necessary to 
build and install Squid. Testing Squid, including testing with "make 
check", is (evidently) considered a separate activity that "squid" 
package build dependencies (installed by "apt build-dep") do not have to 
accommodate.

Should "squid" package build dependencies accommodate "make check"?

FWIW, packaging is not my area of expertise, and I could not find a 
definitive answer in Debian packaging policy documents[1] or on the web. 
I speculate that the default answer is "yes". If that answer is correct, 
then "squid" package configuration should be adjusted to include 
libcppunit-dev as a build dependency. Otherwise, one should not expect 
"make check" to succeed after "apt build-dep squid".

[1] https://www.debian.org/doc/debian-policy/


Cheers,

Alex.


> pt., 19 lip 2024 o 13:59?Alex Rousskov <rousskov at measurement-factory.com 
> <mailto:rousskov at measurement-factory.com>> napisa?(a):
> 
>     On 2024-07-19 05:04, Rafa? Stanilewicz wrote:
> 
>      > Next step was make check, and it failed with this error:
>      > ../include/unitTestMain.h:16:10: fatal error:
>      > cppunit/BriefTestProgressListener.h: No such file or directory
> 
> 
>      > I found out that I need to do
>      > apt install libcppunit-dev
>      > So i did it.
>      >
>      > I re-ran "make check" , but then things went south completely:
>      >
>     /root/squid-7.0.0-VCS/lib/../include/unitTestMain.h:61:(.text+0x42b):
>      > undefined reference to
>      >
>     `CppUnit::TestResult::TestResult(CppUnit::SynchronizedObject::SynchronizationObject*)'
> 
> 
>     If you have not run ./configure after installing libcppunit-dev,
>     then go
>     back to that step _before_ running "make" and "make check" again:
> 
>      ? ? ?./configure ... && make && make check
> 
>     BTW, if you are building Squid v7+ on a system with N CPU cores, run
>     "make -jN" instead of just "make" to speed things up.
> 
> 
>     HTH,
> 
>     Alex.
> 
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
> 
> 
> 
> -- 
> Zanim wydrukujesz, pomy?l o ?rodowisku.



From anton.kornexl at miex.cc  Mon Jul 22 09:03:14 2024
From: anton.kornexl at miex.cc (Anton Kornexl)
Date: Mon, 22 Jul 2024 11:03:14 +0200
Subject: [squid-users] Squid on Freebsd
Message-ID: <18de4a5f-7c22-4910-a37b-24dc72783b4d@miex.cc>

 ?Hello

i try to use squid (6.10)? with opnsense 24.x on freebsd 13-2-Release-p11.

It produces a "segmentation fault" at start and restart but the process 
runs.

The "segmentation fault" occurs even with squid -k parse.

A "service squid reload" runs OK, but a "service squid restart" produces 
this Segmentation fault.

The problem did not exist with opnsense 23.x and an older squid.

How can I debug this error probably in the parse part?

yours

Anton Kornexl






From odhiambo at gmail.com  Mon Jul 22 09:35:48 2024
From: odhiambo at gmail.com (Odhiambo Washington)
Date: Mon, 22 Jul 2024 12:35:48 +0300
Subject: [squid-users] Squid on Freebsd
In-Reply-To: <18de4a5f-7c22-4910-a37b-24dc72783b4d@miex.cc>
References: <18de4a5f-7c22-4910-a37b-24dc72783b4d@miex.cc>
Message-ID: <CAAdA2WPRL9Wrfv+tpKTzD-icBgh6E+61WJVXpAYxfyrbPDzSww@mail.gmail.com>

On Mon, Jul 22, 2024 at 12:12?PM Anton Kornexl <anton.kornexl at miex.cc>
wrote:

>   Hello
>
> i try to use squid (6.10)  with opnsense 24.x on freebsd 13-2-Release-p11.
>
> It produces a "segmentation fault" at start and restart but the process
> runs.
>
> The "segmentation fault" occurs even with squid -k parse.
>
> A "service squid reload" runs OK, but a "service squid restart" produces
> this Segmentation fault.
>
> The problem did not exist with opnsense 23.x and an older squid.
>
> How can I debug this error probably in the parse part?
>


Squid used to write info into cache.log, IIRC. I think it still does. It's
been long since I last managed a squid install.

-- 
Best regards,
Odhiambo WASHINGTON,
Nairobi,KE
+254 7 3200 0004/+254 7 2274 3223
 In an Internet failure case, the #1 suspect is a constant: DNS.
"Oh, the cruft.", egrep -v '^$|^.*#' ?\_(?)_/? :-)
[How to ask smart questions:
http://www.catb.org/~esr/faqs/smart-questions.html]
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240722/513efd53/attachment.htm>

From ankor2023 at gmail.com  Mon Jul 22 11:42:19 2024
From: ankor2023 at gmail.com (Andrey K)
Date: Mon, 22 Jul 2024 14:42:19 +0300
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <d18f0034-1f3b-4b51-9927-06aa5e7f01ca@measurement-factory.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
 <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
 <d18f0034-1f3b-4b51-9927-06aa5e7f01ca@measurement-factory.com>
Message-ID: <CADJd0Y1h4wviABtDXQpCc2w1C7YQ0n9EKEh79=KYKQDFWLWtpA@mail.gmail.com>

Hello, Jonathan,

> curl http://localhost:3128/squid-internal-mgr/info

> Where would I place the password?

I use the following configuration:
http_access allow localhost  manager
cachemgr_passwd redacted config

The command to read the current running config is:
curl localhost:3128/squid-internal-mgr/config -u :redacted


Kind regards,
      Ankor.




??, 18 ???. 2024??. ? 17:07, Alex Rousskov <rousskov at measurement-factory.com
>:

> On 2024-07-18 00:55, Jonathan Lee wrote:
>
> > curl http://localhost:3128/squid-internal-mgr/info
> >
> > Where would I place the password?
>
> See "man curl" or online manual pages for curl. They will point you to
> two relevant options: --user and --proxy-user. AFAICT, your particular
> cache manager requests are sent _to_ the proxy (as if it were an origin
> server) rather than _through_ the proxy. Thus, you should use --user.
>
> As I keep saying on this thread, due to Squid complications related to
> Bug 5283, specifying seemingly correct client parameters may not be
> enough to convince Squid to accept the cache manager request. I
> recommend the following procedure:
>
> 1. List the corresponding http_port directive first, before any other
> http_port, https_port, and ftp_port directives. Do not use interception
> of any kind for this cache manager port.
>
> 2. Use curl with absolute squid-internal-mgr URLs with http scheme (like
> you show above). Do _not_ use "curl --proxy" or similar. Do not use
> https scheme.
>
> 3. In that absolute mgr URL, use the host name that matches
> visible_hostname in squid.conf. If you do not have visible_hostname in
> squid.conf, add it. This is not required, but, due to Squid bugs, it is
> often much easier to get this to work with visible_hostname than without
> it.
>
> 4. Make (passwordless) mgr:info use case working first, before trying to
> get password-protected pages working.
>
> 5. When you do specify a username and a password, remember that you are
> sending this request to an (equivalent of) a service running on an
> origin server, _not_ a proxy (hence --user rather than --proxy-user).
>
>
> If you cannot figure it out despite carefully going through the above
> steps, share (privately if needed) a pointer to compressed ALL,9
> cache.log while reproducing the problem with throw-away credentials on
> an idle Squid with a single curl request. Mention which step you got
> stuck on.
>
>
> HTH,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240722/427671a2/attachment.htm>

From anton.kornexl at miex.cc  Mon Jul 22 13:46:04 2024
From: anton.kornexl at miex.cc (Anton Kornexl)
Date: Mon, 22 Jul 2024 15:46:04 +0200
Subject: [squid-users] Squid on Freebsd
In-Reply-To: <18de4a5f-7c22-4910-a37b-24dc72783b4d@miex.cc>
References: <18de4a5f-7c22-4910-a37b-24dc72783b4d@miex.cc>
Message-ID: <434672a6-88d5-4bef-a944-292681244278@miex.cc>

Hello,

I have tested the two installations further

Opnsense 23.x with squid 6.6 on freebsd 13.2-Release-p9 produces the 
same segmentation fault, but it does not popup as red window in the 
dashboard.

I have set "debug_options ALL,5" in squid.conf:

I have found the following lines in cache.log (grep _suid cache.log)

2024/07/22 17:26:52.186 kid1| 21,3| tools.cc(625) enter_suid: 
enter_suid: PID 29145 taking root privileges
2024/07/22 17:26:52.186 kid1| 21,31 tools.cc(629) enter_suid: 
enter_suid: setresuid failed: (1) Operation not permitted
2024/07/22 17:26:52.186 kid1| 21,3| tools.cc(561) leave suid: leave 
suid: PID 29145 called
2024/07/22 17:26:52.187 kid1| 21,31 tools.cc(625) enter_suid: 
enter_suid: PID 29145 taking root privileges
2024/07/22 17:26:52.187 kid1| 21,3| tools.cc(629) enter_suid: 
enter_suid: setresuid failed: (1) Operation not permitted
2024/07/22 17:26:52.187 kid1| 21,31 tools.cc(561) leave_suid: leave 
suid: PID 29145 called
2024/07/22 17:26:52.187 kid1| 21,31 tools.cc(625) enter_suid: 
enter_suid: PID 29145 taking root privileges
2024/07/22 17:26:52.187 kid1l 21,31 tools.cc(629) enter_suid: 
enter_suid: setresuid failed: (1) Operation not permitted
2024/07/22 17:26:52.187 kid1| 21,31 tools.cc(561) leave_suid: leave 
suid: PID 29145 called
2024/07/22 17:26:52.187 kid1l 21,31 tools.cc(561) leave_suid: 
leave_suid: PID 29648 called
2024/07/22 17:26:52.187 kid1l 21,31 tools.cc(651) no_suid: no_suid: PID 
29648 giving up root privileges forever

maybe this is the cause of the "segmentation fault".

The difference between the installations 23.x and 24.x is the alerting 
of this segmentaion fault in the dashboard of opnsense.

But what ist the cause of this "Operation not permitted"

yours

Anton Kornexl

Am 22.07.2024 um 11:03 schrieb Anton Kornexl:
> ?Hello
>
> i try to use squid (6.10)? with opnsense 24.x on freebsd 
> 13-2-Release-p11.
>
> It produces a "segmentation fault" at start and restart but the 
> process runs.
>
> The "segmentation fault" occurs even with squid -k parse.
>
> A "service squid reload" runs OK, but a "service squid restart" 
> produces this Segmentation fault.
>
> The problem did not exist with opnsense 23.x and an older squid.
>
> How can I debug this error probably in the parse part?
>
> yours
>
> Anton Kornexl
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From jonathanlee571 at gmail.com  Mon Jul 22 16:01:27 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 22 Jul 2024 09:01:27 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <CADJd0Y1h4wviABtDXQpCc2w1C7YQ0n9EKEh79=KYKQDFWLWtpA@mail.gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
 <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
 <d18f0034-1f3b-4b51-9927-06aa5e7f01ca@measurement-factory.com>
 <CADJd0Y1h4wviABtDXQpCc2w1C7YQ0n9EKEh79=KYKQDFWLWtpA@mail.gmail.com>
Message-ID: <781872AE-13EB-421F-BCB7-9B1E10E65BE4@gmail.com>

Thanks for the info

I tried it and this also failed. Dang

Shell Output - curl localhost:3128/squid-internal-mgr/info -u :redacted
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100  3773  100  3773    0     0  90756      0 --:--:-- --:--:-- --:--:-- 94325
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
<meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>ERROR: The requested URL could not be retrieved</title>
<style type="text/css"><!--
 /*
 * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
 *
 * Squid software is distributed under GPLv2+ license and includes
 * contributions from numerous individuals and organizations.
 * Please see the COPYING and CONTRIBUTORS files for details.
 */

/*
 Stylesheet for Squid Error pages
 Adapted from design by Free CSS Templates
 http://www.freecsstemplates.org
 Released for free under a Creative Commons Attribution 2.5 License
*/
However I get a new error when attempting to connect over a web browser 

ERROR

The requested URL could not be retrieved

Invalid Request error was encountered while trying to process the request:

GET /squid-internal-mgr HTTP/1.1
Host: lee_family.home.arpa:3128
Upgrade-Insecure-Requests: 1
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Safari/605.1.15
Accept-Language: en-US,en;q=0.9
Accept-Encoding: gzip, deflate
Connection: keep-alive
DNT: 1
Some possible problems are:

Request is too large.

Content-Length missing for POST or PUT requests.

Illegal character in hostname; underscores are not allowed.

HTTP/1.1 Expect: feature is being asked from an HTTP/1.0 software.

Your cache administrator is 



> On Jul 22, 2024, at 04:42, Andrey K <ankor2023 at gmail.com> wrote:
> 
> Hello, Jonathan,
> 
> > curl http://localhost:3128/squid-internal-mgr/info 
> 
> > Where would I place the password?
> 
> I use the following configuration:
> http_access allow localhost  manager
> cachemgr_passwd redacted config
> 
> The command to read the current running config is:
> curl localhost:3128/squid-internal-mgr/config -u :redacted
> 
> 
> Kind regards,
>       Ankor.
> 
> 
> 
> 
> ??, 18 ???. 2024??. ? 17:07, Alex Rousskov <rousskov at measurement-factory.com <mailto:rousskov at measurement-factory.com>>:
>> On 2024-07-18 00:55, Jonathan Lee wrote:
>> 
>> > curl http://localhost:3128/squid-internal-mgr/info 
>> > 
>> > Where would I place the password?
>> 
>> See "man curl" or online manual pages for curl. They will point you to 
>> two relevant options: --user and --proxy-user. AFAICT, your particular 
>> cache manager requests are sent _to_ the proxy (as if it were an origin 
>> server) rather than _through_ the proxy. Thus, you should use --user.
>> 
>> As I keep saying on this thread, due to Squid complications related to 
>> Bug 5283, specifying seemingly correct client parameters may not be 
>> enough to convince Squid to accept the cache manager request. I 
>> recommend the following procedure:
>> 
>> 1. List the corresponding http_port directive first, before any other 
>> http_port, https_port, and ftp_port directives. Do not use interception 
>> of any kind for this cache manager port.
>> 
>> 2. Use curl with absolute squid-internal-mgr URLs with http scheme (like 
>> you show above). Do _not_ use "curl --proxy" or similar. Do not use 
>> https scheme.
>> 
>> 3. In that absolute mgr URL, use the host name that matches 
>> visible_hostname in squid.conf. If you do not have visible_hostname in 
>> squid.conf, add it. This is not required, but, due to Squid bugs, it is 
>> often much easier to get this to work with visible_hostname than without it.
>> 
>> 4. Make (passwordless) mgr:info use case working first, before trying to 
>> get password-protected pages working.
>> 
>> 5. When you do specify a username and a password, remember that you are 
>> sending this request to an (equivalent of) a service running on an 
>> origin server, _not_ a proxy (hence --user rather than --proxy-user).
>> 
>> 
>> If you cannot figure it out despite carefully going through the above 
>> steps, share (privately if needed) a pointer to compressed ALL,9 
>> cache.log while reproducing the problem with throw-away credentials on 
>> an idle Squid with a single curl request. Mention which step you got 
>> stuck on.
>> 
>> 
>> HTH,
>> 
>> Alex.
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
>> https://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240722/4ca4b643/attachment.htm>

From jonathanlee571 at gmail.com  Mon Jul 22 16:13:06 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 22 Jul 2024 09:13:06 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <781872AE-13EB-421F-BCB7-9B1E10E65BE4@gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
 <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
 <d18f0034-1f3b-4b51-9927-06aa5e7f01ca@measurement-factory.com>
 <CADJd0Y1h4wviABtDXQpCc2w1C7YQ0n9EKEh79=KYKQDFWLWtpA@mail.gmail.com>
 <781872AE-13EB-421F-BCB7-9B1E10E65BE4@gmail.com>
Message-ID: <46154037-39EA-4F75-9DE5-1D538FEEFAD7@gmail.com>

Also I have tested 

curl 127.0.0.1:3128/squid-internal-mgr -u :redacted
curl localhost:3128/squid-internal-mgr -u :redacted
curl hostname_here:3128/squid-internal-mgr -u :redacted (per bug notes use hostname in place of localhost)

and testing with no password same commands lock up the system with no response and if I do them outside of the host with a web browser I get the errors below seen they are new..

> HTTP/1.1 Expect: feature is being asked from an HTTP/1.0 software.
> 





> On Jul 22, 2024, at 09:01, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Thanks for the info
> 
> I tried it and this also failed. Dang
> 
> Shell Output - curl localhost:3128/squid-internal-mgr/info -u :redacted
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
>                                  Dload  Upload   Total   Spent    Left  Speed
> 
>   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
> 100  3773  100  3773    0     0  90756      0 --:--:-- --:--:-- --:--:-- 94325
> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
> <html><head>
> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
> <title>ERROR: The requested URL could not be retrieved</title>
> <style type="text/css"><!--
>  /*
>  * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
>  *
>  * Squid software is distributed under GPLv2+ license and includes
>  * contributions from numerous individuals and organizations.
>  * Please see the COPYING and CONTRIBUTORS files for details.
>  */
> 
> /*
>  Stylesheet for Squid Error pages
>  Adapted from design by Free CSS Templates
>  http://www.freecsstemplates.org
>  Released for free under a Creative Commons Attribution 2.5 License
> */
> However I get a new error when attempting to connect over a web browser 
> 
> ERROR
> 
> The requested URL could not be retrieved
> 
> Invalid Request error was encountered while trying to process the request:
> 
> GET /squid-internal-mgr HTTP/1.1
> Host: lee_family.home.arpa:3128
> Upgrade-Insecure-Requests: 1
> Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
> User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Safari/605.1.15
> Accept-Language: en-US,en;q=0.9
> Accept-Encoding: gzip, deflate
> Connection: keep-alive
> DNT: 1
> Some possible problems are:
> 
> Request is too large.
> 
> Content-Length missing for POST or PUT requests.
> 
> Illegal character in hostname; underscores are not allowed.
> 
> HTTP/1.1 Expect: feature is being asked from an HTTP/1.0 software.
> 
> Your cache administrator is 
> 
> 
> 
>> On Jul 22, 2024, at 04:42, Andrey K <ankor2023 at gmail.com> wrote:
>> 
>> Hello, Jonathan,
>> 
>> > curl http://localhost:3128/squid-internal-mgr/info 
>> 
>> > Where would I place the password?
>> 
>> I use the following configuration:
>> http_access allow localhost  manager
>> cachemgr_passwd redacted config
>> 
>> The command to read the current running config is:
>> curl localhost:3128/squid-internal-mgr/config -u :redacted
>> 
>> 
>> Kind regards,
>>       Ankor.
>> 
>> 
>> 
>> 
>> ??, 18 ???. 2024??. ? 17:07, Alex Rousskov <rousskov at measurement-factory.com <mailto:rousskov at measurement-factory.com>>:
>>> On 2024-07-18 00:55, Jonathan Lee wrote:
>>> 
>>> > curl http://localhost:3128/squid-internal-mgr/info 
>>> > 
>>> > Where would I place the password?
>>> 
>>> See "man curl" or online manual pages for curl. They will point you to 
>>> two relevant options: --user and --proxy-user. AFAICT, your particular 
>>> cache manager requests are sent _to_ the proxy (as if it were an origin 
>>> server) rather than _through_ the proxy. Thus, you should use --user.
>>> 
>>> As I keep saying on this thread, due to Squid complications related to 
>>> Bug 5283, specifying seemingly correct client parameters may not be 
>>> enough to convince Squid to accept the cache manager request. I 
>>> recommend the following procedure:
>>> 
>>> 1. List the corresponding http_port directive first, before any other 
>>> http_port, https_port, and ftp_port directives. Do not use interception 
>>> of any kind for this cache manager port.
>>> 
>>> 2. Use curl with absolute squid-internal-mgr URLs with http scheme (like 
>>> you show above). Do _not_ use "curl --proxy" or similar. Do not use 
>>> https scheme.
>>> 
>>> 3. In that absolute mgr URL, use the host name that matches 
>>> visible_hostname in squid.conf. If you do not have visible_hostname in 
>>> squid.conf, add it. This is not required, but, due to Squid bugs, it is 
>>> often much easier to get this to work with visible_hostname than without it.
>>> 
>>> 4. Make (passwordless) mgr:info use case working first, before trying to 
>>> get password-protected pages working.
>>> 
>>> 5. When you do specify a username and a password, remember that you are 
>>> sending this request to an (equivalent of) a service running on an 
>>> origin server, _not_ a proxy (hence --user rather than --proxy-user).
>>> 
>>> 
>>> If you cannot figure it out despite carefully going through the above 
>>> steps, share (privately if needed) a pointer to compressed ALL,9 
>>> cache.log while reproducing the problem with throw-away credentials on 
>>> an idle Squid with a single curl request. Mention which step you got 
>>> stuck on.
>>> 
>>> 
>>> HTH,
>>> 
>>> Alex.
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
>>> https://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240722/96dce772/attachment.htm>

From gkinkie at gmail.com  Mon Jul 22 18:13:17 2024
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Mon, 22 Jul 2024 19:13:17 +0100
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <781872AE-13EB-421F-BCB7-9B1E10E65BE4@gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
 <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
 <d18f0034-1f3b-4b51-9927-06aa5e7f01ca@measurement-factory.com>
 <CADJd0Y1h4wviABtDXQpCc2w1C7YQ0n9EKEh79=KYKQDFWLWtpA@mail.gmail.com>
 <781872AE-13EB-421F-BCB7-9B1E10E65BE4@gmail.com>
Message-ID: <CA+Y8hcPzF3eKYARyq2jzHPSAsVGNQCeRT+sJ9BexMpVFTLG68A@mail.gmail.com>

Can you try supplying a username to curl? It's also common practice to
put flags ('-u user:redacted') before arguments (the URL)

On Mon, Jul 22, 2024 at 5:12?PM Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>
> Thanks for the info
>
> I tried it and this also failed. Dang
>
> Shell Output - curl localhost:3128/squid-internal-mgr/info -u :redacted
>
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
>                                  Dload  Upload   Total   Spent    Left  Speed
>
>   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
> 100  3773  100  3773    0     0  90756      0 --:--:-- --:--:-- --:--:-- 94325
> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
> <html><head>
> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
> <title>ERROR: The requested URL could not be retrieved</title>
> <style type="text/css"><!--
>  /*
>  * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
>  *
>  * Squid software is distributed under GPLv2+ license and includes
>  * contributions from numerous individuals and organizations.
>  * Please see the COPYING and CONTRIBUTORS files for details.
>  */
>
> /*
>  Stylesheet for Squid Error pages
>  Adapted from design by Free CSS Templates
>  http://www.freecsstemplates.org
>  Released for free under a Creative Commons Attribution 2.5 License
> */
>
> However I get a new error when attempting to connect over a web browser
>
> ERROR
>
> The requested URL could not be retrieved
>
> ________________________________
>
> Invalid Request error was encountered while trying to process the request:
>
> GET /squid-internal-mgr HTTP/1.1
> Host: lee_family.home.arpa:3128
> Upgrade-Insecure-Requests: 1
> Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
> User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Safari/605.1.15
> Accept-Language: en-US,en;q=0.9
> Accept-Encoding: gzip, deflate
> Connection: keep-alive
> DNT: 1
>
> Some possible problems are:
>
> Request is too large.
>
> Content-Length missing for POST or PUT requests.
>
> Illegal character in hostname; underscores are not allowed.
>
> HTTP/1.1 Expect: feature is being asked from an HTTP/1.0 software.
>
> Your cache administrator is
>
>
>
> On Jul 22, 2024, at 04:42, Andrey K <ankor2023 at gmail.com> wrote:
>
> Hello, Jonathan,
>
> > curl http://localhost:3128/squid-internal-mgr/info
>
> > Where would I place the password?
>
> I use the following configuration:
> http_access allow localhost  manager
> cachemgr_passwd redacted config
>
> The command to read the current running config is:
> curl localhost:3128/squid-internal-mgr/config -u :redacted
>
>
> Kind regards,
>       Ankor.
>
>
>
>
> ??, 18 ???. 2024??. ? 17:07, Alex Rousskov <rousskov at measurement-factory.com>:
>>
>> On 2024-07-18 00:55, Jonathan Lee wrote:
>>
>> > curl http://localhost:3128/squid-internal-mgr/info
>> >
>> > Where would I place the password?
>>
>> See "man curl" or online manual pages for curl. They will point you to
>> two relevant options: --user and --proxy-user. AFAICT, your particular
>> cache manager requests are sent _to_ the proxy (as if it were an origin
>> server) rather than _through_ the proxy. Thus, you should use --user.
>>
>> As I keep saying on this thread, due to Squid complications related to
>> Bug 5283, specifying seemingly correct client parameters may not be
>> enough to convince Squid to accept the cache manager request. I
>> recommend the following procedure:
>>
>> 1. List the corresponding http_port directive first, before any other
>> http_port, https_port, and ftp_port directives. Do not use interception
>> of any kind for this cache manager port.
>>
>> 2. Use curl with absolute squid-internal-mgr URLs with http scheme (like
>> you show above). Do _not_ use "curl --proxy" or similar. Do not use
>> https scheme.
>>
>> 3. In that absolute mgr URL, use the host name that matches
>> visible_hostname in squid.conf. If you do not have visible_hostname in
>> squid.conf, add it. This is not required, but, due to Squid bugs, it is
>> often much easier to get this to work with visible_hostname than without it.
>>
>> 4. Make (passwordless) mgr:info use case working first, before trying to
>> get password-protected pages working.
>>
>> 5. When you do specify a username and a password, remember that you are
>> sending this request to an (equivalent of) a service running on an
>> origin server, _not_ a proxy (hence --user rather than --proxy-user).
>>
>>
>> If you cannot figure it out despite carefully going through the above
>> steps, share (privately if needed) a pointer to compressed ALL,9
>> cache.log while reproducing the problem with throw-away credentials on
>> an idle Squid with a single curl request. Mention which step you got
>> stuck on.
>>
>>
>> HTH,
>>
>> Alex.
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco


From jonathanlee571 at gmail.com  Mon Jul 22 18:21:21 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 22 Jul 2024 11:21:21 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <CA+Y8hcPzF3eKYARyq2jzHPSAsVGNQCeRT+sJ9BexMpVFTLG68A@mail.gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
 <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
 <d18f0034-1f3b-4b51-9927-06aa5e7f01ca@measurement-factory.com>
 <CADJd0Y1h4wviABtDXQpCc2w1C7YQ0n9EKEh79=KYKQDFWLWtpA@mail.gmail.com>
 <781872AE-13EB-421F-BCB7-9B1E10E65BE4@gmail.com>
 <CA+Y8hcPzF3eKYARyq2jzHPSAsVGNQCeRT+sJ9BexMpVFTLG68A@mail.gmail.com>
Message-ID: <FADEBDA5-3FA3-4D7A-B84E-E832E847B24F@gmail.com>

That would require a username for the cachemgr_password account right? I have no usernames set up for this.

How does one add a username for this directive ?

> On Jul 22, 2024, at 11:13, Francesco Chemolli <gkinkie at gmail.com> wrote:
> 
> Can you try supplying a username to curl? It's also common practice to
> put flags ('-u user:redacted') before arguments (the URL)
> 
> On Mon, Jul 22, 2024 at 5:12?PM Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> Thanks for the info
>> 
>> I tried it and this also failed. Dang
>> 
>> Shell Output - curl localhost:3128/squid-internal-mgr/info -u :redacted
>> 
>>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
>>                                 Dload  Upload   Total   Spent    Left  Speed
>> 
>>  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
>> 100  3773  100  3773    0     0  90756      0 --:--:-- --:--:-- --:--:-- 94325
>> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
>> <html><head>
>> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
>> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
>> <title>ERROR: The requested URL could not be retrieved</title>
>> <style type="text/css"><!--
>> /*
>> * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
>> *
>> * Squid software is distributed under GPLv2+ license and includes
>> * contributions from numerous individuals and organizations.
>> * Please see the COPYING and CONTRIBUTORS files for details.
>> */
>> 
>> /*
>> Stylesheet for Squid Error pages
>> Adapted from design by Free CSS Templates
>> http://www.freecsstemplates.org
>> Released for free under a Creative Commons Attribution 2.5 License
>> */
>> 
>> However I get a new error when attempting to connect over a web browser
>> 
>> ERROR
>> 
>> The requested URL could not be retrieved
>> 
>> ________________________________
>> 
>> Invalid Request error was encountered while trying to process the request:
>> 
>> GET /squid-internal-mgr HTTP/1.1
>> Host: lee_family.home.arpa:3128
>> Upgrade-Insecure-Requests: 1
>> Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
>> User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Safari/605.1.15
>> Accept-Language: en-US,en;q=0.9
>> Accept-Encoding: gzip, deflate
>> Connection: keep-alive
>> DNT: 1
>> 
>> Some possible problems are:
>> 
>> Request is too large.
>> 
>> Content-Length missing for POST or PUT requests.
>> 
>> Illegal character in hostname; underscores are not allowed.
>> 
>> HTTP/1.1 Expect: feature is being asked from an HTTP/1.0 software.
>> 
>> Your cache administrator is
>> 
>> 
>> 
>> On Jul 22, 2024, at 04:42, Andrey K <ankor2023 at gmail.com> wrote:
>> 
>> Hello, Jonathan,
>> 
>>> curl http://localhost:3128/squid-internal-mgr/info
>> 
>>> Where would I place the password?
>> 
>> I use the following configuration:
>> http_access allow localhost  manager
>> cachemgr_passwd redacted config
>> 
>> The command to read the current running config is:
>> curl localhost:3128/squid-internal-mgr/config -u :redacted
>> 
>> 
>> Kind regards,
>>      Ankor.
>> 
>> 
>> 
>> 
>> ??, 18 ???. 2024??. ? 17:07, Alex Rousskov <rousskov at measurement-factory.com>:
>>> 
>>> On 2024-07-18 00:55, Jonathan Lee wrote:
>>> 
>>>> curl http://localhost:3128/squid-internal-mgr/info
>>>> 
>>>> Where would I place the password?
>>> 
>>> See "man curl" or online manual pages for curl. They will point you to
>>> two relevant options: --user and --proxy-user. AFAICT, your particular
>>> cache manager requests are sent _to_ the proxy (as if it were an origin
>>> server) rather than _through_ the proxy. Thus, you should use --user.
>>> 
>>> As I keep saying on this thread, due to Squid complications related to
>>> Bug 5283, specifying seemingly correct client parameters may not be
>>> enough to convince Squid to accept the cache manager request. I
>>> recommend the following procedure:
>>> 
>>> 1. List the corresponding http_port directive first, before any other
>>> http_port, https_port, and ftp_port directives. Do not use interception
>>> of any kind for this cache manager port.
>>> 
>>> 2. Use curl with absolute squid-internal-mgr URLs with http scheme (like
>>> you show above). Do _not_ use "curl --proxy" or similar. Do not use
>>> https scheme.
>>> 
>>> 3. In that absolute mgr URL, use the host name that matches
>>> visible_hostname in squid.conf. If you do not have visible_hostname in
>>> squid.conf, add it. This is not required, but, due to Squid bugs, it is
>>> often much easier to get this to work with visible_hostname than without it.
>>> 
>>> 4. Make (passwordless) mgr:info use case working first, before trying to
>>> get password-protected pages working.
>>> 
>>> 5. When you do specify a username and a password, remember that you are
>>> sending this request to an (equivalent of) a service running on an
>>> origin server, _not_ a proxy (hence --user rather than --proxy-user).
>>> 
>>> 
>>> If you cannot figure it out despite carefully going through the above
>>> steps, share (privately if needed) a pointer to compressed ALL,9
>>> cache.log while reproducing the problem with throw-away credentials on
>>> an idle Squid with a single curl request. Mention which step you got
>>> stuck on.
>>> 
>>> 
>>> HTH,
>>> 
>>> Alex.
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>> 
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 
> 
> 
> -- 
>    Francesco



From gkinkie at gmail.com  Mon Jul 22 18:22:48 2024
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Mon, 22 Jul 2024 19:22:48 +0100
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <FADEBDA5-3FA3-4D7A-B84E-E832E847B24F@gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
 <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
 <d18f0034-1f3b-4b51-9927-06aa5e7f01ca@measurement-factory.com>
 <CADJd0Y1h4wviABtDXQpCc2w1C7YQ0n9EKEh79=KYKQDFWLWtpA@mail.gmail.com>
 <781872AE-13EB-421F-BCB7-9B1E10E65BE4@gmail.com>
 <CA+Y8hcPzF3eKYARyq2jzHPSAsVGNQCeRT+sJ9BexMpVFTLG68A@mail.gmail.com>
 <FADEBDA5-3FA3-4D7A-B84E-E832E847B24F@gmail.com>
Message-ID: <CA+Y8hcNH9K4Ot12SU42Mu-+OMb1P_+Y-ZnpLpvxCWG9eiK8u7Q@mail.gmail.com>

Not really, no. Username is not considered, it's just to make sure
that curl sends all the data

On Mon, Jul 22, 2024 at 7:21?PM Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>
> That would require a username for the cachemgr_password account right? I have no usernames set up for this.
>
> How does one add a username for this directive ?
>
> > On Jul 22, 2024, at 11:13, Francesco Chemolli <gkinkie at gmail.com> wrote:
> >
> > Can you try supplying a username to curl? It's also common practice to
> > put flags ('-u user:redacted') before arguments (the URL)
> >
> > On Mon, Jul 22, 2024 at 5:12?PM Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> >>
> >> Thanks for the info
> >>
> >> I tried it and this also failed. Dang
> >>
> >> Shell Output - curl localhost:3128/squid-internal-mgr/info -u :redacted
> >>
> >>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
> >>                                 Dload  Upload   Total   Spent    Left  Speed
> >>
> >>  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
> >> 100  3773  100  3773    0     0  90756      0 --:--:-- --:--:-- --:--:-- 94325
> >> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
> >> <html><head>
> >> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
> >> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
> >> <title>ERROR: The requested URL could not be retrieved</title>
> >> <style type="text/css"><!--
> >> /*
> >> * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
> >> *
> >> * Squid software is distributed under GPLv2+ license and includes
> >> * contributions from numerous individuals and organizations.
> >> * Please see the COPYING and CONTRIBUTORS files for details.
> >> */
> >>
> >> /*
> >> Stylesheet for Squid Error pages
> >> Adapted from design by Free CSS Templates
> >> http://www.freecsstemplates.org
> >> Released for free under a Creative Commons Attribution 2.5 License
> >> */
> >>
> >> However I get a new error when attempting to connect over a web browser
> >>
> >> ERROR
> >>
> >> The requested URL could not be retrieved
> >>
> >> ________________________________
> >>
> >> Invalid Request error was encountered while trying to process the request:
> >>
> >> GET /squid-internal-mgr HTTP/1.1
> >> Host: lee_family.home.arpa:3128
> >> Upgrade-Insecure-Requests: 1
> >> Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
> >> User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Safari/605.1.15
> >> Accept-Language: en-US,en;q=0.9
> >> Accept-Encoding: gzip, deflate
> >> Connection: keep-alive
> >> DNT: 1
> >>
> >> Some possible problems are:
> >>
> >> Request is too large.
> >>
> >> Content-Length missing for POST or PUT requests.
> >>
> >> Illegal character in hostname; underscores are not allowed.
> >>
> >> HTTP/1.1 Expect: feature is being asked from an HTTP/1.0 software.
> >>
> >> Your cache administrator is
> >>
> >>
> >>
> >> On Jul 22, 2024, at 04:42, Andrey K <ankor2023 at gmail.com> wrote:
> >>
> >> Hello, Jonathan,
> >>
> >>> curl http://localhost:3128/squid-internal-mgr/info
> >>
> >>> Where would I place the password?
> >>
> >> I use the following configuration:
> >> http_access allow localhost  manager
> >> cachemgr_passwd redacted config
> >>
> >> The command to read the current running config is:
> >> curl localhost:3128/squid-internal-mgr/config -u :redacted
> >>
> >>
> >> Kind regards,
> >>      Ankor.
> >>
> >>
> >>
> >>
> >> ??, 18 ???. 2024??. ? 17:07, Alex Rousskov <rousskov at measurement-factory.com>:
> >>>
> >>> On 2024-07-18 00:55, Jonathan Lee wrote:
> >>>
> >>>> curl http://localhost:3128/squid-internal-mgr/info
> >>>>
> >>>> Where would I place the password?
> >>>
> >>> See "man curl" or online manual pages for curl. They will point you to
> >>> two relevant options: --user and --proxy-user. AFAICT, your particular
> >>> cache manager requests are sent _to_ the proxy (as if it were an origin
> >>> server) rather than _through_ the proxy. Thus, you should use --user.
> >>>
> >>> As I keep saying on this thread, due to Squid complications related to
> >>> Bug 5283, specifying seemingly correct client parameters may not be
> >>> enough to convince Squid to accept the cache manager request. I
> >>> recommend the following procedure:
> >>>
> >>> 1. List the corresponding http_port directive first, before any other
> >>> http_port, https_port, and ftp_port directives. Do not use interception
> >>> of any kind for this cache manager port.
> >>>
> >>> 2. Use curl with absolute squid-internal-mgr URLs with http scheme (like
> >>> you show above). Do _not_ use "curl --proxy" or similar. Do not use
> >>> https scheme.
> >>>
> >>> 3. In that absolute mgr URL, use the host name that matches
> >>> visible_hostname in squid.conf. If you do not have visible_hostname in
> >>> squid.conf, add it. This is not required, but, due to Squid bugs, it is
> >>> often much easier to get this to work with visible_hostname than without it.
> >>>
> >>> 4. Make (passwordless) mgr:info use case working first, before trying to
> >>> get password-protected pages working.
> >>>
> >>> 5. When you do specify a username and a password, remember that you are
> >>> sending this request to an (equivalent of) a service running on an
> >>> origin server, _not_ a proxy (hence --user rather than --proxy-user).
> >>>
> >>>
> >>> If you cannot figure it out despite carefully going through the above
> >>> steps, share (privately if needed) a pointer to compressed ALL,9
> >>> cache.log while reproducing the problem with throw-away credentials on
> >>> an idle Squid with a single curl request. Mention which step you got
> >>> stuck on.
> >>>
> >>>
> >>> HTH,
> >>>
> >>> Alex.
> >>>
> >>> _______________________________________________
> >>> squid-users mailing list
> >>> squid-users at lists.squid-cache.org
> >>> https://lists.squid-cache.org/listinfo/squid-users
> >>
> >> _______________________________________________
> >> squid-users mailing list
> >> squid-users at lists.squid-cache.org
> >> https://lists.squid-cache.org/listinfo/squid-users
> >>
> >>
> >> _______________________________________________
> >> squid-users mailing list
> >> squid-users at lists.squid-cache.org
> >> https://lists.squid-cache.org/listinfo/squid-users
> >
> >
> >
> > --
> >    Francesco
>


-- 
    Francesco


From jonathanlee571 at gmail.com  Mon Jul 22 18:24:03 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 22 Jul 2024 11:24:03 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <CA+Y8hcNH9K4Ot12SU42Mu-+OMb1P_+Y-ZnpLpvxCWG9eiK8u7Q@mail.gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
 <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
 <d18f0034-1f3b-4b51-9927-06aa5e7f01ca@measurement-factory.com>
 <CADJd0Y1h4wviABtDXQpCc2w1C7YQ0n9EKEh79=KYKQDFWLWtpA@mail.gmail.com>
 <781872AE-13EB-421F-BCB7-9B1E10E65BE4@gmail.com>
 <CA+Y8hcPzF3eKYARyq2jzHPSAsVGNQCeRT+sJ9BexMpVFTLG68A@mail.gmail.com>
 <FADEBDA5-3FA3-4D7A-B84E-E832E847B24F@gmail.com>
 <CA+Y8hcNH9K4Ot12SU42Mu-+OMb1P_+Y-ZnpLpvxCWG9eiK8u7Q@mail.gmail.com>
Message-ID: <9349AE15-1533-4CAE-A93D-5079845BED38@gmail.com>

Ok thanks let me boot that environment and test again, my concern is that is looks like it is attempting it from my WAN side address that is my wan address and not the loopback 

> On Jul 22, 2024, at 11:22, Francesco Chemolli <gkinkie at gmail.com> wrote:
> 
> Not really, no. Username is not considered, it's just to make sure
> that curl sends all the data
> 
> On Mon, Jul 22, 2024 at 7:21?PM Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> That would require a username for the cachemgr_password account right? I have no usernames set up for this.
>> 
>> How does one add a username for this directive ?
>> 
>>> On Jul 22, 2024, at 11:13, Francesco Chemolli <gkinkie at gmail.com> wrote:
>>> 
>>> Can you try supplying a username to curl? It's also common practice to
>>> put flags ('-u user:redacted') before arguments (the URL)
>>> 
>>> On Mon, Jul 22, 2024 at 5:12?PM Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>> 
>>>> Thanks for the info
>>>> 
>>>> I tried it and this also failed. Dang
>>>> 
>>>> Shell Output - curl localhost:3128/squid-internal-mgr/info -u :redacted
>>>> 
>>>> % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
>>>>                                Dload  Upload   Total   Spent    Left  Speed
>>>> 
>>>> 0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
>>>> 100  3773  100  3773    0     0  90756      0 --:--:-- --:--:-- --:--:-- 94325
>>>> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
>>>> <html><head>
>>>> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
>>>> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
>>>> <title>ERROR: The requested URL could not be retrieved</title>
>>>> <style type="text/css"><!--
>>>> /*
>>>> * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
>>>> *
>>>> * Squid software is distributed under GPLv2+ license and includes
>>>> * contributions from numerous individuals and organizations.
>>>> * Please see the COPYING and CONTRIBUTORS files for details.
>>>> */
>>>> 
>>>> /*
>>>> Stylesheet for Squid Error pages
>>>> Adapted from design by Free CSS Templates
>>>> http://www.freecsstemplates.org
>>>> Released for free under a Creative Commons Attribution 2.5 License
>>>> */
>>>> 
>>>> However I get a new error when attempting to connect over a web browser
>>>> 
>>>> ERROR
>>>> 
>>>> The requested URL could not be retrieved
>>>> 
>>>> ________________________________
>>>> 
>>>> Invalid Request error was encountered while trying to process the request:
>>>> 
>>>> GET /squid-internal-mgr HTTP/1.1
>>>> Host: lee_family.home.arpa:3128
>>>> Upgrade-Insecure-Requests: 1
>>>> Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
>>>> User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Safari/605.1.15
>>>> Accept-Language: en-US,en;q=0.9
>>>> Accept-Encoding: gzip, deflate
>>>> Connection: keep-alive
>>>> DNT: 1
>>>> 
>>>> Some possible problems are:
>>>> 
>>>> Request is too large.
>>>> 
>>>> Content-Length missing for POST or PUT requests.
>>>> 
>>>> Illegal character in hostname; underscores are not allowed.
>>>> 
>>>> HTTP/1.1 Expect: feature is being asked from an HTTP/1.0 software.
>>>> 
>>>> Your cache administrator is
>>>> 
>>>> 
>>>> 
>>>> On Jul 22, 2024, at 04:42, Andrey K <ankor2023 at gmail.com> wrote:
>>>> 
>>>> Hello, Jonathan,
>>>> 
>>>>> curl http://localhost:3128/squid-internal-mgr/info
>>>> 
>>>>> Where would I place the password?
>>>> 
>>>> I use the following configuration:
>>>> http_access allow localhost  manager
>>>> cachemgr_passwd redacted config
>>>> 
>>>> The command to read the current running config is:
>>>> curl localhost:3128/squid-internal-mgr/config -u :redacted
>>>> 
>>>> 
>>>> Kind regards,
>>>>     Ankor.
>>>> 
>>>> 
>>>> 
>>>> 
>>>> ??, 18 ???. 2024??. ? 17:07, Alex Rousskov <rousskov at measurement-factory.com>:
>>>>> 
>>>>> On 2024-07-18 00:55, Jonathan Lee wrote:
>>>>> 
>>>>>> curl http://localhost:3128/squid-internal-mgr/info
>>>>>> 
>>>>>> Where would I place the password?
>>>>> 
>>>>> See "man curl" or online manual pages for curl. They will point you to
>>>>> two relevant options: --user and --proxy-user. AFAICT, your particular
>>>>> cache manager requests are sent _to_ the proxy (as if it were an origin
>>>>> server) rather than _through_ the proxy. Thus, you should use --user.
>>>>> 
>>>>> As I keep saying on this thread, due to Squid complications related to
>>>>> Bug 5283, specifying seemingly correct client parameters may not be
>>>>> enough to convince Squid to accept the cache manager request. I
>>>>> recommend the following procedure:
>>>>> 
>>>>> 1. List the corresponding http_port directive first, before any other
>>>>> http_port, https_port, and ftp_port directives. Do not use interception
>>>>> of any kind for this cache manager port.
>>>>> 
>>>>> 2. Use curl with absolute squid-internal-mgr URLs with http scheme (like
>>>>> you show above). Do _not_ use "curl --proxy" or similar. Do not use
>>>>> https scheme.
>>>>> 
>>>>> 3. In that absolute mgr URL, use the host name that matches
>>>>> visible_hostname in squid.conf. If you do not have visible_hostname in
>>>>> squid.conf, add it. This is not required, but, due to Squid bugs, it is
>>>>> often much easier to get this to work with visible_hostname than without it.
>>>>> 
>>>>> 4. Make (passwordless) mgr:info use case working first, before trying to
>>>>> get password-protected pages working.
>>>>> 
>>>>> 5. When you do specify a username and a password, remember that you are
>>>>> sending this request to an (equivalent of) a service running on an
>>>>> origin server, _not_ a proxy (hence --user rather than --proxy-user).
>>>>> 
>>>>> 
>>>>> If you cannot figure it out despite carefully going through the above
>>>>> steps, share (privately if needed) a pointer to compressed ALL,9
>>>>> cache.log while reproducing the problem with throw-away credentials on
>>>>> an idle Squid with a single curl request. Mention which step you got
>>>>> stuck on.
>>>>> 
>>>>> 
>>>>> HTH,
>>>>> 
>>>>> Alex.
>>>>> 
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>> 
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>> 
>>>> 
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>>> 
>>> 
>>> 
>>> --
>>>   Francesco
>> 
> 
> 
> -- 
>    Francesco



From jonathanlee571 at gmail.com  Mon Jul 22 18:33:51 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 22 Jul 2024 11:33:51 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <9349AE15-1533-4CAE-A93D-5079845BED38@gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
 <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
 <d18f0034-1f3b-4b51-9927-06aa5e7f01ca@measurement-factory.com>
 <CADJd0Y1h4wviABtDXQpCc2w1C7YQ0n9EKEh79=KYKQDFWLWtpA@mail.gmail.com>
 <781872AE-13EB-421F-BCB7-9B1E10E65BE4@gmail.com>
 <CA+Y8hcPzF3eKYARyq2jzHPSAsVGNQCeRT+sJ9BexMpVFTLG68A@mail.gmail.com>
 <FADEBDA5-3FA3-4D7A-B84E-E832E847B24F@gmail.com>
 <CA+Y8hcNH9K4Ot12SU42Mu-+OMb1P_+Y-ZnpLpvxCWG9eiK8u7Q@mail.gmail.com>
 <9349AE15-1533-4CAE-A93D-5079845BED38@gmail.com>
Message-ID: <E82119E9-2124-4500-9268-2A5CEC069173@gmail.com>

Tested thanks for the reply and idea access denied and tested with a firewall rule to approve everything to port 80 same result with or without mgr_passord configured, it is like the page is missing in Squid 6.6 or something 

Shell Output - curl localhost:3128/squid-internal-mgr/info -u admin:redacted
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100  3783  100  3783    0     0   111k      0 --:--:-- --:--:-- --:--:--  115k
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
<meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>ERROR: The requested URL could not be retrieved</title>
<style type="text/css"><!--
 /*
 * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
 *
 * Squid software is distributed under GPLv2+ license and includes
 * contributions from numerous individuals and organizations.
 * Please see the COPYING and CONTRIBUTORS files for details.
 */

/*
 Stylesheet for Squid Error pages
 Adapted from design by Free CSS Templates
 http://www.freecsstemplates.org
 Released for free under a Creative Commons Attribution 2.5 License
*/

/* Page basics */
* {
	font-family: verdana, sans-serif;
}

html body {
	margin: 0;
	padding: 0;
	background: #efefef;
	font-size: 12px;
	color: #1e1e1e;
}

> On Jul 22, 2024, at 11:24, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Ok thanks let me boot that environment and test again, my concern is that is looks like it is attempting it from my WAN side address that is my wan address and not the loopback 
> 
>> On Jul 22, 2024, at 11:22, Francesco Chemolli <gkinkie at gmail.com> wrote:
>> 
>> Not really, no. Username is not considered, it's just to make sure
>> that curl sends all the data
>> 
>> On Mon, Jul 22, 2024 at 7:21?PM Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>> 
>>> That would require a username for the cachemgr_password account right? I have no usernames set up for this.
>>> 
>>> How does one add a username for this directive ?
>>> 
>>>> On Jul 22, 2024, at 11:13, Francesco Chemolli <gkinkie at gmail.com> wrote:
>>>> 
>>>> Can you try supplying a username to curl? It's also common practice to
>>>> put flags ('-u user:redacted') before arguments (the URL)
>>>> 
>>>> On Mon, Jul 22, 2024 at 5:12?PM Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>>> 
>>>>> Thanks for the info
>>>>> 
>>>>> I tried it and this also failed. Dang
>>>>> 
>>>>> Shell Output - curl localhost:3128/squid-internal-mgr/info -u :redacted
>>>>> 
>>>>> % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
>>>>>                               Dload  Upload   Total   Spent    Left  Speed
>>>>> 
>>>>> 0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
>>>>> 100  3773  100  3773    0     0  90756      0 --:--:-- --:--:-- --:--:-- 94325
>>>>> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
>>>>> <html><head>
>>>>> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
>>>>> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
>>>>> <title>ERROR: The requested URL could not be retrieved</title>
>>>>> <style type="text/css"><!--
>>>>> /*
>>>>> * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
>>>>> *
>>>>> * Squid software is distributed under GPLv2+ license and includes
>>>>> * contributions from numerous individuals and organizations.
>>>>> * Please see the COPYING and CONTRIBUTORS files for details.
>>>>> */
>>>>> 
>>>>> /*
>>>>> Stylesheet for Squid Error pages
>>>>> Adapted from design by Free CSS Templates
>>>>> http://www.freecsstemplates.org
>>>>> Released for free under a Creative Commons Attribution 2.5 License
>>>>> */
>>>>> 
>>>>> However I get a new error when attempting to connect over a web browser
>>>>> 
>>>>> ERROR
>>>>> 
>>>>> The requested URL could not be retrieved
>>>>> 
>>>>> ________________________________
>>>>> 
>>>>> Invalid Request error was encountered while trying to process the request:
>>>>> 
>>>>> GET /squid-internal-mgr HTTP/1.1
>>>>> Host: lee_family.home.arpa:3128
>>>>> Upgrade-Insecure-Requests: 1
>>>>> Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
>>>>> User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Safari/605.1.15
>>>>> Accept-Language: en-US,en;q=0.9
>>>>> Accept-Encoding: gzip, deflate
>>>>> Connection: keep-alive
>>>>> DNT: 1
>>>>> 
>>>>> Some possible problems are:
>>>>> 
>>>>> Request is too large.
>>>>> 
>>>>> Content-Length missing for POST or PUT requests.
>>>>> 
>>>>> Illegal character in hostname; underscores are not allowed.
>>>>> 
>>>>> HTTP/1.1 Expect: feature is being asked from an HTTP/1.0 software.
>>>>> 
>>>>> Your cache administrator is
>>>>> 
>>>>> 
>>>>> 
>>>>> On Jul 22, 2024, at 04:42, Andrey K <ankor2023 at gmail.com> wrote:
>>>>> 
>>>>> Hello, Jonathan,
>>>>> 
>>>>>> curl http://localhost:3128/squid-internal-mgr/info
>>>>> 
>>>>>> Where would I place the password?
>>>>> 
>>>>> I use the following configuration:
>>>>> http_access allow localhost  manager
>>>>> cachemgr_passwd redacted config
>>>>> 
>>>>> The command to read the current running config is:
>>>>> curl localhost:3128/squid-internal-mgr/config -u :redacted
>>>>> 
>>>>> 
>>>>> Kind regards,
>>>>>    Ankor.
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> ??, 18 ???. 2024??. ? 17:07, Alex Rousskov <rousskov at measurement-factory.com>:
>>>>>> 
>>>>>> On 2024-07-18 00:55, Jonathan Lee wrote:
>>>>>> 
>>>>>>> curl http://localhost:3128/squid-internal-mgr/info
>>>>>>> 
>>>>>>> Where would I place the password?
>>>>>> 
>>>>>> See "man curl" or online manual pages for curl. They will point you to
>>>>>> two relevant options: --user and --proxy-user. AFAICT, your particular
>>>>>> cache manager requests are sent _to_ the proxy (as if it were an origin
>>>>>> server) rather than _through_ the proxy. Thus, you should use --user.
>>>>>> 
>>>>>> As I keep saying on this thread, due to Squid complications related to
>>>>>> Bug 5283, specifying seemingly correct client parameters may not be
>>>>>> enough to convince Squid to accept the cache manager request. I
>>>>>> recommend the following procedure:
>>>>>> 
>>>>>> 1. List the corresponding http_port directive first, before any other
>>>>>> http_port, https_port, and ftp_port directives. Do not use interception
>>>>>> of any kind for this cache manager port.
>>>>>> 
>>>>>> 2. Use curl with absolute squid-internal-mgr URLs with http scheme (like
>>>>>> you show above). Do _not_ use "curl --proxy" or similar. Do not use
>>>>>> https scheme.
>>>>>> 
>>>>>> 3. In that absolute mgr URL, use the host name that matches
>>>>>> visible_hostname in squid.conf. If you do not have visible_hostname in
>>>>>> squid.conf, add it. This is not required, but, due to Squid bugs, it is
>>>>>> often much easier to get this to work with visible_hostname than without it.
>>>>>> 
>>>>>> 4. Make (passwordless) mgr:info use case working first, before trying to
>>>>>> get password-protected pages working.
>>>>>> 
>>>>>> 5. When you do specify a username and a password, remember that you are
>>>>>> sending this request to an (equivalent of) a service running on an
>>>>>> origin server, _not_ a proxy (hence --user rather than --proxy-user).
>>>>>> 
>>>>>> 
>>>>>> If you cannot figure it out despite carefully going through the above
>>>>>> steps, share (privately if needed) a pointer to compressed ALL,9
>>>>>> cache.log while reproducing the problem with throw-away credentials on
>>>>>> an idle Squid with a single curl request. Mention which step you got
>>>>>> stuck on.
>>>>>> 
>>>>>> 
>>>>>> HTH,
>>>>>> 
>>>>>> Alex.
>>>>>> 
>>>>>> _______________________________________________
>>>>>> squid-users mailing list
>>>>>> squid-users at lists.squid-cache.org
>>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>> 
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>>> 
>>>>> 
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>> 
>>>> 
>>>> 
>>>> --
>>>>  Francesco
>>> 
>> 
>> 
>> -- 
>>   Francesco
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240722/14451e3e/attachment.htm>

From squid3 at treenet.co.nz  Mon Jul 22 22:53:16 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 23 Jul 2024 10:53:16 +1200
Subject: [squid-users] squid "make check" error
In-Reply-To: <7e8bbd55-2997-4e2a-89c7-fab75a8f4bdc@measurement-factory.com>
References: <CAPnyBTN-Yy4NqraDKTbPDnOmzohVyHmp2jpQ4fxJ_UAy9MYMJA@mail.gmail.com>
 <807cf936-1616-44ac-9e8b-0aa4efb323e4@measurement-factory.com>
 <CAPnyBTOKgTE3StJUqu2T4JKWSzX0BMeUuxhpAGaaxKgbM87BdA@mail.gmail.com>
 <7e8bbd55-2997-4e2a-89c7-fab75a8f4bdc@measurement-factory.com>
Message-ID: <a69342cb-6509-468e-af9c-9b4702fda167@treenet.co.nz>

On 20/07/24 03:19, Alex Rousskov wrote:
> On 2024-07-19 09:20, Rafa? Stanilewicz wrote:
>> Thank you. It worked.
> 
> Glad to hear that!
> 

Seconded.

> 
>> I incorrectly assumed all dependencies would be captured by aptitude 
>> build-dep squid and ./configure.
> 

AFAIK that is a correct assumption for Debian based packages. The only 
additional dependencies needed should be for features *not* enabled in 
the package.

This failure is quite a surprise to me. That said, I test the Debian 
"squid" package with "apt" not "aptitude" and there are some unexpected 
algorithm differences at times.

> 
> Should "squid" package build dependencies accommodate "make check"?
> 

The Debian/Ubuntu packages should since the package creation runs "make 
check". The "apt build-dep squid" should pull in everything necessary to 
build the relevant squid_*.deb package (except some few essential OS 
packages which should exist everywhere).


libcppunit-dev has been listed as a squid dependency for many years. So 
I would not be surprised if some ancient Ubuntu (circa 2010 or such) 
showed this behaviour, but certainly not the one you have.


Cheers
Amos


From gkinkie at gmail.com  Tue Jul 23 07:03:48 2024
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Tue, 23 Jul 2024 08:03:48 +0100
Subject: [squid-users] Squid on Freebsd
In-Reply-To: <434672a6-88d5-4bef-a944-292681244278@miex.cc>
References: <18de4a5f-7c22-4910-a37b-24dc72783b4d@miex.cc>
 <434672a6-88d5-4bef-a944-292681244278@miex.cc>
Message-ID: <CA+Y8hcNzefM=jyD4ma3q4hkW008z3+BMYTnfarUeLnL8muyiwA@mail.gmail.com>

Hi Anton,
  no, segmentation fault shouldn't happen at any time.
Could you try to follow the instructions at
https://wiki.squid-cache.org/SquidFaq/BugReporting#crashes-and-core-dumps
 ?
What are the last lines in the cache.log when the segmentation fault happens?
Thanks

On Tue, Jul 23, 2024 at 3:12?AM Anton Kornexl <anton.kornexl at miex.cc> wrote:
>
> Hello,
>
> I have tested the two installations further
>
> Opnsense 23.x with squid 6.6 on freebsd 13.2-Release-p9 produces the
> same segmentation fault, but it does not popup as red window in the
> dashboard.
>
> I have set "debug_options ALL,5" in squid.conf:
>
> I have found the following lines in cache.log (grep _suid cache.log)
>
> 2024/07/22 17:26:52.186 kid1| 21,3| tools.cc(625) enter_suid:
> enter_suid: PID 29145 taking root privileges
> 2024/07/22 17:26:52.186 kid1| 21,31 tools.cc(629) enter_suid:
> enter_suid: setresuid failed: (1) Operation not permitted
> 2024/07/22 17:26:52.186 kid1| 21,3| tools.cc(561) leave suid: leave
> suid: PID 29145 called
> 2024/07/22 17:26:52.187 kid1| 21,31 tools.cc(625) enter_suid:
> enter_suid: PID 29145 taking root privileges
> 2024/07/22 17:26:52.187 kid1| 21,3| tools.cc(629) enter_suid:
> enter_suid: setresuid failed: (1) Operation not permitted
> 2024/07/22 17:26:52.187 kid1| 21,31 tools.cc(561) leave_suid: leave
> suid: PID 29145 called
> 2024/07/22 17:26:52.187 kid1| 21,31 tools.cc(625) enter_suid:
> enter_suid: PID 29145 taking root privileges
> 2024/07/22 17:26:52.187 kid1l 21,31 tools.cc(629) enter_suid:
> enter_suid: setresuid failed: (1) Operation not permitted
> 2024/07/22 17:26:52.187 kid1| 21,31 tools.cc(561) leave_suid: leave
> suid: PID 29145 called
> 2024/07/22 17:26:52.187 kid1l 21,31 tools.cc(561) leave_suid:
> leave_suid: PID 29648 called
> 2024/07/22 17:26:52.187 kid1l 21,31 tools.cc(651) no_suid: no_suid: PID
> 29648 giving up root privileges forever
>
> maybe this is the cause of the "segmentation fault".
>
> The difference between the installations 23.x and 24.x is the alerting
> of this segmentaion fault in the dashboard of opnsense.
>
> But what ist the cause of this "Operation not permitted"
>
> yours
>
> Anton Kornexl
>
> Am 22.07.2024 um 11:03 schrieb Anton Kornexl:
> >  Hello
> >
> > i try to use squid (6.10)  with opnsense 24.x on freebsd
> > 13-2-Release-p11.
> >
> > It produces a "segmentation fault" at start and restart but the
> > process runs.
> >
> > The "segmentation fault" occurs even with squid -k parse.
> >
> > A "service squid reload" runs OK, but a "service squid restart"
> > produces this Segmentation fault.
> >
> > The problem did not exist with opnsense 23.x and an older squid.
> >
> > How can I debug this error probably in the parse part?
> >
> > yours
> >
> > Anton Kornexl
> >
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > https://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco


From anton.kornexl at miex.cc  Tue Jul 23 17:34:47 2024
From: anton.kornexl at miex.cc (Anton Kornexl)
Date: Tue, 23 Jul 2024 19:34:47 +0200
Subject: [squid-users] Squid on Freebsd
In-Reply-To: <CA+Y8hcNzefM=jyD4ma3q4hkW008z3+BMYTnfarUeLnL8muyiwA@mail.gmail.com>
Message-ID: <cd459d39-05ec-404e-aba5-157ec92c8f10@email.android.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240723/76eb255f/attachment.htm>

From rousskov at measurement-factory.com  Tue Jul 23 19:22:59 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 23 Jul 2024 15:22:59 -0400
Subject: [squid-users] Squid on Freebsd
In-Reply-To: <cd459d39-05ec-404e-aba5-157ec92c8f10@email.android.com>
References: <cd459d39-05ec-404e-aba5-157ec92c8f10@email.android.com>
Message-ID: <dff99ccc-4af8-4a9e-9149-b3981238fd86@measurement-factory.com>

On 2024-07-23 13:34, Anton Kornexl wrote:

> Squid starts, shows a segmentation fault and continues working normally.
> Squid forks a worker child and probably this child works, but the parent 
> process dies with segmentation fault. There is no sign of this 
> segmention fault in the cache log.

You may catch parent Squid in the act of crashing if you start Squid 
from gdb, but telling gdb which process to watch may not be trivial, and 
I would leave that experiment for later and focus on an easier target first:


> The segmentation fault occurs even when calling squid -k parse.
> 
> Should i try to produce a coredump of a squid -k parse run?

Yes, please: `gdb --args squid -k parse ...` or a similar command may 
work to tell gdb how to start Squid. After that, inside gdb, a "run" 
command should start Squid and produce a stack trace we need to triage 
this problem further.

Alternatively, enable coredump file generation in your OS (if needed) 
and examine the dump file using gdb as detailed on the same page that 
Francesco has referenced earlier:
https://wiki.squid-cache.org/SquidFaq/BugReporting#crashes-and-core-dumps


HTH,

Alex.


> Am 23.07.2024 09:03 schrieb Francesco Chemolli <gkinkie at gmail.com>:
> 
>     Hi Anton,
>      ? no, segmentation fault shouldn't happen at any time.
>     Could you try to follow the instructions at
>     https://wiki.squid-cache.org/SquidFaq/BugReporting#crashes-and-core-dumps
>     ?
>     What are the last lines in the cache.log when the segmentation fault
>     happens?
>     Thanks
> 
>     On Tue, Jul 23, 2024 at 3:12?AM Anton Kornexl
>     <anton.kornexl at miex.cc> wrote:
>      >
>      > Hello,
>      >
>      > I have tested the two installations further
>      >
>      > Opnsense 23.x with squid 6.6 on freebsd 13.2-Release-p9 produces the
>      > same segmentation fault, but it does not popup as red window in the
>      > dashboard.
>      >
>      > I have set "debug_options ALL,5" in squid.conf:
>      >
>      > I have found the following lines in cache.log (grep _suid cache.log)
>      >
>      > 2024/07/22 17:26:52.186 kid1| 21,3| tools.cc(625) enter_suid:
>      > enter_suid: PID 29145 taking root privileges
>      > 2024/07/22 17:26:52.186 kid1| 21,31 tools.cc(629) enter_suid:
>      > enter_suid: setresuid failed: (1) Operation not permitted
>      > 2024/07/22 17:26:52.186 kid1| 21,3| tools.cc(561) leave suid: leave
>      > suid: PID 29145 called
>      > 2024/07/22 17:26:52.187 kid1| 21,31 tools.cc(625) enter_suid:
>      > enter_suid: PID 29145 taking root privileges
>      > 2024/07/22 17:26:52.187 kid1| 21,3| tools.cc(629) enter_suid:
>      > enter_suid: setresuid failed: (1) Operation not permitted
>      > 2024/07/22 17:26:52.187 kid1| 21,31 tools.cc(561) leave_suid: leave
>      > suid: PID 29145 called
>      > 2024/07/22 17:26:52.187 kid1| 21,31 tools.cc(625) enter_suid:
>      > enter_suid: PID 29145 taking root privileges
>      > 2024/07/22 17:26:52.187 kid1l 21,31 tools.cc(629) enter_suid:
>      > enter_suid: setresuid failed: (1) Operation not permitted
>      > 2024/07/22 17:26:52.187 kid1| 21,31 tools.cc(561) leave_suid: leave
>      > suid: PID 29145 called
>      > 2024/07/22 17:26:52.187 kid1l 21,31 tools.cc(561) leave_suid:
>      > leave_suid: PID 29648 called
>      > 2024/07/22 17:26:52.187 kid1l 21,31 tools.cc(651) no_suid:
>     no_suid: PID
>      > 29648 giving up root privileges forever
>      >
>      > maybe this is the cause of the "segmentation fault".
>      >
>      > The difference between the installations 23.x and 24.x is the
>     alerting
>      > of this segmentaion fault in the dashboard of opnsense.
>      >
>      > But what ist the cause of this "Operation not permitted"
>      >
>      > yours
>      >
>      > Anton Kornexl
>      >
>      > Am 22.07.2024 um 11:03 schrieb Anton Kornexl:
>      > >? Hello
>      > >
>      > > i try to use squid (6.10)? with opnsense 24.x on freebsd
>      > > 13-2-Release-p11.
>      > >
>      > > It produces a "segmentation fault" at start and restart but the
>      > > process runs.
>      > >
>      > > The "segmentation fault" occurs even with squid -k parse.
>      > >
>      > > A "service squid reload" runs OK, but a "service squid restart"
>      > > produces this Segmentation fault.
>      > >
>      > > The problem did not exist with opnsense 23.x and an older squid.
>      > >
>      > > How can I debug this error probably in the parse part?
>      > >
>      > > yours
>      > >
>      > > Anton Kornexl




From andre.bolinhas at articatech.com  Tue Jul 23 23:20:00 2024
From: andre.bolinhas at articatech.com (Andre Bolinhas)
Date: Wed, 24 Jul 2024 00:20:00 +0100
Subject: [squid-users] SQUID - WINDBIND - very slow internet speed
Message-ID: <11060a91-e9b8-4755-8e60-fe9bdbce2032@articatech.com>

Hi Team.

I'm using SQUID 5.9 + windbindd 4.9.5, the authentication method is NTLM.

Every day, around 5pm, the internet speed becomes very slow, with users 
reporting that websites takes too long to open.

Also, the time that the issue occur is very strange, since is when most 
of the users are not in the office anymore

By doing a deep analyze on Proxy server, I manage to find this error 
that could be related with this issue.

Cache.log
GENSEC login failed: NT_STATUS_LOGON_FAILURE
GENSEC login failed: NT_STATUS_LOGON_FAILURE
GENSEC login failed: NT_STATUS_LOGON_FAILURE
GENSEC login failed: NT_STATUS_LOGON_FAILURE

Windbindd.log
[2024/07/22 17:06:48.220216,? 2] 
../source3/winbindd/winbindd.c:1121(remove_client)
 ? final write to client failed: Broken pipe
[2024/07/22 17:06:48.220319,? 0] 
../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
 ? winbindd: Exceeding 500 client connections, no idle connection found
[2024/07/22 17:06:48.261482,? 0] 
../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
 ? winbindd: Exceeding 500 client connections, no idle connection found
[2024/07/22 17:06:48.261857,? 2] 
../source3/winbindd/winbindd.c:1121(remove_client)
 ? final write to client failed: Broken pipe
[2024/07/22 17:06:48.261926,? 0] 
../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
 ? winbindd: Exceeding 500 client connections, no idle connection found
[2024/07/22 17:06:48.276216,? 0] 
../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
 ? winbindd: Exceeding 500 client connections, no idle connection found
[2024/07/22 17:06:48.276507,? 2] 
../source3/winbindd/winbindd.c:1121(remove_client)
 ? final write to client failed: Broken pipe
[2024/07/22 17:06:48.276568,? 0] 
../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
 ? winbindd: Exceeding 500 client connections, no idle connection found
[2024/07/22 17:09:02.512093,? 1] 
../source4/lib/messaging/messaging.c:83(ping_message)
 ? INFO: Received PING message from server 10301 []
[2024/07/22 17:09:02.512159,? 1] ../source3/lib/messages.c:131(ping_message)
 ? INFO: Received PING message from PID 10301 []
[2024/07/22 17:11:27.979681,? 1] 
../source3/winbindd/winbindd_util.c:440(trustdom_list_done)
 ? trustdom_list_done: Could not receive trusts for domain BANK
[2024/07/22 17:11:27.979756,? 1] 
../source3/winbindd/winbindd_util.c:440(trustdom_list_done)
 ? trustdom_list_done: Could not receive trusts for domain HLGROUP
[2024/07/22 17:12:02.612725,? 1] 
../source4/lib/messaging/messaging.c:83(ping_message)
 ? INFO: Received PING message from server 4706 []
[2024/07/22 17:12:02.612794,? 1] ../source3/lib/messages.c:131(ping_message)
 ? INFO: Received PING message from PID 4706 []
[2024/07/22 17:15:03.307322,? 1] 
../source4/lib/messaging/messaging.c:83(ping_message)
 ? INFO: Received PING message from server 13541 []
[2024/07/22 17:15:03.307477,? 1] ../source3/lib/messages.c:131(ping_message)
 ? INFO: Received PING message from PID 13541 []
[2024/07/22 17:18:02.603927,? 1] 
../source4/lib/messaging/messaging.c:83(ping_message)
 ? INFO: Received PING message from server 27640 []
[2024/07/22 17:18:02.603983,? 1] ../source3/lib/messages.c:131(ping_message)
 ? INFO: Received PING message from PID 27640 []

smb.conf
[global]
 ?? netbios name?????????????? = ASP02
 ?? log level????????????????? = 2
 ?? workgroup????????????????? = mydom
 ?? kerberos method??????????? = dedicated keytab
 ?? dedicated keytab file????? = /etc/krb5.keytab
 ?? realm????????????????????? = mydom.MY
 ?? password server??????????? = 10.150.1.62
 ?? security?????????????????? = ads
 ?? winbind enum groups??????? = No
 ?? winbind enum users???????? = No
 ?? idmap config * : backend?? = tdb
 ?? idmap config * : range???? = 3000-7999
 ?? idmap config mydom:backend = ad
 ?? idmap config mydom:schema_mode = rfc2307
 ?? idmap config mydom:range = 10000-999999
 ?? idmap config mydom:unix_nss_info = yes
tls enabled = yes
ldap ssl = start tls
tls keyfile? = tls/key.pem
tls certfile = tls/cert.pem
tls cafile?? = tls/ca.pem
client ldap sasl wrapping = plain
 ?? client ntlmv2 auth???????? = Yes
 ?? client lanman auth???????? = No
 ?? client ldap sasl wrapping? = sign
 ?? winbind normalize names??? = No
 ?? winbind separator????????? = /
 ?? winbind use default domain = yes
 ?? winbind nested groups????? = Yes
 ?? winbind reconnect delay??? = 30
 ?? winbind offline logon????? = true
 ?? winbind cache time???????? = 1800
 ?? winbind refresh tickets??? = true
 ?? winbind refresh tickets??? = true
 ?? winbind max clients??????? = 500
 ?? allow trusted domains????? = Yes
 ?? server signing???????????? = auto
 ?? client signing???????????? = auto
 ?? lm announce??????????????? = No
 ?? ntlm auth????????????????? = No
 ?? lanman auth??????????????? = No
 ?? preferred master?????????? = No
 ?? local master?????????????? = No
 ?? wins support?????????????? = No
 ?? encrypt passwords????????? = yes
 ?? printing?????????????????? = bsd
 ?? load printers????????????? = no
 ?? socket options???????????? = TCP_NODELAY SO_RCVBUF=8192 SO_SNDBUF=8192
 ?? min protocol?????????????? = SMB2
 ?? client min protocol ??? ??? ?= SMB2
 ?? client max protocol ??? ??? ?= SMB3
 ?? load printers????????????? = no
 ?? printing?????????????????? = bsd
 ?? printcap name????????????? = /dev/null
 ?? disable spoolss??????????? = yes

Squid.conf

# kerberos_conf() LockActiveDirectoryToKerberos = 0

#
#KerbAuthMethod = 0/1 and NOT_NTLM = False
auth_param ntlm program /usr/bin/ntlm_auth? --domain=mydom.MY 
--helper-protocol=squid-2.5-ntlmssp
auth_param ntlm children 500 startup=5 idle=1 concurrency=0 
queue-size=2000 on-persistent-overload=ERR
auth_param ntlm keep_alive off

#
# ads groups OK
#Other settings
auth_param basic credentialsttl 7200 seconds
authenticate_ttl 3600 seconds
authenticate_ip_ttl 1 seconds
authenticate_cache_garbage_interval 3600 seconds

acl authFailed src all
acl AUTHENTICATED proxy_auth REQUIRED
# END NTLM Parameters --------------------------------
# Basic authentication for other browser that did not supports NTLM
auth_param basic program /usr/bin/ntlm_auth 
--helper-protocol=squid-2.5-basic
auth_param basic children 60 startup=2 idle=1
auth_param basic realm Active Directory Basic Identification
auth_param basic credentialsttl 7200 seconds
authenticate_ttl 3600 seconds
authenticate_ip_ttl 1 seconds
authenticate_cache_garbage_interval 3600 seconds

# ldap_auth_ad() EnableAdLDAPAuth = 0 - SKIP

# ads groups OK



# --------------------------------------------------



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240724/a1582d52/attachment.htm>

From gkinkie at gmail.com  Wed Jul 24 18:48:07 2024
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Wed, 24 Jul 2024 19:48:07 +0100
Subject: [squid-users] SQUID - WINDBIND - very slow internet speed
In-Reply-To: <11060a91-e9b8-4755-8e60-fe9bdbce2032@articatech.com>
References: <11060a91-e9b8-4755-8e60-fe9bdbce2032@articatech.com>
Message-ID: <CA+Y8hcO1HkF3oRtK7ra5CCpu6ZW74NCfLXP8OD15YjffhbV9yQ@mail.gmail.com>

Hi Andre,

The chain of services here is:

browser <-> squid <-> ntlm_auth <-> winbindd <-> active directory

In order to bisect the problem, could you try using `wbinfo -a` on one
of the affected machiens to authenticate against Active Directory and
see if the performance is on the winbindd <-> AD side of the equation
on on the squid <-> ntlm_auth side?

On Wed, Jul 24, 2024 at 7:27?PM Andre Bolinhas
<andre.bolinhas at articatech.com> wrote:
>
> Hi Team.
>
> I'm using SQUID 5.9 + windbindd 4.9.5, the authentication method is NTLM.
>
> Every day, around 5pm, the internet speed becomes very slow, with users reporting that websites takes too long to open.
>
> Also, the time that the issue occur is very strange, since is when most of the users are not in the office anymore
>
> By doing a deep analyze on Proxy server, I manage to find this error that could be related with this issue.
>
> Cache.log
> GENSEC login failed: NT_STATUS_LOGON_FAILURE
> GENSEC login failed: NT_STATUS_LOGON_FAILURE
> GENSEC login failed: NT_STATUS_LOGON_FAILURE
> GENSEC login failed: NT_STATUS_LOGON_FAILURE
>
> Windbindd.log
> [2024/07/22 17:06:48.220216,  2] ../source3/winbindd/winbindd.c:1121(remove_client)
>   final write to client failed: Broken pipe
> [2024/07/22 17:06:48.220319,  0] ../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
>   winbindd: Exceeding 500 client connections, no idle connection found
> [2024/07/22 17:06:48.261482,  0] ../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
>   winbindd: Exceeding 500 client connections, no idle connection found
> [2024/07/22 17:06:48.261857,  2] ../source3/winbindd/winbindd.c:1121(remove_client)
>   final write to client failed: Broken pipe
> [2024/07/22 17:06:48.261926,  0] ../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
>   winbindd: Exceeding 500 client connections, no idle connection found
> [2024/07/22 17:06:48.276216,  0] ../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
>   winbindd: Exceeding 500 client connections, no idle connection found
> [2024/07/22 17:06:48.276507,  2] ../source3/winbindd/winbindd.c:1121(remove_client)
>   final write to client failed: Broken pipe
> [2024/07/22 17:06:48.276568,  0] ../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
>   winbindd: Exceeding 500 client connections, no idle connection found
> [2024/07/22 17:09:02.512093,  1] ../source4/lib/messaging/messaging.c:83(ping_message)
>   INFO: Received PING message from server 10301 []
> [2024/07/22 17:09:02.512159,  1] ../source3/lib/messages.c:131(ping_message)
>   INFO: Received PING message from PID 10301 []
> [2024/07/22 17:11:27.979681,  1] ../source3/winbindd/winbindd_util.c:440(trustdom_list_done)
>   trustdom_list_done: Could not receive trusts for domain BANK
> [2024/07/22 17:11:27.979756,  1] ../source3/winbindd/winbindd_util.c:440(trustdom_list_done)
>   trustdom_list_done: Could not receive trusts for domain HLGROUP
> [2024/07/22 17:12:02.612725,  1] ../source4/lib/messaging/messaging.c:83(ping_message)
>   INFO: Received PING message from server 4706 []
> [2024/07/22 17:12:02.612794,  1] ../source3/lib/messages.c:131(ping_message)
>   INFO: Received PING message from PID 4706 []
> [2024/07/22 17:15:03.307322,  1] ../source4/lib/messaging/messaging.c:83(ping_message)
>   INFO: Received PING message from server 13541 []
> [2024/07/22 17:15:03.307477,  1] ../source3/lib/messages.c:131(ping_message)
>   INFO: Received PING message from PID 13541 []
> [2024/07/22 17:18:02.603927,  1] ../source4/lib/messaging/messaging.c:83(ping_message)
>   INFO: Received PING message from server 27640 []
> [2024/07/22 17:18:02.603983,  1] ../source3/lib/messages.c:131(ping_message)
>   INFO: Received PING message from PID 27640 []
>
> smb.conf
> [global]
>    netbios name               = ASP02
>    log level                  = 2
>    workgroup                  = mydom
>    kerberos method            = dedicated keytab
>    dedicated keytab file      = /etc/krb5.keytab
>    realm                      = mydom.MY
>    password server            = 10.150.1.62
>    security                   = ads
>    winbind enum groups        = No
>    winbind enum users         = No
>    idmap config * : backend   = tdb
>    idmap config * : range     = 3000-7999
>    idmap config mydom:backend = ad
>    idmap config mydom:schema_mode = rfc2307
>    idmap config mydom:range = 10000-999999
>    idmap config mydom:unix_nss_info = yes
> tls enabled = yes
> ldap ssl = start tls
> tls keyfile  = tls/key.pem
> tls certfile = tls/cert.pem
> tls cafile   = tls/ca.pem
> client ldap sasl wrapping = plain
>    client ntlmv2 auth         = Yes
>    client lanman auth         = No
>    client ldap sasl wrapping  = sign
>    winbind normalize names    = No
>    winbind separator          = /
>    winbind use default domain = yes
>    winbind nested groups      = Yes
>    winbind reconnect delay    = 30
>    winbind offline logon      = true
>    winbind cache time         = 1800
>    winbind refresh tickets    = true
>    winbind refresh tickets    = true
>    winbind max clients        = 500
>    allow trusted domains      = Yes
>    server signing             = auto
>    client signing             = auto
>    lm announce                = No
>    ntlm auth                  = No
>    lanman auth                = No
>    preferred master           = No
>    local master               = No
>    wins support               = No
>    encrypt passwords          = yes
>    printing                   = bsd
>    load printers              = no
>    socket options             = TCP_NODELAY SO_RCVBUF=8192 SO_SNDBUF=8192
>    min protocol               = SMB2
>    client min protocol          = SMB2
>    client max protocol          = SMB3
>    load printers              = no
>    printing                   = bsd
>    printcap name              = /dev/null
>    disable spoolss            = yes
>
> Squid.conf
>
> # kerberos_conf() LockActiveDirectoryToKerberos = 0
>
> #
> #KerbAuthMethod = 0/1 and NOT_NTLM = False
> auth_param ntlm program /usr/bin/ntlm_auth  --domain=mydom.MY --helper-protocol=squid-2.5-ntlmssp
> auth_param ntlm children 500 startup=5 idle=1 concurrency=0 queue-size=2000 on-persistent-overload=ERR
> auth_param ntlm keep_alive off
>
> #
> # ads groups OK
> #Other settings
> auth_param basic credentialsttl 7200 seconds
> authenticate_ttl 3600 seconds
> authenticate_ip_ttl 1 seconds
> authenticate_cache_garbage_interval 3600 seconds
>
> acl authFailed src all
> acl AUTHENTICATED proxy_auth REQUIRED
> # END NTLM Parameters --------------------------------
> # Basic authentication for other browser that did not supports NTLM
> auth_param basic program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-basic
> auth_param basic children 60 startup=2 idle=1
> auth_param basic realm Active Directory Basic Identification
> auth_param basic credentialsttl 7200 seconds
> authenticate_ttl 3600 seconds
> authenticate_ip_ttl 1 seconds
> authenticate_cache_garbage_interval 3600 seconds
>
> # ldap_auth_ad() EnableAdLDAPAuth = 0 - SKIP
>
> # ads groups OK
>
>
>
> # --------------------------------------------------
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco


From gkinkie at gmail.com  Wed Jul 24 21:29:23 2024
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Wed, 24 Jul 2024 22:29:23 +0100
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <46154037-39EA-4F75-9DE5-1D538FEEFAD7@gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
 <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
 <d18f0034-1f3b-4b51-9927-06aa5e7f01ca@measurement-factory.com>
 <CADJd0Y1h4wviABtDXQpCc2w1C7YQ0n9EKEh79=KYKQDFWLWtpA@mail.gmail.com>
 <781872AE-13EB-421F-BCB7-9B1E10E65BE4@gmail.com>
 <46154037-39EA-4F75-9DE5-1D538FEEFAD7@gmail.com>
Message-ID: <CA+Y8hcMS0gHUx8nUBcY6pvRCvvU3=XrZmNDk9kuadCenf8JWhA@mail.gmail.com>

Hi Jonathan,
  could you try:
curl -u anything:redacted http://localhost:3128/squid-internal-mgr/menu

?

On Mon, Jul 22, 2024 at 8:52?PM Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>
> Also I have tested
>
> curl 127.0.0.1:3128/squid-internal-mgr -u :redacted
> curl localhost:3128/squid-internal-mgr -u :redacted
> curl hostname_here:3128/squid-internal-mgr -u :redacted (per bug notes use hostname in place of localhost)
>
> and testing with no password same commands lock up the system with no response and if I do them outside of the host with a web browser I get the errors below seen they are new..
>
> HTTP/1.1 Expect: feature is being asked from an HTTP/1.0 software.
>
>
>
>
>
> On Jul 22, 2024, at 09:01, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>
> Thanks for the info
>
> I tried it and this also failed. Dang
>
> Shell Output - curl localhost:3128/squid-internal-mgr/info -u :redacted
>
>   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
>                                  Dload  Upload   Total   Spent    Left  Speed
>
>   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
> 100  3773  100  3773    0     0  90756      0 --:--:-- --:--:-- --:--:-- 94325
> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
> <html><head>
> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
> <title>ERROR: The requested URL could not be retrieved</title>
> <style type="text/css"><!--
>  /*
>  * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
>  *
>  * Squid software is distributed under GPLv2+ license and includes
>  * contributions from numerous individuals and organizations.
>  * Please see the COPYING and CONTRIBUTORS files for details.
>  */
>
> /*
>  Stylesheet for Squid Error pages
>  Adapted from design by Free CSS Templates
>  http://www.freecsstemplates.org
>  Released for free under a Creative Commons Attribution 2.5 License
> */
>
> However I get a new error when attempting to connect over a web browser
>
> ERROR
>
> The requested URL could not be retrieved
>
> ________________________________
>
> Invalid Request error was encountered while trying to process the request:
>
> GET /squid-internal-mgr HTTP/1.1
> Host: lee_family.home.arpa:3128
> Upgrade-Insecure-Requests: 1
> Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
> User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Safari/605.1.15
> Accept-Language: en-US,en;q=0.9
> Accept-Encoding: gzip, deflate
> Connection: keep-alive
> DNT: 1
>
> Some possible problems are:
>
> Request is too large.
>
> Content-Length missing for POST or PUT requests.
>
> Illegal character in hostname; underscores are not allowed.
>
> HTTP/1.1 Expect: feature is being asked from an HTTP/1.0 software.
>
> Your cache administrator is
>
>
>
> On Jul 22, 2024, at 04:42, Andrey K <ankor2023 at gmail.com> wrote:
>
> Hello, Jonathan,
>
> > curl http://localhost:3128/squid-internal-mgr/info
>
> > Where would I place the password?
>
> I use the following configuration:
> http_access allow localhost  manager
> cachemgr_passwd redacted config
>
> The command to read the current running config is:
> curl localhost:3128/squid-internal-mgr/config -u :redacted
>
>
> Kind regards,
>       Ankor.
>
>
>
>
> ??, 18 ???. 2024??. ? 17:07, Alex Rousskov <rousskov at measurement-factory.com>:
>>
>> On 2024-07-18 00:55, Jonathan Lee wrote:
>>
>> > curl http://localhost:3128/squid-internal-mgr/info
>> >
>> > Where would I place the password?
>>
>> See "man curl" or online manual pages for curl. They will point you to
>> two relevant options: --user and --proxy-user. AFAICT, your particular
>> cache manager requests are sent _to_ the proxy (as if it were an origin
>> server) rather than _through_ the proxy. Thus, you should use --user.
>>
>> As I keep saying on this thread, due to Squid complications related to
>> Bug 5283, specifying seemingly correct client parameters may not be
>> enough to convince Squid to accept the cache manager request. I
>> recommend the following procedure:
>>
>> 1. List the corresponding http_port directive first, before any other
>> http_port, https_port, and ftp_port directives. Do not use interception
>> of any kind for this cache manager port.
>>
>> 2. Use curl with absolute squid-internal-mgr URLs with http scheme (like
>> you show above). Do _not_ use "curl --proxy" or similar. Do not use
>> https scheme.
>>
>> 3. In that absolute mgr URL, use the host name that matches
>> visible_hostname in squid.conf. If you do not have visible_hostname in
>> squid.conf, add it. This is not required, but, due to Squid bugs, it is
>> often much easier to get this to work with visible_hostname than without it.
>>
>> 4. Make (passwordless) mgr:info use case working first, before trying to
>> get password-protected pages working.
>>
>> 5. When you do specify a username and a password, remember that you are
>> sending this request to an (equivalent of) a service running on an
>> origin server, _not_ a proxy (hence --user rather than --proxy-user).
>>
>>
>> If you cannot figure it out despite carefully going through the above
>> steps, share (privately if needed) a pointer to compressed ALL,9
>> cache.log while reproducing the problem with throw-away credentials on
>> an idle Squid with a single curl request. Mention which step you got
>> stuck on.
>>
>>
>> HTH,
>>
>> Alex.
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco


From ankor2023 at gmail.com  Thu Jul 25 06:02:10 2024
From: ankor2023 at gmail.com (Andrey K)
Date: Thu, 25 Jul 2024 09:02:10 +0300
Subject: [squid-users] SQUID - WINDBIND - very slow internet speed
In-Reply-To: <CA+Y8hcO1HkF3oRtK7ra5CCpu6ZW74NCfLXP8OD15YjffhbV9yQ@mail.gmail.com>
References: <11060a91-e9b8-4755-8e60-fe9bdbce2032@articatech.com>
 <CA+Y8hcO1HkF3oRtK7ra5CCpu6ZW74NCfLXP8OD15YjffhbV9yQ@mail.gmail.com>
Message-ID: <CADJd0Y1S5f4vAp-Ek1gt1-hRC214p6soZq1-O-QoPW0-Q-hfGw@mail.gmail.com>

Hello, Andre,

Your logs say:
> winbindd: Exceeding 500 client connections, no idle connection found

So In addition to Francesco's suggestion, you can try to increase the
"winbind max clients" parameter in your smb.conf

Your squid.conf record:
auth_param ntlm children 500 startup=5 idle=1
limits the number of ntlm-helpers, but in the SMP squid configuration this
value is multiplied by the number of workers (although I did not notice the
activation of multiprocessing support in your squid configuration).

Kind regards,
     Andrey





??, 24 ???. 2024??. ? 21:57, Francesco Chemolli <gkinkie at gmail.com>:

> Hi Andre,
>
> The chain of services here is:
>
> browser <-> squid <-> ntlm_auth <-> winbindd <-> active directory
>
> In order to bisect the problem, could you try using `wbinfo -a` on one
> of the affected machiens to authenticate against Active Directory and
> see if the performance is on the winbindd <-> AD side of the equation
> on on the squid <-> ntlm_auth side?
>
> On Wed, Jul 24, 2024 at 7:27?PM Andre Bolinhas
> <andre.bolinhas at articatech.com> wrote:
> >
> > Hi Team.
> >
> > I'm using SQUID 5.9 + windbindd 4.9.5, the authentication method is NTLM.
> >
> > Every day, around 5pm, the internet speed becomes very slow, with users
> reporting that websites takes too long to open.
> >
> > Also, the time that the issue occur is very strange, since is when most
> of the users are not in the office anymore
> >
> > By doing a deep analyze on Proxy server, I manage to find this error
> that could be related with this issue.
> >
> > Cache.log
> > GENSEC login failed: NT_STATUS_LOGON_FAILURE
> > GENSEC login failed: NT_STATUS_LOGON_FAILURE
> > GENSEC login failed: NT_STATUS_LOGON_FAILURE
> > GENSEC login failed: NT_STATUS_LOGON_FAILURE
> >
> > Windbindd.log
> > [2024/07/22 17:06:48.220216,  2]
> ../source3/winbindd/winbindd.c:1121(remove_client)
> >   final write to client failed: Broken pipe
> > [2024/07/22 17:06:48.220319,  0]
> ../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
> >   winbindd: Exceeding 500 client connections, no idle connection found
> > [2024/07/22 17:06:48.261482,  0]
> ../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
> >   winbindd: Exceeding 500 client connections, no idle connection found
> > [2024/07/22 17:06:48.261857,  2]
> ../source3/winbindd/winbindd.c:1121(remove_client)
> >   final write to client failed: Broken pipe
> > [2024/07/22 17:06:48.261926,  0]
> ../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
> >   winbindd: Exceeding 500 client connections, no idle connection found
> > [2024/07/22 17:06:48.276216,  0]
> ../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
> >   winbindd: Exceeding 500 client connections, no idle connection found
> > [2024/07/22 17:06:48.276507,  2]
> ../source3/winbindd/winbindd.c:1121(remove_client)
> >   final write to client failed: Broken pipe
> > [2024/07/22 17:06:48.276568,  0]
> ../source3/winbindd/winbindd.c:1246(winbindd_listen_fde_handler)
> >   winbindd: Exceeding 500 client connections, no idle connection found
> > [2024/07/22 17:09:02.512093,  1]
> ../source4/lib/messaging/messaging.c:83(ping_message)
> >   INFO: Received PING message from server 10301 []
> > [2024/07/22 17:09:02.512159,  1]
> ../source3/lib/messages.c:131(ping_message)
> >   INFO: Received PING message from PID 10301 []
> > [2024/07/22 17:11:27.979681,  1]
> ../source3/winbindd/winbindd_util.c:440(trustdom_list_done)
> >   trustdom_list_done: Could not receive trusts for domain BANK
> > [2024/07/22 17:11:27.979756,  1]
> ../source3/winbindd/winbindd_util.c:440(trustdom_list_done)
> >   trustdom_list_done: Could not receive trusts for domain HLGROUP
> > [2024/07/22 17:12:02.612725,  1]
> ../source4/lib/messaging/messaging.c:83(ping_message)
> >   INFO: Received PING message from server 4706 []
> > [2024/07/22 17:12:02.612794,  1]
> ../source3/lib/messages.c:131(ping_message)
> >   INFO: Received PING message from PID 4706 []
> > [2024/07/22 17:15:03.307322,  1]
> ../source4/lib/messaging/messaging.c:83(ping_message)
> >   INFO: Received PING message from server 13541 []
> > [2024/07/22 17:15:03.307477,  1]
> ../source3/lib/messages.c:131(ping_message)
> >   INFO: Received PING message from PID 13541 []
> > [2024/07/22 17:18:02.603927,  1]
> ../source4/lib/messaging/messaging.c:83(ping_message)
> >   INFO: Received PING message from server 27640 []
> > [2024/07/22 17:18:02.603983,  1]
> ../source3/lib/messages.c:131(ping_message)
> >   INFO: Received PING message from PID 27640 []
> >
> > smb.conf
> > [global]
> >    netbios name               = ASP02
> >    log level                  = 2
> >    workgroup                  = mydom
> >    kerberos method            = dedicated keytab
> >    dedicated keytab file      = /etc/krb5.keytab
> >    realm                      = mydom.MY
> >    password server            = 10.150.1.62
> >    security                   = ads
> >    winbind enum groups        = No
> >    winbind enum users         = No
> >    idmap config * : backend   = tdb
> >    idmap config * : range     = 3000-7999
> >    idmap config mydom:backend = ad
> >    idmap config mydom:schema_mode = rfc2307
> >    idmap config mydom:range = 10000-999999
> >    idmap config mydom:unix_nss_info = yes
> > tls enabled = yes
> > ldap ssl = start tls
> > tls keyfile  = tls/key.pem
> > tls certfile = tls/cert.pem
> > tls cafile   = tls/ca.pem
> > client ldap sasl wrapping = plain
> >    client ntlmv2 auth         = Yes
> >    client lanman auth         = No
> >    client ldap sasl wrapping  = sign
> >    winbind normalize names    = No
> >    winbind separator          = /
> >    winbind use default domain = yes
> >    winbind nested groups      = Yes
> >    winbind reconnect delay    = 30
> >    winbind offline logon      = true
> >    winbind cache time         = 1800
> >    winbind refresh tickets    = true
> >    winbind refresh tickets    = true
> >    winbind max clients        = 500
> >    allow trusted domains      = Yes
> >    server signing             = auto
> >    client signing             = auto
> >    lm announce                = No
> >    ntlm auth                  = No
> >    lanman auth                = No
> >    preferred master           = No
> >    local master               = No
> >    wins support               = No
> >    encrypt passwords          = yes
> >    printing                   = bsd
> >    load printers              = no
> >    socket options             = TCP_NODELAY SO_RCVBUF=8192 SO_SNDBUF=8192
> >    min protocol               = SMB2
> >    client min protocol          = SMB2
> >    client max protocol          = SMB3
> >    load printers              = no
> >    printing                   = bsd
> >    printcap name              = /dev/null
> >    disable spoolss            = yes
> >
> > Squid.conf
> >
> > # kerberos_conf() LockActiveDirectoryToKerberos = 0
> >
> > #
> > #KerbAuthMethod = 0/1 and NOT_NTLM = False
> > auth_param ntlm program /usr/bin/ntlm_auth  --domain=mydom.MY
> --helper-protocol=squid-2.5-ntlmssp
> > auth_param ntlm children 500 startup=5 idle=1 concurrency=0
> queue-size=2000 on-persistent-overload=ERR
> > auth_param ntlm keep_alive off
> >
> > #
> > # ads groups OK
> > #Other settings
> > auth_param basic credentialsttl 7200 seconds
> > authenticate_ttl 3600 seconds
> > authenticate_ip_ttl 1 seconds
> > authenticate_cache_garbage_interval 3600 seconds
> >
> > acl authFailed src all
> > acl AUTHENTICATED proxy_auth REQUIRED
> > # END NTLM Parameters --------------------------------
> > # Basic authentication for other browser that did not supports NTLM
> > auth_param basic program /usr/bin/ntlm_auth
> --helper-protocol=squid-2.5-basic
> > auth_param basic children 60 startup=2 idle=1
> > auth_param basic realm Active Directory Basic Identification
> > auth_param basic credentialsttl 7200 seconds
> > authenticate_ttl 3600 seconds
> > authenticate_ip_ttl 1 seconds
> > authenticate_cache_garbage_interval 3600 seconds
> >
> > # ldap_auth_ad() EnableAdLDAPAuth = 0 - SKIP
> >
> > # ads groups OK
> >
> >
> >
> > # --------------------------------------------------
> >
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > https://lists.squid-cache.org/listinfo/squid-users
>
>
>
> --
>     Francesco
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240725/828c1bb7/attachment.htm>

From stu.lists at spacehopper.org  Thu Jul 25 11:23:35 2024
From: stu.lists at spacehopper.org (Stuart Henderson)
Date: Thu, 25 Jul 2024 11:23:35 -0000 (UTC)
Subject: [squid-users] SQUID - WINDBIND - very slow internet speed
References: <11060a91-e9b8-4755-8e60-fe9bdbce2032@articatech.com>
Message-ID: <slrnva4ddn.h8a.stu.lists@naiad.spacehopper.org>

On 2024-07-23, Andre Bolinhas <andre.bolinhas at articatech.com> wrote:
> I'm using SQUID 5.9 + windbindd 4.9.5, the authentication method is NTLM.
>
> Every day, around 5pm, the internet speed becomes very slow, with users 
> reporting that websites takes too long to open.
>
> Also, the time that the issue occur is very strange, since is when most 
> of the users are not in the office anymore

Around 5pm sounds like a time when DCs may be busier than usual handling
logouts.




From rousskov at measurement-factory.com  Thu Jul 25 13:28:11 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 25 Jul 2024 09:28:11 -0400
Subject: [squid-users] SQUID - WINDBIND - very slow internet speed
In-Reply-To: <11060a91-e9b8-4755-8e60-fe9bdbce2032@articatech.com>
References: <11060a91-e9b8-4755-8e60-fe9bdbce2032@articatech.com>
Message-ID: <af458748-9072-428a-bbf4-9154cd8efacb@measurement-factory.com>

On 2024-07-23 19:20, Andre Bolinhas wrote:
> winbindd: Exceeding 500 client connections, no idle connection found

> auth_param ntlm children 500 ...

I know virtually nothing about WINDBIND and the authentication helper 
you are using, but configuring Squid to have 500 helper processes is 
usually a mistake, even with a single Squid worker. YMMV, but I would 
try to use a lot fewer helpers (e.g., 10) and increase that number only 
if such an increase actually improves things.

If possible, use a helper that supports concurrent requests.

If your Squid is not competing for resources with other applications on 
the server, then I also recommend keeping a _constant_ number of helper 
processes (instead of asking Squid to start many new helper processes at 
the worse possible time -- when the load on Squid increases). To do 
that, make startup and idle parameters the same as the maximum number of 
children.


HTH,

Alex.
P.S. The credit for highlighting the correlation between winbindd errors 
and "auth_param ntlm children 500" goes to Andrey K.



From andre.bolinhas at articatech.com  Thu Jul 25 14:43:18 2024
From: andre.bolinhas at articatech.com (Andre Bolinhas)
Date: Thu, 25 Jul 2024 15:43:18 +0100
Subject: [squid-users] SQUID - WINDBIND - very slow internet speed
In-Reply-To: <af458748-9072-428a-bbf4-9154cd8efacb@measurement-factory.com>
References: <11060a91-e9b8-4755-8e60-fe9bdbce2032@articatech.com>
 <af458748-9072-428a-bbf4-9154cd8efacb@measurement-factory.com>
Message-ID: <7502b74f-6d43-428d-8686-ec0ff5973eed@articatech.com>

Hi
We have 5 squid workers, we need to handle around 8k concurrent users.

Based on this, what's the auth_param values that you recommend for 
children, idle and startup?
How to know if the helper supports concurrent requests?

> winbindd: Exceeding 500 client connections, no idle connection found 
I will increase this value to check if help to settle the issue


On 25/07/2024 14:28, Alex Rousskov wrote:
> On 2024-07-23 19:20, Andre Bolinhas wrote:
>> winbindd: Exceeding 500 client connections, no idle connection found
>
>> auth_param ntlm children 500 ...
>
> I know virtually nothing about WINDBIND and the authentication helper 
> you are using, but configuring Squid to have 500 helper processes is 
> usually a mistake, even with a single Squid worker. YMMV, but I would 
> try to use a lot fewer helpers (e.g., 10) and increase that number 
> only if such an increase actually improves things.
>
> If possible, use a helper that supports concurrent requests.
>
> If your Squid is not competing for resources with other applications 
> on the server, then I also recommend keeping a _constant_ number of 
> helper processes (instead of asking Squid to start many new helper 
> processes at the worse possible time -- when the load on Squid 
> increases). To do that, make startup and idle parameters the same as 
> the maximum number of children.
>
>
> HTH,
>
> Alex.
> P.S. The credit for highlighting the correlation between winbindd 
> errors and "auth_param ntlm children 500" goes to Andrey K.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240725/b29f44e1/attachment.htm>

From ankor2023 at gmail.com  Fri Jul 26 07:23:46 2024
From: ankor2023 at gmail.com (Andrey K)
Date: Fri, 26 Jul 2024 10:23:46 +0300
Subject: [squid-users] SQUID - WINDBIND - very slow internet speed
In-Reply-To: <7502b74f-6d43-428d-8686-ec0ff5973eed@articatech.com>
References: <11060a91-e9b8-4755-8e60-fe9bdbce2032@articatech.com>
 <af458748-9072-428a-bbf4-9154cd8efacb@measurement-factory.com>
 <7502b74f-6d43-428d-8686-ec0ff5973eed@articatech.com>
Message-ID: <CADJd0Y1TSef2+FSF7+5zsDABVAXfkWQ+Skc5uhA8Qkq6RwfM+w@mail.gmail.com>

Hello, Andre,


> How to know if the helper supports concurrent requests?
You are using /usr/bin/ntlm_auth, and, as far as I know, it does not
support concurrency. But I do not know other ntlm-authentication helpers.

> winbindd: Exceeding 500 client connections, no idle connection found
> I will increase this value to check if help to settle the issue
I think it will only hide the problem.
In my opinion, it is better to follow the Alex's advice and reduce the
number of ntlm-helpers. It should prevent exceeding the maximum winbind
client connections error messages.
The actual number of required ntlm-helpers can be obtained during the
working day.
ps -ef | grep ntlm_auth | grep -v wrapper | grep -v basic | wc -l
You can divide this number by the number of workers and add some spare ones.

When the problem appears again, you can follow the advice of Francesco:
> In order to bisect the problem, could you try using `wbinfo -a` on one
> of the affected machiens to authenticate against Active Directory and
>see if the performance is on the winbindd <-> AD side of the equation
> on on the squid <-> ntlm_auth side?
sudo wbinfo -t
sudo wbinfo -a "DOMAIN\username%password"
Kind regards,
Ankor.




??, 25 ???. 2024??. ? 17:43, Andre Bolinhas <andre.bolinhas at articatech.com>:

> Hi
> We have 5 squid workers, we need to handle around 8k concurrent users.
>
> Based on this, what's the auth_param values that you recommend for
> children, idle and startup?
> How to know if the helper supports concurrent requests?
>
> winbindd: Exceeding 500 client connections, no idle connection found
>
> I will increase this value to check if help to settle the issue
>
>
> On 25/07/2024 14:28, Alex Rousskov wrote:
>
> On 2024-07-23 19:20, Andre Bolinhas wrote:
>
> winbindd: Exceeding 500 client connections, no idle connection found
>
>
> auth_param ntlm children 500 ...
>
>
> I know virtually nothing about WINDBIND and the authentication helper you
> are using, but configuring Squid to have 500 helper processes is usually a
> mistake, even with a single Squid worker. YMMV, but I would try to use a
> lot fewer helpers (e.g., 10) and increase that number only if such an
> increase actually improves things.
>
> If possible, use a helper that supports concurrent requests.
>
> If your Squid is not competing for resources with other applications on
> the server, then I also recommend keeping a _constant_ number of helper
> processes (instead of asking Squid to start many new helper processes at
> the worse possible time -- when the load on Squid increases). To do that,
> make startup and idle parameters the same as the maximum number of
> children.
>
>
> HTH,
>
> Alex.
> P.S. The credit for highlighting the correlation between winbindd errors
> and "auth_param ntlm children 500" goes to Andrey K.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240726/f414352b/attachment.htm>

From gkinkie at gmail.com  Fri Jul 26 07:31:26 2024
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Fri, 26 Jul 2024 08:31:26 +0100
Subject: [squid-users] SQUID - WINDBIND - very slow internet speed
In-Reply-To: <CADJd0Y1TSef2+FSF7+5zsDABVAXfkWQ+Skc5uhA8Qkq6RwfM+w@mail.gmail.com>
References: <11060a91-e9b8-4755-8e60-fe9bdbce2032@articatech.com>
 <af458748-9072-428a-bbf4-9154cd8efacb@measurement-factory.com>
 <7502b74f-6d43-428d-8686-ec0ff5973eed@articatech.com>
 <CADJd0Y1TSef2+FSF7+5zsDABVAXfkWQ+Skc5uhA8Qkq6RwfM+w@mail.gmail.com>
Message-ID: <CA+Y8hcPRmy-r0Qi4jfBsTvJK1zdYMzV=4CO9656xROQizREQyQ@mail.gmail.com>

Have you considered
https://wiki.squid-cache.org/Features/HelperMultiplexer
?
If I remember correctly, it can start new helpers on demand up to a
configured maximum.

@mobile


On Fri, 26 Jul 2024 at 8:23?AM, Andrey K <ankor2023 at gmail.com> wrote:

> Hello, Andre,
>
>
> > How to know if the helper supports concurrent requests?
> You are using /usr/bin/ntlm_auth, and, as far as I know, it does not
> support concurrency. But I do not know other ntlm-authentication helpers.
>
> > winbindd: Exceeding 500 client connections, no idle connection found
> > I will increase this value to check if help to settle the issue
> I think it will only hide the problem.
> In my opinion, it is better to follow the Alex's advice and reduce the
> number of ntlm-helpers. It should prevent exceeding the maximum winbind
> client connections error messages.
> The actual number of required ntlm-helpers can be obtained during the
> working day.
> ps -ef | grep ntlm_auth | grep -v wrapper | grep -v basic | wc -l
> You can divide this number by the number of workers and add some spare
> ones.
>
> When the problem appears again, you can follow the advice of Francesco:
> > In order to bisect the problem, could you try using `wbinfo -a` on one
> > of the affected machiens to authenticate against Active Directory and
> >see if the performance is on the winbindd <-> AD side of the equation
> > on on the squid <-> ntlm_auth side?
> sudo wbinfo -t
> sudo wbinfo -a "DOMAIN\username%password"
> Kind regards,
> Ankor.
>
>
>
>
> ??, 25 ???. 2024??. ? 17:43, Andre Bolinhas <andre.bolinhas at articatech.com
> >:
>
>> Hi
>> We have 5 squid workers, we need to handle around 8k concurrent users.
>>
>> Based on this, what's the auth_param values that you recommend for
>> children, idle and startup?
>> How to know if the helper supports concurrent requests?
>>
>> winbindd: Exceeding 500 client connections, no idle connection found
>>
>> I will increase this value to check if help to settle the issue
>>
>>
>> On 25/07/2024 14:28, Alex Rousskov wrote:
>>
>> On 2024-07-23 19:20, Andre Bolinhas wrote:
>>
>> winbindd: Exceeding 500 client connections, no idle connection found
>>
>>
>> auth_param ntlm children 500 ...
>>
>>
>> I know virtually nothing about WINDBIND and the authentication helper you
>> are using, but configuring Squid to have 500 helper processes is usually a
>> mistake, even with a single Squid worker. YMMV, but I would try to use a
>> lot fewer helpers (e.g., 10) and increase that number only if such an
>> increase actually improves things.
>>
>> If possible, use a helper that supports concurrent requests.
>>
>> If your Squid is not competing for resources with other applications on
>> the server, then I also recommend keeping a _constant_ number of helper
>> processes (instead of asking Squid to start many new helper processes at
>> the worse possible time -- when the load on Squid increases). To do that,
>> make startup and idle parameters the same as the maximum number of
>> children.
>>
>>
>> HTH,
>>
>> Alex.
>> P.S. The credit for highlighting the correlation between winbindd errors
>> and "auth_param ntlm children 500" goes to Andrey K.
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240726/ab55c00a/attachment.htm>

From rousskov at measurement-factory.com  Fri Jul 26 14:03:52 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 26 Jul 2024 10:03:52 -0400
Subject: [squid-users] SQUID - WINDBIND - very slow internet speed
In-Reply-To: <CADJd0Y1TSef2+FSF7+5zsDABVAXfkWQ+Skc5uhA8Qkq6RwfM+w@mail.gmail.com>
References: <11060a91-e9b8-4755-8e60-fe9bdbce2032@articatech.com>
 <af458748-9072-428a-bbf4-9154cd8efacb@measurement-factory.com>
 <7502b74f-6d43-428d-8686-ec0ff5973eed@articatech.com>
 <CADJd0Y1TSef2+FSF7+5zsDABVAXfkWQ+Skc5uhA8Qkq6RwfM+w@mail.gmail.com>
Message-ID: <cfe278e7-7165-4fb2-bb89-ee7f1f776ec4@measurement-factory.com>

On 2024-07-26, Andre wrote:

> How to know if the helper supports concurrent requests?

Good question! You need to consult helper documentation. If that does 
not exist or does not document concurrency, one can analyze helper 
source code and/or test concurrency support, but those two activities 
require specialized skills. Testing is especially difficult because a 
helper may not violently/visibly reject "concurrent" protocol messages: 
Many helpers were written under the false assumption that they will 
never receive invalid traffic.

Asking here (and then improving helper documentation!) may be the best 
option.


HTH,

Alex.


> ??, 25 ???. 2024??. ? 17:43, Andre Bolinhas 
> <andre.bolinhas at articatech.com <mailto:andre.bolinhas at articatech.com>>:
> 
>     __
> 
>     Hi
>     We have 5 squid workers, we need to handle around 8k concurrent users.
> 
>     Based on this, what's the auth_param values that you recommend for
>     children, idle and startup?
>     How to know if the helper supports concurrent requests?
> 
>>     winbindd: Exceeding 500 client connections, no idle connection found 
>     I will increase this value to check if help to settle the issue
> 
> 
>     On 25/07/2024 14:28, Alex Rousskov wrote:
>>     On 2024-07-23 19:20, Andre Bolinhas wrote:
>>>     winbindd: Exceeding 500 client connections, no idle connection found
>>
>>>     auth_param ntlm children 500 ...
>>
>>     I know virtually nothing about WINDBIND and the authentication
>>     helper you are using, but configuring Squid to have 500 helper
>>     processes is usually a mistake, even with a single Squid worker.
>>     YMMV, but I would try to use a lot fewer helpers (e.g., 10) and
>>     increase that number only if such an increase actually improves
>>     things.
>>
>>     If possible, use a helper that supports concurrent requests.
>>
>>     If your Squid is not competing for resources with other
>>     applications on the server, then I also recommend keeping a
>>     _constant_ number of helper processes (instead of asking Squid to
>>     start many new helper processes at the worse possible time -- when
>>     the load on Squid increases). To do that, make startup and idle
>>     parameters the same as the maximum number of children.
>>
>>
>>     HTH,
>>
>>     Alex.
>>     P.S. The credit for highlighting the correlation between winbindd
>>     errors and "auth_param ntlm children 500" goes to Andrey K.
>>
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org>
>>     https://lists.squid-cache.org/listinfo/squid-users
>>     <https://lists.squid-cache.org/listinfo/squid-users>
>     ____ 
> 



From rousskov at measurement-factory.com  Fri Jul 26 14:11:20 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 26 Jul 2024 10:11:20 -0400
Subject: [squid-users] SQUID - WINDBIND - very slow internet speed
In-Reply-To: <CA+Y8hcPRmy-r0Qi4jfBsTvJK1zdYMzV=4CO9656xROQizREQyQ@mail.gmail.com>
References: <11060a91-e9b8-4755-8e60-fe9bdbce2032@articatech.com>
 <af458748-9072-428a-bbf4-9154cd8efacb@measurement-factory.com>
 <7502b74f-6d43-428d-8686-ec0ff5973eed@articatech.com>
 <CADJd0Y1TSef2+FSF7+5zsDABVAXfkWQ+Skc5uhA8Qkq6RwfM+w@mail.gmail.com>
 <CA+Y8hcPRmy-r0Qi4jfBsTvJK1zdYMzV=4CO9656xROQizREQyQ@mail.gmail.com>
Message-ID: <0fcd78b5-e59b-46be-9f12-34eb367b62e9@measurement-factory.com>

On 2024-07-26 03:31, Francesco Chemolli wrote:
> Have you considered
> https://wiki.squid-cache.org/Features/HelperMultiplexer 

Just in case you do not know how to find the actual helper program 
described on the above page, it is installed as libexec/helper-mux. That 
helper has a manual page.


HTH,

Alex.

> On Fri, 26 Jul 2024 at 8:23?AM, Andrey K wrote:
> 
>     Hello, Andre,
> 
> 
>      > How to know if the helper supports concurrent requests?
>     You are using /usr/bin/ntlm_auth, and, as far as I know, it does not
>     support concurrency. But I do not know other ntlm-authentication
>     helpers.
> 
>      > winbindd: Exceeding 500 client connections, no idle connection found
>      > I will increase this value to check if help to settle the issue
>     I think it will only hide the problem.
>     In my opinion, it is betterto followthe Alex's adviceandreducethe
>     numberof ntlm-helpers. It should prevent exceeding the maximum
>     winbind client connections error messages.
>     The actual number of required ntlm-helpers can be obtained during
>     the working day.
>     ps -ef | grep ntlm_auth | grep -v wrapper | grep -v basic | wc -l
>     You can divide this number by the number of workers and add some
>     spare ones.
> 
>     When the problem appears again, you can follow the advice of Francesco:
>     > In order to bisect the problem, could you try using `wbinfo -a` on one
>     > of the affected machiens to authenticate against Active Directory and
>     >see if the performance is on the winbindd <-> AD side of the equation
>     > on on the squid <-> ntlm_auth side?
>     sudo wbinfo -t
>     sudo wbinfo -a "DOMAIN\username%password"
>     Kind regards,
>     Ankor.
> 
> 
> 
> 
>     ??, 25 ???. 2024??. ? 17:43, Andre Bolinhas
>     <andre.bolinhas at articatech.com <mailto:andre.bolinhas at articatech.com>>:
> 
>         __
> 
>         Hi
>         We have 5 squid workers, we need to handle around 8k concurrent
>         users.
> 
>         Based on this, what's the auth_param values that you recommend
>         for children, idle and startup?
>         How to know if the helper supports concurrent requests?
> 
>>         winbindd: Exceeding 500 client connections, no idle connection
>>         found 
>         I will increase this value to check if help to settle the issue
> 
> 
>         On 25/07/2024 14:28, Alex Rousskov wrote:
>>         On 2024-07-23 19:20, Andre Bolinhas wrote:
>>>         winbindd: Exceeding 500 client connections, no idle
>>>         connection found
>>
>>>         auth_param ntlm children 500 ...
>>
>>         I know virtually nothing about WINDBIND and the authentication
>>         helper you are using, but configuring Squid to have 500 helper
>>         processes is usually a mistake, even with a single Squid
>>         worker. YMMV, but I would try to use a lot fewer helpers
>>         (e.g., 10) and increase that number only if such an increase
>>         actually improves things.
>>
>>         If possible, use a helper that supports concurrent requests.
>>
>>         If your Squid is not competing for resources with other
>>         applications on the server, then I also recommend keeping a
>>         _constant_ number of helper processes (instead of asking Squid
>>         to start many new helper processes at the worse possible time
>>         -- when the load on Squid increases). To do that, make startup
>>         and idle parameters the same as the maximum number of children.
>>
>>
>>         HTH,
>>
>>         Alex.
>>         P.S. The credit for highlighting the correlation between
>>         winbindd errors and "auth_param ntlm children 500" goes to
>>         Andrey K.
>>
>>         _______________________________________________
>>         squid-users mailing list
>>         squid-users at lists.squid-cache.org
>>         <mailto:squid-users at lists.squid-cache.org>
>>         https://lists.squid-cache.org/listinfo/squid-users
>>         <https://lists.squid-cache.org/listinfo/squid-users>
>         ____ 
> 



From jonathanlee571 at gmail.com  Fri Jul 26 17:57:12 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 26 Jul 2024 10:57:12 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <CA+Y8hcMS0gHUx8nUBcY6pvRCvvU3=XrZmNDk9kuadCenf8JWhA@mail.gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
 <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
 <d18f0034-1f3b-4b51-9927-06aa5e7f01ca@measurement-factory.com>
 <CADJd0Y1h4wviABtDXQpCc2w1C7YQ0n9EKEh79=KYKQDFWLWtpA@mail.gmail.com>
 <781872AE-13EB-421F-BCB7-9B1E10E65BE4@gmail.com>
 <46154037-39EA-4F75-9DE5-1D538FEEFAD7@gmail.com>
 <CA+Y8hcMS0gHUx8nUBcY6pvRCvvU3=XrZmNDk9kuadCenf8JWhA@mail.gmail.com>
Message-ID: <A0333225-FE68-4A63-B517-D56C85CD85A1@gmail.com>

Shell Output - curl -u anything:REDACTED http://localhost:3128/squid-internal-mgr/menu
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100  3833  100  3833    0     0  64041      0 --:--:-- --:--:-- --:--:-- 64966
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head>
<meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>ERROR: The requested URL could not be retrieved</title>
<style type="text/css"><!--
 /*
 * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
 *
 * Squid software is distributed under GPLv2+ license and includes
 * contributions from numerous individuals and organizations.
 * Please see the COPYING and CONTRIBUTORS files for details.
 */

/*
 Stylesheet for Squid Error pages
 Adapted from design by Free CSS Templates
 http://www.freecsstemplates.org
 Released for free under a Creative Commons Attribution 2.5 License
*/

/* Page basics */
* {
	font-family: verdana, sans-serif;
}

html body {

> On Jul 24, 2024, at 14:29, Francesco Chemolli <gkinkie at gmail.com> wrote:
> 
> Hi Jonathan,
>  could you try:
> curl -u anything:redacted http://localhost:3128/squid-internal-mgr/menu
> 
> ?
> 
> On Mon, Jul 22, 2024 at 8:52?PM Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> Also I have tested
>> 
>> curl 127.0.0.1:3128/squid-internal-mgr -u :redacted
>> curl localhost:3128/squid-internal-mgr -u :redacted
>> curl hostname_here:3128/squid-internal-mgr -u :redacted (per bug notes use hostname in place of localhost)
>> 
>> and testing with no password same commands lock up the system with no response and if I do them outside of the host with a web browser I get the errors below seen they are new..
>> 
>> HTTP/1.1 Expect: feature is being asked from an HTTP/1.0 software.
>> 
>> 
>> 
>> 
>> 
>> On Jul 22, 2024, at 09:01, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> Thanks for the info
>> 
>> I tried it and this also failed. Dang
>> 
>> Shell Output - curl localhost:3128/squid-internal-mgr/info -u :redacted
>> 
>>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
>>                                 Dload  Upload   Total   Spent    Left  Speed
>> 
>>  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
>> 100  3773  100  3773    0     0  90756      0 --:--:-- --:--:-- --:--:-- 94325
>> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
>> <html><head>
>> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
>> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
>> <title>ERROR: The requested URL could not be retrieved</title>
>> <style type="text/css"><!--
>> /*
>> * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
>> *
>> * Squid software is distributed under GPLv2+ license and includes
>> * contributions from numerous individuals and organizations.
>> * Please see the COPYING and CONTRIBUTORS files for details.
>> */
>> 
>> /*
>> Stylesheet for Squid Error pages
>> Adapted from design by Free CSS Templates
>> http://www.freecsstemplates.org
>> Released for free under a Creative Commons Attribution 2.5 License
>> */
>> 
>> However I get a new error when attempting to connect over a web browser
>> 
>> ERROR
>> 
>> The requested URL could not be retrieved
>> 
>> ________________________________
>> 
>> Invalid Request error was encountered while trying to process the request:
>> 
>> GET /squid-internal-mgr HTTP/1.1
>> Host: lee_family.home.arpa:3128
>> Upgrade-Insecure-Requests: 1
>> Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
>> User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Safari/605.1.15
>> Accept-Language: en-US,en;q=0.9
>> Accept-Encoding: gzip, deflate
>> Connection: keep-alive
>> DNT: 1
>> 
>> Some possible problems are:
>> 
>> Request is too large.
>> 
>> Content-Length missing for POST or PUT requests.
>> 
>> Illegal character in hostname; underscores are not allowed.
>> 
>> HTTP/1.1 Expect: feature is being asked from an HTTP/1.0 software.
>> 
>> Your cache administrator is
>> 
>> 
>> 
>> On Jul 22, 2024, at 04:42, Andrey K <ankor2023 at gmail.com> wrote:
>> 
>> Hello, Jonathan,
>> 
>>> curl http://localhost:3128/squid-internal-mgr/info
>> 
>>> Where would I place the password?
>> 
>> I use the following configuration:
>> http_access allow localhost  manager
>> cachemgr_passwd redacted config
>> 
>> The command to read the current running config is:
>> curl localhost:3128/squid-internal-mgr/config -u :redacted
>> 
>> 
>> Kind regards,
>>      Ankor.
>> 
>> 
>> 
>> 
>> ??, 18 ???. 2024??. ? 17:07, Alex Rousskov <rousskov at measurement-factory.com>:
>>> 
>>> On 2024-07-18 00:55, Jonathan Lee wrote:
>>> 
>>>> curl http://localhost:3128/squid-internal-mgr/info
>>>> 
>>>> Where would I place the password?
>>> 
>>> See "man curl" or online manual pages for curl. They will point you to
>>> two relevant options: --user and --proxy-user. AFAICT, your particular
>>> cache manager requests are sent _to_ the proxy (as if it were an origin
>>> server) rather than _through_ the proxy. Thus, you should use --user.
>>> 
>>> As I keep saying on this thread, due to Squid complications related to
>>> Bug 5283, specifying seemingly correct client parameters may not be
>>> enough to convince Squid to accept the cache manager request. I
>>> recommend the following procedure:
>>> 
>>> 1. List the corresponding http_port directive first, before any other
>>> http_port, https_port, and ftp_port directives. Do not use interception
>>> of any kind for this cache manager port.
>>> 
>>> 2. Use curl with absolute squid-internal-mgr URLs with http scheme (like
>>> you show above). Do _not_ use "curl --proxy" or similar. Do not use
>>> https scheme.
>>> 
>>> 3. In that absolute mgr URL, use the host name that matches
>>> visible_hostname in squid.conf. If you do not have visible_hostname in
>>> squid.conf, add it. This is not required, but, due to Squid bugs, it is
>>> often much easier to get this to work with visible_hostname than without it.
>>> 
>>> 4. Make (passwordless) mgr:info use case working first, before trying to
>>> get password-protected pages working.
>>> 
>>> 5. When you do specify a username and a password, remember that you are
>>> sending this request to an (equivalent of) a service running on an
>>> origin server, _not_ a proxy (hence --user rather than --proxy-user).
>>> 
>>> 
>>> If you cannot figure it out despite carefully going through the above
>>> steps, share (privately if needed) a pointer to compressed ALL,9
>>> cache.log while reproducing the problem with throw-away credentials on
>>> an idle Squid with a single curl request. Mention which step you got
>>> stuck on.
>>> 
>>> 
>>> HTH,
>>> 
>>> Alex.
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>> 
>> 
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 
> 
> 
> -- 
>    Francesco
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240726/1ca460b5/attachment.htm>

From jonathanlee571 at gmail.com  Fri Jul 26 17:58:43 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 26 Jul 2024 10:58:43 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <CA+Y8hcMS0gHUx8nUBcY6pvRCvvU3=XrZmNDk9kuadCenf8JWhA@mail.gmail.com>
References: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
 <D6BA04C0-56A8-4E6F-B7E7-0364DC642E1C@gmail.com>
 <77A9F8B9-14D5-4414-8660-04585EF5E0D3@gmail.com>
 <c68f0650-e14c-4cef-ae1c-9e55b3c55a28@treenet.co.nz>
 <922D08E6-BDC7-42C2-9A54-AAF06ABCE780@gmail.com>
 <EA649532-7655-40CF-BDF3-EFA4F8078EEC@gmail.com>
 <d18f0034-1f3b-4b51-9927-06aa5e7f01ca@measurement-factory.com>
 <CADJd0Y1h4wviABtDXQpCc2w1C7YQ0n9EKEh79=KYKQDFWLWtpA@mail.gmail.com>
 <781872AE-13EB-421F-BCB7-9B1E10E65BE4@gmail.com>
 <46154037-39EA-4F75-9DE5-1D538FEEFAD7@gmail.com>
 <CA+Y8hcMS0gHUx8nUBcY6pvRCvvU3=XrZmNDk9kuadCenf8JWhA@mail.gmail.com>
Message-ID: <3D9B6630-9E6F-4075-8977-D6058E42A164@gmail.com>

Shows a miss 403 in the cache logs for it 
-	-
26.07.2024 10:57:01	192.168.1.5	NONE_NONE_ABORTED/200	dc1.ksn.kaspersky-labs.com:443	-	-
26.07.2024 10:56:48	127.0.0.1	TCP_MISS/403	http://localhost:3128/squid-internal-mgr/menu	-	127.0.0.1
26.07.2024 10:56:48	127.0.0.1	TCP_MISS/403	http://localhost:3128/squid-internal-mgr/menu	-	-
26.07.2024 10:56:45	192.168.1.5	NONE_NONE/200	gdmf.apple.com:443	-	-
26.07.2024 10:56:44	192.168.1.5	TCP_TUNNEL/200	configuration.apple.com:443	-	104.107.104.29
26.07.2024 10:56:16	192.168.1.5	TCP_REDIRECT/301	token.safebrowsing.apple:443


> On Jul 24, 2024, at 14:29, Francesco Chemolli <gkinkie at gmail.com> wrote:
> 
> Hi Jonathan,
>  could you try:
> curl -u anything:redacted http://localhost:3128/squid-internal-mgr/menu
> 
> ?
> 
> On Mon, Jul 22, 2024 at 8:52?PM Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> Also I have tested
>> 
>> curl 127.0.0.1:3128/squid-internal-mgr -u :redacted
>> curl localhost:3128/squid-internal-mgr -u :redacted
>> curl hostname_here:3128/squid-internal-mgr -u :redacted (per bug notes use hostname in place of localhost)
>> 
>> and testing with no password same commands lock up the system with no response and if I do them outside of the host with a web browser I get the errors below seen they are new..
>> 
>> HTTP/1.1 Expect: feature is being asked from an HTTP/1.0 software.
>> 
>> 
>> 
>> 
>> 
>> On Jul 22, 2024, at 09:01, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> Thanks for the info
>> 
>> I tried it and this also failed. Dang
>> 
>> Shell Output - curl localhost:3128/squid-internal-mgr/info -u :redacted
>> 
>>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
>>                                 Dload  Upload   Total   Spent    Left  Speed
>> 
>>  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
>> 100  3773  100  3773    0     0  90756      0 --:--:-- --:--:-- --:--:-- 94325
>> <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
>> <html><head>
>> <meta type="copyright" content="Copyright (C) 1996-2023 The Squid Software Foundation and contributors">
>> <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
>> <title>ERROR: The requested URL could not be retrieved</title>
>> <style type="text/css"><!--
>> /*
>> * Copyright (C) 1996-2023 The Squid Software Foundation and contributors
>> *
>> * Squid software is distributed under GPLv2+ license and includes
>> * contributions from numerous individuals and organizations.
>> * Please see the COPYING and CONTRIBUTORS files for details.
>> */
>> 
>> /*
>> Stylesheet for Squid Error pages
>> Adapted from design by Free CSS Templates
>> http://www.freecsstemplates.org
>> Released for free under a Creative Commons Attribution 2.5 License
>> */
>> 
>> However I get a new error when attempting to connect over a web browser
>> 
>> ERROR
>> 
>> The requested URL could not be retrieved
>> 
>> ________________________________
>> 
>> Invalid Request error was encountered while trying to process the request:
>> 
>> GET /squid-internal-mgr HTTP/1.1
>> Host: lee_family.home.arpa:3128
>> Upgrade-Insecure-Requests: 1
>> Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
>> User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Safari/605.1.15
>> Accept-Language: en-US,en;q=0.9
>> Accept-Encoding: gzip, deflate
>> Connection: keep-alive
>> DNT: 1
>> 
>> Some possible problems are:
>> 
>> Request is too large.
>> 
>> Content-Length missing for POST or PUT requests.
>> 
>> Illegal character in hostname; underscores are not allowed.
>> 
>> HTTP/1.1 Expect: feature is being asked from an HTTP/1.0 software.
>> 
>> Your cache administrator is
>> 
>> 
>> 
>> On Jul 22, 2024, at 04:42, Andrey K <ankor2023 at gmail.com> wrote:
>> 
>> Hello, Jonathan,
>> 
>>> curl http://localhost:3128/squid-internal-mgr/info
>> 
>>> Where would I place the password?
>> 
>> I use the following configuration:
>> http_access allow localhost  manager
>> cachemgr_passwd redacted config
>> 
>> The command to read the current running config is:
>> curl localhost:3128/squid-internal-mgr/config -u :redacted
>> 
>> 
>> Kind regards,
>>      Ankor.
>> 
>> 
>> 
>> 
>> ??, 18 ???. 2024??. ? 17:07, Alex Rousskov <rousskov at measurement-factory.com>:
>>> 
>>> On 2024-07-18 00:55, Jonathan Lee wrote:
>>> 
>>>> curl http://localhost:3128/squid-internal-mgr/info
>>>> 
>>>> Where would I place the password?
>>> 
>>> See "man curl" or online manual pages for curl. They will point you to
>>> two relevant options: --user and --proxy-user. AFAICT, your particular
>>> cache manager requests are sent _to_ the proxy (as if it were an origin
>>> server) rather than _through_ the proxy. Thus, you should use --user.
>>> 
>>> As I keep saying on this thread, due to Squid complications related to
>>> Bug 5283, specifying seemingly correct client parameters may not be
>>> enough to convince Squid to accept the cache manager request. I
>>> recommend the following procedure:
>>> 
>>> 1. List the corresponding http_port directive first, before any other
>>> http_port, https_port, and ftp_port directives. Do not use interception
>>> of any kind for this cache manager port.
>>> 
>>> 2. Use curl with absolute squid-internal-mgr URLs with http scheme (like
>>> you show above). Do _not_ use "curl --proxy" or similar. Do not use
>>> https scheme.
>>> 
>>> 3. In that absolute mgr URL, use the host name that matches
>>> visible_hostname in squid.conf. If you do not have visible_hostname in
>>> squid.conf, add it. This is not required, but, due to Squid bugs, it is
>>> often much easier to get this to work with visible_hostname than without it.
>>> 
>>> 4. Make (passwordless) mgr:info use case working first, before trying to
>>> get password-protected pages working.
>>> 
>>> 5. When you do specify a username and a password, remember that you are
>>> sending this request to an (equivalent of) a service running on an
>>> origin server, _not_ a proxy (hence --user rather than --proxy-user).
>>> 
>>> 
>>> If you cannot figure it out despite carefully going through the above
>>> steps, share (privately if needed) a pointer to compressed ALL,9
>>> cache.log while reproducing the problem with throw-away credentials on
>>> an idle Squid with a single curl request. Mention which step you got
>>> stuck on.
>>> 
>>> 
>>> HTH,
>>> 
>>> Alex.
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>> 
>> 
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 
> 
> 
> -- 
>    Francesco
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240726/3816f0c3/attachment.htm>

From jonathanlee571 at gmail.com  Fri Jul 26 22:10:07 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 26 Jul 2024 15:10:07 -0700
Subject: [squid-users] Squid with PV6 Tunnel Broker
Message-ID: <133EDD52-1701-45C9-A50E-8AE700929A96@gmail.com>

Hello fellow squid users can you please help me??

I know I have good IPV6 internet if I use the IPV4 proxy address, and the IPv6 test sites pass 10 out of 10. If I make the client IPV6 only and have the rules set to use the proxy with the proxy IPV6 address for the proxy I get no internet. 

I am using a IPV6 tunnel broker in pfsense. When I configure my client to IPv6 only it can access all IPv6 sites. As soon as I use the proxy address in IPv6 of Squid squid gives me the following errors...

Squid - Cache Logs
Date-Time	Message
26.07.2024 15:07:12	ERROR: failure while accepting a TLS connection on conn26864 local=192.168.1.1:3128 remote=192.168.1.14:52687 FD 452 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000415+TLS_IO_ERR=1
31.12.1969 16:00:00	
26.07.2024 15:07:10	kick abandoning conn26863 local=[2001:470:8052:192::]:3128 remote=[2001:470:8052:192:898d:9911:720b:5bdd]:54252 FD 451 flags=33
31.12.1969 16:00:00	
26.07.2024 15:07:10	SECURITY ALERT: on URL: www.bing.com:443
31.12.1969 16:00:00	
26.07.2024 15:07:10	SECURITY ALERT: By user agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36 Edg/127.0.0.0
31.12.1969 16:00:00	
26.07.2024 15:07:10	SECURITY ALERT: Host header forgery detected on conn26863 local=[2001:470:8052:192::]:3128 remote=[2001:470:8052:192:898d:9911:720b:5bdd]:54252 FD 451 flags=33 (intercepted port does not match 443)

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240726/63061fd4/attachment.htm>

From jonathanlee571 at gmail.com  Sat Jul 27 14:06:14 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sat, 27 Jul 2024 07:06:14 -0700
Subject: [squid-users] Squid with PV6 Tunnel Broker
In-Reply-To: <133EDD52-1701-45C9-A50E-8AE700929A96@gmail.com>
References: <133EDD52-1701-45C9-A50E-8AE700929A96@gmail.com>
Message-ID: <1D1E1A48-903E-494F-BC08-731D119FB9A5@gmail.com>

Do I need to add ::1 as a http port? for transparent I can?t get anything to work I sees the attempts with ipv6 pure mode however nothing connects..

[2001:470:8052:192::]:3128 is my proxy 

I can?t get any connections from ipv6 only hosts.

I can get ipv4 all day and they can access ipv6 sites just not the other way around 

It is currently set as 

http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

http_port [2001:470:8052:192::]:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

https_port [2001:470:8052:192::]:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3


so should it include??

http_port [::1]:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

https_port [::1]:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3




> On Jul 26, 2024, at 15:10, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Hello fellow squid users can you please help me??
> 
> I know I have good IPV6 internet if I use the IPV4 proxy address, and the IPv6 test sites pass 10 out of 10. If I make the client IPV6 only and have the rules set to use the proxy with the proxy IPV6 address for the proxy I get no internet. 
> 
> I am using a IPV6 tunnel broker in pfsense. When I configure my client to IPv6 only it can access all IPv6 sites. As soon as I use the proxy address in IPv6 of Squid squid gives me the following errors...
> 
> Squid - Cache Logs
> Date-Time	Message
> 26.07.2024 15:07:12	ERROR: failure while accepting a TLS connection on conn26864 local=192.168.1.1:3128 remote=192.168.1.14:52687 FD 452 flags=1: SQUID_TLS_ERR_ACCEPT+TLS_LIB_ERR=A000415+TLS_IO_ERR=1
> 31.12.1969 16:00:00	
> 26.07.2024 15:07:10	kick abandoning conn26863 local=[2001:470:8052:192::]:3128 remote=[2001:470:8052:192:898d:9911:720b:5bdd]:54252 FD 451 flags=33
> 31.12.1969 16:00:00	
> 26.07.2024 15:07:10	SECURITY ALERT: on URL: www.bing.com:443
> 31.12.1969 16:00:00	
> 26.07.2024 15:07:10	SECURITY ALERT: By user agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36 Edg/127.0.0.0
> 31.12.1969 16:00:00	
> 26.07.2024 15:07:10	SECURITY ALERT: Host header forgery detected on conn26863 local=[2001:470:8052:192::]:3128 remote=[2001:470:8052:192:898d:9911:720b:5bdd]:54252 FD 451 flags=33 (intercepted port does not match 443)
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240727/23382871/attachment.htm>

From squid3 at treenet.co.nz  Mon Jul 29 07:17:26 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 29 Jul 2024 19:17:26 +1200
Subject: [squid-users] Squid with PV6 Tunnel Broker
In-Reply-To: <133EDD52-1701-45C9-A50E-8AE700929A96@gmail.com>
References: <133EDD52-1701-45C9-A50E-8AE700929A96@gmail.com>
Message-ID: <c44d8379-4e18-4c36-af84-6c39bb053c7d@treenet.co.nz>

On 27/07/24 10:10, Jonathan Lee wrote:
> Hello fellow squid users can you please help me??
> 
> I know I have good IPV6 internet if I use the IPV4 proxy address, and 
> the IPv6 test sites pass 10 out of 10. If I make the client IPV6 only 
> and have the rules set to use the proxy with the proxy IPV6 address for 
> the proxy I get no internet.
> 
> I am using a IPV6 tunnel broker in pfsense. When I configure my client 
> to IPv6 only it can access all IPv6 sites. As soon as I use the proxy 
> address in IPv6 of Squid squid gives me the following errors...

Check that ICMPv6 is working. It is mandatory when tunnels are used.

Also, check the MSS and MTU values.


Cheers
Amos


From jonathanlee571 at gmail.com  Sun Jul 28 02:54:49 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sat, 27 Jul 2024 19:54:49 -0700
Subject: [squid-users] squidclient -h 127.0.0.1 -p 3128 mgr:info shows
 access denined
In-Reply-To: <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
References: <d3bc5490-6c94-48db-8873-41e5e4c2a3cf@treenet.co.nz>
 <EDA98A62-E57C-4F83-9174-6BC3AD943CF5@gmail.com>
 <F19657D2-D16C-4D37-8EDE-A0F7D2A5A64E@gmail.com>
 <AC4A93C3-F77B-414A-A408-39391584B388@gmail.com>
 <D97540C8-E366-4753-BB39-053208E373CB@gmail.com>
 <FDB03E03-1FEE-44A7-A427-8CC3435EFB91@gmail.com>
 <ec61944c-6420-41b7-8737-05230761eac2@treenet.co.nz>
 <3A753A42-FAEE-42F1-87D7-93EB45EF2D9E@gmail.com>
 <706d830e-f42e-4585-b5a3-79bd3fe5f831@treenet.co.nz>
 <5CEDCC1C-0840-4DD5-B45A-8DB67635E6B3@gmail.com>
 <20a104fa-ee36-499e-ad8b-5c23446d4bbe@treenet.co.nz>
Message-ID: <67CE05DB-21FD-49B3-BF66-0533B97C08C0@gmail.com>

Does this also auto solve for IPv6 connections changing it to just 

http_port 3128
https_port 3129??

> On Jul 12, 2024, at 04:57, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 12/07/24 11:50, Jonathan Lee wrote:
>>> I recommend changing your main port to this:
>>> 
>>>   http_port 3128 ssl-bump ....
>> This is set to this when it processes
>> http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
> 
> The key thing here was the removal of the IP address. So that Squid received both the 192.168.*.* and the 127.0.0.* traffic without needing separate http_port lines.
> 
> 
> 
>>> and receiving the intercepted traffic on:
>>> 
>>>  http_port 3129 intercept ssl-bump ?
>> Do you mean https?
> 
> Sorry. I missed that you had an https_port using 3129 already.
> 
> 
> 
>> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!SHA1:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3,NO_TLSv1,SINGLE_DH_USE,SINGLE_ECDH_USE
>> Https uses that port 3129
>> What should I adapt
>> http_port
>> https_port?
> 
> Both.
> 
> FYI, there are two issues:
> 
> 1) listening on IP 127.0.0.1. Inside the OS there are different devices for localhost (lo) and WAN (eg. eth0). NAT is problematic already without introducing any tricky behaviours from bridging those "private" (lo) and "public" WAN devices.
> 
> The simplest solution is just not to put any IP address on the squid.conf *port line(s) with intercept options. The OS will select one appropriate for whatever device and tell Squid on a per-connection basis.
> 
> The more difficult way is to put one of the machines "global" (WAN or LAN) IP addresses. In your case 192.168.1.1. With most connections being from the LAN that minimizes the possible problems.
> 
> 
> 2) listening on a well-known proxy port 3128 for intercepted traffic.
> 
> There is malware in existence that scans for at least port 3128 (likely 1080, 8080 etc common proxy ports) being used by proxies like yours and abuses them. As a result at least one popular antivirus network scanner (from Trend) does the same scan to detect insecure proxies.
> 
> The worst thing about this situation is that the NAT very effectively hides the malware. So it is extremely hard to see whether it is happening to you.
> 
> 
> I am not sure what UI you are using to show those firewall rules in your other email. However the one that had ALLOW for the port range 3128-3129 worries me. AFAIK that should only be for 3128 and a separate rule somewhere else to drop the intercepted port 3129 traffic pre-NAT.
> 
> 
> HTH
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240727/798e17d7/attachment.htm>

From jonathanlee571 at gmail.com  Mon Jul 29 20:47:20 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 29 Jul 2024 13:47:20 -0700
Subject: [squid-users] Squid with PV6 Tunnel Broker
In-Reply-To: <c44d8379-4e18-4c36-af84-6c39bb053c7d@treenet.co.nz>
References: <133EDD52-1701-45C9-A50E-8AE700929A96@gmail.com>
 <c44d8379-4e18-4c36-af84-6c39bb053c7d@treenet.co.nz>
Message-ID: <AC4BE9DD-0521-42BA-A0EA-6D021558CAE2@gmail.com>

I did not know that I had the option set to disable Squid ICMP pinger helper. MSS and MTU values are set to what the tunnel broker requires on the interface, can you also set the MTU inside of Squid configurations? 


I enabled ping helper I show a good socket for my IPV6 interface address but every IPV6 only device shows NONE_NONE/409 on the Squid Access Table 


I get the same result. How would I change MTU on Squid isn?t that set to auto discover with the HTTP port directive?

I also forgot to mention the IPV6 only device works when I have it set to not use the proxy. 

Thanks again for the reply. It does work from IPV4 to IPV6 requests but never for IPV6 to IPV6 addresses or pure IPV6. I can disable the proxy and the system works for IPV6 to IPV6 only. 

Here is my configuration I am testing..

# This file is automatically generated by pfSense
# Do not edit manually !

http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

http_port [REDACTED:192::]:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

https_port [REDACTED:192::]:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

icp_port 0
digest_generation off
dns_v4_first off
pid_filename /var/run/squid/squid.pid
cache_effective_user squid
cache_effective_group proxy
error_default_language en
icon_directory /usr/local/etc/squid/icons
visible_hostname lee_family.home.arpa
cache_mgr jonathanlee571 at gmail.com
access_log /var/squid/logs/access.log
cache_log /var/squid/logs/cache.log
cache_store_log none
netdb_filename /var/squid/logs/netdb.state
pinger_enable on
pinger_program /usr/local/libexec/squid/pinger
sslcrtd_program /usr/local/libexec/squid/security_file_certgen -s /var/squid/lib/ssl_db -M 4MB -b 2048
tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
tls_outgoing_options capath=/usr/local/share/certs/
tls_outgoing_options options=NO_SSLv3
tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
sslcrtd_children 10

logfile_rotate 7
debug_options rotate=7
shutdown_lifetime 3 seconds
# Allow local network(s) on interface(s)
acl localnet src  192.168.1.0/27 REDACTED:192::/64
forwarded_for transparent
httpd_suppress_version_string on
uri_whitespace strip

acl block_hours time 00:30-05:00
ssl_bump terminate all block_hours
http_access deny all block_hours
acl getmethod method GET
#acl to_ipv6 dst ipv6
#acl from_ipv6 src ipv6

#tls_outgoing_options options=0x40000
#request_header_access Accept-Ranges deny all
#reply_header_access Accept-Ranges deny all
#request_header_replace Accept-Ranges none
#reply_header_replace Accept-Ranges none


#tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
tls_outgoing_options options=NO_SSLv3,NO_TLSv1,NO_TLSv1_1,NO_TICKET

#SINGLE_DH_USE,SINGLE_ECDH_USE

acl HttpAccess dstdomain '/usr/local/pkg/http.access'
acl windowsupdate dstdomain '/usr/local/pkg/windowsupdate'
#acl rewritedoms dstdomain '/usr/local/pkg/desdom'

#store_id_program /usr/local/libexec/squid/storeid_file_rewrite /var/squid/storeid/storeid_rewrite.txt
#store_id_children 10 startup=5 idle=1 concurrency=0
#always_direct allow all
#store_id_access deny connect
#store_id_access deny !getmethod
#store_id_access allow rewritedoms
#store_id_access deny all

refresh_all_ims on
reload_into_ims on
max_stale 20 years
minimum_expiry_time 0

refresh_pattern -i ^http.*squid.internal.* 43200 100% 79900 override-expire override-lastmod ignore-reload ignore-no-store ignore-must-revalidate ignore-private ignore-auth

#FACEBOOK
#refresh_pattern ^https.*.facebook.com/* 10080 80% 43200

#FACEBOOK IMAGES  
#refresh_pattern -i pixel.facebook.com..(jpg|png|gif|ico|css|js|jpg?) 10080 80% 43200
#refresh_pattern -i .akamaihd.net..(jpg|png|gif|ico|css|js|jpg?) 10080 80% 43200 
#refresh_pattern -i facebook.com.(jpg|png|gif|jpg?) 10080 80% 43200 store-stale
#refresh_pattern static.(xx|ak).fbcdn.net.(jpg|gif|png|jpg?) 10080 80% 43200
#refresh_pattern ^https.*profile.ak.fbcdn.net.*(jpg|gif|png|jpg?) 10080 80% 43200
#refresh_pattern ^https.*fbcdn.net.*(jpg|gif|png|jpg?) 10080 80% 43200

#FACEBOOK VIDEO
#refresh_pattern -i .video.ak.fbcdn.net.*.(mp4|flv|mp3|amf) 10080 80% 43200
#refresh_pattern (audio|video)/(webm|mp4) 10080 80% 43200

#APPLE STUFF
#refresh_pattern -i apple.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip|dist)$ 0 80% 43200  refresh-ims

#apple update
#refresh_pattern -i (download|adcdownload).apple.com/.*.(pkg|dmg) 4320 100% 43200
#refresh_pattern -i appldnld.apple.com 129600 100% 129600
#refresh_pattern -i phobos.apple.com 129600 100% 129600
#refresh_pattern -i iosapps.itunes.apple.com 129600 100% 129600

# Updates: Windows
refresh_pattern -i microsoft.com/..(cab|exe|msi|msu|msf|asf|wma|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i windowsupdate.com/..(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i windows.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i windows.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i .*windowsupdate.com/.*.(cab|exe) 259200 100% 259200   
refresh_pattern -i .*update.microsoft.com/.*.(cab|exe|dll|msi|psf) 259200 100% 259200   
refresh_pattern windowsupdate.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern download.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern www.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern au.download.windowsupdate.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200 
refresh_pattern bg.v4.pr.dl.ws.microsoft.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
#windows update NEW UPDATE 0.04
refresh_pattern update.microsoft.com/.*.(cab|exe) 43200 100% 129600    
refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200  
refresh_pattern update.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern -i .update.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .download.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .ws.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
    
#refresh_pattern ([^.]+.)?(cs|content[1-9]|hsar|content-origin|client-download).[steampowered|steamcontent].com/.*.* 43200 100% 43200     
#refresh_pattern ([^.]+.)?.akamai.steamstatic.com/.*.* 43200 100% 43200

#refresh_pattern -i ([^.]+.)?.adobe.com/.*.(zip|exe) 43200 100% 43200
#refresh_pattern -i ([^.]+.)?.java.com/.*.(zip|exe) 43200 100% 43200
#refresh_pattern -i ([^.]+.)?.sun.com/.*.(zip|exe) 43200 100% 43200
#refresh_pattern -i ([^.]+.)?.oracle.com/.*.(zip|exe|tar.gz) 43200 100% 43200

#refresh_pattern -i appldnld.apple.com 43200 100% 43200
#refresh_pattern -i ([^.]+.)?apple.com/.*.(ipa) 43200 100% 43200
 
#refresh_pattern -i ([^.]+.)?.google.com/.*.(exe|crx) 10080 80% 43200
#refresh_pattern -i ([^.]+.)?g.static.com/.*.(exe|crx) 10080 80% 43200

acl https_login url_regex -i ^https.*(login|Login).*
cache deny https_login

range_offset_limit 512 MB windowsupdate
range_offset_limit 4 MB
quick_abort_min -1 KB

cache_mem 512 MB
maximum_object_size_in_memory 256 KB
memory_replacement_policy heap GDSF
cache_replacement_policy heap LFUDA
minimum_object_size 0 KB
maximum_object_size 512 MB
cache_dir diskd /var/squid/cache 64000 256 256
offline_mode off
cache_swap_low 90
cache_swap_high 95
acl donotcache dstdomain '/var/squid/acl/donotcache.acl'
cache deny donotcache
cache allow all
# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:    1440  20%  10080
refresh_pattern ^gopher:  1440  0%  1440
refresh_pattern -i (/cgi-bin/|?) 0  0%  0
refresh_pattern .    0  20%  4320


#Remote proxies


# Setup some default acls
# ACLs all, manager, localhost, and to_localhost are predefined.
acl allsrc src all
acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080 3128 3129 1025-65535 
acl sslports port 443 563 8080 5223 2197

acl purge method PURGE
acl connect method CONNECT

# Define protocols used for redirects
acl HTTP proto HTTP
acl HTTPS proto HTTPS

# SslBump Peek and Splice
# http://wiki.squid-cache.org/Features/SslPeekAndSplice
# http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
# Match against the current step during ssl_bump evaluation [fast]
# Never matches and should not be used outside the ssl_bump context.
#
# At each SslBump step, Squid evaluates ssl_bump directives to find
# the next bumping action (e.g., peek or splice). Valid SslBump step
# values and the corresponding ssl_bump evaluation moments are:
#   SslBump1: After getting TCP-level and HTTP CONNECT info.
#   SslBump2: After getting TLS Client Hello info.
#   SslBump3: After getting TLS Server Hello info.
# These ACLs exist even when 'SSL/MITM Mode' is set to 'Custom' so that
# they can be used there for custom configuration.
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
acl banned_hosts src '/var/squid/acl/banned_hosts.acl'
acl whitelist dstdom_regex -i '/var/squid/acl/whitelist.acl'
acl blacklist dstdom_regex -i '/var/squid/acl/blacklist.acl'
http_access allow manager localhost

http_access deny manager
http_access allow purge localhost
http_access deny purge
http_access deny !safeports
http_access deny CONNECT !sslports

# Always allow localhost connections
http_access allow localhost

quick_abort_min 0 KB
quick_abort_max 0 KB
quick_abort_pct 95
request_body_max_size 0 KB
delay_pools 1
delay_class 1 2
delay_parameters 1 -1/-1 -1/-1
delay_initial_bucket_level 100
delay_access 1 allow allsrc

# Reverse Proxy settings

deny_info TCP_RESET allsrc

# Package Integration
url_rewrite_program /usr/local/bin/squidGuard -c /usr/local/etc/squidGuard/squidGuard.conf
url_rewrite_bypass off
url_rewrite_children 32 startup=8 idle=4 concurrency=0

# Custom options before auth
#host_verify_strict on

# These hosts are banned
http_access deny banned_hosts
# Always allow access to whitelist domains
http_access allow whitelist
# Block access to blacklist domains
http_access deny blacklist
# List of domains allowed to logging in to Google services
request_header_access X-GoogApps-Allowed-Domains deny all
request_header_add X-GoogApps-Allowed-Domains consumer_accounts
# Set YouTube safesearch restriction
acl youtubedst dstdomain -n www.youtube.com m.youtube.com youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com
request_header_access YouTube-Restrict deny all
request_header_add YouTube-Restrict none youtubedst
acl sglog url_regex -i sgr=ACCESSDENIED
http_access deny sglog
# Custom SSL/MITM options before auth
cachemgr_passwd disable offline_toggle reconfigure shutdown
cachemgr_passwd REDACTED all
eui_lookup on
acl no_miss url_regex -i gateway.facebook.com/ws/realtime?
acl no_miss url_regex -i web-chat-e2ee.facebook.com/ws/chat
acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com
http_access allow CONNECT wuCONNECT localnet
http_access allow CONNECT wuCONNECT localhost
http_access allow windowsupdate localnet
http_access allow windowsupdate localhost
http_access allow HttpAccess localnet
http_access allow HttpAccess localhost
http_access deny manager

acl BrokenButTrustedServers dstdomain '/usr/local/pkg/dstdom.broken'
acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
sslproxy_cert_error deny all

acl splice_only src 192.168.1.8 #Tasha iPhone
acl splice_only src 192.168.1.10 #Jon iPhone
acl splice_only src REDACTEDIPV6:6383:14b3 #Jon iPhone
acl splice_only src 192.168.1.11 #Amazon Fire
acl splice_only src 192.168.1.15 #Tasha HP
acl splice_only src 192.168.1.16 #iPad
acl splice_only src REDACTEDIPV6f:8589:3922 #iPad

acl splice_only_mac arp REDACTEDMAC
acl splice_only_mac arp REDACTEDMAC
acl splice_only_mac arp REDACTEDMAC
acl splice_only_mac arp REDACTEDMAC
acl splice_only_mac arp REDACTEDMAC


acl NoSSLIntercept ssl::server_name_regex -i '/usr/local/pkg/reg.url.nobump'
acl NoBumpDNS dstdomain '/usr/local/pkg/dns.nobump'

#acl markBumped annotate_client bumped=true
acl active_use annotate_client active=true
acl bump_only src 192.168.1.3 #webtv
acl bump_only src 192.168.1.4 #toshiba
acl bump_only src 192.168.1.5 #imac
acl bump_only src REDACTEDIPV6:720b:5bdd #imac
acl bump_only src 192.168.1.9 #macbook
acl bump_only src 192.168.1.13 #dell

acl bump_only_mac arp REDACTEDMAC
acl bump_only_mac arp REDACTEDMAC
acl bump_only_mac arp REDACTEDMAC
acl bump_only_mac arp REDACTEDMAC
acl bump_only_mac arp REDACTEDMAC


ssl_bump peek step1
miss_access deny no_miss active_use
ssl_bump splice https_login active_use
ssl_bump splice splice_only_mac splice_only active_use
ssl_bump splice NoBumpDNS active_use
ssl_bump splice NoSSLIntercept active_use #tested without MAC match
#ssl_bump bump bump_only_mac bump_only active_use
ssl_bump bump bump_only active_use
#acl activated note active_use true
#ssl_bump terminate !activated

#acl markedBumped note bumped true
#url_rewrite_access deny markedBumped

#acl SSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.bump'
#ssl_bump bump SSLIntercept

# Setup allowed ACLs
# Allow local network(s) on interface(s)
http_access allow localnet
# Default block all to be sure
http_access deny allsrc
Does anyone else have and ideas on what I did wrong? I have also tried to remove the addresses in the HTTP_PORT directive so it automatically configures, that was the same result. I have removed my MAC address matching and the terminate options same result also.

I get 409 errors on ssl bumps 

> On Jul 29, 2024, at 00:17, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 27/07/24 10:10, Jonathan Lee wrote:
>> Hello fellow squid users can you please help me??
>> I know I have good IPV6 internet if I use the IPV4 proxy address, and the IPv6 test sites pass 10 out of 10. If I make the client IPV6 only and have the rules set to use the proxy with the proxy IPV6 address for the proxy I get no internet.
>> I am using a IPV6 tunnel broker in pfsense. When I configure my client to IPv6 only it can access all IPv6 sites. As soon as I use the proxy address in IPv6 of Squid squid gives me the following errors...
> 
> Check that ICMPv6 is working. It is mandatory when tunnels are used.
> 
> Also, check the MSS and MTU values.
> 
> 
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240729/444160b9/attachment.htm>

From a9121431 at gmail.com  Tue Jul 30 12:35:30 2024
From: a9121431 at gmail.com (John Mok)
Date: Tue, 30 Jul 2024 20:35:30 +0800
Subject: [squid-users] Squid 5.7 - HOWTO Transparent SSL-Bump
Message-ID: <CALYzA8HRcb-UJCyMd2hn31JN1aKOzvkCwcwwb5g1tJQf_2AgqA@mail.gmail.com>

Hi all,

I am using squid 5.7 on Debian Bookworm, and would like to setup a
transparent + SSL bump proxy.

Tried the example below, but squid failed to start when https_port
having "intercept ssl-bump"

https://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

Anyone can point to the right direction ?

Thanks a lot.

John MOK
-------------- next part --------------
Squid Cache: Version 5.7
Service Name: squid
Debian linux

This binary uses OpenSSL 3.0.13 30 Jan 2024. configure options:  '--build=x86_64-linux-gnu' '--prefix=/usr' '--includedir=${prefix}/include' '--mandir=${prefix}/share/man' '--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var' '--disable-option-checking' '--disable-silent-rules' '--libdir=${prefix}/lib/x86_64-linux-gnu' '--runstatedir=/run' '--disable-maintainer-mode' '--disable-dependency-tracking' 'BUILDCXXFLAGS=-g -O2 -ffile-prefix-map=/usr/local/src/squid/squid-5.7=. -fstack-protector-strong -Wformat -Werror=format-security -Wno-error=deprecated-declarations -Wdate-time -D_FORTIFY_SOURCE=2 -Wl,-z,relro -Wl,-z,now ' 'BUILDCXX=g++' '--with-build-environment=default' '--enable-build-info=Debian linux' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--libexecdir=/usr/lib/squid' '--mandir=/usr/share/man' '--enable-inline' '--disable-arch-native' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth-basic=DB,fake,getpwnam,LDAP,NCSA,PAM,POP3,RADIUS,SASL,SMB' '--enable-auth-digest=file,LDAP' '--enable-auth-negotiate=kerberos,wrapper' '--enable-auth-ntlm=fake,SMB_LM' '--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,time_quota,unix_group,wbinfo_group' '--enable-security-cert-validators=fake' '--enable-storeid-rewrite-helpers=file' '--enable-url-rewrite-helpers=fake' '--enable-eui' '--enable-esi' '--enable-icmp' '--enable-zph-qos' '--enable-ecap' '--disable-translation' '--with-swapdir=/var/spool/squid' '--with-logdir=/var/log/squid' '--with-pidfile=/run/squid.pid' '--with-filedescriptors=65536' '--with-large-files' '--with-openssl' '--with-default-user=proxy' '--enable-linux-netfilter' '--with-systemd' '--with-gnutls' 'build_alias=x86_64-linux-gnu' 'CFLAGS=-g -O2 -ffile-prefix-map=/usr/local/src/squid/squid-5.7=. -fstack-protector-strong -Wformat -Werror=format-security -Wno-error=deprecated-declarations' 'LDFLAGS=-Wl,-z,relro -Wl,-z,now ' 'CPPFLAGS=-Wdate-time -D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -ffile-prefix-map=/usr/local/src/squid/squid-5.7=. -fstack-protector-strong -Wformat -Werror=format-security -Wno-error=deprecated-declarations'

From andre.bolinhas at articatech.com  Tue Jul 30 13:31:10 2024
From: andre.bolinhas at articatech.com (=?utf-8?Q?Bolinhas_Andr=C3=A9?=)
Date: Tue, 30 Jul 2024 15:31:10 +0200
Subject: [squid-users] IPTABLES - Can't redirect HTTPS traffic to external
 Squid
Message-ID: <zarafa.66a8eb1e.1b97.4cfafe751167e704@ns413437.ip-37-187-142.eu>

I have a external proxy server connected by VPN (IPSEC) to my main branch, and i'm trying to redirect all users HTTP / HTTPS traffic to this proxy.

Scenario Users -> Gateway (Main Branch) -> IPSEC -> Squid Proxy (transparent mode)

In my Gateway (Main Branch) I have this test iptables rule, that is forwarding all the TPC / UDP traffic to the Proxy server.


iptables -t nat -I PREROUTING -s 192.168.60.90 -p tcp -j DNAT --to-destination 172.31.0.1
iptables -t nat -I PREROUTING -s 192.168.60.90 -p udp -j DNAT --to-destination 172.31.0.1


In Squidd Proxy server I have the followed rules

iptables -t nat -I PREROUTING -s 192.168.60.90/32 -p tcp -m tcp --dport 443 -m comment --comment ArticaSquidTransparent -j REDIRECT --to-ports 8081
iptables -t nat -I PREROUTING -s 192.168.60.90/32 -p tcp -m tcp --dport 80 -m comment --comment ArticaSquidTransparent -j REDIRECT --to-ports 8080


Everything is working correctly, HTTP traffic is ok, DNS are also working, the only exeption is the HTTPS traffic, I can see the HTTPS traffic inside the squid access.log but on client side I got a timeout

1722265740.867      1 192.168.60.90 TCP_TUNNEL/200 0 CONNECT cnn.com:443 - HIER_DIRECT/51.210.183.2:443 - mac="00:00:00:00:00:00" webfilterpolicy:%200%0D%0A exterr="-|-"


Anyone can help me to understant if I'm missing so iptable rule to handle the HTTPS traffic?

Sent from Nine
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240730/f4d65491/attachment.htm>

From ngtech1ltd at gmail.com  Tue Jul 30 12:54:05 2024
From: ngtech1ltd at gmail.com (NgTech LTD)
Date: Tue, 30 Jul 2024 15:54:05 +0300
Subject: [squid-users] IPTABLES - Can't redirect HTTPS traffic to
 external Squid
In-Reply-To: <zarafa.66a8eb1e.1b97.4cfafe751167e704@ns413437.ip-37-187-142.eu>
References: <zarafa.66a8eb1e.1b97.4cfafe751167e704@ns413437.ip-37-187-142.eu>
Message-ID: <CABA8h=SwGFZ2Y3HW81HzMrhGrsjn=adJPOBgeqbuAKiYF0KK+Q@mail.gmail.com>

Hey,

The dnat rule should be done on the squid itsef.
You will need to re-route the relevant traffic over the ipsec tunnel to the
squid ip.
It's possible to do that over ipip or gre tunnels.

Eliezer

?????? ??? ??, 30 ????? 2024, 15:41, ??? Bolinhas Andr? ?<
andre.bolinhas at articatech.com>:

> I have a external proxy server connected by VPN (IPSEC) to my main branch,
> and i'm trying to redirect all users HTTP / HTTPS traffic to this proxy.
> Scenario Users -> Gateway (Main Branch) -> IPSEC -> Squid Proxy
> (transparent mode)
>
> In my Gateway (Main Branch) I have this test iptables rule, that is
> forwarding all the TPC / UDP traffic to the Proxy server.
>
> iptables -t nat -I PREROUTING -s 192.168.60.90 -p tcp -j DNAT --to-destination 172.31.0.1
> iptables -t nat -I PREROUTING -s 192.168.60.90 -p udp -j DNAT --to-destination 172.31.0.1
>
> In Squidd Proxy server I have the followed rules
>
> iptables -t nat -I PREROUTING -s 192.168.60.90/32 -p tcp -m tcp --dport 443 -m comment --comment ArticaSquidTransparent -j REDIRECT --to-ports 8081
> iptables -t nat -I PREROUTING -s 192.168.60.90/32 -p tcp -m tcp --dport 80 -m comment --comment ArticaSquidTransparent -j REDIRECT --to-ports 8080
>
> Everything is working correctly, HTTP traffic is ok, DNS are also working,
> the only exeption is the HTTPS traffic, I can see the HTTPS traffic inside
> the squid access.log but on client side I got a timeout
>
> 1722265740.867      1 192.168.60.90 TCP_TUNNEL/200 0 CONNECT cnn.com:443 - HIER_DIRECT/51.210.183.2:443 - mac="00:00:00:00:00:00" webfilterpolicy:%200%0D%0A exterr="-|-"
>
> Anyone can help me to understant if I'm missing so iptable rule to handle
> the HTTPS traffic?
>
> Sent from Nine <http://www.9folders.com/>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240730/57e07057/attachment.htm>

From codemarauder at gmail.com  Tue Jul 30 12:56:09 2024
From: codemarauder at gmail.com (Nishant Sharma)
Date: Tue, 30 Jul 2024 18:26:09 +0530
Subject: [squid-users] Squid 5.7 - HOWTO Transparent SSL-Bump
In-Reply-To: <CALYzA8HRcb-UJCyMd2hn31JN1aKOzvkCwcwwb5g1tJQf_2AgqA@mail.gmail.com>
References: <CALYzA8HRcb-UJCyMd2hn31JN1aKOzvkCwcwwb5g1tJQf_2AgqA@mail.gmail.com>
Message-ID: <1647942d-68e2-44b2-9209-cb31f70d635c@gmail.com>

Hi John,

On 30/07/24 18:05, John Mok wrote:
> Hi all,
> 
> I am using squid 5.7 on Debian Bookworm, and would like to setup a
> transparent + SSL bump proxy.
> 
> Anyone can point to the right direction ?

Squid on Debian and Ubuntu do not have following options:

--enable-ssl
--enable-ssl-crtd

You may want to build one from source for yourself.

Regards,
Nishant


From a9121431 at gmail.com  Tue Jul 30 15:11:05 2024
From: a9121431 at gmail.com (John Mok)
Date: Tue, 30 Jul 2024 23:11:05 +0800
Subject: [squid-users] Squid 5.7 - HOWTO Transparent SSL-Bump
In-Reply-To: <1647942d-68e2-44b2-9209-cb31f70d635c@gmail.com>
References: <CALYzA8HRcb-UJCyMd2hn31JN1aKOzvkCwcwwb5g1tJQf_2AgqA@mail.gmail.com>
 <1647942d-68e2-44b2-9209-cb31f70d635c@gmail.com>
Message-ID: <CALYzA8HR2BvnygTQLhk6YT=aNo0X63a4WUvObVf5E+KVEQivhw@mail.gmail.com>

Hi Nishant,

Yes, I did rebuild the package with

--with-openssl
--enable-ssl-crtd

but squid service failed to start with http_port configured with intercept
and ssl-bump modes at the same time. Any idea ?

On Tue, Jul 30, 2024, 21:12 Nishant Sharma <codemarauder at gmail.com> wrote:

> Hi John,
>
> On 30/07/24 18:05, John Mok wrote:
> > Hi all,
> >
> > I am using squid 5.7 on Debian Bookworm, and would like to setup a
> > transparent + SSL bump proxy.
> >
> > Anyone can point to the right direction ?
>
> Squid on Debian and Ubuntu do not have following options:
>
> --enable-ssl
> --enable-ssl-crtd
>
> You may want to build one from source for yourself.
>
> Regards,
> Nishant
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240730/f944edb3/attachment.htm>

From jonathanlee571 at gmail.com  Tue Jul 30 19:55:15 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Tue, 30 Jul 2024 12:55:15 -0700
Subject: [squid-users] Parse DNS for IPv4 and IPv6
Message-ID: <892E0CEA-C19F-427A-8088-0E63CB85C19C@gmail.com>

Hello fellow squid users can you please help? I have noticed that I get 409 errors with IPv6 only clients this leads me to believe that it?s DNS related. My firewall has both IPV4 and IPV6 DNS. I wonder if when an IPV6 only client is trying to access the proxy it defaults to IPv4 dns. How can one manually set the system to utilize specified DNS for ACL use within subnets? The system works as long as clients are double stacked. 


Sent from my iPhone

From andre.bolinhas at articatech.com  Tue Jul 30 21:43:56 2024
From: andre.bolinhas at articatech.com (=?utf-8?Q?Bolinhas_Andr=C3=A9?=)
Date: Tue, 30 Jul 2024 23:43:56 +0200
Subject: [squid-users] IPTABLES - Can't redirect HTTPS traffic to
 external Squid
Message-ID: <zarafa.66a95e9c.215a.58d8946871302c50@ns413437.ip-37-187-142.eu>

Hi


Do you mean user this

iptables -t nat -I PREROUTING -s 192.168.60.90/32 -p tcp -m tcp --dport 443 -m comment --comment ArticaSquidTransparent -j DNAT --to-destination 172.31.0.1:25976

iptables -t nat -I PREROUTING -s 192.168.60.90/32 -p tcp -m tcp --dport 80 -m comment --comment ArticaSquidTransparent -j DNAT --to-destination 172.31.0.1:52406


Instead this

iptables -t nat -I PREROUTING -s 192.168.60.90/32 -p tcp -m tcp --dport 443 -m comment --comment ArticaSquidTransparent -j REDIRECT --to-ports 25976

iptables -t nat -I PREROUTING -s 192.168.60.90/32 -p tcp -m tcp --dport 80 -m comment --comment ArticaSquidTransparent -j REDIRECT --to-ports 52406


?

Do I also need some kind of

-m state --state NEW,ESTABLISHED,RELATED -j ACCEPT

?


Best regards

Sent from Nine <http://www.9folders.com/> 
--------------------------------
De: NgTech LTD <ngtech1ltd at gmail.com>
Enviado: ter?a-feira, 30 de julho de 2024 14:44
Para: Bolinhas Andr?
Cc: squid-users at lists.squid-cache.org
Assunto Re: [squid-users] IPTABLES - Can't redirect HTTPS traffic to external Squid



Hey,

The dnat rule should be done on the squid itsef.
You will need to re-route the relevant traffic over the ipsec tunnel to the squid ip.
It's possible to do that over ipip or gre tunnels.

Eliezer 


?????? ??? ??, 30 ????? 2024, 15:41, ??? Bolinhas Andr? ?<andre.bolinhas at articatech.com <mailto:andre.bolinhas at articatech.com> >:
I have a external proxy server connected by VPN (IPSEC) to my main branch, and i'm trying to redirect all users HTTP / HTTPS traffic to this proxy.

Scenario Users -> Gateway (Main Branch) -> IPSEC -> Squid Proxy (transparent mode)

In my Gateway (Main Branch) I have this test iptables rule, that is forwarding all the TPC / UDP traffic to the Proxy server.


iptables -t nat -I PREROUTING -s 192.168.60.90 -p tcp -j DNAT --to-destination 172.31.0.1
iptables -t nat -I PREROUTING -s 192.168.60.90 -p udp -j DNAT --to-destination 172.31.0.1


In Squidd Proxy server I have the followed rules

iptables -t nat -I PREROUTING -s 192.168.60.90/32 <http://192.168.60.90/32>  -p tcp -m tcp --dport 443 -m comment --comment ArticaSquidTransparent -j REDIRECT --to-ports 8081
iptables -t nat -I PREROUTING -s 192.168.60.90/32 <http://192.168.60.90/32>  -p tcp -m tcp --dport 80 -m comment --comment ArticaSquidTransparent -j REDIRECT --to-ports 8080


Everything is working correctly, HTTP traffic is ok, DNS are also working, the only exeption is the HTTPS traffic, I can see the HTTPS traffic inside the squid access.log but on client side I got a timeout

1722265740.867      1 192.168.60.90 TCP_TUNNEL/200 0 CONNECT cnn.com:443 <http://cnn.com:443>  - HIER_DIRECT/51.210.183.2:443 <http://51.210.183.2:443>  - mac="00:00:00:00:00:00" webfilterpolicy:%200%0D%0A exterr="-|-"


Anyone can help me to understant if I'm missing so iptable rule to handle the HTTPS traffic?

Sent from Nine
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
https://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240730/aa720f26/attachment.htm>

From ngtech1ltd at gmail.com  Tue Jul 30 21:27:11 2024
From: ngtech1ltd at gmail.com (NgTech LTD)
Date: Wed, 31 Jul 2024 00:27:11 +0300
Subject: [squid-users] IPTABLES - Can't redirect HTTPS traffic to
 external Squid
In-Reply-To: <zarafa.66a95e9c.215a.58d8946871302c50@ns413437.ip-37-187-142.eu>
References: <zarafa.66a95e9c.215a.58d8946871302c50@ns413437.ip-37-187-142.eu>
Message-ID: <CABA8h=TwHtQGSkW19vX3M_fJxAVM4p561fU36Wf=yye1G4s0ew@mail.gmail.com>

Hey,

Sorry I missed understand the scenario.
For now lets assume the packets are routed to the proxy properly but, lets
try to understand how do you route the traffic to the proxy?

Also what is defined on the proxy http_port

Are you using artica proxy?
Where do you implement the iptables rules?

Eliezer

?????? ??? ??, 30 ????? 2024, 23:54, ??? Bolinhas Andr? ?<
andre.bolinhas at articatech.com>:

>
> Hi
>
> Do you mean user this
>
> iptables -t nat -I PREROUTING -s 192.168.60.90/32 -p tcp -m tcp --dport
> 443 -m comment --comment ArticaSquidTransparent -j DNAT --to-destination
> 172.31.0.1:25976
>
> iptables -t nat -I PREROUTING -s 192.168.60.90/32 -p tcp -m tcp --dport
> 80 -m comment --comment ArticaSquidTransparent -j DNAT --to-destination
> 172.31.0.1:52406
>
> Instead this
>
> iptables -t nat -I PREROUTING -s 192.168.60.90/32 -p tcp -m tcp --dport
> 443 -m comment --comment ArticaSquidTransparent -j REDIRECT --to-ports 25976
>
> iptables -t nat -I PREROUTING -s 192.168.60.90/32 -p tcp -m tcp --dport
> 80 -m comment --comment ArticaSquidTransparent -j REDIRECT --to-ports 52406
>
> ?
>
> Do I also need some kind of
>
> -m state --state NEW,ESTABLISHED,RELATED -j ACCEPT
>
> ?
>
> Best regards
> Sent from Nine <http://www.9folders.com/>
> ------------------------------
> *De:* NgTech LTD <ngtech1ltd at gmail.com>
> *Enviado:* ter?a-feira, 30 de julho de 2024 14:44
> *Para:* Bolinhas Andr?
> *Cc:* squid-users at lists.squid-cache.org
> *Assunto* Re: [squid-users] IPTABLES - Can't redirect HTTPS traffic to
> external Squid
>
>
>
> Hey,
>
> The dnat rule should be done on the squid itsef.
> You will need to re-route the relevant traffic over the ipsec tunnel to
> the squid ip.
> It's possible to do that over ipip or gre tunnels.
>
> Eliezer
>
> ?????? ??? ??, 30 ????? 2024, 15:41, ??? Bolinhas Andr? ?<
> andre.bolinhas at articatech.com>:
>
>> I have a external proxy server connected by VPN (IPSEC) to my main
>> branch, and i'm trying to redirect all users HTTP / HTTPS traffic to this
>> proxy.
>> Scenario Users -> Gateway (Main Branch) -> IPSEC -> Squid Proxy
>> (transparent mode)
>>
>> In my Gateway (Main Branch) I have this test iptables rule, that is
>> forwarding all the TPC / UDP traffic to the Proxy server.
>>
>> iptables -t nat -I PREROUTING -s 192.168.60.90 -p tcp -j DNAT --to-destination 172.31.0.1
>> iptables -t nat -I PREROUTING -s 192.168.60.90 -p udp -j DNAT --to-destination 172.31.0.1
>>
>> In Squidd Proxy server I have the followed rules
>>
>> iptables -t nat -I PREROUTING -s 192.168.60.90/32 -p tcp -m tcp --dport 443 -m comment --comment ArticaSquidTransparent -j REDIRECT --to-ports 8081
>> iptables -t nat -I PREROUTING -s 192.168.60.90/32 -p tcp -m tcp --dport 80 -m comment --comment ArticaSquidTransparent -j REDIRECT --to-ports 8080
>>
>> Everything is working correctly, HTTP traffic is ok, DNS are also
>> working, the only exeption is the HTTPS traffic, I can see the HTTPS
>> traffic inside the squid access.log but on client side I got a timeout
>>
>> 1722265740.867      1 192.168.60.90 TCP_TUNNEL/200 0 CONNECT cnn.com:443 - HIER_DIRECT/51.210.183.2:443 - mac="00:00:00:00:00:00" webfilterpolicy:%200%0D%0A exterr="-|-"
>>
>> Anyone can help me to understant if I'm missing so iptable rule to handle
>> the HTTPS traffic?
>>
>> Sent from Nine <http://www.9folders.com/>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240731/2f704b46/attachment.htm>

From squid3 at treenet.co.nz  Wed Jul 31 03:16:06 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 31 Jul 2024 15:16:06 +1200
Subject: [squid-users] Squid with PV6 Tunnel Broker
In-Reply-To: <AC4BE9DD-0521-42BA-A0EA-6D021558CAE2@gmail.com>
References: <133EDD52-1701-45C9-A50E-8AE700929A96@gmail.com>
 <c44d8379-4e18-4c36-af84-6c39bb053c7d@treenet.co.nz>
 <AC4BE9DD-0521-42BA-A0EA-6D021558CAE2@gmail.com>
Message-ID: <4bafee6a-8046-4d8d-b0f0-86d338022528@treenet.co.nz>

On 30/07/24 08:47, Jonathan Lee wrote:
> I did not know that I had the option set to disable Squid ICMP pinger 

pinger helper is not releted.


What I meant was that you need to ensure ICMPv6 protocol is enabled and 
working on your network. That is usually a firewall issue.

If it is blocked, the IPv6 packet fragmentation mechanism (required for 
tunnels) will not work and result in behaviour like you are seeing.
Similarly if MTU is set too large for the tunnel maximum packet size.


> I enabled ping helper I show a good socket for my IPV6 interface address 
> but every IPV6 only device shows NONE_NONE/409 on the Squid Access Table
> 

409 generated by Squid is a failed security check.
<https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery>


> 
> I get the same result. How would I change MTU on Squid isn?t that set to 
> auto discover with the HTTP port directive?

Yes, that is dneone using ICMPv6 and teh primary reason why Squid needs 
that protocol working.

> 
> I also forgot to mention the IPV6 only device works when I have it set 
> to not use the proxy.

The list of ports you show below has Squid accepting direct (forward 
proxy) connections with an IPv4-only port 3128.


I really do recommend using the port-only configuration style. At least 
until you get the proxy working properly. Squid sockets are dual-stack 
and accept both protocols by default. That will help you sort out the 
scope of what each port number is doing and avoid copy-paste mistakes 
like this.


> 
> Thanks again for the reply. It does work from IPV4 to IPV6 requests but 
> never for IPV6 to IPV6 addresses or pure IPV6. I can disable the proxy 
> and the system works for IPV6 to IPV6 only.
> 


> Here is my configuration I am testing..
> 
> # This file is automatically generated by pfSense
> # Do not edit manually !
> 
> http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3
> 
> http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3
> 
> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3
> 
> http_port [REDACTED:192::]:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3
> 
> https_port [REDACTED:192::]:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3
> 


> tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
> tls_outgoing_options capath=/usr/local/share/certs/
> tls_outgoing_options options=NO_SSLv3
> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> sslcrtd_children 10
> 


> # Allow local network(s) on interface(s)
> acl localnet src  192.168.1.0/27 REDACTED:192::/64

> 
> acl block_hours time 00:30-05:00
> ssl_bump terminate all block_hours
> http_access deny all block_hours
> acl getmethod method GET


> tls_outgoing_options options=NO_SSLv3,NO_TLSv1,NO_TLSv1_1,NO_TICKET
> 
> #SINGLE_DH_USE,SINGLE_ECDH_USE
> 
> acl HttpAccess dstdomain '/usr/local/pkg/http.access'
> acl windowsupdate dstdomain '/usr/local/pkg/windowsupdate'


> 
> refresh_pattern -i ^http.*squid.internal.* 43200 100% 79900 override-expire override-lastmod ignore-reload ignore-no-store ignore-must-revalidate ignore-private ignore-auth
> 

> # Updates: Windows
> refresh_pattern -i microsoft.com/..(cab|exe|msi|msu|msf|asf|wma|dat|zip)$ 4320 80% 43200  refresh-ims
> refresh_pattern -i windowsupdate.com/..(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$ 4320 80% 43200  refresh-ims
> refresh_pattern -i windows.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip)$ 4320 80% 43200  refresh-ims
> refresh_pattern -i microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
> refresh_pattern -i windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
> refresh_pattern -i windows.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
> refresh_pattern -i .*windowsupdate.com/.*.(cab|exe) 259200 100% 259200
> refresh_pattern -i .*update.microsoft.com/.*.(cab|exe|dll|msi|psf) 259200 100% 259200
> refresh_pattern windowsupdate.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
> refresh_pattern download.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
> refresh_pattern www.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
> refresh_pattern au.download.windowsupdate.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
> refresh_pattern bg.v4.pr.dl.ws.microsoft.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
> #windows update NEW UPDATE 0.04
> refresh_pattern update.microsoft.com/.*.(cab|exe) 43200 100% 129600
> refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200
> refresh_pattern update.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
> refresh_pattern -i .update.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
> refresh_pattern -i .windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
> refresh_pattern -i .download.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
> refresh_pattern -i .ws.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
>      

You might want to look through these patterns in future and remove the 
impossible-to-match ones and duplicates.

> 
> acl https_login url_regex -i ^https.*(login|Login).*
> cache deny https_login
> 
> acl donotcache dstdomain '/var/squid/acl/donotcache.acl'
> cache deny donotcache
> cache allow all


> # Setup some default acls
> # ACLs all, manager, localhost, and to_localhost are predefined.
> acl allsrc src all
> acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080 3128 3129 1025-65535
> acl sslports port 443 563 8080 5223 2197
> 
> acl purge method PURGE
> acl connect method CONNECT
> 
> # Define protocols used for redirects
> acl HTTP proto HTTP
> acl HTTPS proto HTTPS
> 
> # SslBump Peek and Splice
> # http://wiki.squid-cache.org/Features/SslPeekAndSplice
> # http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
> # Match against the current step during ssl_bump evaluation [fast]
> # Never matches and should not be used outside the ssl_bump context.
> #
> # At each SslBump step, Squid evaluates ssl_bump directives to find
> # the next bumping action (e.g., peek or splice). Valid SslBump step
> # values and the corresponding ssl_bump evaluation moments are:
> #   SslBump1: After getting TCP-level and HTTP CONNECT info.
> #   SslBump2: After getting TLS Client Hello info.
> #   SslBump3: After getting TLS Server Hello info.
> # These ACLs exist even when 'SSL/MITM Mode' is set to 'Custom' so that
> # they can be used there for custom configuration.
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> acl banned_hosts src '/var/squid/acl/banned_hosts.acl'
> acl whitelist dstdom_regex -i '/var/squid/acl/whitelist.acl'
> acl blacklist dstdom_regex -i '/var/squid/acl/blacklist.acl'
> http_access allow manager localhost
> 
> http_access deny manager
> http_access allow purge localhost
> http_access deny purge
> http_access deny !safeports
> http_access deny CONNECT !sslports
> 
> # Always allow localhost connections
> http_access allow localhost
> 
> quick_abort_min 0 KB
> quick_abort_max 0 KB
> quick_abort_pct 95
> request_body_max_size 0 KB
> delay_pools 1
> delay_class 1 2
> delay_parameters 1 -1/-1 -1/-1
> delay_initial_bucket_level 100
> delay_access 1 allow allsrc
> 
> # Reverse Proxy settings
> 
> deny_info TCP_RESET allsrc
> 
> # Package Integration
> url_rewrite_program /usr/local/bin/squidGuard -c /usr/local/etc/squidGuard/squidGuard.conf
> url_rewrite_bypass off
> url_rewrite_children 32 startup=8 idle=4 concurrency=0
> 
> # Custom options before auth
> #host_verify_strict on
> 
> # These hosts are banned
> http_access deny banned_hosts
> # Always allow access to whitelist domains
> http_access allow whitelist
> # Block access to blacklist domains
> http_access deny blacklist
> # List of domains allowed to logging in to Google services
> request_header_access X-GoogApps-Allowed-Domains deny all
> request_header_add X-GoogApps-Allowed-Domains consumer_accounts
> # Set YouTube safesearch restriction
> acl youtubedst dstdomain -n www.youtube.com m.youtube.com youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com
> request_header_access YouTube-Restrict deny all
> request_header_add YouTube-Restrict none youtubedst
> acl sglog url_regex -i sgr=ACCESSDENIED
> http_access deny sglog
> # Custom SSL/MITM options before auth
> cachemgr_passwd disable offline_toggle reconfigure shutdown
> cachemgr_passwd REDACTED all
> eui_lookup on
> acl no_miss url_regex -i gateway.facebook.com/ws/realtime?
> acl no_miss url_regex -i web-chat-e2ee.facebook.com/ws/chat
> acl CONNECT method CONNECT
> acl wuCONNECT dstdomain www.update.microsoft.com
> acl wuCONNECT dstdomain sls.microsoft.com
> http_access allow CONNECT wuCONNECT localnet
> http_access allow CONNECT wuCONNECT localhost
> http_access allow windowsupdate localnet
> http_access allow windowsupdate localhost
> http_access allow HttpAccess localnet
> http_access allow HttpAccess localhost
> http_access deny manager
> 
> acl BrokenButTrustedServers dstdomain '/usr/local/pkg/dstdom.broken'
> acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
> sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
> sslproxy_cert_error deny all
> 
> acl splice_only src 192.168.1.8 #Tasha iPhone
> acl splice_only src 192.168.1.10 #Jon iPhone
> acl splice_only src REDACTEDIPV6:6383:14b3 #Jon iPhone
> acl splice_only src 192.168.1.11 #Amazon Fire
> acl splice_only src 192.168.1.15 #Tasha HP
> acl splice_only src 192.168.1.16 #iPad
> acl splice_only src REDACTEDIPV6f:8589:3922 #iPad
> 
> acl splice_only_mac arp REDACTEDMAC
> acl splice_only_mac arp REDACTEDMAC
> acl splice_only_mac arp REDACTEDMAC
> acl splice_only_mac arp REDACTEDMAC
> acl splice_only_mac arp REDACTEDMAC
> 
> 
> acl NoSSLIntercept ssl::server_name_regex -i '/usr/local/pkg/reg.url.nobump'
> acl NoBumpDNS dstdomain '/usr/local/pkg/dns.nobump'
> 

> acl active_use annotate_client active=true
> acl bump_only src 192.168.1.3 #webtv
> acl bump_only src 192.168.1.4 #toshiba
> acl bump_only src 192.168.1.5 #imac
> acl bump_only src REDACTEDIPV6:720b:5bdd #imac
> acl bump_only src 192.168.1.9 #macbook
> acl bump_only src 192.168.1.13 #dell
> 
> acl bump_only_mac arp REDACTEDMAC
> acl bump_only_mac arp REDACTEDMAC
> acl bump_only_mac arp REDACTEDMAC
> acl bump_only_mac arp REDACTEDMAC
> acl bump_only_mac arp REDACTEDMAC
> 
> 
> ssl_bump peek step1
> miss_access deny no_miss active_use
> ssl_bump splice https_login active_use
> ssl_bump splice splice_only_mac splice_only active_use
> ssl_bump splice NoBumpDNS active_use
> ssl_bump splice NoSSLIntercept active_use #tested without MAC match

> ssl_bump bump bump_only active_use


> 
> # Setup allowed ACLs
> # Allow local network(s) on interface(s)
> http_access allow localnet
> # Default block all to be sure
> http_access deny allsrc
> 



From squid3 at treenet.co.nz  Wed Jul 31 03:22:41 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 31 Jul 2024 15:22:41 +1200
Subject: [squid-users] Squid 5.7 - HOWTO Transparent SSL-Bump
In-Reply-To: <CALYzA8HR2BvnygTQLhk6YT=aNo0X63a4WUvObVf5E+KVEQivhw@mail.gmail.com>
References: <CALYzA8HRcb-UJCyMd2hn31JN1aKOzvkCwcwwb5g1tJQf_2AgqA@mail.gmail.com>
 <1647942d-68e2-44b2-9209-cb31f70d635c@gmail.com>
 <CALYzA8HR2BvnygTQLhk6YT=aNo0X63a4WUvObVf5E+KVEQivhw@mail.gmail.com>
Message-ID: <11201b58-4487-421d-813f-762429756529@treenet.co.nz>


Debian/12 (aka "Bookworm") provides the package "squid-openssl" with the 
SSL-Bump feature enabled. It is a drop-in replacement for the "squid" 
package.


Cheers
Amos



On 31/07/24 03:11, John Mok wrote:
> Hi Nishant,
> 
> Yes, I did rebuild the package with
> 
> --with-openssl
> --enable-ssl-crtd
> 
> but squid service failed to start with http_port configured with 
> intercept and ssl-bump modes at the same time. Any idea ?
> 
> On Tue, Jul 30, 2024, 21:12 Nishant Sharma wrote:
> 
>     Hi John,
> 
>     On 30/07/24 18:05, John Mok wrote:
>      > Hi all,
>      >
>      > I am using squid 5.7 on Debian Bookworm, and would like to setup a
>      > transparent + SSL bump proxy.
>      >
>      > Anyone can point to the right direction ?
> 
>     Squid on Debian and Ubuntu do not have following options:
> 
>     --enable-ssl
>     --enable-ssl-crtd
> 
>     You may want to build one from source for yourself.
> 
>     Regards,
>     Nishant
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     https://lists.squid-cache.org/listinfo/squid-users
>     <https://lists.squid-cache.org/listinfo/squid-users>
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From jonathanlee571 at gmail.com  Wed Jul 31 06:05:37 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Tue, 30 Jul 2024 23:05:37 -0700
Subject: [squid-users] Squid with PV6 Tunnel Broker
In-Reply-To: <4bafee6a-8046-4d8d-b0f0-86d338022528@treenet.co.nz>
References: <4bafee6a-8046-4d8d-b0f0-86d338022528@treenet.co.nz>
Message-ID: <E0BC4731-E579-45D2-9A75-A8FD4B383715@gmail.com>

The error it shows when I activate IPv6 only mode not dual stack is

Error: no forward proxy ports configured 

Squid terminated
Sent from my iPhone

> On Jul 30, 2024, at 20:16, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> ?On 30/07/24 08:47, Jonathan Lee wrote:
>> I did not know that I had the option set to disable Squid ICMP pinger
> 
> pinger helper is not releted.
> 
> 
> What I meant was that you need to ensure ICMPv6 protocol is enabled and working on your network. That is usually a firewall issue.
> 
> If it is blocked, the IPv6 packet fragmentation mechanism (required for tunnels) will not work and result in behaviour like you are seeing.
> Similarly if MTU is set too large for the tunnel maximum packet size.
> 
> 
>> I enabled ping helper I show a good socket for my IPV6 interface address but every IPV6 only device shows NONE_NONE/409 on the Squid Access Table
> 
> 409 generated by Squid is a failed security check.
> <https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery>
> 
> 
>> I get the same result. How would I change MTU on Squid isn?t that set to auto discover with the HTTP port directive?
> 
> Yes, that is dneone using ICMPv6 and teh primary reason why Squid needs that protocol working.
> 
>> I also forgot to mention the IPV6 only device works when I have it set to not use the proxy.
> 
> The list of ports you show below has Squid accepting direct (forward proxy) connections with an IPv4-only port 3128.
> 
> 
> I really do recommend using the port-only configuration style. At least until you get the proxy working properly. Squid sockets are dual-stack and accept both protocols by default. That will help you sort out the scope of what each port number is doing and avoid copy-paste mistakes like this.
> 
> 
>> Thanks again for the reply. It does work from IPV4 to IPV6 requests but never for IPV6 to IPV6 addresses or pure IPV6. I can disable the proxy and the system works for IPV6 to IPV6 only.
> 
> 
>> Here is my configuration I am testing..
>> # This file is automatically generated by pfSense
>> # Do not edit manually !
>> http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3
>> http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3
>> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3
>> http_port [REDACTED:192::]:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3
>> https_port [REDACTED:192::]:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3
> 
> 
>> tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
>> tls_outgoing_options capath=/usr/local/share/certs/
>> tls_outgoing_options options=NO_SSLv3
>> tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>> sslcrtd_children 10
> 
> 
>> # Allow local network(s) on interface(s)
>> acl localnet src  192.168.1.0/27 REDACTED:192::/64
> 
>> acl block_hours time 00:30-05:00
>> ssl_bump terminate all block_hours
>> http_access deny all block_hours
>> acl getmethod method GET
> 
> 
>> tls_outgoing_options options=NO_SSLv3,NO_TLSv1,NO_TLSv1_1,NO_TICKET
>> #SINGLE_DH_USE,SINGLE_ECDH_USE
>> acl HttpAccess dstdomain '/usr/local/pkg/http.access'
>> acl windowsupdate dstdomain '/usr/local/pkg/windowsupdate'
> 
> 
>> refresh_pattern -i ^http.*squid.internal.* 43200 100% 79900 override-expire override-lastmod ignore-reload ignore-no-store ignore-must-revalidate ignore-private ignore-auth
> 
>> # Updates: Windows
>> refresh_pattern -i microsoft.com/..(cab|exe|msi|msu|msf|asf|wma|dat|zip)$ 4320 80% 43200  refresh-ims
>> refresh_pattern -i windowsupdate.com/..(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$ 4320 80% 43200  refresh-ims
>> refresh_pattern -i windows.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip)$ 4320 80% 43200  refresh-ims
>> refresh_pattern -i microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
>> refresh_pattern -i windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
>> refresh_pattern -i windows.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
>> refresh_pattern -i .*windowsupdate.com/.*.(cab|exe) 259200 100% 259200
>> refresh_pattern -i .*update.microsoft.com/.*.(cab|exe|dll|msi|psf) 259200 100% 259200
>> refresh_pattern windowsupdate.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
>> refresh_pattern download.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
>> refresh_pattern www.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
>> refresh_pattern au.download.windowsupdate.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
>> refresh_pattern bg.v4.pr.dl.ws.microsoft.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
>> #windows update NEW UPDATE 0.04
>> refresh_pattern update.microsoft.com/.*.(cab|exe) 43200 100% 129600
>> refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200
>> refresh_pattern update.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200
>> refresh_pattern -i .update.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
>> refresh_pattern -i .windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
>> refresh_pattern -i .download.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
>> refresh_pattern -i .ws.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600
>>     
> 
> You might want to look through these patterns in future and remove the impossible-to-match ones and duplicates.
> 
>> acl https_login url_regex -i ^https.*(login|Login).*
>> cache deny https_login
>> acl donotcache dstdomain '/var/squid/acl/donotcache.acl'
>> cache deny donotcache
>> cache allow all
> 
> 
>> # Setup some default acls
>> # ACLs all, manager, localhost, and to_localhost are predefined.
>> acl allsrc src all
>> acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080 3128 3129 1025-65535
>> acl sslports port 443 563 8080 5223 2197
>> acl purge method PURGE
>> acl connect method CONNECT
>> # Define protocols used for redirects
>> acl HTTP proto HTTP
>> acl HTTPS proto HTTPS
>> # SslBump Peek and Splice
>> # http://wiki.squid-cache.org/Features/SslPeekAndSplice
>> # http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>> # Match against the current step during ssl_bump evaluation [fast]
>> # Never matches and should not be used outside the ssl_bump context.
>> #
>> # At each SslBump step, Squid evaluates ssl_bump directives to find
>> # the next bumping action (e.g., peek or splice). Valid SslBump step
>> # values and the corresponding ssl_bump evaluation moments are:
>> #   SslBump1: After getting TCP-level and HTTP CONNECT info.
>> #   SslBump2: After getting TLS Client Hello info.
>> #   SslBump3: After getting TLS Server Hello info.
>> # These ACLs exist even when 'SSL/MITM Mode' is set to 'Custom' so that
>> # they can be used there for custom configuration.
>> acl step1 at_step SslBump1
>> acl step2 at_step SslBump2
>> acl step3 at_step SslBump3
>> acl banned_hosts src '/var/squid/acl/banned_hosts.acl'
>> acl whitelist dstdom_regex -i '/var/squid/acl/whitelist.acl'
>> acl blacklist dstdom_regex -i '/var/squid/acl/blacklist.acl'
>> http_access allow manager localhost
>> http_access deny manager
>> http_access allow purge localhost
>> http_access deny purge
>> http_access deny !safeports
>> http_access deny CONNECT !sslports
>> # Always allow localhost connections
>> http_access allow localhost
>> quick_abort_min 0 KB
>> quick_abort_max 0 KB
>> quick_abort_pct 95
>> request_body_max_size 0 KB
>> delay_pools 1
>> delay_class 1 2
>> delay_parameters 1 -1/-1 -1/-1
>> delay_initial_bucket_level 100
>> delay_access 1 allow allsrc
>> # Reverse Proxy settings
>> deny_info TCP_RESET allsrc
>> # Package Integration
>> url_rewrite_program /usr/local/bin/squidGuard -c /usr/local/etc/squidGuard/squidGuard.conf
>> url_rewrite_bypass off
>> url_rewrite_children 32 startup=8 idle=4 concurrency=0
>> # Custom options before auth
>> #host_verify_strict on
>> # These hosts are banned
>> http_access deny banned_hosts
>> # Always allow access to whitelist domains
>> http_access allow whitelist
>> # Block access to blacklist domains
>> http_access deny blacklist
>> # List of domains allowed to logging in to Google services
>> request_header_access X-GoogApps-Allowed-Domains deny all
>> request_header_add X-GoogApps-Allowed-Domains consumer_accounts
>> # Set YouTube safesearch restriction
>> acl youtubedst dstdomain -n www.youtube.com m.youtube.com youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com
>> request_header_access YouTube-Restrict deny all
>> request_header_add YouTube-Restrict none youtubedst
>> acl sglog url_regex -i sgr=ACCESSDENIED
>> http_access deny sglog
>> # Custom SSL/MITM options before auth
>> cachemgr_passwd disable offline_toggle reconfigure shutdown
>> cachemgr_passwd REDACTED all
>> eui_lookup on
>> acl no_miss url_regex -i gateway.facebook.com/ws/realtime?
>> acl no_miss url_regex -i web-chat-e2ee.facebook.com/ws/chat
>> acl CONNECT method CONNECT
>> acl wuCONNECT dstdomain www.update.microsoft.com
>> acl wuCONNECT dstdomain sls.microsoft.com
>> http_access allow CONNECT wuCONNECT localnet
>> http_access allow CONNECT wuCONNECT localhost
>> http_access allow windowsupdate localnet
>> http_access allow windowsupdate localhost
>> http_access allow HttpAccess localnet
>> http_access allow HttpAccess localhost
>> http_access deny manager
>> acl BrokenButTrustedServers dstdomain '/usr/local/pkg/dstdom.broken'
>> acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
>> sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
>> sslproxy_cert_error deny all
>> acl splice_only src 192.168.1.8 #Tasha iPhone
>> acl splice_only src 192.168.1.10 #Jon iPhone
>> acl splice_only src REDACTEDIPV6:6383:14b3 #Jon iPhone
>> acl splice_only src 192.168.1.11 #Amazon Fire
>> acl splice_only src 192.168.1.15 #Tasha HP
>> acl splice_only src 192.168.1.16 #iPad
>> acl splice_only src REDACTEDIPV6f:8589:3922 #iPad
>> acl splice_only_mac arp REDACTEDMAC
>> acl splice_only_mac arp REDACTEDMAC
>> acl splice_only_mac arp REDACTEDMAC
>> acl splice_only_mac arp REDACTEDMAC
>> acl splice_only_mac arp REDACTEDMAC
>> acl NoSSLIntercept ssl::server_name_regex -i '/usr/local/pkg/reg.url.nobump'
>> acl NoBumpDNS dstdomain '/usr/local/pkg/dns.nobump'
> 
>> acl active_use annotate_client active=true
>> acl bump_only src 192.168.1.3 #webtv
>> acl bump_only src 192.168.1.4 #toshiba
>> acl bump_only src 192.168.1.5 #imac
>> acl bump_only src REDACTEDIPV6:720b:5bdd #imac
>> acl bump_only src 192.168.1.9 #macbook
>> acl bump_only src 192.168.1.13 #dell
>> acl bump_only_mac arp REDACTEDMAC
>> acl bump_only_mac arp REDACTEDMAC
>> acl bump_only_mac arp REDACTEDMAC
>> acl bump_only_mac arp REDACTEDMAC
>> acl bump_only_mac arp REDACTEDMAC
>> ssl_bump peek step1
>> miss_access deny no_miss active_use
>> ssl_bump splice https_login active_use
>> ssl_bump splice splice_only_mac splice_only active_use
>> ssl_bump splice NoBumpDNS active_use
>> ssl_bump splice NoSSLIntercept active_use #tested without MAC match
> 
>> ssl_bump bump bump_only active_use
> 
> 
>> # Setup allowed ACLs
>> # Allow local network(s) on interface(s)
>> http_access allow localnet
>> # Default block all to be sure
>> http_access deny allsrc
> 


From numsys at free.fr  Wed Jul 31 08:59:44 2024
From: numsys at free.fr (FredB)
Date: Wed, 31 Jul 2024 10:59:44 +0200 (CEST)
Subject: [squid-users] Rock store with docker
In-Reply-To: <1980795407.40184014.1722415881834.JavaMail.root@zimbra30-e5.priv.proxad.net>
Message-ID: <1559603070.40205960.1722416384375.JavaMail.root@zimbra30-e5.priv.proxad.net>

hello All,

I would like to know if anyone is using Squid 6 with Rock Store in a Docker container? On my end, it crashes at launch with the following in my squid.conf:

cache_dir rock /var/spool/squid 55000 max-swap-rate=250 swap-timeout=35

I'm using https://hub.docker.com/r/fredbcode/squid

Thanks in advance.




From uhlar at fantomas.sk  Wed Jul 31 10:35:44 2024
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 31 Jul 2024 12:35:44 +0200
Subject: [squid-users] Parse DNS for IPv4 and IPv6
In-Reply-To: <892E0CEA-C19F-427A-8088-0E63CB85C19C@gmail.com>
References: <892E0CEA-C19F-427A-8088-0E63CB85C19C@gmail.com>
Message-ID: <ZqoTgBWHI00KmKof@fantomas.sk>

On 30.07.24 12:55, Jonathan Lee wrote:
>Hello fellow squid users can you please help?

> I have noticed that I get 409 errors with IPv6 only clients this leads me 
> to believe that it?s DNS related.

why do you think that?

> My firewall has both IPV4 and IPV6 DNS.  
> I wonder if when an IPV6 only client is trying to access the proxy it 
> defaults to IPv4 dns. 

Sice, the connection between client and squid is separate from connection 
between squid and server, it should be perfectly okay to have ipv6 on one 
and ipv4 on another.

> How can one manually set the system to utilize 
> specified DNS for ACL use within subnets?  The system works as long as 
> clients are double stacked.

Can we see example of those errors in log files?

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Support bacteria - they're the only culture some people have.


From uhlar at fantomas.sk  Wed Jul 31 10:52:49 2024
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 31 Jul 2024 12:52:49 +0200
Subject: [squid-users] Squid 5.7 - HOWTO Transparent SSL-Bump
In-Reply-To: <11201b58-4487-421d-813f-762429756529@treenet.co.nz>
References: <CALYzA8HRcb-UJCyMd2hn31JN1aKOzvkCwcwwb5g1tJQf_2AgqA@mail.gmail.com>
 <1647942d-68e2-44b2-9209-cb31f70d635c@gmail.com>
 <CALYzA8HR2BvnygTQLhk6YT=aNo0X63a4WUvObVf5E+KVEQivhw@mail.gmail.com>
 <11201b58-4487-421d-813f-762429756529@treenet.co.nz>
Message-ID: <ZqoXgWmUD9B8YPB6@fantomas.sk>

On 31.07.24 15:22, Amos Jeffries wrote:
>Debian/12 (aka "Bookworm") provides the package "squid-openssl" with 
>the SSL-Bump feature enabled. It is a drop-in replacement for the 
>"squid" package.

FYI this version is available since Debian 11, and build options include 
both --with-openssl and --enable-ssl-crtd


>On 31/07/24 03:11, John Mok wrote:
>>Hi Nishant,
>>
>>Yes, I did rebuild the package with
>>
>>--with-openssl
>>--enable-ssl-crtd
>>
>>but squid service failed to start with http_port configured with 
>>intercept and ssl-bump modes at the same time. Any idea ?
>>
>>On Tue, Jul 30, 2024, 21:12 Nishant Sharma wrote:
>>
>>    Hi John,
>>
>>    On 30/07/24 18:05, John Mok wrote:
>>     > Hi all,
>>     >
>>     > I am using squid 5.7 on Debian Bookworm, and would like to setup a
>>     > transparent + SSL bump proxy.
>>     >
>>     > Anyone can point to the right direction ?
>>
>>    Squid on Debian and Ubuntu do not have following options:
>>
>>    --enable-ssl
>>    --enable-ssl-crtd
>>
>>    You may want to build one from source for yourself.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
99 percent of lawyers give the rest a bad name.


From gkinkie at gmail.com  Wed Jul 31 13:15:19 2024
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Wed, 31 Jul 2024 14:15:19 +0100
Subject: [squid-users] Rock store with docker
In-Reply-To: <1559603070.40205960.1722416384375.JavaMail.root@zimbra30-e5.priv.proxad.net>
References: <1980795407.40184014.1722415881834.JavaMail.root@zimbra30-e5.priv.proxad.net>
 <1559603070.40205960.1722416384375.JavaMail.root@zimbra30-e5.priv.proxad.net>
Message-ID: <CA+Y8hcNc0v4N5XnAoK8v-zh0TP4Qh6LG-CNk1=4-s2x=TKAhRw@mail.gmail.com>

What is the error message you get in cache.log, if any?

On Wed, Jul 31, 2024 at 12:27?PM FredB <numsys at free.fr> wrote:
>
> hello All,
>
> I would like to know if anyone is using Squid 6 with Rock Store in a Docker container? On my end, it crashes at launch with the following in my squid.conf:
>
> cache_dir rock /var/spool/squid 55000 max-swap-rate=250 swap-timeout=35
>
> I'm using https://hub.docker.com/r/fredbcode/squid
>
> Thanks in advance.
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco


From numsys at free.fr  Wed Jul 31 14:57:17 2024
From: numsys at free.fr (FredB)
Date: Wed, 31 Jul 2024 16:57:17 +0200 (CEST)
Subject: [squid-users] Rock store with docker
In-Reply-To: <CA+Y8hcNc0v4N5XnAoK8v-zh0TP4Qh6LG-CNk1=4-s2x=TKAhRw@mail.gmail.com>
Message-ID: <125406946.41180424.1722437837033.JavaMail.root@zimbra30-e5.priv.proxad.net>

I opened a bug here https://bugs.squid-cache.org/show_bug.cgi?id=5394



From jonathanlee571 at gmail.com  Wed Jul 31 20:17:57 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 31 Jul 2024 13:17:57 -0700
Subject: [squid-users] Parse DNS for IPv4 and IPv6
In-Reply-To: <FFDEC81D-ECFB-49B7-A784-55B886C7ACC9@gmail.com>
References: <FFDEC81D-ECFB-49B7-A784-55B886C7ACC9@gmail.com>
Message-ID: <1E4F8E23-FE93-4474-B4F7-2A941DD75109@gmail.com>

I forgot to mention this is over a he tunnel broker gif interface with IPv4 only isp
Sent from my iPhone

> On Jul 31, 2024, at 12:03, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> ?I show HTTP/1.1 409 conflict when it try to reply from the firewall back to the client.
> 
> I do not know if you need a pcap file
> 
> <Capture.PNG>
> <packetcapture-mvneta1.4084-20240731114904.pcap>
> 
> 
>> On Jul 31, 2024, at 03:35, Matus UHLAR - fantomas <uhlar at fantomas.sk> wrote:
>> 
>>> On 30.07.24 12:55, Jonathan Lee wrote:
>>> Hello fellow squid users can you please help?
>> 
>>> I have noticed that I get 409 errors with IPv6 only clients this leads me to believe that it?s DNS related.
>> 
>> why do you think that?
>> 
>>> My firewall has both IPV4 and IPV6 DNS.  I wonder if when an IPV6 only client is trying to access the proxy it defaults to IPv4 dns.
>> 
>> Sice, the connection between client and squid is separate from connection between squid and server, it should be perfectly okay to have ipv6 on one and ipv4 on another.
>> 
>>> How can one manually set the system to utilize specified DNS for ACL use within subnets?  The system works as long as clients are double stacked.
>> 
>> Can we see example of those errors in log files?
>> 
>> --
>> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
>> Warning: I wish NOT to receive e-mail advertising to this address.
>> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
>> Support bacteria - they're the only culture some people have.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 


From jonathanlee571 at gmail.com  Wed Jul 31 21:36:58 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 31 Jul 2024 14:36:58 -0700
Subject: [squid-users] Parse DNS for IPv4 and IPv6
In-Reply-To: <1E4F8E23-FE93-4474-B4F7-2A941DD75109@gmail.com>
References: <1E4F8E23-FE93-4474-B4F7-2A941DD75109@gmail.com>
Message-ID: <56D32EDB-C519-4DBD-A6EF-968D5A1471FE@gmail.com>

Does it require 

acl localnet src fc00::/7
acl localnet src fe80::/10
With the pfsense packages or is that coded into the php code?
Sent from my iPhone

> On Jul 31, 2024, at 13:18, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> ?I forgot to mention this is over a he tunnel broker gif interface with IPv4 only isp
> Sent from my iPhone
> 
>> On Jul 31, 2024, at 12:03, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> ?I show HTTP/1.1 409 conflict when it try to reply from the firewall back to the client.
>> 
>> I do not know if you need a pcap file
>> 
>> <Capture.PNG>
>> <packetcapture-mvneta1.4084-20240731114904.pcap>
>> 
>> 
>>>> On Jul 31, 2024, at 03:35, Matus UHLAR - fantomas <uhlar at fantomas.sk> wrote:
>>> 
>>>> On 30.07.24 12:55, Jonathan Lee wrote:
>>>> Hello fellow squid users can you please help?
>>> 
>>>> I have noticed that I get 409 errors with IPv6 only clients this leads me to believe that it?s DNS related.
>>> 
>>> why do you think that?
>>> 
>>>> My firewall has both IPV4 and IPV6 DNS.  I wonder if when an IPV6 only client is trying to access the proxy it defaults to IPv4 dns.
>>> 
>>> Sice, the connection between client and squid is separate from connection between squid and server, it should be perfectly okay to have ipv6 on one and ipv4 on another.
>>> 
>>>> How can one manually set the system to utilize specified DNS for ACL use within subnets?  The system works as long as clients are double stacked.
>>> 
>>> Can we see example of those errors in log files?
>>> 
>>> --
>>> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
>>> Warning: I wish NOT to receive e-mail advertising to this address.
>>> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
>>> Support bacteria - they're the only culture some people have.
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>> 


