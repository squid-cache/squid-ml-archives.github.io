From jonathanlee571 at gmail.com  Sat Jun  1 05:24:48 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 31 May 2024 22:24:48 -0700
Subject: [squid-users] urlfilterdb.com
In-Reply-To: <31a5d08a-6bf0-4ba8-b749-4efbeb1826e1@urlfilterdb.com>
References: <31a5d08a-6bf0-4ba8-b749-4efbeb1826e1@urlfilterdb.com>
Message-ID: <F247A0AF-6D99-44E4-B8FC-7D15B024B859@gmail.com>

Marcus are you the same guy that does the pfSense Squid GUI package interference code??
Sent from my iPhone

> On May 30, 2024, at 01:38, Marcus Kool <marcus.kool at urlfilterdb.com> wrote:
> 
> ?Not sure if this message was meant for the Squid mailing list but for those who are interested, the DNS provider had an issue with DNSSEC resigning and all is well now.
> 
> Marcus
> 
> 
>> On 28/05/2024 15:23, Anton Kornexl wrote:
>> Hello,
>> 
>> since two days the domain urlfilterdb.com is not resolved to an IP.  We get no updates to the urlfiter-DB and the homepage can?t be opned.
>> 
>> Does someone know the reason?
>> 
>> Kind regards
>> 
>> Anton
>> 
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From marcus.kool at urlfilterdb.com  Sat Jun  1 17:12:58 2024
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Sat, 1 Jun 2024 18:12:58 +0100
Subject: [squid-users] urlfilterdb.com
In-Reply-To: <F247A0AF-6D99-44E4-B8FC-7D15B024B859@gmail.com>
References: <31a5d08a-6bf0-4ba8-b749-4efbeb1826e1@urlfilterdb.com>
 <F247A0AF-6D99-44E4-B8FC-7D15B024B859@gmail.com>
Message-ID: <3018af12-5640-418e-be63-14c9b4736b36@urlfilterdb.com>

I am not :-)

On 01/06/2024 06:24, Jonathan Lee wrote:
> Marcus are you the same guy that does the pfSense Squid GUI package interference code??
> Sent from my iPhone
>
>> On May 30, 2024, at 01:38, Marcus Kool <marcus.kool at urlfilterdb.com> wrote:
>>
>> ?Not sure if this message was meant for the Squid mailing list but for those who are interested, the DNS provider had an issue with DNSSEC resigning and all is well now.
>>
>> Marcus
>>
>>
>>> On 28/05/2024 15:23, Anton Kornexl wrote:
>>> Hello,
>>>
>>> since two days the domain urlfilterdb.com is not resolved to an IP.  We get no updates to the urlfiter-DB and the homepage can?t be opned.
>>>
>>> Does someone know the reason?
>>>
>>> Kind regards
>>>
>>> Anton
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users


From sachin1.g at gmail.com  Wed Jun  5 11:31:25 2024
From: sachin1.g at gmail.com (sachin gupta)
Date: Wed, 5 Jun 2024 17:01:25 +0530
Subject: [squid-users] IPv6 happy eyeball on dualstack host
Message-ID: <CALpWAcqmvQS9rD3TH+zt_ETBg+ZiuhiAPqLmaacqffwvT9iP2Q@mail.gmail.com>

Hi

We are shifting to IPv6 dual stack hosts. As per squid documentation
<https://wiki.squid-cache.org/Features/IPv6>, IPv6 is enabled by default. I
tried a request on www.google.com which has both IPv4 and IPv6 address.
As per documentation, based on DNS response squid will try both IP4 and
IPv6 if DNS return both addresses. But I see that squid is only getting
IPv4 address though with dis command I can see IPv6 address as well. Also
from same host, I am able to make curl command to google using IPv6.

DNS logs for squid

24/06/05 10:41:54.953 kid1| 5,4| AsyncCallQueue.cc(59) fireNext: entering
helperHandleRead(conn4 local=[::] remote=[::] FD 13 flags=1,
data=0x55c87a45bb38, size=5, buf=0x55c87a45bd60)

2024/06/05 10:41:54.953 kid1| 5,4| AsyncCall.cc(41) make: make call
helperHandleRead [call4]

2024/06/05 10:41:54.953 kid1| 78,3| dns_internal.cc(1792) idnsALookup:
idnsALookup: buf is 32 bytes for www.google.com, id = 0xe006

2024/06/05 10:41:54.953 kid1| 5,4| AsyncCall.cc(29) AsyncCall: The
AsyncCall helperHandleRead constructed, this=0x55c87a9301e0 [call89]

2024/06/05 10:41:54.953 kid1| 5,5| Read.cc(58) comm_read_base: comm_read,
queueing read for conn4 local=[::] remote=[::] FD 13 flags=1; asynCall
0x55c87a9301e0*1

2024/06/05 10:41:54.954 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13,
type=1, handler=1, client_data=0x7f183475a700, timeout=0

2024/06/05 10:41:54.954 kid1| 5,4| AsyncCallQueue.cc(61) fireNext: leaving
helperHandleRead(conn4 local=[::] remote=[::] FD 13 flags=1,
data=0x55c87a45bb38, size=5, buf=0x55c87a45bd60)

2024/06/05 10:41:54.955 kid1| 78,3| dns_internal.cc(1318) idnsRead:
idnsRead: starting with FD 11

2024/06/05 10:41:54.955 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 11,
type=1, handler=1, client_data=0, timeout=0

2024/06/05 10:41:54.955 kid1| 78,3| dns_internal.cc(1364) idnsRead:
idnsRead: FD 11: received 48 bytes from 10.0.32.2:53

2024/06/05 10:41:54.955 kid1| 78,3| dns_internal.cc(1171) idnsGrokReply:
idnsGrokReply: QID 0xe006, 1 answers

2024/06/05 10:41:54.955 kid1| 5,5| Connection.cc(99) cloneProfile:
0x55c87a944210 made conn56 local=0.0.0.0 remote=142.251.215.228:80
HIER_DIRECT flags=1

2024/06/05 10:41:54.955 kid1| 5,5| Connection.cc(99) cloneProfile:
0x55c87a944830 made conn57 local=0.0.0.0 remote=142.251.215.228:80
HIER_DIRECT flags=1

2024/06/05 10:41:54.955 kid1| 5,3| ConnOpener.cc(43) ConnOpener: will
connect to conn57 local=0.0.0.0 remote=142.251.215.228:80 HIER_DIRECT
flags=1 with 15 timeout

2024/06/05 10:41:54.955 kid1| 5,5| comm.cc(428) comm_init_opened: conn58
local=0.0.0.0 remote=[::] FD 16 flags=1 is a new socket

2024/06/05 10:41:54.955 kid1| 5,4| AsyncCall.cc(29) AsyncCall: The
AsyncCall Comm::ConnOpener::earlyAbort constructed, this=0x55c87a944cd0
[call95]

2024/06/05 10:41:54.955 kid1| 5,5| comm.cc(1004) comm_add_close_handler:
comm_add_close_handler: FD 16, AsyncCall=0x55c87a944cd0*1

2024/06/05 10:41:54.955 kid1| 5,4| AsyncCall.cc(29) AsyncCall: The
AsyncCall Comm::ConnOpener::timeout constructed, this=0x55c87a944d70
[call96]


Dig Output


dig www.google.com  AAAA


; <<>> DiG 9.16.23-RH <<>> www.google.com AAAA

;; global options: +cmd

;; Got answer:

;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 27477

;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1


;; OPT PSEUDOSECTION:

; EDNS: version: 0, flags:; udp: 4096

;; QUESTION SECTION:

;www.google.com. IN AAAA


;; ANSWER SECTION:

www.google.com. 237 IN AAAA 2607:f8b0:400a:804::2004


;; Query time: 0 msec

;; SERVER: 10.0.32.2#53(10.0.32.2)


Can you please help and let me know if I am missing anything.


Regards

Sachin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240605/3cde85c1/attachment.htm>

From rousskov at measurement-factory.com  Wed Jun  5 13:24:32 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 5 Jun 2024 09:24:32 -0400
Subject: [squid-users] IPv6 happy eyeball on dualstack host
In-Reply-To: <CALpWAcqmvQS9rD3TH+zt_ETBg+ZiuhiAPqLmaacqffwvT9iP2Q@mail.gmail.com>
References: <CALpWAcqmvQS9rD3TH+zt_ETBg+ZiuhiAPqLmaacqffwvT9iP2Q@mail.gmail.com>
Message-ID: <547a317b-3592-4aea-ad11-0667b6f0d015@measurement-factory.com>

On 2024-06-05 07:31, sachin gupta wrote:

> We are shifting to IPv6 dual stack hosts. As per squid documentation 
> <https://wiki.squid-cache.org/Features/IPv6>, IPv6 is enabled by 
> default.

That statement is a bit misleading: IPv6 detection or probing is enabled 
in default Squid builds (i.e. ./configure --enable-ipv6 is the default), 
but whether a Squid instance will actually "enable IPv6" also depends on 
the result of certain startup probes or checks. If those startup checks 
fail, Squid will not send DNS AAAA queries.


> As per documentation, based on DNS response squid will try both IP4 and 
> IPv6 if DNS return both addresses. 

FWIW, this summary does not quite match modern Squid behavior. The 
difference is _not_ important for your current triage because your Squid 
currently does not even request an IPv6 address from DNS. Once you fix 
that, you should _not_ expect Squid to use both IPv4 and IPv6 TCP/IP 
connections in every test case: Squid may or may not use both address 
families, depending on various runtime factors that affect Squid's Happy 
Eyeballs algorithm (e.g., see happy_eyeballs_connect_timeout directive).


> But I see that squid is only getting IPv4 address

To be more precise, your Squid does not send a DNS AAAA query after 
sending a DNS A query (no idnsSendSlaveAAAAQuery line after idnsALookup 
in your cache.log). That fact suggests that your Squid runs with 
disabled IPv6. I suggest the following triage steps:

1. Examine "/path/to/your/executable/squid -v" output to make sure your 
Squid executable is _not_ built with --disable-ipv6.

2. Examine level-1 cache.log for startup BCP 177 warnings like this one:
    WARNING: BCP 177 violation. Detected non-functional IPv6 loopback

3. Examine _early_ level-2 startup ProbeTransport messages. For example:
    $ your/squid -f your.squid.conf -N -X -d9 2>&1 | grep ProbeTransport
     ProbeTransport: Detected IPv6 hybrid or v4-mapping stack...
     ProbeTransport: Detected functional IPv6 loopback ...
     ProbeTransport: IPv6 transport Enabled


Someday, somebody will (a) completely remove --disable-ipv6 and (b) 
improve startup probing code to make steps 1 and 3 completely 
unnecessary. We have recently done a couple of baby steps towards (a).


HTH,

Alex.


> though with dis command I can see IPv6 address as well. 
> Also from same host, I am able to make curl command to google using IPv6.
> 
> DNS logs for squid
> 
> 24/06/05 10:41:54.953 kid1| 5,4| AsyncCallQueue.cc(59) fireNext: 
> entering helperHandleRead(conn4 local=[::] remote=[::] FD 13 flags=1, 
> data=0x55c87a45bb38, size=5, buf=0x55c87a45bd60)
> 
> 2024/06/05 10:41:54.953 kid1| 5,4| AsyncCall.cc(41) make: make call 
> helperHandleRead [call4]
> 
> 2024/06/05 10:41:54.953 kid1| 78,3| dns_internal.cc(1792) idnsALookup: 
> idnsALookup: buf is 32 bytes for www.google.com <http://www.google.com>, 
> id = 0xe006
> 
> 2024/06/05 10:41:54.953 kid1| 5,4| AsyncCall.cc(29) AsyncCall: The 
> AsyncCall helperHandleRead constructed, this=0x55c87a9301e0 [call89]
> 
> 2024/06/05 10:41:54.953 kid1| 5,5| Read.cc(58) comm_read_base: 
> comm_read, queueing read for conn4 local=[::] remote=[::] FD 13 flags=1; 
> asynCall 0x55c87a9301e0*1
> 
> 2024/06/05 10:41:54.954 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 13, 
> type=1, handler=1, client_data=0x7f183475a700, timeout=0
> 
> 2024/06/05 10:41:54.954 kid1| 5,4| AsyncCallQueue.cc(61) fireNext: 
> leaving helperHandleRead(conn4 local=[::] remote=[::] FD 13 flags=1, 
> data=0x55c87a45bb38, size=5, buf=0x55c87a45bd60)
> 
> 2024/06/05 10:41:54.955 kid1| 78,3| dns_internal.cc(1318) idnsRead: 
> idnsRead: starting with FD 11
> 
> 2024/06/05 10:41:54.955 kid1| 5,5| ModEpoll.cc(116) SetSelect: FD 11, 
> type=1, handler=1, client_data=0, timeout=0
> 
> 2024/06/05 10:41:54.955 kid1| 78,3| dns_internal.cc(1364) idnsRead: 
> idnsRead: FD 11: received 48 bytes from 10.0.32.2:53 <http://10.0.32.2:53>
> 
> 2024/06/05 10:41:54.955 kid1| 78,3| dns_internal.cc(1171) idnsGrokReply: 
> idnsGrokReply: QID 0xe006, 1 answers
> 
> 2024/06/05 10:41:54.955 kid1| 5,5| Connection.cc(99) cloneProfile: 
> 0x55c87a944210 made conn56 local=0.0.0.0 remote=142.251.215.228:80 
> <http://142.251.215.228:80> HIER_DIRECT flags=1
> 
> 2024/06/05 10:41:54.955 kid1| 5,5| Connection.cc(99) cloneProfile: 
> 0x55c87a944830 made conn57 local=0.0.0.0 remote=142.251.215.228:80 
> <http://142.251.215.228:80> HIER_DIRECT flags=1
> 
> 2024/06/05 10:41:54.955 kid1| 5,3| ConnOpener.cc(43) ConnOpener: will 
> connect to conn57 local=0.0.0.0 remote=142.251.215.228:80 
> <http://142.251.215.228:80> HIER_DIRECT flags=1 with 15 timeout
> 
> 2024/06/05 10:41:54.955 kid1| 5,5| comm.cc(428) comm_init_opened: conn58 
> local=0.0.0.0 remote=[::] FD 16 flags=1 is a new socket
> 
> 2024/06/05 10:41:54.955 kid1| 5,4| AsyncCall.cc(29) AsyncCall: The 
> AsyncCall Comm::ConnOpener::earlyAbort constructed, this=0x55c87a944cd0 
> [call95]
> 
> 2024/06/05 10:41:54.955 kid1| 5,5| comm.cc(1004) comm_add_close_handler: 
> comm_add_close_handler: FD 16, AsyncCall=0x55c87a944cd0*1
> 
> 2024/06/05 10:41:54.955 kid1| 5,4| AsyncCall.cc(29) AsyncCall: The 
> AsyncCall Comm::ConnOpener::timeout constructed, this=0x55c87a944d70 
> [call96]
> 
> 
> Dig Output
> 
> 
> dig www.google.com <http://www.google.com>AAAA
> 
> 
> ; <<>> DiG 9.16.23-RH <<>> www.google.com <http://www.google.com> AAAA
> 
> ;; global options: +cmd
> 
> ;; Got answer:
> 
> ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 27477
> 
> ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1
> 
> 
> ;; OPT PSEUDOSECTION:
> 
> ; EDNS: version: 0, flags:; udp: 4096
> 
> ;; QUESTION SECTION:
> 
> ;www.google.com <http://www.google.com>.INAAAA
> 
> 
> ;; ANSWER SECTION:
> 
> www.google.com <http://www.google.com>.237INAAAA2607:f8b0:400a:804::2004
> 
> 
> ;; Query time: 0 msec
> 
> ;; SERVER: 10.0.32.2#53(10.0.32.2)
> 
> 
> Can you please help and let me know if I am missing anything.
> 
> 
> Regards
> 
> Sachin
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From akash.karki at capitalone.com  Wed Jun  5 14:30:33 2024
From: akash.karki at capitalone.com (Akash Karki (CONT))
Date: Wed, 5 Jun 2024 15:30:33 +0100
Subject: [squid-users] Upgrade path from squid 4.15 to 6.x
In-Reply-To: <CAAXo-PEWdcZvCXBFVLU-PTG-LKdk5_BqFyYg+H1xWuteHWUAbA@mail.gmail.com>
References: <CAAXo-PEWdcZvCXBFVLU-PTG-LKdk5_BqFyYg+H1xWuteHWUAbA@mail.gmail.com>
Message-ID: <CAAXo-PH6Qf5A-=6CvArYG=8wUeG5gs-0jj32Uu3KhHSQM0HOWQ@mail.gmail.com>

Hi Team,

We are running on squid ver 4.15 and want to update to n-1 of the latest
ver(I believe 6.9 is the latest ver).

I want to understand if we can go straight from 4.15 to 6.x (n-1 of latest
version) without any intermediary steps or do we have to  update to
intermediary first and then move to the n-1 version of 6.9?

Kindly send us the detailed guidance!

On Wed, Jun 5, 2024 at 3:20?PM Akash Karki (CONT) <
akash.karki at capitalone.com> wrote:

> Hi Team,
>
> We are running on squid ver 4.15 and want to update to n-1 of the latest
> ver(I believe 6.9 is the latest ver).
>
> I want to understand if we can go straight from 4.15 to 6.x (n-1 of latest
> version) without any intermediary steps or do we have to  update to
> intermediary first and then move to the n-1 version of 6.9?
>
> Kindly send us the detailed guidance!
>
> --
> Thanks & Regards,
> Akash Karki
>
>
> Save Nature to Save yourself :)
>


-- 
Thanks & Regards,
Akash Karki
UK Hawkeye Team
*Slack : *#uk-monitoring
*Confluence : *UK Hawkeye
<https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye>

Save Nature to Save yourself :)

______________________________________________________________________



The information contained in this e-mail may be confidential and/or proprietary to Capital One and/or its affiliates and may only be used solely in performance of work or services for Capital One. The information transmitted herewith is intended only for use by the individual or entity to which it is addressed. If the reader of this message is not the intended recipient, you are hereby notified that any review, retransmission, dissemination, distribution, copying or other use of, or taking of any action in reliance upon this information is strictly prohibited. If you have received this communication in error, please contact the sender and delete the material from your computer.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240605/6639115d/attachment.htm>

From ngtech1ltd at gmail.com  Wed Jun  5 14:47:25 2024
From: ngtech1ltd at gmail.com (NgTech LTD)
Date: Wed, 5 Jun 2024 17:47:25 +0300
Subject: [squid-users] Upgrade path from squid 4.15 to 6.x
In-Reply-To: <CAAXo-PH6Qf5A-=6CvArYG=8wUeG5gs-0jj32Uu3KhHSQM0HOWQ@mail.gmail.com>
References: <CAAXo-PEWdcZvCXBFVLU-PTG-LKdk5_BqFyYg+H1xWuteHWUAbA@mail.gmail.com>
 <CAAXo-PH6Qf5A-=6CvArYG=8wUeG5gs-0jj32Uu3KhHSQM0HOWQ@mail.gmail.com>
Message-ID: <CABA8h=SWacCiMzgsRYvU0rynqxmBAY0ZfLz3JrUqgwZb9kk7dw@mail.gmail.com>

Depends on the config structure.
If you can send me a private email with the config reduced sensitive
details it will to understand the scenario.

Eliezer

?????? ??? ??, 5 ????? 2024, 17:31, ??? Akash Karki (CONT) ?<
akash.karki at capitalone.com>:

> Hi Team,
>
> We are running on squid ver 4.15 and want to update to n-1 of the latest
> ver(I believe 6.9 is the latest ver).
>
> I want to understand if we can go straight from 4.15 to 6.x (n-1 of latest
> version) without any intermediary steps or do we have to  update to
> intermediary first and then move to the n-1 version of 6.9?
>
> Kindly send us the detailed guidance!
>
> On Wed, Jun 5, 2024 at 3:20?PM Akash Karki (CONT) <
> akash.karki at capitalone.com> wrote:
>
>> Hi Team,
>>
>> We are running on squid ver 4.15 and want to update to n-1 of the latest
>> ver(I believe 6.9 is the latest ver).
>>
>> I want to understand if we can go straight from 4.15 to 6.x (n-1 of
>> latest version) without any intermediary steps or do we have to  update to
>> intermediary first and then move to the n-1 version of 6.9?
>>
>> Kindly send us the detailed guidance!
>>
>> --
>> Thanks & Regards,
>> Akash Karki
>>
>>
>> Save Nature to Save yourself :)
>>
>
>
> --
> Thanks & Regards,
> Akash Karki
> UK Hawkeye Team
> *Slack : *#uk-monitoring
> *Confluence : *UK Hawkeye
> <https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye>
>
> Save Nature to Save yourself :)
> ------------------------------
>
>
> The information contained in this e-mail may be confidential and/or
> proprietary to Capital One and/or its affiliates and may only be used
> solely in performance of work or services for Capital One. The information
> transmitted herewith is intended only for use by the individual or entity
> to which it is addressed. If the reader of this message is not the intended
> recipient, you are hereby notified that any review, retransmission,
> dissemination, distribution, copying or other use of, or taking of any
> action in reliance upon this information is strictly prohibited. If you
> have received this communication in error, please contact the sender and
> delete the material from your computer.
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240605/9be24241/attachment.htm>

From akash.karki at capitalone.com  Wed Jun  5 14:55:39 2024
From: akash.karki at capitalone.com (Akash Karki (CONT))
Date: Wed, 5 Jun 2024 15:55:39 +0100
Subject: [squid-users] [External Sender] Re: Upgrade path from squid
 4.15 to 6.x
In-Reply-To: <CABA8h=SWacCiMzgsRYvU0rynqxmBAY0ZfLz3JrUqgwZb9kk7dw@mail.gmail.com>
References: <CAAXo-PEWdcZvCXBFVLU-PTG-LKdk5_BqFyYg+H1xWuteHWUAbA@mail.gmail.com>
 <CAAXo-PH6Qf5A-=6CvArYG=8wUeG5gs-0jj32Uu3KhHSQM0HOWQ@mail.gmail.com>
 <CABA8h=SWacCiMzgsRYvU0rynqxmBAY0ZfLz3JrUqgwZb9kk7dw@mail.gmail.com>
Message-ID: <CAAXo-PF_UtD1C-rSKFprv1jHqLE=FEgcTrja7LjjZ1pgrnpozg@mail.gmail.com>

Hi  Eliezer,

Thanks for the reply!
I can't share the details with you over mail, sorry for that!

Is there anything which I can refer to in order to figure it out or if we
can get onto a call to chat about it?

On Wed, Jun 5, 2024 at 3:47?PM NgTech LTD <ngtech1ltd at gmail.com> wrote:

> Depends on the config structure.
> If you can send me a private email with the config reduced sensitive
> details it will to understand the scenario.
>
> Eliezer
>
> ?????? ??? ??, 5 ????? 2024, 17:31, ??? Akash Karki (CONT) ?<
> akash.karki at capitalone.com>:
>
>> Hi Team,
>>
>> We are running on squid ver 4.15 and want to update to n-1 of the latest
>> ver(I believe 6.9 is the latest ver).
>>
>> I want to understand if we can go straight from 4.15 to 6.x (n-1 of
>> latest version) without any intermediary steps or do we have to  update to
>> intermediary first and then move to the n-1 version of 6.9?
>>
>> Kindly send us the detailed guidance!
>>
>> On Wed, Jun 5, 2024 at 3:20?PM Akash Karki (CONT) <
>> akash.karki at capitalone.com> wrote:
>>
>>> Hi Team,
>>>
>>> We are running on squid ver 4.15 and want to update to n-1 of the latest
>>> ver(I believe 6.9 is the latest ver).
>>>
>>> I want to understand if we can go straight from 4.15 to 6.x (n-1 of
>>> latest version) without any intermediary steps or do we have to  update to
>>> intermediary first and then move to the n-1 version of 6.9?
>>>
>>> Kindly send us the detailed guidance!
>>>
>>> --
>>> Thanks & Regards,
>>> Akash Karki
>>>
>>>
>>> Save Nature to Save yourself :)
>>>
>>
>>
>> --
>> Thanks & Regards,
>> Akash Karki
>> UK Hawkeye Team
>> *Slack : *#uk-monitoring
>> *Confluence : *UK Hawkeye
>> <https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye>
>>
>> Save Nature to Save yourself :)
>> ------------------------------
>>
>> The information contained in this e-mail may be confidential and/or
>> proprietary to Capital One and/or its affiliates and may only be used
>> solely in performance of work or services for Capital One. The information
>> transmitted herewith is intended only for use by the individual or entity
>> to which it is addressed. If the reader of this message is not the intended
>> recipient, you are hereby notified that any review, retransmission,
>> dissemination, distribution, copying or other use of, or taking of any
>> action in reliance upon this information is strictly prohibited. If you
>> have received this communication in error, please contact the sender and
>> delete the material from your computer.
>>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
>> <https://urldefense.com/v3/__https://lists.squid-cache.org/listinfo/squid-users__;!!FrPt2g6CO4Wadw!Nl80R-tzB0i5Q-J2-AbWaw9wxpP_lm8qaStBLdJ1EmvYv6aAGhjKddfC9XhylijkoPu1NT8XEA5sprebGLY7BEQ$>
>>
>

-- 
Thanks & Regards,
Akash Karki
UK Hawkeye Team
*Slack : *#uk-monitoring
*Confluence : *UK Hawkeye
<https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye>

Save Nature to Save yourself :)

______________________________________________________________________



The information contained in this e-mail may be confidential and/or proprietary to Capital One and/or its affiliates and may only be used solely in performance of work or services for Capital One. The information transmitted herewith is intended only for use by the individual or entity to which it is addressed. If the reader of this message is not the intended recipient, you are hereby notified that any review, retransmission, dissemination, distribution, copying or other use of, or taking of any action in reliance upon this information is strictly prohibited. If you have received this communication in error, please contact the sender and delete the material from your computer.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240605/1a0e30a8/attachment.htm>

From rousskov at measurement-factory.com  Wed Jun  5 15:31:29 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 5 Jun 2024 11:31:29 -0400
Subject: [squid-users] Upgrade path from squid 4.15 to 6.x
In-Reply-To: <CAAXo-PH6Qf5A-=6CvArYG=8wUeG5gs-0jj32Uu3KhHSQM0HOWQ@mail.gmail.com>
References: <CAAXo-PEWdcZvCXBFVLU-PTG-LKdk5_BqFyYg+H1xWuteHWUAbA@mail.gmail.com>
 <CAAXo-PH6Qf5A-=6CvArYG=8wUeG5gs-0jj32Uu3KhHSQM0HOWQ@mail.gmail.com>
Message-ID: <e91a54cb-3cd4-4f71-a46b-d6a9e053bbb5@measurement-factory.com>

On 2024-06-05 10:30, Akash Karki (CONT) wrote:

> I want to understand if we can go straight from 4.15 to 6.x (n-1 of 
> latest version) without any intermediary steps or do we have?to? update 
> to intermediary first and then move to the n-1 version of 6.9?

Go straight to the latest v6. While doing that, study release notes for 
all the Squid versions you are skipping to flag configuration directives 
that you need to adjust (and other upgrade caveats).

Needless to say, test before you deploy the upgraded version -- a lot of 
things have changed since v4, and not all of the changes may be covered 
in release notes. When in doubt, ask (specific) questions.


HTH,

Alex.



> On Wed, Jun 5, 2024 at 3:20?PM Akash Karki (CONT) wrote:
> 
>     Hi Team,
> 
>     We are running on squid ver 4.15 and want to update to n-1 of the
>     latest ver(I believe 6.9 is the latest ver).
> 
>     I want to understand if we can go straight from 4.15 to 6.x (n-1 of
>     latest version) without any intermediary steps or do we have?to 
>     update to intermediary first and then move to the n-1 version of 6.9?
> 
>     Kindly send us the detailed guidance!
> 
>     -- 
>     Thanks & Regards,
>     Akash Karki
> 
> 
>     Save Nature to Save yourself :)
> 
> 
> 
> -- 
> Thanks & Regards,
> Akash Karki
> UK Hawkeye Team*
> *
> *Slack : *#uk-monitoring
> *Confluence : *UK Hawkeye 
> <https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye>
> 
> Save Nature to Save yourself :)
> ------------------------------------------------------------------------
> 
> 
> The information contained in this e-mail may be confidential and/or 
> proprietary to Capital One and/or its affiliates and may only be used 
> solely in performance of work or services for Capital One. The 
> information transmitted herewith is intended only for use by the 
> individual or entity to which it is addressed. If the reader of this 
> message is not the intended recipient, you are hereby notified that any 
> review, retransmission, dissemination, distribution, copying or other 
> use of, or taking of any action in reliance upon this information is 
> strictly prohibited. If you have received this communication in error, 
> please contact the sender and delete the material from your computer.
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From akash.karki at capitalone.com  Wed Jun  5 16:05:49 2024
From: akash.karki at capitalone.com (Akash Karki (CONT))
Date: Wed, 5 Jun 2024 17:05:49 +0100
Subject: [squid-users] [External Sender] Re: Upgrade path from squid
 4.15 to 6.x
In-Reply-To: <e91a54cb-3cd4-4f71-a46b-d6a9e053bbb5@measurement-factory.com>
References: <CAAXo-PEWdcZvCXBFVLU-PTG-LKdk5_BqFyYg+H1xWuteHWUAbA@mail.gmail.com>
 <CAAXo-PH6Qf5A-=6CvArYG=8wUeG5gs-0jj32Uu3KhHSQM0HOWQ@mail.gmail.com>
 <e91a54cb-3cd4-4f71-a46b-d6a9e053bbb5@measurement-factory.com>
Message-ID: <CAAXo-PEC9LXLdrSVmExMCKAo5Zg+gDQqeVy1Qk3VkZMYM3wZwg@mail.gmail.com>

Hi Alex,

Thanks a lot for the response!

Anything specific do we need to check from any documents?
If I can get any document to refer to, that would be great!!

On Wed, Jun 5, 2024 at 4:31?PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 2024-06-05 10:30, Akash Karki (CONT) wrote:
>
> > I want to understand if we can go straight from 4.15 to 6.x (n-1 of
> > latest version) without any intermediary steps or do we have to  update
> > to intermediary first and then move to the n-1 version of 6.9?
>
> Go straight to the latest v6. While doing that, study release notes for
> all the Squid versions you are skipping to flag configuration directives
> that you need to adjust (and other upgrade caveats).
>
> Needless to say, test before you deploy the upgraded version -- a lot of
> things have changed since v4, and not all of the changes may be covered
> in release notes. When in doubt, ask (specific) questions.
>
>
> HTH,
>
> Alex.
>
>
>
> > On Wed, Jun 5, 2024 at 3:20?PM Akash Karki (CONT) wrote:
> >
> >     Hi Team,
> >
> >     We are running on squid ver 4.15 and want to update to n-1 of the
> >     latest ver(I believe 6.9 is the latest ver).
> >
> >     I want to understand if we can go straight from 4.15 to 6.x (n-1 of
> >     latest version) without any intermediary steps or do we have to
> >     update to intermediary first and then move to the n-1 version of 6.9?
> >
> >     Kindly send us the detailed guidance!
> >
> >     --
> >     Thanks & Regards,
> >     Akash Karki
> >
> >
> >     Save Nature to Save yourself :)
> >
> >
> >
> > --
> > Thanks & Regards,
> > Akash Karki
> > UK Hawkeye Team*
> > *
> > *Slack : *#uk-monitoring
> > *Confluence : *UK Hawkeye
> > <https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye>
> >
> > Save Nature to Save yourself :)
> > ------------------------------------------------------------------------
> >
> >
> > The information contained in this e-mail may be confidential and/or
> > proprietary to Capital One and/or its affiliates and may only be used
> > solely in performance of work or services for Capital One. The
> > information transmitted herewith is intended only for use by the
> > individual or entity to which it is addressed. If the reader of this
> > message is not the intended recipient, you are hereby notified that any
> > review, retransmission, dissemination, distribution, copying or other
> > use of, or taking of any action in reliance upon this information is
> > strictly prohibited. If you have received this communication in error,
> > please contact the sender and delete the material from your computer.
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> >
> https://urldefense.com/v3/__https://lists.squid-cache.org/listinfo/squid-users__;!!FrPt2g6CO4Wadw!LFF_SotEcUzjJJWv4JR26UjdlUap9Xu0U8n45FREcUUkuWDemCLyI2vLlkSciqHShz-wFylLp3e-TZwmlCNKQc28HngJzWvg$
>
>

-- 
Thanks & Regards,
Akash Karki
UK Hawkeye Team
*Slack : *#uk-monitoring
*Confluence : *UK Hawkeye
<https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye>

Save Nature to Save yourself :)

______________________________________________________________________



The information contained in this e-mail may be confidential and/or proprietary to Capital One and/or its affiliates and may only be used solely in performance of work or services for Capital One. The information transmitted herewith is intended only for use by the individual or entity to which it is addressed. If the reader of this message is not the intended recipient, you are hereby notified that any review, retransmission, dissemination, distribution, copying or other use of, or taking of any action in reliance upon this information is strictly prohibited. If you have received this communication in error, please contact the sender and delete the material from your computer.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240605/877edf26/attachment.htm>

From rousskov at measurement-factory.com  Wed Jun  5 16:30:33 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 5 Jun 2024 12:30:33 -0400
Subject: [squid-users] [External Sender] Re: Upgrade path from squid
 4.15 to 6.x
In-Reply-To: <CAAXo-PEC9LXLdrSVmExMCKAo5Zg+gDQqeVy1Qk3VkZMYM3wZwg@mail.gmail.com>
References: <CAAXo-PEWdcZvCXBFVLU-PTG-LKdk5_BqFyYg+H1xWuteHWUAbA@mail.gmail.com>
 <CAAXo-PH6Qf5A-=6CvArYG=8wUeG5gs-0jj32Uu3KhHSQM0HOWQ@mail.gmail.com>
 <e91a54cb-3cd4-4f71-a46b-d6a9e053bbb5@measurement-factory.com>
 <CAAXo-PEC9LXLdrSVmExMCKAo5Zg+gDQqeVy1Qk3VkZMYM3wZwg@mail.gmail.com>
Message-ID: <2c7e7fb9-4d07-4e28-9ad0-bd4c443e8c21@measurement-factory.com>

On 2024-06-05 12:05, Akash Karki (CONT) wrote:

> Anything specific do we need to check from any documents?

Yes, anything that mentions features or directives you are using (or 
would like to use).


> If I can get any document to refer to, that would be?great!!

Release notes for Squid vN should be in doc/release-notes/release-N.html 
file inside official Squid source code tarball for vN. For a given major 
Squid version, use the tarball for latest available minor release. 
Official tarballs for various versions are currently available by 
following version-specific links at http://www.squid-cache.org/Versions/

The following wiki pages may also contain useful info:
https://wiki.squid-cache.org/Releases/Squid-5
https://wiki.squid-cache.org/Releases/Squid-6


HTH,

Alex.


> On Wed, Jun 5, 2024 at 4:31?PM Alex Rousskov wrote:
> 
>     On 2024-06-05 10:30, Akash Karki (CONT) wrote:
> 
>      > I want to understand if we can go straight from 4.15 to 6.x (n-1 of
>      > latest version) without any intermediary steps or do we have?to 
>     update
>      > to intermediary first and then move to the n-1 version of 6.9?
> 
>     Go straight to the latest v6. While doing that, study release notes for
>     all the Squid versions you are skipping to flag configuration
>     directives
>     that you need to adjust (and other upgrade caveats).
> 
>     Needless to say, test before you deploy the upgraded version -- a
>     lot of
>     things have changed since v4, and not all of the changes may be covered
>     in release notes. When in doubt, ask (specific) questions.
> 
> 
>     HTH,
> 
>     Alex.
> 
> 
> 
>      > On Wed, Jun 5, 2024 at 3:20?PM Akash Karki (CONT) wrote:
>      >
>      >? ? ?Hi Team,
>      >
>      >? ? ?We are running on squid ver 4.15 and want to update to n-1 of the
>      >? ? ?latest ver(I believe 6.9 is the latest ver).
>      >
>      >? ? ?I want to understand if we can go straight from 4.15 to 6.x
>     (n-1 of
>      >? ? ?latest version) without any intermediary steps or do we have?to
>      >? ? ?update to intermediary first and then move to the n-1 version
>     of 6.9?
>      >
>      >? ? ?Kindly send us the detailed guidance!
>      >
>      >? ? ?--
>      >? ? ?Thanks & Regards,
>      >? ? ?Akash Karki
>      >
>      >
>      >? ? ?Save Nature to Save yourself :)
>      >
>      >
>      >
>      > --
>      > Thanks & Regards,
>      > Akash Karki
>      > UK Hawkeye Team*
>      > *
>      > *Slack : *#uk-monitoring
>      > *Confluence : *UK Hawkeye
>      > <https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye
>     <https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye>>
>      >
>      > Save Nature to Save yourself :)
>      >
>     ------------------------------------------------------------------------
>      >
>      >
>      > The information contained in this e-mail may be confidential and/or
>      > proprietary to Capital One and/or its affiliates and may only be
>     used
>      > solely in performance of work or services for Capital One. The
>      > information transmitted herewith is intended only for use by the
>      > individual or entity to which it is addressed. If the reader of this
>      > message is not the intended recipient, you are hereby notified
>     that any
>      > review, retransmission, dissemination, distribution, copying or
>     other
>      > use of, or taking of any action in reliance upon this information is
>      > strictly prohibited. If you have received this communication in
>     error,
>      > please contact the sender and delete the material from your computer.
>      >
>      >
>      >
>      > _______________________________________________
>      > squid-users mailing list
>      > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>      >
>     https://urldefense.com/v3/__https://lists.squid-cache.org/listinfo/squid-users__;!!FrPt2g6CO4Wadw!LFF_SotEcUzjJJWv4JR26UjdlUap9Xu0U8n45FREcUUkuWDemCLyI2vLlkSciqHShz-wFylLp3e-TZwmlCNKQc28HngJzWvg$ <https://urldefense.com/v3/__https://lists.squid-cache.org/listinfo/squid-users__;!!FrPt2g6CO4Wadw!LFF_SotEcUzjJJWv4JR26UjdlUap9Xu0U8n45FREcUUkuWDemCLyI2vLlkSciqHShz-wFylLp3e-TZwmlCNKQc28HngJzWvg$>
> 
> 
> 
> -- 
> Thanks & Regards,
> Akash Karki
> UK Hawkeye Team*
> *
> *Slack : *#uk-monitoring
> *Confluence : *UK Hawkeye 
> <https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye>
> 
> Save Nature to Save yourself :)
> ------------------------------------------------------------------------
> 
> 
> The information contained in this e-mail may be confidential and/or 
> proprietary to Capital One and/or its affiliates and may only be used 
> solely in performance of work or services for Capital One. The 
> information transmitted herewith is intended only for use by the 
> individual or entity to which it is addressed. If the reader of this 
> message is not the intended recipient, you are hereby notified that any 
> review, retransmission, dissemination, distribution, copying or other 
> use of, or taking of any action in reliance upon this information is 
> strictly prohibited. If you have received this communication in error, 
> please contact the sender and delete the material from your computer.
> 
> 



From squid at kretz.net  Wed Jun  5 17:24:10 2024
From: squid at kretz.net (Kevin)
Date: Wed, 5 Jun 2024 17:24:10 +0000 (UTC)
Subject: [squid-users] can't explain 403 denied for authenticated
In-Reply-To: <mailman.3.1717070401.1412775.squid-users@lists.squid-cache.org>
References: <mailman.3.1717070401.1412775.squid-users@lists.squid-cache.org>
Message-ID: <1999639654.1878278.1717608250039.JavaMail.zimbra@kretz.net>


I appreciate very much your looking at my question. 

>Date: Thu, 30 May 2024 22:15:27 +1200 
>From: Amos Jeffries <squid3 at treenet.co.nz> 
>To: squid-users at lists.squid-cache.org 
>Subject: Re: [squid-users] can't explain 403 denied for authenticated 
> user 
>Message-ID: <96746157-da51-47db-8d52-d65239f2717e at treenet.co.nz> 
>Content-Type: text/plain; charset=UTF-8; format=flowed 
> 
>On 25/05/24 07:28, Kevin wrote: 
>> Hi, 
>> 
>> We have 2 external ACLs that take a request's data (IP, authenticated 
>> username, URL, user-agent, etc) and uses that information to determine 
>> whether a user or host should be permitted to access that URL.?? It 
>> almost always works well, but we have a recurring occasional issue that 
>> I can't figure out. 
>> 
>> When it occurs, it's always around 4AM.?? This particular request occurs 
>> often - averages about once a second throughout the day. 
>> 
>> What we see is a "403 forbidden" for a (should be) permitted site from 
>> an authenticated user from the same IP/user and to the same site that 
>> gets a "202 connection established" every other time. 
> 
>Is maybe 4am the time when your auth system refreshes all nonce? 
> - thus making any currently in-use by the clients invalid until they 
>re-auth. You might see a mix of 403/401/407 in a bunch at such times. 

My auth system is just squid with one flat file each for basic and digest authentication (we allow basic only if an application doesn't support digest). 


>Or maybe in a similar style one/some of the clients is broken and fails 
>to update its nonce before it expires at 4am? 

The client is a Java-based application. I can find out more from the team that wrote it. 

> - looking at which client agent and IP were getting the 403 and/or the 
>nonce which received 403 will give you hints about this possibility. 

Oh: it's only this one application from this one particular host. 


> 
>Or your network router(s) do garbage collection and terminate 
>long-running connections to free up TCP resources? 
> - thus forcing a lot of client re-connects at 4am, which may: 
> a) overload the auth system/helper, or 
> b) break a transaction that included nonce update for clients - 
>resulting in their next request being invalid nonce. 

I'm not aware of a 4AM connection-terminating task but will confirm. As mentioned (in answer to a), the auth system is just squid. Re: b - I hadn't thought of that. 


> 
> 
>Or maybe you have log processing software that does "squid -k restart" 
>instead of the proper "squid -k rotate" to get access to the log files? 

I hadn't checked that! But logrotate runs at 00:00 and the rotate script does use "squid -k rotate". 

>Or maybe your auth system has a limit on how large nonce-count can become? 
> - I notice that the working request has 0x2F uses and the forbidden 
>has 0x35 (suspiciously close to 50 in decimal) 

I don't know what that is. I didn't find a lot of helpful detail on squid's digest auth implementation. 

> 
>> 
>> The difference I see in the logs:? though all the digest auth info looks 
>> okay, the %un field in the log for the usual (successful) request is the 
>> authenticated username, while in the failed request, it's "-".?? So 
>> though there hasn't been an authentication error or "authentication 
>> required" in the log - and the username is in the authentication details 
>> in the log entry -? it seems like squid isn't recognizing that username 
>> as %un. 
> 
> 
>Be aware that a properly behaving client will *not* send credentials 
>until they are requested, after which it should *always* send 
>credentials on that same connection (even if they are not requested 
>explicitly). 

>That means some requests on a multiplex/pipeline/keep-alive connection 
>MAY arrive with credentials and be accepted(2xx)/denied(403) without 
>authentication having occured. Entirely due to your *_access directives 
>sequence. In these cases the log will show auth headers but no value for 
>%un and/or %ul. 
> 
> 
>> 
>> My squid.conf first tests a request to see if an unauthenticated request 
>> from a particular host is permitted.? That external ACL doesn't take a 
>> username as an argument.?? If that external ACL passes, the request is 
>> allowed. 
>> 
> 
>Please *show* the config lines rather than describing what you *think* 
>they do. Their exact ordering matters *a lot*. 
> Obfuscation of sensitive details is okay/expected so long as you makes 
>it easy for us to tell that value A and value B are different. 
> 
>FWIW; if your config file is *actually* containing only what you 
>described it is missing a number of things necessary to have a safe and 
>secure proxy. A look at your full config (without comments or empty 
>lines) will help us point out any unnoticed issues for you to consider 
>fixing. 


Understood. Here it is: 


acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
acl windows_net src 172.18.114.0/24
acl sample_host src 172.18.115.1/32
acl rsync port 873
acl SSL_ports port 443
acl SSL_ports port 873		#873 is rsync
acl Safe_ports port 80		# http
acl Safe_ports port 21		# ftp
acl Safe_ports port 443		# https
acl Safe_ports port 70		# gopher
acl Safe_ports port 210		# wais
acl Safe_ports port 1025-65535	# unregistered ports
acl Safe_ports port 280		# http-mgmt
acl Safe_ports port 488		# gss-http
acl Safe_ports port 591		# filemaker
acl Safe_ports port 777		# multiling http
acl Safe_ports port 873
acl CONNECT method CONNECT
acl PURGE method PURGE
acl localhost src 127.0.0.1
http_access allow PURGE localhost
http_access deny PURGE
acl URN proto URN
http_access deny URN
http_access deny manager
acl API_FIREFOX dstdomain api.profiler.firefox.com
http_access deny API_FIREFOX
acl ff_browser browser ^Mozilla/5\.0
acl rma_ua browser ^RMA/1\.0.*compatible;.RealMedia
uri_whitespace encode
acl trellix_phone_cloud dstdomain amcore-ens.rest.gti.trellix.com
http_access deny trellix_phone_cloud
external_acl_type host_based_filter children-max=15 ttl=0 %ACL %DATA %SRC %>rd %>rP  /PATH/TO/FILTER/SCRIPT.py
acl HostBasedRules external host_based_filter
http_access allow HostBasedRules
auth_param digest program /usr/lib/squid/digest_file_auth -c /etc/squid/passwd
auth_param digest realm squid
auth_param digest children 2
auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/basic_passwd
auth_param basic children 2
auth_param basic realm squidb
auth_param basic credentialsttl 2 hours
acl auth_users proxy_auth REQUIRED
external_acl_type custom_acl_db children-max=15 ttl=0 %ACL %DATA %ul %SRC %>rd %>rP %credentials /PATH/TO/FILTER/SCRIPT.py
acl CustomAclDB external custom_acl_db
http_access allow CustomAclDB
acl CRLs url_regex "/etc/squid/conf.d/CRL_urls.txt"
http_access allow CRLs
deny_info 303:https://abc.def.com/
http_access deny all
acl apache rep_header Server ^Apache
icp_access allow localnet
icp_access deny all
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localhost
http_port 3128
coredump_dir /var/cache/squid
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320
logformat squid %ts.%03tu %6tr %>a %Ss/%>Hs %<st %rm %ru %un %Sh/%<A %mt
logformat squidmime %ul %ts.%03tu %6tr %>a %Ss/%>Hs %<st %rm %ru %un %Sh/%<A %mt [%>h] [%<h]
logformat common %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %Ss:%Sh
logformat combined %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
logformat ip_port %ts %tu %>a %>p %<lp %<a %<p %dt %tr %un %>ru %Ss
access_log daemon:/var/log/squid/access.log combined
access_log daemon:/var/log/squid/network.log ip_port
cache_log /var/log/squid/cache.log
cache_store_log /var/log/squid/store.log
access_log daemon:/var/log/squid/useragent.log useragent
visible_hostname proxy.abc.com
cache deny all 


> 
>> The next line in squid.conf is 
>> 
>> acl auth_users proxy_auth REQUIRED 
>> 
> 
>FYI the above just means that Squid is using authentication. It says 
>nothing about when the authentication will be (or not be) performed. 
> 
> 
>> ... and after that, the external ACL that takes the username as well as 
>> the other info. 
>> 
> 
> 
>HTH 
>Amos 



From: squid-users-request at lists.squid-cache.org 
To: "squid-users" <squid-users at lists.squid-cache.org> 
Sent: Thursday, May 30, 2024 8:00:01 AM 
Subject: squid-users Digest, Vol 117, Issue 31 


I appreciate very much your looking at my question. 

>Date: Thu, 30 May 2024 22:15:27 +1200 
>From: Amos Jeffries <squid3 at treenet.co.nz> 
>To: squid-users at lists.squid-cache.org 
>Subject: Re: [squid-users] can't explain 403 denied for authenticated 
> user 
>Message-ID: <96746157-da51-47db-8d52-d65239f2717e at treenet.co.nz> 
>Content-Type: text/plain; charset=UTF-8; format=flowed 
> 
>On 25/05/24 07:28, Kevin wrote: 
>> Hi, 
>> 
>> We have 2 external ACLs that take a request's data (IP, authenticated 
>> username, URL, user-agent, etc) and uses that information to determine 
>> whether a user or host should be permitted to access that URL.?? It 
>> almost always works well, but we have a recurring occasional issue that 
>> I can't figure out. 
>> 
>> When it occurs, it's always around 4AM.?? This particular request occurs 
>> often - averages about once a second throughout the day. 
>> 
>> What we see is a "403 forbidden" for a (should be) permitted site from 
>> an authenticated user from the same IP/user and to the same site that 
>> gets a "202 connection established" every other time. 
> 
>Is maybe 4am the time when your auth system refreshes all nonce? 
> - thus making any currently in-use by the clients invalid until they 
>re-auth. You might see a mix of 403/401/407 in a bunch at such times. 

My auth system is just squid with one flat file each for basic and digest authentication (we allow basic only if an application doesn't support digest). 


>Or maybe in a similar style one/some of the clients is broken and fails 
>to update its nonce before it expires at 4am? 

The client is a Java-based application. I can find out more from the team that wrote it. 

> - looking at which client agent and IP were getting the 403 and/or the 
>nonce which received 403 will give you hints about this possibility. 

Oh: it's only this one application from this one particular host. 


> 
>Or your network router(s) do garbage collection and terminate 
>long-running connections to free up TCP resources? 
> - thus forcing a lot of client re-connects at 4am, which may: 
> a) overload the auth system/helper, or 
> b) break a transaction that included nonce update for clients - 
>resulting in their next request being invalid nonce. 

I'm not aware of a 4AM connection-terminating task but will confirm. As mentioned (in answer to a), the auth system is just squid. Re: b - I hadn't thought of that. 


> 
> 
>Or maybe you have log processing software that does "squid -k restart" 
>instead of the proper "squid -k rotate" to get access to the log files? 

I hadn't checked that! But logrotate runs at 00:00 and the rotate script does use "squid -k rotate". 

>Or maybe your auth system has a limit on how large nonce-count can become? 
> - I notice that the working request has 0x2F uses and the forbidden 
>has 0x35 (suspiciously close to 50 in decimal) 

I don't know what that is. I didn't find a lot of helpful detail on squid's digest auth implementation. 

> 
>> 
>> The difference I see in the logs:? though all the digest auth info looks 
>> okay, the %un field in the log for the usual (successful) request is the 
>> authenticated username, while in the failed request, it's "-".?? So 
>> though there hasn't been an authentication error or "authentication 
>> required" in the log - and the username is in the authentication details 
>> in the log entry -? it seems like squid isn't recognizing that username 
>> as %un. 
> 
> 
>Be aware that a properly behaving client will *not* send credentials 
>until they are requested, after which it should *always* send 
>credentials on that same connection (even if they are not requested 
>explicitly). 

>That means some requests on a multiplex/pipeline/keep-alive connection 
>MAY arrive with credentials and be accepted(2xx)/denied(403) without 
>authentication having occured. Entirely due to your *_access directives 
>sequence. In these cases the log will show auth headers but no value for 
>%un and/or %ul. 
> 
> 
>> 
>> My squid.conf first tests a request to see if an unauthenticated request 
>> from a particular host is permitted.? That external ACL doesn't take a 
>> username as an argument.?? If that external ACL passes, the request is 
>> allowed. 
>> 
> 
>Please *show* the config lines rather than describing what you *think* 
>they do. Their exact ordering matters *a lot*. 
> Obfuscation of sensitive details is okay/expected so long as you makes 
>it easy for us to tell that value A and value B are different. 
> 
>FWIW; if your config file is *actually* containing only what you 
>described it is missing a number of things necessary to have a safe and 
>secure proxy. A look at your full config (without comments or empty 
>lines) will help us point out any unnoticed issues for you to consider 
>fixing. 


Understood. Here it is: 


acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
acl windows_net src 172.18.114.0/24
acl sample_host src 172.18.115.1/32
acl rsync port 873
acl SSL_ports port 443
acl SSL_ports port 873		#873 is rsync
acl Safe_ports port 80		# http
acl Safe_ports port 21		# ftp
acl Safe_ports port 443		# https
acl Safe_ports port 70		# gopher
acl Safe_ports port 210		# wais
acl Safe_ports port 1025-65535	# unregistered ports
acl Safe_ports port 280		# http-mgmt
acl Safe_ports port 488		# gss-http
acl Safe_ports port 591		# filemaker
acl Safe_ports port 777		# multiling http
acl Safe_ports port 873
acl CONNECT method CONNECT
acl PURGE method PURGE
acl localhost src 127.0.0.1
http_access allow PURGE localhost
http_access deny PURGE
acl URN proto URN
http_access deny URN
http_access deny manager
acl API_FIREFOX dstdomain api.profiler.firefox.com
http_access deny API_FIREFOX
acl ff_browser browser ^Mozilla/5\.0
acl rma_ua browser ^RMA/1\.0.*compatible;.RealMedia
uri_whitespace encode
acl trellix_phone_cloud dstdomain amcore-ens.rest.gti.trellix.com
http_access deny trellix_phone_cloud
external_acl_type host_based_filter children-max=15 ttl=0 %ACL %DATA %SRC %>rd %>rP  /PATH/TO/FILTER/SCRIPT.py
acl HostBasedRules external host_based_filter
http_access allow HostBasedRules
auth_param digest program /usr/lib/squid/digest_file_auth -c /etc/squid/passwd
auth_param digest realm squid
auth_param digest children 2
auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/basic_passwd
auth_param basic children 2
auth_param basic realm squidb
auth_param basic credentialsttl 2 hours
acl auth_users proxy_auth REQUIRED
external_acl_type custom_acl_db children-max=15 ttl=0 %ACL %DATA %ul %SRC %>rd %>rP %credentials /PATH/TO/FILTER/SCRIPT.py
acl CustomAclDB external custom_acl_db
http_access allow CustomAclDB
acl CRLs url_regex "/etc/squid/conf.d/CRL_urls.txt"
http_access allow CRLs
deny_info 303:https://abc.def.com/
http_access deny all
acl apache rep_header Server ^Apache
icp_access allow localnet
icp_access deny all
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localhost
http_port 3128
coredump_dir /var/cache/squid
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320
logformat squid %ts.%03tu %6tr %>a %Ss/%>Hs %<st %rm %ru %un %Sh/%<A %mt
logformat squidmime %ul %ts.%03tu %6tr %>a %Ss/%>Hs %<st %rm %ru %un %Sh/%<A %mt [%>h] [%<h]
logformat common %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %Ss:%Sh
logformat combined %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
logformat ip_port %ts %tu %>a %>p %<lp %<a %<p %dt %tr %un %>ru %Ss
access_log daemon:/var/log/squid/access.log combined
access_log daemon:/var/log/squid/network.log ip_port
cache_log /var/log/squid/cache.log
cache_store_log /var/log/squid/store.log
access_log daemon:/var/log/squid/useragent.log useragent
visible_hostname proxy.abc.com
cache deny all 


> 
>> The next line in squid.conf is 
>> 
>> acl auth_users proxy_auth REQUIRED 
>> 
> 
>FYI the above just means that Squid is using authentication. It says 
>nothing about when the authentication will be (or not be) performed. 
> 
> 
>> ... and after that, the external ACL that takes the username as well as 
>> the other info. 
>> 
> 
> 
>HTH 
>Amos 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240605/dd8ecb7d/attachment.htm>

From squid3 at treenet.co.nz  Thu Jun  6 04:04:18 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 6 Jun 2024 16:04:18 +1200
Subject: [squid-users] can't explain 403 denied for authenticated
In-Reply-To: <1999639654.1878278.1717608250039.JavaMail.zimbra@kretz.net>
References: <mailman.3.1717070401.1412775.squid-users@lists.squid-cache.org>
 <1999639654.1878278.1717608250039.JavaMail.zimbra@kretz.net>
Message-ID: <4b2b8269-46e2-417d-a85b-695e2a6ff724@treenet.co.nz>

Free config audit inline ...

On 6/06/24 05:24, Kevin wrote:
> 
> Understood.?? Here it is:
> 
> 
> acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
> acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
> acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
> acl windows_net src 172.18.114.0/24
> acl sample_host src 172.18.115.1/32
> acl rsync port 873

You can remove the above line. This "rsync" ACL is unused and the port 
is added directly to the SSL_Ports and Safe_ports.


> acl SSL_ports port 443
> acl SSL_ports port 873		#873 is rsync
> acl Safe_ports port 80		# http
> acl Safe_ports port 21		# ftp
> acl Safe_ports port 443		# https
> acl Safe_ports port 70		# gopher
> acl Safe_ports port 210		# wais
> acl Safe_ports port 1025-65535	# unregistered ports
> acl Safe_ports port 280		# http-mgmt
> acl Safe_ports port 488		# gss-http
> acl Safe_ports port 591		# filemaker
> acl Safe_ports port 777		# multiling http
> acl Safe_ports port 873
> acl CONNECT method CONNECT

You can remove the above line. "CONNECT" is a built-in ACL.


> acl PURGE method PURGE

Your proxy is configured with "cache deny all" preventing anything being 
stored.

As such you can improve performance somewhat by removing the "acl PURGE" 
and all config below that uses it.


> acl localhost src 127.0.0.1

You can remove the above line. "localhost" is a built-in ACL.


> http_access allow PURGE localhost
> http_access deny PURGE
> acl URN proto URN
> http_access deny URN
> http_access deny manager
> acl API_FIREFOX dstdomain api.profiler.firefox.com
> http_access deny API_FIREFOX
> acl ff_browser browser ^Mozilla/5\.0
> acl rma_ua browser ^RMA/1\.0.*compatible;.RealMedia
> uri_whitespace encode

Hmm. Accepting whitespace in URLs is a risky choice. One can never be 
completely sure how third-party agents in the network are handling it 
before the request arrived.

If (big IF) you are able to use "uri_whitespace deny" this proxy would 
be a bit more secure. This is just a suggestion, you know best here.


> acl trellix_phone_cloud dstdomain amcore-ens.rest.gti.trellix.com
> http_access deny trellix_phone_cloud
> external_acl_type host_based_filter children-max=15 ttl=0 %ACL %DATA %SRC %>rd %>rP  /PATH/TO/FILTER/SCRIPT.py
> acl HostBasedRules external host_based_filter
> http_access allow HostBasedRules
> auth_param digest program /usr/lib/squid/digest_file_auth -c /etc/squid/passwd
> auth_param digest realm squid
> auth_param digest children 2
> auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/basic_passwd
> auth_param basic children 2
> auth_param basic realm squidb
> auth_param basic credentialsttl 2 hours

> acl auth_users proxy_auth REQUIRED
> external_acl_type custom_acl_db children-max=15 ttl=0 %ACL %DATA %ul %SRC %>rd %>rP %credentials /PATH/TO/FILTER/SCRIPT.py
> acl CustomAclDB external custom_acl_db
> http_access allow CustomAclDB


Hmm, this use of combined authentication+authorization is a bit tricky 
with two layers of asynchronous helper lookups going on. That alone 
might be what is going on with the weird 403's.


A better sequence would be:

  # ensure login is performed
  http_access deny !auth_users

  # check the access permissions for whichever user logged in
  http_access allow CustomAclDB


> acl CRLs url_regex "/etc/squid/conf.d/CRL_urls.txt"
> http_access allow CRLs
> deny_info 303:https://abc.def.com/


FYI; deny_info is a way to customize what happens when the "deny" action 
is performed an a specific ACL match.

The above deny_info line does nothing unless you name which ACL(s) it is 
to become the action for and also those ACLs are used in a "deny" rule.

For example:

  acl redirect_HTTPS url_regex ^http://example\.com
  deny_info 303:https://example.com%rp redirect_HTTPS
  http_access deny redirect_HTTPS



> http_access deny all


So ... none of the http_access lines below here are doing anything.


> acl apache rep_header Server ^Apache
> icp_access allow localnet
> icp_access deny all


These lines...

> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports

.. to here are supposed to protect your proxy against some nasty DDoS 
type attacks.

They need to be first out of all your http_access lines in order to do 
that efficiently.


The http_access below are optional from our default squid.conf setup. 
Since your install does not appear to need them they can just be removed.


> http_access allow localhost manager
> http_access deny manager
> http_access allow localhost

> http_port 3128
> coredump_dir /var/cache/squid
> refresh_pattern ^ftp:		1440	20%	10080
> refresh_pattern ^gopher:	1440	0%	1440
> refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
> refresh_pattern .		0	20%	4320
> logformat squid %ts.%03tu %6tr %>a %Ss/%>Hs %<st %rm %ru %un %Sh/%<A %mt
> logformat squidmime %ul %ts.%03tu %6tr %>a %Ss/%>Hs %<st %rm %ru %un %Sh/%<A %mt [%>h] [%<h]
> logformat common %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %Ss:%Sh
> logformat combined %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh


Please do not re-define the "squid", "common" and "combined" names for 
custom logformat names. Use custom format names for your customized outputs.


> logformat ip_port %ts %tu %>a %>p %<lp %<a %<p %dt %tr %un %>ru %Ss
> access_log daemon:/var/log/squid/access.log combined
> access_log daemon:/var/log/squid/network.log ip_port
> cache_log /var/log/squid/cache.log
> cache_store_log /var/log/squid/store.log


You have defined "cache deny all" to prevent anything being stored.
You should be able to remove the above line entirely.


> access_log daemon:/var/log/squid/useragent.log useragent
> visible_hostname proxy.abc.com
> cache deny all



HTH
Amos



From squid at kretz.net  Thu Jun  6 19:08:36 2024
From: squid at kretz.net (Kevin)
Date: Thu, 6 Jun 2024 19:08:36 +0000 (UTC)
Subject: [squid-users] can't explain 403 denied for authenticated
Message-ID: <2030564793.1892090.1717700916359.JavaMail.zimbra@kretz.net>

>> uri_whitespace encode 
> 
>Hmm. Accepting whitespace in URLs is a risky choice. One can never be 
>completely sure how third-party agents in the network are handling it 
>before the request arrived. 
> 
>If (big IF) you are able to use "uri_whitespace deny" this proxy would 
>be a bit more secure. This is just a suggestion, you know best here. 

I think that was a workaround for a vulnerability. If it was, it may no longer be needed. 


> 
>> acl trellix_phone_cloud dstdomain amcore-ens.rest.gti.trellix.com 
>> http_access deny trellix_phone_cloud 
>> external_acl_type host_based_filter children-max=15 ttl=0 0X0P+0CL >> acl HostBasedRules external host_based_filter 
>> http_access allow HostBasedRules 
>> auth_param digest program /usr/lib/squid/digest_file_auth -c /etc/squid/passwd 
>> auth_param digest realm squid 
>> auth_param digest children 2 
>> auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/basic_passwd 
>> auth_param basic children 2 
>> auth_param basic realm squidb 
>> auth_param basic credentialsttl 2 hours 
> 
>> acl auth_users proxy_auth REQUIRED 
>> external_acl_type custom_acl_db children-max=15 ttl=0 0X0P+0CL >> acl CustomAclDB external custom_acl_db 
>> http_access allow CustomAclDB 
> 
> 
>Hmm, this use of combined authentication+authorization is a bit tricky 
>with two layers of asynchronous helper lookups going on. That alone 
>might be what is going on with the weird 403's. 
> 
> 
>A better sequence would be: 
> 
># ensure login is performed 
>http_access deny !auth_users 
> 
># check the access permissions for whichever user logged in 
>http_access allow CustomAclDB 


The first call the the external_acl is to process unauthenticated requests. Is the suggestion to replace 

acl auth_users proxy_auth REQUIRED 

with 

http_access deny !auth_users 

before the second external_acl (for authenticated requests)? 




Thanks again, very much 


Kevin 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240606/3c223dd9/attachment.htm>

From jonathanlee571 at gmail.com  Fri Jun  7 06:16:09 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 6 Jun 2024 23:16:09 -0700
Subject: [squid-users] can't explain 403 denied for authenticated
In-Reply-To: <2030564793.1892090.1717700916359.JavaMail.zimbra@kretz.net>
References: <2030564793.1892090.1717700916359.JavaMail.zimbra@kretz.net>
Message-ID: <0B651117-9E91-4C7D-B804-0E3B25D67E21@gmail.com>

You can also add this to lock down the proxy after hours so nothing is used much like locking a door, whatever is inside is going to keep working ie connections already established however all new connections will be blocked. I love this one 

acl block_hours time 00:30-05:00
ssl_bump terminate all block_hours
http_access deny all block_hours

however this is for use with ssl intercept and root certificates installed however it also works for spliced connections as it comes before everything else the terminate everything line 

you can also if you want to lock down to specific mac addresses ie small office home network 

use 

eui_lookup on


Example of use with mac addresses

acl splice_only src 192.168.1.8 #Tasha iPhone
acl splice_only src 192.168.1.10 #Jon iPhone
acl splice_only src 192.168.1.11 #Amazon Fire
acl splice_only src 192.168.1.15 #Tasha HP
acl splice_only src 192.168.1.16 #iPad

acl splice_only_mac arp  (unique 48bit hardware address here)
acl splice_only_mac arp (unique 48bit hardware address here)
acl splice_only_mac arp (unique 48bit hardware address here)
acl splice_only_mac arp  (unique 48bit hardware address here)
acl splice_only_mac arp  (unique 48bit hardware address here)

acl NoSSLIntercept ssl::server_name_regex -i "/usr/local/pkg/reg.url.nobump"
acl NoBumpDNS dstdomain "/usr/local/pkg/dns.nobump"

acl markBumped annotate_client bumped=true
acl active_use annotate_client active=true
acl bump_only src 192.168.1.3 #webtv
acl bump_only src 192.168.1.4 #toshiba
acl bump_only src 192.168.1.5 #imac
acl bump_only src 192.168.1.9 #macbook
acl bump_only src 192.168.1.13 #dell

acl bump_only_mac arp (unique 48bit hardware address here)
acl bump_only_mac arp  (unique 48bit hardware address here)
acl bump_only_mac arp  (unique 48bit hardware address here)
acl bump_only_mac arp  (unique 48bit hardware address here)
acl bump_only_mac arp  (unique 48bit hardware address here)

ssl_bump peek step1
miss_access deny no_miss active_use
ssl_bump splice https_login active_use
ssl_bump splice splice_only_mac splice_only active_use (this works as ?and logic? except my annotate active use)
ssl_bump splice NoBumpDNS active_use
ssl_bump splice NoSSLIntercept active_use
ssl_bump bump bump_only_mac bump_only active_use
acl activated note active_use true
ssl_bump terminate !activated

acl markedBumped note bumped true
url_rewrite_access deny markedBumped

> On Jun 6, 2024, at 12:08, Kevin <squid at kretz.net> wrote:
> 
> >> uri_whitespace encode
> >
> >Hmm. Accepting whitespace in URLs is a risky choice. One can never be
> >completely sure how third-party agents in the network are handling it
> >before the request arrived.
> >
> >If (big IF) you are able to use "uri_whitespace deny" this proxy would
> >be a bit more secure. This is just a suggestion, you know best here.
> 
> I think that was a workaround for a vulnerability.  If it was, it may no longer be needed.
> 
> 
> >
> >> acl trellix_phone_cloud dstdomain amcore-ens.rest.gti.trellix.com
> >> http_access deny trellix_phone_cloud
> >> external_acl_type host_based_filter children-max=15 ttl=0 0X0P+0CL >> acl HostBasedRules external host_based_filter
> >> http_access allow HostBasedRules
> >> auth_param digest program /usr/lib/squid/digest_file_auth -c /etc/squid/passwd
> >> auth_param digest realm squid
> >> auth_param digest children 2
> >> auth_param basic program /usr/lib/squid/basic_ncsa_auth /etc/squid/basic_passwd
> >> auth_param basic children 2
> >> auth_param basic realm squidb
> >> auth_param basic credentialsttl 2 hours
> >
> >> acl auth_users proxy_auth REQUIRED
> >> external_acl_type custom_acl_db children-max=15 ttl=0 0X0P+0CL >> acl CustomAclDB external custom_acl_db
> >> http_access allow CustomAclDB
> >
> >
> >Hmm, this use of combined authentication+authorization is a bit tricky
> >with two layers of asynchronous helper lookups going on. That alone
> >might be what is going on with the weird 403's.
> >
> >
> >A better sequence would be:
> >
> ># ensure login is performed
> >http_access deny !auth_users
> >
> ># check the access permissions for whichever user logged in
> >http_access allow CustomAclDB
> 
> 
> The first call the the external_acl is to process unauthenticated requests.   Is the suggestion to replace
> 
> acl auth_users proxy_auth REQUIRED
> 
> with
> 
> http_access deny !auth_users
> 
> before the second external_acl (for authenticated requests)?
> 
> 
> 
> 
> Thanks again, very much
> 
> 
> Kevin
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240606/99fc975e/attachment.htm>

From squid3 at treenet.co.nz  Fri Jun  7 06:43:37 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Jun 2024 18:43:37 +1200
Subject: [squid-users] can't explain 403 denied for authenticated
In-Reply-To: <2030564793.1892090.1717700916359.JavaMail.zimbra@kretz.net>
References: <2030564793.1892090.1717700916359.JavaMail.zimbra@kretz.net>
Message-ID: <706fc366-dff1-4532-9f3f-2f52cbecf5d3@treenet.co.nz>


On 7/06/24 07:08, Kevin wrote:
>  >
>  >> acl trellix_phone_cloud dstdomain amcore-ens.rest.gti.trellix.com
>  >> http_access deny trellix_phone_cloud
>  >> external_acl_type host_based_filter children-max=15 ttl=0 0X0P+0CL 
>  >> acl HostBasedRules external host_based_filter
>  >> http_access allow HostBasedRules
>  >> auth_param digest program /usr/lib/squid/digest_file_auth -c 
> /etc/squid/passwd
>  >> auth_param digest realm squid
>  >> auth_param digest children 2
>  >> auth_param basic program /usr/lib/squid/basic_ncsa_auth 
> /etc/squid/basic_passwd
>  >> auth_param basic children 2
>  >> auth_param basic realm squidb
>  >> auth_param basic credentialsttl 2 hours
>  >
>  >> acl auth_users proxy_auth REQUIRED
>  >> external_acl_type custom_acl_db children-max=15 ttl=0 0X0P+0CL >> 
> acl CustomAclDB external custom_acl_db
>  >> http_access allow CustomAclDB
>  >
>  >
>  >Hmm, this use of combined authentication+authorization is a bit tricky
>  >with two layers of asynchronous helper lookups going on. That alone
>  >might be what is going on with the weird 403's.
>  >
>  >
>  >A better sequence would be:
>  >
>  ># ensure login is performed
>  >http_access deny !auth_users
>  >
>  ># check the access permissions for whichever user logged in
>  >http_access allow CustomAclDB
> 
> 
> The first call the the external_acl is to process unauthenticated 
> requests.?? Is the suggestion to replace
> 
> acl auth_users proxy_auth REQUIRED
> 
> with
> 
> http_access deny !auth_users
> 
> before the second external_acl (for authenticated requests)?
> 

No. It is to ensure that "missing credentials" are treated differently 
than "bad credentials". Specifically that any auth challenge response is 
never able to be given "allow" permission.

HTH
Amos


From akash.karki at capitalone.com  Fri Jun  7 07:19:12 2024
From: akash.karki at capitalone.com (Akash Karki (CONT))
Date: Fri, 7 Jun 2024 08:19:12 +0100
Subject: [squid-users] [External Sender] Re: Upgrade path from squid
 4.15 to 6.x
In-Reply-To: <2c7e7fb9-4d07-4e28-9ad0-bd4c443e8c21@measurement-factory.com>
References: <CAAXo-PEWdcZvCXBFVLU-PTG-LKdk5_BqFyYg+H1xWuteHWUAbA@mail.gmail.com>
 <CAAXo-PH6Qf5A-=6CvArYG=8wUeG5gs-0jj32Uu3KhHSQM0HOWQ@mail.gmail.com>
 <e91a54cb-3cd4-4f71-a46b-d6a9e053bbb5@measurement-factory.com>
 <CAAXo-PEC9LXLdrSVmExMCKAo5Zg+gDQqeVy1Qk3VkZMYM3wZwg@mail.gmail.com>
 <2c7e7fb9-4d07-4e28-9ad0-bd4c443e8c21@measurement-factory.com>
Message-ID: <CAAXo-PGTvRBz+M8RqbGyo+v4ehH=m=Sgn7BEfNVKvUWLmh4Sug@mail.gmail.com>

Thanks a lot Alex!!

I will get back if anything is required, thanks again :)

On Wed, Jun 5, 2024 at 5:30?PM Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 2024-06-05 12:05, Akash Karki (CONT) wrote:
>
> > Anything specific do we need to check from any documents?
>
> Yes, anything that mentions features or directives you are using (or
> would like to use).
>
>
> > If I can get any document to refer to, that would be great!!
>
> Release notes for Squid vN should be in doc/release-notes/release-N.html
> file inside official Squid source code tarball for vN. For a given major
> Squid version, use the tarball for latest available minor release.
> Official tarballs for various versions are currently available by
> following version-specific links at
> https://urldefense.com/v3/__http://www.squid-cache.org/Versions/__;!!FrPt2g6CO4Wadw!Knqvw8ZjzeEeJdjvVy3aMDC3CmDXZBLRpezg16IbnAgHi_8g-pzwZ6maEjjw11B9_z2M0ioXIzHJ6LTwVAD-WZIJuv2dpgaw$
>
> The following wiki pages may also contain useful info:
>
> https://urldefense.com/v3/__https://wiki.squid-cache.org/Releases/Squid-5__;!!FrPt2g6CO4Wadw!Knqvw8ZjzeEeJdjvVy3aMDC3CmDXZBLRpezg16IbnAgHi_8g-pzwZ6maEjjw11B9_z2M0ioXIzHJ6LTwVAD-WZIJuolRbUO1$
>
> https://urldefense.com/v3/__https://wiki.squid-cache.org/Releases/Squid-6__;!!FrPt2g6CO4Wadw!Knqvw8ZjzeEeJdjvVy3aMDC3CmDXZBLRpezg16IbnAgHi_8g-pzwZ6maEjjw11B9_z2M0ioXIzHJ6LTwVAD-WZIJupzLWS1_$
>
>
> HTH,
>
> Alex.
>
>
> > On Wed, Jun 5, 2024 at 4:31?PM Alex Rousskov wrote:
> >
> >     On 2024-06-05 10:30, Akash Karki (CONT) wrote:
> >
> >      > I want to understand if we can go straight from 4.15 to 6.x (n-1
> of
> >      > latest version) without any intermediary steps or do we have to
> >     update
> >      > to intermediary first and then move to the n-1 version of 6.9?
> >
> >     Go straight to the latest v6. While doing that, study release notes
> for
> >     all the Squid versions you are skipping to flag configuration
> >     directives
> >     that you need to adjust (and other upgrade caveats).
> >
> >     Needless to say, test before you deploy the upgraded version -- a
> >     lot of
> >     things have changed since v4, and not all of the changes may be
> covered
> >     in release notes. When in doubt, ask (specific) questions.
> >
> >
> >     HTH,
> >
> >     Alex.
> >
> >
> >
> >      > On Wed, Jun 5, 2024 at 3:20?PM Akash Karki (CONT) wrote:
> >      >
> >      >     Hi Team,
> >      >
> >      >     We are running on squid ver 4.15 and want to update to n-1 of
> the
> >      >     latest ver(I believe 6.9 is the latest ver).
> >      >
> >      >     I want to understand if we can go straight from 4.15 to 6.x
> >     (n-1 of
> >      >     latest version) without any intermediary steps or do we
> have to
> >      >     update to intermediary first and then move to the n-1 version
> >     of 6.9?
> >      >
> >      >     Kindly send us the detailed guidance!
> >      >
> >      >     --
> >      >     Thanks & Regards,
> >      >     Akash Karki
> >      >
> >      >
> >      >     Save Nature to Save yourself :)
> >      >
> >      >
> >      >
> >      > --
> >      > Thanks & Regards,
> >      > Akash Karki
> >      > UK Hawkeye Team*
> >      > *
> >      > *Slack : *#uk-monitoring
> >      > *Confluence : *UK Hawkeye
> >      > <https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye
> >     <https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye>>
> >      >
> >      > Save Nature to Save yourself :)
> >      >
> >
>  ------------------------------------------------------------------------
> >      >
> >      >
> >      > The information contained in this e-mail may be confidential
> and/or
> >      > proprietary to Capital One and/or its affiliates and may only be
> >     used
> >      > solely in performance of work or services for Capital One. The
> >      > information transmitted herewith is intended only for use by the
> >      > individual or entity to which it is addressed. If the reader of
> this
> >      > message is not the intended recipient, you are hereby notified
> >     that any
> >      > review, retransmission, dissemination, distribution, copying or
> >     other
> >      > use of, or taking of any action in reliance upon this information
> is
> >      > strictly prohibited. If you have received this communication in
> >     error,
> >      > please contact the sender and delete the material from your
> computer.
> >      >
> >      >
> >      >
> >      > _______________________________________________
> >      > squid-users mailing list
> >      > squid-users at lists.squid-cache.org
> >     <mailto:squid-users at lists.squid-cache.org>
> >      >
> >
> https://urldefense.com/v3/__https://lists.squid-cache.org/listinfo/squid-users__;!!FrPt2g6CO4Wadw!LFF_SotEcUzjJJWv4JR26UjdlUap9Xu0U8n45FREcUUkuWDemCLyI2vLlkSciqHShz-wFylLp3e-TZwmlCNKQc28HngJzWvg$
> <
> https://urldefense.com/v3/__https://lists.squid-cache.org/listinfo/squid-users__;!!FrPt2g6CO4Wadw!LFF_SotEcUzjJJWv4JR26UjdlUap9Xu0U8n45FREcUUkuWDemCLyI2vLlkSciqHShz-wFylLp3e-TZwmlCNKQc28HngJzWvg$
> >
> >
> >
> >
> > --
> > Thanks & Regards,
> > Akash Karki
> > UK Hawkeye Team*
> > *
> > *Slack : *#uk-monitoring
> > *Confluence : *UK Hawkeye
> > <https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye>
> >
> > Save Nature to Save yourself :)
> > ------------------------------------------------------------------------
> >
> >
> > The information contained in this e-mail may be confidential and/or
> > proprietary to Capital One and/or its affiliates and may only be used
> > solely in performance of work or services for Capital One. The
> > information transmitted herewith is intended only for use by the
> > individual or entity to which it is addressed. If the reader of this
> > message is not the intended recipient, you are hereby notified that any
> > review, retransmission, dissemination, distribution, copying or other
> > use of, or taking of any action in reliance upon this information is
> > strictly prohibited. If you have received this communication in error,
> > please contact the sender and delete the material from your computer.
> >
> >
>
>

-- 
Thanks & Regards,
Akash Karki
UK Hawkeye Team
*Slack : *#uk-monitoring
*Confluence : *UK Hawkeye
<https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye>

Save Nature to Save yourself :)

______________________________________________________________________



The information contained in this e-mail may be confidential and/or proprietary to Capital One and/or its affiliates and may only be used solely in performance of work or services for Capital One. The information transmitted herewith is intended only for use by the individual or entity to which it is addressed. If the reader of this message is not the intended recipient, you are hereby notified that any review, retransmission, dissemination, distribution, copying or other use of, or taking of any action in reliance upon this information is strictly prohibited. If you have received this communication in error, please contact the sender and delete the material from your computer.



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240607/dd52b20d/attachment.htm>

From ronny.preiss at gmail.com  Sat Jun  8 10:08:22 2024
From: ronny.preiss at gmail.com (Ronny Preiss)
Date: Sat, 8 Jun 2024 12:08:22 +0200
Subject: [squid-users] DNS Issue samba_dnsupdate: dns.resolver.NoAnswer
Message-ID: <CABMAtPL1tc6mKHPVKr6kAR9v3zFy2Ctw5CU1z73SgjN6YJhGmg@mail.gmail.com>

Hi,

By doing my weekly task log checking, I saw the following error in syslog.
I've changed nothing the last couple of months.

My Environment:

2x Server Ubuntu 22.04.4 LTS with:
- Samba Version 4.19.0 AC-DC (Selfcompiled default values)

Samba version: 4.19.0
Build environment:
Paths:
   BINDIR: /usr/local/samba/bin
   SBINDIR: /usr/local/samba/sbin
   CONFIGFILE: /usr/local/samba/etc/smb.conf
   NCALRPCDIR: /usr/local/samba/var/run/ncalrpc
   LOGFILEBASE: /usr/local/samba/var
   LMHOSTSFILE: /usr/local/samba/etc/lmhosts
   DATADIR: /usr/local/samba/share
   MODULESDIR: /usr/local/samba/lib
   LOCKDIR: /usr/local/samba/var/lock
   STATEDIR: /usr/local/samba/var/locks
   CACHEDIR: /usr/local/samba/var/cache
   PIDDIR: /usr/local/samba/var/run
   PRIVATE_DIR: /usr/local/samba/private
   CODEPAGEDIR: /usr/local/samba/share/codepages
   SETUPDIR: /usr/local/samba/share/setup
   WINBINDD_SOCKET_DIR: /usr/local/samba/var/run/winbindd
   NTP_SIGND_SOCKET_DIR: /usr/local/samba/var/lib/ntp_signd


- DNS Backend Bind (BIND 9.18.18-0ubuntu0.22.04.2-Ubuntu)
- SysVol is  in sync with rsync

### /var/log/syslog
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.351034,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate: Traceback (most recent call last):
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352082,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate:   File
"/usr/local/samba/sbin/samba_dnsupdate", line 883, in <module>
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352119,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate:     creds = get_credentials(lp)
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352132,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate:   File
"/usr/local/samba/sbin/samba_dnsupdate", line 184, in get_credentials
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352144,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate:     get_krb5_rw_dns_server(creds,
sub_vars['DNSDOMAIN'] + '.')
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352158,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate:   File
"/usr/local/samba/sbin/samba_dnsupdate", line 143, in get_krb5_rw_dns_server
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352203,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate:     rw_dns_servers =
get_possible_rw_dns_server(creds, domain)
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352239,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate:   File
"/usr/local/samba/sbin/samba_dnsupdate", line 122, in
get_possible_rw_dns_server
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352253,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate:     ans_soa =
check_one_dns_name(domain, 'SOA')
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352267,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate:   File
"/usr/local/samba/sbin/samba_dnsupdate", line 274, in check_one_dns_name
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352287,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate:     return resolver.resolve(name,
name_type)
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352302,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate:   File
"/usr/lib/python3/dist-packages/dns/resolver.py", line 1202, in resolve
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352510,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate:     (answer, done) =
resolution.query_result(response, None)
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352551,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate:   File
"/usr/lib/python3/dist-packages/dns/resolver.py", line 674, in query_result
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352693,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate:     raise
NoAnswer(response=answer.response)
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.352783,  0]
../../lib/util/util_runcmd.c:355(samba_runcmd_io_handler)
Jun  8 11:54:11 01-dc01 samba[931]:
 /usr/local/samba/sbin/samba_dnsupdate: dns.resolver.NoAnswer: The DNS
response does not contain an answer to the question: intern.preiss.network.
IN SOA
Jun  8 11:54:11 01-dc01 samba[931]: [2024/06/08 11:54:11.383823,  0]
../../source4/dsdb/dns/dns_update.c:85(dnsupdate_nameupdate_done)
Jun  8 11:54:11 01-dc01 samba[931]:   dnsupdate_nameupdate_done: Failed DNS
update with exit code 1
###

Manual nslookup for the SOA entry works:

root at 01-dc01:~# nslookup -q=SOA intern.preiss.network 10.10.10.11
Server:         10.10.10.11
Address:        10.10.10.11#53

intern.preiss.network
        origin = 01-dc01.intern.preiss.network
        mail addr = hostmaster.intern.preiss.network
        serial = 1159
        refresh = 900
        retry = 600
        expire = 86400
        minimum = 3600

Does someone know how to solve this or can give me some advice?

Greetings,
Ronny
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240608/4dcac74f/attachment.htm>

From ronny.preiss at gmail.com  Sat Jun  8 11:05:22 2024
From: ronny.preiss at gmail.com (Ronny Preiss)
Date: Sat, 8 Jun 2024 13:05:22 +0200
Subject: [squid-users] Samba DNS Invalid zone operation IsSigned
Message-ID: <CABMAtPJ-7n-Mykq==e-Wm=rocHxFMZ7-JYePqX0oFHO9Z578hQ@mail.gmail.com>

Hi Everybody,

Does someone know where this comes from and how to solve it? I've changed
nothing for weeks.

- BIND 9.18.18-0ubuntu0.22.04.2-Ubuntu
- Ubuntu 22.04.4 LTS \n \l
- Samba Version 4.19.0 AC-DC

### /var/log/syslog
Jun  8 13:01:31 01-dc02 samba[996]: [2024/06/08 13:01:31.057443,  0]
../../source4/rpc_server/dn

 sserver/dcerpc_dnsserver.c:1076(dnsserver_query_zone)
Jun  8 13:01:31 01-dc02 samba[996]:   dnsserver: Invalid zone operation
IsSigned
Jun  8 13:01:31 01-dc02 samba[996]: [2024/06/08 13:01:31.060313,  0]
../../source4/rpc_server/dn

 sserver/dcerpc_dnsserver.c:1076(dnsserver_query_zone)
Jun  8 13:01:31 01-dc02 samba[996]:   dnsserver: Invalid zone operation
IsSigned
Jun  8 13:01:31 01-dc02 samba[996]: [2024/06/08 13:01:31.061385,  0]
../../source4/rpc_server/dn

 sserver/dcerpc_dnsserver.c:1076(dnsserver_query_zone)
Jun  8 13:01:31 01-dc02 samba[996]:   dnsserver: Invalid zone operation
IsSigned

Regards, Ronny
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240608/30bf973f/attachment.htm>

From ngtech1ltd at gmail.com  Sun Jun  9 10:10:11 2024
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Sun, 9 Jun 2024 13:10:11 +0300
Subject: [squid-users] Any ideas for a project and\or research with AI about
 squid-cache?
Message-ID: <001201daba55$3766ee50$a634caf0$@gmail.com>

Hey Everyone,

I was wondering if there are specific things which can be worked on with an AI as a testing project to challenge an AI.
I am looking for a set of projects which a beginner squid-cache admin can try to implement to certify himself with real world experience.

What are the most common use cases of squid-cache these days?
* Forward proxy
* Reverse proxy
* Public proxy services with authentication
* Caching
* Authentication proxy against a DB
* Authentication proxy against LDAP and/or AD
* Radius authentication
* Multi factor authentication
* Captive portal
* SSL SNI inspection
* Traffic classification (based on APPS list)
* Url Filtering
* Domain based Filtering
* Internet Usage time limit (30 minutes or any other) based on login or actual traffic.
* Outband IP address selection
Etc

Please help me to fill the list.

Thanks,
Eliezer

----
Eliezer Croitoru
NgTech, Tech Support
Mobile: +972-5-28704261
Email: ngtech1ltd at gmail.com
Web: https://www.ngtech.co.il/




From jonathanlee571 at gmail.com  Sun Jun  9 16:42:41 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sun, 9 Jun 2024 09:42:41 -0700
Subject: [squid-users] Any ideas for a project and\or research with AI
 about squid-cache?
In-Reply-To: <001201daba55$3766ee50$a634caf0$@gmail.com>
References: <001201daba55$3766ee50$a634caf0$@gmail.com>
Message-ID: <32F2831A-9FFE-4275-9598-98598C4BDEA6@gmail.com>

I hate to tell you this AI that you know has been around for many years. Anyone remember Sandblaster 16 ISA card software Dr. Spatzo? All AI is, just adapted improved 1980s ideas. It?s not new, its been here for years, still just if else code with more data analytics. 

Anyway I use Proxy for checking URL requests and blocking them if needed, inspecting HTTPS with antivirus software, caching content and having the ability to scan it before it hits users and block it. Web acceleration. I primarily use it for inspection and security. Squid could simply block out all requests to AI if you wanted, I have it set to block some. CCPA in California provides legal avenues for user privacy, not many web analytics companies follow the requests to not track so they can be simply put blocked out. Squid is very complex software.

> On Jun 9, 2024, at 03:10, ngtech1ltd at gmail.com wrote:
> 
> Hey Everyone,
> 
> I was wondering if there are specific things which can be worked on with an AI as a testing project to challenge an AI.
> I am looking for a set of projects which a beginner squid-cache admin can try to implement to certify himself with real world experience.
> 
> What are the most common use cases of squid-cache these days?
> * Forward proxy
> * Reverse proxy
> * Public proxy services with authentication
> * Caching
> * Authentication proxy against a DB
> * Authentication proxy against LDAP and/or AD
> * Radius authentication
> * Multi factor authentication
> * Captive portal
> * SSL SNI inspection
> * Traffic classification (based on APPS list)
> * Url Filtering
> * Domain based Filtering
> * Internet Usage time limit (30 minutes or any other) based on login or actual traffic.
> * Outband IP address selection
> Etc
> 
> Please help me to fill the list.
> 
> Thanks,
> Eliezer
> 
> ----
> Eliezer Croitoru
> NgTech, Tech Support
> Mobile: +972-5-28704261
> Email: ngtech1ltd at gmail.com
> Web: https://www.ngtech.co.il/
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From ngtech1ltd at gmail.com  Sun Jun  9 19:54:24 2024
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Sun, 9 Jun 2024 22:54:24 +0300
Subject: [squid-users] Any ideas for a project and\or research with AI
 about squid-cache?
In-Reply-To: <32F2831A-9FFE-4275-9598-98598C4BDEA6@gmail.com>
References: <001201daba55$3766ee50$a634caf0$@gmail.com>
 <32F2831A-9FFE-4275-9598-98598C4BDEA6@gmail.com>
Message-ID: <002901dabaa6$d4903910$7db0ab30$@gmail.com>

Hey Jonathan,

First of all, thanks for the response.
I think that all squid-users knows that AI is there since very long ago.
However, since it's a tool of the current times I want to be familiar with the tool capabilities.
The AI tools which are published these days gives a specific response to a specific requirement and need with the growth of IT in the world.

Squid-Cache users list is a place which you can ask a question and a human with emotions, sensitivity and knowledge try to help.
This is one of the only places which I don't even remember someone responding with "google it" or something similar.
The question I am asking myself is: 
I and others will not be here some time in the future and we try to document and leave after us things for the future.
I can try to say that we are working here with UDP and not TCP ie we are sending what we have into the world with the hope
it will reach others and will help them and make them happy and lively.

I believe that it's possible to learn things about Squid-Cache with the existing tools in an interactive way.
There are many documentations on Squid-Cache but some are old and others are just plain wrong.

I have some spare time here and there and I want to write a set of challenges for proxy admins.
I am thinking about it something like:
What might certify a Squid-Cache admin to be capable to be a successful admin?

The first things that most certifications do is to make sure there is "knowledge" or that the admin can implement specific use cases.
I believe that above the knowledge and technical capabilities there is a whole other level which might be lost when some will not be here.
I would be happy if the AI tools will be able to grasp from the mailing list threads something more then just the technical aspect of things.

Do you think a SoundBlaster 16 ISA card on a 386 or Pentium can transfer that?

Squid indeed is a very complex software!!

How can we attract some new Squid users into the list or to try and complete couple challenges?
Also, there are new versions of Linux distros around and these are a great playground for testing.

I will try to see if the AI can summarize the functionality of Squid-Cache (else then the cache itself).
I wrote couple caching tools in the past 10 years and I think that the new AI tools might be able to find
couple things which I missed and maybe offer better solutions for couple things.

Maybe some external_acl helpers or maybe to convert existing tools to rust or golang.
Maybe even these tools will be able to offer some ideas on how to fix specific bugs.
Even if they will not write the whole code for it the fact that what someone else wrote somewhere on the internet is
reaching to the prompt user we might be able to understand how a single document can affect a lot on the end result.

Let's try to follow on this thread later on.

Thanks,
Eliezer

-----Original Message-----
From: Jonathan Lee <jonathanlee571 at gmail.com> 
Sent: Sunday, June 9, 2024 7:43 PM
To: ngtech1ltd at gmail.com
Cc: squid-users <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Any ideas for a project and\or research with AI about squid-cache?

I hate to tell you this AI that you know has been around for many years.
Anyone remember Sandblaster 16 ISA card software Dr. Spatzo?
All AI is, just adapted improved 1980s ideas. It?s not new, its been here for years, still just if else code with more data analytics. 

Anyway I use Proxy for checking URL requests and blocking them if needed, inspecting HTTPS with antivirus software, caching content and having the ability to scan it before it hits users and block it.
Web acceleration.
I primarily use it for inspection and security.
Squid could simply block out all requests to AI if you wanted, I have it set to block some.
CCPA in California provides legal avenues for user privacy, not many web analytics companies follow the requests to not track so they can be simply put blocked out. 

Squid is very complex software.

> On Jun 9, 2024, at 03:10, ngtech1ltd at gmail.com wrote:
> 
> Hey Everyone,
> 
> I was wondering if there are specific things which can be worked on with an AI as a testing project to challenge an AI.
> I am looking for a set of projects which a beginner squid-cache admin can try to implement to certify himself with real world experience.
> 
> What are the most common use cases of squid-cache these days?
> * Forward proxy
> * Reverse proxy
> * Public proxy services with authentication
> * Caching
> * Authentication proxy against a DB
> * Authentication proxy against LDAP and/or AD
> * Radius authentication
> * Multi factor authentication
> * Captive portal
> * SSL SNI inspection
> * Traffic classification (based on APPS list)
> * Url Filtering
> * Domain based Filtering
> * Internet Usage time limit (30 minutes or any other) based on login or actual traffic.
> * Outband IP address selection
> Etc
> 
> Please help me to fill the list.
> 
> Thanks,
> Eliezer
> 
> ----
> Eliezer Croitoru
> NgTech, Tech Support
> Mobile: +972-5-28704261
> Email: ngtech1ltd at gmail.com
> Web: https://www.ngtech.co.il/
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Mon Jun 10 05:01:48 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 10 Jun 2024 17:01:48 +1200
Subject: [squid-users] Samba DNS Invalid zone operation IsSigned
In-Reply-To: <CABMAtPJ-7n-Mykq==e-Wm=rocHxFMZ7-JYePqX0oFHO9Z578hQ@mail.gmail.com>
References: <CABMAtPJ-7n-Mykq==e-Wm=rocHxFMZ7-JYePqX0oFHO9Z578hQ@mail.gmail.com>
Message-ID: <56ef94a9-d42d-46b4-8941-1c050155603e@treenet.co.nz>

Hi Ronny,
  This is the Squid users mailing list.  You would be better served 
contacting the Samba help channels for this problem.


Cheers
Amos


On 8/06/24 23:05, Ronny Preiss wrote:
> Hi Everybody,
> 
> Does someone know where this comes from and how to solve?it? I've 
> changed nothing?for weeks.
> 
> - BIND 9.18.18-0ubuntu0.22.04.2-Ubuntu
> - Ubuntu 22.04.4 LTS \n \l
> - Samba Version 4.19.0 AC-DC
> 
> ### /var/log/syslog
> Jun? 8 13:01:31 01-dc02 samba[996]: [2024/06/08 13:01:31.057443,? 0] 
> ../../source4/rpc_server/dn                                              
>                                                        
>  ?sserver/dcerpc_dnsserver.c:1076(dnsserver_query_zone)
> Jun? 8 13:01:31 01-dc02 samba[996]:? ?dnsserver: Invalid zone operation 
> IsSigned
> Jun? 8 13:01:31 01-dc02 samba[996]: [2024/06/08 13:01:31.060313,? 0] 
> ../../source4/rpc_server/dn                                              
>                                                        
>  ?sserver/dcerpc_dnsserver.c:1076(dnsserver_query_zone)
> Jun? 8 13:01:31 01-dc02 samba[996]:? ?dnsserver: Invalid zone operation 
> IsSigned
> Jun? 8 13:01:31 01-dc02 samba[996]: [2024/06/08 13:01:31.061385,? 0] 
> ../../source4/rpc_server/dn                                              
>                                                        
>  ?sserver/dcerpc_dnsserver.c:1076(dnsserver_query_zone)
> Jun? 8 13:01:31 01-dc02 samba[996]:? ?dnsserver: Invalid zone operation 
> IsSigned
> 
> Regards, Ronny
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From ngtech1ltd at gmail.com  Mon Jun 10 07:43:00 2024
From: ngtech1ltd at gmail.com (ngtech1ltd at gmail.com)
Date: Mon, 10 Jun 2024 10:43:00 +0300
Subject: [squid-users] Upgrade path from squid 4.15 to 6.x
In-Reply-To: <CAAXo-PH6Qf5A-=6CvArYG=8wUeG5gs-0jj32Uu3KhHSQM0HOWQ@mail.gmail.com>
References: <CAAXo-PEWdcZvCXBFVLU-PTG-LKdk5_BqFyYg+H1xWuteHWUAbA@mail.gmail.com>
 <CAAXo-PH6Qf5A-=6CvArYG=8wUeG5gs-0jj32Uu3KhHSQM0HOWQ@mail.gmail.com>
Message-ID: <002c01dabb09$d20eb550$762c1ff0$@gmail.com>

Hey Akash,
(Is this your first name?)
 
There are ways to test the config step by step with docker containers but it depends on the config size and complexity.
Even if you cannot share the squid.conf you can still summarize it to a degree.
There are 2 types of proxy services which can be implemented by Squid:
*	Forward
*	Reverse
 
With these there are tons of bricks which can be pilled up to achieve functionality.
@Alex and @Amos, can you try to help me compile a menu list of functionalities that Squid-Cache can be used for?
Ie as a forward proxy..
 
I believe that the project can offer a set of generic recipes for use cases that every support case will be able to look at to ask about.
Currently there are many questions which were answered but not all of them a documented enough to answer the use cases.
I can take this 4.15 to 6.9 as an example project and to document it for simplicity of others.
 
I will try to take a peek at the release notes from 4.15 till 6.9 to understand if there are specific things to be aware of for my specific use case.
 
The first thing I think should be mentioned is the list of deprecated helpers.
 
Thanks,
Eliezer
 
From: squid-users <squid-users-bounces at lists.squid-cache.org> On Behalf Of Akash Karki (CONT)
Sent: Wednesday, June 5, 2024 5:31 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Upgrade path from squid 4.15 to 6.x
 
Hi Team,
 
We are running on squid ver 4.15 and want to update to n-1 of the latest ver(I believe 6.9 is the latest ver).
 
I want to understand if we can go straight from 4.15 to 6.x (n-1 of latest version) without any intermediary steps or do we have to  update to intermediary first and then move to the n-1 version of 6.9?
 
Kindly send us the detailed guidance!
 
On Wed, Jun 5, 2024 at 3:20?PM Akash Karki (CONT) <akash.karki at capitalone.com <mailto:akash.karki at capitalone.com> > wrote:
Hi Team,
 
We are running on squid ver 4.15 and want to update to n-1 of the latest ver(I believe 6.9 is the latest ver).
 
I want to understand if we can go straight from 4.15 to 6.x (n-1 of latest version) without any intermediary steps or do we have to  update to intermediary first and then move to the n-1 version of 6.9?
 
Kindly send us the detailed guidance!

 
-- 
Thanks & Regards,
Akash Karki
 
 
Save Nature to Save yourself :) 


 
-- 
Thanks & Regards,
Akash Karki
UK Hawkeye Team
Slack : #uk-monitoring
Confluence :  <https://confluence.kdc.capitalone.com/display/UH/UK+Hawkeye> UK Hawkeye
 
Save Nature to Save yourself :) 
  _____  


 

The information contained in this e-mail may be confidential and/or proprietary to Capital One and/or its affiliates and may only be used solely in performance of work or services for Capital One. The information transmitted herewith is intended only for use by the individual or entity to which it is addressed. If the reader of this message is not the intended recipient, you are hereby notified that any review, retransmission, dissemination, distribution, copying or other use of, or taking of any action in reliance upon this information is strictly prohibited. If you have received this communication in error, please contact the sender and delete the material from your computer.




 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240610/19fa1f90/attachment.htm>

From squid.org at bloms.de  Mon Jun 10 12:10:28 2024
From: squid.org at bloms.de (Dieter Bloms)
Date: Mon, 10 Jun 2024 14:10:28 +0200
Subject: [squid-users] Howto enable openssl option
 UNSAFE_LEGACY_RENEGOTIATION ?
Message-ID: <20240610121028.pyrten34umf2wws7@bloms.de>

Hello,

I have activated ssl_bump and must activate the UNSAFE_LEGACY_RENEGOTIATION option to enable access to https://cisco.com.
The web server does not support secure renegotiation.

I have tried to set the following options, but squid does not recognize any of them:

tls_outgoing_options options=UNSAFE_LEGACY_RENEGOTIATION

or 

tls_outgoing_options options=ALLOW_UNSAFE_LEGACY_RENEGOTIATION

and

tls_outgoing_options options=SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION

but no matter which syntax I use, I always get the message during squid-k parse:

?2024/06/10 14:08:17| ERROR: Unknown TLS option ALLOW_UNSAFE_LEGACY_RENEGOTIATION?

How can I activate secure renegotiation for squid?

-- 
Regeards

  Dieter Bloms

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
From field.


From rousskov at measurement-factory.com  Mon Jun 10 12:59:35 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 10 Jun 2024 08:59:35 -0400
Subject: [squid-users] Howto enable openssl option
 UNSAFE_LEGACY_RENEGOTIATION ?
In-Reply-To: <20240610121028.pyrten34umf2wws7@bloms.de>
References: <20240610121028.pyrten34umf2wws7@bloms.de>
Message-ID: <7b5a0cb3-bbb4-46cf-83cc-2003bc44f7a4@measurement-factory.com>

On 2024-06-10 08:10, Dieter Bloms wrote:

> I have activated ssl_bump and must activate the UNSAFE_LEGACY_RENEGOTIATION option to enable access to https://cisco.com.
> The web server does not support secure renegotiation.
> 
> I have tried to set the following options, but squid does not recognize any of them:
> 
> tls_outgoing_options options=UNSAFE_LEGACY_RENEGOTIATION
> 
> or
> 
> tls_outgoing_options options=ALLOW_UNSAFE_LEGACY_RENEGOTIATION
> 
> and
> 
> tls_outgoing_options options=SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION
> 
> but no matter which syntax I use, I always get the message during squid-k parse:
> 
> ?2024/06/10 14:08:17| ERROR: Unknown TLS option ALLOW_UNSAFE_LEGACY_RENEGOTIATION?
> 
> How can I activate secure renegotiation for squid?

To set an OpenSSL connection option that Squid does not know by name, 
use that option hex value (based on your OpenSSL sources). For example:

     # SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION is defined to be
     # SSL_OP_BIT(18) which is equal to (1 << 18) or 0x40000 in hex.
     tls_outgoing_options options=0x40000

Disclaimer: I have not tested the above and do not know whether adding 
that option achieves what you want to achieve.


HTH,

Alex.



From jonathanlee571 at gmail.com  Tue Jun 11 04:45:11 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 10 Jun 2024 21:45:11 -0700
Subject: [squid-users] Information Request: "Accept-Ranges" with use of SSL
 intercept and dynamic update caching
Message-ID: <F025B516-48D2-4E39-8799-5F215CECB986@gmail.com>

Hello fellow Squid community can you please help?

Should I be using the following if I have SSL certificates, dynamic updates, StoreID, and ClamAV running?

request_header_access Accept-Ranges deny all
reply_header_access Accept-Ranges deny all
request_header_replace Accept-Ranges none
reply_header_replace Accept-Ranges none

None of the documents show what Accept-Ranges does

Can anyone help explain this to me?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240610/d6b04b91/attachment.htm>

From jonathanlee571 at gmail.com  Tue Jun 11 04:47:28 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 10 Jun 2024 21:47:28 -0700
Subject: [squid-users] Information Request: "Accept-Ranges" with use of
 SSL intercept and dynamic update caching
In-Reply-To: <F025B516-48D2-4E39-8799-5F215CECB986@gmail.com>
References: <F025B516-48D2-4E39-8799-5F215CECB986@gmail.com>
Message-ID: <FD2D632A-923B-4727-8697-8C480419AB29@gmail.com>

The reason I ask is sometimes Facebook when I am using it locks up and my fan goes crazy I close Safari and restart the browser and it works fine again. It acts like it is restarting a download over and over again. 

> On Jun 10, 2024, at 21:45, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> Hello fellow Squid community can you please help?
> 
> Should I be using the following if I have SSL certificates, dynamic updates, StoreID, and ClamAV running?
> 
> request_header_access Accept-Ranges deny all
> reply_header_access Accept-Ranges deny all
> request_header_replace Accept-Ranges none
> reply_header_replace Accept-Ranges none
> 
> None of the documents show what Accept-Ranges does
> 
> Can anyone help explain this to me?

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240610/275bd965/attachment.htm>

From squid.org at bloms.de  Tue Jun 11 07:33:01 2024
From: squid.org at bloms.de (Dieter Bloms)
Date: Tue, 11 Jun 2024 09:33:01 +0200
Subject: [squid-users] Howto enable openssl option
 UNSAFE_LEGACY_RENEGOTIATION ?
In-Reply-To: <7b5a0cb3-bbb4-46cf-83cc-2003bc44f7a4@measurement-factory.com>
References: <20240610121028.pyrten34umf2wws7@bloms.de>
 <7b5a0cb3-bbb4-46cf-83cc-2003bc44f7a4@measurement-factory.com>
Message-ID: <20240611073301.m265y6ubpdpmalwp@bloms.de>

Hello Alex,

thank you for your answer!

On Mon, Jun 10, Alex Rousskov wrote:

> On 2024-06-10 08:10, Dieter Bloms wrote:
> 
> > I have activated ssl_bump and must activate the UNSAFE_LEGACY_RENEGOTIATION option to enable access to https://cisco.com.
> > The web server does not support secure renegotiation.
> > 
> > I have tried to set the following options, but squid does not recognize any of them:
> > 
> > tls_outgoing_options options=UNSAFE_LEGACY_RENEGOTIATION
> > 
> > or
> > 
> > tls_outgoing_options options=ALLOW_UNSAFE_LEGACY_RENEGOTIATION
> > 
> > and
> > 
> > tls_outgoing_options options=SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION
> > 
> > but no matter which syntax I use, I always get the message during squid-k parse:
> > 
> > ?2024/06/10 14:08:17| ERROR: Unknown TLS option ALLOW_UNSAFE_LEGACY_RENEGOTIATION?
> > 
> > How can I activate secure renegotiation for squid?
> 
> To set an OpenSSL connection option that Squid does not know by name, use
> that option hex value (based on your OpenSSL sources). For example:
> 
>     # SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION is defined to be
>     # SSL_OP_BIT(18) which is equal to (1 << 18) or 0x40000 in hex.
>     tls_outgoing_options options=0x40000
> 
> Disclaimer: I have not tested the above and do not know whether adding that
> option achieves what you want to achieve.

I've added that option like:
tls_outgoing_options options=0x40000 capath=/etc/ssl/certs min-version=1.2 cipher=TLSv1.2:+aRSA:+SHA384:+SHA256:+DH:-kRSA:!PSK:!eNULL:!aNULL:!DSS:!AESCCM:!CAMELLIA:!ARIA:AES256-SHA:AES128-SHA:@SECLEVEL=1
but no change.

I tried 0x4 (for SSL_OP_LEGACY_SERVER_CONNECT), but also without any change.

I use a debian bookworm container and when I use openssl s_client
without -legacy_server_connect I can't established a tls connection

--snip--
root at tarski:/# openssl s_client -connect cisco.com:443
CONNECTED(00000003)
4097F217F17F0000:error:0A000152:SSL routines:final_renegotiate:unsafe legacy renegotiation disabled:../ssl/statem/extensions.c:893:
---
no peer certificate available
---
No client certificate CA names sent
---
SSL handshake has read 5177 bytes and written 322 bytes
Verification: OK
---
New, (NONE), Cipher is (NONE)
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
SSL-Session:
    Protocol  : TLSv1.2
    Cipher    : 0000
    Session-ID: 869B4016868DFF23D1DAB3A33F99F9879274C1F62FD45BF9DF839B27735FC72C
    Session-ID-ctx: 
    Master-Key: 
    PSK identity: None
    PSK identity hint: None
    SRP username: None
    Start Time: 1718090662
    Timeout   : 7200 (sec)
    Verify return code: 0 (ok)
    Extended master secret: no
---
root at tarski:/# 
--snip--

but when I add the -legacy_server_connect option I can as shown here:

--snip--
---
root at cdxiaphttpproxy04:/# openssl s_client -legacy_server_connect -connect cisco.com:443
CONNECTED(00000003)
depth=2 C = US, O = IdenTrust, CN = IdenTrust Commercial Root CA 1
verify return:1
depth=1 C = US, O = IdenTrust, OU = HydrantID Trusted Certificate Service, CN = HydrantID Server CA O1
verify return:1
depth=0 C = US, ST = California, L = San Jose, O = Cisco Systems Inc., CN = www.cisco.com
verify return:1
---
Certificate chain
 0 s:C = US, ST = California, L = San Jose, O = Cisco Systems Inc., CN = www.cisco.com
   i:C = US, O = IdenTrust, OU = HydrantID Trusted Certificate Service, CN = HydrantID Server CA O1
   a:PKEY: rsaEncryption, 2048 (bit); sigalg: RSA-SHA256
   v:NotBefore: Nov 14 05:48:20 2023 GMT; NotAfter: Nov 13 05:47:20 2024 GMT
 1 s:C = US, O = IdenTrust, OU = HydrantID Trusted Certificate Service, CN = HydrantID Server CA O1
   i:C = US, O = IdenTrust, CN = IdenTrust Commercial Root CA 1
   a:PKEY: rsaEncryption, 2048 (bit); sigalg: RSA-SHA256
   v:NotBefore: Dec 12 16:56:15 2019 GMT; NotAfter: Dec 12 16:56:15 2029 GMT
 2 s:C = US, O = IdenTrust, CN = IdenTrust Commercial Root CA 1
   i:C = US, O = IdenTrust, CN = IdenTrust Commercial Root CA 1
   a:PKEY: rsaEncryption, 4096 (bit); sigalg: RSA-SHA256
   v:NotBefore: Jan 16 18:12:23 2014 GMT; NotAfter: Jan 16 18:12:23 2034 GMT
---
Server certificate
-----BEGIN CERTIFICATE-----
MIIHkDCCBnigAwIBAgIQQAGLzF+ffeG2bq2GaN2HuTANBgkqhkiG9w0BAQsFADBy
MQswCQYDVQQGEwJVUzESMBAGA1UEChMJSWRlblRydXN0MS4wLAYDVQQLEyVIeWRy
YW50SUQgVHJ1c3RlZCBDZXJ0aWZpY2F0ZSBTZXJ2aWNlMR8wHQYDVQQDExZIeWRy
YW50SUQgU2VydmVyIENBIE8xMB4XDTIzMTExNDA1NDgyMFoXDTI0MTExMzA1NDcy
MFowajELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExETAPBgNVBAcT
CFNhbiBKb3NlMRswGQYDVQQKExJDaXNjbyBTeXN0ZW1zIEluYy4xFjAUBgNVBAMT
DXd3dy5jaXNjby5jb20wggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC5
CZi7tsogSJCAE5Zu78Z57FBC67OpK0OkIyVeixqKg57K/wqE4UF59GHHHVwOZhGv
VgsD3jjiQOhxZbUJnaen0+cMH6s1lSRZtiIi2K/Z1Oy+1Gytpw2bYZTbuWHWk1/e
VUgH8dS6PbwQp+/KAzV52Z98asWGzxWYqfJV5GUdC5V2MPDuDRfbrrl6uxVb05tN
69xfCIAR2KJtM64UJifesa7ItQBMzh1TYqPa4A15Ku6MgiuOkUddCrkZWRt1uevD
E6k47uR4wcuM/hF/eSX8wl/BaKrM3eiAc94Thom0wvKzlG0uziL4cux/O6O0na0w
o3WPfbSQltquqVPb9Z1JAgMBAAGjggQoMIIEJDAOBgNVHQ8BAf8EBAMCBaAwgYUG
CCsGAQUFBwEBBHkwdzAwBggrBgEFBQcwAYYkaHR0cDovL2NvbW1lcmNpYWwub2Nz
cC5pZGVudHJ1c3QuY29tMEMGCCsGAQUFBzAChjdodHRwOi8vdmFsaWRhdGlvbi5p
ZGVudHJ1c3QuY29tL2NlcnRzL2h5ZHJhbnRpZGNhTzEucDdjMB8GA1UdIwQYMBaA
FIm4m7ae7fuwxr0N7GdOPKOSnS35MCEGA1UdIAQaMBgwCAYGZ4EMAQICMAwGCmCG
SAGG+S8ABgMwRgYDVR0fBD8wPTA7oDmgN4Y1aHR0cDovL3ZhbGlkYXRpb24uaWRl
bnRydXN0LmNvbS9jcmwvaHlkcmFudGlkY2FvMS5jcmwwggE9BgNVHREEggE0MIIB
MIIJY2lzY28uY29tgg13d3cuY2lzY28uY29tgg53d3cxLmNpc2NvLmNvbYIOd3d3
Mi5jaXNjby5jb22CDnd3dzMuY2lzY28uY29tghB3d3ctMDEuY2lzY28uY29tghB3
d3ctMDIuY2lzY28uY29tghF3d3ctcnRwLmNpc2NvLmNvbYISd3d3MS1zczIuY2lz
Y28uY29tghJ3d3cyLXNzMS5jaXNjby5jb22CEnd3dzMtc3MxLmNpc2NvLmNvbYIS
d3d3My1zczIuY2lzY28uY29tghR3d3cuc3RhdGljLWNpc2NvLmNvbYIVcmVkaXJl
Y3QtbnMuY2lzY28uY29tghZjaXNjby1pbWFnZXMuY2lzY28uY29tghh3d3cubWVk
aWFmaWxlcy1jaXNjby5jb20wHQYDVR0OBBYEFJXbJPCc5ySIPskL3ul5pwsnzqOn
MB0GA1UdJQQWMBQGCCsGAQUFBwMBBggrBgEFBQcDAjCCAX0GCisGAQQB1nkCBAIE
ggFtBIIBaQFnAHYAdv+IPwq2+5VRwmHM9Ye6NLSkzbsp3GhCCp/mZ0xaOnQAAAGL
zF+ivwAABAMARzBFAiAV2h1n5lmpF6LmJiUBK23xPvFstpP2e1rgvrgk3/JsmwIh
AMWUWbEUlsvuBOZU4/Zj/319+wLUe00a3oB4TrmGl8dYAHUA7s3QZNXbGs7FXLed
tM0TojKHRny87N7DUUhZRnEftZsAAAGLzF+gvgAABAMARjBEAiAOO0eyzuDUszNb
crQzu64SP6Rb5MK2cma9K0v+TB4xtwIgQZPKexvzy13yOg7Imn9F2d8turRwP/KI
DgAaezKY8AUAdgBIsONr2qZHNA/lagL6nTDrHFIBy1bdLIHZu7+rOdiEcwAAAYvM
X6BZAAAEAwBHMEUCIQCLGuUmgXM4zWGFphL39D0xVwxW9YfN3M0QHuGkh+XcDgIg
duaXqsoaucNUg8Y7iXgB8941hMMVyayYk7qOSBXO50UwDQYJKoZIhvcNAQELBQAD
ggEBAMn5Jz/4Zo9Z2eduV86z+cQ2GLqe00HdV+Nu2g8z3Yg8my8TioRaNbYBj3XB
Ng+sqQ4kAAp7AGcFDFQDBh8tokdH/d9/W+K+rPED3DTADMg/xqKpwdYNjnjOIfjq
RdcPfvvCfpz6FFG67iCfvKGUJtRxCCwxZwOrH+yo5i92dZIVJBwGPT3rUACzswWR
erVDViWgeHdU8BK9cQWAnLoYT4EOUoYgIpowEBW2QJbsjtyF6F/M+6QmIRfAiQmz
ltnSXsmjQg6gU+xnb+hWr8Z6fJQ7WTKklIkq+P0m9XkMILrt2e/mJCVXllvHt1bw
3ppvS7HIO+hyjOL0Ec815gtXQ6Q=
-----END CERTIFICATE-----
subject=C = US, ST = California, L = San Jose, O = Cisco Systems Inc., CN = www.cisco.com
issuer=C = US, O = IdenTrust, OU = HydrantID Trusted Certificate Service, CN = HydrantID Server CA O1
---
No client certificate CA names sent
Peer signing digest: SHA512
Peer signature type: RSA
Server Temp Key: ECDH, prime256v1, 256 bits
---
SSL handshake has read 5570 bytes and written 441 bytes
Verification: OK
---
New, TLSv1.2, Cipher is ECDHE-RSA-AES256-GCM-SHA384
Server public key is 2048 bit
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
No ALPN negotiated
SSL-Session:
    Protocol  : TLSv1.2
    Cipher    : ECDHE-RSA-AES256-GCM-SHA384
    Session-ID: A5AB47FDA51B5E20A65B2C8E5BEE4C03B81A954F6E10525A2D656C0C08C6C72C
    Session-ID-ctx: 
    Master-Key: BB59B80C43F03ABCF1B35A62DCCB15061954F9FF19AAB08907E661F20E9104EA9DF6C4AACDD57245757800B6D80629C6
    PSK identity: None
    PSK identity hint: None
    SRP username: None
    Start Time: 1718090925
    Timeout   : 7200 (sec)
    Verify return code: 0 (ok)
    Extended master secret: no
---
--snip--

so I think, no matter what option I set, it will be ignored

-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
From field.


From rousskov at measurement-factory.com  Tue Jun 11 14:03:37 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 11 Jun 2024 10:03:37 -0400
Subject: [squid-users] Howto enable openssl option
 UNSAFE_LEGACY_RENEGOTIATION ?
In-Reply-To: <20240611073301.m265y6ubpdpmalwp@bloms.de>
References: <20240610121028.pyrten34umf2wws7@bloms.de>
 <7b5a0cb3-bbb4-46cf-83cc-2003bc44f7a4@measurement-factory.com>
 <20240611073301.m265y6ubpdpmalwp@bloms.de>
Message-ID: <7294e62d-881a-4ae8-b7dd-fa63dd9360fe@measurement-factory.com>

On 2024-06-11 03:33, Dieter Bloms wrote:

> I've added that option like:
> tls_outgoing_options options=0x40000 ...
> but no change.
> 
> I tried 0x4 (for SSL_OP_LEGACY_SERVER_CONNECT), but also without any change.

I have seen this behavior before. My current working theory is that 
Squid ignores tls_outgoing_options when SslBump peeks or stares at 
Squid-to-server TLS connection. In case of staring, this smells like a 
Squid bug to me. Peeking case is more nuanced, but Squid code 
modifications are warranted in that case as well.

If your Squid is peeking and splicing Squid-origin connection, then 
please try the following unofficial patch:
https://github.com/measurement-factory/squid/commit/4dad35eb.patch

The patch sets SSL_OP_LEGACY_SERVER_CONNECT unconditionally when 
peeking, for the reasons explained in the patch. This change has been 
proposed for official adoption at
https://github.com/squid-cache/squid/pull/1839


I do not have a patch for the staring use case.


HTH,

Alex.



> I use a debian bookworm container and when I use openssl s_client
> without -legacy_server_connect I can't established a tls connection
> 
> --snip--
> root at tarski:/# openssl s_client -connect cisco.com:443
> CONNECTED(00000003)
> 4097F217F17F0000:error:0A000152:SSL routines:final_renegotiate:unsafe legacy renegotiation disabled:../ssl/statem/extensions.c:893:
> ---
> no peer certificate available
> ---
> No client certificate CA names sent
> ---
> SSL handshake has read 5177 bytes and written 322 bytes
> Verification: OK
> ---
> New, (NONE), Cipher is (NONE)
> Secure Renegotiation IS NOT supported
> Compression: NONE
> Expansion: NONE
> No ALPN negotiated
> SSL-Session:
>      Protocol  : TLSv1.2
>      Cipher    : 0000
>      Session-ID: 869B4016868DFF23D1DAB3A33F99F9879274C1F62FD45BF9DF839B27735FC72C
>      Session-ID-ctx:
>      Master-Key:
>      PSK identity: None
>      PSK identity hint: None
>      SRP username: None
>      Start Time: 1718090662
>      Timeout   : 7200 (sec)
>      Verify return code: 0 (ok)
>      Extended master secret: no
> ---
> root at tarski:/#
> --snip--
> 
> but when I add the -legacy_server_connect option I can as shown here:
> 
> --snip--
> ---
> root at cdxiaphttpproxy04:/# openssl s_client -legacy_server_connect -connect cisco.com:443
> CONNECTED(00000003)
> depth=2 C = US, O = IdenTrust, CN = IdenTrust Commercial Root CA 1
> verify return:1
> depth=1 C = US, O = IdenTrust, OU = HydrantID Trusted Certificate Service, CN = HydrantID Server CA O1
> verify return:1
> depth=0 C = US, ST = California, L = San Jose, O = Cisco Systems Inc., CN = www.cisco.com
> verify return:1
> ---
> Certificate chain
>   0 s:C = US, ST = California, L = San Jose, O = Cisco Systems Inc., CN = www.cisco.com
>     i:C = US, O = IdenTrust, OU = HydrantID Trusted Certificate Service, CN = HydrantID Server CA O1
>     a:PKEY: rsaEncryption, 2048 (bit); sigalg: RSA-SHA256
>     v:NotBefore: Nov 14 05:48:20 2023 GMT; NotAfter: Nov 13 05:47:20 2024 GMT
>   1 s:C = US, O = IdenTrust, OU = HydrantID Trusted Certificate Service, CN = HydrantID Server CA O1
>     i:C = US, O = IdenTrust, CN = IdenTrust Commercial Root CA 1
>     a:PKEY: rsaEncryption, 2048 (bit); sigalg: RSA-SHA256
>     v:NotBefore: Dec 12 16:56:15 2019 GMT; NotAfter: Dec 12 16:56:15 2029 GMT
>   2 s:C = US, O = IdenTrust, CN = IdenTrust Commercial Root CA 1
>     i:C = US, O = IdenTrust, CN = IdenTrust Commercial Root CA 1
>     a:PKEY: rsaEncryption, 4096 (bit); sigalg: RSA-SHA256
>     v:NotBefore: Jan 16 18:12:23 2014 GMT; NotAfter: Jan 16 18:12:23 2034 GMT
> ---
> Server certificate
> -----BEGIN CERTIFICATE-----
> MIIHkDCCBnigAwIBAgIQQAGLzF+ffeG2bq2GaN2HuTANBgkqhkiG9w0BAQsFADBy
> MQswCQYDVQQGEwJVUzESMBAGA1UEChMJSWRlblRydXN0MS4wLAYDVQQLEyVIeWRy
> YW50SUQgVHJ1c3RlZCBDZXJ0aWZpY2F0ZSBTZXJ2aWNlMR8wHQYDVQQDExZIeWRy
> YW50SUQgU2VydmVyIENBIE8xMB4XDTIzMTExNDA1NDgyMFoXDTI0MTExMzA1NDcy
> MFowajELMAkGA1UEBhMCVVMxEzARBgNVBAgTCkNhbGlmb3JuaWExETAPBgNVBAcT
> CFNhbiBKb3NlMRswGQYDVQQKExJDaXNjbyBTeXN0ZW1zIEluYy4xFjAUBgNVBAMT
> DXd3dy5jaXNjby5jb20wggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC5
> CZi7tsogSJCAE5Zu78Z57FBC67OpK0OkIyVeixqKg57K/wqE4UF59GHHHVwOZhGv
> VgsD3jjiQOhxZbUJnaen0+cMH6s1lSRZtiIi2K/Z1Oy+1Gytpw2bYZTbuWHWk1/e
> VUgH8dS6PbwQp+/KAzV52Z98asWGzxWYqfJV5GUdC5V2MPDuDRfbrrl6uxVb05tN
> 69xfCIAR2KJtM64UJifesa7ItQBMzh1TYqPa4A15Ku6MgiuOkUddCrkZWRt1uevD
> E6k47uR4wcuM/hF/eSX8wl/BaKrM3eiAc94Thom0wvKzlG0uziL4cux/O6O0na0w
> o3WPfbSQltquqVPb9Z1JAgMBAAGjggQoMIIEJDAOBgNVHQ8BAf8EBAMCBaAwgYUG
> CCsGAQUFBwEBBHkwdzAwBggrBgEFBQcwAYYkaHR0cDovL2NvbW1lcmNpYWwub2Nz
> cC5pZGVudHJ1c3QuY29tMEMGCCsGAQUFBzAChjdodHRwOi8vdmFsaWRhdGlvbi5p
> ZGVudHJ1c3QuY29tL2NlcnRzL2h5ZHJhbnRpZGNhTzEucDdjMB8GA1UdIwQYMBaA
> FIm4m7ae7fuwxr0N7GdOPKOSnS35MCEGA1UdIAQaMBgwCAYGZ4EMAQICMAwGCmCG
> SAGG+S8ABgMwRgYDVR0fBD8wPTA7oDmgN4Y1aHR0cDovL3ZhbGlkYXRpb24uaWRl
> bnRydXN0LmNvbS9jcmwvaHlkcmFudGlkY2FvMS5jcmwwggE9BgNVHREEggE0MIIB
> MIIJY2lzY28uY29tgg13d3cuY2lzY28uY29tgg53d3cxLmNpc2NvLmNvbYIOd3d3
> Mi5jaXNjby5jb22CDnd3dzMuY2lzY28uY29tghB3d3ctMDEuY2lzY28uY29tghB3
> d3ctMDIuY2lzY28uY29tghF3d3ctcnRwLmNpc2NvLmNvbYISd3d3MS1zczIuY2lz
> Y28uY29tghJ3d3cyLXNzMS5jaXNjby5jb22CEnd3dzMtc3MxLmNpc2NvLmNvbYIS
> d3d3My1zczIuY2lzY28uY29tghR3d3cuc3RhdGljLWNpc2NvLmNvbYIVcmVkaXJl
> Y3QtbnMuY2lzY28uY29tghZjaXNjby1pbWFnZXMuY2lzY28uY29tghh3d3cubWVk
> aWFmaWxlcy1jaXNjby5jb20wHQYDVR0OBBYEFJXbJPCc5ySIPskL3ul5pwsnzqOn
> MB0GA1UdJQQWMBQGCCsGAQUFBwMBBggrBgEFBQcDAjCCAX0GCisGAQQB1nkCBAIE
> ggFtBIIBaQFnAHYAdv+IPwq2+5VRwmHM9Ye6NLSkzbsp3GhCCp/mZ0xaOnQAAAGL
> zF+ivwAABAMARzBFAiAV2h1n5lmpF6LmJiUBK23xPvFstpP2e1rgvrgk3/JsmwIh
> AMWUWbEUlsvuBOZU4/Zj/319+wLUe00a3oB4TrmGl8dYAHUA7s3QZNXbGs7FXLed
> tM0TojKHRny87N7DUUhZRnEftZsAAAGLzF+gvgAABAMARjBEAiAOO0eyzuDUszNb
> crQzu64SP6Rb5MK2cma9K0v+TB4xtwIgQZPKexvzy13yOg7Imn9F2d8turRwP/KI
> DgAaezKY8AUAdgBIsONr2qZHNA/lagL6nTDrHFIBy1bdLIHZu7+rOdiEcwAAAYvM
> X6BZAAAEAwBHMEUCIQCLGuUmgXM4zWGFphL39D0xVwxW9YfN3M0QHuGkh+XcDgIg
> duaXqsoaucNUg8Y7iXgB8941hMMVyayYk7qOSBXO50UwDQYJKoZIhvcNAQELBQAD
> ggEBAMn5Jz/4Zo9Z2eduV86z+cQ2GLqe00HdV+Nu2g8z3Yg8my8TioRaNbYBj3XB
> Ng+sqQ4kAAp7AGcFDFQDBh8tokdH/d9/W+K+rPED3DTADMg/xqKpwdYNjnjOIfjq
> RdcPfvvCfpz6FFG67iCfvKGUJtRxCCwxZwOrH+yo5i92dZIVJBwGPT3rUACzswWR
> erVDViWgeHdU8BK9cQWAnLoYT4EOUoYgIpowEBW2QJbsjtyF6F/M+6QmIRfAiQmz
> ltnSXsmjQg6gU+xnb+hWr8Z6fJQ7WTKklIkq+P0m9XkMILrt2e/mJCVXllvHt1bw
> 3ppvS7HIO+hyjOL0Ec815gtXQ6Q=
> -----END CERTIFICATE-----
> subject=C = US, ST = California, L = San Jose, O = Cisco Systems Inc., CN = www.cisco.com
> issuer=C = US, O = IdenTrust, OU = HydrantID Trusted Certificate Service, CN = HydrantID Server CA O1
> ---
> No client certificate CA names sent
> Peer signing digest: SHA512
> Peer signature type: RSA
> Server Temp Key: ECDH, prime256v1, 256 bits
> ---
> SSL handshake has read 5570 bytes and written 441 bytes
> Verification: OK
> ---
> New, TLSv1.2, Cipher is ECDHE-RSA-AES256-GCM-SHA384
> Server public key is 2048 bit
> Secure Renegotiation IS NOT supported
> Compression: NONE
> Expansion: NONE
> No ALPN negotiated
> SSL-Session:
>      Protocol  : TLSv1.2
>      Cipher    : ECDHE-RSA-AES256-GCM-SHA384
>      Session-ID: A5AB47FDA51B5E20A65B2C8E5BEE4C03B81A954F6E10525A2D656C0C08C6C72C
>      Session-ID-ctx:
>      Master-Key: BB59B80C43F03ABCF1B35A62DCCB15061954F9FF19AAB08907E661F20E9104EA9DF6C4AACDD57245757800B6D80629C6
>      PSK identity: None
>      PSK identity hint: None
>      SRP username: None
>      Start Time: 1718090925
>      Timeout   : 7200 (sec)
>      Verify return code: 0 (ok)
>      Extended master secret: no
> ---
> --snip--
> 
> so I think, no matter what option I set, it will be ignored
> 



From jonathanlee571 at gmail.com  Tue Jun 11 17:24:43 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Tue, 11 Jun 2024 10:24:43 -0700
Subject: [squid-users] Error Question
Message-ID: <1640E4D9-10A7-494C-9451-C5F102B9EE3D@gmail.com>

FATAL: Received Segment Violation...dying. connection: conn749025 local=192.168.1.1:3128 remote=192.168.1.5:59502 flags=1

Does any know how to fix this??
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240611/562f1805/attachment.htm>

From Antony.Stone at squid.open.source.it  Tue Jun 11 17:41:42 2024
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 11 Jun 2024 19:41:42 +0200
Subject: [squid-users] Error Question
In-Reply-To: <1640E4D9-10A7-494C-9451-C5F102B9EE3D@gmail.com>
References: <1640E4D9-10A7-494C-9451-C5F102B9EE3D@gmail.com>
Message-ID: <202406111941.42351.Antony.Stone@squid.open.source.it>

On Tuesday 11 June 2024 at 19:24:43, Jonathan Lee wrote:

> FATAL: Received Segment Violation...dying. connection: conn749025
> local=192.168.1.1:3128 remote=192.168.1.5:59502 flags=1
> 
> Does any know how to fix this??

Can you give any more information such as:

1. Which version of Squid is this?

2. Which version of which Operating System is this running under?

3. What appears in Squid's log files preceding this report?

4. What traffic was going through Squid at the time?

5. Is this an isolated incident or do you see this more frequently?

6. Can you reproduce the problem (and if so, tell us how to do so)?


The more information you can give us about your system, the more likely it is 
that we can understand what it might be doing.


Antony.

-- 
"I estimate there's a world market for about five computers."

 - Thomas J Watson, Chairman of IBM

                                                   Please reply to the list;
                                                         please *don't* CC me.


From jonathanlee571 at gmail.com  Tue Jun 11 17:54:26 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Tue, 11 Jun 2024 10:54:26 -0700
Subject: [squid-users] Error Question
In-Reply-To: <202406111941.42351.Antony.Stone@squid.open.source.it>
References: <1640E4D9-10A7-494C-9451-C5F102B9EE3D@gmail.com>
 <202406111941.42351.Antony.Stone@squid.open.source.it>
Message-ID: <9378A47A-83B2-4684-B3FC-66DC5A22F0AB@gmail.com>

> Can you give any more information such as:
> 
> 1. Which version of Squid is this?
> 
> ??squidclamav-7.2 <https://freshports.org/www/squidclamav>? ??squid_radius_auth-1.10 <https://freshports.org/www/squid_radius_auth>? ??squid-5.8 <https://freshports.org/www/squid>? ??c-icap-modules-0.5.5_1 <https://freshports.org/www/c-icap-modules>?
> 2. Which version of which Operating System is this running under?
> 		pfSense 23.05.1-Release (arm64)
> 3. What appears in Squid's log files preceding this report?
> 		Nothing out of the ordinary 

n 11 10:29:15	kernel		pid 4993 (squid), jid 0, uid 100: exited on signal 6
Jun 11 10:29:15	(squid-1)	4993	FATAL: Received Segment Violation...dying. listening port: 127.0.0.1:3128
Jun 11 10:23:13	kernel		pid 43536 (squid), jid 0, uid 100: exited on signal 6
Jun 11 10:23:05	(squid-1)	43536	FATAL: Received Segment Violation...dying. connection: conn749025 local=192.168.1.1:3128 remote=192.168.1.5:59502 flags=1
Jun 11 10:19:00	sshguard	98282	Now monitoring attacks.

prior is just normal logs 
> 4. What traffic was going through Squid at the time?
			Facebook causes issues every time this occurs
> 
> 5. Is this an isolated incident or do you see this more frequently?
			This is not isolated it occurs often
> 
> 6. Can you reproduce the problem (and if so, tell us how to do so)?
			This can be reproduced by looking at Facebook reels for 10-15 minutes after it freezes restarts Squid and error resolves
I have tested many custom options they all do this with or without StoreID both do the same thing. 
CONFIG:
# This file is automatically generated by pfSense
# Do not edit manually !

http_port 192.168.1.1:3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

http_port 127.0.0.1:3128 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=20MB cert=/usr/local/etc/squid/serverkey.pem tls-cafile=/usr/local/share/certs/ca-root-nss.crt capath=/usr/local/share/certs/ cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS tls-dh=prime256v1:/etc/dh-parameters.2048 options=NO_SSLv3

icp_port 0
digest_generation off
dns_v4_first on
pid_filename /var/run/squid/squid.pid
cache_effective_user squid
cache_effective_group proxy
error_default_language en
icon_directory /usr/local/etc/squid/icons
visible_hostname Lee_Family.home.arpa
cache_mgr jonathanlee571 at gmail.com
access_log /var/squid/logs/access.log
cache_log /var/squid/logs/cache.log
cache_store_log none
netdb_filename /var/squid/logs/netdb.state
pinger_enable on
pinger_program /usr/local/libexec/squid/pinger
sslcrtd_program /usr/local/libexec/squid/security_file_certgen -s /var/squid/lib/ssl_db -M 4MB -b 2048
tls_outgoing_options cafile=/usr/local/share/certs/ca-root-nss.crt
tls_outgoing_options capath=/usr/local/share/certs/
tls_outgoing_options options=NO_SSLv3
tls_outgoing_options cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
sslcrtd_children 10

logfile_rotate 0
debug_options rotate=0
shutdown_lifetime 3 seconds
# Allow local network(s) on interface(s)
acl localnet src  192.168.1.0/27
forwarded_for transparent
httpd_suppress_version_string on
uri_whitespace strip

acl block_hours time 00:30-05:00
ssl_bump terminate all block_hours
http_access deny all block_hours
acl getmethod method GET
acl to_ipv6 dst ipv6
acl from_ipv6 src ipv6

#tls_outgoing_options options=0x40000
request_header_access Accept-Ranges deny all
reply_header_access Accept-Ranges deny all
request_header_replace Accept-Ranges none
reply_header_replace Accept-Ranges none


tls_outgoing_options cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
tls_outgoing_options options=NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

acl HttpAccess dstdomain '/usr/local/pkg/http.access'
acl windowsupdate dstdomain '/usr/local/pkg/windowsupdate'
acl rewritedoms dstdomain '/usr/local/pkg/desdom'

store_id_program /usr/local/libexec/squid/storeid_file_rewrite /var/squid/storeid/storeid_rewrite.txt
store_id_children 10 startup=5 idle=1 concurrency=0
always_direct allow all
#store_id_access deny connect
store_id_access deny !getmethod
store_id_access allow rewritedoms
store_id_access deny all

refresh_all_ims on
reload_into_ims on
max_stale 20 years
minimum_expiry_time 0

refresh_pattern -i ^http.*squid.internal.* 43200 100% 79900 override-expire override-lastmod ignore-reload ignore-no-store ignore-must-revalidate ignore-private ignore-auth

#FACEBOOK
refresh_pattern ^https.*.facebook.com/* 10080 80% 43200

#FACEBOOK IMAGES  
refresh_pattern -i pixel.facebook.com..(jpg|png|gif|ico|css|js|jpg?) 10080 80% 43200
refresh_pattern -i .akamaihd.net..(jpg|png|gif|ico|css|js|jpg?) 10080 80% 43200 
refresh_pattern -i facebook.com.(jpg|png|gif|jpg?) 10080 80% 43200 store-stale
refresh_pattern static.(xx|ak).fbcdn.net.(jpg|gif|png|jpg?) 10080 80% 43200
refresh_pattern ^https.*profile.ak.fbcdn.net.*(jpg|gif|png|jpg?) 10080 80% 43200
refresh_pattern ^https.*fbcdn.net.*(jpg|gif|png|jpg?) 10080 80% 43200

#FACEBOOK VIDEO
refresh_pattern -i .video.ak.fbcdn.net.*.(mp4|flv|mp3|amf) 10080 80% 43200
refresh_pattern (audio|video)/(webm|mp4) 10080 80% 43200

#APPLE STUFF
refresh_pattern -i apple.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip|dist)$ 0 80% 43200  refresh-ims

#apple update
refresh_pattern -i (download|adcdownload).apple.com/.*.(pkg|dmg) 4320 100% 43200
refresh_pattern -i appldnld.apple.com 129600 100% 129600
refresh_pattern -i phobos.apple.com 129600 100% 129600
refresh_pattern -i iosapps.itunes.apple.com 129600 100% 129600

# Updates: Windows
refresh_pattern -i microsoft.com/..(cab|exe|msi|msu|msf|asf|wma|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i windowsupdate.com/..(cab|exe|msi|msu|msf|asf|wma|wmv)|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i windows.com/..(cab|exe|msi|msu|msf|asf|wmv|wma|dat|zip)$ 4320 80% 43200  refresh-ims
refresh_pattern -i microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i windows.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
refresh_pattern -i .*windowsupdate.com/.*.(cab|exe) 259200 100% 259200   
refresh_pattern -i .*update.microsoft.com/.*.(cab|exe|dll|msi|psf) 259200 100% 259200   
refresh_pattern windowsupdate.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern download.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern www.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern au.download.windowsupdate.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200 
refresh_pattern bg.v4.pr.dl.ws.microsoft.com/.*.(cab|exe|dll|msi|psf) 4320 100% 43200
#windows update NEW UPDATE 0.04
refresh_pattern update.microsoft.com/.*.(cab|exe) 43200 100% 129600    
refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200  
refresh_pattern update.microsoft.com/.*.(cab|exe|dll|msi|psf) 10080 100% 43200 
refresh_pattern -i .update.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .windowsupdate.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .download.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
refresh_pattern -i .ws.microsoft.com/.*.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 525600 100% 525600       
    
refresh_pattern ([^.]+.)?(cs|content[1-9]|hsar|content-origin|client-download).[steampowered|steamcontent].com/.*.* 43200 100% 43200     
refresh_pattern ([^.]+.)?.akamai.steamstatic.com/.*.* 43200 100% 43200

refresh_pattern -i ([^.]+.)?.adobe.com/.*.(zip|exe) 43200 100% 43200
refresh_pattern -i ([^.]+.)?.java.com/.*.(zip|exe) 43200 100% 43200
refresh_pattern -i ([^.]+.)?.sun.com/.*.(zip|exe) 43200 100% 43200
refresh_pattern -i ([^.]+.)?.oracle.com/.*.(zip|exe|tar.gz) 43200 100% 43200

refresh_pattern -i appldnld.apple.com 43200 100% 43200
refresh_pattern -i ([^.]+.)?apple.com/.*.(ipa) 43200 100% 43200
 
refresh_pattern -i ([^.]+.)?.google.com/.*.(exe|crx) 10080 80% 43200
refresh_pattern -i ([^.]+.)?g.static.com/.*.(exe|crx) 10080 80% 43200

acl https_login url_regex -i ^https.*(login|Login).*
cache deny https_login

range_offset_limit 512 MB windowsupdate
range_offset_limit 4 MB
range_offset_limit 0
quick_abort_min -1 KB

cache_mem 64 MB
maximum_object_size_in_memory 256 KB
memory_replacement_policy heap GDSF
cache_replacement_policy heap LFUDA
minimum_object_size 0 KB
maximum_object_size 512 MB
cache_dir diskd /var/squid/cache 64000 256 256
offline_mode off
cache_swap_low 90
cache_swap_high 95
acl donotcache dstdomain '/var/squid/acl/donotcache.acl'
cache deny donotcache
cache allow all
# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:    1440  20%  10080
refresh_pattern ^gopher:  1440  0%  1440
refresh_pattern -i (/cgi-bin/|?) 0  0%  0
refresh_pattern .    0  20%  4320


#Remote proxies


# Setup some default acls
# ACLs all, manager, localhost, and to_localhost are predefined.
acl allsrc src all
acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901 8080 3128 3129 1025-65535 
acl sslports port 443 563 8080 5223 2197

acl purge method PURGE
acl connect method CONNECT

# Define protocols used for redirects
acl HTTP proto HTTP
acl HTTPS proto HTTPS

# SslBump Peek and Splice
# http://wiki.squid-cache.org/Features/SslPeekAndSplice
# http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
# Match against the current step during ssl_bump evaluation [fast]
# Never matches and should not be used outside the ssl_bump context.
#
# At each SslBump step, Squid evaluates ssl_bump directives to find
# the next bumping action (e.g., peek or splice). Valid SslBump step
# values and the corresponding ssl_bump evaluation moments are:
#   SslBump1: After getting TCP-level and HTTP CONNECT info.
#   SslBump2: After getting TLS Client Hello info.
#   SslBump3: After getting TLS Server Hello info.
# These ACLs exist even when 'SSL/MITM Mode' is set to 'Custom' so that
# they can be used there for custom configuration.
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
acl banned_hosts src '/var/squid/acl/banned_hosts.acl'
acl whitelist dstdom_regex -i '/var/squid/acl/whitelist.acl'
acl blacklist dstdom_regex -i '/var/squid/acl/blacklist.acl'
http_access allow manager localhost

http_access deny manager
http_access allow purge localhost
http_access deny purge
http_access deny !safeports
http_access deny CONNECT !sslports

# Always allow localhost connections
http_access allow localhost

quick_abort_min 0 KB
quick_abort_max 0 KB
quick_abort_pct 95
request_body_max_size 0 KB
delay_pools 1
delay_class 1 2
delay_parameters 1 -1/-1 -1/-1
delay_initial_bucket_level 100
delay_access 1 allow allsrc

# Reverse Proxy settings

deny_info TCP_RESET allsrc

# Package Integration
url_rewrite_program /usr/local/bin/squidGuard -c /usr/local/etc/squidGuard/squidGuard.conf
url_rewrite_bypass off
url_rewrite_children 32 startup=8 idle=4 concurrency=0

# Custom options before auth
#host_verify_strict on

# These hosts are banned
http_access deny banned_hosts
# Always allow access to whitelist domains
http_access allow whitelist
# Block access to blacklist domains
http_access deny blacklist
# List of domains allowed to logging in to Google services
request_header_access X-GoogApps-Allowed-Domains deny all
request_header_add X-GoogApps-Allowed-Domains consumer_accounts
# Set YouTube safesearch restriction
acl youtubedst dstdomain -n www.youtube.com m.youtube.com youtubei.googleapis.com youtube.googleapis.com www.youtube-nocookie.com
request_header_access YouTube-Restrict deny all
request_header_add YouTube-Restrict none youtubedst
acl sglog url_regex -i sgr=ACCESSDENIED
http_access deny sglog
# Custom SSL/MITM options before auth
cachemgr_passwd disable offline_toggle reconfigure shutdown
cachemgr_passwd redacted! all
eui_lookup on
acl no_miss url_regex -i gateway.facebook.com/ws/realtime?
acl no_miss url_regex -i web-chat-e2ee.facebook.com/ws/chat
acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com
http_access allow CONNECT wuCONNECT localnet
http_access allow CONNECT wuCONNECT localhost
http_access allow windowsupdate localnet
http_access allow windowsupdate localhost
http_access allow HttpAccess localnet
http_access allow HttpAccess localhost
http_access deny manager
http_access deny to_ipv6
http_access deny from_ipv6

acl BrokenButTrustedServers dstdomain '/usr/local/pkg/dstdom.broken'
acl DomainMismatch ssl_error SQUID_X509_V_ERR_DOMAIN_MISMATCH
sslproxy_cert_error allow BrokenButTrustedServers DomainMismatch
sslproxy_cert_error deny all

acl splice_only src 192.168.1.8 #Tasha iPhone
acl splice_only src 192.168.1.10 #Jon iPhone
acl splice_only src 192.168.1.11 #Amazon Fire
acl splice_only src 192.168.1.15 #Tasha HP
acl splice_only src 192.168.1.16 #iPad

acl splice_only_mac arp redacted
acl splice_only_mac arp redacted
acl splice_only_mac arp redacted
acl splice_only_mac arp redacted
acl splice_only_mac arp redacted


acl NoSSLIntercept ssl::server_name_regex -i '/usr/local/pkg/reg.url.nobump'
acl NoBumpDNS dstdomain '/usr/local/pkg/dns.nobump'

acl markBumped annotate_client bumped=true
acl active_use annotate_client active=true
acl bump_only src 192.168.1.3 #webtv
acl bump_only src 192.168.1.4 #toshiba
acl bump_only src 192.168.1.5 #imac
acl bump_only src 192.168.1.9 #macbook
acl bump_only src 192.168.1.13 #dell

acl bump_only_mac arp redacted
acl bump_only_mac arp redacted
acl bump_only_mac arp redacted
acl bump_only_mac arp redacted
acl bump_only_mac arp redacted


ssl_bump peek step1
miss_access deny no_miss active_use
ssl_bump splice https_login active_use
ssl_bump splice splice_only_mac splice_only active_use
ssl_bump splice NoBumpDNS active_use
ssl_bump splice NoSSLIntercept active_use
ssl_bump bump bump_only_mac bump_only active_use
acl activated note active_use true
ssl_bump terminate !activated

acl markedBumped note bumped true
url_rewrite_access deny markedBumped

#workers 3
read_ahead_gap 32 KB
#negative_ttl 1 second
#connect_timeout 30 seconds
#request_timeout 60 seconds
#half_closed_clients off
#shutdown_lifetime 10 seconds
#negative_dns_ttl 1 seconds
#ignore_unknown_nameservers on
#client_persistent_connections off
#server_persistent_connections off
#pipeline_prefetch 100

#acl SSLIntercept ssl::server_name_regex -i '/usr/local/pkg/url.bump'
#ssl_bump bump SSLIntercept

# Setup allowed ACLs
# Allow local network(s) on interface(s)
http_access allow localnet
# Default block all to be sure
http_access deny allsrc

icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_encode off
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024

icap_service service_avi_req reqmod_precache icap://127.0.0.1:1344/squid_clamav bypass=off
adaptation_access service_avi_req allow all
icap_service service_avi_resp respmod_precache icap://127.0.0.1:1344/squid_clamav bypass=on
adaptation_access service_avi_resp allow all

> On Jun 11, 2024, at 10:41, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
> 
> On Tuesday 11 June 2024 at 19:24:43, Jonathan Lee wrote:
> 
>> FATAL: Received Segment Violation...dying. connection: conn749025
>> local=192.168.1.1:3128 remote=192.168.1.5:59502 flags=1
>> 
>> Does any know how to fix this??
> 
> Can you give any more information such as:
> 
> 1. Which version of Squid is this?
> 
> 2. Which version of which Operating System is this running under?
> 
> 3. What appears in Squid's log files preceding this report?
> 
> 4. What traffic was going through Squid at the time?
> 
> 5. Is this an isolated incident or do you see this more frequently?
> 
> 6. Can you reproduce the problem (and if so, tell us how to do so)?
> 
> 
> The more information you can give us about your system, the more likely it is 
> that we can understand what it might be doing.
> 
> 
> Antony.
> 
> -- 
> "I estimate there's a world market for about five computers."
> 
> - Thomas J Watson, Chairman of IBM
> 
>                                                   Please reply to the list;
>                                                         please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240611/c0d11563/attachment.htm>

From rousskov at measurement-factory.com  Tue Jun 11 18:04:41 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 11 Jun 2024 14:04:41 -0400
Subject: [squid-users] Error Question
In-Reply-To: <1640E4D9-10A7-494C-9451-C5F102B9EE3D@gmail.com>
References: <1640E4D9-10A7-494C-9451-C5F102B9EE3D@gmail.com>
Message-ID: <0eceb0cb-6ab8-4ab0-bf38-0db74d2ca430@measurement-factory.com>

On 2024-06-11 13:24, Jonathan Lee wrote:
> FATAL: Received Segment Violation...dying.
> 
> Does any know how to fix this??

Please post full backtrace from this failure:
https://wiki.squid-cache.org/SquidFaq/BugReporting#crashes-and-core-dumps

The other information you have already provided may help, but without a 
usable stack trace, it is unlikely that somebody will guess what is 
going on with your Squid.

Please note that you are running Squid v5 that is no longer supported by 
the Squid Project. You should upgrade to v6+. However, I do not know 
whether that upgrade is going to address the specific problem you are 
suffering from.


HTH,

Alex.



From jonathanlee571 at gmail.com  Tue Jun 11 18:17:23 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Tue, 11 Jun 2024 11:17:23 -0700
Subject: [squid-users] Error Question
In-Reply-To: <0eceb0cb-6ab8-4ab0-bf38-0db74d2ca430@measurement-factory.com>
References: <1640E4D9-10A7-494C-9451-C5F102B9EE3D@gmail.com>
 <0eceb0cb-6ab8-4ab0-bf38-0db74d2ca430@measurement-factory.com>
Message-ID: <C386B28E-E4DA-4296-997C-F3997DE4CE6B@gmail.com>

I have attempted to upgrade the program fails to recognize ?DHParamas Key Size? and will no longer use my certificates and shows many errors. I am kind of stuck on 5.8

I do not know where the core dump would be located on pfSense let me research this and get back to you. 

> On Jun 11, 2024, at 11:04, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> On 2024-06-11 13:24, Jonathan Lee wrote:
>> FATAL: Received Segment Violation...dying.
>> Does any know how to fix this??
> 
> Please post full backtrace from this failure:
> https://wiki.squid-cache.org/SquidFaq/BugReporting#crashes-and-core-dumps
> 
> The other information you have already provided may help, but without a usable stack trace, it is unlikely that somebody will guess what is going on with your Squid.
> 
> Please note that you are running Squid v5 that is no longer supported by the Squid Project. You should upgrade to v6+. However, I do not know whether that upgrade is going to address the specific problem you are suffering from.
> 
> 
> HTH,
> 
> Alex.
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From jonathanlee571 at gmail.com  Tue Jun 11 18:24:31 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Tue, 11 Jun 2024 11:24:31 -0700
Subject: [squid-users] Error Question
In-Reply-To: <C386B28E-E4DA-4296-997C-F3997DE4CE6B@gmail.com>
References: <1640E4D9-10A7-494C-9451-C5F102B9EE3D@gmail.com>
 <0eceb0cb-6ab8-4ab0-bf38-0db74d2ca430@measurement-factory.com>
 <C386B28E-E4DA-4296-997C-F3997DE4CE6B@gmail.com>
Message-ID: <6494229C-C86C-47DC-B8A9-8CDF1F58ED36@gmail.com>

thanks i have enabled

coredump_dir /var/squid/logs

I will submit a dump as soon as it occurs again

> On Jun 11, 2024, at 11:17, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> I have attempted to upgrade the program fails to recognize ?DHParamas Key Size? and will no longer use my certificates and shows many errors. I am kind of stuck on 5.8
> 
> I do not know where the core dump would be located on pfSense let me research this and get back to you. 
> 
>> On Jun 11, 2024, at 11:04, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>> 
>> On 2024-06-11 13:24, Jonathan Lee wrote:
>>> FATAL: Received Segment Violation...dying.
>>> Does any know how to fix this??
>> 
>> Please post full backtrace from this failure:
>> https://wiki.squid-cache.org/SquidFaq/BugReporting#crashes-and-core-dumps
>> 
>> The other information you have already provided may help, but without a usable stack trace, it is unlikely that somebody will guess what is going on with your Squid.
>> 
>> Please note that you are running Squid v5 that is no longer supported by the Squid Project. You should upgrade to v6+. However, I do not know whether that upgrade is going to address the specific problem you are suffering from.
>> 
>> 
>> HTH,
>> 
>> Alex.
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users
> 



From jonathanlee571 at gmail.com  Tue Jun 11 18:46:28 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Tue, 11 Jun 2024 11:46:28 -0700
Subject: [squid-users] Error Question
In-Reply-To: <6494229C-C86C-47DC-B8A9-8CDF1F58ED36@gmail.com>
References: <1640E4D9-10A7-494C-9451-C5F102B9EE3D@gmail.com>
 <0eceb0cb-6ab8-4ab0-bf38-0db74d2ca430@measurement-factory.com>
 <C386B28E-E4DA-4296-997C-F3997DE4CE6B@gmail.com>
 <6494229C-C86C-47DC-B8A9-8CDF1F58ED36@gmail.com>
Message-ID: <62896727-4EC3-40F8-BB7B-753CB57A1915@gmail.com>

2024-05-16 14:10:23 [60780] loading dbfile /var/db/squidGuard/Nick_Blocks/urls.db
2024/06/11 10:23:05 kid1| FATAL: Received Segment Violation...dying.
2024/06/11 10:23:25 kid1| Starting Squid Cache version 5.8 for aarch64-portbld-freebsd14.0...
2024/06/11 10:23:25 kid1| Service Name: squid
2024-06-11 10:23:25 [9471] (squidGuard): can't write to logfile /var/log/squidGuard/squidGuard.log
2024-06-11 10:23:25 [9471] New setting: logdir: /var/squidGuard/log
2024-06-11 10:23:25 [9471] New setting: dbhome: /var/db/squidGuard
2024-06-11 10:23:25 [9471] init domainlist /var/db/squidGuard/blk_blacklists_adult/domains
2024-06-11 10:23:25 [9471] loading dbfile /var/db/squidGuard/blk_blacklists_adult/domains.db
2024-06-11 10:23:25 [9471] init expressionlist /var/db/squidGuard/blk_blacklists_adult/expressions

There is my log file being blocked for some reason 

> On Jun 11, 2024, at 11:24, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> thanks i have enabled
> 
> coredump_dir /var/squid/logs
> 
> I will submit a dump as soon as it occurs again
> 
>> On Jun 11, 2024, at 11:17, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>> 
>> I have attempted to upgrade the program fails to recognize ?DHParamas Key Size? and will no longer use my certificates and shows many errors. I am kind of stuck on 5.8
>> 
>> I do not know where the core dump would be located on pfSense let me research this and get back to you. 
>> 
>>> On Jun 11, 2024, at 11:04, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>> 
>>> On 2024-06-11 13:24, Jonathan Lee wrote:
>>>> FATAL: Received Segment Violation...dying.
>>>> Does any know how to fix this??
>>> 
>>> Please post full backtrace from this failure:
>>> https://wiki.squid-cache.org/SquidFaq/BugReporting#crashes-and-core-dumps
>>> 
>>> The other information you have already provided may help, but without a usable stack trace, it is unlikely that somebody will guess what is going on with your Squid.
>>> 
>>> Please note that you are running Squid v5 that is no longer supported by the Squid Project. You should upgrade to v6+. However, I do not know whether that upgrade is going to address the specific problem you are suffering from.
>>> 
>>> 
>>> HTH,
>>> 
>>> Alex.
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
>> 
> 



From rousskov at measurement-factory.com  Tue Jun 11 21:00:01 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 11 Jun 2024 17:00:01 -0400
Subject: [squid-users] Error Question
In-Reply-To: <62896727-4EC3-40F8-BB7B-753CB57A1915@gmail.com>
References: <1640E4D9-10A7-494C-9451-C5F102B9EE3D@gmail.com>
 <0eceb0cb-6ab8-4ab0-bf38-0db74d2ca430@measurement-factory.com>
 <C386B28E-E4DA-4296-997C-F3997DE4CE6B@gmail.com>
 <6494229C-C86C-47DC-B8A9-8CDF1F58ED36@gmail.com>
 <62896727-4EC3-40F8-BB7B-753CB57A1915@gmail.com>
Message-ID: <48e9c8dc-9d9c-403e-bf02-d7747e93abb9@measurement-factory.com>

On 2024-06-11 14:46, Jonathan Lee wrote:
> 2024-05-16 14:10:23 [60780] loading dbfile /var/db/squidGuard/Nick_Blocks/urls.db
> 2024/06/11 10:23:05 kid1| FATAL: Received Segment Violation...dying.
> 2024/06/11 10:23:25 kid1| Starting Squid Cache version 5.8 for aarch64-portbld-freebsd14.0...
> 2024/06/11 10:23:25 kid1| Service Name: squid
> 2024-06-11 10:23:25 [9471] (squidGuard): can't write to logfile /var/log/squidGuard/squidGuard.log
> 2024-06-11 10:23:25 [9471] New setting: logdir: /var/squidGuard/log
> 2024-06-11 10:23:25 [9471] New setting: dbhome: /var/db/squidGuard
> 2024-06-11 10:23:25 [9471] init domainlist /var/db/squidGuard/blk_blacklists_adult/domains
> 2024-06-11 10:23:25 [9471] loading dbfile /var/db/squidGuard/blk_blacklists_adult/domains.db
> 2024-06-11 10:23:25 [9471] init expressionlist /var/db/squidGuard/blk_blacklists_adult/expressions
> 
> There is my log file being blocked for some reason

Just to avoid a misunderstanding: This mailing list thread is about the 
segmentation fault bug you have reported earlier. The above log is _not_ 
the requested backtrace that we need to triage that bug. If there is 
another problem you need help with, please start a new mailing list 
thread and detail _that_ problem there.


Thank you,

Alex.


>> On Jun 11, 2024, at 11:24, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>
>> thanks i have enabled
>>
>> coredump_dir /var/squid/logs
>>
>> I will submit a dump as soon as it occurs again
>>
>>> On Jun 11, 2024, at 11:17, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>
>>> I have attempted to upgrade the program fails to recognize ?DHParamas Key Size? and will no longer use my certificates and shows many errors. I am kind of stuck on 5.8
>>>
>>> I do not know where the core dump would be located on pfSense let me research this and get back to you.
>>>
>>>> On Jun 11, 2024, at 11:04, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>>
>>>> On 2024-06-11 13:24, Jonathan Lee wrote:
>>>>> FATAL: Received Segment Violation...dying.
>>>>> Does any know how to fix this??
>>>>
>>>> Please post full backtrace from this failure:
>>>> https://wiki.squid-cache.org/SquidFaq/BugReporting#crashes-and-core-dumps
>>>>
>>>> The other information you have already provided may help, but without a usable stack trace, it is unlikely that somebody will guess what is going on with your Squid.
>>>>
>>>> Please note that you are running Squid v5 that is no longer supported by the Squid Project. You should upgrade to v6+. However, I do not know whether that upgrade is going to address the specific problem you are suffering from.
>>>>
>>>>
>>>> HTH,
>>>>
>>>> Alex.
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>>>
>>



From jonathanlee571 at gmail.com  Tue Jun 11 21:06:46 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Tue, 11 Jun 2024 14:06:46 -0700
Subject: [squid-users] Error Question
In-Reply-To: <48e9c8dc-9d9c-403e-bf02-d7747e93abb9@measurement-factory.com>
References: <1640E4D9-10A7-494C-9451-C5F102B9EE3D@gmail.com>
 <0eceb0cb-6ab8-4ab0-bf38-0db74d2ca430@measurement-factory.com>
 <C386B28E-E4DA-4296-997C-F3997DE4CE6B@gmail.com>
 <6494229C-C86C-47DC-B8A9-8CDF1F58ED36@gmail.com>
 <62896727-4EC3-40F8-BB7B-753CB57A1915@gmail.com>
 <48e9c8dc-9d9c-403e-bf02-d7747e93abb9@measurement-factory.com>
Message-ID: <6BBD0CD7-766A-41C5-83C4-9938F4450A45@gmail.com>

I can?t locate the dump file for segmentation fault it never generates one. I am running cache it shows a swap file however it is not readable.

I fixed the other issues. 

> On Jun 11, 2024, at 14:00, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> On 2024-06-11 14:46, Jonathan Lee wrote:
>> 2024-05-16 14:10:23 [60780] loading dbfile /var/db/squidGuard/Nick_Blocks/urls.db
>> 2024/06/11 10:23:05 kid1| FATAL: Received Segment Violation...dying.
>> 2024/06/11 10:23:25 kid1| Starting Squid Cache version 5.8 for aarch64-portbld-freebsd14.0...
>> 2024/06/11 10:23:25 kid1| Service Name: squid
>> 2024-06-11 10:23:25 [9471] (squidGuard): can't write to logfile /var/log/squidGuard/squidGuard.log
>> 2024-06-11 10:23:25 [9471] New setting: logdir: /var/squidGuard/log
>> 2024-06-11 10:23:25 [9471] New setting: dbhome: /var/db/squidGuard
>> 2024-06-11 10:23:25 [9471] init domainlist /var/db/squidGuard/blk_blacklists_adult/domains
>> 2024-06-11 10:23:25 [9471] loading dbfile /var/db/squidGuard/blk_blacklists_adult/domains.db
>> 2024-06-11 10:23:25 [9471] init expressionlist /var/db/squidGuard/blk_blacklists_adult/expressions
>> There is my log file being blocked for some reason
> 
> Just to avoid a misunderstanding: This mailing list thread is about the segmentation fault bug you have reported earlier. The above log is _not_ the requested backtrace that we need to triage that bug. If there is another problem you need help with, please start a new mailing list thread and detail _that_ problem there.
> 
> 
> Thank you,
> 
> Alex.
> 
> 
>>> On Jun 11, 2024, at 11:24, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>> 
>>> thanks i have enabled
>>> 
>>> coredump_dir /var/squid/logs
>>> 
>>> I will submit a dump as soon as it occurs again
>>> 
>>>> On Jun 11, 2024, at 11:17, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>> 
>>>> I have attempted to upgrade the program fails to recognize ?DHParamas Key Size? and will no longer use my certificates and shows many errors. I am kind of stuck on 5.8
>>>> 
>>>> I do not know where the core dump would be located on pfSense let me research this and get back to you.
>>>> 
>>>>> On Jun 11, 2024, at 11:04, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>>> 
>>>>> On 2024-06-11 13:24, Jonathan Lee wrote:
>>>>>> FATAL: Received Segment Violation...dying.
>>>>>> Does any know how to fix this??
>>>>> 
>>>>> Please post full backtrace from this failure:
>>>>> https://wiki.squid-cache.org/SquidFaq/BugReporting#crashes-and-core-dumps
>>>>> 
>>>>> The other information you have already provided may help, but without a usable stack trace, it is unlikely that somebody will guess what is going on with your Squid.
>>>>> 
>>>>> Please note that you are running Squid v5 that is no longer supported by the Squid Project. You should upgrade to v6+. However, I do not know whether that upgrade is going to address the specific problem you are suffering from.
>>>>> 
>>>>> 
>>>>> HTH,
>>>>> 
>>>>> Alex.
>>>>> 
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> https://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240611/94bdfe67/attachment.htm>

From rousskov at measurement-factory.com  Tue Jun 11 21:42:44 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 11 Jun 2024 17:42:44 -0400
Subject: [squid-users] Error Question
In-Reply-To: <6BBD0CD7-766A-41C5-83C4-9938F4450A45@gmail.com>
References: <1640E4D9-10A7-494C-9451-C5F102B9EE3D@gmail.com>
 <0eceb0cb-6ab8-4ab0-bf38-0db74d2ca430@measurement-factory.com>
 <C386B28E-E4DA-4296-997C-F3997DE4CE6B@gmail.com>
 <6494229C-C86C-47DC-B8A9-8CDF1F58ED36@gmail.com>
 <62896727-4EC3-40F8-BB7B-753CB57A1915@gmail.com>
 <48e9c8dc-9d9c-403e-bf02-d7747e93abb9@measurement-factory.com>
 <6BBD0CD7-766A-41C5-83C4-9938F4450A45@gmail.com>
Message-ID: <38e06b53-8d5f-4efb-be67-0fab935b6b75@measurement-factory.com>

On 2024-06-11 17:06, Jonathan Lee wrote:

> I can?t locate the dump file for segmentation fault it never generates 
> one. 

I assume that you cannot locate the core dump file because your 
OS/environment is not configured to produce core dump files. Enabling 
core dumps is a sysadmin task that is mostly independent from Squid 
specifics. The FAQ I linked to earlier has some hints, but none are 
pfsense-specific. If others on the list do not tell you how to enable 
coredumps on pfsense, you may want to ask on pfsense or sysadmin forums.

Alternatively, you can try starting Squid from gdb or attacking gdb to a 
running Squid kid process, but neither is trivial, especially if you are 
using SMP Squid. The same FAQ has some hints.

BTW, to test whether core dumps are enabled in your environment, you do 
not need to wait for Squid to crash. Instead, you can send a SIGABRT 
signal (as "root" if needed) to any running test process and see whether 
it creates a core dump file when crashing.


> I am running cache it shows a swap file however it is not readable.

There are many kinds of swap files, but the core file we need is 
probably not one of them.


> I fixed the other issues.

Glad to hear that!

Alex.


>> On Jun 11, 2024, at 14:00, Alex Rousskov 
>> <rousskov at measurement-factory.com> wrote:
>>
>> On 2024-06-11 14:46, Jonathan Lee wrote:
>>> 2024-05-16 14:10:23 [60780] loading dbfile 
>>> /var/db/squidGuard/Nick_Blocks/urls.db
>>> 2024/06/11 10:23:05 kid1| FATAL: Received Segment Violation...dying.
>>> 2024/06/11 10:23:25 kid1| Starting Squid Cache version 5.8 for 
>>> aarch64-portbld-freebsd14.0...
>>> 2024/06/11 10:23:25 kid1| Service Name: squid
>>> 2024-06-11 10:23:25 [9471] (squidGuard): can't write to logfile 
>>> /var/log/squidGuard/squidGuard.log
>>> 2024-06-11 10:23:25 [9471] New setting: logdir: /var/squidGuard/log
>>> 2024-06-11 10:23:25 [9471] New setting: dbhome: /var/db/squidGuard
>>> 2024-06-11 10:23:25 [9471] init domainlist 
>>> /var/db/squidGuard/blk_blacklists_adult/domains
>>> 2024-06-11 10:23:25 [9471] loading dbfile 
>>> /var/db/squidGuard/blk_blacklists_adult/domains.db
>>> 2024-06-11 10:23:25 [9471] init expressionlist 
>>> /var/db/squidGuard/blk_blacklists_adult/expressions
>>> There is my log file being blocked for some reason
>>
>> Just to avoid a misunderstanding: This mailing list thread is about 
>> the segmentation fault bug you have reported earlier. The above log is 
>> _not_ the requested backtrace that we need to triage that bug. If 
>> there is another problem you need help with, please start a new 
>> mailing list thread and detail _that_ problem there.
>>
>>
>> Thank you,
>>
>> Alex.
>>
>>
>>>> On Jun 11, 2024, at 11:24, Jonathan Lee <jonathanlee571 at gmail.com> 
>>>> wrote:
>>>>
>>>> thanks i have enabled
>>>>
>>>> coredump_dir /var/squid/logs
>>>>
>>>> I will submit a dump as soon as it occurs again
>>>>
>>>>> On Jun 11, 2024, at 11:17, Jonathan Lee <jonathanlee571 at gmail.com> 
>>>>> wrote:
>>>>>
>>>>> I have attempted to upgrade the program fails to recognize 
>>>>> ?DHParamas Key Size? and will no longer use my certificates and 
>>>>> shows many errors. I am kind of stuck on 5.8
>>>>>
>>>>> I do not know where the core dump would be located on pfSense let 
>>>>> me research this and get back to you.
>>>>>
>>>>>> On Jun 11, 2024, at 11:04, Alex Rousskov 
>>>>>> <rousskov at measurement-factory.com> wrote:
>>>>>>
>>>>>> On 2024-06-11 13:24, Jonathan Lee wrote:
>>>>>>> FATAL: Received Segment Violation...dying.
>>>>>>> Does any know how to fix this??
>>>>>>
>>>>>> Please post full backtrace from this failure:
>>>>>> https://wiki.squid-cache.org/SquidFaq/BugReporting#crashes-and-core-dumps
>>>>>>
>>>>>> The other information you have already provided may help, but 
>>>>>> without a usable stack trace, it is unlikely that somebody will 
>>>>>> guess what is going on with your Squid.
>>>>>>
>>>>>> Please note that you are running Squid v5 that is no longer 
>>>>>> supported by the Squid Project. You should upgrade to v6+. 
>>>>>> However, I do not know whether that upgrade is going to address 
>>>>>> the specific problem you are suffering from.
>>>>>>
>>>>>>
>>>>>> HTH,
>>>>>>
>>>>>> Alex.
>>>>>>
>>>>>> _______________________________________________
>>>>>> squid-users mailing list
>>>>>> squid-users at lists.squid-cache.org
>>>>>> https://lists.squid-cache.org/listinfo/squid-users
> 



From jonathanlee571 at gmail.com  Tue Jun 11 22:09:18 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Tue, 11 Jun 2024 15:09:18 -0700
Subject: [squid-users] Error Question
In-Reply-To: <38e06b53-8d5f-4efb-be67-0fab935b6b75@measurement-factory.com>
References: <1640E4D9-10A7-494C-9451-C5F102B9EE3D@gmail.com>
 <0eceb0cb-6ab8-4ab0-bf38-0db74d2ca430@measurement-factory.com>
 <C386B28E-E4DA-4296-997C-F3997DE4CE6B@gmail.com>
 <6494229C-C86C-47DC-B8A9-8CDF1F58ED36@gmail.com>
 <62896727-4EC3-40F8-BB7B-753CB57A1915@gmail.com>
 <48e9c8dc-9d9c-403e-bf02-d7747e93abb9@measurement-factory.com>
 <6BBD0CD7-766A-41C5-83C4-9938F4450A45@gmail.com>
 <38e06b53-8d5f-4efb-be67-0fab935b6b75@measurement-factory.com>
Message-ID: <76BF520C-3E53-48D8-A189-092C053A98F8@gmail.com>

When I run  sysctl debug.kdb.panic=1 I get a crash report for pfsense in var/crash should my path for core dumps use my swap drive too?



> On Jun 11, 2024, at 14:42, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> On 2024-06-11 17:06, Jonathan Lee wrote:
> 
>> I can?t locate the dump file for segmentation fault it never generates one.
> 
> I assume that you cannot locate the core dump file because your OS/environment is not configured to produce core dump files. Enabling core dumps is a sysadmin task that is mostly independent from Squid specifics. The FAQ I linked to earlier has some hints, but none are pfsense-specific. If others on the list do not tell you how to enable coredumps on pfsense, you may want to ask on pfsense or sysadmin forums.
> 
> Alternatively, you can try starting Squid from gdb or attacking gdb to a running Squid kid process, but neither is trivial, especially if you are using SMP Squid. The same FAQ has some hints.
> 
> BTW, to test whether core dumps are enabled in your environment, you do not need to wait for Squid to crash. Instead, you can send a SIGABRT signal (as "root" if needed) to any running test process and see whether it creates a core dump file when crashing.
> 
> 
>> I am running cache it shows a swap file however it is not readable.
> 
> There are many kinds of swap files, but the core file we need is probably not one of them.
> 
> 
>> I fixed the other issues.
> 
> Glad to hear that!
> 
> Alex.
> 
> 
>>> On Jun 11, 2024, at 14:00, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>> 
>>> On 2024-06-11 14:46, Jonathan Lee wrote:
>>>> 2024-05-16 14:10:23 [60780] loading dbfile /var/db/squidGuard/Nick_Blocks/urls.db
>>>> 2024/06/11 10:23:05 kid1| FATAL: Received Segment Violation...dying.
>>>> 2024/06/11 10:23:25 kid1| Starting Squid Cache version 5.8 for aarch64-portbld-freebsd14.0...
>>>> 2024/06/11 10:23:25 kid1| Service Name: squid
>>>> 2024-06-11 10:23:25 [9471] (squidGuard): can't write to logfile /var/log/squidGuard/squidGuard.log
>>>> 2024-06-11 10:23:25 [9471] New setting: logdir: /var/squidGuard/log
>>>> 2024-06-11 10:23:25 [9471] New setting: dbhome: /var/db/squidGuard
>>>> 2024-06-11 10:23:25 [9471] init domainlist /var/db/squidGuard/blk_blacklists_adult/domains
>>>> 2024-06-11 10:23:25 [9471] loading dbfile /var/db/squidGuard/blk_blacklists_adult/domains.db
>>>> 2024-06-11 10:23:25 [9471] init expressionlist /var/db/squidGuard/blk_blacklists_adult/expressions
>>>> There is my log file being blocked for some reason
>>> 
>>> Just to avoid a misunderstanding: This mailing list thread is about the segmentation fault bug you have reported earlier. The above log is _not_ the requested backtrace that we need to triage that bug. If there is another problem you need help with, please start a new mailing list thread and detail _that_ problem there.
>>> 
>>> 
>>> Thank you,
>>> 
>>> Alex.
>>> 
>>> 
>>>>> On Jun 11, 2024, at 11:24, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>>> 
>>>>> thanks i have enabled
>>>>> 
>>>>> coredump_dir /var/squid/logs
>>>>> 
>>>>> I will submit a dump as soon as it occurs again
>>>>> 
>>>>>> On Jun 11, 2024, at 11:17, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>>>>> 
>>>>>> I have attempted to upgrade the program fails to recognize ?DHParamas Key Size? and will no longer use my certificates and shows many errors. I am kind of stuck on 5.8
>>>>>> 
>>>>>> I do not know where the core dump would be located on pfSense let me research this and get back to you.
>>>>>> 
>>>>>>> On Jun 11, 2024, at 11:04, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>>>>> 
>>>>>>> On 2024-06-11 13:24, Jonathan Lee wrote:
>>>>>>>> FATAL: Received Segment Violation...dying.
>>>>>>>> Does any know how to fix this??
>>>>>>> 
>>>>>>> Please post full backtrace from this failure:
>>>>>>> https://wiki.squid-cache.org/SquidFaq/BugReporting#crashes-and-core-dumps
>>>>>>> 
>>>>>>> The other information you have already provided may help, but without a usable stack trace, it is unlikely that somebody will guess what is going on with your Squid.
>>>>>>> 
>>>>>>> Please note that you are running Squid v5 that is no longer supported by the Squid Project. You should upgrade to v6+. However, I do not know whether that upgrade is going to address the specific problem you are suffering from.
>>>>>>> 
>>>>>>> 
>>>>>>> HTH,
>>>>>>> 
>>>>>>> Alex.
>>>>>>> 
>>>>>>> _______________________________________________
>>>>>>> squid-users mailing list
>>>>>>> squid-users at lists.squid-cache.org
>>>>>>> https://lists.squid-cache.org/listinfo/squid-users
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240611/0efbf52c/attachment.htm>

From rousskov at measurement-factory.com  Wed Jun 12 02:15:39 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 11 Jun 2024 22:15:39 -0400
Subject: [squid-users] Error Question
In-Reply-To: <76BF520C-3E53-48D8-A189-092C053A98F8@gmail.com>
References: <1640E4D9-10A7-494C-9451-C5F102B9EE3D@gmail.com>
 <0eceb0cb-6ab8-4ab0-bf38-0db74d2ca430@measurement-factory.com>
 <C386B28E-E4DA-4296-997C-F3997DE4CE6B@gmail.com>
 <6494229C-C86C-47DC-B8A9-8CDF1F58ED36@gmail.com>
 <62896727-4EC3-40F8-BB7B-753CB57A1915@gmail.com>
 <48e9c8dc-9d9c-403e-bf02-d7747e93abb9@measurement-factory.com>
 <6BBD0CD7-766A-41C5-83C4-9938F4450A45@gmail.com>
 <38e06b53-8d5f-4efb-be67-0fab935b6b75@measurement-factory.com>
 <76BF520C-3E53-48D8-A189-092C053A98F8@gmail.com>
Message-ID: <dbbe25c6-192f-4aeb-a1e9-d6aa10ba38b9@measurement-factory.com>

On 2024-06-11 18:09, Jonathan Lee wrote:
> When I run sysctl debug.kdb.panic=1 I get a crash report for pfsense in 
> var/crash should my path for core dumps use my swap drive too?

It is a pfsense-specific question that I do not know the answer for. 
Perhaps others do. However, you may be able to get an answer faster if 
you set coredump_dir in squid.conf to /var/crash, start Squid with that 
configuration, and then kill a running Squid worker with SIGABRT.


HTH,

Alex.


>> On Jun 11, 2024, at 14:42, Alex Rousskov wrote:
>>
>> On 2024-06-11 17:06, Jonathan Lee wrote:
>>
>>> I can?t locate the dump file for segmentation fault it never 
>>> generates one.
>>
>> I assume that you cannot locate the core dump file because your 
>> OS/environment is not configured to produce core dump files. Enabling 
>> core dumps is a sysadmin task that is mostly independent from Squid 
>> specifics. The FAQ I linked to earlier has some hints, but none are 
>> pfsense-specific. If others on the list do not tell you how to enable 
>> coredumps on pfsense, you may want to ask on pfsense or sysadmin forums.
>>
>> Alternatively, you can try starting Squid from gdb or attacking gdb to 
>> a running Squid kid process, but neither is trivial, especially if you 
>> are using SMP Squid. The same FAQ has some hints.
>>
>> BTW, to test whether core dumps are enabled in your environment, you 
>> do not need to wait for Squid to crash. Instead, you can send a 
>> SIGABRT signal (as "root" if needed) to any running test process and 
>> see whether it creates a core dump file when crashing.
>>
>>
>>> I am running cache it shows a swap file however it is not readable.
>>
>> There are many kinds of swap files, but the core file we need is 
>> probably not one of them.
>>
>>
>>> I fixed the other issues.
>>
>> Glad to hear that!
>>
>> Alex.
>>
>>
>>>> On Jun 11, 2024, at 14:00, Alex Rousskov 
>>>> <rousskov at measurement-factory.com> wrote:
>>>>
>>>> On 2024-06-11 14:46, Jonathan Lee wrote:
>>>>> 2024-05-16 14:10:23 [60780] loading dbfile 
>>>>> /var/db/squidGuard/Nick_Blocks/urls.db
>>>>> 2024/06/11 10:23:05 kid1| FATAL: Received Segment Violation...dying.
>>>>> 2024/06/11 10:23:25 kid1| Starting Squid Cache version 5.8 for 
>>>>> aarch64-portbld-freebsd14.0...
>>>>> 2024/06/11 10:23:25 kid1| Service Name: squid
>>>>> 2024-06-11 10:23:25 [9471] (squidGuard): can't write to logfile 
>>>>> /var/log/squidGuard/squidGuard.log
>>>>> 2024-06-11 10:23:25 [9471] New setting: logdir: /var/squidGuard/log
>>>>> 2024-06-11 10:23:25 [9471] New setting: dbhome: /var/db/squidGuard
>>>>> 2024-06-11 10:23:25 [9471] init domainlist 
>>>>> /var/db/squidGuard/blk_blacklists_adult/domains
>>>>> 2024-06-11 10:23:25 [9471] loading dbfile 
>>>>> /var/db/squidGuard/blk_blacklists_adult/domains.db
>>>>> 2024-06-11 10:23:25 [9471] init expressionlist 
>>>>> /var/db/squidGuard/blk_blacklists_adult/expressions
>>>>> There is my log file being blocked for some reason
>>>>
>>>> Just to avoid a misunderstanding: This mailing list thread is about 
>>>> the segmentation fault bug you have reported earlier. The above log 
>>>> is _not_ the requested backtrace that we need to triage that bug. If 
>>>> there is another problem you need help with, please start a new 
>>>> mailing list thread and detail _that_ problem there.
>>>>
>>>>
>>>> Thank you,
>>>>
>>>> Alex.
>>>>
>>>>
>>>>>> On Jun 11, 2024, at 11:24, Jonathan Lee <jonathanlee571 at gmail.com> 
>>>>>> wrote:
>>>>>>
>>>>>> thanks i have enabled
>>>>>>
>>>>>> coredump_dir /var/squid/logs
>>>>>>
>>>>>> I will submit a dump as soon as it occurs again
>>>>>>
>>>>>>> On Jun 11, 2024, at 11:17, Jonathan Lee 
>>>>>>> <jonathanlee571 at gmail.com> wrote:
>>>>>>>
>>>>>>> I have attempted to upgrade the program fails to recognize 
>>>>>>> ?DHParamas Key Size? and will no longer use my certificates and 
>>>>>>> shows many errors. I am kind of stuck on 5.8
>>>>>>>
>>>>>>> I do not know where the core dump would be located on pfSense let 
>>>>>>> me research this and get back to you.
>>>>>>>
>>>>>>>> On Jun 11, 2024, at 11:04, Alex Rousskov 
>>>>>>>> <rousskov at measurement-factory.com> wrote:
>>>>>>>>
>>>>>>>> On 2024-06-11 13:24, Jonathan Lee wrote:
>>>>>>>>> FATAL: Received Segment Violation...dying.
>>>>>>>>> Does any know how to fix this??
>>>>>>>>
>>>>>>>> Please post full backtrace from this failure:
>>>>>>>> https://wiki.squid-cache.org/SquidFaq/BugReporting#crashes-and-core-dumps
>>>>>>>>
>>>>>>>> The other information you have already provided may help, but 
>>>>>>>> without a usable stack trace, it is unlikely that somebody will 
>>>>>>>> guess what is going on with your Squid.
>>>>>>>>
>>>>>>>> Please note that you are running Squid v5 that is no longer 
>>>>>>>> supported by the Squid Project. You should upgrade to v6+. 
>>>>>>>> However, I do not know whether that upgrade is going to address 
>>>>>>>> the specific problem you are suffering from.
>>>>>>>>
>>>>>>>>
>>>>>>>> HTH,
>>>>>>>>
>>>>>>>> Alex.
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> squid-users mailing list
>>>>>>>> squid-users at lists.squid-cache.org
>>>>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>
> 



From jonathanlee571 at gmail.com  Wed Jun 12 03:32:27 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Tue, 11 Jun 2024 20:32:27 -0700
Subject: [squid-users] Error Question
In-Reply-To: <dbbe25c6-192f-4aeb-a1e9-d6aa10ba38b9@measurement-factory.com>
References: <dbbe25c6-192f-4aeb-a1e9-d6aa10ba38b9@measurement-factory.com>
Message-ID: <F77D6A2C-3191-413D-A3E5-E71DEBBF2A38@gmail.com>

So I just run this on command line SIGABRT squid? It?s funny as soon as I enabled the sysctl command and set the directory it won?t crash anymore. I also changed it to reside on the loopback before it was only on my lan interface. I run an external drive as my swap partition or a swap drive, it works I get crash reports when playing around with stuff. /dev/da0 or something it dumps to it and when it reboots shows in the var/crash folder and will display on gui report ready, again if anyone else knows pfSense let me know. I also added an item to the Netgate forum to, but not many users are Squid wizards so it might take a long time to get any community input over there. 
Sent from my iPhone

> On Jun 11, 2024, at 19:15, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> SIGABRT


From rousskov at measurement-factory.com  Wed Jun 12 13:13:30 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 12 Jun 2024 09:13:30 -0400
Subject: [squid-users] Error Question
In-Reply-To: <F77D6A2C-3191-413D-A3E5-E71DEBBF2A38@gmail.com>
References: <dbbe25c6-192f-4aeb-a1e9-d6aa10ba38b9@measurement-factory.com>
 <F77D6A2C-3191-413D-A3E5-E71DEBBF2A38@gmail.com>
Message-ID: <bc60263d-d480-4b97-a461-3094be326766@measurement-factory.com>

On 2024-06-11 23:32, Jonathan Lee wrote:

> So I just run this on command line SIGABRT squid?

On Unix-like systems, the command to send a process a signal is called 
"kill": https://www.man7.org/linux/man-pages/man1/kill.1p.html

For example, if you want to abort a Squid worker process that has OS 
process ID (PID) 12345, you may do something like this:

     sudo kill -SIGABRT 12345

You can use "ps" or "top" commands to learn PIDs of processes you want 
to signal.


> also added an item to the Netgate forum to, but not many users are 
> Squid wizards

Beyond using a reasonable coredump_dir value in squid.conf, the system 
administration problems you need to solve to enable Squid core dumps are 
most likely not specific to Squid.


HTH,

Alex.


> It?s funny as soon as I enabled the sysctl command and set the directory it won?t crash anymore. I also changed it to reside on the loopback before it was only on my lan interface. I run an external drive as my swap partition or a swap drive, it works I get crash reports when playing around with stuff. /dev/da0 or something it dumps to it and when it reboots shows in the var/crash folder and will display on gui report ready, again if anyone else knows pfSense let me know. I also added an item to the Netgate forum to, but not many users are Squid wizards so it might take a long time to get any community input over there.



From jonathanlee571 at gmail.com  Wed Jun 12 17:19:54 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 12 Jun 2024 10:19:54 -0700
Subject: [squid-users] Error Question
In-Reply-To: <bc60263d-d480-4b97-a461-3094be326766@measurement-factory.com>
References: <bc60263d-d480-4b97-a461-3094be326766@measurement-factory.com>
Message-ID: <C65A403F-6456-46D0-A325-8EDDFA2F8E75@gmail.com>

You know what it was, it needed to be bound to the loopback and not just the LAN, again I am still working on getting a core dump file manually. Will update once I get one. Chmod might be needed. 
Sent from my iPhone

> On Jun 12, 2024, at 06:13, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> ?On 2024-06-11 23:32, Jonathan Lee wrote:
> 
>> So I just run this on command line SIGABRT squid?
> 
> On Unix-like systems, the command to send a process a signal is called "kill": https://www.man7.org/linux/man-pages/man1/kill.1p.html
> 
> For example, if you want to abort a Squid worker process that has OS process ID (PID) 12345, you may do something like this:
> 
>    sudo kill -SIGABRT 12345
> 
> You can use "ps" or "top" commands to learn PIDs of processes you want to signal.
> 
> 
>> also added an item to the Netgate forum to, but not many users are Squid wizards
> 
> Beyond using a reasonable coredump_dir value in squid.conf, the system administration problems you need to solve to enable Squid core dumps are most likely not specific to Squid.
> 
> 
> HTH,
> 
> Alex.
> 
> 
>> It?s funny as soon as I enabled the sysctl command and set the directory it won?t crash anymore. I also changed it to reside on the loopback before it was only on my lan interface. I run an external drive as my swap partition or a swap drive, it works I get crash reports when playing around with stuff. /dev/da0 or something it dumps to it and when it reboots shows in the var/crash folder and will display on gui report ready, again if anyone else knows pfSense let me know. I also added an item to the Netgate forum to, but not many users are Squid wizards so it might take a long time to get any community input over there.
> 


From jonathanlee571 at gmail.com  Wed Jun 12 21:51:21 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 12 Jun 2024 14:51:21 -0700
Subject: [squid-users] Error Question
In-Reply-To: <C65A403F-6456-46D0-A325-8EDDFA2F8E75@gmail.com>
References: <bc60263d-d480-4b97-a461-3094be326766@measurement-factory.com>
 <C65A403F-6456-46D0-A325-8EDDFA2F8E75@gmail.com>
Message-ID: <D6853FE9-EBEC-4FB9-8BD7-60BA9B73168B@gmail.com>

when killing squid I only get the following and no core dumps core does does work I have tested it with a sanity check with the help of FreeBSD forum users. However it just does not show a core dump for me on anything kill -11 kill -6 killall or kill -SIGABRT. I have it set in the config to use coredump directory also 
https://forums.freebsd.org/threads/core-dumps.93778/page-2


Jun 12 14:49:09	kernel		pid 87824 (squid), jid 0, uid 100: exited on signal 6
Jun 12 14:47:52	kernel		pid 87551 (squid), jid 0, uid 0: exited on signal 11


> On Jun 12, 2024, at 10:19, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
> 
> You know what it was, it needed to be bound to the loopback and not just the LAN, again I am still working on getting a core dump file manually. Will update once I get one. Chmod might be needed. 
> Sent from my iPhone
> 
>> On Jun 12, 2024, at 06:13, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>> 
>> ?On 2024-06-11 23:32, Jonathan Lee wrote:
>> 
>>> So I just run this on command line SIGABRT squid?
>> 
>> On Unix-like systems, the command to send a process a signal is called "kill": https://www.man7.org/linux/man-pages/man1/kill.1p.html
>> 
>> For example, if you want to abort a Squid worker process that has OS process ID (PID) 12345, you may do something like this:
>> 
>>   sudo kill -SIGABRT 12345
>> 
>> You can use "ps" or "top" commands to learn PIDs of processes you want to signal.
>> 
>> 
>>> also added an item to the Netgate forum to, but not many users are Squid wizards
>> 
>> Beyond using a reasonable coredump_dir value in squid.conf, the system administration problems you need to solve to enable Squid core dumps are most likely not specific to Squid.
>> 
>> 
>> HTH,
>> 
>> Alex.
>> 
>> 
>>> It?s funny as soon as I enabled the sysctl command and set the directory it won?t crash anymore. I also changed it to reside on the loopback before it was only on my lan interface. I run an external drive as my swap partition or a swap drive, it works I get crash reports when playing around with stuff. /dev/da0 or something it dumps to it and when it reboots shows in the var/crash folder and will display on gui report ready, again if anyone else knows pfSense let me know. I also added an item to the Netgate forum to, but not many users are Squid wizards so it might take a long time to get any community input over there.
>> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240612/48c7c3ec/attachment.htm>

From rousskov at measurement-factory.com  Wed Jun 12 22:38:48 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 12 Jun 2024 18:38:48 -0400
Subject: [squid-users] Error Question
In-Reply-To: <D6853FE9-EBEC-4FB9-8BD7-60BA9B73168B@gmail.com>
References: <bc60263d-d480-4b97-a461-3094be326766@measurement-factory.com>
 <C65A403F-6456-46D0-A325-8EDDFA2F8E75@gmail.com>
 <D6853FE9-EBEC-4FB9-8BD7-60BA9B73168B@gmail.com>
Message-ID: <c7c21aae-daa2-4e56-9344-da228ef5f443@measurement-factory.com>

On 2024-06-12 17:51, Jonathan Lee wrote:
> when killing squid I only get the following and no core dumps core does 
> does work

Glad you have a working "sanity check" test! I agree with FreeBSD forum 
folks that you have proven that your OS does have core dumps enabled (in 
general). Now we need to figure out what is the difference between that 
working test script and Squid.

Please start Squid from the command line, with -N command line option 
(among others that you might be using already), just like you start the 
"sanity check" test script. And then kill Squid as you kill the test script.

If the above does not produce a Squid core file, then I would suspect 
that Squid runs as "squid" user while the test script runs as "root". 
Try starting the test script as "squid" user (you may be able to use 
"sudo -u squid ..." for that).

If same user does not expose the difference, start the test script from 
the directory where you told Squid to dump core.


HTH,

Alex.


> I have tested it with a sanity check with the help of FreeBSD 
> forum users. However it just does not show a core dump for me on 
> anything kill -11 kill -6 killall or kill -SIGABRT. I have it set in the 
> config to use coredump directory also
> forums.freebsd.org 
> <https://forums.freebsd.org/threads/core-dumps.93778/page-2>
> 
> 
> Jun 12 14:49:09	kernel	pid 87824 (squid), jid 0, uid 100: exited on signal 6
> Jun 12 14:47:52	kernel	pid 87551 (squid), jid 0, uid 0: exited on signal 11
> 
> 
>> On Jun 12, 2024, at 10:19, Jonathan Lee <jonathanlee571 at gmail.com> wrote:
>>
>> You know what it was, it needed to be bound to the loopback and not 
>> just the LAN, again I am still working on getting a core dump file 
>> manually. Will update once I get one. Chmod might be needed.
>> Sent from my iPhone
>>
>>> On Jun 12, 2024, at 06:13, Alex Rousskov 
>>> <rousskov at measurement-factory.com> wrote:
>>>
>>> ?On 2024-06-11 23:32, Jonathan Lee wrote:
>>>
>>>> So I just run this on command line SIGABRT squid?
>>>
>>> On Unix-like systems, the command to send a process a signal is 
>>> called "kill": https://www.man7.org/linux/man-pages/man1/kill.1p.html
>>>
>>> For example, if you want to abort a Squid worker process that has OS 
>>> process ID (PID) 12345, you may do something like this:
>>>
>>> ??sudo kill -SIGABRT 12345
>>>
>>> You can use "ps" or "top" commands to learn PIDs of processes you 
>>> want to signal.
>>>
>>>
>>>> also added an item to the Netgate forum to, but not many users are 
>>>> Squid wizards
>>>
>>> Beyond using a reasonable coredump_dir value in squid.conf, the 
>>> system administration problems you need to solve to enable Squid core 
>>> dumps are most likely not specific to Squid.
>>>
>>>
>>> HTH,
>>>
>>> Alex.
>>>
>>>
>>>> It?s funny as soon as I enabled the sysctl command and set the 
>>>> directory it won?t crash anymore. I also changed it to reside on the 
>>>> loopback before it was only on my lan interface. I run an external 
>>>> drive as my swap partition or a swap drive, it works I get crash 
>>>> reports when playing around with stuff. /dev/da0 or something it 
>>>> dumps to it and when it reboots shows in the var/crash folder and 
>>>> will display on gui report ready, again if anyone else knows pfSense 
>>>> let me know. I also added an item to the Netgate forum to, but not 
>>>> many users are Squid wizards so it might take a long time to get any 
>>>> community input over there.
>>>
> 



From jonathanlee571 at gmail.com  Thu Jun 13 00:57:47 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 12 Jun 2024 17:57:47 -0700
Subject: [squid-users] Error Question
In-Reply-To: <c7c21aae-daa2-4e56-9344-da228ef5f443@measurement-factory.com>
References: <bc60263d-d480-4b97-a461-3094be326766@measurement-factory.com>
 <C65A403F-6456-46D0-A325-8EDDFA2F8E75@gmail.com>
 <D6853FE9-EBEC-4FB9-8BD7-60BA9B73168B@gmail.com>
 <c7c21aae-daa2-4e56-9344-da228ef5f443@measurement-factory.com>
Message-ID: <973A3715-8A16-4DF9-8933-800361D720AA@gmail.com>

If same user does not expose the difference, start the test script from the directory where you told Squid to dump core.

Shell Output - /var/log/squid/try.sh
sh: /var/log/squid/try.sh: Permission denied
I can?t run it I have set it to chmod 777 and running it as root.
I do not have the sudo enabled currently however I wonder if I add root to the /var/log/squid it that would fix it


> On Jun 12, 2024, at 15:38, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> If same user does not expose the difference, start the test script from the directory where you told Squid to dump core.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240612/c2a6e22d/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jun 13 00:58:33 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Wed, 12 Jun 2024 17:58:33 -0700
Subject: [squid-users] Error Question
In-Reply-To: <c7c21aae-daa2-4e56-9344-da228ef5f443@measurement-factory.com>
References: <bc60263d-d480-4b97-a461-3094be326766@measurement-factory.com>
 <C65A403F-6456-46D0-A325-8EDDFA2F8E75@gmail.com>
 <D6853FE9-EBEC-4FB9-8BD7-60BA9B73168B@gmail.com>
 <c7c21aae-daa2-4e56-9344-da228ef5f443@measurement-factory.com>
Message-ID: <E1B240D3-9D57-4339-8970-33790017917B@gmail.com>

Shell Output - ls -l /var/log/squid/try.sh
-rwxrwxrwx  1 root  squid  46 Jun 12 17:55 /var/log/squid/try.sh
> On Jun 12, 2024, at 15:38, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> If same user does not expose the difference, start the test script from the directory where you told Squid to dump core.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240612/2c0037c8/attachment.htm>

From jonathanlee571 at gmail.com  Thu Jun 13 15:07:01 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 13 Jun 2024 08:07:01 -0700
Subject: [squid-users] Error Question
In-Reply-To: <E1B240D3-9D57-4339-8970-33790017917B@gmail.com>
References: <E1B240D3-9D57-4339-8970-33790017917B@gmail.com>
Message-ID: <55352D60-8C0B-44BF-A160-322713A321D5@gmail.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240613/7f4d5d1c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: favicon.ico
Type: image/x-icon
Size: 7886 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240613/7f4d5d1c/attachment.bin>

From rousskov at measurement-factory.com  Thu Jun 13 15:56:43 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 13 Jun 2024 11:56:43 -0400
Subject: [squid-users] Error Question
In-Reply-To: <55352D60-8C0B-44BF-A160-322713A321D5@gmail.com>
References: <E1B240D3-9D57-4339-8970-33790017917B@gmail.com>
 <55352D60-8C0B-44BF-A160-322713A321D5@gmail.com>
Message-ID: <4d711266-1c0a-4cbe-ac4f-bf41168e4531@measurement-factory.com>

On 2024-06-13 11:07, Jonathan Lee wrote:
> Bug #15555: Coredumps not functional for non-root processes.
> https://redmine.pfsense.org/issues/15555#change-73638
> 
> There is a bug in pfSense not allowing core dumps.

Glad you are making progress! Since pfSense folks believe this bug is 
not specific to Squid, there is nothing more for us to do here (for now).

Alex.



From squid3 at treenet.co.nz  Fri Jun 14 08:36:32 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 14 Jun 2024 20:36:32 +1200
Subject: [squid-users] Upgrade path from squid 4.15 to 6.x
In-Reply-To: <002c01dabb09$d20eb550$762c1ff0$@gmail.com>
References: <CAAXo-PEWdcZvCXBFVLU-PTG-LKdk5_BqFyYg+H1xWuteHWUAbA@mail.gmail.com>
 <CAAXo-PH6Qf5A-=6CvArYG=8wUeG5gs-0jj32Uu3KhHSQM0HOWQ@mail.gmail.com>
 <002c01dabb09$d20eb550$762c1ff0$@gmail.com>
Message-ID: <0098b14c-bdd9-4b4f-99c9-bc0bc0f17284@treenet.co.nz>


Regarding the OP question:

Upgrade for all Squid-3 is to:
  * read release notes of N thru M versions (as-needed) about existing 
feature changes
  * install the new version
  * run "squid -k parse" to identify mandatory changes
  * fix all "FATAL" and "ERROR" identified
  * run with new version

... look at all logged "NOTICE", "UPGRADE" etc, and the Release Notes 
new feature additions to work on operational improvements possible with 
the new version.


HTH
Amos


On 10/06/24 19:43, ngtech1ltd wrote:
> 
> @Alex and @Amos, can you try to help me compile a menu list of 
> functionalities that Squid-Cache can be used for?
> 

The Squid wiki ConfigExamples section does that. Or at least is supposed 
to, with examples per use-case.


FYI, this line of discussion you have is well off-topic for Akash's 
original question and I think is probably just adding confusion.


Cheers
Amos


From ngtech1ltd at gmail.com  Fri Jun 14 08:43:33 2024
From: ngtech1ltd at gmail.com (NgTech LTD)
Date: Fri, 14 Jun 2024 11:43:33 +0300
Subject: [squid-users] Upgrade path from squid 4.15 to 6.x
In-Reply-To: <0098b14c-bdd9-4b4f-99c9-bc0bc0f17284@treenet.co.nz>
References: <CAAXo-PEWdcZvCXBFVLU-PTG-LKdk5_BqFyYg+H1xWuteHWUAbA@mail.gmail.com>
 <CAAXo-PH6Qf5A-=6CvArYG=8wUeG5gs-0jj32Uu3KhHSQM0HOWQ@mail.gmail.com>
 <002c01dabb09$d20eb550$762c1ff0$@gmail.com>
 <0098b14c-bdd9-4b4f-99c9-bc0bc0f17284@treenet.co.nz>
Message-ID: <CABA8h=SepXuzb7U-Tq8bZixG+s6LF+dBdLWcH00LMy4=89gGyg@mail.gmail.com>

Hey Amis,

Ok, so with the tools we have available, can we take this case and maybe
write a brief summary of changes between the squid features versions?

I can't guarantee time limit but it would be very helpful from the
community to get feedback in such cases.

If anyone have done this kind of task, please share with us the details so
others will be able to benefit from your invested time.

Thanks,
Eliezer

* I am well aware...

?????? ??? ??, 14 ????? 2024, 11:36, ??? Amos Jeffries ?<
squid3 at treenet.co.nz>:

>
> Regarding the OP question:
>
> Upgrade for all Squid-3 is to:
>   * read release notes of N thru M versions (as-needed) about existing
> feature changes
>   * install the new version
>   * run "squid -k parse" to identify mandatory changes
>   * fix all "FATAL" and "ERROR" identified
>   * run with new version
>
> ... look at all logged "NOTICE", "UPGRADE" etc, and the Release Notes
> new feature additions to work on operational improvements possible with
> the new version.
>
>
> HTH
> Amos
>
>
> On 10/06/24 19:43, ngtech1ltd wrote:
> >
> > @Alex and @Amos, can you try to help me compile a menu list of
> > functionalities that Squid-Cache can be used for?
> >
>
> The Squid wiki ConfigExamples section does that. Or at least is supposed
> to, with examples per use-case.
>
>
> FYI, this line of discussion you have is well off-topic for Akash's
> original question and I think is probably just adding confusion.
>
>
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240614/3c69faa8/attachment.htm>

From squid3 at treenet.co.nz  Fri Jun 14 08:45:56 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 14 Jun 2024 20:45:56 +1200
Subject: [squid-users] Information Request: "Accept-Ranges" with use of
 SSL intercept and dynamic update caching
In-Reply-To: <FD2D632A-923B-4727-8697-8C480419AB29@gmail.com>
References: <F025B516-48D2-4E39-8799-5F215CECB986@gmail.com>
 <FD2D632A-923B-4727-8697-8C480419AB29@gmail.com>
Message-ID: <c877ab52-90b1-4577-ba07-194dedf6684b@treenet.co.nz>

On 11/06/24 16:47, Jonathan Lee wrote:
> The reason I ask is sometimes Facebook when I am using it locks up and 
> my fan goes crazy I close Safari and restart the browser and it works 
> fine again. It acts like it is restarting a download over and over again.
> 

Because it is. Those websites use "infinite scrolling" for delivery. 
Accept-Ranges tells the server that it does not have to re-deliver the 
entire JSON dataset for the scrolling part in full, every few seconds.

That header is defined by 
<https://www.rfc-editor.org/rfc/rfc9110#name-accept-ranges>


HTH
Amos


>> On Jun 10, 2024, at 21:45, Jonathan Lee wrote:
>>
>> Hello fellow Squid community can you please help?
>>
>> Should I be using the following if I have SSL certificates, dynamic updates, StoreID, and ClamAV running?
>>
>> *request_header_access Accept-Ranges deny all reply_header_access 
>> Accept-Ranges deny all request_header_replace Accept-Ranges none 
>> reply_header_replace Accept-Ranges none*
>>
>> None of the documents show what Accept-Ranges does
>>
>> Can anyone help explain this to me?
> 


From squid3 at treenet.co.nz  Fri Jun 14 09:57:53 2024
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 14 Jun 2024 21:57:53 +1200
Subject: [squid-users] Upgrade path from squid 4.15 to 6.x
In-Reply-To: <CABA8h=SepXuzb7U-Tq8bZixG+s6LF+dBdLWcH00LMy4=89gGyg@mail.gmail.com>
References: <CAAXo-PEWdcZvCXBFVLU-PTG-LKdk5_BqFyYg+H1xWuteHWUAbA@mail.gmail.com>
 <CAAXo-PH6Qf5A-=6CvArYG=8wUeG5gs-0jj32Uu3KhHSQM0HOWQ@mail.gmail.com>
 <002c01dabb09$d20eb550$762c1ff0$@gmail.com>
 <0098b14c-bdd9-4b4f-99c9-bc0bc0f17284@treenet.co.nz>
 <CABA8h=SepXuzb7U-Tq8bZixG+s6LF+dBdLWcH00LMy4=89gGyg@mail.gmail.com>
Message-ID: <6f9fe62f-e799-4f45-b9a8-94d991ebfe49@treenet.co.nz>

On 14/06/24 20:43, NgTech LTD wrote:
> Hey Amis,
> 
> Ok, so with the tools we have available, can we take this case and maybe 
> write a brief summary of changes between the squid features versions?
> 

That what the Release Notes are.

Cheers
Amos


From jonathanlee571 at gmail.com  Fri Jun 14 19:11:49 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Fri, 14 Jun 2024 12:11:49 -0700
Subject: [squid-users] Information Request: "Accept-Ranges" with use of
 SSL intercept and dynamic update caching
In-Reply-To: <c877ab52-90b1-4577-ba07-194dedf6684b@treenet.co.nz>
References: <c877ab52-90b1-4577-ba07-194dedf6684b@treenet.co.nz>
Message-ID: <A67408A3-E6EB-42E7-915B-A3C8CB5B98C9@gmail.com>

Thanks for the info. That makes this directive very clear.
Sent from my iPhone

> On Jun 14, 2024, at 01:46, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> ?On 11/06/24 16:47, Jonathan Lee wrote:
>> The reason I ask is sometimes Facebook when I am using it locks up and my fan goes crazy I close Safari and restart the browser and it works fine again. It acts like it is restarting a download over and over again.
> 
> Because it is. Those websites use "infinite scrolling" for delivery. Accept-Ranges tells the server that it does not have to re-deliver the entire JSON dataset for the scrolling part in full, every few seconds.
> 
> That header is defined by <https://www.rfc-editor.org/rfc/rfc9110#name-accept-ranges>
> 
> 
> HTH
> Amos
> 
> 
>>>> On Jun 10, 2024, at 21:45, Jonathan Lee wrote:
>>> 
>>> Hello fellow Squid community can you please help?
>>> 
>>> Should I be using the following if I have SSL certificates, dynamic updates, StoreID, and ClamAV running?
>>> 
>>> *request_header_access Accept-Ranges deny all reply_header_access Accept-Ranges deny all request_header_replace Accept-Ranges none reply_header_replace Accept-Ranges none*
>>> 
>>> None of the documents show what Accept-Ranges does
>>> 
>>> Can anyone help explain this to me?
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From david at articatech.com  Sun Jun 16 10:27:03 2024
From: david at articatech.com (David Touzeau)
Date: Sun, 16 Jun 2024 12:27:03 +0200
Subject: [squid-users] Simulate connections for tuning squid?
In-Reply-To: <39e268df-fcad-4460-a951-1654acb2f822@measurement-factory.com>
References: <CAK2yrTbTD6t0WHmMvfBKUWYzapFoXjt2EQshqSyFh-CVQiw+Tg@mail.gmail.com>
 <39e268df-fcad-4460-a951-1654acb2f822@measurement-factory.com>
Message-ID: <44fc0eaa-8215-44a1-8fb5-ba20cc6611e8@articatech.com>


Hi

We have made such a tool for us.
I suggest downloading our ISO and install a new server ( virtual )
You will have this feature:
https://wiki.articatech.com/en/proxy-service/tuning/stress-your-proxy-server

You can easily use this feature in a variety of scenarios.

Available free of charge with no restrictions



Le 24/05/2024 ? 16:01, Alex Rousskov a ?crit?:
> On 2024-05-24 01:43, Periko Support wrote:
>
>> I would like to know if there exists a tool that helps us simulate
>> connections to squid and helps us tune squid for different scenarios
>> like small, medium or large networks?
>
> Yes, there are many tools, offering various tradeoffs, including:
>
> * Apache "ab": Not designed for testing proxies but well-known and 
> fairly simple.
>
> * Web Polygraph: Designed for testing proxies but has a steep learning 
> curve and lacks fresh releases.
>
> * curl/wget/netcat: Not designed for testing performance but 
> well-known and very simple.
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users

-- 
David Touzeau - Artica Tech France
Development team, level 3 support
----------------------------------
P: +33 6 58 44 69 46
www:https://wiki.articatech.com
www:http://articatech.net  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240616/81adeb49/attachment.htm>

From Antony.Stone at squid.open.source.it  Sun Jun 16 11:25:17 2024
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sun, 16 Jun 2024 13:25:17 +0200
Subject: [squid-users] Simulate connections for tuning squid?
In-Reply-To: <44fc0eaa-8215-44a1-8fb5-ba20cc6611e8@articatech.com>
References: <CAK2yrTbTD6t0WHmMvfBKUWYzapFoXjt2EQshqSyFh-CVQiw+Tg@mail.gmail.com>
 <39e268df-fcad-4460-a951-1654acb2f822@measurement-factory.com>
 <44fc0eaa-8215-44a1-8fb5-ba20cc6611e8@articatech.com>
Message-ID: <202406161325.17458.Antony.Stone@squid.open.source.it>

On Sunday 16 June 2024 at 12:27:03, David Touzeau wrote:

> Hi
> 
> We have made such a tool for us.

> Available free of charge with no restrictions

I think it would be a good idea to publish a tool like this explicitly under a 
well-known licence.  It makes life considerably simpler for people who care 
about compliance if they can say "these things we use are all under licence X" 
because then everyone knows exactly what that means.


Antony.

-- 
I don't know, maybe if we all waited then cosmic rays would write all our 
software for us. Of course it might take a while.

 - Ron Minnich, Los Alamos National Laboratory

                                                   Please reply to the list;
                                                         please *don't* CC me.


From rousskov at measurement-factory.com  Sun Jun 16 21:59:59 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 16 Jun 2024 17:59:59 -0400
Subject: [squid-users] Anybody still using src_as and dst_as ACLs?
Message-ID: <a89c484c-f214-4b75-a0de-9df35e2456a9@measurement-factory.com>

Hello,

     Does anybody still have src_as and dst_as ACLs configured in their 
production Squids? There are several serious problems with those ACLs, 
and those problems have been present in Squid for many years. I hope 
that virtually nobody uses those ACLs today.

If you do use them, please respond (publicly or privately) and, if 
possible, please indicate whether you have verified that those ACLs are 
working correctly in your deployment environment.


Thank you,

Alex.


> 	acl aclname src_as number ...
> 	acl aclname dst_as number ...
> 	  # [fast]
> 	  # Except for access control, AS numbers can be used for
> 	  # routing of requests to specific caches. Here's an
> 	  # example for routing all requests for AS#1241 and only
> 	  # those to mycache.mydomain.net:
> 	  # acl asexample dst_as 1241
> 	  # cache_peer_access mycache.mydomain.net allow asexample
> 	  # cache_peer_access mycache_mydomain.net deny all


From jonathanlee571 at gmail.com  Sun Jun 16 23:46:49 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Sun, 16 Jun 2024 18:46:49 -0500
Subject: [squid-users] Anybody still using src_as and dst_as ACLs?
In-Reply-To: <a89c484c-f214-4b75-a0de-9df35e2456a9@measurement-factory.com>
References: <a89c484c-f214-4b75-a0de-9df35e2456a9@measurement-factory.com>
Message-ID: <0E004A8F-418C-4A97-B8C8-045173AC05E2@gmail.com>

I use them for ipv6 blocks they seem to work that way in 5.8
Sent from my iPhone

> On Jun 16, 2024, at 17:00, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> ?Hello,
> 
>    Does anybody still have src_as and dst_as ACLs configured in their production Squids? There are several serious problems with those ACLs, and those problems have been present in Squid for many years. I hope that virtually nobody uses those ACLs today.
> 
> If you do use them, please respond (publicly or privately) and, if possible, please indicate whether you have verified that those ACLs are working correctly in your deployment environment.
> 
> 
> Thank you,
> 
> Alex.
> 
> 
>>    acl aclname src_as number ...
>>    acl aclname dst_as number ...
>>      # [fast]
>>      # Except for access control, AS numbers can be used for
>>      # routing of requests to specific caches. Here's an
>>      # example for routing all requests for AS#1241 and only
>>      # those to mycache.mydomain.net:
>>      # acl asexample dst_as 1241
>>      # cache_peer_access mycache.mydomain.net allow asexample
>>      # cache_peer_access mycache_mydomain.net deny all
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Mon Jun 17 13:17:30 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 17 Jun 2024 09:17:30 -0400
Subject: [squid-users] Anybody still using src_as and dst_as ACLs?
In-Reply-To: <0E004A8F-418C-4A97-B8C8-045173AC05E2@gmail.com>
References: <a89c484c-f214-4b75-a0de-9df35e2456a9@measurement-factory.com>
 <0E004A8F-418C-4A97-B8C8-045173AC05E2@gmail.com>
Message-ID: <2ce78833-7ee1-483f-b854-65f4dec59538@measurement-factory.com>

On 2024-06-16 19:46, Jonathan Lee wrote:
> I use them for ipv6 blocks they seem to work that way in 5.8

Just to double check that we are on the same page here, please share an 
example (or two) of your src_as or dst_as ACL definitions (i.e., "acl 
... dst_as ..." or similar lines). I do _not_ need the corresponding 
directives that use those AS-based ACLs (e.g., "http_access deny..."), 
just the "acl" lines themselves.

As an added bonus, I may be able to confirm whether Squid v5.8 can grok 
responses about Autonomous System Numbers used by your specific 
configuration :-).


Thank you,

Alex.


>> On Jun 16, 2024, at 17:00, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>
>> ?Hello,
>>
>>     Does anybody still have src_as and dst_as ACLs configured in their production Squids? There are several serious problems with those ACLs, and those problems have been present in Squid for many years. I hope that virtually nobody uses those ACLs today.
>>
>> If you do use them, please respond (publicly or privately) and, if possible, please indicate whether you have verified that those ACLs are working correctly in your deployment environment.
>>
>>
>> Thank you,
>>
>> Alex.
>>
>>
>>>     acl aclname src_as number ...
>>>     acl aclname dst_as number ...
>>>       # [fast]
>>>       # Except for access control, AS numbers can be used for
>>>       # routing of requests to specific caches. Here's an
>>>       # example for routing all requests for AS#1241 and only
>>>       # those to mycache.mydomain.net:
>>>       # acl asexample dst_as 1241
>>>       # cache_peer_access mycache.mydomain.net allow asexample
>>>       # cache_peer_access mycache_mydomain.net deny all
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> https://lists.squid-cache.org/listinfo/squid-users



From jonathanlee571 at gmail.com  Mon Jun 17 15:43:36 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 17 Jun 2024 10:43:36 -0500
Subject: [squid-users] Anybody still using src_as and dst_as ACLs?
In-Reply-To: <2ce78833-7ee1-483f-b854-65f4dec59538@measurement-factory.com>
References: <2ce78833-7ee1-483f-b854-65f4dec59538@measurement-factory.com>
Message-ID: <78D5247F-5344-4694-B229-F21803C71479@gmail.com>

acl to_ipv6 dst ipv6
acl from_ipv6 src ipv6

I after block them with terminate connections.

I hope that helps our isp is ipv6 only
Sent from my iPhone

> On Jun 17, 2024, at 08:17, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> ?On 2024-06-16 19:46, Jonathan Lee wrote:
>> I use them for ipv6 blocks they seem to work that way in 5.8
> 
> Just to double check that we are on the same page here, please share an example (or two) of your src_as or dst_as ACL definitions (i.e., "acl ... dst_as ..." or similar lines). I do _not_ need the corresponding directives that use those AS-based ACLs (e.g., "http_access deny..."), just the "acl" lines themselves.
> 
> As an added bonus, I may be able to confirm whether Squid v5.8 can grok responses about Autonomous System Numbers used by your specific configuration :-).
> 
> 
> Thank you,
> 
> Alex.
> 
> 
>>>> On Jun 16, 2024, at 17:00, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>> 
>>> ?Hello,
>>> 
>>>    Does anybody still have src_as and dst_as ACLs configured in their production Squids? There are several serious problems with those ACLs, and those problems have been present in Squid for many years. I hope that virtually nobody uses those ACLs today.
>>> 
>>> If you do use them, please respond (publicly or privately) and, if possible, please indicate whether you have verified that those ACLs are working correctly in your deployment environment.
>>> 
>>> 
>>> Thank you,
>>> 
>>> Alex.
>>> 
>>> 
>>>>    acl aclname src_as number ...
>>>>    acl aclname dst_as number ...
>>>>      # [fast]
>>>>      # Except for access control, AS numbers can be used for
>>>>      # routing of requests to specific caches. Here's an
>>>>      # example for routing all requests for AS#1241 and only
>>>>      # those to mycache.mydomain.net:
>>>>      # acl asexample dst_as 1241
>>>>      # cache_peer_access mycache.mydomain.net allow asexample
>>>>      # cache_peer_access mycache_mydomain.net deny all
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> https://lists.squid-cache.org/listinfo/squid-users
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240617/6d4a4d95/attachment.htm>

From rousskov at measurement-factory.com  Mon Jun 17 16:03:06 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 17 Jun 2024 12:03:06 -0400
Subject: [squid-users] Anybody still using src_as and dst_as ACLs?
In-Reply-To: <78D5247F-5344-4694-B229-F21803C71479@gmail.com>
References: <2ce78833-7ee1-483f-b854-65f4dec59538@measurement-factory.com>
 <78D5247F-5344-4694-B229-F21803C71479@gmail.com>
Message-ID: <cb59556f-5fb8-4269-98f4-ba987682430b@measurement-factory.com>

On 2024-06-17 11:43, Jonathan Lee wrote:
> acl to_ipv6 dst ipv6
> acl from_ipv6 src ipv6


Glad I asked! The above configuration is not using "src_as" and "dst_as" 
ACL types that I am asking about. It is using "src" and "dst" ACL types.


 > I hope that helps our isp is ipv6 only

Matching IPv6 addresses is completely unrelated to this thread topic, 
but you may want to see the following commit message about "ipv6" 
problems recently fixed in master/v7. If you want to discuss IPv6 
matching, please start a new mailing list thread!
https://github.com/squid-cache/squid/commit/51c518d5



Thank you,

Alex.


>> On Jun 17, 2024, at 08:17, Alex Rousskov 
>> <rousskov at measurement-factory.com> wrote:
>>
>> ?On 2024-06-16 19:46, Jonathan Lee wrote:
>>> I use them for ipv6 blocks they seem to work that way in 5.8
>>
>> Just to double check that we are on the same page here, please share 
>> an example (or two) of your src_as or dst_as ACL definitions (i.e., 
>> "acl ... dst_as ..." or similar lines). I do _not_ need the 
>> corresponding directives that use those AS-based ACLs (e.g., 
>> "http_access deny..."), just the "acl" lines themselves.
>>
>> As an added bonus, I may be able to confirm whether Squid v5.8 can 
>> grok responses about Autonomous System Numbers used by your specific 
>> configuration :-).
>>
>>
>> Thank you,
>>
>> Alex.
>>
>>
>>>> On Jun 16, 2024, at 17:00, Alex Rousskov 
>>>> <rousskov at measurement-factory.com> wrote:
>>>>
>>>> ?Hello,
>>>>
>>>> ???Does anybody still have src_as and dst_as ACLs configured in 
>>>> their production Squids? There are several serious problems with 
>>>> those ACLs, and those problems have been present in Squid for many 
>>>> years. I hope that virtually nobody uses those ACLs today.
>>>>
>>>> If you do use them, please respond (publicly or privately) and, if 
>>>> possible, please indicate whether you have verified that those ACLs 
>>>> are working correctly in your deployment environment.
>>>>
>>>>
>>>> Thank you,
>>>>
>>>> Alex.
>>>>
>>>>
>>>>> ???acl aclname src_as number ...
>>>>> ???acl aclname dst_as number ...
>>>>> ?????# [fast]
>>>>> ?????# Except for access control, AS numbers can be used for
>>>>> ?????# routing of requests to specific caches. Here's an
>>>>> ?????# example for routing all requests for AS#1241 and only
>>>>> ?????# those to mycache.mydomain.net:
>>>>> ?????# acl asexample dst_as 1241
>>>>> ?????# cache_peer_access mycache.mydomain.net allow asexample
>>>>> ?????# cache_peer_access mycache_mydomain.net deny all
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> https://lists.squid-cache.org/listinfo/squid-users
>>



From jonathanlee571 at gmail.com  Mon Jun 17 16:30:01 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Mon, 17 Jun 2024 11:30:01 -0500
Subject: [squid-users] Anybody still using src_as and dst_as ACLs?
In-Reply-To: <cb59556f-5fb8-4269-98f4-ba987682430b@measurement-factory.com>
References: <cb59556f-5fb8-4269-98f4-ba987682430b@measurement-factory.com>
Message-ID: <C0B5C99E-9C81-4D4C-B4E1-22B6C3DBAE2F@gmail.com>

Is there a different type of directive for source and destination acts?
Sent from my iPhone

> On Jun 17, 2024, at 11:03, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> ?On 2024-06-17 11:43, Jonathan Lee wrote:
>> acl to_ipv6 dst ipv6
>> acl from_ipv6 src ipv6
> 
> 
> Glad I asked! The above configuration is not using "src_as" and "dst_as" ACL types that I am asking about. It is using "src" and "dst" ACL types.
> 
> 
> > I hope that helps our isp is ipv6 only
> 
> Matching IPv6 addresses is completely unrelated to this thread topic, but you may want to see the following commit message about "ipv6" problems recently fixed in master/v7. If you want to discuss IPv6 matching, please start a new mailing list thread!
> https://github.com/squid-cache/squid/commit/51c518d5
> 
> 
> 
> Thank you,
> 
> Alex.
> 
> 
>>>> On Jun 17, 2024, at 08:17, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>> 
>>> ?On 2024-06-16 19:46, Jonathan Lee wrote:
>>>> I use them for ipv6 blocks they seem to work that way in 5.8
>>> 
>>> Just to double check that we are on the same page here, please share an example (or two) of your src_as or dst_as ACL definitions (i.e., "acl ... dst_as ..." or similar lines). I do _not_ need the corresponding directives that use those AS-based ACLs (e.g., "http_access deny..."), just the "acl" lines themselves.
>>> 
>>> As an added bonus, I may be able to confirm whether Squid v5.8 can grok responses about Autonomous System Numbers used by your specific configuration :-).
>>> 
>>> 
>>> Thank you,
>>> 
>>> Alex.
>>> 
>>> 
>>>>> On Jun 16, 2024, at 17:00, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>>>>> 
>>>>> ?Hello,
>>>>> 
>>>>>    Does anybody still have src_as and dst_as ACLs configured in their production Squids? There are several serious problems with those ACLs, and those problems have been present in Squid for many years. I hope that virtually nobody uses those ACLs today.
>>>>> 
>>>>> If you do use them, please respond (publicly or privately) and, if possible, please indicate whether you have verified that those ACLs are working correctly in your deployment environment.
>>>>> 
>>>>> 
>>>>> Thank you,
>>>>> 
>>>>> Alex.
>>>>> 
>>>>> 
>>>>>>    acl aclname src_as number ...
>>>>>>    acl aclname dst_as number ...
>>>>>>      # [fast]
>>>>>>      # Except for access control, AS numbers can be used for
>>>>>>      # routing of requests to specific caches. Here's an
>>>>>>      # example for routing all requests for AS#1241 and only
>>>>>>      # those to mycache.mydomain.net:
>>>>>>      # acl asexample dst_as 1241
>>>>>>      # cache_peer_access mycache.mydomain.net allow asexample
>>>>>>      # cache_peer_access mycache_mydomain.net deny all
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> https://lists.squid-cache.org/listinfo/squid-users
>>> 
> 


From andreas.weigel at securepoint.de  Tue Jun 18 15:34:57 2024
From: andreas.weigel at securepoint.de (Andreas Weigel)
Date: Tue, 18 Jun 2024 15:34:57 +0000
Subject: [squid-users] url_rewrite (with rewrite-url): PinnedConnection
 failure results in total failure
Message-ID: <20240618153457.Horde.aDa9860jL7p99nGuHuosQ7z@webmail.intern.securepoint.de>

Hi,

updating from a (security-patched) Squidv4 to Squidv6, problems  
occurred with regard to url_rewrite Feature used for  
content-filtering. The external helper uses "OK rewrite-url=" to point  
to a custom page that Squid used to retrieve and present to the  
Client. This used to work with SSL-Interception, but it does no longer  
in Squidv6. It does not matter in that regard if peek+splice or  
stare+bump is used, Squid always fails with ERR_CANNOT_FORWARD.

Digging into the codebase, I can see that with v4, Squid first checked  
the validity of any pinned connection and if none is found, still  
retrieves the "replacement page". It seems that  
daf80700130b6f98256b75c511916d1a79b23597 changed the logic in that  
regard, causing the FwdState to fail hard and not try any of the  
remaining peer options (see log excerpts below), although I can see  
that it added two selections (PINNED and HIER_DIRECT).

I understand that using the rewrite-url mechanism is discouraged, but  
would still like to understand if this is intended behavior (and the  
reasoning behind it) or if this has to be considered a bug. Any  
pointers to additional ressources or explanations to understand the  
behavior would be much appreciated.

Kind regards,
Andreas Weigel

PS:

log excerpt from squid-v4.16 (successful rewrite-url)

2024/06/14 14:46:30.750 kid1| 61,2| /client_side_request.cc(1266)  
clientRedirectDone: URL-rewriter diverts URL from https://youtube.com/  
to  
http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
2024/06/14 14:46:30.750 kid1| 33,5| /store_client.cc(317) doCopy:  
store_client::doCopy: co: 0, hi: 0
2024/06/14 14:46:30.750 kid1| 17,3| /FwdState.cc(340) Start:  
'http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener='
2024/06/14 14:46:30.750 kid1| 17,2| /FwdState.cc(142) FwdState:  
Forwarding client request local=172.217.13.206:443  
remote=192.168.180.10:33836 FD 11 flags=33,  
url=http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f
2024/06/14 14:46:30.750 kid1| 17,3| /FwdState.cc(149) FwdState:  
FwdState constructed, this=0x559ad7e89b88
2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(161) peerSelect:  
e:=XIV/0x559ad7e89500*2  
http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(472)  
peerSelectFoo: GET 127.0.0.1
2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(477)  
peerSelectFoo: peerSelectFoo: direct = DIRECT_UNKNOWN (always_direct  
to be checked)
2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(218)  
peerCheckAlwaysDirectDone: peerCheckAlwaysDirectDone: ALLOWED
2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(224)  
peerCheckAlwaysDirectDone: direct = DIRECT_YES (always_direct allow)
2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(472)  
peerSelectFoo: GET 127.0.0.1
2024/06/14 14:46:30.750 kid1| 33,7| /client_side.cc(4119)  
validatePinnedConnection: local=192.168.41.35:47842  
remote=172.217.13.206:443 FD 13 flags=1
2024/06/14 14:46:30.750 kid1| 33,3| /client_side.cc(4154)  
unpinConnection: local=192.168.41.35:47842 remote=172.217.13.206:443  
FD 13 flags=1
2024/06/14 14:46:30.750 kid1| 33,5| src/base/AsyncCall.cc(54) cancel:  
will not call ConnStateData::clientPinnedConnectionClosed [call63]  
because comm_remove_close_handler
2024/06/14 14:46:30.750 kid1| 33,3| src/base/AsyncCall.cc(54) cancel:  
will not call ConnStateData::clientPinnedConnectionRead [call64]  
because comm_read_cancel
2024/06/14 14:46:30.750 kid1| 33,3| src/base/AsyncCall.cc(54) cancel:  
will not call ConnStateData::clientPinnedConnectionRead [call64] also  
because comm_read_cancel
2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(978)  
peerAddFwdServer: adding HIER_DIRECT#127.0.0.1
2024/06/14 14:46:30.750 kid1| 44,2| /peer_select.cc(295)  
peerSelectDnsPaths: Find IP destination for:  
http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=' via  
127.0.0.1
2024/06/14 14:46:30.750 kid1| 44,2| /peer_select.cc(316)  
peerSelectDnsPaths: Found sources for  
'http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener='
2024/06/14 14:46:30.750 kid1| 44,2| /peer_select.cc(317)  
peerSelectDnsPaths:   always_direct = ALLOWED
2024/06/14 14:46:30.750 kid1| 44,2| /peer_select.cc(318)  
peerSelectDnsPaths:    never_direct = DENIED
2024/06/14 14:46:30.750 kid1| 44,2| /peer_select.cc(322)  
peerSelectDnsPaths:          DIRECT = local=0.0.0.0  
remote=127.0.0.1:8081 flags=1
2024/06/14 14:46:30.750 kid1| 44,2| /peer_select.cc(331)  
peerSelectDnsPaths:        timedout = 0
2024/06/14 14:46:30.750 kid1| 17,3| /FwdState.cc(418)  
startConnectionOrFail:  
http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
2024/06/14 14:46:30.750 kid1| 17,3| /FwdState.cc(832) connectStart:  
fwdConnectStart:  
http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
2024/06/14 14:46:30.750 kid1| 17,3| src/base/AsyncCall.cc(25)  
AsyncCall: The AsyncCall fwdConnectDoneWrapper constructed,  
this=0x559ad7e16a00 [call81]
2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(103) ~ps_state:  
http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
2024/06/14 14:46:30.750 kid1| 17,3| src/base/AsyncCall.cc(92)  
ScheduleCall: ../../../squid-4.16/src/comm/ConnOpener.cc(139) will  
call fwdConnectDoneWrapper(local=127.0.0.1:45660 remote=127.0.0.1:8081  
FD 13 flags=1, data=0x559ad7e89b88) [call81]
2024/06/14 14:46:30.750 kid1| 17,3| src/base/AsyncCallQueue.cc(55)  
fireNext: entering fwdConnectDoneWrapper(local=127.0.0.1:45660  
remote=127.0.0.1:8081 FD 13 flags=1, data=0x559ad7e89b88)
2024/06/14 14:46:30.750 kid1| 17,3| src/base/AsyncCall.cc(37) make:  
make call fwdConnectDoneWrapper [call81]
2024/06/14 14:46:30.750 kid1| 17,3| /FwdState.cc(706) connectDone:  
local=127.0.0.1:45660 remote=127.0.0.1:8081 FD 13 flags=1:  
'http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener='

log excerpt for the same setup from squid-v6.9 (Squid reporting  
ERR_CANNOT_FORWARD)

024/06/14 14:59:40.463 kid1| 61,5| /redirect.cc(83)  
redirectHandleReply: reply={result=OK, notes={rewrite-url:  
http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=; cf-info:  
DENIED,proxy%2dnet%5cnoyoutub
2024/06/14 14:59:40.463 kid1| 61,2| /client_side_request.cc(1236)  
clientRedirectDone: URL-rewriter diverts URL from https://youtube.com/  
to  
http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
2024/06/14 14:59:40.463 kid1| 33,5| /store_client.cc(374) doCopy:  
0x55a9d80fc678 into ioBuf(@0, len=4096, 0x55a9d8127770) hi: 0  
objectLen: -1 past_answers: 0
2024/06/14 14:59:40.463 kid1| 17,3| /FwdState.cc(373) Start:  
'http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener='
2024/06/14 14:59:40.463 kid1| 17,2| /FwdState.cc(133) FwdState:  
Forwarding client request conn19 local=172.217.13.206:443  
remote=192.168.180.10:55036 FD 11 flags=33,  
url=http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2
2024/06/14 14:59:40.463 kid1| 17,3| /FwdState.cc(140) FwdState:  
FwdState constructed, this=0x55a9d812ceb8
2024/06/14 14:59:40.463 kid1| 17,4| src/base/AsyncCall.cc(29)  
AsyncCall: The AsyncCall FwdState::Abort constructed,  
this=0x55a9d80fc790 [call90]
2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(309) peerSelect:  
e:=XIV/0x55a9d80fc5f0*3  
http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(612) selectMore:  
GET 127.0.0.1
2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(617) selectMore:  
direct = DIRECT_UNKNOWN (always_direct to be checked)
2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(373)  
checkAlwaysDirectDone: ALLOWED
2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(379)  
checkAlwaysDirectDone: direct = DIRECT_YES (always_direct allow)
2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(612) selectMore:  
GET 127.0.0.1
2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(1102)  
addSelection: adding PINNED#127.0.0.1
2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(1102)  
addSelection: adding HIER_DIRECT#127.0.0.1
2024/06/14 14:59:40.463 kid1| 44,2| /peer_select.cc(1176) handlePath:  
PeerSelector2 found pinned, destination #1 for  
http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
2024/06/14 14:59:40.463 kid1| 44,2| /peer_select.cc(1180) handlePath:   
  always_direct = ALLOWED
2024/06/14 14:59:40.463 kid1| 44,2| /peer_select.cc(1181) handlePath:   
   never_direct = DENIED
2024/06/14 14:59:40.463 kid1| 44,2| /peer_select.cc(1182) handlePath:   
       timedout = 0
2024/06/14 14:59:40.463 kid1| 33,7| /client_side.cc(3954)  
borrowPinnedConnection: conn30 local=192.168.41.35:50322  
remote=172.217.13.206:443 ORIGINAL_DST FD 13 flags=1
2024/06/14 14:59:40.463 kid1| 33,3| /client_side.cc(3997)  
unpinConnection: conn30 local=192.168.41.35:50322  
remote=172.217.13.206:443 ORIGINAL_DST FD 13 flags=1
2024/06/14 14:59:40.463 kid1| 33,5| src/base/AsyncCall.cc(58) cancel:  
will not call ConnStateData::clientPinnedConnectionClosed [call73]  
because comm_remove_close_handler
2024/06/14 14:59:40.463 kid1| 33,3| src/base/AsyncCall.cc(58) cancel:  
will not call ConnStateData::clientPinnedConnectionRead [call74]  
because comm_read_cancel
2024/06/14 14:59:40.463 kid1| 33,3| src/base/AsyncCall.cc(58) cancel:  
will not call ConnStateData::clientPinnedConnectionRead [call74] also  
because comm_read_cancel
2024/06/14 14:59:40.465 kid1| 17,3| /FwdState.cc(471) fail:  
ERR_CANNOT_FORWARD "Service Unavailable"
          
http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
2024/06/14 14:59:40.465 kid1| 17,3| /FwdState.cc(185) stopAndDestroy:  
for pinned connection failure
2024/06/14 14:59:40.465 kid1| 44,3| /peer_select.cc(1149)  
interestedInitiator: PeerSelector2 initiator lost interest
2024/06/14 14:59:40.465 kid1| 44,3| /peer_select.cc(405)  
selectionAborted: Aborting peer selection: Initiator gone or lost  
interest.
2024/06/14 14:59:40.465 kid1| 44,3| /peer_select.cc(241)  
~PeerSelector:  
http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
2024/06/14 14:59:40.465 kid1| 17,3| /FwdState.cc(310) ~FwdState:  
FwdState destructor start
2024/06/14 14:59:40.466 kid1| 33,5| /store_client.cc(374) doCopy:  
0x55a9d80fc678 into ioBuf(@0, len=4096, 0x55a9d8127770) hi: 148495  
objectLen: -1 past_answers: 0
2024/06/14 14:59:40.466 kid1| 33,5| /store_client.cc(422) doCopy: just  
send HTTP headers: 207
2024/06/14 14:59:40.466 kid1| 17,4| src/base/AsyncCall.cc(58) cancel:  
will not call FwdState::Abort [call90] because FwdState object  
destructed
2024/06/14 14:59:40.466 kid1| 17,3| /FwdState.cc(332) ~FwdState:  
FwdState destructed, this=0x55a9d812ceb8

-- 
Andreas Weigel
UTM Backend Developer

Securepoint GmbH
Bleckeder Landstra?e 28
D-21337 L?neburg
https://www.securepoint.de

Gesch?ftsf?hrer: Ren? Hofmann
Amtsgericht L?neburg HRB 1776



From rousskov at measurement-factory.com  Tue Jun 18 19:03:47 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 18 Jun 2024 15:03:47 -0400
Subject: [squid-users] url_rewrite (with rewrite-url): PinnedConnection
 failure results in total failure
In-Reply-To: <20240618153457.Horde.aDa9860jL7p99nGuHuosQ7z@webmail.intern.securepoint.de>
References: <20240618153457.Horde.aDa9860jL7p99nGuHuosQ7z@webmail.intern.securepoint.de>
Message-ID: <71778731-9756-4385-9064-c94e802dba68@measurement-factory.com>

On 2024-06-18 11:34, Andreas Weigel wrote:

> updating from a (security-patched) Squidv4 to Squidv6, problems occurred 
> with regard to url_rewrite Feature used for content-filtering. The 
> external helper uses "OK rewrite-url=" to point to a custom page that 
> Squid used to retrieve and present to the Client. This used to work with 
> SSL-Interception, but it does no longer in Squidv6. It does not matter 
> in that regard if peek+splice or stare+bump is used, Squid always fails 
> with ERR_CANNOT_FORWARD.

The peek+splice and stare+bump cases are very different with regard to 
how the request destination should be computed (including how pinned 
connection should be reused) IMO. In my response, I will focus on the 
stare+bump case.


> I understand that using the rewrite-url mechanism is discouraged, but 
> would still like to understand if this is intended behavior (and the 
> reasoning behind it) or if this has to be considered a bug.

Overall, I believe that a Squid admin should be able to rewrite any HTTP 
request (destination). Whether to classify the lack of this 
functionality in current Squid bumping code as a regression bug or a 
missing feature is currently unimportant AFAICT.

Needless to say, using another destination after a Squid-to-server 
connection has been pinned to the client-to-Squid connection is not 
quite compatible with some guarantees implied by "pinning", so extra 
care should be done when (re)enabling this behavior. I would not be 
surprised if we need to introduce several pinning categories, with 
different guarantees and re-pinning options!

For example, a client pinned to a server after a failed Host validation 
should not be able to send a second request to another destination 
without Squid admin permission. I am not sure how to detect such a 
permission when, say, a URL rewriter simply echoes client-chosen 
destination (possibly trusting Squid to block any requests that are 
attempting to escape their "pinned jail"). Distinguishing "intended" 
destination rewrites from canonicalizing or DNS-resolving echoes may be 
difficult!

It is also not clear whether the originally pinned Squid-to-server 
connection should be preserved in such cases (to be used for future 
non-redirected requests received on the same client-to-Squid connection, 
if any). Again, the correct answer may depend on the "pinning category".


HTH,

Alex.




> Digging into the codebase, I can see that with v4, Squid first
> checked the validity of any pinned connection and if none is found,
> still retrieves the "replacement page". It seems that
> daf80700130b6f98256b75c511916d1a79b23597 changed the logic in that
> regard, causing the FwdState to fail hard and not try any of the
> remaining peer options (see log excerpts below), although I can see
> that it added two selections (PINNED and HIER_DIRECT).

> PS:
> 
> log excerpt from squid-v4.16 (successful rewrite-url)
> 
> 2024/06/14 14:46:30.750 kid1| 61,2| /client_side_request.cc(1266) 
> clientRedirectDone: URL-rewriter diverts URL from https://youtube.com/ 
> to 
> http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
> 2024/06/14 14:46:30.750 kid1| 33,5| /store_client.cc(317) doCopy: 
> store_client::doCopy: co: 0, hi: 0
> 2024/06/14 14:46:30.750 kid1| 17,3| /FwdState.cc(340) Start: 
> 'http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener='
> 2024/06/14 14:46:30.750 kid1| 17,2| /FwdState.cc(142) FwdState: 
> Forwarding client request local=172.217.13.206:443 
> remote=192.168.180.10:33836 FD 11 flags=33, 
> url=http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f
> 2024/06/14 14:46:30.750 kid1| 17,3| /FwdState.cc(149) FwdState: FwdState 
> constructed, this=0x559ad7e89b88
> 2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(161) peerSelect: 
> e:=XIV/0x559ad7e89500*2 
> http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
> 2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(472) peerSelectFoo: 
> GET 127.0.0.1
> 2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(477) peerSelectFoo: 
> peerSelectFoo: direct = DIRECT_UNKNOWN (always_direct to be checked)
> 2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(218) 
> peerCheckAlwaysDirectDone: peerCheckAlwaysDirectDone: ALLOWED
> 2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(224) 
> peerCheckAlwaysDirectDone: direct = DIRECT_YES (always_direct allow)
> 2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(472) peerSelectFoo: 
> GET 127.0.0.1
> 2024/06/14 14:46:30.750 kid1| 33,7| /client_side.cc(4119) 
> validatePinnedConnection: local=192.168.41.35:47842 
> remote=172.217.13.206:443 FD 13 flags=1
> 2024/06/14 14:46:30.750 kid1| 33,3| /client_side.cc(4154) 
> unpinConnection: local=192.168.41.35:47842 remote=172.217.13.206:443 FD 
> 13 flags=1
> 2024/06/14 14:46:30.750 kid1| 33,5| src/base/AsyncCall.cc(54) cancel: 
> will not call ConnStateData::clientPinnedConnectionClosed [call63] 
> because comm_remove_close_handler
> 2024/06/14 14:46:30.750 kid1| 33,3| src/base/AsyncCall.cc(54) cancel: 
> will not call ConnStateData::clientPinnedConnectionRead [call64] because 
> comm_read_cancel
> 2024/06/14 14:46:30.750 kid1| 33,3| src/base/AsyncCall.cc(54) cancel: 
> will not call ConnStateData::clientPinnedConnectionRead [call64] also 
> because comm_read_cancel
> 2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(978) 
> peerAddFwdServer: adding HIER_DIRECT#127.0.0.1
> 2024/06/14 14:46:30.750 kid1| 44,2| /peer_select.cc(295) 
> peerSelectDnsPaths: Find IP destination for: 
> http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=' via 127.0.0.1
> 2024/06/14 14:46:30.750 kid1| 44,2| /peer_select.cc(316) 
> peerSelectDnsPaths: Found sources for 
> 'http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener='
> 2024/06/14 14:46:30.750 kid1| 44,2| /peer_select.cc(317) 
> peerSelectDnsPaths:?? always_direct = ALLOWED
> 2024/06/14 14:46:30.750 kid1| 44,2| /peer_select.cc(318) 
> peerSelectDnsPaths:??? never_direct = DENIED
> 2024/06/14 14:46:30.750 kid1| 44,2| /peer_select.cc(322) 
> peerSelectDnsPaths:????????? DIRECT = local=0.0.0.0 
> remote=127.0.0.1:8081 flags=1
> 2024/06/14 14:46:30.750 kid1| 44,2| /peer_select.cc(331) 
> peerSelectDnsPaths:??????? timedout = 0
> 2024/06/14 14:46:30.750 kid1| 17,3| /FwdState.cc(418) 
> startConnectionOrFail: 
> http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
> 2024/06/14 14:46:30.750 kid1| 17,3| /FwdState.cc(832) connectStart: 
> fwdConnectStart: 
> http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
> 2024/06/14 14:46:30.750 kid1| 17,3| src/base/AsyncCall.cc(25) AsyncCall: 
> The AsyncCall fwdConnectDoneWrapper constructed, this=0x559ad7e16a00 
> [call81]
> 2024/06/14 14:46:30.750 kid1| 44,3| /peer_select.cc(103) ~ps_state: 
> http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
> 2024/06/14 14:46:30.750 kid1| 17,3| src/base/AsyncCall.cc(92) 
> ScheduleCall: ../../../squid-4.16/src/comm/ConnOpener.cc(139) will call 
> fwdConnectDoneWrapper(local=127.0.0.1:45660 remote=127.0.0.1:8081 FD 13 
> flags=1, data=0x559ad7e89b88) [call81]
> 2024/06/14 14:46:30.750 kid1| 17,3| src/base/AsyncCallQueue.cc(55) 
> fireNext: entering fwdConnectDoneWrapper(local=127.0.0.1:45660 
> remote=127.0.0.1:8081 FD 13 flags=1, data=0x559ad7e89b88)
> 2024/06/14 14:46:30.750 kid1| 17,3| src/base/AsyncCall.cc(37) make: make 
> call fwdConnectDoneWrapper [call81]
> 2024/06/14 14:46:30.750 kid1| 17,3| /FwdState.cc(706) connectDone: 
> local=127.0.0.1:45660 remote=127.0.0.1:8081 FD 13 flags=1: 
> 'http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener='
> 
> log excerpt for the same setup from squid-v6.9 (Squid reporting 
> ERR_CANNOT_FORWARD)
> 
> 024/06/14 14:59:40.463 kid1| 61,5| /redirect.cc(83) redirectHandleReply: 
> reply={result=OK, notes={rewrite-url: 
> http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=; cf-info: DENIED,proxy%2dnet%5cnoyoutub
> 2024/06/14 14:59:40.463 kid1| 61,2| /client_side_request.cc(1236) 
> clientRedirectDone: URL-rewriter diverts URL from https://youtube.com/ 
> to 
> http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
> 2024/06/14 14:59:40.463 kid1| 33,5| /store_client.cc(374) doCopy: 
> 0x55a9d80fc678 into ioBuf(@0, len=4096, 0x55a9d8127770) hi: 0 objectLen: 
> -1 past_answers: 0
> 2024/06/14 14:59:40.463 kid1| 17,3| /FwdState.cc(373) Start: 
> 'http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener='
> 2024/06/14 14:59:40.463 kid1| 17,2| /FwdState.cc(133) FwdState: 
> Forwarding client request conn19 local=172.217.13.206:443 
> remote=192.168.180.10:55036 FD 11 flags=33, 
> url=http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2
> 2024/06/14 14:59:40.463 kid1| 17,3| /FwdState.cc(140) FwdState: FwdState 
> constructed, this=0x55a9d812ceb8
> 2024/06/14 14:59:40.463 kid1| 17,4| src/base/AsyncCall.cc(29) AsyncCall: 
> The AsyncCall FwdState::Abort constructed, this=0x55a9d80fc790 [call90]
> 2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(309) peerSelect: 
> e:=XIV/0x55a9d80fc5f0*3 
> http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
> 2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(612) selectMore: GET 
> 127.0.0.1
> 2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(617) selectMore: 
> direct = DIRECT_UNKNOWN (always_direct to be checked)
> 2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(373) 
> checkAlwaysDirectDone: ALLOWED
> 2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(379) 
> checkAlwaysDirectDone: direct = DIRECT_YES (always_direct allow)
> 2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(612) selectMore: GET 
> 127.0.0.1
> 2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(1102) addSelection: 
> adding PINNED#127.0.0.1
> 2024/06/14 14:59:40.463 kid1| 44,3| /peer_select.cc(1102) addSelection: 
> adding HIER_DIRECT#127.0.0.1
> 2024/06/14 14:59:40.463 kid1| 44,2| /peer_select.cc(1176) handlePath: 
> PeerSelector2 found pinned, destination #1 for 
> http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
> 2024/06/14 14:59:40.463 kid1| 44,2| /peer_select.cc(1180) handlePath:  
>  ?always_direct = ALLOWED
> 2024/06/14 14:59:40.463 kid1| 44,2| /peer_select.cc(1181) handlePath:    
> never_direct = DENIED
> 2024/06/14 14:59:40.463 kid1| 44,2| /peer_select.cc(1182) handlePath:  
>  ????? timedout = 0
> 2024/06/14 14:59:40.463 kid1| 33,7| /client_side.cc(3954) 
> borrowPinnedConnection: conn30 local=192.168.41.35:50322 
> remote=172.217.13.206:443 ORIGINAL_DST FD 13 flags=1
> 2024/06/14 14:59:40.463 kid1| 33,3| /client_side.cc(3997) 
> unpinConnection: conn30 local=192.168.41.35:50322 
> remote=172.217.13.206:443 ORIGINAL_DST FD 13 flags=1
> 2024/06/14 14:59:40.463 kid1| 33,5| src/base/AsyncCall.cc(58) cancel: 
> will not call ConnStateData::clientPinnedConnectionClosed [call73] 
> because comm_remove_close_handler
> 2024/06/14 14:59:40.463 kid1| 33,3| src/base/AsyncCall.cc(58) cancel: 
> will not call ConnStateData::clientPinnedConnectionRead [call74] because 
> comm_read_cancel
> 2024/06/14 14:59:40.463 kid1| 33,3| src/base/AsyncCall.cc(58) cancel: 
> will not call ConnStateData::clientPinnedConnectionRead [call74] also 
> because comm_read_cancel
> 2024/06/14 14:59:40.465 kid1| 17,3| /FwdState.cc(471) fail: 
> ERR_CANNOT_FORWARD "Service Unavailable"
>          
> http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
> 2024/06/14 14:59:40.465 kid1| 17,3| /FwdState.cc(185) stopAndDestroy: 
> for pinned connection failure
> 2024/06/14 14:59:40.465 kid1| 44,3| /peer_select.cc(1149) 
> interestedInitiator: PeerSelector2 initiator lost interest
> 2024/06/14 14:59:40.465 kid1| 44,3| /peer_select.cc(405) 
> selectionAborted: Aborting peer selection: Initiator gone or lost interest.
> 2024/06/14 14:59:40.465 kid1| 44,3| /peer_select.cc(241) ~PeerSelector: 
> http://127.0.0.1:8081/?cat=&cat_all=&action=URLLIST&srv=&url=https%3a%2f%2fyoutube%2ecom%2f&shortener=
> 2024/06/14 14:59:40.465 kid1| 17,3| /FwdState.cc(310) ~FwdState: 
> FwdState destructor start
> 2024/06/14 14:59:40.466 kid1| 33,5| /store_client.cc(374) doCopy: 
> 0x55a9d80fc678 into ioBuf(@0, len=4096, 0x55a9d8127770) hi: 148495 
> objectLen: -1 past_answers: 0
> 2024/06/14 14:59:40.466 kid1| 33,5| /store_client.cc(422) doCopy: just 
> send HTTP headers: 207
> 2024/06/14 14:59:40.466 kid1| 17,4| src/base/AsyncCall.cc(58) cancel: 
> will not call FwdState::Abort [call90] because FwdState object destructed
> 2024/06/14 14:59:40.466 kid1| 17,3| /FwdState.cc(332) ~FwdState: 
> FwdState destructed, this=0x55a9d812ceb8
> 



From stu at spacehopper.org  Thu Jun 20 12:42:40 2024
From: stu at spacehopper.org (Stuart Henderson)
Date: Thu, 20 Jun 2024 12:42:40 -0000 (UTC)
Subject: [squid-users] Anybody still using src_as and dst_as ACLs?
References: <a89c484c-f214-4b75-a0de-9df35e2456a9@measurement-factory.com>
Message-ID: <slrnv788u0.h8a.stu.lists@naiad.spacehopper.org>

On 2024-06-16, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>      Does anybody still have src_as and dst_as ACLs configured in their 
> production Squids? There are several serious problems with those ACLs, 
> and those problems have been present in Squid for many years. I hope 
> that virtually nobody uses those ACLs today.

In case anyone still does, replacing with a config file fragment
included from the main squid.conf and generated by simple processing
on output from bgpq4 or a similar tool would be fairly straightforward
(and more featureful, as it can follow AS-SET macros).




From pheriko.support at gmail.com  Fri Jun 21 03:53:07 2024
From: pheriko.support at gmail.com (Periko Support)
Date: Thu, 20 Jun 2024 20:53:07 -0700
Subject: [squid-users] Simulate connections for tuning squid?
In-Reply-To: <202406161325.17458.Antony.Stone@squid.open.source.it>
References: <CAK2yrTbTD6t0WHmMvfBKUWYzapFoXjt2EQshqSyFh-CVQiw+Tg@mail.gmail.com>
 <39e268df-fcad-4460-a951-1654acb2f822@measurement-factory.com>
 <44fc0eaa-8215-44a1-8fb5-ba20cc6611e8@articatech.com>
 <202406161325.17458.Antony.Stone@squid.open.source.it>
Message-ID: <CAK2yrTa8yrs4aMYW-HoqgM7Uw=CjQSWP3UaB40h-WfLYs4ZRZw@mail.gmail.com>

Wow, yeay I test the tool and let you know, thanks!!!

On Sun, Jun 16, 2024 at 4:25?AM Antony Stone
<Antony.Stone at squid.open.source.it> wrote:
>
> On Sunday 16 June 2024 at 12:27:03, David Touzeau wrote:
>
> > Hi
> >
> > We have made such a tool for us.
>
> > Available free of charge with no restrictions
>
> I think it would be a good idea to publish a tool like this explicitly under a
> well-known licence.  It makes life considerably simpler for people who care
> about compliance if they can say "these things we use are all under licence X"
> because then everyone knows exactly what that means.
>
>
> Antony.
>
> --
> I don't know, maybe if we all waited then cosmic rays would write all our
> software for us. Of course it might take a while.
>
>  - Ron Minnich, Los Alamos National Laboratory
>
>                                                    Please reply to the list;
>                                                          please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From j.ohms at tu-braunschweig.de  Tue Jun 25 06:34:39 2024
From: j.ohms at tu-braunschweig.de (Ohms, Jannis)
Date: Tue, 25 Jun 2024 06:34:39 +0000
Subject: [squid-users] Requesting Help to debug my squid
Message-ID: <deb6c6da4bce4dcdbef9c7ef6a0ce040@tu-braunschweig.de>

Hi all,

I run Squid 6.6  my  squid crashes  periodically I recive logs similar to this  one

2024-06-25T08:14:04.539274+02:00 surfer-proxy squid[585630]: Starting Squid Cache version 6.6 for x86_64-pc-linux-gnu...
2024-06-25T08:14:04.539391+02:00 surfer-proxy squid[585630]: Service Name: squid
2024-06-25T08:14:04.539457+02:00 surfer-proxy squid[585630]: Process ID 585630
2024-06-25T08:14:04.539525+02:00 surfer-proxy squid[585630]: Process Roles: worker
2024-06-25T08:14:04.539587+02:00 surfer-proxy squid[585630]: With 16348 file descriptors available
2024-06-25T08:14:04.539647+02:00 surfer-proxy squid[585630]: Initializing IP Cache...
2024-06-25T08:14:04.539821+02:00 surfer-proxy squid[585630]: DNS IPv6 socket created at [::], FD 8
2024-06-25T08:14:04.539893+02:00 surfer-proxy squid[585630]: DNS IPv4 socket created at 0.0.0.0, FD 9
2024-06-25T08:14:04.539955+02:00 surfer-proxy squid[585630]: Adding nameserver 127.0.0.1 from /etc/resolv.conf
2024-06-25T08:14:04.540026+02:00 surfer-proxy squid[585630]: Adding domain biblio.etc.tu-bs.de from /etc/resolv.conf
2024-06-25T08:14:04.540091+02:00 surfer-proxy squid[585630]: Adding domain surfer.unibib.local from /etc/resolv.conf
2024-06-25T08:14:04.552194+02:00 surfer-proxy squid[585630]: Logfile: opening log stdio:/var/log/squid/access.log
2024-06-25T08:14:04.804840+02:00 surfer-proxy squid[585630]: Unlinkd pipe opened on FD 14
2024-06-25T08:14:04.809285+02:00 surfer-proxy squid[585630]: Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2024-06-25T08:14:04.809435+02:00 surfer-proxy squid[585630]: Store logging disabled
2024-06-25T08:14:04.809513+02:00 surfer-proxy squid[585630]: Swap maxSize 102400 + 98304 KB, estimated 15438 objects
2024-06-25T08:14:04.809577+02:00 surfer-proxy squid[585630]: Target number of buckets: 771
2024-06-25T08:14:04.809647+02:00 surfer-proxy squid[585630]: Using 8192 Store buckets
2024-06-25T08:14:04.809715+02:00 surfer-proxy squid[585630]: Max Mem  size: 98304 KB
2024-06-25T08:14:04.809775+02:00 surfer-proxy squid[585630]: Max Swap size: 102400 KB
2024-06-25T08:14:04.810390+02:00 surfer-proxy squid[585630]: Rebuilding storage in /var/squid/cache (dirty log)
2024-06-25T08:14:04.810535+02:00 surfer-proxy squid[585630]: Using Least Load store dir selection
2024-06-25T08:14:04.810635+02:00 surfer-proxy squid[585630]: Current Directory is /
2024-06-25T08:14:04.860606+02:00 surfer-proxy squid[585630]: Finished loading MIME types and icons.
2024-06-25T08:14:04.861090+02:00 surfer-proxy squid[585630]: HTCP Disabled.
2024-06-25T08:14:04.862578+02:00 surfer-proxy squid[585630]: Pinger socket opened on FD 19
2024-06-25T08:14:04.862850+02:00 surfer-proxy squid[585630]: Squid plugin modules loaded: 0
2024-06-25T08:14:04.862931+02:00 surfer-proxy squid[585630]: Adaptation support is off.
2024-06-25T08:14:04.862999+02:00 surfer-proxy squid[585630]: Accepting HTTP Socket connections at conn3 local=[::]:8080 remote=[::] FD 17 flags=9#012    listening port: 8080
2024-06-25T08:14:04.882088+02:00 surfer-proxy squid[585630]: Done reading /var/squid/cache swaplog (540 entries)
2024-06-25T08:14:04.882254+02:00 surfer-proxy squid[585630]: Finished rebuilding storage from disk.#012        540 Entries scanned#012          0 Invalid entries#012          0 With invalid flags#012        540 Objects loaded#012          0 Objects expired#012          0 Objects canceled#012          0 Duplicate URLs purged#012          0 Swapfile clashes avoided#012    Took 0.07 seconds (7526.24 objects/sec).
2024-06-25T08:14:04.882339+02:00 surfer-proxy squid[585630]: Beginning Validation Procedure
2024-06-25T08:14:04.882619+02:00 surfer-proxy squid[585630]: Completed Validation Procedure#012    Validated 540 Entries#012    store_swap_size = 18780.00 KB
2024-06-25T08:14:05.044043+02:00 surfer-proxy squid[585630]: FATAL: assertion failed: FilledChecklist.cc:263: "!rfc931[0]"#012    current master transaction: master57
2024-06-25T08:14:05.181283+02:00 surfer-proxy squid[585262]: Squid Parent: squid-1 process 585630 exited due to signal 6 with status 0
2024-06-25T08:14:05.181485+02:00 surfer-proxy squid[585262]: Squid Parent: squid-1 process 585630 will not be restarted for 3600 seconds due to repeated, frequent failures
2024-06-25T08:14:05.182410+02:00 surfer-proxy squid[585262]: Exiting due to repeated, frequent failures
2024-06-25T08:14:05.182520+02:00 surfer-proxy squid[585262]: Removing PID file (/run/squid.pid)
2024-06-25T08:14:05.191194+02:00 surfer-proxy systemd[1]: squid.service: Main process exited, code=exited, status=1/FAILURE
2024-06-25T08:14:05.191417+02:00 surfer-proxy systemd[1]: squid.service: Killing process 585610 (pinger) with signal SIGKILL.
2024-06-25T08:14:05.191477+02:00 surfer-proxy systemd[1]: squid.service: Killing process 585615 (pinger) with signal SIGKILL.
2024-06-25T08:14:05.191515+02:00 surfer-proxy systemd[1]: squid.service: Killing process 585622 (pinger) with signal SIGKILL.
2024-06-25T08:14:05.191554+02:00 surfer-proxy systemd[1]: squid.service: Killing process 585627 (pinger) with signal SIGKILL.
2024-06-25T08:14:05.191593+02:00 surfer-proxy systemd[1]: squid.service: Killing process 585632 (pinger) with signal SIGKILL.
2024-06-25T08:14:05.193169+02:00 surfer-proxy systemd[1]: squid.service: Failed with result 'exit-code'.
2024-06-25T08:14:05.193809+02:00 surfer-proxy systemd[1]: squid.service: Consumed 2.090s CPU time, 32.9M memory peak, 0B memory swap peak.

The log seems to indicate that some assertion is failing.
Is this an assertion on the swaplog or my config ?
would it help to purge the swap log
is it possible to restive the  element which violates the assertion

Feel free to ask for additional information

Any Hints are welcome. I am new to squid and inherited this project

Thanks

Jannis

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20240625/f9d315a9/attachment.htm>

From rousskov at measurement-factory.com  Tue Jun 25 13:13:02 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 25 Jun 2024 09:13:02 -0400
Subject: [squid-users] Requesting Help to debug my squid
In-Reply-To: <deb6c6da4bce4dcdbef9c7ef6a0ce040@tu-braunschweig.de>
References: <deb6c6da4bce4dcdbef9c7ef6a0ce040@tu-braunschweig.de>
Message-ID: <62212349-98a6-432b-9741-abb256f51bf9@measurement-factory.com>

On 2024-06-25 02:34, Ohms, Jannis wrote:

> I run Squid 6.6 ?my ?squid crashes ?periodically I recive logs similar 
> to this? one

> 2024-06-25T08:14:05.044043+02:00 surfer-proxy squid[585630]: FATAL: 
> assertion failed: FilledChecklist.cc:263: "!rfc931[0]"

The above assertion is a Squid bug related to Ident support (RFC 931 
obsoleted by RFC 1413). There are other Ident bugs and problems in 
Squid. Our recent comprehensive fix[1] for master/v7 was superseded by 
removing Ident support itself (master/v7 commit e94ff52 [2]). Squid v6 
still has (buggy) Ident code.

If you do not really need Ident, stop using Ident features[3] in 
squid.conf and disable Ident support when building Squid:
     ./configure --disable-ident-lookups ...

If you do need Ident, consider writing an external_acl helper that 
performs Ident lookups and then disable native Ident support in Squid.


HTH,

Alex.

[1] https://github.com/squid-cache/squid/pull/1815

[2] 
https://github.com/squid-cache/squid/commit/e94ff5274ce05e6f06d7c789bb2c6452c7886584

[3] Ident features include: ident/ident_regex ACLs, %ui logformat codes, 
%IDENT external_acl_type format code, and ident_lookup_access/ident_timeout
directives.



From codemarauder at gmail.com  Thu Jun 27 14:35:01 2024
From: codemarauder at gmail.com (Nishant Sharma)
Date: Thu, 27 Jun 2024 20:05:01 +0530
Subject: [squid-users] FATAL: assertion failed: mem/PageStack.cc:159:
 "StoredNode().is_lock_free()"
Message-ID: <f399b9c1-9b62-4de2-81d3-893d5eb22fa7@gmail.com>

Hello,

I am running squid 6.10 on Openwrt 23.05.2, which is cross compiled for 
ramips / mipsel_24kc which has a 32 bit CPU (MT7621A) with 2 cores and 2 
threads.

Squid fails to start in SMP mode when I set workers > 1.

SMP worked fine with squid 4.13 on same architecture.

I have filed a bug report with Openwrt at

https://github.com/openwrt/packages/issues/24469

where someone suggested, "ramips has one CPU and the assert is that 
system pointers are not 64bit."

Below are the logs for debug_options 54,9:

2024/06/27 19:48:45.888| 54,3| mem/Segment.cc(245) unlink: unlinked 
/squid-cf__metadata.shm segment
2024/06/27 19:48:45.888| 54,3| mem/Segment.cc(128) create: created 
/squid-cf__metadata.shm segment: 8
2024/06/27 19:48:45.888| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing 
disabled
2024/06/27 19:48:45.889| 54,3| mem/Segment.cc(245) unlink: unlinked 
/squid-cf__queues.shm segment
2024/06/27 19:48:45.889| 54,3| mem/Segment.cc(128) create: created 
/squid-cf__queues.shm segment: 32852
2024/06/27 19:48:45.889| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing 
disabled
2024/06/27 19:48:45.890| 54,3| mem/Segment.cc(245) unlink: unlinked 
/squid-cf__readers.shm segment
2024/06/27 19:48:45.890| 54,3| mem/Segment.cc(128) create: created 
/squid-cf__readers.shm segment: 40
2024/06/27 19:48:45.890| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing 
disabled
2024/06/27 19:48:45.891| 54,7| Queue.cc(50) QueueReader: constructed ipcQR1
2024/06/27 19:48:45.891| 54,7| Queue.cc(50) QueueReader: constructed ipcQR2
2024/06/27 19:48:45.891| 54,5| mem/PageStack.cc(129) IdSetMeasurements: 
rounded capacity up from 8192 to 8192
2024/06/27 19:48:45.891| 54,3| mem/Segment.cc(245) unlink: unlinked 
/squid-squid-page-pool.shm segment
2024/06/27 19:48:45.892| 54,3| mem/Segment.cc(128) create: created 
/squid-squid-page-pool.shm segment: 268437592
2024/06/27 19:48:45.892| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing 
disabled
2024/06/27 19:48:45.892| 54,5| mem/PageStack.cc(129) IdSetMeasurements: 
rounded capacity up from 8192 to 8192
2024/06/27 19:48:45| FATAL: assertion failed: mem/PageStack.cc:159: 
"StoredNode().is_lock_free()"


Any pointers would be really helpful.

Thanks in advance.

Regards,
Nishant


From jonathanlee571 at gmail.com  Thu Jun 27 15:55:53 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 27 Jun 2024 08:55:53 -0700
Subject: [squid-users] FATAL: assertion failed: mem/PageStack.cc:159:
 "StoredNode().is_lock_free()"
In-Reply-To: <f399b9c1-9b62-4de2-81d3-893d5eb22fa7@gmail.com>
References: <f399b9c1-9b62-4de2-81d3-893d5eb22fa7@gmail.com>
Message-ID: <E4ACDE05-8056-4119-94FE-994FF9D00995@gmail.com>

Has anyone ran this on a Banana Pi r3 or r4? 
Sent from my iPhone

> On Jun 27, 2024, at 08:12, Nishant Sharma <codemarauder at gmail.com> wrote:
> 
> ?Hello,
> 
> I am running squid 6.10 on Openwrt 23.05.2, which is cross compiled for ramips / mipsel_24kc which has a 32 bit CPU (MT7621A) with 2 cores and 2 threads.
> 
> Squid fails to start in SMP mode when I set workers > 1.
> 
> SMP worked fine with squid 4.13 on same architecture.
> 
> I have filed a bug report with Openwrt at
> 
> https://github.com/openwrt/packages/issues/24469
> 
> where someone suggested, "ramips has one CPU and the assert is that system pointers are not 64bit."
> 
> Below are the logs for debug_options 54,9:
> 
> 2024/06/27 19:48:45.888| 54,3| mem/Segment.cc(245) unlink: unlinked /squid-cf__metadata.shm segment
> 2024/06/27 19:48:45.888| 54,3| mem/Segment.cc(128) create: created /squid-cf__metadata.shm segment: 8
> 2024/06/27 19:48:45.888| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing disabled
> 2024/06/27 19:48:45.889| 54,3| mem/Segment.cc(245) unlink: unlinked /squid-cf__queues.shm segment
> 2024/06/27 19:48:45.889| 54,3| mem/Segment.cc(128) create: created /squid-cf__queues.shm segment: 32852
> 2024/06/27 19:48:45.889| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing disabled
> 2024/06/27 19:48:45.890| 54,3| mem/Segment.cc(245) unlink: unlinked /squid-cf__readers.shm segment
> 2024/06/27 19:48:45.890| 54,3| mem/Segment.cc(128) create: created /squid-cf__readers.shm segment: 40
> 2024/06/27 19:48:45.890| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing disabled
> 2024/06/27 19:48:45.891| 54,7| Queue.cc(50) QueueReader: constructed ipcQR1
> 2024/06/27 19:48:45.891| 54,7| Queue.cc(50) QueueReader: constructed ipcQR2
> 2024/06/27 19:48:45.891| 54,5| mem/PageStack.cc(129) IdSetMeasurements: rounded capacity up from 8192 to 8192
> 2024/06/27 19:48:45.891| 54,3| mem/Segment.cc(245) unlink: unlinked /squid-squid-page-pool.shm segment
> 2024/06/27 19:48:45.892| 54,3| mem/Segment.cc(128) create: created /squid-squid-page-pool.shm segment: 268437592
> 2024/06/27 19:48:45.892| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing disabled
> 2024/06/27 19:48:45.892| 54,5| mem/PageStack.cc(129) IdSetMeasurements: rounded capacity up from 8192 to 8192
> 2024/06/27 19:48:45| FATAL: assertion failed: mem/PageStack.cc:159: "StoredNode().is_lock_free()"
> 
> 
> Any pointers would be really helpful.
> 
> Thanks in advance.
> 
> Regards,
> Nishant
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From jonathanlee571 at gmail.com  Thu Jun 27 15:57:32 2024
From: jonathanlee571 at gmail.com (Jonathan Lee)
Date: Thu, 27 Jun 2024 08:57:32 -0700
Subject: [squid-users] FATAL: assertion failed: mem/PageStack.cc:159:
 "StoredNode().is_lock_free()"
In-Reply-To: <f399b9c1-9b62-4de2-81d3-893d5eb22fa7@gmail.com>
References: <f399b9c1-9b62-4de2-81d3-893d5eb22fa7@gmail.com>
Message-ID: <8DFE7B71-5AF7-4159-85C3-BDF84C3930A9@gmail.com>

I have Squid 5.8 I can?t start it with multiple workers enabled in pfSense also. It is a 64bit 2100MAX
Sent from my iPhone

> On Jun 27, 2024, at 08:12, Nishant Sharma <codemarauder at gmail.com> wrote:
> 
> ?Hello,
> 
> I am running squid 6.10 on Openwrt 23.05.2, which is cross compiled for ramips / mipsel_24kc which has a 32 bit CPU (MT7621A) with 2 cores and 2 threads.
> 
> Squid fails to start in SMP mode when I set workers > 1.
> 
> SMP worked fine with squid 4.13 on same architecture.
> 
> I have filed a bug report with Openwrt at
> 
> https://github.com/openwrt/packages/issues/24469
> 
> where someone suggested, "ramips has one CPU and the assert is that system pointers are not 64bit."
> 
> Below are the logs for debug_options 54,9:
> 
> 2024/06/27 19:48:45.888| 54,3| mem/Segment.cc(245) unlink: unlinked /squid-cf__metadata.shm segment
> 2024/06/27 19:48:45.888| 54,3| mem/Segment.cc(128) create: created /squid-cf__metadata.shm segment: 8
> 2024/06/27 19:48:45.888| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing disabled
> 2024/06/27 19:48:45.889| 54,3| mem/Segment.cc(245) unlink: unlinked /squid-cf__queues.shm segment
> 2024/06/27 19:48:45.889| 54,3| mem/Segment.cc(128) create: created /squid-cf__queues.shm segment: 32852
> 2024/06/27 19:48:45.889| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing disabled
> 2024/06/27 19:48:45.890| 54,3| mem/Segment.cc(245) unlink: unlinked /squid-cf__readers.shm segment
> 2024/06/27 19:48:45.890| 54,3| mem/Segment.cc(128) create: created /squid-cf__readers.shm segment: 40
> 2024/06/27 19:48:45.890| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing disabled
> 2024/06/27 19:48:45.891| 54,7| Queue.cc(50) QueueReader: constructed ipcQR1
> 2024/06/27 19:48:45.891| 54,7| Queue.cc(50) QueueReader: constructed ipcQR2
> 2024/06/27 19:48:45.891| 54,5| mem/PageStack.cc(129) IdSetMeasurements: rounded capacity up from 8192 to 8192
> 2024/06/27 19:48:45.891| 54,3| mem/Segment.cc(245) unlink: unlinked /squid-squid-page-pool.shm segment
> 2024/06/27 19:48:45.892| 54,3| mem/Segment.cc(128) create: created /squid-squid-page-pool.shm segment: 268437592
> 2024/06/27 19:48:45.892| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing disabled
> 2024/06/27 19:48:45.892| 54,5| mem/PageStack.cc(129) IdSetMeasurements: rounded capacity up from 8192 to 8192
> 2024/06/27 19:48:45| FATAL: assertion failed: mem/PageStack.cc:159: "StoredNode().is_lock_free()"
> 
> 
> Any pointers would be really helpful.
> 
> Thanks in advance.
> 
> Regards,
> Nishant
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Thu Jun 27 17:36:05 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 27 Jun 2024 13:36:05 -0400
Subject: [squid-users] FATAL: assertion failed: mem/PageStack.cc:159:
 "StoredNode().is_lock_free()"
In-Reply-To: <f399b9c1-9b62-4de2-81d3-893d5eb22fa7@gmail.com>
References: <f399b9c1-9b62-4de2-81d3-893d5eb22fa7@gmail.com>
Message-ID: <f07dddcd-8f6e-422e-b21b-9b9d9a60c718@measurement-factory.com>

On 2024-06-27 10:35, Nishant Sharma wrote:

> I am running squid 6.10 on Openwrt 23.05.2, which is cross compiled for 
> ramips / mipsel_24kc which has a 32 bit CPU (MT7621A) with 2 cores and 2 
> threads.
> 
> Squid fails to start in SMP mode when I set workers > 1.

The assertion in question may be overreaching -- I suspect the relevant 
code works correctly when std::atomic<uint64_t>::is_lock_free() is 
false. Depending on how those locks are implemented in your environment, 
and how your traffic tickles them, SMP Squid without atomic locks might 
become very slow! We do not (and, IMO, should not) optimize performance 
for environments without lock-free atomics!

I see the following options for going forward:

* Comment out the assertion, void your warranty, and hope for the best.
* Audit relevant code to confirm that the assertion is safe to remove.
* Find a usable OS/environment that has lock-free 64-bit atomics.


> SMP worked fine with squid 4.13 on same architecture.

SMP Squid v4 has an ABA problem that could, at least in theory, result 
in silent cache corruption. If you are interested in low-level details, 
please see commit 7a5af8db message:
https://github.com/squid-cache/squid/commit/7a5af8db


HTH,

Alex.


> I have filed a bug report with Openwrt at
> 
> https://github.com/openwrt/packages/issues/24469
> 
> where someone suggested, "ramips has one CPU and the assert is that 
> system pointers are not 64bit."
> 
> Below are the logs for debug_options 54,9:
> 
> 2024/06/27 19:48:45.888| 54,3| mem/Segment.cc(245) unlink: unlinked 
> /squid-cf__metadata.shm segment
> 2024/06/27 19:48:45.888| 54,3| mem/Segment.cc(128) create: created 
> /squid-cf__metadata.shm segment: 8
> 2024/06/27 19:48:45.888| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing 
> disabled
> 2024/06/27 19:48:45.889| 54,3| mem/Segment.cc(245) unlink: unlinked 
> /squid-cf__queues.shm segment
> 2024/06/27 19:48:45.889| 54,3| mem/Segment.cc(128) create: created 
> /squid-cf__queues.shm segment: 32852
> 2024/06/27 19:48:45.889| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing 
> disabled
> 2024/06/27 19:48:45.890| 54,3| mem/Segment.cc(245) unlink: unlinked 
> /squid-cf__readers.shm segment
> 2024/06/27 19:48:45.890| 54,3| mem/Segment.cc(128) create: created 
> /squid-cf__readers.shm segment: 40
> 2024/06/27 19:48:45.890| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing 
> disabled
> 2024/06/27 19:48:45.891| 54,7| Queue.cc(50) QueueReader: constructed ipcQR1
> 2024/06/27 19:48:45.891| 54,7| Queue.cc(50) QueueReader: constructed ipcQR2
> 2024/06/27 19:48:45.891| 54,5| mem/PageStack.cc(129) IdSetMeasurements: 
> rounded capacity up from 8192 to 8192
> 2024/06/27 19:48:45.891| 54,3| mem/Segment.cc(245) unlink: unlinked 
> /squid-squid-page-pool.shm segment
> 2024/06/27 19:48:45.892| 54,3| mem/Segment.cc(128) create: created 
> /squid-squid-page-pool.shm segment: 268437592
> 2024/06/27 19:48:45.892| 54,5| mem/Segment.cc(211) lock: mlock(2)-ing 
> disabled
> 2024/06/27 19:48:45.892| 54,5| mem/PageStack.cc(129) IdSetMeasurements: 
> rounded capacity up from 8192 to 8192
> 2024/06/27 19:48:45| FATAL: assertion failed: mem/PageStack.cc:159: 
> "StoredNode().is_lock_free()"
> 
> 
> Any pointers would be really helpful.
> 
> Thanks in advance.
> 
> Regards,
> Nishant
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> https://lists.squid-cache.org/listinfo/squid-users



From codemarauder at gmail.com  Fri Jun 28 05:38:46 2024
From: codemarauder at gmail.com (Nishant Sharma)
Date: Fri, 28 Jun 2024 11:08:46 +0530
Subject: [squid-users] FATAL: assertion failed: mem/PageStack.cc:159:
 "StoredNode().is_lock_free()"
In-Reply-To: <f07dddcd-8f6e-422e-b21b-9b9d9a60c718@measurement-factory.com>
References: <f399b9c1-9b62-4de2-81d3-893d5eb22fa7@gmail.com>
 <f07dddcd-8f6e-422e-b21b-9b9d9a60c718@measurement-factory.com>
Message-ID: <91526e3e-39cf-4ba5-9aac-a90729170993@gmail.com>

Thanks for your reply Alex.

On 27/06/24 23:06, Alex Rousskov wrote:
> and how your traffic tickles them, SMP Squid without atomic locks might 
> become very slow! We do not (and, IMO, should not) optimize performance 
> for environments without lock-free atomics!
> 
> I see the following options for going forward:
> 
> * Comment out the assertion, void your warranty, and hope for the best.
> * Audit relevant code to confirm that the assertion is safe to remove.
> * Find a usable OS/environment that has lock-free 64-bit atomics.

I am not a developer, so it will take me some help to get the code and 
repercussions of it's modification understood.

In our use case, we do not use caching at all except a small in-memory 
cache of say 64MB.

Squid is used for access control with external acl helper and SSL Bump 
where SMP used to help with version 4.x.

Would it be catastrophic to comment out the assertion and then remove 
relevant code for such a use case where there is no disk cache available 
for probable corruption?

Regards,
Nishant


From rousskov at measurement-factory.com  Fri Jun 28 14:14:30 2024
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 28 Jun 2024 10:14:30 -0400
Subject: [squid-users] FATAL: assertion failed: mem/PageStack.cc:159:
 "StoredNode().is_lock_free()"
In-Reply-To: <91526e3e-39cf-4ba5-9aac-a90729170993@gmail.com>
References: <f399b9c1-9b62-4de2-81d3-893d5eb22fa7@gmail.com>
 <f07dddcd-8f6e-422e-b21b-9b9d9a60c718@measurement-factory.com>
 <91526e3e-39cf-4ba5-9aac-a90729170993@gmail.com>
Message-ID: <6deef121-649e-4d70-b5fb-92dbc4ec05db@measurement-factory.com>

On 2024-06-28 01:38, Nishant Sharma wrote:
> On 27/06/24 23:06, Alex Rousskov wrote:
>> and how your traffic tickles them, SMP Squid without atomic locks 
>> might become very slow! We do not (and, IMO, should not) optimize 
>> performance for environments without lock-free atomics!
>>
>> I see the following options for going forward:
>>
>> * Comment out the assertion, void your warranty, and hope for the best.
>> * Audit relevant code to confirm that the assertion is safe to remove.
>> * Find a usable OS/environment that has lock-free 64-bit atomics.
> 
> I am not a developer, so it will take me some help to get the code and 
> repercussions of it's modification understood.
> 
> In our use case, we do not use caching at all except a small in-memory 
> cache of say 64MB.
> 
> Squid is used for access control with external acl helper and SSL Bump 
> where SMP used to help with version 4.x.
> 
> Would it be catastrophic to comment out the assertion and then remove 
> relevant code for such a use case where there is no disk cache available 
> for probable corruption?

I do not know the answer to your question. SMP performance penalties are 
often smaller for smaller cache sizes, but cache size is not the only 
performance-affecting locking-sensitive parameter, so YMMV.


 > ... and then remove relevant code ...

Just to avoid a misunderstanding: Other than commenting out the 
assertion line, no code removal is suggested in my bulleted list quoted 
above. The first bullet is a speculative "remove the assertion and see 
what happens" experiment. The second bullet is about reviewing existing 
code (without code modifications) to validate the need for that 
assertion. That audit/validation is required to remove the assertion 
from official Squid sources. That need (and that decision) do not depend 
on cache sizes and other deployment specifics.


HTH,

Alex.



From codemarauder at gmail.com  Fri Jun 28 14:31:49 2024
From: codemarauder at gmail.com (Nishant Sharma)
Date: Fri, 28 Jun 2024 20:01:49 +0530
Subject: [squid-users] FATAL: assertion failed: mem/PageStack.cc:159:
 "StoredNode().is_lock_free()"
In-Reply-To: <6deef121-649e-4d70-b5fb-92dbc4ec05db@measurement-factory.com>
References: <f399b9c1-9b62-4de2-81d3-893d5eb22fa7@gmail.com>
 <f07dddcd-8f6e-422e-b21b-9b9d9a60c718@measurement-factory.com>
 <91526e3e-39cf-4ba5-9aac-a90729170993@gmail.com>
 <6deef121-649e-4d70-b5fb-92dbc4ec05db@measurement-factory.com>
Message-ID: <c9cda733-0838-4cd6-a269-11efcaff80e9@gmail.com>

On 28/06/24 19:44, Alex Rousskov wrote:
> I do not know the answer to your question. SMP performance penalties are 
> often smaller for smaller cache sizes, but cache size is not the only 
> performance-affecting locking-sensitive parameter, so YMMV.

I was able to compile after commenting the specific line of code. Squid 
workers start and I am able to bind them to specific CPU cores.

I will do some extensive testing in the next few days in SMP and non-SMP 
mode before rolling the new version out in the field.
> Just to avoid a misunderstanding: Other than commenting out the 
> assertion line, no code removal is suggested in my bulleted list quoted 
> above. The first bullet is a speculative "remove the assertion and see 
> what happens" experiment. The second bullet is about reviewing existing 
> code (without code modifications) to validate the need for that 
> assertion. That audit/validation is required to remove the assertion 
> from official Squid sources. That need (and that decision) do not depend 
> on cache sizes and other deployment specifics.

I have already acted on first of the bulleted suggestion items list :)

For the next two, I can run tests on these devices under various 
workloads and scenarios, if that helps in validation and further 
decision making.

Thanks again for your help.

Regards,
Nishant


